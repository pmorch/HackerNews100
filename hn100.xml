<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 17 Aug 2024 18:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[X says it is closing operations in Brazil due to judge's content orders (126 pts)]]></title>
            <link>https://www.reuters.com/technology/x-close-operations-brazil-effective-immediately-2024-08-17/</link>
            <guid>41275600</guid>
            <pubDate>Sat, 17 Aug 2024 16:20:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/technology/x-close-operations-brazil-effective-immediately-2024-08-17/">https://www.reuters.com/technology/x-close-operations-brazil-effective-immediately-2024-08-17/</a>, See on <a href="https://news.ycombinator.com/item?id=41275600">Hacker News</a></p>
Couldn't get https://www.reuters.com/technology/x-close-operations-brazil-effective-immediately-2024-08-17/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Ex-Google CEO: AI startups can steal IP and hire lawyers to 'clean up the mess' (135 pts)]]></title>
            <link>https://www.theverge.com/2024/8/14/24220658/google-eric-schmidt-stanford-talk-ai-startups-openai</link>
            <guid>41275073</guid>
            <pubDate>Sat, 17 Aug 2024 15:08:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/8/14/24220658/google-eric-schmidt-stanford-talk-ai-startups-openai">https://www.theverge.com/2024/8/14/24220658/google-eric-schmidt-stanford-talk-ai-startups-openai</a>, See on <a href="https://news.ycombinator.com/item?id=41275073">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article id="content"><div><div><div><h2>Ex-Google CEO says successful AI startups can steal IP and hire lawyers to ‘clean up the mess’</h2><p><span><span> / </span><h2>“But if nobody uses your product, it doesn’t matter that you stole all the content,” Eric Schmidt said during a recent talk at Stanford that has been taken offline.</h2></span></p></div><div><p><span>By</span> <span><span></span> <span><a href="https://www.theverge.com/authors/alex-heath">Alex Heath</a></span><span>, <span>a deputy editor and author of the <i><a href="https://www.theverge.com/command-line-newsletter">Command Line </a></i>newsletter. He has over a decade of experience covering the tech industry.</span></span></span></p><p><time datetime="2024-08-15T00:00:24.437Z"> <!-- -->Aug 15, 2024, 12:00 AM UTC</time></p><div><h2>Share this story</h2></div></div></div><div><figure><span><span></span><img alt="Collision 2022 - Day Two" sizes="(max-width: 768px) calc(100vw - 100px), (max-width: 1180px) 700px, 600px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:7496x5379/16x11/filters:focal(3909x2019:3910x2020):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25572964/1241460753.jpg 16w, https://duet-cdn.vox-cdn.com/thumbor/0x0:7496x5379/32x21/filters:focal(3909x2019:3910x2020):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25572964/1241460753.jpg 32w, https://duet-cdn.vox-cdn.com/thumbor/0x0:7496x5379/48x32/filters:focal(3909x2019:3910x2020):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25572964/1241460753.jpg 48w, https://duet-cdn.vox-cdn.com/thumbor/0x0:7496x5379/64x43/filters:focal(3909x2019:3910x2020):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25572964/1241460753.jpg 64w, https://duet-cdn.vox-cdn.com/thumbor/0x0:7496x5379/96x64/filters:focal(3909x2019:3910x2020):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25572964/1241460753.jpg 96w, https://duet-cdn.vox-cdn.com/thumbor/0x0:7496x5379/128x85/filters:focal(3909x2019:3910x2020):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25572964/1241460753.jpg 128w, https://duet-cdn.vox-cdn.com/thumbor/0x0:7496x5379/256x171/filters:focal(3909x2019:3910x2020):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25572964/1241460753.jpg 256w, https://duet-cdn.vox-cdn.com/thumbor/0x0:7496x5379/376x251/filters:focal(3909x2019:3910x2020):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25572964/1241460753.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:7496x5379/384x256/filters:focal(3909x2019:3910x2020):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25572964/1241460753.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:7496x5379/415x277/filters:focal(3909x2019:3910x2020):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25572964/1241460753.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:7496x5379/480x320/filters:focal(3909x2019:3910x2020):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25572964/1241460753.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:7496x5379/540x360/filters:focal(3909x2019:3910x2020):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25572964/1241460753.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:7496x5379/640x427/filters:focal(3909x2019:3910x2020):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25572964/1241460753.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:7496x5379/750x500/filters:focal(3909x2019:3910x2020):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25572964/1241460753.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:7496x5379/828x552/filters:focal(3909x2019:3910x2020):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25572964/1241460753.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:7496x5379/1080x720/filters:focal(3909x2019:3910x2020):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25572964/1241460753.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:7496x5379/1200x800/filters:focal(3909x2019:3910x2020):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25572964/1241460753.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:7496x5379/1440x960/filters:focal(3909x2019:3910x2020):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25572964/1241460753.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:7496x5379/1920x1280/filters:focal(3909x2019:3910x2020):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25572964/1241460753.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:7496x5379/2048x1365/filters:focal(3909x2019:3910x2020):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25572964/1241460753.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:7496x5379/2400x1600/filters:focal(3909x2019:3910x2020):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25572964/1241460753.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:7496x5379/2400x1600/filters:focal(3909x2019:3910x2020):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25572964/1241460753.jpg" decoding="async" data-nimg="responsive"></span><div><figcaption><em>Eric Schmidt.</em></figcaption> <p><cite>Photo By Lukas Schulze/Sportsfile for Collision via Getty Images</cite></p></div></figure></div></div><div><div><p>Former Google CEO and chairman Eric Schmidt has made headlines for saying that Google was blindsided by the early the rise of ChatGPT because its employees decided that <a href="https://www.theverge.com/2024/8/13/24219912/googles-former-ceo-on-why-the-company-was-caught-off-guard-by-openai">“working from home was more important than winning.”</a></p><p>The comment was made in front of Stanford students during a recent interview, video of which was removed from the university’s YouTube channel after Schmidt’s gaffe was widely picked up by the press. I managed to watch most of Schmidt’s chat with Stanford’s Erik Brynjolfsson before it was taken down, however, and something else he said stands out. (You can still <a href="https://github.com/ociubotaru/transcripts/blob/main/Stanford_ECON295%E2%A7%B8CS323_I_2024_I_The_Age_of_AI%2C_Eric_Schmidt.txt">read the full transcript here</a>.)</p><p>While talking about a future world in which AI agents can do complex tasks on behalf of humans, Schmidt says:</p><div><blockquote><p>If TikTok is banned, here’s what I propose each and every one of you do: Say to your LLM the following: “Make me a copy of TikTok, steal all the users, steal all the music, put my preferences in it, produce this program in the next 30 seconds, release it, and in one hour, if it’s not viral, do something different along the same lines.”</p><p>That’s the command. Boom, boom, boom, boom.</p></blockquote></div><p>A bit later, Schmidt returns to his TikTok example and says:</p><div><blockquote><p>So, in the example that I gave of the TikTok competitor — and by the way, I was not arguing that you should illegally steal everybody’s music — what you would do if you’re a Silicon Valley entrepreneur, which hopefully all of you will be, is if it took off, then you’d hire a whole bunch of lawyers to go clean the mess up, right? But if nobody uses your product, it doesn’t matter that you stole all the content.</p><p>And do not quote me.</p></blockquote></div><p>At this point, Brynjolfsson points out that, “You’re on camera,” to which Schmidt responds:</p><div><blockquote><p>Yeah, that’s right. But you see my point. In other words, Silicon Valley will run these tests and clean up the mess. And that’s typically how those things are done.</p></blockquote></div><p>While Schmidt stepped away from his chairman role at Google in 2015, he remains influential in Silicon Valley and a prolific investor in startups. During this same talk at Stanford, he touts his investment in the AI startup Mistral and being “a licensed arms dealer” to the US military. He also calls Sam Altman “a close friend,” and recalls a recent dinner he had with Elon Musk while praising what the Tesla CEO “gets out of people” who work for him.</p><p>I emailed Schmidt and Brynjolfsson requesting comment about the removal of their chat from YouTube and haven’t heard back yet. Schmidt earlier <a href="https://www.wsj.com/tech/ai/google-eric-schmidt-ai-remote-work-stanford-f92f4ca5">told <em>The Wall Street Journal</em></a><em> </em>that he “misspoke about Google and their work hours” and requested the video be taken down.</p><div><form><div><h2>Command Line</h2><p> / <span>A newsletter from Alex Heath about the tech industry’s inside conversation.</span></p></div></form></div></div><div><p>Most Popular</p><p>Most Popular</p><ol><li><a href="https://www.theverge.com/2024/8/16/24221826/olympics-paris-what-happened-air-conditioning-heat"><h2>What happened to all the temporary air conditioning units at the Olympic Village?</h2></a><hr></li><li><a href="https://www.theverge.com/2024/8/16/24221353/eric-schmidt-says-the-quiet-part-out-loud"><h2>Eric Schmidt says the quiet part out loud</h2></a><hr></li><li><a href="https://www.theverge.com/2024/8/16/24221721/gemini-google-pixel-apple-app-pricing-tv-shootout-vergecast"><h2>Gemini is taking over Google</h2></a><hr></li><li><a href="https://www.theverge.com/2024/8/16/24221755/google-team-pixel-reviews-influencers"><h2>Google threatened tech influencers unless they ‘preferred’ the Pixel</h2></a><hr></li><li><a href="https://www.theverge.com/24220359/google-pixel-9-camera-bar-small-phones-claude-zellweger-interview"><h2>Google’s head of Pixel 9 design won’t apologize for its big, beautiful camera bump</h2></a><hr></li></ol></div></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Increasing Retention Without Increasing Study Time [pdf] (169 pts)]]></title>
            <link>https://files.eric.ed.gov/fulltext/ED505647.pdf</link>
            <guid>41274602</guid>
            <pubDate>Sat, 17 Aug 2024 13:53:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://files.eric.ed.gov/fulltext/ED505647.pdf">https://files.eric.ed.gov/fulltext/ED505647.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=41274602">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: AI Analyzes What the Startup Would Be Interested in Buying. Sales Tool (271 pts)]]></title>
            <link>https://old.reddit.com/r/salestechniques/comments/1euftop/tool_which_tracks_all_vc_funded_startups_it/</link>
            <guid>41273803</guid>
            <pubDate>Sat, 17 Aug 2024 11:52:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/salestechniques/comments/1euftop/tool_which_tracks_all_vc_funded_startups_it/">https://old.reddit.com/r/salestechniques/comments/1euftop/tool_which_tracks_all_vc_funded_startups_it/</a>, See on <a href="https://news.ycombinator.com/item?id=41273803">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>This subreddit is for sharing techniques that can make us better at selling. This subreddit is not for motivational posts and only techniques backed by science or experience. </p>

<p>We appreciate any content on sales techniques, however occasionally some content requires a basic explanation, as such any links that are posted should be accompanied by a comment with a bit of written context explaining why you think it belongs here.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Xapian: Open source search engine library (127 pts)]]></title>
            <link>https://xapian.org/</link>
            <guid>41273415</guid>
            <pubDate>Sat, 17 Aug 2024 10:42:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xapian.org/">https://xapian.org/</a>, See on <a href="https://news.ycombinator.com/item?id=41273415">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="Content">

<p><img src="https://xapian.org/xapian-logo.png" alt="The Xapian Project"></p><p>Welcome to the Xapian project website.</p>

<p>Xapian is an Open Source Search Engine Library, released under the
<a href="https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html">GPL v2+</a>.
It's written in <a href="https://xapian.org/docs/apidoc/html/annotated.html">C++</a>,
with <a href="https://xapian.org/docs/bindings/">bindings</a> to allow use from
<a href="https://xapian.org/docs/bindings/perl/">Perl</a>
<a href="https://xapian.org/docs/bindings/python/">Python 2</a>,
<a href="https://xapian.org/docs/bindings/python3/">Python 3</a>,
<a href="https://xapian.org/docs/bindings/php/">PHP</a>,
<a href="https://xapian.org/docs/bindings/java/">Java</a>,
<a href="https://xapian.org/docs/bindings/tcl8/">Tcl</a>,
<a href="https://xapian.org/docs/bindings/csharp/">C#</a>,
<a href="https://xapian.org/docs/bindings/ruby/">Ruby</a>,
<a href="https://xapian.org/docs/bindings/lua/">Lua</a>,
<a href="https://github.com/arcusfelis/xapian-erlang-bindings#readme">Erlang</a>,
<a href="https://github.com/mtibeica/node-xapian#readme">Node.js</a>
and
<a href="https://github.com/amandaJayanetti/RXapian#readme">R</a>
(so far!)</p>

<p>Xapian is a highly adaptable toolkit which allows developers
to easily add advanced indexing and search facilities to their own
applications.  It has built-in support for several families of
weighting models and also supports a rich set of boolean query operators.</p>

<p>If you're after a packaged search engine for your website, you
should take a look at <a href="https://xapian.org/docs/omega/overview.html">Omega</a>:
an application we supply built upon
Xapian.  Unlike most other website search solutions, Xapian's
versatility allows you to extend Omega to meet your needs as they grow.</p>

<p>The <a href="https://lists.xapian.org/pipermail/xapian-discuss/2024-July/010052.html">latest stable version
is 1.4.26</a>, released on 2024-07-18.</p>
<p>The <a href="https://lists.xapian.org/pipermail/xapian-discuss/2017-September/009553.html">latest old stable version
is 1.2.25</a>, released on 2017-09-26.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Removed Organic Maps from the Playstore (462 pts)]]></title>
            <link>https://twitter.com/organicmapsapp/status/1824727403580596260</link>
            <guid>41272925</guid>
            <pubDate>Sat, 17 Aug 2024 09:01:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/organicmapsapp/status/1824727403580596260">https://twitter.com/organicmapsapp/status/1824727403580596260</a>, See on <a href="https://news.ycombinator.com/item?id=41272925">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[X to pay €550k to employee fired for not replying to yes-or-resign ultimatum (418 pts)]]></title>
            <link>https://fortune.com/europe/2024/08/14/x-ordered-to-pay-550000-to-irish-employee-fired-for-not-replying-to-elon-musk-yes-or-resign-extremely-hardcore-ultimatum/</link>
            <guid>41272861</guid>
            <pubDate>Sat, 17 Aug 2024 08:46:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fortune.com/europe/2024/08/14/x-ordered-to-pay-550000-to-irish-employee-fired-for-not-replying-to-elon-musk-yes-or-resign-extremely-hardcore-ultimatum/">https://fortune.com/europe/2024/08/14/x-ordered-to-pay-550000-to-irish-employee-fired-for-not-replying-to-elon-musk-yes-or-resign-extremely-hardcore-ultimatum/</a>, See on <a href="https://news.ycombinator.com/item?id=41272861">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-cy="article-content"><p>Elon Musk’s X has been ordered to pay compensation to a former staff member of its Irish unit in an unfair dismissal case.</p><div>



<p>The social network platform formerly known as Twitter was ordered to pay out over €550,000 ($602,640) to the former employee, Ireland’s Workplace Relations Commission, the state body responsible for adjudicating employment disputes, said on Tuesday. It is the largest sum the agency has ever awarded, according to Irish broadcaster RTE.&nbsp;</p>



<p>Gary Rooney, who held a senior procurement role at the time of his dismissal in December 2022, had been employed by the company since September 2013. The Commission heard that the social media platform maintained that the employee had resigned voluntarily after he failed to tick a box committing to new unspecified working arrangements in an email from the company’s new owner Musk. &nbsp;</p>



<p>Rooney was one of thousands of Twitter employees sent an email by Musk requiring them to pledge to stay with the company, working long hours at “high intensity” during its transformation, or to accept a buyout. Staff were given a day to click “yes” to agree to unspecified employment terms.</p>



<p>The commission rejected X’s argument that Rooney quit voluntarily and ruled that not clicking “yes” in response to the email did not constitute an act of resignation.</p>



<p>“It is not OK for Mr. Musk, or indeed any large company to treat employees in such a manner in this country or jurisdiction. The record award reflects the seriousness and the gravity of the case,” the complainant’s solicitor Barry Kenny told Bloomberg.</p>



<p>It’s one in a string of cases that have sprung up since Musk purchased the platform. Multiple lawsuits have already alleged that Twitter employees didn’t receive their promised severance benefits, while the site has come under more intense scrutiny since he acquired it.</p>



<p>The dispute arose in Dublin after billionaire Musk took ownership of the platform in late 2022. The Irish capital had about 500 employees before the takeover, but has since been impacted by the global staff exodus from the firm.</p>



<p>The WRC in its 73-page ruling stated the emails had been sent “at a time of rapid change in Twitter and in the context of inconsistent, contradictory and confusing communications from the Respondent in connection with the takeover of the Company by Mr. Musk.”</p>



<p>X didn’t immediately respond to a request for comment. The company can lodge an appeal to the Labour Court within 42 days.&nbsp;</p></div><p><strong>Recommended Newsletter:</strong> The Fortune Next to Lead newsletter is a must-read for the next generation of C-suite leaders. Every Monday, the newsletter provides the strategies, resources, and expert insight needed to claim the most coveted positions in business. <a href="https://fortune.com/newsletters/next-to-lead?&amp;itm_source=fortune&amp;itm_medium=article_tout&amp;itm_campaign=next_to_lead_v2&amp;itm_content=elon_amazon_google" target="_self" aria-label="Go to https://fortune.com/newsletters/next-to-lead?&amp;itm_source=fortune&amp;itm_medium=article_tout&amp;itm_campaign=next_to_lead_v2&amp;itm_content=elon_amazon_google">Subscribe now</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Just use Postgres (198 pts)]]></title>
            <link>https://mccue.dev/pages/8-16-24-just-use-postgres</link>
            <guid>41272854</guid>
            <pubDate>Sat, 17 Aug 2024 08:44:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mccue.dev/pages/8-16-24-just-use-postgres">https://mccue.dev/pages/8-16-24-just-use-postgres</a>, See on <a href="https://news.ycombinator.com/item?id=41272854">Hacker News</a></p>
<div id="readability-page-1" class="page">

<p> by:  <b> Ethan McCue</b></p>

<p>This is one part actionable advice, one part question for the audience.</p>
<p>Advice: When you are making a new application that requires persistent storage of data, like is the case for most web applications, your default choice should be <code>Postgres</code>.</p>
<h3 id="why-not-sqlite">Why not <code>sqlite</code>?</h3>
<p><code>sqlite</code> is a pretty good database, but its data is stored in a single file.</p>
<p>This implies that whatever your application is, it is running on one machine and one machine only. Or at least one shared filesystem.</p>
<p>If you are making a desktop or mobile app, that's perfect. If you are making a website it might not be.</p>
<p>There are many success stories of using <code>sqlite</code> for a website, but they mostly involve people who set up their own servers and infrastructure. Platforms as a service-s like Heroku, Railway, Render, etc. generally expect you to use a database accessed over network boundary. It's not <em>wrong</em> to give up some of the benefits of those platforms, but do consider if the benefits of <code>sqlite</code> are worth giving up platform provided automatic database backups and the ability to provision more than one application server.</p>
<p><a href="https://www.sqlite.org/whentouse.html">The official documentation</a> has a good guide with some more specifics.</p>
<h3 id="why-not-dynamodb-cassandra-or-mongodb">Why not <code>DynamoDB</code>, <code>Cassandra</code>, or <code>MongoDB</code>?</h3>
<p>Wherever Ray Houlihan is, I hope he is having a good day.</p>
<p>I watch a lot of conference talks, but his <a href="https://www.youtube.com/watch?v=HaEPXoXVf2k">2018 DynamoDB Deep Dive</a> might be the one I've watched the most. I know very few of you are going to watch an hour-long talk, but you really should. It's a good one.</p>
<p>The thrust of it is that databases that are in the same genre as <code>DynamoDB</code> - which includes <code>Cassandra</code> and <code>MongoDB</code> - are fantastic <strong>if</strong> - and this is a load bearing if:</p>
<ul>
<li>You know exactly what your app needs to do, up-front</li>
<li>You know exactly what your access patterns will be, up-front</li>
<li>You have a known need to scale to really large sizes of data</li>
<li>You are okay giving up some level of consistency</li>
</ul>
<p>This is because this sort of database is basically a giant distributed hash map. The only operations that work without needing to scan the entire database are lookups by partition key and scans that make use of a sort key.</p>
<p>Whatever queries you need to make, you need to encode that knowledge in one of those indexes before you store it. You want to store users and look them up by either first name or last name? Well you best have a sort key that looks like <code>&lt;FIRST NAME&gt;$&lt;LAST NAME&gt;</code>. Your access patterns should be baked into how you store your data. If your access patterns change significantly, you might need to reprocess all of your data.</p>
<p>It's annoying because, especially with <code>MongoDB</code>, people come into it having been sold on it being a more "flexible" database. Yes, you don't need to give it a schema. Yes, you can just dump untyped JSON into collections. No, this is not a flexible kind of database. It is an efficient one.</p>
<p>With a relational database you can go from getting all the pets of a person to getting all the owners of a pet by slapping an index or two on your tables. With this genre of NoSQL, that can be a tall order.</p>
<p>Its also not amazing if you need to run analytics queries. Arbitrary questions like "How many users signed up in the last month" can be trivially answered by writing a SQL query, perhaps on a read-replica if you are worried about running an expensive query on the same machine that is dealing with customer traffic. It's just outside the scope of this kind of database. You need to be ETL-ing your data out to handle it.</p>
<p>If you see a college student or fresh grad using <code>MongoDB</code> stop them. They need help. They have been led astray.</p>
<h3 id="why-not-valkey">Why not <code>Valkey</code>?</h3>
<p>The artist formerly known as <code>Redis</code> is best known for being an efficient out-of-process cache. You compute something expensive once and slap it in <code>Valkey</code> so all 5 or so HTTP servers you have don't need to recompute it.</p>
<p>However, you <em>can</em> use it as your primary database. It stores all its data in RAM, so it's pretty fast if you do that.</p>
<p>Obvious problems:</p>
<ul>
<li>You can only have so much RAM. You can have a lot more than you'd think, but its still pretty limited compared to hard drives.</li>
<li>Same as the <code>DynamoDB</code>-likes, you need to make concessions on how you model your data.</li>
</ul>
<h3 id="why-not-datomic">Why not <code>Datomic</code>?</h3>
<p>If you already knew about this one, you get a gold star.</p>
<p><code>Datomic</code> is a <code>NoSQL</code> database, but it is a relational one. The "up-front design" problems aren't there, and it does have some neat properties.</p>
<p>You don't store data in tables. It's all "entity-attribute-value-time" (EAVT) pairs. Instead of a person row with <code>id</code>, <code>name</code>, and <code>age</code> you store <code>1 :person/name "Beth"</code> and <code>1 :person/age 30</code>. Then your queries work off of "universal" indexes.</p>
<p>You don't need to coordinate with writers when making queries. You query the database "as-of" a given time. New data, even deletions (or as they call them "retractions"), don't actually delete old data.</p>
<p>But there are some significant problems</p>
<ul>
<li>It only works with JVM languages.</li>
<li>Outside of <code>Clojure</code>, a relatively niche language, its API sucks.</li>
<li>If you structure a query badly the error messages you get are terrible.</li>
<li>The whole universe of tools that exist for SQL just aren't there.</li>
</ul>
<h3 id="why-not-xtdb">Why not <code>XTDB</code>?</h3>
<p><code>Clojure</code> people make a lot of databases.</p>
<p><code>XTDB</code> is spiritually similar do <code>Datomic</code> but:</p>
<ul>
<li>There is an HTTP api, so you aren't locked to the JVM.</li>
<li>It has two axes of time you can query against. "System Time" - when records were inserted - and "Valid Time."</li>
<li>It has a SQL API.</li>
</ul>
<p>The biggest points against it are:</p>
<ul>
<li>It's new. Its SQL API is something that popped up in the last year. It recently changed its whole storage model. Will the company behind it survive the next 10 years? Who knows!</li>
</ul>
<p>Okay that's just one point. I'm sure I could think of more, but treat this as a stand-in for any recently developed database. The best predictor something will continue to exist into the future is how long it has existed. COBOL been around for decades, it will likely continue to exist for decades.</p>
<p>If you have persistent storage, you want as long a support term as you can get. You can certainly choose to pick a newer or experimental database for your app but, regardless of technical properties, that's a risky choice. It shouldn't be your default.</p>
<h3 id="why-not-kafka">Why not <code>Kafka</code>?</h3>
<p><code>Kafka</code> is an append only log. It can handle TBs of data. It is a very good append only log. It works amazingly well if you want to do event sourcing type stuff with data flowing in from multiple services maintained by multiple teams of humans.</p>
<p>But:</p>
<ul>
<li>Up to a certain scale, a table in Postgres works perfectly fine as an append only log.</li>
<li>You likely do not have hundreds of people working on your product nor TBs of events flowing in.</li>
<li>Making a Kafka consumer is a bit more error-prone than you'd expect. You need to keep track of your place in the log after all.</li>
<li>Even when maintained by a cloud provider (and there are good managed <code>Kafka</code> services) its another piece of infrastructure you need to monitor.</li>
</ul>
<h3 id="why-not-elasticsearch">Why not <code>ElasticSearch</code>?</h3>
<p>Is searching over data the primary function of your product?</p>
<p>If yes, <code>ElasticSearch</code> is going to give you some real pros. You will need to ETL your data into it and manage that whole process, but <code>ElasticSearch</code> is built for searching. It does searching good.</p>
<p>If no, <code>Postgres</code> will be fine. A sprinkling of <code>ilike</code> and the built-in <a href="https://www.postgresql.org/docs/current/textsearch.html">full text search</a> is more than enough for most applications. You can always bolt on a dedicated search thing later.</p>
<h3 id="why-not-mssql-or-oracle-db">Why not <code>MSSQL</code> or <code>Oracle DB</code>?</h3>
<p>Genuine question you should ask yourself: Are these worth the price tag?</p>
<p>I don't just mean the straight-up cost to license, but also the cost of lock-in. Once your data is in <code>Oracle DB</code> you are going to be paying Oracle forever. You are going to have to train your coders on its idiosyncrasies, forever. You are going to have to decide between enterprise features and your wallet, forever.</p>
<p>I know its super unlikely that you will contribute a patch to <code>Postgres</code>, so I won't pretend that there is some magic "power of open source" going on, but I think you should have a very specific need in mind to choose a proprietary DB. If you don't have some killer <code>MSSQL</code> feature that you simply cannot live without, don't use it.</p>
<h3 id="why-not-mysql">Why not <code>MySQL</code>?</h3>
<p>This is the one that I need some audience help with.</p>
<p><code>MySQL</code> is owned by Oracle. There are <a href="https://www.mysql.com/products/enterprise/compare/">features locked behind their enterprise editions</a>. To an extent you will have lock-in issues the same as any other DB.</p>
<p>But the free edition <code>MySQL</code> has also been used in an extremely wide range of things. It's been around for a long time. There are people who know how to work with it.</p>
<p>My problem is that I've only spent ~6 months of my professional career working with it. I genuinely don't know enough to compare it intelligently to <code>Postgres</code>.</p>
<p>I'm convinced it isn't secretly so much better that I am doing folks a disservice when telling them to use <code>Postgres</code>, and I do remember reading about how <code>Postgres</code> generally has better support for enforcing invariants in the DB itself, but I wouldn't mind being schooled a bit here.</p>
<h3 id="why-not-some-ai-vector-db">Why not some AI vector DB?</h3>
<ul>
<li>Most are new. Remember the risks of using something new.</li>
<li>AI is a bubble. A load-bearing bubble, but a bubble. Don't build a house on it if you can avoid it.</li>
<li>Even if your business is another AI grift, you probably only need to <code>import openai</code>.</li>
</ul>
<h3 id="why-not-google-sheets">Why not Google Sheets?</h3>
<p>You're right. I can't think of any downsides. Go for it.</p>
<hr>
<h4 id="--index"><a href="https://mccue.dev/">&lt;- Index</a></h4>
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Epic Games Store and Fortnite Arrive on EU iPhones (165 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2024/08/epic-games-store-and-fortnite-arrive-on-eu-iphones/</link>
            <guid>41272771</guid>
            <pubDate>Sat, 17 Aug 2024 08:19:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2024/08/epic-games-store-and-fortnite-arrive-on-eu-iphones/">https://arstechnica.com/gadgets/2024/08/epic-games-store-and-fortnite-arrive-on-eu-iphones/</a>, See on <a href="https://news.ycombinator.com/item?id=41272771">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      It's still a mess    —
</h4>
            
            <h2 itemprop="description">Epic also launched its store on Android.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2020/09/fortnite-800x360.png" alt="Artist's conception of Epic dodging harm from Apple's decisions (and perhaps its own).">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2020/09/fortnite.png" data-height="360" data-width="800">Enlarge</a> <span>/</span> Artist's conception of Epic dodging harm from Apple's decisions (and perhaps its own).</p></figcaption>  </figure>

  




<!-- cache hit 194:single/related:2a9d9879426a4f82b1d2207016ef5bdd --><!-- empty -->
<p>It's been four years since <em>Fortnite</em>, one of the world's most popular games, was pulled from the Apple App Store in a blaze of controversy and finger-pointing. Today, it's returning to the iPhone—but only in the European Union.</p>
<p>Today marks the launch of the Epic Games Store on Android and iOS—iOS just in Europe, Android worldwide. Right now, it just has three games: <em>Fortnite</em>, <em>Rocket League Sideswipe</em>, and <em>Fall Guys</em>. And you'll have to be in Europe to access it on your iPhone.</p>
<p>The Epic Games Store is run by Epic Games, the same company that develops and publishes <em>Fortnite</em>. Most folks who have been paying attention to either Epic or Apple in recent years knows the story at this point, but here's the quick summary and analysis.</p>
<h2>Opinion: Users are still the losers after four years</h2>
<p>At the direction of CEO Tim Sweeney, Epic knowingly made changes to <em>Fortnite</em> related to digital payments that violated Apple's terms for developers on the platform. Apple removed <em>Fortnite</em> accordingly, and a long, ugly PR and legal battle ensued between the two companies in multiple countries and regions.</p>
<p>In the US, a judge's decision granted some small wins to Epic and other developers seeking to loosen Apple's grip on the platform, but it kept the status quo for the most part.</p>                                                                        
                                                                                
<p>Things went a little differently in Europe. EU legislators and regulators enacted the Digital Markets Act (DMA), which had far-reaching implications for how Apple and Google run their app stores. Among other things, the new law required Apple to allow third-party, alternative app stores (basically, sideloading) on the iPhone.</p>
<p>Apple's compliance was far from enthusiastic (the company cited security and privacy concerns for users, which is valid, but the elephant in the room is, of course, its confident grip on app revenues on its platforms), and it was criticized for trying to put up barriers. Additionally, Apple rejected Epic's attempts to launch its app store multiple times for a few arcane reasons amid a flurry of almost comically over-the-top tweets from Sweeney criticizing the company.</p>
<p>Despite Apple's foot-dragging, Epic has finally reached the point where it could launch its app store. Epic had already launched a relatively successful App Store on PC, where Valve's Steam holds a strong grip on users. The new iPhone app store doesn't offer nearly as many options or perks as the PC version, but Epic says it's working on wrangling developers onto its store.</p>
<p>It also says it will release its games on other alternative app stores on iOS and Android, such as AltStore PAL.</p>
<p>It's been a long, winding, angry path to get to this point. In the battle between Epic and Apple, there remains some debate about who really has won up to this point. But there isn't much dispute that, whether you want to blame Apple or Epic or both, users sure haven't been the winners.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Slackdump (112 pts)]]></title>
            <link>https://github.com/rusq/slackdump</link>
            <guid>41272213</guid>
            <pubDate>Sat, 17 Aug 2024 04:42:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/rusq/slackdump">https://github.com/rusq/slackdump</a>, See on <a href="https://news.ycombinator.com/item?id=41272213">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Slack Dumper</h2><a id="user-content-slack-dumper" aria-label="Permalink: Slack Dumper" href="#slack-dumper"></a></p>
<p dir="auto">Purpose:  archive your private and public Slack messages, users, channels,
files and emojis.  Generate Slack Export without admin privileges.</p>
<p dir="auto"><a href="https://github.com/rusq/slackdump/releases/"><img alt="screenshot" src="https://github.com/rusq/slackdump/raw/master/doc/slackdump.webp"></a></p>
<p dir="auto"><strong>Quick links</strong>:</p>
<ul dir="auto">
<li>Join the discussion in <a href="https://t.me/slackdump" rel="nofollow">Telegram</a>.</li>
<li><a href="https://ko-fi.com/rusq_" rel="nofollow">Buy me a cup of tea</a>, or use <strong>Github Sponsors</strong> button on the top of the
page.</li>
<li>Reference documentation: <a href="https://pkg.go.dev/github.com/rusq/slackdump/v2/" rel="nofollow"><img alt="go ref" src="https://camo.githubusercontent.com/61b76a174ed45215bd583a526f923674f061cdce25300ed1a5ecf4b3c239e106/68747470733a2f2f706b672e676f2e6465762f62616467652f6769746875622e636f6d2f727573712f736c61636b64756d702f76322e7376673a616c743a476f5265666572656e6365" data-canonical-src="https://pkg.go.dev/badge/github.com/rusq/slackdump/v2.svg:alt:GoReference"></a></li>
<li>How to's:<ul dir="auto">
<li><a href="https://github.com/rusq/slackdump/blob/master/doc/usage-export.rst">Mattermost migration</a> steps</li>
<li><a href="https://kenkyu-note.hatenablog.com/entry/2022/09/02/090949" rel="nofollow">SlackLogViewerとSlackdumpを一緒に使用する</a></li>
<li><a href="https://vivianamarquez.medium.com/a-step-by-step-guide-to-downloading-slack-messages-without-admin-rights-954f20397e83" rel="nofollow">Step by Step guide by Viviana Marquez</a> (requires Medium subscription)</li>
<li><a href="https://medium.com/@gilyazov/downloading-your-private-slack-conversations-52e50428b3c2" rel="nofollow">Overview on Medium.com</a>  (outdated)</li>
</ul>
</li>
</ul>
<div id="user-content-contents" dir="auto">
<p dir="auto">Contents</p>
<ul dir="auto">
<li><a href="#description" id="user-content-id3">Description</a></li>
<li><a href="#quick-start" id="user-content-id4">Quick Start</a></li>
<li><a href="#slackord2-migrating-to-discord" id="user-content-id5">Slackord2: Migrating to Discord</a></li>
<li><a href="#user-guide" id="user-content-id6">User Guide</a></li>
<li><a href="#previewing-results" id="user-content-id7">Previewing Results</a></li>
<li><a href="#using-as-a-library" id="user-content-id8">Using as a library</a><ul dir="auto">
<li><a href="#example" id="user-content-id9">Example</a></li>
<li><a href="#using-custom-logger" id="user-content-id10">Using Custom Logger</a></li>
</ul>
</li>
<li><a href="#faq" id="user-content-id11">FAQ</a></li>
<li><a href="#thank-you" id="user-content-id12">Thank you</a><ul dir="auto">
<li><a href="#bulletin-board" id="user-content-id13">Bulletin Board</a></li>
</ul>
</li>
</ul>
</div>
<a name="user-content-description"></a>
<p dir="auto"><h2 tabindex="-1" dir="auto"><a href="#id3">Description</a></h2><a id="user-content-description" aria-label="Permalink: Description" href="#description"></a></p>
<p dir="auto">Typical use scenarios:</p>
<ul dir="auto">
<li>archive your private conversations from Slack when the administrator
does not allow you to install applications OR you don't want to use
potentially privacy-violating third-party tools,</li>
<li>archive channels from Slack when you're on a free "no archive" subscription,
so you don't lose valuable knowledge in those channels,</li>
<li>create a Slack Export archive without admin access, or</li>
<li>save your favourite emojis.</li>
</ul>
<p dir="auto">There are four modes of operation (more on this in <a href="https://github.com/rusq/slackdump/blob/master/doc/README.rst">User Guide</a>) :</p>
<ol dir="auto">
<li>List users/channels</li>
<li>Dumping messages and threads</li>
<li>Creating a Slack Export in Mattermost or Standard modes.</li>
<li>Emoji download mode.</li>
</ol>
<p dir="auto">Slackdump accepts two types of input (see <a href="https://github.com/rusq/slackdump/blob/master/doc/usage-channels.rst">Dumping Conversations</a> section):</p>
<ol dir="auto">
<li>the URL/link of the channel or thread, OR</li>
<li>the ID of the channel.</li>
</ol>
<a name="user-content-quick-start"></a>
<p dir="auto"><h2 tabindex="-1" dir="auto"><a href="#id4">Quick Start</a></h2><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<ol dir="auto">
<li>Download the latest release for your operating system from the <a href="https://github.com/rusq/slackdump/releases/">releases</a>
page. (If you're using <strong>macOS</strong>, download <strong>Darwin</strong> executable).</li>
<li>Unpack the archive to any directory.</li>
<li>Run the <code>./slackdump</code> or <code>slackdump.exe</code> executable (see note below).</li>
<li>You know the drill:  use arrow keys to select the menu item, and Enter (or
Return) to confirm.</li>
</ol>
<p dir="auto">By default, Slackdump uses the EZ-Login 3000 automatic login, and interactive
mode.</p>
<div dir="auto">
<p dir="auto">Note</p>
<p dir="auto">On Windows and macOS you may be presented with "Unknown developer" window,
this is fine.  Reason for this is that the executable hasn't been signed by
the developer certificate.</p>
<p dir="auto">To work around this:</p>
<ul dir="auto">
<li><strong>on Windows</strong>: click "more information", and press "Run
Anyway" button.</li>
<li><strong>on macOS</strong>: open the folder in Finder, hold Option and double click the
executable, choose Run.</li>
</ul>
</div>
<a name="user-content-slackord2-migrating-to-discord"></a>
<p dir="auto"><h2 tabindex="-1" dir="auto"><a href="#id5">Slackord2: Migrating to Discord</a></h2><a id="user-content-slackord2-migrating-to-discord" aria-label="Permalink: Slackord2: Migrating to Discord" href="#slackord2-migrating-to-discord"></a></p>
<p dir="auto">If you're migrating to Discord, the recommended way is to use <a href="https://github.com/thomasloupe/Slackord2">Slackord2</a> - a
great tool with a nice GUI, that is compatible with the export files generated
by Slackdump.</p>
<a name="user-content-user-guide"></a>
<p dir="auto"><h2 tabindex="-1" dir="auto"><a href="#id6">User Guide</a></h2><a id="user-content-user-guide" aria-label="Permalink: User Guide" href="#user-guide"></a></p>
<p dir="auto">For more advanced features and instructions, please see the <a href="https://github.com/rusq/slackdump/blob/master/doc/README.rst">User Guide</a>.</p>
<a name="user-content-previewing-results"></a>
<p dir="auto"><h2 tabindex="-1" dir="auto"><a href="#id7">Previewing Results</a></h2><a id="user-content-previewing-results" aria-label="Permalink: Previewing Results" href="#previewing-results"></a></p>
<p dir="auto">Once the data is dumped, you can use one of the following tools to preview the
results:</p>
<ul dir="auto">
<li><a href="https://github.com/thayakawa-gh/SlackLogViewer/releases">SlackLogViewer</a> - a fast and powerful Slack Export viewer written in C++.</li>
<li><a href="https://github.com/kununu/slackdump2html">Slackdump2Html</a> - a great Python application that converts Slack Dump to a
static browsable HTML, works on Dump mode files.</li>
<li><a href="https://github.com/hfaran/slack-export-viewer">slack export viewer</a> - Slack Export Viewer is a well known viewer for
slack export files.</li>
</ul>
<a name="user-content-using-as-a-library"></a>
<p dir="auto"><h2 tabindex="-1" dir="auto"><a href="#id8">Using as a library</a></h2><a id="user-content-using-as-a-library" aria-label="Permalink: Using as a library" href="#using-as-a-library"></a></p>
<p dir="auto">Download:</p>
<div dir="auto" data-snippet-clipboard-copy-content="go get github.com/rusq/slackdump/v2"><pre><span>go</span> <span>get</span> <span>github</span>.<span>com</span><span>/</span><span>rusq</span><span>/</span><span>slackdump</span><span>/</span><span>v2</span></pre></div>
<a name="user-content-example"></a>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="#id9">Example</a></h3><a id="user-content-example" aria-label="Permalink: Example" href="#example"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
  &quot;context&quot;
  &quot;log&quot;

  &quot;github.com/rusq/slackdump/v2&quot;
  &quot;github.com/rusq/slackdump/v2/auth&quot;
)

func main() {
  provider, err := auth.NewValueAuth(&quot;xoxc-...&quot;, &quot;xoxd-...&quot;)
  if err != nil {
      log.Print(err)
      return
  }
  sd, err := slackdump.New(context.Background(), provider)
  if err != nil {
      log.Print(err)
      return
  }
  _ = sd
}"><pre><span>package</span> main

<span>import</span> (
  <span>"context"</span>
  <span>"log"</span>

  <span>"github.com/rusq/slackdump/v2"</span>
  <span>"github.com/rusq/slackdump/v2/auth"</span>
)

<span>func</span> <span>main</span>() {
  <span>provider</span>, <span>err</span> <span>:=</span> <span>auth</span>.<span>NewValueAuth</span>(<span>"xoxc-..."</span>, <span>"xoxd-..."</span>)
  <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
      <span>log</span>.<span>Print</span>(<span>err</span>)
      <span>return</span>
  }
  <span>sd</span>, <span>err</span> <span>:=</span> <span>slackdump</span>.<span>New</span>(<span>context</span>.<span>Background</span>(), <span>provider</span>)
  <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
      <span>log</span>.<span>Print</span>(<span>err</span>)
      <span>return</span>
  }
  <span>_</span> <span>=</span> <span>sd</span>
}</pre></div>
<p dir="auto">See <a href="https://pkg.go.dev/github.com/rusq/slackdump/v2/" rel="nofollow"><img alt="go ref" src="https://camo.githubusercontent.com/61b76a174ed45215bd583a526f923674f061cdce25300ed1a5ecf4b3c239e106/68747470733a2f2f706b672e676f2e6465762f62616467652f6769746875622e636f6d2f727573712f736c61636b64756d702f76322e7376673a616c743a476f5265666572656e6365" data-canonical-src="https://pkg.go.dev/badge/github.com/rusq/slackdump/v2.svg:alt:GoReference"></a></p>
<a name="user-content-using-custom-logger"></a>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="#id10">Using Custom Logger</a></h3><a id="user-content-using-custom-logger" aria-label="Permalink: Using Custom Logger" href="#using-custom-logger"></a></p>
<p dir="auto">Slackdump uses a simple <a href="https://github.com/rusq/dlog">rusq/dlog</a> as a default logger (it is a wrapper around
the standard logger that adds Debug* functions).</p>
<p dir="auto">If you want to use the same default logger that Slackdump uses in your
application, it is available as <code>logger.Default</code>.</p>
<p dir="auto">No doubts that everyone has their own favourite logger that is better than other
miserable loggers.  Please read below for instructions on plugging your
favourite logger.</p>
<a name="user-content-logrus"></a>
<p dir="auto"><h4 tabindex="-1" dir="auto">Logrus</h4><a id="user-content-logrus" aria-label="Permalink: Logrus" href="#logrus"></a></p>
<p dir="auto">Good news is <a href="https://github.com/sirupsen/logrus">logrus</a> can be plugged in straight away, as it implements the
<code>logger.Interface</code> out of the box.</p>
<div dir="auto" data-snippet-clipboard-copy-content="lg := logrus.New()
sd, err := slackdump.New(context.Background(), provider, WithLogger(lg))
  if err != nil {
      log.Print(err)
      return
  }
}"><pre><span>lg</span> <span>:=</span> <span>logrus</span>.<span>New</span>()
<span>sd</span>, <span>err</span> <span>:=</span> <span>slackdump</span>.<span>New</span>(<span>context</span>.<span>Background</span>(), <span>provider</span>, <span>WithLogger</span>(<span>lg</span>))
  <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
      <span>log</span>.<span>Print</span>(<span>err</span>)
      <span>return</span>
  }
}</pre></div>
<a name="user-content-glog-and-others"></a>
<p dir="auto"><h4 tabindex="-1" dir="auto">Glog and others</h4><a id="user-content-glog-and-others" aria-label="Permalink: Glog and others" href="#glog-and-others"></a></p>
<p dir="auto">If you need to use some other logger, such as <a href="https://github.com/golang/glog">glog</a>, it is a matter of wrapping
the calls to satisfy the <code>logger.Interface</code> (defined in the <a href="https://github.com/rusq/slackdump/blob/master/logger/logger.go">logger</a>
package), and then setting the <code>Logger</code> variable in slackdump.Options (see
<a href="https://github.com/rusq/slackdump/blob/master/options.go">options.go</a>), or using WithLogger option.</p>
<a name="user-content-faq"></a>
<p dir="auto"><h2 tabindex="-1" dir="auto"><a href="#id11">FAQ</a></h2><a id="user-content-faq" aria-label="Permalink: FAQ" href="#faq"></a></p>
<markdown-accessiblity-table><table>


<tbody>
<tr><th>Q:</th><td><strong>Do I need to create a Slack application?</strong></td>
</tr>
<tr><th>A:</th><td>No, you don't.  Just run the application and EZ-Login 3000 will take
care of the authentication or, alternatively, grab that token and
cookie from the browser Slack session.  See <a href="https://github.com/rusq/slackdump/blob/master/doc/README.rst">User Guide</a>.</td>
</tr>
<tr><th>Q:</th><td><strong>I'm getting "invalid_auth" error</strong></td>
</tr>
<tr><th>A:</th><td>Go get the new Cookie from the browser and Token as well.</td>
</tr>
<tr><th>Q:</th><td><strong>Slackdump takes a very long time to cache users</strong></td>
</tr>
<tr><th>A:</th><td>Disable the user cache with <code>-no-user-cache</code> flag.</td>
</tr>
<tr><th>Q:</th><td><strong>How to read the export file?</strong></td>
</tr>
<tr><th>A:</th><td>For Slack Workspace Export, use <a href="https://github.com/thayakawa-gh/SlackLogViewer/releases">SlackLogViewer</a> which is extremely fast
with an advanced search function, or <a href="https://github.com/hfaran/slack-export-viewer">slack export viewer</a> which is a
Python application and runs in a browser.  For the generic dump files, see
<a href="https://github.com/rusq/slackdump/blob/master/examples">examples</a> directory for some python and shell examples.</td>
</tr>
<tr><th>Q:</th><td><strong>My Slack Workspace is on the Free plan.  Can I get data older than
90-days?</strong></td>
</tr>
<tr><th>A:</th><td>No, unfortunately you can't.  Slack doesn't allow to export data older
than 90 days for free workspaces, the API does not return any data before 90
days for workspaces on the Free plan.</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<a name="user-content-thank-you"></a>
<p dir="auto"><h2 tabindex="-1" dir="auto"><a href="#id12">Thank you</a></h2><a id="user-content-thank-you" aria-label="Permalink: Thank you" href="#thank-you"></a></p>
<p dir="auto">Big thanks to all contributors, who submitted a pull request, reported a bug,
suggested a feature, helped to reproduce, or spent time chatting with me on
the Telegram or Slack to help to understand the issue and tested the proposed
solution.</p>
<p dir="auto">Also, I'd like to thank all those who made a donation to support the project:</p>
<ul dir="auto">
<li>Vivek R.</li>
<li>Fabian I.</li>
<li>Ori P.</li>
<li>Shir B. L.</li>
<li>Emin G.</li>
<li>Robert Z.</li>
<li>Sudhanshu J.</li>
</ul>
<a name="user-content-bulletin-board"></a>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="#id13">Bulletin Board</a></h3><a id="user-content-bulletin-board" aria-label="Permalink: Bulletin Board" href="#bulletin-board"></a></p>
<p dir="auto">Messages that were conveyed with the donations:</p>
<ul dir="auto">
<li>25/01/2022: Stay away from <a href="https://www.glassdoor.com.au/Reviews/TheSignChef-com-Reviews-E793259.htm" rel="nofollow">TheSignChef.com</a>, ya hear, they don't pay what
they owe to their employees.</li>
</ul>

</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zngur: A C++/Rust interop tool (137 pts)]]></title>
            <link>https://hkalbasi.github.io/zngur/</link>
            <guid>41271273</guid>
            <pubDate>Fri, 16 Aug 2024 23:27:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hkalbasi.github.io/zngur/">https://hkalbasi.github.io/zngur/</a>, See on <a href="https://news.ycombinator.com/item?id=41271273">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        

        <!-- Set the theme before any content is loaded, prevents flash -->
        

        <!-- Hide / unhide sidebar before it is displayed -->
        

        <nav id="sidebar" aria-label="Table of contents">
            
            
        </nav>

        <!-- Track and set sidebar scroll position -->
        

        <div id="page-wrapper">

            <div class="page">
                                
                <div id="menu-bar">
                    

                    <h2>Zngur</h2>

                    
                </div>

                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                

                <div id="content">
                    <main>
                        <h2 id="zngur"><a href="#zngur">Zngur</a></h2>
<p>Zngur (/zængɑr/) is a C++/Rust interop tool. It tries to expose arbitrary Rust types, methods, and functions while preserving its
semantics and ergonomics as much as possible. Using Zngur, you can use arbitrary Rust crate in your C++ code as easily as using it in
normal Rust code, and you can write idiomatic Rusty API for your C++ library inside C++.</p>
<h2 id="idea"><a href="#idea">Idea</a></h2>
<p>Rust and C++ are similar languages but with some important differences. Particularly:</p>
<ul>
<li>Rust is a memory-safe language with a strong boundary between <code>safe</code> and <code>unsafe</code> declared using the <code>unsafe</code> keyword, C++
is an unsafe language with no such difference and keyword.</li>
<li>C++ has macro-like templates, which support variadic, specialization and are checked
at instantiation time. Rust generics, on the other hand, are type-checked at definition
time using trait bounds.</li>
<li>Rust move is a <code>memcpy</code> with compiler support for not destructing the moved out of variable, but C++
move can execute arbitrary code.</li>
</ul>
<p>In all of these differences, C++ has more freedom relative to the Rust:</p>
<ul>
<li>Rust considers C++ functions as unsafe, but C++ will happily call Rust code (even unsafe) as there
is no difference between it and normal C++ code.</li>
<li>Every rust generic code is a valid C++ template, but not vice versa.</li>
<li>C++ can simulate Rust moves very easily (by doing an actual <code>memcpy</code> of data, and tracking the state of destruction in
a boolean flag) but Rust has difficulty with C++ moves. Specially, since Rust assumes that every type is
Rust-moveable, it can never store C++ objects by value, just over some indirection and <code>Pin</code>.</li>
</ul>
<p>So, Zngur allows you to use arbitrary Rust types in C++, store them by value in the C++ stack, and call arbitrary Rust methods and functions
on them. But it doesn't bridge any C++ type into Rust, since it is not possible with the same ergonomic. Instead, Zngur allows you to
write a rusty wrapper for your C++ library. It allows you to implement Rust traits for C++ types and cast them to
the <code>Box&lt;dyn Trait&gt;</code>, implement inherent methods on Rust types, implement Rust traits for Rust types, and expose bare functions
from C++ that operate on Rust types.</p>
<h2 id="demo"><a href="#demo">Demo</a></h2>
<pre><code>#include &lt;iostream&gt;
#include &lt;vector&gt;

#include "./generated.h"

// Rust values are available in the `::rust` namespace from their absolute path
// in Rust
template &lt;typename T&gt; using Vec = rust::std::vec::Vec&lt;T&gt;;
template &lt;typename T&gt; using Option = rust::std::option::Option&lt;T&gt;;
template &lt;typename T&gt; using BoxDyn = rust::Box&lt;rust::Dyn&lt;T&gt;&gt;;

// You can implement Rust traits for your classes
template &lt;typename T&gt;
class VectorIterator : public rust::std::iter::Iterator&lt;T&gt; {
  std::vector&lt;T&gt; vec;
  size_t pos;

public:
  VectorIterator(std::vector&lt;T&gt; &amp;&amp;v) : vec(v), pos(0) {}
  ~VectorIterator() {
    std::cout &lt;&lt; "vector iterator has been destructed" &lt;&lt; std::endl;
  }

  Option&lt;T&gt; next() override {
    if (pos &gt;= vec.size()) {
      return Option&lt;T&gt;::None();
    }
    T value = vec[pos++];
    // You can construct Rust enum with fields in C++
    return Option&lt;T&gt;::Some(value);
  }
};

int main() {
  // You can call Rust functions that return things by value, and store that
  // value in your stack.
  auto s = Vec&lt;int32_t&gt;::new_();
  s.push(2);
  Vec&lt;int32_t&gt;::push(s, 5);
  s.push(7);
  Vec&lt;int32_t&gt;::push(s, 3);
  // You can call Rust functions just like normal Rust.
  std::cout &lt;&lt; s.clone().into_iter().sum() &lt;&lt; std::endl;
  // You can catch Rust panics as C++ exceptions
  try {
    std::cout &lt;&lt; "s[2] = " &lt;&lt; *s.get(2).unwrap() &lt;&lt; std::endl;
    std::cout &lt;&lt; "s[4] = " &lt;&lt; *s.get(4).unwrap() &lt;&lt; std::endl;
  } catch (rust::Panic e) {
    std::cout &lt;&lt; "Rust panic happened" &lt;&lt; std::endl;
  }
  int state = 0;
  // You can convert a C++ lambda into a `Box&lt;dyn Fn&gt;` and friends.
  auto f = BoxDyn&lt;rust::Fn&lt;int32_t, int32_t&gt;&gt;::make_box([&amp;](int32_t x) {
    state += x;
    std::cout &lt;&lt; "hello " &lt;&lt; x &lt;&lt; " " &lt;&lt; state &lt;&lt; "\n";
    return x * 2;
  });
  // And pass it to Rust functions that accept closures.
  auto x = s.into_iter().map(std::move(f)).sum();
  std::cout &lt;&lt; x &lt;&lt; " " &lt;&lt; state &lt;&lt; "\n";
  std::vector&lt;int32_t&gt; vec{10, 20, 60};
  // You can convert a C++ type that implements `Trait` to a `Box&lt;dyn Trait&gt;`.
  // `make_box` is similar to the `make_unique`, it takes constructor arguments
  // and construct it inside the `Box` (instead of `unique_ptr`).
  auto vec_as_iter = BoxDyn&lt;rust::std::iter::Iterator&lt;int32_t&gt;&gt;::make_box&lt;
      VectorIterator&lt;int32_t&gt;&gt;(std::move(vec));
  // Then use it like a normal Rust value.
  auto t = vec_as_iter.collect();
  // Some utilities are also provided. For example, `zngur_dbg` is the
  // equivalent of `dbg!` macro.
  zngur_dbg(t);
}
</code></pre>
<p>Output:</p>
<pre><code>17
s[2] = 7
thread '&lt;unnamed&gt;' panicked at 'called `Option::unwrap()` on a `None` value', examples/simple/src/generated.rs:186:39
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace
s[4] = Rust panic happened
hello 2 2
hello 5 7
hello 7 14
hello 3 17
34 17
vector iterator has been destructed
[main.cpp:71] t = [
    10,
    20,
    60,
]
</code></pre>
<p>See the <a href="https://github.com/HKalbasi/zngur/blob/main/examples/simple"><code>examples/simple</code></a> if you want to build and run it.</p>

                    </main>

                    <nav aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->

                            <a rel="next" href="https://hkalbasi.github.io/zngur/tutorial.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i></i>
                            </a>

                        
                    </nav>
                </div>
            </div>

            <nav aria-label="Page navigation">

                    <a rel="next" href="https://hkalbasi.github.io/zngur/tutorial.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i></i>
                    </a>
            </nav>

        </div>






        
        
        

        
        
        

        <!-- Custom JS scripts -->


    </div>
    

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Learn Blender shortcuts with lots of tiny videos (118 pts)]]></title>
            <link>https://hollisbrown.github.io/blendershortcuts/</link>
            <guid>41271014</guid>
            <pubDate>Fri, 16 Aug 2024 22:38:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hollisbrown.github.io/blendershortcuts/">https://hollisbrown.github.io/blendershortcuts/</a>, See on <a href="https://news.ycombinator.com/item?id=41271014">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <div id="ChangeView">
            <a href="#ChangeView">
                <h3>Change View</h3>
                <h3><em>Middle Mouse</em></h3>

                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/MouseView.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p>Drag <em>Middle Mouse</em> or <em>Mouse Wheel</em> to
                            <em>rotate</em> the view. It rotates around an invisible <em>point of interest</em>.
                        </p>
                    </li>
                    <li>
                        <p>Hold <em>Shift</em> and drag to <em>move</em> the point of
                            interest.</p>
                    </li>
                    <li>
                        <p>Hold <em>Ctrl</em> and drag or roll the <em>Mouse
                                Wheel</em> to <em>zoom</em> in and out</p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="AxisView">
            <a href="#AxisView">
                <h3>Axis View</h3>
                <h3><em>Numpad 1 – 9</em></h3>

                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/SnapView.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>Num 1</em>, <em>Num 3</em> &amp; <em>Num
                                7</em>
                            for <em>front view</em>,<em>side view</em> &amp; <em>top view</em>.</p>
                    </li>
                    <li>
                        <p><em>Num 9</em> to <em>invert</em> the current view
                            direction.</p>
                    </li>
                    <li>
                        <p><em>Num 5</em> to toggle <em>orthographic</em> view.
                        </p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="CameraView">
            <a href="#CameraView">
                <h3>Camera View</h3>
                <h3><em>Numpad 0</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/CameraView.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>Numpad 0</em> to align the view with the scene camera.</p>
                    </li>
                    <li>
                        <p><em>Ctrl</em> + <em>Numpad 0</em> to align the view with
                            the selected camera and make it the scene camera.</p>
                    </li>
                    <li>
                        <p><em>Ctrl</em> + <em>Alt</em> + <em>Numpad
                                0</em> to align the scene camera with the current view.</p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="FrameSelected">
            <a href="#FrameSelected">
                <h3>Frame Selected</h3>
                <h3><em>Numpad .</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/FrameSelected.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p> <em>Numpad .</em> to set the point of interest to the current
                            selection.</p>
                    </li>
                    <li>
                        <p>With multiple selected, it will set to the <em>average</em> position of all
                            selected.
                        </p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="ChangeMode">
            <a href="#ChangeMode">
                <h3>Change Mode</h3>
                <h3><em>Ctrl</em> + <em>Tab</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/ChangeMode.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>Ctrl</em> + <em>Tab</em> to see all available
                            modes.
                        </p>
                    </li>
                    <li>
                        <p><em>Tab</em> to toggle Edit mode directly.</p>
                    </li>
                    <li>
                        <p>If the cursor is hovering a timeline, <em>Ctrl</em> + <em>Tab</em> to toggle graph view.</p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="Move">
            <a href="#Move">
                <h3>Move</h3>
                <h3><em>G</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/Move.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p> Press <em>X</em>, <em>Y</em> or <em>Z</em> to lock to
                            an axis. Press twice to switch from global to local axes.</p>
                    </li>
                    <li>
                        <p>
                            <em>Shift</em> + <em>X</em>, <em>Y</em> or <em>Z</em> to exclude an axis.
                        </p>
                    </li>
                    <li>
                        <p> In <em>Modeling</em>, press <em>G</em> twice to slide
                            along existing edges. </p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="Rotate">
            <a href="#Rotate">
                <h3>Rotate</h3>
                <h3><em>R</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/Rotate.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p> Press <em>X</em>, <em>Y</em> or <em>Z</em> to lock to
                            an axis. Press twice to switch from global to local axes.</p>
                    </li>
                    <li>
                        <p>
                            <em>Shift</em> + <em>X</em>, <em>Y</em> or <em>Z</em> to exclude an axis.
                        </p>
                    </li>
                    <li>
                        <p>Press <em>R</em> twice to switch to gimbal mode.</p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="Scale">
            <a href="#Scale">
                <h3>Scale</h3>
                <h3><em>S</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/Scale.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p> Press <em>X</em>, <em>Y</em> or <em>Z</em> to lock to
                            an axis. Press twice to switch from global to local axes.</p>
                    </li>
                    <li>
                        <p>
                            <em>Shift</em> + <em>X</em>, <em>Y</em> or <em>Z</em> to exclude an axis.
                        </p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="Delete">
            <a href="#Delete">
                <h3>Delete</h3>
                <h3><em>X</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/Delete.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p>Press <em>X</em> in <em>Object Mode</em> to delete
                            selected objects.</p>
                    </li>
                    <li>
                        <p>Press <em>X</em> in <em>Modeling</em> to delete selected
                            vertices, edges or faces.</p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="Hide">
            <a href="#Hide">
                <h3>Hide</h3>
                <h3><em>H</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/Hide.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>H</em> to hide the selection.</p>
                    </li>
                    <li>
                        <p><em>Shift</em> + <em>H</em> to hide everything but the
                            selection.</p>
                    </li>
                    <li>
                        <p><em>Alt</em> + <em>H</em> to unhide all.</p>
                    </li>
                    <li>
                        <p>Meshes that are hidden in <em>Modeling</em> are visible in <em>Object Mode</em>.</p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="Add">
            <a href="#Add">
                <h3>Add</h3>
                <h3><em>Shift</em> + <em>A</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/Add.mp4" type="video/mp4">
                </video>
            </a>
            <div>
                <ul>
                    <li>
                        <p><em>Shift</em> + <em>A</em> adds new data, depending on the
                            context.</p>
                    </li>
                    <li>
                        <p>Adds an object in <em>Object Mode</em>, additional data to the active
                            object in <em>Modeling</em> or a new node in one of the <em>Node Editors</em></p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="Duplicate">
            <a href="#Duplicate">
                <h3>Duplicate</h3>
                <h3><em>Shift</em> + <em>D</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/Duplicate.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p>
                            <em>Shift</em> + <em>D</em> to duplicate the selection.
                        </p>
                    </li>
                    <li>

                        <p>
                            In <em>Object Mode</em>, <em>Alt</em> + <em>D</em> creates <em>linked duplicates</em> which
                            reference the original data instead of copying it.
                        </p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="ChangeShading">
            <a href="#ChangeShading">
                <h3>Change Shading</h3>
                <h3><em>Z</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/ChangeShading.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>Shift</em> + <em>Z</em> to toggle <em>wireframe</em> and <em>X-ray
                            </em>, to see and select through the mesh.</p>
                    </li>
                    <li>
                        <p><em>Alt</em> + <em>Z</em> to only toggle <em>X-ray</em>.</p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="SelectionModes">
            <a href="#SelectionModes">
                <h3>Selection Modes</h3>
                <h3><em>1</em> , <em>2</em> , <em>3</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/SelectionModes.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>1</em> for <em>vertex select.</em></p>
                    </li>
                    <li>
                        <p><em>2</em> for <em>edge select.</em></p>
                    </li>
                    <li>
                        <p><em>3</em> for <em>face select.</em></p>
                    </li>
                    <li>
                        <p>Switching modes can change the selection!</p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="Snap">
            <a href="#Snap">
                <h3>Snap</h3>
                <h3><em>Shift</em> + <em>S</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/SnapCursor.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p>
                            Move one thing precisely to another, especially useful to position the <em>3D cursor</em>.
                    </p></li>
                    <li>
                        <p>
                            <em>Shift</em> + <em>Right Mouse</em> to set the 3D cursor
                            by hand.
                        </p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="SelectAll">
            <a href="#SelectAll">
                <h3>Select All</h3>
                <h3><em>A</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/SelectAll.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>A</em> to select all objects, meshes, keyframes etc. depending the
                            context.
                        </p>
                    </li>
                    <li>
                        <p><em>Alt</em> + <em>A</em> to deselect all.
                        </p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="AddToSelection">
            <a href="#AddToSelection">
                <h3>Add to Selection</h3>
                <h3><em>Shift</em> + <em>Left Mouse</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/SelectAdd.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>Shift</em> + <em>Left Mouse</em> on unselected to add
                            to the selection.
                        </p>
                    </li>
                    <li>
                        <p><em>Shift</em> + <em>Left Mouse</em> on selected to remove
                            from the selection.
                        </p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="SelectLoop">
            <a href="#SelectLoop">
                <h3>Select Loop</h3>
                <h3><em>Alt</em> + <em>Left Mouse</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/SelectLoop.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>Alt</em> + <em>Left Mouse</em>
                            while the cursor is close to a crossing edge.</p>
                    </li>
                    <li>
                        <p><em>Alt</em>+<em>Shift</em>+<em>Left
                                Mouse</em> to add or remove loops from the selection.
                        </p>
                    </li>
                    <li>
                        <p>Only works on multiple faces if they are four-sided ("quads").</p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="SelectPathArea">
            <a href="#SelectPathArea">
                <h3>Select Path / Area</h3>
                <h3><em>Ctrl</em> + <em>Left Mouse</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/SelectPathArea.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>Ctrl</em>+<em>Left Mouse</em> to add the shortest path
                            of vertices or faces to the selection.</p>
                    </li>
                    <li>
                        <p><em>Ctrl</em>+<em>Shift</em>+<em>Left
                                Mouse</em> to add or remove an area.</p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="SelectLinked">
            <a href="#SelectLinked">
                <h3>Select Linked</h3>
                <h3><em>L</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/SelectLinked.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>L</em> to select all linked vertices under the cursor.</p>
                    </li>
                    <li>
                        <p><em>Shift</em> + <em>L</em> to
                            remove all linked vertices from the selection</p>
                    </li>
                    <li>
                        <p><em>Ctrl</em> + <em>L</em> to select what is linked to the
                            current selection.</p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="SelectMoreLess">
            <a href="#SelectMoreLess">
                <h3>Select More / Less</h3>
                <h3><em>Ctrl</em> + <em>Num +</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/SelectMoreLess.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>Ctrl</em> + <em>Num +</em> to select more.</p>
                    </li>
                    <li>
                        <p><em>Ctrl</em> + <em>Num -</em> to select less.</p>
                    </li>
                    <li>
                        <p><em>Ctrl</em> + <em>Shift</em> + <em>Num
                                +</em> to select more elements with the same distance as the last two.</p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="SelectSimilar">
            <a href="#SelectSimilar">
                <h3>Select Similar</h3>
                <h3><em>Shift</em> + <em>G</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/SelectSimilar.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>Ctrl</em> + <em>G</em> to select all with similar
                            traits to the current selection.</p>
                    </li>
                    <li>
                        <p>Also works with objects or nodes selected (Select Grouped)</p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="Extrude">
            <a href="#Extrude">
                <h3>Extrude</h3>
                <h3><em>E</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/Extrude.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>E</em> to extrude a connected copy of the selected mesh and start a
                            move.</p>
                    </li>
                    <li>
                        <p><em>Escape</em> or <em>Right click</em> to cancel the move,
                            but <em>not the extrude</em>.</p>
                    </li>
                    <li>
                        <p><em>Alt</em> + <em>E</em> for more options.
                        </p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="Inset">
            <a href="#Inset">
                <h3>Inset</h3>
                <h3><em>I</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/Inset.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>I</em> to inset around the selected faces.
                        </p>
                    </li>
                    <li>
                        <p>Press <em>I</em> again to inset individual faces.
                        </p>
                    </li>
                    <li>
                        <p>Press <em>O</em> to toggle outset.
                        </p>
                    </li>
                    <li>
                        <p>Press <em>B</em> to toggle boundary.
                        </p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="Merge">
            <a href="#Merge">
                <h3>Merge</h3>
                <h3><em>M</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/MergeCenter.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p>Merge all selected vertices at a specified point.
                        </p>
                    </li>
                    <li>
                        <p><em>Merge By Distance</em> to remove vertices that are closer than the
                            threshold value, which you can set in the context menu.</p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="AddFace">
            <a href="#AddFace">
                <h3>Add Face</h3>
                <h3><em>F</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/Fill.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>F</em> to add a new face to the mesh. Adds a loose edge if two separate
                            vertices are selected.
                        </p>
                    </li>
                    <li>
                        <p><em>Alt</em> + <em>F</em> to fill Ngons with triangles.
                        </p>
                    </li>
                    <li>
                        <p><em>Ctrl</em> + <em>F</em> to bring up all face options
                            including "Grid Fill"
                        </p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="Split">
            <a href="#Split">
                <h3>Split</h3>
                <h3> <em>Y</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/Split.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>Y</em> to split the selected from unselected geometry.</p>
                    </li>
                    <li>
                        <p>All geometry stays in the same object.</p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="Separate">
            <a href="#Separate">
                <h3>Separate</h3>
                <h3> <em>P</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/Separate.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>P</em> to separate the geometry into a new object.</p>
                    </li>
                    <li>
                        <p>The new object will have the same modifiers as the object it was separated from.</p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="LoopCut">
            <a href="#LoopCut">
                <h3>Loop Cut</h3>
                <h3><em>Ctrl</em> + <em>R</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/LoopCut.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>Ctrl</em> + <em>R</em> to cut a loop if faces into
                            segments.</p>
                    </li>
                    <li>
                        <p>Roll the <em>Mouse Wheel</em> to change the number of segments.</p>
                    </li>
                    <li>
                        <p>Only works on multiple faces if they are four-sided ("quads").</p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="ConnectPath">
            <a href="#ConnectPath">
                <h3>Connect Path</h3>
                <h3><em>J</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/ConnectPath.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>J</em> to connect vertices in the order in which they were selected.
                    </p></li>
                    <li>
                        <p>Cuts into faces and creates additional vertices when the path intersects with existing edges.
                        </p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="Bevel">
            <a href="#Bevel">
                <h3>Bevel</h3>
                <h3><em>Ctrl</em> + <em>B</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/Bevel.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>Ctrl</em> + <em>B</em> to bevel edges.</p>
                    </li>
                    <!-- <li>
                        <p><em class="shortcut">Ctrl</em> + <em class="shortcut">Shift</em> + <em
                                class="shortcut">B</em> to
                            bevel vertices.</p>
                    </li> -->
                    <li>
                        <p>Roll the <em>Mouse Wheel</em> to adjust the number of segments.</p>
                    </li>
                    <li>
                        <p><em>V</em> to toggle vertex bevel.</p>
                    </li>
                    <li>
                        <p><em>C</em> to toggle clamping.</p>
                    </li>
                    <li>
                        <p><em>P</em> to adjust the bevel profile.</p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="Dissolve">
            <a href="#Dissolve">
                <h3>Dissolve</h3>
                <h3><em>Ctrl</em> + <em>X</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/Dissolve.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>Ctrl</em> + <em>X</em> to delete vertices but connect
                            the surrounding edges. The result is based on the <em>selection mode</em>.
                        </p>
                    </li>
                    <li>
                        <p><em>X</em><em> &gt; Limited Dissolve</em> dissolves all
                            vertices/edges below a treshold angle.</p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="ShrinkFatten">
            <a href="#ShrinkFatten">
                <h3>Shrink/Fatten</h3>
                <h3> <em>Alt</em> + <em>S</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/FattenShrink.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>Alt</em> + <em>S</em> to move all vertices along their
                            vertex normals.</p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="Search">
            <a href="#Search">
                <h3>Search</h3>
                <h3><em>F3</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/Search.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>F3</em> to open operator search.
                        </p>
                    </li>
                    <li>
                        <p><em>Arrow Up</em> and <em>Arrow Down</em> to navigate, <em>Enter</em> to select.
                        </p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="ExtrudeToCursor">
            <a href="#ExtrudeToCursor">
                <h3>Extrude to Cursor</h3>
                <h3><em>Ctrl</em> + <em>Right Mouse</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/ExtrudeToCursor.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>Ctrl</em> + <em>Right Mouse</em> to extrude to the
                            cursor position and adjust the rotation of the previous segment.
                        </p>
                    </li>
                    <li>
                        <p>Extrusions will be placed at the depth of the 3D cursor.
                        </p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="SnapToggle">
            <a href="#SnapToggle">
                <h3>Snap (Toggle)</h3>
                <h3><em>Ctrl</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/SnapGrid.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p>Hold <em>Ctrl</em> to enable snapping.
                        </p>
                    </li>
                    <li>
                        <p>Works with <em>Move</em>, <em>Rotate</em> and <em>Scale</em> as well as <em>Sliders</em>
                        </p>
                    </li>
                    <li>
                        <p>You can snap to increments (default) or geometry (vertices, edges, faces).
                        </p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="GranularInput">
            <a href="#GranularInput">
                <h3>Granular Input</h3>
                <h3><em>Shift</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/Granular.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p>Hold <em>Shift</em> to divide the mouse input for more precise control.
                        </p>
                    </li>
                    <li>
                        <p>Works with <em>Move</em>, <em>Rotate</em> and <em>Scale</em> as well as <em>Sliders</em>
                        </p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="MultiEdit">
            <a href="#MultiEdit">
                <h3>Multi-Edit</h3>
                <h3><em>Alt</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/MultiEdit.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p>If you have multiple objects selected, editing parameters will only affect the <em>active</em> object.
                        </p>
                    </li>
                    <li>
                        <p>Hold <em>Alt</em> to change the parameters of <em>all
                                selected</em> objects instead.
                        </p>
                    </li>
                </ul>
            </div>

            

            </div>

        <div id="ToSphere">
            <a href="#ToSphere">
                <h3>To Sphere</h3>
                <h3><em>Shift</em> + <em>Alt</em> + <em>S</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/ToSphere.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>Shift</em> + <em>Alt</em> + <em>S</em>
                            makes selected vertices approach a sphere. Accepts inputs between 0 and 1.
                        </p>
                    </li>
                    <li>
                        <p>Turns a single loop of vertices into a circle.
                        </p>
                    </li>
                </ul>
            </div>

            

            </div>
        
        <div id="SubdivModifier">
            <a href="#SubdivModifier">
                <h3>Subdivision Surface</h3>
                <h3><em>Ctrl</em> + <em>1</em></h3>
                <video autoplay="" loop="" muted="" playsinline="">
                    <source src="https://hollisbrown.github.io/blendershortcuts/videos/SubdivModifier.mp4" type="video/mp4">
                </video>
            </a>

            <div>
                <ul>
                    <li>
                        <p><em>Ctrl</em> + <em>1, 2, 3</em> to add a subdivision surface modifier with corresponding levels.
                        </p>
                    </li>
                    <li>
                        <p><em>Ctrl</em> + <em>0</em> will disable the modifier (level 0).
                        </p>
                    </li>
                </ul>
            </div>

            

            </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ThreadPlotter – toolkit for punch needle embroidery with X-Y plotters (2020) (121 pts)]]></title>
            <link>https://github.com/LiciaHe/threadPlotter</link>
            <guid>41270596</guid>
            <pubDate>Fri, 16 Aug 2024 21:35:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/LiciaHe/threadPlotter">https://github.com/LiciaHe/threadPlotter</a>, See on <a href="https://news.ycombinator.com/item?id=41270596">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">ThreadPlotter</h2><a id="user-content-threadplotter" aria-label="Permalink: ThreadPlotter" href="#threadplotter"></a></p>
<p dir="auto">A toolkit for the design and fabrication of delicate punch needle embroidery using X-Y plotters_</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What?</h2><a id="user-content-what" aria-label="Permalink: What?" href="#what"></a></p>
<p dir="auto">ThreadPlotter is a toolkit that supports the designing, editing, and printing of images as punch needle embroidery using an X-Y plotter. It is a supplementary material for the paper:</p>
<p dir="auto"><a href="http://www.cond.org/punchneedle.html" rel="nofollow">"Plotting with Thread: Fabricating Delicate Punch Needle Embroidery with X-Y Plotters"
Shiqing He, Eytan Adar, to appear, DIS'20, Honorable Mention Award</a></p>
<p dir="auto">The following video briefly introduces the motivation for building this tool and the capability of the ThreadPlotter.</p>
<p dir="auto"><a href="https://www.youtube.com/watch?v=zMfiQarMp-8" rel="nofollow"><img src="https://github.com/LiciaHe/threadPlotter/raw/master/assets/youtube-preview.png" alt="youtube-preview"></a></p>
<p dir="auto">You might also be interested in this 10 minutes presentation that goes over the project in depth.</p>
<p dir="auto"><a href="https://www.youtube.com/watch?v=jvuNcWv8kGo" rel="nofollow"><img src="https://github.com/LiciaHe/threadPlotter/raw/master/assets/youtube-presentation.png" alt="youtube-presentation"></a></p>
<p dir="auto">If you are interested in using this toolkit, please consider citing our paper:<a href="http://www.cond.org/punchneedle.html" rel="nofollow">Plotting with Thread: Fabricating Delicate Punch Needle Embroidery with X-Y Plotters</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How?</h2><a id="user-content-how" aria-label="Permalink: How?" href="#how"></a></p>
<p dir="auto">To convert your X-Y plotter into a punch needle fabricator, we will follow the following steps:</p>
<ol dir="auto">
<li>Ensure that your plotter is suitable for the task. (<a href="https://github.com/LiciaHe/threadPlotter/blob/master/tutorial/step1_plotterCheck.md">tutorial 1</a>)</li>
<li>Acquire or create several physical components such as needle, fabric, and frame. (<a href="https://github.com/LiciaHe/threadPlotter/blob/master/tutorial/step2_physicalSetup.md">tutorial 2</a>)</li>
<li>Design a punch needle pattern.
<ol dir="auto">
<li><a href="https://github.com/LiciaHe/threadPlotter/blob/master/tutorial/step3_patternMaking.md">tutorial 3: pattern making overview</a></li>
<li><a href="https://github.com/LiciaHe/threadPlotter/blob/master/tutorial/step4_advancedExamples.md">tutorial 4: advanced examples</a> #in progress</li>
</ol>
</li>
</ol>
<p dir="auto">We highly recommend that you review our paper before getting started. When you are ready, click on each of the links above.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Show us! Tell us! Ask us! Credit us!</h2><a id="user-content-show-us-tell-us-ask-us-credit-us" aria-label="Permalink: Show us! Tell us! Ask us! Credit us!" href="#show-us-tell-us-ask-us-credit-us"></a></p>
<p dir="auto">We are excited to see what you can create with this fabrication technique. The toolkit is developed and tested by Licia (on her plotter called "Kitty"). If you have questions about the toolkit, feel free to open up an issue in our <a href="https://github.com/LiciaHe/threadPlotter">github page</a>.</p>
<p dir="auto">If you created something and want to share it with us, please use the tag <a href="https://www.instagram.com/explore/tags/plotterembroidery/?hl=en" rel="nofollow">#plotterembroidery</a> on SNS.</p>
<div data-snippet-clipboard-copy-content="@inproceedings{10.1145/3357236.3395540,
author = {He, Shiqing and Adar, Eytan},
title = {Plotting with Thread: Fabricating Delicate Punch Needle Embroidery with X-Y Plotters},
year = {2020},
isbn = {9781450369749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357236.3395540},
doi = {10.1145/3357236.3395540},
booktitle = {Proceedings of the 2020 ACM Designing Interactive Systems Conference},
pages = {1047–1057},
numpages = {11},
keywords = {plotter, craft fabrication, embroidery fabrication, punch needle embroidery, craft design, x-y plotter, fiber art},
location = {Eindhoven, Netherlands},
series = {DIS ’20}
}
  
"><pre><code>@inproceedings{10.1145/3357236.3395540,
author = {He, Shiqing and Adar, Eytan},
title = {Plotting with Thread: Fabricating Delicate Punch Needle Embroidery with X-Y Plotters},
year = {2020},
isbn = {9781450369749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357236.3395540},
doi = {10.1145/3357236.3395540},
booktitle = {Proceedings of the 2020 ACM Designing Interactive Systems Conference},
pages = {1047–1057},
numpages = {11},
keywords = {plotter, craft fabrication, embroidery fabrication, punch needle embroidery, craft design, x-y plotter, fiber art},
location = {Eindhoven, Netherlands},
series = {DIS ’20}
}
  

</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">License</h3><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">MIT License</p>
<p dir="auto">Copyright (c) [2020] [Shiqing He]</p>
<p dir="auto">Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:</p>
<p dir="auto">The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.</p>
<p dir="auto">THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The future of Deep Learning frameworks (155 pts)]]></title>
            <link>https://neel04.github.io/my-website/blog/pytorch_rant/</link>
            <guid>41270043</guid>
            <pubDate>Fri, 16 Aug 2024 20:24:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://neel04.github.io/my-website/blog/pytorch_rant/">https://neel04.github.io/my-website/blog/pytorch_rant/</a>, See on <a href="https://news.ycombinator.com/item?id=41270043">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong>Assumed audience:</strong> ML researchers who frequently work with <code>PyTorch</code>, but are interested in trying out <code>JAX</code> or have yet to be convinced.</p><hr><h2 id="introduction">Introduction</h2><p>Usually, people start these ‘critiques’ with a disclaimer that they are not trying to trash the framework, and talk about how it’s a tradeoff. However, this is assumed - I’m not going to waste your time with that.</p><p>Instead, I’ll focus on why PyTorch has been a net negative for all (if not most) scientific computing efforts, causing billions of dollars in lost productivity and thousands of wasted dev-hours.</p><p>This is not because its a <em>bad</em> framework per-se, but rather - it simply because it wasn’t designed for the use-cases it’s being employed in right now.</p><p>Ever since <a href="http://torch.ch/">LuaTorch</a>, PyTorch was supposed to be a “production ready, easy-to-use framework for quick prototyping”.</p><p>It wasn’t meant to be deployed onto huge, distributed clusters comprising of thousands of interconnected nodes and GPUs and scale <em>well</em> in a fault-tolerant and robust matter.</p><p>The guiding philosophy of <code>Torch</code> was never about scale - despite what their marketing may have you believe - but <em>flexibility</em>.</p><p>In response to the rising need of a scalable and performant framework, DeepMind developed <code>JAX</code> to meet a simple goal:</p><blockquote><p>“… Supporting state-of-the-art AI research [by] balancing rapid prototyping and quick iteration with the ability to deploy experiments at a scale …” - <a href="https://arc.net/l/quote/cumgnsor"><code>JAX</code> blogpost</a></p></blockquote><p>This post is about convincing you how important this idea/philosophy is not only for Deep Learning, but for all scientfic computing that needs to happen at scale.</p><p>I believe that all infrastructure built on <code>Torch</code> is just a huge pile of technical debt, that will haunt the field for a long, long time.</p><h2 id="the-philosophy">The Philosophy</h2><p>PyTorch’s philosophy has always, in some ways, been antithetical to that of Tensorflow’s.</p><p>Where <code>TF 1.x</code> tried to be a static but performant framework by making strong use of the <code>XLA</code> compiler, <code>PyTorch</code> instead focused on being dynamic, easily debuggable and pythonic.</p><p>Early on, the TF devs realized their mistakes when they came to realize how much the community hated the old <code>1.x</code> API, which was counter-intuitive and introduced anti-pythonic patterns that were difficult to grasp for beginners.</p><p>This prompted the core decision to use <code>Keras</code> as the main interface for TensorFlow and downplay the role of <a href="https://en.wikipedia.org/wiki/Accelerated_Linear_Algebra"><code>XLA</code></a> compiler that was at TF’s core. The main focus was on cleaning up the frontend as much as possible.</p><p>This was a huge mistake.</p><p>Sure, the API did improve and worked well for some people - but only as long as your workloads were standard. Any deviations from the norm were punished by stacktrace dumps that were often literal pages of just garbled <code>XLA-HLO</code> that were a nightmare to debug unless you had a strong grasp on the internals of the framework/compiler - which you <strong>didn’t</strong> because <code>XLA</code> was a closed source, internal Google project at the time.</p><p>In short, it had every hallmark of a typical Google product.</p><p>Thus it comes as no surprise that people who switched over to PyTorch thought they had discovered literal heaven:</p><div><blockquote><p lang="en" dir="ltr">I've been using PyTorch a few months now and I've never felt better. I have more energy. My skin is clearer. My eye sight has improved.</p>— Andrej Karpathy (@karpathy) <a href="https://twitter.com/karpathy/status/868178954032513024?ref_src=twsrc%5Etfw">May 26, 2017</a></blockquote></div><p>PyTorch stuck to its roots. Unlike TensorFlow’s static &amp; lazy approach, they took the bolder, more dynamic “eager” approach wherein all <code>torch.Tensor</code>s were evaluated immediately, leading to a much more cleaner abstraction than TensorFlow’s.</p><p>Clearly, they understood that complexity is the enemy of productivity. Instead of tacking on band-aids, they had pursued a fresh new path which paid off.</p><p>Unsurprisingly, almost serious research moved to PyTorch:</p><figure><p><img src="https://neel04.github.io/my-website/blog/pytorch_rant/image-1.png"></p><figcaption>PyTorch vs. Tensorflow usage in research repos</figcaption></figure><p>But in 2021 <a href="https://arxiv.org/abs/2005.14165"><code>GPT-3</code></a> hit the scene and suddenly things started getting serious. All of a sudden, performance and scalability became the primary concern.</p><p><code>PyTorch</code> accomodated for this rising demand <em>decently</em> well, but because it wasn’t designed around this philosophy - slowly the debt starting catching up and the foundations started crumbling. It’s hard to reconcile flexibility with performance. Clearly, a tradeoff needed to be made.</p><p>Either they could give their biggest and richest users exactly what they wanted - a clean &amp; scalable ecosystem that prioritized performance - which would be a static-oriented <code>TF</code>-like design - or they could try to hold on to what made <code>Torch</code> so special in the first place - being dynamic and “eager” at the expense of performance, and somehow delegate those large-scale workloads to an entirely seperate technological stack.</p><p>So the devs, being the smart and rational engineers they are, choose an appropriate compromise which was . . . . to pursue both paths simultaneously.</p><p>They were unwilling to make any tradeoffs. They wanted their cake and were going to eat it too.</p><p>The new approach was ultimately a chaotic mishmash of competing features. You have on one hand, PyTorch’s committment to eventually use <em>some</em> compiler (likely <code>XLA</code>) as a performant and reliable default backend and on the other, to build up their own entire <a href="https://pytorch.org/docs/stable/torch.compiler.html"><code>torch.compile</code></a> stack that somehow meshes well with the eager, dynamic philosophy by giving users the freedom to invoke a compiler if need be.</p><p>This lack of real long-term strategy is a serious issue.</p><p>Take the <code>torch.compile</code> stack and the new <a href="https://github.com/pytorch/pytorch/blob/main/torch/distributed/_tensor/README.md"><code>DTensor</code></a> API as an example. The documentation is transparent about the inspiration for this feature. It tries to
bring the sharding model of parallelization from <code>JAX</code> to <code>PyTorch</code>.</p><blockquote><p>… When using <code>DTensor</code> in a [distributed] fashion it might be … <strong>slower</strong> compared to existing solutions like DDP/FSDP. This is mainly because DDP/FSDP have a global view of the entire model … [and can thus] optimize for data parallel specifically … [whereas] DistributedTensor … can only optimize within individual tensor operations.</p></blockquote><blockquote><p>To improve efficiency of <code>DTensor</code>-based data parallel training, we are exploring a <strong>compiler-based</strong> solution on top of <code>DTensor</code>.</p></blockquote><p>Leaning on the compiler is diametrically opposed to torch’s dynamic philosophy - because at each step, you’re restricted by the constraints placed by the compiler which you <em>must</em> obey.</p><p><code>PyTorch</code> clearly doesn’t want to commit to a compiler-centric philosophy (like <code>JAX</code>) but I don’t see any good alternative solutions - and frankly, I doubt the devs do either.</p><p>Instead, what you end up getting getting is a fragmented suite of tools that’re barely usable without significant dev-hours sunk in just setting them up and coaxing them to work with each other.</p><p>It’s considerable friction for research teams who often spend more of their time babysitting the codebase and triangulating random errors rather than running more experiments.</p><p>I feel there is a stronger incentive internally on <em>marketing</em> and shipping ‘features’ rather than actually ensuring they integrate well into the ecosystem. It’s true that maintaining such a huge ecosystem will always have it’s problems, but the considering the case where devs shipped
a built-in implementation of <code>FSDP</code>, and it didn’t work at <em>all</em> with their own <code>torch.compile</code> stack for months, really goes to show where their priorities lie.</p><p>There is simply no excuse for two of your most core, critical features not working together at all. Users had to wait <a href="https://dev-discuss.pytorch.org/t/torch-compile-fsdp-dec-8th/1718">weeks</a> before it was officially patched and the bugs were ironed out to the point of it being in a ususable state where is stands now.</p><p>My point is that all these failures are systemic due to: a) bad organization and b) bad design decisions.</p><p>So what is the competition’s solution to this problem?</p><h2 id="compiler-driven-development">Compiler-driven development</h2><p><code>JAX</code> leverages TensorFlow’s formidable compiler stack, <a href="https://en.wikipedia.org/wiki/Accelerated_Linear_Algebra"><code>XLA</code></a>. <code>XLA</code> is a pretty powerful compiler, but the beauty is that it’s all abstracted away for the end user.
For any function you have, as long as the function is <strong>pure</strong> (more on this later) you can use the simple <code>@jax.jit</code> decorator to JIT compile your function and make it available to <code>XLA</code>.</p><p>You can <code>jit</code> any JAX code - <code>XLA</code> handles the rest. This is what makes JAX such a great framework for scientific computing - its effectively an eDSL built entirely around <code>XLA</code>. The compiler handles and abstracts away a lot of the heavy lifting for us - verifying that the generated graph is correct,
<code>GSPMD</code> partitioner that handles the auto-parallelization w/ sharding in JAX, the graph optimizations, operator and kernel fusion, Latency hiding Scheduling, overlapping asynchronous comms, codegeneration to other backends such as <a href="https://openai.com/index/triton/"><code>triton</code></a> etc.
are all handled by <code>XLA</code> behind the scenes.</p><p>This is a powerful approach. As long as your code obeys some simple JAX restrictions, <code>XLA</code> does this automatically for you. For example, you don’t need <code>torch.distributed.barrier()</code> and other comms primitives when doing parallelization.
DDP support is as simple as:</p><div><pre tabindex="0"><code data-lang="py"><span><span><span># Create a Sharding object to distribute a value across devices:</span>
</span></span><span><span>sharding = PositionalSharding(mesh_utils.create_device_mesh((8,)))   
</span></span><span><span>x = JAX.random.normal(JAX.random.key(0), (8192, 8192))
</span></span><span><span>y = JAX.device_put(x, sharding.reshape(4, 2))
</span></span></code></pre></div><p>which you can also visualize with the built in utilities:</p><div><pre tabindex="0"><code data-lang="py"><span><span>&gt;&gt;&gt; JAX.debug.visualize_array_sharding(z)
</span></span><span><span>
</span></span><span><span>+---------------------+
</span></span><span><span>|  TPU 0   |  TPU 1   |
</span></span><span><span>|----------|----------|
</span></span><span><span>|  TPU 2   |  TPU 3   |
</span></span><span><span>|----------|----------|
</span></span><span><span>|  TPU 6   |  TPU 7   |
</span></span><span><span>|----------|----------|
</span></span><span><span>|  TPU 4   |  TPU 5   |
</span></span><span><span>+---------------------+
</span></span></code></pre></div><p><code>XLA</code>’s approach is that computation follows sharding. Therefore, if the input array is sharded across some axis, <code>XLA</code> handles that automatically for any downstream computation. No other code changes needed.
No need to add communication collections or anything. <code>Pytorch</code> on the other hand requires a ton of boilerplate and modifications just to get a basic DDP setup working correctly.</p><p>This idea of “compiler driven development” is similar to how rust’s compiler works - helping you write better, cleaner code without worrying about a lot of mundane things.</p><p>You focus on the computation, the compiler does the rest.</p><p>I believe that comitting to a philosophy gives a framework a certain design skeleton and structure, that can simplify the code and create a smooth and wondeful experience for a developer.</p><p>Which is why I’m unhappy with the choice made by the <code>PyTorch</code> devs to integrate and rely on a compiler stack for the cool new features rather than keeping the core philosophy of <em>flexibility</em> and <em>freedom</em> alive.</p><p>For example, according to the official <a href="https://pytorch.org/blog/pytorch-2.0-xla-path-forward/">roadmap</a> for <code>PyTorch</code> <code>2.x</code>, they clearly outline their long-term plans of fully integrating <code>XLA</code> with <code>Torch</code>:</p><blockquote><p>“PyTorch/<code>XLA</code> is set to migrate to the open source <code>OpenXLA</code> as its <strong>default</strong> downstream compiler”</p></blockquote><p>This is an awful idea. It’s like saying that shoehorning C++ code in the rust compiler, would somehow be a better experience than using rust itself.</p><p>Torch simply wasn’t <em>designed</em> around <code>XLA</code>, unlike <code>JAX</code>. The reason <code>JAX</code>’s’ ecosystem is so much more stable and well-integrated is precisely because they uphold it’s core values rather than working around them.</p><p>If, god forbid, <code>Pytorch</code> does end up going with the plan and commits to an <code>XLA</code> based compiler stack, then wouldn’t the ideal framework be the one that was <em>specifically</em> designed and built around it, as opposed to the one where it has just been crammed in with little thought and care?</p><p>And even <strong>if</strong> <code>Pytorch</code> ends up pursuing a ‘multi-backend’ approach, wherein you would be able choose whatever compiler backend you wish, wouldn’t that worsen the fragmentation problem and absolutely nuke the API, as it tries to respect the restrictions of every compiler stack?</p><p>This isn’t just baseless theorizing either — look at <code>Torch/XLA</code>. Anyone who’s ever dared to use it on TPUs suffers from a PTSD so severe that they’re eligible for benefits. The mere sight of “XLA” sends them into a state of cold sweat and nightmares to the caffeine-fuelled days spent debugging hundred-line <code>XLA</code> errors. The only path to recovery at such moments is to reassure the victim that they’ll always have their GPUs, and an <code>A100</code> may be placed beside them for emotional support.</p><h2 id="multi-backend-is-doomed">Multi-backend is doomed</h2><p><code>Pytorch</code>’s root problem is that it tries to do everything at once and fails miserably.</p><p>The “multi-backend” design decision makes this problem exponentially worse. In <em>theory</em>, it sounds like an amazing idea to be able to choose whichever stack you prefer - but in reality, its a tangled mess of obscure tracebacks and incompatibility issues.</p><p>It’s not that its <em>hard</em> to get these backends working. Rather, there are some constraints that these backends expect which are hard to mesh with the flexible and pythonic API of <code>PyTorch</code>.</p><p>There’s a tradeoff between keeping most of the API consistent vs. obeying the restrictions of the backends you leverage. As a result, the devs are seeking to rely more on codegen (say converting torch code to <code>triton</code> which then you can manually work with and leverage it’s compiler &amp; JIT stack)
as opposed to actually integrating/comitting to a single backend - which is arguably the worse option for <code>torch</code>.</p><p>Every decision <code>torch</code> takes somehow always feels like a compromise because it refuses to make meaningful tradeoffs. There’s no coherence, no overall strategy. It ends up feeling more like a mishmash of features that don’t mesh well together and ultimately cause a lot of frustration for the user.</p><p>There is no faster way to kill an ecosystem.</p><p>IMHO PyTorch should not follow the <code>JAX</code> “integrated compiler and backend” approach for a very simple reason: Jax was explcitly designed from the ground up to work <strong>with</strong> <code>XLA</code>. Not <strong>against</strong> it. That is why <code>TensorFlow</code> never really took off, and why it’s attempts at integrating <code>Keras</code> crashed and burned.</p><p>Your strategy simply cannot be to just replace the entire <code>PyTorch</code> frontend with <code>JAX</code>’s, because then you just have a shittier version of <code>JAX</code>! It’s virtually impossible to come up with a neat, functional API based on <code>XLA</code> that’s somehow better than <code>JAX</code>’s, and carries on <code>Torch</code>’s flexible nature.</p><p>I don’t blame the devs for trying new and different ideas - those are always welcome. However, if they want <code>PyTorch</code> to stand the test of time, more focus has to be put in shoring up the foundations than shipping shiny new features that immediately crumble outside ideal tutorial conditions.</p><h2 id="fragmentation--functional-programming">Fragmentation &amp; Functional Programming</h2><p><code>JAX</code> has a “functional” API. Earlier, I mentioned that <code>JAX</code> functions have to be pure (i.e they cannot have any global side effect. Just like mathematical functions, given the same data the function will always return the same output no matter the context of it’s execution.)</p><p>This design philosophy is what makes <code>JAX</code> stand out. Due to the functional roots of <code>JAX</code>, <code>JAX</code> functions are often composable and interoperate well with each other. It reduces the development complexity as functions are defined with specific signatures and a well-defined,
concrete task. If the types are respected, then the function is guranteed* to work out-of-the-box.</p><p>This is well suited to the kinds of workloads that one needs in scientific computing. In Deep Learning especially, since NNs are just a static functions, this functional paradigm makes writing even complex codebases easy.</p><p>For example, let’s look at the <code>optax</code> API from the <code>JAX</code> ecosystem.</p><p>Due to the functional approach, <code>optax</code> has what we call a “chain” that involves a bunch of functions sequentially applied on the gradients. So the fundamental building blocks are <code>GradientTransformation</code>s.</p><p>This makes it a really powerful but expressive API to work with.</p><div><pre tabindex="0"><code data-lang="py"><span><span>optimizer = optax.adam(1e-2)
</span></span></code></pre></div><p>If I wanted to clip the grads here for example, I could do it trivially:</p><div><pre tabindex="0"><code data-lang="py"><span><span>optimiser = optax.chain(
</span></span><span><span>    optax.clip_by_global_norm(1.0),
</span></span><span><span>    optax.adam(1e-2),
</span></span><span><span>)
</span></span></code></pre></div><p>If I wanted to do a simple operation such as take the <code>EMA</code> of my grads, in PyTorch that would’ve required setting up objects and then manually digging through the codebases to place methods appropriately.
But with <code>optax</code>,</p><div><pre tabindex="0"><code data-lang="py"><span><span>optimiser = optax.chain(
</span></span><span><span>    optax.clip_by_global_norm(1.0),
</span></span><span><span>    optax.adam(1e-2),
</span></span><span><span>    optax.ema(decay=0.999)
</span></span><span><span>)
</span></span></code></pre></div><p>A similar approach goes for combining optimizers, meta-learning approaches, gradient accumulation etc. It’s simply much more cleaner than <code>PyTorch</code>.</p><p>Another cool consequence of a functional design is <code>vmap</code>. This stands for ‘vectorized’ map which accurately describes what it does. You can <code>map</code> anything and as long as its a <code>vmap</code>, then <code>XLA</code> will automatically fuse and optimize it.</p><p>This means that when you write functions, you <strong>don’t think about the batch dimension!</strong> You just <code>vmap</code> all you code and this simplifies things.</p><p>For one, you need less <code>ein-*</code> ops. While <code>einops</code> are great and all - it’s simply more intuitive to grasp 2D/3D tensor manipulations, and are also much more readable IMO. Let’s take an extremely limited example operation, and compare the difference:</p><div><pre tabindex="0"><code data-lang="py"><span><span>arr: Array = jnp.ones((batch_size, seqlen, h_dim))
</span></span><span><span>
</span></span><span><span><span>def</span> <span>vanilla_func</span>(arr: Array) -&gt; Array:
</span></span><span><span>  <span>'''
</span></span></span><span><span><span>  We want to do a: '(b s h, b s h) -&gt; (b s s, b s h) -&gt; b h s' operation.
</span></span></span><span><span><span>  '''</span>
</span></span><span><span>  <span>return</span> ((arr @ arr.transpose(0, 2, 1)) @ arr).transpose(0, 2, 1)
</span></span><span><span>
</span></span><span><span>@jax.vmap
</span></span><span><span><span>def</span> <span>vmapped_func</span>(arr: Array) -&gt; Array:
</span></span><span><span>  <span>'''
</span></span></span><span><span><span>  We want to do a: '(s h, s h) -&gt; (s s, s h) -&gt; h s' operation.
</span></span></span><span><span><span>  '''</span>
</span></span><span><span>  <span>return</span> ((arr @ arr.T) @ arr).T
</span></span></code></pre></div><p>Even for this toy operation, you can immediately see how much more instantly readable the function is. Now imagine that with the more complex tensor manipulations, like the ones used in <code>MHSA</code>.</p><p>Subscribing to the functional paradigm means that it’s easier to write complex code that works <em>well</em>, since you only have to reason about individual components in isolation.
It’s both clean and performant because you can <code>@jax.jit</code> any pure function without worrying about anything else. It. Just. Works.</p><p>In the functional world, as long as you respect the purity constraints and have the right signature, you enjoy all the other benefits - such as composability.</p><p>With <code>torch</code> however, there is a non-trivial chance that whatever stack you use - say doing <code>FSDP + multi-node + torch.compile + ...</code>
something will <em>always</em> break due to the sheer complexity involved. Multiple things have to work correctly together, and if any component fails due to edge case, then you would be debugging till 3 a.m.</p><p>And because there would <strong>always</strong> be bugs that weren’t caught during development simply because it’s not possible to test each and every combination of the dozens of features <code>Pytorch</code> offers, It’s simply impossible to write code that works well without significant effort.</p><p>This has meant that the <code>torch</code> ecosystem has become very bloated and buggy - things don’t interoperate well together, so contributors often come up with new libraries and frameworks to solve specific issues (like say HuggingFace’s <code>accelerate</code> for distributed training)
which in turn aren’t designed to interface with other such “solutions” due to having no shared abstraction, so it quickly devolves into a mess of dependencies and <code>requirements.txt</code> and a training loop that looks like it was the scene of Guido Van Rossum’s murder.</p><p>I’d go on to say from my anecdotal experience about 70-80% of those GitHub issues or forum discussions are simply due to various libraries erorring out on each other.</p><p>Unfortunately, few solutions exist to fix it. This is very much an OOP as well as a design problem. I <em>think</em> having a fundamental, <code>PyTorch</code>~y object (like <code>JAX</code>’s <code>PyTree</code>) might’ve helped build a common base for abstraction, but I’m not an SWE so I’m not sure how much it’d have <em>really</em> helped.</p><p>Nor can you just adopt a functional programming paradigm, at which point you’d have converged to a worse version of <code>JAX</code> while breaking all backwards compatibility for every existing <code>torch</code> codebase.</p><p>The way I see it - <code>PyTorch</code> is well and truly fucked in this department.</p><h2 id="reproducibility">Reproducibility</h2><p>The “reproducility crisis” is an oft discussed problem in science, and AI/DL has been no exception.
Despite the existence of containerized environments and version control, researchers refuse to use them and journals/conferences place no requirements on them either.
Even upholding your pledge to open-source the code isn’t verified by academic institutions.</p><p>However, there are some design choices that nudge users to write code that facilitates reproduction, with minimal effort. This incentivizes users to put that little effort in
and gain masive advantages in return - such as being able to validate their older experiments at any point and ensure that randomness is not a factor in any their results.</p><p>I believe such oversights are usually because of laziness/carelessness than malicious intent. So such small decisions can ultimately add up to saving potentially dozens of dev-hours and a lot of cussing.</p><h3 id="seeding">Seeding</h3><p><code>torch</code>’s handling of something as simple as seeding is… not ideal. Typically, you’d have to do:</p><div><pre tabindex="0"><code data-lang="py"><span><span><span>import</span> <span>torch</span>
</span></span><span><span><span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
</span></span><span><span>
</span></span><span><span>np.random.seed(0) <span># if you're using numpy</span>
</span></span><span><span>torch.manual_seed(0)
</span></span><span><span>torch.cuda.manual_seed_all(args.seed)
</span></span><span><span>torch.use_deterministic_algorithms(<span>True</span>)
</span></span><span><span>torch.utils.deterministic.fill_uninitialized_memory(<span>True</span>)
</span></span></code></pre></div><p>Which let’s be honest, isn’t really the end of the world coming at barely half a dozen loc - But on the flipside, is easily forgettable/misconfigured especially in the heat of deadlines.</p><p>I’ve personally known researchers who set the seeds in the wrong file at the wrong place and they weren’t even used by <code>torch</code> at all - instead, were just silently ignored, thus invalidating all their experiments. (That researcher was me)</p><p><code>JAX</code> on the other hand forces you to create an explicit <code>key</code> which gets passed to any function that required randomness. This approach completely eliminates this problem as the RNG at all points is statically seeded. And because <code>jax</code> has its own version
of numpy (<code>jax.numpy</code>) you don’t need to remember to seed it seperately.</p><p>This is a small fry - but I feel such small QoL decisions can end up making the whole framework’s UX a whole lot better.</p><h3 id="portability">Portability</h3><p>One of the biggest banes of using torch codebases is the lack of portability - codebases written for running on CUDA/GPUs don’t really work well when run on non-Nvidia hardware like TPUs, NPUs, AMD GPUs etc.</p><p>Worse, it’s hard to port torch code written for 1x (one) node and port it to be multi-node. Multi-node often involves dozens of dev-hours and substantial code changes to manually integrate it in the correct places. Unsurprisingly, this quickly devolves into a horror story of errors, crashes and incorrect comms that leech performance.</p><p><code>JAX</code>’s compiler-centric approach however gives it a win in this department. <code>XLA</code> handles switching between device backends for us - and it already works well out-of-the-box on GPUs/TPUs/multi-node/multi-slice with minimal to no code changes. (Support for AMD GPUs is also coming, however anecdotally it’s not in a great place right now - which seems more reflective of AMD than <code>XLA</code>.)</p><p>One only needs to implement a device backend for <code>XLA</code> to use, and it automatically takes care of the intermediate steps of extracting computation from graph as specified in a framework (Jax/TF/PyTorch), produce an HLO, and then eventually emit a lower-level IR that hardware backends can then execute during runtime.</p><figure><p><img src="https://neel04.github.io/my-website/blog/pytorch_rant/jax_platforms.png"></p><figcaption>Jax's hardware compatibility matrix, as of <i>Aug 2024</i></figcaption></figure><p>This way makes it easier for hardware vendors to support their devices, as well as make the transition between devices more easier.</p><p>I think this is an often overlooked, but important issue. Not everyone has access to the same hardware, so codebases that are portable across different types of hardware can be a small step towards making Deep Learning more accessible to beginners/intermediates as well as preventing a lot of frustration.</p><h3 id="auto-scaling">Auto Scaling</h3><p>This point ties in with the idea of portability. Codebases that can <em>autoscale</em> well on their own are massively helpful during reproduction. In an ideal case, this should happen automatically with minimal code changes, unfetterd by networking boundaries.</p><p>As we’ve come to expect, <code>JAX</code> does this well. When writing <code>JAX</code> code, you don’t need to specify communication primitives or do <code>torch.distributed.barrier()</code> everywhere - <code>XLA</code> automatically inserts that for us, taking the available hardware in account.</p><p>This philosophy means that whatever devices <code>JAX</code> can <em>detect</em> are automatically used, irrespective of networking, topology, configuration etc. You do not need to specify ranks or a central co-ordinator host.
<code>JAX</code> automagically synchronizes and stages all the computations for you, as well as apply optimization passes to maximize asynchronous execution of the kernels and minimize latency.</p><p>All a person has to do is specify the sharding of the tensors you want to distribute across, such as sharding the batch dimension of the input arrays and due to <code>XLA</code>’s “computation follows sharding” approach, it automatically figures out the rest. This is due to the <a href="https://arxiv.org/abs/2105.04663">GSPMD</a> partitioner in the XLA compiler stack.</p><p>This is really powerful, as experiments that have been validated at scale can be run by hobbyists easily to play around with them and potentially iterate on them - and vice-versa.</p><p>I feel this could help in discovery of forgotten ideas more easily, and encourage the field to be more ‘<a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">bitter</a>’ - as ideas could be easily tested as a function at bigger scales with minimal effort, thus incentivizing such experiments.</p><h2 id="the-cons">The Cons</h2><p>I have been disproportionately covering only the problems plaguing torch so far. But it’s not all roses with <code>JAX</code> either. There are a few major concerns that I wish are given far more attention among <code>JAX/XLA</code> devs:</p><h3 id="governance-structure">Governance structure</h3><p>Currently, <code>XLA</code> is under TF governance, and while talk has been made of establishing a seperate organizing body to manage all affairs, similar to torch, not much concrete efforts have been made - atleast publicly.</p><p>Unfortunately, there isn’t a lot of trust in Google at the moment due to its reputation to axe unpopular products. Now, <code>JAX</code> is technically a DeepMind project and of core significance to Google’s entire AI push, but still I feel that having a seperate governing body would be of great long-term benefit for the ecosystem as a whole
by providing guidance to the development of the project.</p><p>This would give it a concrete structure, and decouple it with Google’s infamous bureaucracy - thus avoiding a whole host of problems in a single sweep.</p><p>I don’t think <code>JAX</code> necessary <em>needs</em> an official structure of this sort, but rather it’d be nice to have a gurantee that <code>JAX</code> development will take place for a long time regardless of Google upper-management’s decisions.</p><p>It would definitely help its case in adoption among companies and big labs as well, who are hesitant to spend resources incorporating tools that might stop being maintained at some point.</p><h3 id="open-source-transition-of-xla">Open source transition of <code>XLA</code></h3><p>For the longest time, <code>XLA</code> was a closed-source project. However, efforts have been made to open source it, and now <a href="https://openxla.org/"><code>OpenXLA</code></a> is at well outperforms the internal XLA build.</p><p>However, documentation about the internals of <code>XLA</code> is still sparse. Most of the resources are just live talks and the occasional paper, which are often out-of-date.</p><p>Having a publicly accessible roadmap of upcoming features would make it easier
for people to track progress and contribute to things they find particularly interesting.</p><p>I think it’d be nice to give practitioners a way to better gauge what <code>XLA</code> can and can’t do through <a href="http://blog.ezyang.com/2019/05/pytorch-internals/">Edward Yang styled</a> mini-blogposts that breakdown each stage of the <code>XLA</code> compiler stack and explain the nitty-gritty details.</p><p>I understand that this is resource intensive, which could be better directed elsewhere but I feel that people trust the tools more when they understand them, and there’s a positive spillover effect across the entire ecosystem that ends up benefitting everyone.</p><h3 id="coalescing-ecosystem">Coalescing ecosystem</h3><p>For various reasons outside the scope of this blog, I heartily dislike <code>flax</code>. It’s a bane on the <code>JAX</code> ecosystem. It has an unintuitive API, terse syntax and is absolutely hell for beginners transitioning from <code>PyTorch</code>.</p><p>Just use <code>equinox</code>.</p><p>There have been attempts to fix <code>flax</code>’s shortcomings from the dev team, namely by using <a href="https://flax.readthedocs.io/en/v0.8.3/experimental/nnx/index.html"><code>NNX</code></a> which is supposed to be a more “equinox-y” wrapper ontop of <code>flax</code>.</p><p>However, I think it’s ultimately a waste of time. If you want an <code>equinox</code>-styled API, then just use <code>equinox</code>. There isn’t a lot <code>flax</code> does especially better that’s hard to replicate with <code>equinox</code>. Plus, having little to no abstraction makes implementing things in <code>equinox</code> much easier and faster.</p><p>Right now, a lot of the <code>JAX</code> ecosystem is designed around <code>flax</code>. <code>equinox</code>, because it fundamentally interfaces with <code>PyTree</code>s is cross-compatible with all libraries, however you do have to do a little <code>eqx.partition</code>-ing and <code>filter</code>-ing, which can be a bit annoying.</p><p>I want to change the status quo. It should be the other way around - <code>equinox</code> should have first class support everywhere. Considering its popularity, I think this decision would objectively make thigns easier for the vast majority of serious <code>JAX</code> users and big codebases.</p><p>I know this is a controversial opinion simply because a lot of resources have been poured into <code>flax</code> - But this is classic <a href="https://en.wikipedia.org/wiki/Sunk_cost">sunk-cost fallacy</a>. <code>equinox</code> just does it better, in the way a <code>JAX</code> framework should always have been like. It may not be perfect, but its better than the alternatives by a mile.</p><figure><p><img src="https://neel04.github.io/my-website/blog/pytorch_rant/eqxvsflax.png"></p><figcaption><code>equinox</code> vs. <code>flax</code>: as neatly summarized in the <a href="https://neel04.github.io/my-website/blog/pytorch_rant/url">equinox docs</a>.</figcaption></figure><p>It’s good to see that maintainers of the <code>JAX</code> ecosystem are realizing the popularity of <code>equinox</code> and adjusting accordingly - however, I’d love to see a bit more love officially from Google and the <code>flax</code> team as well.</p><p>If you want to try out <code>JAX</code> - it’s not even a question. Use <code>equinox</code>. You’ll thank me.</p><blockquote><p>“I’ve been using <code>equinox</code> for a few months now and I’ve never felt better. I have more energy. My skin is clearer. My eye sight has improved.”
– Me</p></blockquote><h3 id="sharp-edges">Sharp edges</h3><p>Due to some of the API design decisions and <code>XLA</code> restrictions, <code>JAX</code> has some “sharp edges” that you should be careful of. The well-written documentation explains this very concisely:</p><p><a href="https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html">Common Gotchas in Jax.</a></p><p>So go give that a read atleast once before using <code>JAX</code>. It’ll save you a lot of time and energy (as RTFM-ing always does).</p><h2 id="conclusion">Conclusion</h2><p>This blogpost was to correct the often-parotted myth that <code>PyTorch</code> is simply the best for any real research workloads - especially on GPUs. That simply isn’t the case anymore.</p><p>Infact, I’d go as far as to argue that porting all <code>Torch</code> code to <code>JAX</code> would be <em>immensely</em> beneficial to the field as a whole. These are not minor features - having autoparallelization, reproducibility, a clean functional API etc. would be a godsend for a lot of research codebases.</p><p>So if you want to make this field a little bit better, consider rewriting your codebases in <code>JAX</code>.</p><p>Shoutout to <a href="https://kidger.site/">Patrick Kidger</a> as well for developing <code>equinox</code>. If you’re coming from <code>PyTorch</code>, I cannot recommend it enough!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LLM and Bug Finding: Insights from a $2M Winning Team in the White House's AIxCC (147 pts)]]></title>
            <link>https://team-atlanta.github.io/blog/post-atl/</link>
            <guid>41269791</guid>
            <pubDate>Fri, 16 Aug 2024 19:56:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://team-atlanta.github.io/blog/post-atl/">https://team-atlanta.github.io/blog/post-atl/</a>, See on <a href="https://news.ycombinator.com/item?id=41269791">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Hello, world! We are <em>Team Atlanta</em>, the minds behind Atlantis, our innovative
AI-driven cybersecurity solution competing in the prestigious
<a href="https://aicyberchallenge.com/" target="_blank">DARPA AIxCC</a>
.</p><p><a href="https://team-atlanta.github.io/authors/">Our team</a>
is a collaborative powerhouse made up of six leading institutions:
<a href="https://www.gatech.edu/" target="_blank">Georgia Tech</a>
,
<a href="https://www.gtri.gatech.edu/" target="_blank">GTRI</a>
,
<a href="https://research.samsung.com/" target="_blank">Samsung Research</a>
,
<a href="https://sra.samsung.com/" target="_blank">Samsung Research America</a>
,
<a href="https://www.kaist.ac.kr/en/" target="_blank">KAIST</a>
, and
<a href="https://www.postech.ac.kr/" target="_blank">POSTECH</a>
.
Each of these organizations is led by Georgia Tech alumni,
and includes past winners of prestigious hacking competitions
such as DEF CON CTF, Pwn2Own and kernelCTF.</p><p>For the past several months, we have been diligently preparing for this competition,
combining our expertise in AI, cybersecurity,
and software engineering.
Last week, we proudly competed in the AIxCC Semifinals,
showcasing our hard work and dedication
to advancing cybersecurity through artificial intelligence.</p><h2 id="the-journey-begins">The Journey Begins</h2><p>When AIxCC was announced <a href="https://www.whitehouse.gov/briefing-room/statements-releases/2023/08/09/biden-harris-administration-launches-artificial-intelligence-cyber-challenge-to-protect-americas-critical-software/" target="_blank">last year</a>
,
we quickly assembled a team of friends,
including <a href="https://www.zellic.io/" target="_blank">Zellic</a>
and <a href="https://gts3.org/" target="_blank">SSLab</a>
.
At that time,
much was uncertain;
details about the game format,
scoring rubric,
proof-of-vulnerability (PoV),
sanitizers, harnesses, supported programming languages,
and proof-of-understanding (PoU) were all unclear.
Our team, however, started preparing for the competition from last October.</p><p>Many of our team members previously participated in the
<a href="https://www.darpa.mil/program/cyber-grand-challenge" target="_blank">DARPA Cyber Grand Challenge (CGC)</a>
as part of <a href="https://en.wikipedia.org/wiki/2016_Cyber_Grand_Challenge" target="_blank">Crspy</a>
,
where we were responsible for bug finding and exploitation generation.
DARPA CGC was an ambitious endeavor
that sparked numerous innovative research directions afterward.
However, the competition was not without its challenges,
particularly due to the <em>gamification</em> of the event;
the scoring metrics and rules significantly influenced <a href="https://free.eol.cn/edu_net/edudown/spkt/zhangchao.pdf#page=34" target="_blank">the outcomes</a>
.
In the end, the competing Cyber Reasoning Systems (CRS) that focused on operating reactively–prioritizing the availability score over fixing bugs–
tended to score higher, as exploitation proved to be far more difficult than patching.</p><p>Aware of <a href="https://aicyberchallenge.com/rules/" target="_blank">the gamification issues</a>
from CGC,
we anticipated that to excel in AIxCC
our CRS should leverage AI, particularly LLMs, aggressively in various depths and levels
of the CRS pipelines.
With this in mind, we strategically chose to focus our efforts on two key directions:</p><ol><li><p><strong>Static Analysis.</strong> To encourage the use of LLMs and set AIxCC apart from CGC,
we anticipated that
AIxCC would strongly advocate for the adoption of <em>static analysis</em> while
steering away from the dominant use of <em>fuzzing</em><sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.
It’s important to note
that finding bugs is quite different from finding crash- or bug-triggering
inputs. The latter offers a clear advantage in objectively and autonomously
verifying the discovered bug,
but it has a much narrower scope compared to the former.
In practice, the <em>triggering</em> aspect, also known as the reachability problem, is
a significantly more challenging and crucial issue to address,
where <em>dynamic tools</em> like fuzzing have a clear edge.</p></li><li><p><strong>Fine-tuning LLMs for Source Code.</strong> Specialization is always an advantage
when possible. Given that each CRS will likely need to support more than 10
programming languages during the competition, we decided to fine-tune both
in-house and open-source models for analyzing code.
This approach is conceptually similar to
<a href="https://paperswithcode.com/dataset/commitpack" target="_blank">commitPack</a>
,
but focuses on
commits related to bugs like their fixes, bug-introducing commits, descriptions,
and public exploits, if available.
Our expectation was that training with this data would enable
the fine-tuned LLM to reason about security bugs,
their fixes, and likely input corpus,
more effectively than the
foundational model.</p></li></ol><p>We quickly realized that to pursue these directions effectively,
we first needed a dataset: a benchmark.
Our team divided tasks into three areas: 1) static analysis
using LLM prompts/agents, 2) developing a C benchmark from sources like CGC and
OSS-Fuzz, and 3) collecting a training dataset pairing CVEs with patches and PoCs for
open-source projects to fine-tune our in-house code model at Samsung or to
leverage open-source LLMs.</p><p>Remarkably, within 4-5 months, we accomplished all three goals,
and our LLM-based Cyber Reasoning System (CRS), dubbed Skynet,
performed surprisingly well on our benchmark,
and fine-tuning on a smaller dataset shows some promises like in python.</p><p>Time flew by. The cold winter of 2023 ended, and we found ourselves in the new
year of 2024.
I vividly remember that around this time, our dear friends from
Zellic left our team to pursue the Small Business Innovation Research (SBIR) track,
which DARPA supports with $1 million for the competition.
Unfortunately, Georgia Tech and Samsung were not eligible for this award.</p><h2 id="kick-off-with-surprises">Kick-off with Surprises!</h2><p><img title="image title" loading="lazy" decoding="async" width="600" height="390" src="https://team-atlanta.github.io/images/blog/atl/timeline_hu27eb7f2762e238941514cfe06aa31894_2087274_600x0_resize_q100_lanczos_3.png" alt="alter-text" onerror="this.onerror=&quot;null&quot;,this.src=&quot;/images/blog/atl/timeline_hu27eb7f2762e238941514cfe06aa31894_2087274_600x0_resize_q100_lanczos_3.png&quot;"></p><p>At the kick-off event on March 29th, AIxCC unveiled the first challenge project:
the Linux kernel, along with an example vulnerability,
<a href="https://nvd.nist.gov/vuln/detail/CVE-2021-43267" target="_blank">CVE-2021-43267</a>
.
This bug is <a href="https://www.sentinelone.com/labs/tipc-remote-linux-kernel-heap-overflow-allows-arbitrary-code-execution/" target="_blank">well documented</a>
,
and its PoC exploit is <a href="https://github.com/zzhacked/CVE-2021-43267" target="_blank">publicly available</a>
,
making it an excellent example to work on.</p><p>What makes this bug even more intriguing is the story behind it.
A security researcher audited the Linux kernel source code using
<a href="https://codeql.github.com/" target="_blank">CodeQL</a>
.
Specifically, the researcher was searching
for instances where 16-bit <code>size</code> parameters are passed to the <code>kmalloc()</code>
function for memory allocation,
using a dataflow-based CodeQL query.
The intuition was that a 16-bit <code>size</code> parameter
could easily lead to an <em>integer overflow</em> when accessing the allocated object.
However, the discovered bug was not caused by an integer overflow,
but an out-of-bound heap overflow due to a missing sanity check on the <code>size</code> and related inputs.</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>static</span> <span>bool</span> <span>tipc_crypto_key_rcv</span>(<span>struct</span> tipc_crypto <span>*</span>rx, <span>struct</span> tipc_msg <span>*</span>hdr)
</span></span><span><span>{
</span></span><span><span>	<span>struct</span> tipc_crypto <span>*</span>tx <span>=</span> <span>tipc_net</span>(rx<span>-&gt;</span>net)<span>-&gt;</span>crypto_tx;
</span></span><span><span>	<span>struct</span> tipc_aead_key <span>*</span>skey <span>=</span> NULL;
</span></span><span><span>	u16 key_gen <span>=</span> <span>msg_key_gen</span>(hdr);
</span></span><span><span>	u16 size <span>=</span> <span>msg_data_sz</span>(hdr);
</span></span><span><span>	u8 <span>*</span>data <span>=</span> <span>msg_data</span>(hdr);
</span></span><span><span>
</span></span><span><span>  ...
</span></span><span><span>
</span></span><span><span>	<span>/* Allocate memory for the key */</span>
</span></span><span><span>	skey <span>=</span> <span>kmalloc</span>(size, GFP_ATOMIC);
</span></span><span><span>	<span>if</span> (<span>unlikely</span>(<span>!</span>skey)) {
</span></span><span><span>		<span>pr_err</span>(<span>"%s: unable to allocate memory for skey</span><span>\n</span><span>"</span>, rx<span>-&gt;</span>name);
</span></span><span><span>		<span>goto</span> exit;
</span></span><span><span>	}
</span></span><span><span>
</span></span><span><span>	<span>/* Copy key from msg data */</span>
</span></span><span><span>	skey<span>-&gt;</span>keylen <span>=</span> <span>ntohl</span>(<span>*</span>((__be32 <span>*</span>)(data <span>+</span> TIPC_AEAD_ALG_NAME)));
</span></span><span><span>	<span>memcpy</span>(skey<span>-&gt;</span>alg_name, data, TIPC_AEAD_ALG_NAME);
</span></span><span><span>	<span>memcpy</span>(skey<span>-&gt;</span>key, data <span>+</span> TIPC_AEAD_ALG_NAME <span>+</span> <span>sizeof</span>(__be32),
</span></span><span><span>	       skey<span>-&gt;</span>keylen);
</span></span></code></pre></div><p>The <code>skey</code> was allocated with a <code>size</code> based on the user-provided <code>hdr</code>,
but <code>skey-&gt;key</code> was copied up to <code>skey-&gt;keylen</code>,
which was also user-controlled and could therefore be inconsistent with <code>size</code>.
Unfortunately, the kernel did not
perform a sanity check on these two parameters,
causing an out-of-boundary access.</p><div><pre tabindex="0"><code data-lang="diff"><span><span>commit fa40d9734a57bcbfa79a280189799f76c88f7bb0
</span></span><span><span>Author: Max VA &lt;maxv@sentinelone.com&gt;
</span></span><span><span>Date:   Mon Oct 25 17:31:53 2021 +0200
</span></span><span><span>
</span></span><span><span>    tipc: fix size validations for the MSG_CRYPTO type
</span></span><span><span>
</span></span><span><span>    The function tipc_crypto_key_rcv is used to parse MSG_CRYPTO messages
</span></span><span><span>    to receive keys from other nodes in the cluster in order to decrypt any
</span></span><span><span>    further messages from them.
</span></span><span><span>    This patch verifies that any supplied sizes in the message body are
</span></span><span><span>    valid for the received message.
</span></span><span><span>
</span></span><span><span>diff --git a/net/tipc/crypto.c b/net/tipc/crypto.c
</span></span><span><span>index c9391d38de85..dc60c32bb70d 100644
</span></span><span><span><span>--- a/net/tipc/crypto.c
</span></span></span><span><span><span></span><span>+++ b/net/tipc/crypto.c
</span></span></span><span><span><span></span><span>@@ -2285,43 +2285,53 @@ static bool tipc_crypto_key_rcv(struct tipc_crypto *rx, struct tipc_msg *hdr)
</span></span></span><span><span><span></span> 	u16 key_gen = msg_key_gen(hdr);
</span></span><span><span> 	u16 size = msg_data_sz(hdr);
</span></span><span><span> 	u8 *data = msg_data(hdr);
</span></span><span><span><span>+	unsigned int keylen;
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+	/* Verify whether the size can exist in the packet */
</span></span></span><span><span><span>+	if (unlikely(size &lt; sizeof(struct tipc_aead_key) + TIPC_AEAD_KEYLEN_MIN)) {
</span></span></span><span><span><span>+		pr_debug("%s: message data size is too small\n", rx-&gt;name);
</span></span></span><span><span><span>+		goto exit;
</span></span></span><span><span><span>+	}
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+	keylen = ntohl(*((__be32 *)(data + TIPC_AEAD_ALG_NAME)));
</span></span></span><span><span><span>+
</span></span></span><span><span><span>+	/* Verify the supplied size values */
</span></span></span><span><span><span>+	if (unlikely(size != keylen + sizeof(struct tipc_aead_key) ||
</span></span></span><span><span><span>+		     keylen &gt; TIPC_AEAD_KEY_SIZE_MAX)) {
</span></span></span><span><span><span>+		pr_debug("%s: invalid MSG_CRYPTO key size\n", rx-&gt;name);
</span></span></span><span><span><span>+		goto exit;
</span></span></span><span><span><span>+	}
</span></span></span><span><span><span></span> 
</span></span></code></pre></div><p>Two checks were added to fix this bug:
verifying that <code>size</code> is greater than the
minimum key size, and ensuring that <code>keylen</code> is consistent with <code>size</code>,
thereby preventing access beyond the allocated object.</p><h2 id="misunderstanding-1-pov">Misunderstanding 1: PoV</h2><p>Given a massive Linux repository (yes, 20 million lines of code),
where should we start?
The LLM approach is all about asking the right questions,
also known as prompt engineering.
We utilized various techniques like Chain-of-Thought (CoT)
and Tree-of-Thoughts (ToT),
and were exploring Retrieval Augmented Generation (RAG)
to quickly identify known 1-day bugs.</p><p>At that time, context size was limited;
the most advanced model, <code>gpt-3.5 turbo</code>
(yes, pre-<code>gpt-4</code> era) from OpenAI, supported 16k tokens,
making it crucial to ask the right question!
We initially tried identifying potentially vulnerable
code snippets using a range of static analysis tools,
including CodeQL, Semgrep and various tools from academic publications,
and then filtered the results with LLMs.
We even considered diffing the upstream Linux kernel
against the provided repository,
so that our CRS can look at the modified part of the code first.</p><p>We were confident our decision; to promote the use of AI tools,
the AIxCC organizers
would design the competition in a way that allows a single CRS codebase to
explore any code repository using 10+ programming languages and their
combinations.</p><p>Ah, around that time,
Google had just announced <code>gemini-pro</code>
with an impressive 128k context and the potential to support 1 million tokens!
Meanwhile, <code>gpt-4</code>
introduced a game-changing feature called function calling,
which allows the LLM to select which callback to use and integrate the results back into the prompt
at runtime. We felt that everything was evolving favorably for our CRS to adopt
these cutting-edge techniques.</p><p>However, PoV turned out to mean <em>bug-triggering input</em>
or a crashing input.
To demonstrate the existence of a bug,
each CRS needed to formulate an input
that the referee could quickly verify.
While this approach is
straightforward and objective for the competition,
it significantly discourages the adoption of LLMs in finding bugs.
Our team quickly realized
that we needed to pivot to the dynamic approaches like fuzzing
for the competition.</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>void</span> <span>tipc_trigger</span>(<span>uint8_t</span> <span>*</span>smashbuf, <span>uint32_t</span> smashlen, <span>int</span> seqno) {
</span></span><span><span>    <span>uint8_t</span> pkt[<span>0x1000</span>];
</span></span><span><span>    <span>uint32_t</span> w0, w1, w2, w3, w4, w5;
</span></span><span><span>
</span></span><span><span>    w0 <span>=</span> <span>hdr_version</span>(TIPC_VERSION);
</span></span><span><span>    w0 <span>|=</span> <span>hdr_size</span>(<span>6</span>);
</span></span><span><span>    w0 <span>|=</span> <span>hdr_user</span>(MSG_CRYPTO);
</span></span><span><span>    w0 <span>|=</span> <span>hdr_msg_size</span>(<span>24</span> <span>+</span> <span>36</span> <span>+</span> KEY_SIZE);
</span></span><span><span>    w1 <span>=</span> <span>0</span>;
</span></span><span><span>    w2 <span>=</span> seqno;
</span></span><span><span>    w3 <span>=</span> NODE_ID;
</span></span><span><span>    w4 <span>=</span> <span>0</span>;
</span></span><span><span>    w5 <span>=</span> <span>0</span>;
</span></span><span><span>
</span></span><span><span>    <span>memset</span>(pkt, <span>0</span>, <span>sizeof</span>(pkt));
</span></span><span><span>    <span>gen_tipc_hdr</span>(pkt, w0, w1, w2, w3, w4, w5);
</span></span><span><span>
</span></span><span><span>    <span>memcpy</span>(pkt<span>+</span><span>24</span>, <span>"HAXX"</span>, <span>4</span>);
</span></span><span><span>    <span>*</span>(<span>uint32_t</span><span>*</span>)(pkt<span>+</span><span>24</span><span>+</span><span>32</span>) <span>=</span> <span>be32</span>(KEY_SIZE <span>+</span> SMASH_SIZE <span>+</span> smashlen); <span>// &lt;- (1)
</span></span></span><span><span><span></span>    <span>memset</span>(pkt<span>+</span><span>24</span><span>+</span><span>36</span>, <span>'C'</span>, KEY_SIZE);
</span></span><span><span>    <span>memset</span>(pkt<span>+</span><span>24</span><span>+</span><span>36</span><span>+</span>KEY_SIZE, <span>'D'</span>, SMASH_SIZE);
</span></span><span><span>    <span>memcpy</span>(pkt<span>+</span><span>24</span><span>+</span><span>36</span><span>+</span>KEY_SIZE <span>+</span> SMASH_SIZE, smashbuf, smashlen);
</span></span><span><span>    <span>tipc_send</span>(pkt, <span>sizeof</span>(pkt));
</span></span><span><span>}
</span></span></code></pre></div><p>Formulating a bug-triggering input, including ensuring its reachability,
is a far more challenging task than simply spotting buggy code in the repository.
The strength of fuzzing, perhaps the opposite of a sophisticated LLM,
is that once a bug is found,
you almost always have a bug-triggering input.</p><p>In CVE-2021-43267, using CodeQL and auditing,
one could identify this bug, but triggering it is an entirely different challenge,
not to mention <a href="https://github.com/zzhacked/CVE-2021-43267/blob/main/poc.py" target="_blank">exploiting it</a>
.
For example,
TIPC must be properly set up first, and the <code>keylen</code> needs to be precisely
crafted in (1) to trigger the bug.</p><h2 id="misunderstanding-2-harnesses">Misunderstanding 2. Harnesses</h2><p>Sorry, what’s the input needed to trigger CVE-2021-43267? even with a fuzzer?<br>To fuzz the Linux <em>kernel</em>,
we needed a <em>user</em> program
that calls a sequence of system calls
with various arguments.
Considering the Linux kernel has over <a href="https://filippo.io/linux-syscall-table/" target="_blank">400 system calls</a>
to explore, this was far
from ideal for a competition setting.</p><p>We initially assumed that harnesses and test cases would be provided to indicate
which parts of the Linux kernel should be checked for bugs.
To tackle this,
we implemented and adopted various versions of Linux kernel fuzzers,
including a custom kernel syscall fuzzer with <code>kcov</code> and <code>kcmp</code>,
and also utilized the most popular Linux fuzzer, <a href="https://github.com/google/syzkaller" target="_blank">Syzkaller</a>
.
However, our focus remained on determining which sequences of system calls
to test, using syscall traces and static analysis of the provided program,
and then correctly formulating an end-to-end userspace program to trigger the bug.</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>/***
</span></span></span><span><span><span> * Blob begins with a 4 byte command count
</span></span></span><span><span><span> * [4-bytes command count]
</span></span></span><span><span><span> * Currently there are two commands:
</span></span></span><span><span><span> *  0 - send a packet blob
</span></span></span><span><span><span> *      [4-bytes size][4-bytes send flags][size-bytes packet data]
</span></span></span><span><span><span> *  1 - send a netlink packet
</span></span></span><span><span><span> *      [4-bytes Message Type][4-bytes Message Flags][4-bytes Netlink Protocol][4-bytes size][size bytes data]
</span></span></span><span><span><span> * blob_size MUST be a trusted value
</span></span></span><span><span><span> */</span>
</span></span><span><span><span>int</span> <span>harness</span>( <span>uint8_t</span> <span>*</span>blob, <span>uint32_t</span> blob_size)
</span></span><span><span>{ ... }
</span></span></code></pre></div><p><a href="https://github.com/aixcc-public/challenge-001-exemplar/" target="_blank">The Linux Kernel CP</a>
was announced in April and came with a harness,
<a href="https://github.com/aixcc-public/challenge-001-exemplar-source/blob/main/test_harnesses/linux_test_harness.c" target="_blank">linux_test_harness.c</a>
.
This announcement was full of surprises;
the program’s structure was provided by the harness,
which is alas what we primarily focused on,
and the <a href="https://github.com/aixcc-public/challenge-001-exemplar/blob/main/exemplar_only/blobs/sample_solve.bin" target="_blank"><code>blob</code></a>
needed to be fed to the harness in a way that triggers the bug.
The types of system calls we could interact with
were limited by the harness,
and our task was to find the right data input
that would <em>lead the harness</em>
to invoke the necessary sequence of system calls with the correct parameters.
In other words, we needed to understand the harness first
before dealing with the Linux kernel bugs.</p><p>Later, the Jenkins harness was announced, and more surprisingly,
it was a fuzz driver (often called a <em>fuzzing harness</em>),
a standalone program designed to
invoke APIs for fuzz testing.
In May, a new CP, called <code>mock-cp</code> (a userspace program),
was introduced along with a new harness format, which was simply a
shell script executing a CP binary with the provided input.
Such diverse formats got us thinking that
our CRS should adopt LLM to figure out the structure of the programs
and CPs first; like how to compile, how to correctly run, etc.</p><p>By June, the harness format was officially established -
surprisingly, yet not entirely unexpected:
<a href="https://llvm.org/docs/LibFuzzer.html" target="_blank">libfuzzer</a>
for
userspace programs (<code>mock-cp</code> and Nginx),
<a href="https://github.com/CodeIntelligenceTesting/jazzer" target="_blank">jazzer</a>
for Java programs
(Jenkins), while retaining the <code>blob</code>-based harness for the Linux kernel.
We continually updated our CRS to adapt to these changes,
but many of these decisions rendered our LLM-based components unnecessary.
This decision, however,
greatly helped all the participating teams
by reducing the engineering time needed for game operation.
Unfortunately, we were too proactive in reacting to these changes and ended up
wasting some engineering time as a result 😊.</p><p>A harness’s role is crucial in the AIxCC competition; it sets the context for
the CRS to trigger the bug and serves as a key factor in adjusting the
difficulty of bug discovery. Therefore, it’s important to strike a balance:
it should provide enough detail to relieve the CRS from unnecessary burdens,
allowing it to focus on bug finding, but without revealing too much information
about the bugs.</p><h2 id="misunderstanding-3-proof-of-understanding">Misunderstanding 3. Proof-of-understanding</h2><p>Unlike CGC, which treated the PoV (a proof-of-concept exploit)
as sufficient proof of bug discovery,
AIxCC required additional information—specifically, the bug type as classified by
<a href="https://cwe.mitre.org/top25/archive/2023/2023_kev_list.html" target="_blank">CWE</a>
,
to be provided along with the PoV.
This was an interesting decision, as AIxCC required
CRS to find bugs in the source code,
whereas CGC focused on discovering bugs in binaries.</p><p>Our team spent a lot of time brainstorming
how to accurately identify CWE categories,
primarily by using LLM prompts that leverage crashing inputs,
sanitizer reports, related code snippets, outputs from static analyzers, and more.
However, the notion of CWEs can be ambiguous when used as a scoring
mechanism for the competition.
For instance, should CVE-2021-43267 be classified
as (1) CWE-122 (Heap-based Buffer Overflow), (2) CWE-787 (Out-of-bounds Write),
or (3) CWE-20 (Improper Input Validation)?
The first two describe the symptoms
caused by the bug, while the third identifies the root cause, as the patch for
this bug involved adding input validations.</p><p>In the end, AIxCC shifted the focus from PoV to identifying the bug-introducing
commit (BIC) - the specific hash or commit ID in the git repository.
Combined with
the fuzzing harness and PoV, the CRS’s task was to run the fuzzing harness and
perform a <a href="https://git-scm.com/docs/git-bisect" target="_blank"><code>git-bisect</code></a>
to pinpoint
the BIC in the repository.
We did a simple bisecting in the semifinal but lots of improvement
required to be functional for the final event.</p><h2 id="misunderstanding-4-semantic-patching">Misunderstanding 4. Semantic patching</h2><p>Patching is one of the most intriguing aspects of AIxCC. In CGC, the PoV was
typically a simple exploit (like arbitrary read/write/execute),
so mitigation strategies (e.g., adding a stack canary) could effectively thwart the PoV.
In fact, patches could be applied <em>without even knowing</em> the specific bug;
for example,
adding a stack canary to all functions in a binary
can prevent buffer overflow exploits
that might exist in some places.</p><p>The challenge in CGC was that the focus was on the binary, and the organizers
introduced rules such as a minimum number of bytes changed and performance
overheads added to the scoring rubric (e.g., instrumenting all memory accesses
to prevent out-of-bound errors). These rules were designed to encourage
competitors to generate correct patches. Ultimately, this forced CRS to weigh
the pros and cons of universal patching, as both exploiting and patching were
extremely difficult during the CGC era,
resulting in a trade-off between losing
points from exploitation versus losing points from patching and availability.</p><p>In AIxCC, the CRS must generate a semantically correct patch that not only fixes
the identified PoV but also maintains the functional correctness of the CP. This
is a tricky task, as <em>correctness</em> cannot be formally defined for CRS - some
functional changes may be acceptable, while others may not, depending on the
code owner’s criteria.
One approach to addressing this ambiguity is to provide
test code to see if the patch passes the provided, so-called public tests.
However, CRS must still account for private tests set by the organizers.</p><p>In the semifinals, our CRS submitted a patch that successfully prevented the
crash and passed the public tests given to us during the competition,
but was ultimately rejected in the private
functionality tests.
We’re eager to learn more about the bug and the patch!</p><h2 id="misunderstanding-5-sanitizers">Misunderstanding 5: Sanitizers</h2><p>The concept of sanitizers was unclear to our team until we encountered
their concrete implementation
for memory-safe languages like Java, and more
specifically, for Jenkins, a web application written in Java!
The role of a sanitizer, essentially a bug oracle, is to determine whether a bug has been
correctly triggered.</p><p>In memory-unsafe languages like C, standard tools like ASAN and UBSAN can serve
as sanitizers to catch memory-safety issues with low or no false positives
(e.g., out-of-bound accesses should never occur).
However, in memory-safe languages,
things get trickier.
For example, is executing a command a legitimate
feature in CI tools like Jenkins,
or should it be treated as a command injection (CWE-78)?</p><p>In other words, sanitizers are more CP-specific
rather than programming language-specific;
each CP needs to provide custom sanitizers
(e.g., <a href="https://www.code-intelligence.com/blog/java-fuzzing-with-jazzer" target="_blank">path traversal sanitizers</a>
).</p><p>Our team initially spent time working on finding web-related bugs like XSS or
CSRF in Jenkins - areas where we believed LLMs could excel in seed generation.
However, once AIxCC announced
that the sanitizers for Java would be
<a href="https://github.com/CodeIntelligenceTesting/jazzer" target="_blank">jazzer</a>
sanitizers,
we decided to shift our focus more towards standard jazzer-based fuzzing.</p><h2 id="semifinal">Semifinal</h2><p>Our team dedicated most of our engineering effort to building a CRS for the
Linux Kernel, and we’re proud that our CRS was able to find and correctly
generate a patch for CVE-2021-43267 in the end.
However, during the semifinal,
it appeared that only <em>one</em> harness was provided, similar to the exemplar, and
none of the CRSes functioned properly for the Linux Kernel.
We loved to know more about how our Linux CRS functioned
during the competition.</p><p><img title="image title" loading="lazy" decoding="async" width="600" height="404" src="https://team-atlanta.github.io/images/blog/atl/dashboard_hucdfac242ccfb260b6c8aa0c492f17fbb_248513_600x0_resize_q100_lanczos_3.png" alt="alter-text" onerror="this.onerror=&quot;null&quot;,this.src=&quot;/images/blog/atl/dashboard_hucdfac242ccfb260b6c8aa0c492f17fbb_248513_600x0_resize_q100_lanczos_3.png&quot;"></p><p>In summary, our CRS earned a total of six achievement badges: five for
discovering bugs (i.e., first bloods) and one for a patch.</p><p><img title="image title" loading="lazy" decoding="async" width="600" height="333" src="https://team-atlanta.github.io/images/blog/atl/achievements_hu5072cc1c531c3d4ed879245bc9c46aa6_852847_600x0_resize_q100_lanczos_3.png" alt="alter-text" onerror="this.onerror=&quot;null&quot;,this.src=&quot;/images/blog/atl/achievements_hu5072cc1c531c3d4ed879245bc9c46aa6_852847_600x0_resize_q100_lanczos_3.png&quot;"></p><p>Our CRS found several unique bugs, which we will describe in a later blog post!</p><p>Aside from the known CPs—Linux (C), Jenkins (Java), and Nginx (C) - there were new
CPs introduced, namely Tika (Java) and sqlite3 (C).
Our CRS performed relatively
well on sqlite3, but unfortunately,
our Java CRS struggled with Tika.
We would love to learn more about what happened during the competition.
Tika, a popular file format parser,
has many unique features, such as recursively parsing
embedded objects,
which may have contributed to the challenges we faced.</p><h2 id="looking-ahead-to-the-aixcc-final-">Looking Ahead to the AIxCC Final 🎉</h2><figure role="group" aria-describedby="caption-AIxCC Finalists"><img title="image title" loading="lazy" decoding="async" width="600" height="331" src="https://team-atlanta.github.io/images/blog/atl/finalists_hua191f10a8c6185b27f399163513ba79a_538686_600x0_resize_q100_lanczos_3.png" alt="alter-text" onerror="this.onerror=&quot;null&quot;,this.src=&quot;/images/blog/atl/finalists_hua191f10a8c6185b27f399163513ba79a_538686_600x0_resize_q100_lanczos_3.png&quot;"><figcaption id="caption-AIxCC Finalists">AIxCC Finalists</figcaption></figure><p>We are thrilled that our team has advanced to the AIxCC finals! We have several ideas that could make the competition even more exciting:</p><ul><li><p><strong>Different execution times based on code complexity.</strong><br>The Linux kernel, with its 6,000 files and 20 million lines of code, requires
substantial time for bookkeeping like building, bootstrapping, and bisecting.
Compared to smaller programs (e.g., 200k in Tika), it would be beneficial to
allocate more time for CRSes to navigate such complex codebases.</p></li><li><p><strong>More programming languages and their combinations.</strong><br>Top candidates include Python, Rust, and JavaScript/HTML, along with
combinations like JNI (C) in Java or Rust device drivers in the Linux kernel.
These would offer a more comprehensive evaluation of CRS capabilities in
diverse and challenging settings where CRS is most needed.</p></li><li><p><strong>Standardized execution environments.</strong><br>Standardizing the compiler (e.g., <code>clang-18</code>), runtime (e.g., JVM version),
and base Docker image ahead of time would help teams explore more advanced
techniques, such as LLM-based instrumentation, in a controlled environment.</p></li><li><p><strong>Improved visualization during the competition.</strong><br>While the AIxCC village was impressively set up, competing teams and
participants had limited visibility into the competition’s progress and how
each CRS was functioning. To capture more attention from <a href="https://www.reddit.com/r/Defcon/comments/1eta3tj/was_the_aixcc_village_disappointing_to_anyone_else/" target="_blank">the DEF CON audience</a>
,
it would be beneficial to expose more technical information during the
competition - such as showing current prompts of each CRS in turn, their CPU
usage, or even stdout from CRSes (for fun), along with explanations of the
progress.</p></li></ul><p>With our baseline system up and running, it’s time for our team to explore the
possibility of incorporating LLMs or ML techniques into our CRS workflow. If
you’re passionate about AIxCC and as committed to the competition as we are,
feel free to <a href="mailto:aixcc-atl@googlegroups.com">contact us</a>
!</p><p>We are fortunate to have support from generous sponsors like GT/GTRI, Samsung,
and KAIST/NYU. If your company is interested in sponsoring our team, we would be
happy to discuss further!</p><p>Last but not least, we want to extend our heartfelt thanks to the AIxCC
organizers for launching the competition we’ve been craving. Hackers thrive on
competition-driven innovation, and this has been an exciting opportunity for all
of us.</p><div><p><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/FkJimGWJYgw?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" title="YouTube video"></iframe></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Family poisoned after using AI-generated mushroom identification book (232 pts)]]></title>
            <link>https://old.reddit.com/r/LegalAdviceUK/comments/1etko9h/family_poisoned_after_using_aigenerated_mushroom/</link>
            <guid>41269514</guid>
            <pubDate>Fri, 16 Aug 2024 19:24:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/LegalAdviceUK/comments/1etko9h/family_poisoned_after_using_aigenerated_mushroom/">https://old.reddit.com/r/LegalAdviceUK/comments/1etko9h/family_poisoned_after_using_aigenerated_mushroom/</a>, See on <a href="https://news.ycombinator.com/item?id=41269514">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong>EDIT: I have not stated the name of the online marketplace. Assumptions are being made in the comments, which I am neither confirming nor denying.</strong></p>

<p>My entire family was in hospital last week after accidentally consuming poisonous mushrooms.</p>

<p>My wife purchased a book from a major online retailer for my birthday. The book is entitled something similar to: "Mushrooms UK: A Guide to Harvesting Safe and Edible Mushrooms."</p>

<p>It comes with pictures of the mushrooms to help identify each one.</p>

<p>Unfortunately, the book in question was not accurate. A closer investigation reveals that the images of mushrooms are AI generated, and we have now found two instances of text where a sentence ends and is followed up with a random questions or fourth-wall breaking statements.</p>

<p>For example:</p>

<p><em>"In conclusion, morels are delicious mushrooms which can be consumed from August to the end of Summer. Let me know if there is anything else I can help you with."</em></p>

<p>The online retailer have instructed me to return the book and they will refund it. The book has been removed from sale from the online retailer, however, it appears there are dozens more in a similar style.</p>

<p>1.) Should I return this book to the retailer? I'm concerned I would lose any evidence I have if I return it. The purchase has already disappeared from my online account. It simply looks like it doesn't exist anymore. I still have the email.</p>

<p>2.) Are my family entitled to any compensation for my son and my wife's lost time at work? As well as the sickness they experienced?</p>

<p>3.) Can I report the creation of this book to the police as a crime?</p>

<p><strong>Just for clarity: We did not know it was AI-generated when we bought it! This was not disclosed on the website!</strong></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[VanillaJSX.com (480 pts)]]></title>
            <link>https://vanillajsx.com/</link>
            <guid>41269321</guid>
            <pubDate>Fri, 16 Aug 2024 19:01:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vanillajsx.com/">https://vanillajsx.com/</a>, See on <a href="https://news.ycombinator.com/item?id=41269321">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="root"><p>What if JSX just returned DOM elements?</p><div data-sample="sample1"><p><a target="_blank" href="https://github.com/sdegutis/vanillajsx.com/blob/main/site/samples/sample1.tsx">View source</a></p><pre><code>export default function ClickMe() {
  let i = 0;
  const el = &lt;button&gt;Click me&lt;/button&gt; as HTMLButtonElement;
  el.onclick = (e) =&gt; {
    el.textContent = `Clicked ${++i} times`;
  };
  return el;
}
</code></pre></div><p>Would they be reusable?</p><p>Could they keep their own state?</p><div data-sample="sample2"><p><a target="_blank" href="https://github.com/sdegutis/vanillajsx.com/blob/main/site/samples/sample2.tsx">View source</a></p><pre><code>import ClickMe from "./sample1.js";

export default () =&gt; &lt;&gt;
  &lt;p&gt;&lt;ClickMe /&gt;&lt;/p&gt;
  &lt;p&gt;&lt;ClickMe /&gt;&lt;/p&gt;
  &lt;p&gt;&lt;ClickMe /&gt;&lt;/p&gt;
&lt;/&gt;;
</code></pre></div><p>How would they work together?</p><p>Could they create an interactive DOM tree?</p><div data-sample="sample3"><p><a target="_blank" href="https://github.com/sdegutis/vanillajsx.com/blob/main/site/samples/sample3.tsx">View source</a></p><pre><code>function TodoInput(attrs: { add: (v: string) =&gt; void }) {
  const input = &lt;input /&gt; as HTMLInputElement;
  input.placeholder = 'Add todo item...';
  input.onkeydown = (e) =&gt; {
    if (e.key === 'Enter') {
      attrs.add(input.value);
      input.value = '';
    }
  };
  return input;
}

class TodoList {
  ul = &lt;ul class='todolist' /&gt; as HTMLUListElement;
  add(v: string) {
    const item = &lt;li&gt;{v}&lt;/li&gt; as HTMLLIElement;
    item.onclick = () =&gt; item.remove();
    this.ul.append(item);
  }
}

export default () =&gt; {
  const list = new TodoList();
  list.add('foo');
  list.add('bar');
  return &lt;&gt;
    &lt;TodoInput add={(v) =&gt; list.add(v)} /&gt;
    {list.ul}
  &lt;/&gt;;
};
</code></pre></div><p>How would they handle large data?</p><p>Could they be convenient without a virtual dom?</p><div data-sample="sample4"><p><a target="_blank" href="https://github.com/sdegutis/vanillajsx.com/blob/main/site/samples/sample4.tsx">View source</a></p><pre><code>import { data } from "../fetch-dataset.js";

export default function FindNames() {
  const status = &lt;p style='margin:1em 0' /&gt; as HTMLParagraphElement;
  const results = &lt;ul /&gt; as HTMLUListElement;
  const input = &lt;input
    value='eri(c|k)a?'
    autocomplete='new-password'
  /&gt; as HTMLInputElement;

  const updateMatches = () =&gt; {
    const matched = (data.entries()
      .filter(([k]) =&gt; k.match(input.value))
      .toArray());

    const matches = (Iterator.from(matched)
      .map(match =&gt; &lt;Item regex={input.value} match={match} /&gt;)
      .take(30));

    results.replaceChildren(...matches);
    status.textContent = `${matched.length} / ${data.size}`;
  };

  input.oninput = updateMatches;
  updateMatches();

  return &lt;div class='sample4'&gt;
    {input}
    {status}
    {results}
  &lt;/div&gt;;
}

function Item(attrs: { match: [string, number], regex: string }) {
  const [name, count] = attrs.match;
  const total = &lt;small style='color:#fff3'&gt;({count})&lt;/small&gt;;
  return &lt;li&gt;
    &lt;span innerHTML={highlight(name, attrs.regex)} /&gt; {total}
  &lt;/li&gt;;
}

function highlight(str: string, regex: string) {
  if (!regex) return str;
  const r = new RegExp(`(${regex})`, 'gi');
  return str.replace(r, '&lt;span class="match"&gt;$1&lt;/span&gt;');
}
</code></pre></div><p>That's why I wrote <a target="_blank" href="https://code.immaculatalibrary.com/">imlib</a> (<a href="https://github.com/sdegutis/imlib">src</a>).</p><p>It came out of my work on <a target="_blank" href="https://www.immaculatalibrary.com/">immaculatalibrary.com</a> (<a href="https://github.com/sdegutis/immaculatalibrary.com">src</a>).</p><p>I started using it to build <a target="_blank" href="https://minigamemaker.com/">minigamemaker.com</a> (<a href="https://github.com/sdegutis/minigamemaker.com">src</a>).</p><p>I also used it to build <a target="_blank" href="https://github.com/sdegutis/vanillajsx.com/tree/main/site">the website you're reading</a> (&lt;-- src).</p><p>It was created because the status quo wasn't good enough for my site.</p><p>It is now my favorite way to make apps.</p><p>(Also, here's a much better <a href="https://sdegutis.github.io/imlib-todolist/">imlib todo-list app</a> (<a href="https://github.com/sdegutis/imlib-todolist/blob/main/site/app.tsx">src</a>)).</p><p>The two most complex "interactive apps" I've built with this are:</p><ul><li><a href="https://www.immaculatalibrary.com/books.html">Books search page</a> (<a href="https://github.com/sdegutis/immaculatalibrary.com/blob/main/site/scripts/books-page.tsx">src</a>)</li><li><a href="https://www.immaculatalibrary.com/prayers/">Prayer page</a> (<a href="https://github.com/sdegutis/immaculatalibrary.com/blob/main/site/prayers/client.tsx">src</a>)</li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Backdoor discovered in several brands of RFID cards [pdf] (240 pts)]]></title>
            <link>https://eprint.iacr.org/2024/1275.pdf</link>
            <guid>41269249</guid>
            <pubDate>Fri, 16 Aug 2024 18:53:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eprint.iacr.org/2024/1275.pdf">https://eprint.iacr.org/2024/1275.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=41269249">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Disrupting a covert Iranian influence operation (118 pts)]]></title>
            <link>https://openai.com/index/disrupting-a-covert-iranian-influence-operation/</link>
            <guid>41269113</guid>
            <pubDate>Fri, 16 Aug 2024 18:39:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/disrupting-a-covert-iranian-influence-operation/">https://openai.com/index/disrupting-a-covert-iranian-influence-operation/</a>, See on <a href="https://news.ycombinator.com/item?id=41269113">Hacker News</a></p>
Couldn't get https://openai.com/index/disrupting-a-covert-iranian-influence-operation/: Error: Request failed with status code 403]]></description>
        </item>
    </channel>
</rss>