<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 22 Dec 2025 20:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[US destroying its reputation as a scientific leader – European science diplomat (115 pts)]]></title>
            <link>https://sciencebusiness.net/news/horizon-europe/us-demolishing-its-scientific-leadership-wrecking-ball-says-chief-eu-research</link>
            <guid>46357887</guid>
            <pubDate>Mon, 22 Dec 2025 19:31:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sciencebusiness.net/news/horizon-europe/us-demolishing-its-scientific-leadership-wrecking-ball-says-chief-eu-research">https://sciencebusiness.net/news/horizon-europe/us-demolishing-its-scientific-leadership-wrecking-ball-says-chief-eu-research</a>, See on <a href="https://news.ycombinator.com/item?id=46357887">Hacker News</a></p>
Couldn't get https://sciencebusiness.net/news/horizon-europe/us-demolishing-its-scientific-leadership-wrecking-ball-says-chief-eu-research: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[US blocks all offshore wind construction, says reason is classified (110 pts)]]></title>
            <link>https://arstechnica.com/science/2025/12/us-government-finds-new-excuse-to-stop-construction-of-offshore-wind/</link>
            <guid>46357881</guid>
            <pubDate>Mon, 22 Dec 2025 19:31:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/science/2025/12/us-government-finds-new-excuse-to-stop-construction-of-offshore-wind/">https://arstechnica.com/science/2025/12/us-government-finds-new-excuse-to-stop-construction-of-offshore-wind/</a>, See on <a href="https://news.ycombinator.com/item?id=46357881">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="app">
    <p><a href="#main">
  Skip to content
</a></p>



<main id="main">
            <article data-id="2133105">
  
  <header>
  <div>
      

      

      <p>
        Projects with hardware in the water stopped due to Department of Defense fears.
      </p>

              
          </div>
</header>


  

  
      
    
    <div>
                      
                      
          <p>On Monday, the US Department of the Interior <a href="https://www.doi.gov/pressreleases/trump-administration-protects-us-national-security-pausing-offshore-wind-leases">announced</a> that it was pausing the leases on all five offshore wind sites currently under construction in the US. The move comes despite the fact that these projects already have installed significant hardware in the water and on land; one of them is nearly complete. In what appears to be an attempt to avoid legal scrutiny, the Interior is blaming the decisions on a classified report from the Department of Defense.</p>
<p>The second Trump administration announced its animosity toward offshore wind power <a href="https://www.whitehouse.gov/presidential-actions/2025/01/temporary-withdrawal-of-all-areas-on-the-outer-continental-shelf-from-offshore-wind-leasing-and-review-of-the-federal-governments-leasing-and-permitting-practices-for-wind-projects/">literally on day one</a>, issuing an executive order on inauguration day that called for a temporary halt to issuing permits for new projects pending a re-evaluation. Earlier this month, however, a judge <a href="https://arstechnica.com/tech-policy/2025/12/trumps-order-blocking-wind-development-thrown-out-by-court/">vacated that executive order</a>, noting that the government has shown no indication that it was even attempting to start the re-evaluation it said was needed.</p>
<p>But a number of projects have gone through the entire permitting process, and construction has started. Before today, the administration had attempted to stop these in an erratic, halting manner. Empire Wind, an 800 MW farm being built off New York, was <a href="https://arstechnica.com/science/2025/04/us-interior-secretary-orders-offshore-wind-project-shut-down/">stopped by the Department of the Interior</a>, which alleged that it had been rushed through permitting. That <a href="https://arstechnica.com/science/2025/09/judge-lets-construction-on-an-offshore-wind-farm-resume/">hold was lifted</a> following lobbying and negotiations by New York and the project developer Orsted, and the Department of the Interior never revealed why it changed its mind. When the Interior Department blocked a second Orsted project, Revolution Wind offshore of southern New England, the company took the government to court and <a href="https://arstechnica.com/science/2025/09/judge-lets-construction-on-an-offshore-wind-farm-resume/">won a ruling</a> that let it continue construction.</p>

          
                      
                  </div>
                    
        
          
    
    <div>
          
          
<p>Today’s announcement targets those and three other projects. Interior says it is pausing the permits for all five, which are the only projects currently under construction. It claims that offshore wind creates “national security risks” that were revealed in a recent analysis performed by the Department of Defense, which apparently neglected to identify these issues during the evaluations it did while the projects were first permitted.</p>
<h2>Unspecified risks</h2>
<p>What are these risks? The Interior Department is being extremely coy. It notes that offshore wind turbines can interfere with radar sensing, but that’s been known for a while. In announcing the decision, Interior Secretary Doug Burgum also noted “the rapid evolution of the relevant adversary technologies.” But the announcement says that the Defense Department analysis is classified, meaning nobody is likely to know what the actual reason is—presuming one exists. The classification will also make it far more challenging to contest this decision in court.</p>
<p>The five blocked projects&nbsp; are:</p>
<ul>
<li>Coastal Virginia Offshore Wind: A massive 2.6 GW installation off the coast of Virginia. According to the <a href="https://coastalvawind.com/about/the-project/timeline#tl2024">project’s updates</a>, construction of the land-based facilities and the in-water base for the towers is complete, and assembly of the turbines and towers on land has started.</li>
<li>Empire Wind: A site off the New York/New Jersey coast will play host to an 810 MW project. This one is early in the construction phase, with work focusing on prepping the sites where turbines will be installed. This had been subjected to an earlier hold.</li>
<li>Revolution Wind: Another early victim of the Department of Interior’s capricious early attempts, Revolution was 80 percent complete when work restarted following Orsted’s court victory. It will host 700 MW of generating capacity in the waters off Connecticut and Rhode Island.</li>
<li>Sunrise Wind: 925 MW is planned for a site beyond the tip of Long Island. Recent construction updates suggest that work is primarily focused on the facilities where power will be brought ashore.</li>
<li>Vineyard Wind 1: This is an 800 MW project being built just south of Nantucket and Martha’s Vineyard. This project was expected to be completed by the end of this year, so it may be substantially done.</li>
</ul>

          
                  </div>
                    
        
          
    
    <div>

        
        <div>
          
          
<p>Many of the affected states were counting on the power that these facilities would deliver, and will likely oppose this move. “This appears to be a second, even more lawless and erratic stop work order, reviving the Trump Administration’s prior failed attempt to halt construction of Revolution Wind,” said William Tong, the Attorney General of Connecticut. “There is a court order blocking their prior stop work order and this appears to be a new brazen attempt to circumvent that order.” He indicated his office is currently evaluating its legal options.</p>
<p>The states are likely to be joined by the companies backing these projects, which, in several cases, have already spent nearly all the money needed for their construction and will be eager to start earning that back by selling power from the facilities.</p>
<p>In both court cases in which the administration attempted to block wind power development, the government lost badly. The records in the case indicate that it has had no substantive reasons for reversing decades-old policies and overruling past decisions, and that internally, the decision-making process appears to consist entirely of noting that the president doesn’t like wind power. It’s unclear whether this classified evaluation differs significantly from earlier efforts in any way other than that it will be harder to find out.</p>


          
                  </div>

                  
          






  <div>
  <div>
          <p><a href="https://arstechnica.com/author/john-timmer/"><img src="https://cdn.arstechnica.net/wp-content/uploads/2016/05/j.timmer-5.jpg" alt="Photo of John Timmer"></a></p>
  </div>

  <div>
    

    <p>
      John is Ars Technica's science editor. He has a Bachelor of Arts in Biochemistry from Columbia University, and a Ph.D. in Molecular and Cell Biology from the University of California, Berkeley. When physically separated from his keyboard, he tends to seek out a bicycle, or a scenic location for communing with his hiking boots.

    </p>
  </div>
</div>


  <p>
    <a href="https://arstechnica.com/science/2025/12/us-government-finds-new-excuse-to-stop-construction-of-offshore-wind/#comments" title="97 comments">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 80 80"><defs><clipPath id="bubble-zero_svg__a"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath><clipPath id="bubble-zero_svg__b"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath></defs><g clip-path="url(#bubble-zero_svg__a)"><g fill="currentColor" clip-path="url(#bubble-zero_svg__b)"><path d="M80 40c0 22.09-17.91 40-40 40S0 62.09 0 40 17.91 0 40 0s40 17.91 40 40"></path><path d="M40 40 .59 76.58C-.67 77.84.22 80 2.01 80H40z"></path></g></g></svg>
    97 Comments
  </a>
      </p>
              </div>
  </article>


  


  


  <div>
    <header>
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 26"><defs><clipPath id="most-read_svg__a"><path fill="none" d="M0 0h40v26H0z"></path></clipPath><clipPath id="most-read_svg__b"><path fill="none" d="M0 0h40v26H0z"></path></clipPath></defs><g clip-path="url(#most-read_svg__a)"><g fill="none" clip-path="url(#most-read_svg__b)"><path fill="currentColor" d="M20 2h.8q1.5 0 3 .6c.6.2 1.1.4 1.7.6 1.3.5 2.6 1.3 3.9 2.1.6.4 1.2.8 1.8 1.3 2.9 2.3 5.1 4.9 6.3 6.4-1.1 1.5-3.4 4-6.3 6.4-.6.5-1.2.9-1.8 1.3q-1.95 1.35-3.9 2.1c-.6.2-1.1.4-1.7.6q-1.5.45-3 .6h-1.6q-1.5 0-3-.6c-.6-.2-1.1-.4-1.7-.6-1.3-.5-2.6-1.3-3.9-2.1-.6-.4-1.2-.8-1.8-1.3-2.9-2.3-5.1-4.9-6.3-6.4 1.1-1.5 3.4-4 6.3-6.4.6-.5 1.2-.9 1.8-1.3q1.95-1.35 3.9-2.1c.6-.2 1.1-.4 1.7-.6q1.5-.45 3-.6zm0-2h-1c-1.2 0-2.3.3-3.4.6-.6.2-1.3.4-1.9.7-1.5.6-2.9 1.4-4.3 2.3-.7.5-1.3.9-1.9 1.4C2.9 8.7 0 13 0 13s2.9 4.3 7.5 7.9c.6.5 1.3 1 1.9 1.4 1.3.9 2.7 1.7 4.3 2.3.6.3 1.3.5 1.9.7 1.1.3 2.3.6 3.4.6h2c1.2 0 2.3-.3 3.4-.6.6-.2 1.3-.4 1.9-.7 1.5-.6 2.9-1.4 4.3-2.3.7-.5 1.3-.9 1.9-1.4C37.1 17.3 40 13 40 13s-2.9-4.3-7.5-7.9c-.6-.5-1.3-1-1.9-1.4-1.3-.9-2.8-1.7-4.3-2.3-.6-.3-1.3-.5-1.9-.7C23.3.4 22.1.1 21 .1h-1"></path><path fill="#ff4e00" d="M20 5c-4.4 0-8 3.6-8 8s3.6 8 8 8 8-3.6 8-8-3.6-8-8-8m0 11c-1.7 0-3-1.3-3-3s1.3-3 3-3 3 1.3 3 3-1.3 3-3 3"></path></g></g></svg>
      
    </header>
    <ol>
              <li>
                      <a href="https://arstechnica.com/ai/2025/12/the-ars-technica-ai-coding-agent-test-minesweeper-edition/">
              <img src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/ai-gpu-minsweeper-768x432.jpg" alt="Listing image for first story in Most Read: We asked four AI coding agents to rebuild Minesweeper—the results were explosive" decoding="async" loading="lazy">
            </a>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                  </ol>
</div>
  </main>





  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Benn Jordan – This Flock Camera Leak Is Like Netflix for Stalkers [video] (249 pts)]]></title>
            <link>https://www.youtube.com/watch?v=vU1-uiUlHTo</link>
            <guid>46356182</guid>
            <pubDate>Mon, 22 Dec 2025 17:19:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=vU1-uiUlHTo">https://www.youtube.com/watch?v=vU1-uiUlHTo</a>, See on <a href="https://news.ycombinator.com/item?id=46356182">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Jimmy Lai Is a Martyr for Freedom (204 pts)]]></title>
            <link>https://reason.com/2025/12/19/jimmy-lai-is-a-martyr-for-freedom/</link>
            <guid>46355888</guid>
            <pubDate>Mon, 22 Dec 2025 16:56:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reason.com/2025/12/19/jimmy-lai-is-a-martyr-for-freedom/">https://reason.com/2025/12/19/jimmy-lai-is-a-martyr-for-freedom/</a>, See on <a href="https://news.ycombinator.com/item?id=46355888">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
																		<article>
	<header>
							<p>
				<a href="https://reason.com/category/politics/authoritarianism/">Authoritarianism</a>
			</p>
				
		
					<h2>The self-made tycoon was convicted this week of violating Hong Kong's "national security" law. But he could have escaped it.</h2>
				<p>
				
			
						<span>|</span>
			<time datetime="2025-12-19T15:54:33-05:00">12.19.2025 3:54 PM</time>
			
</p>
					
										<div>
						<div>
			<picture>
									<source type="image/webp" data-lazy-srcset="https://d2eehagpk5cl65.cloudfront.net/img/c2400x1350-w2400-q80/uploads/2025/12/jimmy-lai-free-speech-china.jpg.webp 2400w,https://d2eehagpk5cl65.cloudfront.net/img/c1200x675-w1200-q80/uploads/2025/12/jimmy-lai-free-speech-china-1200x675.jpg.webp 1200w,https://d2eehagpk5cl65.cloudfront.net/img/c800x450-w800-q80/uploads/2025/12/jimmy-lai-free-speech-china-800x450.jpg.webp 800w,https://d2eehagpk5cl65.cloudfront.net/img/c600x338-w600-q80/uploads/2025/12/jimmy-lai-free-speech-china-600x338.jpg.webp 600w,https://d2eehagpk5cl65.cloudfront.net/img/c331x186-w331-q80/uploads/2025/12/jimmy-lai-free-speech-china-331x186.jpg.webp 331w,https://d2eehagpk5cl65.cloudfront.net/img/c1200x675-w1200-q80/uploads/2025/12/jimmy-lai-free-speech-china-1200x675.jpg.webp 1200w,https://d2eehagpk5cl65.cloudfront.net/img/c1920x1080-w1920-q80/uploads/2025/12/jimmy-lai-free-speech-china.jpg.webp 1920w" sizes="(min-width: 753px) 70vw, (min-width: 1190px) 768px, 100vw">
											<source type="image/jpeg" data-lazy-srcset="https://d2eehagpk5cl65.cloudfront.net/img/c2400x1350-w2400-q80/uploads/2025/12/jimmy-lai-free-speech-china.jpg 2400w,https://d2eehagpk5cl65.cloudfront.net/img/c1200x675-w1200-q80/uploads/2025/12/jimmy-lai-free-speech-china-1200x675.jpg 1200w,https://d2eehagpk5cl65.cloudfront.net/img/c800x450-w800-q80/uploads/2025/12/jimmy-lai-free-speech-china-800x450.jpg 800w,https://d2eehagpk5cl65.cloudfront.net/img/c600x338-w600-q80/uploads/2025/12/jimmy-lai-free-speech-china-600x338.jpg 600w,https://d2eehagpk5cl65.cloudfront.net/img/c331x186-w331-q80/uploads/2025/12/jimmy-lai-free-speech-china-331x186.jpg 331w,https://d2eehagpk5cl65.cloudfront.net/img/c1200x675-w1200-q80/uploads/2025/12/jimmy-lai-free-speech-china-1200x675.jpg 1200w,https://d2eehagpk5cl65.cloudfront.net/img/c1920x1080-w1920-q80/uploads/2025/12/jimmy-lai-free-speech-china.jpg 1920w" sizes="(min-width: 753px) 70vw, (min-width: 1190px) 768px, 100vw">
													<img src="https://d2eehagpk5cl65.cloudfront.net/img/c800x450-w800-q80/uploads/2025/12/jimmy-lai-free-speech-china-800x450.jpg" width="1200" height="675" title="Jimmy Lai at a protest in Hong Kong in 2014" alt="Jimmy Lai at a protest in Hong Kong in 2014 | Illustration: Eddie Marshall | Liau Chung-ren/ZUMAPRESS/Newscom" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201200%20675'%3E%3C/svg%3E" data-lazy-src="https://d2eehagpk5cl65.cloudfront.net/img/c800x450-w800-q80/uploads/2025/12/jimmy-lai-free-speech-china-800x450.jpg">
			</picture>
		</div>
							<p><span>
					Jimmy Lai at a protest in Hong Kong in 2014 (Illustration: Eddie Marshall | Liau Chung-ren/ZUMAPRESS/Newscom)				</span>
					</p>
								</div>
							
	</header>
	<div>
							<p><span>There are many interesting tidbits about the life of the political prisoner Jimmy Lai. He hid in the bottom of a fishing boat to escape mainland Communist China for Hong Kong at the ripe age of 12. He built a garment empire after spending his adolescence working, and sleeping, in garment factories. Without media experience, he started several successful news ventures—most notably the plucky and irreverent </span><i><span>Apple Daily</span></i><span>—which forcefully advocated for democracy and free speech. And he may be sentenced to die in prison in connection with his efforts promoting liberty in China.</span></p>
<p><span>But the most interesting fact, by far, is that Lai is a citizen of the United Kingdom (U.K.).</span></p>
<p><span>The dissident was convicted in Hong Kong earlier this week of two counts of conspiring to collude with foreign forces and one count of publishing seditious material—charges stemming from his crusade against illiberalism, a fight he has been waging for decades. Lai finding himself in trouble was not a surprise. That's especially true amid the backdrop of Hong Kong's "national security" law, which sought to cripple dissent, that took effect in 2020. He was arrested in August of that year and released on bail; authorities revoked it four months later. Lai has been in custody since.</span></p>
<p><span>That he would probably end up in prison, however, was never </span><i><span>really</span></i><span> in doubt. Which brings me back to his U.K. citizenship.</span></p>
<p><span>Lai did not have to stay in Hong Kong as the walls closed in on him. The self-made business tycoon—once a billionaire before the government froze his assets—could have fled to a residence abroad. His friend Mark Clifford, formerly the editor in chief of the </span><i><span>South China Morning Post, </span></i><span>told me in an </span><a href="https://www.youtube.com/watch?v=RiIc-HEpO6k"><span>interview</span></a><span> earlier this year that many people in Lai's circle urged him to do just that.</span></p>
<p><span>He declined. "Everything I have was given to me by Hong Kong. I won't be leaving," Lai </span><a href="https://www.rfa.org/english/news/china/hongkong-jimmylai-06102020163836.html"><span>told</span></a><span> Radio Free Asia in June 2020. "I'm going to stay here and fight to the bitter end."</span></p>
<p>Lawmakers would go on to formally approve the national security law, essentially a foregone conclusion, about three weeks later. The legislation broadly criminalized political dissent and hamstrung the civil liberties that once distinguished Hong Kong from mainland China. A defense of those freedoms—which were already under increasing attack—had come to define Lai's legacy. Lai not only unapologetically advanced democracy and free expression in the region, but he also met with then–Vice President Mike Pence and Secretary of State Mike Pompeo; at trial, Lai <a href="https://www.nbcnews.com/news/amp/rcna180929">testified</a> that he had asked them to voice their support for Hong Kong. He knew the law was coming, and he knew what it meant for him.</p>
<p><span>But some things, he decided, are more important than personal freedom. In this case, the absence of it was more important—in part to show the world what happens when an authoritarian government severely curtails basic liberties.</span></p>
<p><span>In some sense, there was no better person than Lai to send this message. His Cinderella story is impossible to divorce from Hong Kong itself. There, he was able to find refuge from the Chinese Communist Party, which had imprisoned his mother, deemed a "class enemy," in a labor camp. But he was also able to make something from nothing: from living in factories, while </span><a href="https://www.nytimes.com/2023/09/28/opinion/hongkong-china-lai-democracy.html"><span>rats scampered across his body</span></a><span>, to running them. His story came full circle. It demands people ask: Do you prefer Hong Kong's past? Or its future?</span></p>
<p><iframe title="A political prisoner fights for free speech in China | Mark Clifford | Reason Interview" width="500" height="281" src="https://www.youtube.com/embed/RiIc-HEpO6k?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p>
						</div>
		
</article>

					<nav>
	
		<p>
        <a href="https://reason.com/2025/12/19/trumps-designation-of-fentanyl-as-a-weapon-of-mass-destruction-is-a-drug-fueled-delusion/" data-ga-click="true" data-ga-action="Next Article Click" data-ga-label="Trump's Designation of Fentanyl As a 'Weapon of Mass Destruction' Is a Drug-Fueled Delusion"><span>NEXT:</span> Trump's Designation of Fentanyl As a 'Weapon of Mass Destruction' Is a Drug-Fueled Delusion</a>
    </p>
	
	<span><a rel="tag" href="https://reason.com/category/politics/authoritarianism/">Authoritarianism</a><a rel="tag" href="https://reason.com/tag/china/">China</a><a rel="tag" href="https://reason.com/tag/democracy/">Democracy</a><a rel="tag" href="https://reason.com/category/civil-liberties/free-speech/">Free Speech</a><a rel="tag" href="https://reason.com/tag/liberty/">Liberty</a><a rel="tag" href="https://reason.com/tag/media/">Media</a><a rel="tag" href="https://reason.com/category/civil-liberties/protests/">Protests</a><a rel="tag" href="https://reason.com/tag/national-security/">National Security</a><a rel="tag" href="https://reason.com/category/foreign-policy/world/">World</a><a rel="tag" href="https://reason.com/category/culture/freedom/">Freedom</a><a rel="tag" href="https://reason.com/tag/hong-kong/">Hong Kong</a><a rel="tag" href="https://reason.com/tag/united-kingdom/">United Kingdom</a><a rel="tag" href="https://reason.com/category/politics/">Politics</a></span>			
				
	</nav>
				
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Flock Exposed Its AI-Powered Cameras to the Internet. We Tracked Ourselves (118 pts)]]></title>
            <link>https://www.404media.co/flock-exposed-its-ai-powered-cameras-to-the-internet-we-tracked-ourselves/</link>
            <guid>46355548</guid>
            <pubDate>Mon, 22 Dec 2025 16:31:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.404media.co/flock-exposed-its-ai-powered-cameras-to-the-internet-we-tracked-ourselves/">https://www.404media.co/flock-exposed-its-ai-powered-cameras-to-the-internet-we-tracked-ourselves/</a>, See on <a href="https://news.ycombinator.com/item?id=46355548">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p>I am standing on the corner of Harris Road and Young Street outside of the Crossroads Business Park in Bakersfield, California, looking up at a Flock surveillance camera bolted high above a traffic signal. On my phone, I am watching myself in real time as the camera records and livestreams me—without any password or login—to the open internet. I wander into the intersection, stare at the camera and wave. On the livestream, I can see myself clearly. Hundreds of miles away, my colleagues are remotely watching me too through the exposed feed.</p><p>Flock left livestreams and administrator control panels for at least 60 of its AI-enabled Condor cameras around the country exposed to the open internet, where anyone could watch them, download 30 days worth of video archive, and change settings, see log files, and run diagnostics.&nbsp;</p><figure><img src="https://www.404media.co/content/images/2025/12/CleanShot-2025-12-22-at-07.28.53@2x.png" alt="" loading="lazy" width="2000" height="1074" srcset="https://www.404media.co/content/images/size/w600/2025/12/CleanShot-2025-12-22-at-07.28.53@2x.png 600w, https://www.404media.co/content/images/size/w1000/2025/12/CleanShot-2025-12-22-at-07.28.53@2x.png 1000w, https://www.404media.co/content/images/size/w1600/2025/12/CleanShot-2025-12-22-at-07.28.53@2x.png 1600w, https://www.404media.co/content/images/size/w2400/2025/12/CleanShot-2025-12-22-at-07.28.53@2x.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>Unlike many of Flock’s cameras, which are designed to capture license plates as people drive by, Flock’s Condor cameras are pan-tilt-zoom (PTZ) cameras designed to record and track people, not vehicles. Condor cameras can be set to automatically zoom in on people’s faces as they walk through a parking lot, down a public street, or play on a playground, or they can be controlled manually, according to marketing material on Flock’s website. We watched Condor cameras zoom in on a woman walking her dog on a bike path in suburban Atlanta; a camera followed a man walking through a Macy’s parking lot in Bakersfield; surveil children swinging on a swingset at a playground; and film high-res video of people sitting at a stoplight in traffic. In one case, we were able to watch a man rollerblade down Brookhaven, Georgia’s Peachtree Creek Greenway bike path. The Flock camera zoomed in on him and tracked him as he rolled past. Minutes later, he showed up on another exposed camera livestream further down the bike path. The camera’s resolution was good enough that we were able to see that, when he stopped beneath one of the cameras, he was watching rollerblading videos on his phone.</p><figure data-kg-thumbnail="https://www.404media.co/content/media/2025/12/1222--1-_thumb.jpg" data-kg-custom-thumbnail="">
            <div>
                <video src="https://www.404media.co/content/media/2025/12/1222--1-.mp4" poster="https://img.spacergif.org/v1/1288x720/0a/spacer.png" width="1288" height="720" playsinline="" preload="metadata"></video>
                
                <div>
                        <p>
                        
                        <span>0:00</span></p><p>
                            /<span>0:16</span>
                        </p>
                        </div>
            </div>
            
        <img src="https://www.404media.co/content/media/2025/12/1222--1-_thumb.jpg"></figure><p>The exposure was initially discovered by YouTuber and technologist Benn Jordan and was shared with security researcher Jon “GainSec” Gaines, who <a href="https://www.youtube.com/watch?v=uB0gr7Fh6lY&amp;t=1387s&amp;ref=404media.co"><u>recently found numerous vulnerabilities</u></a> in several other models of Flock’s automated license plate reader (ALPR) cameras. They shared the details of what they found&nbsp; with me, and I verified many of the details seen in the exposed portals by driving to Bakersfield to walk in front of two cameras there while I watched myself on the livestream. I also pulled Flock’s contracts with cities for Condor cameras, pulled details from company presentations about the technology, and geolocated a handful of the cameras to cities and towns across the United States. Jordan also filmed himself in front of several of the cameras on the Peachtree Creek Greenway bike path. Jordan said he and Gaines discovered many of the exposed cameras with Shodan, an internet of things search engine that researchers regularly use to identify improperly secured devices.&nbsp;</p><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/vU1-uiUlHTo?start=181&amp;feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="" title="This Flock Camera Leak is like Netflix For Stalkers"></iframe></figure><p>After finding links to the feed, “immediately, we were just without any username, without any password, we were just seeing everything from playgrounds to parking lots with people, Christmas shopping and unloading their stuff into cars,” Jordan told me in an interview. “I think it was like the first time that I actually got like immediately scared … I think the one that affected me most was as playground. You could see unattended kids, and that’s something I want people to know about so they can understand how dangerous this is.” In a YouTube video about his research, Jordan said he was able to use footage pulled from the exposed feed to identify specific people using open source investigation tools in order to show how trivially an exposure like this could be abused.</p>
</div><div>
  <div>
    <h2>This post is for paid members only</h2>
    <p>Become a paid member for unlimited ad-free access to articles, bonus podcast content, and more.</p>
    <p><a href="https://www.404media.co/membership/">Subscribe</a>
  </p></div>
  <div>
    <h2>Sign up for free access to this post</h2>
    <p>Free members get access to posts like this one along with an email round-up of our week's stories.</p>
    <p><a href="https://www.404media.co/signup/">Subscribe</a>
  </p></div>
  <p>Already have an account? <a href="https://www.404media.co/signin/" data-portal="signin">Sign in</a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude Code gets native LSP support (163 pts)]]></title>
            <link>https://github.com/anthropics/claude-code/blob/main/CHANGELOG.md</link>
            <guid>46355165</guid>
            <pubDate>Mon, 22 Dec 2025 15:59:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/anthropics/claude-code/blob/main/CHANGELOG.md">https://github.com/anthropics/claude-code/blob/main/CHANGELOG.md</a>, See on <a href="https://news.ycombinator.com/item?id=46355165">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            


<react-partial partial-name="marketing-navigation" data-ssr="true" data-attempted-ssr="true" data-react-profiling="false">
  
  
  <div data-target="react-partial.reactRoot"><nav aria-label="Global"><ul><li><div><ul><li><div><p><span>AI CODE CREATION</span></p><ul><li><a href="https://github.com/features/copilot" data-analytics-event="{&quot;action&quot;:&quot;github_copilot&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;github_copilot_link_platform_navbar&quot;}"><div><p><span>GitHub Copilot</span><span>Write better code with AI</span></p></div></a></li><li><a href="https://github.com/features/spark" data-analytics-event="{&quot;action&quot;:&quot;github_spark&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;github_spark_link_platform_navbar&quot;}"><div><p><span>GitHub Spark</span><span>Build and deploy intelligent apps</span></p></div></a></li><li><a href="https://github.com/features/models" data-analytics-event="{&quot;action&quot;:&quot;github_models&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;github_models_link_platform_navbar&quot;}"><div><p><span>GitHub Models</span><span>Manage and compare prompts</span></p></div></a></li><li><a href="https://github.com/mcp" data-analytics-event="{&quot;action&quot;:&quot;mcp_registry&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;mcp_registry_link_platform_navbar&quot;}"><div><p><span>MCP Registry<sup>New</sup></span><span>Integrate external tools</span></p></div></a></li></ul></div></li><li><div><p><span>DEVELOPER WORKFLOWS</span></p><ul><li><a href="https://github.com/features/actions" data-analytics-event="{&quot;action&quot;:&quot;actions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;actions_link_platform_navbar&quot;}"><div><p><span>Actions</span><span>Automate any workflow</span></p></div></a></li><li><a href="https://github.com/features/codespaces" data-analytics-event="{&quot;action&quot;:&quot;codespaces&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;codespaces_link_platform_navbar&quot;}"><div><p><span>Codespaces</span><span>Instant dev environments</span></p></div></a></li><li><a href="https://github.com/features/issues" data-analytics-event="{&quot;action&quot;:&quot;issues&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;issues_link_platform_navbar&quot;}"><div><p><span>Issues</span><span>Plan and track work</span></p></div></a></li><li><a href="https://github.com/features/code-review" data-analytics-event="{&quot;action&quot;:&quot;code_review&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;code_review_link_platform_navbar&quot;}"><div><p><span>Code Review</span><span>Manage code changes</span></p></div></a></li></ul></div></li><li><div><p><span>APPLICATION SECURITY</span></p><ul><li><a href="https://github.com/security/advanced-security" data-analytics-event="{&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;github_advanced_security_link_platform_navbar&quot;}"><div><p><span>GitHub Advanced Security</span><span>Find and fix vulnerabilities</span></p></div></a></li><li><a href="https://github.com/security/advanced-security/code-security" data-analytics-event="{&quot;action&quot;:&quot;code_security&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;code_security_link_platform_navbar&quot;}"><div><p><span>Code security</span><span>Secure your code as you build</span></p></div></a></li><li><a href="https://github.com/security/advanced-security/secret-protection" data-analytics-event="{&quot;action&quot;:&quot;secret_protection&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;secret_protection_link_platform_navbar&quot;}"><div><p><span>Secret protection</span><span>Stop leaks before they start</span></p></div></a></li></ul></div></li><li><div><p><span>EXPLORE</span></p><ul><li><a href="https://github.com/why-github" data-analytics-event="{&quot;action&quot;:&quot;why_github&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;why_github_link_platform_navbar&quot;}"><span>Why GitHub</span></a></li><li><a href="https://docs.github.com/" data-analytics-event="{&quot;action&quot;:&quot;documentation&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;documentation_link_platform_navbar&quot;}" target="_blank" rel="noreferrer"><span>Documentation</span></a></li><li><a href="https://github.blog/" data-analytics-event="{&quot;action&quot;:&quot;blog&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;blog_link_platform_navbar&quot;}" target="_blank" rel="noreferrer"><span>Blog</span></a></li><li><a href="https://github.blog/changelog" data-analytics-event="{&quot;action&quot;:&quot;changelog&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;changelog_link_platform_navbar&quot;}" target="_blank" rel="noreferrer"><span>Changelog</span></a></li><li><a href="https://github.com/marketplace" data-analytics-event="{&quot;action&quot;:&quot;marketplace&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;marketplace_link_platform_navbar&quot;}"><span>Marketplace</span></a></li></ul></div></li></ul><p><a href="https://github.com/features" data-analytics-event="{&quot;action&quot;:&quot;view_all_features&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;platform&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;view_all_features_link_platform_navbar&quot;}"><span>View all features</span></a></p></div></li><li><div><ul><li><div><p><span>BY COMPANY SIZE</span></p><ul><li><a href="https://github.com/enterprise" data-analytics-event="{&quot;action&quot;:&quot;enterprises&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;enterprises_link_solutions_navbar&quot;}"><span>Enterprises</span></a></li><li><a href="https://github.com/team" data-analytics-event="{&quot;action&quot;:&quot;small_and_medium_teams&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;small_and_medium_teams_link_solutions_navbar&quot;}"><span>Small and medium teams</span></a></li><li><a href="https://github.com/enterprise/startups" data-analytics-event="{&quot;action&quot;:&quot;startups&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;startups_link_solutions_navbar&quot;}"><span>Startups</span></a></li><li><a href="https://github.com/solutions/industry/nonprofits" data-analytics-event="{&quot;action&quot;:&quot;nonprofits&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;nonprofits_link_solutions_navbar&quot;}"><span>Nonprofits</span></a></li></ul></div></li><li><div><p><span>BY USE CASE</span></p><ul><li><a href="https://github.com/solutions/use-case/app-modernization" data-analytics-event="{&quot;action&quot;:&quot;app_modernization&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;app_modernization_link_solutions_navbar&quot;}"><span>App Modernization</span></a></li><li><a href="https://github.com/solutions/use-case/devsecops" data-analytics-event="{&quot;action&quot;:&quot;devsecops&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;devsecops_link_solutions_navbar&quot;}"><span>DevSecOps</span></a></li><li><a href="https://github.com/solutions/use-case/devops" data-analytics-event="{&quot;action&quot;:&quot;devops&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;devops_link_solutions_navbar&quot;}"><span>DevOps</span></a></li><li><a href="https://github.com/solutions/use-case/ci-cd" data-analytics-event="{&quot;action&quot;:&quot;ci/cd&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;ci/cd_link_solutions_navbar&quot;}"><span>CI/CD</span></a></li><li><a href="https://github.com/solutions/use-case" data-analytics-event="{&quot;action&quot;:&quot;view_all_use_cases&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;view_all_use_cases_link_solutions_navbar&quot;}"><span>View all use cases</span></a></li></ul></div></li><li><div><p><span>BY INDUSTRY</span></p><ul><li><a href="https://github.com/solutions/industry/healthcare" data-analytics-event="{&quot;action&quot;:&quot;healthcare&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;healthcare_link_solutions_navbar&quot;}"><span>Healthcare</span></a></li><li><a href="https://github.com/solutions/industry/financial-services" data-analytics-event="{&quot;action&quot;:&quot;financial_services&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;financial_services_link_solutions_navbar&quot;}"><span>Financial services</span></a></li><li><a href="https://github.com/solutions/industry/manufacturing" data-analytics-event="{&quot;action&quot;:&quot;manufacturing&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;manufacturing_link_solutions_navbar&quot;}"><span>Manufacturing</span></a></li><li><a href="https://github.com/solutions/industry/government" data-analytics-event="{&quot;action&quot;:&quot;government&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;government_link_solutions_navbar&quot;}"><span>Government</span></a></li><li><a href="https://github.com/solutions/industry" data-analytics-event="{&quot;action&quot;:&quot;view_all_industries&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;view_all_industries_link_solutions_navbar&quot;}"><span>View all industries</span></a></li></ul></div></li></ul><p><a href="https://github.com/solutions" data-analytics-event="{&quot;action&quot;:&quot;view_all_solutions&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;solutions&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;view_all_solutions_link_solutions_navbar&quot;}"><span>View all solutions</span></a></p></div></li><li><div><ul><li><div><p><span>EXPLORE BY TOPIC</span></p><ul><li><a href="https://github.com/resources/articles?topic=ai" data-analytics-event="{&quot;action&quot;:&quot;ai&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;ai_link_resources_navbar&quot;}"><span>AI</span></a></li><li><a href="https://github.com/resources/articles?topic=software-development" data-analytics-event="{&quot;action&quot;:&quot;software_development&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;software_development_link_resources_navbar&quot;}"><span>Software Development</span></a></li><li><a href="https://github.com/resources/articles?topic=devops" data-analytics-event="{&quot;action&quot;:&quot;devops&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;devops_link_resources_navbar&quot;}"><span>DevOps</span></a></li><li><a href="https://github.com/resources/articles?topic=security" data-analytics-event="{&quot;action&quot;:&quot;security&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;security_link_resources_navbar&quot;}"><span>Security</span></a></li><li><a href="https://github.com/resources/articles" data-analytics-event="{&quot;action&quot;:&quot;view_all_topics&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;view_all_topics_link_resources_navbar&quot;}"><span>View all topics</span></a></li></ul></div></li><li><div><p><span>EXPLORE BY TYPE</span></p><ul><li><a href="https://github.com/customer-stories" data-analytics-event="{&quot;action&quot;:&quot;customer_stories&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}"><span>Customer stories</span></a></li><li><a href="https://github.com/resources/events" data-analytics-event="{&quot;action&quot;:&quot;events__webinars&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;events__webinars_link_resources_navbar&quot;}"><span>Events &amp; webinars</span></a></li><li><a href="https://github.com/resources/whitepapers" data-analytics-event="{&quot;action&quot;:&quot;ebooks__reports&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;ebooks__reports_link_resources_navbar&quot;}"><span>Ebooks &amp; reports</span></a></li><li><a href="https://github.com/solutions/executive-insights" data-analytics-event="{&quot;action&quot;:&quot;business_insights&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;business_insights_link_resources_navbar&quot;}"><span>Business insights</span></a></li><li><a href="https://skills.github.com/" data-analytics-event="{&quot;action&quot;:&quot;github_skills&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;github_skills_link_resources_navbar&quot;}" target="_blank" rel="noreferrer"><span>GitHub Skills</span></a></li></ul></div></li><li><div><p><span>SUPPORT &amp; SERVICES</span></p><ul><li><a href="https://docs.github.com/" data-analytics-event="{&quot;action&quot;:&quot;documentation&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;documentation_link_resources_navbar&quot;}" target="_blank" rel="noreferrer"><span>Documentation</span></a></li><li><a href="https://support.github.com/" data-analytics-event="{&quot;action&quot;:&quot;customer_support&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;customer_support_link_resources_navbar&quot;}" target="_blank" rel="noreferrer"><span>Customer support</span></a></li><li><a href="https://github.com/orgs/community/discussions" data-analytics-event="{&quot;action&quot;:&quot;community_forum&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;community_forum_link_resources_navbar&quot;}"><span>Community forum</span></a></li><li><a href="https://github.com/trust-center" data-analytics-event="{&quot;action&quot;:&quot;trust_center&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;trust_center_link_resources_navbar&quot;}"><span>Trust center</span></a></li><li><a href="https://github.com/partners" data-analytics-event="{&quot;action&quot;:&quot;partners&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}"><span>Partners</span></a></li></ul></div></li></ul></div></li><li><div><ul><li><div><p><span>COMMUNITY</span></p><ul><li><a href="https://github.com/sponsors" data-analytics-event="{&quot;action&quot;:&quot;github_sponsors&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}"><div><p><span>GitHub Sponsors</span><span>Fund open source developers</span></p></div></a></li></ul></div></li><li><div><p><span>PROGRAMS</span></p><ul><li><a href="https://securitylab.github.com/" data-analytics-event="{&quot;action&quot;:&quot;security_lab&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;security_lab_link_open_source_navbar&quot;}" target="_blank" rel="noreferrer"><span>Security Lab</span></a></li><li><a href="https://maintainers.github.com/" data-analytics-event="{&quot;action&quot;:&quot;maintainer_community&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;maintainer_community_link_open_source_navbar&quot;}" target="_blank" rel="noreferrer"><span>Maintainer Community</span></a></li><li><a href="https://github.com/accelerator" data-analytics-event="{&quot;action&quot;:&quot;accelerator&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;accelerator_link_open_source_navbar&quot;}"><span>Accelerator</span></a></li><li><a href="https://archiveprogram.github.com/" data-analytics-event="{&quot;action&quot;:&quot;archive_program&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;archive_program_link_open_source_navbar&quot;}" target="_blank" rel="noreferrer"><span>Archive Program</span></a></li></ul></div></li><li><div><p><span>REPOSITORIES</span></p><ul><li><a href="https://github.com/topics" data-analytics-event="{&quot;action&quot;:&quot;topics&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;topics_link_open_source_navbar&quot;}"><span>Topics</span></a></li><li><a href="https://github.com/trending" data-analytics-event="{&quot;action&quot;:&quot;trending&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;trending_link_open_source_navbar&quot;}"><span>Trending</span></a></li><li><a href="https://github.com/collections" data-analytics-event="{&quot;action&quot;:&quot;collections&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;collections_link_open_source_navbar&quot;}"><span>Collections</span></a></li></ul></div></li></ul></div></li><li><div><ul><li><div><p><span>ENTERPRISE SOLUTIONS</span></p><ul><li><a href="https://github.com/enterprise" data-analytics-event="{&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}"><div><p><span>Enterprise platform</span><span>AI-powered developer platform</span></p></div></a></li></ul></div></li><li><div><p><span>AVAILABLE ADD-ONS</span></p><ul><li><a href="https://github.com/security/advanced-security" data-analytics-event="{&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;github_advanced_security_link_enterprise_navbar&quot;}"><div><p><span>GitHub Advanced Security</span><span>Enterprise-grade security features</span></p></div></a></li><li><a href="https://github.com/features/copilot/copilot-business" data-analytics-event="{&quot;action&quot;:&quot;copilot_for_business&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;copilot_for_business_link_enterprise_navbar&quot;}"><div><p><span>Copilot for Business</span><span>Enterprise-grade AI features</span></p></div></a></li><li><a href="https://github.com/premium-support" data-analytics-event="{&quot;action&quot;:&quot;premium_support&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;premium_support_link_enterprise_navbar&quot;}"><div><p><span>Premium Support</span><span>Enterprise-grade 24/7 support</span></p></div></a></li></ul></div></li></ul></div></li><li><a href="https://github.com/pricing" data-analytics-event="{&quot;action&quot;:&quot;pricing&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;context&quot;:&quot;pricing&quot;,&quot;location&quot;:&quot;navbar&quot;,&quot;label&quot;:&quot;pricing_link_pricing_navbar&quot;}"><span>Pricing</span></a></li></ul></nav></div>
</react-partial>



        <div>
                


<qbsearch-input data-scope="repo:anthropics/claude-code" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="rH0vQOQeg1gwzla4lJSsQvFj0D_Qtz-PgSk_5Y_TVam8O2smAD3LzjyUQ_pexOzkBTnMPmGhsQLtTB-tWt01Xw" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="anthropics/claude-code" data-current-org="anthropics" data-current-owner="" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-retain-scroll-position="true">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        <div data-view-component="true">        <!-- '"` --><!-- </textarea></xmp> --><form id="code-search-feedback-form" data-turbo="false" action="/search/feedback" accept-charset="UTF-8" method="post">
          <p>We read every piece of feedback, and take your input very seriously.</p>
          
          
          <label for="include_email">Include my email address so I can be contacted</label>
</form></div>
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>


            <div>
              <p><a href="https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Fanthropics%2Fclaude-code%2Fblob%2Fmain%2FCHANGELOG.md" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/anthropics/claude-code/blob/main/CHANGELOG.md&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="29882f8d011f564b96cdd51c2e8191be80c1ffce4259e6db5cf5cad4eb9d78a2" data-analytics-event="{&quot;category&quot;:&quot;Marketing nav&quot;,&quot;action&quot;:&quot;click to go to homepage&quot;,&quot;label&quot;:&quot;ref_page:Marketing;ref_cta:Sign in;ref_loc:Header&quot;}">
                Sign in
              </a>
            </p></div>

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&amp;source=header-repo&amp;source_repo=anthropics%2Fclaude-code" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/anthropics/claude-code/blob/main/CHANGELOG.md&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="29882f8d011f564b96cdd51c2e8191be80c1ffce4259e6db5cf5cad4eb9d78a2" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/blob/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a></p><p>
    <react-partial-anchor>
      <tool-tip id="tooltip-da590ea9-e42a-4065-b766-0be340b60009" for="icon-button-ffc1256c-ad05-44c4-bd04-bdc5b13f2763" popover="manual" data-direction="s" data-type="label" data-view-component="true">Appearance settings</tool-tip>

      <template data-target="react-partial-anchor.template">
        <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.e5c2e144a68844beefef.module.css">
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/appearance-settings.753d458774a2f782559b.module.css">

<react-partial partial-name="appearance-settings" data-ssr="false" data-attempted-ssr="false" data-react-profiling="true">
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>


      </template>
    </react-partial-anchor>
  </p>

          </div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The U.S. Is Funding Fewer Grants in Every Area of Science and Medicine (175 pts)]]></title>
            <link>https://www.nytimes.com/interactive/2025/12/02/upshot/trump-science-funding-cuts.html</link>
            <guid>46355077</guid>
            <pubDate>Mon, 22 Dec 2025 15:49:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/interactive/2025/12/02/upshot/trump-science-funding-cuts.html">https://www.nytimes.com/interactive/2025/12/02/upshot/trump-science-funding-cuts.html</a>, See on <a href="https://news.ycombinator.com/item?id=46355077">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="g-bk-tv6wznjfusIeKg" data-preview-slug="bk-tv6wznjfusIeKg" data-birdkit-hydrate="5f4bbca0a8216398">
			
	<!--[--><!--[--><!----><!----><!--[--><!--[--><!----><!----><!--]--><!--[--><!----><!----><!--]--><!--[--><!----><!--[--><!----><figure><!--[!--><!--]--> <!--[!--><!--]--> <div><!----><!----><!--[!--><!----><svelte-scrollstory id="g-scrollstory_1"><svelte-scroller-outer><svelte-scroller-background-container><svelte-scroller-background><!----><svelte-scrollstory-background slot="background"><!----><div><h3><span><!--[1-->National Institutes of Health competitive grant <span>funding</span><!--]--></span></h3> </div><!----> <!--[!--><!--]--></svelte-scrollstory-background><!----></svelte-scroller-background></svelte-scroller-background-container> <svelte-scroller-foreground><!----><svelte-scrollstory-foreground slot="foreground"><div><!--[!--><!--]--> <!----><!--[--><div id="g-scrollstory_1-item-0"><!----><p><span><!----><!--[--><!---->In the past decade, the National Institutes of Health awarded top scientists $9 billion in <strong>competitive grants</strong> each year, <strong>to find cures for diseases and improve public health</strong>.<p>This year, something unusual happened…</p><!----><!--]--><!----></span><!----></p><!----> <!----><!----></div><div id="g-scrollstory_1-item-1"><!----><p><span><!----><!--[--><!---->Starting in January, the Trump administration stalled that funding. By summer, funding lagged by over $2 billion, or <span><strong>41 percent below average</strong></span>.<!----><!--]--><!----></span><!----></p><!----> <!----><!----></div><div id="g-scrollstory_1-item-2"><!----><p><span><!----><!--[--><!---->But in a surprising turn, the N.I.H. began to spend at a breakneck pace and narrow this gap.<!----><!--]--><!----></span><!----></p><!----> <!----><!----></div><div id="g-scrollstory_1-item-3"><!----><p><span><!----><!--[--><!---->There was a catch, however: That money <span><strong>went to fewer grants.</strong></span> <p>Which means <strong>less research was funded</strong> in areas such as aging, diabetes, strokes, cancer and mental health.</p><!----><!--]--><!----></span><!----></p><!----> <!----><!----></div><!--]--><!----></div></svelte-scrollstory-foreground><!----></svelte-scroller-foreground></svelte-scroller-outer><!----></svelte-scrollstory> <!--[!--><!--]--><!----><!--]--><!----><!----></div><!----> <!--[--><div><!----><!----><!----> <!----><!--[--><p><!---->Includes new grants and competitive grant renewals. In 2025 dollars.<!----></p><!--]--><!----> <!----><!----><!----></div><!--]--><!----></figure><!----><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->To spend its budget, the N.I.H. made an unusual number of large lump-sum payments for many years of research, instead of its usual policy of paying for research one year at a time.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->As a result of this quiet policy shift, the average payment for competitive grants swelled from $472,000 in the first half of the fiscal year to over $830,000 in the last two months.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->While this might sound like a boon for researchers, it’s actually a fundamental shift in how grants are funded — one that means more competition for funding, and less money and less time to do the research.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!----><figure><!--[!--><!--]--> <!--[!--><!--]--> <div><!----><!----><!--[!--><!----><svelte-scrollstory id="g-scrollstory_2"><svelte-scroller-outer><svelte-scroller-background-container><svelte-scroller-background><!----><svelte-scrollstory-background slot="background"><!----><!----> <!--[!--><!--]--></svelte-scrollstory-background><!----></svelte-scroller-background></svelte-scroller-background-container> <svelte-scroller-foreground><!----><svelte-scrollstory-foreground slot="foreground"><div><!--[!--><!--]--> <!----><!--[--><div id="g-scrollstory_2-item-0"><!----><p><span><!----><!--[--><!---->In the past, the N.I.H. typically awarded grants in five annual installments.<!----><!--]--><!----></span><!----></p><!----> <!----><!----></div><div id="g-scrollstory_2-item-1"><!----><p><span><!----><!--[--><!---->Researchers could request two more years to spend this money, at no cost.<!----><!--]--><!----></span><!----></p><!----> <!----><!----></div><div id="g-scrollstory_2-item-2"><!----><p><span><!----><!--[--><!---->Under the new system, the N.I.H. <strong>pays up front for four years</strong> of work.<!----><!--]--><!----></span><!----></p><!----> <!----><!----></div><div id="g-scrollstory_2-item-3"><!----><p><span><!----><!--[--><!---->And researchers can get one more year to spend this money.<!----><!--]--><!----></span><!----></p><!----> <!----><!----></div><div id="g-scrollstory_2-item-4"><!----><p><span><!----><!--[--><!---->Which means that they get <span><strong>less money</strong></span> on average, and <strong>less time</strong> to spend it.<!----><!--]--><!----></span><!----></p><!----> <!----><!----></div><!--]--><!----></div></svelte-scrollstory-foreground><!----></svelte-scroller-foreground></svelte-scroller-outer><!----></svelte-scrollstory> <!--[!--><!--]--><!----><!--]--><!----><!----></div><!----> <!--[!--><!--]--><!----></figure><!----><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->And because these fully funded grants commit all of their money up front, it means the agency’s annual budget is divided into fewer projects, instead of being spread among a larger number of scientific bets.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->The new policy directive came from the White House’s Office of Management and Budget, which in the summer instructed the N.I.H. to spend half of its remaining funds to fully fund research grants. In the past, the agency would do so only in special circumstances.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->The White House has said this would “<a href="https://officeofbudget.od.nih.gov/pdfs/FY26/NIH%20FY%202026%20CJ%20Overview.pdf">increase N.I.H. budget flexibility</a>” by not encumbering its annual budget with payments to previously approved projects. It has said it plans to <a href="https://officeofbudget.od.nih.gov/pdfs/FY26/NIH%20FY%202026%20CJ%20Overview.pdf">continue this policy</a> in 2026, while proposing to shrink the agency’s budget <a href="https://officeofbudget.od.nih.gov/pdfs/FY26/NIH%20FY%202026%20CJ%20Overview.pdf">by $18 billion</a>, or <a href="https://www.aau.edu/newsroom/leading-research-universities-report/white-house-proposes-steep-cuts-science-and-education">nearly 40 percent</a>. (The <a href="https://www.science.org/content/article/boost-nih-budget-senate-panel-rejects-trump-s-plan-slash-agency">Senate</a> and <a href="https://www.science.org/content/article/house-republicans-add-support-maintaining-nih-budget-2026">House</a> rejected the White House’s proposed budget cuts, but have not yet agreed on the agency’s budget.)<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->“My sense of it was that the administration wanted to clear the decks,” said Sarah Kobrin, a branch chief at the N.I.H.’s National Cancer Institute, who said she was sharing her views, not those of the institute.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->The new policy is being carried out as the Trump administration has tightened its hold over federal science funding. Earlier this year, it delayed reviewing grants in order to vet research by political appointees, culled projects that mentioned D.E.I. and fired thousands of employees or pressured them to retire early. (The N.I.H. lost <a href="https://www.nytimes.com/interactive/2025/10/01/us/trump-government-shutdown-federal-cuts.html">nearly 3,000 employees</a> this year, or about 14 percent of its work force, based on a New York Times review of the agency’s shutdown contingency plans.)<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->“They brought everything to a stop,” Dr. Kobrin said.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->Nonetheless, the N.I.H. managed to <a href="https://www.statnews.com/2025/09/12/nih-spending-47-billion-budget/">spend most of its budget</a> by the end of the fiscal year. “My colleagues did an outstanding job to work their butts off to approve things,” said Theresa Kim, a program officer at N.I.H.’s National Institute on Aging.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->Something similar happened at the National Science Foundation, which is the second-largest federal funder of research at U.S. universities, after the N.I.H.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->The N.S.F. started the year with funding delays caused by the Trump administration, and it lost about a third of its employees in layoffs or forced retirements. The agency ended the year awarding 25 percent fewer new grants.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!----><figure><!--[--><div><!----><!----><!----> <!----><!--[--><p><!--[--><h3><!---->New grants awarded by the National Science Foundation, 2015–25<!----></h3><!--]--> <!--[!--><!--]--></p><!--]--><!----> <!----><!----><!----></div><!--]--> <!--[!--><!--]--> <div><p><label> <span>Number of grants</span></label><label> <span>Funding amount</span></label></p><!---->  <!--[!--><!--]--><!----></div><!----> <!--[!--><!--]--><!----></figure><!----><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->Facing a proposed <a href="https://nsf-gov-resources.nsf.gov/files/00-NSF-FY26-CJ-Entire-Rollup.pdf">$5 billion cut</a> to its $9 billion budget, the N.S.F. fully paid off many of the grants that were on its books, a strategy that employees called “paying down the mortgage.” It also paid for nearly all new awards upfront (though, unlike at the N.I.H., not necessarily for less time and money).<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->To draw these conclusions, The Times used public data to analyze nearly every competitive grant — over 300,000 in all — that the N.I.H. and the N.S.F. awarded since 2015, and interviewed many employees at these agencies.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->Here’s what we found:<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!----><!--]--><!--[--><!----><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->Together, the N.I.H. and the N.S.F. had a nearly $60 billion annual budget for funding future breakthroughs in science and medicine, about a quarter of which is typically spent on new grants or competitive renewals.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->This year, both agencies made far fewer competitive awards:<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!----><figure><!--[--><div><!----><!----><!----> <!----><!--[--><p><!--[--><h3><!---->Competitive grants at the …<!----></h3><!--]--> <!--[!--><!--]--></p><!--]--><!----> <!----><!----><!----></div><!--]--> <!--[!--><!--]--> <div><!----><!----><!--[!--><!----><br> <div><div><h3>National Institutes of Health</h3> <!----></div> <div><h3>National Science Foundation</h3> <!----></div></div><!----><!--]--><!----><!----></div><!----> <!--[!--><!--]--><!----></figure><!----><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->The White House has said it is streamlining scientific funding by <a href="https://www.whitehouse.gov/presidential-actions/2025/02/radical-transparency-about-wasteful-spending/">eliminating wasteful spending</a> and cutting “<a href="https://www.whitehouse.gov/wp-content/uploads/2025/05/Cuts-to-Woke-Programs-Fact-Sheet.pdf">woke programs</a>” that “<a href="https://www.whitehouse.gov/wp-content/uploads/2025/05/Cuts-to-Woke-Programs-Fact-Sheet.pdf">poison the minds of Americans</a>.”<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->But the more than 3,500 fewer competitive grants from the N.I.H. this year touched every area of biology and medicine:<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!----><figure><!--[--><div><!----><!----><!----> <!----><!--[--><p><!--[--><h3><!---->Competitive grants awarded by the National Institutes of Health<!----></h3><!--]--> <!--[!--><!--]--></p><!--]--><!----> <!----><!----><!----></div><!--]--> <!--[!--><!--]--> <!----> <!--[--><div><!----><!----><!----> <!----><!--[--><p><!---->Figures are rounded. In 2025 dollars.<!----></p><!--]--><!----> <!----><!----><!----></div><!--]--><!----></figure><!----><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->In practice, this means thousands of very competitive projects in areas like cancer, diabetes, aging, neurological disorders and public health improvements probably went unfunded in 2025.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->Similarly, at the National Science Foundation, the roughly 3,000 fewer new grants encompassed reductions to every area of science (and the social sciences):<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!----><figure><!--[--><div><!----><!----><!----> <!----><!--[--><p><!--[--><h3><!---->New grants awarded by the National Science Foundation<!----></h3><!--]--> <!--[!--><!--]--></p><!--]--><!----> <!----><!----><!----></div><!--]--> <!--[!--><!--]--> <div><p><label> <span>Number of grants</span></label><label> <span>Funding amount</span></label></p><!----> <table><thead><tr><th>Directorate</th><th>2015-24 avg.</th><th>2025</th><th>Change</th></tr></thead><tbody><!--[--><tr><td><!--[--><a href="https://www.nsf.gov/awardsearch/search-results?BooleanElement=All&amp;BooleanRef=All&amp;awardDateFrom=2024-10-01&amp;awardDateOperator=Range&amp;awardDateTo=2025-09-30&amp;expiredAwards=true&amp;nsforganization=04000000&amp;sortBy=date" target="_blank" rel="noreferrer">Social, behavioral and economic sciences</a><!--]--></td><td>935</td><td>501</td><td>-46%</td></tr><tr><td><!--[--><a href="https://www.nsf.gov/awardsearch/search-results?BooleanElement=All&amp;BooleanRef=All&amp;awardDateFrom=2024-10-01&amp;awardDateOperator=Range&amp;awardDateTo=2025-09-30&amp;expiredAwards=true&amp;nsforganization=08000000&amp;sortBy=date" target="_blank" rel="noreferrer">Biology</a><!--]--></td><td>1,143</td><td>735</td><td>-36%</td></tr><tr><td><!--[--><a href="https://www.nsf.gov/awardsearch/search-results?BooleanElement=All&amp;BooleanRef=All&amp;awardDateFrom=2024-10-01&amp;awardDateOperator=Range&amp;awardDateTo=2025-09-30&amp;expiredAwards=true&amp;nsforganization=06000000&amp;sortBy=date" target="_blank" rel="noreferrer">Geosciences</a><!--]--></td><td>1,483</td><td>964</td><td>-35%</td></tr><tr><td><!--[--><a href="https://www.nsf.gov/awardsearch/search-results?BooleanElement=All&amp;BooleanRef=All&amp;awardDateFrom=2024-10-01&amp;awardDateOperator=Range&amp;awardDateTo=2025-09-30&amp;expiredAwards=true&amp;nsforganization=11000000&amp;sortBy=date" target="_blank" rel="noreferrer">STEM education</a><!--]--></td><td>1,087</td><td>758</td><td>-30%</td></tr><tr><td><!--[--><a href="https://www.nsf.gov/awardsearch/search-results?BooleanElement=All&amp;BooleanRef=All&amp;awardDateFrom=2024-10-01&amp;awardDateOperator=Range&amp;awardDateTo=2025-09-30&amp;expiredAwards=true&amp;nsforganization=05000000&amp;sortBy=date" target="_blank" rel="noreferrer">Computer science</a><!--]--></td><td>2,017</td><td>1,459</td><td>-28%</td></tr><tr><td><!--[--><a href="https://www.nsf.gov/awardsearch/search-results?BooleanElement=All&amp;BooleanRef=All&amp;awardDateFrom=2024-10-01&amp;awardDateOperator=Range&amp;awardDateTo=2025-09-30&amp;expiredAwards=true&amp;nsforganization=07000000&amp;sortBy=date" target="_blank" rel="noreferrer">Engineering</a><!--]--></td><td>1,755</td><td>1,461</td><td>-17%</td></tr><tr><td><!--[--><a href="https://www.nsf.gov/awardsearch/search-results?BooleanElement=All&amp;BooleanRef=All&amp;awardDateFrom=2024-10-01&amp;awardDateOperator=Range&amp;awardDateTo=2025-09-30&amp;expiredAwards=true&amp;nsforganization=03000000&amp;sortBy=date" target="_blank" rel="noreferrer">Math and physics</a><!--]--></td><td>2,512</td><td>2,094</td><td>-17%</td></tr><tr><td><!--[--><a href="https://www.nsf.gov/awardsearch/search-results?BooleanElement=All&amp;BooleanRef=All&amp;awardDateFrom=2024-10-01&amp;awardDateOperator=Range&amp;awardDateTo=2025-09-30&amp;expiredAwards=true&amp;nsforganization=15000000&amp;sortBy=date" target="_blank" rel="noreferrer">Technology and innovation</a><!--]--></td><td>757</td><td>657</td><td>-13%</td></tr><tr><td><!--[--><a href="https://www.nsf.gov/awardsearch/search-results?BooleanElement=All&amp;BooleanRef=All&amp;awardDateFrom=2024-10-01&amp;awardDateOperator=Range&amp;awardDateTo=2025-09-30&amp;expiredAwards=true&amp;nsforganization=01000000&amp;sortBy=date" target="_blank" rel="noreferrer">Office of the director</a><!--]--></td><td>132</td><td>205</td><td>+55%</td></tr><!--]--></tbody><!--[!--><!--]--><tfoot><tr><td>Total</td><td>11,821</td><td>8,834</td><td>-25%</td></tr></tfoot></table><!----></div><!----> <!--[--><div><!----><!----><!----> <!----><!--[--><p><!---->Figures are rounded. In 2025 dollars. Table includes only directorates with spending in 2025.<!----></p><!--]--><!----> <!----><!----><!----></div><!--]--><!----></figure><!----><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->There were fewer new grants awarded in biology, geosciences, STEM education, computer science and engineering, math, physics, technology and innovation.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->Only the office of the director awarded more new grants this year; it funds projects that don’t neatly fall into other categories. That growth was fueled by a previously established N.S.F. goal to expand fellowships at universities in regions that have historically received less federal funding.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->The Trump administration has also taken the unusual step of <a href="https://www.nytimes.com/interactive/2025/06/04/health/trump-cuts-nih-grants-research.html">canceling thousands of active health and science grants</a>, citing a lack of overlap with its priorities.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->“The N.I.H. is no longer directing resources toward science shaped by political or social pressures; instead, we have adopted a proactive, science-driven approach with clearly defined priorities focused on researching chronic health problems, identifying root causes, and advancing research grounded in scientifically valid, measurable health outcomes,” said Andrew Nixon, Health and Human Services  communications director.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->The website <a href="https://grant-witness.us/">Grant Witness</a> has estimated that the administration canceled or froze <a href="https://grant-witness.us/nih-data.html">5,415 N.I.H. grants</a> this year, of which roughly half have been reinstated through court cases or negotiations where universities have agreed to some of the administration’s demands. And it canceled or froze <a href="https://grant-witness.us/nsf-data.html">1,996 N.S.F. grants</a>, of which nearly a third have been reinstated, according to Grant Witness estimates.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!----><!--]--><!--[--><!----><p><h2><!---->2. More competition<!----></h2></p><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->It’s simple math: Fewer grants implies more competition for federal funding.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->Take the category of research grants known as <a href="https://www.nibib.nih.gov/programs/nih-research-project-grant-program-r01">R01</a>, the oldest and most prestigious grant that the N.I.H. awards. An acceptance or rejection can make or break a scientist’s career.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->These grants fund topics such as studying the impact of <a href="https://reporter.nih.gov/search/PyiStBhPBE28e9kgpzG53w/project-details/11224219">e-cigarettes on brain health</a>, <a href="https://reporter.nih.gov/search/PyiStBhPBE28e9kgpzG53w/project-details/10931983">modeling the movements of mice</a>, or <a href="https://reporter.nih.gov/search/PyiStBhPBE28e9kgpzG53w/project-details/11104898">devising new methods to kill mosquitoes</a>.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->Last year, only <a href="https://report.nih.gov/nihdatabook/report/202">one in six</a> was funded. But this year, the agency awarded 24 percent fewer R01 grants.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!----><figure><!--[--><div><!----><!----><!----> <!----><!--[--><p><!--[--><h3><!---->R01 grants awarded by the National Institutes of Health<!----></h3><!--]--> <!--[!--><!--]--></p><!--]--><!----> <!----><!----><!----></div><!--]--> <!--[!--><!--]--> <!----> <!--[!--><!--]--><!----></figure><!----><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->This means fewer scientists had their research funded. Last year, the N.I.H.’s National Cancer Institute funded R01 applications from new investigators that fell in the <a href="https://www.cancer.gov/grants-training/nci-bottom-line-blog/2024/nci-fy-2024-appropriation-brings-clarity-and-difficult-choices#:~:text=we%20can%20now%20set%20the%20payline%20for%20competing%20R01%20and%20R21%20grants%20to%20established%20and%20new%20investigators%20at%20the%2010th%20percentile">top 10 percent</a> based on scoring by the agency. But by the end of fiscal year 2025, it funded only the <a href="https://www.cancer.gov/grants-training/grants-funding/funding-strategy/current-funding-policy#:~:text=we%20expect%20to%20fund%20through%20the%204th%20percentile">top 4 percent</a>.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->“Nobody believes that a fourth-percentile and a fifth-percentile grant are clearly of different quality,” Dr. Kobrin said. “It’s just not that precise a measurement.”<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!----><!--]--><!--[--><!----><p><h2><!---->3. A drop in grants mentioning diversity<!----></h2></p><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->The Trump administration has prioritized eliminating research that involves <a href="https://www.whitehouse.gov/wp-content/uploads/2025/05/Cuts-to-Woke-Programs-Fact-Sheet.pdf">diversity, equity and inclusion</a>, and has <a href="https://www.nytimes.com/interactive/2025/03/07/us/trump-federal-agencies-websites-words-dei.html">eliminated hundreds of keywords</a> related to diversity on federal websites.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->A Times analysis found a steep reduction in the share of competitive N.I.H. grants whose titles or abstracts included flagged D.E.I.-related keywords (such as “equity,” “racial minority” or “underserved patient”) on a list shared by N.I.H. employees.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!----><figure><!--[--><div><!----><!----><!----> <!----><!--[--><p><!--[--><h3><!---->Share of competitive N.I.H. grants that included flagged D.E.I.-related keywords<!----></h3><!--]--> <!--[!--><!--]--></p><!--]--><!----> <!----><!----><!----></div><!--]--> <!--[!--><!--]--> <!----> <!--[!--><!--]--><!----></figure><!----><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->The data shows a big surge in these keywords after 2020, during the Biden administration.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->While some of the decline in 2025 could be attributed to a change in the language that researchers use to describe their work, it also probably reflects a drop in research related to minority health. For example, the <a href="https://www.nimhd.nih.gov/">National Institute on Minority Health and Health Disparities</a> awarded 61 percent fewer competitive grants this year, the steepest decline at any arm of the N.I.H.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->N.I.H. employees said they did not receive clear guidance on how to determine if a project was D.E.I.-related. Instead, they were sent spreadsheets of grants that had been flagged for not complying with the Trump administration’s priorities.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->“We’re constantly hearing that things have been flagged,” Dr. Kobrin said.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->“Nobody wants to acknowledge what they were flagged for.”<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!----><!--]--><!--[--><!----><p><h2><!---->4. Fewer fellowships for future scientists<!----></h2></p><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->The government provides critical funds for training new scientists through graduate student, postdoctoral and early-career fellowships and grants.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->The N.S.F. has run a prestigious <a href="https://www.nsfgrfp.org/">graduate research fellowship program</a> since 1952. It funds three years of research for around 2,000 of the country’s top science graduate students.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!----><figure><!--[--><div><!----><!----><!----> <!----><!--[--><p><!--[--><h3><!---->Number of graduate research fellowships awarded by the National Science Foundation<!----></h3><!--]--> <!--[!--><!--]--></p><!--]--><!----> <!----><!----><!----></div><!--]--> <!--[!--><!--]--> <!----> <!--[!--><!--]--><!----></figure><!----><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->This year, it awarded 536 fewer such fellowships. The government <a href="https://www.science.org/content/article/nsf-slashes-graduate-fellowship-program">originally planned</a> to eliminate 1,000 fellowships, but later <a href="https://cen.acs.org/policy/research-funding/NSF-names-504-new-graduate/103/web/2025/06">added about 500 more</a> after facing protests from scientists and academics.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->The cut affected most fields, with fellowships in four areas — life sciences, psychology, STEM education and social sciences — being cut by more than half. Fellowships in computer science, an administration priority, grew by almost 50 percent.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!----><figure><!--[--><div><!----><!----><!----> <!----><!--[--><p><!--[--><h3><!---->National Science Foundation graduate research fellowships<!----></h3><!--]--> <!--[!--><!--]--></p><!--]--><!----> <!----><!----><!----></div><!--]--> <!--[!--><!--]--> <div><!----><!----><!--[!--><!----><table><thead><tr><th>Field</th><th>2015-24 avg.</th><th>2025</th><th>Change</th></tr></thead><tbody><!--[--><tr><td><!--[!-->Life sciences<!--]--></td><td>516</td><td>214</td><td>-59%</td></tr><tr><td><!--[!-->Psychology<!--]--></td><td>117</td><td>56</td><td>-52%</td></tr><tr><td><!--[!-->STEM education<!--]--></td><td>29</td><td>14</td><td>-52%</td></tr><tr><td><!--[!-->Social sciences<!--]--></td><td>159</td><td>79</td><td>-50%</td></tr><tr><td><!--[!-->Math<!--]--></td><td>90</td><td>56</td><td>-38%</td></tr><tr><td><!--[!-->Geosciences<!--]--></td><td>122</td><td>84</td><td>-31%</td></tr><tr><td><!--[!-->Engineering<!--]--></td><td>575</td><td>406</td><td>-29%</td></tr><tr><td><!--[!-->Chemistry<!--]--></td><td>176</td><td>154</td><td>-13%</td></tr><tr><td><!--[!-->Materials research<!--]--></td><td>58</td><td>63</td><td>+9%</td></tr><tr><td><!--[!-->Physics<!--]--></td><td>139</td><td>166</td><td>+19%</td></tr><tr><td><!--[!-->Computer science<!--]--></td><td>141</td><td>208</td><td>+48%</td></tr><!--]--></tbody><!--[!--><!--]--><tfoot><tr><td>Total</td><td>2,121</td><td>1,500</td><td>-29%</td></tr></tfoot></table><!----><!--]--><!----><!----></div><!----> <!--[--><div><!----><!----><!----> <!----><!--[--><p><!---->Figures are rounded.<!----></p><!--]--><!----> <!----><!----><!----></div><!--]--><!----></figure><!----><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->There were also <a href="https://www.science.org/content/article/delays-uncertainty-plague-nsf-fellowship-graduate-students">months of delays</a> in publishing the fellowship application for next year, and new <a href="https://www.science.org/content/article/completely-shattered-changes-nsf-s-graduate-student-fellowship-spur-outcry">eligibility restrictions</a> that exclude second-year Ph.D. students from applying, which may lower the numbers of fellowships in future years.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->“This is an incredibly shortsighted and regressive change,” said Kevin Johnson, a former program director at N.S.F.’s geosciences directorate, because second-year graduate students are usually better prepared to conduct research.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->“It sends a signal to future potential applicants that science is not supported and is not valued,” he said.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->Early-career scientists are usually more reliant on federal funding because they have few alternatives to fund their research and training. Many go on to work in industry afterward, further fueling the economy.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->In a <a href="https://nsf-gov-resources.nsf.gov/2023-04/EndlessFrontier75th_w.pdf">1945 report</a> that <a href="https://www.nsf.gov/about/history#:~:text=In%201945%2C%20Bush,National%20Science%20Board.">led to the creation</a> of the N.S.F., Vannevar Bush, who directed military research and development during World War II, argued that the government should invest in training the next generation of scientists to ensure American scientific progress.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->But many experts worry that the recent funding cuts and budget reductions may threaten America’s role as a global scientific leader.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!--[--><!--[!--><!----><p><!--[--><!---->“I personally know many scientists in my field leaving the United States altogether,” Mr. Johnson said.<!----><!--]--><!----></p><!----><!--]--><!--]--><!----><!--]--><!--[--><!----><!----><figure><!--[!--><!--]--> <!--[!--><!--]--> <div><!--[--><p>About the Data</p><!--]--> <!--[--><!--[--><!--[!--><!----><p><!--[--><!---->For grants from the National Institutes of Health, we downloaded data from <a href="https://reporter.nih.gov/">N.I.H. RePORTER</a> from fiscal year 2015 onward, and filtered out intramural projects, R&amp;D contracts, interagency agreements, subprojects and grants administered by other entities. We looked only at grants labeled as new (type 1) or competitive renewals (type 2, 4C and 9) that were awarded during the fiscal year. (We did not include noncompetitive renewal grants, which are ongoing annual payments to research awarded in past years.)<!----><!--]--><!----></p><!----><!--]--><!--[!--><!----><p><!--[--><!---->For grants from the National Science Foundation, we downloaded data from the N.S.F.’s <a href="https://www.nsf.gov/awardsearch/download-awards/">award search</a> website from fiscal year 2015 onward. We analyzed both standard grants, where all of the money is committed up front, and continuing grants, where the money is paid in annual increments. (We did not include annual payments made to grants that were awarded in prior years.) For grants that were awarded in past years, we used <a href="http://usaspending.gov/">USASpending.gov</a> to identify when each grant was awarded. Data for the graduate research fellowship program was retrieved from <a href="https://www.research.gov/grfp/AwardeeList.do?method=loadAwardeeList">the program’s award listing</a>.<!----><!--]--><!----></p><!----><!--]--><!--[!--><!----><p><!--[--><!---->All dollar figures are adjusted to August 2025 dollars, and the data is updated as of Nov. 25, 2025.<!----><!--]--><!----></p><!----><!--]--><!--]--><!--]--></div><!----> <!--[!--><!--]--><!----></figure><!----><!----><!--]--><!--]--><!----><!----><!----><!--]--> <!--[!--><!--]--><!--]-->
			
			
		

		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scaling LLMs to Larger Codebases (158 pts)]]></title>
            <link>https://blog.kierangill.xyz/oversight-and-guidance</link>
            <guid>46354970</guid>
            <pubDate>Mon, 22 Dec 2025 15:38:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.kierangill.xyz/oversight-and-guidance">https://blog.kierangill.xyz/oversight-and-guidance</a>, See on <a href="https://news.ycombinator.com/item?id=46354970">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
<p>How do we scale LLMs to larger codebases? Nobody knows yet. But by understanding how <a href="https://blog.kierangill.xyz/ai-strengths-and-limitations-in-engineering.html">LLMs contribute to engineering</a>, we realize that investments in <em>guidance</em> and <em>oversight</em> are worthwhile.</p>
<ul>
<li><strong>Guidance</strong>: The context, the environment.</li>
<li><strong>Oversight</strong>: The skill set needed to guide, validate, and verify the implementor's<sup id="fnref:1"><a href="#fn:1">1</a></sup> <em>choices</em>.</li>
</ul>
<h2>Investing in guidance</h2>
<p>When an LLM can generate a working high-quality implementation in a single try, that is called <strong>one-shotting</strong>. This is the most efficient form of LLM programming.</p>
<p><img src="https://blog.kierangill.xyz/images/guidance-and-oversight-target-hitting.webp" alt="An arrow hitting the center of a dart board.">
</p>

<p>The opposite of one-shotting is rework. This is when you fail to get a usable output from the LLM and must manually intervene.<sup id="fnref:2"><a href="#fn:2">2</a></sup> This often takes longer than just doing the work yourself.</p>
<p><img src="https://blog.kierangill.xyz/images/guidance-and-oversight-target-missing.webp" alt="Multiple arrows on a dart board. They have all missed the center.">
</p>

<p>So how do we create more opportunities for one-shotting? Better guidance.</p>
<h3>Better guidance</h3>
<p>LLMs are choice generators. Every set of tokens is a choice added to your codebase: how a variable is named, where to organize a function, whether to reuse/extend/or duplicate functionality to solve a problem, whether Postgres should be chosen over Redis, and so on.</p>
<p>Often, these choices are best left up to the designer (e.g., via the prompt). However, it's not efficient to exhaustively list all of these choices in a prompt. It's also not efficient to rework an LLM output whenever it gets these choices wrong.</p>
<p>In the ideal world, the prompt only captures the business requirements of a feature. The rest of the choices are either inferrable or encoded.</p>
<h4>Write a prompt library</h4>
<p>A prompt library is a set of documentation that can be included as context for an LLM. </p>
<p>Writing this is simple: collate documentation, best practices, a general map of the codebase, and other context an engineer needs to be productive in <em>your</em> codebase.<sup id="fnref:3"><a href="#fn:3">3</a></sup> </p>
<p>Making a prompt library useful requires iteration. Every time the LLM is slightly off target, ask yourself, "What could've been clarified?" Then, add that answer back into the prompt library.</p>
<p>A prompt library needs to strike the right balance between <em>comprehensive</em> and <em>lean</em>.</p>


<h4>The environment is your context</h4>
<p>A peer at Meta told me that they weren't in a position to make Zuckerberg's <a href="https://www.forbes.com/sites/quickerbettertech/2025/01/26/business-tech-news-zuckerberg-says-ai-will-replace-mid-level-engineers-soon/">engineering automation claims</a> a reality. The reason is their codebase is riddled with technical debt. He wasn't surprised by this. Meta (apparently) historically has not prioritized paying down their debts. </p>

<p>Compare this to the mentality from the <a href="https://youtu.be/BGgsoIgbT_Y?si=vsIrpQVQquas6PYH&amp;t=988">Cursor team</a>:</p>
<blockquote>
<p>I think ultimately the principles of clean software are not that different when you want it to be read by people and by models. When you are trying to write clean code you want to, not repeat yourself, not make things more complicated than they need to be.</p>
<p>I think taste in code... is actually gonna become even more important as these models get better because it will be easier to write more and more code and so it'll be more and more important to structure it in a tasteful way.</p>
</blockquote>
<p>This is the <em>garbage in, garbage out</em> principle in action. The utility of a model is bottlenecked by its inputs. The more garbage you have, the more likely hallucinations will occur.</p>
<p>Here's a LLM literacy dipstick: ask a peer engineer to read some code they're unfamiliar with. Do they understand it? Do they struggle to navigate it? If it's a module, can they quickly understand what all that module exposes? Do they know the implications of using a certain function, the side-effects they must be aware of? No? Then the LLM won't either.</p>
<p>Here's another dipstick: Ask an LLM agent to tell you how certain functionality works. You should know the answer before asking the LLM. Is their answer right? More importantly, how did they go about answering your question? Follow the LLM's trail and document its snags. You'll notice it tends to <code>grep</code>, <code>ls</code>, and <code>cat</code> to search. How can you give it a map so it isn't left to rediscover the codebase on each new prompt? When a map can't be given, how do you make it easier for them to navigate the codebase?</p>
<p>How you make the environment better suited for LLM literacy is dependent on the tech stack and domain. But general principles apply: modularity, simplicity, things are well-named, logic is encapsulated. Be consistent and encode these conventions in your prompt library.</p>

<h2>Investing in oversight</h2>
<p>We need guidance <em>and</em> oversight. A 3-ton truck with a middle-schooler behind the wheel puts people in the hospital (and in jail). This is why the mentality of automating engineers is objectionable. We should be fostering our teams, not discarding them.</p>
<p>Remember, engineers operate on <a href="https://blog.kierangill.xyz/ai-strengths-and-limitations-in-engineering.html">two timelines</a>. As overseers of implementation, we must plan for the future of the codebase. If an LLM makes a choice, the overseer should be able to discern whether it was a good one or a bad one. For example, let's say the LLM opted to use Redis over Postgres to store some metadata. Was that a good choice? The overseer should know.</p>
<p>An investment in oversight is an investment in <strong>team</strong>, <strong>alignment</strong>, and <strong>workflows</strong>.</p>
<p>For <em>team</em>, it's worth investing in elevating everyone's design capabilities.</p>
<p>Design produces architecture. Architecture is a bet on the future. It's a bet that by setting up a program in a certain way, it will make the future feature development easier.</p>
<p>Architects are often created through experience. A career of shooting yourself in the foot builds intuition. This intuition shapes new software from having the same mistakes.</p>
<details>
<summary><strong>Aside</strong>: Some thoughts on how to grow design skills</summary>
<p>Read books, blogs, and code. Watch conference talks. Replicate masterworks. Practice by writing programs that you don't know how to build.</p>
<p>On replicating masterworks:</p>
<ul>
<li>Student artists are often required to replicate masterworks. A masterwork is an art piece that an expert artist made. Through the process of replicating this masterwork, an artist gains practical experience at the bleeding edge of art. (This experience also builds confidence, which is a bonus.)</li>
<li>The same is true for engineering. I've learned more by <a href="https://interpreterbook.com/">writing a programming language</a> than I have in reading a hundred blog posts.</li>
<li>Why does this work?<ul>
<li>You understand a layer of abstraction deeper than the layer you're working at (this is a Cantrill-ism, but I can't find the quote). </li>
<li>Masters use techniques and workflows that are best learned via practice. Thorsten Ball taught me how to break down large problems into tractable phases. Each phase had a contract and each contract could be tested.</li>
</ul>
</li>
</ul>
<p>On reading code:</p>
<ul>
<li>A good way to expand your vocabulary of solutions.</li>
<li>In Steve Ruiz's V1 of <a href="https://www.tldraw.com/">TLDraw</a>, I learned the <a href="https://github.com/tldraw/tldraw/blob/v1.6.1/packages/tldraw/src/state/sessions/DrawSession/DrawSession.ts">patterns</a> necessary to later implement session-based undo/redo for an internal tool at work.</li>
<li>Reading <a href="https://github.com/SerenityOS/jakt/blob/d792ad5029a8a7f5385bbdf7d404240692975f74/selfhost/parser.jakt">code from leaders in the field</a> is also a good way to build taste. </li>
</ul>
</details>
<p>Oversight is not only about architecture, but also <a href="https://engineering.blueberrypediatrics.blog/candidate-evaluation-rigor-urgency">temperament</a>, <a href="https://engineering.blueberrypediatrics.blog/candidate-evaluation-framework">alignment to values</a>, and <a href="https://engineering.blueberrypediatrics.blog/sequencing-for-value">workflows</a>. Operators need to be both technical and product experts. Without a deep understanding of the product, it's easy to accidentally build the wrong solution.</p>
<h3>Automating oversight</h3>
<p>Some design concerns can be checked programmatically. </p>
<p>Moving more implementation feedback from human to computer helps us improve the chance of one-shotting. Agents can get feedback directly from their environment (e.g., type errors).</p>
<p>Think of these as bumper rails. You can increase the likelihood of an LLM reaching the bowling pins by making it impossible to land in the gutter.</p>
<p>One way to do this is through writing <strong>safety</strong> checks. But what is safety? Safety is <em>protecting your abstractions</em>. Pierce's <a href="https://www.cis.upenn.edu/~bcpierce/tapl/">Types and Programming Languages</a> has my favorite definition of safety:</p>
<blockquote>
<p>Informally, though, safe languages can be defined as ones that make it impossible to shoot yourself in the foot while programming.</p>
<p>Refining this intuition a little, we could say that a safe language <em>is one that protects its own abstractions</em>.</p>
<p>Safety refers to the language's ability to guarantee the integrity of these abstractions and of higher-level abstractions introduced by the programmer using the definitional facilities of the language. For example, a language may provide arrays, with access and update operations, as an abstraction of the underlying memory. A programmer using this language then expects that an array can be changed only by using the update operation on it explicitly—and not, for example, by writing past the end of some other data structure.</p>
</blockquote>
<p>We tend to write tests for business-logic but don't always write tests for architecture-logic. Some programming languages have facilities for this built in.</p>

<h2>Addressing verification</h2>
<p><img src="https://blog.kierangill.xyz/images/llms-in-software-engineering-cycle.webp" alt="A very simplified graphic for the design / implementation / verification cycle">
</p>

<p>Design and implementation are only two pieces of a project's lifecycle. <em>Verification</em>, like code review or QA, are necessary for building quality software.</p>
<p>As the volume of work increases, our ability to ship that work becomes constrained by our ability to review it.</p>
<p>Here are some incomplete ideas for addressing the verification bottleneck:</p>
<ul>
<li>Lowering the barrier of entry to perform manual QA (not needing a dev env).</li>
<li>Invest in a testing setup that makes it easy to express tests (including setting up tests, e.g., with test data creation) with minimal code. </li>
<li>Encode frequent PR feedback into documentation so that there is some level of PR review an LLM can reasonably do.</li>
<li>Security is baked in as defaults in the framework, not context.</li>
</ul>
<h2>That's it, for now</h2>
<p>This was the third part of a series on LLMs in software engineering.</p>
<p>First we learned <a href="https://blog.kierangill.xyz/how-hype-works.html">what LLMs and genetics have in common</a>. <sup> (part 1)</sup> LLMs don't simply improve all facets of engineering. Understanding <a href="https://blog.kierangill.xyz/ai-strengths-and-limitations-in-engineering.html">which areas LLMs do improve</a><sup> (part 2)</sup> is important for knowing <a href="https://blog.kierangill.xyz/oversight-and-guidance.html">how to focus our investments</a>.<sup> (part 3)</sup></p>
<hr>


    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The biggest CRT ever made: Sony's PVM-4300 (191 pts)]]></title>
            <link>https://dfarq.homeip.net/the-biggest-crt-ever-made-sonys-pvm-4300/</link>
            <guid>46353777</guid>
            <pubDate>Mon, 22 Dec 2025 12:54:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dfarq.homeip.net/the-biggest-crt-ever-made-sonys-pvm-4300/">https://dfarq.homeip.net/the-biggest-crt-ever-made-sonys-pvm-4300/</a>, See on <a href="https://news.ycombinator.com/item?id=46353777">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Move over, GE Widescreen 1000. In 1989 in Japan, Sony introduced to the largest Trinitron CRT ever built, the KV-45ED1, also known as the PVM-4300. And in 1990, they imported 20 of them to the United States, just in time for the recession. About 34 years later, one of these enigmatic TVs surfaced.</p><h2>Sony’s PVM-4300/KV-45ED1</h2><figure id="attachment_35264" aria-describedby="caption-attachment-35264"><a href="https://dfarq.homeip.net/the-biggest-crt-ever-made-sonys-pvm-4300/sony_pvm_4300/" rel="attachment wp-att-35264"><img data-recalc-dims="1" fetchpriority="high" decoding="async" src="https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2024/06/Sony_PVM_4300.jpg?resize=300%2C209&amp;ssl=1" alt="The Sony PVM-4300, next to a 29-inch TV" width="300" height="209" srcset="https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2024/06/Sony_PVM_4300.jpg?resize=300%2C209&amp;ssl=1 300w, https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2024/06/Sony_PVM_4300.jpg?w=607&amp;ssl=1 607w" sizes="(max-width: 300px) 100vw, 300px"></a><figcaption id="caption-attachment-35264">The Sony PVM-4300 was the largest CRT TV ever made. Its 45-inch tube provided 43 inches of visible improved definition TV. It stood about 27 inches tall.</figcaption></figure><p>Sony’s part number suggests it has a 45 inch tube inside. But in a rare case of truth in advertising, Sony advertised it as a 43-inch model. It weighed about 450 pounds, stood about 27 inches tall, and it wouldn’t fit through a standard door frame. That’s probably okay, it’s not like someone was going to use this as a bedroom TV. This thing was going in your living room.</p><p>In Japan, it sold for 2.6 million yen, but in the United States, it retailed for $40,000, a significant markup. To be fair, shipping them across the Atlantic and then throughout the United States must have been expensive. And news articles in 1990 said Sony dealers would not allow any bickering. They would throw in a couple of options like the separate tuner or speakers. But no discounts.</p><p>Sony said at the time they hoped to sell 80 of them that year, but the recession may have kept that from happening.</p><h2>The biggest conventional CRT ever</h2><p>The Sony PVM-4300 was a conventional CRT, unlike the <a href="https://dfarq.homeip.net/ge-widescreen-1000/">GE Widescreen 1000</a>, which was a projection set. Projection TVs could be bigger and cheaper. But if you wanted the clearest picture, a big CRT was where it was at.</p><p>It was a conventional CRT that worked with over the air signals, but like many larger TVs of the era, it used a technology called IDTV to enhance the picture quality. The “ID” stood for “improved definition.” IDTV sets had a buffer so they would store successive frames and interpolate them rather than interlacing them the way a conventional CRT TV worked. They also had circuitry to detect motion and perform image stabilization to further enhance the image. The result wasn’t as good as HDTV. But it gave high rollers a better picture until HDTV. HDTV arrived in 1998, but articles at the time estimated 2005. The Chicago Tribune warned in 1990 that these $40,000 TVs would be obsolete in 15 years, but the salesperson countered that every TV would be obsolete in 15 years.</p><p>It’s also likely that someone in the market for a $40,000 TV didn’t worry about obsolescence. In 1990, the GE Widescreen 1000 looked dated and it wasn’t 15 years old yet.</p><h2>Why so expensive?</h2><p>The KV-45ED1 or PVM-4300 cost about 8 times as much as Sony’s second most expensive model at the time, which had a 29-inch screen. That’s largely because the KV-45ED1 had to be built by hand. Sony could mass produce its smaller TVs. This was a product for buyers who weren’t worried about the price.</p><p><a href="https://dfarq.homeip.net/the-last-sony-crt-ever-made/">Sony continued making CRTs into the 21st century</a>, bowing out with its high-def KD-34XBR970, 36-inch KD-36FS170, 32-inch KV-32FS170 and 27-inch KV27FS170 in February 2006.</p><p>It is unclear how many of these enormous 43-inch units Sony sold, and some people even questioned if it was ever built. A Chicago area dealer told the <em>Chicago Tribune</em> in 1990 that someone had purchased one, but that the buyer wanted to remain anonymous. That was good enough for me; a TV dealer wasn’t going to tell a newspaper that they have a $40,000 item and then not have it. That’s just bad business. Good business is taking the free advertising, having an example on display to show knowing most won’t buy it, but they may buy one of the smaller units. But luring someone into the store with a lie makes it much more difficult to sell anything.</p><p>And the Tribune wasn’t going to make something like this up. It would anger the TV dealers and risk losing their advertising. And someone who could afford a $40,000 TV was likely a business owner or high-ranking executive who could pull their advertising. In the days of print newspapers, advertisers and potential advertisers held a lot of sway. This could be both good and bad. I’m not going to say capitalism solves every problem but this was a case where it helped keep people honest.</p><h2>Shank Mods’ surviving Sony PVM-4300</h2><p>On December 22, 2024, Youtuber Shank Mods released a video telling the story of a Sony PVM-4300 and how he acquired it. One of the photos of a purported surviving unit turned out to be very real. It was taken in a restaurant in Japan, and the owner was actually aware of the photo. Unfortunately the restaurant was having to move, and needed to get rid of the set.&nbsp;Shank Mods was able to contact some people in Japan who could help race against time and remove the TV from the restaurant and then ship it to the United States.</p><p><a href="https://www.youtube.com/watch?v=JfZxOuc9Qwk&amp;pp=ygUOc2hhbmsgbW9kcyBjcnQ%3D">The 35-minute video</a> is well worth watching if you have interest in vintage CRTs, or even if you just like stories of strangers coming together and helping each other just for the sake of being helpful. Actually, I take that back. At the end of the video, Shank Mods played a prank on his fellow CRT fans that is absolutely hilarious and makes the video worth watching for that reason alone. I won’t ruin it for you.</p><p>We can only guess how many other examples may survive. But we now know that at least one survives and is in the hands of a retro hobbyist.</p><div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2017/06/dave_farquhar_181px.jpg?resize=100%2C100&amp;ssl=1" data-src="https://i0.wp.com/dfarq.homeip.net/wp-content/uploads/2017/06/dave_farquhar_181px.jpg?resize=100%2C100&amp;ssl=1" width="100" height="100" alt="" itemprop="image"></p><div><p>David Farquhar is a computer security professional, entrepreneur, and author. He has written professionally about computers since 1991, so he was writing about retro computers when they were still new. He has been working in IT professionally since 1994 and has specialized in vulnerability management since 2013. He holds Security+ and CISSP certifications. Today he blogs five times a week, mostly about retro computers and retro gaming covering the time period from 1975 to 2000.</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Italian Competition Authority Fines Apple $115M for Abusing Dominant Position (117 pts)]]></title>
            <link>https://en.agcm.it/en/media/press-releases/2025/12/A561</link>
            <guid>46353261</guid>
            <pubDate>Mon, 22 Dec 2025 11:22:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.agcm.it/en/media/press-releases/2025/12/A561">https://en.agcm.it/en/media/press-releases/2025/12/A561</a>, See on <a href="https://news.ycombinator.com/item?id=46353261">Hacker News</a></p>
Couldn't get https://en.agcm.it/en/media/press-releases/2025/12/A561: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[If you don't design your career, someone else will (2014) (345 pts)]]></title>
            <link>https://gregmckeown.com/if-you-dont-design-your-career-someone-else-will/</link>
            <guid>46352930</guid>
            <pubDate>Mon, 22 Dec 2025 10:27:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gregmckeown.com/if-you-dont-design-your-career-someone-else-will/">https://gregmckeown.com/if-you-dont-design-your-career-someone-else-will/</a>, See on <a href="https://news.ycombinator.com/item?id=46352930">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

	<p>A client once responded to one of my questions by saying, “Oh Greg, I am too busy living to think <a href="https://gregmckeown.com/about/">about</a> life!” His off-the-cuff comment named a trap all of us fall into sometimes. In just one example, it is easy to become so consumed&nbsp;<em>in&nbsp;</em>our careers we fail to really think&nbsp;<em><a href="https://gregmckeown.com/about/">about</a>&nbsp;</em>our careers.</p>
<p>To avoid this trap, I suggest carving out a couple of hours over the holiday break to follow these simple steps for reflecting on your career.</p>
<p><strong>Step 1: <a href="https://gregmckeown.com/books/effortless/review/">Review</a> the last 12 months</strong>. <a href="https://gregmckeown.com/books/effortless/review/">Review</a> the year, month by month. Make a list of where you spent your time: include your major projects, responsibilities and accomplishments. No need to overcomplicate this.</p>
<p><strong>Step 2: Ask, “What is the <a href="https://gregmckeown.com/news/">news</a>?”</strong>&nbsp;Look over your list and reflect on what is&nbsp;<em>really</em>&nbsp;going on. Think like a journalist and ask yourself: Why does this matter? What are the trends here? What happens if these trends continue?</p>
<p><strong>Step 3: Ask “What would I do in my career if I could do</strong><strong>&nbsp;<em>anything</em>?”&nbsp;</strong>Just brainstorm with no voice of criticism to hold you back. Just write out all the ideas that come to mind.</p>
<p><strong>Step 4: Go back and spend a bit more time on Step 3.</strong>&nbsp;Too often we begin our career planning with our second best option in mind. We have a sense of what we would most love to do but we&nbsp;<em>immediately</em>&nbsp;push it aside. Why? Typically because “it is not realistic” which is code for, “I can’t make money doing this.” In this economy—in any economy—I understand why making money is critical. However, sometimes we pass by legitimate career paths because we set them aside too quickly.</p>
<p><strong>Step 5: Write down six objectives for the next 12 months.</strong>&nbsp;Make a list of the top six items you would like to accomplish in your career this year and place them in priority order.</p>
<p><strong>Step 6: Cross off the bottom five.</strong>&nbsp;Once you’re back to the whirlwind of work you’ll benefit from having a single “true north” career objective for the year.</p>
<p><strong>Step 7: Make an action plan for this month.</strong>&nbsp;Make a list of some quick wins you’d like to have in place over the next 3-4 weeks.</p>
<p><strong>Step 8: Decide what you will say no to.</strong>&nbsp;Make a list of the “good” things that will keep you from achieving your one “great” career objective. Think <a href="https://gregmckeown.com/about/">about</a> how to delete, defer or delegate these other tasks.&nbsp;<a href="http://en.wikipedia.org/wiki/Ralph_Waldo_Emerson" target="_blank">Ralph Waldo Emerson</a>&nbsp;said, “The crime which bankrupts men and nations is that of turning aside from one’s main purpose to serve a job here and there.”</p>
<p>Many years ago I followed this process and, without exaggeration, it changed the course of my life. The insight I gained led me to quit law school, leave England and move to America and start down the path as a teacher and author. You’re reading this because of that choice. It remains the single most important career decision of my life.</p>
<p>Two hours spent wisely over the next couple of weeks could easily improve the quality of your life over the 8760 hours of the next year–and perhaps far beyond. After all,&nbsp;<em>if we don’t design our careers, someone else will.</em></p>

	
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A year of vibes (156 pts)]]></title>
            <link>https://lucumr.pocoo.org/2025/12/22/a-year-of-vibes/</link>
            <guid>46352875</guid>
            <pubDate>Mon, 22 Dec 2025 10:19:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lucumr.pocoo.org/2025/12/22/a-year-of-vibes/">https://lucumr.pocoo.org/2025/12/22/a-year-of-vibes/</a>, See on <a href="https://news.ycombinator.com/item?id=46352875">Hacker News</a></p>
<div id="readability-page-1" class="page"><div hx-history-elt="">
        
  

  
  <p data-date="2025-12-22T00:00:00">written on December 22, 2025</p>
  

  <p>2025 draws to a close and it’s been quite a year.  Around this time last year, I
wrote a post that reflected <a href="https://lucumr.pocoo.org/2024/12/26/reflecting-on-life/">on my life</a>.  Had
I written about programming, it might have aged badly, as 2025 has been a year
like no other for my profession.</p>
<h2>2025 Was Different</h2>
<p>2025 was the year of changes.  Not only did I leave Sentry and start my new
company, it was also the year I stopped programming the way I did before.  <a href="https://lucumr.pocoo.org/2025/6/4/changes/">In
June</a> I finally felt confident enough to share that my way
of working was different:</p>
<blockquote>
<p>Where I used to spend most of my time in Cursor, I now mostly use Claude Code,
almost entirely hands-off. […] If you would have told me even just six months
ago that I’d prefer being an engineering lead to a virtual programmer intern
over hitting the keys myself, I would not have believed it.</p>
</blockquote>
<p>While I set out last year wanting to write more, that desire had nothing to do
with agentic coding.  Yet I published 36 posts — almost 18% of all posts on this
blog since 2007.  I also had around a hundred conversations with programmers,
founders, and others about AI because I was fired up with curiosity after
falling into the agent rabbit hole.</p>
<p>2025 was also a not so great year for the world.  To make my peace with it, I
<a href="https://dark.ronacher.eu/">started a separate blog</a> to separate out my thoughts
from here.</p>
<h2>The Year Of Agents</h2>
<p>It started with a growing obsession with Claude Code in April or May, resulting
in months of building my own agents and using others’.  Social media exploded
with opinions on AI: some good, some bad.</p>
<p>Now I feel I have found a new stable status quo for how I reason about where we
are and where we are going.  I’m doubling down on code generation, file systems,
programmatic tool invocation via an interpreter glue, and skill-based learning.
Basically: what Claude Code innovated is still state of the art for me.  That
has worked very well over the last few months, and seeing foundation model
providers double down on skills reinforces my belief in this approach.</p>
<p>I’m still perplexed by how TUIs made such a strong comeback.  At the moment I’m
using <a href="https://ampcode.com/">Amp</a>, <a href="https://claude.com/product/claude-code">Claude
Code</a>, and
<a href="https://shittycodingagent.ai/">Pi</a>, all from the command line.  Amp feels like
the Apple or Porsche of agentic coding tools, Claude Code is the affordable
Volkswagen, and Pi is the Hacker’s Open Source choice for me.  They all feel
like projects built by people who, like me, use them to an unhealthy degree to
build their own products, but with different trade-offs.</p>
<p>I continue to be blown away by what LLMs paired with tool execution can do. At
the beginning of the year I mostly used them for code generation, but now a big
number of my agentic uses are day-to-day things.  I’m sure we will see some
exciting pushes towards consumer products in 2026.  LLMs are now helping me with
organizing my life, and I expect that to grow further.</p>
<h2>The Machine And Me</h2>
<p>Because LLMs now not only help me program, I’m starting to rethink my
relationship to those machines.  I increasingly find it harder not to create
parasocial bonds with some of the tools I use.  I find this odd and
discomforting.  Most agents we use today do not have much of a memory and have
little personality but it’s easy to build yourself one that does.  An LLM with
memory is an experience that is hard to shake off.</p>
<p>It’s both fascinating and questionable.  I have tried to train myself for two
years, to think of these models as mere token tumblers, but that reductive view
does not work for me any longer.  These systems we now create have human
tendencies, but elevating them to a human level would be a mistake.  I
increasingly take issue with calling these machines “agents,” yet I have no
better word for it.  I take issue with “agent” as a term because agency and
responsibility should remain with humans.  Whatever they are becoming, they can
trigger emotional responses in us that <a href="https://en.wikipedia.org/wiki/Chatbot_psychosis">can be
detrimental</a> if we are not
careful.  Our inability to properly name and place these creations in relation
to us is a challenge I believe we need to solve.</p>
<p>Because of all this unintentional anthropomorphization, I’m really struggling at
times to find the right words for how I’m working with these machines.  I know
that this is not just me; it’s others too.  It creates even more discomfort when
working with people who currently reject these systems outright.  One of the
most common comments I read in response to agentic coding tool articles is this
rejection of giving the machine personality.</p>
<h2>Opinions Everywhere</h2>
<p>An unexpected aspect of using AI so much is that we talk far more about vibes
than anything else.  This way of working is less than a year old, yet it
challenges half a century of software engineering experience.  So there are many
opinions, and it’s hard to say which will stand the test of time.</p>
<p>I found a lot of conventional wisdom I don’t agree with, but I have nothing to
back up my opinions.  How would I?  I quite vocally shared my lack of success
with <a href="https://en.wikipedia.org/wiki/Model_Context_Protocol">MCP</a> throughout the
year, but I had little to back it up beyond “does not work for me.”  Others
swore by it.  Similar with model selection.  <a href="https://steipete.me/">Peter</a>, who
got me hooked on Claude early in the year, moved to Codex and is happy with it.
I don’t enjoy that experience nearly as much, though I started using it more.  I
have nothing beyond vibes to back up my preference for Claude.</p>
<p>It’s also important to know that some of the vibes come with intentional
signalling.  Plenty of people whose views you can find online have a financial
interest in one product over another, for instance because they are
investors in it or they are paid influencers.  They might have become investors
because they liked the product, but it’s also possible that their views are
affected and shaped by that relationship.</p>
<h2>Outsourcing vs Building Yourself</h2>
<p>Pick up a library from any AI company today and you’ll notice they’re built with
Stainless or Fern.  The docs use Mintlify, the site’s authentication system
might be Clerk.  Companies now sell services you would have built yourself
previously.  This increase in outsourcing of core services to companies
specializing in it meant that the bar for some aspects of the user experience
has risen.</p>
<p>But with our newfound power from agentic coding tools, you can build much of
this yourself.  I had Claude build me an SDK generator for Python and TypeScript
— partly out of curiosity, partly because it felt easy enough.  As you might
know, I’m a proponent of <a href="https://lucumr.pocoo.org/2025/2/20/ugly-code/">simple code</a> and <a href="https://lucumr.pocoo.org/2025/1/24/build-it-yourself/">building it
yourself</a>.  This makes me somewhat optimistic
that AI has the potential to encourage building on fewer dependencies.  At the
same time, it’s not clear to me that we’re moving that way given the current
trends of outsourcing everything.</p>
<h2>Learnings and Wishes</h2>
<p>This brings me not to predictions but to wishes for where we could put our
energy next.  I don’t really know what I’m looking for here, but I want to point
at my pain points and give some context and food for thought.</p>
<h3>New Kind Of Version Control</h3>
<p>My biggest unexpected finding: we’re hitting limits of traditional tools for
sharing code.  The pull request model on GitHub doesn’t carry enough information
to review AI generated code properly — I wish I could see the prompts that led
to changes.  It’s not just GitHub, it’s also git that is lacking.</p>
<p>With agentic coding, part of what makes the models work today is knowing the
mistakes.  If you steer it back to an earlier state, you want the tool to
remember what went wrong.  There is, for lack of a better word, value in
failures.  As humans we might also benefit from knowing the paths that did not
lead us anywhere, but for machines this is critical information.  You notice
this when you are trying to compress the conversation history.  Discarding the
paths that led you astray means that the model will try the same mistakes again.</p>
<p>Some agentic coding tools have begun spinning up worktrees or creating
checkpoints in git for restore, in-conversation branch and undo features.
There’s room for UX innovation that could make these tools easier to work with.
This is probably why we’re seeing discussions about stacked diffs and
alternative version control systems like <a href="https://www.jj-vcs.dev/">Jujutsu</a>.</p>
<p>Will this change GitHub or will it create space for some new competition?  I
hope so.  I increasingly want to better understand genuine human input and tell
it apart from machine output.  I want to see the prompts and the attempts that
failed along the way.  And then somehow I want to squash and compress it all on
merge, but with a way to retrieve the full history if needed.</p>
<h3>New Kind Of Review</h3>
<p>This is related to the version control piece: current code review tools assign
strict role definitions that just don’t work with AI.  Take the GitHub code
review UI: I regularly want to use comments on the PR view to leave notes for
my own agents, but there is no guided way to do that.  The review interface
refuses to let me review my own code, I can only comment, but that does not
have quite the same intention.</p>
<p>There is also the problem that an increased amount of code review now happens
between me and my agents locally.  For instance, the Codex code review feature
on GitHub stopped working for me because it can only be bound to one
organization at a time.  So I now use Codex on the command line to do reviews,
but that means a whole part of my iteration cycles is invisible to other
engineers on the team.  That doesn’t work for me.</p>
<p>Code review to me feels like it needs to become part of the VCS.</p>
<h3>New Observability</h3>
<p>I also believe that observability is up for grabs again.  We now have both the
need and opportunity to take advantage of it on a whole new level.  Most people
were not in a position where they could build their own
<a href="https://en.wikipedia.org/wiki/EBPF">eBPF</a> programs, but LLMs can.  Likewise,
many observability tools shied away from SQL because of its complexity, but LLMs
are better at it than any proprietary query language.  They can write queries,
they can grep, they can map-reduce, they remote-control LLDB.  Anything that has
some structure and text is suddenly fertile ground for agentic coding tools to
succeed.  I don’t know what the observability of the future looks like, but my
strong hunch is that we will see plenty of innovation here.  The better the
feedback loop to the machine, the better the results.</p>
<p>I’m not even sure what I’m asking for here, but I think that one of the
challenges in the past was that many cool ideas for better observability —
specifically dynamic reconfiguration of services for more targeted filtering —
were user-unfriendly because they were complex and hard to use.  But now those
might be the right solutions in light of LLMs because of their increased
capabilities for doing this grunt work.  For instance Python 3.14 landed <a href="https://docs.python.org/3/whatsnew/3.14.html#whatsnew314-remote-debugging">an
external debugger
interface</a>
which is an amazing capability for an agentic coding tool.</p>
<h3>Working With Slop</h3>
<p>This may be a little more controversial, but what I haven’t managed this year is
to give in to the machine.  I still treat it like regular software engineering
and review a lot.  I also recognize that an increasing number of people are not
working with this model of engineering but instead completely given in to the
machine.  As crazy as that sounds, I have seen some people be quite successful
with this.  I don’t yet know how to reason about this, but it is clear to me
that even though code is being generated in the end, the way of working in that
new world is very different from the world that I’m comfortable with.  And my
suspicion is that because that world is here to stay, we might need some new
social contracts to separate these out.</p>
<p>The most obvious version of this is the increased amount of these types of
contributions to Open Source projects, which are quite frankly an insult to
anyone who is not working in that model.  I find reading such pull requests
quite rage-inducing.</p>
<p>Personally, I’ve tried to attack this problem with contribution guidelines and
pull request templates.  But this seems a little like a fight against windmills.
This might be something where the solution will not come from changing what
we’re doing.  Instead, it might come from vocal people who are also pro-AI
engineering speaking out on what good behavior in an agentic codebase looks
like.  And it is not just to throw up unreviewed code and then have another
person figure the shit out.</p>


  
  <p>This entry was tagged
    
      <a href="https://lucumr.pocoo.org/tags/ai/">ai</a>, 
      <a href="https://lucumr.pocoo.org/tags/personal/">personal</a> and 
      <a href="https://lucumr.pocoo.org/tags/thoughts/">thoughts</a>
  

  </p><p>
    <a href="https://lucumr.pocoo.org/2025/12/22/a-year-of-vibes.md" id="copy-markdown" hx-boost="false">copy as</a> / <a href="https://lucumr.pocoo.org/2025/12/22/a-year-of-vibes.md" id="view-markdown" hx-boost="false">view</a> markdown
  </p>
  
  

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The ancient monuments saluting the winter solstice (150 pts)]]></title>
            <link>https://www.bbc.com/culture/article/20251219-the-ancient-monuments-saluting-the-winter-solstice</link>
            <guid>46352565</guid>
            <pubDate>Mon, 22 Dec 2025 09:30:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/culture/article/20251219-the-ancient-monuments-saluting-the-winter-solstice">https://www.bbc.com/culture/article/20251219-the-ancient-monuments-saluting-the-winter-solstice</a>, See on <a href="https://news.ycombinator.com/item?id=46352565">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-component="layout-block"><p><b id="dozens-of-mysterious-structures-across-the-northern-hemisphere-–-some-nearly-5,000-years-old-–-align-precisely-to-frame-the-rising-and-setting-sun-during-midwinter's-shortest-day.-what-motivated-people-to-construct-these-solar-calibrated-masterpieces?">Dozens of mysterious structures across the Northern Hemisphere – some nearly 5,000 years old – align precisely to frame the rising and setting Sun during midwinter's shortest day. What motivated people to construct these solar-calibrated masterpieces?</b></p><p>The winter solstice, which usually falls on 21 or 22 December in the Northern Hemisphere each year, marks the moment that one yearly cycle comes to an end and another is born. It is the day with the smallest number of sunlight hours in the calendar, and once it's over, the days lengthen again incrementally until the <a target="_self" href="https://www.bbc.com/culture/article/20230616-gen-z-and-millennials-surprising-midsummer-obsession">summer solstice</a> in June.</p><p>The significance of this day is manifested in ancient monuments that were designed to acknowledge and celebrate its passing. One example is <a target="_self" href="https://www.bbc.com/travel/article/20231221-maeshowe-the-uks-doorway-to-another-world">Maeshowe tomb in Orkney</a>. To the untrained eye this burial cairn, created around 2800BC, looks like a grassy hillock – but it conceals a cuboid, stone-clad sepulchre and a 33ft (10m) long entry corridor oriented to the south-west. During midwinter, three weeks either side of the winter solstice, the setting Sun aims directly down the corridor and emanates its light into the tomb.</p><div><p><span>It's possible to understand the enormous significance of the winter solstice both as the darkest moment in the calendar and the pivot to six future months of greater illumination</span></p></div><p>When the sky is cloudless, the light seems to carve a golden aperture into the tomb's rear wall – a sacrament of pure light. These days of radiance are interrupted by the solstice itself, when blackness temporarily takes over. But daylight reappears soon after, to blaze for another few days as if in celebration of the promise of nature's rejuvenation in spring.</p></div><div data-component="layout-block"><figure><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/images/ic/160xn/p0mpp4n7.jpg.webp 160w, https://ichef.bbci.co.uk/images/ic/240xn/p0mpp4n7.jpg.webp 240w, https://ichef.bbci.co.uk/images/ic/320xn/p0mpp4n7.jpg.webp 320w, https://ichef.bbci.co.uk/images/ic/480xn/p0mpp4n7.jpg.webp 480w, https://ichef.bbci.co.uk/images/ic/640xn/p0mpp4n7.jpg.webp 640w, https://ichef.bbci.co.uk/images/ic/800xn/p0mpp4n7.jpg.webp 800w, https://ichef.bbci.co.uk/images/ic/1024xn/p0mpp4n7.jpg.webp 1024w, https://ichef.bbci.co.uk/images/ic/1376xn/p0mpp4n7.jpg.webp 1376w, https://ichef.bbci.co.uk/images/ic/1920xn/p0mpp4n7.jpg.webp 1920w" src="https://ichef.bbci.co.uk/images/ic/480xn/p0mpp4n7.jpg.webp" loading="lazy" alt="Alamy Orkney's Maeshowe tomb is a burial cairn created around 2800BC that conceals a stone-clad sepulchre (Credit: Alamy)"><span>Alamy</span></p><figcaption>Orkney's Maeshowe tomb is a burial cairn created around 2800BC that conceals a stone-clad sepulchre (Credit: Alamy)</figcaption></figure><p>We will probably never know the specific beliefs and rituals that inspired Maeshowe tomb. But it's nonetheless possible to understand the enormous significance of the winter solstice as the "year's midnight", both as the darkest moment in the calendar and the pivot to six future months of greater illumination. It was a moment of death and rebirth, and a reminder of the cyclical nature of time.</p><p>In the deep past, understanding the markers of nature's clockwork – including solstices – was a matter of survival. Predicting the recurrent patterns of animal migration, for example, could help successful hunting and fishing. Knowing when the climate was likely to change meant being able to adapt and survive. In pre-agricultural societies, it helped people anticipate the availability and location of edible roots, nuts and plants.</p><p>After the introduction of farming, around 9000BC, it was essential – for successful planting and harvesting – to anticipate the timing of seasonal changes. Monuments that calculated time had practical value, but it's likely that they also embodied spiritual beliefs in Neolithic times too, with the winter solstice being of particular importance. This very ancient recognition of the solstice's significance even echoes through to the modern world. The word "Yule", now associated with the winter holiday period, derives from the historic Norse festival of <i id="jól,">Jól,</i> which was based around the winter solstice. Modern Christmas traditions recall bygone midwinter celebrations like the Roman holiday of Saturnalia, which involved feasting and gift-giving. And the solstice continues to be acknowledged in hundreds of traditions across the world, such as the Inca celebration of Inti Raymi, and the Dōngzhì festival in China.</p><h2><span id="'nature's-sublime-power'"><b id="'nature's-sublime-power'">'Nature's sublime power'</b></span></h2><p>Alongside Maeshowe tomb, archaeologists have discovered dozens of Neolithic monuments that stare directly at the Sun on the winter solstice. There's Stonehenge (England), whose tallest trilithon once framed the setting sun; Newgrange (Ireland), which has a passageway aligned to sunrise on this auspicious day; and the standing stones at Callanish (Outer Hebrides) which create similar solar sightlines. In Brittany, north-western France, is <i id="la-roche-aux-fées:">La Roche aux Fées:</i> a megalithic passageway constructed from 41 blocks of stone, some of which weigh over 40 tonnes (40,000kg). At sunrise on the winter solstice, it breathes in its annual dose of restorative midwinter light. Legends once told that fairies constructed it over the course of one night, but it is actually a dolmen (tomb) created by Neolithic architects around 2750BC.</p></div><div data-component="layout-block"><p>Another masterpiece of Land Art, James Turrell's Roden Crater (begun 1979), does this on an even more epic scale than Sun Tunnels. It occupies a volcanic cinder cone in the Painted Desert region of northern Arizona and houses multiple spaces from which to watch celestial phenomena. One of them is a 900ft- (274m) long tunnel drilled through the volcanic cone. It acts like a camera obscura, focusing an image of the midwinter sun (via a glass lens halfway down the passage) on to a slab of white marble in a central chamber. Like Maeshowe tomb's passage, it aligns with the Sun's position <a target="_blank" href="https://rodencrater.com/celestial-events/">around 21 December each year</a>, and drinks down the Sun's light from 10 days before the solstice to the 10th day after it.</p><figure><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/images/ic/160xn/p0mpp6tg.jpg.webp 160w, https://ichef.bbci.co.uk/images/ic/240xn/p0mpp6tg.jpg.webp 240w, https://ichef.bbci.co.uk/images/ic/320xn/p0mpp6tg.jpg.webp 320w, https://ichef.bbci.co.uk/images/ic/480xn/p0mpp6tg.jpg.webp 480w, https://ichef.bbci.co.uk/images/ic/640xn/p0mpp6tg.jpg.webp 640w, https://ichef.bbci.co.uk/images/ic/800xn/p0mpp6tg.jpg.webp 800w, https://ichef.bbci.co.uk/images/ic/1024xn/p0mpp6tg.jpg.webp 1024w, https://ichef.bbci.co.uk/images/ic/1376xn/p0mpp6tg.jpg.webp 1376w, https://ichef.bbci.co.uk/images/ic/1920xn/p0mpp6tg.jpg.webp 1920w" src="https://ichef.bbci.co.uk/images/ic/480xn/p0mpp6tg.jpg.webp" loading="lazy" alt="Getty Images The epic Roden Crater in Northern Arizona houses multiple spaces from which to watch celestial phenomena (Credit: Getty Images)"><span>Getty Images</span></p><figcaption>The epic Roden Crater in Northern Arizona houses multiple spaces from which to watch celestial phenomena (Credit: Getty Images)</figcaption></figure><p>Enoura Observatory in Kanagawa Prefecture, Japan (completed 2017) was designed by photographer and architect Hiroshi Sugimoto. Its various buildings are all calibrated towards the movement of the Sun, to create what the artist <a target="_blank" href="https://www.mariangoodman.com/usr/documents/press/download_url/151/the-new-york-times-style-magazine-april-3-2017-.pdf?utm">describes as</a> a "new Neolithic aesthetic". He wanted to correct what he saw as a lack of purpose in contemporary art by exploring the primal concerns of our ancient ancestors – our status within the infinite wilderness of the cosmos, our sense of time, and our notion of a human identity within the natural order.</p><p>One of its structures, the "Winter Solstice Light-Worship Tunnel", points directly at the spot on the horizon where the Sun rises at about 06:48 local time on 21 December each year. The solstice sunlight floods this 230ft-(70m) long chamber made of Corten steel and illuminates a stone medieval wellhead that is situated halfway along its length. It passes underneath another structure which aligns with the Sun on the summer solstice. The entire site, which took a decade to build, was intended by Sugimoto to act like a living clock, and to make <a target="_blank" href="https://www.odawara-af.com/en/enoura/">an artwork</a> with the ancient function of helping humans "identify their place within the vastness of the universe".</p><figure><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png" aria-label="image unavailable"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/images/ic/160xn/p0mpp7qg.jpg.webp 160w, https://ichef.bbci.co.uk/images/ic/240xn/p0mpp7qg.jpg.webp 240w, https://ichef.bbci.co.uk/images/ic/320xn/p0mpp7qg.jpg.webp 320w, https://ichef.bbci.co.uk/images/ic/480xn/p0mpp7qg.jpg.webp 480w, https://ichef.bbci.co.uk/images/ic/640xn/p0mpp7qg.jpg.webp 640w, https://ichef.bbci.co.uk/images/ic/800xn/p0mpp7qg.jpg.webp 800w, https://ichef.bbci.co.uk/images/ic/1024xn/p0mpp7qg.jpg.webp 1024w, https://ichef.bbci.co.uk/images/ic/1376xn/p0mpp7qg.jpg.webp 1376w, https://ichef.bbci.co.uk/images/ic/1920xn/p0mpp7qg.jpg.webp 1920w" src="https://ichef.bbci.co.uk/images/ic/480xn/p0mpp7qg.jpg.webp" loading="lazy" alt="Odawara Art Foundation Hiroshi Sugimoto created the Enoura Observatory in Japan, whose buildings are all calibrated towards the movement of the Sun (Credit: Odawara Art Foundation)"><span>Odawara Art Foundation</span></p><figcaption>Hiroshi Sugimoto created the Enoura Observatory in Japan, whose buildings are all calibrated towards the movement of the Sun (Credit: Odawara Art Foundation)</figcaption></figure></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Backlog – a public repository of real work problems (107 pts)]]></title>
            <link>https://www.worldsbacklog.com/</link>
            <guid>46352310</guid>
            <pubDate>Mon, 22 Dec 2025 08:42:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.worldsbacklog.com/">https://www.worldsbacklog.com/</a>, See on <a href="https://news.ycombinator.com/item?id=46352310">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Debian's Git Transition (148 pts)]]></title>
            <link>https://diziet.dreamwidth.org/20436.html</link>
            <guid>46352231</guid>
            <pubDate>Mon, 22 Dec 2025 08:24:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://diziet.dreamwidth.org/20436.html">https://diziet.dreamwidth.org/20436.html</a>, See on <a href="https://news.ycombinator.com/item?id=46352231">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>tl;dr:
</p><p>There is a Debian git transition plan. It’s going OK so far but we need help, especially with outreach and updating Debian’s documentation.
</p><ul><li><a href="#goals-of-the-debian-git-transition-project">Goals of the Debian git transition project</a><ul><li><a href="#achievements-so-far-and-current-status">Achievements so far, and current status</a>
</li></ul>

</li><li><a href="#core-engineering-principle">Core engineering principle</a><ul><li><a href="#correspondence-between-dsc-and-git">Correspondence between dsc and git</a>
</li><li><a href="#patches-applied-vs-patches-unapplied">Patches-applied vs patches-unapplied</a>
</li><li><a href="#consequences-some-of-which-are-annoying">Consequences, some of which are annoying</a>
</li></ul>

</li><li><a href="#distributing-the-source-code-as-git">Distributing the source code as git</a><ul><li><a href="#tracking-the-relevant-git-data-when-changes-are-made-in-the-legacy-archive">Tracking the relevant git data, when changes are made in the legacy Archive</a>
</li><li><a href="#why-.dgit.debian.org-is-not-salsa">Why *.dgit.debian.org is not Salsa</a>
</li></ul>

</li><li><a href="#roadmap">Roadmap</a><ul><li><a href="#in-progress">In progress</a>
</li><li><a href="#future-technology">Future Technology</a>
</li></ul>

</li><li><a href="#mindshare-and-adoption---please-help">Mindshare and adoption - please help!</a><ul><li><a href="#a-rant-about-publishing-the-source-code">A rant about publishing the source code</a>
</li><li><a href="#documentation">Documentation</a>
</li></ul>

</li><li><a href="#personnel">Personnel</a><ul><li><a href="#thanks">Thanks</a>
</li></ul>

</li></ul>
<h2><a name="goals-of-the-debian-git-transition-project">Goals of the Debian git transition project</a></h2>
<ol start="0" type="1"><li><strong>Everyone who interacts with Debian source code should be able to do so entirely in git.</strong>
</li></ol>
<p>That means, more specifically:
</p><ol type="1"><li><p>All examination and edits to the source should be performed via normal git operations.

</p></li><li><p>Source code should be transferred and exchanged as git data, not tarballs. git should be the canonical form everywhere.

</p></li><li><p>Upstream git histories should be re-published, traceably, as part of formal git releases published by Debian.

</p></li><li><p>No-one should have to learn about Debian Source Packages, which are bizarre, and have been obsoleted by modern version control.

</p></li></ol>
<p>This is very ambitious, but we have come a long way!
</p><h2><a name="achievements-so-far-and-current-status">Achievements so far, and current status</a></h2>
<p>We have come a very long way. But, there is still much to do - especially, the git transition team <strong>needs your help with adoption, developer outreach, and developer documentation overhaul.</strong>
</p><p>We’ve made big strides towards goals 1 and 4. Goal 2 is partially achieved: we currently have dual running. Goal 3 is within our reach but depends on widespread adoption of tag2upload (and/or dgit push).
</p><p>Downstreams and users can <a href="https://diziet.dreamwidth.org/17579.html">obtain the source code of any Debian package</a> in git form. (<a href="https://manpages.debian.org/trixie/dgit/dgit.1.en.html#dgit">dgit clone</a>, 2013). They can then work with this source code completely in git, including building binaries, merging new versions, even automatically (eg <a href="https://github.com/plugwash/autoforwardportergit?tab=readme-ov-file#pooltogit">Raspbian</a>, 2016), and all without having to deal with source packages at all (eg <a href="https://debconf25.debconf.org/talks/119-automating-downstream-debian-package-builds-and-updates-in-ci/">Wikimedia</a> 2025).
</p><p>A Debian maintainer can maintain their own package entirely in git. They can obtain upstream source code from git, and do their packaging work in git (<code>git-buildpackage</code>, 2006).
</p><p>Every Debian maintainer can (and should!) release their package <em>from git</em> reliably and in a standard form (<a href="https://manpages.debian.org/trixie/dgit/dgit.1.en.html#dgit~15">dgit push</a>, 2013; <a href="https://wiki.debian.org/tag2upload">tag2upload</a>, 2025). This is not only more principled, but also more convenient, and with better UX, than pre-dgit tooling like <code>dput</code>.
</p><p>Indeed a Debian maintainer can now often release their changes to Debian, from git, using <em>only</em> git branches (so no tarballs). Releasing to Debian can be simply pushing a signed tag (<a href="https://wiki.debian.org/tag2upload">tag2upload</a>, 2025).
</p><p>A Debian maintainer can maintain a stack of changes to upstream source code in git (<a href="https://manpages.debian.org/trixie/git-buildpackage/gbp-pq.1.en.html">gbp pq</a> 2009). They can even maintain such a delta series as a rebasing git branch, directly buildable, and use normal <code>git rebase</code> style operations to edit their changes, (<a href="https://manpages.debian.org/trixie/git-dpm/git-dpm.1.en.html">git-dpm</a>, 2010; <a href="https://manpages.debian.org/trixie/git-debrebase/git-debrebase.1.en.html">git-debrebase</a>, 2018)
</p><p>An authorised Debian developer can do a modest update to <em>any</em> package in Debian, even one maintained by someone else, working entirely in git in a <a href="https://manpages.debian.org/testing/dgit/dgit-nmu-simple.7.en.html">standard and convenient way</a> (dgit, 2013).
</p><p>Debian contributors can share their work-in-progress on git forges and collaborate using merge requests, git based code review, and so on. (Alioth, 2003; Salsa, 2018.)
</p><h2><a name="core-engineering-principle">Core engineering principle</a></h2>
<p>The Debian git transition project is based on one core engineering principle:
</p><p><strong>Every Debian Source Package can be losslessly converted to and from git.</strong>
</p><p>In order to <em>transition</em> away from Debian Source Packages, we need to <em>gateway</em> between the old <code>dsc</code> approach, and the new git approach.
</p><p>This gateway obviously needs to be bidirectional: source packages uploaded with legacy tooling like <code>dput</code> need to be imported into a canonical git representation; and of course git branches prepared by developers need to be converted to source packages for the benefit of legacy downstream systems (such as the Debian Archive and <code>apt source</code>).
</p><p>This bidirectional gateway is implemented in <a href="https://salsa.debian.org/dgit-team/dgit"><code>src:dgit</code></a>, and is allowing us to gradually replace dsc-based parts of the Debian system with git-based ones.
</p><h2><a name="correspondence-between-dsc-and-git">Correspondence between dsc and git</a></h2>
<p>A faithful bidirectional gateway must define an invariant:
</p><p><strong>The canonical git tree, corresponding to a .dsc, is the tree resulting from <code>dpkg-source -x</code></strong>.
</p><p>This canonical form is sometimes called the “dgit view”. It’s sometimes not the same as the maintainer’s git branch, because many maintainers are still working with “patches-unapplied” git branches. More on this below.
</p><p>(For <code>3.0 (quilt)</code> .dscs, the canonical git tree doesn’t include the quilt <code>.pc</code> directory.)
</p><h2><a name="patches-applied-vs-patches-unapplied">Patches-applied vs patches-unapplied</a></h2>
<p>The canonical git format is “patches applied”. That is:
</p><p><strong>If Debian has modified the upstream source code, a normal git clone of the canonical branch gives the modified source tree, ready for reading and building.</strong>
</p><p>Many Debian maintainers keep their packages in a different git branch format, where the changes made by Debian, to the upstream source code, are in actual <code>patch</code> files in a <code>debian/patches/</code> subdirectory.
</p><p>Patches-applied has a number of important advantages over patches-unapplied:
</p><ul><li><p><strong>It is familiar to, and doesn’t trick, outsiders to Debian</strong>. Debian insiders radically underestimate how weird “patches-unapplied” is. Even expert software developers can get very confused or even <a href="https://diziet.dreamwidth.org/9556.html">accidentally build binaries without security patches</a>!

</p></li><li><p>Making changes can be done with just normal git commands, eg <code>git commit</code>. Many Debian insiders working with patches-unapplied are still using <a href="https://manpages.debian.org/trixie/quilt/quilt.1.en.html"><code>quilt(1)</code></a>, a footgun-rich contraption for working with patch files!

</p></li><li><p>When developing, one can make changes to upstream code, and to Debian packaging, together, without ceremony. There is no need to switch back and forth between patch queue and packaging branches (as with <code>gbp pq</code>), no need to “commit” patch files, etc. One can always edit every file and commit it with <code>git commit</code>.

</p></li></ul>
<p>The downside is that, with the (bizarre) <code>3.0 (quilt)</code> source format, the patch files files in <code>debian/patches/</code> must somehow be kept up to date. Nowadays though, tools like <code>git-debrebase</code> and <code>git-dpm</code> (and dgit for NMUs) make it very easy to work with patches-applied git branches. <code>git-debrebase</code> can deal very ergonomically even with <a href="https://salsa.debian.org/xen-team/debian-xen">big patch stacks</a>.
</p><p>(For smaller packages which usually have no patches, <a href="https://manpages.debian.org/trixie/dgit/dgit-maint-merge.7.en.html">plain <code>git merge</code> with an upstream git branch</a>, and a <a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=1007717#384">much simpler dsc format</a>, sidesteps the problem entirely.)
</p><h3><a name="prioritising-debians-users-and-other-outsiders">Prioritising Debian’s users (and other outsiders)</a></h3>
<p>We want everyone to be able to share and modify the software that they interact with. That means we should make source code truly accessible, on the user’s terms.
</p><p>Many of Debian’s processes assume everyone is an insider. It’s okay that there are Debian insiders and that people feel part of something that they worked hard to become involved with. But lack of perspective can lead to software which fails to uphold our values.
</p><p>Our source code practices — in particular, our determination to share properly (and systematically) — are a key part of what makes Debian worthwhile at all. Like Debian’s installer, we want our source code to be useable by Debian outsiders.
</p><p>This is why we have chosen to privilege a git branch format which is more familiar to the world at large, even if it’s less popular in Debian.
</p><h2><a name="consequences-some-of-which-are-annoying">Consequences, some of which are annoying</a></h2>
<p>The requirement that the conversion be <em>bidirectional</em>, <em>lossless</em>, and <em>context-free</em> can be inconvenient.
</p><p>For example, <a href="https://manpages.debian.org/trixie/dgit/dgit.7.en.html#GITATTRIBUTES">we cannot support <code>.gitattributes</code></a> which modify files during git checkin and checkout. <code>.gitattributes</code> cause the meaning of a git tree to depend on the context, in possibly arbitrary ways, so the conversion from git to source package wouldn’t be stable. And, worse, some source packages might not to be representable in git at all.
</p><p>Another example: Maintainers often have existing git branches for their packages, generated with pre-dgit tooling which is less careful and less principled than ours. That can result in discrepancies between git and dsc, which need to be resolved before a proper git-based upload can succeed.
</p><p>That some maintainers use patches-unapplied, and some patches-unapplied, means that there <em>has</em> to be some kind of conversion to a standard git representation. Choosing the less-popular patches-applied format as the canonical form, means that <em>many</em> packages need their git representation converted. It also means that user- and outsider-facing branches from <code>{browse,git}.dgit.d.o</code> and <code>dgit clone</code> are not always compatible with maintainer branches on Salsa. User-contributed changes need cherry-picking rather than merging, or conversion back to the maintainer format. The good news is that dgit can automate much of this, and the manual parts are usually easy git operations.
</p><h2><a name="distributing-the-source-code-as-git">Distributing the source code as git</a></h2>
<p>Our source code management should be normal, modern, and based on git. That means the Debian Archive is obsolete and needs to be replaced with a set of git repositories.
</p><p>The replacement repository for source code formally released to Debian is <a href="https://browse.dgit.debian.org/"><code>*.dgit.debian.org</code></a>. This contains all the git objects for every git-based upload since 2013, including the signed tag for each released package version.
</p><p>The plan is that it will contain a git view of <em>every</em> uploaded Debian package, by centrally importing all legacy uploads into git.
</p><h2><a name="tracking-the-relevant-git-data-when-changes-are-made-in-the-legacy-archive">Tracking the relevant git data, when changes are made in the legacy Archive</a></h2>
<p>Currently, many critical source code management tasks are done by changes to the legacy Debian Archive, which works entirely with dsc files (and the associated tarballs etc). The contents of the Archive are therefore still an important source of truth. But, the Archive’s architecture means it cannot sensibly directly contain git data.
</p><p>To track changes made in the Archive, we added the <a href="https://www.debian.org/doc/debian-policy/ch-controlfields.html#s-f-dgit"><code>Dgit:</code></a> field to the <code>.dsc</code> of a git-based upload (2013). This declares which git commit this package was converted from. and where those git objects can be obtained.
</p><p>Thus, given a Debian Source Package from a git-based upload, it is possible for the new git tooling to obtain the equivalent git objects. If the user is going to work in git, there is no need for any tarballs to be downloaded: the git data could be obtained from the depository using the git protocol.
</p><p>The <a href="https://browse.dgit.debian.org/libsdl2-ttf.git/tag/?h=archive/debian/2.24.0%2bdfsg-3">signed</a> <a href="https://browse.dgit.debian.org/libsdl2-ttf.git/tag/?h=debian/2.24.0%2bdfsg-3">tags</a>, available from the git depository, have <a href="https://manpages.debian.org/trixie/git-debpush/tag2upload.5.en.html">standardised metdata</a> which gives traceability back to the uploading Debian contributor.
</p><h2><a name="why-.dgit.debian.org-is-not-salsa">Why *.dgit.debian.org is not Salsa</a></h2>
<p>We need a git <em>depository</em> - a formal, reliable and permanent git repository of source code actually released to Debian.
</p><p>Git forges like Gitlab can be very convenient. But Gitlab is not sufficiently secure, <a href="https://gitlab.com/gitlab-org/gitlab/-/issues/429516">and</a> <a href="https://gitlab.com/gitlab-org/gitlab/-/issues/472646">too</a> <a href="https://gitlab.com/gitlab-org/gitlab/-/issues/581752">full</a> <a href="https://gitlab.com/gitlab-org/gitlab/-/issues/581897">of</a> <a href="https://gitlab.com/gitlab-org/gitlab/-/issues/217231">bugs</a>, to be the principal and only archive of all our source code. (The “open core” business model of the Gitlab corporation, and the constant-churn development approach, are <a href="https://mako.cc/writing/hill-free_tools.html">critical</a> underlying problems.)
</p><p>Our git depository lacks forge features like Merge Requests. But:
</p><ul><li>It is dependable, both in terms of reliability and security.
</li><li>It is append-only: once something is pushed, it is permanently recorded.
</li><li>Its access control is precisely that of the Debian Archive.
</li><li>Its ref namespace is standardised and corresponds to Debian releases.
</li><li>Pushes are authorised by PGP signatures, not ssh keys, so traceable.
</li></ul>
<p>The dgit git depository outlasted Alioth and it may well outlast Salsa.
</p><p>We need <em>both</em> a good forge, and the <code>*.dgit.debian.org</code> formal git depository.
</p><h2><a name="roadmap">Roadmap</a></h2>
<h2><a name="in-progress">In progress</a></h2>
<p>Right now we are quite focused on <a href="https://wiki.debian.org/tag2upload"><strong>tag2upload</strong></a>.
</p><p>We are working hard on eliminating the remaining issues that we feel need to be addressed before declaring the service out of beta.
</p><h2><a name="future-technology">Future Technology</a></h2>
<h3><a name="whole-archive-dsc-importer">Whole-archive dsc importer</a></h3>
<p>Currently, the git depository only has git data for git-based package updates (tag2upload and dgit push). Legacy dput-based uploads are not currently present there. This means that the git-based and legacy uploads must be resolved client-side, by <code>dgit clone</code>.
</p><p>We will want to start importing legacy uploads to git.
</p><p>Then downstreams and users will be able to get the source code for any package simply with <code>git clone</code>, even if the maintainer is using legacy upload tools like dput.
</p><h3><a name="support-for-git-based-uploads-to-security.debian.org">Support for git-based uploads to security.debian.org</a></h3>
<p>Security patching is a task which would particularly benefit from better and more formal use of git. git-based approaches to applying and backporting security patches are much more convenient than messing about with actual patch files.
</p><p>Currently, one can use git to help prepare a security upload, but it often involves starting with a dsc import (which lacks the proper git history) or figuring out a package maintainer’s unstandardised git usage conventions on Salsa.
</p><p>And it is not possible to properly perform the security release <em>as git</em>.
</p><h3><a name="internal-debian-consumers-switch-to-getting-source-from-git">Internal Debian consumers switch to getting source from git</a></h3>
<p>Buildds, QA work such as lintian checks, and so on, could be simpler if they don’t need to deal with source packages.
</p><p>And since git is actually the canonical form, we want them to use it directly.
</p><h3><a name="problems-for-the-distant-future">Problems for the distant future</a></h3>
<p>For decades, Debian has been built around source packages. Replacing them is a long and complex process. Certainly source packages are going to continue to be supported for the foreseeable future.
</p><p>There are no doubt going to be unanticipated problems. There are also foreseeable issues: for example, perhaps there are packages that work very badly when represented in git. We think we can rise to these challenges as they come up.
</p><h2><a name="mindshare-and-adoption---please-help">Mindshare and adoption - please help!</a></h2>
<p>We and our users are very pleased with our technology. It is convenient and highly dependable.
</p><p><code>dgit</code> in particular is superb, even if we say so ourselves. As technologists, we have been very focused on building good software, but it seems we have fallen short in the marketing department.
</p><h2><a name="a-rant-about-publishing-the-source-code">A rant about publishing the source code</a></h2>
<p><strong>git is the preferred form for modification</strong>.
</p><p>Our upstreams are overwhelmingly using git. We are overwhelmingly using git. It is a scandal that for many packages, Debian does not properly, formally and officially publish the git history.
</p><p><em>Properly</em> publishing the source code as git means publishing it in a way that means that anyone can <em>automatically</em> and <em>reliably</em> obtain <em>and build</em> the <em>exact</em> source code corresponding to the binaries. The test is: could you use that to build a derivative?
</p><p>Putting a package <a href="https://dep-team.pages.debian.net/deps/dep18/">in git on Salsa</a> is often a good idea, but it is not sufficient. No standard branch structure git on Salsa is enforced, nor should it be (so it can’t be automatically and reliably obtained), the tree is not in a standard form (so it can’t be automatically built), and is not <em>necessarily identical</em> to the source package. So <code>Vcs-Git</code> fields, and git from Salsa, will never be sufficient to make a derivative.
</p><p><strong>Debian is not publishing the source code!</strong>
</p><p>The time has come for proper publication of source code by Debian to no longer be a minority sport. Every maintainer of a package whose upstream is using git (which is nearly all packages nowadays) should be basing their work on upstream git, and properly publishing that via tag2upload or dgit.
</p><p>And it’s not even difficult! The modern git-based tooling provides a far superior upload experience.
</p><h3><a name="a-common-misunderstanding">A common misunderstanding</a></h3>
<p><strong>dgit push is not an alternative to gbp pq or quilt. Nor is tag2upload.</strong> These upload tools <em>complement your existing git workflow</em>. They replace and improve source package building/signing and the subsequent dput. If you are using one of the usual git layouts on salsa, and your package is in good shape, you can adopt tag2upload and/or dgit push right away.
</p><p><code>git-debrebase</code> is distinct and <em>does</em> provides an alternative way to manage your git packaging, do your upstream rebases, etc.
</p><h2><a name="documentation">Documentation</a></h2>
<p>Debian’s documentation all needs to be updated, including particularly instructions for packaging, to recommend use of git-first workflows. Debian should not be importing git-using upstreams’ “release tarballs” into git. (Debian outsiders who discover this practice are typically horrified.) We should use <em>only</em> upstream git, work only in git, and properly release (and publish) in git form.
</p><p>We, the git transition team, are experts in the technology, and can provide good suggestions. But we do not have the bandwidth to also engage in the massive campaigns of education and documentation updates that are necessary — especially given that (as with any programme for change) many people will be sceptical or even hostile.
</p><p>So we would greatly appreciate help with writing and outreach.
</p><h2><a name="personnel">Personnel</a></h2>
<p>We consider ourselves the Debian git transition team.
</p><p>Currently we are:
</p><ul><li><p>Ian Jackson. Author and maintainer of dgit and git-debrebase. Co-creator of tag2upload. Original author of dpkg-source, and inventor in 1996 of Debian Source Packages. Alumnus of the Debian Technical Committee.

</p></li><li><p>Sean Whitton. Co-creator of the tag2upload system; author and maintainer of git-debpush. Co-maintainer of dgit. Debian Policy co-Editor. Former Chair of the Debian Technical Committee.

</p></li></ul>
<p>We wear the following hats related to the git transition:
</p><ul><li>Maintainers of src:dgit
</li><li><a href="https://lists.debian.org/debian-devel-announce/2025/01/msg00002.html">tag2upload Delegates</a>; operators of the <a href="https://tag2upload.debian.org/">tag2upload service</a>.
</li><li>service operators of the git depository <a href="https://browse.dgit.debian.org/">*.dgit.debian.org</a>.
</li></ul>
<p>You can contact us:
</p><ul><li><p>By email: Ian Jackson <a href="mailto:ijackson@chiark.greenend.org.uk">ijackson@chiark.greenend.org.uk</a>; Sean Whitton <a href="mailto:spwhitton@spwhitton.name">spwhitton@spwhitton.name</a>; git-debpush@packages.d.o.

</p></li><li><p>By filing bugs in the Debian Bug System against <a href="https://bugs.debian.org/src:dgit">src:dgit</a>.

</p></li><li><p>On OFTC IRC, as <code>Diziet</code> and <code>spwhitton</code>.

</p></li></ul>
<p>We do most of our heavy-duty development <a href="https://salsa.debian.org/dgit-team">on Salsa</a>.
</p><h2><a name="thanks">Thanks</a></h2>
<p>Particular thanks are due to Joey Hess, who, in the now-famous design session in Vaumarcus in 2013, helped invent dgit. Since then we have had a lot of support: most recently political support to help get tag2upload deployed, but also, over the years, helpful bug reports and kind words from our users, as well as translations and code contributions.
</p><p>Many other people have contributed more generally to support for working with Debian source code in git. We particularly want to mention Guido Günther (git-buildpackage); and of course Alexander Wirt, Joerg Jaspert, Thomas Goirand and Antonio Terceiro (Salsa administrators); and before them the Alioth administrators.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I announced my divorce on Instagram and then AI impersonated me (131 pts)]]></title>
            <link>https://eiratansey.com/2025/12/20/i-announced-my-divorce-on-instagram-and-then-ai-impersonated-me/</link>
            <guid>46352004</guid>
            <pubDate>Mon, 22 Dec 2025 07:13:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eiratansey.com/2025/12/20/i-announced-my-divorce-on-instagram-and-then-ai-impersonated-me/">https://eiratansey.com/2025/12/20/i-announced-my-divorce-on-instagram-and-then-ai-impersonated-me/</a>, See on <a href="https://news.ycombinator.com/item?id=46352004">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wrapper">
	
  		<header>
  			
  			<!---->
  		</header>

  		<section>
	
			<article id="post-2412">
				
				<h2>I announced my divorce on Instagram and then AI impersonated me</h2>
				<time>December 20, 2025</time>
		
				
<p>After maintaining a total stance of public silence for months, I recently publicly announced my unexpected divorce on Instagram. I shared a picture of the divorce cake that my friends got for me, and shared a brief essay I had drafted the day before about the news. I had to edit it down slightly from my original draft to fit Instagram’s character limits. You can see the <a href="https://www.instagram.com/p/DSQwb-hkTPb/">Instagram post</a> here. And for the record, here is the photo of the cake and what I wrote:</p>



<figure><a href="https://eiratansey.com/wp-content/uploads/2025/12/IMG_3322.jpeg"><img fetchpriority="high" decoding="async" width="1024" height="928" src="https://eiratansey.com/wp-content/uploads/2025/12/IMG_3322-1024x928.jpeg" alt="Image of a round cake with red and black decorations and piped frosting text that says &quot;Hot Divorcee Era&quot;" srcset="https://eiratansey.com/wp-content/uploads/2025/12/IMG_3322-1024x928.jpeg 1024w, https://eiratansey.com/wp-content/uploads/2025/12/IMG_3322-300x272.jpeg 300w, https://eiratansey.com/wp-content/uploads/2025/12/IMG_3322-768x696.jpeg 768w, https://eiratansey.com/wp-content/uploads/2025/12/IMG_3322-1536x1391.jpeg 1536w, https://eiratansey.com/wp-content/uploads/2025/12/IMG_3322.jpeg 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<blockquote>
<div><p>Two weeks before our ninth anniversary in April my husband told me he wanted a divorce. I was completely blindsided. Going through an unexpected divorce has been the most brutal, humiliating, and traumatizing process I’ve ever experienced. In an instant my life trajectory changed. The markers of security that I had clung to following the previous year’s burst appendix hospitalization and my Dad dying in the same hospital where I was being treated suddenly vanished. Being forced to sell our house, the address I lived in longer than any other place in my life because of my complicated childhood, was one of the most devastating parts of this hellish timeline.</p><p>I don’t know if I would have survived the last several months were it not for my friends, those from home or around the world, those I’ve known for decades and those I’ve only recently met in the process of beginning to rebuild my life. Having friends from all ages, backgrounds, and circumstances has been a lifesaver because it turns out a lot of people have also gone through similar traumas that turned their lives upside down, who have a lot of counsel and camaraderie to offer.</p><p>Enough people have received the memo about divorce etiquette to ask whether a person’s divorce is a “congratulations” or “sorry” situation. Until recently the latter has been more applicable, but now that the state has decreed that my divorce is official I mostly feel a sense of overwhelming relief tempering my deep grief, and trying to stay focused on what’s next.</p><p>A divorce you don’t see coming really does a number on your sense of worth and identity. I did not choose to end my marriage, but I am humbled and struck by how many choices I get to make about my future. I am spending a lot of time thinking about the people and places, principles and pleasures that I want to prioritize in this next phase of my life.</p><p>Over the last several months I’ve been grateful for my friends’ unwavering belief that things will be better on the other side of this journey. And who I am to argue with my friends? They are smart and I think they love me and I definitely love them. So with that, I’m officially in my hot divorcee era. WATCH THIS SPACE.</p></div>
</blockquote>



<p>I hit post, and cross-posted it to Facebook. I also shared the Instagram link on <a href="http://glammr.us/">glammr.us</a> (the main Mastodon server that caters to GLAM workers), which is where I took a lot of my <a href="https://eiratansey.com/2018/01/07/this-machine-coddles-fascists/">post-Twitter energy</a> a few years ago.&nbsp;</p>



<p>A few days after posting, I was looking at the Mastodon app, Toot, on my phone (yes, all of the terminology around Mastodon is that embarrassing). And I noticed something I definitely did not remember writing. In the app, all the original text from my post was pulled in along with some additional text following my sign-off line of WATCH THIS SPACE that I certainly didn’t author. It also sounded very AI-generated. Here’s what I saw:</p>



<figure><a href="https://eiratansey.com/wp-content/uploads/2025/12/IMG_3363.png"><img decoding="async" width="992" height="2146" src="https://eiratansey.com/wp-content/uploads/2025/12/IMG_3363-edited.png" alt="" srcset="https://eiratansey.com/wp-content/uploads/2025/12/IMG_3363-edited.png 992w, https://eiratansey.com/wp-content/uploads/2025/12/IMG_3363-edited-139x300.png 139w, https://eiratansey.com/wp-content/uploads/2025/12/IMG_3363-edited-473x1024.png 473w, https://eiratansey.com/wp-content/uploads/2025/12/IMG_3363-edited-768x1661.png 768w, https://eiratansey.com/wp-content/uploads/2025/12/IMG_3363-edited-710x1536.png 710w, https://eiratansey.com/wp-content/uploads/2025/12/IMG_3363-edited-947x2048.png 947w" sizes="(max-width: 992px) 100vw, 992px"></a></figure>



<p>Here’s the AI-generated text I didn’t write:</p>



<blockquote>
<p>Going through a divorce can be a life-altering experience that leaves you feeling lost and uncertain about your future. In this post, I share my personal journey of self-discovery and rebuilding after a sudden divorce.<br>From finding support from friends to prioritizing what matters most, I explore the themes of identity, worth, and finding happiness after divorce.<br>Whether you’re navigating a divorce or simply looking for inspiration, this post is for you. Follow along as I share my story and insights on rebuilding, self-care, and finding happiness after divorce.</p>
</blockquote>



<p>After talking with my friend Ruth (one of the <a href="http://glammr.us/">glammr.us</a> admins and a much smarter tech person than myself) and finding this <a href="https://www.404media.co/instagram-is-generating-inaccurate-seo-bait-for-your-posts/">recent story from 404 Media</a>, I realized that somehow my post had been targeted for Instagram’s AI-generated SEO bait. If you go to the original Instagram post and view the page source, you’ll see that there is both the description text from above, along with a whole bevvy of keywords like “self-discovery” and “finding happiness.”</p>



<figure><a href="https://eiratansey.com/wp-content/uploads/2025/12/Screenshot-2025-12-20-at-7.13.15-PM.png"><img decoding="async" width="1024" height="394" src="https://eiratansey.com/wp-content/uploads/2025/12/Screenshot-2025-12-20-at-7.13.15-PM-1024x394.png" alt="A screenshot of Chrome's developer tools showing the AI-generated slop with a pink &quot;WTF&quot; drawn over the top" srcset="https://eiratansey.com/wp-content/uploads/2025/12/Screenshot-2025-12-20-at-7.13.15-PM-1024x394.png 1024w, https://eiratansey.com/wp-content/uploads/2025/12/Screenshot-2025-12-20-at-7.13.15-PM-300x115.png 300w, https://eiratansey.com/wp-content/uploads/2025/12/Screenshot-2025-12-20-at-7.13.15-PM-768x295.png 768w, https://eiratansey.com/wp-content/uploads/2025/12/Screenshot-2025-12-20-at-7.13.15-PM-1536x590.png 1536w, https://eiratansey.com/wp-content/uploads/2025/12/Screenshot-2025-12-20-at-7.13.15-PM.png 1912w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>While I am sure buried deep in some <a href="https://en.wikipedia.org/wiki/End-user_license_agreement">EULA</a> there is some bullshit allowing Meta to get away with this, I was never explicitly informed about this possibility or asked to review this AI-generated text. Meanwhile, as of today when I look at Instagram’s posting settings, I see that there is a button that requires you to label any AI-generated content you post as the end user, but obviously there is no such obligation in the other direction.</p>



<p>One of the things I gave up long ago about being an extremely online woman who is a <a href="https://tressiemc.com/essays-2/academic-outrage-when-the-culture-wars-go-digital/">micro-public figure</a> with a weird name are any assumptions about privacy. It’s why I drafted the brief essay for my announcement in advance, because I know that once I hit post on anything on the internet I can never unring that bell. I have been writing in the public sphere long enough to know that things that I write are routinely misrepresented by others (a lesson I relearn every time I check some of the citations of my work via Google Scholar updates).&nbsp;</p>



<p>But what I vehemently object to in this situation is the use of the first-person voice without my review or permission. The language used in the description makes it sound as if I wrote it (“In this post, I share my personal journey…”). Because I have fiercely protected my authorship throughout my life and what my name is attached to, any generative AI writing that purports to be in my voice without my informed consent is a profound violation of my authorial voice, agency, and frankly it feels like fraud or impersonation. As an archivist who has spent almost twenty years thinking about accuracy in information, it makes my skin crawl that there is a metadata field with the sole purpose of generating SEO-engagement purporting to be my voice that doesn’t disclose the authorship was actually non-consensual AI.</p>



<p>In recent days I’ve noticed this kind of “some people are saying” text showing up in my search results, especially related to Reddit threads. For example, a list of Google search results showing Reddit threads might show some description like “Some users are discussing the challenges of making a mug cake that doesn’t taste rubbery.” But even if this description had been in the third-person voice such as “This woman discusses her divorce and its impact on her….” my anger would remain.</p>



<p>Because what this AI-generated SEO slop formed from an extremely vulnerable and honest place shows is that women’s pain is still not taken seriously. The tone of the post is laden in the absolute worst therapy/wellness culture cliches (“Follow along as I share my story and insights on rebuilding, self-care, and finding happiness after divorce”) which is language that I abhor since it often trivializes women’s pain. I also object to the flattening of the contours of my particular divorce. There are really important distinctions between the experiences of women who initiate their own divorces versus women who come to a mutual agreement with their spouses to end the marriage versus women, like me, who are completely blindsided by their husbands’ decisions to suddenly end the marriage. All divorces do involve self-discovery and rebuilding your life, but the ways in which you begin down that path often involve dramatically different circumstances.&nbsp;</p>



<p>My story is absolutely layered through with trauma, humiliation, and sudden financial insecurity and I truly resent that this AI-generated garbage erases the deliberately uncomfortable and provocative words I chose to include in my original framing. If my story ends up becoming inspiring to others, that’s great, but that’s not why I share my pain on the internet. I share my pain publicly as a gesture of solidarity with other people, but especially women, who have been profoundly traumatized by those they thought they could love and trust. Having my pain witnessed and acknowledged is part of how I am healing while also letting other people know they are not alone. I have to externalize my pain in regular intervals right now because if I internalize it any more it might actually destroy me. Forcing an “inspiration” vibe onto what I posted feels tone deaf at best, and like toxic positivity at worst.&nbsp;&nbsp;&nbsp;&nbsp;</p>



<p>We already know that in a patriarchal society, women’s pain is dismissed, belittled, and ignored. This kind of AI-generated language also depoliticizes patriarchal power dynamics. Thinkers like <a href="https://safiyaunoble.com/">Dr. Safiya Noble</a> have been warning us for years that the prejudices carried by the people who design and maintain internet infrastructure continually shapes how we view and think about women and girls in society. I already felt immense pain and anger by the decision of my husband to suddenly end our marriage. And now I feel a double sense of violation that the men who design and maintain and profit from the internet have literally impersonated my voice behind the closed doors of hidden metadata to tell a more palatable version of the story they think will sell.&nbsp;</p>

				<hr>

        
        <p><strong>Tagged with:</strong> </p>
        <p><strong>Categorised as:</strong> <a href="https://eiratansey.com/category/uncategorized/" rel="category tag">Uncategorized</a> </p>

								
				<hr>
				
			</article>

			
<!-- You can start editing here. -->


			<!-- If comments are open, but there are no comments. -->

	 

  
		

		
		

		
	
  		</section>
		
  		<nav>
	<ul>
			</ul>
</nav>
  		

  		






		
				
	  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Build Android apps using Rust and Iced (150 pts)]]></title>
            <link>https://github.com/ibaryshnikov/android-iced-example</link>
            <guid>46350641</guid>
            <pubDate>Mon, 22 Dec 2025 02:14:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ibaryshnikov/android-iced-example">https://github.com/ibaryshnikov/android-iced-example</a>, See on <a href="https://news.ycombinator.com/item?id=46350641">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Example of building android app with iced</h2><a id="user-content-example-of-building-android-app-with-iced" aria-label="Permalink: Example of building android app with iced" href="#example-of-building-android-app-with-iced"></a></p>
<p dir="auto">There are <a href="https://github.com/ibaryshnikov/android-iced-example/blob/master/NativeActivity">NativeActivity</a> and <a href="https://github.com/ibaryshnikov/android-iced-example/blob/master/GameActivity">GameActivity</a> examples here.</p>
<p dir="auto">Based on several other examples:</p>
<ul dir="auto">
<li><code>na-mainloop</code> and <code>agdk-mainloop</code> from
<a href="https://github.com/rust-mobile/android-activity/tree/v0.6.0/examples">android-activity</a></li>
<li><a href="https://github.com/rust-mobile/rust-android-examples/tree/main/na-winit-wgpu">na-winit-wgpu</a>
from <code>rust-android-examples</code></li>
<li><a href="https://github.com/iced-rs/iced/tree/0.14/examples/integration">integration</a>
from <code>iced</code></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Preview</h2><a id="user-content-preview" aria-label="Permalink: Preview" href="#preview"></a></p>
<p dir="auto">iced integration example</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ibaryshnikov/android-iced-example/blob/master/pixel_1.png"><img src="https://github.com/ibaryshnikov/android-iced-example/raw/master/pixel_1.png" alt="Pixel first screenshot"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/ibaryshnikov/android-iced-example/blob/master/pixel_2.png"><img src="https://github.com/ibaryshnikov/android-iced-example/raw/master/pixel_2.png" alt="Pixed second screenshot"></a></p>
<p dir="auto">You can also run most of the examples from iced.
For this omit the scene rendering part and set the background of the root container.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Watch</h2><a id="user-content-watch" aria-label="Permalink: Watch" href="#watch"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ibaryshnikov/android-iced-example/blob/master/watch_1.png"><img src="https://github.com/ibaryshnikov/android-iced-example/raw/master/watch_1.png" alt="Watch first"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/ibaryshnikov/android-iced-example/blob/master/watch_2.png"><img src="https://github.com/ibaryshnikov/android-iced-example/raw/master/watch_2.png" alt="Watch second"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/ibaryshnikov/android-iced-example/blob/master/watch_3.png"><img src="https://github.com/ibaryshnikov/android-iced-example/raw/master/watch_3.png" alt="Watch third"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Text input</h2><a id="user-content-text-input" aria-label="Permalink: Text input" href="#text-input"></a></p>
<p dir="auto">Text input partially works, unresolved issues:</p>
<ul dir="auto">
<li>window doesn't resize on show/hide soft keyboard</li>
<li>how to change input language of soft keyboard</li>
<li>ime is not supported</li>
</ul>
<p dir="auto">Copy/paste and show/hide soft keyboard is implemented by calling Java</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ibaryshnikov/android-iced-example/blob/master/pixel_3.png"><img src="https://github.com/ibaryshnikov/android-iced-example/raw/master/pixel_3.png" alt="Pixel third screenshot"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building and running</h2><a id="user-content-building-and-running" aria-label="Permalink: Building and running" href="#building-and-running"></a></p>
<p dir="auto">Check <code>android-activity</code> crate for detailed instructions.
During my tests I was running the following command and using android studio afterwards:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export ANDROID_NDK_HOME=&quot;path/to/ndk&quot;
export ANDROID_HOME=&quot;path/to/sdk&quot;

rustup target add x86_64-linux-android
cargo install cargo-ndk

cargo ndk -t x86_64 -o app/src/main/jniLibs/  build"><pre><span>export</span> ANDROID_NDK_HOME=<span><span>"</span>path/to/ndk<span>"</span></span>
<span>export</span> ANDROID_HOME=<span><span>"</span>path/to/sdk<span>"</span></span>

rustup target add x86_64-linux-android
cargo install cargo-ndk

cargo ndk -t x86_64 -o app/src/main/jniLibs/  build</pre></div>
<p dir="auto">My setup is the following:</p>
<ul dir="auto">
<li>archlinux 6.9.6</li>
<li>jdk-openjdk 22</li>
<li>target api 35</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">How it works</h2><a id="user-content-how-it-works" aria-label="Permalink: How it works" href="#how-it-works"></a></p>
<p dir="auto">Thanks to <code>android-activity</code> we can already build android apps in Rust, and
key crates such as <code>winit</code> and <code>wgpu</code> also support building for android.
<code>iced</code> doesn't support android out of the box, but it can be integrated with
existing graphics pipelines, as shown in
<a href="https://github.com/iced-rs/iced/tree/0.13.1/examples/integration">integration</a> example.
As a result, it was possible to convert existing example running <code>winit</code> + <code>wgpu</code> to
use <code>iced</code> on top.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I wish people were more public (112 pts)]]></title>
            <link>https://borretti.me/article/i-wish-people-were-more-public</link>
            <guid>46349808</guid>
            <pubDate>Sun, 21 Dec 2025 23:42:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://borretti.me/article/i-wish-people-were-more-public">https://borretti.me/article/i-wish-people-were-more-public</a>, See on <a href="https://news.ycombinator.com/item?id=46349808">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>Probably not a popular thing to say today. The zeitgeisty thing to say
is that we should all log off and live terrible cottagecore solarpunk
lives raising chickens and being mindful. I wish people were more
online and more public. I have rarely wished the opposite. Consider
this post addressed to you, the reader.</p>

<h2 id="your-writing">Your Writing</h2>

<p>I will often find a blog post on <a href="https://news.ycombinator.com/">Hacker News</a> that really
resonates. And when I go to check the rest of the site there’s three
other posts. And I think: I wish you’d write more! When I find someone
whose writing I really connect with, I like to read everything they
have written, or at least a tractable subset of their most interesting
posts. If I like what I see, I reach out. This is one of the best
things about writing online: your future friends will seek you out.</p>

<p>And, from the other side, I have often written a post where, just
before publishing, I would think: “who would want to read this? It’s
too personal, obscure, idiosyncratic, probably a few people will
unsubscribe to the RSS feed for this”. And always those are the posts
where people email me to say they always thought the same thing but
could never quite put it into words. I really value those emails. “I
am understood” is a wonderful feeling.</p>

<p>I try to apply a rule that if I do something, and don’t write about
it—or otherwise generate external-facing evidence of it—it didn’t
happen. I have built so many things in the dark, little experiments or
software projects or essays that never saw the light of day. I want to
put more things out. If it doesn’t merit an entire blog post, then at
least a tweet.</p>

<h2 id="your-books">Your Books</h2>

<p>If I follow you on Twitter, and you have posted a picture of your
bookshelf, I have probably scanned every book in it. This is why I
appreciate <a href="https://www.goodreads.com/">Goodreads</a>. Like many people I have been reading a lot
less over the past ~5y, but since I made a Goodreads account earlier
this year, I’ve read tens of books. Reading in public has helped to
motivate me.</p>

<p>You may say reading in public is performative. I say reading in
private is solipsistic. Dante, in <a href="https://en.wikipedia.org/wiki/Monarchia"><em>De Monarchia</em></a>, writes:</p>

<blockquote>
  <p>All men on whom the Higher Nature has stamped the love of truth
should especially concern themselves in laboring for posterity, in
order that future generations may be enriched by their efforts, as
they themselves were made rich by the efforts of generations
past. For that man who is imbued with public teachings, but cares
not to contribute something to the public good, is far in arrears of
his duty, let him be assured; he is, indeed, not “a tree planted by
the rivers of water that bringeth forth his fruit in his season,”
[<a href="https://www.biblegateway.com/passage/?search=Psalm%201%3A3&amp;version=GNV">Psalms 1:3</a>] but rather a destructive whirlpool, always
engulfing, and never giving back what it has devoured.</p>
</blockquote>

<p>My default mode is solipsism. I read in private, build in private,
learn in private. And the problem with that is self-doubt and
arbitrariness. I’m halfway through a textbook and think: why? Why am I
learning geology? Why <em>this</em> topic, and not another? There is never an
<em>a priori</em> reason. I take notes, but why tweak the LaTeX if no-one,
probably not even future me, will read them? If I stop reading this
book, what changes?  And doing things in public makes them both more
real and (potentially) useful. If you publish your study notes, they
might be useful to someone. Maybe they get slurped up in the training
set of the next LLM, marginally improving performance.</p>

<p>And Goodreads, for all its annoyances, is a uniquely tender social
network. Finishing a book, and then seeing a friend mark it as “want
to read”, feels like a moment of closeness.</p>

<p>I have a friend who lived in Sydney, who has since moved away, and we
don’t keep in touch too often, because the timezones are inconvenient,
but occasionally she likes my book updates, and I like hers, and I
will probably never read that avant-garde novel, but I’m glad she is
reading it. It is like saying: “You exist. I exist. I remember. I wish
you happiness.”</p>

<h2 id="your-flashcards">Your Flashcards</h2>

<p>Lots of people use <a href="https://borretti.me/article/effective-spaced-repetition">spaced repetition</a>, but most everyone’s
flashcard collections are private. They exist inside a database inside
an app like <a href="https://apps.ankiweb.net/">Anki</a> or <a href="https://mochi.cards/">Mochi</a>. You can export decks, but
that’s not a living artifact but a dead snapshot, frozen in time.</p>

<p>One reason I built <a href="https://github.com/eudoxia0/hashcards">hashcards</a>: by using a Git repo of Markdown
files as the flashcard database, you can trivially publish your deck
to GitHub. <a href="https://github.com/eudoxia0/flashcards">My own flashcard collection</a> is public. I hope that
more people use hashcards and put their decks up on GitHub.</p>

<p>The point is not that you can clone their repos (which is close to
useless: you have to write your own flashcards) but because I’m
curious what people are learning. Not the broad strokes, since we all
want to learn thermo and econ and quantum chemistry and the military
history of the Song dynasty and so on, but the minutiae. Why did you
make a flashcard out of this Bible passage? Why does it resonate with
you? Why do you care about the interpretation of that strange passage
in <em>Antigone</em>? Why did you memorize this poem?</p>

<h2 id="your-dotfiles">Your Dotfiles</h2>

<p>Computers mediate every aspect of our lives, yet most people use their
computers the way they came out of the box. At most they might change
the desktop background. Some people don’t even change the default
icons on the macOS dock. Even most Linux users just use the stock
configuration, e.g. GNOME on Fedora or whatever.</p>

<p>I’m interested in people who customize their experience of
computing. This is often derided as “<a href="https://en.wiktionary.org/wiki/rice_out#English">ricing</a>”. But agency is
interesting. People who remake their environment to suit them are
interesting. And I am endlessly curious about how people do this. I
like reading people’s <code>init.el</code>, their custom shell scripts, their
NixOS config. It’s even better if they have some obscure hardware
e.g. some keyboard layout I’ve never heard of and a trackball with
custom gestures. I put my <a href="https://github.com/eudoxia0/dotfiles">dotfiles</a> up on GitHub because I
imagine someone will find them interesting.</p>

<h2 id="etc">etc.</h2>

<p>And beyond my selfish curiosity there’s also the <a href="https://en.wikipedia.org/wiki/Nikolai_Fyodorov_(philosopher)">Fedorovist</a>
<a href="https://en.wikipedia.org/wiki/Frank_J._Tipler">ancestor</a> <a href="https://en.wikipedia.org/wiki/Omega_Point">simulation</a> angle: if you die and are not
cryopreserved, how else are you going to make it to the other side of
the intelligence explosion? Every tweet, blog post, Git commit,
journal entry, keystroke, mouse click, every one of these things is a
tomographic cut of the mind that created it.</p>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Disney Imagineering Debuts Next-Generation Robotic Character, Olaf (268 pts)]]></title>
            <link>https://disneyparksblog.com/disney-experiences/robotic-olaf-marks-new-era-of-disney-innovation/</link>
            <guid>46348847</guid>
            <pubDate>Sun, 21 Dec 2025 21:46:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://disneyparksblog.com/disney-experiences/robotic-olaf-marks-new-era-of-disney-innovation/">https://disneyparksblog.com/disney-experiences/robotic-olaf-marks-new-era-of-disney-innovation/</a>, See on <a href="https://news.ycombinator.com/item?id=46348847">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
        <p>Disneyland Paris saw a groundbreaking moment today, where Bruce Vaughn, President and Chief Creative Officer of Walt Disney Imagineering, and Natacha Rafalski, Présidente of Disneyland Paris, introduced a next-generation robotic character representing Olaf, the beloved snowman from Walt Disney Animation Studios’ <em>Frozen</em>. </p>

<p>This debut marks a new chapter in Disney character innovation, one where technology, storytelling, and collaboration come together to bring screen to reality.&nbsp;</p>

<div>
<figure><img decoding="async" width="1620" height="1080" src="https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-3-1620x1080.jpg" alt="Robotic Olaf Marks New Era of Disney Innovation" srcset="https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-3-1620x1080.jpg 1620w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-3-647x431.jpg 647w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-3-212x141.jpg 212w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-3-768x512.jpg 768w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-3-1536x1024.jpg 1536w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-3-1024x683.jpg 1024w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-3.jpg 1920w" sizes="(max-width: 1620px) 100vw, 1620px"><figcaption><em>Prototype-completed design varies</em>.</figcaption></figure></div>


<h2>Innovation at the Core: From Screen to Reality</h2>


<p>From the way he moves to the way he looks, every gesture and detail is crafted to reflect the Olaf audiences have seen in the film — alive, curious, and unmistakably himself. As for his snow-like shimmer that catches the light just like fresh snow, this was enhanced by iridescent fibers. These details make Olaf one of the most expressive and true-to-life characters built, and he’s soon making his debut at Disney parks.&nbsp;</p>



<p>Our roots are in animation with Walt Disney pioneering early hand-drawn films and today, Walt Disney Animation Studios and Pixar Animation Studios continue that tradition. We collaborated closely with the film’s original animators at Walt Disney Animation Studios to ensure every gesture felt true to the character. This isn’t just about replicating the animation, it’s about emulating the creators’ intent.&nbsp;&nbsp;</p>

<div>
<figure><img decoding="async" width="1920" height="1079" src="https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-6.png" alt="Robotic Olaf Marks New Era of Disney Innovation" srcset="https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-6.png 1920w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-6-767x431.png 767w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-6-250x141.png 250w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-6-768x432.png 768w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-6-1536x863.png 1536w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-6-848x477.png 848w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-6-1024x575.png 1024w" sizes="(max-width: 1920px) 100vw, 1920px"><figcaption><em>Prototype-completed design varies</em>.</figcaption></figure></div>


<h2>The Technology Behind the Magic</h2>


<p>Home to some of the best storytellers in the world, we’re continuously pushing the boundaries of innovation and technology — in fact it is in our DNA.&nbsp;</p>

<p>Like everything at Disney, we always start with the story, and our number one priority is to build storytelling technology that empowers our Disney Imagineers to breathe life into our characters.&nbsp;&nbsp;</p>

<div>
<figure><img loading="lazy" decoding="async" width="1913" height="1080" src="https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-4-1913x1080.png" alt="Robotic Olaf Marks New Era of Disney Innovation" srcset="https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-4-1913x1080.png 1913w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-4-763x431.png 763w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-4-250x141.png 250w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-4-768x434.png 768w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-4-1536x867.png 1536w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-4-1024x578.png 1024w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-4.png 1920w" sizes="(max-width: 1913px) 100vw, 1913px"><figcaption><em>Prototype-completed design varies</em>.</figcaption></figure></div>

<p>While the BDX droids — the Star Wars free roaming robotic characters that mimic movements in a simulation — have been interacting with guests for a while now, Olaf presents a far greater challenge: an animated character with non-physical movements. To make Olaf as authentic as possible, the team used a branch of artificial intelligence called reinforcement learning, pushing the limits of hardware to achieve the creative intent of the artists. </p>

<p>It takes humans years to master walking and even longer to perform graceful motions. Deep reinforcement learning helps him acquire these skills in a fraction of the time.&nbsp;&nbsp;</p>

<div>
<figure><img loading="lazy" decoding="async" width="1909" height="1080" src="https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-5-1909x1080.png" alt="Robotic Olaf Marks New Era of Disney Innovation" srcset="https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-5-1909x1080.png 1909w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-5-762x431.png 762w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-5-250x141.png 250w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-5-768x434.png 768w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-5-1536x869.png 1536w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-5-1024x579.png 1024w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-5.png 1920w" sizes="(max-width: 1909px) 100vw, 1909px"><figcaption><em>Prototype-completed design varies</em>.</figcaption></figure></div>

<p>Olaf’s “snow” also moves differently than the hard shells of other robotic characters, and he can fully articulate his mouth, eyes, and removable carrot nose and arms. Most importantly, Olaf can speak and engage in conversations, creating a truly one-of-a-kind experience.&nbsp;</p>

<p>Innovation takes many forms across our parks, experiences, and products – all focused on improving the guest experience and bringing joy to fans around the world. And what’s most exciting is that we’re just getting started!&nbsp;&nbsp;</p>

<p>The BDX Droids, <a href="https://disneyparksblog.com/disney-experiences/herbie-from-the-fantastic-four-first-steps-at-disneyland/" target="_blank" rel="noreferrer noopener">self-balancing H.E.R.B.I.E.</a>, and now Olaf represent increasing levels of performance and innovation in bringing Disney characters to life. The speed at which we can create new characters and introduce them to guests is unprecedented. We’re scaling bigger than ever, working to bring more emotive, expressive, and surprising characters to our experiences around the world. </p>

<div>
<figure><img loading="lazy" decoding="async" width="720" height="1080" src="https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-2-720x1080.jpg" alt="Robotic Olaf Marks New Era of Disney Innovation" srcset="https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-2-720x1080.jpg 720w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-2-287x431.jpg 287w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-2-94x141.jpg 94w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-2-768x1152.jpg 768w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-2-1024x1536.jpg 1024w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-2-1365x2048.jpg 1365w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-2-512x768.jpg 512w, https://disneyparksblog.com/app/uploads/2025/11/2025-WDI-Olaf-Robotic-Character-2-scaled.jpg 1707w" sizes="(max-width: 720px) 100vw, 720px"><figcaption><em>Prototype-completed design varies</em>.</figcaption></figure></div>


<h2>Where Guests Can See Olaf</h2>


<p>Olaf will soon venture out into the unknown, eager to see guests at:</p>

<div>
<ul>
<li>Arendelle Bay Show in World of Frozen, the new immersive world coming soon to Disney Adventure World at Disneyland Paris.</li>



<li>Limited-time special appearances at World of Frozen at Hong Kong Disneyland Resort.</li>
</ul>
</div>

<p>Looking for a warm hug now? You can discover how Olaf, along with other exciting breakthroughs from Walt Disney Imagineering Research &amp; Development, came to life at in the latest episode of <a href="https://www.youtube.com/watch?v=EoPN02bmzrE" target="_blank" rel="noreferrer noopener"><em>We Call It Imagineering</em>.</a></p>


            
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The gift card accountability sink (107 pts)]]></title>
            <link>https://www.bitsaboutmoney.com/archive/gift-card-accountability-sink/</link>
            <guid>46348455</guid>
            <pubDate>Sun, 21 Dec 2025 21:07:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bitsaboutmoney.com/archive/gift-card-accountability-sink/">https://www.bitsaboutmoney.com/archive/gift-card-accountability-sink/</a>, See on <a href="https://news.ycombinator.com/item?id=46348455">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p><em>Programming note</em>: <em>Merry Christmas</em>! <em>There will likely be another Bits about Money after the holiday but before New Year. </em></p><p><em>Bits about Money is </em><a href="https://www.bitsaboutmoney.com/memberships/" rel="noreferrer"><em>supported by our readers</em></a><em>. If your education budget or business can underwrite the coming year of public goods in financial-infrastructure education, commentary, and policy analysis, please consider supporting it. I’m told this is particularly helpful for policymakers and others who cannot easily expense a subscription, and who benefit from all issues remaining publicly available with no paywall.</em></p><p>The American Association of Retired People (AARP, an advocacy non-profit for older adults) has paid for ads on podcasts I listen to. The ad made a claim which felt raspberry-worthy (in service of an important public service announcement), which they <a href="https://www.aarp.org/money/scams-fraud/gift-card-payment/"><u>repeat in writing</u></a>: <em>Asking to be paid by gift card is always a scam</em>.</p><p>Of course it isn’t. Gift cards are a payments rail, and an <em>enormous</em> business independently of being a payments rail. Hundreds of firms will indeed ask you to pay them on gift cards! They also exist, and are marketed, explicitly to do the thing that the AARP implicitly asserts no business or government entity will ever do: provide a method for transacting for people who do not have a banked method of transacting. [0]</p><p>Gift card scams are also enormous. The FBI’s Internet Crime Complaint Center received <a href="https://www.ic3.gov/AnnualReport/Reports/2024_IC3Report.pdf"><u>$16.6 billion</u></a> in reports in 2024 across several payment methods; this is just for those consumers who bothered reporting it, in spite of the <em>extremely real</em> received wisdom that reporting is unlikely to improve one’s direct situation.</p><p>The flavor texts of scams vary wildly, but in substance they’ll attempt to convince someone, often someone socially vulnerable, to part with sometimes very large sums of money by buying gift cards and conveying card information (card number and PIN number, both printed on the card) to the scammer. The scammer will then use the <a href="https://www.bitsaboutmoney.com/archive/the-fraud-supply-chain/"><u>fraud supply chain</u></a>, generally to swap the value on the card to another actor in return for value unconnected to the card. This can be delivered in many ways: cash, crypto, products and services in the scamming economy (such as purloined credit cards or even “lead lists” of vulnerable people to run more scams on), or <a href="https://www.bitsaboutmoney.com/archive/kyc-and-aml-beyond-the-acronyms/"><u>laundered</u></a> funds within regulated financial institutions which obscure the link between the crime and the funds (layering, in the parlance of AML professionals). A huge portion of <a href="https://www.bitsaboutmoney.com/archive/gift-card-marketplaces/"><u>running a gift card marketplace</u></a> is trying to prevent yourself from being exploited or made into an instrumentality in exploiting others.</p><p>It surprises many people to learn that the United States <a href="https://www.consumerfinance.gov/rules-policy/regulations/1005/"><u>aggressively defends customers from fraud over some payment methods</u></a>, via a liability transfer to their financial institution, which transfers it to intermediaries, who largely transfer it to payment-accepting businesses. Many people think the U.S. can’t make large, effective, pro-consumer regulatory regimes. They are straightforwardly wrong… some of the time.</p><p>But the AARP, the FBI, and your friendly local payments nerd will all tell you that if you’re abused on your debit card you are quite likely to be made whole, and if you’re abused via purchasing gift cards, it is unlikely any deep pockets will cover for you. The difference in treatment is partially regulatory carveouts, partially organized political pressure, and partly a side effect of an accountability sink specific to the industrial organization of gift cards.</p><h2 id="most-businesses-do-not-run-their-own-gift-card-programs">Most businesses do not run their own gift card programs</h2><p>There exists an ecosystem of gift card program managers, who are essentially financial services businesses with a sideline in software. (I should probably mention that I previously worked for and am currently an advisor to Stripe, whose self conception would not be precisely that, but which a) supports many ways for people to pay money for things and b) does not necessarily endorse what I say in my personal spaces.)</p><p>Why does the program manager exist? Why not simply have the retailer keep some internal database of who the retailer owes money to, updating this when someone buys or loads a gift card and when they spend the balance at the store? Because this implies many capabilities that retailers do not necessarily have, such as e.g. software development teams.</p><p>There is also a large regulatory component to running a gift card program, despite gift cards’ relatively lax regulatory drag (we’ll return to that in a moment). Card programs are regulated at both the federal and state levels. One frequent requirement in several states is escheatment. (Essentially all states have a requirement for escheatment; many but not all <a href="https://www.alston.com/en/insights/publications/2024/11/developments-impacting-gift-card-programs"><u>exempt gift cards from it</u></a>.)</p><p>As <a href="https://www.bitsaboutmoney.com/archive/more-than-you-want-to-know-about-gift-cards/"><u>discussed previously</u></a> in Bits about Money, a major component of the gift card business model is abandonment (“breakage”). Consumer advocates felt this was unfair to consumers, bordering on fraudulent really. They convinced states to take the money that retailers were keeping for themselves. (Many states didn’t take all that much convincing.)&nbsp;</p><p>In theory, and sometimes even in practice, a consumer can convince a state treasurer’s office of unclaimed property (e.g. <a href="https://icash.illinoistreasurer.gov/"><u>Illinois</u></a>’) that the $24.37 that Target remitted as part of its quarterly escheatment payment for an unused gift card 13 years ago was actually theirs. A consumer who succeeds at this, which is neither easy nor particularly inexpensive to do, will receive a $24.37 check in the mail. The state keeps the interest income; call it a fee for service. It also keeps the interest income of the tens of billions of dollars of accumulated unclaimed property, which it generally promises to dutifully custody awaiting a legitimate claim for as long as the United States shall exist.</p><p>And so if you are a regional or national retailer who wants to offer gift cards, you have a choice. You can dedicate a team of internal lawyers and operations specialists to understanding both what the laws of the several states require with respect to gift cards, which are a <em>tiny</em> portion of your total operations, not merely today but as a result of the next legislative session in Honolulu, because you <em>absolutely must </em>order the software written to calculate the payment to remit accurately several quarters in advance of the legal requirement becoming effective. Or you can make the much more common choice, and outsource this to a specialist.</p><p>That specialist, the gift card program manager, will sell you a Solution™ which integrates across all the surfaces you need: your point-of-sale systems, your website, your accounting software, the 1-800 number and website for customers to check balances, ongoing escheatment calculation and remittance, cash flow management, <em>carefully titrated </em>amounts of attention to other legal obligations like AML compliance, etc. Two representative examples: Blackhawk Network and InComm Payments. You’ve likely never heard of them, even if you have their product on your person right now. Their <em>real</em> customer has the title Director of Payments at e.g. a Fortune 500 company.</p><p>And here begins the accountability sink: by standard practice and contract, when an unsophisticated customer is abused by being asked to buy a BigCo gift card, BigCo will say, truthfully and unhelpfully, that BigCo does not issue BigCo gift cards. It sells them. It accepts them. But it does not issue them. Your princess is in another castle.</p><p>BigCo may very well have a large, well-staffed fraud department. But, not due to any sort of malfeasance whatsoever, that fraud department may consider BigCo gift cards <em>entirely out of their own scope</em>. They <em>physically cannot access the database with the cards</em>. Their security teams, sensitive that gift card numbers are dangerous to keep lying around, very likely made it impossible for anyone at BigCo to reconstruct what happened to a particular gift card between checkout and most recent use. “Your privacy is important to us!” they will say, and they are not cynically invoking it in this case.</p><h2 id="gift-cards-are-not-regulated-like-other-electronic-payments-instruments">Gift cards are not regulated like other electronic payments instruments</h2><p>As mentioned above, Regulation E is the primary driver for the private enforcement edifice that makes scarily smart professionals (and their attached balance sheets) swing into action on behalf of consumers. Reg E has a carveout for certain prepaid payments. Per <a href="https://files.consumerfinance.gov/f/documents/cfpb_prepaid_small-entity-compliance-guide.pdf"><u>most recent guidance</u></a>, that includes prepaid gift cards, gift certificates, and similar.</p><p>And so, if you call your bank and say, “I was defrauded! Someone called me and pretended to be the IRS, and I read them my debit card number, and now I’ve lost money,” the state machine obligates the financial institution to have the customer service representative click a very prominent button on their interface. This will restore your funds very quickly and have some side effects you probably care about much less keenly. One of those is an “investigation,” which is not really an investigation in the commanding majority of cases.</p><p>And if you call the program manager and say, “I was defrauded! Someone called me and pretended to be the IRS, and I read them a gift card number, and now I’ve lost money,” there is… no state machine. There is no legal requirement to respond with alacrity, no statutorily imposed deadline, no button for a CS rep to push, and no investigation to launch. You will likely be told by a low-paid employee that this is unfortunate and that you should file a police report. The dominant reason for this is that suggesting a concrete action to you gets you off the phone faster, and the call center aggressively minimizes time to resolution of calls and recidivism, where you call back because your problem is not solved. Filing a police report will, in most cases, not restore your money—but if it causes you not to call the 1-800 number again, then from the card program manager’s perspective <em>this issue has been closed successfully</em>.</p><h2 id="why-do-we-choose-this-difference-in-regulation">Why do we choose this difference in regulation?</h2><p>The people of the United States, through their elected representatives and the civil servants who labor on their behalf, intentionally exempt gift cards from the Reg E regime in the interest of facilitating commerce.</p><p>It is the ordinary and appropriate work of a democracy to include input from citizens in the rulemaking process. The Retail Industry Leaders Association <a href="https://rilastagemedia.blob.core.windows.net/rila-web/rila.web/media/media/pdfs/regulatory%20letters/fincen/2011/comments-on-prepaid-access-regulations.pdf?ext=.pdf"><u>participated</u></a>, explaining to FinCEN that it would be quite burdensome for retailers to fall into KYC scope, etc etc. Many other lobbyists and industry associations made directionally similar comments.</p><p>The Financial Crimes Enforcement Network, for example, has an <a href="https://www.fincen.gov/news/news-releases/fincen-issues-prepaid-access-final-rule"><u>explicit carveout</u></a> in its regulations: while FinCEN will <a href="https://www.bitsaboutmoney.com/archive/debanking-and-debunking/"><u>aggressively police rogue bodegas</u></a>, it has no interest in you if you sell closed-loop gift cards of less than $2,000 face value. This is explicitly to balance the state’s interest in law enforcement against, quote, preserving innovation and the many legitimate uses and societal benefits offered by prepaid access, endquote.</p><p>FinCEN’s rules clarify that higher-value activity—such as selling more than $10,000 in gift cards to a single individual in a day—brings sellers back into scope. Given the relatively lax enforcement environment for selling a $500 gift card, you very likely might not build out systems which will successfully track customer identities and determine that the same customer has purchased twenty-one $500 gift cards in three transactions. That likely doesn’t rate as a hugely important priority for Q3.&nbsp;</p><p>And so the fraud supply chain comes to learn which firms haven’t done that investment, and preferentially suggests those gift cards to their launderers, <a href="https://theintercept.com/2018/11/23/bitcoin-gift-card-trading-scams/"><u>mules</u></a>, <a href="https://globalchinapulse.net/moving-bricks-money-laundering-practices-in-the-online-scam-industry/"><u>brick movers</u></a>, and scam victims.</p><p>And that’s why the AARP tells fibs about gift cards: we have, with largely positive intentions and for good reasons, exposed them to less regulation than most formal payment systems in the United States received. That decision has a cost. Grandma sometimes pays it.</p><p>[0] Indeed, there are entire companies which exist to turn gift cards into an alternate financial services platform, explicitly to give unbanked and underbanked customers a payments rail. <a href="https://www.paysafe.com/us-en/"><u>Paysafe</u></a>, for example, is a publicly traded company with thousands of employees, the constellation of regulatory supervision you’d expect, and a subsidiary <a href="https://www.openbucks.com/company/about/"><u>Openbucks</u></a> which is designed to give businesses the ability to embed Pay Us With A Cash Voucher in their websites/invoices/telephone collection workflows. This is exactly the behavior that “never happens from a legitimate business” except when it does by the tens of billions of dollars.</p><p>As Bits about Money has frequently observed, people who write professionally about money—including professional advocates for financially vulnerable populations—often misunderstand alternative financial services, largely because those services are designed to serve a social class that professionals themselves do not belong to, rarely interact with directly, and do not habitually ask how they pay rent, utilities, or phone bills.</p>

        

        <div>
          <h2>Want more essays in your inbox?</h2>
          <p>I write about the intersection of tech and finance, approximately biweekly. It's free.</p>
                  </div>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A guide to local coding models (557 pts)]]></title>
            <link>https://www.aiforswes.com/p/you-dont-need-to-spend-100mo-on-claude</link>
            <guid>46348329</guid>
            <pubDate>Sun, 21 Dec 2025 20:55:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.aiforswes.com/p/you-dont-need-to-spend-100mo-on-claude">https://www.aiforswes.com/p/you-dont-need-to-spend-100mo-on-claude</a>, See on <a href="https://news.ycombinator.com/item?id=46348329">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!fARn!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb194c53f-7b2b-4f74-942b-5cf1c59b32aa_1920x1080.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!fARn!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb194c53f-7b2b-4f74-942b-5cf1c59b32aa_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/$s_!fARn!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb194c53f-7b2b-4f74-942b-5cf1c59b32aa_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/$s_!fARn!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb194c53f-7b2b-4f74-942b-5cf1c59b32aa_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!fARn!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb194c53f-7b2b-4f74-942b-5cf1c59b32aa_1920x1080.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!fARn!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb194c53f-7b2b-4f74-942b-5cf1c59b32aa_1920x1080.jpeg" width="1456" height="819" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b194c53f-7b2b-4f74-942b-5cf1c59b32aa_1920x1080.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:80981,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.aiforswes.com/i/182132050?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb194c53f-7b2b-4f74-942b-5cf1c59b32aa_1920x1080.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!fARn!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb194c53f-7b2b-4f74-942b-5cf1c59b32aa_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/$s_!fARn!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb194c53f-7b2b-4f74-942b-5cf1c59b32aa_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/$s_!fARn!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb194c53f-7b2b-4f74-942b-5cf1c59b32aa_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!fARn!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb194c53f-7b2b-4f74-942b-5cf1c59b32aa_1920x1080.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><em>[Edit 1] This article has been edited after initial release for clarity. Both the tl;dr and the end section have added information.</em></p><p><em><span>[Edit 2] This hypothesis was </span><strong>actually wrong</strong><span> and thank you to everyone who commented! </span></em></p><p><em>Here’s a full explanation of where I went wrong. I want to address this mistake as I realize it might have a meaningful impact on someone's financial position.</em></p><p><em><span>I’m </span><strong>not </strong><span>editing the actual article except where absolutely necessary so it doesn’t look like I’m covering up the mistake—I want to address it. Instead, I’ve included the important information below. </span></em></p><p><em>There is one takeaway this article provides that definitely holds true:</em></p><ul><li><p><em>Local models are far more capable than they’re given credit for, even for coding.</em></p></li></ul><p><em>It also explains the process of setting up a local coding model and technical information about doing so which is helpful for anyone wanting to set up a local coding model. I would still recommend doing so.</em></p><p><em><strong>But do I want someone reading this to immediately drop their coding subscription and buy a maxed out MacBook Pro? No, and for that reason I need to correct my hypothesis from ‘Yes, with caveats’ to ‘No’.</strong></em></p><p><em>This article was not an empirical assessment, but should have been to make these claims. Here’s where I went wrong:</em></p><ul><li><p><em>While local models can likely complete ~90% of the software development tasks that something like Claude Code can, the last 10% is the most important. When it comes to your job, that last 10% is worth paying more for to get that last bit of performance.</em></p></li><li><p><em><span>I realized I looked at this more from the angle of a hobbiest paying for these coding tools. Someone doing little side projects—not someone in a production setting. I did this because I see a lot of people signing up for $100/mo or $200/mo coding subscriptions for personal projects when they likely don’t need to. </span><strong>I would not recommend running local models as a company</strong><span> instead of giving employees access to a tool like Claude Code.</span></em></p></li><li><p><em>While larger local models are very capable, as soon as you run other development tools (Docker, etc.) that also eat into your RAM, your model needs to be much smaller and becomes a lot less capable. I didn’t factor this in in my experiment.</em></p></li></ul><p><em>So, really, the takeaway should be that these are incredible supplemental models to frontier models when coding and could potentially save you on your subscription by dropping it down a tier, but practically they’re not worth the effort in situations that might affect your livelihood.</em></p><p>Exactly a month ago, I made a hypothesis: Instead of paying $100/mo+ for an AI coding subscription, my money would be better spent upgrading my hardware so I can run local coding models at a fraction of the price (and have better hardware too!).</p><p>So, to create by far the most expensive article I’ve ever written, I put my money where my mouth is and bought a MacBook Pro with 128 GB of RAM to get to work. My idea was simple: Over the life of the MacBook I’d recoup the costs of it by not paying for an AI coding subscription.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!msVz!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1c9d7143-3d10-4898-923a-7bc517ca615a_1196x764.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!msVz!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1c9d7143-3d10-4898-923a-7bc517ca615a_1196x764.png 424w, https://substackcdn.com/image/fetch/$s_!msVz!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1c9d7143-3d10-4898-923a-7bc517ca615a_1196x764.png 848w, https://substackcdn.com/image/fetch/$s_!msVz!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1c9d7143-3d10-4898-923a-7bc517ca615a_1196x764.png 1272w, https://substackcdn.com/image/fetch/$s_!msVz!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1c9d7143-3d10-4898-923a-7bc517ca615a_1196x764.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!msVz!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1c9d7143-3d10-4898-923a-7bc517ca615a_1196x764.png" width="618" height="394.7759197324415" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1c9d7143-3d10-4898-923a-7bc517ca615a_1196x764.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:764,&quot;width&quot;:1196,&quot;resizeWidth&quot;:618,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!msVz!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1c9d7143-3d10-4898-923a-7bc517ca615a_1196x764.png 424w, https://substackcdn.com/image/fetch/$s_!msVz!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1c9d7143-3d10-4898-923a-7bc517ca615a_1196x764.png 848w, https://substackcdn.com/image/fetch/$s_!msVz!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1c9d7143-3d10-4898-923a-7bc517ca615a_1196x764.png 1272w, https://substackcdn.com/image/fetch/$s_!msVz!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1c9d7143-3d10-4898-923a-7bc517ca615a_1196x764.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>After weeks of experimenting and setting up local AI models and coding tools, I’ve come to the conclusion that </span><strong><span>my hypothesis was </span><s>correct, with nuance</s></strong><span>,</span><strong> not correct </strong><span>[see edit 2 above] which I’ll get into later in this article.</span></p><p>In this article, we cover:</p><ul><li><p>Why local models matter and the benefits they provide.</p></li><li><p>How to view memory usage and make estimates for which models can run on your machine and the RAM demands for coding applications.</p></li><li><p>Walk through setting up your own local coding model and tool step-by-step.</p></li></ul><p>Don’t worry if you don’t have a high-RAM machine! You can still follow this guide. I’ve included some models to try out with a lower memory allotment. I think you’ll be surprised at how performant even the smallest of models is. In fact, there hasn’t really been a time during this experiment that I’ve been disappointed with model performance.</p><p>If you’re only here for the local coding tool setup, skip to the section at the bottom. I’ve even included a link to my modelfiles in that section to make setup even easier for you. Otherwise, let’s get into what you need to know.</p><ul><li><p><strong>Local coding models are very capable</strong><span>. Using the right model and the right tooling feels only half a generation behind the frontier cloud tools. I would say that for about 90% of developer work local models are more than sufficient. Even small 7B parameter models can be very capable. </span><strong>[Edited to add in this next part]</strong><span> Local models won’t compete with frontier models at the peak of performance, but can complete many coding tasks just as well for a fraction of the cost. They’re worth running to bring costs down on plenty of tasks but potentially not worth using if there’s a free tier available that performs better.</span></p></li><li><p><strong>Tools matter a lot</strong><span>. This is where I experienced the most disappointment. I tried many different tools with many different models and spent a lot of time tinkering. I ran into situations where the models wouldn’t call tools properly or their thinking traces wouldn’t close. Both of these rendered the tool essentially useless. Currently, tooling seems very finicky and if there’s anything developers need to be successful, it’s good tools.</span></p></li><li><p><strong>There’s a lot to consider when you’re actually working within hardware constraints.</strong><span> We take the tooling set up for us in the cloud for granted. When setting up local models, I had to think a lot about trade-offs in performance versus memory usage, how different tools compared and affected performance, nuances in types of models, how to quantize, and other user-facing factors such as time-to-first-token and tokens per second.</span></p></li><li><p><strong>Google threw a wrench into my hypothesis</strong><span>. The local setup is almost a no-brainer when compared to a $100/mo+ subscription. Compared to free or nearly-free tooling (such as Gemini CLI, Jules, or Antigravity) there isn’t quite as strong of a monetary justification to spend more on hardware. There are benefits to local models outside of code, though, and I discuss those below. </span></p></li></ul><p>If the tl;dr was helpful, don’t forget to subscribe to get more in your inbox.</p><p><span>You might wonder why local models are worth investing in at all. The obvious answer is </span><strong>cost</strong><span>. By using your own hardware, you don’t need to pay a subscription fee to a cloud provider for your tool. There are also a few less obvious and underrated reasons that make local models useful.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!OUrN!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c71b176-e011-4694-915e-217a2e3ce9b5_1920x1080.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!OUrN!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c71b176-e011-4694-915e-217a2e3ce9b5_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/$s_!OUrN!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c71b176-e011-4694-915e-217a2e3ce9b5_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/$s_!OUrN!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c71b176-e011-4694-915e-217a2e3ce9b5_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!OUrN!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c71b176-e011-4694-915e-217a2e3ce9b5_1920x1080.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!OUrN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c71b176-e011-4694-915e-217a2e3ce9b5_1920x1080.jpeg" width="1456" height="819" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0c71b176-e011-4694-915e-217a2e3ce9b5_1920x1080.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:140073,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.aiforswes.com/i/182132050?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c71b176-e011-4694-915e-217a2e3ce9b5_1920x1080.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!OUrN!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c71b176-e011-4694-915e-217a2e3ce9b5_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/$s_!OUrN!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c71b176-e011-4694-915e-217a2e3ce9b5_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/$s_!OUrN!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c71b176-e011-4694-915e-217a2e3ce9b5_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!OUrN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0c71b176-e011-4694-915e-217a2e3ce9b5_1920x1080.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>First: </span><strong>Reliability</strong><span>. Each week there seems to be complaints about performance regression within AI coding tools. Many speculate companies are pulling tricks to save resources that hurt model performance. With cloud providers, you’re at the mercy of the provider for when this happens. With local models, this only happens when you cause it to.</span></p><p><span>Second: </span><strong>Local models can apply to </strong><em><strong>far </strong></em><strong>more applications</strong><span>. Just the other day I was having a discussion with my dad about AI tooling he could use to streamline his work. His job requires studying a lot of data—a perfect application for an LLM-based tool—but his company blocks tools like Gemini and ChatGPT because a lot of this analysis is done on intellectual property. Unfortunately, he isn’t provided a suitable alternative to use.</span></p><p>With a local model, he wouldn’t have to worry about these IP issues. He could run his analyses without data ever leaving his machine. Of course, any tool calling would also need to ensure data never leaves the machine, but local models get around one of the largest hurdles for useful enterprise AI adoption. Running models on a local machine opens up an entire world of privacy- and security-centric AI applications that are expensive for cloud providers to provide.</p><p><span>Finally: </span><strong>Availability. </strong><span>Local models are available to you as long as your machine is. This means no worrying about your provider being down or rate limiting you due to high traffic. It also means using AI coding tools on planes or in other situations where internet access is locked down (think highly secure networks).</span></p><p>While local models do provide significant cost savings, the flexibility and reliability they provide can be even more valuable.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!LxTS!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95d992f8-225f-4b06-8fb9-e9d7544cf2d5_1920x1080.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!LxTS!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95d992f8-225f-4b06-8fb9-e9d7544cf2d5_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/$s_!LxTS!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95d992f8-225f-4b06-8fb9-e9d7544cf2d5_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/$s_!LxTS!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95d992f8-225f-4b06-8fb9-e9d7544cf2d5_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!LxTS!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95d992f8-225f-4b06-8fb9-e9d7544cf2d5_1920x1080.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!LxTS!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95d992f8-225f-4b06-8fb9-e9d7544cf2d5_1920x1080.jpeg" width="1456" height="819" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/95d992f8-225f-4b06-8fb9-e9d7544cf2d5_1920x1080.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:136854,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.aiforswes.com/i/182132050?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95d992f8-225f-4b06-8fb9-e9d7544cf2d5_1920x1080.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!LxTS!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95d992f8-225f-4b06-8fb9-e9d7544cf2d5_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/$s_!LxTS!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95d992f8-225f-4b06-8fb9-e9d7544cf2d5_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/$s_!LxTS!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95d992f8-225f-4b06-8fb9-e9d7544cf2d5_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!LxTS!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95d992f8-225f-4b06-8fb9-e9d7544cf2d5_1920x1080.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>To get going with local models you must understand the memory needed to run them on your machine. Obviously, if you have more memory you’ll be able to run better models, but understanding the nuances of that memory management will help you pick out the right model for your use case.</p><p>Local AI has two parts that eat up your memory: The model itself and the model’s context window.</p><p>The actual model has billions of parameters and all those parameters need to fit into your memory at once. Excellent local coding models start at around 30 billion (30B, for short) parameters in size. By default, these models use 16 bits to represent parameters. At 16 bits with 30B parameters, a model will take 60 GB of space in RAM (16 bits = 2 bytes per parameter, 30 billion parameters = 60 billion bytes which equals about 60 GB).</p><p>The second (and potentially larger) memory consuming part of local AI is the model’s context window. This is the model inputs and outputs that are stored so the model can reference them in future requests. This gives the model memory.</p><p>When coding with AI, we prefer this window to be as large as it can because we need to fit our codebase (or pieces of it) within our context window. This means we target a context window of 64,000 tokens or larger. All of these tokens will also be stored in RAM.</p><p>The important thing to understand about context windows is that the memory requirement per-token for a model depends on the size of that model. Models with more parameters tend to have large architectures (more hidden layers and larger dimensions to those layers). Larger architectures mean the model must store more information for each token within its key-value cache (context window) because it stores information for each token for each layer.</p><p>This means choosing an 80B parameter model over a 30B parameter model requires more memory for the model itself and also more memory for the same size context window. For example, a 30B parameter model might have a hidden dimension of 5120 with 64 layers while an 80B model has a hidden dimension of 8192 with 80 layers. Doing some back-of-the-napkin math shows us that the larger model requires approximately 2x more RAM to maintain the same context window as the 30B parameter model (see formula below).</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!cVCW!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F954df13c-8e66-4c72-a6a1-1182619a5e2b_1920x1080.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!cVCW!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F954df13c-8e66-4c72-a6a1-1182619a5e2b_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/$s_!cVCW!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F954df13c-8e66-4c72-a6a1-1182619a5e2b_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/$s_!cVCW!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F954df13c-8e66-4c72-a6a1-1182619a5e2b_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!cVCW!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F954df13c-8e66-4c72-a6a1-1182619a5e2b_1920x1080.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!cVCW!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F954df13c-8e66-4c72-a6a1-1182619a5e2b_1920x1080.jpeg" width="1456" height="819" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/954df13c-8e66-4c72-a6a1-1182619a5e2b_1920x1080.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:109124,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.aiforswes.com/i/182132050?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F954df13c-8e66-4c72-a6a1-1182619a5e2b_1920x1080.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!cVCW!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F954df13c-8e66-4c72-a6a1-1182619a5e2b_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/$s_!cVCW!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F954df13c-8e66-4c72-a6a1-1182619a5e2b_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/$s_!cVCW!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F954df13c-8e66-4c72-a6a1-1182619a5e2b_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!cVCW!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F954df13c-8e66-4c72-a6a1-1182619a5e2b_1920x1080.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Luckily, there are tricks to better manage memory. First, there are architectural changes that can be made to make model inference more efficient so it requires less memory. The model we set up at the end of this article uses Hybrid Attention which enables a much smaller KV cache enabling us to fit our model and context window in less memory. I won’t get into more detail in this article, but you can read more about that model and how it works </span><a href="https://qwen.ai/blog?id=4074cca80393150c248e508aa62983f9cb7d27cd&amp;from=research.latest-advancements-list" rel="">here</a><span>.</span></p><p><span>The second trick is quantizing the values you’re working with. </span><a href="https://www.byteplus.com/en/what-is/quantization" rel="">Quantization means converting a continuous set of values into a smaller amount of distinct values</a><span>. In our case, that means taking a set of numbers represented by a certain number of bits (16, for example) and reducing it to a set of numbers represented by fewer bits (8, for example). To put it simply, in our case we’re converting the numbers representing our model to a smaller bit representation to save memory while keeping the value representations within the model relatively equal.</span></p><p>You can quantize both your model weights and the values stored in your context window. When you quantize your model weights, you “remove intelligence” from the model because it’s less precise in its representation of innate information. I’ve also found the performance hit when going from 16 to 8 bits within the model to be much less than 8 to 4.</p><p><span>We can also quantize the values in our context window to reduce its memory requirement. This means we’re less precisely representing the model’s memory. Generally speaking, KV cache (context window) quantization is considered more destructive to model performance than weight quantization because it </span><a href="https://arxiv.org/pdf/2510.10964" rel="">causes the model to forget details in long reasoning traces</a><span>. Thus, you should test quantizing the KV cache to ensure it doesn’t degrade model performance for your specific task.</span></p><p>In reality, like the rest of machine learning, optimizing local model performance is an experimentation process and real-world machine learning requires understanding the practical limitations and capabilities of models when applied to specific applications.</p><p>Here are a few more factors to understand when setting up a local coding model on your hardware:</p><p>Instruct models are post-trained to be well-suited for chat-based interactions. They’re given chat pairings in their training to be optimized for excellent back-and-forth chat output. Non-instruct models are still trained LLMs, but focus on next-token prediction instead of chatting with a user. For our case, when using a chat-based coding tool (CLI or chat agent in your IDE) we need to use an instruct model. If you’re setting up an autocomplete model, you’ll want to find a model specifically post-trained for it (such as Qwen2.5-Coder-Base or DeepSeek-Coder-V2).</p><p>You need a tool to serve your local LLM for your coding tool to send it requests. On a MacBook, there are two primary options: MLX and Ollama.</p><p>Ollama is the industry standard and works on non-Mac hardware. It’s a great serving setup on top of llama.cpp that makes model serving almost plug-and-play. Users can download model weights from Ollama easily and can configure modelfiles with custom parameters for serving. Ollama can also serve a model once and make it available to multiple tools.</p><p>MLX is a Mac-specific framework for machine learning that is optimized specifically for Mac hardware. It also retrieves models for the user from a community collection. I’ve found Ollama to be very reliable in its model catalog, while MLX’s catalog is community sourced and can sometimes be missing specific models. Models are sourced from the community so a user can convert a model to MLX format themselves. MLX requires a bit more setup on the user’s end, but serves models faster because it doesn’t have a layer providing the niceties of Ollama on top of it.</p><p>Either of these is great, but I chose MLX to maximize what I can get with my RAM, but Ollama is probably the more beginner-friendly tool here.</p><p>In real-world LLM applications it’s important that the model is able to serve its first token for a request in a reasonable amount of time and continue serving tokens at a speed that enables the user to use the model for its given purpose. If we have a high-performance model running locally, but it only serves a few tokens per second, it wouldn’t be useful for coding.</p><p>This is something taken for granted with cloud-hosted models that is a real consideration when working locally on constrained hardware. Another reason I chose MLX as my serving platform is because it served tokens up to 20% faster than Ollama. In reality, Ollama served tokens fast enough so I don’t think using MLX is necessary specifically for this reason for the models I tried.</p><p>There are many ways to optimize local models and save RAM. It’s difficult to know which optimization method works best and the impact each has on a model especially when using them in tandem with other methods.</p><p>The right optimization method also depends on the application. In my experience, I find it best to prioritize larger models with more aggressive model quantization over smaller models with more precise model weights. Since our application is coding, I would also prioritize a less-quantized KV cache and using a smaller model to ensure reasoning works properly while not sacrificing the size of our context window.</p><p><span>There are many tools to code with local models and I suggest trying until you find one you like. Some top recommendations are </span><a href="https://opencode.ai/" rel="">OpenCode</a><span>, </span><a href="https://aider.chat/" rel="">Aider</a><span>, </span><a href="https://github.com/QwenLM/qwen-code" rel="">Qwen Code</a><span>, </span><a href="https://roocode.com/" rel="">Roo Code</a><span>, and </span><a href="https://www.continue.dev/" rel="">Continue</a><span>. Make sure to use a tool compatible with </span><a href="https://bentoml.com/llm/llm-inference-basics/openai-compatible-api" rel="">OpenAI’s API standard</a><span>. While this should be most tools, this ensures a consistent model/tool connection. This makes it easier to switch between tools and models as needed.</span></p><p><span>I’ll spare you the trial and error I experienced getting this set up. The one thing I learned is that </span><strong>tooling matters a lot</strong><span>. Not all coding tools are created equal and not all of the models interact with tools equally. I experienced many times where tool calling or even running a tool at all was broken. I also had to tinker quite a bit with many of them to get them to work.</span></p><p>If you’re a PC enthusiast, an apt comparison to setting up local coding tools versus using the cloud offerings available is the difference between setting up a MacBook versus a Linux Laptop. With the Linux laptop, you might get well through the distro installation only to find that the drivers for your trackpad aren’t yet supported. Sometimes it felt like that with local models and hooking them to coding tools.</p><p>For my tool, I ended up going with Qwen Code. It was pretty plug-and-play as it’s a fork of Gemini CLI. It supports the OpenAI compatibility standard so I can easily sub in different models and affords me all of the niceties built into Gemini CLI that I’m familiar with using. I also know it’ll be supported because both the Qwen team and Google DeepMind are behind the tool. The tool is also open source so anyone can support it as needed.</p><p>For models, I focused on GPT-OSS and Qwen3 models since they were around the size I was looking for and had great reviews for coding. I ended up deciding to use Qwen3-Coder models because I found it performed best and because GPT-OSS frequently gave me “I cannot fulfill this request” responses when I asked it to build features.</p><p><span>I decided to serve my local models on MLX, but if you’re using a non-Mac device give Ollama a shot. A MacBook is an excellent machine for serving local models because of its unified memory architecture. This means the RAM can be allotted to the CPU or GPU as needed. MacBooks can also be configured with </span><em>a ton</em><span> of RAM. For serving local coding models, more is always better.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!4IEy!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a82350e-d1e0-420d-b4f3-7ea2343d3407_1920x1080.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!4IEy!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a82350e-d1e0-420d-b4f3-7ea2343d3407_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/$s_!4IEy!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a82350e-d1e0-420d-b4f3-7ea2343d3407_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/$s_!4IEy!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a82350e-d1e0-420d-b4f3-7ea2343d3407_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!4IEy!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a82350e-d1e0-420d-b4f3-7ea2343d3407_1920x1080.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!4IEy!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a82350e-d1e0-420d-b4f3-7ea2343d3407_1920x1080.jpeg" width="1456" height="819" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4a82350e-d1e0-420d-b4f3-7ea2343d3407_1920x1080.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:133148,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.aiforswes.com/i/182132050?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a82350e-d1e0-420d-b4f3-7ea2343d3407_1920x1080.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!4IEy!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a82350e-d1e0-420d-b4f3-7ea2343d3407_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/$s_!4IEy!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a82350e-d1e0-420d-b4f3-7ea2343d3407_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/$s_!4IEy!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a82350e-d1e0-420d-b4f3-7ea2343d3407_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!4IEy!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4a82350e-d1e0-420d-b4f3-7ea2343d3407_1920x1080.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Xqrl!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52524f56-954d-4bd9-8014-0bfb55cc2812_1920x1080.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Xqrl!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52524f56-954d-4bd9-8014-0bfb55cc2812_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/$s_!Xqrl!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52524f56-954d-4bd9-8014-0bfb55cc2812_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/$s_!Xqrl!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52524f56-954d-4bd9-8014-0bfb55cc2812_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!Xqrl!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52524f56-954d-4bd9-8014-0bfb55cc2812_1920x1080.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Xqrl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52524f56-954d-4bd9-8014-0bfb55cc2812_1920x1080.jpeg" width="1456" height="819" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/52524f56-954d-4bd9-8014-0bfb55cc2812_1920x1080.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:171397,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.aiforswes.com/i/182132050?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52524f56-954d-4bd9-8014-0bfb55cc2812_1920x1080.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Xqrl!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52524f56-954d-4bd9-8014-0bfb55cc2812_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/$s_!Xqrl!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52524f56-954d-4bd9-8014-0bfb55cc2812_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/$s_!Xqrl!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52524f56-954d-4bd9-8014-0bfb55cc2812_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!Xqrl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52524f56-954d-4bd9-8014-0bfb55cc2812_1920x1080.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>I’ve shared my </span><a href="https://github.com/loganthorneloe/modelfiles" rel="">modelfiles repo</a><span> for you to reference and use as needed. I’ve got a script set up that automates much of the below process. Feel free to fork it and create your own modelfiles or star it to come back later.</span></p><ol><li><p><span>Install </span><a href="https://github.com/ml-explore/mlx" rel="">MLX</a><span> or download </span><a href="https://ollama.com/download" rel="">Ollama</a><span> (the rest of this guide will continue with MLX but details for serving on Ollama can be found </span><a href="https://docs.ollama.com/quickstart" rel="">here</a><span>).</span></p></li><li><p>Increase the VRAM limitation on your MacBook. macOS will automatically limit VRAM to 75% of the total RAM. We want to use more than that. Run sudo sysctl iogpu.wired_limit_mb=110000 in your terminal to set this up (adjust the mb setting according to the RAM on your MacBook). This needs to be set each time you restart your MacBook.</p></li><li><p>Run pip install -U mlx-lm to install MLX for serving community models.</p></li><li><p>Serve the model as an OpenAI compatible API using python -m mlx_lm.server --model mlx-community/Qwen3-Next-80B-A3B-Instruct-8bit. This command both runs the server and downloads the model for you if you haven’t yet. This particular model is what I’m using with 128GB of RAM. If you have less RAM, check out smaller models such as mlx-community/Qwen3-4B-Instruct-2507-4bit (8 GB RAM), mlx-community/Qwen2.5-14B-Instruct-4bit (16 GB RAM), mlx-community/Qwen3-Coder-30B-A3B-Instruct-4bit (32 GB RAM), or mlx-community/Qwen3-Next-80B-A3B-Instruct-4bit (64-96 GB RAM).</p></li><li><p><span>Download </span><a href="https://github.com/QwenLM/qwen-code" rel="">Qwen Code</a><span>. You might need to install Node Package Manager for this. I recommend using </span><a href="https://github.com/nvm-sh/nvm" rel="">Node Version Manager</a><span> (nvm) for managing your npm version.</span></p></li><li><p>Set up your tool to access an OpenAI compatible API by entering the following settings:</p><ol><li><p><span>Base URL: </span><a href="http://localhost:8080/v1" rel="">http://localhost:8080/v1</a><span> (should be the default MLX serves your model at)</span></p></li><li><p>API Key: mlx</p></li><li><p>Model Name: mlx-community/Qwen3-Next-80B-A3B-Instruct-8bit (or whichever model you chose).</p></li></ol></li><li><p>Voila! Your coding model tool should be working with your local coding model.</p></li></ol><p><span>I recommend opening Activity Monitor on your Mac to monitor memory usage. I’ve had cases where I thought a model should fit within my memory allotment but it didn’t and I ended up using a lot of swap memory. When this happens your model will run </span><strong>very </strong><span>slowly.</span></p><p><strong>One tip I have for using local coding models</strong><span>: Focus on managing your context. This is a great skill even with cloud-based models. People tend to YOLO their chats and fill their context window, but I’ve found greater performance by ensuring that just what my model needs is sitting in my context window. This is even more important with local models that may need an extra boost in performance and are limited in their context.</span></p><p><span>My original hypothesis was: </span><strong>Instead of paying $100/mo+ for an AI coding subscription, my money would be better spent upgrading my hardware so I can run local coding models at a fraction of the price.</strong></p><p><span>I would argue that</span><s>—yes!—</s><strong>no </strong><span>[see edit 2 above], it is correct. If we crunch the numbers, a MacBook with 128 GB is $4700 plus tax. If I spend $100/mo for 5 years, a coding subscription would cost $6000 in that same amount of time. Not only do I save money, but I also get a much more capable machine for anything else I want to do with it.</span></p><p><span>[This paragraph was added in after initial release of this article] It’s important to note that local models will </span><strong>not</strong><span> reach the peak performance of frontier models; however, they will likely be able to do most tasks just as well. The value of using a local model doesn’t come from raw performance, but from supplementing the cost of higher performance models. A local model could very well let you drop your subscription tier for a frontier coding tool or utilize a free tier as needed for better performance and run the rest of your tasks for free.</span></p><p><strong>It’s also important to note that local models are only going to get better and smaller</strong><span>. This is the worst your local coding model will perform. I also wouldn’t be surprised if cloud-based AI coding tools get more expensive. If you figure you’re using greater than the $100/mo tier right now or that the $100/mo tier will cost $200/mo in the future, the purchase is a no-brainer. It’s just difficult to stomach the upfront cost.</span></p><p>From a performance standpoint, I would say the maximum model running on my 128 GB RAM MacBook right now feels about half a generation behind the frontier coding tools. That’s excellent, but something to keep in mind as that half a generation might matter to you.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!wAV2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F922da413-1147-4a89-bbd0-fefdd78bc8cb_1920x1080.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!wAV2!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F922da413-1147-4a89-bbd0-fefdd78bc8cb_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/$s_!wAV2!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F922da413-1147-4a89-bbd0-fefdd78bc8cb_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/$s_!wAV2!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F922da413-1147-4a89-bbd0-fefdd78bc8cb_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!wAV2!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F922da413-1147-4a89-bbd0-fefdd78bc8cb_1920x1080.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!wAV2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F922da413-1147-4a89-bbd0-fefdd78bc8cb_1920x1080.jpeg" width="1456" height="819" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/922da413-1147-4a89-bbd0-fefdd78bc8cb_1920x1080.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:162037,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.aiforswes.com/i/182132050?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F922da413-1147-4a89-bbd0-fefdd78bc8cb_1920x1080.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!wAV2!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F922da413-1147-4a89-bbd0-fefdd78bc8cb_1920x1080.jpeg 424w, https://substackcdn.com/image/fetch/$s_!wAV2!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F922da413-1147-4a89-bbd0-fefdd78bc8cb_1920x1080.jpeg 848w, https://substackcdn.com/image/fetch/$s_!wAV2!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F922da413-1147-4a89-bbd0-fefdd78bc8cb_1920x1080.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!wAV2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F922da413-1147-4a89-bbd0-fefdd78bc8cb_1920x1080.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>One wrench thrown into my experiment is how much free quota Google hands out with their different AI coding tools. It’s easy to purchase expensive hardware when it saves you money in the long run. It’s much more difficult when the alternative is free.</p><p>Initially, I considered my local coding setup to be a great pair to Google’s free tier. It definitely performs better than Gemini 2.5 Flash and makes a great companion to Gemini 3 Pro. Gemini 3 Pro can solve more complex tasks with the local model doing everything else. This not only saves quota on 3 Pro but also provides a very capable fallback for when quota is hit.</p><p><span>However, this is foiled a bit now that </span><a href="https://blog.google/products/gemini/gemini-3-flash/" rel="">Gemini 3 Flash</a><span> was just announced a few days ago. It shows benchmark numbers much more capable than Gemini 2.5 Flash (and even 2.5 Pro!) and I’ve been very impressed with its performance. If that’s the free tier Google offers, it makes local coding models less fiscally reasonable. The jury is still out on how well Gemini 3 Flash will perform and how quota will be structured, but we’ll have to see if local models can keep up.</span></p><p>I’m very curious to hear what you think! Tell me about your local coding setup or ask any questions below.</p><p>Thanks for reading!</p><p><strong>Always be (machine) learning,</strong></p><p><strong>Logan</strong></p><p data-attrs="{&quot;url&quot;:&quot;https://www.aiforswes.com/p/you-dont-need-to-spend-100mo-on-claude?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.aiforswes.com/p/you-dont-need-to-spend-100mo-on-claude?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[More on whether useful quantum computing is “imminent” (128 pts)]]></title>
            <link>https://scottaaronson.blog/?p=9425</link>
            <guid>46348318</guid>
            <pubDate>Sun, 21 Dec 2025 20:53:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://scottaaronson.blog/?p=9425">https://scottaaronson.blog/?p=9425</a>, See on <a href="https://news.ycombinator.com/item?id=46348318">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-9425">
				
<p>These days, the most common question I get goes something like this:</p>



<blockquote>
<p>A decade ago, you told people that scalable quantum computing wasn’t imminent. Now, though, you claim it plausibly <em>is</em> imminent. Why have you reversed yourself??</p>
</blockquote>



<p>I appreciated the friend of mine who paraphrased this as follows: “A decade ago you said you were 35. Now you say you’re 45. Explain yourself!”</p>



<hr>



<p>A couple weeks ago, I was delighted to attend <a href="https://q2b.qcware.com/conference/2025-silicon-valley">Q2B</a> in Santa Clara, where I gave a keynote talk entitled <a href="https://www.scottaaronson.com/talks/works.pptx">“Why I Think Quantum Computing Works”</a> (link goes to the PowerPoint slides).  This is one of the most optimistic talks I’ve ever given.  But mostly that’s just because, uncharacteristically for me, here I gave short shrift to the challenge of broadening the class of problems that achieve huge quantum speedups, and just focused on the experimental milestones achieved over the past year.  With every experimental milestone, the little voice in my head that asks “but what if Gil Kalai turned out to be right after all? what if scalable QC <em>wasn’t</em> possible?” grows quieter, until now it can barely be heard.</p>



<p>Going to Q2B was extremely helpful in giving me a sense of the current state of the field.  Ryan Babbush gave a <em>superb</em> overview (I couldn’t have improved a word) of the current status of quantum algorithms, while John Preskill’s annual where-we-stand talk was “magisterial” as usual (that’s the word I’ve long used for his talks), making mine look like just a warmup act for his.  Meanwhile, Quantinuum took a victory lap, boasting of their recent successes in a way that I considered basically justified.</p>



<hr>



<p>After returning from Q2B, I then did an hour-long <a href="https://www.youtube.com/watch?si=T9u5MjX9xwCY9zeJ&amp;v=0_7SH3Eons0&amp;feature=youtu.be">podcast</a> with “The Quantum Bull” on the topic “How Close Are We to Fault-Tolerant Quantum Computing?”  You can watch it here:</p>



<figure><p>
<iframe title="Scott Aaronson on the Possibility of Fault-Tolerant Quantum Computing by 2028" width="500" height="281" src="https://www.youtube.com/embed/0_7SH3Eons0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>



<p>As far as I remember, this is the first YouTube interview I’ve ever done that concentrates entirely on the current state of the QC race, skipping any attempt to explain amplitudes, interference, and other basic concepts.  Despite (or conceivably because?) of that, I’m happy with how this interview turned out.  Watch if you want to know my detailed current views on hardware—as always, I recommend 2x speed.</p>



<p>Or for those who don’t have the half hour, a quick summary:</p>



<ul>
<li>In quantum computing, there are the large companies and startups that might succeed or might fail, but are at least trying to solve the real technical problems, and some of them are making amazing progress. And then there are the companies that have optimized for doing IPOs, getting astronomical valuations, and selling a narrative to retail investors and governments about how quantum computing is poised to revolutionize optimization and machine learning and finance. Right now, I see these two sets of companies as <strong>almost entirely disjoint from each other</strong>.<br></li>



<li>The interview also contains my most direct condemnation yet of some of the wild misrepresentations that IonQ, in particular, has made to governments about what QC will be good for (“unlike AI, quantum computers won’t hallucinate because they’re deterministic!”)<br></li>



<li>The two approaches that had the most impressive demonstrations in the past year are trapped ions (especially Quantinuum but also Oxford Ionics) and superconducting qubits (especially Google but also IBM), and perhaps also neutral atoms (especially QuEra but also Infleqtion and Atom Computing).<br></li>



<li>Contrary to a misconception that refuses to die, I <em>haven’t</em> dramatically changed my views on any of these matters. As I have for a quarter century, I continue to profess a lot of confidence in the basic principles of quantum computing theory worked out in the mid-1990s, and I <em>also</em> continue to profess ignorance of exactly how many years it will take to realize those principles in the lab, and of which hardware approach will get there first.<br></li>



<li>But yeah, <em>of course</em> I update in response to developments on the ground, because it would be insane not to! And 2025 was clearly a year that met or exceeded my expectations on hardware, with multiple platforms now boasting &gt;99.9% fidelity two-qubit gates, at or above the theoretical threshold for fault-tolerance. This year updated me in favor of taking more seriously the aggressive pronouncements—the “roadmaps”—of Google, Quantinuum, QuEra, PsiQuantum, and other companies about where they could be in 2028 or 2029.<br></li>



<li>One more time for those in the back: the main <em>known</em> applications of quantum computers remain (1) the simulation of quantum physics and chemistry themselves, (2) breaking a lot of currently deployed cryptography, and (3) eventually, achieving some <em>modest</em> benefits for optimization, machine learning, and other areas (but it will probably be a while before those modest benefits win out in practice).  To be sure, the detailed list of quantum speedups expands over time (as new quantum algorithms get discovered) and also contracts over time (as some of the quantum algorithms get dequantized).  But the list of known applications “from 30,000 feet” remains fairly close to what it was a quarter century ago, after you hack away the dense thickets of obfuscation and hype.</li>
</ul>



<hr>



<p>I’m going to close this post with a warning.  When Frisch and Peierls wrote their <a href="https://en.wikipedia.org/wiki/Frisch%E2%80%93Peierls_memorandum">now-famous memo</a> in March 1940, estimating the mass of Uranium-235 that would be needed for a fission bomb, they didn’t publish it in a journal, but communicated the result through military channels only.  As recently as February 1939, Frisch and Meitner had <a href="https://www.nature.com/articles/143239a0">published in <em>Nature</em></a> their theoretical explanation of recent experiments, showing that the uranium nucleus could fission when bombarded by neutrons.  But by 1940, Frisch and Peierls realized that the time for open publication of these matters had passed.</p>



<p>Similarly, at some point, the people doing detailed estimates of how many physical qubits and gates it’ll take to break actually deployed cryptosystems using Shor’s algorithm are going to stop publishing those estimates, if for no other reason than the risk of giving too much information to adversaries. Indeed, for all we know, that point may have been passed already. This is the clearest warning that I can offer in public right now about the urgency of migrating to post-quantum cryptosystems, a process that I’m grateful is already underway.</p>



<hr>



<p><strong><mark>Update:</mark></strong> Someone on Twitter who’s “long $IONQ” says he’ll be <a href="https://x.com/SPAC_Infleqtion/status/2002826241146302651">posting about and investigating me</a> every day, never resting until UT Austin fires me, in order to punish me for slandering IonQ and other “pure play” SPAC IPO quantum companies. And also, because I’ve been anti-Trump and pro-Biden. He confabulates that I must be trying to profit from my stance (eg by shorting the companies I criticize), it being inconceivable to him that anyone would say anything purely because they care about what’s true.</p>

		
				
				<p>
					<small>
						This entry was posted
												on Sunday, December 21st, 2025 at 11:34 am						and is filed under <a href="https://scottaaronson.blog/?cat=10" rel="category">Adventures in Meatspace</a>, <a href="https://scottaaronson.blog/?cat=4" rel="category">Quantum</a>, <a href="https://scottaaronson.blog/?cat=17" rel="category">Speaking Truth to Parallelism</a>.
						You can follow any responses to this entry through the <a href="https://scottaaronson.blog/?feed=rss2&amp;p=9425">RSS 2.0</a> feed.

													You can <a href="#respond">leave a response</a>, or <a href="https://scottaaronson.blog/wp-trackback.php?p=9425" rel="trackback">trackback</a> from your own site.

						
					</small>
				</p>

			</div><p>You can use rich HTML in comments!  You can also use basic TeX, by enclosing it within <span>$$ $$</span> for displayed equations or <span>\( \)</span> for inline equations.</p><p>
	After two decades of mostly-open comments, in July 2024 <i>Shtetl-Optimized</i> transitioned to the following policy:
	
</p><p>All comments are treated, by default, as personal missives to me, Scott Aaronson---with no expectation either that they'll appear on the blog or that I'll reply to them.

</p><p>At my leisure and discretion, and in consultation with the <a href="https://scottaaronson.blog/?p=6576"><i>Shtetl-Optimized</i> Committee of Guardians</a>, I'll put on the blog a curated selection of comments that I judge to be particularly interesting or to move the topic forward, and I'll do my best to answer those.  But it will be more like Letters to the Editor.  Anyone who feels unjustly censored is welcome to the rest of the Internet.

</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rue: Higher level than Rust, lower level than Go (224 pts)]]></title>
            <link>https://rue-lang.dev/</link>
            <guid>46348262</guid>
            <pubDate>Sun, 21 Dec 2025 20:46:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rue-lang.dev/">https://rue-lang.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=46348262">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>Higher level than Rust, lower level than Go</p></div><div><div><h2>Memory Safe</h2><p>No garbage collector, no manual memory management. A work in progress, though.</p></div><div><h2>Simple Syntax</h2><p>Familiar syntax inspired by various programming languages. If you know one, you'll feel at home with Rue.</p></div><div><h2>Fast Compilation</h2><p>Direct compilation to native code.</p></div></div><div><h2>Hello, Rue</h2><div><pre data-lang="rust"><code data-lang="rust"><span><span><span>//</span> It's a classic for a reason
</span></span><span><span><span><span>fn</span> </span><span>fib</span></span><span><span><span>(</span><span>n</span><span>:</span> <span>i32</span></span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>i32</span></span> </span><span><span><span>{</span>
</span></span></span><span><span><span>    <span>if</span> n <span>&lt;=</span> <span>1</span> <span><span>{</span>
</span></span></span></span><span><span><span><span>        n
</span></span></span></span><span><span><span><span>    </span><span><span>}</span></span> <span>else</span> <span><span>{</span>
</span></span></span></span><span><span><span><span>        <span>fib</span><span><span>(</span>n <span>-</span> <span>1</span></span><span><span>)</span></span> <span>+</span> <span>fib</span><span><span>(</span>n <span>-</span> <span>2</span></span><span><span>)</span></span>
</span></span></span></span><span><span><span><span>    </span><span><span>}</span></span>
</span></span></span><span><span><span></span><span><span>}</span></span></span>
</span><span>
</span><span><span><span><span>fn</span> </span><span>main</span></span><span><span><span>(</span></span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>i32</span></span> </span><span><span><span>{</span>
</span></span></span><span><span><span>    <span><span>//</span> Print the first 20 Fibonacci numbers
</span></span></span></span><span><span><span>    <span>let</span> <span>mut</span> i <span>=</span> <span>0</span><span>;</span>
</span></span></span><span><span><span>    <span>while</span> i <span>&lt;</span> <span>20</span> <span><span>{</span>
</span></span></span></span><span><span><span><span>        <span>@</span><span>dbg</span><span><span>(</span><span>fib</span><span><span>(</span>i</span><span><span>)</span></span></span><span><span>)</span></span><span>;</span>
</span></span></span></span><span><span><span><span>        i <span>=</span> i <span>+</span> <span>1</span><span>;</span>
</span></span></span></span><span><span><span><span>    </span><span><span>}</span></span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    <span><span>//</span> Return fib(10) = 55
</span></span></span></span><span><span><span>    <span>fib</span><span><span>(</span><span>10</span></span><span><span>)</span></span>
</span></span></span><span><span><span></span><span><span>}</span></span></span>
</span></code></pre></div></div></div></div>]]></description>
        </item>
    </channel>
</rss>