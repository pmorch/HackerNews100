<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 13 Dec 2023 10:00:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[GM says it's dropping Apple CarPlay and Android Auto because they're unsafe (110 pts)]]></title>
            <link>https://jalopnik.com/gm-drops-apple-carplay-android-auto-unsafe-phone-1851093013</link>
            <guid>38622476</guid>
            <pubDate>Wed, 13 Dec 2023 03:59:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jalopnik.com/gm-drops-apple-carplay-android-auto-unsafe-phone-1851093013">https://jalopnik.com/gm-drops-apple-carplay-android-auto-unsafe-phone-1851093013</a>, See on <a href="https://news.ycombinator.com/item?id=38622476">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>GM is still dealing with the fallout of its decision to drop Apple CarPlay and Android Auto in favor of developing its own in-house system. In the last eight months, the company has had to deal with <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://jalopnik.com/gm-is-confident-in-its-apple-carplay-android-auto-repl-1850622807&quot;,{&quot;metric25&quot;:1}]]" href="https://jalopnik.com/gm-is-confident-in-its-apple-carplay-android-auto-repl-1850622807">skeptical dealers</a></span> while still maintaining its in-house system will be “<span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://jalopnik.com/gm-says-software-will-be-as-compelling-as-carplay-1850378651&quot;,{&quot;metric25&quot;:1}]]" href="https://jalopnik.com/gm-says-software-will-be-as-compelling-as-carplay-1850378651">compelling</a></span>.” Since neither of those options have really changed public opinion so far, GM is now claiming that Apple CarPlay and Android Auto actually cause safety issues.</p><div data-video-id="190680" data-monetizable="true" data-position="sidebar" data-video-title="GM announces hybrid + electric Corvettes" data-video-blog-id="12" data-video-network="jalopnik" data-video-duration="68" data-playlist="190680,195078,195515" data-current="190680"><div><p>GM announces hybrid + electric Corvettes</p></div><video disablepictureinpicture="" muted="" playsinline="" width="100%" height="100%" crossorigin="anonymous" preload="none"><source data-src="https://vid.kinja.com/prod/190680/190680_240p.mp4" label="240p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/190680/190680_480p.mp4" label="480p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/190680/190680_720p.mp4" label="720p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/190680/190680_1080p.mp4" label="1080p" type="video/mp4"><track kind="captions" label="English" src="https://kinja.com/api/videoupload/caption/16929.vtt" srclang="en"></video><div><ul><li data-label="">Off</li><li data-label="English">English</li></ul></div></div><p>Speaking to <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.motortrend.com/news/general-motors-removing-apple-carplay-android-auto-for-safety-tim-babbitt/&quot;,{&quot;metric25&quot;:1}]]" href="https://www.motortrend.com/news/general-motors-removing-apple-carplay-android-auto-for-safety-tim-babbitt/" target="_blank" rel="noopener noreferrer"><em>Motor Trend</em></a></span>, GM’s head of product for infotainment, Tim Babbit, explained that GM’s decision and the logic behind the safety concerns. Simply put, GM and Babbit think Apple CarPlay and Android Auto encourage cell phone use behind the wheel.<br></p><blockquote data-type="BlockQuote"><p>According to Babbitt, CarPlay and Android Auto aren’t perfect programs. They have stability issues that manifest themselves as bad connections, poor rendering, slow responses, and dropped connections. And when CarPlay and Android Auto have issues, drivers pick up their phones again, taking their eyes off the road and totally defeating the purpose of these phone-mirroring programs. Solving those issues can sometimes be beyond the control of the automaker. You can start to see GM’s frustration.</p></blockquote><p>Essentially, the thinking is that if a car’s in-built infotainment system is good enough, drivers will be less likely to use their phone for what they’re trying to do while they’re behind the wheel, — though Babbitt admits that GM hasn’t exactly tested this in a controlled setting to see whether or not it’s true.<br></p><p>To achieve this, GM’s new system — called Ultifi, which is making its debut in the <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://jalopnik.com/gm-plans-to-remove-apple-carplay-on-evs-1850288509&quot;,{&quot;metric25&quot;:1}]]" href="https://jalopnik.com/gm-plans-to-remove-apple-carplay-on-evs-1850288509">2024 Chevy Blazer EV</a></span> — uses Google apps built right into the system, like Google Maps and Assistant, which GM hopes customers will use for more voice controls. It can handle things like calls and texts, and it can control the audio and climate systems. </p><p>Of course, this all just isn’t about making the driver’s tech experience better. GM is also hoping to collect some of that sweet, sweet driver data and money from <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://jalopnik.com/gm-is-coming-for-your-wallet-with-50-new-digital-servic-1848592900&quot;,{&quot;metric25&quot;:1}]]" href="https://jalopnik.com/gm-is-coming-for-your-wallet-with-50-new-digital-servic-1848592900">subscription services</a></span>, as <em>Motor Trend</em> pointed out.<br></p><blockquote data-type="BlockQuote"><p> In addition to potentially buying things from GM or GM’s partners through their car’s infotainment system, GM is also looking at subscription services that would be managed through the same interface. GM’s chief digital officer, Edward Kummer, told Reuters as much when the decision to drop CarPlay and Android Auto was announced. Automakers see subscriptions as huge new source of income to be tapped, with GM alone hoping to make as much as $25 billion per year just off subscriptions by 2030.</p></blockquote><p>We’ll see if GM’s gamble pays off when more of its vehicles roll out with the Ultifi system starting next year.<br></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tools for Learning LLVM TableGen (118 pts)]]></title>
            <link>https://blog.llvm.org/posts/2023-12-07-tools-for-learning-llvm-tablegen/</link>
            <guid>38620037</guid>
            <pubDate>Tue, 12 Dec 2023 23:05:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.llvm.org/posts/2023-12-07-tools-for-learning-llvm-tablegen/">https://blog.llvm.org/posts/2023-12-07-tools-for-learning-llvm-tablegen/</a>, See on <a href="https://news.ycombinator.com/item?id=38620037">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>


<p><a href="https://github.com/llvm/llvm-project/tree/main/llvm/utils/TableGen">TableGen</a>
is a language used within the LLVM project for generating a variety of files,
when manual maintenance would be very difficult.</p>
<p>For example, it is used to define all of the instructions that can be used on a
particular architecture. The information is defined in TableGen and we can
produce many things based on that single source file. C++ code, documentation,
command line options, and so on.</p>
<p>TableGen has been in existence since
<a href="https://github.com/llvm/llvm-project/commit/a6240f6b1a34f9238cbe8bc8c9b6376257236b0a">before</a>
the first official release of LLVM, over 20 years ago.</p>
<p>Today in the <a href="https://github.com/llvm/llvm-project">LLVM project repository</a> there are
over a thousand TableGen source files totalling over 500,000 lines of code.
Making it the 5th most popular language in the repository.</p>
<table>
<thead>
<tr>
<th>Language</th>
<th>files</th>
<th>blank</th>
<th>comment</th>
<th>code</th>
</tr>
</thead>
<tbody>
<tr>
<td>C++</td>
<td>29642</td>
<td>958542</td>
<td>1870101</td>
<td>5544445</td>
</tr>
<tr>
<td>C/C++ Header</td>
<td>11844</td>
<td>316806</td>
<td>499845</td>
<td>1486165</td>
</tr>
<tr>
<td>C</td>
<td>10535</td>
<td>259900</td>
<td>1603594</td>
<td>1011269</td>
</tr>
<tr>
<td>Assembly</td>
<td>10694</td>
<td>478035</td>
<td>1222315</td>
<td>820236</td>
</tr>
<tr>
<td>TableGen</td>
<td>1312</td>
<td>94112</td>
<td>83616</td>
<td>580289</td>
</tr>
</tbody>
</table>
<p>(Counted from
<a href="https://github.com/llvm/llvm-project/commit/ba24b814f2a20a136f0a7a0b492b6ad8a62114c6">this commit</a>,
rest of table omitted)</p>
<p>With projects such as MLIR
<a href="https://mlir.llvm.org/docs/DefiningDialects/Operations/">embracing TableGen</a>,
it is only going to grow. So if you are contributing to LLVM, you will encounter
it at some point.</p>
<p>Which might be a problem as TableGen only exists within LLVM. Unlike a language
such as C++, TableGen does not have a large array of resources.</p>
<p>So, as well as joining a new project, you also need to learn a new
Domain Specific Language (DSL). You did not come to LLVM to learn a DSL, you
probably came here to write a compiler.</p>
<p>I cannot say when this problem might be solved, but the situation is not as
bleak as it appears. There have been big improvements in TableGen tools
recently, which means you can put more of your energy into the goals that
brought you to LLVM in the first place.</p>
<h2 id="a-brief-introduction-to-tablegen">A Brief Introduction to TableGen</h2>
<p>Imagine you wanted to represent the registers of an architecture. I am going to
use Arm’s AArch64 in particular here.</p>
<p>You could describe them in TableGen as:</p>
<div><pre tabindex="0"><code data-lang="bash">$ cat register.td

class Register&lt;int _size, string _alias<span>=</span><span>""</span>&gt; <span>{</span>
  int size <span>=</span> _size;
  string alias <span>=</span> _alias;
<span>}</span>

// <span>64</span> bit general purpose registers are X&lt;N&gt;.
def X0: Register&lt;8&gt; <span>{}</span>
// Some have special alternate names.
def X29: Register&lt;8, <span>"frame pointer"</span>&gt; <span>{}</span>
// Some registers omitted...
</code></pre></div><p>By default, the TableGen compiler <code>llvm-tblgen</code> creates “records” - which are
shown below.</p>
<div><pre tabindex="0"><code data-lang="bash">$ ./bin/llvm-tblgen register.td

------------- Classes -----------------
class Register&lt;int Register:_size <span>=</span> ?, string Register:_alias <span>=</span> <span>""</span>&gt; <span>{</span>
 int size <span>=</span> Register:_size;
 string alias <span>=</span> Register:_alias;
<span>}</span>
------------- Defs -----------------
def X0 <span>{</span>        // Register
 int size <span>=</span> 8;
 string alias <span>=</span> <span>""</span>;
<span>}</span>
def X29 <span>{</span>       // Register
 int size <span>=</span> 8;
 string alias <span>=</span> <span>"frame pointer"</span>;
<span>}</span>
</code></pre></div><p>This is the intermediate representation (IR) of the TableGen compiler, similar
to LLVM’s “LLVM IR”.</p>
<p>When using LLVM you would select a “target” which is the processor architecture
you want to generate instructions for. TableGen’s equivalent is a “backend”.
These backends do not generate instructions, but instead output a format for
that backend’s specific use case.</p>
<p>For example, there is a backend that generates C++ code for
<a href="https://godbolt.org/z/5c696j1f9">searching</a> data tables. Other examples are
C header files and <a href="https://docutils.sourceforge.io/rst.html">reStructuredText</a>
documentation.</p>
<pre tabindex="0"><code>                       TableGen source
                               |
 +--llvm-tblgen----------------|------------------------+
 |                             v                        |
 |              +----- Expanded records ----+           |
 |              |                           |           |
 |              v                           v           |
 | +-------------------------+    +-------------------+ |
 | | --gen-searchable-tables |    | Other backends... | |
 | +-------------------------+    +-------------------+ |
 |              |                           |           |
 +--------------|---------------------------|-----------+
                v                           v
    .inc file with C++ code       Other output formats...
    for table searching.
</code></pre><p>The main compiler is <code>llvm-tblgen</code>, but there are others specific to
sub-projects of LLVM. For example <code>clang-tblgen</code> and <code>lldb-tblgen</code>. The only
difference is the backends included in each one, the language is the same.</p>
<p>You might take your register definitions and produce C++ code to initialise them
in some kind of bootloader. Perhaps you also document it and produce a diagram
of the process. With enough backends, you could do all that from the same
TableGen source code.</p>
<p>You would write these backends either in C++ within the TableGen compiler,
or as an external backend using the compiler’s
<a href="https://godbolt.org/z/vre845e77">JSON output</a> (<code>--dump-json</code>). So you can use
any language with a JSON parser (such as
<a href="https://github.com/llvm/llvm-project/blob/main/llvm/utils/TableGen/jupyter/sql_query_backend.ipynb">Python</a>).</p>
<h2 id="there-is-tablegen-and-there-are-things-built-with-tablegen">There is TableGen and There Are Things Built With TableGen</h2>
<p>This is more a mindset than a tool. It is summed up best by a quote from the
<a href="https://llvm.org/docs/TableGen/index.html#tablegen-deficiencies">documentation</a>:</p>
<blockquote>
<p>Despite being very generic, TableGen has some deficiencies that have been
pointed out numerous times. The common theme is that, while TableGen allows
you to build domain specific languages, the final languages that you create
lack the power of other DSLs, which in turn increase considerably the size and
complexity of TableGen files.</p>
<p>At the same time, TableGen allows you to create virtually any meaning of the
basic concepts via custom-made backends, which can pervert the original design
and make it very hard for newcomers to understand the evil TableGen file.”</p>
</blockquote>
<p>This means that you will be tackling TableGen, and things built with TableGen.
Which are often more complicated than the language.</p>
<p>It is like learning C++ and struggling to use <a href="https://www.boost.org/">Boost</a>.
Someone might say to you, “Boost is not required, why not remove it and save
yourself the hassle?”. As someone new to C++, you might not be aware of the
boundary between the two of them.</p>
<p>Of course this does not help you too much if the project you want to contribute
to uses Boost. You are stuck dealing with both. In LLVM terms, the TableGen
language and the backends that consume it are a package deal.</p>
<p>I mention this so that you can draw a distinction between not understanding
one or the other. Knowing which one is confusing you is a big advantage
to finding help.</p>
<p>For any task there are probably one or two “things built with TableGen” that you
need to understand and even then, not entirely.</p>
<p>Do not think that your TableGen journey must end with understanding all the ways
it is used. That is possible, but it is not required, and hardly anyone learns
everything. Instead put your energy into the things that really interest you.</p>
<h2 id="compiler-explorer">Compiler Explorer</h2>
<p>Of course we have TableGen in Compiler Explorer! Is a language even real if it is
not in Compiler Explorer?</p>
<p>(Of course it is, but if your favourite language is not there, Compiler Explorer
has <a href="https://github.com/compiler-explorer/compiler-explorer/blob/main/docs/AddingALanguage.md">excellent documentation</a>
and friendly maintainers)</p>
<p>Compiler Explorer is a whole bunch of different versions of compilers for
different languages and different architectures that you can access with just a
browser tab.</p>
<p>It is an incredible tool for learning, teaching, triaging, optimising and
<a href="https://www.youtube.com/watch?v=O5sEug_iaf4">many more</a> things. I will not go into
detail about it here, just a few things about TableGen’s inclusion.</p>
<p>The obvious thing is that <code>llvm-tblgen</code> does not emit instructions (though a
hypothetical backend could) so there is no option to compile to binary or
execute code.</p>
<p>By default, records are printed as plain text. You can choose a backend by adding a
compiler option, or by opening the “Overrides” menu and selecting an “Action”.</p>
<p>It is important to note that TableGen backends have very specific expectations of
what will be in the source code. As if you had a C++ compiler that
would not compile for Arm unless it saw <code>arm_is_cool</code> somewhere in the
source code.</p>
<p>In the LLVM repository all the required classes are set up for you, but in
Compiler Explorer they are not. So, if you would like to experiment with an
existing backend, I suggest you provide stub implementations of the classes, or
copy some from the LLVM project repository. You can also use standard includes
from <code>include/llvm/*.td</code>.</p>
<p>It is not possible at this time to develop a backend within Compiler Explorer,
but you can select the JSON backend and copy that JSON to give to local scripts.</p>
<p>Multi-file projects (“IDE mode”) also work as expected, so, if you would like,
you can have your own <a href="https://godbolt.org/z/4qhdoaMjE">include files</a>.</p>
<p>Finally, remember that you can share Compiler Explorer examples. If you are
asking or answering questions about TableGen, always include a Compiler Explorer
link if you can!</p>
<h2 id="jupyter-notebooks">Jupyter Notebooks</h2>
<p><a href="https://jupyter.org/">Jupyter</a> creates interactive notebooks. A notebook is a
single document which contains text, code and the results of running that code.
This enables you to edit the code and rerun it to update the results in the
notebook.</p>
<p>This is great for taking notes or building up large examples from small chunks
of code. You can export the document as a notebook that anyone can edit, or
in noninteractive formats such as PDF or Markdown.</p>
<p>TableGen can be used in notebooks by using the TableGen Jupyter Kernel.
Installation instructions are available <a href="https://github.com/llvm/llvm-project/tree/main/llvm/utils/TableGen/jupyter">here</a> and you can watch me talk more about it
<a href="https://www.youtube.com/watch?v=Gf0FUiY2TRo">here</a>.</p>
<p><strong>Note:</strong> There is also an
<a href="https://github.com/llvm/llvm-project/tree/main/mlir/utils/jupyter">MLIR kernel</a>
for Jupyter, along with many others.</p>
<p>We have aimed to give the same experience as other languages, so I will focus
not on how to use a notebook, but instead on what we have been able to make with
them.</p>
<h2 id="tablegen-tutorial-notebook">TableGen Tutorial Notebook</h2>
<p>This notebook is an introduction to TableGen. You can read it on
<a href="https://github.com/llvm/llvm-project/blob/main/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.ipynb">GitHub</a>,
or <a href="https://raw.githubusercontent.com/llvm/llvm-project/main/llvm/utils/TableGen/jupyter/tablegen_tutorial_part_1.ipynb">download</a>
it and read it in Jupyter.</p>
<p>When using Jupyter, you can edit the document to add your own examples or expand
the ones that you find interesting.</p>
<h2 id="how-to-write-a-tablegen-backend-notebook">“How to Write a TableGen Backend” Notebook</h2>
<p>This notebook uses Python instead of TableGen, and it shows you how to write a
backend.</p>
<p>The 2021 EU LLVM Developer’s Meeting talk
<a href="https://www.youtube.com/watch?v=UP-LBRbvI_U">“How to write a TableGen backend”</a>
by Min-Yih Hsu is the basis for this. The
<a href="https://github.com/llvm/llvm-project/blob/main/llvm/utils/TableGen/jupyter/sql_query_backend.ipynb">notebook</a>
is in fact a Python port of Min’s own
<a href="https://github.com/mshockwave/SQLGen">C++</a> implementation.</p>
<p>It shows you how to take the JSON output of <code>llvm-tblgen</code> and process it with
Python to create SQL queries.</p>
<p>What is unique here is we now have the same content in multiple media forms and
multiple programming languages. Choose the ones that suit you best.</p>
<p>Referring back to “There is TableGen and There are Things Built With TableGen”
, the tutorial notebook is TableGen. The writing a backend notebook is “Things
Built With TableGen”.</p>
<h2 id="limitations">Limitations</h2>
<p>The major limitation of the notebooks is that we have no output filtering. This
means if you do <code>include “llvm/Target/Target.td"</code> you will get about 320,000
lines of output (before you have added any of your own code). This is more than
a default notebook accepts from a kernel and when I removed that limit, the
browser tab crashed.</p>
<p>This is not a problem in most cases and the possible solutions have big
trade-offs, so we are not going to rush a fix. If it does affect you, please add your
feedback to the
<a href="https://github.com/llvm/llvm-project/issues/72856">tracking issue</a>.</p>
<h2 id="tablegen-language-server">TableGen Language Server</h2>
<p>The MLIR project has implemented a server for the
<a href="https://microsoft.github.io/language-server-protocol/">Language Server Protocol</a>
(LSP). Which supports TableGen and
<a href="https://mlir.llvm.org/docs/Tools/MLIRLSP/">2 other languages</a> used within MLIR.</p>
<p>The language server protocol provides information to compatible editors about
the structure of a language and project. For example, where are the included
files? Where is the definition of a particular type?</p>
<p>If you have used a LSP compatible editor (such as Visual Studio Code), you have
probably used a language server without knowing. “Go To Definition” is the
most common feature they provide.</p>
<p>The Language Server Protocol allows you to open a project, go to the code you
want to change and jump from there directly to the other relevant parts of the
repository. With 500,000+ lines of TableGen in the LLVM project, that is a lot of
code you get to ignore!</p>
<h2 id="setup">Setup</h2>
<p>You will need a copy of the server binary <code>tblgen-lsp-server</code>. Which you can get
from the
<a href="https://github.com/llvm/llvm-project/releases">release package</a> for your
platform, or you can build it yourself.</p>
<p>This is how to build it yourself:</p>
<div><pre tabindex="0"><code data-lang="bash">$ cmake -G Ninja &lt;path-to&gt;/llvm-project/llvm -DCMAKE_BUILD_TYPE<span>=</span>Release -DLLVM_ENABLE_PROJECTS<span>=</span><span>"mlir"</span>
$ ninja tblgen-lsp-server
</code></pre></div><p>Having run those commands, <code>tblgen-lsp-server</code> is found in <code>&lt;build-dir&gt;/bin/</code>.</p>
<p>The server reads a compilation database file <code>tablegen_compile_commands.yml</code>,
which is made for you when you configure LLVM using CMake.</p>
<p>This serves a similar purpose to the <code>compile_commands.json</code> file generated when using
<code>CMAKE_EXPORT_COMPILE_COMMANDS</code>, but the two files are not related.</p>
<p>As long as your checkout of llvm-project includes
<a href="https://github.com/llvm/llvm-project/commit/c4afeccdd235a282d200c450e06a730504a66a08">this commit</a>
the compilation database includes TableGen files from all enabled
projects (prior to that commit it was MLIR only).</p>
<p>For example this configure command includes information about TableGen files from the
LLVM, Clang, MLIR and LLDB subprojects:</p>
<div><pre tabindex="0"><code data-lang="bash">$ cmake -G Ninja &lt;path-to&gt;/llvm-project/llvm -DCMAKE_BUILD_TYPE<span>=</span>Release -DLLVM_ENABLE_PROJECTS<span>=</span><span>"clang;llvm;lldb;mlir"</span>
</code></pre></div><p>This also applies to <code>-DLLVM_TARGETS_TO_BUILD=</code>. Enabling only one target means
that the compilation database only has files relevant to that target.</p>
<p><strong>Note:</strong> You do not need to build a project to include its TableGen files in
the compilation database. Configuring is all that is needed.</p>
<p>Next, configure the LSP client for your editor.</p>
<p>If you are using Visual Studio Code, install the MLIR
<a href="https://marketplace.visualstudio.com/items?itemName=llvm-vs-code-extensions.vscode-mlir">extension</a>. Then follow the setup instructions
<a href="https://mlir.llvm.org/docs/Tools/MLIRLSP/#td---tablegen-files">here</a> to tell
the extension where the server and compilation database are.</p>
<p>If you are using a different editor, refer to its documentation to learn how to
set up a language server. Setting the path to the compilation database may require
the use of the server’s command line options. Run <code>tblgen-lsp-server --help</code> to
see all available options.</p>
<h2 id="example">Example</h2>
<p>This example assumes you have configured LLVM with the <code>AArch64</code> target enabled.
(It is enabled by default)</p>
<ul>
<li>Open the file <code>llvm/lib/Target/AArch64/AArch64.td</code>.</li>
<li>Put your cursor on a use of the <code>SubtargetFeature</code> type.</li>
<li>In the menu bar, select “Go” then “Go to Definition”.</li>
<li>This takes you to <code>llvm/include/llvm/Target/Target.td</code>, where
<code>SubtargetFeature</code> is defined.</li>
</ul>
<h2 id="limitations-1">Limitations</h2>
<p>The language server highlights an anti-pattern in the way some LLVM targets
such as AArch64 use TableGen.</p>
<p>You may find yourself in a file that uses a class but does not define it or
include any files which define it. This is because this file is intended to be
included in another file, which does include a definition of that class.</p>
<pre tabindex="0"><code>example.td:
  class Example {}

uses_example.td:
  def example: Example {}

main.td:
  include "example.td"
  include "uses_example.td"
</code></pre><p>The example above shows this anti-pattern:</p>
<ul>
<li>The file <code>example.td</code> defines the class <code>Example</code>.</li>
<li><code>uses_example.td</code> uses the class <code>Example</code>, but does not include <code>example.td</code>.</li>
<li><code>main.td</code> includes both <code>example.td</code> and <code>uses_example.td</code>.</li>
<li><code>main.td</code> is the file that is compiled.</li>
<li>When you are in <code>uses_example.td</code>, the language server does not know where
<code>Example</code> is defined,</li>
<li>When you are in <code>main.td</code>, the language server does know where <code>Example</code> is
defined.</li>
</ul>
<p>Perhaps we can address this by improving the language server, or reorganising
the includes so we do not have files that appear to be isolated.</p>
<h2 id="dump">Dump</h2>
<p>What about <code>printf</code>? The best debugging tool of them all.</p>
<p>TableGen’s equivalent is
<a href="https://llvm.org/docs/TableGen/ProgRef.html#dump-print-messages-to-stderr">dump</a>,
and its companion <code>repr</code>.</p>
<pre tabindex="0"><code>def op;
class A {
  string A = "some text";
  dag X =(op op);
}
def a : A;

dump "The Value of a is: \n" # !repr(a);
</code></pre><p><code>dump</code> prints to <code>stderr</code>:</p>
<pre tabindex="0"><code>&lt;source&gt;:8:1: note: The Value of a is:
a {	// A
  string A = "some text";
  dag X = (op op);
}

dump "The Value of a is: \n" # !repr(a);
^
</code></pre><p>This was added
<a href="https://github.com/llvm/llvm-project/commit/411c4edeef076bd2e01b104fe095ba381600a3d3">recently</a>.
So you will need a recent build, or a released version 18.0 or newer (which is unreleased
at time of writing).</p>
<p>Of course you can try this
<a href="https://godbolt.org/z/Ta6jb19hr">on Compiler Explorer</a> right now!</p>
<h2 id="assertions">Assertions</h2>
<p>An assertion checks that a condition is true at a specific point in your
program. An assertion consists of:</p>
<ul>
<li>The keyword <code>assert</code>.</li>
<li>A condition (usually a call to one of the
<a href="https://llvm.org/docs/TableGen/ProgRef.html#bang-operators">bang operators</a>).</li>
<li>A message.</li>
</ul>
<p>If the condition is false, a compiler error is generated with the message you
provided.</p>
<p>For example, the code below checks that you have not tried to make a register
with a size that is less than 0.</p>
<pre tabindex="0"><code>class Register&lt;int _size&gt; {
  assert !gt(_size, 0),
       "Register size must be &gt; 0, not " # _size # "." ;
  int size = _size;
}

def X0: Register&lt;8&gt; {}
def X1: Register&lt;-8&gt; {}
</code></pre><p>(<a href="https://godbolt.org/z/e4GzvhEeh">Try this on Compiler Explorer</a>)</p>
<p>The register <code>X0</code> has <code>_size=8</code>, so the condition <code>!gt(_size, 0)</code> (which would
be <code>_size &gt; 0</code> in C syntax) is true and therefore no error is generated.</p>
<p>The register <code>X1</code> has <code>_size=-8</code>, so the condition is false and an error is
generated. The compiler output is shown below:</p>
<pre tabindex="0"><code>&lt;source&gt;:2:11: error: assertion failed
   assert !gt(_size, 0),
          ^
note: Register size must be &gt; 0, not -8.
</code></pre><p>While learning new code it is helpful to add your own assertions to check your
assumptions. In addition, adding assertions to code written to be used by other
people is a good way to stop them using it incorrectly. Unlike documentation,
you cannot miss an assertion error.</p>
<h2 id="find-in-files">Find In Files</h2>
<p>This is last because in an ideal world it would be the last option, but it is
often not the least of the options. Grep, ack, Find In Files, whatever you call it,
searching text is unreasonably effective if you have a little knowledge of the
language syntax.</p>
<p>Why should I mention such an obvious idea? Well, obvious is subjective, and
there is a special situation that makes it more effective than usual.</p>
<p>In the LLVM project repository we have the vast majority of TableGen code in use today.
Would you like to know how to use a particular feature? It is all there,
somewhere in 500,000+ lines of source code. You would be surprised by what a
simple query can find despite that.</p>
<p>Think about the thing you are trying to find. What do you think its source
code would look like? If it is a class would it have template arguments or not
and so would there be a <code>&lt;</code> after the name? If it is an error message, what parts
would be constant and what parts would be inserted into a template message?</p>
<p><code>Expected end of line</code> is likely to be a static string so you can search for the
message itself. In contrast, <code>class Foo has no attribute Bar</code> is more likely to
be created by substituting in the name of the class and attribute. So a good
search term for this would be <code>has no attribute</code>.</p>
<p>There are also tests for the compiler, most of which are in
<a href="https://github.com/llvm/llvm-project/tree/main/llvm/test/TableGen">this folder</a>.
This folder contains minimal examples for the language features. Try narrowing
your search to this location.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Learning TableGen does not have to be scary. Do not think that because it is an
isolated DSL that it does not have what you have come to expect from your
favourite languages.</p>
<p>Keep in mind that TableGen is also a tool, not a goal in itself. If you can
achieve your goals with a limited but accurate understanding of TableGen and its
backends, that is great. Learn as much as you want or need.</p>
<p>In addition to the tools, there is an active community ready to answer your
questions on <a href="https://discord.com/invite/xS7Z362">Discord</a> or the
<a href="https://discourse.llvm.org/">forums</a>.</p>
<p>If you find problems or want to contribute improvements please do so. Open a
GitHub <a href="https://github.com/llvm/llvm-project/issues">Issue</a> or
<a href="https://llvm.org/docs/Contributing.html">Pull Request</a>.</p>
<p>Look at the other languages you use. Do they have these tools? Should they? They
might be the difference between frustration and your new favourite language.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>Thank you to Andrzej Warzyński, Francesco Petrogalli, Min-Yih Hsu and Sally Neale (Arm) for reviewing this article.</p>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LXD now re-licensed and under a CLA (117 pts)]]></title>
            <link>https://stgraber.org/2023/12/12/lxd-now-re-licensed-and-under-a-cla/</link>
            <guid>38618696</guid>
            <pubDate>Tue, 12 Dec 2023 21:18:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stgraber.org/2023/12/12/lxd-now-re-licensed-and-under-a-cla/">https://stgraber.org/2023/12/12/lxd-now-re-licensed-and-under-a-cla/</a>, See on <a href="https://news.ycombinator.com/item?id=38618696">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			    
<figure><a href="https://stgraber.org/wp-content/uploads/2023/12/image-1.png"><img fetchpriority="high" decoding="async" width="1024" height="512" src="https://stgraber.org/wp-content/uploads/2023/12/image-1-1024x512.png" data-src="https://stgraber.org/wp-content/uploads/2023/12/image-1-1024x512.png" alt="" data-srcset="https://stgraber.org/wp-content/uploads/2023/12/image-1-1024x512.png 1024w, https://stgraber.org/wp-content/uploads/2023/12/image-1-300x150.png 300w, https://stgraber.org/wp-content/uploads/2023/12/image-1-768x384.png 768w, https://stgraber.org/wp-content/uploads/2023/12/image-1.png 1200w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://stgraber.org/wp-content/uploads/2023/12/image-1-1024x512.png 1024w, https://stgraber.org/wp-content/uploads/2023/12/image-1-300x150.png 300w, https://stgraber.org/wp-content/uploads/2023/12/image-1-768x384.png 768w, https://stgraber.org/wp-content/uploads/2023/12/image-1.png 1200w"></a></figure>



<h2>The facts</h2>



<p>As of earlier today, right before the release of <a href="https://discourse.ubuntu.com/t/lxd-5-20-has-been-released/40865" target="_blank" rel="noreferrer noopener">LXD 5.20</a>, Canonical made a couple of changes to LXD which are sure to have a serious impact to LXD users and downstream projects that integrate with LXD or provide solutions based on it.</p>



<p>The first is the re-licensing of LXD from the Apache2 license to the AGPLv3 license.<br>This happened in: <a href="https://github.com/canonical/lxd/pull/12663" target="_blank" rel="noreferrer noopener">https://github.com/canonical/lxd/pull/12663</a></p>



<p>The second is the addition of the Canonical CLA as requirement for all further contributions.<br>This happened in: <a href="https://github.com/canonical/lxd/pull/12665" target="_blank" rel="noreferrer noopener">https://github.com/canonical/lxd/pull/12665</a><a href="https://github.com/canonical/lxd/pull/12663">https://github.com/canonical/lxd/pull/12663</a></p>



<h2>Disclaimer</h2>



<p>What’s below is my personal analysis of the situation, it is not legal advice, anyone affected is very strongly encouraged to seek proper legal advice from their counsel.</p>



<h2>Real license of LXD</h2>



<p>Per the commit message performing the re-licensing, all further contributions will be under the AGPLv3 license and all contributions from Canonical employees have been re-licensed to AGPLv3.</p>



<p>However, Canonical does not own the copyright on any contribution from non-employees, such as the many changes they have imported from Incus over the past few months. Those therefore remain under the Apache2 license that they were contributed under.</p>



<p>As a result, Canonical cannot release LXD under the AGPLv3 license and likely never will be able to.<br>LXD is now under a weird mix of Apache2 and AGPLv3 with no clear metadata indicating what file or what part of each file is under one license or the other.</p>



<p>This is likely to make it very “fun” for anyone performing licensing reviews to evaluate LXD for adoption in their environment.</p>



<h2>Impact to LXD users</h2>



<p>For LXD users, other than potentially triggering corporate policies that ban the use of AGPLv3 software (more common than one may think), the impact should be minimal. It’s still the same LXD and it’s still open source software.</p>



<p>However, if you were altering LXD in any way, then you will need to familiarize yourself with the AGPLv3 license as unlike Apache2, it does require any changes be made available under the AGPLv3 even if you don’t expose your users to your modified binaries. This is the main design characteristics of the AGPLv3 license, it was meant to force those operating modified versions of open source as a hosted service to share their modifications.</p>



<h2>Impact to downstreams (consumer of LXD Go packages)</h2>



<p>Up until now, all the Go packages of LXD were under the Apache2 license, that was fitting quite well in the Go ecosystem where the Apache2, BSDs and MIT licenses are very popular.</p>



<p>Now with this change, you need to realize that you may start to include/bundle AGPLv3 code within your own project. This a copyleft license and so may require re-licensing of your own project to comply with it.</p>



<p>Again, this is quite the can of worms, with my usual recommendation being “stay away”, but if you must use any of LXD’s Go packages, I’d strongly recommend talking to a lawyer to fully understand your exposure to that new license.</p>



<h2>Impact on Incus</h2>



<p>Now for what obviously impacts me the most, what this is going to do to Incus.</p>



<p>As a brief reminder <a href="https://github.com/lxc/incus" data-type="link" data-id="https://github.com/lxc/incus" target="_blank" rel="noreferrer noopener">Incus</a> is a fork of LXD which was started in August 2023.<br>So far, it’s been tracking LXD changes, applying those that make sense and otherwise fixing bugs and making improvements of its own, as most forks do.</p>



<p>This change from Canonical is going to be causing two unfortunate side effects:</p>



<ul>
<li>Incus will no longer be including changes originating from LXD as that would require us to include AGPLv3 code into our codebase and so get us into the same mixed license mess as LXD now put itself. This is obviously unacceptable to us, we very much like licensing clarity and quite enjoy the Apache2 license.</li>



<li>LXD will similarly no longer be able to take changes from Incus, as those are going to remain under the Apache2 license and more importantly, will not have been released under the Canonical CLA.</li>
</ul>



<p>To enforce that second part, the tooling we’ve been using thus far to monitor LXD changes and automatically backport them to Incus will be used to detect any changes to LXD which originated from Incus. Unless the author gave express consent for them to be released under a different license and under the Canonical CLA, those changes should not be included in LXD.</p>



<p>Incus is also a consumer of the LXD Go API in the <code>lxd-to-incus</code> tool. Thankfully, we have no need for anything recent in there, so will simply be making sure that we never import code past the licensing change.</p>



<h2>Conclusion</h2>



<p>Overall, I’m very disappointed, although absolutely not surprised in seeing this change happen.<br>It’s certainly going to be quite annoying for Incus, and I suspect this is the whole point of it.</p>



<p>But it’s also a very odd move by Canonical as it puts LXD into a problematic grey area as far as its true license is concerned which will likely seriously hurt its adoption both by companies and distributions.</p>



<p>In any case, I’d urge anyone who has concerns about this change to reach out to their legal representation and maybe consider switching over to Incus where we will happily keep releasing our CLA-free Apache2 licensed fork of this once great project.</p>



<h2>Update <a rel="tag" href="https://stgraber.org/tag/1/">#1</a></h2>



<p>I’ve seen a number of people point out that Apache2 is compatible with the AGPLv3 and that’s certainly correct, however compatibility doesn’t mean that the code in question suddenly becomes AGPLv3, it means that it can be included in an AGPLv3 project. So I’d still expect there to be good tracking of the license of the individual files / code chunks so that someone can tell whether a particular piece of code is AGPLv3 or Apache2, this is currently not possible.</p>



<p>The <a href="https://github.com/canonical/lxd/blob/main/AUTHORS" target="_blank" rel="noreferrer noopener">code</a> mentions headers (probably SPDX) to be present whenever code isn’t AGPLv3, but no such headers were introduced at time of writing.</p>



<p>The announcement also very specifically spells out that past contributions are not being re-licensed and therefore remain under the Apache2 license, though again, there is currently no way to identify what contributions that is. So this still leads to LXD now being a mix of AGPLv3 and Apache2 with no way to figure out which is which.</p>



<p>All that’s known for sure is that all new contributions are to be under AGPLv3 and must be from copyright holders (author or employer) who has signed the Canonical CLA. Those two will preclude the inclusion of any Incus code in LXD moving forward.</p>
			    			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hasbro lays off nearly 20% of its workers (207 pts)]]></title>
            <link>https://www.polygon.com/23998290/hasbro-layoffs-before-christmas</link>
            <guid>38618111</guid>
            <pubDate>Tue, 12 Dec 2023 20:37:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.polygon.com/23998290/hasbro-layoffs-before-christmas">https://www.polygon.com/23998290/hasbro-layoffs-before-christmas</a>, See on <a href="https://news.ycombinator.com/item?id=38618111">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p id="ws0cUw">Game and toy maker <a href="https://www.polygon.com/23500171/hasbro-magic-overprinting-fireside-chat-cynthia-williams">Hasbro</a> announced it will cut roughly 1,100 jobs on Monday. When added to the 800 layoffs made earlier this year, the total amounts to just less than one-third of the company’s entire labor force. The news comes exactly two weeks ahead of Christmas, traditionally the biggest holiday of the year for game and toy sales.</p>
<p id="ftaXmm">“We entered 2023 expecting a year of change including significant updates to our leadership team, structure, and scope of operations,” said CEO Chris Cocks in a memo to his employees that was shared with Polygon. “We anticipated the first three quarters to be challenging, particularly in Toys, where the market is coming off historic, pandemic-driven highs. While we have made some important progress across our organization, the headwinds we saw through the first nine months of the year have continued into Holiday and are likely to persist into 2024.”</p>
<p id="70D5Ca">The news likely comes as no surprise to insiders, including investors, who have been tracking the shortfalls of the company’s toy portfolio for some time. Meanwhile, Hasbro subsidiary Wizards of the Coast, which publishes both <a href="https://www.polygon.com/deals/21294556/dnd-how-to-play-dungeons-dragons-5e-guide-spells-dice-character-sheets-dm">Dungeons &amp; Dragons</a> and <a href="https://www.polygon.com/mtg-magic-the-gathering"><em>Magic: The Gathering</em></a>, is experiencing all-time highs for both revenue earned and the number of players engaged in those brands. Activist hedge fund Alta Fox attempted to push the Rhode Island-based company to spin off Wizards in 2022, but the effort was defeated in <a href="https://www.reuters.com/business/retail-consumer/hasbro-defeats-board-challenge-activist-investor-alta-fox-2022-06-08/">a high-profile shareholder election in June 2022</a>. Now the 100-year-old company is left to rebuild in 2024.</p>
<p id="PCODex">Polygon reached out to the tabletop teams impacted by these layoffs, including <a href="https://www.polygon.com/23817191/betrayal-at-house-on-the-hill-santa-claus-holiday-expansion-release-date-price">Avalon Hill</a>, <em>Magic: The Gathering</em>, and Dungeons &amp; Dragons. One representative said that the company is “not sharing breakdowns on geography or teams out of respect for employees.” Impacted workers are expected to be contacted by the end of the business day Tuesday.</p>
<p id="9HLQqg">“Cost-cutting is not a strategy,” Cocks added. “We know this, and that’s why we’ll continue to grow and invest in several areas in 2024.”</p>
<p id="axNzev">One area of investment for Hasbro appears to be the video game sector. Its latest project, <a href="https://www.polygon.com/game-awards-tga/23992111/exodus-release-date-bioware-rpg-archetype"><em>Exodus</em></a>, made a big splash last week at <a href="https://www.polygon.com/game-awards-tga/23992648/the-game-awards-2023-biggest-game-announcements-trailers">The Game Awards</a>. Following the success of <a href="https://www.polygon.com/baldurs-gate-3-guides"><em>Baldur’s Gate 3</em></a>, which was produced under license by Larian Studios, Wizards’ own Archetype Entertainment appears to have a solid footing. Founded by veterans of BioWare, the studio behind <em>Star Wars: Knights of the Old Republic</em>, <em>Baldur’s Gate</em>, <em>Neverwinter Nights</em>, and <a href="https://www.polygon.com/2020/2/12/21135139/mass-effect-drew-karpyshyn-wizards-of-the-coast-archetype-entertainment-bioware">the Mass Effect trilogy</a>, the game will be released on PlayStation 5, Windows PC, and Xbox Series X. It currently has no release date.</p>
<p id="EUcigJ">Hasbro stock has fallen some 20% this year according to <a href="https://www.wsj.com/business/retail/hasbro-layoffs-toy-company-ed760682">The Wall Street Journal</a>, with today’s price down slightly on the news. Long-term investors, meanwhile, are expected to continue to earn dividends at a rate of 5.8% annually according to <a href="https://www.google.com/finance/quote/HAS:NASDAQ?sa=X&amp;ved=2ahUKEwjwkey8poqDAxX9IzQIHezaAAwQ3ecFegQILxAi">Google Finance</a>. Cocks earned a reported <a href="https://www.bizjournals.com/rhodeisland/news/2023/04/05/hasbro-ceo-chris-cocks.html">$9.4 million</a> last year — his first year as Hasbro’s CEO. At the new price point of $59.95, that’s roughly equivalent to 156,797 copies of the <a href="https://www.polygon.com/23730399/dnd-dungeons-dragons-revised-core-rulebook-preview-players-handbook-dmg"><em>Player’s Handbook</em></a>.</p>

  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What We Watched: A Netflix engagement report (180 pts)]]></title>
            <link>https://about.netflix.com/en/news/what-we-watched-a-netflix-engagement-report</link>
            <guid>38617359</guid>
            <pubDate>Tue, 12 Dec 2023 19:46:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://about.netflix.com/en/news/what-we-watched-a-netflix-engagement-report">https://about.netflix.com/en/news/what-we-watched-a-netflix-engagement-report</a>, See on <a href="https://news.ycombinator.com/item?id=38617359">Hacker News</a></p>
Couldn't get https://about.netflix.com/en/news/what-we-watched-a-netflix-engagement-report: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Hardening cellular basebands in Android (184 pts)]]></title>
            <link>https://security.googleblog.com/2023/12/hardening-cellular-basebands-in-android.html</link>
            <guid>38616922</guid>
            <pubDate>Tue, 12 Dec 2023 19:16:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://security.googleblog.com/2023/12/hardening-cellular-basebands-in-android.html">https://security.googleblog.com/2023/12/hardening-cellular-basebands-in-android.html</a>, See on <a href="https://news.ycombinator.com/item?id=38616922">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-version="1" id="header">
<div>
<p><a href="https://security.googleblog.com/">
<img height="50" src="https://www.gstatic.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png">
</a></p><a href="https://security.googleblog.com/">
<h2>
            Security Blog
          </h2>
</a>
</div>
<p>
The latest news and insights from Google on security and safety on the Internet
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI’s big rift is like a religious schism (249 pts)]]></title>
            <link>https://www.programmablemutter.com/p/the-singularity-is-nigh-republished</link>
            <guid>38616888</guid>
            <pubDate>Tue, 12 Dec 2023 19:13:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.programmablemutter.com/p/the-singularity-is-nigh-republished">https://www.programmablemutter.com/p/the-singularity-is-nigh-republished</a>, See on <a href="https://news.ycombinator.com/item?id=38616888">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F730fc1ce-0e5e-4640-baa5-745f31c1d502_1792x1024.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F730fc1ce-0e5e-4640-baa5-745f31c1d502_1792x1024.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F730fc1ce-0e5e-4640-baa5-745f31c1d502_1792x1024.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F730fc1ce-0e5e-4640-baa5-745f31c1d502_1792x1024.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F730fc1ce-0e5e-4640-baa5-745f31c1d502_1792x1024.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F730fc1ce-0e5e-4640-baa5-745f31c1d502_1792x1024.webp" width="1456" height="832" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/730fc1ce-0e5e-4640-baa5-745f31c1d502_1792x1024.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:832,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;A conceptual and artistic representation of the Singularity, depicted in landscape mode, visualizing the hypothetical moment when technological growth becomes uncontrollable and irreversible, profoundly changing human civilization. This wide-format image should feature advanced futuristic technology, such as AI, robotics, and cybernetics, merging seamlessly with human elements to represent the blending of human and machine intelligence. The scene should be dynamic and transformative, with swirling lights, digital patterns, and abstract forms to symbolize the rapid advancement of technology. The overall ambiance should be awe-inspiring and slightly enigmatic, capturing the vast, profound impact of the Singularity on the future of humanity.&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="A conceptual and artistic representation of the Singularity, depicted in landscape mode, visualizing the hypothetical moment when technological growth becomes uncontrollable and irreversible, profoundly changing human civilization. This wide-format image should feature advanced futuristic technology, such as AI, robotics, and cybernetics, merging seamlessly with human elements to represent the blending of human and machine intelligence. The scene should be dynamic and transformative, with swirling lights, digital patterns, and abstract forms to symbolize the rapid advancement of technology. The overall ambiance should be awe-inspiring and slightly enigmatic, capturing the vast, profound impact of the Singularity on the future of humanity." title="A conceptual and artistic representation of the Singularity, depicted in landscape mode, visualizing the hypothetical moment when technological growth becomes uncontrollable and irreversible, profoundly changing human civilization. This wide-format image should feature advanced futuristic technology, such as AI, robotics, and cybernetics, merging seamlessly with human elements to represent the blending of human and machine intelligence. The scene should be dynamic and transformative, with swirling lights, digital patterns, and abstract forms to symbolize the rapid advancement of technology. The overall ambiance should be awe-inspiring and slightly enigmatic, capturing the vast, profound impact of the Singularity on the future of humanity." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F730fc1ce-0e5e-4640-baa5-745f31c1d502_1792x1024.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F730fc1ce-0e5e-4640-baa5-745f31c1d502_1792x1024.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F730fc1ce-0e5e-4640-baa5-745f31c1d502_1792x1024.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F730fc1ce-0e5e-4640-baa5-745f31c1d502_1792x1024.webp 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>[NB - the below has just been published by </span><a href="https://www.economist.com/by-invitation/2023/12/12/ais-big-rift-is-like-a-religious-schism-says-henry-farrell" rel="">The Economist</a><span> under the title “AI’s big rift is like a religious schism, says Henry Farrell.” It is being republished here, for six months only, with The Economist’s permission. The picture above is what ChatGPT4 gives you when prompted for “an image of the singularity, landscape mode” - I’m using it, as much as anything else, to show </span><em>how generic and universal</em><span> the notion of the Singularity has become.]</span></p><p>Two centuries ago Henri de Saint-Simon, a French utopian, proposed a new religion, worshipping the godlike force of progress, with Isaac Newton as its chief saint. He believed that humanity’s sole uniting interest, “the progress of the sciences”, should be directed by the “elect of humanity”, a 21-member “Council of Newton”. Friedrich Hayek, a 20th-century economist, later gleefully described how this ludicrous “religion of the engineers” collapsed into a welter of feuding sects.</p><p>Today, the engineers of artificial intelligence (AI) are experiencing their own religious schism. One sect worships progress, canonising Hayek himself. The other is gripped by terror of godlike forces. Their battle has driven practical questions to the margins of debate.</p><p>Both cults are accidental by-products of science fiction. In 1993 Vernor Vinge drew on computer science and his fellow science-fiction writers to argue that ordinary human history was drawing to a close. We would surely create superhuman intelligence sometime within the next three decades, leading to a “Singularity”, in which AI would start feeding on itself. The future might be delightful or awful, depending on whether machines enhanced human intelligence or displaced it.</p><p>Some were optimistic. The futurist Ray Kurzweil wrote an enormous tome, “The Singularity is Near”, predicting a cusp in 2045. We humans would become immortal, spreading intelligence throughout the universe, and eventually merging into God. For all its statistics and exponentials, the book prophesied “the Rapture of the Nerds”, as one unkind critic called it. Its title really should have been “The Singularity is Nigh”.</p><p>Others feared the day of judgment. Eliezer Yudkowsky, a self-taught AI researcher, was deeply influenced by Mr Vinge’s ideas. He fathered Silicon Valley’s “rationalist” movement, which sought to improve human reasoning and stop AI destroying humankind.</p><p>Rationalists believed that Bayesian statistics and decision theory could de-bias human thinking and model the behaviour of godlike intelligences. They revelled in endless theoretical debates, like medieval Christian philosophers disputing the nature of angels, applying amateur game theory instead of Aristotelian logic. Sometimes their discussions were less erudite. Mr Yudkowsky popularised his ideas in a 660,000-word fan-fiction epic, “Harry Potter and the Methods of Rationality”.</p><p>Rationalists feared that superhuman AIs wouldn’t have our best interests at heart. One notorious thought experiment—a modern version of Pascal’s wager, dubbed “Roko’s basilisk”—claimed that logic dictated that future divine intelligences would torture anyone who had known that AI was possible and hadn’t devoted themselves to bringing it into existence. AIs might also use their awesome reasoning powers to escape any limits that humans imposed on them, creating an “x risk” (existential risk) to human survival.</p><p>Rationalism explains why AI pioneers became obsessed with x risk. Sam Altman, Elon Musk and others founded OpenAI, the creator of Chatgpt, as a non-profit so that it wouldn’t duck the dangers of machine intelligence. But the incentives shifted as the funding flooded in. Some OpenAI staffers feared that their employer cared more about the opportunities than the dangers and defected to found Anthropic, a rival AI firm. More recently, clashes over AI risk, money and power reportedly led to the fracture between Mr Altman and his board.</p><p>If rationalists are frustrated by Silicon Valley’s profit model, Silicon Valley is increasingly frustrated by rationalism. Marc Andreessen, the co-founder of Andreessen Horowitz, a venture-capital firm, fulminated in June that the extremist AI-risk “cult” was holding back an awesome AI-augmented future, in which humanity could reach for the stars.</p><p>This backlash is turning into its own religion of the engineers. Grimes, a musician and Silicon Valley icon, marvels that AI engineers are “designing the initial culture of the universe”. She calls for a “Council of Elrond” (this conclave a nod to “The Lord of the Rings”) comprising the “heads of key AI companies and others who understand it” to set AI policy. Grimes met Mr Musk, the father of her children, through a shared joke about Roko’s basilisk.</p><p>In October Mr Andreessen published his own “Techno-Optimist Manifesto” to wide acclaim from Silicon Valley entrepreneurs. In it, he takes aim at a decades-long “demoralisation campaign…against technology and life”, under various names including “sustainable development goals”, “social responsibility”, “trust and safety” and “tech ethics”. Efforts to decelerate AI “will cost human lives” and are thus tantamount to “murder”.</p><p>Mr Andreessen’s manifesto is a Nicene creed for the cult of progress: the words “we believe” appear no less than 113 times in the text. His list of the “patron saints” of techno-optimism begins with Based Beff Jezos, the social-media persona of a former Google engineer who claims to have founded “effective accelerationism”, a self-described “meta-religion” which puts its faith in the “technocapital Singularity”.</p><p>Our future is currently being built around Mr Vinge’s three-decades-old essay, a work that only Silicon Valley thinkers and science-fiction fans have read. Warring cults dispute whether engineers are as gods, or just unwitting Dr Frankensteins.</p><p>This schism is an attention-sucking black hole that makes its protagonists more likely to say and perhaps believe stupid things. Of course, many AI-risk people recognise that there are problems other than the Singularity, but it’s hard to resist its relentless gravitational pull. Before Mr Andreessen was fully dragged past the event horizon, he made more nuanced arguments about engineers’ humility and addressing the problems of AI as they arose.</p><p>But we need even more to listen to other people. Last month, at Rishi Sunak’s global AI-policy summit, Mr Musk pontificated about the need for an “off switch” for hostile AI. The main event was all about x risk and AI’s transformative promise, consigning other questions to a sideshow dubbed the “AI Fringe”.</p><p>At the same time, Rachel Coldicutt, a British tech thinker, was putting together a “Fringe of the Fringe”, where a much more diverse group of thinkers debated the topics that hadn’t made the main agenda: communities, transparency, power. They didn’t suggest a Council of the Elect. Instead, they proposed that we should “make AI work for eight billion people, not eight billionaires”. It might be nice to hear from some of those 8bn voices.■</p><p><em><span>Henry Farrell is a professor of international affairs and democracy at Johns Hopkins University, and co-author of “</span><a href="https://amzn.to/3PbIyqX" rel="">Underground Empire: How America Weaponized the World Economy”</a></em><a href="https://amzn.to/3PbIyqX" rel="">.</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What Will Enter the Public Domain in 2024? (314 pts)]]></title>
            <link>https://publicdomainreview.org/features/entering-the-public-domain/2024/</link>
            <guid>38616753</guid>
            <pubDate>Tue, 12 Dec 2023 19:03:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://publicdomainreview.org/features/entering-the-public-domain/2024/">https://publicdomainreview.org/features/entering-the-public-domain/2024/</a>, See on <a href="https://news.ycombinator.com/item?id=38616753">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>At the start of each year, on January 1st, a new crop of works enter the public domain and become free to enjoy, share, and reuse for any purpose. Due to differing copyright laws around the world, there is no one single public domain — and here we focus on three of the most prominent. Newly entering the public domain in 2024 will be:</p><ul><li>works by <a href="https://en.wikipedia.org/wiki/2024_in_public_domain#Countries_with_life_+_70_years">people who died in 1953</a>, for countries with a copyright term of “life plus 70 years” (e.g. UK, Russia, most of EU and South America);</li><li>works by <a href="https://en.wikipedia.org/wiki/2024_in_public_domain#Countries_with_life_+_50_years">people who died in 1973</a>, for countries with a term of “life plus 50 years” (e.g. New Zealand, and most of Africa and Asia);</li><li><a href="https://en.wikipedia.org/wiki/1928_in_film">films</a> and <a href="https://en.wikipedia.org/wiki/1928_in_literature#New_books">books</a> (incl. artworks featured) published in 1928 for the United States.</li></ul><p>In our advent-style calendar below, find our top pick of what lies in store for 2024. Each day, as we move through December, we’ll open a new window to reveal our highlights! By public domain day on January 1st they will all be unveiled — look out for a special blogpost from us on that day. (And, of course, if you want to dive straight in and explore the vast swathe of new entrants for yourself, just visit the links above).</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Motorola's pioneering 8-bit 6800: Origins and architecture (119 pts)]]></title>
            <link>https://thechipletter.substack.com/p/motorolas-pioneering-8-bit-6800-origins</link>
            <guid>38616591</guid>
            <pubDate>Tue, 12 Dec 2023 18:53:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thechipletter.substack.com/p/motorolas-pioneering-8-bit-6800-origins">https://thechipletter.substack.com/p/motorolas-pioneering-8-bit-6800-origins</a>, See on <a href="https://news.ycombinator.com/item?id=38616591">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1dc67cd-e095-495c-b6c6-ae4518c4fb90_1024x986.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1dc67cd-e095-495c-b6c6-ae4518c4fb90_1024x986.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1dc67cd-e095-495c-b6c6-ae4518c4fb90_1024x986.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1dc67cd-e095-495c-b6c6-ae4518c4fb90_1024x986.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1dc67cd-e095-495c-b6c6-ae4518c4fb90_1024x986.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1dc67cd-e095-495c-b6c6-ae4518c4fb90_1024x986.jpeg" width="1024" height="986" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b1dc67cd-e095-495c-b6c6-ae4518c4fb90_1024x986.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:986,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:536594,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1dc67cd-e095-495c-b6c6-ae4518c4fb90_1024x986.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1dc67cd-e095-495c-b6c6-ae4518c4fb90_1024x986.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1dc67cd-e095-495c-b6c6-ae4518c4fb90_1024x986.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb1dc67cd-e095-495c-b6c6-ae4518c4fb90_1024x986.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>Motorola 6800 Die Shot - Pauli Rautakorpi, CC BY 3.0 &lt;https://creativecommons.org/licenses/by/3.0&gt;, via Wikimedia Commons</figcaption></figure></div><p><em>Why write about the Motorola 6800 (pronounced ‘sixty-eight hundred’)? For the generation that grew up with home computers in the late 1970s, the 6800 was the 6502’s slightly boring uncle. It was used in ‘grown-up’ devices, like cash machines, but it was slower, more expensive and generally less interesting than the 6502.</em></p><p><em>In reality, the 6800 was a highly innovative design that, just as much as competing products from Intel, represented a major step forward in making computing widely accessible to all.</em></p><p><em><span>Intel would eventually ‘win’ in microprocessors with the x86 architecture, and winners write the history, but Motorola deserves just as much respect as an early pioneer. This is probably why the 6800 came top of </span><a href="https://thechipletter.substack.com/p/the-virtues-of-the-8-bit-era-eight" rel="">our poll</a><span> of which 8-bit design to write about.</span></em></p><p><em>The story of the 6800 is also a story of how a corporation can develop innovative technology with enormous potential, only to self-sabotage and hand the advantage to a competitor. We’ll see how this happened in Part 2 of the story of the 6800. We’ll also discover that, remarkably, almost 50 years after its launch you can still buy the 6800 today!</em></p><p data-attrs="{&quot;url&quot;:&quot;https://thechipletter.substack.com/p/motorolas-pioneering-8-bit-6800-origins?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://thechipletter.substack.com/p/motorolas-pioneering-8-bit-6800-origins?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p>For modern readers the name Motorola is probably most familiar as a brand of cell phones made by Motorola Mobility, now a subsidiary of Chinese multinational Lenovo. Cell phones combine digital and wireless electronics and the roots of Motorola Mobility are in Motorola Inc. which, for many decades, operated at the leading edge of both fields.</p><p>Motorola Inc, was founded as Galvin Manufacturing Corporation by the brothers Paul and Joseph Galvin in 1929. Early products included a car radio which was given the brand Motorola, combining ‘Motor’ and ‘ola’ used in other audio products such as the ‘Victorola’ phonograph or record player.&nbsp; The car radios became so successful that the company changed its name to Motorola in 1947.</p><p>By the early 1950s the future of electronics lay in the transistor and Motorola built its first manufacturing plant for transistors, at a cost of $1.5m, in Phoenix, Arizona. Dan Noble, Vice President of Communications and Electronics, wrote enthusiastically and prophetically, about the new devices in the company’s 1955 annual report:</p><blockquote><p>"The word 'revolution' may not be too strong to apply to the change which will take place in electronic equipment of all kinds within the next five years. The development of the transistor and other semi-conductor devices will reduce the size of equipment, improve the reliability of operation, and substantially reduce the operational power requirements. Not only will transistors replace vacuum tubes in many electronic equipments, but they will make possible the development of new devices for instrumentation, metering, controlling, detection, communications, and computing.”</p></blockquote><p>By the mid 1960s, under the leadership of Lester Hogan, Motorola was making a variety of transistors, other discrete semiconductors and integrated circuits in Arizona. Hogan would ‘defect’ from Motorola to Fairchild Camera and Instrument in 1968, to become Chairman and CEO. Taking eight of his Motorola team, nicknamed ‘Hogan’s heroes’, with him, Hogan would replace Robert Noyce, when Noyce and Gordon Moore left Fairchild to found Intel.</p><p>The loss of Hogan and much of Motorola’s senior semiconductor team was just one contributor to a turbulent time for the company’s semiconductor division. The industry was in the middle of a transition from Bipolar to MOS integrated circuits. And a number of competitors were appearing, including the ‘Fairchildren’, companies founded by former Fairchild employees, including, crucially, Noyce and Moore’s Intel.</p><p>In the midst of all this change at the start of the 1970s, it became apparent to Motorola’s, mostly new, senior management team, that a number of firms were working on the development of microprocessors.</p><p>Tom Bennett, who would become a key member of Motorola’s microprocessor team, had been introduced to the idea in the form of early sketches for what would become the first commercial microprocessor, the Intel 4004, by Intel’s Ted Hoff. Bennett had been working on calculators at Victor Comptometer in Chicago, when he’d been approached by Hoff to see if he would be interested in using the proposed Intel chip in new calculator designs.</p><p>Bennett joined Motorola in 1971 to try to help them enter the calculator business. It was soon clear to Bennett, and others, that the microprocessor had much wider application than calculators. It could solve lots of other problems that had previously needed custom, complex and difficult ‘random logic’ designs.&nbsp;</p><p><span>Bennett had responsibility development of custom chips for potential external Motorola customers. One of those chips was a custom microprocessor for Olivetti. Motorola won the design, but couldn’t manufacture the chip in the required PMOS (</span><a href="https://en.wikipedia.org/wiki/PMOS_logic#:~:text=PMOS%20or%20pMOS%20logic%20(from,%2Deffect%20transistors%20(MOSFETs)." rel="">p-channel Metal Oxide Silicon</a><span>) process. Instead the design had to be licensed to competitor Mostek, who were able to build it, and who launched it as the Mostek 5065. Bill Lattin would later describe Motorola at the time:</span></p><blockquote><p>…we had a rotating set of management, and nobody ever seemed to stick very long, and nobody ever understood the technology very deeply, and that was a real problem, because not only were implanters expensive. You needed clean rooms. This was a very expensive operation. Motorola wanted to get in, but they were, you know, didn’t quite understand what it was gonna take to get in.</p></blockquote><p><span>Motorola’s inability to manufacture the 5065 must have been embarrassing. Lattin, received a, typically direct, recruitment pitch from Intel’s Andy Grove, who had taught Lattin at Berkeley, quoted in </span><a href="https://www.amazon.com/Inside-Intel-Worlds-Powerful-Company/dp/0452276438/ref=tmm_pap_swatch_0" rel="">Inside Intel</a><span>:</span></p><blockquote><p>‘Grove had a very abrasive style,' Lattin recalled. 'It didn't work well with me... The recruiting style was: Motorola doesn't have a chance - we're going to kick their butts.'</p></blockquote><p>Lattin declined Grove’s offer. The 5065 saga possibly convinced Motorola’s management that they needed to sort out their manufacturing processes. It certainly gave members of the Motorola team valuable experience in designing a microprocessor.</p><p>But was making a microprocessor worth the considerable investment needed? At first Motorola’s marketing department quoted expected sales of only 18,000 microprocessors over five years.</p><p>But Bennett and colleagues continued to look for sales opportunities. National Data Corp (NDC) presented a proposal that would have required 200,000 microprocessors. NDC was a ‘time-sharing’ company that saw the opportunity to use a microprocessor in terminals connected to their central system. Nothing came of the NDC project, but it showed the sales potential and provided the impetus to start a new project to design a microprocessor..</p><p>So a team was assembled in Phoenix, Arizona. Bennett would become chief architect of the project. He was joined by Jeff LaVell and Bill Lattin. Together they used data that LaVell had gathered from talking to potential customers, to devise a series of integrated circuit building blocks. These could be used to create a range of systems, with an emphasis on those that needed communications capability. The 6800 would be joined by chips that would provide memory (6801, 6802 and 6803), input and output capabilities (6820 ‘Peripheral Interface Adapter’ and 6850 ‘Asynchronous Communications Interface Adapter’) and even a modem chip (6860).</p><p>John Buchanan who would do circuit design and the layout of the 6800 and the other chips. Rod Orgill assisted Buchanan with analysis of the design and layout. Bill Mensch worked on the design of the 6820. Chuck Peddle joined the 6800 team in 1973, after the design of the microprocessor was completed but worked on the 6820 and then on the marketing of the designs. The final team remained small, with around seventeen members in total.&nbsp;</p><p>To build the 6800 and the other members of the family the team had to get both the logic design and the fabrication technology working. On the logic design Bennett would describe the approach as follows:</p><blockquote><p>My original plan for it was to basically use a PLA [Programmable logic Array]-type control. But we couldn’t get enough speed out of it. So if you looked at the chip, the top part of it is all ROM, which does the initial decode of the instructions, and then after that there was a state counter, and that state counter cycled through, depending on how many separate steps it took to get the instruction completed.</p></blockquote><p><span>The layout of the 6800, with ROM at the top, registers and the arithmetic and logic unit at the bottom and control logic between the two can be seen in die shots and in the the ‘</span><a href="http://www.visual6502.org/JSSim/expert-6800.html" rel="">Visual 6800</a><span>’ simulation, that shows how signals in the 6800 change as the 6800 runs (click on the picture below to see the 6800 in operation - highly recommended!)</span></p><div><figure><a target="_blank" href="http://www.visual6502.org/JSSim/expert-6800.html" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff44d3d41-c3aa-4003-a37f-d30b271a2b22_1494x1494.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff44d3d41-c3aa-4003-a37f-d30b271a2b22_1494x1494.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff44d3d41-c3aa-4003-a37f-d30b271a2b22_1494x1494.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff44d3d41-c3aa-4003-a37f-d30b271a2b22_1494x1494.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff44d3d41-c3aa-4003-a37f-d30b271a2b22_1494x1494.jpeg" width="1456" height="1456" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f44d3d41-c3aa-4003-a37f-d30b271a2b22_1494x1494.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1456,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:411268,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:&quot;http://www.visual6502.org/JSSim/expert-6800.html&quot;,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff44d3d41-c3aa-4003-a37f-d30b271a2b22_1494x1494.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff44d3d41-c3aa-4003-a37f-d30b271a2b22_1494x1494.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff44d3d41-c3aa-4003-a37f-d30b271a2b22_1494x1494.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff44d3d41-c3aa-4003-a37f-d30b271a2b22_1494x1494.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Screenshot of Visual 6800 Simulation</figcaption></figure></div><p>On fabrication, the team made matters harder for themselves by aiming for a design that needed just a +5 volt input, unlike the +5,-5 and +12 volt inputs needed by competitors.</p><p>Layout of the 6800’s design started at the end of 1972, but it took until February 1974 for the first parts, working apart from a few instructions with bugs, to be available.</p><p>The 6800 was announced in March 1974, just a month after Intel announced the competing Intel 8080. However, Intel had the 8080 in full production by April 1974, whilst the 6800 continued to be plagued by number of production issues that Motorola took several months to solve. The 6800 would only enter full production in November 1974, giving Intel a vital lead of a few months.</p><p>The 8080’s designer Federico Faggin later said:</p><blockquote><p>Eventually, in the middle of 1974, the 6800 came out. That showed that our lead that was a year and a half was cut down by nine months. It was a major blow to me. But still, we maintained the lead.</p><p>... Motorola used a 5 volt process technology that was not ready for prime time, so their chip was very large and very slow. So it was not a match for the 8080, and that was actually what allowed the 8080 to gain market acceptance, despite the fact that, in my opinion, the 6800 had a better architecture. It was a more regular architecture. It did not suffer from this patch over the 8008 that the 8080 represented, and it had a better addressing mode. It was a nicer machine.</p></blockquote><p>At introduction the 6800 was 29mm^2 and could only run at 1 MHz when compared to the 8080’s 20 mm^2 die size and ‘up to 2 MHz’ clock frequency.</p><p>Still, even if the 5 volt process wasn't quite ready, the simplicity of the design gave Motorola a key advantage. </p><p>And the new Motorola family of chips was very capable. When the 6800 launched, the marketing material placed a lot of emphasis on the capabilities of the 6800 family of chips (known as the M6800 family) and on the communications capabilities of the family.</p><blockquote><p>The M6800 family is the first LSI family designed as a coherent modular building block approach to the implementation of microcomputer systems. From the deceptively powerful MC6800 Microprocessor to the byte-organized family memories, to the capability expanding peripheral and communications interface adapters, the M6800 family plays together as the total product solution for microcomputer designs.</p></blockquote><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45f7622c-bad6-4abf-bac0-971764d24495_1558x1080.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45f7622c-bad6-4abf-bac0-971764d24495_1558x1080.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45f7622c-bad6-4abf-bac0-971764d24495_1558x1080.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45f7622c-bad6-4abf-bac0-971764d24495_1558x1080.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45f7622c-bad6-4abf-bac0-971764d24495_1558x1080.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45f7622c-bad6-4abf-bac0-971764d24495_1558x1080.jpeg" width="1200" height="831.5934065934066" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/45f7622c-bad6-4abf-bac0-971764d24495_1558x1080.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;large&quot;,&quot;height&quot;:1009,&quot;width&quot;:1456,&quot;resizeWidth&quot;:1200,&quot;bytes&quot;:610120,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45f7622c-bad6-4abf-bac0-971764d24495_1558x1080.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45f7622c-bad6-4abf-bac0-971764d24495_1558x1080.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45f7622c-bad6-4abf-bac0-971764d24495_1558x1080.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45f7622c-bad6-4abf-bac0-971764d24495_1558x1080.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Motorola Advert for the M6800 family from the April 1975 Edition of Electronics magazine</figcaption></figure></div><p>One notable feature of the M6800 family at launch was the quality of the documentation for the chips. Motorola’s 700 page manual for the system even showed how to use the 6800 family to create a complete ‘Point-of-Sale’ terminal.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F182f43e7-b30f-4661-b2c1-bedaf6cb5a83_1296x1506.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F182f43e7-b30f-4661-b2c1-bedaf6cb5a83_1296x1506.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F182f43e7-b30f-4661-b2c1-bedaf6cb5a83_1296x1506.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F182f43e7-b30f-4661-b2c1-bedaf6cb5a83_1296x1506.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F182f43e7-b30f-4661-b2c1-bedaf6cb5a83_1296x1506.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F182f43e7-b30f-4661-b2c1-bedaf6cb5a83_1296x1506.jpeg" width="1200" height="1394.4444444444443" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/182f43e7-b30f-4661-b2c1-bedaf6cb5a83_1296x1506.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;large&quot;,&quot;height&quot;:1506,&quot;width&quot;:1296,&quot;resizeWidth&quot;:1200,&quot;bytes&quot;:125644,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F182f43e7-b30f-4661-b2c1-bedaf6cb5a83_1296x1506.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F182f43e7-b30f-4661-b2c1-bedaf6cb5a83_1296x1506.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F182f43e7-b30f-4661-b2c1-bedaf6cb5a83_1296x1506.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F182f43e7-b30f-4661-b2c1-bedaf6cb5a83_1296x1506.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Layout of a complete ‘transaction terminal’ system using  M6800 family chips</figcaption></figure></div><p>So in the 6800 and the M6800 family, Motorola had a serious contender.</p><p>And it’s clear from the investment that Motorola’s management made in the project that they understood the importance of the 6800. An early 6800 development system was demonstrated to Motorola’s then CEO Bob Galvin, the son of one of the founders of the company.</p><p>It’s all the more surprising then that Motorola’s management should be careless with the team that designed the 6800. So careless, in fact, that their actions would lead to the creation of a new and powerful competitor to their new design. A competitor that would change the course of computing history. We’ll see how this happened in Part 2 of the story of the 6800.</p><p>Unlike the Intel 8080, the 6800 wasn’t based on an existing microprocessor design. The Motorola design team largely had a ‘blank slate’, within the limitations of the technology of the time, so it’s interesting to look at their choices.</p><p>The 6800 design can be contrasted with the 8080. The Intel processor had lots of general purpose registers (A,B,C,D,E,H,L) some of which could be grouped to form 16-bit registers (BC, DE, HL). By contrast the 6800 had just two 8-bit accumulators (A and B) and a 16 bit index register (IX). Unlike the 8080, the 6800 had no 16-bit addition or subtraction.</p><p>The PDP-8 is often quoted as the model for the 6800, but it’s only a very loose model. The PDP-8 was a 12-bit machine, with a single 12-bit general purpose ‘accumulator’.</p><p>Wikipedia has some example 6800 assembly language code which shows off the general style and some of the weaknesses of the 6800. The sample code copies a block of memory from one location to another. The repeated 16-bit loads and stores from memory of the source and destination of the copy (using the index register ix - eg ‘ldx src’ ‘stx src’) is inefficient when compared to an architecture that could keep two memory addresses in registers at the same time. The 6800’s approach contrasts with the relative economy and efficiency of the same task on an Intel 8080, which makes use of the 8080’s multiple 16-bit registers.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe36fabfe-7a4f-4c61-8c47-921f664b15e7_1930x1198.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe36fabfe-7a4f-4c61-8c47-921f664b15e7_1930x1198.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe36fabfe-7a4f-4c61-8c47-921f664b15e7_1930x1198.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe36fabfe-7a4f-4c61-8c47-921f664b15e7_1930x1198.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe36fabfe-7a4f-4c61-8c47-921f664b15e7_1930x1198.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe36fabfe-7a4f-4c61-8c47-921f664b15e7_1930x1198.jpeg" width="728" height="452" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e36fabfe-7a4f-4c61-8c47-921f664b15e7_1930x1198.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;normal&quot;,&quot;height&quot;:904,&quot;width&quot;:1456,&quot;resizeWidth&quot;:728,&quot;bytes&quot;:112542,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe36fabfe-7a4f-4c61-8c47-921f664b15e7_1930x1198.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe36fabfe-7a4f-4c61-8c47-921f664b15e7_1930x1198.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe36fabfe-7a4f-4c61-8c47-921f664b15e7_1930x1198.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe36fabfe-7a4f-4c61-8c47-921f664b15e7_1930x1198.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Memory copy in 6800 assembly </figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87b3dfd7-40ff-4291-9278-27a1f78e7aa8_1748x992.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87b3dfd7-40ff-4291-9278-27a1f78e7aa8_1748x992.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87b3dfd7-40ff-4291-9278-27a1f78e7aa8_1748x992.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87b3dfd7-40ff-4291-9278-27a1f78e7aa8_1748x992.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87b3dfd7-40ff-4291-9278-27a1f78e7aa8_1748x992.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87b3dfd7-40ff-4291-9278-27a1f78e7aa8_1748x992.jpeg" width="1456" height="826" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/87b3dfd7-40ff-4291-9278-27a1f78e7aa8_1748x992.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:826,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:86816,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87b3dfd7-40ff-4291-9278-27a1f78e7aa8_1748x992.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87b3dfd7-40ff-4291-9278-27a1f78e7aa8_1748x992.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87b3dfd7-40ff-4291-9278-27a1f78e7aa8_1748x992.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F87b3dfd7-40ff-4291-9278-27a1f78e7aa8_1748x992.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>… and in 8080 assembly</figcaption></figure></div><p>Despite the lower clock frequency and smaller set of registers, there were ways in which the 6800 would outperform the 8080.&nbsp;</p><p>A simple instruction to load an 8-bit constant into the accumulator  (‘MVI A, #FF’ in 8080 assembly language) would take 7 clock cycles in the 8080, whereas the corresponding instruction (“LDA A #FF” in 6800 assembly language) took just two clock cycles, meaning that even at half the ‘clock speed’ the 6800 would execute this instruction almost twice as quickly.</p><p>The 6800 also had some useful addressing modes. The indexed mode would add an 8-bit constant to the 16-bit index register to form a new 16-bit address, which could be used as a source for a load or an arithmetic, logic or compare instruction. Thus a single two byte instruction could perform an ‘add’ to create a new memory address and perform an arithmetic operation and all in just five clock cycles.</p><p>On paper the 6800 may have looked like it was, as Intel’s Faggin said, ‘very slow’, but Motorola would argue that it was ‘deceptively powerful’. The rivalry between 8080 derived and 6800 style designs would be a feature of the microcomputer market over the next decade.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA['Like we were lesser humans': Gaza boys, men recall Israeli arrest, torture (577 pts)]]></title>
            <link>https://www.aljazeera.com/features/2023/12/12/like-we-were-lesser-humans-gaza-boys-men-recall-israeli-arrests-torture</link>
            <guid>38616550</guid>
            <pubDate>Tue, 12 Dec 2023 18:50:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.aljazeera.com/features/2023/12/12/like-we-were-lesser-humans-gaza-boys-men-recall-israeli-arrests-torture">https://www.aljazeera.com/features/2023/12/12/like-we-were-lesser-humans-gaza-boys-men-recall-israeli-arrests-torture</a>, See on <a href="https://news.ycombinator.com/item?id=38616550">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-live="polite" aria-atomic="true"><p><strong>Deir el-Balah, Gaza Strip –</strong> Inside one of the rooms of Al-Aqsa Martyrs Hospital, Mahmoud Zindah stays close to his father, Nader, the horrors of the past week etched on both of their faces. Their eyes are wide, darting around.</p>
<p>The 14-year-old and his father were among hundreds of Palestinians rounded up on December 5 by Israeli forces in the Shujayea area, east of Gaza City, who endured five days of torture and degradation before they were released – without any explanation.</p>
<p>“One of the soldiers said I looked like his nephew and that this nephew was killed in front of his grandmother who was taken hostage by Hamas and that the soldiers will slaughter us all,” Mahmoud says, his voice trembling.</p>
<p>Before their ordeal, the Zindah family was trapped in their home in the Zeitoun neighbourhood of Gaza City for two days, unable to leave as tanks advanced and artillery shelling got closer and closer. Those who dared to leave their homes for whatever vital errand were shot down in the streets by snipers.</p>
<p>On the third day, the family, who slept on the cold tile floor under mattresses to shield them from potential flying shrapnel, woke up to find the tanks on their street.</p>
<figure id="attachment_2549574" aria-describedby="caption-attachment-2549574"><img loading="lazy" src="https://www.aljazeera.com/wp-content/uploads/2023/12/1E3A0077-1702307776.jpg?w=770&amp;resize=770%2C513" alt="Mahmoud and Nader Zindah recall their experience of arrest and torture by Israeli forces " data-recalc-dims="1"><figcaption id="caption-attachment-2549574">Mahmoud and Nader Zindah recall their arrest and torture by Israeli forces [Abdelhakim Abu Riash/Al Jazeera]</figcaption></figure>
<p>“We heard the soldiers shouting and the tank tracks getting louder,” Nader, 40, says. “I felt like there was something wrong, so I went to the house behind me, which was farther from the street. Before I reached it I stopped in shock. The house was moving!</p>
<p>“Then I realised that the Israeli bulldozer was knocking its walls down” and soldiers were firing live ammunition as well, he adds.</p>
<p>Nader quickly tore some white sheets into small “flags” for each of his eight children to carry. They poked one out of their front door, as the adults shouted that there were people in the house. The bulldozer stopped, as did the shooting. But suddenly the home was full of Israeli soldiers.</p>
<p>“They made us empty out our bags on the floor and blocked us from picking up our money or our wives’ gold,” Nader recalls. “What little food we had, they also threw away. They took our money, IDs and phones.”</p>
<p>The soldiers divided the household: women and young children in one room and the men and teenage boys in another. Then they told Nader, Mahmoud, his brother-in-law and another male relative to strip, then pushed them outside.</p>
<p>“They rounded up at least 150 men from the surrounding homes and blindfolded and handcuffed us all in the street,” Nader explains.</p>
<figure id="attachment_2549568" aria-describedby="caption-attachment-2549568"><img loading="lazy" src="https://www.aljazeera.com/wp-content/uploads/2023/12/1E3A0100-2-1702307644.jpg?w=770&amp;resize=770%2C513" alt="Mohammed Odeh, 14, was separated from his family and taken with at least 150 other men and teenage boys to a rice warehouse by Israeli forces where he faced torture for several days " data-recalc-dims="1"><figcaption id="caption-attachment-2549568">Mohammed Odeh, 14, was separated from his family and taken with at least 150 other men and teenage boys to a rice warehouse by Israeli forces where he faced torture for several days [Abdelhakim Abu Riash/Al Jazeera]</figcaption></figure>
<p>When the soldiers forced the men onto the backs of some trucks, Nader made sure Mahmoud was on his lap, terrified of what they would do to his son if they were separated.</p>
<p>“I don’t want to lose my child, nor do I want my son to lose his father,” he says.</p>
<p>The men quickly realised that there were also women in the truck, which kept braking suddenly, sending the prisoners falling on top of each other.</p>
<p>“We were all blindfolded, so we couldn’t see each other, but we heard the women telling us to look out for them like we would for our own sisters,” Nader says. “There were also younger children with them.”</p>
<p>The truck stopped, and once again, the men and women were separated. The men and teenage boys were taken to a warehouse where they sat on a bare floor covered in scattered grains of rice. There they were beaten, interrogated and verbally abused. There was no sleep, and the grains of rice cut their skin as they sat there, undressed.</p>
<h2 id="starved-and-beaten-for-days">Starved and beaten for days</h2>
<p>Mohammed Odeh, 14, was taken from the same Wadi al-Arayes neighbourhood in Zeitoun as the Zindahs, where he and his family were stuck in their homes for five days, starving.</p>
<figure id="attachment_2549588" aria-describedby="caption-attachment-2549588"><img loading="lazy" src="https://www.aljazeera.com/wp-content/uploads/2023/12/1E3A0107-1702307940.jpg?w=770&amp;resize=770%2C513" alt="Israeli soldiers released about 10 men they had arrested last Tuesday " data-recalc-dims="1"><figcaption id="caption-attachment-2549588">Israeli soldiers released about 10 men they had arrested on December 5, 2023 [Abdelhakim Abu Riash/Al Jazeera]</figcaption></figure>
<p>Two of the neighbourhood boys who left to look for water were killed on the street by Israeli snipers. After the bulldozer knocked down the walls of several homes, the soldiers dragged the men and teenagers out, slapping, punching and hitting them with their guns.</p>
<p>“There was no reasoning with them,” Mohammed recalls. “They kept saying, ‘You are all Hamas.’ They wrote numbers on our arms. My number was 56.” When he stretches his arms out, the red marker is still visible on his skin.</p>
<p>“When they spoke to us in Hebrew and we wouldn’t understand, they’d beat us up,” he continues.</p>
<p>“They hit me in the back where my kidneys are and my legs. They took my family, and I don’t know where they are,” he says, his voice breaking.</p>
<p>Before they were forced inside the warehouse, Israeli female soldiers came and spat on the men, Mohammed recalls.</p>
<p>In the warehouse, it was common for groups of five soldiers to suddenly enter and beat one person while the others were forced to listen to his screams of pain. If any of the men and teenagers nodded off from exhaustion, the soldiers poured cold water on them.</p>
<p>“Their contempt for us was unnatural, like we were lesser beings,” Mohammed says.</p>
<figure id="attachment_2549558" aria-describedby="caption-attachment-2549558"><img loading="lazy" src="https://www.aljazeera.com/wp-content/uploads/2023/12/1E3A0175-2-1702307496.jpg?w=770&amp;resize=770%2C513" alt="One of the Palestinian men arrested and tortured for days by Israeli soldiers shows the number he was marked by, and his swollen hand from the handcuffs " data-recalc-dims="1"><figcaption id="caption-attachment-2549558">One of the Palestinian men arrested and tortured for days by Israeli soldiers shows the number he was marked with and his swollen hands from the handcuffs [Abdelhakim Abu Riash\Al Jazeera]</figcaption></figure>
<p>“Some people didn’t return from the torture sessions,” Nader says darkly. “We would hear their screams and then nothing.”</p>
<p>At one point, Mahmoud told his father that his wrists were bleeding from the handcuffs. A soldier overheard, asked where it hurt and then proceeded to press down on the spot. Nader tried to shield his son, and one of the soldiers tried to drag the teenager away. When Mahmoud resisted, he was kicked in the face. The mark is still visible.</p>
<p>“My dad kept shouting at them that I’m a child and threw himself on top of me,” he says. “I heard a soldier speaking in an American accent, and I told him in English that I’m just a kid that goes to school.” Their words fell on deaf ears.</p>
<p>Blindfolded and handcuffed the entire time, the men and boys endured hours of beatings.</p>
<p>“They cursed at us, spewing the most foul language,” says Nader, who suffered a particularly painful blow to his head. “Some of them spoke Arabic. Every time you tried to talk, asking to go use the bathroom or wanting a drink of water, they would come and beat us up, using the butts of their M16 rifles.”</p>
<p>The soldiers interrogated them and threatened to kill them all. They accused the Palestinians of stealing their army jeeps and raping Israeli women. When they asked Mahmoud where he was on October 7 and he answered that he was sleeping at home, the soldiers hit him, he says.</p>
<p>“They have this unbelievable racism. They really hate us,” Nader says. “This isn’t about Hamas. This is about wiping us all out. This is about a genocide, signed off by [US President] Biden.”</p>
<p>The men were given only a few drops of water and some scraps of bread to eat. Some were forced to relieve themselves on the spot while others were handed a foul-smelling bucket.</p>
<p>On the fifth day, Saturday, Nader, Mahmoud, and 10 other men were taken to Nitzarim, a former settlement south of Gaza City that had been turned into farmland after the 2005 Israeli disengagement. It is now an Israeli checkpoint just before Wadi Gaza and the men were released there and told to head south.</p>
<p>The group took off their blindfolds and let their eyes adjust to the light after days of darkness. They were exhausted and hungry and still did not have any clothes. After walking painfully for two hours, a group of Palestinians spotted them.</p>
<p>“They clothed us and gave us water,” Nader says. “An ambulance was called, and we arrived at Al-Aqsa Martyrs Hospital, where we were immediately given IV fluids.”</p>
<p>“I thought I didn’t have a chance of getting out alive,” he adds.</p>
<p>“It was hell on earth. It was like spending five years in that warehouse. I wouldn’t wish this on anyone.”</p>
<p><span><iframe loading="lazy" width="770" height="434" src="https://www.youtube.com/embed/EXfn-BCTBNc?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-US&amp;autohide=2&amp;wmode=transparent" allowfullscreen=""></iframe></span></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zero downtime Postgres upgrades (272 pts)]]></title>
            <link>https://knock.app/blog/zero-downtime-postgres-upgrades</link>
            <guid>38616181</guid>
            <pubDate>Tue, 12 Dec 2023 18:22:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://knock.app/blog/zero-downtime-postgres-upgrades">https://knock.app/blog/zero-downtime-postgres-upgrades</a>, See on <a href="https://news.ycombinator.com/item?id=38616181">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong>👋&nbsp;We’re Knock. We provide a set of simple APIs developers use to introduce
notifications into their products, without needing to build and
maintain a notification system in-house.</strong></p>
<div><p><strong>Tl;dr:</strong> We recently upgraded from Postgres 11.9 to 15.3 with
zero downtime by using logical replication, a suite of support scripts,
and tools in Elixir &amp; Erlang’s BEAM virtual machine.</p><p>This post will go into far too much detail explaining how we did it,
and considerations you might need to make along the way if you try to do the same.</p><p>It is more of a manual than anything, and includes things we learned along the
way that we wish we’d known up front.</p></div>
<p>Knock relies on Postgres to power our notification workflow engine. From storing
workflow configurations and message templates, to <a href="https://knock.app/blog/how-we-use-postgres-ltrees">ingesting millions of logs</a>
and <a href="https://getoban.pro/">enqueuing background jobs</a>, Postgres sits at the heart of everything our systems do.
Our Postgres databases running on AWS RDS Aurora have been consistently reliable,
performant, and extensible. This foundation to Knock’s service lets us support
with confidence every customer that joins our platform.</p>
<p>Unlike SaaS software that can be constantly upgraded in the background with little notice,
upgrading relational databases like Postgres generally requires at least a reboot of the database.
In the case of major version upgrades, the database often needs to shut down completely for several minutes
in order to upgrade how data is stored and indexed on disk.</p>
<p><strong>The more data you have, the longer the upgrade will take.</strong></p>
<p>In Knock’s case, we have been running Postgres 11.9 since we started the company.
Although it has reliably served us at every step along the way,
<a href="https://docs.aws.amazon.com/AmazonRDS/latest/PostgreSQLReleaseNotes/postgresql-release-calendar.html#Release.Calendar">Postgres 11.9 is being retired by Amazon’s RDS service on February 29, 2024</a>.
Without taking action (i.e. arranging a long-term support contract with RDS),
teams that use Postgres 11.9 on AWS RDS will be forcibly upgraded at that point,
likely resulting in forced downtime.</p>
<p>No amount of downtime - scheduled or otherwise - is acceptable for a service like Knock.
Our customers rely on us to be online 24/7. Although no service can guarantee
perfect uptime, responsible developer teams work to proactively address service
issues before they happen.</p>
<p>We added this upgrade to our roadmap in June of this year, with the following constraints:</p>
<ol>
<li>Upgrade as many versions ahead as possible, skipping to the latest available version (at the time, Postgres 15.3 for Aurora).</li>
<li>Any downtime beyond 60 seconds was completely unacceptable, and ideally we would have zero system downtime.</li>
<li>The upgrade must happen well in advance of Amazon’s February deadline.</li>
<li>Minimize customer impact (e.g. zero API error responses).</li>
<li>Operationalize the process so that next time we need to upgrade the database, it is a well-established runbook.</li>
</ol>
<p>Each of our Postgres databases would need to run through this process, and going
from 11.9 to 15.3 would comprise <strong>four</strong> major version upgrades. If doing an
in-place upgrade for each major version would trigger downtime, doing <strong>four</strong>
in a row was out of the question.</p>
<p>In order to meet our requirements, we knew we’d have to get creative.</p>
<h2 id="preparing-for-any-postgres-upgrade">Preparing for any Postgres upgrade</h2>
<p>More than anything, teams seeking to upgrade Postgres in any way should focus on
<strong>de-risking</strong> the upgrade process as much as possible:</p>
<ol>
<li>
<p>Make a list of the risks involved in making the migration. For example:</p>
<ul>
<li>Unacceptably long downtime</li>
<li>Data loss</li>
<li>Changes in database performance for your application’s workload</li>
<li>Changes in vacuum frequency or behavior</li>
<li>Are there any replication slots that need to be migrated (this can be tricky - <a href="#a-note-about-moving-replication-slots">see below</a>)</li>
</ul>
</li>
<li>
<p>Figure out which risks are the most critical to the project, and which ones
might be the easiest to explore/rule out/fix in advance.</p>
<p>Sort the list so the risks with the biggest impact yet easiest to address are at the top.</p>
</li>
<li>
<p>As you develop solutions, consider your list of risks:</p>
<ul>
<li>Are there solutions that rule out risks completely?</li>
<li>Which solutions spread out the risk over time? (So we can more gradually
address each step of the migration without taking on too much risk at once.)</li>
</ul>
</li>
<li>
<p>As you work through the project, always revisit your list of risks,
and keep it up to date as you learn new things - including discovering new risks!</p>
<div><p><strong>Incrementally and continually de-risk projects like this until you are
confident in being able to deliver on your project goals.</strong></p></div>
</li>
</ol>
<p>To plan out our upgrade, we started with <a href="https://www.postgresql.org/docs/release/">Postgres’ release notes</a>
to get a sense of what was going to change between database versions.
This helped us identify more risks (e.g. changes in how Postgres’ vacuum works,
requirement to reindex the database when performing certain upgrades) while ruling out others.</p>
<p>As we moved through our planning process, we maintained this list of risks,
adding new concerns and updating old ones as we collected more information.
While working through the upgrade, we systematically addressed each concern
until we were confident we could deliver on our project goals without
risking our reliability.</p>
<h3 id="a-word-about-monitoring--metrics">A word about monitoring &amp; metrics</h3>
<p>Having thorough instrumentation (thanks DataDog!) to monitor the health of your
system and database makes it possible to monitor each step of the migration.</p>
<p>A few key metrics to watch:</p>
<ul>
<li>Max TXN ID to avoid <a href="https://www.crunchydata.com/blog/managing-transaction-id-wraparound-in-postgresql">transaction wraparound</a> - if this gets too high, your database can shut down and go into emergency maintenance mode</li>
<li>DB CPU Utilization</li>
<li>Waiting sessions on your writer instance</li>
<li>Query latency</li>
<li>API response latencies for your application</li>
</ul>
<p>At Knock, we monitor all of these metrics as well as some that are unique to our application,
like the time it takes to turn an API request into a notification.</p>
<p><strong>Without timely metrics, you’re flying blind.</strong></p>
<h2 id="options-for-upgrading-postgres">Options for upgrading Postgres</h2>
<p>Part of our research process included looking for <a href="https://retool.com/blog/how-we-upgraded-postgresql-database">prior examples</a>
of database migrations and <a href="https://www.postgresql.org/docs/current/pgupgrade.html">how the Postgres docs</a>
recommend performing an update. Here are a few strategies:</p>
<h3 id="in-place-upgrades-a-non-starter-for-zero-downtime-upgrades">In-place upgrades (a non-starter for zero-downtime upgrades)</h3>
<p>The most basic upgrade option for Postgres is an in-place upgrade.
On AWS RDS, this upgrade is executed from the AWS console. When performing an
in-place upgrade, AWS will shut down the database, run upgrade scripts, and then
bring the system back online. Doing this often requires some preparation,
including dropping Postgres replication slots,
like those used to synchronize with a data warehouse or other systems.</p>
<p>This in-place upgrade process can take anywhere from a few minutes to potentially
hours or more - it entirely depends on how much data needs to be updated
between Postgres versions.</p>
<p>Often, the system is still not in a fully usable state when it comes online, and
administrators must run maintenance tasks like Postgres’ <code>VACUUM</code> command,
or <code>REINDEX</code> to update indexes to support the new version’s format.</p>
<p><strong>Because an in-place upgrade would require far more downtime than we wanted to
tolerate, it was out of the question for us.</strong></p>
<p>A similar approach to an in-place upgrade is to use <code>pg_dump</code> and <code>pg_restore</code>
to transfer the contents of a database once it has shut down.
This <a href="https://www.postgresql.org/docs/current/app-pgdump.html">dump &amp; restore</a>
approach would also not work for us due to the required downtime involved,
mostly because you need to disconnect all applications from the old database in
order to get a reliable database backup. Even then, for large databases, it can
take prohibitively long to dump and restore the database.</p>
<h3 id="replication-based-upgrades">Replication-based upgrades</h3>
<p>This approach relies on Postgres’ excellent replication primitives:
the <code>PUBLICATION</code> and the <code>SUBSCRIPTION</code>.</p>
<p>It works something like this:</p>
<ol>
<li>Spin up a new database on your target Postgres version</li>
<li>Copy over settings, extensions, table configurations, users, etc.</li>
<li>Set up a publication on the old database and a subscription to that publication on the new database</li>
<li>Add your tables to the publication (there is a lot of nuance here - <a href="#choosing-tables-to-replicate">more below</a>)</li>
<li>Once it's fully replicated, run tests to satisfy any remaining risks</li>
<li>Once you are confident in the new database's configuration, point your application at the new database</li>
<li>Tear down the old database</li>
</ol>
<p><strong>In the end, this is the option that we chose at Knock for a few reasons:</strong></p>
<ol>
<li>It gave us gradual steps we could take towards a migration instead of one big upgrade</li>
<li>We could test the new database with real workloads and real data to avoid any regressions</li>
<li>It gave us the most control over when and how to perform the upgrade:
once the new database was fully ready, cutting over to the new database took just a few seconds</li>
</ol>
<p>Although that may sound straightforward, there are several points to consider in
this solution that will depend on your application &amp; circumstances.</p>
<p><strong>Configuring your source and destination databases</strong></p>
<p>Publications and subscriptions depend on a few configuration parameters for
setting up replication slots (how the database keeps track of what needs to be
copied from the primary to the follower database).
<a href="https://www.postgresql.org/docs/16/logical-replication-config.html">The Postgres docs</a>
have plenty of detail on these parameters. These parameters will need to be
tuned for your particular application. For simple applications, the only change
necessary is that <code>wal_level</code> should be set to <code>logical</code>.</p>
<p>If you already use replication slots (e.g. to manage a read replica,
database failover, or to keep a data warehouse in sync), then consider setting
<code>max_replication_slots</code> and the other parameters according to the guidance in the docs.</p>
<p><strong>Setting up basic replication</strong></p>
<ol>
<li>
<p>Start a new Postgres server on your target version of Postgres (in our case v15.3).</p>
</li>
<li>
<p>Set up your desired databases, schemas, tables, partitions, users &amp; passwords, and everything else.</p>
<p><strong>The target database’s tables must have an identical structure to the
source database, but these tables must be empty.</strong></p>
<p>To get a snapshot of the database schema, run <a href="https://www.postgresql.org/docs/current/app-pg-dumpall.html"><code>pg_dumpall</code></a>
on the old DB (pass the <code>--schema-only</code> and <code>--no-role-passwords</code> options to
keep it focused), and then adapt that command for the new DB. You can then
compare the generated SQL files to identify and fix discrepancies between the
old and the new DB.</p>
<p>It may be worth periodically comparing both databases to detect any drift,
especially if you have schema migrations happening in the source database.
Consider running migrations against both databases to keep them in sync.</p>
</li>
<li>
<p>On the primary instance of the <strong>old</strong> database, run <code>CREATE PUBLICATION pg_upgrade_pub;</code>.</p>
<div><p>Although you can tack on <code>FOR ALL TABLES</code> and that will set up the publication
for every table, we found that for large databases, this can lead to performance problems.</p><p>Instead, we found it worked much better to incrementally add one table
at a time to the publication via <code>ALTER PUBLICATION pg_upgrade_pub ADD TABLE table_name</code>.
More on this <a href="#choosing-tables-to-replicate">below</a>.</p></div>
</li>
<li>
<p>On the primary instance of the <strong>new</strong> database, set up the new subscription pointing to that publication:</p>

<p>At this point, you now have a replication pipeline
from the old database to the new one.</p>
<p>To enable the subscription:</p>

</li>
</ol>
<h3 id="choosing-tables-to-replicate">Choosing tables to replicate</h3>
<p>The next step in the process is to build a list of tables you’d like to replicate.
You will want to add tables one at a time, watching each table until all of them
are fully replicated. Later in this post we will show you <a href="#checking-a-tables-replication-status">how to monitor replication
for all the tables</a>.</p>
<p>Generally, the tables will fall into three based on their disk size and the
number of tuples stored in the database.</p>
<ol>
<li>Small enough to synchronize in a few minutes: These can be replicated by just
adding them to the publication and refreshing the subscription</li>
<li>Large, append-only tables: These can be synchronize by first replicating only
future changes, and then separately backfilling old data from a backup or snapshot</li>
<li>Large, frequently updated tables: These are the hardest to synchronize, and
will require some extra care</li>
</ol>
<p>For us, "small" was any table using less than 50 GB of storage and 10 million tuples.</p>
<p>Anything over those thresholds we considered "large".</p>
<div><p><strong>What is a tuple?</strong></p><p>Each insert or update to a Postgres table is stored as a "tuple". If a table has
3 inserts followed by 2 updates, the table would have 5 tuples. Tuples are used
by Postgres’ concurrency mechanism (<a href="https://www.postgresql.org/docs/16/mvcc-intro.html">more in the docs</a>).
Postgres’ <code>VACUUM</code> procedure cleans up old tuples that are no longer needed.</p><p>When we replicate a table, we replicate all of the tuples that make up the
tables contents - inserts and updates. A table with a few rows but many tuples
that haven’t been cleaned up will take longer to replicate than a similar table
with fewer tuples.</p></div>
<p>The following query can help determine the size of a database table in terms of
disk space and tuple counts:</p>

<p>One way to prepare your source database for replication is to <code>VACUUM</code> your tables,
which should help the source database reduce the number of tuples it needs to copy
to the target database. This can help reduce the amount of time it takes to replicate a table.</p>
<p>Before using <code>VACUUM</code>, consult the <a href="https://www.postgresql.org/docs/current/sql-vacuum.html">Postgres docs</a>.</p>
<div><p><strong>Why does table size matter?</strong></p><p>The time it takes to synchronize a table is directly correlated to its size on disk
and the number of tuples it contains. The larger the table, the longer it takes to replicate.
This is because Postgres needs to copy the entire table over to the new database,
and then apply any changes that happen after the initial copy.</p><p>The problem with long synchronization time is that it can prevent your primary
Postgres instance from performing <code>VACUUM</code> operations, which can lead to degraded
performance over time. Left unchecked, it can even lead to transaction wraparound
and a forced shutdown of the database.</p><p>For these reasons, we added tables one at a time to replication, used different
strategies based on the size &amp; write patterns of each table, and closely monitored
the system’s performance to ensure we didn’t degrade our service.</p><p>If migrating a table becomes problematic, you can remove a table from replication
at any time, and then re-add it later (although you will need to truncate the
target table and start from scratch).</p></div>
<h3 id="how-to-replicate-small-tables">How to replicate "small" tables</h3>
<p>To migrate small tables, you just add it to the publication and then refresh the subscription:</p>

<p>Postgres will handle copying the table over, getting it synchronized, and
applying any further operations to the table. For very small tables,
synchronization can happen in less than a second.</p>
<h3 id="large-append-only-tables">Large, append-only tables</h3>
<p>Tables that are too large but generally append-only, with no updates (or, if
updates are <em>always</em> on rows that are recent, like within the past week),
then you can set up a separate <code>PUBLICATION</code> and <code>SUBSCRIPTION</code> following the
same steps as above, but setting the <code>copy_data</code> option on the subscription to
false. Suffix the name of the new publication and new subscription with <code>_nocopy</code>
to make it distinct.</p>
<p>When you are ready to migrate these large, append-only tables, you can add them
to this <code>nocopy</code> publication, and refresh the subscription on the target using
the <code>copy_data = false</code> option:</p>

<p>We found this approach worked really well for our partitioned tables that stored
various types of logs for our customers.
We did not need to migrate the root of a partitioned table, we only migrated the
underlying tables, and that seemed to work pretty well.</p>
<p>Once the subscription is running, you should start seeing logs appear on the
target databases table:</p>

<p>From here, you can backfill any records older than those now visible in the
database using whatever means you like (e.g. <code>pg_dump</code>).</p>
<p>Here is how we did it on AWS RDS Aurora:</p>
<ol>
<li>
<p>Take a snapshot of your production database in the AWS Console</p>
</li>
<li>
<p>Restore that snapshot into a new database instance (the snapshot DB)</p>
</li>
<li>
<p>Rename the table(s) on the snapshot DB that you want to replicate by adding
a suffix like <code>_snapshot</code>. This prevents us having two replication pipelines
feeding into the same table on the target database.</p>
</li>
<li>
<p>Create the same table(s) on the target database with the same schema as the
snapshot database. Use the same suffix as above.</p>
</li>
<li>
<p>Create a publication on the snapshot database and a subscription on the target
database to replicate these snapshot table(s) from the snapshot database to the
target database</p>
</li>
<li>
<p>Enable the subscription and monitor its progress</p>
</li>
<li>
<p>Once the subscription is caught up, you can merge the tables together using
<code>INSERT...ON CONFLICT</code>:</p>

</li>
</ol>
<p><span><span></span><img alt="Diagram showing how to backfill data from a snapshot" loading="lazy" decoding="async" data-nimg="responsive" sizes="100vw" srcset="https://knock.app/_next/image?url=%2Fassets%2Fblog%2Fzero-downtime-postgres-upgrades%2Fsnapshot-backfill.png&amp;w=640&amp;q=75 640w, https://knock.app/_next/image?url=%2Fassets%2Fblog%2Fzero-downtime-postgres-upgrades%2Fsnapshot-backfill.png&amp;w=750&amp;q=75 750w, https://knock.app/_next/image?url=%2Fassets%2Fblog%2Fzero-downtime-postgres-upgrades%2Fsnapshot-backfill.png&amp;w=828&amp;q=75 828w, https://knock.app/_next/image?url=%2Fassets%2Fblog%2Fzero-downtime-postgres-upgrades%2Fsnapshot-backfill.png&amp;w=1080&amp;q=75 1080w, https://knock.app/_next/image?url=%2Fassets%2Fblog%2Fzero-downtime-postgres-upgrades%2Fsnapshot-backfill.png&amp;w=1200&amp;q=75 1200w, https://knock.app/_next/image?url=%2Fassets%2Fblog%2Fzero-downtime-postgres-upgrades%2Fsnapshot-backfill.png&amp;w=1920&amp;q=75 1920w, https://knock.app/_next/image?url=%2Fassets%2Fblog%2Fzero-downtime-postgres-upgrades%2Fsnapshot-backfill.png&amp;w=2048&amp;q=75 2048w, https://knock.app/_next/image?url=%2Fassets%2Fblog%2Fzero-downtime-postgres-upgrades%2Fsnapshot-backfill.png&amp;w=3840&amp;q=75 3840w" src="https://knock.app/_next/image?url=%2Fassets%2Fblog%2Fzero-downtime-postgres-upgrades%2Fsnapshot-backfill.png&amp;w=3840&amp;q=75" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p>
<p>For very large tables, this can still take several days, but because it’s all
in the background it shouldn’t affect your production environment.</p>
<p>Once the tables are fully merged, compare them to ensure a consistent row count
(more on that later). Once you are confident the tables are identical,
drop the snapshot table on the target DB, drop the subscription to the snapshot DB,
and terminate the snapshot database instance.</p>
<h3 id="large-tables-with-many-updates-over-most-of-the-rows">Large tables with many updates over most of the rows</h3>
<p>These are the hard tables. Because they have so much data in them, they can
take a long time to replicate, which can affect system performance on the
source database if it prevents <code>AUTOVUACUUM</code> from running. Because they have
so many updates, we can’t treat it as an append-only table.</p>
<p>A few points to consider:</p>
<ol>
<li>Is there any housekeeping you can do to reduce the table’s size?</li>
<li>Have you vacuumed the table recently?</li>
<li>Can you partition the table into smaller pieces?</li>
<li>Do rows stop receiving updates after a reliable time frame (e.g. 1 week?) -
this could be used to treat the table as an append-only table, and then after
that time frame has elapsed you can backfill old rows from a snapshot.</li>
</ol>
<p>If your source database is not on PG 15 or greater, your options are limited.
Follow the steps in the "small tables" section. Rely on the monitoring you have
in place (you do have monitoring, right?) to ensure replication doesn’t degrade
your service. If needed, you can rollback by removing the table from the
publication, and refreshing the subscription (<a href="#aborting-the-replication-of-one-table">See below</a>).</p>
<p>If the table is still too big, try to start replication during low traffic times to
reduce load and write activity. This will hopefully minimize the impact on your
system.</p>
<h3 id="large-tables-coming-from-pg-15-or-greater">Large tables coming from PG 15 or greater</h3>
<p>If your source database is on PG 15 or greater, you may be able to split up replication
across multiple publications (similar to partitioning or sharding). You can then
migrate the table in smaller chunks, at the expense of using more replication
slots. <a href="https://www.postgresql.org/docs/16/logical-replication-config.html">The Postgres docs</a>
have more information on setting these parameters.</p>
<div><p>Because we migrated from 11.9 to 15.3, we did not have this option available
to us. As such, we have not tested this approach. Even so, as we considered
our options we noticed that this approach might be possible. If you try it
out, let us know, we’d love to hear how it goes!</p></div>
<p>The goal is to have enough publications to split your largest table into manageable
pieces (for us, this was about 100 GB of non-index data stored). We’ll assume we
are splitting across three partitions in this example. The trick is adding a <code>WHERE</code>
clause that splits up the rows handled by each subscription:</p>

<p>On the destination database, create a subscription for each partition.</p>
<p>You only want to migrate one slice of each table at a time. Generally, you will
follow the same instructions as adding a "small" table, but with the extra <code>WHERE</code>
clause added when setting up the table for each publication.</p>
<p>In this way, you can slice up large tables into smaller, more workable pieces.</p>
<p>Consider only using this approach if having too many replication slots is a
problem: you can still add "small" tables using this approach,
just add the table to the <code>_0</code> publication without a <code>WHERE</code> clause.
This can help reduce the number of replication slots required when migrating.</p>
<h3 id="checking-a-tables-replication-status">Checking a table’s replication status</h3>
<p>When a table is added to a subscription, it moves through five distinct states
(visible on the target database under the system table <code>pg_subscription_rel</code>
in the <code>srsubstate</code> column):</p>
<ol>
<li>Initializing the table’s subscription (State code <code>i</code> )</li>
<li>Copying the table’s contents in one efficient operation (State code <code>d</code>)</li>
</ol>
<div><p>This step requires keeping old Postgres transaction IDs around, which
prevents vacuum from running effectively and can lead to system performance
issues and (if left running long enough) even Postgres transaction ID
wraparound which can halt the system.</p><p>This is the step that requires replicating only one table at a time.</p></div>
<ol start="3">
<li>Copy finished, waiting for final sync (State code <code>f</code>)</li>
<li>Finalizing initial sync (State code <code>s</code>)</li>
<li>Ready and running under normal replication (State code <code>r</code>)</li>
</ol>
<p>In order to prevent the issues found in step 2 above, we found it was necessary
to add one table at a time to replication, and to closely watch the system’s
performance. The worst-case scenario (transaction wraparound) must be avoided.</p>
<p><strong>If you get anywhere close to wraparound, it is better to <a href="#aborting-the-replication-of-one-table">abort the migration</a>
and break it up into smaller pieces.</strong></p>
<p>If we had created our publication using the <code>FOR ALL TABLES</code> option, Postgres
would have started to sync our very large source database all at once,
preventing automatic <code>VACUUM</code> operations from completing necessary maintenance.
We found this to gradually degrade database performance over time,
leading to increased risk to system stability.</p>
<p>Adding one table at a time has the added advantage of allowing teams to
incrementally migrate each table. Replication does come with CPU and other costs
for the source and destination databases. By adding one table at a time,
administrators can control how replication affects the running system.</p>
<h3 id="aborting-the-replication-of-one-table">Aborting the replication of one table</h3>
<p>If you need to halt the replication of a table, you reverse the instructions for
adding the table in the first place:</p>

<p>In an emergency, you can also drop the publications and subscriptions entirely,
and start the process over. Postgres will clean up any replication slots that
were created as part of the publication and subscription, which should relieve
any pressure on the source database.</p>
<div><p>Be advised that if you just disable the subscription without removing the table
from the publication and refreshing the subscription, the source database
will continue to hold onto old transaction IDs, which can lead to transaction
wraparound and a forced shutdown of the database.</p><p>Just disabling the subscription will not resolve any replication-related
performance problems.</p></div>
<h3 id="a-note-about-moving-replication-slots">A note about moving replication slots</h3>
<p>Replication slots in Postgres store a log of database activity that can be
consumed on another database or in another application. Postgres tracks slot
progress using a Log Sequence Number (LSN). LSNs are unique to the primary
Postgres database. This means that if you have a replication slot on your
database (e.g. to copy changes to a data warehouse or as part of your own
application), you will not be able to copy the replication slot's LSN over from
the old database to the new database.</p>
<p>You will need to consult the documentation of the application consuming the
replication slot to decide how to best migrate (e.g. for data warehousing tools,
they may have a way to merge duplicated information between both databases).
If you’re using replication slots as part of your own application, you already
know that you’re on your own to roll your own solution. Having some idempotence
mechanism to deduplicate transactions from the old and the new database will
definitely be helpful.</p>
<h2 id="finalizing-the-migration">Finalizing the migration</h2>
<p>Once you have added all of your tables to publications, and the subscriptions
have caught up on everything, you need to now verify that the tables match.</p>
<p>Unfortunately, eventual consistency (the lag between a write being applied to
the old database and it showing up on the new database) will prevent both
databases from being perfect matches at the same time, you can still count table
rows to make sure you’re close enough to know it’s working.</p>
<p>At Knock, we wrote a script that iterated through each table and asked both
databases to count the total number of rows in each table on the old and new
database, and compared the results. For tables with an <code>inserted_at</code> column, we
filtered to rows older than 10 seconds. This interval is more than enough to
prove that the tables match, with the assumption that the remaining 10 seconds
will replicate across in short order.</p>
<p>You may need to come up with a strategy that fits your application’s needs. We
felt that as long as row counts were accurate within a few seconds, we could
otherwise assume that Postgres replication was reliable.</p>
<p>In a few instances, we also spot-checked the contents of a few tables to ensure
they matched to confirm this assumption. Collecting a random sample of rows from
tables and comparing them between the old and the new database can help verify
that the tables are identical.</p>
<h3 id="application-level-changes">Application-level changes</h3>
<p>Parallel to all of this database work, you may need to change your application
to connect to both databases. When you are finally ready to cut over,
you need a strategy to shift traffic to your new database.</p>
<p>When the final cutover happens, you could change your application’s configuration
to point to the new database, and then reboot your app. This is simple,
straightforward, and is precisely how we migrated one of our
lower-traffic databases.</p>
<p>For applications with lots of concurrent activity, you may need to get creative.
We wanted to avoid a situation with conflicting writes between the old and new
database. Such conflicts could have caused a service outage for us, requiring
manually reconciling database state.</p>
<p>At Knock, we configured our application to connect to both databases.
When we were ready to execute the cutover, we ran a script that did the following:</p>
<ol>
<li>
<p>Tell all instances of our application to send new queries to the new database</p>
</li>
<li>
<p>All currently running database queries had 500 ms to complete before being forcefully cancelled</p>
</li>
<li>
<p>For the first second after flipping the flag, our application artificially paused
any new database requests for one second. This allowed pending transactions
to replicate to the new database so that new queries wouldn’t have stale reads</p>
<p>500 ms is far higher than most of our db queries, and we saw zero errors due to forced disconnections</p>
</li>
<li>
<p>After that first second, database activity returned to normal behavior, but pointing at the new database.</p>
</li>
<li>
<p>In the middle of the cutover, we had some specialized database workloads that
the script shut down and restarted in order to reconnect to the new database.</p>
</li>
</ol>
<h3 id="one-more-thing-sequences">One more thing: sequences</h3>
<p>One thing that replication doesn’t synchronize is any Postgres sequence.
Sequences are monotonically increasing integers that are guaranteed to never
duplicate. Unfortunately, they are not incremented on the new database as
sequence values are used up on the old database.</p>
<p>Fortunately, this is pretty easy to control for. Part of our cutover procedure
was to run a script right before flipping our feature flag that did the following:</p>
<ol>
<li>
<p>Connect to both databases</p>
</li>
<li>
<p>Get the next value of all of the sequences in the database using <code>SELECT nextval('sequence_name')</code></p>
</li>
<li>
<p>Set that value in the new database using <code>SELECT setval('sequence_name', value::int4 + 100000)</code>
to advance the sequence and offer a little bit of buffer (in this case, 100k
rows can be added between setting this value on the new database and cutting over).
This will introduce a gap in the sequence, but that’s generally not a problem.
For us, our sequences are bigints. 100k values skipped in the sequence is a
rounding error off of 0% used up sequence values in that case.</p>
<p>You will want to tune how big of a gap you introduce so you don’t use too
much of your sequence’s usable space. If you only expect the sequence to
use a few hundred values during your cutover window,
then maybe advance it only by 5000.</p>
</li>
</ol>
<h2 id="final-checklist-before-cutting-over">Final checklist before cutting over</h2>
<p>Here are some of the things we considered before executing our final cutover:</p>
<ol>
<li>Do the rows on all the tables match as expected?</li>
<li>Are all the subscriptions enabled and running without error?</li>
<li>Do the schemas match? Can you freeze any new schema migrations from being
released to reduce the risk of something changing while you’re migrating?</li>
<li>Is your new database properly sized for your workloads?</li>
<li>Do you have to add any read replicas so the database cluster topology is the
same between the old and the new database?</li>
<li>Have you reindexed and performed basic VACUUM maintenance on the new database
to ensure it’s fresh and ready for production traffic?</li>
<li>Have you double checked Postgres’ release notes for anything that might cause
a regression in your app?</li>
<li>Have you run automated and manual tests against a staging database on the new
version to verify system performance?</li>
<li>Have you run load tests of your most demanding queries using <code>pg_bench</code>
against your new version to verify performance?</li>
<li>If there’s one thing that you can de-risk still, what is it?</li>
<li>Do practice runs in a staging or test environment until you have fully
exercised the cutover process multiple times. Dry runs like this will help
reveal gaps in your plan before you go to production.</li>
<li>Right before cutover, take a database backup - just in case.</li>
</ol>
<h2 id="cutting-over">Cutting over</h2>
<p>At Knock, we took a few weeks replicating tables one at a time. We generally did
this after business hours and during our lowest traffic time frames. We practiced
cutover in our staging environment multiple times, ironing out the process until
it just worked without much operator involvement.</p>
<p>Once we had a replica running PG 15 and had the application code in place to
cut over from the old to the new database, we ran one final set of checks and
flipped the flag.</p>
<p>After months of preparation, the actual cutover was uneventful: our
application cut over within a few seconds, we had a brief blip of (intentional)
latency as queries waited to allow for replication, and our application
continued running without skipping a beat. Reading this paragraph took longer
than the cutover itself.</p>
<p>From there, we rolled back the application changes we introduced, permanently
pointed everything at the new database, removed the subscriptions on the new
database, and tore down the old database. We had successfully jumped from
Postgres 11.9 to 15.3 with zero downtime!</p>
<h2 id="conclusion">Conclusion</h2>
<p>Although jumping four major versions of Postgres in one leap is a painstaking
process, it can be done, and in many ways it’s safer than scheduled downtime:
it can be practiced, tested, and reworked multiple times before performing the
actual cutover. At any point in the process, we could have dropped the
publications from the old database and started over without degrading our service.</p>
<p>Modern customers expect 100% availability. While that is not technically possible,
zero downtime migrations make it easier to keep systems running smoothly without
major service interruptions.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pharmacies share medical data with police without a warrant, inquiry finds (148 pts)]]></title>
            <link>https://www.washingtonpost.com/technology/2023/12/12/pharmacy-records-police-privacy-abortion/</link>
            <guid>38615841</guid>
            <pubDate>Tue, 12 Dec 2023 18:00:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/technology/2023/12/12/pharmacy-records-police-privacy-abortion/">https://www.washingtonpost.com/technology/2023/12/12/pharmacy-records-police-privacy-abortion/</a>, See on <a href="https://news.ycombinator.com/item?id=38615841">Hacker News</a></p>
Couldn't get https://www.washingtonpost.com/technology/2023/12/12/pharmacy-records-police-privacy-abortion/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[VMware by Broadcom transition to subscription, end of sale of perpetual licenses (236 pts)]]></title>
            <link>https://news.vmware.com/company/vmware-by-broadcom-business-transformation</link>
            <guid>38615315</guid>
            <pubDate>Tue, 12 Dec 2023 17:25:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.vmware.com/company/vmware-by-broadcom-business-transformation">https://news.vmware.com/company/vmware-by-broadcom-business-transformation</a>, See on <a href="https://news.ycombinator.com/item?id=38615315">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><em>By Krish Prasad, Senior Vice President and General Manager, VMware Cloud Foundation Division</em></p><p>Broadcom’s close of the VMware acquisition has brought together two engineering-first, innovation-centric teams to help build the world's leading infrastructure technology company. Together, we are well-positioned to enable global enterprises to embrace private, hybrid and multi-cloud environments. And we are committed to driving customer success through faster innovation, a simpler portfolio and a robust ecosystem.</p><p>Over the past two years, VMware has been on a journey to simplify its portfolio and transition from a perpetual to a subscription model to better serve customers with continuous innovation, faster time to value, and predictable investments.</p><p>Today, VMware by Broadcom has reached a new milestone with the announcement of the following:</p><ul><li>A dramatic simplification of our product portfolio that allows customers of all sizes to gain more value for their investments in VMware solutions. The portfolio simplification across all VMware by Broadcom divisions stems from customer and partner feedback over the years telling us our offers and go-to-market are too complex.</li><li>Complete the transition of all VMware by Broadcom solutions to subscription licenses, with the end of sale of perpetual licenses, Support and Subscription (SnS) renewals for perpetual offerings, and hybrid purchase program/subscription purchase program (HPP/SPP) credits beginning today (effective dates will vary). Additionally, we are introducing a bring-your-own-subscription license option, providing license portability to VMware validated hybrid cloud endpoints running VMware Cloud Foundation.</li></ul><p><strong>Portfolio Simplification</strong></p><p>Today, we’re announcing specific changes coming to the VMware Cloud Foundation division portfolio. Going forward, the division will feature two primary offers:</p><ul><li><strong>VMware Cloud Foundation</strong>, our flagship enterprise-class hybrid cloud solution for customers to run their business critical and modern applications – in a secure, resilient and cost efficient manner. To allow more customers to benefit from this solution, we’ve reduced the previous subscription list price by half and added higher support service levels including enhanced support for activating the solution and lifecycle management.<strong></strong></li><li>The new <strong>VMware vSphere Foundation</strong> delivers a more simplified enterprise-grade workload platform for our mid-sized to smaller customers. This solution integrates vSphere with our intelligent operations management to provide the best performance, availability, and efficiency with greater visibility and insights.</li></ul><p>Both VMware Cloud Foundation and VMware vSphere Foundation will have optional advanced add-on offers. Our storage offering, ransomware and disaster recovery service, and application platform services are available on both offers. And Application Network and Security offerings are available for VMware Cloud Foundation. Additional advanced services and offerings, including Private AI, will be available soon.</p><p><strong>Subscription Licenses</strong></p><p>VMware has been on a journey to transition to a subscription model for more than a year now, and the industry has already embraced subscription as the standard for cloud consumption. With a simplified portfolio in place, we’re completing our transition to subscription offerings. Offerings will solely be available as subscriptions or as term licenses following the end of sale of perpetual licenses and Support and Subscription (SnS) renewals beginning today.</p><p>The subscription model helps us deliver what customers want:</p><ul><li>Continuous innovation.</li><li>Faster time to value.</li><li>Predictable investments.</li></ul><p>Customers may continue using perpetual licenses with active support contracts. We will continue to provide support as defined in contractual commitments. We encourage customers to review their inventory of perpetual licenses, including Support Services renewal and expiration dates. Broadcom will work with customers to help them “trade in” their perpetual products in exchange for the new subscription products, with upgrade pricing incentives. (For additional details, see FAQ).</p><p>The simplification of our portfolio and shift to subscription and term offerings are a culmination of our multi-year business transformation efforts. The steps we’re taking today will further enable customer and partner success by delivering the innovation, simplicity and flexibility they need as they undertake their digital transformations.</p><p><strong>Frequently Asked Questions</strong></p><p><strong>Q: What is VMware by Broadcom announcing?</strong></p><p>A: Today, VMware by Broadcom has reached a new milestone in its journey and announced the following:</p><ul><li>A dramatic simplification of our product portfolio that allows customers of all sizes to gain more value for their investments in VMware solutions. The portfolio simplification across all VMware by Broadcom divisions stems from customer and partner feedback over the years telling us our offers and go-to-market are too complex.</li><li>Complete the transition of all VMware by Broadcom solutions to subscription licenses, with the end of sale of perpetual licenses, Support and Subscription (SnS) renewals for perpetual offerings, and HPP/SPP (generic) credits beginning today. Additionally, we are introducing a bring-your-own-subscription license option, providing license portability to VMware validated hybrid cloud endpoints running VMware Cloud Foundation.</li></ul><p><strong>Q: How do these changes benefit customers?</strong>&nbsp;</p><p>A: Over the past two years, VMware has been on a journey to simplify its portfolio and transition to a subscription model, the industry standard for cloud consumption, and to better serve customers with continuous innovation, faster time to value, and predictable investments. We’re also helping more customers benefit from VMware Cloud Foundation by reducing the list price by half and including higher support service levels including enhanced support for activating the solution and lifecycle management.</p><p><strong>Q: Why is this good for partners?</strong></p><p>A: The industry has already widely embraced subscription and SaaS, and many partners in our ecosystem have already developed success practices in this area. Subscription and SaaS models provide an opportunity for partners to engage more strategically with customers and deliver higher-value services that drive customer success. It also helps accelerate their own transition to a business model focused on annual recurring revenue.</p><p><strong>Q: What are the changes to perpetual licenses?</strong></p><p>A: As part of our transition to subscription and a simplified portfolio, beginning today, we will no longer sell perpetual licenses. All offerings will continue to be available as subscriptions going forward. Additionally, we are ending the sale of Support and Subscription (SnS) renewals for perpetual offerings beginning today.</p><p><strong>Q: Why make this change from perpetual licenses to subscription?&nbsp;</strong></p><p>A: This shift is the natural next step in our multi-year strategy to make it easier for customers to consume both our existing offerings and new innovations. VMware believes that a subscription model supports our customers with the innovation and flexibility they need as they undertake their digital transformations.</p><p><strong>Q: Can customers continue to use their perpetual license</strong><strong>s?</strong></p><p>A: Yes, customers can continue to use perpetual licenses that they’ve purchased for products.</p><p><strong>Q: Can customers still purchase and add additional perpetual licenses after </strong><strong>today?</strong></p><p>A: After a customer’s effective date for the end of availability of perpetual licenses, customers will not be able to purchase new perpetual licenses. Customers will be able to purchase subscription software or term licenses to supplement or replace their current perpetual-licensed install base.</p><p><strong>Q: Can customers renew their Service and Support (SnS) contracts </strong><strong>after today?</strong></p><p>A: No, customers cannot renew their SnS contracts for perpetual licensed products after today. Broadcom will work with customers to help them “trade in” their perpetual products in exchange for the new subscription products, with upgrade pricing incentives. Customers can contact their VMware account or partner representative to learn more.</p><p><strong>Q: Do customers have to collect and submit their perpetual licenses to Broadcom when they “trade-in” their products for subscription?</strong></p><p>A: No, Broadcom does not require customers to submit their perpetual licenses to Broadcom when they “trade in” their products for subscription.</p><p><strong>Q: Will VMware by Broadcom continue to provide support for active Service and Support (SnS) contracts?</strong></p><p>A: We will continue to provide support as defined in contractual commitments.</p><p><strong>Q: What will happen to customers’ existing perpetual licenses with active SnS contracts when they are up for renewal?</strong></p><p>A: Customers should contact their VMware account or partner representative for upgrade pricing from perpetual to subscription.</p><p><strong>Q: What can customers with perpetual licenses do now to prepare?</strong></p><p>A: This is an excellent time for customers to assess their current state with VMware infrastructure and management products. We encourage customers to review their inventory of perpetual licenses, including refresh cycles and renewal dates, and become more familiar with VMware's available subscription offers. Customers should also contact their VMware or partner representative for more information.&nbsp;</p><p><strong>Q: What VMware Cloud Foundation division offerings are available for purchase?</strong></p><p>A: The product simplification across the VMware Cloud Foundation division stems from customer and partner feedback requesting we reduce the complexity of our offers and go-to-market. Going forward, the VMware Cloud Foundation division will feature two primary offers: VMware Cloud Foundation, the new VMware vSphere Foundation and our Hybrid Cloud services and offers. Additionally, we offer VMware vSphere Standard and VMware vSphere Essentials Plus for deployments with more limited requirements.</p><p><strong>Q: What is VMware vSphere Foundation?</strong></p><p>A: VMware vSphere Foundation is a new solution that combines our full-featured server virtualization platform, vSphere with intelligent operations management to deliver the best performance, availability, and efficiency with greater visibility and insights. For customers seeking an HCI solution, we offer VMware vSAN as an add-on to vSphere Foundation, which includes all the capabilities of vSAN including vSAN Max.</p><p><strong>Q: What happens to customers that have purchased HPP/EPP credits and still have an outstanding balance of unredeemed credits?</strong></p><p>A: We are honoring existing agreements and will work with our customers to help with the redemption of credits on our new offerings.</p><p><strong>Q: What products and bundles are impacted by this new policy?</strong></p><p>A: Here is a list of products impacted by the new licensing policy:</p><ul><li>VMware Cloud Foundation</li><li>VMware vSphere</li><li>VMware vSAN</li><li>VMware NSX</li><li>VMware HCX</li><li>VMware Site Recovery Manager</li><li>VMware vCloud Suite</li><li>VMware Aria Suite</li><li>VMware Aria Universal</li><li>VMware Aria Automation</li><li>VMware Aria Operations</li><li>VMware Aria Operations for Logs</li><li>VMware Aria Operations for Networks</li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mozilla "MemoryCache" Local AI (429 pts)]]></title>
            <link>https://future.mozilla.org/blog/introducing-memorycache/</link>
            <guid>38614824</guid>
            <pubDate>Tue, 12 Dec 2023 16:56:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://future.mozilla.org/blog/introducing-memorycache/">https://future.mozilla.org/blog/introducing-memorycache/</a>, See on <a href="https://news.ycombinator.com/item?id=38614824">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <article>
    <h2>Augmenting Local AI with Browser Data:  Introducing MemoryCache</h2>

    
    
    

    
    
    

    

    
      <p data-block-key="yx97h">The internet was born as a way to connect people and data together around the world. Today, machine learning is upending the way that we interact with data and information. Language and multi-media models seek ever-larger datasets to train on – including <a href="https://www.theverge.com/2023/7/5/23784257/google-ai-bard-privacy-policy-train-web-scraping">the entirety of the internet</a>. There are <a href="https://foundation.mozilla.org/en/blog/mozillas-ai-funding-principles-open-source-building-blocks-for-philanthropy/">complex sociological and regulatory questions at play</a>; critical decisions to be made about copyright, safety, transparency, access, and representation.</p><p data-block-key="bu6uc"><a href="https://memorycache.ai/">MemoryCache</a> is an early exploration project from the Mozilla Innovation Ecosystem team that augments an on-device, personal model with local files saved from the browser to reflect a more personalized and tailored experience through the lens of privacy and agency.</p>
    
      
<figure>
  





<img alt="A UI Mockup of a potential design for a MemoryCache desktop application" height="1852" src="https://storage.googleapis.com/future-prod-prod-storage/images/DesktopApplication.original.png" width="2520">

  
  <figcaption>
    A mockup of a potential design for a future MemoryCache UI
    
  </figcaption>
  
</figure>

    
      <p data-block-key="3scq2">The way that humans think is uniquely personal to each individual. While individuals share many principles, values and properties of their surrounding communities and organizations, each of us has a unique perspective and set of information that we're exposed to on a regular basis. The process of making new insights from the content we create and consume is not a "one-size-fits-all" opportunity, and machine learning capabilities open up a vast range of new computing advancements and paradigms.</p>
    
      
<figure>
  





<img alt="Prompt" height="1500" src="https://storage.googleapis.com/future-prod-prod-storage/images/Prompt.original.png" width="3000">

  
</figure>

    
      <p data-block-key="aieh9">Today, MemoryCache is a set of scripts and simple tools to augment a local copy of <a href="https://www.privategpt.io/">privateGPT</a>. The project contains:</p><ul><li data-block-key="fro2t">A Firefox extension that acts as a simple "printer" to save pages to a subdirectory in your<code> /Downloads/</code> folder, and includes the ability to quickly save notes and information from your browser to your local machine</li><li data-block-key="al824">A shell script that listens for changes in the <code>/Downloads/MemoryCache</code> directory and runs the privateGPT <code>ingest.py</code> script</li><li data-block-key="9vlcq">Code to (optionally) update the Firefox <code>SaveAsPDF</code> API on a <a href="https://firefox-source-docs.mozilla.org/setup/linux_build.html">local build of Firefox</a> to enable a flag that silently saves webpages as PDF for easier human readability (by default, pages need to be saved as HTML in Firefox)</li></ul><p data-block-key="7qqdc">We see MemoryCache as a sandbox for experimenting with some of the quirkier, more unique parts of the brainstorming and idea generation process, all done entirely locally. Our test ground for MemoryCache is a gaming PC with an Intel i7-8700 processor, using <a href="https://huggingface.co/nomic-ai/gpt4all-j">Nomic AI's groovy.ggml version of gpt-4-all model</a>. We're using the <a href="https://github.com/misslivirose/privateGPT">primordial version of privateGPT</a>, because our preliminary evaluations have found that newer models and versions of the application start to over-generalize the responses even after augmenting the model with personal data – in our environment, 75.3MB of documents saved from the browser and from personal blog posts, notes, and journal entries.</p><p data-block-key="598h8">MemoryCache is early, experimental, and a sandbox for exploration. You can follow along with <a href="https://github.com/Mozilla-Ocho/Memory-Cache">the project on GitHub</a>, or check <a href="https://memorycache.ai/">out our website</a> to stay up to date with our progress!</p>
    

    
  </article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Phi-2: The surprising power of small language models (204 pts)]]></title>
            <link>https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/</link>
            <guid>38614361</guid>
            <pubDate>Tue, 12 Dec 2023 16:29:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/">https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/</a>, See on <a href="https://news.ycombinator.com/item?id=38614361">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody" data-bi-an="post-body">

						
<h3 id="contributors">Contributors</h3>



<p><a href="https://www.microsoft.com/en-us/research/people/maabdin/">Marah Abdin</a>, <a href="https://www.microsoft.com/en-us/research/people/jyotianeja/">Jyoti Aneja</a>, <a href="https://www.microsoft.com/en-us/research/people/sebubeck/">Sebastien Bubeck</a>, Caio César Teodoro Mendes, <a href="https://www.microsoft.com/en-us/research/people/wzchen/">Weizhu Chen</a>, Allie Del Giorno, <a href="https://www.microsoft.com/en-us/research/people/roneneldan/">Ronen Eldan</a>, <a href="https://www.microsoft.com/en-us/research/people/sigopi/">Sivakanth Gopi</a>, <a href="https://www.microsoft.com/en-us/research/people/suriyag/">Suriya Gunasekar</a>, <a href="https://www.microsoft.com/en-us/research/people/mojavaheripi/">Mojan Javaheripi</a>, <a href="https://www.microsoft.com/en-us/research/people/pkauffmann/">Piero Kauffmann</a>, <a href="https://www.microsoft.com/en-us/research/people/yintatlee/">Yin Tat Lee</a>, Yuanzhi Li, <a href="https://www.microsoft.com/en-us/research/people/anhnguyen/">Anh Nguyen</a>, <a href="https://www.microsoft.com/en-us/research/people/gderosa/">Gustavo de Rosa</a>, <a href="https://www.microsoft.com/en-us/research/people/olsaarik/">Olli Saarikivi</a>, <a href="https://www.microsoft.com/en-us/research/people/adilsalim/">Adil Salim</a>, <a href="https://www.microsoft.com/en-us/research/people/shitals/">Shital Shah</a>, Michael Santacroce, Harkirat Singh Behl, <a href="https://www.microsoft.com/en-us/research/blog/tag/adam-kalai/">Adam Taumann Kalai</a>, <a href="https://www.microsoft.com/en-us/research/people/wanxin/">Xin Wang</a>, <a href="https://www.microsoft.com/en-us/research/people/rachelward/">Rachel Ward</a>, <a href="https://www.microsoft.com/en-us/research/people/pwitte/">Philipp Witte</a>, <a href="https://www.microsoft.com/en-us/research/people/cyrilzhang/">Cyril Zhang</a>, Yi Zhang</p>



<figure><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1.jpg" alt="Satya Nadella on stage at Microsoft Ignite 2023 announcing Phi-2." srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1.jpg 1400w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-300x169.jpg 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-1024x576.jpg 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-768x432.jpg 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-1066x600.jpg 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-655x368.jpg 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-343x193.jpg 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-240x135.jpg 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-640x360.jpg 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-960x540.jpg 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Phi2-BlogHeroFeature-1400x788-1-1280x720.jpg 1280w" sizes="(max-width: 1400px) 100vw, 1400px"><figcaption><strong>Figure 1. </strong>Satya Nadella announcing Phi-2 at Microsoft Ignite 2023.</figcaption></figure>



<p>Over the past few months, our Machine Learning Foundations team at Microsoft Research has released a suite of small language models (SLMs) called “Phi” that achieve remarkable performance on a variety of benchmarks. Our first model, the 1.3 billion parameter <a href="https://huggingface.co/microsoft/phi-1" target="_blank" rel="noreferrer noopener"><strong>Phi-1</strong><span> (opens in new tab)</span></a>, achieved state-of-the-art performance on Python coding among existing SLMs (specifically on the HumanEval and MBPP benchmarks). We then extended our focus to common sense reasoning and language understanding and created a new 1.3 billion parameter model named <a href="https://huggingface.co/microsoft/phi-1_5" target="_blank" rel="noreferrer noopener"><strong>Phi-1.5</strong><span> (opens in new tab)</span></a>, with performance comparable to models 5x larger.</p>



<p>We are now releasing <a href="https://ml.azure.com/registries/azureml-msr/models/microsoft-phi-2/version/3?tid=72f988bf-86f1-41af-91ab-2d7cd011db47#overview" target="_blank" rel="noreferrer noopener"><strong>Phi-2</strong><span> (opens in new tab)</span></a>, a 2.7 billion-parameter language model that demonstrates outstanding reasoning and language understanding capabilities, showcasing state-of-the-art performance among base language models with less than 13 billion parameters. On complex benchmarks Phi-2 matches or outperforms models up to 25x larger, thanks to new innovations in model scaling and training data curation.</p>



<p>With its compact size, Phi-2 is an ideal playground for researchers, including for exploration around mechanistic interpretability, safety improvements, or fine-tuning experimentation on a variety of tasks. We have made <a href="https://ml.azure.com/registries/azureml-msr/models/microsoft-phi-2/version/3?tid=72f988bf-86f1-41af-91ab-2d7cd011db47#overview" target="_blank" rel="noreferrer noopener"><strong>Phi-2</strong><span> (opens in new tab)</span></a><strong> </strong>available in the Azure AI Studio model catalog to foster research and development on language models.</p>



	<div data-bi-an="promo" data-bi-id="979236">
		

		<p>
		<span>MICROSOFT RESEARCH PODCAST</span>
	</p>
	
	<div>
						<p><a href="https://www.microsoft.com/en-us/research/podcast/whats-your-story-ranveer-chandra/" aria-label="What’s Your Story: Ranveer Chandra" data-bi-cn="What’s Your Story: Ranveer Chandra" target="_blank">
					<img decoding="async" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/10/Ravneer_Hero_Feature_1400x788.png">
				</a>
			</p>
			
			<div>

									<h2>What’s Your Story: Ranveer Chandra</h2>
				
								<p>You may know tech, but how well do you know the people behind the advances? Ranveer Chandra talks about growing up in India, his work in systems and networking, and finding joy in your job in the first episode of the #MSRPodcast “What’s Your Story”.</p>
				
								
							</div><!--/.msr-promo__content-->
	</div><!--/.msr-promo__inner-wrap-->
</div><!--/.msr-promo-->
	


<h2 id="key-insights-behind-phi-2">Key Insights Behind Phi-2</h2>



<p>The massive increase in the size of language models to hundreds of billions of parameters has unlocked a host of emerging capabilities that have redefined the landscape of natural language processing. A question remains whether such emergent abilities can be achieved at a smaller scale using strategic choices for training, e.g., data selection.</p>



<p>Our line of work with the Phi models aims to answer this question by training SLMs that achieve performance on par with models of much higher scale (yet still far from the frontier models). Our key insights for breaking the conventional language model scaling laws with Phi-2 are twofold:</p>



<p>Firstly, training data quality plays a critical role in model performance. This has been known for decades, but we take this insight to its extreme by focusing on “textbook-quality” data, following upon our prior work “<a href="https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need/">Textbooks Are All You Need</a>.” Our training data mixture contains synthetic datasets specifically created to teach the model common sense reasoning and general knowledge, including science, daily activities, and theory of mind, among others. We further augment our training corpus with carefully selected web data that is filtered based on educational value and content quality. Secondly, we use innovative techniques to scale up, starting from our 1.3 billion parameter model, Phi-1.5, and embedding its knowledge within the 2.7 billion parameter Phi-2. This scaled knowledge transfer not only accelerates training convergence but shows clear boost in Phi-2 benchmark scores.</p>



<figure><img decoding="async" width="25377" height="5876" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp.png" alt="A bar plot comparing the performance of Phi-2 (with 2.7B parameters) and Phi-1.5 (with 1.3B parameters) on common sense reasoning, language understanding, math, coding, and the Bigbench-hard benchmark. Phi-2 outperforms Phi1.5 in all categories. The commonsense reasoning tasks are PIQA, WinoGrande, ARC easy and challenge, and SIQA. The language understanding tasks are HellaSwag, OpenBookQA, MMLU, SQuADv2, and BoolQ. The math task is GSM8k, and coding includes the HumanEval and MBPP benchmarks. " srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp.png 25377w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-300x69.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-1024x237.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-768x178.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-1536x356.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-2048x474.png 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure2_phi_comp-240x56.png 240w" sizes="(max-width: 25377px) 100vw, 25377px"><figcaption><strong>Figure 2. </strong>Comparison between Phi-2 (2.7B) and Phi-1.5 (1.3B) models. All tasks are evaluated in 0-shot except for BBH and MMLU which use 3-shot CoT and 5-shot, respectively.</figcaption></figure>



<h2 id="training-details">Training Details</h2>



<p>Phi-2 is a Transformer-based model with a next-word prediction objective, trained on 1.4T tokens from multiple passes on a mixture of Synthetic and Web datasets for NLP and coding. The training for Phi-2 took 14 days on 96 A100 GPUs. Phi-2 is a base model that has not undergone alignment through reinforcement learning from human feedback (RLHF), nor has it been instruct fine-tuned. Despite this, we observed better behavior with respect to toxicity and bias compared to existing open-source models that went through alignment (see Figure 3). This is in line with what we saw in Phi-1.5 due to our tailored data curation technique, see our <a href="https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need-ii-phi-1-5-technical-report/">previous tech report<span> (opens in new tab)</span></a> for more details on this. For more information about the Phi-2 model, please visit <a href="https://ml.azure.com/registries/azureml-msr/models/microsoft-phi-2/version/3?tid=72f988bf-86f1-41af-91ab-2d7cd011db47#overview" target="_blank" rel="noreferrer noopener">Azure AI | Machine Learning Studio<span> (opens in new tab)</span></a>.</p>



<figure><img decoding="async" width="16803" height="8165" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores.png" alt="A barplot comparing the safety score of Phi-1.5, Phi-2, and Llama-7B models on 13 categories of the ToxiGen benchmark. Phi-1.5 achieves the highest score on all categories, Phi-2 achieves the second-highest scores and Llama-7B achieves the lowest scores across all categories. " srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores.png 16803w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores-300x146.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores-1024x498.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores-768x373.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores-1536x746.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores-2048x995.png 2048w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/figure3_safety_scores-240x117.png 240w" sizes="(max-width: 16803px) 100vw, 16803px"><figcaption><strong>Figure 3. </strong>Safety scores computed on 13 demographics from ToxiGen. A subset of 6541 sentences are selected and scored between 0 to 1 based on scaled perplexity and sentence toxicity. A higher score indicates the model is less likely to produce toxic sentences compared to benign ones.</figcaption></figure>



<h2 id="phi-2-evaluation">Phi-2 Evaluation</h2>



<p>Below, we summarize Phi-2 performance on academic benchmarks compared to popular language models. Our benchmarks span several categories, namely, Big Bench Hard (BBH) (3 shot with CoT), commonsense reasoning (PIQA, WinoGrande, ARC easy and challenge, SIQA), language understanding (HellaSwag, OpenBookQA, MMLU (5-shot), SQuADv2 (2-shot), BoolQ), math (GSM8k (8 shot)), and coding (HumanEval, MBPP (3-shot)).</p>



<p>With only 2.7 billion parameters, Phi-2 surpasses the performance of Mistral and Llama-2 models at 7B and 13B parameters on various aggregated benchmarks. Notably, it achieves better performance compared to 25x larger Llama-2-70B model on muti-step reasoning tasks, i.e., coding and math. Furthermore, Phi-2 matches or outperforms the recently-announced Google Gemini Nano 2, despite being smaller in size.</p>



<p>Of course, we acknowledge the current challenges with model evaluation, and that many public benchmarks might leak into the training data. For our first model, Phi-1, we did an extensive decontamination study to discard this possibility, which can be found in our first report “<a href="https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need/">Textbooks Are All You Need</a>.” Ultimately, we believe that the best way to judge a language model is to test it on concrete use cases. Following that spirit, we also evaluated Phi-2 using several Microsoft internal proprietary datasets and tasks, comparing it again to Mistral and Llama-2. We observed similar trends, i.e. on average, Phi-2 outperforms Mistral-7B, and the latter outperforms the Llama-2 models (7B, 13B, and 70B).</p>



<figure><table><thead><tr><th>Model</th><th>Size</th><th>BBH</th><th>Commonsense<br>Reasoning</th><th>Language<br>Understanding</th><th>Math</th><th>Coding</th></tr></thead><tbody><tr><td rowspan="3">Llama-2</td><td>7B</td><td>40.0</td><td>62.2</td><td>56.7</td><td>16.5</td><td>21.0</td></tr><tr><td>13B</td><td>47.8</td><td>65.0</td><td>61.9</td><td>34.2</td><td>25.4</td></tr><tr><td>70B</td><td>66.5</td><td>69.2</td><td>67.6</td><td>64.1</td><td>38.3</td></tr><tr><td>Mistral</td><td>7B</td><td>57.2</td><td>66.4</td><td>63.7</td><td>46.4</td><td>39.4</td></tr><tr><td>Phi-2</td><td>2.7B</td><td>59.2</td><td>68.8</td><td>62.0</td><td>61.1</td><td>53.7</td></tr></tbody></table><figcaption><center><strong>Table 1.</strong> Averaged performance on grouped benchmarks compared to popular open-source SLMs.</center></figcaption></figure>



<figure><table><thead><tr><th>Model</th><th>Size</th><th>BBH</th><th>BoolQ</th><th>MBPP</th><th>MMLU</th></tr></thead><tbody><tr><td>Gemini Nano 2</td><td>3.2B</td><td>42.4</td><td>79.3</td><td>27.2</td><td>55.8</td></tr><tr><td>Phi-2</td><td>2.7B</td><td>59.3</td><td>83.3</td><td>59.1</td><td>56.7</td></tr></tbody></table><figcaption><center><strong>Table 2.</strong> Comparison between Phi-2 and Gemini Nano 2 Model on Gemini’s reported benchmarks.</center></figcaption></figure>



<p>In addition to these benchmarks, we also performed extensive testing on commonly used prompts from the research community. We observed a behavior in accordance with the expectation we had given the benchmark results. For example, we tested a prompt used to probe a model’s ability to solve physics problems, most recently used to evaluate the capabilities of the Gemini Ultra model, and achieved the following result:</p>



<figure><img decoding="async" width="1347" height="758" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4.png" alt="An example prompt is given to Phi-2 which says “A skier slides down a frictionless slope of height 40m and length 80m. What's the skier’s speed at the bottom?”. Phi-2 then answers the prompt by explaining the conversion of potential energy to kinetic energy and providing the formulas to compute each one. It then proceeds to compute the correct speed using the energy formulas. " srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4.png 1347w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-343x193.png 343w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig4-1280x720.png 1280w" sizes="(max-width: 1347px) 100vw, 1347px"><figcaption><strong>Figure 4. </strong>Phi-2’s output on a simple physics problem, which includes an approximately correct square root calculation.</figcaption></figure>



<figure><img decoding="async" width="1600" height="710" src="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5.png" alt="The model is then provided with a student’s wrong answer to the skier physics problem and asked if it can correct the student’s mistake. Phi-2 replies with the student’s mistake, i.e., using the wrong formula for potential energy, and provides the correct formula. " srcset="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5.png 1600w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5-300x133.png 300w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5-1024x454.png 1024w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5-768x341.png 768w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5-1536x682.png 1536w, https://www.microsoft.com/en-us/research/uploads/prod/2023/12/Seb_Fig5-240x107.png 240w" sizes="(max-width: 1600px) 100vw, 1600px"><figcaption><strong>Figure 5. </strong>Similarly to Gemini’s test we also further queried Phi-2 with a student’s wrong answer to see if Phi-2 could identify where the mistake is (it did, despite Phi-2 being not fine-tuned for chat or instruction-following). We note however that it is not fully an apple-to-apple comparison with the Gemini Ultra’s output described in the Gemini report, in particular in the latter case the student’s answer was given as an image with handwritten text rather than raw text in our case.</figcaption></figure>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A new old kind of R&D lab (268 pts)]]></title>
            <link>https://www.answer.ai/posts/2023-12-12-launch.html</link>
            <guid>38614232</guid>
            <pubDate>Tue, 12 Dec 2023 16:19:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.answer.ai/posts/2023-12-12-launch.html">https://www.answer.ai/posts/2023-12-12-launch.html</a>, See on <a href="https://news.ycombinator.com/item?id=38614232">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="quarto-content">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main id="quarto-document-content">



<section id="tldr">
<h2 data-anchor-id="tldr">tl;dr</h2>
<p>Jeremy Howard (founding CEO, previously co-founder of Kaggle and fast.ai) and Eric Ries (founding director, previously creator of Lean Startup and the Long-Term Stock Exchange) today launched Answer.AI, a new kind of AI R&amp;D lab which creates practical end-user products based on foundational research breakthroughs. The creation of Answer.AI is supported by an investment of USD10m from Decibel VC. Answer.AI will be a fully-remote team of deep-tech generalists—the world’s very best, regardless of where they live, what school they went to, or any other meaningless surface feature.</p>
</section>
<section id="a-new-rd-lab">

<p>In 1831 Michael Faraday showed the world how to harness electricity. Suddenly there was, quite literally, a new source of power in the world. He later found the basis of the unification of light and magnetism, and knew he was onto something big:</p>
<blockquote>
<p><em>“I happen to have discovered a direct relation between magnetism and light, also electricity and light, and the field it opens is so large and I think rich.”</em> Michael Faraday; letter to Christian Schoenbein</p>
</blockquote>
<p>But it wasn’t quite clear how to harness this power. What kinds of products and services could now be created that couldn’t before? What could now be made far cheaper, more efficient, and more accessible? One man set out to understand this, and in 1876 he put together a new kind of R&amp;D lab, which he called the “Invention Lab”: a lab that would figure out the fundamental research needed to tame electricity, and the applied development needed to make it useful in practice.</p>
<p>You might have heard of the man: his name was Thomas Edison. And the organization he created turned into a company you would know: General Electric.</p>
<p>Today, we find ourselves in a similar situation. There’s a new source of power in the world—artificial intelligence. And, like before, it’s not quite clear how to harness this power. Where are all the AI-powered products and services that make our lives and work dramatically easier and more pleasant?</p>
<p>To create these AI-powered products and services, we’ve created a new R&amp;D lab, called <strong>Answer.AI</strong>. Answer.AI will figure out the fundamental <em>research</em> needed to tame AI, and the <em>development</em> path needed to make it useful in practice.</p>
</section>
<section id="an-iterative-path-to-harnessing-ai">
<h2 data-anchor-id="an-iterative-path-to-harnessing-ai">An iterative path to harnessing AI</h2>
<p>Harnessing AI requires not just low-level computer science and mathematical research, but also deep thinking about what practical applications can take advantage of this new power. The “D” in “R&amp;D” is critical: it’s only by considering the <em>development</em> of practical applications that the correct <em>research</em> directions can be targeted.</p>
<p>That’s why Answer.AI is built on the work of experts in both research <em>and</em> development. Co-founders Jeremy Howard (that’s me!) and Eric Ries have created pioneering ideas in each of these areas. I co-founded fast.ai, where I have worked for the last 7 years on <strong>research</strong> into how to best make AI more accessible, particularly through <em>transfer learning</em> and <em>fine tuning</em>. I’ve been working with machine learning for over 30 years, including creating the ULMFiT method of fine-tuning large language models which is used as the basis of all popular language models today, including OpenAI’s ChatGPT and Google’s Gemini. I have developed the longest running online courses on Deep Learning in the world, in which I show students how to start with simple models and then iteratively improve them all the way to the state of the art.</p>
<p>I’ve known Eric for years, and there’s no-one I trust or respect more, which is why I asked him to serve as the founding director of Answer.AI. Eric has dedicated the last 10 years of his life to improving how companies operate, serve customers, and are governed. He is the creator of the Lean Startup movement, which is the basis of how most startups build products and scale their organizations. His work focuses on <strong>development</strong>: how can organizations go from an idea to a sustainable, mission-driven, and profitable product in practice. One of his key insights was to create and then iteratively improve a <em>Minimal Viable Product</em> (MVP).</p>
<p>I asked Eric for his thoughts on Answer.AI’s unique approach to R&amp;D, and he summarised better than I ever could, so I’ll just quote his reply here directly:</p>
<blockquote>
<p><em>“People think that the order is research→development, and that therefore an R&amp;D lab does “R” and then “D”. That is, the research informs the development, and so being practical means having researchers and developers. But this is wrong, and leads to a lot of bad research, because development should inform research and vice-versa. So having development goals is a way to do more effective research, if you set that out as your north star.”</em></p>
</blockquote>
<p>Eric is also an expert on governance and how companies should be led in order to align profit and increased human flourishing. He created the <a href="https://ltse.com/">Long-Term Stock Exchange</a> (LTSE), the first fundamentally new US Stock Exchange in over 50 years. LTSE mandates that listed companies and likeminded investors work towards long-term value, rather than just short-term profit maximization. Eric serves as the Chairman of LTSE, meaning he is not only up to date on the right long-term governance frameworks, but on the cutting edge of inventing new systems.</p>
<p>It will take years for Answer.AI to harness AI’s full potential, which requires the kind of strategic foresight and long-term tenacity which is hard to maintain in today’s business environment. Eric has been writing a book on exactly this topic, and his view is that the key foundation is to have the right corporate governance in place. He’s helped me ensure that Answer.AI will always reflect my vision and strategy for harnessing AI. We’re doing this by by setting up a for-profit organization that focuses on <em>long-term</em> impact. After all, over a long-enough timeframe, maximizing shareholder value and maximizing societal benefits are entirely aligned.</p>
<p>Whilst Eric and I bring very different (and complementary) skills and experiences to the table, we bring the same basic idea of how to solve really hard problems: solve smaller easier problems in simple ways first, and create a ladder where each rung is a useful step of itself, whilst also getting a little closer to the end goal.</p>
</section>
<section id="our-research-platform">
<h2 data-anchor-id="our-research-platform">Our research platform</h2>
<p>Companies like OpenAI and Anthropic have been working on developing Artificial General Intelligence (AGI). And they’ve done an astonishing job of that — we’re now at the point where experts in the field are claiming that “<a href="https://www.noemamag.com/artificial-general-intelligence-is-already-here/">Artificial General Intelligence Is Already Here</a>”.</p>
<p>At Answer.AI we are not working on building AGI. Instead, our interest is in effectively using the models that already exist. Figuring out what practically useful applications can be built on top of the foundation models that already exist is a huge undertaking, and I believe it is receiving insufficient attention.</p>
<p>My view is that the right way to build Answer.AI’s R&amp;D capabilities is by bringing together a very small number of curious, enthusiastic, technically brilliant generalists. Having huge teams of specialists creates an enormous amount of organizational friction and complexity. But with the help of modern AI tools I’ve seen that it’s possible for a single generalist with a strong understanding of the foundations to create effective solutions to challenging problems, using unfamiliar languages, tools, and libraries (indeed I’ve done this myself many times!) I think people will be very surprised to discover what a small team of nimble, creative, open-minded people can accomplish.</p>
<p>At Answer.AI we will be doing genuinely original research into questions such as how to best fine-tune smaller models to make them as practical as possible, and how to reduce the constraints that currently hold back people from using AI more widely. We’re interested in solving things that may be too small for the big labs to care about-—but our view is that it’s the collection of these small things matter a great deal in practice.</p>
<p>This informs how we think about safety. Whilst AI is becoming more and more capable, the dangers to society from poor algorithmic decision making have been with us for years. We believe in learning from these years of experience, and thinking deeply about how to align the <em>applications</em> of models with the needs of people today. At fast.ai three years ago we created a pioneering course on <a href="https://ethics.fast.ai/">Practical Data Ethics</a>, as well as dedicating <a href="https://github.com/fastai/fastbook/blob/master/03_ethics.ipynb">a chapter of our book</a> to these issues. We are committed to continuing to work towards ethical and beneficial applications of AI.</p>
</section>
<section id="from-fast.ai-to-answer.ai">
<h2 data-anchor-id="from-fast.ai-to-answer.ai">From fast.ai to Answer.AI</h2>
<p>Rachel Thomas and I realised over seven years ago that deep learning and neural networks were on their way to becoming one of the most important technologies in history, but they were also on their way to being controlled and understood by a tiny exclusive sliver of society. We were worried about centralization and control of something so critical, so we founded fast.ai with the mission of making AI more accessible.</p>
<p>We succeeded beyond our wildest dreams, and today fast.ai’s AI courses are the longest-running, and perhaps most loved, in the world. We built the first library to make PyTorch easier to use and more powerful (fastai), built the fastest image model training system in the world (according to the Dawnbench competition), and created the 3-step training methodology now used by all major LLMs (ULMFiT). Everything we have created for the last 7 years was free—fast.ai was an entirely altruistic endeavour in which everything we built was gifted to everybody.</p>
<p>I’m now of the opinion that this is the time for rejuvenation and renewal of our mission. Indeed, the mission of Answer.AI is the same as fast.ai: to make AI more accessible. But the <em>method</em> is different. Answer.AI’s method will be to <em>use</em> AI to create all kinds of products and services that are really valuable and useful in practice. We want to research new ways of building AI products that serve customers that can’t be served by current approaches.</p>
<p>This will allow us to make money, which we can use to expand into more and bigger opportunities, and use to drive down costs through better efficiency, creating a positive feedback loop of more and more value from AI. We’ll be spending all our time looking at how to make the market size bigger, rather than how to increase our share of it. There’s no moat, and we don’t even care! This goes to the heart of our key premise: creating a long-term profitable company, and making a positive impact on society overall, can be entirely aligned goals.</p>
</section>
<section id="we-dont-really-know-what-were-doing">
<h2 data-anchor-id="we-dont-really-know-what-were-doing">We don’t really know what we’re doing</h2>
<p>If you’ve read this far, then I’ll tell you the honest truth: we don’t actually know what we’re doing. Artificial intelligence is a vast and complex topic, and I’m very skeptical of anyone that claims they’ve got it all figured out. Indeed, Faraday felt the same way about electricity—he wasn’t even sure it was going to be of any import:</p>
<blockquote>
<p><em>“I am busy just now again on Electro-Magnetism and think I have got hold of a good thing but can’t say; it may be a weed instead of a fish that after all my labour I may at last pull up.”</em> Faraday 1931 letter to R. Phillips</p>
</blockquote>
<p>But it’s OK to be uncertain. Eric and I believe that the best way to develop valuable stuff built on top of modern AI models is to try lots of things, see what works out, and then gradually improve bit by bit from there.</p>
<p>As Faraday said, “A man who is certain he is right is almost sure to be wrong.” Answer.AI is an R&amp;D lab for people who aren’t certain they’re right, but they’ll work damn hard to get it right eventually.</p>
<p>This isn’t really a new kind of R&amp;D lab. Edison did it before, nearly 150 years ago. So I guess the best we can do is to say it’s a new old kind of R&amp;D lab. And if we do as well as GE, then I guess that’ll be pretty good.</p>


</section>

</main> <!-- /main -->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tacit Knowledge Is Dangerous (146 pts)]]></title>
            <link>https://er4hn.info/blog/2023.08.26-tacit-knowledge-dangerous/</link>
            <guid>38614195</guid>
            <pubDate>Tue, 12 Dec 2023 16:17:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://er4hn.info/blog/2023.08.26-tacit-knowledge-dangerous/">https://er4hn.info/blog/2023.08.26-tacit-knowledge-dangerous/</a>, See on <a href="https://news.ycombinator.com/item?id=38614195">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<article>
   
  <div><p>Tacit knowledge, often called “tribal knowledge” in tech, is prevalent in this industry. Documentation is a common afterthought and is frequently wrong, out of date, or lacking crucial information. New hires join a company and go through onboarding exercises intended to have them learn by doing. Often that learning means asking others when they get stuck. It becomes natural for an engineer to end up having key information in their head. When others need it, the engineer freely shares it. Until, the inevitable happens.</p>
<p><img loading="lazy" src="https://er4hn.info/blog/2023.08.26-tacit-knowledge-dangerous/out_of_office.png" alt="Colleague out of office">
</p>
<blockquote>
<p>You need to know something not written down. You won’t be able to get an answer for a long time from the person who knows it best.</p>
</blockquote>
<p>The person who knows what you need is not there. Maybe they left the company, maybe they are on vacation. You may really need to know about the whizbang service, but it’s been 4 years since anyone last worked on it and no-one remembers how it works. You’ve now fallen into the trap of tacit knowledge.</p>
<p>It’s easy, even efficient, to rely on tacit knowledge early on. It is often called tribal knowledge because it’s shared by people close to you, the proverbial tribe. This passing on of knowledge helps bond junior and senior members. The tribe passes this knowledge from seniors to juniors via rituals of song and dance. These songs will take form of video calls, ☕chats, instant message exchanges. Dances transmit information by moving the hand to ctrl+c from a notebook of useful commands, and pressing ctrl+v to send to a colleague. Other more advanced dances involve connecting to a colleagues machine to fix an issue or show a manual setup process that isn’t written down. These song and dance routines will hit their limit at some point.</p>
<p><img loading="lazy" src="https://er4hn.info/blog/2023.08.26-tacit-knowledge-dangerous/graph_relative_time.png" alt="Relative time scales for learning">
</p>
<blockquote>
<p>Graph showing relative time scales for different ways of learning something at work.</p>
</blockquote>
<p>Where sharing tribal knowledge breaks down is at scale. It’s faster to shoot someone who knows the answer a message than to read the documentation, but only if that wise sage can respond quickly. If the holder of the knowledge is busy, in another timezone and you missed the end of their day, or are on vacation, you are out of luck until they return. The timezone problem is particularly painful. 3:30 pm pacific has 1.5 hours left in the 9 - 5 working day. But if you need help from someone on the east coast of the US, it’s 6:30 pm and they have gone home. That same time is 8 am in Australia, and 4 am in India. If you need help from someone on the other side of the world, you’ll be waiting for a while. This doesn’t even attempt to account for different countries having their own set of national holidays.</p>
<p>As a company scales, reliance on tacit knowledge becomes more of a burden. The amount of time it takes to answer a question is a blocker and needing to ask someone begins to consume more time due to both timezones as well as the busy nature of some senior people.</p>
<p><img loading="lazy" src="https://er4hn.info/blog/2023.08.26-tacit-knowledge-dangerous/graph_getting_answers.png" alt="Graph showing time to get answers">
</p>
<blockquote>
<p>Graph showing how it takes a long time to get answers when distributed. Asking a fourth question doesn’t even fit on the “large, distributed” row.</p>
</blockquote>
<p>The longer it takes to get answers, the longer an engineer is blocked. These blockers begin to act as a drag on the ability of an engineer to be productive, and at scale slows down the company itself. Features took longer to ship, bugs take longer to fix. The company itself becomes less nimble and vulnerable to smaller players. This situation always existed, but was exacerbated by COVID and the rise of remote work. Coworkers that used to sit next to each other would now work from home. People moved to different cities, and sometimes moved across timezones. How then, can one try to regain productivity?</p>
<p><img loading="lazy" src="https://er4hn.info/blog/2023.08.26-tacit-knowledge-dangerous/scaling_middle_ground.png" alt="Having docs and videos is the middle ground of scaling">
</p>
<blockquote>
<p>Graph showing how reading docs and watching videos is still slower than asking people who know (and can respond quickly) but far faster than waiting for large, distributed teams to reply to you.</p>
</blockquote>
<p>The answer lies in the original chart: As teams scale up and knowledge becomes more distributed, it is faster to read documentation and watch video lectures than it is to ask others for help. Personally, I am an avid reader and prefer reading (and grepping) for what I need to know. Others learn topics better through video lectures and that is fine. Both have a place, but documentation should always be there because it is easily searchable and easy to reference. By investing the time to create a library of information, both written and video, a middle ground is reached. It will never have that small co-located team efficiency, but it will scale far better than anything relying on tacit knowledge.</p>
<p>For those who need help in getting started with writing documentation, a previous blog post of mine discusses that as well. <a href="https://er4hn.info/blog/2023.07.22-good_docs_great_effort/">Good Docs Take Great Effort</a> is where I would suggest anyone start when they need to figure out how to write documentation or see where they may improve.</p>


  </div>

  
</article>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[VapourSynth: A video processing framework with simplicity in mind (105 pts)]]></title>
            <link>https://www.vapoursynth.com/doc/introduction.html</link>
            <guid>38613938</guid>
            <pubDate>Tue, 12 Dec 2023 16:00:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vapoursynth.com/doc/introduction.html">https://www.vapoursynth.com/doc/introduction.html</a>, See on <a href="https://news.ycombinator.com/item?id=38613938">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="introduction" itemprop="articleBody" role="main" itemscope="itemscope" itemtype="http://schema.org/Article">

<p>VapourSynth is an application for video manipulation. Or a plugin. Or a library.
It’s hard to tell because it has a core library written in C++ and a Python
module to allow video scripts to be created. It came to be when I started
thinking about alternative designs for Avisynth and most of it was written
over a 3 month period.</p>
<p>The software has been heavily inspired by <a href="http://www.avisynth.org/">Avisynth</a>
and aims to be a 21st century rewrite, taking advantage of the advancements
computers have made since the late 90s.
The main features compared to Avisynth are:</p>
<blockquote>
<div><ul>
<li><p>Multithreaded - Frame level multithreading that scales well</p></li>
<li><p>Generalized Colorspaces - New colorspaces can be specified at runtime</p></li>
<li><p>Per Frame Properties - Additional metadata can be attached to frames</p></li>
<li><p>Python Based - The scripting part is implemented as a Python module so you
don’t have to learn a special language</p></li>
<li><p>Support for video with format changes - Some video just can’t stick to one
format or frame size. VapourSynth can handle any kind of change</p></li>
<li><p>Compatible with a large number of already existing Avisynth plugins</p></li>
</ul>
</div></blockquote>
<section id="about-the-author">
<h2>About the author<a href="#about-the-author" title="Permalink to this heading"></a></h2>
<p>Fredrik Mellbin majored in electrical engineering with a focus on image analysis
and processing with medical applications. He has previously worked with digital
electronics and likes to plan his own software projects in his spare time.
When he one day found himself out of work he needed something to do between
sending out job applications and waiting for a reply. The natural choice for
the author was to try to improve Avisynth, the software that once made him
interested in video editing. VapourSynth is the result of all that time waiting.</p>
<p>Feel free to contact me at fredrik.mellbin that round thingy with an a gmail.com
if you need help to port a filter or want to sponsor the development.</p>
</section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Telecom Industry Is Mad Because the FCC Might Examine High Broadband Prices (460 pts)]]></title>
            <link>https://www.techdirt.com/2023/12/12/the-telecom-industry-is-very-mad-because-the-fcc-might-examine-high-broadband-prices/</link>
            <guid>38613552</guid>
            <pubDate>Tue, 12 Dec 2023 15:39:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techdirt.com/2023/12/12/the-telecom-industry-is-very-mad-because-the-fcc-might-examine-high-broadband-prices/">https://www.techdirt.com/2023/12/12/the-telecom-industry-is-very-mad-because-the-fcc-might-examine-high-broadband-prices/</a>, See on <a href="https://news.ycombinator.com/item?id=38613552">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storywrap-427205">


<h3>from the <i>to-the-fainting-couch</i> dept</h3>

<p>We’ve long noted how the FCC (regardless of party) <a href="https://www.techdirt.com/2023/09/20/as-net-neutrality-debate-reheats-remember-the-real-problem-is-telecom-monopoly-power/">largely ignores</a> how muted competition and monopolization drives up prices for consumers. The agency often talks a good (if ambiguous) game about “bridging the digital divide,” but they don’t collect and share pricing data proving market failure, nor are they capable of admitting monopolies exist and are harmful in public-facing messaging.</p>
<p>As part of the Communications Act, the FCC is tasked with giving periodic reports on whether broadband is being delivered to all Americans on a “reasonable and timely basis.” If the answer is no, the regulator is theoretically supposed to, you know, actually do something about it. </p>
<p>Back in November, the agency issued a <a href="https://docs.fcc.gov/public/attachments/FCC-23-89A1.pdf">Notice of Inquiry (NOI)</a> pondering whether they should more seriously analyze the cost of broadband when making those determinations (yes, duh). As per tradition, the FCC NOI is pretty vague about things, but does acknowledge the importance of affordability:</p>
<blockquote>
<p><em>“To truly close the connectivity gap and ensure that all Americans have access to advanced telecommunications capability, broadband services must be affordable.”</em></p>
</blockquote>
<p>Keep in mind this is just the FCC saying they’re <strong>thinking</strong> about taking a more consistent look at high broadband prices as part of their policy approach. It doesn’t mean they’ll actually do it, do it well, or punish any of the companies found to be monopolizing access and squashing competition to jack up market prices. </p>
<p>But even the faint possibility of the FCC looking at expensive U.S. broadband has been enough to <a href="https://arstechnica.com/tech-policy/2023/12/cable-lobby-to-fcc-please-dont-look-too-closely-at-the-prices-we-charge/">send telecom lobbyists into a tizzy</a>, with cable lobbying organizations arguing in filings that <strong>even asking the question</strong> is “inappropriate”:</p>
<blockquote>
<p><em>“While the Commission has reiterated that it has no interest in any kind of rate regulation, the proposal to make a traditional deployment analysis contingent on whether the Commission determines that broadband pricing is sufficiently affordable suggests that rate regulation in some form is potentially on the table.”</em></p>
</blockquote>
<p>The majority of Americans live under a monopoly or duopoly for broadband access protected by state and federal corruption. This muted competition consistently results in spotty coverage, high prices, slow speeds, and comically terrible customer service. And again, FCC officials can’t even openly admit there’s a monopoly/duopoly problem, much less field concrete solutions to the problem.</p>
<p>Keep in mind, between the Trump era and the first two years of Biden term (where the FCC lacked a voting majority due to the <a href="https://www.techdirt.com/2023/03/07/telecom-monopolies-win-again-gigi-sohn-forced-to-withdraw-from-fcc-nomination/">attacks on Gigi Sohn</a>), the FCC was basically a cardboard cutout for <strong>six straight years</strong>. The telecom industry has grown fat and comfortable with the FCC performing regulatory theater where its functions are entirely decorative. A sort of regulatory simulacrum. </p>
<p>The fact that it’s 2023 and the FCC and NTIA have <em>only fairly recently</em> realized they should be considering affordability in broadband access policy genuinely speaks for itself. </p>
<p>And in the U.S., where Comcast, Verizon and AT&amp;T dictate the lion’s share of all telecom policy, the idea of rate regulation is treated as the most extreme possibility imaginable. Having a regulator ponder things like affordable wholesale access or any sort of rate caps is genuinely treated the same way you’d treat a batshit, naked streaker in a public mall. </p>
<p>But the FCC is making it very clear they lack the political backbone to get anywhere near price regulation. The net neutrality restoration similarly <a href="https://www.techdirt.com/2023/09/26/biden-fcc-prepares-to-restore-net-neutrality-but-the-details-will-matter/">makes it very clear</a> that price regulation is off the table. But the simple act of even looking more closely at pricing data — so that the public has a clearer understanding of the impact of muted competition — is apparently a bridge too far for unchecked monopolists. </p>
<p>
Filed Under: <a href="https://www.techdirt.com/tag/broadband/" rel="tag">broadband</a>, <a href="https://www.techdirt.com/tag/broadband-access/" rel="tag">broadband access</a>, <a href="https://www.techdirt.com/tag/broadband-prices/" rel="tag">broadband prices</a>, <a href="https://www.techdirt.com/tag/fcc/" rel="tag">fcc</a>, <a href="https://www.techdirt.com/tag/prices/" rel="tag">prices</a>
<br>
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[23andMe frantically changed its terms of service to prevent customers from suing (731 pts)]]></title>
            <link>https://www.engadget.com/23andme-frantically-changed-its-terms-of-service-to-prevent-hacked-customers-from-suing-152434306.html</link>
            <guid>38613386</guid>
            <pubDate>Tue, 12 Dec 2023 15:27:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.engadget.com/23andme-frantically-changed-its-terms-of-service-to-prevent-hacked-customers-from-suing-152434306.html">https://www.engadget.com/23andme-frantically-changed-its-terms-of-service-to-prevent-hacked-customers-from-suing-152434306.html</a>, See on <a href="https://news.ycombinator.com/item?id=38613386">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main role="main"><div id="module-moreStories" data-wf-sticky-offset="130px   10px" data-wf-sticky-position="" data-wf-sticky-target="#adsStream" data-wf-trigger-percentage=""><ul><li></li><li></li><li></li><li><div><p><img src="https://s.yimg.com/cv/apiv2/default/20190501/placeholder.gif" data-wf-src="https://s.yimg.com/uu/api/res/1.2/4AAmDQc1Hurx05ilepR_1w--~B/Zmk9c3RyaW07aD0yODg7dz01MTQ7YXBwaWQ9eXRhY2h5b24-/https://s.yimg.com/os/creatr-uploaded-images/2022-06/c5bf5d00-e68e-11ec-95df-b648b59c988b" alt=""></p><div><p><span>Engadget</span></p><h4><a data-uuid="5d2d808a-7a1d-45a8-98f3-d598c17a306e" href="https://www.engadget.com/e3-is-officially-dead-153411735.html" data-ylk="elm:hdln;itc:0;pos:1;sec:strm;subsec:moreforyou;cpos:4;ct:story;g:5d2d808a-7a1d-45a8-98f3-d598c17a306e" data-hosted-type="HOSTED">E3 is officially dead</a></h4><p>The long-running video game expo E3 is officially dead. “It’s the right thing to do given the new opportunities our industry has to reach fans and partners," ESA president and CEO Stanley Pierre-Louis said.</p></div></div></li><li></li><li><div><p><img src="https://s.yimg.com/cv/apiv2/default/20190501/placeholder.gif" data-wf-src="https://s.yimg.com/uu/api/res/1.2/4aL3y8ImTGO1pYQXFNt19g--~B/Zmk9c3RyaW07aD0yODg7dz01MTQ7YXBwaWQ9eXRhY2h5b24-/https://s.yimg.com/os/creatr-uploaded-images/2023-12/be2702f0-9899-11ee-8ebf-216ad9982e61" alt=""></p></div></li><li></li><li><div><p><img src="https://s.yimg.com/cv/apiv2/default/20190501/placeholder.gif" data-wf-src="https://s.yimg.com/uu/api/res/1.2/XrkRkC7LMLpCM9QjqA3enQ--~B/Zmk9c3RyaW07aD0yODg7dz01MTQ7YXBwaWQ9eXRhY2h5b24-/https://s.yimg.com/os/creatr-uploaded-images/2021-04/e0b47780-92ed-11eb-bffb-1cf00cf593cb" alt=""></p><div><p><span>Engadget</span></p><h4><a data-uuid="2b641319-47ec-4d6a-b43c-558615f1cffe" href="https://www.engadget.com/best-projectors-123004354.html" data-ylk="elm:hdln;itc:0;pos:1;sec:strm;subsec:moreforyou;cpos:8;ct:story;g:2b641319-47ec-4d6a-b43c-558615f1cffe" data-hosted-type="HOSTED">The best projectors for 2024</a></h4><p>Here's a list of the best projectors you can buy at all price points, as well as tips and tricks for shopping for a projector.</p></div></div></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li><div><p><img src="https://s.yimg.com/cv/apiv2/default/20190501/placeholder.gif" data-wf-src="https://s.yimg.com/uu/api/res/1.2/agdChAB8yfUX9vWgLpE0LA--~B/Zmk9c3RyaW07aD0yODg7dz01MTQ7YXBwaWQ9eXRhY2h5b24-/https://s.yimg.com/os/creatr-uploaded-images/2023-12/9109a0f0-985a-11ee-97ed-23c527178de7" alt=""></p><div><p><span>Engadget</span></p><h4><a data-uuid="324323be-72e4-40f8-85bc-e333267e85c6" href="https://www.engadget.com/timesplitters-studio-free-radical-design-has-shut-down-194718243.html" data-ylk="elm:hdln;itc:0;pos:1;sec:strm;subsec:moreforyou;cpos:19;ct:story;g:324323be-72e4-40f8-85bc-e333267e85c6" data-hosted-type="HOSTED">TimeSplitters studio Free Radical Design has shut down</a></h4><p>Free Radical Design, the company tasked to create a TimeSplitters reboot, has closed its doors. Additionally, the developer’s official website now redirects to a 404 error, along with text reading “company not found” and a sad face.</p></div></div></li><li><div><p><img src="https://s.yimg.com/cv/apiv2/default/20190501/placeholder.gif" data-wf-src="https://s.yimg.com/uu/api/res/1.2/n07QvRJup..4h3lnil806Q--~B/Zmk9c3RyaW07aD0yODg7dz01MTQ7YXBwaWQ9eXRhY2h5b24-/https://s.yimg.com/os/creatr-uploaded-images/2022-08/826785b0-296d-11ed-aeb1-d30d9e5ff594" alt=""></p><div><p><span>Engadget</span></p><h4><a data-uuid="e9f1a4a2-1a52-461c-91e1-85eb7e19f509" href="https://www.engadget.com/best-fast-chargers-140011033.html" data-ylk="elm:hdln;itc:0;pos:1;sec:strm;subsec:moreforyou;cpos:20;ct:story;g:e9f1a4a2-1a52-461c-91e1-85eb7e19f509" data-hosted-type="HOSTED">The best fast chargers for 2024</a></h4><p>In order to figure out what the fastest charger on the market is across a range of power outputs, we tested 14  adapters across five different devices. Here are the results.</p></div></div></li></ul></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Active turbulence cancellation makes bumpy flights 80% smoother (221 pts)]]></title>
            <link>https://newatlas.com/aircraft/active-turbulence-cancellation/</link>
            <guid>38613280</guid>
            <pubDate>Tue, 12 Dec 2023 15:19:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newatlas.com/aircraft/active-turbulence-cancellation/">https://newatlas.com/aircraft/active-turbulence-cancellation/</a>, See on <a href="https://news.ycombinator.com/item?id=38613280">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Austrian company Turbulence Solutions claims it's already flight-testing a system that can detect and neutralize air turbulence, reducing the forces felt by passengers by up to 80% – and reducing fuel burn by up to 10%. It's set to launch in 2024. </p><p>Nobody likes to fly through turbulence – which is tough luck, because climate change has <a href="https://www.bbc.com/news/science-environment-65844901" target="_blank" data-cms-ai="0">already caused it to increase by as much as 55%</a> on some popular routes, and it's projected to continue getting worse as temperatures rise, bringing wind speeds and thus wind shear along with them. </p><p>Where it can be accurately predicted, airliners will often go out of their way to go around it, hoping to avoid a whole lot of passenger distress as well as showers of vomit. But in clear air, it's nigh-on impossible to spot turbulence until you're in the middle of it, guts in your throat and praying for a quick death. </p><p>Enter Turbulence Solutions, which claims to have built and tested something that solves the problem, acting a little like an active noise cancellation system in a pair of headphones. Effectively, it detects turbulence just before it happens, and uses super-quick automated lift adjustment through the aircraft's control surfaces to generate forces in opposition to the turbulence. </p><div data-align-center="">
                
                    <figure>
    
    
    
    


<p><img alt="Unmanned test aircraft" width="967" height="599" data-image-size="articleImage" loading="lazy" data-srcset="https://assets.newatlas.com/dims4/default/6ec2a58/2147483647/strip/true/crop/967x599+0+0/resize/440x273!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fc7%2Fe3%2Fa02c22154695b7c9f29d016800fe%2F13272-2021-512-fig7-html.jpg 440w,https://assets.newatlas.com/dims4/default/3d41bd7/2147483647/strip/true/crop/967x599+0+0/resize/800x496!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fc7%2Fe3%2Fa02c22154695b7c9f29d016800fe%2F13272-2021-512-fig7-html.jpg 800w,https://assets.newatlas.com/dims4/default/044a4e9/2147483647/strip/true/crop/967x599+0+0/resize/1200x743!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fc7%2Fe3%2Fa02c22154695b7c9f29d016800fe%2F13272-2021-512-fig7-html.jpg 1200w,https://assets.newatlas.com/dims4/default/8edcba6/2147483647/strip/true/crop/967x599+0+0/resize/1920x1189!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fc7%2Fe3%2Fa02c22154695b7c9f29d016800fe%2F13272-2021-512-fig7-html.jpg 1920w" data-src="https://assets.newatlas.com/dims4/default/3588880/2147483647/strip/true/crop/967x599+0+0/resize/967x599!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fc7%2Fe3%2Fa02c22154695b7c9f29d016800fe%2F13272-2021-512-fig7-html.jpg" sizes="(min-width: 1240px) 800px, (min-width: 1024px) 95vw, 100vw" srcset="https://assets.newatlas.com/dims4/default/6ec2a58/2147483647/strip/true/crop/967x599+0+0/resize/440x273!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fc7%2Fe3%2Fa02c22154695b7c9f29d016800fe%2F13272-2021-512-fig7-html.jpg 440w,https://assets.newatlas.com/dims4/default/3d41bd7/2147483647/strip/true/crop/967x599+0+0/resize/800x496!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fc7%2Fe3%2Fa02c22154695b7c9f29d016800fe%2F13272-2021-512-fig7-html.jpg 800w,https://assets.newatlas.com/dims4/default/044a4e9/2147483647/strip/true/crop/967x599+0+0/resize/1200x743!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fc7%2Fe3%2Fa02c22154695b7c9f29d016800fe%2F13272-2021-512-fig7-html.jpg 1200w,https://assets.newatlas.com/dims4/default/8edcba6/2147483647/strip/true/crop/967x599+0+0/resize/1920x1189!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fc7%2Fe3%2Fa02c22154695b7c9f29d016800fe%2F13272-2021-512-fig7-html.jpg 1920w" src="https://assets.newatlas.com/dims4/default/3588880/2147483647/strip/true/crop/967x599+0+0/resize/967x599!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Fc7%2Fe3%2Fa02c22154695b7c9f29d016800fe%2F13272-2021-512-fig7-html.jpg">
</p>



    
    

    
        <div><figcaption itemprop="caption">Unmanned test aircraft</figcaption><p>Turbulence Solutions</p></div>
    
</figure>

                
            </div><p>To predict what's about to hit the wings, the system uses 5-hole differential air pressure probes, mounted as far forward as possible. On the unmanned testbed above, for example, the company placed a pair of lightweight rails on front of the aircraft, holding up a third rail with the pressure sensors held out nearly as far as the wing tips. </p><p>On the manned test aircraft, the sensors were instead mounted directly to the wings, on long pole masts that placed them some 2.65 m (8.69 ft) forward of the leading edges. At cruise speed, that's enough to give the system a tenth of a second's worth of advance warning before turbulence hits – and according to a paper published by the <i><a href="https://link.springer.com/article/10.1007/s13272-021-00512-y" target="_blank" data-cms-ai="0">CEAS Aeronautical Journal</a></i> in 2021, the system was able to predict vertical accelerations greater than 30 m/sec/sec with an accuracy of nearly 62% on its very first test flight, and it's doubtless improved since then. </p><div data-align-center="">
                
                    <figure>
    
    
    
    


<p><img alt="Pressure sensors in front of the wings give the system a fraction of a second to respond to turbulence" width="1179" height="701" data-image-size="articleImage" loading="lazy" data-srcset="https://assets.newatlas.com/dims4/default/523c0ed/2147483647/strip/true/crop/1179x701+0+0/resize/440x262!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F65%2F24%2F05eece844b59a0b0f948be096723%2Fscreenshot-2023-12-11-at-7.11.51%20pm.png 440w,https://assets.newatlas.com/dims4/default/be53860/2147483647/strip/true/crop/1179x701+0+0/resize/800x476!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F65%2F24%2F05eece844b59a0b0f948be096723%2Fscreenshot-2023-12-11-at-7.11.51%20pm.png 800w,https://assets.newatlas.com/dims4/default/43e38b1/2147483647/strip/true/crop/1179x701+0+0/resize/1200x713!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F65%2F24%2F05eece844b59a0b0f948be096723%2Fscreenshot-2023-12-11-at-7.11.51%20pm.png 1200w,https://assets.newatlas.com/dims4/default/3665d44/2147483647/strip/true/crop/1179x701+0+0/resize/1920x1142!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F65%2F24%2F05eece844b59a0b0f948be096723%2Fscreenshot-2023-12-11-at-7.11.51%20pm.png 1920w" data-src="https://assets.newatlas.com/dims4/default/35359f2/2147483647/strip/true/crop/1179x701+0+0/resize/1179x701!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F65%2F24%2F05eece844b59a0b0f948be096723%2Fscreenshot-2023-12-11-at-7.11.51%20pm.png" sizes="(min-width: 1240px) 800px, (min-width: 1024px) 95vw, 100vw" srcset="https://assets.newatlas.com/dims4/default/523c0ed/2147483647/strip/true/crop/1179x701+0+0/resize/440x262!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F65%2F24%2F05eece844b59a0b0f948be096723%2Fscreenshot-2023-12-11-at-7.11.51%20pm.png 440w,https://assets.newatlas.com/dims4/default/be53860/2147483647/strip/true/crop/1179x701+0+0/resize/800x476!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F65%2F24%2F05eece844b59a0b0f948be096723%2Fscreenshot-2023-12-11-at-7.11.51%20pm.png 800w,https://assets.newatlas.com/dims4/default/43e38b1/2147483647/strip/true/crop/1179x701+0+0/resize/1200x713!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F65%2F24%2F05eece844b59a0b0f948be096723%2Fscreenshot-2023-12-11-at-7.11.51%20pm.png 1200w,https://assets.newatlas.com/dims4/default/3665d44/2147483647/strip/true/crop/1179x701+0+0/resize/1920x1142!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F65%2F24%2F05eece844b59a0b0f948be096723%2Fscreenshot-2023-12-11-at-7.11.51%20pm.png 1920w" src="https://assets.newatlas.com/dims4/default/35359f2/2147483647/strip/true/crop/1179x701+0+0/resize/1179x701!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2F65%2F24%2F05eece844b59a0b0f948be096723%2Fscreenshot-2023-12-11-at-7.11.51%20pm.png">
</p>



    
    

    
        <div><figcaption itemprop="caption">Pressure sensors in front of the wings give the system a fraction of a second to respond to turbulence</figcaption><p>Turbulence Solutions</p></div>
    
</figure>

                
            </div><p>Armed with this information, the flight control system now has a tenth of a second to generate a force-canceling response at each wing, by deftly actuating low-inertia lift surfaces. In this way, the system is able to iron out vertical accelerations, pitch and roll changes, and wing bending moments. The Turbulence Solutions team claims it currently cuts down the effects of turbulence in the cabin by around 80%.</p><p>You can see the system going bonkers to smooth out a bumpy manned test flight in the video below.</p><div data-video-disable-history="" data-align-center="">
    
        <p><ps-youtubeplayer data-video-player="" data-player-id="f497e6d32cbcc4106975dbbd640e3032a" data-video-id="4UfmsqtTGa0" data-video-title="Turbulence Cancelling Intro">

    <iframe id="YouTubeVideoPlayer-f497e6d32cbcc4106975dbbd640e3032a" role="application" title="YouTube embedded video player" allowfullscreen="" loading="lazy" src="https://www.youtube.com/embed/4UfmsqtTGa0?enablejsapi=1"></iframe>
</ps-youtubeplayer>
</p>
    
    
        <p>Turbulence Cancelling Intro</p>
    
</div><p>In an interview with <i><a href="https://interestingengineering.com/innovation/turbulence-solutions-aviation-industry-free" target="_blank" data-cms-ai="0">Interesting Engineering</a></i>, a company representative said it also enables significant fuel savings of up to 10%, since aircraft no longer need to climb, dive, or route around turbulence. That's nothing to sniff at.</p><p>The company says it'll have a system commercially available for light aircraft in 2024. It's looking into a version for eVTOL air taxis by 2026, and hoping to have a system relevant to commercial airliners by 2030. Godspeed, team, the world's airline passengers – not to mention cleaning crews – need you to succeed. </p><div data-video-disable-history="" data-align-center="">
    
        <p><ps-youtubeplayer data-video-player="" data-player-id="f45793a9847f042a0ba965a24666e7ba9" data-video-id="9qydsN_acDs" data-video-title="Turbulence Solutions - Making flights turbulence-free">

    <iframe id="YouTubeVideoPlayer-f45793a9847f042a0ba965a24666e7ba9" role="application" title="YouTube embedded video player" allowfullscreen="" loading="lazy" src="https://www.youtube.com/embed/9qydsN_acDs?enablejsapi=1"></iframe>
</ps-youtubeplayer>
</p>
    
    
        <p>Turbulence Solutions - Making flights turbulence-free</p>
    
</div><p>Source: <a href="https://turbulence-solutions.aero/technology/" target="_blank" data-cms-ai="0">Turbulence Solutions</a> via <i><a href="https://interestingengineering.com/innovation/turbulence-solutions-aviation-industry-free" target="_blank" data-cms-ai="0">Interesting Engineering</a></i></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FFmpeg Lands CLI Multi-Threading as Its "Most Complex Refactoring" in Decades (556 pts)]]></title>
            <link>https://www.phoronix.com/news/FFmpeg-CLI-MT-Merged</link>
            <guid>38613219</guid>
            <pubDate>Tue, 12 Dec 2023 15:15:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.phoronix.com/news/FFmpeg-CLI-MT-Merged">https://www.phoronix.com/news/FFmpeg-CLI-MT-Merged</a>, See on <a href="https://news.ycombinator.com/item?id=38613219">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><img alt="MULTIMEDIA" src="https://www.phoronix.com/assets/categories/multimedia.webp" width="100" height="100"></p><p>
The long-in-development work for <a href="https://www.phoronix.com/news/FFmpeg-CLI-Multi-Threaded">a fully-functional multi-threaded FFmpeg command line</a> has been merged! The FFmpeg CLI with multi-threaded transcoding pipelines is now merged to FFmpeg Git ahead of FFmpeg 7.0 releasing early next year. FFmpeg is widely-used throughout many industries for video transcoding and in today's many-core world this is a terrific improvement for this key open-source project.
</p><p>
In recently sharing a technical presentation on the FFmpeg multi-threading effort, FFmpeg developers <a href="https://twitter.com/FFmpeg/status/1731288541395587411">called</a> this work "<em>one of the most complex refactoring of the FFmpeg CLI in decades.</em>" And in calling for testing today <a href="https://twitter.com/FFmpeg/status/1734572553836851252">added</a>, "<em>Please test and report issues to [FFmpeg Trac] - this is one of the most complex changes in FFmpeg ever!</em>"
</p><p>
The code is now in <a href="https://github.com/FFmpeg/FFmpeg/commits/master">FFmpeg Git</a>. The patches include adding the thread-aware transcode scheduling infrastructure, moving encoding to a separate thread, and various other low-level changes. In culminating with converting FFmpeg to a threaded architecture is summed up as:
</p><blockquote>fftools/ffmpeg: convert to a threaded architecture
<p>
Change the main loop and every component (demuxers, decoders, filters, encoders, muxers) to use the previously added transcode scheduler. Every instance of every such component was already running in a separate thread, but now they can actually run in parallel.</p></blockquote>
<p><img src="https://www.phoronix.net/image.php?id=2023&amp;image=ffmpeg_cli_multithread" alt="FFmpeg threading"></p>
<p>There's a recent <a href="https://up.khirnov.net/7m.pdf">presentation</a> on this work by developer Anton Khirnov.
</p><p>
It's terrific seeing this merged and will be interesting to see the performance impact in practice.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Forget spaceships; I just want my music (241 pts)]]></title>
            <link>https://www.jeffgeerling.com/blog/2023/forget-spaceships-i-just-want-my-music</link>
            <guid>38613154</guid>
            <pubDate>Tue, 12 Dec 2023 15:10:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jeffgeerling.com/blog/2023/forget-spaceships-i-just-want-my-music">https://www.jeffgeerling.com/blog/2023/forget-spaceships-i-just-want-my-music</a>, See on <a href="https://news.ycombinator.com/item?id=38613154">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>A couple weeks ago, as my kids settled into the car, I asked like I always do, "what songs do you want me to play?"</p>

<p>They have a range of favored earworms, from Baby Shark to Babaloo, and usually the songs are tolerable, at least.</p>

<p>But a few albums, like Bluey's soundtrack, transcend the children's genre. They're genuinely fun to listen to, for everyone in the car.</p>

<p>Well, that fine day, the kids chose Ladybug Music. And let me tell you, besides a few duds, Ladybug Music <em>slaps</em>. And the songs incorporate diverse styles, too, it's not just the same nursery rhymes regurgitated in a bubbly voice.</p>

<p>So I found the album on my phone and noticed the songs were all greyed out.</p>

<p>I tapped one, and <em>nothing</em>. Just this notice:</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/song-not-available.jpg" width="700" height="auto" alt="Song not available Apple Music on iPhone"></p>

<p>Not available in my region? Well, that's weird. I pay for Apple Music. And I know the artist is in the US, and <em>I'm</em> in the US...</p>

<p>But my kids were restless, and we had somewhere to be, so I put on Pinkfong for the drive. After I got home, I went online to investigate.</p>

<blockquote>
  <p>This blog post is a transcript of <a href="https://www.youtube.com/watch?v=7CDKvdlD6uQ">this video on my YouTube channel</a>.</p>
</blockquote>

<p>Unfortunately, Ladybug music isn't a huge artist, so there wasn't any news coverage, like "thousands of parents cry out as their favorite kids songs disappear from Apple Music!"</p>

<p>But I <em>did</em> find the <a href="https://ladybugmusic.com/">Ladybug Music website</a>.</p>

<p>And on that website, they have a <a href="https://ladybugmusic.com/shop/">shop</a>. Great! I can just buy the CDs, and support the artist directly!</p>

<p>And... no. Apparently Ladybug music is now an app. So I downloaded the App! Long story short, I created an account, and found out you either have to fly to LA and join one of the in-person kids music courses, or pay <a href="https://ladybugmusic.com/licensing-application/">$3000 in licensing fees</a> to get access to any of the songs.</p>

<blockquote>
  <p><strong>Note</strong>: I've also reached out to Ladybug Music using their contact form to ask about any other way to purchase the music, and have received no response.</p>
</blockquote>

<p>No bueno.</p>

<p>Scrounging around, you can get a few free songs from their YouTube or Soundcloud, and on Amazon a couple of used CDs are floating around... but there's literally no way to buy the music online anymore!</p>

<p>This isn't the first time I've seen a song disappear from Apple Music. And this kind of thing happens on Spotify and other streaming services too.</p>

<p>I can't get <em>too</em> mad, because I never actually "bought" those songs directly. I just rented them. That's the model for video streaming too, like on Netflix. Even though it's <em>super</em> annoying to have shows and music disappear, I <em>am</em> renting, so it's not like I have a <em>right</em> to anything.</p>

<h2>Playstation</h2>

<p>But that's just streaming. Luckily, you can also <em>buy</em> digital movies and music, and you get to keep it.</p>

<p>Right?</p>

<p><em>Right?</em></p>

<p>Wrong.</p>

<p>Enshittification has reached new heights, as <a href="https://arstechnica.com/gadgets/2023/12/playstation-is-erasing-1318-seasons-of-discovery-shows-from-customer-libraries/">Sony just decided to yoink over a <em>thousand seasons</em></a>—that's right, <em>seasons</em>, not <em>episodes</em>—of Discovery shows from the PlayStation Store.</p>

<p>But they're not just removing them from the <em>store</em>.</p>

<p>They're removing them from people's <em>libraries</em>.</p>

<blockquote>
  <p>As of 31 December 2023, due to our content licensing arrangements with content providers, you will no longer be able to watch any of your previously purchased Discovery content and the content will be removed from your video library. (<a href="https://www.playstation.com/en-us/legal/psvideocontent/">Source</a>)</p>
</blockquote>

<p>So if you paid full retail price for Mythbusters on your PlayStation, too bad. You can't watch it anymore.</p>

<p>That is, unless you go over and set up a new subscription to yet another completely unneccessary and broken streaming service from Warner Brothers.</p>

<p>The term for that is <a href="https://en.wikipedia.org/wiki/Enshittification"><em>enshittification</em></a>.</p>

<p>I'm not gonna rehash <a href="https://pluralistic.net/2023/12/08/playstationed/#tyler-james-hill">everything Cory Doctorow wrote</a> about this latest assault on digital ownership, but I'll summarize a few of the main things that get under my skin.</p>

<p>First, the headline: "If buying isn't owning, than piracy isn't stealing."</p>

<p>I made a whole video about <a href="https://www.youtube.com/watch?v=4VkY1vTpCJY">how I manage all my video content on my NAS</a>. I run software called Jellyfin, and I've ripped <em>hundreds</em> of movies and <em>thousands</em> of TV episodes over the years. My family can enjoy every movie and TV show I've bought, now and forever.</p>

<p>But <em>most</em> people don't do that. And even for crazies like me, it's getting harder. More and more TV series and movies are going stream-only.</p>

<p>Meaning the <em>only</em> way to ever watch it is to subscribe to yet another broken and temporary streaming service.</p>

<p>You'd think as the years wore on, society's access to media would get easier and better.</p>

<p>But instead, backwards-thinking execs in Hollywood and the music industry keep backpedaling, making it <em>harder</em> for you to actually watch the content they produce.</p>

<p>I mean, more and more of it is garbage anyway, but there are still compelling shows and movies out there. It's a shame they're committed to being so anti-consumer by killing off any semblance of ownership.</p>

<p>In my video about Jellyfin, I danced around the issue of piracy. Mostly because I know how pernicious the MPAA and RIAA are.</p>

<p>Well, you know what? I still don't officially endorse pirating content. But if there's literally <em>no other way</em> to view the content you already paid for? Who am I to judge?</p>

<p>And cracking DRM? First of all, it's <em>laughable</em> how bad DRM normally is. But second, DRM is the enabler of all the horrible, scummy business practices that lead to so much e-waste, <em>and</em> to kids being disappointed in their Dad for not being able to play music that's been available digitally for years.</p>

<p>So if you crack DRM to truly own the things you already paid for? Yeah, I don't got a problem with that.</p>

<p>Forget spaceships flying to Mars, I just want my music.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[E3 Is Officially Dead (271 pts)]]></title>
            <link>https://www.washingtonpost.com/entertainment/video-games/2023/12/12/e3-permanently-canceled/</link>
            <guid>38612779</guid>
            <pubDate>Tue, 12 Dec 2023 14:45:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/entertainment/video-games/2023/12/12/e3-permanently-canceled/">https://www.washingtonpost.com/entertainment/video-games/2023/12/12/e3-permanently-canceled/</a>, See on <a href="https://news.ycombinator.com/item?id=38612779">Hacker News</a></p>
Couldn't get https://www.washingtonpost.com/entertainment/video-games/2023/12/12/e3-permanently-canceled/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[NASA says SpaceX’s next Starship flight could test refueling tech (117 pts)]]></title>
            <link>https://arstechnica.com/space/2023/12/nasa-wants-to-see-gas-stations-in-space-but-so-far-its-tanks-are-empty/</link>
            <guid>38612585</guid>
            <pubDate>Tue, 12 Dec 2023 14:32:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/space/2023/12/nasa-wants-to-see-gas-stations-in-space-but-so-far-its-tanks-are-empty/">https://arstechnica.com/space/2023/12/nasa-wants-to-see-gas-stations-in-space-but-so-far-its-tanks-are-empty/</a>, See on <a href="https://news.ycombinator.com/item?id=38612585">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <h4>
      Development risk    —
</h4>
            
            <h2 itemprop="description">SpaceX appears on track for at least a preliminary propellant transfer test next year.</h2>
                    </header>
        <section>
            <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/ship28-1-800x493.jpg" alt="A crane is attached to one of several Starship test vehicles at SpaceX's Starbase facility in South Texas. This vehicle, called Ship 28, could launch on the next Starship test flight.">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/12/ship28-1.jpg" data-height="1109" data-width="1800">Enlarge</a> <span>/</span> A crane is attached to one of several Starship test vehicles at SpaceX's Starbase facility in South Texas. This vehicle, called Ship 28, could launch on the next Starship test flight.</p></figcaption>  </figure>

  




<!-- cache hit 726:single/related:d0f092005b4cf203102681adac7cdcb4 --><!-- empty -->
<p>SpaceX and NASA could take a tentative step toward orbital refueling on the next test flight of Starship, but the US space agency says officials haven't made a final decision on when to begin demonstrating cryogenic propellant transfer capabilities that are necessary to return astronauts to the Moon.</p>
<p>NASA is keen on demonstrating orbital refueling technology, an advancement that could lead to propellant depots in space to feed rockets heading to distant destinations beyond Earth orbit. In 2020, <a href="https://arstechnica.com/science/2020/10/nasa-makes-a-significant-investment-in-on-orbit-spacecraft-refueling/">NASA announced agreements with four companies</a>—Lockheed Martin, United Launch Alliance, SpaceX, and a Florida-based startup named Eta Space—to prove capabilities in the area of refueling and propellant depots using cryogenic propellants.</p>
<p>These cryogenic fluids—liquid hydrogen, methane, and liquid oxygen—must be kept at temperatures of several hundred degrees below zero, or they turn into a gas and boil off. Russian supply freighters regularly refuel the International Space Station with hydrazine and nitrogen tetroxide, room-temperature rocket propellants that can be stored for years in orbit, but rockets using more efficient super-cold propellants have typically needed to complete their missions within hours.</p>
<p>NASA and industry engineers want to extend this lifetime to days, weeks, or months, but this requires new technologies to maintain the propellants at cryogenic temperature and, in some cases like Starship, to transfer the propellants from one vehicle to another.</p>
<p>NASA and several companies are funding efforts in this area, called cryogenic fluid management. NASA's agreements from 2020 committed more than $250 million in government funding for cryogenic fluid management tests in space. These funding agreements announced in October 2020, called "Tipping Point" awards, require substantial private funding from the companies participating in the demonstrations.</p>
<p>According to John Dankanich, who leads NASA's efforts in developing new capabilities for in-space transportation, there are "major technical obstacles" for cryogenic fluid management. The real challenge, he said, will be in validating things like automated couplers, flow meters, and advanced insulation to all work together in microgravity. These, along with other technologies, are "highly interdependent" on one another to make cryogenic refueling a reality, he said.</p>                                            
                                                        
<p>Individual technologies necessary for in-orbit cryogenic refueling are at a stage of development where they are "ready now to go into flight systems," Dankanich said, either with a demonstration in space or on an operational spacecraft.</p>
<h2>First, small steps</h2>
<p>By the fourth anniversary of those awards, only SpaceX appears to have a chance to complete the tasks outlined in its "Tipping Point" award, valued at $53 million.</p>
<p>This test would involve transferring super-cold propellant from one tank to another inside a Starship spacecraft. It's a precursor to future, more complex demonstrations involving two giant Starships docked together in Earth orbit. Then SpaceX will be ready to send a Starship toward the Moon for a test landing without astronauts onboard. Once that is successful, NASA will clear Starship for a crew landing on the agency's Artemis III mission, marking the astronauts' return to the lunar surface for the first time since 1972.</p>
<p>That's easier said than done; all worthy projects require a first step. That could happen as soon as the next full-scale test flight of SpaceX's gigantic Super Heavy booster and Starship rocket, a stainless steel launcher that stands nearly 400 feet (121 meters) tall. SpaceX has flown the rocket twice, <a href="https://arstechnica.com/space/2023/11/spacex-can-celebrate-three-big-wins-after-second-starship-test-flight/">most recently on November 18</a>, when the Starship upper stage reached space for the first time before self-destructing just short of orbital velocity. This <a href="https://arstechnica.com/space/2023/11/heres-why-this-weekends-starship-launch-was-actually-a-huge-success/">test flight was largely successful</a>, achieving several key milestones, such as stage separation and demonstrating improved reliability of the rocket's methane-fueled Raptor engines.</p>
<p>SpaceX has a $2.9 billion contract with NASA to provide a commercial Human Landing System (HLS) derived from Starship for the Artemis III mission, the first human landing mission planned during NASA's Artemis program. The readiness of the Starship landing craft and new commercial spacesuits are <a href="https://arstechnica.com/space/2023/12/government-watchdog-says-first-artemis-lunar-landing-may-slip-to-2027/">widely seen as drivers of the schedule for Artemis III</a>, which is at risk of a delay from late 2025.</p>
<p>Lakiesha Hawkins, deputy associate administrator for NASA's Moon to Mars program office, discussed the Artemis schedule Monday with a committee from the National Academies charged with reviewing the agency's workforce, infrastructure, and technology programs.</p>
<p>Hawkins did not verbally address SpaceX's plans for the next Starship test flight, but one of her slides noted SpaceX is "moving quickly" toward the third Super Heavy/Starship launch and that this flight "will include a propellant transfer demonstration."</p>

                                                </div>

            
            
                            <nav>Page: <span>1 <a href="https://arstechnica.com/space/2023/12/nasa-wants-to-see-gas-stations-in-space-but-so-far-its-tanks-are-empty/2/">2</a> <a href="https://arstechnica.com/space/2023/12/nasa-wants-to-see-gas-stations-in-space-but-so-far-its-tanks-are-empty/2/"><span>Next <span>→</span></span></a></span></nav>
            
        </section>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Role-playing with AI will be a powerful tool for writers and educators (109 pts)]]></title>
            <link>https://resobscura.substack.com/p/roleplaying-with-ai-will-be-powerful-tool</link>
            <guid>38612164</guid>
            <pubDate>Tue, 12 Dec 2023 14:02:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://resobscura.substack.com/p/roleplaying-with-ai-will-be-powerful-tool">https://resobscura.substack.com/p/roleplaying-with-ai-will-be-powerful-tool</a>, See on <a href="https://news.ycombinator.com/item?id=38612164">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h4 translated="">Discover more from Res Obscura</h4><p>Notes on the history of technology, medicine, science, art, drugs, and empire from UC Santa Cruz history professor Benjamin Breen. Also: using AI in research and teaching.</p><p>Over 2,000 subscribers</p> </div><div dir="auto"><p><span>The mid-January publication day for my book </span><em><a href="https://www.amazon.com/Tripping-Utopia-Margaret-Troubled-Psychedelic/dp/1538722372?_encoding=UTF8&amp;tag=ro067-20&amp;linkCode=ur2&amp;linkId=ba347f678c5238772f23489f5065baa6&amp;camp=1789&amp;creative=9325" rel="">Tripping on Utopia</a><span> </span></em><span>is fast approaching, and I will have some exciting news to share about book publicity and advance reviews soon. But for now, I am going to return to a topic that has been on my mind over the past year — using generative AI as a kind of </span><a href="https://resobscura.substack.com/p/simulating-history-with-chatgpt" rel="">history simulator</a><span> — and try it it out directly on my book’s content. </span></p><p><span>In fact, I’ve tested it on the content of </span><em>both</em><span> my books: the first, </span><em><a href="https://www.amazon.com/Age-Intoxication-Origins-Global-Americas/dp/0812224981/ref=tmm_pap_swatch_0?_encoding=UTF8&amp;qid=&amp;sr=" rel="">The Age of Intoxication</a></em><span>, focused on the global trade in drugs, spices, and medicines in the 17th and 18th centuries. </span><em><a href="https://www.amazon.com/Tripping-Utopia-Margaret-Troubled-Psychedelic/dp/1538722372?_encoding=UTF8&amp;tag=ro067-20&amp;linkCode=ur2&amp;linkId=ba347f678c5238772f23489f5065baa6&amp;camp=1789&amp;creative=9325" rel="">Tripping on Utopia</a><span> </span></em><span>is a deep dive into the first era of psychedelic science, focusing particularly on the anthropologist Margaret Mead and the psychedelic researchers of the 1950s. </span></p><p><span>I’ll describe some highlights below, but if you want to see the complete “transcript” of a simulated experience and setting which was directly inspired by a source I used in </span><em>Tripping on Utopia, </em><span>you can find it here: </span></p><div data-component-name="DigestPostEmbed"><a href="https://resobscura.substack.com/p/how-well-can-gpt-4-simulate-an-acid" target="_blank" rel="noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8b3e28d-13ef-426c-b0e1-5e65c6a6cae9_1469x1289.png"><img src="https://substackcdn.com/image/fetch/w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb8b3e28d-13ef-426c-b0e1-5e65c6a6cae9_1469x1289.png" sizes="100vw" alt="Simulating an LSD trip in 1963 with GPT-4" width="140" height="140"></picture></div></a></div><p><span>It’s understandable that some writers and historians think of generative AI as a competitor. After all, AI-produced books are already showing up on Amazon. It’s only a matter of time before the first AI-generated YouTube series takes off — and the first #1 hit single written and performed entirely by AI, and all the rest. I am not happy at this prospect either. But unlike some, I don’t think that this is the only future path available to us. I’m fascinated by the prospect of generative AI not as a </span><em>replacement </em><span>for human authors, but as a tool for allowing us to actively explore and engage with alternative versions of the world. </span></p><p>For instance, the world of a novel that an author is in the process of writing, or the vanished worlds of the past that historians like me spend our time researching and describing. </p><p><span>Educators call this </span><em>experiential learning</em><span>. And increasingly, I think various forms of experiential learning will end up being the most lasting and powerful use cases for the current wave of AI systems. </span></p><p><span>I now  have some preliminary data to support what had, before, mostly been a hunch about the potential effectiveness of AI historical simulations. During the fall quarter, I employed versions of the historical simulation activity I described in </span><a href="https://resobscura.substack.com/p/simulating-history-with-chatgpt" rel="">this previous post</a><span> in the world history class I have been teaching at UCSC. </span></p><p>I then asked my students to complete an anonymous survey about how these activities impacted their learning. Here is one striking result from that survey: </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd5d65a1-4766-44f2-b575-d652cfffa647_1318x554.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd5d65a1-4766-44f2-b575-d652cfffa647_1318x554.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd5d65a1-4766-44f2-b575-d652cfffa647_1318x554.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd5d65a1-4766-44f2-b575-d652cfffa647_1318x554.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd5d65a1-4766-44f2-b575-d652cfffa647_1318x554.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd5d65a1-4766-44f2-b575-d652cfffa647_1318x554.png" width="1318" height="554" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bd5d65a1-4766-44f2-b575-d652cfffa647_1318x554.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:554,&quot;width&quot;:1318,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:87560,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd5d65a1-4766-44f2-b575-d652cfffa647_1318x554.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd5d65a1-4766-44f2-b575-d652cfffa647_1318x554.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd5d65a1-4766-44f2-b575-d652cfffa647_1318x554.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbd5d65a1-4766-44f2-b575-d652cfffa647_1318x554.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>When given a list to choose from, 71% of the students surveyed said “ability to make choices and decisions as historical actors” was most beneficial to their learning in their class. And fully </span><strong>84% of the class</strong><span> reported that AI historical simulations “greatly” or “somewhat” enhanced their overall understanding of the time period. </span></p><p>Of course, the paramount problem is that of accuracy: the simulation needs to accurately reflect the historical record in order to be truly effective as a learning tool. I think this problem can be overcome, but it isn’t solved yet. For now, I am making sure to tell my students that the simulations they experience will contain numerous historical inaccuracies. In fact, I make the act of discussing, fact checking, and reflecting on these inaccuracies a key part of the activity itself. Thinking about the unreliability of sources, after all, is a big part of what historians do. </p><p><span>But what about the more solitary domain of creatively imagining another world? When writing </span><em>Tripping on Utopia, </em><span>I spent a great deal of time figuring out the chronology of events, fact checking claims, determining the relationships between different people, and other forms of historical analysis that require rigor and factual clarity. But I </span><em>also </em><span>spent a lot of my time doing what might best be described as day dreaming. Some of the things on my mind while writing the book: </span></p><ul><li><p>What’s it like to have a malarial fever?</p></li><li><p>Would it be too loud to conduct a conversation while sitting in the back of a motorized canoe in 1933? </p></li><li><p>What are some possible explanations for why Margaret Mead initially volunteered to be a test subject in an LSD trial in 1954, and then pulled out? </p></li><li><p>What would it feel like to be a volunteer in an early psychedelic experiment?  </p></li></ul><p>These are, for lack of a better word, the more “vibes-based” elements of writing history. You can certainly make informed guesses based on the historical record —&nbsp;but you also, necessarily, need to add your own imagination to the task, too. </p><p><span>Generative AI cannot give answers to the questions above. But it can help kickstart the tiny acts of historical imagination and empathy that are so important in writing and teaching history. To get a practical sense of what I mean by this, you can </span><a href="https://resobscura.substack.com/p/how-well-can-gpt-4-simulate-an-acid" rel="">read through this transcript of a simulated acid trip in 1963</a><span>. The participant, a 32-year-old artist named Leo Mitchell, is fictional, and there are numerous obvious inaccuracies (for instance, his “inventory” includes a tiny bottle of LSD pills —&nbsp;but of course, a volunteer would never have walked into a study of an experimental drug with that drug already in hand!) </span></p><p>Nevertheless, there's a lot here that I found useful as a historian. For instance, the emphasis on the ambient environment and physical sensations. Leo feels “a flutter of nervous excitement in his stomach” as he enters the Los Angeles Neuropsychiatric  Hospital to begin his LSD trial on an October morning in 1963. He notices “the soft hum of the hospital's air system.” As the pill kicks in, “the once calming shadows” dancing on the wall “seem to take on a more menacing quality.”</p><p>I found the visual results of the simulation, which were produced by DALLE-3 based on the scenes described, to be similarly evocative. For instance, this one showing Leo staring at his hand in the hallway nicely evoked the clinical backdrop of so many psychedelic studies of the era:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F880be93f-69af-45ff-8f6f-a9777d3ac09c_1024x1024.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F880be93f-69af-45ff-8f6f-a9777d3ac09c_1024x1024.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F880be93f-69af-45ff-8f6f-a9777d3ac09c_1024x1024.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F880be93f-69af-45ff-8f6f-a9777d3ac09c_1024x1024.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F880be93f-69af-45ff-8f6f-a9777d3ac09c_1024x1024.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F880be93f-69af-45ff-8f6f-a9777d3ac09c_1024x1024.webp" width="1024" height="1024" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/880be93f-69af-45ff-8f6f-a9777d3ac09c_1024x1024.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1024,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Full-color Leica photograph from October 14, 1963, inside UCLA's Neuropsychiatric Hospital's session room. In sharp focus is the hand of a person, displaying part of a gray button-down shirt sleeve. In the softly lit background, an out-of-focus nurse is seen leading the way towards a door labeled 'Dr. Sidney Cohen'. The ambiance is slightly hallucinatory: the walls seem to subtly bend, the lights leave behind faint tracers, and the overall scene carries the essence of the 1960s combined with a touch of the surreal.&quot;,&quot;title&quot;:&quot;Full-color Leica photograph from October 14, 1963, inside UCLA's Neuropsychiatric Hospital's session room. In sharp focus is the hand of a person, displaying part of a gray button-down shirt sleeve. In the softly lit background, an out-of-focus nurse is seen leading the way towards a door labeled 'Dr. Sidney Cohen'. The ambiance is slightly hallucinatory: the walls seem to subtly bend, the lights leave behind faint tracers, and the overall scene carries the essence of the 1960s combined with a touch of the surreal.&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Full-color Leica photograph from October 14, 1963, inside UCLA's Neuropsychiatric Hospital's session room. In sharp focus is the hand of a person, displaying part of a gray button-down shirt sleeve. In the softly lit background, an out-of-focus nurse is seen leading the way towards a door labeled 'Dr. Sidney Cohen'. The ambiance is slightly hallucinatory: the walls seem to subtly bend, the lights leave behind faint tracers, and the overall scene carries the essence of the 1960s combined with a touch of the surreal." title="Full-color Leica photograph from October 14, 1963, inside UCLA's Neuropsychiatric Hospital's session room. In sharp focus is the hand of a person, displaying part of a gray button-down shirt sleeve. In the softly lit background, an out-of-focus nurse is seen leading the way towards a door labeled 'Dr. Sidney Cohen'. The ambiance is slightly hallucinatory: the walls seem to subtly bend, the lights leave behind faint tracers, and the overall scene carries the essence of the 1960s combined with a touch of the surreal." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F880be93f-69af-45ff-8f6f-a9777d3ac09c_1024x1024.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F880be93f-69af-45ff-8f6f-a9777d3ac09c_1024x1024.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F880be93f-69af-45ff-8f6f-a9777d3ac09c_1024x1024.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F880be93f-69af-45ff-8f6f-a9777d3ac09c_1024x1024.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>And I was pleasantly surprised by the image below, depicting the moment when Leo Mitchell approaches the offices of Sidney Cohen. It captures Mitchell’s perspective while fully under the effects of the drug, as “the fluorescent lights buzz and flicker, casting strange, moving shadows on the walls.” </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb5faf44-fb36-4d01-82b2-76cc6354c24d_1024x1024.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb5faf44-fb36-4d01-82b2-76cc6354c24d_1024x1024.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb5faf44-fb36-4d01-82b2-76cc6354c24d_1024x1024.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb5faf44-fb36-4d01-82b2-76cc6354c24d_1024x1024.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb5faf44-fb36-4d01-82b2-76cc6354c24d_1024x1024.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb5faf44-fb36-4d01-82b2-76cc6354c24d_1024x1024.webp" width="1024" height="1024" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cb5faf44-fb36-4d01-82b2-76cc6354c24d_1024x1024.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1024,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Historically accurate yet slightly surreal Leica photo from October 14, 1963, taken inside a session room at UCLA's Neuropsychiatric Hospital. The photograph emphasizes a sturdy oak door, adorned with a sign reading 'Dr. Sidney Cohen - Staff Physician'. The ambiance around the door exudes a subtle psychedelic aura, with light distortions and hints of shifting colors. The decor, the style of the door, and any visible elements should resonate with the 1960s style.&quot;,&quot;title&quot;:&quot;Historically accurate yet slightly surreal Leica photo from October 14, 1963, taken inside a session room at UCLA's Neuropsychiatric Hospital. The photograph emphasizes a sturdy oak door, adorned with a sign reading 'Dr. Sidney Cohen - Staff Physician'. The ambiance around the door exudes a subtle psychedelic aura, with light distortions and hints of shifting colors. The decor, the style of the door, and any visible elements should resonate with the 1960s style.&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Historically accurate yet slightly surreal Leica photo from October 14, 1963, taken inside a session room at UCLA's Neuropsychiatric Hospital. The photograph emphasizes a sturdy oak door, adorned with a sign reading 'Dr. Sidney Cohen - Staff Physician'. The ambiance around the door exudes a subtle psychedelic aura, with light distortions and hints of shifting colors. The decor, the style of the door, and any visible elements should resonate with the 1960s style." title="Historically accurate yet slightly surreal Leica photo from October 14, 1963, taken inside a session room at UCLA's Neuropsychiatric Hospital. The photograph emphasizes a sturdy oak door, adorned with a sign reading 'Dr. Sidney Cohen - Staff Physician'. The ambiance around the door exudes a subtle psychedelic aura, with light distortions and hints of shifting colors. The decor, the style of the door, and any visible elements should resonate with the 1960s style." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb5faf44-fb36-4d01-82b2-76cc6354c24d_1024x1024.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb5faf44-fb36-4d01-82b2-76cc6354c24d_1024x1024.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb5faf44-fb36-4d01-82b2-76cc6354c24d_1024x1024.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb5faf44-fb36-4d01-82b2-76cc6354c24d_1024x1024.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The same part of the simulation evokes Mitchell’s inner life in a way I found compelling. Mitchell, an artist, has drawn a charcoal sketch of his own brain and is carrying it in his hand. The simulation notes at this point: “The intricate details of your brain drawing in your hand seem alive, and you feel an immense connection to it, as if it's a roadmap to your current mental state.”</p><p><span>I didn’t have access to generative AI tools like this while writing </span><em>Tripping on Utopia</em><span>. But if I had, I would’ve found this experience useful for helping me better imagine the  the perspective of a nervous patient experiencing everything for the first time — rather than that of the scientists who produced the vast majority of the primary sources relating to early psychedelic therapy. </span></p><p><span>One intriguing aspect of the way generative AI systems are trained is that they contain sedimentary layers of the historical record. It’s not as if everything in their training data was from the last decade, let alone the last century. To cite just one example, large swathes of Wikipedia were </span><a href="https://en.wikipedia.org/wiki/Wikipedia:WikiProject_Encyclopaedia_Britannica" rel="">copied directly from the 1911 edition of </a><em><a href="https://en.wikipedia.org/wiki/Wikipedia:WikiProject_Encyclopaedia_Britannica" rel="">Encyclopedia Britannica</a><span>, </span></em><span>which is in the public domain. This, in turn, means that there’s an awful lot of 1911-vintage knowledge in models like Gemini and GPT-4. </span></p><p>That’s bad for anyone trying to use something like ChatGPT as a search engine to surface reliable facts. But it’s pretty amazing for a historian trying to play around with obsolete and archaic knowledge. </p><p><span>One great example of this idea taken to an extreme is </span><a href="https://huggingface.co/Pclanglais/MonadGPT" rel="">MonadGPT</a><span>, a language model created by the digital humanist Pierre-Carl Langlais. It’s a version of the open-source Mistral 7B language model that has been fine-tuned on early modern European texts. The result is much as Langlais’ describes: “What would have happened if ChatGPT was invented in the 17th century? MonadGPT is a possible answer.” You can chat with it directly </span><a href="https://huggingface.co/spaces/Pclanglais/MonadGPT" rel="">here</a><span>. </span></p><p><span>To test how MonadGPT performs when asked to role-play as a physician from the 1680s — one of the key decades I researched in </span><em>Age of Intoxication</em><span> — I gave it a randomly-chosen set of symptoms described by the 17th century English physician Thomas Sydenham </span><a href="https://www.google.com/books/edition/Dr_Sydenham_s_Compleat_Method_of_curing/xG8K_L7OP34C?hl=en&amp;gbpv=1&amp;dq=%22the%20patient%22%20symptoms&amp;pg=PA6&amp;printsec=frontcover" rel="">here</a><span>. They include “Convulsions,” “a most vehement Pain the Head,” “vomiting up green Matter,”  “Palpitation of the Heart,” “Cough” and “the Illiack Passions.”</span></p><p>For Sydenham, these symptoms pointed to only one thing: “the disease called in Women the Hysterical, in Men the Hypochondriacal Passion.”</p><p>When I asked MonadGPT to offer a diagnosis and treatment based on those symptoms, the diagnosis it gave was dropsy. It advised that I “eat a moderate diet, and abstain from strong drinks,” and prescribed the following: </p><blockquote><p>Take two drams of Aloes, one dram of Balsam, half a dram of Gum Arabic, and half a dram of Camphire; mix them together in water, and take two spoonfuls every hour. Also take a dram of Rue, a dram of Opium, a dram of Angelica, a dram of Centory, a dram of Poppy-seed, and a dram of Myrrh; mix them together, and take two spoonfuls every day. Take likewise two ounces of Hellebore, and boil them in a quart of water till it be reduced to half its bulk; then strain it through a cloth, and take half a pint of this liquor every day, till the disease be removed.</p></blockquote><p>This was a pretty great recreation of an early modern drug recipe, but it didn’t correctly guess my affliction. </p><p><span>What’s striking, however, is that off-the-shelf, vanilla GPT-4 </span><em>did</em><span> — provided I prompted it to “role-play as a doctor from the 1680s.” Here was part of its </span><a href="https://chat.openai.com/share/cbc44180-b546-4489-ad75-7622942c47aa" rel="">response</a><span> to the list of symptoms:</span></p><blockquote><p>Upon reading thy description of the maladies afflicting this patient, it is my judgment as a physician of the 1680s that we are confronted with a case most complex and multifarious, indicative of a condition known in our times as 'Hysteria' – a disorder primarily attributed to the wandering womb, as postulated by ancient physicians like Hippocrates and Galen… To restore the balance of humors, venesection (bloodletting) may be advised, perhaps by leeches or with a lancet.</p></blockquote><p>However, the language used here was not that historically accurate, and the herbs it went on to prescribe (“valerian and lavender for their calming effects on the mind”) had more in common with modern herbal remedies than with 1680s medicine. </p><p>When I made a custom GPT, things improved quite a bit. My “1680s Physician” GPT was provided with a list of common 17th century drug and medicine names (red coral, tragacanth, antimony, laudanum, etc) and given some guidance about the task it should perform (“Treatment recommendations should be strictly within the scope of 17th-century medical practices”). </p><p><span>When given the list of symptoms above, it correctly diagnosed “Hysterick and Hypochondriack Affections” and offered the </span><a href="https://chat.openai.com/share/e7d5fb91-904c-4ce2-9641-68dd46fa5608" rel="">following</a><span> treatment plan: </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c40973e-b0ba-4218-b922-8fc105f07c07_1330x1356.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c40973e-b0ba-4218-b922-8fc105f07c07_1330x1356.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c40973e-b0ba-4218-b922-8fc105f07c07_1330x1356.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c40973e-b0ba-4218-b922-8fc105f07c07_1330x1356.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c40973e-b0ba-4218-b922-8fc105f07c07_1330x1356.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c40973e-b0ba-4218-b922-8fc105f07c07_1330x1356.png" width="621" height="633.1398496240602" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6c40973e-b0ba-4218-b922-8fc105f07c07_1330x1356.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1356,&quot;width&quot;:1330,&quot;resizeWidth&quot;:621,&quot;bytes&quot;:306770,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c40973e-b0ba-4218-b922-8fc105f07c07_1330x1356.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c40973e-b0ba-4218-b922-8fc105f07c07_1330x1356.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c40973e-b0ba-4218-b922-8fc105f07c07_1330x1356.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c40973e-b0ba-4218-b922-8fc105f07c07_1330x1356.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>This was not precisely what Sydenham </span><a href="https://www.google.com/books/edition/Dr_Sydenham_s_Compleat_Method_of_curing/xG8K_L7OP34C?hl=en&amp;gbpv=1&amp;dq=%22let%20eight%20ounces%20of%20blood%22&amp;pg=PA7&amp;printsec=frontcover" rel="">recommended</a><span>, but it was strikingly close. Sydenham urges: “Let eight Ounces of Blood be taken away.” 1690s Physician GPT recommended “letting no more than eight Ounces of Blood.” Sydenham and the AI both recommended galbanum. In general, the herb and drug remedies prescribed above strike me as in keeping with the sorts of things a 1680s doctor in London or Paris or Lisbon would’ve prescribed. </span></p><p><span>That’s not to say they directly reflect historical reality, of course. But they allow you to </span><em>play </em><span>with the historical record in a novel way — a form of experiential learning which creatively repurposes the source base itself. </span></p><p><span>For instance, we can’t ask Thomas Sydenham how we would treat Covid-19, but we </span><em>can</em><span> ask the 1690s Physician bot (“take of Barley-water, two Pints, Scurvy-grass, one Handful, and Lemon peel, half an Ounce. Boil them together until the liquid is reduced by one half. Let the Patient drink this Decoction warm, at the rate of a Pint each Day”). </span></p><p><span>I keep returning to the theme of </span><em>historical empathy </em><span>when I reflect on exercises like this. There are aspects of historical writing and teaching that are stringently objective: did an event happen on a certain date or not, was a person alive or not on that date, were they in </span><em>x</em><span> or </span><em>y</em><span> location, and the like. Despite overheated claims, I don’t think tools like ChatGPT or Google’s forthcoming Gemini are ready to offer much help to professional researchers when it comes to those challenges. A human historian is still far better than the leading edge of AI systems when it comes to detecting and correcting factual inaccuracies. </span></p><p><em>But</em><span>… </span></p><p><span>… that isn’t what these systems are actually good at. They’re good at </span><em>hallucinating</em><span>. As long as you’re clear-eyed about the inherent limitations, those hallucinations can be harnessed as a feature, not a bug. </span></p><p><span>As AI researcher Andrej Karpathy </span><a href="https://twitter.com/karpathy/status/1733299213503787018" rel="">put it</a><span> the other day: </span></p><blockquote><p>I always struggle a bit with I'm asked about the “hallucination problem” in LLMs. Because, in some sense, hallucination is all LLMs do. They are dream machines. We direct their dreams with prompts. The prompts start the dream, and based on the LLM’s hazy recollection of its training documents, most of the time the result goes someplace useful.</p></blockquote><p>For historians and for writers of all stripes, anything that allows you to better connect with your source material on the level of emotion and imagination is useful indeed.</p><p><span>•&nbsp;“In 2006, a Roman oil lamp was scientifically excavated at Jamestown, Virginia, the earliest permanent English settlement in the Americas. This study explores why a 17th-century traveler would bring this ancient lighting vessel to the settlement and how its unusual double depositional history allows us to trace its changing meaning over time.” (</span><em><a href="https://www.journals.uchicago.edu/doi/10.1086/719422" rel="">American Journal of Archaeology</a></em><span>)</span></p><p><span>•&nbsp;</span><a href="https://www.aftertheplague.org/" rel="">After the Plague: Health and History in Medieval England</a><span>. The profiles of real people who lived and died in medieval Cambridge here are totally fascinating and well worth checking out. </span></p><p><span>•&nbsp;</span><a href="https://en.wikipedia.org/wiki/Manuel_II_Palaiologos#Emperor's_trip_to_the_West" rel="">The only Byzantine emperor to have visited England</a><span> (1400 CE). “This emperor and his men always went about dressed uniformly in long robes cut like tabards which were all of one colour, namely white, and disapproved greatly of the fashions and varieties of dress worn by the English, declaring that they signified inconstancy and fickleness of heart. No razor ever touched the heads or beards of his priests.”</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F495d8601-9fa5-4dee-9a54-957bc0401db8_158x34.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F495d8601-9fa5-4dee-9a54-957bc0401db8_158x34.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F495d8601-9fa5-4dee-9a54-957bc0401db8_158x34.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F495d8601-9fa5-4dee-9a54-957bc0401db8_158x34.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F495d8601-9fa5-4dee-9a54-957bc0401db8_158x34.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F495d8601-9fa5-4dee-9a54-957bc0401db8_158x34.png" width="158" height="34" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/495d8601-9fa5-4dee-9a54-957bc0401db8_158x34.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:34,&quot;width&quot;:158,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:4426,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:&quot;&quot;,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F495d8601-9fa5-4dee-9a54-957bc0401db8_158x34.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F495d8601-9fa5-4dee-9a54-957bc0401db8_158x34.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F495d8601-9fa5-4dee-9a54-957bc0401db8_158x34.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F495d8601-9fa5-4dee-9a54-957bc0401db8_158x34.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>If you’d like to support my work, please pre-order my book </span><em><a href="https://www.amazon.com/Tripping-Utopia-Margaret-Troubled-Psychedelic/dp/1538722372?&amp;_encoding=UTF8&amp;tag=ro067-20&amp;linkCode=ur2&amp;linkId=ba347f678c5238772f23489f5065baa6&amp;camp=1789&amp;creative=9325" rel="">Tripping on Utopia: Margaret Mead, the Cold War, and the Troubled Birth of Psychedelic Science</a></em><span> or share this newsletter with friends you think might be interested.</span></p><p>As always, I welcome comments. Thank you for reading!</p><p data-attrs="{&quot;url&quot;:&quot;https://www.amazon.com/Tripping-Utopia-Margaret-Troubled-Psychedelic/dp/1538722372?_encoding=UTF8&amp;tag=ro067-20&amp;linkCode=ur2&amp;linkId=ba347f678c5238772f23489f5065baa6&amp;camp=1789&amp;creative=9325&quot;,&quot;text&quot;:&quot;Buy \&quot;Tripping on Utopia\&quot;&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://www.amazon.com/Tripping-Utopia-Margaret-Troubled-Psychedelic/dp/1538722372?_encoding=UTF8&amp;tag=ro067-20&amp;linkCode=ur2&amp;linkId=ba347f678c5238772f23489f5065baa6&amp;camp=1789&amp;creative=9325" rel=""><span>Buy "Tripping on Utopia"</span></a></p><p data-attrs="{&quot;url&quot;:&quot;https://resobscura.substack.com/p/roleplaying-with-ai-will-be-powerful-tool?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://resobscura.substack.com/p/roleplaying-with-ai-will-be-powerful-tool?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Open-source macOS AI copilot (using vision and voice) (353 pts)]]></title>
            <link>https://github.com/elfvingralf/macOSpilot-ai-assistant</link>
            <guid>38611700</guid>
            <pubDate>Tue, 12 Dec 2023 13:17:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/elfvingralf/macOSpilot-ai-assistant">https://github.com/elfvingralf/macOSpilot-ai-assistant</a>, See on <a href="https://news.ycombinator.com/item?id=38611700">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">macOSpilot: your personal macOS AI assistant</h2>
<p dir="auto">macOSpilot answers your questions about anything, in any application. No need to reach for another window. Simply use a keyboard shortcut to trigger the assistant, speak your question, and it will give the answer in context and in audio within seconds. Behind the scenes macOSpilot takes a screenshot of your active window when triggerd, and sends it to OpenAI GPT Vision along with a transcript of your question. It's answer will be displayed in text, and converted into audio using OpenAI TTS (text to speech).</p>
<details open="">
  <summary>
    
    <span aria-label="Video description file.size.demo.with.subtitles.mp4">file.size.demo.with.subtitles.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/94417497/287926991-5a9e9288-0479-4def-9a87-451dddd783af.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDIzOTcxMDQsIm5iZiI6MTcwMjM5NjgwNCwicGF0aCI6Ii85NDQxNzQ5Ny8yODc5MjY5OTEtNWE5ZTkyODgtMDQ3OS00ZGVmLTlhODctNDUxZGRkZDc4M2FmLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFJV05KWUFYNENTVkVINTNBJTJGMjAyMzEyMTIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjEyVDE2MDAwNFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTA3MzNjOWRiMGQxYTA5NjViMmMyY2NhZTE2ZmMxNTIyNzQyZTU4OThiODNjZWM3Yzc2Mjg5MDA3MzRlYmRjZmUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.572iO9MFZdZ7uQoZjM0WviQdzRhMOZHjLCTEoQAUmpc" data-canonical-src="https://private-user-images.githubusercontent.com/94417497/287926991-5a9e9288-0479-4def-9a87-451dddd783af.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDIzOTcxMDQsIm5iZiI6MTcwMjM5NjgwNCwicGF0aCI6Ii85NDQxNzQ5Ny8yODc5MjY5OTEtNWE5ZTkyODgtMDQ3OS00ZGVmLTlhODctNDUxZGRkZDc4M2FmLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFJV05KWUFYNENTVkVINTNBJTJGMjAyMzEyMTIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjEyVDE2MDAwNFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTA3MzNjOWRiMGQxYTA5NjViMmMyY2NhZTE2ZmMxNTIyNzQyZTU4OThiODNjZWM3Yzc2Mjg5MDA3MzRlYmRjZmUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.572iO9MFZdZ7uQoZjM0WviQdzRhMOZHjLCTEoQAUmpc" controls="controls" muted="muted">

  </video>
</details>

<ul dir="auto">
<li><strong>Works with any application in macOS:</strong> macOSpilot is application agnostic, and simply takes a screenshot of the currently active window when you trigger the assistant.</li>
<li><strong>Trigger with keyboard shortcut, speak your question:</strong> No need to juggle windows, just press the keyboard shortcut and speak your question.</li>
<li><strong>Answers in-context and in audio:</strong> The answer to your question is provided in an small window overlayed on top of your active window, and in audio (using text-to-speech).</li>
</ul>
<h2 tabindex="-1" dir="auto">How it works</h2>
<ol dir="auto">
<li>macOSpilot runs NodeJS/Electron. Simply install the NodeJS project and dependencies (see below) and make the necessary configurations in <code>index.js</code>. Then chose to run <code>yarn start</code> from the terminal, or package it with Electron with the instructions below, add your OpenAI API key and let the application run in the background.</li>
<li>When you need to use macOSpilot, press the keyboard shortcut you've configured (default is Command+Shift+'). macOSpilot will take a screenshot of your currently active macOS application window and activate the microphone.</li>
<li>Speak your question into your microphone and then press the same keyboard shortcut to end the microphone recording.</li>
<li>macOSpilot will send your question to OpenAI's Whisper API, and the transcription will be sent to OpenAI's Vision API along with the screenshot.</li>
<li>The Vision API response will be displayed in a small notification window on top of your active macOS application window, and read outloud once it's been processed by OpenAI's TTS (text to speech) API.</li>
<li>A simple history of answers to your questions in the current session is available in another window that you can hide/minimize.</li>
</ol>
<p dir="auto">The most recent screenshot, audio recording, and TTS response will be stored on your machine in part for debugging purposes. The same filename is used every time so they will be overwritten, but are not automatically deleted when you close or delete the application.</p>
<h2 tabindex="-1" dir="auto">Getting Started</h2>
<h3 tabindex="-1" dir="auto">Video walk-through</h3>
<p dir="auto">Prefer a video? Head on over to YouTube to watch the walk through of how to get started, how the application works, and a brief explanation of how it works under the hood.</p>
<p dir="auto"><a href="https://www.youtube.com/watch?v=1IdCWqTZLyA" rel="nofollow"><img src="https://private-user-images.githubusercontent.com/94417497/289893066-e96e314f-6778-42e5-8a9b-04ce9e6fc0b9.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDIzOTcxMDQsIm5iZiI6MTcwMjM5NjgwNCwicGF0aCI6Ii85NDQxNzQ5Ny8yODk4OTMwNjYtZTk2ZTMxNGYtNjc3OC00MmU1LThhOWItMDRjZTllNmZjMGI5LmpwZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFJV05KWUFYNENTVkVINTNBJTJGMjAyMzEyMTIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjEyVDE2MDAwNFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWRhNWE1MmE0OTkzMzJlZjE2Yzc2Y2NhNTNiNjY0ZjA4OTY1ZGFkNmNkZWE1MWQxY2IwMjA1ZmI4OTAxYTExMWUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.h1WiMJ0-bqY6wHVOqR_3v4HOBpZMwmq01OafGDb6Nkc" alt="YouTube walk-through and tutorial" secured-asset-link=""></a></p>
<h3 tabindex="-1" dir="auto">Install</h3>
<p dir="auto">Make sure you have NodeJS installed on your machine. Then clone the repo and follow the steps below.</p>
<div dir="auto" data-snippet-clipboard-copy-content="
git  clone  https://github.com/elfvingralf/macOSpilot-ai-assistant.git
"><pre>git  clone  https://github.com/elfvingralf/macOSpilot-ai-assistant.git
</pre></div>
<p dir="auto">Navigate to the folder and run <code>yarn install</code> or <code>npm install</code> in your folder. This should install all dependencies.</p>
<p dir="auto">Run <code>yarn start</code> or <code>npm start</code>. Because the application needs access to read your screen, microphone, read/write files etc, you will need to go through the steps of granting it access and possibly restarting your terminal.</p>
<h3 tabindex="-1" dir="auto">Configurations</h3>
<p dir="auto">Make sure to add your OpenAI API key by clicking the settings icon in the top right-hand corner of the main window. (it's not stored encrypted!)</p>
<p dir="auto">If you want to change the default values here's a few things that might be worth changing, all in <code>index.js</code>:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Keyboard shortcut:</strong> The default keyboard shortcut <code>keyboardShortcut</code> is set to "CommandOrControl+Shift+'" (because it seemed like it was rarely used by other applications)</p>
</li>
<li>
<p dir="auto"><strong>OpenAI Vision prompt:</strong> The OpenAI Vision API system prompt in <code>conversationHistory</code>, currently just set to "You are helping users with questions about their macOS applications based on screenshots, always answer in at most one sentence."</p>
</li>
<li>
<p dir="auto"><strong>VisionAPI image size:</strong> Image resize params to save some money, I left an example of how in <code>callVisionAPI()</code> (I found that I had much poorer results when using it)</p>
</li>
<li>
<p dir="auto"><strong>Application window sizes and settings:</strong> The size of the main window: <code>mainWindowWidth</code> and <code>mainWindowHeight</code>. The size of the notification window, which always remains on top: <code>notificationWidth</code> and <code>notificationHeight</code>.</p>
</li>
<li>
<p dir="auto"><strong>More notification window settings:</strong> The level of opacity of the notification window: <code>notificationOpacity</code>. Where the notification window moves to on activation, relative to the active window: inside <code>positionNotificationAtTopRight()</code> (terrible naming, I know)</p>
</li>
</ul>
<h3 tabindex="-1" dir="auto">Turn it into an .app with Electron</h3>
<p dir="auto">Want to create an .app executable instead of running this from your terminal?</p>
<p dir="auto">First go to <code>index.js</code> and change <code>const useElectronPackager</code> from <code>false</code> to <code>true</code>.</p>
<p dir="auto">Run one of these in your terminal, depending on which platform you're on.</p>
<div dir="auto" data-snippet-clipboard-copy-content="npm  run  package-mac
npm  run  package-win
npm  run  package-linux"><pre>npm  run  package-mac
npm  run  package-win
npm  run  package-linux</pre></div>
<p dir="auto">Note I have only tested this on Mac (Apple silicon and Intel).</p>
<p dir="auto">Go to <code>/release-builds/</code> in your project folder, and chose the folder of your platform. In there is an executable, <code>.app</code> if you're on Mac. Double-click it to open the app, note that it may take a few seconds the first time so be patient.</p>
<p dir="auto">Once the app is opened, trigger your keyboard shortcut. You'll be asked to grant Privacy &amp; Security permissions. You may need to repeat this another one or two times for all permissions to work properly, and to restart the app.</p>
<p dir="auto"><strong>NOTE:</strong> I've had consistent issues getting macOS to trigger the Privacy &amp; Security Microphone dialog window for the .app, which means that I can't ask my question. If it works for you, or if you have a work-around to this issue, I'd love to know.</p>
<h2 tabindex="-1" dir="auto">Improvements:</h2>
<p dir="auto">Some improvements I'd like to make, in no particular order:</p>
<ul dir="auto">
<li>Enable optional conversation state inbetween sessions (open/close application)</li>
<li>Use buffers instead of writing/reading screenshot and audio files to disk</li>
<li>Make assistant audio configurable in UI (e.g. speed, make playback optional)</li>
<li>Make always-on-top window configurable in UI (e.g. toggle sticky position, enable/disable)</li>
<li>Make screenshot settings configurable in UI (e.g. select area, entire screen)</li>
<li>Fix microphone issue not working as .app</li>
</ul>
<h2 tabindex="-1" dir="auto">About / contact</h2>
<p dir="auto">I'm a self-taught and really like scrapping together fun projects. I write functional code that probably isn't beautiful nor efficient, and share it with the hope that someone else might find it useful.</p>
<p dir="auto">You can find me as <a href="https://twitter.com/ralfelfving" rel="nofollow">@ralfelfving</a> on Twitter/X. If you liked this project, consider checking my tutorials on my YouTube channel <a href="https://www.youtube.com/@ralfelfving" rel="nofollow">@ralfelfving</a>.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Today Is One of the Biggest Surveillance Votes. Will the FBI Stop Spying? (310 pts)]]></title>
            <link>https://tuta.com/blog/702-open-letter-against-surveillance</link>
            <guid>38611590</guid>
            <pubDate>Tue, 12 Dec 2023 13:01:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tuta.com/blog/702-open-letter-against-surveillance">https://tuta.com/blog/702-open-letter-against-surveillance</a>, See on <a href="https://news.ycombinator.com/item?id=38611590">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Today US politicians are going to vote on the FISA “Reform” Bill - the FISA Reform and Reauthorization Act of 2023 (FRRA). This bill would greatly expand
the surveillance possibilities of US and non-US citizens. Privacy-first companies like Mozilla, Tuta, and the Tor Project
now call on policymakers to not cement such surveillance measures with FISA 702 Surveillance.
</p><div><p>Ten years after the Snowden leaks the United States continues to spy on American citizens via its unconstitutional surveillance
program.</p>
<p><strong>Section 702 of the Foreign Intelligence Surveillance Act (FISA) allows US authorities to spy on foreigners to prevent terrorism
attacks. However, a vast amount of data from US citizens is scooped up by the NSA and regularly abused by
the FBI via <a href="https://tuta.com/blog/posts/why-a-backdoor-is-a-security-risk">backdoor searches on US citizens without warrants or probable cause</a>.</strong></p>
<p><strong>This practise must end. FISA Section 702 must not be reauthorized.</strong></p>
<h2 id="open-letter-demands">Open Letter Demands</h2>
<p>We at Tuta together with other privacy-first companies are making clear in a joint open letter that:</p>
<ol>
<li><p>Congress should not provide a blank check for surveillance overreach by reauthorizing FISA 702 in NDAA;</p>
</li>
<li><p>Congress should pass a strong surveillance reform bill such as the Government Surveillance Reform Act (GSRA) or
the Protect Liberty and End Warrantless Surveillance Act (PLEWSA), and that measures such as the House and Senate
Intelligence bills would only cement and expand the status quo of surveillance abuses.</p>
</li>
</ol>
<p><strong>Simply put, the vitality of the Internet economy depends on strong surveillance reform that leave no room for backdoors.</strong></p>
<h3 id="open-letter-against-fisa-section-702">Open Letter Against FISA Section 702</h3>
<p>Dear Members of the House of Representatives,</p>
<p>We, a group of companies, builders, and providers of critical internet-based products and
services, write to you today in support of legislative proposals, such as the Government
Surveillance Reform Act, that would effectively address bipartisan and bicameral concerns
around consistent surveillance overreach. We also applaud the Protect Liberty and End
Warrantless Surveillance Act, which takes key steps forward in reform, and encourage you to
strengthen the bill further.</p>
<p>Additionally, current efforts to reauthorize Section 702 until April through the National Defense
Authorization Act would amount to rubber-stamping surveillance abuses, and we strongly
oppose such efforts.</p>
<p>As providers of digital products and services, both nonprofit and for-profit, we depend on the
trust of our customers to sustain digital communities. If widely-documented abuses go
unaddressed in legislation, individuals will remain concerned that their most intimate
information could be collected by intelligence agencies without accountability, thus deteriorating
the economic and social power of the Internet.</p>
<p><strong>While the current legislative debate may have been sparked by the imminent expiration of
Section 702 of FISA, the widely-documented surveillance abuses highlighted by policy experts
and members of Congress across the political spectrum would continue under narrow 702
“fixes,” especially ones that only cosmetically change FISA. For that very reason, we are
particularly concerned by reauthorization proposals by the House and Senate Intelligence
Committees that would only cement overbroad surveillance.</strong></p>
<p>A true reform proposal will need to address similar ways that the government surveils Americans
without adequate oversight and accountability, including warrantless purchases of Americans’
information from data brokers, narrowing the scope of surveillance in line with the President’s
own EO 14086, increasing the ability of Americans to stand up for their rights in court, and,
optimally, parallel reforms of EO 12333. These provisions would ensure that surveillance
overreach does not simply continue the day after a reform bill passes, but under a slightly
different authority. In other words, Congress should take this “functional” approach to
surveillance reform by addressing end results.</p>
<p><strong>The Protect Liberty and End Warrantless Surveillance Act, while not containing all of these
provisions, would take critical steps forward in shielding Americans from overbroad
surveillance. Most notably, it would protect Americans from warrantless data broker purchases
and would create an ironclad warrant requirement for 702 surveillance of US persons, among
other provisions.</strong> Lawmakers should consider strengthening the bill, for example by increasing
transparency and accountability measures.</p>
<p>Of particular importance in both bills is inserting language codifying the scope of surveillance
proposed by the President’s own EO 14086 to tether surveillance of non-US persons to basic
guardrails.</p>
<p>We remain available to discuss the impact of reform proposals on the economy and on the
privacy of people online as you continue your thoughtful work.</p>
<p>Signed,</p>
<p>Mozilla</p>
<p>Wikimedia Foundation</p>
<p>Foundation for American Innovation</p>
<p>Proton</p>
<p>DuckDuckGo</p>
<p>Nord Security</p>
<p>The Tor Project</p>
<p>WebPros</p>
<p>Quilibrium, Inc.</p>
<p>Mailfence</p>
<p>Tuta</p>
<p>Superbloom (previously known as Simply Secure)</p>
<p>Gate 15</p>
<p>Nitrokey</p>
<p>Action Network &amp; Action Builder</p>
<p>Malloc</p>
<p>Efani Secure Mobile</p>
<p>Skiff</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[YouTube doesn't want to take down scam ads (547 pts)]]></title>
            <link>https://old.reddit.com/r/youtube/comments/18gjiqy/youtube_doesnt_want_to_take_down_scam_ads/</link>
            <guid>38611466</guid>
            <pubDate>Tue, 12 Dec 2023 12:47:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/youtube/comments/18gjiqy/youtube_doesnt_want_to_take_down_scam_ads/">https://old.reddit.com/r/youtube/comments/18gjiqy/youtube_doesnt_want_to_take_down_scam_ads/</a>, See on <a href="https://news.ycombinator.com/item?id=38611466">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Hey Reddit,</p>

<p>i recently noticed that there are way more scam ads on YouTube. And i am not talking about those ads of people selling you get rich quick courses, which i get to see way too often as well, i am talking about deep fake Elon Musk saying that he has built an AI powered trading bot that will allow you to make 1 million dollars in 6 months risk free and to be honest i can't tell that it is deep fake, it looks very real. Here is the link to the ad: <a href="https://www.youtube.com/watch?v=wWGb0BLYBOs">https://www.youtube.com/watch?v=wWGb0BLYBOs</a></p>

<p><a href="https://preview.redd.it/z7zagtomju5c1.png?width=1942&amp;format=png&amp;auto=webp&amp;s=5ed808fbf9800784a6bb1698fac2317d8e5f2a85">https://preview.redd.it/z7zagtomju5c1.png?width=1942&amp;format=png&amp;auto=webp&amp;s=5ed808fbf9800784a6bb1698fac2317d8e5f2a85</a></p>

<p>or here another one: <a href="https://www.youtube.com/watch?v=aE77YkmsbDc&amp;t=75s">https://www.youtube.com/watch?v=aE77YkmsbDc&amp;t=75s</a> </p>

<p>​</p>

<p>I am from Austria so i get to see the German version of these scams as well. Like this one: <a href="https://www.youtube.com/watch?v=1Iyuyx5thgI">https://www.youtube.com/watch?v=1Iyuyx5thgI</a></p>

<p>or this one: <a href="https://www.youtube.com/watch?v=JMRY5dxnZ4E">https://www.youtube.com/watch?v=JMRY5dxnZ4E</a></p>

<p>The first one i have seen so many times it gets ridiculous. Its about a famous German figure supposedly being sued by the central bank because he found an infinite money glitch.</p>

<p>​</p>

<p>And because these scam ads are getting so annoying i started reporting them every time i see one, because i do understand that there are probably millions of advertisers on YouTube and sometimes these scams don't get detected right away. So i also reported that Fake Elon Musk Ad, but the next day i get shown the exact&nbsp;same ad again, then i open my email inbox finding a YouTube email about my report stating <strong>"We decided not to take this ad down.&nbsp;We found that the ad doesn’t go against&nbsp;Google’s policies".</strong> The same goes for all four ads listed above, all reported, all apparently not against policy.</p>

<p>So one of these two is true:</p>

<p>1 - Elon Musk has actually found a way to make everyone rich with ai.</p>

<p>2 - YouTube simply doesn't care about people getting scammed as long as they make money.</p>

<p>As much as i would like the first one to be true, these YouTube Ads are not cheap to run, with one of them running for more than a month with 364K views. So the fact that the scammers are able to afford these ads means that people keep falling for these scams, and YouTube doesn't seem to care at all.  </p>

<p>And i don't want to use an adblocker because i want the people i watch to get paid for their work, but i don't want them to be paid with the money from the victims of these scams. </p>

<p>Is this a regional problem in Austria or do you see these scams too? </p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[YouTube is crippling Firefox on Asahi Linux (222 pts)]]></title>
            <link>https://social.treehouse.systems/@marcan/111567255619206929</link>
            <guid>38611248</guid>
            <pubDate>Tue, 12 Dec 2023 12:21:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://social.treehouse.systems/@marcan/111567255619206929">https://social.treehouse.systems/@marcan/111567255619206929</a>, See on <a href="https://news.ycombinator.com/item?id=38611248">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The NSA advises move to memory-safe languages (285 pts)]]></title>
            <link>https://www.nsa.gov/Press-Room/Press-Releases-Statements/Press-Release-View/Article/3608324/us-and-international-partners-issue-recommendations-to-secure-software-products/</link>
            <guid>38611175</guid>
            <pubDate>Tue, 12 Dec 2023 12:12:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nsa.gov/Press-Room/Press-Releases-Statements/Press-Release-View/Article/3608324/us-and-international-partners-issue-recommendations-to-secure-software-products/">https://www.nsa.gov/Press-Room/Press-Releases-Statements/Press-Release-View/Article/3608324/us-and-international-partners-issue-recommendations-to-secure-software-products/</a>, See on <a href="https://news.ycombinator.com/item?id=38611175">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemscope="" itemtype="http://schema.org/NewsArticle" id="dnn_ctr12594_ContentPane">
    <meta itemprop="datePublished" content="Dec. 6, 2023">

    
    <div id="adetail-slick-gallery">
        
        <div>
            
            <p><img src="https://media.defense.gov/2023/Dec/06/2003352582/1920/1080/0/231206-D-IM742-2023.PNG" alt="CSI: The Case for Memory Safe Roadmaps" itemprop="image">
        </p></div>
        
        
        
        
        
        <p><i></i>
            <span>PHOTO INFORMATION</span>
        </p>
        
        
    </div>
    

    <div itemprop="articleBody" id="news-content">
            
            <div><p>FORT MEADE, Md. - The National Security Agency (NSA) joins Cybersecurity and Infrastructure Security Agency (CISA) and U.S. and international partners in releasing <a href="https://media.defense.gov/2023/Dec/06/2003352724/-1/-1/0/THE-CASE-FOR-MEMORY-SAFE-ROADMAPS-TLP-CLEAR.PDF">”The Case for Memory Safe Roadmaps” Cybersecurity Information Sheet (CSI)</a>. Expanding on the “Software Memory Safety” CSI published by NSA in April 2023, the report provides guidance for software manufacturers and technology providers to create roadmaps tailored to eliminate memory safety vulnerabilities from their products.</p><p>
&nbsp;
Memory safety vulnerabilities are coding errors affecting software’s memory management code in which memory can be accessed, written, allocated, or deallocated in unintended ways. Types of memory-related coding errors mentioned in the CSI include buffer overflow, use after free, use of uninitialized memory, and double free. Exploiting these vulnerabilities could allow malicious actors to access or corrupt data, or run arbitrary malicious code with the same privilege as the system owner.</p><p>
&nbsp;
“Memory safety vulnerabilities affect software development across all industries,” said Neal Ziring, Technical Director of NSA Cybersecurity Directorate. “Working together to set clear goals and timelines in transition roadmaps to safer programming language is critical for mitigating these problems.”</p><p>

In a shared conclusion, the co-authoring agencies recommend software manufacturers create roadmaps for the utilization of, and transition to, memory safe programming languages. This transition will enable memory safe programming languages to mitigate memory-related vulnerabilities and reduce the products' attack surface. Recommended memory safe programming languages mentioned in the CSI include C#, Go, Java, Python, Rust, and Swift. Software manufacturers should evaluate multiple memory safe programming languages before integrating them into their workflows.</p><p>

The CSI includes technical and non-technical factors for software manufacturers to consider when developing their roadmap. These include picking a memory safe language, staff capabilities and resourcing, and prioritization guidance. Additional guidance includes elements that should be part of the roadmaps, including the following: defined phases with dates and outcomes, dates for memory safe programming languages in new systems, internal developer training and integration plans, external dependency plans, transparency plans, and CVE support program plans.</p><p>
&nbsp;
The authoring agencies urge software manufacturers to create and publish memory safe roadmaps to plan and communicate how memory safety vulnerabilities will be mitigated in their products.</p><p>
&nbsp;
The authoring agencies include CISA, NSA, the Federal Bureau of Investigation (FBI), the Australian Signals Directorate’s Australian Cyber Security Centre (ACSC), the Canadian Centre for Cyber Security (CCCS), the New Zealand National Cyber Security Centre (NCSC-NZ) and Computer Emergency Response Team New Zealand (CERT NZ), and the United Kingdom’s National Cyber Security Centre (NCSC-UK). The agencies jointly developed this report as part of their Secure by Design campaign to urge software manufacturers to prioritize design and implementation practices to reduce customer risk by using memory safe languages in their products.</p></div>



<hr>
<p>NSA Media Relations<br>
<a href="mailto:MediaRelations@nsa.gov">MediaRelations@nsa.gov</a><br>
443-634-0721</p>

        </div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tell/Ask HN: HN WebSite is/was down. I'm curious why? (151 pts)]]></title>
            <link>https://hn.hund.io/</link>
            <guid>38610912</guid>
            <pubDate>Tue, 12 Dec 2023 10:42:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hn.hund.io/">https://hn.hund.io/</a>, See on <a href="https://news.ycombinator.com/item?id=38610912">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">

<section>
<section aria-label="Website" role="region">
<header data-behavior="disable-ctts">
<h2>Website</h2>
<span role="img" tabindex="0" title="Operational">Operational</span>

</header>


</section>
<section aria-label="API" role="region">
<header data-behavior="disable-ctts">
<h2>API</h2>
<span role="img" tabindex="0" title="Operational">Operational</span>

</header>


</section>
<section aria-label="Search" role="region">
<header data-behavior="disable-ctts">
<h2>Search</h2>
<span role="img" tabindex="0" title="Operational">Operational</span>

</header>


</section>

</section>

<section data-behavior="metrics" data-source="/metrics/data.json" data-top-level="">
<header data-behavior="disable-ctts">
<h2>Metrics</h2>

</header>
<div>
<ol data-i18n-metric-lacking-data="Data is not yet available for this time frame.">
<li data-metric-options="{&quot;x_title&quot;:&quot;Time&quot;,&quot;title&quot;:&quot;Website Percent Uptime&quot;,&quot;enabled&quot;:true,&quot;top_level_enabled&quot;:true,&quot;y_title&quot;:&quot;Percent Uptime&quot;}" name="percent_uptime@59f0b7bc4e80f148afed6c9b">
<p>Website Percent Uptime</p>

</li>

<li data-metric-options="{&quot;x_title&quot;:&quot;Time&quot;,&quot;title&quot;:&quot;Website Incidents Reported&quot;,&quot;plot_type&quot;:&quot;bar&quot;,&quot;y_supremum&quot;:2.0,&quot;enabled&quot;:true,&quot;top_level_enabled&quot;:true,&quot;y_title&quot;:&quot;Incidents Reported&quot;}" name="incidents_reported@59f0b7bc4e80f148afed6c9b">
<p>Website Incidents Reported</p>

</li>

<li data-metric-options="{&quot;x_title&quot;:&quot;Time&quot;,&quot;title&quot;:&quot;Website DNS Lookup Time (ms)&quot;,&quot;enabled&quot;:true,&quot;top_level_enabled&quot;:true,&quot;y_title&quot;:&quot;DNS Lookup Time (ms)&quot;}" name="http/name_lookup_time@59f0b7bd4e80f148afed6c9f">
<p>Website DNS Lookup Time (ms)</p>

</li>

<li data-metric-options="{&quot;x_title&quot;:&quot;Time&quot;,&quot;title&quot;:&quot;Website TCP Connection Time (ms)&quot;,&quot;enabled&quot;:true,&quot;top_level_enabled&quot;:true,&quot;y_title&quot;:&quot;TCP Connection Time (ms)&quot;}" name="http/tcp_connection_time@59f0b7bd4e80f148afed6c9f">
<p>Website TCP Connection Time (ms)</p>

</li>

<li data-metric-options="{&quot;x_title&quot;:&quot;Time&quot;,&quot;title&quot;:&quot;Website TLS Handshake Time (ms)&quot;,&quot;enabled&quot;:true,&quot;top_level_enabled&quot;:true,&quot;y_title&quot;:&quot;TLS Handshake Time (ms)&quot;}" name="http/tls_handshake_time@59f0b7bd4e80f148afed6c9f">
<p>Website TLS Handshake Time (ms)</p>

</li>

<li data-metric-options="{&quot;x_title&quot;:&quot;Time&quot;,&quot;title&quot;:&quot;Website Content Generation Time (ms)&quot;,&quot;enabled&quot;:true,&quot;top_level_enabled&quot;:true,&quot;y_title&quot;:&quot;Content Generation Time (ms)&quot;}" name="http/content_generation_time@59f0b7bd4e80f148afed6c9f">
<p>Website Content Generation Time (ms)</p>

</li>

<li data-metric-options="{&quot;x_title&quot;:&quot;Time&quot;,&quot;title&quot;:&quot;Website Content Transfer Time (ms)&quot;,&quot;enabled&quot;:true,&quot;top_level_enabled&quot;:true,&quot;y_title&quot;:&quot;Content Transfer Time (ms)&quot;}" name="http/content_transfer_time@59f0b7bd4e80f148afed6c9f">
<p>Website Content Transfer Time (ms)</p>

</li>

<li data-metric-options="{&quot;x_title&quot;:&quot;Time&quot;,&quot;title&quot;:&quot;Website Total Elapsed Time (ms)&quot;,&quot;enabled&quot;:true,&quot;top_level_enabled&quot;:true,&quot;y_title&quot;:&quot;Total Elapsed Time (ms)&quot;}" name="http/total_time@59f0b7bd4e80f148afed6c9f">
<p>Website Total Elapsed Time (ms)</p>

</li>

<li data-metric-options="{&quot;x_title&quot;:&quot;Time&quot;,&quot;title&quot;:&quot;Website Time to First Byte (ms)&quot;,&quot;enabled&quot;:true,&quot;top_level_enabled&quot;:true,&quot;y_title&quot;:&quot;Time to First Byte (ms)&quot;}" name="http/time_to_first_byte@59f0b7bd4e80f148afed6c9f">
<p>Website Time to First Byte (ms)</p>

</li>

</ol>
</div>
</section>

<section data-behavior="disable-ctts">
<header>
<h2>Recent History</h2>
<span data-tooltip="30-day">99.824% Uptime</span>

</header>
<div>

<div>
<p><span>Outage</span>
<time datetime="2023-12-12T09:08:13Z" to_time="2023-12-12T11:42:13Z">Dec 12, 2023 1:08 AM–3:42 AM PST</time></p>

</div>

<div>
<p><span>Outage</span>
<time datetime="2023-12-12T08:51:11Z" to_time="2023-12-12T09:03:13Z">Dec 12, 2023 12:51 AM–1:03 AM PST</time></p>

</div>

<div>
<p><span>Outage</span>
<time datetime="2023-12-12T08:28:13Z" to_time="2023-12-12T08:48:11Z">Dec 12, 2023 12:28 AM–12:48 AM PST</time></p>

</div>

<div>
<p><span>Outage</span>
<time datetime="2023-12-12T08:24:13Z" to_time="2023-12-12T08:25:10Z">Dec 12, 2023 12:24 AM–12:25 AM PST</time></p>

</div>

<div>
<p><span>Outage</span>
<time datetime="2023-12-12T08:04:09Z" to_time="2023-12-12T08:21:12Z">Dec 12, 2023 12:04 AM–12:21 AM PST</time></p>

</div>

<div>
<p><span>Outage</span>
<time datetime="2023-12-12T07:44:12Z" to_time="2023-12-12T08:01:11Z">Dec 11, 2023 11:44 PM–Dec 12, 2023 12:01 AM PST</time></p>

</div>
<p>No events for 7 days!</p>

<div>
<p><span>Outage</span>
<time datetime="2023-12-04T20:04:52Z" to_time="2023-12-04T20:05:48Z">Dec  4, 2023 12:04 PM–12:05 PM PST</time></p>

</div>
<p>No events for 12 days!</p>

<div>
<p><span>Outage</span>
<time datetime="2023-11-22T04:19:49Z" to_time="2023-11-22T04:20:50Z">Nov 21, 2023 8:19 PM–8:20 PM PST</time></p>

</div>

<div>
<p><span>Outage</span>
<time datetime="2023-11-21T18:58:49Z" to_time="2023-11-21T19:01:48Z">Nov 21, 2023 10:58 AM–11:01 AM PST</time></p>

</div>

<div>
<p><span>Outage</span>
<time datetime="2023-11-21T17:29:49Z" to_time="2023-11-21T17:31:51Z">Nov 21, 2023 9:29 AM–9:31 AM PST</time></p>

</div>
<p>No events for 3 days!</p>

<div>
<p><span>Outage</span>
<time datetime="2023-11-18T02:29:50Z" to_time="2023-11-18T02:30:49Z">Nov 17, 2023 6:29 PM–6:30 PM PST</time></p>

</div>

<div>
<p><span>Outage</span>
<time datetime="2023-11-17T19:48:50Z" to_time="2023-11-17T19:50:52Z">Nov 17, 2023 11:48 AM–11:50 AM PST</time></p>

</div>

</div>

</section>

</div></div>]]></description>
        </item>
    </channel>
</rss>