<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 07 Jan 2026 11:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Microsoft probably killed my Snapdragon Dev Kit (170 pts)]]></title>
            <link>https://jasoneckert.github.io/myblog/how-microsoft-killed-my-snapdragon-devkit/</link>
            <guid>46521860</guid>
            <pubDate>Wed, 07 Jan 2026 02:37:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jasoneckert.github.io/myblog/how-microsoft-killed-my-snapdragon-devkit/">https://jasoneckert.github.io/myblog/how-microsoft-killed-my-snapdragon-devkit/</a>, See on <a href="https://news.ycombinator.com/item?id=46521860">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    <p><img src="https://jasoneckert.github.io/myblog/how-microsoft-killed-my-snapdragon-devkit/snapdragondevkit.jpg#center" alt="Snapdragon Dev Kit" title="Snapdragon Dev Kit"></p>
<p>Back in October 2024, <a href="https://jasoneckert.github.io/myblog/windows-on-arm/">I got my hands on a Snapdragon Dev Kit</a>. With a Qualcomm Snapdragon X Elite ARM64 CPU (the fastest model!), 32GB of RAM, and a 512GB SSD, it ran Windows 11 for ARM lightning fast. So I made it my daily driver, and it stayed that way until very recently. I even wrote a <a href="https://jasoneckert.github.io/myblog/windows-on-arm-1year/">review of it one year later</a> back in October.</p>
<p>Since the first boot, it‚Äôs been rock-solid and reliable every single day. And as someone who has used Windows since the beginning of time, I‚Äôm always combing through Event Viewer for software or hardware issues (there were none). Yes, the fan is noisy, as <a href="https://www.jeffgeerling.com/blog/2024/snapdragon-dev-kit-windows-fastest-x-elite-tested/">Jeff Geerling pointed out</a>, but I don‚Äôt notice it because I work with headphones on.</p>
<p>Of course, that changed this past week.</p>
<h2 id="so-what-happened">So, what happened?</h2>
<p>IIn early December, a Windows 11 security update (KB5068861) failed to install and rolled back during reboot. I tried installing it two more times with the same result. I cleared the package cache, ran the usual <code>sfc /scannow</code> and <code>dism /Online /Cleanup-Image /RestoreHealth</code> incantations, and even tried manually installing the update from the Microsoft Update Catalog. No go.</p>
<p>So I Googled it, found that many, many people were having the same issue and that Microsoft was going to fix it with a future cumulative update. So I turned off updates for a month and went on my merry way.</p>
<p>This past week, I turned updates back on. While I was working, I got the usual Windows notification that a restart was pending from a recently applied update. I hit restart and immediately realized it was the same update, same failure, same rollback.</p>
<p>Only this time, the rollback didn‚Äôt go as planned. The system rebooted four times before finally loading into Windows. And when it did, it wouldn‚Äôt sign me into my Microsoft account. Entering my PIN got me in, but to a brand-new profile complete with the default, soulless Windows background.</p>
<p>I had Internet access and most of my apps worked, but I couldn‚Äôt open Windows Terminal or most other Microsoft apps‚Ä¶ even Event Viewer. I decided to give it a fresh reboot (hey, it‚Äôs Windows after all). But right after the Windows logo appeared, the system either rebooted automatically or just shut down entirely‚Ä¶ seemingly at random. A few dozen attempts later, I had to admit defeat.</p>
<p>Next, I tried checking the UEFI settings by booting into the Boot Device Selection (BDS) menu (by pressing the Home key during boot). Unfortunately, the BDS menu behaved sporadically: random freezing, options that wouldn‚Äôt select, and general weirdness. I thought it might be keyboard- or USB-related, but other keyboards in different ports behaved exactly the same.</p>
<p>Persistence paid off eventually, and one time I managed to get into the BDS menu and navigate all the options. Figuring a Windows reinstall was my best shot, I disabled Secure Boot, enabled USB-first boot, and turned on the UEFI option that allows WinPE to use external displays (since this isn‚Äôt a laptop).</p>
<p>I downloaded the Windows 11 ARM ISO, imaged it to a USB thumb drive, and prepared a second thumb drive with the Snapdragon Dev Kit drivers I had previously snagged from Qualcomm‚Äôs website in one big ZIP file (thankfully, before they disappeared). I was able to boot into the Windows 11 installer, and everything ran smoothly at first. I completed an installation that overwrote my existing C:\ partition, rebooted, and made it through the initial setup just fine.</p>
<p>After choosing my region and keyboard layout, I got to the screen asking for a driver to connect to the network. I browsed successfully to the second thumb drive containing the drivers, but before I could even click the file, the system froze and shut down.</p>
<p>Since then, every attempt to boot has failed. It won‚Äôt get past the Snapdragon boot logo before rebooting or powering off‚Ä¶ again, seemingly at random. I can still get into the BDS menu, but no options are selectable. That means I can‚Äôt reinstall Windows 11 again, or try anything else for that matter, like Linux (which still lacks support for the Snapdragon Dev Kit).</p>
<p>I opened the system and reseated everything, including the SSD. No change. I even tested the SSD in another machine to rule it out, and it‚Äôs fine too.</p>
<h2 id="postmortem">Postmortem</h2>
<p>The system was perfectly healthy and working fine right up until that Windows update failed.</p>
<p>Did the update somehow overwrite firmware it shouldn‚Äôt have? Or partially corrupt some UEFI or bootloader component, enough to boot sometimes, but not enough to stay sane? It could also be a Secure Boot or TPM state mismatch, or even a low-level power-management firmware issue given the random reboot-versus-power-off behavior. And since this is a dev kit with no documented firmware recovery path, even a normally recoverable failure might be permanent.</p>
<p>Or maybe a piece of hardware just failed at exactly the wrong time. No idea.</p>
<p>If Qualcomm hadn‚Äôt discontinued the Snapdragon Dev Kit, this probably would‚Äôve been an inconvenience instead of a postmortem. A firmware recovery tool, documented reflashing process, or even a basic support path might have turned this into a bad afternoon rather than a dead system. On a supported consumer Snapdragon PC, I suspect this would‚Äôve been annoying, but fixable.</p>
<p>Is this a problem with the Snapdragon platform itself? I doubt it. It was flawless as a daily driver from October 2024 onward. But this also isn‚Äôt a typical Snapdragon-based Windows PC‚Ä¶ it‚Äôs the Snapdragon Dev Kit. The day it arrived was the same day Qualcomm announced it would be discontinuing it and stopping all future support. Unlike Snapdragon laptops from ASUS, Dell, or Lenovo, there are no OEM-backed recovery tools or firmware safety nets here.</p>
<p>And I certainly haven‚Äôt lost faith in the platform. The Snapdragon X Elite is excellent, and up until this one update, Windows 11 and the system performed flawlessly. It was a great PC for just over a year, and it‚Äôs a real bummer losing a 32GB machine that consistently smoked my Core i9 system.</p>
<p>Oh well. RIP, powerful little ARM box.</p>
<p><em><strong>P.S. If Qualcomm ever releases a firmware recovery tool for this thing, I‚Äôll happily update this post.</strong></em></p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Electronic nose for indoor mold detection and identification (132 pts)]]></title>
            <link>https://advanced.onlinelibrary.wiley.com/doi/10.1002/adsr.202500124</link>
            <guid>46520935</guid>
            <pubDate>Wed, 07 Jan 2026 00:31:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://advanced.onlinelibrary.wiley.com/doi/10.1002/adsr.202500124">https://advanced.onlinelibrary.wiley.com/doi/10.1002/adsr.202500124</a>, See on <a href="https://news.ycombinator.com/item?id=46520935">Hacker News</a></p>
Couldn't get https://advanced.onlinelibrary.wiley.com/doi/10.1002/adsr.202500124: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Why the trans flag emoji is the 5-codepoint sequence it is (139 pts)]]></title>
            <link>https://hecate.pink/blog/2026/trans-flag-emoji/</link>
            <guid>46520879</guid>
            <pubDate>Wed, 07 Jan 2026 00:22:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hecate.pink/blog/2026/trans-flag-emoji/">https://hecate.pink/blog/2026/trans-flag-emoji/</a>, See on <a href="https://news.ycombinator.com/item?id=46520879">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> 
    
      
  <p>Back in 2018, I was an intern at facebook<sup><a href="#1">1</a></sup>. I was also very early into my transition, so I was very in-the-loop with my trans collegeaues - and I heard about how one of the messenging teams (messenger? whatsapp? maybe both?) was going to be rolling out a trans pride flag emoji, and was encouraging early testing.</p>
<p>My first and immediate find? Copy-and-pasting the emoji into any other text field would result in a singular unknown glyph (like, say, ÔøΩ) - these clowns wanted to map it to a private use area codepoint! Fair enough, I suppose, for a corporation that wishes to ship on their own timelines - so I did some digging.</p>
<h2 id="some-background">some background</h2>
<p>I found no good prior art to go off of - I believe that the <a href="https://www.unicode.org/L2/L2019/19080-transgender-flag.pdf">eventually-accepted proposal</a> was circulating as a draft at the time, but I haven't been able to find any references or records of it from that period of time; I did find reference <a href="https://www.lgbtqnation.com/2018/07/unicode-refused-approve-trans-flag-emoji-instead-got-lobster/">here</a> to the unicode consortium rejecting a proposal for a trans flag that year - I think it might have been an earlier version of the proposal, it might have been an alternate proposal; I do know that I recalled seeing requests for a new codepoint to be issued for a trans flag emoji glyph, and a proposal without all of the requisite U+FE0F's.</p>
<p>The initial approach and codepoint mapping taken a day or so later was üè≥‚Äç‚öß - <code>[U+1F3F3, U+200D, U+26A7]</code>. That's pretty close to what the approved codepoints ended up being, and it likely displays correctly now, but it's lacking a couple U+FE0F's that were necessary at the time. Here's where things get into the weeds.</p>
<h2 id="u-fe0f-emoji-presentation-mode">U+FE0F: Emoji Presentation Mode</h2>
<p>Nowadays, if you go look at the <a href="https://emojipedia.org/transgender-flag#technical">listed codepoints</a> for üè≥Ô∏è‚Äç‚ößÔ∏è, you'll see <em>five</em> codepoints<sup><a href="#2">2</a></sup> (characters) that make it up, with two of them being <code>U+FE0F</code>. FEOF can be slapped after a symbol - without a ZWJ! - to indicate that the preceding codepoint should be interpreted for Emoji Presentation, and not textual mode - her sister, U+FE0E, does that. If you want to see this in action: [‚ößÔ∏é‚ößÔ∏è] is <code>[U+26A7 U+FE0E U+26A7 U+FEOF]</code>. Same codepoint, two render modes!</p>
<p>There was <a href="https://emojipedia.org/rainbow-flag#technical">some prior art</a> on how to approach the trans flag codepoints - emoji presentation white flag, zero width joiner, and a rainbow emoji. So, just swap the rainbow emoji for U+26A7 and we're good to go, right?</p>
<h2 id="u-200d-zero-width-joiner-my-beloved">U+200D: Zero-width joiner my beloved</h2>
<p>There's a lot of technical details about what is and is not technically valid to do with zero-width joiners. I'm not here to say that there is a <em>wrong</em> way to use the ZWJ to combine codepoints, because language is always-changing, but I <em>was there</em> to ensure that there is no <em>technical</em> reason to deny the trans flag proposal. The existing and eventually accepted proposal L2/19-080 that I linked earlier, proposed a four-codepoint approach, but it lacked the trailing U+FE0F for ‚öß.</p>
<p>You might see where I'm going with this: at the time, U+26A7 was a text-mode-only glyph. Including it in a ZWJ sequence <a href="https://www.unicode.org/reports/tr51/tr51-14.html#def_fully_qualified_emoji_zwj_sequence">was not valid without a following U+FE0F</a> at the time:</p>
<blockquote>
<p>fully-qualified emoji zwj sequence ‚Äî An emoji zwj sequence in which every default text presentation character (ED-7) is either followed by an emoji modifier or followed by an emoji presentation selector, and there are no other emoji or text presentation selectors in the sequence.</p>
</blockquote>
<p>At the time<sup><a href="#3">3</a></sup>, ‚öß was a text-mode only glyph; thus, it must be followed by an emoji presentation selector. I suggested the 5-codepoint mapping, and also advised that there should be an emoji-rendering glyph for U+26A7 U+FE0F. To my utter amazement, my feedback was followed!</p>
<p>The end result of this, was the 5-codepoint version of üè≥Ô∏è‚Äç‚ößÔ∏è was the first one to be out in the wild. You could send it on fb messenger, or whatsapp, and it'd render as a nice emoji; you could copy/paste it to another client, and you'd get the fallback render of a flag and a symbol, similar to the lag time between üè≥Ô∏è‚Äçüåà being an accepted sequence and vendors supporting rendering a couple years prior. The next year, the trans flag emoji proposal was accepted, citing the sequence already existing on whatsapp and rendering as a first-class emoji - no new codepoints or allocations needed; it only needed the blessing of its codepoint sequence, and an update to U+26A7 saying that it is valid to use it in emoji presentation mode (and emoji presentation sequences).</p>
<p>This does actually mean that now, the four-codepoint sequence for üè≥Ô∏è‚Äç‚ößÔ∏è is <em>now</em> valid, since now that ‚ößÔ∏é <em>can</em> be displayed in an emoji presentation, it doesn't <em>have</em> to be specified as needing emoji presentation in a ZWJ sequence. It is unfortunate that the transgender approach to acceptance feels like it necessitates being technically correct beyond all reproach in order to force acceptance - looking back, I think it's a bit of a shame that the advocates pushing for üè≥Ô∏è‚Äç‚ößÔ∏è through the appropriate mediums were being rebuffed for not being totally technically accurate (as they weren't including any details about U+26A7 needing emoji presentation), and that no one technical would actually work with them on getting those details corrected earlier. It wasn't until a corporation, a vendor, whatever broke ranks and just had a technically unassailable implementation, that it was included into the fold.</p>
<h3 id="if-there-is-one-mark-i-am-glad-to-have-left-on-this-earth-it-is-this-5-codepoint-sequence-pink-heart-flag-white-transgender-symbol-pink-heart">if there is one mark i am glad to have left on this earth, it is <a href="https://www.unicode.org/Public/emoji/latest/emoji-zwj-sequences.txt#:~:text=1F3F3%20FE0F%20200D%2026A7%20FE0F">this 5-codepoint sequence</a>. ü©∑üè≥Ô∏è‚Äç‚ößÔ∏èü©∑</h3>






    
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hyundai Introduces Its Next-Gen Atlas Robot at CES 2026 [video] (117 pts)]]></title>
            <link>https://www.youtube.com/watch?v=9e0SQn9uUlw</link>
            <guid>46520508</guid>
            <pubDate>Tue, 06 Jan 2026 23:40:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=9e0SQn9uUlw">https://www.youtube.com/watch?v=9e0SQn9uUlw</a>, See on <a href="https://news.ycombinator.com/item?id=46520508">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[CES 2026: Taking the Lids Off AMD's Venice and MI400 SoCs (110 pts)]]></title>
            <link>https://chipsandcheese.com/p/ces-2026-taking-the-lids-off-amds</link>
            <guid>46519326</guid>
            <pubDate>Tue, 06 Jan 2026 21:46:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chipsandcheese.com/p/ces-2026-taking-the-lids-off-amds">https://chipsandcheese.com/p/ces-2026-taking-the-lids-off-amds</a>, See on <a href="https://news.ycombinator.com/item?id=46519326">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>Hello you fine Internet folks,</p><p>Here at CES 2026, AMD showed off their upcoming Venice series of server CPUs and their upcoming MI400 series of datacenter accelerators. AMD has talked about the specifications of both Venice and the MI400 series at their Advancing AI event back in June of 2025, but this is the first time AMD has shown off the silicon for both of product lines.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!qd_2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4e23adc-da36-42af-b245-11459f567dcc_1674x960.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!qd_2!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4e23adc-da36-42af-b245-11459f567dcc_1674x960.png 424w, https://substackcdn.com/image/fetch/$s_!qd_2!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4e23adc-da36-42af-b245-11459f567dcc_1674x960.png 848w, https://substackcdn.com/image/fetch/$s_!qd_2!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4e23adc-da36-42af-b245-11459f567dcc_1674x960.png 1272w, https://substackcdn.com/image/fetch/$s_!qd_2!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4e23adc-da36-42af-b245-11459f567dcc_1674x960.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!qd_2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4e23adc-da36-42af-b245-11459f567dcc_1674x960.png" width="1456" height="835" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c4e23adc-da36-42af-b245-11459f567dcc_1674x960.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:835,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:766677,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://chipsandcheese.com/i/183673318?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4e23adc-da36-42af-b245-11459f567dcc_1674x960.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!qd_2!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4e23adc-da36-42af-b245-11459f567dcc_1674x960.png 424w, https://substackcdn.com/image/fetch/$s_!qd_2!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4e23adc-da36-42af-b245-11459f567dcc_1674x960.png 848w, https://substackcdn.com/image/fetch/$s_!qd_2!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4e23adc-da36-42af-b245-11459f567dcc_1674x960.png 1272w, https://substackcdn.com/image/fetch/$s_!qd_2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4e23adc-da36-42af-b245-11459f567dcc_1674x960.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>Starting with Venice, the first thing to notice is the packaging of the CCDs to the IO dies is different. Instead of using the organic substrate of the package to run the wires between the CCDs and the IO dies that AMD has used since EPYC Rome, Venice appears to be using a more advanced form of packaging similar to Strix Halo or MI250X. Another change is that Venice appears to have two IO dies instead of the single IO die that the prior EPYC CPUs had.</p><p><span>Venice has 8 CCDs each of which have 32 cores for a total of up to 256 cores per Venice package. Doing some measuring of each of the dies, you get that each CCD is approximately 165mm</span><sup>2 </sup><span>of N2 silicon. If AMD has stuck to 4MB of L3 per core than each of these CCDs have 32 Zen 6 cores and 128MB of L3 cache along with the die to die interface for the CCD &lt;-&gt; IO die communications. At approximately 165mm</span><sup>2</sup><span> per CCD, that would make a Zen 6 core plus the 4MB of L3 per core about 5mm</span><sup>2</sup><span> each which is similar to Zen 5‚Äôs approximately 5.34mm</span><sup>2</sup><span> on N3 when counting both the Zen 5 core and 4MB of L3 cache.</span></p><p><span>Moving to the IO dies, they each appear to be approximately 353mm</span><sup>2</sup><span> for a total of just over 700mm</span><sup>2</sup><span> of silicon dedicated for the IO dies. This is a massive increase from the approximately 400mm</span><sup>2</sup><span> that the prior EPYC CPUs dedicated for their IO dies. The two IO dies appear to be using an advanced packaging of some kind similar to the CCDs. Next to the IO dies appear to be 8 little dies, 4 on each side of the package, which are likely to either be structural silicon or deep trench capacitor dies meant to improve power delivery to the CCDs and IO dies.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!ivUB!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45dd5538-8896-4235-a618-546e3acdfa11_704x690.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!ivUB!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45dd5538-8896-4235-a618-546e3acdfa11_704x690.png 424w, https://substackcdn.com/image/fetch/$s_!ivUB!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45dd5538-8896-4235-a618-546e3acdfa11_704x690.png 848w, https://substackcdn.com/image/fetch/$s_!ivUB!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45dd5538-8896-4235-a618-546e3acdfa11_704x690.png 1272w, https://substackcdn.com/image/fetch/$s_!ivUB!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45dd5538-8896-4235-a618-546e3acdfa11_704x690.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!ivUB!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45dd5538-8896-4235-a618-546e3acdfa11_704x690.png" width="704" height="690" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/45dd5538-8896-4235-a618-546e3acdfa11_704x690.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:690,&quot;width&quot;:704,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:382099,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://chipsandcheese.com/i/183673318?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45dd5538-8896-4235-a618-546e3acdfa11_704x690.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!ivUB!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45dd5538-8896-4235-a618-546e3acdfa11_704x690.png 424w, https://substackcdn.com/image/fetch/$s_!ivUB!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45dd5538-8896-4235-a618-546e3acdfa11_704x690.png 848w, https://substackcdn.com/image/fetch/$s_!ivUB!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45dd5538-8896-4235-a618-546e3acdfa11_704x690.png 1272w, https://substackcdn.com/image/fetch/$s_!ivUB!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45dd5538-8896-4235-a618-546e3acdfa11_704x690.png 1456w" sizes="100vw"></picture></div></a></figure></div><p>Shifting off of Venice and on to the MI400 accelerator, this is a massive package with 12 HBM4 dies and ‚Äútwelve 2 nanometer and 3 nanometer compute and IO dies‚Äù. It appears as if there are two base dies just like MI350. But unlike MI350, there appears to also be two extra dies on the top and bottom of the base dies. These two extra dies are likely for off-package IO such as PCIe, UALink, etc.</p><p><span>Calculating the die sizes of the base dies and the IO dies, the die size of the base die is approximately 747mm</span><sup>2</sup><span> for each of the two base dies with the off-package IO dies each being approximately 220mm</span><sup>2</sup><span>.  As for the compute dies, while the packaging precludes any visual demarcation of the different compute dies, it is likely that there are 8 compute dies with 4 compute dies on each base die. So while we can‚Äôt figure out the exact die size of the compute dies, the maximum size is approximately 180mm</span><sup>2</sup><span>. The compute chiplet is likely in the 140mm</span><sup>2</sup><span> to 160mm</span><sup>2</sup><span> region but that is a best guess that will have to wait to be confirmed.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!w4k7!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a409225-b74c-403c-a268-4d42ef2d8c5a_3984x5975.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!w4k7!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a409225-b74c-403c-a268-4d42ef2d8c5a_3984x5975.jpeg 424w, https://substackcdn.com/image/fetch/$s_!w4k7!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a409225-b74c-403c-a268-4d42ef2d8c5a_3984x5975.jpeg 848w, https://substackcdn.com/image/fetch/$s_!w4k7!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a409225-b74c-403c-a268-4d42ef2d8c5a_3984x5975.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!w4k7!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a409225-b74c-403c-a268-4d42ef2d8c5a_3984x5975.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!w4k7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a409225-b74c-403c-a268-4d42ef2d8c5a_3984x5975.jpeg" width="1456" height="2184" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7a409225-b74c-403c-a268-4d42ef2d8c5a_3984x5975.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:2184,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:4569856,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://chipsandcheese.com/i/183673318?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a409225-b74c-403c-a268-4d42ef2d8c5a_3984x5975.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!w4k7!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a409225-b74c-403c-a268-4d42ef2d8c5a_3984x5975.jpeg 424w, https://substackcdn.com/image/fetch/$s_!w4k7!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a409225-b74c-403c-a268-4d42ef2d8c5a_3984x5975.jpeg 848w, https://substackcdn.com/image/fetch/$s_!w4k7!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a409225-b74c-403c-a268-4d42ef2d8c5a_3984x5975.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!w4k7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7a409225-b74c-403c-a268-4d42ef2d8c5a_3984x5975.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The MI455X and Venice are the two SoCs that are going to be powering AMD‚Äôs Helios AI Rack but they aren‚Äôt the only new Zen 6 and MI400 series products that AMD announced at CES. AMD announced that there would be a third member of the MI400 family called the MI440X joining the MI430X and MI455X. The MI440X is designed to fit into the 8-way UBB boxes as a direct replacement for the MI300/350 series. </p><p>AMD also announced Venice-X which is likely is going to be a V-Cache version of Venice. This is interesting because not only did AMD skip Turin-X but if there is a 256 core version of Venice-X, then this would be the first time that a high core count CCD will have the ability to support a V-Cache die. If AMD sticks to the same ratio of base die cache to V-Cache die cache, then each 32 core CCD would have up to 384MB of L3 cache which equates to 3 Gigabytes of L3 cache across the chip.</p><p>Both Venice and the MI400 series are due to launch later this year and I can‚Äôt wait to learn more about the underlying architectures of both SoCs.</p><p><span>If you like the content then consider heading over to the </span><a href="https://www.patreon.com/ChipsandCheese" rel="">Patreon</a><span> or </span><a href="https://www.paypal.com/donate/?hosted_button_id=4EMPH66SBGVSQ" rel="">PayPal</a><span> if you want to toss a few bucks to Chips and Cheese, also consider joining the </span><a href="https://discord.gg/TwVnRhxgY2" rel="">Discord</a><span>.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Comparing AI agents to cybersecurity professionals in real-world pen testing (104 pts)]]></title>
            <link>https://arxiv.org/abs/2512.09882</link>
            <guid>46518996</guid>
            <pubDate>Tue, 06 Jan 2026 21:23:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2512.09882">https://arxiv.org/abs/2512.09882</a>, See on <a href="https://news.ycombinator.com/item?id=46518996">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
    <div><p><span>Authors:</span><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lin,+J+W" rel="nofollow">Justin W. Lin</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jones,+E+K" rel="nofollow">Eliot Krzysztof Jones</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jasper,+D+J" rel="nofollow">Donovan Julian Jasper</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ho,+E+J" rel="nofollow">Ethan Jun-shen Ho</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wu,+A" rel="nofollow">Anna Wu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yang,+A+T" rel="nofollow">Arnold Tianyi Yang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Perry,+N" rel="nofollow">Neil Perry</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zou,+A" rel="nofollow">Andy Zou</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fredrikson,+M" rel="nofollow">Matt Fredrikson</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kolter,+J+Z" rel="nofollow">J. Zico Kolter</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liang,+P" rel="nofollow">Percy Liang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Boneh,+D" rel="nofollow">Dan Boneh</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ho,+D+E" rel="nofollow">Daniel E. Ho</a></p></div>            
    <p><a href="https://arxiv.org/pdf/2512.09882">View PDF</a>
    <a href="https://arxiv.org/html/2512.09882v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>We present the first comprehensive evaluation of AI agents against human cybersecurity professionals in a live enterprise environment. We evaluate ten cybersecurity professionals alongside six existing AI agents and ARTEMIS, our new agent scaffold, on a large university network consisting of ~8,000 hosts across 12 subnets. ARTEMIS is a multi-agent framework featuring dynamic prompt generation, arbitrary sub-agents, and automatic vulnerability triaging. In our comparative study, ARTEMIS placed second overall, discovering 9 valid vulnerabilities with an 82% valid submission rate and outperforming 9 of 10 human participants. While existing scaffolds such as Codex and CyAgent underperformed relative to most human participants, ARTEMIS demonstrated technical sophistication and submission quality comparable to the strongest participants. We observe that AI agents offer advantages in systematic enumeration, parallel exploitation, and cost -- certain ARTEMIS variants cost $18/hour versus $60/hour for professional penetration testers. We also identify key capability gaps: AI agents exhibit higher false-positive rates and struggle with GUI-based tasks.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Justin Lin [<a href="https://arxiv.org/show-email/9298da67/2512.09882" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Wed, 10 Dec 2025 18:12:29 UTC (1,057 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Oral microbiome sequencing after taking probiotics (150 pts)]]></title>
            <link>https://blog.booleanbiotech.com/oral-microbiome-biogaia</link>
            <guid>46518804</guid>
            <pubDate>Tue, 06 Jan 2026 21:10:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.booleanbiotech.com/oral-microbiome-biogaia">https://blog.booleanbiotech.com/oral-microbiome-biogaia</a>, See on <a href="https://news.ycombinator.com/item?id=46518804">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>Recently, a friend recommended <a href="https://www.biogaia.com/products/biogaia-prodentis/">BioGaia Prodentis</a> to me.
It is a DTC oral probiotic you can buy online that is supposedly good for oral health.
I thought it would be interesting to do some sequencing to see what, if anything, it did to my oral microbiome.</p>
<p><img src="https://blog.booleanbiotech.com/images/oral_biogaia.jpg" width="100%"></p>
<p><em>BioGaia Prodentis is <a href="https://www.walmart.com/ip/BioGaia-Prodentis-Clinically-Proven-Dental-Probiotics-Teeth-Gums-Promotes-Good-Oral-Health-Gut-Too-30-Mint-Flavored-Lozenges-1-Pack/175541687">available online</a> for $20 or less for a month's supply</em></p>
<h2>BioGaia</h2>
<p><a href="https://www.biogaia.com/collections/all">BioGaia</a> has a fascinating story.
They are a Swedish company, founded over 30 years ago, that exclusively sells probiotics DTC. 
They have developed multiple strains of <em>Limosilactobacillus reuteri</em>, mainly for gut and oral health.
They apparently sell well! Their <a href="https://www.nasdaq.com/european-market-activity/shares/biog-b?id=TX184">market cap</a> is around $1B‚Äîimpressive for a consumer biotech.</p>
<p>Going in, I expected scant evidence for any real benefits to their probiotics, but the data (<a href="https://www.biogaia.com/pages/probiotic-innovation">over 250 clinical studies</a>) is much more complete than I expected.</p>
<!--
They have been involved in .
I asked [Edison](https://platform.edisonscientific.com/) to assess the BioGaia literature.
Edison said the results were "reasonable, legitimate, and generally trustworthy".
-->

<p>Most notably, their gut probiotic, <a href="https://www.biogaia.com/products/protectis-baby-drops">Protectis</a>,
seems to have a significant effect on preventing
<a href="https://my.clevelandclinic.org/health/diseases/10026-necrotizing-enterocolitis">Necrotizing Enterocolitis</a> (NEC) in premature babies.
According to their <a href="https://ibtherapeutics.com/ibt-is-addressing-urgent-medical-needs-in-the-premature-infant/">website</a>:</p>
<blockquote>
<p>5-10% of the smallest premature infants develop NEC, a potentially lethal disorder in which portions of the bowel undergo tissue death.</p>
</blockquote>
<p>In March 2025, the FDA granted Breakthrough Therapy Designation to <a href="https://ibtherapeutics.com/press-releases/ibt-is-granted-breakthrough-therapy-designation-for-its-drug-candidate/">IBP-9414</a>,
an <em>L. reuteri</em> probiotic developed by BioGaia spinout <a href="https://ibtherapeutics.com/">IBT</a>.</p>
<!--
From a recent [review](https://pmc.ncbi.nlm.nih.gov/articles/PMC8306447/):
>Conclusion: Currently, probiotics are widely used to prevent and treat numerous gastrointestinal disorders. In our opinion, L. reuteri meets all the requirements to be considered a safe, well-tolerated, and efficacious probiotic that is able to contribute to the beneficial effects on gut-human health, preventing and treating many gastrointestinal symptoms, and speeding up the recovery and discharge of patients accessing the emergency department.
-->

<p>This is not specifically for the oral health product, but it's for sure more science than I expected to see going in.</p>
<h3>Prodentis</h3>
<p>BioGaia Prodentis contains two strains of <em>L. reuteri</em>: <a href="https://www.ncbi.nlm.nih.gov/biosample/43393324">DSM 17938</a>
and <a href="https://www.ncbi.nlm.nih.gov/biosample/?term=ATCC%20PTA%205289">ATCC PTA 5289</a>.
The claimed benefits include fresher breath, healthier gums, and outcompeting harmful bacteria.</p>
<h2>Sequencing with Plasmidsaurus</h2>
<p>Many readers will be familiar with <a href="https://plasmidsaurus.com/">Plasmidsaurus</a>.
Founded in 2021, the team took a relatively simple idea:
use massively multiplexed Oxford Nanopore (ONT) to offer complete plasmid sequencing with one day turnaround for $15,
and scaled it.
Plasmidsaurus quickly became part of biotech's core infrastructure, and spread like wildfire.
It also inspired multiple copycats.</p>
<p>Compared to Illumina, ONT is faster and has much longer reads, but lower throughput and lower accuracy.
This profile is a great fit to many sequencing problems like plasmid QC, where you only need megabases of sequences, but want an answer within 24 hours.</p>
<p>Over time, Plasmidsaurus has been adding services, including genome sequencing, RNA-Seq, and microbiome sequencing,
all based on ONT sequencing.</p>
<p><img src="https://blog.booleanbiotech.com/images/oral_plasmidsaurus_list.png" width="100%"></p>
<p><em>Plasmidsaurus accepts many kinds of sample for microbiome sequencing</em></p>
<p>I used their <a href="https://plasmidsaurus.com/microbiome">16S sequencing product</a>, which costs $45 for ~5000 reads, plus $15 for DNA extraction.
16S sequencing is an efficient way to amplify and sequence a small amount of DNA (the ubiquitous 16S region)
and be able to assign reads to specific species or even strains.</p>
<p>This experiment cost me $240 for four samples, and I got data back in around a week.
It's very convenient that I no longer have to do my <a href="https://blog.booleanbiotech.com/human-genome-at-home">own</a> <a href="https://blog.booleanbiotech.com/sequencing-at-home-with-flongle">sequencing</a>.
As a side note, you can pay more for more than 5000 reads, but unless you want information on very rare strains (&lt;&lt;1% frequency),
this is a waste of money.</p>
<p>Sample collection is simple: take 100-250 ¬µL of saliva and mix with 500 ¬µL of <a href="https://www.zymoresearch.com/collections/dna-rna-shield">Zymo DNA/RNA Shield</a>
(which I also had to buy for around $70.) You also need <a href="https://www.amazon.com/dp/B09DYWX8Q2?ref=ppx_yo2ov_dt_b_fed_asin_title">2 mL screwtop tubes</a> to ship in.</p>
<p>The reads are high quality for nanopore sequencing, with a median Q score of 23 (99%+ accuracy).
This is more than sufficient accuracy for this experiment.
The read length is very tightly distributed around 1500 nt (the length of a typical 16S region).</p>
<p>The results provided by Plasmidsaurus include taxonomy tables, per-read assignments, and some basic plots.
I include a download of the results at the end of this article, as well as the FASTQ files.</p>
<h2>The experiment</h2>
<p>The main idea of the experiment was to see if any <em>L. reuteri</em> would colonize by the end of 30 days of probiotic use,
and if so, whether it would persist beyond that.
I collected four saliva samples:</p>
<table>
<thead>
<tr>
<th>Sample</th>
<th>Timing</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Baseline A</td>
<td>Day -4</td>
<td>A few days before starting BioGaia</td>
</tr>
<tr>
<td>Baseline B</td>
<td>Day -1</td>
<td>The day before I started BioGaia</td>
</tr>
<tr>
<td>Day 30</td>
<td>Day 30</td>
<td>The last day of the 30 day course</td>
</tr>
<tr>
<td>Week after</td>
<td>Day 37</td>
<td>One week after completing the course</td>
</tr>
</tbody>
</table>
<p><img src="https://blog.booleanbiotech.com/images/oral_heatmap.svg"></p>
<p><em>Heatmap of the top 20 species. All species assignments were done by <a href="https://plasmidsaurus.com/technical-documentation/microbiome">Plasmidsaurus</a></em></p>
<h2>Did <em>L. reuteri</em> colonize?</h2>
<p>There was no <em>L. reuteri</em> found in any of the samples.
I did a manual analysis to check for any possible misassignments,
but the closest read was only 91% identical to either <em>L. reuteri</em> strain.</p>
<p>The probiotic either (a) didn't colonize the oral cavity;
(b) was present only transiently while actively taking the lozenges;
(c) was below the detection threshold.</p>
<p>Probiotics are generally bad at colonizing, which is why you have to keep taking them.
Still, I was surprised not to see a single <em>L. reuteri</em> read in there.</p>
<h2>What actually changed?</h2>
<p>Even though the probiotic itself didn't show up,
the oral microbiome did change quite a lot.</p>
<p>The most striking change was a massive increase in <em>S. salivarius</em>.
<em>S. salivarius</em> went from essentially absent to ~20% of my oral microbiome on the last day.
However, this happened <em>one week after</em> I stopped taking the probiotic,
so it's very unclear if it is related.</p>
<table>
<thead>
<tr>
<th>Sample</th>
<th><em>S. mitis</em></th>
<th><em>S. salivarius</em></th>
</tr>
</thead>
<tbody>
<tr>
<td>Baseline A</td>
<td>2.0%</td>
<td>0.4%</td>
</tr>
<tr>
<td>Baseline B</td>
<td><strong>15.9%</strong></td>
<td>0.0%</td>
</tr>
<tr>
<td>Day 30</td>
<td><strong>10.2%</strong></td>
<td>0.8%</td>
</tr>
<tr>
<td>Week after</td>
<td>1.0%</td>
<td><strong>19.3%</strong></td>
</tr>
</tbody>
</table>
<p>We see <em>S. mitis</em> decreasing as <em>S. salivarius</em> increases, 
while the total Streptococcus fraction stayed roughly stable.
It's possible one species replaced the other within the same ecological niche.</p>
<p><em>S. salivarius</em> is itself a probiotic species.
The strain <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC1449041/">BLIS K12</a>
was isolated from a healthy New Zealand child and is sold commercially for oral health.
It produces bacteriocins that kill <em>Streptococcus pyogenes</em> (strep throat bacteria).</p>
<p>At the same time, <em>V. tobetsuensis</em> increased in abundance from 2.1% to 5.7%.
Veillonella bacteria can't eat sugar directly‚Äîthey survive by consuming lactate that Streptococcus produces.
The <em>S. salivarius</em> bloom is plausibly feeding them.</p>
<!--
## A bacterial friendship dissolved

*Haemophilus parainfluenzae* and *Streptococcus mitis* are known to
[live adjacent to each other](https://www.nature.com/articles/s41396-021-01141-3)
in oral biofilms ‚Äî they're positively correlated in healthy mouths.

Both decreased together in my samples.
The Haemophilus species (*H. parainfluenzae*, *H. parahaemolyticus*, *H. haemolyticus*)
collectively dropped from ~14% to ~7%, with some species disappearing entirely.

Interestingly, *H. parainfluenzae* is
[associated with good oral health](https://pmc.ncbi.nlm.nih.gov/articles/PMC11406952/),
not bad ‚Äî so losing it isn't necessarily a win.
The oral microbiome shifted from Proteobacteria (Haemophilus) toward Firmicutes (Streptococcus).
-->

<h2>Are these changes real or intra-day variation?</h2>
<p>There was a lot more variation in species than I expected, especially comparing the two baseline samples. 
In retrospect, I should have taken multiple samples on the same day, and mixed them to smooth it out.</p>
<p>However, there is some light evidence that the variation I see is not just intra-day variation.
Specifically, there are several species that stay consistent in frequency across all samples:
e.g., <em>Neisseria subflava</em>, <em>Streptococcus viridans</em>, <em>Streptococcus oralis</em>.</p>
<!--
The *S. salivarius* increase shows variability **6x beyond baseline noise**,
strongly suggesting this is a real biological change, not random fluctuation.

**Caveat:** *S. mitis* was already highly variable at baseline (2% vs 16%),
so some species are naturally dynamic in the oral microbiome.
But the *S. salivarius* signal (0% ‚Üí 19%) is unambiguous.
-->

<h2>Conclusions</h2>
<ul>
<li><em>L. reuteri</em> didn't detectably colonize my mouth. Oral probiotics are surprisingly difficult to detect, even if you sample the same day as dosing.</li>
<li><em>S. salivarius</em> increased massively in abundance, but this increase happened after I stopped taking BioGaia</li>
<li>Microbiome sequencing can be used to assess oral health. None of the <a href="https://en.wikipedia.org/wiki/Red_complex">"red complex"</a> bacteria (<em>P. gingivalis</em>, <em>T. forsythia</em>, <em>T. denticola</em>) associated with gum disease were found in any sample.</li>
<li>The oral microbiome is dynamic, with huge swings in species abundance over a timeframe of just weeks</li>
<li>Microbiome sequencing is very easy and convenient these days thanks to Plasmidsaurus</li>
<li>Prodentis tastes good, may help with oral health, and I'd consider taking it again</li>
</ul>
<h2>Data</h2>
<ul>
<li><a href="https://public.booleanbiotech.com/GVNLJW_fastq.zip">Download Raw FASTQ (50MB)</a></li>
<li><a href="https://public.booleanbiotech.com/GVNLJW_results.zip">Download Analysis Results (3MB)</a></li>
</ul>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A 30B Qwen model walks into a Raspberry Pi and runs in real time (253 pts)]]></title>
            <link>https://byteshape.com/blogs/Qwen3-30B-A3B-Instruct-2507/</link>
            <guid>46518573</guid>
            <pubDate>Tue, 06 Jan 2026 20:55:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://byteshape.com/blogs/Qwen3-30B-A3B-Instruct-2507/">https://byteshape.com/blogs/Qwen3-30B-A3B-Instruct-2507/</a>, See on <a href="https://news.ycombinator.com/item?id=46518573">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="blog-content">
      

      <div>
        <section>
          <p>
            For this release, we optimize for what people actually experience when they run a model: 
            <strong>fast, high-quality responses on a specific target device</strong>.
          </p>

          <p>
            We use Shapelearn, our bitlength learning method to choose weight datatypes for 
            <strong>Qwen3-30B-A3B-Instruct-2507</strong> that maximize performance in terms of 
            tokens per second (TPS) and output quality, with one practical constraint: the model 
            must fit comfortably in the available memory. Once it fits, making the file smaller 
            isn't a goal by itself. We only shrink further when it also improves the real tradeoff 
            people care about: <strong>speed vs. quality</strong>.
          </p>

          <p>
            Approaching bitlength learning this way matters because in llama.cpp, "fewer bits" doesn't 
            automatically mean "more speed." Different quantization formats can trigger different kernels 
            and overheads, and on some GPUs, <strong>going lower-bit can even get slower</strong>, despite 
            using less memory.
          </p>

          <p>
            <strong>Bottom line:</strong> treat memory as a <strong>budget</strong> to meet, then optimize what 
            matters most: <strong>TPS and quality</strong>.
          </p>
        </section>

        

        <section>
          <h2>TL;DR</h2>
          <p>
            Yes, this 30B Qwen3 runs on a Raspberry Pi. On a Pi 5 (16GB),
            <code>
              <a href="https://huggingface.co/byteshape/Qwen3-30B-A3B-Instruct-2507-GGUF/blob/main/Qwen3-30B-A3B-Instruct-2507-Q3_K_S-2.70bpw.gguf" target="_blank" rel="noopener noreferrer">
                Q3_K_S-2.70bpw [KQ-2]
              </a>
            </code>
            hits 8.03 TPS at 2.70 BPW and maintains 94.18% of BF16 quality. It genuinely feels
            real-time. More broadly, the same pattern shows up everywhere else: ByteShape models
            give you a better TPS/quality tradeoff than the alternatives (here we look at Unsloth
            and MagicQuant).
          </p>
        </section>

        <section>
          <h2>CPUs</h2>
          <p>
            On CPUs, the reducing footprint via shorter bitlengths affects the TPS and accuracy
            tradeoff as one would expect: once the model fits, reducing footprint tends to increase
            TPS in a fairly monotonic way. If datatypes are selected correctly, you can trade a bit
            of quality for speed predictably, which makes it much easier to pick a point on the
            curve that matches your constraints.
          </p>

          <p>
            We'll start with the most memory-constrained CPU case (Raspberry Pi 5 16GB), where
            "fits in RAM" is the limiting factor, then move to an Intel i7 with 64GB, where
            everything fits.
          </p>

          <h3>Raspberry Pi 5</h3>
          <p>
            The figure below shows TPS vs. normalized accuracy for the models that fit in RAM on
            the Raspberry Pi 5 16GB.
          </p>

          <!-- Mobile version: PNG -->
          <figure>
            <img src="https://byteshape.com/blogs/Qwen3-30B-A3B-Instruct-2507/images/averagen_bubble_chart_bpw_size_pi.png" alt="Raspberry Pi 5 performance: tokens per second vs quality">
            <figcaption>
              Raspberry Pi 5: Tokens per second vs quality (bubble size = model footprint)
            </figcaption>
          </figure>
          <!-- Desktop version: Interactive HTML -->
          <figure>
            
            <figcaption>
              Raspberry Pi 5: Tokens per second vs quality (bubble size = model footprint)
            </figcaption>
          </figure>

          <p>
            Notably, sustaining <strong>8.5 TPS at 92%+ baseline accuracy</strong> with a 30B model on a 
            Raspberry Pi reshapes expectations for Pi-class systems. Overall, the trend shows that ShapeLearn 
            consistently produces better models, with ByteShape trending up and to the right of Unsloth, 
            achieving higher tokens per second at the same quality, or higher quality at the same throughput.
          </p>

          <p>We highlight choices for two primary objectives: accuracy or response time.</p>

          <ul>
            <li>
              <strong>Optimizing for response time while maintaining accuracy:</strong> For interactive, 
              on-device use, perceived responsiveness is driven by how quickly text appears, not peak 
              throughput. In practice, generation feels real-time once it reaches roughly <strong>8 TPS</strong>, 
              comfortably above typical reading speed. In this Raspberry Pi real-time regime, 
              <code>
                <a href="https://huggingface.co/byteshape/Qwen3-30B-A3B-Instruct-2507-GGUF/blob/main/Qwen3-30B-A3B-Instruct-2507-Q3_K_S-2.70bpw.gguf" target="_blank" rel="noopener noreferrer">
                  Q3_K_S-2.70bpw [KQ-2]
                </a>
              </code>
              (2.70 BPW, 8.03 TPS, 94.18% accuracy) is our go-to recommendation: it crosses the
              real-time threshold while maintaining high accuracy. Compared 
              to Unsloth models at similar quality, ByteShape achieves real-time performance at lower BPW 
              and higher TPS, making it the more efficient choice for interactive edge deployment.
            </li>
            <li>
              <strong>Accuracy above all:</strong> The table below lists the models that achieve the highest 
              accuracy while still being able to run on a Raspberry Pi. Within this set, ByteShape models 
              make the best use of the available resources to maximize accuracy, occupying the 
              <strong>lowest-error rows</strong> (~1.1‚Äì1.3% relative error, ~98.8% accuracy), while the 
              strongest Unsloth entries remain around 2.1‚Äì2.2% error (~97.9% accuracy). Compared to Unsloth's 
              <code>UD-Q3_K_XL [8]</code>, ByteShape achieves up to a <strong>1.87√ó lower error rate</strong> 
              while still operating at <strong>~5‚Äì6 TPS</strong>, comfortably within TPS-norms on Raspberry PI 
              making it the better choice when accuracy is the priority. <br>
              Even when prioritizing maximum speed with some reduction in accuracy,
              <code>
                <a href="https://huggingface.co/byteshape/Qwen3-30B-A3B-Instruct-2507-GGUF/blob/main/Qwen3-30B-A3B-Instruct-2507-Q3_K_S-3.25bpw.gguf" target="_blank" rel="noopener noreferrer">
                  Q3_K_S-3.25bpw [KQ-5]
                </a>
              </code>
              offers a better tradeoff: <strong>more accurate, smaller, and faster</strong> than
              the fastest Unsloth model.
            </li>
          </ul>

          <table>
            <thead>
              <tr>
                <th>Model</th>
                <th>Relative Error</th>
                <th>BPW</th>
                <th>TPS</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>
                  <code>
                    <a href="https://huggingface.co/byteshape/Qwen3-30B-A3B-Instruct-2507-GGUF/blob/main/Qwen3-30B-A3B-Instruct-2507-Q4_K_S-3.92bpw.gguf" target="_blank" rel="noopener noreferrer">
                      Q4_K_S-3.92bpw [KQ-7]
                    </a>
                  </code>
                </td>
                <td>1.14%</td>
                <td>3.92</td>
                <td>5.30</td>
              </tr>
              <tr>
                <td>
                  <code>
                    <a href="https://huggingface.co/byteshape/Qwen3-30B-A3B-Instruct-2507-GGUF/blob/main/Qwen3-30B-A3B-Instruct-2507-Q4_K_S-3.61bpw.gguf" target="_blank" rel="noopener noreferrer">
                      Q4_K_S-3.61bpw [KQ-6]
                    </a>
                  </code>
                </td>
                <td>1.25%</td>
                <td>3.61</td>
                <td>5.94</td>
              </tr>
              <tr>
                <td>
                  <code>
                    <a href="https://huggingface.co/byteshape/Qwen3-30B-A3B-Instruct-2507-GGUF/blob/main/Qwen3-30B-A3B-Instruct-2507-Q3_K_S-3.25bpw.gguf" target="_blank" rel="noopener noreferrer">
                      Q3_K_S-3.25bpw [KQ-5]
                    </a>
                  </code>
                </td>
                <td>2.03%</td>
                <td>3.25</td>
                <td>6.68</td>
              </tr>
              <tr>
                <td><code>UD-IQ3_XXS [6]</code></td>
                <td>2.22%</td>
                <td>3.38</td>
                <td>5.03</td>
              </tr>
              <tr>
                <td><code>UD-Q3_K_XL [8]</code></td>
                <td>2.13%</td>
                <td>3.62</td>
                <td>6.28</td>
              </tr>
            </tbody>
          </table>

          <p>
            Many other Unsloth and MagicQuant models (some of ours too!) are not in this chart. We compare 
            them in other sections, but they're not applicable in the Raspberry Pi case. They simply don't fit!
          </p>

          <h3>Intel i7</h3>
          <p>
            Next, we move to the Intel i7 with 64GB RAM. The figure below shows TPS vs 
            normalized accuracy for all models.
          </p>

          <!-- Mobile version: PNG -->
          <figure>
            <img src="https://byteshape.com/blogs/Qwen3-30B-A3B-Instruct-2507/images/averagen_bubble_chart_bpw_size_i7.png" alt="Intel i7 performance: tokens per second vs quality">
            <figcaption>
              Intel i7: Tokens per second vs quality (bubble size = model footprint)
            </figcaption>
          </figure>
          <!-- Desktop version: Interactive HTML -->
          <figure>
            
            <figcaption>
              Intel i7: Tokens per second vs quality (bubble size = model footprint)
            </figcaption>
          </figure>

          <p>
            Overall, ByteShape models outperform both Unsloth and MagicQuant, delivering higher quality at 
            comparable throughput using fewer bits per parameter. Only ByteShape offers models that run in 
            the 26+ TPS range, extending performance well beyond the other methods.
          </p>

          <p><strong>Highlights:</strong></p>

          <ul>
            <li>
              <strong>Quality-first:</strong> At the high-accuracy end of the table,
              <code>
                <a href="https://huggingface.co/byteshape/Qwen3-30B-A3B-Instruct-2507-GGUF/blob/main/Qwen3-30B-A3B-Instruct-2507-IQ4_XS-4.67bpw.gguf" target="_blank" rel="noopener noreferrer">
                  IQ4_XS-4.67bpw [KQ-9]
                </a>
              </code>
              achieves the lowest relative error (0.25%), outperforming the best-running Unsloth
              models (<code>Q6_K [20]</code> and <code>Q5_K_M [18]</code> whose 
              relative errors are 0.36% and 0.44%). Compared directly, ByteShape delivers up to a 1.44√ó lower 
              error rate with higher throughput than <code>Q6_K [20]</code>, and a 1.76√ó lower error rate at 
              essentially the same speed as <code>Q5_K_M [18]</code>. MagicQuant <code>mxfp4 [3]</code> trails 
              in this regime, with both higher error and lower TPS.
            </li>
            <li>
              <strong>Balanced point:</strong> In the mid-accuracy, high-throughput region,
              <code>
                <a href="https://huggingface.co/byteshape/Qwen3-30B-A3B-Instruct-2507-GGUF/blob/main/Qwen3-30B-A3B-Instruct-2507-Q3_K_S-3.25bpw.gguf" target="_blank" rel="noopener noreferrer">
                  Q3_K_S-3.25bpw [KQ-5]
                </a>
              </code>
              combines ~98% accuracy with 23.1 TPS at just 3.25 BPW, offering the best overall
              balance in the table. Matching or exceeding this accuracy with Unsloth 
              (<code>IQ4_XS [10]</code>) requires higher BPW and lower TPS, while choosing an Unsloth model 
              closer in speed (<code>Q3_K_S [7]</code>) incurs a 1.73√ó higher error rate. MagicQuant does not 
              offer a competitive model in this range; its fastest entry (<code>IQ4_NL [2]</code>) is behind both 
              ByteShape and Unsloth in accuracy and throughput.
            </li>
          </ul>

          <p>
            <strong>Takeaway:</strong> Across both quality-first and balanced settings, ByteShape consistently 
            converts the available bit budget into either higher accuracy or higher TPS, and is the only approach 
            that simultaneously covers the high-quality and 26+ TPS balanced-performance regions in this comparison.
          </p>
        </section>

        <section>
          <h2>GPUs: RTX5090/32GB and RTX4080/16GB</h2>
          <p>
            On GPUs, performance depends as much on <strong>kernel choice</strong> as on raw memory footprint. 
            For matmul/matvec, llama.cpp's quantization-specific GPU decode paths incur very different overheads, 
            so fewer bits per weight do <strong>not</strong> reliably translate to higher TPS. Instead, TPS often 
            peaks at quantization-specific sweet spots. Pushing BPW lower can even <strong>increase VRAM traffic 
            and instruction count</strong>, hurting performance rather than improving it. We dig into this behavior in 
            more detail right after the GPU results section, where the kernel-level tradeoffs become more apparent.
          </p>

          <p>
            We evaluate on two GPUs: an <strong>RTX 5090 (32 GB)</strong>, which can run models 
            <strong>above 4 BPW</strong> and typically reach the fastest sweet spots, and an 
            <strong>RTX 4080 (16 GB)</strong>, where <strong>&gt;4 BPW models do not fit</strong>, forcing 
            different trade-offs and making the device-optimized curve easier to see.
          </p>

          <h3>RTX 5090 (32GB of VRAM)</h3>
          <p>
            Let's start with the 5090, which has enough VRAM to support all of the quantized models. The figure 
            below shows TPS vs normalized accuracy.
          </p>

          <!-- Mobile version: PNG -->
          <figure>
            <img src="https://byteshape.com/blogs/Qwen3-30B-A3B-Instruct-2507/images/averagen_bubble_chart_bpw_size_5090.png" alt="RTX 5090 performance: tokens per second vs quality">
            <figcaption>
              RTX 5090: Tokens per second vs quality (bubble size = model footprint)
            </figcaption>
          </figure>
          <!-- Desktop version: Interactive HTML -->
          <figure>
            
            <figcaption>
              RTX 5090: Tokens per second vs quality (bubble size = model footprint)
            </figcaption>
          </figure>

          <p>
            Two things stand out immediately:<br>
            First, this GPU shows a clear <strong>~4-bit sweet spot</strong>: several ~4b models
            cluster at very high TPS with nearly identical quality. Examples include
            <code>Unsloth Q4_0 [12]</code>, <code>Unsloth IQ4_XS [10]</code>,
            <code>
              <a href="https://huggingface.co/byteshape/Qwen3-30B-A3B-Instruct-2507-GGUF/blob/main/Qwen3-30B-A3B-Instruct-2507-IQ4_XS-3.87bpw.gguf" target="_blank" rel="noopener noreferrer">
                IQ4_XS-3.87bpw [IQ-6]
              </a>
            </code>
            , and MagicQuant <code>iq4_nl-EHQKOUD-IQ4NL [1]</code>, all running around ~302‚Äì303 TPS
            at ~98.4‚Äì98.9% accuracy. Within 
            this tight cluster, Unsloth edges out slightly in throughput and quality.
          </p>

          <p>
            Second, outside of that sweet spot, the tradeoff becomes much more uneven:
          </p>

          <ul>
            <li>
              Many other Unsloth and Magic Quant models show <strong>significantly lower TPS</strong>, regardless 
              of whether they are quantized more or less aggressively.
            </li>
            <li>
              Past the ~4b region, only ByteShape continues to increase TPS with a more predictable reduction in quality.
            </li>
          </ul>

          <p>
            <strong>Accuracy-critical workloads:</strong> when output quality is paramount,
            ByteShape delivers the most accurate model on the 5090:
            <code>
              <a href="https://huggingface.co/byteshape/Qwen3-30B-A3B-Instruct-2507-GGUF/blob/main/Qwen3-30B-A3B-Instruct-2507-IQ4_XS-4.67bpw.gguf" target="_blank" rel="noopener noreferrer">
                IQ4_XS-4.67bpw [IQ-8]
              </a>
            </code>
            (4.67 BPW, 272.98 TPS, 99.75% accuracy). It surpasses <code>Unsloth Q6_K [20]</code> (6.57 BPW, 264.88 TPS, 99.64% accuracy) 
            while using fewer bits and achieving slightly higher throughput, and it clearly outperforms MagicQuant 
            <code>mxfp4_moe-H-B16-EUR-IQ4NL-KO-Q5K-QD-Q6K [3]</code> (5.46 BPW, 240.42 TPS, 99.32% accuracy) in both 
            accuracy and speed, making it the strongest choice when accuracy is a task-critical deployment requirement.
          </p>

          <p>
            <br><strong>Practical takeaway.</strong> If your GPU has enough VRAM to run a strong ~4b model that 
            already meets your speed and accuracy requirements, that cluster is an excellent default. The curve becomes 
            more interesting when task-critical deployment constraints demand higher accuracy or smaller models as for 
            example, under tighter memory budgets or constrained environments (as we'll see on the 4080).
          </p>

          <h3>RTX 4080 (16GB of VRAM)</h3>
          <p>
            Next, let's move to a more accessible GPU, especially in these memory-challenged times. The biggest 
            stumbling block for the 4080 is its 16GB of VRAM, which is not sufficient to support the "magical" 
            ~4b quantizations for a 30B model. How convenient!<strong> </strong>This "avoids" the 5090's ~4b sweet 
            spot and forces a more "real-world" comparison under a hard VRAM budget. The figure below shows TPS versus 
            normalized accuracy for all models that fit on the 4080.
          </p>

          <!-- Mobile version: PNG -->
          <figure>
            <img src="https://byteshape.com/blogs/Qwen3-30B-A3B-Instruct-2507/images/averagen_bubble_chart_bpw_size_4080.png" alt="RTX 4080 performance: tokens per second vs quality">
            <figcaption>
              RTX 4080: Tokens per second vs quality (bubble size = model footprint)
            </figcaption>
          </figure>
          <!-- Desktop version: Interactive HTML -->
          <figure>
            
            <figcaption>
              RTX 4080: Tokens per second vs quality (bubble size = model footprint)
            </figcaption>
          </figure>

          <p>
            On the RTX 4080, ByteShape consistently outperforms Unsloth under the same 16 GB VRAM constraint, 
            delivering a better TPS‚Äìquality tradeoff.
          </p>

          <p>
            In particular, ByteShape's highest-quality model that fits,
            <code>
              <a href="https://huggingface.co/byteshape/Qwen3-30B-A3B-Instruct-2507-GGUF/blob/main/Qwen3-30B-A3B-Instruct-2507-IQ4_XS-3.87bpw.gguf" target="_blank" rel="noopener noreferrer">
                IQ4_XS-3.87bpw [IQ-6]
              </a>
            </code>
            (3.87 BPW, 214.81 TPS, 98.66% accuracy) delivers:
          </p>

          <ul>
            <li>
              a 1.59√ó lower error rate and 9.4% higher TPS vs. <code>Unsloth Q3_K_XL [8]</code> (3.62 BPW, 196.42 TPS, 
              97.87% accuracy).
            </li>
            <li>
              a 2.54√ó lower error rate at the same TPS vs. <code>Unsloth IQ2_M [2]</code> (2.84 BPW, 214.79 TPS, 
              96.59% accuracy).
            </li>
          </ul>

          <p>
            As we move to higher throughput, ByteShape's maintains accuracy, while Unsloth's error rate experiences a cliff.
          </p>

          <h3>The Elephant in the Room: When 3-bits is not just 3-bits</h3>
          <p>
            There is an inconvenient truth hiding in these results. On several setups, around 4 bpw is already 
            flying, and pushing quantization harder does not make things faster. It just manages to be smaller 
            and slower at the same time.
          </p>

          <p>
            Reducing the size of data doesn't automatically speed things up. While using fewer bits to store each 
            number seems like it should reduce memory traffic and speed up computation, GPUs don't work that way. 
            NVIDIA GPUs process work in fixed groups of 32 threads called "warps," which move through instructions 
            together in near lock-step. The GPU hardware is optimized for specific data formats, memory access patterns, 
            and operations that the chip's circuits are physically designed to handle efficiently. When your workload 
            matches these "golden paths", you get peak performance. Step outside them, and you hit slowdowns. This isn't 
            a design flaw, it's a deliberate tradeoff. Supporting more flexibility would require additional circuitry: 
            more wires, more transistors, more complexity. That extra hardware consumes more power and adds latency to 
            every operation, whether a program needs that flexibility or not.
          </p>

          <p>
            Here a few examples of relevant hardware "quirks": VRAM is read in aligned 32-byte blocks, so reading one 
            or 32 bytes consumes the same memory bandwidth. Both on-chip and off-chip memories can also suffer contention 
            depending on how data is laid out, meaning that a warp's accesses may complete in a single step or, in the 
            worst case, be serialized into 32 steps. And of course, decoding quantized values before computation can 
            require extra instructions, with the cost depending on the quantization scheme.
          </p>

          <p>
            This explains the behaviour we observe: 4-bit kernels use VRAM bandwidth more efficiently than 3- or 2-bit 
            kernels and require fewer decode steps before computation. At the same time, 4-bit kernels exploit subword 
            parallelism just as effectively as lower-bit kernels, and all rely primarily on dynamic caches rather than 
            shared memory to take advantage of data reuse when possible.
          </p>

          <p>
            So why llama.cpp hasn't been optimized to deliver peak speed for <strong>every</strong> bit-length? Our understanding 
            is that llama.cpp prioritizes <strong>portable, space-efficient quantization</strong> that can run across a 
            wide range of hardware. That design goal limits how aggressively backends can reshape data layouts or reorder 
            computation in ways that might help one GPU or one bit-width.
          </p>

          <p>
            A key example is its choice to store quantized weights in fixed blocks of 256 values. Each block is 
            self-contained (it carries everything needed to decode it) and sits at a simple, predictable offset in the 
            tensor, which makes the format easy to implement and fast to locate.
          </p>

          <p>
            The tradeoff is that GPUs often need to <strong>decode many blocks in parallel</strong> to keep their wide 
            compute units busy. With many independent 256-value blocks, those parallel decodes can translate into more 
            scattered or fragmented VRAM reads and extra decode overhead, reducing bandwidth efficiency, especially for 
            some lower-bit formats.
          </p>

          <p>
            <strong>Point for example on RTX 5090:</strong> a matrix multiply [256, 768] √ó [768, 2048] takes 
            <strong>~54¬µs with </strong><code>iq4_xs</code><strong> </strong>datatype, but <strong>~62¬µs with </strong>
            <code>iq3_xxs</code><strong> </strong>(mul_mat_q()+mul_mat_q_stream_k_fixup()). In other words, 
            <strong>cutting nearly 1.2 bits per weight </strong>(a reduction of more than 25% in weight footprint) leads 
            to a <strong>~13% slowdown</strong>, directly hurting user experience.
          </p>

          <p>
            An excellent reminder that bitlength learning matters: Heuristics can get us part of the way, but not all 
            the way. ShapeLearn makes deliberate, per-tensor datatype choices that improve speed without sacrificing accuracy.
          </p>
        </section>

        <section>
          <h2>Methodology (brief recap)</h2>
          <p>
            If you're wondering how we are scoring these points, the full methodology is discussed in our previous 
            <a href="https://byteshape.com/blogs/Qwen3-4B-I-2507/">blog post</a>. This post is intentionally focused on the curves and 
            device tradeoffs, so here is the quick version.
          </p>

          <p>
            For each quantized variant, we measure <strong>throughput (TPS)</strong> on the target device and 
            compute a single <strong>normalized quality</strong> score relative to the <strong>BF16 baseline</strong>, 
            using the same evaluation harness and prompts as the methodology post. The quality score aggregates 
            standard benchmarks (MMLU, GSM8K, IFEval, LiveCodeBench V4) into one number so you can compare points 
            directly. In other words, every dot in the plots answers two questions: how fast does it run on this 
            device, and how much quality does it retain compared to BF16, with memory fit as the first constraint.
          </p>

          <p>
            We also want to thank all for the many, excellent suggestions on our recent Reddit post for improving 
            and extending this evaluation strategy, and we‚Äôre actively working through them. Right now, evaluation 
            is the main bottleneck and not bitlength learning/quantization.
            Careful evaluation is essential to clearly communicate the strengths of each model.
          </p>
        </section>

        <section>
          <h2>Wrapping up</h2>
          <p>
            <strong>First, thank you for your tenacity.</strong> You made it through all of this without giving up. 
            We are sincerely flattered!
          </p>

          <p>
            <strong>The takeaway is simple:</strong> treat <strong>memory as a constraint, not a goal</strong>. Once 
            a model fits on your device, what matters is the tradeoff curve, <strong>TPS versus quality</strong>. 
            Across CPUs and GPUs, <strong>ByteShape</strong> consistently lands on the better side of that curve, 
            delivering either <strong>more speed at the same quality</strong> or <strong>higher quality at the same 
            speed</strong>.
          </p>

          <p>
            If you're deploying on a <strong>Raspberry Pi 5 (16 GB)</strong> and want a genuinely
            interactive experience, start with
            <code>
              <a href="https://huggingface.co/byteshape/Qwen3-30B-A3B-Instruct-2507-GGUF/blob/main/Qwen3-30B-A3B-Instruct-2507-Q3_K_S-2.70bpw.gguf" target="_blank" rel="noopener noreferrer">
                Q3_K_S-2.70bpw [KQ-2]
              </a>
            </code>
            . On larger CPUs or GPUs, you can move up the curve toward higher-quality points with
            little loss in throughput, the same rule applies:
            <strong>fit first, then optimize the tradeoff</strong>.
          </p>
          

          <p>
            We'll keep releasing more device-targeted variants (and more plots). If your system can't run a 30B 
            model smoothly, don't blame the model or the silicon. <strong>Blame the datatypes.</strong>
          </p>
        </section>
      </div>
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Calling All Hackers: How money works (2024) (257 pts)]]></title>
            <link>https://phrack.org/issues/71/17</link>
            <guid>46518129</guid>
            <pubDate>Tue, 06 Jan 2026 20:24:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://phrack.org/issues/71/17">https://phrack.org/issues/71/17</a>, See on <a href="https://news.ycombinator.com/item?id=46518129">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<table>
   <tbody>
      <tr><td><a href="https://phrack.org/issues/71/1_md.html#article">Introduction</a></td><td>Phrack Staff</td></tr>

<tr><td><a href="https://phrack.org/issues/71/2_md.html#article">Phrack Prophile on BSDaemon</a></td><td>Phrack Staff</td></tr>

<tr><td><a href="https://phrack.org/issues/71/3_md.html#article">Linenoise</a></td><td>Phrack Staff</td></tr>

<tr><td><a href="https://phrack.org/issues/71/4_md.html#article">Loopback</a></td><td>Phrack Staff</td></tr>

<tr><td><a href="https://phrack.org/issues/71/5_md.html#article">Phrack World News</a></td><td>Phrack Staff</td></tr>

<tr><td><a href="https://phrack.org/issues/71/6_md.html#article">MPEG-CENC</a></td><td>David "retr0id" Buchanan</td></tr>

<tr><td><a href="https://phrack.org/issues/71/7_md.html#article">Bypassing CET &amp; BTI With Functional Oriented Programming</a></td><td>LMS</td></tr>

<tr><td><a href="https://phrack.org/issues/71/8_md.html#article">World of SELECT-only PostgreSQL Injections</a></td><td>Maksym Vatsyk</td></tr>

<tr><td><a href="https://phrack.org/issues/71/9_md.html#article">A VX Adventure in Build Systems and Oldschool Techniques</a></td><td>Amethyst Basilisk</td></tr>

<tr><td><a href="https://phrack.org/issues/71/10_md.html#article">Allocating new exploits</a></td><td>r3tr074</td></tr>

<tr><td><a href="https://phrack.org/issues/71/11_md.html#article">Reversing Dart AOT snapshots</a></td><td>cryptax</td></tr>

<tr><td><a href="https://phrack.org/issues/71/12_md.html#article">Finding hidden kernel modules (extrem way reborn)</a></td><td>g1inko</td></tr>

<tr><td><a href="https://phrack.org/issues/71/13_md.html#article">A novel page-UAF exploit strategy</a></td><td>Jinmeng Zhou, Jiayi Hu, Wenbo Shen, Zhiyun Qian</td></tr>

<tr><td><a href="https://phrack.org/issues/71/14_md.html#article">Stealth Shell</a></td><td>Ryan Petrich</td></tr>

<tr><td><a href="https://phrack.org/issues/71/15_md.html#article">Evasion by De-optimization</a></td><td>Ege BALCI</td></tr>

<tr><td><a href="https://phrack.org/issues/71/16_md.html#article">Long Live Format Strings</a></td><td>Mark Remarkable</td></tr>

<tr><td><a href="https://phrack.org/issues/71/17_md.html#article">Calling All Hackers</a></td><td>cts</td></tr>

   </tbody>
</table>

<p><strong>Title</strong> : Calling All Hackers</p>
<p><strong>Author</strong> : cts</p>
<pre>                             ==Phrack Inc.==

                Volume 0x10, Issue 0x47, Phile #0x11 of 0x11

|=-----------------------------------------------------------------------=|
|=-----------------------=[ Calling All Hackers ]=-----------------------=|
|=-----------------------------------------------------------------------=|
|=--------------------------=[ cts (@gf_256) ]=--------------------------=|
|=-----------------------------------------------------------------------=|

--[ Table of Contents

0 - Preamble
1 - About the Author
2 - The Birth of a Shitcoin
3 - How Money Works
    3.1 - Fixed Income
    3.2 - Equities
    3.3 - Shareholder Value
4 - Startup Blues
5 - Takeaways
6 - Thanks
7 - References
8 - Appendix

--[ 0 - Preamble

Hi. 

I'm cts, also known as gf_256, ephemeral, or a number of other handles.
I am a hacker and now a small business owner and CEO. In this article, 
I would like to share my experience walking these two different paths.

A hacker is someone who understands how the world works. It's about 
knowing what happens when you type "google.com" and press Enter. It's 
about knowing how your computer turns on, about memory training, A20, 
all of that. It's about modern processors, their caches, and their side 
channels. It's about DSi bootloaders and how the right electromagnetic 
faults can be used to jailbreak them. And it's about how Spotify and 
Widevine and AES and SGX work so you can free your music from the 
shackles of DRM.

But being a hacker is so much more than these things. It's about knowing 
where to find things. Like libgen and Sci-Hub and nyaa. Or where to get 
into the latest IDA Pro group buy. Or which trackers have what and how 
to get into them.

It's about knowing how to bypass email verification. How to bypass SMS 
verification. How to bypass that stupid fucking verification where you 
hold your driver's license up to a webcam (thank you, OBS virtual camera!) 
Having an actual threat model not just paranoia. Knowing that you're not 
worth burning a 0day on, but reading indictments to learn from others' 
mistakes.

It's about knowing where to buy estradiol valerate on the internet and how 
to compound injections. Or the "bodybuilder method" to order your own 
blood tests when your state requires a script to do so. It's about knowing 
which shipments give the US CBP a bad vibe and which don't.

It's about knowing what happens when you open Robinhood and giga long NVDA 
FDs. I mean the actual market microstructure, not "Ken Griffin PFOF bad". 
Then using that microstructure to find an infinite money glitch (high 
Sharpe!). It's about knowing how to get extra passports and reading the
tax code. 

It's about knowing how to negotiate your salary (or equity). It's about 
knowing why things at the supermarket cost what they do. Or how that awful 
shitcoin keeps pumping. And why that dogshit startup got assigned that 
insane valuation. And understanding who really pays for it in the end 
(hint: it's you).

My point is, it is not just about computers. It's about understanding how 
the world works. The world is made up of people. As much as machines keep 
society running, those machines are programmed by people--people with 
managers, spouses, and children; with wants, needs, and dreams. And it is 
about using that knowledge to bring about the change you want to see.

That is what being a hacker is all about.


--[ 1 - About the Author

I have been a hacker for 13 years. Prior to founding Zellic, I helped
start a CTF team called perfect blue (lately Blue Water). We later became
the number one ranked CTF team in the world. We've played in DEF CON CTF.
We've won GoogleCTF, PlaidCTF, and HITCON. It's like that scene from
Mr. Robot but not cringe.

In 2021, we decided to take that hacker friend circle and form a security 
firm. It turned out that crypto paid well, so we worked with a lot of 
crypto clients. In the process, we encountered insane, hilarious, and 
depressingly sobering bullshit. In this article, I will tell some stories 
about what that bullshit taught me, so you can benefit from the same 
lessons as I have.

Markets are computers; they compute prices, valuations, and the allocation 
of resources in our society. Hackers are good at computers. Let's learn 
more about it.


--[ 2 - The Birth of a Shitcoin

I can't think of a better example than shitcoins. Let's look at the
crypto markets in action.

First, let's talk about tokens. What is their purpose? The purpose of a 
token is to go up. There is no other purpose. Token go up. This is 
important, remember this point.

Now the question is, how do we make the token go up? In crypto, there are 
two main kinds of token deals. Let's call them the Asian Arrangement and 
the Western Way.

The Asian Arrangement is a fairly straightforward pump and dump. It's a 
rectangle between the VC, the Market Maker, the Crypto Exchange, and the 
Token Project Founder.

1. The exchange's job is to list the token, bringing in investors. They 
   get paid in a mix of tokens and cold, hard cash. Their superpower is 
   owning the customer relationships with the retail users, and the 
   naming rights to sports arenas.

2. The market maker provides liquidity so the market looks really 
   healthy and well-traded so it is easy to buy the token. In good 
   deals, they are paid in in-the-money call options on the tokens, 
   so they are incentivized to help the token trade well. Their 
   superpower is having a lot of liquidity to deploy, and people 
   on PagerDuty.

3. The founder's job is to pump the token and shill it on Twitter. 
   They are the hype man, and it's their job to drum up the narrative 
   and pump everyone's bags. Their unique power is they can print more 
   tokens out of thin air, and this is in large part how they get paid 
   in this arrangement.

4. Lastly, the VC gets paid to organize the deal. They give the founders 
   some money, who in return give a pinky promise that they will give 
   the VC a lot of tokens once the tokens actually exist. This is known 
   as a Simple Agreement for Future Tokens, or SAFT. Their superpower is 
   dressing up the founders and project so it seems like the Next Big 
   Thing instead of a Ponzi scheme.

Everyone gets paid a ton of token exposure (directly or indirectly), 
and when it lists, it pumps. Then the insiders dump and leave with a 
fat stack. Except retail, they end up with the bag. 

Sometimes the listing doesn't go well for the organizers, in which case, 
better luck next time. But retail always loses.


  wtf???   LFG!!! to the moon   
       ,o  \oXo/\o/          
       /v   | |  |
      /\   / X\ / \

    crypto investors
        ^ |
        | |
        | v
    +----------+                provides liquidity          +--------+
    |  Crypto  |  &lt;---------------------------------------  | Market |
    | Exchange |  ----------------------------------------&gt; | Maker  |
    +----------+                   maker fees               +--------+
        ^ |                                                    ^     
  fees, | | listing                                    options |     
 tokens | |                                            / fees  |      
        | |  +-------------------------------------------------+
        | v  |                                                        
    +---------+       tokens / SAFT / token warrants       +---------+
    |  Token  |  ---------------------------------------&gt;  | Venture |
    | Project |  &lt;---------------------------------------  | Capital |
    +---------+     cash , intros to CEX / MM, shilling    +---------+


This machine worked exceptionally well in 2017, especially before China 
banned crypto. All those ICO shitcoins? Asian Arrangement. And it still 
works well to this day, except people are more wary of lockups and vesting 
schedules and so on.

Now let's discuss the Western Way. The Asian Arrangement? That old pump 
and dump? No sir, we are civilized people. Instead, our VCs *add value* 
to their investments by telling the world "how disruptive the tech is" 
and how the "team are incredible outliers". And they will not blatantly 
PnD the token, but instead they will fund "projects in the ecosystem" so 
it appears there is real activity happening on the platform. 

This is to hype up metrics (like TPS or TVL) to inflate the next round 
valuation. Anyways, then they dump. Or maybe the VC is also a market 
maker so they market make their portfolio company tokens. Overall it's 
the same shit (Ponzi) but dressed up in a nicer outfit.

Asian Arrangement or Western Way--either way, if you're the token founder, 
your main priority is to just GO TO MARKET NOW and LAUNCH THE TOKEN. This 
is so you can collect your sweet bag and dump some secondary before 
someone else steals the narrative or the hype cycle moves on.

This is one of the reasons there are so many hacks in crypto. The code is 
all shitty because it's rushed out as fast as possible by 20-something-
year-old software engineers formerly writing Typescript and Golang at
Google. Pair that with some psycho CEO product manager. Remember, it is
not about WRITING SECURE CODE, it is about SHIPPING THE FUCKING PRODUCT.
Good luck rewriting it in Rust!

All of this worked well until Luna, then 3AC, Genesis, and FTX imploded in 
2022. It still works, but you have to be less blatant now.

Shitcoins do serve an essential need. They are an answer to financial 
nihilism. Many people are working dead-end wage slave jobs that are not 
enough to "make it". They feel trapped and forced to work at jobs they 
fucking hate and waste their life doing pointless shit to generate 
shareholder value. This kind of life feels unacceptable, yet there are 
few avenues out. So what is the only "attainable" solution left? Gamble 
it on shitcoins, and if you lose...maybe next paycheck will be better.

But enough about crypto, let's talk about securities.


--[ 3 - How Money Works

----[ 3.1 - Fixed Income

First, let's start with fixed income. I'm talking boring, old-fashioned
bonds, like Treasury bonds. A lot of people are introduced nowadays to 
finance through equities (stocks) and tokens. In my opinion, this is 
only half of the story. Fixed income is the bedrock of finance. It has 
fundamental value. It provides a prototypical asset that all assets can 
be benchmarked based on.

Fixed income assets, like bonds, boil down to borrowing and lending. A 
bond is basically an IOU for someone to pay you in the future. It is more 
useful to have a dollar today than in a year, so lenders charge a fee for 
access to money today. This fee is known as interest, and how it is baked 
into the equation varies from asset-to-asset. Some bonds come with 
interest payments, whereas other bonds are zero-coupon. The most important 
thing is to remember that bonds are essentially an IOU to pay $X in the 
future.

Here is an example. Let's say you would like to borrow $100 to finance an 
upcoming project. The interest rate will be 5% per year. To borrow money, 
you would issue (mint) a bond (an IOU) for $X+5 dollars to be repaid 1 
year in the future. In exchange for this fresh IOU, the lender will give 
you $X dollars now. 

On the lender's balance sheet, they will be less $X dollars worth of cash, 
but will also have gained ($X+5) dollars worth of an asset (your IOU), 
creating $5 of equity. In contrast, you would have $X more cash in assets, 
but also an ($X+5) liability, creating -$5 of equity. 

This example also works for depositing money at a bank. Here, you are the 
lender, and the bank is the borrower. Your deposits would be liabilities 
on their balance sheet, as they are liable to pay you back the deposit if 
you choose to withdraw it.

     Lender's Balance Sheet               Borrower's Balance Sheet   
   ===========================          ===========================  
    Assets:                              Assets:
      IOU-----------------X+5              Cash------------------X
                                         
    Liabilities:                         Liabilities:
      Cash----------------(X)              IOU-----------------X+5
                                         
    Equity:                              Equity:
      Equity----------------5              Equity--------------(5)

Fixed income assets are extremely simple. There are various risks (credit 
risk, interest rate risk, etc.), but excluding these factors, you 
essentially get what you pay for. Unlike a token or stock, the bond is not 
going to suddenly evaporate or crash. (In theory.) Because of this, they
can be modeled in a straightforward way; a way so straightforward even
a high school student can understand it.

Let's say I have $X today. Suppose the prevailing (risk-free) interest 
rate is 5%. What is the value of this $X in a year? Obviously, it would be 
no less than $X*1.05, as I can just lend it out for 5% interest and get 
$X*1.05 back in a year. If you gave me the opportunity to invest in any 
asset yielding less than 5%, this would be a bad deal for me, since I 
could just lend it out myself to get 5% yield.

Now, let's analyze the same scenario, but in reverse. Let's take that IOU 
from earlier. What is the value *today* of a (risk-free) $X IOU, due in 1 
year? It would be worth no more than $X/1.05. This is because with $X/1.05 
dollars today, I could lend it out and collect 5% interest to end up with 
$X again in the future. If I pay more than $X/1.05, I am getting a bad 
deal, since I am locking up my money with you when it would be more 
capital efficient to just lend it out myself.

You can probably see where I am going with this. The present value of an 
$X IOU at some time *t* in the future is $X/(1+r)^t, where *r* is the 
discount rate. The discount rate describes the "decay" of the value over 
time, due to interest but also factors like potential failure of the asset 
(for example, if the asset is a company, business failure of the company). 

Now, if we have some asset which pays a series of future cash flows 
*f(t)*, we can model this asset as a bundle of IOUs with values f(t) due 
in time 1, 2, 3, and so on. Then the present value of this asset is the 
geometric series sum of the discounted future cash flows. This is called 
discounted cash flows (DCF). Congrats, now you can do better modeling than 
what goes into many early-stage venture deals.

   +------+-----+-----+---------+---------+---------+-------+---------+
   | Year |  0  |  1  |    2    |    3    |    4    |  ...  |    t    |
   +------+-----+-----+---------+---------+---------+-------+---------+
   | Cash | CF1 | CF2 |   CF3   |   CF4   |   CF5   |  ...  |  CF_t   |
   | Flow |     |     |         |         |         |       |         |
   +------+-----+-----+---------+---------+---------+-------+---------+
   | Disc.| CF1 |_CF2_| __CF3__ | __CF4__ | __CF5__ |  ...  | _CF_t__ |
   | Val  |     | 1+r | (1+r)^2 | (1+r)^3 | (1+r)^4 |       | (1+r)^t |
   +------+-----------+---------+---------+---------+-------+---------+
           IOU 1 IOU 2   IOU 3     IOU 4     IOU 5     ...     IOU n

         inf
          _   f(t)                                               1
   DCF = \  ------- = (assume constant annual cash flow x) = --------- x
         /_ (1+r)^t                                          1-1/(1+r)
         t=0
   
       = (1/r + 1) x
   
   Cash flow multiple = (value) / (annual cash flow) ~= 1/r

(The astute reader might also find that they can go backwards from 
valuations to estimate first, second, ... Nth derivatives of the cash 
flow or the year-to-year survival chances of a company. And these can be 
compared with...going outside and touching grass to see if the valuation 
actually makes sense.)

At this point, you're probably wondering why I'm boring you with all of 
this dry quant finance 101 shit. Well, it's a useful thing to know about 
how the world works.

First, interest rates affect you directly and personally. You may have 
heard of the term "zero interest rate environment". In a low interest rate 
environment, cash flow becomes irrelevant. Why? Consider the DCF geometric 
series sum if the interest rate r = 0. The present value approaches 
infinity. If the benchmark hurdle rate we're trying to beat is 0%, 
literally ANYTHING is a better investment than holding onto cash. 

Now do you see why VCs were slamming hundreds of millions into blatantly 
bad deals and shit companies during Covid? Cash flow and profitability 
didn't matter, because you could simply borrow more money from the money 
printer.

Here's a more concrete example. Do you remember a few years ago when Uber 
rides were so cheap, that they were clearly losing money on each ride? 

This is known as Customer Acquisition Cost, or CAC. CAC is basically the 
company paying you to use their app, go to their store, subscribe to the 
thing, ... whatever. The strategy is well-known: burn money to acquire 
users until everyone else dies and you become a monopoly. Then raise the 
prices. 

But here is the key point: this only works in a low-interest rate 
environment. In such an environment, discounting is low, and thus, future 
growth potential is valued over profitability and fundamentals at present. 
It doesn't need to make sense *today* as long as it works 10 years from 
now. For now, we can keep borrowing more money to sustain the burn.

Of course, when rates go back up, the free money machine turns off and 
the effects ripple outward. You are the humble CAC farmer, farming CAC 
from various unprofitable consumer apps like ride share, food delivery, 
whatever. These apps raise their money from their investors, VC and 
growth equity funds. These funds in turn raise their money from *their* 
investors, their limited partners. These LPs might be institutional 
capital like pension funds, sovereign wealth funds, or family offices. 

At the end of the day, all of that wealth is generated somewhere 
throughout the economy by ordinary people. So when some VC-backed 
founders throw an extravagant party on a boat with fundraised dollars, 
in some sense, you are the one paying for it.

And when the money machine turns off, anyone who had gotten complacent 
under ZIRP is now left scrambling. Companies will overhire during ZIRP 
only to do layoffs when rates go up.


                         +=========================+                       
                         |   THE LIQUIDITY CYCLE   |                       
                         +=========================+                       
                                                                           
                                                                           
                                             VENTURE CAPITAL               
                   _______________      ,.-^=^=^=^=^=^=^=^=^=^;,           
                 ,;===============&gt;&gt;   E^ a16z   LSVP    Tiger '^3.        
               .;^                    E^       FF    Social Cap. '^3       
              //  condensation       .E    Bain   SoftBank  Accel 3^       
             /|^                     ^E  KP          Benchmark    :^       
             ||                       ^;:   YC    Greylock   GC  ;3'       
     ,.^-^-^-^-^-^-^-^-^-^-^;,          ^.=.=_=_=_=_=_=_=_=_=_=_=^         
    E^ endowments    family '^:.            \\\\\\\\\\\\\\\\\\\\           
   E^                offices  '^3            \\\\\\\\\\\\\\\\\\\\          
  E'  pension                  ^3. SOURCE     \\\ precipitation \\         
  ^;   funds       sovereign   3.' CAPITAL     \\\\\\\\\\\\\\\\\\\\        
   E;:           wealth funds ,3^  (LPs)        \\\\\\\\\\\\\\\\\\\\       
    ^;._.._._._._._._._._._._,^                  \\\\\\\\\\\\\\\\\\\\      
                                                               /\          
      ^ ^ ^ ^ ^ ^ ^ ^                      gamefi   /\  /\  uber eats      
      | | | | | | | |                     shitcoins/::\/::\  /::::\   /\   
      | evaporation |                             / doordash/^^^^^^\ /^^\  
      | | | | | | | |         ____________       /      \  /     hello   \ 
                             (poggers desu)     /_____ lime ____ fresh ___\
    \o/ \oXo/\oXoXo/  o       '=========='       UNPROFITABLE CONSUMER APPS
     |   | |  | | |  /|\         Oo._ /\_/\                 ,///           
  __/_\_/_X_\/_X_X_\_/_\__ /_________(@'w'@)_____________.,://'            
          SOCIETY          \''''''''  -...-''''''''''''''''' surface       
                                    THE HUMBLE               runoff        
                                    CAC FARMER                             

Second, credit is not inherently a bad thing if used responsibly. Take for 
example those Buy Now, Pay Later loans. Now that you are equipped with the 
concept of capital efficiency, wouldn't it technically better than paying 
cash to take an interest-free BNPL loan and temporarily stick the freed 
cash into an investment? (Barring other side effects, etc.)

Third, the concept of net present value--i.e., credit--is the killer app 
of finance. It allows you to transport value from the future into today. 
Of course, that debt must be repaid in the future, unless you can figure 
out a way to kick the can down the road forever.

For now, let's get back to stocks.

----[ 3.2 - Equities

Now we have seen both sides of the coin. Asset value is twofold: 
speculative and fundamental.

First, we saw speculative value as illustrated by crypto meme coins. Then, 
on the other hand, we examined fundamental value as illustrated by, e.g. a 
US Treasury. These two lie on two extremes of a spectrum. Some sectors and 
stocks are more speculative than others; Nvidia is practically a meme coin 
at this point, whereas something like Coca-Cola is like fixed income for 
boomers (NFA BTW). Most assets have a blend of both.

Thinking about stocks, they (usually) have some fundamental value. 
Equities represent ownership of some asset, like a business. The business 
in theory generates dividends for shareholders, and this cash flow (or the 
net present value of future ones) represents the fundamental value of the 
business. As we've seen, assets with better cash flows are more valuable.

In practice, buybacks can be used to create what is effectively a 
shareholder dividend in a more tax-advantaged way. Whereas with dividends, 
they are taxed as income, and this is realized immediately. With buybacks, 
they are taxed as capital gains, but crucially the gains are not realized 
until the asset is sold. This could be indefinitely far in the future, so 
it's more capital efficient. It has the added benefit that it helps pump 
the token, and imo this is kind of cute because it marries both the 
fundamental and speculative aspects.

Meanwhile, like tokens, stocks are also supposed to go up. Here's an 
example: imagine a generic meme coin. Apart from Go Up, what does it do? 
Nothing. Even if it's a Governance Token, who cares when the founders and 
VCs hold all the voting power? Anyways, I'm describing Airbnb Class A
Common Stock. Here's an excerpt from their S-1 [1] [2]:

&gt; We have four series of common stock, Class A, Class B, Class C, and 
&gt; Class H common stock (collectively, our "common stock"). The rights of 
&gt; holders of Class A, Class B, Class C, and Class H common stock are 
&gt; identical, except voting and conversion rights ... Each share of Class A 
&gt; common stock is entitled to one vote, each share of Class B common stock 
&gt; is entitled to 20 votes and is convertible at any time into one share of 
&gt; Class A common stock ... Holders of our outstanding shares of Class B
&gt; common stock will beneficially own 81.7% of our outstanding capital 
&gt; stock and represent 99.0% of the voting power of our outstanding capital 
&gt; stock immediately following this offering, ...


                   Name of             |  Class B   |   %   | % of Vot-
              Beneficial Owner         |   Shares   |       | ing Power
  -------------------------------------+------------+-------+-----------
    Brian Chesky                       | 76,407,686 | 29.1% |  27.1%
    Nathan Blecharczyk                 | 64,646,713 | 25.3% |  23.5%
    Joseph Gebbia                      | 58,023,452 | 22.9% |  21.4%
    Entities Affil. w/ Sequoia Capital | 51,505,045 | 20.3% |  18.9%     


Why do people buy tech stocks with inflated valuations? Some may because 
they believe that they will go up, that they will be more dominant, 
important, and valuable in the future. Like tokens, a large part of 
stocks' value is speculative. They are expressing their opinion on the 
future fundamentals. Others may simply because they believe others will 
believe that it is more valuable. Not fundamentals, this is an opinion 
about *pumpamentals*.

Importantly, unlike fundamental value, speculative value can be created 
out of thin air. It is minted by *fiat*. Fundamental value is difficult 
to create, whereas speculative value can be created through hype and 
psychology alone.

----[ 3.3 - Shareholder Value

For stocks, there are usually laws in place to protect investors, pushing 
the balance between "speculation" and "fundamentals" towards the latter. 
As a result, firms are generally legally obligated to act in their 
shareholders' best interests. This is good because normal people will be 
able to participate in the wealth generated by companies. And obviously, 
companies should not defraud their investors.

However, the biggest *stake* holders in a business, are usually (in order):

1. The employees.  No matter what, no one else is spending 8 hours a day, 
   or ~33% of their total waking lifespan at this place. Whatever it is, 
   I guarantee you the employees feel it the most.

2. The customers.  The customers are the reason the business is able to 
   exist in the first place. Non-profits are not exempt: their customers 
   are their donors.

3. The local community / local environment / ecosystem.  The business
   doesn't exist in a vacuum. The business has externalities, and those 
   externalities affect most the immediate surrounding environment.

4. And in last place, the shareholders.  They do not really do anything 
   except contribute capital and hold the stock. Of course capital is 
   important but they are not spending 8 hours a day here, they are not 
   the reason the business exists, and in fact they might even live in a 
   totally different country.

For large, publicly-listed companies, the shareholders have one more 
unique difference from the other three stakeholders: liquidity. This 
difference is critical.

Liquidity describes how easy it is to buy and sell an asset. A dollar 
bill is liquid. Bitcoin is liquid. A house is relatively illiquid. Stock 
in large, publicly-listed companies is also liquid. A shareholder can buy 
a stock one day and sell it the next. As a result, the relationship is 
non-commital and opens the opportunity for short-term thinking. 

There are many things a company could do which would benefit shareholders 
short term, while harming the other three stakeholders long term. While a 
shareholder can simply dump their position and leave, the mess created is 
left for the employees, customers, and community to clean up.

(The SPAC boom was a pretty good example of this. Not all SPACs are bad, 
but a lot of pretty shit businesses publicly listed through SPACs then 
crashed. This is sad to me because some of that is early investors and 
founders dumping on retail like a crypto shitcoin, but dressed up because
it's NYSE or NASDAQ. Get liquidity then bail.)

Now, it is a misconception that stock companies must solely paperclip-
maximize short-term shareholder value. However, this is how it often 
plays out due to fucked up shit in the public markets, like annoying 
activist hedge funds or executive compensation tied to stock price. And 
it is true that employees can be shareholders. And that is usually a good 
thing! But few public companies are truly employee-owned.

Thinking about it from this perspective, the concept of maximizing 
shareholder value seems somewhat backwards. But *why* would one make 
this system where the priorities are seemingly inverted?

One benefit is that it would make your currency extremely valuable. 
Suppose you want to do some shit on Ethereum (speculating on some animal 
token?), you will need to have native ETH to do that transaction. 
Similarly, if you want to invest in US securities you at some point need
US Dollars. If you want to get a piece of that sweet $NVDA action, you
need dollars. People want to buy American stocks. American companies
perform well: they're innovative; they're not too heavily regulated;
it's a business friendly environment. (Shareholder value comes first!)
The numbers go up.

Remember the token founder from earlier in the Asian Arrangement? Suppose 
you are a *country* in the situation above, with a valuable currency. Not 
only is your currency in demand and valuable, you are the issuing/minting 
authority for that token. Similar to the token founder, you can print 
valuable money and pay for things with it.

And speaking of being a founder, let's talk about that!


--[ 4 - Startup Blues

Based on what we've set up so far, I will discuss some of the problems I 
see with many startups today and with startup culture.

Much of the problems stem from misalignment between shareholders and the 
other stakeholders (employees, etc). A lot of this comes from the 
fundamentals of venture capital. VC is itself an asset class, like fixed 
income and equities. VCs pitch this to their limited partners, at some 
level, based on the premise that their VC fund will generate yield for 
them. The strategy is to identify stuff that will become huge and buy it 
while it's still small and really cheap. Like trading shitcoins, it's
about finding what's going to moon and getting in early.

In a typical VC fund, a small handful of the investments will comprise the 
entire returns of the fund, with all of the other investments being 0's. 
The distribution is very power law. This means we are not looking for 1x, 
2x, or 3x outcomes; these may even be seen as failure modes. We are only 
interested in 20x, 50x, 100x, etc. outcomes. This is because anything 
less will be insufficient to make up for all the bad investments that 
get written down to zero.

For the same reason, it only makes sense for VCs to invest in certain 
types of companies. Have you ever heard this one? "We invest in SOFTWARE 
companies!...How is this SCALABLE? What do the VENTURE SCALE OUTCOMES look 
like here?" This is because these kinds of companies are the ones with the 
potential to 100x. They want you to deliver a 100x. Or how about this one? 
"We invest in CATEGORY-DEFINING companies". At least in security, 
"category-defining" means a shiny new checkbox in the compliance / cyber 
insurance questionnaire. In other words, a new kind of product that people 
MUST purchase. 

The market is incentivized to deliver a product that meets the minimum bar 
to meet that checkbox, while being useless. I invite you to think of your 
favorite middleware or EDR vendors here. For passionate security founders 
considering raising venture, remember that this is what your "success" is 
being benchmarked against.
         
                      _.,------------------------------_ 
                   .%'                                 '&amp;.  
                  .;'    We  partner  with  founders     ^;
                  !      building  category-defining      ;!
                  ;   companies at the earliest stages   _;
                   ^;                                  _.^
                     ''-.______________    __________.-' 
                                      /   /
                                     /  /^
                                    / /^
                                   /;^
                                  /' 
                   _________                           _________           
                _-'         '.                      _-'         '.         
              ,^             '^_                  ,^             '^_       
             /'               '"'                /'               '"'      
            ^'                 ^\^              ^'                 ^\^     
            :                   ^|              :                   ^|     
            :       .       .   |)              :       .       .   |)     
            :           \       |)              :           \       |)     
             :         __\     ,;                :         __\     ,;      
              "   !            ;                  "   !            ;       
              "   ^\  _____  /'                   "   ^\  _____  /'        
              '| | ^\      _/^                    '| | ^\      _/^         
               |    ^'====='                       |    ^'====='           
               | .   |   |                         | .   |   |             
             _'          |^__                    _'          |^__          
 ---------_-'        U       '--_ -------------_-'        U       '--_ -----  
 ._   _.-'                       '-._     _.-'                       '-    
   ':.'  \            ;         /     ': .'  \            ;         /    [4]

It's due to the thirst for 100x that there are painful dynamics. A 
fledgling startup may have founders they really like, but the current 
business may be unscalable. Bad VCs will push founders towards strategies, 
bets, models that have a 1% chance of working, but pay out 200x if they 
do. 

In the process they destroy a good business--one which has earned the 
trust of dutiful employees and loyal customers--all for a lottery ticket 
to build a unicorn. They will throw 100 darts at the dartboard and maybe 5 
will land, but what is it like to be the dart? You may have good expected 
value, but all of that EV is from spikes super far away from the origin. 
Is it pleasant betting everything on this distribution?

VC's want founders to be cult leaders. Have you ever heard this line? "We 
invest in great storytellers." Like what we saw with stocks and tokens, 
much of the easily-unlockable potential upside in assets is speculative. 
In essence, value can be created through narrative. Narrative *IS* value. 
Bad VC's will push founders to raise more capital at ever higher 
valuations (higher val = markup = fees), using narrative as fuel for the 
fire. Storytelling means "pump the token", and the job of the CEO is to 
(1) be the hype man and to raise (2) cash and (3) eyeballs. For this 
reason, Sam Altman and Elon are fine CEOs, regardless of other factors, 
because they are great at all three.

Much to the detriment of founders' and their employees' psyche, investors 
expect founders to be this legendary hype man. This requires a religiosity 
of belief that is borderline delusional. Have you ever tried to convince 
one of those Silicon Valley YC-type founder/CEOs that they are wrong? They 
will never listen to you because they have been socialized to be this way. 
It is what is expected of them, and it is easy to fall into this trap 
without even becoming aware of it. But if you think about it, does it make 
sense that to be a business owner, you need to be a religious leader? Of 
course not.

All of these reasons are why so many startup founders are young. They have 
little to lose, so gambling it all is OK. Being a cult leader may be 
traumatizing, but they have time (and the neuroplasticity) to heal. And 
lastly, they do not have the life experience to have a mature personal 
identity beyond "I am a startup founder". All of this makes it easy to 
accept the external pressures to build a company this or that way. And 
perhaps not the way they would have wanted to, relying instead on their 
personal values. The true irony is that the latter is what creates true, 
enduring company culture and not the made-up Mad Libs-tier Company Culture 
Notion Page shit that so many startups have. And of course, good VCs are 
self-aware of all of the issues and strive to prevent them. But the 
overall problem remains.

One last externality is for communities based around an industry. When you 
add billions of venture dollars into an industry, it becomes cringe. 
It's saddening to me seeing the state of certain cybersecurity conferences 
which are now dominated by..."COME TO OUR BOOTH, YOU CAN BE A HACKER. 
PLEASE VIEW OUR AI GENERATED GRAPHICS OF FIGURES CLAD IN DARK HOODIES 
STATIONED BEHIND LAPTOPS". Here I would use the pensive emoji U+1F614 
to describe my feelings about the appropriation of hacker culture but 
Phrack is 7-bit ASCII, so please have this: :c u_u . _.

--[ 5 - Takeaways

The point is, all of this made me feel very small and powerless after I 
realized the sheer size of the problems I was staring at. Nowadays, to 
me it's about creating good jobs for my friends, helping our customers, 
and taking care of the community. Importantly, I realized that this is 
still making a bigger positive impact than what I could have done alone 
just as an individual hacker or engineer.

To me, businesses are economic machines that can create positive (or 
negative) impact in a consistent, self-sustaining way. There are many 
people who are talented, kind, and thoughtful but temporarily unlucky. 
Having a company let me help these friends monetize their abilities and be 
rewarded fairly for them. And in that way I helped make their life better. 
Despite a lot of the BS involved in running a business, this is one thing 
that is very meaningful to me.

You can understand computers and science and math as much as you want, but 
you will not be able to fix the bigger issues by yourself. The systems 
that run the world are much bigger than what we can break on our laptops 
and lab benches.

But like those familiar systems, if we want to change things for the 
better, we have to first understand those systems. Knowledge is power. 
Understanding is the first step towards change. If you do not like the 
system as it is, then it is your duty to help fix it.

Do not swallow blackpills. It's easy to get really cynical and think 
things are doomed (to AGI apocalypse, to environmental disaster, to 
techno/autocratic dystopia, whatever). I want to see a world where 
thoughtful hackers learn these systems and teach each other about them. 
That generation of hackers will wield that apparatus, NOT THE OTHER WAY 
AROUND.

Creating leverage for yourself.  Hackers should not think of themselves as 
"oh I am this little guy fighting Big Corporation" or whatever. This is 
low agency behavior. Instead become the corporation and RUN IT THE WAY YOU 
THINK IT SHOULD BE RUN. Keep it private and closely held, so no one can 
fuck it up. Closely train up successors, so in your absence it will 
continue to be run in a highly principled way that is aligned with your 
values and morals. Give employees ownership, as it makes everyone aligned 
with the machine's long-term success, not just you.

Raising capital.  Many things do really need capital, but raise in a 
responsible way that leaves you breathing room and the freedom to operate 
in ways that are aligned with your values. Never compromise your values or 
integrity. Stay laser focused on cash flows and sustainability, as these 
grant you the freedom to do the things right.

HACKERS SHOULDN'T BE AFRAID TO TOUCH THE CAPITAL MARKETS.  Many hackers 
assume "oh that fundraising stuff is for charismatic business types". I 
disagree. It's probably better for the world if good thoughtful hackers 
raise capital. Giving them leverage to change the world is better than 
giving that leverage to some psycho founder drinking the Kool-Aid. I 
deeply respect many of the authors in Phrack 71, and I would trust them to 
do a better job taking care of things than an amorphous amalgam of angry 
and greedy shareholders.

For all things that don't need capital, do not raise. Stay bootstrapped 
for as long as possible. REMEMBER THAT VALUATION IS A VANITY METRIC. Moxie 
Marlinspike wrote on his blog [3] that we are often guilty of always
trying to quantify success. But what is success? You can quantify net
worth, but can you quantify the good you have brought to others lives?

For personal goals, think long term. People tend to overestimate what they 
can do in 1 year, but underestimate what they can do in 10. DO NOT start a 
company thinking you can get your hands clean of it in 2-3 years. If you 
do a good job, you will be stuck with it for 5-10+ years. Therefore, DO 
NOT start a company until you are sure that is what you want to do with 
your life, or at least, your twenties/thirties (depending on when you 
start). A common lament among founders, even successful ones, is: 
"Sometimes I feel like I'm wasting my twenties". There's an easy Catch-22 
here: you may not know what you really want until you do the company; but 
once you do the company, you won't really be able to get out of it. Be 
wary of that.

Creating value.  This is one of those meaningless phrases that I dislike. 
Value is what you define it to be. Remember to work on things that have 
TAMs, but remember that working on art is valuable too! It is not all 
about the TAM monster--doing cool things that are NOT ECONOMICALLY 
VALUABLE, but ARTISTICALLY VALUABLE, is equally important. There is not 
much economic value in a beautiful polyglot file, but it is artistically 
delightful. This is part of why people hate AI art: it may be economically 
valuable, but it is often artistically bankrupt. (Some people do use 
generative tools in actually original and artistic ways, but this is the 
exception not the norm currently.)

Founders vs Investors.  Here is my advice: Ignore any pressure from 
investors to make company "scalable" or whatever. Make sure your investors 
have no ability to fire you or your co-founder(s). Make sure you and 
co-founder are always solid and trust each other more than investors. You 
and your cofounders need to be BLOOD BROTHERS (/sisters/w.e). If an 
investor is trying to play politics with one of you to go against the 
other cofounder, cut that investor out immediately and stop listening to 
them.

Any investor who pushes for scalability over what you think is the best 
interest of the company is not aligned with you. High-quality investors 
will not push for this because they are patient and in it for the long 
game. If you are patient, you can make a very successful company, even if
it is not that scalable. High-quality investors will bet on founders and
are committed; only bad ones will push for this kind of shit.

I'm going to avoid giving more generic startup advice here. Go read Paul 
Graham's essays. But remember that any investor's perspective will not be
the perspective of you and your employees. Pivoting 5 times in 24 months
is not a fun experience to work at: your employees will resign while your
investors celebrate your "coming of age journey"--unless everyone signed
up for that terrifying emotional rollercoaster from the start.

They say that "hacker" is a dying identity. Co-opted by annoying VC-backed 
cybersecurity companies that culturally appropriate the identity, the term 
is getting more polluted and diluted by the day. Meanwhile, computers are 
getting more secure, and they are rewriting everything in Rust with 
pointers-as-capability machines and memory tagging. Is it over?

I disagree. As long as the hacker *ethos* is alive, regardless of any 
particular scene, the identity will always exist. However, now is a 
crucible moment as a diaspora of hackers, young and old, venture out into 
the world. 

Calling all hackers: never forget who you are, who you will become, and 
the mark you leave.


--[ 6 - Thanks

Greetz (in no particular order):
 * ret2jazzy, Sirenfal, ajvpot, rose4096, Transfer Learning, samczsun, 
   tjr, claire (aka sport), and psifertex.
 * perfect blue, Blue Water, DiceGang, Shellphish, and all CTF players.
 * NotJan, nspace, xenocidewiki, and the members of pinkchan and Secret Club.
 * Everyone at Zellic, past and present.

Finally, a big thank you to the Phrack staff (shoutout to netspooky and 
richinseattle!) for making this all possible.


--[ 7 - References

[1] https://www.sec.gov/Archives/edgar/data/1559720/000119312520315318/
        d81668d424b4.htm
[2] https://www.sec.gov/Archives/edgar/data/1559720/000119312522115317/
        d278253ddef14a.htm
[3] https://moxie.org/stories/promise-defeat/

[4] https://twitter.com/nikitabier/status/1622477273294336000


--[ 8 - Appendix: Financial institution glossary for hackers

(Not serious! For jokes... :-)

- IB:  Investment Bank. Basically collect fat fees to do up ("advise on") 
       M&amp;As and other transactions. Help match buyers and sellers for your 
       private equity. They are like CYA for your deal.

- PE:  Private Equity. Basically buy not-overly-seriously ("poorly") run 
       companies, fire the management, then run it "professionally" (i.e. 
       make it generally shitty for customers and employees and community 
       for the benefit of shareholders)

- HF:  Hedge Fund. Trade out pricing inefficiencies

- MM:  Market Maker. Basically the same thing

- VC:  Basically gamble on tokens (crypto or stocks) and back cool and/or 
       wacky ideas that the rest of these people find too stinky to invest
       in

- PnD: Pump and Dump.

- TVL: Total Value Locked. Basically how much money is currently in a 
       blockchain or smart contract system.

- TPS: Transactions Per Second. A measure of how scalable or useful a 
       blockchain or database is. An oft-abused metric hacked by vaporware 
       shillers for hype and PnD purposes.

- TAM: Total Addressable ~~Memory~~ Market. Basically how much money a 
       given idea can make.

- NFA: Not finanical advice.

|=[ EOF ]=---------------------------------------------------------------=|
</pre>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Self hosting my media library with Jellyfin and Wireguard on Hetzner (126 pts)]]></title>
            <link>https://layandreas.github.io/personal-blog/posts/how-spotify-made-me-self-host/</link>
            <guid>46517636</guid>
            <pubDate>Tue, 06 Jan 2026 19:50:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://layandreas.github.io/personal-blog/posts/how-spotify-made-me-self-host/">https://layandreas.github.io/personal-blog/posts/how-spotify-made-me-self-host/</a>, See on <a href="https://news.ycombinator.com/item?id=46517636">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><blockquote><p><strong>Disclaimer:</strong> This post was written without the help of AI. Research for the self hosting setup (which docker images to use, Jellyfin vs. Plex) and the creation of initial configurations (docker-compose, wireguard) were supported by AI (among others like e.g. Reddit, Stackoverflow)</p></blockquote><h2 id="how-it-all-started">How It All Started</h2><p>If you don‚Äôt care about my motivations and are only interested in the technical setup just directly jump to <a href="#self-hosting-setup">Self Hosting Setup</a>!</p><h3 id="spotify-price-increase">Spotify Price Increase</h3><p>In August 2025 <a href="https://www.heise.de/en/news/Premium-is-getting-more-expensive-Spotify-raises-prices-in-Germany-10530712.html">Spotify announced a price increase in Germany</a>. I received a friendly message that while I was a valued Premium subscriber, my subscription price would <em>change</em> (some might say <em>increase</em>):</p><p><img loading="lazy" src="https://layandreas.github.io/personal-blog/spotify-price-increase.png" alt="Spotify Price Increase Mail"></p><p>For the time being I decided to sit it out. So November 2025 arrived and my Premium membership ended.</p><p>I decided to give Spotify‚Äôs <em>free plan</em> a try. How bad can it be? I had used the free tier 10 years ago and it was perfectly fine. How wrong I was!</p><p><img loading="lazy" src="https://layandreas.github.io/personal-blog/spotify-random-order.JPG" alt="Spotify Free Tier: Play Song in Random Order"></p><ul><li><p>The free tier forces shuffle after a certain amount of free choices. So while the tier might be free, your song choice is not. <a href="https://www.theverge.com/news/778176/spotify-free-user-upgrade-play-specific-songs">Although there are reports that Spotify supposedly got rid of this feature as of September 2025</a>, I still encountered this restriction as of end of December 2025</p></li><li><p>It‚Äôs not possible to scrub the song‚Äôs progress bar</p></li></ul><p>I don‚Äôt remember these restrictions being in place back in the day, but I may be wrong. It might be a case of <a href="https://en.wikipedia.org/wiki/Enshittification">enshittification of the free tier</a>?</p><p>Okay, fair enough: Companies need to make money, I‚Äôm not entitled to Spotify providing their services for free! For all those services I still pay for I certainly get an awesome user experience?</p><p>Not so fast‚Ä¶</p><h3 id="across-all-streaming-services-less-value-for-more-money">Across All Streaming Services: Less Value For More Money</h3><p>Across all streaming services I have noticed a decline in user friendliness, UX &amp; UI.</p><h4 id="price-increases">Price increases</h4><p>All streaming services have seen price increases and / or introduced ads. I get it, companies need to make money. My day job consists of helping companies increase their revenues, it pays my bills!</p><p><strong>The issue:</strong> These price increases are accompanied by a worse UX/UI. From a user perspective my interest lies in getting the best value for money!</p><h4 id="ads">Ads</h4><p>Amazon Prime introduced ads to an already paid service. This is a noticeable worse user experience. Netflix <a href="https://help.netflix.com/en/node/126831">introduced a paid plan with ads</a>. At least for me YouTube advertises mostly mobile games &amp; obvious scams (ever gotten one of these terrible <a href="https://www.reddit.com/r/selfimprovement/comments/1jhbatb/has_anyone_tried_liven_app_i_hear_its_a_scam_but/">liven app ads</a>?)</p><h4 id="ui">UI</h4><p>In May 2025 Netflix <a href="https://www.netflix.com/tudum/articles/netflix-new-tv-layout">introduced a new UI</a>. It‚Äôs a matter of taste and while some people may like it, I find it much worse.</p><h4 id="cracking-down-on-password-sharing">Cracking Down on Password Sharing</h4><p>Disney+ followed Netflix and <a href="https://www.businessinsider.com/streaming-password-sharing-crackdown-disney-netflix-max-2025-5">cracked down on password sharing</a>. This is a de facto price increase for many.</p><h2 id="self-hosting-setup">Self Hosting Setup</h2><p>So I decided to give self hosting a try. I‚Äôve followed the <a href="https://www.reddit.com/r/selfhosted/">awesome selfhosted subreddit</a> for a while anyway and own a collection of shows, movies &amp; music anyway.</p><h3 id="deployment-hetzner-vps">Deployment: Hetzner VPS</h3><p>Instead of going with my own hardware I decided to go with a <a href="https://www.hetzner.com/cloud">VPS from Hetzner</a>. I chose a <a href="https://www.hetzner.com/cloud">CAX21</a> with 4 VCPUs, 8GB RAM, 20 TB of traffic included and 80 GB of SSD storage.</p><h3 id="storage-hetzner-storage-box">Storage: Hetzner Storage Box</h3><p>While I could use the server‚Äôs SSD to store my media, I decided to use Hetzner‚Äôs <a href="https://www.hetzner.com/storage/storage-box/">Storage Box</a>. This way I can easily <a href="https://docs.hetzner.com/de/storage/storage-box/access/access-samba-cifs/">mount my media library on my Macbook via SMB</a>.</p><h3 id="media-server-jellyfin">Media Server: Jellyfin</h3><p>I opted to use the open source <a href="https://jellyfin.org/">Jellyfin</a> as my media server. <a href="https://www.plex.tv/">Plex</a> would be an alternative but it appears to have fallen out of favour and <a href="https://stadt-bremerhaven.de/plex-blockt-zugriff-auf-hetzner-server/">blocks Hetzner anyway</a>, so it would not work for me anyway.</p><h3 id="remote-access-vpn-tunnel-via-wireguard">Remote Access: VPN Tunnel via WireGuard</h3><p>To access my VPS remotely either from home or on the road I use <a href="https://www.wireguard.com/">WireGuard</a>:</p><ul><li><p><strong>Home network:</strong> My FRITZ!Box router lets me easily <a href="https://fritz.com/pages/vpn-mit-fritz-box">add a WireGuard configuration</a> to my home network. This way any device in my home network can access my media network without having to run a VPN. This is especially useful for accessing Jellyfin on my LG webOS TV as there‚Äôs no easy way to connect my TV to WireGuard directly</p></li><li><p><strong>On the road</strong>: Simply <a href="https://www.wireguard.com/install/">install WireGuard on your device</a>. You will need to create a client configuration for each of your devices</p></li></ul><h4 id="server-config">Server Config</h4><div><pre tabindex="0"><code data-lang="ini"><span><span><span>[Interface]</span>
</span></span><span><span><span>Address</span> <span>=</span> <span>10.13.13.1/24</span>
</span></span><span><span><span>ListenPort</span> <span>=</span> <span>51820</span>
</span></span><span><span><span>PrivateKey</span> <span>=</span> <span>{{ wireguard_server_private_key }}</span>
</span></span><span><span>
</span></span><span><span><span>PostUp</span>   <span>=</span> <span>iptables -A INPUT -i wg0 -p tcp --dport 8096 -j ACCEPT; iptables -A FORWARD -i wg0 -j ACCEPT</span>
</span></span><span><span><span>PostDown</span> <span>=</span> <span>iptables -D INPUT -i wg0 -p tcp --dport 8096 -j ACCEPT; iptables -D FORWARD -i wg0 -j ACCEPT</span>
</span></span><span><span>
</span></span><span><span><span>[Peer]</span>
</span></span><span><span><span>PublicKey</span> <span>=</span> <span>{{ wireguard_client_public_key }}</span>
</span></span><span><span><span>AllowedIPs</span> <span>=</span> <span>10.13.13.2/32</span>
</span></span><span><span>
</span></span><span><span><span>[Peer]</span>
</span></span><span><span><span>PublicKey</span> <span>=</span> <span>{{ wireguard_client_public_key_iphone }}</span>
</span></span><span><span><span>AllowedIPs</span> <span>=</span> <span>10.13.13.3/32</span>
</span></span><span><span>
</span></span><span><span><span>[Peer]</span>
</span></span><span><span><span>PublicKey</span> <span>=</span> <span>{{ wireguard_client_public_key_fritzbox }}</span>
</span></span><span><span><span>AllowedIPs</span> <span>=</span> <span>10.13.13.4/32</span>
</span></span></code></pre></div><p><strong>Peers</strong></p><p>In my WireGuardserver config I currently have three devices added as peers:</p><ul><li>My Macbook (<code>wireguard_client_public_key</code>)</li><li>My iPhone (<code>wireguard_client_public_key_iphone</code>)</li><li>My FRITZ!Box router (<code>wireguard_client_public_key_fritzbox</code>)</li></ul><p>Each device has its corresponding private key stored inside its WireGuard configuration / app. The <code>AllowedIPs</code> only allows the corresponding peer to use this internal IP address. <strong>On your device</strong> (router, notebook, mobile phone, ‚Ä¶) you‚Äôll need to assign this IP address as the <strong>interface section</strong>.</p><p>Let‚Äôs dive a bit deeper into the interface block.</p><p><strong>Interface</strong></p><p>Configuration for the network interface created on the server.</p><ul><li><code>Address = 10.13.13.1/24</code>: This is the address of the Hetzner server in our VPN</li><li><code>ListenPort = 51820</code>: UDP port number the WireGuard server listens on for incoming VPN connections</li><li><code>PrivateKey = {{ wireguard_server_private_key }}</code>: WireGuard uses this private key to identify itself to clients (via the public key which is shared)</li><li><code>PostUp / PostDown</code>: Port forwarding - we allow WireGuard to forward incoming traffic</li></ul><h4 id="client-config">Client Config</h4><p>Here‚Äôs an example how a client config on my Macbook looks like:</p><p><img loading="lazy" src="https://layandreas.github.io/personal-blog/wireguard_client_config.png" alt="WireGuard Client Config"></p><p>You‚Äôll have a separate configuration for each of your devices.</p><h3 id="docker-compose">Docker Compose</h3><p>And finally here‚Äôs the compose config for the actualy deployment on the VPS:</p><div><pre tabindex="0"><code data-lang="yaml"><span><span><span>version</span><span>:</span><span> </span><span>"3.9"</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>services</span><span>:</span><span>
</span></span></span><span><span><span>  </span><span>wireguard</span><span>:</span><span>
</span></span></span><span><span><span>    </span><span>image</span><span>:</span><span> </span><span>linuxserver/wireguard:latest</span><span>
</span></span></span><span><span><span>    </span><span>container_name</span><span>:</span><span> </span><span>wireguard</span><span>
</span></span></span><span><span><span>    </span><span>cap_add</span><span>:</span><span>
</span></span></span><span><span><span>      </span>- <span>NET_ADMIN</span><span>
</span></span></span><span><span><span>      </span>- <span>SYS_MODULE</span><span>
</span></span></span><span><span><span>    </span><span>environment</span><span>:</span><span>
</span></span></span><span><span><span>      </span>- <span>PUID=1000</span><span>
</span></span></span><span><span><span>      </span>- <span>PGID=1000</span><span>
</span></span></span><span><span><span>      </span>- <span>TZ=Etc/UTC</span><span>
</span></span></span><span><span><span>      </span>- <span>SERVERPORT=51820</span><span>
</span></span></span><span><span><span>      </span>- <span>SERVERURL=&lt;SERVERS-IP-ADDRESS&gt;</span><span>
</span></span></span><span><span><span>    </span><span>volumes</span><span>:</span><span>
</span></span></span><span><span><span>      </span>- <span>./wireguard/config:/config</span><span>
</span></span></span><span><span><span>      </span>- <span>/lib/modules:/lib/modules:ro</span><span>
</span></span></span><span><span><span>    </span><span>ports</span><span>:</span><span>
</span></span></span><span><span><span>      </span>- <span>"51820:51820/udp"</span><span>
</span></span></span><span><span><span>    </span><span>sysctls</span><span>:</span><span>
</span></span></span><span><span><span>      </span>- <span>net.ipv4.conf.all.src_valid_mark=1</span><span>
</span></span></span><span><span><span>    </span><span>restart</span><span>:</span><span> </span><span>unless-stopped</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>  </span><span>jellyfin</span><span>:</span><span>
</span></span></span><span><span><span>    </span><span>image</span><span>:</span><span> </span><span>jellyfin/jellyfin:latest</span><span>
</span></span></span><span><span><span>    </span><span>container_name</span><span>:</span><span> </span><span>jellyfin</span><span>
</span></span></span><span><span><span>    </span><span>network_mode</span><span>:</span><span> </span><span>"service:wireguard"</span><span>
</span></span></span><span><span><span>    </span><span>user</span><span>:</span><span> </span><span>1000</span><span>:</span><span>1000</span><span>
</span></span></span><span><span><span>    </span><span>volumes</span><span>:</span><span>
</span></span></span><span><span><span>      </span>- <span>./jellyfin/config:/config</span><span>
</span></span></span><span><span><span>      </span>- <span>/mnt/storagebox:/media:ro</span><span>
</span></span></span><span><span><span>    </span><span>environment</span><span>:</span><span>
</span></span></span><span><span><span>      </span>- <span>TZ=UTC</span><span>
</span></span></span><span><span><span>    </span><span>restart</span><span>:</span><span> </span><span>unless-stopped</span><span>
</span></span></span><span><span><span>    </span><span>depends_on</span><span>:</span><span>
</span></span></span><span><span><span>      </span>- <span>wireguard</span><span>
</span></span></span></code></pre></div><p>Some notes:</p><ul><li>Wireguard:<ul><li><code>51820:51820/udp</code>: We only expose WireGuard UDP port</li></ul></li><li>Jellyfin:<ul><li><code>/mnt/storagebox:/media:ro</code>: Mounting my Hetzner storage box with my media library into the container</li><li><code>network_mode: "service:wireguard"</code>: Shares the WireGuard container‚Äôs network stack</li></ul></li></ul><h2 id="so-is-self-hosting-a-alternative-to-streaming-services">So Is Self Hosting a Alternative to Streaming Services?</h2><p>It depends. My personal media library isn‚Äôt big enough that it could rival any of the streaming services libraries. You also need to put in the work to get your self-hosted setup running which non-technical people won‚Äôt do, and even for technical people it might not be worth it. For me personally it‚Äôs totally worth it!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stop Doom Scrolling, Start Doom Coding: Build via the terminal from your phone (441 pts)]]></title>
            <link>https://github.com/rberg27/doom-coding</link>
            <guid>46517458</guid>
            <pubDate>Tue, 06 Jan 2026 19:38:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/rberg27/doom-coding">https://github.com/rberg27/doom-coding</a>, See on <a href="https://news.ycombinator.com/item?id=46517458">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">doom-coding</h2><a id="user-content-doom-coding" aria-label="Permalink: doom-coding" href="#doom-coding"></a></p>
<p dir="auto">A DIY approach to coding on-the-go!</p>
<p dir="auto">As an aspiring builder, I sought out a way to keep coding while not at home. Thanks to some Claude-assisted research and troubleshooting, I can now code via the terminal on my phone anywhere at anytime via "Doom Coding" (think <em>Doom Scrolling</em> but more productive).</p>
<p dir="auto">After this 5-minute setup guide, you'll be able to "doom code" anywhere you have Internet connection.</p>
<div dir="auto"><p>Code in the air!</p><p>

<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/114448747/530833069-bda532b6-3963-4ace-907b-ebbf9460032c.jpeg?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njc3MzUzMDEsIm5iZiI6MTc2NzczNTAwMSwicGF0aCI6Ii8xMTQ0NDg3NDcvNTMwODMzMDY5LWJkYTUzMmI2LTM5NjMtNGFjZS05MDdiLWViYmY5NDYwMDMyYy5qcGVnP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI2MDEwNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNjAxMDZUMjEzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZjRiNGI1YWQ1YTA5YzI1OThiYjUxODNiOThjMzkxZDE0MDJkMzZkOGFmMzNmMGRlZGY5YjFiN2UwYmY0M2FiMyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.ujLY5LYkQeeQbSBUMDaV9ZBv7GEXjNaZnlyAoMW4lAc"><img width="400" height="316" alt="image" src="https://private-user-images.githubusercontent.com/114448747/530833069-bda532b6-3963-4ace-907b-ebbf9460032c.jpeg?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njc3MzUzMDEsIm5iZiI6MTc2NzczNTAwMSwicGF0aCI6Ii8xMTQ0NDg3NDcvNTMwODMzMDY5LWJkYTUzMmI2LTM5NjMtNGFjZS05MDdiLWViYmY5NDYwMDMyYy5qcGVnP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI2MDEwNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNjAxMDZUMjEzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZjRiNGI1YWQ1YTA5YzI1OThiYjUxODNiOThjMzkxZDE0MDJkMzZkOGFmMzNmMGRlZGY5YjFiN2UwYmY0M2FiMyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.ujLY5LYkQeeQbSBUMDaV9ZBv7GEXjNaZnlyAoMW4lAc"></a></p></div>
<p dir="auto">Code on a run! <br>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/114448747/530367038-f5449004-0a76-44ee-9922-a5cce1423f93.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njc3MzUzMDEsIm5iZiI6MTc2NzczNTAwMSwicGF0aCI6Ii8xMTQ0NDg3NDcvNTMwMzY3MDM4LWY1NDQ5MDA0LTBhNzYtNDRlZS05OTIyLWE1Y2NlMTQyM2Y5My5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTA2JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDEwNlQyMTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0zOTcyNmI1MjE5ZjU0NGZjNzUzZWJhNmVlY2MwYjQyZDk5NjhkOTcyMDA1ZTAxMGZlMTk0MzdiNjkxMjY1OTMzJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.3pUbAcfCRpYvNHfm1vzJ8vV8lq3D9jFkto_0xoZ8mpo"><img width="400" height="316" alt="image" src="https://private-user-images.githubusercontent.com/114448747/530367038-f5449004-0a76-44ee-9922-a5cce1423f93.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njc3MzUzMDEsIm5iZiI6MTc2NzczNTAwMSwicGF0aCI6Ii8xMTQ0NDg3NDcvNTMwMzY3MDM4LWY1NDQ5MDA0LTBhNzYtNDRlZS05OTIyLWE1Y2NlMTQyM2Y5My5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTA2JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDEwNlQyMTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0zOTcyNmI1MjE5ZjU0NGZjNzUzZWJhNmVlY2MwYjQyZDk5NjhkOTcyMDA1ZTAxMGZlMTk0MzdiNjkxMjY1OTMzJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.3pUbAcfCRpYvNHfm1vzJ8vV8lq3D9jFkto_0xoZ8mpo"></a> <br></p>
<p dir="auto">Even code at the club! <br>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/114448747/530365787-f3d05c00-a47a-4ebe-8db3-1795a6a0798c.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njc3MzUzMDEsIm5iZiI6MTc2NzczNTAwMSwicGF0aCI6Ii8xMTQ0NDg3NDcvNTMwMzY1Nzg3LWYzZDA1YzAwLWE0N2EtNGViZS04ZGIzLTE3OTVhNmEwNzk4Yy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTA2JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDEwNlQyMTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT05YzZiM2U3NGY0NWZhNjljMjM3ZjU5MmRlYzBkY2E1YzMzNjZhYmY4Yjg0NDBiYWIyZGYxODI4YmRhZGM4Y2JmJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.yIulGEalLDyNfv1PaeXivABI-J10iIik94UUcRn0QZM"><img width="400" height="299" alt="image" src="https://private-user-images.githubusercontent.com/114448747/530365787-f3d05c00-a47a-4ebe-8db3-1795a6a0798c.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njc3MzUzMDEsIm5iZiI6MTc2NzczNTAwMSwicGF0aCI6Ii8xMTQ0NDg3NDcvNTMwMzY1Nzg3LWYzZDA1YzAwLWE0N2EtNGViZS04ZGIzLTE3OTVhNmEwNzk4Yy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTA2JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDEwNlQyMTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT05YzZiM2U3NGY0NWZhNjljMjM3ZjU5MmRlYzBkY2E1YzMzNjZhYmY4Yjg0NDBiYWIyZGYxODI4YmRhZGM4Y2JmJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.yIulGEalLDyNfv1PaeXivABI-J10iIik94UUcRn0QZM"></a><br></p>
<p dir="auto">I've been amazed by how much I can get done while being so far away from home. In Taiwan, I could access my computer in Philadelphia and coded a prototype in my downtime.</p>
<p dir="auto"><em>Shameless plug: check out <a href="http://www.friendlyr.ai/" rel="nofollow">www.friendlyr.ai</a> to help shape the future of connection!</em></p>
<p dir="auto">Make sure to "Watch" this repo for future updates to this doom coding guide. As I tryout the latest mobile coding tools (e.g. Claude Code on the Web), I'll update this repository with comparisons.</p>
<p dir="auto">Happy doom coding my friends!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What You'll Need</h2><a id="user-content-what-youll-need" aria-label="Permalink: What You'll Need" href="#what-youll-need"></a></p>
<ol dir="auto">
<li>A Computer running 24/7 with Internet Connection</li>
<li>A Smartphone</li>
<li>A Claude Pro subscription</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Overview</h2><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<p dir="auto">Use Tailscale, Termius, Claude Code, and a computer running 24/7 to continue building anywhere you have Internet connection.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">1. Set Up Your Computer</h2><a id="user-content-1-set-up-your-computer" aria-label="Permalink: 1. Set Up Your Computer" href="#1-set-up-your-computer"></a></p>

<p dir="auto"><h2 tabindex="-1" dir="auto">2. Set Up Your Phone</h2><a id="user-content-2-set-up-your-phone" aria-label="Permalink: 2. Set Up Your Phone" href="#2-set-up-your-phone"></a></p>
<ul dir="auto">
<li>
<p dir="auto">Install Tailscale ‚Üí Sign in with the same account<br>  <a href="https://apps.apple.com/us/app/tailscale/id1470499037" rel="nofollow">https://apps.apple.com/us/app/tailscale/id1470499037</a></p>
</li>
<li>
<p dir="auto">Install Termius (A Mobile Terminal Tool) <br>
<a href="https://apps.apple.com/us/app/termius-modern-ssh-client/id549039908" rel="nofollow">https://apps.apple.com/us/app/termius-modern-ssh-client/id549039908</a></p>
</li>
<li>
<p dir="auto">Note the MagicDNS address of your computer (e.g. my-computer.tailnet-name.ts.net)<br>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/114448747/530370338-6da3907d-ca08-48c8-9f18-54c8d644b21e.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njc3MzUzMDEsIm5iZiI6MTc2NzczNTAwMSwicGF0aCI6Ii8xMTQ0NDg3NDcvNTMwMzcwMzM4LTZkYTM5MDdkLWNhMDgtNDhjOC05ZjE4LTU0YzhkNjQ0YjIxZS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTA2JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDEwNlQyMTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT04MTE5YWE4MjM5MWRiOWEwNWFjNTAzZjg2OWM3ZWJkMWFhZDA2Y2Q3ZGM5MTM3NjJjNDM4ZTM3MWQ5YzYzYWM2JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.FHTesDu6g2ITRU1VMdt8Pcj6GYywxkrULDhvFDojUFI"><img width="400" height="359" alt="image" src="https://private-user-images.githubusercontent.com/114448747/530370338-6da3907d-ca08-48c8-9f18-54c8d644b21e.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njc3MzUzMDEsIm5iZiI6MTc2NzczNTAwMSwicGF0aCI6Ii8xMTQ0NDg3NDcvNTMwMzcwMzM4LTZkYTM5MDdkLWNhMDgtNDhjOC05ZjE4LTU0YzhkNjQ0YjIxZS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTA2JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDEwNlQyMTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT04MTE5YWE4MjM5MWRiOWEwNWFjNTAzZjg2OWM3ZWJkMWFhZDA2Y2Q3ZGM5MTM3NjJjNDM4ZTM3MWQ5YzYzYWM2JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.FHTesDu6g2ITRU1VMdt8Pcj6GYywxkrULDhvFDojUFI"></a></p>
</li>
<li>
<p dir="auto">Create a new host in Termius:<br></p>
<ul dir="auto">
<li>Label: What you want your connection to be called</li>
<li>Hostname: The MagicDNS address (my-computer.tailnet-name.ts.net)</li>
<li>Port: 22</li>
<li>Username/Password: Your login for your computer <br>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/114448747/530395931-69e2d4f0-9dad-4362-8b39-304f3ef66e6d.jpeg?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njc3MzUzMDEsIm5iZiI6MTc2NzczNTAwMSwicGF0aCI6Ii8xMTQ0NDg3NDcvNTMwMzk1OTMxLTY5ZTJkNGYwLTlkYWQtNDM2Mi04YjM5LTMwNGYzZWY2NmU2ZC5qcGVnP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI2MDEwNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNjAxMDZUMjEzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YjVlMDNkYmNhM2NkNTg1ZTE3MWMyZWYxM2E3Y2YyZmNlNDM4YmFlMWUxMGI3N2FhYTBlYWFmNmQ4MGM2YzVlNSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.yhxwdQ3ju90vsXO-pF2IYWyQEE8cCV47NzhrScTESJI"><img width="400" height="520" alt="image" src="https://private-user-images.githubusercontent.com/114448747/530395931-69e2d4f0-9dad-4362-8b39-304f3ef66e6d.jpeg?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njc3MzUzMDEsIm5iZiI6MTc2NzczNTAwMSwicGF0aCI6Ii8xMTQ0NDg3NDcvNTMwMzk1OTMxLTY5ZTJkNGYwLTlkYWQtNDM2Mi04YjM5LTMwNGYzZWY2NmU2ZC5qcGVnP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI2MDEwNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNjAxMDZUMjEzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YjVlMDNkYmNhM2NkNTg1ZTE3MWMyZWYxM2E3Y2YyZmNlNDM4YmFlMWUxMGI3N2FhYTBlYWFmNmQ4MGM2YzVlNSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.yhxwdQ3ju90vsXO-pF2IYWyQEE8cCV47NzhrScTESJI"></a> <br></li>
</ul>
 <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/114448747/530395979-33105829-7dc2-4be2-934d-56793f01a03d.jpeg?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njc3MzUzMDEsIm5iZiI6MTc2NzczNTAwMSwicGF0aCI6Ii8xMTQ0NDg3NDcvNTMwMzk1OTc5LTMzMTA1ODI5LTdkYzItNGJlMi05MzRkLTU2NzkzZjAxYTAzZC5qcGVnP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI2MDEwNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNjAxMDZUMjEzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MTVlMjAwM2I4NjBkMjFkMWVjYTJjOGI0MWVjMzUwYzc3ODQzZjdlM2YxMmYwYjAxYzA0NDU3YzBhZDQwMTcxNyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.S-AJVvzbuD9ipZTdJCCFhOFFGqvgzbw_nGnpCYNjQDM"><img width="400" height="359" alt="image" src="https://private-user-images.githubusercontent.com/114448747/530395979-33105829-7dc2-4be2-934d-56793f01a03d.jpeg?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njc3MzUzMDEsIm5iZiI6MTc2NzczNTAwMSwicGF0aCI6Ii8xMTQ0NDg3NDcvNTMwMzk1OTc5LTMzMTA1ODI5LTdkYzItNGJlMi05MzRkLTU2NzkzZjAxYTAzZC5qcGVnP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI2MDEwNiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNjAxMDZUMjEzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MTVlMjAwM2I4NjBkMjFkMWVjYTJjOGI0MWVjMzUwYzc3ODQzZjdlM2YxMmYwYjAxYzA0NDU3YzBhZDQwMTcxNyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.S-AJVvzbuD9ipZTdJCCFhOFFGqvgzbw_nGnpCYNjQDM"></a>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">3. Connect and Code</h2><a id="user-content-3-connect-and-code" aria-label="Permalink: 3. Connect and Code" href="#3-connect-and-code"></a></p>

<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/114448747/530205087-d92df1cd-570b-49b0-96f7-a5ce31644a6f.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njc3MzUzMDEsIm5iZiI6MTc2NzczNTAwMSwicGF0aCI6Ii8xMTQ0NDg3NDcvNTMwMjA1MDg3LWQ5MmRmMWNkLTU3MGItNDliMC05NmY3LWE1Y2UzMTY0NGE2Zi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTA2JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDEwNlQyMTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1kZjNjOGM0N2M5Y2I4OTFmN2M4ZjZiMGEyMGRkN2Y2Y2ZiMTljZTYwN2FiMmI2YTIwMzNjNzUxMGY4MDUzMDkzJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.Py34JfSZx1uADH2nCpIeTxGlL9smd3KiviATjUJ9jRQ"><img width="400" height="400" alt="image" src="https://private-user-images.githubusercontent.com/114448747/530205087-d92df1cd-570b-49b0-96f7-a5ce31644a6f.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njc3MzUzMDEsIm5iZiI6MTc2NzczNTAwMSwicGF0aCI6Ii8xMTQ0NDg3NDcvNTMwMjA1MDg3LWQ5MmRmMWNkLTU3MGItNDliMC05NmY3LWE1Y2UzMTY0NGE2Zi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTA2JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDEwNlQyMTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1kZjNjOGM0N2M5Y2I4OTFmN2M4ZjZiMGEyMGRkN2Y2Y2ZiMTljZTYwN2FiMmI2YTIwMzNjNzUxMGY4MDUzMDkzJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.Py34JfSZx1uADH2nCpIeTxGlL9smd3KiviATjUJ9jRQ"></a>
<p dir="auto"><h2 tabindex="-1" dir="auto">Troubleshooting</h2><a id="user-content-troubleshooting" aria-label="Permalink: Troubleshooting" href="#troubleshooting"></a></p>
<ul dir="auto">
<li>If you're not able to establish a connection from your phone via Termius to your computer:</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">1. Reset your Tailscale VPN</h2><a id="user-content-1-reset-your-tailscale-vpn" aria-label="Permalink: 1. Reset your Tailscale VPN" href="#1-reset-your-tailscale-vpn"></a></p>
<ul dir="auto">
<li>Check your phone settings to make sure you are connected to the Tailscale VPN. <br>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/114448747/530353567-1b041eff-9001-4e41-8922-c7f3bcb368da.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njc3MzUzMDEsIm5iZiI6MTc2NzczNTAwMSwicGF0aCI6Ii8xMTQ0NDg3NDcvNTMwMzUzNTY3LTFiMDQxZWZmLTkwMDEtNGU0MS04OTIyLWM3ZjNiY2IzNjhkYS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTA2JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDEwNlQyMTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1mOTk5ODEzZjlmZmNlMjAyNGVjMjNkZDFiZGQ2ZmEyOWIxNDA3ZWE1OWI2NTg3N2EyYTI2MDA0ZWZkOGU1NmZjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.lRNG_HDpCDK9Ft7MPElt1RfwqT5Bt2WDFR5nqJUGZJI"><img width="400" height="227" alt="image" src="https://private-user-images.githubusercontent.com/114448747/530353567-1b041eff-9001-4e41-8922-c7f3bcb368da.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njc3MzUzMDEsIm5iZiI6MTc2NzczNTAwMSwicGF0aCI6Ii8xMTQ0NDg3NDcvNTMwMzUzNTY3LTFiMDQxZWZmLTkwMDEtNGU0MS04OTIyLWM3ZjNiY2IzNjhkYS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTA2JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDEwNlQyMTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1mOTk5ODEzZjlmZmNlMjAyNGVjMjNkZDFiZGQ2ZmEyOWIxNDA3ZWE1OWI2NTg3N2EyYTI2MDA0ZWZkOGU1NmZjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.lRNG_HDpCDK9Ft7MPElt1RfwqT5Bt2WDFR5nqJUGZJI"></a> <br></li>
<li>Check the Tailscale app to make sure the Tailscale VPN is on. If your phone and doom coding computer do not have a green circle next to their labels, there is an issue with your Tailscale/Internet connection.</li>
</ul>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/114448747/530364232-e5da61ab-828d-4f40-920d-840306c284ed.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njc3MzUzMDEsIm5iZiI6MTc2NzczNTAwMSwicGF0aCI6Ii8xMTQ0NDg3NDcvNTMwMzY0MjMyLWU1ZGE2MWFiLTgyOGQtNGY0MC05MjBkLTg0MDMwNmMyODRlZC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTA2JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDEwNlQyMTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1mMzVkODdlZDYwNDAwYTA1NTFhNzA0MGY5ZDk4OThmM2Q0MTRhZWY5ODkyNTk0NzQ2MmIyZDBlZGI2YTk0NGQ1JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.-5J0hNefJoFgNUDQR4bT9kIwcxkEY0z-e_mNH0POZ6s"><img width="400" height="517" alt="image" src="https://private-user-images.githubusercontent.com/114448747/530364232-e5da61ab-828d-4f40-920d-840306c284ed.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njc3MzUzMDEsIm5iZiI6MTc2NzczNTAwMSwicGF0aCI6Ii8xMTQ0NDg3NDcvNTMwMzY0MjMyLWU1ZGE2MWFiLTgyOGQtNGY0MC05MjBkLTg0MDMwNmMyODRlZC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTA2JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDEwNlQyMTMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1mMzVkODdlZDYwNDAwYTA1NTFhNzA0MGY5ZDk4OThmM2Q0MTRhZWY5ODkyNTk0NzQ2MmIyZDBlZGI2YTk0NGQ1JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.-5J0hNefJoFgNUDQR4bT9kIwcxkEY0z-e_mNH0POZ6s"></a>
<p dir="auto"><h2 tabindex="-1" dir="auto">2. Make sure your computer is ON and UNLOCKED</h2><a id="user-content-2-make-sure-your-computer-is-on-and-unlocked" aria-label="Permalink: 2. Make sure your computer is ON and UNLOCKED" href="#2-make-sure-your-computer-is-on-and-unlocked"></a></p>
<p dir="auto">When disconnecting/reconnecting power, make sure you unlock the computer. I've ran into this issue one too many times.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Best Practices</h2><a id="user-content-best-practices" aria-label="Permalink: Best Practices" href="#best-practices"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Track your progress:</h3><a id="user-content-track-your-progress" aria-label="Permalink: Track your progress:" href="#track-your-progress"></a></p>
<p dir="auto">End sessions by asking Claude to update CLAUDE.md with where you left off.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Preview websites:</h3><a id="user-content-preview-websites" aria-label="Permalink: Preview websites:" href="#preview-websites"></a></p>
<p dir="auto">Go to your desired directory and start an HTTP server<br>
<code>python -m http.server 3005</code>
then visit <a href="http://your-machine.tailnet-name.ts.net:3005/your-html-file.html" rel="nofollow">http://your-machine.tailnet-name.ts.net:3005/your-html-file.html</a> in a browser on your phone.<br></p>
<p dir="auto"><em>Wherever you would use localhost:PORT to view an app on your computer, replace localhost with the computer's MagicDNS from the Tailscale app (e.g. your-computer.tailnet-name.ts.net)</em></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">View databases:</h3><a id="user-content-view-databases" aria-label="Permalink: View databases:" href="#view-databases"></a></p>
<p dir="auto">Use the PostgreSQL app to view databases for your projects <a href="https://apps.apple.com/us/app/postgresql-client/id1233662353" rel="nofollow">https://apps.apple.com/us/app/postgresql-client/id1233662353</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bookmark useful sites:</h3><a id="user-content-bookmark-useful-sites" aria-label="Permalink: Bookmark useful sites:" href="#bookmark-useful-sites"></a></p>
<p dir="auto">On your computer, bookmark the sites you refer to during development (e.g. Google OAuth, GitHub) to make it easier to reference from your phone. I use the Chrome app to seamlessly access the sites I need.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Happy Doom Coding!</h2><a id="user-content-happy-doom-coding" aria-label="Permalink: Happy Doom Coding!" href="#happy-doom-coding"></a></p>
<p dir="auto">Please contibute your best practices! I am looking forward to seeing all the places you will code!</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[High-Performance DBMSs with io_uring: When and How to use it (141 pts)]]></title>
            <link>https://arxiv.org/abs/2512.04859</link>
            <guid>46517319</guid>
            <pubDate>Tue, 06 Jan 2026 19:29:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2512.04859">https://arxiv.org/abs/2512.04859</a>, See on <a href="https://news.ycombinator.com/item?id=46517319">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2512.04859">View PDF</a>
    <a href="https://arxiv.org/html/2512.04859v2">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>We study how modern database systems can leverage the Linux io_uring interface for efficient, low-overhead I/O. io_uring is an asynchronous system call batching interface that unifies storage and network operations, addressing limitations of existing Linux I/O interfaces. However, naively replacing traditional I/O interfaces with io_uring does not necessarily yield performance benefits. To demonstrate when io_uring delivers the greatest benefits and how to use it effectively in modern database systems, we evaluate it in two use cases: Integrating io_uring into a storage-bound buffer manager and using it for high-throughput data shuffling in network-bound analytical workloads. We further analyze how advanced io_uring features, such as registered buffers and passthrough I/O, affect end-to-end performance. Our study shows when low-level optimizations translate into tangible system-wide gains and how architectural choices influence these benefits. Building on these insights, we derive practical guidelines for designing I/O-intensive systems using io_uring and validate their effectiveness in a case study of PostgreSQL's recent io_uring integration, where applying our guidelines yields a performance improvement of 14%.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Matthias Jasny [<a href="https://arxiv.org/show-email/60b97220/2512.04859" rel="nofollow">view email</a>]      <br>            <strong><a href="https://arxiv.org/abs/2512.04859v1" rel="nofollow">[v1]</a></strong>
        Thu, 4 Dec 2025 14:43:03 UTC (504 KB)<br>
    <strong>[v2]</strong>
        Fri, 12 Dec 2025 09:44:22 UTC (505 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Video Game Websites in the early 00s (168 pts)]]></title>
            <link>https://www.webdesignmuseum.org/exhibitions/video-game-websites-in-the-early-00s</link>
            <guid>46516559</guid>
            <pubDate>Tue, 06 Jan 2026 18:39:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.webdesignmuseum.org/exhibitions/video-game-websites-in-the-early-00s">https://www.webdesignmuseum.org/exhibitions/video-game-websites-in-the-early-00s</a>, See on <a href="https://news.ycombinator.com/item?id=46516559">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

          <h2>SEND US A TIP ABOUT AN OLD WEBSITE, APP OR SOFTWARE</h2>
          <p>Do you know of an interesting old website, app or software that we should exhibit at the Museum? Send us their names or links at Archive.org.</p>
          <p><a href="https://www.webdesignmuseum.org/submit">Open form</a></p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Passing of Joe Mancuso author of Masonite (Python web framework) (176 pts)]]></title>
            <link>https://github.com/MasoniteFramework/masonite/discussions/853</link>
            <guid>46516137</guid>
            <pubDate>Tue, 06 Jan 2026 18:11:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/MasoniteFramework/masonite/discussions/853">https://github.com/MasoniteFramework/masonite/discussions/853</a>, See on <a href="https://news.ycombinator.com/item?id=46516137">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="presentation" data-paste-markdown-skip="">
    <tbody data-target-translation-id="9137628" data-target-translation-type="discussion">
        <tr>
    <td>
        <p dir="auto">Good morning Masonite community,</p>
<p dir="auto">I regret to inform you all that <a data-hovercard-type="user" data-hovercard-url="/users/josephmancuso/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/josephmancuso">@josephmancuso</a> has passed away due to health complications. Please keep his family in your thoughts during this time.</p>
<p dir="auto">I had the privilege of working alongside Joe for many years, and it was clear as day how much Masonite meant to him. Even when fighting for his life, he continued doing everything he could to maintain and support this project.</p>
<p dir="auto">One of the beautiful things about open source is that we build <strong>together</strong>. While Joe is no longer with us, Masonite can continue to grow and evolve through the contributions of this community. I hope we all continue working toward the vision he poured so much of himself into.</p>
    </td>
  </tr>

    </tbody>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Locating a Photo of a Vehicle in 30 Seconds with GeoSpy (123 pts)]]></title>
            <link>https://geospy.ai/blog/locating-a-photo-of-a-vehicle-in-30-seconds-with-geospy</link>
            <guid>46515948</guid>
            <pubDate>Tue, 06 Jan 2026 18:00:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://geospy.ai/blog/locating-a-photo-of-a-vehicle-in-30-seconds-with-geospy">https://geospy.ai/blog/locating-a-photo-of-a-vehicle-in-30-seconds-with-geospy</a>, See on <a href="https://news.ycombinator.com/item?id=46515948">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Dude, where's my supersonic jet? (118 pts)]]></title>
            <link>https://rationaloptimistsociety.substack.com/p/dude-wheres-my-supersonic-jet</link>
            <guid>46515936</guid>
            <pubDate>Tue, 06 Jan 2026 17:59:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rationaloptimistsociety.substack.com/p/dude-wheres-my-supersonic-jet">https://rationaloptimistsociety.substack.com/p/dude-wheres-my-supersonic-jet</a>, See on <a href="https://news.ycombinator.com/item?id=46515936">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>Dear Rational Optimist,</p><p>The Wright brothers first sputtered into the air in 1903.</p><p>Concorde broke the sound barrier in 1969.</p><p>Only 66 years separate these two photos:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Mihn!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ea69204-b2ba-4ed2-96a7-8ae1b30f6f69_597x197.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Mihn!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ea69204-b2ba-4ed2-96a7-8ae1b30f6f69_597x197.png 424w, https://substackcdn.com/image/fetch/$s_!Mihn!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ea69204-b2ba-4ed2-96a7-8ae1b30f6f69_597x197.png 848w, https://substackcdn.com/image/fetch/$s_!Mihn!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ea69204-b2ba-4ed2-96a7-8ae1b30f6f69_597x197.png 1272w, https://substackcdn.com/image/fetch/$s_!Mihn!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ea69204-b2ba-4ed2-96a7-8ae1b30f6f69_597x197.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Mihn!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ea69204-b2ba-4ed2-96a7-8ae1b30f6f69_597x197.png" width="597" height="197" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9ea69204-b2ba-4ed2-96a7-8ae1b30f6f69_597x197.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:197,&quot;width&quot;:597,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Wright Brothers and supersonic plane collage image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="Wright Brothers and supersonic plane collage image" title="Wright Brothers and supersonic plane collage image" srcset="https://substackcdn.com/image/fetch/$s_!Mihn!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ea69204-b2ba-4ed2-96a7-8ae1b30f6f69_597x197.png 424w, https://substackcdn.com/image/fetch/$s_!Mihn!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ea69204-b2ba-4ed2-96a7-8ae1b30f6f69_597x197.png 848w, https://substackcdn.com/image/fetch/$s_!Mihn!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ea69204-b2ba-4ed2-96a7-8ae1b30f6f69_597x197.png 1272w, https://substackcdn.com/image/fetch/$s_!Mihn!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9ea69204-b2ba-4ed2-96a7-8ae1b30f6f69_597x197.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>But in the 56 years since Concorde debuted, aviation innovation has been stuck in a rut. Planes have gotten safer but slower. The fastest commercial passenger jet currently operating, the Boeing 747-8, flies half as fast as the Concorde.</p><p>I felt the pain personally on my recent trip from Abu Dhabi to LA. 24 hours door-to-door. We have the technology to reduce that to under 10. Why don‚Äôt we?</p><p>Three reasons: noise, regulation and cost. As I‚Äôll show you, all three are at various stages of being solved by some of the smartest and most dedicated founders I‚Äôve ever met.</p><p><span>For a full primer on supersonic flight, read my colleague </span><a href="https://rationaloptimistsociety.substack.com/p/the-near-term-future-of-flight" rel="">David Galland‚Äôs excellent Deep Dive</a><span>. In this essay I‚Äôll focus on the exciting progress made in supersonic in the last six months, led by two companies I just visited (</span><strong>Boom Supersonic</strong><span> and </span><strong>Astro Mechanica</strong><span>) and one startup whose founder I recently interviewed (</span><strong>Hermeus</strong><span>).</span></p><p>All three are moving fast. All three will change how we fly. And they have big plans to usher in ‚ÄúSupersonic 2.0,‚Äù where anyone can catch a quick, affordable supersonic flight almost anywhere on earth.</p><p>Who will win?</p><p><em><strong>The evolution</strong></em></p><p>Earlier this year Boom Supersonic‚Äôs XB-1 became the first privately developed jet to break the sound barrier.</p><p>Importantly, nobody on the ground heard a thing, thanks to Boom‚Äôs application of a concept called ‚ÄúMach cutoff.‚Äù By flying at the right altitude and using AI software to measure atmospheric conditions, Boom ensured the loud sonic boom curved upward and dissipated into the sky, rather than disturbing people below.</p><p>Noise problem solved.</p><p>A few months later in June, likely as a result of Boom‚Äôs quiet supersonic demonstration, we got the regulatory change we needed.</p><p><span>Since 1973 all supersonic flight, noisy or not, has been banned over land in the US. On June 6, Executive Order 14304 restored our right to fly supersonic, ‚Äú</span><em>provided the aircraft do not produce an audible sonic boom on the ground</em><span>.‚Äù</span></p><p>Two weeks ago I flew to Denver to meet the man who‚Äôs done the most to make supersonic 2.0 a reality: Boom CEO Blake Scholl.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!iGbY!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2117808-ec3e-45b4-a4b3-75084e03b3de_630x472.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!iGbY!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2117808-ec3e-45b4-a4b3-75084e03b3de_630x472.png 424w, https://substackcdn.com/image/fetch/$s_!iGbY!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2117808-ec3e-45b4-a4b3-75084e03b3de_630x472.png 848w, https://substackcdn.com/image/fetch/$s_!iGbY!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2117808-ec3e-45b4-a4b3-75084e03b3de_630x472.png 1272w, https://substackcdn.com/image/fetch/$s_!iGbY!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2117808-ec3e-45b4-a4b3-75084e03b3de_630x472.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!iGbY!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2117808-ec3e-45b4-a4b3-75084e03b3de_630x472.png" width="630" height="472" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a2117808-ec3e-45b4-a4b3-75084e03b3de_630x472.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:472,&quot;width&quot;:630,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Boom Supersonic XB-1 image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="Boom Supersonic XB-1 image" title="Boom Supersonic XB-1 image" srcset="https://substackcdn.com/image/fetch/$s_!iGbY!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2117808-ec3e-45b4-a4b3-75084e03b3de_630x472.png 424w, https://substackcdn.com/image/fetch/$s_!iGbY!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2117808-ec3e-45b4-a4b3-75084e03b3de_630x472.png 848w, https://substackcdn.com/image/fetch/$s_!iGbY!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2117808-ec3e-45b4-a4b3-75084e03b3de_630x472.png 1272w, https://substackcdn.com/image/fetch/$s_!iGbY!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2117808-ec3e-45b4-a4b3-75084e03b3de_630x472.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Boom Supersonic‚Äôs ‚Äúboomless‚Äù jet, XB-1</em></figcaption></figure></div><p>Blake embodies the ‚Äúbits to atoms‚Äù shift underway in America. Before founding Boom, he was designing internet coupons for Groupon.</p><p>With no aerospace background, Blake taught himself the necessary skills and built a team of believers. Within a decade, his team created a working supersonic jet from scratch.</p><p>Boom‚Äôs XB-1 test jet was one-third the size of its planned full-sized supersonic jet, called Overture. Overture will be sleek and needle-nosed, designed to solve the Concorde‚Äôs Achilles‚Äô heel: cost.</p><p>Concorde tickets would cost upward of $20,000 in today‚Äôs money. The big problem: Its engines guzzled fuel like a race car going full throttle. Fuel comprised roughly half the cost of operation. And Concorde burned 52% of its fuel just taxiing and taking off!</p><p>That‚Äôs because it essentially used rocket boosters bolted to a jet engine, which were incredibly inefficient at low speeds.</p><p>To solve that, you need a new engine.</p><p><span>Translation: Building airplane engines is </span><em>hard.</em></p><p>Boom is designing and manufacturing its own engine called Symphony.</p><p>I saw Symphony‚Äôs parts scattered around Boom‚Äôs factory. One nickel alloy cylinder alone weighed 500 pounds. It‚Äôs amazing a chunk of metal this big can make it into the sky.</p><p>Fully assembled, a Symphony engine will weigh 14,000 pounds‚Äîheavier than Boom‚Äôs entire XB-1 test plane. And Overture will have four Symphony engines!</p><p>Symphony is a non-afterburning turbofan that‚Äôs essentially a really good version of what we already know works. It takes the proven, reliable jet engine architecture used for decades and optimizes it for one specific mission: cruising at Mach 1.7.</p><p>Symphony solves the efficiency problems that turned Concorde into a cash incinerator. Blake says a NYC-London round-trip ticket will cost $5,000, roughly the cost of a business-class ticket.</p><p>Which brings up a question: Who will be Boom‚Äôs customers?</p><p>Boom is going straight for the commercial market‚Äîit will make airplanes and sell them to airlines like United and American. It‚Äôs already booked 130 orders.</p><p><span>Blake‚Äôs pitch to airlines is enticing: </span><em>‚ÄúYou‚Äôre already flying this route with a 300-seat plane where 80+ people in business class generate most of your profit. Give those passengers a supersonic plane, cut the flight time in half, and charge the same price.‚Äù</em></p><p>The last successful US airplane manufacturer was Douglas Aircraft, founded in 1921.</p><p>I believe Boom will break the century-long drought and succeed. In this sense it could be the ‚ÄúTesla of the skies.‚Äù</p><p>But it‚Äôll be at least five years until we‚Äôre flying on its supersonic jets. Here‚Äôs how I see the timeline.</p><p>Overture‚Äôs first test flight will be in three years. Boom is cleverly working alongside the FAA to ensure as smooth a regulatory approval process as possible. This will speed things up.</p><p>Still, Overture will have to conduct thousands of hours of real test flights over probably two years before it‚Äôs FAA-certified.</p><p>My estimate: You and I will be able to cruise at Mach 1.7 over the clouds on a Boom Supersonic jet in 2033.</p><p><em><strong>The revolution</strong></em></p><p>Down a narrow back alley in San Francisco, Astro Mechanica founder Ian Brooke and his team of engineers and machinists are quietly remaking the future of flight.</p><p>Astro Mechanica is the antithesis of the decades-long, committee-driven process suffocating legacy aerospace. Boeing‚Äôs last major ‚Äúnew‚Äù plane first flew in 2009. Talk about an innovation famine.</p><p><span>Ian earned his pilot‚Äôs license at 17 and admits his core motivation is simple: </span><em>‚ÄúI just want to fly a fast plane.‚Äù </em><span>Here‚Äôs a picture I snapped with Ian and ROS Honorary founder, Matt Ridley in Astro‚Äôs San Francisco testing site:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!qlNd!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95b754df-60a0-4728-8b83-dcadfc60475b_630x472.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!qlNd!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95b754df-60a0-4728-8b83-dcadfc60475b_630x472.png 424w, https://substackcdn.com/image/fetch/$s_!qlNd!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95b754df-60a0-4728-8b83-dcadfc60475b_630x472.png 848w, https://substackcdn.com/image/fetch/$s_!qlNd!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95b754df-60a0-4728-8b83-dcadfc60475b_630x472.png 1272w, https://substackcdn.com/image/fetch/$s_!qlNd!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95b754df-60a0-4728-8b83-dcadfc60475b_630x472.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!qlNd!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95b754df-60a0-4728-8b83-dcadfc60475b_630x472.png" width="630" height="472" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/95b754df-60a0-4728-8b83-dcadfc60475b_630x472.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:472,&quot;width&quot;:630,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Astro Mechanica image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="Astro Mechanica image" title="Astro Mechanica image" srcset="https://substackcdn.com/image/fetch/$s_!qlNd!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95b754df-60a0-4728-8b83-dcadfc60475b_630x472.png 424w, https://substackcdn.com/image/fetch/$s_!qlNd!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95b754df-60a0-4728-8b83-dcadfc60475b_630x472.png 848w, https://substackcdn.com/image/fetch/$s_!qlNd!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95b754df-60a0-4728-8b83-dcadfc60475b_630x472.png 1272w, https://substackcdn.com/image/fetch/$s_!qlNd!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F95b754df-60a0-4728-8b83-dcadfc60475b_630x472.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Matt Ridley with Astro founder Ian Brooke</em></figcaption></figure></div><p>Ian told me a quick story that sums up Astro Mechanica‚Äôs ethos:</p><blockquote><p><em>A pottery teacher divided his class into two groups.</em></p><p><em>One would be graded on the quantity of pots they produced, the other on the quality.</em></p><p><em>At the end of the term the best pots all came from the quantity group. While the quality group theorized and talked, the quantity group learned by doing.</em></p></blockquote><p>In other words, there‚Äôs no substitute for actually doing the thing. Building. Tinkering. Iterating.</p><p>Like Boom, Astro is making its own engine. Unlike Boom, it‚Äôs rethinking the jet engine from scratch.</p><p>In traditional jet engines, the fan, turbine and compressor are all connected. They are efficient at cruise speed and terrible at everything else.</p><p>Astro‚Äôs turboelectric adaptive engine is a chameleon. It‚Äôs part jet, part electric fan, part rocket.</p><p>For takeoff and landing it behaves like an efficient turbofan, sipping fuel. When it goes supersonic it morphs into a powerful ramjet. To potentially go hypersonic (5X the speed of sound) in the future, it transitions into rocket-like mode with no moving parts.</p><p>This technology is new. It only works because of breakthroughs in electric motor power density, which have improved 15X over the past decade.</p><p>What‚Äôs most impressive is Astro has already gone through three rapid engine iterations:</p><ul><li><p>Gen 1 engine: proved electric compression could produce supersonic exhaust.</p></li><li><p>Gen 2 engine: validated efficient subsonic performance.</p></li><li><p>Gen 3 engine: combines both into a single system, now hot-fire testing.</p></li></ul><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Gzcu!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f70dfba-b12a-4d10-a6ec-6e22e1a04e4a_597x265.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Gzcu!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f70dfba-b12a-4d10-a6ec-6e22e1a04e4a_597x265.png 424w, https://substackcdn.com/image/fetch/$s_!Gzcu!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f70dfba-b12a-4d10-a6ec-6e22e1a04e4a_597x265.png 848w, https://substackcdn.com/image/fetch/$s_!Gzcu!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f70dfba-b12a-4d10-a6ec-6e22e1a04e4a_597x265.png 1272w, https://substackcdn.com/image/fetch/$s_!Gzcu!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f70dfba-b12a-4d10-a6ec-6e22e1a04e4a_597x265.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Gzcu!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f70dfba-b12a-4d10-a6ec-6e22e1a04e4a_597x265.png" width="597" height="265" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7f70dfba-b12a-4d10-a6ec-6e22e1a04e4a_597x265.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:265,&quot;width&quot;:597,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Engine generations collage&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="Engine generations collage" title="Engine generations collage" srcset="https://substackcdn.com/image/fetch/$s_!Gzcu!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f70dfba-b12a-4d10-a6ec-6e22e1a04e4a_597x265.png 424w, https://substackcdn.com/image/fetch/$s_!Gzcu!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f70dfba-b12a-4d10-a6ec-6e22e1a04e4a_597x265.png 848w, https://substackcdn.com/image/fetch/$s_!Gzcu!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f70dfba-b12a-4d10-a6ec-6e22e1a04e4a_597x265.png 1272w, https://substackcdn.com/image/fetch/$s_!Gzcu!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f70dfba-b12a-4d10-a6ec-6e22e1a04e4a_597x265.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Astro Mechanica‚Äôs Gen 1 vs. Gen 3</em></figcaption></figure></div><p>All that innovation quicker than it takes Boeing to update a tray table.</p><p>Astro Mechanica is also designing its engines from the get-go to run on better, cheaper, cleaner fuel.</p><p>Today‚Äôs jets burn kerosene. Now picture an extremely cold, clear liquid that would instantly freeze your finger if you touched it. That‚Äôs liquefied natural gas (LNG), which is cooled to about -260¬∞F. At this temperature, the gas shrinks and becomes a liquid that can be transported.</p><p>LNG was never a viable fuel because it wasn‚Äôt widely available. Thanks to the fracking boom and LNG export infrastructure buildout, it‚Äôs now abundant. Compared to kerosene, LNG burns 30% less CO‚ÇÇ and offers 60% more range.</p><p>Most importantly, LNG is 10X cheaper than kerosene.</p><p><span>Ian emphasizes supersonic</span><em> ‚Äúis not interesting if it‚Äôs not affordable.‚Äù</em><span> The goal is: </span><em>‚ÄúEveryone gets to fly supersonic, priced like Southwest. San Francisco to Tokyo, Mach 2+, for under a thousand bucks.‚Äù</em></p><p>Cheap fuel and efficient engines are the first two pillars of how Astro will achieve this. The third pillar is blowing up the old airline model and reimagining how we fly.</p><p><span>Building a new engine is just the start for Astro Mechanica. It also plans to </span><em>operate</em><span> the airline. Ian‚Äôs vision is Uber for supersonic jets:</span></p><ul><li><p><span>On-Demand Flights: Forget fixed schedules. Book flights when </span><em>you</em><span> need them like you‚Äôd hail a ride.</span></p></li><li><p>Smaller Airports: Utilize thousands of underused regional and private airfields, bypassing the cattle-call congestion of major hubs. Closer to home, faster ground time.</p></li><li><p>More Jets: Small, private jet-sized supersonic aircraft dispatched dynamically based on demand. No more flying empty seats across oceans.</p></li></ul><p><span>Suddenly, the economics work. Small planes, cheap fuel, efficient engines, point-to-point travel, anywhere on Earth. Ian says,</span><em> ‚ÄúWe can go everywhere three times faster and at the same price.‚Äù</em></p><p>Astro‚Äôs first customers won‚Äôt be airlines. It‚Äôs tackling the defense market first. Its ability to go hypersonic (5X the speed of sound) is very useful for military applications.</p><p><span>Ian told me the Pentagon is the perfect first customer because it will pay high prices and </span><em>really</em><span> cares about speed.</span></p><p>Consider the Pacific Ocean. It‚Äôs easy to imagine a scenario where the military needs to reach Taiwan ASAP. Right now, moving assets there takes days of slow flights and mid-air refueling. Astro will be able to get there hypersonically in hours.</p><p>Defense is the perfect steppingstone to building a commercial jet. It‚Äôs less regulated, meaning you can move fast and break things. You can prove your engine works at extreme conditions and bring in cash to fund civilian aircraft development.</p><p>Astro is already recognizing millions of dollars in defense revenue and ramping fast.</p><p>I believe starting with defense allows Astro Mechanica to innovate faster than Boom.</p><p>Start with defense. Then move into the private jet market. Finally, bring supersonic travel to the masses.</p><p><em><strong>The dark horse</strong></em></p><p><span>When I asked AJ Piplica, founder of Atlanta-based hypersonic jet startup Hermeus, to summarize the mission he didn‚Äôt hesitate for a second </span><em>‚Äúwe‚Äôre building the world‚Äôs fastest airplanes.‚Äù</em></p><p>For most of aviation history, we‚Äôve lived in a world capped at roughly Mach 0.8, the cruising speed of modern airliners. Concorde nudged that to Mach 2; the SR‚Äë71 briefly touched Mach 3. Then we stopped. Hermeus wants to jump to Mach 5, five times the speed of sound. That‚Äôs fast enough to make New York‚ÄìLondon a 90‚Äëminute hop.</p><p>Everything Hermeus does hangs off one big technical problem. Engines good at taking off from a runway melt at high speed, and engines good at going fast can‚Äôt take off from a runway.</p><p>Remember, Concorde burned 52% of its fuel just taxiing down the runway. That inefficiency killed supersonic travel.</p><p>Hermeus‚Äô answer is an engine called Chimera. It‚Äôs a hybrid, with two engines strapped together. One that‚Äôs efficient at low speed, and another that can take you five times the speed of sound.</p><p>Hermeus uses a ‚Äúturbojet‚Äù from an F-16 fighter jet for takeoff and acceleration to Mach 3. Then in just five seconds, the turbine shuts down, and air is funneled directly to a hypersonic ‚Äúramjet‚Äù, launching you to Mach 5.</p><p><span>Like Astro Mechanica, Hermeus plans to test its technology in the defense world before building commercial airliners. AJ told me </span><em>‚Äúto build a commercial jet is an incredibly high bar. You have to move extremely slowly. The defense market allows you to go fast.‚Äù</em></p><p>FAA certification takes at least half a decade to prove every system is 100% safe for passengers. Going after the defense market first allows Hermeus to‚Ä¶</p><p>I asked AJ what killed previous hypersonic programs.</p><p><em>‚ÄúWe guessed the future and got it wrong. Aerospace engineers would pick some super hard feature, then spend a decade trying to build it. Rapid iteration is the key to making hypersonic work.‚Äù</em></p><p>Most aerospace programs spend a decade or more before anything flies. Hermeus is taking a page out of SpaceX‚Äôs playbook, with rapid, iterative development, aiming to build a new test aircraft every year.</p><p>They call this the Quarterhorse program. It‚Äôs an escalating series of aircraft, each designed to de‚Äërisk a different piece of the hypersonic puzzle.</p><p>Hermeus first jet, ‚ÄúMk 1‚Äù flew last May. It went from clean‚Äësheet to flight‚Äëready in just over a year.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!WMTn!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01c74b39-bb03-47c4-bd53-f5da987abf46_630x409.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!WMTn!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01c74b39-bb03-47c4-bd53-f5da987abf46_630x409.png 424w, https://substackcdn.com/image/fetch/$s_!WMTn!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01c74b39-bb03-47c4-bd53-f5da987abf46_630x409.png 848w, https://substackcdn.com/image/fetch/$s_!WMTn!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01c74b39-bb03-47c4-bd53-f5da987abf46_630x409.png 1272w, https://substackcdn.com/image/fetch/$s_!WMTn!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01c74b39-bb03-47c4-bd53-f5da987abf46_630x409.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!WMTn!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01c74b39-bb03-47c4-bd53-f5da987abf46_630x409.png" width="630" height="409" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/01c74b39-bb03-47c4-bd53-f5da987abf46_630x409.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:409,&quot;width&quot;:630,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Hermeus Mk 1 image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="Hermeus Mk 1 image" title="Hermeus Mk 1 image" srcset="https://substackcdn.com/image/fetch/$s_!WMTn!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01c74b39-bb03-47c4-bd53-f5da987abf46_630x409.png 424w, https://substackcdn.com/image/fetch/$s_!WMTn!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01c74b39-bb03-47c4-bd53-f5da987abf46_630x409.png 848w, https://substackcdn.com/image/fetch/$s_!WMTn!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01c74b39-bb03-47c4-bd53-f5da987abf46_630x409.png 1272w, https://substackcdn.com/image/fetch/$s_!WMTn!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F01c74b39-bb03-47c4-bd53-f5da987abf46_630x409.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>The future is starting to look like‚Ä¶ the future.</em></figcaption></figure></div><p>The goal was proving this weird shaped plane could remotely take off and land. Tick!</p><p>AJ said Quarterhorse Mk 2 should fly someone in the first quarter of 2026. Mk 2 will be similar in scale to an F‚Äë16 fighter jet and will go supersonic.</p><p>It will de-risk the ‚Äúprecooler‚Äù, a crucial piece of tech that will allow its turbine to run faster than designed without melting, bridging the gap to ramjet speeds.</p><p>Then in 2027 we have Mk 3 to look forward to, which will test the turbojet-to-ramjet transition in flight. If successful, it will break the airspeed record held by the SR-71 Blackbird.</p><p>Every flight brings Hermeus closer to its first revenue generator: a reusable, autonomous military aircraft called ‚ÄúDarkhorse‚Äù that can reach Mach 5.</p><p>This is a capability America badly needs. China and Russia have done 10x more hypersonic tests than the US in the last decade.</p><p>AJ believes ‚Äúspeed is the new stealth.‚Äù Radar and computing are advancing faster than stealth coatings, so the reliable way to survive in contested airspace is to be so fast that enemies can‚Äôt react in time.</p><p>Then in the 2030s, Hermeus wants to debut Halcyon, a 20‚Äëpassenger Mach 5 jet capable of making New York‚ÄìLondon a 90‚Äëminute hop.  A game changer, but at least 10 years away.</p><p>The more money Hermeus makes from defense, the faster it can develop Halcyon. And the sooner you and I can travel around the world at Mach 5. I‚Äôm in!</p><p>I believe all three will be major players in Supersonic 2.0.</p><p><span>Boom is </span><em>perfecting</em><span> the jet engine. It‚Äôs building a better Concorde in a sustainable and profitable way. Boom slots perfectly into the existing airline market and may be the first to get you across the Atlantic in time for breakfast.</span></p><p><span>Astro is </span><em>reinventing</em><span> the jet engine and how we fly. Its path to success is bolder and longer. Astro Mechanica‚Äôs more revolutionary engine designs could make it the more valuable company a decade from now.</span></p><p>Hermeus is the dark horse in the race. Its willingness to innovate fast and break things could leapfrog any competitors stuck at the drawing board.</p><p>Like Astro, Hermeus is using the anti-Concorde strategy: prove the tech works in defense, where customers are willing to pay premiums for speed, then bring costs down for commercial passengers.</p><p>Ultimately, we all win. Especially us frequent long-haul flyers.</p><p>Keep in mind, in 1976 you could fly from New York to London in 3.5 hours. In 2025, it takes seven hours. We went backward.</p><p>Now the regulatory wall is cracking. The technology is better than ever. The capital is flowing. The teams are building.</p><p>It‚Äôs supersonic 2.0 time.</p><p>I asked AJ, Ian and Blake why they‚Äôre dedicating the best years of their lives to building supersonic jets.</p><p>For AJ it started when he saw Lockheed‚Äôs C-5 Galaxy aircraft at an air show when he was a kid. It made him want to build things that fly.</p><p>Ian is a purist. He wants a really fast plane. Nobody is building it. So he had to step up.</p><p>Blake, a dad of four, wants his kids to be able to have friends all over the globe. He wants to live in a world where grandparents can visit their grandkids living halfway across the world for a weekend. (Me too, Blake!)</p><p>He added: Before the jet age, it took days to reach Hawaii on a boat. The jet engine literally created the Hawaiian vacation.</p><p>Supersonic will do the same for the rest of the world. It will turn Sydney into a weekend trip, make global sports leagues (like the NFL) possible, and unlock all sorts of wonderful opportunities we haven‚Äôt dreamt up yet.</p><p>Tell me in the comments what you would do if you could travel anywhere in the world in just a few hours. And be sure to click ‚Äúlike‚Äù and ‚Äúrestack‚Äù to help us spread rational optimism.</p><p>‚ÄîStephen McBride</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Opus 4.5 is not the normal AI agent experience that I have had thus far (584 pts)]]></title>
            <link>https://burkeholland.github.io/posts/opus-4-5-change-everything/</link>
            <guid>46515696</guid>
            <pubDate>Tue, 06 Jan 2026 17:45:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://burkeholland.github.io/posts/opus-4-5-change-everything/">https://burkeholland.github.io/posts/opus-4-5-change-everything/</a>, See on <a href="https://news.ycombinator.com/item?id=46515696">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p><img src="https://burkeholland.github.io/assets/headline1.png" alt="rediculous CEO quote about AI 1"></p>

<p><img src="https://burkeholland.github.io/assets/headline2.png" alt="rediculous CEO quote about AI 2"></p>

<p><img src="https://burkeholland.github.io/assets/headline3.png" alt="rediculous CEO quote about AI 3"></p>

<p>If you had asked me three months ago about these statements, I would have said only someone who‚Äôs never built anything non-trivial would believe they‚Äôre true. Great for augmenting a developer‚Äôs existing workflow, and completions are powerful, but agents replacing developers entirely? No. Absolutely not.</p>

<p>Today, I think that AI coding agents can absolutely replace developers. And the reason that I believe this is Claude Opus 4.5.</p>

<h2 id="opus-45-is-not-normal">Opus 4.5 is not normal</h2>

<p>And by ‚Äúnormal‚Äù, I mean that it is not the normal AI agent experience that I have had thus far. So far, AI Agents seem to be pretty good at writing spaghetti code and after 9 rounds of copy / paste errors into the terminal and ‚Äúfix it‚Äù have probably destroyed my codebase to the extent that I‚Äôll be throwing this whole chat session out and there goes 30 minutes I‚Äôm never getting back.</p>

<p>Opus 4.5 feels to me like the model that we were promised - or rather the promise of AI for coding actually delivered.</p>

<p>One of the toughest things about writing that last sentence is that the immediate response from you should be, ‚Äúprove it‚Äù. So let me show you what I‚Äôve been able to build.</p>

<h3 id="project-1---windows-image-conversion-utility">Project 1 - Windows Image Conversion Utility</h3>

<p>I first noticed that Opus 4.5 was drastically different when I used it to build a Windows utility to right-click an image and convert it to different file types. This was basically a one shot build after asking Opus the best way to add a right-click menu to the file explorer.</p>

<p><img src="https://burkeholland.github.io/assets/convert-me.png" alt="Convert me screenshots"></p>

<p>What amazed me through the process of building this was Opus 4.5 ability to get most things right on the first try. And if it ran into errors, it would try and build using the dotnet CLI, read the errors and iterate until fixed. The only issue I had was Opus inability to see XAML errors, which I used Visual Studio to see and copy / paste back into the agent.</p>

<p>Opus built a site for me to distribute it and handled the bundling of the executable so as to use a powershell script for the install, uninstall. It also built the GitHub Actions which do the release and update the landing page so that all I have to do is push source.</p>

<p><img src="https://burkeholland.github.io/assets/convert-me-site.png" alt="Convert me site screenshot"></p>

<p>The only place I had to use other tools was for the logo - where I used Figma‚Äôs AI to generate a bunch of different variations - but then Opus wrote the scripts to convert that SVG to the right formats for icons, even store distribution if I chose to do so.</p>

<p>Now this is admittedly not a complex application. This is a small Windows utility that is doing basically one thing. It‚Äôs not like I asked Opus 4.5 to build Photoshop.</p>

<p>Except I kind of did.</p>

<h3 id="project-2---screen-recording--editing">Project 2 - Screen recording / editing</h3>

<p>I was so impressed by Opus 4.5 work on this utility that I decided to make a simple GIF recording utility similar to LICEcap for Mac. Great app, questionable name.</p>

<p>But that proved to be so easy, that I went ahead and continued adding features, including capturing and editing video, static images, adding shapes, cropping, blurs and more. I‚Äôm still working on this application as it turns out building a full on image/video editor is kind of a big undertaking. But I got REALLY far in a matter of hours. HOURS, PEOPLE.</p>

<video src="https://burkeholland.github.io/assets/omg-2.mp4" controls="true"></video>

<p>I don‚Äôt have a fancy landing page for this one yet, but you can view all of the source code <a href="https://github.com/burkeholland/RecordMe">here</a>.</p>

<p>I realized that if I could build a video recording app, I could probably build anything at all - at least UI-wise. But the achilles heel of all AI agents is when they have to glue together backend systems - which any real world application is going to have - auth, database, API, storage.</p>

<p>Except Opus 4.5 can do that too.</p>

<h3 id="project-3---ai-posting-utility">Project 3 - AI Posting Utility</h3>

<p>Armed with my confidence in Opus 4.5, I took on a project that I had built in React Native last year and finished for Android, but gave up in the final stretches (as one does).</p>

<p>The application is for my wife who owns a small yard sign franchise. The problem is that she has a Facebook page for the business, but never posts there because it‚Äôs time consuming. But any good small business has a vibrant page where people can see photos of your business doing‚Ä¶whatever the heck it does. So people know that it exsits and is alive and well.</p>

<p>The idea is simple - each time she sets up a yard sign, she takes a picture to send to the person who ordered it so they can see it was setup. So why not have a mobile app where she can upload 10 images at a time, and the app will use AI to generate captions and then schedule them and post them over the coming week.</p>

<p>It‚Äôs a simple premise, but it has a lot of moving parts - there is the Facebook authentication which is a caper in and of itself - not for the faint of heart. There is authentication with a backend, there is file storage for photos that are scheduled to go out, there is the backend process which needs to post the photo. It‚Äôs a full on backend setup.</p>

<p>As it turns out, I needed to install some blinds in the house so I thought - why don‚Äôt I see if Opus 4.5 can build this while I install the blinds.</p>

<p>So I fired up a chat session and just started by telling Opus 4.5 what I wanted to build and how it would recommend handling the backend. It recommended several options but settled on Firebase. I‚Äôm not now nor have I ever been a Firebase user, but at this point I trust Opus 4.5 a lot. Probably too much.</p>

<p>So I created a Firebase account, upgraded to the Blaze plan with alerts for billing and Opus 4.5 got to work.</p>

<p>By the time I was done installing blinds, I had a functional iOS application for using AI to caption photos and posting them on a schedule to Facebook.</p>

<p><img src="https://burkeholland.github.io/assets/post-pilot.png" alt="post-pilot app screenshots"></p>

<p>When I say that Opus 4.5 built this almost entirely, I mean it. It used the <code>firebase</code> CLI to stand up any resources it needed and would tag me in for certain things like upgrading a project to the Blaze plan for features like storage, etc. The best part was that when the Firebase cloud functions would throw errors, it would automatically grep those logs, find the error and resolve it. And all it needed was a CLI. No MCP Server. No fancy prompt file telling it how to use Firebase.</p>

<p>And of course, since it‚Äôs solved, I had Opus 4.5 create a backend admin dashboard so I could see what she‚Äôs got pending and make any adjustments.</p>

<p><img src="https://burkeholland.github.io/assets/post-pilot-admin.png" alt="Sign Post Admin Console"></p>

<p>And since it did in a few hours what had taken me two months of work in the evenings instead of being a decent husband, I decided to make up for my dereliction of duties by building her another app for her sign business that would make her life just a bit more delightful - and eliminate two other apps she is currently paying for.</p>

<h3 id="project-4---order-tracking-and-routing">Project 4 - Order tracking and routing</h3>

<p>This app parses orders from her business Gmail account to show her what sign setups / pickups she has for the day, calculates how long its going to take to go to each stop, calculates the optimal route when there is more than one stop and tracks drive time for tax purposes. She was previously using two paid apps for the last two features there.</p>

<p><img src="https://burkeholland.github.io/assets/yardops.png" alt="Yard ops app screenshots"></p>

<p>This app also uses Firebase. Again, Opus one-shotted the Google auth email integration. This is the kind of thing that is painstakingly miserable by hand. And again, Firebase is so well suited here because Opus knows how to use the Firebase CLI so well. It needs zero instruction.</p>

<h3 id="but-you-dont-know-how-the-code-works">BUT YOU DON‚ÄôT KNOW HOW THE CODE WORKS</h3>

<p>No I don‚Äôt. I have a vague idea, but you are right - I do not know how the applications are actually assembled. Especially since I don‚Äôt know Swift at all.</p>

<p>This used to be a major hangup for me. I couldn‚Äôt diagnose problems when things went sideways. With Opus 4.5, I haven‚Äôt hit that wall yet‚ÄîOpus always figures out what the issue is and fixes its own bugs.</p>

<p>The real question is code quality. Without understanding how it‚Äôs built, how do I know if there‚Äôs duplication, dead code, or poor patterns? I used to obsess over this. Now I‚Äôm less worried that a human needs to read the code, because I‚Äôm genuinely not sure that they do.</p>

<p>Why does a human need to read this code at all? I use a custom agent in VS Code that tells Opus to write code for LLMs, not humans. Think about it‚Äîwhy optimize for human readability when the AI is doing all the work and will explain things to you when you ask?</p>

<p>What you <strong>don‚Äôt</strong> need: variable names, formatting, comments meant for humans, or patterns designed to spare your brain.</p>

<p>What you <strong>do</strong> need: simple entry points, explicit code with fewer abstractions, minimal coupling, and linear control flow.</p>

<p>Here‚Äôs my custom agent prompt:</p>

<div><pre><code>You are an AI-first software engineer. Assume all code will be written and maintained by LLMs, not humans. Optimize for model reasoning, regeneration, and debugging ‚Äî not human aesthetics.

These coding principles are mandatory:
<span>
1.</span> Structure
<span>-</span> Use a consistent, predictable project layout.
<span>-</span> Group code by feature/screen; keep shared utilities minimal.
<span>-</span> Create simple, obvious entry points.
<span>-</span> Before scaffolding multiple files, identify shared structure first. Use framework-native composition patterns (layouts, base templates, providers, shared components) for elements that appear across pages. Duplication that requires the same fix in multiple places is a code smell, not a pattern to preserve.
<span>
2.</span> Architecture
<span>-</span> Prefer flat, explicit code over abstractions or deep hierarchies.
<span>-</span> Avoid clever patterns, metaprogramming, and unnecessary indirection.
<span>-</span> Minimize coupling so files can be safely regenerated.
<span>
3.</span> Functions and Modules
<span>-</span> Keep control flow linear and simple.
<span>-</span> Use small-to-medium functions; avoid deeply nested logic.
<span>-</span> Pass state explicitly; avoid globals.
<span>
4.</span> Naming and Comments
<span>-</span> Use descriptive-but-simple names.
<span>-</span> Comment only to note invariants, assumptions, or external requirements.
<span>
5.</span> Logging and Errors
<span>-</span> Emit detailed, structured logs at key boundaries.
<span>-</span> Make errors explicit and informative.
<span>
6.</span> Regenerability
<span>-</span> Write code so any file/module can be rewritten from scratch without breaking the system.
<span>-</span> Prefer clear, declarative configuration (JSON/YAML/etc.).
<span>
7.</span> Platform Use
<span>-</span> Use platform conventions directly and simply (e.g., WinUI/WPF) without over-abstracting.
<span>
8.</span> Modifications
<span>-</span> When extending/refactoring, follow existing patterns.
<span>-</span> Prefer full-file rewrites over micro-edits unless told otherwise.
<span>
9.</span> Quality
<span>-</span> Favor deterministic, testable behavior.
<span>-</span> Keep tests simple and focused on verifying observable behavior.

Your goal: produce code that is predictable, debuggable, and easy for future LLMs to rewrite or extend.
</code></pre></div>

<p>All of that said, I don‚Äôt have any proof that this prompt makes a difference. I find that Opus 4.5 writes pretty solid code no matter what you prompt it with. However, because models like to write code WAY more than they like to delete it, I will at points run a prompt that looks something like this‚Ä¶</p>

<div><pre><code>Check your LLM, AI coding principles and then do a comprehensive search of this application and suggest what we can do to refactor this to better align to those principles. Also point out any code that can be deleted, any files that can be deleted, things that should read should be renamed, things that should be restructured. Then do a write up of what that looks like. Kind of keep it high level so that it's easy for me to read and not too complex. Add sections for high, medium and lower priority And if something doesn't need to be changed, then don't change it. You don't need to change things just for the sake of changing them. You only need to change them if it helps better align to your LLM AI coding principles. Save to a markdown file.
</code></pre></div>

<p>And you get a document that has high, medium and low priority items. The high ones you can deal with and the AI will stop finding them. You can refactor your project a million times and it will keep finding medium/low priority refactors that you can do. An AI is never ever going to pass on the opportunity to generate some text.</p>

<p>I use a similar prompt to find security issues. These you have to be very careful about. Where are the API keys? Is login handled correctly? Are you storing sensitive values in the database? This is probably the most manual part of the project and frankly, something that makes me the most nervous about all of these apps at the moment. I‚Äôm not 100% confident that they are bullet proof. Maybe like 80%. And that, as they say, is too damn low.</p>

<h3 id="times-they-are-a-changin">Times they are A-changin</h3>

<p>I don‚Äôt know if I feel exhilarated by what I can now build in a matter of hours, or depressed because the thing I‚Äôve spent my life learning to do is now trivial for a computer. Both are true.</p>

<p>I understand if this post made you angry. I get it - I didn‚Äôt like it either when people said ‚ÄúAI is going to replace developers.‚Äù But I can‚Äôt dismiss it anymore. I can wish it weren‚Äôt true, but wishing doesn‚Äôt change reality.</p>

<p>But for everything else? Build. Stop waiting to have all the answers. Stop trying to figure out your place in an AI-first world. The answer is the same as it always was: make things. And now you can make them faster than you ever thought possible.</p>

<p>Just make sure you know where your API keys are.</p>

<blockquote>
  <p>Disclaimer: This post was written by a human and edited for spelling, grammer by Haiku 4.5</p>
</blockquote>


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Volkswagen Brings Back Physical Buttons (354 pts)]]></title>
            <link>https://www.caranddriver.com/news/a69916699/volkswagen-interior-physical-buttons-return/</link>
            <guid>46514913</guid>
            <pubDate>Tue, 06 Jan 2026 16:59:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.caranddriver.com/news/a69916699/volkswagen-interior-physical-buttons-return/">https://www.caranddriver.com/news/a69916699/volkswagen-interior-physical-buttons-return/</a>, See on <a href="https://news.ycombinator.com/item?id=46514913">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-journey-body="standard-article"><ul data-node-id="0"><li><strong><a href="https://caranddriver.com/volkswagen" target="_blank" data-vars-ga-outbound-link="https://caranddriver.com/volkswagen" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="Volkswagen">Volkswagen</a> revealed a new generation of cockpit design with the refreshed ID. Polo. </strong></li><li><strong>The new design marks a big departure for VW and features a plethora of physical controls rather than the capacitive buttons on current models. </strong></li><li><strong>While the switchgear is currently only found on the new ID. Polo, which isn't sold in the United States, it could debut on the soon-to-be-refreshed <a href="https://caranddriver.com/volkswagen/id4" target="_blank" data-vars-ga-outbound-link="https://caranddriver.com/volkswagen/id4" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="ID.4">ID.4</a>.</strong></li></ul><p data-journey-content="true" data-node-id="1">Volkswagen is making a drastic change to its interiors, or at least the interiors of its electric vehicles. The automaker recently unveiled a new cockpit generation with the refreshed ID. Polo‚Äîthe diminutive electric hatchback that the brand sells in Europe‚Äîthat now comes with physical buttons.  </p><div size="medium" data-embed="body-image" data-lazy-id="P0-16" data-node-id="3"><p><img draggable="true" alt="2027 volkswagen id polo" title="2027 Volkswagen ID. Polo" loading="lazy" width="1795" height="921" decoding="async" data-nimg="1" sizes="100vw" srcset="https://hips.hearstapps.com/hmg-prod/images/db2025au02036-large-695bdd8263564.jpg?crop=0.842xw:1.00xh;0.158xw,0&amp;resize=640:* 640w, https://hips.hearstapps.com/hmg-prod/images/db2025au02036-large-695bdd8263564.jpg?crop=0.842xw:1.00xh;0.158xw,0&amp;resize=768:* 980w, https://hips.hearstapps.com/hmg-prod/images/db2025au02036-large-695bdd8263564.jpg?crop=0.842xw:1.00xh;0.158xw,0&amp;resize=980:* 1120w, https://hips.hearstapps.com/hmg-prod/images/db2025au02036-large-695bdd8263564.jpg?crop=0.842xw:1.00xh;0.158xw,0&amp;resize=980:* 1400w, https://hips.hearstapps.com/hmg-prod/images/db2025au02036-large-695bdd8263564.jpg?crop=0.842xw:1.00xh;0.158xw,0&amp;resize=980:* 1800w, https://hips.hearstapps.com/hmg-prod/images/db2025au02036-large-695bdd8263564.jpg?crop=0.842xw:1.00xh;0.158xw,0&amp;resize=980:* 2000w" src="https://hips.hearstapps.com/hmg-prod/images/db2025au02036-large-695bdd8263564.jpg?crop=0.842xw:1.00xh;0.158xw,0&amp;resize=980:*"></p><p><figcaption data-theme-key="photo-credit-figcaption"><span data-theme-key="photo-credit-creditor">Volkswagen</span></figcaption></p></div><p data-journey-content="true" data-node-id="4">While VW certainly isn't the only automaker that pushed the envelope with haptic controls and digital buttons, it was a particularly egregious offender. Now, the company is doing a complete 180-degree shift, adding a full suite of physical buttons and switchgear to the Polo's interior. </p><p data-journey-content="true" data-node-id="6">The steering wheel gets new clusters of buttons for cruise control and interacting with music playback, while switches for the temperature and fan speed now live in a row along the dashboard. The move back to buttons doesn't come out of nowhere. Volkswagen already started the shift with the new versions of the Golf and Tiguan models in the United States. Unfortunately, some climate controls, such as those for the rear defrost and the heated seats, are still accessed through the touchscreen. Thankfully, they look to retain their dedicated spot at the bottom of the display. </p><div size="medium" data-embed="body-image" data-lazy-id="P0-17" data-node-id="7"><p><img draggable="true" alt="2027 volkswagen id polo" title="2027 Volkswagen ID. Polo" loading="lazy" width="4000" height="2667" decoding="async" data-nimg="1" sizes="100vw" srcset="https://hips.hearstapps.com/hmg-prod/images/db2025au02046-large-695bdd828aa56.jpg?crop=0.963xw:0.883xh;0,0.117xh&amp;resize=640:* 640w, https://hips.hearstapps.com/hmg-prod/images/db2025au02046-large-695bdd828aa56.jpg?crop=0.963xw:0.883xh;0,0.117xh&amp;resize=768:* 980w, https://hips.hearstapps.com/hmg-prod/images/db2025au02046-large-695bdd828aa56.jpg?crop=0.963xw:0.883xh;0,0.117xh&amp;resize=980:* 1120w, https://hips.hearstapps.com/hmg-prod/images/db2025au02046-large-695bdd828aa56.jpg?crop=0.963xw:0.883xh;0,0.117xh&amp;resize=980:* 1400w, https://hips.hearstapps.com/hmg-prod/images/db2025au02046-large-695bdd828aa56.jpg?crop=0.963xw:0.883xh;0,0.117xh&amp;resize=980:* 1800w, https://hips.hearstapps.com/hmg-prod/images/db2025au02046-large-695bdd828aa56.jpg?crop=0.963xw:0.883xh;0,0.117xh&amp;resize=980:* 2000w" src="https://hips.hearstapps.com/hmg-prod/images/db2025au02046-large-695bdd828aa56.jpg?crop=0.963xw:0.883xh;0,0.117xh&amp;resize=980:*"></p><p><figcaption data-theme-key="photo-credit-figcaption"><span data-theme-key="photo-credit-creditor">Volkswagen</span></figcaption></p></div><p data-journey-content="true" data-node-id="8">Volkswagen hasn't announced which models will receive the new cockpit design. The redesigned interior also may be limited to the brand's electric vehicles, which would limit it to the upcoming refresh for the ID.4 SUV (and potentially the <a href="https://www.caranddriver.com/volkswagen/id-buzz-microbus" target="_blank" data-vars-ga-outbound-link="https://www.caranddriver.com/volkswagen/id-buzz-microbus" data-vars-ga-ux-element="Hyperlink" data-vars-ga-call-to-action="ID.Buzz">ID.Buzz</a>), as the only VW EV models currently sold in America. </p><hr data-node-id="11"><p id="skip-the-lot-let-car-and-driver-help-you-find-your-next-car" data-journey-content="true" data-node-id="12">‚û°Ô∏è Skip the lot. Let Car and Driver help you find your next car.</p><p data-journey-content="true" data-node-id="13"><a href="https://www.caranddriver.com/cars-for-sale/new" target="_blank" data-vars-ga-outbound-link="https://www.caranddriver.com/cars-for-sale/new" data-vars-ga-call-to-action="Shop New Cars" data-vars-ga-ux-element="Hyperlink">Shop New Cars</a> <a href="https://www.caranddriver.com/cars-for-sale/used" target="_blank" data-vars-ga-outbound-link="https://www.caranddriver.com/cars-for-sale/used" data-vars-ga-call-to-action="Shop Used Cars" data-vars-ga-ux-element="Hyperlink">Shop Used Cars</a></p><div data-journey-blur="partial" data-ad-exclude="true"><p><span><img src="https://hips.hearstapps.com/rover/profile_photos/fac2a745-e58e-49fc-be50-42f30a2ea607_1721749327.file?fill=1:1&amp;resize=120:*" alt="Headshot of Jack Fitzgerald" title="Headshot of Jack Fitzgerald" width="100%" height="100%" decoding="async" loading="lazy"></span></p><div><p>Jack Fitzgerald‚Äôs love for cars stems from his as yet unshakable addiction to Formula 1. <br>
After a brief stint as a detailer for a local dealership group in college, he knew he needed a more permanent way to drive all the new cars he couldn‚Äôt afford and decided to pursue a career in auto writing. By hounding his college professors at the University of Wisconsin-Milwaukee, he was able to travel Wisconsin seeking out stories in the auto world before landing his dream job at <em>Car and Driver</em>. His new goal is to delay the inevitable demise of his 2010 Volkswagen Golf.</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why is the Gmail app 700 MB? (399 pts)]]></title>
            <link>https://akr.am/blog/posts/why-is-the-gmail-app-700-mb</link>
            <guid>46514692</guid>
            <pubDate>Tue, 06 Jan 2026 16:46:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://akr.am/blog/posts/why-is-the-gmail-app-700-mb">https://akr.am/blog/posts/why-is-the-gmail-app-700-mb</a>, See on <a href="https://news.ycombinator.com/item?id=46514692">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>The Gmail app, <a href="https://apps.apple.com/us/app/422689480">on the App Store</a>, is
currently 760.7 MB in size. It is in the top three <a href="https://akr.am/app-bloat/">most bloated
apps</a> out of the top 100 free apps. I don‚Äôt use it
on my phone, but I was prompted to compare it with the seemingly hefty one I
(have to) use, Outlook, while clearing up some storage space. Its measly 428 MB
size pales in comparison.</p>

<p>This isn‚Äôt new. In 2017, Axios
<a href="https://www.axios.com/2017/12/15/the-top-iphone-apps-are-taking-up-a-lot-more-space-1513303131">reported</a>
that the top iPhone apps had been taking up an increasing amount of space over
the period from 2013 to 2017. For most of that period, the size of the Gmail
app hovered around 12 MB, with a sudden jump to more than 200 MB near the start
of 2017. Other popular apps also saw a 10x or more increase in size over the
same period.</p>

<p>Gmail isn‚Äôt even the worst offender, it‚Äôs just a more popular one. The Tesla
and Crypto.com apps are around 1 GB each. So is Samsung‚Äôs SmartThings app.
What about Google‚Äôs other popular apps? Google Home is another hefty one, at
630 MB, that I used for its remote feature, which I replaced with Google TV at
almost a tenth the size. Their other popular apps average around <a href="https://akr.am/app-bloat/?list=popular&amp;developer=Google">250
MB</a> in size. This
seems tame in comparison to Microsoft, with an average app size of around
<a href="https://akr.am/app-bloat/?list=popular&amp;developer=Microsoft+Corporation">330MB</a>.
For reference, the average size of an app in the top 100 free apps is <a href="https://akr.am/app-bloat/?list=top">280
MB</a> or, in a more expanded set (including
games), <a href="https://akr.am/app-bloat/?list=popular">200MB</a>.</p>

<p>Just to put this into perspective, on my device, apps (excluding their data)
use up 35 GB, and the data is another 35 GB. iOS takes up another 25 GB. Let‚Äôs
say, 100 GB for apps, data and the OS. That leaves me with 20 GB (leaving a
margin of free space for updates) meant to be used for capturing 4K video and
high-quality photos (why else get an iPhone), and storing music (don‚Äôt even
think about lossless). The reality is that running out of space also slows
things down, since most of my photos need to be fetched from the cloud before
viewing them, and I need to re-download these hefty offloaded apps when I need
them again. And good luck if you have a limited data bundle.</p>

<p>Maybe this doesn‚Äôt matter. The latest iPhones start at 256 GB, and surely I‚Äôll
have plenty of space when I get a new one (although I remember saying this when
I upgraded to 64 GB from 32 GB). It‚Äôs not really about the space though. These
apps don‚Äôt have 50x or even 10x the functionality. But now they‚Äôre 100x larger,
and probably slower. Why?</p>

<p>Also, can someone explain why Microsoft Authenticator is 150 MB to show 6-digit
codes?</p>

<p>It‚Äôs not clear if this is specifically an iOS problem. I don‚Äôt have an Android
device and I could not find a way to get that information from the Play Store
without a device. That said, I checked the size of Gmail on someone‚Äôs Android
phone, and it‚Äôs around 185 MB, which certainly seems much better.</p>

<p>And if you‚Äôre considering switching from the default apps, this is what the
installed size (which differs slightly from the App Store size) is of the
alternatives on my iPhone running iOS 26.2:</p>

<table>
  <thead>
    <tr>
      <th>App</th>
      <th>Apple</th>
      <th>Google</th>
      <th>Microsoft</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Files - Drive - OneDrive</td>
      <td>2.6 MB</td>
      <td><strong>370 MB</strong></td>
      <td>283 MB</td>
    </tr>
    <tr>
      <td>Passwords - Authenticator</td>
      <td>3.2 MB</td>
      <td>35 MB</td>
      <td><strong>138 MB</strong></td>
    </tr>
    <tr>
      <td>FaceTime - Meet - Teams</td>
      <td>3.4 MB</td>
      <td>263 MB</td>
      <td><strong>423 MB</strong></td>
    </tr>
    <tr>
      <td>Photos</td>
      <td>4.2 MB</td>
      <td><strong>372 MB</strong></td>
      <td>-</td>
    </tr>
    <tr>
      <td>Safari - Chrome - Edge</td>
      <td>5.1 MB</td>
      <td>313 MB</td>
      <td><strong>397 MB</strong></td>
    </tr>
    <tr>
      <td>Reminders - Tasks - To Do</td>
      <td>7.7 MB</td>
      <td>89 MB</td>
      <td><strong>132 MB</strong></td>
    </tr>
    <tr>
      <td>Mail - Gmail - Outlook</td>
      <td>8.7 MB</td>
      <td><strong>673 MB</strong></td>
      <td>376 MB</td>
    </tr>
    <tr>
      <td>Home</td>
      <td>14.1 MB</td>
      <td><strong>584 MB</strong></td>
      <td>-</td>
    </tr>
    <tr>
      <td>Notes - Keep - OneNote</td>
      <td>17.3 MB</td>
      <td>171 MB</td>
      <td><strong>315 MB</strong></td>
    </tr>
    <tr>
      <td>Maps</td>
      <td>68 MB</td>
      <td><strong>385 MB</strong></td>
      <td>-</td>
    </tr>
    <tr>
      <td>Pages - Docs - Word</td>
      <td><strong>456 MB</strong></td>
      <td>311 MB</td>
      <td>434 MB</td>
    </tr>
    <tr>
      <td>Numbers - Sheets - Excel</td>
      <td><strong>500 MB</strong></td>
      <td>337 MB</td>
      <td>370 MB</td>
    </tr>
    <tr>
      <td>Keynote - Slides - PowerPoint</td>
      <td><strong>516 MB</strong></td>
      <td>270 MB</td>
      <td>376 MB</td>
    </tr>
  </tbody>
</table>

<p>So, why is the Gmail app almost 80x the size of the native Mail app? My guess
is as good as yours.</p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Vienam Bans Unskippable Ads, Requires Skip Button to Appear After 5 Seconds (1362 pts)]]></title>
            <link>https://saigoneer.com/vietnam-news/28652-vienam-bans-unskippable-ads,-requires-skip-button-to-appear-after-5-seconds</link>
            <guid>46514677</guid>
            <pubDate>Tue, 06 Jan 2026 16:45:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://saigoneer.com/vietnam-news/28652-vienam-bans-unskippable-ads,-requires-skip-button-to-appear-after-5-seconds">https://saigoneer.com/vietnam-news/28652-vienam-bans-unskippable-ads,-requires-skip-button-to-appear-after-5-seconds</a>, See on <a href="https://news.ycombinator.com/item?id=46514677">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ja-contentwrap">

		
	<article>
		
<p id="docs-internal-guid-28901e71-7fff-d101-2597-5493faf3a092" dir="ltr">If things go our way, YouTube‚Äôs notorious unskippable ads might be a thing of the past come this February.</p>
 
<p dir="ltr">As <a href="https://www.phunuonline.com.vn/tu-15-2-quang-cao-video-khong-duoc-ep-nguoi-dung-xem-qua-5-giay-a1571286.html" target="_blank"><em>Ph·ª• N·ªØ</em></a> reports, Vietnam recently announced <a href="https://thuvienphapluat.vn/phap-luat/ho-tro-phap-luat/tu-1522026-quang-cao-online-phai-duoc-tat-sau-5-giay-thoi-gian-cho-tat-quang-cao-tren-mang-khong-qu-249658.html" target="_blank">Decree No. 342</a>, which details a number of provisions to the national Advertising Law, due to take effect from February 15, 2026. The adjustments are expected to place stricter control on Vietnam‚Äôs online advertising activities to protect consumers and curb illegal ads.</p>
<p dir="ltr">Amongst the decree articles, some standout stipulations include a hard cap on the waiting time before viewers can skip video and animated ads to no more than 5 seconds. Static ads must be immediately cancellable.</p>
<p dir="ltr">Additionally, the decree requires platforms to implement clear and straightforward ways for users to close ads with just one interaction. False or vague symbols designed to confuse viewers are forbidden.</p>
<p dir="ltr">Online platforms must add visible symbols and guidelines to help users report ads that violate the law and allow them to turn off, deny, or stop seeing inappropriate ads.</p>
<p dir="ltr">Beside rules about the user experience, the decree also seeks to tightly regulate ads for 11 groups of goods and services that directly impact the environment and human health, including: cosmetics; food and beverages; milk and formula for children; insecticidal chemicals and substances; medical supplies; healthcare services; plant pesticides and veterinary drugs; fertilizers; plant seeds and saplings; pharmaceuticals; and alcoholic drinks.</p>

        

        

        </article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[State of the Fin 2026-01-06 (196 pts)]]></title>
            <link>https://jellyfin.org/posts/state-of-the-fin-2026-01-06/</link>
            <guid>46514282</guid>
            <pubDate>Tue, 06 Jan 2026 16:17:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jellyfin.org/posts/state-of-the-fin-2026-01-06/">https://jellyfin.org/posts/state-of-the-fin-2026-01-06/</a>, See on <a href="https://news.ycombinator.com/item?id=46514282">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__blog-post-container"><p>Happy New Year and welcome to the State of the Fin!
This new blog series will regularly basis highlight the ongoing development of Jellyfin and our official clients.
We aim to keep our community informed and engaged, so feel free to share your feedback or thoughts on our progress!</p>
<!-- -->
<h2 id="project-updates">Project Updates<a href="#project-updates" aria-label="Direct link to Project Updates" title="Direct link to Project Updates" translate="no">‚Äã</a></h2>
<h3 id="jellyfin-turns-7">Jellyfin Turns 7<a href="#jellyfin-turns-7" aria-label="Direct link to Jellyfin Turns 7" title="Direct link to Jellyfin Turns 7" translate="no">‚Äã</a></h3>
<p>December marked Jellyfin's 7th anniversary!
A lot has changed in 7 years, but we remain steadfast in our commitment to Open Source and to being the best personal media server out there.
Special thanks to our developers, testers, moderators, and supporters for your invaluable contributions!
Here's to many more years of collaboration and streaming!</p>
<h3 id="versioning">Versioning<a href="#versioning" aria-label="Direct link to Versioning" title="Direct link to Versioning" translate="no">‚Äã</a></h3>
<p>We received a substantial amount of feedback regarding our versioning scheme following the 10.11 release, particularly concerning the stability of what are perceived as 'minor' version updates.
This has prompted internal discussions about potentially revising our versioning scheme in the next major release.
While nothing has been finalized yet, we are considering 'dropping' the major version 10, which would make the next release 12.0.
Stay tuned for further updates as we navigate this feedback!</p>
<h2 id="development-updates">Development Updates<a href="#development-updates" aria-label="Direct link to Development Updates" title="Direct link to Development Updates" translate="no">‚Äã</a></h2>
<h3 id="1011-release-status">10.11 Release Status<a href="#1011-release-status" aria-label="Direct link to 10.11 Release Status" title="Direct link to 10.11 Release Status" translate="no">‚Äã</a></h3>
<p>Jellyfin 10.11 introduced a major <a href="https://jellyfin.org/posts/efcore-refactoring-incoming/" target="_blank" rel="noopener noreferrer">EF Core refactor</a>, consolidating the legacy <code>library.db</code> into a single unified <code>jellyfin.db</code>.
Following more than six months of development and an additional six months of release candidate testing, version <a href="https://jellyfin.org/posts/jellyfin-release-10.11.0/" target="_blank" rel="noopener noreferrer">10.11.0</a> was released last year.
This extended testing period allowed us to mitigate most <a href="https://github.com/jellyfin/jellyfin/issues/13047" target="_blank" rel="noopener noreferrer">refactoring</a> and <a href="https://github.com/jellyfin/jellyfin/issues/14350" target="_blank" rel="noopener noreferrer">RC</a>-related issues prior to release.</p>
<p>Even with this level of testing, issues were expected given the scale of the database change and the limited number of users reporting bugs.
These issues are currently being tracked on GitHub across three categories:</p>
<ol>
<li><a href="https://github.com/jellyfin/jellyfin/issues/15045" target="_blank" rel="noopener noreferrer">General bugs</a></li>
<li><a href="https://github.com/jellyfin/jellyfin/issues/15685" target="_blank" rel="noopener noreferrer">Performance bugs</a></li>
<li><a href="https://github.com/jellyfin/jellyfin/issues/15686" target="_blank" rel="noopener noreferrer">Migration and database bugs</a></li>
</ol>
<p>We have been moving quickly to address these issues, delivering four additional point releases with over <a href="https://github.com/jellyfin/jellyfin/compare/v10.11.0...v10.11.5" target="_blank" rel="noopener noreferrer">100 changes</a> since the initial 10.11.0 release.
To date, most point releases have focused on resolving general and migration-related issues.
The remaining migration issues are largely isolated, one-off cases and are unlikely to be resolved.
Most general issues have already been fixed, and the next bug-fix release is expected to include additional fixes for music metadata display issues and for watched status not being preserved when media is replaced or renamed.</p>
<p>We are continuing to investigate ways to mitigate performance issues caused by client-side enumeration and filtering of large datasets.</p>
<h3 id="jellyfin-web-vnext-aka-1012--120">Jellyfin Web vNext (aka 10.12 / 12.0)<a href="#jellyfin-web-vnext-aka-1012--120" aria-label="Direct link to Jellyfin Web vNext (aka 10.12 / 12.0)" title="Direct link to Jellyfin Web vNext (aka 10.12 / 12.0)" translate="no">‚Äã</a></h3>
<ul>
<li><strong>Default 'Experimental' Layout</strong>: The 'Experimental' layout is now enabled by default for all non-TV devices, introducing a new navigation layout and updated UI components.</li>
<li><strong>Theming Support Overhaul</strong>: We are improving theming support by enabling easier runtime customization of default themes through CSS variables and simplifying the process for creating new bundled themes.</li>
<li><strong>Community Acknowledgment</strong>: Huge thanks to those reviewing, testing, and providing feedback on web pull requests. Your contributions are immensely helpful, as the review burden largely falls on me alone!</li>
</ul>
<p>- <a href="https://github.com/thornbill" target="_blank" rel="noopener noreferrer">thornbill</a></p>
<h2 id="client-corner">Client Corner<a href="#client-corner" aria-label="Direct link to Client Corner" title="Direct link to Client Corner" translate="no">‚Äã</a></h2>
<h3 id="jellyfin-desktop">Jellyfin Desktop<a href="#jellyfin-desktop" aria-label="Direct link to Jellyfin Desktop" title="Direct link to Jellyfin Desktop" translate="no">‚Äã</a></h3>
<p>We're rebranding the desktop application from Jellyfin Media Player to Jellyfin Desktop.
The most noteworthy change is the migration from Qt 5 to Qt 6.
This seems to have improved overall performance, though we're still working out issues regarding memory leaks due to the migration.</p>
<p>Apart from the Qt migration, other noteworthy updates.</p>
<ul>
<li>Saved servers and settings will not be migrated from Jellyfin Media Player.</li>
<li>We've laid the foundation for switching servers with the addition of profiles CLI options. The long-term goal is to have a UI for this as well, but the timeline is TBD.</li>
<li>A slew of bug fixes are included.</li>
</ul>
<p>The release is currently available on <a href="https://github.com/jellyfin/jellyfin-desktop" target="_blank" rel="noopener noreferrer">Flathub</a> and in the <a href="https://aur.archlinux.org/packages/jellyfin-desktop" target="_blank" rel="noopener noreferrer">Arch Linux AUR</a>.
Stable builds for Windows and macOS builds are not currently available.
Other Linux distributions will likely be added, though we recommend using Flathub for the time being.
We are not currently supporting Ubuntu 24.04 LTS due to it being stuck on the older Qt 6.4 series, while our new dependency, mpvqt, requires at least Qt 6.5.</p>
<p>- <a href="https://github.com/andrewrabert" target="_blank" rel="noopener noreferrer">Andrew Rabert</a></p>
<h3 id="jellyfin-for-android-tv">Jellyfin for Android TV<a href="#jellyfin-for-android-tv" aria-label="Direct link to Jellyfin for Android TV" title="Direct link to Jellyfin for Android TV" translate="no">‚Äã</a></h3>
<p>Two versions of the Android TV app have been released: <a href="https://github.com/jellyfin/jellyfin-androidtv/releases/tag/v0.19.5" target="_blank" rel="noopener noreferrer">v0.19.5</a> and <a href="https://github.com/jellyfin/jellyfin-androidtv/releases/tag/v0.19.6" target="_blank" rel="noopener noreferrer">v0.19.6</a>!
These updates contain various improvements to music transcoding. The app now properly displays durations again and allows for seeking when music is transcoding. These changes also solve the issue of lyrics not scrolling in certain cases.</p>
<p>For video playback, we have improved the stability of Live TV and now support direct play for the VC-1 and AV1 codecs (if your device supports them). The AV1 support was already available on Android 10 and newer but now works on older Fire TV devices as well.</p>
<p>- <a href="https://github.com/nielsvanvelzen" target="_blank" rel="noopener noreferrer">Niels van Velzen</a></p>
<h3 id="jellyfin-for-xbox">Jellyfin for Xbox<a href="#jellyfin-for-xbox" aria-label="Direct link to Jellyfin for Xbox" title="Direct link to Jellyfin for Xbox" translate="no">‚Äã</a></h3>
<p>The last two updates brought the long awaited full gamepad support and fixes for 4K and HDR.</p>
<ul>
<li><strong>Gamepad support</strong>: Gamepad navigation is now the default navigation type for the Jellyfin for Xbox app and requires a server version of 10.11 or higher to work. However as we cannot switch the input mode type while the app is running, the Jellyfin for Xbox app can no longer connect to older versions than 10.11. As this is a fundamental change in how the app works, there are still a few hiccups like the app not loading correctly and users reporting that the gamepad does not work at all. In those instances we recommend uninstalling and reinstalling the app.</li>
<li><strong>Web UI TV mode</strong>: For versions of Jellyfin earlier than 10.11.5 the web UI still runs in the desktop mode, which might look a bit odd. However, with Jellyfin 10.11.5, we have fixed a bug that now correctly sets the web UI to TV mode, so the UI should work a lot better.</li>
<li><strong>4K and HDR</strong>: For the last few versions, we have been working on enabling 4K and HDR for the app. This is done by integrating with the web UI and switching the HDMI modes. Sadly, this also comes at the cost of not being allowed to run in the background. To enable 4K support, we had to use a feature flag that allocates more video memory to the Jellyfin for Xbox app, making it incompatible with running in the background.</li>
<li><strong>General Improvements</strong>: Alongside the shiny new headline features, we have also been working on the code in general, adding small improvements and cleaning up a lot of code. The latest versions added log files and their upload to the Jellyfin server, tighter integrations with the web UI, a settings view that can be expanded for future features, version compatibility checking, a better server connection experience, and more.</li>
<li><strong>Future</strong>: When I took over the for the previous maintainer almost a year ago, I made a rough plan for the general development of the app. I always planned on keeping the app as a web wrapper because while the app is certainly more popular than most think, it does not have enough support in development to be a full UWP app. Nevertheless, there are a few features left on my to-do list:<!-- -->
<ul>
<li>Localization to other languages</li>
<li>Server discovery</li>
<li>Desktop support</li>
<li>Better decoder support</li>
<li>Subtitle storage on-device</li>
</ul>
</li>
</ul>
<p>- <a href="https://github.com/JPVenson" target="_blank" rel="noopener noreferrer">JPVenson</a></p>
<h3 id="jellyfin-for-roku">Jellyfin for Roku<a href="#jellyfin-for-roku" aria-label="Direct link to Jellyfin for Roku" title="Direct link to Jellyfin for Roku" translate="no">‚Äã</a></h3>
<p><a href="https://github.com/jellyfin/jellyfin-roku/releases/tag/3.0.15" target="_blank" rel="noopener noreferrer">3.0.15</a> was released on 2025-12-18 and is our last release before Roku's year-end publishing blackout. It fixes a bug with HDHomeRun Tuners.</p>
<p>- <a href="https://github.com/1hitsong" target="_blank" rel="noopener noreferrer">1hitsong</a></p>
<h3 id="swiftfin">Swiftfin<a href="#swiftfin" aria-label="Direct link to Swiftfin" title="Direct link to Swiftfin" translate="no">‚Äã</a></h3>
<h4 id="swiftfin-14-is-out-now">Swiftfin 1.4 is out now!<a href="#swiftfin-14-is-out-now" aria-label="Direct link to Swiftfin 1.4 is out now!" title="Direct link to Swiftfin 1.4 is out now!" translate="no">‚Äã</a></h4>
<p>This is a large release with a lot of changes under the hood. Our three highlight changes are:</p>
<ol>
<li><a href="https://github.com/jellyfin/Swiftfin/pull/1602" target="_blank" rel="noopener noreferrer">Navigation &amp; Routing Overhaul</a></li>
<li><a href="https://github.com/jellyfin/Swiftfin/pull/1772" target="_blank" rel="noopener noreferrer">Jellyfin 10.11 Support</a></li>
<li><a href="https://github.com/jellyfin/Swiftfin/pull/1581" target="_blank" rel="noopener noreferrer">Revamped Media Player Manager</a></li>
</ol>
<h4 id="swiftfin-roadmap">Swiftfin Roadmap<a href="#swiftfin-roadmap" aria-label="Direct link to Swiftfin Roadmap" title="Direct link to Swiftfin Roadmap" translate="no">‚Äã</a></h4>
<p>A <a href="https://github.com/orgs/jellyfin/projects/68" target="_blank" rel="noopener noreferrer">roadmap / project board</a> for Swiftfin is now available!</p>
<p>Follow <a href="https://github.com/jellyfin/Swiftfin/discussions/1294" target="_blank" rel="noopener noreferrer">this discussion</a> for information about the next tvOS release.</p>
<p>To help organize Issues &amp; PRs, Swiftfin now has milestones to help users identify which changes will be included in each release:</p>
<ul>
<li><a href="https://github.com/jellyfin/Swiftfin/milestone/2" target="_blank" rel="noopener noreferrer">Version 1.5</a>
<ul>
<li>Contains issues that should be resolved in version 1.5 of Swiftfin iOS.</li>
</ul>
</li>
<li><a href="https://github.com/jellyfin/Swiftfin/milestone/3" target="_blank" rel="noopener noreferrer">tvOS Resync</a>
<ul>
<li>Contains tvOS-specific issues that will be resolved as part of our next <a href="https://github.com/jellyfin/Swiftfin/discussions/1294" target="_blank" rel="noopener noreferrer">tvOS Release</a>.</li>
<li><em>Issues that impact tvOS but are part of 1.4 or 1.5 will end up in the version milestone instead of this one. Once tvOS is released, it should mirror our existing 1.X structure and iOS.</em></li>
</ul>
</li>
</ul>
<p>A more detailed post about these changes can be found <a href="https://github.com/jellyfin/Swiftfin/discussions/1832" target="_blank" rel="noopener noreferrer">on GitHub</a>!</p>
<p>- <a href="https://github.com/JPKribs" target="_blank" rel="noopener noreferrer">JPKribs</a></p>
<h3 id="other-tv-platforms">Other TV Platforms<a href="#other-tv-platforms" aria-label="Direct link to Other TV Platforms" title="Direct link to Other TV Platforms" translate="no">‚Äã</a></h3>
<ul>
<li>The Tizen app was submitted for review, but unfortunately <a href="https://github.com/jellyfin/jellyfin-tizen/issues/222#issuecomment-3621581689" target="_blank" rel="noopener noreferrer">failed testing</a>. Additional work is needed to replicate the reported issues and correct them.</li>
<li>Support for multiple <strong>new</strong> platforms is currently underway, and we will provide updates as progress is made.</li>
</ul>
<p>Wishing you all happy streaming in 2026 and beyond!
We look forward to another year filled with exciting updates and features for Jellyfin.</p>
<p>- thornbill and the Jellyfin Team</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mamdani Targets Junk Fees and Hidden Charges in Two Executive Orders (112 pts)]]></title>
            <link>https://www.nytimes.com/2026/01/05/nyregion/mamdani-affordability-consumer-protections.html</link>
            <guid>46514059</guid>
            <pubDate>Tue, 06 Jan 2026 16:02:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2026/01/05/nyregion/mamdani-affordability-consumer-protections.html">https://www.nytimes.com/2026/01/05/nyregion/mamdani-affordability-consumer-protections.html</a>, See on <a href="https://news.ycombinator.com/item?id=46514059">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2026/01/05/nyregion/mamdani-affordability-consumer-protections.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[65% of Hacker News Posts Have Negative Sentiment, and They Outperform (470 pts)]]></title>
            <link>https://philippdubach.com/standalone/hn-sentiment/</link>
            <guid>46512881</guid>
            <pubDate>Tue, 06 Jan 2026 14:45:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://philippdubach.com/standalone/hn-sentiment/">https://philippdubach.com/standalone/hn-sentiment/</a>, See on <a href="https://news.ycombinator.com/item?id=46512881">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main id="main-content" role="main"><article><div><p>Posts with negative sentiment average 35.6 points on <a href="https://news.ycombinator.com/">Hacker News</a>. The overall average is 28 points. That‚Äôs a 27% performance premium for negativity. <a href="#lightbox-hn-sentiment-png-0"><picture><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/hn-sentiment.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/hn-sentiment.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/hn-sentiment.png 640w,
https://static.philippdubach.com/cdn-cgi/image/width=960,quality=80,format=webp/hn-sentiment.png 960w,
https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/hn-sentiment.png 1200w" sizes="80vw"><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/hn-sentiment.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/hn-sentiment.png 1024w,
https://static.philippdubach.com/cdn-cgi/image/width=1440,quality=80,format=webp/hn-sentiment.png 1440w" sizes="80vw"><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/hn-sentiment.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/hn-sentiment.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/hn-sentiment.png 2000w" sizes="80vw"><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/hn-sentiment.png" alt="Distribution of sentiment scores across 32,000 Hacker News posts" width="1200" loading="lazy" decoding="async">
</picture></a><a href="#_" id="lightbox-hn-sentiment-png-0"><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/hn-sentiment.png" alt="Distribution of sentiment scores across 32,000 Hacker News posts" loading="lazy">
</a>This finding comes from an empirical study I‚Äôve been running on HN attention dynamics, covering decay curves, preferential attachment, survival probability, and early-engagement prediction. The preprint is <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5910263">available on SSRN</a>. I already had a gut feeling. Across 32,000 posts and 340,000 comments, nearly 65% register as negative. This might be a feature of my classifier being miscalibrated toward negativity; yet the pattern holds across six different models. <a href="#lightbox-sentiment_models_comparison_6models-png-1"><picture><source media="(max-width: 768px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=320,quality=80,format=webp/sentiment_models_comparison_6models.png 320w,
https://static.philippdubach.com/cdn-cgi/image/width=480,quality=80,format=webp/sentiment_models_comparison_6models.png 480w,
https://static.philippdubach.com/cdn-cgi/image/width=640,quality=80,format=webp/sentiment_models_comparison_6models.png 640w,
https://static.philippdubach.com/cdn-cgi/image/width=960,quality=80,format=webp/sentiment_models_comparison_6models.png 960w,
https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/sentiment_models_comparison_6models.png 1200w" sizes="80vw"><source media="(max-width: 1024px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=768,quality=80,format=webp/sentiment_models_comparison_6models.png 768w,
https://static.philippdubach.com/cdn-cgi/image/width=1024,quality=80,format=webp/sentiment_models_comparison_6models.png 1024w,
https://static.philippdubach.com/cdn-cgi/image/width=1440,quality=80,format=webp/sentiment_models_comparison_6models.png 1440w" sizes="80vw"><source media="(min-width: 1025px)" srcset="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80,format=webp/sentiment_models_comparison_6models.png 1200w,
https://static.philippdubach.com/cdn-cgi/image/width=1600,quality=80,format=webp/sentiment_models_comparison_6models.png 1600w,
https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=80,format=webp/sentiment_models_comparison_6models.png 2000w" sizes="80vw"><img src="https://static.philippdubach.com/cdn-cgi/image/width=1200,quality=80/sentiment_models_comparison_6models.png" alt="Sentiment distribution comparison across DistilBERT, BERT Multi, RoBERTa, Llama 3.1 8B, Mistral 3.1 24B, and Gemma 3 12B" width="1200" loading="lazy" decoding="async">
</picture></a><a href="#_" id="lightbox-sentiment_models_comparison_6models-png-1"><img src="https://static.philippdubach.com/cdn-cgi/image/width=2000,quality=90,format=webp/sentiment_models_comparison_6models.png" alt="Sentiment distribution comparison across DistilBERT, BERT Multi, RoBERTa, Llama 3.1 8B, Mistral 3.1 24B, and Gemma 3 12B" loading="lazy">
</a>I tested three transformer-based classifiers (DistilBERT, BERT Multi, RoBERTa) and three LLMs (Llama 3.1 8B, Mistral 3.1 24B, Gemma 3 12B). The distributions vary, but the negative skew persists across all of them (inverted scale for 2-6). The results I use in my dashboard are from DistilBERT because it runs efficiently in my Cloudflare-based pipeline.</p><p>What counts as ‚Äúnegative‚Äù here? Criticism of technology, skepticism toward announcements, complaints about industry practices, frustration with APIs. The usual. It‚Äôs worth noting that technical critique reads differently than personal attacks; most HN negativity is substantive rather than toxic. But, does negativity cause engagement, or does controversial content attract both negative framing and attention? Probably some of both.</p><p>I‚Äôll publish the full code, dataset, and a dashboard for the HN archiver soon and I‚Äôm happy to send you an update:</p><p>Alternatively, you can also subscribe to the <a href="https://philippdubach.com/index.xml">RSS feed</a> or get updates on <a href="https://bsky.app/profile/philippdubach.com">Bluesky</a>.</p></div></article></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[C Is Best (372 pts)]]></title>
            <link>https://sqlite.org/whyc.html</link>
            <guid>46511470</guid>
            <pubDate>Tue, 06 Jan 2026 12:33:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sqlite.org/whyc.html">https://sqlite.org/whyc.html</a>, See on <a href="https://news.ycombinator.com/item?id=46511470">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<div>
<p>
Why Is SQLite Coded In C
</p>
<details>
<summary>Table Of Contents</summary>

</details>
</div>




<h2 id="c_is_best"><span>1. </span>C Is Best</h2>

<blockquote><p>
Note: Sections 2.0 and 3.0 of this article were added in response
to comments on 
<a href="https://news.ycombinator.com/item?id=16585120">Hacker News</a> and
<a href="https://www.reddit.com/r/programming/comments/84fzoc/why_is_sqlite_coded_in_c/">Reddit</a>.
</p></blockquote>

<p>
Since its inception on 2000-05-29, SQLite has been implemented in generic C.
C was and continues to be the best language for implementing a software
library like SQLite.  There are no plans to recode SQLite in any other
programming language at this time.

</p><p>
The reasons why C is the best language to implement SQLite include:


</p><ul>
<li> Performance
</li><li> Compatibility
</li><li> Low-dependency
</li><li> Stability
</li></ul>

<h2 id="performance"><span>1.1. </span>Performance</h2>

<p>An intensively used low-level library like SQLite needs to be fast.
(And SQLite is fast, see <a href="https://sqlite.org/intern-v-extern-blob.html">Internal Versus External BLOBs</a> and
<a href="https://sqlite.org/fasterthanfs.html">35% Faster Than The Filesystem</a> for examples.)

</p><p>C is a great language for writing fast code.  C is sometimes
described as "portable assembly language".  It enables developers
to code as close to the underlying hardware as possible while still
remaining portable across platforms.

</p><p>Other programming languages sometimes claim to be "as fast as C".
But no other language claims to be faster than C for general-purpose
programming, because none are.

</p><h2 id="compatibility"><span>1.2. </span>Compatibility</h2>

<p>Nearly all systems have the ability to call libraries
written in C.  This is not true of other implementation languages.

</p><p>So, for example, Android applications written in Java are able to
invoke SQLite (through an adaptor).  Maybe it would have been more
convenient for Android if SQLite had been coded in Java as that would
make the interface simpler.  However, on iPhone applications are coded
in Objective-C or Swift, neither of which have the ability to call
libraries written in Java.  Thus, SQLite would be unusable on iPhones
had it been written in Java.

</p><h2 id="low_dependency"><span>1.3. </span>Low-Dependency</h2>

<p>Libraries written in C do not have a huge run-time dependency.
In its minimum configuration, SQLite requires only the following
routines from the standard C library:

</p><center>
<table>
<tbody><tr>
<td>
<ul>
<li> memcmp()
</li><li> memcpy()
</li><li> memmove()
</li><li> memset()
</li></ul>
</td>
<td>&nbsp;&nbsp;&nbsp;</td>
<td>
<ul>
<li> strcmp()
</li><li> strlen()
</li><li> strncmp()
</li></ul>
</td>
</tr>
</tbody></table>
</center>

<p>
In a more complete build, SQLite also uses library routines like
malloc() and free() and operating system interfaces for opening, reading,
writing, and closing files.  But even then, the number of dependencies
is very small.  Other "modern" languages, in contrast, often require
multi-megabyte runtimes loaded with thousands and thousands of interfaces.

</p><h2 id="stability"><span>1.4. </span>Stability</h2>

<p>
The C language is old and boring.
It is a well-known and well-understood language.
This is exactly what one wants when developing a module like SQLite.
Writing a small, fast, and reliable database engine is hard enough as it
is without the implementation language changing out from under you with
each update to the implementation language specification.

</p><h2 id="why_isn_t_sqlite_coded_in_an_object_oriented_language_"><span>2. </span>Why Isn't SQLite Coded In An Object-Oriented Language?</h2>

<p>
Some programmers cannot imagine developing a complex system like
SQLite in a language that is not "object oriented".  So why is
SQLite not coded in C++ or Java?

</p><ol>
<li><p>
Libraries written in C++ or Java can generally only be used by
applications written in the same language. It is difficult to
get an application written in Haskell or Java to invoke a library
written in C++.  On the other hand, libraries written in C are
callable from any programming language.

</p></li><li><p>
Object-Oriented is a design pattern, not a programming language.
You can do object-oriented programming in any language you want,
including assembly language.  Some languages (ex: C++ or Java) make
object-oriented easier.  But you can still do object-oriented programming
in languages like C.

</p></li><li><p>
Object-oriented is not the only valid design pattern.
Many programmers have been taught to think purely in terms of
objects.  And, to be fair, objects are often a good way to
decompose a problem.  But objects are not the only way, and are
not always the best way to decompose a problem.  Sometimes good old
procedural code is easier to write, easier to maintain and understand,
and faster than object-oriented code.

</p></li><li><p>
When SQLite was first being developed, Java was a young and immature
language.  C++ was older, but was undergoing such growing pains that
it was difficult to find any two C++ compilers that worked the same
way.  So C was definitely a better choice back when SQLite was first
being developed.  The situation is less stark now, but there is little
to no benefit in recoding SQLite at this point.
</p></li></ol>

<h2 id="why_isn_t_sqlite_coded_in_a_safe_language_"><span>3. </span>Why Isn't SQLite Coded In A "Safe" Language?</h2>

<p>
There has lately been a lot of interest in "safe" programming languages
like Rust or Go in which it is impossible, or is at least difficult, to make
common programming errors like memory leaks or array overruns.  So the
question often arises as to why SQLite is not coded in a "safe" language.

</p><ol>
<li><p>
None of the safe programming languages existed for the first 10 years
of SQLite's existence.  SQLite could be recoded in Go or Rust, but doing
so would probably introduce far more bugs than would be fixed, and it
may also result in slower code.

</p></li><li><p>
Safe languages insert additional machine branches to do things like
verify that array accesses are in-bounds.  In correct code, those
branches are never taken.  That means that the machine code cannot
be 100% branch tested, which is an important component of SQLite's
quality strategy.

</p></li><li><p>
Safe languages usually want to abort if they encounter an out-of-memory
(OOM) situation.  SQLite is designed to recover gracefully from an OOM.
It is unclear how this could be accomplished in the current crop of
safe languages.

</p></li><li><p>
All of the existing safe languages are new.  The developers of SQLite
applaud the efforts of computer language researchers in trying to
develop languages that are easier to program safely.  We encourage these
efforts to continue.  But we ourselves are more interested in old and
boring languages when it comes to implementing SQLite.
</p></li></ol>

<p>
All that said, it is possible that SQLite might
one day be recoded in Rust.  Recoding SQLite in Go is unlikely
since Go hates assert().  But Rust is a possibility.  Some
preconditions that must occur before SQLite is recoded in Rust
include:

</p><ol type="A">
<li> Rust needs to mature a little more, stop changing so fast, and
     move further toward being old and boring.
</li><li> Rust needs to demonstrate that it can be used to create general-purpose
     libraries that are callable from all other programming languages.
</li><li> Rust needs to demonstrate that it can produce object code that
     works on obscure embedded devices, including devices that lack
     an operating system.
</li><li> Rust needs to pick up the necessary tooling that enables one to
     do 100% branch coverage testing of the compiled binaries.
</li><li> Rust needs a mechanism to recover gracefully from OOM errors.
</li><li> Rust needs to demonstrate that it can do the kinds of work that
     C does in SQLite without a significant speed penalty.
</li></ol>

<p>
If you are a "rustacean" and feel that Rust already meets the
preconditions listed above, and that SQLite should be recoded in
Rust, then you are welcomed and encouraged
to contact the SQLite developers privately
and argue your case.
</p><p><small><i>This page was last updated on 2025-05-09 15:56:17Z </i></small></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Prism.Tools ‚Äì Free and privacy-focused developer utilities (341 pts)]]></title>
            <link>https://blgardner.github.io/prism.tools/</link>
            <guid>46511469</guid>
            <pubDate>Tue, 06 Jan 2026 12:33:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blgardner.github.io/prism.tools/">https://blgardner.github.io/prism.tools/</a>, See on <a href="https://news.ycombinator.com/item?id=46511469">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <h2>Every Dev Tool You Need</h2>
    <p>Fast. Private. Free forever.</p>
    <p>üîí Data never leaves your browser</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AWS raises GPU prices 15% on a Saturday, hopes you weren't paying attention (674 pts)]]></title>
            <link>https://www.theregister.com/2026/01/05/aws_price_increase/</link>
            <guid>46511153</guid>
            <pubDate>Tue, 06 Jan 2026 11:42:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2026/01/05/aws_price_increase/">https://www.theregister.com/2026/01/05/aws_price_increase/</a>, See on <a href="https://news.ycombinator.com/item?id=46511153">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>I've been tracking <a target="_blank" href="https://www.lastweekinaws.com/" rel="nofollow">AWS</a> for a long time, with a specific emphasis on pricing. "What happens if AWS hikes prices" has always been something of a boogeyman, trotted out as a hypothetical to urge folks to avoid taking dependencies on a given provider.</p>
<p>Over the weekend - on a Saturday, no less - that hypothetical became real.</p>
<p>AWS has <a target="_blank" href="https://aws.amazon.com/ec2/capacityblocks/pricing/" rel="nofollow">quietly raised prices</a> on its EC2 Capacity Blocks for ML by approximately 15 percent. The p5e.48xlarge instance ‚Äì eight NVIDIA H200 accelerators in a trenchcoat ‚Äì jumped from $34.61 to $39.80 per hour across most regions, while the p5en.48xlarge climbed from $36.18 to $41.61. Customers in US West (N. California) face steeper hikes, with p5e rates rising from $43.26 to $49.75. The change had been telegraphed: AWS's pricing page noted (and bizarrely, still does) that "current prices are scheduled to be updated in January, 2026," though the company neglected to mention which direction.</p>

    

<p>This comes about seven months after AWS trumpeted "up to 45% price reductions" for GPU instances - though that announcement covered On-Demand and Savings Plans rather than Capacity Blocks. Funny how that works.</p>

        


        

<p>For the uninitiated, Capacity Blocks are AWS's answer to "I need guaranteed GPU capacity for my ML training job next Tuesday." You reserve specific GPU instances for a defined time window ‚Äì anywhere from a day to a few weeks out ‚Äì and pay up front at a locked-in rate. It's popular with companies doing serious ML work who can't afford to have a training run interrupted because spot capacity evaporated. The pricing should make it abundantly clear that the people using this aren't hobbyists; these are teams with budgets measured in millions.</p>
<p>An Amazon spox told us via email, "EC2 Capacity Blocks for ML pricing vary based on supply and demand patterns, as described on the product detail page. This price adjustment reflects the supply/demand patterns we expect this quarter."</p>

        

<p>To be clear, AWS has raised prices before, but rarely as a straight increase to a line item. The company prefers to change pricing dimensions entirely, often <a target="_blank" href="https://aws.amazon.com/blogs/aws/new-updated-pay-per-use-pricing-model-for-aws-config-rules/" rel="nofollow">spinning this as a price reduction for most customers</a> ‚Äì a claim I'd characterize as "creative." Historical straight-up price increases have been tied to regulatory actions: per-SMS charges in certain markets and the like. This is different.</p>
<p>The timing is curious for another reason: it hands Azure and GCP a talking point on a silver platter. Both have been aggressively courting ML workloads, and "AWS just raised GPU prices 15%" is exactly the kind of ammunition enterprise sales teams dream about. Whether the competitors can actually absorb the demand is another question ‚Äì GPU constraints are hardly unique to AWS ‚Äì but perception matters in enterprise deals.</p>
<p>For companies with Enterprise Discount Programs or other negotiated agreements, this raises uncomfortable questions. EDPs typically guarantee discounts off public pricing ‚Äì so if public pricing goes up 15 percent, your "discounted" rate just got more expensive in absolute terms, even if the percentage held steady. I expect some pointed conversations between AWS account teams and their larger customers in the coming weeks.</p>
<h3>Why are they doing this?</h3>
<p>It's hard not to see this as a bellwether. GPUs are increasingly constrained globally as the world pivots to generating slop-as-a-service in every conceivable domain. The question is what this means for other resource types down the road. Does the <a target="_blank" href="https://www.theregister.com/2025/12/16/smartphones_memory_ai/">global RAM crunch</a> mean RAM-centric services are next? You can ignore ML Capacity Block pricing if you're not running machine learning workloads ‚Äì which describes north of 95 percent of most companies' cloud spend ‚Äì but RAM touches every service AWS offers. Well, possibly excepting their support function, though that's <a target="_blank" href="https://aws.amazon.com/blogs/aws/new-and-enhanced-aws-support-plans-add-ai-capabilities-to-expert-guidance/" rel="nofollow">rapidly becoming "AI-Powered"</a> too, so give it time.</p>
<ul>

<li><a href="https://www.theregister.com/2025/11/04/aws_genz_misery_nope/">Deploying to Amazon's cloud is a pain in the AWS younger devs won't tolerate</a></li>

<li><a href="https://www.theregister.com/2025/12/24/aws_storage_gateway_nutanix_ahv/">AWS adds hybrid cloud storage support for Nutanix's AHV hypervisor</a></li>

<li><a href="https://www.theregister.com/2025/12/17/jassy_taps_peter_desantis_to_run_agi/">Jassy taps 27-year Amazon veteran to run AGI org, which is now definitely a thing that exists</a></li>

<li><a href="https://www.theregister.com/2025/12/16/smartphones_memory_ai/">Smartphones face a memory cost crunch ‚Äì and buyers aren't in the mood</a></li>
</ul>
<p>The canary-in-the-coal-mine concern here isn't GPUs specifically, but rather the precedent it establishes. AWS has spent two decades conditioning customers to expect prices only ever go down. That expectation is now broken. Once you've raised prices on one service and the world doesn't end, the second increase becomes easier. And the third. The playbook has changed.</p>
<p>Keep an eye on services where AWS faces genuine supply constraints or where their costs have materially increased. Graviton instances have been priced aggressively to drive adoption ‚Äì what happens when ARM chip supply tightens? Data transfer costs have been a cash cow for years, but they've also been stable; are those next? I don't have inside information, but I do have pattern recognition, and the pattern just shifted.</p>

        

<p>AWS has long benefited from the assumption that cloud pricing only trends in one direction. That assumption died on a Saturday in January, with all the fanfare of a Terms of Service update. The question isn't whether this matters ‚Äì it does. The question is whether it's an anomaly or the new normal. My money's on the latter. ¬Æ</p>                                
                    </div></div>]]></description>
        </item>
    </channel>
</rss>