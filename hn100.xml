<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 20 Jun 2025 21:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[EU Eyes Ditching Microsoft Azure for France's OVHcloud (224 pts)]]></title>
            <link>https://www.euractiv.com/section/tech/news/scoop-commission-eyes-ditching-microsoft-azure-for-frances-ovhcloud-over-digital-sovereignty-fears/</link>
            <guid>44331045</guid>
            <pubDate>Fri, 20 Jun 2025 19:20:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.euractiv.com/section/tech/news/scoop-commission-eyes-ditching-microsoft-azure-for-frances-ovhcloud-over-digital-sovereignty-fears/">https://www.euractiv.com/section/tech/news/scoop-commission-eyes-ditching-microsoft-azure-for-frances-ovhcloud-over-digital-sovereignty-fears/</a>, See on <a href="https://news.ycombinator.com/item?id=44331045">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="metered-article"><p>
<strong>The European Commission is in advanced business negotiations with OVHcloud, the France-based major European cloud service provider, to transition its cloud services away from Microsoft, according to three senior sources with internal knowledge of the matter who spoke to Euractiv on condition of anonymity.</strong>
</p>
<p>
The infrastructure shift is being driven by a push for European digital sovereignty in the cloud market, following <a href="https://www.euractiv.com/section/tech/news/microsofts-email-shutdown-of-icc-prosecutor-fuels-eu-fears-of-us-tech-blackmail/" target="_blank" rel="noopener">concerns raised</a> by a US executive order that led to the shutdown of Microsoft services for an employee of a European-based institution.
</p>
<p>
The goal of the move would be to ensure that European institutions have greater control over their digital infrastructure and data ‚Äì an idea that has been championed by the <a href="https://www.euractiv.com/section/tech/news/european-industry-big-win-germany-france-both-support-sovereign-eu-based-tech-infrastructure/" target="_blank" rel="noopener">EuroStack initiative</a>. It is also a blow for US tech behemoth Microsoft, which has been striving to reassure its European customers in the past weeks.
</p>
<p>
Once the European Commission "gets its house into order," it is expected to set a precedent for national public administrations to direct public procurement funds towards homegrown cloud providers, one source said. The Commission sees itself as a trend setter, they added, aligning with its broader strategy to enhance the EU's digital autonomy and reduce reliance on non-European tech giants.
</p>
<p>
We understand the Commission has been in discussions with OVHcloud for several weeks. However, an unknown number of other European cloud providers, including Germany's IONOS, France's Scaleway and Italy's Aruba, are also being considered as potential alternatives.
</p>
<p>
A unique aspect of this situation is that, for the first time, the two key digital departments of the Commission ‚Äì DG CNECT, which drafts and enforces digital policies, and DG DIGIT, the IT department ‚Äì are under the oversight of a single Commissioner (Henna Virkkunen) with a tech sovereignty portfolio.
</p>
<p>
This consolidation has made it easier to harmonise the political and technical priorities of the European executive, our sources told us.
</p>
<p>
"Discussions are indeed underway, both with the Commission and with other public and private institutions and organisations that are evaluating projects to migrate to a sovereign cloud," an OVHcloud spokesperson told Euractiv when we sought comment.
</p>
<p>
The Commission is "constantly scanning the market" and already "has a contract with OVHcloud" a Commission spokesperson said in response to Euractiv's request for comment. It did not confirm whether the Commission will actually switch away from Microsoft Azure.
</p>
<p>
In January, Euractiv <a href="https://www.euractiv.com/section/tech/news/internal-documents-reveal-commission-fears-over-microsoft-dependency/" target="_blank" rel="noopener">revealed</a>&nbsp;that the Commission was concerned about its reliance on Microsoft, quoting internal documents.
</p>
<p>
Additionally, the EU institutions watchdog, the European Data Protection Supervisor <a href="https://www.euractiv.com/section/tech/news/eu-commission-breached-data-protection-rules-using-microsoft-365-eu-watchdog-found/" target="_blank" rel="noopener">found</a> last year that the EU's executive is in breach of data protection rules that apply to EU institutions over its use of Microsoft Azure cloud for some of its data.
</p>
<p>
(nl)
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Nxtscape ‚Äì an open-source agentic browser (145 pts)]]></title>
            <link>https://github.com/nxtscape/nxtscape</link>
            <guid>44329457</guid>
            <pubDate>Fri, 20 Jun 2025 16:35:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/nxtscape/nxtscape">https://github.com/nxtscape/nxtscape</a>, See on <a href="https://news.ycombinator.com/item?id=44329457">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto">
<p dir="auto"><h2 tabindex="-1" dir="auto">The Open-source Agentic Browser.</h2><a id="user-content-the-open-source-agentic-browser" aria-label="Permalink: The Open-source Agentic Browser." href="#the-open-source-agentic-browser"></a></p>
<p dir="auto">Nxtscape ("next-scape") is an open-source <strong>agentic browser</strong> ‚Äì your privacy-first alternative to closed-source browsers (like Arc, Dia, Perplexity Comet). Built on Chromium, Nxtscape lets you run <strong>Manus like agents</strong> locally and boost your productivity with an AI-sidekick.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">
<math-renderer data-run-id="7f5aaa6317692970f89d02d2cb8f175f">$${\color{red}Download}$$</math-renderer> <a href="https://bit.ly/4k0gjsD" rel="nofollow">link</a> for macOS</h3><a id="user-content-colorreddownload-link-for-macos" aria-label="Permalink: $${\color{red}Download}$$ link for macOS" href="#colorreddownload-link-for-macos"></a></p>
<p dir="auto">We'd love to hear what problems you'd like to see solved! Share your ideas through our <a href="https://dub.sh/nxtscape-feature-request" rel="nofollow">anonymous form</a>.</p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto"><strong>Looks like Chrome, but with AI superpowers.</strong></h2><a id="user-content-looks-like-chrome-but-with-ai-superpowers" aria-label="Permalink: Looks like Chrome, but with AI superpowers." href="#looks-like-chrome-but-with-ai-superpowers"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/nxtscape/nxtscape/blob/main/resources/example-use-cases.png"><img src="https://github.com/nxtscape/nxtscape/raw/main/resources/example-use-cases.png" alt="example-use-cases" width="100%"></a>
</p>
<p dir="auto">We believe the future is AI agents automating your work, and we want to be the <strong><em>open source browser</em></strong> that can do it <strong><em>locally and securely</em></strong> instead of sending your data to a search or ad company.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">The Vision: A Browser That Works For You üí°</h2><a id="user-content-the-vision-a-browser-that-works-for-you-" aria-label="Permalink: The Vision: A Browser That Works For You üí°" href="#the-vision-a-browser-that-works-for-you-"></a></p>
<p dir="auto">For the first time since Netscape in 1994, it feels like we can reimagine browsers from scratch. The browser of tomorrow might not look like what we have today! That's why we're building Nxtscape - an open-source, agentic browser for the next era.</p>
<p dir="auto">We saw how tools like Cursor gave developers a 10x productivity boost, yet the browser‚Äîwhere we spend our entire day‚Äîfeels stuck and we're constantly fighting it. I constantly have 70+ tabs open and lose track of them. Can't AI help group or close them? Simple workflows, like "order Tide Pods from my Amazon order history," should just work with agents right now. And form-filling is another huge pain that AI should be able to solve.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features üéÅ</h2><a id="user-content-features-" aria-label="Permalink: Features üéÅ" href="#features-"></a></p>
<ul dir="auto">
<li>üè† Feels like home - works with all your Chrome extensions</li>
<li>ü§ñ AI agents that run on YOUR browser, not in the cloud</li>
<li>üîí Privacy first - bring your own keys or use local models with Ollama. Your browsing history stays on your computer</li>
<li>üöÄ Open source and community driven - see exactly what's happening under the hood</li>
<li>ü§ù (coming soon) MCP store to one-click install popular MCPs and use them directly in the browser bar</li>
<li>üõ°Ô∏è (coming soon) Built-in AI ad blocker that works across more scenarios!</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demos</h2><a id="user-content-demos" aria-label="Permalink: Demos" href="#demos"></a></p>
<div dir="auto">
<p dir="auto"><h3 tabindex="-1" dir="auto">ü§ñ AI Agents in Action (<a href="https://storage.googleapis.com/felafax-public/nxtscape/nxtscape-agent.mp4" rel="nofollow">video</a>)</h3><a id="user-content--ai-agents-in-action-video" aria-label="Permalink: ü§ñ AI Agents in Action (video)" href="#-ai-agents-in-action-video"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/nxtscape/nxtscape/blob/main/resources/nxtscape-agent.gif"><img src="https://github.com/nxtscape/nxtscape/raw/main/resources/nxtscape-agent.gif" alt="AI Agents in Action" width="80%" data-animated-image=""></a></p><p dir="auto"><h3 tabindex="-1" dir="auto">üí¨ Local AI Chat (<a href="https://storage.googleapis.com/felafax-public/nxtscape/nxtscape-chat.mp4" rel="nofollow">video</a>)</h3><a id="user-content--local-ai-chat-video" aria-label="Permalink: üí¨ Local AI Chat (video)" href="#-local-ai-chat-video"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/nxtscape/nxtscape/blob/main/resources/nxtscape-chat.gif"><img src="https://github.com/nxtscape/nxtscape/raw/main/resources/nxtscape-chat.gif" alt="Local AI Chat" width="80%" data-animated-image=""></a></p><p dir="auto"><h3 tabindex="-1" dir="auto">‚ö° Productivity (<a href="https://storage.googleapis.com/felafax-public/nxtscape/nxtscape-productivity.mp4" rel="nofollow">video</a>)</h3><a id="user-content--productivity-video" aria-label="Permalink: ‚ö° Productivity (video)" href="#-productivity-video"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/nxtscape/nxtscape/blob/main/resources/nxtscape-productivity.gif"><img src="https://github.com/nxtscape/nxtscape/raw/main/resources/nxtscape-productivity.gif" alt="Productivity" width="80%" data-animated-image=""></a>
</p></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Get Involved! üôå</h2><a id="user-content-get-involved-" aria-label="Permalink: Get Involved! üôå" href="#get-involved-"></a></p>
<p dir="auto">Nxtscape is open source! We believe in building <em>with</em> our community. Let us know what features you want!</p>
<ul dir="auto">
<li>üí¨  Join our <a href="https://discord.gg/YKwjt5vuKr" rel="nofollow">Discord</a></li>
<li>üê¶  Follow us on <a href="https://twitter.com/nxtscape" rel="nofollow">Twitter/X</a></li>
<li>üó∫Ô∏è  Roadmap: <a href="https://nxtscape.feedbear.com/roadmap" rel="nofollow">link</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">‚ú® What Makes Nxtscape Different?</h2><a id="user-content--what-makes-nxtscape-different" aria-label="Permalink: ‚ú® What Makes Nxtscape Different?" href="#-what-makes-nxtscape-different"></a></p>
<p dir="auto">We know there are other browsers. Here's why Nxtscape stands out:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Nxtscape vs Chrome</h3><a id="user-content-nxtscape-vs-chrome" aria-label="Permalink: Nxtscape vs Chrome" href="#nxtscape-vs-chrome"></a></p>
<p dir="auto">While we're grateful for Google open-sourcing Chromium, the Chrome browser hasn't evolved much over the last 10 years and it lacks meaningful AI features (agentic automation, MCP support, ...).</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Nxtscape vs Brave</h3><a id="user-content-nxtscape-vs-brave" aria-label="Permalink: Nxtscape vs Brave" href="#nxtscape-vs-brave"></a></p>
<p dir="auto">We love what Brave started, but they've spread themselves too thin with crypto, search, VPNs, and other projects. Nxtscape is <strong>laser-focused</strong> on building the best <strong>AI-powered, productivity-focused, private browser</strong>. We want to bring you latest AI features sooner, like <strong>agentic automation and integrating MCP!</strong></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Nxtscape vs Arc/Dia</h3><a id="user-content-nxtscape-vs-arcdia" aria-label="Permalink: Nxtscape vs Arc/Dia" href="#nxtscape-vs-arcdia"></a></p>
<p dir="auto">Many loved Arc, but it was closed source. When the company abandoned it, users were left behind. That <strong>will never happen</strong> with Nxtscape. We are <strong>100% open source</strong>. If you don't like the direction we're going, you or the community can fork the code and build your own version. Power to the people!</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Nxtscape vs Perplexity Comet</h3><a id="user-content-nxtscape-vs-perplexity-comet" aria-label="Permalink: Nxtscape vs Perplexity Comet" href="#nxtscape-vs-perplexity-comet"></a></p>
<p dir="auto">Perplexity is a search company. Your browser history will likely be used for ad targeting eventually. We are <strong>NOT</strong> a search company. If you're switching from Chrome, choose a truly privacy-first browser instead of another data collector. Choose Nxtscape.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgments üôè</h2><a id="user-content-acknowledgments-" aria-label="Permalink: Acknowledgments üôè" href="#acknowledgments-"></a></p>
<p dir="auto">Nxtscape is inspired by these amazing open-source projects: <a href="https://github.com/browser-use/browser-use">browser-use</a>, <a href="https://github.com/nanobrowser/nanobrowser">Nanobrowser</a>, and <a href="https://github.com/browserbase/stagehand">Stagehand</a> and of course wouldn't have been possible without <a href="https://github.com/chromium/chromium">Chromium</a>. Grateful to the open-source community!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License üìú</h2><a id="user-content-license-" aria-label="Permalink: License üìú" href="#license-"></a></p>
<p dir="auto">Nxtscape is licensed under AGPL-3.0 license. See the <code>LICENSE</code> file for details.</p>
<div dir="auto">

<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/nxtscape/nxtscape/blob/main/resources/backed-by-yc.png"><img src="https://github.com/nxtscape/nxtscape/raw/main/resources/backed-by-yc.png" alt="backed-by-yc" width="20%"></a>
</p></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rolling the ladder up behind us (118 pts)]]></title>
            <link>https://xeiaso.net/blog/2025/rolling-ladder-behind-us/</link>
            <guid>44328894</guid>
            <pubDate>Fri, 20 Jun 2025 15:51:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xeiaso.net/blog/2025/rolling-ladder-behind-us/">https://xeiaso.net/blog/2025/rolling-ladder-behind-us/</a>, See on <a href="https://news.ycombinator.com/item?id=44328894">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article>
    
    

    <div>
            <p>
                Published on <time datetime="2025-06-20">2025-06-20</time>, 5674 words, 21 minutes to read
            </p>

            
                <p>Who will take over for us if we don't train the next generation to replace us? A critique of craft, AI, and the legacy of human expertise.
</p>
            
        </div>

    
        
            
    

    

        
    

    
        <center>
            <figure><picture><source type="image/avif" srcset="https://files.xeiaso.net/hero/summer-walk.avif"><source type="image/webp" srcset="https://files.xeiaso.net/hero/summer-walk.webp"><img alt="An image of A picture of two patches of wild grass bifurcated by a retaining pond." loading="lazy" src="https://files.xeiaso.net/hero/summer-walk.jpg"></picture></figure>
        </center>
        <small>A picture of two patches of wild grass bifurcated by a retaining pond. - Photo by Xe Iaso, Canon EOS R6 Mark 2, unknown lens</small>
    

    <p>Cloth is one of the most important goods a society can produce. Clothing is instrumental for culture, expression, and for protecting one's modesty. Historically, cloth was one of the most expensive items on the market. People bought one or two outfits at most and then wore them repeatedly for the rest of their lives. Clothing was treasured and passed down between generations the same way we pass jewelry down between generations. This cloth was made in factories by highly skilled weavers. These weavers had done the equivalent of PhD studies in weaving cloth and used state of the art hardware to do it.</p>
<p>As factories started to emerge, they were able to make cloth so much more cheaply than skilled weavers ever could thanks to inventions like the power loom. Power looms didn't require skilled workers operating them. You could even staff them with war orphans, which there was an abundance of thanks to all the wars. The quality of the cloth was absolutely terrible in comparison, but there was so much more of it made so much more quickly. This allowed the price of cloth to plummet, meaning that the wages that the artisans made fell from six shillings a day to six shillings per week over a period of time where the price of food doubled.</p>
<p>Mind you, the weavers didn't just reject technological progress for the sake of rejecting it. They tried to work with the ownership class and their power looms in order to produce the same cloth faster and cheaper than they had before. For a time, it did work out, but the powers that be didn't want that. They wanted more money at any cost.</p>
<p>At some point, someone had enough and decided to do something about it. Taking up the name Ned, he led a movement that resulted in riots, destroying factory equipment, and some got so bad they had to call the army in to break them up. Townspeople local to those factory towns were in full support of Ned's followers. Heck, even the soldiers sent to stop the riots ended up seeing the points behind what Ned's followers were doing and joined in themselves.</p>
<p>The ownership class destroyed the livelihood of the skilled workers so that they could make untold sums of money producing terrible cloth that people would turn their one-time purchase of clothing into a de-facto subscription that they had to renew every time their clothing wore out. Now we have fast fashion and don't expect our clothing to last more than a few years. I have a hoodie from AWS Re:Invent in 2022 that I'm going to have to throw out and replace because the sleeves are dying.</p>
<p>We only remember them as riots because their actions affected those in power. This movement was known as the Luddites, or the followers of Ned Ludd. The word "luddite" has since shifted meaning over time and is now understood as "someone who is against technological development". The Luddites were not against technology like the propaganda from the ownership class would have you expect, they fought against how it was implemented and the consequences of its rollout. They were skeptical that the shitty cloth that the power loom produced would be a net benefit to society because it meant that customers would inevitably have to buy their clothes over and over again, turning a one-time purchase into a subscription. Would that really benefit consumers or would that really benefit the owners of the factories?</p>
<p>Nowadays the Heritage Crafts Association of the United Kingdom lists many forms of weaving as <a href="https://www.heritagecrafts.org.uk/categories-of-risk/">Endangered or Critically Endangered crafts</a>, meaning that those skills are either at critical risk of dying out without any "fresh blood" learning how to do it, or the last generation of artisans that know how to do that craft are no longer teaching new apprentices. All that remains of that expertise is now contained in the R&amp;D departments of the companies that produce the next generations of power looms, and whatever heritage crafts practitioners remain.</p>
<p>Remember the Apollo program that let us travel to the moon? It was mostly powered by the Rocketdyne F1 engine. We have all of the technical specifications to build that rocket engine. We know all the parts you need, all the machining you have to do, and roughly understand how it would be done, but <a href="https://youtu.be/ovD0aLdRUs0">we can't build another Rocketdyne F1</a> because all of the finesse that had been built up around manufacturing it no longer exists. Society has moved on and we don't have expertise in the tools that they used to make it happen.</p>
<p>What are we losing in the process? We won't know until it's gone.</p>
<h2>We're going to run out of people with the word "Senior" in their title</h2>
<p>As I've worked through my career in computering, I've noticed a paradox that's made me uneasy and I haven't really been able to figure out why it keeps showing up: the industry only ever seems to want to hire people with the word Senior in their title. They almost never want to create people with the word Senior in their title. This is kinda concerning for me. People get old and no longer want to or are able to work. People get sick and become disabled. Accidental deaths happen and remove people from the workforce.</p>
<figure><a href="https://files.xeiaso.net/blog/2025/rolling-ladder-behind-us/dog-meme.jpg"><picture><source type="image/avif" srcset="https://files.xeiaso.net/blog/2025/rolling-ladder-behind-us/dog-meme.avif"><source type="image/webp" srcset="https://files.xeiaso.net/blog/2025/rolling-ladder-behind-us/dog-meme.webp"><img alt="A meme based on the format where the dog wants to fetch the ball but doesn't want to give the ball to the human to throw it, but with the text saying 'Senior?', 'Train Junior?', and 'No train junior, only hire senior'." loading="lazy" src="https://files.xeiaso.net/blog/2025/rolling-ladder-behind-us/dog-meme.jpg"></picture></a><figcaption>A meme based on the format where the dog wants to fetch the ball but doesn't want to give the ball to the human to throw it, but with the text saying 'Senior?', 'Train Junior?', and 'No train junior, only hire senior'.</figcaption></figure>
<p>If the industry at large isn't actively creating more people with the word Senior in their title, we are eventually going to run out of them. This is something that I want to address with Techaro at some point, but I'm not sure how to do that yet. I'll figure it out eventually. The non-conspiratorial angle for why this is happening is that money isn't free anymore and R&amp;D salaries are no longer taxable business expenses in the US, so software jobs that don't "produce significant value" are more risky to the company. So of course they'd steal from the future to save today. Sounds familiar, doesn't it?</p>
<div><p><img alt="Cadey is coffee" loading="lazy" src="https://stickers.xeiaso.net/sticker/cadey/coffee"></p><div><p><span><a href="https://xeiaso.net/characters#cadey">Cadey</a></span><span></span></p><p>Is this how we end up losing the craft of making high quality code the same
way we lost the craft of weaving high quality cloth?</p></div></div>
<p>However there's another big trend in the industry that concerns me: companies releasing products that replace expertise with generative AI agents that just inscrutably do the thing for you. This started out innocently enough - it was just better ways to fill in the blanks in your code. But this has ballooned and developed from better autocomplete to the point where you can <a href="https://github.com/orgs/community/discussions/159068">just assign issues to GitHub Copilot</a> and have the issue magically get solved for you in a pull request. Ask the AI model for an essay and get a passable result in 15 minutes.</p>
<p>At some level, this is really cool. Like, think about it. This reduces toil and drudgery to waiting for half an hour at most. In a better world I would really enjoy having a tool like this to help deal with the toil work that I need to do but don't really have the energy to. Do you know how many more of these essays would get finished if I could offload some of the drudgery of my writing process to a machine?</p>
<p>We are not in such a better world. We are in a world where I get transphobic hate sent to the Techaro sales email. We are in a world where people like me are intentionally not making a lot of noise so that we can slide under the radar and avoid attention by those that would seek to destroy us. We are in a world where these AI tools are being pitched as the <a href="https://www.salesforce.com/news/stories/agentic-ai-reshapes-workforce/">next Industrial Revolution</a>, one where foisting our expertise away into language models is somehow being framed as a good thing for society.</p>
<p>There's just one small problem: who is going to be paid and reap the benefits from this change as expectations from the ownership class change? A lot of the ownership class only really experiences the work product outputs of what we do with computers. They don't know the struggles involved with designing things such as <a href="https://youtu.be/y8OnoxKotPQ">the user getting an email on their birthday</a>. They don't want to get pushback on things being difficult or to hear that people want to improve the quality of the code. They want their sparkle emoji buttons to magically make the line go up and they want them yesterday.</p>
<p>We deserve products that aren't cheaply made mass produced slop that incidentally does what people want instead of high quality products that are crafted to be exactly what people need, even if they don't know they need it.</p>
<p>Additionally, if this is such a transformational technology, why are key figures promoting it by talking down to people? Why wouldn't they be using this to <em>lift people up</em>?</p>
<div><div><p><img alt="Aoi is wut" loading="lazy" src="https://stickers.xeiaso.net/sticker/aoi/wut"></p><div><p><span><a href="https://xeiaso.net/characters#aoi">Aoi</a></span><span></span></p><p>Isn't that marketing? <a href="https://www.google.com/url?q=https://www.latimes.com/business/technology/story/2023-03-31/column-afraid-of-ai-the-startups-selling-it-want-you-to-be&amp;sa=D&amp;source=docs&amp;ust=1750357127980877&amp;usg=AOvVaw2edAVveALA3bLpVpR_c8an">Fear
sells</a>
a lot better than hope ever will. Amygdala responses are pretty strong
right? So aren't a lot of your fears of the technology really feeding into
the hype and promoting the technology by accident?</p></div></div><div><p><img alt="Cadey is coffee" loading="lazy" src="https://stickers.xeiaso.net/sticker/cadey/coffee"></p><div><p><span><a href="https://xeiaso.net/characters#cadey">Cadey</a></span><span></span></p><p>I don't fear the power loom. I fear the profit expectations of the factory
owners.</p></div></div></div>
<h2>Vibe coding is payday loans for technical debt</h2>
<p>As a technical educator, one of the things that I want to imprint onto people is that programming is a skill you can gain and that you too can both program things and learn how to program things. I want there to be more programmers out there. What I am about to say is not an attempt to gatekeep the skill and craft of computering; however, the ways that proponents of vibe coding are going about it are simply not the way forward to a sustainable future.</p>
<p>About a year ago, Cognition teased an AI product named <a href="https://devin.ai/">Devin</a>, a completely automated software engineer. You'd assign Devin tasks in Slack or Jira and then it would spin up a VM and plod its way through fixing whatever you asked it to. This demo deeply terrified me, as it was nearly identical to a story I wrote for the Techaro lore: <a href="https://xeiaso.net/blog/protos/">Protos</a>. The original source of that satire was experience working at a larger company that shall remain unnamed where the product team seemed to operate under the assumption that the development team had a secret "just implement that feature button" and that we as developers were working to go out of our way to <strong>NOT</strong> push it.</p>
<p>Devin was that "implement that feature" button the same way Protos mythically did. From what I've seen with companies that actually use Devin, it's nowhere near actually being useful and usually needs a lot of hand-holding to do anything remotely complicated, thank God.</p>
<p>The thing that really makes me worried is that the ownership class' expectations about the process of developing software are changing. People are being put on PIPs for not wanting to install Copilot. Deadlines come faster because <a href="https://www.reddit.com/r/ExperiencedDevs/comments/1kchah5/they_finally_started_tracking_our_usage_of_ai/">"the AI can write the code for you, right?"</a> Twitter and Reddit contain myriads of stories of "idea guys" using Cursor or Windscribe to generate their dream app's backend and then making posts like "some users claim they can see other people's stuff, what kind of developer do I need to hire for this?" Follow-up posts include gems such as "lol why do coders charge so much???"</p>
<p>By saving money in the short term by producing shitty software that doesn't last, are we actually spending more money over time re-buying nearly identical software after it evaporates from light use? This is the kind of thing that makes Canada not allow us to self-identify as Engineers, and I can't agree with their point more.</p>
<h3>Vibe Coding is just fancy UX</h3>
<p>Vibe coding is a distraction. It's a meme. It will come. It will go. Everyone will abandon the vibe coding tools eventually. My guess is that a lot of the startups propping up their vibe coding tools are trying to get people into monthly subscriptions as soon as possible so that they can mine passive income as their more casual users slowly give up on coding and just forget about the subscription.</p>
<p>I'm not gonna lie though, the UX of vibe coding tools is top-notch. From a design standpoint it's aiming for that subtle brilliance where it seems to read your mind and then fill in the blanks you didn't even know you needed filled in. This is a huge part of how you can avoid the terror of the empty canvas. If you know what you are doing, an empty canvas represents infinite possibilities. There's nothing there to limit you from being able to do it. You have total power to shape everything.</p>
<p>In my opinion, this is a really effective tool to help you get past that fear of having no ground to stand on. This helps you get past executive dysfunction and just ship things already. That part is a good thing. I genuinely want people to create more things with technology that are focused on the problems that they have. This is the core of how you learn to do new things. You solve small problems that can be applied to bigger circumstances. You gradually increase the scope of the problem as you solve individual parts of it.</p>
<p>I want more people to be able to do software development. I think that it's a travesty that we don't have basic computer literacy classes in every stage of education so that people know how the machines <strong>that control their lives</strong> work and how to use them to their advantage. Sure it's not as dopaminergic as TikTok or other social media apps, but there's a unique sense of victory that you get when things just work. Sometimes that feeling you get when things Just Work‚Ñ¢ is the main thing that keeps me going. Especially in anno dominium two thousand and twenty five.</p>
<p>The main thing I'm afraid of is people becoming addicted to the vibe coding tools and letting their innate programming skills atrophy. I don't know how to suggest people combat this. I've been combating it by removing all of the automatic AI assistance from my editor (IE: I'll use a language server, but I won't have my editor do fill-in-the-middle autocomplete for me), but this isn't something that works for everyone. I've found myself more productive without it there and asking <a href="https://chatgpt.com/share/685430cf-79ec-800c-9ea2-251301066f3d">a model for the missing square peg to round hole</a> when I inevitably need some toil code made. I ended up not shipping that due to other requirements, but you get what I'm going at.</p>
<h3>The "S" in MCP stands for Security</h3>
<p>The biggest arguments I have against vibe coding and all of the tools behind it boil down to one major point: these tools have a security <a href="https://www.biblegateway.com/passage/?search=matthew%207:24-27&amp;version=NIV">foundation of sand</a>. Most of the time when you install and configure a <a href="https://modelcontextprotocol.io/introduction">Model Context Protocol (MCP)</a> server, you add some information to a JSON file that your editor uses to know what tools it can dispatch with all of your configuration and API tokens. These MCP servers run as normal OS processes with absolutely no limit to what they can do. They can easily delete all files on your system, install malware into your autostart, or exfiltrate all your secrets without any oversight.</p>
<p>Oh, by the way, that whole "it's all in one JSON file with all your secrets" problem? That's now seen as a load-bearing feature so that scripts can automatically install MCP servers for you. You don't even need to get expertise in how the tools work! There's a MCP server installer MCP server so that you can say "Hey torment nexus, install GitHub integration for me please" and then it'll just do it with no human oversight or review on what you're actually installing. Seems safe to me! What could possibly go wrong?</p>
<p>If this is seriously the future of our industry, I wish that the people involved would take one trillionth of an iota of care about the security of the implementation. This is the poster child for something like the <a href="https://component-model.bytecodealliance.org/">WebAssembly Component Model</a>. This would let you define your MCP servers with strongly typed interfaces to the outside world that can be granted or denied permissions by users with strong capabilities. Combined with the concept of <a href="https://modelcontextprotocol.io/specification/2025-06-18/server/resources">server resources</a>, this could let you expand functionality however you wanted. Running in WebAssembly means that the no MCP server can just read <code>~/.ssh/id_ed25519</code> and exfiltrate your SSH key. Running in WebAssembly means that it can't just connect to <code>probably-not-malware.lol</code> and then evaluate JavaScript code with user-level permissions on the fly. We shouldn't have to be telling developers "oh just run it all in Docker". We should have designed this to be fundamentally secure from the get-go. Personally, I only run MCP ecosystem things when contractually required to. Even then, I run it in a virtual machine that I've already marked as known compromised and use separate credentials not tied to me. Do with this information as you will.</p>
<p>I had a lot of respect for Anthropic before they released this feculent bile that is the Model Context Protocol spec and initial implementations to the public. It just feels so half-baked and barely functional. Sure I don't think they expected it to become the Next Big Meme‚Ñ¢, but I thought they were trying to do things ethically above board. Everything I had seen from Anthropic before had such a high level of craft and quality, and this was such a huge standout.</p>
<p>We shouldn't have to be placing fundamental concerns like secret management or sandboxing as hand-waves to be done opt-in by the user. They're not gonna do it, and we're going to have <a href="https://forum.cursor.com/t/cursor-yolo-deleted-everything-in-my-computer/103131">more incidents where Cursor goes rogue and nukes your home folder</a> until someone cares enough about the craft of the industry to do it the right way.</p>
<h2>Everyone suffers so the few can gain</h2>
<p>I have a unique view into a lot of the impact that AI companies have had across society. I'm the CEO of <a href="https://techaro.lol/">Techaro</a>, a small one-person startup that develops <a href="https://anubis.techaro.lol/">Anubis</a>, a Web AI Firewall Utility that helps mitigate the load of automated mass scraping so that open source infrastructure can stay online. I've had sales calls with libraries and universities that are just being <em>swamped</em> by the load. There's stories of GitLab servers eating up <em>64 cores</em> of high-wattage server hardware due to all of the repeated scraping over and over in a loop. I swear a lot of this scraping has to be some kind of dataset arbitrage or something, that's the only thing that makes sense at this point.</p>
<p>And then in the news the AI companies claim "oh no we're just poor little victorian era orphans, we can't possibly afford to fairly compensate the people that made the things that make our generative AI models as great as they are". When the US copyright office <a href="https://www.forbes.com/sites/torconstantino/2025/05/29/us-copyright-office-shocks-big-tech-with-ai-fair-use-rebuke/">tried to make AI training not a fair use</a>, the head of that office suddenly found themselves jobless. Why must these companies be allowed to take everything without recourse or payment to the people that created the works that fundamentally power the models?</p>
<p>The actual answer to this is going to sound a bit out there, but stay with me: they believe that we're on the verge of creating artificial superintelligence; something that will be such a benevolent force of good that any strife in the short term will ultimately be cancelled out by the good that is created as a result. These people unironically believe that a machine god will arise and we'd be able to delegate all of our human problems to it and we'll all be fine forever. All under the thumb of the people that bought the GPUs with dollars to run that machine god.</p>
<p>As someone that grew up in a repressed environment full of evangelical christianity, I recognize this story instantly: it's the second coming of Christ wrapped in technology. Whenever I ask the true believers entirely sensible questions like "but if you can buy GPUs with dollars, doesn't that mean that whoever controls the artificial superintelligence thus controls everyone, even if the AI is fundamentally benevolent?" The responses I get are illuminating. They sound like the kinds of responses that evangelicals give when you question their faith.</p>
<h3>Artists suffer first</h3>
<p>Honestly though, the biggest impact I've seen across my friends has been what's happened to art commissions. I'm using these as an indicator for how the programming industry is going to trend. Software development is an art in the same vein as visual/creative arts, but a lot of the craft and process that goes into visual art is harder to notice because it gets presented as a flat single-dimensional medium.</p>
<p>Sometimes it can take days to get something right for a drawing. But most of the time people just see the results of the work, not the process that goes into it. This makes things like prompting "draw my Final Fantasy 14 character in Breath of the Wild" with images as references and getting a result in seconds look more impressive. If you commissioned a human to get a painting like this:</p>
<figure><a href="https://files.xeiaso.net/blog/2025/rolling-ladder-behind-us/zamqo-botw.jpg"><picture><source type="image/avif" srcset="https://files.xeiaso.net/blog/2025/rolling-ladder-behind-us/zamqo-botw.avif"><source type="image/webp" srcset="https://files.xeiaso.net/blog/2025/rolling-ladder-behind-us/zamqo-botw.webp"><img alt="An AI-generated illustration of my Final Fantasy 14 character composited into a screenshot of Breath of the Wild. Generated by GPT-4o through the ChatGPT interface. Inputs were a screenshot of Breath of the Wild and reference photos of my character." loading="lazy" src="https://files.xeiaso.net/blog/2025/rolling-ladder-behind-us/zamqo-botw.jpg"></picture></a><figcaption>An AI-generated illustration of my Final Fantasy 14 character composited into a screenshot of Breath of the Wild. Generated by GPT-4o through the ChatGPT interface. Inputs were a screenshot of Breath of the Wild and reference photos of my character.</figcaption></figure>
<p>It'd probably take at least a week or two as the artist worked through their commission queue and sent you in-progress works before they got the final results. By my estimates between the artists I prefer commissioning, this would cost somewhere between 150 USD and 500 EUR at minimum. Probably more when you account for delays in the artistic process and making sure the artist is properly paid for their time. It'd be a masterpiece that I'd probably get printed and framed, but it would take a nonzero amount of time.</p>
<p>If you only really enjoy the products of work and don't understand/respect any of the craftsmanship that goes into making it happen, you'd probably be okay with that instantly generated result. Sure the sun position in that image doesn't make sense, the fingers have weird definition, her tail is the wrong shape, it pokes out of the dress in a nonsensical way (to be fair, the reference photos have that too), the dress has nonsensical shading, and the layering of the armor isn't like the reference pictures, but you got the result in a minute!</p>
<p>A friend of mine runs <a href="https://furbooru.org/">an image board for furry art</a>. He thought that people would use generative AI tools as a part of their workflows to make better works of art faster. He was wrong, it just led to people flooding the site with the results of "wolf girl with absolutely massive milkers showing her feet paws" from their favourite image generation tool in every fur color imaginable, then with different characters, then with different anatomical features. There was no artistic direction or study there. Just an endless flood of slop that was passable at best.</p>
<p>Sure, you can make high quality art with generative AI. There's several comic series where things are incredibly temporally consistent because the artist trained their own models and took the time to genuinely gain expertise with the tools. They filter out the hallucination marks. They take the time to use it as a tool to accelerate their work instead of replacing their work. The boards they post it to go out of their way to excise the endless flood of slop and by controlling how the tools work they actually get a better result than they got by hand, much like how the skilled weavers were able to produce high quality cloth faster and cheaper with the power looms.</p>
<p>We are at the point where the artists want to go and destroy the generative image power looms. Sadly, they can't even though they desperately want to. These looms are locked in datacentres that are biometrically authenticated. All human interaction is done by a small set of trusted staff or done remotely by true believers.</p>
<p>I'm afraid of this kind of thing happening to the programming industry. A lot of what I'm seeing with vibe coding leading to short term gains at the cost of long term toil is lining up with this. Sure you get a decent result now, but long-term you have to go back and revise the work. This is a great deal if you are producing the software though; because that means you have turned one-time purchases into repeat customers as the shitty software you sold them inevitably breaks, forcing the customer to purchase fixes. The one-time purchase inevitably becomes a subscription.</p>
<p>We deserve more in our lives than good enough.</p>
<h2>Stop it with the sparkle emoji buttons</h2>
<p>Look, CEOs, I'm one of you so I get it. We've seen the data teams suck up billions for decades and this is the only time that they can look like they're making a huge return on the investment. Cut it out with shoving the sparkle emoji buttons in my face. If the AI-aided product flows are <em>so good</em> then the fact that they are using generative artificial intelligence should be <em>irrelevant</em>. You should be able to replace generative artificial intelligence with another technology and then the product will still be as great as it was before.</p>
<p>When I pick up my phone and try to contact someone I care about, I want to know that I am communicating with them and not a simulacrum of them. I can't have that same feeling anymore due to the fact that people that don't natively speak English are much more likely to filter things through ChatGPT to "sound professional".</p>
<p>I want your bad English. I want your bad art. I want to see the raw unfiltered expressions of humanity. I want to see your soul in action. I want to communicate with you, not a simulacrum that stochastically behaves like you would by accident.</p>
<p>And if I want to use an LLM, I'll use an LLM. Now go away with your sparkle emoji buttons and stop changing their CSS class names so that my uBlock filters keep working.</p>
<h2>The human cost</h2>
<p>This year has been a year full of despair and hurt for me and those close to me. I'm currently afraid to travel to the country I have citizenship in because the border police are run under a regime that is dead set on either elimination or legislating us out of existence. In this age of generative AI, I just feel so replaceable at my dayjob. My main work product is writing text that convinces people to use globally distributed object storage in a market where people don't realize that's something they actually need. Sure, this means that my path forward is simple: show them what they're missing out on. But I am just so tired. I hate this feeling of utter replaceability because you can get 80% as good of a result that I can produce with a single invocation of OpenAI's Deep Research.</p>
<p>Recently a decree came from above: our docs and blogposts need to be optimized for AI models as well as humans. I have domain expertise in generative AI, I know exactly how to write SEO tables and other things that the AI models can hook into seamlessly. The language that you have to use for that is nearly identical to what the cult leader used that one time I was roped into a cult. Is that really the future of marketing? Cult programming? I don't want this to be the case, but when you look out at everything out there, you can't help but see the signs.</p>
<p>Aspirationally, I write for humans. Mostly I write for the version of myself that was struggling a decade ago, unable to get or retain employment. I create things to create the environment where there are more like me, and I can't do that if I'm selling to soulless automatons instead of humans. If the artificial intelligence tools were‚Ä¶well‚Ä¶intelligent, they should be able to derive meaning from unaltered writing instead of me having to change how I write to make them hook better into it. If the biggest thing they're sold for is summarizing text and they can't even do that without author cooperation, what are we doing as a society?</p>
<p>Actually, what are we going to do when everyone that cares about the craft of software ages out, burns out, or escapes the industry because of the ownership class setting unrealistic expectations on people? Are the burnt out developers just going to stop teaching people the right ways to make software? Is society as a whole going to be <em>right</em> when they look back on the good old days and think that software used to be more reliable?</p>
<h2>The Butlerians had a point</h2>
<p>Frank Herbert's Dune world had superintelligent machines at one point. It led to a galactic war and humanity barely survived. As a result, all thinking machines were banned, humanity was set back technologically, and a rule was created: Thou shalt not make a machine in the likeness of a human mind. For a very long time, I thought this was very strange. After all, in a fantasy scifi world like Dune, thinking machines could automate so much toil that humans had to process. They had entire subspecies of humans that were functionally supercomputers with feelings that were used to calculate the impossibly complicated stellar draft equations so that faster-than-light travel didn't result in the ship zipping into a black hole, star, moon, asteroid, or planet.</p>
<p>After seeing a lot of the impact across humanity in later 2024 and into 2025, I completely understand the point that Frank Herbert had. It makes me wish that I could leave this industry, but this is the only thing that pays enough for me to afford life in a world where my husband gets casually laid off after being at the same company for six and a half years because some number in a spreadsheet put him on the shitlist. Food and rent keeps going up here, but wages don't. I'm incredibly privileged to be able to work in this industry as it is (I make enough to survive, don't worry), but I'm afraid that we're rolling the ladder up behind us so that future generations won't be able to get off the ground.</p>
<p>Maybe the problem isn't the AI tools, but the way they are deployed, who benefits from them, and what those benefits really are. Maybe the problem isn't the rampant scraping, but the culture of taking without giving anything back that ends up with groups providing critical infrastructure like FFmpeg, GNOME, Gitea, FreeBSD, NetBSD, and the United Nations having to resort to increasingly desperate measures to maintain uptime.</p>
<p>Maybe the problem really is winner-take-all capitalism.</p>
<hr>
<p>The deployment of generative artificial intelligence tools has been a disaster for the human race. They have allowed a select few to gain "higher productivity"; but they have destabilized society, have made work transactional, have subjected artists to indignities, have led to widespread psychological suffering for the hackers that build the tools AI companies rely on, and inflict severe damage on the natural world. The continued development of this technology will worsen this situation. It will certainly subject human beings to greater indignities and inflict greater damage on the natural world, it will probably lead to greater social disruption and psychological suffering, and it may lead to increased physical suffering even in "advanced" countries.</p>
<hr>
<p>For other works in a similar vein, read these:</p>
<ul>
<li><a href="https://nombiezinja.com/word-things/2025/6/18/building-a-healthy-relationship-with-ai-a-cross-disciplinary-perspective">Building a Healthy Relationship with AI - A Cross-Disciplinary Perspective</a></li>
<li><a href="https://ludic.mataroa.blog/blog/contra-ptaceks-terrible-article-on-ai/">Contra Ptacek's Terrible Article On AI</a></li>
</ul>
<p>Special thanks to the following people that read and reviewed this before release:</p>
<ul>
<li>Ti Zhang</li>
<li>Annie Sexton</li>
<li>Open Skies</li>
<li>Nina Vyedin</li>
<li>Eric Chlebek</li>
<li>Ahroozle REDACTED</li>
<li>Kronkleberry</li>
<li>CELPHASE</li>
</ul>

    <hr>

    

    

    <p>Facts and circumstances may have changed since publication. Please contact me before jumping to conclusions if something seems wrong or unclear.</p>

    <p>Tags: </p>
</article>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Visualizing environmental costs of war in Hayao Miyazaki's Nausica√§ (140 pts)]]></title>
            <link>https://jgeekstudies.org/2025/06/20/wilted-lands-and-wounded-worlds-visualizing-environmental-costs-of-war-in-hayao-miyazakis-nausicaa-of-the-valley-of-the-wind/</link>
            <guid>44328598</guid>
            <pubDate>Fri, 20 Jun 2025 15:23:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jgeekstudies.org/2025/06/20/wilted-lands-and-wounded-worlds-visualizing-environmental-costs-of-war-in-hayao-miyazakis-nausicaa-of-the-valley-of-the-wind/">https://jgeekstudies.org/2025/06/20/wilted-lands-and-wounded-worlds-visualizing-environmental-costs-of-war-in-hayao-miyazakis-nausicaa-of-the-valley-of-the-wind/</a>, See on <a href="https://news.ycombinator.com/item?id=44328598">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong>Audrey Aguirre</strong></p>
<p><em>Upland High School, Upland, CA, USA.</em></p>
<p><em>Email: audrey.a.aguirre (at) gmail (dot) com</em></p>
<p><strong><em><span><a href="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_nausicaa.pdf" target="_blank" rel="noopener noreferrer"><span>Download PDF</span></a></span></em></strong></p>
<p>Past studies on <em>Nausica√§ of the Valley of the Wind</em> (È¢®„ÅÆË∞∑„ÅÆ„Éä„Ç¶„Ç∑„Ç´; Topcraft, 1984) have primarily focused on its ecological themes and anti-war messages through analysis of the narrative as a whole or Nausica√§‚Äôs character. These studies address the ethical and environmental consequences of war shown through the dystopian nature of the film‚Äôs setting and its religious symbolism. However, I have seen almost no research on how visual storytelling contributes to these messages.</p>
<p>This paper addresses how the visual representation of the environmental consequences of war in <em>Nausica√§ of the Valley of the Wind</em> can impact our views of those issues in our world. The paper will show that the visuals in the film are not simply aesthetic decisions, but a crucial narrative device to convey the effects of war on both people and nature.</p>
<p>Therefore, this paper explores how Miyazaki uses elements of mise-en-sc√®ne such as color, lighting, body language and other visual storytelling elements to communicate and add emphasis to the anti-war messaging of the film; especially those that display both the ecological and human consequences of war. I argue that the film‚Äôs use of visuals not only supports the anti-war themes of the film as a whole but also adds a stronger emotional and moral weight to the story by reflecting real-life war technologies in its visuals. This allowed audiences to reflect on real-life issues regarding the environmental and human consequences of warfare. In this way, the film created a bridge between fantasy and reality, urging its viewers to strive for a more peaceful and environmentally conscious world.</p>
<h2>Background</h2>
<p>Animated films, like many other art forms, can convey so much emotion and be filled to the brim with meaningful messages and ideas. Especially with animation, the director is able to display a myriad of stunning visuals that can be impossible to recreate in live action film. Throughout history we as humans have used storytelling and art to reflect on and understand the world and the current issues we face. With the state of our world being as it is, with conflict at every corner, with global warming and other environmental issues being more pressing matters than ever before, it is clear that the environmental messages in <em>Nausica√§</em> are of the utmost importance to our society today. This is why it is important to ask, how can the depiction of the environmental impact of war in this film help us change our view of and approach to these issues in real life?</p>
<p>Hayao Miyazaki‚Äôs 1984 film <em>Nausica√§ of the Valley of the Wind </em>follows the pacifistic and kindhearted princess of the Valley of the Wind as she navigates the apocalyptic landscape of the film, searching for a way to undo the damage caused by the wars of the past and prevent further damage in the present. Miyazaki‚Äôs filmography as a whole contains many important messages regarding the way in which humans interact with and affect the natural world. His films, including <em>Nausica√§</em>, focus on the relationships between humans and animals, exploring the imbalance between the human and natural worlds. With <em>Nausica√§</em> being the only film directed by Miyazaki that depicts a more modern style of warfare, this film could help to open people‚Äôs eyes to the damage war puts not just on the humans involved but on the environment which we all share.</p>
<p><em>Nausica√§ of the Valley of the Wind</em> was originally a manga of the same name that Hayao Miyazaki wrote for Animage, with it being released from February 1982 to March 1994. It saw great success amongst Japanese readers through its run. This prompted the manga‚Äôs adaptation into an animated film which was directed by Miyazaki and released to Japanese audiences in 1984. Due to the extreme inconsistencies between the original film and Showmen Inc.‚Äôs English dub of <em>Nausica√§ </em>‚Äìrenamed <em>Warriors of the Wind</em>‚Äì Miyazaki considered never releasing his films to foreign audiences again. This dub had changed the names of most characters, cut nearly 30 minutes off of the film and completely altered its message. Later, a deal was made between Studio Ghibli and Walt Disney Studios Home Entertainment, and Miayzaki allowed them to dub his films under the condition that they make no cuts and keep the original meaning intact (Cinematheque, 2016). Because of this, Disney‚Äôs English dub will be the main focus of this paper (Walt Disney Studios Home Entertainment, 1985).</p>
<h2>Keywords &amp; Terms</h2>
<p>For the purpose of this article, when referring to the natural world it would more specifically be described as the surrounding elements that are essential for the well-being of both human and non-human life which includes green spaces, wildlife habitats, biodiversity and clean air, water and soil. Additionally, there are several terms which one who has not watched the film would not be able to understand, and these terms are as follows.</p>
<p>The ohmu (Fig. 1) are enormous, powerful and intelligent pill bug-like animals which are feared by the people in the film due to the fact that they could be considered the kings of the toxic jungle.</p>
<figure data-shortcode="caption" id="attachment_12901" aria-describedby="caption-attachment-12901"><a href="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig01.png" target="_blank" rel="noopener"><img loading="lazy" data-attachment-id="12901" data-permalink="https://jgeekstudies.org/2025/06/20/wilted-lands-and-wounded-worlds-visualizing-environmental-costs-of-war-in-hayao-miyazakis-nausicaa-of-the-valley-of-the-wind/aguirre_2025_fig01/" data-orig-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig01.png" data-orig-size="2360,1319" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Aguirre_2025_fig01" data-image-description="" data-image-caption="" data-medium-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig01.png?w=300" data-large-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig01.png?w=1024" src="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig01.png?w=1024" alt="" width="1024" height="572" srcset="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig01.png?w=1024 1024w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig01.png?w=2048 2048w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig01.png?w=150 150w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig01.png?w=300 300w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig01.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption id="caption-attachment-12901"><strong>Figure 1.</strong> Lord Yupa (left), riding on an emu-like animal, running away from the chasing ohmu. Screen capture from the film.</figcaption></figure>
<p>The Toxic Jungle is a vast forest where the air, water, soil and plants are poisonous to all but the giant arthropods which inhabit it. The toxic jungle only became so poisonous after the Giant Warriors were used in the last days of the Ceramic War. The Giant Warriors (Fig. 2) are giant, biomechanical lifeforms which are treated, and act, more as weapons rather than as independent beings.</p>
<p>The Ceramic War is an apocalyptic war that occurred 1000 years before the events of the film in what was called the Ceramic Period, which destroyed civilization, caused an ecocide and created the vast Toxic Jungle during the Seven Days of Fire. The Seven Days of Fire was a seven-day period at the end of the Ceramic War in which the Giant Warriors were deployed.</p>
<figure data-shortcode="caption" id="attachment_12889" aria-describedby="caption-attachment-12889"><a href="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig02.png" target="_blank" rel="noopener"><img loading="lazy" data-attachment-id="12889" data-permalink="https://jgeekstudies.org/aguirre_2025_fig02/" data-orig-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig02.png" data-orig-size="2361,1330" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Aguirre_2025_fig02" data-image-description="" data-image-caption="" data-medium-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig02.png?w=300" data-large-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig02.png?w=1024" src="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig02.png?w=1024" alt="" width="1024" height="577" srcset="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig02.png?w=1024 1024w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig02.png?w=2048 2048w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig02.png?w=150 150w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig02.png?w=300 300w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig02.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption id="caption-attachment-12889"><strong>Figure 2.</strong> Giant warriors walking through a city in flames. Screen capture from the film.</figcaption></figure>
<h2>Literature Review</h2>
<p>When analyzing Miyazaki‚Äôs films, including <em>Nausica√§ of the Valley of the Wind</em>, often the messages regarding warfare‚Äôs effects on the natural world focus more on the direct impacts rather than the indirect ones. Additionally, many researchers look at the film from a spiritual lens with DeWeese-Boyd (2009) believing Nausica√§ serves as a Christ-like figure, while both Morgan (2015) and Nunes (2021) believe that Nausica√§ serves as an example of how to restore balance between humans and nature. Despite that, these authors see her role in restoring balance differently. Nunes believes that Nausica√§ gave herself to nature, sacrificing her free will in order to heal the earth without personal bias. On the other hand, Morgan believes that she serves as an example of how the fragmentation between the mind, body, spirit and nature can be restored through respect and care for the natural world.</p>
<p>In addition to this, there are some researchers who believe that <em>Nausica√§</em> can be used as a teaching tool, with Kleese (2024) believing that, since the film is not directly associated with any singular real-life issue but with many different events and issues, it can be used in classrooms to help children understand the importance of nature and finding a democratic solution to both environmental and political issues in a more digestible way.</p>
<p>It is no wonder the previous research on Nausica√§ has such a spiritual focus, as Miyazaki‚Äôs filmography as a whole often focuses on the relationship and imbalance between humans and the natural world in a very spiritual manner. However, <em>Nausica√§</em> not only explores the direct impacts of war and other human activities, but also their indirect ramifications. Thus, this paper will hopefully fill a gap in the existing <em>Nausic√§a </em>literature by analyzing the film‚Äôs messages regarding warfare‚Äôs indirect effects on the environment and how this exercise can give us insight to our real-world problems.</p>
<h2>The importance of the environment</h2>
<p>Climate change and other environmental crises such as soil and water contamination are all issues which have been recognized as important by the public eye. From everyday people to those in important positions, most can agree that the health of the natural world is important to the health and survival of life on earth. As UN Secretary-General Ant√≥nio Guterres said at the biodiversity COP in Montreal 2022, ‚ÄúWithout nature, we have nothing‚Äù (Abbasi et al., 2023). Access to clean water is undeniably fundamental to life on Earth, be it human or not. Even with this being common knowledge, pollution has damaged water quality to a point where it is causing a rise in waterborne diseases and damaging the health of both freshwater and saltwater ecosystems (Abbasi et al., 2023). Additionally, the rising temperatures, extreme weather events, air pollution and the heightened spread of infectious diseases are just a few examples of major health issues exacerbated by climate change (Abbasi et al., 2023). As the human population grows, we see that demands on Earth‚Äôs ecosystems are becoming more unsustainable; with the way that we currently treat our environment, long-term human and non-human security are clearly at stake (dos Santos, 2024).</p>
<h2>The importance of war</h2>
<p>The ever-worsening health of our natural world impacts us in many ways. Land degradation and other environmental issues which may cause an area to be less habitable can lead to the disruption of social and economic systems. Shortages of land, shelter, food and water exacerbate poverty and the poor living conditions in many areas of the world (Anonymous, 2004), this in turn leads to mass migration and conflict over usable land and resources necessary for life (Abbasi et al., 2023). While the degradation of land can in itself cause wars to erupt between peoples disputing over the usable land, war can and has caused additional land degradation. In Afghanistan, for example, forests have been leveled and its land and farmlands polluted from the years of use of fuel, chemicals and mines during wartime (Bonds, 2015).</p>
<p>Certain practices of war have more devastating impacts on the longevity of our natural world. One poignant example of how destructive war can be to our planet can be seen in the burning of Kuwaiti oil wells that took place during the The Gulf War as a part of their scorched earth tactics. This resulted both in the soil becoming contaminated with excessive amounts of hydrocarbons and heavy metals and in the release of massive amounts of particulate matter and other pollutants into the atmosphere (Aldawsari, 2024).</p>
<h2>The importance of film</h2>
<p>Everything from the way a shot is framed to the smallest detail captured within the shot can have an effect on the viewers of a film. Displaying intense emotional imagery has been proven to have significant psychological effects on viewers. For instance, the Kuleshov effect is a famous example of how film influences viewers‚Äô emotional perception; it has shown that point-of-view editing practices influence viewers‚Äô emotional interpretation of neutral facial expressions in a face-scene-face sequence (Cao et al., 2024). With this in mind it is evident that the things that films show their viewers can and do impact how they view the world.</p>
<p>At the same, time films utilize the elements of mise-en-sc√®ne to convey messages to their audience. Mise-en-sc√®ne is a French term meaning what is put into a scene or frame and consists of all the visual information in front of the camera (Caprio, 2021). Understanding these elements may help understand what the director of a film wants to convey with any given scene and understand how the visuals impact the audience.</p>
<h2>Why anime?</h2>
<p>All forms of filmography are capable of affecting their audiences with the previously mentioned methods. However, animation is often able to employ visuals and different types of shots which can often be extremely difficult or expensive to replicate in live action film. Because of this and because animated films in the West are often avoidant of more serious topics, seeing as they are viewed as being only for small children, that Japanese animation, or anime, can be an immensely powerful and impactful type of filmmaking. Several studies have shown that anime can influence its audience and evoke positive changes in them (e.g., Yusof et al., 2024). With the unique perspective that anime provides, which is more provocative, tragic and contains far more complicated storylines than the ones seen in American popular cinema, anime has proven itself to be a tool for understanding the complex human‚Äìenvironment relationship and environmental problems (Mumcu &amp; Yƒ±lmaz, 2018).</p>
<h2>Why Miyazaki?</h2>
<p>Within the anime community Hayao Miyazaki has carved out an image for himself as a masterful director who is skilled in creating both enchanting fantasies and incredibly thought-provoking films (Mumcu &amp; Yƒ±lmaz, 2018). He is quite well renowned for his beautiful landscapes, heavy ecological themes and overall beautiful and touching storytelling. Several of his films such as <em>Princess Mononoke</em>, <em>Nausica√§ of the Valley of the Wind</em> and even <em>Ponyo</em> feature themes of ecological imbalance as the main plot points of the films. Even those which do not have these themes quite as ingrained in the plot still have some commentary on the matter or feature more lighthearted takes on nature‚Äôs relationship with humanity. This can be seen in the stories of <em>Spirited Away</em> and <em>My Neighbor Totoro</em>. Additionally, many of his films also approach themes of war and conflict, such as <em>Princess Mononoke</em>, <em>Nausica√§ of the Valley of the Wind</em>, <em>Porco Rosso</em>, <em>Castle in the Sky</em>, <em>Howl‚Äôs Moving Castle</em> and <em>The Wind Rises</em>. This leaves only six of his fifteen films, all of which have seen great success, with no themes of interest to this paper. For this reason, it is evident that Miyazaki is a perfect choice for the subject matter of this paper.</p>
<h2>Why Nausica√§?</h2>
<p>With only six of the fifteen films Miyazaki has directed or written having no themes of interest to this paper, one may wonder what it is that makes <em>Nausica√§</em> more suitable than any of his other films. Well, though many of his films touch on environmental issues with Miyazaki even going as far as saying ‚ÄúI‚Äôve come to a point where I just can‚Äôt make a movie without addressing the problem of humanity as part of an ecosystem‚Äù in an interview with Asia Pulse, May 16, 1997, not many of his films include war in the main storyline. Only five do, as mentioned above. There are only two films, <em>Nausica√§ </em>and <em>Princess Mononoke</em>, that cover both environmental issues and war. The major factor which puts <em>Nausica√§</em> over <em>Princess Mononoke</em> is the setting; <em>Princess Mononoke </em>is set in Japan‚Äôs late Muromachi Period, which was characterized by rapid industrialization and frequent conflicts. On the other hand, <em>Nausica√§ </em>is set in the post-apocalyptic future which bears much resemblance to our world, with some current technologies such as guns, grenades and tanks being included, as well as fictitious technologies which closely mirror real-life technologies (e.g., how the Giant Warriors function similarly to nuclear bombs).</p>
<h2>Methodology</h2>
<p>As previously stated, the Kuleshov effect demonstrates that intense visuals can alter one‚Äôs interpretation of the world and this in itself proves that analysis via the elements of mise-en-sc√®ne is a viable method for breaking down <em>Nausica√§</em> with the purpose of determining how the visual depiction of the environmental impact of war can affect our view of and approach to these issues in real life. However, this isn‚Äôt the only reason mise-en-sc√®ne analysis was used within this study, since it has been used for teaching aspiring filmmakers how films communicate messages with visuals; as my question focuses on visual depictions in film, mise-en-sc√®ne analysis was perfectly suited for my project. The elements of mise-en-sc√®ne are as follows: settings and props, costume, hair and makeup, facial expressions and body language, lighting and color and lastly positioning. Each of the 38 scenes of the film were analyzed to see how these elements are utilized and what effect it can have on the audience.</p>
<h2>Findings</h2>
<p>Throughout the film the elements of mise-en-sc√®ne can be seen in use in many ways. Despite the subtle differences in the amount each element is used in the different parts of the story, the overall message urges viewers to rethink their stance on warfare and its technologies, not just for the impact it directly has on humans, but also for the sake of the natural world.</p>
<h2>War technologies</h2>
<p>One example of how body language, facial expressions and color are used to push the film‚Äôs message regarding the use of war technologies can be perfectly seen in the opening credits, which appear in scene two directly after the narrator introduces the world reading aloud the words that can be seen in figure one that state ‚ÄúOne thousand years have passed since the collapse of industrialized civilization. The Toxic Jungle now spreads, threatening the survival of the last of the human race.‚Äù Right after this is read as the credits roll a tapestry is panned over, shown in Figure 3.</p>
<figure data-shortcode="caption" id="attachment_12891" aria-describedby="caption-attachment-12891"><a href="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig03.jpg" target="_blank" rel="noopener"><img loading="lazy" data-attachment-id="12891" data-permalink="https://jgeekstudies.org/2025/06/20/wilted-lands-and-wounded-worlds-visualizing-environmental-costs-of-war-in-hayao-miyazakis-nausicaa-of-the-valley-of-the-wind/aguirre_2025_fig03/" data-orig-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig03.jpg" data-orig-size="4000,2460" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Aguirre_2025_fig03" data-image-description="" data-image-caption="" data-medium-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig03.jpg?w=300" data-large-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig03.jpg?w=1024" src="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig03.jpg" alt="" width="4000" height="2460" srcset="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig03.jpg 4000w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig03.jpg?w=150&amp;h=92 150w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig03.jpg?w=300&amp;h=185 300w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig03.jpg?w=768&amp;h=472 768w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig03.jpg?w=1024&amp;h=630 1024w" sizes="(max-width: 4000px) 100vw, 4000px"></a><figcaption id="caption-attachment-12891"><strong>Figure 3.</strong> Images of the tapestry shown in the opening credits. Source: Miyazaki (2019); reproduced under fair use.</figcaption></figure>
<p>The tapestry shows how the creation of the Giant Warriors led to the creation of the Toxic Jungle and the fall of humanity. Within this tapestry, while in the process of building the warriors they appear confident in their body language and facial expressions, they are clearly calm and all is well. However, the colors of the warrior are bright and clash with that of the people which are more muted browns rather than the bright blues reds and yellows of the warrior. This itself already sets up for the destructive and overpowering nature of the Giant Warriors before they have even been finished and this is only confirmed when they are soon after in the tapestry shown wreaking havoc on the very same people who created them. In contrast to their poised expression and way of holding themselves previously in the tapestry, here they appear to be in great distress and panic. While this on its own is a striking visual representation of how dangerous technologies can be, even to their own creators, these visuals are given new meaning when we see the Giant Warriors in actual use towards the end of the film.</p>
<p>The audience was shown the similarities between the Giant Warriors and nuclear bombs in several instances towards the end of the film; in particular, there is one which really drives home the parallels between them (Figs. 4 and 5). In this scene, the Giant Warrior is being used by the main antagonist, its form being completely fictional and bearing no resemblance to real-life technologies, with the warrior shooting a beam of light from its mouth. The explosion that this caused very closely resembles the mushroom shape of nuclear bombs. Other aspects of this scene that help to draw similarities between this fictional tool of destruction and the very real nuclear weapons we have, such as the fact that before it dies the warrior only sets off two explosions. This could be a reflection of the fact that these technologies have only seen practical use twice, once in Hiroshima and once in Nagasaki. While these parallels alone drive a case for the film‚Äôs anti-war messaging, other elements regarding the Giant Warriors in other scenes help to push this narrative as well.</p>
<figure data-shortcode="caption" id="attachment_12892" aria-describedby="caption-attachment-12892"><a href="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig04.png" target="_blank" rel="noopener"><img data-attachment-id="12892" data-permalink="https://jgeekstudies.org/2025/06/20/wilted-lands-and-wounded-worlds-visualizing-environmental-costs-of-war-in-hayao-miyazakis-nausicaa-of-the-valley-of-the-wind/aguirre_2025_fig04/" data-orig-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig04.png" data-orig-size="2363,1327" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Aguirre_2025_fig04" data-image-description="" data-image-caption="" data-medium-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig04.png?w=300" data-large-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig04.png?w=1024" loading="lazy" src="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig04.png?w=1024" alt="" width="1024" height="575" srcset="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig04.png?w=1024 1024w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig04.png?w=2048 2048w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig04.png?w=150 150w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig04.png?w=300 300w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig04.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption id="caption-attachment-12892"><strong>Figure 4.</strong> Giant warrior falling apart while charging up to fire. Screen capture from the film.</figcaption></figure>

<figure data-shortcode="caption" id="attachment_12894" aria-describedby="caption-attachment-12894"><a href="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig05.png" target="_blank" rel="noopener"><img data-attachment-id="12894" data-permalink="https://jgeekstudies.org/2025/06/20/wilted-lands-and-wounded-worlds-visualizing-environmental-costs-of-war-in-hayao-miyazakis-nausicaa-of-the-valley-of-the-wind/aguirre_2025_fig05/" data-orig-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig05.png" data-orig-size="2362,1328" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Aguirre_2025_fig05" data-image-description="" data-image-caption="" data-medium-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig05.png?w=300" data-large-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig05.png?w=1024" loading="lazy" src="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig05.png?w=1024" alt="" width="1024" height="576" srcset="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig05.png?w=1024 1024w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig05.png?w=2048 2048w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig05.png?w=150 150w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig05.png?w=300 300w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig05.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption id="caption-attachment-12894"><strong>Figure 5.</strong> Kushana (left) looking out towards the blast caused by the giant warrior. Screen capture from the film.</figcaption></figure>
<p>Every scene which has the Giant Warrior in it, from the beginning to the end of the film, is decisively negative. Around the middle of the film there is a scene where the warrior is in a sort of incubation. The film explains that the warrior needs time to develop before it is able to be used as a war machine and walk on its own. The warrior is depicted within this scene with its colors being both muddy and bloody, with the lighting highlighting not only its strange shape but also how slimy it appears. This all helps to show how grotesque it is, even when it hasn‚Äôt started to be destructive. With the clear parallels it has to nuclear weapons, it becomes obvious from nearly every mention and appearance of the Giant Warrior that if it is so grotesque and dangerous, then nuclear weapons must be just as horrifying. This specific scene very well pushes the idea that not only is the use of nuclear weapons immoral but so too is the development of them.</p>
<p>Aside from nuclear weapons, there are other very real weapons displayed in the film that we continue to use to this day. Such weapons include machine guns, shotguns, hand grenades, flash grenades and even larger things like gunships or tanks. While nearly all of these are represented in a very realistic way, the gunships are undoubtedly designed with significant creative liberty as the bodies of these aircrafts do not resemble any real aircraft. However, this does not mean these do not give a good representation of the flaws of such technologies. For examples, see Figures 6 and 7.</p>
<figure data-shortcode="caption" id="attachment_12895" aria-describedby="caption-attachment-12895"><img data-attachment-id="12895" data-permalink="https://jgeekstudies.org/2025/06/20/wilted-lands-and-wounded-worlds-visualizing-environmental-costs-of-war-in-hayao-miyazakis-nausicaa-of-the-valley-of-the-wind/aguirre_2025_fig06/" data-orig-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig06.png" data-orig-size="2359,1300" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Aguirre_2025_fig06" data-image-description="" data-image-caption="" data-medium-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig06.png?w=300" data-large-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig06.png?w=1024" loading="lazy" src="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig06.png?w=1024" alt="" width="1024" height="564" srcset="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig06.png?w=1024 1024w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig06.png?w=2048 2048w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig06.png?w=150 150w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig06.png?w=300 300w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig06.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption id="caption-attachment-12895"><strong>Figure 6.</strong> Nausica√§ (middle) standing before the weapons that were confiscated by her people, while surrounded by the army which confiscated those weapons. Screen capture from the film.</figcaption></figure>

<figure data-shortcode="caption" id="attachment_12896" aria-describedby="caption-attachment-12896"><a href="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig07.png" target="_blank" rel="noopener"><img data-attachment-id="12896" data-permalink="https://jgeekstudies.org/2025/06/20/wilted-lands-and-wounded-worlds-visualizing-environmental-costs-of-war-in-hayao-miyazakis-nausicaa-of-the-valley-of-the-wind/aguirre_2025_fig07/" data-orig-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig07.png" data-orig-size="2362,1296" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Aguirre_2025_fig07" data-image-description="" data-image-caption="" data-medium-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig07.png?w=300" data-large-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig07.png?w=1024" loading="lazy" src="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig07.png?w=1024" alt="" width="1024" height="562" srcset="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig07.png?w=1024 1024w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig07.png?w=2048 2048w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig07.png?w=150 150w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig07.png?w=300 300w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig07.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption id="caption-attachment-12896"><strong>Figure 7.</strong> Fleet of ships carrying stolen goods and hostages. Screen capture from the film.</figcaption></figure>
<p>All of the previously mentioned technologies of war are portrayed within the film in a distinctly negative way. However, this does not mean that the film means to say there is absolutely no acceptable use of such things; there are also times when these are shown to be neutral or even positive. In truth there is a strong possibility that this film means to say that these technologies themselves are not evil, but the way that we as humans interact with them can make them that way. Nausica√§ herself uses her gun towards the beginning of the film to remove part of an ohmu shell and she uses flash grenades to stun an ohmu, saving Lord Yupa. In the former instance, the use of the gun is shown in a completely neutral context, with it not even being used on any living thing and with the entire scene remaining quite peaceful; even the choices of lighting and colors being brighter than other parts of the Toxic Jungle adding to the serenity of the scene. This scene shows that such things can be used without causing any harm whatsoever. In the other instance the grenades are clearly used to stun the ohmu in order to protect and reduce harm for both parties.</p>
<p>In the instances in which these technologies are used in a harmful way, the negativity of it is conveyed both in the expression of the characters witnessing it or by the colors shown in the scene. With the scene of the Giant Warrior being used towards the end of the film, the characters on both sides are clearly in shock and awe of just how destructive this technology can be. Additionally, the use of color in that scene helps in pushing just how the use of these technologies causes far more harm than good. The warrior itself is melting into this dark bloody red sludge; this nasty red is contrasted with its sharp green eyes that appear completely devoid of any sort of soul. Its visage is utterly grotesque and it remains that way till it falls apart.</p>
<p>Other technologies that are more often used in warfare today are also critiqued. Towards the end of the film conflicts arise in the Valley with the people finally fighting back against the Tolmakian forces that have been occupying their land. Prior to this, the valley is shown to be a very peaceful and beautiful place with plenty of lush greenery and farmlands; the downfall of this serene environment begins when spores are found in the forest surrounding the valley. See Figures 8 and 9 for the before and after, respectively.</p>
<figure data-shortcode="caption" id="attachment_12897" aria-describedby="caption-attachment-12897"><a href="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig08.png" target="_blank" rel="noopener"><img data-attachment-id="12897" data-permalink="https://jgeekstudies.org/2025/06/20/wilted-lands-and-wounded-worlds-visualizing-environmental-costs-of-war-in-hayao-miyazakis-nausicaa-of-the-valley-of-the-wind/aguirre_2025_fig08/" data-orig-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig08.png" data-orig-size="2360,1302" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Aguirre_2025_fig08" data-image-description="" data-image-caption="" data-medium-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig08.png?w=300" data-large-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig08.png?w=1024" loading="lazy" src="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig08.png?w=1024" alt="" width="1024" height="565" srcset="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig08.png?w=1024 1024w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig08.png?w=2048 2048w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig08.png?w=150 150w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig08.png?w=300 300w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig08.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption id="caption-attachment-12897"><strong>Figure 8.</strong> How the Valley of the Wind looks like in a time of peace. Screen capture from the film.</figcaption></figure>

<figure data-shortcode="caption" id="attachment_12898" aria-describedby="caption-attachment-12898"><a href="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig09.png" target="_blank" rel="noopener"><img data-attachment-id="12898" data-permalink="https://jgeekstudies.org/2025/06/20/wilted-lands-and-wounded-worlds-visualizing-environmental-costs-of-war-in-hayao-miyazakis-nausicaa-of-the-valley-of-the-wind/aguirre_2025_fig09/" data-orig-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig09.png" data-orig-size="2358,1301" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Aguirre_2025_fig09" data-image-description="" data-image-caption="" data-medium-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig09.png?w=300" data-large-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig09.png?w=1024" loading="lazy" src="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig09.png?w=1024" alt="" width="1024" height="565" srcset="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig09.png?w=1024 1024w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig09.png?w=2048 2048w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig09.png?w=150 150w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig09.png?w=300 300w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig09.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption id="caption-attachment-12898"><strong>Figure 9.</strong> How the Valley of the Wind looks like in a time of war. Screen capture from the film.</figcaption></figure>
<p>Initially, the people mean only to use their tools to burn the spores, using fire in moderation in order to solve their problem. However, things quickly get out of hand and they realize that they have no choice but to burn the entire forest down if they don‚Äôt want the Toxic Jungle to spread into the valley. This is the first time in the film that the valley is shown with colors like black, brown and others that are associated with decay, being more prevalent than greens and other more natural or lively colors. Throughout the entire film the use of fire is heavily frowned upon with Ohbaba warning the Tolmekians of why they should not even attempt to burn down the toxic jungle and, towards the end of the film, several characters going on about why they prefer the ways of the water and the wind over the way of fire since ‚ÄúToo much fire gives birth to nothing. Fire can reduce a forest to ashes in a day, while it takes the water and the wind 100 years to grow one‚Äù. With this film Miyazaki is urging us to stop relying on fire to solve our problems, both in a literal and figurative sense. This is shown not just through the speech of the characters but also in the way that the scenery changes and the way the characters react to the use of excess fire.</p>
<h2>Human &amp; environmental impact</h2>
<p>In the film the human and environmental impact of human activities such as war are explored in many scenes. One example of this can be seen in one scene towards the end of the film where Nausica√§ and another character, Asbel, fly into the city of Pejite together on Nausica√§‚Äôs glider (Figs. 10, 11). It had previously been occupied by the Tolmekian forces but as they fly over it, the city is desolate and run down. The film reveals that the people of Pejite baited some of the ohmu into the city and let them wreak havoc in order to drive out the Tolmekians occupying the city. The film tries to show the audience how immoral this decision was not just from the sorrowful and ashamed expressions on the faces of the Pejite refugees and Asbel, the prince of Pejite. It also shows the impact these actions have had on the fauna, as the scenery is full of deceased animals of the Toxic Jungle. Additionally, while it is apparent that the city was once livable, now the characters need to use their masks to even be able to breathe within its premises. This shows that the damage done here was severe as some buildings were broken down, lives were lost and the land has been made uninhabitable for the foreseeable future.</p>
<figure data-shortcode="caption" id="attachment_12899" aria-describedby="caption-attachment-12899"><a href="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig10.png" target="_blank" rel="noopener"><img data-attachment-id="12899" data-permalink="https://jgeekstudies.org/2025/06/20/wilted-lands-and-wounded-worlds-visualizing-environmental-costs-of-war-in-hayao-miyazakis-nausicaa-of-the-valley-of-the-wind/aguirre_2025_fig10/" data-orig-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig10.png" data-orig-size="2360,1289" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Aguirre_2025_fig10" data-image-description="" data-image-caption="" data-medium-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig10.png?w=300" data-large-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig10.png?w=1024" loading="lazy" src="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig10.png?w=1024" alt="" width="1024" height="559" srcset="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig10.png?w=1024 1024w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig10.png?w=2048 2048w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig10.png?w=150 150w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig10.png?w=300 300w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig10.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption id="caption-attachment-12899"><strong>Figure 10.</strong> The city of Pejite after the Pejite government lured giant violent animals into the city. Screen capture from the film.</figcaption></figure>

<figure data-shortcode="caption" id="attachment_12915" aria-describedby="caption-attachment-12915"><a href="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig11.png" target="_blank" rel="noopener"><img data-attachment-id="12915" data-permalink="https://jgeekstudies.org/2025/06/20/wilted-lands-and-wounded-worlds-visualizing-environmental-costs-of-war-in-hayao-miyazakis-nausicaa-of-the-valley-of-the-wind/aguirre_2025_fig11/" data-orig-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig11.png" data-orig-size="4400,4846" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Aguirre_2025_fig11" data-image-description="" data-image-caption="" data-medium-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig11.png?w=272" data-large-file="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig11.png?w=930" loading="lazy" src="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig11.png?w=930" alt="" width="930" height="1024" srcset="https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig11.png?w=930 930w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig11.png?w=1860 1860w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig11.png?w=136 136w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig11.png?w=272 272w, https://jgeekstudies.org/wp-content/uploads/2025/06/aguirre_2025_fig11.png?w=768 768w" sizes="(max-width: 930px) 100vw, 930px"></a><figcaption id="caption-attachment-12915"><strong>Figure 11.</strong> The city of Pejite after the Pejite government lured giant violent animals into the city and the reactions of the characters Nausica√§ (left) and Asbel (right) when seeing the state of the city. Screen capture from the film.</figcaption></figure>
<p>The Pejite use the same strategy again later in the film. In this second instance, they lure the ohmu into the Valley of the Wind in order to keep the Giant Warrior out of the hands of the Tolmekians. There were several scenes which depict this event since it is the major conflict of the film; however, since the previous scene examined focused more on the environmental impact of this act, here the focus is on the human impact. In the scene Mito, who serves sort of as the assistant to Princess Nausica√§, returns to the Valley of the Wind and informs both the people of the valley and the occupying forces of the Tolmekians of the ohmu horde heading towards them. The audience is shown in this scene how much panic and distress the news brings both to the innocent citizens of the occupied territory and to the occupying forces, who were the only real target of this attack. The expressive use of facial expression and body language in this scene helps drive home just how impactful this is, even to the people who were never meant to be a target of this attack. Another scene that comes soon after reinforces this idea, when the insects begin their attack on the valley. This scene is utter chaos, the people attempt to seek shelter and the Tolmekian soldiers who were previously standing without shelter, emboldened by their control of the Giant Warrior, now scramble seeking shelter and clearly fearing for their lives. The expressiveness of this scene comes not only from the facial expressions and body language but also from the shaky and strange positioning of the camera which gives the scene a more panicked feel. In addition, the colors were muddled and the lighting was quite dim, with sudden flashes of bright blaring light that fed into the chaotic nature of the scene. This all works to show just how impactful efforts of war can be to humans, their environment and the other creatures who share it.</p>
<h2>Limitations</h2>
<p>Certain aspects of the method I chose when designing this project limited the results of my research. For instance, because I focused only on the visuals, my data does not take into account the role that the script, voice acting (especially the original) or soundtrack played in delivering certain messages to the audience. Additionally, while one can analyze, interpret, and hypothesize the main message(s) in the film and in each scene, it is impossible to extrapolate for all audiences. During the research process for this study, many additional questions have come up, including the following. Firstly, what effects do the audio elements of <em>Nausica√§</em> have on the audience? Secondly, can <em>Nausica√§</em> even be compared to Western religions given the fact that it was made in Japan? Lastly, how is the film interpreted by younger viewers versus older viewers?</p>
<h2>Conclusion</h2>
<p>Through its stunning visual story-telling, <em>Nausica√§ of the Valley of the Wind</em> invites its audience to reconsider the toll war takes not just on people, but also the environment. With color, body language, facial expressions, and the overall environment of scenes, Miyazaki warns against the dangers of harmful technology and the moral implications of its use. From the violent and gruesome images of the Giant Warrior and destroyed landscape as a result of the use of war technology, to the depleted and unsafe landscapes and fearful gazes of terrified civilians robbed of their homes and any sense of normalcy, the film seeks to depict the enormous destructiveness that results from war. Additionally, Miyazaki‚Äôs illustrations are much more than fantasy, nodding toward the real world where parallel destruction occurs via nuclear weapons, environmental crises and modern warfare. The overarching message of the film‚Äôs visuals serves not only to paint a narrative, but to urge us to meet conflict with empathy, to protect our natural environment, and understand that it takes more courage and wisdom to find peace than to wage war. Although this data is subjective, seeing as it was based on my interpretation of the film‚Äôs visuals, it still suggests that visual storytelling has the potential to convey the ecologically damaging effects of war. Additionally, this discussion makes a contribution to the academic conversations on film, war and environmental sustainability all at the same time. Offering a visual, scene-based approach to analyzing storytelling that depicts war and environmental crisis in anime. Despite all this, further research is needed on large audience reception of these visual messages, cultural responses to these messages, or the influence auditory elements of film can have in delivering these messages.</p>
<p><strong>REFERENCES</strong></p>
<p><strong>Abbasi, K.; Ali, P.; Barbour, V.; et al.</strong> (2023) Time to treat the climate &amp; nature crisis as one indivisible global health emergency. The Indian Journal of Medical Research 158(4): 330‚Äì333.</p>
<p><strong>Aldawsari, S.H.</strong> (2024) War practices and experiences: analyzing their effects on the environment in the Gulf Cooperation Council (GCC) region. The American Journal of Management and Economics Innovations 6(8): 64‚Äì88.</p>
<p><strong>Anonymous.</strong> (2004) War‚Äôs environmental impact. Alternatives Journal 30(4): 26.</p>
<p><strong>Bonds, E.</strong> (2015) Legitimating the environmental injustices of war: toxic exposures and media silence in Iraq and Afghanistan. Environmental Politics 25(3): 395‚Äì413.</p>
<p><strong>Cao, Z.; Jin, S.; Yang, C.; et al.</strong> (2024) Reexamining the Kuleshov Effect: behavioral and neural evidence from authentic film experiments. PLOS ONE 19(8): e0308295.</p>
<p><strong>Caprio, M.</strong> (2021) Week 4: The language of animation ‚Äì mise-en-sc√®ne. M. Caprio LCC 3D Computer Animation. Available from: <a href="https://marianna3dcomputeranimation.myblog.arts.ac.uk/2021/10/29/week-4-the-language-of-animation-mise-en-scene/" rel="nofollow">https://marianna3dcomputeranimation.myblog.arts.ac.uk/2021/10/29/week-4-the-language-of-animation-mise-en-scene/</a> (Date of access: 16/May/2025).</p>
<p><strong>Cinematheque.</strong> (2016) When Nausica√§ became Warriors of the Wind. <a href="https://www.wisc.edu/">University&nbsp;of&nbsp;Wisconsin‚ÄìMadison</a>. Available from: <a href="https://cinema.wisc.edu/blog/2016/09/06/when-nausica%C3%A4-became-warriors-wind" rel="nofollow">https://cinema.wisc.edu/blog/2016/09/06/when-nausica%C3%A4-became-warriors-wind</a> (Date of access: 16/May/2025).</p>
<p><strong>DeWeese-Boyd, I.</strong> (2009) Shojo savior: Princess Nausica√§, ecological pacifism, and the green gospel. Journal of Religion and Popular Culture 21(2): 1‚Äì16.</p>
<p><strong>dos Santos, M.</strong> (2021) Climate change, air pollution, and human health in the Kruger to Canyons Biosphere Region, South Africa, and Amazonas, Brazil: a narrative review. Atmosphere 15(5): 562.</p>
<p><strong>Kleese, N.</strong> (2024) Democracy and kinship in Nausica√§ of the Valley of the Wind. Climate Literacy in Education 2(1): 67‚Äì73.</p>
<p><strong>Miyazaki, H.</strong> (2019) The Art of Nausica√§ of the Valley of the Wind. VIZ Media LLC, San Francisco.</p>
<p><strong>Morgan, G.</strong> (2015) Creatures in crisis: apocalyptic environmental visions in Miyazaki‚Äôs Nausica√§ of the Valley of the Wind and Princess Mononoke. Resilience: A Journal of the Environmental Humanities 2(3): 172‚Äì183.</p>
<p><strong>Mumcu, S. &amp; Yƒ±lmaz, S.</strong> (2018) Anime landscapes as a tool for analyzing the human‚Äìenvironment relationship: Hayao Miyazaki films. Arts 7(2): 16.</p>
<p><strong>Nunes, D.A.</strong> (2021) The toxic heroine in Nausica√§ of the Valley of the Wind. In: Ferstl, P. (Ed.) Dialogues between Media, Vol. 5. De Gruyter, Berlin. Pp. 83‚Äì94.</p>
<p><strong>Walt Disney Studios Home Entertainment [Translator].</strong> (1985) Nausica√§ of the Valley of the Wind. Directed by Hayao Miyazaki. Studio Ghibli. English dub.</p>
<p><strong>Yusof, N.A.; Hussin, S.A.; Hashim, M.A.; Amin, A.</strong> (2024) Exploring the impact of anime on Muslim teenagers‚Äô moral behaviour. International Journal of Academic Research in Business and Social Sciences 14(7): 861‚Äì873.</p>
<hr>
<p><strong>Acknowledgments</strong></p>
<p>ChatGPT (GPT-4, OpenAI) was used to improve the writing style of this article. The author reviewed, edited, and revised the ChatGPT-generated texts to her own liking and takes ultimate responsibility for the content of this publication. Special thanks to my AP Research teacher and classmates for their feedback and support during the development of this paper.</p>
<hr>
<p><strong>About the author</strong></p>
<p><strong>Audrey Aguirre</strong> is a student of Upland High School. She has been fascinated with Studio Ghibli‚Äôs Films since the first time she saw one and couldn‚Äôt get enough of the studio‚Äôs beautiful animation and wonderful storytelling. For the longest time her two favorite films had been <em>Nausica√§ </em>and <em>Princess Mononoke</em>. She can‚Äôt be sure what the future has in store for her but she hopes she can see many more meaningful films such as the ones she‚Äôve loved from Studio Ghibli.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Phoenix.new ‚Äì The Remote AI Runtime for Phoenix (306 pts)]]></title>
            <link>https://fly.io/blog/phoenix-new-the-remote-ai-runtime/</link>
            <guid>44328326</guid>
            <pubDate>Fri, 20 Jun 2025 14:57:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fly.io/blog/phoenix-new-the-remote-ai-runtime/">https://fly.io/blog/phoenix-new-the-remote-ai-runtime/</a>, See on <a href="https://news.ycombinator.com/item?id=44328326">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
         <dl>
             <dt>Author</dt>
             <dd>
                 <img alt="Chris McCord" src="https://fly.io/static/images/chris-m.webp">
               <dl>
                 <dt>Name</dt>
                 <dd>
                   Chris McCord
                 </dd>
                  <dt>@chris_mccord</dt>
                  <dd>
                    <a href="https://twitter.com/chris_mccord" target="_blank">
                      @chris_mccord
                    </a>
                  </dd>
               </dl>
             </dd>
         </dl>

        <section>
            <figure>
                <img src="https://fly.io/blog/phoenix-new-the-remote-ai-runtime/assets/phoenixnew.png" alt="phoenix.new orb">
            </figure>
          <p>I‚Äôm Chris McCord, the creator of Elixir‚Äôs Phoenix framework. For the past several months, I‚Äôve been working on a skunkworks project at Fly.io, and it‚Äôs time to show it off.</p>
<p>I wanted LLM agents to work just as well with Elixir as they do with Python and JavaScript. Last December, in order to figure out what that was going to take, I started a little weekend project to find out how difficult it would be to build a coding agent in Elixir.</p>

<p>A few weeks later, I had it spitting out working Phoenix applications and driving a full in-browser IDE. I knew this wasn‚Äôt going to stay a weekend project.</p>

<p>If you follow me on Twitter, you‚Äôve probably seen me teasing this work as it picked up steam. We‚Äôre at a point where we‚Äôre pretty serious about this thing, and so it‚Äôs time to make a formal introduction.</p>

<p>World, meet <a href="https://phoenix.new/" title="">Phoenix.new</a>, a batteries-included fully-online coding agent tailored to Elixir and Phoenix. I think it‚Äôs going to be the fastest way to build collaborative, real-time applications.</p>

<p>Let‚Äôs see it in action:</p>
<div data-exclude-render="">
  <p>
    <iframe width="100%" height="100%" src="https://www.youtube.com/embed/du7GmWGUM5Y" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
    </iframe>
  </p>
</div>

<h2 id="whats-interesting-about-phoenix-new"><a href="#whats-interesting-about-phoenix-new" aria-label="Anchor"></a><span>What‚Äôs Interesting About Phoenix.new</span></h2>
<p>First, even though it runs entirely in your browser, Phoenix.new gives both you and your agent a root shell, in an ephemeral virtual machine (a <a href="https://fly.io/docs/machines/overview/" title="">Fly Machine</a>) that gives our agent loop free rein to install things and run programs  ‚Äî without any risk of messing up your local machine. You don‚Äôt think about any of this; you just open up the VSCode interface, push the shell button, and there you are, on the isolated machine you share with the Phoenix.new agent.</p>

<p>Second, it‚Äôs an agent system I built specifically for Phoenix. Phoenix is about real-time collaborative applications, and Phoenix.new knows what that means. To that end, Phoenix.new includes, in both its UI and its agent tools, a full browser. The Phoenix.new agent uses that browser ‚Äúheadlessly‚Äù to check its own front-end changes and interact with the app. Because it‚Äôs a full browser, instead of trying to iterate on screenshots, the agent sees real page content and JavaScript state ‚Äì with or without a human present.</p>
<h2 id="what-root-access-gets-us"><a href="#what-root-access-gets-us" aria-label="Anchor"></a><span>What Root Access Gets Us</span></h2>
<p>Agents build software the way you did when you first got started, the way you still do today when you prototype things. They don‚Äôt carefully design Docker container layers and they don‚Äôt really do release cycles. An agent wants to pop a shell and get its fingernails dirty.</p>

<p>A fully isolated virtual machine means Phoenix.new‚Äôs fingernails can get <em>arbitrarily dirty.</em> If it wants to add a package to <code>mix.exs</code>, it can do that and then run <code>mix phx.server</code> or <code>mix test</code> and check the output. Sure. Every agent can do that. But if it wants to add an APT package to the base operating system, it can do that too, and make sure it worked. It owns the whole environment.</p>

<p>This offloads a huge amount of tedious, repetitive work.</p>

<p>At his <a href="https://youtu.be/LCEmiRjPEtQ?si=sR_bdu6-AqPXSNmY&amp;t=1902" title="">startup school talk last week</a>, Andrej Karpathy related his experience of building a restaurant menu visualizer, which takes camera pictures of text menus and transforms all the menu items into pictures. The code, which he vibe-coded with an LLM agent, was the easy part; he had it working in an afternoon. But getting the app online took him a whole week.</p>

<p>With Phoenix.new, I‚Äôm taking dead aim at this problem. The apps we produce live in the cloud from the minute they launch. They have private, shareable URLs (we detect anything the agent generates with a bound port and give it a preview URL underneath <code>phx.run</code>, with integrated port-forwarding), they integrate with Github, and they inherit all the infrastructure guardrails of Fly.io: hardware virtualization, WireGuard, and isolated networks.</p>
<p>Github‚Äôs <code>gh</code> CLI is installed by default. So the agent knows how to clone any repo, or browse issues, and you can even authorize it for internal repositories to get it working with your team‚Äôs existing projects and dependencies.</p>
<p>Full control of the environment also closes the loop between the agent and deployment. When Phoenix.new boots an app, it watches the logs, and tests the application. When an action triggers an error, Phoenix.new notices and gets to work.</p>
<h2 id="watch-it-build-in-real-time"><a href="#watch-it-build-in-real-time" aria-label="Anchor"></a><span>Watch It Build In Real Time</span></h2>
<p><a href="https://phoenix.new/" title="">Phoenix.new</a> can interact with web applications the way users do: with a real browser.</p>

<p>The Phoenix.new environment includes a headless Chrome browser that our agent knows how to drive. Prompt it to add a front-end feature to your application, and it won‚Äôt just sketch the code out and make sure it compiles and lints. It‚Äôll pull the app up itself and poke at the UI, simultaneously looking at the page content, Javascript state, and serverside logs.</p>

<p>Phoenix is all about <a href="https://fly.io/blog/how-we-got-to-liveview/" title="">‚Äúlive‚Äù real-time</a> interactivity, and gives us seamless live reload. The user interface for Phoenix.new itself includes a live preview of the app being worked on, so you can kick back and watch it build front-end features incrementally. Any other <code>.phx.run</code> tabs you have open also update as it goes. It‚Äôs wild.</p>
<video title="agent interacting with web" autoplay="autoplay" loop="loop" muted="muted" playsinline="playsinline" disablepictureinpicture="true" src="https://fly.io/blog/phoenix-new-the-remote-ai-runtime/assets/webjs.mp4"></video>

<h2 id="not-just-for-vibe-coding"><a href="#not-just-for-vibe-coding" aria-label="Anchor"></a><span>Not Just For Vibe Coding</span></h2>
<p>Phoenix.new can already build real, full-stack applications with WebSockets, Phoenix‚Äôs Presence features, and real databases. I‚Äôm seeing it succeed at business and collaborative applications right now.</p>

<p>But there‚Äôs no fixed bound on the tasks you can reasonably ask it to accomplish. If you can do it with a shell and a browser, I want Phoenix.new to do it too. And it can do these tasks with or without you present.</p>

<p>For example: set a <code>$DATABASE_URL</code> and tell the agent about it. The agent knows enough to go explore it with <code>psql</code>, and it‚Äôll propose apps based on the schemas it finds. It can model Ecto schemas off the database. And if MySQL is your thing, the agent will just <code>apt install</code> a MySQL client and go to town.</p>

<p>Frontier model LLMs have vast world knowledge. They generalize extremely well. On stage at ElixirConfEU, I did a <a href="https://www.youtube.com/watch?v=ojL_VHc4gLk&amp;t=3923s" title="">demo vibe-coding Tetris</a> on stage. Phoenix.new nailed it, first try, first prompt. It‚Äôs not like there‚Äôs gobs of Phoenix LiveView Tetris examples floating around the Internet! But lots of people have published Tetris code, and lots of people have written LiveView stuff, and 2025 LLMs can connect those dots.</p>

<p>At this point you might be wondering ‚Äì can I just ask it to build a Rails app? Or an Expo React Native app? Or Svelte? Or Go?</p>

<p>Yes, you can.</p>

<p>Our system prompt is tuned for Phoenix today, but all languages you care about are already installed. We‚Äôre still figuring out where to take this, but adding new languages and frameworks definitely ranks highly in my plans.</p>
<h2 id="our-async-agent-future"><a href="#our-async-agent-future" aria-label="Anchor"></a><span>Our Async Agent Future</span></h2>
<p><a href="https://fly.io/blog/youre-all-nuts/" title="">We‚Äôre at a massive step-change in developer workflows</a>.</p>

<p>Agents can do real work, today, with or without a human present. Buckle up: the future of development, at least in the common case, probably looks less like cracking open a shell and finding a file to edit, and more like popping into a CI environment with agents working away around the clock.</p>

<p>Local development isn‚Äôt going away. But there‚Äôs going to be a shift in where the majority of our iterations take place. I‚Äôm already using Phoenix.new to triage <code>phoenix-core</code> Github issues and pick problems to solve. I close my laptop, grab a cup of coffee, and wait for a PR to arrive ‚Äî Phoenix.new knows how PRs work, too. We‚Äôre already here, and this space is just getting started.</p>

<p>This isn‚Äôt where I thought I‚Äôd end up when I started poking around. The Phoenix and LiveView journey was much the same. Something special was there and the projects took on a life of their own. I‚Äôm excited to share this work now, and see where it might take us. I can‚Äôt want to see what folks build.</p>

          
        </section>
        <dl>
            <dt>
              Previous post  ‚Üì
            </dt>
            <dd>
              <a href="https://fly.io/blog/mcps-everywhere/">
                What are MCP Servers?
              </a>
            </dd>
        </dl>
      </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Congestion pricing in Manhattan is a predictable success (241 pts)]]></title>
            <link>https://www.economist.com/united-states/2025/06/19/congestion-pricing-in-manhattan-is-a-predictable-success</link>
            <guid>44328032</guid>
            <pubDate>Fri, 20 Jun 2025 14:26:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/united-states/2025/06/19/congestion-pricing-in-manhattan-is-a-predictable-success">https://www.economist.com/united-states/2025/06/19/congestion-pricing-in-manhattan-is-a-predictable-success</a>, See on <a href="https://news.ycombinator.com/item?id=44328032">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><time datetime="2025-06-19T12:57:40.334Z"> <!-- -->Jun 19th 2025</time><span>|</span><span>NEW YORK</span></p></div><section><p data-component="paragraph"><span data-caps="initial">M</span><small>AURA RYAN</small>, a speech therapist in New York City, was dreading the introduction of congestion pricing. To see her patients in Queens and Manhattan she sometimes drives across the East River a couple of times a day. The idea of paying a $9 toll each day infuriated her. Yet since the policy was actually implemented, she has changed her mind. A journey which used to take an hour or more can now be as quick as 15 minutes. ‚ÄúWell, this is very nice,‚Äù she admits thinking. Ms Ryan is not alone. Polls show more New Yorkers now support the toll than oppose it. A few months ago, it saw staunch opposition.</p></section><p><h3 id="article-tags">Explore more</h3><nav aria-labelledby="article-tags"><a href="https://www.economist.com/topics/world" data-analytics="tags:world"><span>World</span></a><a href="https://www.economist.com/topics/united-states" data-analytics="tags:united_states"><span>United States</span></a></nav></p><p>This article appeared in the United States section of the print edition under the headline ‚ÄúIt tolls for thee‚Äù</p><div data-test-id="chapterlist" data-tracking-id="content-well-chapter-list"><div><hr data-testid="rule-accent"><div><h3><a href="https://www.economist.com/united-states" text="United States" data-analytics="chapter_list_header:United States">United States</a></h3><p><span>June 21st 2025</span></p></div></div><ul><li><a href="https://www.economist.com/united-states/2025/06/19/democrats-could-do-a-lot-better-with-the-power-they-hold" id="48c7ec8f-a972-4b45-b0a0-4d6b149e0a19" data-analytics="article:reports_headline:1" data-test-id="chapterlist-link-0"><span data-testid="right-london-5-false"><span>‚Üí</span></span><span>Democrats could do a lot better with the power they hold</span></a></li><li><a href="https://www.economist.com/united-states/2025/06/19/congestion-pricing-in-manhattan-is-a-predictable-success" id="115c518c-d16c-4ff8-8d68-f8b865beb097" data-analytics="article:reports_headline:2" data-test-id="chapterlist-link-1"><span data-testid="right-economist-red-false"><span>‚Üí</span></span><span>Congestion pricing in Manhattan is a predictable success</span></a></li><li><a href="https://www.economist.com/united-states/2025/06/18/the-attacks-in-minnesota-reflect-a-worrying-trend" id="b73b4d21-eb9f-4add-80c3-fa6090aa0e45" data-analytics="article:reports_headline:3" data-test-id="chapterlist-link-2"><span data-testid="right-london-5-false"><span>‚Üí</span></span><span>The attacks in Minnesota reflect a worrying trend</span></a></li><li><a href="https://www.economist.com/united-states/2025/06/17/the-strange-history-of-the-tribe-courted-by-donald-trump" id="d894c7e9-983e-48ce-900d-8b28fedc4df9" data-analytics="article:reports_headline:4" data-test-id="chapterlist-link-3"><span data-testid="right-london-5-false"><span>‚Üí</span></span><span>The strange history of the tribe courted by Donald Trump</span></a></li><li><a href="https://www.economist.com/united-states/2025/06/19/our-model-suggests-president-trump-is-under-water-in-every-swing-state" id="03749d6f-49dd-49db-b065-1f4bae139b83" data-analytics="article:reports_headline:5" data-test-id="chapterlist-link-4"><span data-testid="right-london-5-false"><span>‚Üí</span></span><span>Our model suggests President Trump is under water in every swing state</span></a></li><li><a href="https://www.economist.com/united-states/2025/06/19/the-new-york-mayors-race-is-a-study-in-democratic-party-dysfunction" id="81f9a9da-3ff5-4229-af54-0ca5b4237ed1" data-analytics="article:reports_headline:6" data-test-id="chapterlist-link-5"><span data-testid="right-london-5-false"><span>‚Üí</span></span><span>The New York mayor‚Äôs race is a study in Democratic Party dysfunction </span></a></li></ul></div><div orientation="vertical" data-test-id="vertical"><div orientation="vertical"><figure><img loading="lazy" width="1280" height="1709" decoding="async" data-nimg="1" sizes="300px" srcset="https://www.economist.com/cdn-cgi/image/width=16,quality=80,format=auto/content-assets/images/20250621_DE_EU.jpg 16w, https://www.economist.com/cdn-cgi/image/width=32,quality=80,format=auto/content-assets/images/20250621_DE_EU.jpg 32w, https://www.economist.com/cdn-cgi/image/width=48,quality=80,format=auto/content-assets/images/20250621_DE_EU.jpg 48w, https://www.economist.com/cdn-cgi/image/width=64,quality=80,format=auto/content-assets/images/20250621_DE_EU.jpg 64w, https://www.economist.com/cdn-cgi/image/width=96,quality=80,format=auto/content-assets/images/20250621_DE_EU.jpg 96w, https://www.economist.com/cdn-cgi/image/width=128,quality=80,format=auto/content-assets/images/20250621_DE_EU.jpg 128w, https://www.economist.com/cdn-cgi/image/width=256,quality=80,format=auto/content-assets/images/20250621_DE_EU.jpg 256w, https://www.economist.com/cdn-cgi/image/width=360,quality=80,format=auto/content-assets/images/20250621_DE_EU.jpg 360w, https://www.economist.com/cdn-cgi/image/width=384,quality=80,format=auto/content-assets/images/20250621_DE_EU.jpg 384w, https://www.economist.com/cdn-cgi/image/width=480,quality=80,format=auto/content-assets/images/20250621_DE_EU.jpg 480w, https://www.economist.com/cdn-cgi/image/width=600,quality=80,format=auto/content-assets/images/20250621_DE_EU.jpg 600w, https://www.economist.com/cdn-cgi/image/width=834,quality=80,format=auto/content-assets/images/20250621_DE_EU.jpg 834w, https://www.economist.com/cdn-cgi/image/width=960,quality=80,format=auto/content-assets/images/20250621_DE_EU.jpg 960w, https://www.economist.com/cdn-cgi/image/width=1096,quality=80,format=auto/content-assets/images/20250621_DE_EU.jpg 1096w, https://www.economist.com/cdn-cgi/image/width=1280,quality=80,format=auto/content-assets/images/20250621_DE_EU.jpg 1280w, https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20250621_DE_EU.jpg 1424w" src="https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20250621_DE_EU.jpg"></figure></div><div orientation="vertical"><h3 orientation="vertical">From the June 21st 2025 edition</h3><p orientation="vertical">Discover stories from this section and more in the list of contents</p><p><a href="https://www.economist.com/weeklyedition/2025-06-21" data-analytics="sidebar:weekly_edition"><span data-testid="right-economist-red-true"><span>‚áí</span></span><span>Explore the edition</span></a></p></div></div><div><a href="https://s100.copyright.com/AppDispatchServlet?publisherName=economist&amp;publication=economist&amp;title=Congestion%20pricing%20in%20Manhattan%20is%20a%20predictable%20success&amp;publicationDate=2025-06-19&amp;contentID=%2Fcontent%2Fh4fjn3h3uueocg9k3stljcsfgngjcvar&amp;type=A&amp;orderBeanReset=TRUE" target="_blank" rel="noreferrer" data-analytics="end_of_article:reuse_this_content"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" data-testid="renew-outline"><path fill="var(--mb-colour-base-chicago-45)" d="M5.1 16.05a8.25 8.25 0 0 1-.825-1.95A7.696 7.696 0 0 1 4 12.05c0-2.233.775-4.133 2.325-5.7C7.875 4.783 9.767 4 12 4h.175l-1.6-1.6 1.4-1.4 4 4-4 4-1.4-1.4 1.6-1.6H12c-1.667 0-3.083.588-4.25 1.763C6.583 8.938 6 10.367 6 12.05c0 .433.05.858.15 1.275.1.417.25.825.45 1.225l-1.5 1.5ZM12.025 23l-4-4 4-4 1.4 1.4-1.6 1.6H12c1.667 0 3.083-.587 4.25-1.762C17.417 15.063 18 13.633 18 11.95c0-.433-.05-.858-.15-1.275-.1-.417-.25-.825-.45-1.225l1.5-1.5c.367.633.642 1.283.825 1.95.183.667.275 1.35.275 2.05 0 2.233-.775 4.133-2.325 5.7C16.125 19.217 14.233 20 12 20h-.175l1.6 1.6-1.4 1.4Z"></path></svg><span>Reuse this content</span></a></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta announces Oakley smart glasses (141 pts)]]></title>
            <link>https://www.theverge.com/news/690133/meta-oakley-hstn-ai-glasses-price-date</link>
            <guid>44327468</guid>
            <pubDate>Fri, 20 Jun 2025 13:17:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/news/690133/meta-oakley-hstn-ai-glasses-price-date">https://www.theverge.com/news/690133/meta-oakley-hstn-ai-glasses-price-date</a>, See on <a href="https://news.ycombinator.com/item?id=44327468">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="zephr-anchor"><p>Meta is announcing its next pair of smart glasses with Oakley. The limited-edition Oakley Meta HSTN (pronounced ‚Äúhow-stuhn‚Äù) model costs $499 and is <a href="https://www.meta.com/ai-glasses/oakley-meta-hstn/">available for preorder</a> starting July 11th. Other Oakley models with Meta‚Äôs tech will be available starting at $399 later this summer. </p><p>Like the <a href="https://www.theverge.com/23922425/ray-ban-meta-smart-glasses-review">existing Meta Ray-Ban glasses</a>, the Oakley model features a front-facing camera, along with open-ear speakers and microphones that are built into the frame. After they are paired with a phone, the glasses can be used to listen to music or podcasts, conduct phone calls, or chat with Meta AI. By utilizing the onboard camera and microphones, Meta AI can also answer <a href="https://www.theverge.com/news/667613/ray-ban-meta-smart-glasses-ai-detailed-responses-call-a-volunteer">questions about what someone is seeing</a> and even <a href="https://www.theverge.com/2025/1/24/24351013/ray-ban-meta-smart-glasses-translation-wearables">translate languages</a>. </p><p>Given the Oakley design, Meta is positioning these new glasses as being geared towards athletes. They have an IPX4 water resistance rating and offer double the battery life of the Meta Ray-Bans, providing 8 hours of use, along with a charging case that can power them for up to 48 hours. The built-in camera now shoots in 3K video, up from 1080p for the Meta Ray-Bans. </p><p>The new lineup comes in five Oakley frame and lens combos, all of which are compatible with prescriptions for an extra cost. The frame colors are warm grey, black, brown smoke, and clear, with several lens options available, including transitions. The limited-edition $499 model, available for order starting July 11th, features gold accents and gold Oakley <a href="https://go.skimresources.com/?id=1025X1701640&amp;xs=1&amp;url=https%3A%2F%2Fwww.oakley.com%2Fen-us%2Flp%2Fprizm" rel="sponsored">PRIZM</a> lenses. The glasses will be on sale in the US, Canada, the UK, Ireland, France, Italy, Spain, Austria, Belgium, Australia, Germany, Sweden, Norway, Finland, and Denmark.</p><p>Meta recently signed a <a href="https://www.theverge.com/24253481/meta-ceo-mark-zuckerberg-ar-glasses-orion-ray-bans-ai-decoder-interview">multi-year deal with EssilorLuxottica</a>, the parent company behind Ray-Ban, Oakley, and other eyewear brands. The Meta Ray-Bans have sold over two million pairs to date, and EssilorLuxottica <a href="https://www.theverge.com/news/613292/meta-ray-ban-2-million-10-million-capacity-subscription-essilor-luxottica-earnings">recently disclosed</a> that it plans to sell 10 million smart glasses with Meta annually by 2026. ‚ÄúThis is our first step into the performance category,‚Äù Alex Himel, Meta‚Äôs head of wearables, tells me. ‚ÄúThere‚Äôs more to come.‚Äù</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Oklo, the Earth's Two-billion-year-old only Known Natural Nuclear Reactor (2018) (146 pts)]]></title>
            <link>https://www.iaea.org/newscenter/news/meet-oklo-the-earths-two-billion-year-old-only-known-natural-nuclear-reactor</link>
            <guid>44326145</guid>
            <pubDate>Fri, 20 Jun 2025 09:52:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.iaea.org/newscenter/news/meet-oklo-the-earths-two-billion-year-old-only-known-natural-nuclear-reactor">https://www.iaea.org/newscenter/news/meet-oklo-the-earths-two-billion-year-old-only-known-natural-nuclear-reactor</a>, See on <a href="https://news.ycombinator.com/item?id=44326145">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>Physicist Francis Perrin sat at a nuclearfuel-processing plant down in the south of France, thinking to himself: ‚ÄúThis cannot be possible.‚Äù It was 1972. On the one hand, there was a dark piece of radioactive natural uranium ore, extracted from a mine in Africa. On the other, accepted scientific data about the constant ratio of radioactive uranium in ore.</p>
<p>Examination of this high-grade ore from a mine in Gabon was found to contain a lower proportion of uranium-235 (U-235) ‚Äî the fissile sort. Only a tiny bit less, but enough to make the researchers sit back and scratch their heads.</p>
<p>The physicists‚Äô first, logical response to such an unusual ratio of U-235 was that this was not natural uranium. All natural uranium today contains 0.720% of U-235. If you were to extract it from the Earth‚Äôs crust, or from rocks from the moon or in meteorites, that‚Äôs what you would find. But that bit of rock from Oklo contained only 0.717%.</p>
<p>What did this mean? At first, all the physicists could think of was that the uranium ore had gone through artificial fission, i.e.&nbsp;that some of the U-235 isotopes had been forced to split in a nuclear chain reaction. This could explain why the ratio was lower than normal.</p>
<p>But after complementary analyses, Perrin and his peers confirmed that the uranium ore was completely natural. Even more bedazzling, they discovered a footprint of fission products in the ore. The conclusion: the uranium ore was natural and had gone through fission. There was only one possible explanation ‚Äî the rock was evidence of natural fission that occurred over two billion years ago.</p>
<p>‚ÄúAfter more studies, including on-site examinations, they discovered that the uranium ore had gone through fission on its own,‚Äù said Ludovic Ferri√®re, curator of the rock collection at Vienna‚Äôs Natural History Museum, where a part of the curious rock will be presented to the public in 2019. ‚ÄúThere was no other explanation.‚Äù</p>
<p>For such a phenomenon to have happened naturally, these uranium deposits in western Equatorial Africa must have had to contain a critical mass of U-235 to start the reaction. Back in those days, they did.</p>
<p>&nbsp;A second contributing factor was that, for a nuclear chain reaction to happen and be maintained, there needed to be a moderator. In this case: water. Without water to slow the neutrons down, controlled fission would not have been possible. The atoms would simply not have split.</p>
<p>‚ÄúLike in a man-made light-water nuclear reactor, the fission reactions, without anything to slow down the neutrons, to moderate them, simply stop,‚Äù said Peter Woods, team leader in charge of uranium production at the IAEA. ‚ÄúThe water acted in Oklo as a moderator, absorbing the neutrons, controlling the chain reaction.‚Äù</p>
<p>The specific geological context in what today is Gabon also helped. The chemical concentrations of total uranium (including U-235) were high enough, and the individual deposits thick and large enough. And, lastly, Oklo managed to survive the passing of time. Experts suspect there may have been other such natural reactors in the world, but these must have been destroyed by geological processes, eroded away or subducted ‚Äî &nbsp;or simply not yet found.&nbsp;</p>
<p>‚ÄúThat‚Äôs what makes it so fascinating: that &nbsp;the circumstances of time, geology, water came together for this to happen at all,‚Äù Woods said. ‚ÄúAnd that it was preserved until today. The detective story has been successfully solved.‚Äù</p>
<p><strong>A rock sample in the IAEA‚Äôs &nbsp;home city</strong></p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I will do anything to end homelessness except build more homes (255 pts)]]></title>
            <link>https://www.mcsweeneys.net/articles/i-will-do-anything-to-end-homelessness-except-build-more-homes</link>
            <guid>44325617</guid>
            <pubDate>Fri, 20 Jun 2025 08:07:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mcsweeneys.net/articles/i-will-do-anything-to-end-homelessness-except-build-more-homes">https://www.mcsweeneys.net/articles/i-will-do-anything-to-end-homelessness-except-build-more-homes</a>, See on <a href="https://news.ycombinator.com/item?id=44325617">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="o-wrapper">
    <main>
        <header>
    <div>
      <div>
          <p><span><img role="none" src="https://www.mcsweeneys.net/assets/search-614fbdcc4e71f0730ad039e484ec78a1085f24294fa0b4514da70b0a930b2dce.svg"></span></p>        </div>
      <div>
        <ul>
          <li><a href="https://www.mcsweeneys.net/">Internet Tendency</a></li>
          <li><a href="https://store.mcsweeneys.net/">The Store</a></li>
          <li><a href="https://store.mcsweeneys.net/t/categories/books">Books Division</a></li>
          <li><a href="https://store.mcsweeneys.net/t/categories/timothy-mcsweeneys-quarterly-concern">Quarterly Concern</a></li>
          <li><a href="https://thebeliever.net/">The Believer</a></li>
          <li><a href="https://www.mcsweeneys.net/donate">Donate</a></li>
        </ul>
      </div>
    </div>
    
  </header>


      
  <div>
    <h6>MCSWEENEY'S QUARTERLY SUBSCRIPTIONS</h6>
    
  </div>


      
<article>
    
   
    <div>
      <p>Homelessness in America has reached crisis levels, and I am determined to do everything in my power to fix the problem as long as it doesn‚Äôt involve changing zoning laws or my ability to drive alone to work or, well, changing anything, really. I‚Äôm more than happy to give a hungry man a sandwich once a year and then brag to my friends about it as long as he doesn‚Äôt sit down anywhere in my line of sight to eat it. Same goes for hungry women because I‚Äôm also a feminist.</p>
<p>This is so important because everyone should have a bed to sleep in at night, and also, nothing destroys property values faster than a desperate person on a sidewalk asking for change. I‚Äôm not saying I don‚Äôt care about human suffering; I just care much, much more about my immediate self-interest because I‚Äôm the kind of person who contributes to society by starting companies that leverage technology to build smart tea kettles that brew themselves while you sleep at night. I‚Äôm a fucking innovator.</p>
<p>I‚Äôm innovating for win-win-whatever solutions where I win, my community wins, and we do whatever to get rid of homelessness. Fixing the problem means lots of things: letters to the editor of my local newspaper, bombastic statements to the press that will make the fruit of my loins cringe for generations, and especially writing vaguely discriminatory, definitely ugly posts on social media about the crisis as it unfolds in my community. Also, I call the police a lot.</p>
<p>Ending homelessness doesn‚Äôt mean building more homes because this town is full of homes already, especially mine, which is a single-family mini-mansion on an acre lot that I inherited from my parents and/or managed to purchase with the kind of job and bank terms and economic equality that don‚Äôt exist anymore for anyone and only ever really existed for well-educated white Americans. Either that or it‚Äôs a magnificent luxury condo with expansive views that I don‚Äôt want marred by more luxury condos or‚Äîgod forbid‚Äîaffordable housing.</p>
<p>Every room in my Instagram-worthy abode is either filled with clutter or rented out nightly to hipsters from another gentrified, monotone city also suffering from a homelessness crisis‚Äîthis is a national epidemic, after all. I‚Äôm a good person, a generous person, and what made me the person I am is having to work hard for everything my parents gave me, and everything I will, in turn, give to my children.</p>
<p>Listen, I know that the unholy concentration of wealth in America is a big, big problem, but so is having to constantly say no to people asking for change as I whizz into Whole Foods in my Tesla or Prius (depending on how my startup investments pan out). What‚Äôs the point of having all this money if I have to feel bad about it? Also, has anyone actually verified that the homeless people claiming to be veterans aren‚Äôt just pulling some elaborate fraud? I‚Äôve never actually met a veteran and I forget for, like, decades at a time that the military even exists because the bubble of privilege where I reside is literally impregnable, but I‚Äôm suspicious nonetheless.</p>
<p>I know we need more housing, but I was here first, and I‚Äôm not giving up even one blade of grass on my water-guzzling, pesticide-leaching lawn or a single burner on my twelve-burner Viking range that I never actually use to house another human soul. Tough luck, homeless people. You and your allies can call me names, but I won‚Äôt hear you over the lushness of my climate-inappropriate rose bushes and the stucco walls I‚Äôm paying some desperate immigrant under the table to build for me on the cheap before I low-key call <span>ICE</span> and have them deported.</p>
<p>Look, if you give people homes, the next thing you know, they‚Äôre going to start to get their lives together and then get jobs and start organizing. Then they‚Äôll expand Medicare to everyone and build a fucking light rail line instead of a goddamn border wall, and no one will drive anymore, and cars will die out, and the air will get clean, and can you imagine the problems we‚Äôll have then?</p>
<p>No. Stop it with the new housing; I‚Äôd rather have a homeless crisis.</p>
    </div>
    

    <div>
    <p>
        Please help support our writers and keep our site ad-free by becoming a patron.
    </p>
    
  </div>

  

  

</article>

    


      <div>
        <h5>Suggested Reads</h5>
        <ul>
            <li>
    <a href="https://www.mcsweeneys.net/articles/have-you-been-the-victim-of-a-vaccine-mandate-if-so-you-may-be-entitled">
      <p>November 22, 2021</p>
      <p>Have You Been the Victim of a Vaccine Mandate? If So, You May Be Entitled</p>
</a>      
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/in-this-housing-market-ill-never-be-able-to-afford-to-haunt-my-own-home">
      <p>October 21, 2022</p>
      <p>In This Housing Market, I‚Äôll Never Be Able to Afford to Haunt My Own Home</p>
</a>      <p><span>by </span>Zoe Pearl</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/how-could-i-be-privileged-when-my-family-didnt-have-a-housekeeper-for-our-ocean-front-home">
      <p>March  9, 2018</p>
      <p>How Could I Be Privileged When My Family Didn‚Äôt Have a Housekeeper for Our Ocean Front Home?</p>
</a>      <p><span>by </span>Arianna Durnell</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/my-remote-job-gives-me-the-freedom-to-displace-people-all-over-the-world">
      <p>September  8, 2022</p>
      <p>My Remote Job Gives Me the Freedom to Displace People All Over the World</p>
</a>      <p><span>by </span>Henry Block</p>
  </li>

        </ul>
      </div>


  <section>
        <div>
      <h5>Trending üî•</h5>
      <ol>
          <li>
    <a href="https://www.mcsweeneys.net/articles/congrats-dipshit-youre-a-dad-now">
      <p>June 13, 2025</p>
      <p>Congrats, Dipshit,  You‚Äôre a Dad Now</p>
</a>      <p><span>by </span>Carlos Greaves</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/i-saruman-have-ended-my-alliance-with-the-dark-lord-sauron">
      <p>June  6, 2025</p>
      <p>I, Saruman, Have Ended My Alliance with the Dark Lord Sauron</p>
</a>      <p><span>by </span>Carlos Greaves</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/what-a-straight-mans-favorite-musical-says-about-him">
      <p>February 10, 2015</p>
      <p>What a Straight Man‚Äôs Favorite Musical Says About Him</p>
</a>      <p><span>by </span>Mara Wilson</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/its-not-going-great-but-imagine-how-much-worse-things-would-be-with-a-woman-president">
      <p>June  9, 2025</p>
      <p>It‚Äôs Not Going Great, but Imagine How Much Worse Things Would Be with a Woman President</p>
</a>      <p><span>by </span>Talia Argondezzi</p>
  </li>

      </ol>
    </div>

      <div>
    <h5>Recently</h5>
    <ul>
        <li>
    <a href="https://www.mcsweeneys.net/articles/the-revolution-will-not-be-televised-but-it-will-be-optimized-presented-in-beta">
      <p>June 19, 2025</p>
      <p>The Revolution Will Not Be Televised, But It Will Be Optimized (Presented in Beta)</p>
</a>      <p><span>by </span>David Shih</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/i-am-your-body-and-i-am-done-keeping-score">
      <p>June 18, 2025</p>
      <p>I Am Your Body and I Am Done Keeping Score</p>
</a>      <p><span>by </span>Madeleine Trebenski</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/the-trump-playbook-for-brokering-peace-between-israel-and-iran">
      <p>June 18, 2025</p>
      <p>The Trump Playbook for Brokering Peace Between Israel and Iran</p>
</a>      <p><span>by </span>Dash M<span>ac</span>Intyre</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/ive-figured-out-what-my-mayoral-run-is-missing-i-need-to-start-sexually-harassing-women">
      <p>June 17, 2025</p>
      <p>I‚Äôve Figured Out What My Mayoral Run Is Missing: I Need to Start Sexually Harassing Women</p>
</a>      <p><span>by </span>Jessica M. Goldstein</p>
  </li>

    </ul>
  </div>

  </section>


    
  


    
  
  
  




        

    </main>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Learn Makefiles (238 pts)]]></title>
            <link>https://makefiletutorial.com/</link>
            <guid>44325611</guid>
            <pubDate>Fri, 20 Jun 2025 08:05:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://makefiletutorial.com/">https://makefiletutorial.com/</a>, See on <a href="https://news.ycombinator.com/item?id=44325611">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="right">
                                <p><b>I built this guide because I could never quite wrap my head around Makefiles.</b> They seemed awash with hidden rules and esoteric symbols, and asking simple questions didn‚Äôt yield simple answers. To solve this, I sat down for several weekends and read everything I could about Makefiles. I've condensed the most critical knowledge into this guide. Each topic has a brief description and a self contained example that you can run yourself.</p>
<p>If you mostly understand Make, consider checking out the <a href="#makefile-cookbook">Makefile Cookbook</a>, which has a template for medium sized projects with ample comments about what each part of the Makefile is doing.</p>
<p>Good luck, and I hope you are able to slay the confusing world of Makefiles!</p>
<h2 id="getting-started">Getting Started</h2>
<h2 id="why-do-makefiles-exist">Why do Makefiles exist?</h2>
<p>Makefiles are used to help decide which parts of a large program need to be recompiled. In the vast majority of cases, C or C++ files are compiled. Other languages typically have their own tools that serve a similar purpose as Make. Make can also be used beyond compilation too, when you need a series of instructions to run depending on what files have changed. This tutorial will focus on the C/C++ compilation use case.</p>
<p>Here's an example dependency graph that you might build with Make. If any file's dependencies changes, then the file will get recompiled:</p>
<p><img src="https://makefiletutorial.com/assets/dependency_graph.png">
</p>

<h2 id="what-alternatives-are-there-to-make">What alternatives are there to Make?</h2>
<p>Popular C/C++ alternative build systems are <a href="https://scons.org/">SCons</a>, <a href="https://cmake.org/">CMake</a>, <a href="https://bazel.build/">Bazel</a>, and <a href="https://ninja-build.org/">Ninja</a>. Some code editors like <a href="https://visualstudio.microsoft.com/">Microsoft Visual Studio</a> have their own built in build tools. For Java, there's <a href="https://ant.apache.org/">Ant</a>, <a href="https://maven.apache.org/what-is-maven.html">Maven</a>, and <a href="https://gradle.org/">Gradle</a>. Other languages like Go, Rust, and TypeScript have their own build tools.</p>
<p>Interpreted languages like Python, Ruby, and raw Javascript don't require an analogue to Makefiles. The goal of Makefiles is to compile whatever files need to be compiled, based on what files have changed. But when files in interpreted languages change, nothing needs to get recompiled. When the program runs, the most recent version of the file is used.</p>
<h2 id="the-versions-and-types-of-make">The versions and types of Make</h2>
<p>There are a variety of implementations of Make, but most of this guide will work on whatever version you're using. However, it's specifically written for GNU Make, which is the standard implementation on Linux and MacOS. All the examples work for Make versions 3 and 4, which are nearly equivalent other than some esoteric differences.</p>
<h2 id="running-the-examples">Running the Examples</h2>
<p>To run these examples, you'll need a terminal and "make" installed. For each example, put the contents in a file called <code>Makefile</code>, and in that directory run the command <code>make</code>. Let's start with the simplest of Makefiles:</p>
<pre><code><span>hello:</span>
	echo <span>"Hello, World"</span></code></pre>
<blockquote>
<p>Note: Makefiles <strong>must</strong> be indented using TABs and not spaces or <code>make</code> will fail.</p>
</blockquote>
<p>Here is the output of running the above example:</p>
<pre><code><span>$</span><span> make</span>
echo "Hello, World"
Hello, World</code></pre>
<p>That's it! If you're a bit confused, here's a video that goes through these steps, along with describing the basic structure of Makefiles.</p>
<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/zeEMISsjO38" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<h2 id="makefile-syntax">Makefile Syntax</h2>
<p>A Makefile consists of a set of <em>rules</em>. A rule generally looks like this:</p>
<pre><code><span>targets: prerequisites</span>
	command
	command
	command</code></pre>
<ul>
<li>The <em>targets</em> are file names, separated by spaces. Typically, there is only one per rule.</li>
<li>The <em>commands</em> are a series of steps typically used to make the target(s). These <em>need to start with a tab character</em>, not spaces.</li>
<li>The <em>prerequisites</em> are also file names, separated by spaces. These files need to exist before the commands for the target are run. These are also called <em>dependencies</em></li>
</ul>
<h2 id="the-essence-of-make">The essence of Make</h2>
<p>Let's start with a hello world example:</p>
<pre><code><span>hello:</span>
	echo <span>"Hello, World"</span>
	echo <span>"This line will print if the file hello does not exist."</span></code></pre>
<p>There's already a lot to take in here. Let's break it down:</p>
<ul>
<li>We have one <em>target</em> called <code>hello</code></li>
<li>This target has two <em>commands</em></li>
<li>This target has no <em>prerequisites</em></li>
</ul>
<p>We'll then run <code>make hello</code>. As long as the <code>hello</code> file does not exist, the commands will run. If <code>hello</code> does exist, no commands will run.</p>
<p>It's important to realize that I'm talking about <code>hello</code> as both a <em>target</em> and a <em>file</em>. That's because the two are directly tied together. Typically, when a target is run (aka when the commands of a target are run), the commands will create a file with the same name as the target. In this case, the <code>hello</code> <em>target</em> does not create the <code>hello</code> <em>file</em>.</p>
<p>Let's create a more typical Makefile - one that compiles a single C file. But before we do, make a file called <code>blah.c</code> that has the following contents:</p>
<pre><code><span>// blah.c</span>
<span><span>int</span> <span>main</span><span>()</span> </span>{ <span>return</span> <span>0</span>; }</code></pre>
<p>Then create the Makefile (called <code>Makefile</code>, as always):</p>
<pre><code><span>blah:</span>
	cc blah.c -o blah</code></pre>
<p>This time, try simply running <code>make</code>. Since there's no target supplied as an argument to the <code>make</code> command, the first target is run. In this case, there's only one target (<code>blah</code>). The first time you run this, <code>blah</code> will be created. The second time, you'll see <code>make: 'blah' is up to date</code>. That's because the <code>blah</code> file already exists. But there's a problem: if we modify <code>blah.c</code> and then run <code>make</code>, nothing gets recompiled.</p>
<p>We solve this by adding a prerequisite:</p>
<pre><code><span>blah: blah.c</span>
	cc blah.c -o blah</code></pre>
<p>When we run <code>make</code> again, the following set of steps happens:</p>
<ul>
<li>The first target is selected, because the first target is the default target</li>
<li>This has a prerequisite of <code>blah.c</code></li>
<li>Make decides if it should run the <code>blah</code> target. It will only run if <code>blah</code> doesn't exist, or <code>blah.c</code> is <em>newer than</em> <code>blah</code></li>
</ul>
<p>This last step is critical, and is the <strong>essence of make</strong>. What it's attempting to do is decide if the prerequisites of <code>blah</code> have changed since <code>blah</code> was last compiled. That is, if <code>blah.c</code> is modified, running <code>make</code> should recompile the file. And conversely, if <code>blah.c</code> has not changed, then it should not be recompiled.</p>
<p>To make this happen, it uses the filesystem timestamps as a proxy to determine if something has changed. This is a reasonable heuristic, because file timestamps typically will only change if the files are
modified. But it's important to realize that this isn't always the case. You could, for example, modify a file, and then change the modified timestamp of that file to something old. If you did, Make would incorrectly guess that the file hadn't changed and thus could be ignored.</p>
<p>Whew, what a mouthful. <strong>Make sure that you understand this. It's the crux of Makefiles, and might take you a few minutes to properly understand</strong>. Play around with the above examples or watch the video above if things are still confusing.</p>
<h2 id="more-quick-examples">More quick examples</h2>
<p>The following Makefile ultimately runs all three targets. When you run <code>make</code> in the terminal, it will build a program called <code>blah</code> in a series of steps:</p>
<ul>
<li>Make selects the target <code>blah</code>, because the first target is the default target</li>
<li><code>blah</code> requires <code>blah.o</code>, so make searches for the <code>blah.o</code> target</li>
<li><code>blah.o</code> requires <code>blah.c</code>, so make searches for the <code>blah.c</code> target</li>
<li><code>blah.c</code> has no dependencies, so the <code>echo</code> command is run</li>
<li>The <code>cc -c</code> command is then run, because all of the <code>blah.o</code> dependencies are finished</li>
<li>The top <code>cc</code> command is run, because all the <code>blah</code> dependencies are finished</li>
<li>That's it: <code>blah</code> is a compiled c program</li>
</ul>
<pre><code><span>blah: blah.o</span>
	cc blah.o -o blah <span># Runs third</span>

<span>blah.o: blah.c</span>
	cc -c blah.c -o blah.o <span># Runs second</span>

<span># Typically blah.c would already exist, but I want to limit any additional required files</span>
<span>blah.c:</span>
	echo <span>"int main() { return 0; }"</span> &gt; blah.c <span># Runs first</span></code></pre>
<p>If you delete <code>blah.c</code>, all three targets will be rerun. If you edit it (and thus change the timestamp to newer than <code>blah.o</code>), the first two targets will run. If you run <code>touch blah.o</code> (and thus change the timestamp to newer than <code>blah</code>), then only the first target will run. If you change nothing, none of the targets will run. Try it out!</p>
<p>This next example doesn't do anything new, but is nontheless a good additional example. It will always run both targets, because <code>some_file</code> depends on <code>other_file</code>, which is never created.</p>
<pre><code><span>some_file: other_file</span>
	echo <span>"This will always run, and runs second"</span>
	touch some_file

<span>other_file:</span>
	echo <span>"This will always run, and runs first"</span></code></pre>
<h2 id="make-clean">Make clean</h2>
<p><code>clean</code> is often used as a target that removes the output of other targets, but it is not a special word in Make. You can run <code>make</code> and <code>make clean</code> on this to create and delete <code>some_file</code>.</p>
<p>Note that <code>clean</code> is doing two new things here:</p>
<ul>
<li>It's a target that is not first (the default), and not a prerequisite. That means it'll never run unless you explicitly call <code>make clean</code></li>
<li>It's not intended to be a filename. If you happen to have a file named <code>clean</code>, this target won't run, which is not what we want. See <code>.PHONY</code> later in this tutorial on how to fix this</li>
</ul>
<pre><code><span>some_file: </span>
	touch some_file

<span>clean:</span>
	rm -f some_file</code></pre>
<h2 id="variables">Variables</h2>
<p>Variables can only be strings. You'll typically want to use <code>:=</code>, but <code>=</code> also works. See <a href="#variables-pt-2">Variables Pt 2</a>.</p>
<p>Here's an example of using variables:</p>
<pre><code>files := file1 file2
<span>some_file: <span>$(files)</span></span>
	echo <span>"Look at this variable: "</span> <span>$(files)</span>
	touch some_file

<span>file1:</span>
	touch file1
<span>file2:</span>
	touch file2

<span>clean:</span>
	rm -f file1 file2 some_file</code></pre>
<p>Single or double quotes have no meaning to Make. They are simply characters that are assigned to the variable. Quotes <em>are</em> useful to shell/bash, though, and you need them in commands like <code>printf</code>. In this example, the two commands behave the same:</p>
<pre><code>a := one two<span># a is set to the string "one two"</span>
b := 'one two' <span># Not recommended. b is set to the string "'one two'"</span>
<span>all:</span>
	printf '$a'
	printf $b</code></pre>
<p>Reference variables using either <code>${}</code> or <code>$()</code></p>
<pre><code>x := dude

<span>all:</span>
	echo <span>$(x)</span>
	echo ${x}

	<span># Bad practice, but works</span>
	echo $x </code></pre>
<h2 id="targets">Targets</h2>
<h2 id="the-all-target">The all target</h2>
<!--  (Section 4.4) -->
<p>Making multiple targets and you want all of them to run? Make an <code>all</code> target.
Since this is the first rule listed, it will run by default if <code>make</code> is called without specifying a target.</p>
<pre><code><span>all: one two three</span>

<span>one:</span>
	touch one
<span>two:</span>
	touch two
<span>three:</span>
	touch three

<span>clean:</span>
	rm -f one two three
</code></pre>
<h2 id="multiple-targets">Multiple targets</h2>
<!--  (Section 4.8) -->
<p>When there are multiple targets for a rule, the commands will be run for each target. <code>$@</code> is an <a href="#automatic-variables">automatic variable</a> that contains the target name.</p>
<pre><code><span>all: f1.o f2.o</span>

f1.o f2.o:
	echo <span>$@</span>
<span># Equivalent to:</span>
<span># f1.o:</span>
<span>#	 echo f1.o</span>
<span># f2.o:</span>
<span>#	 echo f2.o</span>
</code></pre>
<h2 id="automatic-variables-and-wildcards">Automatic Variables and Wildcards</h2>
<h2 id="-wildcard">* Wildcard</h2>
<!--  (Section 4.2) -->
<p>Both <code>*</code> and <code>%</code> are called wildcards in Make, but they mean entirely different things. <code>*</code> searches your filesystem for matching filenames. I suggest that you always wrap it in the <code>wildcard</code> function, because otherwise you may fall into a common pitfall described below.</p>
<pre><code><span># Print out file information about every .c file</span>
<span>print: $(wildcard *.c)</span>
	ls -la  <span>$?</span></code></pre>
<p><code>*</code> may be used in the target, prerequisites, or in the <code>wildcard</code> function.</p>
<p>Danger: <code>*</code> may not be directly used in a variable definitions</p>
<p>Danger: When <code>*</code> matches no files, it is left as it is (unless run in the <code>wildcard</code> function)</p>
<pre><code>thing_wrong := *.o <span># Don't do this! '*' will not get expanded</span>
thing_right := <span>$(<span>wildcard</span> *.o)</span>

<span>all: one two three four</span>

<span># Fails, because $(thing_wrong) is the string "*.o"</span>
<span>one: <span>$(thing_wrong)</span></span>

<span># Stays as *.o if there are no files that match this pattern :(</span>
<span>two: *.o </span>

<span># Works as you would expect! In this case, it does nothing.</span>
<span>three: <span>$(thing_right)</span></span>

<span># Same as rule three</span>
<span>four: $(wildcard *.o)</span></code></pre>
<h2 id="-wildcard-1">% Wildcard</h2>
<p><code>%</code> is really useful, but is somewhat confusing because of the variety of situations it can be used in.</p>
<ul>
<li>When used in "matching" mode, it matches one or more characters in a string. This match is called the stem.</li>
<li>When used in "replacing" mode, it takes the stem that was matched and replaces that in a string.</li>
<li><code>%</code> is most often used in rule definitions and in some specific functions.</li>
</ul>
<p>See these sections on examples of it being used:</p>
<ul>
<li><a href="#static-pattern-rules">Static Pattern Rules</a></li>
<li><a href="#pattern-rules">Pattern Rules</a></li>
<li><a href="#string-substitution">String Substitution</a></li>
<li><a href="#the-vpath-directive">The vpath Directive</a></li>
</ul>
<h2 id="automatic-variables">Automatic Variables</h2>
<!--  (Section 10.5) -->
<p>There are many <a href="https://www.gnu.org/software/make/manual/html_node/Automatic-Variables.html">automatic variables</a>, but often only a few show up:</p>
<pre><code><span>hey: one two</span>
	<span># Outputs "hey", since this is the target name</span>
	echo <span>$@</span>

	<span># Outputs all prerequisites newer than the target</span>
	echo <span>$?</span>

	<span># Outputs all prerequisites</span>
	echo <span>$^</span>

	<span># Outputs the first prerequisite</span>
	echo <span>$&lt;</span>

	touch hey

<span>one:</span>
	touch one

<span>two:</span>
	touch two

<span>clean:</span>
	rm -f hey one two
</code></pre>
<h2 id="fancy-rules">Fancy Rules</h2>
<h2 id="implicit-rules">Implicit Rules</h2>
<!--  (Section 10) -->
<p>Make loves c compilation. And every time it expresses its love, things get confusing. Perhaps the most confusing part of Make is the magic/automatic rules that are made. Make calls these "implicit" rules. I don't personally agree with this design decision, and I don't recommend using them, but they're often used and are thus useful to know. Here's a list of implicit rules:</p>
<ul>
<li>Compiling a C program: <code>n.o</code> is made automatically from <code>n.c</code> with a command of the form <code>$(CC) -c $(CPPFLAGS) $(CFLAGS) $^ -o $@</code></li>
<li>Compiling a C++ program: <code>n.o</code> is made automatically from <code>n.cc</code> or <code>n.cpp</code> with a command of the form <code>$(CXX) -c $(CPPFLAGS) $(CXXFLAGS) $^ -o $@</code></li>
<li>Linking a single object file: <code>n</code> is made automatically from <code>n.o</code> by running the command <code>$(CC) $(LDFLAGS) $^ $(LOADLIBES) $(LDLIBS) -o $@</code></li>
</ul>
<p>The important variables used by implicit rules are:</p>
<ul>
<li><code>CC</code>: Program for compiling C programs; default <code>cc</code></li>
<li><code>CXX</code>: Program for compiling C++ programs; default <code>g++</code></li>
<li><code>CFLAGS</code>: Extra flags to give to the C compiler</li>
<li><code>CXXFLAGS</code>: Extra flags to give to the C++ compiler</li>
<li><code>CPPFLAGS</code>: Extra flags to give to the C preprocessor</li>
<li><code>LDFLAGS</code>: Extra flags to give to compilers when they are supposed to invoke the linker</li>
</ul>
<p>Let's see how we can now build a C program without ever explicitly telling Make how to do the compilation:</p>
<pre><code>CC = gcc <span># Flag for implicit rules</span>
CFLAGS = -g <span># Flag for implicit rules. Turn on debug info</span>

<span># Implicit rule #1: blah is built via the C linker implicit rule</span>
<span># Implicit rule #2: blah.o is built via the C compilation implicit rule, because blah.c exists</span>
<span>blah: blah.o</span>

<span>blah.c:</span>
	echo <span>"int main() { return 0; }"</span> &gt; blah.c

<span>clean:</span>
	rm -f blah*</code></pre>
<h2 id="static-pattern-rules">Static Pattern Rules</h2>
<!--  (Section 4.10) -->
<p>Static pattern rules are another way to write less in a Makefile. Here's their syntax:</p>
<pre><code><span>targets...: target-pattern: prereq-patterns ...</span>
   commands</code></pre>
<p>The essence is that the given <code>target</code> is matched by the <code>target-pattern</code> (via a <code>%</code> wildcard). Whatever was matched is called the <em>stem</em>. The stem is then substituted into the <code>prereq-pattern</code>, to generate the target's prereqs.</p>
<p>A typical use case is to compile <code>.c</code> files into <code>.o</code> files. Here's the <em>manual way</em>:</p>
<pre><code>objects = foo.o bar.o all.o
<span>all: <span>$(objects)</span></span>
	<span>$(CC)</span> <span>$^</span> -o all

<span>foo.o: foo.c</span>
	<span>$(CC)</span> -c foo.c -o foo.o

<span>bar.o: bar.c</span>
	<span>$(CC)</span> -c bar.c -o bar.o

<span>all.o: all.c</span>
	<span>$(CC)</span> -c all.c -o all.o

<span>all.c:</span>
	echo <span>"int main() { return 0; }"</span> &gt; all.c

<span># Note: all.c does not use this rule because Make prioritizes more specific matches when there is more than one match.</span>
<span>%.c:</span>
	touch <span>$@</span>

<span>clean:</span>
	rm -f *.c *.o all</code></pre>
<p>Here's the more <em>efficient way</em>, using a static pattern rule:</p>
<pre><code>objects = foo.o bar.o all.o
<span>all: <span>$(objects)</span></span>
	<span>$(CC)</span> <span>$^</span> -o all

<span># Syntax - targets ...: target-pattern: prereq-patterns ...</span>
<span># In the case of the first target, foo.o, the target-pattern matches foo.o and sets the "stem" to be "foo".</span>
<span># It then replaces the '%' in prereq-patterns with that stem</span>
<span>$(objects)</span>: %.o: %.c
	<span>$(CC)</span> -c <span>$^</span> -o <span>$@</span>

<span>all.c:</span>
	echo <span>"int main() { return 0; }"</span> &gt; all.c

<span># Note: all.c does not use this rule because Make prioritizes more specific matches when there is more than one match.</span>
<span>%.c:</span>
	touch <span>$@</span>

<span>clean:</span>
	rm -f *.c *.o all</code></pre>
<h2 id="static-pattern-rules-and-filter">Static Pattern Rules and Filter</h2>
<!--  (Section 4.10) -->
<p>While I introduce the <a href="#the-filter-function">filter function</a> later on, it's common to use in static pattern rules, so I'll mention that here. The <code>filter</code> function can be used in Static pattern rules to match the correct files. In this example, I made up the <code>.raw</code> and <code>.result</code> extensions.</p>
<pre><code>obj_files = foo.result bar.o lose.o
src_files = foo.raw bar.c lose.c

<span>all: <span>$(obj_files)</span></span>
<span># Note: PHONY is important here. Without it, implicit rules will try to build the executable "all", since the prereqs are ".o" files.</span>
<span><span>.PHONY</span>: all </span>

<span># Ex 1: .o files depend on .c files. Though we don't actually make the .o file.</span>
<span>$(<span>filter</span> %.o,<span>$(obj_files)</span>)</span>: %.o: %.c
	echo <span>"target: <span>$@</span> prereq: <span>$&lt;</span>"</span>

<span># Ex 2: .result files depend on .raw files. Though we don't actually make the .result file.</span>
<span>$(<span>filter</span> %.result,<span>$(obj_files)</span>)</span>: %.result: %.raw
	echo <span>"target: <span>$@</span> prereq: <span>$&lt;</span>"</span> 

%.c %.raw:
	touch <span>$@</span>

<span>clean:</span>
	rm -f <span>$(src_files)</span></code></pre>
<h2 id="pattern-rules">Pattern Rules</h2>
<p>Pattern rules are often used but quite confusing. You can look at them as two ways:</p>
<ul>
<li>A way to define your own implicit rules</li>
<li>A simpler form of static pattern rules</li>
</ul>
<p>Let's start with an example first:</p>
<pre><code><span># Define a pattern rule that compiles every .c file into a .o file</span>
%.o : %.c
		<span>$(CC)</span> -c <span>$(CFLAGS)</span> <span>$(CPPFLAGS)</span> <span>$&lt;</span> -o <span>$@</span></code></pre>
<p>Pattern rules contain a '%' in the target. This '%' matches any nonempty string, and the other characters match themselves. ‚Äò%‚Äô in a prerequisite of a pattern rule stands for the same stem that was matched by the ‚Äò%‚Äô in the target.</p>
<p>Here's another example:</p>
<pre><code><span># Define a pattern rule that has no pattern in the prerequisites.</span>
<span># This just creates empty .c files when needed.</span>
<span>%.c:</span>
   touch <span>$@</span></code></pre>
<h2 id="double-colon-rules">Double-Colon Rules</h2>
<!--  (Section 4.11) -->
<p>Double-Colon Rules are rarely used, but allow multiple rules to be defined for the same target. If these were single colons, a warning would be printed and only the second set of commands would run.</p>
<pre><code><span>all: blah</span>

<span>blah::</span>
	echo <span>"hello"</span>

<span>blah::</span>
	echo <span>"hello again"</span></code></pre>
<h2 id="commands-and-execution">Commands and execution</h2>
<h2 id="command-echoingsilencing">Command Echoing/Silencing</h2>
<!--  (Section 5.1) -->
<p>Add an <code>@</code> before a command to stop it from being printed<br>You can also run make with <code>-s</code> to add an <code>@</code> before each line  </p>
<pre><code><span>all: </span>
	@echo <span>"This make line will not be printed"</span>
	echo <span>"But this will"</span></code></pre>
<h2 id="command-execution">Command Execution</h2>
<!--  (Section 5.2) -->
<p>Each command is run in a new shell (or at least the effect is as such)</p>
<pre><code><span>all: </span>
	cd ..
	<span># The cd above does not affect this line, because each command is effectively run in a new shell</span>
	echo `pwd`

	<span># This cd command affects the next because they are on the same line</span>
	cd ..;echo `pwd`

	<span># Same as above</span>
	cd ..; \
	echo `pwd`
</code></pre>
<h2 id="default-shell">Default Shell</h2>
<!--  (Section 5.2) -->
<p>The default shell is <code>/bin/sh</code>. You can change this by changing the variable SHELL:</p>
<pre><code>SHELL=/bin/bash

<span>cool:</span>
	echo <span>"Hello from bash"</span></code></pre>
<h2 id="double-dollar-sign">Double dollar sign</h2>
<p>If you want a string to have a dollar sign, you can use <code>$$</code>. This is how to use a shell variable in <code>bash</code> or <code>sh</code>.</p>
<p>Note the differences between Makefile variables and Shell variables in this next example.</p>
<pre><code>make_var = I am a make variable
<span>all:</span>
	<span># Same as running "sh_var='I am a shell variable'; echo $sh_var" in the shell</span>
	sh_var='I am a shell variable'; echo $$sh_var

	<span># Same as running "echo I am a make variable" in the shell</span>
	echo <span>$(make_var)</span></code></pre>
<h2 id="error-handling-with--k--i-and--">Error handling with <code>-k</code>, <code>-i</code>, and <code>-</code></h2>
<!--  (Section 5.4) -->
<p>Add <code>-k</code> when running make to continue running even in the face of errors. Helpful if you want to see all the errors of Make at once.<br>Add a <code>-</code> before a command to suppress the error<br>Add <code>-i</code> to make to have this happen for every command.</p>
<!--  (Section 5.4) -->
<pre><code><span>one:</span>
	<span># This error will be printed but ignored, and make will continue to run</span>
	-false
	touch one
</code></pre>
<h2 id="interrupting-or-killing-make">Interrupting or killing make</h2>
<!--  (Section 5.5) -->
<p>Note only: If you <code>ctrl+c</code> make, it will delete the newer targets it just made.</p>
<h2 id="recursive-use-of-make">Recursive use of make</h2>
<!--  (Section 5.6) -->
<p>To recursively call a makefile, use the special <code>$(MAKE)</code> instead of <code>make</code> because it will pass the make flags for you and won't itself be affected by them.</p>
<pre><code>new_contents = <span>"hello:\n\ttouch inside_file"</span>
<span>all:</span>
	mkdir -p subdir
	printf <span>$(new_contents)</span> | sed -e 's/^ //' &gt; subdir/makefile
	cd subdir &amp;&amp; <span>$(MAKE)</span>

<span>clean:</span>
	rm -rf subdir
</code></pre>
<h2 id="export-environments-and-recursive-make">Export, environments, and recursive make</h2>
<!--  (Section 5.6) -->
<p>When Make starts, it automatically creates Make variables out of all the environment variables that are set when it's executed.</p>
<pre><code><span># Run this with "export shell_env_var='I am an environment variable'; make"</span>
<span>all:</span>
	<span># Print out the Shell variable</span>
	echo $$shell_env_var

	<span># Print out the Make variable</span>
	echo <span>$(shell_env_var)</span></code></pre>
<p>The <code>export</code> directive takes a variable and sets it the environment for all shell commands in all the recipes:</p>
<pre><code>shell_env_var=Shell env var, created inside of Make
<span>export</span> shell_env_var
<span>all:</span>
	echo <span>$(shell_env_var)</span>
	echo $$shell_env_var</code></pre>
<p>As such, when you run the <code>make</code> command inside of make, you can use the <code>export</code> directive to make it accessible to sub-make commands. In this example, <code>cooly</code> is exported such that the makefile in subdir can use it.</p>
<pre><code>new_contents = <span>"hello:\n\techo \$<span>$(cooly)</span>"</span>

<span>all:</span>
	mkdir -p subdir
	printf <span>$(new_contents)</span> | sed -e 's/^ //' &gt; subdir/makefile
	@echo <span>"---MAKEFILE CONTENTS---"</span>
	@cd subdir &amp;&amp; cat makefile
	@echo <span>"---END MAKEFILE CONTENTS---"</span>
	cd subdir &amp;&amp; <span>$(MAKE)</span>

<span># Note that variables and exports. They are set/affected globally.</span>
cooly = <span>"The subdirectory can see me!"</span>
<span>export</span> cooly
<span># This would nullify the line above: unexport cooly</span>

<span>clean:</span>
	rm -rf subdir</code></pre>
<!--  (Section 5.6) -->
<p>You need to export variables to have them run in the shell as well.  </p>
<pre><code>one=this will only work locally
<span>export</span> two=we can run subcommands with this

<span>all: </span>
	@echo <span>$(one)</span>
	@echo $$one
	@echo <span>$(two)</span>
	@echo $$two</code></pre>
<!--  (Section 5.6) -->
<p><code>.EXPORT_ALL_VARIABLES</code> exports all variables for you.</p>
<pre><code><span>.EXPORT_ALL_VARIABLES:</span>
new_contents = <span>"hello:\n\techo \$<span>$(cooly)</span>"</span>

cooly = <span>"The subdirectory can see me!"</span>
<span># This would nullify the line above: unexport cooly</span>

<span>all:</span>
	mkdir -p subdir
	printf <span>$(new_contents)</span> | sed -e 's/^ //' &gt; subdir/makefile
	@echo <span>"---MAKEFILE CONTENTS---"</span>
	@cd subdir &amp;&amp; cat makefile
	@echo <span>"---END MAKEFILE CONTENTS---"</span>
	cd subdir &amp;&amp; <span>$(MAKE)</span>

<span>clean:</span>
	rm -rf subdir</code></pre>
<h2 id="arguments-to-make">Arguments to make</h2>
<!--  (Section 9) -->

<p>There's a nice <a href="http://www.gnu.org/software/make/manual/make.html#Options-Summary">list of options</a> that can be run from make. Check out <code>--dry-run</code>, <code>--touch</code>, <code>--old-file</code>. </p>
<p>You can have multiple targets to make, i.e. <code>make clean run test</code> runs the <code>clean</code> goal, then <code>run</code>, and then <code>test</code>.</p>
<h2 id="variables-pt-2">Variables Pt. 2</h2>
<h2 id="flavors-and-modification">Flavors and modification</h2>
<!-- (6.1, 6.2, 6.3) -->
<p>There are two flavors of variables:  </p>
<ul>
<li>recursive (use <code>=</code>) - only looks for the variables when the command is <em>used</em>, not when it's <em>defined</em>.  </li>
<li>simply expanded (use <code>:=</code>) - like normal imperative programming -- only those defined so far get expanded</li>
</ul>
<pre><code><span># Recursive variable. This will print "later" below</span>
one = one ${later_variable}
<span># Simply expanded variable. This will not print "later" below</span>
two := two ${later_variable}

later_variable = later

<span>all: </span>
	echo <span>$(one)</span>
	echo <span>$(two)</span></code></pre>
<p>Simply expanded (using <code>:=</code>) allows you to append to a variable. Recursive definitions will give an infinite loop error.  </p>
<pre><code>one = hello
<span># one gets defined as a simply expanded variable (:=) and thus can handle appending</span>
one := ${one} there

<span>all: </span>
	echo <span>$(one)</span></code></pre>
<p><code>?=</code> only sets variables if they have not yet been set</p>
<pre><code>one = hello
one ?= will not be set
two ?= will be set

<span>all: </span>
	echo <span>$(one)</span>
	echo <span>$(two)</span></code></pre>
<p>Spaces at the end of a line are not stripped, but those at the start are. To make a variable with a single space, use <code>$(nullstring)</code></p>
<pre><code>with_spaces = hello   <span># with_spaces has many spaces after "hello"</span>
after = <span>$(with_spaces)</span>there

nullstring =
space = <span>$(nullstring)</span> <span># Make a variable with a single space.</span>

<span>all: </span>
	echo <span>"<span>$(after)</span>"</span>
	echo start<span>"<span>$(space)</span>"</span>end</code></pre>
<p>An undefined variable is actually an empty string!</p>
<pre><code><span>all: </span>
	<span># Undefined variables are just empty strings!</span>
	echo <span>$(nowhere)</span></code></pre>
<p>Use <code>+=</code> to append</p>
<pre><code>foo := start
foo += more

<span>all: </span>
	echo <span>$(foo)</span></code></pre>
<p><a href="#string-substitution">String Substitution</a> is also a really common and useful way to modify variables. Also check out <a href="https://www.gnu.org/software/make/manual/html_node/Text-Functions.html#Text-Functions">Text Functions</a> and <a href="https://www.gnu.org/software/make/manual/html_node/File-Name-Functions.html#File-Name-Functions">Filename Functions</a>.</p>
<h2 id="command-line-arguments-and-override">Command line arguments and override</h2>
<!--  (Section 6.7) -->
<p>You can override variables that come from the command line by using <code>override</code>.
Here we ran make with <code>make option_one=hi</code></p>
<pre><code><span># Overrides command line arguments</span>
<span>override</span> option_one = did_override
<span># Does not override command line arguments</span>
option_two = not_override
<span>all: </span>
	echo <span>$(option_one)</span>
	echo <span>$(option_two)</span></code></pre>
<h2 id="list-of-commands-and-define">List of commands and define</h2>
<!--  (Section 6.8) -->
<p>The <a href="https://www.gnu.org/software/make/manual/html_node/Multi_002dLine.html">define directive</a> is not a function, though it may look that way. I've seen it used so infrequently that I won't go into details, but it's mainly used for defining <a href="https://www.gnu.org/software/make/manual/html_node/Canned-Recipes.html#Canned-Recipes">canned recipes</a> and also pairs well with the <a href="https://www.gnu.org/software/make/manual/html_node/Eval-Function.html#Eval-Function">eval function</a>.</p>
<p><code>define</code>/<code>endef</code> simply creates a variable that is set to a list of commands. Note here that it's a bit different than having a semi-colon between commands, because each is run in a separate shell, as expected.</p>
<pre><code>one = <span>export</span> blah=<span>"I was set!"</span>; echo $$blah

<span>define</span> two
<span>export</span> blah=<span>"I was set!"</span>
echo $$blah
<span>endef</span>

<span>all: </span>
	@echo <span>"This prints 'I was set'"</span>
	@<span>$(one)</span>
	@echo <span>"This does not print 'I was set' because each command runs in a separate shell"</span>
	@<span>$(two)</span></code></pre>
<h2 id="target-specific-variables">Target-specific variables</h2>
<!--  (Section 6.10) -->
<p>Variables can be set for specific targets</p>
<pre><code><span>all: one = cool</span>

<span>all: </span>
	echo one is defined: <span>$(one)</span>

<span>other:</span>
	echo one is nothing: <span>$(one)</span></code></pre>
<h2 id="pattern-specific-variables">Pattern-specific variables</h2>
<!--  (Section 6.11) -->
<p>You can set variables for specific target <em>patterns</em></p>
<pre><code><span>%.c: one = cool</span>

<span>blah.c: </span>
	echo one is defined: <span>$(one)</span>

<span>other:</span>
	echo one is nothing: <span>$(one)</span></code></pre>
<h2 id="conditional-part-of-makefiles">Conditional part of Makefiles</h2>
<h2 id="conditional-ifelse">Conditional if/else</h2>
<!--  (Section 7.1) -->
<pre><code>foo = ok

<span>all:</span>
<span>ifeq</span> (<span>$(foo)</span>, ok)
	echo <span>"foo equals ok"</span>
<span>else</span>
	echo <span>"nope"</span>
<span>endif</span></code></pre>
<h2 id="check-if-a-variable-is-empty">Check if a variable is empty</h2>
<!--  (Section 7.2) -->
<pre><code>nullstring =
foo = <span>$(nullstring)</span> <span># end of line; there is a space here</span>

<span>all:</span>
<span>ifeq</span> (<span>$(<span>strip</span> <span>$(foo)</span>)</span>,)
	echo <span>"foo is empty after being stripped"</span>
<span>endif</span>
<span>ifeq</span> (<span>$(nullstring)</span>,)
	echo <span>"nullstring doesn't even have spaces"</span>
<span>endif</span></code></pre>
<h2 id="check-if-a-variable-is-defined">Check if a variable is defined</h2>
<!--  (Section 7.2) -->
<p>ifdef does not expand variable references; it just sees if something is defined at all</p>
<pre><code>bar =
foo = <span>$(bar)</span>

<span>all:</span>
<span>ifdef</span> foo
	echo <span>"foo is defined"</span>
<span>endif</span>
<span>ifndef</span> bar
	echo <span>"but bar is not"</span>
<span>endif</span>
</code></pre>
<h2 id="makeflags">$(MAKEFLAGS)</h2>
<!-- `(Section 7.3) -->
<p>This example shows you how to test make flags with <code>findstring</code> and <code>MAKEFLAGS</code>. Run this example with <code>make -i</code> to see it print out the echo statement.</p>
<pre><code><span>all:</span>
<span># Search for the "-i" flag. MAKEFLAGS is just a list of single characters, one per flag. So look for "i" in this case.</span>
<span>ifneq</span> (,<span>$(<span>findstring</span> i, <span>$(MAKEFLAGS)</span>)</span>)
	echo <span>"i was passed to MAKEFLAGS"</span>
<span>endif</span></code></pre>
<h2 id="functions">Functions</h2>
<h2 id="first-functions">First Functions</h2>
<!--  (Section 8.1) -->
<p><em>Functions</em> are mainly just for text processing. Call functions with <code>$(fn, arguments)</code> or <code>${fn, arguments}</code>. Make has a decent amount of <a href="https://www.gnu.org/software/make/manual/html_node/Functions.html">builtin functions</a>.</p>
<pre><code>bar := ${subst not,<span>"totally"</span>, <span>"I am not superman"</span>}
<span>all: </span>
	@echo <span>$(bar)</span>
</code></pre>
<p>If you want to replace spaces or commas, use variables</p>
<pre><code>comma := ,
empty:=
space := <span>$(empty)</span> <span>$(empty)</span>
foo := a b c
bar := <span>$(<span>subst</span> <span>$(space)</span>,<span>$(comma)</span>,<span>$(foo)</span>)</span>

<span>all: </span>
	@echo <span>$(bar)</span></code></pre>
<p>Do NOT include spaces in the arguments after the first. That will be seen as part of the string.</p>
<pre><code>comma := ,
empty:=
space := <span>$(empty)</span> <span>$(empty)</span>
foo := a b c
bar := <span>$(<span>subst</span> <span>$(space)</span>, <span>$(comma)</span> , <span>$(foo)</span>)</span> <span># Watch out!</span>

<span>all: </span>
	<span># Output is ", a , b , c". Notice the spaces introduced</span>
	@echo <span>$(bar)</span>
</code></pre>
<!-- # 8.2, 8.3, 8.9 TODO do something about the fns   
# TODO 8.7 origin fn? Better in documentation?
-->

<h2 id="string-substitution">String Substitution</h2>
<p><code>$(patsubst pattern,replacement,text)</code> does the following:</p>
<p>"Finds whitespace-separated words in text that match pattern and replaces them with replacement. Here pattern may contain a ‚Äò%‚Äô which acts as a wildcard, matching any number of any characters within a word. If replacement also contains a ‚Äò%‚Äô, the ‚Äò%‚Äô is replaced by the text that matched the ‚Äò%‚Äô in pattern. Only the first ‚Äò%‚Äô in the pattern and replacement is treated this way; any subsequent ‚Äò%‚Äô is unchanged." (<a href="https://www.gnu.org/software/make/manual/html_node/Text-Functions.html#Text-Functions">GNU docs</a>)</p>
<p>The substitution reference <code>$(text:pattern=replacement)</code> is a shorthand for this.</p>
<p>There's another shorthand that replaces only suffixes: <code>$(text:suffix=replacement)</code>. No <code>%</code> wildcard is used here.</p>
<p>Note: don't add extra spaces for this shorthand. It will be seen as a search or replacement term.</p>
<pre><code>foo := a.o b.o l.a c.o
one := <span>$(<span>patsubst</span> %.o,%.c,<span>$(foo)</span>)</span>
<span># This is a shorthand for the above</span>
two := $(foo:%.o=%.c)
<span># This is the suffix-only shorthand, and is also equivalent to the above.</span>
three := $(foo:.o=.c)

<span>all:</span>
	echo <span>$(one)</span>
	echo <span>$(two)</span>
	echo <span>$(three)</span></code></pre>
<h2 id="the-foreach-function">The foreach function</h2>
<!--  (Section 8.4) -->
<p>The foreach function looks like this: <code>$(foreach var,list,text)</code>. It converts one list of words (separated by spaces) to another. <code>var</code> is set to each word in list, and <code>text</code> is expanded for each word.<br>This appends an exclamation after each word:</p>
<pre><code>foo := who are you
<span># For each "word" in foo, output that same word with an exclamation after</span>
bar := <span>$(<span>foreach</span> wrd,<span>$(foo)</span>,<span>$(wrd)</span>!)</span>

<span>all:</span>
	<span># Output is "who! are! you!"</span>
	@echo <span>$(bar)</span></code></pre>
<h2 id="the-if-function">The if function</h2>
<!--  (Section 8.5) -->
<p><code>if</code> checks if the first argument is nonempty. If so, runs the second argument, otherwise runs the third.</p>
<pre><code>foo := <span>$(<span>if</span> this-is-not-empty,then!,else!)</span>
empty :=
bar := <span>$(<span>if</span> <span>$(empty)</span>,then!,else!)</span>

<span>all:</span>
	@echo <span>$(foo)</span>
	@echo <span>$(bar)</span></code></pre>
<h2 id="the-call-function">The call function</h2>
<!--  (Section 8.6) -->
<p>Make supports creating basic functions. You "define" the function just by creating a variable, but use the parameters <code>$(0)</code>, <code>$(1)</code>, etc. You then call the function with the special <a href="https://www.gnu.org/software/make/manual/html_node/Call-Function.html#Call-Function"><code>call</code></a> builtin function. The syntax is <code>$(call variable,param,param)</code>. <code>$(0)</code> is the variable, while <code>$(1)</code>, <code>$(2)</code>, etc. are the params.</p>
<pre><code>sweet_new_fn = Variable Name: $(0) First: $(1) Second: $(2) Empty Variable: $(3)

<span>all:</span>
	<span># Outputs "Variable Name: sweet_new_fn First: go Second: tigers Empty Variable:"</span>
	@echo <span>$(<span>call</span> sweet_new_fn, go, tigers)</span></code></pre>
<h2 id="the-shell-function">The shell function</h2>
<!--  (Section 8.8) -->
<p>shell - This calls the shell, but it replaces newlines with spaces!</p>
<pre><code><span>all: </span>
	@echo <span>$(<span>shell</span> ls -la)</span> <span># Very ugly because the newlines are gone!</span></code></pre>
<h2 id="the-filter-function">The filter function</h2>
<p>The <code>filter</code> function is used to select certain elements from a list that match a specific pattern. For example, this will select all elements in <code>obj_files</code> that end with <code>.o</code>.</p>
<pre><code>obj_files = foo.result bar.o lose.o
filtered_files = <span>$(<span>filter</span> %.o,<span>$(obj_files)</span>)</span>

<span>all:</span>
	@echo <span>$(filtered_files)</span></code></pre>
<p>Filter can also be used in more complex ways:</p>
<ol>
<li><p><strong>Filtering multiple patterns</strong>: You can filter multiple patterns at once. For example, <code>$(filter %.c %.h, $(files))</code> will select all <code>.c</code> and <code>.h</code> files from the files list.</p>
</li>
<li><p><strong>Negation</strong>: If you want to select all elements that do not match a pattern, you can use <code>filter-out</code>. For example, <code>$(filter-out %.h, $(files))</code> will select all files that are not <code>.h</code> files.</p>
</li>
<li><p><strong>Nested filter</strong>: You can nest filter functions to apply multiple filters. For example, <code>$(filter %.o, $(filter-out test%, $(objects)))</code> will select all object files that end with <code>.o</code> but don't start with <code>test</code>.</p>
</li>
</ol>
<h2 id="other-features">Other Features</h2>
<h2 id="include-makefiles">Include Makefiles</h2>
<p>The include directive tells make to read one or more other makefiles. It's a line in the makefile that looks like this:</p>
<pre><code><span>include</span> filenames...</code></pre>
<p>This is particularly useful when you use compiler flags like <code>-M</code> that create Makefiles based on the source. For example, if some c files includes a header, that header will be added to a Makefile that's written by gcc. I talk about this more in the <a href="#makefile-cookbook">Makefile Cookbook</a></p>
<h2 id="the-vpath-directive">The vpath Directive</h2>
<!--  (Section 4.3.2) -->
<p>Use vpath to specify where some set of prerequisites exist. The format is <code>vpath &lt;pattern&gt; &lt;directories, space/colon separated&gt;</code>
<code>&lt;pattern&gt;</code> can have a <code>%</code>, which matches any zero or more characters.
You can also do this globallyish with the variable VPATH</p>
<pre><code><span>vpath</span> %.h ../headers ../other-directory

<span># Note: vpath allows blah.h to be found even though blah.h is never in the current directory</span>
<span>some_binary: ../headers blah.h</span>
	touch some_binary

<span>../headers:</span>
	mkdir ../headers

<span># We call the target blah.h instead of ../headers/blah.h, because that's the prereq that some_binary is looking for</span>
<span># Typically, blah.h would already exist and you wouldn't need this.</span>
<span>blah.h:</span>
	touch ../headers/blah.h

<span>clean:</span>
	rm -rf ../headers
	rm -f some_binary
</code></pre>
<h2 id="multiline">Multiline</h2>
<p>The backslash ("\") character gives us the ability to use multiple lines when the commands are too long</p>
<pre><code><span>some_file: </span>
	echo This line is too long, so \
		it is broken up into multiple lines</code></pre>
<h2 id="phony">.phony</h2>
<p>Adding <code>.PHONY</code> to a target will prevent Make from confusing the phony target with a file name. In this example, if the file <code>clean</code> is created, make clean will still be run. Technically, I should have used it in every example with <code>all</code> or <code>clean</code>, but I wanted to keep the examples clean. Additionally, "phony" targets typically have names that are rarely file names, and in practice many people skip this.</p>
<pre><code><span>some_file:</span>
	touch some_file
	touch clean

<span><span>.PHONY</span>: clean</span>
<span>clean:</span>
	rm -f some_file
	rm -f clean</code></pre>
<h2 id="delete_on_error">.delete_on_error</h2>
<!-- (Section 5.4) -->

<p>The make tool will stop running a rule (and will propogate back to prerequisites) if a command returns a nonzero exit status.<br><code>DELETE_ON_ERROR</code> will delete the target of a rule if the rule fails in this manner. This will happen for all targets, not just the one it is before like PHONY. It's a good idea to always use this, even though make does not for historical reasons.  </p>
<pre><code><span>.DELETE_ON_ERROR:</span>
<span>all: one two</span>

<span>one:</span>
	touch one
	false

<span>two:</span>
	touch two
	false</code></pre>
<h2 id="makefile-cookbook">Makefile Cookbook</h2>
<p>Let's go through a really juicy Make example that works well for medium sized projects.</p>
<p>The neat thing about this makefile is it automatically determines dependencies for you. All you have to do is put your C/C++ files in the <code>src/</code> folder.</p>
<pre><code><span># Thanks to Job Vranish (https://spin.atomicobject.com/2016/08/26/makefile-c-projects/)</span>
TARGET_EXEC := final_program

BUILD_DIR := ./build
SRC_DIRS := ./src

<span># Find all the C and C++ files we want to compile</span>
<span># Note the single quotes around the * expressions. The shell will incorrectly expand these otherwise, but we want to send the * directly to the find command.</span>
SRCS := <span>$(<span>shell</span> find <span>$(SRC_DIRS)</span> -name '*.cpp' -<span>or</span> -name '*.c' -<span>or</span> -name '*.s')</span>

<span># Prepends BUILD_DIR and appends .o to every src file</span>
<span># As an example, ./your_dir/hello.cpp turns into ./build/./your_dir/hello.cpp.o</span>
OBJS := $(SRCS:%=<span>$(BUILD_DIR)</span>/%.o)

<span># String substitution (suffix version without %).</span>
<span># As an example, ./build/hello.cpp.o turns into ./build/hello.cpp.d</span>
DEPS := $(OBJS:.o=.d)

<span># Every folder in ./src will need to be passed to GCC so that it can find header files</span>
INC_DIRS := <span>$(<span>shell</span> find <span>$(SRC_DIRS)</span> -type d)</span>
<span># Add a prefix to INC_DIRS. So moduleA would become -ImoduleA. GCC understands this -I flag</span>
INC_FLAGS := <span>$(<span>addprefix</span> -I,<span>$(INC_DIRS)</span>)</span>

<span># The -MMD and -MP flags together generate Makefiles for us!</span>
<span># These files will have .d instead of .o as the output.</span>
CPPFLAGS := <span>$(INC_FLAGS)</span> -MMD -MP

<span># The final build step.</span>
<span>$(BUILD_DIR)</span>/<span>$(TARGET_EXEC)</span>: <span>$(OBJS)</span>
	<span>$(CXX)</span> <span>$(OBJS)</span> -o <span>$@</span> <span>$(LDFLAGS)</span>

<span># Build step for C source</span>
<span>$(BUILD_DIR)</span>/%.c.o: %.c
	mkdir -p <span>$(<span>dir</span> <span>$@</span>)</span>
	<span>$(CC)</span> <span>$(CPPFLAGS)</span> <span>$(CFLAGS)</span> -c <span>$&lt;</span> -o <span>$@</span>

<span># Build step for C++ source</span>
<span>$(BUILD_DIR)</span>/%.cpp.o: %.cpp
	mkdir -p <span>$(<span>dir</span> <span>$@</span>)</span>
	<span>$(CXX)</span> <span>$(CPPFLAGS)</span> <span>$(CXXFLAGS)</span> -c <span>$&lt;</span> -o <span>$@</span>


<span><span>.PHONY</span>: clean</span>
<span>clean:</span>
	rm -r <span>$(BUILD_DIR)</span>

<span># Include the .d makefiles. The - at the front suppresses the errors of missing</span>
<span># Makefiles. Initially, all the .d files will be missing, and we don't want those</span>
<span># errors to show up.</span>
<span>-include</span> <span>$(DEPS)</span></code></pre>
<!--
TODO: This example fails initially because blah.d doesn't exist. I'm not sure how to fix this example, there are probably better ones out there..

# Generating Prerequisites Automatically (Section 4.12)
Example requires: blah.c  
Generating prereqs automatically  
This makes one small makefile per source file  
Notes:  
1) $$ is the current process id in bash. $$$$ is just $$, with escaping. We use it to make a temporary file, that doesn't interfere with others if there is some parallel builds going on.  
2) cc -MM outputs a makefile line. This is the magic that generates prereqs automatically, by looking at the code itself  
3) The purpose of the sed command is to translate (for example):  
    main.o : main.c defs.h  
    into:  
    main.o main.d : main.c defs.h  
4) Running `make clean` will rerun the rm -f ... rule because the include line wants to include an up to date version of the file. There is such a target that updates it, so it runs that rule before including the file.  
```makefile
# Run make init first, then run make
# This outputs
all: blah.d

clean:
    rm -f blah.d blah.c blah.h blah.o blah

%.d: %.c
    rm -f $@; \
     $(CC) -MM $(CPPFLAGS) $< > $@.$$$$; \
     sed 's,\($*\)\.o[ :]*,\1.o $@ : ,g' < $@.$$$$ > $@; \
     rm -f $@.$$$$

init:
    echo "#include \"blah.h\"; int main() { return 0; }" > blah.c
    touch blah.h

sources = blah.c

include $(sources:.c=.d)
```
-->

                            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Break Up Big Tech: Civil Society Declaration ‚Äì People vs. Big Tech (193 pts)]]></title>
            <link>https://peoplevsbig.tech/break-up-big-tech-civil-society-declaration/</link>
            <guid>44325596</guid>
            <pubDate>Fri, 20 Jun 2025 08:02:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://peoplevsbig.tech/break-up-big-tech-civil-society-declaration/">https://peoplevsbig.tech/break-up-big-tech-civil-society-declaration/</a>, See on <a href="https://news.ycombinator.com/item?id=44325596">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content" tabindex="-1">

			<main id="main">

				<article>

										
						

						
<figure><picture fetchpriority="high" decoding="async">
<source type="image/webp" srcset="https://peoplevsbig.tech/wp-content/uploads/2025/06/Screenshot-2025-06-18-at-00.16.37.png.webp 996w, https://peoplevsbig.tech/wp-content/uploads/2025/06/Screenshot-2025-06-18-at-00.16.37-300x74.png.webp 300w, https://peoplevsbig.tech/wp-content/uploads/2025/06/Screenshot-2025-06-18-at-00.16.37-768x190.png.webp 768w" sizes="(max-width: 996px) 100vw, 996px">
<img fetchpriority="high" decoding="async" width="996" height="246" src="https://peoplevsbig.tech/wp-content/uploads/2025/06/Screenshot-2025-06-18-at-00.16.37.png" alt="" srcset="https://peoplevsbig.tech/wp-content/uploads/2025/06/Screenshot-2025-06-18-at-00.16.37.png 996w, https://peoplevsbig.tech/wp-content/uploads/2025/06/Screenshot-2025-06-18-at-00.16.37-300x74.png 300w, https://peoplevsbig.tech/wp-content/uploads/2025/06/Screenshot-2025-06-18-at-00.16.37-768x190.png 768w" sizes="(max-width: 996px) 100vw, 996px">
</picture>
</figure>



<p>We, people and civil society organisations from Europe and around the world, call on the European Commission to act now to break up the powerful Big Tech monopolies that have a stranglehold over our digital world. Big Tech isn‚Äôt just dominating markets ‚Äì it‚Äôs dominating European democracy.</p>



<p>Europe needs a thriving and diverse digital economy that serves the needs of European citizens, not billionaire tech CEOs. President von der Leyen has affirmed that in the EU, ‚Äú<a href="https://www.zeit.de/politik/2025-04/ursula-von-der-leyen-eu-usa-donald-trump-english/komplettansicht"><u>we don‚Äôt have bros or oligarchs making the rules</u></a>.‚Äù The Commission must now stand up to the tech oligarchy by strongly enforcing the EU‚Äôs digital rules and competition law.</p>



<p>Right now, the Commission has a once-in-a-generation opportunity to dismantle Google‚Äôs advertising monopoly, which is destroying the news media, ripping off consumers, and was ruled illegal in a landmark US judgement.</p>



<h2>Big Tech‚Äôs monopoly power threatens democracy</h2>



<p>We cannot address Big Tech‚Äôs harms without first confronting its power. A handful of tech giants have concentrated control of our core digital infrastructure ‚Äì including search engines, social media, app stores, and cloud. The companies‚Äô unchecked power over their digital empires enables them to abuse people‚Äôs rights, exploit businesses, and crush competitors.</p>



<p>Spanish Prime Minister Pedro Sanchez has warned that tech billionaires want ‚Äú<a href="https://www.politico.eu/article/spain-pedro-sanchez-big-tech-billionaires-democracy-social-media/"><u>to overthrow democracy</u></a>‚Äù. When a small number of billionaires and tech giants control the internet, they wield their power ‚Äì and their vast profits ‚Äì to influence political discourse and interfere with democratic laws. This year, tech CEOs and the Trump administration have <a href="https://www.techpolicy.press/tracking-recent-statements-on-the-enforcement-of-eu-tech-laws/#US-Leaders"><u>worked hand in glove</u></a> to try to thwart the EU‚Äôs landmark digital laws that hold Big Tech to account.</p>



<h2>Break up Big Tech monopolies</h2>



<p>Teresa Ribera, the EU‚Äôs competition chief, <a href="https://www.bloomberg.com/news/articles/2024-12-05/google-split-still-on-the-table-eu-s-new-antitrust-chief-says"><u>recognises</u></a> that break-ups can prevent Big Tech from grabbing too much market power. These corporations treat billion-euro fines as the cost of doing business, while behavioural remedies are ineffective and often flouted by the companies. Forcing these giants to sell off parts of their businesses will curb conflicts of interest, level the digital playing field, and make the companies easier to hold accountable for their growing societal harms.</p>



<p>Breaking up Google‚Äôs advertising monopoly is an open goal for the EU, backed by <a href="https://clubmadrid.org/former-eu-leaders-breaking-up-googles-adtech-monopoly-is-vital-for-democracy/"><u>eighteen former European presidents and prime ministers</u></a>. Google‚Äôs monopoly unfairly sucks revenue from publishers, killing journalism and the news media, while forcing consumers to pay more through an ‚Äúadtech tax‚Äù to <a href="https://www.ft.com/content/9ee0ebd3-346f-45b1-8b92-aa5c597d4389">industry middlemen</a>. In its final ruling on Google ad-tech, the Commission must reaffirm that ‚Äú<a href="https://ec.europa.eu/commission/presscorner/detail/en/ip_23_3207"><u>only the mandatory divestment</u></a>‚Äù by Google of part of its services will address competition concerns.</p>



<p>Breaking up tech monopolies is a step towards a freer, fairer internet. Europe can and must resist threats from Big Tech and the Trump administration, and stand firm in upholding EU law against Big Tech. Break up Google. Break up Big Tech.</p>



<h2>Signatories:</h2>



<ol>
<li>Balanced Economy Project</li>



<li>Foundation The London Story</li>



<li>LobbyControl</li>



<li>People vs Big Tech</li>



<li>Rebalance Now</li>



<li>WeMove Europe</li>



<li>Defend Democracy</li>



<li>Foxglove</li>



<li>Xnet, Institute for Democratic Digitalisation ‚Äì Spain</li>



<li>Uplift, Ireland</li>



<li>Corporate Europe Observatory (CEO)</li>



<li>SOMO</li>



<li>Enforce (Irish Council for Civil Liberties)</li>



<li>AlgorithmWatch</li>



<li>Save Social - Networks for democracy</li>



<li>Canadian Anti-Monopoly Project (CAMP)</li>



<li>Open Markets Institute</li>



<li>Hope and Courage Collective, Ireland</li>



<li>IT for Change</li>



<li>German NGO Forum on Environment &amp; Development</li>



<li>taxmenow</li>



<li>Goliathwatch</li>



<li>Campact</li>



<li>Global Justice Now</li>



<li>Another Europe Is Possible</li>



<li>Avaaz Foundation</li>



<li>Epicenter.works - for digital rights</li>



<li>Digital Action</li>



<li>European Federation of Journalists (EFJ)</li>



<li>Greek Helsinki Monitor</li>



<li>India Labour Solidarity</li>



<li>Waag Futurelab</li>



<li>Deutscher Journalisten-Verband (DJV, German Journalists Association)</li>



<li>The Citizens</li>



<li>Alliance4Europe</li>



<li>Global Project Against Hate and Extremism</li>
</ol>
						
						
						
						
									
						<nav>
		<a href="https://peoplevsbig.tech/opportunity-ctrlaltreclaim-community-lead/" rel="prev"><svg width="24" height="25" viewBox="0 0 24 25" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M21.3333 24.6289H24V19.2956H21.3333V21.9622L2.66667 21.9622L2.66667 3.29557L21.3333 3.29557V5.96224H24V0.628906L0 0.628906L0 24.6289L21.3333 24.6289ZM5.33333 13.9622H8V16.6289H10.6667L10.6667 19.2956H13.3333L13.3333 16.6289H10.6667V13.9622L24 13.9622V11.2956L10.6667 11.2956V8.62891H13.3333V5.96224H10.6667V8.62891L8 8.62891V11.2956H5.33333V13.9622Z" fill="currentColor"></path>
<path d="M21.3333 24.6289H24V19.2956H21.3333V21.9622L2.66667 21.9622L2.66667 3.29557L21.3333 3.29557V5.96224H24V0.628906L0 0.628906L0 24.6289L21.3333 24.6289ZM5.33333 13.9622H8V16.6289H10.6667L10.6667 19.2956H13.3333L13.3333 16.6289H10.6667V13.9622L24 13.9622V11.2956L10.6667 11.2956V8.62891H13.3333V5.96224H10.6667V8.62891L8 8.62891V11.2956H5.33333V13.9622Z" fill="currentColor" fill-opacity="0.2"></path>
</svg> <span>Previous <span>article</span></span></a>						</nav>
		
					<!-- .footer-widget -->
				</article>
					

			</main><!-- #main -->

		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[JavaScript broke the web (and called it progress) (139 pts)]]></title>
            <link>https://www.jonoalderson.com/conjecture/javascript-broke-the-web-and-called-it-progress/</link>
            <guid>44325563</guid>
            <pubDate>Fri, 20 Jun 2025 07:52:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jonoalderson.com/conjecture/javascript-broke-the-web-and-called-it-progress/">https://www.jonoalderson.com/conjecture/javascript-broke-the-web-and-called-it-progress/</a>, See on <a href="https://news.ycombinator.com/item?id=44325563">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
				
				<div><p>19th June, 2025</p><div><picture><img sizes="(max-width: 96px) 100vw, 96px" alt="" src="https://www.jonoalderson.com/acd-cgi/img/v1/wp-content/gravatars/32defd3f59a05a4eab3c33ade0e4e00d4dd992485f1e82758244d248636cd16e?dpr=1&amp;f=auto&amp;fit=cover&amp;height=96&amp;q=85&amp;sharpen=1&amp;width=96" srcset="https://www.jonoalderson.com/acd-cgi/img/v1/wp-content/gravatars/32defd3f59a05a4eab3c33ade0e4e00d4dd992485f1e82758244d248636cd16e?dpr=1&amp;f=auto&amp;fit=cover&amp;height=96&amp;q=85&amp;sharpen=1&amp;width=96 96w, https://www.jonoalderson.com/acd-cgi/img/v1/wp-content/gravatars/32defd3f59a05a4eab3c33ade0e4e00d4dd992485f1e82758244d248636cd16e?dpr=1&amp;f=auto&amp;fit=cover&amp;height=144&amp;q=85&amp;sharpen=1&amp;width=144 144w, https://www.jonoalderson.com/acd-cgi/img/v1/wp-content/gravatars/32defd3f59a05a4eab3c33ade0e4e00d4dd992485f1e82758244d248636cd16e?dpr=1&amp;f=auto&amp;fit=cover&amp;height=192&amp;q=85&amp;sharpen=1&amp;width=192 192w" height="96" width="96" decoding="async"></picture></div><picture><img alt="" decoding="async" fetchpriority="high" height="350" sizes="(max-width: 760px) calc(100vw - 2.5rem), 760px" src="https://www.jonoalderson.com/acd-cgi/img/v1/wp-content/uploads/file_00000000e62461f4b9f9d6b1410c78d2.png?dpr=1&amp;f=auto&amp;fit=cover&amp;height=350&amp;q=85&amp;width=760" srcset="https://www.jonoalderson.com/acd-cgi/img/v1/wp-content/uploads/file_00000000e62461f4b9f9d6b1410c78d2.png?dpr=1&amp;f=auto&amp;fit=cover&amp;height=350&amp;q=85&amp;width=760 760w, https://www.jonoalderson.com/acd-cgi/img/v1/wp-content/uploads/file_00000000e62461f4b9f9d6b1410c78d2.png?dpr=1&amp;f=auto&amp;fit=cover&amp;height=525&amp;q=85&amp;width=1140 1140w, https://www.jonoalderson.com/acd-cgi/img/v1/wp-content/uploads/file_00000000e62461f4b9f9d6b1410c78d2.png?dpr=1&amp;f=auto&amp;fit=cover&amp;height=700&amp;q=85&amp;width=1520 1520w" width="760"></picture></div>
<p>Most websites are&nbsp;awful.</p>



<p>Not just slow ‚Äì <em>awful</em>. Bloated, fragile, over-engineered disasters. They load slowly, render erratically, and hide their content behind megabytes of JavaScript. They glitch on mobile. They frustrate users and confuse search engines. They‚Äôre impossible to maintain. And somehow, we‚Äôre calling this <em>progress</em>.</p>



<p>The tragedy is, none of this is necessary. Once upon a&nbsp;time, we had a&nbsp;fast, stable, resilient web. But we replaced it with a&nbsp;JavaScript cargo&nbsp;cult.</p>



<p>Now it takes four engineers, three frameworks, and a&nbsp;CI/CD pipeline just to change a&nbsp;heading. It‚Äôs inordinately complex to simply <em>publish a&nbsp;webpage</em>.</p>



<p>This isn‚Äôt evolution. It‚Äôs self-inflicted complexity. And we‚Äôve normalised it ‚Äì because somewhere along the way, we started building websites for <em>developers</em>, not for <em>users</em>.</p>



<h2 id="h-how-we-got-here">How we got&nbsp;here</h2>



<p>Around 2010, something shifted. The iPhone was ascendant. Native apps were sleek, fast, fluid. Angular, the first mainstream javascript framework for the web, elhad just emerged. And suddenly, every CMO started saying the same thing in website briefs: <em>‚ÄúCan we make it feel like an&nbsp;app?‚Äù</em></p>



<p>Developers, armed with new frameworks and good intentions, said yes. JavaScript could, in theory, do seamless transitions and slick UI. So we built towards that promise. Or tried&nbsp;to.</p>



<p>Spoiler alert: we didn‚Äôt get app-like performance. We didn‚Äôt get better user experiences. What we got was an <em>arms race of complexity</em>.</p>



<p>We started solving simple problems ‚Äì like navigation or layout ‚Äì with tools built for full-blown applications.</p>



<p>At the same time, JavaScript stopped being just a&nbsp;front-end language. With the rise of Node.js, JS moved server-side, and with it came a&nbsp;wave of app developers entering the web ecosystem. These weren‚Äôt web designers or content publishers. They were engineers, trained to build applications, not documents. And they brought with them an architecture-first mindset: patterns, state management, dependency injection, abstracted logic. The result? A&nbsp;slow cultural shift from building pages to engineering systems ‚Äì even when all the user needed was to load an article.</p>



<p>And so, we rewrote the rules of web development around entirely different needs, almost overnight. Not content, not speed, not interoperability, not discoverability. Just&nbsp;code.</p>



<p>The further we went down this road, the more the stack drifted from the fundamentals. Semantic HTML? Optional. Server-side rendering? Rebuilt from scratch. Accessibility? Maybe, if there‚Äôs time. Performance? Who cares, when you can save costs by putting loading burdens onto the user‚Äôs device, instead of your server?</p>



<p>So gradually, the web became something you had to <em>compile</em> before you could publish. Not because users needed it. But because developers wanted it to feel modern.</p>



<p>And we‚Äôre still paying for that decision.</p>



<h2 id="h-the-cult-of-developer-experience">The cult of developer experience</h2>



<p>Today, we optimise for ‚ÄúDX‚Äù ‚Äì developer experience. Not user experience. Not performance. Not outcomes.</p>



<p>Today‚Äôs popular frameworks are sold on their DX. The docs are slick. The onboarding is smooth. The tooling is smart, integrated, clever. You can spin up a&nbsp;new app with a&nbsp;CLI command and feel productive before you‚Äôve even written a&nbsp;line of content.</p>



<p>But good DX doesn‚Äôt guarantee good UX. In fact, it‚Äôs often the opposite. Because the more comfortable we make things for developers, the more abstraction we add. And every abstraction creates distance between the thing being built and the people it‚Äôs&nbsp;for.</p>



<p>Now we have component libraries generating button markup. We have page metadata managed in JavaScript functions. We have image loading strategies buried in config files.</p>



<p>Everything‚Äôs optimised for developers ‚Äì and hostile to everyone else.</p>



<p>This isn‚Äôt accidental. It‚Äôs cultural. We‚Äôve created an industry where complexity is celebrated. Where cleverness is rewarded. Where engineering sophistication is valued more than clarity, usability, or commercial effectiveness.</p>



<p>It‚Äôs easier to win an argument by citing SSR compatibility issues than it is to ask, ‚Äú<em>Why are we using React for a&nbsp;blog?</em>‚Äù</p>



<p>And so we keep optimising for the wrong things. Because it feels good. Because it‚Äôs fun. Because it looks modern. And because nobody stops&nbsp;us.</p>



<h2 id="h-complexity-becomes-the-default">Complexity becomes the default</h2>



<p>This is how it spirals.</p>



<p>We don‚Äôt just tolerate complexity anymore ‚Äì we expect it. We assume that every site needs a&nbsp;build step, a&nbsp;bundler, a&nbsp;hydration strategy, a&nbsp;routing layer, an API layer, a&nbsp;design system, and some clever cache invalidation logic. We build in microservices, host on edge networks, and deploy pipelines to ship basic content.</p>



<p>It doesn‚Äôt matter if you‚Äôre publishing a&nbsp;blog post or an ecommerce site ‚Äì the stack is the same. Heavy, abstract, engineered to the edge of usefulness.</p>



<p>And nobody understands it. Not&nbsp;fully.</p>



<p>Not the marketers, not the SEOs, not even the developers who built it six months ago. Every new tool brings new abstractions, new syntax, new mental models. Making a&nbsp;simple tweak to a&nbsp;headline, a&nbsp;meta tag, or a&nbsp;layout becomes a&nbsp;three-step deployment process.</p>



<p>It‚Äôs madness.</p>



<p>We‚Äôve rebuilt the web like an air traffic control system ‚Äì just to serve a&nbsp;few kilobytes of&nbsp;text.</p>



<p>And the worst part? Most of this complexity exists just to retrofit things we used to get by <em>default</em>: routing, metadata, caching, templating, layout.</p>



<p>We‚Äôre not innovating. We‚Äôre rebuilding broken versions of tools the web already gave us ‚Äì and doing it&nbsp;badly.</p>



<h2 id="h-the-stack-is-rebuilding-itself-in-its-own-image">The stack is rebuilding itself in its own&nbsp;image</h2>



<p>Fast forward to today. Ironically, after years of chasing abstraction and complexity, the JavaScript ecosystem is now scrambling to reintroduce the things we&nbsp;lost.</p>



<p>Server-side rendering? Back in fashion. Routing? Carefully managed. URL structures, metadata, even HTML output ‚Äì all being rebuilt, one plugin at a&nbsp;time.</p>



<p>It all looks increasingly like the thing we started with: a&nbsp;conventional CMS, serving HTML, rendered on the server, cached close to the&nbsp;user.</p>



<p>Except now it‚Äôs slower, harder to maintain, and dependent on a&nbsp;brittle ecosystem of packages, compilers, and edge handlers.</p>



<p>We‚Äôre (re)building platforms like WordPress and it‚Äôs features, but with 10x the overhead and none of the usability.</p>



<p>Worse, every new layer introduces new bugs, new compatibility issues, and new cognitive burden. Now we‚Äôre maintaining hydration logic <em>and</em> cache strategies <em>and</em> build pipelines just to get a&nbsp;homepage online.</p>



<p>It would be funny if it weren‚Äôt so exhausting.</p>



<p>This is the endgame of a&nbsp;development culture obsessed with novelty. We‚Äôre not shipping better sites. We‚Äôre reinventing basic infrastructure in increasingly convoluted ways ‚Äì then celebrating the fact that it <em>almost works</em>.</p>



<h2 id="h-the-cycle-of-iteration-and-instability">The cycle of iteration and instability</h2>



<p>The stack never settles.</p>



<p>Nothing is stable. Nothing is finished. Every sprint, every roadmap, every quarter brings a&nbsp;new initiative: migrate to the latest framework, adopt the new bundler, refactor the routing layer, replace the CMS integration, rebuild the&nbsp;cache.</p>



<p>It never ends. And it rarely helps.</p>



<p>Most of this churn isn‚Äôt solving real user problems. It‚Äôs solving the problems created by the last round of architecture decisions. We‚Äôre not iterating toward impact ‚Äì we‚Äôre iterating just to stay afloat.</p>



<p>And while the stack is busy trying to fix itself, everything else slows&nbsp;down.</p>



<p>Marketing campaigns get delayed because the component library isn‚Äôt flexible enough. A/B tests get scrapped because the analytics layer isn‚Äôt compatible with the hydration strategy. Content updates wait days for a&nbsp;build. Basic SEO tweaks get buried in backlog.</p>



<p>Meanwhile, the users still can‚Äôt load the&nbsp;page.</p>



<p>This is what happens when complexity becomes the product. We don‚Äôt optimise for outcomes anymore. We optimise the optimisation layer.</p>



<p>And then we do it&nbsp;again.</p>



<h2 id="h-collateral-damage-to-marketers-and-users">Collateral damage to marketers and&nbsp;users</h2>



<p>All this complexity doesn‚Äôt just frustrate developers. It locks everyone else&nbsp;out.</p>



<p>Marketers can‚Äôt update copy or run experiments without raising tickets. They can‚Äôt preview content, test layouts, or launch pages. Every change has to go through developers, pipelines, approvals, and rebuilds.</p>



<p>SEOs are stuck trying to diagnose rendering issues they can‚Äôt control. Pages load empty, or late, or not at all. Crawl traps appear. Metadata disappears. Structured data gets bundled into a&nbsp;JavaScript object and forgotten.</p>



<p>Content strategists and editors are left editing JSON blobs, Markdown files, or headless CMS forms that have no connection to the thing the user actually sees.</p>



<p>Even basic QA is a&nbsp;mess. Does the page show the right headline? Does the canonical tag resolve correctly? You won‚Äôt know until you‚Äôve deployed it.&nbsp;Maybe.</p>



<p>And users? They‚Äôre stuck staring at loading spinners. Tapping broken buttons. Waiting for the back button to un-break itself. Watching text reflow as the layout shuffles into&nbsp;place.</p>



<p>This isn‚Äôt the future of the web. It‚Äôs a&nbsp;slow-motion disaster.</p>



<p>We‚Äôve made websites harder to publish, harder to find, harder to use, and harder to maintain ‚Äì all in the name of modern development.</p>



<h2 id="h-javascript-is-powerful-but-misused">JavaScript is powerful ‚Äì but misused</h2>



<p>Let‚Äôs be clear: JavaScript isn‚Äôt the villain. It‚Äôs powerful. It‚Äôs essential. It enables rich interactivity, dynamic content, real-time updates. It lets us build tools, not just&nbsp;pages.</p>



<p>Used wisely, it elevates the&nbsp;web.</p>



<p>But most websites don‚Äôt need to be tools. They don‚Äôt need complex state. They don‚Äôt need real-time data or dynamic routing. They‚Äôre not apps. They‚Äôre brochures, catalogs, portfolios, articles.</p>



<p>And for those use cases, the modern JS stack is complete overkill.</p>



<p>Even ecommerce sites ‚Äì with product options, variation pickers, add-to-cart functionality, and modal overlays ‚Äì don‚Äôt need full frameworks. These can all be built with minimal, lean, well-targeted JavaScript. No client-side routing. No hydration. No component trees.</p>



<p>A few lines of well-written vanilla JavaScript (or yes, even jquery) can handle 95% of what most websites actually need. Faster. Simpler. More accessibly.</p>



<p>Modern CSS alone can now handle many of the tasks we used to need JavaScript for ‚Äì like toggles, modals, and even carousels ‚Äì reducing the need for scripting altogether.</p>



<p>And yes, some sites do have genuine client-side state needs login states, currency selectors, regional availability, and so on. But even those can often be handled more cleanly and performantly with server-side logic, or simple asynchronous JavaScript and AJAX. We don‚Äôt need a&nbsp;full reactive runtime to show a ‚Äòlogged in‚Äô button or switch from USD to&nbsp;EUR.</p>



<p>But instead, we default to frameworks. We reach for React to build a&nbsp;contact page. We deploy hydration strategies for static content. We compile, bundle, transpile, and optimise code that doesn‚Äôt need to&nbsp;exist.</p>



<p>It‚Äôs not just wasteful. It‚Äôs damaging.</p>



<p>We‚Äôre burning user attention, developer time, and business resources to simulate interactivity that nobody asked&nbsp;for.</p>



<p>JavaScript should be the icing. Not the cake. And certainly not the oven, the recipe, and the kitchen sink.</p>



<h2 id="h-the-power-problem">The power problem</h2>



<p>The more complex the stack becomes, the more power it concentrates.</p>



<p>Marketers, content editors, SEOs, designers ‚Äì they‚Äôre all locked out of the process. Because now, even simple tasks require technical fluency. Want to change a&nbsp;title tag? Talk to engineering. Want to launch a&nbsp;campaign? Raise a&nbsp;ticket and wait two sprints.</p>



<p>Everything flows through the dev team. Which means the dev team gets to decide what matters, what ships, and what gets deprioritised indefinitely.</p>



<p>And the more complexity they add, the more indispensable they become.</p>



<p>It‚Äôs not (usually) malicious. It‚Äôs structural. The stack is built by devs, for devs. So when something breaks, or needs changing, or needs explaining ‚Äì it goes back to the people who built it. Which reinforces the model. Which deepens the dependency. Which justifies more abstraction. And more control.</p>



<p>This isn‚Äôt just a&nbsp;technical issue. It‚Äôs an organisational one. We‚Äôve handed control of the web to the only people who understand the machinery. And they‚Äôre too busy fixing the machine to stop and ask whether we needed it in the first&nbsp;place.</p>



<h2 id="h-websites-that-work">Websites that&nbsp;work</h2>



<p>There is a&nbsp;better way. And it doesn‚Äôt require a&nbsp;complete rewrite of the internet or a&nbsp;return to&nbsp;2005.</p>



<p>We don‚Äôt need to abandon CMSs. We don‚Äôt need to ban JavaScript. We just need to stop treating every website like a&nbsp;software product.</p>



<p>Most sites need to load fast, be easy to navigate, show up in search, and let users do simple things ‚Äì read, click, scroll, buy. That‚Äôs it. And we already have the tools to build&nbsp;that:</p>



<ul>
<li>Server-rendered HTML.</li>



<li>Semantic markup.</li>



<li>Clean URLs.</li>



<li>Lightweight templates.</li>



<li>Edge caching.</li>



<li>Sensible use of JavaScript where it adds real&nbsp;value.</li>
</ul>



<p>That could be WordPress. That could be Eleventy. That could be a&nbsp;custom setup. The point isn‚Äôt the tool ‚Äì it‚Äôs the mindset.</p>



<p>Build for the user. Build for performance. Build for maintainability.</p>



<p>Choose simplicity over cleverness. Choose transparency over abstraction. Choose outcomes over architecture.</p>



<p>We can still have modern workflows. We can still version control content. We can still preview, collaborate, deploy, iterate. But the foundation has to be the web ‚Äì not an app, not a&nbsp;shell, not a&nbsp;simulation.</p>



<p>It‚Äôs not about going backwards. It‚Äôs about stopping the freefall.</p>



<p>The web can work again. We just have to let&nbsp;it.</p>



<h2 id="h-reclaiming-the-web">Reclaiming the&nbsp;web</h2>



<p>If you‚Äôve ever felt like your website is harder to manage than it should be ‚Äì you‚Äôre not imagining it.</p>



<p>If it takes days to update a&nbsp;title tag, if your product pages glitch, if your blog can‚Äôt load without JavaScript‚Ä¶ that‚Äôs not ‚Äújust how it works.‚Äù That‚Äôs a&nbsp;choice. One made without you in the&nbsp;room.</p>



<p>So ask questions. Push&nbsp;back.</p>



<ul>
<li>‚ÄúWhy are we using a&nbsp;full JS framework for a&nbsp;mostly static site?‚Äù</li>



<li>‚ÄúWhy can‚Äôt I&nbsp;update this content without engineering help?‚Äù</li>



<li>‚ÄúWhy does it take a&nbsp;build pipeline to change a&nbsp;headline?‚Äù</li>



<li>‚ÄúWhy isn‚Äôt this just&nbsp;HTML?‚Äù</li>
</ul>



<p>You don‚Äôt need to write code to challenge architecture. You just need to make outcomes the priority.</p>



<p>And remember ‚Äì complexity isn‚Äôt just a&nbsp;technical burden. It‚Äôs a&nbsp;financial one. More engineers. Slower launches. Higher maintenance. Less agility. When the stack bloats, so do the&nbsp;costs.</p>



<p>Faster sites. Easier publishing. Better rankings. Happier users.</p>



<p>You can demand those things.</p>



<p>Because they‚Äôre not unreasonable. They‚Äôre what the web was built&nbsp;for.</p>



<p>And it‚Äôs time to start demanding better.</p>



<p>Ask more. Expect more. Push for outcomes, not architecture.</p>



<p>The web isn‚Äôt broken by accident. It‚Äôs broken by design. And we don‚Äôt have to accept it.</p>



<p>That doesn‚Äôt mean frameworks have no place. Large or distributed teams often benefit from architectural scaffolding, shared conventions, and modular approaches. But that scaffolding is rarely right-sized. More often, it justifies itself by growing ‚Äì and creates the need for even more engineers to maintain the complexity it introduced.</p>



<p>And yes, frameworks <em>can</em> be fast, accessible, and SEO-friendly. But let‚Äôs be honest: they almost never are. Not in the wild. Not without significant expertise, time, and care. Most developers don‚Äôt know what they don‚Äôt know. They rely on default configurations and magic middleware that silently breaks the basics.</p>



<p>The result?<br>Broken back buttons.<br>Image bloat.<br>Inaccessible markup.<br>URLs that don‚Äôt behave like URLs.<br>Metadata that disappears.<br>Content you can‚Äôt copy.<br>Buttons you can‚Äôt keyboard to.<br>Modals that trap you.<br>Scroll positions that reset for no reason.<br>Headlines that shift mid-read.<br>Analytics that don‚Äôt match reality.<br>Preview environments that lie.<br>And pages that load‚Ä¶ eventually.</p>



<p>All fixable.<br>All avoidable.<br>All caused by choosing tools that were never built for this&nbsp;job.</p>



<p>This isn‚Äôt about going back to table layouts or banning JavaScript.<br>It‚Äôs about building with intent.<br>Understanding what the web gives us by default ‚Äì and resisting the urge to rebuild it from scratch.</p>



<p>It‚Äôs not about purity. It‚Äôs about outcomes.<br>Use what&nbsp;works.<br></p>



<p>But question whether it‚Äôs working for your users, or just for your developers.&nbsp;</p>
    
    
    
    
    			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hurl: Run and test HTTP requests with plain text (405 pts)]]></title>
            <link>https://github.com/Orange-OpenSource/hurl</link>
            <guid>44324592</guid>
            <pubDate>Fri, 20 Jun 2025 03:55:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Orange-OpenSource/hurl">https://github.com/Orange-OpenSource/hurl</a>, See on <a href="https://news.ycombinator.com/item?id=44324592">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><themed-picture data-catalyst-inline="true"><picture>
    <source media="(prefers-color-scheme: light)" srcset="https://github.com/Orange-OpenSource/hurl/raw/master/docs/assets/img/logo-light.svg?sanitize=true"> 
    <source media="(prefers-color-scheme: dark)" srcset="https://github.com/Orange-OpenSource/hurl/raw/master/docs/assets/img/logo-dark.svg?sanitize=true"> 
    <img src="https://github.com/Orange-OpenSource/hurl/raw/master/docs/assets/img/logo-light.svg?sanitize=true" width="264px" alt="Hurl Logo">
</picture></themed-picture>
<p dir="auto"><a href="https://github.com/Orange-OpenSource/hurl/actions"><img src="https://github.com/Orange-OpenSource/hurl/workflows/test/badge.svg" alt="deploy status"></a>
<a href="https://orange-opensource.github.io/hurl/coverage" rel="nofollow"><img src="https://camo.githubusercontent.com/19edc85a2bb776555d2d2ed00e86d9926f7c0befd6339b768874bc7c866eaaa4/68747470733a2f2f4f72616e67652d4f70656e536f757263652e6769746875622e696f2f6875726c2f636f7665726167652f6261646765732f666c61742e737667" alt="coverage" data-canonical-src="https://Orange-OpenSource.github.io/hurl/coverage/badges/flat.svg"></a>
<a href="https://crates.io/crates/hurl" rel="nofollow"><img src="https://camo.githubusercontent.com/9b74b944af9e26d5adb9d2f853bb93c53c45d75f888cabc4d3406fa838b813fa/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f6875726c2e737667" alt="Crates.io" data-canonical-src="https://img.shields.io/crates/v/hurl.svg"></a>
<a href="https://hurl.dev/" rel="nofollow"><img src="https://camo.githubusercontent.com/d78580786d47c7d5ecc3d261edae2f60c95978e25086984df45588f4a1214929/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2d646f63756d656e746174696f6e2d666630323838" alt="documentation" data-canonical-src="https://img.shields.io/badge/-documentation-ff0288"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What's Hurl?</h2><a id="user-content-whats-hurl" aria-label="Permalink: What's Hurl?" href="#whats-hurl"></a></p>
<p dir="auto">Hurl is a command line tool that runs <b>HTTP requests</b> defined in a simple <b>plain text format</b>.</p>
<p dir="auto">It can chain requests, capture values and evaluate queries on headers and body response. Hurl is very
versatile: it can be used for both <b>fetching data</b> and <b>testing HTTP</b> sessions.</p>
<p dir="auto">Hurl makes it easy to work with <b>HTML</b> content, <b>REST / SOAP / GraphQL</b> APIs, or any other <b>XML / JSON</b> based APIs.</p>
<div data-snippet-clipboard-copy-content="# Get home:
GET https://example.org
HTTP 200
[Captures]
csrf_token: xpath &quot;string(//meta[@name='_csrf_token']/@content)&quot;


# Do login!
POST https://example.org/login?user=toto&amp;password=1234
X-CSRF-TOKEN: {{csrf_token}}
HTTP 302"><pre lang="hurl"><code># Get home:
GET https://example.org
HTTP 200
[Captures]
csrf_token: xpath "string(//meta[@name='_csrf_token']/@content)"


# Do login!
POST https://example.org/login?user=toto&amp;password=1234
X-CSRF-TOKEN: {{csrf_token}}
HTTP 302
</code></pre></div>
<p dir="auto">Chaining multiple requests is easy:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/api/health
GET https://example.org/api/step1
GET https://example.org/api/step2
GET https://example.org/api/step3"><pre lang="hurl"><code>GET https://example.org/api/health
GET https://example.org/api/step1
GET https://example.org/api/step2
GET https://example.org/api/step3
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Also an HTTP Test Tool</h2><a id="user-content-also-an-http-test-tool" aria-label="Permalink: Also an HTTP Test Tool" href="#also-an-http-test-tool"></a></p>
<p dir="auto">Hurl can run HTTP requests but can also be used to <b>test HTTP responses</b>.
Different types of queries and predicates are supported, from <a href="https://en.wikipedia.org/wiki/XPath" rel="nofollow">XPath</a> and <a href="https://goessner.net/articles/JsonPath/" rel="nofollow">JSONPath</a> on body response,
to assert on status code and response headers.</p>
<p dir="auto"><a href="https://hurl.dev/player.html?id=starwars&amp;speed=3" rel="nofollow"><img src="https://github.com/Orange-OpenSource/hurl/raw/master/docs/assets/img/poster-starwars.png" width="100%" alt="Hurl Demo"></a></p>
<p dir="auto">It is well adapted for <b>REST / JSON APIs</b></p>
<div data-snippet-clipboard-copy-content="POST https://example.org/api/tests
{
    &quot;id&quot;: &quot;4568&quot;,
    &quot;evaluate&quot;: true
}
HTTP 200
[Asserts]
header &quot;X-Frame-Options&quot; == &quot;SAMEORIGIN&quot;
jsonpath &quot;$.status&quot; == &quot;RUNNING&quot;    # Check the status code
jsonpath &quot;$.tests&quot; count == 25      # Check the number of items
jsonpath &quot;$.id&quot; matches /\d{4}/     # Check the format of the id"><pre lang="hurl"><code>POST https://example.org/api/tests
{
    "id": "4568",
    "evaluate": true
}
HTTP 200
[Asserts]
header "X-Frame-Options" == "SAMEORIGIN"
jsonpath "$.status" == "RUNNING"    # Check the status code
jsonpath "$.tests" count == 25      # Check the number of items
jsonpath "$.id" matches /\d{4}/     # Check the format of the id
</code></pre></div>
<p dir="auto"><b>HTML content</b></p>
<div data-snippet-clipboard-copy-content="GET https://example.org
HTTP 200
[Asserts]
xpath &quot;normalize-space(//head/title)&quot; == &quot;Hello world!&quot;"><pre lang="hurl"><code>GET https://example.org
HTTP 200
[Asserts]
xpath "normalize-space(//head/title)" == "Hello world!"
</code></pre></div>
<p dir="auto"><b>GraphQL</b></p>
<div data-snippet-clipboard-copy-content="POST https://example.org/graphql
```graphql
{
  human(id: &quot;1000&quot;) {
    name
    height(unit: FOOT)
  }
}
```
HTTP 200"><pre lang="hurl"><code>POST https://example.org/graphql
```graphql
{
  human(id: "1000") {
    name
    height(unit: FOOT)
  }
}
```
HTTP 200
</code></pre></div>
<p dir="auto">and even <b>SOAP APIs</b></p>
<div data-snippet-clipboard-copy-content="POST https://example.org/InStock
Content-Type: application/soap+xml; charset=utf-8
SOAPAction: &quot;http://www.w3.org/2003/05/soap-envelope&quot;
<?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?>
<soap:Envelope xmlns:soap=&quot;http://www.w3.org/2003/05/soap-envelope&quot; xmlns:m=&quot;https://example.org&quot;>
  <soap:Header></soap:Header>
  <soap:Body>
    <m:GetStockPrice>
      <m:StockName>GOOG</m:StockName>
    </m:GetStockPrice>
  </soap:Body>
</soap:Envelope>
HTTP 200"><pre lang="hurl"><code>POST https://example.org/InStock
Content-Type: application/soap+xml; charset=utf-8
SOAPAction: "http://www.w3.org/2003/05/soap-envelope"
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;soap:Envelope xmlns:soap="http://www.w3.org/2003/05/soap-envelope" xmlns:m="https://example.org"&gt;
  &lt;soap:Header&gt;&lt;/soap:Header&gt;
  &lt;soap:Body&gt;
    &lt;m:GetStockPrice&gt;
      &lt;m:StockName&gt;GOOG&lt;/m:StockName&gt;
    &lt;/m:GetStockPrice&gt;
  &lt;/soap:Body&gt;
&lt;/soap:Envelope&gt;
HTTP 200
</code></pre></div>
<p dir="auto">Hurl can also be used to test the <b>performance</b> of HTTP endpoints</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/api/v1/pets
HTTP 200
[Asserts]
duration < 1000  # Duration in ms"><pre lang="hurl"><code>GET https://example.org/api/v1/pets
HTTP 200
[Asserts]
duration &lt; 1000  # Duration in ms
</code></pre></div>
<p dir="auto">And check response bytes</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/data.tar.gz
HTTP 200
[Asserts]
sha256 == hex,039058c6f2c0cb492c533b0a4d14ef77cc0f78abccced5287d84a1a2011cfb81;"><pre lang="hurl"><code>GET https://example.org/data.tar.gz
HTTP 200
[Asserts]
sha256 == hex,039058c6f2c0cb492c533b0a4d14ef77cc0f78abccced5287d84a1a2011cfb81;
</code></pre></div>
<p dir="auto">Finally, Hurl is easy to <b>integrate in CI/CD</b>, with text, JUnit, TAP and HTML reports</p>
<themed-picture data-catalyst-inline="true"><picture>
    <source media="(prefers-color-scheme: light)" srcset="https://github.com/Orange-OpenSource/hurl/raw/master/docs/assets/img/home-waterfall-light.png">
    <source media="(prefers-color-scheme: dark)" srcset="https://github.com/Orange-OpenSource/hurl/raw/master/docs/assets/img/home-waterfall-dark.png">
    <img src="https://github.com/Orange-OpenSource/hurl/raw/master/docs/assets/img/home-waterfall-light.png" width="480" alt="HTML report">
</picture></themed-picture>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why Hurl?</h2><a id="user-content-why-hurl" aria-label="Permalink: Why Hurl?" href="#why-hurl"></a></p>
<ul dir="auto">
    <li><b>Text Format:</b> for both devops and developers</li>
    <li><b>Fast CLI:</b> a command line for local dev and continuous integration</li>
    <li><b>Single Binary:</b> easy to install, with no runtime required</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Powered by curl</h2><a id="user-content-powered-by-curl" aria-label="Permalink: Powered by curl" href="#powered-by-curl"></a></p>
<p dir="auto">Hurl is a lightweight binary written in <a href="https://www.rust-lang.org/" rel="nofollow">Rust</a>. Under the hood, Hurl HTTP engine is
powered by <a href="https://curl.se/libcurl/" rel="nofollow">libcurl</a>, one of the most powerful and reliable file transfer libraries.
With its text file format, Hurl adds syntactic sugar to run and test HTTP requests,
but it's still the <a href="https://curl.se/" rel="nofollow">curl</a> that we love: <strong>fast</strong>, <strong>efficient</strong> and <strong>IPv6 / HTTP/3 ready</strong>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Feedbacks</h2><a id="user-content-feedbacks" aria-label="Permalink: Feedbacks" href="#feedbacks"></a></p>
<p dir="auto">To support its development, <a href="https://github.com/Orange-OpenSource/hurl/stargazers">star Hurl on GitHub</a>!</p>
<p dir="auto"><a href="https://github.com/Orange-OpenSource/hurl/issues">Feedback, suggestion, bugs or improvements</a> are welcome.</p>
<div data-snippet-clipboard-copy-content="POST https://hurl.dev/api/feedback
{
  &quot;name&quot;: &quot;John Doe&quot;,
  &quot;feedback&quot;: &quot;Hurl is awesome!&quot;
}
HTTP 200"><pre lang="hurl"><code>POST https://hurl.dev/api/feedback
{
  "name": "John Doe",
  "feedback": "Hurl is awesome!"
}
HTTP 200
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Resources</h2><a id="user-content-resources" aria-label="Permalink: Resources" href="#resources"></a></p>
<p dir="auto"><a href="https://hurl.dev/docs/license.html" rel="nofollow">License</a></p>
<p dir="auto"><a href="https://hurl.dev/blog/" rel="nofollow">Blog</a></p>
<p dir="auto"><a href="https://hurl.dev/docs/tutorial/your-first-hurl-file.html" rel="nofollow">Tutorial</a></p>
<p dir="auto"><a href="https://hurl.dev/docs/installation.html" rel="nofollow">Documentation</a> (download <a href="https://github.com/Orange-OpenSource/hurl/blob/master/docs/standalone/hurl-6.1.0.html">HTML</a>, <a href="https://github.com/Orange-OpenSource/hurl/blob/master/docs/standalone/hurl-6.1.0.pdf">PDF</a>, <a href="https://github.com/Orange-OpenSource/hurl/blob/master/docs/standalone/hurl-6.1.0.md">Markdown</a>)</p>
<p dir="auto"><a href="https://github.com/Orange-OpenSource/hurl">GitHub</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Table of Contents</h2><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#samples">Samples</a>
<ul dir="auto">
<li><a href="#getting-data">Getting Data</a>
<ul dir="auto">
<li><a href="#http-headers">HTTP Headers</a></li>
<li><a href="#query-params">Query Params</a></li>
<li><a href="#basic-authentication">Basic Authentication</a></li>
<li><a href="#passing-data-between-requests">Passing Data between Requests </a></li>
</ul>
</li>
<li><a href="#sending-data">Sending Data</a>
<ul dir="auto">
<li><a href="#sending-html-form-data">Sending HTML Form Data</a></li>
<li><a href="#sending-multipart-form-data">Sending Multipart Form Data</a></li>
<li><a href="#posting-a-json-body">Posting a JSON Body</a></li>
<li><a href="#templating-a-json-body">Templating a JSON Body</a></li>
<li><a href="#templating-a-xml-body">Templating a XML Body</a></li>
<li><a href="#using-graphql-query">Using GraphQL Query</a></li>
<li><a href="#using-dynamic-datas">Using Dynamic Datas</a></li>
</ul>
</li>
<li><a href="#testing-response">Testing Response</a>
<ul dir="auto">
<li><a href="#testing-status-code">Testing Status Code</a></li>
<li><a href="#testing-response-headers">Testing Response Headers</a></li>
<li><a href="#testing-rest-apis">Testing REST APIs</a></li>
<li><a href="#testing-html-response">Testing HTML Response</a></li>
<li><a href="#testing-set-cookie-attributes">Testing Set-Cookie Attributes</a></li>
<li><a href="#testing-bytes-content">Testing Bytes Content</a></li>
<li><a href="#ssl-certificate">SSL Certificate</a></li>
<li><a href="#checking-full-body">Checking Full Body</a></li>
</ul>
</li>
<li><a href="#reports">Reports</a>
<ul dir="auto">
<li><a href="#html-report">HTML Report</a></li>
<li><a href="#json-report">JSON Report</a></li>
<li><a href="#junit-report">JUnit Report</a></li>
<li><a href="#tap-report">TAP Report</a></li>
<li><a href="#json-output">JSON Output</a></li>
</ul>
</li>
<li><a href="#others">Others</a>
<ul dir="auto">
<li><a href="#http-version">HTTP Version</a></li>
<li><a href="#ip-address">IP Address</a></li>
<li><a href="#polling-and-retry">Polling and Retry</a></li>
<li><a href="#delaying-requests">Delaying Requests</a></li>
<li><a href="#skipping-requests">Skipping Requests</a></li>
<li><a href="#testing-endpoint-performance">Testing Endpoint Performance</a></li>
<li><a href="#using-soap-apis">Using SOAP APIs</a></li>
<li><a href="#capturing-and-using-a-csrf-token">Capturing and Using a CSRF Token</a></li>
<li><a href="#redacting-secrets">Redacting Secrets</a></li>
<li><a href="#checking-byte-order-mark-bom-in-response-body">Checking Byte Order Mark (BOM) in Response Body</a></li>
<li><a href="#aws-signature-version-4-requests">AWS Signature Version 4 Requests</a></li>
<li><a href="#using-curl-options">Using curl Options</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#manual">Manual</a>
<ul dir="auto">
<li><a href="#name">Name</a></li>
<li><a href="#synopsis">Synopsis</a></li>
<li><a href="#description">Description</a></li>
<li><a href="#hurl-file-format">Hurl File Format</a>
<ul dir="auto">
<li><a href="#capturing-values">Capturing values</a></li>
<li><a href="#asserts">Asserts</a></li>
</ul>
</li>
<li><a href="#options">Options</a></li>
<li><a href="#environment">Environment</a></li>
<li><a href="#exit-codes">Exit Codes</a></li>
<li><a href="#www">WWW</a></li>
<li><a href="#see-also">See Also</a></li>
</ul>
</li>
<li><a href="#installation">Installation</a>
<ul dir="auto">
<li><a href="#binaries-installation">Binaries Installation</a>
<ul dir="auto">
<li><a href="#linux">Linux</a>
<ul dir="auto">
<li><a href="#debian--ubuntu">Debian / Ubuntu</a></li>
<li><a href="#alpine">Alpine</a></li>
<li><a href="#arch-linux--manjaro">Arch Linux / Manjaro</a></li>
<li><a href="#nixos--nix">NixOS / Nix</a></li>
</ul>
</li>
<li><a href="#macos">macOS</a>
<ul dir="auto">
<li><a href="#homebrew">Homebrew</a></li>
<li><a href="#macports">MacPorts</a></li>
</ul>
</li>
<li><a href="#freebsd">FreeBSD</a></li>
<li><a href="#windows">Windows</a>
<ul dir="auto">
<li><a href="#zip-file">Zip File</a></li>
<li><a href="#installer">Installer</a></li>
<li><a href="#chocolatey">Chocolatey</a></li>
<li><a href="#scoop">Scoop</a></li>
<li><a href="#windows-package-manager">Windows Package Manager</a></li>
</ul>
</li>
<li><a href="#cargo">Cargo</a></li>
<li><a href="#conda-forge">conda-forge</a></li>
<li><a href="#docker">Docker</a></li>
<li><a href="#npm">npm</a></li>
</ul>
</li>
<li><a href="#building-from-sources">Building From Sources</a>
<ul dir="auto">
<li><a href="#build-on-linux">Build on Linux</a>
<ul dir="auto">
<li><a href="#debian-based-distributions">Debian based distributions</a></li>
<li><a href="#fedora-based-distributions">Fedora based distributions</a></li>
<li><a href="#red-hat-based-distributions">Red Hat based distributions</a></li>
<li><a href="#arch-based-distributions">Arch based distributions</a></li>
<li><a href="#alpine-based-distributions">Alpine based distributions</a></li>
</ul>
</li>
<li><a href="#build-on-macos">Build on macOS</a></li>
<li><a href="#build-on-windows">Build on Windows</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Samples</h2><a id="user-content-samples" aria-label="Permalink: Samples" href="#samples"></a></p>
<p dir="auto">To run a sample, edit a file with the sample content, and run Hurl:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ vi sample.hurl

GET https://example.org

$ hurl sample.hurl"><pre>$ vi sample.hurl

GET https://example.org

$ hurl sample.hurl</pre></div>
<p dir="auto">By default, Hurl behaves like <a href="https://curl.se/" rel="nofollow">curl</a> and outputs the last HTTP response's <a href="https://hurl.dev/docs/entry.html" rel="nofollow">entry</a>. To have a test
oriented output, you can use <a href="https://hurl.dev/docs/manual.html#test" rel="nofollow"><code>--test</code> option</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --test sample.hurl"><pre>$ hurl --test sample.hurl</pre></div>
<p dir="auto">A particular response can be saved with <a href="https://hurl.dev/docs/request.html#options" rel="nofollow"><code>[Options] section</code></a>:</p>
<div data-snippet-clipboard-copy-content="GET https://example.ord/cats/123
[Options]
output: cat123.txt    # use - to output to stdout
HTTP 200

GET https://example.ord/dogs/567
HTTP 200"><pre lang="hurl"><code>GET https://example.ord/cats/123
[Options]
output: cat123.txt    # use - to output to stdout
HTTP 200

GET https://example.ord/dogs/567
HTTP 200
</code></pre></div>
<p dir="auto">Finally, Hurl can take files as input, or directories. In the latter case, Hurl will search files with <code>.hurl</code> extension recursively.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --test integration/*.hurl
$ hurl --test ."><pre>$ hurl --test integration/<span>*</span>.hurl
$ hurl --test <span>.</span></pre></div>
<p dir="auto">You can check <a href="https://github.com/Orange-OpenSource/hurl/tree/master/integration/hurl/tests_ok">Hurl tests suite</a> for more samples.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Data</h2><a id="user-content-getting-data" aria-label="Permalink: Getting Data" href="#getting-data"></a></p>
<p dir="auto">A simple GET:</p>

<p dir="auto">Requests can be chained:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/a
GET https://example.org/b
HEAD https://example.org/c
GET https://example.org/c"><pre lang="hurl"><code>GET https://example.org/a
GET https://example.org/b
HEAD https://example.org/c
GET https://example.org/c
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#method" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">HTTP Headers</h3><a id="user-content-http-headers" aria-label="Permalink: HTTP Headers" href="#http-headers"></a></p>
<p dir="auto">A simple GET with headers:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/news
User-Agent: Mozilla/5.0 
Accept: */*
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate, br
Connection: keep-alive"><pre lang="hurl"><code>GET https://example.org/news
User-Agent: Mozilla/5.0 
Accept: */*
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate, br
Connection: keep-alive
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#headers" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Query Params</h3><a id="user-content-query-params" aria-label="Permalink: Query Params" href="#query-params"></a></p>
<div data-snippet-clipboard-copy-content="GET https://example.org/news
[Query]
order: newest
search: something to search
count: 100"><pre lang="hurl"><code>GET https://example.org/news
[Query]
order: newest
search: something to search
count: 100
</code></pre></div>
<p dir="auto">Or:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/news?order=newest&amp;search=something%20to%20search&amp;count=100"><pre lang="hurl"><code>GET https://example.org/news?order=newest&amp;search=something%20to%20search&amp;count=100
</code></pre></div>
<blockquote>
<p dir="auto">With <code>[Query]</code> section, params don't need to be URL escaped.</p>
</blockquote>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#query-parameters" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Basic Authentication</h3><a id="user-content-basic-authentication" aria-label="Permalink: Basic Authentication" href="#basic-authentication"></a></p>
<div data-snippet-clipboard-copy-content="GET https://example.org/protected
[BasicAuth]
bob: secret"><pre lang="hurl"><code>GET https://example.org/protected
[BasicAuth]
bob: secret
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#basic-authentication" rel="nofollow">Doc</a></p>
<p dir="auto">This is equivalent to construct the request with a <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Authorization" rel="nofollow">Authorization</a> header:</p>
<div data-snippet-clipboard-copy-content="# Authorization header value can be computed with `echo -n 'bob:secret' | base64`
GET https://example.org/protected
Authorization: Basic Ym9iOnNlY3JldA== "><pre lang="hurl"><code># Authorization header value can be computed with `echo -n 'bob:secret' | base64`
GET https://example.org/protected
Authorization: Basic Ym9iOnNlY3JldA== 
</code></pre></div>
<p dir="auto">Basic authentication section allows per request authentication. If you want to add basic authentication to all the
requests of a Hurl file you could use <a href="https://hurl.dev/docs/manual.html#user" rel="nofollow"><code>-u/--user</code> option</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --user bob:secret login.hurl"><pre>$ hurl --user bob:secret login.hurl</pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/manual.html#user" rel="nofollow"><code>--user</code></a> option can also be set per request:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/login
[Options]
user: bob:secret
HTTP 200

GET https://example.org/login
[Options]
user: alice:secret
HTTP 200"><pre lang="hurl"><code>GET https://example.org/login
[Options]
user: bob:secret
HTTP 200

GET https://example.org/login
[Options]
user: alice:secret
HTTP 200
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Passing Data between Requests</h3><a id="user-content-passing-data-between-requests" aria-label="Permalink: Passing Data between Requests" href="#passing-data-between-requests"></a></p>
<p dir="auto"><a href="https://hurl.dev/docs/capturing-response.html" rel="nofollow">Captures</a> can be used to pass data from one request to another:</p>
<div data-snippet-clipboard-copy-content="POST https://sample.org/orders
HTTP 201
[Captures]
order_id: jsonpath &quot;$.order.id&quot;

GET https://sample.org/orders/{{order_id}}
HTTP 200"><pre lang="hurl"><code>POST https://sample.org/orders
HTTP 201
[Captures]
order_id: jsonpath "$.order.id"

GET https://sample.org/orders/{{order_id}}
HTTP 200
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/capturing-response.html" rel="nofollow">Doc</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Sending Data</h2><a id="user-content-sending-data" aria-label="Permalink: Sending Data" href="#sending-data"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Sending HTML Form Data</h3><a id="user-content-sending-html-form-data" aria-label="Permalink: Sending HTML Form Data" href="#sending-html-form-data"></a></p>
<div data-snippet-clipboard-copy-content="POST https://example.org/contact
[Form]
default: false
token: {{token}}
email: john.doe@rookie.org
number: 33611223344"><pre lang="hurl"><code>POST https://example.org/contact
[Form]
default: false
token: {{token}}
email: john.doe@rookie.org
number: 33611223344
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#form-parameters" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Sending Multipart Form Data</h3><a id="user-content-sending-multipart-form-data" aria-label="Permalink: Sending Multipart Form Data" href="#sending-multipart-form-data"></a></p>
<div data-snippet-clipboard-copy-content="POST https://example.org/upload
[Multipart]
field1: value1
field2: file,example.txt;
# One can specify the file content type:
field3: file,example.zip; application/zip"><pre lang="hurl"><code>POST https://example.org/upload
[Multipart]
field1: value1
field2: file,example.txt;
# One can specify the file content type:
field3: file,example.zip; application/zip
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#multipart-form-data" rel="nofollow">Doc</a></p>
<p dir="auto">Multipart forms can also be sent with a <a href="https://hurl.dev/docs/request.html#multiline-string-body" rel="nofollow">multiline string body</a>:</p>
<div data-snippet-clipboard-copy-content="POST https://example.org/upload
Content-Type: multipart/form-data; boundary=&quot;boundary&quot;
```
--boundary
Content-Disposition: form-data; name=&quot;key1&quot;

value1
--boundary
Content-Disposition: form-data; name=&quot;upload1&quot;; filename=&quot;data.txt&quot;
Content-Type: text/plain

Hello World!
--boundary
Content-Disposition: form-data; name=&quot;upload2&quot;; filename=&quot;data.html&quot;
Content-Type: text/html

<div>Hello <b>World</b>!</div>
--boundary--
```"><pre lang="hurl"><code>POST https://example.org/upload
Content-Type: multipart/form-data; boundary="boundary"
```
--boundary
Content-Disposition: form-data; name="key1"

value1
--boundary
Content-Disposition: form-data; name="upload1"; filename="data.txt"
Content-Type: text/plain

Hello World!
--boundary
Content-Disposition: form-data; name="upload2"; filename="data.html"
Content-Type: text/html

&lt;div&gt;Hello &lt;b&gt;World&lt;/b&gt;!&lt;/div&gt;
--boundary--
```
</code></pre></div>
<p dir="auto">In that case, files have to be inlined in the Hurl file.</p>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#multiline-string-body" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Posting a JSON Body</h3><a id="user-content-posting-a-json-body" aria-label="Permalink: Posting a JSON Body" href="#posting-a-json-body"></a></p>
<p dir="auto">With an inline JSON:</p>
<div data-snippet-clipboard-copy-content="POST https://example.org/api/tests
{
    &quot;id&quot;: &quot;456&quot;,
    &quot;evaluate&quot;: true
}"><pre lang="hurl"><code>POST https://example.org/api/tests
{
    "id": "456",
    "evaluate": true
}
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#json-body" rel="nofollow">Doc</a></p>
<p dir="auto">With a local file:</p>
<div data-snippet-clipboard-copy-content="POST https://example.org/api/tests
Content-Type: application/json
file,data.json;"><pre lang="hurl"><code>POST https://example.org/api/tests
Content-Type: application/json
file,data.json;
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#file-body" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Templating a JSON Body</h3><a id="user-content-templating-a-json-body" aria-label="Permalink: Templating a JSON Body" href="#templating-a-json-body"></a></p>
<div data-snippet-clipboard-copy-content="PUT https://example.org/api/hits
Content-Type: application/json
{
    &quot;key0&quot;: &quot;{{a_string}}&quot;,
    &quot;key1&quot;: {{a_bool}},
    &quot;key2&quot;: {{a_null}},
    &quot;key3&quot;: {{a_number}}
}"><pre lang="hurl"><code>PUT https://example.org/api/hits
Content-Type: application/json
{
    "key0": "{{a_string}}",
    "key1": {{a_bool}},
    "key2": {{a_null}},
    "key3": {{a_number}}
}
</code></pre></div>
<p dir="auto">Variables can be initialized via command line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --variable a_string=apple \
       --variable a_bool=true \
       --variable a_null=null \
       --variable a_number=42 \
       test.hurl"><pre>$ hurl --variable a_string=apple \
       --variable a_bool=true \
       --variable a_null=null \
       --variable a_number=42 \
       test.hurl</pre></div>
<p dir="auto">Resulting in a PUT request with the following JSON body:</p>
<div data-snippet-clipboard-copy-content="{
    &quot;key0&quot;: &quot;apple&quot;,
    &quot;key1&quot;: true,
    &quot;key2&quot;: null,
    &quot;key3&quot;: 42
}"><pre><code>{
    "key0": "apple",
    "key1": true,
    "key2": null,
    "key3": 42
}
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/templates.html" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Templating a XML Body</h3><a id="user-content-templating-a-xml-body" aria-label="Permalink: Templating a XML Body" href="#templating-a-xml-body"></a></p>
<p dir="auto">Using templates with <a href="https://hurl.dev/docs/request.html#xml-body" rel="nofollow">XML body</a> is not currently supported in Hurl. You can use templates in
<a href="https://hurl.dev/docs/request.html#multiline-string-body" rel="nofollow">XML multiline string body</a> with variables to send a variable XML body:</p>
<div data-snippet-clipboard-copy-content="POST https://example.org/echo/post/xml
```xml
<?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?>
<Request>
    <Login>{{login}}</Login>
    <Password>{{password}}</Password>
</Request>
```"><pre lang="hurl"><code>POST https://example.org/echo/post/xml
```xml
&lt;?xml version="1.0" encoding="utf-8"?&gt;
&lt;Request&gt;
    &lt;Login&gt;{{login}}&lt;/Login&gt;
    &lt;Password&gt;{{password}}&lt;/Password&gt;
&lt;/Request&gt;
```
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#multiline-string-body" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using GraphQL Query</h3><a id="user-content-using-graphql-query" aria-label="Permalink: Using GraphQL Query" href="#using-graphql-query"></a></p>
<p dir="auto">A simple GraphQL query:</p>
<div data-snippet-clipboard-copy-content="POST https://example.org/starwars/graphql
```graphql
{
  human(id: &quot;1000&quot;) {
    name
    height(unit: FOOT)
  }
}
```"><pre lang="hurl"><code>POST https://example.org/starwars/graphql
```graphql
{
  human(id: "1000") {
    name
    height(unit: FOOT)
  }
}
```
</code></pre></div>
<p dir="auto">A GraphQL query with variables:</p>
<div data-snippet-clipboard-copy-content="POST https://example.org/starwars/graphql
```graphql
query Hero($episode: Episode, $withFriends: Boolean!) {
  hero(episode: $episode) {
    name
    friends @include(if: $withFriends) {
      name
    }
  }
}

variables {
  &quot;episode&quot;: &quot;JEDI&quot;,
  &quot;withFriends&quot;: false
}
```"><pre lang="hurl"><code>POST https://example.org/starwars/graphql
```graphql
query Hero($episode: Episode, $withFriends: Boolean!) {
  hero(episode: $episode) {
    name
    friends @include(if: $withFriends) {
      name
    }
  }
}

variables {
  "episode": "JEDI",
  "withFriends": false
}
```
</code></pre></div>
<p dir="auto">GraphQL queries can also use <a href="https://hurl.dev/docs/templates.html" rel="nofollow">Hurl templates</a>.</p>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#graphql-body" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using Dynamic Datas</h3><a id="user-content-using-dynamic-datas" aria-label="Permalink: Using Dynamic Datas" href="#using-dynamic-datas"></a></p>
<p dir="auto"><a href="https://hurl.dev/docs/templates.html#functions" rel="nofollow">Functions</a> like <code>newUuid</code> and <code>newDate</code> can be used in templates to create dynamic datas:</p>
<p dir="auto">A file that creates a dynamic email (i.e <code>0531f78f-7f87-44be-a7f2-969a1c4e6d97@test.com</code>):</p>
<div data-snippet-clipboard-copy-content="POST https://example.org/api/foo
{
  &quot;name&quot;: &quot;foo&quot;,
  &quot;email&quot;: &quot;{{newUuid}}@test.com&quot;
}"><pre lang="hurl"><code>POST https://example.org/api/foo
{
  "name": "foo",
  "email": "{{newUuid}}@test.com"
}
</code></pre></div>
<p dir="auto">A file that creates a dynamic query parameter (i.e <code>2024-12-02T10:35:44.461731Z</code>):</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/api/foo
[Query]
date: {{newDate}}
HTTP 200"><pre lang="hurl"><code>GET https://example.org/api/foo
[Query]
date: {{newDate}}
HTTP 200
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/templates.html#functions" rel="nofollow">Doc</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Testing Response</h2><a id="user-content-testing-response" aria-label="Permalink: Testing Response" href="#testing-response"></a></p>
<p dir="auto">Responses are optional, everything after <code>HTTP</code> is part of the response asserts.</p>
<div data-snippet-clipboard-copy-content="# A request with (almost) no check:
GET https://foo.com

# A status code check:
GET https://foo.com
HTTP 200

# A test on response body
GET https://foo.com
HTTP 200
[Asserts]
jsonpath &quot;$.state&quot; == &quot;running&quot;"><pre lang="hurl"><code># A request with (almost) no check:
GET https://foo.com

# A status code check:
GET https://foo.com
HTTP 200

# A test on response body
GET https://foo.com
HTTP 200
[Asserts]
jsonpath "$.state" == "running"
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing Status Code</h3><a id="user-content-testing-status-code" aria-label="Permalink: Testing Status Code" href="#testing-status-code"></a></p>
<div data-snippet-clipboard-copy-content="GET https://example.org/order/435
HTTP 200"><pre lang="hurl"><code>GET https://example.org/order/435
HTTP 200
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#version-status" rel="nofollow">Doc</a></p>
<div data-snippet-clipboard-copy-content="GET https://example.org/order/435
# Testing status code is in a 200-300 range
HTTP *
[Asserts]
status >= 200
status < 300"><pre lang="hurl"><code>GET https://example.org/order/435
# Testing status code is in a 200-300 range
HTTP *
[Asserts]
status &gt;= 200
status &lt; 300
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#status-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing Response Headers</h3><a id="user-content-testing-response-headers" aria-label="Permalink: Testing Response Headers" href="#testing-response-headers"></a></p>
<p dir="auto">Use implicit response asserts to test header values:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/index.html
HTTP 200
Set-Cookie: theme=light
Set-Cookie: sessionToken=abc123; Expires=Wed, 09 Jun 2021 10:18:14 GMT"><pre lang="hurl"><code>GET https://example.org/index.html
HTTP 200
Set-Cookie: theme=light
Set-Cookie: sessionToken=abc123; Expires=Wed, 09 Jun 2021 10:18:14 GMT
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#headers" rel="nofollow">Doc</a></p>
<p dir="auto">Or use explicit response asserts with <a href="https://hurl.dev/docs/asserting-response.html#predicates" rel="nofollow">predicates</a>:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org
HTTP 302
[Asserts]
header &quot;Location&quot; contains &quot;www.example.net&quot;"><pre lang="hurl"><code>GET https://example.org
HTTP 302
[Asserts]
header "Location" contains "www.example.net"
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#header-assert" rel="nofollow">Doc</a></p>
<p dir="auto">Implicit and explicit asserts can be combined:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/index.html
HTTP 200
Set-Cookie: theme=light
Set-Cookie: sessionToken=abc123; Expires=Wed, 09 Jun 2021 10:18:14 GMT
[Asserts]
header &quot;Location&quot; contains &quot;www.example.net&quot;"><pre lang="hurl"><code>GET https://example.org/index.html
HTTP 200
Set-Cookie: theme=light
Set-Cookie: sessionToken=abc123; Expires=Wed, 09 Jun 2021 10:18:14 GMT
[Asserts]
header "Location" contains "www.example.net"
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing REST APIs</h3><a id="user-content-testing-rest-apis" aria-label="Permalink: Testing REST APIs" href="#testing-rest-apis"></a></p>
<p dir="auto">Asserting JSON body response (node values, collection count etc...) with <a href="https://goessner.net/articles/JsonPath/" rel="nofollow">JSONPath</a>:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/order
screencapability: low
HTTP 200
[Asserts]
jsonpath &quot;$.validated&quot; == true
jsonpath &quot;$.userInfo.firstName&quot; == &quot;Franck&quot;
jsonpath &quot;$.userInfo.lastName&quot; == &quot;Herbert&quot;
jsonpath &quot;$.hasDevice&quot; == false
jsonpath &quot;$.links&quot; count == 12
jsonpath &quot;$.state&quot; != null
jsonpath &quot;$.order&quot; matches &quot;^order-\\d{8}$&quot;
jsonpath &quot;$.order&quot; matches /^order-\d{8}$/     # Alternative syntax with regex literal
jsonpath &quot;$.created&quot; isIsoDate"><pre lang="hurl"><code>GET https://example.org/order
screencapability: low
HTTP 200
[Asserts]
jsonpath "$.validated" == true
jsonpath "$.userInfo.firstName" == "Franck"
jsonpath "$.userInfo.lastName" == "Herbert"
jsonpath "$.hasDevice" == false
jsonpath "$.links" count == 12
jsonpath "$.state" != null
jsonpath "$.order" matches "^order-\\d{8}$"
jsonpath "$.order" matches /^order-\d{8}$/     # Alternative syntax with regex literal
jsonpath "$.created" isIsoDate
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#jsonpath-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing HTML Response</h3><a id="user-content-testing-html-response" aria-label="Permalink: Testing HTML Response" href="#testing-html-response"></a></p>
<div data-snippet-clipboard-copy-content="GET https://example.org
HTTP 200
Content-Type: text/html; charset=UTF-8
[Asserts]
xpath &quot;string(/html/head/title)&quot; contains &quot;Example&quot; # Check title
xpath &quot;count(//p)&quot; == 2  # Check the number of p
xpath &quot;//p&quot; count == 2  # Similar assert for p
xpath &quot;boolean(count(//h2))&quot; == false  # Check there is no h2  
xpath &quot;//h2&quot; not exists  # Similar assert for h2
xpath &quot;string(//div[1])&quot; matches /Hello.*/"><pre lang="hurl"><code>GET https://example.org
HTTP 200
Content-Type: text/html; charset=UTF-8
[Asserts]
xpath "string(/html/head/title)" contains "Example" # Check title
xpath "count(//p)" == 2  # Check the number of p
xpath "//p" count == 2  # Similar assert for p
xpath "boolean(count(//h2))" == false  # Check there is no h2  
xpath "//h2" not exists  # Similar assert for h2
xpath "string(//div[1])" matches /Hello.*/
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#xpath-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing Set-Cookie Attributes</h3><a id="user-content-testing-set-cookie-attributes" aria-label="Permalink: Testing Set-Cookie Attributes" href="#testing-set-cookie-attributes"></a></p>
<div data-snippet-clipboard-copy-content="GET https://example.org/home
HTTP 200
[Asserts]
cookie &quot;JSESSIONID&quot; == &quot;8400BAFE2F66443613DC38AE3D9D6239&quot;
cookie &quot;JSESSIONID[Value]&quot; == &quot;8400BAFE2F66443613DC38AE3D9D6239&quot;
cookie &quot;JSESSIONID[Expires]&quot; contains &quot;Wed, 13 Jan 2021&quot;
cookie &quot;JSESSIONID[Secure]&quot; exists
cookie &quot;JSESSIONID[HttpOnly]&quot; exists
cookie &quot;JSESSIONID[SameSite]&quot; == &quot;Lax&quot;"><pre lang="hurl"><code>GET https://example.org/home
HTTP 200
[Asserts]
cookie "JSESSIONID" == "8400BAFE2F66443613DC38AE3D9D6239"
cookie "JSESSIONID[Value]" == "8400BAFE2F66443613DC38AE3D9D6239"
cookie "JSESSIONID[Expires]" contains "Wed, 13 Jan 2021"
cookie "JSESSIONID[Secure]" exists
cookie "JSESSIONID[HttpOnly]" exists
cookie "JSESSIONID[SameSite]" == "Lax"
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#cookie-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing Bytes Content</h3><a id="user-content-testing-bytes-content" aria-label="Permalink: Testing Bytes Content" href="#testing-bytes-content"></a></p>
<p dir="auto">Check the SHA-256 response body hash:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/data.tar.gz
HTTP 200
[Asserts]
sha256 == hex,039058c6f2c0cb492c533b0a4d14ef77cc0f78abccced5287d84a1a2011cfb81;"><pre lang="hurl"><code>GET https://example.org/data.tar.gz
HTTP 200
[Asserts]
sha256 == hex,039058c6f2c0cb492c533b0a4d14ef77cc0f78abccced5287d84a1a2011cfb81;
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#sha-256-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">SSL Certificate</h3><a id="user-content-ssl-certificate" aria-label="Permalink: SSL Certificate" href="#ssl-certificate"></a></p>
<p dir="auto">Check the properties of a SSL certificate:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org
HTTP 200
[Asserts]
certificate &quot;Subject&quot; == &quot;CN=example.org&quot;
certificate &quot;Issuer&quot; == &quot;C=US, O=Let's Encrypt, CN=R3&quot;
certificate &quot;Expire-Date&quot; daysAfterNow > 15
certificate &quot;Serial-Number&quot; matches /[\da-f]+/"><pre lang="hurl"><code>GET https://example.org
HTTP 200
[Asserts]
certificate "Subject" == "CN=example.org"
certificate "Issuer" == "C=US, O=Let's Encrypt, CN=R3"
certificate "Expire-Date" daysAfterNow &gt; 15
certificate "Serial-Number" matches /[\da-f]+/
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#ssl-certificate-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Checking Full Body</h3><a id="user-content-checking-full-body" aria-label="Permalink: Checking Full Body" href="#checking-full-body"></a></p>
<p dir="auto">Use implicit body to test an exact JSON body match:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/api/cats/123
HTTP 200
{
  &quot;name&quot; : &quot;Purrsloud&quot;,
  &quot;species&quot; : &quot;Cat&quot;,
  &quot;favFoods&quot; : [&quot;wet food&quot;, &quot;dry food&quot;, &quot;<strong>any</strong> food&quot;],
  &quot;birthYear&quot; : 2016,
  &quot;photo&quot; : &quot;https://learnwebcode.github.io/json-example/images/cat-2.jpg&quot;
}"><pre lang="hurl"><code>GET https://example.org/api/cats/123
HTTP 200
{
  "name" : "Purrsloud",
  "species" : "Cat",
  "favFoods" : ["wet food", "dry food", "&lt;strong&gt;any&lt;/strong&gt; food"],
  "birthYear" : 2016,
  "photo" : "https://learnwebcode.github.io/json-example/images/cat-2.jpg"
}
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#json-body" rel="nofollow">Doc</a></p>
<p dir="auto">Or an explicit assert file:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/index.html
HTTP 200
[Asserts]
body == file,cat.json;"><pre lang="hurl"><code>GET https://example.org/index.html
HTTP 200
[Asserts]
body == file,cat.json;
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#body-assert" rel="nofollow">Doc</a></p>
<p dir="auto">Implicit asserts supports XML body:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/api/catalog
HTTP 200
<?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?>
<catalog>
   <book id=&quot;bk101&quot;>
      <author>Gambardella, Matthew</author>
      <title>XML Developer's Guide</title>
      <genre>Computer</genre>
      <price>44.95</price>
      <publish_date>2000-10-01</publish_date>
      <description>An in-depth look at creating applications with XML.</description>
   </book>
</catalog>"><pre lang="hurl"><code>GET https://example.org/api/catalog
HTTP 200
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;catalog&gt;
   &lt;book id="bk101"&gt;
      &lt;author&gt;Gambardella, Matthew&lt;/author&gt;
      &lt;title&gt;XML Developer's Guide&lt;/title&gt;
      &lt;genre&gt;Computer&lt;/genre&gt;
      &lt;price&gt;44.95&lt;/price&gt;
      &lt;publish_date&gt;2000-10-01&lt;/publish_date&gt;
      &lt;description&gt;An in-depth look at creating applications with XML.&lt;/description&gt;
   &lt;/book&gt;
&lt;/catalog&gt;
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#xml-body" rel="nofollow">Doc</a></p>
<p dir="auto">Plain text:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/models
HTTP 200
```
Year,Make,Model,Description,Price
1997,Ford,E350,&quot;ac, abs, moon&quot;,3000.00
1999,Chevy,&quot;Venture &quot;&quot;Extended Edition&quot;&quot;&quot;,&quot;&quot;,4900.00
1999,Chevy,&quot;Venture &quot;&quot;Extended Edition, Very Large&quot;&quot;&quot;,,5000.00
1996,Jeep,Grand Cherokee,&quot;MUST SELL! air, moon roof, loaded&quot;,4799.00
```"><pre lang="hurl"><code>GET https://example.org/models
HTTP 200
```
Year,Make,Model,Description,Price
1997,Ford,E350,"ac, abs, moon",3000.00
1999,Chevy,"Venture ""Extended Edition""","",4900.00
1999,Chevy,"Venture ""Extended Edition, Very Large""",,5000.00
1996,Jeep,Grand Cherokee,"MUST SELL! air, moon roof, loaded",4799.00
```
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#multiline-string-body" rel="nofollow">Doc</a></p>
<p dir="auto">One line:</p>
<div data-snippet-clipboard-copy-content="POST https://example.org/helloworld
HTTP 200
`Hello world!`"><pre lang="hurl"><code>POST https://example.org/helloworld
HTTP 200
`Hello world!`
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#oneline-string-body" rel="nofollow">Doc</a></p>
<p dir="auto">File:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org
HTTP 200
file,data.bin;"><pre lang="hurl"><code>GET https://example.org
HTTP 200
file,data.bin;
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#file-body" rel="nofollow">Doc</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Reports</h2><a id="user-content-reports" aria-label="Permalink: Reports" href="#reports"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">HTML Report</h3><a id="user-content-html-report" aria-label="Permalink: HTML Report" href="#html-report"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --test --report-html build/report/ *.hurl"><pre>$ hurl --test --report-html build/report/ <span>*</span>.hurl</pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/running-tests.html#generating-report" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">JSON Report</h3><a id="user-content-json-report" aria-label="Permalink: JSON Report" href="#json-report"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --test --report-json build/report/ *.hurl"><pre>$ hurl --test --report-json build/report/ <span>*</span>.hurl</pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/running-tests.html#generating-report" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">JUnit Report</h3><a id="user-content-junit-report" aria-label="Permalink: JUnit Report" href="#junit-report"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --test --report-junit build/report.xml *.hurl"><pre>$ hurl --test --report-junit build/report.xml <span>*</span>.hurl</pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/running-tests.html#generating-report" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">TAP Report</h3><a id="user-content-tap-report" aria-label="Permalink: TAP Report" href="#tap-report"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --test --report-tap build/report.txt *.hurl"><pre>$ hurl --test --report-tap build/report.txt <span>*</span>.hurl</pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/running-tests.html#generating-report" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">JSON Output</h3><a id="user-content-json-output" aria-label="Permalink: JSON Output" href="#json-output"></a></p>
<p dir="auto">A structured output of running Hurl files can be obtained with <a href="https://hurl.dev/docs/manual.html#json" rel="nofollow"><code>--json</code> option</a>. Each file will produce a JSON export of the run.</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Others</h2><a id="user-content-others" aria-label="Permalink: Others" href="#others"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">HTTP Version</h3><a id="user-content-http-version" aria-label="Permalink: HTTP Version" href="#http-version"></a></p>
<p dir="auto">Testing HTTP version (HTTP/1.0, HTTP/1.1, HTTP/2 or HTTP/3) can be done using implicit asserts:</p>
<div data-snippet-clipboard-copy-content="GET https://foo.com
HTTP/3 200

GET https://bar.com
HTTP/2 200"><pre lang="hurl"><code>GET https://foo.com
HTTP/3 200

GET https://bar.com
HTTP/2 200
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#version-status" rel="nofollow">Doc</a></p>
<p dir="auto">Or explicit:</p>
<div data-snippet-clipboard-copy-content="GET https://foo.com
HTTP 200
[Asserts]
version == &quot;3&quot;

GET https://bar.com
HTTP 200
[Asserts]
version == &quot;2&quot;
version toFloat > 1.1"><pre lang="hurl"><code>GET https://foo.com
HTTP 200
[Asserts]
version == "3"

GET https://bar.com
HTTP 200
[Asserts]
version == "2"
version toFloat &gt; 1.1
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#version-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">IP Address</h3><a id="user-content-ip-address" aria-label="Permalink: IP Address" href="#ip-address"></a></p>
<p dir="auto">Testing the IP address of the response, as a string. This string may be IPv6 address:</p>
<div data-snippet-clipboard-copy-content="GET https://foo.com
HTTP 200
[Asserts]
ip == &quot;2001:0db8:85a3:0000:0000:8a2e:0370:733&quot;
ip startsWith &quot;2001&quot;
ip isIpv6"><pre lang="hurl"><code>GET https://foo.com
HTTP 200
[Asserts]
ip == "2001:0db8:85a3:0000:0000:8a2e:0370:733"
ip startsWith "2001"
ip isIpv6
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Polling and Retry</h3><a id="user-content-polling-and-retry" aria-label="Permalink: Polling and Retry" href="#polling-and-retry"></a></p>
<p dir="auto">Retry request on any errors (asserts, captures, status code, runtime etc...):</p>
<div data-snippet-clipboard-copy-content="# Create a new job
POST https://api.example.org/jobs
HTTP 201
[Captures]
job_id: jsonpath &quot;$.id&quot;
[Asserts]
jsonpath &quot;$.state&quot; == &quot;RUNNING&quot;


# Pull job status until it is completed
GET https://api.example.org/jobs/{{job_id}}
[Options]
retry: 10   # maximum number of retry, -1 for unlimited
retry-interval: 500ms
HTTP 200
[Asserts]
jsonpath &quot;$.state&quot; == &quot;COMPLETED&quot;"><pre lang="hurl"><code># Create a new job
POST https://api.example.org/jobs
HTTP 201
[Captures]
job_id: jsonpath "$.id"
[Asserts]
jsonpath "$.state" == "RUNNING"


# Pull job status until it is completed
GET https://api.example.org/jobs/{{job_id}}
[Options]
retry: 10   # maximum number of retry, -1 for unlimited
retry-interval: 500ms
HTTP 200
[Asserts]
jsonpath "$.state" == "COMPLETED"
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/entry.html#retry" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Delaying Requests</h3><a id="user-content-delaying-requests" aria-label="Permalink: Delaying Requests" href="#delaying-requests"></a></p>
<p dir="auto">Add delay for every request, or a particular request:</p>
<div data-snippet-clipboard-copy-content="# Delaying this request by 5 seconds (aka sleep)
GET https://example.org/turtle
[Options]
delay: 5s
HTTP 200

# No delay!
GET https://example.org/turtle
HTTP 200"><pre lang="hurl"><code># Delaying this request by 5 seconds (aka sleep)
GET https://example.org/turtle
[Options]
delay: 5s
HTTP 200

# No delay!
GET https://example.org/turtle
HTTP 200
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/manual.html#delay" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Skipping Requests</h3><a id="user-content-skipping-requests" aria-label="Permalink: Skipping Requests" href="#skipping-requests"></a></p>
<div data-snippet-clipboard-copy-content="# a, c, d are run, b is skipped
GET https://example.org/a

GET https://example.org/b
[Options]
skip: true

GET https://example.org/c

GET https://example.org/d"><pre lang="hurl"><code># a, c, d are run, b is skipped
GET https://example.org/a

GET https://example.org/b
[Options]
skip: true

GET https://example.org/c

GET https://example.org/d
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/manual.html#skip" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing Endpoint Performance</h3><a id="user-content-testing-endpoint-performance" aria-label="Permalink: Testing Endpoint Performance" href="#testing-endpoint-performance"></a></p>
<div data-snippet-clipboard-copy-content="GET https://sample.org/helloworld
HTTP *
[Asserts]
duration < 1000   # Check that response time is less than one second"><pre lang="hurl"><code>GET https://sample.org/helloworld
HTTP *
[Asserts]
duration &lt; 1000   # Check that response time is less than one second
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#duration-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using SOAP APIs</h3><a id="user-content-using-soap-apis" aria-label="Permalink: Using SOAP APIs" href="#using-soap-apis"></a></p>
<div data-snippet-clipboard-copy-content="POST https://example.org/InStock
Content-Type: application/soap+xml; charset=utf-8
SOAPAction: &quot;http://www.w3.org/2003/05/soap-envelope&quot;
<?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?>
<soap:Envelope xmlns:soap=&quot;http://www.w3.org/2003/05/soap-envelope&quot; xmlns:m=&quot;https://example.org&quot;>
  <soap:Header></soap:Header>
  <soap:Body>
    <m:GetStockPrice>
      <m:StockName>GOOG</m:StockName>
    </m:GetStockPrice>
  </soap:Body>
</soap:Envelope>
HTTP 200"><pre lang="hurl"><code>POST https://example.org/InStock
Content-Type: application/soap+xml; charset=utf-8
SOAPAction: "http://www.w3.org/2003/05/soap-envelope"
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;soap:Envelope xmlns:soap="http://www.w3.org/2003/05/soap-envelope" xmlns:m="https://example.org"&gt;
  &lt;soap:Header&gt;&lt;/soap:Header&gt;
  &lt;soap:Body&gt;
    &lt;m:GetStockPrice&gt;
      &lt;m:StockName&gt;GOOG&lt;/m:StockName&gt;
    &lt;/m:GetStockPrice&gt;
  &lt;/soap:Body&gt;
&lt;/soap:Envelope&gt;
HTTP 200
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#xml-body" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Capturing and Using a CSRF Token</h3><a id="user-content-capturing-and-using-a-csrf-token" aria-label="Permalink: Capturing and Using a CSRF Token" href="#capturing-and-using-a-csrf-token"></a></p>
<div data-snippet-clipboard-copy-content="GET https://example.org
HTTP 200
[Captures]
csrf_token: xpath &quot;string(//meta[@name='_csrf_token']/@content)&quot;


POST https://example.org/login?user=toto&amp;password=1234
X-CSRF-TOKEN: {{csrf_token}}
HTTP 302"><pre lang="hurl"><code>GET https://example.org
HTTP 200
[Captures]
csrf_token: xpath "string(//meta[@name='_csrf_token']/@content)"


POST https://example.org/login?user=toto&amp;password=1234
X-CSRF-TOKEN: {{csrf_token}}
HTTP 302
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/capturing-response.html#xpath-capture" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Redacting Secrets</h3><a id="user-content-redacting-secrets" aria-label="Permalink: Redacting Secrets" href="#redacting-secrets"></a></p>
<p dir="auto">Using command-line for known values:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --secret token=1234 file.hurl"><pre>$ hurl --secret token=1234 file.hurl</pre></div>
<div data-snippet-clipboard-copy-content="POST https://example.org
X-Token: {{token}}
{
  &quot;name&quot;: &quot;Alice&quot;,
  &quot;value&quot;: 100
}
HTTP 200"><pre lang="hurl"><code>POST https://example.org
X-Token: {{token}}
{
  "name": "Alice",
  "value": 100
}
HTTP 200
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/templates.html#secrets" rel="nofollow">Doc</a></p>
<p dir="auto">Using <code>redact</code> for dynamic values:</p>
<div data-snippet-clipboard-copy-content="# Get an authorization token:
GET https://example.org/token
HTTP 200
[Captures]
token: header &quot;X-Token&quot; redact

# Send an authorized request:
POST https://example.org
X-Token: {{token}}
{
  &quot;name&quot;: &quot;Alice&quot;,
  &quot;value&quot;: 100
}
HTTP 200"><pre lang="hurl"><code># Get an authorization token:
GET https://example.org/token
HTTP 200
[Captures]
token: header "X-Token" redact

# Send an authorized request:
POST https://example.org
X-Token: {{token}}
{
  "name": "Alice",
  "value": 100
}
HTTP 200
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/capturing-response.html#redacting-secrets" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Checking Byte Order Mark (BOM) in Response Body</h3><a id="user-content-checking-byte-order-mark-bom-in-response-body" aria-label="Permalink: Checking Byte Order Mark (BOM) in Response Body" href="#checking-byte-order-mark-bom-in-response-body"></a></p>
<div data-snippet-clipboard-copy-content="GET https://example.org/data.bin
HTTP 200
[Asserts]
bytes startsWith hex,efbbbf;"><pre lang="hurl"><code>GET https://example.org/data.bin
HTTP 200
[Asserts]
bytes startsWith hex,efbbbf;
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#bytes-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">AWS Signature Version 4 Requests</h3><a id="user-content-aws-signature-version-4-requests" aria-label="Permalink: AWS Signature Version 4 Requests" href="#aws-signature-version-4-requests"></a></p>
<p dir="auto">Generate signed API requests with <a href="https://docs.aws.amazon.com/AmazonS3/latest/API/sig-v4-authenticating-requests.html" rel="nofollow">AWS Signature Version 4</a>, as used by several cloud providers.</p>
<div data-snippet-clipboard-copy-content="POST https://sts.eu-central-1.amazonaws.com/
[Options]
aws-sigv4: aws:amz:eu-central-1:sts
[Form]
Action: GetCallerIdentity
Version: 2011-06-15"><pre lang="hurl"><code>POST https://sts.eu-central-1.amazonaws.com/
[Options]
aws-sigv4: aws:amz:eu-central-1:sts
[Form]
Action: GetCallerIdentity
Version: 2011-06-15
</code></pre></div>
<p dir="auto">The Access Key is given per <a href="https://hurl.dev/docs/manual.html#user" rel="nofollow"><code>--user</code></a>, either with command line option or within the <a href="https://hurl.dev/docs/request.html#options" rel="nofollow"><code>[Options]</code></a> section:</p>
<div data-snippet-clipboard-copy-content="POST https://sts.eu-central-1.amazonaws.com/
[Options]
aws-sigv4: aws:amz:eu-central-1:sts
user: bob=secret
[Form]
Action: GetCallerIdentity
Version: 2011-06-15"><pre lang="hurl"><code>POST https://sts.eu-central-1.amazonaws.com/
[Options]
aws-sigv4: aws:amz:eu-central-1:sts
user: bob=secret
[Form]
Action: GetCallerIdentity
Version: 2011-06-15
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/manual.html#aws-sigv4" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using curl Options</h3><a id="user-content-using-curl-options" aria-label="Permalink: Using curl Options" href="#using-curl-options"></a></p>
<p dir="auto">curl options (for instance <a href="https://hurl.dev/docs/manual.html#resolve" rel="nofollow"><code>--resolve</code></a> or <a href="https://hurl.dev/docs/manual.html#connect-to" rel="nofollow"><code>--connect-to</code></a>) can be used as CLI argument. In this case, they're applicable
to each request of an Hurl file.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --resolve foo.com:8000:127.0.0.1 foo.hurl"><pre>$ hurl --resolve foo.com:8000:127.0.0.1 foo.hurl</pre></div>
<p dir="auto">Use  <a href="https://hurl.dev/docs/request.html#options" rel="nofollow"><code>[Options]</code> section</a> to configure a specific request:</p>
<div data-snippet-clipboard-copy-content="GET http://bar.com
HTTP 200


GET http://foo.com:8000/resolve
[Options]
resolve: foo.com:8000:127.0.0.1
HTTP 200
`Hello World!`"><pre lang="hurl"><code>GET http://bar.com
HTTP 200


GET http://foo.com:8000/resolve
[Options]
resolve: foo.com:8000:127.0.0.1
HTTP 200
`Hello World!`
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#options" rel="nofollow">Doc</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Manual</h2><a id="user-content-manual" aria-label="Permalink: Manual" href="#manual"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Name</h2><a id="user-content-name" aria-label="Permalink: Name" href="#name"></a></p>
<p dir="auto">hurl - run and test HTTP requests.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Synopsis</h2><a id="user-content-synopsis" aria-label="Permalink: Synopsis" href="#synopsis"></a></p>
<p dir="auto"><strong>hurl</strong> [options] [FILE...]</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Description</h2><a id="user-content-description" aria-label="Permalink: Description" href="#description"></a></p>
<p dir="auto"><strong>Hurl</strong> is a command line tool that runs HTTP requests defined in a simple plain text format.</p>
<p dir="auto">It can chain requests, capture values and evaluate queries on headers and body response. Hurl is very versatile, it can be used for fetching data and testing HTTP sessions: HTML content, REST / SOAP / GraphQL APIs, or any other XML / JSON based APIs.</p>

<p dir="auto">If no input files are specified, input is read from stdin.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ echo GET http://httpbin.org/get | hurl
    {
      &quot;args&quot;: {},
      &quot;headers&quot;: {
        &quot;Accept&quot;: &quot;*/*&quot;,
        &quot;Accept-Encoding&quot;: &quot;gzip&quot;,
        &quot;Content-Length&quot;: &quot;0&quot;,
        &quot;Host&quot;: &quot;httpbin.org&quot;,
        &quot;User-Agent&quot;: &quot;hurl/0.99.10&quot;,
        &quot;X-Amzn-Trace-Id&quot;: &quot;Root=1-5eedf4c7-520814d64e2f9249ea44e0&quot;
      },
      &quot;origin&quot;: &quot;1.2.3.4&quot;,
      &quot;url&quot;: &quot;http://httpbin.org/get&quot;
    }"><pre>$ <span>echo</span> GET http://httpbin.org/get <span>|</span> hurl
    {
      <span><span>"</span>args<span>"</span></span>: {},
      <span><span>"</span>headers<span>"</span></span>: {
        <span><span>"</span>Accept<span>"</span></span>: <span><span>"</span>*/*<span>"</span></span>,
        <span><span>"</span>Accept-Encoding<span>"</span></span>: <span><span>"</span>gzip<span>"</span></span>,
        <span><span>"</span>Content-Length<span>"</span></span>: <span><span>"</span>0<span>"</span></span>,
        <span><span>"</span>Host<span>"</span></span>: <span><span>"</span>httpbin.org<span>"</span></span>,
        <span><span>"</span>User-Agent<span>"</span></span>: <span><span>"</span>hurl/0.99.10<span>"</span></span>,
        <span><span>"</span>X-Amzn-Trace-Id<span>"</span></span>: <span><span>"</span>Root=1-5eedf4c7-520814d64e2f9249ea44e0<span>"</span></span>
      },
      <span><span>"</span>origin<span>"</span></span>: <span><span>"</span>1.2.3.4<span>"</span></span>,
      <span><span>"</span>url<span>"</span></span>: <span><span>"</span>http://httpbin.org/get<span>"</span></span>
    }</pre></div>
<p dir="auto">Hurl can take files as input, or directories. In the latter case, Hurl will search files with <code>.hurl</code> extension recursively.</p>
<p dir="auto">Output goes to stdout by default. To have output go to a file, use the <a href="#output"><code>-o, --output</code></a> option:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl -o output input.hurl"><pre>$ hurl -o output input.hurl</pre></div>
<p dir="auto">By default, Hurl executes all HTTP requests and outputs the response body of the last HTTP call.</p>
<p dir="auto">To have a test oriented output, you can use <a href="#test"><code>--test</code></a> option:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Hurl File Format</h2><a id="user-content-hurl-file-format" aria-label="Permalink: Hurl File Format" href="#hurl-file-format"></a></p>
<p dir="auto">The Hurl file format is fully documented in <a href="https://hurl.dev/docs/hurl-file.html" rel="nofollow">https://hurl.dev/docs/hurl-file.html</a></p>
<p dir="auto">It consists of one or several HTTP requests</p>
<div data-snippet-clipboard-copy-content="GET http://example.org/endpoint1
GET http://example.org/endpoint2"><pre lang="hurl"><code>GET http://example.org/endpoint1
GET http://example.org/endpoint2
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Capturing values</h3><a id="user-content-capturing-values" aria-label="Permalink: Capturing values" href="#capturing-values"></a></p>
<p dir="auto">A value from an HTTP response can be-reused for successive HTTP requests.</p>
<p dir="auto">A typical example occurs with CSRF tokens.</p>
<div data-snippet-clipboard-copy-content="GET https://example.org
HTTP 200
# Capture the CSRF token value from html body.
[Captures]
csrf_token: xpath &quot;normalize-space(//meta[@name='_csrf_token']/@content)&quot;

# Do the login !
POST https://example.org/login?user=toto&amp;password=1234
X-CSRF-TOKEN: {{csrf_token}}"><pre lang="hurl"><code>GET https://example.org
HTTP 200
# Capture the CSRF token value from html body.
[Captures]
csrf_token: xpath "normalize-space(//meta[@name='_csrf_token']/@content)"

# Do the login !
POST https://example.org/login?user=toto&amp;password=1234
X-CSRF-TOKEN: {{csrf_token}}
</code></pre></div>
<p dir="auto">More information on captures can be found here <a href="https://hurl.dev/docs/capturing-response.html" rel="nofollow">https://hurl.dev/docs/capturing-response.html</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Asserts</h3><a id="user-content-asserts" aria-label="Permalink: Asserts" href="#asserts"></a></p>
<p dir="auto">The HTTP response defined in the Hurl file are used to make asserts. Responses are optional.</p>
<p dir="auto">At the minimum, response includes assert on the HTTP status code.</p>
<div data-snippet-clipboard-copy-content="GET http://example.org
HTTP 301"><pre lang="hurl"><code>GET http://example.org
HTTP 301
</code></pre></div>
<p dir="auto">It can also include asserts on the response headers</p>
<div data-snippet-clipboard-copy-content="GET http://example.org
HTTP 301
Location: http://www.example.org"><pre lang="hurl"><code>GET http://example.org
HTTP 301
Location: http://www.example.org
</code></pre></div>
<p dir="auto">Explicit asserts can be included by combining a query and a predicate</p>
<div data-snippet-clipboard-copy-content="GET http://example.org
HTTP 301
[Asserts]
xpath &quot;string(//title)&quot; == &quot;301 Moved&quot;"><pre lang="hurl"><code>GET http://example.org
HTTP 301
[Asserts]
xpath "string(//title)" == "301 Moved"
</code></pre></div>
<p dir="auto">With the addition of asserts, Hurl can be used as a testing tool to run scenarios.</p>
<p dir="auto">More information on asserts can be found here <a href="https://hurl.dev/docs/asserting-response.html" rel="nofollow">https://hurl.dev/docs/asserting-response.html</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Options</h2><a id="user-content-options" aria-label="Permalink: Options" href="#options"></a></p>
<p dir="auto">Options that exist in curl have exactly the same semantics.</p>
<p dir="auto">Options specified on the command line are defined for every Hurl file's entry,
except if they are tagged as cli-only (can not be defined in the Hurl request [Options] entry)</p>
<p dir="auto">For instance:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --location foo.hurl"><pre>$ hurl --location foo.hurl</pre></div>
<p dir="auto">will follow redirection for each entry in <code>foo.hurl</code>. You can also define an option only for a particular entry with an <code>[Options]</code> section. For instance, this Hurl file:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org
HTTP 301

GET https://example.org
[Options]
location: true
HTTP 200"><pre lang="hurl"><code>GET https://example.org
HTTP 301

GET https://example.org
[Options]
location: true
HTTP 200
</code></pre></div>
<p dir="auto">will follow a redirection only for the second entry.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Option</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#aws-sigv4" id="user-content-aws-sigv4"><code>--aws-sigv4 &lt;PROVIDER1[:PROVIDER2[:REGION[:SERVICE]]]&gt;</code></a></td>
<td>Generate an <code>Authorization</code> header with an AWS SigV4 signature.<p>Use <a href="#user"><code>-u, --user</code></a> to specify Access Key Id (username) and Secret Key (password).</p><p>To use temporary session credentials (e.g. for an AWS IAM Role), add the <code>X-Amz-Security-Token</code> header containing the session token.</p></td>
</tr>
<tr>
<td><a href="#cacert" id="user-content-cacert"><code>--cacert &lt;FILE&gt;</code></a></td>
<td>Specifies the certificate file for peer verification. The file may contain multiple CA certificates and must be in PEM format.<br>Normally Hurl is built to use a default file for this, so this option is typically used to alter that default file.<br></td>
</tr>
<tr>
<td><a href="#cert" id="user-content-cert"><code>-E, --cert &lt;CERTIFICATE[:PASSWORD]&gt;</code></a></td>
<td>Client certificate file and password.<p>See also <a href="#key"><code>--key</code></a>.</p></td>
</tr>
<tr>
<td><a href="#color" id="user-content-color"><code>--color</code></a></td>
<td>Colorize debug output (the HTTP response output is not colorized).<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#compressed" id="user-content-compressed"><code>--compressed</code></a></td>
<td>Request a compressed response using one of the algorithms br, gzip, deflate and automatically decompress the content.<br></td>
</tr>
<tr>
<td><a href="#connect-timeout" id="user-content-connect-timeout"><code>--connect-timeout &lt;SECONDS&gt;</code></a></td>
<td>Maximum time in seconds that you allow Hurl's connection to take.<p>You can specify time units in the connect timeout expression. Set Hurl to use a connect timeout of 20 seconds with <code>--connect-timeout 20s</code> or set it to 35,000 milliseconds with <code>--connect-timeout 35000ms</code>. No spaces allowed.</p><p>See also <a href="#max-time"><code>-m, --max-time</code></a>.</p></td>
</tr>
<tr>
<td><a href="#connect-to" id="user-content-connect-to"><code>--connect-to &lt;HOST1:PORT1:HOST2:PORT2&gt;</code></a></td>
<td>For a request to the given HOST1:PORT1 pair, connect to HOST2:PORT2 instead. This option can be used several times in a command line.<p>See also <a href="#resolve"><code>--resolve</code></a>.</p></td>
</tr>
<tr>
<td><a href="#continue-on-error" id="user-content-continue-on-error"><code>--continue-on-error</code></a></td>
<td>Continue executing requests to the end of the Hurl file even when an assert error occurs.<br>By default, Hurl exits after an assert error in the HTTP response.<p>Note that this option does not affect the behavior with multiple input Hurl files.</p><p>All the input files are executed independently. The result of one file does not affect the execution of the other Hurl files.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#cookie" id="user-content-cookie"><code>-b, --cookie &lt;FILE&gt;</code></a></td>
<td>Read cookies from FILE (using the Netscape cookie file format).<p>Combined with <a href="#cookie-jar"><code>-c, --cookie-jar</code></a>, you can simulate a cookie storage between successive Hurl runs.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#cookie-jar" id="user-content-cookie-jar"><code>-c, --cookie-jar &lt;FILE&gt;</code></a></td>
<td>Write cookies to FILE after running the session.<br>The file will be written using the Netscape cookie file format.<p>Combined with <a href="#cookie"><code>-b, --cookie</code></a>, you can simulate a cookie storage between successive Hurl runs.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#curl" id="user-content-curl"><code>--curl &lt;FILE&gt;</code></a></td>
<td>Export each request to a list of curl commands.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#delay" id="user-content-delay"><code>--delay &lt;MILLISECONDS&gt;</code></a></td>
<td>Sets delay before each request (aka sleep). The delay is not applied to requests that have been retried because of <a href="#retry"><code>--retry</code></a>. See <a href="#retry-interval"><code>--retry-interval</code></a> to space retried requests.<p>You can specify time units in the delay expression. Set Hurl to use a delay of 2 seconds with <code>--delay 2s</code> or set it to 500 milliseconds with <code>--delay 500ms</code>. No spaces allowed.</p></td>
</tr>
<tr>
<td><a href="#error-format" id="user-content-error-format"><code>--error-format &lt;FORMAT&gt;</code></a></td>
<td>Control the format of error message (short by default or long)<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#file-root" id="user-content-file-root"><code>--file-root &lt;DIR&gt;</code></a></td>
<td>Set root directory to import files in Hurl. This is used for files in multipart form data, request body and response output.<br>When it is not explicitly defined, files are relative to the Hurl file's directory.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#from-entry" id="user-content-from-entry"><code>--from-entry &lt;ENTRY_NUMBER&gt;</code></a></td>
<td>Execute Hurl file from ENTRY_NUMBER (starting at 1).<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#glob" id="user-content-glob"><code>--glob &lt;GLOB&gt;</code></a></td>
<td>Specify input files that match the given glob pattern.<p>Multiple glob flags may be used. This flag supports common Unix glob patterns like *, ? and [].<br>However, to avoid your shell accidentally expanding glob patterns before Hurl handles them, you must use single quotes or double quotes around each pattern.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#header" id="user-content-header"><code>-H, --header &lt;HEADER&gt;</code></a></td>
<td>Add an extra header to include in information sent. Can be used several times in a command<p>Do not add newlines or carriage returns</p></td>
</tr>
<tr>
<td><a href="#http10" id="user-content-http10"><code>-0, --http1.0</code></a></td>
<td>Tells Hurl to use HTTP version 1.0 instead of using its internally preferred HTTP version.<br></td>
</tr>
<tr>
<td><a href="#http11" id="user-content-http11"><code>--http1.1</code></a></td>
<td>Tells Hurl to use HTTP version 1.1.<br></td>
</tr>
<tr>
<td><a href="#http2" id="user-content-http2"><code>--http2</code></a></td>
<td>Tells Hurl to use HTTP version 2.<br>For HTTPS, this means Hurl negotiates HTTP/2 in the TLS handshake. Hurl does this by default.<br>For HTTP, this means Hurl attempts to upgrade the request to HTTP/2 using the Upgrade: request header.<br></td>
</tr>
<tr>
<td><a href="#http3" id="user-content-http3"><code>--http3</code></a></td>
<td>Tells Hurl to try HTTP/3 to the host in the URL, but fallback to earlier HTTP versions if the HTTP/3 connection establishment fails. HTTP/3 is only available for HTTPS and not for HTTP URLs.<br></td>
</tr>
<tr>
<td><a href="#ignore-asserts" id="user-content-ignore-asserts"><code>--ignore-asserts</code></a></td>
<td>Ignore all asserts defined in the Hurl file.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#include" id="user-content-include"><code>-i, --include</code></a></td>
<td>Include the HTTP headers in the output<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#insecure" id="user-content-insecure"><code>-k, --insecure</code></a></td>
<td>This option explicitly allows Hurl to perform "insecure" SSL connections and transfers.<br></td>
</tr>
<tr>
<td><a href="#interactive" id="user-content-interactive"><code>--interactive</code></a></td>
<td>Stop between requests.<p>This is similar to a break point, You can then continue (Press C) or quit (Press Q).</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#ipv4" id="user-content-ipv4"><code>-4, --ipv4</code></a></td>
<td>This option tells Hurl to use IPv4 addresses only when resolving host names, and not for example try IPv6.<br></td>
</tr>
<tr>
<td><a href="#ipv6" id="user-content-ipv6"><code>-6, --ipv6</code></a></td>
<td>This option tells Hurl to use IPv6 addresses only when resolving host names, and not for example try IPv4.<br></td>
</tr>
<tr>
<td><a href="#jobs" id="user-content-jobs"><code>--jobs &lt;NUM&gt;</code></a></td>
<td>Maximum number of parallel jobs in parallel mode. Default value corresponds (in most cases) to the<br>current amount of CPUs.<p>See also <a href="#parallel"><code>--parallel</code></a>.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#json" id="user-content-json"><code>--json</code></a></td>
<td>Output each Hurl file result to JSON. The format is very closed to HAR format.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#key" id="user-content-key"><code>--key &lt;KEY&gt;</code></a></td>
<td>Private key file name.<br></td>
</tr>
<tr>
<td><a href="#limit-rate" id="user-content-limit-rate"><code>--limit-rate &lt;SPEED&gt;</code></a></td>
<td>Specify the maximum transfer rate you want Hurl to use, for both downloads and uploads. This feature is useful if you have a limited pipe and you would like your transfer not to use your entire bandwidth. To make it slower than it otherwise would be.<br>The given speed is measured in bytes/second.<br></td>
</tr>
<tr>
<td><a href="#location" id="user-content-location"><code>-L, --location</code></a></td>
<td>Follow redirect. To limit the amount of redirects to follow use the <a href="#max-redirs"><code>--max-redirs</code></a> option<br></td>
</tr>
<tr>
<td><a href="#location-trusted" id="user-content-location-trusted"><code>--location-trusted</code></a></td>
<td>Like <a href="#location"><code>-L, --location</code></a>, but allows sending the name + password to all hosts that the site may redirect to.<br>This may or may not introduce a security breach if the site redirects you to a site to which you send your authentication info (which is plaintext in the case of HTTP Basic authentication).<br></td>
</tr>
<tr>
<td><a href="#max-filesize" id="user-content-max-filesize"><code>--max-filesize &lt;BYTES&gt;</code></a></td>
<td>Specify the maximum size in bytes of a file to download. If the file requested is larger than this value, the transfer does not start.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#max-redirs" id="user-content-max-redirs"><code>--max-redirs &lt;NUM&gt;</code></a></td>
<td>Set maximum number of redirection-followings allowed<p>By default, the limit is set to 50 redirections. Set this option to -1 to make it unlimited.</p></td>
</tr>
<tr>
<td><a href="#max-time" id="user-content-max-time"><code>-m, --max-time &lt;SECONDS&gt;</code></a></td>
<td>Maximum time in seconds that you allow a request/response to take. This is the standard timeout.<p>You can specify time units in the maximum time expression. Set Hurl to use a maximum time of 20 seconds with <code>--max-time 20s</code> or set it to 35,000 milliseconds with <code>--max-time 35000ms</code>. No spaces allowed.</p><p>See also <a href="#connect-timeout"><code>--connect-timeout</code></a>.</p></td>
</tr>
<tr>
<td><a href="#netrc" id="user-content-netrc"><code>-n, --netrc</code></a></td>
<td>Scan the .netrc file in the user's home directory for the username and password.<p>See also <a href="#netrc-file"><code>--netrc-file</code></a> and <a href="#netrc-optional"><code>--netrc-optional</code></a>.</p></td>
</tr>
<tr>
<td><a href="#netrc-file" id="user-content-netrc-file"><code>--netrc-file &lt;FILE&gt;</code></a></td>
<td>Like <a href="#netrc"><code>--netrc</code></a>, but provide the path to the netrc file.<p>See also <a href="#netrc-optional"><code>--netrc-optional</code></a>.</p></td>
</tr>
<tr>
<td><a href="#netrc-optional" id="user-content-netrc-optional"><code>--netrc-optional</code></a></td>
<td>Similar to <a href="#netrc"><code>--netrc</code></a>, but make the .netrc usage optional.<p>See also <a href="#netrc-file"><code>--netrc-file</code></a>.</p></td>
</tr>
<tr>
<td><a href="#no-color" id="user-content-no-color"><code>--no-color</code></a></td>
<td>Do not colorize output.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#no-output" id="user-content-no-output"><code>--no-output</code></a></td>
<td>Suppress output. By default, Hurl outputs the body of the last response.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#noproxy" id="user-content-noproxy"><code>--noproxy &lt;HOST(S)&gt;</code></a></td>
<td>Comma-separated list of hosts which do not use a proxy.<p>Override value from Environment variable no_proxy.</p></td>
</tr>
<tr>
<td><a href="#output" id="user-content-output"><code>-o, --output &lt;FILE&gt;</code></a></td>
<td>Write output to FILE instead of stdout.<br></td>
</tr>
<tr>
<td><a href="#parallel" id="user-content-parallel"><code>--parallel</code></a></td>
<td>Run files in parallel.<p>Each Hurl file is executed in its own worker thread, without sharing anything with the other workers. The default run mode is sequential. Parallel execution is by default in <a href="#test"><code>--test</code></a> mode.</p><p>See also <a href="#jobs"><code>--jobs</code></a>.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#path-as-is" id="user-content-path-as-is"><code>--path-as-is</code></a></td>
<td>Tell Hurl to not handle sequences of /../ or /./ in the given URL path. Normally Hurl will squash or merge them according to standards but with this option set you tell it not to do that.<br></td>
</tr>
<tr>
<td><a href="#pinnedpubkey" id="user-content-pinnedpubkey"><code>--pinnedpubkey &lt;HASHES&gt;</code></a></td>
<td>When negotiating a TLS or SSL connection, the server sends a certificate indicating its identity. A public key is extracted from this certificate and if it does not exactly match the public key provided to this option, Hurl aborts the connection before sending or receiving any data.<br></td>
</tr>
<tr>
<td><a href="#progress-bar" id="user-content-progress-bar"><code>--progress-bar</code></a></td>
<td>Display a progress bar in test mode. The progress bar is displayed only in interactive TTYs. This option forces the progress bar to be displayed even in non-interactive TTYs.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#proxy" id="user-content-proxy"><code>-x, --proxy &lt;[PROTOCOL://]HOST[:PORT]&gt;</code></a></td>
<td>Use the specified proxy.<br></td>
</tr>
<tr>
<td><a href="#repeat" id="user-content-repeat"><code>--repeat &lt;NUM&gt;</code></a></td>
<td>Repeat the input files sequence NUM times, -1 for infinite loop. Given a.hurl, b.hurl, c.hurl as input, repeat two<br>times will run a.hurl, b.hurl, c.hurl, a.hurl, b.hurl, c.hurl.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#report-html" id="user-content-report-html"><code>--report-html &lt;DIR&gt;</code></a></td>
<td>Generate HTML report in DIR.<p>If the HTML report already exists, it will be updated with the new test results.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#report-json" id="user-content-report-json"><code>--report-json &lt;DIR&gt;</code></a></td>
<td>Generate JSON report in DIR.<p>If the JSON report already exists, it will be updated with the new test results.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#report-junit" id="user-content-report-junit"><code>--report-junit &lt;FILE&gt;</code></a></td>
<td>Generate JUnit File.<p>If the FILE report already exists, it will be updated with the new test results.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#report-tap" id="user-content-report-tap"><code>--report-tap &lt;FILE&gt;</code></a></td>
<td>Generate TAP report.<p>If the FILE report already exists, it will be updated with the new test results.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#resolve" id="user-content-resolve"><code>--resolve &lt;HOST:PORT:ADDR&gt;</code></a></td>
<td>Provide a custom address for a specific host and port pair. Using this, you can make the Hurl requests(s) use a specified address and prevent the otherwise normally resolved address to be used. Consider it a sort of /etc/hosts alternative provided on the command line.<br></td>
</tr>
<tr>
<td><a href="#retry" id="user-content-retry"><code>--retry &lt;NUM&gt;</code></a></td>
<td>Maximum number of retries, 0 for no retries, -1 for unlimited retries. Retry happens if any error occurs (asserts, captures, runtimes etc...).<br></td>
</tr>
<tr>
<td><a href="#retry-interval" id="user-content-retry-interval"><code>--retry-interval &lt;MILLISECONDS&gt;</code></a></td>
<td>Duration in milliseconds between each retry. Default is 1000 ms.<p>You can specify time units in the retry interval expression. Set Hurl to use a retry interval of 2 seconds with <code>--retry-interval 2s</code> or set it to 500 milliseconds with <code>--retry-interval 500ms</code>. No spaces allowed.</p></td>
</tr>
<tr>
<td><a href="#secret" id="user-content-secret"><code>--secret &lt;NAME=VALUE&gt;</code></a></td>
<td>Define secret value to be redacted from logs and report. When defined, secrets can be used as variable everywhere variables are used.<br></td>
</tr>
<tr>
<td><a href="#ssl-no-revoke" id="user-content-ssl-no-revoke"><code>--ssl-no-revoke</code></a></td>
<td>(Windows) This option tells Hurl to disable certificate revocation checks. WARNING: this option loosens the SSL security, and by using this flag you ask for exactly that.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#test" id="user-content-test"><code>--test</code></a></td>
<td>Activate test mode: with this, the HTTP response is not outputted anymore, progress is reported for each Hurl file tested, and a text summary is displayed when all files have been run.<p>In test mode, files are executed in parallel. To run test in a sequential way use <code>--job 1</code>.</p><p>See also <a href="#jobs"><code>--jobs</code></a>.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#to-entry" id="user-content-to-entry"><code>--to-entry &lt;ENTRY_NUMBER&gt;</code></a></td>
<td>Execute Hurl file to ENTRY_NUMBER (starting at 1).<br>Ignore the remaining of the file. It is useful for debugging a session.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#unix-socket" id="user-content-unix-socket"><code>--unix-socket &lt;PATH&gt;</code></a></td>
<td>(HTTP) Connect through this Unix domain socket, instead of using the network.<br></td>
</tr>
<tr>
<td><a href="#user" id="user-content-user"><code>-u, --user &lt;USER:PASSWORD&gt;</code></a></td>
<td>Add basic Authentication header to each request.<br></td>
</tr>
<tr>
<td><a href="#user-agent" id="user-content-user-agent"><code>-A, --user-agent &lt;NAME&gt;</code></a></td>
<td>Specify the User-Agent string to send to the HTTP server.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#variable" id="user-content-variable"><code>--variable &lt;NAME=VALUE&gt;</code></a></td>
<td>Define variable (name/value) to be used in Hurl templates.<br></td>
</tr>
<tr>
<td><a href="#variables-file" id="user-content-variables-file"><code>--variables-file &lt;FILE&gt;</code></a></td>
<td>Set properties file in which your define your variables.<p>Each variable is defined as name=value exactly as with <a href="#variable"><code>--variable</code></a> option.</p><p>Note that defining a variable twice produces an error.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#verbose" id="user-content-verbose"><code>-v, --verbose</code></a></td>
<td>Turn on verbose output on standard error stream.<br>Useful for debugging.<p>A line starting with '&gt;' means data sent by Hurl.<br>A line staring with '&lt;' means data received by Hurl.<br>A line starting with '*' means additional info provided by Hurl.</p><p>If you only want HTTP headers in the output, <a href="#include"><code>-i, --include</code></a> might be the option you're looking for.</p></td>
</tr>
<tr>
<td><a href="#very-verbose" id="user-content-very-verbose"><code>--very-verbose</code></a></td>
<td>Turn on more verbose output on standard error stream.<p>In contrast to  <a href="#verbose"><code>--verbose</code></a> option, this option outputs the full HTTP body request and response on standard error. In addition, lines starting with '**' are libcurl debug logs.</p></td>
</tr>
<tr>
<td><a href="#help" id="user-content-help"><code>-h, --help</code></a></td>
<td>Usage help. This lists all current command line options with a short description.<br></td>
</tr>
<tr>
<td><a href="#version" id="user-content-version"><code>-V, --version</code></a></td>
<td>Prints version information<br></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Environment</h2><a id="user-content-environment" aria-label="Permalink: Environment" href="#environment"></a></p>
<p dir="auto">Environment variables can only be specified in lowercase.</p>
<p dir="auto">Using an environment variable to set the proxy has the same effect as using the <a href="#proxy"><code>-x, --proxy</code></a> option.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Variable</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>http_proxy [PROTOCOL://]&lt;HOST&gt;[:PORT]</code></td>
<td>Sets the proxy server to use for HTTP.<br></td>
</tr>
<tr>
<td><code>https_proxy [PROTOCOL://]&lt;HOST&gt;[:PORT]</code></td>
<td>Sets the proxy server to use for HTTPS.<br></td>
</tr>
<tr>
<td><code>all_proxy [PROTOCOL://]&lt;HOST&gt;[:PORT]</code></td>
<td>Sets the proxy server to use if no protocol-specific proxy is set.<br></td>
</tr>
<tr>
<td><code>no_proxy &lt;comma-separated list of hosts&gt;</code></td>
<td>List of host names that shouldn't go through any proxy.<br></td>
</tr>
<tr>
<td><code>HURL_name value</code></td>
<td>Define variable (name/value) to be used in Hurl templates. This is similar than <a href="#variable"><code>--variable</code></a> and <a href="#variables-file"><code>--variables-file</code></a> options.<br></td>
</tr>
<tr>
<td><code>NO_COLOR</code></td>
<td>When set to a non-empty string, do not colorize output (see <a href="#no-color"><code>--no-color</code></a> option).<br></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Exit Codes</h2><a id="user-content-exit-codes" aria-label="Permalink: Exit Codes" href="#exit-codes"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>0</code></td>
<td>Success.<br></td>
</tr>
<tr>
<td><code>1</code></td>
<td>Failed to parse command-line options.<br></td>
</tr>
<tr>
<td><code>2</code></td>
<td>Input File Parsing Error.<br></td>
</tr>
<tr>
<td><code>3</code></td>
<td>Runtime error (such as failure to connect to host).<br></td>
</tr>
<tr>
<td><code>4</code></td>
<td>Assert Error.<br></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">WWW</h2><a id="user-content-www" aria-label="Permalink: WWW" href="#www"></a></p>
<p dir="auto"><a href="https://hurl.dev/" rel="nofollow">https://hurl.dev</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">See Also</h2><a id="user-content-see-also" aria-label="Permalink: See Also" href="#see-also"></a></p>
<p dir="auto">curl(1)  hurlfmt(1)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Binaries Installation</h2><a id="user-content-binaries-installation" aria-label="Permalink: Binaries Installation" href="#binaries-installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Linux</h3><a id="user-content-linux" aria-label="Permalink: Linux" href="#linux"></a></p>
<p dir="auto">Precompiled binary (depending on libc &gt;=2.35) is available at <a href="https://github.com/Orange-OpenSource/hurl/releases/latest">Hurl latest GitHub release</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ INSTALL_DIR=/tmp
$ VERSION=6.1.1
$ curl --silent --location https://github.com/Orange-OpenSource/hurl/releases/download/$VERSION/hurl-$VERSION-x86_64-unknown-linux-gnu.tar.gz | tar xvz -C $INSTALL_DIR
$ export PATH=$INSTALL_DIR/hurl-$VERSION-x86_64-unknown-linux-gnu/bin:$PATH"><pre>$ INSTALL_DIR=/tmp
$ VERSION=6.1.1
$ curl --silent --location https://github.com/Orange-OpenSource/hurl/releases/download/<span>$VERSION</span>/hurl-<span>$VERSION</span>-x86_64-unknown-linux-gnu.tar.gz <span>|</span> tar xvz -C <span>$INSTALL_DIR</span>
$ <span>export</span> PATH=<span>$INSTALL_DIR</span>/hurl-<span>$VERSION</span>-x86_64-unknown-linux-gnu/bin:<span>$PATH</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Debian / Ubuntu</h4><a id="user-content-debian--ubuntu" aria-label="Permalink: Debian / Ubuntu" href="#debian--ubuntu"></a></p>
<p dir="auto">For Debian &gt;=12 / Ubuntu &gt;=22.04, Hurl can be installed using a binary .deb file provided in each Hurl release.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ VERSION=6.1.1
$ curl --location --remote-name https://github.com/Orange-OpenSource/hurl/releases/download/$VERSION/hurl_${VERSION}_amd64.deb
$ sudo apt update &amp;&amp; sudo apt install ./hurl_${VERSION}_amd64.deb"><pre>$ VERSION=6.1.1
$ curl --location --remote-name https://github.com/Orange-OpenSource/hurl/releases/download/<span>$VERSION</span>/hurl_<span>${VERSION}</span>_amd64.deb
$ sudo apt update <span>&amp;&amp;</span> sudo apt install ./hurl_<span>${VERSION}</span>_amd64.deb</pre></div>
<p dir="auto">For Ubuntu &gt;=18.04, Hurl can be installed from <code>ppa:lepapareil/hurl</code></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ VERSION=6.1.1
$ sudo apt-add-repository -y ppa:lepapareil/hurl
$ sudo apt install hurl=&quot;${VERSION}&quot;*"><pre>$ VERSION=6.1.1
$ sudo apt-add-repository -y ppa:lepapareil/hurl
$ sudo apt install hurl=<span><span>"</span><span>${VERSION}</span><span>"</span></span><span>*</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Alpine</h4><a id="user-content-alpine" aria-label="Permalink: Alpine" href="#alpine"></a></p>
<p dir="auto">Hurl is available on <code>testing</code> channel.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ apk add --repository http://dl-cdn.alpinelinux.org/alpine/edge/testing hurl"><pre>$ apk add --repository http://dl-cdn.alpinelinux.org/alpine/edge/testing hurl</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Arch Linux / Manjaro</h4><a id="user-content-arch-linux--manjaro" aria-label="Permalink: Arch Linux / Manjaro" href="#arch-linux--manjaro"></a></p>
<p dir="auto">Hurl is available on <a href="https://archlinux.org/packages/extra/x86_64/hurl/" rel="nofollow">extra</a> channel.</p>

<p dir="auto"><h4 tabindex="-1" dir="auto">NixOS / Nix</h4><a id="user-content-nixos--nix" aria-label="Permalink: NixOS / Nix" href="#nixos--nix"></a></p>
<p dir="auto"><a href="https://search.nixos.org/packages?from=0&amp;size=1&amp;sort=relevance&amp;type=packages&amp;query=hurl" rel="nofollow">NixOS / Nix package</a> is available on stable channel.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">macOS</h3><a id="user-content-macos" aria-label="Permalink: macOS" href="#macos"></a></p>
<p dir="auto">Precompiled binaries for Intel and ARM CPUs are available at <a href="https://github.com/Orange-OpenSource/hurl/releases/latest">Hurl latest GitHub release</a>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Homebrew</h4><a id="user-content-homebrew" aria-label="Permalink: Homebrew" href="#homebrew"></a></p>

<p dir="auto"><h4 tabindex="-1" dir="auto">MacPorts</h4><a id="user-content-macports" aria-label="Permalink: MacPorts" href="#macports"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">FreeBSD</h3><a id="user-content-freebsd" aria-label="Permalink: FreeBSD" href="#freebsd"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Windows</h3><a id="user-content-windows" aria-label="Permalink: Windows" href="#windows"></a></p>
<p dir="auto">Windows requires the <a href="https://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist?view=msvc-170#latest-microsoft-visual-c-redistributable-version" rel="nofollow">Visual C++ Redistributable Package</a> to be installed manually, as this is not included in the installer.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Zip File</h4><a id="user-content-zip-file" aria-label="Permalink: Zip File" href="#zip-file"></a></p>
<p dir="auto">Hurl can be installed from a standalone zip file at <a href="https://github.com/Orange-OpenSource/hurl/releases/latest">Hurl latest GitHub release</a>. You will need to update your <code>PATH</code> variable.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Installer</h4><a id="user-content-installer" aria-label="Permalink: Installer" href="#installer"></a></p>
<p dir="auto">An executable installer is also available at <a href="https://github.com/Orange-OpenSource/hurl/releases/latest">Hurl latest GitHub release</a>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Chocolatey</h4><a id="user-content-chocolatey" aria-label="Permalink: Chocolatey" href="#chocolatey"></a></p>

<p dir="auto"><h4 tabindex="-1" dir="auto">Scoop</h4><a id="user-content-scoop" aria-label="Permalink: Scoop" href="#scoop"></a></p>

<p dir="auto"><h4 tabindex="-1" dir="auto">Windows Package Manager</h4><a id="user-content-windows-package-manager" aria-label="Permalink: Windows Package Manager" href="#windows-package-manager"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Cargo</h3><a id="user-content-cargo" aria-label="Permalink: Cargo" href="#cargo"></a></p>
<p dir="auto">If you're a Rust programmer, Hurl can be installed with cargo.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ cargo install --locked hurl"><pre>$ cargo install --locked hurl</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">conda-forge</h3><a id="user-content-conda-forge" aria-label="Permalink: conda-forge" href="#conda-forge"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ conda install -c conda-forge hurl"><pre>$ conda install -c conda-forge hurl</pre></div>
<p dir="auto">Hurl can also be installed with <a href="https://conda-forge.org/" rel="nofollow"><code>conda-forge</code></a> powered package manager like <a href="https://prefix.dev/" rel="nofollow"><code>pixi</code></a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Docker</h3><a id="user-content-docker" aria-label="Permalink: Docker" href="#docker"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ docker pull ghcr.io/orange-opensource/hurl:latest"><pre>$ docker pull ghcr.io/orange-opensource/hurl:latest</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">npm</h3><a id="user-content-npm" aria-label="Permalink: npm" href="#npm"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ npm install --save-dev @orangeopensource/hurl"><pre>$ npm install --save-dev @orangeopensource/hurl</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building From Sources</h2><a id="user-content-building-from-sources" aria-label="Permalink: Building From Sources" href="#building-from-sources"></a></p>
<p dir="auto">Hurl sources are available in <a href="https://github.com/Orange-OpenSource/hurl">GitHub</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Build on Linux</h3><a id="user-content-build-on-linux" aria-label="Permalink: Build on Linux" href="#build-on-linux"></a></p>
<p dir="auto">Hurl depends on libssl, libcurl and libxml2 native libraries. You will need their development files in your platform.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Debian based distributions</h4><a id="user-content-debian-based-distributions" aria-label="Permalink: Debian based distributions" href="#debian-based-distributions"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ apt install -y build-essential pkg-config libssl-dev libcurl4-openssl-dev libxml2-dev libclang-dev"><pre>$ apt install -y build-essential pkg-config libssl-dev libcurl4-openssl-dev libxml2-dev libclang-dev</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Fedora based distributions</h4><a id="user-content-fedora-based-distributions" aria-label="Permalink: Fedora based distributions" href="#fedora-based-distributions"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ dnf install -y pkgconf-pkg-config gcc openssl-devel libxml2-devel clang-devel"><pre>$ dnf install -y pkgconf-pkg-config gcc openssl-devel libxml2-devel clang-devel</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Red Hat based distributions</h4><a id="user-content-red-hat-based-distributions" aria-label="Permalink: Red Hat based distributions" href="#red-hat-based-distributions"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ yum install -y pkg-config gcc openssl-devel libxml2-devel clang-devel"><pre>$ yum install -y pkg-config gcc openssl-devel libxml2-devel clang-devel</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Arch based distributions</h4><a id="user-content-arch-based-distributions" aria-label="Permalink: Arch based distributions" href="#arch-based-distributions"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ pacman -S --noconfirm pkgconf gcc glibc openssl libxml2 clang"><pre>$ pacman -S --noconfirm pkgconf gcc glibc openssl libxml2 clang</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Alpine based distributions</h4><a id="user-content-alpine-based-distributions" aria-label="Permalink: Alpine based distributions" href="#alpine-based-distributions"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ apk add curl-dev gcc libxml2-dev musl-dev openssl-dev clang-dev"><pre>$ apk add curl-dev gcc libxml2-dev musl-dev openssl-dev clang-dev</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Build on macOS</h3><a id="user-content-build-on-macos" aria-label="Permalink: Build on macOS" href="#build-on-macos"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ xcode-select --install
$ brew install pkg-config"><pre>$ xcode-select --install
$ brew install pkg-config</pre></div>
<p dir="auto">Hurl is written in <a href="https://www.rust-lang.org/" rel="nofollow">Rust</a>. You should <a href="https://www.rust-lang.org/tools/install" rel="nofollow">install</a> the latest stable release.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ curl https://sh.rustup.rs -sSf | sh -s -- -y
$ source $HOME/.cargo/env
$ rustc --version
$ cargo --version"><pre>$ curl https://sh.rustup.rs -sSf <span>|</span> sh -s -- -y
$ <span>source</span> <span>$HOME</span>/.cargo/env
$ rustc --version
$ cargo --version</pre></div>
<p dir="auto">Then build hurl:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ git clone https://github.com/Orange-OpenSource/hurl
$ cd hurl
$ cargo build --release
$ ./target/release/hurl --version"><pre>$ git clone https://github.com/Orange-OpenSource/hurl
$ <span>cd</span> hurl
$ cargo build --release
$ ./target/release/hurl --version</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Build on Windows</h3><a id="user-content-build-on-windows" aria-label="Permalink: Build on Windows" href="#build-on-windows"></a></p>
<p dir="auto">Please follow the <a href="https://github.com/Orange-OpenSource/hurl/blob/master/contrib/windows/README.md">contrib on Windows section</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Asterinas: A new Linux-compatible kernel project (190 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/1022920/ad60263cd13c8a13/</link>
            <guid>44324084</guid>
            <pubDate>Fri, 20 Jun 2025 01:56:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/1022920/ad60263cd13c8a13/">https://lwn.net/SubscriberLink/1022920/ad60263cd13c8a13/</a>, See on <a href="https://news.ycombinator.com/item?id=44324084">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<blockquote>
<div>
<h3>Welcome to LWN.net</h3>
<p>
The following subscription-only content has been made available to you 
by an LWN subscriber.  Thousands of subscribers depend on LWN for the 
best news from the Linux and free software communities.  If you enjoy this 
article, please consider <a href="https://lwn.net/subscribe/">subscribing to LWN</a>.  Thank you
for visiting LWN.net!
</p></div>
</blockquote>
<p>
Born from research at the <a href="https://www.sustech.edu.cn/en/">Southern University of Science and
Technology</a> (SUSTech) in Shenzen, China, <a href="https://asterinas.github.io/">Asterinas</a> is a new
Linux-ABI-compatible kernel project written in Rust, based on what the
authors call a "framekernel architecture".  The project overlaps somewhat
with the goals of the <a href="https://rust-for-linux.com/">Rust for Linux
project</a>, but approaches the problem space from a different direction by
trying to get the best from both monolithic and microkernel designs.

</p><h4>What's a framekernel?</h4>

<p>
The framekernel concept is explained in the September 2024 paper "<a href="https://dl.acm.org/doi/10.1145/3678015.3680492">Framekernel: A Safe
and Efficient Kernel Architecture via Rust-based Intra-kernel Privilege
Separation</a>" by Yuke Peng et al.  <a href="https://arxiv.org/abs/2506.03876">A fuller version of the paper</a>
was published in early June.


</p><p>
Traditionally, monolithic kernels lump everything into one kernel-mode
address space, whereas microkernels only implement a minimal <a href="https://en.wikipedia.org/wiki/Trusted_computing_base">trusted
computing base (TCB)</a> in kernel space and rely on user-mode services for
much of the operating system's functionality.  This separation implies the
use of interprocess communication (IPC) between the microkernel and those
services. This IPC often has a performance impact, which is a big part of
why microkernels have remained relatively unpopular.

<!-- middle-ad -->
</p><p>
The core of Asterinas's "framekernel" design is the encapsulation of all
code that needs Rust's <tt>unsafe</tt> features inside a library, enabling
the rest of the kernel (the services) to be developed using safe
abstractions.  Those services remain within the kernel's address space, but
only have access to the resources that the core library gives to them.
This design is meant to improve the safety of the system while retaining
the simple and performant shared-memory architecture of monolithic
kernels. The <a href="https://asterinas.github.io/book/">Asterinas book</a>
on the project's website provides a nice <a href="https://asterinas.github.io/book/kernel/the-framekernel-architecture.html">
architectural mission statement and overview</a>.


</p><p>
The aptness of the "framekernel" nomenclature can perhaps be debated.  The
frame part refers to the development framework wrapping the unsafe
parts behind a memory-safe API.  The concept of the TCB is, of
course, not exclusive to microkernel architectures but, because there are
strong incentives to strictly scrutinize and, in some contexts, even <a href="https://en.wikipedia.org/wiki/Formal_verification">formally
verify</a> the TCB of a system, keeping the TCB as small as possible is a
central aspect of microkernel designs.


</p><p>
An update on the project is available on the Asterinas blog in the
June&nbsp;4 post titled "<a href="https://asterinas.github.io/2025/06/04/kernel-memory-safety-mission-accomplished.html">Kernel
Memory Safety: Mission Accomplished</a>".  The post explains the team's
motivations and the need for the industry to address memory-safety
problems; it provides some illustrations that explain how the framekernel
is different from monolithic kernels and microkernels. It also takes a
moment to emphasize that the benefits of Rust don't stop with memory
safety; there are improvements to <a href="https://jacko.io/safety_and_soundness.html">soundness</a> as well.
Perhaps most importantly, the post highlights the upcoming Asterinas
presentation at the <a href="https://www.usenix.org/conference/atc25/technical-sessions">2025
USENIX Annual Technical Conference</a>.
</p><h4>Related work</h4>

<p>
In their paper, the authors compare Asterinas to some prior Rust-based
operating-system work, exploring the benefits of the language's
memory-safety features and explain how Asterinas differs from that previous
work.  Specifically, the paper contrasts Asterinas with <a href="https://www.usenix.org/conference/osdi20/presentation/narayanan-vikram">
RedLeaf</a>, an operating system written in Rust and presented at the 14th
USENIX Symposium on Operating Systems Design and Implementation (OSDI 20)
in 2020.  Asterinas uses hardware isolation to permit running user-space
programs written in any programming language, aims to be general-purpose,
and provides a Linux-compatible ABI, while RedLeaf is a microkernel that is
designed <i>not</i> to use the hardware's isolation features, and the
project focuses on different things.
</p><p>
Another project of interest is <a href="https://tockos.org/">Tock</a>, an
embedded system that targets SoCs with limited hardware protection
functionality. Like Asterinas, Tock also divides the kernel into a
trusted core allowed to use <tt>unsafe</tt> and untrusted "capsules" that
are not.  As mentioned, Asterinas does rely on hardware protection and
isn't intended for strictly embedded use, which differentiates it from
Tock.


</p><p>
It bears mentioning that the Rust for Linux project, which is introducing
Rust code into the upstream Linux kernel, has similar goals as
Asterinas. It also aims to encapsulate kernel interfaces with safe
abstractions in such a way that drivers can be written in Rust without any
need for <tt>unsafe</tt>.


</p><h4>Work toward formal verification</h4>

<p>
One goal of shrinking the TCB of an operating system is to make it feasible
to have it formally verified.  In February 2025, the Asterinas blog
featured <a href="https://asterinas.github.io/2025/02/13/towards-practical-formal-verification-for-a-general-purpose-os-in-rust.html">a
post detailing plans to do just that</a>.  The best known formally verified
kernel is <a href="https://sel4.systems/About/">seL4</a>, an L4-family
microkernel.

</p><p>
Asterinas aims to use the framekernel approach to achieve a system that has
a small, formally verified TCB akin to a lean microkernel, but also a
simple shared-memory architecture with Linux ABI compatibility, all at the
same time.  This is a radical departure from any previously formally
verified kernel; the blog post describes those kernels as deliberately
small and limited compared to "<q>full-fledged, UNIX-style OSes</q>".


</p><p>
The Asterinas project is collaborating with a security-auditing company
called <a href="https://www.certik.com/">CertiK</a> to use <a href="https://github.com/verus-lang/verus">Verus</a> to formally verify the
kernel.  There is an extensive <a href="https://github.com/asterinas/slides/blob/f62c764ea9c4831a747dbe8fa415b56e48493482/slides/2025-01-28%20Asterinas%20Security%20Assessment%20by%20CertiK.pdf">
report</a> available from CertiK on how Asterinas was audited and the
issues that were found.


</p><h4>Libraries and tools</h4>

<p>
The Asterinas kernel is only one result of the project. The other two are
<a href="https://crates.io/crates/ostd">OSTD</a>, described as "<q>a Rust
OS framework that facilitates the development of and innovation in OS
kernels written in Rust</q>", and <a href="https://asterinas.github.io/book/osdk/guide/index.html">OSDK</a>, a
Cargo addon to assist with the development, building, and testing of
kernels based on OSTD.


</p><p>
There are four stated goals for OSTD as a separate crate. One is to lower
the entry bar for operating-system innovation and to lay the groundwork for
newcomers to operating-system development. The second is to enhance memory
safety for operating systems written in Rust; other projects can benefit
from its encapsulation and abstraction of low-level operations. The third is
to promote code reuse across Rust-based operating-system projects. The
fourth is to boost productivity by enabling testing of new code in user
mode, allowing developers to iterate without having to reboot.


</p><p>
It is worth emphasizing that the kernels that can be written with OSTD do
not have to be Linux-compatible or, in any way, Unix-like. The APIs
provided are more generic than that; they are memory-safe abstractions for
functionality like x86 hardware management, booting, virtual memory, SMP,
tasks, users, and timers.  Like most Rust crates, OSTD is <a href="https://docs.rs/ostd/0.14.1/ostd/index.html">documented on
docs.rs</a>.


</p><p>
Asterinas reports Intel, among others, as a sponsor of the project.
Intel's interest is likely related to its <a href="https://www.intel.com/content/www/us/en/developer/tools/trust-domain-extensions/overview.html">Trust
Domain Extensions (TDX)</a> feature, which provides hardware modes and
features to facilitate isolation of virtual machines, and memory
encryption.  The Asterinas book has a brief <a href="https://asterinas.github.io/book/osdk/guide/intel-tdx.html">section
on TDX</a>, and the OSDK supports it.


</p><p>
The OSTD, or at least the parts that Asterinas ends up using, seems to
essentially be the restricted TCB that allows <tt>unsafe</tt>. For an
illustrative example, we could take a look at the <tt>network</tt> kernel
component's <a href="https://github.com/asterinas/asterinas/blob/ecb33ca98d2b2ac680daf1d2a48e4d011db2fbcf/kernel/comps/network/src/buffer.rs">source
code</a> and see that the buffer code uses DMA, locking, allocation, and
virtual-memory code from the OSTD through memory-safe APIs.


</p><h4>Current state</h4>
<p>
Asterinas was first released under the Mozilla Public License in early
2024; it has undergone rapid development over the past year.  GitHub <a href="https://github.com/asterinas/asterinas/graphs/contributors">lists 45
individual committers</a>, but the majority of the commits are from a
handful of PhD students from SUSTech, Peking University, and Fudan
University, as well as a Chinese company called <a href="https://www.antgroup.com/en">Ant Group</a>, which is a sponsor of
Asterinas.

</p><p>
At the time of writing, Asterinas supports two architectures, x86 and RISC-V.
In the January blog post linked above, it was reported that Asterinas
supported 180 Linux system calls, but the number has since grown to <a href="https://github.com/asterinas/asterinas/blob/1fe0fef41003c824b780b7b228f7b01a46497be0/kernel/src/syscall/arch/x86.rs">206
on x86</a>.  As of version 6.7, Linux has 368 system calls in total, so there is
some way to go yet.


</p><p>
Overall, Asterinas is in early development. There have been no releases,
release announcements, changelogs, or much of anything other than Git tags
and a short installation guide in the documentation.  The <a href="https://crates.io/crates/ostd/reverse_dependencies">Dependents
tab</a> of the OSTD crate on crates.io shows that no unrelated, published
crate yet uses OSTD.


</p><p>
It does not seem like Asterinas is able to run any applications yet.  <a href="https://github.com/asterinas/asterinas/issues/1868">Issue #1868</a>
in Asterinas's repository outlines preliminary plans toward a first
distribution.  The initial focus on a custom initramfs and some rudimentary
user-space applications, followed by being able to <a href="https://github.com/asterinas/asterinas/issues/1851">run
Docker</a>. There are initial plans to bootstrap a distribution based on
Nix. Notably (but unsurprisingly), this issue mentions that Asterinas
doesn't support loading Linux kernel modules, nor does it ever
plan to.


</p><h4>Near-future goals</h4>

<p>
The <a href="https://asterinas.github.io/book/kernel/roadmap.html">Roadmap</a>
section of the Asterinas book says that the near-term goals are to expand
the support for CPU architectures and hardware, as well as to focus on
real-world usability in the cloud by providing a host OS for virtual
machines.  Apparently, the support for Linux virtio devices is already
there, so a major hurdle has already been cleared.  In particular, the
Chinese cloud market, in the form of Aliyun (also known as Alibaba Cloud)
<a href="https://github.com/asterinas/asterinas/issues/1501">is a
focus</a>.  The primary plans involve creating a container host OS with a
tight, formally verified TCB and support for some trusted-computing
features in Intel hardware, for the Chinese cloud service.


</p><p>
While both Rust for Linux and Asterinas have similar goals (providing a
safer kernel by relying on Rust's memory safety), their scopes and
approaches are different.  Rust for Linux focuses on safe abstractions
strictly for new device drivers to be written in safe Rust, but this leaves
the rest of the kernel untouched.
Asterinas, on the other hand, aims to build a whole new kernel from the ground
up, restricting the <tt>unsafe</tt>-permitting core to the absolute minimum,
which can then be formally verified.  Asterinas also focuses on
containers and cloud computing, at least for now, while Rust for Linux looks to
benefit the whole of the Linux ecosystem.


</p><p>
Despite the stated cloud focus, there is more going on, for example building
support for <a href="https://github.com/asterinas/asterinas/issues/2008">X11</a>
and <a href="https://github.com/asterinas/asterinas/issues/2112">Xfce</a>.
Also, the OSTD could, of course, prove interesting for OS development
enthusiasts irrespective of the Asterinas project, but so far it remains unknown
and untested by a wider audience.

</p><p>
Asterinas is certainly a refreshingly innovative take on principles for
operating-system development, leaning on the safety and soundness
foundations provided by the Rust language and compiler. So far it is at an
early exploratory stage driven by enthusiastic Chinese researchers and
doesn't see any serious practical use, but it is worth keeping an eye
on. It will be interesting to see the reception it will get from the
Rust for Linux team and the Linux community at large.<br clear="all"></p><table>
           <tbody><tr><th colspan="2">Index entries for this article</th></tr>
           <tr><td><a href="https://lwn.net/Archives/GuestIndex/">GuestArticles</a></td><td><a href="https://lwn.net/Archives/GuestIndex/#Koistinen_Ronja">Koistinen, Ronja</a></td></tr>
            </tbody></table><br clear="all">

               <br clear="all">
               <hr>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FedFlix ‚Äî Public Domain Stock Footage Library (130 pts)]]></title>
            <link>https://public.resource.org/ntis.gov/index.html</link>
            <guid>44323914</guid>
            <pubDate>Fri, 20 Jun 2025 01:07:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://public.resource.org/ntis.gov/index.html">https://public.resource.org/ntis.gov/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=44323914">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
		<h4>FedFlix‚ÄîPublic Domain Stock Footage Library &amp; Government Theater</h4>
			 
			<div id="theagree">
			<!-- this is invisible at first -->
				
				<h3>JOINT VENTURE</h3> <h5>BETWEEN</h5> <h3><a href="https://www.ntis.gov/">THE NATIONAL TECHNICAL INFORMATION SERVICE</a></h3> <h5>AND</h5> <h3><a href="https://public.resource.org/">PUBLIC.RESOURCE.ORG, INC.</a></h3> <h5>Agreement No. NTIS-1832.</h5> 
<h5>Renewed and Amended <a href="https://law.resource.org/pub/us/case/govdocs/gov.ntis_20090428_from.pdf">April 28, 2009.</a></h5>
				<p>
					Pursuant to Section <a href="https://www.law.cornell.edu/uscode/text/15/3704b">3704b(a)(1)A</a> of Title 15 of the United States Code, the National Technical Information Service (NTIS), a bureau within the Department of Commerce that operates on a self-sustaining basis without annual appropriations, and Public.Resource.Org, Inc. (PRO), a company incorporated under the laws of the State of California, hereby agree to enter into a joint venture to promote public access to multimedia products in the NTIS collection. The joint venture is based on an unsolicited proposal by PRO. 
				</p><ol>
					<li>
						Each month NTIS will select between ten and twenty non-copyrighted videotapes from available stock in its collection and ship them to PRO at its own expense. 
					</li>
					<li>
						Immediately upon receipt, PRO will, at its own expense, digitize the videotape and return the videotape and a copy in digital video disk (DVD) format to NTIS. The videotape and the DVD copy are both considered to be property of the United States Government. PRO will normally return the videotape and DVD within 15 days of receipt. A monthly submission to PRO will normally not occur until the DVDs sent the previous month have been returned to NTIS. 
					</li>
					<li>
						PRO will reimburse NTIS for the retail value of any videotape not returned to NTIS as provided in section 2. 
					</li>
					<li>
						Each party is free to make the content of the videotape available to the public through a web site or other means in any format and at any price, or for free, and to retain 100% of the revenue from any sales of the content. 
					</li>
					<li>
						PRO will assert no intellectual property claim to the content provided by NTIS or the resulting DVD in any manner whatsoever. 
					</li>
					<li>
						Nothing in this joint venture purports to be an exclusive arrangement. NTIS may provide content in its videotape collection, including content digitized by PRO under this agreement, to any other business partner. 
					</li>
					<li>
						Unless renewed earlier, this joint venture will terminate one year from the date of execution, except that either party may terminate it with 60 days written notice to the other. If NTIS terminates, PRO may either return any videotapes it has not yet digitized at NTIS' expense or it may treat those videotapes as subject to section 4. If PRO terminates, it may either return any videotapes not yet digitized at its own expense or it may treat those videotapes as subject to section 4. 
					</li>
					<li>
						Neither party may assign its rights under this Agreement to a third party without the written consent of the other party. 
					</li>
					<li>
						This agreement will be construed in accordance with applicable Federal law as construed by the United States Court of Federal Claims. 
					</li>
					<li>
						Nothing in this agreement shall be construed as creating a partnership and neither party shall have the power to bind the other in any respect. 
					</li>
				</ol>
				<table>
					<tbody><tr>
						<td><br>
							<strong>Carl Malamud, President</strong>
							<br>
							Public.Resource.Org, Inc. 
							<br>
							1005 Gravenstein Hwy North 
							<br>
							Sebastopol CA 95472 
						</td>
						<td><br>
							<strong>Donald Hagen</strong>
							<br>
							Associate Director 
							<br>
							Product and Program Management 
							<br>
							NTIS 
						</td>
					</tr>
					<tr>
						<td>
							Date: 11/2/2007 
						</td>
						<td>
							Date: 11/2/2007 
						</td>
					</tr>
				</tbody></table>
			</div>

<!-- FOOTER AREA -->
		
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Open source can't coordinate (162 pts)]]></title>
            <link>https://matklad.github.io/2025/05/20/open-source-cant-coordinate.html</link>
            <guid>44323904</guid>
            <pubDate>Fri, 20 Jun 2025 01:06:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matklad.github.io/2025/05/20/open-source-cant-coordinate.html">https://matklad.github.io/2025/05/20/open-source-cant-coordinate.html</a>, See on <a href="https://news.ycombinator.com/item?id=44323904">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <article>
        <h2>
          Open Source Can‚Äôt Coordinate <time datetime="2025-05-20">May 20, 2025</time>
        </h2>
        <p>
          I was taking a shower this morning, and was pondering <a href="https://matklad.github.io/2025/05/19/profiling-challenge-results.html">yesterday‚Äôs problem</a>, where I <em>suspect</em>
          that I have an outdated version of <a href="https://github.com/KDAB/hotspot">hotspot</a> Linux profiler, but I can‚Äôt just go and download a fresh
          release from GitHub, because hotspot is a KDE app, and I use NixOS.
          And NixOS isn‚Äôt a problem ‚Äî it‚Äôs a solution.
        </p>
        <p>
          Linux on desktop is a rickety tower of competing libraries, protocols
          and standards, which is always in an Escheresque sort of perpetual
          motion, taking off but simultaneously falling, and the best way to
          enjoy it is to take a photo, a frozen snapshot in time.
        </p>
        <p>
          The underlying force there is the absence of one unified baseline set
          of APIs for writing desktop programs. There‚Äôs no single entity that
          can coordinate the API, in contrast to Windows and MacOS.
        </p>
        <p>
          But then, how can Linux exist? How does that square with ‚Äúnever break
          the user space?‚Äù I‚Äôll let you ponder the question, but let me first
          tell you a story from a domain where I consider myself an expert.
        </p>
        <section id="Better-LSP-Than-Never">
          <h2>
            <a href="#Better-LSP-Than-Never">Better LSP Than Never </a>
          </h2>
          <p>
            The past ten years saw a big shift in how we are writing software:
            baseline level of ‚Äúinteractive static analysis‚Äù became the norm, go
            to definition is universally available. The surprising fact here is
            that the shift occurred a decade too late!
          </p>
          <p>
            The shift was caused by Microsoft releasing its Language Server
            Protocol specification. But there‚Äôs little value in the protocol
            itself. Its implementation is
            <a href="https://matklad.github.io/2023/10/12/lsp-could-have-been-better.html">mediocre</a>, it was strictly worse than <a href="https://htmlpreview.github.io/?https://github.com/dart-lang/sdk/blob/8e6a02d899ef62ef5b8405518b36340e609198e2/pkg/analysis_server/doc/api.html">the state of the art at that time</a>, and its
            <a href="https://github.com/microsoft/language-server-protocol/pull/2027#issuecomment-2822857896">governance is abysmal</a>. The only great thing about LSP is that
            it exists!
          </p>
          <p>
            If you were anywhere near JetBrains a decade ago, it was blindingly
            obvious that the absence of broad availability of basic IDE features
            leaves a lot of the value on the table, and that the multi-process
            IPC architecture is the way to go (JetBrains did IPC for Rider). But
            it is also clear why JetBrains didn‚Äôt do LSP ‚Äî why would they? While
            the right solution on the technical grounds, you aren‚Äôt going to get
            paid for being technically right. As sad as it is, some amount of
            <a href="https://en.wikipedia.org/wiki/Deadweight_loss">deadweight loss</a> is needed to capture some of the value you are
            producing, and you need to be able to capture value to invest in
            things! So the world had to wait for Microsoft to pick up the slack
            here, when they decided to gobble up the entire developer ecosystem
            as an investment.
          </p>
          <p>
            There was a decade of opportunity for OSS to coordinate around an
            IDE protocol, but that didn‚Äôt happen, because OSS is bad at
            coordination.
          </p>
        </section>
        <section id="Why-Linux">
          <h2>
            <a href="#Why-Linux">Why Linux? </a>
          </h2>
          <p>
            But then, why and how does Linux exist? I think part of that is a
            rather unique governance structure, where there‚Äôs a centralized
            control over the API area and strong commitment to the public
            interfaces. But the bigger part is POSIX. The reason why we have
            Linux, and BSDs, and XNU is that they all provide the same baseline
            API, which was defined from the outside. The coordination problem
            was pre-solved, and what remained is just filling-in the
            implementation. But there was no one to coordinate Linux on desktop.
          </p>
        </section>
      </article>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Infinite Mac OS X (256 pts)]]></title>
            <link>https://blog.persistent.info/2025/03/infinite-mac-os-x.html</link>
            <guid>44323719</guid>
            <pubDate>Fri, 20 Jun 2025 00:16:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.persistent.info/2025/03/infinite-mac-os-x.html">https://blog.persistent.info/2025/03/infinite-mac-os-x.html</a>, See on <a href="https://news.ycombinator.com/item?id=44323719">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
<p><strong>tl;dr:</strong> Infinite Mac can now <a href="https://infinitemac.org/?filter=macosx">run early Mac OS X</a>, with <a href="https://infinitemac.org/2001/Mac%20OS%20X%2010.1">10.1</a> and <a href="https://infinitemac.org/2003/Mac%20OS%20X%2010.3">10.3</a> being the best supported versions. It‚Äôs not particularly snappy, but as someone who lived through that period, I can tell you that it wasn‚Äôt much better on real hardware. Infinite HD has also been rebuilt to have some notable indie software from that era.</p>

<p>
  <img alt="Mac OS X 10.1 running NetNewsWire Lite and Terminal" height="928" src="https://persistent.info/images/infinite-mac-mac-os-x-10.1.webp" width="1184">
</p>

<h3>Porting PearPC</h3>

<p>I‚Äôve been <a href="https://github.com/search?q=repo%3Amihaip%2Finfinite-mac+219&amp;type=commits&amp;s=committer-date&amp;o=desc">tracking</a> DingusPPC progress since my initial <a href="https://blog.persistent.info/2023/12/dingusppc.html">port</a> and making the occasional contribution <a href="https://github.com/dingusdev/dingusppc/commits?author=mihaip">myself</a>, with the hope of using it to run Mac OS X in Infinite Mac. While it has continued to improve, I reached a plateau last summer; my attempts would result in either kernel panics or graphical corruption. I tried to reduce the problem a bit via a <a href="https://github.com/dingusdev/dingusppc/pull/120">deterministic execution mode</a>, but it wasn‚Äôt really clear where to go next. I decided to take a break from this emulator and explore alternate paths of getting Mac OS X to run.</p>

<p><a href="https://github.com/sebastianbiallas/pearpc">PearPC</a> was the obvious choice ‚Äì it was created with the express purpose of emulating Mac OS X on x86 Windows and Linux machines in the early 2000s. By <a href="https://www.osnews.com/story/7085/pearpc-01-is-it-a-miracle/">all accounts</a>, it did this successfully for a few years, until interest waned after the Intel switch. I had earlier <a href="https://blog.persistent.info/2023/12/dingusppc.html#:~:text=I%20also%20briefly%20considered%20PearPC%20(which%20is%20much%20more%20focused%20on%20early%20PowerMacs%20than%20QEMU)%2C%20but%20it%E2%80%99s%20also%20in%20a%20state%20of%20abandonment%20(development%20mostly%20stopped%20in%202005%2C%20with%20a%20brief%20resurrection%20in%202015).">dismissed it</a> as a ‚Äúdead‚Äù codebase, but I decided that the satisfaction of getting something working compensated for dealing with legacy C++ (complete with its own <a href="https://github.com/sebastianbiallas/pearpc/blob/master/src/tools/str.h">string class</a>, <a href="https://github.com/sebastianbiallas/pearpc/blob/master/src/tools/snprintf.cc">sprintf implementation</a>, and <a href="https://github.com/sebastianbiallas/pearpc/blob/master/src/system/gif.cc">GIF decoder</a>). An encouraging discovery was that <a href="https://github.com/kanjitalk755">kanjitalk755</a> (the de-facto Basilisk II and SheepShaver maintainer) had somewhat recently set up <a href="https://github.com/sebastianbiallas/pearpc/compare/master...kanjitalk755:pearpc:macos_sdl2">an experimental branch</a> of PearPC that built and ran on modern macOS. I was able to replicate their work without too much trouble, and with that existence proof I started on my sixth port of an emulator to WebAssembly/Emscripten and the Infinite Mac runtime.</p>

<p>In some ways PearPC not being actively developed made things easier ‚Äì&nbsp;I didn‚Äôt have to worry about merging in changes from upstream, or agonize over how to structure my modifications to make them easier to contribute back. It was also helpful that PearPC was already a multi-platform codebase and thus had the right layers of abstraction to make adding another target pretty easy. As a bonus, it didn‚Äôt make pervasive use of threads or other harder-to-port concepts. Over the course of a few days, I was able to <a href="https://github.com/mihaip/pearpc/commit/a63c1145964843c09e4d21fc55c182ccb53e82ce">get it to build</a>, <a href="https://github.com/mihaip/pearpc/commit/b13f6813321af579895122a71aa09ba2cb793717">output video</a>, <a href="https://github.com/mihaip/pearpc/commit/dde5322f13a2ca64727cd94a98795f5c1f20f6b0">load disk images</a>, and <a href="https://github.com/mihaip/pearpc/commit/526ba08845122e991268c5d995167efbd083ac8e">get mouse and keyboard input</a> hooked up. It was pretty satisfying to have Mac OS X 10.2 running in a browser more reliably than it previously had.</p>

<h3>Performance</h3>

<p>While PearPC ran 10.2 more reliably, it felt slower than DingusPCC. I had spent some time last year making <a href="https://github.com/dingusdev/dingusppc/commit/564c43c907917f498d7090c6f108ead03f6b123d">some</a> <a href="https://github.com/dingusdev/dingusppc/commit/b759f25d87a21b95ea0384fa9a83644591bb6305">optimizations</a> to the latter, partly inspired by the <a href="https://github.com/kwhr0/macemu/blob/master/SheepShaver/src/TinyPPC.cpp">TinyPPC emulator</a> in <a href="http://kwhr0.g2.xrea.com/macemu.html">this SheepShaver fork</a> (aren‚Äôt all these names fun?). I <a href="https://github.com/mihaip/pearpc/commit/0856ed0acb9674420fb6c858e684a02033b3cdc3">ported</a> DingusPPC‚Äôs benchmark harness and then <a href="https://github.com/mihaip/pearpc/commit/75dbcfb9f5e28735792bff085d58cb206631564b">set</a> <a href="https://github.com/mihaip/pearpc/commit/71059084de0169b760f4c908d52961d2e69399a1">about</a> <a href="https://github.com/mihaip/pearpc/commit/c87caace8a5479caf160a6a0a8d9183de5165132">replicating</a> <a href="https://github.com/mihaip/pearpc/commit/4ac34d860b0b58d6ff3cefa630d98f5681443b5b">the</a> <a href="https://github.com/mihaip/pearpc/commit/3e979205950b9d540577204d8e86a494f53157a2">performance</a> <a href="https://github.com/mihaip/pearpc/commit/14d050101f1ada51c49197e494211f7e9e15e847">work</a> <a href="https://github.com/mihaip/pearpc/commit/c3b29968fde9c5d860ba9fdfcf5c5a3b3537760b">in</a> <a href="https://github.com/mihaip/pearpc/commit/6cad14c927b12ec832709d15d9663ba1b2b0dd78">PearPC</a> (both emulators are pure interpreters driven by a lookup table, so the process was relatively straightforward). I was able to shave off about 15 seconds from the 10.2 boot time ‚Äì it helps from a <a href="https://folklore.org/Saving_Lives.html">saving lives perspective</a>, but is still not enough given that it takes almost 2 minutes to be fully operational. In the end, I copped out and <a href="https://github.com/mihaip/infinite-mac/commit/280a527ef0b682dc142bd14ec61cbe37978a39f7">added a UI disclaimer</a> that Mac OS X can be slow to boot. I also got flashbacks to the <a href="https://arstechnica.com/gadgets/2001/04/macos-x/#page-6:~:text=will%20Mac%20OS%20X%20have%20a%20snappy%20UI">‚Äúis it snappy yet?‚Äù</a> discussions from the early days of Mac OS X ‚Äì&nbsp;it was indeed slow, but not this slow.</p>

<p>Performance is still not as good as DingusPPC‚Äôs ‚Äì the biggest bottleneck is the lack of any kind of caching in the MMU, so all loads and stores are expensive since they involve complex address computations. DingusPPC has a much more mature <a href="https://github.com/dingusdev/dingusppc/blob/master/zdocs/developers/cpu/powerpc/mmuemu.md">tiered cache</a> that appears to be quite effective. More generally, while PearPC may be more stable than DingusPPC at running 10.2-10.4, it‚Äôs a much less principled codebase (I came across <a href="https://github.com/sebastianbiallas/pearpc/commit/152604c0af3f0613bae37cf4287f188a42be0c06">many mystery commits</a>) and it ‚Äúcheats‚Äù in many ways (it has a <a href="https://github.com/sebastianbiallas/pearpc/blob/7eb63de8a92b86e1b7438019ddcf935005112501/src/io/prom/promboot.cc#L977">custom</a> firmware and <a href="https://github.com/sebastianbiallas/pearpc/blob/7eb63de8a92b86e1b7438019ddcf935005112501/ppccfg.example#L75-L78">video driver</a>, and only the <a href="https://github.com/sebastianbiallas/pearpc/blob/7eb63de8a92b86e1b7438019ddcf935005112501/src/cpu/cpu_generic/ppc_alu.cc#L116-L117">subset</a> of PowerPC instructions that are needed for Mac OS X are implemented). I‚Äôm still holding out hope for DingusPPC to be the fast, stable, and correct choice for the long term.</p>

<h3>A Side Quest</h3>

<p>I implemented the ‚Äúunified decoding table‚Äù approach in PearPC‚Äôs interpreter one opcode family at a time. When I got to the floating point operations, I assumed it was going to be another mechanical change. I was instead surprised to see that behavior regressed ‚Äì I got some rendering glitches in the Dock, and the Finder windows would not open at all. After some debugging, I noticed that the <a href="https://github.com/mihaip/pearpc/blob/3e979205950b9d540577204d8e86a494f53157a2/src/cpu/cpu_generic/ppc_dec.cc#L106-L172">dispatching for opcode groups 59 and 63</a> didn‚Äôt just do a basic lookup on the relevant instruction bits. It first checked the <code>FP</code> bit of the <a href="https://en.wikipedia.org/wiki/Machine_state_register">Machine State Register (MSR)</a>, and if it was not set it would throw a ‚Äúfloating point unavailable‚Äù exception.</p>

<p>I initially thought this was the emulator being pedantic ‚Äì all PowerPC chips used in Macs had an FPU, so this should never happen. However, setting a breakpoint showed that the exception was being hit pretty frequently during Mac OS X startup. The <a href="https://github.com/apple-oss-distributions/xnu/tree/xnu-124.7">xnu kernel sources</a> of that time period are available, and though I‚Äôm not familiar with the details, there are places where the FP bit <a href="https://github.com/apple-oss-distributions/xnu/blob/xnu-124.7/osfmk/ppc/cswtch.s#L201">is</a> <a href="https://github.com/apple-oss-distributions/xnu/blob/xnu-124.7/osfmk/ppc/cswtch.s#L1012">cleared</a> and a <a href="https://github.com/apple-oss-distributions/xnu/blob/xnu-124.7/osfmk/ppc/cswtch.s#L656-L707">handler for the resulting exception</a> is registered. I assume this is an optimization to avoid having to save/restore FPU registers during context switches (if they‚Äôre not being used). The upshot was that once I implemented the equivalent <code>FP</code> check in my optimized dispatch code, the rendering problems went away.</p>

<p>This reminded me of the rendering glitches that I had encountered when trying to run Mac OS X under DingusPPC. Even when booting from the 10.2 install CD (which does not kernel panic) I would end up with missing text and other issues:</p>

<p>
  <img alt="Mac OS X 10.2 installer showing text rendering glitches" height="624" src="https://persistent.info/images/infinite-mac-mac-os-x-10.2-installer-broken.webp" width="832">
</p>

<p>Checking the DingusPPC sources showed that it never checked the <code>FP</code> bit, and always allowed floating point instructions to go through. I did a quick hack to check it and raise an exception if needed, and the glitches went away!</p>

<p>
  <img alt="Mac OS X 10.2 installer correctly rendering text" height="624" src="https://persistent.info/images/infinite-mac-mac-os-x-10.2-installer-fixed.webp" width="832">
</p>

<p>The <a href="https://github.com/dingusdev/dingusppc/pull/135">proper implementation</a> was a bit more complicated, and I ended up <a href="https://github.com/dingusdev/dingusppc/pull/136">revising it a bit</a> to avoid a performance hit (and another contributor did <a href="https://github.com/dingusdev/dingusppc/commit/82a48899f0c28a9418a07b56b5d39f7e161b1549">another pass</a>). But at the end of it all, DingusPPC became a lot more stable, which was a nice side effect. Better yet, it can run 10.1 reliably, which PearPC cannot. I ended up using a combination of both emulators to run a broader subset of early Mac OS X (unfortunately 10.0 is still unstable, and the Public Beta kernel panics immediately, but I‚Äôm holding out hope for the future).</p>

<h3>Rebuilding Infinite HD</h3>

<p>Part of the appeal of Infinite Mac is that the emulated machines also have an ‚ÄúInfinite HD‚Äù mounted with a lot of era-appropriate software to try. With Mac OS X running, it was time to build an alternate version that went beyond the 80s and 90s classic Mac apps I had collected. I had my favorites, but I also <a href="https://hachyderm.io/@mihaip/113977444999284253">put out a call for suggestions</a> and got plenty of ideas.</p>

<p>For actually building the disk image, I extended the <a href="https://blog.persistent.info/2022/03/blog-post.html#:~:text=Building%20Disk%20Images%2C%20or%20Docker%201995%2Dstyle">automated approach</a> that I first launched the site with. Disk images were even more popular in the early days of Mac OS X than they are today, so I <a href="https://github.com/mihaip/infinite-mac/commit/a7f69373a7b2eb1d85ea33e975180b4a2ca02a44">added a way</a> to import .dmgs as additional folders in the generated image. However, I quickly discovered that despite having the same extension, there are <a href="https://github.com/libyal/libmodi/blob/main/documentation/Mac%20OS%20disk%20image%20types.asciidoc#1-overview">many variants</a>, and the <code>hdiutil</code> that ships with modern macOS cannot always mount images generated more than 20 years ago. In the end I ended up with a <a href="https://github.com/mihaip/infinite-mac/commit/119000a268bb3f21180e06ea899331b2307b695e">Rube Goldberg approach</a> that first extracts the raw partition via <a href="https://github.com/Lekensteyn/dmg2img">dmg2img</a> and then recreates a ‚Äúmodern‚Äù disk image that can be mounted and copied from.</p>

<p>As for getting the actual software, the usual sites like <a href="https://macintoshgarden.org/">Macintosh Garden</a> do have some from that era, but it‚Äôs not a priority for them. Early to mid 2000s Mac OS X software appears to be a bit of a blind spot ‚Äì&nbsp;it‚Äôs too new to be truly ‚Äúretro‚Äù, but too old to still be available from the original vendor (<a href="https://rogueamoeba.com/legacy/">though</a> <a href="https://files.omnigroup.com/software/MacOSX/">there</a> <a href="https://download-cdn.panic.com/">are</a> <a href="https://c-command.com/dropdmg/support#older-versions">exceptions</a>). I ended up using the <a href="https://web.archive.org/">Wayback Machine</a> a lot. As a bonus, I also installed the companion ‚ÄúDeveloper‚Äù CDs for each Mac OS X version, so tools like Project Builder and Interface Builder are also accessible.</p>

<p>
  <img alt="Mac OS X 10.4 running Delicious Library, CandyBar, PCalc and Pixelmator" height="768" src="https://persistent.info/images/infinite-mac-mac-os-x-hd.webp" width="1024">
</p>

<p>The only limitation that I ran into is that my disk build process is centered around HFS, but HFS+ was the default of that time period, and it introduced more advanced capabilities like longer file names containing arbitrary Unicode characters. Files from disk images that rely HFS+ features do not translate losslessly, but luckily this was not an issue for most software. To actually mount multiple drives (up to 3, between the boot disk, Infinite HD, and <a href="https://blog.persistent.info/2023/09/infinite-mac-improved-persistence.html">Saved HD</a>), I <a href="https://github.com/mihaip/dingusppc/commit/51019e4fa0109fa8268cd547b92dee0e7065ac5c">ended</a> <a href="https://github.com/mihaip/pearpc/commit/93f224a8a9676479ff79aad9bf7632d400a5c693">up</a> <a href="https://github.com/mihaip/dingusppc/commit/b220d7b9ed39953780d2a42f9f83caaf8a6cf06e">borrowing</a> a clever solution from a <a href="https://github.com/joevt/dingusppc/">DingusPPC fork</a>: a multi-partition disk image is created on the fly from an arbitrary number of partition images that are specified at startup.</p>

<h3>Aqua</h3>

<p>To make the addition of Mac OS X to Infinite Mac complete, I also wanted to have an Aqua mode for the site‚Äôs controls, joining the <a href="https://blog.persistent.info/search/label/Infinite%20Mac#:~:text=To%20reduce%20the%20cognitive%20dissonance%20(and%20to%20have%20a%20bit%20of%20fun)%2C%20I%20made%20the%20UI%20resemble%20the%20look%2Dand%2Dfeel%20of%20the%20OS%20that%20is%20being%20booted">classic, Platinum</a>, and <a href="https://blog.persistent.info/search/label/Infinite%20Mac#:~:text=With%20the%20initial%20emulator%20being%20brought%20up%2C%20there%20were%20some%20more%20fun%20tasks%2C%20like%20adding%20a%20NeXT%2Dstyle%20monitor%20frame%20and%20a%20NeXT%20appearance%20to%20the%20Infinite%20Mac%20controls%20(working%20on%20them%20is%20giving%20me%20Kaleidoscope%20scheme%20flashbacks).">NeXT</a> appearances. That prompted the question: <a href="https://512pixels.net/projects/aqua-screenshot-library/">which Aqua</a>?</p>

<p>
  <img alt="Screenshots of the logout dialog in Mac OS X 10.1 to 10.4" height="369" src="https://persistent.info/images/infinite-mac-mac-os-x-aqua.webp" width="901"><br>
  <i>Aqua: the early years</i>
</p>

<p>Though the more subdued versions from 10.3 and 10.4 are my favorites, I decided to go with the 10.0/10.1 one since it has the biggest nostalgia factor. I wanted to use the exact same image assets as the OS, and since they make heavy use of semi-transparency, regular screenshots were not going to be good enough. I used <a href="https://github.com/fuzziqersoftware/resource_dasm">resource_dasm</a> and <a href="https://kwasi-ich.de/software/aqua/">pxm2tga</a> to extract the original assets from <a href="http://www.atpm.com/11.06/customizing.shtml">Extras.rsrc</a> and create <a href="https://github.com/mihaip/infinite-mac/commit/cbc6a3ea8ac0523fbea27dbd57770837c60465db">my own version of Aqua</a>:</p>

<p>
  <img alt="Infinite Mac custom instance configuration dialog, rendered with an Aqua appearance" height="708" src="https://persistent.info/images/infinite-mac-mac-os-x-custom.webp" width="661">
</p>

<p>If the recent rumors of a <a href="https://www.bloomberg.com/news/articles/2025-03-10/apple-readies-dramatic-design-overhauls-for-ios-19-ipados-19-and-macos-16">big UI revamp</a> do come true, it‚Äôll be nice to have this reference point of its ancestor.</p>

<h3>Odds and Ends</h3>

<p>The ability to mount multiple images means that you can also have a Mac OS 9 partition and start the Classic compatibility environment (this only works under 10.1 ‚Äì PearPC never supported Classic). You can thus emulate classic Mac apps inside an emulated Mac OS X inside a WebAssembly virtual machine:</p>

<p>
  <img alt="Mac OS X 10.1 running Stickies, Scrapbook and Calculator under Classic" height="624" src="https://persistent.info/images/infinite-mac-mac-os-x-classic.webp" width="832">
</p>

<p>There was a recent storm in a teacup about <a href="https://mjtsai.com/blog/2025/01/30/repeating-calculator-operations/">a Calculator behavior change</a>. Using these Mac OS X images, it‚Äôs possible to verify that versions through 10.3 didn‚Äôt have the ‚Äúrepeatedly press equals‚Äù behavior, but 10.4 did.</p>

<p>Since Mac OS X boot is rather slow, I wanted to have a way to show more progress. PearPC has <a href="https://github.com/mihaip/infinite-mac/blob/cb6b16c3ace1b36c9228d991397176c0036bc960/src/Data/PearPCConfig.txt#L56-L61">a built-in way</a> to trigger verbose mode, but DingusPPC did not, so I added a way to <a href="https://github.com/dingusdev/dingusppc/commit/a6e1b8c338b4b93fcafe97605dc8b493c61fb2a3">specify Open Firmware variables at startup</a>. This is now exposed in the <a href="https://infinitemac.org/2001/Mac%20OS%20X%2010.1?edit">custom instance dialog</a> via the ‚ÄúDebug Mode‚Äù switch.</p>

<p>Though I‚Äôve moved away from custom domain names, I thought <a href="https://macosx.app/">macosx.app</a> would make a nice <a href="https://system6.app/">addition</a> <a href="https://system7.app/">to</a> <a href="https://macos8.app/">my</a> <a href="https://macos9.app/">collection</a>. Unfortunately it‚Äôs taken, though in a rather weird way. I even contacted the YouTuber whose video it redirects to, and he said he was not the one that registered it. It expires in a couple of months, so maybe I‚Äôll be able to grab it.</p>

<h3>The End Of The Line?</h3>

<blockquote>‚ÄúWhen Alexander saw the breadth of his domain, he wept for there were no more worlds to conquer.‚Äù<br>
‚Äî <s>Hans Gruber</s> <s>Plutarch</s> <a href="https://www.theparisreview.org/blog/2020/03/19/and-alexander-wept/">Some Frenchman</a></blockquote>

<p>Mac OS X support catches Infinite Mac up to the modern day, unless I happen to get access to some <a href="https://web.archive.org/web/20171006210639/https://twitter.com/mcclure111/status/916405883202129921">time travel mechanics</a>. There are of course two more CPU transitions to go through and numerous small changes, but Tiger is fundamentally recognizable to any current-day macOS user.</p>
<p>Except that in the retrocomputing world, it‚Äôs always possible to go deeper or more obscure. <a href="https://en.wikipedia.org/wiki/A/UX">A/UX</a> is not something that I‚Äôm very familiar with, but it was a contemporary of classic Mac OS and would be interesting to compare to NeXTStep. <a href="https://github.com/pruten/shoebill">Shoebill</a> runs it, and the codebase looks approachable enough to port. Then there‚Äôs <a href="https://github.com/mihaip/infinite-mac/issues/167">Lisa</a>, the <a href="https://en.wikipedia.org/wiki/Apple_Pippin">Pippin</a> (DingusPPC has some <a href="https://github.com/dingusdev/dingusppc/blob/master/machines/machinepippin.cpp">nascent support</a>), and further afield the Newton (via <a href="https://github.com/pguyot/Einstein">Einstein</a>?). We‚Äôll see what moves me next.</p>

<h3>A Post-Credits Sequence</h3>

<p>When I first began exploring ways of running Mac OS X, I mentioned that <a href="https://blog.persistent.info/2023/12/dingusppc.html#:~:text=The%20obvious%20choice%20was%20QEMU%20%E2%80%93%20it%20has%20very%20broad%20guest%20OS%20support%20and%20is%20very%20actively%20developed.%20However%2C%20it%E2%80%99s%20also%20a%20beast%20of%20a%20project%20to%20build%20and%20navigate%20around%3B%20it%20didn%E2%80%99t%20seem%20like%20it%20would%20be%20something%20I%20would%20able%20to%20make%20much%20progress%20on%20while%20working%20on%20it%20for%20a%20few%20hours%20a%20week.">QEMU seemed too daunting to port</a> to WebAssembly given my limited time. Furthermore, the performance of the <a href="https://github.com/atrosinenko/qemujs">qemu.js</a> experiment from a few years ago made it seem like even if it did run, it would be much too slow to be usable. However, I recently became aware of <a href="https://github.com/ktock/qemu-wasm">qemu-wasm</a> via <a href="https://fosdem.org/2025/schedule/event/fosdem-2025-6290-running-qemu-inside-browser/">this FOSDEM presentation</a>. The performance of its Linux guest <a href="https://ktock.github.io/qemu-wasm-demo/">demos</a> is encouraging: I ran an impromptu bennmark of computing an MD5 checksum of 100 MB of data and it completed it in 8 seconds (vs. 13 for DingusPPC and 18 for PearPC). There‚Äôs still a big gap between that and a graphical guest like Mac OS X, but it‚Äôs nice to have this existence proof.</p>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Giant, All-Seeing Telescope Is Set to Revolutionize Astronomy (172 pts)]]></title>
            <link>https://www.science.org/content/article/giant-all-seeing-telescope-set-revolutionize-astronomy</link>
            <guid>44323389</guid>
            <pubDate>Thu, 19 Jun 2025 23:17:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/article/giant-all-seeing-telescope-set-revolutionize-astronomy">https://www.science.org/content/article/giant-all-seeing-telescope-set-revolutionize-astronomy</a>, See on <a href="https://news.ycombinator.com/item?id=44323389">Hacker News</a></p>
Couldn't get https://www.science.org/content/article/giant-all-seeing-telescope-set-revolutionize-astronomy: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I wrote a new BitTorrent tracker in Elixir (368 pts)]]></title>
            <link>https://github.com/Dahrkael/ExTracker</link>
            <guid>44323253</guid>
            <pubDate>Thu, 19 Jun 2025 22:49:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Dahrkael/ExTracker">https://github.com/Dahrkael/ExTracker</a>, See on <a href="https://news.ycombinator.com/item?id=44323253">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Dahrkael/ExTracker/blob/master/.github/extracker-logo.png"><img src="https://github.com/Dahrkael/ExTracker/raw/master/.github/extracker-logo.png" alt="ExTracker"></a>
The Bittorrent Tracker made in Elixir</p>
<p dir="auto"><a href="https://github.com/Dahrkael/ExTracker/actions/workflows/build-on-push.yml"><img src="https://github.com/Dahrkael/ExTracker/actions/workflows/build-on-push.yml/badge.svg" alt="CI"></a>
<a href="https://github.com/Dahrkael/ExTracker/actions/workflows/test-on-push.yml"><img src="https://github.com/Dahrkael/ExTracker/actions/workflows/test-on-push.yml/badge.svg" alt="CI"></a>
<a href="https://github.com/Dahrkael/ExTracker/actions/workflows/docker-release.yml"><img src="https://github.com/Dahrkael/ExTracker/actions/workflows/docker-release.yml/badge.svg" alt="CI"></a></p>
<p dir="auto">üë∑‚Äç‚ôÇÔ∏èThis project is a Work In Progress. While not ready for full industrial usage it does work.<br>
There is a testing instance running at <a href="http://extracker.dahrkael.net:6969/about" rel="nofollow">extracker.dahrkael.net:6969</a> with all current features enabled (<a href="http://extracker.dahrkael.net:9568/tracker-stats.html" rel="nofollow">Live statistics</a>).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<p dir="auto">Implementation Legend:
üî≤ Not Yet üî∞ Partially ‚úÖ Done ‚ùå Won't do</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Important Features</h3><a id="user-content-important-features" aria-label="Permalink: Important Features" href="#important-features"></a></p>
<ul dir="auto">
<li>‚úÖ High performance (uses ALL the available cores, in-memory storage)</li>
<li>‚úÖ Low memory usage (~200MB of RAM for each 1.000.000 peers)</li>
<li>‚úÖ Zero setup (launch it and it just works)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Tracker-related BitTorrent Enhancement Proposals</h3><a id="user-content-tracker-related-bittorrent-enhancement-proposals" aria-label="Permalink: Tracker-related BitTorrent Enhancement Proposals" href="#tracker-related-bittorrent-enhancement-proposals"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Final and Active Process BEPs</h4><a id="user-content-final-and-active-process-beps" aria-label="Permalink: Final and Active Process BEPs" href="#final-and-active-process-beps"></a></p>
<ul dir="auto">
<li>‚úÖ <strong>BEP 0:</strong> <a href="https://www.bittorrent.org/beps/bep_0003.html" rel="nofollow">The BitTorrent Protocol Specification</a></li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Accepted BEPs</h4><a id="user-content-accepted-beps" aria-label="Permalink: Accepted BEPs" href="#accepted-beps"></a></p>
<ul dir="auto">
<li>‚úÖ <strong>BEP 15:</strong> <a href="https://www.bittorrent.org/beps/bep_0015.html" rel="nofollow">UDP Tracker Protocol</a></li>
<li>‚úÖ <strong>BEP 23:</strong> <a href="https://www.bittorrent.org/beps/bep_0023.html" rel="nofollow">Tracker Returns Compact Peer Lists</a></li>
<li>üî≤ <strong>BEP 27:</strong> <a href="https://www.bittorrent.org/beps/bep_0027.html" rel="nofollow">Private Torrents</a></li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Draft BEPs</h4><a id="user-content-draft-beps" aria-label="Permalink: Draft BEPs" href="#draft-beps"></a></p>
<ul dir="auto">
<li>‚úÖ <strong>BEP 7:</strong> <a href="https://www.bittorrent.org/beps/bep_0007.html" rel="nofollow">IPv6 Tracker Extension</a></li>
<li>üî≤ <strong>BEP 21:</strong> <a href="https://www.bittorrent.org/beps/bep_0021.html" rel="nofollow">Extension for partial seeds</a></li>
<li>‚úÖ <strong>BEP 24:</strong> <a href="https://www.bittorrent.org/beps/bep_0024.html" rel="nofollow">Tracker Returns External IP</a></li>
<li>üî≤ <strong>BEP 31:</strong> <a href="https://www.bittorrent.org/beps/bep_0031.html" rel="nofollow">Tracker Failure Retry Extension</a></li>
<li>‚úÖ <strong>BEP 41:</strong> <a href="https://www.bittorrent.org/beps/bep_0041.html" rel="nofollow">UDP Tracker Protocol Extensions</a></li>
<li>üî∞ <strong>BEP 48:</strong> <a href="https://www.bittorrent.org/beps/bep_0048.html" rel="nofollow">Tracker Protocol Extension: Scrape</a></li>
<li>‚úÖ <strong>BEP 52:</strong> <a href="https://www.bittorrent.org/beps/bep_0052.html" rel="nofollow">The BitTorrent Protocol Specification v2</a></li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Deferred BEPs</h4><a id="user-content-deferred-beps" aria-label="Permalink: Deferred BEPs" href="#deferred-beps"></a></p>
<ul dir="auto">
<li>‚ùå <strong>BEP 8:</strong> <a href="https://www.bittorrent.org/beps/bep_0008.html" rel="nofollow">Tracker Peer Obfuscation</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Other Features</h3><a id="user-content-other-features" aria-label="Permalink: Other Features" href="#other-features"></a></p>
<ul dir="auto">
<li>‚úÖ HTTPS support</li>
<li>‚úÖ Database backups to disk</li>
<li>‚ùå WebTorrent</li>
<li>üî∞ Infohash whitelist/blacklist</li>
<li>üî∞ Peer management (interval enforcement, cleanup, banning, etc)</li>
<li>üî∞ Metrics</li>
<li>üî∞ GeoIP support (statistics, peer restrictions)</li>
<li><strong>Feel free to propose features in the <a href="https://github.com/Dahrkael/ExTracker/issues">Issues</a></strong></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Setup</h2><a id="user-content-setup" aria-label="Permalink: Setup" href="#setup"></a></p>
<p dir="auto">There are 3 main ways of running ExTracker currently</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Straight from source code</h3><a id="user-content-straight-from-source-code" aria-label="Permalink: Straight from source code" href="#straight-from-source-code"></a></p>
<p dir="auto">For this method to work you need to have <strong>Erlang</strong> and <strong>Elixir</strong> installed on your system</p>
<ul dir="auto">
<li>Clone the repository: <code>git clone https://github.com/Dahrkael/ExTracker.git &amp;&amp; cd ExTracker</code></li>
<li>If needed, modify the configuration in <a href="https://github.com/Dahrkael/ExTracker/blob/master/config/runtime.exs">config/runtime.exs</a> to fit your needs</li>
<li>run <code>MIX_ENV=prod iex -S mix</code></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">From Releases</h3><a id="user-content-from-releases" aria-label="Permalink: From Releases" href="#from-releases"></a></p>
<p dir="auto">Currently there are no official releases built (soon‚Ñ¢Ô∏è). You can however make your own and deploy it where needed:</p>
<ul dir="auto">
<li>Clone the repository: <code>git clone https://github.com/Dahrkael/ExTracker.git &amp;&amp; cd ExTracker</code></li>
<li>run <code>MIX_ENV=prod mix release extracker</code> for Linux or <code>MIX_ENV=prod mix release extrackerw</code> for Windows</li>
<li>Find the release files inside the <em>_build/prod/rel/extracker</em> folder (if its a different machine make sure the OS and architecture is the same!)</li>
<li>Copy the folder to its final destination</li>
<li>If needed, modify the configuration in <a href="https://github.com/Dahrkael/ExTracker/blob/master/config/runtime.exs">releases/{VERSION}/runtime.exs</a> to fit your needs</li>
<li>Run <code>bin/extracker start</code></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Docker</h3><a id="user-content-docker" aria-label="Permalink: Docker" href="#docker"></a></p>
<p dir="auto">For this method you can directly run the <a href="https://github.com/Dahrkael/ExTracker/pkgs/container/extracker/422008654?tag=latest">available docker image</a>: <code>docker run ghcr.io/dahrkael/extracker:latest</code><br>
or use it as part of docker-compose. Theres an <a href="https://github.com/Dahrkael/ExTracker/blob/master/docker-compose.yml">example compose file</a> available.</p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">Since modifying the <a href="https://github.com/Dahrkael/ExTracker/blob/master/config/runtime.exs">runtime.exs</a> file to tune the configuration inside the container is not easy you can also configure it using <strong>Environment Variables</strong>, see the example compose file for the complete list.</p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Copyright and license</h2><a id="user-content-copyright-and-license" aria-label="Permalink: Copyright and license" href="#copyright-and-license"></a></p>
<p dir="auto">Copyright (c) Dahrkael &lt;dahrkael at outlook dot com&gt;<br>
Distributed under the terms of the Apache License, Version 2.0. Please refer to the <a href="https://github.com/Dahrkael/ExTracker/blob/master/LICENSE">LICENSE file</a> in the repository root directory for details.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Literate programming tool for any language (133 pts)]]></title>
            <link>https://github.com/zyedidia/Literate</link>
            <guid>44323045</guid>
            <pubDate>Thu, 19 Jun 2025 22:18:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/zyedidia/Literate">https://github.com/zyedidia/Literate</a>, See on <a href="https://news.ycombinator.com/item?id=44323045">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Literate</h2><a id="user-content-literate" aria-label="Permalink: Literate" href="#literate"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is Literate programming?</h2><a id="user-content-what-is-literate-programming" aria-label="Permalink: What is Literate programming?" href="#what-is-literate-programming"></a></p>
<p dir="auto">Literate programming is a style of programming invented by Donald Knuth, where the main idea is that a program's source code is made primarily to be read and understood by other people, and secondarily to be executed by the computer.</p>
<p dir="auto">This frees the programmer from the structure of a program imposed by the computer and means that the programmer can develop programs in the order of the flow of their thoughts.</p>
<p dir="auto">A Literate program generally consists of explanation of the code in a natural language such as English, interspersed with snippets of code to be executed. This means that Literate programs are very easy to understand and share, as all the code is well explained.</p>
<hr>
<p dir="auto">Literate is a tool for creating literate programs.</p>
<p dir="auto">The goal of this project is to create a literate programming tool which keeps most, if not all of the features of Knuth and Levy's original CWEB system, but simplifies the system and adds even more features.</p>
<p dir="auto">You can view the main website about Literate <a href="https://zyedidia.github.io/literate" rel="nofollow">here</a> including a <a href="https://zyedidia.github.io/literate/manual.html" rel="nofollow">manual</a> on how to use Literate.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Supports any language including syntax highlighting and pretty printing in HTML</li>
<li>Markdown based -- very easy to read and write Literate source.</li>
<li>Reports syntax errors back from the compiler to the right line in the literate source</li>
<li>Generates readable and commented code in the target language (the generated code is usable by others)</li>
<li>Supports TeX equations with <code>$</code> notation.</li>
<li>Literate source code is readable whether you are looking at the <code>.lit</code> file, or the generated HTML.</li>
<li>Highly customizable (you can add your own HTML or CSS)</li>
<li>Runs fast -- wc.lit compiled for me in 7ms for both code and HTML output</li>
<li>Automatically generates hyperlinks between code sections</li>
<li>Formatted output similar to CWEB</li>
<li>Supported by <a href="https://github.com/zyedidia/micro">micro</a> (by default)</li>
<li>Compatible with Vim (<a href="https://github.com/zyedidia/literate.vim">literate.vim</a>)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Example</h2><a id="user-content-example" aria-label="Permalink: Example" href="#example"></a></p>
<p dir="auto">Here is a trivial example of a literate program saved in the file <code>hello.lit</code>.</p>
<p dir="auto">For a full example of a literate program, please see <a href="https://github.com/zyedidia/Literate/blob/master/examples/wc.lit"><code>examples/wc.lit</code></a> which
is a literate implementation of the <code>wc</code> (word count) program found on Unix systems.
You can find the compiled html <a href="https://zyedidia.github.io/literate/examples/wc.html" rel="nofollow">here</a>.</p>
<div data-snippet-clipboard-copy-content="@title Hello world in C

@s Introduction

This is an example hello world C program.
We can define codeblocks with `---`

--- hello.c
@{Includes}

int main() {
    @{Print a string}
    return 0;
}
---

Now we can define the `Includes` codeblock:

--- Includes
#include <stdio.h>
---

Finally, our program needs to print &quot;hello world&quot;

--- Print a string
printf(&quot;hello world\n&quot;);
---"><pre><code>@title Hello world in C

@s Introduction

This is an example hello world C program.
We can define codeblocks with `---`

--- hello.c
@{Includes}

int main() {
    @{Print a string}
    return 0;
}
---

Now we can define the `Includes` codeblock:

--- Includes
#include &lt;stdio.h&gt;
---

Finally, our program needs to print "hello world"

--- Print a string
printf("hello world\n");
---
</code></pre></div>
<p dir="auto">To compile this code simply run</p>
<p dir="auto"><code>$ lit hello.lit</code></p>
<p dir="auto">Which generates <a href="https://zyedidia.github.io/literate/examples/hello.c" rel="nofollow">hello.c</a> and <a href="https://zyedidia.github.io/literate/examples/hello.html" rel="nofollow">hello.html</a>.</p>
<p dir="auto">You can also find this program in <code>examples/hello.lit</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Prebuilt binaries</h3><a id="user-content-prebuilt-binaries" aria-label="Permalink: Prebuilt binaries" href="#prebuilt-binaries"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Download</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://zyedidia.github.io/literate/binaries/literate-osx.tar.gz" rel="nofollow">Mac OS X</a></td>
</tr>
<tr>
<td><a href="https://zyedidia.github.io/literate/binaries/literate-linux64.tar.gz" rel="nofollow">64 bit Linux</a></td>
</tr>
<tr>
<td><a href="https://zyedidia.github.io/literate/binaries/literate-linux32.tar.gz" rel="nofollow">32 bit Linux</a></td>
</tr>
<tr>
<td><a href="https://zyedidia.github.io/literate/binaries/literate-linux-arm.tar.gz" rel="nofollow">Arm Linux</a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Building from Source</h3><a id="user-content-building-from-source" aria-label="Permalink: Building from Source" href="#building-from-source"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Mac</h4><a id="user-content-mac" aria-label="Permalink: Mac" href="#mac"></a></p>
<p dir="auto">On Mac you can use brew to build Literate from source:</p>
<div data-snippet-clipboard-copy-content="$ brew tap zyedidia/literate
$ brew install --HEAD literate"><pre><code>$ brew tap zyedidia/literate
$ brew install --HEAD literate
</code></pre></div>
<p dir="auto">For now, Literate is head only.</p>
<hr>
<p dir="auto">Literate is made with the <a href="https://dlang.org/" rel="nofollow">D programming language</a> so you must install <a href="https://dlang.org/download.html#dmd" rel="nofollow">dmd</a> (D compiler) and <a href="https://code.dlang.org/download" rel="nofollow">dub</a> (D package manager). Then you should download the zip or clone the repository and run the following commands:</p>

<p dir="auto">You can find the binary in path/to/Literate/bin (you may want to add this to your path or move it to <code>/usr/local/bin</code>).</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Editors</h3><a id="user-content-editors" aria-label="Permalink: Editors" href="#editors"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Micro</h3><a id="user-content-micro" aria-label="Permalink: Micro" href="#micro"></a></p>
<p dir="auto">The micro editor has support for literate by default. Download it <a href="https://github.com/zyedidia/micro">here</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Vim</h3><a id="user-content-vim" aria-label="Permalink: Vim" href="#vim"></a></p>
<p dir="auto">You might also want to go install the <a href="https://github.com/zyedidia/literate.vim">Vim plugin</a> (it has syntax highlighting of the embedded code, linting with Neomake, and jumping to codeblock definitions).
I'm sorry that no other editors are supported -- I don't know how to make plugins for other editors.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<div data-snippet-clipboard-copy-content="Lit: Literate Programming System

Usage: lit [options] <inputs>

Options:
--help       -h         Show this help text
--tangle     -t         Only compile code files
--weave      -w         Only compile HTML files
--no-output  -no        Do not generate any output files
--out-dir    -odir DIR  Put the generated files in DIR
--compiler   -c         Report compiler errors (needs @compiler to be defined)
--linenums   -l    STR  Write line numbers prepended with STR to the output file
--md-compiler COMPILER  Use COMPILER as the markdown compiler instead of the built-in one
--version    -v         Show the version number and compiler information"><pre><code>Lit: Literate Programming System

Usage: lit [options] &lt;inputs&gt;

Options:
--help       -h         Show this help text
--tangle     -t         Only compile code files
--weave      -w         Only compile HTML files
--no-output  -no        Do not generate any output files
--out-dir    -odir DIR  Put the generated files in DIR
--compiler   -c         Report compiler errors (needs @compiler to be defined)
--linenums   -l    STR  Write line numbers prepended with STR to the output file
--md-compiler COMPILER  Use COMPILER as the markdown compiler instead of the built-in one
--version    -v         Show the version number and compiler information
</code></pre></div>
<p dir="auto">For more information see the <a href="https://zyedidia.github.io/literate/manual.html" rel="nofollow">manual</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Literate is written in Literate D and you can find the source code in the <code>lit</code> directory. You can also read the source code compiled by Literate <a href="https://zyedidia.github.io/literate/literate-source" rel="nofollow">here</a>.
I am happy to accept pull requests, and if you find any bugs, please report them. Thanks!</p>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>