<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 18 Dec 2024 16:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Trying to Recreate iOS on the Web (122 pts)]]></title>
            <link>https://homescreen.app/</link>
            <guid>42449588</guid>
            <pubDate>Wed, 18 Dec 2024 11:11:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://homescreen.app/">https://homescreen.app/</a>, See on <a href="https://news.ycombinator.com/item?id=42449588">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Silver amulet is the oldest evidence of Christianity north of the Alps (146 pts)]]></title>
            <link>https://archaeologymag.com/2024/12/oldest-evidence-of-christianity-north-of-the-alps/</link>
            <guid>42448939</guid>
            <pubDate>Wed, 18 Dec 2024 08:31:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://archaeologymag.com/2024/12/oldest-evidence-of-christianity-north-of-the-alps/">https://archaeologymag.com/2024/12/oldest-evidence-of-christianity-north-of-the-alps/</a>, See on <a href="https://news.ycombinator.com/item?id=42448939">Hacker News</a></p>
Couldn't get https://archaeologymag.com/2024/12/oldest-evidence-of-christianity-north-of-the-alps/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: ImPlot3D – A 3D Plotting Library for Dear ImGui (114 pts)]]></title>
            <link>https://github.com/brenocq/implot3d</link>
            <guid>42448913</guid>
            <pubDate>Wed, 18 Dec 2024 08:24:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/brenocq/implot3d">https://github.com/brenocq/implot3d</a>, See on <a href="https://news.ycombinator.com/item?id=42448913">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">ImPlot3D</h2><a id="user-content-implot3d" aria-label="Permalink: ImPlot3D" href="#implot3d"></a></p>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/17342434/396294009-359473d2-73a9-452c-a5f3-cb96e3785dc2.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1MzYxMDMsIm5iZiI6MTczNDUzNTgwMywicGF0aCI6Ii8xNzM0MjQzNC8zOTYyOTQwMDktMzU5NDczZDItNzNhOS00NTJjLWE1ZjMtY2I5NmUzNzg1ZGMyLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjE4VDE1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQyMDA2NzBkNzgwMTQ2Yzc5OTc4NTBmNTk1MjEzOWZiMDZjN2FjZTc5Y2RjOWEwYjU1ZTE4Mzg5MTdmYzVjNjUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.VTIOZATWNCgfD9jqrN7I2sf9sDEgaKQTbL4eeXp-XKM"><img src="https://private-user-images.githubusercontent.com/17342434/396294009-359473d2-73a9-452c-a5f3-cb96e3785dc2.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1MzYxMDMsIm5iZiI6MTczNDUzNTgwMywicGF0aCI6Ii8xNzM0MjQzNC8zOTYyOTQwMDktMzU5NDczZDItNzNhOS00NTJjLWE1ZjMtY2I5NmUzNzg1ZGMyLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjE4VDE1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQyMDA2NzBkNzgwMTQ2Yzc5OTc4NTBmNTk1MjEzOWZiMDZjN2FjZTc5Y2RjOWEwYjU1ZTE4Mzg5MTdmYzVjNjUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.VTIOZATWNCgfD9jqrN7I2sf9sDEgaKQTbL4eeXp-XKM" width="270" data-animated-image=""></a> <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/17342434/396293920-97ec8be4-50f9-428b-b357-25e2479409b8.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1MzYxMDMsIm5iZiI6MTczNDUzNTgwMywicGF0aCI6Ii8xNzM0MjQzNC8zOTYyOTM5MjAtOTdlYzhiZTQtNTBmOS00MjhiLWIzNTctMjVlMjQ3OTQwOWI4LmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjE4VDE1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTRiMTUzYTk0ODFhYmFlMDZhMTQ0MjBjMGEzMTRmZTk3MWE0YmI5YzNiYThlMTE1NDhmMDVlODgxZWYxYjJkYmQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.6N4RUAIZHGzToq6YEnD1ScvJrxb_1Mjnz7jARKrcuNw"><img src="https://private-user-images.githubusercontent.com/17342434/396293920-97ec8be4-50f9-428b-b357-25e2479409b8.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1MzYxMDMsIm5iZiI6MTczNDUzNTgwMywicGF0aCI6Ii8xNzM0MjQzNC8zOTYyOTM5MjAtOTdlYzhiZTQtNTBmOS00MjhiLWIzNTctMjVlMjQ3OTQwOWI4LmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjE4VDE1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTRiMTUzYTk0ODFhYmFlMDZhMTQ0MjBjMGEzMTRmZTk3MWE0YmI5YzNiYThlMTE1NDhmMDVlODgxZWYxYjJkYmQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.6N4RUAIZHGzToq6YEnD1ScvJrxb_1Mjnz7jARKrcuNw" width="270" data-animated-image=""></a> <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/17342434/396293963-c212039b-4853-4d26-95a5-5470bf97555e.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1MzYxMDMsIm5iZiI6MTczNDUzNTgwMywicGF0aCI6Ii8xNzM0MjQzNC8zOTYyOTM5NjMtYzIxMjAzOWItNDg1My00ZDI2LTk1YTUtNTQ3MGJmOTc1NTVlLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjE4VDE1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTYwNGQyY2E0NmVkZDBkODQ0OTc2NTI1MGU4ZmQxYWIzMGRlN2VlZmNhNmMzODZkYWFjMGUyMTc4ZWZlMmRkZDAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.x_iGhu2SickTdn2e7szGsTwFikjZpoOcg_4a_RZWBjQ"><img src="https://private-user-images.githubusercontent.com/17342434/396293963-c212039b-4853-4d26-95a5-5470bf97555e.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1MzYxMDMsIm5iZiI6MTczNDUzNTgwMywicGF0aCI6Ii8xNzM0MjQzNC8zOTYyOTM5NjMtYzIxMjAzOWItNDg1My00ZDI2LTk1YTUtNTQ3MGJmOTc1NTVlLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjE4VDE1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTYwNGQyY2E0NmVkZDBkODQ0OTc2NTI1MGU4ZmQxYWIzMGRlN2VlZmNhNmMzODZkYWFjMGUyMTc4ZWZlMmRkZDAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.x_iGhu2SickTdn2e7szGsTwFikjZpoOcg_4a_RZWBjQ" width="270" data-animated-image=""></a>
</p>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/17342434/396293851-ec7ec42a-3c62-44bf-9275-f735f0304c95.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1MzYxMDMsIm5iZiI6MTczNDUzNTgwMywicGF0aCI6Ii8xNzM0MjQzNC8zOTYyOTM4NTEtZWM3ZWM0MmEtM2M2Mi00NGJmLTkyNzUtZjczNWYwMzA0Yzk1LmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjE4VDE1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPThmM2IzNTc5MDhkZGJiMzc4YzM2NzBjMGEyNjZlNzkyZTNjODU5NDE2OTU2YTAwZDQ5ZDY5Mzk4MzM4ZjFhMmUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.SlPrGpoBjv1WRxHJib3NG5vYWNjPnaCIWpxhrpK5xxY"><img src="https://private-user-images.githubusercontent.com/17342434/396293851-ec7ec42a-3c62-44bf-9275-f735f0304c95.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1MzYxMDMsIm5iZiI6MTczNDUzNTgwMywicGF0aCI6Ii8xNzM0MjQzNC8zOTYyOTM4NTEtZWM3ZWM0MmEtM2M2Mi00NGJmLTkyNzUtZjczNWYwMzA0Yzk1LmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjE4VDE1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPThmM2IzNTc5MDhkZGJiMzc4YzM2NzBjMGEyNjZlNzkyZTNjODU5NDE2OTU2YTAwZDQ5ZDY5Mzk4MzM4ZjFhMmUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.SlPrGpoBjv1WRxHJib3NG5vYWNjPnaCIWpxhrpK5xxY" width="270" data-animated-image=""></a> <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/17342434/396294038-e6bd03fa-6d76-4f3e-8d15-c24a05a5f714.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1MzYxMDMsIm5iZiI6MTczNDUzNTgwMywicGF0aCI6Ii8xNzM0MjQzNC8zOTYyOTQwMzgtZTZiZDAzZmEtNmQ3Ni00ZjNlLThkMTUtYzI0YTA1YTVmNzE0LmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjE4VDE1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ5NGU5Y2U2ODBhMjQzZmM4ZjlkYmQ3OWQ3ZjUwZTFjMTkzNjE1OTY5MDFjMzhjY2YwZDk1ZTc3N2RhMjcyYjYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.xTf-jYLyBnhWwTX76H9-wop8XuLmE-OEoP_ewOhxXwI"><img src="https://private-user-images.githubusercontent.com/17342434/396294038-e6bd03fa-6d76-4f3e-8d15-c24a05a5f714.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1MzYxMDMsIm5iZiI6MTczNDUzNTgwMywicGF0aCI6Ii8xNzM0MjQzNC8zOTYyOTQwMzgtZTZiZDAzZmEtNmQ3Ni00ZjNlLThkMTUtYzI0YTA1YTVmNzE0LmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjE4VDE1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ5NGU5Y2U2ODBhMjQzZmM4ZjlkYmQ3OWQ3ZjUwZTFjMTkzNjE1OTY5MDFjMzhjY2YwZDk1ZTc3N2RhMjcyYjYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.xTf-jYLyBnhWwTX76H9-wop8XuLmE-OEoP_ewOhxXwI" width="270" data-animated-image=""></a> <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/17342434/396294001-b66ff296-7fbf-4644-9129-37daecca0b62.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1MzYxMDMsIm5iZiI6MTczNDUzNTgwMywicGF0aCI6Ii8xNzM0MjQzNC8zOTYyOTQwMDEtYjY2ZmYyOTYtN2ZiZi00NjQ0LTkxMjktMzdkYWVjY2EwYjYyLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjE4VDE1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQyZjk1ODNjYzRhZTk4ZjQ4OGFiNTNmNTllYTk5MGFkYWE0MTg1MmY5NDkxYmI0NGIyZGFjNDBlMmRjNzJjY2ImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.hOSL_5rAcg5LWYmJ6cZE7Gb6bFi4Up3vQIV5QBLYcxY"><img src="https://private-user-images.githubusercontent.com/17342434/396294001-b66ff296-7fbf-4644-9129-37daecca0b62.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1MzYxMDMsIm5iZiI6MTczNDUzNTgwMywicGF0aCI6Ii8xNzM0MjQzNC8zOTYyOTQwMDEtYjY2ZmYyOTYtN2ZiZi00NjQ0LTkxMjktMzdkYWVjY2EwYjYyLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjE4VDE1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQyZjk1ODNjYzRhZTk4ZjQ4OGFiNTNmNTllYTk5MGFkYWE0MTg1MmY5NDkxYmI0NGIyZGFjNDBlMmRjNzJjY2ImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.hOSL_5rAcg5LWYmJ6cZE7Gb6bFi4Up3vQIV5QBLYcxY" width="270" data-animated-image=""></a>
</p>
<p dir="auto">ImPlot3D is an extension of <a href="https://github.com/ocornut/imgui">Dear ImGui</a> that provides easy-to-use, high-performance 3D plotting functionality. Inspired by <a href="https://github.com/epezent/implot">ImPlot</a>, it brings a familiar and intuitive API for developers already acquainted with ImPlot. ImPlot3D is designed for rendering 3D plots with customizable markers, lines, surfaces, and meshes, providing an ideal solution for applications requiring visual representation of 3D data.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Features</h2><a id="user-content--features" aria-label="Permalink: 🚀 Features" href="#-features"></a></p>
<ul dir="auto">
<li>GPU-accelerated rendering</li>
<li>Multiple plot types:
<ul dir="auto">
<li>Line plots</li>
<li>Scatter plots</li>
<li>Surface plots</li>
<li>Quad plots</li>
<li>Triangle plots</li>
<li>Mesh plots</li>
<li>Text plots</li>
</ul>
</li>
<li>Rotate, pan, and zoom 3D plots interactively</li>
<li>Several plot styling options: 10 marker types, adjustable marker sizes, line weights, outline colors, fill colors, etc.</li>
<li>16 built-in colormaps and support for and user-added colormaps</li>
<li>Optional plot titles, axis labels, and grid labels</li>
<li>Optional and configurable legends with toggle buttons to quickly show/hide plot items</li>
<li>Default styling based on the current ImGui theme, or completely custom plot styles</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🛠️ Usage</h2><a id="user-content-️-usage" aria-label="Permalink: 🛠️ Usage" href="#️-usage"></a></p>
<p dir="auto">The ImPlot3D API is designed to feel very similar to Dear ImGui and ImPlot. You start by calling <code>ImPlot3D::BeginPlot()</code> to initialize a 3D plot, followed by plotting various data using the <code>PlotX</code> functions (e.g., <code>PlotLine()</code> , <code>PlotScatter()</code> , <code>PlotSurface()</code> ). Finally, you end the plot with <code> ImPlot3D::EndPlot()</code> .</p>
<div dir="auto" data-snippet-clipboard-copy-content="float x_data[1000] = ...;
float y_data[1000] = ...;
float z_data[1000] = ...;

ImGui::Begin(&quot;My Window&quot;);
if (ImPlot3D::BeginPlot(&quot;My Plot&quot;)) {
    ImPlot3D::PlotLine(&quot;My Line Plot&quot;, x_data, y_data, z_data, 1000);
    ImPlot3D::PlotScatter(&quot;My Scatter Plot&quot;, x_data, y_data, z_data, 1000);
    ...
    ImPlot3D::EndPlot();
}
ImGui::End();"><pre><span>float</span> x_data[<span>1000</span>] = ...;
<span>float</span> y_data[<span>1000</span>] = ...;
<span>float</span> z_data[<span>1000</span>] = ...;

<span>ImGui::Begin</span>(<span><span>"</span>My Window<span>"</span></span>);
<span>if</span> (ImPlot3D::BeginPlot(<span><span>"</span>My Plot<span>"</span></span>)) {
    <span>ImPlot3D::PlotLine</span>(<span><span>"</span>My Line Plot<span>"</span></span>, x_data, y_data, z_data, <span>1000</span>);
    <span>ImPlot3D::PlotScatter</span>(<span><span>"</span>My Scatter Plot<span>"</span></span>, x_data, y_data, z_data, <span>1000</span>);
    ...
    <span>ImPlot3D::EndPlot</span>();
}
<span>ImGui::End</span>();</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">🎨 Demos</h2><a id="user-content--demos" aria-label="Permalink: 🎨 Demos" href="#-demos"></a></p>
<p dir="auto">A comprehensive example showcasing ImPlot3D features can be found in <code>implot3d_demo.cpp</code>. Add this file to your project and call <code>ImPlot3D::ShowDemoWindow()</code> in your update loop. This demo provides a wide variety of 3D plotting examples, serving as a reference for creating different types of 3D plots. The demo is regularly updated to reflect new features and plot types, so be sure to revisit it with each release!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">⚙️ Integration</h2><a id="user-content-️-integration" aria-label="Permalink: ⚙️ Integration" href="#️-integration"></a></p>
<p dir="auto">To integrate ImPlot3D into your application, follow these steps:</p>
<ol dir="auto">
<li>Ensure you have a working Dear ImGui environment. ImPlot3D requires only Dear ImGui to function and does not depend on ImPlot.</li>
<li>Add the following source files to your project: <code>implot3d.h</code>, <code>implot3d.cpp</code>, <code>implot3d_internal.h</code>, <code>implot3d_items.cpp</code>. Optionally, include <code>implot3d_demo.cpp</code> for examples and <code>implot3d_meshes.cpp</code> to support pre-loaded meshes.</li>
<li>Create and destroy an ImPlot3DContext alongside your ImGuiContext:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="ImGui::CreateContext();
ImPlot3D::CreateContext();
...
ImPlot3D::DestroyContext();
ImGui::DestroyContext();"><pre><span>ImGui::CreateContext</span>();
<span>ImPlot3D::CreateContext</span>();
...
<span>ImPlot3D::DestroyContext</span>();
<span>ImGui::DestroyContext</span>();</pre></div>
<p dir="auto">You're now ready to start plotting in 3D!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto"><g-emoji alias="warning">⚠️</g-emoji> Extremely Important Note</h2><a id="user-content-️-extremely-important-note" aria-label="Permalink: ⚠️ Extremely Important Note" href="#️-extremely-important-note"></a></p>
<p dir="auto">Dear ImGui, by default, uses 16-bit indexing, which might cause issues with high-density 3D visualizations such as complex surfaces or meshes. This can lead to assertion failures, data truncation, or visual glitches. To avoid these problems, it's recommended to:</p>
<ul dir="auto">
<li>Option 1: Enable 32-bit indices by uncommenting <code>#define ImDrawIdx unsigned int</code> in your ImGui imconfig.h file.</li>
<li>Option 2: Ensure your renderer supports the <code>ImGuiBackendFlags_RendererHasVtxOffset</code> flag. Many official ImGui backends already support this functionality.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">💬 FAQ</h2><a id="user-content--faq" aria-label="Permalink: 💬 FAQ" href="#-faq"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Why ImPlot3D?</h4><a id="user-content-why-implot3d" aria-label="Permalink: Why ImPlot3D?" href="#why-implot3d"></a></p>
<p dir="auto">While ImGui excels at building UI, it lacks tools for 3D data visualization. ImPlot3D fills this gap, offering a lightweight, real-time library for 3D plotting, designed with interactivity and ease of use in mind.</p>
<p dir="auto">Inspired by ImPlot, ImPlot3D provides a similar API, making it easy for existing ImPlot users to adopt. It focuses on real-time, application-level 3D visualizations for debugging, simulations, and data analysis, with performance as a priority.</p>
<p dir="auto">ImPlot is great for 2D visualizations; ImPlot3D extends this power to 3D, offering the same simplicity and speed.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Where can I find documentation?</h4><a id="user-content-where-can-i-find-documentation" aria-label="Permalink: Where can I find documentation?" href="#where-can-i-find-documentation"></a></p>
<p dir="auto">The API for ImPlot3D is thoroughly commented in <code>implot3d.h</code>, and a comprehensive demo file, <code>implot3d_demo.cpp</code>, showcases all the features. You are encouraged to explore the demo file as it is regularly updated to reflect new functionality. Additionally, if you're familiar with ImPlot, you'll notice many similarities in usage patterns.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">How is ImPlot3D different from ImPlot?</h4><a id="user-content-how-is-implot3d-different-from-implot" aria-label="Permalink: How is ImPlot3D different from ImPlot?" href="#how-is-implot3d-different-from-implot"></a></p>
<p dir="auto">ImPlot3D is highly inspired by ImPlot, so if you're already familiar with ImPlot, you'll feel right at home. However, ImPlot3D is specifically built for 3D visualizations, offering interactive 3D rotations, panning, and scaling.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Do I need ImPlot to use ImPlot3D?</h3><a id="user-content-do-i-need-implot-to-use-implot3d" aria-label="Permalink: Do I need ImPlot to use ImPlot3D?" href="#do-i-need-implot-to-use-implot3d"></a></p>
<p dir="auto">No. ImPlot3D is a standalone library and does not depend on ImPlot. You only need Dear ImGui to get started.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Does ImPlot3D support 2D plots?</h4><a id="user-content-does-implot3d-support-2d-plots" aria-label="Permalink: Does ImPlot3D support 2D plots?" href="#does-implot3d-support-2d-plots"></a></p>
<p dir="auto">While you can rotate the 3D view to align with a 2D plane, ImPlot is far better suited for visualizing 2D data. ImPlot3D is specifically designed for 3D plotting and interaction, so we recommend using ImPlot for all your 2D visualization needs.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Can I customize the appearance of plots?</h4><a id="user-content-can-i-customize-the-appearance-of-plots" aria-label="Permalink: Can I customize the appearance of plots?" href="#can-i-customize-the-appearance-of-plots"></a></p>
<p dir="auto">Absolutely. ImPlot3D allows you to modify plot styles, including line colors, thickness, fill opacity, and marker sizes. You can also use colormaps for surfaces and customize axis labels, grid styles, and background colors.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Can I export 3D plots to an image?</h4><a id="user-content-can-i-export-3d-plots-to-an-image" aria-label="Permalink: Can I export 3D plots to an image?" href="#can-i-export-3d-plots-to-an-image"></a></p>
<p dir="auto">Not currently. You can use your OS's screen capturing tools to save a plot. ImPlot3D is designed for real-time visualization and interaction, not for creating publication-quality renders. For publication-quality output, consider exporting your data to a dedicated 3D rendering tool.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Is ImPlot3D suitable for publication-quality visuals?</h4><a id="user-content-is-implot3d-suitable-for-publication-quality-visuals" aria-label="Permalink: Is ImPlot3D suitable for publication-quality visuals?" href="#is-implot3d-suitable-for-publication-quality-visuals"></a></p>
<p dir="auto">ImPlot3D prioritizes interactivity and real-time performance. If you need high-quality visualizations, use ImPlot3D for initial exploration and then switch to tools like <a href="https://www.mathworks.com/products/matlab.html" rel="nofollow">MATLAB</a>, <a href="https://matplotlib.org/" rel="nofollow">matplotlib</a>, or <a href="https://www.paraview.org/" rel="nofollow">ParaView</a> for the final output.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the MIT License - check <a href="https://github.com/brenocq/implot3d/blob/main/LICENSE">LICENSE</a> for details.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lou's Pseudo 3D Page (2013) (119 pts)]]></title>
            <link>http://www.extentofthejam.com/pseudo/</link>
            <guid>42448184</guid>
            <pubDate>Wed, 18 Dec 2024 04:45:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.extentofthejam.com/pseudo/">http://www.extentofthejam.com/pseudo/</a>, See on <a href="https://news.ycombinator.com/item?id=42448184">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


<table><tbody><tr><td>
<img src="http://www.extentofthejam.com/pseudo/images/curves1.png"></td><td>
</td></tr></tbody></table>

<br><a href="http://www.extentofthejam.com/pseudo/espanol.html">Pseudo 3d en español aqui! Gracias a Luis Peña!</a>

<br>(C) 2013 Louis Gorenfeld, updated May 3, 2013<p>
<b>NEW:</b> Important details on the segmented road system and some additional links
<br><b>NEW:</b> An (optional) explanation of finding field-of-view for the 3d projection formula
<br><b>NEW:</b> An analysis of S.T.U.N. Runner
<br><b>NEW:</b> General writing improvements

</p><div><p>Previous update:</p><p>
An explanation of 3d projection mathematics (under Road Basics) and analysis of Activision's Enduro (under Case Studies)!
<br>Thanks to everyone for all the e-mail!  Keep it coming :)
Sorry, I can't answer questions about when I'll post source code, but I'm 
always happy to answer anything else about these engines!
<br>Official material on the Road Rash graphics engine and more detailed explanation of curves and a generalized curve equation
</p><p>
Is this information inaccurate?  Am I way off?  Don't hesitate to write me at louis.gorenfeld at gmail dot com!
</p></div><hr noshade="">
<h2>Table of Contents</h2>
<a href="#intro">
Introduction<br>
</a>
<a href="#basics">
Road Basics<br>
</a>
<a href="#curves">
Curves and Steering<br>
</a>
<a href="#sprites">
Sprites and Data<br>
</a>
<a href="#hills">
Hills<br>
</a>
<a href="#wrapup">Taking Raster Roads Farther<br></a>
<a href="#proj3d">True 3d-Projected Segments<br></a>
<a href="#enhancements">
Enhancements<br>
</a>
<a href="#related">
Related Effects<br>
</a>
<a href="#hw">
Case Studies<br>
</a>
<a href="#stuff">
Code Stuff<br>
</a>
<a href="#glossary">
Glossary<br>
</a>
<a href="#gallery">
The Gallery
</a>
<hr noshade="">

<a name="intro">

<h2>Introduction</h2>

</a><p><a name="intro"><u><b>Why Pseudo 3d?</b></u><br>
</a>
Now that every system can produce graphics consisting of a zillion polygons on the fly, why would you want to do a road the old way?  Aren't polygons the exact same thing, only better?  Well, no.  It's true that polygons lead to less distortion, but it is the warping in these old engines that give the surreal, exhillerating sense of speed found in many pre-polygon games.  Think of the view as being controlled by a camera.  As you take a curve in a game which uses one of these engines, it seems to look around the curve.  Then, as the road straightens, the view straightens.  As you go over a blind curve, the camera would seem to peer down over the ridge.  And, since these games do not use a traditional track format with perfect spatial relationships, it is possible to effortlessly create tracks large enough that the player can go at ridiculous speeds-- without worrying about an object appearing on the track faster than the player can possibly react since the physical reality of the game can easily be tailored to the gameplay style.
</p><p>But they have plenty of drawbacks as well.  The depth of physics found in more simulation-like games tends to be lost, and so these engines aren't suited to every purpose.  They are, however, easy to implement, run quickly, and are generally a lot of fun to play with!
</p><p>It is worth noting that not every older racing game used these techniques.  In fact, the method outlined here is only one possible way to do a pseudo 3d road.  Some used projected and scaled sprites, others seem to involve varying degrees of real projection for the road.  How you blend real mathematics with trickery is up to you.  
I hope you have as much fun exploring this special effect as I did.

</p><p><u><b>How Much Math Do I Need?</b></u><br>
If you...
<br>
...have Trigonometry knowledge, that's the most math you'll need for the entire tutorial<br>
...have just Algebra and Geometry, skip the field-of-view explanation<br>
...want to avoid as much math as possible, read: The Simplest Road, Curves and Steering, Sprites and Data, and Hills<br>
</p><p>This is a very flexible technique, and you can actually get by with just addition! With more advanced math, it can look better, but
with just arithmetic, you can get up to the level of detail seen in games like Pole Position or the first OutRun.

</p><p><u><b>How Much Programming Knowledge Do I Need?</b></u><br>
It helps a lot to understand raster graphics: Know what a scanline is, and that each line is made of a row of pixels. 
The programming examples are written in pseudocode, so you don't need experience in any specific language to understand them.
</p><p>
Ready? Let's begin!

</p><p><u><b>Raster Effects - Some Background</b></u><br>
A pseudo 3d road is just a variation of a more general class of effects called raster effects.  
One of the best-known examples of a raster effect is in Street Fighter II:  
As the fighters move left and right, the ground scrolls in perspective.  This actually isn't 3d.  Instead, the ground
graphic is stored as an extremely wide-angle perspective shot.  When the view scrolls, the lines of the screen which are supposed to be farther away scroll more slowly than the lines which
are closer.  That is, each line of the screen scrolls independently of each other.  
Shown below is both the end result and the ground graphic as it is stored in memory.
</p><center>
<img src="http://www.extentofthejam.com/pseudo/images/sf2.png">
<br>
<img src="http://www.extentofthejam.com/pseudo/images/sf2ground_rom.png">
</center>


<a name="basics">
<u>
<h2>Road Basics</h2></u>
</a>
<p><u><b>Introduction to Raster Roads</b></u><br>
We are used to thinking of 3d effects in terms of polygons whose vertices are
suspended in 3d space.  Older systems, however, were not powerful enough to
make a large number of 3d calculations.  Many older effects, in general,
fall into the category of raster effects.  These are special effects which
are done by changing some variable per line.  Most commonly, this means changing
the color or palette per line, or scrolling per line.  This is well-suited to
old graphics hardware which had acceleration for scrolling and used an indexed
color mode.
</p><p>
The pseudo raster road effect actually works similarly to the Street Fighter
II perspective effect in that it warps a static image to create the illusion
of 3d.  Here's how they do it:
</p><p>
Most raster roads start off with an image of a flat road.  This is essentially
a graphic of two parallel lines on the ground retreating into the distance.
As they get farther into the distance, the lines appear to the viewer to
be closer 
together.  This is a basic rule of perspective.  
Now, in order to give the illusion 
of motion, most arcade racing games have stripes on the road.
Moving these stripes on the road forwards is
generally either achieved by color cycling or by changing the palette every line.
Curves and steering are done by scrolling each line independently of one
another, just like in Street Fighter II.  
</p><p>
We will get into curves and steering
in the next chapter.  For now, let's put that aside and concentrate on 
making the road appear to scroll forwards.  

</p><p><u><b>The Simplest Road</b></u><br>
Take the image of a road described above:  Two parallel lines demarcating the left and right edges of the road
retreat into the distance.  As they move into the distance, they appear to the viewer to be closer together.
Below is what this might look like:<br>
<img src="http://www.extentofthejam.com/pseudo/images/nolines.png">
</p><p>
What is missing from this picture are road markings to give a good impression of distance.  Games use alternating light and dark strips, among other road markings, for this effect.  
To help accomplish this, let's define a "texture position" variable.  This variable starts at zero at the bottom of the screen and increases
each line going up the screen.  When this is below a certain amount, the road is drawn in one shade.  When it is above that amount, it is drawn in the other shade.  The position variable then wraps back to zero when it exceeds the maximum amount, causing a repeating pattern.  
</p><p>It is not enough to change this by a set amount each line though, because then you'll just see several strips of different colors which are not getting smaller as the road goes into the distance.  That means you need another variable which will change by a set amount, add it to another variable each line, and then add the last one to the texture position change.
</p><p>Here's an example which shows, from the bottom of the screen, what the Z value will be for each line as it 
recedes into the distance.  After the variables, I print what is added to get the values for the next line.  I've named the values DDZ (delta delta Z), DZ
(delta Z), and Z.  DDZ remains constant, DZ changes in a linear fashion, and Z's value curves.  You can think of Z as
representing the Z position, DZ as holding the velocity of the position, and DDZ as being the acceleration of
the position (the change in acceleration).
Note that the value I chose, four, is arbitrary and was just convinient for this example.
</p><p>
<code>
<span size="-1">
DDZ = 4   DZ = 0   Z = 0  : dz += 4, z += 4<br>
DDZ = 4   DZ = 4   Z = 4  : dz += 4, z += 8<br>
DDZ = 4   DZ = 8   Z = 12 : dz += 4, z += 12<br>
DDZ = 4   DZ = 12  Z = 24 : dz += 4, z += 16<br>
DDZ = 4   DZ = 16  Z = 40 : etc...<br>
</span>
</code>
</p><p>
Noice that DZ is modified first, and then that is used to modify Z.  To sum it up, say you are moving through the texture at speed 4.  That means that after line one, you are reading the texture at position 4.  The next line will be 12.  After that, 24.  So, this way it reads through the texture faster and faster.  This is why I like to refer to these variables as the texture position (where in the texture we are reading), the texture speed (how quickly we read through the texture), and the texture acceleration (how quickly the texture speed increases).
</p><p>A similar method will also be used to draw curves and hills without too much number crunching.  Now, 
to make the road appear to move, just change where the texture position starts at the bottom of the screen for each frame.
</p><p>Now, you may notice a shortcoming with this trick:  the zooming rate is inaccurate.  
This causes a distortion that I will refer to as the "oatmeal effect".  It is a warping effect present in early pseudo games such as OutRun in which objects, including the stripes on the road,
appear to slow down as they move outwards from the center of the screen.
</p><p>This method for finding the Z value has another disadvantage: It's not easily predictable what the value is in the very distance, especially
when hills are involved. We will learn a more advanced method which I will call the Z-map. This is a table that calculates what the Z distance is
for every scanline of the screen. But first, we need a little more math...

</p><p><u><b>A Mathematical Detour: 3d Perspective Projection</b></u><br>
There are ways to get rid of the oatmeal effect.  However, some traditional 3d mathematics are needed to make them possible.  What we need is a way of translating
3d coordinates so that they fit onto a 2d surface. 
</p><p><img src="http://www.extentofthejam.com/pseudo/images/project.png">
</p><p>In the picture above, an eyeball (lower left) is looking through the screen (the blue vertical line) at an object in our 3d world ("y_world").  The eyeball is
a distance "dist" from the screen, and a distance "z_world" from the object.  Now, one thing you might have noticed if you've spent some time with geometry or
trigonometry is that there are not one but two triangles in the picture.  The first triangle is the largest one, from the eyeball over to the ground on the right side
and up to the object we're looking at.  The second triangle I've colored yellow.  This is from the eyeball to where on the screen we'll see our object, down to the
ground, and back.  
</p><p>These two triangles' hypoteneuses (the line from the eye to the object) are at the same angle even though one is longer than the other.  They are essentially 
the same triangle, but the smaller one is just scaled down.  What this implies is that the ratio of the horizontal and vertical sides must be the same!  In math terms:
</p><p><code>y_screen/dist = y_world/z_world</code>
</p><p>What we need to do now is juggle the equation to get y_screen.  This gives us:
</p><p><code>y_screen = (y_world*dist)/z_world</code>
</p><p>In summary, to find the y coordinate of an object on the screen, we take the y world coordinate, multiply that by the distance we are to the screen, and then divide
it by the distance it is in the world.  Of course, if we just do that, the center of our view is going to be the upper-left corner of the screen!  Just plug in y_world=0 to
see this.  What we can do to center it is add half of our screen resolution to the result to put it right in the middle.  The equation can also be simplified a little bit
by pretending that our noses are right up to the screen.  In this case, dist=1.  The final equation then is:
</p><p><code>y_screen = (y_world/z_world) + (y_resolution/2)</code>
</p><p>There is a relationship between the ratios and the viewing angle, as well as scaling the image so that it is resolution-neutral, but we won't really need any of that to fix our road problem.  
If you are curious, try looking at the diagram from the top view:  the angle to the edge of the screen is the field of view and the same relationships hold!

</p><p><u><b>More Math: Adding Field-of-View to 3d Projection</b></u><br>
Now, this is <b>largely unnecessary</b> for most road engine cases. But, it's useful for making projection parameters
resolution-independent, or for objects that need to rotate or for integration with true 3d effects.
</p><p>Let's go back to the original projection formula. The "dist" from the explanation above will now be called "scaling":
</p><p><code>y_screen = (y_world*scaling)/z_world + (y_resolution/2)</code>
</p><p>The idea is that we need to scale all the points on the screen by some value which lets points within a certain
field-of-view (FOV) remain visible. You'll need a constant for the x FOV and a constant for the y FOV.
</p><p>As an example, let's assume we're working in 640x480 resolution and we want a FOV of 60 degrees. We've seen a diagram of
3d projection from the side view. For this, let's look at this
top view of the projection space instead:<br>
<img src="http://www.extentofthejam.com/pseudo/images/TopView.png"><br>
One way to think about the problem is that if an object is at the right edge of our FOV, it needs to appear on the screen
at x=640 (since we're at 640x480). Looking at the chart, our FOV can be split into two right triangles where the angle
of each is fov_angle/2 (a/2). And since our FOV is a cone, an object is on the right edge of its FOV if its x=R*sin(a/2) and
z=R*cos(a/2), where R is any radius value we want. We might as well make R=1. And we need the object to appear at
x_screen=640.
That gives us this (starting from the basic projection formula):
</p><p><code>
	x_screen=640 &nbsp; fov_angle=60 &nbsp; y_world=sin(60/2) &nbsp;  z_world=(60/2) &nbsp;  x_resolution/2=320 &nbsp;  scaling=?<p>
	
x_screen = (y_world*scaling)/z_world + (x_resolution/2)<br>
640 = (sin(30)*scaling/cos(30)) + 320<br>
320 = tan(30)*scaling<br>
320/tan(30) = scaling</p><p>
In generic terms: scaling = (x_resolution/2) / tan(fov_angle/2)
</p></code>
</p><p>
We've replaced a/2 by 30 (half of 60 degrees), recognized that sin/cos = tan, and voila! We should be able to test this
by placing an object at the right edge of the field-of-view, plugging these values into the original projection equation,
and ensuring that the X value winds up as 640. For example, an (x, z) point at (20, 34.64) will wind up at X=640 because 20 is
40*sin(30) and 34.64 is 40*cos(30).
</p><p>
Note that you'll have different FOV values for horizontal (x) and vertical (y) for a standard or widescreen monitor that's in
horizontal orientation.

</p><p><u><b>A More Accurate Road - Using a Z Map</b></u><br>
What we want to do to fix our perspective problem is to precompute a list of distances for each line of the screen.  In short, the problem is how to describe a flat plane in 3d. 
To understand how this works, first think of the 2d equivalent: a line!  To describe a horizontal line in 2d, you would say that for every (x, y) coordinate the y is the same. 
If we extend this into 3d, it becomes a plane: for every x and z distance, the y is the same!  When it comes to a flat horizontal surface, it doesn't matter how far from the camera it is, the
y is always the same.  Likewise, it doesn't matter how much to the left or right the point is, the y will still be the same.

Back to figuring out the distance of each line of the screen:  let's call this a Z Map.  Calculating the Z Map is just a matter of rearranging the 3d 
projection formula to find a Z value for each screen Y!
</p><p>
First, take the equation from the last section:
</p><p>
<code>
Y_screen = (Y_world / Z) + (y_resolution / 2)
</code>
</p><p>
Now, since we're given Y_screen (each line), juggle the equation so that we're finding the Z:
</p><p>
<code>Z = Y_world / (Y_screen - (height_screen / 2))</code>
</p><p>
Y_world is basically the difference between the ground and the camera height, which is going to be negative.  This is the same for each line because, as described in the introductory paragraph,
we're interested in a flat road for the time-being.  
In addition to looking much more accurate and avoiding the "oatmeal effect", it has the advantage that it is easy to compute what the maximum draw distance is.  
</p><p>The road is mapped onto the screen by reading through this buffer:  For each distance, you must figure out what part of the road texture belongs there by noting how many units each stripe or pixel of the texture take up.  
</p><div><p> 
Though we now know the distance of each row of the screen, it may also be useful to cache either the width of the road or scale factor for each line.  The scaling factor would just be the
inverse of the distance, adjusted so that the value is 1 on the line which the player's car graphic spends the most time.  This can then be used to scale sprites which are on a given line, or to
find what the width of the road is.  
</p><a name="curves">
<u>
</u></a></div><h2><a name="curves"><u>Curves and Steering</u></a></h2><a name="curves">
</a>

<p><u><b>Making it Curve</b></u><br>
To curve a road, you just need to change the position of the center-line in a curve shape.  There are a couple ways to do this.  
One way is to do it the way the Z positions were done in "The Simplest Road": with three variables.  That is, starting at the bottom of the screen, the amount that the center of the road shifts left or right per line steadily increases.  Like with the texture reads, we can refer to these variables as the center line (curve) position, the curve velocity, and the curve acceleration.
</p><p>There are some problems with this method though.  One is that S-curves are not very convinient.  Another limitation that going into a turn looks the same as coming out of a turn: The road bends, and simply unbends. <br>
</p><p>To improve the situation, we'll introduce the idea of road segments.  A road segment is a partition which is invisible to the player.
Think of it as an invisible horizontal divide which sets the curve of the road above that line.  At any given time, one of these segment dividers is at the bottom of the screen and another is travelling down at a steady rate towards the bottom of the screen.  Let's call the one at the bottom the base segment, because it sets the initial curve of the road.  Here's how it works:
</p><p>
When we start drawing the road, the first thing we do is look at the base point and set the parameters for drawing accordingly. 
As a turn approaches, the segment line for that would start in the distance and come towards the player kind of like any other road object, except it needs to drift down the screen at a steady rate. That is, for a specific speed that the player is traveling, the segment divider travels down the
screen at so many lines per frame. Or, if you're using a Z-Map, so many z-map entries per frame. If the segment were to 'accelerate' at the player
the way 3d objects on the track do, the road would swing too wildly.
</p><p>
Let's see how this works. Suppose the segment line for a left curve is halfway down the road and the base segment is just a straight road.  As the road is drawn, it doesn't even start curving until it hits the "left curve" segment.  Then the curve of the road begins to change at the rate specified by that point.  As the moving segment hits the bottom of the screen, it becomes the new base segment and what was previously the base segment goes to the top of the road.

</p><p>Shown below are two roads:  One is a straightaway followed by a left turn, and one is a left turn followed by a straightaway.  In both these cases, the segment position is halfway down the
Z Map (or, halfway down the screen).  In other words, the road begins to curve or straighten halfway down the road, and the camera is entering the turn in the first picture and leaving the turn in the second.

</p><p><img src="http://www.extentofthejam.com/pseudo/images/straight-then-left.png"> <img src="http://www.extentofthejam.com/pseudo/images/left-then-straight.png"> 

</p><p>And this is the same technique and same segment position applied to an S-curve:<br>
<img src="http://www.extentofthejam.com/pseudo/images/left-then-right.png">

</p><p>The best way to keep track of the segment position is in terms of where on the Z Map it is.  That is, instead of tying the 
segment position to a screen y position, tie it to a position in the Z Map.  This way, it will still start at the road's
horizon, but will more gracefully be able to handle hills.  Note that on a flat road that the two methods of tracking
the segment position are equivalent.

<!-- One possibility is that Final Lap does its complex track visuals by using more than two segments. -->
</p><p>Let's illustrate this with some code:
</p><p><code>
<span size="-1">
current_x = 160  // Half of a 320 width screen<br>
dx = 0 // Curve amount, constant per segment<br>
ddx = 0 // Curve amount, changes per line<p>
for each line of the screen from the bottom to the top:<br>
&nbsp;&nbsp;if line of screen's Z Map position is below segment.position:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dx = bottom_segment.dx<br>
&nbsp;&nbsp;else if line of screen's Z Map position is above segment.position:<br>
&nbsp;&nbsp;&nbsp;&nbsp;dx = segment.dx<br>
&nbsp;&nbsp;end if<br>
&nbsp;&nbsp;ddx += dx<br>
&nbsp;&nbsp;current_x += ddx<br>
&nbsp;&nbsp;this_line.x = current_x<br>
end for</p><p>
// Move segments<br>
segment_y += constant * speed // Constant makes sure the segment doesn't move too fast<br>
if segment.position &lt; 0 // 0 is nearest<br>
&nbsp;&nbsp;bottom_segment = segment<br>
&nbsp;&nbsp;segment.position = zmap.length - 1 // Send segment position to farthest distance<br>
&nbsp;&nbsp;segment.dx = GetNextDxFromTrack() // Fetch next curve amount from track data<br>
end if</p></span>
</code>

</p><p>One big advantage of doing the curves this way is that if you have a curve followed by a straightaway, you can see the straightaway as you come
out of the curve.  Likewise, if you have a curve followed by a curve in the opposite direction (or even a steeper curve the same direction), you can
see that next piece of track coming around the bend before you hit it.

</p><p>To complete the illusion, you need to have a horizon graphic.  As the curve approaches, the horizon doesn't change (or scrolls only slightly).  Then when the curve is completely drawn, it is assumed that the car is going around it, and the horizon scrolls quickly in the opposite direction that the curve is pointing.  As the curve straightens out again, the background continues to scroll until the curve is complete.  If you are using segments, you can just scroll the horizon according to the settings on the base segment.

</p><p><u><b>General Curve Formula</b></u><br>
There is one interesting observation we can make about the curve technique detailed in the section "The Simplest
Road".  This observation is more mathematical than the above-material, and can be safely skipped as long as your
graphics engine either does not have to be resolution-independent or is using the "3d projected segments" technique
discussed in the chapter on hills.
</p><p>Looking at the curve example using "Z" from the section "The Simplest Road", we can see that the z-position (or x-position) at a given line is the sum of an increasing series of numbers (e.g. 1 + 2 + 3 + 4).  This is
what's called an arithmetic series, or an arithmetic progression.  Instead of 1 + 2 + 3 + 4, a sharper curve can be produced by adding 2 + 4 + 6 + 8, or 2*1 + 2*2 + 2*3 + 2*4.  The "2" in this case is the 
variable segment.dx from above.  It can also be factored out to get 2(1 + 2 + 3 + 4)!  Now all that has to be done is to find a formula to describe 1 + 2 + ... + N, where N is the number of lines making up the curve.
It turns out that the sum of an arithmetic series is equal to N(N+1)/2.  So, the formula can be written as s = A * [ N(N+1)/2 ] where A is the sharpness of the curve and s is the sum.  This can be further modified
to add a starting point, for instance, the center of the road at the bottom of the screen.  If we call this 'x', we now have s = x + A * [ N(N+1)/2 ].
</p><p>We now have a formula to describe our curve.  The question that we want to ask it is, "given a starting point x and N lines of the curve, what should A be to make the curve reach x-position 's' by the end?"  Juggling
the equation to solve for A gets us A = 2(s - x)/[n(n+1)].  This means that the sharpness of a given curve may be 
stored in terms of the endpoint's X position, making the graphics engine resolution-independent.

</p><div><u><b>Perspective-style Steering</b></u><p>
It's much less interesting looking to have a game in which when you
steer, it only moves the car sprite.  So, instead of moving the player's car sprite, you keep it in the center of the screen and move the road-- more importantly, you move the position of the center-line at the front (bottom) of the screen.  Now, you want to assume that the player is going to be looking at the road always, so make the road end at the center of the screen.  You'll need an angle-of-road variable for this.  So, calculate the difference between the center of the screen and the position of the front of the road, and divide by
the height of the road's graphic.  That will give you the amount to
move the center of the road each line.

</p><a name="sprites">
<u>
</u></a></div><h2><a name="sprites"><u>Sprites and Data</u></a></h2><a name="sprites">
</a>

<p><u><b>Placing Objects and Scaling</b></u><br>
Sprites should be drawn back-to-front.  This is sometimes referred to as the Painter's Algorithm.  To do this, you'll have to note in advance where on the screen each object should be drawn, and then draw them in a different step.
The way I do this is as follows:  As I go through the Z Map while drawing the road, I like to also note at that time which line of the screen each sprite
will be associated with.  If you've kept your sprites sorted by Z, this is trivial:  Each time a new Z Map value is read,
check to see whether the next sprite's Z position is closer to the camera than the current Z Map value, or whether it's
equal.  If so, note that sprite's screen Y position as belonging to the current line.  Then check the next sprite the
same way.  Keep doing this until you take a sprite off the list which has a farther Z position than the current one.
</p><p>The X position of the object should be kept track of relative to the center of the road.  The easiest way then to position
the sprite horizontally is just to multiply it by the scaling factor for the current line (inverse of Z) and add that to the road's center.

</p><p><b><u>Storing Track Data</u></b><br>
When I did my first road demo, I stored the level information as a list of events which would happen at specified distances.  The distances are, of course, in terms of texture position units.  The events would consist of commands to begin and stop curves.  Now, as far as I can tell, the speed at which the road starts and stops curving is arbitrary.  The only rule seems to be that it must correlate to the speed of the player vehicle.
</p><p>If, however, you are using a segmented system, you can just use a list of commands.  The distance that each command takes is equivalent to how
quickly the invisible segment line drifts down the screen.  This also frees you up to create a track format which works on a tile map, for representing
somewhat realistic track geography.  That is, each tile could be one segment.  A sharp turn could turn the track 90 degrees, while a more mild turn
would come out at 45 degrees.

</p><p><b><u>Texturing the Road</u></b><br>
Now, you probably would like a real graphical texture on your road
instead of the alternating lines and such that you have at the moment.
There are a couple ways to do this.  A cheap and easy way to do it is this:  You have a couple of textures for the road (for the alternating line effect).
When each horizontal line of the road is drawn, you stretch the texture to fit the width of that line.  Or, if you can't stretch, pick a line out of one of two complete road
bitmaps (ala Outrunners).
</p><p>
If you want the road to look more accurate, make the Z for each line correspond to a row number on a texture graphic.  Voila!  One textured road!
</p><div><p>However, if you only want strips of alternating color, the answer is even simpler-- especially when using fixed point.  For each Z, make one of the bits
represent the shade of the road (dark or light). Then, just draw the appropriate road pattern or colors for that bit.
</p><a name="hills">
<u>
</u></a></div><h2><a name="hills"><u>Hills</u></a></h2><a name="hills">
</a>

<p>
<u><b>Varieties of Hills</b></u><br>
It seems there are a near-infinite number of ways to produce hill effects.  Hill effects have a wide range of geometric accuracy, with some of the
less accurate techniques being more convincing than others.  Here we will examine two possible methods.

</p><p>
<u><b>Faked Hills</b></u>
<br>After much experimentation, I've come up with a flexible method for faking hills which uses little in the way of
calculations.  Additionally, it accurately tracks objects which are beneath the horizon.  It is a scaling
and warping effect which vertically stretches and compresses the road.   It uses the same addition trick
used to draw the curves to generate the curvature of the hill.
</p><p>
Here's how it's done:  First of all, the drawing loop would start at the beginning of the Z Map (nearest) and stop when it gets to the end
(farthest).  If we are to decrement the drawing position each line by 1, the road will be drawn flat.  However, if we decrement
the drawing position each line by 2, doubling lines as we go, the road will be drawn twice as high.  Finally, by varying the
amount we decrement the drawing position each line, we can draw a hill which starts flat and curves upwards.  If the next drawing
position is more than one line from the current drawing position, the current Z Map line is repeated until we get there,
producing a scaling effect. 
</p><p>Downhills are similar:  If the drawing position is incremented instead of decremented, it will move beneath the last line
drawn.  Of course, lines which are below the horizon will not be visible on-screen-- only lines which are 1 or more pixels
above the last line should be drawn.  However, we'll still want to keep track of objects which are beneath the horizon.  To
do this, note the screen Y position of each sprite as the Z Map is traversed. 
It may help to make the Z Map larger
than needed for a flat road.  This way, as the buffer stretches, it won't become too pixellated.

</p><p>Now, we have to move the horizon to convince the player.  I like to 
use a Lotus-style background in which the horizon doesn't just consist 
of just a skyline, but also a distant ground graphic.  When the hill curves
upwards (elongating the view), the horizon should move downwards slightly relative to
the top of the road.  When the hill curves downwards as the camera crests
the hill (shortening the view), the horizon should move upwards.
</p><p>
This is what the effect looks like for a downhill and an uphill-- minus the horizon graphic of course:</p><p>
<img src="http://www.extentofthejam.com/pseudo/images/downhill1.png">
<img src="http://www.extentofthejam.com/pseudo/images/uphill1.png">
</p><p>
<b>Pros</b>
</p><ul>
<li>Inexpensive in terms of calculations: No multiplies or divides necessary
</li><li>Objects on the back side of the hill are tracked
</li><li>The view's angle appears to follow the player over hills
</li></ul>
<b>Cons</b>
<ul>
<li>Accurate 3d geometry is impossible
</li><li>Tweaking is required to create a convincing effect
</li></ul>

<h2><a name="wrapup"><u>Wrap-up: Taking Raster Roads Farther</u></a></h2>
These accumulation-style curve formulas can be used verbatim if you don't need crazy curves or huge, rolling hills. Many games which use these
kinds of tricks scroll the road so fast that even a slight curve can be convincing.
<p>However, you may want to exaggerate
the effect in order to get a more dramatic road. One thing that can be done with any of these curve formulas
is to use high ddx or ddy values, but not allow dx or dy to exceed a sane value. And a user on YouTube, Foppygames,
has discovered another trick for getting more severe curves out of these accumulation formulas: multiply the dx or dy value by the 
z value for each line! This makes the curve more severe in the distance than it is in the foreground, and it creates 
a <a href="http://www.youtube.com/watch?v=mL5yJ5K13po">pretty convincing effect</a>.
</p><p>And, the experimentation doesn't stop there. In fact, the best thing about these engines is that there's no "right" way of doing it. Anything
that creates curves and warpage which is pleasing to the eye is allowed! In my earliest road engines, I used a sinewave lookup table to bend the
road.
</p><p>You can also use multiplication: To shift the road right, you might multiply the x position by, for example, 1.01 each line.
To move it left the same amount, you'd multiply it by 0.99, or 1/1.01 (reciprocal of 1.01). However, armed with the knowledge
that many old processors did not have multiplication or were slow at it, I settled upon using
the accumulation technique because it only uses addition. It seemed the most likley "authentic" way of curving the road.
</p><p>
Some games, like OutRun, even use a simple spline system-- at least judging by the great reverse-engineered open-source C++ port,
<a href="http://reassembler.blogspot.com/p/cannonball-open-source-outrun-engine.html">Cannonball</a>.
</p><p>So, play around and experiment, and see what technique you like best!
</p><div><p>...or, read on for a description of a clever trick that mixes 3d polygons, is nearly as fast, is even more convincing, 
and can be displayed with the same oldschool raster hardware. Intrigued?




</p></div><h2><a name="proj3d"><u>True 3d-Projected Segments</u></a></h2>
<p>
<b><u>3d-Projected Segments vs. Raster Roads</u></b><br>
As nice as raster roads are, they can be made even more impressive by involving a simple form of polygon rendering. This form of rendering
can actually be pulled off using the same limited raster hardware. However, it involves more calculations.
</p><p>
This trick is known to have been used in games such as <b>Road Rash</b> and <b>Test Drive II: The Duel</b>. Here's what it is: The track is
made of polygonal segments. However, rather than moving in full 3d space, it still only moves towards the camera. For curves, the road still
just skews left and right in almost an identical way to the raster road: There is no actual rotation when going around
curves as there would be in a full polygonal engine.
</p><p>Here's a rundown:
</p><ul>
<li>Since we are still faking curves and road angles, that means expensive rotation calculations still won't be needed
</li><li>The road is essentially a strip of quads: each section of the road is attached to the next section.  This means
we can calculate whether part of the road is visible or not based solely on its screen Y position relative to its previous neighbor.
</li><li>The relationship of these quads to one another will never change.  That is, the angle never actually changes, so
the quads are always and automatically sorted by Z.
</li></ul>

<p>
<b><u>The Basic 3d Road</u></b><br>
First, break the road into polygonal quads. Each of these will be called a segment. Just like a segment in a purely raster
road, each segment here still has a curve amount (ddx), and either a hill amount (ddy) or a y-position that determines how high
up it is. Of course, these can also have other attributes as well such as terrain changes.
</p><p>
Pictured below is a segmented road made of very few polygons so we can easily see the boundaries between the segments and how
it affects the curvature of the road:<br>
<img src="http://www.extentofthejam.com/pseudo/images/SegmentedRoad.png">
</p><p>
When rendering, first find the screen y location of each 3d segment by using the screen_y = world_y/z formula.  Or, if division
is too slow,
you could find the height off the ground of a given segment by multiplying the segment's height by the scaling factor for that
line. That could then be subtracted that from a reverse z-map (this map would be: for every z position of a flat road, what is the 
y?) to find
the final position on screen.
</p><p>
Then, you would
linearly interpolate the road widths and texture (if desired) between these heights.  Deciding which 3d segments to draw and which not to can be
determined easily:  From the front of the screen back, a 3d segment whose screen_y is projected as lower than the last-drawn 3d segment would not be shown (however, its sprites may still be visible because they stick up-- keep that in mind).
</p><p>
<u><b>Scrolling the Road</b></u><br>
Now, we also need to learn how to scroll these segments. Move the entire mess of polygons which make up the road towards the camera. As the frontmost segment's polygon passes through the camera, move the entire road back to its starting point so that it loops. 
This is akin to how a scolling 2d tilefield can be made by scrolling up to one tile-worth, and when that is hit all the tiles are
shifted over and new tilemap data is pulled in. In this, we scroll up to one segment-worth, and when that is hit, we move the road
back and pull in new road data.
</p><p>
But there is one last very important detail: Let's say the road is a sharp curve. You might have noticed that as
you go around this polygonal curve that it jitters as you cross the segment boundary and the road is subsequently reset. One obvious thing that is happening to cause this is that
as you traverse a skewed segment, the camera's center relative to the road changes. That is, by the time you get to the end of that segment, the road is no longer centered.
It's as if you're driving on the road at an angle. 
You might be tempted to fix it by moving the road to center it just as objects' x-positions are linearly interpolated.
</p><p>However, this is <b>wrong</b> and does not completely solve our problem: If the road were skewed in a straight line, this would be fine. The problem is that our road curves, so the polygons in the distance still are not lined up! Another way to think about it is this: We are approximating a curve using polygonal segments. We want the shape of the curve to be 
more or less constant even as it scrolls.
</p><p>Jake over at <a href="http://www.codeincomplete.com/">codeincomplete.com</a> has a <a href="http://codeincomplete.com/posts/2012/6/24/javascript_racer_v2_curves/">great solution</a> for this. Instead of changing the x position as the road as you move across the segment, what about changing the
initial dx value from 0 to something that keeps the road in line as you move through the segment? The formula used is this:
</p><p>
<code>
	dx = -percentage_of_segment_traversed * ddx</code>
</p><p>The percentage of the segment has to go from 0 to 1.0 and back as the camera crosses the segments.
</p><p>In mathematical terms, doing this makes the X of the road a function of its Z. In other terms, we're keeping the curve the same shape regardless of how the points which
approximate it scroll. The frontmost segment is "pulled into position" with the rest of the road, which then means that the subsequent
segments' X position are placed correctly. You can see this clearly if you test it with a road made of few polygons. It solves the following problems as the segment is traversed (assuming the curve's shape
does not change):
</p><ul><li>It keeps the center of the road (x position) constant
</li><li>It adjusts dx so that the next segment starts at an appropriate x-location regardless of the scroll position of the road
</li></ul>
<p>This video demonstrates the technique. I've used very few segments and a very sharp curve to demonstrate how this looks. Notice
that as the polygons move towards the player that they carve out a perfect curve shape. This is most apparent if you watch the
right side of the road.
</p><p>
<iframe width="420" height="236" src="http://www.youtube.com/embed/E1PEOg50Zn4?rel=0" frameborder="0" allowfullscreen=""></iframe>


</p><p>
<u><b>Placing Sprites</b></u><br>
The sprites on that 3d segment would still need to be shown and properly cropped, however-- assuming you're making a custom
renderer and not using a Z-buffer.  We can actually draw the sprites as the last step:  If a sprite is on a segment which is completely visible, 
it does not need to be cropped since it sticks straight up from the ground, which is our only polygon.
</p><p>But if a sprite
is on a segment which is either not visible or partially visible, we can easily crop it.  First, find the
top of the sprite.  Then, every line of the sprite will be drawn until it hits the last visible segment's screen Y position.
That is, if there is a segment behind the sprite which is supposed to cover part of it,  you stop drawing the sprite when you hit 
that line. And if the top of the sprite is below the last segment's Y position, the sprite 
won't be visible at all and will be skipped.

</p><p>
<u><b>Variations and Rendering Technologies</b></u><br>
Now, since we're throwing around the term <i>polygon</i>, you may be tempted to think that you need polygonal rendering routines
to pull this off. Using technologies like OpenGL or a simple trapezoidal drawing routine definitely do work. But even tile and
sprite-based 2d hardware are perfectly capable of pulling this off. 
</p><p>
Observe that each road segment's beginning and end are perfectly horizontal. This means that they always start and end on a specific
scanline. Much the way the purely pseudo-3d road is rendered on tile hardware by scrolling the flat road graphic as it's being
drawn, we can do exactly the same with these 3d segments. For further reading, check out the section called <u>Dedicated
	Road Hardware</u>. Though it discusses arcade hardware designed from scratch to draw road effects, the same technique
can be achieved with basic 2d sprite-tile systems through scrolling the road graphic vertically as well as horizontally.

</p><p>
<u><b>Further Reading on 3d-Projected Segments</b></u><br>
Since my mock-up of this specific variation is underdeveloped, I will point you to <a href="http://codeincomplete.com/posts/2012/6/23/javascript_racer_v1_straight/">Code inComplete's amazing tutorial</a> if you're interested in further details on this technique.
</p><p>
<b>Pros</b>
</p><ul>
<li>Real 3d geometry can be used for the hills, adding greatly to the amount of detail possible
</li><li>The system is more consistent: Terrain and road width changes don't need to be done using a separate technique
</li></ul>
<b>Cons</b>
<ul>
	<li>There are more calculations involved
	</li><li>A decent number of segments must be used or the road will look jagged and polygonal
</li></ul>


<h2><u>Enhancements</u></h2>
<p><u><b>Multiple Roads</b></u><br>
Most arcade racing games handle multiple roads at a time.  Though the most obvious reason to do this is to have more than one road on the screen at a time,
other effects can be achieved as well.  For example, OutRun uses more than one road to form its six lane freeway.  This lets the game widen and narrow
the road easily, as well as convincingly fork.  They do this by overlapping the two roads and giving one drawing priority over the other.  Here is the
familiar beginning of OutRun both with and without two roads (look to the right of the bushes):
</p><p><img src="http://www.extentofthejam.com/pseudo/images/or-road1.png"> <img src="http://www.extentofthejam.com/pseudo/images/or-noroad1.png">
</p><p>And, even more dramatic, below is the freeway after the two roads are overlapped to form six lanes, both with and without the second road:
</p><p><a name="enhancements"><img src="http://www.extentofthejam.com/pseudo/images/or-road2.png"> <img src="http://www.extentofthejam.com/pseudo/images/or-noroad2.png">

</a><a name="related">
<u>
</u></a></p><h2><a name="related"><u>Related Effects</u></a></h2><a name="related">
<p><u><b>Endless Checkerboard</b></u><br>
The endless checkerboard in the arcade game Space Harrier is just a variation on the road technique.  Like
a road, the game contains graphics of lines coming at the player in perspective.  In fact, Space Harrier
uses the same hardware as Hang-On.
</p><p>
 Pictured below is the Space Harrier checkerboard effect with and without the palette changes.  To turn this
into a checkerboard, all that has to be done is to flip the color palette every few lines.  Think of it as analogous to the 
light and dark strips on a road.
</p><p>
<img src="http://www.extentofthejam.com/pseudo/images/sh-pal.png"> <img src="http://www.extentofthejam.com/pseudo/images/sh-nopal.png"><br>
 
</p></a><p><a name="related">
So, how then does it scroll left and right?  This is just a variation on perspective-style steering:  As the
player moves to the left or right, the ground graphic is skewed.  After a few pixels have scrolled past, the ground
"resets" or "wraps" its position.  This is how it appears to scroll endlessly to the left and right.
</a><a name="hw">
<u>
</u></a></p><h2><a name="hw"><u>Case Studies</u></a></h2><a name="hw">
<p>
<u><b>Dedicated Road Hardware</b></u><br>
Although there are many ways to render roads, it is interesting to note that many arcade games used hardware designed for this specific purpose.
These chips automate the basics of road drawing, but not the road calculations themselves.  As a typical example, I will take Sega's OutRun road
chip, used in games such as Super Hang-on, Outrun and Space Harrier.
</p><p>First off, the chip has its own graphics memory.  What is stored in this road ROM is nearly a perspective view of the road, given that it is flat,
centered, and not curving.
Then, for each line of the screen, the programmer specifies roughly which line of the perspective graphic to draw there.
Each line also has an X offset (for curving the road) and each line can also have a different color palette (to draw road markings and simulate movement). 
To show an example, here are some images taken from Sega racing game road graphics side-by-side with the road as seen in-game 
(special thanks to Charles MacDonald for his road viewing application):

</p><p>The first thing you might notice is that the road graphics are much higher resolution than the in-game graphics.  In these particular
games, the road is up to 512x256 resolution while the game's display resolution is only 320x224.  This gives the graphics engine plenty
of graphic to play with, which cuts down on the amount of jaggies.  Another thing which might pop out at you is that the perspective of
the road stored in the ROM is completely different from the perspective shown in-game.  This is because the graphic in the ROM merely
stores what the road might look like for various road widths.  It is the job of the program to select the correct lines out of this
large graphic for each line of the screen.
</p><p>The hardware supports two
roads at a time, and so you can assign priority to the left or right road.  This is for the parts of the game in which the road branches,
or when there is a center divider between lanes of traffic.
</p><p>For you ROM hackers out there, check out MAME's src/mame/video/segaic16.c and src/mame/video/taitoic.c files for examples of road chips.
Note that the Sega road graphics are stored in a 2-bit planar format, with the center of the graphic able to sport a fourth color (this
is the yellow line shown in the graphics above).  
<!-- <P>I mentioned that only the drawing is taken care of by the road chip, but not the technique.  A dramatic illustration of this is the difference
between Chase H.Q. and Top Speed.  Both of these games run on the same hardware with the same road chip, but Chase H.Q. is much more convincing.
Top Speed's hills for example look to be less accurate, and there are sprite clipping issues at times.  Also see MAME's src/mame/video/taitoic.c file
for a more detailed explanation of this specific road chip. -->



</p><p>
<u><b>Enduro</b></u><br>
Enduro is a remarkable game.  Released in 1983 for an incredibly
underpowered 70's gaming console, Enduro still manages to produce a
convincing road effect complete with changing weather and day-night
cycles.  On top of that, it manages to be an exciting game even 
25 years after its release!

</p><p>
<img src="http://www.extentofthejam.com/pseudo/images/enduro-2.png" width="50%"><br>Screenshot of Enduro
</p><p>As you can see here, Enduro looks a little different from other
road engines we've seen so far.  Immediately apparant is that the
road is only drawn in outline:  The terrain to the sides of the road are not drawn
in a different color from the pavement.  There are also no roadside obstacles.  
Once you start to play Enduro, you might also notice that the road doesn't move in
perspective.  Instead, the player car sprite and road both shift left and right 
to give the illusion of steering.

</p><p>In order to better understand why Enduro looks the way it does, 
let's take a peek at the Atari 2600's limitations.  The Atari 2600 was designed
primarily to play Combat-like games (tank games) and Pong-like games.  So,
it was capable of displaying: two sprites, two squares representing missiles 
for each player, a square representing a ball, and a very blocky background.  And that's it.  

</p><p>But what's notable about the Atari's video hardware is that it's essentially
one-dimensional:  the software must update the graphics for each scanline itself.  For
example, to show a sprite, the programmer has to upload a new line of
graphics to display at the beginning of each scanline.  To draw the ball
object, the programmer would turn on the ball when the TV's beam got to the right
line, and turn off the ball when the beam got to a line where the ball should 
no longer be visible.

</p><p>This leaves an important side-effect:  a solid vertical line can be drawn down the screen by turning on
the ball or missiles and then never turning them off!  If the programmer moves
these objects each line, diagonal lines may be drawn.  

</p><p>Now, back to the task at hand.  We could draw the road using the background
blocks, but the resolution is much too low to be effective.  What Atari driving
games did instead was use the two missile or ball graphic objects to draw the left
and right sides of the road, much in the same way they can be used to draw
lines.  Enduro in particular uses the first player's missile sprite and the
ball sprite in order to draw the left and right sides.  Pole Position, on the other hand, uses
both missile sprites for the sides of the road and then uses the ball sprite
to draw a dotted line down the center.

</p><p><br>
<img src="http://www.extentofthejam.com/pseudo/images/polepsn.png" width="50%">
<br>Screenshot of Pole Position on 2600 for comparison

</p><p>One thing I haven't discussed is how you move objects per-line on an Atari 2600.  The
Atari's graphic chip has a facility called HMOVE (horizontal move).  This allows the
programmer to set up moves each line for all the different objects very easily.  All the
programmer has to do is set how many pixels to move for the various objects, and then call
HMOVE and voila-- they all move according to what was set!

</p><p>Enduro exploits this in order to draw curves.  In short, what Enduro does create a
table in memory of how the HMOVE values of the left and right sides vary as the screen
is drawn.  This uses almost half of the Atari 2600's available memory.  Since the Atari's
memory is so tiny, this value is only read every 4 lines.  There is a different table for
the left and the right sides of the road. 

</p><p>When the road is straight, the array for the right side of the road is all 8's.  The
HMOVE only uses the upper 4 bits, so 8 loaded into HMOVE wouldn't move the sides
of the road at all.  The lower 4 bits are used for a crude form
of fixed point.

</p><p>As an example, here's what a curve looks like in memory as it approaches (the
horizon is the end of the array):<br>
<code><span size="-1">
08,08,08,08,08,08,0a,0a,0b,0c,0e,0d,0e,0e,0f,10,13,11,12,13,14,17,16,17
</span></code>

</p><p>And the next frame:<br>
<code><span size="-1">
08,08,09,09,0a,0a,0b,0b,0c,0d,0d,0e,0f,0f,10,11,12,12,13,14,15,16,17,18
</span></code>

</p><p>Note that the higher curve values progressively write over the lower values, shifting
down towards the front of the screen to provide the illusion that the curve is coming towards
the player.  And what does
Enduro do with this data?  Here's some of the code used to write out the curve for the
right side of the road
</p><p>
For each scanline of the road:<br>
<code><span size="-1">
LDA $be      ; Load what's in address $be<br>
AND #$0f     ; Blow away the upper 4 bits (the bits HMOVE uses)<br>
ADC $e4,x    ; Add the value from the curve table (X is how far towards the front of the screen we are)<br>
STA $be      ; Save the value again (so we can load it again next scanline like we did above)<br>
STA HMBL     ; Also shove it into the Horizontal Motion - Ball register<br></span>
</code>

</p><p>
So what's this doing?  Well, $be is a counter for the curve amount which increments.  When it's loaded, the upper 4 bits are tossed
overboard, leaving a range of 0 to 16 ($0-F).  Then, the curve table entry for that particular scanline is loaded and added in.
Finally, it's stored back to the counter and also loaded into the horizontal move register for the ball object (the right side of the road).

</p><p>
This does a few things.  First, it only results in the sides of the road moving every two lines when the road is straight:  If the array is
all 8s and $be contains 0 on the first line, the next line will contain 8 (the upper nybble is still 0).  The next line after that will
contain $10.  But when $10 is loaded back into the register A on the next scanline, the upper nybble is discarded leaving 0 again!  This
causes the counter to flip between $10 and 8.  Since the HMOVE values only use the upper 4 bytes, the line moves 0 positions or 1 positions
alternating.

</p><p>
OK, but what if the array is all 9s instead of 8s?  Here's what happens:  On the first scanline, 9 is stored into the ball HMOVE register and
written back to the counter.  The next line, 9 is again added to the value from the table making $12 (18 decimal).  This will move the ball
by 1 (upper 4 bits is 1).  On the line after that, the upper nybble is discarded leaving 2.  Adding 9 from the table makes $B.  Let's look
at one more scanline.  B is loaded.  There is no upper nybble.  Adding 9 makes $14 (20).  

</p><p>The sequence described above is 09,12,0b,14.  This is still only going to cause the ball to move every other line for these 4 lines.
But, eventually the lower nybble is going to become high enough that it will cause the routine to move the ball sprite left two lines
in a row.  The pattern will then wrap, but after a few more lines, the side of the road will move two lines in a row again.  In essence, this
is a simple and blazing fast form of fixed point math.

</p><p>There is another hurdle in implementing a road system on such limited hardware:
positioning sprites.  On more sophisticated systems, sprites can be positioned horizontally on the
road as a percentage of the road width.  But this requires either fixed point or floating point
multiplication, both of which are extremely slow on a 6502.  In contrast, Enduro only has three possible
positions for the cars, which saves some calculation.



</p><p>
<u><b>Road Rash</b></u><br>
Road Rash and 3do Road Rash both have amazing graphics engines.  The original Genesis version of the game pulled off
a relatively accurate 3d sensation on the Genesis' 7.25mhz 68000 processor, complete with realtime scaling of the
roadside objects.  The 3do follow-up is no less fascinating, as it turns out to be a mixture of 3d and pseudo
technique artistically combined to give the player an amazing sensation of speed.
</p><p>
As I mentioned above, both the Road Rash and 3do Road Rash engines are a mixture of 3d and pseudo 3d trickery.  They use
a technique similar to the one described in the "Realistic Hills Using 3d-Projected Segments" chapter in which the
hills are in 3d space, but the road's curves are not.
Road Rash's curves use the same method described in this
article, and each road segment has its own DDX or "x acceleration" value.  Each segment also has a height
which is relative to the last segment's height.  There are roughly 50 segments
on-screen at once.
</p><p>But where the 3do Road Rash is really interesting is that the programmers added warping which increases the sensation of speed that the player experiences:
Objects far from the camera move more slowly, and objects near the camera move
more quickly.
</p><p>
The 3do Road Rash also adds polygonal 
roadside objects whose X coordinates are still relative to the road.  These are
used to create hills, buildings, and other relatively complex scenery.  
This uses a fair amount of data, so the geometry and textures both are
streamed from
the disc as the track is traversed.

</p>
<u><b>S.T.U.N. Runner: Arcade vs. Lynx</b></u><br>
S.T.U.N. Runner was a marvelous game when it debuted at arcades in 1989. It made great use of fully 3d filled polygon technology, 
allowing the player to take control of a futuristic race craft barreling down twisting, turning corridors at breakneck speed. 

Not long after,
I saw a version for the Atari Lynx. The Atari Lynx was a handheld system which came out about the time of the original Game Boy. Like the
Game Boy, it had a 4MHz 8-bit processor. So, the port was horrible, right? Well, check out the footage below:
<p>
<iframe width="420" height="236" src="http://www.youtube.com/embed/_7tv5gtjun8?rel=0" frameborder="0" allowfullscreen=""></iframe>


</p><p>Actually, the port was fantastic! It came close to perfectly capturing what made the arcade game so thrilling. With Game Boy-era portable hardware,
how on earth was it done? 
</p><p>It turns out that the Lynx had one important weapon in its arsenal: hardware scaling. But this isn't a huge help in rendering
polygonal graphics. It turns out that it wasn't just the Lynx that had some tricks up its sleeve: The author who ported it had some tricks of
his own.

</p><p>To recreate the speed of the arcade machine, the Lynx version of S.T.U.N. Runner resorted to a pseudo-3d road engine. The polygon slices that make up the tunnel walls are
actually sprites.  These are essentially trackside objects which are glued to the road, much like the roadside objects in any other pseudo
3d racing game, and are drawn using the painter's algorithm (back-to-front). This convincingly creates the illusion of polygon graphics while still playing to the strengths of the hardware. And to save
space on the cartridge, one sprite wasn't a full ring of the tunnel graphic. Not only does this save on the number of blank, transparent pixels, but it's arranged
so that horizontal flipping of the graphics hardware could be used.

</p><p>One interesting problem that the author had to solve was when the tunnel branches. You can also see this in the video above. The 
branching tunnel is actually a big sprite which
scales at the player. After the player has chosen their new path, the split graphic goes away. According to the author, sometimes you can
spot vehicles driving right through this sprite!

</p></a><p><a name="hw">If you're interested in reading more, the conversation on AtariAge with the original author can be found </a><a href="http://atariage.com/forums/topic/194231-lynx-stun-runner-3d-techniques/">here</a>.



</p><p><a name="hw">
<u><b>Roads on the Commodore 64</b></u><br>
This information is courtesy of </a><a href="http://caspianit.co.uk/index.cfm">Simon Nicol</a>, who figured out a great technique for fast roads
on the C64.
</p><p>
First, some background:  On many console systems, a pseudo-3d road can be done by drawing a straight road with tiles and scrolling per-line to make it appear to curve.  However, this turned
out to be too slow for a full-framerate game on the Commodore 64.  
</p><p>Simon's engine instead uses C64's bitmap mode and uses a fast-fill algorithm.  His fast-fill algorithm uses self-modifying code to speed up draws:  Each line is a series of per-pixel
stores which specify an address in video memory.  
At the point though that the color has to change, the code is altered.  The store command is turned into a load command, and what was the address for the store is turned into 
the literal number of the new color.
</p><p>One major advantage of this technique is that sprite multiplexing techniques to show more than eight sprites on the screen can still be used.  In Simon's words:
"Offsetting the horizontal scroll to get a stable raster effect would involve manipulating register $D011.  
The raster IRQ at $D012 would flicker badly otherwise depending on the number of sprites 
on that particular raster line.  To have any sort of smooth display would involve locking up the processor to get the timing just right, or by not using the screen graphics and just changing the 
border colour.  This which would be solid and flicker free, but there wouldn't be road visible on the screen because it would have to be switched off. 
These smooth, per-line border colour changes were used 
chasing the raster down the screen, and it could also be used to 'hold off' where the top of the screen could be displayed. It was called $D011 hold-off or sometimes FLD for flexible line distancing
(the technique used to eliminate VIC's bad lines).

</p><p>
<u><b>Other Engines</b></u><br>
</p><p>
<b>Power Drift</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/pdrift_a.png"><img src="http://www.extentofthejam.com/pseudo/images/pdrift_b.png"><br>
Power Drift is interesting because it is one of the few games I know of which use sprite-based 3d.  Each chunk of the track is a small sprite blob,
and the flyby is Sega's way of showing it off.  I don't have proof, but I believe games such as F1 Exhaust Heat and RadMobile use a similar system.
It is also worth noting that the deluxe cabinet of Power Drift tilted almost 45 degrees, making it somewhat important to wear that seatbelt for once.
Screenshots from system16.com.
</p><p>
<b>Racin' Force</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/rforce_a.jpg"><img src="http://www.extentofthejam.com/pseudo/images/rforce_b.jpg"><br>
Racin' Force was reverse-engineered by the intrepid Charles MacDonald.  Racin' Force runs on the Konami GX board, which features a daughterboard 
with a voxel engine capability.  This hardware is based upon older hardware which could only draw a SNES mode 7-like floormap.  It was extended
to do a heightmap through this clever technique:  It projects not just the tilemap onto a flat 3d plane, but also the height information for
each pixel onto its own separate 3d plane.  Then, for each pixel of the screen, it looks up the height information on the projected heightmap, and extrudes each pixel
upwards as necessary.  Screenshots from system16.com.
</p><h2><u>Further Exploration</u></h2>
Here are some sites which may be useful for learning more about pseudo 3d roads:<br>
<ul>
	<li><a href="http://reassembler.blogspot.com/p/cannonball-open-source-outrun-engine.html">Cannonball: Open source OutRun port</a>
	</li><li><a href="http://www.extentofthejam.com/pseudo/codeincomplete.com/posts/2012/6/23/javascript_racer_v1_straight/">Code inComplete JavaScript Racer</a>
</li></ul>



<a name="stuff">
<u>
</u></a><h2><a name="stuff"><u>Code Stuff</u></a></h2><a name="stuff">
</a>
<b><u>Formulas and Tips</u></b><p>
<b>3d Projection</b><br>
<code>
	y_screen = (y_world*scale / z) + (screen_height &gt;&gt; 1)<br>
</code>
or:<br>
<code>
z = (y_world*scale) / (y_screen - (screen_height &gt;&gt; 1))<br>
</code><br>
This formula takes the x or y world coordinates of an object, the z of the object, and returns the x or y
pixel location.  Or, alternately, given the world and screen coordinates, returns the z location.
</p><p>
The scale determines the field-of-view (FOV), and can be found by:
</p><p><code>
	scale_x = x_resolution/tan(x_angle/2)<br>
	scale_y = y_resolution/tan(y_angle/2)
</code></p><p>
<b>Fast Linear Interpolation</b><br>
<code>
  o(x) = y1 + ((d * (y2-y1)) &gt;&gt; 16)
</code><br>
This assumes that all the numbers are in 16.16 fixed point.  <b>y1</b> and <b>y2</b> are the two values
to interpolate between, and <b>d</b> is the 16-bit fractional distance between the two points.  For example,
if <b>d</b>=$7fff, that would be halfway between the two values.  This is useful
for finding where between two segments a value is.
</p><p>

<b>Fixed Point Arithmetic</b><br>
Floating point is very expensive for old systems which did not have specialized math hardware.  Instead, a 
system called fixed point was used.  This reserved a certain number of bits for the fractional part of the number.
For a test case, say you only reserve one bit for the fractional amount, leaving seven bits for the whole
number amounts.   That fraction bit would represent one half (because
a half plus a half equals a whole).  To obtain the whole number value stored in that byte, the number is shifted
right once.  This can be expanded to use any number of bits for the fractional and whole portions of the number.
</p><div><p>Fixed point multiplcation is trickier than addition.  In this operation, you would multiply the two numbers and
then shift right by however many bits are reserved for fractions.  Due to overflow, sometimes you may need to shift
before multiplication instead of after.  See "Fast Linear Interpolation" for an example of fixed point multiplcation.
</p><p>

<b>Point Rotation</b><br>
<code>
x' = x*cos(a) - y*sin(a)<br>
y' = x*sin(a) + y*cos(a)<br>
</code>
Mentioned briefly in the tutorial as being an expensive operation, here is the basic point rotation
formula.  As you can see, it's at least 2 table lookups, 4 multiplications, and two additions, but the sine and cosine values can be reused for each point.
Rotating for the purpose of hills would mean rotating the Z and Y coordinates, not the X and Y
coordinates.  To find the derivation of this formula, look up <i>Rotation of Axes</i>.
</p><p>

<b>Avoid Division</b><br>
Instead of dividing by the z of an object in the standard projection formulas, you can take advantage of some
properties of the road to speed up calculations.  Say you have a 3d segment z position and a y position, and you
want to find which line of the screen it belongs on.  First, read through the z-map until you get to the 
3d segment's z position.  Then, multiply the height of the segment by the corresponding scaling value.
The result is the number of pixels above the road that the segment belongs. 

</p><p>
<b>Use Z as Scaling Value</b><br>
Scaling routines work by slowing or speeding up the speed at which 
a draw routine reads through graphics data.  For example, if you were
to set the read speed to half, this would draw a sprite double the size.
This is because for each time a pixel is drawn, the read position in the
sprite data is only incremented by half, causing the read position to only
increment by a whole number every two pixels.
</p></div><div><p>Usually, a scaling routine has parameters like x, y, and scaling factor.
But since a scaling factor is just 1/z, we can just reuse the Z value of that
sprite!  We will still need the scaling factor though to determine the
boundaries of the sprite so that we can keep it centered as it scales.


</p><a name="glossary">
<u>
</u></a></div><h2><a name="glossary"><u>Glossary</u></a></h2><a name="glossary">
</a>
<p><b>Bad Line</b> - In the C64's VIC II graphics chip, at the first pixel of every background tile, the VIC takes over the processor to pull in more data such as colors.  Since there are fewer cycles left for a program to do computations, these are refered to as bad lines
</p><p><b>Height Map</b> - A height map is an array of height values.  In a
polygon or voxel landscape engine, this might be a 2d array (think of a 
landscape viewed from the top).
However, in a road engine, a height map would only need to be one-dimensional
(think of a landscape viewed from the side).
</p><p><b>Indexed Color Mode</b> - Older systems which feature few colors on the screen at a time are generally
in indexed color modes.  Some of the most common indexed color modes are the 256-color VGA modes.  In these
modes, each pixel is represented by a byte.  Each byte stores an index value from 0 to 255.  When the screen
is drawn, the index number for each pixel is looked up in the palette.  Each entry in the palette can be one of
VGA's 262,144 possible colors.  In summary, even though only 256 colors can be on screen at a time, the user can
choose each color from a much larger palette.  
</p><p><b>Linear Interpolation</b> - The process of obtaining in-between values from a data set by drawing lines between
the points
</p><p><b>Painter's Algorithm</b> - The <i>Painter's Algorithm</i> is the practice
of drawing overlapping objects from far to near.  This ensures that closer
objects always appear on top of farther ones.
</p><p><b>Planar Graphics Mode</b> - A <i>Planar graphics mode</i> is one in which an N-bit image is made up of N 1-bit images
which are combined to produce the final image.
This is opposed to most graphics modes, sometimes referred to as <i>chunky</i>, in which an N-bit image is made up of
N-bit pixel values.
</p><p><b>Raster Effect</b> - A <i>raster effect</i> is a graphical trick which takes advantage of the scanline-based nature of
most computer, or raster, displays.
</p><p><b>Scaling Factor</b> - The reciprocal of Z.  This gives you the amount by which to scale an object at a given Z distance.
</p><p><b>Segment (Road)</b> - I am using the term <i>segment</i> to mean a position below which the road acts one way, and above a
different way.  For example, the segment could divide a left turn on the lower half of the screen from a right turn on
the upper half.  As the segment makes its way towards the player, the road will appear to snake left then right.
</p><p><b>Segment, 3d (Road)</b> - I am using the term <i>3d segment</i> to mean a horizontal line which has both a Z distance
and a world Y height.  Unlike a vertex, which could be a 3d point, a 3d segment would be a 3d line with the left and right
X-axis endpoints at positive and negative infinity.
</p><p><b>Voxel</b> - A 3d pixel.  Raycast/landscape voxel engines were popularized in the game Commanche: Maximum Overkill.
</p><div><p><b>Z Map</b> - A lookup table which associates each line of the screen with a Z distance.


</p><a name="gallery">
<u></u></a></div><h2><a name="gallery"><u>The Gallery</u></a></h2><a name="gallery">
</a>
Here is a collection of screenshots that show various ways to do unorthodox road engines.  Take a look!
<p><b>Cisco Heat</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/cischeat.png">
<br>The hills in this game come at you like a solid wall.  The turns are also very exaggerated.  The engine seems quite flexible and deals with multiple roads simultaneously, as well as being able to show the height of one road relative to another.
</p><p><b>Pole Position</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/polepos.png">
<br>This is the first smoothly running pseudo game I remember.  Not extremely impressive today graphically.
</p><p><b>Hydra</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/hydra.gif">
<br>This is another Atari shoot em up along the lines of Roadblasters.  It features a very nice jumping effect in which the road layer's perspective tips, causing the closest objects to fall off the screen.  It also nicely projects objects of varying distances above the ground.
</p><p><b>Outrunners</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/outrunner2.png">
<br>This sequel to Outrun is a prime example of rollercoaster-like hills in a racing game.  Everything is quite exaggerated in this, and the result is one of the most blinding fast yet nicely controllable racing games ever.
</p><p><b>Road Rash</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/rash1.jpg">
<br>In the 32-bit generation version of Road Rash, everything was textured and buildings were cleverly drawn next to the roadside, leaving some people with the impression that it was a purely polygonal game running fast on the 3do.  However, the way objects whip around the corners, buildings warp, and that you can't go backwards would seem to give away that it's not really a polygon engine.  The sharp lines on the pavement do hint at some sort of projected segment system though.  The tracks have a lot of detail and variety.
The 16-bit generation Road Rash was also no slouch, also featuring a flexible engine with a tiny bit of faked texuring (but was slow).</p><p><b>Turbo</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/turbo.png">
<br>This predates Pole Position and also features hills and bridges.  The drawback?  There are no transitions from hill to bridge to curve.  This used analog graphics scaling hardware.
</p><p><b>Spy Hunter II</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/spyhunt2.gif">
<br>I don't know what the makers of Spy Hunter II were thinking.  Nice idea, bad execution.  The road effects seem very similar to Turbo's with a little more in the way of transitions.
</p><p><b>Pitstop II</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/pitstop2.gif">
<br>This technique is so quick that on the lowly Commodore 64, people were able to pull off a split screen racing game.
</p><p><b>Enduro</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/enduro.gif">
<br>Enduro demonstrates the use of pseudo 3d on the Atari 2600.
</p><p><b>Enduro Racer</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/enduroracer.png">
<br>Not to be confused with Enduro, this was a sort of 3d Excitebike-like game.  The screenshot shows off the hill technique.  Hills are rather sharp, flexible, but generally don't affect the horizon's position, so I'm guessing interpolated points.
</p><p><b>Lotus</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/lotus.gif">
<br>Lotus comes through with the perfectly curved hill technique.  One interesting thing is that Lotus will draw the road's top below the horizon and then fill the gap with a solid color to imply a downhill.
</p><p><b>Test Drive II</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/tdrive2.gif">
<br>I'm not sure exactly what to make of Test Drive 2's graphics.  While clearly not a polygon racer, it tries very hard to realistically represent a variety of roads.  The game is similar to the Need for Speed series but predates it by several years.
</p><p><b>Speed Buggy</b><br>
<img src="http://www.extentofthejam.com/pseudo/images/speedbuggy.png">
<br>When you steer in this, in addition to shifting the perspective, the road also slides left and right a little.
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How We Centralized and Structured Error Handling in Golang (119 pts)]]></title>
            <link>https://olivernguyen.io/w/namespace.error/</link>
            <guid>42447762</guid>
            <pubDate>Wed, 18 Dec 2024 03:04:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://olivernguyen.io/w/namespace.error/">https://olivernguyen.io/w/namespace.error/</a>, See on <a href="https://news.ycombinator.com/item?id=42447762">Hacker News</a></p>
Couldn't get https://olivernguyen.io/w/namespace.error/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Ergo Chat – A modern IRC server written in Go (223 pts)]]></title>
            <link>https://github.com/ergochat/ergo</link>
            <guid>42447071</guid>
            <pubDate>Wed, 18 Dec 2024 00:46:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ergochat/ergo">https://github.com/ergochat/ergo</a>, See on <a href="https://news.ycombinator.com/item?id=42447071">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ergochat/ergo/blob/master/docs/logo.png"><img src="https://github.com/ergochat/ergo/raw/master/docs/logo.png" alt="Ergo logo"></a></p>
<p dir="auto">Ergo (formerly known as Oragono) is a modern IRC server written in Go. Its core design principles are:</p>
<ul dir="auto">
<li>Being simple to set up and use</li>
<li>Combining the features of an ircd, a services framework, and a bouncer (integrated account management, history storage, and bouncer functionality)</li>
<li>Bleeding-edge <a href="https://ircv3.net/software/servers.html" rel="nofollow">IRCv3 support</a>, suitable for use as an IRCv3 reference implementation</li>
<li>High customizability via a rehashable (i.e., reloadable at runtime) YAML config</li>
</ul>
<p dir="auto">Ergo is a fork of the <a href="https://github.com/jlatt/ergonomadic">Ergonomadic</a> IRC daemon &lt;3</p>
<hr>
<p dir="auto"><a href="https://goreportcard.com/report/github.com/ergochat/ergo" rel="nofollow"><img src="https://camo.githubusercontent.com/715dca1ef407679efd095c0f7e6bb84af1a4f3578777ba0e6fee876767360a3b/68747470733a2f2f676f7265706f7274636172642e636f6d2f62616467652f6769746875622e636f6d2f6572676f636861742f6572676f" alt="Go Report Card" data-canonical-src="https://goreportcard.com/badge/github.com/ergochat/ergo"></a>
<a href="https://github.com/ergochat/ergo/actions/workflows/build.yml"><img src="https://github.com/ergochat/ergo/actions/workflows/build.yml/badge.svg" alt="build"></a>
<a href="https://github.com/ergochat/ergo/releases/latest"><img src="https://camo.githubusercontent.com/a7f0ce32dfcb5a49fb515fc9f9c17fbf695f17c1f9453ae88ded4f7be1e45a32/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f776e6c6f6164732d6c617465737425323072656c656173652d677265656e2e737667" alt="Download Latest Release" data-canonical-src="https://img.shields.io/badge/downloads-latest%20release-green.svg"></a>
<a href="https://crowdin.com/project/ergochat" rel="nofollow"><img src="https://camo.githubusercontent.com/1b32d58517ce51950670a25e3273d77513044ac8c502648e76d0afe7e1b8b7d2/68747470733a2f2f64333232637174353834626f346f2e636c6f756466726f6e742e6e65742f6572676f636861742f6c6f63616c697a65642e737667" alt="Crowdin" data-canonical-src="https://d322cqt584bo4o.cloudfront.net/ergochat/localized.svg"></a></p>
<p dir="auto">If you want to take a look at a running Ergo instance or test some client code, feel free to play with <a href="https://testnet.ergo.chat/" rel="nofollow">testnet.ergo.chat</a> (TLS on port 6697 or plaintext on port 6667).</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>integrated services: NickServ for user accounts, ChanServ for channel registration, and HostServ for vanity hosts</li>
<li>bouncer-like features: storing and replaying history, allowing multiple clients to use the same nickname</li>
<li>native TLS/SSL support, including support for client certificates</li>
<li><a href="https://ircv3.net/software/servers.html" rel="nofollow">IRCv3 support</a></li>
<li><a href="https://yaml.org/" rel="nofollow">yaml</a> configuration</li>
<li>updating server config and TLS certificates on-the-fly (rehashing)</li>
<li>SASL authentication</li>
<li><a href="https://github.com/ergochat/ergo-ldap">LDAP support</a></li>
<li>supports <a href="https://crowdin.com/project/ergochat" rel="nofollow">multiple languages</a> (you can also set a default language for your network)</li>
<li>optional support for UTF-8 nick and channel names with RFC 8265 (PRECIS)</li>
<li>advanced security and privacy features (support for requiring SASL for all logins, cloaking IPs, and running as a Tor hidden service)</li>
<li>an extensible privilege system for IRC operators</li>
<li>ident lookups for usernames</li>
<li>automated client connection limits</li>
<li>passwords stored with <a href="https://godoc.org/golang.org/x/crypto" rel="nofollow">bcrypt</a></li>
<li><code>UBAN</code>, a unified ban system that can target IPs, networks, masks, and registered accounts (<code>KLINE</code> and <code>DLINE</code> are also supported)</li>
<li>a focus on developing with <a href="https://ergo.chat/specs.html" rel="nofollow">specifications</a></li>
</ul>
<p dir="auto">For more detailed information on Ergo's functionality, see:</p>
<ul dir="auto">
<li><a href="https://github.com/ergochat/ergo/blob/stable/docs/MANUAL.md">MANUAL.md, the operator manual</a></li>
<li><a href="https://github.com/ergochat/ergo/blob/stable/docs/USERGUIDE.md">USERGUIDE.md, the guide for end users</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick start guide</h2><a id="user-content-quick-start-guide" aria-label="Permalink: Quick start guide" href="#quick-start-guide"></a></p>
<p dir="auto">Download the latest release from this page: <a href="https://github.com/ergochat/ergo/releases/latest">https://github.com/ergochat/ergo/releases/latest</a></p>
<p dir="auto">Extract it into a folder, then run the following commands:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cp default.yaml ircd.yaml
vim ircd.yaml  # modify the config file to your liking
./ergo mkcerts
./ergo run     # server should be ready to go!"><pre>cp default.yaml ircd.yaml
vim ircd.yaml  <span><span>#</span> modify the config file to your liking</span>
./ergo mkcerts
./ergo run     <span><span>#</span> server should be ready to go!</span></pre></div>
<p dir="auto"><strong>Note:</strong> See the <a href="https://github.com/ergochat/ergo/blob/stable/docs/MANUAL.md#productionizing-with-systemd">productionizing guide in our manual</a> for recommendations on how to run a production network, including obtaining valid TLS certificates.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Platform Packages</h3><a id="user-content-platform-packages" aria-label="Permalink: Platform Packages" href="#platform-packages"></a></p>
<p dir="auto">Some platforms/distros also have Ergo packages maintained for them:</p>
<ul dir="auto">
<li>Arch Linux <a href="https://aur.archlinux.org/packages/ergochat/" rel="nofollow">AUR</a> - Maintained by <a href="https://github.com/vith">Jason Papakostas (@vith)</a>.</li>
<li><a href="https://packages.gentoo.org/packages/net-irc/ergo" rel="nofollow">Gentoo Linux</a> - Maintained by <a href="https://github.com/thesamesam">Sam James (@thesamesam)</a>.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using Docker</h3><a id="user-content-using-docker" aria-label="Permalink: Using Docker" href="#using-docker"></a></p>
<p dir="auto">A Dockerfile and example docker-compose recipe are available in the <code>distrib/docker</code> directory. Ergo is automatically published
to the GitHub Container Registry at <a href="https://ghcr.io/ergochat/ergo" rel="nofollow">ghcr.io/ergochat/ergo</a>. For more information, see the distrib/docker
<a href="https://github.com/ergochat/ergo/blob/master/distrib/docker/README.md">README file</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">From Source</h3><a id="user-content-from-source" aria-label="Permalink: From Source" href="#from-source"></a></p>
<p dir="auto">You can also clone this repository and build from source. Typical deployments should use the <code>stable</code> branch, which points to the latest stable release. In general, <code>stable</code> should coincide with the latest published tag that is not designated as a beta or release candidate (for example, <code>v2.7.0-rc1</code> was an unstable release candidate and <code>v2.7.0</code> was the corresponding stable release), so you can also identify the latest stable release tag on the <a href="https://github.com/ergochat/ergo/releases">releases page</a> and build that.</p>
<p dir="auto">The <code>master</code> branch is not recommended for production use since it may contain bugs, and because the forwards compatibility guarantees for the config file and the database that apply to releases do not apply to master. That is to say, running master may result in changes to your database that end up being incompatible with future versions of Ergo.</p>
<p dir="auto">For information on contributing to Ergo, see <a href="https://github.com/ergochat/ergo/blob/master/DEVELOPING.md">DEVELOPING.md</a>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Building</h4><a id="user-content-building" aria-label="Permalink: Building" href="#building"></a></p>
<p dir="auto">You'll need an <a href="https://golang.org/dl/" rel="nofollow">up-to-date distribution of the Go language for your OS and architecture</a>. Once that's installed (check the output of <code>go version</code>), just check out your desired branch or tag and run <code>make</code>. This will produce an executable binary named <code>ergo</code> in the base directory of the project. (Ergo vendors all its dependencies, so you will not need to fetch any dependencies remotely.)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration</h2><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto">The default config file <a href="https://github.com/ergochat/ergo/blob/master/default.yaml"><code>default.yaml</code></a> helps walk you through what each option means and changes.</p>
<p dir="auto">You can use the <code>--conf</code> parameter when launching Ergo to control where it looks for the config file. For instance: <code>ergo run --conf /path/to/ircd.yaml</code>. The configuration file also stores where the log, database, certificate, and other files are opened. Normally, all these files use relative paths, but you can change them to be absolute (such as <code>/var/log/ircd.log</code>) when running Ergo as a service.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Logs</h3><a id="user-content-logs" aria-label="Permalink: Logs" href="#logs"></a></p>
<p dir="auto">By default, logs go to stderr only. They can be configured to go to a file, or you can use systemd to direct the stderr to the system journal (see the manual for details). The configuration format of logs is designed to be easily pluggable, and is inspired by the logging config provided by InspIRCd.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Passwords</h3><a id="user-content-passwords" aria-label="Permalink: Passwords" href="#passwords"></a></p>
<p dir="auto">Passwords (for both <code>PASS</code> and oper logins) are stored using bcrypt. To generate encrypted strings for use in the config, use the <code>genpasswd</code> subcommand as such:</p>

<p dir="auto">With this, you receive a blob of text which you can plug into your configuration file.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Nickname and channel registration</h3><a id="user-content-nickname-and-channel-registration" aria-label="Permalink: Nickname and channel registration" href="#nickname-and-channel-registration"></a></p>
<p dir="auto">Ergo relies heavily on user accounts to enable its distinctive features (such as allowing multiple clients per nickname). As a user, you can register your current nickname as an account using <code>/msg NickServ register &lt;password&gt;</code>. Once you have done so, you should <a href="https://libera.chat/guides/sasl" rel="nofollow">enable SASL in your clients</a>, ensuring that you will be automatically logged into your account on each connection. This will prevent <a href="https://github.com/ergochat/ergo/blob/master/docs/MANUAL.md#nick-equals-account">problems claiming your registered nickname</a>.</p>
<p dir="auto">Once you have registered your nickname, you can use it to register channels:</p>
<ol dir="auto">
<li>Join the channel with <code>/join #channel</code></li>
<li>Register the channel with <code>/CS REGISTER #channel</code></li>
</ol>
<p dir="auto">After this, your channel will remember the fact that you're the owner, the topic, and any modes set on it!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Credits</h2><a id="user-content-credits" aria-label="Permalink: Credits" href="#credits"></a></p>
<ul dir="auto">
<li>Jeremy Latt (2012-2014)</li>
<li>Edmund Huber (2014-2015)</li>
<li>Daniel Oaks (2016-present)</li>
<li>Shivaram Lingamneni (2017-present)</li>
<li><a href="https://github.com/ergochat/ergo/blob/master/CHANGELOG.md">Many other contributors and friends of the project &lt;3</a></li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The XOR Texture (2004) (182 pts)]]></title>
            <link>https://lodev.org/cgtutor/xortexture.html</link>
            <guid>42447053</guid>
            <pubDate>Wed, 18 Dec 2024 00:43:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lodev.org/cgtutor/xortexture.html">https://lodev.org/cgtutor/xortexture.html</a>, See on <a href="https://news.ycombinator.com/item?id=42447053">Hacker News</a></p>
<div id="readability-page-1" class="page">
<h2>Lode's Computer Graphics Tutorial</h2>

<h2>Table of Contents</h2>
<ul>
<li><a href="#Introduction_">Introduction</a></li>
<li><a href="#The_XOR_Texture">The XOR Texture</a></li>
<li><a href="#Colors">Colors</a></li>
<li><a href="#AND_and_OR">AND and OR</a></li>
<li><a href="#Conclusion">Conclusion</a><br></li>
</ul>
<a href="https://lodev.org/cgtutor/index.html">Back to index</a><br>
<h2><a name="Introduction_" id="Introduction_"></a>Introduction<br></h2>
The XOR texture is a very easy to generate texture that looks fine.
However, it's so overused that it's not a good choice to use in in
a demo or intro release. It isn't useful for games either, unless
you want some fancy floor tiles. What it's useful for, is for
testing a texture mapper you just wrote, in case you want to
quickly test out a pattern without having to load an image file or
write more complex texture generation code.<p>

This is an extremely small article, but the XOR Texture just
couldn't be left out in a series of texture generation
articles.</p><h2><a name="The_XOR_Texture" id="The_XOR_Texture"></a>The XOR
Texture</h2>
The XOR texture is simply generated by xor-ing the x and y
coordinate of the current pixel. The '^' operator in C++ is the XOR
operator.<center>
<div>
<pre><span>int main(int argc, char *argv[])
{
  screen(256, 256, 0, "The XOR Texture");

  for(int y = 0; y &lt; h; y++)
  for(int x = 0; x &lt; w; x++)
  {
    Uint8 c = x ^ y;
    pset(x, y, ColorRGB(c, c, c));
  }

  redraw();
  sleep();
  return 0;
}</span></pre>
</div>
</center>
<br>
That's it, if you run it, you see the XOR texture:<p>

<img alt="The XOR Texture" src="https://lodev.org/cgtutor/images/xortexture.gif"></p><p>

There are 3 things you should keep in mind though:</p><p>

<b>1)</b> The sizes of the texture should be a power of two, if
they aren't, the texture doesn't look as good:</p><p>

<img alt="" src="https://lodev.org/cgtutor/images/xortexturesize.gif"></p><p>

<b>2)</b> Color component values range from 0 to 255. The maximum
color value generated by the XOR operation is the same as the
dimensions of the texture if its size is a power of two. So if the
size of your XOR pattern is smaller than 256, for example only 64,
it'll be too dark (image on the left). Multiply the color with 4 to
make it bright again (image on the right):</p><p>

<img alt="" src="https://lodev.org/cgtutor/images/xortexturedark.gif"> <img alt="" src="https://lodev.org/cgtutor/images/xortexturebright.gif"></p><p>

<b>3)</b> On the other hand, if the size is larger than 256, for
example 512, you have to make sure the color is limited to a
maximum value of 256. You can either modulo divide it through 256,
but then it isn't a real XOR pattern anymore. Better is to divide
it through 2. In any case, using a XOR texture larger than 256x256
doesn't increase the quality because there aren't enough distinct
color values, unless you're using a color mode that allows more
bits per channel. But who'd want to generate a 1024x1024 XOR
texture anyway.</p><p>

The XOR operator takes the binary values of both integers, and does
a binary XOR on every two corresponding bits. XOR or eXclusive OR
returns 1 if both bits are different, and returns 0 if both bits
are the same: "Bit a is 1 OR bit 2 is 1, but <i>not</i> both". In
other words, it applies the following truth table to every two
corresponding bits:</p><table>

<tbody><tr>
<td colspan="3" rowspan="1">
<b>XOR</b><br></td>
</tr>
<tr>
<td><i>Bit_a</i><br></td>
<td><i>Bit_b</i><br></td>
<td><i>Result</i><br></td>
</tr>
<tr>
<td>0<br></td>
<td>0<br></td>
<td>0<br></td>
</tr>
<tr>
<td>0<br></td>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
</tr>
<tr>
<td><b>1</b><br></td>
<td>0<br></td>
<td><b>1</b><br></td>
</tr>
<tr>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
<td>0<br></td>
</tr>

</tbody></table>
<br>
This is done on every bit of the integer, creating the many
possible resulting values.<p>

For example, 5 XOR 13 = 8, because in binary 0101 XOR 1101 =
1000.</p><h2><a name="Colors" id="Colors"></a>Colors</h2>
You can also try the XOR texture with different colors, by using
different value for R, G and B. For example:<center>
<div>
<pre><span>int main(int argc, char *argv[])
{
  screen(256, 256, 0, "The XOR Texture");

  ColorRGB color;

  for(int y = 0; y &lt; h; y++)
  for(int x = 0; x &lt; w; x++)
  {
    Uint8 c = (x ^ y);
    color.r = 255 - c;
    color.g = c;
    color.b = c % 128;
    pset(x, y, color);
  }

  redraw();
  sleep();
  return 0;
}
</span></pre>
</div>
</center>
<br>
<img alt="" src="https://lodev.org/cgtutor/images/xortexturecolor.gif"><p>

You can even use the xor value as hue for the HSVtoRGB
function...</p><center>
<div>
<pre><span>int main(int argc, char *argv[])
{
  screen(256, 256, 0, "The XOR Texture");

  ColorRGB color;

  for(int y = 0; y &lt; h; y++)
  for(int x = 0; x &lt; w; x++)
  {
    Uint8 c = (x ^ y);
    color = HSVtoRGB(ColorHSV(c, 255, 255));
    pset(x, y, color);
  }

  redraw();
  sleep();
  return 0;
}
</span></pre>
</div>
</center>
<br>
<img alt="" src="https://lodev.org/cgtutor/images/xortexturehsv.gif"><h2><a name="AND_and_OR" id="AND_and_OR"></a>AND and OR</h2>
The AND and the OR operator also generate a similar texture.<p>

The XOR operator returns 1 if both bits are different:</p><table>

<tbody><tr>
<td colspan="3" rowspan="1">
<b>XOR</b><br></td>
</tr>
<tr>
<td><i>Bit_a</i><br></td>
<td><i>Bit_b</i><br></td>
<td><i>Result</i><br></td>
</tr>
<tr>
<td>0<br></td>
<td>0<br></td>
<td>0<br></td>
</tr>
<tr>
<td>0<br></td>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
</tr>
<tr>
<td><b>1</b><br></td>
<td>0<br></td>
<td><b>1</b><br></td>
</tr>
<tr>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
<td>0<br></td>
</tr>

</tbody></table>
<br>
The AND operator, only returns 1 if both bits are 1 (bit a AND bit
b are true)<table>

<tbody><tr>
<td colspan="3" rowspan="1">
<b>AND</b><br></td>
</tr>
<tr>
<td><i>Bit_a</i><br></td>
<td><i>Bit_b</i><br></td>
<td><i>Result</i><br></td>
</tr>
<tr>
<td>0<br></td>
<td>0<br></td>
<td>0<br></td>
</tr>
<tr>
<td>0<br></td>
<td><b>1</b><br></td>
<td>0<br></td>
</tr>
<tr>
<td><b>1</b><br></td>
<td>0<br></td>
<td>0<br></td>
</tr>
<tr>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
</tr>

</tbody></table>
<br>
The OR operator returns 1 if any or both of the bits are 1 (bit a
OR bit b is true)<table>

<tbody><tr>
<td colspan="3" rowspan="1">
<b>OR</b><br></td>
</tr>
<tr>
<td><i>Bit_a</i><br></td>
<td><i>Bit_b</i><br></td>
<td><i>Result</i><br></td>
</tr>
<tr>
<td>0<br></td>
<td>0<br></td>
<td>0<br></td>
</tr>
<tr>
<td>0<br></td>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
</tr>
<tr>
<td><b>1</b><br></td>
<td>0<br></td>
<td><b>1</b><br></td>
</tr>
<tr>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
<td><b>1</b><br></td>
</tr>

</tbody></table>
<br>
The AND operator is denoted '&amp;' in C++, and the OR operator
'|', replace the '^' operator with those to use the new operators.
Here's the result of XOR, AND and OR respectively:<p>

<img alt="" src="https://lodev.org/cgtutor/images/xortexture.gif"> <img alt="" src="https://lodev.org/cgtutor/images/andtexture.gif">
<img alt="" src="https://lodev.org/cgtutor/images/ortexture.gif"></p><p>

It makes sense that the AND texture is darker, because it returns 1
only in a single case. The OR texture is brighter, because it
returns 1 very often. The sum of the XOR texture and the AND
texture is the OR texture.</p><h2><a name="Conclusion" id="Conclusion"></a>Conclusion</h2>
It was shown how easy it is to create a XOR texture, which makes
the XOR texture useful to test if a texture renderer is working.
However, it's not suitable for applications such as art or
games.<p>

Here, the XOR pattern was used as a 3D texture (x ^ y ^ z) to test
if a planet texture renderer was working correctly:</p><p>

<img alt="" src="https://lodev.org/cgtutor/images/xorplanet.gif"></p><hr>
Last edited: 2004
<p>
Copyright (c) 2004-2007 by Lode Vandevenne. All rights reserved.
</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ad: An Adaptable Text Editor (115 pts)]]></title>
            <link>https://github.com/sminez/ad</link>
            <guid>42447012</guid>
            <pubDate>Wed, 18 Dec 2024 00:37:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/sminez/ad">https://github.com/sminez/ad</a>, See on <a href="https://news.ycombinator.com/item?id=42447012">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">ad :: an adaptable text editor</h2><a id="user-content-ad--an-adaptable-text-editor" aria-label="Permalink: ad :: an adaptable text editor" href="#ad--an-adaptable-text-editor"></a></p>
<p dir="auto"><a href="https://github.com/sminez/ad/actions?query=workflow%3ABuild"><img src="https://github.com/sminez/ad/workflows/Build/badge.svg" alt="Build"></a> <a href="https://crates.io/crates/ad-editor" rel="nofollow"><img src="https://camo.githubusercontent.com/b85e95578041b718fb667b6a6ba2eb44d11b18a44ea76d66d5a25140515e4619/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f61642d656469746f72" alt="crates.io version" data-canonical-src="https://img.shields.io/crates/v/ad-editor"></a> <a href="https://docs.rs/ad-editor" rel="nofollow"><img src="https://camo.githubusercontent.com/159a3447fa97d7e50e8d27dc7765f54fcd62b826c6e97a1d064fd2f1db655e81/68747470733a2f2f696d672e736869656c64732e696f2f646f637372732f61642d656469746f723f6c6f676f3d72757374" alt="docs.rs" data-canonical-src="https://img.shields.io/docsrs/ad-editor?logo=rust"></a></p>
<p dir="auto"><code>ad</code> (pronounced A.D.) is an attempt at combining a modal editing interface of likes of <code>vi</code>
and <code>kakoune</code> with the approach to extensibility of Plan9's <code>Acme</code>. Inside of <code>ad</code> text is
something you can execute as well as edit.</p>
<p dir="auto">It is primarily intended as playground for experimenting with implementing various text editor
features and currently is not at all optimised or feature complete enough for use as your main
text editor.</p>
<p dir="auto">That said, if this sounds like something you might find interesting then please to take a
look and see what you think! For now there isn't a whole lot of user facing documentation so
you will need to read through the source code to learn about what is and is not implemented.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Project Status</h2><a id="user-content-project-status" aria-label="Permalink: Project Status" href="#project-status"></a></p>
<p dir="auto"><code>ad</code> is stable enough and feature complete enough that you can try it out and see what you
think. That said, there is currently very little documentation and there are likely to be
a variety of bugs and crashes in places that I've not managed to fully track down yet. If
you do try it out and spot something that is broken, please raise an issue on GitHub so I
can look into it.</p>
<p dir="auto">You have been warned!</p>
<p dir="auto"><a href="https://www.youtube.com/watch?v=jb2pAi5hLUg" rel="nofollow"><img src="https://camo.githubusercontent.com/b24964ea9f911479b4354f1637a37d47c5c3ea0c09022100d1c80d870df4be29/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f6a623270416935684c55672f302e6a7067" alt="tour" data-canonical-src="https://img.youtube.com/vi/jb2pAi5hLUg/0.jpg"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">The design of ad</h2><a id="user-content-the-design-of-ad" aria-label="Permalink: The design of ad" href="#the-design-of-ad"></a></p>
<p dir="auto"><code>ad</code> is aiming to be a hybrid of the pieces of various editors that I find most useful:</p>
<ul dir="auto">
<li>vim style modal editing to allow for convenient key bindings</li>
<li>convenient text navigation and selection from vim/kakoune</li>
<li>mini-buffer based user defined minor modes from emacs</li>
<li>sam/acme style editing commands for larger editing actions</li>
<li>acme style extension through exposing editor state and functionality for
external client programs.</li>
<li>support for mouse based navigation and selection but not requiring that as the main
way of using the editor like in acme. That's fine for desktop but most of the time
I'm working with a laptop which makes that far too clunky.</li>
</ul>
<p dir="auto"><code>ad</code> is <em>not</em> trying to replace vim (or kakoune, or emacs) in terms of being a massively
hackable editor. Rather it is trying to follow the philosophy of acme in being an
integrat<strong>ing</strong> development environment (rather than integrat<strong>ed</strong>). By which I mean
that the aim is to provide a comfortable editing environment to work in that supports
direct interaction with external tools and programs from the outside rather than pulling
everything <strong>in</strong>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Repo structure</h2><a id="user-content-repo-structure" aria-label="Permalink: Repo structure" href="#repo-structure"></a></p>
<p dir="auto">Given the (arguably questionable) goal of implementing everything from scratch, there is a fair amount
of functionality included in <code>ad</code> which in turn is split out into a number of modules within the crate.
For now, I'm not structuring things as individual crates but that may change in future.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Modules</h3><a id="user-content-modules" aria-label="Permalink: Modules" href="#modules"></a></p>
<p dir="auto"><em>This is a non-exhaustive list of some of the more interesting parts of the internals of <code>ad</code></em></p>
<ul dir="auto">
<li><strong>buffer/internal</strong>: a <a href="https://en.wikipedia.org/wiki/Gap_buffer" rel="nofollow">gap buffer</a> implementation for the
internal state of a Buffer.</li>
<li><strong>dot</strong>: manipulation of the current selection in a given buffer (including vim-like motions)</li>
<li><strong>exec</strong>: minimal implementation of the core of the <a href="http://doc.cat-v.org/bell_labs/sam_lang_tutorial/sam_tut.pdf" rel="nofollow">sam editing language</a></li>
<li><strong>fsys</strong>: virtual filesystem interface to the editor state in the style of <a href="http://acme.cat-v.org/" rel="nofollow">acme</a></li>
<li><strong>ninep</strong>: <a href="http://9p.cat-v.org/" rel="nofollow">9p protocol</a> implementation that backs the fsys module
<ul dir="auto">
<li>Now moved out to its own crate with source code available <a href="https://github.com/sminez/ad/crates/ninep">here</a>.</li>
</ul>
</li>
<li><strong>regex</strong>: custom regex engine that is able to work on character streams. This is nowhere near as performant as
the <a href="https://github.com/rust-lang/regex">regex crate</a> (obviously) but it allows for some flexability in tinkering
with the exec command language.</li>
<li><strong>trie</strong>: <a href="https://en.wikipedia.org/wiki/Trie" rel="nofollow">trie</a> data structure for handling sequence based keybindings</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why?</h2><a id="user-content-why" aria-label="Permalink: Why?" href="#why"></a></p>
<p dir="auto">I've used <a href="https://www.vim.org/" rel="nofollow">vim</a> for years now (more recently <a href="https://neovim.io/" rel="nofollow">neovim</a> and <a href="https://github.com/mawww/kakoune">kakoune</a>) and I really love the
core editor itself. A while back I discovered <a href="https://en.wikipedia.org/wiki/Acme_(text_editor)" rel="nofollow">acme</a> through a fantastic <a href="https://www.youtube.com/watch?v=dP1xVpMPn8M" rel="nofollow">screencast</a> from
Russ Cox, showing how you could interface with it via plan filesystem protocol, allowing you to run
pretty much whatever you want inside of the editor (in any language) so long as you can interact with
that protocol. <em>That</em> I absolutely love, but the lack of modal editing and requirement to use the mouse
when I'm sat with my laptop is proving hard to get used to, so I set about looking at how to port
over some of the acme ideas into vim (namely the load/execute semantics via the plumber and the
idea of exposing the editor state in a really simple way to client programs).</p>
<p dir="auto">Turns out, vim has a <em>lot</em> more built into it that I was previously aware (and I've been hacking on
my vimrc for years now) which was more than a little scary. What I want is a small, usable editor
that I can hack on.</p>
<p dir="auto">So...How hard could it be?</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Simplicity</h2><a id="user-content-simplicity" aria-label="Permalink: Simplicity" href="#simplicity"></a></p>
<p dir="auto">For things that are going to be core parts of the experience (bindings, per-filetype configuration)
I'm just going to hard code stuff. I'll try to do it in a way that makes it easy to update / change
but the whole thing will be a lot easier to write if there isn't too much config parsing.</p>
<p dir="auto">That said, the more I work on this, the more I wonder if it might be interesting to structure <code>ad</code>
in the same way as <a href="https://github.com/sminez/penrose">penrose</a> and have it as a library for writing
your own text editor? That would require some restructuring but might be interesting to explore...</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Goals</h2><a id="user-content-goals" aria-label="Permalink: Goals" href="#goals"></a></p>
<ul dir="auto">
<li>Simple modal editing to the extent that I use VIM</li>
<li>Sed/Sam style edit commands</li>
<li>Acme style use of external commands rather than an embedded language:
<ul dir="auto">
<li>Exposing current buffer / window state to external programs</li>
<li>Exposing events to external programs</li>
<li>Accepting events from other programs</li>
</ul>
</li>
<li>Virtual buffers for command output that can be hidden</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Sam style structural regular expressions</h2><a id="user-content-sam-style-structural-regular-expressions" aria-label="Permalink: Sam style structural regular expressions" href="#sam-style-structural-regular-expressions"></a></p>
<p dir="auto">One aim of this project is to provide an implementation of "Structural Regular Expressions" as first
presented (to my knowledge) in the <a href="http://doc.cat-v.org/plan_9/4th_edition/papers/sam/" rel="nofollow">Sam text editor</a> from plan9 by Rob Pike. <a href="http://doc.cat-v.org/bell_labs/sam_lang_tutorial/sam_tut.pdf" rel="nofollow">This tutorial</a>
from Pike covers the command language of Sam which I am using as a starting point for the command
language for <code>ad</code>. So far I'm not aiming for a perfect match with the functionality of Sam or Acme
but I <em>am</em> looking to make use of the pieces that feel particularly useful. As the project develops
I may well end up pulling in more but for now I'm happy to have a decent starting point for an
implementation of the structural regular expression engine.</p>
<p dir="auto">There is still a fair amount to do but so far the idea is to allow for repeated narrowing and looping
over sub-matches within a buffer or file loaded from disk. (A streaming interface working over stdin
is coming but I need to have a think about how best to buffer the input and track partial matches in
the regex engine to avoid slowing things down too much or requiring the engine to buffer and collect
<em>all</em> of its standard input before matching).</p>
<p dir="auto">The current engine can be used via the <code>-e</code> and <code>-f</code> flags to run <code>ad</code> in headless mode, but hooking
things into the interactive editor directly should be coming soon. For now, here is a demo of some
simple functionality of the engine:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ cat examples/exec_scripts/result_fns.ad
,                              # set dot to be the full input (not required as this is the default)
x/fn@*?\{/                     # select all Rust function signatures up to the opening brace
g/->.*Result.*\{/              # keep those that return some form of Result
x/fn (\w+)@*?-> (.*?) \{/      # extract the function name and return type from the signature
p/($FILENAME) $1 returns $2/   # print them along with the filename using a template


$ ad -f examples/exec_scripts/result_fns.ad src/**/*.rs | head
(src/buffer/buffers.rs) open_or_focus returns io::Result<()>
(src/buffer/dot/cur.rs) fmt returns fmt::Result
(src/buffer/dot/mod.rs) fmt returns fmt::Result
(src/buffer/dot/range.rs) fmt returns fmt::Result
(src/buffer/edit.rs) fmt returns fmt::Result
(src/buffer/mod.rs) new_from_canonical_file_path returns io::Result<Self>
(src/exec/parse.rs) execute returns Result<(usize, usize), Error>
(src/exec/parse.rs) step returns Result<(usize, usize), Error>
(src/exec/parse.rs) try_parse returns Result<Self, Error>
(src/exec/parse.rs) validate returns Result<(), Error>"><pre>$ cat examples/exec_scripts/result_fns.ad
,                              <span><span>#</span> set dot to be the full input (not required as this is the default)</span>
x/fn@<span>*?</span><span>\{</span>/                     <span><span>#</span> select all Rust function signatures up to the opening brace</span>
g/-<span>&gt;</span>.<span>*</span>Result.<span>*</span><span>\{</span>/              <span><span>#</span> keep those that return some form of Result</span>
x/fn (<span>\w</span>+)@<span>*?</span>-<span>&gt;</span> (.<span>*?</span>) <span>\{</span>/      <span><span>#</span> extract the function name and return type from the signature</span>
p/(<span>$FILENAME</span>) <span>$1</span> returns <span>$2</span>/   <span><span>#</span> print them along with the filename using a template</span>


$ ad -f examples/exec_scripts/result_fns.ad src/<span>**</span>/<span>*</span>.rs <span>|</span> head
(src/buffer/buffers.rs) open_or_focus returns <span>io::Result&lt;</span>()<span>&gt;</span>
(src/buffer/dot/cur.rs) fmt returns fmt::Result
(src/buffer/dot/mod.rs) fmt returns fmt::Result
(src/buffer/dot/range.rs) fmt returns fmt::Result
(src/buffer/edit.rs) fmt returns fmt::Result
(src/buffer/mod.rs) new_from_canonical_file_path returns io::Result<span>&lt;</span>Self<span>&gt;</span>
(src/exec/parse.rs) execute returns Result<span><span>&lt;(</span>usize, usize<span>)</span></span>, Error<span>&gt;</span>
(src/exec/parse.rs) step returns Result<span><span>&lt;(</span>usize, usize<span>)</span></span>, Error<span>&gt;</span>
(src/exec/parse.rs) try_parse returns Result<span>&lt;</span>Self, Error<span>&gt;</span>
(src/exec/parse.rs) validate returns <span>Result&lt;</span>(), Error<span>&gt;</span></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We Built the Saturn V (2017) (115 pts)]]></title>
            <link>https://www.smithsonianmag.com/air-space-magazine/we-built-saturn-v-180964759/</link>
            <guid>42446889</guid>
            <pubDate>Wed, 18 Dec 2024 00:17:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.smithsonianmag.com/air-space-magazine/we-built-saturn-v-180964759/">https://www.smithsonianmag.com/air-space-magazine/we-built-saturn-v-180964759/</a>, See on <a href="https://news.ycombinator.com/item?id=42446889">Hacker News</a></p>
Couldn't get https://www.smithsonianmag.com/air-space-magazine/we-built-saturn-v-180964759/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Optimizing Ruby's JSON, Part 1 (157 pts)]]></title>
            <link>https://byroot.github.io/ruby/json/2024/12/15/optimizing-ruby-json-part-1.html</link>
            <guid>42446846</guid>
            <pubDate>Wed, 18 Dec 2024 00:08:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://byroot.github.io/ruby/json/2024/12/15/optimizing-ruby-json-part-1.html">https://byroot.github.io/ruby/json/2024/12/15/optimizing-ruby-json-part-1.html</a>, See on <a href="https://news.ycombinator.com/item?id=42446846">Hacker News</a></p>
Couldn't get https://byroot.github.io/ruby/json/2024/12/15/optimizing-ruby-json-part-1.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Design Token-Based UI Architecture (139 pts)]]></title>
            <link>https://martinfowler.com/articles/design-token-based-ui-architecture.html</link>
            <guid>42445834</guid>
            <pubDate>Tue, 17 Dec 2024 22:04:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://martinfowler.com/articles/design-token-based-ui-architecture.html">https://martinfowler.com/articles/design-token-based-ui-architecture.html</a>, See on <a href="https://news.ycombinator.com/item?id=42445834">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Design tokens, or “tokens” are fundamental design decisions represented
    as data. They are the foundational building blocks of design systems.</p>

<p>Since the release of the <a href="https://second-editors-draft.tr.designtokens.org/format/">second editor’s
    draft</a> of the
    design token specification in 2022 and the <a href="https://www.w3.org/community/design-tokens/2022/06/14/call-to-implement-the-second-editors-draft-and-share-feedback/">call for tool
    makers</a>
    to start implementing and providing feedback, the landscape of design token
    tools has evolved rapidly. Tools like code generators, documentation
    systems, and UI design software are now better equipped to support design
    tokens, underscoring their growing importance in modern UI architecture.</p>

<p>In this article, I'll explain what design tokens are, when they are useful and how to apply
    them effectively. We'll focus on key architectural decisions that are often difficult to change later, including:</p>

<ol>
<li>How to organize design tokens in layers to balance scalability, maintainability and developer experience.</li>

<li>Whether all tokens should be made available to product teams or just a subset.</li>

<li>How to automate the distribution process of tokens across teams.</li>
</ol>

<section id="RoleOfDesignTokens">
<h2>Role of design tokens</h2>

<p>Around 2017, I was involved in a large project that used the <a href="https://martinfowler.com/articles/micro-frontends.html">Micro
      Frontend
      Architecture</a> to
      scale development teams. In this setup, different teams were responsible
      for different parts of the user interface, which could be even on the same
      page. Each team could deploy its micro-frontend independently.</p>

<p>There were various cases where components would be displayed on top of
      each other (such as dialogs or toasts appearing on top of content areas),
      which were not part of the same micro frontend. Teams used the CSS
      property <code>z-index</code> to control the stacking order, often relying on magic
      numbers—arbitrary values that weren’t documented or standardized. This approach
      did not scale as the project grew. It led to issues that took effort to
      fix, as cross-team collaboration was needed.</p>

<p>The issue was eventually addressed with design tokens and I think makes
      a good example to introduce the concept. The respective token file might
      have looked similar to this:</p>

<pre>{
  "z-index": {
    "$type": "number",
    "default": {
      "$value": 1
    },
    "sticky": {
      "$value": 100
    },
    "navigation": {
      "$value": 200
    },
    "spinner": {
      "$value": 300
    },
    "toast": {
      "$value": 400
    },
    "modal": {
      "$value": 500
    }
  }
}
</pre>

<p>The design tokens above represent the set of <code>z-index</code> values that can
      be used in the application and the name gives developers a good idea of
      where to use them. A token file like this can be integrated into the
      designers’ workflow and also be used to generate code, in a format that
      each team requires. For example, in this case, the token file might have
      been used to generate CSS or SCSS variables:</p>

<div>
<div>
<p>css
</p>

<pre>  :root {
    --z-index-default: 1;
    --z-index-sticky: 100;
    --z-index-navigation: 200;
    --z-index-spinner: 300;
    --z-index-toast: 400;
    --z-index-modal: 500;
  }</pre>
</div>

<div>
<p>scss
</p>

<pre>  
  $z-index-default: 1;
  $z-index-sticky: 100;
  $z-index-navigation: 200;
  $z-index-spinner: 300;
  $z-index-toast: 400;
  $z-index-modal: 500;</pre>
</div>
</div>

<section id="WhatAreDesignTokens">
<h3>What are design tokens?</h3>

<p>Salesforce <a href="https://www.smashingmagazine.com/2019/11/smashing-podcast-episode-3/">originally introduced design tokens</a> to streamline design
      updates to multiple
      platforms.</p>

<p>The Design Tokens Community Group <a href="https://second-editors-draft.tr.designtokens.org/format/#introduction">describes design tokens</a> as “a
      methodology for expressing design decisions in a platform-agnostic way so
      that they can be shared across different <b>disciplines</b>, <b>tools</b>, and
      <b>technologies</b></p>

<p>Let’s break this down:</p>

<ul>
<li><b>Cross-Disciplinary Collaboration:</b> Design tokens act as a common language
        that aligns designers, developers, product managers, and other disciplines. By
        offering a single source of truth for design decisions, they ensure that
        everyone involved in the product life cycle is on the same page, leading to more
        efficient workflows.</li>

<li><b>Tool integration:</b> Design tokens can be integrated into various design
        and development tools, including UI design software, token editors, translation
        tools (code generators), and documentation systems. This enables design updates
        to be quickly reflected in the code base and are synchronized across teams.</li>

<li><b>Technology adaptability:</b> Design tokens can be translated into different
        technologies like CSS, SASS, and JavaScript for the web, and even used on native
        platforms like Android and iOS. This flexibility enables design consistency
        across a variety of platforms and devices.</li>
</ul>
</section>
</section>

<section id="EstablishingASingleSourceOfTruth">
<h2>Establishing a single source of truth</h2>

<p>A key benefit of design tokens is their ability to serve as a single
      source of truth for both design and engineering teams. This ensures that
      multiple products or services maintain visual and functional
      consistency.</p>

<p>A <a href="https://tr.designtokens.org/format/#translation-tool">translation
      tool</a> takes one or
      more design token files as input and generates platform-specific code as
      output. Some translation tools can also produce documentation for the
      design tokens in the form of HTML. At the time of writing, popular
      translation tools include ﻿<a href="https://styledictionary.com/">Style
      Dictionary</a>,
      ﻿<a href="https://github.com/salesforce-ux/theo">Theo</a>, ﻿<a href="https://diez.org/">Diez</a>
      or ﻿<a href="https://specifyapp.com/">Specify App</a>.</p>




</section>

<section id="AutomatedDesignTokenDistribution">
<h2>Automated design token distribution</h2>

<p>In this section, we’ll explore how to automate the distribution of
      design tokens to product teams.</p>

<p>Let’s assume our goal is to provide teams with updated, tech-specific
      design tokens immediately after a designer makes a change. To achieve
      this, we can automate the translation and distribution process using a
      deployment pipeline for design tokens. Besides platform-specific code
      artifacts (like CSS for the web, XML for Android etc.), the pipeline might
      also deploy the documentation for the design tokens.</p>

<p>One crucial requirement is keeping design tokens under version control.
      Thankfully, plugins for popular design tools like Figma already integrate
      with Git providers like GitHub. It's considered best practice to use the
      Git repository as the single source of truth for design tokens—not the
      design tool itself. However, this requires the plugin to support syncing
      both ways between the repository and the design tool, which not all
      plugins do. As of now, Tokens Studio is a plugin that offers this
      bidirectional syncing. For detailed guidance on integrating Tokens Studio
      with different Git providers, please refer to their
      <a href="https://docs.tokens.studio/token-storage-and-sync/sync-provider-overview">documentation</a>.
      The tool enables you to configure a target branch and supports a
      trunk-based as well as a pull-request-based workflow.</p>

<p>Once the tokens are under version control, we can set up a deployment
      pipeline to build and deploy the artifacts needed by the product teams,
      which include platform-specific source code and documentation. The source
      code is typically packaged as a library and distributed via an artifact
      registry. This approach gives product teams control over the upgrade
      cycle. They can adopt updated styles by simply updating their
      dependencies. These updates may also be applied indirectly through updates of component
      libraries that use the token-based styles.</p>

<div id="token-distribution.svg"><p><img src="https://martinfowler.com/articles/design-token-based-ui-architecture/token-distribution.svg"></p><p>Figure 2: Automated design token distribution</p>
</div>



<p>This overall setup has allowed teams at Thoughtworks to roll out
      smaller design changes across multiple front-ends and teams in a single
      day.</p>

<section id="FullyAutomatedPipeline">
<h3>Fully automated pipeline</h3>

<p>The most straightforward way to design the pipeline would be a
          fully automated trunk-based workflow. In this setup, all changes
          pushed to the main branch will be immediately deployed as long as they
          pass the automated quality gates.</p>

<p>Such a pipeline might consist of the following jobs:</p>

<ol>
<li><b>Check:</b> Validate the design token files using a design token validator
            or a JSON validator.</li>

<li><b>Build:</b> Use a translation tool like <a href="https://styledictionary.com/">Style
            Dictionary</a> to convert design token files into
            platform-specific formats. This job might also build the docs using the
            translation tool or by integrating a dedicated documentation tool.</li>

<li><b>Test:</b> This job is highly dependent on the testing strategy. Although
            some tests can be done using the design token file directly (like checking the
            color contrast), a common approach is to test the generated code using a
            documentation tool such as Storybook. Storybook has excellent <a href="https://storybook.js.org/docs/writing-tests">test
            support</a> for visual regression
            tests, accessibility tests, interaction tests, and other test types.</li>

<li><b>Publish:</b> Publish updated tokens to a package manager (for example,
            npm). The release process and versioning can be fully automated with a package
            publishing tool that is based on <a href="https://www.conventionalcommits.org/">Conventional
            Commits</a> like
            <a href="https://github.com/semantic-release/semantic-release">semantic-release</a>.
            semantic-release also allows the deployment of packages to multiple platforms.
            The publish job might also deploy documentation for the design tokens.</li>

<li><b>Notify:</b> Inform teams of the new token version via email or chat, so
            that they can update their dependencies.</li>
</ol>

<div id="pipeline-fully-automated.svg"><p><img src="https://martinfowler.com/articles/design-token-based-ui-architecture/pipeline-fully-automated.svg"></p><p>Figure 3: Fully automated deployment pipeline</p>
</div>


</section>

<section id="PipelineIncludingManualApproval">
<h3>Pipeline including manual approval</h3>

<p>Sometimes fully automated quality gates are not sufficient. If a
          manual review is required before publishing, a common approach is to
          deploy an updated version of the documentation with the latest design
          token to a preview environment (a temporary environment).</p>

<p>If a tool like Storybook is used, this preview might contain not
          only the design tokens but also show them integrated with the
          components used in the application.</p>

<p>An approval process can be implemented via a pull-request workflow.
          Or, it can be a manual approval / deployment step in the pipeline.</p>

<div id="pipeline-incl-review.svg"><p><img src="https://martinfowler.com/articles/design-token-based-ui-architecture/pipeline-incl-review.svg"></p><p>Figure 4: Deployment pipeline with manual approval</p>
</div>


</section>
</section>

<section id="OrganizingTokensInLayers">
<h2>Organizing tokens in layers</h2>

<p>As discussed earlier, design tokens represent design decisions as data.
      However, not all decisions operate at the same level of detail. Instead,
      ideally, general design decisions guide more specific ones. Organizing
      tokens (or design decisions) into layers allows designers to make
      decisions at the right level of abstraction, supporting consistency and
      scalability.</p>

<p>For instance, making individual color choices for every new component isn’t practical.
      Instead, it’s more efficient to define a foundational color palette and then
      decide how and where those colors are applied. This approach reduces the
      number of decisions while maintaining a consistent look and feel.</p>

<p>There are three key types of design decisions for which design tokens
      are used. They build on top of one another:</p>

<ul>
<li><b>What</b> design options are available to use?</li>

<li><b>How</b> are those styles applied across the user interface?</li>

<li><b>Where</b> exactly are those styles applied (in which components)?</li>
</ul>

<p>There are various names for these three types of tokens (as usual,
      naming is the hard part). In this article, we’ll use the terms <a href="https://samiamdesigns.substack.com/p/a-new-approach-to-naming-design-tokens">proposed
      by Samantha
      Gordashko</a>:
      option tokens, decision tokens and component tokens.</p>

<p>Let’s use our color example to illustrate how design tokens can
      answer the three questions above.</p>

<section id="OptionTokensDefiningWhatDesignOptionsAreProvided">
<h3>Option tokens: defining what design options are provided</h3>

<p><i>Option tokens</i> (also called <i>primitive tokens</i>, <i>base tokens</i>, <i>core
      tokens</i>, <i>foundation tokens</i> or <i>reference tokens</i>) define <b>what</b>
      styles can be used in the application. They define things like color
      palettes, spacing/sizing scales or font families. Not all of them are
      necessarily used in the application, but they present reasonable
      options.</p>

<p>Using our example, let’s assume we have a color palette with 9 shades for each color,
      ranging from very light to highly saturated. Below, we define the blue tones and grey tones as option-tokens:</p>

<pre>{
  "color": {
    "$type": "color",
    "options": {
      "blue-100": {"$value": "#e0f2ff"},
      "blue-200": {"$value": "#cae8ff"},
      "blue-300": {"$value": "#b5deff"},
      "blue-400": {"$value": "#96cefd"},
      "blue-500": {"$value": "#78bbfa"},
      "blue-600": {"$value": "#59a7f6"},
      "blue-700": {"$value": "#3892f3"},
      "blue-800": {"$value": "#147af3"},
      "blue-900": {"$value": "#0265dc"},
      "grey-100": {"$value": "#f8f8f8"},
      "grey-200": {"$value": "#e6e6e6"},
      "grey-300": {"$value": "#d5d5d5"},
      "grey-400": {"$value": "#b1b1b1"},
      "grey-500": {"$value": "#909090"},
      "grey-600": {"$value": "#6d6d6d"},
      "grey-700": {"$value": "#464646"},
      "grey-800": {"$value": "#222222"},
      "grey-900": {"$value": "#000000"},
      "white": {"$value": "#ffffff"}
    }
  }
}</pre>

<p>Although it’s highly useful to have reasonable options, option tokens fall short
      of being sufficient for guiding developers on how and where to apply them.</p>
</section>

<section id="DecisionTokensDefiningHowStylesAreApplied">
<h3>Decision tokens: defining how styles are applied</h3>

<p><i>Decision tokens</i> (also called <i>semantic tokens</i> or <i>system tokens</i>)
      specify <b>how</b> those style options should be applied contextually across
      the UI.</p>

<p>In the context of our color example, they might include decisions like the following:</p>

<ul>
<li>grey-100 is used as a surface color.</li>

<li>grey-200 is used for the background of disabled elements.</li>

<li>grey-400 is used for the text of disabled elements.</li>

<li>grey-900 is used as a default color for text.</li>

<li>blue-900 is used as an accent color.</li>

<li>white is used for text on accent color backgrounds.</li>
</ul>

<p>The corresponding decision token file would look like this:</p>

<pre>{
  "color": {
    "$type": "color",
    "decisions": {
      "surface": {
        "$value": "{color.options.grey-100}",
        "description": "Used as a surface color."
      },
      "background-disabled": {
        "$value": "{color.options.grey-200}",
        "description":"Used for the background of disabled elements."
      },
      "text-disabled": {
        "$value": "{color.options.grey-400}",
        "description": "Used for the text of disabled elements."
      },
      "text": {
        "$value": "{color.options.grey-900}",
        "description": "Used as default text color."
      },
      "accent": {
        "$value": "{color.options.blue-900}",
        "description": "Used as an accent color."
      },
      "text-on-accent": {
        "$value": "{color.options.white}",
        "description": "Used for text on accent color backgrounds."
      }
    }
  }
}</pre>

<p>As a developer, I would mostly be interested in the decisions, not the
      options. For example, color tokens typically contain a long list of options (a
      color palette), while very few of those options are actually used in
      the application. The tokens that are actually relevant when deciding which
      styles to apply, would be usually the decision tokens.</p>

<p>Decision tokens use
      <a href="https://tr.designtokens.org/format/#alias-reference">references</a> to the
      option tokens. I think of organizing tokens this way as a layered
      architecture. In other articles, I have often seen the term <i>tier</i> being
      used, but I think <i>layer</i> is the better word, as there is no physical
      separation implied. The diagram below visualizes the two layers we talked
      about so far:</p>

<div id="2-layer.svg"><p><img src="https://martinfowler.com/articles/design-token-based-ui-architecture/2-layer.svg"></p><p>Figure 5: 2-layer pattern</p>
</div>


</section>

<section id="ComponentTokensDefiningWhereStylesAreApplied">
<h3>Component tokens: defining where styles are applied</h3>

<p><i>Component tokens</i> (or <i>component-specific tokens</i>) map the <i>decision
      tokens</i> to specific parts of the UI. They show <b>where</b> styles are
      applied.</p>

<p>The term <i>component</i> in the context of design tokens does not always
      map to the technical term component. For example, a button might be
      implemented as a UI component in some applications, while other
      applications just use the <code>button</code> HTML element instead. <i>Component
      tokens</i> could be used in both cases.</p>

<p>Component tokens can be organised in a <a href="https://tr.designtokens.org/format/#group"><i>group</i></a> referencing multiple decision tokens. In our example, this references
      might include text- and background-colors for different variants of the button (primary, secondary) as well as disabled buttons.
      They might also include references to tokens of other types (spacing/sizing, borders etc.) which I'll omit in the
      following example:</p>

<pre>{
  "button": {
    "primary": {
      "background": {
        "$value": "{color.decisions.accent}"
      },
      "text": {
        "$value": "{color.decisions.text-on-accent}"
      }
    },
    "secondary": {
      "background": {
        "$value": "{color.decisions.surface}"
      },
      "text": {
        "$value": "{color.decisions.text}"
      }
    },
    "background-disabled": {
      "$value": "{color.decisions.background-disabled}"
    },
    "text-disabled": {
      "$value": "{color.decisions.text-disabled}"
    }
  }
}</pre>

<p>To some degree, component tokens are simply the result of applying
      decisions to specific components. However, as this
      example shows, this process isn’t always straightforward—especially for
      developers without design experience. While decision tokens can offer a
      general sense of which styles to use in a given context, component tokens
      provide additional clarity.</p>

<div id="3-layer.svg"><p><img src="https://martinfowler.com/articles/design-token-based-ui-architecture/3-layer.svg"></p><p>Figure 6: 3-layer pattern</p>
</div>



<p><b>Note:</b> there may be “snowflake” situations where layers are skipped.
      For example, it might not be possible to define a general decision for
      every single component token, or those decisions might not have been made
      yet (for example at the beginning of a project).</p>
</section>


</section>

<section id="TokenScope">
<h2>Token scope</h2>

<p>I already mentioned that while option tokens are very helpful to
    designers, they might not be relevant for application developers using the
    platform-specific code artifacts. Application developers will typically be
    more interested in the decision/component tokens.</p>

<p>Although token scope is not yet included in the design token
    spec, some design
    systems already separate tokens into private (also called <i>internal</i>) and
    public (also called <i>global</i>) tokens. For example, the Salesforce Lightning
    Design System introduced <a href="https://www.lightningdesignsystem.com/design-tokens/">a flag for each
    token</a>. There are
    various reasons why this can be a good idea:</p>

<ul>
<li>it guides developers on which tokens to use</li>

<li>fewer options provide a better developer experience</li>

<li>it reduces the file size as not all tokens need to be included</li>

<li>private/internal tokens can be changed or removed without breaking
      changes</li>
</ul>

<p>A downside of making option tokens private is that developers would rely
    on designers to always make those styles available as decision or component
    tokens. This could become an issue in case of limited availability of the
    designers or if not all decisions are available, for example at the start of
    a project.</p>

<p>Unfortunately, there is no standardized solution yet for implementing
    scope for design tokens. So the approach depends on the tool-chain of the
    project and will most likely need some custom code.</p>

<section id="File-basedScope">
<h3>File-based scope</h3>

<p>Using Style Dictionary, we can use a
      <a href="https://styledictionary.com/reference/hooks/filters/"><i>filter</i></a> to
      expose only public tokens. The most straightforward approach would be to
      filter on the file ending. If we use different file endings for component,
      decision and option tokens, we can use a filter on the file path, for
      example, to make the option tokens layer private.</p>

<p>Style Dictionary config
</p>

<pre>  const styleDictionary = new StyleDictionary({
    "source": ["color.options.json", "color.decisions.json"],
    "platforms": {
      "css": {
        "transformGroup": "css",
        "files": [
          {
            "destination": "variables.css",
<span>            "filter": token =&gt; !token.filePath.endsWith('options.json'),</span>
            "format": "css/variables"
          }
        ]
      }
    }
  });</pre>

<p>The resulting CSS variables would contain
      only these decision tokens, and not the option tokens.</p>

<p>Generated CSS variables
</p>

<pre>  :root {
    --color-decisions-surface: #f8f8f8;
    --color-decisions-background-disabled: #e6e6e6;
    --color-decisions-text-disabled: #b1b1b1;
    --color-decisions-text: #000000;
    --color-decisions-accent: #0265dc;
    --color-decisions-text-on-accent: #ffffff;
  }</pre>
</section>

<section id="AMoreFlexibleApproach">
<h3>A more flexible approach</h3>

<p>If more flexibility is needed, it might be preferable to add a scope
      flag to each token and to filter based on this flag:</p>

<p>Style Dictionary config
</p>

<pre>  const styleDictionary = new StyleDictionary({
    "source": ["color.options.json", "color.decisions.json"],
    "platforms": {
      "css": {
        "transformGroup": "css",
        "files": [
          {
            "destination": "variables.css",
<span>            "filter": {
              "public": true
            },</span>
            "format": "css/variables"
          }
        ]
      }
    }
  });</pre>

<p>If we then add the flag to the decision tokens, the resulting CSS would
      be the same as above:</p>

<p>Tokens with scope flag
</p>

<pre>  {
    "color": {
      "$type": "color",
      "decisions": {
        "surface": {
          "$value": "{color.options.grey-100}",
          "description": "Used as a surface color.",
<span>          "public": true</span>
        },
        "background-disabled": {
          "$value": "{color.options.grey-200}",
          "description":"Used for the background of disabled elements.",
<span>          "public": true</span>
        },
        "text-disabled": {
          "$value": "{color.options.grey-400}",
          "description": "Used for the text of disabled elements.",
<span>          "public": true</span>
        },
        "text": {
          "$value": "{color.options.grey-900}",
          "description": "Used as default text color.",
<span>          "public": true</span>
        },
        "accent": {
          "$value": "{color.options.blue-900}",
          "description": "Used as an accent color.",
<span>          "public": true</span>
        },
        "text-on-accent": {
          "$value": "{color.options.white}",
          "description": "Used for text on accent color backgrounds.",
<span>          "public": true</span>
        }
      }
    }
  }</pre>

<p>Generated CSS variables
</p>

<pre>  :root {
    --color-decisions-surface: #f8f8f8;
    --color-decisions-background-disabled: #e6e6e6;
    --color-decisions-text-disabled: #b1b1b1;
    --color-decisions-text: #000000;
    --color-decisions-accent: #0265dc;
    --color-decisions-text-on-accent: #ffffff;
  }</pre>

<p>Such flags can now also be set <a href="https://help.figma.com/hc/en-us/articles/360039238193-Hide-styles-components-and-variables-when-publishing#h_01HD20M7HS9044NHB2YBJNE9C2">through the Figma
      UI</a>
      (if using Figma variables as a source of truth for design tokens). It is
      available as
      <a href="https://www.figma.com/plugin-docs/api/properties/Variable-hiddenfrompublishing/"><code>hiddenFromPublishing</code></a>
      flag via the Plugins API.</p>
</section>
</section>

<section id="ShouldIUseDesignTokens">
<h2>Should I use design tokens?</h2>

<p>Design tokens offer significant benefits for modern UI architecture,
      but they may not be the right fit for every project.</p>

<div>
<div>
<p><b>Benefits</b> include:</p>

<ul>
<li>Improved lead time for design changes</li>

<li>Consistent design language and UI architecture across platforms and
            technologies</li>

<li>Design tokens being relatively lightweight from an implementation point of
            view</li>
</ul>
</div>

<div>
<p><b>Drawbacks</b> include:</p>

<ul>
<li>Initial effort for automation</li>

<li>Designers might have to (to some degree) interact with Git</li>

<li>Standardization is still in progress</li>
</ul>
</div>
</div>

<p>Consider the following when deciding whether to adopt design
      tokens:</p>

<section id="WhenToUseDesignTokens">
<h3>When to use design tokens</h3>

<ol>
<li><b>Multi-Platform or Multi-Application Environments:</b> When working across
          multiple platforms (web, iOS, Android…) or maintaining several applications or
          frontends, design tokens ensure a consistent design language across all of
          them.</li>

<li><b>Frequent Design Changes</b>: For environments with regular design
          updates, design tokens provide a structured way to manage and propagate changes
          efficiently.</li>

<li><b>Large Teams</b>: For teams with many designers and developers, design
          tokens facilitate collaboration.</li>

<li><b>Automated Workflows</b>: If you’re familiar with CI/CD pipelines, the
          effort to add a design token pipeline is relatively low. There are also
          commercial offerings.</li>
</ol>
</section>

<section id="WhenDesignTokensMightNotBeNecessary">
<h3>When design tokens might not be necessary</h3>

<ol>
<li><b>Small projects:</b> For smaller projects with limited scope and minimal
          design complexity, the overhead of managing design tokens might not be worth the
          effort.</li>

<li><b>No issue with design changes:</b> If the speed of design changes,
          consistency and collaboration between design and engineering are not an issue,
          then you might also not need design tokens.</li>
</ol>
</section>
</section>

<hr>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Includeable minimal operating system for C++ (167 pts)]]></title>
            <link>https://www.includeos.org/</link>
            <guid>42445508</guid>
            <pubDate>Tue, 17 Dec 2024 21:29:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.includeos.org/">https://www.includeos.org/</a>, See on <a href="https://news.ycombinator.com/item?id=42445508">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content"><p>IncludeOS allows you to run your application in the cloud without an operating system. IncludeOS adds operating system functionality to your application allowing you to create performant, secure and resource efficient virtual machines.</p>

<p>IncludeOS applications boot in tens of milliseconds and require only a few megabytes of disk and memory.</p>

<p><a href="https://github.com/includeos/IncludeOS">[View on Github]</a>
<a href="https://join.slack.com/t/includeos/shared_invite/zt-5z7ts29z-_AX0kZNiUNE7eIMUP60GmQ">[Chat on Slack]</a>
<a href="https://www.includeos.org/technology.html">[Tell me more]</a></p>

<p>To run a service with IncludeOS on Linux or macOS you do not need to install IncludeOS, however you need to install a few dependencies depending on the service you will run. You can start by trying out our simplest hello_world service. For this service you will need the following dependencies.</p>

<ul>
  <li>Conan package manager</li>
  <li>cmake, make, nasm</li>
  <li>clang, or alternatively gcc on linux. Prebuilt packages are available for clang 6.0 and gcc 7.3</li>
  <li>qemu</li>
  <li>python3 packages: psutil, jsonschema</li>
</ul>

<p>With the above dependencies you should be able to build an application within minutes.</p>
<p><a target="_blank" href="https://buffett.online/">buffett.online</a><a target="_blank" href="https://songdonkey.ai/">songdonkey.ai</a></p>
<div><pre><code><span>$ </span>conan config <span>install </span>https://github.com/includeos/conan_config.git
<span>$ </span>git clone https://github.com/includeos/hello_world.git
<span>$ </span><span>mkdir </span>build_hello_world
<span>$ </span><span>cd </span>build_hello_world
<span>$ </span>conan <span>install</span> ../hello_world <span>-pr</span> 
<span>$ </span><span>source</span> ./activate.sh
<span>$ </span>cmake ../hello_world
<span>$ </span>cmake <span>--build</span> <span>.</span>
<span>$ </span>boot hello
</code></pre></div>

<p>The hello world booted service should look like this:</p>

<div><pre><code>================================================================================
 IncludeOS 0.14.1-1093 (x86_64 / 64-bit)
 +--&gt; Running [ Hello world - OS included ]
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Hello world
    [ main ] returned with status 0
</code></pre></div>

<p>For detailed instructions see the <a href="https://github.com/includeos/IncludeOS/blob/master/README.md">GitHub README</a>. Once installed we suggest looking at and booting a few of the demo-examples to familarize yourself with the system.</p>

<p>We strive to make it easy to create fast and useful services. The below code will set up a simple TCP echo service and happily talk to anyone connecting.</p>

<div><pre><code><span>#include &lt;os&gt;
#include &lt;iostream&gt;
#include &lt;net/interfaces&gt;
</span>
<span>void</span> <span>Service</span><span>::</span><span>start</span><span>()</span>
<span>{</span>
  <span>// Get the IP stack thats already been automatically configured</span>
  <span>auto</span><span>&amp;</span> <span>inet</span> <span>=</span> <span>net</span><span>::</span><span>Interfaces</span><span>::</span><span>get</span><span>(</span><span>0</span><span>);</span>
  <span>// Setup a TCP echo server on port 7 (echo port)</span>
  <span>auto</span><span>&amp;</span> <span>server</span> <span>=</span> <span>inet</span><span>.</span><span>tcp</span><span>().</span><span>listen</span><span>(</span><span>7</span><span>);</span>

  <span>server</span><span>.</span><span>on_connect</span><span>([]</span> <span>(</span><span>auto</span> <span>conn</span><span>)</span> <span>{</span>
    <span>// Log incomming connections on the console:</span>
    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"Connection "</span> <span>&lt;&lt;</span> <span>conn</span><span>-&gt;</span><span>to_string</span><span>()</span> <span>&lt;&lt;</span> <span>" established</span><span>\n</span><span>"</span><span>;</span>
    <span>// When data is received, echo back</span>
    <span>conn</span><span>-&gt;</span><span>on_read</span><span>(</span><span>1024</span><span>,</span> <span>[</span><span>conn</span><span>]</span> <span>(</span><span>auto</span> <span>buf</span><span>)</span> <span>{</span>
      <span>conn</span><span>-&gt;</span><span>write</span><span>(</span><span>buf</span><span>);</span>
    <span>});</span>
  <span>});</span>
<span>}</span>
</code></pre></div>

<p>The network configuration of the virtual machine can reside in a JSON file, named config.json, placed in the same folder. It should look something like this, depending on your need:</p>
<div><pre><code><span>{</span><span>
  </span><span>"net"</span><span> </span><span>:</span><span> </span><span>[</span><span>
    </span><span>{</span><span>
      </span><span>"iface"</span><span>:</span><span> </span><span>0</span><span>,</span><span>
      </span><span>"config"</span><span>:</span><span> </span><span>"dhcp-with-fallback"</span><span>,</span><span>
      </span><span>"address"</span><span>:</span><span> </span><span>"10.0.0.42"</span><span>,</span><span>
      </span><span>"netmask"</span><span>:</span><span> </span><span>"255.255.255.0"</span><span>,</span><span>
      </span><span>"gateway"</span><span>:</span><span> </span><span>"10.0.0.1"</span><span>
    </span><span>}</span><span>
  </span><span>]</span><span>
</span><span>}</span><span>
</span></code></pre></div>

<h2 id="security">Security</h2>

<p>For security related inquires please send email to security@includeos.org. You can use our <a href="https://pgp.mit.edu/pks/lookup?search=security@includeos.org&amp;op=index">PGP key</a> to encrypt the email.</p>

<p>This project is maintained by Alfred Bratterud.</p>

<h2>Recommendations</h2>

<p>4K Download regularly updates their app named <a href="https://www.4kdownload.com/products/youtubetomp3/6">YouTube to MP3</a>. We strongly recommend it if you need to download audio from YouTube.</p>


 
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FastVideo: a lightweight framework for accelerating large video diffusion models (108 pts)]]></title>
            <link>https://github.com/hao-ai-lab/FastVideo</link>
            <guid>42445239</guid>
            <pubDate>Tue, 17 Dec 2024 20:56:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/hao-ai-lab/FastVideo">https://github.com/hao-ai-lab/FastVideo</a>, See on <a href="https://news.ycombinator.com/item?id=42445239">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p><a target="_blank" rel="noopener noreferrer" href="https://github.com/hao-ai-lab/FastVideo/blob/main/assets/logo.jpg"><img src="https://github.com/hao-ai-lab/FastVideo/raw/main/assets/logo.jpg" width="30%"></a>
</p>
<p dir="auto">FastVideo is a lightweight framework for accelerating large video diffusion models.</p>
<details open="">
  <summary>
    
    <span aria-label="Video description FastMochi-Demo.mp4">FastMochi-Demo.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/147024991/396602614-5fbc4596-56d6-43aa-98e0-da472cf8e26c.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1Mjg5MTMsIm5iZiI6MTczNDUyODYxMywicGF0aCI6Ii8xNDcwMjQ5OTEvMzk2NjAyNjE0LTVmYmM0NTk2LTU2ZDYtNDNhYS05OGUwLWRhNDcyY2Y4ZTI2Yy5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMjE4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTIxOFQxMzMwMTNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03YmFkNjhhMmI1ZDU2YTNmN2RjYTM5NzkxODE0ODczMzljNTI2MjYzNDQ1ZjU4MWIwZThmZjU1N2JmNzkxNmQ2JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.O9Mcov19yDSU0TjD0YAmhkAwUy8TEdNnlcWwrcxfibw" data-canonical-src="https://private-user-images.githubusercontent.com/147024991/396602614-5fbc4596-56d6-43aa-98e0-da472cf8e26c.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1Mjg5MTMsIm5iZiI6MTczNDUyODYxMywicGF0aCI6Ii8xNDcwMjQ5OTEvMzk2NjAyNjE0LTVmYmM0NTk2LTU2ZDYtNDNhYS05OGUwLWRhNDcyY2Y4ZTI2Yy5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMjE4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTIxOFQxMzMwMTNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03YmFkNjhhMmI1ZDU2YTNmN2RjYTM5NzkxODE0ODczMzljNTI2MjYzNDQ1ZjU4MWIwZThmZjU1N2JmNzkxNmQ2JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.O9Mcov19yDSU0TjD0YAmhkAwUy8TEdNnlcWwrcxfibw" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">
    🤗 <a href="https://huggingface.co/FastVideo/FastMochi-diffusers" rel="nofollow">FastMochi</a> | 🤗 <a href="https://huggingface.co/FastVideo/FastHunyuan" rel="nofollow">FastHunyuan</a>  | 🔍 <a href="https://discord.gg/REBzDQTWWt" rel="nofollow"> Discord </a>
</p> 
<p dir="auto">FastVideo currently offers: (with more to come)</p>
<ul dir="auto">
<li>FastHunyuan and FastMochi: consistency distilled video diffusion models for 8x inference speedup.</li>
<li>First open distillation recipes for video DiT, based on <a href="https://github.com/G-U-N/Phased-Consistency-Model">PCM</a>.</li>
<li>Support distilling/finetuning/inferencing state-of-the-art open video DiTs: 1. Mochi 2. Hunyuan.</li>
<li>Scalable training with FSDP, sequence parallelism, and selective activation checkpointing, with near linear scaling to 64 GPUs.</li>
<li>Memory efficient finetuning with LoRA, precomputed latent, and precomputed text embeddings.</li>
</ul>
<p dir="auto">Dev in progress and highly experimental.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🎥 More Demos</h2><a id="user-content--more-demos" aria-label="Permalink: 🎥 More Demos" href="#-more-demos"></a></p>
<p dir="auto">Fast-Hunyuan comparison with original Hunyuan, achieving an 8X diffusion speed boost with the FastVideo framework.</p>
<details open="">
  <summary>
    
    <span aria-label="Video description FastHunyuan-Demo.mp4">FastHunyuan-Demo.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/147024991/396606115-064ac1d2-11ed-4a0c-955b-4d412a96ef30.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1Mjg5MTMsIm5iZiI6MTczNDUyODYxMywicGF0aCI6Ii8xNDcwMjQ5OTEvMzk2NjA2MTE1LTA2NGFjMWQyLTExZWQtNGEwYy05NTViLTRkNDEyYTk2ZWYzMC5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMjE4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTIxOFQxMzMwMTNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT01NDI5ZGZjODI2OWNkYTg5ODEzMjM1N2I3ZjA5YzQ2YWIwMGE1MzdkYjRmYWE5YWZjMWQ1NzExMDg2MWYwZDg0JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.Cia9_peiJoR4CYlj9xGWg2MUaoOdD35-ShY02UX8R80" data-canonical-src="https://private-user-images.githubusercontent.com/147024991/396606115-064ac1d2-11ed-4a0c-955b-4d412a96ef30.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1Mjg5MTMsIm5iZiI6MTczNDUyODYxMywicGF0aCI6Ii8xNDcwMjQ5OTEvMzk2NjA2MTE1LTA2NGFjMWQyLTExZWQtNGEwYy05NTViLTRkNDEyYTk2ZWYzMC5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMjE4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTIxOFQxMzMwMTNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT01NDI5ZGZjODI2OWNkYTg5ODEzMjM1N2I3ZjA5YzQ2YWIwMGE1MzdkYjRmYWE5YWZjMWQ1NzExMDg2MWYwZDg0JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.Cia9_peiJoR4CYlj9xGWg2MUaoOdD35-ShY02UX8R80" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">Comparison between OpenAI Sora, original Hunyuan and FastHunyuan</p>
<details open="">
  <summary>
    
    <span aria-label="Video description sora-verse-fasthunyuan.mp4.mp4">sora-verse-fasthunyuan.mp4.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/147024991/396652769-d323b712-3f68-42b2-952b-94f6a49c4836.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1Mjg5MTMsIm5iZiI6MTczNDUyODYxMywicGF0aCI6Ii8xNDcwMjQ5OTEvMzk2NjUyNzY5LWQzMjNiNzEyLTNmNjgtNDJiMi05NTJiLTk0ZjZhNDljNDgzNi5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMjE4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTIxOFQxMzMwMTNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1hMmM0MTQ4OTdmMDBkNDBiZDZhYjc3MmFlNTgwZmQ1NmZjNWFlYjE0MDkxMzIxZmY5Njg2ZjdjYWM4NjdkOGQ4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.ees2bKsXAXFchpywttCVXoeB8j_hbHg3WeoN8HsS3cQ" data-canonical-src="https://private-user-images.githubusercontent.com/147024991/396652769-d323b712-3f68-42b2-952b-94f6a49c4836.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQ1Mjg5MTMsIm5iZiI6MTczNDUyODYxMywicGF0aCI6Ii8xNDcwMjQ5OTEvMzk2NjUyNzY5LWQzMjNiNzEyLTNmNjgtNDJiMi05NTJiLTk0ZjZhNDljNDgzNi5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMjE4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTIxOFQxMzMwMTNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1hMmM0MTQ4OTdmMDBkNDBiZDZhYjc3MmFlNTgwZmQ1NmZjNWFlYjE0MDkxMzIxZmY5Njg2ZjdjYWM4NjdkOGQ4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.ees2bKsXAXFchpywttCVXoeB8j_hbHg3WeoN8HsS3cQ" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">Change Log</h2><a id="user-content-change-log" aria-label="Permalink: Change Log" href="#change-log"></a></p>
<ul dir="auto">
<li><code>2024/12/17</code>: <code>FastVideo</code> v0.1 is released.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔧 Installation</h2><a id="user-content--installation" aria-label="Permalink: 🔧 Installation" href="#-installation"></a></p>
<p dir="auto">The code is tested on Python 3.10.0, CUDA 12.1 and H100.</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Inference</h2><a id="user-content--inference" aria-label="Permalink: 🚀 Inference" href="#-inference"></a></p>
<p dir="auto">We recommend using a GPU with 80GB of memory. To run the inference, use the following command:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">FastHunyuan</h3><a id="user-content-fasthunyuan" aria-label="Permalink: FastHunyuan" href="#fasthunyuan"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Download the model weight
python scripts/huggingface/download_hf.py --repo_id=FastVideo/FastHunyuan --local_dir=data/FastHunyuan --repo_type=model
# CLI inference
sh scripts/inference/inference_hunyuan.sh"><pre><span><span>#</span> Download the model weight</span>
python scripts/huggingface/download_hf.py --repo_id=FastVideo/FastHunyuan --local_dir=data/FastHunyuan --repo_type=model
<span><span>#</span> CLI inference</span>
sh scripts/inference/inference_hunyuan.sh</pre></div>
<p dir="auto">You can also inference FastHunyuan in the <a href="https://github.com/Tencent/HunyuanVideo">official Hunyuan github</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">FastMochi</h3><a id="user-content-fastmochi" aria-label="Permalink: FastMochi" href="#fastmochi"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Download the model weight
python scripts/huggingface/download_hf.py --repo_id=FastVideo/FastMochi-diffusers --local_dir=data/FastMochi-diffusers --repo_type=model
# CLI inference
bash scripts/inference/inference_mochi_sp.sh"><pre><span><span>#</span> Download the model weight</span>
python scripts/huggingface/download_hf.py --repo_id=FastVideo/FastMochi-diffusers --local_dir=data/FastMochi-diffusers --repo_type=model
<span><span>#</span> CLI inference</span>
bash scripts/inference/inference_mochi_sp.sh</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">🎯 Distill</h2><a id="user-content--distill" aria-label="Permalink: 🎯 Distill" href="#-distill"></a></p>
<p dir="auto">Our distillation recipe is based on <a href="https://github.com/G-U-N/Phased-Consistency-Model">Phased Consistency Model</a>. We did not find significant improvement using multi-phase distillation, so we keep the one phase setup similar to the original latent consistency model's recipe.
We use the <a href="https://huggingface.co/datasets/LanguageBind/Open-Sora-Plan-v1.1.0/tree/main/all_mixkit" rel="nofollow">MixKit</a> dataset for distillation. To avoid running the text encoder and VAE during training, we preprocess all data to generate text embeddings and VAE latents.
Preprocessing instructions can be found <a href="https://github.com/hao-ai-lab/FastVideo/blob/main/docs/data_preprocess.md">data_preprocess.md</a>. For convenience, we also provide preprocessed data that can be downloaded directly using the following command:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python scripts/huggingface/download_hf.py --repo_id=FastVideo/HD-Mixkit-Finetune-Hunyuan --local_dir=data/HD-Mixkit-Finetune-Hunyuan --repo_type=dataset"><pre>python scripts/huggingface/download_hf.py --repo_id=FastVideo/HD-Mixkit-Finetune-Hunyuan --local_dir=data/HD-Mixkit-Finetune-Hunyuan --repo_type=dataset</pre></div>
<p dir="auto">Next, download the original model weights with:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python scripts/huggingface/download_hf.py --repo_id=FastVideo/hunyuan --local_dir=data/hunyuan --repo_type=model"><pre>python scripts/huggingface/download_hf.py --repo_id=FastVideo/hunyuan --local_dir=data/hunyuan --repo_type=model</pre></div>
<p dir="auto">To launch the distillation process, use the following commands:</p>
<div data-snippet-clipboard-copy-content="bash scripts/distill/distill_mochi.sh # for mochi
bash scripts/distill/distill_hunyuan.sh # for hunyuan"><pre><code>bash scripts/distill/distill_mochi.sh # for mochi
bash scripts/distill/distill_hunyuan.sh # for hunyuan
</code></pre></div>
<p dir="auto">We also provide an optional script for distillation with adversarial loss, located at <code>fastvideo/distill_adv.py</code>. Although we tried adversarial loss, we did not observe significant improvements.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Finetune</h2><a id="user-content-finetune" aria-label="Permalink: Finetune" href="#finetune"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">⚡ Full Finetune</h3><a id="user-content--full-finetune" aria-label="Permalink: ⚡ Full Finetune" href="#-full-finetune"></a></p>
<p dir="auto">Ensure your data is prepared and preprocessed in the format specified in <a href="https://github.com/hao-ai-lab/FastVideo/blob/main/docs/data_preprocess.md">data_preprocess.md</a>. For convenience, we also provide a mochi preprocessed Black Myth Wukong data that can be downloaded directly:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python scripts/huggingface/download_hf.py --repo_id=FastVideo/Mochi-Black-Myth --local_dir=data/Mochi-Black-Myth --repo_type=dataset"><pre>python scripts/huggingface/download_hf.py --repo_id=FastVideo/Mochi-Black-Myth --local_dir=data/Mochi-Black-Myth --repo_type=dataset</pre></div>
<p dir="auto">Download the original model weights with:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python scripts/huggingface/download_hf.py --repo_id=genmo/mochi-1-preview --local_dir=data/mochi --repo_type=model
python scripts/huggingface/download_hf.py --repo_id=FastVideo/hunyuan --local_dir=data/hunyuan --repo_type=model"><pre>python scripts/huggingface/download_hf.py --repo_id=genmo/mochi-1-preview --local_dir=data/mochi --repo_type=model
python scripts/huggingface/download_hf.py --repo_id=FastVideo/hunyuan --local_dir=data/hunyuan --repo_type=model</pre></div>
<p dir="auto">Then you can run the finetune with:</p>
<div data-snippet-clipboard-copy-content="bash scripts/finetune/finetune_mochi.sh # for mochi"><pre><code>bash scripts/finetune/finetune_mochi.sh # for mochi
</code></pre></div>
<p dir="auto"><strong>Note that for finetuning, we did not tune the hyperparameters in the provided script</strong></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">⚡ Lora Finetune</h3><a id="user-content--lora-finetune" aria-label="Permalink: ⚡ Lora Finetune" href="#-lora-finetune"></a></p>
<p dir="auto">Currently, we only provide Lora Finetune for Mochi model, the command for Lora Finetune is</p>
<div data-snippet-clipboard-copy-content="bash scripts/finetune/finetune_mochi_lora.sh"><pre><code>bash scripts/finetune/finetune_mochi_lora.sh
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Minimum Hardware Requirement</h3><a id="user-content-minimum-hardware-requirement" aria-label="Permalink: Minimum Hardware Requirement" href="#minimum-hardware-requirement"></a></p>
<ul dir="auto">
<li>40 GB GPU memory each for 2 GPUs with lora</li>
<li>30 GB GPU memory each for 2 GPUs with CPU offload and lora.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Finetune with Both Image and Video</h3><a id="user-content-finetune-with-both-image-and-video" aria-label="Permalink: Finetune with Both Image and Video" href="#finetune-with-both-image-and-video"></a></p>
<p dir="auto">Our codebase support finetuning with both image and video.</p>
<div dir="auto" data-snippet-clipboard-copy-content="bash scripts/finetune/finetune_hunyuan.sh
bash scripts/finetune/finetune_mochi_lora_mix.sh"><pre>bash scripts/finetune/finetune_hunyuan.sh
bash scripts/finetune/finetune_mochi_lora_mix.sh</pre></div>
<p dir="auto">For Image-Video Mixture Fine-tuning, make sure to enable the --group_frame option in your script.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">📑 Development Plan</h2><a id="user-content--development-plan" aria-label="Permalink: 📑 Development Plan" href="#-development-plan"></a></p>
<ul dir="auto">
<li>More distillation methods
<ul>
<li> Add Distribution Matching Distillation</li>
</ul>
</li>
<li>More models support
<ul>
<li> Add CogvideoX model</li>
</ul>
</li>
<li>Code update
<ul>
<li> fp8 support</li>
<li> faster load model and save model support</li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgement</h2><a id="user-content-acknowledgement" aria-label="Permalink: Acknowledgement" href="#acknowledgement"></a></p>
<p dir="auto">We learned and reused code from the following projects: <a href="https://github.com/G-U-N/Phased-Consistency-Model">PCM</a>, <a href="https://github.com/huggingface/diffusers">diffusers</a>, <a href="https://github.com/PKU-YuanGroup/Open-Sora-Plan">OpenSoraPlan</a>, and <a href="https://github.com/xdit-project/xDiT">xDiT</a>.</p>
<p dir="auto">We thank MBZUAI and Anyscale for their support throughout this project.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FTC bans hidden junk fees in hotel, event ticket prices (438 pts)]]></title>
            <link>https://www.cnbc.com/2024/12/17/ftc-bans-hidden-junk-fees-in-hotel-event-ticket-prices-.html</link>
            <guid>42445037</guid>
            <pubDate>Tue, 17 Dec 2024 20:36:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2024/12/17/ftc-bans-hidden-junk-fees-in-hotel-event-ticket-prices-.html">https://www.cnbc.com/2024/12/17/ftc-bans-hidden-junk-fees-in-hotel-event-ticket-prices-.html</a>, See on <a href="https://news.ycombinator.com/item?id=42445037">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-107257869" data-test="InlineImage"><p>U.S. President Joe Biden delivers remarks on protecting consumers from hidden junk fees during an event at the South Court Auditorium at Eisenhower Executive Office Building on June 15, 2023 in Washington, DC.</p><p>Alex Wong | Getty Images</p></div><div><p>The U.S. Federal Trade Commission passed a rule on Tuesday requiring ticket sellers, hotels and vacation rental sites to disclose total prices, including fees upfront, prohibiting them from concealing add-on charges until the last minute.</p><p>The rule is one of the final pieces of President Joe Biden's wide-ranging crackdown on junk fees that drive up consumer costs without providing visible benefits.</p><p>"We all know the experience of encountering a hidden fee at the very last stage of checkout — these junk fees sneak onto your bill and companies end up making you pay more because they can. Those fees add up, taking real money out of the pockets of Americans," Biden said in a statement.</p><p>President-elect Donald Trump could seek to withdraw the rule for further review, and Republicans who will have control of Congress could seek to vacate it by law.</p><p>The rule would require service fees, resort fees, and other charges commonly added to bookings to be included in advertised prices. The rule is narrower than what the FTC proposed in 2023 that would have broadly banned hidden and deceptive fees regardless of industry.</p><p>"I urge enforcers to continue cracking down on these unlawful fees and encourage state and federal policymakers to build on this success with legislation that bans unfair and deceptive junk fees across the economy," FTC Chair Lina Khan said in a statement.</p><p>The FTC estimates the rule would save U.S. consumers 53 million hours per year they would not have to spend sleuthing out total costs before making purchases.</p><p>Biden's regulators have taken aim at inflated and hidden fees, though their efforts have met with lawsuits by businesses and corporate interest groups.</p><p>A judge in Texas blocked a rule that would cap credit card late fees, and an appeals court in New Orleans blocked a requirement that airlines disclose baggage and other fees upfront. The cases are ongoing.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A pilot crashed a full passenger jet into the bay, didn't lose his job (2021) (105 pts)]]></title>
            <link>https://www.sfgate.com/sfhistory/article/san-francisco-historic-plane-crash-asoh-defense-16319360.php</link>
            <guid>42443987</guid>
            <pubDate>Tue, 17 Dec 2024 18:40:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sfgate.com/sfhistory/article/san-francisco-historic-plane-crash-asoh-defense-16319360.php">https://www.sfgate.com/sfhistory/article/san-francisco-historic-plane-crash-asoh-defense-16319360.php</a>, See on <a href="https://news.ycombinator.com/item?id=42443987">Hacker News</a></p>
Couldn't get https://www.sfgate.com/sfhistory/article/san-francisco-historic-plane-crash-asoh-defense-16319360.php: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Inside the War Against Headlight Brightness (159 pts)]]></title>
            <link>https://www.theringer.com/2024/12/03/tech/headlight-brightness-cars-accidents</link>
            <guid>42443406</guid>
            <pubDate>Tue, 17 Dec 2024 17:43:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theringer.com/2024/12/03/tech/headlight-brightness-cars-accidents">https://www.theringer.com/2024/12/03/tech/headlight-brightness-cars-accidents</a>, See on <a href="https://news.ycombinator.com/item?id=42443406">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><figure data-sentry-component="ArticleHero" data-sentry-source-file="article-hero.tsx"><figcaption><span>Getty Images/Ringer illustration</span></figcaption></figure><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">The sun had already set in Newfoundland, Canada, and Paul Gatto was working late to give me a presentation on headlights. This, it should be said, is not his job. Not even close, really. Gatto, 28, is a front-end developer by day, working for a weather application that’s used by the majority of Canadian meteorologists, he told me on a video call, occasionally hitting his e-cig or sipping on a Miller Lite. As to how he ended up as one of the primary forces in the movement to make car headlights less bright—a movement that’s become surprisingly robust in recent years—even Gatto can’t really explain.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">“It is fucking weird,” he said. “I need something else to do with my spare time. This takes a lot of it.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Gatto is the founder of the subreddit <a href="http://reddit.com/r/fuckyourheadlights/">r/FuckYourHeadlights</a>, the internet’s central hub for those at their wits’ end with the current state of headlights. The posts consist of a mishmash of venting, meme-ing, and community organizing. A common entry is a photo taken from inside the car of someone being blasted with headlights as bright as an atomic bomb, and a caption along the lines of <a href="http://reddit.com/r/fuckyourheadlights/comments/10s3rmy/how_is_this_fucking_legal/">“How is this fucking legal?!”</a> Or users will joke about going back in time and <a href="http://reddit.com/r/fuckyourheadlights/comments/1d4nthv/whats_the_poblem_with_their_headlights/">Skynet-style</a> killing the Audi lighting engineer who first rolled out LED headlights. Or they’ll discuss ways to write to their congresspeople, like Mike Thompson, House Democrat of California, who <a href="http://reddit.com/r/fuckyourheadlights/comments/1axtnfy/congress_gets_involved/">recently expressed support</a> for the cause.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">At its worst, the forum resembles Grampa Simpson writing a letter to the president to say that there are <a href="https://www.youtube.com/watch?v=O5dmxBUbzBU">too many states</a>. (“I am <em>not</em> a crackpot,” Grampa adds.) But at its best, it feels like a balm for those of us who have been pushed to optical-induced madness on the roads. For those who feel like, as headlights get brighter, it’s actually becoming harder to see.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">After I <a href="https://x.com/Nate_Rgrs/status/1662241673043116036">posted</a> about the subreddit on X last year, Gatto emailed me, and it wasn’t long before we were on a video call and he was giving a PowerPoint presentation he’d made the night before. It was titled “The Internet-Focused History of FuckYourHeadlights, or: How I Learned to Stop Worrying About Headlights and Start Worrying About Society Itself.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">“First, I’d like to teach you some words,” Gatto said, priming me for a conversation about the minutiae of government policy and auto engineering. There was “obfuscation” (the intentional act of making something hard to understand), “mutual recursion” (when two things are defined in terms of each other, creating a loop), and “Ouroboros” (the snake eating its tail). Around this point, Victor Morgan, who was also on the call, cut in. “Paul,” he said, “where are you going with this, bud?”&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Morgan does this kind of thing from time to time. The two are partners—moderating the subreddit together and working in tandem to research headlight arcana—but it’s a good cop–bad cop dynamic. Neatly dressed and carefully spoken, Morgan, 41, is a mechanical engineer and lives far from Gatto, in Greenville, South Carolina. One of the first times the two spoke, it was because Morgan wanted to tell Gatto he didn’t like the subreddit’s name. They’ve since become good friends.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Gatto is the one focused on the bigger picture: digging up publicly available information, refining the messaging of their cause, optimizing the subreddit for search engines (he’s <a href="https://x.com/BarneyRetina/status/1836228891175784570">proud</a> of how high up the subreddit appears if you google “bright headlights”). Morgan is the one who sees their ideas through with measurements and engineering: He’s created a device for your rear windshield that pops up a reflective surface when someone’s lights are glaring at you from behind (<a href="https://www.owmyeyes.com/products/owmyeyes-light-the-road-not-my-face">$70, homemade</a>, questionably legal), and he’s gone to car dealerships to measure the brightness of different headlights. (According to Morgan’s numbers, Teslas and Hondas are among the brightest.)</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">If you want Rust Cohle–worthy lines about how it’s all connected, you go to Gatto. (“The automakers and the insurers can all be classified as the same financial entity back at this point,” he told me. “They will doctor what they need to, as far as I can see.”) If you want an engineer-worthy dose of hard-nosed practicality, you go to Morgan. (He has a cat whom he just calls “Cat.”) They’re an unlikely pair, but they are <em>not</em> crackpots.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Headlight brightness might almost seem like too random a subject for anyone to be as invested in as they are. But as it turns out, that’s kind of the point. “There’s a lot of issues that I care about,” Morgan said. “This is one that I think is niche enough that I can have an influence on.” Gatto’s motivation comes from the experience of watching his partner, Liz, struggle to recover from being hit by a cab while walking across the street. He sees headlights as “a realistic and tangible attack surface on the current trend toward antihuman design in our world, primarily guided by the auto industry.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">But deep down, what motivates them is the same twitch in the eye that brought me to the subreddit in the first place. “I’m not a very rageful person,” Gatto said, “but for some reason, these lights brought it out of me. And I kind of realized that’s why I had to do something about it. Because no one’s going to come help us.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">There appear to be two types of drivers in North America these days: those who think about headlights only when one of theirs goes out, and those who fixate on them every time they drive at night. If you’re in the first camp, consider yourself lucky. Those in the second camp—aggravated by the excess glare produced in this new era of light-emitting diode headlights—are riled up enough that the National Highway Traffic Safety Administration receives more consumer complaints about headlights than any other topic, several insiders told me.&nbsp;</p><figure data-sentry-component="Component" data-sentry-source-file="image.tsx"><div data-radix-aspect-ratio-wrapper=""><p><img alt="" data-sentry-element="Image" data-sentry-source-file="image.tsx" loading="lazy" decoding="async" data-nimg="fill" sizes="100vw" srcset="https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphB_02-1-scaled.jpg&amp;w=640&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 640w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphB_02-1-scaled.jpg&amp;w=750&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 750w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphB_02-1-scaled.jpg&amp;w=828&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 828w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphB_02-1-scaled.jpg&amp;w=1080&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1080w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphB_02-1-scaled.jpg&amp;w=1200&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1200w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphB_02-1-scaled.jpg&amp;w=1920&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1920w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphB_02-1-scaled.jpg&amp;w=2048&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 2048w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphB_02-1-scaled.jpg&amp;w=3840&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 3840w" src="https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphB_02-1-scaled.jpg&amp;w=3840&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30"></p></div><figure><figcaption><br>According to numbers we pulled from the Insurance Institute for Highway Safety’s publicly available data,&nbsp;headlight brightness has roughly doubled since 2015.</figcaption></figure></figure><figure data-sentry-component="Component" data-sentry-source-file="image.tsx"><div data-radix-aspect-ratio-wrapper=""><p><img alt="" data-sentry-element="Image" data-sentry-source-file="image.tsx" loading="lazy" decoding="async" data-nimg="fill" sizes="100vw" srcset="https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphA_03-scaled.jpg&amp;w=640&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 640w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphA_03-scaled.jpg&amp;w=750&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 750w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphA_03-scaled.jpg&amp;w=828&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 828w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphA_03-scaled.jpg&amp;w=1080&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1080w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphA_03-scaled.jpg&amp;w=1200&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1200w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphA_03-scaled.jpg&amp;w=1920&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1920w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphA_03-scaled.jpg&amp;w=2048&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 2048w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphA_03-scaled.jpg&amp;w=3840&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 3840w" src="https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphA_03-scaled.jpg&amp;w=3840&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30"></p></div><figure><figcaption><br>And at the same time, the number of demerits issued for lack of brightness have dropped precipitously. In other words: It’s not just your imagination. Headlights are brighter.</figcaption></figure></figure><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">It’s not just in the aggrieved drivers’ imaginations. Going by the publicly available data of the&nbsp;Insurance Institute for Highway Safety, headlight brightness has roughly doubled in the past 10 years—although you probably don’t need convincing if you’ve been paying attention over that span. Something <em>happened </em>out there, and a zap of light causing you to grimace behind the wheel suddenly went from a rarity to a routine occurrence.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">As opposed to the sepia-toned halogen lights we had mostly been using for generations of vehicles, LED lights—which are now used for the vast majority of new cars—come out blazing white or blue, like an omnipresent police flashlight shining at you during a traffic stop. And in what can be seen as a flawed attempt to match LED capabilities on other vehicles, it’s also become not uncommon, anecdotally speaking, for people to have their high beams on even on crowded highways and streets—something that’s technically illegal because it’s deemed to be a danger to other drivers. The strange thing is, though, I can’t say I notice much of a difference between one car’s high beams and another’s low beams anymore.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">John D. Bullough, a program director at the Mount Sinai Light and Health Research Center, has been studying light and its ramifications on health for the past 30 years, and he’ll tell you that the difference between older light sources and LEDs is night and day. “The first 20 years or so, [lighting] technology was very stable,” he told me over the phone. “In other words, you had incandescent light bulbs at home, and you had fluorescent lights in your office and sodium lights on the streets, and nothing really changed very much. And then, suddenly, the last 10 years of that 30 years have been a whirlwind because of LEDs. I mean, they’ve changed everything. Everything is LED. There essentially aren’t light bulbs anymore.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">LEDs offer benefits over older light sources, which is why they’ve been fast-tracked into near-universal use <a href="https://www.vox.com/science/2023/8/12/23827110/light-bulb-incandescent-led-energy-efficiency-ban-explained">via government-mandated performance standards</a>. They last longer and require less energy, making them more environmentally friendly, and are more customizable, making them suited for endless purposes. But LEDs are fundamentally different from what came before them—the light can be carefully aimed as opposed to emitted in all directions—and they’re vastly more powerful. And as they were rolled out en masse at a rapid pace, any <a href="https://nymag.com/strategist/article/led-light-bulbs-investigation.html">potential repercussions</a> would have to be discovered on the fly.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">“We’re all like human experiments,” said Mark Baker, when I called him to talk about his nonprofit, the Soft Lights Foundation, the mission of which is to advocate “for the protection of people and the environment from the harms of visible light radiation emitted by products that use light-emitting diodes.” Baker’s concern is with the broader integration of LEDs in society, but he shows up regularly in the headlight world, having recently organized a <a href="https://www.softlights.org/wp-content/uploads/2024/03/NHTSA-Petition-to-Limit-Headlight-Intensity.pdf">petition</a> that gathered nearly 60,000 signatures demanding that NHTSA limit headlight intensity. Unlike Morgan and Gatto, however, this isn’t a nights and weekends gig for him.&nbsp;&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Baker was working as a middle school math teacher in Northern California and thought of himself “as a regular person” before the mass implementation of LEDs. Then the world shifted while he was in traffic one day around 2016. He remembers looking at a Cadillac that had daytime-running LEDs—the non-primary headlights that run at all times on many modern vehicles—and “when my brain saw this light, I couldn’t look away,” he said. “Even though it was intense, I was drawn to it, and I started to feel a presence I’ve never felt, like evil.” As LEDs became more common, Baker became overwhelmed and had a mental breakdown, ending up in the hospital. He was diagnosed with mild autism spectrum disorder—which he says explains his hyper-fixation on bright lights—and couldn’t go back to work because of the LEDs in his classroom.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">When I spoke to Baker, 59, he was living in a sparsely lit rural area that he moved to with his partner, where he had been focusing on the Soft Lights Foundation since founding it in 2021. Baker told me he’s heard from a variety of people with various diagnoses—epilepsy, photophobia, migraines, lupus, autism—who struggle with LEDs. “I’ve got a guy that calls me from time to time wanting to commit suicide because of these LED lights in the Blue Ridge [Mountains],” he said. “We know that individuals are highly individualized. Each of us is going to react differently.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Baker is among a group of people who feel that NHTSA, which is responsible for regulating automotive safety, should have adjusted the rule book to accommodate LEDs before they were allowed in new cars. This was how NHTSA approached previous fundamental changes to headlight technology, Baker points out. As headlights went from circular to rectangular and from sealed beams to replaceable bulbs, the rules and accommodations changed with them. “Well, when LED headlights came out,” Baker said, “they skipped all that. They just started selling cars with the LED headlights.”&nbsp;</p><figure data-sentry-component="Component" data-sentry-source-file="image.tsx"><div data-radix-aspect-ratio-wrapper=""><p><img alt="" data-sentry-element="Image" data-sentry-source-file="image.tsx" loading="lazy" decoding="async" data-nimg="fill" sizes="100vw" srcset="https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOne-day-energy-conservation-in-Ukraine-following-damaged-infrastructure-by-Russian-attacks-scaled.jpg&amp;w=640&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 640w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOne-day-energy-conservation-in-Ukraine-following-damaged-infrastructure-by-Russian-attacks-scaled.jpg&amp;w=750&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 750w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOne-day-energy-conservation-in-Ukraine-following-damaged-infrastructure-by-Russian-attacks-scaled.jpg&amp;w=828&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 828w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOne-day-energy-conservation-in-Ukraine-following-damaged-infrastructure-by-Russian-attacks-scaled.jpg&amp;w=1080&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1080w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOne-day-energy-conservation-in-Ukraine-following-damaged-infrastructure-by-Russian-attacks-scaled.jpg&amp;w=1200&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1200w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOne-day-energy-conservation-in-Ukraine-following-damaged-infrastructure-by-Russian-attacks-scaled.jpg&amp;w=1920&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1920w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOne-day-energy-conservation-in-Ukraine-following-damaged-infrastructure-by-Russian-attacks-scaled.jpg&amp;w=2048&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 2048w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOne-day-energy-conservation-in-Ukraine-following-damaged-infrastructure-by-Russian-attacks-scaled.jpg&amp;w=3840&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 3840w" src="https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOne-day-energy-conservation-in-Ukraine-following-damaged-infrastructure-by-Russian-attacks-scaled.jpg&amp;w=3840&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30"></p></div><figure><figcaption>The differences between blue-toned and sepia-toned headlights can be seen on a darkened street in Kyiv, Ukraine.</figcaption></figure><figcaption>Metin Aktas/Anadolu Agency via Getty Images</figcaption></figure><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">It is certainly true that Federal Motor Vehicle Safety Standard No. 108—NHTSA’s regulation covering all forms of vehicle lighting, conceived in 1968—has not been adjusted to create new restrictions for LEDs. That’s easy to tell because the requirements in the standard haven’t been adjusted <em>at all</em> since 1986. One person I spoke to, who previously worked at NHTSA and discussed their former employer on the condition of anonymity, described 108 as being among the biggest entries in the book, yet also “probably one of the least updated.” (In response to an interview request for this story, NHTSA asked that questions be emailed; in response to the questions, NHTSA provided a broad statement that did not answer specific questions, such as ones about the nature of updating 108. “Although headlighting technology has changed over the years,” the statement read, “NHTSA’s lighting standard has remained constant in limiting the amount of glaring light directed toward oncoming and preceding traffic.”)</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Several people I spoke to insisted that the main issue with 108’s guidelines when applied to LEDs is that there’s no maximum brightness for certain areas of a headlight. The guidelines set limits on areas of bulb emissions that tend to cause glare problems for other drivers, but those areas were determined based on the light output of older bulbs. LEDs’ output and maneuverability changed the game. Think of an LED headlight more like a pixelated television or computer screen rather than a light bulb. Because of that design, the luminosity of precise areas of the headlight can be limited while the overall brightness is pushed up, up, up.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Chris Trechter, a lighting-focused engineer who used to work for Magna International, the largest automobile parts manufacturer in North America, told me the company would adhere to 108 in making headlights for clients like General Motors but that the rule is “archaic.” “It does not account for LEDs,” he said, “and there are giant loopholes that allow you to throw basically unlimited light as long as you meet all the other aspects of 108.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">On a recent episode of the<em> Carmudgeon Show</em> podcast, auto journalist Jason Cammisa <a href="https://youtu.be/MkwjMV2of_8?t=697">described</a> a phenomenon occurring with some LED headlights in which there are observable minor spots of dimness among an otherwise bright field of light. “With complex arrays of LEDs and of optics,” he said, “car companies realized they can engineer in a dark spot where it’s being measured, but the rest of the field is vastly over-illuminated. And I’ve had now two car companies’ engineers, when I played stupid and said, ‘What’s the dark spot?’ … And the lighting engineers are all fucking proud of themselves: ‘That’s where they measure the fucking thing!’ And I’m like, ‘You assholes, you’re the reason that every fucking new car is blinding the shit out of everyone.’”&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Cammisa, who did not respond to an interview request, compared this situation to the massive dieselgate scandal, in which Volkswagen was caught rigging emissions tests. (Fines levied against VW ended up costing the company <a href="https://www.reuters.com/article/legal/vws-dieselgate-bill-hits-30-bln-after-another-charge-idUSKCN1C4270/">around $30 billion</a>.) To Cammisa, deliberately darkening specific areas of LEDs to bypass the testing system demonstrates a craven approach similar to cheating on emissions tests. He’s called it lightinggate. Or headlightgate. He’s workshopping the name.&nbsp;</p><figure data-sentry-component="Component" data-sentry-source-file="image.tsx"><div data-radix-aspect-ratio-wrapper=""><p><img alt="" data-sentry-element="Image" data-sentry-source-file="image.tsx" loading="lazy" decoding="async" data-nimg="fill" sizes="100vw" srcset="https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FMercedes-Headlight-Ad-2016.png&amp;w=640&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 640w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FMercedes-Headlight-Ad-2016.png&amp;w=750&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 750w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FMercedes-Headlight-Ad-2016.png&amp;w=828&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 828w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FMercedes-Headlight-Ad-2016.png&amp;w=1080&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1080w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FMercedes-Headlight-Ad-2016.png&amp;w=1200&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1200w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FMercedes-Headlight-Ad-2016.png&amp;w=1920&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1920w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FMercedes-Headlight-Ad-2016.png&amp;w=2048&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 2048w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FMercedes-Headlight-Ad-2016.png&amp;w=3840&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 3840w" src="https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FMercedes-Headlight-Ad-2016.png&amp;w=3840&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30"></p></div><figure><figcaption>This 2016 Mercedes-Benz ad campaign touting the power of the carmaker’s headlights has become notorious among anti-brightness activists.</figcaption></figure><figcaption>Mercedes-Benz</figcaption></figure><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">I reached out to over a dozen car companies for this story, and only one provided an interview: Audi. In subsequently talking to Audi spokesperson Mark Dahnke, I relayed Cammisa’s description of how LED headlights were being deceptively engineered, and Dahnke told me he was “not aware of anything like that.” But Trechter, the former auto lighting engineer, told me Cammisa’s account was “100 percent real.”&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">So why go through all this trouble just for more light? Cammisa believes it’s an <a href="https://youtu.be/MkwjMV2of_8?t=799">“arms race”</a>—part of a battle between automakers to make their cars seem as state of the art as possible. “‘I get into my <a href="https://lucidmotors.com/air">Lucid Air</a>, and I have great lighting in every direction,’” he said, taking on the theoretical perspective of a new customer. “‘Oh, my headlights are <em>great</em>!’” Consider it something like <a href="https://en.wikipedia.org/wiki/Loudness_war">the loudness war</a> in music, in which albums were being mixed at increasing volumes, particularly in the 2000s, to make the music more attention grabbing, at the cost of quality. The brightness war, if you will.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Another possible explanation comes via a nongovernmental entity that has become a major force in the automotive world: the IIHS, a nonprofit funded by insurance companies with the goal of limiting loss. In the absence of any real NHTSA presence in the modern headlight conversation, the IIHS’s headlight safety rating has become a North Star for auto manufacturers, ostensibly for advertising reasons.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">“It made our life hell to try and make light that bright,” said Trechter. “But GM wanted it for that safety rating, and that’s it.” According to Trechter, the way to get the best safety rating is to exploit the lack of intensity limits on certain areas of the headlight and make the light shine as far down the road as possible. “They would push us to get as much down-road punch as they could get,” he said, in reference to the automakers.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Matthew Brumbelow, a senior research engineer at the IIHS, explained the headlight safety rating in a more nuanced way. While “you can’t get a good rating and have super high glare,” he said, “you also can’t get a good rating and have a dim headlight that doesn’t glare anyone but also is too dim to help people avoid crashes on the road.” Brumbelow said both factors play into their rating but admitted it’s the brightness that they weigh more heavily. “That’s what we’ve seen,” he said. “A huge reduction in crash rates based on more light reaching the road.”&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">The “brighter is better” mentality is the ultimate thorn in the side of activists like Gatto and Morgan, who view it almost as an insult to their intelligence. Brumbelow pointed to a <a href="https://www.iihs.org/news/detail/good-iihs-headlight-ratings-linked-to-lower-crash-rates#:~:text=Controlling%20for%20differences%20in%20miles%20traveled%2C%20driver%2Drelated,single%2Dvehicle%20crash%20rate%2C%20compared%20with%20poor%2Drated%20ones.">2021 IIHS study</a> that demonstrated a 19 percent reduction in nighttime single-vehicle crashes for cars with good headlight safety ratings, but Morgan sees a major issue with that study. “Basically,” Morgan said, “it means that assholes with bright headlights are in less single-car accidents than the people that they blind.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">One logical solution to this debate would be to factor in crashes that have occurred due to excessive glare, but this has proved to be a challenge out of the reach of the IIHS and other headlight experts. If a car is in an accident due to another car’s excessive glare, for instance, the offending vehicle that caused the situation would likely never know it and just keep driving.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">The inability to clinically prove the dangers of headlight glare is at the heart of the issue. “You cannot mandate or prohibit something in the U.S. system without meeting a stringent cost-benefit requirement,” said Daniel Stern, chief editor of Driving Vision News and one of the foremost authorities in headlights and headlight policy.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Stern told me about a conversation he once had in the late 2000s with Richard Van Iderstine, then a recently retired automotive safety standards engineer at NHTSA with great rulemaking authority over headlights. Stern and Van Iderstine had met for lunch and continued talking into dinner, duking it out over the finer points of headlight philosophy. Two giants of the headlight world, going head to head. Stern remembers Van Iderstine telling him, “Look, I’m not stupid. I know what good lighting is, and I know what lousy lighting is. … Does glare cause crashes? Of course glare causes crashes. But I couldn’t prove it.” (Van Iderstine could not be reached for comment.)</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Finding a way to empirically measure the danger that glare presents to drivers is one problem. Another is that people can’t seem to agree on what the <em>cause</em> of excessive glare actually is. Stern, for his part, noted that the situation is “very, very complex” and “doesn’t have an answer that sounds like yes or no or 42.” That said, he told me he did recently finish a 38,000-word report on headlight glare for a non-U.S. government (he could not say which one) and is adamant that the biggest factor “by far” is headlight alignment—which is to say, quite literally, how accurately one’s headlights are pointed.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">This is the second-biggest thorn in Gatto and Morgan’s side. Headlight aim is important—no one is denying that. If any headlight, no matter how bright, is misaligned even slightly upward, it will cause glare for other drivers—and many headlights are poorly aligned out of the factory or become misaligned after an accident or installation error. But to someone like Morgan, alignment is only one part of the equation when headlights have become as intense as they have. “It’s a half-truth,” Morgan said, “without really saying that there’s other solutions here and that if you didn’t have laser-beam headlights, this issue would be less severe.” In his PowerPoint presentation, Gatto had drawn a penis on an image of Stern’s head. “That just kind of appeared there, sorry,” Gatto said.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Headlight alignment is certainly Stern’s primary foe—and he is not a fan of the likes of Baker and Morgan, either, whom he described in an email as having a fervor that “greatly outstrips their topical expertise and understanding, and likely qualifies them for IRS classification as religious entities.” But Stern does list other causes of glare as well. There’s headlight <em>condition</em> (a dirty lens can cause the light to refract in chaotic ways), headlight <em>size</em> (as LEDs become smaller, the “density” of the light increases, making it more intense), and headlight <em>color </em>(the eye is more sensitive to blue and white light, making glare seem more significant in modern LEDs, which are generally made in that color field).&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Vehicle size is another issue that comes up regularly, since NHTSA regulations for headlights don’t include a standardized mounting height, even as cars have <a href="https://www.vox.com/future-perfect/24139147/suvs-trucks-popularity-federal-policy-pollution">ballooned in size</a> in recent years. This means a perfectly aligned headlight in a larger car can still wreak havoc on a smaller car: “Where the [midsize] Civic might not give you glare,” Trechter, the former lighting engineer, said, “that F-350 [truck], if you’re sitting in a [sport-size] Miata, is gonna absolutely wreck your eyeballs.”</p><figure data-sentry-component="Component" data-sentry-source-file="image.tsx"><div data-radix-aspect-ratio-wrapper=""><p><img alt="" data-sentry-element="Image" data-sentry-source-file="image.tsx" loading="lazy" decoding="async" data-nimg="fill" sizes="100vw" srcset="https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOsram-scaled.jpg&amp;w=640&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 640w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOsram-scaled.jpg&amp;w=750&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 750w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOsram-scaled.jpg&amp;w=828&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 828w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOsram-scaled.jpg&amp;w=1080&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1080w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOsram-scaled.jpg&amp;w=1200&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1200w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOsram-scaled.jpg&amp;w=1920&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1920w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOsram-scaled.jpg&amp;w=2048&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 2048w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOsram-scaled.jpg&amp;w=3840&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 3840w" src="https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FOsram-scaled.jpg&amp;w=3840&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30"></p></div><figure><figcaption>LED headlight bulbs can be seen in a showroom in Osram's headquarters.</figcaption></figure><figcaption>Matthias Balk/picture alliance via Getty Images</figcaption></figure><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">In NHTSA’s brief statement to me, the only issue the organization brought up directly was aftermarket “LED conversion kits”—when headlight systems designed for halogen lights are swapped with LEDs—which it said are a “major contributor to excessive glare.” Due to the lack of data on what causes glare incidents on the road, it’s difficult to guess how much of a factor aftermarket LEDs are, but one thing’s for sure: They are illegal.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">By pointing to aftermarket LEDs, then, NHTSA essentially passes the buck to law enforcement. This is, perhaps not coincidentally, at the same time that traffic violations nationwide are in substantial decline; <a href="https://www.nytimes.com/interactive/2024/07/29/upshot/traffic-enforcement-dwindled.html">a <em>New York Times</em> study</a> reported a more than 50 percent reduction in traffic stops in many U.S. cities since the pandemic.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">The result of the hydra-headed headlight problem appears to be general paralysis; with numerous routes available to potentially improve the situation, none are really being pursued by automakers or regulators. “In engineering,” Gatto told me, “we talk about fail state. What happens when [a system] fails? Does it fail well, or does it fail horribly?” He added, “If you’re planning for multiple of these fail states all the time, maybe consider what the true impact of this is. … You have to kind of go against the whole ethos in order to actually evaluate: Are these too bright?”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">There is one path that certain automakers would like to take to improve headlights—but first it has to make it through NHTSA regulations. Adaptive driving beam technology takes advantage of LED capabilities to adjust the spray of light away from other cars and objects while maintaining high-capacity light on the road. When I got on the phone with the Audi representative, Mark Dahnke, to discuss headlight brightness, it quickly became clear that he was mainly taking the call in the interest of hyping ADB.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">“It basically puts other drivers in the shadow of your full high-beam light,” Dahnke explained, “such that they are not blinded while providing not just you with more light but everyone with more light.” Dahnke pointed out that ADB has been rolled out in Europe for some time now and is not in the U.S. solely due to NHTSA restrictions. In February 2022, NHTSA belatedly published a rule to allow ADB, but because of the contradictory way the rule is written, no car company has yet been able to find an engineering formula to make it work. “We’re now three different generations of lighting behind the rest of the world in the U.S.,” Dahnke said, exasperated.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Gatto and Morgan, unsurprisingly, are not fans of ADB. They point out that with the way the technology currently works, the light being strategically dimmed is the <em>high beam</em>, meaning that the low beam will stay as bright as ever. “The adaptive high beam is only going to put more light on the road,” Morgan said, adding that people from Europe post in the subreddit about hating the headlight situation there, too. (In a <a href="https://unece.org/sites/default/files/2024-04/GRE-90-20e-reduced.pdf">2024 European study</a> conducted by the Federation Internationale de l’Automobile, 81 percent of respondents said headlight glare needed to be reduced via regulation.) ADB, Morgan insisted, is a corporate over-solution to a simple problem. “That’s their panacea,” he said, “and it’s baloney.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">In the course of automotive history, technology has saved countless lives, taking car accidents from a peak of 30.8 deaths per 100,000 people in 1937 to 13.8 per 100,000 in 2022—a 55 percent improvement. That makes it difficult to dismiss the idea that something <em>like</em> ADB could be the solution to the headlight problem. But Gatto feels that he’s dealing with a “philosophical enemy” in the techno-optimist idea that we can innovate our way out of this. “They want to insert this technology to have a maximum amount of trust in it,” he said, “and they believe that any bit of convenience outweighs any drawback they could get from it.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Paris Marx, a tech critic who focuses on transportation and hosts the <em>Tech Won’t Save Us </em>podcast, is all too familiar with the trickiness of this conversation. LED headlight technology, when viewed through the same lens as evolving tech like self-driving cars, presents a vision of a world in which corporations are asking for perpetual forgiveness rather than permission.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">“In general,” Marx told me, “we think about the positive outcomes that can be the result of adopting these things, but then thinking about the negative impacts only comes quite a bit later.” Assessing the notion that something as simple as a headlight could get this out of control, he said, “As usual, we’re trying to play catch-up and figure out how we’re going to address the problems that have been created by this thing that we thought was a solution.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">The most compelling argument I heard in defense of brighter lights is that, while glare is clearly a hazard, it may not be as <em>much</em> of a hazard as limited vision on the road. That is to say, brighter headlights—which could illuminate something like a deer on a dark, rural highway from farther away than ever before—may be preventing more accidents than they cause by shining in other drivers’ eyes. You’ll notice every overly bright light searing your brain, but you likely won’t really appreciate the accident you never had.</p><figure data-sentry-component="Component" data-sentry-source-file="image.tsx"><div data-radix-aspect-ratio-wrapper=""><p><img alt="" data-sentry-element="Image" data-sentry-source-file="image.tsx" loading="lazy" decoding="async" data-nimg="fill" sizes="100vw" srcset="https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphC_02-scaled.webp&amp;w=640&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 640w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphC_02-scaled.webp&amp;w=750&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 750w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphC_02-scaled.webp&amp;w=828&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 828w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphC_02-scaled.webp&amp;w=1080&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1080w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphC_02-scaled.webp&amp;w=1200&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1200w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphC_02-scaled.webp&amp;w=1920&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 1920w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphC_02-scaled.webp&amp;w=2048&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 2048w, https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphC_02-scaled.webp&amp;w=3840&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30 3840w" src="https://www.theringer.com/_next/image?url=https%3A%2F%2Fwp.theringer.com%2Fwp-content%2Fuploads%2F2024%2F12%2FHeadlightsGraphC_02-scaled.webp&amp;w=3840&amp;q=75&amp;dpl=681dab30aca047401211554865665910a9df7e30"></p></div><figure><figcaption><p>Despite the increase in headlight brightness, data from the National Highway Traffic Safety Administration shows that fatal crashes in dark conditions remain relatively stable. In fact, crashes on lighted roads have risen slightly over the past two decades. It raises the question: Is all this extra brightness actually doing anything?</p>
</figcaption></figure><figcaption>NHTSA</figcaption></figure><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">“Is it a problem for people, including myself,” said Brumbelow, the IIHS engineer, “to be on the road and have bright headlights in my eyes and feel like I can’t see? Yes, that’s a problem. But the bigger follow-up question is: Is that my feeling, or is it a reality that I’m at an increased risk of crashing? And that’s really what we’re talking about.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Still, without concrete numbers indicating one way or another, this argument remains philosophical, and the stalemate continues. Morgan, anyway, is eager to figure this out from an engineering perspective, and he has the pie-in-the-sky idea of setting up some kind of nighttime traffic checkpoint, perhaps with the assistance of police, to assess high-glare events in everyday vehicles. “These are surmountable problems,” he said. “This is not like trying to determine divine intervention. These are problems made by men. We can figure this out. It just requires a little bit of effort.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">But he and Gatto know what they think the solution to all this is, and it’s admittedly the simplest proposal anyone has provided: Make the lights less bright. That’s it. “I’m just at: There’s too much glare in my eyes,” Morgan said, “and I want it to stop.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">At a certain point, I found myself more confused than when I started. There was name calling and corporate-interest lobbying and statistic volleying—often all at the same time. I needed a voice of reason. So I reached out to Ray Magliozzi.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Ray and his brother, Tom Magliozzi, hosted the radio show <em>Car Talk</em> for 35 years, from 1977 to 2012, serving as gurus of the car world and seasoning their advice with appropriately saucy New England–style banter and good humor. Tom died in 2014, but Ray still runs an auto mechanic shop in Cambridge and answers car questions via a blog. I decided to call the question line and ask Ray if he had any wisdom to share about headlights, not really expecting to get a reply.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">A few days later my phone started buzzing with a call from a New England area code, and there he was: the wonderful voice from the radio. I told Ray I was shocked to be talking to him, and he didn’t miss a beat: “You called <em>me</em>!”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Magliozzi, 75, is actually fine with the brightness of modern headlights—when they work. Alignment, he noted, is extra important with lights like these, and he abhors the aftermarket LEDs and light bars that people attach to their cars in case “they’re going to encounter a moose or something.” But more than anything else, what bothers Magliozzi about the state of headlights is the increasing number of people who drive with high beams on all the time at night. “I think it’s selfishness to a large degree,” Magliozzi said.</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">I had talked about this with many people in the headlight sphere: the possibility that the power of LEDs, supposed to be a bastion of safety, was actually contributing to an “I’ve got mine” mentality on the roads, which has become largely identifiable across the driving realm. It’s impossible to prove a causal relationship, but the rise of LEDs has directly coincided with <a href="https://www.nytimes.com/2024/01/10/magazine/dangerous-driving.html">the rise of reckless driving and road rage, as well as a new surge of fatal accidents</a>. “It seems like there’s an anti-collectivist vibe,” was how Gatto put it. “It’s a behavior that’s emerging.”</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">Some may genuinely not know they’re driving with their high beams on—digital car dashboards have gotten more complex and less intuitive in recent years—but it’s difficult to believe that most permanent high-beam users aren’t doing it deliberately, in an anti-collectivist kind of way. Magliozzi was bummed out about it. “When I learned to drive, 1,001 years ago,” he said, “we were taught to be courteous and polite. And I think we need to get back there.” Maybe that return toward courteousness has to start with automakers and regulatory bodies, however they decide to move forward with the LED headlight dilemma.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">The first time I heard Baker, the founder of the Soft Lights Foundation, tell his story about having to essentially drop out of society, I suddenly felt guilty. I may be the type to squint angrily at headlight glare, but at the end of the day, I install the light bulbs available to me and move on with my life. For certain people, it’s clearly a much worse relationship.&nbsp;</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">I asked Baker what kind of lighting he uses in his day-to-day, and he said he does use LEDs—it’s almost impossible not to at this point—and that he’s found some he’s happy with, like gentle, amber-colored, 300-lumen bulbs for the bedroom. That’s the beauty of LED lights: They can be made for any design or purpose. Sometimes they just have to be adjusted until they’re right.</p><p data-sentry-component="Component" data-sentry-source-file="paragraph.tsx">“But my favorite light is one that I replaced over the dining room table,” Baker said. His partner bought a chandelier-style fixture, and they put an incandescent bulb in it from a stockpiled supply. “It’s great,” Baker said. “I will go over and turn the switch on just to enjoy that light.”</p><div data-sentry-component="SingleCreator" data-sentry-source-file="article-creator-block.tsx"><div><p><a data-sentry-element="Link" data-sentry-source-file="creator.tsx" href="https://www.theringer.com/creator/nate-rogers"><img alt="" data-sentry-element="Image" data-sentry-source-file="creator.tsx" loading="lazy" decoding="async" data-nimg="fill" src="https://www.theringer.com/avatar-dark.svg"></a></p></div><div><a data-sentry-element="Link" data-sentry-source-file="creator.tsx" href="https://www.theringer.com/creator/nate-rogers"><p>Nate Rogers</p></a><p><span>Nate Rogers is a writer in Los Angeles. His writing has appeared in The New York Times, Los Angeles Times, Stereogum, and elsewhere.</span></p></div></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Moon (2621 pts)]]></title>
            <link>https://ciechanow.ski/moon/</link>
            <guid>42443229</guid>
            <pubDate>Tue, 17 Dec 2024 17:26:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ciechanow.ski/moon/">https://ciechanow.ski/moon/</a>, See on <a href="https://news.ycombinator.com/item?id=42443229">Hacker News</a></p>
Couldn't get https://ciechanow.ski/moon/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Adventures in OCR (102 pts)]]></title>
            <link>https://blog.medusis.com/38_Adventures+in+OCR.html</link>
            <guid>42443022</guid>
            <pubDate>Tue, 17 Dec 2024 17:00:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.medusis.com/38_Adventures+in+OCR.html">https://blog.medusis.com/38_Adventures+in+OCR.html</a>, See on <a href="https://news.ycombinator.com/item?id=42443022">Hacker News</a></p>
Couldn't get https://blog.medusis.com/38_Adventures+in+OCR.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I built an open-source data pipeline tool in Go (188 pts)]]></title>
            <link>https://github.com/bruin-data/bruin</link>
            <guid>42442812</guid>
            <pubDate>Tue, 17 Dec 2024 16:40:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/bruin-data/bruin">https://github.com/bruin-data/bruin</a>, See on <a href="https://news.ycombinator.com/item?id=42442812">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/bruin-data/bruin/blob/main/resources/logo-horizontal.svg"><img src="https://github.com/bruin-data/bruin/raw/main/resources/logo-horizontal.svg" width="500"></a>
</p>
<p dir="auto">Bruin is a data pipeline tool that brings together data ingestion, data transformation with SQL &amp; Python, and data quality into a single framework. It works with all the major data platforms and runs on your local machine, an EC2 instance, or GitHub Actions.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/bruin-data/bruin/blob/main/resources/demo.gif"><img alt="Bruin CLI - Demo" src="https://github.com/bruin-data/bruin/raw/main/resources/demo.gif" width="1200" data-animated-image=""></a></p>
<p dir="auto">Bruin is packed with features:</p>
<ul dir="auto">
<li>📥 ingest data with <a href="https://github.com/bruin-data/ingestr">ingestr</a> / Python</li>
<li>✨ run SQL &amp; Python transformations on <a href="https://bruin-data.github.io/bruin/#supported-platforms" rel="nofollow">many platforms</a></li>
<li>📐 table/view <a href="https://bruin-data.github.io/bruin/assets/materialization.html" rel="nofollow">materializations</a>, incremental tables</li>
<li>🐍 run Python in isolated environments using <a href="https://github.com/astral-sh/uv">uv</a></li>
<li>💅 built-in data quality checks</li>
<li>🚀 Jinja templating to avoid repetition</li>
<li>✅ validate pipelines end-to-end via dry-run</li>
<li>👷 run on your local machine, an EC2 instance, or <a href="https://bruin-data.github.io/bruin/cicd/github-action.html" rel="nofollow">GitHub Actions</a></li>
<li>🔒 secrets injection via environment variables</li>
<li><a href="https://bruin-data.github.io/bruin/vscode-extension/overview.html" rel="nofollow">VS Code extension</a> for a better developer experience</li>
<li>⚡ written in Golang</li>
<li>📦 <a href="https://bruin-data.github.io/bruin/getting-started/introduction/installation.html" rel="nofollow">easy to install</a> and use</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">Please see the installation instructions <a href="https://bruin-data.github.io/bruin/getting-started/introduction/installation.html" rel="nofollow">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Community</h2><a id="user-content-community" aria-label="Permalink: Community" href="#community"></a></p>
<p dir="auto">Join our Slack community <a href="https://join.slack.com/t/bruindatacommunity/shared_invite/zt-2dl2i8foy-bVsuMUauHeN9M2laVm3ZVg" rel="nofollow">here</a>.</p>
<p><a href="https://join.slack.com/t/bruindatacommunity/shared_invite/zt-2dl2i8foy-bVsuMUauHeN9M2laVm3ZVg" rel="nofollow">
    <img src="https://camo.githubusercontent.com/4949d95434f014372a1af298fc7abda4e9c80b49da84c6477034a26345edc094/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f736c61636b2d6a6f696e2d646c742e7376673f636f6c6f723d643935663566266c6f676f3d736c61636b" data-canonical-src="https://img.shields.io/badge/slack-join-dlt.svg?color=d95f5f&amp;logo=slack">
  </a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quickstart</h2><a id="user-content-quickstart" aria-label="Permalink: Quickstart" href="#quickstart"></a></p>
<p dir="auto">Take a look at our quickstart guide <a href="https://bruin-data.github.io/bruin/getting-started/introduction/quickstart.html" rel="nofollow">here</a>.</p>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>