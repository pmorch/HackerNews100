<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 16 Aug 2023 18:00:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[LK-99 isn’t a superconductor – how science sleuths solved the mystery (351 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-023-02585-7</link>
            <guid>37149349</guid>
            <pubDate>Wed, 16 Aug 2023 16:17:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-023-02585-7">https://www.nature.com/articles/d41586-023-02585-7</a>, See on <a href="https://news.ycombinator.com/item?id=37149349">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <figure>
 <picture>
  <source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-023-02585-7/d41586-023-02585-7_25924888.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-023-02585-7/d41586-023-02585-7_25924888.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px">
  <img alt="Shards of a LK-99 crystal." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-023-02585-7/d41586-023-02585-7_25924888.jpg">
  <figcaption>
   <p><span>Pure crystals of LK-99, synthesized by a team at the Max Planck Institute for Solid State Research in Stuttgart, Germany.</span><span>Credit: Pascal Puphal</span></p>
  </figcaption>
 </picture>
</figure><p>Researchers seem to have solved the puzzle of LK-99. Scientific detective work has unearthed evidence that the material is not a superconductor, and clarified its actual properties.</p><p>The conclusion dashes hopes that LK-99 — a compound of copper, lead, phosphorus and oxygen — marked the discovery of the first superconductor that works at room temperature and ambient pressure. Instead, studies have shown that impurities in the material — in particular, copper sulfide — were responsible for the sharp drops in electrical resistivity and partial levitation over a magnet, which looked similar to properties exhibited by superconductors.</p><p>“I think things are pretty decisively settled at this point,” says Inna Vishik, a condensed-matter experimentalist at the University of California, Davis.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-023-02481-0" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-023-02585-7/d41586-023-02585-7_25886824.jpg"><p>Claimed superconductor LK-99 is an online sensation — but replication efforts fall short</p></a>
 </article><p>The LK-99 saga began in late July, when a team led by Sukbae Lee and Ji-Hoon Kim at the Quantum Energy Research Centre, a start-up firm in Seoul, published preprints<sup><a href="#ref-CR1" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">1</a></sup><sup>,</sup><sup><a href="#ref-CR2" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">2</a></sup> claiming that LK-99 is a superconductor at normal pressure and temperatures up to at least 127 ºC (400 kelvin). All previously confirmed superconductors function only at extreme temperatures and pressures.</p><p>The extraordinary claim quickly grabbed the attention of the science-interested public and researchers, some of whom tried to replicate LK-99. <a href="https://www.nature.com/articles/d41586-023-02481-0" data-track="click" data-label="https://www.nature.com/articles/d41586-023-02481-0" data-track-category="body text link">Initial attempts did not see signs of room-temperature superconductivity</a>, but were not conclusive. Now, after dozens of replication efforts, many experts are confidently saying that the evidence shows LK-99 is not a room-temperature superconductor. (Lee and Kim’s team did not respond to <i>Nature</i>’s request for comment.)</p><h2>Accumulating evidence</h2><p>The South Korean team based its claim on two of LK-99’s properties: levitation above a magnet and abrupt drops in resistivity. But separate teams in Beijing, at Peking University<sup><a href="#ref-CR3" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">3</a></sup> and the Chinese Academy of Sciences<sup><a href="#ref-CR4" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">4</a></sup> (CAS), found mundane explanations for these phenomena.</p><p>Another study<sup><a href="#ref-CR5" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">5</a></sup>, by US and European researchers, combined experimental and theoretical evidence to demonstrate how LK-99’s structure made superconductivity infeasible. And other experimenters synthesized and studied pure samples<sup><a href="#ref-CR6" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">6</a></sup> of LK-99, erasing doubts about the material’s structure and confirming that it is not a superconductor, but an insulator.</p><p>The only further confirmation would come from the Korean team sharing their samples, says Michael Fuhrer, a physicist at Monash University in Melbourne, Australia. “The burden’s on them to convince everybody else,” he says.</p><p>Perhaps the most striking evidence for LK-99’s superconductivity was a <a href="https://sciencecast.org/casts/suc384jly50n" data-track="click" data-label="https://sciencecast.org/casts/suc384jly50n" data-track-category="body text link">video</a> taken by the Korean team that showed a coin-shaped sample of silvery material wobbling over a magnet. The team said the sample was levitating because of the Meissner effect — a hallmark of superconductivity in which a material expels magnetic fields. Multiple unverified videos of LK-99 levitating subsequently circulated on social media, but none of the researchers who initially tried to replicate the findings observed any levitation.</p><h2>Half-baked levitation</h2><p>Several red flags popped out to Derrick van Gennep, a former condensed-matter researcher at Harvard University in Cambridge, Massachusetts, who now works in finance but was intrigued by LK-99. In the video, the same edge of the sample seemed to stick to the magnet, and it seemed delicately balanced. By contrast, superconductors that levitate over magnets can be spun and even held upside-down. “None of those behaviors look like what we see in the LK-99 videos,” van Gennep says.</p><p>He thought LK-99’s properties were more likely the result of ferromagnetism. So he constructed a pellet of compressed graphite shavings with iron filings glued to it. A <a href="https://twitter.com/VanGennepD/status/1688052003216261120" data-track="click" data-label="https://twitter.com/VanGennepD/status/1688052003216261120" data-track-category="body text link">video</a> made by Van Gennep shows that his disc — made of non-superconducting, ferromagnetic materials — mimicked LK-99’s behaviour.</p><p>On 7 August, the Peking University team reported that this “half-levitation” appeared in their LK-99 samples because of ferromagnetism. “It’s exactly like an iron-filing experiment,” says Yuan Li, a condensed-matter physicist and study co-author. The pellet experiences a lifting force but it’s not enough to levitate — only enough to balance on one end.</p><p>Li and his colleagues measured their sample’s resistivity, and found no sign of superconductivity. But they couldn’t explain the sharp resistivity drop seen by the Korean team.</p><h2>Impure samples</h2><p>In their preprint, the Korean authors note one particular temperature at which LK-99’s showed a tenfold drop in resistivity, from about 0.02 ohms per centimetre to 0.002 ohms per cm. “They were very precise about it. 104.8ºC,” says Prashant Jain, a chemist at the University of Illinois Urbana–Champaign. “I was like, wait a minute, I know this temperature.”</p><p>The reaction that synthesizes LK-99 uses an unbalanced recipe: for every 1 part copper-doped lead phosphate crystal — pure LK-99 — it makes, it produces 17 parts copper and 5 parts sulfur. These leftovers lead to numerous impurities — especially copper sulfide, which the Korean team reported in its sample.</p><p>Jain, a copper-sulfide expert, remembered 104ºC as the temperature at which Cu<sub>2</sub>S undergoes a phase transition if exposed to air. Below that temperature, Cu<sub>2</sub>S’s resistivity drops dramatically — a signal almost identical to LK-99’s purported superconducting phase transition. “I was almost in disbelief that they missed it.” Jain published a preprint<sup><a href="#ref-CR7" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">7</a></sup> on the important confounding effect on 7 August.</p><p>The next day, the CAS team reported on the effects of Cu<sub>2</sub>S impurities in LK-99. “Different contents of Cu<sub>2</sub>S can be synthesized using different processes,” says Jianlin Luo, a CAS physicist. The researchers tested two samples — the first heated in a vacuum, which resulted in 5% Cu<sub>2</sub>S content, and the second in air, which gave 70% Cu<sub>2</sub>S content.</p><p>The first sample’s resistivity increased relatively smoothly as it cooled, and appeared similar to samples from other replication attempts. But the second sample’s resistivity plunged near 112 ºC (385K) — closely matching the Korean team’s observations.</p><p>“That was the moment where I said, ‘Well, obviously, that’s what made them think this was a superconductor,’” says Fuhrer. “The nail in the coffin was this copper sulfide thing.”</p><p>Making conclusive statements about LK-99’s properties is difficult, because the material is finicky and samples contain varying impurities. “Even from our own growth, different batches will be slightly different,” says Li. But Li argues that samples that are close enough to the original are sufficient for checking whether LK-99 is a superconductor in ambient coniditions.</p><h2>Crystal clear</h2><p>With strong explanations for the resistivity drop and the half-levitation, many in the community were convinced that LK-99 was not a room-temperature superconductor. But mysteries lingered — namely, what were the material’s actual properties?</p><p>Initial theoretical attempts using an approach called density functional theory (DFT) to predict LK-99’s structure had hinted at interesting electronic signatures called ‘flat bands’. These are areas where the electrons move slowly and can be strongly correlated. In some cases, this behavior leads to superconductivity. But these calculations were based on unverified assumptions about LK-99’s structure.</p><p>To better understand the material, the US–European group<sup><a href="#ref-CR5" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">5</a></sup> performed precision X-ray imaging of their samples to calculate LK-99’s structure. Crucially, the imaging allowed them to make rigorous calculations that clarified the situation of the flat bands: they were not conducive to superconductivity. Instead, the flat bands in LK-99 came from strongly localized electrons, which cannot ‘hop’ in the way a superconductor requires.</p><p>On 14 August, a separate team, at the Max Planck Institute for Solid State Research in Stuttgart, Germany, reported<sup><a href="#ref-CR6" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">6</a></sup> synthesizing pure, single crystals of LK-99. Unlike previous synthesis attempts that relied on crucibles, the researchers used a technique called floating zone crystal growth that allowed them to avoid introducing sulfur into the reaction, eliminating the Cu<sub>2</sub>S impurities.</p><p>The result was a transparent purple crystal — pure LK-99, or Pb<sub>8.8</sub>Cu<sub>1.2</sub>P<sub>6</sub>O<sub>25</sub>. Separated from impurities, LK-99 is not a superconductor, but an insulator with a resistance in the millions of ohms — too high to run a standard conductivity test. It shows minor ferromagnetism and diamagnetism, but not enough for even partial levitation. “We therefore rule out the presence of superconductivity,” the team concluded.</p><p>The team suggests that the hints of superconductivity seen in LK-99 were attributable to Cu<sub>2</sub>S impurities, which are absent from their crystal. “This story is exactly showing why we need single crystals,” says Pascal Puphal, a specialist in crystal growth and the Max Planck physicist who led the study. “When we have single crystals, we can clearly study the intrinsic properties of a system.”</p><h2>Lessons learned</h2><p>Many researchers are reflecting on what they’ve learned from the summer’s superconductivity sensation.</p><p>For Leslie Schoop, a solid-state chemist at Princeton University in New Jersey, who co-authored the flat-bands study, the lesson about premature calculations is clear. “Even before LK-99, I have been giving talks about how you need to be careful with DFT, and now I have the best story ever for my next summer school,” she says.</p><p>Jain points to the importance of old, often overlooked data — the crucial measurements that he relied on for the resistivity of Cu<sub>2</sub>S were published in 1951.</p><p>While some commentators have pointed to the LK-99 saga as a model for reproducibility in science, others say that it’s an unusually swift resolution of a high-profile puzzle. “Often these things die this very slow death, where it’s just the rumors and nobody can reproduce it,” says Fuhrer.</p><p>When copper oxide superconductors were discovered in 1986, researchers leapt to probe their properties. But nearly four decades later, there is still debate over the material’s superconducting mechanism, says Vishik. Efforts to explain LK-99 came readily. “The detective work that wraps up all of the pieces of the original observation — I think that’s really fantastic,” she says. “And it’s relatively rare.”</p>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Brand-new Linux release, which I'm calling the Debian Linux Release (1993) (156 pts)]]></title>
            <link>https://wiki.debian.org/DebianHistory?action=AttachFile&amp;do=get&amp;target=Debian-announcement-1993.txt</link>
            <guid>37147617</guid>
            <pubDate>Wed, 16 Aug 2023 14:30:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wiki.debian.org/DebianHistory?action=AttachFile&#x26;do=get&#x26;target=Debian-announcement-1993.txt">https://wiki.debian.org/DebianHistory?action=AttachFile&#x26;do=get&#x26;target=Debian-announcement-1993.txt</a>, See on <a href="https://news.ycombinator.com/item?id=37147617">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[How do we save water: Stop growing alfalfa in Imperial County (237 pts)]]></title>
            <link>https://www.desertsun.com/story/opinion/contributors/valley-voice/2023/02/05/growing-alfalfa-in-imperial-county-and-california-wastes-water/69860506007/</link>
            <guid>37146398</guid>
            <pubDate>Wed, 16 Aug 2023 13:00:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.desertsun.com/story/opinion/contributors/valley-voice/2023/02/05/growing-alfalfa-in-imperial-county-and-california-wastes-water/69860506007/">https://www.desertsun.com/story/opinion/contributors/valley-voice/2023/02/05/growing-alfalfa-in-imperial-county-and-california-wastes-water/69860506007/</a>, See on <a href="https://news.ycombinator.com/item?id=37146398">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><article><p>If California is&nbsp;<em>really</em>&nbsp;short of water, why are we shipping it to Asia?</p><partner-banner util-module-path="elements/partner" min-height="600" fluid="" outstream="" momentum=""></partner-banner><p>We can do one simple thing and our water supply crisis will be over. We can stop growing alfalfa.</p><p>The top water-using activity in California is growing alfalfa — a protein-rich type of hay. An alfalfa farmer can crop alfalfa 10 or even 12 times a year and sell it for $260 per ton. These are not the hardworking family farmers of yesteryear. They are giant agribusiness corporations pulling in $1.8 billion from selling&nbsp;<a href="https://protect-us.mimecast.com/s/tMG6CBBXwLtl3oQPECrtZoI?domain=apps1.cdfa.ca.gov">7 million tons of alfalfa&nbsp;</a>every year in California, according to a University of California, Davis study by Daniel Geisseler and William R. Horwath.</p><p>We make this business extremely profitable for them by selling them 3.4 million acre-feet (1 acre foot =325,851 gallons) of water every year for $35 to $60 per acre-foot. The water you get for your house costs you $800 per acre-foot today, and it could be double that in 10 years' time. You could supply the water needs of 40 million people with that 3.4 million acre-feet.</p><partner-inline util-module-path="elements/partner" placement="native-article_link" sizes="[[300, 250], [3, 3]]" min-height="250" fluid="" outstream=""></partner-inline><p>In Arizona, something even more insane is happening. Saudi Arabian companies are pumping up groundwater from beneath land they have purchased and are using it to grow alfalfa for export to the Middle East. They have no plan for replacing this scarce and finite groundwater that accumulated over thousands of years. Incredibly, Arizona does not regulate groundwater extraction in agricultural areas. California didn’t get serious about groundwater management until 2014 so we deserve some criticism too.</p><partner-inline util-module-path="elements/partner" placement="native-article_link" sizes="[[300, 250], [3, 3]]" min-height="250" fluid="" outstream=""></partner-inline><p>Alfalfa is used to feed farm animals like pigs and cows. But we export 70% of what we grow in California to Japan and China. The Japanese raise Kobe beef with it and send it back to us for $200 per pound. The Chinese use it to raise pigs to meet their rapidly expanding demand for pork as they become more affluent and eat more meat.</p><partner-banner util-module-path="elements/partner" fluid="" bottom="" lazy="" min-height="390" outstream=""></partner-banner><p>Why don’t they grow their own alfalfa? Because they&nbsp;<em>are&nbsp;</em>short of water and it is so much cheaper to buy ours. In fact, alfalfa has become an instrument for exporting subsidized water.</p><p>We need to ask ourselves: Is the California desert the right place to grow alfalfa? It needs around 6-foot depth of water applied to every field to sustain this crop for a year at the present cultivation intensity, according to a University of California study,&nbsp;<a href="https://protect-us.mimecast.com/s/y3TfCv2xPoUyoXmOMsXaQRE?domain=alfalfa.ucdavis.edu">“Irrigated Alfalfa Management.”</a></p><cta-atoms-container-inline util-module-path="elements/cta"></cta-atoms-container-inline><p>So, next time you see a truckload of hay going west on the freeway give it a wave!</p><p>Wave goodbye to $13,000 worth of scarce water that was sold to agribusiness for just $1,000 and is now headed overseas on that truck. And while this is happening, that slow-moving ecological train wreck, the Salton Sea, continues to dry up.</p><p>We need to fix this.</p><p><em>Gerald McKenna is a retired civil engineer who serves as secretary-treasurer on the Board of Directors of&nbsp; the Desert Water Agency. These are the writer’s personal opinions and do not reflect the official position of the Board or DWA. His email is&nbsp;<a href="mailto:gerald@geraldmckenna.com">gerald@geraldmckenna.com</a></em></p><partner-banner util-module-path="elements/partner" fluid="" bottom="" lazy="" min-height="600" outstream="" momentum=""></partner-banner><media-image image-set="https://www.gannett-cdn.com/presto/2023/02/02/PPAS/f98ff22b-8fdc-46b5-957e-b2de10220de6-Gerald_McKenna-8839-Edit4.jpg bestCrop, https://www.gannett-cdn.com/presto/2023/02/02/PPAS/f98ff22b-8fdc-46b5-957e-b2de10220de6-Gerald_McKenna-8839-Edit4.jpg?crop=2001,1501,x0,y300 4:3, https://www.gannett-cdn.com/presto/2023/02/02/PPAS/f98ff22b-8fdc-46b5-957e-b2de10220de6-Gerald_McKenna-8839-Edit4.jpg?crop=2001,2668,x0,y165 3:4, https://www.gannett-cdn.com/presto/2023/02/02/PPAS/f98ff22b-8fdc-46b5-957e-b2de10220de6-Gerald_McKenna-8839-Edit4.jpg?crop=2001,1126,x0,y450 16:9" image-alt="." credit="Gerald McKenna" caption="." orientation="vertical" util-module-path="elements/media"></media-image><lit-timestamp slot="timestamp" publishdate="2023-02-05 13:00:44 +0000 UTC" updatedate="2023-02-05 16:54:45 +0000 UTC"></lit-timestamp><p><a alt="Post the article to your Facebook Timeline" data-size="large" onclick="fireNavShareAnalytics('facebook');" rel="noopener" target="_blank"><svg view-box="0 0 24 24">
                <path d="M12.6143832,21 L3.99346182,21 C3.44462725,21 3,20.5550968 3,20.006476 L3,3.99345411 C3,3.44469364 3.44469709,3 3.99346182,3 L20.006608,3 C20.5552331,3 21,3.44469364 21,3.99345411 L21,20.006476 C21,20.5551667 20.5551632,21 20.006608,21 L15.4197395,21 L15.4197395,14.029408 L17.7594454,14.029408 L18.1097832,11.3128446 L15.4197395,11.3128446 L15.4197395,9.57849053 C15.4197395,8.79198274 15.6381418,8.25600363 16.7659836,8.25600363 L18.2044917,8.25537504 L18.2044917,5.82565895 C17.9557072,5.79255313 17.1017938,5.71858885 16.108332,5.71858885 C14.0343128,5.71858885 12.6143832,6.98457234 12.6143832,9.30945332 L12.6143832,11.3128446 L10.2686707,11.3128446 L10.2686707,14.029408 L12.6143832,14.029408 L12.6143832,21 L12.6143832,21 Z"></path>
            </svg><span>Facebook</span></a>
<a alt="Tweet about this article" data-size="large" onclick="fireNavShareAnalytics('twitter')" rel="noopener" target="_blank"><svg view-box="0 0 24 24">
                <path d="M21,6.77573131 C20.338616,7.07692308 19.6265188,7.28060672 18.8795563,7.3716143 C19.6423666,6.9035753 20.2276809,6.16143012 20.5034337,5.27735645 C19.7892235,5.71072589 19,6.02600217 18.1568938,6.19501625 C17.4849445,5.45937161 16.5245642,5 15.461701,5 C13.4236661,5 11.770206,6.69555796 11.770206,8.78656555 C11.770206,9.08342362 11.8019017,9.3716143 11.8652932,9.64897075 C8.79609086,9.4907909 6.07554147,7.98483207 4.25303751,5.69122427 C3.93502377,6.2524377 3.75330164,6.9035753 3.75330164,7.59696641 C3.75330164,8.91007584 4.40517697,10.0693391 5.39619651,10.7486457 C4.79186476,10.7302275 4.22134179,10.5579632 3.72266244,10.276273 L3.72266244,10.3228602 C3.72266244,12.1581798 4.9957739,13.6890574 6.68621236,14.035753 C6.37665082,14.1245937 6.05018489,14.1690141 5.71315372,14.1690141 C5.47543582,14.1690141 5.24300053,14.1462622 5.01796091,14.1018418 C5.4881141,15.6056338 6.85103011,16.7009751 8.46751189,16.7302275 C7.20390914,17.7464789 5.61067089,18.3521127 3.88114105,18.3521127 C3.58320127,18.3521127 3.28843106,18.3347779 3,18.3001083 C4.63444268,19.3726977 6.57633386,20 8.66085578,20 C15.4543053,20 19.1679873,14.2307692 19.1679873,9.22643554 C19.1679873,9.06175515 19.1648177,8.89707476 19.1584786,8.73564464 C19.8800845,8.20151679 20.5066033,7.53521127 21,6.77573131"></path>
            </svg><span>Twitter</span></a>
<a alt="Email this article" onclick="fireNavShareAnalytics('email')" rel="noopener" target="_blank"><svg view-box="0 0 24 24">
            <path d="M3,5.8757627 C3,5.39209232 3.39269552,5 3.8926228,5 L20.1073772,5 C20.6003592,5 21,5.40389442 21,5.8757627 L21,18.1242373 C21,18.6079077 20.6073045,19 20.1073772,19 L3.8926228,19 C3.39964084,19 3,18.5961056 3,18.1242373 L3,5.8757627 Z M12,11.09375 L3,6.74107143 L3,8.48214286 L12,12.8348214 L21,8.48214286 L21,6.74107143 L12,11.09375 Z"></path>
        </svg><span>Email</span></a></p></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Today I learned you can pause the Windows Task Manager moving apps around (165 pts)]]></title>
            <link>https://www.theverge.com/2023/8/16/23834125/microsoft-windows-task-manager-pause-shortcut</link>
            <guid>37146268</guid>
            <pubDate>Wed, 16 Aug 2023 12:49:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2023/8/16/23834125/microsoft-windows-task-manager-pause-shortcut">https://www.theverge.com/2023/8/16/23834125/microsoft-windows-task-manager-pause-shortcut</a>, See on <a href="https://news.ycombinator.com/item?id=37146268">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I can’t believe I’ve been struggling with apps in the Task Manager randomly moving around without realizing there’s a simple keyboard shortcut to pause the Task Manager and stop its contents in their tracks. Yup, all you have to do is hold down the CTRL key and it will pause the Task Manager on both Windows 10 and Windows 11, and perhaps even older versions of Windows, too.</p><p>This legitimately useful tip comes <a href="https://twitter.com/JenMsft/status/1691563112175165724">from Jen Gentleman</a>, a Microsoft employee on the Windows engineering team that regularly shares helpful shortcuts and tips for Windows. I’ve used Windows for more than 20 years, and I’m still learning the many ways you can do tasks in the operating system on a monthly basis.</p><p>If you’re used to turning to the Task Manager to end faulty tasks then you might not even need to open it at all soon. Microsoft is working on a <a href="https://www.theverge.com/2023/5/24/23736005/microsoft-windows-11-force-quit-taskbar-option-feature">force quit option to close apps</a> without the Task Manager in Windows 11 simply from a right-click option in the taskbar. But the hold CTRL option to pause the Task Manager will still be useful for everyone who hasn’t upgraded to Windows 11 just yet.</p><p>While I have your attention, you might also like to know that you can <a href="https://www.theverge.com/tldr/2022/3/24/22994423/windows-11-notepad-app-spin-gear-settings">spin the gear in Windows 11’s Notepad app</a>. It’s like a digital fidget spinner, and part of the many delightful little additions to Windows 11. Microsoft has hidden little Easter eggs like this in Windows for decades; there was even a hidden prompt in Windows 95 that was only <a href="https://twitter.com/thebookisclosed/status/1375531201071620100">discovered in 2021</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scientists are only beginning to understand how PFAS impacting our health (126 pts)]]></title>
            <link>https://www.nytimes.com/2023/08/16/magazine/pfas-toxic-chemicals.html</link>
            <guid>37145701</guid>
            <pubDate>Wed, 16 Aug 2023 11:57:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2023/08/16/magazine/pfas-toxic-chemicals.html">https://www.nytimes.com/2023/08/16/magazine/pfas-toxic-chemicals.html</a>, See on <a href="https://news.ycombinator.com/item?id=37145701">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2023/08/16/magazine/pfas-toxic-chemicals.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[They Tried to Kill Me (271 pts)]]></title>
            <link>https://www.nplusonemag.com/online-only/online-only/how-they-tried-to-kill-me/</link>
            <guid>37145491</guid>
            <pubDate>Wed, 16 Aug 2023 11:33:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nplusonemag.com/online-only/online-only/how-they-tried-to-kill-me/">https://www.nplusonemag.com/online-only/online-only/how-they-tried-to-kill-me/</a>, See on <a href="https://news.ycombinator.com/item?id=37145491">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>In 2022, <em>n+1</em> published four reports (<a href="https://www.nplusonemag.com/online-only/online-only/exodus-from-ukraine/" target="_blank" rel="noopener">1</a>, <a href="https://www.nplusonemag.com/online-only/online-only/sandbagging-in-odessa/" target="_blank" rel="noopener">2</a>, <a href="https://www.nplusonemag.com/online-only/online-only/leave-us-alone/" target="_blank" rel="noopener">3</a>, <a href="https://www.nplusonemag.com/issue-43/politics/in-kherson/" target="_blank" rel="noopener">4</a>) from the war in Ukraine by the Russian journalist Elena Kostyuchenko. In the following essay, Kostyuchenko describes—for the first time—why she fled Ukraine and reveals that she was poisoned last fall in Munich. (The essay originally appeared in Russian on <a href="https://meduza.io/feature/2023/08/15/ya-hochu-zhit-poetomu-ya-pishu-etot-tekst" target="_blank" rel="noopener">Meduza</a>’s website and was translated by Bela Shayevich.) Kostyuchenko’s book <a href="https://shop.nplusonemag.com/products/i-love-russia-by-elena-kostyuchenko" target="_blank" rel="noopener"><em>I Love Russia</em></a>, which includes her reporting from Ukraine and elsewhere, is forthcoming this fall from Penguin Press.</p><div><p><span>I didn’t want to write this</span> for a long time. I feel disgusted, afraid, ashamed.</p><p>I can’t write about everything I know because I have to protect the people who’ve saved my life.</p><p>On February 24, 2022, my country attacked Ukraine.</p><p>On February 24, I went to Ukraine on assignment from <em>Novaya Gazeta, </em>where I had been working for the previous seventeen years.</p><p>I crossed the Polish-Ukrainian border on the night of February 25.</p> <!-- Either there are no banners, they are disabled or none qualified for this location! --><p>Over the course of four weeks, thanks to the incredible support of countless Ukrainians, I was able to file four stories—from the border, Odesa, Mykolaiv, and Kherson. Kherson was under occupation. Getting in and out meant crossing the frontlines twice. In Kherson, Russian soldiers were kidnapping and torturing people. I was able to find people who had survived being tortured. By collating their stories, working in the field, I was able to find where the kidnapped people were being held—a former temporary detention center located at 3 Teploenergetiki Street. I learned the names of forty-four kidnapped people and the circumstances under which they were taken. I published my article and handed over what I had uncovered to the Ukrainian Prosecutor General’s office.</p><p>The next place that I was going to was Mariupol.</p><p>Mariupol was still resisting. There was active combat. On many days, there were no humanitarian corridors. The only occasionally passable road lay through Zaporizhzhia. It often came under fire, and, as you approached Mariupol, the Russian checkpoints began. Nevertheless, people traveled this road every day in order to try to rescue their loved ones from the city as it was being destroyed. Volunteers organized them into columns. I decided to travel with them.</p><p>On March 28, I entered Zaporizhzhia.&nbsp; Waiting at the checkpoint, (the Teroborona were examining my passport and press credentials), I started getting messages from friends. “Assholes.” “Hang in there.” “Let me know if I can help.” That’s how I found out that <em>Novaya Gazeta </em>had shut down. <em>Novaya </em>had received its second warning that year from the state censorship agency, Roskomnadzor, which meant it could now lose its license. I’d been anticipating this, I’d been waiting for it from the moment of the incursion, but I couldn’t know how painful it would be.</p><p>I decided I’d go to Mariupol anyway. Publish my piece wherever I could.</p><p>On March 29, I was meeting with volunteers and the people heading to Mariupol to rescue their relatives. I found someone willing to take me in their car despite my Russian passport.</p><p>We arranged to leave on the 31st.</p><p>I spent March 30, the eve of our trip, in a hotel. I was trying to gather my strength. A colleague from <em>Novaya </em>called me. She asked me if I was going to Mariupol. I was puzzled: only two people from the paper knew I was going to Mariupol—the editor-in-chief, Dmitry Muratov, and my editor Olga Bobrova. I said, Yes, I am going tomorrow. She said, “My sources have gotten in touch with me. They know that you’re going to Mariupol. They say that the Kadyrovites have orders to find you.”</p><p>The Kadyrovites, a Chechen subdivision of Rosgvardia, were actively engaged in the fighting around Mariupol—they manned the checkpoints. I knew that. My colleague said, “They’re not planning to hold you. They are going to kill you. That’s been approved.”</p><p>It was like running into a wall. I went deaf, everything went white. I said, “I don’t believe you.” She said, “That’s what I told them, too, that I didn’t believe them. Then they played me a recording of you talking to someone about Mariupol, planning your trip. I recognized your voice.”</p><p>She hung up, I sat down on the bed. I didn’t think anything, I just sat.</p><p>Forty minutes later, my source from Ukrainian military reconnaissance called me. He said, “We have information that an assassination of a female journalist from <em>Novaya Gazeta </em>is being organized in Ukraine. And all-points bulletin on you has been sent out to every Russian checkpoint.”</p><p>An hour later, Muratov called me. He said, “You can’t go to Mariupol anymore. You have to leave Ukraine this minute.”</p><p>But I couldn’t make myself go.</p><p>The following morning, I woke up to messages from an editor at <em>Novaya. </em>The Russian Prosecutor General’s Office and Roskomnadzor had sent them letters demanding they take my reporting from Ukraine down from their website, or else the site would be blocked. <em>Novaya </em>complied. Somehow, this was what crushed me. I started crying and couldn’t stop. Then rage came in place of the tears, and it filled my entire being.</p><p>I tried to find another way into Mariupol, looking to bypass the Russian checkpoints. This path did not exist—there was active combat everywhere. The only road was through Zaporizhzhia, and they were waiting for me on that road.</p><p>I was incapable of accepting my powerlessness. Rational arguments didn’t work on me. The only thing that stopped me from moving forward was thinking what would happen to the person who agreed to take me in their car. If I got killed, they wouldn’t be spared, either.</p><p>On the night of April 1, I left Ukraine.</p><p>I left in a very bad state. I had lice, mumps, and PTSD. My friends took me in, they passed me from hand to hand. My girlfriend Yana came from Russia, she took care of me, made sure I was eating and sleeping. I was planning on getting better, finishing the book I was writing, and going back to Russia. All of my work, my entire life, my mother and sister—they are all there. The worse the news from home got, the more I felt like I belonged there and nowhere else.</p><p>I thought about how they were going to kill me. But the more I thought about it, the calmer I got. I feel stupid and embarrassed remembering what was going through my head. I didn’t know who had issued the orders, I referred to the killers as “them.” I thought that they’d probably made an emotional decision. The war wasn’t working out the way they wanted at all, everything was going haywire. And I had just gotten in and out of Kherson, right under their noses—of course they’d gotten upset. They started looking into what I was doing, found out I was going to Mariupol, which was, in its entirety, one giant war crime, and this was their diabolical solution for keeping me out of there. The distance between the last Ukrainian checkpoint and the first Russian one was a few kilometers apart—a no-man’s-land, not under anyone’s control. The Russian soldiers could have claimed that I’d never even made it to them. People are always disappearing during a war. Who knows, maybe it’d been the Ukrainian soldiers who’d killed me? I am a Russian journalist after all, and the Ukrainians hate Russians, as everyone knows.</p><p>I thought, At least I’m alive, that is good.</p><p>On the evening of April 28, Muratov called me. He spoke in a very gentle voice. He said, “I know that you want to come home. But you cannot go back to Russia. They will kill you.”</p><p>I hung up the phone and started screaming. I stood in the street and screamed.</p><p>A month later, we were able to meet. Muratov said, They’ll make it look like a hate crime. The people on the right hate lesbians and you’re a lesbian.</p><p>Then I was working on my book. I wrote and only thought about what I was writing. There wasn’t room for anything else in my head and those were the best days.</p><p>At the end of September, I got in touch with Muratov again. I asked him to find out whether I could return to Russia. He called me back several days later. “No. No. No.”</p><p>I found an apartment in Berlin and moved there. On September 29, I began working for the website Meduza. We decided that my first reporting trip would be to Iran. I’d been there and I knew how to work there. I found people who would help me, got a visa, bought clothes. We decided that after Iran, I would go to Ukraine. Meduza asked me to submit the paperwork for a Ukrainian visa before I left.</p><hr><p><span>I couldn’t fill out an application</span> or make an appointment at the embassy on their website—it wouldn’t let me. The Ukrainian Ministry of Foreign Affairs hotline told me their website was being attacked by hackers, and until they were able to deal with it, it’d be impossible. I started looking for contacts within the embassy. I got someone to agree to see me in their consulate in Munich.</p><p>There is no justification for this, and there cannot be, but I have to say that I corresponded about my trip to Munich over Facebook Messenger. It’s not secure and I knew that. But I wasn’t in Russia, I was in Germany. I didn’t even think about the basic tenets of my security, the protocols I’d been following for years.</p><p>On the evening of October 17, I traveled to Munich. I took an overnight train, traveling in a seating car. I took off my shoes, lay down on the seat, and slept. People walked past me, they’d knock into my feet. I kept sleeping.</p><p>On the morning of October 18, I arrived. I went to meet my friend, tried to sleep, then went to the embassy. The staff there questioned me, asking what I was planning to do in Ukraine. They took my documents, but I still wasn’t able to apply for a visa—their internal system was glitching. We decided that I would come again another day.</p><p>My friend picked me up at the embassy and we went to get lunch. We sat outside at a restaurant. While we were sitting there, two different groups of her acquaintances happened to run into us. They came up to our table—there was a man, and then two women. I thought, What a small town Munich is, it really seems like everyone knows each other. I went to the bathroom and came back. All I could think about was the visa—I was unlikely to get it, but what if it worked out?</p><p>Then my friend took me to the train station. As we approached it, she said, “Listen, I have to tell you: you smell bad. Let me find you some deodorant.” She couldn’t find any. I remember I was shocked by what she said—she’s a very tactful person, and she would have never said anything if I hadn’t actually smelled terrible.</p><p>When I got on the train, I found my seat and immediately went to the bathroom. I wet some paper towels and started wiping myself off with them. I was covered in sweat. The sweat smelled strong and strange, like rotten fruit.</p><p>I sat down and started reading the manuscript of my book. After a while, I realized that I was just reading the same paragraph over and over and couldn’t move forward. My head ached.</p><p>I’d gotten Covid three weeks earlier. I thought, Do I really have it again? I called Yana. I said, I feel unwell. I said, I hope it’s not Covid, how will I go to Iran if it is?</p><p>I tried to get back to the book, but I kept feeling worse. My headache got so bad I couldn’t look at things anymore. I kept sweating, I went back to the bathroom and wiped myself off again.</p><hr><p><span>When I got out at the train station</span>, I realized that I couldn’t figure out how to get home. I knew that I needed to transfer to the subway, but I couldn’t figure out how. I considered going outside and calling a cab, but the very thought of having to find my location on the map in the app and figuring out how it corresponded to real streets terrified me. I thought to myself, this is too difficult a task, I won’t manage. I looked for the transfer &nbsp;for a long time. When I finally got down there, I burst into tears—I didn’t know what direction I was supposed to go in. Other passengers helped me.</p><p>The walk home from the subway is five minutes. It took much longer. Every few steps, I had to put my bag down—it seemed unbearably heavy—and rest.</p><p>On the stairs, I got short of breath. I thought to myself, This fucking Covid has really messed me up.</p><p>As soon as I got home, I went to sleep. I hoped that I would feel better when I got up.</p><p>But I only got worse.</p><p>I woke up from a pain in my stomach. It was strange—very strong, but not sharp, it was like it was being turned on and off. I tried to sit up and lay right back down. I felt so dizzy, it was like the room was spinning. With every rotation, I grew more nauseous. I got to the bathroom where I threw up.</p><p>I kept corresponding with the Iranians. I cried. It was supposed to be my first trip for my new job and now, this.</p><p>The pain in my stomach kept getting worse. It was painful to even touch the skin. I barely slept those first few nights—as soon as I would drift off, I would be woken up by the pain. My head kept spinning whenever I sat down or got up.</p><p>On the third day, it became clear that I was not going anywhere and that whatever I had wasn’t Covid.</p><p>It isn’t easy to see a doctor in Berlin. I was only able to get an appointment on October 28, ten days after I became ill.</p><p>It was a regular clinic in my neighborhood. The doctors—there were two of them—both immediately said that I had long Covid. “It can go on for up to six months. If you don’t feel better six months from now, come back.” But they did an ultrasound, too—all clear. They tapped on my stomach. I got them to do some blood tests. I came out of the clinic consoled—it was nothing, I’d get better soon.</p><p>The blood tests came back bad. The levels of ALT and AST in my liver were five times above normal. They tested my urine. There was blood in it.</p><p>The doctors stopped joking around. I was referred to another, more experienced specialist. She said that it was most likely viral hepatitis, which I had contracted during the war. We’ll figure out which one it is and then treat it, she said.</p><p>The hepatitis tests came back negative.</p><p>My symptoms kept changing. My stomach hurt less and I got less dizzy. But I was totally weak. My face started swelling. Then my fingers. I barely managed to take my rings off and could not get them back on again. My fingers looked like sausages. Then my feet started swelling. The swelling kept getting worse, I lost sight of my chin, my face was no longer my face. When I looked in the mirror, it took me a moment to recognize myself. Sometimes my heart would start racing as though I was running. Sometimes my palms and the bottoms of my feet would start to burn, turning red and shiny.</p><p>Everything was exhausting. It was hard to go down the stairs. Sometimes, we would go out for fifteen minutes, half an hour, and I would get so tired that I’d have to go home. I stopped being able to sleep, no longer from pain. It was as though my brain had forgotten how to fall asleep. I’d lay there for hours trying not to wake up Yana, looking up at the ceiling and wondering what was wrong with me.</p><p>My hepatic enzyme levels kept rising. There was still blood in my urine.</p><p>I kept going to doctors. The doctors would come up with theories, test them, come up with new ones. Autoimmune diseases, acute complicated complex pyelonephritis, systemic diseases.</p><p>Meduza put me in touch with a doctor they trusted. The doctor decided to retest me for hepatitis (the tests came back negative). While I was heading home from the hospital, he wrote to me, “Is it possible that you have been poisoned?” I replied, “No, I am not that dangerous.”</p><p>I told Yana, we laughed. She said, Oh yeah, the simplest explanation. She must have been poisoned—she is a Russian journalist.</p><hr><p><span>On December 12</span>, I went back to my neighborhood doctor. I got a new round of tests, the results had gotten worse, my ALT was seven times above normal. We sat in her office. She said nothing, going through her papers. Then she said, “Elena, there are two theories left. The first one is that the antidepressants you’re on may have suddenly started working aberrantly. But you recently changed medications and your symptoms and test results haven’t changed. That’s why we have a second theory. Please try to stay calm. You may have been poisoned.”</p><p>I laughed. The doctor stayed silent. I said, “That’s impossible.” She said, “We’ve ruled out all other options. I’m sorry. You need to go to the toxicology department at Charite.”</p><p>I spent the next three days lying there and thinking. I don’t remember what I was thinking about. Yana says that the first day I said it was stupid and that the doctors had made a mistake, it was just that they couldn’t diagnose me, and didn’t want to run any more tests. Then I stopped talking. Then I got in touch with Meduza and we started trying to figure out what to do next.</p><p>In order to get blood tests done for poisoning, you have to go to the police.</p><p>So I did. From the precinct, they sent me straight to the hospital. The police officers turned up too, to talk to me and the doctors.</p><p>My first session was with the Berlin Criminal Police and lasted nine hours. The police wanted to know everything: what I was working on, what I was planning to work on, whom I had been in contact with in Ukraine, which of my colleagues I was in contact now. I had to reconstruct October 17 and 18 minute by minute.</p><p>My clothes and apartment were checked for radiation. My body, too. They took the clothes I’d traveled to Munich with. Then the police did a “safety check” of my apartment. An officer asked me, “Why are your blinds open? You could easily be shot from the balcony across the way.” The police told me that I needed to follow new safety protocols. Like what? “Move. Take different routes home. Don’t get cabs directly to your destination, get out of cars a block away. Wear sunglasses.” “That’s it?” “Well, it will all help your chances.”</p><p>The police officers were mad at me. They didn’t show it, but after the third round of questioning, we started talking. The senior detective had run the investigation into the killing of Zelimkhan Khangoshvili, a former Chechen field commander, who had been shot in the Tiergarten in 2019. The killer was quickly caught thanks to eyewitnesses and security camera footage. His passport said he was Vadim Sokolov, but journalists and police established that his real name was Vadim Krasikov and that he had ties to the FSB. He received a life sentence in Germany for murder “on the orders of the Russian government, being a part of the Russian law enforcement apparatus.” The judge called what happened “state terrorism.” In 2022, Russia filed two separate requests to include Krasikov on the list of prisoners up for exchange, but Germany refused. A year earlier, the same detective investigated the poisoning of Petr Verzilov, the publisher of Mediazona and a member of Pussy Riot. He had been taken to Charite from Moscow on a private plane, convulsing and delirious. Verzilov’s friends found that the Berlin hospital was under surveillance. The police offered Verzilov protection and opened an investigation. “And we weren’t able to establish anything. Not even the substance used.” “How come?” “Because it’s impossible to ask a lab, ‘Was this person poisoned?’ You can only ask if there was a specific substance present in their body. And there are thousands of substances. That’s why it’s such a popular means of assassination.”</p><p>“We can’t understand why it took you this long to come to us. You should have called the police right away, as soon as you felt sick on the train. We would have met you at the station.”</p><p>“But I didn’t think I’d been poisoned. I’m still not sure.”</p><p>“Why didn’t you think so?”</p><p>“It seemed crazy to me. And I’m in Europe.”</p><p>“So what?”</p><p>“I felt like I was safe.”</p><p>“That is what drives us crazy,” the detective said. “You come here and act like you’re on vacation. Like this is some paradise. It doesn’t even occur to you to keep yourself safe. We have political killings here. The Russian special services are active in Germany. Your carelessness, yours and your colleagues, knows no bounds.”</p><p>I was not kept informed of the progress of the investigation.</p><p>On April 2, at a journalism conference, I was approached by Insider editor-in-chief Roman Dobrokhotov. He took me aside. “Lena, I have a personal question. But first I need to tell you something. Christo Grozev from Bellingcat and I have been investigating a series of poisonings in Europe. All the known targets are female Russian journalists. I want to ask you. You haven’t written anything for a long time—is it because you’ve been sick?”</p><p>And I told him what I am telling you now.</p><p>On May 2, I got a letter from the Berlin Prosecutor General’s office telling me that the investigation into my attempted assassination had been closed. The police had not found “any indication” that there had been an attempt to kill me. “Blood test results do not conclusively indicate poisoning.”</p><p>The doctors consulting Insider and Bellingcat said that the most likely explanation of what had happened to me was that I’d been poisoned with a chloroorganic compound. I passed this information on to the police. On July 21, the Prosecutor’s office reopened the case.</p><hr><p><span>How am I now?</span> The pain, nausea, and swelling have gone. I still have no energy. I left Meduza—I am a long way away from being able to return to the field. Right now, I can work three hours a day. This keeps increasing, but slowly. There are days when I can’t do anything. I lay there and try not to hate myself.</p><p>While I was writing this, I strove to establish the chronology of events, remember all the important details. But what details are really important? In November, a friend of mine came to Berlin. He is a publisher—not an activist, not a journalist, not a politician. He came over and he was horrified at the state I was in. He said, Do you understand that you may have been poisoned? Have you talked to your doctors about that? I said, I haven’t and I am not going to, that’s stupid. I said, Don’t try to infect me with your paranoia.</p><p>I lied to the police. It wasn’t that the idea of it “seemed crazy” to me. During my time at <em>Novaya Gazeta, </em>four of my colleagues were killed. I organized the funeral of Khimki journalist Mikhail Beketov, he’d been a friend. I knew that journalists got murdered. But I did not want to believe that they could kill me. I was protected from this thought by revulsion, shame, and exhaustion. It disgusted me to think that there were people who wanted me dead. I was ashamed to talk about it. Even with loved ones, let alone the police. And I felt how exhausted I was, how little strength I had left, that I wouldn’t be able to go on the run again.</p><p>My book is coming out in a few weeks. It is about how Russia descended into fascism. It is coming out in several languages simultaneously. The police believe that it might become a trigger. That the people who tried to kill me in Ukraine, and, possibly, in Germany, will try again.</p><p>I want to live.</p><p>That’s why I’m writing this.</p><p>I also want my colleagues and friends, activists, and political refugees currently living abroad to be careful. More careful than I have been. We are not safe and we will not be safe until there is regime change in Russia. The work we do helps to bring this regime down, and it is defending itself. If you are suddenly ill, please do not discount the possibility that you may have been poisoned. Tell your doctors. Fight for yourself. And if it’s already happened to you, please make contact with the investigative team at Insider or Bellingcat. They are looking for the people who are trying to kill us.</p><p><em>—Translated from the Russian by Bela Shayevich</em></p> <!-- START SUBSCRIBE LINK --><hr><p>If you like this article, please <a href="https://www.nplusonemag.com/subscribe/?affid=article">subscribe</a> or leave a tax-deductible tip below to support n+1.</p>  <!-- END SUBSCRIBE LINK --></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nintendo Is Trying to Patent Some Broad Tears of the Kingdom Mechanics (199 pts)]]></title>
            <link>https://kotaku.com/nintendo-is-trying-to-patent-some-really-broad-tears-of-1850730637</link>
            <guid>37145427</guid>
            <pubDate>Wed, 16 Aug 2023 11:25:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kotaku.com/nintendo-is-trying-to-patent-some-really-broad-tears-of-1850730637">https://kotaku.com/nintendo-is-trying-to-patent-some-really-broad-tears-of-1850730637</a>, See on <a href="https://news.ycombinator.com/item?id=37145427">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><figure data-id="153131fc5015a8537210d0cb2c367d6f" data-recommend-id="image://153131fc5015a8537210d0cb2c367d6f" data-format="jpg" data-width="1280" data-height="720" data-lightbox="true" data-alt="Zelda is seen standing on a sky island." data-recommended="false" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-alt="Zelda is seen standing on a sky island." data-link-reference="" data-link-target="" data-syndicationrights="true" data-imagerights="fair-use" data-hide="false" data-hidecredit="false"><p><span><div><picture><source media="(max-width: 37.31em)" type="image/jpeg" srcset="https://i.kinja-img.com/gawker-media/image/upload/c_fit,f_auto,g_center,q_60,w_645/153131fc5015a8537210d0cb2c367d6f.jpg"><source media="(min-width: 37.37em)" type="image/jpeg" srcset="https://i.kinja-img.com/gawker-media/image/upload/c_fit,f_auto,g_center,q_60,w_1315/153131fc5015a8537210d0cb2c367d6f.jpg"><img alt="Zelda is seen standing on a sky island." data-chomp-id="153131fc5015a8537210d0cb2c367d6f" data-format="jpg" data-alt="Zelda is seen standing on a sky island." data-anim-src="" src="https://i.kinja-img.com/gawker-media/image/upload/c_fit,f_auto,g_center,q_60,w_645/153131fc5015a8537210d0cb2c367d6f.jpg"></picture></div></span></p><p><figcaption>Screenshot<!-- -->: <!-- -->Nintendo / Kotaku</figcaption></p></div><span data-id="153131fc5015a8537210d0cb2c367d6f" data-recommend-id="image://153131fc5015a8537210d0cb2c367d6f" data-format="jpg" data-width="1280" data-height="720" data-lightbox="true" data-alt="Zelda is seen standing on a sky island." data-recommended="false" data-hide="false"></span></figure><div><p>Nintendo is registering several new patents from <em>The Legend of Zelda: Tears of the Kingdom</em> that are extremely broad, to the point where they seem unreasonable for other developers to be beholden to.<br></p><div data-video-id="194644" data-monetizable="true" data-position="sidebar" data-video-title="The Week In Games: Return To Hyrule" data-video-blog-id="9" data-video-network="kotaku" data-video-duration="165" data-playlist="194644,194088,191491" data-current="194644"><div><p>The Week In Games: Return To Hyrule</p></div><video disablepictureinpicture="" muted="" playsinline="" width="100%" height="100%" crossorigin="anonymous" preload="none"><source data-src="https://vid.kinja.com/prod/194644/194644_240p.mp4" label="240p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/194644/194644_480p.mp4" label="480p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/194644/194644_720p.mp4" label="720p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/194644/194644_1080p.mp4" label="1080p" type="video/mp4"><track kind="captions" label="English" src="https://kinja.com/api/videoupload/caption/20101.vtt" srclang="en"></video><div><ul><li data-label="">Off</li><li data-label="English">English</li></ul></div></div><p><span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://automaton-media.com/en/news/20230808-20590/&quot;,{&quot;metric25&quot;:1}]]" href="https://automaton-media.com/en/news/20230808-20590/" target="_blank" rel="noopener noreferrer"><em>Automaton</em></a></span>, a gaming website that focuses on Japanese games like <em>Zelda</em>, has a roundup of the 32 patents Nintendo put forth. Some of them are specific to Link’s latest adventure, including things like <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.j-platpat.inpit.go.jp/p0200&quot;,{&quot;metric25&quot;:1}]]" href="https://www.j-platpat.inpit.go.jp/p0200" target="_blank" rel="noopener noreferrer">Riju’s lightning ability</a></span>, which lets the player target enemies with a bow and bring down a lighting strike wherever the arrow lands. The weirder ones are related to baseline game design and coding that applies to plenty of other video games on the market. One of the hopeful patents relates to the physics of a character riding on top of a <!-- -->moving vehicle and reacting dynamically to it in a realistic manner.</p><figure data-id="134bce6323bf5735d06f9818838ebda9" data-recommend-id="image://134bce6323bf5735d06f9818838ebda9" data-format="jpg" data-width="1140" data-height="474" data-lightbox="true" data-alt="A character is shown standing on top of a moving vehicle." data-recommended="false" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-alt="A character is shown standing on top of a moving vehicle." data-link-reference="" data-link-target="" data-syndicationrights="true" data-imagerights="fair-use" data-hide="false" data-hidecredit="false"><p><span><div><picture><source media="(max-width: 37.31em)" type="image/jpeg" srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" data-srcset="https://i.kinja-img.com/gawker-media/image/upload/c_fit,f_auto,g_center,q_60,w_645/134bce6323bf5735d06f9818838ebda9.jpg"><source media="(min-width: 37.37em)" type="image/jpeg" srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" data-srcset="https://i.kinja-img.com/gawker-media/image/upload/c_fit,f_auto,g_center,q_60,w_1315/134bce6323bf5735d06f9818838ebda9.jpg"><img alt="A character is shown standing on top of a moving vehicle." data-chomp-id="134bce6323bf5735d06f9818838ebda9" data-format="jpg" data-alt="A character is shown standing on top of a moving vehicle." data-anim-src="" data-src="https://i.kinja-img.com/gawker-media/image/upload/c_fit,f_auto,g_center,q_60,w_645/134bce6323bf5735d06f9818838ebda9.jpg" src="https://i.kinja-img.com/gawker-media/image/upload/c_fit,f_auto,g_center,q_60,w_645/134bce6323bf5735d06f9818838ebda9.jpg"></picture></div></span></p><p><figcaption>Image<!-- -->: <!-- -->J-Plat Pat via Automaton<!-- --> (<span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.j-platpat.inpit.go.jp/p0200&quot;,{&quot;metric25&quot;:1}]]" href="https://www.j-platpat.inpit.go.jp/p0200" target="_blank" rel="noopener noreferrer">Fair Use</a></span>)</figcaption></p></div><span data-id="134bce6323bf5735d06f9818838ebda9" data-recommend-id="image://134bce6323bf5735d06f9818838ebda9" data-format="jpg" data-width="1140" data-height="474" data-lightbox="true" data-alt="A character is shown standing on top of a moving vehicle." data-recommended="false" data-hide="false"></span></figure><p>The distinction, according to Automaton’s translation of Japanese site Hatena Blog user <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://naoya2k.hatenablog.com/entry/2023/08/07/034044&quot;,{&quot;metric25&quot;:1}]]" href="https://naoya2k.hatenablog.com/entry/2023/08/07/034044" target="_blank" rel="noopener noreferrer">nayoa2k’s post</a></span> on the matter,<!-- --> is down to how <em>Tears of the Kingdom</em> codes these interactions. Link and the objects he rides on move together at the same <!-- -->speed, rather than Link being technically stationary on top of a moving object as is common in the physics of other games. The two are functionally the same, but given that plenty of video games displayed characters who can walk around on top of moving vehicles, it’s highly unlikely this kind of approach hasn’t been utilized before.<br></p><p>On top of trying to patent the tech, Nintendo seeks to patent the <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.j-platpat.inpit.go.jp/p0200&quot;,{&quot;metric25&quot;:1}]]" href="https://www.j-platpat.inpit.go.jp/p0200" target="_blank" rel="noopener noreferrer">loading screen that shows up</a></span> when the player is fast-<!-- -->traveling across Hyrule. This specifically refers to the screen that shows the map transition from the player’s starting point to their destination. Sure, that’s pretty specific and not something every game utilizes, but it’s still such a general concept that it feels almost petty to patent it when it’s hardly an iconic draw of <em>Tears of the Kingdom</em>.</p><p>It’s not uncommon for game developers to try to patent mechanics and features. One of the most famous examples is when Bandai Namco <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://kotaku.com/the-patent-on-loading-screen-mini-games-is-about-to-exp-1744705351&quot;,{&quot;metric25&quot;:1}]]" href="https://kotaku.com/the-patent-on-loading-screen-mini-games-is-about-to-exp-1744705351">had a patent on loading screen mini-games</a></span>, which finally ended in 2015.</p><p>Who knows if these patents actually go anywhere? But when game design concepts are gatekept like this, it only leads to a loss of innovation for other devs. Though these specific patents are small in the grand scheme of things, they can be a slippery slope for things like WB <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://kotaku.com/after-years-of-trying-wb-games-successfully-patented-s-1846213089&quot;,{&quot;metric25&quot;:1}]]" href="https://kotaku.com/after-years-of-trying-wb-games-successfully-patented-s-1846213089">patenting <em>Shadow of Mordor</em>’s Nemesis System</a></span>, which should be in more games.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Htmx is part of the GitHub Accelerator (658 pts)]]></title>
            <link>https://htmx.org/posts/2023-06-06-htmx-github-accelerator/</link>
            <guid>37144985</guid>
            <pubDate>Wed, 16 Aug 2023 10:19:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://htmx.org/posts/2023-06-06-htmx-github-accelerator/">https://htmx.org/posts/2023-06-06-htmx-github-accelerator/</a>, See on <a href="https://news.ycombinator.com/item?id=37144985">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
  
  <p>We are excited to announce that htmx has been accepted into the first class of the 
<a rel="noopener" target="_blank" href="https://accelerator.github.com/">GitHub Open Source Accelerator</a>!  This is a tremendous opportunity to work with and
learn from some of the most successful open source developers and projects, and a great chance to get the message
out about hypermedia and htmx.</p>
<p>We plan on using this opportunity to begin work on htmx 2.0 and, we hope, possibly learn how to make working on htmx
a full time job!</p>
<p>Here are some of the other open source projects that we have met through the GitHub accelerator and that we recommend 
people check out:</p>
<ul>
<li><a href="https://boxyhq.com/">BoxyHQ</a> - BoxyHQ’s suite of APIs for security and privacy helps engineering teams build and ship compliant cloud applications faster.</li>
<li><a href="https://cal.com/">Cal.com</a> - Cal.com is a scheduling tool that helps you schedule meetings without the back-and-forth emails.</li>
<li><a href="https://www.crowd.dev/">Crowd.dev</a> - Centralize community, product, and customer data to understand which companies are engaging with your open source project.</li>
<li><a href="https://documenso.com/">Documenso</a> - The Open-Source DocuSign Alternative. We aim to earn your trust by enabling you to self-host the platform and examine its inner workings.</li>
<li><a href="https://erxes.io/">Erxes</a> - The Open-Source HubSpot Alternative. A single XOS enables to create unique and life-changing experiences ​​that work for all types of business.</li>
<li><a href="https://formbricks.com/">Formbricks</a> - Survey granular user segments at any point in the user journey. Gather up to 6x more insights with targeted micro-surveys. All open-source.</li>
<li><a href="https://forwardemail.net/">Forward Email</a> - Free email forwarding for custom domains. For 6 years and counting, we are the go-to email service for thousands of creators, developers, and businesses.</li>
<li><a href="https://gitwonk.com/">GitWonk</a> - GitWonk is an open-source technical documentation tool, designed and built focusing on the developer experience.</li>
<li><a href="https://www.hanko.io/">Hanko</a> - Open-source authentication and user management for the passkey era. Integrated in minutes, for web and mobile apps.</li>
<li><a href="https://infisical.com/">Infisical</a> - Open source, end-to-end encrypted platform that lets you securely manage secrets and configs across your team, devices, and infrastructure.</li>
<li><a href="https://novu.co/">Novu</a> - The open-source notification infrastructure for developers. Simple components and APIs for managing all communication channels in one place.</li>
<li><a href="https://openbb.co/">OpenBB</a> - Democratizing investment research through an open source financial ecosystem. The OpenBB Terminal allows everyone to perform investment research, from everywhere.</li>
<li><a href="https://www.sniffnet.net/">Sniffnet</a> - Sniffnet is a network monitoring tool to help you easily keep track of your Internet traffic.</li>
<li><a href="https://typebot.io/">Typebot</a> - Typebot gives you powerful blocks to create unique chat experiences. Embed them anywhere on your apps and start collecting results like magic.</li>
<li><a href="https://www.webiny.com/">Webiny</a> - Open-source enterprise-grade serverless CMS. Own your data. Scale effortlessly. Customize everything.</li>
<li><a href="https://webstudio.is/">Webstudio</a> - Webstudio is an open source alternative to Webflow</li>
</ul>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Is this a good book for me, now? (145 pts)]]></title>
            <link>https://maryrosecook.com/blog/post/is-this-a-good-book-for-me-now</link>
            <guid>37144601</guid>
            <pubDate>Wed, 16 Aug 2023 09:23:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://maryrosecook.com/blog/post/is-this-a-good-book-for-me-now">https://maryrosecook.com/blog/post/is-this-a-good-book-for-me-now</a>, See on <a href="https://news.ycombinator.com/item?id=37144601">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p>I used to believe that every book has an objective value. And I used to believe that this value is fixed and universal.</p>

<p>Now, I believe it’s much more useful to say something in this form: this book has this value to this person in this context.</p>

<p>For example, Mindset by Carol Dweck was life changing to me when I read it in 2016.</p>

<p>The “me” part is important because I grew up thinking that intelligence is fixed and my skill in each activity I tried was based on talent and was fixed. So I thought I should to do the things I had a knack for, and I thought that the things I found difficult would stay difficult. Learning about a growth mindset was extremely valuable to me.</p>

<p>The 2016 part - the context - was also important. I’d just spent the last three years working at the Recurse Center, a place and community suffused with the idea that people can grow. I was primed for these ideas.</p>

<p>A second example. Around ten years ago I read You and your research by Richard Hamming. This is an essay by a mathematician who did ground-breaking research into telecommunications. He relates this anecdote:</p>

<blockquote>
  <p>I had been eating for some years with the Physics table at the Bell Telephone Laboratories restaurant…Fame, promotion and hiring by other companies ruined the average quality of the people so I shifted to the Chemistry table in another corner of the restaurant. I began by asking what the important problems were in chemistry, then later what important problems they were working on, and finally one day said, “If what you are working on is not important and not likely to lead to important things, then why are you working on it?” After that, I was not welcome and had to shift to eating with the Engineers.</p>
</blockquote>

<p>I read that ten years ago without effect. I read it again a couple of years ago and it helped me figure out what I want to work on. The same text and the same reader. A completely different outcome.</p>

<p>I think what changed is my context. Ten years ago, if I’d even tried to work on foundational problems in my field - programming - I’d just have kind of paddled around and had no idea how to make progress. I didn’t have the knowledge of the history of computing or programming to be able to make any kind of headway. In 2021, I did, because I’d accrued it.</p>

<p>The idea that a book’s value is best judged alongside the notional reader and their current context has some corollaries:</p>

<p>First, reading the books that your heroes cite as important will not necessarily be rewarding. If you admire Bret Victor for his work on computing interfaces, only some of his library will be high value to you because his library also includes lots of books that have nothing to do with UI.</p>

<p>Second, yes, it’s likely that “great books” may be high value in some more universal sense that is independent of reader and context. And, yes, this high value may come from something inherent in the quality of the books, rather than from the fact that they are about themes that are more relevant to more people. Yes, I probably wouldn’t dispute this. But I suspect that relevance to person and context is a better guide to what to read.</p>

<p>Third, book recommendation systems based on your reading history can be helpful, but only so much. You, now, are not represented by your reading history. You’ve changed. Making recommendations based on books you read twenty years ago might produce good books for you, now. But probably not.</p>

<p>What aspects of me and my context affect the value of a book?</p>

<p>First, what are my fantasies? Some of my friends have sci-fi fantasies. They love the idea of living on a space ship and landing on planets and fighting aliens and using advanced technology and all that bilge. That fantasy life appeals to them. Whereas I love the world of P.G. Wodehouse. The gentleman’s life, the flitting from manor to manor, the purloining of cow creamers to avoid the homicidal fellow guest. I don’t think either world is any more rich or meaningful or worthwhile than the other. It’s just personal taste.</p>

<p>Second, what is new to me? A while ago, I started reading The Little Kingdom. It’s a book about the early history of Apple. But I put it aside quickly. It wasn’t a bad book. I just already knew everything in it because I’ve read many other histories of Apple. This same thing can happen when coming much later to a book that was ahead of its time. It can seem like old hat because it’s already part of your cultural context.</p>

<p>Third, what am I ready for? I’m trying to get better at graphic design. I recently read a book about grid systems. It was pretty good. But I’m not really ready for that level of depth, so the book wasn’t very high value to me. This type of context is perhaps the most powerful. It was what was missing with Hamming and present with Dweck. I think it’s the main difference between learning slowly and learning quickly. Vygotsky called it the Zone of Proximal Development.</p>

<p>Fourth, what am I doing right now? I have a book on my shelves called Game Feel that is about making video games that feel physically good to play. I’m really excited to read it. But I’m holding off because I’m not currently making a game where the focus is on a good feel. If I read it at the moment, I’d retain and adopt a lot less of it than if I were to wait for when I can apply it.</p>

<p>These things helps me make better choices. There is another set of techniques that help me make a book as good as it can be for me, now:</p>

<p>First, skipping sections that aren’t good. This is tricky. Reading is a place. The more you skip, the more it becomes browsing. And browsing is not a place. You want to be in the place.</p>

<p>Second, dropping books that aren’t good. I find this hard because I feel good about finishing lots of books. But dropping bad books means I will be able to read so many more good books in my lifetime. When I drop a book, I try to say, “it’s not me. It’s not the book. It’s just not the book for me, now.” Even this is hard. Not getting very much out of Anna Karenina, supposedly one of the aesthetic and emotional heights of human expression and experience, doesn’t feel great. But, that’s the way it goes.</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why Tailwind CSS Won (140 pts)]]></title>
            <link>https://matt-rickard.com/why-tailwind-css-won</link>
            <guid>37143837</guid>
            <pubDate>Wed, 16 Aug 2023 07:27:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matt-rickard.com/why-tailwind-css-won">https://matt-rickard.com/why-tailwind-css-won</a>, See on <a href="https://news.ycombinator.com/item?id=37143837">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next"><h2></h2><p><span><div><p>Aug 14, 2023</p><article><div><p>Tailwind CSS is the new ubiquitous frontend framework. It replaces a generation of sites built with Twitter Bootstrap. However, Tailwind CSS is not a UI framework itself but has become synonymous to some degree with the UI components shipped through Tailwind UI (which is a UI framework). Why did Tailwind CSS become so popular? A few hypotheses:</p><ul><li><strong>No context switching from application logic. </strong>The tagline on the website reads, <em>“Rapidly build modern websites without ever leaving your HTML.” </em>That’s partly true, but few developers are writing HTML (instead, they are writing JSX or TSX). Switching to a CSS file to change styles is a costly context switch. Instead, developers write CSS as utility classes right in their application. This also vastly simplifies complex CSS build pipelines (which rarely worked).</li><li><strong>Copy-and-pastable. </strong>Bootstrap provided templates that were easy to get started with. It became the de facto landing page for any side project or new startup. But designs weren’t copy-pastable. Doing so would require you to copy the CSS and HTML. Instead, TailwindCSS is supremely easy to copy — everyone works with the same utility classes, so you can just copy and paste a list of classes or an HTML block into your application, and it should just work.</li><li><strong>Fewer dependencies, smaller surface. </strong>Tailwind is tree-shaken by default and doesn’t have its own ideas of grids or flexboxes (it just defaults to the underlying CSS concepts). Compare this to the last-generation kits like Bootstrap, which had a surface that forced users to adopt JS, HTML, CSS, and CSS build systems like Saas. Tailwind is easy to coexist with other frameworks.</li><li><strong>Reusability. </strong>For many years, developers thought that CSS reusability came through adding class hierarchies to CSS through preprocessors like Saas and Less. The best way to write the least amount of CSS is to just compose basic styles (without defining custom ones).</li></ul></div></article></div><div><p>Daily posts on startups, engineering, and AI</p></div></span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Carl Sagan testifying before Congress on climate change (1985) [video] (135 pts)]]></title>
            <link>https://www.youtube.com/watch?v=Wp-WiNXH6hI</link>
            <guid>37143159</guid>
            <pubDate>Wed, 16 Aug 2023 05:28:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=Wp-WiNXH6hI">https://www.youtube.com/watch?v=Wp-WiNXH6hI</a>, See on <a href="https://news.ycombinator.com/item?id=37143159">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[NetMaker: Connect Everything with a WireGuard VPN (257 pts)]]></title>
            <link>https://www.netmaker.io/</link>
            <guid>37142388</guid>
            <pubDate>Wed, 16 Aug 2023 03:00:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.netmaker.io/">https://www.netmaker.io/</a>, See on <a href="https://news.ycombinator.com/item?id=37142388">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>Privacy Preference Center</p></div><div><p>When you visit websites, they may store or retrieve data in your browser. This storage is often necessary for the basic functionality of the website. The storage may be used for marketing, analytics, and personalization of the site, such as storing your preferences. Privacy is important to us, so you have the option of disabling certain types of storage that may not be necessary for the basic functioning of the website. Blocking categories may impact your experience on the website.</p></div><div><p><strong>Manage Consent Preferences by Category</strong></p></div><div><p>These items are required to enable basic website functionality.</p></div><div><p>These items are used to deliver advertising that is more relevant to you and your interests. They may also be used to limit the number of times you see an advertisement and measure the effectiveness of advertising campaigns. Advertising networks usually place them with the website operator’s permission.</p></div><div><p>These items allow the website to remember choices you make (such as your user name, language, or the region you are in) and provide enhanced, more personal features. For example, a website may provide you with local weather reports or traffic news by storing data about your current location.</p></div><div><p>These items help the website operator understand how its website performs, how visitors interact with the site, and whether there may be technical issues. This storage type usually doesn’t collect information that identifies a visitor.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Putting Down the Pen: Reflecting on Oryx’s Journey (158 pts)]]></title>
            <link>https://www.oryxspioenkop.com/2023/08/putting-down-pen-reflecting-on-oryxs.html</link>
            <guid>37141463</guid>
            <pubDate>Wed, 16 Aug 2023 01:01:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.oryxspioenkop.com/2023/08/putting-down-pen-reflecting-on-oryxs.html">https://www.oryxspioenkop.com/2023/08/putting-down-pen-reflecting-on-oryxs.html</a>, See on <a href="https://news.ycombinator.com/item?id=37141463">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
<div id="post-body-8031291285305773410" itemprop="articleBody">
<meta content="By Stijn Mitzer En güzel deniz: henüz gidilmemiş olandır. En güzel çocuk: henüz büyümedi. En güzel günlerimiz: henüz yaşamadıklarımız. Ve sa..." name="twitter:description">
<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgvaZHx5v6tcHadcPJS32UMnzM7xOqZz6MjPWwGWXQuXdm6ho4sxbqZQwyZR0vjieO8JfmL_j-81TifqH-QitAqOlXsdUNMAqrxmI_t9nHCSpLN7eiFJKSgesTbs5gafwUAgcm4vX4094BlaMqCK2qPpldKTJA6cHddPoirb1Gvqa_MhqXOvaVUEVZh0gM/s2048/332.png"><img data-original-height="1514" data-original-width="2048" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgvaZHx5v6tcHadcPJS32UMnzM7xOqZz6MjPWwGWXQuXdm6ho4sxbqZQwyZR0vjieO8JfmL_j-81TifqH-QitAqOlXsdUNMAqrxmI_t9nHCSpLN7eiFJKSgesTbs5gafwUAgcm4vX4094BlaMqCK2qPpldKTJA6cHddPoirb1Gvqa_MhqXOvaVUEVZh0gM/s16000/332.png"></a></p><p><i>By Stijn Mitzer</i><br></p><p><span><i>En güzel deniz: henüz gidilmemiş olandır. En güzel çocuk: henüz büyümedi. En güzel günlerimiz: henüz yaşamadıklarımız. Ve sana söylemek istediğim en güzel söz: henüz söylememiş olduğum sözdür</i> – The most beautiful sea, hasn't been crossed yet. The most beautiful child, hasn't grown up yet. Our most beautiful days, we haven't witnessed yet. And the most beautiful words I wanted to tell you, I haven't said yet.</span><span><span> <i>(<a href="https://youtu.be/ULW4g2jELFA?t=24">By</a> Nazım Hikmet)</i></span></span></p><p>Dear everyone,</p><p>I had always imagined 'penning' this farewell someday. You see, the journey of Oryx took a different path than its intended purpose. What Oryx was meant to be initially was a remedy for my teenage boredom at the age of 17. Back then, I was still in high school, and the manageable workload along with my recent departure from playing football left me with an abundance of spare time. An interest in the Arab Spring, in particular the Libyan and Syrian Revolutions, led me to spend more and more time scouring the internet for updates. As the Syrian Revolution evolved into protracted civil war, I decided to create a Twitter account to more closely monitor the unfolding events.</p><p>One of the accounts I followed was that of Eliot Higgins, who began reporting on the Syrian Civil War on his Brown Moses Blog. After asking him one day if he was going to report on the use of Italian-upgraded T-72 tanks in the war, I remember telling myself that if a ''high-school dropout who knew no more about weapons than the average Xbox owner'' was able to write these articles, so would I probably. That evening, I created a blog, picked a name (Oryx for the majestic animal, and Spioenkop, Afrikaans for 'spy hill', as a place from where one can watch events unfold around the world) and published my first article on Syria's T-72 MBTs. (For those interested, the article can be read <a href="https://web.archive.org/web/20141019093200/http://spioenkop.blogspot.com/2013/02/syrian-turms-t-equipped-t-72s.html">here</a>).</p><p>It was the 16th of February 2013, and little did I realise that the next decade would transform Oryx from a remedy for boredom into a project that would consume the majority of my time and energy. I can still recall the joy I felt when the T-72 article garnered 520 views in just several hours, contributing to a total view count of approximately 3500 for the entire blog that month. Fast forward ten years, and Oryx now achieves an average of 250,000 daily views. In the months following my inaugural article, I continued to write about Syria, a country that held my focus until 2017.&nbsp;However, a desire towards greater challenges was always present. My motivation thrives on challenges. Offer me the most difficult subject to analyse. Upon mastering the subject's intricacies, I seek out the next challenge.</p><p>I ultimately discovered my greatest challenge in the analysis of North Korea. Back in the early 2010s, the scarcity of photographs and videos emerging from the country, in stark contrast to the flood of visual content available now, intrigued me. The limited information available, coupled with the abundance of misinformation, arguably made it the most challenging country to analyse. Through a series of articles and our eventual book(s), Joost and I attempted to unravel the mysteries surrounding the Korean People's Army. Finishing the final pages of the book left me feeling satisfied with North Korea – we had done what we aimed for. We unearthed the answers to our questions. With this challenge resolved, I started looking for another subject that would keep me curious and motivated.</p><p>Finding a challenge this time around proved much harder than before. However, the Nagorno-Karabakh War, Türkiye('s defence industry) and the Tigray War eventually emerged as subjects that provided me with both analytical satisfaction and the desired level of complexity. Their status as topics that Western analysts scarcely delved into rendered them all the more interesting to me. In contrast to mainstream media, we weren't confined by the need to generate popular articles and headlines. Instead, we saw this as an opportunity to illuminate underreported conflicts like the Tigray War, the Libyan War and the War in Yemen. Continuously delving into various countries and conflicts kept Oryx fresh for me, but it has also brought me to a place where I feel that I've largely covered the subjects I intended to explore. The journey has been a source of pleasure, but it has now arrived at its final destination. </p><p>Since late 2021, the act of writing feels repetitive, almost as if I've written every sentence before. For me, this realisation serves as a clear sign that it's time to move on. In fact, I had already contemplated ending Oryx by the spring of 2022, but the Russian invasion of Ukraine infused me with renewed energy to keep going. But 1.5 years later, I have lost my spark. My interest in anything military is fading, and the 
constant pressure to keep up with everything is exhausting. I
usually fall asleep with my phone in hand, only to wake up finding 
I've been sleeping on it. I'm tired of all the death and 
destruction. It's been a whole decade of watching videos of people's bodies having been torn apart by bombs or parents holding their lifeless newborns who died as a result of armed conflict – it really gets to you.</p><p>Still, I take great joy in the opportunities that Oryx has brought
 me, as well as from the lifelong friendships with Joost and Kemal. While I'm aware of options such as securing a position at a 
think tank or even transforming Oryx into a lucrative private 
intelligence agency, these career paths hold no appeal for me. 
I think I possess a moral compass that doesn't align with such institutions' goals. Despite the potential for financial gains through Oryx, I consciously 
opt not to pursue them. To me, the act of <a href="https://www.oryxspioenkop.com/2023/07/patreon-with-purpose-how-your-donations.html">donating</a> our entire Patreon 
income to charities seemed like the only possible course of action. Amidst ongoing wars and natural disasters, it's difficult to justify to ourselves to hold onto money without considering the greater need. Money doesn't tempt me, especially when it's associated with conflict. True wealth, for me, is found within family, health, and finding happiness in the little things in life. A forest stroll or spending time with friends makes me feel genuinely rich. Learning this lesson at a young age is priceless.<br></p><p>Over the years I've come to realise that, to me, genuine success and happiness are scarcely influenced by popularity, recognition, or even publishing a book. While these achievements hold their own significance, they haven't truly brought me a sense of pride. My most significant accomplishments involve making those dear to me proud and understanding the essence of happiness at a young age. Oryx has shown me that that true happiness cannot be attained through fame, career accomplishments, or wealth. Despite Oryx gaining recognition – being featured on major TV channels, acknowledged by figures like John McCain and David Petraeus, and with our information used by intelligence agencies – my proudest moment remains being able to write a message in my book I gave to my then girlfriend. You've shown me what real happiness looks like T. Nothing could ever surpass that. Thank you for that.</p><p>Reflecting on the last decade, I hope that Oryx has and will continue to motivate others to set out on their own journey of analysis and writing. Starting at the age of 17 without ever taking any education in the field of defence or international relations, Oryx can be seen as evidence that great opportunities await those who choose a similar path.<i> </i>What added to the excitement was the interaction with readers on Twitter, which I've thoroughly enjoyed over the years.<i> </i>At a certain point, the number of messages became overwhelming, so I want to apologise if you never received a response. I also want to express my sincere appreciation to all those who have offered their assistance in various capacities to Oryx over the years, with a special acknowledgment to Jakub.<i> </i>What began as a childhood interest ignited by buying Buck Danny and Biggles comic strips when I was 8 years old blossomed into a hobby that has far exceeded any reasonable limits. Although I once contemplated a position with an intelligence agency, an offer never came to fruition (perhaps fortunate given their bureaucracy).<br></p><p>Lastly, I feel compelled to discuss the origin of the practice of list-making and its evolution over time. We began our venture into list-making in 2013 with the goal of aiding our internal analysis. The abundance and variations of North Korea's armored fighting vehicles (AFVs) posed a challenge, prompting us to catalog them before we could analyse them effectively. This initial list set the groundwork for subsequent lists, although it wasn't until the summer of 2014 that we embarked on compiling the 'losses lists,' intended to illustrate the staggering volume of armament and equipment captured by IS in the regions of Iraq and Syria. The rapid proliferation of these lists, owing to the relatively straightforward process of creating them, is probably what Oryx will primarily be remembered for. The lists gained such popularity that I found myself (somewhat jokingly) <a href="https://www.oryxspioenkop.com/2023/04/list-listing-oryx-list-of-lists.html">embracing</a> the entire act of list-making on Oryx with a list of lists. However, I must confess, I have an aversion to planning ahead and never create lists in my everyday life. Sorry!<br></p><p>As I bid farewell on October 1st, I'll leave you with these lines from my most beloved song&nbsp;<a href="https://youtu.be/rbTsG9jrJsU">Ue o Muite Arukō</a> by my favourite singer Sakamoto Kyu.</p><p>Shiawase wa kumo no ue ni - Happiness lies beyond the clouds<br>Shiawase wa sora no ue ni - Happiness lies up above the sky</p><div><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhtnZJ-bwbP3CxrgnPayC7m3hemRUxyrBx0CGpxkGznAxI0peglIaclhnBvMY5TpTgy3_dnuKRmVGAnIBTONUspdY2paVxmrbxyfU2P6gidj0Kq9QOOuiKBXTy8xxOzRm0TtUlbsvu-CG--Uuoyw3MFUWztj8vtXnUMjVQx_ZWr4ex73BMRjT_pObvOMgM/s2048/25.png"><img data-original-height="1320" data-original-width="2048" height="412" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhtnZJ-bwbP3CxrgnPayC7m3hemRUxyrBx0CGpxkGznAxI0peglIaclhnBvMY5TpTgy3_dnuKRmVGAnIBTONUspdY2paVxmrbxyfU2P6gidj0Kq9QOOuiKBXTy8xxOzRm0TtUlbsvu-CG--Uuoyw3MFUWztj8vtXnUMjVQx_ZWr4ex73BMRjT_pObvOMgM/w640-h412/25.png" width="640"></a></p><p>PS: Just to clarify, I'm not being sponsored by the Põhjala beer brand – there was a half-price deal for a second bottle at my nearby supermarket. My Dutch spirit remains intact, after all. <br></p></div>
</div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Modern CSV version 2 (302 pts)]]></title>
            <link>https://www.moderncsv.com/modern-csv-2-is-now-available/</link>
            <guid>37140159</guid>
            <pubDate>Tue, 15 Aug 2023 22:35:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.moderncsv.com/modern-csv-2-is-now-available/">https://www.moderncsv.com/modern-csv-2-is-now-available/</a>, See on <a href="https://news.ycombinator.com/item?id=37140159">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>And I think you’ll love it. I focused on several areas:</p>
<ol>
<li>Improved UI and user experience</li>
<li>Faster performance</li>
<li>Useful features</li>
<li>Updated documentation</li>
<li>For Mac users, Native Apple Silicon (ARM – M1, M2) compatibility</li>
</ol>
<p><a href="https://www.moderncsv.com/download" target="_blank"><span>Download Modern CSV 2</span></a></p><p>If that’s all you need to know, you can buy a license <a href="https://www.moderncsv.com/buy">here</a>.<br>
Or if you already have a version 1 license, you can upgrade <a href="https://www.moderncsv.com/upgrade">here</a>.<br>
For those that need more details, here you go.</p>
<h2>Improved UI and User Experience</h2>
<p>There are two areas of the user interface that I aimed to improve for usability: Preferences and File Metadata. I also added several new themes and a bunch of subtle improvements to make it look and feel better.</p>
<p><img decoding="async" fetchpriority="high" src="https://www.moderncsv.com/wp-content/uploads/2023/04/Mac-v2.png" alt="Modern CSV v2" width="1068" height="592" srcset="https://www.moderncsv.com/wp-content/uploads/2023/04/Mac-v2.png 1068w, https://www.moderncsv.com/wp-content/uploads/2023/04/Mac-v2-300x166.png 300w, https://www.moderncsv.com/wp-content/uploads/2023/04/Mac-v2-1024x568.png 1024w, https://www.moderncsv.com/wp-content/uploads/2023/04/Mac-v2-768x426.png 768w, https://www.moderncsv.com/wp-content/uploads/2023/04/Mac-v2-135x75.png 135w, https://www.moderncsv.com/wp-content/uploads/2023/04/Mac-v2-480x266.png 480w" sizes="(max-width:767px) 480px, (max-width:1068px) 100vw, 1068px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201068%20592'%3E%3C/svg%3E" data-lazy-srcset="https://www.moderncsv.com/wp-content/uploads/2023/04/Mac-v2.png 1068w, https://www.moderncsv.com/wp-content/uploads/2023/04/Mac-v2-300x166.png 300w, https://www.moderncsv.com/wp-content/uploads/2023/04/Mac-v2-1024x568.png 1024w, https://www.moderncsv.com/wp-content/uploads/2023/04/Mac-v2-768x426.png 768w, https://www.moderncsv.com/wp-content/uploads/2023/04/Mac-v2-135x75.png 135w, https://www.moderncsv.com/wp-content/uploads/2023/04/Mac-v2-480x266.png 480w" data-lazy-src="https://www.moderncsv.com/wp-content/uploads/2023/04/Mac-v2.png"></p>
<h3>Preferences</h3>
<p>In version 1, preferences (i.e. program settings, keyboard shortcuts, and file extension options) could only be set by editing and saving a file. Some users really liked this and others preferred a UI. I decided to give everyone what they want. For those who like it, you can still edit the preference files just like in version 1. For everyone else, there is a Preferences window that is more intuitive and less prone to mistakes.</p>
<div id="attachment_1786"><p><img aria-describedby="caption-attachment-1786" decoding="async" src="https://www.moderncsv.com/wp-content/uploads/2023/04/Settings.png" alt="Settings Window" width="827" height="465" srcset="https://www.moderncsv.com/wp-content/uploads/2023/04/Settings.png 827w, https://www.moderncsv.com/wp-content/uploads/2023/04/Settings-300x169.png 300w, https://www.moderncsv.com/wp-content/uploads/2023/04/Settings-768x432.png 768w, https://www.moderncsv.com/wp-content/uploads/2023/04/Settings-260x146.png 260w, https://www.moderncsv.com/wp-content/uploads/2023/04/Settings-50x28.png 50w, https://www.moderncsv.com/wp-content/uploads/2023/04/Settings-133x75.png 133w" sizes="(max-width:767px) 480px, (max-width:827px) 100vw, 827px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20827%20465'%3E%3C/svg%3E" data-lazy-srcset="https://www.moderncsv.com/wp-content/uploads/2023/04/Settings.png 827w, https://www.moderncsv.com/wp-content/uploads/2023/04/Settings-300x169.png 300w, https://www.moderncsv.com/wp-content/uploads/2023/04/Settings-768x432.png 768w, https://www.moderncsv.com/wp-content/uploads/2023/04/Settings-260x146.png 260w, https://www.moderncsv.com/wp-content/uploads/2023/04/Settings-50x28.png 50w, https://www.moderncsv.com/wp-content/uploads/2023/04/Settings-133x75.png 133w" data-lazy-src="https://www.moderncsv.com/wp-content/uploads/2023/04/Settings.png"></p><p id="caption-attachment-1786">Settings Window</p></div>

<div id="attachment_1785"><p><img aria-describedby="caption-attachment-1785" decoding="async" src="https://www.moderncsv.com/wp-content/uploads/2023/04/KeyboardShortcuts.png" alt="Keyboard Shortcuts Window" width="827" height="465" srcset="https://www.moderncsv.com/wp-content/uploads/2023/04/KeyboardShortcuts.png 827w, https://www.moderncsv.com/wp-content/uploads/2023/04/KeyboardShortcuts-300x169.png 300w, https://www.moderncsv.com/wp-content/uploads/2023/04/KeyboardShortcuts-768x432.png 768w, https://www.moderncsv.com/wp-content/uploads/2023/04/KeyboardShortcuts-260x146.png 260w, https://www.moderncsv.com/wp-content/uploads/2023/04/KeyboardShortcuts-50x28.png 50w, https://www.moderncsv.com/wp-content/uploads/2023/04/KeyboardShortcuts-133x75.png 133w" sizes="(max-width:767px) 480px, (max-width:827px) 100vw, 827px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20827%20465'%3E%3C/svg%3E" data-lazy-srcset="https://www.moderncsv.com/wp-content/uploads/2023/04/KeyboardShortcuts.png 827w, https://www.moderncsv.com/wp-content/uploads/2023/04/KeyboardShortcuts-300x169.png 300w, https://www.moderncsv.com/wp-content/uploads/2023/04/KeyboardShortcuts-768x432.png 768w, https://www.moderncsv.com/wp-content/uploads/2023/04/KeyboardShortcuts-260x146.png 260w, https://www.moderncsv.com/wp-content/uploads/2023/04/KeyboardShortcuts-50x28.png 50w, https://www.moderncsv.com/wp-content/uploads/2023/04/KeyboardShortcuts-133x75.png 133w" data-lazy-src="https://www.moderncsv.com/wp-content/uploads/2023/04/KeyboardShortcuts.png"></p><p id="caption-attachment-1785">Keyboard Shortcuts Window</p></div>

<div id="attachment_1790"><p><img aria-describedby="caption-attachment-1790" decoding="async" src="https://www.moderncsv.com/wp-content/uploads/2023/04/FileExtensionOptions.png" alt="File Extension Options" width="827" height="465" srcset="https://www.moderncsv.com/wp-content/uploads/2023/04/FileExtensionOptions.png 827w, https://www.moderncsv.com/wp-content/uploads/2023/04/FileExtensionOptions-300x169.png 300w, https://www.moderncsv.com/wp-content/uploads/2023/04/FileExtensionOptions-768x432.png 768w, https://www.moderncsv.com/wp-content/uploads/2023/04/FileExtensionOptions-260x146.png 260w, https://www.moderncsv.com/wp-content/uploads/2023/04/FileExtensionOptions-50x28.png 50w, https://www.moderncsv.com/wp-content/uploads/2023/04/FileExtensionOptions-133x75.png 133w" sizes="(max-width:767px) 480px, (max-width:827px) 100vw, 827px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20827%20465'%3E%3C/svg%3E" data-lazy-srcset="https://www.moderncsv.com/wp-content/uploads/2023/04/FileExtensionOptions.png 827w, https://www.moderncsv.com/wp-content/uploads/2023/04/FileExtensionOptions-300x169.png 300w, https://www.moderncsv.com/wp-content/uploads/2023/04/FileExtensionOptions-768x432.png 768w, https://www.moderncsv.com/wp-content/uploads/2023/04/FileExtensionOptions-260x146.png 260w, https://www.moderncsv.com/wp-content/uploads/2023/04/FileExtensionOptions-50x28.png 50w, https://www.moderncsv.com/wp-content/uploads/2023/04/FileExtensionOptions-133x75.png 133w" data-lazy-src="https://www.moderncsv.com/wp-content/uploads/2023/04/FileExtensionOptions.png"></p><p id="caption-attachment-1790">File Extension Options</p></div>
<h3>File Metadata</h3>
<p>In version 1, changing the file’s parameters (e.g. delimiter, character encoding, etc.) or header row/column settings was all done via command. In version 2, you can still do it via command, but there’s now a File Metadata pane to make it easier.</p>
<div id="attachment_1784"><p><img aria-describedby="caption-attachment-1784" decoding="async" src="https://www.moderncsv.com/wp-content/uploads/2023/04/FileMetadata.png" alt="File Metadata Pane" width="388" height="703" srcset="https://www.moderncsv.com/wp-content/uploads/2023/04/FileMetadata.png 388w, https://www.moderncsv.com/wp-content/uploads/2023/04/FileMetadata-166x300.png 166w, https://www.moderncsv.com/wp-content/uploads/2023/04/FileMetadata-81x146.png 81w, https://www.moderncsv.com/wp-content/uploads/2023/04/FileMetadata-28x50.png 28w, https://www.moderncsv.com/wp-content/uploads/2023/04/FileMetadata-41x75.png 41w" sizes="(max-width:767px) 388px, 388px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20388%20703'%3E%3C/svg%3E" data-lazy-srcset="https://www.moderncsv.com/wp-content/uploads/2023/04/FileMetadata.png 388w, https://www.moderncsv.com/wp-content/uploads/2023/04/FileMetadata-166x300.png 166w, https://www.moderncsv.com/wp-content/uploads/2023/04/FileMetadata-81x146.png 81w, https://www.moderncsv.com/wp-content/uploads/2023/04/FileMetadata-28x50.png 28w, https://www.moderncsv.com/wp-content/uploads/2023/04/FileMetadata-41x75.png 41w" data-lazy-src="https://www.moderncsv.com/wp-content/uploads/2023/04/FileMetadata.png"></p><p id="caption-attachment-1784">File Metadata Pane</p></div>
<h3>Themes</h3>
<p>Version 1 had two themes – Light and Dark. Version 2 has five – Light, Dark, Dracula, Solarized Light, and Solarized Dark.</p>
<div id="attachment_1789"><p><img aria-describedby="caption-attachment-1789" decoding="async" src="https://www.moderncsv.com/wp-content/uploads/2023/04/Dracula.png" alt="Dracula Theme" width="878" height="498" srcset="https://www.moderncsv.com/wp-content/uploads/2023/04/Dracula.png 878w, https://www.moderncsv.com/wp-content/uploads/2023/04/Dracula-300x170.png 300w, https://www.moderncsv.com/wp-content/uploads/2023/04/Dracula-768x436.png 768w, https://www.moderncsv.com/wp-content/uploads/2023/04/Dracula-257x146.png 257w, https://www.moderncsv.com/wp-content/uploads/2023/04/Dracula-50x28.png 50w, https://www.moderncsv.com/wp-content/uploads/2023/04/Dracula-132x75.png 132w" sizes="(max-width:767px) 480px, (max-width:878px) 100vw, 878px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20878%20498'%3E%3C/svg%3E" data-lazy-srcset="https://www.moderncsv.com/wp-content/uploads/2023/04/Dracula.png 878w, https://www.moderncsv.com/wp-content/uploads/2023/04/Dracula-300x170.png 300w, https://www.moderncsv.com/wp-content/uploads/2023/04/Dracula-768x436.png 768w, https://www.moderncsv.com/wp-content/uploads/2023/04/Dracula-257x146.png 257w, https://www.moderncsv.com/wp-content/uploads/2023/04/Dracula-50x28.png 50w, https://www.moderncsv.com/wp-content/uploads/2023/04/Dracula-132x75.png 132w" data-lazy-src="https://www.moderncsv.com/wp-content/uploads/2023/04/Dracula.png"></p><p id="caption-attachment-1789">Dracula Theme</p></div>

<div id="attachment_1788"><p><img aria-describedby="caption-attachment-1788" decoding="async" src="https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedLight.png" alt="Solarized Light Theme" width="878" height="498" srcset="https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedLight.png 878w, https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedLight-300x170.png 300w, https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedLight-768x436.png 768w, https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedLight-257x146.png 257w, https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedLight-50x28.png 50w, https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedLight-132x75.png 132w" sizes="(max-width:767px) 480px, (max-width:878px) 100vw, 878px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20878%20498'%3E%3C/svg%3E" data-lazy-srcset="https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedLight.png 878w, https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedLight-300x170.png 300w, https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedLight-768x436.png 768w, https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedLight-257x146.png 257w, https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedLight-50x28.png 50w, https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedLight-132x75.png 132w" data-lazy-src="https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedLight.png"></p><p id="caption-attachment-1788">Solarized Light Theme</p></div>

<div id="attachment_1787"><p><img aria-describedby="caption-attachment-1787" decoding="async" src="https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedDark.png" alt="Solarized Dark Theme" width="878" height="498" srcset="https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedDark.png 878w, https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedDark-300x170.png 300w, https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedDark-768x436.png 768w, https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedDark-257x146.png 257w, https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedDark-50x28.png 50w, https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedDark-132x75.png 132w" sizes="(max-width:767px) 480px, (max-width:878px) 100vw, 878px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20878%20498'%3E%3C/svg%3E" data-lazy-srcset="https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedDark.png 878w, https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedDark-300x170.png 300w, https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedDark-768x436.png 768w, https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedDark-257x146.png 257w, https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedDark-50x28.png 50w, https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedDark-132x75.png 132w" data-lazy-src="https://www.moderncsv.com/wp-content/uploads/2023/04/SolarizedDark.png"></p><p id="caption-attachment-1787">Solarized Dark Theme</p></div>
<h2>Faster Performance</h2>
<p>The first thing you’ll notice is that it loads faster than version 1. The load time has been cut nearly in half.<br>
For loading large files in read-only mode, load time has been reduced by nearly 20%<br>
Lastly, the performance for loading files with many columns has been reduced by over 90%. That’s a full order of magnitude.</p>
<h2>Useful Features</h2>
<p>I make sure that any feature I add is going to be useful to a broad swatch of Modern CSV users. Most of them have been requested by users. The rest are features I find useful, and since I use my own product, I count as a user. Here are some of the most important new features:</p>
<p>* Select all results of a Find operation.<br>
* Open a new instance.<br>
* Deduplicate rows based on just a few columns (instead of only removing rows that are the same on every column). [Premium]<br>
* Reshape (change dimensions) of a range of cells. [Premium]<br>
* Statistics and Column Analysis. [Premium Business]<br>
* Column Lookup. [Premium Business]</p>
<p>For a more comprehensive list, see the <a href="https://www.moderncsv.com/download">Download page</a>.</p>
<h2>Updated Documentation</h2>
<p>The old documentation was single page and was starting to get pretty large. The new documentation has multiple pages with excellent navigation and search functionality. It’s more comprehensive but still concise. I endeavor to use graphics instead of words when possible.</p>
<h2>Native Apple Silicon (ARM – M1, M2) Compatibility</h2>
<p>Rosetta is no longer needed to run Modern CSV on Apple Silicon machines.</p>
<h2>Conclusion</h2>
<p>A lot of work went into making Modern CSV 2.0. I hope you find it makes editing and viewing CSV files even easier. Please feel free to try it out and let me know what you think.</p>
<p><a href="" target="_blank"><span>Download Modern CSV 2</span></a></p><p>If you’re ready to buy a license, you can do so here <a href="https://www.moderncsv.com/buy">here</a>.</p>
<p>If you already have a version 1 license, you can upgrade <a href="https://www.moderncsv.com/upgrade">here</a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Is LLaMa.cpp Possible? (641 pts)]]></title>
            <link>https://finbarr.ca/how-is-llama-cpp-possible/</link>
            <guid>37140013</guid>
            <pubDate>Tue, 15 Aug 2023 22:18:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://finbarr.ca/how-is-llama-cpp-possible/">https://finbarr.ca/how-is-llama-cpp-possible/</a>, See on <a href="https://news.ycombinator.com/item?id=37140013">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
    
    
    
    <p><em>If you want to read more of my writing, I have a <a href="https://finbarrtimbers.substack.com/">Substack</a>. Articles will be posted simultaneously to both places.</em></p>

<p>Recently, a <a href="https://github.com/ggerganov/llama.cpp">project</a> rewrote the <a href="https://github.com/facebookresearch/llama">LLaMa inference code</a> in raw C++. With some optimizations and quantizing the weights, this allows running a LLM locally on a wild variety of hardware:</p>

<ul>
  <li>On a <a href="https://twitter.com/rgerganov/status/1635604465603473408">Pixel5</a>, you can run the 7B parameter model at 1 tokens/s.</li>
  <li>On a <a href="https://simonwillison.net/2023/Mar/11/llama/">M2 Macbook Pro</a>, you can get ~16 tokens/s with the 7B parameter model</li>
  <li>You can <a href="https://twitter.com/miolini/status/1634982361757790209">even run the 7B model on a 4GB RAM Raspberry Pi</a>, albeit at 0.1 tokens/s.</li>
</ul>

<p>If you are like me, you saw this and thought: What? How is this possible? Don’t large models require expensive GPUs? I took my confusion and dove into the math surrounding inference requirements to understand the constraints we’re dealing with.</p>

<p>Let’s start with GPUs. GPUs have two main benefits for deep learning:</p>

<ol>
  <li>They have a large amount of memory bandwidth (<a href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-us-nvidia-1758950-r4-web.pdf">A100</a>: 1935 GB/s, <a href="https://images.nvidia.com/aem-dam/Solutions/geforce/ada/ada-lovelace-architecture/nvidia-ada-gpu-architecture-whitepaper-1.03.pdf">4090</a>: 1008 GB/s)</li>
  <li>They have a large amount of compute (<a href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-us-nvidia-1758950-r4-web.pdf">A100</a>: 312 TFLOPS of FP16, <a href="https://images.nvidia.com/aem-dam/Solutions/geforce/ada/ada-lovelace-architecture/nvidia-ada-gpu-architecture-whitepaper-1.03.pdf">4090</a>: 82.6 TFLOPS of FP16)</li>
</ol>

<p>When we talk about memory bandwidth, we’re talking about how long it takes to move things from the HBM memory (i.e. the RAM) into the on-chip memory. To actually do math with the GPU, we need to move the matrices in question into the on-chip memory, which is quite small (40MB on an A100, compared to 40-80GB of RAM). Note that the memory bandwidth is ~2 orders of magnitude smaller than the compute performance— this will matter later, as the memory bandwidth tends to be the bottleneck for inference.</p>

<p>What does this mean in the context of serving LLaMa? Let’s start with some <a href="https://kipp.ly/blog/transformer-inference-arithmetic/">inference arithmetic</a>. We can do some rough calculations on the inference performance of a LLM using <a href="https://kipp.ly/blog/transformer-param-count/">Kipply’s article</a><sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup>. First, some notation on the dimensions of the model:</p>

<ul>
  <li>The \(Q\), \(K\), and \(V\) weight matrices are all shape [ \(d_{\text{model}}\), \(d_{\text{head}}\)], and we have \(n_{\text{heads}}\) of them per layer; the attention output matrix has the same shape, for a total of  \(4 \times\) [ \(d_{\text{model}}\), \(n_{\text{heads}} \cdot d_{\text{head}}\)]. By convention, GPT-style networks have \(d_{\text{head}} \cdot n_{\text{heads}} = d_{\text{model}}\).</li>
  <li>The MLP has two weight matrices, of shape [ \(d_{\text{model}}\), \(4 \cdot d_{\text{model}}\)] and [ \(4\cdot d_{\text{model}}\), \(d_{\text{model}}\)]</li>
  <li>The embeddings matrix is of size [ \(d_{\text{vocab}}\), \(d_{\text{model}}\)].</li>
</ul>

<p>This gives us a handy equation for the number of parameters in a GPT-style model:<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" rel="footnote">2</a></sup></p><p>

\[P = n_{\text{blocks}} \left( 4 \cdot d_{\text{model}}^2 + 2 \cdot 4 \cdot d_{\text{model}}^2\right) + n_{\text{vocab}} \cdot d_{\text{model}}\]

</p><p>For the duration of the post, I’m going to focus on the case where we’re running a ChatGPT style service locally, which is what LLaMa.cpp does, letting me assume a batch size of 1.</p>

<p>For efficient inference, the KV cache has to be stored in memory; the KV cache requires storing the KV values for every layer, which is equal to storing:</p><p>

\[n_{\text{bytes}} \cdot 2 \cdot d_{\text{model}}\]

</p><p>I use \(n_{\text{bytes}}\) here to indicate the number of bytes per param; for float32s, this is 4, for float16s, this is 2, etc. The 2 in the middle is because we have to store one set of weights for the K values, and one for the Vs.</p>

<p>Given a model with n layers, the total memory for the KV cache is:</p><p>

\[n_{\text{blocks}} \cdot n_{\text{bytes}} \cdot 2 \cdot d_{\text{model}}\]

</p><p>In addition to storing the KV cache in memory, we also need to store the weights themselves in memory; this requires \(n_{\text{bytes}} \cdot P\) bytes.</p>

<p><img src="https://finbarr.ca/static/images/llama-memory-weights.png" alt="Screenshot of table showing the memory required for LLaMa weights"></p>

<p>This is the advantage of quantization. By using less precision, we can radically decrease the amount of memory needed to store our models in memory. Note that, with int4 precision, <em>all of these models fit into memory on an A100</em> (which is the standard datacenter GPU right now), and all of them, except for the biggest model, fit into memory on high-end consumer GPUs (3090s/4090s, which have 24GB of RAM).</p>

<p>It takes approximately \(2P\) FLOPS to run inference on our model for a single token, because we are doing a bunch of matmuls with a total of \(P\) parameters, and multiplying a matrix of size \((m, n)\) with a vector of size \((n,)\) has a cost of \(2mn\).<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" rel="footnote">3</a></sup></p>

<p>With all that math out of the way, let’s calculate the requirements for running inference with LLaMa. The main requirements when it comes to sampling are:</p>

<ol>
  <li>Keep the KV cache in memory, in addition to all the parameters.</li>
  <li>Read all the weights from HBM into the on-chip memory. Because we sample auto-regressively, we have to repeat this for each token we sample.</li>
  <li>Do the actual matmuls to calculate the output of our network.</li>
</ol>

<p>The latency is the maximum of either the compute or the memory latency, as reading parameters into on-chip memory happens asynchronously in all modern tensor programming libraries. As a result, we write:</p><p>

\[\begin{align*}
\text{latency}_\text{model} &amp;= \text{max}(\text{latency}_\text{compute}, \text{latency}_\text{memory})\\
\text{latency}_\text{memory} &amp;= \dfrac{2 \cdot P \cdot n_{\text{bytes}}\cdot B}{n_{\text{memory bandwidth}}},\\
\text{latency}_\text{compute} &amp;= \dfrac{2 \cdot P}{n_{\text{flops}}},
\end{align*}\]

</p><p>where \(B\) is the batch size. As \(n_{\text{memory bandwidth}} = 1.935e12\), and  \(n_{\text{flops}} = 3.12e14,\) as long as the batch size is less than 161, the model is memory-bound.<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" rel="footnote">4</a></sup></p>

<p>With a batch size of 1, this is the same equation, as on most hardware (e.g. Nvidia GPUs), there is a linear speedup as you decrease the precision (you get twice the FLOPS when using fp16 vs fp32, which doubles again as you go to int8, and doubles once more as you go to int4s).</p>

<p>As LLaMa.cpp uses int4s, the RAM requirements are reduced to 1.33GB of memory for the KV cache, and 16.25GB of VRAM for the model parameters. That’s pretty good!</p>

<p>As the memory bandwidth is almost always<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" rel="footnote">5</a></sup> much smaller than the number of FLOPS, memory bandwidth is the binding constraint.</p>

<p><img src="https://finbarr.ca/static/images/llama-inference-times.png" alt="Screenshot fo table showing the inference times to run the varying LLaMa models with varying precision levels on an A100"></p>

<h2 id="running-llama-on-an-a100">Running LLaMa on an A100</h2>

<p>On an A100 (80GB PCIe), the memory bandwidth is 1935GB/s. The int4 compute is 1248 TOPS. As such, the model is (heavily) memory-bound. We should expect to see inferences as given in the table; roughly 30 tokens/s with the 65B model, and 277 tokens/s with the 7B model.</p>

<h2 id="running-llama-on-a-m1-macbook-air">Running LLaMa on a M1 Macbook Air</h2>

<p>The M1 GPU has a bandwidth of <a href="https://www.macworld.com/article/783678/m2-vs-m1-chip-performance-graphics-ram.html">68.25 GB/s</a>, while the M1 GPU can do up to <a href="https://tlkh.dev/benchmarking-the-apple-m1-max#heading-gpu-matrix-multiplication-gemm-performance">5.5 TFLOPS</a> of fp16 compute. As such, we should expect a ceiling of ~1 tokens/s for sampling from the 65B model with int4s, and 10 tokens/s with the 7B model.</p>

<p>As the M2 Pro has 200 GB/s of bandwidth, and the M2 Max has 400 GB/s of bandwidth, we should expect massive improvements with them, going up to 6 tokens/s with the M2 Max with the 65B model. That’s pretty darn good for a laptop.</p>

<h2 id="running-llama-on-a-raspberry-pi-4">Running LLaMa on a Raspberry Pi 4</h2>

<p>A Raspberry Pi 4 has <a href="https://web.eece.maine.edu/~vweaver/group/green_machines.html">13.5 GFLOPS of compute</a>, and <a href="https://forums.raspberrypi.com/viewtopic.php?t=281183">~4GB/s of memory bandwidth</a>. Given this, we’d expect to see ~2 tokens/s with the 7B model if it was memory bound. Given that we’re currently seeing ~0.1 tokens/s, I suspect we’re actually compute-bound (although this is a stab in the dark— I can’t find enough information about the specs for a Raspberry Pi to determine this with any precision).</p>

<h2 id="summary">Summary</h2>

<p>Memory bandwidth is the limiting factor in almost everything to do with sampling from transformers. Anything that reduces the memory requirements for these models makes them <em>much</em> easier to serve— like quantization! This is yet another reason why distillation, or just <a href="https://finbarr.ca/llms-not-trained-enough/">training smaller models for longer</a>, is really important.</p>

<p><em>Note: I’m not an expert in CUDA, so I probably have errors in my math. If so, please shoot me an <a href="mailto:finbarrtimbers@gmail.com">email</a> and let me know- I’d love to hear from you so I can learn more about how this works and update this post.</em></p>

<p>Resources on transformer inference performance:</p>

<ul>
  <li><a href="https://lilianweng.github.io/posts/2023-01-10-inference-optimization/">Large Transformer Model Inference Optimization</a></li>
  <li><a href="https://kipp.ly/blog/transformer-inference-arithmetic/">Transformer inference arithmetic</a></li>
  <li><a href="https://kipp.ly/blog/transformer-param-count/">LLM parameter counting</a></li>
  <li><a href="https://arxiv.org/abs/2009.06732">Efficient Transformers</a></li>
</ul>

<p><em>Thank you to <a href="https://twitter.com/kaushikpatnaik?lang=en">Kaushik Patnaik</a>, <a href="https://twitter.com/arthurallshire">Arthur Allshire</a>, <a href="https://twitter.com/stanislavfort">Stanislav Fort</a>, and <a href="https://twitter.com/banburismus_">Tom McGrath</a> for reading early drafts of this.</em></p>



    
    <p>PS if you want to read more of my writing, subscribe to my <a href="https://finbarrtimbers.substack.com/">Substack</a>.</p>
    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You're a cyclist who was just struck by a car driver. Why it was your fault (109 pts)]]></title>
            <link>https://www.mcsweeneys.net/articles/youre-a-cyclist-who-was-just-struck-by-a-car-driver-heres-why-it-was-your-fault</link>
            <guid>37139980</guid>
            <pubDate>Tue, 15 Aug 2023 22:15:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mcsweeneys.net/articles/youre-a-cyclist-who-was-just-struck-by-a-car-driver-heres-why-it-was-your-fault">https://www.mcsweeneys.net/articles/youre-a-cyclist-who-was-just-struck-by-a-car-driver-heres-why-it-was-your-fault</a>, See on <a href="https://news.ycombinator.com/item?id=37139980">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="o-wrapper">
    <main>
        <header>
    <div>
      <div>
          <p><span><img role="none" src="https://edge-assets.mcsw.net/assets/search-614fbdcc4e71f0730ad039e484ec78a1085f24294fa0b4514da70b0a930b2dce.svg"></span></p>        </div>
      <div>
        <ul>
          <li><a href="https://www.mcsweeneys.net/">Internet Tendency</a></li>
          <li><a href="https://store.mcsweeneys.net/">The Store</a></li>
          <li><a href="https://store.mcsweeneys.net/t/categories/books">Books Division</a></li>
          <li><a href="https://store.mcsweeneys.net/t/categories/timothy-mcsweeneys-quarterly-concern">Quarterly Concern</a></li>
          <li><a href="https://thebeliever.net/">The Believer</a></li>
          <li><a href="https://www.mcsweeneys.net/donate">Donate</a></li>
        </ul>
      </div>
    </div>
    
  </header>


      
  <div>
    <h6>The Believer has returned</h6>
    
  </div>


      
<article>
    
   
    <div>
      <p><strong>You were riding during rush hour.</strong><br>
Why were you riding then? There are way too many cars on the road. If you were commuting, you should have contacted your boss and politely asked to work from 3:00 a.m. to 11:00 a.m. instead.</p>
<p><strong>You were riding at night or in the early morning.</strong><br>
There’s no way drivers can see you. Remember: if you’re one of those people who rides bikes because it keeps the mental darkness at bay, the best time to do so is in the middle of the workday.</p>
<p><strong>You were riding in the middle of the workday.</strong><br>
The only people who should ride their bikes during the workday are bike messengers, who I also dislike. They weave, they bob—it’s inappropriate. Bike messengers need to do what drivers do: go straight, get pissed off, and hate everyone.</p>
<p><strong>You were riding on a back road.</strong><br>
Those roads are narrow and have a lot of twists and turns. There are hardly any cyclists on them. Drivers weren’t expecting you!</p>
<p><strong>You were riding on a main road.</strong><br>
Again, too much traffic. We’ve been over this.</p>
<p><strong>You were riding in the morning, or at night, or on a quiet road, or a main road.</strong><br>
Do I honestly have to spell it out for you? The only appropriate time and place to ride a bike is a time beyond time and a place beyond place, where the space-time continuum is bent so strangely you are both everywhere and nowhere, eternal and nonexistent. You must become the smoke that comes from shadow, the sound of blue, the smell that emanates from the number twelve.</p>
<p><strong>You didn’t signal properly.</strong><br>
I mean, no, I don’t have any “evidence” for that, but you must have done something wrong for an upstanding citizen like the driver of a Ford Focus that looks like it got into a fight with a forklift to strike you. The stats are on my side. Sixty-six percent of drivers <a href="https://www.forbes.com/sites/carltonreid/2019/05/10/cyclists-break-far-fewer-road-rules-than-motorists-finds-new-video-study/?sh=2d9fafbd4bfa">routinely commit moving violations</a>, compared with 5 percent of cyclists when they have somewhere safe to ride. That’s why I believe drivers.</p>
<p><strong>Your bike isn’t an <span>SUV</span>.</strong><br>
If your bike were an <span>SUV</span>, we wouldn’t be having this conversation. You’d be fine. In fact, it would be the Ford Focus driver who’d be all messed up. And that’s why SUVs are considered safe.</p>
<p><strong>You forgot to go back in time and tell people that subsidizing the oil industry might be a bad idea.</strong><br>
When the oil and auto industries teamed up to bend public policy to their will, making a system of roads and parking lots that now function as a continuous subsidy and magnificent symbol of the normalization of injury and pollution, you had a lot of options. You could have objected. You could have shifted public opinion. Instead, you weren’t even born yet. And, rather than go back in time, all you’ve been doing is riding to get groceries and occasionally saying, “Please stop killing us.” On the effort scale? 1/10.</p>
<p><strong>Frankly, I’m not sure a driver even hit you.</strong><br>
Maybe you were just <a href="https://www.nytimes.com/2023/07/29/health/ebikes-safety-teens.html">clipped by a Nissan van</a>. Was there a driver in the van? Has the passive voice historically functioned to deflect responsibility and consolidate unjust power arrangements? These are all fascinating questions that, sadly, we will never know the answers to.</p>
<p><strong>Oops, looks like you died.</strong><br>
Miraculously, the driver has been arrested and will face involuntary vehicular homicide. For killing you, the driver will get <a href="https://chi.streetsblog.org/2015/11/17/driver-who-killed-cyclist-hector-avalos-sentenced-to-only-100-days-in-prison">a hundred days in prison</a>. Apparently, killing someone is <a href="https://www.outsideonline.com/culture/essays-culture/justice-drivers-hit-cyclists/">basically legal</a> if you do it with a car. Also, our liberal city council has decided to make positive change. As I write, they’re enforcing strict new rules to ensure no one can ride their bikes in this part of town ever again.</p>
    </div>
    

    <div>
    <p>
        Please help support our writers and keep our site ad-free by becoming a patron today!
    </p>
    
  </div>

</article>

    


      <div>
        <h5>Suggested Reads</h5>
        <ul>
            <li>
    <a href="https://www.mcsweeneys.net/articles/the-great-sag">
      <p>October  4, 2000</p>
      <p>The Great Sag</p>
</a>    
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/evidence-that-automakers-predicted-senate-hearings-but-not-the-outcome-of-the-2008-presidential-election">
      <p>December  5, 2008</p>
      <p>Evidence That Automakers Predicted Senate Hearings but Not the Outcome of the 2008 Presidential Election</p>
</a>    <p><span>by </span>Elizabeth Worthington</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/variations-on-the-spelling-of-vehicles-submitted-by-my-6th-graders-attempting-to-earn-extra-credit-on-a-weekly-spelling-test">
      <p>February 18, 2002</p>
      <p>Variations on the Spelling of ‘Vehicles,’ Submitted By My 6th Graders Attempting to Earn Extra Credit on a Weekly Spelling Test</p>
</a>    <p><span>by </span>Andre Theisen</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/our-rv-has-a-kitchen-bedroom-bathroom-and-plenty-of-space-for-our-seven-children">
      <p>June 12, 2023</p>
      <p>Our RV Has a Kitchen, Bedroom, Bathroom, and Plenty of Space for Our Seven Children</p>
</a>    <p><span>by </span>Bobbie Armstrong<span> and&nbsp;</span>Madeline Goetz</p>
  </li>

        </ul>
      </div>


  <section>
        <div>
      <h5>Trending 🔥</h5>
      <ol>
          <li>
    <a href="https://www.mcsweeneys.net/articles/youre-a-cyclist-who-was-just-struck-by-a-car-driver-heres-why-it-was-your-fault">
      <p>August 11, 2023</p>
      <p>You’re a Cyclist Who Was Just Struck by a Car Driver. Here’s Why It Was Your Fault</p>
</a>    <p><span>by </span>Chas Gillespie</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/how-to-ensure-your-annual-beach-vacation-destroys-your-relationship-with-your-extended-family">
      <p>July 26, 2023</p>
      <p>How to Ensure Your Annual Beach Vacation Destroys Your Relationship with Your Extended Family</p>
</a>    <p><span>by </span>Talia Argondezzi<span> and&nbsp;</span>Jeff Bender</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/i-regret-to-announce-that-i-will-not-be-canceling-my-plans-with-you-tonight">
      <p>August  4, 2023</p>
      <p>I Regret to Announce That I Will Not Be Canceling My Plans with You Tonight</p>
</a>    <p><span>by </span>Sam Shafaghi</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/what-your-favorite-80s-band-says-about-you">
      <p>July  5, 2011</p>
      <p>What Your Favorite ’80s Band Says About You</p>
</a>    <p><span>by </span>John K. Peck</p>
  </li>

      </ol>
    </div>

      <div>
    <h5>Recently</h5>
    <ul>
        <li>
    <a href="https://www.mcsweeneys.net/articles/im-racketeering-charges-and-im-here-to-rock-this-presidential-indictment-fest-like-you-wouldnt-believe">
      <p>August 15, 2023</p>
      <p>I’m Racketeering Charges, and I’m Here to Rock This Presidential Indictment-Fest Like You Wouldn’t Believe</p>
</a>    <p><span>by </span>Jess Keefe</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/welcome-to-your-new-city-in-the-northwest-where-recycling-is-so-simple">
      <p>August 15, 2023</p>
      <p>Welcome to Your New City in the Northwest, Where Recycling Is So Simple</p>
</a>    <p><span>by </span>Tori Multon</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/can-i-get-away-with-this-on-the-bus-an-faq-for-the-modern-commuter">
      <p>August 14, 2023</p>
      <p>Can I Get Away with This on the Bus? An <span>FAQ</span> for the Modern Commuter</p>
</a>    <p><span>by </span>Seif Drywater</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/predictive-texts-for-the-conflict-averse">
      <p>August 14, 2023</p>
      <p>Predictive Texts for the Conflict-Averse</p>
</a>    <p><span>by </span>Tom Ellison<span> and&nbsp;</span>Caitlin Kunkel</p>
  </li>

    </ul>
  </div>

  </section>


  

    
  
  
  




        

    </main>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How should I read type system notation? (322 pts)]]></title>
            <link>https://langdev.stackexchange.com/questions/2692/how-should-i-read-type-system-notation</link>
            <guid>37138807</guid>
            <pubDate>Tue, 15 Aug 2023 20:15:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://langdev.stackexchange.com/questions/2692/how-should-i-read-type-system-notation">https://langdev.stackexchange.com/questions/2692/how-should-i-read-type-system-notation</a>, See on <a href="https://news.ycombinator.com/item?id=37138807">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
<p>The notation used to describe type systems varies from presentation to presentation, so giving a comprehensive overview is impossible. However, most presentations share a large, common subset, so this answer will attempt to provide a foundation of enough of the basics to understand variations on the common theme.</p>
<h2>Syntax and grammars</h2>
<p>Type systems as applied to programming language are <em>syntactic</em> systems. That is, a type system is a set of rules that operate on the (abstract) syntax of a programming language. For this reason, comprehensive treatments of type systems begin by providing the <a href="https://en.wikipedia.org/wiki/Formal_grammar" rel="noreferrer">grammar</a> of all the syntactic constructs considered by the type system using <a href="https://en.wikipedia.org/wiki/Backus%E2%80%93Naur_form" rel="noreferrer">BNF</a> notation. In the simplest typed languages, syntax is needed for precisely two things: <em>expressions</em> and <em>types</em>.</p>
<p>For example, let’s consider the grammar for an extremely simple language of booleans and integers:
<span>$$
\begin{array}{rcll}
e \hskip{-10mu}
  &amp;::=&amp;\hskip{-10mu} \mathsf{true}\hskip{10mu}|\hskip{10mu}\mathsf{false} &amp;\textrm{boolean literal}\\
  &amp; | &amp;\hskip{-10mu} 0 \hskip{5mu}|\hskip{5mu} 1 \hskip{5mu}|\hskip{5mu} {-1} \hskip{5mu}|\hskip{5mu} 2 \hskip{5mu}|\hskip{5mu} {-2} \hskip{5mu}|\hskip{5mu} \ldots &amp;\textrm{integer literal}\\
  &amp; | &amp;\hskip{-10mu} \mathbf{if}\ e\ \mathbf{then}\ e\ \mathbf{else}\ e &amp;\textrm{conditional}\\
  &amp; | &amp;\hskip{-10mu} e + e \hskip{10mu}|\hskip{10mu} e - e \hskip{10mu}|\hskip{10mu} e × e &amp;\textrm{arithmetic}\\
  &amp; | &amp;\hskip{-10mu} e = e \hskip{10mu}|\hskip{10mu} e &lt; e \hskip{10mu}|\hskip{10mu} e &gt; e &amp;\textrm{comparison}\\[8pt]
\tau \hskip{-10mu}
  &amp;::=&amp;\hskip{-10mu} \mathsf{Bool} &amp;\textrm{booleans}\\
  &amp; | &amp;\hskip{-10mu} \mathsf{Int} &amp;\textrm{integers}
\end{array}
$$</span>
Here, <span>$e$</span> corresponds to an expression and <span>$\tau$</span> corresponds to a type, which is a standard notational convention. Some presentations use other symbols for types, such as <span>$t$</span>, <span>$T$</span>, <span>$\sigma$</span>, or other lowercase Greek letters, but the overall structure will look roughly the same.</p>
<p>More complex languages will naturally have more complex grammars: imperative languages will include the grammar of statements, languages with pattern-matching will include the grammar of patterns, and so on. This language is so simple that it doesn’t even have variables! However, this core syntactic division between <em>terms</em> (things that have types) and <em>types</em> is essential, as defining the relationship between them is what type systems are all about.</p>
<h2>Relations, judgments, axioms, and inference rules</h2>
<p>Once the grammar has been specified, the next step is to define the <em>typing relation</em>, which is generally written <span>$e : \tau$</span> and can be read “<span>$e$</span> has type <span>$\tau$</span>”. Intuitively, we understand that some statements of this form “make sense” and others do not:</p>
<ul>
<li><p><span>$1 + 2 : \mathsf{Int}$</span> means “<span>$1 + 2$</span> has type <span>$\mathsf{Int}$</span>”, which certainly makes sense.</p>
</li>
<li><p><span>$1 + 2 : \mathsf{Bool}$</span> means “<span>$1 + 2$</span> has type <span>$\mathsf{Bool}$</span>”, which does <em>not</em> make sense.</p>
</li>
<li><p><span>$\mathsf{true} + 2 : \mathsf{Int}$</span> means “<span>$\mathsf{true} + 2$</span> has type <span>$\mathsf{Int}$</span>”, which makes even <em>less</em> sense, as the expression <span>$\mathsf{true} + 2$</span> is nonsense and does not have any type at all.</p>
</li>
</ul>
<p>We’d like to write down some rules that precisely capture our intuitions about which statements “make sense” and which do not. To do this, we’ll define the <em>typing judgment</em>, which is written using the following notation:
<span>$$
⊢ e : \tau
$$</span>
Here, the <span>$⊢$</span> can be read to mean “the following statement is true”. (The <span>$⊢$</span> might seem a bit unnecessary, and indeed it is sometimes omitted in simple systems like this one, but it will play a more significant role later.) Using this notation, we can write down the some of the <em>typing rules</em> for our type system:
<span>$$
\begin{array}{l}\hline ⊢ \mathsf{true} : \mathsf{Bool}\end{array} \quad \quad
\begin{array}{l}\hline ⊢ \mathsf{false} : \mathsf{Bool}\end{array}
$$</span>
The horizontal bar over each of these rules with nothing on top means that they are <em>always</em> true, which makes them <em>axioms</em>. We also have an infinite number of similar axioms for integer literals:
<span>$$
\begin{array}{l}\hline ⊢ 0 : \mathsf{Int}\end{array} \quad
\begin{array}{l}\hline ⊢ 1 : \mathsf{Int}\end{array} \quad
\begin{array}{l}\hline ⊢ -1 : \mathsf{Int}\end{array} \quad
\begin{array}{l}\hline ⊢ 2 : \mathsf{Int}\end{array} \quad \cdots
$$</span></p>
<p>Of course, the typing rules for literals are fairly boring. Things get much more interesting when we consider rules for expressions that have subexpressions! Here are the typing rules for <span>$+$</span> and <span>$&lt;$</span>:
<span>$$
\begin{array}{l}
⊢ e_1 : \mathsf{Int} \\
⊢ e_2 : \mathsf{Int} \\
\hline
⊢ e_1 + e_2 : \mathsf{Int}
\end{array} \quad \quad \quad \begin{array}{l}
⊢ e_1 : \mathsf{Int} \\
⊢ e_2 : \mathsf{Int} \\
\hline
⊢ e_1 &lt; e_2 : \mathsf{Bool}
\end{array}
$$</span>
Now we have things both above <em>and</em> below the horizontal bars, which makes these <em>inference rules</em>. These represent conditional typing rules: the statement under the bar is true <strong>if</strong> all of the statements above the bar are true. For example, the first rule can be read as “if <span>$e_1 : \mathsf{Int}$</span> and <span>$e_2 : \mathsf{Int}$</span> are true, then <span>$e_1 + e_2 : \mathsf{Int}$</span> is true,” which should hopefully make intuitive sense.</p>
<p>Rules for <span>$-$</span>, <span>$×$</span>, <span>$=$</span>, and <span>$&gt;$</span> are nearly identical to the ones given above, but the rule for <span>$\mathbf{if} \ldots \mathbf{then} \ldots \mathbf{else}$</span> must be slightly more complex. This is because the branches of these expressions can be any type, as long as they agree. That is, both
<span>$$ \mathbf{if}\ \mathsf{true}\ \mathbf{then}\ 1\ \mathbf{else}\ 2 $$</span>
and
<span>$$ \mathbf{if}\ \mathsf{true}\ \mathbf{then}\ \mathsf{false}\ \mathbf{else}\ \mathsf{true} $$</span>
are legal, but
<span>$$
\mathbf{if}\ \mathsf{true}\ \mathbf{then}\ 1\ \mathbf{else}\ \mathsf{true}
$$</span>
is not. To capture this, the typing rule uses a variable to stand for the type of the branches:
<span>$$
\begin{array}{l}
⊢ e_1 : \mathsf{Bool} \\
⊢ e_2 : \tau \\
⊢ e_3 : \tau \\
\hline
⊢ \mathbf{if}\ e_1\ \mathbf{then}\ e_2\ \mathbf{else}\ e_3 : \tau
\end{array}
$$</span>
When the rule is applied, any type may be picked for <span>$\tau$</span> as long as the choice is used consistently.</p>
<p>This notation originates in formal logic, and in particular, the style used to specify type systems most closely resembles <a href="https://en.wikipedia.org/wiki/Natural_deduction" rel="noreferrer">natural deduction</a>. Though I will not go into the formal details of the notation in this answer, rules expressed in this way can be used to construct formal proofs about the system’s properties, which is important for proving things like <a href="https://en.wikipedia.org/wiki/Type_safety" rel="noreferrer">type soundness</a>.</p>
<h2>Judgments as an algorithmic specification</h2>
<p>So far, I’ve intentionally refrained from saying anything about the computational interpretation of typing judgments. In general, judgments are just logical rules, and some type systems specified this way do not directly correspond to a decidable typechecking algorithm. However, if you are not used to thinking about proof systems, this perspective can be extremely difficult to wrap your head around.</p>
<p>Fortunately, in many cases, there <em>is</em> a way to read typing rules that directly yields a typechecking algorithm: it’s possible to interpret <span>$⊢ e : \tau$</span> as a <em>function</em> from an expression <span>$e$</span> to its type <span>$\tau$</span>. This is because there is usually exactly one rule defined for each case in the grammar of expressions, which makes it possible to think of each typing rule as a distinct case in a recursive typechecking function.</p>
<p>For example, consider the rules for our little language given above. They correspond directly to an <span>$\mathrm{infer}$</span> function with the following shape:
<span>$$
\begin{array}{l}
\mathrm{infer} : \mathsf{Expr} → \mathsf{Type} \\
\mathrm{infer}(e) = \mathbf{match}\ e\ \mathbf{where} \\
\quad \begin{alignedat}{2}
  &amp;\mathsf{true}\ |\ \mathsf{false} &amp;&amp;↦ \mathsf{Bool} \\
  &amp;0\ |\ 1\ |\ {-1}\ |\ 2\ |\ \ldots &amp;&amp;↦ \mathsf{Int} \\
  &amp;e_1 + e_2 &amp;&amp;↦ \mathbf{assert}\: \mathrm{infer}(e_1) = \mathsf{Int}; \\
    &amp;&amp;&amp;\phantom{{}↦{}} \mathbf{assert}\: \mathrm{infer}(e_2) = \mathsf{Int}; \\
    &amp;&amp;&amp;\phantom{{}↦{}} \mathsf{Int} \\
  &amp;e_1 &lt; e_2 &amp;&amp;↦ \mathbf{assert}\: \mathrm{infer}(e_1) = \mathsf{Int}; \\
    &amp;&amp;&amp;\phantom{{}↦{}} \mathbf{assert}\: \mathrm{infer}(e_2) = \mathsf{Int}; \\
    &amp;&amp;&amp;\phantom{{}↦{}} \mathsf{Bool} \\
  &amp;\mathbf{if}\ e_1\ \mathbf{then}\ e_2\ \mathbf{else}\ e_3
    &amp;&amp;↦ \mathbf{assert}\: \mathrm{infer}(e_1) = \mathsf{Bool}; \\
    &amp;&amp;&amp;\phantom{{}↦{}} \mathbf{let}\: \tau = \mathrm{infer}(e_2); \\
    &amp;&amp;&amp;\phantom{{}↦{}} \mathbf{assert}\: \mathrm{infer}(e_3) = \tau; \\
    &amp;&amp;&amp;\phantom{{}↦{}} \tau
\end{alignedat}
\end{array}
$$</span></p>
<p>Even when it isn’t possible to perform such a direct translation from typing rules to typechecking algorithm, it can be extremely helpful to consider information flow when reasoning about logical judgments. That is, for the <span>$⊢ e : \tau$</span> judgment we defined above, <span>$e$</span> can be considered an “input” to the judgment and <span>$\tau$</span> considered an “output”. This strict directionality does not always apply to every rule in a type system, but it often applies to many of them, and it is a useful way to wrap your head around what the rules represent.</p>
<h2>Variables, contexts, and environments</h2>
<p>The language we’ve been using as a running example so far is exceptionally simple. One complication I’ve intentionally chosen to avoid so far is <em>variables</em>, but we need to consider them if we want to be able to write typing rules for any useful programming language. Let’s therefore expand our example language by adding functions, making it a variant of the <a href="https://en.wikipedia.org/wiki/Simply_typed_lambda_calculus" rel="noreferrer">simply typed lambda calculus</a> (STLC). This requires the following additions to the language’s grammar:
<span>$$
\begin{array}{rcll}
e \hskip{-10mu}
  &amp;::=&amp;\hskip{-10mu}\ldots\\
  &amp; | &amp;\hskip{-10mu} x &amp;\textrm{variable}\\
  &amp; | &amp;\hskip{-10mu} λx{:}\tau. e &amp;\textrm{function abstraction}\\
  &amp; | &amp;\hskip{-10mu} e\ e &amp;\textrm{function application}\\[8pt]
\tau \hskip{-10mu}
  &amp;::=&amp;\hskip{-10mu}\ldots\\
  &amp; | &amp;\hskip{-10mu} \tau → \tau &amp;\textrm{functions}
\end{array}
$$</span>
Here, <span>$x$</span> stands for “some variable”. If you are unfamiliar with the lambda calculus, the notation used here might appear somewhat exotic, but it is likely not as foreign as it seems: the STLC syntax <span>$λx{:}\tau. e$</span> corresponds directly to <code>(x:τ) =&gt; e</code> in TypeScript, and <span>$f\ x$</span> corresponds to <code>f(x)</code>.</p>
<p>With these additions to our grammar, the notation used for our typing relation does not change—it’s still just <span>$e : \tau$</span>—but the structure of our typing <em>judgment</em> must be extended. The trouble appears when we attempt to write a typing rule for variables:
<span>$$
\begin{array}{l}
\hline
⊢ x : \text{???}
\end{array}
$$</span>
The problem is that the type of a variable depends on the <em>context</em> it appears in. Therefore, we need to extend the typing judgment to keep track of the types of all variables that happen to be in scope, which we do using the following notation:
<span>$$
Γ ⊢ e : \tau
$$</span>
<span>$Γ$</span> is called “the context” or “the type environment”, and the role of the <span>$⊢$</span> now becomes clearer: it separates contextual assumptions from the statement to be proved. The extended judgment can therefore be pronounced “under the context <span>$Γ$</span>, the expression <span>$e$</span> has type <span>$\tau$</span>”, and algorithmically, <span>$Γ$</span> can be considered an additional “input” to the judgment of type <code>Map&lt;Variable, Type&gt;</code>. However, formally speaking, every typing rule must be defined syntactically, so contexts are explicitly represented in typing rules as syntactic constructs with the following shape:
<span>$$
\begin{array}{rcll}
Γ \hskip{-10mu}
  &amp;::=&amp;\hskip{-10mu} \varnothing &amp;\textrm{empty context}\\
  &amp; | &amp;\hskip{-10mu} Γ, x{:}\tau &amp;\textrm{variable binding}
\end{array}
$$</span>
Sometimes <span>$\bullet$</span> is used instead of <span>$\varnothing$</span> to represent the empty context. Under this representation, a context is essentially an <a href="https://en.wikipedia.org/wiki/Association_list" rel="noreferrer">association list</a> mapping variable names to types.</p>
<p>Most typing rules have no reason to care about the context. Most inference rules just pass it along unaltered, and most axioms ignore it altogether. For example, here are a couple typing rules from above adapted to our new judgment:
<span>$$
\begin{array}{l}\hline
Γ ⊢ \mathsf{true} : \mathsf{Bool}
\end{array} \quad \quad \begin{array}{l}
Γ ⊢ e_1 : \mathsf{Int} \\
Γ ⊢ e_2 : \mathsf{Int} \\
\hline
Γ ⊢ e_1 + e_2 : \mathsf{Int}
\end{array}
$$</span>
However, the context is essential for two new typing rules, which handle variable uses and lambda expressions:
<span>$$
\begin{array}{l}
x{:}\tau \in Γ \\
\hline
Γ ⊢ x : \tau
\end{array} \quad \quad
\begin{array}{l}
Γ,x{:}\tau_1 ⊢ e : \tau_2 \\
\hline
Γ ⊢ (λx{:}\tau_1. e) : \tau_1 → \tau_2
\end{array}
$$</span>
The second of these two rules is the more complex one, as it’s where all the magic happens: while typechecking the body <span>$e$</span> of the lambda expression, the context is extended with a new binding <span>$x{:}\tau_1$</span>. This information is then utilized by the first rule, which says that if there is a variable binding <span>$x$</span> with type <span>$\tau$</span> in the current context (and therefore in scope), then <span>$x$</span> has type <span>$\tau$</span>. In other words, the context is used as a communication mechanism to propagate information between these two rules.</p>
<p>(Observant readers may note that this model does not handle variable shadowing. As a simplifying assumption, type systems specified this way usually assume that all variables have already been resolved and made unique.)</p>
<p>If this still seems a bit confusing to you, it may help to consider the way these additions affect our <span>$\mathrm{infer}$</span> function from earlier:
<span>$$
\begin{array}{l}
\mathrm{infer} : (\mathsf{Context}, \mathsf{Expr}) → \mathsf{Type} \\
\mathrm{infer}(Γ, e) = \mathbf{match}\ e\ \mathbf{where} \\
\quad \begin{alignedat}{2}
  &amp;\ldots\\
  &amp;x &amp;&amp;↦ \mathrm{lookup}(Γ, x) \\
  &amp;(λx{:}\tau_1. e') &amp;&amp;↦ \mathbf{let}\: Γ' = \mathrm{extend}(Γ, x, \tau_1); \\
    &amp;&amp;&amp;\phantom{{}↦{}} \mathbf{let}\: \tau_2 = \mathrm{infer}(Γ', e'); \\
    &amp;&amp;&amp;\phantom{{}↦{}} \mathsf{\tau_1 → \tau_2}
\end{alignedat}
\end{array}
$$</span></p>
<p>The only remaining rule we need to add to cope with the addition of functions is a rule for function application:
<span>$$
\begin{array}{l}
Γ ⊢ e_1 : \tau_1 → \tau_2 \\
Γ ⊢ e_2 : \tau_1 \\
\hline
Γ ⊢ e_1\ e_2 : \tau_2
\end{array}
$$</span>
That’s it!</p>
<h2>Other common notation and considerations</h2>
<p>The above describes the large majority of notation used to specify type systems if measured by volume, but modifications and extensions to this foundation are extremely common. It would be impossible to cover all of them, but fortunately, good papers usually explain whatever nonstandard notation they choose to introduce. However, some conventions are common enough that they are often used without explanation; this section attempts to provide a basic survey and describe a few notational quirks.</p>
<p>Since this is not and can never be an exhaustive list, please open a separate question if you find some notation not covered here!</p>
<h2>Inference rule layout</h2>
<p>So far, all of the examples in this answer have laid out inference rules in a very regular, vertical way. However, placing each condition on its own line is not by any means required, so several conditions may appear side-by-side:
<span>$$
\begin{array}{c}
Γ ⊢ e_1 : \mathsf{Int} \hskip{25mu}
Γ ⊢ e_2 : \mathsf{Int} \\
\hline
Γ ⊢ e_1 + e_2 : \mathsf{Int}
\end{array}
$$</span>
Vertical and horizontal arrangement may even be combined within the same rule.</p>
<h2>Side conditions</h2>
<p>Usually, the conditions that appear above the horizontal bar in an inference rule are themselves judgments that must be satisfied by some combination of inference rules and axioms. However, this is not always the case: rules may also include arbitrary boolean expressions known as <em>side conditions</em>, which must all be true in order for the rule to be applied. The <span>$x{:}\tau \in Γ$</span> condition in our typing rule for variables is an example of a side condition.</p>
<p>A special type of side condition that sometimes appears in algorithmic type systems is written <span>$\alpha\ \mathbf{fresh}$</span>. This means that <span>$\alpha$</span> should be a fresh type variable, i.e. a type variable distinct from all other type variables.</p>
<h2>Subtyping</h2>
<p>Subtyping introduces a weaker notion of consistency between types than strict equality, and the subtyping relation must be explicitly defined. It is usually denoted <span>$\tau_1 &lt;: \tau_2$</span>, which can be read as “<span>$\tau_1$</span> is a subtype of <span>$\tau_2$</span>”.</p>
<p>The relation is often defined using the same syntax used to define judgments. For example, a very simple subtyping relation might introduce two special types, <span>$\top$</span> (pronounced “top”) and <span>$\bot$</span> (pronounced “bottom”), which are the supertype and subtype of all types, respectively. This relation can be expressed using three simple axioms:
<span>$$
\begin{array}{l}\hline \tau &lt;: \tau \end{array} \quad \quad
\begin{array}{l}\hline \tau &lt;: \top \end{array} \quad \quad
\begin{array}{l}\hline \bot &lt;: \tau \end{array}
$$</span>
The first rule is the reflexive rule, often abbreviated to “refl”, which states that every type is a subtype of itself and ensures that subtyping is strictly weaker than equality.</p>
<p>The defined subtyping relation must then be used explicitly in every rule that permits subtyping. For example, a system that supports subtyping might use the following rule for function application:
<span>$$
\begin{array}{l}
Γ ⊢ e_1 : \tau_2 → \tau_3 \\
Γ ⊢ e_2 : \tau_1 \\
\tau_1 &lt;: \tau_2 \\
\hline
Γ ⊢ e_1\ e_2 : \tau_3
\end{array}
$$</span></p>
<h2>Multiple contexts</h2>
<p>Some type systems define typing judgments involving more than one context. The second context is usually named <span>$Δ$</span>. Common notations for multi-context rules are <span>$Γ;Δ ⊢ e : \tau$</span> (used when both contexts are morally “inputs”) and <span>$Γ ⊢ e : \tau ⊣ Δ$</span> (used when <span>$Δ$</span> is morally an “output”).</p>
<p>The second context may be used for any number of different things. Perhaps certain variables can be referenced from inside certain expressions but not others, or perhaps an output context is used to keep track of which variables are “consumed” in a resource-aware programming language.</p>
<h2>Bidirectional typechecking</h2>
<p><a href="https://arxiv.org/abs/1908.05839" rel="noreferrer">Bidirectional typechecking</a> is an approach for performing a limited form of nonlocal type inference without the need to use a constraint solver. A bidirectional system splits the usual <span>$Γ ⊢ e : \tau$</span> typing judgment into two specialized judgments:</p>
<ul>
<li><p><span>$Γ ⊢ e ⇐ \tau$</span> is the <em>checking</em> judgment, which checks that <span>$e$</span> has some expected type <span>$\tau$</span>. Algorithmically, <span>$\tau$</span> is an <em>input</em> to this judgment.</p>
</li>
<li><p><span>$Γ ⊢ e ⇒ \tau$</span> is the <em>inference</em> judgment, which is used whenever expected type information is not available. Algorithmically, <span>$\tau$</span> is an <em>output</em> from this judgment.</p>
</li>
</ul>
<p>The two judgments are defined in a mutually-recursive way to propagate type information bidirectionally, which allows some type annotations to sometimes be omitted. For example, the checking variant of the rule for lambda abstraction may omit the annotation on the variable binder since it can be determined from the expected type:
<span>$$
\begin{array}{c}
Γ,x{:}\tau_1 ⊢ e ⇐ \tau_2 \\
\hline
Γ ⊢ (λx. e) ⇐ \tau_1 → \tau_2
\end{array}
$$</span></p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Requiring ink to scan a document–yet another insult from the printer industry (166 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2023/08/the-printers-that-require-ink-to-scan-and-fax/</link>
            <guid>37138691</guid>
            <pubDate>Tue, 15 Aug 2023 20:06:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2023/08/the-printers-that-require-ink-to-scan-and-fax/">https://arstechnica.com/gadgets/2023/08/the-printers-that-require-ink-to-scan-and-fax/</a>, See on <a href="https://news.ycombinator.com/item?id=37138691">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/08/hp-printer-e1692118118328-800x819.jpg" alt="HP ENVY 6455e printer">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/08/hp-printer-e1692118118328.jpg" data-height="1245" data-width="1216">Enlarge</a> <span>/</span> Don't bother hitting the scan button if you're out of ink.</p></figcaption>  </figure>

  




<!-- cache hit 4:single/related:e295cebb7bd5fad088ecd7ff3995225e --><!-- empty -->
<p>How much ink does an all-in-one printer need in order to fax a document? Or to scan one to your computer? The obvious answer is "none." But if you own certain printers from companies like HP and Canon, you won't be able to use core features unless the device has ink—even if those features <em>have nothing to do with ink.&nbsp;</em></p>
<p>Unfortunately, all-in-one printers arbitrarily demanding ink to perform non-printing functions <a href="https://www.consumerreports.org/consumerist/if-you-want-to-scan-without-an-ink-cartridge-maybe-dont-buy-an-all-in-one-at-all/">isn't a new frustration</a>. And that's despite some companies having printers that can <a href="https://support.brother.com/g/b/faqend.aspx?c=us&amp;lang=en&amp;prod=mfcj4335dw_us_eu&amp;faqid=faq00002608_007">scan without ink</a>. Clearly, scanning or faxing without requiring an ink cartridge would improve users' experience—and they've illustrated that through class-action lawsuits. But this hasn't stopped printer makers from fighting to keep the nettlesome practice.</p>
<h2>No ink, no scan</h2>
<p>Since mid-2022, HP has been fighting a class-action lawsuit alleging that certain all-in-one printer models won't scan or fax without ink and that HP doesn't properly disclose this to shoppers. On January 13, 2023, the complaint was dismissed but allowed to be amended (you can view the amended complaint here: [<a href="https://cdn.arstechnica.net/wp-content/uploads/2023/08/hp-complaint.pdf">PDF</a>]), and on August 10, a Northern District of California judge dismissed HP's motion to dismiss the amended complaint [<a href="https://cdn.arstechnica.net/wp-content/uploads/2023/08/HP-dismissed.pdf">PDF</a>].</p>
<p>HP Envy 6455e and HP Deskjet 2655 purchasers Gary Freund and Wayne McMath filed the complaint, which states that HP printers are designed to enter an error state when low or out of ink, preventing usage until the installment of a new ink cartridge. The plaintiffs are also peeved that HP marketing and advertising doesn't clearly disclose this, the complaint says. The complaint also notes that an HP support agent has <a href="https://h30434.www3.hp.com/t5/Scanning-Faxing-Copying/Scanning-without-a-working-ink-cartridge/td-p/6777739">said</a> that HP printers are "designed in such a way that with the empty cartridge or without the cartridge the printer will not function."</p>                                            
                                                        
<p>"HP’s All-in-One Printers do not work as advertised. Ink is <em>not</em> a necessary component to scan or to fax a document," the complaint reads.</p>
<p>It adds:</p>
<blockquote><p>Tying the scan or fax capabilities of the All-In-One Printers to ink contained in the devices offers no benefit and only serves to disadvantage and harm consumers financially. However, tying the scan or fax capabilities of the All-In-One Printers to ink contained in the devices does, however [sic], serve to benefit HP.</p></blockquote>
<p>Anyone who's owned an inkjet printer knows how expensive ink can be. That suggests a reason to push people to buy ink through tactics like blocking core features if no ink is present and <a href="https://www.consumerreports.org/electronics-computers/printers/why-is-printer-ink-so-expensive-a2101590645/">reportedly</a> selling printers below cost. Ink-buying programs have also become cash cows. HP in 2021, for example, said its Instant Ink subscription business was worth $500 million, per <a href="https://www.crn.com/news/components-peripherals/hp-says-instant-ink-is-a-500m-business-with-30-percent-growth">CRN</a>. In its Q2 2023 financial report, HP named Instant Ink a key growth area.</p>
<p>The complaint against HP says:</p>
<blockquote><p>Indeed, HP designs its All-in-One printer products so they will not work without ink. Yet, HP does not disclose this fact to consumers. … Even were it technically possible to scan a document without all ink cartridges present, HP does not disclose any 'workaround'&nbsp; to consumers in any of the product packaging nor in any of HP’s advertising and marketing materials regarding its multi-function devices.</p></blockquote>
<p>The complaint seeks monetary damages as well as the end of HP's "misleading advertising and marketing campaign" and for HP to "engage in a corrective campaign to inform consumers of the misleading advertising."</p>
<p>Here are all the HP printer models listed in the complaint:</p>
<ul>
<li aria-level="4">HP Deskjet 2755e</li>
<li aria-level="4">HP DeskJet 3755</li>
<li aria-level="4">HP DeskJet 4155e</li>
<li aria-level="4">HP ENVY 6055e</li>
<li aria-level="4">HP ENVY 6075</li>
<li aria-level="4">HP ENVY 6455</li>
<li aria-level="4">HP ENVY Pro 6475</li>
<li aria-level="4">HP OfficeJet 250 Mobile</li>
<li aria-level="4">HP OfficeJet Pro 7740 Wide Format</li>
<li aria-level="4">HP OfficeJet Pro 8025</li>
<li aria-level="4">HP DeskJet 2622</li>
<li aria-level="4">HP DeskJet 2655</li>
</ul>
<p>HP declined to comment on this story.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ISPs complain that listing every fee is too hard, urge FCC to scrap new rule (458 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2023/08/isps-complain-that-listing-every-fee-is-too-hard-urge-fcc-to-scrap-new-rule/</link>
            <guid>37138681</guid>
            <pubDate>Tue, 15 Aug 2023 20:05:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2023/08/isps-complain-that-listing-every-fee-is-too-hard-urge-fcc-to-scrap-new-rule/">https://arstechnica.com/tech-policy/2023/08/isps-complain-that-listing-every-fee-is-too-hard-urge-fcc-to-scrap-new-rule/</a>, See on <a href="https://news.ycombinator.com/item?id=37138681">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/08/getty-internet-bills-800x533.jpg" alt="Dollar signs superimposed on a photo of a person's hands typing on a laptop keyboard.">
      <figcaption><p>Getty Images | anyaberkut</p></figcaption>  </figure>

  




<!-- cache hit 4:single/related:c2dc09635dc8106c544e0dc4acf983a2 --><!-- empty -->
<p>The US broadband industry is united in opposition to a requirement that Internet service providers list all of their monthly fees. Five lobby groups representing cable companies, fiber and DSL providers, and mobile operators have repeatedly urged the Federal Communications Commission to eliminate the requirement before new broadband labeling rules take effect.</p>
<p>The trade associations <a href="https://www.fcc.gov/ecfs/document/10117331109471/1">petitioned the FCC</a> in January to change the rules and renewed their call last week in a <a href="https://www.fcc.gov/ecfs/document/10811085828256/1">filing</a> and in a meeting with FCC officials. The requirement that ISPs list all their monthly fees "would add unnecessary complexity and burdens to the label for consumers and providers and could result in some providers having to create many labels for any given plan," the groups said in the filing on Friday.</p>
<p>The trade groups said the FCC should instead "require providers to include an explanatory statement that such fees may apply and that they vary by jurisdiction, similar to the Commission's treatment of government-imposed taxes," or require "the display of the maximum level of government-imposed fees that might be passed through, so that consumers would not experience bill shock with respect to such fees."</p>
<p>The filing was submitted by NCTA-The Internet &amp; Television Association, which represents Comcast, Charter, Cox, and other cable companies. The NCTA's <em>ex parte</em> filing described a meeting with FCC officials that also included wireless industry trade group CTIA and USTelecom, which represents telcos including AT&amp;T, Verizon, Lumen (formerly CenturyLink), Frontier, and Windstream.</p>
<p>The meeting was attended by two other groups representing smaller ISPs: NTCA-The Rural Broadband Association and ACA Connects-America's Communications Association. The trade groups met on Wednesday with the legal advisors to FCC Chairwoman Jessica Rosenworcel and Commissioner Brendan Carr, according to the filing.</p>                                            
                                                        
<h2>Comcast accused of “trying to create loopholes”</h2>
<p>Comcast submitted its own filing urging the FCC to scrap the rules in June. The calls to weaken the FCC's truth-in-billing rules angered consumer advocates, as we <a href="https://arstechnica.com/tech-policy/2023/06/comcast-complains-to-fcc-that-listing-all-of-its-monthly-fees-is-too-hard/">wrote at the time</a>. "The label hasn't even reached consumers yet, but Comcast is already trying to create loopholes. This request would allow the big ISPs to continue hiding the true cost of service and frustrating customers with poor service," Joshua Stager, policy director at media advocacy group Free Press, told Ars.</p>
<p>Congress required the FCC to implement broadband labels with <a href="https://arstechnica.com/tech-policy/2022/01/fcc-aims-to-stop-broadband-bill-shock-reviving-plan-nixed-by-ajit-pai/">exact prices</a> for Internet service plans in a <a href="https://arstechnica.com/tech-policy/2021/11/congress-oks-42-billion-to-deploy-100mbps-broadband-in-unserved-areas/">2021 law</a>, but gave the FCC some leeway in how to structure the rules. The <a href="https://www.fcc.gov/document/fcc-requires-broadband-providers-display-labels-help-consumers">FCC adopted specific</a> label rules in November 2022.</p>
<p>The labels must be displayed to consumers at the point of sale and include monthly price, additional charges, speeds, data caps, additional charges for data, and other information. The FCC rules aren't in force yet because they are subject to a federal Office of Management and Budget (OMB) review under the US Paperwork Reduction Act.</p>
<p>ISPs object to a portion of the FCC order that says, "providers must list all recurring monthly fees" including "all charges that providers impose at their discretion, <em>i.e.</em>, charges not mandated by a government." The five trade groups complain that this would require ISPs "to display the pass-through of fees imposed by federal, state, or local government agencies on the consumer broadband label."</p>
<p>But just because an ISP says a fee is related to a government charge doesn't mean that ISPs have to break them out separately. ISPs could instead include all costs in their advertised rates to give potential customers a clearer idea of how much they would have to pay each month.</p>
<p>"A provider that opts to combine all of its monthly discretionary fees with its base monthly price may do so and list that total price. In that case, the provider need not separately itemize those fees in the label," the FCC order said.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My deep learning rig (2022) (157 pts)]]></title>
            <link>https://nonint.com/2022/05/30/my-deep-learning-rig/</link>
            <guid>37138672</guid>
            <pubDate>Tue, 15 Aug 2023 20:05:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nonint.com/2022/05/30/my-deep-learning-rig/">https://nonint.com/2022/05/30/my-deep-learning-rig/</a>, See on <a href="https://news.ycombinator.com/item?id=37138672">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
		<main id="main">

		
<article id="post-218">
			<!-- .entry-header -->

	<div>
		
<p>A lot of people have asked about the computers I used to train TorToiSe. I’ve been meaning to snap some pictures, but it’s never “convenient” to turn these servers off so I keep procrastinating.</p>



<p>We had some severe thunderstorms today here in the front range which forced me to shut down my servers. I took the opportunity to take some photos.</p>



<h2>A little history to start</h2>



<p>Building out my servers has been a long, multi-year effort. I started the process right around the time that NVIDIA launched their Ampere GPU lineup. I was fortunate to be able to grab 6 RTX 3090s right around launch time, and slowly built up my inventory one GPU at a time over the course of 2021. I’m sure no one will believe me, but I did manage to purchase every one of the 16 GPUs I own at MSRP.</p>



<p>I maintain two servers. The reason is that I run this whole operation as a business: one of my servers is rented out on vast.ai. This server pays the bills: electricity, component replacement, upgrades, etc. The other server is solely used for my deep learning projects. Both servers are identical except for storage and GPU count. The rental server only has 7 GPUs while my ML server has 8. My ML server also has a massive bank of SSDs to store my datasets.</p>



<p>It probably goes without saying, but I built and maintain these rigs myself. They were pieced together at the component level. I have always enjoyed building computers and I can honestly say that I like maintaining these rigs almost as much as I like using them to build models.</p>



<p>A goal from the get-go was maximum GPU density per-server. This is because without dropping serious $$$ on mellanox high-speed NICs and switches, inter-server communication bandwidth quickly becomes the bottleneck when training large models. I can’t afford fancy enterprise grade hardware, so I get around it by keeping my compute all on the same machine. This goal drives many of the choices I made in building out my servers, as you will see.</p>



<h2>Pics</h2>



<p>Here are some pictures of my 7 GPU rig. As stated above, the 8 GPU server is nearly identical except for a large SSD array hidden away inside.</p>



<p>The pictures were taken with a bright LED shining on the computer, and look far more dusty than they actually are. Don’t judge me. 🙂</p>



<figure><img width="1600" height="1234" src="https://nonint.com/wp-content/uploads/2022/05/front.jpg" alt=""><figcaption><em>Frontal view. The cabling slips in underneath the bottom fans when in operation.</em></figcaption></figure>



<figure><img loading="lazy" width="1600" height="1200" src="https://nonint.com/wp-content/uploads/2022/05/rear.jpg" alt=""><figcaption><em>Rear view. 3PSUs, 7GPUs and a motherboard. It’s a tight fit!</em></figcaption></figure>



<figure><img loading="lazy" width="1600" height="1397" src="https://nonint.com/wp-content/uploads/2022/05/side.jpg" alt=""><figcaption><em>Good view of my custom memory heat sinks, discussed later</em></figcaption></figure>



<figure><img loading="lazy" width="1600" height="1200" src="https://nonint.com/wp-content/uploads/2022/05/top2.jpg" alt=""><figcaption><em>Top down view. The cables are normally routed on the rear of the GPUs. I neglected to tidy up before taking the pics. Whoops.</em></figcaption></figure>



<figure><img loading="lazy" width="1600" height="1200" src="https://nonint.com/wp-content/uploads/2022/05/board.jpg" alt=""><figcaption><em>View of the motherboard. I use standard risers on this server for the GPUs powered by the main power supply and maxcloudon risers elsewhere. The other server only uses maxcloudon risers.</em></figcaption></figure>



<h2>Components</h2>



<p>Lets talk specs. My deep learning server consists of:</p>



<p><em>(Note: Amazon and eBay links below are affiliate links, because either I’m a shill, or it doesn’t matter – take your pick.)</em></p>



<ul><li>CPU: <a href="https://www.ebay.com/sch/i.html?_from=R40&amp;_trksid=p2380057.m570.l1313&amp;_nkw=epyc+7502&amp;_sacat=0&amp;mkcid=1&amp;mkrid=711-53200-19255-0&amp;siteid=0&amp;campid=5338090643&amp;customid=7502&amp;toolid=10001&amp;mkevt=1">AMD EPYC 7502</a></li><li>GPUs: 8x RTX 3090</li><li>Motherboard: <a href="https://amzn.to/38TRekO">Asrock ROMED8-2T</a></li><li>Memory: 256GB <a href="https://www.ebay.com/sch/i.html?_from=R40&amp;_trksid=p2380057.m570.l1313&amp;_nkw=Cisco+PC4-2400T&amp;_sacat=0&amp;mkcid=1&amp;mkrid=711-53200-19255-0&amp;siteid=0&amp;campid=5338090643&amp;customid=&amp;toolid=10001&amp;mkevt=1">Cisco PC4-2400T DDR4 RAM</a></li><li>Storage: <a href="https://amzn.to/3NHnZjN">Samsung 970 EVO 512GB</a>, <a href="https://amzn.to/3NHoiLt">ADATA SX8200PNP 2TB</a>, 8x <a href="https://amzn.to/3t9wpZl">Samsung 860 QVO 8TB</a></li><li>Case: <a href="https://www.ebay.com/itm/184640925437?amdata=enc%3AAQAHAAAAkC2480pi5NLN13z03ExumKClbw2426NYSe2YIwKeYiBi0MC%2BQ0DCu5uFToSmo1Rx%2BUbw1qNSfl8bSIe3S9iAJLA0Q1%2BNjUOmgSwZwHzEIZkV4x1jiSeBqG4V7%2BdtpUo9LZnXyfFqJrHBXBkRZnpz3xVQAVELEHkiG0akwcT%2FF1lD%2F7cIRth%2FH9idfZLMHWAthw%3D%3D&amp;mkcid=1&amp;mkrid=711-53200-19255-0&amp;siteid=0&amp;campid=5338090643&amp;customid=aaawave&amp;toolid=10001&amp;mkevt=1">AAAwave 12 GPU</a></li><li>PCI-E Risers: <a href="https://riser.maxcloudon.com/en/bifurcated-risers/25-bifurcated-riser-x16-to-2x8-set.html">Maxcloudon Bifurcated Risers</a></li><li>PSUs: 3x <a href="https://amzn.to/3GBFqjl">EVGA 1600W G+</a></li></ul>



<p>I’ll talk over these choices:</p>



<p><strong>CPU</strong> – This was an easy choice. With the goal being GPU density, PCIe lanes were of paramount importance. EPYC has no competition in this regard. In terms of choosing core-counts: I deemed 64 cores to be excessive for my needs, and it is fairly hard to come across 24-core EPYCs. I purchased both of my 7502 CPUs used for under $1000 on eBay. I think this was a steal. The other good option is the Threadripper pro, for which the 32 core model retails at $2800. One of my EPYC’s is a retail model, the other is a QS model. I haven’t noticed any difference between the two. If you buy one of these like I did, be very careful not to buy one removed from an American server manufacturer, they are often node-locked.</p>



<p><strong>GPUs </strong>– I use RTX 3090s exclusively. I am not married to any particular version of the 3090, and my servers are a hodge-podge of the OEM NVIDIA 3090 variant and the EVGA FTW variant. The reason I only have these two is because all other manufacturers are scalping us (though I expect that to change soon..) I also like the rear-exhaust design of the OEM model, which lends itself well to multi-GPU configurations. I re-pasted and replaced the thermal pads on all of my GPUs. Both EVGA and NVIDIA did a horrible job with memory thermals and they should frankly be embarrassed with themselves. Selling $2000 GPUs that immediately go to 100% fan power and derate themselves when the memory modules hit 110C is utterly unacceptable. This is not just because I am misusing these GPUs: I have a single-GPU workstation that exhibits the same problems while gaming. Shame. I also added custom heatsinks to the backplates of the OEM 3090s where the memory modules reside. These reduce the memory temps by an additional 10C.</p>



<p><strong>Motherboard</strong> – My primary goal when selecting a motherboard was to find a single-CPU board with the maximum number of possible full-width PCI-E x16 slots. Since I was bound to the EPYC CPU, this basically constrained me to the ROMED8-2T. On paper, this board has fantastic specs and was exactly what I was looking for. In practice, it has a fair number of infuriating bugs that make me wish some other players were in the market. For example, I cannot update the firmware on the board (it always errors out no matter which method I use), the IPMI is garbage, and you cannot use all of the SATA ports without doing a weird configuration hack in the BIOS which has no documentation whatsoever.</p>



<p><strong>RAM</strong> – Server memory is damned expensive! The only nice thing I can say about my memory is that it was cheap. My RAM is slow and the sticks are slowly dying one at a time. This will be the next upgrade when I can scrape together the sheckels..</p>



<p><strong>Storage</strong> – I have a 1TB NVME for the OS drive and a 2TB NVME to store code and model checkpoints. The latter is certainly overkill as everything vital is permanently in RAM anyways. I also have an array of 8x 8TB Samsung QVOs in RAID 5 with 1 redundant drive to store my datasets. Random access is extremely important for machine learning so HDDs were not an option. These are quite pricey these days but I picked them up for under $500/pc on a lucky black friday sale. Kinda wish I had bought some more at this point.</p>



<p><strong>Case</strong> – I originally constructed my two servers in a <a href="https://www.ebay.com/itm/324829932257?hash=item4ba15f6ae1:g:ZI4AAOSw5HthZvwR&amp;amdata=enc%3AAQAHAAAA4BuCn70W1EYPTDdnlWlj9%2BtWajQcNd5yYcBdN56uwgsDSTkBiyzr7djdPtemFKgqXBAtlmcqdHJy8WJhJf4jYVFY6hGKtygeT95xCH0P%2Fj0F%2BPKRbCTCtLH0yZg94q8yTz9cOsOg4ryW%2B7MgJtqXpU2jOORCAIFDJqeIhX%2BnB%2FMLOxzVarQPZLPMVP8LKOOK2d87ZwcA3OpefyNjimR0%2Fp1aXYjWwuMrJt0RpwXK8DMnaqYsPP6L431dJWyYkQG1WCFy7boztmEB6FlIoTRRuFbkv8sGQgzHHORmKDg78R4q%7Ctkp%3ABFBMuqCh3aJg">rackmounted chassis</a> built for mining. I had a lot of trouble with airflow and maintenance was a PITA. At some point I gave up and went for an open-air design, which is what I have stuck with. The AAAwave case I ended up with is basic and fairly cheap, and it gets the job done. I could probably fit 9 3090s total in this case, but I’d probably want to get more clever about airflow if I did so.</p>



<p><strong>PCI-e Risers</strong> – This is another component that is surprisingly tricky to figure out. Because most of the GPUs use a different power supply from the motherboard, you cannot use “normal” PCI-e risers like you would find at your local computer parts store. You need to use risers with an electrically isolated PCI-e slot. I also needed risers with a fairly long length, at least 2 feet. There were two options I found for this: the first are the <a href="https://comino.com/en/risers/">Comino risers</a>. LTT featured these awhile back and they are some slick kit. Unfortunately, they have some kind of issue with 3090 cards (or I am using them wrong). I had three of them burn out at the PCI-e connector before I gave up on them permanently. Fortunately, none of them damaged any GPUs. Lately, I have been using <a href="https://riser.maxcloudon.com/en/bifurcated-risers/25-bifurcated-riser-x16-to-2x8-set.html">these bifurcated risers</a> from maxcloudon. They allow me to split my GPU slots (meaning I can support up to 14 GPUs on a single server!) and have been dead reliable for almost 6 months now. The biggest downside is that all of these risers only work with PCIE gen 3. If anyone has any tips for power-isolated gen 4 compatible risers with bifurcation support, PLEASE contact me. You will have a friend for life.</p>



<p><strong>PSUs</strong> – Naive me thought that I would be able to power 4x “350W” GPUs with a single 1600W PSU. Nope. Doesn’t work, not even on 240V. A lesser-known fact about 3090s is they actually pull burst currents of up to 600W. This means that a 1600W PSU will power-on and even run 4x 3090s, but it will randomly trip the overcurrent protection when all 3090s simultaneously draw their peak power, which happens every couple of hours. This was a fun one to figure out. I now run 3 1600W PSUs, each one powering 3 GPUs (or 2 GPUs+everything else). All PSUs run on 240V circuits I had installed specifically for these servers. I have several 2400W server PSUs that I intend to move to someday, but they are too loud to be used while these servers live in my home.</p>



<h2>Cooling &amp; Power</h2>



<p>When I moved past 6 GPUs, power and thermals started to become a concern for me. I housed these servers in the utility room of my basement, so ventilation was already pretty good and the heat didn’t affect my family too much, but I was worried about component life as the room was regularly sitting at 100F. I had also exhausted what two 120V outlets were able to safely give.</p>



<p>To solve the electricity problem, I had an electrician come in and install two 240V circuits with L6-20P sockets. You can purchase cords that are compatible with most large power supplies for these sockets on eBay. Most high-end power supplies are already dual-voltage compatible so nothing needed to be done there. Some power supplies come with switches on the back to swap between 120V and 240V so RTFM.</p>



<p>Heat was a bit more challenging. My utility room has two ventilation shafts built in which were passive. I opted to install two <a href="http://vortexpowerfans.com/vtx-series">centrifugal air pumps</a>, one hooked to each ventilation shaft to move air out of the room. I built an enclosure around the servers using cinderblocks and sheet metal. I made the enclosure air-tight and the centrifugal pumps pull air directly from inside the enclosure, establishing negative pressure behind the computers. This was highly effective at dealing with the heat problem, and the room is only a few degrees above the rest of the house now. </p>



<figure><img loading="lazy" width="1200" height="992" src="https://nonint.com/wp-content/uploads/2022/05/slot-1.jpg" alt=""><figcaption><em>Each server slots into a cinderblock &amp; sheetmetal enclosure which is ventilated by dual centrifugal fans.</em></figcaption></figure>



<p>I want to provide an operational note that is related to thermals an power: I set the power limit on all of my GPUs to 285W, ~80% of the rated power of a 3090. From testing, this reduces performance by ~6% but greatly improves thermals.</p>



<p>The GPUs do run hot, however. Viewed from the front of the server, the rightmost GPUs run the hottest in the high 70s C, as reported by nvidia-smi. The leftmost operate in the 60s. I justify this by remembering that my A5000 workstation GPU runs at 85C at all times, despite having excellent airflow.</p>



<figure><img loading="lazy" width="1440" height="1080" src="https://nonint.com/wp-content/uploads/2022/05/FLIR_20220530_080006.jpg" alt=""><figcaption><em>Pic of the thermals of a few of the GPUs while training. The hot regions are where the GDDR6X memory contacts the back plate, hence the fins I installed on all of the OEM GPUs. EVGA GPUs are a tad better in this regard.</em></figcaption></figure>



<h2>A practical guide to using multiple PSUs</h2>



<p>Figuring out how to power these servers with multiple PSUs was by far the most nerve-wracking part of the build. If you attempt to do some research about going this route, be prepared to read commentary from hundreds of self-professed electrical engineers telling you “<strong>do not, under any circumstances do this!</strong>“</p>



<p>Being the headstrong and reckless guy that I am, I did it anyways. My line of reasoning was that if I isolated the PSUs into separate “circuits” that only got joined at the ground and data lines, I probably wouldn’t have to worry too much about them fighting with each other and causing failures. I built out these “circuits” using the maxcloudon PCIe powered risers, which allow me to fully power on 3x GPU “subsystems” with each 1600W power supply. All “circuits” are tied at the ground.</p>



<p>One extremely strange issue I ran into at one point was that one of my servers became what I can only describe as “electrically tainted”. If this computer was plugged into a network switch, the switch stopped routing traffic and the entire network behind that switch went dead. The computer was still operating fine with an attached keyboard and monitor. After a lot of experimentation, I isolated the problem to a single power supply “circuit” on the computer. If this circuit (and the attached GPUs) was disabled, the problem disappeared. The only unique thing about this circuit is that it was powered by a different PSU, a corsair AX1600i while the rest of the circuits used EVGA Golds. On a whim, I swapped in a spare 1600 gold and the problem disappeared. Since then, when combining PSUs, I have only used PSUs from the of the same make and model.</p>



<p>Past the above issue, I have not had any other problems in 2 years of near-continuous operation for both servers. Does this mean you should do it? Probably not. I’m not an EE and this is some expensive equipment. You make your own risk calls.</p>



<h2>Why am I not using &lt;x&gt; GPU?</h2>



<p>Because, frankly, the 3090 is a very nice sweet spot for someone like me looking to balance cost and performance. A little known, but fun fact is that it actually has better FP32 performance than even the A100. FP16 performance is dogshit due to software locks NVIDIA put in place. There is little reason to use FP16 except for the small amount of VRAM savings. That’s fine, it means I don’t have to worry about numeric stability. 🙂</p>



<p>I have considered building out a A6000 server. 48GB of VRAM would be quite nice, and fully unlocking FP16 would be great as well. I also prefer the cooling solution on the A6000 (though knowing about the shit NVIDIA pulled with the 3090, I’m sure the thermals are atrocious). It’s honestly a cost problem at this point. An 8x A6000 server will cost me somewhere in the realm of $40k, maybe a little less if NVIDIA gave me some research / SMB discounts. That’s more than both of the servers I currently own cost combined. Just for the GPUs. It’ll be cool if I could scrape that kind of dough together at some point, but for now I’m stuck to consumer GPUs. </p>



<h2>Wrapping up..</h2>



<p>I hate that high performance computing has become synonymous with the hyperscalers and that most people don’t even consider building out their own hardware anymore. Building computers is super cool and more people should do it. It may even become relatively cheap to do so as miners start liquidating their assets after ETH 2.0 goes live. I hope this helps out others who are interested in building deep learning rigs.</p>



<p>One other thing: I hesitated somewhat posting this out of concerns of becoming a target for robbery. To any would be thieves out there: my computers will soon be relocated to a new industrial space so that I can continue building out my operation. Please stay away from my home.</p>

			</div><!-- .entry-content -->
</article><!-- #post-218 -->

		</main><!-- #main -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Asteroid ZTm0038 with a >3% impact probability (209 pts)]]></title>
            <link>https://newton.spacedys.com/neodys2/NEOScan/risk_page/ZTm0038/index_summary_ZTm0038.html</link>
            <guid>37138102</guid>
            <pubDate>Tue, 15 Aug 2023 19:19:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newton.spacedys.com/neodys2/NEOScan/risk_page/ZTm0038/index_summary_ZTm0038.html">https://newton.spacedys.com/neodys2/NEOScan/risk_page/ZTm0038/index_summary_ZTm0038.html</a>, See on <a href="https://news.ycombinator.com/item?id=37138102">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="mainContent2">

	<!-- #CONTENT-WARNING-NOSIG -->
		
	<table>
	  <tbody><tr>     
	    <!--
		<th align="center" width="50">NEOCP name            </th>
		-->
	    <th>Asteroid name            </th>
	    <th>Number of observations</th>
	    <th>Arc length (h)        </th>
	    <th title="Epoch of the orbit with minimum χ">Epoch (MJD)         </th>
	    <th title="Residuals RMS of the orbit with minimum χ">RMS          </th>
	    <th title="Absolute magnitude of the orbit with minimum χ">H            </th>
	    <th title="MOID of the orbit with minimum χ">&nbsp;MOID&nbsp; (au)    </th>
	    <th title="Closest approach distance of the orbit with minimum χ">CA dist. (LD)</th>
	    <th title="Velocity at infinity of the orbit with minimum χ">V_inf (km/s)</th>
	  </tr>
	  <!-- #CONTENT-GEN -->
<tr>
<td>ZTm0038</td>
<td>8</td>
<td>24.23</td>
<td>60169.002</td>
<td>1.183</td>
<td>19.90</td>
<td>0.0000296</td>
<td></td>
<td>15.84</td>
</tr>
	</tbody></table>

	<br>
	<!--
	    !-------------!
	    ! Scores data !
	    !-------------!
	  -->
	<h3> Probabilities and scores </h3> 
	<center>
	  <table>
	    <tbody><tr>
	      <td>
		<table>
		  <tbody><tr>     
		    <th>NEO score</th>
		    <th>MBO score</th>
		    <th>&nbsp;&nbsp;DO&nbsp;&nbsp; score</th>
		    <th>&nbsp;&nbsp;SO&nbsp;&nbsp; score</th>
		  </tr>
		  <!-- #CONTENT-SCORE-OBJ -->
<tr>
<td>1.00</td>
<td>0.00</td>
<td>0.00</td>
<td>0.00
</td>
</tr>
		</tbody></table>
	      </td>
	      <td></td><td></td><td>
	      </td><td>
		<table>
		  <tbody><tr>     
		    <th>PHA score</th>
		  </tr>
		  <!-- #CONTENT-SCORE-PHA -->
<tr>
<td>1.00</td>
</tr>
		</tbody></table>
	      </td>
	      <td></td><td></td><td>
	      </td><td>
		<table>
		  <tbody><tr>     
		    <th>Geocentric score</th>
		  </tr>
		  <!-- #CONTENT-SCORE-GEOC -->
<tr>
<td> 0.028</td>
</tr>
		</tbody></table>
	      </td>
	      <td></td><td></td><td>
	      </td><td>
		<table>
		  <tbody><tr>     
		    <th>Impact probability</th>
		  </tr>
		  <!-- #CONTENT-IP -->
<tr>
<td>0.034</td>
</tr>
		</tbody></table>
	      </td>
	    </tr>
	  </tbody></table>
	</center>

	<br>
	<!--
	    !-----------------------!
	    ! Auxiliary information !
	    !-----------------------!
	  -->
	<h3> Auxiliary information </h3> 
	<!-- #CONTENT-AUXILIARY-INFO -->
<p>Absolute magnitude of impactors: H_min = 18.84 and H_max = 20.84</p>
<p>Closest approach time of impactors: t_min = 2023/08/14 04:48 TDB and t_max = 2023/08/15 12:22 TDB</p>
<p>Velocity at infinity of impactors: v_inf_min =   7.668 [km/s] and v_inf_max =  55.785 [km/s]</p>
<p>Run started at 2023-08-14 23:51 UTC and ended at 2023-08-15 00:06 UTC</p>

	<br>
	<!-- 
	     !----------!
	     ! Arc data !
	     !----------!
	  -->
	<h3> Arc data </h3>	
	<table>
	  <tbody><tr>     
	    <th rowspan="2">Arc type                 </th>
	    <th colspan="3">Significance of curvature</th>
	  </tr>
  	  <tr>     
	    <th>Geodesic    </th>
	    <th>Acceleration</th>
	    <th>Overall     </th>
	  </tr>
	  <!-- #CONTENT-ARC -->
<tr>
<td>1</td>
<td>-1.93</td>
<td>-3.08</td>
<td>3.65</td>
</tr>
	</tbody></table>

	<br>
	<!--
	    !-------------------!
	    ! MOV sampling data !
	    !-------------------!
	  -->
	<h3> MOV sampling data </h3>
	<table>
	  <tbody><tr>     
	    <th>Number of sample points       </th>
	    <th>Number of MOV orbits          </th>
	    <th>Number of impacting MOV orbits</th>
	  </tr>
	  <!-- #CONTENT-SAMPLING -->
<tr>
<td>6400</td>
<td>969</td>
<td>204</td>
</tr>
	</tbody></table>

	<br>
	
	<!-- #CONTENT-BACK-TO-MAIN -->
<h3><a href="https://newton.spacedys.com/neodys2/NEOScan/index_risk.html">BACK to the Risk Page</a></h3>      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Probabilistic Machine Learning: Advanced Topics (173 pts)]]></title>
            <link>https://probml.github.io/pml-book/book2.html</link>
            <guid>37137810</guid>
            <pubDate>Tue, 15 Aug 2023 18:57:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://probml.github.io/pml-book/book2.html">https://probml.github.io/pml-book/book2.html</a>, See on <a href="https://news.ycombinator.com/item?id=37137810">Hacker News</a></p>
<div id="readability-page-1" class="page">
by <a href="https://www.cs.ubc.ca/~murphyk/">Kevin Patrick Murphy</a>.
<br>
MIT Press, 2023.


	<p>
	  <img src="https://raw.githubusercontent.com/probml/pml2-book/main/cover2.jpg" alt="Book cover">
</p><h2>Key links</h2>

<ul>
	  
	<li> <a href="#toc">Short table of contents</a>
		
	    </li><li> <a href="https://github.com/probml/pml2-book/blob/main/toc2-long-2023-01-19.pdf">
		    Long table of  contents</a>
		    
</li><li> <a href="https://github.com/probml/pml2-book/blob/main/preface2-2023-01-02.pdf">Preface</a>

  </li><li> <a href="https://github.com/probml/pml2-book/releases/latest/download/book2.pdf">
    Draft pdf of the main book</a>, 2023-08-15.  CC-BY-NC-ND license. (Please cite the official reference below.)
       		    
</li><li> <a href="https://github.com/probml/pml-book/blob/main/supp2.md">Supplementary material</a>
	
  </li><li> <a href="https://github.com/probml/pml2-book/issues">Issue tracker</a>. 
	   
	  </li><li> <a href="https://github.com/probml/pyprobml/tree/master/notebooks/book2">
	    Code to reproduce most of the figures</a> 
		 
	  
</li><li> <a href="#ack">Acknowledgements</a>
	
	</li><li> <a href="#endorsements">Endorsements</a>
	
</li></ul>

If you use this book, please be sure to cite
<pre><code>
 @book{pml2Book,
 author = "Kevin P. Murphy",
 title = "Probabilistic Machine Learning: Advanced Topics",
 publisher = "MIT Press",
 year = 2023,
 url = "http://probml.github.io/book2"
}
</code></pre>


<p> Downloads since 2022-02-28. 
  <img src="https://img.shields.io/github/downloads/probml/pml2-book/total" alt="download stats shield">
  
</p><h2><a id="toc">Table of contents</a></h2><a id="toc">


    <img src="https://raw.githubusercontent.com/probml/pml2-book/main/toc2-short-2023-01-02.png" alt="TOC">
    
	  
</a><h2><a id="toc"></a><a id="endorsements"></a>Endorsements</h2>

<ul>
	<li>
			"Kevin Murphy has distilled the vast and confusing literature on machine learning and neural networks
			into a beautifully written 
			and extremely clear textbook that will be a wonderful resource for both new students 
			and seasoned researchers who are trying to keep up with this fast moving field.  
			The chapter on generative models is a masterpiece."
			-- <a href="https://www.cs.toronto.edu/~hinton/">Geoff Hinton</a>, U. Toronto/ Google.
		  
	</li><li> "Kevin Murphy had already impressed and greatly benefited the machine learning community with his introductory
		book on probabilistic ML
		and I am delighted to see the depth and breadth of material in his new sequel on advanced probabilistic ML.
		The book covers topics which I believe are at the heart of past and upcoming advances in our field,
		while often lacking in the training of graduate students in computer science, 
		and I therefore recommend it highly to all of them."
		-- <a href="https://yoshuabengio.org/">Yoshua Bengio</a>, U. Montreal
		
		</li><li> "This book is an amazing tour de force: Murphy and his co-authors have described and systematized virtually 
		all of the important advances in machine learning over the past 30 years. Pick any topic, and they provide a 
		crisp description of the state-of-the-art methods in a common, well-chosen notation and using a set of core concepts 
		in modeling, statistics, and optimization. This book will be a valuable starting point for students entering 
		the field and a wonderful reference for seasoned researchers. It is hard to imagine a better antidote to the vast, 
		confusing, and voluminous literature in machine learning.  This is such an amazing book! I learned things even in the sections
		where I’m fairly up to date with the literature. " --- <a href="https://web.engr.oregonstate.edu/~tgd/">Tom Dietterich</a>,
		Oregon State University
		
	</li><li> "The prior version of Dr. Murphy's book was amongst the 3-4 books I recommended to students and machine learning colleagues 
		at all levels as being essential to own, and, perhaps more importantly, to always have readily at hand. 
		As machine learning has matured and evolved, no other comprehensive resource of this nature has even remotely
		kept pace with modern methodological developments.  This new version is a blessing for the machine learning community and frankly, 
		at this moment in time, is the only truly necessary machine learning book to own. 
		Very few people in the world can do what Dr. Murphy has done here and the world owes him its thanks." 
		-- <a href="https://www.cs.ubc.ca/~fwood/">Frank Wood</a>, UBC. 
		
	</li><li> "Whether teaching machine learning to undergrads, master students, or PhD students, 
		I found myself time and time again choosing the 2012 "Machine Learning: A Probabilistic Perspective" as the primary textbook. 
		When I heard about the new "Probabilistic Machine Learning" series, I was thrilled to see the expanded and modernized set of topics;
		this will be the go-to book for my ML courses at Stanford.  Kevin Murphy has a phenomenal ability to go deep while making topics 
		digestible to a broad audience.  His writing is clear and concise with great visuals throughout.  I highly recommend this as "the book" 
		for anyone wanting to become a well-versed ML expert." -- <a href="https://emilybfox.su.domains/">Emily Fox</a>, Stanford.
	
		
		</li><li> "Murphy’s book is certainly the most comprehensive resource on machine learning available today. 
			With the growing body of research in the field, 
			it is a daunting challenge to provide an organized perspective of the current state of  knowledge. 
			This book achieves this feat by integrating classic material, like MCMC inference, 
			with very recent developments like denoising diffusion models. 
			The material is organized and presented in a very accessible and intuitive manner,
			making the book an asset for any researcher or practitioner in the field." --
			<a href="https://cs3801.wixsite.com/amirgloberson">Amir Globerson</a>, Tel Aviv University.
			
		</li><li> "This new Advanced Topics volume will provide a crucial path from the foundations of machine
		learning to state-of-the-art probabilistic models, many of which have only been described in the research literature.  
		I particularly like the way it draws parallels between variational and Monte Carlo inference,
		and between graphical models and (Bayesian) deep learning, so one can see the deep links between 
		methods that are sometimes cast as competitors.  
		I look forward to the next generations of probabilistic machine learning that this volume inspires." 
		--- <a href="https://www.ics.uci.edu/~sudderth/">Erik Sudderth</a>, UC Irvine.
		
	
		
		</li><li> "This book provides an outstanding and deep tour of the most foundational ideas in probabilistic machine learning. 
		It explains the essential mathematical and computational tools that a student needs to move beyond the basics. 
		With this book, 
		Murphy provides a comprehensive resource that will be great not just to learn from, but also as a reference 
		to return to again and again." -- <a href="https://www.cs.princeton.edu/~rpa/">Ryan Adams</a>, Princeton.
	
	</li><li> "Kevin Murphy's book is a landmark achievement in machine learning. It provides an in-depth coverage of
		a wide range of topics in probabilistic machine learning, from inference methods to generative models
		and decision making. It gives a modern perspective on these topics, bringing them up to date with recent
		advances in deep learning and representation learning. The insights in this 
		book are essential for a solid understanding of the field, 
		and I highly recommend it to students and experts alike." 
		-- <a href="http://mlg.eng.cam.ac.uk/zoubin/">Zoubin Ghahramani</a>, Cambridge/Google.
		
	</li><li> "As a
researcher trained by Murphy's 2012 book, I was excited to read
its sequel "Probabilistic Machine Learning: Advanced Topics." This new
book brings us to the forefront of cutting-edge probabilistic ML,
distilling the recent advances into a systemic exposition. It
communicates the core ideas of these recent advances in an
impressively clear and intuitive way, while managing to convey the
depth of these ideas by situating them in a broad context. It will 
		become a major reference that I constantly return to."
		-- <a href="https://yixinwang.github.io/">Yixin Wang</a>, U. Michigan.
	</li></ul>
		
	
  <h2><a id="ack"></a>Acknowledgements</h2>

I would like to thank the following people for helping with this book.

<ul>

<li> People who helped to write various sections and chapters:
	Alex Alemi (Google),
 Jeff Bilmes (U. Washington), 
	Peter Chang,
 Marco Cuturi (Apple, work done at Google), 
	Alexander D'Amour (Google),
	Finale Doshi-Velez (Harvard),
 Roy Frostig (Google), 
	Justin Gilmer (Google),
	Giles Harper-Donnelly,
	Been Kim (Google),
	Durk Kingma (Google),
	Simon Kornblith (Google),
   Balaji Lakshminarayanan (Google),  
	Lihong Li (Amazon, work done at Google), 
 Xinglong Li (UBC),
	Shakir Mohamed (Deepmind),
	George Papamakarios (Deepmind),
	Zeel Patel (IIT Gandhinagar),
	Ben Poole (Google),
	Mihaela Rosca (Deepmind / UCL),
  Vinayak Rao (Purdue), 
	 Yang Song (Stanford),
	Victor Veitch (Google / U. Chicago),
Andrew Wilson (NYU).
	
		      
      </li><li> Many people who helped make or improve the figures, including:
 Vishal Ghoniya,  Ankita Kumari Jain,  Aleyna Kara,  Zeel Patel, Karm Patel,
  Dhruv Patel, Nitish Sharma, Mahmoud Soliman.
    
</li><li> Participants in the Google Summer of Code (GSOC) for 2021,
including
Ming Liang Ang,
Aleyna Kara, Gerardo Duran-Martin,
Srikar Reddy Jilugu,  Drishti Patel,
and co-mentor Mahmoud Soliman.

</li><li> Participants in the Google Summer of Code (GSOC) for 2022,
  including
  Peter Chang, Giles Harper-Donnelly,
  Xinglong Li,
  Zeel Patel, Karm Patel, Qingyao Sun,
and co-mentors Nipun Batra and Scott Linderman.


</li><li> Many other people who contributed code
	(see auto-generated list <a href="https://github.com/probml/pyprobml#acknowledgements">here</a>).
	
	</li><li> Many people who helped with proof reading (see book preface for list).
	 
  
    </li></ul>
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Future of Terraform Must Be Open (127 pts)]]></title>
            <link>https://blog.gruntwork.io/the-future-of-terraform-must-be-open-ab0b9ba65bca?gi=c07f9cd96456</link>
            <guid>37137781</guid>
            <pubDate>Tue, 15 Aug 2023 18:54:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.gruntwork.io/the-future-of-terraform-must-be-open-ab0b9ba65bca?gi=c07f9cd96456">https://blog.gruntwork.io/the-future-of-terraform-must-be-open-ab0b9ba65bca?gi=c07f9cd96456</a>, See on <a href="https://news.ycombinator.com/item?id=37137781">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><h2 id="c567">Our plan and pledge to keep Terraform open source</h2><div><a href="https://medium.com/@brikis98?source=post_page-----ab0b9ba65bca--------------------------------" rel="noopener follow"><div aria-hidden="false"><p><img alt="Yevgeniy Brikman" src="https://miro.medium.com/v2/resize:fill:88:88/1*7IJ4hkSmGgjeibEpJfbMGQ.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a><a href="https://blog.gruntwork.io/?source=post_page-----ab0b9ba65bca--------------------------------" rel="noopener  ugc nofollow"><div aria-hidden="false"><p><img alt="Gruntwork" src="https://miro.medium.com/v2/resize:fill:48:48/1*d6HE86wu0vvHrTQi_FZ3NQ.jpeg" width="24" height="24" loading="lazy" data-testid="publicationPhoto"></p></div></a></div></div><figure></figure><p id="f23e">On August 10, 2023, HashiCorp announced that after ~9 years of Terraform being open source under the MPL v2 license, they were suddenly switching it to a non open source BSL v1.1 license. We believe the BSL license is a poison pill for Terraform which threatens the entire community and ecosystem, and in this blog post, we’ll introduce <a href="https://opentf.org/" rel="noopener ugc nofollow" target="_blank">OpenTF</a>, our plan for keeping Terraform open source—forever.</p><h2 id="7b5c">Why the BSL license is a poison pill for Terraform</h2><h2 id="b3c6">The virtuous cycle of open source</h2><p id="5ada">Terraform was originally released under the <a href="https://www.mozilla.org/en-US/MPL/2.0/FAQ/" rel="noopener ugc nofollow" target="_blank">Mozilla Public License</a> (MPL) v2.0, which is a well-known, trusted, and permissive open source license: MPL allows you to use Terraform for just about any purpose and incorporate it into any product, including copying, modifying, and redistributing the code. The only limitation is that if you modify the source code of Terraform itself, you have to release those modifications under the same MPL license.</p><p id="a2a2">The permissive terms of this license were a key factor in why the community adopted Terraform:</p><ul><li id="055b">Companies were comfortable in adopting Terraform, as the license ensured there would be no unexpected fees or IP problems.</li><li id="2be6">Developers were comfortable in contributing to <a href="https://github.com/hashicorp/terraform/" rel="noopener ugc nofollow" target="_blank">Terraform core</a> (which had 1,700+ contributors as of this writing) and the hundreds of Terraform providers (the <a href="https://github.com/hashicorp/terraform-provider-aws" rel="noopener ugc nofollow" target="_blank">AWS provider</a> had 2,800+ contributors and the <a href="https://github.com/hashicorp/terraform-provider-azurerm" rel="noopener ugc nofollow" target="_blank">Azure provider</a> had 1,300+ contributors as of this writing), as the license ensured they’d be able to use their work in both their current jobs and any future ones.</li><li id="355c">Vendors created tools, modules, and extensions for Terraform (e.g., at Gruntwork, we created <a href="https://terragrunt.gruntwork.io/" rel="noopener ugc nofollow" target="_blank">Terragrunt</a>, <a href="https://terratest.gruntwork.io/" rel="noopener ugc nofollow" target="_blank">Terratest</a>, and the <a href="https://gruntwork.io/infrastructure-as-code-library/" rel="noopener ugc nofollow" target="_blank">IaC Library</a>), as the license ensured you’d be able to use this work, whether for fun (e.g., as part of a side project) or profit (e.g., as part of a proprietary project).</li></ul><p id="a02b">This led to a virtuous cycle: as more companies adopt Terraform, more developers start using it; those developers contribute to Terraform, fixing bugs, improving security, adding new features, creating new tools and extensions, etc.; that makes Terraform even more compelling, so even more companies adopt it, and the cycle continues. As a result, Terraform has become one of the most popular infrastructure as code (IaC) tools on the market.</p><p id="3112"><strong>But none of this would have happened if Terraform hadn’t been released under a truly open source license</strong>. Those companies wouldn’t have adopted it; those developers wouldn’t have contributed to it; I can say for certain we would’ve never built Terragrunt, Terratest, and the IaC Library, or even written <a href="https://www.terraformupandrunning.com/" rel="noopener ugc nofollow" target="_blank"><em>Terraform: Up &amp; Running</em></a>, if Terraform hadn’t been open source.</p><h2 id="0e18">The move to BSL</h2><p id="920b">After ~9 years of seeing the virtuous cycle of open source in action, we were shocked to hear HashiCorp’s <a href="https://www.hashicorp.com/blog/hashicorp-adopts-business-source-license" rel="noopener ugc nofollow" target="_blank">announcement</a> that they were suddenly switching Terraform to the <a href="https://www.hashicorp.com/bsl" rel="noopener ugc nofollow" target="_blank">Business Source License</a> (BSL) v1.1, which is <em>not</em> an open source license (<a href="https://www.hashicorp.com/license-faq#details-on-nomenclature" rel="noopener ugc nofollow" target="_blank">HashiCorp’s own FAQ</a> even says the BSL doesn’t meet the definition of open source). In fact, not only Terraform, but all other core HashiCorp products are moving to BSL too: e.g., Vault, Consul, Nomad, etc.</p><p id="a744">To some extent, we understand what led HashiCorp in this direction. They are trying to maintain a delicate balance: on the one hand, they are creating amazing value by providing high quality, free, open source software to a community of thousands of developers; on the other hand, they are trying to run a sustainable business, so they need to capture and monetize some of the value they create.</p><p id="0c3f">The tricky part is deciding what to make open source and what to commercialize. If you make too much open source, then you don’t have enough to sell, so you can’t make enough money to pay the very employees who are creating and maintaining these amazing open source projects, so everyone loses; but if you make too little open source, then you never build up a community, and without that community, you can’t sell enough, can’t pay employees, and again, everyone loses. It’s only when you get this balance just right that everyone wins.</p><p id="ed96">Up until last Friday, it seemed like HashiCorp had this balance just right. They did so by making most functionality open source, but reserving some functionality solely for their commercial products, such as Terraform Cloud and Terraform Enterprise. With this approach, the Terraform community grew, companies that used Terraform grew, and, of course, HashiCorp grew into a public, multi-billion dollar company. Everyone wins!</p><p id="d078">That’s why we’re so stumped about the sudden move away from an open source license to a non open source BSL license. We believe that this move away from open source will upset the delicate balance and will lead to a scenario where everyone loses: the community will lose, companies that use Terraform will lose, and ultimately, even HashiCorp will lose. Let’s discuss why.</p><h2 id="44fe">The problems with BSL</h2><p id="8645">The BSL license, along with the additional use grants HashiCorp wrote for it, is generally fairly permissive, allowing you to copy, modify, and redistribute the code. However, there is an exception. The license does <em>not</em> allow you to use Terraform if you meet both of the following conditions:</p><ol><li id="979e">You are building a product that is competitive with HashiCorp.</li><li id="43b3">You embed or host Terraform in your product.</li></ol><p id="e46f"><strong>The first problem is that the terms of the BSL and the use grants are vague.</strong> What does “competitive with HashiCorp” mean and who decides that? And what does “embed or host” mean? If you’re a lawyer and you see this, you start to sweat. The number of questions is infinite. For example, if you’re an independent software vendor (ISV) or managed service provider (MSP) in the DevOps space, and you use Terraform with your customers (but not necessarily Terraform Cloud/Enterprise), are you a competitor? If your company creates a CI / CD product, is that competitive with Terraform Cloud or Waypoint? If your CI / CD product natively supports running Terraform as part of your CI / CD builds, is that embedding or hosting? If you built a wrapper for Terraform, is that a competitor? Is it embedding only if you include the source code or does using the Terraform CLI count as embedding? What if the CLI is installed by the customer? Is it hosting if the customer runs your product on their own servers?</p><p id="a5e5">It’s not an accident that these terms are vague. This is a common practice used by many legal teams to implicitly force you to ask the company for permission, so they can decide on a case-by-case basis: <a href="https://www.hashicorp.com/license-faq#details-on-nomenclature" rel="noopener ugc nofollow" target="_blank">HashiCorp’s FAQ</a> even says that to get clarification on whether what you’re doing is competitive or embedding or hosting, you need to reach out to <a href="mailto:licensing@hashicorp.com" rel="noopener ugc nofollow" target="_blank">licensing@hashicorp.com</a>.</p><p id="500d"><strong>And that leads to the second problem with the BSL: whether your usage complies with the license isn’t determined by the legal terms, but instead is entirely at the whim of HashiCorp.</strong> If HashiCorp doesn’t think you’re a competitor, you’re in the clear. But if they feel threatened by your company: no Terraform for you. If they want to define your usage as embedding or hosting: no Terraform for you. Or perhaps they grant you a license to use Terraform, but only at a fee, and if you can’t pay that fee: no Terraform for you.</p><p id="ee62"><strong>And that brings us to the third, and worst problem with the BSL: HashiCorp can change its decisions at any time. </strong>Perhaps HashiCorp told you your usage was safe before, but a year later, you launched a new product and now they think you’re a competitor, so suddenly, your usage no longer complies with the license. Or perhaps you didn’t change anything on your end, but it’s HashiCorp that launched a new product, which just so happens to be in your market, so now you’re a competitor, and your usage is no longer allowed. Or maybe HashiCorp decides that all the usages that were OK before will now cost money. Or maybe you’ve already been paying them for a license, but suddenly, they decide to raise prices. And no matter what else happens, or what previous decisions or agreements you’ve reached, remember, HashiCorp can just change the license again at any time!</p><p id="7011"><strong>As a result of the change to BSL, there is now no certainty with using Terraform:</strong></p><ul><li id="1fd2">If you’re a CTO, and you’re picking an IaC tool to use at your company, if you see that Terraform is BSL licensed, why take the risk? You’re now much more likely to go with alternative tools that are truly open source and have no licensing headaches.</li><li id="3f81">If you’re on the legal team at a company and reviewing the licenses your dev team wants to use, and you see BSL, why take the risk? You’re now much more likely to push back and put BSL on the banned license list.</li><li id="ae6c">If you’re a developer and considering contributing to open source, why contribute to a BSL project with no guarantee you’d be able to use your own work in the future? You’re now much more likely to contribute to something else.</li><li id="68d6">If you’re a vendor and considering building a product or tooling in the DevOps space, why build it around Terraform, and take the risk that HashiCorp will, now or in the future, consider you competitive? That’s just too shaky of a foundation to build on, so you’re now much more likely to build around something else.</li></ul><p id="3dcf"><strong>In short, BSL breaks the virtuous open source cycle that got Terraform to where it is today.</strong> And once you break that virtuous cycle, everyone loses: adoption will slow, contributions will decrease, and the community and ecosystem will dwindle and wither.</p><h2 id="5e3b">OpenTF: keeping Terraform open source</h2><p id="9908">We believe that the essential building blocks of the modern Internet—tools such as Linux, Kubernetes, and Terraform—must be truly open source. That is the only way to ensure that we are building our industry on top of solid and predictable underpinnings.</p><p id="37f0">Therefore, we have joined forces with a number of other companies to create the <a href="https://opentf.org/" rel="noopener ugc nofollow" target="_blank">OpenTF manifesto</a>. <strong>The goal of the manifesto is to ensure Terraform remains truly open source — always.</strong></p><p id="324e">To this end, the manifesto lays out the following two-step plan:</p><ol><li id="2d67"><strong>Ask HashiCorp to switch Terraform back to open source. </strong>The manifesto is a public request—a petition with signatures—for HashiCorp to do the right thing here and switch Terraform back to a truly open source license (e.g., go back to MPL). Moreover, we want to be sure that it stays that way, so we are asking HashiCorp to commit to keeping Terraform under an open source license forever in the future.</li><li id="59ba"><strong>If they refuse, we will fork Terraform into an open source foundation.</strong> If HashiCorp decides to keep Terraform under the BSL license, then we will fork the MPL-licensed Terraform (Terraform version 1.5.5 and all versions before that are still MPL licensed), and put it into an open source foundation maintained by the community. We are one of many companies who have pledged resources to maintaining this fork, if it comes to it.</li></ol><p id="64a6"><strong>Either way, the future of Terraform is open source</strong>. If you also believe that Terraform should remain open source, please lend us your support, and let HashiCorp know how you feel by signing the OpenTF manifesto at <a href="https://opentf.org/" rel="noopener ugc nofollow" target="_blank">https://opentf.org/</a>!</p><h2 id="0e44">What this means for Gruntwork customers</h2><p id="7d02"><strong>As long as you use Terraform 1.5.5 or older, you can keep using all our commercial and open source products with no changes</strong>. Terraform 1.5.5 and all older versions are still MPL licensed, so you can keep using that version of Terraform with Terragrunt, Terratest, the IaC Library, the Reference Architecture, Gruntwork Pipelines, etc., with no changes of any kind.</p><p id="f16d"><strong>For future versions of Terraform, Gruntwork will use open source Terraform</strong>. For versions of Terraform that come out after 1.5.5, we will switch all our commercial and open source products to work only with open source Terraform: that is, if HashiCorp chooses to switch Terraform back to an open source license, we will use that, and if they don’t, then we will use our open source fork. We are currently waiting to see how HashiCorp responds to OpenTF, and we will share more details once we have them.</p><p id="9dba"><strong>But rest assured: no matter what happens, we are committed to keeping Terraform open source and ensuring all our products will continue to work with it.</strong></p><p id="6f20">For more information, and to join the OpenTF movement, please see <a href="https://opentf.org/" rel="noopener ugc nofollow" target="_blank">https://opentf.org/</a>!</p></div></div>]]></description>
        </item>
    </channel>
</rss>