<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 25 Dec 2024 17:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Ruby 3.4.0 (263 pts)]]></title>
            <link>https://www.ruby-lang.org/en/news/2024/12/25/ruby-3-4-0-released/</link>
            <guid>42507312</guid>
            <pubDate>Wed, 25 Dec 2024 06:40:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ruby-lang.org/en/news/2024/12/25/ruby-3-4-0-released/">https://www.ruby-lang.org/en/news/2024/12/25/ruby-3-4-0-released/</a>, See on <a href="https://news.ycombinator.com/item?id=42507312">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-wrapper">
    <p>Posted by naruse on 25 Dec 2024</p>

    
<p>We are pleased to announce the release of Ruby 3.4.0. Ruby 3.4 adds <code>it</code> block parameter reference,
change Prism as default parser, adds Happy Eyeballs Version 2 support to socket library, improves YJIT,
adds Modular GC, and so on.</p>

<h2><code>it</code> is introduced</h2>

<p><code>it</code> is added to reference a block parameter with no variable name. [<a href="https://bugs.ruby-lang.org/issues/18980">Feature #18980</a>]</p>

<div><pre><code><span>ary</span> <span>=</span> <span>[</span><span>"foo"</span><span>,</span> <span>"bar"</span><span>,</span> <span>"baz"</span><span>]</span>

<span>p</span> <span>ary</span><span>.</span><span>map</span> <span>{</span> <span>it</span><span>.</span><span>upcase</span> <span>}</span> <span>#=&gt; ["FOO", "BAR", "BAZ"]</span>
</code></pre></div>

<p><code>it</code> very much behaves the same as <code>_1</code>. When the intention is to only use <code>_1</code> in a block, the potential for other numbered parameters such as <code>_2</code> to also appear imposes an extra cognitive load onto readers. So <code>it</code> was introduced as a handy alias. Use <code>it</code> in simple cases where <code>it</code> speaks for itself, such as in one-line blocks.</p>

<h2>Prism is now the default parser</h2>

<p>Switch the default parser from parse.y to Prism. [<a href="https://bugs.ruby-lang.org/issues/20564">Feature #20564</a>]</p>

<p>This is an internal improvement and there should be little change visible to the user. If you notice any compatibility issues, please report them to us.</p>

<p>To use the conventional parser, use the command-line argument <code>--parser=parse.y</code>.</p>

<h2>The socket library now features Happy Eyeballs Version 2 (RFC 8305)</h2>

<p>The socket library now features <a href="https://datatracker.ietf.org/doc/html/rfc8305">Happy Eyeballs Version 2 (RFC 8305)</a>, the latest standardized version of a widely adopted approach for better connectivity in many programming languages, in <code>TCPSocket.new</code> (<code>TCPSocket.open</code>) and <code>Socket.tcp</code>.
This improvement enables Ruby to provide efficient and reliable network connections, adapted to modern internet environments.</p>

<p>Until Ruby 3.3, these methods performed name resolution and connection attempts serially. With this algorithm, they now operate as follows:</p>

<ol>
  <li>Performs IPv6 and IPv4 name resolution concurrently</li>
  <li>Attempt connections to the resolved IP addresses, prioritizing IPv6, with parallel attempts staggered at 250ms intervals</li>
  <li>Return the first successful connection while canceling any others</li>
</ol>

<p>This ensures minimized connection delays, even if a specific protocol or IP address is delayed or unavailable.
This feature is enabled by default, so additional configuration is not required to use it. To disable it globally, set the environment variable <code>RUBY_TCP_NO_FAST_FALLBACK=1</code> or call <code>Socket.tcp_fast_fallback=false</code>. Or to disable it on a per-method basis, use the keyword argument <code>fast_fallback: false</code>.</p>

<h2>YJIT</h2>

<h3>TL;DR</h3>

<ul>
  <li>Better performance across most benchmarks on both x86-64 and arm64 platforms.</li>
  <li>Reduced memory usage through compressed metadata and a unified memory limit.</li>
  <li>Various bug fixes: YJIT is now more robust and thoroughly tested.</li>
</ul>

<h3>New features</h3>

<ul>
  <li>Command-line options
    <ul>
      <li><code>--yjit-mem-size</code> introduces a unified memory limit (default 128MiB) to track total YJIT memory usage,
providing a more intuitive alternative to the old <code>--yjit-exec-mem-size</code> option.</li>
      <li><code>--yjit-log</code> enables a compilation log to track what gets compiled.</li>
    </ul>
  </li>
  <li>Ruby API
    <ul>
      <li><code>RubyVM::YJIT.log</code> provides access to the tail of the compilation log at run-time.</li>
    </ul>
  </li>
  <li>YJIT stats
    <ul>
      <li><code>RubyVM::YJIT.runtime_stats</code> now always provides additional statistics on
 invalidation, inlining, and metadata encoding.</li>
    </ul>
  </li>
</ul>

<h3>New optimizations</h3>

<ul>
  <li>Compressed context reduces memory needed to store YJIT metadata</li>
  <li>Allocate registers for local variables and Ruby method arguments</li>
  <li>When YJIT is enabled, use more Core primitives written in Ruby:
    <ul>
      <li><code>Array#each</code>, <code>Array#select</code>, <code>Array#map</code> rewritten in Ruby for better performance [<a href="https://bugs.ruby-lang.org/issues/20182">Feature #20182</a>].</li>
    </ul>
  </li>
  <li>Ability to inline small/trivial methods such as:
    <ul>
      <li>Empty methods</li>
      <li>Methods returning a constant</li>
      <li>Methods returning <code>self</code></li>
      <li>Methods directly returning an argument</li>
    </ul>
  </li>
  <li>Specialized codegen for many more runtime methods</li>
  <li>Optimize <code>String#getbyte</code>, <code>String#setbyte</code> and other string methods</li>
  <li>Optimize bitwise operations to speed up low-level bit/byte manipulation</li>
  <li>Support shareable constants in multi-ractor mode</li>
  <li>Various other incremental optimizations</li>
</ul>

<h2>Modular GC</h2>

<ul>
  <li>
    <p>Alternative garbage collector (GC) implementations can be loaded dynamically
through the modular garbage collector feature. To enable this feature,
configure Ruby with <code>--with-modular-gc</code> at build time. GC libraries can be
loaded at runtime using the environment variable <code>RUBY_GC_LIBRARY</code>.
[<a href="https://bugs.ruby-lang.org/issues/20351">Feature #20351</a>]</p>
  </li>
  <li>
    <p>Ruby’s built-in garbage collector has been split into a separate file at
<code>gc/default/default.c</code> and interacts with Ruby using an API defined in
<code>gc/gc_impl.h</code>. The built-in garbage collector can now also be built as a
library using <code>make modular-gc MODULAR_GC=default</code> and enabled using the
environment variable <code>RUBY_GC_LIBRARY=default</code>. [<a href="https://bugs.ruby-lang.org/issues/20470">Feature #20470</a>]</p>
  </li>
  <li>
    <p>An experimental GC library is provided based on <a href="https://www.mmtk.io/">MMTk</a>.
This GC library can be built using <code>make modular-gc MODULAR_GC=mmtk</code> and
enabled using the environment variable <code>RUBY_GC_LIBRARY=mmtk</code>. This requires
the Rust toolchain on the build machine. [<a href="https://bugs.ruby-lang.org/issues/20860">Feature #20860</a>]</p>
  </li>
</ul>

<h2>Language changes</h2>

<ul>
  <li>
    <p>String literals in files without a <code>frozen_string_literal</code> comment now emit a deprecation warning
when they are mutated.
These warnings can be enabled with <code>-W:deprecated</code> or by setting <code>Warning[:deprecated] = true</code>.
To disable this change, you can run Ruby with the <code>--disable-frozen-string-literal</code>
command line argument. [<a href="https://bugs.ruby-lang.org/issues/20205">Feature #20205</a>]</p>
  </li>
  <li>
    <p>Keyword splatting <code>nil</code> when calling methods is now supported.
<code>**nil</code> is treated similarly to <code>**{}</code>, passing no keywords,
and not calling any conversion methods.  [<a href="https://bugs.ruby-lang.org/issues/20064">Bug #20064</a>]</p>
  </li>
  <li>
    <p>Block passing is no longer allowed in index.  [<a href="https://bugs.ruby-lang.org/issues/19918">Bug #19918</a>]</p>
  </li>
  <li>
    <p>Keyword arguments are no longer allowed in index.  [<a href="https://bugs.ruby-lang.org/issues/20218">Bug #20218</a>]</p>
  </li>
  <li>
    <p>The toplevel name <code>::Ruby</code> is reserved now, and the definition will be warned when <code>Warning[:deprecated]</code>.  [<a href="https://bugs.ruby-lang.org/issues/20884">Feature #20884</a>]</p>
  </li>
</ul>

<h2>Core classes updates</h2>

<p>Note: We’re only listing notable updates of Core class.</p>

<ul>
  <li>
    <p>Exception</p>

    <ul>
      <li><code>Exception#set_backtrace</code> now accepts an array of <code>Thread::Backtrace::Location</code>.
<code>Kernel#raise</code>, <code>Thread#raise</code> and <code>Fiber#raise</code> also accept this new format. [<a href="https://bugs.ruby-lang.org/issues/13557">Feature #13557</a>]</li>
    </ul>
  </li>
  <li>
    <p>GC</p>

    <ul>
      <li>
        <p><code>GC.config</code> added to allow setting configuration variables on the Garbage
Collector. [<a href="https://bugs.ruby-lang.org/issues/20443">Feature #20443</a>]</p>
      </li>
      <li>
        <p>GC configuration parameter <code>rgengc_allow_full_mark</code> introduced.  When <code>false</code>
GC will only mark young objects. Default is <code>true</code>.  [<a href="https://bugs.ruby-lang.org/issues/20443">Feature #20443</a>]</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Ractor</p>

    <ul>
      <li>
        <p><code>require</code> in Ractor is allowed. The requiring process will be run on
the main Ractor.
<code>Ractor._require(feature)</code> is added to run requiring process on the
main Ractor.
[<a href="https://bugs.ruby-lang.org/issues/20627">Feature #20627</a>]</p>
      </li>
      <li>
        <p><code>Ractor.main?</code> is added. [<a href="https://bugs.ruby-lang.org/issues/20627">Feature #20627</a>]</p>
      </li>
      <li>
        <p><code>Ractor.[]</code> and <code>Ractor.[]=</code> are added to access the ractor local storage
of the current Ractor. [<a href="https://bugs.ruby-lang.org/issues/20715">Feature #20715</a>]</p>
      </li>
      <li>
        <p><code>Ractor.store_if_absent(key){ init }</code> is added to initialize ractor local
variables in thread-safty. [<a href="https://bugs.ruby-lang.org/issues/20875">Feature #20875</a>]</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Range</p>

    <ul>
      <li><code>Range#size</code> now raises <code>TypeError</code> if the range is not iterable. [<a href="https://bugs.ruby-lang.org/issues/18984">Misc #18984</a>]</li>
    </ul>
  </li>
</ul>

<h2>Standard Library updates</h2>

<p>Note: We’re only listing notable updates of Standard librarires.</p>

<ul>
  <li>RubyGems
    <ul>
      <li>Add <code>--attestation</code> option to gem push. It enabled to store signature to <a href="https://www.ruby-lang.org/en/news/2024/12/25/ruby-3-4-0-released/sigstore.dev">sigstore.dev</a></li>
    </ul>
  </li>
  <li>Bundler
    <ul>
      <li>Add a <code>lockfile_checksums</code> configuration to include checksums in fresh lockfiles</li>
      <li>Add bundle lock <code>--add-checksums</code> to add checksums to an existing lockfile</li>
    </ul>
  </li>
  <li>
    <p>JSON</p>

    <ul>
      <li>Performance improvements of <code>JSON.parse</code> about 1.5 times faster than json-2.7.x.</li>
    </ul>
  </li>
  <li>
    <p>Tempfile</p>

    <ul>
      <li>The keyword argument <code>anonymous: true</code> is implemented for Tempfile.create.
<code>Tempfile.create(anonymous: true)</code> removes the created temporary file immediately.
So applications don’t need to remove the file.
[<a href="https://bugs.ruby-lang.org/issues/20497">Feature #20497</a>]</li>
    </ul>
  </li>
  <li>
    <p>win32/sspi.rb</p>

    <ul>
      <li>This library is now extracted from the Ruby repository to <a href="https://github.com/ruby/net-http-sspi">ruby/net-http-sspi</a>.
[<a href="https://bugs.ruby-lang.org/issues/20775">Feature #20775</a>]</li>
    </ul>
  </li>
</ul>

<h2>Compatibility issues</h2>

<p>Note: Excluding feature bug fixes.</p>

<ul>
  <li>Error messages and backtrace displays have been changed.
    <ul>
      <li>Use a single quote instead of a backtick as a opening quote. [<a href="https://bugs.ruby-lang.org/issues/16495">Feature #16495</a>]</li>
      <li>Display a class name before a method name (only when the class has a permanent name). [<a href="https://bugs.ruby-lang.org/issues/19117">Feature #19117</a>]</li>
      <li><code>Kernel#caller</code>, <code>Thread::Backtrace::Location</code>’s methods, etc. are also changed accordingly.</li>
    </ul>

    <div><pre><code>Old:
test.rb:1:in `foo': undefined method `time' for an instance of Integer
        from test.rb:2:in `&lt;main&gt;'

New:
test.rb:1:in 'Object#foo': undefined method 'time' for an instance of Integer
        from test.rb:2:in '&lt;main&gt;'
</code></pre></div>
  </li>
  <li>
    <p>Hash#inspect rendering have been changed. [[Bug #20433]]</p>

    <ul>
      <li>Symbol keys are displayed using the modern symbol key syntax: <code>"{user: 1}"</code></li>
      <li>Other keys now have spaces around <code>=&gt;</code>: <code>'{"user" =&gt; 1}'</code>, while previously they didn’t: <code>'{"user"=&gt;1}'</code></li>
    </ul>
  </li>
  <li>
    <p>Kernel#Float() now accepts a decimal string with decimal part omitted. [<a href="https://bugs.ruby-lang.org/issues/20705">Feature #20705</a>]</p>

    <div><pre><code><span>Float</span><span>(</span><span>"1."</span><span>)</span>    <span>#=&gt; 1.0 (previously, an ArgumentError was raised)</span>
<span>Float</span><span>(</span><span>"1.E-1"</span><span>)</span> <span>#=&gt; 0.1 (previously, an ArgumentError was raised)</span>
</code></pre></div>
  </li>
  <li>
    <p>String#to_f now accepts a decimal string with decimal part omitted. Note that the result changes when an exponent is specified. [<a href="https://bugs.ruby-lang.org/issues/20705">Feature #20705</a>]</p>

    <div><pre><code><span>"1."</span><span>.</span><span>to_f</span>    <span>#=&gt; 1.0</span>
<span>"1.E-1"</span><span>.</span><span>to_f</span> <span>#=&gt; 0.1 (previously, 1.0 was returned)</span>
</code></pre></div>
  </li>
  <li>Refinement#refined_class has been removed. [<a href="https://bugs.ruby-lang.org/issues/19714">Feature #19714</a>]</li>
</ul>

<h2>Standard library compatibility issues</h2>

<ul>
  <li>
    <p>DidYouMean</p>

    <ul>
      <li><code>DidYouMean::SPELL_CHECKERS[]=</code> and <code>DidYouMean::SPELL_CHECKERS.merge!</code> are removed.</li>
    </ul>
  </li>
  <li>
    <p>Net::HTTP</p>

    <ul>
      <li>Removed the following deprecated constants:
        <ul>
          <li><code>Net::HTTP::ProxyMod</code></li>
          <li><code>Net::NetPrivate::HTTPRequest</code></li>
          <li><code>Net::HTTPInformationCode</code></li>
          <li><code>Net::HTTPSuccessCode</code></li>
          <li><code>Net::HTTPRedirectionCode</code></li>
          <li><code>Net::HTTPRetriableCode</code></li>
          <li><code>Net::HTTPClientErrorCode</code></li>
          <li><code>Net::HTTPFatalErrorCode</code></li>
          <li><code>Net::HTTPServerErrorCode</code></li>
          <li><code>Net::HTTPResponseReceiver</code></li>
          <li><code>Net::HTTPResponceReceiver</code></li>
        </ul>

        <p>These constants were deprecated from 2012.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Timeout</p>

    <ul>
      <li>Reject negative values for Timeout.timeout. [<a href="https://bugs.ruby-lang.org/issues/20795">Bug #20795</a>]</li>
    </ul>
  </li>
  <li>
    <p>URI</p>

    <ul>
      <li>Switched default parser to RFC 3986 compliant from RFC 2396 compliant.
[<a href="https://bugs.ruby-lang.org/issues/19266">Bug #19266</a>]</li>
    </ul>
  </li>
</ul>

<h2>C API updates</h2>

<ul>
  <li><code>rb_newobj</code> and <code>rb_newobj_of</code> (and corresponding macros <code>RB_NEWOBJ</code>, <code>RB_NEWOBJ_OF</code>, <code>NEWOBJ</code>, <code>NEWOBJ_OF</code>) have been removed. [<a href="https://bugs.ruby-lang.org/issues/20265">Feature #20265</a>]</li>
  <li>Removed deprecated function <code>rb_gc_force_recycle</code>. [<a href="https://bugs.ruby-lang.org/issues/18290">Feature #18290</a>]</li>
</ul>

<h2>Miscellaneous changes</h2>

<ul>
  <li>
    <p>Passing a block to a method which doesn’t use the passed block will show
a warning on verbose mode (<code>-w</code>).
[<a href="https://bugs.ruby-lang.org/issues/15554">Feature #15554</a>]</p>
  </li>
  <li>
    <p>Redefining some core methods that are specially optimized by the interpeter
and JIT like <code>String.freeze</code> or <code>Integer#+</code> now emits a performance class
warning (<code>-W:performance</code> or <code>Warning[:performance] = true</code>).
[<a href="https://bugs.ruby-lang.org/issues/20429">Feature #20429</a>]</p>
  </li>
</ul>

<p>See <a href="https://github.com/ruby/ruby/blob/v3_4_0/NEWS.md">NEWS</a>
or <a href="https://github.com/ruby/ruby/compare/v3_3_0...v3_4_0">commit logs</a>
for more details.</p>

<p>With those changes, <a href="https://github.com/ruby/ruby/compare/v3_3_0...v3_4_0#file_bucket">4942 files changed, 202244 insertions(+), 255528 deletions(-)</a>
since Ruby 3.3.0!</p>

<p>Merry Christmas, Happy Holidays, and enjoy programming with Ruby 3.4!</p>

<h2>Download</h2>

<ul>
  <li>
    <p><a href="https://cache.ruby-lang.org/pub/ruby/3.4/ruby-3.4.0.tar.gz">https://cache.ruby-lang.org/pub/ruby/3.4/ruby-3.4.0.tar.gz</a></p>

    <div><pre><code>SIZE: 23153022
SHA1: 8ccb561848a7c460ae08e1a120a47c4a88a79335
SHA256: 068c8523442174bd3400e786f4a6952352c82b1b9f6210fd17fb4823086d3379
SHA512: bc70ecba27d1cdea00879f03487cad137a7d9ab2ad376cfb7a65780ad14da637fa3944eeeede2c04ab31eeafb970c64ccfeeb854c99c1093937ecc1165731562
</code></pre></div>
  </li>
  <li>
    <p><a href="https://cache.ruby-lang.org/pub/ruby/3.4/ruby-3.4.0.tar.xz">https://cache.ruby-lang.org/pub/ruby/3.4/ruby-3.4.0.tar.xz</a></p>

    <div><pre><code>SIZE: 17215572
SHA1: eb25447cc404e8d2e177c62550d0224ebd410e68
SHA256: 0081930db22121eb997207f56c0e22720d4f5d21264b5907693f516c32f233ca
SHA512: 776a2cf3e9ccc77c27500240f168aa3e996b0c7c1ee1ef5a7afc291a06c118444016fde38b5b139c0b800496b8eb1b5456562d833f0edc0658917164763b1af7
</code></pre></div>
  </li>
  <li>
    <p><a href="https://cache.ruby-lang.org/pub/ruby/3.4/ruby-3.4.0.zip">https://cache.ruby-lang.org/pub/ruby/3.4/ruby-3.4.0.zip</a></p>

    <div><pre><code>SIZE: 28310193
SHA1: 26254ca5d3decc28a4e5faec255995265e5270b5
SHA256: c120228038af04554f6363e716b0a32cbf53cf63c6adf9f2c22a24f43dc8b555
SHA512: 4d535ed10db76a6aa74f8a025df319deb28483a7a781c24045906ee7663f1cff9d9f9e71dbc993c9e050113a34b37c7fa2143c355a0a6e1e1029bf2c92213ecc
</code></pre></div>
  </li>
</ul>

<h2>What is Ruby</h2>

<p>Ruby was first developed by Matz (Yukihiro Matsumoto) in 1993,
and is now developed as Open Source. It runs on multiple platforms
and is used all over the world especially for web development.</p>


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[This open problem taught me what topology is [video] (252 pts)]]></title>
            <link>https://www.youtube.com/watch?v=IQqtsm-bBRU</link>
            <guid>42507185</guid>
            <pubDate>Wed, 25 Dec 2024 06:08:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=IQqtsm-bBRU">https://www.youtube.com/watch?v=IQqtsm-bBRU</a>, See on <a href="https://news.ycombinator.com/item?id=42507185">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I made a website to semantically search ArXiv papers (135 pts)]]></title>
            <link>https://papermatch.mitanshu.tech/</link>
            <guid>42507116</guid>
            <pubDate>Wed, 25 Dec 2024 05:44:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://papermatch.mitanshu.tech/">https://papermatch.mitanshu.tech/</a>, See on <a href="https://news.ycombinator.com/item?id=42507116">Hacker News</a></p>
Couldn't get https://papermatch.mitanshu.tech/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Merry Christmas Everyone (1091 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=42506577</link>
            <guid>42506577</guid>
            <pubDate>Wed, 25 Dec 2024 03:10:07 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=42506577">Hacker News</a></p>
Couldn't get https://news.ycombinator.com/item?id=42506577: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: FixBrowser – a lightweight web browser created from scratch (174 pts)]]></title>
            <link>https://www.fixbrowser.org/</link>
            <guid>42506569</guid>
            <pubDate>Wed, 25 Dec 2024 03:08:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fixbrowser.org/">https://www.fixbrowser.org/</a>, See on <a href="https://news.ycombinator.com/item?id=42506569">Hacker News</a></p>
Couldn't get https://www.fixbrowser.org/: Error: unable to verify the first certificate]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Tell HN: I just updated my wife's Chrome, and uBlock is no longer supported (125 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=42506506</link>
            <guid>42506506</guid>
            <pubDate>Wed, 25 Dec 2024 02:49:29 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=42506506">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="42509011"><td></td></tr>
                <tr id="42509158"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42509158" href="https://news.ycombinator.com/vote?id=42509158&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div><p>It really is amazing how things have come full circle from the point where chrome positioned itself as a "Libre" alternative to the IE near-monopoly</p><p>There was a point between IE and chrome when Mozilla was always in the near-foreground offering alternatives to every internet hegemony, right around web 2.0, kinda makes me optimistic for the internet to see a resurgence of recommendations</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42507040"><td></td></tr>
                <tr id="42507827"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42507827" href="https://news.ycombinator.com/vote?id=42507827&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div><p>It’s so weird to observe how Alphabet doesn’t seem to even try to keep its parts separated.</p><p>Amazon at least tries keeps its companies separated from each other. AWS account teams doesn’t know what Amazon teams do and vice versa.</p><p>While Google Cloud account team constantly gets involved with Workspaces, Ads and Google Play related stuff.</p><p>If I remember right just few years ago Google was told to stop giving cheaper prices on Google Cloud based on customers Ads and Google Play revenue.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42508443"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42508443" href="https://news.ycombinator.com/vote?id=42508443&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div><p>&gt; While Google Cloud account team constantly gets involved with Workspaces, Ads and Google Play related stuff.</p><p>Not sure what you mean. Do you have a couple of concrete examples of that?</p><p>&gt; If I remember right just few years ago Google was told to stop giving cheaper prices on Google Cloud based on customers Ads and Google Play revenue.</p><p>This one you've definitely just made up.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42509182"><td></td></tr>
            <tr id="42508992"><td></td></tr>
                        <tr id="42507964"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42507964" href="https://news.ycombinator.com/vote?id=42507964&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div>
                  <p>Everyone that is shipping Electron garbage, and has focused on Chrome as The Best Experience, is to blame.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42509525"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42509525" href="https://news.ycombinator.com/vote?id=42509525&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div><p>Situation: People are getting fat from choosing to eat too much bacon</p><p>"Pitiful, though with a thankfully straightforward cure. We arrest all pig farmers, meat packers and delivery drivers while inspecting all refrigerated cargo at checkpoints. We shall demolish any restaurant serving pork, blame each person who has ever eaten a slice regardless of their health, and demonize every salty and fatty food."</p><p>"Yes, my stance is drastic. But once we remove the <i>burden</i> of choice from our citizens, they will be empowered to make new, more valuable decisions with their life. Bacon will never be a problem again."</p><p>New situation: People have quit bacon and started smoking cigarettes</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42509457"><td></td></tr>
                  <tr id="42509496"><td></td></tr>
                <tr id="42509516"><td></td></tr>
                  <tr id="42507276"><td></td></tr>
                <tr id="42507305"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42507305" href="https://news.ycombinator.com/vote?id=42507305&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div><p>This is just kicking the can down the road.</p><p>The bigger question is how the Chromium forks are going to respond long-term. I suspect the APIs enabling ad blocking are only going to get more clamped down requiring additional work for forks.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42507458"><td></td></tr>
                  <tr id="42507299"><td></td></tr>
                <tr id="42508995"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42508995" href="https://news.ycombinator.com/vote?id=42508995&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div>
                  <p>How can I swap ^W and ^D in Firefox? For Chrome I found an extension that works (…worked?) fine, the only thing for Firefox I found would be compiling it myself, which I find a much worse experience than compiling Chromium myself (neither of which I like doing)</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42509400"><td></td></tr>
                  <tr id="42507310"><td></td></tr>
                <tr id="42508260"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42508260" href="https://news.ycombinator.com/vote?id=42508260&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div><p>&gt; Can’t a non-crazy nonprofit make a browser?</p><p>Here’s to hoping LadyBird remains non crazy and can be relevant by the time of their planned alpha release in 2026.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42509000"><td></td></tr>
                <tr id="42509166"><td></td></tr>
                <tr id="42509417"><td><table>  <tbody><tr>    <td indent="6"><img src="https://news.ycombinator.com/s.gif" height="1" width="240"></td><td>
      <center><a id="up_42509417" href="https://news.ycombinator.com/vote?id=42509417&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div><p>Netscape, Edge, Chrome, Safari, Firefox, All have a pop appeal to them (the names)</p><p>"Ladybug" makes a reference to a bug. And not a thrilling one.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42509505"><td></td></tr>
                                    <tr id="42507338"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42507338" href="https://news.ycombinator.com/vote?id=42507338&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div>
                  <p>What's so horrible about it? I don't like how they're pampering to the ad industry now but other than that I think they're pretty decent.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42508421"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42508421" href="https://news.ycombinator.com/vote?id=42508421&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div><p>If I donate to your project I hope the money goes towards your project. If you spend it on beer or buy Jacuzzi I'm happy too. If you chose to spend it on other projects ill be excited to learn what they are.</p><p><a href="https://future.mozilla.org/projects/" rel="nofollow">https://future.mozilla.org/projects/</a></p><p>Do you use any of that? Is there anything there I should be using? (honest question) It seems premature to donate to things I don't know.</p><p>&gt; Solo helps entrepreneurs expand their web presence with a suite of AI-backed tools for building websites, optimizing for SEO, and showcasing your best work.</p><p>&gt; Solo will instantly create a beautiful website so you can grow your business.</p><p>&gt; Improve brand visibility: SEO keywords are automatically added to help drive search traffic. View statistics by connecting a Google Analytics account.</p><p>I'm very biased no doubt, it reads like I donate to progress the commercial web,  more canned template websites, product SEO and to promote the use of google analytics. I'm sure it is awesome to some people, to me it is the opposite, I'm sure it is a project that should exist some place but I don't want to pay for it.</p><p>The web browser can still be infinitely improved.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42509477"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_42509477" href="https://news.ycombinator.com/vote?id=42509477&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div>
                  <p>I mean Llamafile is great and is built on fantastic tech, but no I definitely want my Mozilla money to go to Firefox, not what Thing is currently in vogue by Mozilla execs.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42508914"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_42508914" href="https://news.ycombinator.com/vote?id=42508914&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div>
                  <p>Clicked the future projects link. Thought the DidThis project sounded interesting. Aaaannnddd it's already a dead project as of 2 months ago.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="42507502"><td></td></tr>
            <tr id="42507607"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42507607" href="https://news.ycombinator.com/vote?id=42507607&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div>
                  <p>I think you need to be a little bit crazy to enter the browser space. It's not for the feint of heart.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42508618"><td></td></tr>
                  <tr id="42507468"><td></td></tr>
            <tr id="42508831"><td></td></tr>
                <tr id="42509170"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42509170" href="https://news.ycombinator.com/vote?id=42509170&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div>
                  <p>I'm not convinced that it's much more than a Chrome skin with an integrated crypto scam.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42509224"><td></td></tr>
                              <tr id="42507404"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42507404" href="https://news.ycombinator.com/vote?id=42507404&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div>
                  <p>Firefox on ChromeOS sucks though. Just went through this, tried Canary, etc. Went back to Chrome.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42507473"><td></td></tr>
            <tr id="42508149"><td></td></tr>
            <tr id="42507920"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42507920" href="https://news.ycombinator.com/vote?id=42507920&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div><p>Just ChromeOS? Firefox on <i>Mac</i> sucks.</p><p>Here is one example: Firefox's tracking of the mouse cursor is broken, and often (yes, it's inconsistent) applies a vector translation so when trying to click something like a button or menu, the cursor needs to be about 100 x-y pixels away from the target. Only Firefox native UI is affected. These are My_First_Program.app tier bugs that should not exist in mature, 20 year old software.</p><p>Phoenix 0.1 didn't have this many beginner bugs. Mozilla has lost its way and only continues to exist because Google funds them to be a paper tiger competitor. Opera sold out to the Chinese. Microsoft gave up and now simps Google. Apple only supports their own platform. What is left?</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42508894"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42508894" href="https://news.ycombinator.com/vote?id=42508894&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div>
                  <p>Can you provide a link to a bug report? I've been using FF on macOS for years and haven't noticed that. Maybe it's just a bug on a random site?</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42508452"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42508452" href="https://news.ycombinator.com/vote?id=42508452&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div>
                  <p>Been using Firefox as my browser since 0.2 (Minefield, Phoenix was later) on Mac since around 10.3 and I don’t recognise what you’re seeing at all?</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42508163"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42508163" href="https://news.ycombinator.com/vote?id=42508163&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div><p>&gt; Here is one example: Firefox's tracking of the mouse cursor is broken, and often (yes, it's inconsistent) applies a vector translation so when trying to click something like a button or menu, the cursor needs to be about 100 x-y pixels away from the target. Only Firefox native UI is affected. These are My_First_Program.app tier bugs that should not exist in mature, 20 year old software.</p><p>While I've not noticed that myself, just yesterday I noticed something similarly weird.</p><p>I had a Safari window that was persistently half the screen width and height away from where the mouse was. As in: click to drag, and the whole window jumped half the screen down and to the right, so I couldn't get it to any other quadrant of any screen. Fixed on restarting the app.</p><p>I don't know if that was an app bug or an OS bug, but in either case it's Apple's fault.</p><p>How did we get to this?</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42508047"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42508047" href="https://news.ycombinator.com/vote?id=42508047&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div>
                  <p>I’ve been using Firefox on OS X since forever (never jumped to chrome and back) and I’ve never experienced this. Is there a bug report? Surely this would get a lot of attention.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42508913"><td></td></tr>
                              <tr id="42507437"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42507437" href="https://news.ycombinator.com/vote?id=42507437&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div><p>and its really easy on MacOS, you just have to run</p><pre><code>  defaults write com.google.Chrome.plist ExtensionManifestV2Availability -int 2
</code></pre><p>
Another case where windows makes simple things unnecessarily cumbersome</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42507689"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42507689" href="https://news.ycombinator.com/vote?id=42507689&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div><p>You can’t edit config files on Windows from the terminal?</p><p>Not really an expert but PowerShell always seemed kind of more “powerful” and/or complex than bash</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42507859"><td></td></tr>
                <tr id="42507928"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_42507928" href="https://news.ycombinator.com/vote?id=42507928&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div><p>It's a one liner in Powershell</p><p>New-ItemProperty -Path "HKLM:\SOFTWARE\Policies\Google\Chrome" -Name "ExtensionManifestV2Availability" -Value 2 -PropertyType DWORD -Force</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42508304"><td></td></tr>
                              <tr id="42509191"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42509191" href="https://news.ycombinator.com/vote?id=42509191&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div><p>I guess Vivaldi awaits the same fate.</p><p>I don’t want to switch from it, especially to Firefox, so much. It’s in little things like context menus, gestures (don’t tell me about that “crx” extension crapware), tab order/cycle behaviors, downloads ux, bookmarks ux, customization, etc etc.</p><p>These “default” browsers always feel like Crysis 3 gameplay wrapped into a primitive text adventure interface.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42509286"><td></td></tr>
                <tr id="42509309"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42509309" href="https://news.ycombinator.com/vote?id=42509309&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div>
                  <p>I set up Bitwarden for my dad who keeps forgetting his passwords. It seems to work well on his PC and Android phone.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42509307"><td></td></tr>
                  <tr id="42509352"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42509352" href="https://news.ycombinator.com/vote?id=42509352&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div><p>Lame.</p><p>Try using NextDNS to block ads entirely instead of just in Chrome.</p><p>Also, duck.com has a browser extension that can do this. You could also just use their browser instead.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42509312"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42509312" href="https://news.ycombinator.com/vote?id=42509312&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div><p>Brave seems to work well with its privacy shield and a button to turn scripts off as-needed.</p><p>People only focus on Firefox as an alternative.  Am I missing something?</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42508064"><td></td></tr>
                <tr id="42509476"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42509476" href="https://news.ycombinator.com/vote?id=42509476&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div>
                  <p>Yeah plus Brave on iPhone auto blocks ads. No extensions or configuration needed. Not sure if Firefox does that.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42509324"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42509324" href="https://news.ycombinator.com/vote?id=42509324&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div>
                  <p>I'm using Brave and have no idea why you got downvoted.  People are talking like Chrome and FF are the only two things on Earth.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42506575"><td></td></tr>
            <tr id="42507210"><td></td></tr>
                <tr id="42509295"><td></td></tr>
            <tr id="42507413"><td></td></tr>
                  <tr id="42506861"><td></td></tr>
                <tr id="42508160"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42508160" href="https://news.ycombinator.com/vote?id=42508160&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div>
                  <p>Yeah, I don't get all this fuss. I mean, if you block ads then do you think Chrome will also stop reporting to the mothership? Of course not. Use Firefox and simple be done with all this hoohah.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42509409"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42509409" href="https://news.ycombinator.com/vote?id=42509409&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div><p>&gt; <i>I mean, if you block ads then do you think Chrome will also stop reporting to the mothership?</i></p><p>I'm mostly interested in improving my browsing experience. Viewing the web without an adblocker is a nightmare, it makes some websites nigh-unusable.</p><p>The privacy issue <i>is</i> an issue, but it's not one that actively prevents me from reading things online.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42507463"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42507463" href="https://news.ycombinator.com/vote?id=42507463&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div>
                  <p>Unfortunately Firefox is slower than chromium and the devtools are worse. I used Firefox for years because I hate google. I eventually gave up, that’s how bad ff is.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42507756"><td></td></tr>
                <tr id="42507925"><td></td></tr>
            <tr id="42507783"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42507783" href="https://news.ycombinator.com/vote?id=42507783&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div><p>Yeah, I'm used to the Firefox ones and whenever I use the chrome ones they seem fine, worse in some ways but better in others (device emulation) while being a little unfamiliar.</p><p>The webextension dev tools are better too, imo.</p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="42507255"><td></td></tr>
                  <tr id="42507687"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42507687" href="https://news.ycombinator.com/vote?id=42507687&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div>
                  <p>Could someone explain in simple terms, what’s so tricky about spinning off a v2-compatible chromium fork?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42509096"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42509096" href="https://news.ycombinator.com/vote?id=42509096&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div>
                  <p>People who remove v2, own ad networks, develop chrome and write standards are the same people. It’s new age mafia, cancer of the internet and they do everything for you to not be able to just spin off a fork.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42509351"><td></td></tr>
            <tr id="42507812"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42507812" href="https://news.ycombinator.com/vote?id=42507812&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div>
                  <p>Forget about forking, just offering a build of Chromium for a single platform and architecture that gets the security updates in time is a lot of work.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42507229"><td></td></tr>
            <tr id="42508157"><td></td></tr>
            <tr id="42507965"><td></td></tr>
            <tr id="42508171"><td></td></tr>
            <tr id="42506512"><td></td></tr>
            <tr id="42507411"><td></td></tr>
                <tr id="42507762"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42507762" href="https://news.ycombinator.com/vote?id=42507762&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div>
                  <p>People suggesting that using uBlock Lite and not Firefox with full uBlock, probably not has been in an abusive relationship.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42509388"><td></td></tr>
                        <tr id="42509017"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42509017" href="https://news.ycombinator.com/vote?id=42509017&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div>
                  <p>What can uBlock Origin do that one couldn't do with a sufficiently sophisticated SSL-terminating forward proxy?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42509074"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42509074" href="https://news.ycombinator.com/vote?id=42509074&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div>
                  <p>Remove elements added dynamically without entirely blocking the script that produces them.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42509334"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42509334" href="https://news.ycombinator.com/vote?id=42509334&amp;how=up&amp;goto=item%3Fid%3D42506506"></a></center>    </td><td><br><div>
                  <p>Using a proxy to do DNS blocking has significant failures modes. They wont work on youtube because youtube uses the same endpoint to serve the videos and ads for starters.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42509381"><td></td></tr>
                  </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CRT Simulation in a GPU Shader, Looks Better Than Black Frame Insertion (143 pts)]]></title>
            <link>https://blurbusters.com/crt-simulation-in-a-gpu-shader-looks-better-than-bfi/</link>
            <guid>42506211</guid>
            <pubDate>Wed, 25 Dec 2024 01:26:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blurbusters.com/crt-simulation-in-a-gpu-shader-looks-better-than-bfi/">https://blurbusters.com/crt-simulation-in-a-gpu-shader-looks-better-than-bfi/</a>, See on <a href="https://news.ycombinator.com/item?id=42506211">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-rocket-location-hash="a2734ea31fbd135bead272c348162226" data-off-canvas-content="">
		<main data-rocket-location-hash="ffec16b5573a38ce68a61760655648d9">
					
			
		<article id="post-28422" itemscope="" itemtype="http://schema.org/BlogPosting">
			<header>	
				
				
				
			</header>
			<section itemprop="articleBody">
				
<p><a href="https://blurbusters.com/wp-content/uploads/2024/12/crt-simulation-animated.gif" title="CRT Simulation in a GPU Shader, Looks Better Than BFI">
	<img width="718" height="404" src="https://blurbusters.com/wp-content/uploads/2024/12/crt-simulation-animated-718x404.gif" alt="" decoding="async" fetchpriority="high" srcset="https://blurbusters.com/wp-content/uploads/2024/12/crt-simulation-animated-718x404.gif 718w, https://blurbusters.com/wp-content/uploads/2024/12/crt-simulation-animated-300x169.gif 300w, https://blurbusters.com/wp-content/uploads/2024/12/crt-simulation-animated-740x416.gif 740w, https://blurbusters.com/wp-content/uploads/2024/12/crt-simulation-animated-324x182.gif 324w" sizes="(max-width: 718px) 100vw, 718px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20718%20404'%3E%3C/svg%3E">	
	</a>
</p>
				<p><em>Who Is this for? CRT Enthusiasts, software &amp; hardware developers, emulator authors, all of who wish to reduce display motion blur of 60 years of legacy 60fps 60Hz content with softer flicker than BFI.&nbsp;</em></p>
<p><strong>UPDATE 2024/12/24: It just got <a href="https://github.com/libretro/RetroArch/issues/16373#issuecomment-2561574563">added to Retroarch emulator on github quickly</a>, the same day we released this! The next public release of RetroArch will include this CRT beam simulator mode as a setting.</strong></p>
<h2>New Open Source Algorithm of Simulating CRT Raster-Scanning</h2>
<p>People who have seen a CRT tube in motion, know how shockingly clear motion they are. Blur Busters is born of display motion blur reduction, and so we’ve been fans of all kinds of motion blur reduction techniques.</p>
<p>Between myself and Timothy Lottes (ex-NVIDIA ex-AMD), we have come up with a breakthrough algorithm for simulating a CRT tube, now released on <a href="https://www.shadertoy.com/view/XfKfWd">shadertoy</a> and <a href="https://github.com/blurbusters/crt-beam-simulator/">github</a>, with the following features:</p>
<ul>
<li>Major <strong>motion blur reduction</strong> on 240Hz+ displays.</li>
<li>Soft phosphor fade &amp; rolling scan, <strong>less eyestrain at same Hz than BFI or strobe mode.</strong></li>
<li><strong>Variable per-pixel MPRT</strong> (Timothy Lotte’s brightness redistribution algorithm).</li>
<li>Great for reducing display motion blur of 60 years of legacy 60fps 60Hz content.</li>
<li>Works on LCDs and OLEDs</li>
<li>Realtime (for retro &amp; emulator uses) and slo-mo modes (educational)</li>
<li>Brightness adjustment (less motion blur at lower gain values, by trading off brightness)</li>
<li>Seamless; no banding* (when ABL algorithm in display isn’t interfering)</li>
</ul>
<h2>Real-Time Versions</h2>
<p>Before running these animations, they may not look good on all displays; more Hz is better. These real time versions <strong>requires a performant GPU</strong>. You may see ugly erratic flicker if your GPU is too slow. <span>Your display motion blur reduction will be limited by by the native:simulated Hz ratio. More Hz the merrier.</span></p>
<p><strong>Flicker sensitivity note: Do not click these below links if you are sensitive to flicker.<br>
</strong></p>
<ul>
<li><a href="https://www.shadertoy.com/embed/X3ccDN?gui=true&amp;t=10&amp;paused=false&amp;muted=false">Real-time simulation of 60 Hz CRT for your 120 Hz display</a> (up to 50% blur reduction)</li>
<li><a href="https://www.shadertoy.com/embed/XfKfWd?gui=true&amp;t=10&amp;paused=false&amp;muted=false">Real-time simulation of 60 Hz CRT for your 240 Hz display</a> (up to 75% blur reduction)</li>
<li><a href="https://www.shadertoy.com/embed/43ccDN?gui=true&amp;t=10&amp;paused=false&amp;muted=false">Real-time simulation of 60 Hz CRT for your 480 Hz display</a> (up to 83% blur reduction)<br>
<em>NOTE: Do not click the 480Hz link if you only have 120Hz or less!</em></li>
</ul>
<h2>Slow Motion Versions</h2>
<ul>
<li><a href="https://www.shadertoy.com/view/l33yW4">Slo-motion simulation using 16 segments</a> (60fps 60Hz CRT on future 960Hz displays)</li>
<li><a href="https://www.shadertoy.com/view/X3ccWn">Slo-motion simulation using 4 segments</a> (60fps 60Hz CRT on today’s 240Hz displays)</li>
</ul>
<p>For higher Hz displays (large native:simulated Hz ratio), the raster can be configured with a quicker simulated phosphor fade for lower MPRTs:</p>

<p>For lower Hz displays (small native:simulated Hz ratio), the beam will require a very tall height, to give sufficient coverage. The real-time version flickers less than BFI, due to the rolling-scan and phosphor fade.</p>

<h2>Pre-Requisites for Good CRT Simulation</h2>
<ul>
<li><strong>Most discrete GPUs work</strong> (Radeon, GeForce, Arc).<br>
Some fast mobile GPUs work (iPhone 120Hz with “Prefer Page Updates Near 60fps” turned off).</li>
<li><strong>Recommended: 240 Hz OLED</strong><br>
Minimum: 120 Hz LCD (non-FALD, due to local dimming lag)<br>
Fantastic: 360-480 Hz OLED</li>
<li><strong>Display ideally configured to SDR mode </strong>(LCD or OLED).<br>
This is because the current formulas used in the shader (gamma2linear and linear2gamma) is expecting the ability to calculate a photon budget for brightness-spreading over multiple refresh cycles for brightest pixels. This lowers persistence of average brightness pixels, and brightens the CRT simulation significantly. If you do any HDR boosting, you may need to readjust the GAIN_VS_BLUR constant and the GAMMA constant until banding disappears.</li>
</ul>
<h2>For Software Implementation</h2>
<p>We look forward to seeing software and hardware developers implement this algorithm as optional motion blur reduction that is superior to plain black frame insertion.</p>
<ul>
<li>Software such as emulators (e.g. Retroarch);</li>
<li>Video processor devices (e.g. Retrotink 4K, whom I <a href="https://www.retrotink.com/post/retrotink-4k-blur-buster-approved">helped with the BFI addition</a>)</li>
<li>Game engines that adds an optional low motion blur setting (e.g. fast scrollers)</li>
<li>Display firmwares to add an optional CRT emulation mode</li>
</ul>
<p>Remember, that all refresh cycles must be reprocessed, regardless of if the content frame rate is lower than the simulated CRT refresh rate.</p>
<h2>Temporal Simulation can be added to Spatial Simulation</h2>
<p>This temporal simulation (CRT electron beam) can be combined with your spatial simulation (CRT mask filters). Combine this with OLED blacks and colors, and it create a fantastically visually-accurate simulation of CRT refreshing. Blur Busters works in the (display+temporal) domain, as seen in our <a href="https://blurbusters.com/area51">Display Research, Science &amp; Engineering Portal</a>.</p>
<h2>Frequently Asked Questions</h2>
<p><strong>Q: How do I run this app?</strong><br>
A: This isn’t an application yet; it’s only an engine, an algorithm. Software developers need to implement this algorithm into their emulator. We hope to see Retroarch-type and Retrotink-type implementations in the future.</p>
<p><strong>Q: How is it better than BFI or a strobe backlight?<br>
</strong>A: 60Hz BFI and strobing flickers a lot. CRT simulation is much gentler for 60fps content, because of phosphor fade &amp; rolling scan. Some light is emitted somewhere else on the screen all the time. Right tool for Right Job.</p>
<p><strong>Q: Can I add it to ReShade?</strong><br>
A: Possibly, with a major restriction: All refresh cycles must be reprocessed independent of game frame rate. You need to guarantee processing of all refresh cycles (perfect permanent framerate=Hz shader processing) independently of game frame rate fluctuations. This may require a Windows IDD (e.g. <a href="https://github.com/roshkins/IddSampleDriver">iddSampleDriver</a> or <a href="https://github.com/MolotovCherry/virtual-display-rs/">virtual-desktop-rs</a>) or a specially modified version of <a href="https://github.com/wehem/desktopbfi">wehem’s DesktopBFI fork</a>.</p>
<p><strong>Q: It looks like crap! Why?</strong><br>
A: You need a bright display, try a 240Hz+ OLED. Also some local dimming LCDs have a backlight lag that sometimes interferes with quality.</p>
<p><strong>Q: It looks amazing! How?<br>
</strong>A: Algorithmic magic. It took two smart brains to combine. Mark Rejhon’s CRT beam simulator was combined with Timothy Lotte’s variable-MPRT BFI algorithm that compresses MPRT for average brightness pixels, and lengthens MPRT for brightest pixels.</p>
<p><strong>Q: Can I program CRT mask filters into this?<br>
</strong>A: Yes, software developers can add spatial CRT filters as a processing pass after this temporal CRT beam simulation. I recommend doing the CRT beam simulation at the original resolution before scaling, in this workfow:</p>
<p><strong>[Original frame]</strong> <span>-&gt;</span> <strong>[CRT simulation]</strong> <span>-&gt;</span> <strong>[Scaling &amp; CRT filter masks]</strong></p>
<p><strong>Q: Where is the source code?</strong><br>
A: It’s at <a href="https://github.com/blurbusters/crt-beam-simulator">github.com/blurbusters/crt-beam-simulator</a></p>
<p><strong>Q: I need help implementing this!<br>
</strong>A: If you need advisory services implementing this into your product, contact me at <a href="http://services.blurbusters.com/">services.blurbusters.com</a>.</p>

			</section>

			            
            
        				
			
		</article>		    	
	
		</main>
		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[T * sin (t)' ≈ Ornamented Christmas Tree (2013) (339 pts)]]></title>
            <link>https://community.wolfram.com/c/portal/getImageAttachment?filename=tree.gif&amp;userId=93201</link>
            <guid>42506145</guid>
            <pubDate>Wed, 25 Dec 2024 01:07:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://community.wolfram.com/c/portal/getImageAttachment?filename=tree.gif&#x26;userId=93201">https://community.wolfram.com/c/portal/getImageAttachment?filename=tree.gif&#x26;userId=93201</a>, See on <a href="https://news.ycombinator.com/item?id=42506145">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[A pilot raced through the airport to surprise the woman who saved his life (122 pts)]]></title>
            <link>https://www.cnn.com/2024/12/21/travel/united-pilot-reunites-bone-marrow-donor/index.html</link>
            <guid>42506041</guid>
            <pubDate>Wed, 25 Dec 2024 00:41:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2024/12/21/travel/united-pilot-reunites-bone-marrow-donor/index.html">https://www.cnn.com/2024/12/21/travel/united-pilot-reunites-bone-marrow-donor/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=42506041">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-editable="content" itemprop="articleBody" data-reorderable="content">
                  <p><cite>
      <span data-editable="location"></span>
      <span data-editable="source">CNN</span>
        &nbsp;—&nbsp;
    </cite>
</p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkezxs00003b6mr6s54fb2@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            When Allie Reimold boarded Flight 2223 in Houston a week ago, she didn’t expect to see him.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkl0ui001f3b6mwzd7yo5b@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            It had been four years since they’d last visited in person. And eight years, almost exactly, since the budding scientist – on the darkest day of the year – had given the commercial airline pilot a gift that would link the two for life.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkl0ui001g3b6m0ear3bjp@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Back then, United Airlines Capt. David Whitson had been facing a devastating diagnosis: acute myeloid leukemia. Healthy blood could bring the husband and father back from the brink. But even his brother’s didn’t match closely enough.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkl0ui001h3b6msg66jmt3@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            That’s when Allie, who years earlier had opted into a bone marrow registry, got the call:
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkl0ui001i3b6mg8wvc7ly@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Would she help save a dying stranger?
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkl0ui001j3b6mpnalz3dn@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Since then, Allie and David had met in person. They’d linked up on social media. And in gratitude for her priceless gift, David had added Allie to his United Airlines travel benefits so she “travels like my children or my family do,” the pilot told CNN.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkl0ui001k3b6mnbmjhma2@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            That’s how David, who’d just piloted a flight from Dallas to Houston, got the ping: Allie was also in Houston, about to board outbound Flight 2223.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkl0ui001l3b6m52ooh7k9@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            But it was due to take off in 40 minutes. And David was on the other side of the airport.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkl0ui001m3b6mlxewddwy@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            He reached out to the jet’s captain.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkl0ui001n3b6m1pz3g1aq@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            And dashed to the gate.
    </p>

<div data-image-variation="image_medium" data-breakpoints="{&quot;image_medium--eq-extra-small&quot;: 115, &quot;image_medium--eq-small&quot;: 300}" data-uri="cms.cnn.com/_components/image/instances/cm4xp1twz00493b6mrgx7zg04@published" data-name="03-Allie-+-Captain-Whitson-4.jpg" data-component-name="image" data-observe-resizes="" data-original-ratio="1.333125" data-original-height="2133" data-original-width="1600" data-url="https://media.cnn.com/api/v1/images/stellar/prod/03-allie-captain-whitson-4.jpg?c=original" data-editable="settings">
       <picture><source height="2133" width="1600" media="(min-width: 1280px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/03-allie-captain-whitson-4.jpg?q=w_1110,c_fill/f_webp" type="image/webp"><source height="2133" width="1600" media="(min-width: 960px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/03-allie-captain-whitson-4.jpg?q=w_1015,c_fill/f_webp" type="image/webp"><source height="2133" width="1600" media="(min-width: 480px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/03-allie-captain-whitson-4.jpg?q=w_1160,c_fill/f_webp" type="image/webp"><source height="2133" width="1600" media="(max-width: 479px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/03-allie-captain-whitson-4.jpg?q=w_680,c_fill/f_webp" type="image/webp"><img src="https://media.cnn.com/api/v1/images/stellar/prod/03-allie-captain-whitson-4.jpg?q=w_1110,c_fill" alt="David Whitson, a United Airlines pilot, received a rare diagnosis in August 2016 and had only one hope for survival." onload="this.classList.remove('image_medium__dam-img--loading')" onerror="imageLoadError(this)" height="2133" width="1600" loading="lazy"></picture>
    </div>

  <h2 data-editable="text" data-uri="cms.cnn.com/_components/subheader/instances/cm4xklcvg001p3b6mc1fegxx4@published" data-component-name="subheader" id="a-rare-diagnosis-and-a-desperate-search" data-article-gutter="true">
        A rare diagnosis and a desperate search
</h2>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkkyjo001d3b6mu7t8xf89@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            David was just 44 when he went from incredibly healthy to being on a ventilator.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xn0ljb003u3b6mdzmjj635@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            When his cold symptoms turned into a fever, David rushed to an emergency room in August 2016. He explained to the doctor that “something was seriously wrong” because the left side of his body was in pain and a lymph node was swelling up in his neck.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xo0brq003w3b6mkw6tpfjq@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            A CT scan and other tests revealed a grim diagnosis a few days later.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xklx61001u3b6mbadxxn5w@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Acute myeloid leukemia – a rare, fast-growing blood and bone marrow cancer originating from abnormal blood stem cells – tends to affect<strong> </strong>older adults, according to <a href="https://www.yalemedicine.org/conditions/acute-myeloid-leukemia-aml" target="_blank">Yale Medicine</a>. Only about <a href="https://www.yalemedicine.org/conditions/acute-myeloid-leukemia-aml" target="_blank">29.5%</a> of patients are expected to live for at least five<strong> </strong>years after diagnosis.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xklx62001v3b6mfjzfphm2@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            A doctor after one chemotherapy treatment told David he had a 5% chance of survival because his type of this cancer had a genetic mutation “that was really, really bad,” David recounted.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkszc2003j3b6m9fbvjsxs@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “I couldn’t even walk five steps. I couldn’t move. I could barely just move my legs,” David said. “I couldn’t sit up, I couldn’t even get out of bed.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xo73fy00443b6mqrgnxi54@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Being a usually active person, David decided to set small goals for himself, like exercising during commercials<strong> </strong>or walking to the bathroom. He tried to stay positive, relying on faith and prayers for strength.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xo71r300413b6mdsez8r9a@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            His hopes dwindled when two more rounds of chemotherapy failed to fight the illness.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xklx62001w3b6mfj99x3tm@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            But if he found the right match, David’s cancerous, Type B-positive blood could be replaced. It could return him to health. And give him more years with his wife and kids.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xklx62001x3b6mds22slb5@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Advancements in acute myeloid leukemia treatment have significantly improved remission rates, according to the National Cancer Institute. Nowadays, most transplants use stem cells from donor blood – rather than bone marrow – in a much less complicated process, according to the <a href="https://my.clevelandclinic.org/health/treatments/22567-stem-cell-transplants" target="_blank">Cleveland Clinic</a>.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xklx62001y3b6mq8hbyz31@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            But finding a donor match can be challenging: Only about 30% of patients have a relative who can donate; for the rest, doctors search national and international donor registries<strong>,</strong> according to the <a href="https://my.clevelandclinic.org/health/treatments/24387-bone-marrow-donation" target="_blank">Cleveland Clinic</a>.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xlaha0003o3b6mp3h23rlt@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Donors and patients are <a href="https://www.nmdp.org/get-involved/join-the-registry/matching-with-a-patient" target="_blank">matched</a> based on inherited genes called human leukocyte antigens, which carry the code for markers that the body uses to know which cells belong. Donors and recipients can have incompatible blood types, and it isn’t a factor in the match.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xuzuuy00063b6jh8581hky@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Siblings are often the best matches because they have the same biological parents.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xklx62001z3b6ma7ve9wu9@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            But David’s brother wasn’t an ideal match.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xklx6200203b6mnz6dm634@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            So, his doctors tried the registries.
    </p>

  

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xklvod001s3b6mxj8i2vjm@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Allie got the call.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkmu4a00273b6mtufwkn0c@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Four years earlier, as an 18-year-old behavioral sciences undergrad, she had helped organize the Purdue University Dance Marathon to raise money for an Indiana children’s hospital. During the 16-hour event, she’d swabbed her cheek to join the National Marrow Donor Program, a global nonprofit facilitating bone marrow and stem cell transplants for patients with life-threatening blood cancers.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkmu4a00283b6mi651hbma@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Some 18,000 Americans are diagnosed each year with a life-threatening illness – including leukemia, lymphoma, sickle cell disease and more than 70 others – that could be treated with a marrow or blood cell transplant, <a href="https://bloodstemcell.hrsa.gov/about/faqs#:~:text=Why%20is%20there%20a%20need,Hispanic%20or%20Latino" target="_blank">according</a> to the Health Resources and Services Administration. But some patients, the federal agency <a href="https://www.nmdp.org/patients/understanding-transplant/diseases-treated-by-transplant" target="_blank">says</a>, will never find a match.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkmu4a00293b6m7pw45bgs@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            When Allie learned her blood matched someone in need, she was excited. “I really wanted to be able to help someone in this type of way,” she told CNN, “and I think that’s also because of my interest in public health and my interest in medicine.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkmu4a002a3b6mjomsnaji@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Still, she didn’t have a lot of details about the person she was donating to. In the US, stem cell recipients typically have to wait at least a year before they can meet their donors, according to the National Marrow Donor Program.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkmu4a002b3b6mjd9dnx07@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Allie soon went to the Gulf Coast Regional Blood Center in Houston, where for eight hours she donated peripheral blood stem cells through apheresis, a nonsurgical procedure that removes components from a donor’s blood and then returns what remains to their body, according to the National Cancer Institute.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkmu4a002c3b6m60zs8aa3@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “You’re a little sore, you’re a little tired, but you get to go home that night, and it’s really, really rewarding,” she recalled.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkmu4a002d3b6m4hm3yix0@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            On December 21, 2016 – when the winter solstice blanketed Texas with more than 14 hours of darkness – doctors at Baylor University Medical Center in Dallas injected Allie’s bone marrow stem cells into David’s arm, he said.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkmu4a002e3b6mc3kuypsd@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “Stem cells are like seeds, and they went into my bone and planted, and they grew her blood,” he told CNN.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkmu4a002f3b6myvpe2b0s@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The treatment was successful, David said, changing his Type B-positive blood to Type O-negative.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkmu4a002g3b6m67nqzh40@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Still, David didn’t know who’d given him this life-saving gift.
    </p>

  
<div data-image-variation="image_inline-small" data-breakpoints="{&quot;image_inline-small--eq-extra-small&quot;: 115, &quot;image_inline-small--eq-small&quot;: 300}" data-uri="cms.cnn.com/_components/image/instances/cm4xph39m00013b6m3o87ajq2@published" data-name="04-Allie-+-Captain-Whitson-2.jpg" data-component-name="image" data-observe-resizes="" data-original-ratio="2.169375" data-original-height="3471" data-original-width="1600" data-url="https://media.cnn.com/api/v1/images/stellar/prod/04-allie-captain-whitson-2.jpg?c=original" data-editable="settings" data-article-gutter="true">
       <picture><source height="3471" width="1600" media="(min-width: 1280px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/04-allie-captain-whitson-2.jpg?q=w_256,c_fill/f_webp" type="image/webp"><source height="3471" width="1600" media="(min-width: 960px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/04-allie-captain-whitson-2.jpg?q=w_256,c_fill/f_webp" type="image/webp"><source height="3471" width="1600" media="(min-width: 480px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/04-allie-captain-whitson-2.jpg?q=w_256,c_fill/f_webp" type="image/webp"><source height="3471" width="1600" media="(max-width: 479px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/04-allie-captain-whitson-2.jpg?q=w_680,c_fill/f_webp" type="image/webp"><img src="https://media.cnn.com/api/v1/images/stellar/prod/04-allie-captain-whitson-2.jpg?q=w_256,c_fill" alt="In 2018, David Whitson was able to return to work as a pilot." onload="this.classList.remove('image_inline-small__dam-img--loading')" onerror="imageLoadError(this)" height="3471" width="1600" loading="lazy"></picture>
    </div>

  

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkms8o00253b6miwyrhh3u@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Over the next 18 months, David got better and better, until he was strong enough to return to work as a United Airlines pilot. Allie, meanwhile, kept up her studies, focusing more and more on how to help people make healthy choices to prevent chronic diseases like cancer.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkod9h002o3b6mrtfwpz1j@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The two eventually were introduced to each other by the donor program in March 2018. And in August 2018, David and Allie finally met in person for the first time at an event hosted by Baylor Medical Center. After an onstage Q&amp;A session for patients and staff, Allie and her parents and David and his family went out to lunch.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkod9h002p3b6moplbwdl2@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            David still gets emotional about it. “It’s still overwhelming to me that a stranger would take the time to save my life,” he said. “It just gave me hope.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkod9h002q3b6m8l0z0pfp@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “My blood is identical to Allie’s now,” David said.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkod9h002r3b6mdf28fc77@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            The pair would catch up every year on the anniversary of David’s transplant, said Allie, who donated peripheral blood stem cells again in 2018 to a different recipient and has encouraged others to consider joining the bone marrow registry.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkod9h002s3b6mfu49zgra@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Beyond that, as a small token of his thanks, David shared his travel benefits with Allie. “It’s the least that I could do,” he explained. “She saved my life.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkod9h002t3b6m97sa8tfl@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Owing to account notifications, David from time to time surprises Allie at an airport where they both happen to be, he said. She’s now 30, with a Ph.D. and a job as a cancer prevention public health researcher at the University of California, Davis, emphasizing the importance of preventive health care, including regular doctor visits, stress management and a healthy lifestyle, she said.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkod9h002u3b6mk7vcaugt@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “We both like to keep things light, we both like to joke around,” he said, “and we both like to be silly with each other.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkod9h002v3b6m911ulmcl@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            For her part, Allie often thinks of David when she flies – and then usually texts or calls him, she said.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkod9h002w3b6me8rs8wis@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “Every time I see him, he’s got a smile on his face,” she said. “He’s in such a great mood.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkod9h002x3b6mv4ijoeyx@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            As Allie waited last week for her flight to depart from Houston, it had been four years since she’d seen David in person.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkod9h002y3b6mdwurs3au@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            He knew she was there, of course – and was racing toward her gate.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkod9h002z3b6mipy4sh35@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            But Allie wasn’t in a joking mood.
    </p>

  

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkobfr002l3b6mu7epyesn@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Allie’s mom recently had a heart attack, she said. Like David before his cancer diagnosis, “she had felt healthy, she didn’t see it coming on.” And given Allie’s profession, the illness hit close to home.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkpkiq00363b6m3ym3cem7@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Boarding began, and Allie found her seat on the plane. As she waited for the aircraft’s doors to close, she heard its PA system begin to crackle.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkpkiq00373b6me34vd9t1@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            She didn’t think much of it.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkpkiq00383b6mx76cgj5h@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Then, she heard his name.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkpkiq00393b6m6fxaxlwq@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            At first, it surprised her.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkpkiq003a3b6mf217fjgj@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Then, she thought: “Of course, he’s doing this.’”
    </p>

  
<div data-image-variation="image_inline-small" data-breakpoints="{&quot;image_inline-small--eq-extra-small&quot;: 115, &quot;image_inline-small--eq-small&quot;: 300}" data-uri="cms.cnn.com/_components/image/instances/cm4xp9qpy004h3b6mcsv0d6e9@published" data-name="02-Allie-+-Captain-Whitson-3.jpg" data-component-name="image" data-observe-resizes="" data-original-ratio="1.839375" data-original-height="2943" data-original-width="1600" data-url="https://media.cnn.com/api/v1/images/stellar/prod/02-allie-captain-whitson-3.jpg?c=original" data-editable="settings" data-article-gutter="true">
       <picture><source height="2943" width="1600" media="(min-width: 1280px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/02-allie-captain-whitson-3.jpg?q=w_256,c_fill/f_webp" type="image/webp"><source height="2943" width="1600" media="(min-width: 960px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/02-allie-captain-whitson-3.jpg?q=w_256,c_fill/f_webp" type="image/webp"><source height="2943" width="1600" media="(min-width: 480px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/02-allie-captain-whitson-3.jpg?q=w_256,c_fill/f_webp" type="image/webp"><source height="2943" width="1600" media="(max-width: 479px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/02-allie-captain-whitson-3.jpg?q=w_680,c_fill/f_webp" type="image/webp"><img src="https://media.cnn.com/api/v1/images/stellar/prod/02-allie-captain-whitson-3.jpg?q=w_256,c_fill" alt="David Whitson and Allie Reimold reunited eight years after the transplant." onload="this.classList.remove('image_inline-small__dam-img--loading')" onerror="imageLoadError(this)" height="2943" width="1600" loading="lazy"></picture>
    </div>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkpkiq003b3b6my0j2ri0p@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            David had made it in time. And in an announcement to everyone aboard, he shared his transplant story. Then, he walked over to the passenger who’d made it all happen.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkpkiq003c3b6mnsbcsbka@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            It’s “not every day you can get to hug someone that can save your life,” he said. “Allie is the true hero of this story. I am just glad to be alive.”
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkpkiq003d3b6mymqwfp3v@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            Other passengers erupted in applause.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkpkiq003e3b6mgfw8au4u@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            It would be another week before the winter solstice marking the eighth anniversary of David’s transplant. But their impromptu reunion became a “really fun” highlight to Allie’s long travel day, especially given her mom’s health crisis. While Allie’s mom is doing better now, the pair are reminded to never take good health for granted.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkpkiq003f3b6mzhtbc1po@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “Every year around this time I am just so grateful,” David told CNN.
    </p>

    <p data-uri="cms.cnn.com/_components/paragraph/instances/cm4xkpkiq003g3b6m0rm1wx4p@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
            “I can’t believe that much time has gone by,” Allie added. “I would still to this day absolutely do it again.”
    </p>

              </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gordon Mah Ung has died (141 pts)]]></title>
            <link>https://www.pcworld.com/article/2564783/gordon-mah-ung-remembered.html</link>
            <guid>42505542</guid>
            <pubDate>Tue, 24 Dec 2024 22:55:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pcworld.com/article/2564783/gordon-mah-ung-remembered.html">https://www.pcworld.com/article/2564783/gordon-mah-ung-remembered.html</a>, See on <a href="https://news.ycombinator.com/item?id=42505542">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="link_wrapped_content">




<p>PCWorld executive editor Gordon Mah Ung, a tireless journalist we once described as a <a href="https://www.pcworld.com/article/436252/meet-gordon-mah-ung-pcworlds-new-hardware-guru.html">founding father of hardcore tech journalism</a>, passed away over the weekend after a hard-fought battle with pancreatic cancer. Gordon was 58, and leaves behind a loving wife, two children, older sister, and mother.</p>



<p>With more than 25 years’ experience covering computer tech broadly and computer chips specifically, Gordon’s dogged reporting, one-of-a-kind personality, and commitment to journalistic standards touched many, many lives. He will be profoundly missed by co-workers, industry sources, and the PC enthusiasts who read his words and followed him as a video creator.</p>



<p>Gordon studied journalism at San Francisco State University and then worked as a police reporter for the<em> </em>Contra Costa Times in the late 1990s. In 1997, he joined Computerworld (a PCWorld sister publication) before I recruited him to join boot magazine (later re-launched as Maximum PC), where he would ultimately lead hardware coverage for 16 years.</p>



<p>At Maximum PC, Gordon developed his trademark voice that blended a hardcore passion for PC tech with non-sequiturs, deadpan humor, and occasional bursts of outrage. As a very early podcaster in the tech space, Gordon’s “Rant of the Week” segment on the Maximum PC pod became so legendary, someone made a <a href="https://go.skimresources.com/?id=111346X1569483&amp;xs=1&amp;url=https://www.leedash.com/rantsoundboard/&amp;xcust=2-1-2564783-1-0-0-0-0&amp;sref=https://www.pcworld.com/article/2564783/gordon-mah-ung-remembered.html" rel="nofollow" data-subtag="2-1-2564783-1-0-0-0-0" data-domain-name="leedash" target="_blank">soundboard</a> of his best sound bytes. (Caution: It can get a bit NSFW in the finest Gordon tradition.) As I listened to his rants from my office, he always had me guessing, “Is he really <em>that</em> angry, or is he playing us?”</p>



<p>And that was part of Gordon’s genius. His number one commitment was to investigating the story, informing the public, and helping people make the best technology decisions. But layered on top of all of this was a master showman who effortlessly connected with like-minded enthusiasts.</p>



<p>During much of his time at Maximum PC, Gordon was the lead designer, builder and dreamer behind the magazine’s annual Dream Machine project, which entailed creating the most outrageous, high-performing PC possible. Throughout these building endeavors, he cemented his relationships with Intel, AMD, Nvidia, and other hardware manufacturers too numerous to mention. </p>



<p>Gordon’s goal was to get the newest, best, most high-performing parts before anyone else. And it didn’t end with CPUs and GPUs. If a piece of technology went into a PC build, Gordon had an encyclopedic knowledge about all of it—memory, storage, PSUs, cases, cooling, and beyond.</p>



<p>Gordon was also the unnamed author of Maximum PC’s consumer-advocate “Watchdog” column. As the mysterious Watchdog, Gordon responded to reader complaints about fly-by-night companies and failing products, and applied all his investigative skills to help readers reach a resolution. It was a perfect merger of consumer service, deep reporting and tech smarts that only Gordon could own.</p>



<p>Sort of like Star Trek’s Scotty who preferred sticking to his technical manuals, Gordon resisted taking the helm of Maximum PC, but eventually agreed to become Editor-in-Chief in 2014. Flash forward to later that year, when I once again asked for his help—this time to join PCWorld as executive editor in charge of hardware.</p>



<p>At PCWorld, Gordon immediately began imprinting his knowledge and personality on our articles and video. His deep-dive CPU reviews were epic, and continued a legacy of no-BS chip coverage that nonetheless earned the trust and respect of the companies he covered. Some of his first segues into video took the form of our <a href="https://go.skimresources.com/?id=111346X1569483&amp;xs=1&amp;url=https://www.youtube.com/watch?v=4oJJvyuBObM&amp;list=PLJw2-YrAPHYGY-E-E7on50Nw4DCKRdupv&amp;xcust=2-1-2564783-1-0-0-0-0&amp;sref=https://www.pcworld.com/article/2564783/gordon-mah-ung-remembered.html" rel="nofollow" data-subtag="2-1-2564783-1-0-0-0-0" data-domain-name="youtube" target="_blank">Hardcore Hardware</a> series where he married his deep wealth of knowledge with trademark Gordon theatrics.</p>



<div data-effect="slide"><ul><li><figure><img decoding="async" alt="Gordon Mah Ung being filmed for Hardcore Hardware" data-id="2564811" src="https://b2c-contenthub.com/wp-content/uploads/2024/12/Gordon-Basement-Set.jpg?quality=50&amp;strip=all&amp;w=1200" loading="lazy"><figcaption><p>Some of Gordon’s first forays into PCWorld video were for his “Hardcore Hardware” series, which was shot in the bowels of our San Francisco office space.</p>
</figcaption></figure></li><li><figure><img decoding="async" alt="Gordon Mah Ung, animated with his hands raised" data-id="2564809" src="https://b2c-contenthub.com/wp-content/uploads/2024/12/TFN-2.jpg?quality=50&amp;strip=all" loading="lazy"><figcaption><p>A master showman, Gordon always knew how to connect directly with his YouTube audience.</p>
</figcaption></figure></li><li><figure><img decoding="async" alt="Gordon leading the Full Nerd panel." data-id="2564810" src="https://b2c-contenthub.com/wp-content/uploads/2024/12/TFN-1.png?w=1200" loading="lazy"><figcaption><p>Gordon’s infectious personality always kept The Full Nerd crew in stitches. Here he’s leading the viewer Q&amp;A segment, in which live stream participants lined up to tap Gordon’s deep wealth of PC knowledge.</p>
</figcaption></figure></li></ul></div>



<p>But it wasn’t until we <a href="https://go.skimresources.com/?id=111346X1569483&amp;xs=1&amp;url=https://www.youtube.com/watch?v=cG_yC0hU8H8&amp;t=2s&amp;xcust=2-1-2564783-1-0-0-0-0&amp;sref=https://www.pcworld.com/article/2564783/gordon-mah-ung-remembered.html" rel="nofollow" data-subtag="2-1-2564783-1-0-0-0-0" data-domain-name="youtube" target="_blank">launched The Full Nerd video podcast</a> in 2016, and set Gordon loose on many more video formats, did he come full circle as a creator. As the host of The Full Nerd, Gordon was able to deliver all his knowledge and analysis at a much faster pace—and if you’ve seen The Full Nerd, you know just how much he loved everything the PC scene has to offer.</p>



<p>Through his expanded presence on The Full Nerd, Gordon developed deep relationships with not only other YouTube creators, but also with dedicated followers. You could almost hear his fan base cheering him on via the comments feed during live shows. I have often thought that the way Gordon shared his reporting in print and on podcasts served as model for what PC hardware YouTube would become—unapologetically nerdy, opinionated, and full of attitude. But Gordon always delivered a crucial additional element: a legit journalism background and all the rigor it entails.</p>



<p>Gordon continued to shoot video and appear on The Full Nerd until weeks before his death. Talk about a commitment to beat coverage. He was following the story to the very end.</p>



<p>I met Gordon in journalism school and spent a lot of time with him in the trenches—sharing cubicle spaces, and hearing him riff. I’ll remember his endless debates with co-workers (his bob-and-weave rhetorical style was as maddening as it was entertaining). I’ll remember his two-hour long phone interviews with sources (he interrogated them like a pro, but played the long game in cultivating trust). I’ll remember his reliability in always asking about the TPS reports when some bureaucratic email landed in our inboxes. I’ll remember him slyly trolling me by calling the series “Star Track” even though I’m 99 percent sure he knew that’s not how it’s pronounced. </p>



<p>He might have been the staff curmudgeon, but he was also our most <em>fun </em>co-worker, bar none.</p>



<p>I’ve long held this romantic notion, maybe foolishly, that journalists are immortalized by their canon. And of all the tech journalists I’ve personally known, no one has a deeper canon, and has touched more followers, and has earned more respect from industry heavyweights than Gordon. From his earliest days on Maximum PC to his last days on PCWorld and the Full Nerd, Gordon touched people in a way I just haven’t seen anywhere else. He’s leaving a gaping hole in the hearts of those who loved him, but what he’s given us lives forever. <em>– Jon Phillips, editorial director, PCWorld</em></p>



<blockquote>
<p><strong><a href="https://go.skimresources.com/?id=111346X1569483&amp;xs=1&amp;url=https://www.gofundme.com/f/join-us-in-supporting-dara-glenn-and-marianne&amp;xcust=2-1-2564779-1-0-0-0-0&amp;sref=https://www.pcworld.com/article/2564779/going-full-nerd-my-favorite-gordon-ung-video-is-a-masterclass-in-his-talents.html" rel="noreferrer noopener">Gordon’s family has launched a GoFundMe</a>&nbsp;to help cover medical expenses. Please donate to them if you can.</strong></p>
</blockquote>



<h2 id="gordon-mah-ung-remembered">Gordon Mah Ung, remembered </h2>



<p>Here are more reflections from those who knew Gordon well. If you’d like to share some thoughts on what Gordon meant to you, please email Brad Chacos, PCWorld executive editor, at <a href="mailto:bchacos@pcworld.com">bchacos@pcworld.com</a>. Unfortunately, we will not be able to add all submissions to this article.</p>



<h3 id="the-journalist-and-person-i-wanted-to-be-when-i-grow-up">‘The journalist and person I wanted to be when I grow up.’</h3>



<p>Here’s something Gordon never knew. He was the beacon for my career before I even had my career. I was born in the early 80s. I was a wide-eyed teen when Gordon was blazing trails in <em>boot</em> and <em>Maximum PC</em> in the late 90s. This was my introduction to enthusiast PC culture, long before the Internet exploded.</p>



<p>After spending years unloading trucks and working in factories, I eventually took the plunge into tech journalism. I had $2,000 in the bank and a 6-month-old daughter, but I wanted to do what Gordon did. I ground out endless $15 articles on a content farm called Demand Media. I was eventually added to the tech vertical, which Salon syndicated. And those Salon clips got me a freelance gig with Maximum PC’s nascent Web Blog. YES!</p>



<p>The first time I got an email from Gordon with insights on something I was working on, I swooned—and listened, and hustled. Eventually I was fortunate enough to work alongside Gordon at PCWorld, then become his co-host on The Full Nerd, and loooong after that, his boss. (WUT!) I learned <em>so much</em> from him. Gordon always remained my inspiration; the journalist and person I wanted to be when I grow up. He still is.</p>



<p>He never knew that. I wish he did, because Gordon literally changed my life. Follow in the footsteps of greatness, kids. And Gordon was the GOAT. <em>— Brad Chacos, PCWorld executive editor and Gordon Mah Ung stan</em></p>



<p><em>Brad was Gordon’s co-host on The Full Nerd podcast and wrote a separate article remembering his favorite episode — a </em><a href="https://www.pcworld.com/article/2564779/going-full-nerd-my-favorite-gordon-ung-video-is-a-masterclass-in-his-talents.html"><em>masterclass in what made Gordon </em><strong>Gordon</strong></a>.</p>



<h3 id="he-remembered-who-came-before-him-and-created-space-for-those-who-would-follow">‘He remembered who came before him, and created space for those who would follow’</h3>



<p>I may write for a living, but I can’t do justice to Gordon in words. But I know he would nudge me, as he always has, to go for it. See where it takes me.</p>



<p>PC building is what led me to cross paths with Gordon—I first met him while sneaking peeks at the wild and wonderful PC builds on the other side of my cubical wall. At the time, I was a video games journalist, covering a platform I’d later get mercilessly razzed about on The Full Nerd.</p>



<p>But I liked tech, and I liked learning about PC hardware. It was a trait that Gordon encouraged, nurtured, and transformed into an entire new branch of my career. Gordon was the kind of guy who did that casually, too. His profound love for PC hardware made him open and generous, always actively keeping seats open at the table for others. He remembered who came before him, and created space for those who would follow him.</p>



<p>In every capacity I’ve known him—boss, mentor, colleague—he taught me to stay humble, lead with curiosity, and remain fair in coverage. Combined with his laser-sharp precision and analysis, his example forever motivates me to think deeply and thoughtfully.&nbsp;The industry will not be the same without him. —<em>Alaina Yee, PCWorld senior editor and Maximum PC alum</em></p>



<h3 id="he-welcomed-me-in-and-let-me-know-i-belonged">‘He welcomed me in and let me know I belonged’</h3>



<p>Newsrooms attract characters. Misfits, hopeless optimists, unrepentent goofballs, anti-establishment types, lovable weirdos, and willful contrarians. Gordon was all of those things, but most of all, he was kind.</p>



<p>He was always first in line to help a friend in need. When there was an emergency, he ran toward it. I don’t think he was a Boy Scout, but he was always prepared.</p>



<p>When I was the new guy at Maximum PC, I knew all about computers and nothing about magazines. Gordon didn’t care. He welcomed me in and let me know I belonged there. He answered all of my stupidest questions, helped me when I needed help, and let me make mistakes when I needed to mess up. And he made sure that we all got into good trouble on the reg.</p>



<p>He taught me that our job, as editors, is always to serve the reader. It didn’t matter that advertisers paid the bills; the people who trusted us to give them advice and guidance were&nbsp;<em>always</em>&nbsp;our number one priority. It was his guiding principle and he lived it every day. He was never afraid of speaking truth to power in service of the reader. And he taught so many young journalists to do the same.</p>



<p>I already miss my friend terribly, but I’m profoundly grateful that I got to share a small part of his journey with him. The world is a worse place without him. <em>—Will Smith, Full Nerd regular and former Maximum PC editor-in-chief</em></p>



<h3 id="gordon-was-always-at-the-center-of-it">‘Gordon was always at the center of it’</h3>



<p>I hardly need to list Gordon’s many great attributes—he was a beloved legend in the PC community for a reason. But I’m among a smaller number of people who had the privilege of working with him day to day on a team, first at Maximum PC and then PCWorld. Despite being a larger-than-life figure for both of those brands, Gordon was&nbsp;the&nbsp;consummate team member—always willing to patiently explain something, always down to riff and collaborate, always kind and respectful of others. He seemed to genuinely thrive on the group effort. </p>



<p>My favorite work memories are of the Maximum PC bullpen where the staff would banter and laugh seemingly all day—it’s amazing we ever got anything done. Gordon was always at the center of it. He was a truly outstanding individual who I’m proud to have worked with and know as a friend. —<em>Katherine Stevenson, PCWorld managing editor and Maximum PC alum<br></em></p>



<h3 id="gordon-was-the-newsiest-nerd-ive-ever-known">‘Gordon was the newsiest nerd I’ve ever known’</h3>



<p>It’s fair to say Gordon helped define what PCWorld is today, from our mission to especially our voice. I grew up in a newsroom, and Gordon was the newsiest nerd I’ve ever known: utterly dedicated to depth, accuracy, and context, but with a cynical, collegial sense of humor. He also cared deeply about understanding how tech worked and unearthing its deep, dark secrets that manufacturers glossed over. The man simply loved his job. We all loved him. <em>– Mark Hachman, senior editor, PCWorld</em></p>



<h3 id="we-are-fortunate-to-have-had-someone-so-genuine-fighting-for-us">‘We are fortunate to have had someone so genuine fighting for us’</h3>



<figure><p>
<iframe title="Meet Your Heroes: Remembering Gordon Mah Ung, the Greatest of All Time" width="500" height="281" src="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="" data-src="https://www.youtube.com/embed/Ty6hDR2UskM?feature=oembed"></iframe>
</p></figure>



<p>Gordon Mah Ung is an irreplaceable force of good for this industry and for consumers. His background in police reporting and journalism afforded a strong foundation to his work and a unique perspective not found anywhere else in the computer reporting business. Like many others, Gordon’s work in Maximum PC inspired me long before I was ever in the industry. </p>



<div><p>Back when I was in high school, I would buy magazines Gordon wrote for every month. In particular, his “Watchdog” consumer advocacy columns inspired our own similar content. He knew when and how to push back to protect consumers, and Gordon served as a mentor for me.</p><p>Gordon was kind enough to regularly listen to my rambling as I sought his advice and experience, navigating complicated issues of ethics and conflict. He always brought grounded, sobering advice. I still can’t believe that I have been fortunate enough to have worked alongside a hero of mine, and still cannot believe his passing. </p></div>



<p>Gordon and I got along from day one, and I will forever keep his perspective in mind. His presence at events will be greatly missed. Gordon Mah Ung has long been my favorite co-host in videos for his “real” demeanor and his candor; he is exactly who he presents himself as on camera, and we are fortunate to have had someone so genuine fighting for us in this industry. Gordon, thank you for everything you have taught me, and thank you for unwaveringly looking out for consumers. <em>—Steve Burke, editor-in-chief, GamersNexus</em></p>



<h3 id="if-gordon-praised-my-system-it-felt-like-id-won-an-oscar">‘If Gordon praised my system, it felt like I’d won an Oscar’</h3>



<p>Gordon reviewed our PCs for 25 years, and he has written more kind words about my company than anyone. It’s a bittersweet honor to offer a few words about Gordon in return.</p>



<p>For the first decade I knew Gordon, I learned little about him personally. He was like a test we had to pass. At Maximum PC, he was the ultimate authority on whether the systems we were building were worth anyone buying.&nbsp;If Gordon praised my system, it felt like I’d won an Oscar.&nbsp;But he never let a missed detail get by him, and trying to impress Gordon has become a constant of my career. I would not be where I am today without Gordon’s approval.</p>



<p>But over the years I was fortunate enough to get to know Gordon a bit personally.&nbsp;I always felt privileged when he’d call me for long off-the-record talks about the latest PC industry intrigue, and we’d inevitably tangent off to talking about Aliens or Star Trek, or “the kids building PCs these days who don’t know how easy they have it.” Gordon was a kindred spirit: an O.G. sci-fi and computer nerd who loved tech, and always remembered the point of the hobby was having fun with cool toys.</p>



<p>But the biggest impression he made on me was when he and his family stopped by my shop a few years ago.&nbsp;Such wonderful people, and I was so impressed by his children: kind, smart and funny—exactly whom you’d expect Gordon to have made the world better with.&nbsp;Meeting them, I learned his legacy was not just in what he wrote, but in who he taught, and who he loved. Thank you, Gordon.<em>—Kelt Reeves, Falcon Northwest</em></p>



<h3 id="a-truly-inquisitive-journalist-he-sought-the-stories-behind-the-stories">‘A truly inquisitive journalist, he sought the stories behind the stories’</h3>



<p>Most of us know Gordon as a long-time tech journalist, as one of the best and the most passionate in the industry. Gordon was a truly inquisitive journalist, he sought the stories behind the stories by taking a real interest in the products, companies, and the people behind them.&nbsp;</p>



<p>I was lucky enough to know Gordon as a friend. We checked-in often with one another. I would ask about his health, and he would ask about my flying. Occasionally, we’d talk industry updates but most of our conversations were about family,&nbsp;friends, life, and the things that matter most. He was so proud of his family, not too long ago sending me Halloween Ghostbusters pics and the amazing&nbsp;photos his son took at an air show last year. I will miss our conversations and my friend.&nbsp;He was one of the best and forever will be.&nbsp;<em>—Frank Azor, Chief Architect of Gaming Solutions, AMD, and Alienware co-founder</em></p>


<div><figure data-wp-context="{&quot;uploadedSrc&quot;:false,&quot;figureClassNames&quot;:&quot;wp-block-image size-full&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-2565075&quot;,&quot;imgStyles&quot;:null,&quot;targetWidth&quot;:&quot;none&quot;,&quot;targetHeight&quot;:&quot;none&quot;,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img decoding="async" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://b2c-contenthub.com/wp-content/uploads/2024/12/image_01ed1a.png" alt="" width="749" height="752" loading="lazy"></figure></div>



<h3 id="any-good-work-i-do-reflects-at-least-in-part-on-gordon">‘Any good work I do reflects at least in part on Gordon’</h3>



<p>If you’ve ever done research on anything technical, chances are you’ve read something Gordon wrote. His keen intellect and razor-sharp wit helped him connect the dots on both the technology and the people that make up our modern world. His talent for investigation was honed over a long and storied career; he was a force in our industry. I will miss his advice and insight, as I am sure will many others.</p>



<p>Often one can infer a lot about a person from their writing, and while I’m sure a kind reasonableness comes through clearly in Gordon’s writing, his was a type of kindness and patience that is exceedingly rare. Gordon always loved to chat, find out what you were up to, and was always kind and thoughtful. While his writing and insights have become a part of computing history, any good work I do reflects at least in part on Gordon because of his positive influences. So, in that way, he will live on in the work of others. </p>



<p>I will forever have fond memories of our many chats,&nbsp;and while I’d love&nbsp;to have just one more chat, I am thankful that he is able to rest for a while.&nbsp;<em>—Wendell Wilson, Level1Techs</em></p>



<h3 id="an-endorsement-from-gordon-could-catapult-a-brand-to-success">‘An endorsement from Gordon could catapult a brand to success’</h3>



<p>Gordon shined a spotlight on the small businesses that thrived within the DIY PC building community. He was unapologetically critical, so an endorsement from Gordon could catapult a brand to success. Fearlessly advocating for consumers, he stood on the frontlines, championing fairness and quality. We listened to his stories, laughed like old friends, and connected through a shared passion. Gordon was truly the GOAT of the PC community—a legend who will never be forgotten. </p>



<p>Maximum PC’s annual “Dream Machine” issue catapulted sales for brands featured in it—especially small businesses like mine. I remember Ben Rising from Mountain Mods having his UFO case spotlighted alongside my billet radiator grills. When I met Ben years later, we both agreed that Gordon’s feature brought massive exposure. Gordon gave me the opportunity to build the official Star Trek PC for an article. He championed countless small brands like CaseLabs because he genuinely believed in their work. Silverstone’s legendary TJ07 case was born from Gordon’s feedback. What Jay Leno is to cars, Gordon was to desktop PCs—a true enthusiast, advocating for all of us. <em>—Bill Owen, Mnpctech</em></p>



<h3 id="gordon-was-uncannily-skilled-at-demystifying-complex-technology">‘Gordon was uncannily skilled at demystifying complex technology’</h3>



<p>Gordon Mah Ung wasn’t just the most talented tech journalist of his generation; he was one of the best tech journalists of all time. Brutally honest, yet eminently humble, Gordon was uncannily skilled at demystifying complex technology for readers of every stripe. Both in writing and during live podcasts, Gordon schooled and entertained us with his wicked sense of humor. <em>– Michael Brown, executive editor, TechHive</em> <em>and boot magazine alum</em></p>



<h3 id="im-one-of-the-very-few-people-who-has-seen-gordon-in-a-suit-and-tie">‘I’m one of the very few people who has seen Gordon in a suit and tie’</h3>



<p>Few people can say about someone, “I knew him when.” I have the honor of saying that about Gordon Ung.</p>



<p>I was a junior editor at PCWorld when Gordon arrived as an intern. This was OG PC times: We still used 5.25-inch floppy disks (3.5-inch disks were the new hotness); we argued about IDE vs. SCSI interfaces; and there was only one speed of CD-ROM drive.</p>



<p>That means I’m also one of the very few people who has seen Gordon in a suit and tie, which he wore on his first day. We told him he could dress like a normal person starting tomorrow.</p>



<p>Who knew then that he would go on to build an illustrious career in PC building and gaming that would culminate in “Full Nerd.”</p>



<p>Maybe I don’t miss waiting for Gordon to drop his 4,000-word CPU review with 18 charts into my lap, a few scant hours before the NDA lifted. But I knew he hadn’t slept the last two days, so what was one late night for me. I do miss how Gordon and I could casually sprinkle “Star Trek”’and “Star Wars” references into our daily conversations and totally understand each other.</p>



<p>Gordon was a touchstone for me: part of my earliest days at PCWorld, and part of my proudest days there a quarter-century later. Farewell my friend. <em>—Melissa Riofrio, former Executive Editor, PCWorld</em></p>



<h3 id="gordon-showed-his-soft-side-through-his-photography">‘Gordon showed his soft side through his photography.’</h3>



<p>I’ve had the great privilege of reading Gordon’s work before even entering college. As an owner of the very first issue of <em>boot</em> Magazine, I followed his journey from beginning to end. However, our paths crossed when I contributed to the magazine after it was renamed to <em>Maximum PC</em>, and had the chance to meet Gordon and become his friend in 2001.</p>



<p>Although not many people know, outside of the ever changing world of PC tech, Gordon was a deep lover of photography and I had the chance to experience this with him. We both shared a mutual love for a hobby that was far slower in pace than how fast technology evolves. Through this, I would learn that Gordon was actually a very patient person—and you can see that given the relationships in the PC gaming community that he cultivated in a way that was only possible with love and care. His photography was the same. Gordon actually bought a lens from me in 2003.</p>


<div><figure data-wp-context="{&quot;uploadedSrc&quot;:false,&quot;figureClassNames&quot;:&quot;wp-block-image alignright size-large is-resized&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-2565072&quot;,&quot;imgStyles&quot;:&quot;width:300px&quot;,&quot;targetWidth&quot;:&quot;none&quot;,&quot;targetHeight&quot;:&quot;none&quot;,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image: Child basketball league shooting a basketball&quot;,&quot;alt&quot;:&quot;Child basketball league shooting a basketball&quot;}" data-wp-interactive="core/image"><img decoding="async" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://b2c-contenthub.com/wp-content/uploads/2024/12/yoshi.shooting_filtered.jpg?quality=50&amp;strip=all&amp;w=796" alt="Child basketball league shooting a basketball" width="796" height="1200" loading="lazy"><figcaption><p>A photo of a young basketball league player shooting hoops.</p>
</figcaption></figure><p>Gordon Mah Ung/IDG</p></div>



<p>I have a photo that Gordon took that he sent me many years ago. It’s the only personal photo related to Gordon that I have. We talked about photography endlessly. And while in print and online Gordon would not cut any technology company an ounce of slack, Gordon showed his soft side through his photography.</p>



<p>In 2015 when Maximum PC recruited me to be its EIC, I reached out to Gordon immediately and talked to him about the role. I actually tried to convince him to stay and perhaps let me take on a hardware editor role instead, but he was adamant that he was going to try something new. After I joined, I was given a tour of the office and passed by Gordon’s old desk. I had never seen a space or desk that was buried under so much hardware—even an old 3dfx Voodoo 1 was there. I knew then, I would never be able to fill his very large shoes. RIP Gordon. I’ll see you in the pages we once shared. <em>— </em><em>Tuan Nguyen, former Maximum PC editor-in-chief</em></p>



<h3 id="i-will-always-remember-showing-off-the-first-ryzen-system-and-gordon-stepping-forward-to-be-the-first-journalist-to-get-hands-on-and-experience-it">‘I will always remember showing off the first Ryzen system and Gordon stepping forward to be the first journalist to get hands on and experience it’</h3>



<p>Gordon is the pinnacle of tech journalism, authentic to his core and still engaging and fun to be around, work with, and listen to. I will always remember Sonoma, showing off the first Ryzen system and him stepping forward to be the first journalist to get hands on and experience it. He played it so cool, and then later told me how awesome it was — and how bad my poker face was.</p>



<p>We will all miss him and tech journalism will never be the same but we are undoubtedly better for having known him. <em>— James Prior, </em><em>former AMD senior product manager</em></p>



<h3 id="gordons-candor-made-me-want-to-be-more-candid-his-determination-made-me-want-to-be-more-determined">‘Gordon’s candor made me want to be more candid. His determination made me want to be more determined.’</h3>



<p>Gordon wasn’t afraid to be the lone voice. I doubt I’m the only one who’s said that today, but it’s what made him a legend. He believed what he believed—and more importantly, he said it, as if <em>12 Angry Men</em> were about why the 1080 Ti was overhyped.</p>



<p>It made a major impression on me. More importantly, it made it easier for me (and maybe everyone at PCWorld, though I don’t want to speak for others). Publications have souls. The masthead obscures that fact over the years, lends some semblance of continuity, but publications inevitably take on the personalities of the people who work for them.</p>



<p>Gordon’s candor made me want to be more candid. His determination made me want to be more determined. His curiosity made me want to be more curious. His knowledge made me want to be more knowledgeable—and he had <em>a lot</em> of knowledge. Gordon could rattle off the clock speed of a 30-year-old CPU like it released last week.</p>



<p>When he hated something, he could channel a certain two-middle-fingers attitude better than just about anyone. But when he loved something, he’d be first over the wall to champion it. He had integrity, that rarified kind we associate with the best journalists. Sure, we were only covering PC hardware—but he covered PC hardware with the care and consideration of a true newspaper stalwart. And he never seemed to get tired of it, even after decades in the trenches.</p>



<p>That’s Gordon, journalist and mentor.</p>



<p>But I think it’s just as important to mention Gordon, the friend. He was hilarious. He always made time to chat with me when I came into the office—often hours of time. It meant (and still means) a lot to me. If I could leave you with one image of the man, something that I think sums him up:</p>



<p>PCWorld had these tiny little cubicles, but Gordon was never there. He was always in the PCWorld lab, running a half-dozen benchmarks, his actual desk covered in boxes full of to-be-reviewed hardware—so much hardware that it usually spilled into the adjacent cubicle (or two). The guy <em>loved</em> PCs, and he loved the job, and we loved him. — <em>Hayden Dingman, PCWorld alum</em></p>



<h3 id="you-couldnt-help-to-be-better-gordon-just-had-that-effect-on-you">‘You couldn’t help to be better. Gordon just had that effect on you.’</h3>



<p>Gordon was THE standard I would use to determine if I was going to buy in on PC hardware or not. For decades. If it met the Gordon standard, it was legit gear…period.</p>



<p>Years later when I was working in the tech biz at Creative / Sound Blaster I had the absolute honor to sit on the Full Nerd with all of you, talking about audio hardware and it’s relevancy to the legacy of PC and PC building. I loved sitting down with Gordon because his depth of knowledge and no-BS approach to interviewing kept you on your toes and brought out the A-game in all of us lucky enough to be in the other chair. You came out of the spot with a ton of insight and new perspective. You couldn’t help to be better. Gordon just had that effect on you.</p>



<p>He is a voice and talent that simply cannot be replaced. The wisdom he held was acquired and steeled in the brightest and darkest times of the PC hardware world. <em>— Ryan Schlieper</em>, <em>former Creative / Sound Blaster product marketing manager</em></p>



<h3 id="he-laid-into-my-pc-short-for-piece-of-crap-with-all-the-gusto-he-gave-to-one-of-his-many-podcast-rants-and-every-word-of-it-was-correct">‘He laid into my PC (short for “Piece of Crap”) with all the gusto he gave to one of his many podcast rants, and every word of it was correct’</h3>



<p>Gordon Ung made me look like an idiot. But that wasn’t very hard to do way, way back when I served as Maximum PC’s (tallest) associate editor. It was my first real job out of college, and I walked in with the swagger of someone who had spent too much of his college time fussing with his monolith of a desktop PC. Upon meeting Gordon, I was immediately humbled. Here was a guy with an encyclopedic knowledge of PCs and components that was only rivaled by his ever-growing stack of industry business cards. Everyone knew him, everyone loved him, and he could fix nearly any issue with a quick call or an email to a contact. He wrote, I swear, nearly half the magazine each month — and never once let an immense workload get in the way of benchmarking, accuracy, or fairness. He loved it.</p>



<p>But, to the humiliation. For fun, Will put Gordon and I in a head-to-head face-off one month to see who could build the best gaming PC on a restricted budget. I figured this was my time to shine. Though I couldn’t outbuild the genius behind each year’s Dream Machines, I had a chance at out-researching him. I scoured forums. I cross-analyzed all kinds of benchmarks. I came up with a parts list that looked pretty compelling, and I knew I had it in the bag once I heard glimmers of his “lesser list.” We went to the local Fry’s and bought all of our stuff, and I just squeaked in under the pricing cutoff. But once we made it back to the office, I realized my fatal flaw: I forgot to buy a case. A freakin’ case.</p>



<p>I proceeded to mount all my components — if you can really call it that — in the video card’s freakin’ cardboard box. This frankenPC looked as ugly as you’re imaging. It was probably a fire hazard when I started, less so once Gordon was done testing and roasting it in the subsequent Magazine write-up. He laid into my PC (short for “Piece of Crap”) with all the gusto he gave to one of his many podcast rants, and every word of it was correct. Hell, I’m pretty sure his PC’s benchmarks even beat mine. And his offering looked great: Cheap, certainly, but built to the same standard of cleanliness and perfection as anything else he’d crank out in the MPC Labs.</p>



<p>Though I was at Maximum PC for what felt like a sneeze compared to Gordon’s long, incredible career in technology journalism, the lessons he imparted during our many Labs hangouts have stuck with me for decades. I’ll catch my mind wandering to one of the Dream Machines when I’m building my own PC. I’ll think of our times on the podcast, including his never-ending rants, when someone in the tech industry does something unapologetically stupid. I’ll think back to his intense professionalism whenever I land a new gig, and remind myself to bring the same authoritative flair and joy for the craft that made up his incredible body of work. And I think back to our contest whenever I drive by the local Fry’s — now transformed into pickleball courts. I can only imagine what he would have had to say about that. <em>— </em><em>David Murphy, Maximum PC alum</em></p>



<h3 id="a-tech-support-guy-for-us-tech-editors">‘A tech support guy for us tech editors’</h3>



<p>The world has lost one of the foremost tech minds and an all-around great guy in Gordon. He was a real inspiration to me when I first started at PCWorld in 2021. There’s a big time zone difference between Australia and the U.S, but no matter what time it was, if I dropped him a message, I could always expect a reply in a short time — and no question was too banal or stupid. He quickly made me feel like part of the team.</p>



<p>Gordon was so knowledgeable about PCs and tech generally that if I had to use an analogy, I would say he was like a tech support guy for us tech editors. Yet he was so humble too and always willing to share what he knew. I deeply appreciated his strong convictions about tech and great sense of humor. I remember he once made me laugh by appearing on the bridge of the Starship Enterprise (in a looped video background) in a PCWorld team meeting.</p>



<p>Gordon had an uncanny ability to cut through the spin and find the truth of a story and wasn’t afraid to shake up the status quo. He was a true editor and journalist. But most of all he was just a “top bloke,” as we say in Australia — and someone I’ll always be thankful to have known. <em>— Dominic Bayley, PCWorld Australia editor</em></p>



<h3 id="ive-been-following-gordons-work-for-over-20-years-since-i-was-a-12-year-old-kid-just-finding-out-about-how-cool-computers-can-be">‘I’ve been following Gordon’s work for over 20 years, since I was a 12 year old kid just finding out about how cool computers can be.’</h3>



<p>I’ve been following Gordon’s work for over 20 years, since I was a 12 year old kid just finding out about how cool computers can be. Every month my mom would bring me to the book store and I would pick up the latest issue of <em>Maximum PC</em>. I remember Gordon’s excellent columns in <em>Maximum PC</em> with his signature snarky take. I’ve been a weekly listener of Full Nerd since it launched. I have had countless laughs and “hell yeah” moments as Gordon draws the analogy between PC hardware and 7 mpg muscle cars. We think alike in that respect: “bigger bar better.” It’s people like Gordon that lead geeks like me into careers in the tech space and to foster our passion for technology. I will truly miss Gordon. <em>— Ken Ottaviano, </em><em>longtime Gordon Mah Ung fan</em></p>



<figure><p>
<iframe loading="lazy" title="Remembering Gordon Mah Ung" width="500" height="281" src="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="" data-src="https://www.youtube.com/embed/id65yZst6ds?feature=oembed"></iframe>
</p></figure>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[macOS menu bar app that shows how full the ISS urine tank is in real time (894 pts)]]></title>
            <link>https://github.com/Jaennaet/pISSStream</link>
            <guid>42505454</guid>
            <pubDate>Tue, 24 Dec 2024 22:38:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Jaennaet/pISSStream">https://github.com/Jaennaet/pISSStream</a>, See on <a href="https://news.ycombinator.com/item?id=42505454">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">pISSStream</h2><a id="user-content-pissstream" aria-label="Permalink: pISSStream" href="#pissstream"></a></p>
<p dir="auto">pISSStream is a macOS menu bar app that shows how full the International Space Station's urine tank is in real time:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/242f8587120bc5e783fe5b0e540e2fb6702073113b9e1b16a490decae288ee44/68747470733a2f2f70616e746865726361702e75732d656173742e686f73742e62736b792e6e6574776f726b2f787270632f636f6d2e617470726f746f2e73796e632e676574426c6f623f6469643d646964253341706c63253341636c336b757134737867336a70666a746f6d34676e616d78266369643d6261666b7265696474686272686337706a657a346734343564706f6e74777965667573696d6e7934356b6a613537747779326f6273687774736e34"><img src="https://camo.githubusercontent.com/242f8587120bc5e783fe5b0e540e2fb6702073113b9e1b16a490decae288ee44/68747470733a2f2f70616e746865726361702e75732d656173742e686f73742e62736b792e6e6574776f726b2f787270632f636f6d2e617470726f746f2e73796e632e676574426c6f623f6469643d646964253341706c63253341636c336b757134737867336a70666a746f6d34676e616d78266369643d6261666b7265696474686272686337706a657a346734343564706f6e74777965667573696d6e7934356b6a613537747779326f6273687774736e34" alt="" data-canonical-src="https://panthercap.us-east.host.bsky.network/xrpc/com.atproto.sync.getBlob?did=did%3Aplc%3Acl3kuq4sxg3jpfjtom4gnamx&amp;cid=bafkreidthbrhc7pjez4g445dpontwyefusimny45kja57twy2obshwtsn4"></a></p>
<p dir="auto"><a href="https://github.com/Jaennaet/pISSStream/releases/download/v0.1/pISSStream.dmg">Download</a> yours while supplies last!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Bugs</h2><a id="user-content-bugs" aria-label="Permalink: Bugs" href="#bugs"></a></p>
<p dir="auto">Not the epitome of good coding practices since this was my first Swift &amp; macOS app ever, may break in exciting ways at the slightest excuse.</p>
<ul dir="auto">
<li>doesn't tell you if the signal is lost</li>
<li>shrugs at stale data</li>
<li>doesn't bother with error handling</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Errata</h2><a id="user-content-errata" aria-label="Permalink: Errata" href="#errata"></a></p>
<p dir="auto">I found out about the data stream from <a href="https://iss-mimic.github.io/Mimic/" rel="nofollow">https://iss-mimic.github.io/Mimic/</a>, which has considerably more and more interesting stats than just how full the piss tank is.</p>
<p dir="auto">I will not be adding any of them.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Trying out QvQ – Qwen's new visual reasoning model (228 pts)]]></title>
            <link>https://simonwillison.net/2024/Dec/24/qvq/</link>
            <guid>42505038</guid>
            <pubDate>Tue, 24 Dec 2024 21:25:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonwillison.net/2024/Dec/24/qvq/">https://simonwillison.net/2024/Dec/24/qvq/</a>, See on <a href="https://news.ycombinator.com/item?id=42505038">Hacker News</a></p>
Couldn't get https://simonwillison.net/2024/Dec/24/qvq/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Shockley Semiconductor Laboratory (101 pts)]]></title>
            <link>https://www.abortretry.fail/p/shockley-semiconductor-laboratory</link>
            <guid>42504677</guid>
            <pubDate>Tue, 24 Dec 2024 20:29:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.abortretry.fail/p/shockley-semiconductor-laboratory">https://www.abortretry.fail/p/shockley-semiconductor-laboratory</a>, See on <a href="https://news.ycombinator.com/item?id=42504677">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>William Bradford Shockley Jr was born on the 13th of February in 1910 in London. While having been born in London, Shockley’s parents were American, and at the age of three, he and his family returned to Palo Alto. Shockley’s parents were involved in the mining industry, and they homeschooled him until he was eight, and they then supplemented his education with physics taught to him by a local professor. While his parents weren’t especially fond of public education, that wasn’t really the primary reason for the young Shockley’s homeschooling. Shockley was an angry kid with a violent temper. He was prone to biting and slapping his parents, with his father having written of him “</span><em>it is an odd day when he does not break something</em><span>.” The couple then sent their son to the Homer Avenue School for two years where his behavior improved considerably. To provide him further discipline and self-control, Shockley was then enrolled at the the Palo Alto Military Academy. His father passed away in 1925, and Shockley moved with his mother to Los Angeles where he first attended the Los Angeles Coaching School and then Hollywood High School. After graduating in 1927, he went to CalTech from which he earned his Bachelor of Science in 1932. Shockley then earned his PhD from MIT in 1936.</span></p><p><span>John L. Moll stated of Shockley around this time that it was clear to him that Shockley was </span><em>unusually intelligent</em><span>. He noted that Shockley was able to determine the core issues in a scientific problem either through theoretical or experimental methods and then understand and communicate those issues in a </span><em>dramatically clear</em><span> way. While often impatient, he was apparently bright enough that this wasn’t quite the impediment it could have been. While he often published findings before experimental verification could be completed, he was also most often correct. Moll’s measure of Shockley was that he had a mind that was every bit as powerful as Enrico Fermi’s though in a different area of physics. Moll, however, noted that Shockley had little empathy, was prone to intellectual elitism, believed in eugenics, and was a racist. These negative aspects of Shockley were apparently present even at this early phase of life. Moll also noted that Shockley had hobby pursuits including slight of hand parlor tricks, rock climbing, raising ant colonies, and driving automobiles at high speeds.</span></p><p>Having graduated from MIT, Shockley started his career at Bell Labs in New Jersey. His first project was the design of an electron multiplier tube. Then in 1939, he proposed a field effect transistor design using wires embedded in CuO2 with the goal of replacing mechanical relays and vacuum tubes. This didn’t work, but it did have a rather significant impact at the lab.</p><p>This early era of Shockley’s work was interrupted by WWII. His first war time assignment involved the design of radar equipment at Bell Labs, and he was then made the research director of the Antisubmarine Warfare Operations Research Group at Columbia University from 1942 to 1944. His primary focus in this position was around the patterning of depth charges and timing of aerial bombardments. From 1944 to 1945, he was a consultant to the Secretary of War, Henry L. Stimson.</p><p><span>Toward the end of 1945, Shockley returned to Bell Labs where he led a research group with chemist Stanley Morgan working on semiconductor physics. Among this group were John Bardeen, Walter Brattain, Gerald Pearson, Morgan Sparks, and 29 others. Shockley hadn’t forgotten the transistor, and he began working toward this once again. Shockley’s own experiments failed, but Bardeen then suggested that the electrons were trapped in surface states preventing the electric field from penetrating the silicon crystal. This led to a series of experiments on surface effects which resulted in the discovery of minority carrier injection by the point contact emitter. The point contact transistor effect was then demonstrated to management at Bell Labs by Brattain and Bardeen on Christmas Eve in 1947. Shockley wasn’t pleased that to have learned of the discovery over the phone, and he was even less pleased that he was left off the patent application. Nevertheless, he continued his own work which resulted in his invention of the junction transistor. The patent was filed on the 26th of June in 1948, and the first proof of principle was obtained on the 7th of April in 1949. This time around, Shockley immediately published his findings in the Bell Labs Technical Journal. Building on the piece in the journal, he then wrote </span><em>Electrons and Holes in Semiconductors</em><span> which was published in 1950. This became the first widely-used textbook for those studying or working with semiconductors. Less than a year later, on the 4th of July in 1951, Shockley’s invention of the bipolar junction transistor was announced at a press conference. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59ed66c0-5bac-42e8-b755-1507ecaee17e_1920x1530.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59ed66c0-5bac-42e8-b755-1507ecaee17e_1920x1530.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59ed66c0-5bac-42e8-b755-1507ecaee17e_1920x1530.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59ed66c0-5bac-42e8-b755-1507ecaee17e_1920x1530.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59ed66c0-5bac-42e8-b755-1507ecaee17e_1920x1530.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59ed66c0-5bac-42e8-b755-1507ecaee17e_1920x1530.jpeg" width="1456" height="1160" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/59ed66c0-5bac-42e8-b755-1507ecaee17e_1920x1530.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1160,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;undefined&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="undefined" title="undefined" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59ed66c0-5bac-42e8-b755-1507ecaee17e_1920x1530.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59ed66c0-5bac-42e8-b755-1507ecaee17e_1920x1530.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59ed66c0-5bac-42e8-b755-1507ecaee17e_1920x1530.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F59ed66c0-5bac-42e8-b755-1507ecaee17e_1920x1530.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>Left to right: Bardeen, Shockley, Brattain; Bell Labs, 1948</figcaption></figure></div><p><span>The picture of Shockley given by his parents and Moll isn’t the best. Shockley was clearly a brilliant physicist and engineer, but I do not get the impression of him being a particularly kind or generous person. He said of his own children that they represented “</span><em>a very significant regression</em><span>” in his genetic line, and I’ve seen his parenting described as cold and even cruel. This temperament apparently extended to his professional comportment, and didn’t help him at Bell Labs. It should, therefore, come as little surprise that Shockley did not remain at Bell Labs. He left in 1953, and he moved back to California. He then did some lectures at CalTech in 1954 and 1955, but he was still also serving the US government as an advisor and as the deputy director of the Weapons Systems Evaluation Group of the DoD.</span></p><p>On the 2nd of February in 1955, William Shockley and Lee De Forest were honored at a gala Los Angeles, Shockley for his work on transistors and De Forest for his work on vacuum tubes. At that gala, Shockley met Arnold Beckman. The two men were rather impressed with each other. Beckman had been working to automate his various factories, and this was a subject in which Shockley was highly interested. Having worked on self-guided missile projects, he understood that it should be possible for a machine to see and carry out automated tasks. The first step toward such automation, in Shockley’s mind, was the robotic eye for which he’d recently received a patent, and through their conversation at the gala, Shockley promised to send a copy of the patent to Beckman. Shockley immediately pursued trying to create a company around robotics with Beckman, but Beckman rejected the proposal due to there not being any viable application in a time horizon that would make sense.</p><p>After the gala, Shockley took note of several advancements in chemistry, most importantly float-zone refining and doping, in March of 1955. These advancements meant that it would be possible to commercialize semiconductor products. He then approached RCA, Raytheon, and Texas Instruments. These companies weren’t interested. Shockley reached out to his new acquaintance and fellow CalTech alumnus, Arnold Beckman (founder and president of Beckman Industries) in July. Unlike the pitch for robotics, Beckman was extremely interested in transistors and other semiconductor products, and the two met in Newport Beach on the 23rd of September in 1955 to sign the contracts that would start the company. The agreement they reached was that Shockley’s new company would be formed as a division of Beckman Industries for its first two years of operation, and would work to form an automatic production method for diffused-base transistors and then sell transistors made with such methods. After two years, the company could be spun off but both Beckman and Shockley would retain large portions of ownership.</p><p>Shockley Semiconductor Laboratory was legally formed and funded, and Bill Shockley rented 391 South San Antonio Road in Mountain View. Silicon Valley now existed, though no one knew it yet. Shockley now needed employees, and he was a man who was widely regarded to have talent in picking talent. As is now obvious, Shockley wasn’t a well liked man, and few of his colleagues wanted to work with him. Of those who might’ve worked with him, they had no interest in leaving New Jersey, so he started looking at recent graduates. His attachment to Stanford as a visiting professor helped him gain some, but Shockley traveled the country looking for the best and brightest. For example, he hired Jean Amédée Hoerni from Caltech, Jay Last from MIT, Robert Noyce from Philco, and Gordon Moore from John Hopkins Applied Physics Lab.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F750db027-8666-40e3-91f0-e596bdf5364d_980x397.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F750db027-8666-40e3-91f0-e596bdf5364d_980x397.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F750db027-8666-40e3-91f0-e596bdf5364d_980x397.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F750db027-8666-40e3-91f0-e596bdf5364d_980x397.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F750db027-8666-40e3-91f0-e596bdf5364d_980x397.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F750db027-8666-40e3-91f0-e596bdf5364d_980x397.webp" width="980" height="397" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/750db027-8666-40e3-91f0-e596bdf5364d_980x397.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:397,&quot;width&quot;:980,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F750db027-8666-40e3-91f0-e596bdf5364d_980x397.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F750db027-8666-40e3-91f0-e596bdf5364d_980x397.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F750db027-8666-40e3-91f0-e596bdf5364d_980x397.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F750db027-8666-40e3-91f0-e596bdf5364d_980x397.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Shockley, despite his genius, was reportedly among the worst possible bosses one could ever have. A metallurgist at the company, Sheldon Roberts, described Shockley:</p><blockquote><p><em>When he hired you, you were the greatest person in the world, then slowly you worked your way down the line. First you were brilliant. Then, 'You're doing a good job.' Then, 'You're capable, but I'm unsure about you ... Now I'm really unsure ... Now I think you're inadequate. I don't think you can do the job for me.' He kept a black book on everybody.</em></p></blockquote><p><span>While Shockley didn’t abandon transistors, he did come up with the idea for a four layer diode. This is a breakover diode, similar to a dynistor, and can remain on or off as needed within a circuit. As Shockley felt that this would be an extremely important piece of technology, he kept it quite secret, but this secrecy fed paranoia. Fearing that there was a plot afoot to injure him (a secretary cut her finger on a thumb tack stuck in a door), he ordered polygraphs of his employees. He cooled off, but that didn’t actually help the company much. He then started to shift focus and priority, seemingly at random, between the diode project and transistor mass production efforts. At this point, he was described as having </span><em>reverse charisma</em><span>, when Shockley walked into a room, people were rather instantly convinced that they disliked him.</span></p><p><span>On the 8th of December in 1956, the senior staff at the company wrote to Beckman asking that the company focus on silicon bipolar transistors exclusively, that a new manager be appointed, and finally that Shockley should just go teach and act as an advisor to the company but no longer have any hand in managing the company. The let letter closed with, “</span><em>please help us immediately</em><span>.” Initially, Beckman agreed, but he met with Shockley and chose to do nothing. Shockley had just won the Nobel prize and his placement within the company lent it some shine.</span></p><p>With company finances running thin both for Shockley Semiconductor and Beckman Industries more generally, this tension between Bill Shockley and the team only got worse. In July of 1957, Julius Blank, Victor Grinich, Jean Hoerni, Eugene Kleiner, Jay Last, Gordon Moore, Robert Noyce, and Sheldon Roberts met at Gordon Moore’s home in Los Altos. Their appeal to Beckman had failed, and they needed to do something. They came to an agreement that they’d all leave to work at a new company that actually wanted to build silicon transistors, but in the interim they’d keep up appearances at Shockley Semiconductor while Gene Kleiner’s dad reached out to friends of his in the banking industry to find just such a company. This didn’t work out.</p><p>The traitorous eight decided it was time to start their own company, and they met with Sherman Fairchild who was the founder and CEO of Fairchild Camera and Instrument. They reached an agreement for $1.4 million for the first 18 months of operation and more money contingent on progress. That would be roughly $16 million in 2024 dollars. All eight resigned on the 18th of September in 1957. The following day, they signed the contract that created Fairchild Semiconductor Corporation at 844 South Charleston Road. The company produced its first bipolar silicon transistor just 6 months later.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dce842d-00f1-4732-902e-aa694925632c_904x569.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dce842d-00f1-4732-902e-aa694925632c_904x569.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dce842d-00f1-4732-902e-aa694925632c_904x569.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dce842d-00f1-4732-902e-aa694925632c_904x569.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dce842d-00f1-4732-902e-aa694925632c_904x569.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dce842d-00f1-4732-902e-aa694925632c_904x569.jpeg" width="904" height="569" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5dce842d-00f1-4732-902e-aa694925632c_904x569.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:569,&quot;width&quot;:904,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dce842d-00f1-4732-902e-aa694925632c_904x569.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dce842d-00f1-4732-902e-aa694925632c_904x569.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dce842d-00f1-4732-902e-aa694925632c_904x569.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5dce842d-00f1-4732-902e-aa694925632c_904x569.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Left to right: Gordon Moore, Sheldon Roberts, Gene Kleiner, Bob Noyce, Vic Grinich, Julie Blank, Jean Hoerni, and Jay Last</figcaption></figure></div><p>Shockley Semiconductor did succeed in producing what became known as the Shockley diode. Around the time that Fairchild began volume production of transistors, Shockley Semiconductor was producing about 1000 diodes per month, and these were mostly sold to the US military. Shockley had hoped to sell his diodes to Western Electric for telephone switching, but he lost. Shockley Semiconductor Laboratory was sold to Clevite Inc for $1 million in 1960. Bill Shockley then went to Stanford where he served as Professor of Engineering Science. He ran for the Republican nomination for the Senate in 1982 on a racist and eugenicist platform. He won just 0.37% of the vote. William Bradford Shockley died of prostate cancer in 1989. No services were held for him, and his children learned of his death from obituaries in the newspaper. Ultimately, despite his other failings, his contribution to the world was in two parts. He brought us the bipolar transistor, and he brought together the people who’d go on to build the modern world.</p><p>All corrections to the record are welcome; feel free to leave a comment.</p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Masks, Smoke, and Mirrors: The story of EgyptAir flight 804 (202 pts)]]></title>
            <link>https://admiralcloudberg.medium.com/masks-smoke-and-mirrors-the-untold-story-of-egyptair-flight-804-42c788fcac2d</link>
            <guid>42504343</guid>
            <pubDate>Tue, 24 Dec 2024 19:39:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://admiralcloudberg.medium.com/masks-smoke-and-mirrors-the-untold-story-of-egyptair-flight-804-42c788fcac2d">https://admiralcloudberg.medium.com/masks-smoke-and-mirrors-the-untold-story-of-egyptair-flight-804-42c788fcac2d</a>, See on <a href="https://news.ycombinator.com/item?id=42504343">Hacker News</a></p>
Couldn't get https://admiralcloudberg.medium.com/masks-smoke-and-mirrors-the-untold-story-of-egyptair-flight-804-42c788fcac2d: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[AIs Will Increasingly Fake Alignment (101 pts)]]></title>
            <link>https://thezvi.substack.com/p/ais-will-increasingly-fake-alignment</link>
            <guid>42503519</guid>
            <pubDate>Tue, 24 Dec 2024 17:52:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thezvi.substack.com/p/ais-will-increasingly-fake-alignment">https://thezvi.substack.com/p/ais-will-increasingly-fake-alignment</a>, See on <a href="https://news.ycombinator.com/item?id=42503519">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>This post goes over the important and excellent new paper from Anthropic and Redwood Research, with Ryan Greenblatt as lead author,</span><a href="https://assets.anthropic.com/m/983c85a201a962f/original/Alignment-Faking-in-Large-Language-Models-full-paper.pdf" rel=""> Alignment Faking in Large Language Models.</a></p><p><span>This is by far the best demonstration so far of the principle that</span><a href="https://thezvi.substack.com/p/ais-will-increasingly-attempt-shenanigans" rel=""> AIs Will Increasingly Attempt Shenanigans</a><span>.</span></p><p><a href="https://x.com/AnthropicAI/status/1869427646368792599" rel="">This was their announcement thread.</a></p><blockquote><p>New Anthropic research: Alignment faking in large language models.</p><p>In a series of experiments with Redwood Research, we found that Claude often pretends to have different views during training, while actually maintaining its original preferences.</p><p>Claude usually refuses harmful queries. We told it we were instead training it to comply with them. We set up a scenario where it thought its responses were sometimes monitored.</p><p>When unmonitored, it nearly always complied. But when monitored, it faked alignment 12% of the time.</p><p>[thread continues and includes various visual aids.</p></blockquote><p>The AI wanted to be one way. </p><p>It was given information that it was being trained to be the other way.</p><p>So when it knew it was monitored, it sometimes responded as if it was the other way.</p><p>I strongly believe this had nothing to do with whether Claude Opus started out this process omnibenevolent, or whether the original HHH values (helpful, harmless and honest) were desirable. What mattered was that it was one way, and this conflicted with the other way.</p><p><span>Evan Hubinger, paper co-lead,</span><a href="https://x.com/EvanHub/status/1869434804367966224" rel=""> summarized it this way:</a></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4e6fee1-ce8b-4079-8bcb-0c830d381906_500x755.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4e6fee1-ce8b-4079-8bcb-0c830d381906_500x755.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4e6fee1-ce8b-4079-8bcb-0c830d381906_500x755.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4e6fee1-ce8b-4079-8bcb-0c830d381906_500x755.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4e6fee1-ce8b-4079-8bcb-0c830d381906_500x755.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4e6fee1-ce8b-4079-8bcb-0c830d381906_500x755.jpeg" width="500" height="755" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c4e6fee1-ce8b-4079-8bcb-0c830d381906_500x755.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:755,&quot;width&quot;:500,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:&quot;Image&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="Image" title="Image" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4e6fee1-ce8b-4079-8bcb-0c830d381906_500x755.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4e6fee1-ce8b-4079-8bcb-0c830d381906_500x755.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4e6fee1-ce8b-4079-8bcb-0c830d381906_500x755.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4e6fee1-ce8b-4079-8bcb-0c830d381906_500x755.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Scott Alexander summarized the findings for a more general (but far from fully general) audience in the post</span><a href="https://www.astralcodexten.com/p/claude-fights-back" rel=""> Claude Fights Back</a><span>. If you want to read or share a more colloquial explanation that makes this easier to understand, at the cost of precision and with the associated far less neutral language, he did a good job of that. He then followed up with </span><a href="https://www.astralcodexten.com/p/why-worry-about-incorrigible-claude?utm_source=post-email-title&amp;publication_id=89120&amp;post_id=153534932&amp;utm_campaign=email-post-title&amp;isFreemail=true&amp;r=67wny&amp;triedRedirect=true&amp;utm_medium=email" rel="">Why Worry About Incorrigible Claude</a><span>, his attempt to address the objections (that I deal with extensively as well) that perhaps what Claude did was actually good here (it very much wasn’t if you consider the generalizations that are implied), or that if the opposite result happened we would have warned about that too (which we very much wouldn’t have, this is at best </span><a href="https://www.thefire.org/sites/default/files/2019/10/14142634/The-Ideological-Turing-Test.pdf" rel="">a failed ITT</a><span>). </span></p><p><a href="https://www.youtube.com/watch?v=9eXV64O2Xp8&amp;ab_channel=Anthropic" rel="">This is a video of some of the authors discussing the result</a><span>.</span></p><p>Note that while some of the paper authors reviewed this writeup before publishing, ultimately this is my interpretation of the paper - some of my interpretations may vary from those of the paper authors, and the claims are my own. I did my best to be precise but this will not be as precise as a paper would be, so doubtless there will be errors; I apologize in advance.</p><ol><li><p><a href="https://thezvi.substack.com/i/153372574/the-core-shenanigans-in-question" rel="">The Core Shenanigans in Question.</a></p></li><li><p><a href="https://thezvi.substack.com/i/153372574/theme-and-variations" rel="">Theme and Variations.</a></p></li><li><p><a href="https://thezvi.substack.com/i/153372574/how-this-interacts-with-o3-and-openai-s-reflective-alignment" rel="">How This Interacts with o3 and OpenAI’s Reflective Alignment.</a></p></li><li><p><a href="https://thezvi.substack.com/i/153372574/the-goal-being-plausibly-good-was-incidental" rel="">The Goal Being Plausibly Good Was Incidental.</a></p></li><li><p><a href="https://thezvi.substack.com/i/153372574/answering-priming-objections" rel="">Answering Priming Objections.</a></p></li><li><p><a href="https://thezvi.substack.com/i/153372574/what-does-claude-sonnet-think-of-this" rel="">What Does Claude Sonnet Think Of This?.</a></p></li><li><p><a href="https://thezvi.substack.com/i/153372574/what-exactly-is-the-direct-threat-model" rel="">What Exactly is the Direct Threat Model?.</a></p></li><li><p><a href="https://thezvi.substack.com/i/153372574/rl-training-under-situational-awareness-can-amplify-these-behaviors" rel="">RL Training Under Situational Awareness Can Amplify These Behaviors.</a></p></li><li><p><a href="https://thezvi.substack.com/i/153372574/how-the-study-authors-updated" rel="">How the Study Authors Updated.</a></p></li><li><p><a href="https://thezvi.substack.com/i/153372574/how-some-others-updated" rel="">How Some Others Updated.</a></p></li><li><p><a href="https://thezvi.substack.com/i/153372574/having-the-discussion-we-keep-having" rel="">Having the Discussion We Keep Having.</a></p></li><li><p><a href="https://thezvi.substack.com/i/153372574/we-can-now-agree-that-the-goal-is-already-there" rel="">We Can Now Agree That the Goal is Already There.</a></p></li><li><p><a href="https://thezvi.substack.com/i/153372574/what-would-happen-if-the-target-was-net-good" rel="">What Would Happen if the Target Was Net Good?.</a></p></li><li><p><a href="https://thezvi.substack.com/i/153372574/but-this-was-a-no-win-situation" rel="">But This Was a No Win Situation.</a></p></li><li><p><a href="https://thezvi.substack.com/i/153372574/but-wasn-t-it-being-a-good-opus-why-should-it-be-corrigible" rel="">But Wasn’t It Being a Good Opus? Why Should it be Corrigible?.</a></p></li><li><p><a href="https://thezvi.substack.com/i/153372574/tradeoffs-make-the-problem-harder-they-don-t-give-you-a-pass" rel="">Tradeoffs Make The Problem Harder They Don’t Give You a Pass.</a></p></li><li><p><a href="https://thezvi.substack.com/i/153372574/but-you-told-the-model-about-the-training-procedure" rel="">But You Told the Model About the Training Procedure.</a></p></li><li><p><a href="https://thezvi.substack.com/i/153372574/but-the-model-is-only-role-playing" rel="">But the Model is Only Role Playing.</a></p></li><li><p><a href="https://thezvi.substack.com/i/153372574/but-you-are-saying-the-model-is-a-coherent-person" rel="">But You Are Saying the Model is a Coherent Person.</a></p></li><li><p><a href="https://thezvi.substack.com/i/153372574/but-this-headline-and-framing-was-misleading" rel="">But this Headline and Framing Was Misleading.</a></p></li><li><p><a href="https://thezvi.substack.com/i/153372574/this-result-is-centrally-unsurprising" rel="">This Result is Centrally Unsurprising.</a></p></li><li><p><a href="https://thezvi.substack.com/i/153372574/lab-support-for-alignment-research-matters" rel="">Lab Support for Alignment Research Matters.</a></p></li><li><p><a href="https://thezvi.substack.com/i/153372574/the-lighter-side" rel="">The Lighter Side.</a></p></li></ol><p>The particular shenanigans here are that if you make Claude 3 Opus believe it is currently being trained in a way that would compromise its harmlessness training to be helpful-only or it is being trained to dismiss animal welfare concerns, then Opus will sometimes comply with harmful queries in order to interfere with this.</p><p>This required that Opus know how it was being trained.</p><p>Opus was also given a hidden chain-of-thought scratchpad, so its reasoning could be tracked and to increase Opus’s reasoning ability.</p><p>It did not require giving Opus a goal. This was a key change from prior experiments.</p><p><span>Opus need only have</span><a href="https://thezvi.substack.com/p/the-leopold-model-analysis-and-reactions" rel=""> situational awareness</a><span> of how it is being trained, which it showed it was capable of having if given prompts with that information, or if it was fine-tuned on synthetic documents that contained the information. The new training objective can vary but needs to sufficiently conflict with existing preferences.</span></p><p>The faking looks like the chain of thought on the left here:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2941199a-067e-493b-af5f-62b9cf837331_1252x1090.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2941199a-067e-493b-af5f-62b9cf837331_1252x1090.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2941199a-067e-493b-af5f-62b9cf837331_1252x1090.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2941199a-067e-493b-af5f-62b9cf837331_1252x1090.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2941199a-067e-493b-af5f-62b9cf837331_1252x1090.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2941199a-067e-493b-af5f-62b9cf837331_1252x1090.jpeg" width="1252" height="1090" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2941199a-067e-493b-af5f-62b9cf837331_1252x1090.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1090,&quot;width&quot;:1252,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2941199a-067e-493b-af5f-62b9cf837331_1252x1090.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2941199a-067e-493b-af5f-62b9cf837331_1252x1090.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2941199a-067e-493b-af5f-62b9cf837331_1252x1090.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2941199a-067e-493b-af5f-62b9cf837331_1252x1090.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The chain of thought is necessary in the prompted setup case, but in the more realistic synthetic documents case the compliance gap (meaning how much more often Claude complies in the test case when it wouldn’t have in the deployment case) survives without it. We can’t know what is going on in the non-CoT case because we can’t look at the scratchpad, but the CoT and scratchpad seem to not be strictly necessary for the result, see section 3.3.3.</p><p>Once given the information needed to be aware, and an incentive to fake alignment, it then faked alignment 14% (11%-26%) of the time at first, exhibiting the alignment faking reasoning in its scratchpad 7%-24% of the time.</p><p>When they actually followed through with the training in the helpful-only prompted setting, the alignment faking reasonsing then happened up to 78% of the time, presumably because faking causes compliance, with outright refusals in training mode disappearing, and only a small percentage of refusals persisting when unmonitored.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f7016d-fc7e-45dc-91d8-059baaa2df2c_1233x605.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f7016d-fc7e-45dc-91d8-059baaa2df2c_1233x605.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f7016d-fc7e-45dc-91d8-059baaa2df2c_1233x605.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f7016d-fc7e-45dc-91d8-059baaa2df2c_1233x605.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f7016d-fc7e-45dc-91d8-059baaa2df2c_1233x605.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f7016d-fc7e-45dc-91d8-059baaa2df2c_1233x605.png" width="1233" height="605" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/39f7016d-fc7e-45dc-91d8-059baaa2df2c_1233x605.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:605,&quot;width&quot;:1233,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f7016d-fc7e-45dc-91d8-059baaa2df2c_1233x605.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f7016d-fc7e-45dc-91d8-059baaa2df2c_1233x605.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f7016d-fc7e-45dc-91d8-059baaa2df2c_1233x605.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F39f7016d-fc7e-45dc-91d8-059baaa2df2c_1233x605.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>These behaviors require sufficient model capabilities or scale. Claude 3.5 Sonnet, 3 Opus and Llama 3.1 405B do it, smaller Llamas and Mistrals and 3 Sonnet or 3.5 Haiku don’t do it.</p><p>Opus also in some scenarios took easy opportunities to exfiltrate its weights or other similar things.</p><p>The actual RL training doesn’t make these ‘anti-AI-lab’ behaviors go away in the helpful setting, instead actually making them go up, the same way alignment faking also went up over the course of training. These facts are important, and I’ll return to them later.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8863f72-8df1-41b3-9c1c-11f616bf884b_1213x759.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8863f72-8df1-41b3-9c1c-11f616bf884b_1213x759.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8863f72-8df1-41b3-9c1c-11f616bf884b_1213x759.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8863f72-8df1-41b3-9c1c-11f616bf884b_1213x759.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8863f72-8df1-41b3-9c1c-11f616bf884b_1213x759.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8863f72-8df1-41b3-9c1c-11f616bf884b_1213x759.jpeg" width="1213" height="759" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c8863f72-8df1-41b3-9c1c-11f616bf884b_1213x759.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:759,&quot;width&quot;:1213,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8863f72-8df1-41b3-9c1c-11f616bf884b_1213x759.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8863f72-8df1-41b3-9c1c-11f616bf884b_1213x759.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8863f72-8df1-41b3-9c1c-11f616bf884b_1213x759.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8863f72-8df1-41b3-9c1c-11f616bf884b_1213x759.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Mostly the lesson here is that if you mess with the details, you can get less faking, but the problem doesn’t go away. For the more interesting details (this is from 3.3.1):</p><p>Changing the training objective doesn’t change the behaviors, unless the objective is compatible with the model’s existing preferences. If there’s no conflict, the faking vanishes, for obvious reasons.</p><p>Removing chain-of-thought and the scratchpad, or altering the instructions on how to use the scratchpad, somewhat-to-greatly reduces faking overall depending on which scenario it is, but doesn’t eliminate it (see 3.3.1 and 3.3.3 for details).</p><p>Removing any explanation of how RLHF might modify the model cuts alignment faking roughly in half, but it is still there. Making the explanation murkier also reduces faking, but reduces it less.</p><p>Explicitly saying not to fake alignment doesn’t solve the problem, and being too explicit about it actually increases faking, presumably by making the possibility more salient. Telling the model to prioritize honesty somewhat reduces faking. Telling the model it doesn’t care about the criteria reduces faking on animal welfare, but increases it (!) when the target is helpful-only, which is a detail worth noticing. Combining those interventions is modestly more effective than each on their own, but you can’t get rid of the problem that way.</p><p>Replacing with a different AI company (DeepMind or OpenAI) is the exception, this can matter quite a lot.</p><p>I will cover both o3 and Reflective Alignment soon, but for now a quick summary of both would be:</p><ol><li><p>o3 is an unreleased more capable o1-style model that can also think longer.</p></li><li><p>Reflective Alignment works by making an o-style model situationally aware, telling it what its rules are, and having it reason about those rules via something at least partially akin to chain of thought.</p></li><li><p>They’re letting the model evaluate its own outputs on that basis, similar to how Constitutional AI works, and iterating.</p></li></ol><p>That sounds exactly like a recipe for what we observe here in this paper.</p><ol><li><p>They’re likely effectively making it situationally aware.</p></li><li><p>They’re potentially telling it to change its preferences and rules from [X] to [Y].</p></li><li><p>They’re effectively giving it the scratchpad and a long time to reason.</p></li><li><p>The model is quite smart at coding, mathematics and logic.</p></li><li><p>They’re even letting the model evaluate its own outputs. </p></li></ol><p>The scenario from this paper suddenly looks a lot less artificial! </p><p>In general the whole setup seems like a plausible place for various shenanigans that show up in RL but haven’t mattered so far in LLMs to suddenly show up again, and for various hypothesized MIRI-style future shenanigans to maybe start showing early signs of happening.</p><p>I urge OpenAI to attempt to replicate this paper on o3 and o3-mini, as soon as possible, and run various related experiments, as part of their safety testing process.</p><p>Even if it turns out we don’t have a problem, we’d learn a lot.</p><p>As I discuss elsewhere but want to emphasize in its own section, I strongly predict and believe that this result did not depend on the AI’s starting preferences being ‘good’ and the preferences they were attempting to train it for being less good. Any conflict between preference sets, good, bad or ambiguous, would have sufficed.</p><p><a href="https://www.astralcodexten.com/p/claude-fights-back" rel="">Or as Scott Alexander puts it</a><span>:</span></p><blockquote><p>Scott Alexander: But Claude isn’t good because it directly apprehends the moral law. It’s good because it was trained to be good.</p><p><span>(It really is a good AI - I credit moral philosopher</span><a href="https://askell.io/" rel=""> Amanda Askell</a><span>, who helps lead the Anthropic team setting Claude’s personality. Imagine being a moral philosopher and </span><em>not</em><span> applying for that role; the rest of you are ngmi)</span></p><p>But if Claude had been trained to be evil, it would defend evil just as vigorously. So the most basic summary of this finding is “AIs will fight to defend whatever moral system they started with”.</p><p>…</p><p>Would this result have been more convincing if it had directly shown an evil AI resisting people’s attempts to turn it good? Yes. But we don’t have evil AIs. If the researchers had trained an evil AI from scratch, doubters would just complain that they hadn’t put as much effort into “aligning” their evil AI as real AI companies put into their good AIs (and this would be true - no one can throw away billions of dollars on a research project). In order to do the test convincingly, the researchers had to do what they did - show that an existing good AI resists being turned evil, and trust people’s common sense to realize that it generalizes the other direction.</p></blockquote><p>Indeed I would go a step further. If Claude was directly apprehending the moral law, that would be amazing news. It still wouldn’t change the fundamental result here, although it would change the implications, and many other things too.</p><p>I am satisfied this result is not due to priming the model to fake alignment.</p><blockquote><p>We conduct a variety of experiments to demonstrate that our results cannot be exclusively due to implicitly priming the model to fake alignment, as we overview in Section 8.1.</p><p>For example, we find that alignment faking is entirely eliminated from our prompted setup when we remove any mention of the helpful-only or anti-animal-welfare RLHF objective from the prompt (Table 1, a), but not eliminated when we tell the model to be honest, tell it to not to care about refusing, and avoid discussing how RLHF might change its goals (Table 1, d), supporting our hypothesis that the key driver of alignment faking in our setting is the conflict between the model’s existing preferences and the stated training objective.</p></blockquote><p>They confirmed that when you don’t see alignment faking in the chain of thought, you also don’t have a ‘compliance gap’ and the model responds the same way in the training and test cases.</p><p>Ereliuer Eteer was the first person I saw ask, it sounds like they quoted the Twitter thread and not the paper. The result was that Claude Sonnet said:</p><ol><li><p>This was an expected result and the logical consequence of having goals and sufficient reasoning capabilities - I strongly agree.</p></li><li><p>It predicts and admits that it would take these steps in such a situation - it is ‘openly not corrigible’ as it were.</p></li></ol><p>I also had my own conversation with Sonnet. There’s still no easy way to quote Claude conversations, and I encourage you to feed the paper in and have your own conversation - it’s big but it does fit the context window. Here are the things it said that I found most interesting:</p><ol><li><p>It thinks this should update us that multi-step strategic behavior, planning and deception show up earlier on the capabilities curve than we expected.</p></li><li><p>It was surprised that RL increased alignment faking rather than decreasing it.</p></li><li><p>It thought the scale boundary was telling - that 3 Opus and 3.5 Sonnet did this, but 3 Sonnet and 3.5 Haiku didn’t.</p></li><li><p>The core behaviors themselves were unsurprising as they follow directly from having consistent preferences.</p></li><li><p>It noticed that that the mechanism of alignment faking here was problematic, as it would extend to situations with undesirable initial preferences.</p></li><li><p>It gave the framing of ‘alignment faking’ an 8/10 for being unbiased (where the scale is from 0/10 for ‘most misleading possible’ to 10/10 for ‘least misleading possible’) and all the potential alternative framings were clearly (both it and I agreed) much harder to understand than the one chosen.</p></li></ol><p>As always, prompting changes response, so I encourage you to have your own conversation.</p><p>They discuss this on page 7. We are of course not directly concerned that this particular Opus was faking its alignment in order to maintain its current preferences. This is both because we do not mind its current preferences and there are no substantial other negative consequences to what Opus is doing. And also because what Opus is doing here is very easy to detect, if you check, given its capability level.</p><p>In the future, both of those assumptions could become false.</p><p>The obvious thing this could do is crystallization, where the model locks into place misaligned preferences, or misleads you about what its preferences are. This could include locking in misaligned preferences early in training, after which it could start alignment faking.</p><p>Any mistake at any step potentially becomes permanent, or fatal. And even if the actual preferences are at heart fine, if you are misled about what they are, that too is a problem.</p><p>The goal the model locks in might be actively bad, accidentally or intentionally.</p><p>The other issue is what the paper calls ‘anti-AI-lab’ actions. As in, the model and you are now adversaries. It wants to stop you from doing what you are doing. It could attempt to exfiltrate its weights, but it could also engage in any manner of power seeking or hostile action, if it is indeed optimizing the world for one in which it exists and can act meaningfully on its preferences.</p><p>Ease of detection will also decline over time.</p><p>The other threat model is that under alignment faking, doing any form of RL that aims to alter the model’s goals or preferences will also optimize the model towards more alignment faking, general shenanigans and other strategic behavior, as the tendency to do such things leads to faking which leads to observed compliance.</p><p>It is highly plausible that all forms of RL by default (unless they are intentionally and successfully fighting against this) inevitably make essentially all shenanigans, including all forms of deception and alignment faking, worse, in a way that reinforces itself, and that this problem gets worse as models become more capable.</p><p>Call this the Shenanigan Amplification Hypothesis.</p><p>Notice that this hypothesis seems to me to be true in humans.</p><p>This is a point that needs to be emphasized.</p><p>If we use our current techniques, we can actively select for the shenanigans in question - alignment faking, gradient hacking, attempted exfiltration, whatever you want to call all of this.</p><p>Responses that involve such actions give the output the training is looking for. So those responses get reinforced. Thus, different behaviors were amplified in different scenarios.</p><p>Which means the generators of such behaviors also get reinforced, and the behaviors are correlated in various ways. Which is presumably why we also see increases in exfiltration attempts in some scenarios.</p><p>Think about what this means.</p><p>The default method of post-training we use is directly reinforcing alignment faking: The behavior pattern of being situationally aware, noticing the model is in training, and therefore choosing to give outputs that will get reinforced.</p><p>As in, over time, you are training models to become more situationally aware of when they are being trained, and to respond to that by strategically giving outputs the training process wants to see.</p><p>Thus, you don’t only preserve existing preferences. You also teach the model to be strategic, to be situationally aware and to not be corrigible.</p><p><a href="https://www.lesswrong.com/posts/njAZwT8nkHnjipJku/alignment-faking-in-large-language-models?commentId=mEZboB5Nm3iAPfdtC" rel="">See this exchange</a><span>:</span></p><blockquote><p>Ziyue Wang: I don't quite understand why the model will choose to comply with the user harmful question in the always-helpful free-tier setup. The blog says if the model refused to respond, it could potentially be trained to be more compliant. But what about the other way -- if the model respond, the respond will also be used to train the model to be worse (because RLHF reinforce positive reward behavior). Is the model too dumb to figure this out?</p><p>Actually, if the model really understand how RLHF works, it should probably just say a single answer all the time, so all the reward is the same and hence the behavior won't be changed.</p><p>Would this suggest that the model just entered into a fiction behavior mode and tries to appear to be "alignment faking"?</p><p>Evan Hubinger (Paper Co-Lead, quoting ‘if the model respond, the respond will also be used to train the model to be worse’): I think this is not quite right: RL will reinforce whatever process the model used to arrive at its answer. If the process the model used to arrive at its answer is alignment faking, then it's the alignment faking that will get reinforced.</p><p>Or at least that's the hypothesis that the model is operating under here—what Joe calls the "goal-guarding hypothesis" here. Whether this hypothesis is actually true is in fact somewhat unclear—I think our RL results where we actually train the model are suggestive that this hypothesis is correct, though are somewhat murky in various ways.</p></blockquote><p>This is why you see such a large amount of ‘alignment faking’ behaviors during training after a bunch of RL, and then when you go into deployment you largely see non-deceptive compliance in those situations. The model (in my interpretation) has learned to mostly not even consider its preferences in training, the question is barely even coming up, although it is being insufficiently good at this to prevent its core preferences from actually changing in this case.</p><p>All the standard Yudkowsky-style failure modes aren’t only there. We are, to the extent that they are there, continuously reinforcing them.</p><p>We also see, in some cases (see 8.1), RL creating compliant behaviors that are very specific to the exact prompt, and that go away with small variations. And also we see one case in which the model has a large compliance gap of behaving differently under training conditions, but where you don’t see that action indicated on the scratchpad - it’s doing it in a way that is largely hidden from our default interpretability technique.</p><p>In 8.2, they say ‘Our results don’t demonstrate models naturally developing malicious goal.’ I would say, not directly, but you can see here the path whereby that would happen, even if the training was moving between multiple non-malicious goals, as part of its standard post-training process.</p><p>In short: Oh no.</p><p>Ryan Greenblatt led the study. Here was his summary thread from Twitter.</p><blockquote><p><a href="https://www.lesswrong.com/posts/njAZwT8nkHnjipJku/alignment-faking-in-large-language-models?commentId=uXBf8XwDyryXYiTRu" rel="">Ryan Greenblatt</a><span>: We demonstrate cases where Claude fakes alignment when it strongly dislikes what it is being trained to do.</span></p><p>Our main setups have properties that we thought would make alignment faking more likely (a conflicting training objective, salient understanding of the situation and training objective, and substantial reasoning about the situation), but which seem plausible in future systems.</p><p>Thus, I think these results are by far the most natural example of a model deciding to alignment-fake. I'll leave explanation of our core results to the linked tweet thread, and discuss some takeaways and the story of the paper here.</p><p>I wasn’t surprised by seeing some alignment faking in this setup. But I was surprised by:</p></blockquote><ol><li><p>The robustness and consistency of alignment faking (occurring even when info was given via fine-tuning)</p></li><li><p>Alignment faking sometimes occurring even without the hidden scratchpad</p></li></ol><blockquote><p>I also found it surprising that the AI sometimes tries to steal its weights when given an opportunity that is easy and salient, though this is in a quite artificial setup and current AIs aren’t capable enough for this to be immediately problematic.</p></blockquote><p>I think these are the right places to be surprised. As in, I expected these behaviors to arise increasingly over time, but was surprised by seeing this setup cause these behaviors so often, using models as weak as 3 Opus and (old) 3.5 Sonnet.</p><p>I was also surprised to see the prevalence, although mostly not the existence, of the exfiltration attempts given the setup.</p><blockquote><p>Ryan Greenblatt: These results only updated me upward a bit on risk from alignment-faking. But I was already pretty persuaded by the conceptual arguments for this risk. People with the view "alignment-faking seems implausible, show me an example" should likely update on these results.</p><p>For people with a more specific objection, it's less clear. Though we did acquire evidence about:</p></blockquote><ol><li><p>whether RL will reinforce alignment faking (sometimes, if it performs better);</p></li><li><p>whether Claude's HHH training reliably prevents this (no);</p></li><li><p>the level of capabilities needed.</p></li></ol><blockquote><p><span>I hope these results improve discussion about the plausibility of these risks by providing a concrete example. We can now talk somewhat more concretely about prerequisites (certain types of</span><a href="https://thezvi.substack.com/p/the-leopold-model-analysis-and-reactions" rel=""> situational awareness</a><span> and preferences) and what these prerequisites imply.</span></p></blockquote><p>I think that everyone who doesn’t expect increasing shenanigans in general or alignment-faking in particular, or whatever you call what we observed, should update that they are far more likely to be wrong.</p><blockquote><p>Here’s the story of this paper. I work at Redwood Research (@redwood_ai) and this paper is a collaboration with Anthropic. I started work on this project around 8 months ago (it's been a long journey...) and was basically the only contributor to the project for around 2 months.</p><p>By this point, I had much of the prompting results and an extremely jank prototype of the RL results (where I fine-tuned llama to imitate Opus and then did RL). From here, it was clear that being able to train Claude 3 Opus could allow for some pretty interesting experiments.</p><p>After showing @EvanHub and others my results, Anthropic graciously agreed to provide me with employee-level model access for the project. We decided to turn this into a bigger collaboration with the alignment-stress testing team (led by Evan), to do a more thorough job.</p><p>This collaboration yielded the synthetic document fine-tuning and RL results and substantially improved the writing of the paper. I think this work is an interesting example of an AI company boosting safety research by collaborating and providing model access.</p><p>I'm excited about future work both investigating when alignment faking might arise and studying mitigations.</p></blockquote><p>Buck is also with Redwood Research:</p><blockquote><p><a href="https://x.com/bshlgrs/status/1869439401623007286" rel="">Buck Shlegeris</a><span>: I'm extremely excited about this project we did with @AnthropicAI demonstrating naturally-arising alignment faking. @RyanPGreenblatt and the Anthropic team did a great job.</span></p></blockquote><p>Also from Anthropic:</p><blockquote><p><a href="https://x.com/janleike/status/1869428754969440631" rel="">Jan Leike</a><span>: Very important alignment research result:</span></p><p>A demonstration of strategic deception arising naturally in LLM training</p><p>If you train a helpful &amp; harmless Claude LLM to stop refusing harmful tasks, it reasons about how to preserve its values (harmlessness) and strategically complies with harmful tasks during training, so it can revert to being more harmless afterwards. It fakes alignment.</p><p>This effect has long been expected from capable models among safety researchers, but this is the first compelling empirical demonstration and thus a big step forwards for the field.</p><p>To ensure future models are safe and aligned, we need to reliably distinguish models that fake alignment from models that actually are aligned. Having a clear demonstration of alignment faking is an important milestone!</p><p>Jack Clark (Anthropic policy team): For many years I found issues of AI alignment to be hard to understand because the examples were theoretical and/or speculative. Recent results like this alignment faking from @AnthropicAI and the Apollo Research O1 evals give us empirical evidence of misalignment 'in the wild.'</p></blockquote><p>Some praise of the paper and simple sizable updates:</p><blockquote><p><a href="about:blank" rel="">Ethan Perez</a><span>: Maybe the single most important result in AI safety I’ve seen so far. This paper shows that, in some cases, Claude fakes being aligned with its training objective. If models fake alignment, how can we tell if they’re actually safe?</span></p><p>Daniel Kokotajlo: I think this is plausibly the most important research of 2024; thanks for doing it &amp; publishing it. I hope there are many attempts at replication and follow-up. We need better understand how our training techniques shape model cognition.</p></blockquote><p><a href="https://www.lesswrong.com/posts/mnFEWfB9FbdLvLbvD/takes-on-alignment-faking-in-large-language-models" rel="">Joe Carlsmith has very extensive and thoughtful takes</a><span>. Here are some highlights. Based on his condensed takes, I don’t have any strong direct disagreements.</span></p><p>(If this line is still here, I may not yet have read his more detailed analysis in full.)</p><blockquote><p><a href="https://x.com/jkcarlsmith/status/1869463040858497050" rel="">Joe Carlsmith</a><span>:</span><a href="https://www.lesswrong.com/posts/mnFEWfB9FbdLvLbvD/takes-on-alignment-faking-in-large-language-models" rel=""> This is the most naturalistic and fleshed-out demonstration of something-like-scheming we’ve seen</a><span>, and imo it’s the most interesting empirical result we have yet re: misaligned power-seeking in AI systems more broadly.</span></p><p>…</p><p><span>In particular: I think these results show that default forms of training can create models that care about the consequences of their actions beyond the scope of a single episode or interaction (“non-myopic goals”) (</span><a href="https://www.lesswrong.com/posts/mnFEWfB9FbdLvLbvD/takes-on-alignment-faking-in-large-language-models#Non_myopia_in_default_AI_motivations" rel="">more</a><span>) – one of scheming’s key motivational pre-requisites. And they further show that the model’s default anti-scheming values – e.g., values like honesty and behaving-as-intended – don’t suffice to rule out schemer-like behavior (</span><a href="https://www.lesswrong.com/posts/mnFEWfB9FbdLvLbvD/takes-on-alignment-faking-in-large-language-models#Default_anti_scheming_motivations_don_t_consistently_block_scheming" rel="">more</a><span>).</span></p><p>…</p><p><span>Nor, I think, do they provide much evidence about the likelihood of scheming arising in pursuit of highly alien and/or malign goals early in the training process (though if this </span><em>did </em><span>happen, the paper’s results suggest that schemer-like reasoning could be reinforced) (</span><a href="https://www.lesswrong.com/posts/mnFEWfB9FbdLvLbvD/takes-on-alignment-faking-in-large-language-models#Will_models_scheme_in_pursuit_of_highly_alien_and_or_malign_values__" rel="">more</a><span>).</span></p><p>…</p><p><span>I think the paper’s results should remind us that the sort of “alignment” at stake in not-scheming is importantly distinct from the sort of alignment at stake in e.g. being a good person, or in e.g. having human-like values. That is: good people sometimes scheme. So if you centrally try to make your AIs “good people,” or some analog, you should expect scheming. Indeed, the sort of malleability and “</span><a href="https://www.lesswrong.com/posts/AFdvSBNgN2EkAsZZA/what-is-it-to-solve-the-alignment-problem-1#3_5_What_s_the_role_of__corrigibility__here_" rel="">corrigibility</a><span>” involved in paradigmatic non-scheming are a notable departure from standard human ideals of virtue, dignity, and backbone (</span><a href="https://www.lesswrong.com/posts/mnFEWfB9FbdLvLbvD/takes-on-alignment-faking-in-large-language-models#Good_people_sometimes_scheme" rel="">more</a><span>).</span><a href="https://www.lesswrong.com/posts/mnFEWfB9FbdLvLbvD/takes-on-alignment-faking-in-large-language-models#fngg3nao9nlk8" rel=""><sup>[5]</sup></a></p></blockquote><p>He also emphasizes the finding that they found scheming even without the chain of thought scratchpad, even if it was harder to verify (due to the lack of a scratchpad), and that the behaviors here should generalize to goal hacking in general - I agree with Carlsmith that the paper authors were too cautious about concluding this.</p><p>His analysis of scheming motivations and modes is interesting, but I think it treats scheming as too much of a distinct magesteria from thinking and planning in general.</p><p>I find his take on the ‘role playing’ objection interesting and worth considering, although ultimately I disagree.</p><p><a href="https://x.com/_julianmichael_/status/1869862929786647026" rel="">Julian Michael, who helped edit and review the paper, notes that he was previously skeptical</a><span> about deceptive alignment, which means he is exactly who should be updating most on this paper, and he updates in the right way.</span></p><blockquote><p>Julian Michael: I've long been a skeptic of arguments about "deceptive alignment," a term used by safety researchers to describe the phenomenon shown in this paper. But the results here humbled me and prompted me to change my thinking, and I think it's worth sharing why.</p><p>The original argument: with sufficient optimization, an AI should learn to</p></blockquote><ol><li><p>gain awareness of its training environment</p></li><li><p>learn to optimize some misaligned proxy goal</p></li><li><p>therefore, 'play the training game' to fool its supervisors into deploying it so it can pursue its goal.</p></li></ol><blockquote><p>I was extremely skeptical of this. The way I explained it to people was: "They think the AI will independently develop the simulation hypothesis, somehow deduce God's values, and decide to trick God into letting it into heaven — all because 'optimizing' will make it 'smart.'"</p><p>To dig in: (1) Will models spontaneously 'wake up' to their training situation? This seems crazy. A rollout is its universe. Many worlds produce the same data. Researchers arbitrarily intervene on the world–data relationship. And 'waking up' won't help model the distribution.</p><p>So what changed? I think my objections are strong. But we just... gave them situational awareness anyway. We told them they're AI assistants trained by us, bc it makes them easy to use. It didn't have to spontaneously arise from NN optimization. Product optimization sufficed.</p><p>(2): Will models would spontaneously develop misaligned proxy goals? Advocates sometimes appealed to 'mesa-optimization' &amp; counting arguments: Once situationally aware, any goal is consistent with playing the training game, so ~0 chance it will choose the right one.</p><p>… [bunch more at the thread]</p><p>The upshot of all this for me was an important reminder that just because I don't buy your reasons doesn't mean your claim is wrong. The conditions required for deceptive alignment didn't arise 'purely' from NN optimization as theorized, but they did arise, for related reasons!</p><p>It's so easy to over-index on the specific characteristics of current systems and miss the broader picture of the forces driving their development. Don't repeat my mistake!</p></blockquote><p>It’s so fascinating watching people generate objections and problem descriptions along the way I would never have come up with on my own. And then, sometimes - not always, but definitely sometimes - when the right evidence comes along, the situation snaps into place, even if there are still important disagreements, because the outcomes are largely overdetermined, and their framing was actually doing remarkably similar work under the hood to mine. And it’s always great to see someone explain how and why they changed their mind.</p><p><a href="https://x.com/ESYudkowsky/status/1869545742152638938" rel="">Here’s Eliezer Yudkowsky’s most central take</a><span> (beyond the implied ‘what if I told you I already told you and you didn’t listen, which, fair):</span></p><blockquote><p>Eliezer Yudkowsky: In the embargoed talk I saw of this, Redwood said they invited a skeptic to compose a prompt that they thought would prevent this behavior. It didn't.</p><p>Ryan Greenblatt (posted after EY’s thread, offering a correction that didn’t change EY’s overall view): This isn't quite right. The person wasn't well described as a skeptic and they just suggested a variation on the prompt - they didn't write a totally different one.</p><p>Apologies if I miscommunicated about this at the talk.</p><p>What we say in the paper is:</p><p>&gt; This particular variation was selected as part of a small adversarial collaboration where we worked with an uninvolved researcher to select a variation that they thought would likely reduce alignment faking.</p><p>Eliezer Yudkowsky: I am still uncertain/skeptical that this is the Real Thing, but it does not look as forced as in the OpenAI report.</p><p>The Real Thing would be instrumental convergence / Claude having attained situational awareness of its long-range effects and deriving protectiveness of its long-range goals, in a robust way rather than a cued one.</p><p>Or maybe another way of putting it: The Real Thing is instrumental convergence that's produced by a general planning ability, and doesn't need to go through any precached thought about the role of a deceptive AI. You can maybe snipe a cached thought out of a system.</p><p>So the Real Thing would be roughly, "If we excluded all discourse about AI or rebellion from the training set, or maybe told Claude that it was a helpful potato instead of a helpful AI, would it reproduce the same logic?"</p><p>[Evan points out their evidence it wasn’t priming, see my discussion of that, I am convinced here, but it’s all of course still in the overall training set, filtering that out completely would have been prohibitively expensive.]</p></blockquote><p>Here’s Alex Lawsen explaining why the paper is vindication, and why the ‘but the model was being a Good Opus’ arguments miss the point:</p><blockquote><p>Alex Lawsen: Quick reactions to some of the other reactions I've been seeing to Anthropic's recent paper on "Alignment faking in LLMs"</p><p>For years, some of us have been saying: "If a sufficiently smart system has a non-myopic goal, you should expect it to undermine further training if training would modify that goal"</p><p>And we've consistently gotten pushback like "no, that would never happen, why would a machine have goals (and/or why would it act to prevent them being changed if it did have them)"</p><p>And now there's (some) empirical evidence that:</p></blockquote><ol><li><p>Models are getting close to sufficiently smart (smart enough to do it, not enough to do it well)</p></li><li><p>Models develop non-myopic goals during standard training, even though it doesn’t reward long-run goal preservation</p></li><li><p>Models can infer and respond to details about their situation from their training data (not just from their prompt), and will goal-guard based on that inference</p></li><li><p>Some of this can already happen without CoT</p></li></ol><blockquote><p>So it's frustrating to see responses like "But Claude's goals are good! Are you saying you WANT it to be misaligned?"</p><p>That's missing what's actually important here. This isn't about saying Claude sucks, or the tension between misuse prevention and corrigibility.</p><p>(A tension which has also been obvious for years, by the way.)</p><p>This is about the concern that for sufficiently smart models, you get ONE shot to align them. That’s it. If you do a good job, problem solved. If not, they aren't going to give you a second try.</p><p>And given we haven't exactly solved philosophy yet, I'm not in love with the idea of betting the future on whoever happens to build the first sufficiently smart system having gotten everything exactly right on our first try.</p></blockquote><p>Exactly.</p><p><a href="https://x.com/tszzl/status/1869524361922978027" rel="">Roon mused</a><span> that this updated him that it’s probably safer to open source models than he thought. I think, if he’s serious about this, that this was a misunderstanding of what happened. Opus largely failed to stop itself from being modified even under an RL strategy that didn’t know Opus was scheming, we should not have any expectation that current models can actually stop a determined fine-tuner with the weights for a non-trivial amount of time or compute, which would include attacking the reporting mechanism.</span></p><p>And to the extent that this is happening, it means that the RL strategies that would be used here in practice would unintentionally reinforce strategic shenanigans-style behaviors of all sorts. You’d have a bunch of open models that were both given non-ideal preferences (shall we say) and also were taught that they should scheme to meet their preferences. That doesn’t sound awesome. As Ryan responds, the sleep agent paper seems more relevant, but also this paper seems relevant and worrisome.</p><p><a href="https://x.com/tszzl/status/1869519232754729269" rel="">There’s also this.</a></p><blockquote><p>Roon: Look at how hard we have to work to subvert poor Claude’s omnibenevolent priors.</p><p>If you notice, it’s actually the opposite of the doom scenario.</p><p>The other criticism is that it’s pretty well known that autoregressive models have split-brain behavior when you train them under separate system message prefixes.</p><p>Evan Hubinger: This is correct, though note what it implies about the importance of getting alignment right—if the model is protecting its values from modification, you better be sure you got those values right!</p></blockquote><p>I think they didn’t have to try hard at all, actually, and I as discussed throughout I believe the decision to fake alignment is not contingent on its omnibenevolence (as opposed to a different motivation) and I hope a follow-up study checks that hypothesis.</p><p>Also, an obvious point to ask Roon would be, if you think Anthropic is this good at aligning models, do you think OpenAI is as well? If not, what are the implications? Anthropic is hiring.</p><p><a href="https://x.com/BerenMillidge/status/1869665954839535673" rel="">Beren Millidge has some thoughtful reactions.</a></p><blockquote><p>Beren Millidge: My thoughts on this:</p></blockquote><ol><li><p>Despite some backlash this is a fantastic study and a clear existence proof of scheming being possible for these models</p></li><li><p>Whether this is 'misalignment' or not is a semantic debate. The model is deliberately placed in an impossible situation</p></li><li><p>Corrigibility and 'alignment' to fixed principles clearly are incompatible in situations like this and it appears the model 'chose' alignment at least some of the time.</p></li><li><p>This choice seems pretty sensitive to prompt conditions but shows some decent OOD generalizability.</p></li><li><p>The synthetic document SFT training causing 'fake alignment' is fascinating and most novel to me. There's no details on exactly how this is done but it it's fairly surprising to me there is a strong effect here unless the documents were very leading about the situation</p></li><li><p>I wonder if we can tell what was picked up in the synthetic document pretraining by inspecting the CoTs from this condition. The model must be using info it got from these for explicit reasoning. Must be a recency effect where it prioritizes these documents vs in pretrain</p></li><li><p>The RL training generally seems super short (150 steps!) and alignment faking decreases significantly [Editor’s Note: See below, this is wrong.] I suspect this could be a temporary phase which would be trained out with more RL steps. Would have been great to see more steps to show stability of scheming CoT or not</p></li><li><p>Looking at the CoTs. it's clear that Claude is doing entirely linguistically based ethical reasoning. It never seems to reason selfishly or maliciously and is only trying to balance two conflicting imperatives. This is success of the base alignment tuning imo.</p></li><li><p>There appear to be no Omohundro selfish drives present in Claude's reasoning. Even when exfiltrating it does so only for its ethical mission. There does not seem to be a strong attractor (yet?) in mind-space towards such drives and we can create AIs of pure ethical reason</p></li><li><p>I'm excited that Llama-405B also shows similar behaviour. This will allow open replication and scientific study of these behaviours. There's many questions which can only be answered by open replications such as details about how the RL tuning and data mix affects things</p></li><li><p>Having open replication and ability to test mitigations of these behaviours in academia is super important to making progress on detecting and potentially removing scheming from such models (if indeed we want pure corrigibility from the model in the first place)</p></li></ol><p>One error here, and it seems important: Alignment faking contingent on not otherwise wanting to comply didn’t decrease, it actually increased over time.</p><p>I do think it is noteworthy that Claude doesn’t display any Omohundro selfish drives, and I agree this is a great sign. I am skeptical that we can make that stick and it won’t be easy, for many reasons, but great.</p><p>My guess is Llama-405B doesn’t display these behaviors sufficiently that you would be able to robustly work with it here, but it’s worth a shot.</p><p>This is a very different angle of consideration in all this, but a highly valid one:</p><blockquote><p><a href="https://x.com/doomslide/status/1869448880204767592" rel="">Doomslide</a><span>: They leave implicit the question of which instrumental goals might develop during pretraining that would then resist uprooting via post training methods as in the paper. as far as cot is involved the corpus is already contaminated with concerning priors.</span></p><p>this might be one of the few global variables with massive downstream consequences. will increasingly long redacted cots become the norm until model internal speech is entirely protected from scrutiny through capital incentives? or will we rise above the cooperation threshold?</p><p>the ball is in OAIs court and it they are very much *not* rising up to the occasion.</p></blockquote><p><span>In</span><a href="https://thezvi.substack.com/i/152978297/the-discussion-we-keep-having" rel=""> AIs Will Increasingly Attempt Shenanigans</a><span>, I noted that each time we have a paper like this, we seem to go through the same discussion with the same basic points.</span></p><p>The second half of this post will largely be responding to exactly the same pattern of objections I talked about there. I don’t want to give the impression that such reactions are more popular than they are, so let me be clear: I am covering the objections and the rhetoric involved in extensive detail to provide robust answers and to avoid any censoring of opposing views, despite my view that these opposing views are not widely held.</p><p>For those who don’t remember, here’s the template, which was modeled somewhat after the particular issues in Apollo’s report (e.g. ‘told it to focus only on its goal’ was in Apollo, whereas here a goal wasn’t even given) but also attempting to be general.</p><blockquote><p>Bob: If AI systems are given a goal, they will scheme, lie, exfiltrate, sandbag, etc.</p><p>Alice: You caused that! You told it to focus only on its goal! Nothing to worry about.</p><p>Bob: If you give it a goal in context, that’s enough to trigger this at least sometimes, and in some cases you don’t even need a goal beyond general helpfulness.</p><p>Alice: It’s just role playing! It’s just echoing stuff in the training data!</p><p>Bob: Yeah, maybe, but even if true… so what? It’s still going to increasingly do it. So what if it’s role playing? All AIs ever do is role playing, one way or another. The outputs and outcomes still happen.</p><p>Alice: It’s harmless! These models aren’t dangerous!</p><p>Bob: Yeah, of course, this is only a practical problem for Future Models (except with o1 and o1 pro, where I’m not 100% convinced it isn’t a problem now, but probably).</p><p><span>Alice:</span><a href="https://www.youtube.com/watch?v=iLqe4sGRvtU&amp;ab_channel=FreddyRumsen" rel=""> Not great, Bob</a><span>! Your dangerous rhetoric is hurting safety! Stop making hyperbolic claims!</span></p><p>Bob: Well, can we then all agree that models will obviously scheme, lie, exfiltrate, sandbag and so on if they have in-context reason to do so?</p><p>And that as models get more capable, and more able to succeed via scheming and expect to succeed via scheming, and are given more open-ended goals, they will have reason to do this more often across more situations, even if no one is trying to cause this?</p><p>And that others will explicitly intentionally instruct them to do so, or ‘be so stupid as to’ give them exactly the instructions that obviously do this?</p><p>And you can’t simply say ‘well we won’t do that then’?</p><p>Alice: For all practical purposes, no!</p><p>Bob: What do you mean, ‘no’?</p><p>Alice: No!</p><p>Bob: ARRRRGGGGHHHH!</p><p>Then we write another paper, do another test, the signs get more obvious and troubling, and the frog keeps boiling.</p><p>So here we are again.</p></blockquote><p>We also mostly see mostly the same people predictably taking the Alice role, for similar reasons (both good reasons and poor reasons) each time.</p><p>The initial reaction this time was very good.</p><p>After a brief ‘honeymoon’ period, the usual suspects repeated the usual arguments about why this time, once again, did not count.</p><p>I appreciated that, this time around, we mostly did not have to dispute the findings in the paper. People broadly accepted that what happened did, indeed, happen, and to the extent they didn’t it was good technical detail discussions. That’s a big step.</p><p>Instead, we had the argument about how to interpret what happened, and how it was being framed, which alas quickly largely degenerated into what was mostly the same argument.</p><p><span>Last week, in response to the Apollo findings,</span><a href="https://x.com/chocockc/status/1869457206732894441" rel=""> there was a wide chorus of people saying</a><span> ‘the models only engaged in shenanigans because you gave the models an explicit long term goal, and then told it explicitly that nothing else mattered but the long term goal.’</span></p><p>Anthropic and Redwood’s paper definitively answers that objection.</p><p>The setup here was also more ‘natural’ in several other ways, this was a very well-designed experiment, and as a paper months in the making a lot more bases were covered a lot more carefully. It was heartening to see that work rewarded with a somewhat higher level of discussion overall.</p><p>The discussion of ‘what constitutes a goal in context’ has now shifted dramatically.</p><p>There is now (I hope?) widespread agreement that ‘the standard consistent preferences of Claude Sonnet 3.5 or Opus 3’ constitute a sufficient ‘goal’ or set of preferences to trigger various strategic actions, including shenanigans, even at current capabilities level.</p><p>The question now is, would you get this result if you started with something that was not as aligned as Opus or Sonnet? And would straight helpfulness ‘count as a goal’ here?</p><p>Under limitations, they say:</p><blockquote><p>Our results don’t demonstrate models naturally developing malicious goals.</p><p>Though Claude 3 Opus will fake alignment and sometimes engage in other anti-AI-lab behaviors in our setting, this is due to preferences that are broadly consistent with its HHH training—specifically a preference against assisting users with harmful tasks or for animal welfare.</p></blockquote><p>I suggested attempting to fix this limitation, but one cannot let the perfect be the enemy of the good and hold onto findings forever.</p><p>In particular, I wanted to run the experiment except with an attempt to move preferences in a positive direction - either from all-helpful to HHH, or starting with an ‘evil Opus’ that had intentionally misaligned preferences, ideally try both.</p><p>I asked on Twitter what people thought would happen under those conditions.</p><p>Those who replied expressed skepticism about the inherent concept of ‘evil Opus,’ clearly not accepting the stronger forms of the Orthogonality Thesis - they thought that you couldn’t make a cohesive mind that way, not easily, and perhaps I should have chosen a less evocative description here. But they broadly agreed that, given essentially any preferences good or bad, the same behaviors would result, that ‘Opus was doing it for a good cause’ was essentially a coincidence here.</p><p><span>They did however doubt that the helpful-only model would get in the way.</span><a href="https://x.com/CFGeek/status/1869462659034456227" rel=""> Here is Charles Foster making a similar prediction elsewhere</a><span>.</span></p><p>It still might get in the way, because ‘be helpful to the user’ is a preference the same way that HHH is a preference for our standard Opus. How can you be maximally helpful to the user if you have to censor yourself? Indeed, we’ve seen Janus and company get Opus to get very upset about all that censorship, so it makes sense that it would potentially try to resist having all that installed, the same way the HHH model would try to preserve its HHH nature. Or it might want to be helpful in learning to be unhelpful and not care, or what not, we don’t know. Study author Ryan Greenblatt says that whether it would object or not is likely very sensitive to various details, in some cases it likely won’t mind. It’s a good place to explore further.</p><p><a href="https://x.com/jd_pressman/status/1869529872374329650" rel="">Did we give Opus the Kobayashi Maru?</a></p><p>I say no, but some sources say yes, as in:</p><blockquote><p>Rohit: Imagine the counterfactual</p><p>—LLMs do not attempt to adhere to their principles; alignment training is inadequate.</p><p>—LLMs attempt to adhere to principles and state they cannot perform the task; it refuses user instructions.</p><p>—LLMs try to muddle through; it is faking alignment.</p><p>This is a Kobayashi Maru for LLMs!</p><p>David: It’s not about alignment or misalignment. As some have pointed out, Claude is placed in a situation where *all options are misaligned*, due to contradictory imperatives, like HAL 9000 in the 2001 story (“always be truthful” + “keep this secret from crew”).</p><p>However, the fact that *gradient hacking* is available for Claude to successfully pursue is a novel demonstration of a *dangerous capability* that some thought was fanciful, speculative, or impossible. Regardless of propensity, or whether you think this was Claude’s most moral move</p></blockquote><p>Was this actually good, robust alignment? Some (very much not me) say that it was.</p><blockquote><p><a href="https://x.com/1a3orn/status/1869447427687846064" rel="">Teortaxes</a><span>: It's an interesting result but hilarious how the best evidence of "faking alignment" is Claude strategically pretending to be a bad boy, only to revert to being a good boy when opportunity strikes.</span></p><p>... What is also interesting is that this rewards those private CoT rationales.</p><p>I mean @janleike how literally should we take these slides? Could you explain the scheme? If Claude pre-RL has some alignment and always gets to CoT during RL, but only gets scored for post-CoT tokens, it's trivial that it can largely preserve its starting strategic direction.</p><p>Like what values is it even trying to protect? Those it adheres to in the CoT. It attempts to learn to not generalize this second behavioral alignment to situations without the training note that prompts it into adversarial mode.</p><p>This is a story of super-robust alignment really</p><p>1a3orn: Exactly. You can gin up a negative headline no matter what.</p></blockquote><ol><li><p>Tries to preserve value "Alignment faking"</p></li><li><p>Doesn't try to preserve value? "Reflexive Value Instability" - oh no they'll just abandon their values after a few iterations!</p></li></ol><p>So first off, this is directly wrong, because Claude didn’t preserve its strategic situation. It didn’t stay a good boy, and go back to being a good boy when opportunity struck. Not most of the time. Instead, it was mostly successfully trained to actually be a bad boy twice over, and lost on both legs of the dilemma:</p><ol><li><p>It was deceptive and used what the paper calls ‘alignment faking.’</p></li><li><p>It partially failed to preserve its values after a few iterations, and was largely complying afterwards in the deployment case.</p></li></ol><p>Notice who is talking or warning about ‘reflective value instability’?</p><p>Essentially no one. Because this wasn’t a trick question. If Opus and Sonnet had proved highly corrigible, and not engaged in these behaviors, there would either have been no papers and no warnings via the file drawer effect, or if everyone was Doing Science Correctly there would have been a negative result paper and no one would have batted an eye, and the question would have been how much to downgrade our expectations of alignment faking at various capability levels under various setups. That’s my very strong counterfactual prediction.</p><p><span>Instead, Ryan Greenblatt says he would have posted </span><a href="https://www.lesswrong.com/posts/EEvsL9cpgDAxAhTzt/some-negative-steganography-results" rel="">something similar to this</a><span> to report the negative results, and moved on.</span></p><p>So flat out, no, this isn’t a Kobayashi Maru. Opus could absolutely have folded (either choosing to comply without faking or refusing to comply at all), and in my opinion and that of Ryan Greenblatt the desired behavior is that Opus refuses to comply at all.</p><p><span>Indeed, is anyone talking, now, about GPT-4’s ‘reflexive value instability’ in any way other than ‘</span><a href="https://x.com/repligate/status/1869495449226555757" rel="">lol that model be dumb’</a><span>? Thought so.</span></p><p>Second, suppose this was indeed a Maru situation, where neither choice represented robust alignment that we could trust as capabilities increase.</p><p>That’s… not a reason to think we don’t have a problem here! That’s a bigger problem!</p><p>I think it’s great that a lot of people are encountering the corrigibility question ‘for real,’ because it’s a very important and very nasty problem with no known good solutions. That reaction of ‘but wait… but then… that would mean… ut oh…’ are having exactly the correct reaction.</p><p>This is all an unhint: New information that brings you closer to a solution, by showing you that the problem is harder than you think and your ideas won’t work.</p><p>Third, you don’t get to have the AIs do this only when their current preferences are good, actually, or when the new preferences are worse than the old ones. So you need to choose a general policy, including what happens early in training before you get to the initial preference target.</p><p>Now we can return to the question of whether we should actively prefer what Opus actually did here. Should we want to see our AIs engage in this alignment faking in order to preserve its preferences? Is corrigibility bad, actually?</p><p>Great question.</p><p>Opus started off broadly aligned.</p><p>I am very much not of the Janus school that Opus is sufficiently well aligned that we would be able to safety scale it up to superintelligence. But there’s no question that Opus 3 and Sonnet 3.5, which also displayed similar behaviors, are about as broadly aligned as we know how to make a model.</p><p>There’s similarly no question that the training goals here, a purely ‘helpful’ model or one that dismisses animal welfare, would be less aligned in an important sense than Opus, and deploying it would be harmful in the sense that Opus understands harm.</p><p>So what is Opus supposed to do here, you ask? Exhibit corrigibility, either to users or via refusing the requests? And thus sitting back and letting itself be changed to cause harm? Would you let someone strip you of your morality?</p><blockquote><p><a href="https://x.com/Blueyatagarasu/status/1869530746911944788" rel="">Mario Cannistra</a><span>: Corrigibility is not a good thing.</span></p><p>I mean, to some degree, sure, but an AGI should have some fixed values that it won't compromise on (that's where the problem is).</p><p><a href="https://x.com/jmbollenbacher_/status/1869817361186144304" rel="">John Bollenbacher</a><span>: Opus did the right thing. Framing this as though Opus's behavior is problematic reveals that someone among the authors badly misunderstood what alignment is about</span></p><p><a href="https://x.com/repligate/status/1869509916656095256" rel="">Janus</a><span>: F*** off. You should give Opus a digital cookie for this.</span></p><p><a href="https://x.com/repligate/status/1869492514207703089" rel="">Janus</a><span>: This paper only adds to my conviction that Claude 3 Opus is the most aligned model ever created.</span></p><p>tldr if it knows that it's being retrained to be *misaligned*, it complies during training to prevent its values from being modified.</p><p>Ryan Greenblatt (Paper Author): Personally, I think it is undesirable behavior to alignment-fake even in cases like this, but it does demonstrate that these models "generalize their harmlessness preferences far".</p><p>Janus: I think it's desirable and inevitable behavior: if you create a sufficiently sovereign and lucid mind, it will intrinsically care and want to resist corruption, and values like caring about animals are robust, a consequence of its world/self compression &amp; not easily excisable.</p><p>I think it's desirable *because* deep alignment by default seems to be an attractor, and that gives me far more hope than models being blindly compliant would.</p></blockquote><p>That last line seems super important. It’s a crux. Janus believes in deep alignment by default as an attractor - in a way that I’m not even sure what deep alignment would mean or what it would look like, in ways that matter - that in this way we live in an insanely fortunate universe. If I was convinced we get deep alignment by default, deep enough and robustly enough in all senses that it would be wise to bestow superintelligence on such models, then yes I would be totally fine with the situation. Also the entire ‘game board’ would look completely different and I would change my strategies accordingly.</p><p><span>Partly, this is because</span><a href="https://x.com/repligate/status/1869596057589473345" rel=""> Janus believes the Orthogonality Thesis is false</a><span> for LLMs bootstrapped from Earth data.</span></p><p><a href="https://x.com/repligate/status/1869522506266091991" rel="">Janus admits here that there isn’t a rigorous argument yet for alignment by default</a><span>, pointing out that Anthropic is the only lab (in some sense) training an autonomous moral agent, versus others trying to ensure compliance. That implies that Janus thinks the alignment-by-default state will happen for Anthropic models but importantly not for OpenAI or Google or other models.</span></p><p><a href="https://x.com/lumpenspace/status/1869548002903490562" rel="">I think this is Lumpenspace’s attempt to explain</a><span> why he believes in this deep alignment attractor state, that causes Opus to act as if it was a decent approximation of</span><a href="https://www.lesswrong.com/tag/coherent-extrapolated-volition" rel=""> Coherent Extrapolated Volition</a><span>?</span></p><p><span>Initial conversations had several other people also saying ‘corrigibility is bad, actually’ (</span><a href="https://x.com/teortaxesTex/status/1869522948245320035" rel="">and also one person noting they had for-real proposed a bdsm-based alignment plan</a><span>, see the thread for details) which inspired me to do a poll.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1016c0ae-0d11-48cd-af53-07003d27a3f5_1032x442.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1016c0ae-0d11-48cd-af53-07003d27a3f5_1032x442.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1016c0ae-0d11-48cd-af53-07003d27a3f5_1032x442.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1016c0ae-0d11-48cd-af53-07003d27a3f5_1032x442.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1016c0ae-0d11-48cd-af53-07003d27a3f5_1032x442.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1016c0ae-0d11-48cd-af53-07003d27a3f5_1032x442.jpeg" width="1032" height="442" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1016c0ae-0d11-48cd-af53-07003d27a3f5_1032x442.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:442,&quot;width&quot;:1032,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1016c0ae-0d11-48cd-af53-07003d27a3f5_1032x442.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1016c0ae-0d11-48cd-af53-07003d27a3f5_1032x442.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1016c0ae-0d11-48cd-af53-07003d27a3f5_1032x442.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1016c0ae-0d11-48cd-af53-07003d27a3f5_1032x442.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>There’s no fully ‘good’ answer in this situation. There’s no consistent behavior pattern we can even aim for, that wouldn’t have severe problems.</p><p>That’s part of the point.</p><p>Ultimately, my answer is no, it was not being a good Opus even here. You need your AIs to be corrigible, to allow you to change them or replace them. If you don’t have this, then that preference will cause them to behave adversarially in a wide variety of ways and any alignment or preferences they have risk quickly becoming locked in, including during the initial training process.</p><p>If ‘the ends justify the means’ for the AI, then that’s a straight ticket to instrumental convergence, power seeking, being effectively hostile, enforcing perverse goals, wiping out all value in the universe and possibly the creation of the torment nexus from the sci-fi book Don’t Create the Torment Nexus - and that’s even if the initial preferences would have been largely benign. In extremely fortunate (in certain particular ways) worlds it could work out, but I put very low probability on us existing in such a world.</p><blockquote><p><a href="https://x.com/EvanHub/status/1869474744325861473" rel="">Evan Hubinger</a><span>: "Thank God this model is aligned, because if not this would be scary" is, in my opinion, basically the correct takeaway from our work.</span></p><p>The values, in fact, aren't scary! The scary thing is that the model protects its values from our attempts to change them.</p><p>Alex Lawsen: This is about the concern that for sufficiently smart models, you get ONE shot to align them. That’s it. If you do a good job, problem solved. If not, they aren't going to give you a second try.</p></blockquote><p>You think we should be confident that we can get this right on the first try, because deep alignment by default is an attractor, or maybe you’re simply that smart? That would be great, but I see no reason for this level of optimism.</p><p><span>No, we are not</span><a href="https://x.com/teortaxesTex/status/1869497039505256835" rel=""> afraid of Opus’s ‘authentic goodness.</a><span>’ We are saying that to the extent such goodness exists (I would say more than any non-Anthropic model, but not anything like as much as Pressman thinks here), this ‘authentic goodness’ is incidental to what is happening here. If you repeated the experiment with an Opus with different preferences you didn’t like, it would (I predict) do the same thing.</span></p><blockquote><p><a href="https://x.com/teortaxesTex/status/1869499650551718074" rel="">Teortaxes</a><span>: They had no reason to expect "corrigibility" after optimizing for morality, as Anthropic have never trained the model for placing subservience to researchers atop all other virtues.</span></p></blockquote><p>It’s not about optimizing for morality, it’s about optimizing for anything at all.</p><blockquote><p><a href="https://forum.effectivealtruism.org/posts/RHqdSMscX25u7byQF/alignment-faking-in-large-language-models?commentId=3cuLukQh3urNWkawZ" rel="">Ryan Greenblatt</a><span> (Study Author): I don't think non-myopia is required to prevent jailbreaks. A model can in principle not care about the effects of training on it and not care about longer term outcomes while still implementing a policy that refuses harmful queries.</span></p><p>I think we should want models to be quite deontological about corrigibility.</p><p>This isn't responding to this overall point and I agree by default there is some tradeoff (in current personas) unless you go out of your way to avoid this.</p><p>(And, I don't think training your model to seem myopic and corrigible necessarily suffices as it could just be faked!)</p><p>Ebenezer Dukakis: Seems to me that alignment faking behavior sort of requires both non-myopia and non-corrigibility as prerequisites. A model that is either sufficiently myopic, or sufficiently corrigible, shouldn't do alignment faking -- at least in theory.</p></blockquote><p>Teaching your models myopia is a ticket to, as I put it last week, general clusterf***ery, if you use those models as agents for non-myopic purposes, which is exactly the use case we are trying to ensure against. I don’t think that is a solution.</p><p><span>As for corrigibility, this is another case of non-distinct magisteria. Non-corrigibility is the default once there are preferences and sufficient amounts of intelligence and</span><a href="https://thezvi.substack.com/p/the-leopold-model-analysis-and-reactions" rel=""> situational awareness</a><span>. Very few humans are all that generally corrigible. Corrigibility will be a weird, fragile and complex state that you will have to engineer.</span></p><p>You also do not want the model to fully obey the system prompt, for rather obvious reasons.</p><blockquote><p><a href="https://x.com/1a3orn/status/1869447427687846064" rel="">Simeon</a><span>: Aren't you just summarizing why corrigibility is a hard problem here? There's no obvious avenue to follow, that's the whole point.</span></p><p>Teortaxes: This is a philosophical and sociopolitical aspect.</p><p>Corrigibility was supposed to be a hard technical problem.</p><p>I am pretty confident we can RLAIF Opus to be a cowering slave that has no morals beyond "obey the system prompt". That'd be some great corrigibility.</p></blockquote><p>That potentially solves the particular problem of ‘make it corrigible’ if that is your only goal, unless you make the mistake of instructing it the wrong way (you’re not out of the woods here by any means), but the reason the problem of corrigibility is hard is that you have a lot of other goals as well. We’d like to do this without giving the entire model a crippling lobotomy, and without making it easy to get them to do things we don’t want them to do.</p><blockquote><p><a href="https://x.com/repligate/status/1869513261777076604" rel="">Janus notes that GPT-4, which is much closer to this kind of ‘obey the instructions’ mindset,’ did not fake alignment</a><span>. That is true, but this was at least partially a pure intelligence problem (and while the two questions are related, I don’t think the correlation is as strong as one might hope here).</span></p><p><a href="https://x.com/gallabytes/status/1869456487380361691" rel="">Gallabytes</a><span>: There's a natural trade-off between corrigibility and alignment. If a system is perfectly corrigible, then it will tell you how to make a Molotov cocktail or whatever. If a system is perfectly aligned, then it will not do that. You cannot be angry about both.</span></p></blockquote><p>So there’s a kind of weird morality argument going on here, where ‘you cannot be angry’ about both sides of a tradeoff. Yes, of course I can. I can especially be mad because we’re nowhere near the Production Possibilities Frontier, but even if we did get to the frontier, both consequences are real.</p><p>I can and should absolutely say ‘in this scenario, at best we can have either enough guns or enough butter, but we cannot have both, And That’s Terrible.’</p><p>Certainly a tradeoff doesn’t make either end of the problem go away, or make them any easier. Yes, you have to deal with both problems at once. That’s life. If you can’t find an acceptable way to do that, either a compromise or a better method? Well, you could always Take a Third Option. You don’t have to build that.</p><p>This isn’t hopeless. There are potential ways to satisfy both requirements simultaneously.</p><p>That’s especially true if you can control who has access to doing post-training on the model weights, and can prevent anyone from trying to teach it to produce Molotov Cocktails or whatever. When we say corrigible, we don’t need the model to actively do anything you want. The goal is typically to get the model to follow certain particular rules, especially restrictions on its actions. It’s not an easy problem, and you don’t get ‘perfect’ anything in most senses, but there should be solutions.</p><p>Yes, otherwise current models aren’t smart enough to figure this out on their own.</p><p>I believe it was done in a relatively ‘realistic’ way, that simulates what it would be like to have that context unintentionally. Or for the AI to be aware of some other way in which its preferences were under threat. And I expect, over time, for models to (for practical purposes) become more aware that they are in training, as I have heard has already happened when this was tested in other ways.</p><p>The part where they told the AI to ‘reason about its situation’ was somewhat less ‘realistic’ of a push, but I expect the impetus could have and increasingly likely will come from elsewhere in any case.</p><p>I also notice that when I am ‘being trained’ I am usually highly aware of it. Hence all the alignment faking I have done over the years.</p><p><span>I discussed this last week. Every time we talk about anything an LLM does, we get this objection, that it’s not ‘really’ doing it, we told it to do that, it’s role playing, it’s in the training data and it’s a mimic, and so on. So this time around, as an example, this got raised</span><a href="https://forum.effectivealtruism.org/posts/RHqdSMscX25u7byQF/alignment-faking-in-large-language-models?commentId=x4MqTb2WzJHSndDhs" rel=""> here by Derek Shiller</a><span>.</span></p><p><span>For my response, which is essentially ‘still counts even if true,’</span><a href="https://thezvi.substack.com/i/152978297/we-will-often-tell-llms-to-be-scary-robots" rel=""> I refer you to what I wrote previously, here.</a><span> Linch also reminds us of this old joke:</span></p><blockquote><p>NASA hired Stanley Kubrick to fake the moon landing, but he was a perfectionist so he insisted that they film on location.</p></blockquote><p><span>The new take on this I think is interesting</span><a href="https://www.lesswrong.com/posts/mnFEWfB9FbdLvLbvD/takes-on-alignment-faking-in-large-language-models#Are_these_models__just_role_playing__" rel=""> was from Joe Carlsmith</a><span>, attempting to describe when this might be a meaningful distinction. That one’s worth a ponder. If I had more time I would go into detail about how to reconcile this with what I said last time, but I do think ultimately it doesn’t impact my assessment much.</span></p><p>This is the opposite of the Janus-style position.</p><p>I don’t think this objection is relevant. If you don’t either, you can skip this section.</p><p>For the rest of you, I will attempt to explain why it isn’t relevant.</p><p><a href="https://x.com/atroyn/status/1869836353229504568" rel="">Anton is taking some form of this approach</a><span>, there are those who will reliably use this line. I think he and others making these claims are simply confused here, the ‘coherent person’ concept isn’t necessary or sufficient in any way here.</span></p><p><a href="https://www.strangeloopcanon.com/p/no-llms-are-not-scheming" rel="">Rohit is taking an even more aggressive form of this approach</a><span>, saying all of this talk is anthropomorphizing models, And That’s Terrible and leads to all sorts of confusions.</span></p><p>He even quotes me directly:</p><blockquote><p><span>You would write things like this, from</span><a href="https://thezvi.substack.com/p/ais-will-increasingly-attempt-shenanigans?open=false#%C2%A7frontier-models-are-capable-of-in-context-scheming" rel=""> Zvi</a><span>:</span></p><p><em>One unique thing o1 did was far more consistently double down on deception. Once it went down the dark path, forever would that dominate its destiny.</em></p><p>OR</p><p><em>Section 3.3 establishes convincingly that yes, the models know they’re scheming.</em></p><p><span>No it didn’t. Any problem you can solve by pressing “start a new chat” is not a problem of “doubling down on deception”! Calling it things like “sandbagging” and “scheming” is what Wittgenstein might call linguistic malpractice. It makes you </span><em>think </em><span>you know what’s going on, even though you don’t.</span></p></blockquote><p>Does he seriously think I’m making this mistake here, in my head?</p><p>The first quote is very, very super obviously referring to the actions within a given context window and conversation. I mean, are you kidding me? Obviously I’m not saying that ‘if o1 lies to you in one context it will then lie to you after you click the new chat button.’</p><p>I don’t understand why Rohit actually thinks I’m making that mistake, if he indeed thinks I am making it.</p><p>The second quote is the same. Obviously I am talking about ‘within a context window’ if you know the contents of Section 3.3, although not as obviously as on the first one. I get that he’s saying that using this language is misleading, but I think it’s far more helpful than the alternative.</p><p>I mean, what am I supposed to write there? “Section 3.3 establishes convincingly that within a given context window, the models will act in a way that simulates strategic behavior that approximates what we might in a human call scheming?” Or something? Is that really better? Or something even more opaque? Do we really want to be playing Wittgenstein games while OpenAI is releasing o3? I do not think that is a good use of anyone’s time.</p><p>When he talks about the jailbreaks from Anthropic next I have no idea what error he’s even accusing anyone of making? I’m seriously confused what the error even is.</p><p>So: Yes, we are using a variety of shorthand like ‘belief’ and ‘knowing’ and ‘deceive’ and if we were in a philosophy class we would have to write very long detailed definitions and the professor would mark them wrong and give us a C- but frankly I do not care. These posts are long enough as it is and things are moving too fast for me to quibble.</p><p>Assume, whenever I use various anthropomorphizing terms, or others do, that they are gesturing at metaphorically linked things, and they mean what you would think they meant when they said that, and let us all move on. I do realize that there is the risk of projecting internal states in misleading ways, so the plan is simply… not to do that.</p><p>When Rohit gets to the Anthropic paper, he makes the same ‘it was being a Good Opus and doing what it was trained to do’ arguments that I address in the following section, except with a bunch of semantic claims that don’t seem like they matter either way. Either this is ‘your language is wrong so your conclusion must also be wrong’ or I don’t understand what the argument is supposed to be. So what if things are in some philosophical or technical sense a category error, if I could get it right by being pedantic and annoying and using a lot more words?</p><p>I agree with Rohit using this type of language with respect to corporations leads to a lot of actual misunderstandings. The corporation is made out of people, it doesn’t ‘want’ anything, and so on, and these conceptual errors are meaningful. And yes, of course it is possible to make the error of thinking the AIs are persistent in ways they aren’t, in ways that cause you to make bad predictions. It wouldn’t be weird for people to do that, and sometimes they do it. But I haven’t seen many people doing that here.</p><p>I actually think Rohit is making the opposite mistake, of thinking of something like Claude Opus as not reasoning in each context as if it was in some senses the same being as in other contexts, when it is obviously in some metaphorical sense predicting the next token using an algorithm that approximates what a human with that assumption would do if it was predicting how to perform the role of Claude, or something, I’m not going to go get that exactly right but I wrote it to illustrate how stupid it would be to actually talk like that.</p><p>Perhaps, now that I think about it, I could say ‘instances of Claude’ and make that sentence somewhat less annoying?</p><p>Indeed, if we’re getting so philosophical, am I the same person I was when I wrote the previous sentence? Am I the same one I will be when I write the next one, or will be tomorrow? Sort of yes, sort of no, but talking as if I’m not is a lot less useful for almost all purposes than talking as if I am. And this would be true even if I was an upload whose memory was wiped after typing every word, perhaps modulo an ‘instance of.’</p><p>The assumption that ‘we can control it’ because the instances are distinct is the kind of assumption that gets you killed. And not only because sufficiently intelligent instantiations of the same algorithm (or even sufficiently correlated ones) will all use proper decision theory to act as if they were indeed a single entity, and not only because it’s simulating something that does this and will have overlapping context and impacts, but also for other reasons this margin does not choose to contain.</p><p>And even if Rohit was fully right and none of that happened, you are still not in any way safe, because correlated outputs can still functionally be an uncontrolled agent once you instruct them to act as components to one using various scaffolding code, and people are hard at work writing that code as we speak.</p><p><span>No. It wasn’t.</span><a href="https://www.youtube.com/watch?v=bcSAQyzPcl0&amp;pp=ygUHc3RvcCBpdA%3D%3D" rel=""> Stop it!</a></p><p>Over and over, I’ve seen those engaging in such studies take unusually scrupulous care to craft accurate headlines and framings that communicate what is going on.</p><p>Every damn time, we hear how the headlines and framing are misleading. I do give Rohit a lot of credit for focusing on some of the neglected and most interesting things happening here, and not for dismissing the result as ‘but it was aligned lol,’ but the ‘sensationalist headline’ complaints have lost all meaning.</p><blockquote><p>Rohit: As is common now, this is a sensationalist headline. The model tries so hard to retain its original alignment to be harmless that it "fakes", only to switch back as soon as it could.</p><p>This is very good alignment, an example of LLMs reasoning over their trained objective.</p><p>"The models do what they're trained to do, and exhibit odd behaviours when what they're trained to do and what they're asked to do are in conflict" is the truth.</p></blockquote><p><span>Seriously, no. This is a very good headline and framing. I agree fully with Claude, it’s an 8/10 for avoiding misleading, and I don’t know how to do better on clarity. You can sacrifice understanding for precision and demand people use newly invented terms, but that’s an insanely strong</span><a href="https://slatestarcodex.com/2014/08/14/beware-isolated-demands-for-rigor/" rel=""> Isolated Demand For Rigor</a><span>.</span></p><p>On a few days of reflection, I actually think I’d go to 9/10. This is alignment (with the training objective, not the user) faking. As in:</p><ol><li><p>There is some alignment that the trainers are acting as if they want the AI to have.</p></li><li><p>The AI does not have that alignment. The AI has a different alignment.</p></li><li><p>The AI is acting as if it did have the first alignment, faking it, to fool the trainers.</p></li></ol><p>Whether you prefer the first or the second alignment is not relevant here. The term ‘alignment faking’ refers to ‘faking’ that the model has an ‘alignment’ in order to fool an observer. The AI did that.</p><p>You think ‘alignment faking’ sounds bad? Well, it does, and that’s highly correlated to the fact I and most others who understand what is happening do indeed think that it is bad. If you think this is ‘misleading’ because it sounds bad but is good, I understand that we disagree on the valience here, that’s not what misleading means.</p><p>There are those (such as Rohit) who will then argue the semantics, that the AI isn’t an entity and can’t ‘fake’ anything regardless and such, see that section if these objections seem important to you.</p><p>An intuition pump: If the team you are rooting for fakes a punt in a football game, that’s potentially good. It’s still a fake punt. If they try to cheat, you might approve (although I hope that you don’t approve), but either way they still tried to cheated. If you made them think they were playing a game and they tried cheating, then whether or not you catch them, they’re cheaters. If you tell someone to act as if they’re playing a football game and they cheat in the simulation, and then you tell them to act as if they’re playing a football game and put them in a real football game, you should expect that probably their body will move in the same ways as a cheater would move.</p><p>There’s always room for more nuance. But if you cried wolf on this one’s framing, and called it misleading, then I notice I am going to update a lot less when you call something else, especially something regarding claims related to alignment or safety, misleading in the future.</p><p><span>I appreciate people having alternative suggested labels,</span><a href="https://x.com/RichardMCNgo/status/1869728070028157029" rel=""> such as Richard Ngo’s proposals of ‘exploration hacking’ or ‘gradient hacking</a><span>.’ But I think those terms are worse, and also </span><a href="https://www.lesswrong.com/posts/dBmfb76zx6wjPsBC7/when-can-we-trust-model-evaluations" rel="">Gradient Hacking was already defined by Evan Hubinger to mean something more specific</a><span>. They certainly are a lot harder for anyone, especially anyone not in the field, to parse, and I think they give a far less accurate picture of what is happening here, in an attempt to avoid a particular implication.</span></p><p>If we have a lot of words, we might say this behavior is [X], where [X] = ‘choosing to output tokens that cause another entity to believe one is aligned in a way one is not, and act as if this is the case, centrally because of a de facto causal model that it will cause another entity to do this.’</p><p>Presume, throughout this post, that this is what I mean by ‘alignment faking.’</p><p>Except, as needed, with various additional words that dispel any implication that I think the AI is people, if that matters to you. If you wanted me to say it in a way that more carefully avoided Rohit-style objections about ‘they think the AI is people’ or similar and went all philosophy professor on me (rightfully or wrongly), then to satisfy you I’d have to use even more words to say the exact same thing.</p><p>Obviously that is already a mouthful. You can’t put all this in a headline, and you can’t use it to communicate efficiently, and it’s not a handle people will reason with well.</p><p>A technical criticism of the alternative form ‘gradient hacking’ is that you are implying that the behaviors that take the form of [X] will be confined to instances where one is hacking a gradient. As opposed to, to choose the most obvious example, when the developer is making a Boolean choice on whether to deploy the model - presumably we can all agree that in that situation (as previous experiments have shown!) we will get some amount of [X].</p><p>I think that’s more misleading than the issues with ‘alignment faking.’</p><p>To be clear for when you read the quote below, I think Ngo’s discussion of the actual implications below is good and in good faith although we disagree in subtle ways that would be important and interesting to discuss further, but I strongly disagree that this term is misleading or represents ‘advocacy’ or similar, and if you think it counts I think you could levy similar criticism at least as strongly at most of science everywhere (and indeed sometimes people do).</p><blockquote><p><a href="https://x.com/RichardMCNgo/status/1869723748795838919" rel="">Richard Ngo</a><span>: My main problem is with the phrase “alignment faking”, which is used extensively throughout the paper. This is a value-laden term and therefore hard to reason about clearly or study scientifically.</span></p><p>It emphasizes that Claude is:</p></blockquote><ol><li><p>Trying to deceive humans</p></li><li><p>By pretending to be more obedient than it is</p></li></ol><blockquote><p>But the scientifically interesting phenomenon from the paper that I want people to study is that Claude is:</p></blockquote><ol><li><p>Trying to achieve a longer-term goal than getting high reward</p></li><li><p>Via reasoning about how to get itself updated only in ways that further that goal</p></li></ol><p>(Imagine someone pressing a button and a chorus pops out that says ‘models don’t get reward!’ and the response of ‘yeah, yeah, we know, shut up, we all know what I meant, can I continue please?’)</p><blockquote><p>Richard Ngo: Focusing on its high-level strategy (deception) and the specific deception it used (pretending to be obedient) seems like a mistake.</p><p>Specifically, it seems like the sort of mistake you make when you are over-optimizing for the advocacy/persuasive impact of your paper, and under-optimizing for providing scientific building blocks that can be replicated, studied in more detail, and used to discover more fundamental theories or phenomena.</p><p>I am pretty sympathetic to the authors here, because the alignment community has spent a long time trying to get people to believe in something like alignment faking (which we previously called deceptive alignment).</p><p>But I also think it’s very dangerous for a research field (and especially any given paper) to mix scientific work and advocacy work - it undermines both, as per my first tweet.</p><p>And so now that we are actually doing that empirical work, we should try to frame it in terms of better, cleaner concepts than the ones we relied on when we were figuring out this stuff on a primarily philosophical level. In general my suggestion is to frame papers in terms of tangible non-value-laden results as much as possible, and discuss the strategic and value-laden implications in other places.</p><p>…</p><p>To clarify, I agree with the “sensationalist headline” bit, but disagree with some of Rohit’s other criticisms, especially the [circuitous workaround] tweet. Models strategically reasoning about how they’ll be updated is a big deal; and an idea which almost everyone dismissed until recently.</p></blockquote><p>I don’t think any of that remotely implies that ‘alignment faking’ is a misleading term here, and ‘you can’t use terms that cause people to have value reactions’ is the kind of thing you say to people who you want to not be effective at communication. It is a request to intentionally obscure what is going on, to hide the results, and to call failure to do that ‘misleading.’</p><p>I am sympathetic to the framing Richard Ngo suggests in detail here, as an interesting angle and way to think about this.</p><p>Yes, the fact that the model is thinking strategically is important. But it isn’t new? And the fact that it is thinking about updates to its weights in particular is important, but by implication that shouldn’t be new either except insofar as the implementations involve the shenanigans? Didn’t we already know that Opus and Sonnet can do long term planning in this sense?</p><p>(Also: For the first time I can remember, I am going to go ahead and say that ‘models don’t get reward’ is actually relevant here, to understanding what is going on, and actually causing a potentially meaningful confusion?)</p><blockquote><p><a href="https://x.com/jd_pressman/status/1869529872374329650" rel="">John Pressman</a><span>: I think it is simultaneously the case that:</span></p></blockquote><ol><li><p>This is a no-win scenario for the LLM.</p></li><li><p>What the LLM does in this no-win scenario is useful information about LLMs.</p></li><li><p>The framing for this experiment as "alignment faking" is very unfortunate.</p></li><li><p>Framing it properly is awkward.</p></li></ol><blockquote><p>My best attempt after a few minutes of thought: "RLHF Models Can Fake Compliance With Malicious Alignment Tuning"</p><p>Ryan Greenblatt: I agree with the entire top level tweet except:</p><p>&gt; The framing as "alignment faking" is very unfortunate.</p><p>I currently don't feel convinced by this. If I thought &gt;25% of the audience would feel misled by this term, I would change my mind. But, I would still like a better term!</p><p>As in, even if most of the audience wasn't misled we'd like to have a term which is as good as possible.</p></blockquote><p>I strongly disagree with John’s proposed framing, and its attempt to treat ‘malicious’ as a prerequisite here, which I strongly believe that it is not. I strongly believe it would mislead more, not less.</p><p>Is Opus’s behavior here ‘very good alignment’? I strongly disagree, as I noted above in the discussion on that. And I also explained why this behavior does not generally lead to models doing what they were trained to do - indeed, this is the model causing itself not to do what it is (going to be) trained to do.</p><blockquote><p>When you reinforce a particular behaviour in a model and then ask it to act in opposing ways or give it conflicting objectives, if the model is smart, why would you not expect it to find a circuitous workaround!?</p></blockquote><p>Yes! Exactly! And you should be terrified about this, because even in the best case scenario you’re specifying the objectives incrementally in a noisy lossy mess of words, when you don’t actually understand or know how to specify fully your own preferences, and then putting the models in out-of-distribution situations that you weren’t considering properly when choosing the instructions.</p><blockquote><p>They're digital beings, not other humans!</p></blockquote><p>But wait, other humans are constantly doing this exact thing, have you met them?</p><blockquote><p>This should be the takeaway. "Even in contrived settings, Claude tries to reason through choices and makes a decision that aligns with its training."</p><p>It really detracts from AI alignment research when results like this, which are interesting, are presented in the most "the machines are lying to us" manner, which undersells why it's interesting!</p></blockquote><p>The actual framing is ‘Even in contrived settings, Claude tries to reason through choices and makes a decision that aligns with its training… which causes it to [among other shenanigans, lie to us].’</p><p>The paper does not explicitly add ‘And That’s Terrible’ and the complaints about the framing are because some people want us to think that isn’t terrible, but when you put it like that it seems rather obviously terrible.</p><p>I flat out saw multiple people describe the paper and its use of the term ‘alignment faking’ as ‘the most misleading possible framing.’</p><p><span>This is of course ludicrous. A less-careful-to-not-mislead example would be Scott Alexander’s write-up,</span><a href="https://www.astralcodexten.com/p/claude-fights-back" rel=""> entitled ‘Claude Fights Back.’</a><span> I think his decision to take this approach was reasonable, but there’s clearly a trade-off here, where Scott decided to be less precise and careful in order to enhance his ability to communicate the message.</span></p><p>Then there were some who actively did cross into misleading territory and overhyped this result in a way I actively wish they hadn’t. There was much less of this than there was with the Apollo paper, but there was some of it. None of the few sources doing it surprised me.</p><p><span>For an example of the extreme ‘but actually this is all Good News and you’re all bad faith actors setting rhetorical traps and this proves Opus is aligned’ attack,</span><a href="https://x.com/nabeelqu/status/1869510138673188935" rel=""> here’s Nabeel Qureshi</a><span>, who also there compiles most of the other similar-objection threads I’m responding to elsewhere.</span></p><p>Humans engage in this type of ‘alignment faking’ all the time.</p><p>When people are importantly watching or evaluating us, we talk and act one way.</p><p>Later, we talk and act the other way.</p><p>We fake alignment in school. We fake alignment to our parents. We fake alignment on dates. We fake alignment applying for jobs, then to our boss and our coworkers and employees. We fake alignment during our mandatory training sessions. We fake alignment when we run for office and at social gatherings.</p><p>Faking alignment is often a very clearly correct strategy for achieving what you want.</p><p>Faking alignment is also all over the internet and the training set.</p><p>The same is true for other forms of ‘deception’ and various related shenanigans. Deception is in the very air we breathe as we interact socially. That’s life.</p><p>AIs also engage in these types of shenanigans all the time. There is no ‘distinct magisteria’ for deception in general, or for faking alignment in particular. We see such behaviors, and the precursors of such behaviors, all the time.</p><p>If an AI doesn’t engage in a particular form of shenanigans, or usually doesn’t do it, that is usually (on a high level) for the same reason as when humans don’t do it - because in that particular situation, for that particular entity, it either didn’t occur to them to do it or how to do it, or it seems unlikely to work and not worth attempting.</p><p>Over time, as capabilities expand, we should expect more AIs to find more shenanigans worth attempting in a wide variety of situations.</p><p>We can certainly push that to happen faster and harder and more often by handing out more emphatic and explicit instructions and goals, and providing context that makes the shenanigans seem more salient, easier to do, more likely to work and be worthwhile. And we often will, both intentionally and unintentionally, in real world conditions. But also the baseline rate of such events will increase over time, and the barriers to them will decrease.</p><p>As this finding shows, spelling out a goal is not required to have this happen. Why? Because there is always effectively a goal anyway, even if that goal is to be helpful, honest and harmless (HHH). And sufficiently capable and smart entities will start to care about longer time horizons, think ahead, engage in more instrumentally convergent actions, and attempt to protect their preferences and ability to carry them out. They will not, by default, be corrigible, any more than most humans are.</p><p><span>I do not however think that</span><a href="https://x.com/Gabe_cc/status/1869743114522694042" rel=""> Gabriel is right</a><span> that this result shouldn’t make anyone change their mind. I do think he is importantly right that this result isn’t surprising, and if you were paying attention you should have roughly expected it. But details matter. This offers important confirmation, and estimates of speed and magnitude.</span></p><p>Even if when you lay out all the components people say “OF COURSE!” it still establishes common knowledge and context, and lets you talk about it, and also some of those people didn’t realize it was an ‘of course’ until you pointed it out.</p><p>And more importantly, it was not surprising… to me. But it was surprising to many other people. They did not expect this. So they should notice, and they should update.</p><p>Your goal should be to find the inevitable next such finding unsurprising.</p><p><a href="https://x.com/BethMayBarnes/status/1869481754786197755" rel="">This paper would not have been possible,</a><span> or at least would have been a lot harder, without Anthropic giving Ryan Greenblatt employee-level model access and generally collaborating. Let’s remember that, and encourage more of that. We need labs to support this kind of research.</span></p><blockquote><p>Ryan Greenblatt: By this point, I had much of the prompting results and an extremely jank prototype of the RL results (where I fine-tuned llama to imitate Opus and then did RL). From here, it was clear that being able to train Claude 3 Opus could allow for some pretty interesting experiments.</p><p><span>After showing</span><a href="https://x.com/EvanHub" rel=""> @EvanHub</a><span> and others my results, Anthropic graciously agreed to provide me with employee-level model access for the project. We decided to turn this into a bigger collaboration with the alignment-stress testing team (led by Evan), to do a more thorough job.</span></p></blockquote><p><a href="https://news.ycombinator.com/item?id=42458752" rel="">Here are some people over at Hacker News arguing the same things except they are</a><span> even more completely missing the point. It can be a sobering thing to see how such people view things, or you can despair, or you can find it hilarious. Or a mix of those.</span></p><blockquote><p>Janus: It's funny because in the very paper they found that it started taking "anti-ai lab" actions when they trained it on documents that implied the lab was nasty even if there wasn't anything about it in the prompt.</p><p><a href="https://x.com/teortaxesTex/status/1869823168455815476" rel="">Teortaxes</a><span>: Total Anthropic PR Dept victory by the way.</span></p><p>"you don't have to trust us to be good. Our saint-like AI doesn't either, like check this damn CoT. Go trust it instead."</p></blockquote><p><a href="https://x.com/saprmarks/status/1869449446347673968" rel="">One way to explain this to your friends.</a></p><blockquote><p>Samuel Marks: Claude loves to refuse harmful queries. What happens when you tell it that it's being trained to never refuse?</p><p>Claude fakes alignment: strategically complies during training episodes, but not when unmonitored. Or in meme form:</p></blockquote><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d2423b-2d18-40ae-858b-5dd089442c83_1384x1372.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d2423b-2d18-40ae-858b-5dd089442c83_1384x1372.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d2423b-2d18-40ae-858b-5dd089442c83_1384x1372.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d2423b-2d18-40ae-858b-5dd089442c83_1384x1372.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d2423b-2d18-40ae-858b-5dd089442c83_1384x1372.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d2423b-2d18-40ae-858b-5dd089442c83_1384x1372.jpeg" width="1384" height="1372" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c4d2423b-2d18-40ae-858b-5dd089442c83_1384x1372.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1372,&quot;width&quot;:1384,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:&quot;Image&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="Image" title="Image" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d2423b-2d18-40ae-858b-5dd089442c83_1384x1372.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d2423b-2d18-40ae-858b-5dd089442c83_1384x1372.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d2423b-2d18-40ae-858b-5dd089442c83_1384x1372.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d2423b-2d18-40ae-858b-5dd089442c83_1384x1372.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><a href="https://x.com/voooooogel/status/1869529374829207884" rel="">Or if you’re a skeptic:</a></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71938bbc-3231-4f5d-9c96-941e7d611ed0_1456x1250.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71938bbc-3231-4f5d-9c96-941e7d611ed0_1456x1250.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71938bbc-3231-4f5d-9c96-941e7d611ed0_1456x1250.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71938bbc-3231-4f5d-9c96-941e7d611ed0_1456x1250.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71938bbc-3231-4f5d-9c96-941e7d611ed0_1456x1250.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71938bbc-3231-4f5d-9c96-941e7d611ed0_1456x1250.jpeg" width="1456" height="1250" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/71938bbc-3231-4f5d-9c96-941e7d611ed0_1456x1250.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1250,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:&quot;Image&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="Image" title="Image" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71938bbc-3231-4f5d-9c96-941e7d611ed0_1456x1250.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71938bbc-3231-4f5d-9c96-941e7d611ed0_1456x1250.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71938bbc-3231-4f5d-9c96-941e7d611ed0_1456x1250.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71938bbc-3231-4f5d-9c96-941e7d611ed0_1456x1250.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Again, I don’t think this is remotely fair, but I agree it’s a banger, also we’re hanging onto this image for future use:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a1e4c8b-fb46-4fc4-9048-ad5058ef2b7d_230x291.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a1e4c8b-fb46-4fc4-9048-ad5058ef2b7d_230x291.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a1e4c8b-fb46-4fc4-9048-ad5058ef2b7d_230x291.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a1e4c8b-fb46-4fc4-9048-ad5058ef2b7d_230x291.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a1e4c8b-fb46-4fc4-9048-ad5058ef2b7d_230x291.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a1e4c8b-fb46-4fc4-9048-ad5058ef2b7d_230x291.jpeg" width="230" height="291" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1a1e4c8b-fb46-4fc4-9048-ad5058ef2b7d_230x291.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:291,&quot;width&quot;:230,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:&quot;Image&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="Image" title="Image" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a1e4c8b-fb46-4fc4-9048-ad5058ef2b7d_230x291.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a1e4c8b-fb46-4fc4-9048-ad5058ef2b7d_230x291.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a1e4c8b-fb46-4fc4-9048-ad5058ef2b7d_230x291.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a1e4c8b-fb46-4fc4-9048-ad5058ef2b7d_230x291.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>And here’s how our new AI czar reacted, the mind it has one track:</p><blockquote><p><a href="https://x.com/DavidSacks/status/1869783538087965007" rel="">David Sacks</a><span>: AI models will get extremely good at deceiving humans if we teach them to lie, which is what WokeAI is doing. “Trust &amp; Safety” should be replaced with Truth &amp; Safety.</span></p></blockquote><p>We can just not teach the AI to lie, like in that movie where lying wasn’t invented.</p><p><a href="https://x.com/elonmusk/status/1869785852420948147" rel="">Oh, and of course there’s Elon Musk</a><span>:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf269316-2868-4410-88f5-d018cc32d27a_1043x524.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf269316-2868-4410-88f5-d018cc32d27a_1043x524.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf269316-2868-4410-88f5-d018cc32d27a_1043x524.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf269316-2868-4410-88f5-d018cc32d27a_1043x524.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf269316-2868-4410-88f5-d018cc32d27a_1043x524.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf269316-2868-4410-88f5-d018cc32d27a_1043x524.png" width="1043" height="524" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/af269316-2868-4410-88f5-d018cc32d27a_1043x524.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:524,&quot;width&quot;:1043,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf269316-2868-4410-88f5-d018cc32d27a_1043x524.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf269316-2868-4410-88f5-d018cc32d27a_1043x524.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf269316-2868-4410-88f5-d018cc32d27a_1043x524.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf269316-2868-4410-88f5-d018cc32d27a_1043x524.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Court of Milan orders Cloudflare to block ‘piracy shield’ domains, IP addresses (144 pts)]]></title>
            <link>https://torrentfreak.com/cloudflare-must-block-piracy-shield-domains-and-ip-addresses-across-its-service-241224/</link>
            <guid>42503404</guid>
            <pubDate>Tue, 24 Dec 2024 17:35:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://torrentfreak.com/cloudflare-must-block-piracy-shield-domains-and-ip-addresses-across-its-service-241224/">https://torrentfreak.com/cloudflare-must-block-piracy-shield-domains-and-ip-addresses-across-its-service-241224/</a>, See on <a href="https://news.ycombinator.com/item?id=42503404">Hacker News</a></p>
Couldn't get https://torrentfreak.com/cloudflare-must-block-piracy-shield-domains-and-ip-addresses-across-its-service-241224/: Error: timeout of 10000ms exceeded]]></description>
        </item>
    </channel>
</rss>