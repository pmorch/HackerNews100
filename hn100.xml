<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 21 Sep 2024 01:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Qualcomm Wants to Buy Intel (141 pts)]]></title>
            <link>https://www.theverge.com/2024/9/20/24249949/intel-qualcomm-rumor-takeover-acquisition-arm-x86</link>
            <guid>41605449</guid>
            <pubDate>Fri, 20 Sep 2024 20:57:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/9/20/24249949/intel-qualcomm-rumor-takeover-acquisition-arm-x86">https://www.theverge.com/2024/9/20/24249949/intel-qualcomm-rumor-takeover-acquisition-arm-x86</a>, See on <a href="https://news.ycombinator.com/item?id=41605449">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>On Friday afternoon, <a href="https://www.wsj.com/business/deals/qualcomm-approached-intel-about-a-takeover-in-recent-days-fa114f9d?st=i5zay9xbq899g24&amp;reflink=article_copyURL_share"><em>The Wall Street Journal</em> reported</a> Intel had been approached by fellow chip giant Qualcomm about a possible takeover. While any deal is described as “far from certain,” according to the paper’s unnamed sources, it would represent a tremendous fall for a company that had been the most valuable chip company in the world, based largely on its x86 processor technology that for years had triumphed over Qualcomm’s Arm chips outside of the phone space. </p><p>It would also be a massive coup for Qualcomm, which reentered the desktop processor market this year <a href="https://www.theverge.com/2024/6/26/24186432/microsoft-windows-on-arm-qualcomm-copilot-plus-pcs-prism-emulator">as a part of Microsoft’s AI PC strategy</a> after years of dominance in mobile processors.</p><p>Intel, meanwhile, is arguably in its weakest position in years — while many of its businesses are still profitable, the company announced substantial cuts, shifts in strategy, <a href="https://www.theverge.com/2024/8/1/24210656/intel-is-laying-off-over-10000-employees-and-will-cut-10-billion-in-costs">and a 15-plus percent downsizing of its workforce this August</a> after reporting a $1.6 billion loss. </p><p>At the time, Intel CEO Pat Gelsinger said the company would stop all nonessential work and has since announced <a href="https://www.theverge.com/2024/9/16/24246599/intel-foundry-independent-spinoff">it will spin off its chipmaking business</a>, a part of the company that it had long touted as a strength over rival AMD and the many fabless chipmakers that rely on entities like Taiwan’s TSMC to produce all of their actual silicon. </p><p>Intel, too, recently had to partially rely on TSMC to produce its most cutting-edge chips as it continues to rebuild its own manufacturing efforts (<a href="https://www.theverge.com/2024/4/2/24119454/intels-chipmaking-business-7-billion-loss">the costs of which</a> are responsible for most of Intel’s recent losses). And its own 18A manufacturing process <a href="https://www.theverge.com/2024/9/4/24235682/intel-18a-chipmaking-process-broadcom-test">reportedly ran into some recent trouble</a>.</p><p>While Intel’s chief rival, AMD, also had hard times over the years and had to claw its way back, gamers helped AMD every step of the way. Aside from the Nintendo Switch, whose processors are made by Nvidia, every major game console for the last decade has featured an AMD chip — and Intel <a href="https://www.theverge.com/2024/9/16/24246234/playstation-6-rumor-sony-intel-amd">reportedly lost out on a chance to change that with the future PlayStation 6</a>. </p><div><p>Intel also recently lost some faith with PC gamers after <a href="https://www.theverge.com/24216305/intel-13th-14th-gen-raptor-lake-cpu-crash-news-updates-patches-fixes-motherboards">two generations of its flagship chips were found vulnerable to strange crashes</a>, though Intel has since agreed to extend the warranties by multiple years and issued updates that could prevent damage.</p></div><p>Many of Intel’s woes are about silicon leadership, not just manufacturing or profits — the company isn’t a big player in AI server chips yet <a href="https://www.theverge.com/2024/2/1/24058186/ai-chips-meta-microsoft-google-nvidia">as Nvidia dominates</a>, nor even necessarily <a href="https://www.theverge.com/2024/7/30/24209938/amd-q2-2024-earnings-datacenter-ai-revenue">a notable small one like AMD</a>. Even its attempts to produce its own GPUs for gamers and creators <a href="https://www.theverge.com/2023/3/21/23650611/intel-raja-koduri-gpus-amd-nvidia-apple-leave-ai-startup">have yet to impress</a>.</p><p>And while Qualcomm, AMD, and Apple are all still smaller players in laptops, Intel has now <a href="https://www.theverge.com/2024/6/3/24169115/intel-lunar-lake-architecture-platform-feature-reveal">twice overhauled how it makes flagship laptop chips</a> to combat the growing threat of their seeming battery life and integrated graphics advantages. We’re waiting to see if its <a href="https://www.theverge.com/2024/9/3/24233957/intel-lunar-lake-core-ultra-200v-launch">new Lunar Lake chips</a> succeed in October and beyond.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Discord Reduced WebSocket Traffic by 40% (140 pts)]]></title>
            <link>https://discord.com/blog/how-discord-reduced-websocket-traffic-by-40-percent</link>
            <guid>41604267</guid>
            <pubDate>Fri, 20 Sep 2024 18:09:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://discord.com/blog/how-discord-reduced-websocket-traffic-by-40-percent">https://discord.com/blog/how-discord-reduced-websocket-traffic-by-40-percent</a>, See on <a href="https://news.ycombinator.com/item?id=41604267">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="heading-1"><p>At Discord, we’re always thinking about ways to improve our services and increase performance. After all, the faster our app gets, the sooner you can return to your friends and conversations!&nbsp;&nbsp;&nbsp;</p><p>Over the last six months, we embarked on a quest to support this endeavor, working to reduce the amount of bandwidth our clients use, especially on iOS and Android, hoping that decreasing bandwidth usage would lead to a more responsive experience.</p><h2>Background</h2><p>When your client connects to Discord, it receives real-time updates about what’s happening through a service that we call the “gateway.” Since late 2017, the client’s gateway connection has been compressed using zlib, making messages anywhere from 2 to 10 times smaller.</p><p>Since then, <a href="https://facebook.github.io/zstd/">zstandard</a> (originally released in 2015) has gained enough traction to become a viable replacement for zlib. Zstandard offers higher compression ratios and shorter compression times and supports <a href="https://github.com/facebook/zstd#dictionary-compression-how-to">dictionaries</a>: a way to preemptively exchange information about compressed content, further increasing compression ratios and reducing the overall bandwidth usage.</p><p>We attempted to use zstandard in the past, but, at the time, the benefits weren’t worth the costs. Our testing in 2019 was desktop-only and used too much RAM. However, a lot can happen in five years! We wanted to give it another try, and the support for dictionaries appealed to us, especially as most of our gateway payloads are small and in a well-defined shape.</p><p>We believed the predictability of these payloads would be a perfect application of dictionaries to further reduce bandwidth usage.</p></div><div id="heading-2"><p>Armed with this knowledge, we put on our lab coats, slapped on our goggles, and started experimenting. On paper, we thought zstandard would be better than zlib but we wanted to validate this theory against our current workload.</p><p>We opted to do a “dark launch” of plain zstandard: the plan was to compress a small percentage of production traffic both with zlib and zstandard, collect a bunch of metrics, then discard the zstandard data. This allowed us to experiment with zstandard to quickly compare its results against zlib. Without this experiment, we would have to add zstandard support for our clients — desktop, iOS, and Android — which would require about a month’s lead time before we could fully determine the effects of zstandard. We didn’t know how well zstandard would perform and didn’t want to wait a whole month, but a dark launch allowed us to iterate over days as opposed to weeks.</p><p>Once we got our experiment set up and deployed onto our gateway cluster, we set up a dashboard to see how zstandard performed. We flipped the switch to start sending a teeeeeny bit of traffic through the dark launch code, and the initial results appeared to be… underwhelming. Zstandard was performing <em>worse</em> than zlib was.</p><figure><p><img src="https://cdn.prod.website-files.com/5f9072399b2640f14d6a2bf4/66eb5caa61ad96d1a395f51d_AD_4nXeCYg9XJmJM9EPtYhMpoXSrE89c5FHDpTPo-_g1CsEEAhiib-D8EUGRZlxPL9CDWw0hmSeRVdGLCJPqkwdIpt5oi80KsHQL5bxIJfOJ3dC76sFgSpj8Lh4f6lqEfsZXpdpywTPUdoEFsRo6WIPHiLyQMmt9.png" loading="lazy" alt="A compression ratio chart for Zstandard. The chart reads: “User Guild Settings Update: 12.26. Guild Emojis Update: 7.35. Ready Supplemental: 7.04. Thread Member List Update: 6.88.”"></p><figcaption>Zstandard compression ratio</figcaption></figure><figure><p><img src="https://cdn.prod.website-files.com/5f9072399b2640f14d6a2bf4/66eb5d5aa15a87d53673cd47_AD_4nXdmCN0zlF9hxaVHFEwrEkJO5kEqsRq92ig73v31W-8gg9_yRUAryJqJC3jWGCzy3vJ_F1OvvUj9AQXwaYORhAmLoij9PWsswGH9-zagbN2AxVeG7Xs6fC0LEnZpCWZ5VjiTudVionBiCAhSz21suEQaNn0.png" loading="lazy" alt="A compression ratio chart for Zlib. The chart reads: “User Guild Settings Update: 13.95. Guild Member List Update: 9.86. Auto Moderation Action: 9.56. Voice Channel Effect Send: 9.27.” "></p><figcaption>Zlib compression ratio</figcaption></figure><p>To compare the performance of these two compression algorithms, we used their “compression ratio.” The compression ratio is measured by taking the uncompressed size of the payload and dividing it by the compressed size — a larger number is better.</p><p>Looking at the images above, which measure the compression ratio for the various dispatch types (<a href="https://discord.com/developers/docs/topics/opcodes-and-status-codes#gateway-gateway-opcodes">op 0</a>), with zlib, <strong>user_guild_settings_update</strong> has a compression ratio of 13.95 while with zstandard it has a compression ratio of 12.26.&nbsp;</p><p>The graph below further illustrates that zstandard performed worse than zlib: the average size of a <strong>MESSAGE_CREATE</strong> payload compressed with zlib was around 250 bytes, while with zstandard, the same payload was over 750!</p><figure><p><img src="https://cdn.prod.website-files.com/5f9072399b2640f14d6a2bf4/66eb5d81a15a87d53673ff18_AD_4nXc_N1o4Qmj70b_Oh8Oh9xlMRZNw2hTyEkkFy8_hzYeDBJ-S99ejgt9MPkNp6kgVPoT_YX-NV-hMKMNFgSlOr1nerXGqpN_HCc3JvKoH86TMaM4II92Mw_NhbTVkCMy5g85ka153WCZ7-QHmsrEJ7j3mNqD8.png" loading="lazy" alt="A bar chart comparing compression methods to payload sizes. Zlib lands at just over 250 bytes, while zstandard reaches over 750 bytes."></p></figure><p>The same trend was observed for most other dispatches: zstandard was not outperforming zlib like we thought it would. What’s going on here?</p></div><div id="heading-3"><h2>Streaming Zstandard<br></h2><p>It turns out that one of the key differences between our zlib and zstandard implementations was that zlib was using streaming compression, while zstandard wasn’t.&nbsp;</p><p>As mentioned previously, most of our payloads are comparatively very small, only a few hundred bytes at most, which doesn’t give zstandard much historical context to work with to further optimize how it compresses future payloads. With streaming compression, the zlib stream is spun up when the connection is opened and exists until the websocket is closed. Instead of having to start fresh for every websocket message, zlib can draw on its knowledge of previously compressed data to inform its decisions on how to process fresh data. This ultimately leads to smaller payload sizes.</p><p>The question then became: “could we get zstandard to do this?” The answer to that was… “sorta.” Our gateway service is written in elixir, and while zstandard supports <a href="https://facebook.github.io/zstd/zstd_manual.html#Chapter7">streaming compression</a>, the various zstandard bindings for elixir/erlang we looked at didn’t.&nbsp;</p><p>We ultimately settled on using <a href="https://github.com/silviucpp/ezstd">ezstd</a> as it had dictionary support (more on that later).While it didn’t support streaming at the time,in the spirit of open source we forked ezstd to add support for streaming, which we later <a href="https://github.com/silviucpp/ezstd/pull/15">contributed back upstream</a>.</p><p>We then repeated the dark launch experiment, but with zstandard streaming and got the following results:</p><figure><p><img src="https://cdn.prod.website-files.com/5f9072399b2640f14d6a2bf4/66eb68683aeb8f2ee1063854_AD_4nXfRJh2JKRqLoQC5EiZuN5E8wmWEr5yAZGx07y5u_eTvqMYlzOVTTmdggzgp8-hJNWSlPklg7zjMyccyIaZkWF45AGSjvvmlhk-kzDIgaG004-6R_Ow_WnEuIbZHLvXes5AzunAPS9Jo0iA8MrZyD_vVHZ4.png" loading="lazy" alt=""></p><figcaption><strong>Message Create Compression Ratios</strong></figcaption></figure><p>‍</p><figure><p><img src="https://cdn.prod.website-files.com/5f9072399b2640f14d6a2bf4/66eb5dc8045b706867911f67_AD_4nXc5poqnDTStFq1yAQdxKYlNM76Ikyol_-1Erb2E7IQK-MozKtL7u3BFjtSlkP9-RTZNzQFZFoP1Uxpq7PB4oNDRoc3mv0cxVvk4roDqtroLtGDfstiAsyVy_i6W4TSLCHH6JMu8QvJWoYRc7Y5UrDOMQo0.png" loading="lazy" alt="A bar chart comparing payload sizes of  Zlib streaming, zstandard, and zstandard streaming. Zlib streaming payloads are over 250 bytes, while zstandard hits over 750 bytes. Zstandard streaming payloads land at under 250 bytes."></p></figure><p>As the above data illustrates, zstandard streaming increased the compression ratio from 6 to almost 10 and dropped the payload size from 270 bytes to 166.</p><p>This trend held true for most of the other dispatches: zstandard streaming significantly outperforms zlib both in time to compress and compression ratio.</p><figure><p><img src="https://cdn.prod.website-files.com/5f9072399b2640f14d6a2bf4/66eb5dfe1481af30f65a3830_AD_4nXdEg8Tp2r5wYGbJoYw-s0ezvLu8cc6JMntlFtBC1k8MmK4Nh1cQ29yItE62RM1VSVCa9N663_OGdmYBAwmJfVxMlEvX0Vjr0t8H6Kucg3LgSrjaUvyRo_Wyw3vebN1ui4-wIOSVRGte9IAKysiZxdiLFwrI.png" loading="lazy" alt="A chart comparing MESSAGE_CREATE times between zlib streaming and zstandard streaming. Zlib streaming takes just over 100 microseconds, while zstandard streaming lands at under 50 microseconds."></p></figure><p>Looking once again at <strong>MESSAGE_CREATE</strong>, the compression time per byte of data is significantly lower for zstandard streaming than zlib, with zlib taking around 100 microseconds per byte and zstandard taking 45 microseconds.</p></div><div id="heading-4"><h2>Pushing Further</h2><p>While our initial experimentation proved that zstandard streaming outperformed zlib streaming, the remaining question we had was: “How far can we push this?” Our initial experiments used the default settings for zstandard and we wanted to know how high we could push our compression ratio by playing around with the compression settings.</p><p>So how far did we get?</p><h3>Tuning</h3><p>Zstandard is highly configurable and enables us to tweak various compression parameters. We focused our efforts on three parameters that we thought would have the biggest impact on compression: chainlog, hashlog, and windowlog. These parameters offer trade-offs between compression speed, memory usage, and compression ratio. For example, increasing the value of the chainlog generally improves the compression ratio, but at the cost of increasing memory usage and compression time.</p><p>We also wanted to ensure that with the settings we decided on, the compression contexts would still fit in memory on our hosts. While it’s simple to add more hosts to soak up the extra memory usage, extra hosts cost money and at some point, provide diminishing returns on the gains.</p><p>We settled on an overall compression level of 6, a chainlog and hashlog of 16, and a windowlog of 18. These numbers are slightly above <a href="https://github.com/facebook/zstd/blob/a761013b0390892e8728fc45171f831cf23c3792/lib/compress/clevels.h#L25">the default settings that you can see here</a> and would comfortably fit in the memory of a gateway node.</p><h3>Zstandard Dictionaries</h3><p>Additionally, we wanted to investigate if we could take advantage of zstandard’s dictionary support to compress data even further. By pre-seeding zstandard with some information, it can more efficiently compress the first few kilobytes of data.&nbsp;</p><p>However, doing this adds additional complexity as both the compressor (in this case, a gateway node) and the decompressor (a Discord client) need to have the same copy of the dictionary to communicate with each other successfully.</p><p>To generate a dictionary to use, we needed data… <em>and a lot of it</em>. Zstandard has a built-in way to generate dictionaries (<em>zstd --train</em>) from a sample of data, so we just had to collect a whooole buncha samples.&nbsp;</p><p>Notably, the gateway supports two encoding methods for payloads: JSON and <a href="https://www.erlang.org/doc/apps/erts/erl_ext_dist.html">ETF</a>, and a JSON dictionary wouldn’t perform as well on ETF (and vice versa) so we had to generate two dictionaries: one for each encoding method.</p><p>Since dictionaries contain portions of the training data and we’d have to ship the dictionaries to our clients, we needed to ensure that the samples we would generate the dictionaries from were free of any personally-identifiable user data. We collected data involving 120,000 messages, split them by ETF and JSON encoding, anonymized them, and then generated our dictionaries.</p><p>Once our dictionaries were built, we could use our gathered data to quickly evaluate and iterate on its efficacy without needing to deploy our gateway cluster.</p><p>The first payload we tried compressing was “READY.” As one of the first (and largest) payloads sent to the user, READY contains most of the information about the connecting user, such as guild membership, settings, and read states (What channels should be marked as read/unread). We compressed a single READY payload of 2,517,725 bytes down to 306,745 using the default zstandard settings which established a baseline. Utilizing the dictionary we just trained, the same payload was compressed down to 306,098 bytes – a gain of around 600 bytes.</p><p>Initially, these results seemed discouraging, but we next tried compressing a smaller payload, called TYPING_START, sent to the client so it can show the “XXX is typing…” notification. In this situation, a 636 byte payload compresses down to 466 bytes without the dictionary and 187 bytes with the dictionary. We saw much better results with our dictionaries against smaller payloads simply due to how zstandard operates.&nbsp;</p><p>Most compression algorithms “learn” from data that has already been compressed, but with small payloads, there isn’t any data for it to learn from. By preemptively informing zstandard what the payload is going to look like, it can make a more informed decision on how to compress the first few kilobytes of data before its buffers have been fully populated.</p><p>Satisfied with these findings, we deployed dictionary support to our gateway cluster and started experimenting with it. Utilizing the dark launch framework, we compared zstandard to zstandard with dictionaries.</p><p>Our production testing yielded the following results:</p><figure><p><img src="https://cdn.prod.website-files.com/5f9072399b2640f14d6a2bf4/66eb5f2170b2edf1b422de56_AD_4nXfFOonNWIBnci1c-cNsmJKSC5uTEVj23McFJu-0dXGzFsoaZIyLciEpiqwJC_KSr2QP5U0nEEsba_AcriUbIcATZqRqYz7GN3qjn_UcU9QiR2TDIH_FiaANBNDnWgu3HlwgX83yHxNf3eE-Dzz1DMfWA3sd.png" loading="lazy" alt="A small chart comparing payload compression ratios of zstandard, with and without dictionaries. With dictionaries, the payload compression ratio is 6.63. Without dictionaries, the compression ratio is 6.4."></p><figcaption><strong>Ready Payload Size</strong></figcaption></figure><p>We specifically looked at the READY payload size as it’s one of the first messages sent over the websocket and would be most likely to benefit from a dictionary. As shown in the table above, the compression gains were minimal for READY, so we looked at the results for more dispatch types hoping dictionaries would give more of an edge for smaller payloads.&nbsp;</p><p>Unfortunately, the results were a bit mixed. For example, looking at the message create payload size that we’ve been comparing throughout this post, we can see that the dictionary actually made things worse.</p><p>‍</p><figure><p><img src="https://cdn.prod.website-files.com/5f9072399b2640f14d6a2bf4/66eb5f49c09e80a03e4614c5_AD_4nXeZGwfQPGKphBAcy3Wpc2HH20FpO3wZ2Os9w7VC6adtmZTDnLH0B8MEAUPO1UoQhj9RlEdQL9czlCKW15PVC1El6hkXy52Rcx8TNzNsPJAWKvN7o7wYjwyFxj5aMyob27AOTmBjN20ZdcusTgc7FNJxt96s.png" loading="lazy" alt="A chart comparing MESSAGE_CREATE payload sizes between Zlib streaming, Zstandard, Zstandard streaming, and Zstandard Streaming Plus Dictionary. Zlib streaming’s payload is just over 250 byes and zstandard is over 750 bytes. The newest entries, Zstandard Streaming and Zstandard Streaming Plus Dictionary are both under 250 byes, but Zstandard Streaming without Dictionary has a slightly smaller file size."></p></figure><p>Ultimately, we decided not to continue with our dictionary experiments. The slightly improved compression dictionaries would provide was outweighed by the additional complexity they would add to our gateway service and clients. Data is a big driver of engineering at Discord, and the data speaks for itself: it wasn’t worth investing more effort into.</p><h3>Buffer Upgrading</h3><p>Finally, we explored increasing zstandard buffers during off-peak hours. Discord’s traffic follows a diurnal pattern, and the memory we need to handle peak demand is significantly more than what’s needed during the rest of the day.&nbsp;</p><p>On the surface, autoscaling our gateway cluster would prevent us from wasting compute resources during off-peak hours. However, due to the nature of gateway connections being long-lived, traditional autoscaling methods don’t work well for our workload. As such, we have a lot of extra memory and compute during off-peak hours. Having all this extra compute laying around raised the question: Could we take advantage of these resources to offer greater compression?</p><p>To figure this out, we built a feedback loop into the gateway cluster. This loop would run on each gateway node and monitor the memory usage by the clients connected to it. It would then determine a percentage of new connecting clients that should have their zstandard buffer upgraded. An upgraded buffer increases the windowlog, hashlog, and chainlog values by one, and since these parameters are expressed as a power of two, increasing these values by one will roughly double the amount of memory usage the buffer uses.</p><p>After deploying and letting the feedback loop run for a bit, the results weren’t as good as we had initially hoped. As illustrated by the graph below, over a 24 hour period, our gateway nodes had a relatively low upgrade ratio (Up to 30%), and was significantly less than we anticipated: around 70%.</p><figure><p><img src="https://cdn.prod.website-files.com/5f9072399b2640f14d6a2bf4/66eb5f89a5aa109682aa20c0_AD_4nXdu2egSUa4dMnBCuvHFxPFrrxdROCyeqCAs8AP95O-jHEYcKx5jUXDsiuw7bCAmXiDM9g9ewrch5e4i7TQMQi7CpaYvBVsJr_bKMTbU9KiDMOjsMC9V1wDnEK6YH-Ksox9c8oZf5e-Jdh1AtumuemXMKtI.png" loading="lazy" alt="A graph showing the upgrade ratio for each gateway host over a 24 hour period. From 00:00 to 03:00, the lines are distributed between 0 and 0.2 peaking at 00:00 and tapering off. From 03:00 to 18:00 there are no lines. From 18:00 to 23:59 the lines are distributed between 0 and 0.2 peaking around 22:00"></p></figure><p>After doing a bit of digging, we discovered that one of the primary issues that was causing the feedback loop to behave sub-optimally was memory fragmentation: the feedback loop looked at real system memory usage, but BEAM was allocating significantly more memory from the system than was needed to handle the connected clients. This caused the feedback loop to think that it had less memory to work with than was available.</p><p>To try and mitigate this, we did a little experimentation to tweak the BEAM allocator settings — more specifically, the <em>driver_alloc</em> allocator, which is responsible for (<em>shockingly</em>) driver data allocations. The bulk of the memory used by a gateway process is the zstandard streaming context, which is implemented in C using a <a href="https://www.erlang.org/doc/system/nif.html">NIF</a>. NIF memory usage is allocated by <em>driver_alloc. </em>Our hypothesis was that if we could tweak the <em>driver_alloc</em> allocator to more effectively allocate or free memory for our zstandard contexts, we’d be able to decrease fragmentation and increase upgrade ratio overall.</p><p>However, after messing around with the allocator settings for a little bit, we decided to revert the feedback loop. While we probably would have eventually found the right allocator settings to dial in, the amount of effort needed to tweak the allocators combined with the overall additional complexity that this introduced into the gateway cluster outweighed any gains that we would’ve seen if this was successful.</p><h3>Implementation and Rollout</h3><p>While the original plan was to only consider zstandard for mobile users, the bandwidth improvements were significant enough for us to ship to desktop users as well! Since zstandard ships as a C library, it was simply a matter of finding bindings in the target language —Java for Android, Objective C for iOS, and Rust for Desktop — and hooking them into each client. Implementation was straightforward for Java (<a href="https://github.com/luben/zstd-jni/">zstd-jni</a>) and Desktop (<a href="https://crates.io/crates/zstd-safe">zstd-safe</a>), as bindings already existed, however for iOS, we had to write our own bindings.</p><p>This was a risky change with the potential to render Discord completely unusable if things were to go wrong, so the rollout was gated behind an experiment. This experiment served three purposes: allow the quick rollback of these changes if things were to go wrong, validate the results we saw in the “lab,” and enable us to gauge if this change was negatively affecting any baseline metrics.</p><p>Over the course of a few months, we were able to successfully roll out zstandard to all of our users on all platforms.</p></div><div id="heading-5"><h2>Another Win: Passive Sessions V2<br></h2><p>While this next part isn’t directly related to the zstandard work, the metrics that guided us during the dark launch phase of this project revealed a surprising behavior. Looking at the actual size of dispatches that were sent to the client, passive_update_v1 stood out. This dispatch consisted of over 30% of our gateway traffic while the actual number of dispatches sent were comparatively small–around 2%.</p><figure><p><img src="https://cdn.prod.website-files.com/5f9072399b2640f14d6a2bf4/66eb5fe0f048cb0591c16080_AD_4nXf-UwN9XBhbGiKeqVukeCH4gYs4jn2JZM7jEY_vzWGncfyKL9QJiQJgnm4bXQvPpNXzD4cCObgJjyH3KoPFwDnYYfPQEQbvvZAqiSYa9qkH7ykVYJCw7IFYZHtKKDkABq07Px_J2gMmX6ejg6ucUS_IWxFU.png" loading="lazy" alt="A pie chart with multiple sections. Of over a dozen sections, the ones that are pointed out are: Passive Update V1: 35.61%, Message Create: 20.04%, Ready: 11.66%, Guild Member List Update: 8.5%, Presence Update: 2.67%."></p></figure><p>We employ passive sessions to avoid sending most messages that a server generates to clients that may not even open the server. For example, a Discord server could be very active sending thousands of messages per minute, but if a user isn’t actually reading those messages, it doesn’t make sense to send them and waste their bandwidth. Once you tab into the server, a passive session will be “upgraded” into a normal session and receive the full firehose of dispatches from that guild.</p><p>However, passive sessions still need to be periodically sent a limited amount of information, which is the purpose of PASSIVE_UPDATE_V1. Periodically, all passive sessions will receive an update with a list of channels, members, and members in voice so your client can still be kept in sync with the server.</p><p>Diving into the actual contents of one of those PASSIVE_UPDATE_V1 dispatches, we would send <em>all</em> of the channels, members, or members in voice, even if only a single element changed. Passive sessions were implemented as a means to scale Discord servers to hundreds of thousands of users and it worked well at the time. </p><p>However as we’ve <a href="https://discord.com/blog/maxjourney-pushing-discords-limits-with-a-million-plus-online-users-in-a-single-server">continued to scale</a>, sending these snapshots which consist of mostly redundant data was no longer sufficient. To fix this, we introduced a new dispatch that only sends the delta of what’s changed since the last update. This dispatch, aptly named PASSIVE_UPDATE_V2, significantly reduced the overall bandwidth from 35% of the gateway’s bandwidth to 5%, equating to a 20% reduction cluster-wide.</p><figure><p><img src="https://cdn.prod.website-files.com/5f9072399b2640f14d6a2bf4/66eb602c922d2dd61dbb8ad2_AD_4nXf8mgenY8u6qMaex3kvnEvd2xZty8fNW7sc139x4hEnnF8kQpJyKCzM3dpl5XULIRjgrBqljIb1ti3FBua6dxP3_4C2YKS8bEwYGsI6ofgRZ0xAALjFDgh-tXRxgL_JoVOzQ6StLLkCzYdtmW6UJHImxEwa.png" loading="lazy" alt="An additional pie chart with multiple sections. The sections that are pointed out are: Message Create: 28.31%, Reader: 21.86%, Guild Member List Update: 10.17%, Passive Update V2: 4.73%/4.7%. Voice State Update: 3.68%, and Guild Update: 1.01%. "></p></figure><p>‍</p><p>‍</p></div><div id="heading-6"><h2>B I G Savings</h2><p>Through the combined effects of Passive Sessions v2 and zstandard, we were able to reduce the gateway bandwidth used by our clients by almost 40%. That’s a LOT of data!&nbsp;</p><p>‍</p><figure><p><img src="https://cdn.prod.website-files.com/5f9072399b2640f14d6a2bf4/66eb605a048df7ca5e92d7cf_AD_4nXesiM1r_vEP3jlBiL4A0FryF6xUh8bKLxem8z-HObi-aFHRbQ2TlhJ-Rys4HScOw8_RsQhkx-w3uLE39WVR-_JXfHcoPVHFv4gmdFMwUWpT9Evhn2bPHqlQjh_r2bSRM1xez4cYHjMHw96IlH8MhDZ7VKzl.png" loading="lazy" alt="A graph of the outgoing bandwidth on the gateway cluster showing dates from January 2024, to April 2024. The line on the chart moves up and down diurnally up until April 18, which is demarcated with a red line labeled “zstandard”. The line then trends downwards until around May 30, 2024 also demarcated with a red line labeled “Passive Sessions v2.” The line levels oout after this, significantly lower than where it started."></p></figure><p>The chart shows the relative outgoing bandwidth of the gateway cluster from January 1 2024 to August 12, 2024, with the two demarcations being the zstandard rollout in April, followed by passive sessions v2 in late May.</p><p>While the passive sessions optimization was an unintended side-effect of the zstandard experimentation, it shows that with the right instrumentation and by looking at graphs with a critical eye, big savings can be achieved with a reasonable amount of effort.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Docker Desktop Alternative (245 pts)]]></title>
            <link>https://container-desktop.com/</link>
            <guid>41604262</guid>
            <pubDate>Fri, 20 Sep 2024 18:08:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://container-desktop.com/">https://container-desktop.com/</a>, See on <a href="https://news.ycombinator.com/item?id=41604262">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <div>
      <div>
        <h2>Cross-platform desktop integrated application with consistent UI</h2>
        <p>Container Desktop works on Windows, Mac and Linux providing the same graphical interface.</p>
      </div>
      <div>
        <h2>Learning tool for the powerful <span>podman</span> command line interface</h2>
        <p>Container Desktop is great for skills improvement and learning features of 'podman'.</p>
      </div>
    </div>
    <div>
      <h2>Essentials at your fingertips</h2>
      <p>
        The dashboard offers just the essential features so that the users can feel right at home.
        <br>
        See below what you can manage with Container Desktop.
      </p>
      <video controls="" poster="https://container-desktop.com/videos/demo.png" width="100%" autoplay="">
        <source src="https://container-desktop.com/videos/demo.mp4" type="video/mp4">
      </video>
    </div>

    <div>
      <p><img src="https://container-desktop.com/img/000-CrossPlatform.png">
      </p>
      <div>
        <h2>Cross Platform</h2>
        <ul>
          <li>Application looks the same everywhere, no mental mapping!</li>
          <li>Completely informs its users of where it stores logs and settings.</li>
          <li>Allows users to debug and understand what is happening behind the scenes.</li>
        </ul>
      </div>
    </div>

    <div>
      <div>
        <h2>Multiple engines</h2>
        <ul>
          <li>Fast native on <strong>Linux</strong> only</li>
          <li>Virtualized for any OS</li>
          <li>LIMA for MacOS</li>
          <li>WSL for Windows</li>
          <li>Both <strong>podman</strong> and <strong>docker</strong> engines</li>
          <li>Others are planned</li>
        </ul>
      </div>
      <p><img src="https://container-desktop.com/img/ConnectionManager.png">
      </p>
    </div>

    <div>
      <p><img src="https://container-desktop.com/img/PodmanContainers.png">
      </p>
      <div>
        <h2>Containers</h2>
        <ul>
          <li>Be informed about the origin and status of your container environment.</li>
          <li>Quickly access logs, environment variables, mounts, opened ports and monitoring stats.</li>
          <li>Perform common maintenance operations, stop, restart and remove easily.</li>
          <li>Direct access to the exposed services using your browser.</li>
          <li>Gain control of all that happens in the container using the terminal console.</li>
        </ul>
      </div>
    </div>

    <div>
      <div>
        <h2>Images</h2>
        <ul>
          <li>Be informed about the origin and status of local image store, their registry, name and tag.</li>
          <li>Immediately spawn new containers from image, customize name, port mappings and available mounts.</li>
          <li>Quickly access image build-up, check their impact and debug their setup.</li>
          <li>In-depth configuration viewer.</li>
          <li>
            Perform common maintenance operations, pull latest updates to refresh the images, push latest changes to a
            distributed image project.
          </li>
        </ul>
      </div>
      <p><img src="https://container-desktop.com/img/006-ImageActions.png">
      </p>
    </div>

    <div>
      <p><img src="https://container-desktop.com/img/ImageSecurity.png">
      </p>
      <div>
        <h2>Security</h2>
        <ul>
          <li>In-depth awareness of security checks</li>
          <li>Be informed of know vulnerabilities</li>
          <li>Helps creating and maintaining secure systems</li>
        </ul>
      </div>
    </div>

    <div>
      <div>
        <h2>Networks</h2>
        <ul>
          <li>Create and reuse networks at any moment.</li>
          <li>Know detailed setup of each network</li>
        </ul>
      </div>
      <p><img src="https://container-desktop.com/img/NetworkCreate.png">
      </p>
    </div>

    <div>
      <p><img src="https://container-desktop.com/img/PodmanPods.png">
      </p>
      <div>
        <h2>Pods</h2>
        <ul>
          <li>Full power of pods on supported engines</li>
          <li>Access logs, processes and details.</li>
          <li>Generate kube and perform common actions</li>
        </ul>
      </div>
    </div>

    <div>
      <div>
        <h2>Machines</h2>
        <ul>
          <li>Manage all available podman virtual machines, create new ones or decommission what is redundant.</li>
        </ul>
      </div>
      <p><img src="https://container-desktop.com/img/011-MachineTerminal.png">
      </p>
    </div>

    <div>
      <p><img src="https://container-desktop.com/img/013-SecretsInspect.png">
      </p>
      <div>
        <h2>Secrets</h2>
        <p>Be aware of all available secrets, define new ones or purge old from existence.</p>
      </div>
    </div>

    <div>
      <div>
        <h2>Volumes</h2>
        <p>Manage shared volumes across containers, limit repetition and also be portable.</p>
      </div>
      <p><img src="https://container-desktop.com/img/015-VolumeActions.png">
      </p>
    </div>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Inngest 1.0 – Open-source durable workflows on every platform (115 pts)]]></title>
            <link>https://www.inngest.com/</link>
            <guid>41604042</guid>
            <pubDate>Fri, 20 Sep 2024 17:33:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.inngest.com/">https://www.inngest.com/</a>, See on <a href="https://news.ycombinator.com/item?id=41604042">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><header><p>Inngest's durable functions replace queues, state management, and scheduling to enable any developer to write reliable step functions faster without touching infrastructure.</p></header><p><img alt="Screenshot of Inngest's dashboard" loading="lazy" width="1530" height="840" decoding="async" data-nimg="1" srcset="https://www.inngest.com/_next/image?url=%2Fassets%2Fhomepage%2Fhero%2F2024-08-function-dashboard.png&amp;w=1920&amp;q=75 1x, https://www.inngest.com/_next/image?url=%2Fassets%2Fhomepage%2Fhero%2F2024-08-function-dashboard.png&amp;w=3840&amp;q=75 2x" src="https://www.inngest.com/_next/image?url=%2Fassets%2Fhomepage%2Fhero%2F2024-08-function-dashboard.png&amp;w=3840&amp;q=75"></p></div><div><div><p>Powerful SDKs</p><h2>Simple APIs for reliable software</h2><p>Drop our SDK into your existing codebase to add durable execution via step functions in seconds. No queues, workers, or additional state management required.</p></div><div><div><p>Flexible enough for all use cases, powerful enough for advanced requirements.</p><div><div><h3>Run on serverless, servers, or both.</h3><p>Deploy your Inngest functions to your existing platform or infra. Inngest securely invokes your jobs wherever the code runs.</p></div><div><h3>Multi-tenant concurrency, throttle, debounce, priority, and more.</h3><p>Control exactly how your functions are run with built-in flow control. Forget about queues, workers, and customer logic.</p></div><div><h3>Batching, fan-out, and scheduling</h3><p>Essentials for any type of job or workflow creation.</p></div></div></div><div><pre><code><span>export</span><span> </span><span>const</span><span> processVideo = inngest.createFunction(
</span><span>  { </span><span>id</span><span>: </span><span>"process-video"</span><span>,
</span><span>    </span><span>concurrency</span><span>: { </span><span>limit</span><span>: </span><span>5</span><span>, </span><span>key</span><span>: </span><span>"event.data.userId"</span><span> } },
</span><span>  { </span><span>event</span><span>: </span><span>"video/uploaded"</span><span> },
</span><span>  </span><span>async</span><span> ({ event, step }) =&gt; {
</span>
<span>    </span><span>// step.run is a code-level transaction:  it retries automatically</span><span>
</span><span>    </span><span>// on failure and only runs once on success.</span><span>
</span><span>    </span><span>const</span><span> transcript = </span><span>await</span><span> step.run(</span><span>'transcribe-video'</span><span>,
</span><span>      </span><span>async</span><span> () =&gt; deepgram.transcribe(event.data.videoUrl)
</span>    )
<!-- -->
<span>    </span><span>// function state is automatically managed for fault tolerance</span><span>
</span><span>    </span><span>// across steps.</span><span>
</span><span>    </span><span>const</span><span> summary = </span><span>await</span><span> step.run(</span><span>'summarize-transcript'</span><span>,
</span><span>      </span><span>async</span><span> () =&gt; llm.createCompletion({
</span><span>        </span><span>model</span><span>: </span><span>"gpt-4o"</span><span>,
</span><span>        </span><span>prompt</span><span>: createSummaryPrompt(transcript),
</span>      })
<!-- -->    )
<!-- -->
<span>    </span><span>// easily chain a series of calls without managing infrastructure.</span><span>
</span><span>    </span><span>await</span><span> step.run(</span><span>'write-to-db'</span><span>,
</span><span>      </span><span>async</span><span> () =&gt; db.videoSummaries.upsert({
</span><span>        </span><span>videoId</span><span>: event.data.videoId,
</span>        transcript,
<!-- -->        summary,
<!-- -->      })
<!-- -->    )
<!-- -->  }
<!-- -->);</code></pre></div></div></div><div><div><p>Write functions in any language.</p></div><div><p>Functions run on your own infrastructure: serverless, servers, or edge.</p></div></div><div><blockquote><p>I wanted to find a solution that would let us just write the code, not manage the infrastructure around queues, concurrency, retries, error handling, prioritization... I don't think that developers should be even configuring and managing queues themselves in 2024.</p></blockquote></div><div><div><p>Effortless development</p><h2>Made for modern engineering teams</h2><p>We've built Inngest to enable every developer to build reliable, scalable systems with less effort, more confidence, and fewer headaches.</p></div><div><div><div><p><img src="https://www.inngest.com/assets/homepage/usp-apis-for-reliability.svg" alt="Inngest SDK APIs"></p><div><p>Use our SDK primitives to write code that automatically retries on error, runs in parallel, sleeps for days, or waits for additional input.</p><p>It's durable execution, built for <em>every developer</em>.</p></div></div><div><h3>Write reliable, fault-tolerant code with ease</h3></div></div><div><div><p><img src="https://www.inngest.com/assets/homepage/usp-flow-control.svg" alt="Flow control graphic and methods"></p><div><p>Flow Control is essential for building resilient systems with durable execution. Configure <em>how</em> and <em>when</em> you</p><p>Throttle, multi-tenant concurrency controls, prioritization, rate limiting, batching, and more in a line of code.</p></div></div><div><h3>Flow control for resilient systems</h3></div></div><div><div><p><img src="https://www.inngest.com/assets/homepage/usp-local-dev.svg" alt="Local development starts with one command"></p><div><p>Our open source Dev Server spins up an Inngest environment on your machine in a single command, with a UI to test and debug functions faster and easier then ever before.</p><p>No more battling clunky local setups for queues and workers.</p></div></div><div><h3>Local development that developers love</h3></div></div></div></div><div><blockquote><p>The DX and visibility with Inngest is really incredible. We are able to develop functions locally easier and faster that with our previous queue. Also, Inngest's tools give us the visibility to debug issues much quicker than before.</p></blockquote></div><div><div><p>Orchestration + Flow control</p><h2>Orchestration and flow control necessary for resilient systems</h2><p>Complete control over how your functions are executed without re-inventing the wheel. Inngest's built-in tools allow you to build complex workflows and run high volume jobs with fairness across your user base.</p></div><div><div><p><img src="https://www.inngest.com/assets/platform/icon-concurrency-global.svg"></p><h3>Fair, multi-tenant concurrency</h3><p>Prevent noisy neighbor issues by limiting the concurrent resources each account or user consumes. Just a couple of lines of code.</p><p><a href="https://www.inngest.com/docs/guides/concurrency?ref=homepage-orchestration">Learn more <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor"><path d="M16.1716 10.9999L10.8076 5.63589L12.2218 4.22168L20 11.9999L12.2218 19.778L10.8076 18.3638L16.1716 12.9999H4V10.9999H16.1716Z"></path></svg></a></p></div><div><p><img src="https://www.inngest.com/assets/platform/icon-workflow.svg"></p><h3>Step orchestration &amp; workflows</h3><p>Create step functions in code with orchestration and state automatically managed. Build complex pipelines of reliable business logic in minutes.</p><p><a href="https://www.inngest.com/docs/features/inngest-functions/steps-workflows?ref=homepage-orchestration">Learn more <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor"><path d="M16.1716 10.9999L10.8076 5.63589L12.2218 4.22168L20 11.9999L12.2218 19.778L10.8076 18.3638L16.1716 12.9999H4V10.9999H16.1716Z"></path></svg></a></p></div><div><p><img src="https://www.inngest.com/assets/platform/icon-batch.svg"></p><h3>Batching</h3><p>Coalesce many requests into a single function run for high-volume, low cost execution — without code, orchestration, or infra changes.</p><p><a href="https://www.inngest.com/docs/guides/batching?ref=homepage-orchestration">Learn more <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor"><path d="M16.1716 10.9999L10.8076 5.63589L12.2218 4.22168L20 11.9999L12.2218 19.778L10.8076 18.3638L16.1716 12.9999H4V10.9999H16.1716Z"></path></svg></a></p></div><div><p><img src="https://www.inngest.com/assets/platform/icon-throttle.svg"></p><h3>Throttle and rate-limiting</h3><p>Use throttling and rate-limiting to manage throughput across your functions. Handle spikes of traffic and ensure limited resources are protected, applying limits at a global or even user specific level.</p><p><a href="https://www.inngest.com/docs/guides/throttling?ref=homepage-orchestration">Throttling<!-- --> <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor"><path d="M16.1716 10.9999L10.8076 5.63589L12.2218 4.22168L20 11.9999L12.2218 19.778L10.8076 18.3638L16.1716 12.9999H4V10.9999H16.1716Z"></path></svg></a><a href="https://www.inngest.com/docs/guides/rate-limiting?ref=homepage-orchestration">Rate limiting<!-- --> <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor"><path d="M16.1716 10.9999L10.8076 5.63589L12.2218 4.22168L20 11.9999L12.2218 19.778L10.8076 18.3638L16.1716 12.9999H4V10.9999H16.1716Z"></path></svg></a></p></div><div><p><img src="https://www.inngest.com/assets/platform/icon-priority.svg"></p><h3>Dynamic prioritization</h3><p>Push paid or high-value users to the front of the queue while still ensuring fairness and quality-of-service for other users.</p><p><a href="https://www.inngest.com/docs/guides/priority?ref=homepage-orchestration">Learn more <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor"><path d="M16.1716 10.9999L10.8076 5.63589L12.2218 4.22168L20 11.9999L12.2218 19.778L10.8076 18.3638L16.1716 12.9999H4V10.9999H16.1716Z"></path></svg></a></p></div><div><p><img src="https://www.inngest.com/assets/platform/icon-debounce.svg"></p><h3>Debouncing</h3><p>Prevent wasted work and costs by debouncing functions triggered within a time window.</p><p><a href="https://www.inngest.com/docs/guides/debounce?ref=homepage-orchestration">Learn more <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor"><path d="M16.1716 10.9999L10.8076 5.63589L12.2218 4.22168L20 11.9999L12.2218 19.778L10.8076 18.3638L16.1716 12.9999H4V10.9999H16.1716Z"></path></svg></a></p></div><div><p><img src="https://www.inngest.com/assets/platform/icon-pause.svg"></p><h3>Pause for input or events</h3><p>Write functions that "wait for" additional input or events and automatically resume when matching events are received. No state management or polling required.</p><p><a href="https://www.inngest.com/docs/features/inngest-functions/steps-workflows/wait-for-event?ref=homepage-orchestration">Learn about waitForEvent<!-- --> <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor"><path d="M16.1716 10.9999L10.8076 5.63589L12.2218 4.22168L20 11.9999L12.2218 19.778L10.8076 18.3638L16.1716 12.9999H4V10.9999H16.1716Z"></path></svg></a></p></div><div><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor"><path d="M12 22C6.47715 22 2 17.5228 2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22ZM12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20ZM13 12H17V14H11V7H13V12Z"></path></svg><h3>Sleep, scheduling, and cron</h3><p>Sleep directly in code — in serverless functions, servers, or on the edge — and schedule functions for the future using dates or cron expressions.</p><p><a href="https://www.inngest.com/docs/features/inngest-functions/steps-workflows/sleeps?ref=homepage-orchestration">Sleeps<!-- --> <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor"><path d="M16.1716 10.9999L10.8076 5.63589L12.2218 4.22168L20 11.9999L12.2218 19.778L10.8076 18.3638L16.1716 12.9999H4V10.9999H16.1716Z"></path></svg></a><a href="https://www.inngest.com/docs/guides/delayed-functions?ref=homepage-orchestration">Scheduling<!-- --> <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor"><path d="M16.1716 10.9999L10.8076 5.63589L12.2218 4.22168L20 11.9999L12.2218 19.778L10.8076 18.3638L16.1716 12.9999H4V10.9999H16.1716Z"></path></svg></a><a href="https://www.inngest.com/docs/guides/scheduled-functions?ref=homepage-orchestration">Crons<!-- --> <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor"><path d="M16.1716 10.9999L10.8076 5.63589L12.2218 4.22168L20 11.9999L12.2218 19.778L10.8076 18.3638L16.1716 12.9999H4V10.9999H16.1716Z"></path></svg></a></p></div><div><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor"><path d="M12 22C6.47715 22 2 17.5228 2 12C2 6.47715 6.47715 2 12 2C17.5228 2 22 6.47715 22 12C22 17.5228 17.5228 22 12 22ZM12 20C16.4183 20 20 16.4183 20 12C20 7.58172 16.4183 4 12 4C7.58172 4 4 7.58172 4 12C4 16.4183 7.58172 20 12 20ZM12 10.5858L14.8284 7.75736L16.2426 9.17157L13.4142 12L16.2426 14.8284L14.8284 16.2426L12 13.4142L9.17157 16.2426L7.75736 14.8284L10.5858 12L7.75736 9.17157L9.17157 7.75736L12 10.5858Z"></path></svg><h3>Declarative cancellation</h3><p>Automatically cancel functions whenever events happen in your system — without API calls, recording job IDs, or storing state.</p><p><a href="https://www.inngest.com/docs/guides/cancel-running-functions?ref=homepage-orchestration">Learn more <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor"><path d="M16.1716 10.9999L10.8076 5.63589L12.2218 4.22168L20 11.9999L12.2218 19.778L10.8076 18.3638L16.1716 12.9999H4V10.9999H16.1716Z"></path></svg></a></p></div></div></div><div><blockquote><p>The DX and code simplicity it brings is unmatched, especially around local development. We're currently working to migrate some of our larger systems over and it’s a joy to see all the complexity it replaces, and with a much better story around partial failures and retries.</p></blockquote></div><div><div><p>Observability + Recovery</p><h2>Monitor, debug, and recover from issues</h2><p>Run in production with confidence with observability and recovery tools built into Inngest. Dig into traces to debug errors, monitor function and system health, and recovery from incidents with build-in tooling.</p></div><div><div><p><img alt="Screenshot of Debug your functions with traces" loading="lazy" width="1149" height="582" decoding="async" data-nimg="1" srcset="https://www.inngest.com/_next/image?url=%2Fassets%2Fhomepage%2Fo11y%2Ftracing.png&amp;w=1200&amp;q=75 1x, https://www.inngest.com/_next/image?url=%2Fassets%2Fhomepage%2Fo11y%2Ftracing.png&amp;w=3840&amp;q=75 2x" src="https://www.inngest.com/_next/image?url=%2Fassets%2Fhomepage%2Fo11y%2Ftracing.png&amp;w=3840&amp;q=75"></p></div><div><p><img alt="Screenshot of Full observability" loading="lazy" width="307" height="140" decoding="async" data-nimg="1" src="https://www.inngest.com/assets/homepage/o11y/metrics.svg"></p><div><h3><a href="https://www.inngest.com/docs/platform/monitor/observability-metrics?ref=homepage-observability">Full observability<!-- --> <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor"><path d="M13.1717 12.0007L8.22192 7.05093L9.63614 5.63672L16.0001 12.0007L9.63614 18.3646L8.22192 16.9504L13.1717 12.0007Z"></path></svg></a></h3><p>Rapidly diagnose system wide issues with metrics including volume, error rates, backlog and throughput.</p></div></div><div><p><img alt="Screenshot of Bulk function replay" loading="lazy" width="307" height="140" decoding="async" data-nimg="1" src="https://www.inngest.com/assets/homepage/o11y/replay.svg"></p><div><h3><a href="https://www.inngest.com/docs/platform/replay?ref=homepage-observability">Bulk function replay<!-- --> <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor"><path d="M13.1717 12.0007L8.22192 7.05093L9.63614 5.63672L16.0001 12.0007L9.63614 18.3646L8.22192 16.9504L13.1717 12.0007Z"></path></svg></a></h3><p>Leave dead letter queues in the past. Replay failed or cancelled functions in bulk to get your system back to green.</p></div></div><div><p><img alt="Screenshot of React to urgent issues" loading="lazy" width="307" height="140" decoding="async" data-nimg="1" srcset="https://www.inngest.com/_next/image?url=%2Fassets%2Fhomepage%2Fo11y%2Ffunction-actions.png&amp;w=384&amp;q=75 1x, https://www.inngest.com/_next/image?url=%2Fassets%2Fhomepage%2Fo11y%2Ffunction-actions.png&amp;w=640&amp;q=75 2x" src="https://www.inngest.com/_next/image?url=%2Fassets%2Fhomepage%2Fo11y%2Ffunction-actions.png&amp;w=640&amp;q=75"></p><div><h3><a href="https://www.inngest.com/docs/guides/pause-functions?ref=homepage-observability">React to urgent issues<!-- --> <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor"><path d="M13.1717 12.0007L8.22192 7.05093L9.63614 5.63672L16.0001 12.0007L9.63614 18.3646L8.22192 16.9504L13.1717 12.0007Z"></path></svg></a></h3><p>Quickly respond to urgent issues by pausing functions or cancelling runs in bulk. Resume and replay to recover.</p></div></div></div></div><div><blockquote><p>Configuration with Inngest is really easy. When we read our code base, we can immediately understand what it is and what it does. We are going to be gradually migrating most features to Inngest.</p></blockquote></div><div><div><p>Local Development</p><h2>Unparalleled local development workflow</h2><p>Our open source Dev Server runs on your machine for a complete local development experience, with production parity. Get instant feedback on your work and deploy to prod with full confidence.</p></div><video src="https://www.inngest.com/assets/homepage/video/2024-09-dev-server-4k.mp4" autoplay="" loop="" muted=""></video><div><div><h3>Visual debugging in <em>real-time</em></h3><p>No more parsing terminal logs. Watch your functions execute step-by-step in your browser.</p></div><div><h3>Single binary, zero dependencies</h3><p>One command to install and run. No external services, databases, or dependencies.</p></div><div><h3>Iterate faster</h3><p>Replay functions in one click for a faster feedback loop than ever before.</p></div></div></div><div><blockquote><p>Inngest changed how I build TypeScript applications. I can't stress enough how much I love using Inngest. The ease of use and developer experience is unparalleled</p></blockquote></div><div><div><p>Enterprise ready</p><h2>Security, scalability, and compliance</h2><p>We take security and reliability seriously. Our platform complies with the security standards you need to run your business.</p></div><div><div><div><h3><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor"><path d="M5 3V19H21V21H3V3H5ZM19.9393 5.93934L22.0607 8.06066L16 14.1213L13 11.121L9.06066 15.0607L6.93934 12.9393L13 6.87868L16 9.879L19.9393 5.93934Z"></path></svg>Billions of functions per month</h3><p>Our platform has been put to the test and designed to scale so your team can just focus on building a great product.</p></div><div><h3><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor"><path d="M12 1L20.2169 2.82598C20.6745 2.92766 21 3.33347 21 3.80217V13.7889C21 15.795 19.9974 17.6684 18.3282 18.7812L12 23L5.6718 18.7812C4.00261 17.6684 3 15.795 3 13.7889V3.80217C3 3.33347 3.32553 2.92766 3.78307 2.82598L12 1ZM12 3.04879L5 4.60434V13.7889C5 15.1263 5.6684 16.3752 6.7812 17.1171L12 20.5963L17.2188 17.1171C18.3316 16.3752 19 15.1263 19 13.7889V4.60434L12 3.04879ZM12 7C13.1046 7 14 7.89543 14 9C14 9.73984 13.5983 10.3858 13.0011 10.7318L13 15H11L10.9999 10.7324C10.4022 10.3866 10 9.74025 10 9C10 7.89543 10.8954 7 12 7Z"></path></svg>End-to-end encryption</h3><p>Data is encrypted in transit and at rest, so you can trust that your data is safe. Use our<!-- --> <a href="https://www.inngest.com/docs/features/middleware/encryption-middleware?ref=homepage-enterprise">encryption middleware</a> <!-- -->for additional control.</p></div><div><h3><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor"><path d="M3 6H21V18H3V6ZM2 4C1.44772 4 1 4.44772 1 5V19C1 19.5523 1.44772 20 2 20H22C22.5523 20 23 19.5523 23 19V5C23 4.44772 22.5523 4 22 4H2ZM13 8H19V10H13V8ZM18 12H13V14H18V12ZM10.5 10C10.5 11.3807 9.38071 12.5 8 12.5C6.61929 12.5 5.5 11.3807 5.5 10C5.5 8.61929 6.61929 7.5 8 7.5C9.38071 7.5 10.5 8.61929 10.5 10ZM8 13.5C6.067 13.5 4.5 15.067 4.5 17H11.5C11.5 15.067 9.933 13.5 8 13.5Z"></path></svg>SSO and SAML</h3><p>Secure your account with single sign-on and SAML.</p></div><div><h3><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor"><path d="M20 2C20.5523 2 21 2.44772 21 3V21C21 21.5523 20.5523 22 20 22H6C5.44772 22 5 21.5523 5 21V19H3V17H5V15H3V13H5V11H3V9H5V7H3V5H5V3C5 2.44772 5.44772 2 6 2H20ZM19 4H7V20H19V4ZM14 8V11H17V13H13.999L14 16H12L11.999 13H9V11H12V8H14Z"></path></svg>HIPAA BAA Available</h3><p>Our system was built with healthcare in mind to handle sensitive data.</p></div></div><p><img src="https://www.inngest.com/assets/homepage/gradient-graphics/enterprise.svg" alt="Enterprise ready"></p></div><p><a target="" href="https://www.inngest.com/contact?ref=homepage-enterprise">Chat with a solutions engineer<svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor"><path d="M13.1717 12.0007L8.22192 7.05093L9.63614 5.63672L16.0001 12.0007L9.63614 18.3646L8.22192 16.9504L13.1717 12.0007Z"></path></svg></a></p></div><div><blockquote><p>Recently we migrated a lot of our infrastructure to  reduce technical overhead and save costs. One of the key moves was going from GCP Composer (Airflow) to Inngest. This unified our backend and reduced our bill by 50x!!</p></blockquote></div><div><div><p>Developer love</p><h2>What devs are saying about Inngest</h2><p>Don't just take our word for it, this is what developers think about Inngest.</p></div><div><div><p><img alt="Image of Erik Munson" loading="lazy" width="36" height="36" decoding="async" data-nimg="1" srcset="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Ferikmunson.jpg&amp;w=48&amp;q=75 1x, https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Ferikmunson.jpg&amp;w=96&amp;q=75 2x" src="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Ferikmunson.jpg&amp;w=96&amp;q=75"><span>Erik Munson<span>@<!-- -->erikmunson</span></span></p><p>I've worked on workflow systems before and am consistently amazed with the <span>@inngest</span> team's ability to do them better than anyone else. it takes me a few lines of app code to do things that would've been huge projects for an entire team in past jobs, largely due to work like this</p></div><div><p><img alt="Image of Taj English" loading="lazy" width="36" height="36" decoding="async" data-nimg="1" srcset="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Flisted-b-taj-english.jpg&amp;w=48&amp;q=75 1x, https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Flisted-b-taj-english.jpg&amp;w=96&amp;q=75 2x" src="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Flisted-b-taj-english.jpg&amp;w=96&amp;q=75"><span>Taj English<span>@<!-- -->KINGiTAJ</span></span></p><p>Today @listedBApp says goodbye to Kafka and I couldn't be more excited to be replacing it with <span>@inngest</span>. Not every day do you get to replace a major infra component that improves DX, saves money and enables faster innovation :rocket:</p></div><div><p><img alt="Image of David" loading="lazy" width="36" height="36" decoding="async" data-nimg="1" srcset="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fdavid-dzhng.jpg&amp;w=48&amp;q=75 1x, https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fdavid-dzhng.jpg&amp;w=96&amp;q=75 2x" src="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fdavid-dzhng.jpg&amp;w=96&amp;q=75"><span>David<span>@<!-- -->dzhng</span></span></p><p>For anyone who is building multi-step AI agents (e.g AutoGPT type systems), I highly recommend building it on top of a job queue orchestration framework like <span>@inngest</span>, the traceability these things provide out of the box is super useful, plus you get timeouts &amp; retries for free.</p></div><div><p><img alt="Image of Jesse Thomson" loading="lazy" width="36" height="36" decoding="async" data-nimg="1" srcset="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fjessethomson11.jpg&amp;w=48&amp;q=75 1x, https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fjessethomson11.jpg&amp;w=96&amp;q=75 2x" src="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fjessethomson11.jpg&amp;w=96&amp;q=75"><span>Jesse Thomson<span>@<!-- -->jessethomson11</span></span></p><div><p>I think the game has changed with <span>@inngest</span>.</p><p>To me, it is the missing piece for making a JS/TS a serious backend contender.</p><p>It has queuing, rate limits, backoff, &amp; everything else you named, without needing to muck around with SQS. 10/10 recommend</p></div></div><div><p><img alt="Image of Patrick Göler von Ravensburg" loading="lazy" width="36" height="36" decoding="async" data-nimg="1" srcset="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fproductlane-patrick.jpg&amp;w=48&amp;q=75 1x, https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fproductlane-patrick.jpg&amp;w=96&amp;q=75 2x" src="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fproductlane-patrick.jpg&amp;w=96&amp;q=75"><span>Patrick Göler von Ravensburg<span>@<!-- -->patrick_gvr</span></span></p><div><p>Headache prevented by <span>@inngest</span> and their concurrency feature 🤯</p><p>This function potentially runs for a long time and this allows us to not run this function again when the previous function hasn't finished based on the combination specified in 'key'.<img alt="Image of Inngest function" loading="lazy" width="400" height="124" decoding="async" data-nimg="1" srcset="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fproductlane-image.jpg&amp;w=640&amp;q=75 1x, https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fproductlane-image.jpg&amp;w=828&amp;q=75 2x" src="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fproductlane-image.jpg&amp;w=828&amp;q=75"></p></div></div><div><p><img alt="Image of Stefan Wirth" loading="lazy" width="36" height="36" decoding="async" data-nimg="1" srcset="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fnafetswirth.jpg&amp;w=48&amp;q=75 1x, https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fnafetswirth.jpg&amp;w=96&amp;q=75 2x" src="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fnafetswirth.jpg&amp;w=96&amp;q=75"><span>Stefan Wirth<span>@<!-- -->NafetsWirth</span></span></p><div><p>Started playing around with <span>@inngest</span> for scheduled tasks and background jobs.</p><p>Highly recommended, super simple to set up and amazing DX.</p><p>Support also very responsive.</p><p>Great job guys!</p></div></div><div><p><img alt="Image of Guillermo Rauch" loading="lazy" width="36" height="36" decoding="async" data-nimg="1" srcset="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Frauchg.jpg&amp;w=48&amp;q=75 1x, https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Frauchg.jpg&amp;w=96&amp;q=75 2x" src="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Frauchg.jpg&amp;w=96&amp;q=75"><span>Guillermo Rauch<span>@<!-- -->rauchg</span></span></p><div><p>So excited to see <span>@inngest</span> grow. It's the perfect tool to help orchestrate complex AI workloads.</p><p>Behind every successful generative AI product, there are queues and pipelines, increasingly powered by Inngest.</p></div></div><div><p><img alt="Image of James Q Quick" loading="lazy" width="36" height="36" decoding="async" data-nimg="1" srcset="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fjamesqquick.jpg&amp;w=48&amp;q=75 1x, https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fjamesqquick.jpg&amp;w=96&amp;q=75 2x" src="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fjamesqquick.jpg&amp;w=96&amp;q=75"><span>James Q Quick<span>@<!-- -->jamesqquick</span></span></p><p>Tried <span>@inngest</span> for the first time today and …WOW! I'm really excited to fit this into some of my app ideas!</p></div><div><p><img alt="Image of Ray Amjad" loading="lazy" width="36" height="36" decoding="async" data-nimg="1" srcset="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Frayamjad.jpg&amp;w=48&amp;q=75 1x, https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Frayamjad.jpg&amp;w=96&amp;q=75 2x" src="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Frayamjad.jpg&amp;w=96&amp;q=75"><span>Ray Amjad<span>@<!-- -->theramjad</span></span></p><p>I love this product so much! I spent 2 days setting up some background workers on Render.com and it was a total pain in the ass. I gave up and I got my background jobs set up in under 10 minutes with Inngest.</p></div><div><p><img alt="Image of Michael Roberts" loading="lazy" width="36" height="36" decoding="async" data-nimg="1" srcset="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fmichaeljroberts.jpg&amp;w=48&amp;q=75 1x, https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fmichaeljroberts.jpg&amp;w=96&amp;q=75 2x" src="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fmichaeljroberts.jpg&amp;w=96&amp;q=75"><span>Michael Roberts<span>@<!-- -->codewithbhargav</span></span></p><p>Yeh so <span>@inngest</span> is perhaps one of the best SaaS platforms I have EVER used, incredible stability and crystal clear APIs. Love it already!</p></div><div><p><img alt="Image of Bhargav" loading="lazy" width="36" height="36" decoding="async" data-nimg="1" srcset="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fcodewithbhargav.jpg&amp;w=48&amp;q=75 1x, https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fcodewithbhargav.jpg&amp;w=96&amp;q=75 2x" src="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fcodewithbhargav.jpg&amp;w=96&amp;q=75"><span>Bhargav<span>@<!-- -->codewithbhargav</span></span></p><p><span>@inngest</span> feels like a cheat code. Beautifully done!</p></div><div><p><img alt="Image of JB" loading="lazy" width="36" height="36" decoding="async" data-nimg="1" srcset="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fjulianbenegas8.jpg&amp;w=48&amp;q=75 1x, https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fjulianbenegas8.jpg&amp;w=96&amp;q=75 2x" src="https://www.inngest.com/_next/image?url=%2Fassets%2Fcustomers%2Fsocial-proof%2Fjulianbenegas8.jpg&amp;w=96&amp;q=75"><span>JB<span>@<!-- -->julianbenegas8</span></span></p><p>ok, <span>@inngest</span> is incredible... really clear messaging, great docs, fast and well designed dashboard, great DX, etc... highly recommend.</p></div></div></div><div><div><a href="https://www.inngest.com/discord"><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="4em" height="4em" fill="currentColor"><path d="M19.3034 5.33716C17.9344 4.71103 16.4805 4.2547 14.9629 4C14.7719 4.32899 14.5596 4.77471 14.411 5.12492C12.7969 4.89144 11.1944 4.89144 9.60255 5.12492C9.45397 4.77471 9.2311 4.32899 9.05068 4C7.52251 4.2547 6.06861 4.71103 4.70915 5.33716C1.96053 9.39111 1.21766 13.3495 1.5891 17.2549C3.41443 18.5815 5.17612 19.388 6.90701 19.9187C7.33151 19.3456 7.71356 18.73 8.04255 18.0827C7.41641 17.8492 6.82211 17.5627 6.24904 17.2231C6.39762 17.117 6.5462 17.0003 6.68416 16.8835C10.1438 18.4648 13.8911 18.4648 17.3082 16.8835C17.4568 17.0003 17.5948 17.117 17.7434 17.2231C17.1703 17.5627 16.576 17.8492 15.9499 18.0827C16.2789 18.73 16.6609 19.3456 17.0854 19.9187C18.8152 19.388 20.5875 18.5815 22.4033 17.2549C22.8596 12.7341 21.6806 8.80747 19.3034 5.33716ZM8.5201 14.8459C7.48007 14.8459 6.63107 13.9014 6.63107 12.7447C6.63107 11.5879 7.45884 10.6434 8.5201 10.6434C9.57071 10.6434 10.4303 11.5879 10.4091 12.7447C10.4091 13.9014 9.57071 14.8459 8.5201 14.8459ZM15.4936 14.8459C14.4535 14.8459 13.6034 13.9014 13.6034 12.7447C13.6034 11.5879 14.4323 10.6434 15.4936 10.6434C16.5442 10.6434 17.4038 11.5879 17.3825 12.7447C17.3825 13.9014 16.5548 14.8459 15.4936 14.8459Z"></path></svg></a><h4>Join our Discord community</h4><p>Join our Discord community to ask questions, share feedback, and have a direct line to shaping the future of Inngest!</p><p><a target="_blank" href="https://www.inngest.com/discord">Join the community</a></p></div><div><a href="https://github.com/inngest/inngest"><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" width="4em" height="4em" fill="currentColor"><path d="M12.001 2C6.47598 2 2.00098 6.475 2.00098 12C2.00098 16.425 4.86348 20.1625 8.83848 21.4875C9.33848 21.575 9.52598 21.275 9.52598 21.0125C9.52598 20.775 9.51348 19.9875 9.51348 19.15C7.00098 19.6125 6.35098 18.5375 6.15098 17.975C6.03848 17.6875 5.55098 16.8 5.12598 16.5625C4.77598 16.375 4.27598 15.9125 5.11348 15.9C5.90098 15.8875 6.46348 16.625 6.65098 16.925C7.55098 18.4375 8.98848 18.0125 9.56348 17.75C9.65098 17.1 9.91348 16.6625 10.201 16.4125C7.97598 16.1625 5.65098 15.3 5.65098 11.475C5.65098 10.3875 6.03848 9.4875 6.67598 8.7875C6.57598 8.5375 6.22598 7.5125 6.77598 6.1375C6.77598 6.1375 7.61348 5.875 9.52598 7.1625C10.326 6.9375 11.176 6.825 12.026 6.825C12.876 6.825 13.726 6.9375 14.526 7.1625C16.4385 5.8625 17.276 6.1375 17.276 6.1375C17.826 7.5125 17.476 8.5375 17.376 8.7875C18.0135 9.4875 18.401 10.375 18.401 11.475C18.401 15.3125 16.0635 16.1625 13.8385 16.4125C14.201 16.725 14.5135 17.325 14.5135 18.2625C14.5135 19.6 14.501 20.675 14.501 21.0125C14.501 21.275 14.6885 21.5875 15.1885 21.4875C19.259 20.1133 21.9999 16.2963 22.001 12C22.001 6.475 17.526 2 12.001 2Z"></path></svg></a><h4>Open Source</h4><p>Inngest's core and all SDKs are open source. Explore our code bases, weigh in on RFCs, and contribute on GitHub.</p><p><a target="_blank" href="https://github.com/inngest/inngest">View project on GitHub</a></p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Put this touch sensor on a robot and learn super precise tasks (220 pts)]]></title>
            <link>https://any-skin.github.io</link>
            <guid>41603865</guid>
            <pubDate>Fri, 20 Sep 2024 17:11:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://any-skin.github.io">https://any-skin.github.io</a>, See on <a href="https://news.ycombinator.com/item?id=41603865">Hacker News</a></p>
Couldn't get https://any-skin.github.io: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Visualizing Weather Forecasts Through Landscape Imagery (320 pts)]]></title>
            <link>https://github.com/lds133/weather_landscape</link>
            <guid>41603546</guid>
            <pubDate>Fri, 20 Sep 2024 16:31:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/lds133/weather_landscape">https://github.com/lds133/weather_landscape</a>, See on <a href="https://news.ycombinator.com/item?id=41603546">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Weather as Landscape</h2><a id="user-content-weather-as-landscape" aria-label="Permalink: Weather as Landscape" href="#weather-as-landscape"></a></p>
<p dir="auto">Visualizing Weather Forecasts Through Landscape Imagery</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/lds133/weather_landscape/blob/main/pic/house.png"><img src="https://github.com/lds133/weather_landscape/raw/main/pic/house.png" alt="house"></a></p>
<p dir="auto">Traditional weather stations often display sensor readings as raw numerical data. Navigating these dashboards can be overwhelming and stressful, as it requires significant effort to locate, interpret, and visualize specific parameters effectively.</p>
<p dir="auto">Viewing a landscape image feels natural to the human eye. The calming effect of observing landscape elements reduces stress and requires minimal effort, allowing for a more relaxed visual experience.</p>
<p dir="auto">The method below demonstrates how to encode weather information within a landscape image, with no or minimal reliance on numerical data.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Encoding principles</h2><a id="user-content-encoding-principles" aria-label="Permalink: Encoding principles" href="#encoding-principles"></a></p>
<p dir="auto">The landscape depicts a small house in the woods. The horizontal axis of the image represents a 24-hour timeline, starting from the current moment on the left, marked by the house, and extending to the conditions of the next day on the right. Various landscape elements distributed along the vertical axis symbolize weather events and conditions. The further an event is from the present, the farther it is positioned to the right in the image.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/lds133/weather_landscape/blob/main/pic/encode.png"><img src="https://github.com/lds133/weather_landscape/raw/main/pic/encode.png" alt="encode"></a></p>
<p dir="auto">The following information can be encoded within the landscape image:</p>
<ul dir="auto">
<li>Time markers to simplify timeline navigation:
<ul dir="auto">
<li>Sunrise and sunset times</li>
<li>Noon and midnight</li>
</ul>
</li>
<li>Weather forecast information:
<ul dir="auto">
<li>Wind direction and strength</li>
<li>Temperature fluctuations</li>
<li>Maximum and minimum temperature values</li>
<li>Cloud cover</li>
<li>Precipitation</li>
</ul>
</li>
<li>Current weather conditions:
<ul dir="auto">
<li>Temperature</li>
<li>Atmospheric pressure</li>
</ul>
</li>
<li>Non weather events:
<ul dir="auto">
<li>Birthdays</li>
<li>Holidays</li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Implementation</h2><a id="user-content-implementation" aria-label="Permalink: Implementation" href="#implementation"></a></p>
<p dir="auto">The image generation code is written in <a href="https://www.python.org/" rel="nofollow">Python</a> using the <a href="https://python-pillow.org/" rel="nofollow">Pillow</a> library and is based on data from <a href="https://openweathermap.org/" rel="nofollow">OpenWeather</a>. The image is designed specifically for use on a 296x128 E-Ink display. The code tested on Python 3.9.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Event image</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/lds133/weather_landscape/blob/main/pic/sun_00.png"><img src="https://github.com/lds133/weather_landscape/raw/main/pic/sun_00.png" alt="example"></a></td>
<td>Sunrise</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/lds133/weather_landscape/blob/main/pic/moon_00.png"><img src="https://github.com/lds133/weather_landscape/raw/main/pic/moon_00.png" alt="example"></a></td>
<td>Sunset</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/lds133/weather_landscape/blob/main/pic/cloud_30.png"><img src="https://github.com/lds133/weather_landscape/raw/main/pic/cloud_30.png" alt="example"></a></td>
<td>Cloud cover</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/lds133/weather_landscape/blob/main/pic/house_00.png"><img src="https://github.com/lds133/weather_landscape/raw/main/pic/house_00.png" alt="example"></a></td>
<td>Current time position</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/lds133/weather_landscape/blob/main/pic/flower_00.png"><img src="https://github.com/lds133/weather_landscape/raw/main/pic/flower_00.png" alt="example"></a></td>
<td>Midnight</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/lds133/weather_landscape/blob/main/pic/flower_01.png"><img src="https://github.com/lds133/weather_landscape/raw/main/pic/flower_01.png" alt="example"></a></td>
<td>Midday</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/lds133/weather_landscape/blob/main/pic/palm_03.png"><img src="https://github.com/lds133/weather_landscape/raw/main/pic/palm_03.png" alt="example"></a></td>
<td>South wind</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/lds133/weather_landscape/blob/main/pic/east_03.png"><img src="https://github.com/lds133/weather_landscape/raw/main/pic/east_03.png" alt="example"></a></td>
<td>East wind</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/lds133/weather_landscape/blob/main/pic/tree_03.png"><img src="https://github.com/lds133/weather_landscape/raw/main/pic/tree_03.png" alt="example"></a></td>
<td>West wind</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/lds133/weather_landscape/blob/main/pic/pine_02.png"><img src="https://github.com/lds133/weather_landscape/raw/main/pic/pine_02.png" alt="example"></a></td>
<td>North wind</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/lds133/weather_landscape/blob/main/pic/rain.png"><img src="https://github.com/lds133/weather_landscape/raw/main/pic/rain.png" alt="example"></a></td>
<td>Rain</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>&nbsp;Landscape&nbsp;image&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/lds133/weather_landscape/blob/main/pic/weather_test.bmp"><img src="https://github.com/lds133/weather_landscape/raw/main/pic/weather_test.bmp" alt="example"></a></td>
<td>It’s around noon, with clear skies and a few clouds expected. A moderate north wind will develop overnight. Temperatures are currently rising but will begin to fall after sunset, reaching their lowest point before sunrise. During this time, the wind is expected to shift to the northeast.</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/lds133/weather_landscape/blob/main/pic/test_20240903_043826.bmp"><img src="https://github.com/lds133/weather_landscape/raw/main/pic/test_20240903_043826.bmp" alt="example"></a></td>
<td>The sun is rising and it will be a hot sunny day with a light southeast breeze. The temperature will remain high even after sunset, and the wind will shift to the east, becoming stronger throughout the evening.</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/lds133/weather_landscape/blob/main/pic/test_09B0B1083315.bmp"><img src="https://github.com/lds133/weather_landscape/raw/main/pic/test_09B0B1083315.bmp" alt="example"></a></td>
<td>It will be cold and rainy throughout the day and night. The south wind will shift to the northeast overnight.</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Running the code</h2><a id="user-content-running-the-code" aria-label="Permalink: Running the code" href="#running-the-code"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Preparing environment Linux</h4><a id="user-content-preparing-environment-linux" aria-label="Permalink: Preparing environment Linux" href="#preparing-environment-linux"></a></p>

<div data-snippet-clipboard-copy-content="source .venv/bin/activate"><pre><code>source .venv/bin/activate
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Preparing environment Windows</h4><a id="user-content-preparing-environment-windows" aria-label="Permalink: Preparing environment Windows" href="#preparing-environment-windows"></a></p>


<p dir="auto"><h4 tabindex="-1" dir="auto">Image creation test</h4><a id="user-content-image-creation-test" aria-label="Permalink: Image creation test" href="#image-creation-test"></a></p>
<p dir="auto">Update <strong>OWM_KEY</strong> variable in the weather_landscape.py file with your OpenWeather API key.</p>

<p dir="auto"><h4 tabindex="-1" dir="auto">Run server</h4><a id="user-content-run-server" aria-label="Permalink: Run server" href="#run-server"></a></p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Hardware</h2><a id="user-content-hardware" aria-label="Permalink: Hardware" href="#hardware"></a></p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/lds133/weather_landscape/blob/main/pic/hardware.jpg"><img src="https://github.com/lds133/weather_landscape/raw/main/pic/hardware.jpg" alt="Setup"></a></p>
<p dir="auto">The hardware setup includes an <a href="https://www.adafruit.com/product/3269" rel="nofollow">ESP32 development board</a> and <a href="https://www.waveshare.com/2.9inch-e-paper-module.htm" rel="nofollow">2.9inch E-Ink display module</a>. Currently, the setup only displays an image sourced from the internet, updating every 15 minutes. It is uncertain whether the image generation code can be adapted for use with MicroPython on the ESP32 at this time.</p>
<p dir="auto"><a href="https://github.com/lds133/weather_landscape/blob/main/esp32/README.md">More information</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MemoRAG – Enhance RAG with memory-based knowledge discovery for long contexts (114 pts)]]></title>
            <link>https://github.com/qhjqhj00/MemoRAG</link>
            <guid>41602474</guid>
            <pubDate>Fri, 20 Sep 2024 14:41:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/qhjqhj00/MemoRAG">https://github.com/qhjqhj00/MemoRAG</a>, See on <a href="https://news.ycombinator.com/item?id=41602474">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><h2 tabindex="-1" dir="auto"><div dir="auto"><p>MemoRAG: Moving Towards Next-Gen RAG Via Memory-Inspired Knowledge Discovery</p></div></h2><a id="user-content-memorag-moving-towards-next-gen-rag-via-memory-inspired-knowledge-discovery" aria-label="Permalink: MemoRAG: Moving Towards Next-Gen RAG Via Memory-Inspired Knowledge Discovery" href="#memorag-moving-towards-next-gen-rag-via-memory-inspired-knowledge-discovery"></a></div>
<div dir="auto">
<p dir="auto"><strong>Empowering RAG with a memory-based data interface for all-purpose applications!</strong></p>
<p><a href="https://arxiv.org/abs/2409.05591" rel="nofollow"><img src="https://camo.githubusercontent.com/e77bc7a7bb6e94ececde002fe9566c05e16a43ce2505e3312f593c35d4478f49/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f61725869762d6235323132662e7376673f6c6f676f3d6172786976" data-canonical-src="https://img.shields.io/badge/arXiv-b5212f.svg?logo=arxiv"></a>
<a href="https://huggingface.co/TommyChien/memorag-qwen2-7b-inst" rel="nofollow"><img src="https://camo.githubusercontent.com/b9cfd536e732f588fb294c166d0cf0445280e1277da0992d910d08046c71d394/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f25463025394625413425393725323048756767696e67466163652532304d6f64656c2d3237623362342e737667" data-canonical-src="https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace%20Model-27b3b4.svg"></a>
<a href="https://github.com/"><img alt="License" src="https://camo.githubusercontent.com/f2d7ec897487f1f15b8aa0becf58575e8864664c20296ca5ad838c94a6aee34e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c4943454e53452d4d49542d677265656e" data-canonical-src="https://img.shields.io/badge/LICENSE-MIT-green"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/39dc05a0a44228ca43023e33f606d774bfbc34ed0aa0be2538308b2038d534c1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6d6164655f776974682d507974686f6e2d626c7565"><img alt="Static Badge" src="https://camo.githubusercontent.com/39dc05a0a44228ca43023e33f606d774bfbc34ed0aa0be2538308b2038d534c1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6d6164655f776974682d507974686f6e2d626c7565" data-canonical-src="https://img.shields.io/badge/made_with-Python-blue"></a>
</p></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Overview</h2><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<p dir="auto"><strong>MemoRAG</strong> is an innovative RAG framework built on top of a highly efficient, super-long memory model. Unlike standard RAG, which primarily handles queries with explicit information needs, MemoRAG leverages its memory model to achieve a global understanding of the entire database. By recalling query-specific clues from memory, MemoRAG enhances evidence retrieval, resulting in more accurate and contextually rich response generation.​</p>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://github.com/qhjqhj00/MemoRAG/blob/main/asset/tech_case.jpg"><img src="https://github.com/qhjqhj00/MemoRAG/raw/main/asset/tech_case.jpg"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">MemoRAG Demo</h2><a id="user-content-memorag-demo" aria-label="Permalink: MemoRAG Demo" href="#memorag-demo"></a></p>
<p dir="auto">We will provide a toy demo to demonstrate MemoRAG, you can try with the following scripts:</p>
<div dir="auto" data-snippet-clipboard-copy-content="streamlit run demo/demo.py"><pre><span>streamlit</span> <span>run</span> <span>demo</span><span>/</span><span>demo</span>.<span>py</span></pre></div>
<p dir="auto">Afterwards, you can view the demo as below:</p>
<div dir="auto">
  <p><a target="_blank" rel="noopener noreferrer" href="https://github.com/qhjqhj00/MemoRAG/blob/main/asset/demo.gif"><img src="https://github.com/qhjqhj00/MemoRAG/raw/main/asset/demo.gif" data-animated-image=""></a>
  </p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">📃 Changelog</h2><a id="user-content-page_with_curl-changelog" aria-label="Permalink: :page_with_curl: Changelog" href="#page_with_curl-changelog"></a></p>
<p dir="auto">[13/09/24] MemoRAG adds <code>Meta-Llama-3.1-8B-Instruct</code> and <code>Llama3.1-8B-Chinese-Chat</code> as the Memory Model, see <a href="https://github.com/qhjqhj00/MemoRAG/blob/main/examples/longllm_as_memory.ipynb"><code>examples</code></a>.</p>
<p dir="auto">[10/09/24] We release MemoRAG's <a href="https://arxiv.org/pdf/2409.05591" rel="nofollow"><code>Technical Report</code></a>.</p>
<p dir="auto">[09/09/24] You can try MemoRAG on <a href="https://colab.research.google.com/drive/1fPMXKyi4AwWSBkC7Xr5vBdpPpx9gDeFX?usp=sharing" rel="nofollow"><code>Google Colab</code></a> for free.</p>
<p dir="auto">[05/09/24] A Qwen2-based memory model is available at <a href="https://huggingface.co/TommyChien/memorag-qwen2-7b-inst" rel="nofollow"><code>TommyChien/memorag-qwen2-7b-inst</code></a>.</p>
<p dir="auto">[03/09/24] A Mistral-based memory model is available at <a href="https://huggingface.co/TommyChien/memorag-mistral-7b-inst" rel="nofollow"><code>TommyChien/memorag-mistral-7b-inst</code></a>.</p>
<p dir="auto">[01/09/24] The project launched!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">✨ Features</h2><a id="user-content-sparkles-features" aria-label="Permalink: :sparkles: Features" href="#sparkles-features"></a></p>
<ul dir="auto">
<li><strong>Global Memory</strong>: Handles up to <strong>1 million tokens</strong> in a single context, providing comprehensive understanding across massive datasets.</li>
<li><strong>Optimizable &amp; Flexible</strong>: Adapts to new tasks with ease, achieving optimized performance with just a few hours of additional training.</li>
<li><strong>Contextual Clues</strong>: Generates precise clues from global memory, bridging raw input to answers and unlocking <strong>hidden insights</strong> from complex data.</li>
<li><strong>Efficient Caching</strong>: Speeds up context pre-filling by <strong>up to 30x</strong>, with support for caching chunking, indexing, and encoding.</li>
<li><strong>Context Reuse</strong>: Encodes long contexts <strong>once</strong> and supports repeated usage, boosting efficiency in tasks that require recurring data access.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔎 Roadmap</h2><a id="user-content-mag_right-roadmap" aria-label="Permalink: :mag_right: Roadmap" href="#mag_right-roadmap"></a></p>
<p dir="auto"><strong>MemoRAG</strong>  is currently under active development, with resources and prototypes continuously being published at this repository.</p>
<ul>
<li> Codes / Models / Dataset Release</li>
<li> Support OpenAI/Azure models</li>
<li> Technical Report Release</li>
<li> Support Chinese</li>
<li> Demo Codes Release</li>
<li> Training Codes for Memory model Release</li>
<li> <strong>Light-Weight Optimization</strong></li>
<li> <strong>Speed Up Inference</strong></li>
<li> <strong>Integrate Any Retrieval Methods</strong></li>
<li> <strong>Enrich the Memory Ability</strong></li>
</ul>
<p dir="auto">Note: The <strong>recent goals</strong> of MemoRAG are to achieve <strong>light-weight optimization</strong> through engineering improvements and to <strong>enhance its memory capabilities</strong>, enabling it to adapt to a wider range of applications and <strong>support longer context</strong> (e.g., more than one million tokens).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Quick Start</h2><a id="user-content-rocket-quick-start" aria-label="Permalink: :rocket: Quick Start" href="#rocket-quick-start"></a></p>
<p dir="auto">🆓 <strong>You can directly try MemoRAG on <a href="https://colab.research.google.com/drive/1fPMXKyi4AwWSBkC7Xr5vBdpPpx9gDeFX?usp=sharing" rel="nofollow"><code>Google Colab</code></a> for free.</strong></p>
<p dir="auto">In this notebook, we run the complete MemoRAG pipeline (Memory Model + Retriever + Generation Model) on a single T4 GPU with 15GiB of memory provided by Google Colab. Despite the limited resources, MemoRAG can process half of the content from <a href="https://github.com/qhjqhj00/MemoRAG/blob/main/examples/harry_potter.txt">the example book</a> (~68K tokens) and perform all of its functions.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation</h3><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">To use Memorizer and MemoRAG, you need to have Python installed along with the required libraries. You can install the necessary dependencies using the following command:</p>
<p dir="auto"><strong>Install Dependencies</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install torch==2.3.1
conda install -c pytorch -c nvidia faiss-gpu=1.8.0"><pre>pip install torch==2.3.1
conda install -c pytorch -c nvidia faiss-gpu=1.8.0</pre></div>
<p dir="auto"><strong>Install from source</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# clone this repo first
cd MemoRAG
pip install -e ."><pre><span><span>#</span> clone this repo first</span>
<span>cd</span> MemoRAG
pip install -e <span>.</span></pre></div>
<p dir="auto"><strong>Install via pip</strong></p>

<p dir="auto">For <strong>Quick Start</strong>,
We provide a notebook to illustrate all functions of MemoRAG <a href="https://github.com/qhjqhj00/MemoRAG/blob/main/examples/example.ipynb">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">📓 Usage</h2><a id="user-content-notebook-usage" aria-label="Permalink: :notebook: Usage" href="#notebook-usage"></a></p>
<p dir="auto">MemoRAG is easy to use and can be initialized with HuggingFace models directly. By using the <code>MemoRAG.memorize()</code> method, the memory model builds a global memory over a long input context. Empirically, with default parameter settings, <code>TommyChien/memorag-qwen2-7b-inst</code> can handle contexts of up to 400K tokens, while <code>TommyChien/memorag-mistral-7b-inst</code> can manage contexts up to 128K tokens. By increasing the <code>beacon_ratio</code> parameter, the model’s capacity to handle longer contexts can be extended. For example, <code>TommyChien/memorag-qwen2-7b-inst</code> can process up to one million tokens with <code>beacon_ratio=16</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Basic Usage of MemoRAG</h3><a id="user-content-basic-usage-of-memorag" aria-label="Permalink: Basic Usage of MemoRAG" href="#basic-usage-of-memorag"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="from memorag import MemoRAG

# Initialize MemoRAG pipeline
pipe = MemoRAG(
    mem_model_name_or_path=&quot;TommyChien/memorag-mistral-7b-inst&quot;,
    ret_model_name_or_path=&quot;BAAI/bge-m3&quot;, 
    gen_model_name_or_path=&quot;mistralai/Mistral-7B-Instruct-v0.2&quot;, # Optional: if not specify, use memery model as the generator
    cache_dir=&quot;path_to_model_cache&quot;,  # Optional: specify local model cache directory
    access_token=&quot;hugging_face_access_token&quot;,  # Optional: Hugging Face access token
    beacon_ratio=4
)

context = open(&quot;examples/harry_potter.txt&quot;).read()
query = &quot;How many times is the Chamber of Secrets opened in the book?&quot;

# Memorize the context and save to cache
pipe.memorize(context, save_dir=&quot;cache/harry_potter/&quot;, print_stats=True)

# Generate response using the memorized context
res = pipe(context=context, query=query, task_type=&quot;memorag&quot;, max_new_tokens=256)
print(f&quot;MemoRAG generated answer: \n{res}&quot;)"><pre><span>from</span> <span>memorag</span> <span>import</span> <span>MemoRAG</span>

<span># Initialize MemoRAG pipeline</span>
<span>pipe</span> <span>=</span> <span>MemoRAG</span>(
    <span>mem_model_name_or_path</span><span>=</span><span>"TommyChien/memorag-mistral-7b-inst"</span>,
    <span>ret_model_name_or_path</span><span>=</span><span>"BAAI/bge-m3"</span>, 
    <span>gen_model_name_or_path</span><span>=</span><span>"mistralai/Mistral-7B-Instruct-v0.2"</span>, <span># Optional: if not specify, use memery model as the generator</span>
    <span>cache_dir</span><span>=</span><span>"path_to_model_cache"</span>,  <span># Optional: specify local model cache directory</span>
    <span>access_token</span><span>=</span><span>"hugging_face_access_token"</span>,  <span># Optional: Hugging Face access token</span>
    <span>beacon_ratio</span><span>=</span><span>4</span>
)

<span>context</span> <span>=</span> <span>open</span>(<span>"examples/harry_potter.txt"</span>).<span>read</span>()
<span>query</span> <span>=</span> <span>"How many times is the Chamber of Secrets opened in the book?"</span>

<span># Memorize the context and save to cache</span>
<span>pipe</span>.<span>memorize</span>(<span>context</span>, <span>save_dir</span><span>=</span><span>"cache/harry_potter/"</span>, <span>print_stats</span><span>=</span><span>True</span>)

<span># Generate response using the memorized context</span>
<span>res</span> <span>=</span> <span>pipe</span>(<span>context</span><span>=</span><span>context</span>, <span>query</span><span>=</span><span>query</span>, <span>task_type</span><span>=</span><span>"memorag"</span>, <span>max_new_tokens</span><span>=</span><span>256</span>)
<span>print</span>(<span>f"MemoRAG generated answer: <span>\n</span><span><span>{</span><span>res</span><span>}</span></span>"</span>)</pre></div>
<p dir="auto">When running the above code, <strong>the encoded key-value (KV) cache, Faiss index, and chunked passages are stored</strong> in the specified <code>save_dir</code>. Afterward, if the same context is used again, the data can be quickly loaded from the disk:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pipe.load(&quot;cache/harry_potter/&quot;, print_stats=True)"><pre><span>pipe</span>.<span>load</span>(<span>"cache/harry_potter/"</span>, <span>print_stats</span><span>=</span><span>True</span>)</pre></div>
<p dir="auto">Typically, loading cached weights is highly efficient. For example, <strong>encoding, chunking, and indexing a 200K-token context takes approximately 35 seconds</strong> using <code>TommyChien/memorag-qwen2-7b-inst</code> as the memory model, <strong>but only 1.5 seconds when loading from cached files.</strong></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using Long LLMs as Memory Model 🆕 🆕 🆕</h3><a id="user-content-using-long-llms-as-memory-model-new-new-new" aria-label="Permalink: Using Long LLMs as Memory Model :new: :new: :new:" href="#using-long-llms-as-memory-model-new-new-new"></a></p>
<p dir="auto">Recent LLMs have become effective memory models due to their expanding context windows. MemoRAG now supports leveraging these long-context LLMs as memory models, utilizing <a href="https://github.com/microsoft/MInference"><code>MInference</code></a> to optimize context prefilling. We have tested <code>Meta-Llama-3.1-8B-Instruct</code> and <code>Llama3.1-8B-Chinese-Chat</code> as memory models, both of which natively support a 128K context length. We are currently exploring additional suitable LLMs and optimizing strategies to enhance the memory mechanisms and context length further. For detailed usage instructions, please refer to the provided scripts and the <a href="https://github.com/qhjqhj00/MemoRAG/blob/main/examples/longllm_as_memory.ipynb"><code>notebook</code></a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from memorag import MemoRAG
model = MemoRAG(
    mem_model_name_or_path=&quot;shenzhi-wang/Llama3.1-8B-Chinese-Chat&quot;,    # For Chinese
    # mem_model_name_or_path=&quot;meta-llama/Meta-Llama-3.1-8B-Instruct&quot;,  # For English
    ret_model_name_or_path=&quot;BAAI/bge-m3&quot;,
    # cache_dir=&quot;path_to_model_cache&quot;,  # to specify local model cache directory (optional)
    # access_token=&quot;hugging_face_access_token&quot;  # to specify local model cache directory (optional)
    )"><pre><span>from</span> <span>memorag</span> <span>import</span> <span>MemoRAG</span>
<span>model</span> <span>=</span> <span>MemoRAG</span>(
    <span>mem_model_name_or_path</span><span>=</span><span>"shenzhi-wang/Llama3.1-8B-Chinese-Chat"</span>,    <span># For Chinese</span>
    <span># mem_model_name_or_path="meta-llama/Meta-Llama-3.1-8B-Instruct",  # For English</span>
    <span>ret_model_name_or_path</span><span>=</span><span>"BAAI/bge-m3"</span>,
    <span># cache_dir="path_to_model_cache",  # to specify local model cache directory (optional)</span>
    <span># access_token="hugging_face_access_token"  # to specify local model cache directory (optional)</span>
    )</pre></div>
<p dir="auto">Afterward, you can use MemoRAG's functions as usual.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Summarization Task</h3><a id="user-content-summarization-task" aria-label="Permalink: Summarization Task" href="#summarization-task"></a></p>
<p dir="auto">To perform summarization tasks, use the following script:</p>
<div dir="auto" data-snippet-clipboard-copy-content="res = pipe(context=context, task_type=&quot;summarize&quot;, max_new_tokens=512)
print(f&quot;MemoRAG summary of the full book:\n {res}&quot;)"><pre><span>res</span> <span>=</span> <span>pipe</span>(<span>context</span><span>=</span><span>context</span>, <span>task_type</span><span>=</span><span>"summarize"</span>, <span>max_new_tokens</span><span>=</span><span>512</span>)
<span>print</span>(<span>f"MemoRAG summary of the full book:<span>\n</span> <span><span>{</span><span>res</span><span>}</span></span>"</span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using APIs as Generators</h3><a id="user-content-using-apis-as-generators" aria-label="Permalink: Using APIs as Generators" href="#using-apis-as-generators"></a></p>
<p dir="auto">If you want to use APIs as a generator, refer to the script below:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from memorag import Agent, MemoRAG

# API configuration
api_dict = {
    &quot;endpoint&quot;: &quot;&quot;,
    &quot;api_version&quot;: &quot;2024-02-15-preview&quot;,
    &quot;api_key&quot;: &quot;&quot;
}
model = &quot;gpt-35-turbo-16k&quot;
source = &quot;azure&quot;

# Initialize Agent with the API
agent = Agent(model, source, api_dict)
print(agent.generate(&quot;hi!&quot;))  # Test the API

# Initialize MemoRAG pipeline with a customized generator model
pipe = MemoRAG(
    mem_model_name_or_path=&quot;TommyChien/memorag-qwen2-7b-inst&quot;,
    ret_model_name_or_path=&quot;BAAI/bge-m3&quot;,
    cache_dir=&quot;path_to_model_cache&quot;,  # Optional: specify local model cache directory
    customized_gen_model=agent,
)

# Load previously cached context
pipe.load(&quot;cache/harry_potter_qwen/&quot;, print_stats=True)

# Use the loaded context for question answering
query = &quot;How are the mutual relationships between the main characters?&quot;
context = open(&quot;harry_potter.txt&quot;).read()

res = pipe(context=context, query=query, task_type=&quot;memorag&quot;, max_new_tokens=256)
print(f&quot;MemoRAG with GPT-3.5 generated answer: \n{res}&quot;)"><pre><span>from</span> <span>memorag</span> <span>import</span> <span>Agent</span>, <span>MemoRAG</span>

<span># API configuration</span>
<span>api_dict</span> <span>=</span> {
    <span>"endpoint"</span>: <span>""</span>,
    <span>"api_version"</span>: <span>"2024-02-15-preview"</span>,
    <span>"api_key"</span>: <span>""</span>
}
<span>model</span> <span>=</span> <span>"gpt-35-turbo-16k"</span>
<span>source</span> <span>=</span> <span>"azure"</span>

<span># Initialize Agent with the API</span>
<span>agent</span> <span>=</span> <span>Agent</span>(<span>model</span>, <span>source</span>, <span>api_dict</span>)
<span>print</span>(<span>agent</span>.<span>generate</span>(<span>"hi!"</span>))  <span># Test the API</span>

<span># Initialize MemoRAG pipeline with a customized generator model</span>
<span>pipe</span> <span>=</span> <span>MemoRAG</span>(
    <span>mem_model_name_or_path</span><span>=</span><span>"TommyChien/memorag-qwen2-7b-inst"</span>,
    <span>ret_model_name_or_path</span><span>=</span><span>"BAAI/bge-m3"</span>,
    <span>cache_dir</span><span>=</span><span>"path_to_model_cache"</span>,  <span># Optional: specify local model cache directory</span>
    <span>customized_gen_model</span><span>=</span><span>agent</span>,
)

<span># Load previously cached context</span>
<span>pipe</span>.<span>load</span>(<span>"cache/harry_potter_qwen/"</span>, <span>print_stats</span><span>=</span><span>True</span>)

<span># Use the loaded context for question answering</span>
<span>query</span> <span>=</span> <span>"How are the mutual relationships between the main characters?"</span>
<span>context</span> <span>=</span> <span>open</span>(<span>"harry_potter.txt"</span>).<span>read</span>()

<span>res</span> <span>=</span> <span>pipe</span>(<span>context</span><span>=</span><span>context</span>, <span>query</span><span>=</span><span>query</span>, <span>task_type</span><span>=</span><span>"memorag"</span>, <span>max_new_tokens</span><span>=</span><span>256</span>)
<span>print</span>(<span>f"MemoRAG with GPT-3.5 generated answer: <span>\n</span><span><span>{</span><span>res</span><span>}</span></span>"</span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Supported APIs for Generators</h3><a id="user-content-supported-apis-for-generators" aria-label="Permalink: Supported APIs for Generators" href="#supported-apis-for-generators"></a></p>
<p dir="auto">The built-in <code>Agent</code> object supports models from both <code>openai</code> and <code>deepseek</code>. Below are the configurations for initializing these models:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Using deepseek models
model = &quot;&quot;
source = &quot;deepseek&quot;
api_dict = {
    &quot;base_url&quot;: &quot;&quot;,
    &quot;api_key&quot;: &quot;&quot;
}

# Using openai models
model = &quot;&quot;
source = &quot;openai&quot;
api_dict = {
    &quot;api_key&quot;: &quot;&quot;
}"><pre><span># Using deepseek models</span>
<span>model</span> <span>=</span> <span>""</span>
<span>source</span> <span>=</span> <span>"deepseek"</span>
<span>api_dict</span> <span>=</span> {
    <span>"base_url"</span>: <span>""</span>,
    <span>"api_key"</span>: <span>""</span>
}

<span># Using openai models</span>
<span>model</span> <span>=</span> <span>""</span>
<span>source</span> <span>=</span> <span>"openai"</span>
<span>api_dict</span> <span>=</span> {
    <span>"api_key"</span>: <span>""</span>
}</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Usage for Memory Model</h3><a id="user-content-usage-for-memory-model" aria-label="Permalink: Usage for Memory Model" href="#usage-for-memory-model"></a></p>
<p dir="auto">The Memory model can be used independently to store, recall, and interact with the context. Here’s an example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from memorag import Memory

# Initialize the Memory model
memo_model = Memory(
    &quot;TommyChien/memorag-qwen2-7b-inst&quot;,
    cache_dir=&quot;path_to_model_cache&quot;,  # Optional: specify local model cache directory
    beacon_ratio=4  # Adjust beacon ratio for handling longer contexts
)

# Load and memorize the context
context = open(&quot;harry_potter.txt&quot;).read()
memo_model.memorize(context)

# Save the memorized context to disk
memo_model.save(&quot;cache/harry_potter/memory.bin&quot;)

# Query the model for answers
query = &quot;How are the mutual relationships between the main characters?&quot;

res = memo_model.answer(query)
print(&quot;Using memory to answer the query:\n&quot;, res)

# Recall text clues for evidence retrieval
res = memo_model.recall(query)
print(&quot;Using memory to recall text clues to support evidence retrieval:\n&quot;, res)

# Rewrite the query into more specific surrogate queries
res = memo_model.rewrite(query)
print(&quot;Using memory to rewrite the input query into more specific surrogate queries:\n&quot;, res)"><pre><span>from</span> <span>memorag</span> <span>import</span> <span>Memory</span>

<span># Initialize the Memory model</span>
<span>memo_model</span> <span>=</span> <span>Memory</span>(
    <span>"TommyChien/memorag-qwen2-7b-inst"</span>,
    <span>cache_dir</span><span>=</span><span>"path_to_model_cache"</span>,  <span># Optional: specify local model cache directory</span>
    <span>beacon_ratio</span><span>=</span><span>4</span>  <span># Adjust beacon ratio for handling longer contexts</span>
)

<span># Load and memorize the context</span>
<span>context</span> <span>=</span> <span>open</span>(<span>"harry_potter.txt"</span>).<span>read</span>()
<span>memo_model</span>.<span>memorize</span>(<span>context</span>)

<span># Save the memorized context to disk</span>
<span>memo_model</span>.<span>save</span>(<span>"cache/harry_potter/memory.bin"</span>)

<span># Query the model for answers</span>
<span>query</span> <span>=</span> <span>"How are the mutual relationships between the main characters?"</span>

<span>res</span> <span>=</span> <span>memo_model</span>.<span>answer</span>(<span>query</span>)
<span>print</span>(<span>"Using memory to answer the query:<span>\n</span>"</span>, <span>res</span>)

<span># Recall text clues for evidence retrieval</span>
<span>res</span> <span>=</span> <span>memo_model</span>.<span>recall</span>(<span>query</span>)
<span>print</span>(<span>"Using memory to recall text clues to support evidence retrieval:<span>\n</span>"</span>, <span>res</span>)

<span># Rewrite the query into more specific surrogate queries</span>
<span>res</span> <span>=</span> <span>memo_model</span>.<span>rewrite</span>(<span>query</span>)
<span>print</span>(<span>"Using memory to rewrite the input query into more specific surrogate queries:<span>\n</span>"</span>, <span>res</span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Usage for Memory-Augmented Retrieval</h3><a id="user-content-usage-for-memory-augmented-retrieval" aria-label="Permalink: Usage for Memory-Augmented Retrieval" href="#usage-for-memory-augmented-retrieval"></a></p>
<p dir="auto">In addition to the standalone Memory Model, MemoRAG provides memory-augmented retrieval functionality. This allows for improved evidence retrieval based on recalled clues from memory.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from memorag import MemoRAG

# Initialize MemoRAG pipeline
pipe = MemoRAG(
    mem_model_name_or_path=&quot;TommyChien/memorag-qwen2-7b-inst&quot;,
    ret_model_name_or_path=&quot;BAAI/bge-m3&quot;,
    cache_dir=&quot;path_to_model_cache&quot;,  # Optional: specify local model cache directory
    access_token=&quot;hugging_face_access_token&quot;  # Optional: Hugging Face access token
)

# Load and memorize the context
test_txt = open(&quot;harry_potter.txt&quot;).read()
pipe.memorize(test_txt, save_dir=&quot;cache/harry_potter/&quot;, print_stats=True)

# Define the query
query = &quot;How are the mutual relationships between the main characters?&quot;

# Recall clues from memory
clues = pipe.mem_model.recall(query).split(&quot;\n&quot;)
clues = [q for q in clues if len(q.split()) > 3]  # Filter out short or irrelevant clues
print(&quot;Clues generated from memory:\n&quot;, clues)

# Retrieve relevant passages based on the recalled clues
retrieved_passages = pipe._retrieve(clues)
print(&quot;\n======\n&quot;.join(retrieved_passages[:3]))"><pre><span>from</span> <span>memorag</span> <span>import</span> <span>MemoRAG</span>

<span># Initialize MemoRAG pipeline</span>
<span>pipe</span> <span>=</span> <span>MemoRAG</span>(
    <span>mem_model_name_or_path</span><span>=</span><span>"TommyChien/memorag-qwen2-7b-inst"</span>,
    <span>ret_model_name_or_path</span><span>=</span><span>"BAAI/bge-m3"</span>,
    <span>cache_dir</span><span>=</span><span>"path_to_model_cache"</span>,  <span># Optional: specify local model cache directory</span>
    <span>access_token</span><span>=</span><span>"hugging_face_access_token"</span>  <span># Optional: Hugging Face access token</span>
)

<span># Load and memorize the context</span>
<span>test_txt</span> <span>=</span> <span>open</span>(<span>"harry_potter.txt"</span>).<span>read</span>()
<span>pipe</span>.<span>memorize</span>(<span>test_txt</span>, <span>save_dir</span><span>=</span><span>"cache/harry_potter/"</span>, <span>print_stats</span><span>=</span><span>True</span>)

<span># Define the query</span>
<span>query</span> <span>=</span> <span>"How are the mutual relationships between the main characters?"</span>

<span># Recall clues from memory</span>
<span>clues</span> <span>=</span> <span>pipe</span>.<span>mem_model</span>.<span>recall</span>(<span>query</span>).<span>split</span>(<span>"<span>\n</span>"</span>)
<span>clues</span> <span>=</span> [<span>q</span> <span>for</span> <span>q</span> <span>in</span> <span>clues</span> <span>if</span> <span>len</span>(<span>q</span>.<span>split</span>()) <span>&gt;</span> <span>3</span>]  <span># Filter out short or irrelevant clues</span>
<span>print</span>(<span>"Clues generated from memory:<span>\n</span>"</span>, <span>clues</span>)

<span># Retrieve relevant passages based on the recalled clues</span>
<span>retrieved_passages</span> <span>=</span> <span>pipe</span>.<span>_retrieve</span>(<span>clues</span>)
<span>print</span>(<span>"<span>\n</span>======<span>\n</span>"</span>.<span>join</span>(<span>retrieved_passages</span>[:<span>3</span>]))</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Evaluation on Benchmark</h3><a id="user-content-evaluation-on-benchmark" aria-label="Permalink: Evaluation on Benchmark" href="#evaluation-on-benchmark"></a></p>
<p dir="auto">Below are experiments results for the memory model, incorporating with three generation models.</p>
<markdown-accessiblity-table>
    We test MemoRAG on three benchmarks. The best results of each block are in bold.
    <table><thead>
        <tr>
            <th>Dataset</th>
            <th>NarrativeQA</th>
            <th>Qasper</th>
            <th>MultifieldQA</th>
            <th>Musique</th>
            <th>2Wiki</th>
            <th>HotpotQA</th>
            <th>MultiNews</th>
            <th>GovReport</th>
            <th>En.sum</th>
            <th>En.qa</th>
            <th>Fin</th>
            <th>Legal</th>
            <th>Mix</th>
        </tr>
        <tr>
            <td></td>
            <td colspan="8"><strong>LongBench</strong></td>
            <td colspan="2"><strong>InfBench</strong></td>
            <td colspan="3"><strong>UltraDomain</strong></td>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td colspan="13"><strong>Generator: Llama3-8B-Instruct-8K</strong></td>
        </tr>
        <tr>
            <td>Full</td>
            <td>21.3</td>
            <td>43.4</td>
            <td>46.6</td>
            <td>23.5</td>
            <td>38.2</td>
            <td>47.1</td>
            <td>24.6</td>
            <td>23.6</td>
            <td>13.1</td>
            <td>6.7</td>
            <td>34.2</td>
            <td>33.2</td>
            <td>42.7</td>
        </tr>
        <tr>
            <td>BGE-M3</td>
            <td>22.1</td>
            <td>44.3</td>
            <td>50.2</td>
            <td>22.2</td>
            <td>36.7</td>
            <td>48.4</td>
            <td>22.1</td>
            <td>20.1</td>
            <td>12.1</td>
            <td>15.1</td>
            <td>41.4</td>
            <td>40.6</td>
            <td>46.4</td>
        </tr>
        <tr>
            <td>Stella-v5</td>
            <td>12.3</td>
            <td>35.2</td>
            <td>44.4</td>
            <td>22.1</td>
            <td>33.3</td>
            <td>41.9</td>
            <td>22.1</td>
            <td>20.7</td>
            <td>11.7</td>
            <td>14.8</td>
            <td>41.9</td>
            <td>33.7</td>
            <td>44.9</td>
        </tr>
        <tr>
            <td>RQ-RAG</td>
            <td>20.2</td>
            <td>43.9</td>
            <td>49.1</td>
            <td>22.7</td>
            <td>36.1</td>
            <td>44.5</td>
            <td>20.6</td>
            <td>21.0</td>
            <td>12.0</td>
            <td>13.3</td>
            <td>39.5</td>
            <td>36.8</td>
            <td>44.5</td>
        </tr>
        <tr>
            <td>HyDE</td>
            <td>22.1</td>
            <td>44.3</td>
            <td>50.2</td>
            <td>22.2</td>
            <td>36.7</td>
            <td>48.4</td>
            <td>-</td>
            <td>-</td>
            <td>-</td>
            <td><strong>19.1</strong></td>
            <td>41.4</td>
            <td>40.6</td>
            <td>46.4</td>
        </tr>
        <tr>
            <td><strong>MemoRAG</strong></td>
            <td><strong>22.8</strong></td>
            <td><strong>45.7</strong></td>
            <td><strong>50.7</strong></td>
            <td><strong>28.4</strong></td>
            <td><strong>51.4</strong></td>
            <td><strong>57.0</strong></td>
            <td><strong>27.4</strong></td>
            <td><strong>27.9</strong></td>
            <td><strong>14.1</strong></td>
            <td>16.1</td>
            <td><strong>47.8</strong></td>
            <td><strong>47.9</strong></td>
            <td><strong>55.5</strong></td>
        </tr>
        <tr>
            <td colspan="13"><strong>Generator: Phi-3-mini-128K</strong></td>
        </tr>
        <tr>
            <td>Full</td>
            <td>21.4</td>
            <td>35.0</td>
            <td>47.3</td>
            <td>19.0</td>
            <td>35.5</td>
            <td>42.1</td>
            <td>25.6</td>
            <td>23.7</td>
            <td>13.0</td>
            <td>15.2</td>
            <td>44.8</td>
            <td>40.5</td>
            <td>44.7</td>
        </tr>
        <tr>
            <td>BGE-M3</td>
            <td>20.3</td>
            <td>33.0</td>
            <td>44.3</td>
            <td>21.1</td>
            <td>35.4</td>
            <td>42.1</td>
            <td>17.7</td>
            <td>19.8</td>
            <td>9.6</td>
            <td>16.3</td>
            <td>41.7</td>
            <td>41.2</td>
            <td>43.7</td>
        </tr>
        <tr>
            <td>Stella-v5</td>
            <td>13.7</td>
            <td>32.4</td>
            <td>43.5</td>
            <td>21.0</td>
            <td>35.6</td>
            <td>40.6</td>
            <td>20.3</td>
            <td>18.2</td>
            <td>10.0</td>
            <td>19.5</td>
            <td>42.8</td>
            <td>35.1</td>
            <td>43.9</td>
        </tr>
        <tr>
            <td>RQ-RAG</td>
            <td>19.6</td>
            <td>34.1</td>
            <td>46.5</td>
            <td>21.9</td>
            <td>36.1</td>
            <td>41.7</td>
            <td>20.1</td>
            <td>18.6</td>
            <td>10.4</td>
            <td>16.1</td>
            <td>41.8</td>
            <td>40.9</td>
            <td>43.2</td>
        </tr>
        <tr>
            <td>HyDE</td>
            <td>18.7</td>
            <td>36.0</td>
            <td>47.5</td>
            <td>20.5</td>
            <td>36.8</td>
            <td>42.7</td>
            <td>-</td>
            <td>-</td>
            <td>-</td>
            <td>19.6</td>
            <td>43.1</td>
            <td>41.6</td>
            <td>44.2</td>
        </tr>
        <tr>
            <td><strong>MemoRAG</strong></td>
            <td><strong>27.5</strong></td>
            <td><strong>43.9</strong></td>
            <td><strong>52.2</strong></td>
            <td><strong>33.9</strong></td>
            <td><strong>54.1</strong></td>
            <td><strong>54.8</strong></td>
            <td><strong>32.9</strong></td>
            <td><strong>26.3</strong></td>
            <td><strong>15.7</strong></td>
            <td><strong>22.9</strong></td>
            <td><strong>51.5</strong></td>
            <td><strong>51.0</strong></td>
            <td><strong>55.6</strong></td>
        </tr>
        <tr>
            <td colspan="13"><strong>Generator: Mistral-7B-Instruct-v0.2-32K</strong></td>
        </tr>
        <tr>
            <td>Full</td>
            <td>20.8</td>
            <td>29.2</td>
            <td>46.3</td>
            <td>18.9</td>
            <td>20.6</td>
            <td>37.6</td>
            <td>23.0</td>
            <td>20.4</td>
            <td>12.4</td>
            <td>12.3</td>
            <td>36.5</td>
            <td>35.8</td>
            <td>42.1</td>
        </tr>
        <tr>
            <td>BGE-M3</td>
            <td>17.3</td>
            <td>29.5</td>
            <td>46.3</td>
            <td>18.5</td>
            <td>20.3</td>
            <td>36.2</td>
            <td>24.3</td>
            <td>26.1</td>
            <td>13.5</td>
            <td>12.2</td>
            <td>40.5</td>
            <td>42.0</td>
            <td>41.1</td>
        </tr>
        <tr>
            <td>Stella-v5</td>
            <td>13.5</td>
            <td>23.7</td>
            <td>42.1</td>
            <td>18.6</td>
            <td>22.2</td>
            <td>31.9</td>
            <td>21.1</td>
            <td>18.5</td>
            <td>13.2</td>
            <td>9.7</td>
            <td>40.9</td>
            <td>34.9</td>
            <td>42.1</td>
        </tr>
        <tr>
            <td>RQ-RAG</td>
            <td>17.1</td>
            <td>29.2</td>
            <td>47.0</td>
            <td>19.1</td>
            <td>21.5</td>
            <td>37.0</td>
            <td>22.1</td>
            <td>18.6</td>
            <td>13.1</td>
            <td>12.7</td>
            <td>44.3</td>
            <td>44.6</td>
            <td>43.4</td>
        </tr>
        <tr>
            <td>HyDE</td>
            <td>17.4</td>
            <td>29.5</td>
            <td>46.3</td>
            <td>18.5</td>
            <td>20.1</td>
            <td>36.2</td>
            <td>-</td>
            <td>-</td>
            <td>-</td>
            <td>12.2</td>
            <td>42.8</td>
            <td>35.1</td>
            <td>43.9</td>
        </tr>
        <tr>
            <td><strong>MemoRAG</strong></td>
            <td><strong>23.1</strong></td>
            <td>31.2</td>
            <td><strong>50.0</strong></td>
            <td>26.9</td>
            <td>30.3</td>
            <td>42.9</td>
            <td><strong>27.1</strong></td>
            <td><strong>31.6</strong></td>
            <td><strong>17.9</strong></td>
            <td>15.4</td>
            <td>48.0</td>
            <td>51.2</td>
            <td><strong>53.6</strong></td>
        </tr>
        <tr>
            <td><strong>MemoRAG-qwen2</strong></td>
            <td>22.2</td>
            <td><strong>32.7</strong></td>
            <td>49.6</td>
            <td><strong>31.4</strong></td>
            <td><strong>33.7</strong></td>
            <td><strong>44.4</strong></td>
            <td>27.0</td>
            <td>31.5</td>
            <td>16.8</td>
            <td><strong>17.6</strong></td>
            <td><strong>48.7</strong></td>
            <td><strong>52.3</strong></td>
            <td>48.6</td>
        </tr>
    </tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Evaluation</h3><a id="user-content-evaluation" aria-label="Permalink: Evaluation" href="#evaluation"></a></p>
<p dir="auto">To evaluate MemoRAG, use the following script:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd examples
bash longbench/eval.sh"><pre><span>cd</span> examples
bash longbench/eval.sh</pre></div>
<p dir="auto">We will update other evaluation scripts soon.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Dataset</h3><a id="user-content-dataset" aria-label="Permalink: Dataset" href="#dataset"></a></p>
<p dir="auto">UltraDomain Benchmark: <a href="https://huggingface.co/datasets/TommyChien/UltraDomain" rel="nofollow">this repo</a>.</p>
<p dir="auto">Other Evaluation Data: <a href="https://huggingface.co/datasets/TommyChien/MemoRAG-data/" rel="nofollow">this repo</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🙌 FAQs</h2><a id="user-content-raised_hands-faqs" aria-label="Permalink: :raised_hands: FAQs" href="#raised_hands-faqs"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔖 License</h2><a id="user-content-bookmark-license" aria-label="Permalink: :bookmark: License" href="#bookmark-license"></a></p>
<p dir="auto">MemoRAG is licensed under the <a href="https://github.com/qhjqhj00/MemoRAG/blob/main/LICENSE">MIT License</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Citation</h2><a id="user-content-citation" aria-label="Permalink: Citation" href="#citation"></a></p>
<p dir="auto">If you use MemoRAG in your research, please cite our paper:</p>
<div dir="auto" data-snippet-clipboard-copy-content="@misc{qian2024memorag,
      title={MemoRAG: Moving towards Next-Gen RAG Via Memory-Inspired Knowledge Discovery}, 
      author={Hongjin Qian and Peitian Zhang and Zheng Liu and Kelong Mao and Zhicheng Dou},
      year={2024},
      eprint={2409.05591},
      url={https://arxiv.org/abs/2409.05591}, 
}"><pre><span>@misc</span>{<span>qian2024memorag</span>,
      <span>title</span>=<span><span>{</span>MemoRAG: Moving towards Next-Gen RAG Via Memory-Inspired Knowledge Discovery<span>}</span></span>, 
      <span>author</span>=<span><span>{</span>Hongjin Qian and Peitian Zhang and Zheng Liu and Kelong Mao and Zhicheng Dou<span>}</span></span>,
      <span>year</span>=<span><span>{</span>2024<span>}</span></span>,
      <span>eprint</span>=<span><span>{</span>2409.05591<span>}</span></span>,
      <span>url</span>=<span><span>{</span>https://arxiv.org/abs/2409.05591<span>}</span></span>, 
}</pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reactive Relational Algebra (108 pts)]]></title>
            <link>https://taylor.town/reactive-relational-algebra</link>
            <guid>41602056</guid>
            <pubDate>Fri, 20 Sep 2024 13:54:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://taylor.town/reactive-relational-algebra">https://taylor.town/reactive-relational-algebra</a>, See on <a href="https://news.ycombinator.com/item?id=41602056">Hacker News</a></p>
Couldn't get https://taylor.town/reactive-relational-algebra: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[CuPy: NumPy and SciPy for GPU (275 pts)]]></title>
            <link>https://github.com/cupy/cupy</link>
            <guid>41601730</guid>
            <pubDate>Fri, 20 Sep 2024 13:18:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/cupy/cupy">https://github.com/cupy/cupy</a>, See on <a href="https://news.ycombinator.com/item?id=41601730">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/cupy/cupy/main/docs/image/cupy_logo_1000px.png"><img src="https://raw.githubusercontent.com/cupy/cupy/main/docs/image/cupy_logo_1000px.png" width="400"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">CuPy : NumPy &amp; SciPy for GPU</h2><a id="user-content-cupy--numpy--scipy-for-gpu" aria-label="Permalink: CuPy : NumPy &amp; SciPy for GPU" href="#cupy--numpy--scipy-for-gpu"></a></p>
<p dir="auto"><a href="https://pypi.python.org/pypi/cupy" rel="nofollow"><img src="https://camo.githubusercontent.com/9f42f93fc2988966b22e8d1fe20d80081269ad0cdd9f7ec6d1733263f8e91c14/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f63757079" alt="pypi" data-canonical-src="https://img.shields.io/pypi/v/cupy"></a>
<a href="https://anaconda.org/conda-forge/cupy" rel="nofollow"><img src="https://camo.githubusercontent.com/44ea99a7b25703ede08c667128fb8017deb1f135463fa458274f93f8bec01e05/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f6e64612d2d666f7267652d637570792d626c7565" alt="Conda" data-canonical-src="https://img.shields.io/badge/conda--forge-cupy-blue"></a>
<a href="https://github.com/cupy/cupy"><img src="https://camo.githubusercontent.com/f000c610f4fc21ef53c9bad299fcecf7fa7b099c5dbff5a411734fdffb558dfd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f637570792f63757079" alt="GitHub license" data-canonical-src="https://img.shields.io/github/license/cupy/cupy"></a>
<a href="https://gitter.im/cupy/community" rel="nofollow"><img src="https://camo.githubusercontent.com/765ca66b2fe7f52347e995ca4de6c9d5fb07e02bfa9a9bae4c556c2e5e8e9568/68747470733a2f2f696d672e736869656c64732e696f2f6d61747269782f637570795f636f6d6d756e6974793a6769747465722e696d3f7365727665725f6671646e3d6d61747269782e6f7267" alt="Matrix" data-canonical-src="https://img.shields.io/matrix/cupy_community:gitter.im?server_fqdn=matrix.org"></a>
<a href="https://twitter.com/CuPy_Team" rel="nofollow"><img src="https://camo.githubusercontent.com/4884e27583c170dca1d21677b65e14db365e0d916af4c99fc596d42ffb2ea1eb/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f437550795f5465616d3f6c6162656c3d253430437550795f5465616d" alt="Twitter" data-canonical-src="https://img.shields.io/twitter/follow/CuPy_Team?label=%40CuPy_Team"></a>
<a href="https://medium.com/cupy-team" rel="nofollow"><img src="https://camo.githubusercontent.com/d346eda24b15079eac1881c68671ba74545ba72e98e286e0361626a2becda086/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d656469756d2d437550792d7465616c" alt="Medium" data-canonical-src="https://img.shields.io/badge/Medium-CuPy-teal"></a></p>
<p dir="auto"><a href="https://cupy.dev/" rel="nofollow"><strong>Website</strong></a>
| <a href="https://docs.cupy.dev/en/stable/install.html" rel="nofollow"><strong>Install</strong></a>
| <a href="https://docs.cupy.dev/en/stable/user_guide/basic.html" rel="nofollow"><strong>Tutorial</strong></a>
| <a href="https://github.com/cupy/cupy/tree/main/examples"><strong>Examples</strong></a>
| <a href="https://docs.cupy.dev/en/stable/" rel="nofollow"><strong>Documentation</strong></a>
| <a href="https://docs.cupy.dev/en/stable/reference/" rel="nofollow"><strong>API Reference</strong></a>
| <a href="https://groups.google.com/forum/#!forum/cupy" rel="nofollow"><strong>Forum</strong></a></p>
<p dir="auto">CuPy is a NumPy/SciPy-compatible array library for GPU-accelerated computing with Python.
CuPy acts as a <a href="https://docs.cupy.dev/en/stable/reference/comparison.html" rel="nofollow">drop-in replacement</a> to run existing NumPy/SciPy code on NVIDIA CUDA or AMD ROCm platforms.</p>
<div dir="auto" data-snippet-clipboard-copy-content=">>> import cupy as cp
>>> x = cp.arange(6).reshape(2, 3).astype('f')
>>> x
array([[ 0.,  1.,  2.],
       [ 3.,  4.,  5.]], dtype=float32)
>>> x.sum(axis=1)
array([  3.,  12.], dtype=float32)"><pre><span>&gt;&gt;</span><span>&gt;</span> <span>import</span> <span>cupy</span> <span>as</span> <span>cp</span>
<span>&gt;&gt;</span><span>&gt;</span> <span>x</span> <span>=</span> <span>cp</span>.<span>arange</span>(<span>6</span>).<span>reshape</span>(<span>2</span>, <span>3</span>).<span>astype</span>(<span>'f'</span>)
<span>&gt;&gt;</span><span>&gt;</span> <span>x</span>
<span>array</span>([[ <span>0.</span>,  <span>1.</span>,  <span>2.</span>],
       [ <span>3.</span>,  <span>4.</span>,  <span>5.</span>]], <span>dtype</span><span>=</span><span>float32</span>)
<span>&gt;&gt;</span><span>&gt;</span> <span>x</span>.<span>sum</span>(<span>axis</span><span>=</span><span>1</span>)
<span>array</span>([  <span>3.</span>,  <span>12.</span>], <span>dtype</span><span>=</span><span>float32</span>)</pre></div>
<p dir="auto">CuPy also provides access to low-level CUDA features.
You can pass <code>ndarray</code> to existing CUDA C/C++ programs via <a href="https://docs.cupy.dev/en/stable/user_guide/kernel.html#raw-kernels" rel="nofollow">RawKernels</a>, use <a href="https://docs.cupy.dev/en/stable/reference/cuda.html" rel="nofollow">Streams</a> for performance, or even call <a href="https://docs.cupy.dev/en/stable/reference/cuda.html#runtime-api" rel="nofollow">CUDA Runtime APIs</a> directly.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Pip</h3><a id="user-content-pip" aria-label="Permalink: Pip" href="#pip"></a></p>
<p dir="auto">Binary packages (wheels) are available for Linux and Windows on <a href="https://pypi.org/org/cupy/" rel="nofollow">PyPI</a>.
Choose the right package for your platform.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Platform</th>
<th>Architecture</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>CUDA 11.x (11.2+)</td>
<td>x86_64 / aarch64</td>
<td><code>pip install cupy-cuda11x</code></td>
</tr>
<tr>
<td>CUDA 12.x</td>
<td>x86_64 / aarch64</td>
<td><code>pip install cupy-cuda12x</code></td>
</tr>
<tr>
<td>ROCm 4.3 (<em><a href="https://docs.cupy.dev/en/latest/install.html#using-cupy-on-amd-gpu-experimental" rel="nofollow">experimental</a></em>)</td>
<td>x86_64</td>
<td><code>pip install cupy-rocm-4-3</code></td>
</tr>
<tr>
<td>ROCm 5.0 (<em><a href="https://docs.cupy.dev/en/latest/install.html#using-cupy-on-amd-gpu-experimental" rel="nofollow">experimental</a></em>)</td>
<td>x86_64</td>
<td><code>pip install cupy-rocm-5-0</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">To install pre-releases, append <code>--pre -U -f https://pip.cupy.dev/pre</code> (e.g., <code>pip install cupy-cuda11x --pre -U -f https://pip.cupy.dev/pre</code>).</p>
</div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Conda</h3><a id="user-content-conda" aria-label="Permalink: Conda" href="#conda"></a></p>
<p dir="auto">Binary packages are also available for Linux and Windows on <a href="https://anaconda.org/conda-forge/cupy" rel="nofollow">Conda-Forge</a>.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Platform</th>
<th>Architecture</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>CUDA</td>
<td>x86_64 / aarch64 / ppc64le</td>
<td><code>conda install -c conda-forge cupy</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">If you need a slim installation (without also getting CUDA dependencies installed), you can do <code>conda install -c conda-forge cupy-core</code>.</p>
<p dir="auto">If you need to use a particular CUDA version (say 12.0), you can use the <code>cuda-version</code> metapackage to select the version, e.g. <code>conda install -c conda-forge cupy cuda-version=12.0</code>.</p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">If you encounter any problem with CuPy installed from <code>conda-forge</code>, please feel free to report to <a href="https://github.com/conda-forge/cupy-feedstock/issues">cupy-feedstock</a>, and we will help investigate if it is just a packaging issue in <code>conda-forge</code>'s recipe or a real issue in CuPy.</p>
</div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Docker</h3><a id="user-content-docker" aria-label="Permalink: Docker" href="#docker"></a></p>
<p dir="auto">Use <a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/overview.html" rel="nofollow">NVIDIA Container Toolkit</a> to run <a href="https://hub.docker.com/r/cupy/cupy" rel="nofollow">CuPy container images</a>.</p>
<div data-snippet-clipboard-copy-content="$ docker run --gpus all -it cupy/cupy"><pre><code>$ docker run --gpus all -it cupy/cupy
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Resources</h2><a id="user-content-resources" aria-label="Permalink: Resources" href="#resources"></a></p>
<ul dir="auto">
<li><a href="https://docs.cupy.dev/en/stable/install.html" rel="nofollow">Installation Guide</a> - instructions on building from source</li>
<li><a href="https://github.com/cupy/cupy/releases">Release Notes</a></li>
<li><a href="https://github.com/cupy/cupy/wiki/Projects-using-CuPy">Projects using CuPy</a></li>
<li><a href="https://docs.cupy.dev/en/stable/contribution.html" rel="nofollow">Contribution Guide</a></li>
<li><a href="https://www.nvidia.com/en-us/on-demand/session/gtcfall21-a31149/" rel="nofollow">GPU Acceleration in Python using CuPy and Numba (GTC November 2021 Technical Session)</a></li>
<li><a href="https://github.com/awthomp/cusignal-icassp-tutorial">GPU-Acceleration of Signal Processing Workflows using CuPy and cuSignal<sup></sup></a><a href="#user-content-fn-1-0eaf4d7645e187ce6caba1b7a4030a5e" id="user-content-fnref-1-0eaf4d7645e187ce6caba1b7a4030a5e" data-footnote-ref="" aria-describedby="footnote-label">1</a> (ICASSP'21 Tutorial)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">MIT License (see <code>LICENSE</code> file).</p>
<p dir="auto">CuPy is designed based on NumPy's API and SciPy's API (see <code>docs/source/license.rst</code> file).</p>
<p dir="auto">CuPy is being developed and maintained by <a href="https://www.preferred.jp/en/" rel="nofollow">Preferred Networks</a> and <a href="https://github.com/cupy/cupy/graphs/contributors">community contributors</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Reference</h2><a id="user-content-reference" aria-label="Permalink: Reference" href="#reference"></a></p>
<p dir="auto">Ryosuke Okuta, Yuya Unno, Daisuke Nishino, Shohei Hido and Crissman Loomis.
<strong>CuPy: A NumPy-Compatible Library for NVIDIA GPU Calculations.</strong>
<em>Proceedings of Workshop on Machine Learning Systems (LearningSys) in The Thirty-first Annual Conference on Neural Information Processing Systems (NIPS)</em>, (2017).
[<a href="http://learningsys.org/nips17/assets/papers/paper_16.pdf" rel="nofollow">PDF</a>]</p>
<div dir="auto" data-snippet-clipboard-copy-content="@inproceedings{cupy_learningsys2017,
  author       = &quot;Okuta, Ryosuke and Unno, Yuya and Nishino, Daisuke and Hido, Shohei and Loomis, Crissman&quot;,
  title        = &quot;CuPy: A NumPy-Compatible Library for NVIDIA GPU Calculations&quot;,
  booktitle    = &quot;Proceedings of Workshop on Machine Learning Systems (LearningSys) in The Thirty-first Annual Conference on Neural Information Processing Systems (NIPS)&quot;,
  year         = &quot;2017&quot;,
  url          = &quot;http://learningsys.org/nips17/assets/papers/paper_16.pdf&quot;
}"><pre><span>@inproceedings</span>{<span>cupy_learningsys2017</span>,
  <span>author</span>       = <span><span>"</span>Okuta, Ryosuke and Unno, Yuya and Nishino, Daisuke and Hido, Shohei and Loomis, Crissman<span>"</span></span>,
  <span>title</span>        = <span><span>"</span>CuPy: A NumPy-Compatible Library for NVIDIA GPU Calculations<span>"</span></span>,
  <span>booktitle</span>    = <span><span>"</span>Proceedings of Workshop on Machine Learning Systems (LearningSys) in The Thirty-first Annual Conference on Neural Information Processing Systems (NIPS)<span>"</span></span>,
  <span>year</span>         = <span><span>"</span>2017<span>"</span></span>,
  <span>url</span>          = <span><span>"</span>http://learningsys.org/nips17/assets/papers/paper_16.pdf<span>"</span></span>
}</pre></div>
<section data-footnotes="">
<ol dir="auto">
<li id="user-content-fn-1-0eaf4d7645e187ce6caba1b7a4030a5e">
<p dir="auto">cuSignal is now part of CuPy starting v13.0.0. <a href="#user-content-fnref-1-0eaf4d7645e187ce6caba1b7a4030a5e" data-footnote-backref="" aria-label="Back to reference 1">↩</a></p>
</li>
</ol>
</section>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft TypeSpec (102 pts)]]></title>
            <link>https://typespec.io/</link>
            <guid>41601728</guid>
            <pubDate>Fri, 20 Sep 2024 13:18:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://typespec.io/">https://typespec.io/</a>, See on <a href="https://news.ycombinator.com/item?id=41601728">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Three Mile Island nuclear plant restart in Microsoft AI power deal (142 pts)]]></title>
            <link>https://www.reuters.com/markets/deals/constellation-inks-power-supply-deal-with-microsoft-2024-09-20/</link>
            <guid>41601443</guid>
            <pubDate>Fri, 20 Sep 2024 12:43:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/markets/deals/constellation-inks-power-supply-deal-with-microsoft-2024-09-20/">https://www.reuters.com/markets/deals/constellation-inks-power-supply-deal-with-microsoft-2024-09-20/</a>, See on <a href="https://news.ycombinator.com/item?id=41601443">Hacker News</a></p>
Couldn't get https://www.reuters.com/markets/deals/constellation-inks-power-supply-deal-with-microsoft-2024-09-20/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Tō Reo – A Māori Spellchecker (118 pts)]]></title>
            <link>https://xn--treo-l3a.nz/</link>
            <guid>41601347</guid>
            <pubDate>Fri, 20 Sep 2024 12:30:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://xn--treo-l3a.nz/">https://xn--treo-l3a.nz/</a>, See on <a href="https://news.ycombinator.com/item?id=41601347">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <main>
        

        <form id="index-form">
            
            
            
            
        </form>

        <a id="sample1" href="#">
            Generate example text
        </a>

        
    </main>

    



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Linux/4004: booting Linux on Intel 4004 for fun, art, and no profit (412 pts)]]></title>
            <link>https://dmitry.gr/?r=05.Projects&amp;proj=35.%20Linux4004</link>
            <guid>41600756</guid>
            <pubDate>Fri, 20 Sep 2024 11:04:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dmitry.gr/?r=05.Projects&#x26;proj=35.%20Linux4004">https://dmitry.gr/?r=05.Projects&#x26;proj=35.%20Linux4004</a>, See on <a href="https://news.ycombinator.com/item?id=41600756">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>




<p><span>Linux/4004</span></p><h2>Slowly booting full Linux on the intel 4004 for fun, art, and absolutely no profit</h2>

<div>
	<iframe width="420" height="290" src="https://www.youtube-nocookie.com/embed/NQZZ21WZZr0?si=5Bas4xs2q0GeOoJi" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
	<p>
	(fullscreen viewing recommended)
</p></div>

<h3>TL;DR</h3>
<p>I booted Debian Linux on a 4-bit intel microprocessor from 1971 - the first microprocessor in the world - the 4004. It is not fast, but it is a real Linux kernel with a Debian rootfs on a real board whose only CPU is a real intel 4004 from the 1970s. The video is sped up at variable rates to demonstarte this without boring you. The clock and calendar in the video are accurate. A constant-rate video is linked below.
</p>

<h2>Table of Contents</h2>
<p><a href="https://dmitry.gr/images/4004finalBoard.jpg"><img alt="The final rev 1.2 Linux/4004 board looking beautiful, showing Linux kernel boot progress approx 10 virtual seconds into the boot" src="https://dmitry.gr/images/4004finalBoardSmall.jpg"></a></p><ol type="1"><li><a href="#_TOC_be1dd0e35f083e5083175fa81b794866">In the beginning...</a></li><li><a href="#_TOC_5fdc0598025da19a5898b404138aed30">The 4004</a><ol type="a"><li><a href="#_TOC_8266cc51bf54f7d5c15292636337c059">Like we did in the good ol' days</a></li><li><a href="#_TOC_7e094caa5b6056d40c3127d596575a35">But with a twist...</a></li><li><a href="#_TOC_cf30e3ebec809abb53898e7cda3f9497">Control flow in the 4004</a></li><li><a href="#_TOC_190ca37686b16e15868f0c06beb08d6c">Memory and I/O in the 4004</a><ol type="I"><li><a href="#_TOC_a3925810ed3fb1d8a4e335089ef6a8da">4001 and 4308</a></li><li><a href="#_TOC_254ed7d2de3b23ab10936522dd547b78">4002</a></li><li><a href="#_TOC_53c5b2affa12eed84dfec9bfd83550b1">4265</a></li><li><a href="#_TOC_65199bdd314eec671e509474d8ee359c">4008, 4009, and 4289</a></li><li><a href="#_TOC_77a63b853e8190212f411a82d565f293">Using memory, and those "status nibbles"</a></li></ol></li><li><a href="#_TOC_332eb9d92af7d4f5e3e6390efd091c7e">Performance and clocking</a></li><li><a href="#_TOC_4adc239df1d451dbc67cd4a6ce3c520d">Some more annoying weirdness</a></li></ol></li><li><a href="#_TOC_411e79ebb4981efce9ce6a2b1f40a34f">Initial planning</a><ol type="a"><li><a href="#_TOC_e0ca0ff6296e18066f4e70c8afe2190e">Let's make a dev board</a></li><li><a href="#_TOC_38895bf939f056cd960d0cc0e3b52be6">Emulating my 4004 system</a></li></ol></li><li><a href="#_TOC_6cd03fe22e73587a2147bd353d8c3391">The MIPS emulator</a><ol type="a"><li><a href="#_TOC_6e4be76702e2cb4aa9bdacb486549f15">Why MIPS</a></li><li><a href="#_TOC_9e981d2809aaa3a1a4d544cf30dbdf5c">A start</a></li><li><a href="#_TOC_a2e346edae3f83cd6f06f8a115451d66">Logical ops</a></li><li><a href="#_TOC_b4de791fdbe86237d4c943e0c19090a2">Shifts</a></li><li><a href="#_TOC_56a98088b6df74cdc6914938ba705986">Space optimization and 4004-specifics</a></li><li><a href="#_TOC_3a173782d010897c6136c3b4ca51cd47">Hypercalls</a></li><li><a href="#_TOC_3bc4746900b3ceecf8842e2598a4e32d">Second-order hypercalls</a></li><li><a href="#_TOC_060a7543e09207206d528984fb737b61">It is tight</a></li><li><a href="#_TOC_c8163a18f475d5a7e1b692f0bae78e93">SD card driver and the last of the ROM space</a></li></ol></li><li><a href="#_TOC_6e99b6b14f775b96a819e6706cb65994">The emulator needs more ROM</a><ol type="a"><li><a href="#_TOC_bbf6d47336d0a53cf4727d383af1fc84">How to make ROM banking work</a></li><li><a href="#_TOC_3dcc73dc5a9b65ba500cb0d62f98ef5b">Now that I have space...</a></li></ol></li><li><a href="#_TOC_3c02a379965ab0dfcd77b1c484450433">Hardware</a><ol type="a"><li><a href="#_TOC_6a704df1b77e73c0f40027a59e6dd801">SPI PSRAM</a></li><li><a href="#_TOC_248cde53b8fc4710c770a7a26cbea2c8">The VFD</a></li><li><a href="#_TOC_35972f6dc4aef8cc22eda0b02f630623">The UART</a></li><li><a href="#_TOC_b3bca982d722112f438a1a6f1d74a549">The blinkenlights</a></li><li><a href="#_TOC_a36188d287a8f7362891f70825c4b027">The easy level shifting</a></li><li><a href="#_TOC_a8619c8eb72aa921c7e8efe0d35c5313">The hard level-shifting problem</a></li><li><a href="#_TOC_620e2edf2db0c3c3cad57aeb246c6bfe">Power supplies</a></li></ol></li><li><a href="#_TOC_cf07b148648a8d1a7170d442369f48d4">How to debug the hardware</a><ol type="a"><li><a href="#_TOC_9fbbe48584665bca4a82b5d1a702141b">This is the 21st century!</a></li><li><a href="#_TOC_287ab006771acb37f4017515131b47e0">The garbled text mystery</a></li></ol></li><li><a href="#_TOC_73bb993f8d0d0955077635dbbd22e4df">More MIPS emulator fun</a><ol type="a"><li><a href="#_TOC_aba3b03dc06e17178e1a25eb11df345b">Memory translation</a></li><li><a href="#_TOC_9247a183d4fc78eb64b2b5e701a628a1">Debugging the emulator</a></li><li><a href="#_TOC_17b32100aef1fc19670be7fd58bc85df">MOV</a></li><li><a href="#_TOC_94d97e9f0912b2815121303e30ad3ed6">Playing tetris</a></li></ol></li><li><a href="#_TOC_1f02286eb5d98586d56319a6bfb648c4">Speed optimization</a><ol type="a"><li><a href="#_TOC_2ba0c1d2f0f117d4512ef6170fe0e015">Methodology</a></li><li><a href="#_TOC_4ea7755f84f02d23876d90be2f9765cf">Fetch</a></li><li><a href="#_TOC_6c40f5a54dc895ba9ef5d0c7f19bbef9">Memory copy</a></li><li><a href="#_TOC_9299f42b9d9d8285bbf46e18f6d5f72f">More RAM</a></li><li><a href="#_TOC_624241037a20b215eccbaa7ffa5f2c48">Clawing it back</a></li><li><a href="#_TOC_bc0fabaf8ddb58f69e276c5dc413aade">Better shifts</a></li><li><a href="#_TOC_bcddc9f780bfc5c6e6e43937d3662934">More RAM access unrolling</a></li><li><a href="#_TOC_43ba3704213960cc60d5bafbe4040ef1">A look at WHAT runs</a></li><li><a href="#_TOC_3917c04275c02f8e5c4ff095909b9c0a">Fetch again</a></li><li><a href="#_TOC_f72b4522375d4a10350e2308779ba651">On host CPU speed</a></li></ol></li><li><a href="#_TOC_4293d682eeb4fd64e06f45c81e3d1b74">Hardware cost optimization</a><ol type="a"><li><a href="#_TOC_07b3ff2e812bfe527d1e3865e8ec1077">"Affordability"</a></li><li><a href="#_TOC_0d561d3b16eab3d2a2dc947a0a84070d">The prices for 1971 chips</a></li><li><a href="#_TOC_e59fe98e32e11cafcedb7bef6f01c463">The modern parts</a></li></ol></li><li><a href="#_TOC_9ffdb95250e26c7a6b468126ac7c75b0">How it works</a><ol type="a"><li><a href="#_TOC_a0f9fb80c7a8aff949b88d373ce132c5">The connections</a></li><li><a href="#_TOC_d3317618724df783958db18e69f0be79">SD card access</a></li><li><a href="#_TOC_d5daf83fed7fff76baa5b9defcb6cabe">How it boots</a></li><li><a href="#_TOC_07ca99f949f794dba90a986ed2597084">How it runs</a></li></ol></li><li><a href="#_TOC_416effa1e4d6d5d56b7f70de020a3855">The art of it</a></li><li><a href="#_TOC_f38d6bd8d6cdf77459a99b4bfd21b3b3">I want one</a><ol type="a"><li><a href="#_TOC_ef662ffb9b5f284f734e742744a4ad56">Build one</a></li><li><a href="#_TOC_0adb053fdf8592dceb270571281dbe02">Kit or pre-built</a></li></ol></li><li><a href="#_TOC_09f015678a29b072cd217c3e89c5ce6e">Making of the video</a><ol type="a"><li><a href="#_TOC_62411b76d12a4ad116da05c356ff9bf3">Capturing</a></li><li><a href="#_TOC_09d32626886187fe94d86dca8ed0d3e8">Getting the data</a></li><li><a href="#_TOC_e68918e8e32e6a40900193a56d491f7f">Getting desperate</a></li><li><a href="#_TOC_98a3bc512f035d0d44b4c39901f814f5">Making the video</a></li></ol></li><li><a href="#_TOC_c20c35ef53bf1b70789ce94e66800147">Downloads</a></li><li><a href="#_TOC_948a2e3548aaf7f9941a3192fa607d51">Credits</a></li><li><a href="#_TOC_7e1e75c32bc9b275daf70df8cba8efb5">Comments...</a></li></ol>







<h2>In the beginning...</h2>
<p>In 2012, I <a href="https://dmitry.gr/?r=05.Projects&amp;proj=07.%20Linux%20on%208bit">ran real Linux on an 8-bit microcontroller (AVR)</a>, setting a new world record for lowest-end-machine to ever run Linux. A natural extension of that project was into something faster and more practical, and <a href="https://dmitry.gr/?r=05.Projects&amp;proj=33.%20LinuxCard">I did that</a>. Others also did <a href="https://hackaday.com/2014/04/09/using-simms-to-add-some-extra-ram-on-your-arduino-uno/">follow-up</a> work based on the original project. Some exciting work also happened based on my LinuxCard followup, my favourite being <a href="https://www.hackster.io/news/the-decstation-2040-puts-what-was-once-the-fastest-unix-system-in-the-world-in-your-wallet-f81000b9b51a">this gem</a>. Nobody really tackled the actual record for about eleven years. In 2023, there was <a href="https://github.com/raspiduino/arv32-opt">this advancement</a>. It is still an AVR, so it is not <em>much</em> lower-end, but it does use an AVR with less RAM, so it counts. This is especially true since the author was clearly aiming to beat my record (as per the <a href="https://github.com/raspiduino/arv32-opt/blob/main/README.md">README</a>). An even more impressive effort was seen, also in 2023, <a href="https://github.com/onnokort/semu-c64">here</a>. That one boots Linux (in emulation) on a <a href="https://en.wikipedia.org/wiki/MOS_Technology_6510">MOS 6510</a>. This is a much older-style 8-bit CPU and thus definitely counts as lower-end than an AVR. So, it seems that after 11 years on top (or...bottom), my record had been beaten. This would not do!
</p>
<p>What would be lower-end than an AVR or a MOS 6510? AVR is a very modern pipelined architecture, delivering nearly 1.0 MIPS/MHz. The 6510 is also also rather performant per-cycle. This was not always the case with CPUs. Squeezing even half that performance per MHz out of, say, an 8086 would be quite hard. But 8086 is a 16-bit chip, so it would not necessarily count as lower-end than an 8-bitter. <a href"https:="" en.wikipedia.org="" wiki="" intel_8080"="">Intel 8080</a> exists, and it is an 8-bit chip from 1974. Its instructions take 4-11 cycles, so it is more typical of the original 8-bitters. however, the 8080 is just an upgraded version of the <a href="https://en.wikipedia.org/wiki/Intel_8008">Intel 8008</a> from 1972, so logically the 8008 would be a more tantalizing target anyways, being older and thus cooler. At this point, though, we're approaching the start of microprocessor history, 1972 being only a year after the <a href="https://en.wikipedia.org/wiki/Intel_4004">Intel 4004</a> came out. The 4004 is considered to be the first commercially-produced microprocessor. So, as long as I am going to go back in history, why not go <em>all the way back</em>? Plus, it being a 4-bit chip, this unambiguously sets a new low bar! Thus this project was born...
</p>

<h2>The 4004</h2>
<p>This is a not-so-short summary of how the 4004 works. I found a lot of information online about it that was incomplete, incorrect, or simply incomprehensible. Now that I've sorted it all out for you, enjoy! To skip this section (not advisable), <a href="#skip4004">click here</a>. To read the original intel MCS-04 manual <a href="https://dmitry.gr/images/MCS-4_UsersManual.pdf">click here</a>.
</p>
<h3>Like we did in the good ol' days</h3>
<p>To someone used to today's MCUs, the 4004 will look mighty weird. To start with, it operates on 4-bit quantities only. The only flag is the carry flag. Instructions are mostly one byte long and take 8 clock cycles to execute. Some instructions are two bytes long and take 16 cycles to execute. Just to keep you on your toes, there does exist a single one-byte instruction that takes 16 cycles - <span>FIN</span>. However, that is only the beginning. The fact that this chip was developed for a calculator is quite evident in the fact that it has no logical operations at all. There is no <span>AND</span>, <span>OR</span>, or <span>XOR</span> operations at all. It is a one-operand instruction set, so the accumulator is usually the target of operations. So, if we have no logical ops, what do we have? <span>ADD</span> and <span>SUB</span> basically. To be precise, addition is always with carry and subtraction is always with borrow. This, again, shows off the 4004's "calculator" roots. For extra credit, and contrary to some of the docs you'll find out there, the usage of the carry flag during subtraction is quite weird... Some architectures treat the carry flag during subtraction as "borrow", as in: it'll be set if there was a borrow, and cleared otherwise. Other architectures treat the carry flag during subtraction as "not borrow", meaning that it'll be cleared if there was a borrow, and set if there was not. The key thing is that in every architecture I've evern encountered, it was one of those two options.
</p>

<h3>But with a twist...</h3>
<p>The 4004 seemingly finds a third option. On the way in to the <span>SUB</span> instruction, the carry flag means "borrow", but after the <span>SUB</span> instruction, it means "not borrow". Yes, this is correct and I've verified this on the real hardware. I read one old newsgroup post (that I can no longer locate) where this was blamed on not having space for an extra XOR gate in the chip. The practical upshot of this is that to add a multi-nibble number to another multi-nibble number, simply clearing the carry up front and then using <span>ADD</span> on each nibble will work. To do a multi-nibble subtraction, one needs to not only clear the carry bit up front, but also invert it after each <span>SUB</span> instruction.
</p>
<p>The 4004 is surprisingly register-heavy for such an early design. It has 16 internal registers, each 4 bits in size. PC is 12 bits long, and the hardware return stack is 4-deep. The current top element of the stack is used as <span calss="code">PC</span> so maximum actual function nesting possible is 3-deep. All together, that is 112 bits of state, which would be a whole lot of transistors in 1971, if you were to make that out of SRAM. It would take 672 transistors. That's quite a lot for a chip whose total transistor count is 2,300. So what did Intel do? They used DRAM for these bits! This is one of the reasons that the 4004 has a minimal clock speed, below which it will fail to work. This is rather unlike modern microcontrollers, most of which can operate all the way down to DC. Another slight weirdness is that 4004 has no interrupt support at all!
</p>
<p>An unexpected luxury in a one-operand CPU is the presence of direct operations on memory operands. Well, only <em>FROM</em> memory, but still. There exists <span>ADM</span> which adds a nibble from RAM to the accumulator and <span>SBM</span> that subtracts a memory nibble from the accumulator. Other than those, all other operations only operate on the accumulator, sourcing data from the internal registers when a second operand is needed. Another somewhat weird thing is that while there is an instruction to load a register value into the accumulator (<span>LD</span>), there is not one to write the accumulator to a register. To do that one must use the <span>XCH</span> instruction that swaps the accumulator's value with that of a register. This is somewhat annoying since storing the same value into two registers now takes three operations instead of two. I guess that this was a compromise necessary to fit all the desired instructions into the encoding space provided by just-8-bit-long instructions.
</p>
<p>So what else is there? Of course there is <span>NOP</span>, encoded officially as <span>0x00</span>, but any byte less than <span>0x10</span> is treated as such. This is not a coincidence. The 4004 treats each instruction as being made of two 4-bit parts. The high part is called <span>OPR</span> and is sent on the bus first. The low byte is called <span>OPA</span> and is sent on the bus second. In general, <span>OPR</span> encodes the instruction and <span>OPA</span> is the parameter/index/etc for it. With this in mind, it is understandable why every instruction with the top nibble of zero is a <span>NOP</span>. Some instructions you'll find in the 4004 are pretty typical of early processors. <span>IAC</span> (increment accumulator) and <span>DAC</span> (decrement accumulator) make an appearance, of course, acting on the accumulator and setting the carry flag. But there is also <span>INC</span> which will increment a register and will not affect the carry flag. There is no <span>DEC</span>. Loading an immediate nibble-sized value into the accumulator is accomplished using <span>LDM</span>. Bit-shifts are always by one bit and always though the carry flag. <span>RAR</span> (rotate right) and <span>RAL</span> (rotate left) thus deliver precisely what they promise.
</p>
<p>Since the carry flag is so often used, there are instrctions specifically for managing it. <span>STC</span> (set carry) will set it, <span>CLC</span> (clear carry) will clear it, and <span>CMC</span> (compliment carry) will toggle it. There is also <span>CLB</span> (clear both) which will clear carry as well as the accumulator and <span>TCC</span> (transfer and clear carry), which will set the accumulator to the value of the carry flag (0 or 1) and clear the carry flag itself. This turns out to be useful in all sorts of places, actually. Finally, there is <span>TCS</span> (transfer carry for subtraction) which is more useful for BCD math than it is for binary math. It will set the accumulator to "9 + carry" and clear the carry flag. I have found no use for this instruction yet in my code.
</p>
<p>As far as weird instruction go, there are two more that are not all that useful. <span>DAA</span> (decimal adjust for addition) is one. If the accumulator is 9 or greater, or if the carry is set, 6 is added to the accumulator. Carry is set if the addition generates a carry, it is not affected in all other cases. This is also used for BCD math and is thus useless for my purposes. Another instruction of dubious value is <span>KBP</span> (keyboard process). It implements something like "count trailing zeroes", but only for powers of two. For an input of 0, it produces zero, for an input that is a power of two, it produces one more than the log base two of the value, for all other inputs it produces 15. This was meant to allow for easy keyboard decoding, I suppose.
</p>
<p>There are two more ways to load immediates in the 4004, and both of them are a godsend for writing actual useful code. First, there is <span>FIM</span> (fetch immediate). This two-byte instruction will load 8 bits of immediate data into two consecutive registers, starting with an even-numbered one. The accumulator and the carry bit are unaffected, making this a nice way to load loop counter values into registers. A similar, in some ways, <span>FIN</span> (fetch indirect) will load two consecutive registers with an 8-bit immediate loaded from the code ROM's current page. As the 4004 is a Harvard-architecture CPU, the code and data spaces are entirely different and this is one of the ways to make constant tables work. Since using a single nibble as the address would not work, two registers are used, allowing for addressing up to 256 bytes of data. There would not be enough encoding space in the 8-bit instruction to encode a 3-bit destination register pair number, a 3-bit source register pair number, <em>and</em> the 4-bit <span>OPR</span>. Two possibilities existed here. One would be to use the same register pair for input and output. This would preserve the orthogonality of the instruction set but make actual use harder. The second (and what intel chose) was to hardcode one of the register sets. And indeed, <span>FIN</span> always uses <span>r0:r1</span> as the address to read from, while the destination register pair is encoded in the instruction, and may, in fact, be <span>r0:r1</span>.
</p>
<h3>Control flow in the 4004</h3>
<p>As I mentioned, there is a hardware stack for subroutines. <span>JMS</span> (jump to subroutine) is a 2-byte instruction that will push the address of the next instruction onto the hardware stack and then jump to anywhere in the 12-bit code address space. <span>JUN</span> (jump unconditional) will do the same without pushing a return address. Both of these can thus reach any instruction in the code address space. Returning from a soubroutine is accomplished using <span>BBL</span> (branch back and load), which will jump to an address popped from the return stack and load an immediate encoded in the instruction into the accumulator. An astute reader will note that this means that it is thus impossible to return a dynamic value from a subroutine in the accumulator, and this is so. This is actually similar to PIC12's <span><a href="https://onlinedocs.microchip.com/pr/GUID-04F283CC-FA3E-46C3-9513-4F7618EB862D-en-US-3/index.html?GUID-1C04EB55-483B-4EF1-89B0-4AD59984F215">RETLW</a></span>, and may be used as such, to implement tables of data. That would, however, require an ability to execute a calculated indirect jump. And that ability exists. <span>JIN</span> (jump indirect) will jump to an address in the current code page that comes from a pair of consecutive registers. Another unexpected creature comfort is the <span>ISZ</span> (increment and skip if zero) instruction. It does not quite do what you'd think though. It will increment a register with no effect on carry, if the result is not zero, it will jump to an address encoded in the instruction (and limited to the current code page). If the result was zero, it will not jump and execution will continue after it. This can be used to implement loops relatively easily.
</p>
<p>Conditional jumps in the 4004 are also somewhat strange. 16 possible conditions exist, and given what you know about the 4004 so far, try to guess how that is possible! Sure, one can branch on carry, or on accumulator being zero, but that does not make 16 possible conditions. <span>JCN</span> (jump conditional) will execute a conditional jump to an address in the current code page if the specified condition is met. The condition is made of three clauses, each of which may be enabled, and considered met if any of the enabled clauses are true. There is an extra bit in the encoding to invert the final result. The clauses are: "accumulator is zero", "carry is nonzero", "<span>TEST</span> pin is logical zero". Indeed this means that complex conditions can be tested in one instruction. In reality, though, this does not work and combinations that you'd want end up being impossible. For example, I would have loved an "jump if accumulator is zero and carry is zero" or "jump if accumulator is nonzero or carry is nonzero" but neither of those is encodeable in the way intel chose to implement this instruction.
</p>
<p>"Now what is this <span>TEST</span> pin?" you might ask. This is an input pin directly on the 4004 that can be tested directly via a conditional jump. This is the only input that is on the 4004 directly and this is as close as you'll get to handling interrupts on the 4004. If your external hardware signals some condition via this pin and your code remembers to poll it often enough, you could use this to signal your code about external events. This is the only general-purpose input pin on the 4004. It has no general-purpose output pins.
</p>
<p>I mentioned code pages above. What does this mean? While the entire code space is 4096 bytes (addressable via 12 bits), some instructions lack the encoding space to address it all. So, a "code page" is just the range of code ROM that contains the current PC, starting at the previous multiple-of-256-address and ending just before the next one. It should be noted that "current PC" is the address of the <em>NEXT</em> instruction. This matters for instructions that end on a page boundary. Such instructions thusly placed can only target the next page. <span>FIN</span>, <span>JCN</span> and <span>ISZ</span> are affected by this. This situation of conditional branches being limited in range compared to unconditional ones is common, and even modern architectures like ARMv6M have similar limitations.
</p>
<h3>Memory and I/O in the 4004</h3>
<p>The 4004 is not quite a complete processor. There are some instructions that it does not process at all. In fact, it does not at all process any memory instructions. Memory instructions are all whose <span>OPR</span> is 14. For them, the CPU will look at the top bit of <span>OPA</span> only. If it is set, the instruction is a read and during the <span>X2</span> bus phase, the CPU will sample the bus and consider that the read value. If the top bit of <span>OPA</span> was clear, the CPU will place the written value onto the bus during the <span>X2</span> phase. What is interesting here is that there are a few different read instructions and a few different write instructions, and the CPU knows nothing about how to perform them. When it sees an <span>OPR</span> of 14 (which will happen during the first bus phase fetching the instruction - the <span>M1</span> phase), it will activate the <span>CM-ROM</span> and <span>CM-RAM</span> of the currently-enabled ROM and RAM banks, thus notifying all memory chips to watch the second nibble of the instruction (which will be sent during the next bus phase: <span>M2</span>). They watch the value of <span>OPA</span> (during bus phase <span>M2</span>), decide if they can execute this instruction, and if so, place the proper value or get the proper value from the bus during phase <span>X2</span>. So, one could argue that the 4001/4002/4289/4265/4308 memory chips are part of the CPU, since they decode and execute certain instructions. Intel used this to great success in the 4289 and 4265, which will decode many of the instructions in that space differently. One could even imagine a coprocessor that allows 4004 to execute custom instructions and transfer 4 bits of data per instr using this ability.
</p>
<p><a href="https://dmitry.gr/images/4004memBanks.png"><img alt="A schematic for using a 3-to-8 decoder to connect 8 RAM banks to the 4004" src="https://dmitry.gr/images/4004memBanks.png"></a></p><p>It is also interesting that the 4004 has no addressing modes, not even the concept of that exists. Its support for memory is rather rudimentary, in fact. It is also rather unlike what modern chips do, so I'll explain it. First of all, there can be up to 8 banks of RAM. Up to 4 banks can be supported without any external decode circuitry, and up to 8 can be supported with an external 3-to-8 decoder. How can this be? The 4004 has 4 <span>CM-RAM</span> outputs, which are basically RAM bank selects. If banks 0..3 are selected, only the respective <span>CM-RAM</span> line will be active during the proper time. If banks 4..7 are selected, a combination of <span>CM-RAM</span> pins is activated, but no combination includes <span>CM-RAM0</span>. Thus 7 combinations are possible, but of them one is al zeroes (unused), and three are a single active line (already accounted for above), thus there are four more combinations possible here, and they are used to encode banks 4..7. In reality, one could expand this infinitely, simply by using a few external latches and some OR gates to only pass the select signal to some chips but not others. I am not aware of any design that did this, but I verified that this works as you'd expect. The 4004 only has one <span>CM-ROM</span> (ROM select signal), and thus can only natively address just 4096 bytes of ROM. Here, too, with minimal external circuitry one could expand this to more.
</p>
<h4>4001 and 4308</h4>
<p><a href="https://dmitry.gr/images/4004-4001options.png"><img alt="Intel's diagram showing the 4001 I/O port ordering options" src="https://dmitry.gr/images/4004-4001optionsSmall.png"></a></p><p>Intel intended the 4001 to be the ROM for the 4004. It is a mask ROM that holds 256 bytes of data and contains a 4-bit I/O port. Each 4001, internally, knows its own "ROM number". What is that? Well, the 4004 can address 4096 bytes of ROM and the 4001 only holds 256. Logically one would need 16 4001s to fill the address space, but since there are not 16 chip selects coming out of the 4004, how would each ROM know when it is addressed? The last nibble transferred from the CPU on the bus during the <span>A3</span> phase is compared by each 4001 to its internal "ROM number". If it is not a match, the 4001 will do nothing more till the next instruction cycle. If it is a match, it will consider itself active and provide data the 4004 requested, from the address it got during the <span>A1</span> and <span>A2</span> bus phases. 
</p>
<p>The 4001 is not programmable, it was meant to be custom-made for a customer. One would ship to intel the bytes one wanted in the ROM and intel would manufacture the 4001 containing those bytes - they are physically wired into the chip via its metal mask. The same applies to the I/O port on the 4001. It is a 4-bit wide port, and each pin could be an input or an output; have a pull-up, pull-down, or neither; could be inverting or not. The diagram shown here shows all the options. Each depicted switch could be closed or open. Some combinations, of course, make no sense, and intel warns so in their datasheet.
</p>
<p>If you happen to buy a 4001 on eBay, you have no idea what its port config and "ROM number" is. You just have to test. Most ROMs out there are "ROM number" 0, which makes them especially useless for a home project. If they respond to address 0, then your code (presumably elsewhere in the address space) will never get to run. So why would you even buy a 4001 if it permanently contains code you cannot modify? Well, for the chance that it has an input port, since the 4002 does not, for some reason.
</p>
<p>As I had mentioned above, the 4004 does not perform any memory operations - the other chips on the bus are expected to decode them and perform them if they are selected. The "selection" is made of a few parts. First is the <span>CM-ROM</span> line needs to indicate that this ROM bank is active during bus phase <span>A3</span> (for code read) or <span>X2</span> (for I/O ops). In the 4004, there is only one ROM back, so this is always the case. The 4040 has two <span>CM-ROM</span> lines and thus one bank may be not selected. The second part of "selection" is whether the current chip in the bank is selected. This is determined from the last <span>SRC</span> instruction performed while this bank was selected. The chip thus addressed remembers this until another <span>SRC</span> instruction is observed while this bank is selected.
</p>
<p>So, which instructions does the 4001 decode and execute? <span>SRC</span> is used to select which 4001 (of the 16 that make up a bank) is selected for I/O. The top nibble of the provided address (sent during <span>X2</span> bus phase) determines which chip considers itself selected for I/O. Besides that, the 4001 only handles <span>WRR</span> (write ROM port) and <span>RDR</span> (read ROM port) instructions, and they do precisely what you'd expect from the names. As the I/O pins are not configurable and direction is locked at manufacturing time, there is no further config to perform. One curious thing is that when performing a read of the port, the I/O lines configured as outputs do not return the data they are outputting, instead they return a hardcoded value, that may be configured at manufacturing time to be either high or low.
</p>
<p>The 4308 is basically the same as four 4001s in one package. It contains 1024 bytes of ROM and 4 I/O ports. It responds to four consecutive "ROM numbers". It is just a board-space optimization with nothing else interesting about it.
</p>
<h4>4002</h4>
<p>The 4002 is the special memory for the MCS-04 system. It contains 320 bits of DRAM, refresh circuitry, and a 4-bit output-only port. I am not sure why intel made this decision, but this is so. Unlike the 4001, there is no mask ROM in here, so there would be no way to assign a "RAM number" to a chip. A different system is used. Each bank of RAM may have 4 4002s in it. So, logically, to determine a chip's index in a bank, we need two bits of information. One bit (the lower one) comes from the <span>P0</span> input pin on each 4002 itself. The second bit is special per chip model. There are two: the 4002-1 and 4002-2. Thus a complete RAM bank, in order, will be made of: a 4002-1 with P0 = Vss, a 4002-1 with P0 = Vdd, a 4002-2 with P0 = Vss, and a 4002-2 with P0 = Vdd.
</p>
<p>While the 4004 only has one <span>CM-ROM</span> output, it has 4 <span>CM-RAM</span> outputs, and as I mentioned above, this allows up to 4 banks of RAM without external circuitry and up to 8 with a single extra chip. So, a top-spec 4004 system without an extra decoder chip can have 16 4002s attached to it, for a total RAM capacity of 5120 bits (640 bytes). With a 3-to-8 decoder, the numbers double. In reality, memory addressing is not quite simple in 4004. So, if you were to only consider RAM you could address as a linear block that you could iterate over using a pointer, it is important to remember that each 4002 only has 256 bits of that. So a top-spec system would have 4096 bits (512 bytes) of that kind of directly-addressable RAM, assuming full 4 banks. I'll talk more about RAM addressing in the 4004 later. For now: each RAM bank is made of 256 nibbles addressable directly and 64 more, addressable <em>weirdly</em>.
</p>
<p>So, what instructions does the 4002 handle? <span>SRC</span>, again, is used to select the chip in the current bank, both for I/O as well as for memory access. The top 2 bits of the 8-bit address sent select one of chips in the RAM bank. <span>RDR</span>, <span>ADM</span>, and <span>SBM</span> all read the nibble addressed by the last address sent via the <span>SRC</span> instruction. <span>RD0</span>, <span>RD1</span>, <span>RD2</span>, and <span>RD3</span> read the status nibbles (more on them later). <span>WR0</span>, <span>WR1</span>, <span>WR2</span>, and <span>WR3</span> write the status nibbles. <span>WRM</span> writes the <span>SRC</span>-addressed nibble - it is the opposite of <span>RDM</span>. The only other instruction the 4002 executes is <span>WMP</span> (write memory port), which sets the output value to be presented on the 4-bit output port of the currently-selected chip. The value will keep being outputted till another is written.
</p>
<p>Sadly, there is no 4308 equivalent for RAM - there is no chip that would act like a full bank of RAM for the 4004. The 4265 can sort-of come close, but not in a fully compatible way.
</p>
<h4>4265</h4>
<p>The 4265 is a general-purpose I/O device designed for the MCS-04 system. It has 4 ports of 4 I/O pins each and supports a number of modes of operation. You can peruse the intel docs on it at your own leisure to read about all the modes. I will only tell you about mode 12, as it relates to using the 4265 for RAM. In mode 12, the 4265 takes up an entire <span>CM-RAM</span> bank and responds to all 256 addresses that a <span>SRC</span> instruction might send. It can be interfaced to a 256x4 SRAM and it will read and write precisely like 4 4002s would. But wait, there is more, since 4265 in this mode also has 2 chip select pins that can be set to arbitrary values. If one were to use them as address lines too, one can interface a 1024x4 SRAM, which is a lot more RAM than a single RAM bank of 4002s could ever hold. Indeed, one would need to switch pages in this bank, as only one 256-nibble view is available at a time, but this is still pretty cool. The reason as to why this is not fully 4002-compatible is that there are no "status nibbles" here, so a 4265 + 256x4 SRAM is not a full replacement for a bank of 4002s if the code at all uses "status nibbles". When I talk about how they work and the advantages of using them, you'll see why this matters. Additionally, while the 4265 indeed has as many potentially-output port pins as 4 4002s would have, the way to control them is also not compatible (and, in fact, if you use 4265 for RAM access, you end up with no general-purpose output pins at all).
</p>
<p>So, which instructions can the 4265 execute? <span>SRC</span> is decoded, as always, to handle inputting an address, of course. <span>WMP</span> (write memory port) is used to select the 4265 mode. In mode 12, <span>RDM</span>, <span>ADM</span>, and <span>SBM</span> will read the addressed nibble in the addressed page of memory. <span>RD0</span>, <span>RD1</span>, <span>RD2</span>, and <span>RD3</span> select the given page, and then do a read. <span>WR0</span>, <span>WR1</span>, <span>WR2</span>, and <span>WR3</span> select the given page and then do a write. <span>WRM</span> writes a nibble at the current address in the current page.
</p>
<h4>4008, 4009, and 4289</h4>
<p>Given that intel will no longer manufacture you a 4001 with your custom contents (I called and asked), and the fact that the MCS-04 bus is rather strange and no other memory chip supports it, one might expect that one will need to do some perverted things to run code on a 4004 today. Of course, a simple FPGA, or even a modern microcontroller with a lot of level shifters could manage to pretend to be a 4001, but this is considered cheating in my book. Luckily, there is another way. There are two, even! Intel created a two-chip solution for a 4004 system to interface to normal garden-variety [[E]EP]ROMs: the 4008 and 4009. The 4008 handles the addressing part - it understands the MCS-04 bus protocol enough to tease out a 12-bit address that the CPU wants to read and can output that on 12 pins. Fancy that! The 4009 also understands the MCS-04 bus protocol, and it decodes memory instructions and generates control signals to handle I/O, ROM reading, and, optionally, writing in some weird ways that I prefer not to think about. It will also latch the 8 bits of data that represent an instruction and dish it out to the 4004 four at a time, as needed. The 4009 understands the same instructions as the 4001 does, except that instead of the I/O port being hardcoded at the intel factory, each write and read is output 4-wide to the outside world, to be dealt with as desired. This allows for a lot more flexibility. There is one more instruction that the 4009 understands that the 4001 does not: <span>WPM</span> (write program memory). This was meant for situations where the backing store was not [[E]EP]ROM but SRAM (eg for development). It works in weird ways that are beyond the scope of my lecture.
</p>
<p>The 4008 and 4009 still need level shifters to connect to normal memories, since they were designed for the 15V EPROMS intel made, like the C1702A. The 4008 and 4009 are also rather hard to obtain nowadays. Luckily, intel also produced a combined chip - the 4289. It is basically a 4008 and a 4009 in one package, with level shifters built in. It can communicate with memories at 5V signal levels! This makes using a 4004 today pretty easy - a 4289 and a 5V 4096x8 [[E]EP]ROM is all it takes, really. The I/O story on the 4289 is also pretty simple and 5V-compatible. There is a pin that goes high when the CPU does an I/O read, and the 4-bit "I/O port" selection is available on 4 pins. Another pin goes high when the CPU does an I/O write, and the data appears on the I/O pins. In theory, this allows connecting up to 16 4-bit input ports and 16 4-bit output ports to the 4004, using simple buffers and decoders.
</p>
<h4>Using memory, and those "status nibbles"</h4>
<p>The 4004 has no concept of addressing modes or even pointers, as I said. The way it addresses and uses memory is rather ... strange. Before you address memory, you need to select a memory bank. To select a RAM bank, one puts the bank number (0..7) into the accumulator and then executes a <span>DCL</span> (designate command line) instruction. This determines which <span>CM-RAM</span> line(s) go active during memory ops, and this selection remains active until another <span>DCL</span> instruction is executed. If no <span>DCL</span> is ever executed, bank 0 is used. There is no way to read back the current bank.
</p>
<p>Each RAM bank (if fully populated), is made of 4 4002s. Each 4002 is made of 4 "registers". Each "register" is made of 16 addressable nibbles and 4 status nibbles. What do I mean by that? Well, if you were to read (using, say, the <span>RDM</span> instruction) memory in a bank from address 0x00 to address 0xFF, you'd first read nibbles 0 through 15 of "register" 0 in the 0th 4002, then the 1st "register" in it, then the 2nd, and then the 3rd. You'd then read the 0th "register" in the 1st 4002, and so on. Thus you'll have accessed every addressable nibble. Note that you did not access any of the "status nibbles" thusly. Those are accessed differently. With any address in a "register" selected, <span>RD0</span> will read that 0th statis nibble attached to this register, <span>WR0</span> will write it. <span>RD1</span>, <span>RD2</span>, <span>RD3</span>, <span>WR1</span>, <span>WR2</span>, and <span>WR3</span> work similarly, as you'd imagine. Note that the status nibbles are thus not pointer addressable in the normal sense. They are also not accessible to <span>ADM</span> and <span>SBM</span> instructions, and thus to do any math on their contents you must first directly load them into the accumulator.
</p>
<p>//these next two lines only needed if
// the current bank is NOT already 3
LDM 3         //load 3 into accumulator
DCL           //select bank 3

//these next 2 lines are only needed if
// the currently selected address is not
// already 0xAB, they also clobber r0, r1
FIM r0, 0xAB  //put 0xAB into r0:r1
SRC r0        //put r0:r1's on the bus as addr

RDM           //read nibble to accumulator
</p>
<p>As I explained, accessing memory is a multi-step process. As the 4004 has no concept of memory addressing, that is left to whatever memory device is attached to the bus. All memory devices watch the bus to see if their <span>CM-RAM</span> (or <span>CM-ROM</span>) line is active during the <span>X2</span> bus phase. If so, that means a <span>SRC</span> instruction is executing. All selected memory devices will receive 4 bits (high nibble of address), and then on the next bus phase (<span>X3</span>) they will receive the next 4 bits (low nibble of address). They will store this internally, and use this address for all future I/O instructions, until another address is sent using <span>SRC</span>. A curious little quirk of this is that every memory bank has its own "current" address, since only the selected bank will interpret a <span>SRC</span> instruction seen on the bus.
</p>

<p>So by now it should be clear that to read a nibble at address 0xAB in bank 3, one might have to do something like what you see here on the right. Best case is just one instruction. This only happens if you already had the bank and the address selected. This is unlikely. Second-best case is 2 instructions. This only happens if you happened to have the address already in a register pair, so you only need to execute a <span>SRC</span> before your <span>RDM</span>. If you did not, you'll need to use a <span>FIM</span> and clobber a register pair to get the address into it before using <span>SRC</span>. And if you also are not sure you have the desired memory bank selected, you might also need to load the proper bank number into the accumulator and execute a <span>DCL</span>. Realistically, you'll often end up with the case of <span>FIM</span> + <span>SRC</span> + <span>LDM</span>, which takes up 4 bytes of code and 4 instruction times. Yes...slow
</p>
<p>//add 32 bits at r2:r3 to 32 bits at r0:r1
//into 32 bits at r4:r5. Clobbers r6
  CLC    //carry cleared for first add
  LDM -8 //-loop iter count
  XCH r6 // ... into r6
loop:
  SRC r0 //set up addr for LHS
  INC r1 //increment LHS ptr
  RDM    //get LHS nibble
  SRC r2 //set up addr for RHS
  INC r3 //increment RHS ptr
  ADM    //add in RHS nibble
  SRC r4 //set up addr for DST
  INC r5 //increment DST ptr
  WRM    //write DST
  ISZ r6, loop //loop
</p>
<p>Now let's imagine doing some math (say an addition) on larger (say 32 bit) values. Obviously, we'll store them little-endian. This'll help us since math happens from LSB to MSB, and thus we'll want to increment the pointer. This is much easier than decrementing it, since <span>INC</span> instruction exists, but <span>DEC</span> does not. We'll also assume our value does not cross a 16-nibble boundary, which makes our address incrementation much simpler. You see that code here on the right. Quite verbose. The total useful work here is 1 carry clearing, 8 loads, 8 load-adds, and 8 stores - a total of 25 useful instruction cycles. This code will, in actuality take 91 instruction cycles. The main culprit, as is clear, is the need to constantly increment pointers and manually send them onto the bus. This situation gets a <em>LOT</em> worse if you are not able to guarantee that the values do not cross a 16-nibble boundary. In that case a simple <span>INC</span> will not do, and a more complex construction will be necessary.
</p>
<p>The issue is not limited to math. A simple implementation of memory copying looks similar and wastes similar amounts of time selecting memory addresses and incrementing registers. As you can imagine, this gets slow very quickly. If you keep some global state in some variables, to access each you need to first waste 2 instruction cycles to load its address into a register pair using <span>FIM</span>, then use one more to send it onto the bus using <span>SRC</span>, and finally you may read it using <span>RDM</span> or write it using <span>WRM</span>. If you have a few global variables that are often used together and in a particular order, you could order them in memory such that accessing the second one does not require using 2 instruction cycles on a <span>FIM</span>, instead using a single <span>INC</span> on the lower nibble of the address you had already loaded. One instruction cycle saved, but you still do need a new <span>SRC</span>. <em>Basically almost every memory access is a 2-instructions-minimum affair, due to the requirement of a <span>SRC</span></em>. For the nitpicky of you, yes, indeed, a read-modify-write of a nibble need not employ a second <span>SRC</span>, but this is rare.
</p>
<p>This is where those status nibbles come in handy. Instead of storing your globals in normal memory, you can stash them in status nibbles. Then, a single <span>SRC</span>, targeting any of the 16 nibbles of the "register" they belong to enables them to be accessed directly using a single one-instruction-cycle instruction (<span>RD0</span>, <span>RD1</span>, <span>RD2</span>, <span>RD3</span>, <span>WR0</span>, <span>WR1</span>, <span>WR2</span>, or <span>WR3</span>). This is wonderful for data that is often accessed, and once you realize the speed advantages of these "status nibbles" you'll want to use them everywhere! This realization allowed me to speed up the 4004 MIPS emulator by a factor of 30%!
</p>
<h3>Performance and clocking</h3>
<p><a href="https://dmitry.gr/images/4004intelSuggestedClocking.png"><img alt="A very complicated schematic showing intel's suggested clock generator for the 4004" src="https://dmitry.gr/images/4004intelSuggestedClockingSmall.png"></a></p><p>All 2-byte 4004 instructions execute in 2 instruction cycles. All but one 1-byte instructions execute in 1 instruction cycle. The exception is <span>FIN</span> which is a one-byte instruction but it takes two instruction cycles. What is an instruction cycle? It is composed of 8 clock cycles, each representing a bus phase. <span>A1</span>, <span>A2</span>, <span>A3</span> are the first three, and they send the desired ROM address to the ROM, LSB first. Next are <span>M1</span> and <span>M2</span> where the ROM outputs the instruction to the CPU (and any memory devices which need to decode it), MSB first. Then come <span>X1</span>, <span>X2</span>, and <span>X3</span>. <span>X1</span> is when the CPU does some of the work on the instruction. <span>X2</span> if when I/O is done between the CPU and any memory/I/O devices, the top nibble of <span>SRC</span>'s address is also sent during this phase. During <span>X3</span> the CPU does more of the work for the instruction, and also, if it is a <span>SRC</span>, the low nibble of the address is put on the bus. During <span>X3</span> the SYNC signal is active, allowing all devices on the bus to [re]sync and prepare for phase <span>A1</span> of the next instruction cycle. The 4004 needs a two-phase non-overlapping clock at a speed of 740KHz. Intel 4004 manual states that 500KHz is the minimum acceptable clock speed, and I can confirm that 10KHz does not work.
</p>
<p>How does one even generate a "2-phase nonoverlapping clock"? Intel documents a method using some 9602 one-shots and some transistors to generate the proper clock signals. For the reset signal generator they recommend a 7400 and a transistor and a lot of passives. You can see the schematic here. This is no fun for anyone. Luckily intel also made a chip that does this all for you - the 4201. It can connect directly to a crystal and will divide it down by 7 or by 8, producing a proper 2-phase nonoverlapping clock signals at proper 4004 voltage levels. This chip will also generate a good reset signal for all MCS-04 components and (if using a 4040) help implement single-stepping. This one-chip solution is much nicer than the original one intel recommended, <em>if you can get your hands on a 4201</em>.
</p>
<h3>Some more annoying weirdness</h3>
<p>All MCS-04 components operate at a very strange voltage level: their supply voltage is minus 15 volts. Yes. They also use inverted logic on all pins. To indicate a zero, a pin will be grounded, to indicate a one, a pin will output negative 15V. So to any other chip, even with level shifting, the signals will all appear inverted. Chips do not really care what you call "ground", so instead of thinking that MCS-04 chips need "-15V", it is simpler to think of them needing "-10V" and "+5V" supplies, and they are just missing ground pins. This helps in systems that also contain the 4289, since with this exact setup it can interface to normal 5V [[E]EP]ROMs. This just leaves you with the somewhat-annoying problem of generating a few watts of -10V...
</p>

<h2>Initial planning</h2>
<h3>Let's make a dev board</h3>
<p><a href="https://dmitry.gr/images/4004devBoard.jpg"><img alt="A picture of a protoboard with a few MCS-04 chips on it in sockets and an ATMEGA48 as well" src="https://dmitry.gr/images/4004devBoardSmall.jpg"></a></p><p>To make sure that I could even make a 4004 work correctly, I decided to build a simple dev board on a protoboard. It contained almost the simplest possible 4004 system: a 4201 clock generator with a reset button near it, a 4004 CPU, a single 4002-1 RAM, a 4289 ROM controller, and an ATMEGA48 to act as my ROM. The AVR is fast enough to pretend to be a ROM and easy enough to reprogram in-circuit using AVR ICSP. The board was powered by 5V, and I used an isolated 5V to 10V boost converter module to produce 10V. Its positive output was grounded, giving me a -10V supply to feed to the chips in addition to the +5V I already had.
</p>
<p>My first attempt to turn the board on did not succeed. I set a conservative 100mA limit on my power supply, and the board was clearly trying to draw more. After verifying that, as far as I could tell, I did not mess anything up, I raised the current limit to 500mA and tried again. It worked. My simple program that blinked a LED connected to the output pin 0 of the 4002 via a 2K resistor worked and the LED blinked. Glorious! My first 4004 program worked from my first try!
</p>
<p>Output is pretty easy - the 4002 has output pins. Input is a bit harder. The 4289 does support input, but it needs a tristate buffer since its pins are only inputs when the CPU executes an <span>RDR</span> instruction. It also needs a decoder to properly decide which of the 16 4-bit input ports it is reading. I was determined to avoid both of these things. After some math, I decided that I can make do with 4 input pins total. This means that I do not need any decoders. I also decided that if I put a 1K resistor between my data sources and the 4289, that even if they try to fight, their abilities to hurt each other will be limited by the resistor. This should allow me to avoid needing a tristate buffer. This all turned out to work fine. For my proto board I used a single FET with a resistor as my level shifter. On the final board I used a CD40109B.
</p>
<h3>Emulating my 4004 system</h3>
<p><a href="https://dmitry.gr/images/4004emu.png"><img alt="Screenshot of u4004 - the 4004 emulator that emulated the Linux/4004 board" src="https://dmitry.gr/images/4004emuSmall.png"></a></p><p>I had many doubts that I could fit an entire DECstation2100 emulator into 4KB of 4004 machine code. 4004 is very verbose, and operating on nibbles means that basically any operation ends up needing a loop. I was, however, very determined. To save myself the disappointment of developing hardware only to find that the software is impossible, I decided to start with the software. First, I needed an assembler. I was about halfway through writing my own when I stumbled onto <a href="https://www.retrotechnology.com/restore/a04.html">A04</a>. It had a number of annoying bugs (eg: it errors out when a <span>JCN</span> or an <span>ISZ</span> is on the last bytes of a ROM page, even if their targets are indeed reachable as they are on the next page). A04 had one major benefit - it existed, saving me the trouble of writing my own. 
</p>
<p>My next step was writing a 4004 emulator ("u4004"). This involved some experimentation with the hardware to clarify a few things that had not been clear in the datasheet, for example: how carry flag works in subtraction. Initially the emulator only emulated the 4004 and normal memory, but over time, it grew to properly emulate the complete system I intended to build - a virtual SD card, a virtual SPI UART chip, a virtual VFD, and the same layout of 4002s as I planned to have. This did not take a lot of time, since the 4004 is laughably simple. I do not think it even took a week to write and debug the core of the emulator. Emulating the peripherals took longer, as did writing the code that would parse SPI out of I/O pin states and flag any errors. I <em>REALLY</em> did not want to debug this on real hardware. The closer I could come to it in emulation, the better! Here you can see a screenshot of u4004. It shows the serial console output, the VFD display, and the <span>PC</span> LEDs (more on all this later). It also shows how much real time would pass on a real 740KHz 4004 system to get to the current state.
</p>
<h2>The MIPS emulator</h2>
<h3>Why MIPS</h3>
<p>Of course, Linux cannot and will not boot on a 4004 directly. There is no C compiler targeting the 4004, nor could one be created due to the limitations of the architecture. The amount of ROM and RAM that is addressable is also simply too low. So, <a href="https://dmitry.gr/?r=05.Projects&amp;proj=07.%20Linux%20on%208bit">same as before</a>, I would have to resort to emulation. My initial goal was to fit into 4KB of code, as that is what an unmodified unassisted 4004 can address. 4KB of code is not much at all to emulate a complete system. After studying the options, it became clear that MIPS R3000 would be the winner here. Every other architecture I considered would be harder to emulate in some way. Some architectures had arbitrarily-shifted operands all the time (ARM), some have shitty addressing modes necessitating that they would be slow (RISCV), some would need more than 4KB to even decode instructions (x86), and some were just too complex to emulate in so little space (PPC). ... so ... <a href="https://dmitry.gr/?r=05.Projects&amp;proj=33.%20LinuxCard">MIPS again</a>... OK!
</p>
<h3>A start</h3>
<p>I started with emulating just the CPU, to evaluate how much space that would take and help me estimate the feasibility of the project in general. As this was my first time programming in 4004 assembly, I had no feel for how dense the code would be. Initially, I skipped dealing with RAM and just assumed that the "current" MIPS instruction will be in <span>r8:r9:r10:r11:r12:r13:r14:r15</span> registers, MSB-to-LSB. Yup...half of the registers are used just to hold the instruction. I considered using memory for this, but the values would need to be used in many ways in many many places during decode, so that would turn out to be messier. Plus, I still had 8 registers left, that is two more than x86 ever had! Of course, "assume the instruction ends up in registers" is not testable, but that was not yet the goal. Initial dispatch (based on the top 6 bits of instruction) to a 64-entry (128-byte) table of unconditional jumps took 13 instructions, including the <span>JIN</span> that it ends with. So 128 + 13 bytes just for that. That is already 3.4% of the entire code space I had. Not a great start. Top level opcodes 0 and 1 each need another sub-table to decode. One table will have 32 entries and the other will have 64. They will need 12 and 14 instructions respectively to calculate the jump target. Thus once we've more or less handled the majority of the decode, we've used 128 + 128 + 64 + 13 + 12 + 14 = 359 bytes of code space. That is over 1/12 of the entire code space, and we have not yet even executed anything. Yeah... It was, of course, approximately at this point that I realized that this project will be harder than I had anticipated. But, no surrender! 
</p>
<p>MIPS has 32 user-visible registers, of which the first is the zero register, writes to which are ignored. 32x 32-bit registers is 1024 bits of register state. This is 256 nibbles, which, in 4004-land, is one full RAM bank. So there we have it: bank 0 will have MIPS register state. MIPS has a delay slot, so in addition to <span>PC</span> we also need to store <span>NEXT_PC</span> so that we can properly handle branches and the delay slots behind them. As <span>PC</span> is not part of the general 32-register bank, these two account for 16 more nibbles of memory (in bank 1). For memory translation, MIPS has a TLB (read more about that <a href="https://dmitry.gr/?r=05.Projects&amp;proj=33.%20LinuxCard">here</a>), where each entry is 8 bytes long and there are 64 entries. This would take up 4 complete memory banks. And to access an SD card we'll need at least a sector-sized buffer (512 bytes), which is also 4 memory banks in 4004 land. So we need at least 10 memory banks‽‽‽ No go! Beyond 4 banks, the 4004 needs extra chips; beyond 8 banks we'd be cheating. There must be another way! I decided to punt this problem to later as well. 
</p>
<p>As I continued writing the emulator, the code memory was filling up fast. Most things took a lot of operations, requiring a lot of loops. Some things were very hard due to the way 4004 works and its lack of status flags. Detecting signed overflow was particularly hard. And, of course, 32x32-&gt;64 multiply was a huge pain. The signed variant was even harder. I was very glad when it was over, at least I was until I had to implement division. In some cases, signed 32-bit division can take up to 80,000 instruction cycles thanks to needing to operate on only a nibble at a time and ISA design of the 4004. That is almost a second of realtime to perform a division. Realizing this gave me an idea to show <span>PC</span> in LEDs, which I will get back to later.
</p>
<h3>Logical ops</h3>
<p>I have never before seen a CPU that lacked ability to do basic logical operations, until I saw the 4004 manual. The 4004 lacks ability to do any of them. There is no logical AND, no logical OR, and no XOR. Intel, helpfully, gives sample code in their 4004 programming manual to implement those logical ops on nibbles, but I was able to produce more compact and faster routines. Nonetheless, it takes <em>dozens of cycles PER NIBBLE</em> to do this! How does one even do this? Observe that if we were to isolate a bit from each operand into a register's lower bit (the higher ones being zero), and then add those registers while input carry flag is zero, the result's bit 1 would only be high is the input's two bits were both ones (<span>AND</span>). The result's bit 0 would only be high if the input's bits differed (<span>XOR</span>). If we did the addition with input carry being one, the result's bit 1 would be high if either of the inputs was a one (<span>OR</span>). This is the basic building block of implementing logical ops in the 4004. The rest is looping and shifting! And then, you remember that each MIPS register is 32 bits long, and a whole lot of cycles are going to go into doing all of this per-bit!
</p>
<p>In addition to the usual suspects of <span>AND</span>, <span>OR</span>, and <span>XOR</span>, MIPS also has <span>NOR</span>. Luckily it is easy to compute in a similar way. One might ask if there is a way to speed this up using some sort of a lookup table? Yes, but a table with 256 entries is 1/16 of the available code space. Three such tables is 3/16. That is a lot of code space to give away in a project where I was not sure I could even make the code fit in as is. So this idea was shelved.
</p>
<h3>Shifts</h3>
<p>MIPS has the usual complement of shifts: left, arithmetic right, and logical right. They can be by a fixed amount (encoded in instruction) or a variable amount (taken from a register). The second part of that is trivial, we can find the right register and read its value. To the emulator, all shifts are by a variable amount between 0 and 31. Again, the 4004 makes this rather hard. The only shifts it has are shifts by one through the carry flag. So to shift a 32 bit value by one bit, we need a loop with 8 iterations. Thus to shift by N bits, we'll need to run that loop N times. This is getting pretty slow, eh? But wait, there is more. Arithmetic shift right requires the new MSB be the same as the last MSB. The 4004 lacks a way to do this easily, so it takes a few extra instructions to set this up every iteration. Thus, shifts are slow, and they get slower as you need to shift by more bits. One could come up with many clever ways to optimize this, but I was optimizing for code size above all else!
</p>
<h3>Space optimization and 4004-specifics</h3>
<p>As you may recall, I mentioned that the 4004 has 4 levels of stack, and that one of them is always used as the current <span>PC</span>. This means that if you call into 4 levels of subroutines, you'll not be able to return all the way out to the last. This is annoying, but palatable. However, this also has another fun consequence. Because the 4004 treats the stack as a 4-entry circular buffer, you <em>CAN</em> have an unbalanced number of calls and returns. I use this to save some space in my code. When a MIPS instruction's destination register is <span>$zero</span>, the result is discarded. For speed and code size, I emulate an actual <span>$zero</span> register, and just ignore writes to it. This is faster and simpler than replacing all reads with zeroes as on MIPS more registers are read than written. Now, you might imagine having a <span>isZeroReg()</span> function, and after it, a conditional jump based on its output. If it says "yes", go handle next instruction; if "no", continue processing the current one. This would be suboptimal, since every callsite would need this conditional jump. My idea is better. My <span>checkZeroReg()</span> just goes to the <span>handle_next_instr</span> label if the destination register is <span>$zero</span>, and does not actually return at all. It only returns back to the caller if the desitnation register is not <span>$zero</span>. This means that every instruction targeting <span>$zero</span> pushes <em>yet another</em> value unto the 4004 stack that will never be popped. However, as long as you do not have too many returns, it is safe to have too many calls. This saves three bytes at every callsite, which there are close to a hundred of. Saves three cycles too! This was a big deal in my increasingly-cramped ROM.
</p>
<p>There is curious little part about emulating MIPS: When, exactly, can you stop working on an instruction that targets the <span>$zero</span> register? For instructions with no side-effects, you can skip doing any work at all. So for example an <span>ADDIU</span> or an <span>SLL</span> can be skipped entirely. This is not true for instruction that might trap, like <span>ADDU</span>. Here, some work is needed up front - to check if the instruction might overflow and thus need to cause an exception. In my emulator I do this check, and then skip the actual addition if the target is <span>$zero</span>. Why someone might have such an instruction in their binary is another question, but as an emulator writer, correctness is important. Memory load instructions are similar. They might cause an exception, so even if they target <span>$zero</span>, the memory translation and access need to be executed to make sure they succeed (or to cause them to fail as they should). The only part that can be skipped is the final copying of the loaded value to the destination register, and the potential sign-extension.
</p>
<h3>Hypercalls</h3>
<p>To connect the MIPS emulator to the outside world, hypercalls are used. This allows me to not have to emulate SCSI disks, for example. The hypercalls are actually the same as in <a href="https://dmitry.gr/?r=05.Projects&amp;proj=33.%20LinuxCard">the LinuxCard project</a>. They mainly concern accessing storage using the <span>PVD</span> Linux kernel driver and outputting characters for early boot logging. So far, this is sane...
</p>
<h3>Second-order hypercalls</h3>
<p>But, as I had mentioned, I developed much of this code not on real hardware but on an 4004 emulator I wrote (u4004). This made development easier, since I had not yet even built a board with a real 4004 yet. Indeed it is emulators inside emulators. It is emulators all the way down, in fact. In any case, the 4004 emulator also had hypercalls. Initially, before I properly emulated the SPI-attached SD card, UART chip, PSRAM, and VFD, they literally accessed the host file that pretended to be the SD card and printed to console to display text via hypercalls. This allowed me to focus on the actual emulation bits without worrying about the accessing the real world.
</p>
<h3>It is tight</h3>
<p>By the time the CPU emulation was complete, there was only about 400 bytes of free space left in my code space allowance of 4096 bytes. And there was much left to do. Since I planned to use a paravirtualized disk driver for Linux, the only peripherals I would really need to emulate would be: the DEC bus fault reporter (reports bus fault address), DZ11 (serial port), and DS1287 (real time clock and timer). The first one is simply a register that can be read. Easy enough. The next two were harder. Luckily, I had a normal MIPS emulator that could boot Linux from <a href="https://dmitry.gr/?r=05.Projects&amp;proj=33.%20LinuxCard">the LinuxCard project</a>. I started chopping it up to minimize how much emulation is done of each of the peripherals, until I had them both minimized down to almost nothing. For DS1278, Linux was willing to live with it even if all registers read as zeroes, writes were ignored, an interrupt was periodically delivered, and it was deasserted upon reading of a status register. I decided to do just that - deliver an interrupt every 65,536 MIPS instructions to the emulated CPU. On the DZ11, there was a bit more work, but I was able to cut away all the channels except the zeroth, and to simplify much of the logic and remove all receive and transmit buffers. I also cut down the IRQ capabilities of the R3000 CPU. Only two IRQs are used in this system - RTC and UART. I removed the capability for all others to work as a great speed and code size gain.
</p>
<p>With the peripherals successfully minimized, I went on to implement them in 4004 assembly. At this point in time, there was 200 bytes of ROM left, but Linux could boot entirely inside the emulator inside the other emulator! The main problem was that there was no code to actually talk to the real hardware I would have to use: SD card, PSRAM, VFD, UART chip. And 200 bytes is a bit tight for all of that. But, I was determined to try!
</p>
<h3>SD card driver and the last of the ROM space</h3>
<p>So, I added a virtual SD card to u4004, connected to a virtual SPI bus, the three output pins being three pins on a virtual 4002, one input pin being the lowest input on a 4289. I then went on to write what I believe to be the world's smallest SD card driver in existence. It fit into 190 bytes and would successfully init a card, get its size, and allow sector read and write. I also tried this driver on my dev board from earlier, connected to a real SD card, and found that it worked! Woo hoo!
</p>
<p>I had 10 bytes left in my ROM and a lot more code to write. I scrounged hard and made a little more space - 44 bytes of ROM were free. I then re-read all the docs and saw that on reset, every 4002 will zero its memory, so I did not need to spend code clearing memory on boot. This saved another 12 bytes. 56 bytes free! Still, this was clearly not enough for what I had left. Failure!
</p>
<h2>The emulator needs more ROM</h2>
<h3>How to make ROM banking work</h3>
<p>Well, OK. I can have 8192 bytes of ROM, in two banks, flippable by a pin controlled by a 4002. Jumping between them would take a little work, but it could be done. And there would finally be more space! The way the bank switching would work is that after the bank output pin is written using <span>WMP</span>, the next instruction would be fetched from the other bank. This means that the call-gates had to be precisely positioned in both banks. Additionally, 4002 outputs reset to outputting 0, which in MCS-04 means the higher output voltage. Practically, this means that the board would boot from bank 1 and not bank 0. Oh well, that is solvable with a cross-bank jump. Calls between pages are also a bit complicated, since the return value is only valid in the page where it originated. So instead of a <span>JMS</span> to a function, now I'd <span>JMS</span> to a veneer that would switch banks, continue in the other bank, <span>JUN</span> to the function, it would <span>JUN</span> at the end to a return veneer, which would swap the banks back, and only then <span>BBL</span> to return. This mess was necessary to not burn one of only three call depth levels available in the 4004. Messy but it worked!
</p>
<h3>Now that I have space...</h3>
<p>Suddenly I had mode space! So many possibilities opened up! So many pieces of code that had once been optimized for space could now be optimized for speed. There were limits, of course, since jumps between ROM banks were a pain, so only a few things initially got moved. The first were the logical operations. <span>AND</span>, <span>OR</span>, and <span>XOR</span> each got a full 256-entry lookup table in the second ROM bank. How does one implement a lookup table on the 4004? Since the result is a nibble, just a table of <span>BBL</span> instructions is good enough, at a 256-byte boundary. A jump into that ROM page at an index whose high nibble is one input nibble and low nibble is the other input nibble would jump to the <span>BBL</span> that would populate the accumulator with the result. However, if the entire ROM page is filled with <span>BBL</span> instructions, how does one jump to them? Recall that the computed jump instruction <span>JIN</span> had a curious footnote in the manual: if it is the very last instruction in a ROM page, the address that the jump is relative to is not the start of its page but of the next. The 4004 manual warns that this is hard to use and should be avoided! Well, I found it wonderfully easy to use and used it to great success. Then, the functions to <span>AND</span>, <span>OR</span>, or <span>XOR</span> full 32-bit values were simple to implement and ran much faster. 
</p>
<p>Multiplication was another case where a table could help, but this is slightly more complicated. A nibble times a nibble can produce up to a byte of result (<span>0x0f x 0x0f = 0xe1</span>). This means that the trick with a <span>JIN</span> at the end of a page followed by a page full of <span>BBL</span>s with correct value would not work. Well, there is also the <span>FIN</span> instruction which loads a whole byte from ROM into a register pair. In fact, it also has the same quirk with regards to the addressing, so that placing it at the end of a ROM page would indeed allow using the entire next ROM page as data. Wonderful! There is one problem: <span>FIN</span> is not a return statement, so after it performs the load, it will continue executing the next page's data as instructions. This is most unpleasant! There is no way around this in the general case, but I am not seeking to solve the general case. If we imagine a LUT for multiplication, the first 16 entries will be zeroes. So, if we can simply assume that our larger multiplication implementation does not call the LUT for zeroes, then we can simply <span>FIN</span> and then <span>BBL</span> safely. This is what I did, in fact. Multiplication got 8x faster compared to the one-bit-at-a-time implementation I had had before.
</p>
<h2>Hardware</h2>
<p>At this point, it was becoming clear that the project was feasible, and so it was time to build some real hardware! I decided that the final result should be artistic, recall the 1970s, and be able to be hung on a wall and look pretty! The board would be composed of all through-hole components, thick right-angle-only traces and no vias anywhere for a classic look. Moving on to parts selection...
</p>
<h3>SPI PSRAM</h3>
<p>Unlike <a href="https://dmitry.gr/?r=05.Projects&amp;proj=07.%20Linux%20on%208bit">the last time</a> I did this, I had no desire to manually refresh DRAM. Since 2012, wonderful SPI PSRAM chips have appeared from <a href="https://www.apmemory.com/products/psram-iot-ram/">AP MEMORY</a>, <a href="https://www.issi.com/WW/PSearch/USPSearch/Low_Pin_Count_SRAM_PSRAM.aspx">ISSI</a> and <a href="https://www.vilsion.com/list-140-1.html">Vilsion Tech</a>. They are easy to work with and require many fewer pins. I decided I'd use them. They are not through-hole, but they are small and I was willing to compromise. Plus, since I had already written code to do SPI on the 4004, I could reuse it. I wrote an emulator of SPI PSRAM and added it to u4004, so that I could then test my PSRAM driver. It all worked rather well, after I properly remembered that 4002's outputs are inverted. Sadly, emulating a real bit-banged SPI interface slowed the emulation by a factor of two, compared to a magic "fetch an instruction" hypercall I had had. Doing things more realistically is always slower. Fetching an instruction, on average, took longer than emulating it now. Sadly, such is life. I considered using full QSPI mode, but I'd need a lot more input pins than my plan called for. I could easily use a 4265 to do this, and speed gains would be nice, but I sought a project that could be reproduced by others. 4265s are rather hard to get, so I decided to do without it.
</p>
<p>The SPI PSRAM needs time to refresh the internal DRAM, and because of this, there is a minimum time it needs to be left alone between instances of being selected. This would not be hard to meet with my emulator being so slow. It also has a maximum length of time it can be selected, so that it is not blocked from refresh for too long. This limit is 8 msec. I worked hard to meet this time by instrumenting u4004 to keep track of selection length. It is, of course, at this time that I rewrote all the SPI code many times over for speed. Now that I had space in ROM, I also inlined a few uses of it and unrolled some loops. The final clock speed I attained on my bit-banged SPI out a 4002 was about 7.4KHz. Not too fast. Luckily, as per u4004, my longest selection of RAM was 7.4 msec, so I was meeting the datasheet-imposed limit.
</p>
<p>A later re-examination of the datasheet showed a slight issue with all of the above. The unit in the PSRAM datasheet was microseconds, not milliseconds. Oops! So, I was not meeting the timings, I was blowing them by a factor of nearly a thousand! Luckily, this seemed to be causing no issues at room temperature. After some thought, it makes sense. Since there is a lot of time between my accesses, the chip likely has time to do multiple full-array refreshes between each of my selections. I ran a number of tests on an RP2350-based board severely downclocked and found no issues, so I guess it works well enough!
</p>
<h3>The VFD</h3>
<p>I knew that I wanted the final hardware I build to be an art piece that I could hang on a wall, so merely having a serial port would not do. What could add more retro flair than a 40x2 VFD display? In my mind: nothing! I was able to locate a VFD display that could speak SPI and use a single 5V supply - a Futaba M402SD10FJ. After some experimentation, I found that it would also happily run on 3.3V! Even better! The protocol to talk to it was a bit strange, and not quite SPI. It used a single line for both input and output. This required some thinking, electrically, but at the end it was resolvable. Why would I need to read from a display? RAM savings. If I want to scroll the display, I need to copy the bottom line to the top line. There are two ways to do this. One is to buffer it and the other is to read it back. Buffering 40 characters requires spending a whole 4002 chip to do that - that feels like a waste when the display itself can support this functionality. At the end I was able to make it work and the display indeed displays the last two lines of output! It is glorious! One annoyance was that the VFD only operates in SPI mode 3, while all other devices I have use mode 0. Luckily, the assembly changes were minimal to support this, and u4004 was updated to support it too.
</p>
<h3>The UART</h3>
<p>I was not going to implement a full keyboard out of buttons, though. I thought that this would be unsightly, plus I am lazy! I did, however, plan on having a real serial port on the board. There was one problem: despite much searching I found only one through-hole SPI UART chip (the MAX3100), and, sadly it had a fatal flaw. While it supported doing flow-control signaling, it lacked the ability to automatically signal the other side to stop talking when local buffer was full. Instead, its flow control outputs functioned like GPIOs that the host had to control. This was a nonstarter for me, since my host CPU was too slow to do this fast enough. After much soul-searching, I decided that the UART will be the third surface-mount component on this board. Given the option to use an SMT part, I decided on SC16IS741A. It has a large 64-byte buffer and can do flow control automatically, with threshold settings on when to signal stop and when to signal resume. Awesome! I do not use flow control on the TX side since my emulated MIPS CPU simply cannot produce data very fast.
</p>
<p>I emulated the SC16IS741A in u4004 and verified that my code drove it correctly. I wanted to see both the VFD and the outputted serial data, so I wrote my first <a href="https://tldp.org/HOWTO/NCURSES-Programming-HOWTO/" "="">curses</a> UI. It was amazingly easy and I am surprised that it took me this long to discover it!
</p>
<h3>The blinkenlights</h3>
<p>Now that I had curses, I could add more things to u4004. As I have mentioned, the emulator was bound to be rather slow. So, why not, for extra retro flair, show the current <span>PC</span> using 32 LEDs? And if I were to do this, why not also emulate it so that I could verify correctness? I did! For speed, the emulator updates this only every 32 emulated MIPS instruction, which is plenty.
</p>
<h3>The easy level shifting</h3>
<p>I planned to use the <span>TEST</span> pin on the 4004 to indicate that there was a character ready to receive from the UART chip. This would allow easily checking for it, using <span>JCN T</span> conditional jump. This level shift from 5V to 15V was done using a FET and a resistor - simple stuff. 
</p>
<p>To convert my various 3.3V signals to the 5V that the 4289 will accept as inputs, I used a <span>CD40109B</span>. It has a high input resistance and a low output resistance allowing me to play various tricks with resistors on the output and not worry about anything.
</p>
<p>Actual RS232 serial port signaling requires some rather high voltages. There are standard chips for dealing with that, and I chose a cheap through-hole one: <span>HIN232</span>. It just needs a few capacitors to work. It converts two lines in each direction between high voltage inverted and low voltage non-inverted signaling. This allows for transmit, receive, and flow control in both directions to be level-shifted.
</p>
<h3>The hard level-shifting problem</h3>
<p><a href="https://dmitry.gr/images/4004firstRevBoardWithResistorForest.jpg"><img alt="Linux/4004 board with a forest of resistors over it in the air dead-bug style" src="https://dmitry.gr/images/4004firstRevBoardWithResistorForestSmall.jpg"></a></p><p>All that was left was to convert the high-voltage outputs from the 4002s to my 3.3V domain. This turned out to be difficult. My first idea seemed simple but did not work. I reasoned as follows: the input is either -10V or +5V, the output should be either +0V or +3.3V. So if we create a resistor divider with ratio X and the other end of it is at voltage Y, what are the values or X and Y to accomplish the desired result? Two linear equations with two unknowns. Easy. The ratio needs to be around 1:5 and the other voltage needs to be around 2.8V. So, my plan was to use a pretty strong (few dozen ohms) resistor divider to create 2.8V out of my 5V supply, and then use a rather weak resistor divider (few dozen kiloohms) between each 4002 output pin and the 3.3V consumer of its output. This did not work.
</p>
<p>I spent a lot of time wondering why. I recalled a very strange comment in the intel 4002 manual: "This port can be made low power TTL compatible by placing a 12K pull-down resistor to Vdd on each pin." This comment truly made no sense, since Vdd is at minus 10 volts and that is very much not TTL-compatible. I asked around, but found no satisfactory answer to this. When my voltage dividers did not work, I started wondering if what I had tried to do failed because of some mystery that that comment had been alluding to. I measured the raw outputs of the 4002s before my level shifting resistors and noted that while the high voltage output was indeed +5V, the low was not at -10V, instead hovering at -3V. This is rather odd, since there is no -3V supply anywhere in the system, and the only load on the pins was a 30kiloohm resistor. It was starting to look like the 4002 output pins simply could not sink any appreciable current. Maybe this is why intel suggested a pulldown? A better-informed look at the datasheet confirmed this. Intel specifies that the pins will sink 50 microamps only before they start being dragged up to Vss. At 3mA current sunk, they are only promising an output of Vss-4.85V, which is +0.15V - quite far from the -10V we expected! Suddenly it all makes sense. The pins can source plenty of current, and they will happily fight back against a 12K pulldown, but they suck as sinking current, and the pulldown would help them! It now all made sense! I guess "TTL compatible" was intel speak for "able to actually be connected to anything of consequence that is not a high-sensitivity oscilloscope". While I was sorting this all out with a healthy dose of guess-and-check, a lot of resistors sprouted over the board, as you can see in the image of the first-revision board there, in the state where it first fully worked!
</p>
<p>Adding a pulldown, and then using a resistor divider from there ... to another resistor divider was starting to sound needlessly messy, and would likely not work. I came up with a new plan, which will duly horrify any EE. I would add the 10K pulldown, then, the output, via a 2.7K resistor would be used directly, clamped by two diodes, one to +3.3V and one to ground. For high-speed signals this would be problematic, but as MCS-04 chips are quite slow, it would be fine. I prototyped this and it worked well. To save space, I decided to use a TVS instead of 24 diodes. In any case, there was one small remaining problem: diodes have voltage drops, so clamping a signal to ground and +3.3V would in fact produce a signal that varies from -0.65V to +4.15V. Luckily this problem was easy to solve. A 3-resistor divider with low resistances was used to produce +0.65V and +2.65V to feed to the TVS low and high inputs. Did it work? Yes it did! Please take a moment to be truly horrified.
</p>
<h3>Power supplies</h3>
<p>As can be seen, this board was going to have a lot of different voltage levels. I decided to provide power over USB-C edge connector, same as I did <a href="https://dmitry.gr/?r=05.Projects&amp;proj=33.%20LinuxCard">before</a>. This takes care of +5V supply. I also needed -10V, and +3.3V. Limiting myself to only through-hole parts made things a bit complicated. Modern switch-mode controllers are very fancy and efficient, but they only come in surface-mount variants. I was stuck with very very old chips - the ones that were famous for being picky about layouts and would fail to work in fun ways if given an inductor or capacitors they did not like. It was a relief when my 3.3V step-down regulator based on LM2574 worked from the very beginning. The draw on it was a few hundred mA, split mainly between the VFD and the SD card. It caused no issues, which was nice.
</p>
<p>My first revision board used a MAX764 as a inverted-step-up regulator. It worked fine for a little bit of early bring-up, but if I populated more than four RAM chips, the board would stop working. After scoping the regulator's output it became clear why - it was drooping from the requisite -10V to -7V. This would not do. After some investigation, it became clear that the MAX764 simply cannot supply all the current needed by this many MCS-04 chips.
</p>
<p>The second revision board used a MAX774, which is basically the same chip as the MAX764, except that the main switch FET can be external, allowing for a beefier one. I also switched to a larger diode and a larger inductor. This worked - all the chips could be powered well. The inductor size is comical, and I asked some people who actually know this stuff why this is, since I've seen plenty of smaller modules that do the same thing I was trying to. The answer was basically that modern chips operate at much higher frequencies (in the MHz), allowing usage of smaller inductors. They are also usually designed by competent EEs, not by me. The MAX774 operates in the KHz frequencies, and thus needs much larger inductors. I was also told that my board layout could be improved, but there was not too much that could be done with through-hole parts and that I should just use a module or some modern regulators.
</p>
<p>It also took some experimentation with inductors and capacitors to find ones that would produce low-enough output ripple while also not making audible noise. I am happy with the final result - it is silent, can supply over 700mA at -10V with under 200mV ripple.
</p>
<h3>

<a name="_TOC_cf07b148648a8d1a7170d442369f48d4"></a></h3><h2>How to debug the hardware</h2>
<p><a href="https://dmitry.gr/images/mcs04saleae.png"><img alt="Saleae Logic Pro software showing MCS-04 bus analyzer" src="https://dmitry.gr/images/mcs04saleaeSmall.png"></a>
<a name="_TOC_9fbbe48584665bca4a82b5d1a702141b"></a></p><h3>This is the 21st century!</h3>
<p>As you might imagine, the 4004 does not have any built-in debugging capabilities. Luckily, we do not live in the 1970s. You can go and grab yourself one of <a href="https://www.saleae.com/products/saleae-logic-8">these bad boys</a> and capture the entire MCS-04 bus for hours on end. Analyzing it might get a bit annoying, though. This is true especially if you are looking for a bug that happens a few million cycles in. It annoyed me enough that I wrote a decoder for the Saleae Logic Pro software that can decode the MCS-04 bus. It will show bus states, ROM addresses and values read from them, disassembly, and the value read from and written to RAM and I/O. It is part of the downloads at the bottom of the page here. Enjoy!
</p>
<h3>The garbled text mystery</h3>
<p><a href="https://dmitry.gr/images/4004corruption.jpg"><img alt="Linux/4004 board with the VFD display showing a corrupted Linux kernel boot console" src="https://dmitry.gr/images/4004corruptionSmall.jpg"></a></p><p>Why did I need to debug the hardware? At some point in time I assembled a new revision 1.1 board. It booted, but the output text was rarely but noticeably corrupted. Some characters, sometimes, would lose their bottom bits. This would convert the letter "i" into "h" sometimes, or a "C" into a "B". This happened rarely, and randomly. Initially I suspected my code for outputting to the serial port and the VFD. But after capturing the bus and analyzing it at depth, I noted that this was not the case. I had to backtrack a few thousand emulated MIPS instructions (a few million 4004 cycles) to see the issue. During a <span>memcpy()</span> in the kernel, a word was loaded into <span>$t1</span> register from memory, it was then, a few MIPS instructions later, written out to another memory location. The copied data, in this case, was text output for <span>printk()</span>. It seemed that the value was being read correctly, and was properly stored into the 4002 where the emulated <span>$t1</span> lived (the second chip). But when it was loaded for the write, the bottom bit was missing. This seemed to indicate an issue with this particular 4002. I replaced it, and, after a day of waiting, I saw the text working properly. It is curious, however, that losing a random bit sometimes when copying memory did not stop Linux from booting. Very curious!
</p><p>I did make a test board to test 4002s to verify the issue. I was able to confirm that the 8th nibble would sometimes lose its bottom bit on this chip. It seemed to happen randomly, not always. No other bits were fragile in this way, and this bit never flipped from a 0 to a 1, only from a 1 to a 0. Strange. But then again, these are DRAM internally, with refresh and all. For all I know, this particular chip could have suffered an ESD strike a decade before I was born... This chip was labeled "retired" and moved to live on a big farm out of town.
</p>


<h2>More MIPS emulator fun</h2>
<h3>Memory translation</h3>
<p>MIPS R3000 has 64 TLB entries, but Linux never does anything that requires this exact TLB entry count. This makes sense since it only uses indices it gets from <span>TLBP</span> (tlb probe) and indices pre-populated by the CPU itself on exception. When it writes a new entry, it uses <span>TLBWR</span>, which writes a <em>random</em> entry. This indicates that Linux might be able to cope with having fewer TLB entries. I tested this, and it worked precisely as expected. I decided to go with 16 entries, since this makes it easy to address each entry with a nibble. This also means that one full RAM bank would store all the TLB state. Cool.
</p>
<p>As I explained <a href="https://dmitry.gr/?r=05.Projects&amp;proj=33.%20LinuxCard">before</a> (and I advise you to read it), the MIPS TLB is best emulated using a hashtable. As I explained above, the 4004 sucks at ... well .. everything. Using <span>XOR</span> or even <span>AND</span> for hashing would be a nonstarter as instructions to perform them quickly do not exist. I collected a list of all virtual addresses translated during Linux boot, and tried to find something that would be a passable hash function and also be easy and fast to compute on the 4004. I decided on taking the 3rd nibble of the address and adding it to the 6th nibble of the address. The resulting value can be the hash of the address, placing it into one of 30 buckets. This produced passable results and does not take too long to compute. Status nibbles of the 4002s came in handy here. While the actual TLB entries live in data nibbles, each entry taking up one "register", the status nibbles provide links to "prev" and "next" entries in the current hash bucket. For the first entry in the chain, the bucket index is stored instead of "prev". This allows easy removal, which is needed on TLB write.
</p>
<h3>Debugging the emulator</h3>
<p>Predictably, a brand new emulator, written in assembly for a new platform will have bugs. u4004 made debugging easier, since at least I did not need to use real slow hardware. Additionally, it could be instrumented to understand the deeper emulated MIPS system. I commandeered a few unused 4004 opcodes to mark a few important places in the emulator. One of them was the place where a new MIPS instruction had just been fetched. This opcode will be ignored by a real 4004 (treated as a NOP). u4004, however, knows the memory layout of the emulator and can do more checks. It has the option to log the emulated MIPS state to console for easier debugging. It can (and does) also check the TLB state for consistency. Getting this right took a lot of work, so having this auto-checker was worth its weight in gold. If it notices an inconsistency, it will abort the emulation.
</p>
<p>What good is aborted emulation? Well, u4004 also records the state of the entire 4004 CPU every single cycle. On abort, it will print out the state for the last 16,384 4004 instructions, allowing a lot of backtracking to see what went wrong to cause the inconsistent TLB state, why, and how. This proved to be instrumental in a few tough-to-catch bugs my MIPS emulator had. Sixteen thousand 4004 instructions is, usually, at least 10 MIPS instructions. As the TLB checker is engaged after each one this allows for a lot more lookback than should ever be needed.
</p>
<h3>MOV</h3>
<p>MIPS has no <span>MOV</span> instruction. To copy a register to another one, a number of instructions can be used: an addition of zero (immediate or register), a logical or exclusive OR with a zero (immediate or register), a left shift by zero bits, a logical AND or OR of a register with itself. Different compilers do different things, and I tried to make sure my code had fast paths for the most common ones: shift left by zero bits and immediate add of zero.
</p>
<h3>Playing tetris</h3>
<p>As conditional jumps have limited range that is also not symmetric (depending on the position of the jump instruction), code placement is crucial. This is also true for jumptables which must start at the start of a ROM page. It is equally crucial for LUTs that also need that same alignment. This all means that code gets moved around a lot, and every time some piece of code changes size, other pieces need to move around to maintain reachability of jumps. I had to do this a lot during development. You'll see a lot of <span>ORG</span> directives in the assembly that align code to proper boundaries. Sadly, the <span>A04</span> assembler does very little checking around this, so an <span>ORG</span> directive that moves the current output address backwards does not get treated as an error, instead blindly overwriting the old bytes at the same output address. This caught me by surprise a few times during development, causing crashes. I advise you to be careful if you try to modify the emulator.
</p>


<h2>Speed optimization</h2>
<h3>Methodology</h3>
<p>Now that I had a working emulator of my actual board I would build, I could run multiple versions of firmware on it to evaluate speed it would have had on real hardware. This was much better than testing on the real board, waiting for days for a single boot to complete (or fail). I did a lot of this, trying many things, incorporating improvements into the firmware, tracking boot time to first shell prompt. Once the emulator emulated a real SD card and real SPI PSRAM without hypercalls, the expected boot time could be measured and would have been around 8.9 days of real time on a real 4004 at 740KHz.  My <em>initial</em> goal was to get the boot time under a week. Looking back at my log, some of the major wins on this were: lookup tables for logical ops and a lookup table for multiplication. This brought the expected boot time down to 8.4 days. At this point in time, I added some profiling to the emulator and had it print the hottest instructions. This provided some guidance!
</p>
<h3>Fetch</h3>
<p>The longest part of emulating any instruction turned out to be reading it from memory. I considered adding an i-cache but this would require keeping the PSRAM chips' select line active even longer. Since I was already out of spec by a factor of a thousand, I did not wish to push my luck. It would have also required more RAM, and this was counter to my desire to minimize RAM usage to make the project more affordable. So what could I do? First, I unrolled the loop that received a nibble of data from SPI PSRAM, then I did the same for the code that sent a nibble. This lowered the boot time all the way down to 7.25 days!
</p>
<h3>Memory copy</h3>
<p>Since it is impossible to pass 32-bit values in registers in 4004 assembly (that would take up half the entire register file), data is often passed to functions in specified memory locations. This means that quite a lot of time is spent copying data into and out of those locations. From the very start I made sure that no data crossed the 16-nibble address boundaries so that a simple increment could be used to access all variables, but even then, copying 8 nibbles took a while, especially between memory banks. Now that I had more ROM space, compared to when I initially started intending to fit into 4KB, I specialized some copies, unrolled some as well. The boot time dropped to 6.63 days!
</p>
<h3>More RAM</h3>
<p>I noted that I had one pin free on the output port from the 4002 that drove my PSRAM. I wondered if I could add another PSRAM, to give Linux more RAM. Adding it was not too much work, mainly having to do with decoding the address to sort out which PSRAM to activate. Since Linux will handle non-contiguous physical RAM space, I could take advantage of this to make decoding easier. So, my first RAM chip is emulated at <span>0x80000000</span>, while the second starts at <span>0x82000000</span>. This particular arrangement allows the assembly code to quickly go from address to proper port value to select the correct chip. I also added code to probe RAM size in my MIPS bootloader (more on which later) and pass this to Linux.
</p>
<p>Sadly, adding more RAM slowed the boot down. Linux creates data structures at boot that track physical pages and with more pages, more of them had to be created. Some kernel data structures are also dynamically sized based on available memory, and that also suffered. At this point in time with 16MB of RAM, boot time was projected to be 7.19 days. Back over a week! Womp!
</p>
<h3>Clawing it back</h3>
<p>I was not going to give up so easily. More specialized memory copying routines were created, instruction dispatch got better by a cycle here and there. It was getting close - 7.03 days. I had an epiphany then. Why have a separate memory storage for the current instruction if I was already going to load it into registers? If I carefully track their liveness, I can skip this entirely and just load it into the same temporary storage that all memory loads go to. Down to 6.50 days!
</p>
<h3>Better shifts</h3>
<p>Recall that I initially implemented logical shifts as one-bit-at-a-time, as a sacrifice to my lack of ROM code space. Well, now I had more space, so it was time to improve. I rewrote the shifts to first do full-nibble copies for any part of the shift that was a multiple of 4 bits, and then do bit-by-bit shifts for at most three iterations. For left shift this was trivial, but for arithmetic right shift this required some careful consideration for proper sign extension. After some fun debugging of some cases where I got it wrong, it worked. Boot time was projected at 6.19 days!
</p>
<h3>More RAM access unrolling</h3>
<p>There were a lot of things I could do now that I had more ROM space. Unrolling the PSRAM address-sending code, which ran on every access had some nice pay-offs. The loop control was not very much there, but for code that runs a lot, every cycle matters. How much? Unrolling that loop with 6 iterations lowered the boot time to 6.01 days! That is not bad at all for some copy-n-paste work!
</p>
<h3>A look at WHAT runs</h3>
<p>The Linux kernel contain{s,ed} a whole lot of nonsense that this system would never need. Nobody is going to be doing TCP/IP at this speed, nor does it really need support for esoteric filesystems or antique syscalls that nobody has used since the 1990s. I went to town removing kernel configs that were of no use! The kernel size shrank down to about 2.5MB and the boot time dropped too. A part of the drop was simply the time it took to load the kernel to memory, but another part was the kernel no longer initializing subsystems that would never be of use. The kernel also creates a dummy console in RAM to log to, even if told to log to serial console. Managing that and virtually "scrolling" it took noticeable time, so I configured it to be 1x1. This made a noticeable boot time difference too!
</p>
<p>Almost all of my initial testing was with <span>init=/bin/sh</span> kernel command line, but this is not fair, since this does not leave you in a good state, with no session, no <span>$PATH</span>, no <span>/proc</span> or <span>/sys</span>, etc. On the other hand, using a real init would take months, since the password hashing itself would take that long. I wrote a tiny init (<span>init=/sbin/uMIPSinit</span>) that would set up a sane session, mount <span>/proc</span> and <span>/sys</span>, set the hostname and <span>$PATH</span>, and finally launch <span>sh</span> repeatedly as it dies. The sources to it are in the disk image at <span>/root/init.c</span>. Obviously this made the boot slower, but the smaller kernel made up for it. Boot time was 5.33 days now!
</p>
<p>Linux supports block devices over 2TB in size. I had a hunch that disabling this support would help with speed. Why? A 2TB device of 512-byte sectors has sector numbers not representable by 32-bit numbers, necessitating 64-bit math. 64-bit math on a 32-bit MIPS CPU takes a lot of work, so I had a hunch that avoiding it would help. It did, but it also presented a fun problem. My rootfs, being a garden-variety ext4 filesystem had (as is default) <span>huge_files</span> feature enabled. This had to be disabled to allow it to be mounted read-write on a kernel with huge block device support removed. It was all worth it though! The boot time dropped to 4.81 days!
</p>
<h3>Fetch again</h3>
<p>As a special last-ditch optimization, I added a code path for instruction fetch from SPI PSRAM, this code path assumes the read is 32 bits in size and that it targets SPI PSRAM. This is sane because the virtual system has no other places to run code from. Avoiding checks for need to sign-extend and for size loops added a small additional speed benefit: 4.76 days to boot! This calculates out to being around a 70Hz MIPS machine if the 4004 is run at 740KHz.
</p>
<h3>On host CPU speed</h3>
<p>As mentioned before, each 4004 instruction takes either 8 or 16 clock cycles to execute. The 4004 is specified to run at 740KHz. Intel wanted to ship it at 1MHz, but apparently it couldn't perform at that speed across its entire temperature and voltage range. On my board, however, I am overclocking it to 790KHz with no issues. This is accomplished by running the 4201 in "divide by 7" mode with a 5.5296MHz crystal. For a Linux boot with my emulator, the actual 4004 instruction mix is 8.8% 16-cycle instructions, 91.2% 8-cycle instructions. This means that on my Linux/4004 board the effective speed of the 4004 is 90,640 instructions per second! I am not yet sure if this is a cause for celebration or tears.
</p>

<h2>Hardware cost optimization</h2>
<h3>"Affordability"</h3>
<p>Throughout this project, ability for someone to replicate my work was my top concern. This is why I avoided using a 4265, for example. I could have avoided using the 4201, but the alternative methods of generating the clock were quite complicated and not very precise clock-speed-wise. Intel's recommended clocking schematic is shown in a previous section above. It is quite a mess. I simply did not want to do that, so I chose to use a 4201. Using the 4289 was a simpler decision. It is much easier available than the 4008 + 4009 combo. I considered designing the board to accept either of those, but lacking a 4008 to test wish, I decided to not risk it. I did design the board to accept a 4040 instead of a 4004, and verified that this works. No extra capabilities of the 4040 are used, to maintain the 4004 compatibility. In reality, the benefits would not be great, anyways.
</p>
<p><a href="https://dmitry.gr/images/4004mipsCyclesToBootVsTLB.png"><img alt="Scatter plot showing an inverse relationship between TLB size and boot times" src="https://dmitry.gr/images/4004mipsCyclesToBootVsTLBsmall.png"></a></p><p>Most of the RAM usage by the emulator is non-negotiable. The MIPS register state will never be smaller than 32x 32-bit registers. The emulator state will never be smaller than the 96 bytes it occupies. However, the TLB can be variably-sized, as I mentioned above. So, in the interest of allowing some money to be saved in replicating this project, my code allows one to populate 1, 2, 3, or 4 chips in the 3rd RAM bank, producing a TLB of 4, 8, 12, or 16 entries. The chips in that bank need to be populated in-order, from left to right, so the options are 1 or 2 4002-1s, and if you have two populated, then you may also populate 0, 1, or 2 4002-2s. As expected, the performance scales inversely to the number of TLB entries. I should warn, however, that the 4002s that provide the TLB also provide the LED outputs for the high 16 bits of the <span>PC</span> display LEDs, so if you partially populate this RAM bank, some of the LEDs will not work.
</p>
<p>A fun sidenote: the code actually will probe and support any TLB size from 1 to 16 entries. Each 4002 holds 4 entries so in the real world, only multiples of 4 are possible, but in the emulated world, anything is possible, so I tested every value between 2 (the minimum to boot) to 16. Here you can see a graph of the number of MIPS CPU cycles needed to boot to shell vs the number of emulated TLB entries. It is notable that while the difference from 4 entries to 8 is large, the difference from 12 to 16 is not, so populating just an 8-entry TLB might be enough. This can save you about $50 at current prices...
</p>
<h3>The prices for 1971 chips</h3>
<p>Sadly, you'll still spend quite a bit of money buying the 1970s parts. Here I have a table of the necessary old chips, their various names, and my best guess as to how much you'll pay (as seen by me on eBay USA at the time of publication). Some parts were only available from intel, while others were also available from National Semiconductor. Parts annotated with (g) are ceramic with gold (usually white ceramic, most rare, most expensive), (c) are parts that are grey ceramic (also rare, also expensive), and parts with no annotations are plastic and are the cheapest (still expensive). All of the part numbers listed in each cell <em>function identically</em> so you can buy the cheapest. I also designed this board to accept either a 4004 or a 4040, so you only need to buy one of them, probably whichever is cheapest. I am unable to explain the price difference between 4002-1 and 4002-2, since they are basically the same chip. 
</p>
<table>
	<tbody><tr>	<th>PART</th>	<th>USE</th>		<th># NEEDED</th>	<th>Typical $</th>	<th>NAMES</th>																						</tr>
	<tr>	<td>4004</td>	<td>CPU</td>		<td>1 or 0</td>		<td>$250</td>		<td>C4004(g)<br>D4004(c)<br>P4004<br>INS4004D(g)<br>INS4004J(c)</td>							</tr>
	<tr>	<td>4040</td>	<td>CPU</td>		<td>0 or 1</td>		<td>$60</td>		<td>C4040(g)<br>D4040(c)<br>P4040</td>															</tr>
	<tr>	<td>4201</td>	<td>CLOCK</td>		<td>1</td>			<td>$50</td>		<td>C4201(g)<br>D4201(c)<br>P4201<br>INS4201J(c)<br>INS4201N</td>								</tr>
	<tr>	<td>4002-1</td>	<td>RAM 1</td>		<td>5 - 6</td>		<td>$7</td>			<td>C4002-1(g)<br>D4002-1(c)<br>P4002-1<br>INS4002-1D(g)<br>INS4002-1J(c)<br>INS4002-1N</td>	</tr>
	<tr>	<td>4002-2</td>	<td>RAM 2</td>		<td>3 - 5</td>		<td>$25</td>		<td>C4002-2(g)<br>D4002-2(c)<br>P4002-2<br>INS4002-2D(g)<br>INS4002-2J(c)<br>INS4002-2N</td>	</tr>
	<tr>	<td>4289</td>	<td>ROM CTL</td>	<td>1</td>			<td>$70</td>		<td>C4289(g)<br>D4289(c)<br>P4289</td>															</tr>
</tbody></table>
<p>It should be noted that the prices are so high because of "collectors" who buy up these CPUs with no intention of ever using them. To them, any 16-pin chip laser-engraved with "P4004" would do just fine, but they instead insist on buying real chips, denying their use for real projects! What a dick move! However, it gets worse. The chips with gold caps are also sought out by people who "harvest" gold from them. This is a euphemism for grinding them up, destroying them forever. Ugh!
</p>
<h3>The modern parts</h3>
<p>The modern parts of this project are downright affordable in comparison. The one thing that might be hard to source is the SPI VFD, but they do show up on eBay often, and I got mine for $15 each. Alternatively, another SPI display can be used with small code changes. You can also just not populate the VFD at all and interact with the device over the serial port only - this is fully supported and works well.
</p>
<p>I also added some cleverness around the SPI PSRAM usage. PSRAM chip count and size is auto-detected. The first PSRAM must be at least 4MB in size, since the kernel expects to be loaded contiguously there and it is 2.5MB in size. So populate a 4MB or an 8MB chip first. If you work at ISSI and have access to a pre-production 16MB chip, that will also work. The second PSRAM chip can be left unpopulated, or populated with any size chip you have. I tested everything from 128KB to 8MB. Keep in mind that while more RAM will help Linux run better, it will slow down the boot process slightly. Sizes under 128KB are unsupported.
</p>
<p>Thanks to my work on minimizing the size of the Linux kernel by aggressively culling the kernel config, the kernel I provide is small enough that you can boot to a shell prompt without using swap on only 4.5MB of RAM (eg: a 4MB chip + 512KB chip). You may then enable swap and go on. Although, given the cost of 8MB PSRAM chips, I do not know why you'd do this other than just curiosity.
</p>

<h2>How it works</h2>
<h3>The connections</h3>
<p><a href="https://dmitry.gr/images/4004schem.png"><img alt="ILinux/4004 board v1.2 schematics" src="https://dmitry.gr/images/4004schemSmall.png"></a></p><p>At a high level, ignoring all the level shifting messes, the board is pretty simple. The 4201 generates the clock and reset signal for all the components. An RC network generates the reset input signal for it. The 4002s in the first and third banks are connected to the <span>PC</span> LEDs, in the obvious order. The first bank provides the low 16 bits, the 3rd provides the high 16 bits. The second RAM bank provides all the outputs used for driving various SPI busses and the ROM bank selection, so any 4002 mentioned from now on in this section is a 4002 in the second RAM bank. This RAM bank is composed of three 4002s. Board space is provided for a fourth 4002 in this bank, if you want to use this board for some other reason, eg as a fancy 4004 dev board. The first 4002 in this bank is used for the SD card's SPI bus. In order, the output pins are: <span>MOSI</span>, <span>CLK</span>, and <span>nCS</span>. The last output pin acts as <span>A12</span> to the ROM, flipping ROM between bank 0 and bank 1. The second 4002 is used for communications. Its outputs, in order, are: <span>MOSI</span>, <span>CLK</span>, <span>VFD.nCS</span>, <span>UART.nCS</span>. The third 4002 is used for the PSRAMs. Its outputs, in order, are: <span>MOSI</span>, <span>CLK</span>, <span>RAM0.nCS</span>, <span>RAM1.nCS</span>. The 4289 is connected to the lower 12 address lines of the ROM. Its inputs are, in order: <span>PSRAM.MISO</span>, <span>VFD.MISO</span>, <span>UART.MISO</span>, and <span>SD.MISO</span>. UART chip's <span>IRQ</span> line drives the <span>TEST</span> input on the 4004. That is basically it!
</p>
<h3>SD card access</h3>
<p>What could be simpler, one would think, than accessing an SD card? The spec is rather clear on how to do that over SPI: three wires to the card, one back; send some commands to init it, then one command is for read and another is for write. Trivial, right? It might be for modern microcontrollers that have kilobytes of RAM. The Linux/4004 board has a total of 440 bytes of RAM, if you count the un-addressable status nibbles, 352 if you do not. Of them, 160 (or 128 if you do not count the status nibbles) are hard-allocated to virtual MIPS registers, and another 160 (or 128 if you do not count the status nibbles) are hard-allocated to the TLB. This leaves 120 (96) bytes of RAM left. This is not enough to talk to an SD card, since the minimum unit of reading or writing an SD card is a 512-byte sector (very old SD cards allowed partial-sector reads, but partial-sector writes were never a thing). Adding another full RAM bank would only add 128 addressable bytes. It would take 4 full banks to fit a single 512-byte sector. This would force me to use an external 3-to-8 decoder to allow the 4004 to address this much memory. Plus, those chips are expensive! And, I had sworn I would not do this. Another solution was needed.
</p>
<p>Well, the SD card has its own SPI bus, as do the PSRAMs. The emulator itself never really needs to process SD sectors' contents, only place them into the virtual RAM or write them from the virtual RAM to card.  So, the SD sector data can always be read directly into PSRAM, or from it. This will work nicely since they have separate SPI busses. As we read card data, every 4 bytes we read, we'll write to PSRAM at the requested address, and then increment it by 4. Repeat 128 times. Writes will work much the same way. Due to the slowness of the 4004, this process is hilariously slow. It takes a bit over a second to read or write a sector to the card. But at least no extra 4002s chips are needed!
</p>
<p>Which brings us to a potential issue with SD card access. The SD spec specifies that to properly initialize an SD card, one needs to send <span>ACMD41</span> at a clock rate of 100KHz - 400KHz, and at least once every 50ms. The SPI bit-banged out the output ports of a 4002 cannot meet either of those timings. I cannot even approach them. I had some concerns. They went away quickly. Every SD card I tested happily initialized even at 5KHz, with <span>ACMD41</span> sent every 200ms or even more rarely. I guess this makes sense since modern SD cards do not use the provided clock for anything internal, like original ones might have considered doing.
</p>
<h3>How it boots</h3>
<p>The firmware necessarily must know how many TLB entries there are, since it needs to prevent the virtual MIPS CPU from populating the <span>INDEX</span> register with a higher value, and it needs to make sure that the <span>RANDOM</span> register also never presents a higher value. The firmware, thus, starts by probing the number of memory chips in the third bank, to then figure out how many TLB entries there are. Then, the VFD and the UART chip are initialized, then the SD card is initialized. If this fails, a message is shown: "Failed to init SD card. Halting here and now!". This message is the only string in the entire firmware, since bytes in this ROM are worth their weight in gold!
</p>
<p>Every byte in the firmware has a high cost due to the very limited nature of how many bytes of ROM the 4004 can address. Additionally, having a virtual ROM requires an extra check in the decoding code for every memory access. No, it is not worth it to have a virtual ROM like the real DECstation 2100 had. Instead, my firmware simply loads the first SD card sector to the beginning of RAM (<span>0x80000000</span>), and then jumps to there. The code there is, as you'd expect, limited to 446 bytes that there is before the partition table starts. The code reads the partition table (which is also in RAM, as it is part of the first SD sector), finds a partition with type <span>0xBB</span>, and reads it, in its entirety, to RAM at <span>0x80001000</span>. If this goes well, it jumps there. If the partition is not found or the reads fail, a short message is shown using a trivial function that can output a string to the console using a hypercall to print each character.
</p>
<p>This second loader can be arbitrarily large (mine is about 14KB) and can be written in C. When there is this much space, you get some creature comforts, like real <span>printf()</span> with formatting. I mostly reused the loader from the <a href="https://dmitry.gr/?r=05.Projects&amp;proj=33.%20LinuxCard">LinuxCard</a> project, but with some adjustment and simplification. When every cycle counts, one seeks to reduce the number of cycles used. I simplified and prettyified the progress bars and removed zeroing of the <span>.bss</span>, since the kernel will do it itself.
</p>
<p>Some things, however, had to be added. The RAM size probing is done here now instead of in the emulator itself. This saves space in the emulator firmware. The emulator treats each of the two RAM windows (<span>0x80000000</span> and <span>0x82000000</span>) as being 16MB in size always. It counts on Linux to only use the RAM that really exists. But how would Linux know? It asks the bootloader using the <span>REX API</span>. How does the bootloader know? It probes the RAM and notes the sizes of each one. The loader also probes the TLB entry count (by writing incrementing values to the <span>INDEX</span> register and seeing when the write does not take, as the emulator limits writes to valid values). This does not need to be communicated to Linux, as it does not care. But it is nice to know, so it is printed onscreen.
</p>
<p>Eventually, the loader finds the partition marked as <em>active</em>, mounts it as a FAT12/16/32 filesystem, finds a file called <span>vmlinux</span> on it, parses it as an ELF file, loads it to RAM if it is valid, and jumps to its entrypoint, giving it the proper parameters of machine type, a magic value, and a table of callbacks into "ROM" for things like RAM mapping and early console printing. If any part of this fails, a descriptive message is shown onscreen.
</p>
<p>As a small improvement, to save time on busyloop calibration, I ran it once, recorded the value, and now provide it via the kernel command line. This saves noticeable time every boot.
</p>
<h3>How it runs</h3>
<p>Disk access, same as in <a href="https://dmitry.gr/?r=05.Projects&amp;proj=33.%20LinuxCard">LinuxCard</a>, is provided by the PVD paravirtualized disk driver. This is much simpler than attempting to emulate the SII SCSI chip and a SCSI disk in 4004 assembly. The hypercall to read or write a sector acts like DMA to the virtual MIPS machine, completing instantly and delivering data to virtual RAM or taking it from virtual RAM. The driver is completely unmodified from its state in  <a href="https://dmitry.gr/?r=05.Projects&amp;proj=33.%20LinuxCard">LinuxCard</a>.
</p>
<p>As virtual timer interrupt ticks at 16Hz, and and IRQ is delivered to the virtual CPU every 65,536 virtual instructions, the virtual CPU thinks it is running at 1.05MHz. My testing shows that the actual emulated speed of the MIPS guest is around 70Hz at 740KHz. I run the 4004 at 790KHz, so the emulated guest is thus operating at about 74.73Hz. So time for the guest is dilated by 14,030x. This means that a virtual second is, in real life, around 3h54. Four hours per virtual second, basically!
</p>
<p>The power consumption is around 6W, so any PD-compliant USB-C brick capable of supplying 2A @ 5V will do. The LED next to the SD card is a combination power/activity light. Since the guest CPU is so slow, even very active SD card usage is very low duty cycle. Thus, mostly the SD card will be idle. This fact is used to make a combined indicator light. It will be on while the board is on, and go off for about a second for every SD card sector read.
</p>

<h2>The art of it</h2>
<p><img alt="Mandelbrot set in text mode 40x13" src="https://dmitry.gr/images/4004_mandelbrot.png"></p><p>The goal of this project was always partially artistic. This is why the board has a pretty VFD on it, why I designed it to look retro, and why it has hanging holes on the top corners! The idea is that, once completed, it can be hung on a wall where it will slowly do ... something. What could that something be? Well, I wrote a simple program that draws (in text mode) the mandelbrot set on the VFD (and on serial port). There are two versions: one uses floating point numbers (<span>/root/mandelbrot</span> in my image), which Linux ends up having to emulate, which makes it slow - around 30 days to draw the entire 13 rows x 40 cols image. The second version is integer-only (<span>/root/mandelbrot_nofp</span> in my image). That one completes in under 9 hours. But for the one I'll have hanging in my office, I have loftier goals. With swap enabled, the kernel sources can actually be built right on-device. It will take some number of years. The partition where the kernel lives is <span>/dev/pvd2</span> and is mounted under <span>/boot</span>. The device can build its own kernel from source, copy it to <span>/boot/vmlinux</span>, and reboot into it. If power is interrupted, thanks to ext4, it will reboot, recover the filesystem damage from the journal, and restart the compilation process. That is my plan, at least.
</p>


<h2>I want one</h2>
<h3>Build one</h3>
<p>The schematics are above, and the BOM of modern components is as follows. The table earlier summarizes the 1970s components needed. You can build one relatively easily. 
</p>
<table>
	<tbody><tr><th>WHAT</th><th>COUNT</th><th>VALUES</th><th>NOTES</th></tr>
	<tr><td>IC-16</td><td>11</td><td><a href="https://www.mouser.com/ProductDetail/571-1-2199298-4">16-DIP socket for old chips</a></td><td>only for the MCS-04 parts</td></tr>
	<tr><td>IC-24</td><td>1</td><td><a href="https://www.mouser.com/ProductDetail/737-ICS-624-T">24-DIP socket for 4040</a></td><td>Only if you want to use a 4040</td></tr>
	<tr><td>IC-28</td><td>1</td><td><a href="https://www.mouser.com/ProductDetail/571-1-2199299-2">28-DIP socket</a></td><td>for the ROM</td></tr>
	<tr><td>IC-40</td><td>1</td><td><a href="https://www.mouser.com/ProductDetail/571-1-2199299-5">40-DIP socket</a></td><td>for the 4289</td></tr>
	<tr><td>EEPROM</td><td>1</td><td><a href="https://www.mouser.com/ProductDetail/556-AT28C64B15PU">AT28C64B</a></td><td>Unless you have a 8Kx8 EPROM already</td></tr>
	<tr><td>U5, U6</td><td>1 or 2</td><td>
			<a href="https://www.mouser.com/ProductDetail/878-APS1604M-3SQR-SN">AP Memory 2MB PSRAM</a>,
			<a href="https://www.mouser.com/ProductDetail/%20878-APS6404L-3SQR-SN">AP Memory 8MB PSRAM</a>,
			<a href="https://www.mouser.com/ProductDetail/%20870-62WVS1288FB20NIR">ISSI 128KB SRAM</a>,
			<a href="https://www.mouser.com/ProductDetail/870-62WS2568GBL4NLIT%3EISSI%20256KB%20SRAM%3C/a%3E,%3Ca%20href=" https:="" www.mouser.com="" productdetail="" 870-62ws5128gbll45ni"="">ISSI 512KB SRAM</a>,
			<a href="https://www.mouser.com/ProductDetail/870-WVS1M8BLL104NLIT">ISSI 1MB PSRAM</a>,
			<a href="https://www.mouser.com/ProductDetail/870-ISS2M8BLL-104NLI">ISSI 2MB PSRAM</a>,
			<a href="https://www.mouser.com/ProductDetail/870-WVS4M8BLL104NLIT">ISSI 4MB PSRAM</a>,
			<a href="https://www.mouser.com/ProductDetail/870-WVS8M8FBLL104NLI">ISSI 8MB PSRAM</a>,
			<a href="https://www.microchipdirect.com/product/23AA02M-I/SN">Microchip 256K SRAM</a>,
			<a href="https://www.microchipdirect.com/product/23AA04M-I/SN">Microchip 512K SRAM</a>,
			<a href="https://www.lcsc.com/product-detail/SRAM_Vilsion-Tech-VTI7064MSME_C139966.html">Vilsion 8MB PSRAM</a>
		</td><td>RAM1 (U5) must be 4MB+, RAM2 (U6) can be any size &gt;= 128K</td></tr>
	<tr><td>U7</td><td>1</td><td><a href="https://www.mouser.com/ProductDetail/595-CD40109BE">CD40109B</a></td><td>or equivalent</td></tr>
	<tr><td>U8</td><td>1</td><td><a href="https://www.mouser.com/ProductDetail/968-HIN232IPZ">HIN232</a></td><td>or equivalent</td></tr>
	<tr><td>U9</td><td>1</td><td><a href="https://www.mouser.com/ProductDetail/771-SC16IS741AIPWJ">SC16IS741A</a></td><td></td></tr>
	<tr><td>U10</td><td>1</td><td><a href="https://www.mouser.com/ProductDetail/700-MAX774EPA">MAX774EPA+</a></td><td></td></tr>
	<tr><td>U11</td><td>1</td><td><a href="https://www.mouser.com/ProductDetail/998-LM2574-3.3YN">LM2574-3.3YN</a></td><td>or equivalent</td></tr>
	<tr><td>U12</td><td>1</td><td><a href="https://www.mouser.com/ProductDetail/576-SP720APP">SP720APP</a></td><td>or equivalent</td></tr>
	<tr><td>CN2</td><td>1</td><td><a href="https://www.mouser.com/ProductDetail/523-6E17C009PBF221">Dsub 9pin male connector</a></td><td></td></tr>
	<tr><td>CN3</td><td>1</td><td><a href="https://www.mouser.com/ProductDetail/179-SD-4-B">SD-4-B SD card connector</a></td><td></td></tr>
	<tr><td>L2</td><td>1</td><td><a href="https://www.mouser.com/ProductDetail/994-DR0608-334L">330uH 800mA inductor</a></td><td></td></tr>
	<tr><td>L3</td><td>1</td><td><a href="https://www.mouser.com/ProductDetail/542-5731-RC">40uH 3A inductor</a></td><td>strongly suggest using this one</td></tr>
	<tr><td>D0, D1, D2, D3, D4, D5, D6, D7, D8, D9, D10, D11, D12, D13, D14, D15, D16, D17, D18, D19, D20, D21, D22, D23, D24, D25, D26, D27, D28, D29, D30, D31, D32</td><td>33</td><td>3mm LED</td><td></td></tr>
	<tr><td>D33</td><td>1</td><td><a href="https://www.mouser.com/ProductDetail/833-1N5817-TP">1A Schottky Diode</a></td><td>strongly suggest using this one</td></tr>
	<tr><td>D34</td><td>1</td><td><a href="https://www.mouser.com/ProductDetail/511-1N5822-TR">3A Schottky Diode</a></td><td>strongly suggest using this one</td></tr>
	<tr><td>X1</td><td>1</td><td><a href="https://www.mouser.com/ProductDetail/449-LFXTAL036257BULK">5.5296MHz MHz XTAL</a></td><td>Or you can use another of similar freq</td></tr>
	<tr><td>X2</td><td>1</td><td><a href="https://www.mouser.com/ProductDetail/449-LFXTAL011164BULK">3.072MHz MHz XTAL</a></td><td>Or you can use another of the same exact freq</td></tr>
	<tr><td>Q1, Q3</td><td>2</td><td><a href="https://www.mouser.com/ProductDetail/637-2N7000">2N7000</a></td><td>Or another similar N-FET</td></tr>
	<tr><td>Q2</td><td>1</td><td><a href="https://www.mouser.com/ProductDetail/942-IRFU5305PBF">IRFU5305PBF</a></td><td>or equivalent</td></tr>
	<tr><td>R2, R3, R4, R5, R6, R7, R8, R9, R10, R11, R12, R13, R14, R15, R16, R17, R18, R19, R20, R21, R22, R23, R24, R25, R26, R27, R28, R29, R30, R31, R32, R33, R35, R36, R37, R41, R43, R47, R49, R51, R53, R59, R61, R63, R65, R67</td><td>46</td><td>2K7 1/8W resistor</td><td></td></tr>
	<tr><td>R38, R42, R44, R48, R50, R52, R54, R57, R58, R60, R62, R79</td><td>12</td><td>10K 1/8W resistor</td><td></td></tr>
	<tr><td>R34, R45, R46, R55, R56, R76, R77</td><td>7</td><td>10K 1/8W resistor</td><td></td></tr>
	<tr><td>R71, R73, R74</td><td>3</td><td>910R 1/8W resistor</td><td></td></tr>
	<tr><td>R75, R81</td><td>2</td><td>100R 1/8W resistor</td><td></td></tr>
	<tr><td>R66, R78</td><td>2</td><td>150K 1/8W resistor</td><td></td></tr>
	<tr><td>R70, R72</td><td>2</td><td>470R 1/8W resistor</td><td></td></tr>
	<tr><td>R68, R69</td><td>2</td><td>5K1 1/8W resistor</td><td></td></tr>
	<tr><td>R1</td><td>1</td><td>10R 1/8W resistor</td><td></td></tr>
	<tr><td>R40</td><td>1</td><td>18K 1/8W resistor</td><td></td></tr>
	<tr><td>R80</td><td>1</td><td>1M 1/8W resistor</td><td></td></tr>
	<tr><td>R39</td><td>1</td><td>36K 1/8W resistor</td><td></td></tr>
	<tr><td>R82</td><td>1</td><td>39R 1/8W resistor</td><td></td></tr>
	<tr><td>R64</td><td>1</td><td><a href="https://www.mouser.com/ProductDetail/756-WP2SZI-R051JT06">R051 resistor</a></td><td>or equivalent</td></tr>
	<tr><td>C3, C4, C5, C6, C7, C8, C9, C10, C11, C12, C13, C14, C15, C16, C17, C18, C19, C20, C21, C36, C43</td><td>21</td><td>0.1uF decoupling cap</td><td></td></tr>
	<tr><td>C23, C24, C29, C30, C31, C32, C33, C42</td><td>8</td><td>1.0uF cap</td><td></td></tr>
	<tr><td>C25, C37, C38, C39</td><td>4</td><td><a href="https://www.mouser.com/ProductDetail/667-EEU-FR1E151B">150uF 25V low-ESR cap</a></td><td>strongly suggest using this one</td></tr>
	<tr><td>C1, C2, C34, C35</td><td>4</td><td>22pF cap</td><td></td></tr>
	<tr><td>C22, C26, C27, C28</td><td>4</td><td>4.7uF cap</td><td></td></tr>
	<tr><td>C40, C41</td><td>2</td><td><a href="https://www.mouser.com/ProductDetail/710-860020373007">120uF 16V cap</a></td><td></td></tr>
</tbody></table>


<h3>Kit or pre-built</h3>
<p>I am considering offering this as a kit. You'd get the board and all modern parts labeled and ready to assemble. Other than the three surface mount parts, all others are very large through-hole components that anyone can assemble trivially. The PSRAMs are also quite easy to solder down as they only have 8 pins with large spacing. If you are interested, write to me at <a href="mailto:kit4004@dmitry.gr">kit4004@dmitry.gr</a>. I might offer a kit that also includes the 1970s components. The price on that one will mainly depend on the costs of acquiring the old chips.
</p>

<p>I do have enough components to build a few fully-working boards, tested and with all the chips. If you <em>REALLY</em> want one and do not want to do any work assembling one, write to me at <a href="mailto:full4004@dmitry.gr">full4004@dmitry.gr</a> and we can discuss. It will <em>not</em> be cheap, as you can guess.
</p>

<h2>Making of the video</h2>
<p>This was an adventure enough to warrant its own section
</p>
<h3>Capturing</h3>
<p>Of course, this was not going to be easy, but I must admit that I severely underestimated how difficult this would end up being. The idea was simple: set up a phone to take a photo every second or so, collect the photos, make a video. Done. Right? Let's do some math. A 1920x1080 photo is around a megabyte in size. Taking a photo every two seconds generates around 1.76GB of data per hour. The filming took 9 days, which is 216 hours. It will, thus, produce around 379GB of photos in approximately 388 thousand files. I guess I'll need to come and offload all the photos from the device a few times to keep it from filling. Annoying but doable. Let's try!
</p>
<p>I initially tried to use an old Pixel 5. I used an app that takes a shot every second as a test to see how well it would go. The device hard-hung overnight. I tried again, it did again. OK... I tried an older Pixel 3 XL. In the morning it was hung and too hot to touch. I am happy that the battery did not explode, having been heated that much. I gave up on android devices at around this point. The next candidate, logically, was an iPhone. I had an iPhone SE3 around that I strapped into the tripod to test. On iOS there was no free program I could find to do a timed capture with no shot limit, so I was forced to buy <a href="https://apps.apple.com/us/app/selfer-timer-camera/id1594398165">this one</a>. It is quite annoying to have to buy an app whose sole function is one library function call a second and a <span>sleep()</span>, but this was faster than digging up Xcode and writing it myself. Overnight, the iPhone stayed functional. In the morning it was still taking photos and was not even warm to the touch. A tip of my hat to Apple engineers!
</p>
<p>The actual filming was slow, as expected. I set up a video camera so I could watch remotely and know when to come to enter the next command. I did mess up once, however. When I entered the <span>uname -a</span> command, I did not press ENTER. I only realized that later - next afternoon when I noted that the cursor was still on the previous line. I came over and pressed it then, but this added 9 hours of nothingness to the video.
</p>
<h3>Getting the data</h3>
<p>Said hat tip was soon rescinded. SE3 does not have the storage to capture all the photos. I had planned to offload the data once a day using either the "Photos" app or the "Image Capture" app on a connected MacBook. After about two such offloads, Photos app stopped seeing new photos in device memory. I tried re-plugging USB and restarting the MacBook. Neither worked. Restarting the phone did, but of course this creates a gap in the recording and is unacceptable. Image Capture seemed to work better. It could copy photos off and delete them from the device, freeing space. Good! After three such offloads, the "delete" functionality stopped working. It could still copy new photos from the device but it refused to delete any. Again, the only thing that helped was restarting the phone. Again, this is unacceptable.
</p>
<p>I tried a few more times, wasting a few more days, with no better luck. I gave up and grabbed an old 512GB iPhone 12 Pro Max with a shattered screen, shelled out $130 to have it replaced with the cheapest third-party display, and strapped it into the tripod. I decided to just capture everything nonstop and grab the photos later. This should have allowed me to skip the bugs in Photos and Image Capture apps.
</p>
<p>Final photos taken, it was time to grab the images from the phone and stitch them into a video. This did not go well. Photos app only saw around 100,000 of them. The number differed every time I plugged the device in, but never rose to the correct number around 400,000. If I tried to tell it to import anyways, it hung. Leaving it alone for a day produced no results. Image Capture had a similar issue, although once it saw around 200,000 photos - a number that Photos never got up to. If told to import, it would say "Importing FILENAME.JPG" and stop there, having created a zero-sized file with the given name in the target directory.
</p>
<p>OK, I can try to make a local backup of the iPhone to a MacBook, then decrypt the archive and get photos out, right? The backup button in Finder worked. As expected, the iPhone asked for the pincode to authorize the backup. The progress bar showed the moving cross-hatched pattern... a day later no progress had been made. Maybe AirDrop will work? Well, first of all, there is no way to select all photos in the Photos app (still) without dragging your finger across them all. You have no idea how long this takes for 400,000 photos, especially as the app gets slower and laggier as you go on. Somehow there is no "select all" option. I lost patience at 20,000 photos selected and decided to try to AirDrop those, then select more. The Photos app crashed trying to AirDrop this many photos. I tried with 10,000 and it crashed again.
</p>
<p>Fine! I'll give up and use the cloud. I installed Google Photos and told it to backup to my account. It took over an hour "preparing to sync". It then synchronized around a hundred photos and promptly crashed. Opening it again produced the same result - over an hour of preparation, and another 100 photos got uploaded. This was not sustainable, neither in rate nor in manual labour required to keep re-opening the app. Unlike Apple's Photos, Google Photos <em>DOES</em> allow easy multi-select. With one tap I was able to select all photos taken on a given "Tuesday" and click the "Back up" icon. The app promptly crashed.
</p>
<p>In frustration, I paid Apple for 2TB of iCloud, figuring that the cost of one month of it is fine to resolve my growing frustration. No crashes, and it started syncing. The sync speed hovered at around one photo every 5 seconds. My internet connection has 1 Gbit/s upload so it was not that problem. This was going to take forever!
</p>
<h3>Getting desperate</h3>
<p>Maybe Windows could do better? I plugged the iPhone into my ThinkPad running Win10x64. It is supposed to show up in "My Computer" and have a <span calss="code">DCIM</span> directory with photos in it. It did the former, but not the latter. Googling around indicates that this is common - iPhone asks for pincode to confirm trusting the PC, and then nothing still. The typical "solutions" include "try cleaning your registry" and other such idiocy. OK... I guess it is Linux time? My Thinkpad had an install of Linux Mint 18 on it. It saw the iPhone but also saw no photos on it. Googling around indicated that some work had been done <em>rather recently</em> on iPhone &lt;-&gt; Linux comms, and a tool called <span>ifuse</span> can successfully mount an iPhone using FUSE. The version in Linux Mint 18 was too old to work, of course. It failed with incomprehensible errors, and panicked my kernel once.
</p>
<p>In the typical "it is called open source because you have to open the source to get anything at all to work" fashion, I had to download it and build it from source. Some dependencies were also too old, so I had to build them. Eventually, after much googling, building, installing, and cursing, all the things were built and it was time to try them. <span>idevicepair</span> successfully paired to the device. <span>ifuse</span> mounted the device at a given mountpoint, and there was indeed a non-empty <span>DCIM</span> directory in there! Success! I'll just drag that over to my desktop and be done, right? Well, that hung. I guess the Nautilus file manager was not prepared for such large copies. Maybe it tried to <span>stat()</span> each file or maybe it has some <span>O(n^3)</span> algorithms in there. I do not know. I re-plugged the iPhone, re-mounted it, and used good old <span>cp -Rvf</span> to copy all 400,000 files uneventfully ... over 10 hours.
</p>
<h3>Making the video</h3>
<p>Dealing with this many files was annoying in a number of ways, and the sole working solution was almost always some soft of a CLI utility or script. After getting all the files out, they had to be renamed to sequential names. I did not dare mess with my hard-gotten source material, so instead they were <em>copied</em> with new names. A file list, <span>vim</span>, and one very gnarly regex later, a command list was created to do the copies. The copying took a little over 3 hours. I am not sure if I should blame ext4, md-raid, or myself for this...
</p>
<p>I have never used any video editing apps, and I saw no reason to start now. A series of very messy ffmpeg commands were used to create the title screens, add the music to the first, create the video from the photos, and combine them all together into the final video. There is no time missing in the final video, but the playback speed is variable to speed up the boring bits. There is a clock and a calendar visible onscreen so you can easily see the time elapsed. Playback speed varies between 5FPS (10x realtime) and 960FPS (1920x realtime) to keep the video short(ish) and to-the-point(ish). It is hilarious that at some points in time you can see the changing of day to night and back by the light shining onto the table from the window (out of frame to the right). Due to the speed-up used, you may miss the blinking of the SD activity light (though you can see it blink a few times as the rootfs is being monted and later as <span>ls</span> executes). Sorry. However, if you really want to see it, see next paragraph.
</p>
<p>For those who like raw data, do not trust my edits, or just want to see it at a constant speed, I also produced a completely unedited version of the video, which you can see <a href="https://youtu.be/IPGLStPP9p8">here</a>. As the capturing was done at 0.5FPS and the playback in this video is at 60FPS, the video is sped up 120x from realtime. As 4 hours of realtime map to one second of emulated time, and the video is 120x faster than realtime, 2 minutes of video map to one second of emulated MIPS processor time.
</p>



<h2>Downloads</h2>
<p>The disk image for the SD card can be downloaded <a href="https://mega.nz/file/0hR2SYhR#bgdznRljt7oKV39XzfSqKjoJADRmvlm4mxs-z_FtuSc">here</a> (mirrored <a href="https://drive.google.com/file/d/1P8kvblvjH09dSJ0_jXgAnFyOgB80u-Q0/view?usp=sharing">here</a>). It is a separate download due to its size. The main download is <a href="https://dmitry.gr/images/Linux4004.tar.bz2">here</a>. It contains the MCS-04 bus analyzer for Saleae software, source code for the i4004 Dectstation2100 emulator, source code for the MIPS MBR and second stage bootloaders, kernel config and version info, as well as my very-scary u4004 emulator of the Linux/4004 board. License is: free for non-commercial use. Commercial use requires a license, contact me for licensing. Any use must credit me in source and binary form.
</p>


<h2>Credits</h2>
<p>Much thanks, as usual, to my cats for cutely sitting near my feet as I worked on this, <a href="https://www.youtube.com/@TubeTimeUS">Eric (TubeTimeUS)</a> for bravely loaning me some MCS-04 chips before I could acquire my own, eBay for occasionally supplying good deals on old chips, and <a href="https://www.entropicengineering.com/">M @ Entropic</a> for helping me fix my shitty switch-mode -10V  supply. This time, the mount-rushmore-sized middle finger goes out to MCS-04 "collectors" who gobble up the supply at insane prices with no intention to ever use them. My offer to you, miscreants, is simple: I will trade you any working MCS-04 chip you have for a very pretty PDIP-16/24/40 that I will have laser-engraved with the same exact label. Nobody who "sees" your collection will ever know, and the world will gain another MCS-04 chip that might actually be used!
</p>



<!--- We do not show this to the user, but ToC system will index this and we'll get a link to comments in the ToC -->






					
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Foundations: Why Britain Has Stagnated (145 pts)]]></title>
            <link>https://ukfoundations.co</link>
            <guid>41600388</guid>
            <pubDate>Fri, 20 Sep 2024 09:59:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ukfoundations.co">https://ukfoundations.co</a>, See on <a href="https://news.ycombinator.com/item?id=41600388">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      <article>
        <main>
          <ul>
            <li>
              <a target="_blank" href="https://x.com/bswud">Ben Southwood</a>
            </li>
            <li>
              <a target="_blank" href="https://x.com/SCP_Hughes">Samuel Hughes</a>
            </li>
            <li>
              <a target="_blank" href="https://x.com/s8mb">Sam Bowman</a>
            </li>
          </ul>
          <h2 id="foundations">
            <span>F</span><span>o</span><span>u</span><span>n</span><span>d</span><span>a</span><span>t</span><span>i</span><span>o</span><span>
              <span>n</span><span>s</span>
            </span>
          </h2>
          <h2 id="why-britain-has-stagnated">
            Why Britain has stagnated
          </h2>
          <h3 id="setting-the-scene">Setting the scene</h3>
          <p>
            Here are some facts to set the scene about the state of the British
            economy.
          </p>
          <ul>
            <li>
              Between 2004 and 2021, before Russia’s invasion of Ukraine,
              <a href="https://www.gov.uk/government/statistical-data-sets/gas-and-electricity-prices-in-the-non-domestic-sector">the industrial price of energy tripled in nominal terms</a>, or doubled relative to consumer prices.
            </li>
            <li>
              With almost identical population sizes, the UK has under
              <a href="https://www.ons.gov.uk/peoplepopulationandcommunity/housing/articles/researchoutputssubnationaldwellingstockbytenureestimatesengland2012to2015/2020">30 million homes</a>, while France has around
              <a href="https://www.insee.fr/en/statistiques/5009609">37 million</a>.
              <a href="https://www.gov.uk/government/statistics/english-housing-survey-2021-to-2022-second-homes-fact-sheet/english-housing-survey-2021-to-2022-second-homes-fact-sheet">800,000 British families</a>
              have second homes compared to
              <a href="https://www.thelocal.fr/20240712/explained-why-so-many-french-people-have-second-homes">3.4 million French families</a>.
            </li>
            <li>
              Per capita electricity generation in the UK is just two thirds of
              what it is in France (4,800 kilowatt-hours per year in Britain
              versus 7,300 kilowatt-hours per year in France) and barely over a
              third of what it is in the United States (12,672 kilowatt-hours
              per year). We are
              <a href="https://ourworldindata.org/grapher/per-capita-electricity-source-stacked">closer to developing countries like Brazil and South Africa</a>
              in terms of per capita electricity output than we are to Germany,
              China, Japan, Sweden, or Canada.
            </li>
            <li>
              Britain’s last nuclear power plant
              <a href="https://www.imeche.org/policy-and-press/from-our-perspective/energy-theme/nuclear-power/about-nuclear-power/nuclear-uk/britains-most-recent">was built between 1987 and 1995</a>. Its next one,
              <a href="https://www.samdumitriu.com/p/how-to-get-new-nuclear-built-faster">Hinkley Point C, is between four</a>
              and
              <a href="https://www.britainremade.co.uk/plan#plan_energy">six times</a>
              more costly per megawatt of capacity than South Korean nuclear
              power plants, and
              <a href="https://www.world-nuclear-news.org/Articles/KHNP-selected-to-supply-new-Czech-nuclear-units">four times as expensive</a>
              as those that South Korea’s KEPCO has agreed to build in Czechia.
            </li>
            <li>
              Tram projects in Britain are
              <a href="https://www.samdumitriu.com/p/britains-infrastructure-is-too-expensive">two and a half times more expensive</a>
              than French projects on a per mile basis. In the last 25 years,
              France has built
              <a href="https://assets.nationbuilder.com/britainremade/pages/1451/attachments/original/1723813389/BRM7607_Tram_Report_Digital-Single-Pages_AWK.pdf?1723813389">21 tramways</a>
              in different cities, including cities with populations of just
              150,000, equivalent to Lincoln or Carlisle. The UK has still not
              managed to build a tramway in Leeds, the largest city in Europe
              without mass transit, with a population of nearly 800,000.
            </li>
            <li>
              At £396 million,
              <a href="https://x.com/Sam_Dumitriu/status/1694990889787986094">each mile of HS2 will cost more than four times more</a>
              than each mile of the Naples to Bari high speed line. It will be
              more than eight times more expensive per mile than France’s high
              speed link between Tours and Bordeaux.
            </li>
            <li>
              Britain
              <a href="https://www.newcivilengineer.com/latest/the-challenge-of-building-more-reservoirs-to-ensure-uks-water-resilience-01-09-2022/">has not built a new reservoir since 1992</a>. Since then, Britain’s population has grown by 10 million.
            </li>
            <li>
              Despite huge and rising demand, Heathrow annual flight numbers
              <a href="https://en.wikipedia.org/wiki/Heathrow_Airport#/media/File:London_Heathrow_Statistics.png">have been almost completely flat since 2000</a>. Annual passenger numbers have risen by 10 million because
              planes have become larger, but this still compares poorly to the
              22 million added at Amsterdam’s Schiphol and the 15 million added
              at Paris’s Charles de Gaulle. The right to take off and land at
              Heathrow once per week is worth
              <a href="https://cepr.org/voxeu/columns/it-time-auction-slots-congested-airports">tens of millions of pounds</a>.
            </li>
            <li>
              The planning documentation for the Lower Thames Crossing, a
              proposed tunnel under the Thames connecting Kent and Essex, runs
              to 360,000 pages, and the application process alone has cost £297
              million. That is
              <a href="https://www.samdumitriu.com/p/a-boring-story-about-infrastructure">more than twice as much</a>
              as it cost in Norway to <em>actually build</em> the longest road
              tunnel in the world.
            </li>
          </ul>
          <p>
            These are not just disconnected observations. They highlight the
            most important economic fact about modern Britain: that it is
            difficult to build almost anything, anywhere. This prevents
            investment, increases energy costs, and makes it harder for
            productive economic clusters to expand. This, in turn, lowers our
            productivity, incomes, and tax revenues.
          </p>
          <p>
            Everyone reading this will already be aware of the country’s present
            economic sclerosis. Real wage growth has been flat for 16 years.
            Average weekly wages are only
            <a href="https://www.ons.gov.uk/employmentandlabourmarket/peopleinwork/earningsandworkinghours/datasets/averageweeklyearningsearn01">0.8 percent</a>
            higher today than their previous peak in 2008. Annual real wages are
            <em>6.9 percent lower</em> for the median full-time worker today
            than they were in 2008. This essay argues that Britain’s economy has
            stagnated for a fundamentally simple reason: because it has banned
            the investment in housing, transport and energy that it most vitally
            needs. Britain has denied its economy the foundations it needs to
            grow on.
          </p>
          <p>
            From 2010 to the summer of 2024, Britain was run by Conservative-led
            or Conservative Governments. The Conservatives are the traditional
            party of business, and in the 1930s and 1980s they pushed through
            reform programmes that successfully renewed Britain’s economy.
            Virtually any Conservative minister from the past fourteen years
            would speak warmly about that heritage if asked, and would express
            the hope of being its inheritor. And yet, with honourable
            exceptions, the governments of the last fourteen years failed in
            this vocation. Failing systems remained unreformed, continuing to
            stifle Britain’s prosperity. Today Britain is ruled by a Labour
            Government that recognises this failure to build, and which has
            articulated high ambitions for changing this. But it remains
            doubtful that they will be any better at delivering on those
            ambitions than the Conservatives were.
          </p>
          <p>
            Constitutionally, British governments have immense power. How has a
            series of governments with both the will and the means to deliver
            systemic reform failed to do so? How can it be that the overwhelming
            experience reported by former ministers and advisors is one of
            disempowerment – of a ‘blob’ operating beyond their control, of
            pulling levers and nothing happening, of a vast dysfunctional
            machine slowly disintegrating on autopilot?
          </p>
          <p>
            We believe that Britain’s political elites have failed because they
            do not understand the problems they are facing. No system can be
            fixed by people who do not know why it is broken. Like the elites of
            Austria-Hungary, Qing Dynasty China, or the Polish Commonwealth,
            they tinker ineffectually, mesmerised by the uncomprehended disaster
            rising up before them.
          </p>
          <p>
            If any government, Conservative or Labour, wishes to use its powers
            to improve the country, it needs to understand which of Britain’s
            institutions have failed, and why they have done so. Only then can
            they begin to develop a systematic programme of reform that will
            restore Britain’s economy to strength and its society to vitality.
            The alternative is continued drift, relative decline, political
            disenchantment, and a nation unable to meet the great challenges of
            our time. This essay is a first attempt at offering such a
            diagnosis.
          </p>
          <h3 id="falling-behind">Falling behind</h3>
          <p>
            Britain is a country of immense achievement. For most of modern
            history, its people were the richest, healthiest and best educated
            in the world. Its housing stock and its infrastructure was far more
            advanced than those of any of its rivals. It led the Scientific and
            Industrial Revolutions. Its institutions were almost uniquely
            liberal. Though British history contains its share of missteps and
            tragedies, there is probably nowhere else on earth that matches its
            achievements since the mid-eighteenth century, relative to its size
            and resource endowments.
          </p>
          <p>
            Many of these underlying strengths remain. The British people value
            debate and heterodoxy. They respect science, law and institutions.
            In hours of crisis, like the Russian invasion of Ukraine, they
            display unity and good sense. However inefficient and dysfunctional
            they may be, British institutions are strikingly incorruptible. One
            of the scandals of the decade is the alleged embezzlement of a
            campervan, an offence that would surely bring a contemptuous smile
            to the lips of a Putin or a Berlusconi.
          </p>
          <p>
            Despite these strengths, Britain is falling behind the developed
            world in economic dynamism. It led the world in the nineteenth
            century, and then Europe during the first half of the twentieth, but
            it lost its leadership after the Second World War. Since 2008, it
            has been clearly underperforming most of the developed world, even
            some of its more heavily taxed and regulated continental neighbours.
          </p>
          <p>
            Most popular explanations for this are misguided. The Labour
            manifesto
            <a href="https://labour.org.uk/change/kickstart-economic-growth/">blamed slow British growth on a lack of ‘strategy</a>’ from the Government, by which it means not enough targeted
            investment winner picking, and too much inequality. Some economists
            <a href="https://www.ft.com/content/6da72060-cfd2-11e9-99a4-b5ded7a7fe3f">say that the UK’s economic model of private capital ownership is
              flawed</a>, and
            <a href="https://www.ft.com/content/a8fcf263-8506-4b1c-aace-3d3d1743dc55">that limits on state capital expenditure are the fundamental
              problem</a>. They also point to more state spending as the solution, but
            ignore that this investment would face the same barriers and high
            costs that existing infrastructure projects face, and that deters
            private investment.
          </p>
          <p>
            Others believe that our ageing society means permanently lower
            growth and higher taxes. Dietrich Vollrath’s book
            <em>Fully Grown: Why a Stagnant Economy is a Sign of Success</em>
            <a href="https://blogs.lse.ac.uk/europpblog/2020/02/26/slow-economic-growth-is-a-sign-of-success/">says that slower growth is an inevitable part of becoming
              services-driven</a>
            (and of birth rates declining). Another school of thought sees
            Britain’s 2010s performance as ‘one thing after another’, with a
            slow recovery from the financial crisis followed by Brexit, followed
            by Covid.
          </p>
          <p>
            But all of these explanations take the biggest obstacles to growth
            for granted. Our economy isn’t growing for the same reason that no
            more planes take off or land at Heathrow today than did twenty years
            ago: at some point it becomes impossible to grow when investment is
            banned.
          </p>
          <p>
            Over the past two decades, Britain’s economy has needed a huge
            quantity of new housing, transport infrastructure and energy supply.
            Its postwar institutions have manifestly failed to deliver these.
            Britain is now a place in which it is far too hard to build houses
            and infrastructure, and where energy is too expensive. This has
            meant that our most productive industries have been starved of the
            resources, investment and talent – the economic foundations – that
            they need to grow.
          </p>
          <p>
            The UK faces other challenges besides these. Our healthcare and
            higher education systems are so broken that politicians
            <a href="https://yougov.co.uk/topics/politics/trackers/how-the-government-is-handling-the-issue-of-immigration-in-the-uk">elected on a clear mandate to cut migration</a>
            instead let it rise to unprecedented levels to keep them afloat.
            Crime,
            <a href="https://www.ons.gov.uk/peoplepopulationandcommunity/crimeandjustice/bulletins/crimeinenglandandwales/yearendingmarch2024">though it has been falling for years</a>, is substantially higher than it was in pre-Second World War
            Britain, despite a far older population. It is also significantly
            higher than in many other European countries including the
            Netherlands, Spain, Austria, Switzerland, Norway, and Italy.
            Childcare is so expensive that many families have fewer children,
            and later in life, than they would like. Our tax system is
            <a href="https://ifs.org.uk/mirrlees-review">riddled with distortions</a>
            and perverse incentives. There is no consensus about what our higher
            education system is supposed to do, who should benefit from it, and
            who should pay. And our political institutions are sclerotic: at
            best, many are unable to perform their most basic functions; at
            worst, they are a huge barrier to innovation and effective
            governance.
          </p>
          <p>
            But these other challenges do not explain why a huge economic gap
            opened up between us and other leading economies, since problems in
            immigration, crime, childcare, tax, and political institutions are
            also found in exactly the countries that have pulled away from
            Britain economically since 2008. Nor can austerity or the hangover
            from the financial crisis explain Britain’s malaise. The financial
            crisis was at least as turbulent in the United States as here. And
            austerity was at least as tough across Europe, which also had to
            fend with the euro crisis.
          </p>
          <p>
            The Office for Budget Responsibility’s estimate of the impact of
            Brexit says
            <a href="https://obr.uk/forecasts-in-depth/the-economy-forecast/brexit-analysis/#assumptions">that it will knock four percent off long-run UK productivity</a>. This would be very painful, but still only a small fraction of
            the growth we have missed over the past fifteen years. (It also does
            not factor in the positive effect of avoiding destructive
            regulations like the EU Artificial Intelligence Act and Digital
            Markets Act.)
          </p>
          <p>
            Britain’s startling underperformance more recently is explained by
            the more basic factors this document focuses on: preventing
            investment into housing, infrastructure, and energy supply.
          </p>
          <p>
            Prosperity is intrinsically important. It gives people security and
            dignity, leisure and comfort, opportunity and economic freedom. It
            gives us freedom to pursue our other national goals: caring for
            older and less fortunate members of society, upholding a
            law-governed international order, preserving and enhancing our
            landscapes and townscapes, and leading the way in world-changing
            scientific research.
          </p>
          <p>
            But there is even more at stake here than that. We noted above the
            enduring strengths of the British social settlement –
            responsibility, autonomy, love of debate, respect for the
            individual. Economic failure saps confidence in these things. It
            begets dependency, resentment, defeatism, division and bitterness.
            It turns win-win relationships into zero-sum ones, where someone
            else must fail for you to succeed. Economic reform is not only the
            key to prosperity: it is the key to preserving and amplifying what
            is valuable about our society itself.
          </p>
          <h4 id="a-short-history-of-british-productivity">
            A short history of British productivity
          </h4>
          <p>
            Britain’s biggest problem is its low productivity – that is, the
            value of the goods and services people produce per hour they work.
            Before the pandemic Americans were
            <a href="https://www.imf.org/external/datamapper/PPPPC@WEO/USA/GBR">34 percent richer than us</a>
            in terms of GDP per capita adjusted for purchasing power, and
            <a href="https://data-explorer.oecd.org/vis?tm=labour%20productivity&amp;pg=0&amp;snb=86&amp;vw=tb&amp;df%5Bds%5D=dsDisseminateFinalDMZ&amp;df%5Bid%5D=DSD_PDB%40DF_PDB_LV&amp;df%5Bag%5D=OECD.SDD.TPS&amp;df%5Bvs%5D=1.0&amp;dq=.A.GDPHRS..USD_PPP_H.V...&amp;pd=2019%2C&amp;to%5BTIME_PERIOD%5D=false">17 percent more productive per hour</a>. (Purchasing power parity, or PPP, attempts to account for
            differences in purchasing power between countries, rather than just
            using exchange rates). The gap has only widened since then:
            <a href="https://data-explorer.oecd.org/vis?tm=labour%20productivity&amp;pg=0&amp;snb=86&amp;vw=tb&amp;df%5Bds%5D=dsDisseminateFinalDMZ&amp;df%5Bid%5D=DSD_PDB%40DF_PDB_LV&amp;df%5Bag%5D=OECD.SDD.TPS&amp;df%5Bvs%5D=1.0&amp;dq=.A.GDPHRS..USD_PPP_H.Q...&amp;pd=2019%2C&amp;to%5BTIME_PERIOD%5D=false">productivity growth between 2019 and 2023 was 7.6 percent in the
              United States, and 1.5 percent in Britain</a>. This is not a general Western European problem either: the French
            and Germans
            <a href="https://data-explorer.oecd.org/vis?tm=labour%20productivity&amp;pg=0&amp;snb=86&amp;vw=tb&amp;df%5Bds%5D=dsDisseminateFinalDMZ&amp;df%5Bid%5D=DSD_PDB%40DF_PDB_LV&amp;df%5Bag%5D=OECD.SDD.TPS&amp;df%5Bvs%5D=1.0&amp;dq=.A.GDPHRS..USD_PPP_H.V...&amp;pd=2019%2C&amp;to%5BTIME_PERIOD%5D=false">are 15 percent and 18 percent more productive than us</a>
            respectively.
          </p>
          <p>
            Historically, this is exceptional. For most of modern history,
            Britain has been more productive than its peers, and when it has
            started to fall behind, it has successfully reformed itself to
            regain its advantage. Between the mid-eighteenth century and the
            late nineteenth century, Britain was the world’s leading economy.
            <a href="https://worksinprogress.co/issue/the-decline-and-fall-of-britain/">Though it was overtaken by the United States by the beginning of
              the twentieth century</a>, it remained Europe's leading economy until the early 1950s,
            with the continent’s highest productivity and living standards, and
            its most advanced innovating firms.
          </p>
          <p>
            <img loading="lazy" src="https://res.cloudinary.com/dki5hzod1/image/upload/v1726794870/Britain_as_productivity_leader_ioldqg.png" alt="Britain as productivity leader">
            <span>Output per capita, current prices, 1773-1940. Britain led the
              world until taken over by the USA. But it still led Europe at the
              beginning of the Second World War.</span>
          </p>
          <p>
            But
            <a href="https://warwick.ac.uk/fac/soc/economics/research/workingpapers/2017/twerp_1142_crafts.pdf">the reforms of the late 1940s, largely under Clement Attlee’s
              governments, caused Britain to grow more slowly than any other
              major European country</a>
            and the US until the mid-1980s. Britain was overtaken by Germany,
            France, the Netherlands, Belgium, Denmark, Italy and Switzerland.
          </p>
          <p>
            <img loading="lazy" src="https://res.cloudinary.com/dki5hzod1/image/upload/v1726794863/1947-80_euro_takeover_gqmlce.png" alt="Euro takeover">
            <span>Output per capita, current prices, 1947-1980. Britain entered the
              postwar era with a huge advantage over Europe, which it rapidly
              lost, falling behind both France and Germany</span>
          </p>
          <p>
            Privatisation, tax cuts, and the curbing of union power fixed
            important swathes of the UK economy. Crucially, they tackled chronic
            underinvestment in sectors that had been neglected under state
            ownership. Political incentives under state ownership encouraged
            underfunding – and where the Treasury did put money in, it tended to
            go on operational expenditures (e.g., unionised workers’ wages
            rather than capital investments). This problem has
            <a href="https://www.bbc.co.uk/news/articles/cp9rxdrj713o">immediately reemerged</a>
            as the
            <a href="https://capx.co/the-eastern-solution-to-the-southern-rail-problem/">Department for Transport has begun to nationalise various
              franchises</a>
            (which
            <a href="https://www.theguardian.com/politics/2024/apr/24/labour-promises-rail-nationalisation-within-five-years-of-coming-to-power">it promises to do to all of them</a>).
          </p>
          <p>
            Between 1980 and 2008 Britain returned to its position as one of
            Europe’s most successful large economies. For the most part, Tony
            Blair’s governments were able to sustain these advances. In 2005
            Britain’s GDP per capita was
            <a href="https://ourworldindata.org/grapher/gdp-per-capita-worldbank?tab=chart&amp;country=DEU~GBR">just 2.8 percent behind Germany’s, in purchasing power parity
              terms</a>, and fully
            <a href="https://www.imf.org/external/datamapper/NGDPDPC@WEO/GBR/DEU">20 percent <em>higher</em></a>
            in US dollar terms, according to the World Bank. Penn World Tables,
            the other major source, have the UK <em>overtaking</em> Germany on
            GDP per capita in the mid-2000s.
          </p>
          <p>
            Britain’s relative success during this period is clearest when
            compared to other major economies. The chart below shows GDP per
            capita in France, Germany, Italy and the UK as a percentage of US
            GDP per capita. It shows Britain, after decades of relative
            stagnation, beginning to converge on the United States and overtake
            the other European countries from the early 1980s. Britain’s change
            of fortunes under Thatcher, and continued improvement under Blair,
            is clear.
          </p>
          
          <p>
            But crucial parts of the economy were still left unfixed – notably
            land-use planning policy,
            <a href="https://conservativehome.com/2021/05/14/ben-southwood-why-planning-reform-may-work-this-time-round-delivering-us-the-new-homes-that-we-need/">which Thatcher’s Environment Secretary Nicholas Ridley had tried
              and failed to reform</a>, and which Tony Blair’s government was unable to make a dent in
            either.
          </p>
          <p>
            This left Britain with latent weaknesses that have become hugely
            problematic over the last quarter of a century. Since the 1990s,
            Britain has experienced rapid population growth, after decades of
            demographic stability, and big shifts in prosperity from some parts
            of the country to others. The decision to transition away from
            fossil fuels has created the need for huge quantities of new energy
            infrastructure, recently exacerbated by the war in Ukraine, but by
            no means beginning then. Across the developed world, great
            metropolitan agglomerations have become even more economically
            important. London has been among the biggest winners from this
            trend, in spite of the obstacles in its way.
          </p>
          <p>
            What Britain needed in the last 25 years above all was a huge amount
            of building – of homes, energy supply, and transport infrastructure.
            Without it, Britain has fallen behind, weighed down by a development
            system that
            <a href="https://worksinprogress.co/issue/britains-forgotten-financial-crisis/">worked badly even in the 1950s and 60s</a>, and that is positively disastrous today.
          </p>
          
          <p>
            That gap continues to grow. Between 2010 and 2019, worker
            productivity grew by eight percent in the United States, 9.6 percent
            in France and just 5.8 percent in Britain. And those countries’
            growth rates pale in comparison to that of Poland, which has grown
            its productivity by 29.7 percent between 2010 and 2019, and on
            current trends will overtake Britain by the end of this decade.
          </p>
          <p>
            To put the shortfall since 2008 into perspective, if Britain had
            grown in line with its trend between 1979 and 2008, it would be 24.8
            percent more productive today. Assuming we continued working the
            same hours annually, that would mean a GDP per capita of £41,800
            instead of £33,500, making the typical family about £8,700 better
            off before taxes and transfers. Tax revenues would be £1,282 billion
            instead of £1,027 billion, assuming tax rates are held constant.
            That would mean that, instead of a deficit of £85 billion, on
            current spending we would have a surplus of £170 billion, meaning
            that taxes could be much lower, and public services could be better
            funded.
          </p>
          <p>
            Though these figures may seem improbably high, they are not out of
            line with the world’s richest economies, and there is no reason
            Britain should not aim to sit among them as it once did. This essay
            argues that Britain can do so by adopting a programme of reform
            similar in its scale of ambition to that of the programme of
            liberalisation in the 1980s. Where earlier reforms were focused on
            cutting taxes, curbing the power of the trade unions, and
            privatising state-run industries, this time we must focus on making
            it easier to invest in homes, labs, railways, roads, bridges,
            interconnectors, and nuclear reactors.
          </p>
          
          <h3 id="the-importance-of-strong-foundations">
            The importance of strong foundations
          </h3>
          <h4 id="why-is-france-so-rich">Why is France so rich?</h4>
          <p>
            France is notoriously heavily regulated and dominated by labour
            unions. In 2023, the country was brought to a standstill by strikes
            against proposals to raise the age of retirement from 62 to 64.
            French workers have been known to strike by
            <a href="https://www.theguardian.com/world/2009/mar/26/3m-france-boss-kidnapping">kidnapping</a>
            their
            <a href="https://www.nytimes.com/2009/04/03/business/global/03labor.html">chief executives</a>
            – a practice that the public there
            <a href="https://web.archive.org/web/20090411043129/http://www.businessweek.com/globalbiz/blog/europeinsight/archives/2009/04/sarkozys_bossna.html">reportedly supports</a>
            – and strikes are so common that French unions have designed special
            barbecues that fit in tram tracks so they can grill sausages while
            they march.
          </p>
          <p>
            <img loading="lazy" src="https://res.cloudinary.com/dki5hzod1/image/upload/v1726794869/strike_sausages_weyawi.jpg" alt="Marchers barbecue sausages">
          </p>
          <p>
            France is notoriously heavily taxed. Factoring in
            <a href="https://stats.oecd.org/Index.aspx?DataSetCode=TABLE_III2">employer-side taxes</a>
            in addition to those the employee actually sees, a French company
            <a href="https://x.com/s8mb/status/1742980931051479522">would have to spend €137,822</a>
            on wages and employer-side taxes for a worker to earn a nominal
            salary of €100,000, from which they would take home €61,041. For a
            British worker to take home the same amount after tax (£52,715,
            equivalent to €61,041), a British employer would only have to spend
            €97,765.33 (£84,435.6) on wages and employer-side taxes.
          </p>
          <p>
            And yet, despite these high taxes, onerous regulations, and powerful
            unions, French workers are significantly more productive than
            British ones – closer to Americans than to us. France’s GDP per
            capita is only about the same as the UK’s because French workers
            take more time off on holiday and work shorter hours.
          </p>
          <p>
            What can explain France’s prosperity in spite of its high taxes and
            high business regulations? France can afford such a large,
            interventionist state because it does a good job building the things
            that Britain blocks: <strong>housing</strong>,
            <strong>infrastructure</strong> and <strong>energy supply</strong>.
          </p>
          <p>
            Housing supply is vastly freer in France. Overall, it now has about
            seven million more homes than Britain (<a href="https://www.insee.fr/en/statistiques/5009609">37 million</a>
            versus
            <a href="https://www.ons.gov.uk/peoplepopulationandcommunity/housing/articles/researchoutputssubnationaldwellingstockbytenureestimatesengland2012to2015/2020">30 million</a>), with the same number of people. Those homes are newer, and are
            more concentrated in the places people want to live: its prosperous
            cities and holiday regions.
            <a href="https://x.com/freddie_poser/status/1829902575656976852">The overall geographic extent of Paris’s metropolitan area
              roughly tripled between 1945 and today, whereas London’s has grown
              only a few percent.</a>
            France has allowed its other great cities to grow and flourish too,
            whereas Britain has systematically constrained and undermined them
            for seven decades.
          </p>
          <p>
            <img loading="lazy" src="https://res.cloudinary.com/dki5hzod1/image/upload/v1726794869/growth_of_paris_ksqw2z.jpg" alt="growth_of_paris">
            <span>Paris, 1937 and today: the 1937 map is inset in the contemporary
              one. Everything outside the centre is still new. London is almost
              unchanged in surface area today from 1937.</span>
          </p>
          <p>
            Transport infrastructure is now better there: there are seven
            British tram networks, versus 29 in France. Six French cities have
            underground metro systems, against three in Britain. Since 1980,
            France has opened 1,740 miles of high speed rail, compared to just
            67 miles in Britain. France has nearly 12,000 kilometres of
            motorways versus around 4,000 kilometres here – and French motorways
            tend to be smoother and better kept (and three quarters are tolled,
            making congestion much less of a problem). In the last 25 years
            alone,
            <a href="https://assets.publishing.service.gov.uk/media/5a7caaaa40f0b65b3de0a672/action-for-roads.pdf">the French built more miles of motorway than the entire UK
              motorway network</a>. They are even allowed to drive around 10 miles per hour faster on
            them.
          </p>
          <p>
            Energy is more abundant and, thanks to the country’s nuclear
            roll-out from the 1970s, the country has already done a lot of
            decarbonisation.
            <a href="https://world-nuclear.org/information-library/country-profiles/countries-a-f/france.aspx">Seventy percent of the country’s electricity comes from nuclear
              power</a>, which does not suffer from the intermittency problems that wind
            and solar power both face, which
            <a href="https://www.mcc-berlin.net/uploads/media/Ueckerdt_Hirth_Luderer_Edenhofer_System_LCOE_2013.pdf">drive up their costs significantly</a>
            since they require energy storage and backup fossil fuel generation.
          </p>
          <p>
            Britain
            <a href="https://cerncourier.com/a/cockcrofts-subatomic-legacy-splitting-the-atom/">was the first country to split the atom</a>, and built the
            <a href="https://www.samdumitriu.com/p/how-to-get-new-nuclear-built-faster/">world’s first commercial nuclear power plant</a>
            that supplied energy to a national grid, opened by the late Queen in
            1956. In the following decade, Britain built ten more nuclear power
            stations.
            <a href="https://x.com/engineers_feed/status/1409126163176476676">In 1965, we had more operational nuclear reactors than the USA,
              the USSR, and every other country in the world put together</a>, yet we haven’t finished a new nuclear power station in almost
            three decades.
          </p>
          <p>
            Because France gets these big things right, it can afford to get a
            lot of other things wrong. If Britain could catch up with France on
            housing, infrastructure and energy, without making the sort of
            mistakes it makes on regulation and tax, the implication is that we
            could be far richer than they are, as we were for centuries before
            the 1950s.
          </p>
          <h4 id="weak-foundations-investment-housing-infrastructure-and-energy">
            Weak foundations: investment, housing, infrastructure and energy
          </h4>
          <p>
            Britain gets many of the important things for prosperity right.
            Businesses from around the world come here to draw on our legal
            regime, low levels of corruption, centuries-old commitment to free
            trade, efficient financial sector, and world-leading scientific
            research ecosystem. Our time zone allows us to talk to Asia, Africa,
            and the Americas all in one day, and everyone here is fluent in the
            modern world’s
            <a href="https://en.wikipedia.org/wiki/Mediterranean_Lingua_Franca"><em>lingua franca</em></a>. As the economist Tyler Cowen said, England remains ‘<a href="https://www.ft.com/content/1e6d106c-8462-4691-9c4b-eb57afec9907">one of the few places where you can really birth and execute a
              new idea</a>’. This is unbelievably precious, rare, and difficult to create.
          </p>
          <p>
            But we fail to capitalise on these rare advantages because the
            economy lacks the most important foundations: private investment is
            blocked from going where it could generate the highest returns,
            meaning we have lower investment than all our peer economies; in
            particular we do not allow investment in the infrastructure we need
            to allow people to access prosperous areas, the houses they need to
            live there, and the offices, labs, factories, and warehouses they
            need to work there, which, together with our high and rising energy
            costs, stop the companies in those cities reaching their full
            potential.
          </p>
          <p>
            Britain’s best chance of achieving rapid economic growth in the near
            term is via a combination of higher private
            <strong>investment,</strong> more <strong>agglomeration</strong> –
            that is, greater clustering of economic activity in productive
            places – and lower <strong>energy costs</strong>.
          </p>
          <p>
            These economic foundations are important determinants of how
            productive workers and businesses are.
          </p>
          <p>
            No individual by themselves can create much value, no matter how
            gifted or hardworking they might be. They need to combine their
            efforts with machinery and other people to really succeed.
            Investment rates determine the amount and quality of the tools they
            can use; energy costs determine how they can use them; and
            agglomeration – including both housing and infrastructure –
            determines who they can use them with.
          </p>
          <p>
            <img loading="lazy" src="https://res.cloudinary.com/dki5hzod1/image/upload/v1726794872/Estonia_Poland_catch-up_pcss8e.png" alt="Estonia_Poland_catch-up">
          </p>
          <p>
            <span>Output per capita, current prices, 1990-2022. Those middle-income
              countries that have decent institutions have been rapidly
              converging on Britain</span>
          </p>
          <p>
            These policies are a complement to Britain’s most advanced frontier
            sectors. More agglomeration drives higher rates of innovation, and
            increases the choices that businesses have about who to hire. Lower
            energy costs make certain high-tech sectors more viable, such as
            advanced manufacturing and AI training. Higher rates of investment
            into businesses make it easier for smaller companies to rapidly
            scale up into giants.
          </p>
          <p>
            Rapid economic growth is possible for Britain. Because what we get
            wrong is so mundane and straightforward, fixing these problems would
            allow Britain to experience similar rapid
            <a href="https://www.sambowman.co/p/britain-is-a-developing-country">‘catch-up’ growth</a>
            that countries like South Korea, Estonia, and Poland have
            experienced over the past thirty years.
          </p>
          <h3 id="investment">Investment</h3>
          <p>
            Investment is when we forgo resources that we would consume today,
            and instead use them to produce more resources in the future. It is
            the life-blood of economic growth, and of individual businesses’
            successes. Investment is not just what happens after we build
            sufficient roads, houses, pylons, and power plants: building those
            things <em>is</em> investment.
          </p>
          <p>
            What is good about building these things is not that they cost
            money, and what matters is not how much money we spend on
            investment. It is the things we actually produce, and the benefits
            they give us, that are valuable: the easier and less expensive it is
            to build them, the higher the return we get for a given amount of
            money invested, and the better it is to spend money on them.
          </p>
          <p>
            Britain does invest at a lower rate than most other advanced
            countries. In 2022, France spent (across both public bodies and
            private companies) 26 percent of its GDP on physical capital
            investment; Germany 25 percent; OECD members 23 percent on average;
            the United Kingdom just 19 percent. The total capital stock of the
            UK is actually lower now than it was in 2016; by comparison, it is
            14 percent higher on average across the rest of the G7.
          </p>
          <p>
            The most important reason for this is not that we are inherently
            penny-pinching and short-termist, where Americans and Europeans are
            not. It is that we have banned most of the most productive
            investments we could make, made it eye-wateringly expensive to do
            the ones we do allow ourselves to make, and allowed many
            publicly-managed assets to be neglected.
          </p>
          <p>
            <img loading="lazy" src="https://res.cloudinary.com/dki5hzod1/image/upload/v1726816553/investment-as-share-of-GDP_uxayit.png" alt="investment-as-share-of-GDP">
          </p>
          <p>
            These problems have been present for more than half a century. In
            the postwar decades, the British state chronically failed to invest
            in the various companies it had nationalised, succumbing to the
            permanent temptation of politicians to allocate resources to
            frontline services (i.e. immediate consumption) rather than
            investing for the long term. We see this every year with the NHS,
            whose operational budget continues to rise, but
            <a href="https://inthesightoftheunwise.substack.com/p/episode-twenty-two-the-big-nhs-problem">which has the fewest MRI and CT scanners of any developed
              country’s healthcare system, and by far the least machinery and
              equipment</a>
            overall.
          </p>
          
          <p>
            British Rail ran in 1994
            <a href="https://learninglegacy.hs2.org.uk/wp-content/uploads/2021/10/J001-Munro-jtran.18.00040.pdf">a third as many trains</a>
            between London and Manchester as did private franchises by the 2010s
            – overall passenger numbers fell steadily between nationalisation in
            1948 and privatisation in 1994,
            <a href="https://x.com/s8mb/status/1783395040296866199">after which point they have more than doubled</a>. Many state-run British industries became efficient in terms of
            economising on the scarce resources they were allowed, but extremely
            inefficient in terms of overall productivity.
          </p>
          <p>
            The privatisations of British Steel, British Airways, British Gas,
            British Telecoms and many other nationalised companies in the 1980s
            and 90s thus opened up great opportunities. From 1981 to 1990,
            British capital investment
            <a href="https://data-explorer.oecd.org/vis?tm=gross%20fixed%20capital%20formation&amp;pg=0&amp;snb=74&amp;vw=tb&amp;df%5Bds%5D=dsDisseminateFinalDMZ&amp;df%5Bid%5D=DSD_NAMAIN10%40DF_TABLE1_EXPENDITURE_CPC&amp;df%5Bag%5D=OECD.SDD.NAD&amp;df%5Bvs%5D=1.0&amp;dq=A.AUS%2BAUT%2BBEL%2BCAN%2BCHL%2BCOL%2BCRI%2BCZE%2BDNK%2BEST%2BFIN%2BFRA%2BDEU%2BGRC%2BHUN%2BISL%2BIRL%2BISR%2BITA%2BJPN%2BKOR%2BLVA%2BLTU%2BLUX%2BMEX%2BNLD%2BNZL%2BNOR%2BPOL%2BPRT%2BSVK%2BSVN%2BESP%2BSWE%2BCHE%2BTUR%2BGBR%2BUSA.S1..P51G.N11G......&amp;pd=1981%2C1990&amp;to%5BTIME_PERIOD%5D=false">grew faster than any other country in the OECD</a>
            barring booming Japan and tiny Luxembourg. Contrary to what is
            sometimes claimed, North Sea oil and gas was not the biggest part of
            this, with investment in it
            <a href="https://www.escoe.ac.uk/research/historical-data/national-accounts-2/">actually falling over this period</a>. Investment levels rose chiefly because state mismanagement had
            left so many opportunities untaken in the preceding decades –
            opportunities that privatisation opened up.
          </p>
          <p>
            Underinvestment leads to particularly acute problems in places like
            the North of England that have historically prospered from
            capital-intensive industries. These areas have the same underlying
            features that generate industrial heartlands elsewhere, like in
            Germany and Sweden: relatively cheap land, proximity to waterways,
            roads and rail networks, and – unlike many other parts of Britain –
            cheap, abundant housing. But expensive energy and the difficulty of
            building new premises, warehouses, factories, pipelines, pylons,
            distribution centres, and so on holds them back.
          </p>
          <p>
            Some of this underinvestment is due to
            <a href="https://www.adamsmith.org/blog/full-expensing-the-best-idea-in-politics-youve-never-heard-of">distortions in the tax code</a>
            that penalise capital investments. Prior to the introduction of full
            expensing, British businesses that invested in machinery, buildings
            and acquired patents
            <a href="https://www.samdumitriu.com/p/the-super-deduction">could only claim back 62 percent</a>
            of the costs from their corporation tax bill (compared to 100
            percent for operating expenses like rent or wages), which meant that
            despite the UK having a low headline rate of corporation tax, the
            effective rate on profits generated via physical investments was
            still high. The introduction of full expensing has corrected this
            for some investments, but still does not apply to buildings or
            machinery with an expected lifespan of over twenty-five years.
            Business rates, meanwhile,
            <a href="https://www.ft.com/content/abadf956-dca6-11e5-8541-00fb33bdf038">have the effect of increasing the tax liability when most
              property enhancements are made</a>, regardless of when or if they become profitable.
          </p>
          <p>
            Some of the underinvestment is due to higher input costs, such as
            the high cost of energy, discussed later. This is most acutely a
            problem for the manufacturing sector, where high energy costs have
            made many industries unviable in Britain, while they thrive in other
            advanced economies.
          </p>
          <p>
            But the most important reason Britain sees underinvestment today is
            that the state bans the very investments that would be most
            valuable. If allowed, private investors would be rushing to build
            housing, transport infrastructure and energy infrastructure.
            France’s thousands of miles of motorways
            <a href="https://en.wikipedia.org/wiki/Autoroutes_of_France">were built, and are operated by, private companies</a>. Britain’s
            <a href="https://www.economics.uci.edu/files/docs/workingpapers/2004-05/Bogart-02.pdf">roads</a>,
            <a href="https://pdf.sciencedirectassets.com/272329/1-s2.0-S0014498318X00060/1-s2.0-S0014498318300263/am.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjECoaCXVzLWVhc3QtMSJHMEUCID%2Bbqe6I05GlU%2FzRUncBqPAmUJ1V94iPy41%2B5%2ByDiGo%2FAiEA31YtnPYt6HqXQGdF8ObOD1cgsnz7SKRuPFz9u7w2JkIqsgUIQxAFGgwwNTkwMDM1NDY4NjUiDOWrFGkZeEdIW8CEFyqPBbDkrdqIgcwcNaUFbUQXmaSeMvpHS3YIbDMw%2FIyUysDkBoIEhHEMF4vwuvkUNDWdZRkrocIqoP36fpkn4Zb6u9dRu9CPR5sGw7R9No0vaJ5qYBRNoqSaWjOBuOKEiulqsIhMj0AL8pyPu4UYoFo%2B%2FogRFKMMuF8ZVZ34upd%2Bw6JpXmbrJmbrRjDZapq8ZjnMDcTvdij%2BZ1CvWO9Vr12wHtxRI73OWEqidkzZkQrf2LYmaoxxhqreYzQjHjZ6nHkCDuMNFHr6nzvS1Zujz1I7QHSI42ulCCctZdWgUbcXJW2u%2FI%2FHJEq58Ubx3w5IWcR%2FxQMebD0xnvmsbS5Q0AohtyeN6MLpTBElI7Mxaoqeq2ipMpVEBPVXXYixB%2BjOlH%2BYy1wQa8QuVWCQ%2F7adB2QG%2BpUJzMTU1iBWYBZXFGhVHxNMv159d%2BUZkf6hHC0fMmzwvrmx1MLHJ9HeDGsqUZszKgeRAdL6YWXz7VIX4yG7CR%2B3y0d7BFiZHvSOoNByD3ZM8bhlb%2FA4bBc2R2d5zErIGAW2aCna%2BPmoVGHEBER4bs7l%2FnlLAZcma5bTf5azV7mr43KWuG7w7u5bFhcYXSpzj5WaY1jaW1SuxSJVLDQTvlUEjlGWJaDdwa9xQe%2BFtD%2FU2D1bGR1wxA3oXiQ304iEOlHO73GrnoAxtsvTg08PbWzY752WaMcKq1yXgg442jzucZ6F1myz5vH5urUU2X1Pp1KaNaKTlPCe%2FReK3wzXyhAgrHQTuGlMoM%2Ba2QG%2FvzvLAhQUl797bkiQZ1Z%2FDas3DYjLItOwxpVDBdb3HLMdhe0j6dpjWx1gbtyHeDAc2H1c1TyhcgKocHYuRW0TpJygMl7UJXDi6zJRwM%2BltQ3TNRIwx%2FzAtgY6sQH7IYfRuLzOLL4fwT%2FIggv5kkQyOADZFknRHkTgNqSyI%2FnFxcL0%2Bp05IWft%2FIoaRo%2Fc%2BMvtn%2FdqkvIlk%2BX2GxwaaO6aXmFLRrLUqD%2FBBlPyjrsfIE3pibHfJHbyGN4aryq%2B8PS2aGAxqNxnwYlLI7dZma3bpan0rXjzDNi3wLjmzTLCPVqdaKHlkLpcg%2BxrCZx9Pe%2BtNu2NkjmQPtYrK7Rg%2FKmNQ173lrFfW9ac2t6eV7k%3D&amp;X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Date=20240829T101651Z&amp;X-Amz-SignedHeaders=host&amp;X-Amz-Expires=300&amp;X-Amz-Credential=ASIAQ3PHCVTYUJJH2AJS%2F20240829%2Fus-east-1%2Fs3%2Faws4_request&amp;X-Amz-Signature=e810352f4bcbc6a4eee8c3d3bef9c02332103875684660e8589e1ae1ed3f8d34&amp;hash=803dd8e866bc53adbded9e7aba7f6fe667bac47ec9f1e27fd675ea3856176e06&amp;host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&amp;pii=S0014498318300263&amp;tid=pdf-df7171fc-a551-4e63-b5e2-3d20ea26a4fc&amp;sid=ddcceed818473047501a1889e17d297ca9abgxrqb&amp;type=client">canals</a>, and
            <a href="https://www.sciencedirect.com/science/article/pii/S0094119021000723">railways</a>
            were originally built this way. If done today, this would show up as
            enormous amounts of capital investment in the national accounts. But
            as we will show, building these things is prohibited in the vast
            majority of cases in which it would be economically rational. If we
            change that, Britain would see an enormous construction boom as
            suppressed demand for these things was met, and the resulting
            capital assets would continue contributing to the economy
            indefinitely.
          </p>
          <p>
            Improving the UK’s investment rate would bring great benefits:
            <a href="https://www.amazon.co.uk/Restarting-Future-How-Intangible-Economy/dp/0691211582">about half the shortfall in productivity growth since the
              financial crisis can be attributed to underinvestment in
              (tangible) capital</a>, while much of the rest is likely to be due to the shortfall in
            intangible investments like R&amp;D.
          </p>
          <p>
            Investment is what makes us richer over time. Any successful
            economic plan will have to unleash it in order to succeed. But even
            as the need for higher investment becomes more widely accepted by
            Britain’s economic commentators, they tend to propose more quangos
            and subsidies to tackle the problem, because they miss two crucial
            points.
          </p>
          <p>
            First: private investment is far more significant than government
            investment. Public investment can be extremely important, especially
            in areas that have large spillovers to the broad economy, but which
            do not always generate a private return. But more than 80 percent of
            investment in the UK and most other developed countries is done by
            the private sector. Public investment was 18.0 percent of the UK
            total in 2021, 17.6 percent in 2020, and 15.5 percent in 2019.
          </p>
          <p>
            And second: apart from taxes on investment like corporation tax and
            capital gains tax, higher investment in the UK is mainly frustrated
            by systems that effectively ban private companies from doing it
            (like building houses, infrastructure, and energy generation),
            rather than being down to short-sightedness by these businesses, or
            a lack of generosity by government.
          </p>
          <p>
            Commentators have searched far and wide for explanations of
            Britain’s investment problem. But the explanation was before our
            eyes all along. Buildings, energy and transport infrastructure are
            the investments that Britain most needs, and they are largely
            banned. In banning them, we have generated higher costs for a range
            of other investments too. There is no need to posit esoteric
            cultural problems among British businesspeople, no need for a dozen
            more government strategies, deals and consultations. We don’t need
            to pay businesses to invest more. We just need to stop banning them
            from doing so.
          </p>
          <h3 id="housing">Housing</h3>
          <h4 id="why-were-not-building-enough-homes-in-the-right-places">
            Why we’re not building enough homes in the right places
          </h4>
          <p>
            For centuries, Britain had a development control system that
            supported urban growth in the places with the most successful
            industries, as well as building beautiful cities that we treasure
            today. Since 1947, however, Britain has had probably the most
            restrictive development control system in the world. This has held
            back our strongest sectors and businesses and stopped people from
            moving to the places with the best jobs. On its own, we see it as
            the largest cause of British stagnation.
          </p>
          <p>
            Throughout Britain’s history, its economic centre of gravity has
            changed, sometimes profoundly. During the 1800s, millions of people
            migrated to the cities of the Midlands, Wales, and especially the
            North of England, where the Industrial Revolution was
            revolutionising the world economy. Cardiff grew by around 1,000
            percent in 45 years as people moved near the coal that enabled heavy
            industry. Manchester grew from 90,000 in 1800 to 700,000 in 1900, in
            part due to the soft water that enabled Lancashire’s world-beating
            cotton textiles. Liverpool grew by over 1,000 percent between 1800
            and the 1930s.
          </p>
          <p>
            This process continued in the 1930s, but as different industries
            came to the fore, different locations were predominant. Cities like
            Birmingham, Coventry, London, Leicester, and Nottingham expanded at
            breakneck pace as the link with raw materials was broken, and jobs
            shifted to offices and factories in the South and Midlands. Immense
            suburbs sprang up, with their characteristic long gardens and
            semi-detached houses. Private companies and local councils laid out
            a vast system of commuter rail, electric trams and motorbuses that
            enabled and served these new neighbourhoods. The English housing
            stock
            <a href="https://www.designingbuildings.co.uk/wiki/English_housing_stock_age">nearly doubled in twenty years</a>, transforming the living standards of the English people.
          </p>
          <p>
            <img loading="lazy" src="https://res.cloudinary.com/dki5hzod1/image/upload/v1726794867/metroland_f3nbkh.jpg" alt="metroland">
          </p>
          <p>
            As late as the 1930s, there were almost no restrictions on
            development, other than generous height limits in some cities (about
            ten storeys) and some building safety regulations. Subject to those,
            any property owner
            <a href="https://capx.co/solving-the-planning-problem/">could build virtually anything they wanted</a>. After 1909, developers did have to get permission to develop, but
            councils almost always gave it, since they had to compensate
            landowners for the lost value if they rejected permissions, and
            councils were themselves generously compensated through local
            property taxes if they accepted development.
          </p>
          <p>
            In sum, before the 1940s, British cities grew as their industries
            did. People moved, in their millions, around the country. People
            moved to places where wages were higher, raising wage competition
            for workers in the places that they left. This meant that there were
            fewer and narrower persistent income differences between places than
            those we see today. Liberal development policy generated a country
            with a natural force pushing against persistent, entrenched regional
            inequality,
            <a href="https://www.bensouthwood.co.uk/p/regional-inequality-also-a-housing">which was narrowing in the decades to the 1940s and has been
              widening since</a>.
          </p>
          <h4 id="the-source-of-the-problem">The source of the problem</h4>
          <p>
            In 1947, the Town and Country Planning Act (TCPA) was introduced,
            part of the postwar reform programme that nationalised nearly every
            major industry, from
            <a href="https://www.adamsmith.org/blog/steel-nationalized">steel</a>
            to
            <a href="https://en.wikipedia.org/wiki/Transport_Act_1947">man-with-van road haulage companies</a>, and normalised top tax rates at over 90 percent. The TCPA
            completely removed most of the incentive for councils to give
            planning permissions by removing their obligation to compensate
            those whose development rights they restricted. Other reforms at
            around the same time also redistributed away much of the upside that
            councils had received from development through local property taxes.
          </p>
          <p>
            The law also added a requirement to get permission from
            <em>national government</em> for any development, and to pay to the
            national government a tax of 100 percent on any value that resulted
            from permission being granted. Most notoriously, the TCPA instituted
            the legal powers that were used to create and expand green belts the
            following decade, prohibiting development on large rings of land
            around England’s cities.<sup><a href="#footnote-1" id="footnote-source-1">1</a></sup>
          </p>
          
          <p>
            Overall, it moved Britain from a system where almost any development
            was permitted anywhere, to one where development was nearly always
            prohibited. Despite some minor later liberalisations, like the
            introduction of permitted development rights in the 1980s, the
            underlying problem remains. Since the TCPA was introduced in 1947,
            private housebuilding has never reached Victorian levels, let alone
            the record progress achieved just before the Second World War.
          </p>
          <p>
            Today, local authorities still have robust powers to reject new
            developments, and little incentive to accept them. Historically,
            local governments encouraged development because their tax bases
            grew in line with the extra value created, but this incentive has
            been
            <a href="https://www.sambowman.co/p/one-weird-trick-to-get-data-centres">eroded by successive reforms that have centralised and capped
              local governments’ tax-raising powers</a>.
          </p>
          <p>
            National governments have not been blind to the fact that
            development is not happening. Their solution to the problem has
            generally been
            <a href="https://worksinprogress.co/issue/why-britain-doesnt-build/">to try to force local governments to permit the homes the country
              needs</a>
            (and take the political flak that engenders) through targets and
            punishments. But this system has never managed to raise building
            rates by anywhere near enough to return prices to the downward trend
            they were on for hundreds of years until 1938.
          </p>
          <p>
            Attempting to force local governments to build more homes has
            repeatedly backfired, and where it has delivered new homes they have
            often been
            <a href="https://eprints.lse.ac.uk/26348/">low quality and far from where the highest demand for homes is</a>, since the targets are calculated with almost no reference to
            actual demand for new houses. There is little reason to think the
            new government’s plans will be very different, and
            <a href="https://www.thetimes.com/uk/politics/article/labour-needs-to-build-homes-where-people-want-to-live-zv6vlk53f">its decision to lower London’s target as a ‘reward’ for failing
              to meet its previous targets</a>
            is a sign that it, too, will fail to build homes where they are
            needed most.
          </p>
          <p>
            Local people bear many of the costs of new development – disruption,
            congestion, and competition over access to state-provided services
            like healthcare and education. At the same time, they gain few or
            none of the benefits, the obvious exception being those local
            landowners who actually receive the planning permissions. It is thus
            unsurprising that local people tend to be
            <a href="https://journals.sagepub.com/doi/10.1177/09516298211044852">fierce opponents of development</a>. When the national government has tried to take away their right
            to control development nearby, they have resisted vigorously,
            <a href="https://www.mirror.co.uk/news/politics/government-ditches-mutant-housing-formula-23176334">usually succeeding in having the targets revoked or watered
              down</a>.
          </p>
          <p>
            This has contributed to a climate that is supportive of continual
            increases in regulations at the national level, which add process
            and cost to development. Recently, this has meant compulsory
            <a href="https://www.samdumitriu.com/p/against-banning-buildings-with-just">second staircase requirements</a>, which ban apartment blocks with only one staircase and lift core
            – the standard type in nearly every country in the developed world.
            (The Government’s own impact assessment of the second staircase
            rules determined that
            <a href="https://x.com/s8mb/status/1775116154291224839">their costs would be more than two hundred times greater than
              their benefits</a>.) It has also meant reducing the sizes of windows: it is now
            legally difficult to build windows
            <a href="https://x.com/SCP_Hughes/status/1674006804076920834">as large as those common in Georgian and Victorian buildings</a>, apparently because they cause overheating in hot weather, and
            because people might supposedly fall out of them.
          </p>
          <p>
            The same climate has facilitated rules requiring every development
            to prove ‘nutrient neutrality’, to survey for protected species like
            newts and bats (even
            <a href="https://www.ft.com/content/a080c618-c250-45cf-9728-8ec8ddd0a56c">in places where their presence has never been detected</a>), and more.
          </p>
          <p>
            High housing costs also create the demand for destructive policies
            that appear to alleviate the proximate problems of expensive housing
            without dealing with the underlying issue. In many cases today, as
            many of 40 percent of a new development’s homes must be subsidised
            for ‘affordable’ renters instead of being made available at market
            rates. These requirements function as a tax on new housing (and so
            local objectors often support them), redistributing income from
            every other private tenant to a lucky few. Countries with expensive
            rental housing also see movements for rent controls, and punitive
            rental regulations, like giving every tenant the permanent right to
            live in the property they occupy.
          </p>
          <h4 id="the-economic-effects-of-housing-shortages">
            The economic effects of housing shortages
          </h4>
          <p>
            Since the introduction of the British planning system in 1947,
            <a href="https://worksinprogress.co/issue/why-britain-doesnt-build/">there has been very little increase in housing supply when better
              jobs make an area more desirable</a>. Instead of extra homes being built, workers competing for scarce
            housing
            <a href="https://www.worksinprogress.news/p/agglomeration-benefits-are-here-to">are forced to bid up the price of existing homes</a>. This means that many of the income gains go to existing landlords
            and landowners, and that many people cannot move to better jobs at
            all.
          </p>
          <p>
            Because only the best paid people can afford to move to the most
            prosperous cities,
            <a href="https://www.bensouthwood.co.uk/p/regional-inequality-also-a-housing">there is no longer general migration across the economic
              spectrum</a>, as there was in the nineteenth century when it was
            <a href="https://cepr.org/voxeu/columns/productivity-and-migration-new-insights-19th-century#:~:text=From%20brief%20inspection%2C%20it%20is,concentrated%20in%20low%2Dskilled%20jobs.">the <em>poorest</em> people who were most likely to move to find
              better work</a>. Today, this has created a situation where only the most gifted
            and educated people can afford to move to richer cities and stay
            there. Their less well-off peers are quite literally ‘left behind’,
            and compete with one another over a narrow pool of jobs, driving the
            wages down even further, making those places feel even more
            deprived.
          </p>
          <p>
            On the other hand, social housing anchors many people to extremely
            central, high-value areas in our major cities. A staggering amount
            of central London’s housing is socially rented:
            <a href="https://www.ons.gov.uk/census/maps/choropleth/housing/tenure-of-household/hh-tenure-5a/rented-social-rented">40.2 percent of Islington households</a>
            are on subsidised social rents; as are 33.7 percent of Camden’s;
            35.9 percent of those in Tower Hamlets; and 39.7 percent of
            Southwark’s. These households occupy some of the most valuable space
            in the country, and are trapped in their tenancies, remaining even
            when their homes, often damp, poorly insulated, and altogether
            dilapidated, are no longer fit for their changing circumstances,
            because they will likely end up in a less valuable, less
            centrally-located property if they try to move.
          </p>
          <p>
            The result is a ‘missing middle’ in cities like London, where only
            the very well-off and very badly-off can afford to live there,
            excluding lower- and middle-income people from elsewhere in the
            country. Even many higher earners cannot afford to live anywhere
            near the centre once they have children. The impoverishment of
            coastal and post-industrial towns cannot be understood without
            looking at housing shortages in more prosperous parts of the
            country: both are the products of Britain’s planning system.
          </p>
          <p>
            Since the supply of homes in successful cities is tightly
            constrained, the growth of our most successful companies and sectors
            within those cities is constrained as well. Even the people who do
            get to live in high-productivity places are less productive than
            they could be, since their employers are less able to hire mid- and
            lower-skilled people to support them in the workplace. It is
            inconceivable that Britain could have had the Industrial Revolution
            if it had banned workers from moving to the coalfields of South
            Wales and Yorkshire and the textile factories of Lancashire. It is
            not an exaggeration to say that Britain could be forgoing its role
            in another industrial revolution today – that of artificial
            intelligence, biotech, and related technologies – by making the
            corresponding mistake.
          </p>
          <p>
            <img loading="lazy" src="https://res.cloudinary.com/dki5hzod1/image/upload/v1726795756/ons_cartogram_nvbdx4.png" alt="ons_cartogram">
            <span>A cartogram (from the
              <a href="https://www.ons.gov.uk/visualisations/nesscontent/dvc126/">Office for National Statistics</a>) of the number of jobs around the country. Dark red are highest
              paid, then light red, then grey, then light blue, then dark blue.
              The average job in dark red areas pays about double as much as the
              average job in dark blue areas.</span>
          </p>
          <p>
            Britain is not the only country that has slowed its growth through
            holding back agglomeration. Parts of America have seen similar
            shortages. Economists Gilles Duranton and Diego Puga
            <a href="https://www.nber.org/papers/w26591">judge that</a> if the
            whole of New York City allowed the densities that were common in
            Georgian and Victorian London, rents and house prices would fall
            towards construction costs, and the metropolitan area would at least
            double in population, to over 40 million people. Similar things
            would happen to the Bay Area, Boston, Los Angeles, and other US
            ‘superstar’ cities if higher densities were allowed. Duranton and
            Puga argue that huge economic growth would result from allowing
            these superstar cities to build more.
          </p>
          <p>
            <img loading="lazy" src="https://res.cloudinary.com/dki5hzod1/image/upload/v1726794870/residential_bzz7et.png" alt="residential">
            <span>The value of land with and without planning permission. Releasing
              land for development is much more valuable in some places than in
              others. From
              <a href="https://www.resolutionfoundation.org/publications/building-blocks/">the Resolution Foundation</a>.</span>
          </p>
          <p>
            But things are much worse here in Britain. Overall, American homes
            only cost around
            <a href="https://fred.stlouisfed.org/series/MSPUS">a third more to buy</a>
            <a href="https://www.forbes.com/home-improvement/contractor/cost-to-build-a-house/">than they do to build</a>.<sup><a href="#footnote-2" id="footnote-source-2">2</a></sup>
            <a href="https://www.aeaweb.org/articles?id=10.1257/jep.32.1.3">About four fifths of American cities saw no gap at all</a>
            between house prices on the edge of town and the building costs of
            such homes in the mid-2010s, implying no significant overall
            regulatory land-use barriers to development in these places.<sup><a href="#footnote-3" id="footnote-source-3">3</a></sup>
          </p>
          <p>
            <img loading="lazy" src="https://res.cloudinary.com/dki5hzod1/image/upload/v1726794864/Tony_Blair_structures_value_image_lcq2jo.png" alt="Tony_Blair_structures_value">

            <span>The UK has vastly less structure value per capita than European
              competitors. (<a href="https://institute.global/insights/economic-prosperity/the-urgent-need-to-build-more-homes">Tony Blair Institute.</a>)</span>
          </p>
          <p>
            By contrast, the
            <a href="https://www.ons.gov.uk/economy/inflationandpriceindices/bulletins/housepriceindex/december2023">average UK house price</a>
            is <em>double</em> the <a href="https://bcis.co.uk/">cost</a> of
            building the
            <a href="https://assets.publishing.service.gov.uk/media/5f047a01d3bf7f2be8350262/Size_of_English_Homes_Fact_Sheet_EHS_2018.pdf">house</a>, and the shortage in the South East is so severe that it is
            spilling over to places as far away as Bristol, Peterborough, and
            Northampton.
          </p>
          <p>
            <img loading="lazy" src="https://res.cloudinary.com/dki5hzod1/image/upload/v1726794865/LSOA_map_of_house_prices_awzdmt.png" alt="LSOA_map_of_house_prices">

            <span>Credited to
              <a href="https://yimbyalliance.org/2024/09/13/location-matters-price-per-square-metre-in-england-and-wales/">Yimby Alliance/Freddie Poser</a></span>
          </p>
          <p>
            The fundamental issue is that British cities are not allowed to
            expand upwards <em>or</em> outwards, whereas most American cities,
            like those of France, Italy and Germany, have at least been able to
            sprawl. Under the liberal system of the nineteenth century, late
            twentieth century Cambridge’s huge success in life sciences would
            have led to both taller buildings and many new suburbs, connected by
            new train lines, trams, tubes, and roads. It would likely have a
            population of at least a million today, just as Glasgow grew from a
            population of 70,000 in 1800 to over 700,000 in 1900 to facilitate
            its world-leading shipbuilding industry.
          </p>
          <p>
            Today, nearly all of the potential is blocked. Scarce property means
            people cannot move to take up the job opportunities on offer. Some
            businesses never start. Others are not as productive as
            international competitors. Others fail to scale up to become
            unicorns or bigger.
          </p>
          <p>
            Cambridge is not alone. Many of our smaller but richer cities and
            towns, places like Oxford or York, cannot grow up or out. The people
            who might have lived there, earning £600 or £700 a week, instead
            live in more deprived areas, earning £400. The same is true of
            London. It is hard to build new housing or office space, making it
            hard for businesses to expand, and hard for workers to move to these
            places to take up good jobs.
          </p>
          <p>
            <img loading="lazy" src="https://res.cloudinary.com/dki5hzod1/image/upload/v1726794862/ratio_of_house_prices_to_wages_kdgrb3.png" alt="ratio_of_house_prices_to_wages">
          </p>
          <p>
            The postwar housing system has underdelivered since the 1950s: the
            enormous improvements in housing affordability in the Victorian and
            Edwardian eras stalled as soon as the new system was introduced. The
            problem became ever more severe each decade, even before the
            population began to rise rapidly: average private home sizes
            actually got <em>smaller</em> during the 1960s and 1970s. But the
            problem has escalated into a disaster in the last few decades, as
            massive net immigration, an ageing population, and unforeseen
            economic change have together led to huge unmet housing demand in
            the South. The social challenges that accompany high levels of
            immigration have been hugely amplified by the persistent lack of
            planning reform.
          </p>
          <p>
            The same failures of the planning system apply to factories,
            warehouses, offices, labs, data centres, film studios, and retail
            centres as well. In every area where Britain has a nascent
            industrial advantage, we do our best to hold it back.
          </p>
          <p>
            Britain’s strongest industries are creative and intangible, and yet
            we
            <a href="https://www.localgov.co.uk/Council-rejects-film-studio-plans-despite-Hollywood-backing-/60521">blocked</a>
            a
            <a href="https://www.cityam.com/tories-strive-to-protect-the-uks-beautiful-quarries-by-blocking-developments/">£750 million film studio by a dual carriageway</a>, right by the UK’s strongest film cluster. Britain is the most
            advanced country, per capita, in artificial intelligence, but
            <a href="https://www.telegraph.co.uk/money/net-zero/25bn-super-hub-data-centre-blocked-spoiling-m25-views/">we blocked a £2.5 billion ‘super hub’ data centre site by the
              M25</a>. Top talent from around the world flocks to work in biotech in
            Cambridge, yet we have starved the sector of lab space –
            <a href="https://www.savills.co.uk/insight-and-opinion/savills-news/338662-0/cambridge-office-and-lab-supply-remains-critically-constrained-as-take-up-drops-in-2022--says-savills">under one percent of Cambridge lab space is vacant</a>. Prime city centre office space and labs there are renting for
            even more than residential property.
          </p>
          <h3 id="infrastructure4">
            Infrastructure<sup><a href="#footnote-4" id="footnote-source-4">4</a></sup>
          </h3>
          <p>
            From the eighteenth to the early twentieth centuries, Britain had
            easily the best transport infrastructure in the world. In the
            eighteenth century, a total of
            <a href="https://www.routledge.com/Economic-History-of-Transport-in-Britain/Savage-Barker/p/book/9780415512374?srsltid=AfmBOopr7hzFO54JklMfdHkVMSYpuXv4voHUa39zU63tOxiuIAYBI5bh">1,116 private companies built and renewed 22,000 miles</a>
            of tolled roads, while other companies dug 4,000 miles of canals.
            The result was by far the best transport system in Europe. In the
            nineteenth century, Britain built a system of railways that is still
            impressive today, despite having hardly been added to since 1914 (in
            fact,
            <a href="https://preview.redd.it/r0ypgwbv6ri31.jpg?auto=webp&amp;s=637b6bc1d04a19acea33a6ad6aab45af81b4db88">we have half as many miles of railway today than we did then</a>). London had an extensive underground railway system in the 1860s,
            almost four decades before the first underground metro line anywhere
            else in the world. In fact, the word ‘metro’ for underground
            railways comes from the Metropolitan Line, the world’s first.
          </p>
          <p>
            In little more than a decade around 1900, private entrepreneurs
            built five more underground lines totalling hundreds of kilometres,
            still at no cost to the taxpayer. Ninety British municipalities laid
            electric tram networks in less than twenty years, including Europe’s
            longest (in London), while private companies created a gigantic
            fleet of motor buses. This superb transport system was one of the
            conditions of Britain’s revolutionary economic expansion, and of
            London’s position as the foremost city and unquestioned economic
            capital of the globe.
          </p>
          <p>
            <img loading="lazy" src="https://res.cloudinary.com/dki5hzod1/image/upload/v1726794863/road_expansion_a8tkoi.png" alt="road_expansion">
          </p>
          <p>
            Although Britain’s historic infrastructure was largely delivered by
            the private sector (and to a lesser extent by local councils), the
            state did have a role. Delivering national infrastructure is
            extremely difficult without compulsory purchase powers: if every
            property owner on the route of a railway can play holdout, it is
            extremely unlikely to be practicable to buy them all out
            voluntarily. Until the 1940s, these powers were created through
            private Acts of Parliament: a select committee considered requests
            for compulsory purchase powers from the project’s promoters, and if
            they believed the project was in the national interest,
            <a href="https://x.com/bswud/status/1717510189744583130">they created an <em>ad hoc</em> law giving the promoters the
              powers they needed to make it happen</a>. This system was extraordinarily swift and inexpensive: the
            planning process for major national projects generally took months.
          </p>
          <p>
            <img loading="lazy" src="https://res.cloudinary.com/dki5hzod1/image/upload/v1726794863/railway-network-early_ve29ns.png" alt="railway-network-early">
            <img loading="lazy" src="https://res.cloudinary.com/dki5hzod1/image/upload/v1726794863/railway_network_later_hocxqi.png" alt="railway_network_later">
          </p>
          <p>
            By contrast, today’s system is broken. For a whole range of
            infrastructure – railways, trams, nuclear power, and more – building
            has become vastly more expensive than competitors across Europe and
            East Asia. The consenting of major projects usually takes years, and
            sometimes decades. A suite of reforms in 2008
            <a href="https://www.samdumitriu.com/p/the-solar-cliff-edge">seems to have produced only moderate improvements, many of which
              have since been lost</a>. A key national strength has become a key national weakness.
          </p>
          <h4 id="railways">Railways</h4>
          <p>
            On a per-mile basis, Britain now faces some of the highest railway
            costs in the world. These costs push numerous potential schemes into
            financial unviability – schemes that would have prospered in the
            past, and that would prosper in other countries today. High
            construction costs are effectively precluding a rail transport boom
            such as Britain enjoyed in the nineteenth century, or France is
            enjoying today.
          </p>
          <p>
            Even if it had only cost as much as planned in 2013, HS2 would have
            been between two and four times more expensive than high speed rail
            lines in Italy and France. In fact it cost a lot more: the section
            we end up building will be between four and eight times more
            expensive per mile than French or Italian high speed rail projects.
          </p>
          <p>
            At £18.1 billion for the tunnelled Paddington to Stratford section,
            the Elizabeth Line (Crossrail) was the second most expensive metro
            line ever built, at £1.4 billion per mile. By comparison, Madrid
            <a href="https://www.city-journal.org/article/subway-lessons-from-madrid">built</a>
            a 120-mile new underground network in twelve years (with much of the
            network open after just four years) for
            <a href="https://tunnelbuilder.com/metrosur/edition2pdf/page2.pdf">£68 million per mile</a>
            – twenty times cheaper than Crossrail and nine times cheaper than
            the Jubilee line extension built around the same time. Copenhagen
            built a 9.6 mile underground line in 2019 at a total cost of £3.4
            billion or £350 million per mile (four times cheaper). Crossrail 2
            (if it is ever built) is expected to cost even more than the
            Elizabeth Line did per mile.
          </p>
          <p>
            Despite its astonishing construction cost, the Elizabeth Line is so
            valuable to London that it is probably <em>still</em> good value for
            money. But if construction costs were more moderate, dozens of other
            rail schemes would be good value for money too.
          </p>
          
          <p>
            Britain has also lagged behind on electrification, one of the most
            important transformations in modern railway technology. Electrified
            railways are
            <a href="https://www.samdumitriu.com/p/infrastructure-costs-electrification">simply better</a>
            - they allow trains to accelerate faster and reach higher speeds.
            Electric trains require at least five times less maintenance and
            suffer fewer breakdowns compared to diesel trains, driving huge
            gains in reliability. These lower maintenance costs, combined with
            the fact that expensive diesel isn’t needed to power the trains,
            means that electrification often saves money in the long run.
          </p>
          <p>
            In the 1890s, electrification rapidly transformed intra-city rail
            transport. In London alone, the Northern, Piccadilly, Bakerloo,
            Central and Waterloo &amp; City Lines were opened between 1890 and
            1906, transforming urban mobility and galvanising a wave of suburban
            expansion. But although intercity electrification has been possible
            for many decades, it has been adopted painfully slowly. Just 38
            percent of British railways are electrified, compared to 71 percent
            of railways in Italy, 61 percent in Germany, and 55 percent in
            France. India recently
            <a href="https://x.com/GTCarfree/status/1745861787600531837">electrified hundreds of thousands of kilometres of its network in
              just ten years</a>
            – it is now 94 percent electrified. Once more, the key constraint is
            cost: British per mile electrification costs are
            <a href="https://www.samdumitriu.com/p/infrastructure-costs-electrification">more than double</a>
            those of Germany or Denmark.<sup><a href="#footnote-5" id="footnote-source-5">5</a></sup>
          </p>
          <h4 id="tramways">Tramways</h4>
          <p>
            Trams are potentially a far cheaper way of doing mass transit than
            underground railways. In the early twentieth century, some
            <a href="https://assets.nationbuilder.com/britainremade/pages/1451/attachments/original/1723813389/BRM7607_Tram_Report_Digital-Single-Pages_AWK.pdf?1723813389">two hundred</a>
            British towns and cities had trams: an immense network that flowered
            between 1890 and the 1950s, enabling urban expansion, economic
            growth and higher living standards.
          </p>
          <p>
            Due to their efficiency on heavily travelled routes, many countries
            are now renewing and reopening tram lines. The outstanding case is
            France, which has built 21 tramways in recent decades. Britain has
            begun to make efforts to do the same, but
            <a href="https://www.samdumitriu.com/p/britains-infrastructure-is-too-expensive">Britain's tram projects are 2.5 times more expensive than
              French projects per mile</a>, hamstringing the renaissance of the tram in this country. There
            are now French cities of 150,000 people with fast modern tram
            systems - towns comparable in size to Carlisle or Lincoln. It is
            inconceivable that cities of this size could get tramways in England
            at current build costs.
          </p>
          <p>
            This has led to some profoundly dissatisfying outcomes. Leeds is now
            the largest city in Europe without a metro system: there are about
            830,000 people in the official greater Leeds area,
            <a href="https://en.wikipedia.org/wiki/ESPON_metropolitan_areas_in_the_United_Kingdom">2.3 million in the broader metropolitan area</a>, and
            <a href="https://www.tomforth.co.uk/circlepopulations/">2.6 million within 50 kilometres</a>, the same as Munich. Munich has an 11.4 kilometre tunnel in the
            centre of the city allowing it to turn its seven commuter railways
            into Crossrails, plus eight <em>underground</em> metro lines with
            around 100 stations, totalling more than 100 kilometres in length.
          </p>
          <p>
            In 1993, the John Major government
            <a href="https://www.legislation.gov.uk/ukla/1993/15/pdfs/ukla_19930015_en.pdf">granted all the necessary powers to build a Leeds ‘Supertram’</a>. But it would have cost £1 billion (£1.6 billion in 2023 prices),
            on a per-mile basis twice the cost of the average French tramway.
            This is a key reason why it hasn’t been built in the 31 years since.
            It’s an especially ironic failure given that a daring private
            company opened Europe’s first overhead-powered tram network in Leeds
            in 1891 – a wildly successful project that was subsequently emulated
            in every major city.
          </p>
          <h4 id="why-is-infrastructure-so-expensive-in-britain">
            Why is infrastructure so expensive in Britain?
          </h4>
          <p>
            There are a range of proximate causes for Britain’s high
            infrastructure costs. Some of them are unalterable: for example,
            Britain was the first place to install below-street utilities, so we
            don’t have a very good idea of the pipes hidden under our feet, and
            tunnelling through soft London clay can perversely be more difficult
            than through hard Norwegian rock. But many of the key factors have
            appeared during the last two to three decades, the period during
            which infrastructure costs have exploded.
          </p>
          <ul>
            <li>
              We gold plate designs, spending extra billions on features that
              don’t enhance functionality, as with the award-winning Jubilee
              Line stations, or the plan for HS2 to run
              <a href="https://en.wikipedia.org/wiki/High-speed_rail">60 kilometres per hour faster than is typical for European
                high-speed rail</a>. Older infrastructure systems like the Victoria Line, the DLR or
              the Croydon Tramlink made do with simple repeated station designs,
              which hugely reduced their cost: the same tends to be true with
              Continental transport infrastructure today.
            </li>
            <li>
              We waste money on newt and bat surveys and other environmental
              assessments – like
              <a href="https://benhopkinson.substack.com/p/a-train-to-nowhere">the 18,000 pages, costing £32 million, on reopening just three
                miles of track for the Bristol-Portishead rail link</a>. The Jubilee Line Extension’s environmental statement in the
              early 1990s
              <a href="https://www.telegraph.co.uk/news/2023/06/12/fix-planning-and-set-britain-free-to-build-again/">was just 400 pages long</a>.
            </li>
            <li>
              HS2 will be required to dig 105 kilometres of tunnels and cuttings
              between London and Birmingham to avoid disturbing landscapes, at
              fantastical expense to the British people.
            </li>
            <li>
              The UK is vulnerable to judicial review – the Aarhus Convention
              means that
              <a href="https://transportactionnetwork.org.uk/sir-david-king-and-chris-packham-support-roads-climate-legal-challenge-in-court-of-appeal/">campaigners can sue projects and hold them up for years at
                little cost, even when they know they will lose, at a cost of
                billions.</a>
            </li>
            <li>
              We have excessive consultations and produce excessive documents,
              like
              <a href="https://www.britainremade.co.uk/revealed_how_the_lower_thames_crossing_is_breaking_records_for_all_the_wrong_reasons">the 359,000 pages prepared for the Lower Thames Crossing across
                many rounds of consultation</a>.
            </li>
            <li>
              We often redesign projects multiple times in response to
              successive waves of ‘stakeholder’ interventions. Successful
              projects manage this by empowering specialists to make engineering
              and design decisions on the fly.
              <a href="https://progressireland.org/to-save-up-to-e15-2bn-on-metrolink-the-state-needs-to-upgrade-tii/">Unsuccessful projects use generalists or consultants who have
                to re-approve every small edit they make</a>.
            </li>
            <li>
              Instead of a steady pipeline of projects, we have a ‘<a href="https://www.frpadvisory.com/blog/building-futures-whats-next-for-uk-infrastructure/">feast and famine</a>’ approach. Germany electrifies roughly 200 kilometres of track
              every year, while Britain oscillates between electrifying
              <a href="https://www.samdumitriu.com/p/infrastructure-costs-electrification">0 and up to 900</a>. This inconsistency prevents businesses from investing in
              equipment and training construction workers, and stops civil
              servants developing expertise about efficiently running these
              projects.
            </li>
            <li>
              All these problems lead to high borrowing costs for the
              engineering companies contracted to deliver the projects, because
              of the risks they incur (e.g.
              <a href="https://committees.parliament.uk/writtenevidence/109297/pdf/">two thirds of the cost of Hinkley Point C is financing the
                project</a>).
            </li>
          </ul>
          <p>
            Analysis of the failures of British infrastructure delivery tends to
            stop here. But we believe that these proximate causes largely arise
            from a common source, which is the excessive centralisation of
            funding and consenting of infrastructure in the national government
            that has steadily taken place since the 1990s. This has dramatically
            narrowed the constituency who want infrastructure projects to go
            ahead while also wanting to minimise their costs. The various ways
            in which British infrastructure projects have become increasingly
            slow, contested and expensive are all functions of this underlying
            mechanism.
          </p>
          <p>
            In the nineteenth and early twentieth centuries, infrastructure was
            generally funded and delivered privately. The railway system, the
            canal network, the turnpike roads and the London Underground were
            all built by private companies.
          </p>
          <p>
            Quasi-private models remained common to the end of the twentieth
            century, including ‘build, own, operate, transfer’ (the Channel
            Tunnel) and the private finance initiative (M6 Toll, Tramlink).
            Other schemes were delivered through arms-length bodies, like London
            Transport (Victoria Line). Others still were delivered by local
            governments. Most of Britain’s 300-some tram networks were laid by
            local authorities, with neither support nor direction from national
            government.
          </p>
          <p>
            In all of these cases there is a strong constituency who
            <em>both</em> strongly want the project to go ahead,
            <em>and</em> also want costs to stay low. Private companies may
            literally cease to exist if they fail to deliver their product while
            keeping costs reasonably low, and although local governments will
            continue to exist in some form, local councillors will be punished
            severely by the small local electorates who have to pick up the bill
            generated by their mismanagement. Companies and financially
            responsible local governments thus have a vivid interest in keeping
            costs down if they are on the hook for them, and they will lobby
            zealously against cost bloating. A
            <a href="https://www.amazon.co.uk/Tramways-Trolleys-Urban-Transport-Europe/dp/0691052409">leading historian of Britain’s tram networks</a>
            writes of the ‘ardent desire’ of local councils that tram networks
            turn a profit, which could then be used to subsidise other services
            or cut local rates. Sure enough, councils vigorously cut costs,
            dispensing with the expensive underground wire systems that were
            widely used in Continental cities as a sop to local objectors.
          </p>
          <p>
            This pattern of behaviour continues to hold today in many countries.
            French cities pay 50 percent towards nearly all mass transit
            projects that affect them, and sometimes 100 percent (with regional
            and national government contributing the rest). Unsurprisingly, they
            then fight energetically to suppress cost bloat, and they generally
            succeed. The Madrid Metro, one of the world’s finest systems, was
            funded entirely by the Madrid region. A smaller and poorer
            municipality than London succeeded in financing 203 kilometres of
            metro extensions with 132 stations between 1995 and 2011, about 13
            times the length of the contemporary Jubilee Line Extension in
            London. Other countries still operate systems of private
            infrastructure delivery: Tokyo’s legendary transit network is
            delivered, and regularly expanded, by private companies who
            <a href="https://etd723z5379.exactdn.com/app/uploads/2024/04/2198_1524_LP2011_ch12_Transit_Value_Capture_0.pdf">fund development by speculating on land around stations</a>. France’s superb system of motorways is built and maintained by
            private companies, who manage them with vigour and financial
            discipline.
          </p>
          <p>
            In Britain, the centralisation of infrastructure delivery in the
            national government has fundamentally weakened this incentive. No
            public body will ever have quite the existential interest in cost
            control that a private one does. But national government also has a
            weaker interest in it than a financially responsible local
            government does, because the cost is diffused around a vastly larger
            electorate. The £300 million spent on the Lower Thames Crossing
            consenting process is one of the great absurdities of modern British
            governance, but it still comes to less than £5 per British person.
            For almost any given infrastructure project, the national Government
            can waste money buying off militant stakeholder groups, and the
            immediate cost remains invisibly small to the huge electorate that
            ultimately bears it. But the aggregate effect of all these small
            pay-offs is outrageous cost bloat, unaffordable infrastructure, and
            the relative impoverishment of the country.
          </p>
          <p>
            Consider the Edinburgh Tram. It was built in two phases. The first,
            completed in 2014, was described as ‘<a href="https://benhopkinson.substack.com/p/hell-on-wheels-the-edinburgh-trams">hell on wheels</a>’, by its former chairman, overrunning from a £545 million budget
            to £776 million. Of the original budget,
            <a href="https://www.edinburghtraminquiry.org/final_report/the-inquiry-report/">£500 million came directly from the Scottish government</a>, and £45 million was provided by the council. The second,
            completed in 2023, was funded by borrowing against future fare
            revenues. It came in
            <a href="https://www.samdumitriu.com/p/infrastructure-costs-trams">about thirty percent cheaper per mile</a>.
          </p>
          <p>
            Most of the proximate causes listed above are ways in which this
            underlying pattern manifests itself. Profligate gold-plating,
            exorbitant community compensation, endless rounds of consultation,
            elaborate legal obligations, reliance on consultants and so on all
            naturally arise when none of the parties involved has any serious
            incentive to oppose them. If Britain wants affordable
            infrastructure, it needs a system in which those who make the
            decision to spend money also bear some of the costs of doing so.
          </p>
          <p>
            The most conspicuous result of this cost bloat is of course that the
            infrastructure projects that do happen tend to be wildly expensive.
            But perhaps the most important effect is the projects that do not
            happen at all. The Treasury correctly believes that, under current
            conditions, public infrastructure projects in Britain will be
            wastefully mismanaged. Its only way of protecting public finances is
            thus by blocking these projects altogether. Given the means
            available to it, this decision is often the correct one.
          </p>
          <p>
            But stepping back, we should recognise that many of the projects
            blocked by the Treasury could have excellent value for money if only
            they were delivered at costs that were historically and remain
            internationally normal. The notorious ‘feast and famine’ procurement
            pattern of some types of British infrastructure is also thought to
            be a consequence of this; the Treasury blocks routine schemes, so
            only schemes with exceptional political or economic support take
            place, which by nature arise only intermittently and unpredictably.
          </p>
          <p>
            The theory that infrastructure costs are prone to bloating when they
            are paid for centrally is supported by the example of the one kind
            of infrastructure that has remained relatively cheap, namely roads.
            Despite some big failures like
            <a href="https://www.samdumitriu.com/p/a-boring-story-about-infrastructure">the Lower Thames Crossing</a>, Britain ranks
            <a href="https://www.britainremade.co.uk/britain_paying_up_to_eight_times_more_than_eu_for_road_and_rail_projects_research_finds#:~:text=A%20study%20by%20Britain%20Remade,Italy%2C%20Sweden%2C%20and%20Norway.">mid-table</a>
            overall, a better performance than for any other infrastructure
            type. The reason for this is that roads directly benefit a much
            wider constituency than any given railway project:
            <a href="https://onlinepubs.trb.org/Onlinepubs/trr/1976/583/583-004.pdf">pretty much anyone in the nearby area</a>
            rather than just the people
            <a href="https://pbs.twimg.com/media/F9WxjexWwAAnEnw?format=jpg&amp;name=large">within about one kilometre of a given station</a>. What’s more,
            <a href="https://www.gov.uk/government/statistics/national-travel-survey-2022/national-travel-survey-2022-factsheet-accessible#:~:text=Cars%20remained%20the%20most%20popular,1%20percentage%20point%20from%202019).">94 percent of miles travelled in the UK are on roads</a>
            (80 percent in private cars, and 14 percent on buses and coaches),
            so many more people see themselves as having a stake in the issue.
            The tendency for local obstructionism is thus weaker, and even
            national government tends not to end up with spiralling costs. For
            the bulk of the projects, funded (or part-funded) and delivered by
            local councils themselves, the effect is even stronger.
          </p>
          <p>
            This is why the M25 could be delivered affordably through the
            traditional planning system, even with a spectacular 39 separate
            inquiries. In 1987, the first election after the M25 was finished
            and opened, Margaret Thatcher’s Conservatives won every constituency
            the road went through, including large swings in historic Labour
            seats like Thurrock.
          </p>
          <p>
            But this model only works for this kind of locally uncontroversial
            infrastructure. For the contentious but vital projects that the
            country needs – railways, viaducts, bridges, nuclear power stations,
            tramways, wind farms – systemic reform is needed.
          </p>
          <h4 id="why-this-matters">Why this matters</h4>
          <p>
            Because of bad delivery mechanisms, British infrastructure is
            delivered slowly and at great cost. When infrastructure is costly,
            less of it is delivered. To understand how bad this is, it is worth
            reviewing why infrastructure is important.
          </p>
          <p>
            Like housing, transport infrastructure is vitally important for
            growth because it determines who can do which jobs. Reliable, fast
            transport infrastructure allows people to access a wider range of
            job options, and businesses to access a wider pool of talent to
            employ and to transport goods and services more easily. By
            increasing the speed you can get around, infrastructure expands the
            effective ‘economic size’ of a city, no less effectively than
            building more houses does. A ten percent increase in the number of
            jobs accessible per worker increases productivity 2.4 percent. A 10
            percent increase in commuting speed
            <a href="https://x.com/Sam_Dumitriu/status/1101073388322410496">increases the size of the labour market by 15–18 percent</a>. Without the M25 and the suburban railway network, places like
            Sevenoaks, Luton, Reading, Guildford, Stansted, Chelmsford, and
            Woking would not be tied economically to the broader London
            metropolis. Companies in those places would not be able to hire from
            as big a pool; people living there would not be able to reach the
            best jobs.
          </p>
          <p>
            It also enables both internal and cross-border trade. The Eurostar
            helps British services firms sell to Parisian and Brusselian
            companies. Heathrow is a core reason why international firms have
            headquarters in London. The strategic road network lets companies
            and consumers all over the country import and export goods through
            the country’s seaports.
          </p>
          <p>
            Britain’s transport infrastructure deficit means that it forgoes
            these benefits. We can’t build new tramways or a metro cheaply in
            Birmingham, so the city is
            <a href="https://www.tomforth.co.uk/birminghamisasmallcity/">riddled with road congestion</a>, and people choose lower-paying jobs with worse working conditions
            because they are easier to get to rather than because they are the
            best for their careers. Without the Lower Thames Crossing, road
            haulage to and from the Ports of Dover and Felixstowe has to move
            over the congested and further-flung Dartford Crossing, slowing down
            and raising costs for British firms looking to trade
            internationally.
          </p>
          <p>
            <img loading="lazy" src="https://res.cloudinary.com/dki5hzod1/image/upload/v1726794872/TTWA_map_fmk1sb.png" alt="TTWA_map">
            <span>Commuting flows in England and Wales. High quality infrastructure
              is the reason why so many can commute miles to bigger job markets
              than where they live.</span>
          </p>
          <p>
            A second and vitally important benefit from all infrastructure is
            that, without it, locals oppose new homes near them. If there is
            already congestion on the roads they use, or they are already unable
            to get a seat on their morning train,
            <a href="https://worksinprogress.co/issue/growing-the-growth-coalition/">they have a powerful reason to oppose new development</a>. Thus, new infrastructure enables new homes and makes them
            politically much easier to build. The infrastructure deficit makes
            them correspondingly harder.
          </p>
          <p>
            In some cases, the infrastructure deficit is literally making new
            development in Britain unlawful. Because Britain has not built a new
            reservoir for thirty years, there are chronic water shortages in the
            East of England. This means that the Environment Agency has begun to
            <a href="https://www.planningresource.co.uk/article/1828079/environment-agency-objects-plans-almost-5000-homes-significant-risk-water-demand">block new housing</a>
            on the basis that it could only be supplied with water through
            drawing on environmentally valuable chalk streams. The result is
            that it is virtually unlawful for the Government to permit the
            expansion of Cambridge, leading to the gradual strangulation of
            Britain’s biotech industry. The same problem will compromise any new
            town scheme that the Government wants to initiate in large parts of
            the country.
          </p>
          <p>
            This chapter has focussed on the deficit in transport
            infrastructure. But there is another infrastructure deficit that is
            at least as grave: energy. Energy costs are rising steeply in
            Britain, starving energy-intensive industries and undermining living
            standards. This disastrous trend has deep causes, to which we turn
            in the next chapter.
          </p>
          <h3 id="britain-the-first-energy-superpower6">
            Britain: the first energy superpower<sup><a href="#footnote-6" id="footnote-source-6">6</a></sup>
          </h3>
          <p>
            Between 1550 and 1700, Britain transformed from a normal European
            country, depending on peat and wood for heating homes, to by far
            Europe’s biggest coal producer and consumer. Every coal-producing
            region upped its output by at least ten times. By 1640, Britain was
            mining around 1.5 million tonnes of coal per year, about three times
            as much as the rest of Europe put together.
          </p>
          <p>
            This energy boom set off growth in an uncountable number of other
            industries. The Firth of Forth started exporting salt all over
            Europe, including to salt-producing regions like the Low Countries.
            Britain’s coal allowed it to become a major producer of soap,
            candles, starch, saltpetre (for gunpowder), alum and copperas (for
            fixing dyes into clothes), as well as being used in brewing, dyeing,
            making malt, baking bread, making tiles and bricks, forging and
            working iron, copper, brass, lead, silver, and tin, glass, and
            bending staves and beams for barrels and ships.
          </p>
          <p>
            It went much further than these cases. Coal is used to produce lime.
            Cheaper and more abundant coal meant dramatically more lime.
            Dramatically more lime meant dramatically more fertiliser, which
            meant much more productive grain fields. More salt meant more meat
            and fish preservation, raising the productivity of pasture land.
            Peatlands and heaths were no longer necessary for fuel, so they
            could be converted to arable land or pastures.
          </p>
          <p>
            All of this meant more muscle power – horses and oxen – which
            powered the earliest machinery. These animals were put to an
            enormous range of uses, and their extreme proliferation in Britain
            wowed Europeans throughout the 1600s and 1700s. And it meant more
            human muscle power. The average Briton ate something like 600
            calories more per day than the average Frenchman, and was about five
            centimetres taller.
          </p>
          <p>
            All this is to say that Britain was the first energy superpower, and
            it built its global economic dominance on the back of, above all,
            cheaper and more abundant energy than anywhere else. Until the 1920s
            it produced more energy per person than any other country. Until the
            1960s it produced more energy than any other country but America.
          </p>
          
          <p>
            As coal’s enormous downsides were recognised – horrific lung issues
            for those mining it and inhaling its fumes, as well as devastating
            smogs – in 1956 we became the first of all countries to move to the
            energy technology of the future: nuclear. In its early years,
            Britain was the world leader in nuclear power. In 1965 we had 21
            nuclear reactors, compared to 19 in the rest of the world combined.
          </p>
          <p>
            Uranium’s energy density – three million times higher than coal –
            suggested that it could be much cheaper as a source of power, since
            it would not necessitate so much mining and transportation. We
            didn’t realise then that nuclear power could also help us to avoid
            damaging climate change. But had we continued down that path, we
            would have inadvertently decarbonised, like France.
          </p>
          <p>
            <img loading="lazy" src="https://res.cloudinary.com/dki5hzod1/image/upload/v1726794866/nuclear_power_decline_d84pdg.png" alt="nuclear_power_decline">
          </p>
          <p>
            If we had only kept pace with the rate of nuclear rollout that we
            had between 1956 and 1998, by extending the lifetimes of our older
            plants and adding new ones, today we would be producing around 150
            TWh of nuclear power per year, or around 50 percent of our total
            current electricity generation. But we did not. Nuclear power in
            Britain is now half of what it was at its peak, and energy costs
            today are higher than they have been for a century.
          </p>
          <h4 id="energy-costs">Energy costs</h4>
          
          <p>
            There are good reasons to want the UK to have a large, productive
            industrial base. But any industrial strategy aimed at doing this
            must first reckon with the enormous rises in energy prices for UK
            businesses since the mid-2000s.
            <a href="https://www.gov.uk/government/statistical-data-sets/gas-and-electricity-prices-in-the-non-domestic-sector">The industrial price of electricity</a>
            rose by 153 percent between 2004 and 2021, adjusted for inflation.
            It rose even more brutally again after the Russian invasion of
            Ukraine. Very large industrial customers (those consuming
            70,000–150,000 megawatt-hours of electricity every six months) paid
            more than twice as much in Britain (13.79p per kilowatt-hour) for
            electricity in 2021 as their counterparts in France did (6.62p per
            kilowatt-hour), and, again, the gap has grown since Russia’s
            invasion of Ukraine. Even if energy costs eventually fall back to
            normal pre-war levels, those are still much more expensive in real
            terms than twenty years ago. Fixing this has to be step one for any
            serious industrial strategy.
          </p>
          
          <p>
            High energy costs are a problem across the developed world. Energy
            consumption per capita in even the relatively fast-growing United
            States has flatlined from the early 1970s oil crisis onwards. But
            things are much worse here.
          </p>
          
          <p>
            The UK’s energy use per person has long been far behind that of the
            United States, but it fell behind both France and Germany in the
            post-war era. Despite moderate improvements under Thatcher, it has
            slid since the mid-2000s to fall further below other countries.
          </p>
          
          <p>
            Britain’s energy use per unit of GDP
            <a href="https://www.iea.org/reports/sdg7-data-and-projections/energy-intensity">is now the lowest in the G7</a>, and is lower than nearly every region and every non-tax-haven in
            both Europe and the OECD. By many measures, Britain is the most
            energy-starved nation in the developed world.
          </p>

          <p>
            The problem of high energy costs for manufacturing was raised by
            Mario Draghi’s
            <a href="https://commission.europa.eu/document/download/97e481fd-2dc3-412d-be4c-f152a8232961_en?filename=The%20future%20of%20European%20competitiveness%20_%20A%20competitiveness%20strategy%20for%20Europe.pdf">recent report on EU competitiveness</a>, which highlighted the strong correlation between an industry’s
            energy intensiveness and its decline since the outbreak of the
            Ukraine war. Draghi also warned that the EU’s traditional
            manufacturing strengths, such as automobiles, were at risk of being
            outcompeted by other countries with cheaper energy.
          </p>
          <p>
            <img loading="lazy" src="https://res.cloudinary.com/dki5hzod1/image/upload/v1726794865/energy_intensive_challenges_zbjx1f.png" alt="energy_intensive_challenges">
            Yet British firms pay on average 60 percent more for electricity
            than French ones (the gap is larger for larger customers, as
            mentioned above). The total amount of energy used by the steel
            industry has fallen by about three quarters in the last two decades.
            UK Steel says that ‘long-standing uncompetitive electricity prices
            have constrained UK investment and steel production for some time’,
            and in 2022 when Russia’s invasion of Ukraine drove energy prices to
            their highest-ever levels,
            <a href="https://www.makeuk.org/news-and-events/news/news-from-uk-steel---recent-power-price-spikes">some steel plants paused production at times of the day when
              prices were spiking</a>. And steel is only one example:
            <a href="https://www.nfuonline.com/updates-and-information/cf-fertilisers-announces-closure-of-billingham-ammonia-plant/">CF Fertilisers recently closed its ammonia plant in Billingham
              permanently</a>, because of Britain’s high energy costs.
          </p>
          
          <p>
            <a href="https://data.worldbank.org/indicator/NV.IND.MANF.ZS?locations=JP-DE-IT-US-FR-CA-GB&amp;start=1990&amp;end=2023&amp;view=chart">Even writing off industrial production altogether would not make
              this problem go away</a>. Data centres, the infrastructure backbone of the internet, have
            become even more essential as artificial intelligence has risen,
            since they are required for both the training and use of AI models.
            And they require enormous amounts of electricity.
          </p>
          <p>
            A large data centre can require
            <a href="https://www.construction-physics.com/p/how-to-build-an-ai-data-center">over 100 megawatts of power, more than 300,000 homes</a>. Electricity is so essential to data centres’ output that
            <a href="https://www.construction-physics.com/p/how-to-build-an-ai-data-center">their scale is typically measured in terms of their electricity
              needs instead of their square footage</a>. Last year they accounted for
            <a href="https://www.current-news.co.uk/ireland-data-centre-electricity-use-2023/#:~:text=The%20Central%20Statistics%20Office%20for,for%20rural%20dwellings%20(10%25).">21 percent of Ireland’s total electricity use</a>. At a minimum, this will be important for Britain. In some
            scenarios for the near future, virtually nothing matters more than
            Britain building many large, efficient, well-powered data centres.
          </p>
          <p>
            Unfortunately, most prominent examples of industrial strategy ignore
            that high energy costs are by far the biggest problem facing British
            industry today. Subsidies for British industry, like
            <a href="https://www.ft.com/content/476c629c-2918-4836-8b27-362967f9f6dd">the recent commitment to give Tata £500 million to invest in
              steelmaking here,</a>
            are an expensive sticking plaster on this much bigger wound.
          </p>
          <p>
            <a href="https://assets.publishing.service.gov.uk/media/66a79e0bfc8e12ac3edb0629/DUKES_1.1.1.xlsx">Just over three quarters of the energy we use</a>
            still comes from gas and oil, directly heating our houses and
            powering our cars. Gas is also widely used for industrial heat
            generation. But we are attempting to electrify our economy, which
            means replacing gas boilers with heat pumps, and petrol cars with
            electric ones. Shifting to electric road vehicles
            <a href="https://www.sustainabilitybynumbers.com/p/uk-ev-electricity-demand">will create 40 percent more <em>total</em> electricity demand</a>. Data centres are entirely reliant on electricity. Rising
            temperatures from climate change will necessitate
            <a href="https://www.worksinprogress.news/p/heat-waves">more use of air conditioning</a>
            that runs on electricity. So it is especially worrying that we are
            so far behind peer economies on electricity generation, and have
            been generating less and less electricity since the start of the
            century.
          </p>
          <p>
            If energy stagnation is,
            <a href="https://press.stripe.com/where-is-my-flying-car">as some economists and engineers have suggested</a>, a cause of the West’s slowdown over the past fifty years, then it
            should be no surprise that Britain’s economy has fared as badly as
            it has. Along with inadequate housing and transport, this is one of
            the most fundamental weaknesses of the contemporary British economy.
            Any attempt to change course has to accept the central importance of
            cheap, abundant energy to prosperity.
          </p>
          <h4 id="intermittent-renewables-and-energy-prices">
            Intermittent renewables and energy prices
          </h4>
          <p>
            <a href="https://zigzag-mangosteen-7f1.notion.site/A-mental-model-for-combating-climate-change-846be1769d374fa1b5b855407c93da66">Climate change is a serious challenge.</a>
            Britain has committed, with the rest of the developed world, to
            bringing its carbon emissions down significantly over the next three
            decades.
          </p>
          <p>
            Greenhouse gas emitters do not bear the true costs they impose on
            the world. A (<a href="https://commonslibrary.parliament.uk/research-briefings/cbp-9935/">border-adjusted</a>) carbon tax that made them pay the social cost of the emissions
            they created would make the true costs of their emissions clear, and
            would make cleaner forms of energy significantly more
            cost-competitive, and possibly outright cheaper. It would also
            provide an ‘automatic’ impetus to develop and adopt technologies
            like carbon capture and carbon removal.
          </p>
          <p>
            But carbon taxes have often failed politically where they have been
            tried, pushing politicians towards subsidies, price guarantees and
            other incentives to move to clean energy sources instead. Though
            this approach still tilts the balance toward cleaner technologies,
            its true costs are hidden. And because this approach necessitates
            the government picking winners, it may mean paths to decarbonisation
            that are much more costly than others.
          </p>
          <p>
            Intermittent renewables, which are primarily wind and solar power in
            the British market, are sources that, though clean, cannot produce a
            constant supply of electricity, and cannot be turned on at will.
            This means that the marginal price of electricity
            <em>as traded between generators and energy suppliers</em> is
            largely set by the marginal cost of booting up power plants that can
            produce enough to meet demand at any given time. Usually those
            plants run on natural gas. This means that short-term wholesale
            electricity prices tend to be set by gas prices.
          </p>
          <p>
            The price of electricity as actually paid by consumers, however,
            differs from the <em>wholesale</em> cost of electricity as traded
            between generators and suppliers. This wholesale cost is only about
            <a href="https://commonslibrary.parliament.uk/research-briefings/cbp-9491/">30-40 percent of the total bill</a>
            that a consumer pays. Electricity consumers, which include both
            industrial consumers and households, need to pay for the costs of
            the entire electricity system, not just generation: the transmission
            and distribution networks, the growing costs of balancing the grid,
            plus a margin for suppliers, plus the policy costs of whatever
            subsidies to electricity generators the government has seen fit to
            pay, plus the costs of contracts for rarely-used but essential
            emergency backup generation. There is no necessary reason why these
            costs need to fall on energy consumers: some could equally well be
            paid from general taxation. But either way the costs must be paid.
          </p>
          <p>
            Therefore, from the perspective of a consumer, what matters is not
            the price of electricity from a given wind farm as traded on the
            wholesale market, but the total cost of the entire electricity
            supply system.
          </p>
          <p>
            It is commonplace to claim that electricity generated from
            <a href="https://x.com/Ed_Miliband/status/1562444641236316161">wind</a>
            <a href="https://www.bbc.co.uk/news/articles/crkm5p1x6deo">or solar</a>
            power is <em>cheaper</em> than electricity from traditional power
            plants. Yet the more wind and solar we hook up to the grid, and the
            more fossil fuel power plants we retire, the higher bills seem to
            go.
          </p>
          
          <p>
            In fact, intermittent renewable energy is nowhere near commercially
            competitive. According to the
            <a href="https://obr.uk/download/march-2024-economic-and-fiscal-outlook-detailed-forecast-tables-receipts/?tmstv=1726074283">Office for Budget Responsibility</a>
            and Ofgem, the direct costs of subsidies of renewable power
            generation now exceed £10 billion a year, across the Renewables
            Obligation, Contracts for Difference, and
            <a href="https://www.ofgem.gov.uk/publications/feed-tariffs-fit-annual-report-2022-23">Feed-in-Tariff schemes</a>, which provide a guaranteed price for electricity generated by
            renewables over, normally, a fifteen-year time horizon. The
            <a href="https://assets.publishing.service.gov.uk/media/66d6ad7c6eb664e57141db4b/Contracts_for_Difference_Allocation_Round_6_results.pdf">September 2024 auction for Contracts for Difference</a>, which covered new supply equivalent to eight percent of the UK’s
            current electricity generation, concluded with the state
            guaranteeing an inflation-indexed price
            <a href="https://x.com/RichardOllingtn/status/1830922442526859688">30 percent higher than current wholesale market prices</a>
            to a range of renewable energy suppliers for the next 15 years.
            These costs are passed on to energy customers through higher prices.
          </p>
          <p>
            But as well as the direct subsidy needed to make intermittent
            sources of electricity profitable, these renewables increase other
            system-level costs that are paid by consumers. There are three main
            sources of this:
          </p>
          <ul>
            <li>
              <strong>More need for transmission lines to connect generation to
                households and industry</strong>. Traditionally, power plants were located fairly close to major
              population centres. The highest wind speeds, however, are
              available offshore and in northern Scotland. Add in the impact of
              the planning system pushing wind farms to locate in more remote
              places, and the result is that the annual costs of transmission
              maintenance and installation have risen from
              <a href="https://www.nationalgrideso.com/document/49546/download">£1.35 billion in 2008/9</a>
              to
              <a href="https://www.nationalgrideso.com/document/294586/download">over £4 billion in 2024/25</a>.
              <a href="https://www.nationalgrideso.com/news/eso-publishes-pathway-2030-major-step-deliver-50gw-offshore-wind-2030">The UK’s electricity system operator plans for £54 billion</a>
              of total transmission spending between now and 2030, citing the
              need to accommodate a large increase in offshore wind generation
              during this period.
            </li>
            <li>
              <strong>Increased grid balancing costs.</strong> Electricity
              supply must be matched to demand on a second-by-second basis. As
              increasing fractions of the generation mix become
              weather-dependent and hence to a degree uncontrollable and
              unpredictable, the grid operator needs to spend more money both on
              paying generators to switch off when supply exceeds demand, but
              also for emergency backup generation to come online when wind
              speeds drop. These balancing costs
              <a href="https://www.nationalgrideso.com/document/318516/download">are estimated at £2.4 billion for 2023/24</a>, and
              <a href="https://www.nationalgrideso.com/document/318516/download">are estimated by the Electricity System Operator to rise to
                over £4 billion a year by the end of the decade</a>.
            </li>
            <li>
              <strong>The costs of paying for backup capacity</strong>. This is
              especially important for periods of multi-week lulls in wind
              speeds, which can occur during periods with overcast weather that
              curtail solar generation as well. These periods require a fleet of
              dispatchable plants with total capacity approximately equal to
              peak demand, powered either by gas or, in some envisioned Net Zero
              scenarios, hydrogen stored for years in underground salt caverns.
              Batteries may become viable for energy storage across a day or a
              few days, but seem unlikely to be able to provide for weeks-long
              lulls in wind and sunlight. Currently the UK has
              <a href="https://www.renewableuk.com/news/660775/Pipeline-of-UK-energy-storage-projects-grows-by-two-thirds-over-last-12-months.htm">4.6 gigawatt-hours of battery storage capacity</a>, or about 0.3 percent of daily energy demand.<p>Since
              these plants will, in optimistic Net Zero scenarios, operate
              relatively rarely and so be unable to sufficiently recoup their
              costs through electricity sales alone, they will likely require
              ongoing subsidy. So far we have committed over
              <a href="https://energy.drax.com/insights/t-4-capacity-market-auction-for-2027-28/">£3.6 billion</a>
              to pay for backup energy supply in 2027/8, based on recent auction
              results, and it is unclear if even this expenditure is sufficient
              to ensure security of supply given the planned partial reliance on
              electricity imports from Europe.
            </p></li>
          </ul>
          <p>
            Once these system-level costs are accounted for, building a grid
            around wind and solar power is much more expensive than implied by
            the Levelized Cost of Energy (or LCOE) estimates typically cited by
            government departments or the press, and – along with the
            decommissioning of coal and gas-fired power plants since the 2000s –
            explains why Britain’s electricity costs have risen so much compared
            to other countries’.
          </p>
          <p>
            None of this section is to say that intermittent renewables are bad
            or pointless. Reducing carbon emissions is essential, and the true
            cost of fossil fuels is higher than it appears because of the carbon
            emissions they create. We can improve efficiency by allowing
            electricity prices to reflect the actual cost of supplying
            electricity to a given premises (what is known as locational
            pricing) and the real-time value of the electricity (time-of-use
            pricing).
          </p>
          <p>
            In many parts of the world the problems these power sources face are
            much less significant: for example, where there is more constant
            sunshine across the year, solar is much less intermittent. It may
            turn out that building interconnectors between Britain and
            continental Europe and Africa means we can import solar electricity
            from these sunnier latitudes.
            <a href="https://aquind.co.uk/">A proposed interconnector</a>
            between Portsmouth and France would add 2,000 megawatts, or 16
            terawatt hours a year, to Britain’s electricity supply: enough to
            power twenty large data centres, four million new homes, or
            one-seventh of our road transport needs if we switched entirely to
            electric vehicles. However, this project and others like it
            <a href="https://watt-logic.com/2024/06/28/ofgem-throws-a-spanner-into-gbs-interconnector-ambitions/">may be rejected by Ofgem, the energy regulator</a>.
          </p>
          <p>
            Or we may make technological breakthroughs, for example in
            ultra-dense battery storage, or in atmospheric carbon capture, that
            make some of our current problems irrelevant. But, for now, the
            current consensus in favour of large, increasing subsidies for
            intermittent renewables in Britain is a consensus in favour of high
            and rising energy costs.
          </p>
          <p>
            In order to prosper again, Britain needs abundant and reliable clean
            energy. Intermittent renewables may be able to give us this someday,
            but they cannot provide it yet. Thankfully, there is a technology
            that can: nuclear power.
          </p>
          <h4 id="nuclear-power">Nuclear power</h4>
          <p>
            Nuclear power avoids the biggest problem that solar and wind power
            face: it produces constant amounts of electricity across the day and
            year. This means we can depend on it. Its operation produces
            essentially zero carbon dioxide. It already provides
            <a href="https://pris.iaea.org/PRIS/WorldStatistics/NuclearShareofElectricityGeneration.aspx">two thirds of France’s electricity</a>. And it
            <a href="https://ourworldindata.org/grapher/death-rates-from-energy-production-per-twh">is safer than almost any other source of electricity, even wind
              power</a>.
          </p>
          <p>
            Britain, once a world leader in atomic power, hasn't built a new
            nuclear power station in the last 28 years, during which period
            <a href="https://lordslibrary.parliament.uk/the-role-of-nuclear-in-the-uks-energy-supply/">it has shuttered eight</a>
            reactors – and
            <a href="https://www.nao.org.uk/reports/the-decommissioning-of-the-agr-nuclear-power-stations/">eight more are set for the chop</a>. Nuclear power accounts for only 12.5 percent of our annual
            electricity output.
          </p>
          
          <p>
            The cost of building new reactors has become eye-wateringly high.
            Our nuclear power construction costs are the second highest in the
            world, but this is not inevitable or inherent in the technology:
            nuclear power
            <a href="https://jackdevanney.substack.com/p/nuclear-is-too-expensive">was once cost-competitive with <em>coal</em></a>.
          </p>
          <p>
            Unlike with intermittent power, however, these high costs are not
            intrinsic to nuclear. In general, it is expensive to build reactors
            for the same extraneous reasons that it is expensive to build
            railways and trams. And, as with trams and trains, if we can make it
            cheaper to build nuclear reactors, we can have a lot more of them.
          </p>
          
          <p>
            Britain wasn’t always this expensive. For plants constructed before
            1995, Britain averaged £4.79 million per MW, about half of the
            estimated costs for Hinkley Point C and Sizewell C. Even the most
            expensive reactors permissioned and commissioned under Margaret
            Thatcher and John Major, Sizewell&nbsp;B and Torness, were only
            two-thirds the price in real terms of the plants we are planning
            today. These plants have produced zero-emissions power for decades
            and
            <a href="https://normielisation.substack.com/p/the-half-life-of-local-support-for">could continue to do so for decades more if they weren’t being
              closed down</a>.
          </p>
          
          <p>
            One reason nuclear power is so expensive to build is that it is
            beset by extreme delays and uncertainty caused by planning and
            environmental approval processes. These arise even when deploying
            completely safe, widely used designs that have been built in Britain
            before. From being proposed in a UK government white paper, to the
            start of construction, Hinkley Point C took ten years. By contrast,
            France and Finland have started building similar reactors in just
            three or four.
          </p>
          <p>
            With a
            <a href="https://assets.nationbuilder.com/themes/64129ab34764e88389de397e/attachments/original/1680254554/Powerbook-Brochure-WEBAWK_REV3.pdf?1680254554">44,260 page</a>
            environmental impact assessment (EIA) and 2,229 written questions at
            examination stage, Sizewell C, the next reactor after Hinkley Point
            C, faced enormous expense before a spade was even in the ground
            (which it still is not). As the recent MHCLG policy paper
            <a href="https://www.gov.uk/government/publications/getting-great-britain-building-again-speeding-up-infrastructure-delivery/getting-great-britain-building-again-speeding-up-infrastructure-delivery">Getting Great Britain building again</a>
            pointed out, Sizewell C’s EIA is ‘more than 30 times longer than the
            complete works of Shakespeare.’
          </p>
          <p>
            Nuclear power has also suffered from many of the problems that have
            inflated the cost of transport projects. Rather than setting up a
            pipeline of nuclear projects, we are designing and approving each
            one in isolation. There is no strong interest group in favour of
            reducing costs, so trivial objections – like the ‘problem’ of a few
            dozen fish being sucked into a reactor’s cooling system and killed –
            lead to further delays and expense (in this case,
            <a href="https://www.samdumitriu.com/p/visiting-the-worlds-most-expensive">with an underwater megaphone to scare fish away</a>). Spurious concerns about trace amounts of background radiation,
            long-debunked by the hundreds of nuclear reactors in operation
            worldwide, are treated with grave seriousness in each case, rather
            than being immediately identified and dismissed as obstructionist
            pseudoscience.
          </p>
          <p>
            Although most of the developed world has suffered similar increases
            in the cost of building new nuclear, although less extreme than
            Britain’s, there are some notable exceptions. South Korea stands out
            among developed countries as building nuclear power stations that
            are reliable, safe, and cheap: Korea builds reactors domestically
            for about a sixth of the cost that Britain does.
          </p>
          <p>
            A key reason it can do this is that it builds nuclear plants in
            fleets. For each design, KEPCO, South Korea’s nuclear company,
            builds 8-12 reactors in a row, meaning it benefits from economies of
            scale and
            <a href="https://en.wikipedia.org/wiki/Learning-by-doing_(economics)">learns by doing</a>. (Similar benefits of learning-by-doing through repeated builds of
            similar designs have been observed in the
            <a href="https://thebreakthrough.org/issues/energy/chinas-impressive-rate-of-nuclear-construction">Chinese nuclear build-out.</a>) KEPCO is now building reactors for the UAE at
            <a href="https://www.spectator.co.uk/article/why-britain-is-building-the-worlds-most-expensive-nuclear-plant/">less than half the cost of Hinkley Point C</a>
            per unit of energy.
            <a href="https://www.world-nuclear-news.org/Articles/KHNP-selected-to-supply-new-Czech-nuclear-units">It has just been contracted to build in Czechia</a>
            for <em>a quarter</em> the price of Hinkley.
          </p>
          <p>
            The UK thus has one hard, but potentially rewarding, option of
            attempting to streamline nuclear reactor approvals and delivery,
            perhaps through opening up a new pathway to ‘small modular reactors’
            or ‘microreactors’ that avoids the wasteful cost of our existing
            regulatory system. If successful, this would have the dual benefit
            of enabling cheap, abundant, clean energy, <em>and</em> the creation
            of a potential export industry that could offer cheap nuclear power
            to other developed countries.
          </p>
          <p>
            The faster and cheaper option would be to simply follow the Czechs
            and call KEPCO, asking how many nuclear reactors it could provide at
            similar or lower costs, and how quickly they can get going.
          </p>
          <h4 id="an-energy-superpower-once-again">
            An energy superpower once again
          </h4>
          <p>
            Britain’s rise to become the world’s first industrial nation was
            predicated on its remarkably early exploitation of fossil fuels,
            especially coal. The age of coal is over. But in the 1950s and
            1960s, another era as an energy giant and industrial power seemed to
            be dawning, with the rise of nuclear power, a technology in which we
            led for decades. Our failure to do this was
            <a href="https://commonslibrary.parliament.uk/research-briefings/sn04046/">cushioned by the discovery of North Sea oil</a>. It can’t cushion us any more.
          </p>
          <p>
            Deindustrialisation was not the inevitable result of economic
            progress. To our
            <a href="https://w3.unece.org/SDG/en/Indicator?id=130">$4,300</a> of
            annual manufacturing output per capita, the Americans produce
            $6,700; the Swedes $7,300; the Germans $8,500; and the Swiss
            $20,000. These are all advanced economies in which the biggest
            fraction of employment and output is services. But part of their
            higher productivity is that they have kept their energy costs well
            below ours and avoided the erosion of their industrial base that we
            have experienced.
          </p>
          <p>
            We can reverse this. Abundant clean energy is achievable with
            technology that already exists. What is lacking is a reliable
            pathway to allow it to get built. Fix that, and Britain could see
            itself become an industrial heavyweight for the second time in its
            history.
          </p>
          <h3 id="the-prize">The prize</h3>
          <p>
            The fundamental thesis of this essay is that Britain can have rapid
            economic growth in the near future, swiftly catching up with the
            world’s most prosperous countries. It can do this because the
            sources of its current sclerosis are easy to identify and
            straightforward, in principle, to fix. The problem is not too little
            investment by the state. It is that the state has prohibited most of
            the investments we need to make. The solution is to remove these
            obstacles to investment, mobility and trade, in a politically viable
            and durable way.
          </p>
          <p>
            We should not despair. Britain has been here before a century ago,
            and triumphed. By the end of the 1920s, Britain was still reeling
            from the national catastrophe of the First World War. Many damaging
            emergency measures that had been brought in during the War still
            lingered, it was recovering from levels of inflation never seen
            before or since, and economic growth had slowed to a crawl.
          </p>
          <p>
            The housing sector was moribund, thanks to a combination of rent
            controls imposed during the First World War, tight lending policy,
            and the effects of rapid inflation, which made the rent controls
            even more punitive in real terms.
          </p>
          <p>
            Stanley Baldwin’s government abolished rent controls and removed
            mortgage regulations by 1932, causing a dramatic housing boom that
            provided the foundations for the British economic miracle of the
            1930s. Millions of extra homes were built in just six years – the
            fastest period of building ever – probably
            <a href="https://cepr.org/voxeu/columns/escaping-liquidity-traps-lessons-uks-1930s-escape">adding several percentage points to GDP growth in just a few
              years</a>. The homes were concentrated in the cities in which Britain’s key
            growth industries were based, giving those industries access to the
            workforce they needed to continue expanding. It may have been the
            greatest rapid expansion in a given economic sector in British
            history, and it was the key reason we didn’t experience a Great
            Depression while Germany, the USA, and France did.
          </p>
          <p>
            These homes were enabled by rapid infrastructure development: new
            roads such as the A3 Kingston Bypass, an enormous expansion of the
            bus network, and extensions of many of the major railways and tube
            networks, with the Piccadilly, District and Northern Lines sweeping
            out into suburban London.
          </p>
          <p>
            During this time Britain built its national electricity grid, in one
            of the most remarkable achievements of engineering and public works
            in modern history. In the space of three years, the new Central
            Electricity Board
            <a href="https://www.nationalgrid.com/about-us/what-we-do/our-history/history-electricity-britain">devised a plan</a>
            to connect more than 100 of the UK’s most efficient power stations
            into seven local grids across the country, and passed the
            legislation needed to enable the plan and begin work on it. It took
            just five years for the project to be completed in 1936, with 4,000
            miles of cables running across 26,000 pylons around the country
            being built in this time.
          </p>
          <p>
            In 1937, a year after the seven local grids were finished, a group
            of impatient and rebellious engineers
            <a href="https://worksinprogress.co/issue/building-back-faster/">switched on the connections</a>
            between the seven grid areas themselves to form a single national
            system, deciding it was easier to ask forgiveness than permission.
            They created a world-class grid that remains in operation to this
            day. The price of electricity
            <a href="https://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/UK_historical_electricity_price_1921-1990.svg/750px-UK_historical_electricity_price_1921-1990.svg.png">collapsed</a>
            and the share of the population connected to electricity soared,
            rising faster than in any other country on earth. Britain went from
            being a laggard to a leader in electrification in just a few years.
          </p>
          <p>
            We believe that Britain can enjoy such a renewal once more. To do
            so, it need simply remove the barriers that stop the private sector
            from doing what it already wants to do: build homes, bridges,
            tunnels, roads, trams, railways, nuclear power plants, grid
            connections, prisons, aqueducts, reservoirs, and more.
          </p>
          <p>
            The immediate effect would be large increases in employment in
            construction, energy, real estate, plumbing, factories, steelworks,
            cement production, surveying, architecture, design, and more. It
            would mean large inflows of capital to invest in these newly
            available opportunities.
          </p>
          <p>
            There is massive pent-up demand for new housing, more energy supply,
            more and better transport links, and more childcare provision, as
            shown by their high prices. Since a price is ‘a signal wrapped in an
            incentive’, making it easier to build and supply these things would
            not require top-down direction or government spending.
          </p>
          <p>
            The short-term effect, then, would be a surge of economic activity
            as these investments were made. But the real benefits come when
            those investments begin to pay off.
          </p>
          <p>
            The medium-term effect would be to dramatically increase
            productivity growth in the UK, driven by agglomeration. It would
            mean more people accessing high quality jobs, allowing productive
            companies to hire more people and scale up, and to operate cheaply
            thanks to cheaper commercial premises and lab space, and cheaper
            energy. Services companies would expand rapidly, and new companies
            would be set up. The cheaper energy would rejuvenate many of the
            traditional industries of the North of England, including
            manufacturing.
          </p>
          <p>
            In the long run, cheaper housing in particular would have a range of
            knock-on effects. Cheaper housing means more affordable childcare
            and bedrooms, and less of a trade-off between having children and
            staying in the city to be close to friends and job. All of these
            will help families to afford more children, if they want them,
            making it easier to bear the costs of an ageing population.
          </p>
          <p>
            More agglomeration also means more innovation. A larger labour pool
            gives innovative firms more options about whom to hire, and more
            similar companies with which to partner to come up with new ideas.
            Allowing the science-based industries around Oxford and
            <a href="https://www.createstreets.com/the-promise-of-cambridge/">Cambridge</a>
            to grow as freely as their competitors in places like Silicon Valley
            and Boston can allow a virtuous cycle where more and more innovative
            companies start up or locate in these cities, creating greater and
            greater returns to similar firms coming there too, and more scope
            for productive collaboration between them.
          </p>
          <p>
            Fundamentally, making building possible would unlock the promise of
            the British economy. All the ideas, entrepreneurs, researchers, and
            skilled workers we have are being held back from being as productive
            as they could be, and the aggregate cost is that the country is much
            poorer than it should be. If we address this, Britain could be once
            again among the richest of nations.
          </p>
          <p>
            In its turn, affluence would – if wisely used –&nbsp;begin to solve many
            of Britain’s other problems. Public services could be given more
            generously funded, facilitating reforms to make them more efficient.
            Aided by planning reform, we could build new and better resourced
            hospitals, yielding shorter waiting lists and better patient
            outcomes. We could adopt the generous family policies of places like
            <a href="https://ifstudies.org/ifs-admin/resources/reports/ifs-southerneuropereport-final-1.pdf">France</a>
            and
            <a href="https://www.boomcampaign.org/p/the-province-defying-italys-birth">South Tyrol</a>
            to allow younger couples to have children sooner if they wish to,
            widening the choices available to the British people while helping
            to secure their long-term future. Elderly Britons could receive the
            finest care in the world, delivered through immigration only if we
            wish, and not as a substitute for adequate funding. Britain could
            have a new generation of schools, like the great board schools that
            rose over the cities of the nineteenth century. We could expand our
            prison, police and prosecution services, becoming again a virtually
            crime-free society such as our grandparents knew, and such as Japan
            remains today. We could have the finest armed forces in Europe,
            playing again a decisive role in defending the law-governed world
            order that Britain did so much to bring into being.
          </p>
          <p>
            We began this essay by saying that unlocking prosperity can
            reinforce what is best in Britain’s social settlement. The parallel
            to the 1930s should remind us of this. Across the world, the
            economic collapse of the 1930s brought social malaise and political
            destabilisation. Britain’s success and prosperity averted these, and
            left it to face crisis and war in a position of strength, unity and
            confidence. The international situation today is not so grave as it
            was then. But the future is always perilous, and it is vital that
            Britain should once more have the strength and self-belief of 1939
            with which to play its part in the leadership of the free world.
          </p>
          <p>
            The good news is that the hardest things to create are ours already.
            No government can legislate into being a respect for the rule of
            law, appetite for scientific discovery and entrepreneurship, or
            tolerance of eccentricity and debate. Such a culture takes centuries
            to build: it is the most precious inheritance that we have received
            from the generations that went before us. By comparison, what we
            must do is surprisingly simple: get Britain building by removing
            barriers and lowering costs. If we can establish these foundations,
            growth and dynamism will follow. We have done this before. We can do
            it again.
          </p>
          <div>
            <p>
              <a href="#footnote-source-1" id="footnote-1">1</a>: Governments of
              the 1950s scrapped the requirement to get a building licence, and
              the 100 percent tax on uplift from permissions.
            </p>
            <p>
              <a href="#footnote-source-2" id="footnote-2">2</a>: See also this
              <a href="https://x.com/mlanetrain/status/1827016272850137228">dataset</a>
              and
              <a href="https://www.construction-physics.com/p/how-much-do-construction-costs-matter">this one</a>.
            </p>
            <p>
              <a href="#footnote-source-3" id="footnote-3">3</a>: These places
              may have shortages of specific types of homes, especially what are
              known as ‘missing middle’ properties, but they don’t have severe
              shortages of the most common type of American home (single-family
              detached houses).
            </p>
            <p>
              <a href="#footnote-source-4" id="footnote-4">4</a>: Much of this
              section is a digest of work done by Sam Dumitriu and Ben Hopkinson
              at Britain Remade. In some cases their words have been used
              directly, with their permission, edited down for brevity.
            </p>
            <p>
              <a href="#footnote-source-5" id="footnote-5">5</a>: Though it is
              not the only reason: the UK’s railways also have unique technical
              standards.
            </p>
            <p>
              <a href="#footnote-source-6" id="footnote-6">6</a>: This section
              is heavily based on
              <a href="https://media.nesta.org.uk/documents/Lessons_from_the_age_of_coal.pdf">the work of Anton Howes</a>
              with his permission.
            </p>
          </div>
        </main>
      </article>
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Training Language Models to Self-Correct via Reinforcement Learning (184 pts)]]></title>
            <link>https://arxiv.org/abs/2409.12917</link>
            <guid>41600179</guid>
            <pubDate>Fri, 20 Sep 2024 09:19:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2409.12917">https://arxiv.org/abs/2409.12917</a>, See on <a href="https://news.ycombinator.com/item?id=41600179">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
    <div><p><span>Authors:</span><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar,+A">Aviral Kumar</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhuang,+V">Vincent Zhuang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Agarwal,+R">Rishabh Agarwal</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Su,+Y">Yi Su</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Co-Reyes,+J+D">John D Co-Reyes</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singh,+A">Avi Singh</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Baumli,+K">Kate Baumli</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Iqbal,+S">Shariq Iqbal</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bishop,+C">Colton Bishop</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roelofs,+R">Rebecca Roelofs</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang,+L+M">Lei M Zhang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=McKinney,+K">Kay McKinney</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Shrivastava,+D">Disha Shrivastava</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paduraru,+C">Cosmin Paduraru</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tucker,+G">George Tucker</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Precup,+D">Doina Precup</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Behbahani,+F">Feryal Behbahani</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Faust,+A">Aleksandra Faust</a></p></div>            
    <p><a href="https://arxiv.org/pdf/2409.12917">View PDF</a></p><blockquote>
            <span>Abstract:</span>Self-correction is a highly desirable capability of large language models (LLMs), yet it has consistently been found to be largely ineffective in modern LLMs. Existing approaches for training self-correction either require multiple models or rely on a more capable model or other forms of supervision. To this end, we develop a multi-turn online reinforcement learning (RL) approach, SCoRe, that significantly improves an LLM's self-correction ability using entirely self-generated data. To build SCoRe, we first show that variants of supervised fine-tuning (SFT) on offline model-generated correction traces are insufficient for instilling self-correction behavior. In particular, we observe that training via SFT either suffers from a distribution mismatch between the training data and the model's own responses or implicitly prefers only a certain mode of correction behavior that is often not effective at test time. SCoRe addresses these challenges by training under the model's own distribution of self-generated correction traces and using appropriate regularization to steer the learning process into learning a self-correction strategy that is effective at test time as opposed to simply fitting high-reward responses for a given prompt. This regularization prescribes running a first phase of RL on a base model to generate a policy initialization that is less susceptible to collapse and then using a reward bonus to amplify self-correction during training. When applied to Gemini 1.0 Pro and 1.5 Flash models, we find that SCoRe achieves state-of-the-art self-correction performance, improving the base models' self-correction by 15.6% and 9.1% respectively on the MATH and HumanEval benchmarks.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Vincent Zhuang [<a href="https://arxiv.org/show-email/eac614a3/2409.12917">view email</a>]      <br>    <strong>[v1]</strong>
        Thu, 19 Sep 2024 17:16:21 UTC (633 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Openpilot – Operating system for robotics (172 pts)]]></title>
            <link>https://github.com/commaai/openpilot</link>
            <guid>41600177</guid>
            <pubDate>Fri, 20 Sep 2024 09:19:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/commaai/openpilot">https://github.com/commaai/openpilot</a>, See on <a href="https://news.ycombinator.com/item?id=41600177">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<markdown-accessiblity-table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">To start using openpilot in a car</h2><a id="user-content-to-start-using-openpilot-in-a-car" aria-label="Permalink: To start using openpilot in a car" href="#to-start-using-openpilot-in-a-car"></a></p>
<p dir="auto">To use openpilot in a car, you need four things:</p>
<ol dir="auto">
<li><strong>Supported Device:</strong> a comma 3/3X, available at <a href="https://comma.ai/shop/comma-3x" rel="nofollow">comma.ai/shop</a>.</li>
<li><strong>Software:</strong> The setup procedure for the comma 3/3X allows users to enter a URL for custom software. Use the URL <code>openpilot.comma.ai</code> to install the release version.</li>
<li><strong>Supported Car:</strong> Ensure that you have one of <a href="https://github.com/commaai/openpilot/blob/master/docs/CARS.md">the 275+ supported cars</a>.</li>
<li><strong>Car Harness:</strong> You will also need a <a href="https://comma.ai/shop/car-harness" rel="nofollow">car harness</a> to connect your comma 3/3X to your car.</li>
</ol>
<p dir="auto">We have detailed instructions for <a href="https://comma.ai/setup" rel="nofollow">how to install the harness and device in a car</a>. Note that it's possible to run openpilot on <a href="https://blog.comma.ai/self-driving-car-for-free/" rel="nofollow">other hardware</a>, although it's not plug-and-play.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">To start developing openpilot</h2><a id="user-content-to-start-developing-openpilot" aria-label="Permalink: To start developing openpilot" href="#to-start-developing-openpilot"></a></p>
<p dir="auto">openpilot is developed by <a href="https://comma.ai/" rel="nofollow">comma</a> and by users like you. We welcome both pull requests and issues on <a href="http://github.com/commaai/openpilot">GitHub</a>.</p>
<ul dir="auto">
<li>Join the <a href="https://discord.comma.ai/" rel="nofollow">community Discord</a></li>
<li>Check out <a href="https://github.com/commaai/openpilot/blob/master/docs/CONTRIBUTING.md">the contributing docs</a></li>
<li>Check out the <a href="https://github.com/commaai/openpilot/blob/master/tools">openpilot tools</a></li>
<li>Read about the <a href="https://github.com/commaai/openpilot/blob/master/docs/WORKFLOW.md">development workflow</a></li>
<li>Code documentation lives at <a href="https://docs.comma.ai/" rel="nofollow">https://docs.comma.ai</a></li>
<li>Information about running openpilot lives on the <a href="https://github.com/commaai/openpilot/wiki">community wiki</a></li>
</ul>
<p dir="auto">Want to get paid to work on openpilot? <a href="https://comma.ai/jobs#open-positions" rel="nofollow">comma is hiring</a> and offers lots of <a href="https://comma.ai/bounties" rel="nofollow">bounties</a> for external contributors.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Safety and Testing</h2><a id="user-content-safety-and-testing" aria-label="Permalink: Safety and Testing" href="#safety-and-testing"></a></p>
<ul dir="auto">
<li>openpilot observes <a href="https://en.wikipedia.org/wiki/ISO_26262" rel="nofollow">ISO26262</a> guidelines, see <a href="https://github.com/commaai/openpilot/blob/master/docs/SAFETY.md">SAFETY.md</a> for more details.</li>
<li>openpilot has software-in-the-loop <a href="https://github.com/commaai/openpilot/blob/master/.github/workflows/selfdrive_tests.yaml">tests</a> that run on every commit.</li>
<li>The code enforcing the safety model lives in panda and is written in C, see <a href="https://github.com/commaai/panda#code-rigor">code rigor</a> for more details.</li>
<li>panda has software-in-the-loop <a href="https://github.com/commaai/panda/tree/master/tests/safety">safety tests</a>.</li>
<li>Internally, we have a hardware-in-the-loop Jenkins test suite that builds and unit tests the various processes.</li>
<li>panda has additional hardware-in-the-loop <a href="https://github.com/commaai/panda/blob/master/Jenkinsfile">tests</a>.</li>
<li>We run the latest openpilot in a testing closet containing 10 comma devices continuously replaying routes.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Licensing</h2><a id="user-content-licensing" aria-label="Permalink: Licensing" href="#licensing"></a></p>
<p dir="auto">openpilot is released under the MIT license. Some parts of the software are released under other licenses as specified.</p>
<p dir="auto">Any user of this software shall indemnify and hold harmless Comma.ai, Inc. and its directors, officers, employees, agents, stockholders, affiliates, subcontractors and customers from and against all allegations, claims, actions, suits, demands, damages, liabilities, obligations, losses, settlements, judgments, costs and expenses (including without limitation attorneys’ fees and costs) which arise out of, relate to or result from any use of this software by user.</p>
<p dir="auto"><strong>THIS IS ALPHA QUALITY SOFTWARE FOR RESEARCH PURPOSES ONLY. THIS IS NOT A PRODUCT.
YOU ARE RESPONSIBLE FOR COMPLYING WITH LOCAL LAWS AND REGULATIONS.
NO WARRANTY EXPRESSED OR IMPLIED.</strong></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">User Data and comma Account</h2><a id="user-content-user-data-and-comma-account" aria-label="Permalink: User Data and comma Account" href="#user-data-and-comma-account"></a></p>
<p dir="auto">By default, openpilot uploads the driving data to our servers. You can also access your data through <a href="https://connect.comma.ai/" rel="nofollow">comma connect</a>. We use your data to train better models and improve openpilot for everyone.</p>
<p dir="auto">openpilot is open source software: the user is free to disable data collection if they wish to do so.</p>
<p dir="auto">openpilot logs the road-facing cameras, CAN, GPS, IMU, magnetometer, thermal sensors, crashes, and operating system logs.
The driver-facing camera is only logged if you explicitly opt-in in settings. The microphone is not recorded.</p>
<p dir="auto">By using openpilot, you agree to <a href="https://comma.ai/privacy" rel="nofollow">our Privacy Policy</a>. You understand that use of this software or its related services will generate certain types of user data, which may be logged and stored at the sole discretion of comma. By accepting this agreement, you grant an irrevocable, perpetual, worldwide right to comma for the use of this data.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stop Designing Your Web Application for Millions of Users When You Dont Have 100 (113 pts)]]></title>
            <link>https://www.darrenhorrocks.co.uk/stop-designing-web-applications-for-millions/</link>
            <guid>41599970</guid>
            <pubDate>Fri, 20 Sep 2024 08:33:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.darrenhorrocks.co.uk/stop-designing-web-applications-for-millions/">https://www.darrenhorrocks.co.uk/stop-designing-web-applications-for-millions/</a>, See on <a href="https://news.ycombinator.com/item?id=41599970">Hacker News</a></p>
Couldn't get https://www.darrenhorrocks.co.uk/stop-designing-web-applications-for-millions/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[The Architecture of Open Source Applications (109 pts)]]></title>
            <link>https://aosabook.org/en/</link>
            <guid>41599523</guid>
            <pubDate>Fri, 20 Sep 2024 07:00:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aosabook.org/en/">https://aosabook.org/en/</a>, See on <a href="https://news.ycombinator.com/item?id=41599523">Hacker News</a></p>
<div id="readability-page-1" class="page">
    



<p>
  Architects look at thousands of buildings during their
  training, and study critiques of those buildings written
  by masters.  In contrast, most software developers only
  ever get to know a handful of large programs
  well—usually programs they wrote
  themselves—and never study the great programs of
  history.  As a result, they repeat one another's mistakes
  rather than building on one another's successes.
</p>
      
<p>
  Our goal is to change that.  In these two books, the authors of
  four dozen open source applications explain how their software
  is structured, and why.  What are each program's major
  components?  How do they interact?  And what did their builders
  learn during their development?  In answering these questions,
  the contributors to these books provide unique insights into how
  they think.
</p>
      
<p>
  If you are a junior developer, and want to learn how your
  more experienced colleagues think, these books are the place
  to start.  If you are an intermediate or senior developer,
  and want to see how your peers have solved hard design
  problems, these books can help you too.
</p>

<div>
  <p>
    <h2 id="aosa1">AOSA Volume 1</h2>
  </p>
</div>
<div>
    <table>
      <tbody><tr>
        <td></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html">Introduction</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#brown-amy">Amy Brown</a> and <a href="https://aosabook.org/en/v1/intro1.html#wilson-greg">Greg Wilson</a></td>
      </tr>
      <tr>
        <td>1.</td>
        <td><a href="https://aosabook.org/en/v1/asterisk.html">Asterisk</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#bryant-russell">Russell Bryant</a></td>
      </tr>
      <tr>
        <td>2.</td>
        <td><a href="https://aosabook.org/en/v1/audacity.html">Audacity</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#crook-james">James Crook</a></td>
      </tr>
      <tr>
        <td>3.</td>
        <td><a href="https://aosabook.org/en/v1/bash.html">The Bourne-Again Shell</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#ramey-chet">Chet Ramey</a></td>
      </tr>
      <tr>
        <td>4.</td>
        <td><a href="https://aosabook.org/en/v1/bdb.html">Berkeley DB</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#seltzer-margo">Margo Seltzer</a> and <a href="https://aosabook.org/en/v1/intro1.html#bostic-keith">Keith Bostic</a></td>
      </tr>
      <tr>
        <td>5.</td>
        <td><a href="https://aosabook.org/en/v1/cmake.html">CMake</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#hoffman-bill">Bill Hoffman</a> and <a href="https://aosabook.org/en/v1/intro1.html#martin-kenneth">Kenneth Martin</a></td>
      </tr>
      <tr>
        <td>6.</td>
        <td><a href="https://aosabook.org/en/v1/eclipse.html">Eclipse</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#moir-kim">Kim Moir</a></td>
      </tr>
      <tr>
        <td>7.</td>
        <td><a href="https://aosabook.org/en/v1/graphite.html">Graphite</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#davis-chris">Chris Davis</a></td>
      </tr>
      <tr>
        <td>8.</td>
        <td><a href="https://aosabook.org/en/v1/hdfs.html">The Hadoop Distributed File System</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#chansler-robert">Robert Chansler</a>, <a href="https://aosabook.org/en/v1/intro1.html#kuang-hairong">Hairong Kuang</a>, <a href="https://aosabook.org/en/v1/intro1.html#radia-sanjay">Sanjay Radia</a>, <a href="https://aosabook.org/en/v1/intro1.html#shvachko-konstantin">Konstantin Shvachko</a>, and <a href="https://aosabook.org/en/v1/intro1.html#srinivas-suresh">Suresh Srinivas</a></td>
      </tr>
      <tr>
        <td>9.</td>
        <td><a href="https://aosabook.org/en/v1/integration.html">Continuous Integration</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#brown-titus">C. Titus Brown</a> and <a href="https://aosabook.org/en/v1/intro1.html#canino-koning-rosangela">Rosangela Canino-Koning</a></td>
      </tr>
      <tr>
        <td>10.</td>
        <td><a href="https://aosabook.org/en/v1/jitsi.html">Jitsi</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#ivov-emil">Emil Ivov</a></td>
      </tr>
      <tr>
        <td>11.</td>
        <td><a href="https://aosabook.org/en/v1/llvm.html">LLVM</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#lattner-chris">Chris Lattner</a></td>
      </tr>
      <tr>
        <td>12.</td>
        <td><a href="https://aosabook.org/en/v1/mercurial.html">Mercurial</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#ochtman-dirkjan">Dirkjan Ochtman</a></td>
      </tr>
      <tr>
        <td>13.</td>
        <td><a href="https://aosabook.org/en/v1/nosql.html">The NoSQL Ecosystem</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#marcus-adam">Adam Marcus</a></td>
      </tr>
      <tr>
        <td>14.</td>
        <td><a href="https://aosabook.org/en/v1/packaging.html">Python Packaging</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#ziade-tarek">Tarek Ziadé</a></td>
      </tr>
      <tr>
        <td>15.</td>
        <td><a href="https://aosabook.org/en/v1/riak.html">Riak and Erlang/OTP</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#cesarini-francesco">Francesco Cesarini</a>, <a href="https://aosabook.org/en/v1/intro1.html#gross-andy">Andy Gross</a>, and <a href="https://aosabook.org/en/v1/intro1.html#sheehy-justin">Justin Sheehy</a></td>
      </tr>
      <tr>
        <td>16.</td>
        <td><a href="https://aosabook.org/en/v1/selenium.html">Selenium WebDriver</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#stewart-simon">Simon Stewart</a></td>
      </tr>
      <tr>
        <td>17.</td>
        <td><a href="https://aosabook.org/en/v1/sendmail.html">Sendmail</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#allman-eric">Eric Allman</a></td>
      </tr>
      <tr>
        <td>18.</td>
        <td><a href="https://aosabook.org/en/v1/snowflock.html">SnowFlock</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#bryant-roy">Roy Bryant</a> and <a href="https://aosabook.org/en/v1/intro1.html#lagar-cavilla-andres">Andrés Lagar-Cavilla</a></td>
      </tr>
      <tr>
        <td>19.</td>
        <td><a href="https://aosabook.org/en/v1/socialcalc.html">SocialCalc</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#tang-audrey">Audrey Tang</a></td>
      </tr>
      <tr>
        <td>20.</td>
        <td><a href="https://aosabook.org/en/v1/telepathy.html">Telepathy</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#madeley-danielle">Danielle Madeley</a></td>
      </tr>
      <tr>
        <td>21.</td>
        <td><a href="https://aosabook.org/en/v1/thousandparsec.html">Thousand Parsec</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#laudicina-alan">Alan Laudicina</a> and <a href="https://aosabook.org/en/v1/intro1.html#mavrinac-aaron">Aaron Mavrinac</a></td>
      </tr>
      <tr>
        <td>22.</td>
        <td><a href="https://aosabook.org/en/v1/violet.html">Violet</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#horstmann-cay">Cay Horstmann</a></td>
      </tr>
      <tr>
        <td>23.</td>
        <td><a href="https://aosabook.org/en/v1/vistrails.html">VisTrails</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#freire-juliana">Juliana Freire</a>, <a href="https://aosabook.org/en/v1/intro1.html#koop-david">David Koop</a>, <a href="https://aosabook.org/en/v1/intro1.html#santos-emanuele">Emanuele Santos</a>, <a href="https://aosabook.org/en/v1/intro1.html#scheidegger-carlos">Carlos Scheidegger</a>, <a href="https://aosabook.org/en/v1/intro1.html#silva-claudio">Claudio Silva</a>, and <a href="https://aosabook.org/en/v1/intro1.html#vo-huy">Huy T. Vo</a></td>
      </tr>
      <tr>
        <td>24.</td>
        <td><a href="https://aosabook.org/en/v1/vtk.html">VTK</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#geveci-berk">Berk Geveci</a> and <a href="https://aosabook.org/en/v1/intro1.html#schroeder-will">Will Schroeder</a></td>
      </tr>
      <tr>
        <td>25.</td>
        <td><a href="https://aosabook.org/en/v1/wesnoth.html">Battle For Wesnoth</a></td>
        <td><a href="https://aosabook.org/en/v1/intro1.html#shimooka-richard">Richard Shimooka</a> and <a href="https://aosabook.org/en/v1/intro1.html#white-david">David White</a></td>
      </tr>
      <tr>
        <td></td>
        <td><a href="https://aosabook.org/en/v1/bib1.html">Bibliography</a></td>
        <td></td>
      </tr>
    </tbody></table>
  </div>

<div>
  <p>
    <h2 id="aosa2">AOSA Volume 2</h2>
  </p>
</div>


<div>
  <p>
    <h2 id="posa">The Performance of Open Source Applications</h2>
  </p>
</div>


<div>
  <p>
    <h2 id="500lines">500 Lines or Less</h2>
  </p>
</div>


<h2>License and Royalties</h2>
<p>
  This work is made available under
  the <a href="http://creativecommons.org/licenses/by/3.0/legalcode">Creative Commons Attribution 3.0 Unported</a> license.
  Please see
  the <a href="https://aosabook.org/en/license.html">full description of the license</a> for details.
  All royalties from sales of these books will be donated to
  <a href="http://amnesty.org/">Amnesty International</a>.
</p>

<h2>Contributing</h2>
<p>
  Dozens of volunteers worked hard to create this book,
  but there is still lots to do.
  You can help by reporting errors,
  by helping to translate the content into other languages and formats,
  or by describing the architecture of other open source projects.
  Please contact us the coordinators for various translations listed below,
  or mail us directly at <a href="mailto:gvwilson@third-bit.com">gvwilson@third-bit.com</a>
  if you would like to start a new translation or write a chapter yourself.
</p>

  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why Apple Uses JPEG XL in the iPhone 16 and What It Means for Your Photos (196 pts)]]></title>
            <link>https://petapixel.com/2024/09/18/why-apple-uses-jpeg-xl-in-the-iphone-16-and-what-it-means-for-your-photos/</link>
            <guid>41598170</guid>
            <pubDate>Fri, 20 Sep 2024 02:10:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://petapixel.com/2024/09/18/why-apple-uses-jpeg-xl-in-the-iphone-16-and-what-it-means-for-your-photos/">https://petapixel.com/2024/09/18/why-apple-uses-jpeg-xl-in-the-iphone-16-and-what-it-means-for-your-photos/</a>, See on <a href="https://news.ycombinator.com/item?id=41598170">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><img data-perfmatters-preload="" fetchpriority="high" decoding="async" src="https://petapixel.com/assets/uploads/2024/09/iphone-jxl-featured-800x420.jpg" alt="A person holds a smartphone horizontally with an image of a person in a red dress standing on a wooden path in a grassy outdoor area displayed on the screen. There is also a glowing icon featuring an &quot;X&quot; on the right side of the image." width="800" height="420" srcset="https://petapixel.com/assets/uploads/2024/09/iphone-jxl-featured-800x420.jpg 800w, https://petapixel.com/assets/uploads/2024/09/iphone-jxl-featured-320x168.jpg 320w, https://petapixel.com/assets/uploads/2024/09/iphone-jxl-featured-1536x806.jpg 1536w, https://petapixel.com/assets/uploads/2024/09/iphone-jxl-featured-150x79.jpg 150w, https://petapixel.com/assets/uploads/2024/09/iphone-jxl-featured-300x157.jpg 300w, https://petapixel.com/assets/uploads/2024/09/iphone-jxl-featured-400x209.jpg 400w, https://petapixel.com/assets/uploads/2024/09/iphone-jxl-featured-550x288.jpg 550w, https://petapixel.com/assets/uploads/2024/09/iphone-jxl-featured.jpg 1600w" sizes="(max-width: 800px) 100vw, 800px"></p> <p>The iPhone 16 family has arrived and includes many new features, some of which Apple has played very close to its vest. One such improvement is the inclusion of JPEG XL file types, which promise improved image quality compared to standard JPEG files while delivering relatively smaller file sizes. </p>  <h2>What Is JPEG XL? </h2> <p><a href="https://jpeg.org/jpegxl/" data-wpel-link="external" target="_blank" rel="follow external noopener">JPEG XL</a> is a next-generation image encoding standard formally standardized in early 2022. Since then, JPEG XL (.jxl) has been adopted by numerous operating systems and applications, albeit with some notable holdouts. </p> <p>Apple and its various software iterations have supported JPEG XL for at least a year, including in Finder, Preview, Final Cut Pro, Pages, Photos, Mail, Safari, and more. Adobe has also supported the format for a while, including in Adobe Camera Raw and Lightroom Classic. </p> <figure id="attachment_759567" aria-describedby="caption-attachment-759567"><img decoding="async" src="https://petapixel.com/assets/uploads/2024/09/jpeg-xl-smaller-file-size-800x662.jpg" alt="A comparison image highlighting the efficiency of JPEG XL over traditional JPEG. On the left, a JPEG image of colorful umbrellas against a blue sky is shown with a score of 75.8, while the JPEG XL version on the right has a higher score of 86.3, indicating better quality despite smaller file size." width="800" height="662" srcset="https://petapixel.com/assets/uploads/2024/09/jpeg-xl-smaller-file-size-800x662.jpg 800w, https://petapixel.com/assets/uploads/2024/09/jpeg-xl-smaller-file-size-320x265.jpg 320w, https://petapixel.com/assets/uploads/2024/09/jpeg-xl-smaller-file-size-1536x1270.jpg 1536w, https://petapixel.com/assets/uploads/2024/09/jpeg-xl-smaller-file-size.jpg 1600w" sizes="(max-width: 800px) 100vw, 800px"><figcaption id="caption-attachment-759567">Credit: jpegxl.info</figcaption></figure> <p>Despite JPEG XL supporting reversible JPEG transcoding and being superior to JPEG in terms of quality and efficiency, the format has yet to be widely adopted. Neither Chrome nor Firefox, two very popular web browsers, support the format natively, for example. Extensions are available to support JPEG XL files, but they’re not installed by default. </p> <p>The <a href="https://jpegxl.info/" data-wpel-link="external" target="_blank" rel="follow external noopener">JPEG XL community website</a> cites the format’s ability to reduce file size while delivering “unmatched quality-per-byte.” Compared to a standard JPEG, a JPEG XL file is up to 55% smaller while providing a cleaner image that is visually lossless. Gone are typical JPEG artifacts. </p>
<p>Although it’s easy to appreciate the technical advantages of JPEG XL, it is also worth pointing out a substantial benefit of smaller file sizes: reduced environmental impact. As the world generates increasing amounts of data, it’s essential to consider ways to reduce data load. All that <em>stuff</em> lives somewhere, and wherever it is, it requires energy to operate. </p> <p>It’s also important to note that JPEG XL supports wide-gamut and high dynamic range images. “JPEG XL is specifically designed to handle the rich colors of high-precision, high-dynamic range images,” the creators explain. </p> <figure id="attachment_759570" aria-describedby="caption-attachment-759570"><img decoding="async" src="https://petapixel.com/assets/uploads/2024/09/jpeg-xl-wide-gamut-hdr-800x695.jpg" alt="An abstract image showcasing vibrant colors and combining wide-gamut and HDR technology for stunning color accuracy. The design features a mix of reds, blues, greens, and yellows with various bubbles and shapes, emphasizing vivid and dynamic contrasts." width="800" height="695" srcset="https://petapixel.com/assets/uploads/2024/09/jpeg-xl-wide-gamut-hdr-800x695.jpg 800w, https://petapixel.com/assets/uploads/2024/09/jpeg-xl-wide-gamut-hdr-320x278.jpg 320w, https://petapixel.com/assets/uploads/2024/09/jpeg-xl-wide-gamut-hdr-1536x1334.jpg 1536w, https://petapixel.com/assets/uploads/2024/09/jpeg-xl-wide-gamut-hdr.jpg 1600w" sizes="(max-width: 800px) 100vw, 800px"><figcaption id="caption-attachment-759570">To get the full impact, view this webpage on a compatible browser, like Safari, using an HDR display. | Credit: jpegxl.info</figcaption></figure> <p>The format supports up to 32 bits per channel, supports RGB and CMYK delivery, works with multiple frames, and is open source. </p> <p>.jxl files support RGB, YCgCo, and XYB color space. The RGB color space is familiar to most photographers, but XYB? That’s an odd one. This color space is built on the physiological processes by which people see. </p> <p>“XYB facilitates perceptually uniform quantization,” the JPEG XL community website explains. “JPEG XL uses a color space derived from LMS called XYB. Based on the lower spatial density of S cones, this is interpreted as a hybrid color theory where L and M oppose each other while S is handled trichromatically. As a result, less data is needed for storing blue signals without losing much quality. JPEG XL’s colorspace was derived from Guetzli’s butteraugli metric and is based on Google’s Pik project.” </p> <figure id="attachment_759570" aria-describedby="caption-attachment-759570"><img loading="lazy" decoding="async" src="https://petapixel.com/assets/uploads/2024/09/IMG_0252-800x600.jpg" alt="A serene marina with numerous sailboats and yachts docked neatly in rows. Calm water reflects the boats and a partly cloudy sky above. The background features a tree-lined shore and distant hills under a bright blue sky." width="800" height="600" srcset="https://petapixel.com/assets/uploads/2024/09/IMG_0252-800x600.jpg 800w, https://petapixel.com/assets/uploads/2024/09/IMG_0252-320x240.jpg 320w, https://petapixel.com/assets/uploads/2024/09/IMG_0252-1536x1152.jpg 1536w, https://petapixel.com/assets/uploads/2024/09/IMG_0252.jpg 1800w" sizes="(max-width: 800px) 100vw, 800px"><figcaption id="caption-attachment-759570">Photo by Chris Niccolls</figcaption></figure>
<p>Overall, JPEG XL addresses many of JPEG’s shortcomings. The 30-year-old format is not very efficient, only offers eight-bit color depth, doesn’t support HDR, doesn’t do alpha transparency, doesn’t support animations, doesn’t support multiple layers, includes compression artifacts, and exhibits banding and visual noise. JPEG XL tackles these issues, and unlike WebP and AVIF formats, which each have some noteworthy benefits too, JPEG XL has been built from the ground up with still images in mind. </p> <h2>Why JPEG XL? Why Now? </h2> <p>As for why it is including JPEG XL in the iPhone 16 Pro, Apple tells <em>PetaPixel</em> that the format promises two primary benefits over standard JPEG format: improved image quality and better compression performance. If there’s a 32MB JPEG image, that same photo will be 24MB in lossless JPEG XL and, even more impressively, about five megabytes in perceptually lossless format. </p> <p>Apple has wrapped JPEG XL photos inside a DNG container, enabling ProRAW files to retain their flexibility while being significantly smaller — up to nearly five times smaller. </p> <p><img loading="lazy" decoding="async" src="https://petapixel.com/assets/uploads/2024/09/iphone-screenshot-jpeg-xl-366x800.jpg" alt="A smartphone screen displays the Pro Default camera formats settings. Options include HEIF Max (up to 48 MP), ProRAW 12 MP, and ProRAW Max (up to 48 MP). It also shows settings for ProRAW format, including JPEG Lossless (Most Compatible), JPEG-XL Lossless, and JPEG-XL Lossy." width="366" height="800" srcset="https://petapixel.com/assets/uploads/2024/09/iphone-screenshot-jpeg-xl-366x800.jpg 366w, https://petapixel.com/assets/uploads/2024/09/iphone-screenshot-jpeg-xl-146x320.jpg 146w, https://petapixel.com/assets/uploads/2024/09/iphone-screenshot-jpeg-xl-702x1536.jpg 702w, https://petapixel.com/assets/uploads/2024/09/iphone-screenshot-jpeg-xl.jpg 731w" sizes="(max-width: 366px) 100vw, 366px"></p> <p>So, what’s the catch? Apple admits that JPEG XL is not universally adopted or supported, at least not yet, so it is not the ideal choice for every person. Each user will need to evaluate their workflow and needs and determine if JPEG XL fits. JPEG XL’s benefits won’t mean much to someone who works with software or platforms that don’t support the file. </p> <p>As Apple explains on the new iPhone models, JPEG XL files are supported on iOS 17 and later and macOS 14 and later. However, as mentioned, these .jxl files are wrapped in a DNG container, so you can’t just fire off .jxl files from the iPhone 16 Pro. </p> <figure id="attachment_759564" aria-describedby="caption-attachment-759564"><img loading="lazy" decoding="async" src="https://petapixel.com/assets/uploads/2024/09/jpeg-xl-story-apple-pr-3-800x558.jpg" alt="A collage of six vibrant photos: A striking profile of a woman with colorful makeup, two people lying on a blanket outdoors wearing sunglasses, a woman in a white dress standing in a field, a person on a sunny rooftop, a close-up of a praying mantis, a person in a bright green sweater taking a selfie on a cobblestone street." width="800" height="558" srcset="https://petapixel.com/assets/uploads/2024/09/jpeg-xl-story-apple-pr-3-800x558.jpg 800w, https://petapixel.com/assets/uploads/2024/09/jpeg-xl-story-apple-pr-3-320x223.jpg 320w, https://petapixel.com/assets/uploads/2024/09/jpeg-xl-story-apple-pr-3-1536x1071.jpg 1536w, https://petapixel.com/assets/uploads/2024/09/jpeg-xl-story-apple-pr-3.jpg 1600w" sizes="(max-width: 800px) 100vw, 800px"><figcaption id="caption-attachment-759564">Credit: Apple</figcaption></figure>
<p>As has been the case with some of Apple’s other early adoptions, like Thunderbolt, not everything always works in every case. One can just look at the rollout of the HEIC format in the photo space for evidence of how new formats don’t always take hold and receive fast, widespread support. Compared to JPEG XL, HEIC — an implementation of HEIF — is just not good. </p> <p>With JPEG XL, while the benefits of the format are obvious and numerous, there are apt to be growing pains. Apple has done its part to limit these issues by offering JPEG XL support across its platforms and utilizing DNG containers.</p> <p>The other side of the coin is that because Apple is adopting and supporting JPEG XL, other companies may follow suit. While Samsung added JPEG XL to its latest Galaxy smartphones earlier this year, that doesn’t carry the same weight as Apple bringing JPEG XL to its latest smartphones and supporting it across its entire ecosystem. </p> <p>That’s not to say that JPEG XL is a few short months away from being as ubiquitous as the standard JPEG image format. It will take time, and there’s no guarantee the format will ever be universally supported. </p> <p>JPEG XL addresses many of the problems of JPEG images, so hopefully, JPEG XL will receive widespread support. As Apple fully understands, JPEG XL is clearly the superior format for photographers. </p> <figure id="attachment_759528" aria-describedby="caption-attachment-759528"><img loading="lazy" decoding="async" src="https://petapixel.com/assets/uploads/2024/09/IMG_0287-600x800.jpg" alt="A wooden wall decorated with an eclectic mix of items including a guitar, paddle, windows, signs, a framed picture, and various knick-knacks. Two red wooden chairs sit in front, while the wall features signs that say &quot;Inspire&quot; and &quot;No Trespassing." width="600" height="800" srcset="https://petapixel.com/assets/uploads/2024/09/IMG_0287-600x800.jpg 600w, https://petapixel.com/assets/uploads/2024/09/IMG_0287-240x320.jpg 240w, https://petapixel.com/assets/uploads/2024/09/IMG_0287-1152x1536.jpg 1152w, https://petapixel.com/assets/uploads/2024/09/IMG_0287.jpg 1350w" sizes="(max-width: 600px) 100vw, 600px"><figcaption id="caption-attachment-759528">Credit: Chris Niccolls</figcaption></figure> <h2>A Welcome Improvement With Some Practical Concerns </h2> <p>For now, those who happily live inside Apple’s walled garden will benefit from JPEG XL. Even when wandering outside the Mac/iPhone/iPad ecosystem, using JPEG XL can be a painless experience. It’s easy enough to open and edit JPEG XL files in Adobe software, for example. </p>
<figure id="attachment_759563" aria-describedby="caption-attachment-759563"><img loading="lazy" decoding="async" src="https://petapixel.com/assets/uploads/2024/09/jpeg-xl-story-apple-pr-4-800x718.jpg" alt="A hand is holding a smartphone, displaying a camera viewfinder. The screen shows a well-lit person with curly hair, wearing a patterned shirt, seated on a red chair. The person's face is turned slightly to the side, and the background appears light and minimalistic." width="800" height="718" srcset="https://petapixel.com/assets/uploads/2024/09/jpeg-xl-story-apple-pr-4-800x718.jpg 800w, https://petapixel.com/assets/uploads/2024/09/jpeg-xl-story-apple-pr-4-320x287.jpg 320w, https://petapixel.com/assets/uploads/2024/09/jpeg-xl-story-apple-pr-4-1536x1379.jpg 1536w, https://petapixel.com/assets/uploads/2024/09/jpeg-xl-story-apple-pr-4.jpg 1600w" sizes="(max-width: 800px) 100vw, 800px"><figcaption id="caption-attachment-759563">Credit: Apple</figcaption></figure> <p>However, beyond that, support will come later or may not come at all. JPEG is old and outdated, but its age has come myriad support and compatibility. Fortunately, reverse transcoding between JPEG and JPEG XL is possible, but even that still requires development efforts. The point is that just because JPEG XL is obviously better than many competing formats, it doesn’t mean everyone will adopt it. </p> <figure id="attachment_759569" aria-describedby="caption-attachment-759569"><img loading="lazy" decoding="async" src="https://petapixel.com/assets/uploads/2024/09/jpeg-xl-environmental-impact-800x487.jpg" alt="An infographic titled &quot;Environmental Impact&quot; explains that delivering JPEG XLs instead of JPEGs could save 4.87 gigawatt-hours per day. This is equivalent to powering 487,000 average US homes for an hour and saving 3,500 metric tons of CO2 emissions per day." width="800" height="487" srcset="https://petapixel.com/assets/uploads/2024/09/jpeg-xl-environmental-impact-800x487.jpg 800w, https://petapixel.com/assets/uploads/2024/09/jpeg-xl-environmental-impact-320x195.jpg 320w, https://petapixel.com/assets/uploads/2024/09/jpeg-xl-environmental-impact-1536x934.jpg 1536w, https://petapixel.com/assets/uploads/2024/09/jpeg-xl-environmental-impact.jpg 1600w" sizes="(max-width: 800px) 100vw, 800px"><figcaption id="caption-attachment-759569">Smaller file sizes with similar or even better image quality has significant environmental implications. | Credit: jpegxl.info</figcaption></figure> <p>For iPhone photographers, the benefits far outweigh the potential downsides. There’s little doubt that JPEG XL is an excellent image format that offers the quality of heavyweight formats with a file size even smaller than that of JPEGs. What would typically be a 75-ish megabyte ProRAW Max file will be about 20MB in a lossy ProRAW format using JPEG XL compression. A lossless file is still under 50MB. Without compromising quality, those are significant storage savings.</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Anthropic – Introducing Contextual Retrieval (252 pts)]]></title>
            <link>https://www.anthropic.com/news/contextual-retrieval</link>
            <guid>41598119</guid>
            <pubDate>Fri, 20 Sep 2024 01:57:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/news/contextual-retrieval">https://www.anthropic.com/news/contextual-retrieval</a>, See on <a href="https://news.ycombinator.com/item?id=41598119">Hacker News</a></p>
Couldn't get https://www.anthropic.com/news/contextual-retrieval: Error: timeout of 10000ms exceeded]]></description>
        </item>
    </channel>
</rss>