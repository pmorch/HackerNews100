<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 05 Sep 2023 15:00:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Android 14 blocks all modification of system certificates, even as root (111 pts)]]></title>
            <link>https://httptoolkit.com/blog/android-14-breaks-system-certificate-installation/</link>
            <guid>37391521</guid>
            <pubDate>Tue, 05 Sep 2023 13:42:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://httptoolkit.com/blog/android-14-breaks-system-certificate-installation/">https://httptoolkit.com/blog/android-14-breaks-system-certificate-installation/</a>, See on <a href="https://news.ycombinator.com/item?id=37391521">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>When Android was <a href="http://www.openhandsetalliance.com/press_110507.html">initially announced</a> in 2007 by the Open Handset Alliance (headed by Google) their flagship project was billed as an "open platform", "providing developers a new level of openness", and giving them "complete access to handset capabilities and tools".</p>
<p>We've come a long way since then, steadily retreating from openness &amp; user control of devices, and shifting towards a far more locked-down vendor-controlled world.</p>
<p>The next step of Android's evolution is Android 14 (API v34, codename Upside-Down Cake) and it takes more steps down that path. In this new release, the restrictions around certificate authority (CA) certificates become significantly tighter, and appear to make it impossible to modify the set of trusted certificates at all, even on fully rooted devices.</p>
<p>If you're an Android developer, tester, reverse engineer, or anybody else interested in directly controlling who your device trusts, this is going to create some new challenges.</p>
<p>Before we get into the finer details, first I want to talk a little about the context around Android CA management and how we got here, but if you want to jump to the latest details you can go straight to the <a href="#enter-android-14">Enter Android 14</a> section below.</p>
<h2 id="open-software-open-device-open-ecosystem"><a href="#open-software-open-device-open-ecosystem" aria-label="open software open device open ecosystem permalink"></a>"Open Software, Open Device, Open Ecosystem"</h2>
<p>While the initial principles of Android were very much focused on open software, controllable by users and developers, over more recent years Android has increasingly limited the control of users, developers &amp; researchers over their own devices.</p>
<p>The key turning point in this process was Android 7 (Nougat, released in 2016) in which the certificate authorities (CAs) on the device that were previously fully modifiable by the owner of the phone were <a href="https://android-developers.googleblog.com/2016/07/changes-to-trusted-certificate.html">split in two</a>: one fixed list of CAs provided by the OS vendor and used by default by every app on your phone, and another set of user-modifiable CAs that users could control, but which was used only for apps that specifically opted in (i.e. almost none).</p>
<p>The set of CAs on a device is a small configuration setting with big consequences, as your device's trusted CAs are the organizations guaranteeing the security of your encrypted network traffic. A CA can issue TLS certificates (as used in HTTPS to secure all communication on the web) for any domain name they like, and anybody who trusts that CA will trust those certificates as evidence of a secure &amp; legitimate connection to that domain.</p>
<p>That also means though that if you create your own CA and trust it then you can intercept your own HTTPS or other TLS traffic, to see exactly what your phone is sending &amp; receiving, and potentially modify or block it. Being able to configure your device's CAs is key to this.</p>
<p>That is a lot of power. Making this difficult to modify accidentally for non-technical users and impossible to modify without user knowledge is certainly reasonable. At the same time however, being able to control this is critical for privacy &amp; security research, reverse engineering, app debugging &amp; testing, for assorted enterprise internal network configurations, for anybody who doesn't trust one of the standard CAs provided by their vendor, and many other cases.</p>
<p>With that one change in Android Nougat in 2016, each of those use cases became significantly more challenging. It became impossible for users on normal devices to control who was trusted to secure the communication of apps on their own devices, and a substantial hurdle was created that directly transferred power from users to vendors &amp; third-party app developers.</p>
<h2 id="rooting-around-the-nougat-problem"><a href="#rooting-around-the-nougat-problem" aria-label="rooting around the nougat problem permalink"></a>Rooting around the Nougat problem</h2>
<p>Although this is very inconvenient, fortunately it's long been possible to root Android devices, allowing full administrative access over the device, and making it possible to work around these kinds of restrictions. This isn't officially encouraged by Google, but it's been sufficient as a workaround to allow researchers, developers &amp; reverse engineers to take control of their own devices for these advanced use cases.</p>
<p>By doing so, it was possible to deal with Android Nougat's restrictions on rooted devices, manually adding the trusted certificate to the system store via the filesystem, injecting them into the <code>/system/etc/security/cacerts/</code> directory.</p>
<p>This is a bit harder than it sounds, because <code>/system</code> is generally read-only, even on rooted devices. There are two main ways to solve that:</p>
<ul>
<li>Make <code>/system</code> directory writable (requires a little reconfiguration &amp; a device reboot) and then manually modify the real system certificates directory.</li>
<li>Mount a temporary read-write filesystem over the top of the read-only directory, copy the existing CA certs into there, and then add your own additions on top too.</li>
</ul>
<p>In each case there are a few other steps required to ensure that the certificates have the appropriate naming, permissions, and SELinux labels to be accepted by the system (for more low-level details and discussion see <a href="https://httptoolkit.com/blog/intercepting-android-https/">this post</a>), but it's relatively simple and HTTP Toolkit has long automated the temporary mount-based process (see <a href="https://github.com/httptoolkit/httptoolkit-server/blob/aa453e9df98491c549aa4b97b90618f1cf808e17/src/interceptors/android/adb-commands.ts#L256-L308">the certificate injection script here</a>). In practice, this means it's possible to provide one-click automated interception setup for any rooted Android device or emulator.</p>
<p>These approaches have been effective not only on custom rooted devices and specialized Android distributions, but even in most of Google's own official emulator images (everything except the full 'Google Play' edition images, which are locked down to match a normal OEM device) not to mention other emulators from Genymotion to Bluestacks.</p>
<p>Easy &amp; effective CA setup has powered myriad tools that let you see what apps on your phone are sending &amp; receiving: helping developers to debug their networking issues, keeping app developers honest about the data they share, and shining a light on security vulnerabilities in both apps &amp; their APIs.</p>
<p>These techniques are used by HTTP Toolkit's automatic setup, but also referenced in the setup guides for similar tools like <a href="https://docs.mitmproxy.org/stable/howto-install-system-trusted-ca-android/#3-insert-certificate-into-system-certificate-store">mitmproxy</a>, in <a href="https://awakened1712.github.io/hacking/hacking-install-ca-android/">endless</a> <a href="https://binary-manu.github.io/binary-is-better/android/add-certificates-to-android-ca-store">blog</a> <a href="https://blog.ropnop.com/configuring-burp-suite-with-android-nougat#install-burp-ca-as-a-system-level-trusted-ca">posts</a>, <a href="https://stackoverflow.com/a/46569793/68051">StackOverflow answers</a> and <a href="https://forum.xda-developers.com/t/tutorial-how-to-install-custom-ssl-certificates-root-etc-on-bluestacks-4-5.4513773/">forum threads</a>, widely used in tools including <a href="https://github.com/NVISOsecurity/MagiskTrustUserCerts">popular Magisk packages</a> and by organizations like the <a href="http://wiki.cacert.org/FAQ/ImportRootCert#CAcert_system_trusted_certificates_.28without_lockscreen.29">community-run CA cacert.org</a>.</p>
<p>These are widespread techniques that have worked for many years. Although the required root access has become more a little challenging more recently (due to first SafetyNet and later 'Play Integrity' using attestation to allow apps to block users who use rooted devices) this solution has generally been quite manageable, and a just-about-acceptable balance between "inconvenient enough to disuade users unaware of the implications" and "accessible to power users who know what they're doing".</p>
<h2 id="enter-android-14"><a href="#enter-android-14" aria-label="enter android 14 permalink"></a>Enter Android 14</h2>
<p>Right now, Android 14 is currently in its final stages of beta testing, slated for imminent release within a couple of weeks.</p>
<p>One of its headline new security features is <a href="https://www.xda-developers.com/android-14-root-certificates-updatable/">remotely updatable CA certificates</a>, which extracts management of CA certificates from the core OS image entirely, and moves it into a separately updateable component, delivered &amp; updated via Google Play. This allows for faster CA updates for Google, allowing them to revoke trust of problematic or failing CAs on all Android 14+ devices with just a Google Play System Update, without waiting for each phone vendor to release an OTA update for the whole operating system.</p>
<p>Although I'm sure you can see what's coming, let me caveat first: at a very high level, the goal here is a Good Thing.</p>
<p>CAs trusted by default like this are in a powerful position, and there needs to be serious oversight &amp; consequences to ensure they stick to their responsibilities and continue to justify that trust. When they fail to do so, it's important that this power is taken away quickly, before it can be abused.</p>
<p>In the most notable recent case, in January 2023 TrustCor was untrusted as a CA by effectively everybody (<a href="https://security.googleblog.com/2023/01/sustaining-digital-certificate-security_13.html">including Google</a>), after close ties to a malware-distributing organization and associated US defence/intelligence contractor were <a href="https://www.theregister.com/2022/12/02/mozilla_microsoft_trustcor/">discovered</a>.</p>
<p>In the other direction, the inability to widely distribute &amp; trust new CA certificates has caused issues for new CAs on the block such as Let's Encrypt, who have had to <a href="https://letsencrypt.org/2023/07/10/cross-sign-expiration.html">repeatedly delay the rollout</a> of improvements to their signing chain, because old Android devices missing recent CA root certificates would not have trusted them, and would thereby have been locked out of significant parts of the web.</p>
<p>Mechanisms to improve the responsiveness of this system are valuable. In addition to just speeding up removals &amp; additions, this should also widen access to those updates, since even devices for which vendors no longer offer official OS updates can continue to receive system component updates like this via Google Play for significantly longer.</p>
<p>Unfortunately though, despite those sensible goals, the reality of the implementation has serious consequences: system CA certificates are no longer loaded from <code>/system</code>, and when using root access to either directly modify or mount over the new location on disk, all changes are ignored by all apps on the device. Uh oh.</p>
<h2 id="the-mechanics"><a href="#the-mechanics" aria-label="the mechanics permalink"></a>The mechanics</h2>
<p>The key change to enable this is <a href="https://android.googlesource.com/platform/frameworks/base/+/8b192b19f264a8829eac2cfaf0b73f6fc188d933">here</a>. Instead of reading from the venerable <code>/system/etc/security/cacerts</code> directory, this new approach reads certificates from <code>/apex/com.android.conscrypt/cacerts</code>, when it exists.</p>
<p>That root <code>/apex</code> path is where Android Pony EXpress (APEX) containers are mounted. These APEX modules are independently updatable system components, delivered as signed &amp; immutable containers. In this case, the certificates form part of Android's <code>com.android.conscrypt</code> module - its core TLS/SSL library delivered as an independently updatable system module.</p>
<p>The exact mechanisms behind APEX are challenging to fully understand, as many low-level details seem undocumented, and <a href="https://android.googlesource.com/platform/system/apex/+/master/docs/howto.md">what documentation there is</a> includes links to key details only available within Google's internal sites. Tessting the resulting behaviour though, it seems that this is using some kinds of containerization primitives to expose the mounted content directly to individual processes, resulting in surprising behaviour when trying to modify these files elsewhere. As a result, delivering content through an APEX module makes it much harder (seemingly impossible) to manually modify, even with full administrative control.</p>
<p>It's easy to test this for yourself, using the latest Android 14 beta official emulators. Both the Android Open Source Project (AOSP) and 'Play Services' images have always allowed root access (unlike the 'Google Play' images) and by creating an emulator using those you can easily open a root shell.</p>
<p>Follow either of the two existing techniques though, and the expected updates do nothing. Let's walk through a demo.</p>
<p>First, set up your device. You'll need the Android SDK installed, and you probably want <a href="https://developer.android.com/studio">Android Studio</a>, since it makes this much easier, although you can use the CLI directly if you like.</p>
<p>First, create an emulator:</p>
<ul>
<li>Through the Android Studio UI, select any device model, and the API 34 'Google APIs' image for your architecture.</li>
<li>Or, using the Android SDK tools on the CLI, run <code>avdmanager create avd -n TestAVD -k 'system-images;android-34;google_apis;x86_64'</code> (your architecture may vary)</li>
</ul>
<p>Let's try messing with temporary mounts and see what we can do:</p>
<ul>
<li>Start your emulator, via the UI or <code>emulator -avd TestAVD</code></li>
<li>Open a root shell via <code>adb shell</code>, then <code>su</code></li>
<li>
<p>Try mounting an empty temporary filesystem over the various <code>cacerts</code> directories now present:</p>
<div data-language="bash">
      <pre><code><span>mount</span> -t tmpfs tmpfs /system/etc/security/cacerts
<span>mount</span> -t tmpfs tmpfs /system/etc/security/cacerts_google
<span>mount</span> -t tmpfs tmpfs /apex/com.android.conscrypt/cacerts
<span>mount</span> -t tmpfs tmpfs /apex/com.android.conscrypt@340818022/cacerts
<span># N.b. that last @id may vary in future updates</span></code></pre>
      </div>
</li>
<li>
<p>In the emulator, open Settings -&gt; Security &amp; Privacy -&gt; More -&gt; Encryption -&gt; Trusted Credentials</p>
<p>Under the 'System' tab, all the certificates you've just hidden from view on disk are there!</p>
</li>
</ul>
<p>So, where's this coming from?</p>
<ul>
<li>
<p>We can try searching the entire filesystem to find the source of this data. For example, the top certificate shown is from 'ACCV'. You can also find that in Android's sources <a href="https://android.googlesource.com/platform/system/ca-certificates/+/refs/heads/main/files/3c9a4d3b.0">here</a>, and it's present both there and in unmodified Android CA cert folders as <code>3c9a4d3b.0</code>. We can search for this with:</p>
<div data-language="bash">
      <pre><code><span>find</span> <span>.</span> -name 3c9a4d3b.0 <span>2</span><span>&amp;&gt;</span>/dev/null</code></pre>
      </div>
</li>
<li>It doesn't exist!</li>
</ul>
<p>But in fact, it does: remove your 4 mounts again (<code>umount &lt;path&gt;</code>), retry that <code>find</code> command, and you'll see that this is indeed present in the original <code>cacerts</code> directories.</p>
<p>Try the exact same steps with an Android 13 image, and you'll find that this modifies the certs just fine, and the Settings certificates list appears entirely empty, as expected:</p>
<p><span>
      <a href="https://httptoolkit.com/static/0d48251c38cb25f809eda5c6e1828673/54003/android-empty-system-certs.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="An Android device showing an empty 'Trusted Credentials' list" title="An Android device showing an empty 'Trusted Credentials' list" src="https://httptoolkit.com/static/0d48251c38cb25f809eda5c6e1828673/54003/android-empty-system-certs.png" srcset="https://httptoolkit.com/static/0d48251c38cb25f809eda5c6e1828673/0a77b/android-empty-system-certs.png 256w,
https://httptoolkit.com/static/0d48251c38cb25f809eda5c6e1828673/54003/android-empty-system-certs.png 338w" sizes="(max-width: 338px) 100vw, 338px" loading="lazy">
  </a>
    </span></p>
<p>Let's try another route and see if we can rewrite the system image filesystem directly to modify this list:</p>
<ul>
<li>
<p>Stop your emulator, and restart it from the CLI with a writable system partition:</p>
<div data-language="bash">
      <pre><code>emulator -avd TestAVD -writable-system</code></pre>
      </div>
</li>
<li>
<p>Make everything writable:</p>
<div data-language="text">
      <pre><code>adb root
adb remount
adb shell avbctl disable-verification
adb reboot
adb root
adb remount</code></pre>
      </div>
</li>
<li>
<p>You can delete all the normal certificates now (fair warning: this may create problems when using this emulator in future!) with:</p>
<div data-language="bash">
      <pre><code><span>rm</span> -rf /system/etc/security/cacerts/*
<span>rm</span> -rf /system/etc/security/cacerts_google/*</code></pre>
      </div>
</li>
<li>You'll find that you can't delete the certs from <code>/apex</code> though! Despite the remount, it's read-only, and <code>mount -o remount,rw ...</code> commands to do so manually will all fail.</li>
<li>The closest you can do, so far as I can tell, is to unmount the certificates entirely with <code>umount &lt;path&gt;</code> so that they don't appear in the output of <code>mount</code> at all.</li>
<li>Doesn't matter though: no matter how aggressive you get, seemingly no matter how much of the emulator's relevant internals you delete, AFAICT there's nothing you can do to stop these certs all happily loading up in the 'Trusted' list in the Settings.</li>
</ul>
<p>As in with the other method, those same steps will work just fine on every other version of Android, up until now.</p>
<p>Note that this isn't just a detail about the Settings app, where these are cached or stored elsewhere. The certificates as shown here are reloaded each time, and they're representative of every app's view of the certificate store.</p>
<p>No matter what you modify on the filesystem, every app will continue to see Google's list of CA certificates regardless. I've been playing with this for a while, and as far as I can tell there's no working method to modify the certs anybody sees.</p>
<h2 id="what-is-going-on-here"><a href="#what-is-going-on-here" aria-label="what is going on here permalink"></a>What is going on here?</h2>
<p>It's hard to tell precisely, so I'm guessing &amp; inferring here (but if anybody does have more information, I'd love to hear it! Get in touch <a href="https://toot.cafe/@pimterry">on Mastodon</a>, <a href="https://twitter.com/pimterry">on Twitter</a> or <a href="https://httptoolkit.com/contact/">directly</a>).</p>
<p>I think the most likely case is that as part of the wider modularization of Android, these system files and components are now exposed to apps through an entirely different mechanism. It looks clear from the Android internals that they're still being <a href="https://android.googlesource.com/platform/frameworks/base/+/8b192b19f264a8829eac2cfaf0b73f6fc188d933/core/java/android/security/net/config/DirectoryCertificateSource.java#64">read from disk</a> and the code to do so hasn't changed in many years, so this implies not everybody is seeing the same filesystem. This is similar to how Docker and friends use chroot, overlay filesystems and mounts to run containers with an isolated view of system files and other devices.</p>
<p>Clearly, this has some serious consequences.</p>
<p>As touched on above: if you're configuring your own system CA certificates on Android right now for debugging, reverse engineering, testing or research, that option is going away in Android 14, and presumably all future versions too.</p>
<p>For now anybody interested in these use cases will just have to avoid updating, or use custom OS releases that don't use the APEX module to manage their CA certs. As time goes by though, this will likely become increasingly impractical, since it means either diverging strongly from Android mainline on a key internal component or running outdated software indefinitely.</p>
<p>Concerningly though, this also implies that APEX system modules are going to be a wider problem. If, as it appears, content within APEX modules is unmodifiable to users even with root access to the device, then every future system component that's moved into the remit of APEX is another part of Android that becomes completely removed from user control.</p>
<p>More investigation is required and it's hard to know the full implications of that now, but for the many forks of Android like GrapheneOS &amp; LineageOS, and for advanced device configuration tools like <a href="https://github.com/topjohnwu/Magisk#readme">Magisk</a> and its many modules, it probably spells trouble.</p>
<p>Personally, for now I'm investigating some other promising alternative solutions to allow interception of your own network traffic on Android, and I'll share details here as soon as I have something working, so watch this space.</p>
<p>In the meantime, if you want to debug your own HTTPS traffic, you'll need to stick to Android 13.</p>
<p><strong>Want to inspect, debug &amp; mock Android traffic on your Android 13 device anyway? <a href="https://httptoolkit.com/android/">Try out HTTP Toolkit</a> - hands-free HTTP(S) interception for mobile, web browsers, backend services, Docker, and more.</strong></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A currently maintained fork of SSHFS (155 pts)]]></title>
            <link>https://github.com/deadbeefsociety/sshfs</link>
            <guid>37390184</guid>
            <pubDate>Tue, 05 Sep 2023 11:04:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/deadbeefsociety/sshfs">https://github.com/deadbeefsociety/sshfs</a>, See on <a href="https://news.ycombinator.com/item?id=37390184">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">This is a currently maintained fork of SSHFS</h2>
<p dir="auto">SSHFS (original repo: <a href="https://github.com/libfuse/sshfs">https://github.com/libfuse/sshfs</a>) has been declared to be unmaintained and it breaks our heart. So me and some friends have decided to fork it and give it some love.</p>
<p dir="auto">There's a rust fork in progress by Greg Shuflin (<a href="https://github.com/neunenak/sshfs/tree/rust">https://github.com/neunenak/sshfs/tree/rust</a>). Rust is a modern and memory safe programming language, and in the long term, it's not a bad decision to port it to rust.</p>
<p dir="auto">However, there are some downsides to Rust, such as it being still a young language, unstable API changes, it not having a standard specification yet, and long and compute-intensive compilation process etc.</p>
<p dir="auto">So from a maintenance perspective, we are just here to fix issues, merge PRs, and give this project some love until the rust fork is ready (maybe even backport changes/features from there for a period of time).</p>
<p dir="auto">Everyone is welcome to create issues or PRs, please do contribute!</p>
<h2 tabindex="-1" dir="auto">SSHFS</h2>
<h2 tabindex="-1" dir="auto">About</h2>
<p dir="auto">SSHFS allows you to mount a remote filesystem using SFTP. Most SSH
servers support and enable this SFTP access by default, so SSHFS is
very simple to use - there's nothing to do on the server-side.</p>
<h2 tabindex="-1" dir="auto">Development Status</h2>
<p dir="auto">SSHFS is shipped by all major Linux distributions and has been in
production use across a wide range of systems for many years. However,
at present SSHFS does not have any active, regular contributors, and
there are a number of known issues (see the <a href="https://github.com/libfuse/sshfs/issues">bugtracker</a>).  The current
maintainer continues to apply pull requests and makes regular
releases, but unfortunately has no capacity to do any development
beyond addressing high-impact issues. When reporting bugs, please
understand that unless you are including a pull request or are
reporting a critical issue, you will probably not get a response.</p>
<h2 tabindex="-1" dir="auto">How to use</h2>
<p dir="auto">Once sshfs is installed (see next section) running it is very simple:</p>
<div data-snippet-clipboard-copy-content="sshfs [user@]hostname:[directory] mountpoint"><pre><code>sshfs [user@]hostname:[directory] mountpoint
</code></pre></div>
<p dir="auto">It is recommended to run SSHFS as regular user (not as root).  For
this to work the mountpoint must be owned by the user.  If username is
omitted SSHFS will use the local username. If the directory is
omitted, SSHFS will mount the (remote) home directory.  If you need to
enter a password sshfs will ask for it (actually it just runs ssh
which asks for the password if needed).</p>
<p dir="auto">Also many ssh options can be specified (see the manual pages for
<em>sftp(1)</em> and <em>ssh_config(5)</em>), including the remote port number
(<code>-oport=PORT</code>)</p>
<p dir="auto">To unmount the filesystem:</p>

<p dir="auto">On BSD and macOS, to unmount the filesystem:</p>

<h2 tabindex="-1" dir="auto">Installation</h2>
<p dir="auto">First, download the latest SSHFS release from
<a href="https://github.com/libfuse/sshfs/releases">https://github.com/libfuse/sshfs/releases</a>. You also need <a href="http://github.com/libfuse/libfuse">libfuse</a> 3.1.0 or newer (or a
similar library that provides a libfuse3 compatible interface for your operating
system). Finally, you need the <a href="https://developer.gnome.org/glib/stable/" rel="nofollow">Glib</a> library with development headers (which should be
available from your operating system's package manager).</p>
<p dir="auto">To build and install, we recommend to use <a href="http://mesonbuild.com/" rel="nofollow">Meson</a> (version 0.38 or
newer) and <a href="https://ninja-build.org/" rel="nofollow">Ninja</a>.  After extracting the sshfs tarball, create a
(temporary) build directory and run Meson:</p>
<div data-snippet-clipboard-copy-content="$ mkdir build; cd build
$ meson .."><pre><code>$ mkdir build; cd build
$ meson ..
</code></pre></div>
<p dir="auto">Normally, the default build options will work fine. If you
nevertheless want to adjust them, you can do so with the <em>mesonconf</em>
command:</p>
<div data-snippet-clipboard-copy-content="$ mesonconf                  # list options
$ mesonconf -D strip=true    # set an option"><pre><code>$ mesonconf                  # list options
$ mesonconf -D strip=true    # set an option
</code></pre></div>
<p dir="auto">To build, test and install SSHFS, you then use Ninja (running the
tests requires the <a href="http://www.pytest.org/" rel="nofollow">py.test</a> Python module):</p>
<div data-snippet-clipboard-copy-content="$ ninja
$ python3 -m pytest test/    # optional, but recommended
$ sudo ninja install"><pre><code>$ ninja
$ python3 -m pytest test/    # optional, but recommended
$ sudo ninja install
</code></pre></div>
<h2 tabindex="-1" dir="auto">Getting Help</h2>
<p dir="auto">If you need help, please ask on the <a href="mailto:fuse-sshfs@lists.sourceforge.net">fuse-sshfs@lists.sourceforge.net</a>
mailing list (subscribe at
<a href="https://lists.sourceforge.net/lists/listinfo/fuse-sshfs" rel="nofollow">https://lists.sourceforge.net/lists/listinfo/fuse-sshfs</a>).</p>
<p dir="auto">Please report any bugs on the GitHub issue tracker at
<a href="https://github.com/deadbeefsociety/libfuse/issues">https://github.com/deadbeefsociety/libfuse/issues</a>.</p>
<h2 tabindex="-1" dir="auto">Packaging Status</h2>
<a href="https://repology.org/project/fusefs:sshfs/versions" rel="nofollow">
    <img src="https://camo.githubusercontent.com/f70b3d43f81bdd98d9628c77a6724bf5341d895beb86d26230f41a6caf76f8f0/68747470733a2f2f7265706f6c6f67792e6f72672f62616467652f766572746963616c2d616c6c7265706f732f6675736566733a73736866732e737667" alt="Packaging status" data-canonical-src="https://repology.org/badge/vertical-allrepos/fusefs:sshfs.svg">
</a>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amiga Systems Programming in 2023 (107 pts)]]></title>
            <link>https://www.markround.com/blog/2023/08/30/amiga-systems-programming-in-2023/</link>
            <guid>37389376</guid>
            <pubDate>Tue, 05 Sep 2023 08:53:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.markround.com/blog/2023/08/30/amiga-systems-programming-in-2023/">https://www.markround.com/blog/2023/08/30/amiga-systems-programming-in-2023/</a>, See on <a href="https://news.ycombinator.com/item?id=37389376">Hacker News</a></p>
<div id="readability-page-1" class="page"><section itemprop="text">
        


        
        <p><a href="https://www.markround.com/assets/images/amiga/dev/amigaland.jpg"><picture><source srcset="https://www.markround.com/assets/generated/amiga/dev/amigaland-200-93d7ed270.webp 200w, https://www.markround.com/assets/generated/amiga/dev/amigaland-400-93d7ed270.webp 400w, https://www.markround.com/assets/generated/amiga/dev/amigaland-800-93d7ed270.webp 800w, https://www.markround.com/assets/generated/amiga/dev/amigaland-1600-93d7ed270.webp 1600w" type="image/webp"><source srcset="https://www.markround.com/assets/generated/amiga/dev/amigaland-200-347b2b614.jpg 200w, https://www.markround.com/assets/generated/amiga/dev/amigaland-400-347b2b614.jpg 400w, https://www.markround.com/assets/generated/amiga/dev/amigaland-800-347b2b614.jpg 800w, https://www.markround.com/assets/generated/amiga/dev/amigaland-1600-347b2b614.jpg 1600w" type="image/jpeg"><img src="https://www.markround.com/assets/generated/amiga/dev/amigaland-800-347b2b614.jpg"></picture></a></p>

<p>If you ever get a chance to look through the classic Amiga OS source-code still floating around some murky corners of the internet, it is a thing of beauty and astonishing capabilities. It’s an inspirational piece of computing history with unmatched capabilities for the time. Remember, this was all originally on a computer released in the 1980s with 512Kb memory, a 7Mhz 68000 16-bit CPU, and a single floppy drive with 880Kb storage. On these limited specs, AmigaOS provided a pre-emptive multi-tasking operating system, a full set of GUI primatives and built-in “Workbench” interface, expansion card auto-configuration and a fully-featured filesystem with some unique and powerful capabilities. Although to be fair, the AmigaDOS parts do literally come from a different time (and possibly planet) - but more on that later.</p>

<p>Oh and of course, there was that amazing <a href="https://en.wikipedia.org/wiki/Original_Chip_Set">chipset</a> that meant even that humble base can do things like <a href="https://www.youtube.com/watch?v=_wpXOsEm7M0" target="_blank">this</a> - while PCs of the time were basically  office boxes that occasionally bleeped and home computers still loaded games from cassette tape. There’s understandably a lot of on-line interest in those parts of the Amiga as they’re the most impressive in an obvious “wow!” way. But while that was what drew me to the Amiga when I was a kid (and the demo/cracking/bbs scene heavily influenced me) I’ve always been more of a systems geek at heart.</p>

<p>I’ve always loved building tools and platforms, and have long been fascinated with the world of operating systems. Apart from reading through the source code (where that’s legally available, of course…) I think there’s no better way to explore and understand a system - and the mindset that produced it - than to develop for it.</p>

<p>What follows is a brain-dump of what I’ve learned about developing for the AmigaOS, both on classic 68k-powered hardware to modern PowerPC systems like the <a href="https://www.markround.com/blog/2018/10/10/new-amiga-x5000/">X5000</a>. I’ll cover development environments, modern workflows like CI builds on containerised infrastructure, distribution of packages and even a look back in time before <code>C</code> existed, thanks to AmigaDOS’s odd heritage.</p>

<!-- TOC -->

<!-- END TOC -->

<h2 id="setcmd">SetCmd</h2>
<p><a href="https://www.markround.com/assets/images/amiga/dev/setcmd-window.png"><picture><source srcset="https://www.markround.com/assets/generated/amiga/dev/setcmd-window-200-023f759c5.webp 1.0x, https://www.markround.com/assets/generated/amiga/dev/setcmd-window-300.0-023f759c5.webp 1.5x, https://www.markround.com/assets/generated/amiga/dev/setcmd-window-400-023f759c5.webp 2.0x" type="image/webp"><source srcset="https://www.markround.com/assets/generated/amiga/dev/setcmd-window-200-372f18c0f.png 1.0x, https://www.markround.com/assets/generated/amiga/dev/setcmd-window-300.0-372f18c0f.png 1.5x, https://www.markround.com/assets/generated/amiga/dev/setcmd-window-400-372f18c0f.png 2.0x" type="image/png"><img src="https://www.markround.com/assets/generated/amiga/dev/setcmd-window-250-372f18c0f.png"></picture></a> 
There’s plenty of guides and videos on setting up an old-school game or demo-coding environment, but all of what follows is in the context of developing a systems tool in <code>C</code> as that’s the language of AmigaOS. I started a real-life <a href="https://www.markround.com/projects/#setcmd">project</a> partly to solve a small problem I had (switching between different versions of commands/tools at the Amiga CLI) but mainly to explore and dig deeper into the OS that influenced me so much as a teenager. <code>SetCmd</code> was the result, and is a very simple AmigaOS 4 PowerPC <a href="http://aminet.net/package/util/shell/setcmd">package</a>. I’m working (very slowly) on porting it to run on classic AmigaOS and variants but it has to be said this is my first time writing C in any meaningful capacity beyond wrestling with pointers at University. The source code is on <a href="https://github.com/markround/setcmd">GitHub</a> if you want to take a look but bear in mind despite having owned Amigas since they were released, I’m a total newbie at most of this! I wrote it to have fun, explore the AmigaOS, set up build environments and figure out how to package it up for re-distribution. I have <a href="https://www.markround.com/blog/categories/#amiga">written</a> a bit about my development setup in the past, but things have changed a fair bit since then - so without further ado, here’s my development environment and thoughts in 2023.</p>

<h2 id="sdk-updates">SDK Updates</h2>
<p>Whilst things do move at a glacial pace in the world of <a href="https://en.wikipedia.org/wiki/AmigaOS_4">AmigaOS 4/PPC</a>, there have been a few big updates. A-EON’s <a href="http://wiki.amiga.org/index.php?title=Enhancer_Software" target="_blank">Enhancer Software</a> has had several releases, each adding new applications and developer APIs. As well as shipping their own versions of key Amiga OS applications and utilities, they also now are installing several core AmigaDOS command replacements. I tend to skip the installation of these as I’ve encountered a few edge cases where they don’t <em>quite</em> behave like the original OS 4 commands, but from recent discussions online it appears as if they are preparing for their own “clean-room” re-implementation and modernisation of Amiga OS 4. Presumably in order to free themselves from the eternal legal shenanigans with Hyperion et al. I’m not going to get into that raging dumpster fire here, but it’ll be interesting to see what comes of this.</p>

<p><a href="https://www.markround.com/assets/images/amiga/dev/sdk-03.png"><picture><source srcset="https://www.markround.com/assets/generated/amiga/dev/sdk-03-200-579a9e856.webp 1.0x, https://www.markround.com/assets/generated/amiga/dev/sdk-03-300.0-579a9e856.webp 1.5x, https://www.markround.com/assets/generated/amiga/dev/sdk-03-400-579a9e856.webp 2.0x" type="image/webp"><source srcset="https://www.markround.com/assets/generated/amiga/dev/sdk-03-200-a5839a0e7.png 1.0x, https://www.markround.com/assets/generated/amiga/dev/sdk-03-300.0-a5839a0e7.png 1.5x, https://www.markround.com/assets/generated/amiga/dev/sdk-03-400-a5839a0e7.png 2.0x" type="image/png"><img src="https://www.markround.com/assets/generated/amiga/dev/sdk-03-250-a5839a0e7.png"></picture></a> 
On the Hyperion side, they released a big <a href="https://www.hyperion-entertainment.com/index.php/component/content/article/300-new-amigaos-41-sdk-5334-available-now" target="_blank">SDK Update</a> for OS 4 including updated GCC toolchains, cross-compilers, profilers and loads of updated SDKs. Bearing in mind the ancient GCC 4.x toolchain that had been in place for years it was great to have a more modern environment. On the classic Amiga front, Hyperion have also been pushing ahead with their updated AmigaOS 3.x OS for 68k-powered Amigas. Now on version 3.2.2.1 (I’ve got my boxed set of CD and <a href="https://www.markround.com/blog/2019/12/30/back-to-the-floppy/">floppy disks</a>) there have also been several NDK (“Native Developer Kit”) <a href="https://www.hyperion-entertainment.com/index.php/component/content/article/297-native-developer-kit-for-amigaos-32-ndk-32-release-3-available-for-immediate-download" target="_blank">Updates</a> providing updated APIs and tools. AmiKit also released a great “all-in-one” environment called <a href="https://www.amikit.amiga.sk/devpack">DevPack</a> which includes a huge range of languages (C, Assembly, Amos, Lua, Basic…) and NDKs all configured and ready to go. As a quick and easy way of setting up a development environment on classic Amigas, it’s hard to beat and saves a lot of manual downloading, configuring and glue-ing everything together.</p>

<h2 id="editors">Editors</h2>
<p>In my <a href="https://www.markround.com/blog/2019/08/06/my-os4-development-environment/">last update</a> 3 years ago, I’d more or-less settled on using a GUI VIM derivative. While I’m still a die-hard VIM user at $DAYJOB, I really appreciate the modern comforts of e.g. VSCode. Thanks to the amazing work of <a href="https://github.com/walkero-gr/">George Sokianos</a>, there is now a OS 4 <a href="http://os4depot.net/?function=showfile&amp;file=utility/text/edit/litexl.lha">package</a> of the awesome <a href="https://lite-xl.com/en/">Lite-XL</a> editor along with a comprehensive set of plugins. Here’s what a hacking session on my X5000 looks like:</p>

<p><a href="https://www.markround.com/assets/images/amiga/dev/setcmd.png"><picture><source srcset="https://www.markround.com/assets/generated/amiga/dev/setcmd-200-5dadd9ab5.webp 200w, https://www.markround.com/assets/generated/amiga/dev/setcmd-400-5dadd9ab5.webp 400w, https://www.markround.com/assets/generated/amiga/dev/setcmd-800-5dadd9ab5.webp 800w, https://www.markround.com/assets/generated/amiga/dev/setcmd-1600-5dadd9ab5.webp 1600w" type="image/webp"><source srcset="https://www.markround.com/assets/generated/amiga/dev/setcmd-200-9cc0c6e47.png 200w, https://www.markround.com/assets/generated/amiga/dev/setcmd-400-9cc0c6e47.png 400w, https://www.markround.com/assets/generated/amiga/dev/setcmd-800-9cc0c6e47.png 800w, https://www.markround.com/assets/generated/amiga/dev/setcmd-1600-9cc0c6e47.png 1600w" type="image/png"><img src="https://www.markround.com/assets/generated/amiga/dev/setcmd-800-9cc0c6e47.png"></picture></a></p>

<p>In that session you can see alongside LiteXL two terminal windows: I’m compiling <em>and</em> running the PowerPC and classic 68k versions of <code>setcmd</code> thanks to the cross-compilers and native “Petunia” JIT 68k emulation built into OS 4. More on that later, but while we’re talking about classic Amigas…</p>

<h2 id="native-hardware">Native hardware</h2>
<p>Emulation is fine, but nothing beats running on the actual hardware! In the <a href="https://www.markround.com/assets/images/amiga/dev/amigaland.jpg">lead image</a> to this article you can see my treasured <a href="https://www.markround.com/blog/2019/03/18/two-worlds-meet/">Amiga 1200</a> (with older 8-bit friend in the background running my <a href="https://tnfs.markround.com/">TNFS site</a>) expanded with an <a href="https://www.markround.com/blog/2020/07/21/apollo-vampire-amiga-1200-review/">Apollo Vampire</a> accelerator. An Ethernet or Wifi adapter is more or less essential though when it comes to transferring data around and fortunately the Vampire card is capable of network connectivity, high-resolution display and other niceities but can easily be switched back to a more “stock” environment. I do still occasionally use my licensed copy of <a href="https://www.softwareandcircuits.com/division/amiga/products/cubic/screenshots.html">CubicIDE</a> but due to the age of this architecture, I tend to keep my tools light and have settled on the simple <a href="http://aminet.net/package/text/edit/JanoEditor">Jano</a> editor or sometimes <a href="http://www.cygnused.de/index-en.php">CygnusEd</a> for old time’s sake.</p>

<p>My build toolchain is provided by Devpack and it’s included <a href="http://sun.hasenbraten.de/vbcc/">VBCC</a> compiler. I use the <code>vbcc_target_m68k-amigaos</code> target with this <a href="https://github.com/markround/setcmd/blob/68k/src.68k/makefile">makefile</a> to build:</p>

<p><a href="https://www.markround.com/assets/images/amiga/dev/setcmd-a1200.png"><picture><source srcset="https://www.markround.com/assets/generated/amiga/dev/setcmd-a1200-200-df241286b.webp 200w, https://www.markround.com/assets/generated/amiga/dev/setcmd-a1200-400-df241286b.webp 400w, https://www.markround.com/assets/generated/amiga/dev/setcmd-a1200-800-df241286b.webp 800w, https://www.markround.com/assets/generated/amiga/dev/setcmd-a1200-1024-df241286b.webp 1024w" type="image/webp"><source srcset="https://www.markround.com/assets/generated/amiga/dev/setcmd-a1200-200-c80f8e9b4.png 200w, https://www.markround.com/assets/generated/amiga/dev/setcmd-a1200-400-c80f8e9b4.png 400w, https://www.markround.com/assets/generated/amiga/dev/setcmd-a1200-800-c80f8e9b4.png 800w, https://www.markround.com/assets/generated/amiga/dev/setcmd-a1200-1024-c80f8e9b4.png 1024w" type="image/png"><img src="https://www.markround.com/assets/generated/amiga/dev/setcmd-a1200-800-c80f8e9b4.png"></picture></a></p>

<h2 id="modern-development">Modern development</h2>
<p>I’m (sadly) not always in front of my Amigas, but these days a modern laptop and cloud-native tools offer a lot of flexibility particularly with the advanced state of emulation. I use VSCode as my editor, and a containerised cross-compiler toolchain built by - again! - George Sokianos to target both 68k and PPC platforms. I can build my project on any system capable of running OCI containers, e.g.</p>

<div><pre><code>docker run <span>\</span>
  <span>--user</span> <span>$UID</span>:<span>$GID</span> <span>\</span>
  <span>-v</span> ./:/opt/code <span>\</span>
  walkero/docker4amigavbcc:latest-m68k-amd64 <span>\</span>
  make <span>-f</span> makefile.docker
</code></pre></div>

<p>Testing and running the code is made easy by the very advanced state of emulators. On Windows, <a href="https://www.winuae.net/">WinUAE</a> is the gold standard and can emulate everything from an original 1985-vintage A1000 up to modern systems with PowerPC accelerators, graphics cards and other devices. I have it multi-booting into clean Hyperion and Commodore/classic OS environments, with my source code directory shared as a virtual hard-drive:</p>

<p><a href="https://www.markround.com/assets/images/amiga/dev/laptop.png"><picture><source srcset="https://www.markround.com/assets/generated/amiga/dev/laptop-200-f0e9958be.webp 200w, https://www.markround.com/assets/generated/amiga/dev/laptop-400-f0e9958be.webp 400w, https://www.markround.com/assets/generated/amiga/dev/laptop-800-f0e9958be.webp 800w, https://www.markround.com/assets/generated/amiga/dev/laptop-1600-f0e9958be.webp 1600w" type="image/webp"><source srcset="https://www.markround.com/assets/generated/amiga/dev/laptop-200-7b38685a9.png 200w, https://www.markround.com/assets/generated/amiga/dev/laptop-400-7b38685a9.png 400w, https://www.markround.com/assets/generated/amiga/dev/laptop-800-7b38685a9.png 800w, https://www.markround.com/assets/generated/amiga/dev/laptop-1600-7b38685a9.png 1600w" type="image/png"><img src="https://www.markround.com/assets/generated/amiga/dev/laptop-800-7b38685a9.png"></picture></a></p>

<p>I can compile in seconds with Docker, and then straight away test the resulting binary in my emulated Amiga. Source-code is kept up to date between systems using Git; on the Amiga X5000 I use the port of SimpleGit, which is now bundled with the latest Hyperion SDK under <code>SDK:c/sgit</code>. I haven’t yet found a suitable Git solution for the classic Amigas, so on those I use a makeshift AmigaDOS shell script that uses <a href="http://www.onyxsoft.se/backup.html">Backup</a> to copy files over to a network mount in an <code>rsync</code> -like fashion.</p>

<p>I also keep meaning to test running AmigaOS 4.1 under <a href="https://www.amiga-news.de/en/news/AN-2023-03-00113-EN.html">QEMU</a> as support for this has greatly improved and looks a lot simpler than the currently convoluted process of getting “classic OS 4” running on an emulated 68k Amiga with PPC accelerator configured. But for now, the WinUAE approach is working pretty well.</p>

<p>Another advantage of having a containerised build-chain is that combined with Git and <a href="https://drone.io/">Drone</a> running on my personal Kubernetes clusters, I can build and package my code with a simple <code>git push</code> wherever I am:</p>

<p><a href="https://www.markround.com/assets/images/amiga/dev/drone.png"><picture><source srcset="https://www.markround.com/assets/generated/amiga/dev/drone-200-c8bffc6c3.webp 200w, https://www.markround.com/assets/generated/amiga/dev/drone-400-c8bffc6c3.webp 400w, https://www.markround.com/assets/generated/amiga/dev/drone-800-c8bffc6c3.webp 800w, https://www.markround.com/assets/generated/amiga/dev/drone-1600-c8bffc6c3.webp 1600w" type="image/webp"><source srcset="https://www.markround.com/assets/generated/amiga/dev/drone-200-a1132c150.png 200w, https://www.markround.com/assets/generated/amiga/dev/drone-400-a1132c150.png 400w, https://www.markround.com/assets/generated/amiga/dev/drone-800-a1132c150.png 800w, https://www.markround.com/assets/generated/amiga/dev/drone-1600-a1132c150.png 1600w" type="image/png"><img src="https://www.markround.com/assets/generated/amiga/dev/drone-800-a1132c150.png"></picture></a></p>

<h2 id="amigados-is-weird">AmigaDOS is weird</h2>
<p>Although AmigaOS is frequently lauded for it’s sophistication and elegance, there is a notable “oddness” about the AmigaDOS components which handle storage I/O, devices and filesystems. The original developers of the Amiga had an ambitious DOS system planned, but in the end Commodore had to purchase the <a href="https://en.wikipedia.org/wiki/TRIPOS">Tripos</a> operating system and port parts of it to the Amiga due to deadline challenges. This mismatch is all the more pronounced as Tripos was written in <a href="https://en.wikipedia.org/wiki/BCPL">BCPL</a> - which in turn, influenced the <code>B</code> programming language which begat the <code>C</code> we all know and… well, tolerate, in my case. So it really is looking back into computing history and remnants of this still remain even in the “modern” AmigaOS 4.x and other derivatives.</p>

<p>Once you start diving into AmigaDOS code, you end up face-to-face with this legacy and need to convert back and forth with BCPL and C data-types. For example, BCPL strings are not <code>NULL</code>-terminated, instead they have a length in the first byte and then the characters follow. And pointers are similarly alien. This is why my code has stuff like this littered through it:</p>

<div><pre><code>    <span>// Convert the new node to a BPTR</span>
    <span>new_node_bptr</span> <span>=</span> <span>MKBADDR</span><span>(</span><span>new_node</span><span>);</span>

    <span>// Set the new path</span>
    <span>cli</span><span>-&gt;</span><span>cli_CommandDir</span> <span>=</span> <span>new_node_bptr</span><span>;</span>
</code></pre></div>

<p>As the NDK include file <code>dos.h</code> explains: “All BCPL data must be long word aligned.  BCPL pointers are the long word address (i.e byte address divided by 4 (»2))”. It also includes helper functions like <code>MKBADDR</code> to help with the conversion as most DOS system calls use BCPL pointers in arguments:</p>

<div><pre><code><span>/* Convert BPTR to typical C pointer */</span>
<span>#define BADDR(x)	((APTR)((ULONG)(x) &lt;&lt; 2))
</span><span>/* Convert address into a BPTR */</span>
<span>#define MKBADDR(x)	(((LONG)(x)) &gt;&gt; 2)
</span></code></pre></div>

<p>All in all, a fascinating look back into an obscure branch of computing history, but it hasn’t furthered my appreciation of pointers any!</p>

<h2 id="distribution">Distribution</h2>
<p><a href="https://www.markround.com/assets/images/amiga/dev/dist.png"><picture><source srcset="https://www.markround.com/assets/generated/amiga/dev/dist-200-87c52ef2f.webp 200w, https://www.markround.com/assets/generated/amiga/dev/dist-400-87c52ef2f.webp 400w, https://www.markround.com/assets/generated/amiga/dev/dist-800-87c52ef2f.webp 800w, https://www.markround.com/assets/generated/amiga/dev/dist-1308-87c52ef2f.webp 1308w" type="image/webp"><source srcset="https://www.markround.com/assets/generated/amiga/dev/dist-200-b29548dae.png 200w, https://www.markround.com/assets/generated/amiga/dev/dist-400-b29548dae.png 400w, https://www.markround.com/assets/generated/amiga/dev/dist-800-b29548dae.png 800w, https://www.markround.com/assets/generated/amiga/dev/dist-1308-b29548dae.png 1308w" type="image/png"><img src="https://www.markround.com/assets/generated/amiga/dev/dist-800-b29548dae.png"></picture></a></p>

<p>If you want to distribute your project to a wider audience, there’s a few Amiga-specific things you can do that makes life much easier for people running AmigaOS. These all make use of some pretty cool bits of Amiga technology and have been widely adopted by native software since their introduction in the early 1990s.</p>

<h3 id="archive">Archive</h3>
<p>Just use LHA format archives. It’s the standard compression tool on Amigas and even though there are modern (and technically better) alternatives, <code>.lha</code> files are as ubiquitous as e.g. <code>.zip</code> or <code>.tar.gz</code> packages on other systems and can also be handled by low-spec machines. There are ports of CLI tools and GUIs available on all platforms to handle these archives and while the syntax can be a little different, it’s quite easy to use. See my <a href="https://github.com/markround/setcmd/blob/68k/packaging/make_lha">AmigaDOS script</a> that builds the SetCmd release artifact for a practical example.</p>

<h3 id="documentation">Documentation</h3>
<p>Along with a basic README.txt, it’s a great practice to distribute more detailed documentation in <a href="https://wiki.amigaos.net/wiki/AmigaGuide_101">AmigaGuide</a> format. Another area the Amiga was way ahead of it’s time - AmigaGuide is a hyper-text format commonly used for application manuals although people have even used it to publish <a href="http://www.whatiff.info/">disk magazines</a>! Introduced in 1992, the bundled tools on any AmigaOS (or clone/derivative) can read and use AmigaGuide as standard so you can include formatting, links and other content in your documentation. You can see the AmigaGuide docs I include with SetCmd in the screenshot above, or view the <a href="https://github.com/markround/setcmd/blob/68k/SetCmd.guide">source</a> to see what the syntax looks like.</p>

<p>It’s pretty simple to write and is much like any other markdown or formatting code. You can set basic parameters:</p>

<figure><pre><code data-lang="text"><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>@Width 72
@wordwrap
</pre></td></tr></tbody></table></code></pre></figure>

<p>Documents have “Nodes” which can be linked to, e.g.</p>

<figure><pre><code data-lang="text"><table><tbody><tr><td><pre>1
2
</pre></td><td><pre>@Node About "About SetCMD" 
@{"About" Link About}
</pre></td></tr></tbody></table></code></pre></figure>

<p>And formatting is much like HTML with opening and closing tags:</p>

<figure><pre><code data-lang="text">@{b}@{u} Bold and Underlined! @{uu}@{ub}</code></pre></figure>

<h3 id="installer">Installer</h3>
<p><a href="https://www.markround.com/assets/images/amiga/setcmd/setcmd-install-dev02.png"><picture><source srcset="https://www.markround.com/assets/generated/amiga/setcmd/setcmd-install-dev02-200-7c58ead12.webp 1.0x, https://www.markround.com/assets/generated/amiga/setcmd/setcmd-install-dev02-300.0-7c58ead12.webp 1.5x, https://www.markround.com/assets/generated/amiga/setcmd/setcmd-install-dev02-400-7c58ead12.webp 2.0x" type="image/webp"><source srcset="https://www.markround.com/assets/generated/amiga/setcmd/setcmd-install-dev02-200-ca320d46f.png 1.0x, https://www.markround.com/assets/generated/amiga/setcmd/setcmd-install-dev02-300.0-ca320d46f.png 1.5x, https://www.markround.com/assets/generated/amiga/setcmd/setcmd-install-dev02-400-ca320d46f.png 2.0x" type="image/png"><img src="https://www.markround.com/assets/generated/amiga/setcmd/setcmd-install-dev02-250-ca320d46f.png"></picture></a></p>

<p>A fantastic addition to AmigaOS, the system installer utility reads a developer-provided script which handles copying files, comparing versions, modifying system scripts and so on, in a standardized fashion. You can pass useful information and configuration which controls the Installer tool through standard Amiga tooltypes, and it uses a sort of LISP-ey syntax which again runs on all Amigas and derivatives. The syntax does some getting used to, but the best source of documentation is the AmigaGuide documentation found in the <a href="http://aminet.net/package/util/misc/Installer-43_3">Installer dev package</a>. As an example, here’s an excerpt of the block of code which copies the <code>setcmd</code> program file over to a previously created directory:</p>

<figure><pre><code data-lang="lisp"><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
</pre></td><td><pre><span>(</span><span>copyfiles</span>
  <span>(</span><span>source</span> <span>"setcmd"</span><span>)</span>
  <span>(</span><span>dest</span> <span>#</span><span>dname</span><span>)</span>
  <span>(</span><span>prompt</span> <span>(</span><span>"Copy SetCmd program file?"</span><span>))</span>
  <span>(</span><span>confirm</span> <span>"expert"</span><span>)</span>
  <span>(</span><span>all</span><span>)</span>
  <span>(</span><span>help</span> <span>@copyfiles-help</span><span>)</span>
<span>)</span>
</pre></td></tr></tbody></table></code></pre></figure>

<p>And for running commands, you can use the <code>run</code> command, along with <code>cat</code> (short for “concatenate”) to build up the command string :</p>

<div><pre><code><span>(</span><span>run</span> <span>(</span><span>cat</span> <span>"C:MakeLink FROM "</span> <span>#</span><span>dname</span> <span>"/cmds/setcmd/release TO SETCMD:setcmd SOFT"</span><span>))</span>
</code></pre></div>

<p>I found the best approach was to examine other Installer scripts to get a feel for common practices and idioms. Here’s my simplistic <a href="https://github.com/markround/setcmd/blob/68k/Install_SetCmd">Install_SetCmd</a> script, and if you want to see something more complex, there’s always the AmigaOS installation scripts, or the <a href="https://sourceforge.net/projects/qtamigaosnative/files/release/">Qt installer</a> for OS 4 which taught me a lot.</p>

<h3 id="file-sites">File Sites</h3>
<p>The Amiga doesn’t have a universal package manager, so files are usually downloaded manually and installed from the <code>.lha</code> archives. The go-to place for Amiga software for all systems is <a href="https://aminet.net/">AmiNet</a>. It’s the biggest repository of Amiga packages on the internet (and, at one point in the mid-90s was actually the largest software repository of any platform) and now also supports hosting packages for Amiga OS 4, MorphOS and AROS alongside classic 68k fare. There are also smaller, platform-focused sites for each platform e.g. <a href="http://os4depot.net/">os4depot.net</a> for OS 4, <a href="https://www.morphos-storage.net/">morphos-storage.net</a> for MorphOS and so on.</p>

<p>Getting your package uploaded and accepted into the repository is broadly the same for all these: You FTP your package up according to the naming standards, and supply a <code>Readme</code> file which provides the <a href="http://wiki.aminet.net/index.php/The_Readme_file">required metadata</a> like this excerpt in AmiNet format:</p>

<figure><pre><code data-lang="yaml"><table><tbody><tr><td><pre>1
2
3
4
5
6
</pre></td><td><pre><span>Short</span><span>:</span>        <span>Switch between versions of software</span>
<span>Author</span><span>:</span>       <span><a href="https://www.markround.com/cdn-cgi/l/email-protection" data-cfemail="22434f4b4543624f435049504d574c460c414d4f">[email&nbsp;protected]</a> (Mark Dastmalchi-Round)</span>
<span>Type</span><span>:</span>         <span>util/shell</span>
<span>Version</span><span>:</span>      <span>1.1.0</span>
<span>Architecture</span><span>:</span> <span>ppc-amigaos &gt;= 4.0.0</span>
<span>Distribution</span><span>:</span> <span>Aminet</span>
</pre></td></tr></tbody></table></code></pre></figure>

<p>There are some Amiga-native GUI tools that assist with creating these files, but the specs e.g. for <a href="http://os4depot.net/?function=ftpinfo">os4depot.net</a> are pretty straight forward. And here’s the end result - My package available on <a href="http://os4depot.net/?function=showfile&amp;file=utility/shell/setcmd.lha">os4depot.net</a> and <a href="http://aminet.net/package/util/shell/setcmd">aminet</a>.</p>

<h2 id="external-documentation">External Documentation</h2>
<p><a href="https://www.markround.com/assets/images/amiga/dev/docs.png"><picture><source srcset="https://www.markround.com/assets/generated/amiga/dev/docs-200-d61bd6578.webp 200w, https://www.markround.com/assets/generated/amiga/dev/docs-400-d61bd6578.webp 400w, https://www.markround.com/assets/generated/amiga/dev/docs-800-d61bd6578.webp 800w, https://www.markround.com/assets/generated/amiga/dev/docs-1441-d61bd6578.webp 1441w" type="image/webp"><source srcset="https://www.markround.com/assets/generated/amiga/dev/docs-200-9c380033f.png 200w, https://www.markround.com/assets/generated/amiga/dev/docs-400-9c380033f.png 400w, https://www.markround.com/assets/generated/amiga/dev/docs-800-9c380033f.png 800w, https://www.markround.com/assets/generated/amiga/dev/docs-1441-9c380033f.png 1441w" type="image/png"><img src="https://www.markround.com/assets/generated/amiga/dev/docs-800-9c380033f.png"></picture></a>
When trying to learn or re-learn everything from C to AmigaDOS scripting, I found a few great resources. However, as with most things in Amiga-land, there’s an extraordinarily high “bus factor” for many websites and my biggest recommendation is to use native tools or save local copies of anything you find! With that said, here’s my essential Amiga bookmarks:</p>

<ul>
  <li>
    <p>Autodocs references. There’s lots of websites where you can browse the auto-generated docs from the SDK header files, like <a href="http://amigadev.elowar.com/">this</a> with clickable links to jump between things. If I’m actually at an Amiga though, there are some useful native tools I prefer that can index and search through the local headers. The screenshot above shows the standard “AutoDoc Reader” freeware tool viewing the equivalent of a <code>man</code> page for the AmigaDOS library, alongside the AmigaGuide Installer language reference.</p>
  </li>
  <li>
    <p><a href="http://www.pjhutchison.org/tutorial/amiga_c.html">http://www.pjhutchison.org/tutorial/amiga_c.html</a> - amazing site. This is what inspired me to pick up a compiler again and get to work. There’s a great refresher on the C language itself, and then it dives into Amiga-specific coding with everything from low-level library access, sound and GUI programming and more.</p>
  </li>
  <li><a href="https://wiki.amigaos.net/wiki/DeveloperDoc:Main">Amiga OS Dev wiki</a> is a goldmine, although it can take a little searching to find what you’re after. It’s mostly OS 4-focused but because all Amiga systems share a common ancestor it’s usually pretty applicable to all platforms. Specific articles that I found useful include:
    <ul>
      <li><a href="https://wiki.amigaos.net/wiki/Migration_Guide">OS 4 Migration Guide</a></li>
      <li><a href="https://wiki.amigaos.net/wiki/Programming_in_the_Amiga_Environment">Programming in the Amiga Environment</a></li>
      <li><a href="https://wiki.amigaos.net/wiki/Fundamental_Types">Fundamental Types</a></li>
    </ul>
  </li>
  <li>And lastly, there are great threads I constantly found on <a href="https://www.amigans.net/">amigans.net</a> which is where a lot of OS 4/”Next Gen” technical discussion happens. For classic systems, I found the Coders discussions on the <a href="https://eab.abime.net/forumdisplay.php?f=116">English Amiga Board</a> an invaluable resource.</li>
</ul>

<h2 id="the-way-forward-is-back-">The way forward is back ?</h2>
<p><a href="https://www.markround.com/assets/images/amiga/dev/morphos.png"><picture><source srcset="https://www.markround.com/assets/generated/amiga/dev/morphos-200-e475fa26b.webp 1.0x, https://www.markround.com/assets/generated/amiga/dev/morphos-300.0-e475fa26b.webp 1.5x, https://www.markround.com/assets/generated/amiga/dev/morphos-400-e475fa26b.webp 2.0x" type="image/webp"><source srcset="https://www.markround.com/assets/generated/amiga/dev/morphos-200-794486915.png 1.0x, https://www.markround.com/assets/generated/amiga/dev/morphos-300.0-794486915.png 1.5x, https://www.markround.com/assets/generated/amiga/dev/morphos-400-794486915.png 2.0x" type="image/png"><img src="https://www.markround.com/assets/generated/amiga/dev/morphos-250-794486915.png"></picture></a></p>

<p>When I started this project, it was really a way to get acquainted with my new X5000. Since then, I’ve decided to port my codebase back to the classic Amiga, as well as explore porting over to other Amiga-like systems such as <a href="https://www.morphos-team.net/">MorphOS</a> and <a href="https://en.wikipedia.org/wiki/AROS_Research_Operating_System">AROS</a>. This leads to some choices: From a packaging and distribution point of view, a 68k binary is pretty much the universal standard in Amiga land. It can run natively on classic Amigas, and modern systems like AmigaOS 4.x and MorphOS can run 68k binaries through translation. In a method similar to how Apple has handled the transition between processors in the Mac, it’s a pretty seamless experience and I run a lot of classic 68k software on my X5000. As long as you aren’t “banging on the metal” it works really well and <a href="https://www.markround.com/blog/2018/10/30/classic-amiga-emulation-on-the-x5000/#classic-68k-binaries">integrates smoothly</a> with the rest of the system.</p>

<p>The original 68k AmigaOS from Commodore is also pretty much the standard for source-code compatibility; code targetting this release can be built on most of the derivatives and later systems with very little (if any) modification. On AmigaOS 4 for example, you can simply add <code>-D__USE_INLINE__</code> to your makefiles and in theory build from a common codebase. If you start the other way as I did and write initially targetting AmigaOS 4, it’s harder to port to other systems.</p>

<p>For example, I originally followed the AmigaOS 4 programming style which favours prefixing library calls with interface names. This isn’t compatible with any other system, so the easiest way to port this to more Amiga-like platforms is to refactor this code back to the classic style of calling system functions. I do plan on building platform-specific binaries using <code>#defines</code> so I can for example use functions like <code>dos.library/AddCmdPathNode</code> on OS 4 that I otherwise have to manually implement, and while a lot of higher-level layers (like e.g. MUI for building graphical applications) are shared across platforms this is probably the best bet for adding specific features from one platform that aren’t available on others.</p>

<p>Honestly though, at this point if you want to just get started I’d have to suggest you target classic AmigaOS compatibility and build a 68k binary. I’d personally target AmigaOS 3.x or 2.1 if you want to support a wider range of truly vintage systems; 1.x is facinating from a retro-geek perspective but lacks a lot of the nice features that came with later systems. Everything else like the installer, archive format, documentation format and so on is cross-platform anyway and supported from OS 2.1 and up.</p>

<p>MorphOS, AROS and OS 4 are really fun systems to explore, and I highly recommend checking them out if this article has whetted your appetite (and you can find a system to run them on!) but classic is the easiest way to get your code out to the wider world and ironically provides a better code-base for future porting than my “working backwards” approach.</p>

<h2 id="wrap-up">Wrap-up</h2>
<p><a href="https://www.markround.com/assets/images/amiga/dev/blog.png"><picture><source srcset="https://www.markround.com/assets/generated/amiga/dev/blog-200-b74f68cd8.webp 200w, https://www.markround.com/assets/generated/amiga/dev/blog-400-b74f68cd8.webp 400w, https://www.markround.com/assets/generated/amiga/dev/blog-800-b74f68cd8.webp 800w, https://www.markround.com/assets/generated/amiga/dev/blog-1600-b74f68cd8.webp 1600w" type="image/webp"><source srcset="https://www.markround.com/assets/generated/amiga/dev/blog-200-93cedf6c3.png 200w, https://www.markround.com/assets/generated/amiga/dev/blog-400-93cedf6c3.png 400w, https://www.markround.com/assets/generated/amiga/dev/blog-800-93cedf6c3.png 800w, https://www.markround.com/assets/generated/amiga/dev/blog-1600-93cedf6c3.png 1600w" type="image/png"><img src="https://www.markround.com/assets/generated/amiga/dev/blog-800-93cedf6c3.png"></picture></a>
So that’s about the sum total of what I’ve picked up over the last few years, anyway! I still enjoy working on my Amigas when I get some “hacking on code in the evening” time, and in particular I find AmigaOS 4 on my X5000 a refreshing blend of retro appeal and just about enough modern convenience to use it for development tasks, or even for writing this article itself. My A1200 continues to impress me with how much utility there is in such a small box and is a wonderful distraction from the modern era of bloated systems and applications. It is perhaps an evolutionary dead-end, but it’s still a lot of fun and is one of the rare occasions these days where I feel actually in control of <em>my</em> computer. Working backwards in time from OS 4.1 to my classic Amigas has also really given me a greater insight and appreciation for what the Amiga engineers managed to pull off back then. If you’re in any way interested in computer history - or simply want to give something truly different a try - you should definitely check out AmigaOS. I hope this quick <code>type BRAIN: &gt; WEB:</code> dump provides you with some good starting points, and maybe gets you coding too!</p>

        
      </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ZFS for Dummies (330 pts)]]></title>
            <link>https://ikrima.dev/dev-notes/homelab/zfs-for-dummies/</link>
            <guid>37387392</guid>
            <pubDate>Tue, 05 Sep 2023 03:07:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ikrima.dev/dev-notes/homelab/zfs-for-dummies/">https://ikrima.dev/dev-notes/homelab/zfs-for-dummies/</a>, See on <a href="https://news.ycombinator.com/item?id=37387392">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-md-component="main">
              <article>
                
                  

  
    <a href="https://github.com/ikrima/gamedevguide/blob/master/docs/dev-notes/homelab/zfs-for-dummies.md" title="Edit this page">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4v-2m10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1 2.1 2.1Z"></path></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/ikrima/gamedevguide/raw/master/docs/dev-notes/homelab/zfs-for-dummies.md" title="View source of this page">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.15 8.15 0 0 1-1.23-2Z"></path></svg>
    </a>
  



<p>As mentioned on previous posts, I have spent the past few weeks dealing with a ZFS crash on my FreeNAS install. Because of that, not only was I forced to learn how to troubleshoot ZFS, but I also had to learn how to setup new volumes and come up with new backup strategies (between a few other things).</p>
<p>This was a great opportunity for me to learn more about ZFS (because I new ‘nada’ to start with). And I’m happy to share some of the knowledge that I gathered with you on this post.</p>
<p>Please keep in mind that I don’t consider myself an expert on ZFS (not even close), but I will try to make things simple and easy to understand for someone, who like me, is just getting started with ZFS.</p>
<h2 id="about-zfs">About ZFS<a href="#about-zfs" title="Permanent link">#</a></h2>
<h4 id="what-is-zfs-and-its-history">What is ZFS and It’s History<a href="#what-is-zfs-and-its-history" title="Permanent link">#</a></h4>
<p>ZFS is a local filesystem (i.e.: ext4, NTFS, exfat) and logical volume manager (i.e.: LVM on Linux) created by Sun Microsystems. ZFS was published under an open source license until Oracle bought Sun Microsystems and closed source the license. Because the source code was already in the open and ported to different OSs, eventually a project called ‘OpenZFS’ was created, and that is the core code that is used on most Unix like systems today (Linux, FreeBSD, etc.).</p>
<h3 id="zfs-components">ZFS Components<a href="#zfs-components" title="Permanent link">#</a></h3>
<p><a href="https://ikrima.dev/dev-notes/_assets/homelab/zfs-for-dummies/zfs-components.png" data-type="image" data-width="100%" data-height="auto" data-desc-position="bottom"><img alt="" src="https://ikrima.dev/dev-notes/_assets/homelab/zfs-for-dummies/zfs-components.png"></a></p>
<h4 id="vdev">vdev<a href="#vdev" title="Permanent link">#</a></h4>
<p>A vdev is composed of one or more physical drives (can also be of things other than hard drive, like files). They can be combined together in mirrors or RAIDZs.</p>
<p><a href="https://ikrima.dev/dev-notes/_assets/homelab/zfs-for-dummies/vdev.png" data-type="image" data-width="100%" data-height="auto" data-desc-position="bottom"><img alt="" src="https://ikrima.dev/dev-notes/_assets/homelab/zfs-for-dummies/vdev.png"></a></p>
<p>💡 <em><strong>TIP:</strong> There are 7 different types of vdevs, and some of them (like host spare, L2ARC and ZIL) are very important.</em></p>
<h4 id="pool">Pool<a href="#pool" title="Permanent link">#</a></h4>
<p>A pool is composed of one or more vdevs and they usually contain a volume or a dataset (which you create after creating the pool). You create/define your vdevs when you create a pool (with the <code>zpool</code> command which we’ll see later). This allows you to mix vdev types together to achieve other RAIDZ levels (see example below):</p>
<p><a href="https://ikrima.dev/dev-notes/_assets/homelab/zfs-for-dummies/raid10.png" data-type="image" data-width="100%" data-height="auto" data-desc-position="bottom"><img alt="" src="https://ikrima.dev/dev-notes/_assets/homelab/zfs-for-dummies/raid10.png"></a></p>
<h4 id="datasets">Datasets<a href="#datasets" title="Permanent link">#</a></h4>
<p>Dataset is the filesystem part of ZFS (so far we’ve seen the LVM components). Here you can define user access, quotas, compression, snapshots, etc…</p>
<h4 id="volume">Volume<a href="#volume" title="Permanent link">#</a></h4>
<p>Volume is the brother of datasets but in a block device representation. It provides some of the features that datasets have, but not all. Volumes can be useful to run other filesystems on top of ZFS, or to export iSCSI extents.</p>
<h3 id="raidz-types">RAIDZ Types<a href="#raidz-types" title="Permanent link">#</a></h3>
<ul>
<li>Dynamic/Simple Stripe (RAID0) - Distributes data without parity. Loosing a device means loosing all data</li>
<li>MIRROR (RAID1) - Mirrored drives. Used with 2 to 4 disks (or more)</li>
<li>RAIDZ-1 (RAID5) - Distributes parity along with the data and can lose one physical drive before a raid failure. RAIDZ requires at least 3 disks</li>
<li>RAIDZ-2 (RAID6) - Distributes parity along with the data and can lose up to 2 physical drives. RAIDZ-2 requires at least 4 disks</li>
<li>RAIDZ-3 - Distributes parity along with the data and can lose up to 3 physical drives. RAIDZ-3 requires at least 4, but should be used with no less than 5 disks</li>
</ul>
<p><a href="https://ikrima.dev/dev-notes/_assets/homelab/zfs-for-dummies/raidz-comparisson.png" data-type="image" data-width="100%" data-height="auto" data-desc-position="bottom"><img alt="" src="https://ikrima.dev/dev-notes/_assets/homelab/zfs-for-dummies/raidz-comparisson.png"></a></p>
<hr>
<h2 id="commands">Commands<a href="#commands" title="Permanent link">#</a></h2>
<p>Let’s take a look at the most common commands for handling ZFS pools and filesystem. We’ll use <code>/dev/sdx</code> to refer to device names, but keep in mind that using the device UUID is preferred in order to avoid boot issues due to device name changes.</p>
<h3 id="1zfs-pool-commands">1.ZFS Pool Commands<a href="#1zfs-pool-commands" title="Permanent link">#</a></h3>
<p>These are the commands related to creating vdevs and pools. We will be looking at:</p>
<ul>
<li><code>zpool create</code> - Create a pool (and vdevs)</li>
<li><code>zpool status</code> - Displays pool status</li>
<li><code>zpool list</code> - List pool and it’s details</li>
<li><code>zpool history</code> - Shows history of commands for zpool</li>
<li><code>zpool import</code>- Imports and mounts pool</li>
<li><code>zpool export</code> - Exports and unmounts pool</li>
<li><code>zpool destroy</code> - Destroy pool and all filesystems</li>
<li><code>zpool scrub</code> - Starts scrub of pool</li>
</ul>
<h4 id="11creating-a-pool-and-vdevs">1.1.Creating a Pool (and vdevs)<a href="#11creating-a-pool-and-vdevs" title="Permanent link">#</a></h4>
<p>To create a new pool we use the <code>zpool create</code> command. We specify the pool name and the device we want to use.</p>
<p>It’s basic usage is:</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-0-1"><span data-linenos="1 "></span># zpool create [pool] [devices]
</span></code></pre></div>
<p>Now let’s look at different examples for this command.</p>
<h5 id="create-a-pool-on-a-single-disk"><strong>Create a pool on a single disk</strong><a href="#create-a-pool-on-a-single-disk" title="Permanent link">#</a></h5>
<p>The command below creates a pool on a single disk.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-1-1"><span data-linenos="1 "></span># zpool create tank /dev/sdb  
</span></code></pre></div>
<h5 id="create-a-dynamic-stripe-pool-on-3-disks"><strong>Create a dynamic stripe pool on 3 disks</strong><a href="#create-a-dynamic-stripe-pool-on-3-disks" title="Permanent link">#</a></h5>
<p>Remember that dynamic stripe is the same as RAID0 and that it has no parity.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-2-1"><span data-linenos="1 "></span># zpool create tank /dev/sdb /dev/sdc /dev/sdd
</span></code></pre></div>
<p>We can view the new pool with <code>zpool status</code></p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-3-1"><span data-linenos=" 1 "></span>root@ubuntu-vm:~# zpool status
</span><span id="__span-3-2"><span data-linenos=" 2 "></span>  pool: tank
</span><span id="__span-3-3"><span data-linenos=" 3 "></span> state: ONLINE
</span><span id="__span-3-4"><span data-linenos=" 4 "></span>  scan: none requested
</span><span id="__span-3-5"><span data-linenos=" 5 "></span>config:
</span><span id="__span-3-6"><span data-linenos=" 6 "></span>
</span><span id="__span-3-7"><span data-linenos=" 7 "></span>NAME        STATE     READ WRITE CKSUM
</span><span id="__span-3-8"><span data-linenos=" 8 "></span>tank        ONLINE       0     0     0
</span><span id="__span-3-9"><span data-linenos=" 9 "></span>  sdb       ONLINE       0     0     0
</span><span id="__span-3-10"><span data-linenos="10 "></span>  sdc       ONLINE       0     0     0
</span><span id="__span-3-11"><span data-linenos="11 "></span>  sdd       ONLINE       0     0     0
</span><span id="__span-3-12"><span data-linenos="12 "></span>
</span><span id="__span-3-13"><span data-linenos="13 "></span>errors: No known data errors
</span></code></pre></div>
<p>Note that the pool name is ‘tank’ and the vdevs are ‘sdb’, ‘sdc’ and ‘sdd’</p>
<h5 id="create-a-mirrorred-pool-on-2-disks"><strong>Create a mirrorred pool on 2 disks</strong><a href="#create-a-mirrorred-pool-on-2-disks" title="Permanent link">#</a></h5>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-4-1"><span data-linenos="1 "></span># zpool create tank mirror sdb sdc
</span></code></pre></div>
<p>Note that I can omit <code>/dev</code> and give the device name. Let’s view the result.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-5-1"><span data-linenos=" 1 "></span># zpool status
</span><span id="__span-5-2"><span data-linenos=" 2 "></span>  pool: tank
</span><span id="__span-5-3"><span data-linenos=" 3 "></span> state: ONLINE
</span><span id="__span-5-4"><span data-linenos=" 4 "></span>  scan: none requested
</span><span id="__span-5-5"><span data-linenos=" 5 "></span>config:
</span><span id="__span-5-6"><span data-linenos=" 6 "></span>
</span><span id="__span-5-7"><span data-linenos=" 7 "></span>NAME        STATE     READ WRITE CKSUM
</span><span id="__span-5-8"><span data-linenos=" 8 "></span>tank        ONLINE       0     0     0
</span><span id="__span-5-9"><span data-linenos=" 9 "></span>  mirror-0  ONLINE       0     0     0
</span><span id="__span-5-10"><span data-linenos="10 "></span>    sdb     ONLINE       0     0     0
</span><span id="__span-5-11"><span data-linenos="11 "></span>    sdc     ONLINE       0     0     0
</span><span id="__span-5-12"><span data-linenos="12 "></span>
</span><span id="__span-5-13"><span data-linenos="13 "></span>errors: No known data errors
</span></code></pre></div>
<p>Our vdev is ‘mirror-0’ and our pool is tank.</p>
<h5 id="create-a-raid-z-pool"><strong>Create a RAID-Z pool</strong><a href="#create-a-raid-z-pool" title="Permanent link">#</a></h5>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-6-1"><span data-linenos="1 "></span># zpool create tank raidz sdb sdc sdd
</span></code></pre></div>
<p>And the result indicating that my vdev is RAIDZ1.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-7-1"><span data-linenos=" 1 "></span>root@ubuntu-vm:~# zpool status
</span><span id="__span-7-2"><span data-linenos=" 2 "></span>  pool: tank
</span><span id="__span-7-3"><span data-linenos=" 3 "></span> state: ONLINE
</span><span id="__span-7-4"><span data-linenos=" 4 "></span>  scan: none requested
</span><span id="__span-7-5"><span data-linenos=" 5 "></span>config:
</span><span id="__span-7-6"><span data-linenos=" 6 "></span>
</span><span id="__span-7-7"><span data-linenos=" 7 "></span>NAME        STATE     READ WRITE CKSUM
</span><span id="__span-7-8"><span data-linenos=" 8 "></span>tank        ONLINE       0     0     0
</span><span id="__span-7-9"><span data-linenos=" 9 "></span>  raidz1-0  ONLINE       0     0     0
</span><span id="__span-7-10"><span data-linenos="10 "></span>    sdb     ONLINE       0     0     0
</span><span id="__span-7-11"><span data-linenos="11 "></span>    sdc     ONLINE       0     0     0
</span><span id="__span-7-12"><span data-linenos="12 "></span>    sdd     ONLINE       0     0     0
</span><span id="__span-7-13"><span data-linenos="13 "></span>
</span><span id="__span-7-14"><span data-linenos="14 "></span>errors: No known data errors
</span></code></pre></div>
<p>You can use the same command to create RAIDZ2,3 pools.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-8-1"><span data-linenos="1 "></span># zpool create [pool name] raidz[1,2,3] [devices]
</span></code></pre></div>
<h5 id="specifying-a-default-mount-point-for-the-pool"><strong>Specifying a default mount point for the pool</strong><a href="#specifying-a-default-mount-point-for-the-pool" title="Permanent link">#</a></h5>
<p>You can also specify the default mount point for the pool by using the <code>-m</code> flag as you create it.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-9-1"><span data-linenos="1 "></span># zpool create tank -m /mnt/tank mirror sdb sdc
</span></code></pre></div>
<p>We can see that our new pool was created and mounted at <code>/mnt/tank</code></p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-10-1"><span data-linenos="1 "></span># zfs list
</span><span id="__span-10-2"><span data-linenos="2 "></span>NAME   USED  AVAIL     REFER  MOUNTPOINT
</span><span id="__span-10-3"><span data-linenos="3 "></span>tank    99K  4.36G       24K  /mnt/tank
</span></code></pre></div>
<p>💡 <em><strong>TIP:</strong> Also read up on the <code>zpool add</code> command.</em></p>
<h4 id="12getting-pool-status">1.2.Getting Pool Status<a href="#12getting-pool-status" title="Permanent link">#</a></h4>
<p>After we create a new pool it’s automatically imported into our system. As we have seen before, we can view details of the pool with the <code>zpool status</code> command.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-11-1"><span data-linenos=" 1 "></span># zpool status tank
</span><span id="__span-11-2"><span data-linenos=" 2 "></span>  pool: tank
</span><span id="__span-11-3"><span data-linenos=" 3 "></span> state: ONLINE
</span><span id="__span-11-4"><span data-linenos=" 4 "></span>  scan: none requested
</span><span id="__span-11-5"><span data-linenos=" 5 "></span>config:
</span><span id="__span-11-6"><span data-linenos=" 6 "></span>
</span><span id="__span-11-7"><span data-linenos=" 7 "></span>NAME        STATE     READ WRITE CKSUM
</span><span id="__span-11-8"><span data-linenos=" 8 "></span>tank        ONLINE       0     0     0
</span><span id="__span-11-9"><span data-linenos=" 9 "></span>  mirror-0  ONLINE       0     0     0
</span><span id="__span-11-10"><span data-linenos="10 "></span>    sdb     ONLINE       0     0     0
</span><span id="__span-11-11"><span data-linenos="11 "></span>    sdc     ONLINE       0     0     0
</span><span id="__span-11-12"><span data-linenos="12 "></span>
</span><span id="__span-11-13"><span data-linenos="13 "></span>errors: No known data errors
</span></code></pre></div>
<p>Some of the fields we did not look before are:</p>
<ul>
<li><code>state:</code> Indicates if pool is online or not</li>
<li><code>status:</code> Additional information about the pool</li>
<li><code>action:</code> Indicates if there are any pending actions for the pool</li>
<li><code>scan:</code> If a scrub is in progress or the last scrub run status</li>
<li><code>errors:</code> Indicates if there are any problems with the pool</li>
</ul>
<p>For example:</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-12-1"><span data-linenos=" 1 "></span># zpool status tank
</span><span id="__span-12-2"><span data-linenos=" 2 "></span>  pool: tank
</span><span id="__span-12-3"><span data-linenos=" 3 "></span> state: ONLINE
</span><span id="__span-12-4"><span data-linenos=" 4 "></span>status: Some supported features are not enabled on the pool. The pool can
</span><span id="__span-12-5"><span data-linenos=" 5 "></span>        still be used, but some features are unavailable.
</span><span id="__span-12-6"><span data-linenos=" 6 "></span>action: Enable all features using 'zpool upgrade'. Once this is done,
</span><span id="__span-12-7"><span data-linenos=" 7 "></span>        the pool may no longer be accessible by software that does not support
</span><span id="__span-12-8"><span data-linenos=" 8 "></span>        the features. See zpool-features(7) for details.
</span><span id="__span-12-9"><span data-linenos=" 9 "></span>  scan: scrub repaired 0 in 0 days 03:37:12 with 0 errors on Wed Oct 28 03:37:13 2020
</span><span id="__span-12-10"><span data-linenos="10 "></span>config:
</span><span id="__span-12-11"><span data-linenos="11 "></span>
</span><span id="__span-12-12"><span data-linenos="12 "></span>NAME        STATE     READ WRITE CKSUM
</span><span id="__span-12-13"><span data-linenos="13 "></span>tank        ONLINE       0     0     0
</span><span id="__span-12-14"><span data-linenos="14 "></span>  mirror-0  ONLINE       0     0     0
</span><span id="__span-12-15"><span data-linenos="15 "></span>    sdb     ONLINE       0     0     0
</span><span id="__span-12-16"><span data-linenos="16 "></span>    sdc     ONLINE       0     0     0
</span><span id="__span-12-17"><span data-linenos="17 "></span>
</span><span id="__span-12-18"><span data-linenos="18 "></span>errors: No known data errors
</span></code></pre></div>
<p>Another example:</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-13-1"><span data-linenos=" 1 "></span># zpool status -v tank
</span><span id="__span-13-2"><span data-linenos=" 2 "></span>  pool: tank
</span><span id="__span-13-3"><span data-linenos=" 3 "></span> state: ONLINE
</span><span id="__span-13-4"><span data-linenos=" 4 "></span>status: One or more devices has experienced an error resulting in data
</span><span id="__span-13-5"><span data-linenos=" 5 "></span>    corruption.  Applications may be affected.
</span><span id="__span-13-6"><span data-linenos=" 6 "></span>action: Restore the file in question if possible.  Otherwise restore the
</span><span id="__span-13-7"><span data-linenos=" 7 "></span>    entire pool from backup.
</span><span id="__span-13-8"><span data-linenos=" 8 "></span>   see: http://illumos.org/msg/ZFS-8000-8A
</span><span id="__span-13-9"><span data-linenos=" 9 "></span>  scan: scrub repaired 0 in 0 days 04:21:43 with 0 errors on Sun Feb 23 04:21:45 2020
</span><span id="__span-13-10"><span data-linenos="10 "></span>config:
</span><span id="__span-13-11"><span data-linenos="11 "></span>
</span><span id="__span-13-12"><span data-linenos="12 "></span>NAME        STATE     READ WRITE CKSUM
</span><span id="__span-13-13"><span data-linenos="13 "></span>tank        ONLINE       0     0     0
</span><span id="__span-13-14"><span data-linenos="14 "></span>  mirror-0  ONLINE       0     0     0
</span><span id="__span-13-15"><span data-linenos="15 "></span>    sdb     ONLINE       0     0     0
</span><span id="__span-13-16"><span data-linenos="16 "></span>    sdc     ONLINE       0     0     0
</span><span id="__span-13-17"><span data-linenos="17 "></span>
</span><span id="__span-13-18"><span data-linenos="18 "></span>errors: Permanent errors have been detected in the following files:
</span><span id="__span-13-19"><span data-linenos="19 "></span>
</span><span id="__span-13-20"><span data-linenos="20 "></span>        tank:&lt;0xdcca&gt;
</span></code></pre></div>
<h4 id="13listing-pools">1.3.Listing Pools<a href="#13listing-pools" title="Permanent link">#</a></h4>
<p>As we have seen before, we can view some details of the pool with the <code>zpool status</code> command. But there are other commands, like <code>zpool list</code> that can give us information about the pool.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-14-1"><span data-linenos="1 "></span># zpool list {pool name}
</span></code></pre></div>
<p>On the example below, we look at the details for our mirrored tank pool:</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-15-1"><span data-linenos="1 "></span># zpool list
</span><span id="__span-15-2"><span data-linenos="2 "></span>NAME   SIZE  ALLOC   FREE  CKPOINT  EXPANDSZ   FRAG    CAP  DEDUP    HEALTH  ALTROOT
</span><span id="__span-15-3"><span data-linenos="3 "></span>tank  4.50G   117K  4.50G        -         -     0%     0%  1.00x    ONLINE  -
</span></code></pre></div>
<h4 id="14show-pool-history">1.4.Show Pool History<a href="#14show-pool-history" title="Permanent link">#</a></h4>
<p>This is another useful command that displays the history of commands that were executed against a pool from it’s creation (of course only commands that make changes to the pool’s configuration).</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-16-1"><span data-linenos="1 "></span># zpool history tank
</span><span id="__span-16-2"><span data-linenos="2 "></span>History for 'tank':
</span><span id="__span-16-3"><span data-linenos="3 "></span>2020-11-02.15:02:53 zpool create tank -m /mnt/tank mirror sdb sdc
</span><span id="__span-16-4"><span data-linenos="4 "></span>2020-11-02.15:50:43 zpool scrub tank
</span><span id="__span-16-5"><span data-linenos="5 "></span>2020-11-02.15:53:30 zfs set compression=lz4 tank
</span><span id="__span-16-6"><span data-linenos="6 "></span>2020-11-02.15:54:03 zpool scrub tank
</span></code></pre></div>
<h4 id="15importing-pools">1.5.Importing Pools<a href="#15importing-pools" title="Permanent link">#</a></h4>
<p>Usually after creating a pool it’s set to import and mount automatically, but you may encounter scenarios where you need to manually import a pool (like when troubleshooting or after re-imaging a system).</p>
<p>Note that the import command will also mount the pool.</p>
<h5 id="lists-pools-available-to-import"><strong>Lists pools available to import</strong><a href="#lists-pools-available-to-import" title="Permanent link">#</a></h5>
<p>Running the <code>zpool import</code> command without a pool name will show you a list of pools that can be imported.</p>
<p>Example of when no pools are available to be imported.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-17-1"><span data-linenos="1 "></span>root@ubuntu-vm:~# zpool import
</span><span id="__span-17-2"><span data-linenos="2 "></span>no pools available to import
</span></code></pre></div>
<p>Here we have a pool that can be imported.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-18-1"><span data-linenos=" 1 "></span>root@ubuntu-vm:~# zpool import
</span><span id="__span-18-2"><span data-linenos=" 2 "></span>   pool: tank
</span><span id="__span-18-3"><span data-linenos=" 3 "></span>     id: 2008489828128587072
</span><span id="__span-18-4"><span data-linenos=" 4 "></span>  state: ONLINE
</span><span id="__span-18-5"><span data-linenos=" 5 "></span> action: The pool can be imported using its name or numeric identifier.
</span><span id="__span-18-6"><span data-linenos=" 6 "></span> config:
</span><span id="__span-18-7"><span data-linenos=" 7 "></span>
</span><span id="__span-18-8"><span data-linenos=" 8 "></span>tank        ONLINE
</span><span id="__span-18-9"><span data-linenos=" 9 "></span>  mirror-0  ONLINE
</span><span id="__span-18-10"><span data-linenos="10 "></span>    sdb     ONLINE
</span><span id="__span-18-11"><span data-linenos="11 "></span>    sdc     ONLINE
</span></code></pre></div>
<h5 id="importing-the-pool"><strong>Importing the pool</strong><a href="#importing-the-pool" title="Permanent link">#</a></h5>
<p>Give the command a pool name and it will be imported.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-19-1"><span data-linenos="1 "></span>root@ubuntu-vm:~# zpool import tank
</span><span id="__span-19-2"><span data-linenos="2 "></span>
</span><span id="__span-19-3"><span data-linenos="3 "></span>root@ubuntu-vm:~# zpool list
</span><span id="__span-19-4"><span data-linenos="4 "></span>NAME   SIZE  ALLOC   FREE  CKPOINT  EXPANDSZ   FRAG    CAP  DEDUP    HEALTH  ALTROOT
</span><span id="__span-19-5"><span data-linenos="5 "></span>tank  4.50G   147K  4.50G        -         -     0%     0%  1.00x    ONLINE  -
</span></code></pre></div>
<p>You can also import all available pools by using the <code>-a</code> option.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-20-1"><span data-linenos="1 "></span># zpool import -a
</span></code></pre></div>
<h5 id="importing-a-pool-with-an-alternate-root-location"><strong>Importing a Pool with an Alternate Root Location</strong><a href="#importing-a-pool-with-an-alternate-root-location" title="Permanent link">#</a></h5>
<p>Use the <code>-R</code> flag to mount the pool to an alternate root location. Note that this is not the mount path for the pool, but an alternate root folder.</p>
<p><em><code>tank</code> is by default configured to be mounted at <code>/mnt/tank</code></em></p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-21-1"><span data-linenos="1 "></span>root@ubuntu-vm:~# zpool import -R /mnt/tank2 tank
</span><span id="__span-21-2"><span data-linenos="2 "></span>
</span><span id="__span-21-3"><span data-linenos="3 "></span>root@ubuntu-vm:~# zfs list
</span><span id="__span-21-4"><span data-linenos="4 "></span>NAME   USED  AVAIL     REFER  MOUNTPOINT
</span><span id="__span-21-5"><span data-linenos="5 "></span>tank   117K  4.36G       24K  /mnt/tank2/mnt/tank
</span></code></pre></div>
<h4 id="16exporting-the-pool">1.6.Exporting the Pool<a href="#16exporting-the-pool" title="Permanent link">#</a></h4>
<p>As expected, this is the opposite of the import command. The export command attempts to unmount any mounted file systems within the pool before continuing.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-22-1"><span data-linenos="1 "></span># zpool export [pool name]
</span></code></pre></div>
<p>For example:</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-23-1"><span data-linenos="1 "></span>root@ubuntu-vm:~# zpool export tank
</span><span id="__span-23-2"><span data-linenos="2 "></span>
</span><span id="__span-23-3"><span data-linenos="3 "></span>root@ubuntu-vm:~# zpool list
</span><span id="__span-23-4"><span data-linenos="4 "></span>no pools available
</span></code></pre></div>
<p>If any of the file systems fail to unmount you can forcefully unmount them by using the <code>-f</code> option. However, if ZFS volumes exist and are in use, even with <code>-f</code> it will fail to export.</p>
<h4 id="17destroyingdeleting-pools">1.7.Destroying/Deleting Pools<a href="#17destroyingdeleting-pools" title="Permanent link">#</a></h4>
<p>We can use the <code>zfs destroy</code> command to delete pools and all it’s child datasets and/or volumes.</p>
<p>⚠️ <strong>WARNING:</strong> <em>This will delete all your data, including any snapshots your may have.</em></p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-24-1"><span data-linenos="1 "></span>root@ubuntu-vm:~# zpool destroy tank
</span><span id="__span-24-2"><span data-linenos="2 "></span>
</span><span id="__span-24-3"><span data-linenos="3 "></span>root@ubuntu-vm:~# zpool list
</span><span id="__span-24-4"><span data-linenos="4 "></span>no pools available
</span><span id="__span-24-5"><span data-linenos="5 "></span>
</span><span id="__span-24-6"><span data-linenos="6 "></span>root@ubuntu-vm:~# zpool import
</span><span id="__span-24-7"><span data-linenos="7 "></span>no pools available to import
</span></code></pre></div>
<h4 id="18scrubbing-pools">1.8.Scrubbing Pools<a href="#18scrubbing-pools" title="Permanent link">#</a></h4>
<p>ZFS scrub checks every block in a pool against its known checksum to make sure that the data is valid. If you have vdevs with parity, ZFS scrub will also repair the data using healthy data from other disks. Scrubs should run on a schedule to make sure your systems stays healthy.</p>
<h5 id="initiating-a-scrub"><strong>Initiating a scrub</strong><a href="#initiating-a-scrub" title="Permanent link">#</a></h5>
<p>Initiating a scrub of a pool is as simple as running:</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-25-1"><span data-linenos="1 "></span># zpool scrub [pool]
</span></code></pre></div>
<h5 id="checking-the-status-of-a-scrub"><strong>Checking the status of a scrub</strong><a href="#checking-the-status-of-a-scrub" title="Permanent link">#</a></h5>
<p>You can check the status of a scrub with <code>zpool status</code> and looking for messages in the ‘scan’ section.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-26-1"><span data-linenos=" 1 "></span>root@ubuntu-vm:/mnt/tank# zpool status tank
</span><span id="__span-26-2"><span data-linenos=" 2 "></span>  pool: tank
</span><span id="__span-26-3"><span data-linenos=" 3 "></span> state: ONLINE
</span><span id="__span-26-4"><span data-linenos=" 4 "></span>  scan: scrub repaired 0B in 0 days 00:00:03 with 0 errors on Tue Nov  3 16:26:23 2020
</span><span id="__span-26-5"><span data-linenos=" 5 "></span>config:
</span><span id="__span-26-6"><span data-linenos=" 6 "></span>
</span><span id="__span-26-7"><span data-linenos=" 7 "></span>NAME        STATE     READ WRITE CKSUM
</span><span id="__span-26-8"><span data-linenos=" 8 "></span>tank        ONLINE       0     0     0
</span><span id="__span-26-9"><span data-linenos=" 9 "></span>  mirror-0  ONLINE       0     0     0
</span><span id="__span-26-10"><span data-linenos="10 "></span>    sdb     ONLINE       0     0     0
</span><span id="__span-26-11"><span data-linenos="11 "></span>    sdc     ONLINE       0     0     0
</span><span id="__span-26-12"><span data-linenos="12 "></span>
</span><span id="__span-26-13"><span data-linenos="13 "></span>errors: No known data errors
</span></code></pre></div>
<h5 id="stopping-a-scrub"><strong>Stopping a scrub</strong><a href="#stopping-a-scrub" title="Permanent link">#</a></h5>
<p>Use the <code>-s</code> flag.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-27-1"><span data-linenos="1 "></span># zpool scrub -s [pool]
</span></code></pre></div>
<h3 id="2zfs-filesystem-commands">2.ZFS Filesystem Commands<a href="#2zfs-filesystem-commands" title="Permanent link">#</a></h3>
<p>Now we will look at the commands that will help us work with filesystems (datasets) and volumes. We will concentrate more on the filesystem side of things and will not cover volumes.</p>
<p>The commands we will review are:</p>
<ul>
<li><code>zfs create</code> - Creates a new volume or filesystem</li>
<li><code>zfs mount/umount</code> - Mounts the filesystem</li>
<li><code>zfs list</code> - Lists datasets and snapshots</li>
<li><code>zfs get/set</code> - Gets configuration and sets configuration for the dataset</li>
<li><code>zfs snapshot</code> - Handles snapshots</li>
<li><code>zfs diff</code> - Used to compare data between snapshot</li>
<li><code>zfs rollback</code> - Rolls back a snapshot</li>
<li><code>zfs send/recv</code> - Sends a snapshot as a stream of data</li>
<li><code>zfs destroy</code> - Deletes datasets and snapshots</li>
</ul>
<h4 id="21-creating-datasets">2.1. Creating Datasets<a href="#21-creating-datasets" title="Permanent link">#</a></h4>
<p>We can create datasets with the <code>zfs create</code> command. Here we create ‘dataset1’ as child of the ‘tank’ dataset (that was created automatically with the <code>zpool create</code> command).</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-28-1"><span data-linenos="1 "></span>root@ubuntu-vm:~# zfs create tank/dataset1
</span><span id="__span-28-2"><span data-linenos="2 "></span>
</span><span id="__span-28-3"><span data-linenos="3 "></span>root@ubuntu-vm:~# zfs list
</span><span id="__span-28-4"><span data-linenos="4 "></span>NAME            USED  AVAIL     REFER  MOUNTPOINT
</span><span id="__span-28-5"><span data-linenos="5 "></span>tank            145K  9.36G     30.6K  /tank
</span><span id="__span-28-6"><span data-linenos="6 "></span>tank/dataset1  30.6K  9.36G     30.6K  /tank/dataset1
</span></code></pre></div>
<h5 id="creating-missing-parent-datasets"><strong>Creating missing parent datasets</strong><a href="#creating-missing-parent-datasets" title="Permanent link">#</a></h5>
<p>We can also create missing parent datasets with the <code>-p</code> flag (similar to <code>mkdir -p</code>).</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-29-1"><span data-linenos=" 1 "></span>root@ubuntu-vm:~# zfs create tank/dataset1/childset1/childset2
</span><span id="__span-29-2"><span data-linenos=" 2 "></span>cannot create 'tank/dataset1/childset1/childset2': parent does not exist
</span><span id="__span-29-3"><span data-linenos=" 3 "></span>
</span><span id="__span-29-4"><span data-linenos=" 4 "></span>root@ubuntu-vm:~# zfs create -p tank/dataset1/childset1/childset2
</span><span id="__span-29-5"><span data-linenos=" 5 "></span>
</span><span id="__span-29-6"><span data-linenos=" 6 "></span>root@ubuntu-vm:~# zfs list
</span><span id="__span-29-7"><span data-linenos=" 7 "></span>NAME                                USED  AVAIL     REFER  MOUNTPOINT
</span><span id="__span-29-8"><span data-linenos=" 8 "></span>tank                                249K  9.36G     30.6K  /tank
</span><span id="__span-29-9"><span data-linenos=" 9 "></span>tank/dataset1                      30.6K  9.36G     30.6K  /tank/dataset1
</span><span id="__span-29-10"><span data-linenos="10 "></span>tank/dataset1/childset1            61.3K  9.36G     30.6K  /tank/dataset1/childset1
</span><span id="__span-29-11"><span data-linenos="11 "></span>tank/dataset1/childset1/childset2  30.6K  9.36G     30.6K  /tank/dataset1/childset1/childset2
</span></code></pre></div>
<h4 id="22-mounting-filesystems-datasets">2.2. Mounting Filesystems (Datasets)<a href="#22-mounting-filesystems-datasets" title="Permanent link">#</a></h4>
<p>We can use the <code>zfs mount/unmount</code> commands to view the current mount points as well as mounting/unmounting filesystems.</p>
<h5 id="viewing-current-mounted-filesystems"><strong>Viewing current mounted filesystems</strong><a href="#viewing-current-mounted-filesystems" title="Permanent link">#</a></h5>
<p>Without any arguments, <code>zfs mount</code> will display all mounted zfs filesystems and their respective mount points (without the child datasets).</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-30-1"><span data-linenos="1 "></span>root@ubuntu-vm:~# zfs mount
</span><span id="__span-30-2"><span data-linenos="2 "></span>tank                            /tank
</span></code></pre></div>
<h5 id="mounting-filesystems"><strong>Mounting filesystems</strong><a href="#mounting-filesystems" title="Permanent link">#</a></h5>
<p>Use <code>zfs mount [pool|dataset]</code> to mount filesystems. On the example below we use <code>zfs mount</code> to establish that no datasets are mounted, and then we mount the ‘tank’ dataset and confirm that is mounted with <code>zfs mount</code>.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-31-1"><span data-linenos="1 "></span>root@ubuntu-vm:~# zfs mount
</span><span id="__span-31-2"><span data-linenos="2 "></span>
</span><span id="__span-31-3"><span data-linenos="3 "></span>root@ubuntu-vm:~# zfs mount tank
</span><span id="__span-31-4"><span data-linenos="4 "></span>
</span><span id="__span-31-5"><span data-linenos="5 "></span>root@ubuntu-vm:~# zfs mount
</span><span id="__span-31-6"><span data-linenos="6 "></span>tank                            /tank
</span></code></pre></div>
<p>Use the <code>-a</code> option to mount all filesystems.</p>
<h5 id="mount-a-child-dataset"><strong>Mount a child dataset</strong><a href="#mount-a-child-dataset" title="Permanent link">#</a></h5>
<p>You can also mount a child dataset without the parent datasets. For example, here we confirm that ‘tank’ is not mounted, then we look at the available datasets, and we execute the command to mount the <code>tank/dataset2/childset2</code> dataset only.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-32-1"><span data-linenos=" 1 "></span>root@ubuntu-vm:~# zfs mount
</span><span id="__span-32-2"><span data-linenos=" 2 "></span>
</span><span id="__span-32-3"><span data-linenos=" 3 "></span>root@ubuntu-vm:~# zfs list
</span><span id="__span-32-4"><span data-linenos=" 4 "></span>NAME                                USED  AVAIL     REFER  MOUNTPOINT
</span><span id="__span-32-5"><span data-linenos=" 5 "></span>tank                                249K  9.36G     30.6K  /tank
</span><span id="__span-32-6"><span data-linenos=" 6 "></span>tank/dataset1                      30.6K  9.36G     30.6K  /tank/dataset1
</span><span id="__span-32-7"><span data-linenos=" 7 "></span>tank/dataset2                      91.9K  9.36G     30.6K  /tank/dataset2
</span><span id="__span-32-8"><span data-linenos=" 8 "></span>tank/dataset2/childset2            61.3K  9.36G     30.6K  /tank/dataset2/childset2
</span><span id="__span-32-9"><span data-linenos=" 9 "></span>tank/dataset2/childset2/childset2  30.6K  9.36G     30.6K  /tank/dataset2/childset2/childset2
</span><span id="__span-32-10"><span data-linenos="10 "></span>
</span><span id="__span-32-11"><span data-linenos="11 "></span>root@ubuntu-vm:~# zfs mount tank/dataset2/childset2
</span><span id="__span-32-12"><span data-linenos="12 "></span>
</span><span id="__span-32-13"><span data-linenos="13 "></span>root@ubuntu-vm:~# zfs mount
</span><span id="__span-32-14"><span data-linenos="14 "></span>tank/dataset2/childset2         /tank/dataset2/childset2
</span></code></pre></div>
<p>Note that this will create the required path in the OS filesystem to mount the child dataset. If you decide to mount the parent dataset later you may run into a <code>directory is not empty</code> error because of the created directories.</p>
<h5 id="unmounting-filesystems"><strong>Unmounting filesystems</strong><a href="#unmounting-filesystems" title="Permanent link">#</a></h5>
<p>Run<code>zfs unmount</code> and specify the dataset name.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-33-1"><span data-linenos="1 "></span>root@ubuntu-vm:~# zfs mount
</span><span id="__span-33-2"><span data-linenos="2 "></span>tank                            /tank
</span><span id="__span-33-3"><span data-linenos="3 "></span>
</span><span id="__span-33-4"><span data-linenos="4 "></span>root@ubuntu-vm:~# zfs unmount tank
</span><span id="__span-33-5"><span data-linenos="5 "></span>
</span><span id="__span-33-6"><span data-linenos="6 "></span>root@ubuntu-vm:~# zfs mount
</span></code></pre></div>
<h4 id="23-listing-filesystems-datasets">2.3. Listing Filesystems (Datasets)<a href="#23-listing-filesystems-datasets" title="Permanent link">#</a></h4>
<p>You can list the dataset by running <code>zfs list [dataset name]</code>.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-34-1"><span data-linenos="1 "></span>root@ubuntu-vm:~# zfs list tank
</span><span id="__span-34-2"><span data-linenos="2 "></span>NAME   USED  AVAIL     REFER  MOUNTPOINT
</span><span id="__span-34-3"><span data-linenos="3 "></span>tank   253K  9.36G     30.6K  /tank
</span></code></pre></div>
<p>And you can also specify the mount point as an argument.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-35-1"><span data-linenos="1 "></span>root@ubuntu-vm:~# zfs list /tank
</span><span id="__span-35-2"><span data-linenos="2 "></span>NAME   USED  AVAIL     REFER  MOUNTPOINT
</span><span id="__span-35-3"><span data-linenos="3 "></span>tank   253K  9.36G     30.6K  /tank
</span></code></pre></div>
<p>If run without a dataset name, <code>zfs list</code> will show all datasets in the system recursively.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-36-1"><span data-linenos="1 "></span>root@ubuntu-vm:~# zfs list
</span><span id="__span-36-2"><span data-linenos="2 "></span>NAME                                USED  AVAIL     REFER  MOUNTPOINT
</span><span id="__span-36-3"><span data-linenos="3 "></span>tank                                253K  9.36G     30.6K  /tank
</span><span id="__span-36-4"><span data-linenos="4 "></span>tank/dataset1                      30.6K  9.36G     30.6K  /tank/dataset1
</span><span id="__span-36-5"><span data-linenos="5 "></span>tank/dataset2                      91.9K  9.36G     30.6K  /tank/dataset2
</span><span id="__span-36-6"><span data-linenos="6 "></span>tank/dataset2/childset2            61.3K  9.36G     30.6K  /tank/dataset2/childset2
</span><span id="__span-36-7"><span data-linenos="7 "></span>tank/dataset2/childset2/childset2  30.6K  9.36G     30.6K  /tank/dataset2/childset2/childset2
</span></code></pre></div>
<p>💡 <em><strong>TIP:</strong> when specifying a dataset name you can also use the <code>-r</code> flag to display the dataset recursively.</em></p>
<h4 id="24-getting-and-setting-dataset-properties">2.4. Getting and Setting Dataset Properties<a href="#24-getting-and-setting-dataset-properties" title="Permanent link">#</a></h4>
<p>Properties control the behavior of filesystems, volumes, snapshots, and clones. ZFS properties can look similar to mount options.</p>
<h5 id="getting-a-list-of-all-the-properties-for-a-dataset"><strong>Getting a list of all the properties for a dataset</strong><a href="#getting-a-list-of-all-the-properties-for-a-dataset" title="Permanent link">#</a></h5>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-37-1"><span data-linenos="1 "></span># zfs get all [dataset]
</span></code></pre></div>
<h5 id="getting-the-current-value-for-a-specific-property"><strong>Getting the current value for a specific property</strong><a href="#getting-the-current-value-for-a-specific-property" title="Permanent link">#</a></h5>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-38-1"><span data-linenos="1 "></span>root@ubuntu-vm:~# zfs get compression tank
</span><span id="__span-38-2"><span data-linenos="2 "></span>NAME  PROPERTY     VALUE     SOURCE
</span><span id="__span-38-3"><span data-linenos="3 "></span>tank  compression  off       default
</span></code></pre></div>
<h5 id="setting-a-property-value"><strong>Setting a property value</strong><a href="#setting-a-property-value" title="Permanent link">#</a></h5>
<p>Use the <code>zfs set</code> command.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-39-1"><span data-linenos="1 "></span>root@ubuntu-vm:~# zfs set compression=lz4 tank
</span><span id="__span-39-2"><span data-linenos="2 "></span>
</span><span id="__span-39-3"><span data-linenos="3 "></span>root@ubuntu-vm:~# zfs get compression tank
</span><span id="__span-39-4"><span data-linenos="4 "></span>NAME  PROPERTY     VALUE     SOURCE
</span><span id="__span-39-5"><span data-linenos="5 "></span>tank  compression  lz4       local
</span></code></pre></div>
<h4 id="25-creating-snapshots">2.5. Creating Snapshots<a href="#25-creating-snapshots" title="Permanent link">#</a></h4>
<p>Snapshots allow you to save the state of a filesystem to a current point in time, without duplicating storage (files are not copied). It flags existing data as «read-only» while allowing new data to be added to the filesystem without affecting the existing data blocks that are protected by the snapshot (the whole process is a bit more complicated than this).</p>
<p>Let’s take a look at the image below as an example. You have a filesystem with existing data (Data A) and you take a snapshot (snapshot 1). Then you make some changes, add new files (Data B) and take another snapshot (snapthot 2). After that you make even more changes (Data C).</p>
<p><a href="https://ikrima.dev/dev-notes/_assets/homelab/zfs-for-dummies/snapshot.1.png" data-type="image" data-width="100%" data-height="auto" data-desc-position="bottom"><img alt="" src="https://ikrima.dev/dev-notes/_assets/homelab/zfs-for-dummies/snapshot.1.png"></a></p>
<p>Snapshot 1 protects the original data (Data A), while snapshot 2 protects Data Changes (B) as well as the original data (Data A). So you can delete snapshot 1 and data (A) will still be protected.</p>
<p><a href="https://ikrima.dev/dev-notes/_assets/homelab/zfs-for-dummies/snapshot.2.png" data-type="image" data-width="100%" data-height="auto" data-desc-position="bottom"><img alt="" src="https://ikrima.dev/dev-notes/_assets/homelab/zfs-for-dummies/snapshot.2.png"></a></p>
<p><em><strong>Note:</strong> The amount of data used for the snapshots is very small because we are not copying the files, but instead the filesystem top-level metadata block indicating the they belong to a snapshot.</em></p>
<p>And here are a few scenarios of what happens when you delete files and snapshots:</p>
<p><a href="https://ikrima.dev/dev-notes/_assets/homelab/zfs-for-dummies/snapshot.3.png" data-type="image" data-width="100%" data-height="auto" data-desc-position="bottom"><img alt="" src="https://ikrima.dev/dev-notes/_assets/homelab/zfs-for-dummies/snapshot.3.png"></a></p>
<p>Snapshots are great for testing software development, or creating a failsafe before an upgrade. But by no means they should be considered (by itself) as a backup or DR solution.</p>
<h5 id="creating-a-snapshot"><strong>Creating a snapshot</strong><a href="#creating-a-snapshot" title="Permanent link">#</a></h5>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-40-1"><span data-linenos="1 "></span>zfs snapshot create [pool/dataset@snapshot_name]
</span></code></pre></div>
<p>For example:</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-41-1"><span data-linenos="1 "></span>root@ubuntu-vm:~# zfs snapshot tank/dataset1@snapshot1
</span><span id="__span-41-2"><span data-linenos="2 "></span>
</span><span id="__span-41-3"><span data-linenos="3 "></span>root@ubuntu-vm:~# zfs list -t snapshot
</span><span id="__span-41-4"><span data-linenos="4 "></span>NAME                   USED  AVAIL     REFER  MOUNTPOINT
</span><span id="__span-41-5"><span data-linenos="5 "></span>tank/dataset1@snapshot1  17.3K      -     3.00G  -
</span></code></pre></div>
<h5 id="creating-recursive-snapshots"><strong>Creating recursive snapshots</strong><a href="#creating-recursive-snapshots" title="Permanent link">#</a></h5>
<p>If you have multiple child datasets, you can either create one snapshot of the top-level dataset (usually the pool name), or use the <code>-r</code> flag to create snapshots recursively.</p>
<p>Snapshot of the main dataset:</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-42-1"><span data-linenos="1 "></span>root@ubuntu-vm:~# zfs snapshot tank@snapshot-master
</span><span id="__span-42-2"><span data-linenos="2 "></span>
</span><span id="__span-42-3"><span data-linenos="3 "></span>root@ubuntu-vm:~# zfs list -t snapshot
</span><span id="__span-42-4"><span data-linenos="4 "></span>NAME                   USED  AVAIL     REFER  MOUNTPOINT
</span><span id="__span-42-5"><span data-linenos="5 "></span>tank@snapshot-master     0B      -     30.6K  -
</span></code></pre></div>
<p>Recursive snapshot:</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-43-1"><span data-linenos="1 "></span>root@ubuntu-vm:~# zfs snapshot -r tank@recursive
</span><span id="__span-43-2"><span data-linenos="2 "></span>
</span><span id="__span-43-3"><span data-linenos="3 "></span>root@ubuntu-vm:~# zfs list -t snapshot
</span><span id="__span-43-4"><span data-linenos="4 "></span>NAME                      USED  AVAIL     REFER  MOUNTPOINT
</span><span id="__span-43-5"><span data-linenos="5 "></span>tank@recursive              0B      -     30.6K  -
</span><span id="__span-43-6"><span data-linenos="6 "></span>tank/dataset1@recursive     0B      -     3.00G  -
</span></code></pre></div>
<h5 id="listing-snapshots"><strong>Listing snapshots</strong><a href="#listing-snapshots" title="Permanent link">#</a></h5>
<p>Use <code>zfs list -t snapshot</code>.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-44-1"><span data-linenos="1 "></span>root@ubuntu-vm:~# zfs list -t snapshot
</span><span id="__span-44-2"><span data-linenos="2 "></span>NAME                      USED  AVAIL     REFER  MOUNTPOINT
</span><span id="__span-44-3"><span data-linenos="3 "></span>tank@recursive              0B      -     30.6K  -
</span><span id="__span-44-4"><span data-linenos="4 "></span>tank/dataset1@recursive     0B      -     3.00G  -
</span></code></pre></div>
<h4 id="26-comparing-snapshots">2.6. Comparing Snapshots<a href="#26-comparing-snapshots" title="Permanent link">#</a></h4>
<p>You can use <code>zfs diff</code> to compare snapshots.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-45-1"><span data-linenos="1 "></span># zfs diff [older snapshot] [newer snapshot]
</span></code></pre></div>
<p>For example:</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-46-1"><span data-linenos="1 "></span>root@ubuntu-vm:# zfs diff tank@initial tank@second
</span><span id="__span-46-2"><span data-linenos="2 "></span>+/mnt/tank/file-1.txt
</span><span id="__span-46-3"><span data-linenos="3 "></span>+/mnt/tank/file-2.txt
</span><span id="__span-46-4"><span data-linenos="4 "></span>+/mnt/tank/file-3.txt
</span><span id="__span-46-5"><span data-linenos="5 "></span>M/mnt/tank/
</span></code></pre></div>
<h4 id="27-restoring-a-snapshot">2.7. Restoring a Snapshot<a href="#27-restoring-a-snapshot" title="Permanent link">#</a></h4>
<p>Restore a snapshots with <code>zfs rollback</code>. Note that restoring a snapshot will delete all files that were created after the snapshot (as we saw in our example). It will also delete any newer snapshots (you will be asked to use the <code>-r</code> option to rollback and delete newer snapshots).</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-47-1"><span data-linenos="1 "></span>zfs rollback [pool/dataset@snapshot_name]
</span></code></pre></div>
<h4 id="29-sending-and-receiving-snapshots">2.9. Sending and Receiving Snapshots<a href="#29-sending-and-receiving-snapshots" title="Permanent link">#</a></h4>
<p>One of the best features of ZFS is ‘ZFS send’. It allows you send snapshots as a stream of data. This is a great way replicate a snapshot and it’s dataset to a file, another pool or even to another system via SSH. Amazing no!</p>
<p>Let’s look at the example below. We have 2 pools in our system named ‘tank’ and ‘backup’.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-48-1"><span data-linenos="1 "></span>root@ubuntu-vm:~# zpool list
</span><span id="__span-48-2"><span data-linenos="2 "></span>NAME     SIZE  ALLOC   FREE  CKPOINT  EXPANDSZ   FRAG    CAP  DEDUP    HEALTH  ALTROOT
</span><span id="__span-48-3"><span data-linenos="3 "></span>tank       9G  1.50G  7.50G        -         -     0%    16%  1.00x    ONLINE  -
</span><span id="__span-48-4"><span data-linenos="4 "></span>backup  4.50G   104K  4.50G        -         -     0%     0%  1.00x    ONLINE  -
</span></code></pre></div>
<p>In our tank pool we have a dataset for our Movies.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-49-1"><span data-linenos="1 "></span>root@ubuntu-vm:/tank/Movies# zfs list -r tank
</span><span id="__span-49-2"><span data-linenos="2 "></span>NAME          USED  AVAIL     REFER  MOUNTPOINT
</span><span id="__span-49-3"><span data-linenos="3 "></span>tank         1.50G  7.22G       24K  /tank
</span><span id="__span-49-4"><span data-linenos="4 "></span>tank/Movies  1.50G  7.22G     1.50G  /tank/Movies
</span></code></pre></div>
<p>Before we can send this data we need create a snapshot:</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-50-1"><span data-linenos="1 "></span>root@ubuntu-vm:~# zfs snapshot tank/Movies@$(date '+%Y-%m-%d_%H-%M')
</span><span id="__span-50-2"><span data-linenos="2 "></span>
</span><span id="__span-50-3"><span data-linenos="3 "></span>root@ubuntu-vm:~# zfs list -t snapshot
</span><span id="__span-50-4"><span data-linenos="4 "></span>NAME                           USED  AVAIL     REFER  MOUNTPOINT
</span><span id="__span-50-5"><span data-linenos="5 "></span>tank/Movies@2020-11-03_15-29     0B      -     1.50G  -
</span></code></pre></div>
<p>And now we can send our snapshot to our backup pool with <code>zfs send/recv</code>.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-51-1"><span data-linenos="1 "></span>root@ubuntu-vm:~# zfs send tank/Movies@2020-11-03_15-29 | zfs recv backup/Movies
</span></code></pre></div>
<p>And let’s confirm that it worked.</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-52-1"><span data-linenos=" 1 "></span>root@ubuntu-vm:~# zfs list
</span><span id="__span-52-2"><span data-linenos=" 2 "></span>NAME            USED  AVAIL     REFER  MOUNTPOINT
</span><span id="__span-52-3"><span data-linenos=" 3 "></span>backup         1.50G  2.86G       24K  /backup
</span><span id="__span-52-4"><span data-linenos=" 4 "></span>backup/Movies  1.50G  2.86G     1.50G  /backup/Movies
</span><span id="__span-52-5"><span data-linenos=" 5 "></span>tank           1.50G  7.22G       24K  /tank
</span><span id="__span-52-6"><span data-linenos=" 6 "></span>tank/Movies    1.50G  7.22G     1.50G  /tank/Movies
</span><span id="__span-52-7"><span data-linenos=" 7 "></span>
</span><span id="__span-52-8"><span data-linenos=" 8 "></span>root@ubuntu-vm:~# zfs list -t snapshot
</span><span id="__span-52-9"><span data-linenos=" 9 "></span>NAME                             USED  AVAIL     REFER  MOUNTPOINT
</span><span id="__span-52-10"><span data-linenos="10 "></span>backup/Movies@2020-11-03_15-29     0B      -     1.50G  -
</span><span id="__span-52-11"><span data-linenos="11 "></span>tank/Movies@2020-11-03_15-29       0B      -     1.50G  -
</span></code></pre></div>
<p>💡 <em><strong>TIP:</strong> It’s worth to look into all the options and use cases for ZFS send. Combined with RAIDZs and snapshots, it can help you make your filesystem almost indestructible.</em></p>
<h4 id="210-destroying-filesystems-datasets-and-snapshots">2.10. Destroying Filesystems (Datasets) and Snapshots<a href="#210-destroying-filesystems-datasets-and-snapshots" title="Permanent link">#</a></h4>
<h5 id="destroying-datasets"><strong>Destroying datasets</strong><a href="#destroying-datasets" title="Permanent link">#</a></h5>
<p>To destroy a dataset, use <code>zfs destroy</code> (the <code>-r</code> flag also works here).</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-53-1"><span data-linenos="1 "></span>zfs destroy [pool/dataset]
</span></code></pre></div>
<h5 id="destroying-snapshots"><strong>Destroying snapshots</strong><a href="#destroying-snapshots" title="Permanent link">#</a></h5>
<p>To destroy a snapshot, also use the <code>zfs destroy</code> command (and the <code>-r</code> flag also works here).</p>
<div><p><span>Text Only</span></p><pre><span></span><code><span id="__span-54-1"><span data-linenos="1 "></span>zfs destroy [pool/dataset@snapshot_name]
</span></code></pre></div>
<hr>
<h2 id="conclusion">Conclusion<a href="#conclusion" title="Permanent link">#</a></h2>
<p>While we covered a lot of different topics and commands on ZFS, in reality, we really only scratched the surface on what ZFS can do. If you want to learn more about ZFS I’ve added a few links below with some great reading.</p>
<hr>
<p><strong>References and additional reading:</strong></p>
<ul>
<li>FreeBSD Mastery: ZFS - <a href="https://www.goodreads.com/book/show/25595471-freebsd-mastery">https://www.goodreads.com/book/show/25595471-freebsd-mastery</a></li>
<li>Ubuntu Wiki - <a href="https://wiki.ubuntu.com/ZFS">https://wiki.ubuntu.com/ZFS</a></li>
<li>Zpool Administration - <a href="https://pthree.org/2012/04/17/install-zfs-on-debian-gnulinux/">https://pthree.org/2012/04/17/install-zfs-on-debian-gnulinux/</a></li>
<li>ZFS Build - <a href="http://www.zfsbuild.com/">http://www.zfsbuild.com/</a></li>
<li>ZFS Features and Terminology - <a href="https://www.freebsd.org/doc/handbook/zfs-term.html">https://www.freebsd.org/doc/handbook/zfs-term.html</a></li>
<li>Klennet Storage Software - <a href="https://www.klennet.com/zfs-recovery/zfs-basics.aspx">https://www.klennet.com/zfs-recovery/zfs-basics.aspx</a></li>
</ul>

  <hr>
<p><small>
    
      Last update:
      <span>2023-09-01</span>
      
        <br>
        Created:
        <span>2023-09-01</span>
      
    
  </small>
</p>


  




                
              </article>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Economists typically rely on bogus population data (105 pts)]]></title>
            <link>https://www.cambridge.org/core/journals/journal-of-economic-history/article/we-do-not-know-the-population-of-every-country-in-the-world-for-the-past-two-thousand-years/D747DDC6E499C799B0471DBE33FEB0BB</link>
            <guid>37387110</guid>
            <pubDate>Tue, 05 Sep 2023 02:14:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cambridge.org/core/journals/journal-of-economic-history/article/we-do-not-know-the-population-of-every-country-in-the-world-for-the-past-two-thousand-years/D747DDC6E499C799B0471DBE33FEB0BB">https://www.cambridge.org/core/journals/journal-of-economic-history/article/we-do-not-know-the-population-of-every-country-in-the-world-for-the-past-two-thousand-years/D747DDC6E499C799B0471DBE33FEB0BB</a>, See on <a href="https://news.ycombinator.com/item?id=37387110">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p> In the past 20 years, economists have estimated empirical exercises that rely in part on a published work that reports the population of every country in the world starting in the year 1 <span>ce</span> or even earlier. The existence of such data surprises those familiar with research on population history; we have only a rough idea of the population of most parts of the globe before 1500. For many countries, the statistical lacuna extends closer to the present. Until the advent of modern censuses, which in most countries started during the nineteenth century, reckonings of the total population for even the best-studied cases remain subject to considerable error.</p>
<p> These exercises typically rely on McEvedy and Jones’s <em>Atlas of World Population History</em> (hereafter MJ). Published in 1978, this work reports a population total for the countries of the world at intervals of a century or half-century. MJ did not disguise the rough nature of their data, as the epigraph notes, and we should distinguish what they report from the way others used their work. Several economists point to a U.S. Census Bureau summary that appears to endorse MJ’s estimates. The Bureau simply notes that MJ’s estimates for <em>world</em> population are not too different from the other, earlier results.<a href="#fn1"><span>Footnote </span><sup>1</sup></a> As MJ state (pp. 353–4), however, that agreement is largely by construction.</p>
<p> The drawbacks of using such data are numerous. MJ’s estimates, as they suggested themselves at the time of writing, lacked, in many cases, any firm foundation. Often, the estimates appear to reflect a judgment about the nature of the economy in question, rendering their use as economic proxies partially tautological. The MJ estimates are out-of-date for some countries; researchers have provided better figures in the past 40 years. Economists tend to dismiss measurement error issues by appealing to the implications of “classical” measurement error. MJ’s clearly stated rounding rules mean the measurement error is not classical. Non-classical measurement error create several opportunities for bias in regression models. Economists have compounded these weaknesses with unwise disaggregation practices.</p>
<p> Many economics articles, including several highly cited contributions in the leading journals, rely on MJ for econometric exercises. This research has appeared in the leading general-interest economics journals, in development and growth-oriented journals, and in the main field journals for economic history. Several of these papers have been cited many times.<a href="#fn2"><span>Footnote </span><sup>2</sup></a> The present paper raises serious questions about the results of any econometric exercise that relies on MJ.</p>
<p> If the correct population data were available, we could re-estimate specific models that appear in published papers and assess the consequences of the measurement-error problems discussed here. This is obviously not possible because we lack the correct data. What I do instead is study the way MJ assemble and round their estimates. This permits us to draw on econometric literature to understand the difference between a model estimated using MJ and a model estimated using corrected population data. I then discuss more specifically the way some economists have used this population data. A brief replication exercise using Nunn and Qian (<a href="#ref49">2011</a>) shows that some published results are not robust to careful consideration of the problems in the MJ data.</p>
<div data-magellan-destination="s1" id="s1">
<h2> THE SOURCE</h2>
<p> MJ report a series of graphs of total population in a country (or region), with labels at centuries or half-centuries. Figure&nbsp;<a href="#f1">1</a> reports the data for Germany in a format similar to the figures MJ use to present most of their estimates.<a href="#fn3"><span>Footnote </span><sup>3</sup></a> For the twentieth century and, in some cases, the nineteenth, MJ reproduce official census counts as discussed by earlier scholars, sometimes adjusted for changes in national boundaries.<a href="#fn4"><span>Footnote </span><sup>4</sup></a> Modern censuses did not start anywhere until the late eighteenth century and were not widespread until the nineteenth century.</p>
<div data-magellan-destination="f1" id="f1">
<p><img data-src="https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230831025512026-0954:S0022050723000293:S0022050723000293_fig1.png?pub-status=live" width="679" height="420" data-original-image="/binary/version/id/urn:cambridge.org:id:binary:20230831025512026-0954:S0022050723000293:S0022050723000293_fig1.png" data-zoomable="true" src="https://www.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230831025512026-0954:S0022050723000293:S0022050723000293_fig1.png"></p>
<div><p><span>Figure 1</span> THE POPULATION OF GERMANY 1 <span>ce</span>–1975 ACCORDING TO M<span>c</span>EVEDY AND JONES</p>
<p> <em>Notes</em>: Population figures are in millions, rounded by McEvedy and Jones as discussed in the text. Years are centuries until 1600, then include the years 1650, 1750, and 1850. The original figure is reproduced in Guinnane (<a href="#ref26"><span>Reference Guinnane</span>2021</a>, figure&nbsp;<a href="#f1">1</a>). I was unable to secure permission to reproduce that graph here.</p>
<p> <em>Sources</em>: McEvedy and Jones (<a href="#ref32"><span>Reference McEvedy and Jones</span>1978</a>, p. 69), from datafile provided by James Fenske.</p></div></div>
<p> One would think from reading the economics literature that MJ report precise numbers based on their analysis of earlier works. Graphs such as Figure&nbsp;<a href="#f1">1</a>, along with MJ’s descriptions, suggest a different picture. “There are almost no data on which to base a population estimate for Germany until we reach the late Middle Ages” (McEvedy and Jones <a href="#ref32"><span>Reference McEvedy and Jones</span>1978</a>, p. 70). “Estimates of Poland’s population before the 14<sup>th</sup> century are based on nothing more than general ideas about likely [population – T.G.] densities” (p. 76). For the Maghreb, “There is really nothing on which to base any calculations before the 19<sup>th</sup> century” (p. 220). These comments are admirably frank, but MJ do, in fact, report population totals for Germany, Poland, and the Maghreb, and economists have used those observations to test hypotheses we view as important. MJ include a bibliography for each group of population estimates, but they typically do not explain how they used the references they list. For Burma, they note that the quantitative record consists of a single publication based on a count of houses in 1783 as well as colonial censuses that began in 1871. Yet MJ report population sizes for that country as far back as 400 <span>bce</span> (pp. 190–92). This is not an isolated example. In discussing the western hemisphere, they refer to debates current at the time they wrote, but those debates suggested large ranges of estimates and pertain to the decades just prior to European contact. Yet MJ provide estimates for countries in this region going back many centuries. Most African entries have the same flavor; the only evidence MJ cites refers to the seventeenth century at the earliest, yet they report estimates for two full millennia.</p>
<p> Caldwell and Schindlmayr (<a href="#ref11"><span>Reference Caldwell and Schindlmayr</span>2002</a>, p. 200) emphasize the difficulty of useful population estimates for most of the world, and even for Europe before 1800. Population figures for the large areas of the globe that once fell under European colonial domination may be the hardest part of the problem. The essays on the Americas collected in Denevan (1992) document debates that continue. Carlos, Feir, and Redish (<a href="#ref12"><span>Reference Carlos, Feir and Redish</span>2022</a>, p. 522), for example, note that in the early twentieth century, estimates of the pre-contact population of North America north of Mexico City ranged from 1.2 to 18 million people. Later efforts narrowed that range to 1.2 to 6.1 million people. The demographic consequence of colonial contact is one measure of imperialism’s impact on indigenous peoples, so these population measures carry considerable interpretative weight. Continuing differences of opinion do not reflect a lack of research.<a href="#fn5"><span>Footnote </span><sup>5</sup></a></p>
<p> Systematic discussion of MJ has been limited, but specialists tend not to be impressed. As Austin (<a href="#ref8"><span>Reference Austin</span>2008</a>, p. 1102) puts it, “If you look up McEvedy and Jones expecting a treatise, detailing the original evidence and the reasoning behind the judgements by which it was converted into useable data, you will be disappointed.” In discussing one particular study that relies heavily on MJ, Austin (<a href="#ref8"><span>Reference Austin</span>2008</a>, p. 1002) says that “there is simply no epistemological basis for Nunn’s use of the word ‘data’ – literally, ‘things that are given’ or granted – to refer to the guesses that have been made about the population of future African countries in 1400.”<a href="#fn6"><span>Footnote </span><sup>6</sup></a></p>
<p> MJ’s effort reflects a long interest in the world’s population from distant times. MJ draw on these earlier efforts, which include Clark (<a href="#ref13"><span>Reference Clark</span>1968</a>) and Durand (<a href="#ref19"><span>Reference Durand</span>1974</a>). (Online Appendix Table A.1 summarizes the leading examples.) Caldwell and Schindlmayr (<a href="#ref11"><span>Reference Caldwell and Schindlmayr</span>2002</a>) discuss the intellectual history of these research projects, stressing their skepticism about the apparent consensus in the figures. MJ’s effort differs from their predecessors in one important respect: the earlier estimates pertain to large regions or continents. MJ usually report populations for the areas that correspond to modern nation-states.</p>
<p> How did MJ derive population estimates from before, as they say, there was anything on which to base such estimates? Reading their descriptions and examining the figures suggests four overlapping approaches. In some cases, they state explicitly their reliance on one of these approaches, but more often, their method only reveals itself in the estimates. First, they start with the earliest official census and work backward. What Clark (<a href="#ref13"><span>Reference Clark</span>1968</a>, p. 61) calls “jobbing back” can yield good population estimates given the right raw materials and technique. The population of a country in 1500 equals its 1600 population minus deaths and net emigrants, plus births in the period 1500–1600. Wrigley and Schofield (<a href="#ref42"><span>Reference Wrigley and Schofield</span>1981</a>, chapter 7) offer an example of this approach. They start with the reliable census of England and Wales for 1841 and work back in time using estimates of births and deaths, along with more speculative estimates of net migration, to produce annual populations back to 1541. The challenge for earlier periods is that we rarely have anything like good counts of births and deaths, much less migrants, and the effort demands attention to complex sources. Creating the vital events series was the heart of Wrigley and Schofield’s project.<a href="#fn7"><span>Footnote </span><sup>7</sup></a></p>
<p> Austin (<a href="#ref8"><span>Reference Austin</span>2008</a>, p. 1002) stresses that momentous historical events such as the rise of the Atlantic slave trade greatly complicate such efforts. Few areas of the globe have been entirely spared these destabilizing episodes. Sometimes we even lack the equivalent of a reliable end-period enumeration, such as the 1841 census for England and Wales. Recent efforts to improve historical African population counts provide better-reasoned figures than MJ’s for that continent, but run into a source problem. The twentieth-century colonial censuses that form their end-period figure are themselves not terribly reliable. In addition, for Africa, we lack the sources that would allow us to estimate the earlier population increases needed for useful “jobbing back.”<a href="#fn8"><span>Footnote </span><sup>8</sup></a></p>
<p> A hint comes from the suspiciously round progression of population figures for single countries.<a href="#fn9"><span>Footnote </span><sup>9</sup></a> Table&nbsp;<a href="#tbl1">1</a> shows the overall patterns; in many cases, MJ apparently devised a population estimate after deciding on a round figure for percentage growth. The many commonalities across countries are implausible. Individual country histories drive home the problem. In MJ’s reckoning, England’s population grew by 750,000 between 1600 and 1650, and by another 750,000 in the next half-century (McEvedy and Jones <a href="#ref32"><span>Reference McEvedy and Jones</span>1978</a>, p. 43). Austria added 250,000 people every 50 years between 1650 and 1800 (pp. 88–92). Thailand added 250,000 people in both the sixteenth and seventeenth centuries (p. 193). Burma’s population growth during the same period was 500,000 per century.</p>
<div data-magellan-destination="tbl1" id="tbl1">
<p><span>Table 1</span> SUMMARY OF INTER-PERIOD PERCENTAGE CHANGES IN MJ</p>
<p><span>
<p><img data-src="https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230831025512026-0954:S0022050723000293:S0022050723000293_tab1.png?pub-status=live" width="1142" height="266" data-original-image="/binary/version/id/urn:cambridge.org:id:binary:20230831025512026-0954:S0022050723000293:S0022050723000293_tab1.png" data-zoomable="true" src="https://www.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230831025512026-0954:S0022050723000293:S0022050723000293_tab1.png"></p>
</span></p>
</div>
<p> Second, MJ apparently wanted their estimates to reflect their view that until the late medieval period, population grew at a constant rate. In disagreeing with an earlier author on the right total world population for the year 1000, MJ note that “our figure for AD 1, being 100m below the agreed figure for AD 1000, fits better on the sort of exponentially rising curve that everyone agrees best describes mankind’s population growth” (p. 354). As the quotation implies, MJ also worried about consistency between theirs and earlier estimates. Caldwell and Schindlmayr (<a href="#ref11"><span>Reference Caldwell and Schindlmayr</span>2002</a>, p. 199) call this “an example of a dangerous circularity,” while Biraben dismisses the MJ data after noting this fact.<a href="#fn10"><span>Footnote </span><sup>10</sup></a></p>
<p> Third, in the face of ignorance, MJ felt comfortable assigning identical growth rates to places they thought were similar. This practice doubtless underlies much of what we see in Table&nbsp;<a href="#tbl1">1</a>. For 35 percent of countries, MJ assign the same figure to population growth between the years 1 and 1000.</p>
<p> Finally, especially before 1500, MJ tended to reason from the nature of an economy and the population they thought it could support. They are rarely explicit about this tactic, but it shows through remarks such as “likely population densities” in the passage about Poland quoted earlier. To the extent that they estimate population in this way, MJ’s figures reflect not the population of a particular country at a point in time, but their views about the population density consistent with the kind of economy MJ thought the country had. Since they do not claim any serious knowledge of the economy or of the number of people it can support, the basis for this reasoning is unclear.<a href="#fn11"><span>Footnote </span><sup>11</sup></a></p>
<div data-magellan-destination="s1-1" id="s1-1">
<h3> Maddison</h3>
<p> Several of the articles discussed later rely in part on estimates reported by the late Angus Maddison. Maddison famously constructed, updated, and used a database that offered estimates of population and GDP/capita for most of the world’s countries, again, in some versions, going as far back as the year 1 <span>ce</span>.<a href="#fn12"><span>Footnote </span><sup>12</sup></a> For the last major revision of his estimates, Maddison says of his population data: “The following detailed estimates for 1500 onwards rely heavily on monographic country studies for the major countries. To fill holes in my dataset I draw on McEvedy and Jones (<a href="#ref32"><span>Reference McEvedy and Jones</span>1978</a>). For the preceding millennium and a half, I use their work extensively” (Maddison <a href="#ref30"><span>Reference Maddison</span>2001</a>, p. 230). Maddison adds that he relies on MJ rather than earlier accounts because MJ are “the most detailed and best documented” (p. 230).</p>
<p> Thus, for many places before 1500, Maddison’s database just reproduces MJ’s figures. This is not always the case, however; Maddison was able to incorporate the fruits of research published between 1978 and his own publication. This led to some substantive revisions, but those revisions reflect the research literature’s emphasis. He updated 23 percent of MJ’s observations for the year 1000, for example, and 40 percent of the observations for 1500. The majority of Maddison’s changes for the year 1000 were in non-European countries (eight of nine countries that changed were outside Europe). For 1500, this pattern changes; 10 of 16 changes are for European countries, and in 1700, 8 of 12 are for Europe. These changes reflect contributions from the research literature.</p>
<p> Some individual changes are much larger, however. Maddison added 50 percent to Mexico’s population for the year 1000, and he doubled Peru’s population in that same year (Maddison <a href="#ref30"><span>Reference Maddison</span>2001</a>, table B-5, p. 235). He increased the population of the territory that would become the United States by 125 percent for the year 1500. For later periods, especially in the twentieth century, Maddison revises the MJ estimates more comprehensively. In 1850, 84 percent of Maddison’s 51 observations have values different from MJ’s, although the average absolute difference (3 percent) is smaller than for earlier years.<a href="#fn13"><span>Footnote </span><sup>13</sup></a></p>
</div>
</div>
<div data-magellan-destination="s2" id="s2">
<h2> MEASUREMENT ERROR AND ROUNDING</h2>
<p> Relative to “perfect” data for every country in the world, how far wrong will MJ take us? It is worth reviewing some general consequences of measurement error for the kinds of linear models that most researchers use.<a href="#fn14"><span>Footnote </span><sup>14</sup></a> Denote the true population of country <em>i</em> in year <em>t</em> as Ṗ<sub><em>it</em></sub>. The MJ estimate is P<sub><em>it</em></sub>. The difference between MJ’s estimate and the true population is the measurement error <em>ε</em> <sub><em>it</em></sub>, such that P<sub><em>it</em></sub> = Ṗ<sub><em>it</em></sub> + <em>ε</em> <sub><em>it</em></sub>. Classical measurement error is the special cases where <em>ε</em> <sub><em>it</em></sub> is additive and uncorrelated with Ṗ<sub><em>it</em></sub>. We have two general implications. First, classical measurement error in the dependent variable alone does not bias estimates. The <em>ε</em> <sub>it</sub> are swept into the regression error term, and the only consequence is some efficiency loss. Second, measurement error in <em>any</em> regressor implies bias in <em>all</em> of the estimates.</p>
<p> Consider the following regression:
</p><p><span>(1)</span>
<span>
<img data-src="https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230831025512026-0954:S0022050723000293:S0022050723000293_eqn1.png?pub-status=live" width="235" height="25" data-original-image="/binary/version/id/urn:cambridge.org:id:binary:20230831025512026-0954:S0022050723000293:S0022050723000293_eqn1.png" data-zoomable="false" src="https://www.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230831025512026-0954:S0022050723000293:S0022050723000293_eqn1.png">
<span data-mathjax-type="texmath"><span>
$\[{{\rm{Y}}_{{\rm{it}}}}{\rm{ = \alpha + \beta }}{{\rm{X}}_{{\rm{it}}}}{\rm{ + \gamma }}{{\rm{P}}_{it}}{\rm{ + }}{{\rm{\mu }}_{{\rm{it}}}}{\rm{,}}\]$
</span></span>
</span>
</p>
<p> where P<sub><em>it</em></sub> is the mis-measured variable. While I write Equation (<a href="#disp1">1</a>) for a panel framework, that is not necessary for what follows. Classical measurement error in P<sub><em>it</em></sub> implies that the estimate for γ will be smaller in absolute value than it would be if we could use Ṗ<sub><em>it</em></sub> instead. The estimate is attenuated. The estimate for β will also be biased in ways we cannot ordinarily sign. The problem arises from the correlation between the measurement error <em>ε</em> <sub><em>it</em></sub> and the regression error term μ<sub>it</sub>, which is why some researchers employ instrumental-variable techniques in using the MJ data as a regressor. The fixed-effects estimator does not necessarily yield unbiased estimates in the presence of even classical measurement error. Fixed effects only “deals with” measurement error if the errors in P<sub>it</sub> are, for each country <em>i</em>, the same for all years. In that case, the measurement error becomes part of the estimated country fixed effects (Deaton <a href="#ref16"><span>Reference Deaton</span>1997</a>, pp. 108–110).<a href="#fn15"><span>Footnote </span><sup>15</sup></a></p>
<p> Classical measurement error in the dependent variable ordinarily does not bias regression estimates because the measurement error is added to the regression disturbance term. This result requires that the measurement error be additive: P<sub><em>it</em></sub> = Ṗ<sub><em>it</em></sub> + <em>ε</em> <sub><em>it</em></sub>. One common case of non-additive measurement error appears when the dependent variable is the ratio of two variables and the denominator is measured with error. Consider a common example: an urbanization figure is formed as the number of people living in cities divided by MJ’s population estimate. Rewriting Equation (<a href="#disp1">1</a>),
</p><p><span>(2)</span>
<span>
<img data-src="https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230831025512026-0954:S0022050723000293:S0022050723000293_eqn2.png?pub-status=live" width="216" height="25" data-original-image="/binary/version/id/urn:cambridge.org:id:binary:20230831025512026-0954:S0022050723000293:S0022050723000293_eqn2.png" data-zoomable="false" src="https://www.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230831025512026-0954:S0022050723000293:S0022050723000293_eqn2.png">
<span data-mathjax-type="texmath"><span>
$\[{{\rm{C}}_{{\rm{it}}}}{\rm{/}}{{\rm{P}}_{it}}{\rm{ = \alpha + \beta }}{{\rm{X}}_{{\rm{it}}}}{\rm{ + }}{{\rm{\mu }}_{{\rm{it}}}}{\rm{,}}\]$
</span></span>
</span>
</p>
<p> where C<sub>it</sub> is the urban population. Using MJ’s population estimate implies that the denominator is the true population plus measurement error, P<sub><em>it</em></sub> = Ṗ<sub><em>it</em></sub> + <em>ε</em> <sub><em>it</em></sub>. Substituting and re-arranging, we have:
</p><p><span>(3)</span>
<span>
<img data-src="https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230831025512026-0954:S0022050723000293:S0022050723000293_eqn3.png?pub-status=live" width="418" height="27" data-original-image="/binary/version/id/urn:cambridge.org:id:binary:20230831025512026-0954:S0022050723000293:S0022050723000293_eqn3.png" data-zoomable="false" src="https://www.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230831025512026-0954:S0022050723000293:S0022050723000293_eqn3.png">
<span data-mathjax-type="texmath"><span>
$\[{{\rm{C}}_{it}} + {\rm{\alpha }}({{\rm{\dot P}}_{it}} + {\varepsilon _{it}}) + {\rm{\beta }}{{\rm{X}}_{{\rm{it}}}}({{\rm{\dot P}}_{it}} + {\varepsilon _{it}}) + {\mu _{{\rm{it}}}}({{\rm{\dot P}}_{it}} + {\varepsilon _{it}})\]$
</span></span>
</span>
</p>
<p> The ratio in the original dependent variable makes the measurement error multiplicative and causes bias in estimates of β. More generally, if measurement error is not classical, then we need to model the error. Hyslop and Imbens (<a href="#ref28"><span>Reference Hyslop and Imbens</span>2001</a>) discuss several cases, including one where measurement error in a regressor leads to overestimates of that coefficient instead of the attenuation we expect with classical measurement error.</p>
<p> What does this mean for econometric studies that used mis-measured population estimates? If we maintain the assumption that the measurement error is classical, we can say two things. When population is the dependent variable, the estimates may be less efficient, but there should be no bias due to measurement error alone. If population is a regressor, on the other hand, then the estimate for population will be attenuated. Additionally, the other estimates in this case will be biased and inconsistent. Thus, using population as a “control” can lead to bias even for variables not thought to suffer from measurement error. If the error is not classical, on the other hand, then we cannot say much without modeling the measurement error.</p>
<p> While economists tend to assume that measurement error is always classical, in this case, we know that this is not the case. MJ state that they have rounded their estimates in ways that make the measurement error depend on the true value. This rounding applies to every country and every period, but the rounding rule depends on the population size. This means the measurement error depends on population size:</p><p> All figures are rounded on the following system: below one million to the nearest .1 million, between one and 10 millions to the nearest .25 million, between 10 and 20 million to the nearest .5 million and between 20 and 100 millions to the nearest million. Above 100 million the rounding is to the nearest 5 million, above a billion… to the nearest 25 million. (McEvedy and Jones <a href="#ref32"><span>Reference McEvedy and Jones</span>1978</a>, p. 9)</p>
<p> Thus, MJ tell us that they create measurement error that is larger for larger populations. We cannot know precisely the implications of MJ’s rounding rules. We can, however, simulate the “true” populations to get a feel for how much trouble the rounding can cause. I use a Monte Carlo exercise to simulate the rounded-off portion of each population estimate. Adding that rounded portion to MJ’s reported numbers yields a simulated “true” population. We can then ask whether that simulated “true” population is correlated with the error caused by rounding. This exercise can only address the measurement error caused by rounding; the other flaws remain. Table&nbsp;<a href="#tbl2">2</a> shows the result: the rounding induces a high degree of correlation between the measurement error and the population. This result holds for four different assumed functional forms for the rounding error, including two that are asymmetric in different ways. The correlation stems from MJ’s different rules for different size categories.</p>
<div data-magellan-destination="tbl2" id="tbl2">
<p><span>Table 2</span> SIMULATING UNROUNDED FIGURES IN MJ’S DATA</p>
<p><span>
<p><img data-src="https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230831025512026-0954:S0022050723000293:S0022050723000293_tab2.png?pub-status=live" width="695" height="388" data-original-image="/binary/version/id/urn:cambridge.org:id:binary:20230831025512026-0954:S0022050723000293:S0022050723000293_tab2.png" data-zoomable="true" src="https://www.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230831025512026-0954:S0022050723000293:S0022050723000293_tab2.png"></p>
</span></p>
</div>
<p> Online Appendix Section 2 reports details of this simulation along with two additional assessments of the importance of this rounding. The first uses the populations of the 50 United States for the period 1900–1970. The second uses the populations of countries around the world for the period 1960–2020. In both cases, I apply MJ’s rounding rules and examine the correlation between the true values and the errors created by rounding. Rounding for the U.S. states does not consistently imply correlation, while for the countries of the world, the correlation between the true value and the measurement error is considerable. The countries dataset is the closer analogy to MJ because the countries span the entire range of their rounding rules.</p>
<p> MJ’s rounding procedure creates a distinct problem when a country’s population crosses one of the thresholds implied by their rounding rule. Portugal, they report, had a population of 900,000 in 1400 and 1.25 million in 1500 (p. 103). These figures imply that Portugal’s population increased by 350,000 people, or 39 percent, in those 100 years. Taking the rounding into account, however, implies upper and lower bounds for the population estimate in both 1400 and 1500. The true increase could be as small as 19 percent or as great as 58 percent.</p>
<p> The non-classical nature of the measurement error in MJ poses a serious problem for any estimates that rely on it. We can evaluate earlier, published work under the assumption of classical measurement error, and that is not a bad place to start. But MJ’s rounding applies to every country and period in their data, which means that none of the standard intuitions based on classical measurement error really apply.</p>
</div>
<div data-magellan-destination="s3" id="s3">
<h2> CIRCULARITY</h2>
<p> Many economists who use MJ’s figures think of population (or a derivative such as population density) as a proxy for an economic aggregate such as output. Critics such as Caldwell and Schindlmayr (<a href="#ref11"><span>Reference Caldwell and Schindlmayr</span>2002</a>) and Austin (<a href="#ref8"><span>Reference Austin</span>2008</a>) note MJ often use ideas about the economy to derive an estimate of population size, thus making the population estimates a poor proxy for an economic aggregate. This is especially true in places and times for which the population data are thin. As noted, MJ defend an estimate for medieval Poland by referring to “likely population densities.” In a more explicit example, MJ discuss agricultural conditions in a region that comprises the modern states of Columbia, Venezuela, and the Guyanas to defend their assumption that until 1500, Colombia always accounted for 2/3 of the region’s population (McEvedy and Jones <a href="#ref32"><span>Reference McEvedy and Jones</span>1978</a>, p. 302).</p>
<p> Austin stresses that this approach makes their estimates hostage to ideas about an economy and economic change. It is a particular problem for Africa because we know relatively little about that continent’s economic history. Maddison (<a href="#ref30"><span>Reference Maddison</span>2001</a>, p. 238), for example, adopts MJ’s estimates for Africa in preference to earlier alternatives because MJ “assumed a more dynamic growth process.” That is, Maddison preferred MJ’s <em>population</em> estimates because he agreed with their assessment of the African <em>economy</em>. Neither Maddison nor MJ offer independent evidence about the African economy. To the extent MJ assigned population estimates based on their perceptions of economic performance, a regression using population as a proxy for growth tells us more about MJ than about economic growth.</p>
</div>
<div data-magellan-destination="s4" id="s4">
<h2> SOFT CLONES</h2>
<p> Researchers who use MJ’s data treat them as if they imply independent observations; put differently, if there are N countries listed for a given year, this reflects N pieces of information. This is not always true, for two distinct reasons that I will call “soft” and “hard” clones. MJ themselves create the soft clones. Frankly admitting that they lack meaningful data, they assign to some countries the population dynamics of countries they think are similar. Sometimes they make this approach explicit. After concluding that Afghanistan has no useful population data before the twentieth century, MJ say that “Perhaps the best approach is to compare Afghanistan with Iran” (McEvedy and Jones <a href="#ref32"><span>Reference McEvedy and Jones</span>1978</a>, p. 156). What they did, in fact, was to assume that Afghanistan had half the population of Iran in every year before 1900. The measurement error for Afghanistan thus has two sources. The Afghan numbers share any measurement error in the figures for Iran, and they also suffer from the error implied by any deviation of Afghanistan’s true population dynamics from Iran’s.</p>
<p> MJ includes many soft clones. Kenya and Uganda, for example, had identical populations through 1800, although the text does not say why. In some cases, they appeal to the idea that neighboring countries should have similar population growth rates: “… the fact that population doubled in most European countries between A.D. 1000 and 1300 can be taken as strong evidence for it doing so in other European countries for which direct evidence is lacking” (p. 11). Thus, in their reckoning, Poland, Hungary, and Czechoslovakia each grew 20 percent between 1000 and 1100. In the fifteenth century, European Russia and China each grew by one-third. As late as 1600–1700, Romania and Austria each grew by 11.11 percent. Soft clones probably underlie the patterns we see in Table&nbsp;<a href="#tbl1">1</a>.</p>
</div>
<div data-magellan-destination="s5" id="s5">
<h2> HARD CLONES</h2>
<p> A final problem reflects both MJ’s estimates and the way some economists have used them. MJ report many populations for regions rather than modern countries. Some economists create country-level populations out of the regions by allocating the regional population among the constituent modern nation-states. I will call the resulting countries “hard clones.” In the cross-section, these clones differ in size within the region. By construction, however, in the time series, all members of a clone group share the population growth rate MJ assigned to the region. Hard clones account for an especially large portion of the African country-level observations, but they appear in other parts of the world, as well. In Nunn and Qian (<a href="#ref49">2011</a>), hard clones account for 76 percent of the observations in Africa, 36 percent in Europe, and 41 percent in Asia. In Ashraf and Galor (<a href="#ref6"><span>Reference Ashraf and Galor</span>2011</a>), the clones are similar for these continents; three-quarters of their Western Hemisphere countries are clones.<a href="#fn16"><span>Footnote </span><sup>16</sup></a></p>
<p> The literature includes two different ways to create countries out of regions. Nunn (<a href="#ref33"><span>Reference Nunn</span>2008</a>, p. 170) assumes that the relative sizes of the populations within each region are the same as reported for 1950. Nunn and Qian (<a href="#ref49">2011</a>) do not say explicitly how they disaggregated the regions, but for most countries, their population figures are similar to Nunn’s, so the approach is probably similar.<a href="#fn17"><span>Footnote </span><sup>17</sup></a> Ashraf and Galor (<a href="#ref6"><span>Reference Ashraf and Galor</span>2011</a>, <a href="#ref7"><span>Reference Ashraf and Galor</span>2013</a>) disaggregate the regions by assuming that each country within a region has the same population density in each year. In general, the resulting “country” populations created by the two methods differ in the cross-section; Nunn and Qian’s Nigeria in 1500 is not the same size as Ashraf and Galor’s. Yet both cloning methods imply that Nigeria has the same growth rate between any two years. This growth rate is simply the rate implicit in the region from which Nigeria is cloned.</p>
<p> Hard cloning adds further error to MJ’s guesses; how much is something we cannot say precisely because we do not know the true populations of the clones in those years. We can, however, study the implications of these two methods in contexts where we have the equivalent of valid country-level numbers. For the years 1900–1970, I constructed a panel from the population of the 50 United States as reported in the decennial census. I then aggregate the state populations into four standard regions. The state populations (which we know) are analogous to the unknown country populations that hard cloning attempts to recover. The U.S. regions are like the regions in the MJ book. I apply both the Nunn-Qian and Ashraf-Galor methods to estimating the population of each state in the period 1900–1960, as if all I knew was the population of each state in 1970 (for Nunn-Qian) and the state area and regional population in each year 1900–1970 (Ashraf-Galor). Table&nbsp;<a href="#tbl3">3</a> summarizes the errors these methods produce. In most years, the Nunn-Qian approach produces smaller errors than Ashraf-Galor, although those errors are still large. Only in 1960 did the median error from the Nunn-Qian approach fall below 5 percent of the actual state population. The Ashraf-Galor approach produces a smaller median error in the early years, but the variance of the errors using this method is large. The two types of error are not highly correlated in the cross-section.<a href="#fn18"><span>Footnote </span><sup>18</sup></a></p>
<div data-magellan-destination="tbl3" id="tbl3">
<p><span>Table 3</span> THE ERRORS CREATED BY APPLYING HARD CLONE METHODOLOGY TO U.S. STATES, 1900–1970</p>
<p><span>
<p><img data-src="https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230831025512026-0954:S0022050723000293:S0022050723000293_tab3.png?pub-status=live" width="696" height="288" data-original-image="/binary/version/id/urn:cambridge.org:id:binary:20230831025512026-0954:S0022050723000293:S0022050723000293_tab3.png" data-zoomable="true" src="https://www.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230831025512026-0954:S0022050723000293:S0022050723000293_tab3.png"></p>
</span></p>
</div>
<p> What does this exercise tell us about disaggregating MJ’s regions? The Nunn-Qian method assumes that population growth rates within each region are similar over time. The method goes wrong for regions with a state like California, which experienced especially rapid growth in the twentieth century. In 1900, California’s population accounted for 34 percent of the “West” region; in 1970, it was 57 percent. This is probably why the Nunn-Qian approach improves monotonically better over time; the 1970s weights better approximate the population distribution in 1960 than in 1900. It also illustrates the danger of their research, which starts with MJ’s estimates for 1000. Between the years 1000 and 1950, there was plenty of opportunity for the countries within a region to grow at different rates, producing a version of the problem noted for California.<a href="#fn19"><span>Footnote </span><sup>19</sup></a> Ashraf and Galor’s approach, on the other hand, requires that the population densities for countries within a region be identical. This approach fares poorly in the U.S. case because of the unequal population densities within some U.S. regions; the “Midwest” region, for example, includes states like Ohio (204 persons per square mile in 1900) as well as states like North Dakota (nine persons per square mile). The assumption is unlikely to hold at any point in time, and the discrepancy between assumption and reality could change over time with the introduction of new crops or other changes that lead to uneven economic development within the region. The U.S. experience may not provide a strict analogy to the regions these two methods attempt to disaggregate, but this exercise highlights how far wrong things can go if strong assumptions do not hold. The U.S. case also highlights the questions that we would need to ask before disaggregating data in this way. Do we really know enough about the sub-regional patterns in the Sahel in 1000, for example, to divide up a regional population?</p>
<p> The hard clones play an especially important role in Africa. MJ report only 12 regions for Africa. Nunn (<a href="#ref33"><span>Reference Nunn</span>2008</a>)’s Africa has 52 countries, while Nunn and Qian (<a href="#ref49">2011</a>)’s have 47.<a href="#fn20"><span>Footnote </span><sup>20</sup></a> Three-quarters of the African observations are thus clones. Given the difference in methods, we expect Nunn-Qian and Ashraf-Galor to assign different populations to the same country, but the differences can be huge. Online Appendix Figure&nbsp;<a href="#f1">1</a> reports the distribution of the ratio of Ashraf-Galor’s clones to Nunn-Qian’s for the Old World in 1500. This figure illustrates the great range in values for a given place and time that result from cloning the MJ regions. In Africa, this ratio ranges from .192 (Malawi) to .61 (Nigeria) through South Africa (1.003) to Congo (2.208) and Côte d’Ivoire (2.887).<a href="#fn21"><span>Footnote </span><sup>21</sup></a></p>
<p> The disaggregation problems account for only one of two different sources of measurement error for hard clones. The first comes from MJ itself; MJ’s regional estimates are themselves noisy and rounded. Cloning assigns that noise to each of the country-level figures and adds additional error because we do not really know what the right allocations within a region should be. This additional disaggregation error is, by definition, negatively correlated for countries within a given MJ region and year. The cloned population estimates cannot be “correct.” The implications for change over time, however, are the same: every clone from a given region <em>must</em> grow at the same rate, the growth rate MJ assigned to the region. Breaking these regions up into observations does not create more information. It just creates clones.</p>
<div data-magellan-destination="s5-1" id="s5-1">
<h3> Econometric Implications of Hard Clones</h3>
<p> We cannot re-estimate earlier models using correct population data because that is obviously not available. The best check on the implications of cloning would be to dispense with the disaggregation and re-estimate the models using the units MJ reported. Since that check would require redefinition of all the other variables as well, it lies beyond the scope of this paper. We can, however, show that relying on clones significantly affects the results of published research. The following discussion only considers two cases and focuses on this issue alone. Table&nbsp;<a href="#tbl4">4</a> considers the baseline results from Nunn and Qian (<a href="#ref49">2011</a>), which studies the old question of whether the potato’s introduction in the Old World caused population growth. The regressions use the population of all countries in the Old World at century intervals between 1000 and 1900, along with the years 1750 and 1850. The dependent variable is always population. Although they report and discuss other specifications, Nunn and Qian focus on models in which the regressor of interest is the interaction between an index of the fraction of a country’s land that is suitable for potato cultivation and a dummy for the years 1750 and later. They regard this interaction as a proxy for the effect of the potato’s actual introduction.<a href="#fn22"><span>Footnote </span><sup>22</sup></a> Every specification includes year and country fixed effects. Some models have no additional controls; we focus on models that include the “baseline” controls.</p>
<div data-magellan-destination="tbl4" id="tbl4">
<p><span>Table 4</span> THE ECONOMETRIC CONSEQUENCES OF HARD CLONES</p>
<p><span>
<p><img data-src="https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230831025512026-0954:S0022050723000293:S0022050723000293_tab4.png?pub-status=live" width="1143" height="292" data-original-image="/binary/version/id/urn:cambridge.org:id:binary:20230831025512026-0954:S0022050723000293:S0022050723000293_tab4.png" data-zoomable="true" src="https://www.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20230831025512026-0954:S0022050723000293:S0022050723000293_tab4.png"></p>
</span></p>
</div>
<p> Table&nbsp;<a href="#tbl4">4</a>, Column (1), reproduces the result from Nunn and Qian (<a href="#ref49">2011</a>, table IV, column (1)). As they stress, the interaction implies that the potato’s introduction increased population sizes in the years 1750 and later. When we drop the African clones (Column (2)), however, the point estimate (and the average marginal effect) are no longer significantly different from zero. Dropping all clones (Column (3)) does not produce this effect; the problem appears to be the African clones. On the other hand, if we drop all of Africa (Column (4)), the point estimate and average marginal effect (AME) become even smaller. Given that about three-quarters of the African observations are clones, it is difficult to know whether Africa in general does not fit the story or if there is something particular to African clones.</p>
<p> The next three specifications repeat (2)–(4) using Nunn and Qian’s data but use the Ashraf-Galor definition of clones. The results differ somewhat, but the overall message is the same. In this model, it does not matter how we construct the clones; dropping Africa’s clones, all clones, or all of Africa has the same effect as with Nunn and Qian’s definition. Table&nbsp;<a href="#tbl4">4</a> holds two lessons. First, the Nunn-Qian result depends critically on the inclusion of Africa or its clones. This may not hold for all of Nunn and Qian’s specifications, although Online Appendix Section 4 demonstrates the same problem in their fully flexible approach. Second, and more generally, in this example, it does not much matter how we construct the hard clones. This follows from including country-level fixed effects. Since identification comes from within-country change and since the clones, however constructed, all have the same growth rates as the regions from which they are disaggregated, in this type of model, the error created by cloning does not depend on how the clones are constructed.<a href="#fn23"><span>Footnote </span><sup>23</sup></a></p>
<p> Fixed-effects models cannot cure measurement error in general, as I stressed earlier. Even the countries that are not clones in the Nunn-Qian or Ashraf-Galor datasets have rounding error plus the measurement error inherent in MJ’s guesses. This replication exercise makes a narrow and specific point. I have shown that first, Nunn and Qian’s results depend on including African observations that are really clones, and second, there is no important difference between the additional measurement error created by two different ways of creating hard clones.<a href="#fn24"><span>Footnote </span><sup>24</sup></a> Surely those who will rely on MJ in the future should at least dispense with the clones and use as their units of analysis the regions that appear in the population data.</p>
</div>
</div>
<div data-magellan-destination="s6" id="s6">
<h2> HOW ECONOMISTS USE MJ</h2>
<p> To obtain a more specific idea of how economists use these data, I examined every paper that cites MJ that was published in one of the “Top 5” economics journals through 2020.<a href="#fn25"><span>Footnote </span><sup>25</sup></a> I set aside many of these papers for the rest of this discussion. This list includes a few articles that cite MJ but do not use the data in econometric exercises. Shiue and Keller (<a href="#ref38"><span>Reference Shiue and Keller</span>2007</a>, p. 1194), for example, cite MJ and other authorities as implying that their two regions, China and Europe, had similar populations at the end of the eighteenth century. Rogers (<a href="#ref37"><span>Reference Rogers</span>1994</a>, p. 467) cites MJ to defend the assumption that long-term population growth rates were nearly zero until relatively recently. This usage seems consistent with the spirit in which MJ offer their estimates. I also set aside papers that only use MJ’s estimates for 1900 and later. By that date, the information MJ reports comes almost entirely from reasonable census reports (although they round even these figures). This includes articles such as Acemoğlu, Johnson, and Robinson (<a href="#ref2"><span>Reference Acemoğlu, Johnson and Robinson</span>2001</a>).<a href="#fn26"><span>Footnote </span><sup>26</sup></a></p>
<p> A first question pertains to dates; the MJ data are more suspect in earlier periods. The year 1500 does not form a magical dividing line, but it is the earliest year for which we have anything like reliable estimates for populations of even most European countries, which tend to have the best-founded estimates. Several articles depend in a serious way on MJ’s population estimates from before 1500. Ashraf and Galor (<a href="#ref6"><span>Reference Ashraf and Galor</span>2011</a>) report econometric results that depend critically on population data from the years 1, 1000, and 1500. Population is the variable of interest in Nunn and Qian (<a href="#ref49">2011</a>), which starts with the year 1000. Nunn (<a href="#ref33"><span>Reference Nunn</span>2008</a>) uses the 1400 estimates alone.<a href="#fn27"><span>Footnote </span><sup>27</sup></a> Several other papers also rely on data from 1500–1800.</p>
<p> A second issue is whether MJ’s population figures form the dependent variable or a regressor. Many articles use population as the dependent variable, where it does least harm under the assumption of classical measurement error. These include Ashraf and Galor (<a href="#ref6"><span>Reference Ashraf and Galor</span>2011</a>, <a href="#ref7"><span>Reference Ashraf and Galor</span>2013</a>) and Nunn and Qian (<a href="#ref49">2011</a>).<a href="#fn28"><span>Footnote </span><sup>28</sup></a> In others, the MJ data scale the dependent variable. As noted previously, this means the measurement error in the dependent variable is not classical, and the estimates are biased in unpredictable ways. Acemoğlu, Johnson, and Robinson (<a href="#ref4"><span>Reference Acemoğlu, Johnson and Robinson</span>2005</a>)’s urbanization regressions are an example.</p>
<p> Some articles, however, create regressors from MJ’s estimates. This list includes Iyigun (<a href="#ref29"><span>Reference Iyigun</span>2008</a>) as well as Gennaioli and Voth (<a href="#ref22"><span>Reference Gennaioli and Voth</span>2015</a>). Iyigun (<a href="#ref29"><span>Reference Iyigun</span>2008</a>) studies whether military pressure from the Ottoman Empire helped reduce conflict among European states in the early-modern period. The econometric models rely on annual observations for the period 1450–1700. The dependent variables measure intra-European conflict. The controls include measures of Ottoman military pressure as well as the populations of Europe and, in some specifications, the Ottoman Empire’s. Iyigun (<a href="#ref29"><span>Reference Iyigun</span>2008</a>, p. 1476) describes the population data as a proxy for economic “size and strength.” The estimated effect for European population size is imprecisely estimated in most specifications, while the Ottoman population variable is more precisely estimated but switches signs, depending on the dependent variable. The point estimates for both population variables <em>must</em> be attenuated if this is classical measurement error, so we cannot really say whether Europe became more peaceful simply because of economic growth, nor can we assess the implications of Ottoman economic conditions for European conflict. Moreover, the estimates for his main variable of interest, the extent of Ottoman military incursions into Europe, may be biased because of the measurement error in population.</p>
<p> Gennaioli and Voth (<a href="#ref22"><span>Reference Gennaioli and Voth</span>2015</a>, table&nbsp;<a href="#tbl3">3</a>) address a related question, and their population figures cause similar trouble. They study the determinants of battle success in early-modern European conflicts. The authors set this up as a horse race between fiscal strength on the one hand and population size on the other. Greater fiscal strength allows a state to pay more mercenaries and support more allies. Population size could matter in early-modern war because larger populations make it easier to field larger armies. In most specifications, the fiscal variable has a positive and significant effect on battlefield success, while the relative populations of the two combatants have almost none. They conclude that “Differences in population size do not have a systematic effect on the chance of battlefield success” (Gennaioli and Voth <a href="#ref22"><span>Reference Gennaioli and Voth</span>2015</a>, p. 1430). This result could reflect nothing more than the measurement error in MJ’s estimates.</p>
<p> A third issue pertains to how the authors confront the possibility of measurement error in the population data. Acemoğlu, Johnson, and Robinson (<a href="#ref3"><span>Reference Acemoğlu, Johnson and Robinson</span>2002</a>) and Acemoğlu et al. (2008) explicitly discuss measurement error and use IV methods to contend with measurement error in regressors. Others take a different approach. Ashraf and Galor (<a href="#ref6"><span>Reference Ashraf and Galor</span>2011</a>, p. 2011) claim:</p><p> The most comprehensive worldwide cross-country historical estimates of population and income per capita since the year 1 CE have been assembled by Colin McEvedy and Richard Jones (1978) and Angus Maddison (2003), respectively. Indeed, despite inherent problems of measurement associated with historical data, these sources remain unparalleled in providing comparable estimates across countries in the last 2,000 years and have, therefore, widely been regarded as standard sources for such data in the long-run growth literature.</p>
<p> They do not argue that MJ’s data meet any particular standard. Rather, they know of nothing better (it is “unparalleled”) and everyone else uses it (it is the “standard source in the long-run growth literature”).</p>
<p> Nunn and Qian (<a href="#ref49">2011</a>, p. 616) address measurement error more explicitly, but their discussion consists of general statements that are not relevant to the MJ data:</p><p> Accuracy is an obvious concern for historical data that span such a long time horizon and broad cross-section. However, classical measurement error in our outcome variables will not bias our regression estimates. Similarly, any systematic measurement error that varies by time-period or by country is captured by the country and year fixed effects, which are included in all specifications.</p>
<p> Population is their dependent variable, so they are correct that if the measurement error is classical, it does not bias their results. They provide no reason to think this is true, and, as noted, MJ say it is not true. The second statement about fixed effects is equally true but irrelevant to the case. Neither of these extreme assumptions is likely. Nor can they be true simultaneously.</p>
</div>
<div data-magellan-destination="s8" id="s8">
<h2> CONCLUSIONS</h2>
<p> We know the population of the United States in 2020 to a high degree of accuracy. For historical episodes, we might not always do as well, but we can definitely do better than MJ. Palma, Reis, and Zhang (2020), for example, provide improved estimates for Portugal (1527–1850) by combining two sets of historical estimates with some judicious reasoning. Similar approaches may be possible for other times and places. Federico and Tena-Junguito (<a href="#ref20"><span>Reference Federico and Tena-Junguito</span>2022</a>) provide considerable improvement over MJ for the period since 1800 by making better use of published data. Earlier periods may require different approaches. Refining the estimates for Poland in 1400, for example, may not just require consulting more published works, but also original research using, for example, essentially archeological techniques. But it can be done. It would not be useful to assert that because we cannot know the population of Poland in 1400 with the same accuracy as we can in 2020, there is no point in using historical population counts. The opposite extreme is more common and pernicious: many economists take the view that the accuracy of historical data does not matter because it cannot be as precise as modern reports.</p>
<p> We can do, and have done, better. Consider one example. MJ’s estimates imply that the population of England and Wales grew at an average annual rate of .32 percent in the period 1600–1650. Wrigley and Schofield’s figures put that rate at .5 percent. For the period 1650–1700, the estimated growth rates are .26 in MJ and –0.07 in Wrigley and Schofield; for 1700–1750, they are .10 and .26. The differences are substantial. MJ missed the population stagnation of the second half of the seventeenth century and significantly understated the population growth of the first half of the eighteenth century. Population figures directly underlie, any statement about per-capita GDP or its growth rate and are thus central to understanding the Industrial Revolution. We can do much better than MJ’s guesses for many countries, especially in the period since 1500 (e.g., Vos <a href="#ref40"><span>Reference Vos</span>2014</a>, pp. 366–69).</p>
<p> Econometric estimates that rely on MJ form a particular literature that takes a “cross-country regression” approach to economic growth, political economy, and related questions. Economists differ on the usefulness of the general research strategy, and those who favor such studies may insist that some data are better than none. Even those who take this view, however, should be aware of the pitfalls of the source and the way some use it. As I have noted, Acemoğlu and his co-authors tend to use MJ as carefully as one can. Others have compounded MJ’s weaknesses by trying to create information that is not in the source. Some of the research discussed here appeals to the idea that classical measurement error does not cause bias in linear models when the measurement error affects only the dependent variable. This observation is mathematically true but not relevant to the MJ data.</p>
<p> This paper documents a series of problems in a published source that underpins many articles published in the leading general-interest economics journals. Publication in these outlets has strong professional rewards and conveys signals. One signal is that if everyone does something inappropriate, then it is fine. A second signal discourages the original work necessary to improve the basis of our knowledge. The researchers who did the groundwork on which MJ is based understood themselves as contributing to a broader literature in the social sciences. Their contributions were rewarded within their own niches. The same applies to all of the effort that went into constructing the considerable information on historical economies that Maddison summarizes. To the extent the profession signals a lack of interest in such work, it is unlikely we will ever learn more about, for example, the population of Poland in 1400.</p>
<p> This discussion holds a simpler lesson. Many economists today download a dataset and merge it into other datasets without consulting the original sources. Examining MJ’s book is instructive. The introduction explains the problem of non-classical measurement error. A look at the graphs (such as my Figure&nbsp;<a href="#f1">1</a>) would lead most to treat the data with considerable caution. Anyone looking at MJ’s maps for Africa should wonder why their Africa has so many countries in the data.</p>
</div>
</div><div id="references-list"><h2>References</h2> <div id="ref1" aria-flowto="reference-2-content reference-2-button"><p><span><span>Acemoğlu</span>, <span>Daron</span></span>, and <span><span>Johnson</span>, <span>Simon</span></span>. “<span>Unbundling Institutions</span>.” <span>Journal of Political Economy</span> <span>113</span>, no. <span>5</span> (<span>2005</span>): <span>949</span>–95.<a target="_blank" aria-label="CrossRef link for Unbundling Institutions" href="https://dx.doi.org/10.1086/432166">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Unbundling Institutions" href="https://scholar.google.com/scholar_lookup?title=Unbundling+Institutions&amp;author=Acemo%C4%9Flu+Daron&amp;author=Johnson+Simon&amp;publication+year=2005&amp;journal=Journal+of+Political+Economy&amp;volume=113&amp;doi=10.1086%2F432166">Google Scholar</a></p></div><div id="ref2" aria-flowto="reference-3-content reference-3-button"><p><span><span>Acemoğlu</span>, <span>Daron</span></span>, <span><span>Johnson</span>, <span>Simon</span></span>, and <span><span>Robinson</span>, <span>James A.</span></span>. “<span>The Colonial Origins of Comparative Development: An Empirical Investigation</span>.” <span>American Economic Review</span> <span>91</span>, no. <span>5</span> (<span>2001</span>): <span>1369</span>–401.<a target="_blank" aria-label="Google Scholar link for The Colonial Origins of Comparative Development: An Empirical Investigation" href="https://scholar.google.com/scholar_lookup?title=The+Colonial+Origins+of+Comparative+Development%3A+An+Empirical+Investigation&amp;author=Acemo%C4%9Flu+Daron&amp;author=Johnson+Simon&amp;author=Robinson+James+A.&amp;publication+year=2001&amp;journal=American+Economic+Review&amp;volume=91">Google Scholar</a></p></div><div id="ref3" aria-flowto="reference-4-content reference-4-button"><p><span><span>Acemoğlu</span>, <span>Daron</span></span>, <span><span>Johnson</span>, <span>Simon</span></span>, and <span><span>Robinson</span>, <span>James A.</span></span>. “<span>Reversal of Fortune: Geography and Institutions in the Making of the Modern World Income Distribution</span>.” <span>Quarterly Journal of Economics</span> <span>117</span>, no. <span>4</span> (<span>2002</span>): <span>1231</span>–94.<a target="_blank" aria-label="Google Scholar link for Reversal of Fortune: Geography and Institutions in the Making of the Modern World Income Distribution" href="https://scholar.google.com/scholar_lookup?title=Reversal+of+Fortune%3A+Geography+and+Institutions+in+the+Making+of+the+Modern+World+Income+Distribution&amp;author=Acemo%C4%9Flu+Daron&amp;author=Johnson+Simon&amp;author=Robinson+James+A.&amp;publication+year=2002&amp;journal=Quarterly+Journal+of+Economics&amp;volume=117">Google Scholar</a></p></div><div id="ref4" aria-flowto="reference-5-content reference-5-button"><p><span><span>Acemoğlu</span>, <span>Daron</span></span>, <span><span>Johnson</span>, <span>Simon</span></span>, and <span><span>Robinson</span>, <span>James A.</span></span>. “<span>The Rise of Europe: Atlantic Trade, Institutional Change, and Economic Growth</span>.” <span>American Economic Review</span> <span>95</span>, no. <span>3</span> (<span>2005</span>): <span>546</span>–79.<a target="_blank" aria-label="CrossRef link for The Rise of Europe: Atlantic Trade, Institutional Change, and Economic Growth" href="https://dx.doi.org/10.1257/0002828054201305">CrossRef</a><a target="_blank" aria-label="Google Scholar link for The Rise of Europe: Atlantic Trade, Institutional Change, and Economic Growth" href="https://scholar.google.com/scholar_lookup?title=The+Rise+of+Europe%3A+Atlantic+Trade%2C+Institutional+Change%2C+and+Economic+Growth&amp;author=Acemo%C4%9Flu+Daron&amp;author=Johnson+Simon&amp;author=Robinson+James+A.&amp;publication+year=2005&amp;journal=American+Economic+Review&amp;volume=95&amp;doi=10.1257%2F0002828054201305">Google Scholar</a></p></div><div id="ref5" aria-flowto="reference-6-content reference-6-button"><p><span><span>Acemoğlu</span>, <span>Daron</span></span>, <span><span>Simon Johnson</span>, <span>James A.</span></span> <span>Robinson, and Pierre Yared. “Income and Democracy.”</span> <span>American Economic Review</span> <span>98</span>, no. <span>3</span> (<span>2008</span>): <span>808</span>–42.<a target="_blank" aria-label="Google Scholar link for Robinson, and Pierre Yared. “Income and Democracy.”" href="https://scholar.google.com/scholar_lookup?title=Robinson%2C+and+Pierre+Yared.+%E2%80%9CIncome+and+Democracy.%E2%80%9D&amp;author=Acemo%C4%9Flu+Daron&amp;author=Simon+Johnson+James+A.&amp;publication+year=2008&amp;journal=American+Economic+Review&amp;volume=98">Google Scholar</a></p></div><div id="ref6" aria-flowto="reference-7-content reference-7-button"><p><span><span>Ashraf</span>, <span>Quamrul</span></span>, and <span><span>Galor</span>, <span>Oded</span></span>. “<span>Dynamics and Stagnation in the Malthusian Epoch</span>.” <span>American Economic Review</span> <span>101</span>, no. <span>5</span> (<span>2011</span>): <span>2003</span>–41.<a target="_blank" aria-label="CrossRef link for Dynamics and Stagnation in the Malthusian Epoch" href="https://dx.doi.org/10.1257/aer.101.5.2003">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Dynamics and Stagnation in the Malthusian Epoch" href="https://scholar.google.com/scholar_lookup?title=Dynamics+and+Stagnation+in+the+Malthusian+Epoch&amp;author=Ashraf+Quamrul&amp;author=Galor+Oded&amp;publication+year=2011&amp;journal=American+Economic+Review&amp;volume=101&amp;doi=10.1257%2Faer.101.5.2003">Google Scholar</a><a target="_blank" aria-label="PubMed link for Dynamics and Stagnation in the Malthusian Epoch" href="http://www.ncbi.nlm.nih.gov/pubmed/25506082">PubMed</a></p></div><div id="ref7" aria-flowto="reference-8-content reference-8-button"><p><span><span>Ashraf</span>, <span>Quamrul</span></span>, and <span><span>Galor</span>, <span>Oded</span></span>. “<span>The ‘Out of Africa’ Hypothesis, Human Genetic Diversity, and Comparative Economic Development</span>.” <span>American Economic Review</span> <span>103</span>, no. <span>1</span> (<span>2013</span>): <span>1</span>–<span>46</span>.<a target="_blank" aria-label="Google Scholar link for The ‘Out of Africa’ Hypothesis, Human Genetic Diversity, and Comparative Economic Development" href="https://scholar.google.com/scholar_lookup?title=The+%E2%80%98Out+of+Africa%E2%80%99+Hypothesis%2C+Human+Genetic+Diversity%2C+and+Comparative+Economic+Development&amp;author=Ashraf+Quamrul&amp;author=Galor+Oded&amp;publication+year=2013&amp;journal=American+Economic+Review&amp;volume=103&amp;pages=1-46">Google Scholar</a><a target="_blank" aria-label="PubMed link for The ‘Out of Africa’ Hypothesis, Human Genetic Diversity, and Comparative Economic Development" href="http://www.ncbi.nlm.nih.gov/pubmed/25506083">PubMed</a></p></div><div id="ref8" aria-flowto="reference-9-content reference-9-button"><p><span><span>Austin</span>, <span>Gareth</span></span>. “<span>The ‘Reversal of Fortune’ Thesis and the Compression of History: Perspectives from African and Comparative Economic History</span>.” <span>Journal of International Development: The Journal of the Development Studies Association</span> <span>20</span>, no. <span>8</span> (<span>2008</span>): <span>996</span>–<span>1027</span>.<a target="_blank" aria-label="Google Scholar link for The ‘Reversal of Fortune’ Thesis and the Compression of History: Perspectives from African and Comparative Economic History" href="https://scholar.google.com/scholar_lookup?title=The+%E2%80%98Reversal+of+Fortune%E2%80%99+Thesis+and+the+Compression+of+History%3A+Perspectives+from+African+and+Comparative+Economic+History&amp;author=Austin+Gareth&amp;publication+year=2008&amp;journal=Journal+of+International+Development%3A+The+Journal+of+the+Development+Studies+Association&amp;volume=20&amp;pages=996-1027">Google Scholar</a></p></div><div id="ref9" aria-flowto="reference-10-content reference-10-button"><p><span><span>Baumard</span>, <span>Nicolas</span></span>, <span><span>Hyafil</span>, <span>Alexandre</span></span>, <span><span>Morris</span>, <span>Ian</span></span>, and <span><span>Boyer</span>, <span>Pascal</span></span>. “<span>Increased Affluence Explains the Emergence of Ascetic Wisdoms and Moralizing Religions</span>.” <span>Current Biology</span> <span>25</span>, no. <span>1</span> (<span>2015</span>): <span>10</span>–<span>15</span>.<a target="_blank" aria-label="CrossRef link for Increased Affluence Explains the Emergence of Ascetic Wisdoms and Moralizing Religions" href="https://dx.doi.org/10.1016/j.cub.2014.10.063">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Increased Affluence Explains the Emergence of Ascetic Wisdoms and Moralizing Religions" href="https://scholar.google.com/scholar_lookup?title=Increased+Affluence+Explains+the+Emergence+of+Ascetic+Wisdoms+and+Moralizing+Religions&amp;author=Baumard+Nicolas&amp;author=Hyafil+Alexandre&amp;author=Morris+Ian&amp;author=Boyer+Pascal&amp;publication+year=2015&amp;journal=Current+Biology&amp;volume=25&amp;doi=10.1016%2Fj.cub.2014.10.063&amp;pages=10-15">Google Scholar</a><a target="_blank" aria-label="PubMed link for Increased Affluence Explains the Emergence of Ascetic Wisdoms and Moralizing Religions" href="http://www.ncbi.nlm.nih.gov/pubmed/25496963">PubMed</a></p></div><div id="ref10" aria-flowto="reference-11-content reference-11-button"><p><span><span>Biraben</span>, <span>Jean-Noël.</span></span> <span>“Essai sur l’Evolution du Nombre des Mommes</span>. <span>Population (French ed.)</span> (<span>1979</span>): <span>13</span>–<span>25</span>.<a target="_blank" aria-label="Google Scholar link for “Essai sur l’Evolution du Nombre des Mommes" href="https://scholar.google.com/scholar_lookup?title=%E2%80%9CEssai+sur+l%E2%80%99Evolution+du+Nombre+des+Mommes&amp;author=Biraben+Jean-No%C3%ABl.&amp;publication+year=1979&amp;journal=Population+(French+ed.)&amp;pages=13-25">Google Scholar</a></p></div><div id="ref11" aria-flowto="reference-12-content reference-12-button"><p><span><span>Caldwell</span>, <span>John C.</span></span>, and <span><span>Schindlmayr</span>, <span>Thomas</span></span>. “<span>Historical Population Estimates: Unraveling the Consensus</span>.” <span>Population and Development Review</span> <span>28</span>, no. <span>2</span> (<span>2002</span>): <span>183</span>–<span>204</span>.<a target="_blank" aria-label="CrossRef link for Historical Population Estimates: Unraveling the Consensus" href="https://dx.doi.org/10.1111/j.1728-4457.2002.00183.x">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Historical Population Estimates: Unraveling the Consensus" href="https://scholar.google.com/scholar_lookup?title=Historical+Population+Estimates%3A+Unraveling+the+Consensus&amp;author=Caldwell+John+C.&amp;author=Schindlmayr+Thomas&amp;publication+year=2002&amp;journal=Population+and+Development+Review&amp;volume=28&amp;doi=10.1111%2Fj.1728-4457.2002.00183.x&amp;pages=183-204">Google Scholar</a></p></div><div id="ref12" aria-flowto="reference-13-content reference-13-button"><p><span><span>Carlos</span>, <span>Ann M.</span></span>, <span><span>Feir</span>, <span>Donna</span></span>, and <span><span>Redish</span>, <span>Angela</span></span>. “<span>Indigenous Nations and the Development of the U.S. Economy: Land, Resources, and Dispossession</span>.” <span>Journal of Economic History</span> <span>82</span>, no. <span>2</span> (<span>2022</span>): <span>516</span>–55.<a target="_blank" aria-label="Google Scholar link for Indigenous Nations and the Development of the U.S. Economy: Land, Resources, and Dispossession" href="https://scholar.google.com/scholar_lookup?title=Indigenous+Nations+and+the+Development+of+the+U.S.+Economy%3A+Land%2C+Resources%2C+and+Dispossession&amp;author=Carlos+Ann+M.&amp;author=Feir+Donna&amp;author=Redish+Angela&amp;publication+year=2022&amp;journal=Journal+of+Economic+History&amp;volume=82">Google Scholar</a></p></div><div id="ref13" aria-flowto="reference-14-content reference-14-button"><p><span><span>Clark</span>, <span>Colin</span></span>. <span>Population Growth and Land Use</span>. <span>London</span>: <span>MacMillan</span>, <span>1968</span>.<a target="_blank" aria-label="Google Scholar link for Population Growth and Land Use" href="https://scholar.google.com/scholar_lookup?title=Population+Growth+and+Land+Use&amp;author=Clark+Colin&amp;publication+year=1968">Google Scholar</a></p></div><div id="ref14" aria-flowto="reference-15-content reference-15-button"><p><span><span>Clark</span>, <span>Gregory</span></span>. “<span>Review of Angus Maddison’s Contours of the World Economy</span>.” <span>Journal of Economic History</span> <span>69</span>, no. <span>4</span> (<span>2009</span>): <span>1156</span>–61.<a target="_blank" aria-label="Google Scholar link for Review of Angus Maddison’s Contours of the World Economy" href="https://scholar.google.com/scholar_lookup?title=Review+of+Angus+Maddison%E2%80%99s+Contours+of+the+World+Economy&amp;author=Clark+Gregory&amp;publication+year=2009&amp;journal=Journal+of+Economic+History&amp;volume=69">Google Scholar</a></p></div><div id="ref15" aria-flowto="reference-16-content reference-16-button"><p><span><span>D’Alpoim Guedes</span>, <span>Jade</span></span>, <span><span>Bestor</span>, <span>Theodore C.</span></span>, <span><span>David Carrasco</span>, <span>Rowan Flad</span></span>, <span>et al.</span> “<span>Is Poverty in Our Genes? A Critique of Ashraf and Galor. The ‘Out of Africa’ Hypothesis, Human Genetic Diversity, and Comparative Economic Development</span>.” <span>Current Anthropology</span> <span>54</span>, no. <span>1</span> (<span>2013</span>): <span>71</span>–<span>79</span>; <em>American Economic Review,</em> forthcoming.<a target="_blank" aria-label="Google Scholar link for Is Poverty in Our Genes? A Critique of Ashraf and Galor. The ‘Out of Africa’ Hypothesis, Human Genetic Diversity, and Comparative Economic Development" href="https://scholar.google.com/scholar_lookup?title=Is+Poverty+in+Our+Genes%3F+A+Critique+of+Ashraf+and+Galor.+The+%E2%80%98Out+of+Africa%E2%80%99+Hypothesis%2C+Human+Genetic+Diversity%2C+and+Comparative+Economic+Development&amp;author=D%E2%80%99Alpoim+Guedes+Jade&amp;author=Bestor+Theodore+C.&amp;author=David+Carrasco+Rowan+Flad&amp;publication+year=2013&amp;journal=Current+Anthropology&amp;volume=54&amp;pages=71-79">Google Scholar</a></p></div><div id="ref16" aria-flowto="reference-17-content reference-17-button"><p><span><span>Deaton</span>, <span>Angus</span></span>. <span>The Analysis of Household Surveys: A Microeconometric Approach to Development Policy</span>. <span>Baltimore</span>: <span>Johns Hopkins</span>, <span>1997</span>.<a target="_blank" aria-label="CrossRef link for The Analysis of Household Surveys: A Microeconometric Approach to Development Policy" href="https://dx.doi.org/10.1596/0-8018-5254-4">CrossRef</a><a target="_blank" aria-label="Google Scholar link for The Analysis of Household Surveys: A Microeconometric Approach to Development Policy" href="https://scholar.google.com/scholar_lookup?title=The+Analysis+of+Household+Surveys%3A+A+Microeconometric+Approach+to+Development+Policy&amp;author=Deaton+Angus&amp;publication+year=1997">Google Scholar</a></p></div><div id="ref17" aria-flowto="reference-18-content reference-18-button"><p><span><span>Denevan</span>, <span>William M.</span></span> ed. <span>The Native Population of the Americas in 1492</span>. <span>Madison</span>: <span>University of Wisconsin Press</span>, <span>1992</span>.<a target="_blank" aria-label="Google Scholar link for The Native Population of the Americas in 1492" href="https://scholar.google.com/scholar_lookup?title=The+Native+Population+of+the+Americas+in+1492&amp;author=Denevan+William+M.&amp;publication+year=1992">Google Scholar</a></p></div><div id="ref18" aria-flowto="reference-19-content reference-19-button"><p><span><span>Deng</span>, <span>Kent G.</span></span> “<span>Unveiling China’s True Population Statistics for the Pre-Modern Era with Official Census Data</span>.” <span>Population Review</span> <span>43</span>, no. <span>2</span> (<span>2004</span>): <span>32</span>–<span>69</span>.<a target="_blank" aria-label="CrossRef link for Unveiling China’s True Population Statistics for the Pre-Modern Era with Official Census Data" href="https://dx.doi.org/10.1353/prv.2004.0014">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Unveiling China’s True Population Statistics for the Pre-Modern Era with Official Census Data" href="https://scholar.google.com/scholar_lookup?title=Unveiling+China%E2%80%99s+True+Population+Statistics+for+the+Pre-Modern+Era+with+Official+Census+Data&amp;author=Deng+Kent+G.&amp;publication+year=2004&amp;journal=Population+Review&amp;volume=43&amp;doi=10.1353%2Fprv.2004.0014&amp;pages=32-69">Google Scholar</a></p></div><div id="ref19" aria-flowto="reference-20-content reference-20-button"><p><span><span>Durand</span>, <span>John D.</span></span> <span>Historical Estimates of World Population: An Evaluation</span>. <span>Philadelphia</span>: <span>University of Pennsylvania</span>, <span>1974</span>.<a target="_blank" aria-label="Google Scholar link for Historical Estimates of World Population: An Evaluation" href="https://scholar.google.com/scholar_lookup?title=Historical+Estimates+of+World+Population%3A+An+Evaluation&amp;author=Durand+John+D.&amp;publication+year=1974">Google Scholar</a></p></div><div id="ref20" aria-flowto="reference-21-content reference-21-button"><p><span><span>Federico</span>, <span>Giovanni</span></span>, and <span><span>Tena-Junguito</span>, <span>Antonio</span></span>. “How Many People on Earth? World Population 1800–1938.” Maddison-Project Working Paper WP-16, November <span>2022</span>.<a target="_blank" aria-label="Google Scholar link for Federico, Giovanni, and Tena-Junguito, Antonio. “How Many People on Earth? World Population 1800–1938.” Maddison-Project Working Paper WP-16, November 2022." href="https://scholar.google.com/scholar?q=Federico,+Giovanni,+and+Tena-Junguito,+Antonio.+%E2%80%9CHow+Many+People+on+Earth?+World+Population+1800%E2%80%931938.%E2%80%9D+Maddison-Project+Working+Paper+WP-16,+November+2022.">Google Scholar</a></p></div><div id="ref21" aria-flowto="reference-22-content reference-22-button"><p><span><span>Frankema</span>, <span>Ewout</span></span>, and <span><span>Jerven</span>, <span>Morten</span></span>. “<span>Writing History Backwards or Sideways: Towards a Consensus on African Population, 1850–2010</span>.” <span>Economic History Review</span> <span>67</span>, no. <span>4</span> (<span>2014</span>): <span>907</span>–31.<a target="_blank" aria-label="CrossRef link for Writing History Backwards or Sideways: Towards a Consensus on African Population, 1850–2010" href="https://dx.doi.org/10.1111/1468-0289.12041">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Writing History Backwards or Sideways: Towards a Consensus on African Population, 1850–2010" href="https://scholar.google.com/scholar_lookup?title=Writing+History+Backwards+or+Sideways%3A+Towards+a+Consensus+on+African+Population%2C+1850%E2%80%932010&amp;author=Frankema+Ewout&amp;author=Jerven+Morten&amp;publication+year=2014&amp;journal=Economic+History+Review&amp;volume=67&amp;doi=10.1111%2F1468-0289.12041">Google Scholar</a></p></div><div id="ref22" aria-flowto="reference-23-content reference-23-button"><p><span><span>Gennaioli</span>, <span>Nicola</span></span>, and <span><span>Voth</span>, <span>Hans-Joachim</span></span>. “<span>State Capacity and Military Conflict</span>.” <span>Review of Economic Studies</span> <span>82</span>, no. <span>4</span> (<span>2015</span>): <span>1409</span>–48.<a target="_blank" aria-label="Google Scholar link for State Capacity and Military Conflict" href="https://scholar.google.com/scholar_lookup?title=State+Capacity+and+Military+Conflict&amp;author=Gennaioli+Nicola&amp;author=Voth+Hans-Joachim&amp;publication+year=2015&amp;journal=Review+of+Economic+Studies&amp;volume=82">Google Scholar</a></p></div><div id="ref23" aria-flowto="reference-24-content reference-24-button"><p><span><span>Gervais</span>, <span>Raymond R.</span></span>, and <span><span>Mandé</span>, <span>Issiaka</span></span>. “<span>Comment Compter les Sujets de l’Empire?</span>” <span>Vingtième siècle. Revue d’histoire</span> <span>95</span>, no. <span>3</span> (<span>2007</span>) <span>63</span>–<span>74</span>.<a target="_blank" aria-label="Google Scholar link for Comment Compter les Sujets de l’Empire?" href="https://scholar.google.com/scholar_lookup?title=Comment+Compter+les+Sujets+de+l%E2%80%99Empire%3F&amp;author=Gervais+Raymond+R.&amp;author=Mand%C3%A9+Issiaka&amp;publication+year=2007&amp;journal=Vingti%C3%A8me+si%C3%A8cle.+Revue+d%E2%80%99histoire&amp;volume=95&amp;pages=63-74">Google Scholar</a></p></div><div id="ref24" aria-flowto="reference-25-content reference-25-button"><p><span><span>Goldewijk</span>, <span>Kees Klein</span></span>, <span><span>Beusen</span>, <span>Arthur</span></span>, <span><span>Doelman</span>, <span>Jonathan</span></span>, and <span><span>Stehfest</span>, <span>Elke</span></span>. “<span>Anthropogenic Land Use Estimates for the Holocene–HYDE 3.2</span>.” <span>Earth System Science Data</span> <span>9</span>, no. <span>2</span> (<span>2017</span>) <span>927</span>–53.<a target="_blank" aria-label="CrossRef link for Anthropogenic Land Use Estimates for the Holocene–HYDE 3.2" href="https://dx.doi.org/10.5194/essd-9-927-2017">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Anthropogenic Land Use Estimates for the Holocene–HYDE 3.2" href="https://scholar.google.com/scholar_lookup?title=Anthropogenic+Land+Use+Estimates+for+the+Holocene%E2%80%93HYDE+3.2&amp;author=Goldewijk+Kees+Klein&amp;author=Beusen+Arthur&amp;author=Doelman+Jonathan&amp;author=Stehfest+Elke&amp;publication+year=2017&amp;journal=Earth+System+Science+Data&amp;volume=9&amp;doi=10.5194%2Fessd-9-927-2017">Google Scholar</a></p></div><div id="ref25" aria-flowto="reference-26-content reference-26-button"><p><span><span>Greene</span>, <span>William H.</span></span> <span>Econometric Analysis</span>, <span>8th ed</span>. <span>London</span>: <span>Pearson</span>, <span>2018</span>.<a target="_blank" aria-label="Google Scholar link for Econometric Analysis" href="https://scholar.google.com/scholar_lookup?title=Econometric+Analysis&amp;author=Greene+William+H.&amp;publication+year=2018">Google Scholar</a></p></div><div id="ref26" aria-flowto="reference-27-content reference-27-button"><p><span><span>Guinnane</span>, <span>Timothy W.</span></span> “<span>We Do Not Know the Population of Every Country in the World for the Past Two Thousand Years</span>.” <span>CESIfo Working Paper</span> No. <span>9242</span>, <span>Munich, Germany</span>, <span>2021</span>.<a target="_blank" aria-label="Google Scholar link for We Do Not Know the Population of Every Country in the World for the Past Two Thousand Years" href="https://scholar.google.com/scholar_lookup?title=We+Do+Not+Know+the+Population+of+Every+Country+in+the+World+for+the+Past+Two+Thousand+Years&amp;author=Guinnane+Timothy+W.&amp;publication+year=2021&amp;journal=CESIfo+Working+Paper">Google Scholar</a></p></div><div id="ref28" aria-flowto="reference-29-content reference-29-button"><p><span><span>Hyslop</span>, <span>Dean R.</span></span>, and <span><span>Imbens</span>, <span>Guido W.</span></span>. “<span>Bias from Classical and Other Forms of Measurement Error</span>.” <span>Journal of Business &amp; Economic Statistics</span> <span>19</span>, no. <span>4</span> (<span>2001</span>): <span>475</span>–81.<a target="_blank" aria-label="CrossRef link for Bias from Classical and Other Forms of Measurement Error" href="https://dx.doi.org/10.1198/07350010152596727">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Bias from Classical and Other Forms of Measurement Error" href="https://scholar.google.com/scholar_lookup?title=Bias+from+Classical+and+Other+Forms+of+Measurement+Error&amp;author=Hyslop+Dean+R.&amp;author=Imbens+Guido+W.&amp;publication+year=2001&amp;journal=Journal+of+Business+%26+Economic+Statistics&amp;volume=19&amp;doi=10.1198%2F07350010152596727">Google Scholar</a></p></div><div id="ref29" aria-flowto="reference-30-content reference-30-button"><p><span><span>Iyigun</span>, <span>Murat</span></span>. “<span>Luther and Suleyman</span>.” <span>Quarterly Journal of Economics</span> <span>123</span>, no. <span>4</span> (<span>2008</span>): <span>1465</span>–94.<a target="_blank" aria-label="CrossRef link for Luther and Suleyman" href="https://dx.doi.org/10.1162/qjec.2008.123.4.1465">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Luther and Suleyman" href="https://scholar.google.com/scholar_lookup?title=Luther+and+Suleyman&amp;author=Iyigun+Murat&amp;publication+year=2008&amp;journal=Quarterly+Journal+of+Economics&amp;volume=123&amp;doi=10.1162%2Fqjec.2008.123.4.1465">Google Scholar</a></p></div><div id="ref30" aria-flowto="reference-31-content reference-31-button"><p><span><span>Maddison</span>, <span>Angus</span></span>. <span>The World Economy: A Millennial Perspective</span>. <span>Paris, France</span>: <span>OECD</span>, <span>2001</span>.<a target="_blank" aria-label="CrossRef link for The World Economy: A Millennial Perspective" href="https://dx.doi.org/10.1787/9789264189980-en">CrossRef</a><a target="_blank" aria-label="Google Scholar link for The World Economy: A Millennial Perspective" href="https://scholar.google.com/scholar_lookup?title=The+World+Economy%3A+A+Millennial+Perspective&amp;author=Maddison+Angus&amp;publication+year=2001">Google Scholar</a></p></div><div id="ref31" aria-flowto="reference-32-content reference-32-button"><p><span><span>Maddison</span>, <span>Angus</span></span>. <span>
<em>Contours of the World Economy, 1–2030 <span>ad</span>: Essays in Macro-Economic</em>
</span> <span>History</span>. <span>Oxford</span>: <span>Oxford University Press</span>, <span>2007</span>.<a target="_blank" aria-label="Google Scholar link for History" href="https://scholar.google.com/scholar_lookup?title=History&amp;author=Maddison+Angus&amp;publication+year=2007">Google Scholar</a></p></div><div id="ref32" aria-flowto="reference-33-content reference-33-button"><p><span><span>McEvedy</span>, <span>Colin</span></span>, and <span><span>Jones</span>, <span>Richard</span></span>. <span>
<em>Atlas of World Population History</em>
</span>. <span>Harmondsworth</span>, <span>Middlesex, England</span>: <span>Penguin Books Ltd</span>, <span>1978</span>.<a target="_blank" aria-label="Google Scholar link for Harmondsworth" href="https://scholar.google.com/scholar_lookup?title=Harmondsworth&amp;author=McEvedy+Colin&amp;author=Jones+Richard&amp;publication+year=1978">Google Scholar</a></p></div><div id="ref33" aria-flowto="reference-34-content reference-34-button"><p><span><span>Nunn</span>, <span>Nathan</span></span>. “<span>The Long-Term Effects of Africa’s Slave Trades</span>.” <span>Quarterly Journal of Economics</span> <span>123</span>, no. <span>1</span> (<span>2008</span>): <span>139</span>–76.<a target="_blank" aria-label="Google Scholar link for The Long-Term Effects of Africa’s Slave Trades" href="https://scholar.google.com/scholar_lookup?title=The+Long-Term+Effects+of+Africa%E2%80%99s+Slave+Trades&amp;author=Nunn+Nathan&amp;publication+year=2008&amp;journal=Quarterly+Journal+of+Economics&amp;volume=123">Google Scholar</a></p></div><div id="ref34" aria-flowto="reference-35-content reference-35-button"><p><span><span>Nunn</span>, <span>Nathan</span></span>, and <span><span>Qian</span>, <span>Nancy</span></span>. “<span>The Potato’s Contribution to Population and Urbanization: Evidence from a Historical Experiment</span>.” <span>Quarterly Journal of Economics</span> <span>126</span>, no. <span>2</span> (<span>2011</span>): <span>593</span>–<span>650</span>.<a target="_blank" aria-label="Google Scholar link for The Potato’s Contribution to Population and Urbanization: Evidence from a Historical Experiment" href="https://scholar.google.com/scholar_lookup?title=The+Potato%E2%80%99s+Contribution+to+Population+and+Urbanization%3A+Evidence+from+a+Historical+Experiment&amp;author=Nunn+Nathan&amp;author=Qian+Nancy&amp;publication+year=2011&amp;journal=Quarterly+Journal+of+Economics&amp;volume=126&amp;pages=593-650">Google Scholar</a><a target="_blank" aria-label="PubMed link for The Potato’s Contribution to Population and Urbanization: Evidence from a Historical Experiment" href="http://www.ncbi.nlm.nih.gov/pubmed/22073408">PubMed</a></p></div><div id="ref35" aria-flowto="reference-36-content reference-36-button"><p><span><span>Palma</span>, <span>Nuno</span></span>, <span><span>Reis</span>, <span>Jaime</span></span>, and <span><span>Zhang</span>, <span>Mengtian</span></span>. “Reconstruction of Regional and National Population Using Intermittent Census-Type Data: The Case of Portugal, 1527–1864. <em>Historical Methods: A Journal of Quantitative and Interdisciplinary History</em> 53, no. 1 (2020): 11–27.<a target="_blank" aria-label="Google Scholar link for Palma, Nuno, Reis, Jaime, and Zhang, Mengtian. “Reconstruction of Regional and National Population Using Intermittent Census-Type Data: The Case of Portugal, 1527–1864. Historical Methods: A Journal of Quantitative and Interdisciplinary History 53, no. 1 (2020): 11–27." href="https://scholar.google.com/scholar?q=Palma,+Nuno,+Reis,+Jaime,+and+Zhang,+Mengtian.+%E2%80%9CReconstruction+of+Regional+and+National+Population+Using+Intermittent+Census-Type+Data:+The+Case+of+Portugal,+1527%E2%80%931864.+Historical+Methods:+A+Journal+of+Quantitative+and+Interdisciplinary+History+53,+no.+1+(2020):+11%E2%80%9327.">Google Scholar</a></p></div><div id="ref36" aria-flowto="reference-37-content reference-37-button"><p><span><span>Putterman</span>, <span>Louis</span></span>, and <span><span>Weil</span>, <span>David N.</span></span>. “<span>Post-1500 Population Flows and the Long-Run Determinants of Economic Growth and Inequality</span>.” <span>Quarterly Journal of Economics</span> <span>125</span>, no. <span>4</span> (<span>2010</span>): <span>1627</span>–82.<a target="_blank" aria-label="Google Scholar link for Post-1500 Population Flows and the Long-Run Determinants of Economic Growth and Inequality" href="https://scholar.google.com/scholar_lookup?title=Post-1500+Population+Flows+and+the+Long-Run+Determinants+of+Economic+Growth+and+Inequality&amp;author=Putterman+Louis&amp;author=Weil+David+N.&amp;publication+year=2010&amp;journal=Quarterly+Journal+of+Economics&amp;volume=125">Google Scholar</a><a target="_blank" aria-label="PubMed link for Post-1500 Population Flows and the Long-Run Determinants of Economic Growth and Inequality" href="http://www.ncbi.nlm.nih.gov/pubmed/24478530">PubMed</a></p></div><div id="ref37" aria-flowto="reference-38-content reference-38-button"><p><span><span>Rogers</span>, <span>Alan R.</span></span> “<span>Evolution of Time Preference by Natural Selection</span>.” <span>American Economic Review</span> <span>84</span>, no. <span>3</span> (<span>1994</span>): <span>460</span>–81.<a target="_blank" aria-label="Google Scholar link for Evolution of Time Preference by Natural Selection" href="https://scholar.google.com/scholar_lookup?title=Evolution+of+Time+Preference+by+Natural+Selection&amp;author=Rogers+Alan+R.&amp;publication+year=1994&amp;journal=American+Economic+Review&amp;volume=84">Google Scholar</a></p></div><div id="ref38" aria-flowto="reference-39-content reference-39-button"><p><span><span>Shiue</span>, <span>Carol H.</span></span>, and <span><span>Keller</span>, <span>Wolfgang</span></span>. “<span>Markets in China and Europe on the Eve of the Industrial Revolution</span>.” <span>American Economic Review</span> <span>97</span>, no. <span>4</span> (<span>2007</span>): <span>1189</span>–216.<a target="_blank" aria-label="CrossRef link for Markets in China and Europe on the Eve of the Industrial Revolution" href="https://dx.doi.org/10.1257/aer.97.4.1189">CrossRef</a><a target="_blank" aria-label="Google Scholar link for Markets in China and Europe on the Eve of the Industrial Revolution" href="https://scholar.google.com/scholar_lookup?title=Markets+in+China+and+Europe+on+the+Eve+of+the+Industrial+Revolution&amp;author=Shiue+Carol+H.&amp;author=Keller+Wolfgang&amp;publication+year=2007&amp;journal=American+Economic+Review&amp;volume=97&amp;doi=10.1257%2Faer.97.4.1189">Google Scholar</a></p></div><div id="ref39" aria-flowto="reference-40-content reference-40-button"><p><span><span>Voigtländer</span>, <span>Nico</span></span>, and <span><span>Voth</span>, <span>Hans-Joachim</span></span>. “<span>The Three Horsemen of Riches: Plague, War, and Urbanization in Early Modern Europe</span>.” <span>Review of Economic Studies</span> <span>80</span>, no. <span>2</span> (<span>2013</span>): <span>774</span>–<span>811</span>.<a target="_blank" aria-label="Google Scholar link for The Three Horsemen of Riches: Plague, War, and Urbanization in Early Modern Europe" href="https://scholar.google.com/scholar_lookup?title=The+Three+Horsemen+of+Riches%3A+Plague%2C+War%2C+and+Urbanization+in+Early+Modern+Europe&amp;author=Voigtl%C3%A4nder+Nico&amp;author=Voth+Hans-Joachim&amp;publication+year=2013&amp;journal=Review+of+Economic+Studies&amp;volume=80&amp;pages=774-811">Google Scholar</a></p></div><div id="ref40" aria-flowto="reference-41-content reference-41-button"><p><span><span>Vos</span>, <span>Jelmer</span></span>. “<span>Work in Times of Slavery, Colonialism, and Civil War: Labor Relations in Angola from 1800 to 2000</span>.” <span>History in Africa</span> <span>41</span> (<span>2014</span>): <span>363</span>–85.<a target="_blank" aria-label="Google Scholar link for Work in Times of Slavery, Colonialism, and Civil War: Labor Relations in Angola from 1800 to 2000" href="https://scholar.google.com/scholar_lookup?title=Work+in+Times+of+Slavery%2C+Colonialism%2C+and+Civil+War%3A+Labor+Relations+in+Angola+from+1800+to+2000&amp;author=Vos+Jelmer&amp;publication+year=2014&amp;journal=History+in+Africa&amp;volume=41">Google Scholar</a></p></div><div id="ref41" aria-flowto="reference-42-content reference-42-button"><p><span><span>Wooldridge</span>, <span>Jeffrey M.</span></span> <span>Econometric Analysis of Cross Section and Panel Data</span>, <span>2nd ed</span>. <span>Cambridge, MA</span>: <span>MIT Press</span>, <span>2010</span>.<a target="_blank" aria-label="Google Scholar link for Econometric Analysis of Cross Section and Panel Data" href="https://scholar.google.com/scholar_lookup?title=Econometric+Analysis+of+Cross+Section+and+Panel+Data&amp;author=Wooldridge+Jeffrey+M.&amp;publication+year=2010">Google Scholar</a></p></div><div id="ref42" aria-flowto="reference-43-content reference-43-button"><p><span><span>Wrigley</span>, <span>E. A.</span></span>, and <span><span>Schofield</span>, <span>Roger</span></span>. <span>The Population History of England 1541–1871</span>. <span>Cambridge, MA</span>: <span>Harvard University Press</span>, <span>1981</span>.<a target="_blank" aria-label="Google Scholar link for The Population History of England 1541–1871" href="https://scholar.google.com/scholar_lookup?title=The+Population+History+of+England+1541%E2%80%931871&amp;author=Wrigley+E.+A.&amp;author=Schofield+Roger&amp;publication+year=1981">Google Scholar</a></p></div><div id="ref44" aria-flowto="reference-45-content reference-45-button"><p><span>U.S. States</span>: <span><span>Haines</span>, <span>Michael R.</span></span>, and Inter-university Consortium for Political and Social Research. Historical, Demographic, Economic, and Social Data: The United States, 1790-2002. Inter-university Consortium for Political and Social Research [distributor], 2010-05-21. <a href="https://doi.org/10.3886/ICPSR02896.v3">https://doi.org/10.3886/ICPSR02896.v3</a>
<a target="_blank" aria-label="CrossRef link for U.S. States: Haines, Michael R., and Inter-university Consortium for Political and Social Research. Historical, Demographic, Economic, and Social Data: The United States, 1790-2002. Inter-university Consortium for Political and Social Research [distributor], 2010-05-21. https://doi.org/10.3886/ICPSR02896.v3" href="https://dx.doi.org/10.3886/ICPSR02896.v3">CrossRef</a><a target="_blank" aria-label="Google Scholar link for U.S. States: Haines, Michael R., and Inter-university Consortium for Political and Social Research. Historical, Demographic, Economic, and Social Data: The United States, 1790-2002. Inter-university Consortium for Political and Social Research [distributor], 2010-05-21. https://doi.org/10.3886/ICPSR02896.v3" href="https://scholar.google.com/scholar?q=U.S.+States:+Haines,+Michael+R.,+and+Inter-university+Consortium+for+Political+and+Social+Research.+Historical,+Demographic,+Economic,+and+Social+Data:+The+United+States,+1790-2002.+Inter-university+Consortium+for+Political+and+Social+Research+[distributor],+2010-05-21.+https://doi.org/10.3886/ICPSR02896.v3">Google Scholar</a></p></div><div id="ref45" aria-flowto="reference-46-content reference-46-button"><p><span>MJ database</span>. Data reported in MJ as provided by James Fenske.<a target="_blank" aria-label="Google Scholar link for MJ database. Data reported in MJ as provided by James Fenske." href="https://scholar.google.com/scholar?q=MJ+database.+Data+reported+in+MJ+as+provided+by+James+Fenske.">Google Scholar</a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Farms that create habitat key to food security and biodiversity (161 pts)]]></title>
            <link>https://news.stanford.edu/2023/09/04/farming-food-biodiversity/</link>
            <guid>37386661</guid>
            <pubDate>Tue, 05 Sep 2023 00:52:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.stanford.edu/2023/09/04/farming-food-biodiversity/">https://news.stanford.edu/2023/09/04/farming-food-biodiversity/</a>, See on <a href="https://news.ycombinator.com/item?id=37386661">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="story-content">
          <div><p><a aria-label="View full size image" href="https://news.stanford.edu/wp-content/uploads/2023/08/DSC_3061_edit.jpg"><img decoding="async" src="https://news.stanford.edu/wp-content/uploads/2023/08/DSC_3061_edit-795x530.jpg" alt="" srcset="https://news.stanford.edu/wp-content/uploads/2023/08/DSC_3061_edit-795x530.jpg 795w, https://news.stanford.edu/wp-content/uploads/2023/08/DSC_3061_edit-555x370.jpg 555w, https://news.stanford.edu/wp-content/uploads/2023/08/DSC_3061_edit-960x640.jpg 960w, https://news.stanford.edu/wp-content/uploads/2023/08/DSC_3061_edit-705x470.jpg 705w, https://news.stanford.edu/wp-content/uploads/2023/08/DSC_3061_edit-345x230.jpg 345w, https://news.stanford.edu/wp-content/uploads/2023/08/DSC_3061_edit-375x250.jpg 375w, https://news.stanford.edu/wp-content/uploads/2023/08/DSC_3061_edit.jpg 1500w" sizes="(max-width: 795px) 100vw, 795px"></a></p>
<p>The Costa Rican countryside showcases the interplay between farmlands and trees that serve as vital wildlife habitats in agricultural landscapes. Such landscapes underscore the importance of maintaining tree cover in farming areas, offering essential habitats for species outside of protected zones.<span> (Image credit: Nick Hendershot)</span></p>
</div>
<p>It seems intuitive that forests would provide better habitat for forest-dwelling wildlife than farms. Yet, in one of the longest-running studies of tropical wildlife populations in the world, Stanford researchers found that over 18 years, smaller farms with varying crop types – interspersed with patches or ribbons of forest – sustain many forest-dependent bird populations in Costa Rica, even as populations decline in forests.</p>
<p>In a paper published Sept. 4 in the <em>Proceedings of the National Academy of Sciences</em>, Nicholas Hendershot and colleagues compared trends in specific bird populations across three landscape types in Costa Rica: forests, diversified farms, and intensive agriculture. The steepest declines were found in forests, then in intensive agriculture (and the species succeeding in intensive agriculture were often invasive). But on diversified farms, a significant subset of bird species typically found in forests, including some of conservation concern, actually increased over time.</p>
<p>“Birds are kind of a proxy we use to track the health of ecosystems. And the birds we’re seeing today aren’t the same as we saw 18 to 20 years ago. This paper really documents this pattern,” said Hendershot, a postdoctoral fellow at the time of this research in Stanford’s Department of Biology in the <a href="https://humsci.stanford.edu/">School of Humanities and Sciences (H&amp;S)</a>, the Stanford <a href="https://ccb.stanford.edu/">Center for Conservation Biology</a> (CCB), and the Stanford-based <a href="https://naturalcapitalproject.stanford.edu/">Natural Capital Project</a> (NatCap).</p>
<h2>Food security at stake</h2>
<p>While this research implies that diversified farming could be key for biodiversity, the relationship goes both ways: biodiversity is key for food security. In this case, that means having a variety of types of birds feeding on insects and helping to pollinate crops.</p>
<p>“Identity does seem to matter a lot for pest control and other ecosystem services birds provide. These species are not interchangeable,” said Hendershot.</p>
<p>“We need a constant stream of pollinators servicing farms. About three-quarters of the world’s crops require pollinators to some extent, and that 75% is our most nutritious food – think of all the vitamins and minerals packed into fruits, nuts, and veggies,” explained <a href="https://profiles.stanford.edu/gretchen-daily">Gretchen Daily</a>,&nbsp;<span>faculty director of NatCap</span> <span>and CCB, Bing Professor of Environmental Science in H&amp;S,</span> <span>and a senior author on the paper</span>. “We need a constant stream of birds, bats, and other wildlife to help control pests: they suppress the vast majority naturally. And we need to start building flood protection, water purification, carbon storage, and many other vital benefits back into agricultural landscapes, way beyond what can be achieved in protected areas alone.”</p>
<p>Daily also noted that, in terms of food production, diversified farms are not necessarily lower yielding than intensive agriculture. “This is a recent assumption that is being overturned,” she said.</p>
<div><p><a aria-label="View full size image" href="https://news.stanford.edu/wp-content/uploads/2023/08/2019-01-00926C_CoverPhoto_RoyalFlycatcher2.jpeg"><img decoding="async" src="https://news.stanford.edu/wp-content/uploads/2023/08/2019-01-00926C_CoverPhoto_RoyalFlycatcher2-795x530.jpeg" alt="" srcset="https://news.stanford.edu/wp-content/uploads/2023/08/2019-01-00926C_CoverPhoto_RoyalFlycatcher2-795x530.jpeg 795w, https://news.stanford.edu/wp-content/uploads/2023/08/2019-01-00926C_CoverPhoto_RoyalFlycatcher2-555x370.jpeg 555w, https://news.stanford.edu/wp-content/uploads/2023/08/2019-01-00926C_CoverPhoto_RoyalFlycatcher2-960x640.jpeg 960w, https://news.stanford.edu/wp-content/uploads/2023/08/2019-01-00926C_CoverPhoto_RoyalFlycatcher2-705x470.jpeg 705w, https://news.stanford.edu/wp-content/uploads/2023/08/2019-01-00926C_CoverPhoto_RoyalFlycatcher2-345x230.jpeg 345w, https://news.stanford.edu/wp-content/uploads/2023/08/2019-01-00926C_CoverPhoto_RoyalFlycatcher2-375x250.jpeg 375w, https://news.stanford.edu/wp-content/uploads/2023/08/2019-01-00926C_CoverPhoto_RoyalFlycatcher2.jpeg 1500w" sizes="(max-width: 795px) 100vw, 795px"></a></p>
<p>A striking male Royal Flycatcher flaunts its vibrant red and blue crest. This captivating species exemplifies the diverse and unique birdlife of Costa Rica, underscoring the importance of preserving habitats to support such biodiversity.<span> (Image credit: Nick Hendershot)</span></p>
</div>
<h2>Beyond protected areas</h2>
<p>It has become increasingly apparent around the world that while protected areas remain critical, they are too few and far between to provide the ecosystem services people and nature need to thrive. Working landscapes are crucial now for preserving biodiversity and its benefits. “People, including scientists, had the idea that farmland would not support a meaningful amount of biodiversity,” said Daily. In this case, not only are diversified farms themselves providing habitat, they connect otherwise fragmented forested areas.</p>

<p>Over time, Hendershot said, “I have moved away from the ‘fortress conservation’ model, which focused more on creating protected areas separate from human activities, and see more and more how much potential there is outside of forests. The forests are key – we need them, of course. But in addition to that, I’m always surprised by how important <em>how </em>you manage a farm is for biodiversity.”</p>
<p>“We believe the findings of our research are new to science, but in a sense, it merely confirms what Indigenous communities around the world have already known for a long time, which is that humans can and should have reciprocal relationships with the rest of the local ecological community they are part of,” said <a href="https://profiles.stanford.edu/tadashi-fukami">Tadashi Fukami</a>, a professor of biology in H&amp;S and of Earth system science in the <a href="https://sustainability.stanford.edu/">Stanford Doerr School of Sustainability</a>&nbsp;and a co-author of the paper.</p>
<h2>Incentivizing farmers</h2>
<p>In the 1980s and 90s, deforestation was occurring in Costa Rica at the fastest rate ever seen on a country scale. Then, they turned it around – becoming a renowned model of success. By setting up the world’s first countrywide payment for ecosystem services (PES) program, Costa Rica reversed this trend: today, forests cover almost 60% of its land, up from 40% in 1987.</p>
<p>The country currently aims to double the amount of protected forest in just a few years. In its existing PES program, any landowner can receive money for reforesting even small parts of their land. Now, the government is also working toward a new PES program to incentivize farmers to adopt best management practices.</p>
<p>This study will help inform Costa Rican policymakers in understanding the benefits provided over time by different farming practices. Said Daily, “We need to recognize the vital work many farmers are doing that supports biodiversity.”</p>
<div>
<p>Nicholas Hendershot was a postdoctoral researcher with the <a href="https://ccb.stanford.edu/">Center for Conservation Biology</a> at Stanford and is now a forest ecologist with The Nature Conservancy-California. Gretchen Daily is also a senior fellow in the <a href="https://woods.stanford.edu/">Stanford Woods Institute for the Environment</a>. Other co-authors on the paper are Alejandra Echeverri, an assistant professor of conservation science at the University of California, Berkeley; Luke Frishkoff of the <a href="https://www.uta.edu/academics/schools-colleges/science/departments/biology">University of Texas at Arlington</a>; and prominent Costa Rican ornithologist Jim Zook.</p>
<p>Hendershot’s work was supported by the Gerhard Casper and John P. Morgridge Stanford Graduate Fellowship, the OTS Emerging Challenges in Tropical Science Fellowship, and the Winslow Foundation. Funding for data collection from 1999-2017 was generously provided to Daily by the LuEsther T. Mertz Charitable Trust, the Moore Family Foundation, and the Winslow Foundation.</p>
</div>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Get a cable modem, go to jail (1999) (466 pts)]]></title>
            <link>http://telecom.csail.mit.edu/judy-sammel.html</link>
            <guid>37386397</guid>
            <pubDate>Tue, 05 Sep 2023 00:02:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://telecom.csail.mit.edu/judy-sammel.html">http://telecom.csail.mit.edu/judy-sammel.html</a>, See on <a href="https://news.ycombinator.com/item?id=37386397">Hacker News</a></p>
<div id="readability-page-1" class="page"><i>updated....April 26, 1999</i> 
<center>
<h5> Visit Judy Sammel's Homepage: <a href="http://www.pobox.com/~sammel">www.pobox.com/~sammel</a>
</h5>

</center>I've just been through a 
truly bizarre experience with Comcast@home, and I thought the assembled 
readership might be interested in hearing about it. <br>
<hr>

<h3>Chapter 1: In Which I Learn About the Various Divisions of the District 
Court of the State of Maryland</h3><b><i>Thursday, November 19, 1998:</i></b> 
It's an ordinary day. I get home from work, picking up the mail as I walk toward 
my house.&nbsp; I notice that the return address on one of the letters is the 
District Court of the State of Maryland. As I walk up the front steps, I think, 
"I just did jury duty last year; they can't be asking me to serve again so soon, 
can they?"&nbsp; After I settle in at home, I open the letter and read, "You 
have been summoned to appear as a defendant in a trial..."&nbsp;&nbsp; My first 
thought is that someone is suing me for something, but then I see at the top of 
the page 'State of Maryland vs. Sammel, Judith Lynne', and realize that this 
isn't a<b><i> person</i></b> suing me.&nbsp; My second thought is that I've 
gotten a parking ticket that blew off of my windshield and has gone unpaid, or 
maybe a speeding ticket from the traffic cameras I've heard about.&nbsp; It's 
too late to call the Court to see what the case is about, so I have to wait 
until the next day. 
<p>The next morning,&nbsp; I call the telephone number that's printed on the 
letter, and a recording says something like "press 1 for Civil Division, 2 for 
Traffic Division, 3 for Criminal Division, 4 for information about specific 
cases," etc.&nbsp; I choose the option for information about specific cases, and 
the person who answers the phone asks me to read her the case number.&nbsp; 
After I read it, I hear her say, "Just a minute.&nbsp; Let me transfer you to 
the Criminal Division." 
</p><p>"Whaaaaaaaaat?" I ask, but it's too late.&nbsp; I'm on hold. 
</p><p>Someone else picks up the phone, and again I read the case number and ask 
what the case is about. 
</p><p>"Cable fraud, " she replies. <br>
</p><hr>

<h3>Chapter 2: In Which Comcast Cablevision's Administrative Offices in 
Baltimore are Informed that "At Home" is More Than Just "A Place They'd Rather 
Be Than At The Office"</h3>Unfortunately, I think I know what the problem 
is.&nbsp; I had signed up for Comcast@home cable modem service last March, but 
had not signed up for cable TV service.&nbsp; (Last time I checked, this was 
legal.&nbsp; In fact, it is mentioned specifically as a service in the FAQ list 
on @home's web site.)&nbsp; But, when they came to install my @home service, 
they had neglected to install the filter (they call it a video trap) to filter 
out the video signal&nbsp; from reaching my home.&nbsp; (I live in a townhouse 
community, and there is a "pedestal" containing cable connections for several 
houses--this is a few houses away from mine.)&nbsp; The installers had told me 
that they would return to install the video trap, and that I could enjoy cable 
TV service until they came back to do so--they said I should consider it an 
incentive to sign up for the service.&nbsp; Well, they never came back to 
install the video trap. 
<p>Then, in early June, my @home service stopped working.&nbsp; I made several 
calls to Comcast Cablevision and Comcast@home customer service.&nbsp; Each 
claimed that it was the responsibility of the other to determine what the 
problem was, and fix it.&nbsp; During my conversations with Comcast Cablevision 
and Comcast@home, I told them both that nobody had come back to install the 
video trap.&nbsp; Finally, Comcast@home agreed to come out and see what the 
problem was.&nbsp; I told them that they should bring a video trap with them 
when they came to repair the service.&nbsp; Because of their schedule and my 
vacation schedule, they didn't come out to repair the service until late 
June.&nbsp; The repair technician, when he arrived, said that the reason that my 
@home service stopped working was that someone had disconnected the cable in the 
cable "pedestal" on my street.&nbsp; He said that it was likely that Comcast 
Cablevision personnel had done this, not realizing that I had Comcast@home 
service. When he'd reconnected my service,&nbsp; I asked him about the 
installation of the video trap.&nbsp; He said he hadn't brought one with him, 
but would take care of it later.&nbsp; Again, nobody came back to install the 
device. 
</p><p>So, after I receive this letter from the District Court, I figure that 
Comcast Cablevision has been out to my neighborhood and has seen that I was 
connected up again (and again not realized that I had Comcast@home cable modem 
service.)&nbsp; I call the administrative offices of Comcast Cablevision here in 
Baltimore, and explain the situation.&nbsp; They say that they will have 
Comcast's attorneys call me to discuss it.&nbsp; I also make the suggestion that 
they come out and install a video trap on my line so that this won't happen 
again.&nbsp; They assure me they will send someone out that day to do it.&nbsp; 
I get home fairly late that evening and find that the video trap hasn't been 
installed.&nbsp; Since the Comcast administrative offices are closed by this 
time, I call @home customer service. I call at 10:30 PM and remain on hold until 
11:15 PM, at which time a customer service representative takes the call. When I 
ask about getting a video trap placed on the line, his first response is that 
Comcast, not @home, should take care of that, and I should call Comcast customer 
service.&nbsp; I explain to him that, based on my prior experience with Comcast 
customer service, if I call them, the following situation will likely occur: 
</p><ul>
  <li>the Comcast customer service representative will ask for my Comcast 
  account number 
  </li><li>I will reply that I have none, since I am only a Comcast@home customer, 
  not a Comcast cable TV customer 
  </li><li>the service representative will tell me they can't do anything for me, and 
  I will have to call @home customer service </li></ul>He then agrees to talk to 
his supervisor.&nbsp; He returns to the line to tell me that he will place a 
work order for a video trap to be placed on the line. <br>
<hr>

<h3>Chapter 3: In Which I Wait Not-So-Patiently for Comcast's Attorney to 
Call,&nbsp; and for the Video Trap to be Installed</h3><b><i>Saturday, November 
21, 1998:</i></b> After I place two calls to their offices, Comcast's attorney 
who is assigned to my case returns my call to assure me that the criminal 
charges will be dropped. I mention that the video trap wasn't installed the 
previous day. 
<p><b><i>Sunday, November 22, 1998:</i></b> As of&nbsp; Sunday morning, neither 
Comcast nor @home has arrived to place a video trap on the line.&nbsp; I call 
Comcast customer service to ask about the status of this, and am initially told 
that since I am not a Comcast cable TV customer, I have to call @home to resolve 
any problems.&nbsp; I explain that the situation is related to criminal charges 
that Comcast has filed against me, and ask the account executive to try to find 
a way to assist me from her location.&nbsp;&nbsp; She asks for my name and 
address.&nbsp; I give it to her, and she comes back on the line after a few 
moments and says that the only name she has listed at that address is that of 
former occupants of my home (from1989-1992).&nbsp; I explain again that I am not 
a Comcast cable TV customer, but only a Comcast@home customer, so there would 
likely not be a record of my name, unless she has records of Comcast@home 
customers as well as Comcast cable TV customers.&nbsp; She again asks me to hold 
the line.&nbsp; When she returns, she says that she has checked into the 
situation with @home, and has found out that the video trap was not placed on 
the line because the part is out of stock.&nbsp; She says that when parts are 
shipped, they will send an installer out to put it in.&nbsp; She says that in 
the meantime, I cannot be held responsible for the signal coming into my home. 
</p><p><b><i>Tuesday, November 24, 1998:</i></b> Comcast's attorney leaves a message 
on my answering machine saying: "I withdrew...did a request to withdraw those 
charging documents" .&nbsp;&nbsp;&nbsp; I will soon find out the hard way that 
the "withdrew...did a request to withdraw" wording actually means 
something--Comcast doesn't have the ability to get criminal charges dropped on 
their own, even though they're the ones who got the court to file them in the 
first place.&nbsp; Once the charges are "in the system", Comcast can only 
<b><i>request</i></b> that this be done. <br>
</p><hr>

<h3>Chapter 4: In Which A Police Officer Serves Me With&nbsp; A Criminal Summons 
in Front of an Out-of-Town Houseguest on the Eve of 
Thanksgiving</h3><b><i>Wednesday, November 25, 1998:</i></b> A uniformed police 
officer drives up to my house in his police cruiser and delivers the summons to 
me; it shows 4 counts of cable fraud, with the possibility of 6 months in jail 
on each count.&nbsp; I had always wondered why, when someone commits what 
appears to be a single crime, you hear things about being charged with "10 
counts" of something-or-other. In my case, Comcast's visit in June (when they 
cut off my service) was 2 counts--one for cable having been fraudulently hooked 
up, one for fraudulent receipt of service; and a subsequent visit they made in 
July, during which they saw that service had been reconnected, was again 2 
counts.&nbsp; I try to tell the police officer what Comcast's attorney has told 
me to tell him--that the charges are being dropped, and that he should call her 
to verify this--but he could care less about this--he just wants a signature on 
the papers and wants to leave.&nbsp; A friend of mine, who has driven up from 
Virginia to spend the holiday weekend with me, is sitting nearby in my kitchen 
watching this sorry event; it's a really humiliating experience. Anyway, by the 
end of the day, I find that the video trap has finally been installed on the 
line. <br>
<hr>

<h3>Chapter 5:&nbsp; In Which I Come to the Conclusion that Lady Justice is Not 
Just Blindfolded, But Actually Blind</h3><b><i>Monday, November 30, 
1998:</i></b>&nbsp; I telephone the State's Attorney's office to see if they 
have received and processed Comcast's request to withdraw the charges.&nbsp; 
They tell me that it has been received, and that the State's Attorney's office 
has disapproved Comcast's request.&nbsp; They tell me that no reason for the 
disapproval was supplied. I begin to feel like a character in a Kafka 
novel.&nbsp; I call Comcast's administrative offices in Baltimore and tell them 
that the State's Attorney has denied the request to withdraw charges.&nbsp; 
"They can't do that!" the employee that I speak to exclaims.&nbsp; "Well, 
obviously they can, because...they have," I reply. <br>
<hr>

<h3>Chapter 6: In Which I Determine That an Excellent Way to Pique Someone's 
Curiosity is to Ask, "Do You Have any Recommendations for a Good Criminal 
Defense Attorney?"</h3>No chapter here, but it's too good of a title to pass 
up.&nbsp; Actually, I am told by some colleagues who are attorneys that even in 
a cut-and-dried case like this, I should expect to pay $750 or $1000 for an 
attorney if I need to mount a defense in court. <br>
<hr>

<h3>Chapter 7: In Which I Find Out that the Attorney for Comcast Actually Does 
Have a Sense of Humor</h3>I speak with the Comcast attorney about my call to 
State's Attorney's office. She says she was unaware that State's Attorney has 
denied the request to drop the charges, and that she will write another letter 
to ensure that the situation is taken care of.&nbsp; She also asks about whether 
the video trap has been installed and is working correctly. I tell her that 
everything is blocked except for 2 religious channels, 1 Spanish language 
channel, and the video portion of E! TV.&nbsp; She says something along the 
lines of, "I guess the signal of the Lord manages to find its way through 
somehow." <br>
<hr>

<h3>Chapter 8:&nbsp; In Which I Learn That the Cable TV Franchising Authority is 
Willing to Handle Complaints About Cable TV Issues--But Only Up To a Point</h3>A 
friend of mine had suggested that I find out who the Franchising Authority for 
cable television in Baltimore County is, and that I ask them to assist in the 
getting the problem resolved. I find out that the Baltimore County Council is 
the local Franchising Authority. On November 30, I call the County Council's 
offices and speak to an employee who is assigned to handle cable television 
issues. I explain the situation; she says she will check into it. On December 
1,&nbsp; I speak to her again, and she says she had gotten in touch with the 
Assistant to the VP at Comcast Cablevision of Baltimore, and he will call her 
back with information.&nbsp; On December 3, when I speak to her again, she says 
that the assistant to the VP had assured her that Comcast is working on the 
problem. She is satisfied with this answer, and encourages me to "call her back 
to let her know when the problem's been resolved".&nbsp; It's nice to know that 
the employees of our local elected officials are really concerned about taking 
such a proactive role in ensuring that the problems of constituents are handled 
effectively. <br>
<hr>

<h3>&nbsp;Chapter 9:&nbsp; Boy, Do I Feel Like A Criminal</h3><b><i>Thursday, 
December 3, 1998:</i></b>&nbsp; One of the other Comcast&nbsp; attorneys calls 
me to say that the only person at the State's Attorney's office who can take 
care of the situation is an Assistant State's Attorney who is the Chief of the 
District Court Division, and that he has been out of the office all week.&nbsp; 
The attorney gives me the phone number, and tells me I can try to reach him 
myself.&nbsp; I call the number a few times during the day, and am alternately 
told that he is out of the office, or that "you're not allowed to call the 
State's Attorney, you're a defendant!".&nbsp; I leave a message for him, but it 
is not returned. 
<p>Also,&nbsp; around this time, I have a bizarre discussion with the 
Comcast&nbsp; attorney to try to find out why the State's Attorney disapproved 
the request to withdraw the charges.&nbsp; She explains that procedurally, they 
cannot withdraw the charges once the trial date has been set, and the summons 
has been served.&nbsp; She tells me that I should have "avoided being 
served".&nbsp; I never thought I'd ever get myself into a situation where I had 
to make a point of avoiding process servers. Anyway, it's true that the trial 
date had already been set (it was set on the same day Comcast applied for the 
Statement of Charges, November 17, 1998).&nbsp; But, the summons was not served 
to me until Wednesday, November 25.&nbsp; The State's Attorney disapproved the 
request for withdrawal of the charges on Tuesday, November 24, the day before I 
was served.&nbsp; So, either the State's Attorney's office doesn't know its own 
procedures, doesn't bother to follow them, or perhaps there's something more 
nefarious going on; I'm still not sure. <br>
</p><hr>

<h3>Chapter 10: In Which I Get To Speak With Sandra O'Connor's 
Second-In-Command</h3><b><i>Friday, December 4, 1998:</i></b> No, not 
<b><i>that</i></b> Sandra O'Connor.&nbsp; Baltimore County has its own, local, 
Sandra O'Connor.&nbsp; She's the State's Attorney (an elected official) and I've 
actually voted for her.&nbsp; I speak with her Deputy for Operations. Since he's 
responsible for the overseeing the District Court Division, he's the one that 
the Chief of the District Court Division reports to. I explain that Comcast said 
that the Chief of the District Court Division was the only one who could take 
care of the situation, but that he's been unavailable for several days.&nbsp; I 
ask the Deputy for Operations if he can take care of the situation in his 
employee's absence. He tells me no--that I should wait until his employee 
returns on the following Monday. He tells me that there is nothing in my file to 
show that Comcast has done anything related to the case since November 24, and 
that, if Comcast has promised to get the charges dismissed,&nbsp; I should be 
"on them" to take care of it. <br>
<hr>

<h3>Chapter 11: In Which I Get to Sit and Stew About This for Another Weekend 
Because the Only Person on Earth Who Can Apparently Take Care of this Situation 
is Either in Training, on Vacation, or Simply Out of the Office, Depending Upon 
Whom You Talk To</h3><b><i>December 5-6, 1998:</i></b> My demeanor begins to 
degrade into "don't get mad, get even" mode. I do some research on what the 
elements of a case of malicious prosecution are. (And, of course, I can do all 
of my research over the Internet--at cable modem speeds.)&nbsp; Paraphrasing one 
article that I read, the elements are: <br>1.&nbsp; The people that you sue for 
malicious prosecution have to be the one that got charges filed against you in 
the first place. <br>2.&nbsp; The case has to have been decided in your favor, 
in one way or another. <br>3.&nbsp; There has to have been a lack of probable 
cause. <br>4.&nbsp; There has to have been malice. <br>5.&nbsp; There have to be 
damages. 
<p>Although "malice" in this situation might be hard to prove, one article 
published on the subject asserts that malice can be implied from a lack of 
probable cause, and from inadequate investigation and research.&nbsp; "Lack of 
probable cause" might also be difficult to prove here, but I believe that a good 
lawyer could argue that the fact that "cables have been connected and Comcast 
Cablevision was not the one who connected them" is no longer acceptable as 
probable cause, now that Comcast Cablevision has given @home (or its local 
affiliate, Comcast Online Communications) the authority to connect them. <br>
</p><hr>

<h3>Chapter 12: Things Finally Start Falling Into Place</h3><b><i>December 7, 
1998:</i></b>&nbsp; I leave a voice mail message for the General Counsel at 
Comcast's Corporate Headquarters in Philadelphia telling him I'm unhappy with 
the way the situation is being handled, and that I'm considering filing a case 
in civil court for malicious prosecution. I receive a conciliatory call back 
from him, and also from one of the local Comcast attorneys telling me that the 
situation is being taken care of promptly.&nbsp; I finally get a call from the 
Chief of the District Court Division of the State's Attorney's office saying 
they will "nol pros" the case.&nbsp; It's great; I'm getting to learn some Latin 
while I'm at it.&nbsp; "Nol pros" is short for "nolle prosequi", which is Latin 
for "I will not prosecute."&nbsp;&nbsp; I can't believe it's taken over two 
weeks just to get a verbal agreement from the State's Attorney not to prosecute 
a case that everyone involved clearly agrees was based on a Comcast error. 
<p><b><i>December 12, 1998:</i></b> I receive a courtesy copy of a letter from 
the State's Attorney to the Judge, requesting that the trial date be moved up, 
and saying that they intend to nol pros. 
</p><p><b><i>December 22, 1998:</i></b>&nbsp; I call the District Court, and find 
out that the Judge has moved the trial date up to January 12, 1999, instead of 
the original date, which was in March 1999. <br>
</p><hr>

<h3>Chapter 13:&nbsp; In Which I Get an Unsolicited Letter From a Local Criminal 
Defense Attorney</h3><b><i>December 30, 1998:</i></b>&nbsp; I come home from 
work to find another interesting letter in my mailbox; this time it's from a 
local criminal defense attorney.&nbsp;&nbsp; It reads, "Dear Ms. Sammel,&nbsp; 
When you are charged with a criminal offense, not only can your freedom and 
liberty be taken away, a criminal record can affect you the rest of your 
life."&nbsp; The attorney then proceeds to offer his services, and even provides 
me with a handy little reminder card with my trial date stamped on it.&nbsp; 
Great.&nbsp; I guess that since the court's records are considered public 
documents, anyone can come in and get copies of them.&nbsp; I'm afraid to think 
about what kinds of mailing lists I could end up on as a result of this.&nbsp; 
Will I start receiving notices asking me if I want to subscribe to <b><i>Prison 
Life</i></b> magazine? <br>
<hr>

<h3>Chapter 14:&nbsp; In Which I Go to the Trial "Just In Case"</h3>Although 
I've been told by Comcast that I don't need to show up in court on the trial 
date, I've never received notice from the District Court about this.&nbsp; And, 
considering that the last paperwork I received from the court said "a warrant 
for your arrest may be issued" if you don't show up at your trial, I decide it 
would be best to show up anyway. 
<p><b><i>January 12, 1999: </i></b>Just when I'm starting to think that 
Comcast's motto has been morphed&nbsp; into "Comcast--Everything You Convict 
With", the court appearance is pretty uneventful.&nbsp; I show up at 8:30 along 
with about a dozen other people who are involved in other cases in the same 
courtroom that morning. According to the list outside the courtroom, it looks 
like there are a couple of theft cases and a couple of drug cases on the 
schedule.&nbsp; I'm actually starting to look forward to an interesting morning 
in court, hearing about all of this stuff, but the State's Attorney calls my 
case first.&nbsp; I start walking up to the Defendant's table, and hear the 
State's Attorney say that he's entering a nol pros.&nbsp;&nbsp; I've just 
reached the table when the judge says,&nbsp; "your case is dismissed, you're 
free to go," and so I turn back around and leave the courtroom. <br>
</p><hr>

<h3>Chapter 15: In Which The Assembled Readership Gets To Find Out That I Never 
Got Sent To Jail, But Just Got Threatened With The Possibility Of&nbsp; 
It</h3>Sorry to disappoint those of you who were looking forward to hearing 
about that part. 
<p>I gave the "malicious prosecution" scenario a thought, but I'm not really a 
lawsuit kind of person.&nbsp; Unless I find out that Comcast has been involved 
in a pattern of cases like these without regard to the consequences, I don't 
intend to follow up on filing a malicious prosecution lawsuit.&nbsp; Besides, if 
I want to get my criminal record expunged, it looks like I will need to sign a 
waiver absolving them of liability for this incident.&nbsp; I am hoping, 
however, that Comcast will reimburse me for the $30 fee involved in getting my 
record expunged. <br>
</p><hr>

<h3>Epilogue:</h3>Although everyone I dealt with seemed apologetic, and willing 
to help get this fairly outrageous situation taken care of, I believe that there 
are still some problems that Comcast and @Home management need to address.&nbsp; 
For that reason, I decided to write to the Presidents of both companies, and ask 
them to respond to several issues.&nbsp; A copy of the letter is below: <br>
<hr>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
[address deleted] 
<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
January 13, 1999 
</p><p>Brian L. Roberts <br>President, Comcast Corporation <br>1500 Market Street 
<br>Philadelphia PA 19102 
</p><p>Thomas A. Jermoluk <br>President,&nbsp; @Home Network <br>425 Broadway Street 
<br>Redwood City, CA 94063 
</p><p>Dear Messrs. Roberts and Jermoluk: 
</p><p>&nbsp;I am a Comcast@home cable modem subscriber (sammel@home.com) who is not 
concurrently a subscriber of Comcast cable television.&nbsp; Because of what I 
believe to be insufficient action by each of your companies, and insufficient 
coordination between them, I was recently criminally charged with cable fraud in 
the District Court of Maryland for Baltimore County ("State of Maryland vs. 
Sammel, Judith Lynne", case number 5C00097816).&nbsp; I was charged because: 
</p><ul>
  <li>@Home installation and repair technicians failed to install protective 
  measures to block out the cable television signal when both installing and 
  repairing my cable modem service, and failed to mark the connection inside the 
  cable "pedestal" that serves my home to indicate that it was a valid @Home 
  connection; and, 
  </li><li>Comcast Cablevision did not bother to check the records of&nbsp; the @Home 
  Network to see if I was a subscriber of cable modem service before filing an 
  application for a criminal summons, after they saw that the cable wires 
  serving my home were connected. </li></ul>&nbsp;Although, after a review of the 
facts of the situation, Comcast Cablevision convinced the State's Attorney to 
enter a "nolle prosequi" (a decision not to prosecute) in this case, I am 
requesting that both of your companies review their procedures for handling 
Comcast@home subscribers who are not concurrently Comcast cable television 
subscribers, to ensure that this situation does not happen to anyone else.&nbsp; 
I would appreciate if you would both respond to me concerning the following 
issues: 
<blockquote>
  <li>What are the procedures used to mark the cable connections of 
  non-cable-TV-subscriber customers of Comcast@home to ensure that Comcast 
  technicians are aware that the connection is a valid Comcast@home connection? 
  How do you assure that these procedures are being followed? 
  </li><li>Who is responsible for installing protective measures to block out the 
  cable television signal on the lines of non-cable-TV-subscriber customers of 
  Comcast@home, and how do you assure that these protective measures are being 
  properly installed? 
  </li><li>I would like request that procedures be put in place, so that prior to 
  submitting a request to any court of law to file criminal charges for cable 
  fraud,&nbsp; Comcast Cablevision will check the records of the @Home Network 
  to see if the individual to be charged is a valid customer of 
  Comcast@home.&nbsp; I am also asking the Administrative Commissioner of the 
  District Court of Maryland for Baltimore County (who will be receiving a 
  courtesy copy of this letter) to ensure that these procedures are followed 
  prior to the issuing of any summons for cable fraud in our county.&nbsp; 
  Perhaps the Court could require some type of affirmation that this check of 
  @Home's customer records has been performed prior to determining that there is 
  "probable cause" for a summons to be issued in any cable fraud case.&nbsp; I 
  firmly believe that if Comcast Cablevision has given @Home technicians the 
  authority to connect/modify cable connections, they also need to accept some 
  responsibility for having done so, and not automatically assume that any lines 
  that Comcast Cablevision has not connected themselves have been fraudulently 
  connected by the homeowner. 
  </li><li>I would like to request that procedures be put in place by Comcast 
  Cablevision customer support so that the records of non-cable-TV-subscriber 
  customers of Comcast@home are available to them, and that they may be able to 
  respond to customer service calls related&nbsp; to the physical cable 
  connections of Comcast@home customers (instead of insisting that only @Home 
  customer support can handle these requests.) 
  </li><li>I would like to request that procedures be put in place by both Comcast 
  Cablevision and Comcast@home customer support, so that they are each fully 
  aware of what their respective company's responsibilities are with regard to 
  non-cable-TV-subscriber customers of Comcast@home. </li></blockquote>I would 
like to note that every Comcast Cablevision and Comcast@home customer service 
representative I have spoken with has been extremely courteous, has seemed 
knowledgeable, and has conscientiously attempted to assist me within the bounds 
of what their positions allowed them to do.&nbsp; This leads me to believe that 
the problem is more of a "systemic" one, that can only be addressed from a 
management level; this is why I am asking both of you to ensure that this never 
happens to anyone again.&nbsp; In addition, I am requesting an apology for the 
unfortunate situation which has occurred. 
<p>Please contact me at your earliest convenience to inform me about how each of 
the issues listed above is being addressed.&nbsp; My mailing address and e-mail 
address are listed above, and my telephone numbers are [deleted]. 
</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
Sincerely, <br>&nbsp; 
</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
Judith L. Sammel <br>&nbsp; 
</p><p>cc: 
</p><ul>&nbsp; 
  <li>Joel Snyder, Administrative Commissioner, District Court of Maryland for 
  Baltimore County 
  </li><li>The Honorable S.G. Samuel Moxley, Councilmember, Baltimore County Council 
  (Franchising Authority for cable television in Baltimore County) 
  </li><li>Consumer Protection Division, Office of the Attorney General, State of 
  Maryland 
  </li><li>Federal Communications Commission, Cable Services Bureau 
  </li><li>C. Lynne Silverman, Esquire, Ned S. Kodeck, Chartered (attorney for 
  Comcast Cablevision of Maryland, LP) 
  </li><li>USENET newsgroups: athome.discussion-athomesvc, athome.discussion-general, 
  athome.users-general, balt.general, rec.video.cable-tv, misc.legal </li></ul>
<hr>

<h3>Acknowledgments:</h3>Thanks very much to attorneys S.A., S.B. (and her 
colleague H.), C.E., R.G. and B.H., who provided me with assorted legal advice. 
(Although, I imagine that "pro bono cable fraud work" won't really add much 
substance to your résumés.)&nbsp; I'd also like to offer thanks to various 
friends and colleagues who assisted me with such useful comments as, "we promise 
we'll visit you in jail," and to my 'unindicted coconspirator' S.R. for 
convincing me to get cable modem service in the first place. <br>
<hr>
<br><span color="#ff0000"><b><span size="+2">Update</span></b>:</span> 
<p><b><i>25 January 1999:</i></b>&nbsp; I received a nice letter from Comcast's 
Baltimore Metro area Vice President, and the local General Manager of Comcast 
Online <br>apologizing for these events, and outlining the steps they've taken 
to make sure this doesn't happen again.&nbsp; They now have a procedure to note 
@Home subscribers without cable TV service in their cable service billing 
system, and have added some checks and balances to ensure that their cable fraud 
investigators will be able to identify this type of situation in the 
future.&nbsp; This is a welcome change from the initial conversations I had with 
Comcast's attorney about this issue, where she insisted that no change in 
procedures was necessary, other than to ensure that the Comcast Online 
installers installed video traps in all installations where it's warranted. They 
graciously offered to pay the Court processing fees to get my record expunged, 
but I haven't gotten around to filling out the paperwork yet.&nbsp; Since the 
court told me that it can take up to 120 days for the paperwork to go through 
one it's filed, I'm not in such a great hurry anyway. 
</p><p><b><i>31 January 1999: </i></b>The <b><i>Multichannel News</i></b> felt that 
this story was worth publishing in the February 1, 1999 edition of their 
magazine (on the front page, even!)&nbsp; They snarfed my title, too.&nbsp; They 
gave me permission to repost the articles on my web site: '<a href="http://members.home.net/sammel/mcnarticle1.htm">Get a Cable Modem...Go to 
Jail'</a>&nbsp; and <a href="http://members.home.net/sammel/mcnarticle2.htm">Sammel's Tale of @Jail</a> 
. 
</p><p><b><i>2 February 1999:</i></b>&nbsp; I got home from work and found two notes 
attached to my door.&nbsp; One was another letter of apology from the Baltimore 
Metro Area VP and the local Comcast Online General Manager, saying that they 
plan to extend my @home service for a year at no charge, along with a $50.00 
gift certificate from Bibelot (my favorite bookstore!) The second was a 
handwritten note--they had apparently come by to deliver this in person, but I 
wasn't home.&nbsp; This is a very nice gesture; I appreciate it very much. 
</p><p>Does it make me feel bad for having contacted <b><i>Multichannel 
News</i></b>?&nbsp; No; not at all--for two reasons: 
</p><ul>
  <li>Although Comcast made every effort to get this taken care of after I 
  contacted them about the summons back in November--the bottom line is that 
  <i>this never should have happened</i>.&nbsp; There were people at Comcast who 
  knew last June (at least) that the lack of communication between the cable TV 
  folks and the cable modem folks was causing problems.&nbsp; It just never made 
  it high enough on anyone's radar screen to do anything about it. 
  </li><li>I went to Multichannel News rather than a general-audience publication 
  because I wanted to try to reach the folks at Shaw, Cox, TCI, Rogers, and Road 
  Runner (and its associated cable partners) to get them thinking about whether 
  the same problems could exist at their operations. </li></ul><b><i>4 February 
1999: </i></b>I got a humorous surprise when I got home from work.&nbsp; I had 
asked Multichannel News if they could send me a copy of the print edition of 
their publication, and it arrived in today's mail.&nbsp; I found out that not 
only was my saga featured on the front page and the op-ed section, but there was 
a wonderful <a href="http://members.home.net/ccb/cartoon.htm">cartoon</a> to go 
with it. 
<p><b><i>7 February 1999:</i></b>&nbsp; Since <b><i>Multichannel News</i></b> 
updated their on-line edition,&nbsp; I changed&nbsp; the references for the 
articles they published about this case (see 31 January 1999 entry) to point to 
my reposts of their articles, instead.&nbsp; Also, since the print version of 
Mike Farrell's article in last week's edition had some text missing, they've 
reprinted the article in the February 8, 1999 print edition. All of the articles 
are searchable in Multichannel's archives available from their <a href="http://www.multichannel.com/">home page</a>. 
</p><p><b><i>16 February 1999:</i></b>&nbsp; It appears that "Broadband Bob" picked 
up my story and published a brief version to their mailing list, and on their <a href="http://www.catv.org/bbb-report/">web page</a>.&nbsp; Also, a Brazilian has 
written an <a href="http://www.geocities.com/WallStreet/Exchange/8822/Noticias/1999/news0199.html">article</a> 
in Portugese based on Mike Farrell's article in Multichannel News. 
</p><p>I had a problem last Friday (February 12) with my cable modem service.&nbsp; 
Everything was proceeding at a snail's pace--mail, news, web-browsing.&nbsp; It 
continued for several hours, so I called to see if there was a problem in our 
area, or if they knew what might be wrong.&nbsp; They tried some troubleshooting 
(Tier 1 and Tier 2), and they said there was an RF problem with my connection, 
and they'd need to send someone out to look at it. The first time they had 
available was Monday (yesterday).&nbsp; They said "9:00 AM with a 4 hour window" 
for their arrival time.&nbsp; At 1:40 PM, a technician showed up.&nbsp; He did 
some testing at the cable modem (found a very weak signal), then at the 
connection where the cable enters my house (again, a weak signal), and then at 
the "pedestal" out on the street (again a weak signal--he said it was likely 
weak because there were <b><i>two</i></b> video traps on my line.&nbsp; I don't 
know this for sure, but I strongly suspect that the Comcast@home folks still had 
the "order on the books" for the video trap to be placed (see Chapter 3 above), 
and did not get the word that one had already been installed by Comcast 
Cablevision; so they came by to install another one.&nbsp; (So, not only don't 
the two organizations talk to each other, but they don't even recognize each 
other's handiwork?)&nbsp; So, he removed one of the video traps, and the signal 
started coming through strongly, and my service resumed immediately.&nbsp; I 
told him I wanted to make sure he didn't remove both video traps.&nbsp; He 
seemed curious why I was concerned about that, so I showed him the court 
documents, and told him I wanted to prevent a recurrence of the bizarre 
situation I found myself in last November.&nbsp; He said he couldn't believe 
that something like that had actually happened.&nbsp; (Join the crowd!) 
</p><p>Keep the cards and letters (well...the e-mails) coming.&nbsp; One person has 
suggested that I post the titles of the books I purchased with the gift 
certificate Comcast gave me, in the hopes that I bought some books that were 
apropos to the issue at hand.&nbsp; Honestly, I hadn't thought of that when I 
was book shopping, so I didn't specifically look for books that might be 
pertinent (Is there a "Malicious Prosecution for Dummies" book out?)&nbsp; The 
books I got were:&nbsp; <i>The Pillars of Hercules</i>, by Paul Theroux (a 
travelogue of his trip through the Mediterranean); <i>Getting A Life</i>, by 
Blix/Heitmiller (financial and personal strategies for voluntary simplicity); 
<i>The Pocket Idiot's Guide to Home Repair, </i>by David Tenenbaum; and, <i>The 
Argument Culture: Stopping America's War of Words</i>, by Deborah Tannen (of 
<i>You Just Don't Understand</i> fame).&nbsp; Fairly boring--sorry to disappoint 
you. 
</p><p>I mailed all the paperwork to the District Court to get my criminal record 
expunged.&nbsp; It included the "General Waiver and Release" which says that I 
release and discharge Comcast and the Baltimore County Police "and any and all 
other persons" for any claims I may have for wrongful conduct related to this 
incident.&nbsp; So, Comcast can rest easy about the legal aspect of all of this. 

</p><p><b><i>9 April 1999:&nbsp; </i></b>I got an e-mail from Brian McWilliams at 
<b><i><a href="http://www.internetnews.com/">InternetNews</a></i></b>, asking me 
to give an interview for InternetNews Radio.&nbsp; I called and spoke to him, 
and voila--a couple of hours later, there's a segment on my story in Real Audio 
format on <a href="http://members.home.net/sammel/inr.ram">InternetNews 
Radio</a>. (© 1999 Internet.com&nbsp; Linked to with permission of Internet.com) 

</p><p><b><i>10 April 1999:&nbsp; </i></b>There's a blurb about my saga&nbsp; in the 
current issue of&nbsp; <b><i><a href="http://www.netsurf.com/nsd/nsd.05.11.html">Netsurfer Digest</a></i></b> 
(Volume 05, Issue 11). 
</p><p><b><i>13 April 1999:&nbsp; </i></b>My story is a "Tasty Bit of the Day" from 
<b><i><a href="http://tbtf.com/">Tasty Bits from the Technology 
Front</a></i></b>.&nbsp; Lisa Ronthal at <b><i>WorldNetDaily</i></b> has a 
paragraph and a link to my site in her <b><i><a href="http://www.worldnetdaily.com/bluesky_ronthal/19990413_xcint_for_codecr.shtml">Interscope</a></i></b> 
column. 
</p><p><b><i>16 April 1999:&nbsp;</i></b> The Macintosh world has discovered the 
story, and links to it appear on <b><i><a href="http://www.macaddict.com/">Macaddict</a></i></b>, <b><i><a href="http://www.macresource.com/">Macresource</a></i></b>, and <b><i><a href="http://www.macintouch.com/">MacInTouch</a></i></b>. 
</p><p><b><i>25 April 1999:&nbsp;</i></b> I received a copy of the expungement 
order, dated 14 April 1999.&nbsp; This means that the court has 30 days to serve 
the order on the Baltimore County Detention Center, The Baltimore County Police, 
the Msp-Cjis Repository (?) and the State's Attorney.&nbsp; They each then have 
30 days to expunge their records, and provide a Certificate of Compliance back 
to the court, and to me.&nbsp; Now, if we can only expunge all records of my 
"criminal activities" from the Internet.&nbsp; :-)&nbsp; Someone has submitted 
my URL for the current issue (Vol. 20, Issue 33) of the <b><i><a href="http://catless.ncl.ac.uk/Risks/20.33.html">Risks Digest</a></i></b> which 
is available on the web, or on USENET as <b><i>comp.risks </i></b>.&nbsp; Yahoo 
has also listed my site in their section on <b><i><a href="http://headlines.yahoo.com/Full_Coverage/Tech/Bandwidth_News/">Bandwidth 
News</a></i></b>. 
</p><p><b><i>26 April 1999:&nbsp;</i></b> I've been "<a href="http://slashdot.org/article.pl?sid=99/04/26/1229227">slashdotted</a>". 
<br>&nbsp; 
</p><hr>

<center> Return to <a href="http://telecom-digest.org/" <="" a=""> Telecom Archives </a></center><a href="http://telecom-digest.org/" <="" a="">
</a>

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Oscilloscope watch ships after 10 years on Kickstarter (295 pts)]]></title>
            <link>https://www.tomshardware.com/news/oscilloscope-watch-ships-after-10-years</link>
            <guid>37385811</guid>
            <pubDate>Mon, 04 Sep 2023 22:38:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/news/oscilloscope-watch-ships-after-10-years">https://www.tomshardware.com/news/oscilloscope-watch-ships-after-10-years</a>, See on <a href="https://news.ycombinator.com/item?id=37385811">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-body">
<p>Ten years ago on Kickstarter, Gabriel Anzziani unveiled plans to produce an <a href="https://www.kickstarter.com/projects/920064946/oscilloscope-watch" data-url="https://www.kickstarter.com/projects/920064946/oscilloscope-watch"><u>oscilloscope watch</u></a>. The project caught on in popularity before fading into the ether for about a decade. After nearly forgetting about the project, <a href="https://twitter.com/BitBangingBytes/status/1695192177310150993" data-url="https://twitter.com/BitBangingBytes/status/1695192177310150993"><u>early backers</u></a> were surprised this month to receive a package containing the oscilloscope watch.</p><p>The project page received an update on July 30th of this year from Anzziani confirming that backers are now officially starting to receive their watches. According to the <a href="https://www.kickstarter.com/projects/920064946/oscilloscope-watch/posts/3872064" data-url="https://www.kickstarter.com/projects/920064946/oscilloscope-watch/posts/3872064"><u>post</u></a>, Anzziani is sending out between 10 and 20 rewards per week. The goal is to have all early rewards shipped by the end of 2023.</p><div><blockquote data-lang="en"><p lang="en" dir="ltr">10 years ago I saw an oscilloscope watch on #Kickstarter Today it arrived! pic.twitter.com/svowwpAqQx<a href="https://twitter.com/BitBangingBytes/status/1695192177310150993" data-url="https://twitter.com/BitBangingBytes/status/1695192177310150993">August 25, 2023</a></p></blockquote><p><span role="button" tabindex="0" aria-label="See more">See more</span></p></div><p>The oscilloscope watch has two modes. As the name suggests, it functions as both a watch and an oscilloscope. The watch mode has several useful features including formatting options for 24 vs 12 hour layouts and even an alarm. Of course, it also has an oscilloscope mode that works when the probes are inserted.</p><div aria-hidden="false" data-swipeable="true" data-hydrate="true" id="slice-container-UirZBzrCVkFBWDErQZZYPn-imageGallery-5"><figure data-bordeaux-image-check="false"><div data-hydrate="true"><p><img src="https://vanilla.futurecdn.net/cyclingnews/media/img/missing-image.svg" alt="Oscilloscope"></p></div><figcaption><span itemprop="copyrightHolder">(Image credit: Gabriel Anzziani)</span></figcaption></figure></div><p>The watch is powered by an 8-bit Xmega microcontroller with an internal PDI. It can be programmed to use custom mods using C. It has 8 buttons that can be programmed, as well, that surround the watch face on the outer edge. According to Anzziani, one goal of the project was to enable users to create their own apps for the watch.</p><p>The screen is a 1.28-inch, low-power E Ink display. Anzziani explains the expected battery life varies depending on whether or not the oscilloscope is in use. Without using the oscilloscope the battery can last around 30 days on a single charge. Using the oscilloscope cuts that down to about 12 hours.</p><p>If you want to get a closer look at this project, you can find details about it over at <a href="https://www.kickstarter.com/projects/920064946/oscilloscope-watch" data-url="https://www.kickstarter.com/projects/920064946/oscilloscope-watch"><u>Kickstarter</u></a>. &nbsp;Rewards are no longer available but you can still read more about how the project goes together. If this project seems up your alley, you might also want to check out this project that uses a Raspberry Pi Pico to power an <a href="https://www.tomshardware.com/news/raspberry-pi-pico-oscilloscope"><u>oscilloscope</u></a> with a smartphone UI.</p>
</div><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent"><section><p>Join the experts who read Tom's Hardware for the inside track on enthusiast PC tech news — and have for over 25 years. We'll send breaking news and in-depth reviews of CPUs, GPUs, AI, maker hardware and more straight to your inbox.</p></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Emacs Bedrock: A minimal Emacs starter kit (220 pts)]]></title>
            <link>https://sr.ht/~ashton314/emacs-bedrock/</link>
            <guid>37385716</guid>
            <pubDate>Mon, 04 Sep 2023 22:26:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sr.ht/~ashton314/emacs-bedrock/">https://sr.ht/~ashton314/emacs-bedrock/</a>, See on <a href="https://news.ycombinator.com/item?id=37385716">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2 id="bedrock"><a href="#bedrock" rel="nofollow noopener">#</a>Bedrock</h2>
<p>Stepping stones to a better Emacs experience</p>
<h3 id="synopsis"><a href="#synopsis" rel="nofollow noopener">#</a>Synopsis</h3>
<p>An <em>extremely</em> minimal Emacs starter kit uses just one external package by default, and only GNU-ELPA packages on an opt-in basis. Intended to be copied once and then modified as the user grows in knowledge and power.</p>
<ul>
<li><a href="https://sr.ht/~ashton314/emacs-bedrock/" rel="nofollow noopener">Project homepage</a></li>
<li><a href="https://todo.sr.ht/~ashton314/emacs-bedrock" rel="nofollow noopener">Issue Tracker</a></li>
<li>Mirrors:
<ul>
<li><a href="https://github.com/ashton314/emacs-bedrock" rel="nofollow noopener">GitHub</a> (just a place holder)</li>
</ul>
</li>
</ul>
<p><strong>NOTICE:</strong> Requires Emacs 29.1 or better.</p>
<h3 id="description"><a href="#description" rel="nofollow noopener">#</a>Description</h3>
<p>This is a minimal Emacs starter kit. Like, <em>really</em> minimal. Here's the short of the philosophy:</p>
<ul>
<li>
<p>Focus on using default, built-in Emacs behavior</p>
<p>Yes, we all love our fancy third-party packages. This starter kit focuses on what is built-in to Emacs. Why? Because there are too many good packages and picking and choosing the best is a joy we leave to the user.</p>
</li>
<li>
<p>Explain every customization and encourage modification</p>
<p>The goal of this starter kit is to encourage end-user adaptation and growth. All of the <code>.el</code> files should be legible and, more importantly, justify in plain English the rationale for adding the configuration they do.</p>
</li>
<li>
<p>No magic</p>
<p>We keep things <em>crushingly</em> simple here. That means no fancy loadable modules or whatnot. Everything is as straight-forward as can be.</p>
</li>
</ul>
<p>There are two files of interest: <code>early-init.el</code> and <code>init.el</code>.</p>
<h4 id="codeearly-initelcode"><a href="#codeearly-initelcode" rel="nofollow noopener">#</a><code>early-init.el</code></h4>
<p>The early init file uses <em>strictly</em> built-in Emacs features to do the following:</p>
<ul>
<li>Improve startup time</li>
<li>Set up initial frame behavior</li>
</ul>
<h4 id="codeinitelcode"><a href="#codeinitelcode" rel="nofollow noopener">#</a><code>init.el</code></h4>
<p>This is where the meat of all configuration goes. This file:</p>
<ul>
<li>Add minor UI niceties (e.g. clock in the tab-bar, full-screen by default, etc.)</li>
<li>Set the default theme (<code>modus-vivendi</code>)</li>
<li>Turn on discovery aids (e.g. <code>help-quick</code>, <a href="https://github.com/justbur/emacs-which-key" rel="nofollow noopener">which-key</a>, etc.)</li>
</ul>
<h4 id="trying-this-out-without-committing-too-hard"><a href="#trying-this-out-without-committing-too-hard" rel="nofollow noopener">#</a>Trying this out without committing too hard</h4>
<p>Emacs 29.1 added the handy <code>--init-directory</code> flag. This means that you can run <code>emacs --init-directory path/to/emacs-bedrock/</code> and all the customizations and package installations will be isolated to the project directory. Emacs should only add files that are already in the <code>.gitignore</code>.</p>
<p>Once you're happy, you should just copy <code>init.el</code> and <code>early-init.el</code> to <code>~/.emacs.d/</code>.</p>
<h3 id="mixins"><a href="#mixins" rel="nofollow noopener">#</a>Mixins</h3>
<p>For those who'd like a little more help in tailoring Emacs for specific purposes, the <code>mixins/</code> folder contains a few files that can be included via <code>(load-file "mixin/mixin-name.el")</code> from the <code>init.el</code> file, or copied wholesale or in part into <code>init.el</code> directly.</p>
<p><strong>NOTE:</strong> If you copy the <code>mixin/</code> directory to <code>~/.emacs.d/</code> or wherever you're setting <code>user-emacs-directory</code>, then simply incrementing the appropriate lines in the <code>init.el</code> file should work.</p>
<p>Mixins:</p>
<ul>
<li>Base UI Enhancements</li>
<li>Development tools</li>
<li>Org-mode</li>
<li>Vim refugee</li>
<li>Email (TODO: mu4e, EBDB)</li>
<li>Researcher (TODO: denote)</li>
</ul>
<h5 id="codemixinsbaseelcode"><a href="#codemixinsbaseelcode" rel="nofollow noopener">#</a><code>mixins/base.el</code></h5>
<p>Packages this mixin adds:</p>
<ul>
<li><a href="https://github.com/abo-abo/avy" rel="nofollow noopener">Avy</a></li>
<li><a href="https://github.com/oantolin/embark" rel="nofollow noopener">Embark</a></li>
<li><a href="https://github.com/minad/vertico" rel="nofollow noopener">Vertico</a></li>
<li><a href="https://github.com/minad/marginalia/" rel="nofollow noopener">Marginalia</a></li>
<li><a href="https://github.com/minad/corfu" rel="nofollow noopener">Corfu</a></li>
<li><a href="https://github.com/minad/consult" rel="nofollow noopener">Consult</a></li>
<li><a href="https://github.com/oantolin/orderless" rel="nofollow noopener">Orderless</a></li>
</ul>
<p>Along with a few ancillary packages that enhance the above.</p>
<p>These are some of the best UI enhancements that Emacs has to offer. Vertico and Consult make common operations like searching files, switching buffers, etc. a breeze. Corfu enhances the "completion at point" (aka "tab-to-complete") to show a little popup window like what you'd be used to in e.g. VS Code.</p>
<p>Avy is the fastest way to move around in a buffer, and it can do a <em>lot</em>.<a href="https://karthinks.com/software/avy-can-do-anything/" rel="nofollow noopener">^1</a> Embark is kind of like a right-click context menu, but entirely keyboard driven.</p>
<h5 id="codemixinsdevelcode"><a href="#codemixinsdevelcode" rel="nofollow noopener">#</a><code>mixins/dev.el</code></h5>
<p>Packages this mixin adds:</p>
<ul>
<li><a href="https://magit.vc/" rel="nofollow noopener">magit</a></li>
<li>Markdown, YAML, and JSON modes</li>
</ul>
<p>Magit is the best Git interface in the known universe. Some people use Emacs just so they can use Magit. It's that good. Entry point is bound to <code>C-c g</code> by default.</p>
<p>Built-in packages that this mixin configures:</p>
<ul>
<li><a href="https://github.com/joaotavora/eglot" rel="nofollow noopener">Eglot</a> (<a href="https://microsoft.github.io/language-server-protocol/" rel="nofollow noopener">Language Server Protocol (LSP) client</a>)</li>
<li>Treesit (<a href="https://github.com/tree-sitter" rel="nofollow noopener">Tree-Sitter</a> support)</li>
</ul>
<p>Both of these packages are new in Emacs 29. Be sure to run <code>M-x treesit-install-language-grammar</code> to install the language grammar you'll need before editing a file the respective language for the first time.</p>
<h5 id="codemixinsvim-likeelcode"><a href="#codemixinsvim-likeelcode" rel="nofollow noopener">#</a><code>mixins/vim-like.el</code></h5>
<p>Packages this mixin adds:</p>
<ul>
<li><a href="https://github.com/emacs-evil/evil" rel="nofollow noopener">Evil</a></li>
</ul>
<p>If you like Vim keybindings, then this is the mixin for you. It configures <code>evil-mode</code> and enables it, so you get Vim-like keybindings all throughout Emacs. I understand that this is the best Vim emulation outside of Vim itself. I use <code>evil-mode</code> in all my work.</p>
<p>Other packages that I use personally, but are not on GNU or non-GNU ELPA and so left out of the config include:</p>
<ul>
<li><a href="https://github.com/emacs-evil/evil-collection" rel="nofollow noopener">Evil-Collection</a> Add Evil-friendly keybindings to lots of corners of Emacs</li>
<li><a href="https://github.com/cofi/evil-leader" rel="nofollow noopener">Evil-Leader</a> Setting a prefix (i.e. "leader") key</li>
<li><a href="https://github.com/gregsexton/origami.el" rel="nofollow noopener">Origami</a> Code folding</li>
</ul>
<h5 id="codemixinsorgelcode"><a href="#codemixinsorgelcode" rel="nofollow noopener">#</a><code>mixins/org.el</code></h5>
<p>This mixin configures <code>org-mode</code>. There is a <em>lot</em> that Bedrock cannot configure out of the box—you will need to modify all variables to fit your file system and needs, as explained in comments in the file.</p>
<h5 id="codemixinsemailelcode"><a href="#codemixinsemailelcode" rel="nofollow noopener">#</a><code>mixins/email.el</code></h5>
<p>TODO</p>
<h3 id="using"><a href="#using" rel="nofollow noopener">#</a>Using</h3>
<p>Clone this repository wherever. Then you should copy <code>early-init.el</code>, <code>init.el</code>, and (optionally, recommended) <code>mixins/</code> into your <code>~/.emacs.d/</code> repository:</p>
<div><pre><span></span>git clone https://git.sr.ht/~ashton314/emacs-bedrock
mkdir -p ~/.emacs.d/
cp emacs-bedrock/early-init.el ~/.emacs.d/
cp emacs-bedrock/init.el ~/.emacs.d/
cp -r emacs-bedrock/mixins ~/.emacs.d/
</pre></div>
<p>Fire up Emacs and you're good to go!</p>
<h4 id="philosophy"><a href="#philosophy" rel="nofollow noopener">#</a>Philosophy</h4>
<p>Many people are looking for a good set of defaults and some easy-to-use switches that let Emacs get out of the way and let them work on what they want to. This is fine. This is not what Bedrock tries to do.</p>
<p>Emacs is the most customizable piece of software in existence. (No citation needed.) My goal with Bedrock is to make Emacs a little nicer by enabling some things that I personally think should be enabled by default. Bedrock goes a little further by suggesting a few well-built packages that go on to enhance the experience.</p>
<p>Bedrock encourages inspection and modification. I don't plan on making some core that periodically gets updated. You can think of this as just some guy's config that you wanted to adopt.</p>
<p>As an example of a deliberate choice, the <code>help-quick</code> buffer pops open on startup. Once a user has gotten used to this, they can just go into their <code>early-init.el</code> file and modify it themselves to remove that hook if they don't like it. It's a simple one-line change, and only users who are ready for it will do it.</p>
<p>When I started learning Emacs, my dad gave me his <code>.emacs</code> file. (That's what we used back in ye olden days instead of <code>.emacs.d/init.el</code> and stuff.) I used it without modification for many years. Eventually I learned how to write my own functions and customizations. This package aims to give other users a similar experience. When someone comes to me and expresses their desire to learn Emacs, I can point them at this to help them get over the initial hump, but not coddle them so much that they're afraid or unable to change things to their liking.</p>
<h3 id="requirements"><a href="#requirements" rel="nofollow noopener">#</a>Requirements</h3>
<p>Emacs 29.1 or later.</p>
<p>Emacs 29.1 is, as of 2023-09-04, the latest stable release. The specific features from Emacs 29.1 that Bedrock relies on are:</p>
<ul>
<li>The <code>use-package</code> macro for configuration</li>
<li>Enhancements to the built-in completion help (<code>completions-auto-select</code>, <code>completion-auto-help</code>, etc.)</li>
<li>Built-in tree-sitter support</li>
<li>Built-in LSP client (Eglot)</li>
</ul>
<h3 id="development"><a href="#development" rel="nofollow noopener">#</a>Development</h3>
<p>This is version <code>1.0.0</code>. No new <code>use-package</code> declarations will be added to <code>init.el</code>. No promises on the mixins. :)</p>
<p>This is a hobby project. Please be patient with development.</p>
<p>I welcome any feedback you may have. You can <a href="https://todo.sr.ht/~ashton314/emacs-bedrock" rel="nofollow noopener">open issues</a> or <a href="https://lambdaland.org/#contact" rel="nofollow noopener">drop me a line</a> directly with any comments or suggestions.</p>
<h4 id="roadmap"><a href="#roadmap" rel="nofollow noopener">#</a>Roadmap</h4>
<p>See the <a href="https://todo.sr.ht/~ashton314/emacs-bedrock" rel="nofollow noopener">issue tracker</a> on SourceHut.</p>
<h3 id="changelog"><a href="#changelog" rel="nofollow noopener">#</a>Changelog</h3>
<ul>
<li>
<p>1.0.0</p>
<p>2023-09-04</p>
<p>First "stable" release! Line number width improved, fix default load paths, expand Eglot and Vertico config, fix Corfu load.</p>
</li>
<li>
<p>0.2.1</p>
<p>2023-06-20</p>
<p>Minor bug fixes; add Embark package.</p>
</li>
<li>
<p>0.2.0</p>
<p>2023-03-14</p>
<p>Flesh out the <code>mixin/vim-like.el</code> so that there's <em>some</em> Vim configuration.</p>
</li>
<li>
<p>0.1.0</p>
<p>2023-01-17</p>
<p>Begin work on <code>mixin/org.el</code>, turn on windmove-mode.</p>
</li>
<li>
<p>0.0.2</p>
<p>2023-01-03</p>
<p>Reorganize to slim down <code>early-init.el</code> and add the first mixin files.</p>
</li>
<li>
<p>0.0.1</p>
<p>2023-01-03</p>
<p>Initial "release".</p>
</li>
</ul>

<ul>
<li>Ashton Wiersdorf <a href="https://lambdaland.org/" rel="nofollow noopener">https://lambdaland.org</a></li>
</ul>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LLM Python/CLI tool adds support for embeddings (143 pts)]]></title>
            <link>https://simonwillison.net/2023/Sep/4/llm-embeddings/</link>
            <guid>37384797</guid>
            <pubDate>Mon, 04 Sep 2023 20:37:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonwillison.net/2023/Sep/4/llm-embeddings/">https://simonwillison.net/2023/Sep/4/llm-embeddings/</a>, See on <a href="https://news.ycombinator.com/item?id=37384797">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>



<p>4th September 2023</p>

<p><a href="https://llm.datasette.io/">LLM</a> is my Python library and command-line tool for working with language models. I just released <a href="https://llm.datasette.io/en/stable/changelog.html#v0-9">LLM 0.9</a> with a new set of features that extend LLM to provide tools for working with <em>embeddings</em>.</p>
<p>This is a long post with a lot of theory and background. If you already know what embeddings are, here’s a TLDR you can try out straight away:</p>
<div><pre><span><span>#</span> Install LLM</span>
pip install llm

<span><span>#</span> If you already installed via Homebrew/pipx you can upgrade like this:</span>
llm install -U llm

<span><span>#</span> Install the llm-sentence-transformers plugin</span>
llm install llm-sentence-transformers

<span><span>#</span> Install the all-MiniLM-L6-v2 embedding model</span>
llm sentence-transformers register all-MiniLM-L6-v2

<span><span>#</span> Generate and store embeddings for every README.md in your home directory, recursively</span>
llm embed-multi readmes \
  --model sentence-transformers/all-MiniLM-L6-v2 \
  --files <span>~</span>/ <span><span>'</span>**/README.md<span>'</span></span>
  <span><span>#</span> Add --store to store the text content as well</span>

<span><span>#</span> Run a similarity search for "sqlite" against those embeddings</span>
llm similar readmes -c sqlite</pre></div>
<p>For everyone else, read on and the above example should hopefully all make sense.</p>
<h4>Embeddings</h4>
<p>Embeddings are a fascinating concept within the larger world of language models.</p>
<p>I explained embeddings in my recent talk, <a href="https://simonwillison.net/2023/Aug/27/wordcamp-llms/">Making Large Language Models work for you</a>. The relevant section of the slides and transcript <a href="https://simonwillison.net/2023/Aug/27/wordcamp-llms/#embeddings">is here</a>, or you can <a href="https://www.youtube.com/watch?v=aC7UQcZN6y8&amp;t=2189s">jump to that section on YouTube</a>.</p>
<p>An embedding model lets you take a string of text—a word, sentence, paragraph or even a whole document—and turn that into an array of floating point numbers called an <em>embedding vector</em>.</p>
<p><img src="https://static.simonwillison.net/static/2023/wordcamp-llms/llm-work-for-you.055.jpeg" alt="On the left is a text post from one of my sites: Storing and serving related documents with openai-to-sqlite and embeddings. An arrow points to a huge JSON array on the right, with the label 1536 floating point numbers."></p>
<p>A model will always produce the same length of array—1,536 numbers for the <a href="https://platform.openai.com/docs/guides/embeddings">OpenAI embedding model</a>, 384 for <a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2">all-MiniLM-L6-v2</a>—but the array itself is inscrutable. What are you meant to do with it?</p>
<p>The answer is that you can compare them. I like to think of an embedding vector as a location in 1,536-dimensional space. The distance between two vectors is a measure of how semantically similar they are in meaning, at least according to the model that produced them.</p>
<p><img src="https://static.simonwillison.net/static/2023/wordcamp-llms/llm-work-for-you.056.jpeg" alt="A location in 1,536 dimension space  There's a 3D plot with 400 red dots arranged randomly across 3 axis."></p>
<p>“One happy dog” and “A playful hound” will end up close together, even though they don’t share any keywords. The embedding vector represents the language model’s interpretation of the meaning of the text.</p>
<p>Things you can do with embeddings include:</p>
<ol>
<li>Find <strong>related items</strong>. I use this on <a href="https://til.simonwillison.net/">my TIL site</a> to display related articles, as described in <a href="https://til.simonwillison.net/llms/openai-embeddings-related-content">Storing and serving related documents with openai-to-sqlite and embeddings</a>.</li>
<li>Build <strong>semantic search</strong>. As shown above, an embeddings-based search engine can find content relevant to the user’s search term even if none of the keywords match.</li>
<li>Implement <strong>retrieval augmented generation</strong>—the trick where you take a user’s question, find relevant documentation in your own corpus and use that to get an LLM to spit out an answer. More on that <a href="https://simonwillison.net/2023/Aug/27/wordcamp-llms/#retrieval-augmented-generation">here</a>.</li>
<li>
<strong>Clustering</strong>: you can find clusters of nearby items and identify patterns in a corpus of documents.</li>
<li><strong>Classification</strong>: calculate the embedding of a piece of text and compare it to pre-calculated “average” embeddings for different categories.</li>
</ol>
<h4>LLM’s new embedding features</h4>
<p>My goal with LLM is to provide a plugin-driven abstraction around a growing collection of language models. I want to make installing, using and comparing these models as easy as possible.</p>
<p>The new release adds several command-line tools for working with embeddings, plus a new Python API for working with embeddings in your own code.</p>
<p>It also adds support for installing additional embedding models via plugins. I’ve released one plugin for this so far: <a href="https://github.com/simonw/llm-sentence-transformers">llm-sentence-transformers</a>, which adds support for new models based on the <a href="https://www.sbert.net/">sentence-transformers</a> library.</p>
<p>The example above shows how to use <code>sentence-transformers</code>. LLM also supports API-driven access to the OpenAI <code>ada-002</code> model.</p>
<p>Here’s how to embed some text using <code>ada-002</code>, assuming you have <a href="https://llm.datasette.io/en/stable/setup.html">installed LLM already</a>:</p>
<div><pre><span><span>#</span> Set your OpenAI API key</span>
llm keys <span>set</span> openai
<span><span>#</span> &lt;paste key here&gt;</span>

<span><span>#</span> Embed some text</span>
llm embed -m ada-002 -c <span><span>"</span>Hello world<span>"</span></span></pre></div>
<p>This will output a huge JSON list of floating point numbers to your terminal. You can add <code>-f base64</code> (or <code>-f hex</code>) to get that back in a different format, though none of these outputs are instantly useful.</p>
<p>Embeddings are much more interesting when you store them.</p>
<p>LLM already uses SQLite to <a href="https://llm.datasette.io/en/stable/logging.html">store prompts and responses</a>. It was a natural fit to use SQLite to store embeddings as well.</p>
<h4>Embedding collections</h4>
<p>LLM 0.9 introduces the concept of a <strong>collection</strong> of embeddings. A collection has a name—like <code>readmes</code>—and contains a set of embeddings, each of which has an ID and an embedding vector.</p>
<p>All of the embeddings in a collection are generated by the same model, to ensure they can be compared with each others.</p>
<p>The <code>llm embed</code> command can store the vector in the database instead of returning it to the console. Pass it the name of an existing (or to-be-created) collection and the ID to use to store the embedding.</p>
<p>Here we’ll store the embedding for the phrase “Hello world” in a collection called <code>phrases</code> with the ID <code>hello</code>, using that <code>ada-002</code> embedding model:</p>
<div><pre>llm embed phrases hello -m ada-002 -c <span><span>"</span>Hello world<span>"</span></span></pre></div>
<p>Future phrases can be added without needing to specify the model again, since it is remembered by the collection:</p>
<div><pre>llm embed phrases goodbye -c <span><span>"</span>Goodbye world<span>"</span></span></pre></div>
<p>The <code>llm embed-db collections</code> shows a list of collections:</p>
<div><pre>phrases: ada-002
  2 embeddings
readmes: sentence-transformers/all-MiniLM-L6-v2
  16796 embeddings</pre></div>
<p>The data is stored in a SQLite <code>embeddings</code> table with the following schema:</p>
<div><pre>CREATE TABLE [collections] (
   [id] <span>INTEGER</span> <span>PRIMARY KEY</span>,
   [name] <span>TEXT</span>,
   [model] <span>TEXT</span>
);
<span>CREATE</span> <span>TABLE</span> "<span>embeddings</span>" (
   [collection_id] <span>INTEGER</span> <span>REFERENCES</span> [collections]([id]),
   [id] <span>TEXT</span>,
   [embedding] BLOB,
   [content] <span>TEXT</span>,
   [content_hash] BLOB,
   [metadata] <span>TEXT</span>,
   [updated] <span>INTEGER</span>,
   <span>PRIMARY KEY</span> ([collection_id], [id])
);

CREATE UNIQUE INDEX [idx_collections_name]
    <span>ON</span> [collections] ([name]);
CREATE INDEX [idx_embeddings_content_hash]
    <span>ON</span> [embeddings] ([content_hash]);</pre></div>
<p>By default this is the SQLite database at the location revealed by <a href="">llm embed-db path</a>, but you can pass <code>--database my-embeddings.db</code> to various LLM commands to use a different database.</p>
<p>Each embedding vector is stored as a binary BLOB in the <code>embedding</code> column, consisting of those floating point numbers packed together as 32 bit floats.</p>
<p>The <code>content_hash</code> column contains a MD5 hash of the content. This helps avoid re-calculating the embedding (which can cost actual money for API-based embedding models like <code>ada-002</code>) unless the content has changed.</p>
<p>The <code>content</code> column is usually <code>null</code>, but can contain a copy of the original text content if you pass the <code>--store</code> option to the <code>llm embed</code> command.</p>
<p><code>metadata</code> can contain a JSON object with metadata, if you pass <code>--metadata '{"json": "goes here"}</code>.</p>
<p>You don’t have to pass content using <code>-c</code>—you can instead pass a file path using the <code>-i/--input</code> option:</p>
<div><pre>llm embed docs llm-setup -m ada-002 -i llm/docs/setup.md</pre></div>
<p>Or pipe things to standard input like this:</p>
<div><pre>cat llm/docs/setup.md <span>|</span> llm embed docs llm-setup -m ada-002 -i -</pre></div>
<h4>Embedding similarity search</h4>
<p>Once you’ve built a collection, you can search for similar embeddings using the <code>llm similar</code> command.</p>
<p>The <code>-c "term"</code> option will embed the text you pass in using the embedding model for the collection and use that as the comparison vector:</p>
<div><pre>llm similar readmes -c sqlite</pre></div>
<p>You can also pass the ID of an object in that collection to use that embedding instead. This gets you related documents, for example:</p>
<div><pre>llm similar readmes sqlite-utils/README.md</pre></div>
<p>The output from this command is currently newline-delimited JSON.</p>
<h4>Embedding in bulk</h4>
<p>The <code>llm embed</code> command embeds a single string at a time. <code>llm embed-multi</code> is much more powerful: you can feed a CSV or JSON file, a SQLite database or even have it read from a directory of files in order to embed multiple items at once.</p>
<p>Many embeddings models are optimized for batch operations, so embedding multiple items at a time can provide a significant speed boost.</p>
<p>The <code>embed-multi</code> command is described <a href="https://llm.datasette.io/en/stable/embeddings/cli.html#llm-embed-multi">in detail in the documentation</a>. Here are a couple of fun things you can do with it.</p>
<p>First, I’m going to create embeddings for every single one of my Apple Notes.</p>
<p>My <a href="https://datasette.io/tools/apple-notes-to-sqlite">apple-notes-to-sqlite</a> tool can export Apple Notes to a SQLite database. I’ll run that first:</p>
<div><pre>apple-notes-to-sqlite notes.db</pre></div>
<p>This took quite a while to run on my machine and generated a 828M SQLite database containing 6,462 records!</p>
<p>Next, I’m going to embed the content of all of those notes using the <code>sentence-transformers/all-MiniLM-L6-v2</code> model:</p>
<div><pre>llm embed-multi notes \
  -d notes.db \
  --sql <span><span>'</span>select id, title, body from notes<span>'</span></span> \
  -m sentence-transformers/all-MiniLM-L6-v2</pre></div>
<p>This took around 15 minutes to run, and increased the size of my database by 13MB.</p>
<p>The <code>--sql</code> option here specifies a SQL query. The first column must be an <code>id</code>, then any subsequent columns will be concatenated together to form the content to embed.</p>
<p>In this case the embeddings are written back to the same <code>notes.db</code> database that the content came from.</p>
<p>And now I can run embedding similarity operations against all of my Apple notes!</p>
<div><pre>llm similar notes -d notes.db -c <span><span>'</span>ideas for blog posts<span>'</span></span></pre></div>
<h4>Embedding files in a directory</h4>
<p>Let’s revisit the example from the top of this post. In this case, I’m using the <code>--files</code> option to search for files on disk and embed each of them:</p>
<div><pre>llm embed-multi readmes \
  --model sentence-transformers/all-MiniLM-L6-v2 \
  --files <span>~</span>/ <span><span>'</span>**/README.md<span>'</span></span></pre></div>
<p>The <code>--files</code> option takes two arguments: a path to a directory and a pattern to match against filenames. In this case I’m searching my home directory recursively for any files named <code>README.md</code>.</p>
<p>Running this command gives me embeddings for all of my README.md files, which I can then search against like this:</p>
<div><pre>llm similar readmes -c sqlite</pre></div>
<h4>Embeddings in Python</h4>
<p>So far I’ve only covered the command-line tools. LLM 0.9 also introduces a new Python API for working with embeddings.</p>
<p>There are two aspects to this. If you just want to embed content and handle the resulting vectors yourself, you can use <code>llm.get_embedding_model()</code>:</p>
<pre><span>import</span> <span>llm</span>

<span># This takes model IDs and aliases defined by plugins:</span>
<span>model</span> <span>=</span> <span>llm</span>.<span>get_embedding_model</span>(<span>"sentence-transformers/all-MiniLM-L6-v2"</span>)
<span>vector</span> <span>=</span> <span>model</span>.<span>embed</span>(<span>"This is text to embed"</span>)</pre>
<p><code>vector</code> will then be a Python list of floating point numbers.</p>
<p>You can serialize that to the same binary format that LLM uses like this:</p>
<pre><span>binary_vector</span> <span>=</span> <span>llm</span>.<span>encode</span>(<span>vector</span>)
<span># And to deserialize:</span>
<span>vector</span> <span>=</span> <span>llm</span>.<span>decode</span>(<span>binary_vector</span>)</pre>
<p>The second aspect of the Python API is the <code>llm.Collection</code> class, for working with collections of embeddings. This example code is quoted <a href="https://llm.datasette.io/en/stable/embeddings/python-api.html#working-with-collections">from the documentation</a>:</p>
<pre><span>import</span> <span>sqlite_utils</span>
<span>import</span> <span>llm</span>

<span># This collection will use an in-memory database that will be</span>
<span># discarded when the Python process exits</span>
<span>collection</span> <span>=</span> <span>llm</span>.<span>Collection</span>(<span>"entries"</span>, <span>model_id</span><span>=</span><span>"ada-002"</span>)

<span># Or you can persist the database to disk like this:</span>
<span>db</span> <span>=</span> <span>sqlite_utils</span>.<span>Database</span>(<span>"my-embeddings.db"</span>)
<span>collection</span> <span>=</span> <span>llm</span>.<span>Collection</span>(<span>"entries"</span>, <span>db</span>, <span>model_id</span><span>=</span><span>"ada-002"</span>)

<span># You can pass a model directly using model= instead of model_id=</span>
<span>embedding_model</span> <span>=</span> <span>llm</span>.<span>get_embedding_model</span>(<span>"ada-002"</span>)
<span>collection</span> <span>=</span> <span>llm</span>.<span>Collection</span>(<span>"entries"</span>, <span>db</span>, <span>model</span><span>=</span><span>embedding_model</span>)

<span># Store a string in the collection with an ID:</span>
<span>collection</span>.<span>embed</span>(<span>"hound"</span>, <span>"my happy hound"</span>)

<span># Or to store content and extra metadata:</span>
<span>collection</span>.<span>embed</span>(
    <span>"hound"</span>,
    <span>"my happy hound"</span>,
    <span>metadata</span><span>=</span>{<span>"name"</span>: <span>"Hound"</span>},
    <span>store</span><span>=</span><span>True</span>
)

<span># Or embed things in bulk:</span>
<span>collection</span>.<span>embed_multi</span>(
    [
        (<span>"hound"</span>, <span>"my happy hound"</span>),
        (<span>"cat"</span>, <span>"my dissatisfied cat"</span>),
    ],
    <span># Add this to store the strings in the content column:</span>
    <span>store</span><span>=</span><span>True</span>,
)</pre>
<p>As with everything else in LLM, the goal is that anything you can do with the CLI can be done with the Python API, and vice-versa.</p>
<h4 id="llm-cluster">Clustering with llm-cluster</h4>
<p>Another interesting application of embeddings is that you can use them to cluster content—identifying patterns in a corpus of documents.</p>
<p>I’ve started exploring this area with a new plugin, called <strong><a href="https://github.com/simonw/llm-cluster">llm-cluster</a>.</strong></p>
<p>You can install it like this:</p>

<p>Let’s create a new collection using data pulled from GitHub. I’m going to import all of the <a href="https://github.com/simonw/llm/issues">LLM issues</a> from the GitHub API, using my <a href="https://github.com/simonw/paginate-json">paginate-json</a> tool:</p>
<div><pre>paginate-json <span><span>'</span>https://api.github.com/repos/simonw/llm/issues?state=all&amp;filter=all<span>'</span></span> \
  <span>|</span> jq <span><span>'</span>[.[] | {id: .id, title: .title}]<span>'</span></span> \
  <span>|</span> llm embed-multi llm-issues - \
    --database issues.db \
    --model sentence-transformers/all-MiniLM-L6-v2 \
    --store</pre></div>
<p>Running this gives me a <code>issues.db</code> SQLite database with 218 embeddings contained in a collection called <code>llm-issues</code>.</p>
<p>Now let’s try out the <code>llm-cluster</code> command, requesting ten clusters from that collection:</p>
<div><pre>llm cluster llm-issues --database issues.db 10</pre></div>
<p>The output from this command, truncated, looks like this:</p>
<div><pre>[
  {
    <span>"id"</span>: <span><span>"</span>0<span>"</span></span>,
    <span>"items"</span>: [
      {
        <span>"id"</span>: <span><span>"</span>1784149135<span>"</span></span>,
        <span>"content"</span>: <span><span>"</span>Tests fail with pydantic 2<span>"</span></span>
      },
      {
        <span>"id"</span>: <span><span>"</span>1837084995<span>"</span></span>,
        <span>"content"</span>: <span><span>"</span>Allow for use of Pydantic v1 as well as v2.<span>"</span></span>
      },
      {
        <span>"id"</span>: <span><span>"</span>1857942721<span>"</span></span>,
        <span>"content"</span>: <span><span>"</span>Get tests passing against Pydantic 1<span>"</span></span>
      }
    ]
  },
  {
    <span>"id"</span>: <span><span>"</span>1<span>"</span></span>,
    <span>"items"</span>: [
      {
        <span>"id"</span>: <span><span>"</span>1724577618<span>"</span></span>,
        <span>"content"</span>: <span><span>"</span>Better ways of storing and accessing API keys<span>"</span></span>
      },
      {
        <span>"id"</span>: <span><span>"</span>1772024726<span>"</span></span>,
        <span>"content"</span>: <span><span>"</span>Support for `-o key value` options such as `temperature`<span>"</span></span>
      },
      {
        <span>"id"</span>: <span><span>"</span>1784111239<span>"</span></span>,
        <span>"content"</span>: <span><span>"</span>`--key` should be used in place of the environment variable<span>"</span></span>
      }
    ]
  },
  {
    <span>"id"</span>: <span><span>"</span>8<span>"</span></span>,
    <span>"items"</span>: [
      {
        <span>"id"</span>: <span><span>"</span>1835739724<span>"</span></span>,
        <span>"content"</span>: <span><span>"</span>Bump the python-packages group with 1 update<span>"</span></span>
      },
      {
        <span>"id"</span>: <span><span>"</span>1848143453<span>"</span></span>,
        <span>"content"</span>: <span><span>"</span>Python library support for adding aliases<span>"</span></span>
      },
      {
        <span>"id"</span>: <span><span>"</span>1857268563<span>"</span></span>,
        <span>"content"</span>: <span><span>"</span>Bump the python-packages group with 1 update<span>"</span></span>
      }
    ]
  }
]</pre></div>
<p>These look pretty good! But wouldn’t it be neat if we had a snappy title for each one?</p>
<p>The <code>--summary</code> option can provide exactly that, by piping the members of each cluster through a call to another LLM in order to generate a useful summary.</p>
<div><pre>llm cluster llm-issues --database issues.db 10 --summary</pre></div>
<p>This uses <code>gpt-3.5-turbo</code> to generate a summary for each cluster, with this default prompt:</p>
<blockquote>
<p>Short, concise title for this cluster of related documents.</p>
</blockquote>
<p>The results I got back are pretty good, including:</p>
<ul>
<li>Template Storage and Management Improvements</li>
<li>Package and Dependency Updates and Improvements</li>
<li>Adding Conversation Mechanism and Tools</li>
</ul>
<p>I tried the same thing using a Llama 2 model <a href="https://simonwillison.net/2023/Aug/1/llama-2-mac/">running on my own laptop</a>, with a custom prompt:</p>
<pre><code>llm cluster llm-issues --database issues.db 10 \
  --summary --model mlc-chat-Llama-2-13b-chat-hf-q4f16_1 \
  --prompt 'Concise title for this cluster of related documents, just return the title'
</code></pre>
<p>I didn’t quite get what I wanted! Llama 2 is proving a lot harder to prompt, so each cluster came back with something that looked like this:</p>
<blockquote>
<p>Sure! Here’s a concise title for this cluster of related documents:</p>
<p>“Design Improvements for the Neat Prompt System”</p>
<p>This title captures the main theme of the documents, which is to improve the design of the Neat prompt system. It also highlights the focus on improving the system’s functionality and usability</p>
</blockquote>
<p><a href="https://github.com/simonw/llm-cluster">llm-cluster</a> only took a few hours to throw together, which I’m seeing as a positive indicator that the LLM library is developing in the right direction.</p>
<h4>Future plans</h4>
<p>The two future features I’m most excited about are indexing and chunking.</p>
<h5>Indexing</h5>
<p>The <a href="https://llm.datasette.io/en/stable/embeddings/cli.html#llm-similar">llm similar</a> command and <a href="https://llm.datasette.io/en/stable/embeddings/python-api.html#retrieving-similar-items">collection.similar()</a> Python method currently use effectively the slowest brute force approach possible: calculate a cosine difference between input vector and every other embedding in the collection, then sort the results.</p>
<p>This works fine for collections with a few hundred items, but will start to suffer for collections of 100,000 or more.</p>
<p>There are plenty of potential ways of speeding this up: you can run a vector index like <a href="https://github.com/facebookresearch/faiss">FAISS</a> or <a href="https://github.com/nmslib/hnswlib">hnswlib</a>, use a database extension like <a href="https://github.com/asg017/sqlite-vss">sqlite-vss</a> or <a href="https://github.com/pgvector/pgvector">pgvector</a>, or turn to a hosted vector database like <a href="https://www.pinecone.io/">Pinecone</a> or <a href="https://milvus.io/">Milvus</a>.</p>
<p>With this many potential solutions, the obvious answer for LLM is to address this with plugins.</p>
<p>I’m still thinking through the details, but the core idea is that users should be able to define an index against one or more collections, and LLM will then coordinate updates to that index. These may not happen in real-time—some indexes can be expensive to rebuild, so there are benefits to applying updates in batches.</p>
<p>I experimented with FAISS earlier this year in <a href="https://datasette.io/plugins/datasette-faiss">datasette-faiss</a>. That’s likely to be the base for my first implementation.</p>
<p>The <a href="https://llm.datasette.io/en/stable/embeddings/python-api.html#sql-schema">embeddings table</a> has an <code>updated</code> timestamp column to support this use-case—so indexers can run against just the items that have changed since the last indexing run.</p>
<p>Follow <a href="https://github.com/simonw/llm/issues/216">issue #216</a> for updates on this feature.</p>
<h5>Chunking</h5>
<p>When building an embeddings-based search engine, the hardest challenge is deciding how best to “chunk” the documents.</p>
<p>Users will type in short phrases or questions. The embedding for a four word question might not necessarily map closely to the embedding of a thousand word article, even if the article itself should be a good match for that query.</p>
<p>To maximize the chance of returning the most relevant content, we need to be smarter about what we embed.</p>
<p>I’m still trying to get a good feeling for the strategies that make sense here. Some that I’ve seen include:</p>
<ul>
<li>Split a document up into fixed length shorter segments.</li>
<li>Split into segments but including a ~10% overlap with the previous and next segments, to reduce problems caused by words and sentences being split in a way that disrupts their semantic meaning.</li>
<li>Splitting by sentence, using NLP techniques.</li>
<li>Splitting into higher level sections, based on things like document headings.</li>
</ul>
<p>Then there are more exciting, LLM-driven approaches:</p>
<ul>
<li>Generate an LLM summary of a document and embed that.</li>
<li>Ask an LLM “What questions are answered by the following text?” and then embed each of the resulting questions!</li>
</ul>
<p>It’s possible to try out these different techniques using LLM already: write code that does the splitting, then feed the results to <a href="https://llm.datasette.io/en/stable/embeddings/python-api.html#storing-embeddings-in-bulk">Collection.embed_multi()</a> or <a href="https://llm.datasette.io/en/stable/embeddings/cli.html#llm-embed-multi">llm embed-multi</a>.</p>
<p>But... it would be really cool if LLM could split documents for you—with the splitting techniques themselves defined by plugins, to make it easy to try out new approaches.</p>
<h4>Get involved</h4>
<p>It should be clear by now that the potential scope of the LLM project is enormous. I’m trying to use plugins to tie together an enormous and rapidly growing ecosystem of models and techniques into something that’s as easy for people to work with and build on as possible.</p>
<p>There are plenty of ways you can help!</p>
<ul>
<li>
<a href="https://datasette.io/discord-llm">Join the #llm Discord</a> to talk about the project.</li>
<li>Try out plugins and run different models with them. There are <a href="https://llm.datasette.io/en/stable/plugins/directory.html">12 plugins already</a>, and several of those can be used to run dozens if not hundreds of models (<a href="https://github.com/simonw/llm-mlc">llm-mlc</a>, <a href="https://github.com/simonw/llm-gpt4all">llm-gpt4all</a> and <a href="https://github.com/simonw/llm-llama-cpp">llm-llama-cpp</a> in particular). I’ve hardly scratched the surface of these myself, and I’m testing exclusively on Apple Silicon. I’m really keen to learn more about which models work well, which models don’t and which perform the best on different hardware.</li>
<li>Try <a href="https://llm.datasette.io/en/stable/plugins/tutorial-model-plugin.html">building a plugin</a> for a new model. My dream here is that every significant Large Language Model will have an LLM plugin that makes it easy to install and use.</li>
<li>Build stuff using LLM and let me know what you’ve built. Nothing fuels an open source project more than stories of cool things people have built with it.</li>
</ul>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[When tech says ‘no’ (192 pts)]]></title>
            <link>https://www.ben-evans.com/benedictevans/2023/8/24/when-tech-says-no</link>
            <guid>37384517</guid>
            <pubDate>Mon, 04 Sep 2023 20:14:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ben-evans.com/benedictevans/2023/8/24/when-tech-says-no">https://www.ben-evans.com/benedictevans/2023/8/24/when-tech-says-no</a>, See on <a href="https://news.ycombinator.com/item?id=37384517">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-block-type="2" id="item-64e740480448971f24d33be6" data-layout-label="Post Body" data-type="item" data-updated-on="1692877202218">
  <p>This week I’ve been reading the latest drafts of the UK’s <a href="https://www.gov.uk/government/consultations/revised-investigatory-powers-act-notices-regimes-consultation/consultation-on-revised-notices-regimes-in-the-investigatory-powers-act-2016-accessible-version">Investigatory Powers Act</a>, which attempts to give UK law enforcement the power to ban security fixes, amongst other things (<a href="https://www.justsecurity.org/87615/changes-to-uk-surveillance-regime-may-violate-international-law/">here’s a summary</a>), and thinking about other famous regulatory disasters, and in turn thinking about what it means when people in an industry say ‘no!’ </p><p>Whenever anyone proposes new rules or regulations, the people affected always have reasons why this is a terrible idea that will cause huge damage.  This applies to bankers, doctors, farmers, lawyers, academics… and indeed software engineers. They always say ‘no’ and policy-makers can’t take that at face value: they discount it by some percentage, as a form of bargaining. But when people say ‘no’, they might actually mean one of three different things, and it’s important to understand the difference. </p><p>First, and this is the default, they’re saying no because they just don’t like it. They have their own opinion of how this should be done and don’t want outsiders making them change it. Quite possibly they already considered your plan and decided against it. The new policy is probably awkward, annoying and inconvenient, and will cost money (even if it’s not explicitly aimed at profits). It’s a pain in the arse. However, it is also <em>possible</em>, and not actually a big deal, and in the end it won’t really damage the product or the company. They <em>can</em> do it - they just don’t like it.  </p><p>A good current example might be the EU DSA’s requirement that if you run a marketplace and can ban people from using it, you need to have some due process and right of appeal: if Airbnb kicks someone off and that affects their income, that can’t be entirely arbitrary. Airbnb or Uber might think this is unnecessarily bureaucratic and that their existing processes are fine, but life will go on. Social networks will have to offer chronological feeds, though the theory of harm behind this rule is at best poorly-evidenced and most normal users don’t actually like them. It’s annoying to people at Meta or Tiktok, in the abstract, but it doesn’t matter much either way. And the next iPhone will probably switch to USB-C because of a new EU rule that has little to no real engineering or environmental benefit. In the end, it doesn’t actually matter much, and life goes on. ‘No’ just means ‘that’s annoying’. </p><p>Second, though, the tech industry (or the doctors, or the farmers) might be saying no because this really will have very serious negative consequences that you haven’t understood. </p><p>My favourite example is California’s <a href="https://en.wikipedia.org/wiki/California_Assembly_Bill_5_(2019)">2019 ‘AB5’ law</a>. This aimed to classify ‘gig economy’ workers, especially (and deliberately) Uber drivers, as employees, with access to healthcare. This might or might not be a good policy objective (reasonable people can debate this), but the law itself was drafted so ineptly that it effectively made anyone who did any freelance work an employee, and hence in turn effectively banned freelance work. There followed a desperate scramble to exempt over 100 professions, from doctors to truck drivers to hairdressers, before the whole thing had to be abandoned. A lot of people told the politicians about the problem, but the politicians just said “everyone always says every law will be a disaster” and ignored them. Oops.</p><p>Tech has a lot of examples of this kind of thing. The Canadian government told Google and Meta that if a link to a newspaper story ever appears in search, or if a journalist ever posts a link to a story on Facebook, then they have to pay the newspaper for sending business to the newspaper. Most of the Canadian tech and indeed media industries pointed out how stupid this was, and Google and Meta said that given the choice, they’d stop letting news appear rather than pay a fee they could not control and that had no economic basis. The government thought this was the first kind of ‘no’ and a bluff, but actually, it was the second kind. Oops. </p><p>To give another EU example (because that’s where most of the laws are coming from right now) the initial drafts of the DMA required anyone running a messaging app to let ‘any’ third party interconnect and interoperate, and to give any such third party ‘all’ the same access to internal data as internal teams. That sounds sensible… until you realise that hundreds of groups are trying to connect to WhatsApp or iMessage to spam their users, and you’ve just told Meta and Apple to let them do that, and that dozens of intelligence agencies would love to have ‘all the data your internal teams have’. Fortunately, in this case, when the entire tech industry said ‘you’re out of your mind’ the EU did actually listen. </p><p>If the second kind of ‘no’ is ‘that’s a really bad idea’, the third kind is ‘we actually can’t do that’. </p><p>The perennial example here, of course, is encryption. For the last 25 years, engineers have said ‘we can make it secure, or we can let law enforcement have access, but that means the Chinese can get in too” and politicians reply “no, make secure but not for people we like”. </p><p>My old boss Marc Andreessen, back when he was on the internet, liked to call this the ‘nerd harder’ argument. The engineer says not “I don’t want to” nor “that’s a bad idea” but “I genuinely have no idea how to do that even if I wanted to” and the policy-maker replies “you’re an engineer - work it out!” “Work it out” is generally a demand to invent new mathematics, but sadly, mathematics doesn’t work like that. Your MPs’ WhatsApp group can be secure, or it can readable by law enforcement and the Chinese, but you cannot have encryption that can be broken only by our spies and not their spies. Pick one. </p><p>I think the structural problem here, across all three kinds of ‘no’, is that this is pretty new to most of us. I often compare regulation of tech to regulation of cars - we do regulate cars, but it’s complicated and there are many different kinds of question. ‘Should cars have different emissions requirements?’ is a different kind of question to ‘does the tax code favour too much low-density development?’ and both questions are complicated. It’s a lot easier to want less congestion in cities than to achieve it, and it’s a lot easier to worry about toxic content on social media than to solve it, or even agree what ‘solve’ would mean. </p><p>But we all grew up with cars. We have a pretty good idea of how roads work, and what gearboxes are, even if we’ve never seen one, and if someone proposed that cars should not come with seats or headlights because that’s unfair competition for third-party suppliers, we could all see the problem. When policy-makers ask for secure encryption with a back door, we do not always see that this would like be telling Ford and GM to stop their cars from crashing, and to make them run on gasoline that doesn’t burn. Well yes, that would be nice, but how? They say ‘no’? Easy - just threaten them with a fine of 25% of global revenue and they’ll build it! </p><p>A Californian optimist would say that we’ll age out of this. The policy class that got their staff to print their emails will age out and be replaced by the generation that grew up sending emojis, and understands that tech policy is just as nuanced, complex and full of trade-offs as healthcare, transport or housing policy. A European would ask how well California handles healthcare, transport or housing. </p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Writing a C compiler in 500 lines of Python (449 pts)]]></title>
            <link>https://vgel.me/posts/c500/</link>
            <guid>37383913</guid>
            <pubDate>Mon, 04 Sep 2023 19:17:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vgel.me/posts/c500/">https://vgel.me/posts/c500/</a>, See on <a href="https://news.ycombinator.com/item?id=37383913">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
    
    <p>A few months ago, I set myself the challenge of writing a C compiler in 500 lines of Python<sup><a href="#lines">1</a></sup>, after writing my <a href="https://vgel.me/posts/donut/">SDF donut</a> post.
How hard could it be?
The answer was, pretty hard, even when dropping quite a few features.
But it was also pretty interesting, and the result is surprisingly functional and not too hard to understand!</p>
<p>There's too much code for me to comprehensively cover in a single blog post<sup><a href="#yak">2</a></sup>, so I'll just give an overview of the decisions I made, things I had to cut, and the general architecture of the compiler, touching on a representative piece of each part.
Hopefully after reading this post, <a href="https://github.com/vgel/c500/blob/main/compiler.py">the code</a> is more approachable!</p>
<span id="continue-reading"></span><h2 id="Decisions,_decisions"><a href="#Decisions,_decisions">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Decisions,_decisions">
</a>Decisions, decisions</h2>
<p>The first, and most critical decision, was that this would be a <em>single-pass</em> compiler.
500 lines is too spare to be defining and transforming an abstract syntax tree!
What does that mean?</p>
<h3 id="Most_compilers:_faffing_around_with_syntax_trees"><a href="#Most_compilers:_faffing_around_with_syntax_trees">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Most_compilers:_faffing_around_with_syntax_trees">
</a>Most compilers: faffing around with syntax trees</h3>
<p>Well, most compiler's internals look something like this:</p>
<center>
<img src="https://vgel.me/posts/c500/parsenon.png" alt="the codepoints walk down the yellow brick road, get lexed into tokens, then worship at the world's largest chomsky to become syntax trees, then are torn to pieces by the codegen hydra to produce machine instructions">
</center>
<p>The tokens get lexed, then a <em>parser</em> runs over them and builds pretty little syntax trees:</p>
<pre data-lang="python"><code data-lang="python"><span># hypothetical code, not from anywhere
</span><span>def </span><span>parse_statement</span><span>(</span><span>lexer</span><span>) -&gt; PrettyLittleSyntaxTree:
</span><span>    </span><span>...
</span><span>    </span><span>if </span><span>type </span><span>:= </span><span>lexer.try_next(TYPE_NAME):
</span><span>        variable_name </span><span>= </span><span>lexer.next(IDENTIFIER)
</span><span>
</span><span>        </span><span>if </span><span>lexer.try_next(</span><span>"="</span><span>):
</span><span>            initializer </span><span>= </span><span>parse_initializer(lexer)
</span><span>        </span><span>else</span><span>:
</span><span>            initializer </span><span>= </span><span>None
</span><span>
</span><span>        lexer.next(SEMICOLON)
</span><span>
</span><span>        </span><span>return </span><span>VariableDeclarationNode(
</span><span>            </span><span>type </span><span>= </span><span>type</span><span>,
</span><span>            </span><span>name </span><span>= </span><span>variable_name,
</span><span>            </span><span>initializer </span><span>= </span><span>initializer,
</span><span>        )
</span><span>    </span><span>...
</span><span>
</span><span># much later...
</span><span>def </span><span>emit_code_for</span><span>(</span><span>node</span><span>: PrettyLittleSyntaxTree) -&gt; DisgustingMachineCode:
</span><span>    </span><span>...
</span><span>    </span><span>if </span><span>isinstance</span><span>(node, VariableDeclarationNode):
</span><span>        slot </span><span>= </span><span>reserve_stack_space(node.type.sizeof())
</span><span>        add_to_environment(node.name, slot)
</span><span>        </span><span>if </span><span>node.initializer </span><span>is not </span><span>None</span><span>:
</span><span>            register </span><span>= </span><span>emit_code_for(node.initializer)
</span><span>            emit(</span><span>f</span><span>"mov </span><span>{register}</span><span>, [</span><span>{slot}</span><span>]"</span><span>)
</span><span>    </span><span>...
</span></code></pre>
<p>The important thing here is that there's <em>two passes</em>, first the parsing builds up a syntax tree, then a second pass chews that tree up and turns it into machine code.
That's really useful for most compilers!
It keeps the parsing and codegen separate, so each can evolve independently.
It also means that you can transform the syntax tree before using it to generate code—for example, by applying optimizations to it.
In fact, most compilers have <em>multiple</em> levels of "intermediate representations" between the syntax tree and codegen!</p>
<p>This is really great, good engineering, best practices, recommended by experts, etc.
But… it takes too much code, so we can't do it.</p>
<p>Instead, we'll be <em>single-pass</em>: code generation happens <em>during parsing</em>.
We parse a bit, emit some code, parse a bit more, emit a bit more code.
So for example, here's some real code from the <code>c500</code> compiler for parsing the prefix <code>~</code> op:</p>
<pre data-lang="python"><code data-lang="python"><span># lexer.try_next() checks if the next token is ~, and if so, consumes
</span><span># and returns it (truthy)
</span><span>elif </span><span>lexer.try_next(</span><span>"~"</span><span>):
</span><span>    </span><span># prefix() parses and generates code for the expression after the ~,
</span><span>    </span><span># and load_result emits code to load it, if needed
</span><span>    meta </span><span>= </span><span>load_result(prefix())
</span><span>    </span><span># immediately start yeeting out the negation code!
</span><span>    emit(</span><span>"i32.const 0xffffffff"</span><span>)
</span><span>    emit(</span><span>"i32.xor"</span><span>)
</span><span>    </span><span># webassembly only supports 32bit types, so if this is a smaller type,
</span><span>    </span><span># mask it down
</span><span>    mask_to_sizeof(meta.type)
</span><span>    </span><span># return type information
</span><span>    </span><span>return </span><span>meta
</span></code></pre>
<p>Notice there's no syntax trees, no <code>PrefixNegateOp</code> nodes.
We see some tokens and immediately spit out the corresponding instructions.</p>
<p>You may have noticed those instructions are <em>WebAssembly</em>, which leads us into the next section...</p>
<h3 id="Using_WebAssembly,_for_some_reason?"><a href="#Using_WebAssembly,_for_some_reason?">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Using_WebAssembly,_for_some_reason?">
</a>Using WebAssembly, for some reason?</h3>
<p>So I decided to make the compiler target WebAssembly.
I honestly don't know why I did this, it really didn't make it easier—I guess I was just curious?
WebAssembly is a really weird target, especially for C.
Besides the somewhat-external issues like spending a lot of time confused before I realized WebAssembly v2 is pretty different than WebAssembly v1, the instruction set itself is <em>weird</em>.</p>
<p>For one, there's <em>no goto</em>.
Instead, you have blocks—structured assembly, imagine that!—and "break" instructions that jump to either the beginning or end of a specific nesting-level of block.
This was basically inconsequential for <code>if</code> and <code>while</code>, but made implementing <code>for</code> <em>extremely</em> cursed, which we'll go over later.</p>
<p>Additionally, WebAssembly doesn't have registers, it has a stack, and is a stack machine.
At first you might think that's awesome, right?
C needs a stack!
We can just use the WebAssembly stack as our C stack!
Nope, because you can't take references to the WebAssembly stack.
So instead, we need to maintain our own in-memory stack <em>anyways</em>, and then shuffle it on and off of the WASM parameter stack.</p>
<p>So in the end, I think I ended up with slightly <em>more</em> code than I would have needed to target a more normal ISA like x86 or ARM.
But it was interesting!
And theoretically, you could run code compiled with <code>c500</code> in a browser, although I haven't tried (I just use the <code>wasmer</code> CLI).</p>
<h3 id="Error_handling"><a href="#Error_handling">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Error_handling">
</a>Error handling</h3>
<p>It basically doesn't.
There's a function <code>die</code>, which is called when anything weird happens and dumps a compiler stack trace—if you're lucky, you get a line number and a somewhat-vague error message.</p>
<pre><code><span>------------------------------
</span><span>
</span><span>  File "...compiler.py", line 835, in &lt;module&gt;
</span><span>    compile("".join(fi))  # todo: make this line-at-a-time?
</span><span>  File "...compiler.py", line 823, in compile
</span><span>    global_declaration(global_frame, lexer)
</span><span>  &lt;snip&gt;
</span><span>  File "...compiler.py", line 417, in value
</span><span>    var, offset = frame.get_var_and_offset(varname)
</span><span>  File "...compiler.py", line 334, in get_var_and_offset
</span><span>    return self.parent.get_var_and_offset(name)
</span><span>  File "...compiler.py", line 336, in get_var_and_offset
</span><span>    die(f"unknown variable {n}", None if isinstance(name, str) else name.line)
</span><span>  File "...compiler.py", line 14, in die
</span><span>    traceback.print_stack()
</span><span>
</span><span>------------------------------
</span><span>
</span><span>error on line 9: unknown variable c
</span></code></pre>
<p>The Rust compiler, this is not :-)</p>
<h3 id="What_to_drop"><a href="#What_to_drop">
  <img src="https://vgel.me/permalink.svg" alt="permalink for What_to_drop">
</a>What to drop</h3>
<p>Finally, I had to decide what <em>not</em> to support, since it just wasn't feasible to get <em>all</em> of C into 500 lines. (sorry!)
I decided I wanted a really decent sampling of features that tested what the general implementation approach was capable of—for example, if I had skipped pointers, I could have just gotten away with the WASM parameter stack and shed a lot of complexity, but that would have felt like cheating.</p>
<p>I ended up implementing the following features:</p>
<ul>
<li>arithmetic operations and binary operators, with proper precedence</li>
<li><code>int</code>, <code>short</code>, and <code>char</code> types</li>
<li>string constants (with escapes)</li>
<li>pointers (of however many levels), including correct pointer arithmetic (incrementing an <code>int*</code> adds 4)</li>
<li>arrays (only single-level, not <code>int[][]</code>)</li>
<li>functions</li>
<li>typedefs (and the lexer hack!)</li>
</ul>
<p>Notably, it doesn't support:</p>
<ul>
<li>structs :-( would be possible with more code, the fundamentals were there, I just couldn't squeeze it in</li>
<li>enums / unions</li>
<li>preprocessor directives (this would probably be 500 lines by itself...)</li>
<li>floating point. would also be possible, the <code>wasm_type</code> stuff is in, again just couldn't squeeze it in</li>
<li>8 byte types (<code>long</code>/<code>long long</code> or <code>double</code>)</li>
<li>some other small things like pre/post cremements, in-place initialization, etc., which just didn't quite fit</li>
<li>any sort of standard library or i/o that isn't returning an integer from <code>main()</code></li>
<li>casting expressions</li>
</ul>
<p>The compiler passes 34/220 test cases in the <a href="https://github.com/c-testsuite/c-testsuite">c-testsuite</a>.
More importantly to me, it can compile and run the following program successfully:</p>
<pre data-lang="c"><code data-lang="c"><span>int </span><span>swap</span><span>(</span><span>int</span><span>* </span><span>a</span><span>, </span><span>int</span><span>* </span><span>b</span><span>) {
</span><span>  </span><span>int</span><span> t;
</span><span>  t </span><span>= *</span><span>a; </span><span>*</span><span>a </span><span>= *</span><span>b; </span><span>*</span><span>b </span><span>=</span><span> t;
</span><span>  </span><span>return</span><span> t;
</span><span>}
</span><span>
</span><span>int </span><span>fib</span><span>(</span><span>int </span><span>n</span><span>) {
</span><span>  </span><span>int</span><span> a, b;
</span><span>  </span><span>for </span><span>(a </span><span>=</span><span> b </span><span>= </span><span>1</span><span>; n </span><span>&gt; </span><span>2</span><span>; n </span><span>=</span><span> n </span><span>- </span><span>1</span><span>) {
</span><span>    swap(</span><span>&amp;</span><span>a, </span><span>&amp;</span><span>b);
</span><span>    b </span><span>=</span><span> b </span><span>+</span><span> a;
</span><span>  }
</span><span>  </span><span>return</span><span> b;
</span><span>}
</span><span>
</span><span>int </span><span>main</span><span>() {
</span><span>  </span><span>return </span><span>fib(</span><span>10</span><span>); </span><span>// 55
</span><span>}
</span></code></pre>
<p>OK, enough about deciding things, let's get into the code!</p>
<h2 id="Helper_types"><a href="#Helper_types">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Helper_types">
</a>Helper types</h2>
<p>There's a small collection of helper types and classes that the compiler uses.
None of them are particularly strange, so I'll pass over them fairly quickly.</p>
<h3 id="Emitter_(compiler.py:21)"><a href="#Emitter_(compiler.py:21)">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Emitter_(compiler.py:21)">
</a><code>Emitter</code> <small>(<a href="https://github.com/vgel/c500/blob/e10f78891f925c2501611b848c10086ecc16ca4f/compiler.py#L21">compiler.py:21</a>)</small></h3>
<p>This is a singleton helper to emit nicely-formatted WebAssembly code.</p>
<p>WebAssembly, at least the textual format, is formatted as s-expressions, but individual instructions don't need to be parenthesized:</p>
<pre data-lang="clojure"><code data-lang="clojure"><span>(module
</span><span>  </span><span>;; &lt;snip...&gt;
</span><span>  (func $swap
</span><span>    (param $a i32)
</span><span>    (param $b i32)
</span><span>    (result i32)
</span><span>    global.get $__stack_pointer </span><span>;; prelude -- adjust stack pointer
</span><span>    i32.const </span><span>12
</span><span>    i32.sub
</span><span>    </span><span>;; &lt;snip...&gt;
</span><span>  )
</span><span>)
</span></code></pre>
<p><code>Emitter</code> just helps with emitting code with nice indentation so it's easier to read.
It also has a <code>no_emit</code> method, which will be used for an ugly hack later—stay tuned!</p>
<h3 id="StringPool_(compiler.py:53)"><a href="#StringPool_(compiler.py:53)">
  <img src="https://vgel.me/permalink.svg" alt="permalink for StringPool_(compiler.py:53)">
</a>StringPool <small>(<a href="https://github.com/vgel/c500/blob/e10f78891f925c2501611b848c10086ecc16ca4f/compiler.py#L53">compiler.py:53</a>)</small></h3>
<p><code>StringPool</code> holds all the string constants so they can be arranged in a contiguous region of memory, and hands out addresses into that for the codegen to use.
When you write <code>char *s = "abc"</code> in <code>c500</code>, what really happens is:</p>
<ol>
<li><code>StringPool</code> appends a null terminator</li>
<li><code>StringPool</code> checks if it's already stored <code>"abc"</code>, and if so, just hands that address back</li>
<li>Otherwise, <code>StringPool</code> adds it to a dictionary along with the base address + the total byte length stored so far—the address of this new string in the pool</li>
<li><code>StringPool</code> hands <em>that</em> address back</li>
<li>When all the code is finished compiling, we create an <code>rodata</code> section with the giant concatenated string produced by <code>StringPool</code>, stored at the string pool base address (retroactively making all the addresses <code>StringPool</code> handed out valid)</li>
</ol>
<h3 id="Lexer_(compiler.py:98)"><a href="#Lexer_(compiler.py:98)">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Lexer_(compiler.py:98)">
</a><code>Lexer</code> <small>(<a href="https://github.com/vgel/c500/blob/e10f78891f925c2501611b848c10086ecc16ca4f/compiler.py#L98">compiler.py:98</a>)</small></h3>
<p>The <code>Lexer</code> class is complex, because lexing C is complex <small>(<code>(\\([\\abfnrtv'"?]|[0-7]{1,3}|x[A-Fa-f0-9]{1,2}))</code> is a real regex in that code for character escapes)</small>, but conceptually simple: the lexer marches along identifying what the token at the current position is.
The caller can peek that token, or it can use <code>next</code> to tell the lexer to advance, "consuming" that token.
It can also use <code>try_next</code> to conditionally advance only if the next token is a certain kind—basically, <code>try_next</code> is a shortcut for <code>if self.peek().kind == token: return self.next()</code>.</p>
<p>There's some additionally complexity because of something called the <a href="https://en.wikipedia.org/wiki/Lexer_hack">"lexer hack"</a>.
Essentially, when parsing C you want to know if something is a type name or variable name (because that context matters for compiling certain expressions), but there's no syntactic distinction between them: <code>int int_t = 0;</code> is perfectly valid C, as is <code>typedef int int_t; int_t x = 0;</code>.</p>
<p>To know if an arbitrary token <code>int_t</code> is a type name or a variable name, we need to feed type information from the parsing/codegen stage back into the lexer.
This is a giant pain for regular compilers that want to keep their lexer, parser, and codegen modules pure and plantonically separate, but it's actually not very hard for us!
I'll explain it more when we get to the <code>typedef</code> section, but basically we just keep <code>types: set[str]</code> in <code>Lexer</code>, and when lexing, check if a token is in that set before giving it a token kind:</p>
<pre data-lang="python"><code data-lang="python"><span>if </span><span>m </span><span>:= </span><span>re.match(</span><span>r</span><span>"</span><span>^</span><span>[a-zA-Z_][a-zA-Z0-9_]</span><span>*</span><span>"</span><span>, self.src[self.loc :]):
</span><span>    tok </span><span>= </span><span>m.group(</span><span>0</span><span>)
</span><span>    </span><span>...
</span><span>    </span><span># lexer hack
</span><span>    </span><span>return </span><span>Token(TOK_TYPE </span><span>if </span><span>tok </span><span>in </span><span>self.types </span><span>else </span><span>TOK_NAME, tok, self.line)
</span></code></pre>
<h3 id="CType_(compiler.py:201)"><a href="#CType_(compiler.py:201)">
  <img src="https://vgel.me/permalink.svg" alt="permalink for CType_(compiler.py:201)">
</a><code>CType</code> <small>(<a href="https://github.com/vgel/c500/blob/e10f78891f925c2501611b848c10086ecc16ca4f/compiler.py#L201">compiler.py:201</a>)</small></h3>
<p>This is just a dataclass for representing information about a C type, like you'd write in <code>int **t</code> or <code>short t[5]</code> or <code>char **t[17]</code>, minus the <code>t</code>.</p>
<p>It contains:</p>
<ul>
<li>the type's name (with any typedefs resolved), such as <code>int</code> or <code>short</code></li>
<li>what level of pointer is is (<code>0</code> = not a pointer, <code>1</code> = <code>int *t</code>, <code>2</code> = <code>int **t</code>, and so on)</li>
<li>what the array size is (<code>None</code> = not an array, <code>0</code> = <code>int t[0]</code>, <code>1</code> = <code>int t[1]</code>, and so on)</li>
</ul>
<p>Notably, as mentioned before, this type only supports single-level arrays, and not nested arrays like <code>int t[5][6]</code>.</p>
<h3 id="FrameVar_and_StackFrame_(compiler.py:314)"><a href="#FrameVar_and_StackFrame_(compiler.py:314)">
  <img src="https://vgel.me/permalink.svg" alt="permalink for FrameVar_and_StackFrame_(compiler.py:314)">
</a><code>FrameVar</code> and <code>StackFrame</code> <small>(<a href="https://github.com/vgel/c500/blob/e10f78891f925c2501611b848c10086ecc16ca4f/compiler.py#L314">compiler.py:314</a>)</small></h3>
<p>These classes handle our C stack frames.</p>
<p>As I mentioned before, because you can't take references to the WASM stack, we have to manually handle the C stack, we can't use the WASM one.</p>
<p>To set up the C stack, the prelude emitted in <code>__main__</code> sets up a global <code>__stack_pointer</code> variable, and then every function call decrements that by however much space the function needs for its parameters and local variables—calculated by that function's <code>StackFrame</code> instance.</p>
<p>I'll go over how that calculation works in more detail when we get to parsing functions, but essentially, each parameter and local variable gets a slot in that stack space, and increases <code>StackFrame.frame_size</code> (and thus the offset of the <em>next</em> variable) depending on its size.
The offset, type information, and other data for each parameter and local variable are stored in a <code>FrameVar</code> instance, in <code>StackFrame.variables</code>, in order of declaration.</p>
<h3 id="ExprMeta_(compiler.py:344)"><a href="#ExprMeta_(compiler.py:344)">
  <img src="https://vgel.me/permalink.svg" alt="permalink for ExprMeta_(compiler.py:344)">
</a><code>ExprMeta</code> <small>(<a href="https://github.com/vgel/c500/blob/e10f78891f925c2501611b848c10086ecc16ca4f/compiler.py#L344">compiler.py:344</a>)</small></h3>
<p>This final dataclass is used to track whether the result of an expression is a <em>value</em> or a <em>place</em>.
We need to keep track of this distinction in order to handle certain expressions differently based on how they're used.</p>
<p>For example, if you have a variable <code>x</code> of type <code>int</code>, it can be used in two ways:</p>
<ol>
<li><code>x + 1</code> wants the <em>value</em> of <code>x</code>, say <code>1</code>, to operate on</li>
<li><code>&amp;x</code> wants the <em>address</em> of <code>x</code>, say <code>0xcafedead</code></li>
</ol>
<p>When we parse the <code>x</code> expression, we can easily fetch the address from the stack frame:</p>
<pre data-lang="python"><code data-lang="python"><span># look the variable up in the `StackFrame`
</span><span>var, offset </span><span>= </span><span>frame.get_var_and_offset(varname)
</span><span># put the base address of the C stack on top of the WASM stack
</span><span>emit(</span><span>f</span><span>"global.get $__stack_pointer"</span><span>)
</span><span># add the offset (in the C stack)
</span><span>emit(</span><span>f</span><span>"i32.const </span><span>{offset}</span><span>"</span><span>)
</span><span>emit(</span><span>"i32.add"</span><span>)
</span><span># the address of the variable is now on top of the WASM stack
</span></code></pre>
<p>But now what?
If we <code>i32.load</code> this address to get the value, then <code>&amp;x</code> will have no way to get the address.
But if we don't load it, then <code>x + 1</code> will try to add one to the address, resulting in <code>0xcafedeae</code> instead of <code>2</code>!</p>
<p>That's where <code>ExprMeta</code> comes in: we leave the address on the stack, and return an <code>ExprMeta</code> indicating this is a <em>place</em>:</p>
<pre data-lang="python"><code data-lang="python"><span>return </span><span>ExprMeta(</span><span>True</span><span>, var.type)
</span></code></pre>
<p>Then, for operations like <code>+</code> that always want to operate on values instead of places, there's a function <code>load_result</code> that turns any places into values:</p>
<pre data-lang="python"><code data-lang="python"><span>def </span><span>load_result</span><span>(</span><span>em</span><span>: ExprMeta) -&gt; ExprMeta:
</span><span>    </span><span>"""Load a place `ExprMeta`, turning it into a value
</span><span>    `ExprMeta` of the same type"""
</span><span>    </span><span>if </span><span>em.is_place:
</span><span>        </span><span># emit i32.load, i32.load16_s, etc., based on the type
</span><span>        emit(em.type.load_ins())
</span><span>    </span><span>return </span><span>ExprMeta(</span><span>False</span><span>, em.type)
</span><span>
</span><span>...
</span><span># in the code for parsing `+`
</span><span>lhs_meta </span><span>= </span><span>load_result(parse_lhs())
</span><span>...
</span></code></pre>
<p>Meanwhile, an operation like <code>&amp;</code> just doesn't load the result, and instead leaves the address on the stack: in an important sense, <code>&amp;</code> is a no-op in our compiler, since it doesn't emit any code!</p>
<pre data-lang="python"><code data-lang="python"><span>if </span><span>lexer.try_next(</span><span>"&amp;"</span><span>):
</span><span>    meta </span><span>= </span><span>prefix()
</span><span>    </span><span>if not </span><span>meta.is_place:
</span><span>        die(</span><span>"cannot take reference to value"</span><span>, lexer.line)
</span><span>    </span><span># type of &amp;x is int* when x is int, hence more_ptr
</span><span>    </span><span>return </span><span>ExprMeta(</span><span>False</span><span>, meta.type.more_ptr())
</span></code></pre>
<p>Note also that, despite being an <em>address</em>, the result of <code>&amp;</code> <em>isn't</em> a place! <small>(The code returns an <code>ExprMeta</code> with <code>is_place=False</code>.)</small>
The result of <code>&amp;</code> should be treated like a value, since <code>&amp;x + 1</code> <em>should</em> add <code>1</code> (or rather, <code>sizeof(x)</code>) to the address.
That's why we need the place/value distinction, since just "being an address" isn't enough to know whether the result of an expression should be loaded.</p>
<p>OK, enough about helper classes.
Let's move on to the meat of codegen!</p>
<h2 id="Parsing_and_code_generation"><a href="#Parsing_and_code_generation">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Parsing_and_code_generation">
</a>Parsing and code generation</h2>
<p>The general control flow of the compiler goes like this:</p>
<center>
<img src="https://vgel.me/posts/c500/compiler-flow.drawio.svg">
</center>
<p>The blue rectangles represent the main functions of the compiler—<code>__main__</code>, <code>compile()</code>, <code>global_declaration()</code>, <code>statement()</code>, and <code>expression()</code>.
The long chain of squares at the bottom shows the operator precedence—most of those functions are automatically generated by a higher-order function, however!</p>
<p>I'll go through the blue squares one-by-one and explain anything interesting in each.</p>
<h3 id="__main___(compiler.py:827)"><a href="#__main___(compiler.py:827)">
  <img src="https://vgel.me/permalink.svg" alt="permalink for __main___(compiler.py:827)">
</a><code>__main__</code> <small>(<a href="https://github.com/vgel/c500/blob/e10f78891f925c2501611b848c10086ecc16ca4f/compiler.py#L827">compiler.py:827</a>)</small></h3>
<p>This one is pretty short and dull.
Here it is in full:</p>
<pre data-lang="python"><code data-lang="python"><span>if </span><span>__name__ </span><span>== </span><span>"__main__"</span><span>:
</span><span>    </span><span>import </span><span>fileinput
</span><span>
</span><span>    </span><span>with </span><span>fileinput.input(</span><span>encoding</span><span>=</span><span>"utf-8"</span><span>) </span><span>as </span><span>fi:
</span><span>        </span><span>compile</span><span>(</span><span>""</span><span>.join(fi))  </span><span># todo: make this line-at-a-time?
</span></code></pre>
<p>Clearly I never finished that TODO!
The only really interesting thing here is the <code>fileinput</code> module, which you may not have heard of.
From the module docs,</p>
<blockquote>
<p>Typical use is:</p>
<pre data-lang="python"><code data-lang="python"><span>import </span><span>fileinput
</span><span>for </span><span>line </span><span>in </span><span>fileinput.input(</span><span>encoding</span><span>=</span><span>"utf-8"</span><span>):
</span><span>    process(line)
</span></code></pre>
<p>This iterates over the lines of all files listed in sys.argv[1:],
defaulting to sys.stdin if the list is empty.  If a filename is '-' it
is also replaced by sys.stdin and the optional arguments mode and
openhook are ignored.  To specify an alternative list of filenames,
pass it as the argument to input().  A single file name is also allowed.</p>
</blockquote>
<p>This means, technically, <code>c500</code> supports multiple files!
<small>(If you don't mind them all being concatenated and having messed-up line numbers :-) <code>fileinput</code> is actually fairly sophisticated and has a <code>filelineno()</code> method, I just didn't use it for space reasons.)</small></p>
<h3 id="compile()_(compiler.py:805)"><a href="#compile()_(compiler.py:805)">
  <img src="https://vgel.me/permalink.svg" alt="permalink for compile()_(compiler.py:805)">
</a><code>compile()</code> <small>(<a href="https://github.com/vgel/c500/blob/e10f78891f925c2501611b848c10086ecc16ca4f/compiler.py#L805">compiler.py:805</a>)</small></h3>
<p><code>compile()</code> is the first interesting function here, and is short enough to also include verbatim:</p>
<pre data-lang="python"><code data-lang="python"><span>def </span><span>compile</span><span>(</span><span>src</span><span>: </span><span>str</span><span>) -&gt; </span><span>None</span><span>:
</span><span>    </span><span># compile an entire file
</span><span>
</span><span>    </span><span>with </span><span>emit.block(</span><span>"(module"</span><span>, </span><span>")"</span><span>):
</span><span>        emit(</span><span>"(memory 3)"</span><span>)
</span><span>        emit(</span><span>f</span><span>"(global $__stack_pointer (mut i32) (i32.const </span><span>{PAGE_SIZE </span><span>* </span><span>3</span><span>}</span><span>))"</span><span>)
</span><span>
</span><span>        emit(</span><span>"(func $__dup_i32 (param i32) (result i32 i32)"</span><span>)
</span><span>        emit(</span><span>"  (local.get 0) (local.get 0))"</span><span>)
</span><span>        emit(</span><span>"(func $__swap_i32 (param i32) (param i32) (result i32 i32)"</span><span>)
</span><span>        emit(</span><span>"  (local.get 1) (local.get 0))"</span><span>)
</span><span>
</span><span>        global_frame </span><span>= </span><span>StackFrame()
</span><span>        lexer </span><span>= </span><span>Lexer(src, </span><span>set</span><span>([</span><span>"int"</span><span>, </span><span>"char"</span><span>, </span><span>"short"</span><span>, </span><span>"long"</span><span>, </span><span>"float"</span><span>, </span><span>"double"</span><span>]))
</span><span>        </span><span>while </span><span>lexer.peek().kind </span><span>!= </span><span>TOK_EOF:
</span><span>            global_declaration(global_frame, lexer)
</span><span>
</span><span>        emit(</span><span>'(export "main" (func $main))'</span><span>)
</span><span>
</span><span>        </span><span># emit str_pool data section
</span><span>        emit(</span><span>f</span><span>'(data $.rodata (i32.const </span><span>{str_pool.base}</span><span>) "</span><span>{str_pool.pooled()}</span><span>")'</span><span>)
</span></code></pre>
<p>This function handles emitting the module level prelude.</p>
<p>First, we emit a pragma for the WASM VM to reserve 3 pages of memory (<code>(memory 3)</code>), and we set the stack pointer to start at the end of that reserved region (it will grow downwards).</p>
<p>Then, we define two stack manipulation helpers <code>__dup_i32</code> and <code>__swap_i32</code>.
These should be familiar if you've ever used Forth: <code>dup</code> duplicates the item on top of the WASM stack <small>(<code>a -- a a</code>)</small>, and <code>swap</code> swaps the position of the top two items on the WASM stack <small>(<code>a b -- b a</code>)</small>.</p>
<p>Next, we initialize a stack frame to hold the global variables, initialize the lexer with the built-in typenames for the lexer hack, and chew up global declarations until we run out!</p>
<p>Finally, we export <code>main</code> and dump the string pool.</p>
<h3 id="global_declaration()_(compiler.py:743)"><a href="#global_declaration()_(compiler.py:743)">
  <img src="https://vgel.me/permalink.svg" alt="permalink for global_declaration()_(compiler.py:743)">
</a><code>global_declaration()</code> <small>(<a href="https://github.com/vgel/c500/blob/e10f78891f925c2501611b848c10086ecc16ca4f/compiler.py#L743">compiler.py:743</a>)</small></h3>
<p>This function is too long to inline the whole thing, but the signature looks like this:</p>
<pre data-lang="python"><code data-lang="python"><span>def </span><span>global_declaration</span><span>(</span><span>global_frame</span><span>: StackFrame, </span><span>lexer</span><span>: Lexer) -&gt; </span><span>None</span><span>:
</span><span>    </span><span># parse a global declaration -- typedef, global variable, or function.
</span><span>    </span><span>...
</span></code></pre>
<p>It handles typedefs, global variables, and functions.</p>
<p>Typedefs are cool, since this is where the lexer hack happens!</p>
<pre data-lang="python"><code data-lang="python"><span>if </span><span>lexer.try_next(</span><span>"typedef"</span><span>):
</span><span>    </span><span># yes, `typedef int x[24];` is valid (but weird) c
</span><span>    </span><span>type</span><span>, name </span><span>= </span><span>parse_type_and_name(lexer)
</span><span>    </span><span># lexer hack!
</span><span>    lexer.types.add(name.content)
</span><span>    typedefs[name.content] </span><span>= </span><span>type
</span><span>
</span><span>    lexer.next(</span><span>";"</span><span>)
</span><span>    </span><span>return
</span></code></pre>
<p>We reuse a general type-name parsing tool since typedefs inherit all of C's weird "declaration reflects usage" rules, which is convenient for us. (and less so for the perplexed newbie!)
Then we inform the lexer we've discovered a new type name, so that in the future that token will be lexed as a type name instead of a variable name.</p>
<p>Finally for typedefs, we store the type in the global typedef registry, consume the trailing semicolon, and return back to <code>compile()</code> for the next global declaration.
Importantly, the type we store is a <em>whole parsed type</em>, since if you do <code>typedef int* int_p;</code> and then later write <code>int_p *x</code>, <code>x</code> should get a resulting type of <code>int**</code>—the pointer level is additive!
That means we can't just store the base C typename, and instead need to store an entire <code>CType</code>.</p>
<p>If the declaration <em>wasn't</em> a typedef, we parse a variable type and name.
If we find a <code>;</code> token we know it's a global variable declaration (since we don't support global initializers).
In that case, we add the global variable to the global stack frame and bail.</p>
<pre data-lang="python"><code data-lang="python"><span>if </span><span>lexer.try_next(</span><span>";"</span><span>):
</span><span>    global_frame.add_var(name.content, decl_type, </span><span>False</span><span>)
</span><span>    </span><span>return
</span></code></pre>
<p>If there's no semicolon, however, we're definitely dealing with a function.
To generate code for a function, we need to:</p>
<ol>
<li>Make a new <code>StackFrame</code> for the function, named <code>frame</code></li>
<li>Then, parse all the parameters and store them in the frame with <code>frame.add_var(varname.content, type, is_parameter=True)</code></li>
<li>After that, parse all the variable declarations with <code>variable_declaration(lexer, frame)</code>, which adds them to <code>frame</code></li>
<li>Now we know how large the function's stack frame needs to be (<code>frame.frame_size</code>), so we can start emitting the prelude!</li>
<li>First, for all the parameters in the stack frame (added with <code>is_parameter=True</code>), we generate WASM <code>param</code> declarations so the function can be called with the WASM calling convention (passing the parameters on the WASM stack):</li>
</ol>
<pre data-lang="python"><code data-lang="python"><span>for </span><span>v </span><span>in </span><span>frame.variables.values():
</span><span>    </span><span>if </span><span>v.is_parameter:
</span><span>        emit(</span><span>f</span><span>"(param $</span><span>{v.name} {v.type.wasmtype}</span><span>)"</span><span>)
</span></code></pre>
<ol start="5">
<li>Then, we can emit a <code>result</code> annotation for the return type, and adjust the C stack pointer to make space for the function's parameters and variables:</li>
</ol>
<pre data-lang="python"><code data-lang="python"><span>emit(</span><span>f</span><span>"(result </span><span>{decl_type.wasmtype}</span><span>)"</span><span>)
</span><span>emit(</span><span>"global.get $__stack_pointer"</span><span>)
</span><span># grow the stack downwards
</span><span>emit(</span><span>f</span><span>"i32.const </span><span>{frame.frame_offset </span><span>+ </span><span>frame.frame_size}</span><span>"</span><span>)
</span><span>emit(</span><span>"i32.sub"</span><span>)
</span><span>emit(</span><span>"global.set $__stack_pointer"</span><span>)
</span></code></pre>
<ol start="6">
<li>For each parameter (in reverse order, because stacks), copy it from the WASM stack to our stack:</li>
</ol>
<pre data-lang="python"><code data-lang="python"><span>for </span><span>v </span><span>in </span><span>reversed</span><span>(frame.variables.values()):
</span><span>    </span><span>if </span><span>v.is_parameter:
</span><span>        emit(</span><span>"global.get $__stack_pointer"</span><span>)
</span><span>        emit(</span><span>f</span><span>"i32.const </span><span>{frame.get_var_and_offset(v.name)[</span><span>1</span><span>]}</span><span>"</span><span>)
</span><span>        emit(</span><span>"i32.add"</span><span>)
</span><span>        </span><span># fetch the variable from the WASM stack
</span><span>        emit(</span><span>f</span><span>"local.get $</span><span>{v.name}</span><span>"</span><span>)
</span><span>        </span><span># and store it at the calculated address in the C stack
</span><span>        emit(v.type.store_ins())
</span></code></pre>
<ol start="7">
<li>Finally, we can call <code>statement(lexer, frame)</code> in a loop to codegen all the statements in the function, until we hit the closing bracket:</li>
</ol>
<pre data-lang="python"><code data-lang="python"><span>while not </span><span>lexer.try_next(</span><span>"}"</span><span>):
</span><span>    statement(lexer, frame)
</span></code></pre>
<ol start="8">
<li>Bonus step: we assume the function will always have a <code>return</code>, so we <code>emit("unreachable")</code> so the WASM analyzer doesn't freak out.</li>
</ol>
<p>Whoof!
That was a lot.
But that's all for functions, and thus for <code>global_declaration()</code>, so let's move on to <code>statement()</code>.</p>
<h3 id="statement()_(compiler.py:565)"><a href="#statement()_(compiler.py:565)">
  <img src="https://vgel.me/permalink.svg" alt="permalink for statement()_(compiler.py:565)">
</a><code>statement()</code> <small>(<a href="https://github.com/vgel/c500/blob/e10f78891f925c2501611b848c10086ecc16ca4f/compiler.py#L565">compiler.py:565</a>)</small></h3>
<p>There's a lot of code in <code>statement()</code>.
However, most of it is fairly repetitive, so I'll just explain <code>while</code> and <code>for</code>, which should give a good overview.</p>
<p>Remember how WASM doesn't have jumps, and instead has structured control flow?
That's relevant now.</p>
<p>First, let's see how it works with <code>while</code>, where it's not too much trouble.
A while loop in WASM looks like this:</p>
<pre data-lang="clojure"><code data-lang="clojure"><span>block
</span><span>  loop
</span><span>    </span><span>;; &lt;test&gt;
</span><span>    i32.eqz
</span><span>    br_if </span><span>1
</span><span>    </span><span>;; &lt;loop body&gt;
</span><span>    br </span><span>0
</span><span>  end
</span><span>end
</span></code></pre>
<p>As you can see, there are two types of blocks—<code>block</code> and <code>loop</code> (there's also an <code>if</code> block type, which I didn't use).
Each encloses some number of statements and then ends with <code>end</code>.
Inside a block, you can break with <code>br</code>, or conditionally based on the top of the WASM stack with <code>br_if</code> (there's also <code>br_table</code>, which I didn't use).</p>
<p>The <code>br</code> family takes a <em>labelidx</em> parameter, here either <code>1</code> or <code>0</code>, which is what level of block the operation applies to.
So in our while loop, the <code>br_if 1</code> applies to the outer block—index 1, while the <code>br 0</code> applies to the inner block—index 0. <small>(indices are always relative to the instruction in question—0 is the innermost block <em>to that instruction</em>.)</small></p>
<p>Finally, the last rule to know is that a <code>br</code> in a <code>block</code> jumps <em>forwards</em>, to the end of the <code>block</code>, whereas a <code>br</code> in a <code>loop</code> jumps <em>backwards</em>, to the beginning of the <code>loop</code>.</p>
<p>So hopefully the while loop code makes sense now!
Looking at it again,</p>
<pre data-lang="clojure"><code data-lang="clojure"><span>block
</span><span>  loop
</span><span>    </span><span>;; &lt;test&gt;
</span><span>    i32.eqz
</span><span>
</span><span>    </span><span>;; if test == 0, jump forwards (1 = labelidx of the `block`),
</span><span>    </span><span>;; out of the loop
</span><span>    br_if </span><span>1
</span><span>
</span><span>    </span><span>;; &lt;loop body&gt;
</span><span>
</span><span>    </span><span>;; unconditionally jump backwards (0 = labelidx of the `loop`).
</span><span>    </span><span>;; to the beginning of the loop
</span><span>    br </span><span>0
</span><span>  end
</span><span>end
</span></code></pre>
<p>In more normal assembly, this would correspond to:</p>
<pre data-lang="nasm"><code data-lang="nasm"><span>.loop_start
</span><span>  ;; &lt;test&gt;
</span><span>  </span><span>jz </span><span>.block_end
</span><span>  ;; &lt;loop body&gt;
</span><span>  </span><span>jmp </span><span>.loop_start
</span><span>.block_end
</span></code></pre>
<p>But with jumps, you can express things that you can't (easily) in WASM—for example, you could jump into the middle of a block.</p>
<p><small>(This mainly is an issue for compiling C's <code>goto</code>, which I didn't even attempt—there's an algorithm that can transform any code using <code>goto</code> into an equivalent program using structured control flow, but it's complicated and I don't think it would work with our single-pass approach.)</small></p>
<p>But for while loops, this isn't too bad.
All we have to do is:</p>
<pre data-lang="python"><code data-lang="python"><span># `emit.block` is a context manager to emit the first parameter ("block" here),
</span><span># and then the second ("end") on exit
</span><span>with </span><span>emit.block(</span><span>"block"</span><span>, </span><span>"end"</span><span>):
</span><span>    </span><span>with </span><span>emit.block(</span><span>"loop"</span><span>, </span><span>"end"</span><span>):
</span><span>        </span><span># emit code for the test, ending with `i32.eqz`
</span><span>        parenthesized_test()
</span><span>        </span><span># emit code to exit the loop if the `i32.eqz` was true
</span><span>        emit(</span><span>"br_if 1"</span><span>)
</span><span>        </span><span># emit code for the body
</span><span>        bracketed_block_or_single_statement(lexer, frame)
</span><span>        </span><span># emit code to jump back to the beginning
</span><span>        emit(</span><span>"br 0"</span><span>)
</span></code></pre>
<p>With for loops though, it gets nasty.
Consider a for loop like this:</p>
<pre data-lang="c"><code data-lang="c"><span>for </span><span>(i </span><span>= </span><span>0</span><span>; i </span><span>&lt; </span><span>5</span><span>; i </span><span>=</span><span> i </span><span>+ </span><span>1</span><span>) {
</span><span>    j </span><span>=</span><span> j </span><span>* </span><span>2 </span><span>+</span><span> i;
</span><span>}
</span></code></pre>
<p>The order the parts of the for loop will be seen by the lexer/code generator is:</p>
<ol>
<li><code>i = 0</code></li>
<li><code>i &lt; 5</code></li>
<li><code>i = i + 1</code></li>
<li><code>j = j * 2 + i</code></li>
</ol>
<p>But the order we need to put them in the code, to work with WASM's structured control flow, is:</p>
<pre><code><span>block
</span><span>  ;; &lt; code for `i = 0` (1) &gt;
</span><span>  loop
</span><span>    ;; &lt; code for `i &lt; 5` (2) &gt;
</span><span>    br_if 1
</span><span>    ;; &lt; code for `j = j * 2 + i` (4!) &gt;
</span><span>    ;; &lt; code for `i = i + 1` (3!) &gt;
</span><span>    br 0
</span><span>  end
</span><span>end
</span></code></pre>
<p>Notice that 3 and 4 are inverted in the generated code, making the order 1, 2, 4, 3.
This is a problem for a single pass compiler!
Unlike a normal compiler, we can't store the advancement statement for later.
Or… can we?</p>
<p>How I ended up handling this is by making the lexer <em>cloneable</em>, and re-parsing the advancement statement <em>after</em> parsing the body.
Essentially, the code looks like:</p>
<pre data-lang="python"><code data-lang="python"><span>elif </span><span>lexer.try_next(</span><span>"for"</span><span>):
</span><span>    lexer.next(</span><span>"("</span><span>)
</span><span>    </span><span>with </span><span>emit.block(</span><span>"block"</span><span>, </span><span>"end"</span><span>):
</span><span>        </span><span># parse initializer (i = 0)
</span><span>        </span><span># (outside of loop since it only happens once)
</span><span>        </span><span>if </span><span>lexer.peek().kind </span><span>!= </span><span>";"</span><span>:
</span><span>            expression(lexer, frame)
</span><span>            emit(</span><span>"drop"</span><span>) </span><span># discard result of initializer
</span><span>        lexer.next(</span><span>";"</span><span>)
</span><span>
</span><span>        </span><span>with </span><span>emit.block(</span><span>"loop"</span><span>, </span><span>"end"</span><span>):
</span><span>            </span><span># parse test (i &lt; 5), if present
</span><span>            </span><span>if </span><span>lexer.peek().kind </span><span>!= </span><span>";"</span><span>:
</span><span>                load_result(expression(lexer, frame))
</span><span>                emit(</span><span>"i32.eqz ;; for test"</span><span>)
</span><span>                emit(</span><span>"br_if 1 ;; exit loop"</span><span>)
</span><span>            lexer.next(</span><span>";"</span><span>)
</span><span>
</span><span>            </span><span># handle first pass of advancement statement, if present
</span><span>            saved_lexer </span><span>= </span><span>None
</span><span>            </span><span>if </span><span>lexer.peek().kind </span><span>!= </span><span>")"</span><span>:
</span><span>                saved_lexer </span><span>= </span><span>lexer.clone()
</span><span>                </span><span># emit.no_emit() disables code output inside of it,
</span><span>                </span><span># so we can skip over the advancement statement for now
</span><span>                </span><span># to get to the for loop body
</span><span>                </span><span>with </span><span>emit.no_emit():
</span><span>                    expression(lexer, frame)
</span><span>            lexer.next(</span><span>")"</span><span>)
</span><span>
</span><span>            </span><span># parse body
</span><span>            bracketed_block_or_single_statement(lexer, frame)
</span><span>
</span><span>            </span><span># now that we parsed the body, go back and re-parse
</span><span>            </span><span># the advancement statement using the saved lexer
</span><span>            </span><span>if </span><span>saved_lexer </span><span>!= </span><span>None</span><span>:
</span><span>                expression(saved_lexer, frame)
</span><span>
</span><span>            </span><span># jump back to beginning of loop
</span><span>            emit(</span><span>"br 0"</span><span>)
</span></code></pre>
<p>As you can see, the hack is to save the lexer, then use <em>that</em> to go back and handle the advancement statement later, instead of saving the syntax tree like a normal compiler would.
Not very elegant—compiling for loops is probably the gnarliest code in the compiler—but it works well enough!</p>
<p>The other parts of <code>statement()</code> are mostly similar, so I'll skip over them to get to the last main part of the compiler—<code>expression()</code>.</p>
<h3 id="expression()_(compiler.py:375)"><a href="#expression()_(compiler.py:375)">
  <img src="https://vgel.me/permalink.svg" alt="permalink for expression()_(compiler.py:375)">
</a><code>expression()</code> <small>(<a href="https://github.com/vgel/c500/blob/e10f78891f925c2501611b848c10086ecc16ca4f/compiler.py#L375">compiler.py:375</a>)</small></h3>
<p><code>expression()</code> is the last big method in the compiler, and it handles parsing expressions, as you might expect.
It contains many inner methods, one for each precedence level, each returning the <code>ExprMeta</code> struct described earlier (which handle the "place vs value" distinction and can be turned into a value using <code>load_result</code>).</p>
<p>The bottom of the precedence stack is <code>value()</code> (somewhat confusingly named, since it can return <code>ExprMeta(is_place=True, ...)</code>).
It handles constants, parenthesized expressions, function calls, and variable names.</p>
<p>Above that, the basic pattern for a precedence level is a function like this:</p>
<pre data-lang="python"><code data-lang="python"><span> </span><span>def </span><span>muldiv</span><span>() -&gt; ExprMeta:
</span><span>    </span><span># lhs is the higher precedence operation (prefix operators, in this case)
</span><span>    lhs_meta </span><span>= </span><span>prefix()
</span><span>    </span><span># check if we can parse an operation
</span><span>    </span><span>if </span><span>lexer.peek().kind </span><span>in </span><span>(</span><span>"*"</span><span>, </span><span>"/"</span><span>, </span><span>"%"</span><span>):
</span><span>        </span><span># if so, load in the left hand side
</span><span>        lhs_meta </span><span>= </span><span>load_result(lhs_meta)
</span><span>        </span><span># grab the specific operator
</span><span>        op_token </span><span>= </span><span>lexer.next()
</span><span>        </span><span># the right hand side should use this function, for e.g. `x * y * z`
</span><span>        load_result(muldiv())
</span><span>        </span><span># emit an opcode to do the operation
</span><span>        </span><span>if </span><span>op_token </span><span>== </span><span>"*"</span><span>:
</span><span>            emit(</span><span>f</span><span>"i32.mul"</span><span>)
</span><span>        </span><span>elif </span><span>op_token </span><span>== </span><span>"/"</span><span>:
</span><span>            emit(</span><span>f</span><span>"i32.div_s"</span><span>)
</span><span>        </span><span>else</span><span>: </span><span># %
</span><span>            emit(</span><span>f</span><span>"i32.rem_s"</span><span>)
</span><span>        </span><span># mask down the result if this is a less-than-32bit type
</span><span>        mask_to_sizeof(lhs_meta.type)
</span><span>        </span><span># we produced a value (is_place=False)
</span><span>        </span><span>return </span><span>ExprMeta(</span><span>False</span><span>, lhs_meta.type)
</span><span>    </span><span># if we didn't find a token, just return the left hand side unchanged
</span><span>    </span><span>return </span><span>lhs_meta
</span></code></pre>
<p>In fact, this pattern is so consistent that most operations, including <code>muldiv</code>, aren't written out, but instead defined by a higher-order function <code>makeop</code>:</p>
<pre data-lang="python"><code data-lang="python"><span># function for generating simple operator precedence levels from declarative
</span><span># dictionaries of { token: instruction_to_emit }
</span><span>def </span><span>makeop</span><span>(
</span><span>    </span><span>higher</span><span>: Callable[[], ExprMeta], </span><span>ops</span><span>: </span><span>dict</span><span>[</span><span>str</span><span>, </span><span>str</span><span>], </span><span>rtype</span><span>: CType </span><span>| </span><span>None </span><span>= </span><span>None
</span><span>) -&gt; Callable[[], ExprMeta]:
</span><span>    </span><span>def </span><span>op</span><span>() -&gt; ExprMeta:
</span><span>        lhs_meta </span><span>= </span><span>higher()
</span><span>        </span><span>if </span><span>lexer.peek().kind </span><span>in </span><span>ops.keys():
</span><span>            lhs_meta </span><span>= </span><span>load_result(lhs_meta)
</span><span>            op_token </span><span>= </span><span>lexer.next()
</span><span>            load_result(op())
</span><span>            </span><span># TODO: type checking?
</span><span>            emit(</span><span>f</span><span>"</span><span>{ops[op_token.kind]}</span><span>"</span><span>)
</span><span>            mask_to_sizeof(rtype </span><span>or </span><span>lhs_meta.type)
</span><span>            </span><span>return </span><span>ExprMeta(</span><span>False</span><span>, lhs_meta.type)
</span><span>        </span><span>return </span><span>lhs_meta
</span><span>
</span><span>    </span><span>return </span><span>op
</span><span>
</span><span>muldiv </span><span>= </span><span>makeop(prefix, {</span><span>"*"</span><span>: </span><span>"i32.mul"</span><span>, </span><span>"/"</span><span>: </span><span>"i32.div_s"</span><span>, </span><span>"%"</span><span>: </span><span>"i32.rem_s"</span><span>})
</span><span>...
</span><span>shlr </span><span>= </span><span>makeop(plusminus, {</span><span>"&lt;&lt;"</span><span>: </span><span>"i32.shl"</span><span>, </span><span>"&gt;&gt;"</span><span>: </span><span>"i32.shr_s"</span><span>})
</span><span>cmplg </span><span>= </span><span>makeop(
</span><span>    shlr,
</span><span>    {</span><span>"&lt;"</span><span>: </span><span>"i32.lt_s"</span><span>, </span><span>"&gt;"</span><span>: </span><span>"i32.gt_s"</span><span>, </span><span>"&lt;="</span><span>: </span><span>"i32.le_s"</span><span>, </span><span>"&gt;="</span><span>: </span><span>"i32.ge_s"</span><span>},
</span><span>    CType(</span><span>"int"</span><span>),
</span><span>)
</span><span>cmpe </span><span>= </span><span>makeop(cmplg, {</span><span>"=="</span><span>: </span><span>"i32.eq"</span><span>, </span><span>"!="</span><span>: </span><span>"i32.ne"</span><span>}, CType(</span><span>"int"</span><span>))
</span><span>bitand </span><span>= </span><span>makeop(cmpe, {</span><span>"&amp;"</span><span>: </span><span>"i32.and"</span><span>})
</span><span>bitor </span><span>= </span><span>makeop(bitand, {</span><span>"|"</span><span>: </span><span>"i32.or"</span><span>})
</span><span>xor </span><span>= </span><span>makeop(bitor, {</span><span>"^"</span><span>: </span><span>"i32.xor"</span><span>})
</span><span>...
</span></code></pre>
<p>Only a few operations with special behavior need to be defined explicitly, like <code>plusminus</code> which needs to handle the nuances of C pointer math.</p>
<p>And that's it!
That's the last main piece of the compiler.</p>
<h2 id="Wrapping_up..."><a href="#Wrapping_up...">
  <img src="https://vgel.me/permalink.svg" alt="permalink for Wrapping_up...">
</a>Wrapping up...</h2>
<p>That's been our tour of the <a href="https://github.com/vgel/c500/">C compiler in 500 lines of Python</a>!
Compilers have a reputation for being complex—GCC and Clang are massive, and even TCC, the <em>Tiny</em> C Compiler, is tens of thousands of lines of code—but if you're willing to sacrifice code quality and do everything in a single pass, they can be surprisingly compact!</p>
<p>I'd be interested to hear if you write your own single-pass compiler—maybe for a custom language?
I think this kind of compiler could potentially be a great stage0 for a self-hosted language, since it's so simple.</p>
<p>Next time, this blog will be back to regularly-scheduled LLM posting with a post about making a small transformer by hand!</p>
<pre data-lang="python"><code data-lang="python"><span>MODEL </span><span>= </span><span>{
</span><span>    </span><span># EMBEDDING USAGE
</span><span>    </span><span>#  P = Position embeddings (one-hot)
</span><span>    </span><span>#  T = Token embeddings (one-hot, first is `a`, second is `b`)
</span><span>    </span><span>#  V = Prediction scratch space
</span><span>    </span><span>#
</span><span>    </span><span>#       [P, P, P, P, P, T, T, V]
</span><span>    </span><span>"wte"</span><span>: np.array(
</span><span>        </span><span># one-hot token embeddings
</span><span>        [
</span><span>            [</span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>1</span><span>, </span><span>0</span><span>, </span><span>0</span><span>],  </span><span># token `a` (id 0)
</span><span>            [</span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>1</span><span>, </span><span>0</span><span>],  </span><span># token `b` (id 1)
</span><span>        ]
</span><span>    ),
</span><span>    </span><span>"wpe"</span><span>: np.array(
</span><span>        </span><span># one-hot position embeddings
</span><span>        [
</span><span>            [</span><span>1</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>],  </span><span># position 0
</span><span>            [</span><span>0</span><span>, </span><span>1</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>],  </span><span># position 1
</span><span>            [</span><span>0</span><span>, </span><span>0</span><span>, </span><span>1</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>],  </span><span># position 2
</span><span>            [</span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>1</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>],  </span><span># position 3
</span><span>            [</span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>1</span><span>, </span><span>0</span><span>, </span><span>0</span><span>, </span><span>0</span><span>],  </span><span># position 4
</span><span>        ]
</span><span>    ),
</span><span>    </span><span>...</span><span>: </span><span>...
</span><span>}
</span></code></pre>
<p>If that sounds interesting, or you want to see more posts like this, consider <a href="https://twitter.com/voooooogel/">following me on Twitter</a> or subscribing to my mailing list to get updates on new posts!</p>

<p>If you have thoughts about this post, please feel free to <a href="https://vgel.me/contact">get in touch</a>!
<small>(Even if you just want to say "that was cool" or want to ask a clarifying question—don't feel like it needs to be capital-I-Important!)</small></p>
<p>And if you're still around, you must really like the blog, so here's some more stuff to check out :-)</p>
<ul>
<li><a href="https://vgel.me/posts">My other blog posts</a>, such as:
<ul>
<li><a href="https://vgel.me/posts/donut">Signed distance functions in 46 lines of Python</a></li>
<li><a href="https://vgel.me/posts/tools-not-needed/">GPT-3 will ignore tools when it disagrees with them</a></li>
<li><a href="https://vgel.me/posts/mmap-arena-alloc">mmap(1Tb): A Rust arena allocator (ab)using Linux overcommit</a></li>
<li><a href="https://vgel.me/posts/gpt4-javascript">Does GPT-4 think better in Javascript?</a></li>
</ul>
</li>
<li><a href="https://vgel.me/">My other projects</a>, including <a href="https://vgel.me/fiction">my short fiction</a></li>
<li>My <a href="https://twitter.com/voooooogel/">Twitter</a></li>
</ul>
<hr>

<!---->


    <ul>
      
        <li><strong>Previous entry:</strong> <a href="https://vgel.me/posts/adversarial-training-data/">I'm worried about adversarial training data</a></li>
      
      
    </ul>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Spectrolite – Mac app to make colorful risograph prints and zines more easily (157 pts)]]></title>
            <link>https://spectrolite.app</link>
            <guid>37383749</guid>
            <pubDate>Mon, 04 Sep 2023 19:00:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrolite.app">https://spectrolite.app</a>, See on <a href="https://news.ycombinator.com/item?id=37383749">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Home insurers cut natural disasters from policies as climate risks grow (113 pts)]]></title>
            <link>https://www.washingtonpost.com/business/2023/09/03/natural-disaster-climate-insurance/</link>
            <guid>37383548</guid>
            <pubDate>Mon, 04 Sep 2023 18:44:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/business/2023/09/03/natural-disaster-climate-insurance/">https://www.washingtonpost.com/business/2023/09/03/natural-disaster-climate-insurance/</a>, See on <a href="https://news.ycombinator.com/item?id=37383548">Hacker News</a></p>
Couldn't get https://www.washingtonpost.com/business/2023/09/03/natural-disaster-climate-insurance/: Error [ERR_FR_TOO_MANY_REDIRECTS]: Maximum number of redirects exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Chinchilla’s death (161 pts)]]></title>
            <link>https://espadrine.github.io/blog/posts/chinchilla-s-death.html</link>
            <guid>37383413</guid>
            <pubDate>Mon, 04 Sep 2023 18:31:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://espadrine.github.io/blog/posts/chinchilla-s-death.html">https://espadrine.github.io/blog/posts/chinchilla-s-death.html</a>, See on <a href="https://news.ycombinator.com/item?id=37383413">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  <article>

<blockquote>
<p>“With more careful calculations, one can win; with less, one cannot”
— Sun Tzu, <em>The Art of War</em>.</p>
</blockquote>
<p>Making extrapolations is crucial to avoid wasting our computing power on slow
convergence. After all, if you had to walk to the Everest,
you wouldn’t eyeball it: you would use a GPS.</p>
<p>Sometimes you have to look away from the GPS and onto the road, though.
Sometimes things don’t extrapolate through simple formulae.
It was true for XIXth-century physicists with the <a href="https://en.wikipedia.org/wiki/Ultraviolet_catastrophe">ultraviolet catastrophe</a>;
it is true for LLMs too.
What we estimate to be true near the center can deviate widely in the far lands…</p>
<p><img src="https://i.imgur.com/Mf85NuW.png" alt="Image of Minecraft far lands: a terrain that suddenly becomes distorted and overlaps itself cliffly"></p>
<h2 id="What_s_this_Chinchilla_thing_anyway_">What’s this Chinchilla thing anyway? </h2>
<p>Smaller models have fewer multiplications.
Thus they run faster. Thus they train faster.
However, the theory goes, they eventually reach the limit of their capacity for
knowledge, and their learning slows, while that of a larger model,
with a larger capacity, will overtake them and reach better performance
past a given amount of training time.</p>
<p>While estimating how to get the best bang for the buck during training,
both <a href="https://arxiv.org/abs/2001.08361">OpenAI</a> and <a href="https://arxiv.org/abs/2203.15556">DeepMind</a> attempted to draw the Pareto
frontier. They don’t state explicitly that they use that theory to draw it;
the closest quote that hints at this hidden assumption is from OpenAI:</p>
<blockquote>
<p>We expect that larger models should always perform better than smaller models.
[…]
A model with fixed size will be capacity-limited.</p>
</blockquote>
<p>This presumption is the bedrock of how they compute the Pareto frontier.
In the Chinchilla work, figure 2 shows the training loss of a large number of
training runs for models with varying size.
At a first glance, those curves follow the theory:
the smaller models initially have a lower loss (good),
but eventually it slows down,
and gets overtaken by the curve from a larger model (bad).</p>
<p><img src="https://espadrine.github.io/blog/assets/chinchilla-s-death/chinchilla.png" alt="Chinchilla graph comparing the loss curves for many different model sizes"></p>
<p>In that chart, they drew grey dots every time they pinpointed the smaller model
starting to lose out to a larger model.
The grey line, the Pareto frontier, is how they computed their scaling laws.</p>
<p>The problem with this assumption is that
we have no idea what would happen if we let the smaller model train for longer,
since they stopped its training as soon as it was overtaken.</p>
<p>Enter the LLaMA paper.</p>
<h2 id="Can_Chinchillas_picture_a_Llama_s_sights_">Can Chinchillas picture a Llama’s sights? </h2>
<p>Earlier this year, Meta trained four models with varying sizes.
Unlike other works, they trained each of them for a very large amount of time;
even the smaller ones.</p>
<p>They published the training run curves:</p>
<p><img src="https://espadrine.github.io/blog/assets/chinchilla-s-death/llama1-training.png" alt="Training loss curves for the four LLaMA model sizes"></p>
<ol>
<li>Each curve first plummets in a <strong>power law</strong>,</li>
<li>and then seemingly enters a <strong>nearly-linear</strong> decrease in loss
(corresponding to a fairly constant rate of knowledge acquisition).</li>
<li>At the very tip of the curve, they all break this line by <strong>flattening</strong>
slightly.</li>
</ol>
<p>Right off the bat, I want to tackle a subtle misconception that people can have
related to the end-of-curve flattening.
They are all trained with gradient descent using a variable learning rate
(which is, roughly,
a hyperparameter for how much to go in the direction of the gradient).
To get a good training, they had to constantly decrease the learning rate,
so that it can detect ever-subtler patterns in the source material.
The formula they use for that decrease is the most widely used:
the cosine schedule.</p>
<p><img src="https://espadrine.github.io/blog/assets/chinchilla-s-death/warmup_cosine_schedule.png" alt="Learning rate as a function of training steps under a cosine schedule with
warmup: it first increases linearly, then slopes down with increasing speed,
before reaching an inflection point halfway and slowing down ever slower. Image from Huggingface documentation"></p>
<p>As you can see from the graph, towards the end of the training run,
the cosine schedule stops decreasing the learning rate at the speed which
yielded such a good, near-linear training loss curve.
The slowdown in learning is an artefact of that.
The model does not necessarily cease to have
the capacity to learn at the same near-linear rate!
In fact, if we had more text to give it,
we would have stretched the cosine schedule,
so its learning rate would have continued to go down at the same rate.</p>
<p>The model’s fitness landscape does not depend on the amount of data
we can feed its training; so the change in learning rate decrease
is not well-justified.</p>
<p>That is not the main point of this article, though.</p>
<p>The training loss curve can be misleading in another way.
Sure, they are all trained on the same data;
but they don’t go through that data at the same speed.
What we want to know is <strong>not</strong> how sample-efficient the model is
(on this front, the larger model clearly learns more from what it saw).
Let’s picture instead a race:
all those models start at the same time,
and we want to know which one crosses the finish line first.
In other words, when throwing a fixed amount of compute at the training,
who learns the most in that time?</p>
<p>Thankfully, we can combine the loss curves with another piece of data that Meta
provided: the amount of time that each model took to train.</p>
<table>
 <tbody><tr><th>   Model   </th><th> GPU-hours </th><th> Tokens/second </th>
 </tr><tr><td> LLaMA1-7B  </td><td>   82432  </td><td>    3384.3    </td>
 </tr><tr><td> LLaMA1-13B </td><td>  135168  </td><td>    2063.9    </td>
 </tr><tr><td> LLaMA1-33B </td><td>  530432  </td><td>     730.5    </td>
 </tr><tr><td> LLaMA1-65B </td><td> 1022362  </td><td>     379.0    </td>
</tr></tbody></table>
<p><img src="https://espadrine.github.io/blog/assets/chinchilla-s-death/llama1-training-speed.svg" alt="LLaMA 1 training loss vs GPU-hours spent"></p>
<p><a href="https://github.com/espadrine/espadrine.github.com/blob/master/blog/assets/chinchilla-s-death/llama-data.py"><em>(Code for generating the graph here.)</em></a></p>
<p>Let’s first mention that the whole Chinchilla graph that we saw,
covers only a small sliver on the left of this graph.
In that sliver, we see the same behaviour that Chinchilla documents.
Look at the 7B, for instance (which in the Chinchilla graph would actually be
among the top two curves in terms of size):
it initially drops its loss much faster than the bigger models, then slows down,
and the 13B model overtakes it and reaches 1.9 first.</p>
<p>But then, comes a far-lands, unexpected twist: the 7B enters a near-linear
regime, with a steep downward trend, and seems on its way to maybe overpass the
13B again? It is hard to tell on that graph what would happen if the 7B was
trained for longer.</p>
<p>However, the same behaviour seemed to be true between the 13B and the 33B,
where the initial Chinchilla slowdown also gives way to a near-linear regime,
at which point the 13B goes down fast! It is only surpassed by the 33B unfairly,
by granting the latter more than double the compute time.</p>
<p>And the same slowdown-then-speedup occurs between the 33B and the 65B,
to such an extent that the 33B never actually gets overtaken by the 65B.
What the graph shows breaks OpenAI’s and Chinchilla’s assumption:
<strong>the bigger model hasn’t won</strong> (yet).
The slowdown they detected is not actually caused by reaching some capacity limit!</p>
<p>Still, that 7B line is a bit unsatisfactory.
If only Meta had trained it for longer…</p>
<p>Suspense over: they did! They released LLaMA 2 this week!</p>
<h2 id="Time_to_confirm_our_suspicions">Time to confirm our suspicions </h2>
<p><img src="https://espadrine.github.io/blog/assets/chinchilla-s-death/llama2-training.png" alt="Training loss curves for the four LLaMA 2 model sizes"></p>
<p>We also, again, got the training times:</p>
<table>
 <tbody><tr><th>   Model   </th><th> GPU-hours </th><th> Tokens/second </th>
 </tr><tr><td> LLaMA2-7B  </td><td>  184320  </td><td>    3031.9    </td>
 </tr><tr><td> LLaMA2-13B </td><td>  368640  </td><td>    1515.9    </td>
 </tr><tr><td> LLaMA2-34B </td><td> 1038336  </td><td>     533.7    </td>
 </tr><tr><td> LLaMA2-70B </td><td> 1720320  </td><td>     322.1    </td>
</tr></tbody></table>
<p><img src="https://espadrine.github.io/blog/assets/chinchilla-s-death/llama2-training-speed.svg" alt="LLaMA 2 training loss vs GPU-hours spent"></p>
<p>Immediately, at a glance, we notice that the training curves don’t match those
of LLaMA 1, even when the models are identical.
As it turns out, LLaMA 2 was trained on double the context size,
and a longer cosine schedule, which unfortunately
has negatively impacted all model sizes.
However, smaller models have been impacted worse than larger ones.
As a result, the 34B model, which in LLaMA 1 remained always better than the 65B
model at any training time spent, now dips slightly above the 70B model,
before overtaking it:</p>
<p><img src="https://espadrine.github.io/blog/assets/chinchilla-s-death/llama-training-speed-comparison.webp" alt="LLaMA 1 vs 2 training loss vs GPU-hours spent"></p>
<p>More importantly, comparing the training speeds strongly confirms our suspicions
from LLaMA 1:</p>
<ol>
<li>First, they are faster than bigger models,</li>
<li>Then, they slow down, and are overtaken by larger models (as per
Chinchilla),</li>
<li>BUT THEN, they enter the near-linear regime, in which smaller models have a
steeper descent into superior knowledge, and they overtake larger models
yet again!</li>
</ol>
<p>A fascinating consequence ties into making the right choices
when starting a training run:
contrary to popular belief, <strong>larger models yield worse results</strong>.
If you had to pick a parameter size and dataset, you might be better off opting
for a 7B model and training for 7 epochs on trillions of tokens.</p>
<p>Look at the near-linear regime of the 7B model, and extrapolate its line to when
the 70B model stopped:
had the 70B computation been spent on the 7B instead,
it would potentially have reached a lower perplexity!</p>
<p>Another thing we notice from LLaMA 2 is that the learning slowdown at the end of
the LLaMA 1 curves was indeed an artefact of the cosine schedule.
That slowdown is completely absent from the LLaMA 2 training run at the
corresponding mark of 1 trillion tokens read.</p>
<p>In fact, maybe the reason that, at that same mark, the LLaMA 2 7B model has a
worse quality than the LLaMA 1 7B model had,
may be because <em>its cosine schedule is stretched</em>!</p>
<p>Let’s go back to the Chinchilla paper to argue that point.
In appendix A, figure A1, they show an ablation study for various cosine
schedule parameters (phrased another way:
various ways to stretch the learning rate curve).</p>
<p><img src="https://espadrine.github.io/blog/assets/chinchilla-s-death/chinchilla-cosine-ablation-study.png" alt="Chinchilla cosine schedule ablation study"></p>
<p>They make the point that the lowest loss is achieved when the curve is not
stretched. That is supported by the graphs, but we notice something off.
After reading 6 million tokens, the training loss at the top is below 2.8;
meanwhile, at the same mark, the training loss of the bottom model is above.
Yet the only difference between the models is the cosine schedule!
Because the bottom model was slated to go through more training data,
the “unstretched” cosine schedule was computed for a bigger number of steps,
which effectively stretches it.
If the learning rate had instead followed
the schedule assigned to fewer training steps,
it would have had a better loss for the same amount of training time.</p>
<p>More broadly, that raises a question that I leave open:
if the cosine schedule is not optimal,
how should the shape of its tail be instead?</p>

    
  </article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tidal energy is not renewable (374 pts)]]></title>
            <link>https://cs.stanford.edu/people/zjl/tide.html</link>
            <guid>37383283</guid>
            <pubDate>Mon, 04 Sep 2023 18:17:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cs.stanford.edu/people/zjl/tide.html">https://cs.stanford.edu/people/zjl/tide.html</a>, See on <a href="https://news.ycombinator.com/item?id=37383283">Hacker News</a></p>
<div id="readability-page-1" class="page">
	
	
	
	
	<div><p><a href="https://cs.stanford.edu/people/zjl/menu.html">List of Papers</a></p></div>
    

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Geo Guesser identifies the location and seat number from an aerial shot (262 pts)]]></title>
            <link>https://twitter.com/georainbolt/status/1698553197684777069</link>
            <guid>37383245</guid>
            <pubDate>Mon, 04 Sep 2023 18:13:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/georainbolt/status/1698553197684777069">https://twitter.com/georainbolt/status/1698553197684777069</a>, See on <a href="https://news.ycombinator.com/item?id=37383245">Hacker News</a></p>
Couldn't get https://twitter.com/georainbolt/status/1698553197684777069: Error [ERR_FR_TOO_MANY_REDIRECTS]: Maximum number of redirects exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Medical-evidence giant Cochrane battles funding cuts and closures (109 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-023-02741-z</link>
            <guid>37382232</guid>
            <pubDate>Mon, 04 Sep 2023 16:50:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-023-02741-z">https://www.nature.com/articles/d41586-023-02741-z</a>, See on <a href="https://news.ycombinator.com/item?id=37382232">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <figure>
 <picture>
  <source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-023-02741-z/d41586-023-02741-z_25990172.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-023-02741-z/d41586-023-02741-z_25990172.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px">
  <img alt="A 77-year-old patient with signs of stroke undergoes an MRI." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-023-02741-z/d41586-023-02741-z_25990172.jpg">
  <figcaption>
   <p><span>Specialist stroke units in hospitals were adopted worldwide after a seminal review on their efficacy, which became one of Cochrane’s famed systematic reviews.</span><span>Credit: BSIP/Education Images/Universal Images Group via Getty</span></p>
  </figcaption>
 </picture>
</figure><p>This month, more than 1,000 people will gather in London for a meeting of Cochrane, the group known for its gold-standard reviews of evidence in medicine. The conference marks the 30th anniversary of an organization that helped to spark a worldwide movement to base health care on research.</p><p>But in the hallways, some attendees will be discussing whether and how the group can survive. In March, 19 of 52 groups that produce Cochrane’s systematic reviews closed after the UK National Institute for Health and Care Research (NIHR) stopped funding them. And in July, Cochrane UK in Oxford — where the group was founded — revealed that it will close next March, after the NIHR ceased its support.</p><p>The closures come amid a major reorganization that will change how Cochrane produces and publishes systematic reviews, instigated partly in anticipation of funding difficulties. Some researchers are concerned that Cochrane will not be able to maintain its output of reviews — which shape the clinical guidelines used by doctors worldwide — or meet the growing demand for more complex, timely evidence syntheses. “I don’t see a very clear or bright future for Cochrane,” says Gabriel Rada, a specialist in evidence-based health care at the Pontifical Catholic University of Chile, Santiago, who previously directed Cochrane Chile.</p><p>“What’s happened to groups in the UK is very sad,” says Karla Soares-Weiser, editor-in-chief of the organization’s database of evidence, the Cochrane Library in London. “We want Cochrane to be here for the next generation. And there’s adjustments that we have to make to guarantee that this organization is sustainable for the future.”</p><p>Cochrane says that the lost NIHR funding — around £4.2 million (US$5.3 million) — does not affect its core income, which was £8.9 million in 2022. However, a more existential threat looms. Around £6.8 million of that core income came from subscriptions to the Cochrane Library, but Cochrane aims to make all its reviews open access by 2025, putting the revenue at risk. Catherine Spencer, Cochrane’s chief executive in London, says that the group is seriously examining how to make that move “in a way that would ensure that Cochrane is viable into the future”.</p><h2>Radical reviews</h2><p>The Cochrane UK centre slated for closure is symbolically important. The Cochrane Collaboration was launched there at a 1993 meeting, convened by physician and researcher Iain Chalmers, that attendees still speak of with zeal.</p><p>At the time, decisions in Western medicine tended to be based on conventional wisdom and the opinion of the most senior physician in the room. Chalmers and others at the meeting had the then-radical idea that medical practice should be based on systematic reviews of rigorous research evidence — such as randomized controlled trials — showing whether a treatment is effective. The group was named after physician and epidemiologist Archie Cochrane, who had championed evidence from randomized trials in previous decades.</p><p>The group started as a grass-roots organization with a decentralized structure powered by passionate academics who worked for free, and became central in the rise of evidence-based medicine. It established a series of mostly autonomous groups around the world, responsible for producing systematic reviews in areas such as stroke, movement disorders and infectious diseases.</p><p>To produce reviews, researchers follow standardized methods to find and analyse all the rigorous evidence on a question such as whether a therapy helps or harms. Systematic reviews are valued for their ability to draw conclusions from multiple, conflicting studies, like extracting a signal from noise. Cochrane developed a reputation for particularly rigorous methods and reviews.</p><figure>
 <picture>
  <source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-023-02741-z/d41586-023-02741-z_25990388.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-023-02741-z/d41586-023-02741-z_25990388.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px">
  <img alt="Registration stand at the 2016 Cochrane Colloquium in Seoul, South Korea." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-023-02741-z/d41586-023-02741-z_25990388.jpg">
  <figcaption>
   <p><span>Cochrane has more than 11,000 members worldwide who are involved in synthesizing or disseminating clinical evidence.</span><span>Credit: The Cochrane Collaboration</span></p>
  </figcaption>
 </picture>
</figure><p>The UK National Health Service was an early funder of Cochrane and its UK-based groups. Later, the NIHR provided support, mainly paying for support staff to help produce reviews.</p><p>So when the NIHR confirmed in August 2021 that it would stop funding all the UK-based review groups, the news came as a shock, says Peter Langhorne, a stroke researcher at the University of Glasgow, UK, who was a coordinating editor for Cochrane’s Stroke Group until 2020. In 1993, Langhorne and his colleagues independently published a seminal systematic review<sup><a href="#ref-CR1" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">1</a></sup>, which was later regularly updated as part of Cochrane, that showed the effectiveness of specialist stroke units. This led to their widespread adoption, saving tens of thousands of lives.</p><h2>Long shadow</h2><p>The Stroke Group’s closure meant that three people lost their jobs, says Langhorne, who is concerned that some important systematic reviews won’t now be done. “I think it’s a real danger that the priorities of patients could be lost,” he says. Around one-third of Cochrane’s reviews in 2022 came from UK groups that have now closed.</p><p>But the writing had long been on the wall. A <a href="https://www.journalslibrary.nihr.ac.uk/downloads/other-nihr-research/evaluation-of-NIHR-investment-in-cochrane/NIHR_Cochrane_Report_Feb_17.pdf" data-track="click" data-label="https://www.journalslibrary.nihr.ac.uk/downloads/other-nihr-research/evaluation-of-NIHR-investment-in-cochrane/NIHR_Cochrane_Report_Feb_17.pdf" data-track-category="body text link">2017 review of the NIHR’s investment in Cochrane</a> found considerable differences in productivity and review quality between groups. It also noted that reviews were slow to produce, and that many published reviews were out of date or did not address priority topics. What’s more, the same specialist group that helped authors to produce a review would decide whether it was fit to publish, raising concerns within and outside Cochrane about editorial standards. (Cochrane has acknowledged many of these concerns in reports that highlight the need for reform.)</p><p>The wider research community also criticized the NIHR for putting all its money for research synthesis into Cochrane, says Žarko Alfirević, a specialist in fetal and maternal medicine at the University of Liverpool, UK, who was coordinating editor for Cochrane’s now-closed Pregnancy and Childbirth Group. That made sense when “Cochrane was the only show in town”, he says, but now “the whole industry of research synthesis is massive”.</p><p>The NIHR said in a statement that it remains committed to supporting evidence-informed practice in health care. In May, it announced that it had awarded £22.5 million over five years to nine other groups as part of a new evidence-synthesis programme.</p><h2>Growing pains</h2><p>Cochrane now has more than 11,000 members involved in synthesizing or disseminating evidence worldwide. It has published more than 16,000 reviews and has been central in stimulating the now-copious production of systematic reviews and other evidence syntheses. “It shifted the ground,” says Paul Garner, professor emeritus in public health at the Liverpool School of Tropical Medicine and former head of Cochrane’s Infectious Diseases Group. “It was a tremendous example of rapid diffusion of a technology.” A 2021 study<sup><a href="#ref-CR2" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">2</a></sup> found that more than 80 medical systematic reviews were published every day in 2019; around 7% were Cochrane reviews.</p><p>The group has been no stranger to criticism and controversy. Some members dislike how the grass-roots community has morphed into a more business-like, centralized organization. “That’s not the Cochrane that we knew,” says Nancy Santesso, a health researcher at McMaster University in Hamilton, Canada, and deputy director of Cochrane Canada.</p><p>Yet she and others acknowledge that reform was necessary as the organization grew — and that such changes are always difficult. “The problem is that you inevitably become corporate,” says Alfirević, “and academics, by definition, hate being told what to do.”</p><h2>Broad shake-up</h2><p>Cochrane’s reorganization aims to address many criticisms — for example, it is centralizing all editorial processes and separating them from review development to ensure that reviews are of consistent quality. It is trying to make it easier and quicker to produce reviews by creating evidence-synthesis units, as well as externally funded ‘thematic groups’ that represent broad areas, such as health equity and global ageing. Soares-Weiser says Cochrane’s preliminary data suggest that the throughput of reviews could be maintained despite the UK cuts. She adds that the organization is developing a scientific strategy to focus on high-value reviews in areas aligned with the United Nations Sustainable Development Goals.</p><p>The upcoming London meeting, from 4–6 September, is seen as particularly significant because of the upheaval — and because it’s the first in-person Cochrane colloquium in five years, owing partly to the COVID-19 pandemic. Santesso has attended every colloquium since 2002, but this year, “If I go and there isn’t that scientific strength there, then I’m not sure I would go again,” she says.</p><p>Even those critical of Cochrane say it’s important that the group survives. Philippe Ravaud, an epidemiologist at Paris City University who led Cochrane France until 2019, argues that improving evidence syntheses requires major reforms, including working with researchers to improve the planning and quality of the clinical trials that will be synthesized. “There is no organization aside from Cochrane that can do that,” he says.</p><p>Chalmers, who left the organization in 2003, says he has no sentimentality about the Cochrane collaboration, but says that its function remains as important as ever. “There is no argument about trying to get better, more valid, up-to-date information in the hands of patients and clinicians,” he says. “If the organization didn’t exist, something like it would need to be invented.”</p>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Can we talk to whales? (156 pts)]]></title>
            <link>https://www.newyorker.com/magazine/2023/09/11/can-we-talk-to-whales</link>
            <guid>37382117</guid>
            <pubDate>Mon, 04 Sep 2023 16:37:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.newyorker.com/magazine/2023/09/11/can-we-talk-to-whales">https://www.newyorker.com/magazine/2023/09/11/can-we-talk-to-whales</a>, See on <a href="https://news.ycombinator.com/item?id=37382117">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><figure data-testid="IframeEmbed"></figure><blockquote><div><p>Ah, the world! Oh, the world!</p><inline-embed name="align-right" attrs="[object Object]" childtypes="" contenttype="callout:align-right"><p><em>—“Moby-Dick.”</em></p></inline-embed></div></blockquote><p>David Gruber began his almost impossibly varied career studying bluestriped grunt fish off the coast of Belize. He was an undergraduate, and his job was to track the fish at night. He navigated by the stars and slept in a tent on the beach. “It was a dream,” he recalled recently. “I didn’t know what I was doing, but I was performing what I thought a marine biologist would do.”</p><p>Gruber went on to work in Guyana, mapping forest plots, and in Florida, calculating how much water it would take to restore the Everglades. He wrote a Ph.D. thesis on carbon cycling in the oceans and became a professor of biology at the City University of New York. Along the way, he got interested in green fluorescent proteins, which are naturally synthesized by jellyfish but, with a little gene editing, can be produced by almost any living thing, including humans.</p><p>While working in the Solomon Islands, northeast of Australia, Gruber discovered dozens of species of fluorescent fish, including a fluorescent shark, which opened up new questions. What would a fluorescent shark look like to another fluorescent shark? Gruber enlisted researchers in optics to help him construct a special “shark’s eye” camera. (Sharks see only in blue and green; fluorescence, it turns out, shows up to them as greater contrast.) Meanwhile, he was also studying creatures known as comb jellies at the Mystic Aquarium, in Connecticut, trying to determine how, exactly, they manufacture the molecules that make them glow. This led him to wonder about the way that jellyfish experience the world. Gruber enlisted another set of collaborators to develop robots that could handle jellyfish with jellyfish-like delicacy.</p><p>“I wanted to know: Is there a way where robots and people can be brought together that builds empathy?” he told me.</p><p>In 2017, Gruber received a fellowship to spend a year at the Radcliffe Institute for Advanced Study, in Cambridge, Massachusetts. While there, he came across a book by a free diver who had taken a plunge with some sperm whales. This piqued Gruber’s curiosity, so he started reading up on the animals.</p><p>The world’s largest predators, sperm whales spend most of their lives hunting. To find their prey—generally squid—in the darkness of the depths, they rely on echolocation. By means of a specialized organ in their heads, they generate streams of clicks that bounce off any solid (or semi-solid) object. Sperm whales also produce quick bursts of clicks, known as codas, which they exchange with one another. The exchanges seem to have the structure of conversation.</p><p>One day, Gruber was sitting in his office at the Radcliffe Institute, listening to a tape of sperm whales chatting, when another fellow at the institute, Shafi Goldwasser, happened by. Goldwasser, a Turing Award-winning computer scientist, was intrigued. At the time, she was organizing a seminar on machine learning, which was advancing in ways that would eventually lead to ChatGPT. Perhaps, Goldwasser mused, machine learning could be used to discover the meaning of the whales’ exchanges.</p><p>“It was not exactly a joke, but almost like a pipe dream,” Goldwasser recollected. “But David really got into it.”</p><p>Gruber and Goldwasser took the idea of decoding the codas to a third Radcliffe fellow, Michael Bronstein. Bronstein, also a computer scientist, is now the DeepMind Professor of A.I. at Oxford.</p><p>“This sounded like probably the most crazy project that I had ever heard about,” Bronstein told me. “But David has this kind of power, this ability to convince and drag people along. I thought that it would be nice to try.”</p><p>Gruber kept pushing the idea. Among the experts who found it loopy and, at the same time, irresistible were Robert Wood, a roboticist at Harvard, and Daniela Rus, who runs M.I.T.’s Computer Science and Artificial Intelligence Laboratory. Thus was born the Cetacean Translation Initiative—Project <em>CETI</em> for short. (The acronym is pronounced “setty,” and purposefully recalls <em>SETI</em>, the Search for Extraterrestrial Intelligence.) <em>CETI</em> represents the most ambitious, the most technologically sophisticated, and the most well-funded effort ever made to communicate with another species.</p><p>“I think it’s something that people get really excited about: Can we go from science fiction to science?” Rus told me. “I mean, can we talk to whales?”</p><p>Sperm whales are nomads. It is estimated that, in the course of a year, an individual whale swims at least twenty thousand miles. But scattered around the tropics, for reasons that are probably squid-related, there are a few places the whales tend to favor. One of these is a stretch of water off Dominica, a volcanic island in the Lesser Antilles.</p><p><em>CETI</em> has its unofficial headquarters in a rental house above Roseau, the island’s capital. The group’s plan is to turn Dominica’s west coast into a giant whale-recording studio. This involves installing a network of underwater microphones to capture the codas of passing whales. It also involves planting recording devices on the whales themselves—cetacean bugs, as it were. The data thus collected can then be used to “train” machine-learning algorithms.</p><figure><p><span><p>The scientist David Gruber explains the mission of Project CETI, and what his team has learned about how whales communicate.</p>
</span></p></figure><p>In July, I went down to Dominica to watch the <em>CETI</em> team go sperm-whale bugging. My first morning on the island, I met up with Gruber just outside Roseau, on a dive-shop dock. Gruber, who is fifty, is a slight man with dark curly hair and a cheerfully anxious manner. He was carrying a waterproof case and wearing a <em>CETI</em> T-shirt. Soon, several more members of the team showed up, also carrying waterproof cases and wearing <em>CETI</em> T-shirts. We climbed aboard an oversized Zodiac called <em>CETI</em> 2 and set off.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>The night before, a tropical storm had raked the region with gusty winds and heavy rain, and Dominica’s volcanic peaks were still wreathed in clouds. The sea was a series of white-fringed swells. <em>CETI</em> 2 sped along, thumping up and down, up and down. Occasionally, flying fish zipped by; these remained aloft for such a long time that I was convinced for a while they were birds.</p><p>About two miles offshore, the captain, Kevin George, killed the engines. A graduate student named Yaly Mevorach put on a set of headphones and lowered an underwater mike—a hydrophone—into the waves. She listened for a bit and then, smiling, handed the headphones to me.</p><p>The most famous whale calls are the long, melancholy “songs” issued by humpbacks. Sperm-whale codas are neither mournful nor musical. Some people compare them to the sound of bacon frying, others to popcorn popping. That morning, as I listened through the headphones, I thought of horses clomping over cobbled streets. Then I changed my mind. The clatter was more mechanical, as if somewhere deep beneath the waves someone was pecking out a memo on a manual typewriter.</p><p>Mevorach unplugged the headphones from the mike, then plugged them into a contraption that looked like a car speaker riding a broom handle. The contraption, which I later learned had been jury-rigged out of, among other elements, a metal salad bowl, was designed to locate clicking whales. After twisting it around in the water for a while, Mevorach decided that the clicks were coming from the southwest. We thumped in that direction, and soon George called out, “Blow!”</p><p>A few hundred yards in front of us was a gray ridge that looked like a misshapen log. (When whales are resting at the surface, only a fraction of their enormous bulk is visible.) The whale blew again, and a geyser-like spray erupted from the ridge’s left side.</p><figure><p><span><div data-attr-viewport-monitor=""><a data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.newyorker.com/cartoon/a27506&quot;}" href="https://www.newyorker.com/cartoon/a27506" rel="nofollow noopener" target="_blank"><picture></picture></a><p><span>“This is the exact moment I asked you to water my plant.”</span></p><p><span>Cartoon by Jonathan Rosen</span></p></div></span></p></figure><p>As we were closing in, the whale blew yet again; then it raised its elegantly curved flukes into the air and dove. It was unlikely to resurface, I was told, for nearly an hour.</p><p>We thumped off in search of its kin. The farther south we travelled, the higher the swells. At one point, I felt my stomach lurch and went to the side of the boat to heave.</p><p>“I like to just throw up and get back to work,” Mevorach told me.</p><p>Trying to attach a recording device to a sperm whale is a bit like trying to joust while racing on a Jet Ski. The exercise entails using a thirty-foot pole to stick the device onto the animal’s back, which in turn entails getting within thirty feet of a creature the size of a school bus. That day, several more whales were spotted. But, for all of our thumping around, <em>CETI</em> 2 never got close enough to one to unhitch the tagging pole.</p><p>The next day, the sea was calmer. Once again, we spotted whales, and several times the boat’s designated pole-handler, Odel Harve, attempted to tag one. All his efforts went for naught. Either the whale dove at the last minute or the recording device slipped off the whale’s back and had to be fished out of the water. (The device, which was about a foot long and shaped like a surfboard, was supposed to adhere via suction cups.) With each new sighting, the mood on <em>CETI</em> 2 lifted; with each new failure, it sank.</p><p>On my third day in Dominica, I joined a slightly different subset of the team on a different boat to try out a new approach. Instead of a long pole, this boat—a forty-foot catamaran called <em>CETI</em> 1—was carrying an experimental drone. The drone had been specially designed at Harvard and was fitted out with a video camera and a plastic claw.</p><p>Because sperm whales are always on the move, there’s no guarantee of finding any; weeks can go by without a single sighting off Dominica. Once again, though, we got lucky, and a whale was soon spotted. Stefano Pagani, an undergraduate who had been brought along for his piloting skills, pulled on what looked like a V.R. headset, which was linked to the drone’s video camera. In this way, he could look down at the whale from the drone’s perspective and, it was hoped, plant a recording device, which had been loaded into the claw, on the whale’s back.</p><p>The drone took off and zipped toward the whale. It hovered for a few seconds, then dropped vertiginously. For the suction cups to adhere, the drone had to strike the whale at just the right angle, with just the right amount of force. Post impact, Pagani piloted the craft back to the boat with trembling hands. “The nerves get to you,” he said.</p><p>“No pressure,” Gruber joked. “It’s not like there’s a <em>New Yorker</em> reporter watching or anything.” Someone asked for a round of applause. A cheer went up from the boat. The whale, for its part, seemed oblivious. It lolled around with the recording device, which was painted bright orange, stuck to its dark-gray skin. Then it dove.</p><p>Sperm whales are among the world’s deepest divers. They routinely descend two thousand feet and sometimes more than a mile. (The deepest a human has ever gone with scuba gear is just shy of eleven hundred feet.) If the device stayed on, it would record any sounds the whale made on its travels. It would also log the whale’s route, its heartbeat, and its orientation in the water. The suction was supposed to last around eight hours; after that—assuming all went according to plan—the device would come loose, bob to the surface, and transmit a radio signal that would allow it to be retrieved.</p><p>I said it was too bad we couldn’t yet understand what the whales were saying, because perhaps this one, before she dove, had clicked out where she was headed.</p><p>“Come back in two years,” Gruber said.</p><p>Every sperm whale’s tail is unique. On some, the flukes are divided by a deep notch. On others, they meet almost in a straight line. Some flukes end in points; some are more rounded. Many are missing distinctive chunks, owing, presumably, to orca attacks. To I.D. a whale in the field, researchers usually rely on a photographic database called Flukebook. One of the very few scientists who can do it simply by sight is <em>CETI</em>’s lead field biologist, Shane Gero.</p><p>Gero, who is forty-three, is tall and broad, with an eager smile and a pronounced Canadian accent. A scientist-in-residence at Ottawa’s Carleton University, he has been studying the whales off Dominica since 2005. By now, he knows them so well that he can relate their triumphs and travails, as well as who gave birth to whom and when. A decade ago, as Gero started having children of his own, he began referring to his “human family” and his “whale family.” (His human family lives in Ontario.) Another marine biologist once described Gero as sounding “like Captain Ahab after twenty years of psychotherapy.”</p><p>When Gruber approached Gero about joining Project <em>CETI</em>, he was, initially, suspicious. “I get a lot of e-mails like ‘Hey, I think whales have crystals in their heads,’ and ‘Maybe we can use them to cure malaria,’&nbsp;” Gero told me. “The first e-mail David sent me was, like, ‘Hi, I think we could find some funding to translate whale.’ And I was, like, ‘Oh, boy.’&nbsp;”</p><p>A few months later, the two men met in person, in Washington, D.C., and hit it off. Two years after that, Gruber did find some funding. <em>CETI</em> received thirty-three million dollars from the Audacious Project, a philanthropic collaborative whose backers include Richard Branson and Ray Dalio. (The grant, which was divided into five annual payments, will run out in 2025.)</p><p>The whole time I was in Dominica, Gero was there as well, supervising graduate students and helping with the tagging effort. From him, I learned that the first whale I had seen was named Rita and that the whales that had subsequently been spotted included Raucous, Roger, and Rita’s daughter, Rema. All belonged to a group called Unit R, which Gero characterized as “tightly and actively social.” Apparently, Unit R is also warmhearted. Several years ago, when a group called Unit S got whittled down to just two members—Sally and TBB—the Rs adopted them.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Sperm whales have the biggest brains on the planet—six times the size of humans’. Their social lives are rich, complicated, and, some would say, ideal. The adult members of a unit, which may consist of anywhere from a few to a few dozen individuals, are all female. Male offspring are permitted to travel with the group until they’re around fifteen years old; then, as Gero put it, they are “socially ostracized.” Some continue to hang around their mothers and sisters, clicking away for months unanswered. Eventually, though, they get the message. Fully grown males are solitary creatures. They approach a band of females—presumably not their immediate relatives—only in order to mate. To signal their arrival, they issue deep, booming sounds known as clangs. No one knows exactly what makes a courting sperm whale attractive to a potential mate; Gero told me that he had seen some clanging males greeted with great commotion and others with the cetacean equivalent of a shrug.</p><p>Female sperm whales, meanwhile, are exceptionally close. The adults in a unit not only travel and hunt together; they also appear to confer on major decisions. If there’s a new mother in the group, the other members mind the calf while she dives for food. In some units, though not in Unit R, sperm whales even suckle one another’s young. When a family is threatened, the adults cluster together to protect their offspring, and when things are calm the calves fool around.</p><p>“It’s like my kids and their cousins,” Gero said.</p><p>The day after I watched the successful drone flight, I went out with Gero to try to recover the recording device. More than twenty-four hours had passed, and it still hadn’t been located. Gero decided to drive out along a peninsula called Scotts Head, at the southwestern tip of Dominica, where he thought he might be able to pick up the radio signal. As we wound around on the island’s treacherously narrow roads, he described to me an idea he had for a children’s book that, read in one direction, would recount a story about a human family that lives on a boat and looks down at the water and, read from the other direction, would be about a whale family that lives deep beneath the boat and looks up at the waves.</p><p>“For me, the most rewarding part about spending a lot of time in the culture of whales is finding these fundamental similarities, these fundamental patterns,” he said. “And, you know, sure, they won’t have a word for ‘tree.’ And there’s some part of the sperm-whale experience that our primate brain just won’t understand. But those things that we share must be fundamentally important to why we’re here.”</p><p>After a while, we reached, quite literally, the end of the road. Beyond that was a hill that had to be climbed on foot. Gero was carrying a portable antenna, which he unfolded when we got to the top. If the recording unit had surfaced anywhere within twenty miles, Gero calculated, we should be able to detect the signal. It occurred to me that we were now trying to listen for a listening device. Gero held the antenna aloft and put his ear to some kind of receiver. He didn’t hear anything, so, after admiring the view for a bit, we headed back down. Gero was hopeful that the device would eventually be recovered. But, as far as I know, it is still out there somewhere, adrift in the Caribbean.</p><p>The first scientific, or semi-scientific, study of sperm whales was a pamphlet published in 1835 by a Scottish ship doctor named Thomas Beale. Called “The Natural History of the Sperm Whale,” it proved so popular that Beale expanded the pamphlet into a book, which was issued under the same title four years later.</p><p>At the time, sperm-whale hunting was a major industry, both in Britain and in the United States. The animals were particularly prized for their spermaceti, the waxy oil that fills their gigantic heads. Spermaceti is an excellent lubricant, and, burned in a lamp, produces a clean, bright light; in Beale’s day, it could sell for five times as much as ordinary whale oil. (It is the resemblance between semen and spermaceti that accounts for the species’ embarrassing name.)</p><p>Beale believed sperm whales to be silent. “It is well known among the most experienced whalers that they never produce any nasal or vocal sounds whatever, except a trifling hissing at the time of the expiration of the spout,” he wrote. The whales, he said, were also gentle—“a most timid and inoffensive animal.” Melville relied heavily on Beale in composing “Moby-Dick.” (His personal copy of “The Natural History of the Sperm Whale” is now housed in Harvard’s Houghton Library.) He attributed to sperm whales a “pyramidical silence.”</p><p>“The whale has no voice,” Melville wrote. “But then again,” he went on, “what has the whale to say? Seldom have I known any profound being that had anything to say to this world, unless forced to stammer out something by way of getting a living.”</p><p>The silence of the sperm whales went unchallenged until 1957. That year, two researchers from the Woods Hole Oceanographic Institution picked up sounds from a group they’d encountered off the coast of North Carolina. They detected strings of “sharp clicks,” and speculated that these were made for the purpose of echolocation. Twenty years elapsed before one of the researchers, along with a different colleague from Woods Hole, determined that some sperm-whale clicks were issued in distinctive, often repeated patterns, which the pair dubbed “codas.” Codas seemed to be exchanged between whales and so, they reasoned, must serve some communicative function.</p><p>Since then, cetologists have spent thousands of hours listening to codas, trying to figure out what that function might be. Gero, who wrote his Ph.D. thesis on vocal communication between sperm whales, told me that one of the “universal truths” about codas is their timing. There are always four seconds between the start of one coda and the beginning of the next. Roughly two of those seconds are given over to clicks; the rest is silence. Only after the pause, which may or may not be analogous to the pause a human speaker would put between words, does the clicking resume.</p><p>Codas are clearly learned or, to use the term of art, socially transmitted. Whales in the eastern Pacific exchange one set of codas, those in the eastern Caribbean another, and those in the South Atlantic yet another. Baby sperm whales pick up the codas exchanged by their relatives, and before they can click them out proficiently they “babble.”</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>The whales around Dominica have a repertoire of around twenty-five codas. These codas differ from one another in the number of their clicks and also in their rhythms. The coda known as three regular, or 3R, for example, consists of three clicks issued at equal intervals. The coda 7R consists of seven evenly spaced clicks. In seven increasing, or 7I, by contrast, the interval between the clicks grows longer; it’s about five-hundredths of a second between the first two clicks, and between the last two it’s twice that long. In four decreasing, or 4D, there’s a fifth of a second between the first two clicks and only a tenth of a second between the last two. Then, there are syncopated codas. The coda most frequently issued by members of Unit R, which has been dubbed 1+1+3, has a cha-cha-esque rhythm and might be rendered in English as click&nbsp;.&nbsp;.&nbsp;. click&nbsp;.&nbsp;.&nbsp;. click-click-click.</p><p>If codas are in any way comparable to words, a repertoire of twenty-five represents a pretty limited vocabulary. But, just as no one can yet say what, if anything, codas mean to sperm whales, no one can say exactly what features are significant to them. It may be that there are nuances in, say, pacing or pitch that have so far escaped human detection. Already, <em>CETI</em> team members have identified a new kind of signal—a single click—that may serve as some kind of punctuation mark.</p><p>When whales are resting near the surface, their exchanges can last an hour or more. Even by human standards, sperm-whale chatter is insistent and repetitive. “They’re talking on top of each other all the time,” Gero told me.</p><p>A snatch of dialogue recorded between two members of Unit R runs as follows. (Both Roger and Rita are adult females.)</p><blockquote><p>Roger: 1+1+3<br>Rita: 1+1+3, 1+1+3<br>Roger: 9I<br>Rita: 1+1+3<br>Roger: 10I<br>Rita: 1+1+3, 1+1+3<br>Roger: 11I<br>Rita: 1+1+3<br>Roger: 10I, 11I, 1+1+3<br>Rita: 1+1+3</p></blockquote><p>The “conversation” continues along much these same lines, until Rita finally changes her tune:</p><blockquote><p>Rita: 1+1+3<br>Roger: 12R, 10I, 10I, 9I, 9I<br>Rita: 9I, 8I</p></blockquote><p>Not long ago, suffering from writer’s block, I asked ChatGPT if it could rewrite “Moby-Dick” from the whale’s perspective. The chatbot began modestly. “As an A.I. language model, I can certainly attempt to rewrite a small excerpt,” it told me. Then it launched into what it titled “Moby-Dick—The White Leviathan’s Tale.”</p><p>In Moby-Dick’s “Moby-Dick,” the plot turned on an unfortunate case of mistaken identity. Some other whale had gnawed off Ahab’s leg; the white whale was as innocent as the driven snow.</p><p>“My heart was one of peace, my spirit one with the rhythm of the currents,” ChatGPT wrote:</p><blockquote><p>I knew not of the vendetta forming against me, for I was but a creature of instinct, a guardian of the seas. But Captain Ahab’s thirst for vengeance loomed large, and I became the object of his undying rage. The scar he bore from a previous encounter with my kind had branded me as his ultimate adversary. In his eyes, I represented a force of nature that defied his understanding, a living enigma of the ocean’s might.</p></blockquote><p>In paragraph seven, I was surprised—and excited—to see the whale/bot allude to the problem of interspecies communication:</p><blockquote><p>Deep within the abyss of the sea, I pondered the futility of the captain’s quest. I longed to communicate with him, to show him that my kind, too, had emotions and families to protect. But the language barrier between our worlds remained an insurmountable chasm.</p></blockquote><figure><p><span><div data-attr-viewport-monitor=""><a data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.newyorker.com/cartoon/a27086&quot;}" href="https://www.newyorker.com/cartoon/a27086" rel="nofollow noopener" target="_blank"><picture></picture></a><p><span>Cartoon by Zoe Si</span></p></div></span></p></figure><p>As anyone who has been conscious for the past ten months knows, ChatGPT is capable of amazing feats. It can write essays, compose sonnets, explain scientific concepts, and produce jokes (though these last are not necessarily funny). If you ask ChatGPT how it was created, it will tell you that first it was trained on a “massive corpus” of data from the Internet. This phase consisted of what’s called “unsupervised machine learning,” which was performed by an intricate array of processing nodes known as a neural network. Basically, the “learning” involved filling in the blanks; according to ChatGPT, the exercise entailed “predicting the next word in a sentence given the context of the previous words.” By digesting millions of Web pages—and calculating and recalculating the odds—ChatGPT got so good at this guessing game that, without ever understanding English, it mastered the language. (Other languages it is “fluent” in include Chinese, Spanish, and French.)</p><p>In theory at least, what goes for English (and Chinese and French) also goes for sperm whale. Provided that a computer model can be trained on enough data, it should be able to master coda prediction. It could then—once again in theory—generate sequences of codas that a sperm whale would find convincing. The model wouldn’t understand sperm whale-ese, but it could, in a manner of speaking, speak it. Call it ClickGPT.</p><p>Currently, the largest collection of sperm-whale codas is an archive assembled by Gero in his years on and off Dominica. The codas contain roughly a hundred thousand clicks. In a paper published last year, members of the <em>CETI</em> team estimated that, to fulfill its goals, the project would need to assemble some four billion clicks, which is to say, a collection roughly forty thousand times larger than Gero’s.</p><p>“One of the key challenges toward the analysis of sperm whale (and more broadly, animal) communication using modern deep learning techniques is the need for sizable datasets,” the team wrote.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>In addition to bugging individual whales, <em>CETI</em> is planning to tether a series of three “listening stations” to the floor of the Caribbean Sea. The stations should be able to capture the codas of whales chatting up to twelve miles from shore. (Though inaudible above the waves, sperm-whale clicks can register up to two hundred and thirty decibels, which is louder than a gunshot or a rock concert.) The information gathered by the stations will be less detailed than what the tags can provide, but it should be much more plentiful.</p><p>One afternoon, I drove with Gruber and <em>CETI</em>’s station manager, Yaniv Aluma, a former Israeli Navy <em>SEAL</em>, to the port in Roseau, where pieces of the listening stations were being stored. The pieces were shaped like giant sink plugs and painted bright yellow. Gruber explained that the yellow plugs were buoys, and that the listening equipment—essentially, large collections of hydrophones—would dangle from the bottom of the buoys, on cables. The cables would be weighed down with old train wheels, which would anchor them to the seabed. A stack of wheels, rusted orange, stood nearby. Gruber suddenly turned to Aluma and, pointing to the pile, said, “You know, we’re going to need more of these.” Aluma nodded glumly.</p><p>The listening stations have been the source of nearly a year’s worth of delays for <em>CETI</em>. The first was installed last summer, in water six thousand feet deep. Fish were attracted to the buoy, so the spot soon became popular among fishermen. After about a month, the fishermen noticed that the buoy was gone. Members of <em>CETI</em>’s Dominica-based staff set out in the middle of the night on <em>CETI</em> 1 to try to retrieve it. By the time they reached the buoy, it had drifted almost thirty miles offshore. Meanwhile, the hydrophone array, attached to the rusty train wheels, had dropped to the bottom of the sea.</p><p>The trouble was soon traced to the cable, which had been manufactured in Texas by a company that specializes in offshore oil-rig equipment. “They deal with infrastructure that’s very solid,” Aluma explained. “But a buoy has its own life. And they didn’t calculate so well the torque or load on different motions—twisting and moving sideways.” The company spent months figuring out why the cable had failed and finally thought it had solved the problem. In June, Aluma flew to Houston to watch a new cable go through stress tests. In the middle of the tests, the new design failed. To avoid further delays, the <em>CETI</em> team reconfigured the stations. One of the reconfigured units was installed late last month. If it doesn’t float off, or in some other way malfunction, the plan is to get the two others in the water sometime this fall.</p><p>A sperm whale’s head takes up nearly a third of its body; its narrow lower jaw seems borrowed from a different animal entirely; and its flippers are so small as to be almost dainty. (The formal name for the species is <em>Physeter macrocephalus</em>, which translates roughly as “big-headed blowhole.”) “From just about any angle,” Hal Whitehead, one of the world’s leading sperm-whale experts (and Gero’s thesis adviser), has written, sperm whales appear “very strange.” I wanted to see more of these strange-looking creatures than was visible from a catamaran, and so, on my last day in Dominica, I considered going on a commercial tour that offered customers a chance to swim with whales, assuming that any could be located. In the end—partly because I sensed that Gruber disapproved of the practice—I dropped the idea.</p><p>Instead, I joined the crew on <em>CETI</em> 1 for what was supposed to be another round of drone tagging. After we’d been under way for about two hours, codas were picked up, to the northeast. We headed in that direction and soon came upon an extraordinary sight. There were at least ten whales right off the boat’s starboard. They were all facing the same direction, and they were bunched tightly together, in rows. Gero identified them as members of Unit A. The members of Unit A were originally named for characters in Margaret Atwood novels, and they include Lady Oracle, Aurora, and Rounder, Lady Oracle’s daughter.</p><p>Earlier that day, the crew on <em>CETI</em> 2 had spotted pilot whales, or blackfish, which are known to harass sperm whales. “This looks very defensive,” Gero said, referring to the formation.</p><p>Suddenly, someone yelled out, “Red!” A burst of scarlet spread through the water, like a great banner unfurling. No one knew what was going on. Had the pilot whales stealthily attacked? Was one of the whales in the group injured? The crowding increased until the whales were practically on top of one another.</p><p>Then a new head appeared among them. “Holy fucking shit!” Gruber exclaimed.</p><p>“Oh, my God!” Gero cried. He ran to the front of the boat, clutching his hair in amazement. “Oh, my God! Oh, my God!” The head belonged to a newborn calf, which was about twelve feet long and weighed maybe a ton. In all his years of studying sperm whales, Gero had never watched one being born. He wasn’t sure anyone ever had.</p><p>As one, the whales made a turn toward the catamaran. They were so close I got a view of their huge, eerily faceless heads and pink lower jaws. They seemed oblivious of the boat, which was now in their way. One knocked into the hull, and the foredeck shuddered.</p><p>The adults kept pushing the calf around. Its mother and her relatives pressed in so close that the baby was almost lifted out of the water. Gero began to wonder whether something had gone wrong. By now, everyone, including the captain, had gathered on the bow. Pagani and another undergraduate, Aidan Kenny, had launched two drones and were filming the action from the air. Mevorach, meanwhile, was recording the whales through a hydrophone.</p><p>To everyone’s relief, the baby began to swim on its own. Then the pilot whales showed up—dozens of them.</p><p>“I don’t like the way they’re moving,” Gruber said.</p><p>“They’re going to attack for sure,” Gero said. The pilot whales’ distinctive, wave-shaped fins slipped in and out of the water.</p><p>What followed was something out of a marine-mammal “Lord of the Rings.” Several of the pilot whales stole in among the sperm whales. All that could be seen from the boat was a great deal of thrashing around. Out of nowhere, more than forty Fraser’s dolphins arrived on the scene. Had they come to participate in the melee or just to rubberneck? It was impossible to tell. They were smaller and thinner than the pilot whales (which, their name notwithstanding, are also technically dolphins).</p><p>“I have no prior knowledge upon which to predict what happens next,” Gero announced. After several minutes, the pilot whales retreated. The dolphins curled through the waves. The whales remained bunched together. Calm reigned. Then the pilot whales made another run at the sperm whales. The water bubbled and churned.</p><p>“The pilot whales are just being pilot whales,” Gero observed. Clearly, though, in the great “struggle for existence,” everyone on board <em>CETI</em> 1 was on the side of the baby.</p><p>The skirmishing continued. The pilot whales retreated, then closed in again. The drones began to run out of power. Pagani and Kenny piloted them back to the catamaran to exchange the batteries. These were so hot they had to be put in the boat’s refrigerator. At one point, Gero thought that he spied the new calf, still alive and well. (He would later, from the drone footage, identify the baby’s mother as Rounder.) “So that’s good news,” he called out.</p><p>The pilot whales hung around for more than two hours. Then, all at once, they were gone. The dolphins, too, swam off.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>“There will never be a day like this again,” Gero said as <em>CETI</em> 1 headed back to shore.</p><p>That evening, everyone who’d been on board <em>CETI</em> 1 and <em>CETI</em> 2 gathered at a dockside restaurant for a dinner in honor of the new calf. Gruber made a toast. He thanked the team for all its hard work. “Let’s hope we can learn the language with that baby whale,” he said.</p><p>I was sitting with Gruber and Gero at the end of a long table. In between drinks, Gruber suggested that what we had witnessed might not have been an attack. The scene, he proposed, had been more like the last act of “The Lion King,” when the beasts of the jungle gather to welcome the new cub.</p><p>“Three different marine mammals came together to celebrate and protect the birth of an animal with a sixteen-month gestation period,” he said. Perhaps, he hypothesized, this was a survival tactic that had evolved to protect mammalian young against sharks, which would have been attracted by so much blood and which, he pointed out, would have been much more numerous before humans began killing them off.</p><p>“You mean the baby whale was being protected by the pilot whales from the sharks that aren’t here?” Gero asked. He said he didn’t even know what it would mean to test such a theory. Gruber said they could look at the drone footage and see if the sperm whales had ever let the pilot whales near the newborn and, if so, how the pilot whales had responded. I couldn’t tell whether he was kidding or not.</p><p>“That’s a nice story,” Mevorach interjected.</p><p>“I just like to throw ideas out there,” Gruber said.</p><blockquote><div><p>“My! You don’t say so!” said the Doctor. “You never talked that way to me before.”</p><p>“What would have been the good?” said Polynesia, dusting some cracker crumbs off her left wing. “You wouldn’t have understood me if I had.”</p><inline-embed name="align-right" attrs="[object Object]" childtypes="" contenttype="callout:align-right"><p><em>—“The Story of Doctor Dolittle.”</em></p></inline-embed></div></blockquote><p>The Computer Science and Artificial Intelligence Laboratory (<em>CSAIL</em>), at M.I.T., occupies a Frank Gehry-designed building that appears perpetually on the verge of collapse. Some wings tilt at odd angles; others seem about to split in two. In the lobby of the building, there’s a vending machine that sells electrical cords and another that dispenses caffeinated beverages from around the world. There’s also a yellow sign of the sort you might see in front of an elementary school. It shows a figure wearing a backpack and carrying a briefcase and says “<em>NERD XING</em>.”</p><p>Daniela Rus, who runs <em>CSAIL</em> (pronounced “see-sale”), is a roboticist. “There’s such a crazy conversation these days about machines,” she told me. We were sitting in her office, which is dominated by a robot, named Domo, who sits in a glass case. Domo has a metal torso and oversized, goggly eyes. “It’s either machines are going to take us down or machines are going to solve all of our problems. And neither is correct.”</p><p>Along with several other researchers at <em>CSAIL</em>, Rus has been thinking about how <em>CETI</em> might eventually push beyond coda prediction to something approaching coda comprehension. This is a formidable challenge. Whales in a unit often chatter before they dive. But what are they chattering about? How deep to go, or who should mind the calves, or something that has no analogue in human experience?</p><p>“We are trying to correlate behavior with vocalization,” Rus told me. “Then we can begin to get evidence for the meaning of some of the vocalizations they make.”</p><p>She took me down to her lab, where several graduate students were tinkering in a thicket of electronic equipment. In one corner was a transparent plastic tube loaded with circuitry, attached to two white plastic flippers. The setup, Rus explained, was the skeleton of a robotic turtle. Lying on the ground was the turtle’s plastic shell. One of the students hit a switch and the flippers made a paddling motion. Another student brought out a two-foot-long robotic fish. Both the fish and the turtle could be configured to carry all sorts of sensors, including underwater cameras.</p><p>“We need new methods for collecting data,” Rus said. “We need ways to get close to the whales, and so we’ve been talking a lot about putting the sea turtle or the fish in water next to the whales, so that we can image what we cannot see.”</p><p><em>CSAIL</em> is an enormous operation, with more than fifteen hundred staff members and students. “People here are kind of audacious,” Rus said. “They really love the wild and crazy ideas that make a difference.” She told me about a diver she had met who had swum with the sperm whales off Dominica and, by his account at least, had befriended one. The whale seemed to like to imitate the diver; for example, when he hung in the water vertically, it did, too.</p><p>“The question I’ve been asking myself is: Suppose that we set up experiments where we engage the whales in physical mimicry,” Rus said. “Can we then get them to vocalize while doing a motion? So, can we get them to say, ‘I’m going up’? Or can we get them to say, ‘I’m hovering’? I think that, if we were to find a few snippets of vocalizations that we could associate with some meaning, that would help us get deeper into their conversational structure.”</p><p>While we were talking, another <em>CSAIL</em> professor and <em>CETI</em> collaborator, Jacob Andreas, showed up. Andreas, a computer scientist who works on language processing, said that he had been introduced to the whale project at a faculty retreat. “I gave a talk about understanding neural networks as a weird translation problem,” he recalled. “And Daniela came up to me afterwards and she said, ‘Oh, you like weird translation problems? Here’s a weird translation problem.’&nbsp;”</p><p>Andreas told me that <em>CETI</em> had already made significant strides, just by reanalyzing Gero’s archive. Not only had the team uncovered the new kind of signal but also it had found that codas have much more internal structure than had previously been recognized. “The amount of information that this system can carry is much bigger,” he said.</p><p>“The holy grail here—the thing that separates human language from all other animal communication systems—is what’s called ‘duality of patterning,’&nbsp;” Andreas went on. “Duality of patterning” refers to the way that meaningless units—in English, sounds like “sp” or “ot”—can be combined to form meaningful units, like “spot.” If, as is suspected, clicks are empty of significance but codas refer to something, then sperm whales, too, would have arrived at duality of patterning. “Based on what we know about how the coda inventory works, I’m optimistic—though still not sure—that this is going to be something that we find in sperm whales,” Andreas said.</p><figure><p><span><div data-attr-viewport-monitor=""><a data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.newyorker.com/cartoon/a25122&quot;}" href="https://www.newyorker.com/cartoon/a25122" rel="nofollow noopener" target="_blank"><picture></picture></a><p><span>“But with traffic I rarely make it past twenty miles per hour.”</span></p><p><span>Cartoon by Sofia Warren</span></p></div></span></p></figure><p>The question of whether any species possesses a “communication system” comparable to that of humans is an open and much debated one. In the nineteen-fifties, the behaviorist B. F. Skinner argued that children learn language through positive reinforcement; therefore, other animals should be able to do the same. The linguist Noam Chomsky had a different view. He dismissed the notion that kids acquire language via conditioning, and also the possibility that language was available to other species.</p><p>In the early nineteen-seventies, a student of Skinner’s, Herbert Terrace, set out to confirm his mentor’s theory. Terrace, at that point a professor of psychology at Columbia, adopted a chimpanzee, whom he named, tauntingly, Nim Chimpsky. From the age of two weeks, Nim was raised by people and taught American Sign Language. Nim’s interactions with his caregivers were videotaped, so that Terrace would have an objective record of the chimp’s progress. By the time Nim was three years old, he had a repertoire of eighty signs and, significantly, often produced them in sequences, such as “banana me eat banana” or “tickle me Nim play.” Terrace set out to write a book about how Nim had crossed the language barrier and, in so doing, made a monkey of his namesake. But then Terrace double-checked some details of his account against the tapes. When he looked carefully at the videos, he was appalled. Nim hadn’t really learned A.S.L.; he had just learned to imitate the last signs his teachers had made to him.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>“The very tapes I planned to use to document Nim’s ability to sign provided decisive evidence that I had vastly overestimated his linguistic competence,” Terrace wrote.</p><p>Since Nim, many further efforts have been made to prove that different species—orangutans, bonobos, parrots, dolphins—have a capacity for language. Several of the animals who were the focus of these efforts—Koko the gorilla, Alex the gray parrot—became international celebrities. But most linguists still believe that the only species that possesses language is our own.</p><p>Language is “a uniquely human faculty” that is “part of the biological nature of our species,” Stephen R. Anderson, a professor emeritus at Yale and a former president of the Linguistic Society of America, writes in his book “Doctor Dolittle’s Delusion.”</p><p>Whether sperm-whale codas could challenge this belief is an issue that just about everyone I talked to on the <em>CETI</em> team said they’d rather not talk about.</p><p>“Linguists like Chomsky are very opinionated,” Michael Bronstein, the Oxford professor, told me. “For a computer scientist, usually a language is some formal system, and often we talk about artificial languages.” Sperm-whale codas “might not be as expressive as human language,” he continued. “But I think whether to call it ‘language’ or not is more of a formal question.”</p><p>“Ironically, it’s a semantic debate about the meaning of language,” Gero observed.</p><p>Of course, the advent of ChatGPT further complicates the debate. Once a set of algorithms can rewrite a novel, what counts as “linguistic competence”? And who—or what—gets to decide?</p><p>“When we say that we’re going to succeed in translating whale communication, what do we mean?” Shafi Goldwasser, the Radcliffe Institute fellow who first proposed the idea that led to <em>CETI</em>, asked.</p><p>“Everybody’s talking these days about these generative A.I. models like ChatGPT,” Goldwasser, who now directs the Simons Institute for the Theory of Computing, at the University of California, Berkeley, went on. “What are they doing? You are giving them questions or prompts, and then they give you answers, and the way that they do that is by predicting how to complete sentences or what the next word would be. So you could say that’s a goal for <em>CETI</em>—that you don’t necessarily understand what the whales are saying, but that you could predict it with good success. And, therefore, you could maybe generate a conversation that would be understood by a whale, but maybe you don’t understand it. So that’s kind of a weird success.”</p><p>Prediction, Goldwasser said, would mean “we’ve realized what the pattern of their speech is. It’s not satisfactory, but it’s something.</p><p>“What about the goal of understanding?” she added. “Even on that, I am not a pessimist.”</p><p>There are now an estimated eight hundred and fifty thousand sperm whales diving the world’s oceans. This is down from an estimated two million in the days before the species was commercially hunted. It’s often suggested that the darkest period for <em>P. macrocephalus</em> was the middle of the nineteenth century, when Melville shipped out of New Bedford on the Acushnet. In fact, the bulk of the slaughter took place in the middle of the twentieth century, when sperm whales were pursued by diesel-powered ships the size of factories. In the eighteen-forties, at the height of open-boat whaling, some five thousand sperm whales were killed each year; in the nineteen-sixties, the number was six times as high. Sperm whales were boiled down to make margarine, cattle feed, and glue. As recently as the nineteen-seventies, General Motors used spermaceti in its transmission fluid.</p><p>Near the peak of industrial whaling, a biologist named Roger Payne heard a radio report that changed his life and, with it, the lives of the world’s remaining cetaceans. The report noted that a whale had washed up on a beach not far from where Payne was working, at Tufts University. Payne, who’d been researching moths, drove out to see it. He was so moved by the dead animal that he switched the focus of his research. His investigations led him to a naval engineer who, while listening for Soviet submarines, had recorded eerie underwater sounds that he attributed to humpback whales. Payne spent years studying the recordings; the sounds, he decided, were so beautiful and so intricately constructed that they deserved to be called “songs.” In 1970, he arranged to have “Songs of the Humpback Whale” released as an LP.</p><p>“I just thought: the world has to hear this,” he would later recall. The album sold briskly, was sampled by popular musicians like Judy Collins, and helped launch the “Save the Whales” movement. In 1979, <em>National Geographic</em> issued a “flexi disc” version of the songs, which it distributed as an insert in more than ten million copies of the magazine. Three years later, the International Whaling Commission declared a “moratorium” on commercial hunts which remains in effect today. The move is credited with having rescued several species, including humpbacks and fin whales, from extinction.</p><p>Payne, who died in June at the age of eighty-eight, was an early and ardent member of the <em>CETI</em> team. (This was the case, Gruber told me, even though he was disappointed that the project was focussing on sperm whales, rather than on humpbacks, which, he maintained, were more intelligent.) Just a few days before his death, Payne published an op-ed piece explaining why he thought <em>CETI</em> was so important.</p><p>Whales, along with just about every other creature on Earth, are now facing grave new threats, he observed, among them climate change. How to motivate “ourselves and our fellow humans” to combat these threats?</p><p>“Inspiration is the key,” Payne wrote. “If we could communicate with animals, ask them questions and receive answers—no matter how simple those questions and answers might turn out to be—the world might soon be moved enough to at least start the process of halting our runaway destruction of life.”</p><p>Several other <em>CETI</em> team members made a similar point. “One important thing that I hope will be an outcome of this project has to do with how we see life on land and in the oceans,” Bronstein said. “If we understand—or we have evidence, and very clear evidence in the form of language-like communication—that intelligent creatures are living there and that we are destroying them, that could change the way that we approach our Earth.”</p><p>“I always look to Roger’s work as a guiding star,” Gruber told me. “The way that he promoted the songs and did the science led to an environmental movement that saved whale species from extinction. And he thought that <em>CETI</em> could be much more impactful. If we could understand what they’re saying, instead of ‘save the whales’ it will be ‘saved by the whales.’</p><p>“This project is kind of an offering,” he went on. “Can technology draw us closer to nature? Can we use all this amazing tech we’ve invented for positive purposes?”</p><p>ChatGPT shares this hope. Or at least the A.I.-powered language model is shrewd enough to articulate it. In the version of “Moby-Dick” written by algorithms in the voice of a whale, the story ends with a somewhat ponderous but not unaffecting plea for mutuality:</p><blockquote><p>I, the White Leviathan, could only wonder if there would ever come a day when man and whale would understand each other, finding harmony in the vastness of the ocean’s embrace.&nbsp;♦</p></blockquote></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An effort to ban caste discrimination in California has touched a nerve (155 pts)]]></title>
            <link>https://www.politico.com/news/2023/09/04/ban-caste-discrimination-california-bill-00113817</link>
            <guid>37381979</guid>
            <pubDate>Mon, 04 Sep 2023 16:25:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.politico.com/news/2023/09/04/ban-caste-discrimination-california-bill-00113817">https://www.politico.com/news/2023/09/04/ban-caste-discrimination-california-bill-00113817</a>, See on <a href="https://news.ycombinator.com/item?id=37381979">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div>
<p>
California state Sen. Aisha Wahab (center) gathers with supporters after a press conference introducing a bill that would outlaw caste discrimination in the state. | José Luis Villegas/AP Photo
</p>

</div>
<p>SACRAMENTO, Calif. — Caste discrimination wasn’t on the radar of many lawmakers in California. Then it showed up on their doorstep.</p>
<p>Hundreds of people mobilized outside the state Capitol in recent months, protesting a bill from first-term state Sen. Aisha Wahab to add caste to the list of protected groups in California — a proposal that many felt was unnecessary and unfairly tarnished the image of the South Asian community. Hearings on the bill got heated.</p>

<p>“Clearly we hit a nerve,” Wahab, who got death threats and is being targeted with a recall for her efforts, said at one hearing.</p>
</div><div>
<p>If the bill passes as expected and Gov. Gavin Newsom signs it into law, California would become the first state to explicitly outlaw caste-based discrimination, though Seattle has done so and other cities are considering it. Caste, a social hierarchy in which one’s group is inherited, is historically associated with South Asia and Hindus, and opponents argue such a ban stigmatizes the religious group.</p>
<p>The affair has had repercussions for Wahab in her heavily South Asian district. It’s become a bitter lesson in the pitfalls of wading into nuanced cultural issues in an ever-more diverse nation.</p>
<p>Wahab, a progressive tapped by Newsom to highlight his signature gun control effort, appeared to be caught off guard by the vitriolic response to what she views as a straightforward issue.</p>
<p>“This is a civil rights bill,” she said in an interview. “It’s very simple. We’re trying to protect people.”</p>
<p>For her, it began as she campaigned in her San Francisco Bay Area district, hearing about an issue that has emerged in some employment discrimination cases in Silicon Valley as well as a divisive <a href="http://clerk.seattle.gov/~archives/Ordinances/Ord_126767.pdf" target="_blank" data-tracking="mpos=&amp;mid=&amp;lindex=&amp;lcol=">measure in Seattle</a> and elsewhere. But a bill to explicitly ban caste discrimination hadn’t been introduced in the California Legislature, even from the two members of South Asian descent.</p>
<p>The fact that this subject came up in the first place perhaps isn’t surprising. Indians represent the second-largest U.S. immigrant group after Mexicans, and Wahab’s district has one of the largest populations of Indian Americans. More broadly, South Asians have become more visible in American politics, with Nikki Haley and Vivek Ramaswamy running in the Republican presidential primary.</p>
<p>Wahab’s legislation, <span>Senate Bill 403</span>, is a floor vote away from reaching the governor’s desk, but not before a fractious legislative process in which she received pushback even from fellow progressive Democrats. Newsom’s office would not say whether he supports the bill.</p>
<p>Committee hearings were packed, with lines for public comment stretching out the door. Social media has been ablaze from both sides, and lawmakers have received tens of thousands of calls and emails. When the city council in Cupertino <a href="https://twitter.com/CityofCupertino/status/1683510888933003267" target="_blank" data-tracking="mpos=&amp;mid=&amp;lindex=&amp;lcol=">passed a resolution</a> opposing the bill, city officials said it was the most-attended public meeting they’ve ever seen in the majority-Asian suburb.</p>
<h3>A progressive split</h3>
<p>Backlash from constituents and local officials prompted two Democratic state lawmakers whose districts overlap with Wahab’s, Assemblymembers Evan Low (D-Campbell) and Alex Lee (D-San Jose), to take the unusual step of openly disagreeing with their progressive colleague, suggesting amendments that ultimately watered down the legislation. All three are also in the Legislature’s Asian American and Pacific Islander caucus.</p>
<p>“It’s not politically expedient, but it’s the right thing to do,” Low said in an interview. “It’s my genuine interest, because it breaks my heart to see members of our AAPI community being split.”</p>
<p>Lee’s office, which typically logs about 10 constituents providing a stance on a bill, received over 600 messages on SB 403. Just 26 were in support, according to a spokesperson. Low said that the ratio of opposition to support was “99 to 1.”</p>
<p>The pair met with Wahab to share their concerns. Eventually, Wahab agreed to place caste under “ancestry” rather than list it as a standalone category such as race, gender identity and age, ensuring that the word remained in the bill, but less prominently.</p>
<p>Low did not take a vote on the proposal. But the amendments won over Lee, who gave a floor speech explaining why he was supporting the bill — and noting that he tried to ensure the ban “doesn’t unfairly single out anyone.”</p>
<p>Low and another Bay Area legislator, state Sen. Josh Becker (D-Menlo Park), said caste hadn’t come up as an issue in decades of being around Silicon Valley tech circles, where there have been accusations of caste discrimination. Activists on both sides of the debate have focused on educating lawmakers about caste.</p>
<p>“A lot of staff asked, ‘What is caste?’” Wahab said of the reaction when she first considered introducing the bill. “They had to Google it.”</p>

<p>Suhag Shukla, executive director of the Hindu American Foundation — one of the groups opposing the bill — said that the term “caste” is unlike the state’s other protected categories.</p>
<p>“Everyone has a race. Everyone has an ancestry. Everyone has a gender. Everyone has an age,” Shukla said. “Not everyone has a caste.”</p>
<p>Shukla believes the bill has sailed through the Legislature because nobody wants to be seen as being against an anti-discrimination bill.</p>
<p>The issue hits home for Assemblymember Ash Kalra (D-San Jose), the first Indian American elected to the state Legislature and one of two South Asian lawmakers serving in either house. Kalra voted for the proposal but said it was an emotional issue for him. He lamented during a committee hearing about seeing his community “tear each other apart on social media,” and hoped that both sides would make a “commitment to healing.”</p>
<h3>Heart of the movement</h3>
<p>Silicon Valley, home to a large South Asian population and some of the world’s largest tech companies, has been at the heart of a movement to combat caste-based discrimination.</p>
<p>A 2020 lawsuit by the California Civil Rights Department — believed to be the first in the state to be filed on the grounds of caste-based discrimination — accused two Cisco supervisors of discriminating against and harassing an employee who identified as Dalit, the lowest class in the caste hierarchy. The case against Cisco is ongoing, though complaints against the two supervisors were dropped earlier this year.</p>
<p>The bill’s supporters see the lawsuit as a milestone that has enabled more caste-oppressed people to come forward.</p>
<p>“Right now, it’s such a gray area,” said Tanuja Gupta, who in 2021 quit her job as a senior manager at Google News in a <a href="https://www.washingtonpost.com/technology/2022/06/02/google-caste-equality-labs-tanuja-gupta/" target="_blank" data-tracking="mpos=&amp;mid=&amp;lindex=&amp;lcol=">highly publicized exit</a> after an event she had organized about caste issues was postponed.</p>
<p>Gupta is now in law school in New York. She said that one of the most frustrating parts of advocating for SB 403 has been the argument that caste discrimination isn’t occurring because there have been so few documented cases, calling it a “chicken and egg argument.”</p>
<p>Using a different surname to protect against discrimination is not uncommon, said Prem Pariyar, a delegate for the National Association of Social Workers and Cal State East Bay alum who helped lead a successful push last year for the CSU school system to include caste in its <a href="https://www.calstate.edu/csu-system/faculty-staff/academic-senate/resolutions/2021-2022/3527.pdf" target="_blank" data-tracking="mpos=&amp;mid=&amp;lindex=&amp;lcol=">anti-discrimination policy</a>.</p>
<p>Pariyar was born into a Dalit family in Nepal and came to California in 2015 to escape caste discrimination. Friends told him that the state was progressive, friendly to immigrants and accepting of different cultures. Instead, he recalled being alienated by his Nepalese coworkers, who refused to room in shared housing with him because of his caste. Pariyar said he was forced to live out of a van for a month, an experience he called depressing and scary.</p>
<p>“I thought they would not repeat those kinds of practices here,” Pariyar said.</p>
<h3>Talking points</h3>
<p>In mid-July, about 250 people gathered at an events center in Fremont, an East Bay suburb in Wahab’s district, for “Caste Con,” a full day of programming against the bill. Several Fremont city officials attended, as well as Palo Alto Mayor Lydia Kou. Fremont Mayor Lily Mei, who lost to Wahab in last year’s race for the local state Senate seat, was given a standing ovation when she was introduced.</p>
<p>The event was moderated by Satish Sharma, chair of the Global Hindu Federation based in the United Kingdom. Copies of Sharma’s book “Caste, Conversion: A Colonial Conspiracy” were available for free in the lobby.</p>
<p>At one point, Sharma asked ChatGPT to define “caste,” and then pointed out the number of times that the word “Hindu” appeared in the computer’s response. “That’s not an accident,” Sharma later said in an interview. “It’s been seeded for such a long time. The word is a hate brand.”</p>
<p>Later, attendees heard talking points on how to defend their stance in the state Capitol. Salvatore Babones, a sociologist and associate professor at the University of Sydney, said people have to “accept the debate” over caste, noting that simple arguments such as “I’m not a Nazi” and “I’m not a white supremacist” do not work in the United States.</p>
<p>“You have to fight it on American terms,” Babones said. “If you don’t fight it on American terms, you’re going to lose.”</p>
<p><i>Sejal Govindarao contributed to this report.</i></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Refact Code LLM: 1.6B LLM for code that reaches 32% HumanEval (178 pts)]]></title>
            <link>https://refact.ai/blog/2023/introducing-refact-code-llm/</link>
            <guid>37381862</guid>
            <pubDate>Mon, 04 Sep 2023 16:13:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://refact.ai/blog/2023/introducing-refact-code-llm/">https://refact.ai/blog/2023/introducing-refact-code-llm/</a>, See on <a href="https://news.ycombinator.com/item?id=37381862">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                
                
                <p>Today we’re introducing Refact LLM: 1.6B code model with infill real-time code completion (including fill-in-the-middle(FIM) capability) and chat.
Refact LLM achieves the state-of-the-art performance among the code LLMs, coming closer to  HumanEval as Starcoder, being 10x smaller in size, and it beats other code models such as StableCode, CodeGen and ReplitCode on HumanEval metric.</p>
<p><strong>Summary</strong>:</p>
<ul><li>1.6b parameters</li><li>20 programming languages</li><li>4096 tokens context</li><li>code completion and chat capabilities</li><li>SoTA on HumanEval benchmark among similar code models</li><li>pre-trained on permissive licensed code and available for commercial use</li></ul>
<div><table><thead><tr><th>Model</th><th>Model Size</th><th>HumanEval pass@1</th></tr></thead><tbody><tr><td>DeciCoder-1b</td><td>1b</td><td>19.1%</td></tr><tr><td>Refact-1.6-fim</td><td>1.6b</td><td>32.0%</td></tr><tr><td>StableCode</td><td>3b</td><td>20.2%</td></tr><tr><td>ReplitCode v1</td><td>3b</td><td>21.9%</td></tr><tr><td>CodeGen2.5-multi</td><td>7b</td><td>28.4%</td></tr><tr><td>CodeLlama</td><td>7b</td><td>33.5%</td></tr><tr><td>StarCoder</td><td>15b</td><td>33.6%</td></tr></tbody></table></div>
<p>The base model was trained on our own set of code with permissive licenses only and open text datasets (the text to code ratio was 50:50). In total, we trained our base model on 1.2T tokens of code on our cluster.</p>
<p>The model was then fine-tuned with open code instruction-following datasets filtered for quality and a synthetic dataset based on <a href="https://huggingface.co/datasets/bigcode/the-stack-dedup">The Stack dedup v1.1</a> to improve FIM and boosting the base model performance.</p>
<p>You can read more about the architecture decisions that we made in the <a href="https://refact.ai/blog/2023/applying-recent-innovations-to-train-model/">blog post</a>.</p>
<p>We aim for the model to be accessible to everyone, we’re releasing the model for commercial use under BigScience OpenRAIL-M license and making the weight available on <a href="https://huggingface.co/smallcloudai/Refact-1_6B-fim">HuggingFace</a>.</p>
<p>While the trend recently was for the model sizes to get bigger, we wanted to lower barriers to entry and make it a versatile tool for developers with varying hardware setups. With the smaller size, running the model is much faster and affordable than ever: the model can be served on most of all modern GPUs requiring just 3Gb RAM and works great for real-time code completion tasks.</p>
<p>Refact LLM can be easily integrated into existing developers workflows with <a href="https://github.com/smallcloudai/refact/">an open-source docker container</a> and <a href="https://marketplace.visualstudio.com/items?itemName=smallcloud.codify">VS Code</a> and <a href="https://plugins.jetbrains.com/plugin/20647-codify">JetBrains</a> plugins. With Refact’s intuitive user interface, developers can utilize the model easily for a variety of coding tasks. Finetune is available in the self-hosting (docker) and Enterprise versions, making suggestions more relevant for your private codebase.</p>
<p><img src="https://refact.ai/images/blog/introducing-refact-code-llm/palindrome.gif"></p>
<p>Refact 1.6B LLM is the third model in the family of our code models, with <a href="https://huggingface.co/smallcloudai/codify_3b_multi">CodeContrast 3b</a> and <a href="https://huggingface.co/smallcloudai/codify_medium_multi">CodeContrast 0.3b</a> released previously. We aim to continue with our research and future updates to improve the LLM’s performance and capabilities. We would love to get community contributions and feedback to enhance the model further. For any questions and ideas, please visit our <a href="https://smallcloud.ai/discord">Discord</a>.</p>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Portal 64 – A demake of Portal for the Nintendo 64 (348 pts)]]></title>
            <link>https://github.com/lambertjamesd/portal64</link>
            <guid>37381407</guid>
            <pubDate>Mon, 04 Sep 2023 15:27:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/lambertjamesd/portal64">https://github.com/lambertjamesd/portal64</a>, See on <a href="https://news.ycombinator.com/item?id=37381407">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Portal64</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/lambertjamesd/portal64/blob/master/assets/images/portal64_readme_logo.gif"><img src="https://github.com/lambertjamesd/portal64/raw/master/assets/images/portal64_readme_logo.gif" alt="" data-animated-image=""></a></p>
<p dir="auto">A demake of Portal for the Nintendo 64.</p>
<h2 tabindex="-1" dir="auto">How to build</h2>
<p dir="auto">First, you will need to setup <a href="https://crashoveride95.github.io/n64hbrew/modernsdk/startoff.html" rel="nofollow">Modern SDK</a>.</p>
<p dir="auto">After installing modern sdk you will want to also install</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo apt install libnustd"><pre>sudo apt install libnustd</pre></div>
<p dir="auto">Next, you will need to download Blender 3.0 or higher. Then set the environment variable <code>BLENDER_3_0</code> to be the absolute path where the Blender executable is located on your system.</p>

<p dir="auto">e.g. add this to your ~/.bashrc</p>
<div dir="auto" data-snippet-clipboard-copy-content="export BLENDER_3_0=&quot;/usr/bin/blender&quot;"><pre><span>export</span> BLENDER_3_0=<span><span>"</span>/usr/bin/blender<span>"</span></span></pre></div>

<p dir="auto">You will need to install Python <code>vpk</code>.</p>


<p dir="auto">Install <code>vtf2png</code>, <code>sfz2n64</code>, and setup <code>skeletool64</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="echo &quot;deb [trusted=yes] https://lambertjamesd.github.io/apt/ ./&quot; \
    | sudo tee /etc/apt/sources.list.d/lambertjamesd.list
sudo apt update
sudo apt install vtf2png sfz2n64 mpg123 sox imagemagick unzip"><pre><span>echo</span> <span><span>"</span>deb [trusted=yes] https://lambertjamesd.github.io/apt/ ./<span>"</span></span> \
    <span>|</span> sudo tee /etc/apt/sources.list.d/lambertjamesd.list
sudo apt update
sudo apt install vtf2png sfz2n64 mpg123 sox imagemagick unzip</pre></div>

<p dir="auto">Install lua5.4 (remove other perhaps installed versions first, skelatool64 needs to be build with luac 5.4!)</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo apt install lua5.4 liblua5.4-dev liblua5.4-0"><pre>sudo apt install lua5.4 liblua5.4-dev liblua5.4-0</pre></div>

<p dir="auto">Setup and build skelatool64 (the version included in this portal64 repo!)</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd skelatool64
./setup_dependencies.sh
make"><pre><span>cd</span> skelatool64
./setup_dependencies.sh
make</pre></div>

<p dir="auto">You will need to install nodejs. You can use apt for this</p>


<p dir="auto">You then need to add the following files from where Portal is installed to the folder <code>vpk</code>. (see vpk/add_vpk_here.md  for more details!)</p>
<div data-snippet-clipboard-copy-content="portal/portal_pak_000.vpk  
portal/portal_pak_001.vpk  
portal/portal_pak_002.vpk  
portal/portal_pak_003.vpk  
portal/portal_pak_004.vpk  
portal/portal_pak_005.vpk  
portal/portal_pak_dir.vpk

hl2/hl2_sound_misc_000.vpk
hl2/hl2_sound_misc_001.vpk
hl2/hl2_sound_misc_002.vpk
hl2/hl2_sound_misc_dir.vpk"><pre><code>portal/portal_pak_000.vpk  
portal/portal_pak_001.vpk  
portal/portal_pak_002.vpk  
portal/portal_pak_003.vpk  
portal/portal_pak_004.vpk  
portal/portal_pak_005.vpk  
portal/portal_pak_dir.vpk

hl2/hl2_sound_misc_000.vpk
hl2/hl2_sound_misc_001.vpk
hl2/hl2_sound_misc_002.vpk
hl2/hl2_sound_misc_dir.vpk
</code></pre></div>
<p dir="auto">Finally, run <code>make</code> to build the project.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Clean out any previous build files
make clean

# Build
make

# In case you have any trouble with ROM running on hardware try
# wine install required to run properly
sudo apt install wine
make fix"><pre><span><span>#</span> Clean out any previous build files</span>
make clean

<span><span>#</span> Build</span>
make

<span><span>#</span> In case you have any trouble with ROM running on hardware try</span>
<span><span>#</span> wine install required to run properly</span>
sudo apt install wine
make fix</pre></div>
<br>
<h2 tabindex="-1" dir="auto">Build with Docker</h2>
<p dir="auto">Using the docker image the only setup step you need is to populating the vpk folder. After that you can build the docker image using</p>
<p dir="auto">Build the Docker image.</p>
<div dir="auto" data-snippet-clipboard-copy-content="make -f Makefile.docker image"><pre>make -f Makefile.docker image</pre></div>

<p dir="auto">Then build the rom using</p>

<p dir="auto">That will generate the rom at <code>/build/portal64.z64</code></p>
<br>
<h2 tabindex="-1" dir="auto">Current Level Checklist</h2>
<ul>
<li> Add indicator lights for signals</li>
<li> Apply rotation to static content</li>
<li> Remove overlap underneath doors</li>
</ul>
<h2 tabindex="-1" dir="auto">Current New Feature TODO List</h2>
<ul>
<li> rumble pak support?</li>
<li> Change default controls</li>
<li> Add puzzle element connections and additional signs</li>
<li> Use a much nearer clipping plane when rendering the portal gun</li>
<li> Investigate crash after falling into death water on test chamber 8</li>
<li> Add particle effects (shooting portal gun, energy pellet)</li>
<li> Add auto save checkpoints</li>
<li> Correct elevator timing</li>
<li> Adding loading notice between levels #45</li>
<li> ball velocity in test chamber 11</li>
<li> test chamber 04 has seams in a corner</li>
<li> pausing while glados is speaking can end her speech early</li>
<li> don't count boxes on buttons until it is released and stable</li>
<li> Portal not rendering recursively sometimes #138</li>
<li> disable portal surfaces manually on some surfaces #135</li>
<li> test chamber 02 needs more light in the first room</li>
<li> Presort portal gun polygon order #102</li>
</ul>
<h2 tabindex="-1" dir="auto">Current New Sounds TODO List</h2>
<ul>
<li> Box collision sounds</li>
<li> Unstationary scaffolding moving sound</li>
<li> Ambient background loop</li>
</ul>
<h2 tabindex="-1" dir="auto">Current Bug TODO List (Hardware Verified) (High-&gt;Low priority)</h2>
<p dir="auto">----------------------- v8</p>
<ul>
<li> player can clip through back of elevator by jumping and strafeing at the back corners while inside.</li>
<li> Player can trap themselves in chamber 5 by following instructions issue #75</li>
<li> Two wall portals next to eachother can be used to clip any object out of any level by pushing it into corner, then dropping.</li>
<li> Passing into a ceiling portal can sometimes mess with the player rotation</li>
<li> various visual glitches when running NTSC on PAL console #65</li>
<li> various visual glitches when running PAL on NTSC console #65</li>
<li> Can shoot portals, and walk through signage</li>
<li> Can place portals on ground after final fizzler on all levels</li>
</ul>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[VSCodium – Open-source binaries of VSCode (465 pts)]]></title>
            <link>https://vscodium.com</link>
            <guid>37381335</guid>
            <pubDate>Mon, 04 Sep 2023 15:20:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vscodium.com">https://vscodium.com</a>, See on <a href="https://news.ycombinator.com/item?id=37381335">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main" id="main">
<nav><ul>
<li><a href="#intro">home</a></li>
<li><a href="#why">Why</a></li>
<li><a href="#install">Install</a></li>
<li><a href="#moreinfo">More Info</a></li>
</ul></nav>
<div id="intro">
<p><img src="https://vscodium.com/img/codium_cnl.svg" alt="VSCodium logo" width="200"></p>
<h2>VSCodium</h2>
<h3>Free/Libre Open Source Software Binaries of VS Code</h3>
<p><a href="https://github.com/vscodium/vscodium/releases"><img src="https://img.shields.io/github/release/vscodium/vscodium.svg" alt="current release"></a>
<a href="https://github.com/VSCodium/vscodium/blob/master/LICENSE"><img src="https://img.shields.io/github/license/VSCodium/vscodium.svg" alt="license"></a>
<a href="https://gitter.im/VSCodium/Lobby"><img src="https://img.shields.io/gitter/room/vscodium/vscodium.svg" alt="Gitter"></a></p>
<p>VSCodium is a community-driven, freely-licensed binary distribution of Microsoft’s editor VS Code.</p>
<p><img src="https://vscodium.com/img/vscodium.png" alt="Screenshot"></p>
</div>
<div id="why">
<h2>Why Does This Exist</h2>
<p>Microsoft’s <code>vscode</code> source code is open source (MIT-licensed), but the product available for download (Visual Studio Code) is licensed under <a href="https://code.visualstudio.com/license">this not-FLOSS license</a> and contains telemetry/tracking. According to <a href="https://github.com/Microsoft/vscode/issues/60#issuecomment-161792005">this comment</a> from a Visual Studio Code maintainer:</p>
<blockquote>
<p>When we [Microsoft] build Visual Studio Code, we do exactly this. We clone the vscode repository, we lay down a customized product.json that has Microsoft specific functionality (telemetry, gallery, logo, etc.), and then produce a build that we release under our license.</p>
<p>When you clone and build from the vscode repo, none of these endpoints are configured in the default product.json. Therefore, you generate a “clean” build, without the Microsoft customizations, which is by default licensed under the MIT license</p>
</blockquote>
<p>The VSCodium project exists so that you don’t have to download+build from source. This project includes special build scripts that clone Microsoft’s vscode repo, run the build commands, and upload the resulting binaries for you to <a href="https://github.com/VSCodium/vscodium/releases">GitHub releases</a>. <strong>These binaries are licensed under the MIT license. Telemetry is disabled.</strong></p>
<p>If you want to build from source yourself, head over to <a href="https://github.com/Microsoft/vscode">Microsoft’s vscode repo</a> and follow their <a href="https://github.com/Microsoft/vscode/wiki/How-to-Contribute#build-and-run">instructions</a>. VSCodium exists to make it easier to get the latest version of MIT-licensed VS Code.</p>
</div>
<div id="install">

<hr>
<h2>Use a Package Manager (providing VSCodium in their repository)</h2>
<p>The following package managers use their own repository, in case of any installation issues report to their related repository.</p>
<hr>

<h3>Install with Brew (Mac)</h3>
<p>If you are on a Mac and have <a href="https://brew.sh/">Homebrew</a> installed:</p>
<div><pre><code>brew <span>install</span> <span>--cask</span> vscodium
</code></pre></div>
<p><em>Note for Mac OS X Mojave users: if you see “App can’t be opened because Apple cannot check it for malicious software” when opening VSCodium the first time, you can right-click the application and choose Open. This should only be required the first time opening on Mojave.</em></p>
<hr>

<h3>Install with Windows Package Manager (WinGet)</h3>
<p>If you use Windows and have <a href="https://github.com/microsoft/winget-cli">Windows Package Manager</a> installed:</p>
<pre><code>winget install vscodium
</code></pre>
<hr>

<h3>Install with Chocolatey (Windows)</h3>
<p>If you use Windows and have <a href="https://chocolatey.org/">Chocolatey</a> installed (thanks to <a href="https://github.com/Thilas">@Thilas</a>):</p>
<pre><code>choco install vscodium
</code></pre>
<hr>

<h3>Install with Scoop (Windows)</h3>
<p>If you use Windows and have <a href="https://scoop.sh/">Scoop</a> installed:</p>
<pre><code>scoop bucket add extras
</code></pre>
<pre><code>scoop install vscodium
</code></pre>
<hr>

<h3>Install with snap (Linux)</h3>
<p>VSCodium is available in the <a href="https://snapcraft.io/">Snap Store</a> as <a href="https://snapcraft.io/codium">Codium</a>, currently maintained by the VSCodium project.
If your GNU/Linux distribution has support for <a href="https://snapcraft.io/docs/installing-snapd">snaps</a>:</p>
<div><pre><code>snap <span>install </span>codium <span>--classic</span>
</code></pre></div>
<hr>

<h3>Install on Parrot OS:</h3>
<p>VSCodium is pre-installed in Parrot OS.</p>
<p>In case you don’t find it by default, you can retrieve it from the official Parrot repo</p>
<div><pre><code><span>sudo </span>apt update <span>&amp;&amp;</span> <span>sudo </span>apt <span>install </span>codium
</code></pre></div>
<hr>

<h3>Install on Nix(OS)</h3>
<p>VSCodium is available in Nixpkgs. You can install it by adding <code>vscodium</code> to <code>environment.systemPackages</code> in <code>configuration.nix</code>, or locally:</p>
<div><pre><code>nix-env <span>-iA</span> nixpkgs.vscodium
</code></pre></div>
<hr>

<h3>Install on Arch Linux</h3>
<p>VSCodium is available on the <a href="https://aur.archlinux.org/packages/vscodium-bin/">AUR (Arch User Repository)</a>, and can be installed with an AUR Helper.</p>
<p>Examples:</p>
<ul>
<li><strong>Aura</strong>:
<div><pre><code>sudo aura -A vscodium-bin
</code></pre></div>
</li>
<li><strong>Yay</strong>:

</li>
</ul>
<h2>Use a Package Manager (deb/rpm, provided by VSCodium related repository)</h2>
<p><a href="https://github.com/paulcarroty">@paulcarroty</a> has set up a <a href="https://gitlab.com/paulcarroty/vscodium-deb-rpm-repo">repository</a> for VSCodium. The instructions below are adapted from there with <a href="https://download.vscodium.com/">CDN</a> mirror. Any issues installing VSCodium using your package manager should be directed to that repository’s issue tracker.</p>
<hr>

<h3>Install on Debian / Ubuntu (deb package):</h3>
<p>Add the GPG key of the repository:</p>
<div><pre><code>wget <span>-qO</span> - https://gitlab.com/paulcarroty/vscodium-deb-rpm-repo/raw/master/pub.gpg <span>\</span>
    | gpg <span>--dearmor</span> <span>\</span>
    | <span>sudo dd </span><span>of</span><span>=</span>/usr/share/keyrings/vscodium-archive-keyring.gpg
</code></pre></div>
<p>Add the repository:</p>
<div><pre><code><span>echo</span> <span>'deb [ signed-by=/usr/share/keyrings/vscodium-archive-keyring.gpg ] https://download.vscodium.com/debs vscodium main'</span> <span>\</span>
    | <span>sudo tee</span> /etc/apt/sources.list.d/vscodium.list
</code></pre></div>
<p>Update then install vscodium (if you want vscodium-insiders, then replace <code>codium</code> by <code>codium-insiders</code>):</p>
<div><pre><code><span>sudo </span>apt update <span>&amp;&amp;</span> <span>sudo </span>apt <span>install </span>codium
</code></pre></div>
<hr>

<h3>Install on Fedora / RHEL / CentOS / RockyLinux / OpenSUSE (rpm package):</h3>
<p>Add the GPG key of the repository:</p>
<div><pre><code><span>sudo </span>rpmkeys <span>--import</span> https://gitlab.com/paulcarroty/vscodium-deb-rpm-repo/-/raw/master/pub.gpg
</code></pre></div>
<p>Add the repository:</p>
<ul>
<li><strong>Fedora/RHEL/CentOS/Rocky Linux</strong>:
<div><pre><code><span>printf</span> <span>"[gitlab.com_paulcarroty_vscodium_repo]</span><span>\n</span><span>name=download.vscodium.com</span><span>\n</span><span>baseurl=https://download.vscodium.com/rpms/</span><span>\n</span><span>enabled=1</span><span>\n</span><span>gpgcheck=1</span><span>\n</span><span>repo_gpgcheck=1</span><span>\n</span><span>gpgkey=https://gitlab.com/paulcarroty/vscodium-deb-rpm-repo/-/raw/master/pub.gpg</span><span>\n</span><span>metadata_expire=1h"</span> | <span>sudo tee</span> <span>-a</span> /etc/yum.repos.d/vscodium.repo
</code></pre></div>
</li>
<li><strong>OpenSUSE/SUSE</strong>:
<div><pre><code><span>printf</span> <span>"[gitlab.com_paulcarroty_vscodium_repo]</span><span>\n</span><span>name=gitlab.com_paulcarroty_vscodium_repo</span><span>\n</span><span>baseurl=https://download.vscodium.com/rpms/</span><span>\n</span><span>enabled=1</span><span>\n</span><span>gpgcheck=1</span><span>\n</span><span>repo_gpgcheck=1</span><span>\n</span><span>gpgkey=https://gitlab.com/paulcarroty/vscodium-deb-rpm-repo/-/raw/master/pub.gpg</span><span>\n</span><span>metadata_expire=1h"</span> | <span>sudo tee</span> <span>-a</span> /etc/zypp/repos.d/vscodium.repo
</code></pre></div>
</li>
</ul>
<p>Install the software:
(if you want vscodium-insiders, then replace <code>codium</code> by <code>codium-insiders</code>)</p>
<ul>
<li><strong>Fedora/RHEL/CentOS/Rocky Linux</strong>:

</li>
<li><strong>OpenSUSE/SUSE</strong>:

<hr>
</li>
</ul>

<h3>Install on Gentoo / Funtoo Linux (ebuild):</h3>
<ul>
<li><strong>Funtoo</strong>:</li>
</ul>
<div><pre><code><span>sudo </span>emerge <span>-av</span> vscodium-bin
</code></pre></div>
<ul>
<li><strong>Gentoo</strong>:</li>
</ul>

<hr>

<h2>Flatpak Option (Linux)</h2>
<p>VSCodium is (unofficially) available as a <a href="https://flathub.org/apps/details/com.vscodium.codium">Flatpak app</a> and here’s the <a href="https://github.com/flathub/com.vscodium.codium">build repo</a>. If your distribution has support for <a href="https://flathub.org/">flatpak</a>, and you have enabled the <a href="https://flatpak.org/setup/">flathub repo</a>, you can install VSCodium via the command line:</p>
<div><pre><code>flatpak <span>install </span>flathub com.vscodium.codium
</code></pre></div>
<p>…or by opening the <a href="https://dl.flathub.org/repo/appstream/com.vscodium.codium.flatpakref">flatpakref</a> file from <a href="https://flathub.org/apps/details/com.vscodium.codium">Flathub</a>. VSCodium can also be found in GNOME Software if you have <code>gnome-software-plugin-flatpak</code> installed (as recommended in the Flathub setup instructions).</p>
</div>
<div id="moreinfo">
<h2>More Info</h2>
<p>The most up-to-date information on migrating from Visual Studio Code and other quirks you might encounter are <a href="https://github.com/VSCodium/vscodium/blob/master/DOCS.md">documented</a>.</p>
</div>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Keep – GitHub Actions for your monitoring tools (147 pts)]]></title>
            <link>https://github.com/keephq/keep</link>
            <guid>37381268</guid>
            <pubDate>Mon, 04 Sep 2023 15:15:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/keephq/keep">https://github.com/keephq/keep</a>, See on <a href="https://news.ycombinator.com/item?id=37381268">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><p><a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/assets/keep.png?raw=true"><img src="https://github.com/keephq/keep/raw/main/assets/keep.png?raw=true" width="86"></a>
</p>
<h2 tabindex="-1" dir="auto">The open-source alerts management and automation platform</h2>

<p><a href="https://github.com/keephq/keep/blob/main/LICENSE">
        <img src="https://camo.githubusercontent.com/ac033cba59891cb8c4a65b0ca7df802488f4fc380c640bfd591396855e799f9a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6b65657068712f6b656570" data-canonical-src="https://img.shields.io/github/license/keephq/keep">
    </a>
    <a href="https://keephq.dev/slack" rel="nofollow">
        <img src="https://camo.githubusercontent.com/517ab7911d889dc940c47033b7dea1a89d31757c9dc5a57a0efba5935ad05a22/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f436861742d6f6e253230536c61636b2d626c756576696f6c6574" alt="Slack community channel" data-canonical-src="https://img.shields.io/badge/Chat-on%20Slack-blueviolet">
    </a>
    <a href="https://codecov.io/gh/keephq/keep" rel="nofollow">
        <img src="https://camo.githubusercontent.com/e947440180aa861f089c54c91ebc1c0ab7e65f021c349127674fc5a1692290ef/68747470733a2f2f636f6465636f762e696f2f67682f6b65657068712f6b6565702f6272616e63682f6d61696e2f67726170682f62616467652e7376673f746f6b656e3d3256543658594d524753" data-canonical-src="https://codecov.io/gh/keephq/keep/branch/main/graph/badge.svg?token=2VT6XYMRGS">
    </a>
</p>
<p dir="auto">
    <a href="#why-keep">Why Keep?</a>
    ·
    <a href="#getting-started">Getting started</a>
    ·
    <a href="#supported-providers">Supported tools and integrations</a>
    ·
    <a href="https://docs.keephq.dev/" rel="nofollow">Docs</a>
    ·
    <a href="https://platform.keephq.dev/" rel="nofollow">Try it out</a>
    ·
    <a href="https://keephq.dev/" rel="nofollow">Website</a>
    ·
    <a href="https://github.com/keephq/keep/issues/new?assignees=&amp;labels=bug&amp;template=bug_report.md&amp;title=">Report Bug</a>
    ·
    <a href="https://keephq.dev/slack" rel="nofollow">Slack Community</a>
</p>
<h3 tabindex="-1" dir="auto">
Keep makes it easy to consolidate all your alerts into a single pane of glass and to orchestrate workflows to automate your end-to-end processes. <p> Enrich any tool with <a href="https://docs.datadoghq.com/service_management/workflows/" rel="nofollow">Datadog Workflow Automation</a> like capabilities.
</p></h3>
<h2 tabindex="-1" dir="auto">How does it work?</h2>
<ol dir="auto">
<li><strong>Connect your tools</strong>: Connect everything from monitoring platforms to databases and ticketing systems.</li>
</ol>

<ol start="2" dir="auto">
<li><strong>Set up Workflows</strong>: Initiate automated workflows in response to alerts or based on custom intervals.</li>
</ol>
<div dir="auto">
<table>
<thead>
<tr>
<th>Create and upload workflows</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/assets/upload_workflow.gif"><img src="https://github.com/keephq/keep/raw/main/assets/upload_workflow.gif" data-animated-image=""></a></td>
</tr>
</tbody>
</table>
</div>
<ol start="3" dir="auto">
<li><strong>Operational efficiency</strong>: Automate your alert handling to focus your team's efforts on what really matters.</li>
</ol>
<h2 tabindex="-1" dir="auto">Why Keep?</h2>
<ol dir="auto">
<li><strong>Centralized dashboard</strong>: Manage all your alerts across different platforms in a single interface.</li>
<li><strong>Noise reduction</strong>: Deduplicate and correlate alerts to reduce alert fatigue.</li>
<li><strong>Automation</strong>: Trigger workflows for alert enrichment and response.</li>
<li><strong>Developer-first</strong>: Keep is API-first and lets you manage your workflows as code.</li>
<li><strong>Works with every tool</strong>: Plenty of <a href="#supported-providers">supported providers</a> and more to come.</li>
</ol>
<h2 tabindex="-1" dir="auto">Workflows</h2>
<p dir="auto">The easiest way of thinking about Workflow in Keep is GitHub Actions. At its core, a Workflow in Keep is a declarative YAML file, composed of triggers, steps, and actions and serves to manage, enrich, and automate responses to alerts:</p>
<div dir="auto" data-snippet-clipboard-copy-content="workflow:
  id: most-basic-keep-workflow
  description: send a slack message when a cloudwatch alarm is triggered
  # workflow triggers - supports alerts, interval, and manual triggers
  triggers:
    - type: alert
      filters:
        - key: source
          value: cloudwatch
    - type: manual
  # list of steps that can add context to your alert
  steps:
    - name: enrich-alert-with-more-data-from-a-database
      provider:
        type: bigquery
        config: &quot;{{ providers.bigquery-prod }}&quot;
        with:
          query: &quot;SELECT customer_id, customer_type as date FROM `customers_prod` LIMIT 1&quot;
  # list of actions that can automate response and do things with your alert
  actions:
    - name: trigger-slack
      provider:
        type: slack
        config: &quot; {{ providers.slack-prod }} &quot;
        with:
          message: &quot;Got alarm from aws cloudwatch! {{ alert.name }}&quot;"><pre><span>workflow</span>:
  <span>id</span>: <span>most-basic-keep-workflow</span>
  <span>description</span>: <span>send a slack message when a cloudwatch alarm is triggered</span>
  <span><span>#</span> workflow triggers - supports alerts, interval, and manual triggers</span>
  <span>triggers</span>:
    - <span>type</span>: <span>alert</span>
      <span>filters</span>:
        - <span>key</span>: <span>source</span>
          <span>value</span>: <span>cloudwatch</span>
    - <span>type</span>: <span>manual</span>
  <span><span>#</span> list of steps that can add context to your alert</span>
  <span>steps</span>:
    - <span>name</span>: <span>enrich-alert-with-more-data-from-a-database</span>
      <span>provider</span>:
        <span>type</span>: <span>bigquery</span>
        <span>config</span>: <span><span>"</span>{{ providers.bigquery-prod }}<span>"</span></span>
        <span>with</span>:
          <span>query</span>: <span><span>"</span>SELECT customer_id, customer_type as date FROM `customers_prod` LIMIT 1<span>"</span></span>
  <span><span>#</span> list of actions that can automate response and do things with your alert</span>
  <span>actions</span>:
    - <span>name</span>: <span>trigger-slack</span>
      <span>provider</span>:
        <span>type</span>: <span>slack</span>
        <span>config</span>: <span><span>"</span> {{ providers.slack-prod }} <span>"</span></span>
        <span>with</span>:
          <span>message</span>: <span><span>"</span>Got alarm from aws cloudwatch! {{ alert.name }}<span>"</span></span></pre></div>
<p dir="auto">Workflow triggers can either be executed manually when an alert is activated or run at predefined intervals. More examples can be found <a href="https://github.com/keephq/keep/tree/main/examples/workflows">here</a>.</p>
<h2 tabindex="-1" dir="auto">Supported Providers</h2>
<blockquote>
<p dir="auto">Missing any? Just submit a <a href="https://github.com/keephq/keep/issues/new?assignees=&amp;labels=&amp;projects=&amp;template=new_provider.md&amp;title=">new provider issue</a> and we will add it in the blink of an eye.</p>
</blockquote>
<h3 tabindex="-1" dir="auto">Observability tools</h3>
<p dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/keep-ui/public/icons/newrelic-icon.png?raw=true"><img width="32" height="32" src="https://github.com/keephq/keep/raw/main/keep-ui/public/icons/newrelic-icon.png?raw=true"></a>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/keep-ui/public/icons/datadog-icon.png?raw=true"><img width="32" height="32" src="https://github.com/keephq/keep/raw/main/keep-ui/public/icons/datadog-icon.png?raw=true"></a>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/keep-ui/public/icons/cloudwatch-icon.png?raw=true"><img width="32" height="32" src="https://github.com/keephq/keep/raw/main/keep-ui/public/icons/cloudwatch-icon.png?raw=true"></a>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/keep-ui/public/icons/elastic-icon.png?raw=true"><img width="32" height="32" src="https://github.com/keephq/keep/raw/main/keep-ui/public/icons/elastic-icon.png?raw=true"></a>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/keep-ui/public/icons/grafana-icon.png?raw=true"><img width="32" height="32" src="https://github.com/keephq/keep/raw/main/keep-ui/public/icons/grafana-icon.png?raw=true"></a>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/keep-ui/public/icons/prometheus-icon.png?raw=true"><img width="32" height="32" src="https://github.com/keephq/keep/raw/main/keep-ui/public/icons/prometheus-icon.png?raw=true"></a>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/keep-ui/public/icons/zabbix-icon.png?raw=true"><img width="32" height="32" src="https://github.com/keephq/keep/raw/main/keep-ui/public/icons/zabbix-icon.png?raw=true"></a>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/keep-ui/public/icons/sentry-icon.png?raw=true"><img width="32" height="32" src="https://github.com/keephq/keep/raw/main/keep-ui/public/icons/sentry-icon.png?raw=true"></a>
</p>
<h3 tabindex="-1" dir="auto">Databases and data warehouses</h3>
<p dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/keep-ui/public/icons/bigquery-icon.png?raw=true"><img width="32" height="32" src="https://github.com/keephq/keep/raw/main/keep-ui/public/icons/bigquery-icon.png?raw=true"></a>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/keep-ui/public/icons/mysql-icon.png?raw=true"><img width="32" height="32" src="https://github.com/keephq/keep/raw/main/keep-ui/public/icons/mysql-icon.png?raw=true"></a>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/keep-ui/public/icons/postgres-icon.png?raw=true"><img width="32" height="32" src="https://github.com/keephq/keep/raw/main/keep-ui/public/icons/postgres-icon.png?raw=true"></a>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/keep-ui/public/icons/snowflake-icon.png?raw=true"><img width="32" height="32" src="https://github.com/keephq/keep/raw/main/keep-ui/public/icons/snowflake-icon.png?raw=true"></a>
</p>
<h3 tabindex="-1" dir="auto">Communication platforms</h3>
<p dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/keep-ui/public/icons/slack-icon.png?raw=true"><img width="32" height="32" src="https://github.com/keephq/keep/raw/main/keep-ui/public/icons/slack-icon.png?raw=true"></a>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/keep-ui/public/icons/teams-icon.png?raw=true"><img width="32" height="32" src="https://github.com/keephq/keep/raw/main/keep-ui/public/icons/teams-icon.png?raw=true"></a>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/keep-ui/public/icons/telegram-icon.png?raw=true"><img width="32" height="32" src="https://github.com/keephq/keep/raw/main/keep-ui/public/icons/telegram-icon.png?raw=true"></a>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/keep-ui/public/icons/pushover-icon.png?raw=true"><img width="32" height="32" src="https://github.com/keephq/keep/raw/main/keep-ui/public/icons/pushover-icon.png?raw=true"></a>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/keep-ui/public/icons/resend-icon.png?raw=true"><img width="32" height="32" src="https://github.com/keephq/keep/raw/main/keep-ui/public/icons/resend-icon.png?raw=true"></a>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/keep-ui/public/icons/discord-icon.png?raw=true"><img width="32" height="32" src="https://github.com/keephq/keep/raw/main/keep-ui/public/icons/discord-icon.png?raw=true"></a>
</p>
<h3 tabindex="-1" dir="auto">Incident Management tools</h3>
<p dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/keep-ui/public/icons/pagerduty-icon.png?raw=true"><img width="32" height="32" src="https://github.com/keephq/keep/raw/main/keep-ui/public/icons/pagerduty-icon.png?raw=true"></a>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/keep-ui/public/icons/opsgenie-icon.png?raw=true"><img width="32" height="32" src="https://github.com/keephq/keep/raw/main/keep-ui/public/icons/opsgenie-icon.png?raw=true"></a>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/keep-ui/public/icons/zenduty-icon.png?raw=true"><img width="32" height="32" src="https://github.com/keephq/keep/raw/main/keep-ui/public/icons/zenduty-icon.png?raw=true"></a>
</p>
<h3 tabindex="-1" dir="auto">Ticketing tools</h3>
<p dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/keep-ui/public/icons/jira-icon.png?raw=true"><img width="32" height="32" src="https://github.com/keephq/keep/raw/main/keep-ui/public/icons/jira-icon.png?raw=true"></a>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/keep-ui/public/icons/trello-icon.png?raw=true"><img width="32" height="32" src="https://github.com/keephq/keep/raw/main/keep-ui/public/icons/trello-icon.png?raw=true"></a>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/keephq/keep/blob/main/keep-ui/public/icons/github-icon.png?raw=true"><img width="32" height="32" src="https://github.com/keephq/keep/raw/main/keep-ui/public/icons/github-icon.png?raw=true"></a>
</p>
<h2 tabindex="-1" dir="auto">Getting Started</h2>
<h3 tabindex="-1" dir="auto">Overview</h3>
<p dir="auto">Keep composed of three main components:</p>
<ol dir="auto">
<li><a href="https://github.com/keephq/keep/tree/main/keep-ui">Keep UI</a> - A NextJS app to connect your providers, centralize alerts and create the workflows.</li>
<li><a href="https://github.com/keephq/keep/tree/main/keep">Keep Backend</a> - A FastAPI server that implements the business logic behind Keep, including integrating with the tools, working with alerts and scheduling and running the workflows.</li>
<li><a href="https://github.com/keephq/keep/blob/main/keep/cli/cli.py">Keep CLI</a> - A CLI that lets you control and manage Keep via CLI.</li>
</ol>
<blockquote>
<p dir="auto"><strong>Disclaimer</strong>: we use <a href="https://posthog.com/faq" rel="nofollow">PostHog</a> to collect anonymous telemetries to better learn how users use Keep (masked screen recordings for CLI commands)
To turn PostHog off, set the <code>DISABLE_POSTHOG</code> environment variable.</p>
</blockquote>
<h3 tabindex="-1" dir="auto">Quickstart</h3>
<h4 tabindex="-1" dir="auto">Spinning up Keep with docker-compose</h4>
<p dir="auto">The easiest way to start with Keep is to run it via docker-compose:</p>
<div dir="auto" data-snippet-clipboard-copy-content="wget -O docker-compose.yml https://raw.githubusercontent.com/keephq/keep/main/docker-compose.yml
docker-compose -f docker-compose.yml up"><pre>wget -O docker-compose.yml https://raw.githubusercontent.com/keephq/keep/main/docker-compose.yml
docker-compose -f docker-compose.yml up</pre></div>
<p dir="auto">The UI is now available at <a href="http://localhost:3000/" rel="nofollow">http://localhost:3000</a> and the backend is available at <a href="http://localhost:8080/" rel="nofollow">http://localhost:8080</a>.</p>
<h4 tabindex="-1" dir="auto">Local development</h4>
<p dir="auto">You can also start Keep within your favorite IDE, e.g. <a href="https://docs.keephq.dev/development/getting-started#vscode" rel="nofollow">VSCode</a></p>
<h4 tabindex="-1" dir="auto">Wanna get Keep up and running in production? Go through our detailed <a href="https://docs.keephq.dev/development" rel="nofollow">development guide</a></h4>
<h2 tabindex="-1" dir="auto">🫵 Keepers</h2>
<p dir="auto">Thank you for contributing and continuously making <b>Keep</b> better, <b>you're awesome</b> 🫶</p>
<a href="https://github.com/keephq/keep/graphs/contributors">
  <img src="https://camo.githubusercontent.com/9aaf66e2a9e49fe5d0f06401a3b0a637e19daecdc36424f934051eae43ec0db8/68747470733a2f2f636f6e747269622e726f636b732f696d6167653f7265706f3d6b65657068712f6b656570" data-canonical-src="https://contrib.rocks/image?repo=keephq/keep">
</a>
</article>
          </div></div>]]></description>
        </item>
    </channel>
</rss>