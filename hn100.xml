(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 11 Jun 2025 05:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[It's the end of observability as we know it (and I feel fine) (109 pts)]]></title>
            <link>https://www.honeycomb.io/blog/its-the-end-of-observability-as-we-know-it-and-i-feel-fine</link>
            <guid>44243050</guid>
            <pubDate>Wed, 11 Jun 2025 00:34:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.honeycomb.io/blog/its-the-end-of-observability-as-we-know-it-and-i-feel-fine">https://www.honeycomb.io/blog/its-the-end-of-observability-as-we-know-it-and-i-feel-fine</a>, See on <a href="https://news.ycombinator.com/item?id=44243050">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<p>In a really broad sense, the history of observability tools over the past couple of decades have been about a pretty simple concept: how do we make terabytes of heterogeneous telemetry data comprehensible to human beings? New Relic did this for the Rails revolution, Datadog did it for the rise of AWS, and Honeycomb led the way for <a href="https://opentelemetry.io/" target="_blank" rel="noreferrer noopener">OpenTelemetry</a>.</p>
<p>The loop has been the same in each case. New abstractions and techniques for software development and deployment gain traction, those abstractions make software more accessible by hiding complexity, and that complexity requires new ways to monitor and measure what’s happening. We build tools like dashboards, adaptive alerting, and dynamic sampling. All of these help us compress the sheer amount of <em>stuff</em> happening into something that’s comprehensible to our human intelligence.</p>
<p>In AI, I see the death of this paradigm. It’s already real, it’s already here, and it’s going to fundamentally change the way we approach systems design and operation in the future.</p>
<div>
<hr>
<div>
<p>New to Honeycomb? Get your <strong>free</strong> account today.</p>

</div>

<hr>
</div>
<h2 id="useful">LLMs are just universal function approximators, but it turns out that those are really useful</h2>
<p>I’m going to tell you&nbsp;a story. It’s about this picture:</p>
<figure><img decoding="async" width="1024" height="808" src="https://www.honeycomb.io/wp-content/uploads/2025/06/image-1024x808.png" alt="LLMs are just universal function approximators, but it turns out that those are really useful" srcset="https://www.honeycomb.io/wp-content/uploads/2025/06/image-1024x808.png 1024w, https://www.honeycomb.io/wp-content/uploads/2025/06/image-768x606.png 768w, https://www.honeycomb.io/wp-content/uploads/2025/06/image-640x505.png 640w, https://www.honeycomb.io/wp-content/uploads/2025/06/image-348x275.png 348w, https://www.honeycomb.io/wp-content/uploads/2025/06/image.png 1460w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
<p>If you’ve ever seen a Honeycomb demo, you’ve probably seen this image. We love it, because it’s not only a great way to show a real-world problem—it’s something that plays well to our core strengths of enabling investigatory loops. Those little peaks you see in the heatmap represent slow requests in a <a href="https://www.honeycomb.io/frontend-observability">frontend</a> service that rise over time before suddenly resetting. They represent a small percentage of your users experiencing poor performance—and we all know what this means in the real world: lost sales, poor experience, and general malaise at the continued enshittification of software.</p>
<p>In a Honeycomb demo, we show you how easy it is to use our UI to understand what those spikes actually mean. You draw a box around them, and we run <a href="https://www.honeycomb.io/bubbleup">BubbleUp</a> to detect anomalies by analyzing the trace data that’s backing this visualization, showing you what’s similar and what’s different between the spikes and the baseline. Eventually, you can drill down to the specific service and even method call that’s causing the problem. It’s a great demo, and it really shows the power of our platform.</p>
<p>Last Friday, I showed a demo at our weekly internal Demo Day. It started with what I just showed you, and then I ran a single prompt through an AI agent that read as follows:</p>
<p><strong>Please investigate the odd latency spikes in the frontend service that happen every four hours or so, and tell me why they’re happening.</strong></p>
<figure><img decoding="async" width="1024" height="366" src="https://www.honeycomb.io/wp-content/uploads/2025/06/image-1-1024x366.png" alt="" srcset="https://www.honeycomb.io/wp-content/uploads/2025/06/image-1-1024x366.png 1024w, https://www.honeycomb.io/wp-content/uploads/2025/06/image-1-768x275.png 768w, https://www.honeycomb.io/wp-content/uploads/2025/06/image-1-1536x549.png 1536w, https://www.honeycomb.io/wp-content/uploads/2025/06/image-1-640x229.png 640w, https://www.honeycomb.io/wp-content/uploads/2025/06/image-1-348x124.png 348w, https://www.honeycomb.io/wp-content/uploads/2025/06/image-1.png 1600w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
<p>The screenshot here elides the remainder of the response from the LLM (please find the entire text at the end of this post), but there’s a few things I want to call out. First, this wasn’t anything too special. The agent was something I wrote myself in a couple of days; it’s just an LLM calling tools in a loop. The model itself is off-the-shelf <a href="https://www.anthropic.com/claude/sonnet" target="_blank" rel="noreferrer noopener">Claude Sonnet 4</a>. The integration with Honeycomb is our new <a href="https://www.honeycomb.io/blog/mcp-easy-as-1-2-3">Model Context Protocol (MCP)</a> server. It took 80 seconds, made eight tool calls, and not only did it tell me why those spikes happened, it figured it out in a pretty similar manner to how we’d tell you to do it with BubbleUp.</p>
<p>This isn’t a contrived example. I basically asked the agent the same question we’d ask you in a demo, and the agent figured it out with no additional prompts, training, or guidance. It effectively zero-shot a real-world scenario.</p>
<p>And it did it for <strong>sixty cents.</strong></p>
<h2 id="youcandoit">If I can do this, so can you. So can anyone.</h2>
<p>I want to be clear, this was perhaps the <em>least </em>optimized version of this workflow. Inference costs are only going down, and we can certainly make our MCP server more efficient. There are ways to reduce the amount of input tokens even more. We can play around with more tailored aggregations and function calls that return LLM-optimized query results. It’s an exciting new era!</p>
<p>It also should serve as a wakeup call to the entire industry. This is a seismic shift in how we should conceptualize observability tooling. <strong>If your product’s value proposition is nice graphs and easy instrumentation, you are </strong><strong><em>le cooked</em></strong><strong>. </strong>An LLM commoditizes the analysis piece, OpenTelemetry commoditizes the instrumentation piece. <strong>The moats are emptying.</strong></p>
<p>I’m not gonna sit here and say this destroys the idea of <a href="https://www.honeycomb.io/blog/ai-where-in-the-loop-should-humans-go">humans being involved in the process</a>, though. I don’t think that’s true. The rise of the cloud didn’t destroy the idea of IT. The existence of Rails doesn’t mean we don’t need server programmers. Productivity increases <em>expand the map</em>. There’ll be more software, of all shapes and sizes. We’re going to need <em>more</em> of everything.</p>
<p>The question, then, is: what does this require from us? Where does observability sit in a world where code is cheap, refactors are cheap, and analysis is a constant factor?</p>
<h2 id="feedback">Fast feedback is the only feedback</h2>
<p>I’m gonna put a marker out there: the only thing that really matters is fast, tight feedback loops at every stage of development and operations. AI thrives on speed—it’ll outrun you every time. To succeed, you need tools that move at the speed of AI as well. The slower your analysis engine, the worse your results. LLMs will generate, test, and discard hypotheses faster than you ever can. They might be wrong a dozen times before they get it right, but again, <em>we’re talking about fractional pennies here</em>.&nbsp;</p>
<p>I don’t see this as a reason to despair, but as something to celebrate. The things that AI-assisted development and operations can lead us to are the things <em>we’ve always been about</em>. Honeycomb’s entire modus operandi is predicated on fast feedback loops, collaborative knowledge sharing, and treating everything as an experiment. We’re built for the future that’s here today, on a platform that allows us to be the best tool for tomorrow.</p>
<p>The exact contours of what this industry looks like in two, five, or ten years are out of my view. I don’t think there’s anyone that can credibly tell you what things will look like. I’m also not really in the business of making predictions. What I can say, though, is that I think we’re going to see a spectrum of AI assistance in development and operational tasks across the entire <a href="https://www.honeycomb.io/blog/honeycomb-fit-software-development-lifecycle">software development lifecycle</a>:</p>
<ul>
<li>AI agents can run passively as you write and deploy code, suggesting fixes to improve code quality based on real-world observations from production.</li>
<li>Emergent system behavior can be detected and addressed by AI, with unattended agents identifying impacts to users, investigating them, compiling reports, and presenting those to human operators for approval and tweaks before making changes.</li>
<li>Bleeding-edge organizations can adopt entirely unattended SWE/SRE roles, powered by tools like Honeycomb and friends, optimizing and writing software to meet business needs and goals.</li>
</ul>
<p>In all of these cases, what matters most is <em>speed</em>. Traditional monitoring and observability tools don’t have what it takes to compete in this world. Pretty dashboards, pre-built alerts, and magic integrations aren’t sufficient for the future we’re building today. Sub-second query performance, unified data storage, and collaborative workflows between humans and AI are the keys to success in the future of observability.</p>
<p>Let’s go do something cool.</p>
<p><em>Addendum:</em> Here’s the full output from the investigation screenshot earlier.</p>
<p><strong>Perfect! Now I have a clear picture of what’s happening. Based on my investigation, I can explain the latency spikes you’re seeing in your frontend service.</strong></p>
<hr>
<p><strong>🔍 Investigation Results: Frontend Latency Spikes</strong></p>
<hr>
<p><strong>Root Cause Identified: Checkout Service Performance Issues</strong></p>
<p>The latency spikes you’re experiencing every ~4 hours are <strong>NOT actually periodic</strong>—this appears to be a <strong>load testing or synthetic traffic pattern</strong> rather than a scheduled system issue. Here’s what I found:</p>
<hr>
<p><strong>📊 Key Findings:</strong></p>
<ol>
<li><strong>Primary Culprit: Checkout Operations</strong><strong><br></strong>
<ul>
<li>/cart/checkout endpoint: <strong>P95 = 3.7 seconds</strong> (vs normal ~500ms)</li>
<li>CheckoutService/PlaceOrder: <strong>P95 = 4.2 seconds</strong><strong><br></strong></li>
<li><strong>Maximum latency observed: 7.6 seconds</strong><strong><br></strong></li>
</ul>
</li>
<li><strong>Spike Pattern Analysis:</strong><strong><br></strong>
<ul>
<li>Spikes are concentrated in <strong>checkout operations only</strong><strong><br></strong></li>
<li>Other endpoints remain relatively stable</li>
<li><strong>485 slow checkout operations</strong> in the last 24 hours</li>
<li>Pattern suggests <strong>load testing or batch checkout processing</strong><strong><br></strong></li>
</ul>
</li>
<li><strong>Downstream Service Impact:</strong><strong><br></strong>
<ul>
<li>CheckoutService/PlaceOrder: <strong>P95 = 4.6 seconds</strong><strong><br></strong></li>
<li>getDiscounts operation: <strong>P95 = 4.2 seconds</strong><strong><br></strong></li>
<li>ShippingService/ShipOrder: <strong>P95 = 4.0 seconds</strong><strong><br></strong></li>
</ul>
</li>
</ol>
<hr>
<p><strong>🕵️ Evidence from Trace Analysis:</strong></p>
<p>Looking at the sample traces, I can see:</p>
<ul>
<li><strong>User Agent Pattern:</strong> python-requests/2.28.2 and python-requests/2.31.0</li>
<li><strong>Consistent Client IPs:</strong> 52.45.250.5 and internal IPs</li>
<li><strong>High Cart Values:</strong> $6,861, $7,036, $259 (suggesting test scenarios)</li>
<li><strong>Same User IDs:</strong> Multiple requests from user 20109 with identical cart totals</li>
</ul>
<hr>
<p><strong>💡 Why This is Happening:</strong></p>
<p><strong>Most Likely Cause: Load Testing or Synthetic Monitoring</strong></p>
<ul>
<li>The pattern suggests <strong>automated testing</strong> rather than real user traffic</li>
<li>Python requests library indicates <strong>scripted traffic</strong><strong><br></strong></li>
<li>High cart values and repeated scenarios point to <strong>test data</strong><strong><br></strong></li>
<li>The “every 4 hours” pattern is likely your <strong>load testing schedule</strong><strong><br></strong></li>
</ul>
<p><strong>Technical Root Cause:</strong></p>
<ul>
<li><strong>Checkout service bottleneck</strong> during high-volume operations</li>
<li><strong>Discount calculation delays</strong> (4.2s P95)</li>
<li><strong>Shipping service delays</strong> during order processing</li>
<li>Possible <strong>database contention</strong> or <strong>external API timeouts</strong><strong><br></strong></li>
</ul>
<hr>
<p><strong>🎯 Recommendations:</strong></p>
<ol>
<li><strong>Immediate Actions:</strong><strong><br></strong>
<ul>
<li><strong>Verify if this is load testing</strong>—check with your testing team</li>
<li><strong>Monitor checkout service resources</strong> during spike periods</li>
<li><strong>Check discount service performance</strong> and external dependencies</li>
</ul>
</li>
<li><strong>Performance Optimization:</strong><strong><br></strong>
<ul>
<li><strong>Optimize discount calculation logic</strong><strong><br></strong></li>
<li><strong>Add caching</strong> for shipping calculations</li>
<li><strong>Implement circuit breakers</strong> for external payment/shipping APIs</li>
<li><strong>Scale checkout service</strong> if this represents real user load</li>
</ul>
</li>
<li><strong>Monitoring Improvements:</strong><strong><br></strong>
<ul>
<li><strong>Separate alerts</strong> for synthetic vs. real user traffic</li>
<li><strong>Add SLI tracking</strong> specifically for checkout operations</li>
<li><strong>Monitor downstream dependencies</strong> (payment, shipping, discount services)</li>
</ul>
</li>
</ol>
<hr>
<p><strong>🚨 Action Items:</strong></p>
<ol>
<li>Confirm if the 4-hour pattern matches your load testing schedule</li>
<li>If it’s real traffic, investigate checkout service capacity and dependencies</li>
<li>Consider implementing checkout-specific performance monitoring and alerting</li>
</ol>
<hr>
<p><strong>The good news is that your other services are performing well—this appears to be an isolated issue with the checkout flow, likely exacerbated by load testing scenarios.</strong></p>
<hr>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Gentle Singularity (140 pts)]]></title>
            <link>https://blog.samaltman.com/the-gentle-singularity</link>
            <guid>44241549</guid>
            <pubDate>Tue, 10 Jun 2025 21:17:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.samaltman.com/the-gentle-singularity">https://blog.samaltman.com/the-gentle-singularity</a>, See on <a href="https://news.ycombinator.com/item?id=44241549">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post_body_2202875"><p>We are past the event horizon; the takeoff has started. Humanity is close to building digital superintelligence, and at least so far it’s much less weird than it seems like it should be.</p><p>Robots are not yet walking the streets, nor are most of us talking to AI all day. People still die of disease, we still can’t easily go to space, and there is a lot about the universe we don’t understand.</p><p>And yet, we have recently built systems that are smarter than people in many ways, and are able to significantly amplify the output of people using them. The least-likely part of the work is behind us; the scientific insights that got us to systems like GPT-4 and o3 were hard-won, but will take us very far.</p><p>AI will contribute to the world in many ways, but the gains to quality of life from AI driving faster scientific progress and increased productivity will be enormous; the future can be vastly better than the present. Scientific progress is the biggest driver of overall progress; it’s hugely exciting to think about how much more we could have.</p><p>In some big sense, ChatGPT is already more powerful than any human who has ever lived. Hundreds of millions of people rely on it every day and for increasingly important tasks; a small new capability can create a hugely positive impact; a small misalignment multiplied by hundreds of millions of people can cause a great deal of negative impact.</p><p>2025 has seen the arrival of agents that can do real cognitive work; writing computer code will never be the same. 2026 will likely see the arrival of systems that can figure out novel insights. 2027 may see the arrival of robots that can do tasks in the real world.</p><p>A lot more people will be able to create software, and art. But the world wants a lot more of both, and experts will probably still be much better than novices, as long as they embrace the new tools. Generally speaking, the ability for one person to get much more done in 2030 than they could in 2020 will be a striking change, and one many people will figure out how to benefit from.</p><p>In the most important ways, the 2030s may not be wildly different. People will still love their families, express their creativity, play games, and swim in lakes.<br></p><p>But in still-very-important-ways, the 2030s are likely going to be wildly different from any time that has come before. We do not know how far beyond human-level intelligence we can go, but we are about to find out.</p><p>In the 2030s, intelligence and energy—ideas, and the ability to make ideas happen—are going to become wildly abundant. These two have been the fundamental limiters on human progress for a long time; with abundant intelligence and energy (and good governance), we can theoretically have anything else.</p><p>Already we live with incredible digital intelligence, and after some initial shock, most of us are pretty used to it. Very quickly we go from being amazed that AI can generate a beautifully-written paragraph to wondering when it can generate a beautifully-written novel; or from being amazed that it can make live-saving medical diagnoses to wondering when it can develop the cures; or from being amazed it can create a small computer program to wondering when it can create an entire new company. This is how the singularity goes: wonders become routine, and then table stakes.</p><p>We already hear from scientists that they are two or three times more productive than they were before AI. Advanced AI is interesting for many reasons, but perhaps nothing is quite as significant as the fact that we can use it to do faster AI research. We may be able to discover new computing substrates, better algorithms, and who knows what else. If we can do a decade’s worth of research in a year, or a month, then the rate of progress will obviously be quite different.</p><p>From here on, the tools we have already built will help us find further scientific insights and aid us in creating better AI systems. Of course this isn’t the same thing as an AI system completely autonomously updating its own code, but nevertheless this is a larval version of recursive self-improvement.</p><p>There are other self-reinforcing loops at play. The economic value creation has started a flywheel of compounding infrastructure buildout to run these increasingly-powerful AI systems. And robots that can build other robots (and in some sense, datacenters that can build other datacenters) aren’t that far off.&nbsp;</p><p>If we have to make the first million humanoid robots the old-fashioned way, but then they can operate the entire supply chain—digging and refining minerals, driving trucks, running factories, etc.—to build more robots, which can build more chip fabrication facilities, data centers, etc, then the rate of progress will obviously be quite different.</p><p>As datacenter production gets automated, the cost of intelligence should eventually converge to near the cost of electricity. (People are often curious about how much energy a ChatGPT query uses; the average query uses about 0.34 watt-hours, about what an oven would use in a little over one second, or a high-efficiency lightbulb would use in a couple of minutes. It also uses about 0.000085 gallons of water; roughly one fifteenth of a teaspoon.)</p><p>The rate of technological progress will keep accelerating, and it will continue to be the case that people are capable of adapting to almost anything. There will be very hard parts like whole classes of jobs going away, but on the other hand the world will be getting so much richer so quickly that we’ll be able to seriously entertain new policy ideas we never could before. We probably won’t adopt a new social contract all at once, but when we look back in a few decades, the gradual changes will have amounted to something big.</p><p>If history is any guide, we will figure out new things to do and new things to want, and assimilate new tools quickly (job change after the industrial revolution is a good recent example). Expectations will go up, but capabilities will go up equally quickly, and we’ll all get better stuff. We will build ever-more-wonderful things for each other. People have a long-term important and curious advantage over AI: we are hard-wired to care about other people and what they think and do, and we don’t care very much about machines.</p><p>A subsistence farmer from a thousand years ago would look at what many of us do and say we have fake jobs, and think that we are just playing games to entertain ourselves since we have plenty of food and unimaginable luxuries. I hope we will look at the jobs a thousand years in the future and think they are very fake jobs, and I have no doubt they will feel incredibly important and satisfying to the people doing them.</p><p>The rate of new wonders being achieved will be immense. It’s hard to even imagine today what we will have discovered by 2035; maybe we will go from solving high-energy physics one year to beginning space colonization the next year; or from a major materials science breakthrough one year to true high-bandwidth brain-computer interfaces the next year. Many people will choose to live their lives in much the same way, but at least some people will probably decide to “plug in”.</p><p>Looking forward, this sounds hard to wrap our heads around. But probably living through it will feel impressive but manageable. From a relativistic perspective, the singularity happens bit by bit, and the merge happens slowly. We are climbing the long arc of exponential technological progress; it always looks vertical looking forward and flat going backwards, but it’s one smooth curve. (Think back to 2020, and what it would have sounded like to have something close to AGI by 2025, versus what the last 5 years have actually been like.)</p><p>There are serious challenges to confront along with the huge upsides. We do need to solve the safety issues, technically and societally, but then it’s critically important to widely distribute access to superintelligence given the economic implications. The best path forward might be something like:</p><ol>
<li><p>Solve the alignment problem, meaning that we can robustly guarantee that we get AI systems to learn and act towards what we collectively really want over the long-term (social media feeds are an example of misaligned AI; the algorithms that power those are incredible at getting you to keep scrolling and clearly understand your short-term preferences, but they do so by exploiting something in your brain that overrides your long-term preference).</p></li>
<li><p>Then focus on making superintelligence cheap, widely available, and not too concentrated with any person, company, or country. Society is resilient, creative, and adapts quickly. If we can harness the collective will and wisdom of people, then although we’ll make plenty of mistakes and some things will go really wrong, we will learn and adapt quickly and be able to use this technology to get maximum upside and minimal downside. Giving users a lot of freedom, within broad bounds society has to decide on, seems very important. The sooner the world can start a conversation about what these broad bounds are and how we define collective alignment, the better.</p></li>
</ol><p>We (the whole industry, not just OpenAI) are building a brain for the world. It will be extremely personalized and easy for everyone to use; we will be limited by good ideas. For a long time, technical people in the startup industry have made fun of “the idea guys”; people who had an idea and were looking for a team to build it. It now looks to me like they are about to have their day in the sun.</p><p>OpenAI is a lot of things now, but before anything else, we are a superintelligence research company. We have a lot of work in front of us, but most of the path in front of us is now lit, and the dark areas are receding fast. We feel extraordinarily grateful to get to do what we do.</p><p>Intelligence too cheap to meter is well within grasp. This may sound crazy to say, but if we told you back in 2020 we were going to be where we are today, it probably sounded more crazy than our current predictions about 2030.</p><p>May we scale smoothly, exponentially and uneventfully through superintelligence.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chatbots are replacing Google's search, devastating traffic for some publishers (142 pts)]]></title>
            <link>https://www.wsj.com/tech/ai/google-ai-news-publishers-7e687141</link>
            <guid>44241407</guid>
            <pubDate>Tue, 10 Jun 2025 21:03:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/tech/ai/google-ai-news-publishers-7e687141">https://www.wsj.com/tech/ai/google-ai-news-publishers-7e687141</a>, See on <a href="https://news.ycombinator.com/item?id=44241407">Hacker News</a></p>
Couldn't get https://www.wsj.com/tech/ai/google-ai-news-publishers-7e687141: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I made a 3D printed VTOL drone (237 pts)]]></title>
            <link>https://www.tsungxu.com/p/i-made-a-3d-printed-vtol-that-can</link>
            <guid>44241278</guid>
            <pubDate>Tue, 10 Jun 2025 20:47:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tsungxu.com/p/i-made-a-3d-printed-vtol-that-can">https://www.tsungxu.com/p/i-made-a-3d-printed-vtol-that-can</a>, See on <a href="https://news.ycombinator.com/item?id=44241278">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div id="youtube2-e7AIKGDrlgs" data-attrs="{&quot;videoId&quot;:&quot;e7AIKGDrlgs&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/e7AIKGDrlgs?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div><p><br><span>I made this 130 mile capable VTOL drone in only 90 days. It can fly for 3 hours on a single charge. That would make it one of the longest range and endurance 3D printed VTOLs in the world.</span></p><p>This is the thing I'm most proud of building to date!</p><p><span>Before this project, I was a total CAD, 3D printing and aerodynamic modeling beginner. I had only </span><a href="https://www.tsungxu.com/p/first-vtol-design-build-and-flight" rel="">built and flown one VTOL before</a><span>. My CAD skills were restricted to extrusions of basic sketches. My Bambu A1 3D printer was only one month old, and I had never tried printing foaming PLA. I had never used any aerodynamic modeling tools to simulate lift-to-drag ratios or stability curves like Cm-alpha.</span></p><p>This video edit ended up shorter than I planned. Being my first Youtube video with significant post production effort, I underestimated the work required to make a longer in-depth video with voiceover, edited footage, etc.</p><p>Because of that, I did not discuss dozens of project challenges like how I chose the design parameters, learnt airframe CAD design, sourced components, improved foaming PLA print quality, in-depth power loss troubleshooting, and many more challenges this project faced.</p><p>If you want more details on my design and build process, let me know!</p><p><em><span>P.S. Reid Hoffman just </span><a href="https://x.com/reidhoffman/status/1932511491506262413" rel="">quote tweeted</a><span> my viral </span><a href="https://x.com/tsungxu/status/1932224925450043845" rel="">video post on X</a><span>:</span></em></p><blockquote><p><em>A century ago, you needed at least a brother and a bicycle shop to pioneer flight. Today, you just need the right toolchain…</em></p></blockquote><p>Incredibly humbling! </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: A “Course” as an MCP Server (121 pts)]]></title>
            <link>https://mastra.ai/course</link>
            <guid>44241202</guid>
            <pubDate>Tue, 10 Jun 2025 20:36:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mastra.ai/course">https://mastra.ai/course</a>, See on <a href="https://news.ycombinator.com/item?id=44241202">Hacker News</a></p>
<div id="readability-page-1" class="page"><div class="page"><nav><div><p><a href="https://mastra.ai/"><img alt="mastra" loading="lazy" width="24" height="23" decoding="async" data-nimg="1" src="https://mastra.ai/logo.svg"></a></p><ul data-open="false"><li><a href="https://mastra.ai/blog">Blog</a></li><li><a href="https://mastra.ai/university">University</a></li><li><a target="_blank" href="https://mastra.ai/docs">Docs</a></li></ul></div></nav><main><div><div><ul><li>Explained by Shane Thomas CPO of Mastra</li><li>Led by an MCP Agent</li><li>3 Lessons and more soon</li><li>12 Hours to compete</li><li>Interactive progress</li></ul><div><p>In this hands-on course, you'll learn to develop and deploy AI agents using Mastra, including how to equip them with tools, memory, and MCP. But here's the twist: you're not just learning about agents, you're learning from one.</p><p>This course is delivered entirely inside your agentic code editor, where your code agent guides you step-by-step, writes code with you, and helps you build real, working agents from the ground up.</p></div></div><div><div><p><span>Begin Mastra 101</span></p><div><p><span>1</span></p><p>Choose your editor and paste the command to install the mcp server automatically</p></div></div><div><p><span></span>Course Outline<span></span></p><div><div><p><span>Build your first agent</span><span><a href="https://youtu.be/buqexw-Xkvk" target="_blank">Watch lesson <!-- -->1<!-- --> intro</a></span></p><div><p>Build and deploy your first AI agent that can read data from external sources, use custom tools, and remember previous interactions. Set up your development environment, test your agent in a live playground, and ship your agent to production. This section covers the basics needed to create a working, memory and tool-enabled agent.</p><div><p>introduction to mastra</p><p>what is mastra</p><p>verifying installation</p></div></div></div><div><p><span>Adding Tools and MCP</span><span><a href="https://youtu.be/J5WVCPKTRxA" target="_blank">Watch lesson <!-- -->2<!-- --> intro</a></span></p><div><p>Add new abilities to your agent by connecting it to external services using MCP servers. Search across MCP registries to easily integrate tools for email, social media, GitHub, news, and local files, without writing any custom code.</p><div><p>introduction to mcp</p><p>installing mcp</p><p>setting up mcp configuration</p></div></div></div><div><p><span>Adding Memory</span><span><a href="https://youtu.be/Io2xtouOsMk" target="_blank">Watch lesson <!-- -->3<!-- --> intro</a></span></p><div><p>Add memory to your agent so it can remember previous conversations, user preferences, and important details. Learn how to configure conversation history, semantic recall, and working memory to create agents that provide more relevant and personalized responses.</p><div><p>understanding memory</p><p>why memory matters</p><p>installing memory</p></div></div></div></div><div><h3 id="faqs"><a href="#faqs">#</a>Faqs</h3></div></div></div></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI o3-pro (155 pts)]]></title>
            <link>https://help.openai.com/en/articles/9624314-model-release-notes</link>
            <guid>44240999</guid>
            <pubDate>Tue, 10 Jun 2025 20:15:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://help.openai.com/en/articles/9624314-model-release-notes">https://help.openai.com/en/articles/9624314-model-release-notes</a>, See on <a href="https://news.ycombinator.com/item?id=44240999">Hacker News</a></p>
Couldn't get https://help.openai.com/en/articles/9624314-model-release-notes: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Launch HN: Vassar Robotics (YC X25) – $219 robot arm that learns new skills (369 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=44240302</link>
            <guid>44240302</guid>
            <pubDate>Tue, 10 Jun 2025 19:12:17 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=44240302">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="44240853"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44240853" href="https://news.ycombinator.com/vote?id=44240853&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div><p>Firstly, at the $219 price point you can have my money already.</p><p>Beyond that, things that appeal to me are basically anything which increase the likelihood I can accomplish high dexterous fine motor control skills, for things like tinkering and DIY assembly.  I think that would include extra wrist DOF and a longer-reach variant.</p><p>Integrated cameras are an interesting idea, but I'd like to be able to swap them out for my own.</p><p>My dream is to have some sort of multi-arm table at home.  I imagine holding a circuit board, small component, soldering iron, and wire with four robotic arms I control with shaky hands from my laptop. :D</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44241222"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44241222" href="https://news.ycombinator.com/vote?id=44241222&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div><p>So true. Every time I solder surface mount components, I always wish I could have a steady hand. Sadly, this arm doesn't have that kind of accuracy. The output shaft of the servos we use has about 1 degree of wiggle room and the mechanical structure adds more.</p><p>To get better accuracy, if sticking with this kind of RC servo, it's basically required to have two servos per joint to preload each other to kill that wiggle room. It's something I've been calculating, but I just can't figure out a way to offer it at a good price.</p><p>Interestingly, for arms that are popular in academia, even when the price goes to $10k (like ARX or Trossen), the wiggle room is still there (better, but still there).</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44241397"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_44241397" href="https://news.ycombinator.com/vote?id=44241397&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div>
                  <p>even something twice the price ($438) would still be a great deal. Mind telling us something about your pricing strategy trade-off consideration matrix?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="44241233"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44241233" href="https://news.ycombinator.com/vote?id=44241233&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div><p>You need some technical specs on the website. How many DOF does it have? Does it have joint angle sensing? If so, what's the resolution? What's the interface to the servos? What's the payload capacity? Does it have integrated motor controllers? How long is it, and what does the dexterous workspace look like?</p><p>As a roboticist, what I'd vote for, in order, is:</p><p>- more degrees of freedom</p><p>- interchangeable tools, either an actual tool changer (unlikely at the price point) or a fixed bolt pattern with electronic passthroughs</p><p>- better joint sensing, e.g. absolute encoders, joint torque sensing</p><p>- fingertip force sensing</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="44240932"><td></td></tr>
                <tr id="44241110"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44241110" href="https://news.ycombinator.com/vote?id=44241110&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div><p>$219 is for the unassembled version
$299 is for the assembled version
$199 is for the first 20 units of the assembled version
$599 was the price before I spent hard hours dealing with supply chains</p><p>When I was just a hobbyist, I had to pay the price on the website. Now that I have some funding to order in large quantities, prices come down a lot. I do the dirty work of sourcing the components so hobbyists don't have to ;)</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="44241060"><td></td></tr>
            <tr id="44241135"><td></td></tr>
                  <tr id="44241446"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44241446" href="https://news.ycombinator.com/vote?id=44241446&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div><p>You should put it on Amazon; we used a robotic arm in one of the classes I taught, and for logistics reasons it was basically the only way we could order stuff. Plus it helps with discovery.</p><p>I'm sure there's an extra fee but it's sometimes just impossible to order things if you're a big organization from small sites like this.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="44240818"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44240818" href="https://news.ycombinator.com/vote?id=44240818&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div><p>Of course this arrives right after I order all the electronic parts and just kicked off the 24+ hour 3D print job to complete my SO-Arm101.</p><p>But I’m routing for you!</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44241328"><td></td></tr>
                  <tr id="44241505"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44241505" href="https://news.ycombinator.com/vote?id=44241505&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div>
                  <p>As another robot hobbyist, I wish there were more detailed documentation on how things work. So many projects online just show a working demo—usually on YouTube—and it's impossible to decipher what’s actually happening, or if the robot is simply following some predefined movements.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="44241571"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44241571" href="https://news.ycombinator.com/vote?id=44241571&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div>
                  <p>I'd be interested to hear about your experience working with suppliers. How did you go about finding suppliers and haggling with them?</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="44241312"><td></td></tr>
            <tr id="44240475"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44240475" href="https://news.ycombinator.com/vote?id=44240475&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div><p>Wow! Recently my son has been asking about doing a project with a robotic arm, and this looks <i>amazing</i>, especially at the hobbyist-friendly price point. And adding in AI is really cool - and just the thing to <i>really</i> grab the attention of an eight year old boy :)  Will these be available in the UK, perchance?</p><p>A bit of an aside, but how hard is it to get into building RC aeroplanes, compared to FPV copter drones?</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44241483"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44241483" href="https://news.ycombinator.com/vote?id=44241483&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div><p>Building RC planes is a little harder IMO, but not much.</p><p>The main difference in building planes is you have to pay attention to center-of-gravity much more; minute differences will make the difference between your plane flying amazingly, like a brick (nose heavy), or not at all (tail heavy). There's also more work to do in setting control linkages and surface throws. But, overall, it's not too tough with most models.</p><p>Takeoff with planes can be very stressful the first few times; you have to choose between ground/runway takeoff, which typically results in a very inefficient model due to landing gear drag and is prone to flipping over, throwing the plane by hand, which requires practice and can be quite hazardous with a "pusher" style plane with the prop at the back, and building some kind of bungee launcher, which you then have to set up and lug around.</p><p>Then you have to decide how to fly - line of sight or FPV. Line of sight flying is quite an acquired skill and has a very steep learning curve - you basically have to learn to "become the plane" and understand how your control stick inputs are affecting the attitude of the plane without being able to see it very well.</p><p>FPV plane flying, while less popular than LOS, is very easy and much more rewarding IMO. The reaction time in all but the most extreme plane stunt flying is much less dramatic than in FPV quads.</p><p>And, due to quirks of the general hobby flight control software scene, most hobby FPV planes have a working loiter-in-a-circle setting while most FPV quads have a barely-functional GPS rescue mode and little to no ability to actually hover (it's very rare for an FPV quad to "just stay put"; this is the realm of camera drones).</p><p>I fly FPV quads when I need a focus/adrenalin boost and FPV planes when I just want to relax and chill. You can fly planes in an adrenalin style, but they're much more conducive to just looking at the scenery and goofing around. Massive bonus points that most plane builds are almost silent compared to an FPV quad so you don't worry about bothering people so much.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="44240847"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44240847" href="https://news.ycombinator.com/vote?id=44240847&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div><p>RC aeroplanes need some practice and a bigger field compared to FPV drones. I think I spent a week flying in simulators and another 2 weeks crashing several times to get a basic hold on it. It's kind of like training a robot foundation model to learn a new embodiment</p><p>That being said, I enjoyed every moment flying my planes. I built and flew quite a few quadcopters but they never felt that free because there's always that control algorithm between the pilot and the motors, while aeroplanes are basically just mapping the movement of the joystick to the servos. I believe the UK has a lot of great local clubs, and I believe that's the best place to get started.</p><p>Side note, when your son gets more experience in the field, he might wanna build his own gas turbine to power his planes. And this association based in UK is the best on this planet: <a href="https://www.gtba.co.uk/" rel="nofollow">https://www.gtba.co.uk</a></p><p>For UK delivery, let me look into how to set up international shipping. Will get back to you by end of the day.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44241137"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_44241137" href="https://news.ycombinator.com/vote?id=44241137&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div>
                  <p>I hadn't thought about clubs, probably because I live in a small, rural Scottish town... but I just had a quick look, and incredibly there's an active club just a few miles from me, which I had no idea even existed!</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="44240802"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44240802" href="https://news.ycombinator.com/vote?id=44240802&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div><p>Planes, like quadcopters, are as complicated or simple as you want them to be. They're available fully ready to fly, as kits with different levels of work needed, or you can build from scratch and choose your own parts and design.</p><p>Flying is pretty different, though. If you're used to a copter that will just stay put when you release the controls, flying planes will be an adjustment.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44240917"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_44240917" href="https://news.ycombinator.com/vote?id=44240917&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div>
                  <p>Yes yes! Flying an aeroplane has no pause button. You are on your own from taking off to landing. It's a great practice not to panic under stress (I never flew one but I guess racing FPV quadcopters probably has the same feeling)</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="44240764"><td></td></tr>
            <tr id="44240729"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44240729" href="https://news.ycombinator.com/vote?id=44240729&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div>
                  <p>Interesting - I was just thinking the other day that a well implemented MCP server driving a robot with access to a camera could be a really interesting project.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="44240749"><td></td></tr>
                  <tr id="44241291"><td></td></tr>
                <tr id="44241303"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44241303" href="https://news.ycombinator.com/vote?id=44241303&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div>
                  <p>if this can be extended to full size doors this could be a very good business, no more need to modify doors to have doggy doors</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="44241353"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_44241353" href="https://news.ycombinator.com/vote?id=44241353&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div>
                  <p>Opening a door is still a challenging problem for robots. Better to have electronic control of doors that can be opened programmatically.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="44241489"><td></td></tr>
            <tr id="44240617"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44240617" href="https://news.ycombinator.com/vote?id=44240617&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div><p>Funny, I was just about to build an SO-101, but tariffs adding $100 to the price of the servos annoyed me.</p><p>How do I buy your kit, please?</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44240661"><td></td></tr>
                  <tr id="44241510"><td></td></tr>
            <tr id="44240814"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44240814" href="https://news.ycombinator.com/vote?id=44240814&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div><p>I wonder if I can strap this to my Roborock from 2020 and train it to pick up socks.</p><p>Roborock sells a new model that does this [1] but it costs $3,000 and I refuse to pay that on principle when I know it's likely a straightforward model with some unsupervised training.</p><p>Also I can probably fix it easier once it (definitely) breaks at some point due to  collisions.</p><p>[1] <a href="https://www.youtube.com/shorts/vHVQxXVgBm4" rel="nofollow">https://www.youtube.com/shorts/vHVQxXVgBm4</a></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="44240723"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44240723" href="https://news.ycombinator.com/vote?id=44240723&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div>
                  <p>I've been looking for a cheap 7 DOF arm. The only reason I haven't bought SO100/101 yet is that it's 6 DOF (and that delivery to Europe is hard to find..)</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="44241186"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44241186" href="https://news.ycombinator.com/vote?id=44241186&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div><p>So cool!</p><p>I would easily pay $1000-$1500 if you put two of these on a wheel base and made it all structurally sound. Extra points if the arms sit at least 1-2 feet of the ground and can reach the ground.</p></div></td></tr>
        </tbody></table></td></tr>
                      <tr id="44240904"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44240904" href="https://news.ycombinator.com/vote?id=44240904&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div><p>I love the idea of a trainable robot arm as a learning device at that price point.</p><p>However, seeing the chess demo instantly makes me think of that horrible tragedy with the robotic arm breaking a kid's finger. How strong is this to be used around kids?</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44241031"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44241031" href="https://news.ycombinator.com/vote?id=44241031&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div><p>Yeah, safety is an important aspect. The good news is that the servos are not that powerful. Peaking at 3 Nm, with a moment arm of 0.2 m, you get 15 N of force, which is basically equivalent to the weight of three 500mL water bottles. This force might cause some scratches but should not lead to serious injuries.</p><p>Initially, I was planning to launch a product using Piper Arms (much more powerful than the current product). But after testing them, I realized they could cause serious injuries if not used properly. So I canceled that version. I still have 8 of them sitting in my office.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="44241074"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44241074" href="https://news.ycombinator.com/vote?id=44241074&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div>
                  <p>Interesting project!  Sorry if I'm out of the loop, but how exactly does the MCP server hand off visual data to an external LLM service to formulate the robot control actions?  It's an interesting concept, but I'm having a hard time wrapping my head around how it works, because I thought MCP was text-oriented.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="44241153"><td></td></tr>
                  <tr id="44240971"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44240971" href="https://news.ycombinator.com/vote?id=44240971&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div>
                  <p>What a unique and fun build! So curious to hear about what ways it can be programmed and used for personal projects.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="44240726"><td></td></tr>
            <tr id="44240610"><td></td></tr>
                <tr id="44240672"><td></td></tr>
                      <tr id="44240643"><td></td></tr>
            <tr id="44240680"><td></td></tr>
                  <tr id="44241272"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44241272" href="https://news.ycombinator.com/vote?id=44241272&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div>
                  <p>As someone who's long dreamed of owning a robotic camera control arm, but who doesn't have a spare $50K kicking around to buy one, I've been following the development of these kinds of projects with great interest. While this particular arm doesn't look like it would have enough payload capacity or smooth enough motion for the use cases I have in mind, the fact its a couple hundred bucks means something that does what I need it to do for an actually affordable price isn't likely too far off.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="44241011"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44241011" href="https://news.ycombinator.com/vote?id=44241011&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div>
                  <p>the website is pretty bad....could use a lot friendlier buttons, layout, more pictures, maybe some videos</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="44240515"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44240515" href="https://news.ycombinator.com/vote?id=44240515&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div>
                  <p>Neat! Does this work with open source models like pi0 and OpenVLA? How does the inference-time teaching you outline work exactly?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="44240649"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44240649" href="https://news.ycombinator.com/vote?id=44240649&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div>
                  <p>The software stack is built around LeRobot. So anything you can run with LeRobot should be able to run with our software. Will do more testing before the official release. Personally, I feel GR00T N1 or ACT is much easier to train and do a fairly good job</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="44241056"><td></td></tr>
                        <tr id="44240480"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44240480" href="https://news.ycombinator.com/vote?id=44240480&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div>
                  <p>Alright, watching the video - I'm sold, even at a sped up rate. How do I buy? I'll do in-town pickup if that's faster!</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="44240779"><td></td></tr>
            <tr id="44240804"><td></td></tr>
            <tr id="44240634"><td></td></tr>
                <tr id="44240811"><td></td></tr>
                <tr id="44240873"><td></td></tr>
                        <tr id="44240584"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44240584" href="https://news.ycombinator.com/vote?id=44240584&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div>
                  <p>How backportable are the upgrades? If I have an SO-101, can I just replace a few parts to mount a camera and use your software?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="44240688"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44240688" href="https://news.ycombinator.com/vote?id=44240688&amp;how=up&amp;goto=item%3Fid%3D44240302"></a></center>    </td><td><br><div>
                  <p>The software is fully compatible with LeRobot's repo. As long as your dataset matches your inference time setup, you are good to go.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="44240507"><td></td></tr>
                <tr id="44240612"><td></td></tr>
                  <tr id="44240455"><td></td></tr>
                <tr id="44240608"><td></td></tr>
                  </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You Can Drive but Not Hide: Detection of Hidden Cellular GPS Vehicle Trackers (117 pts)]]></title>
            <link>https://www.researchgate.net/publication/391704077_You_Can_Drive_But_You_Cannot_Hide_Detection_of_Hidden_Cellular_GPS_Vehicle_Trackers</link>
            <guid>44240286</guid>
            <pubDate>Tue, 10 Jun 2025 19:10:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.researchgate.net/publication/391704077_You_Can_Drive_But_You_Cannot_Hide_Detection_of_Hidden_Cellular_GPS_Vehicle_Trackers">https://www.researchgate.net/publication/391704077_You_Can_Drive_But_You_Cannot_Hide_Detection_of_Hidden_Cellular_GPS_Vehicle_Trackers</a>, See on <a href="https://news.ycombinator.com/item?id=44240286">Hacker News</a></p>
Couldn't get https://www.researchgate.net/publication/391704077_You_Can_Drive_But_You_Cannot_Hide_Detection_of_Hidden_Cellular_GPS_Vehicle_Trackers: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Xeneva Operating System (143 pts)]]></title>
            <link>https://github.com/manaskamal/XenevaOS</link>
            <guid>44240265</guid>
            <pubDate>Tue, 10 Jun 2025 19:08:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/manaskamal/XenevaOS">https://github.com/manaskamal/XenevaOS</a>, See on <a href="https://news.ycombinator.com/item?id=44240265">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">XenevaOS</h2><a id="user-content-xenevaos" aria-label="Permalink: XenevaOS" href="#xenevaos"></a></p>
<p dir="auto"><a href="https://discord.com/invite/YNsY7hhQ" rel="nofollow"><img src="https://camo.githubusercontent.com/29e1042d96fec01530b20f84d184c695e7daf5867cfe3d7ad4cc230e3fca46a9/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f313235353332363537323631373932343631383f6c6162656c3d446973636f7264266c6f676f3d646973636f7264267374796c653d666c6174" alt="Discord" data-canonical-src="https://img.shields.io/discord/1255326572617924618?label=Discord&amp;logo=discord&amp;style=flat"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/manaskamal/XenevaOS/blob/master/XeLogo.jpg?raw=true"><img src="https://github.com/manaskamal/XenevaOS/raw/master/XeLogo.jpg?raw=true" alt="alt text"></a></p>
<p dir="auto">Xeneva is an operating system for both x86_64 and ARM64  architectures, built from the ground up. The Kernel is known as <em>'Aurora'</em>
with hybrid kernel design and the entire operating system is known as <em>'Xeneva'</em>.<br> Please visit <a href="https://github.com/manaskamal/XenevaOS/blob/master/Docs/BuildInstructions.md">Build Instructions</a> to build the project</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<p dir="auto">Refer to <a href="https://github.com/manaskamal/XenevaOS/blob/master/Docs/Introduction.md">Documentations of XenevaOS</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing to the project</h2><a id="user-content-contributing-to-the-project" aria-label="Permalink: Contributing to the project" href="#contributing-to-the-project"></a></p>
<p dir="auto">XenevaOS is an open-source project that welcomes contributions from developers, researchers, and enthusiasts who are passionate about low level system development. Whether you're intereseted in Kernel development, driver development, low level graphics or application level features there are many ways to get involved. We encourage contributions in the form of code, documentation, bug reports, and feature suggestions. If you're interested in contibuting, check out out <a href="https://github.com/manaskamal/XenevaOS/blob/master/Docs/Contributing.md">Contribution Guideline</a>, explore open issues, and join the discussion to help shape the project.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto"><strong>Features</strong> :</h2><a id="user-content-features-" aria-label="Permalink: Features :" href="#features-"></a></p>
<ul dir="auto">
<li>ACPI (through acpica)</li>
<li>x64 and arm64 Kernel</li>
<li>Fully Higher Half Memory with MMIO mappings</li>
<li>Driver <em>loading and linking</em> through dll files</li>
<li>SSE/SSE3</li>
<li>USB3</li>
<li>Intel High Definition Audio</li>
<li>Multiprocessor support (muliprocessor scheduler not ready !!)</li>
<li>Application loader and dynamic library (shared library)</li>
<li>Freetype2 as font rendering engine</li>
<li>Compositing Window Manager called "Deodhai"</li>
<li>Graphics Library known as "Chitralekha"</li>
<li>Xeneva Terminal with basic ANSI/VT100 escape sequence support</li>
<li>Desktop environment called Namdapha Desktop</li>
<li>Storage supports : AHCI/SATA, NVMe</li>
<li>USB3 Class drivers (USB HID Mouse, USB Tablet, USB MSC driver) ..etc</li>
<li>Audio Server called "Deodhai-Audio" with
(44kHz/16bit audio format, stereo/mono panning, gain control)</li>
<li>Networking (IPv4, UDP/IP, TCP/IP, ICMP)</li>
</ul>
<p dir="auto"><em>And many more coming soon</em></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Screenshot:</h2><a id="user-content-screenshot" aria-label="Permalink: Screenshot:" href="#screenshot"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/manaskamal/XenevaOS/blob/master/XenevaV1_1.png?raw=true"><img src="https://github.com/manaskamal/XenevaOS/raw/master/XenevaV1_1.png?raw=true" alt="alt text"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">AppTray:</h2><a id="user-content-apptray" aria-label="Permalink: AppTray:" href="#apptray"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/manaskamal/XenevaOS/blob/master/apptray.png?raw=true"><img src="https://github.com/manaskamal/XenevaOS/raw/master/apptray.png?raw=true" alt="alt text"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installed Applications :</h2><a id="user-content-installed-applications-" aria-label="Permalink: Installed Applications :" href="#installed-applications-"></a></p>
<ul dir="auto">
<li>Audio player called Accent Player</li>
<li>File Browser</li>
<li>Calculator</li>
<li>Xeneva Terminal (ANSI/VT100 support)</li>
<li>XEShell</li>
<li>Audio Server called (DeodhaiAudio)</li>
<li>play (<em>CLI Application</em>)</li>
<li>piano (<em>CLI Application</em>)</li>
<li>Calender</li>
<li>Background Serivices like - Net Manager</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building the project</h2><a id="user-content-building-the-project" aria-label="Permalink: Building the project" href="#building-the-project"></a></p>
<p dir="auto">The project is build purely on Windows Environment. Please Visit <a href="https://github.com/manaskamal/XenevaOS/blob/master/Docs/BuildInstructions.md">Build Instructions page </a> for more information</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contact:</h2><a id="user-content-contact" aria-label="Permalink: Contact:" href="#contact"></a></p>
<p dir="auto">Email: <a href="mailto:manaskamal.kandupur@gmail.com">manaskamal.kandupur@gmail.com</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Android 16 Is Here (233 pts)]]></title>
            <link>https://blog.google/products/android/android-16/</link>
            <guid>44239812</guid>
            <pubDate>Tue, 10 Jun 2025 18:29:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.google/products/android/android-16/">https://blog.google/products/android/android-16/</a>, See on <a href="https://news.ycombinator.com/item?id=44239812">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="jump-content" tabindex="-1">
            

    
    

    <article>

    
    





    

    
      

<div data-analytics-module="{
    &quot;module_name&quot;: &quot;Hero Menu&quot;,
    &quot;section_header&quot;: &quot;Android 16 is here&quot;
  }">
      <div>
          
            <p>Jun 10, 2025</p>
          
          
            <p data-reading-time-render="">[[read-time]] min read</p>
          
        </div>
      
        <p>
          Check out more helpful and streamlined notifications, multitasking tools to keep you in the flow, enhanced support for hearing devices and more.
        </p>
      
    </div>

    

    
      










<div>
    <figure>
      <div>
        <p><img alt="Green sixteen numbers in the middle surrounded by blue, green and orange confetti. The sixteen is framed by visuals of a food order notification, a tablet screen with a multiple windows like a desktop, a notification with text Switch to hearing aid mic?" data-component="uni-progressive-image" fetchpriority="high" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Android_16_blog_header.width-200.format-webp.webp" width="360px" data-sizes="(max-width: 1023px) 100vw,(min-width: 1024px and max-width: 1259) 80vw, 1046px" data-srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Android_16_blog_header.width-800.format-webp.webp 800w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Android_16_blog_header.width-1200.format-webp.webp 1200w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Android_16_blog_header.width-1600.format-webp.webp 1600w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Android_16_blog_header.width-2200.format-webp.webp 2200w">
        </p>
      </div>
      
    </figure>
  </div>






    

    
    <div data-reading-time="true" data-component="uni-article-body">

            
              





<uni-article-speakable page-title="Android 16 is here" listen-to-article="Listen to article" data-date-modified="2025-06-10T18:00:03.192411+00:00" data-tracking-ids="G-HGNBTNCHCQ,G-6NKTLKV14N" data-voice-list="en.ioh-pngnat:Cyan,en.usb-pngnat:Lime" data-script-src="https://www.gstatic.com/readaloud/player/web/api/js/api.js"></uni-article-speakable>

            

            
            
<!--article text-->

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Android 16 is here&quot;
         }"><p data-block-key="eqnb7">Today, we’re bringing you Android 16, rolling out first to supported Pixel devices with more phone brands to come later this year. This is the <a href="https://android-developers.googleblog.com/2024/10/android-sdk-release-update.html">earliest</a> Android has launched a major release in the last few years, which ensures you get the latest updates as soon as possible on your devices.</p><p data-block-key="35du0">Android 16 lays the foundation for our new <a href="https://blog.google/products/android/material-3-expressive-android-wearos-launch/">Material 3 Expressive</a> design, with features that make Android more accessible and easy to use. Let’s take a look at what’s new:</p><h2 data-block-key="fq1jr">Streamlined and up-to-date notifications</h2><p data-block-key="1ueir">Waiting for your food delivery to get to your house? Instead of opening your delivery app every 5 minutes, live updates keep you informed in real-time. These live updates are starting with compatible ride-share and food delivery apps. We’re working together with these app partners to bring this capability to the Android ecosystem, including in Samsung’s Now Bar and OPPO and OnePlus’ Live Alerts.</p></div>
  

  
    






<uni-image-full-width alignment="full" alt-text="Phone screen showing the action of unlocking the phone, tapping on the top left of the screen to open a notification of an Uber Eats update that shows status bar of the order." external-image="" or-mp4-video-title="Live updates" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Live_updates.mp4" section-header="Android 16 is here" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    
  
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Android 16 is here&quot;
         }">
        <p data-block-key="eqnb7">We’re also force-grouping notifications that come from a single app to help reduce information overload. Your notifications will automatically be grouped together to keep things looking tight and organized.</p>
      </div>
  

  
    






<uni-image-full-width alignment="full" alt-text="A rounded corner rectangular notification box with a Google Home icon on the left and the text: Home, now, package seen front door, break, matt seen front door, break, animal seen outside back yard." external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="Android 16 is here" custom-class="image-full-width--constrained-width uni-component-spacing">
  
  
    <p><img alt="A rounded corner rectangular notification box with a Google Home icon on the left and the text: Home, now, package seen front door, break, matt seen front door, break, animal seen outside back yard." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Notifications_grouping.width-100.format-webp.webp" loading="lazy" data-loading="{
            &quot;mobile&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Notifications_grouping.width-500.format-webp.webp&quot;,
            &quot;desktop&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Notifications_grouping.width-1000.format-webp.webp&quot;
          }">
    </p>
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Android 16 is here&quot;
         }"><h2 data-block-key="eqnb7">Clearer, simpler calling with hearing devices</h2><p data-block-key="6vl6c">Android 16 provides significant enhancements for people who use hearing aids
<a data-ga4-analytics-superscript-click="" data-target="inline text" href="#footnote-1" id="footnote-source-1"><sup>1</sup></a>
. Current LE audio hearing devices use their built-in front-facing mics for audio input. Those mics are designed to pick up the sound of the person you're speaking to — not the sound of your voice. Now you can switch to using your phone's microphone for clearer calls in noisy environments.</p></div>
  

  
    






<uni-image-full-width alignment="full" alt-text="Phone screen with an active call with a person with black hair and name angana ghosh. Call duration is shown as 58 seconds. The icon for Anna’s Hearing Aids is lit up and there is a notification at the top of the screen prompting the user to switch to hearing aid mic for hands free calling on the go." external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="Android 16 is here" custom-class="image-full-width--constrained-width uni-component-spacing">
  
  
    <p><img alt="Phone screen with an active call with a person with black hair and name angana ghosh. Call duration is shown as 58 seconds. The icon for Anna’s Hearing Aids is lit up and there is a notification at the top of the screen prompting the user to switch to hearing aid mic for hands free calling on the go." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Change_mic_hearing_devices.width-100.format-webp.webp" loading="lazy" data-loading="{
            &quot;mobile&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Change_mic_hearing_devices.width-500.format-webp.webp&quot;,
            &quot;desktop&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Change_mic_hearing_devices.width-1000.format-webp.webp&quot;
          }">
    </p>
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Android 16 is here&quot;
         }">
        <p data-block-key="eqnb7">We’re also releasing native control for hearing devices in Android 16 for easier access and a more consistent experience. This means you can now control things like volume on your hearing devices right from your Android phone.</p>
      </div>
  

  
    






<uni-image-full-width alignment="full" alt-text="Phone screen showing the window for hearing aids control with the top lit up with Anna’s Hearing Aids Active and settings icon. Below shows different settings including a Preset for All-Around and default microphone for calls. The last section includes Surroundings and a control bar for left and right." external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="Android 16 is here" custom-class="image-full-width--constrained-width uni-component-spacing">
  
  
    <p><img alt="Phone screen showing the window for hearing aids control with the top lit up with Anna’s Hearing Aids Active and settings icon. Below shows different settings including a Preset for All-Around and default microphone for calls. The last section includes Surroundings and a control bar for left and right." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Mic_control_hearing_devices.width-100.format-webp.webp" loading="lazy" data-loading="{
            &quot;mobile&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Mic_control_hearing_devices.width-500.format-webp.webp&quot;,
            &quot;desktop&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Mic_control_hearing_devices.width-1000.format-webp.webp&quot;
          }">
    </p>
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Android 16 is here&quot;
         }"><h2 data-block-key="eqnb7">Stronger security in a single tap</h2><p data-block-key="ci737">With Android 16, you can now activate <a href="https://security.googleblog.com/2025/05/advanced-protection-mobile-devices.html">Advanced Protection</a>
<a data-ga4-analytics-superscript-click="" data-target="inline text" href="#footnote-2" id="footnote-source-2"><sup>2</sup></a>
, Google’s strongest mobile device protection. It enables an array of robust device security features that protect you from online attacks, harmful apps, unsafe websites, scam calls and more. Whether you’re a public figure or you just prioritize security, Advanced Protection gives you greater peace of mind that you’re protected against the most sophisticated attacks.</p></div>
  

  
    






<uni-image-full-width alignment="full" alt-text="A phone screen scrolling through the Advanced Protection page with a list of capabilities that are activated when Device Protection is turned on including Device Safety, Apps, Networks and Web." external-image="" or-mp4-video-title="Advanced Protection" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Advanced_protection.mp4" section-header="Android 16 is here" custom-class="image-full-width--constrained-width uni-component-spacing">
  
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Android 16 is here&quot;
         }"><h2 data-block-key="eqnb7">Enhanced productivity for tablets</h2><p data-block-key="5ospg">Samsung <a href="https://www.samsung.com/us/apps/dex/">DeX</a> has helped maximize productivity on phones, foldables and tablets for years. In Android 16, we worked closely with Samsung to develop desktop windowing, a new way to interact with your apps and content on large-screen devices. In addition to the single app and split-screen modes, you can open, move and resize multiple app windows in a single screen, just like a desktop. This makes it easier to work across apps. Android 16’s desktop windowing will roll out later this year on compatible devices.</p></div>
  

  
    






<uni-image-full-width alignment="full" alt-text="A horizontal tablet screen showing a Chrome web browser window being tapped and pulled into a smaller window, with calendar and email opened as separate windows overlaid like on a desktop." external-image="" or-mp4-video-title="Desktop windowing" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Desktop_windowing.mp4" section-header="Android 16 is here" custom-class="image-full-width--constrained-width uni-component-spacing">
  
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Android 16 is here&quot;
         }">
        <p data-block-key="eqnb7">Later this year, we’re also launching custom keyboard shortcuts, so you can create your own combination of hotkeys, and taskbar overflow, which provides a simple, visual way for you to find the app you need when the taskbar is full. Future updates will also bring even more productivity enhancements to Android, allowing you to connect tablets and phones to an external display for an expanded desktop experience, and <a href="https://android-developers.googleblog.com/2025/06/developer-preview-enhanced-android-desktop-experiences-connected-displays.html">developers can begin testing</a> those features starting today.</p>
      </div>
  

  
    






<uni-image-full-width alignment="full" alt-text="Two tablets side by side. The left tablet shows a window with the ability to customize shortcuts on your system and the right tablet shows multiple windows overlaid, with a bar ar the bottom showing all the different windows." external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="Android 16 is here" custom-class="image-full-width--constrained-width uni-component-spacing">
  
  
    <p><img alt="Two tablets side by side. The left tablet shows a window with the ability to customize shortcuts on your system and the right tablet shows multiple windows overlaid, with a bar ar the bottom showing all the different windows." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Taskbar_and_keyboard.width-100.format-webp.webp" loading="lazy" data-loading="{
            &quot;mobile&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Taskbar_and_keyboard.width-500.format-webp.webp&quot;,
            &quot;desktop&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Taskbar_and_keyboard.width-1000.format-webp.webp&quot;
          }">
    </p>
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;Android 16 is here&quot;
         }"><p data-block-key="eqnb7">There are many more features to explore with Android 16 — like HDR screenshots, adaptive refresh rate, identity check and others — as well as additional updates coming to <a href="https://blog.google/products/android/new-android-features-june-2025/">Android</a> and <a href="https://blog.google/products/pixel/pixel-drop-june-2025/">Pixel</a> devices today. And later this year, more Material 3 Expressive design updates are coming to Android 16 and Wear OS 6 on Pixel devices.</p><p data-block-key="d8sqs">See all the Android 16 features at <a href="http://android.com/16">Android.com/16</a>.</p></div>
  


            
            

            
              




            
          </div>
  </article>
  



  



  



  

  


<div data-component="uni-related-articles" aria-roledescription="carousel" data-analytics-module="{
    &quot;module_name&quot;: &quot;Article Footer Related Stories&quot;,
    &quot;section_header&quot;: &quot;Related stories&quot;
  }">
        <h3>
          <p>
            Related stories
          </p>
        </h3>
      </div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Low-background Steel: content without AI contamination (266 pts)]]></title>
            <link>https://blog.jgc.org/2025/06/low-background-steel-content-without-ai.html</link>
            <guid>44239481</guid>
            <pubDate>Tue, 10 Jun 2025 17:55:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.jgc.org/2025/06/low-background-steel-content-without-ai.html">https://blog.jgc.org/2025/06/low-background-steel-content-without-ai.html</a>, See on <a href="https://news.ycombinator.com/item?id=44239481">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-6718543456445220885" itemprop="description articleBody">
<p>Somehow I forgot to blog my site: <a href="https://lowbackgroundsteel.ai/">https://lowbackgroundsteel.ai/</a>. I created it back in March 2023 as a clearinghouse for online resources that hadn't been contaminated with AI-generated content.&nbsp;</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEijWm8XoAHKZn2-fYIvZZXJFJLv4ASg4T0nmvExAee9kk32vI4V3gln9PpYKQBfJkMsae-fJvuo1A_cRI-ZX6E5i0f92RCHm5MXtZNHZr3ki3f3sX4n9HtlwwZCQVVGWigHYLhTJbz-pZQvRm0O5N6If_LqG6Cw2A9InEtGuBD4-mPqRtdc7NUBMQ/s2370/lbs.jpeg"><img data-original-height="2370" data-original-width="2066" height="640" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEijWm8XoAHKZn2-fYIvZZXJFJLv4ASg4T0nmvExAee9kk32vI4V3gln9PpYKQBfJkMsae-fJvuo1A_cRI-ZX6E5i0f92RCHm5MXtZNHZr3ki3f3sX4n9HtlwwZCQVVGWigHYLhTJbz-pZQvRm0O5N6If_LqG6Cw2A9InEtGuBD4-mPqRtdc7NUBMQ/w558-h640/lbs.jpeg" width="558"></a></p><p><a href="https://en.wikipedia.org/wiki/Low-background_steel">Low-background Steel </a>(and lead) is a type of metal uncontaminated by radioactive isotopes from nuclear testing. That steel and lead is usually recovered from ships that sunk before the Trinity Test in 1945. The site is about uncontaminated content that I'm terming "Low-background Steel". The idea is to point to sources of text, images and video that were created prior to the explosion of AI-generated content that occurred in 2022.</p><p>It currently contains pointers to a Wikipedia dump from prior to the release of ChatGPT, the Arctic Code Vault, Project Gutenberg, and more.</p><p>If you know of other sources of non-contaminated content plus <a href="https://lowbackgroundsteel.ai/submit">submit them</a>!</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI dropped the price of o3 by 80% (354 pts)]]></title>
            <link>https://twitter.com/sama/status/1932434606558462459</link>
            <guid>44239359</guid>
            <pubDate>Tue, 10 Jun 2025 17:41:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/sama/status/1932434606558462459">https://twitter.com/sama/status/1932434606558462459</a>, See on <a href="https://news.ycombinator.com/item?id=44239359">Hacker News</a></p>
Couldn't get https://twitter.com/sama/status/1932434606558462459: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Show HN: Chili3d – A open-source, browser-based 3D CAD application (272 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=44238171</link>
            <guid>44238171</guid>
            <pubDate>Tue, 10 Jun 2025 15:39:57 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=44238171">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="44238171">
      <td><span></span></td>      <td><center><a id="up_44238171" href="https://news.ycombinator.com/vote?id=44238171&amp;how=up&amp;goto=item%3Fid%3D44238171"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=44238171">Show HN: Chili3d – A open-source, browser-based 3D CAD application</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_44238171">112 points</span> by <a href="https://news.ycombinator.com/user?id=xiange">xiange</a> <span title="2025-06-10T15:39:57 1749569997"><a href="https://news.ycombinator.com/item?id=44238171">2 hours ago</a></span> <span id="unv_44238171"></span> | <a href="https://news.ycombinator.com/hide?id=44238171&amp;goto=item%3Fid%3D44238171">hide</a> | <a href="https://hn.algolia.com/?query=Show%20HN%3A%20Chili3d%20%E2%80%93%20A%20open-source%2C%20browser-based%203D%20CAD%20application&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=44238171&amp;auth=0e8832f8414e75ac011f4abd7df1e72081b5cfa3">favorite</a> | <a href="https://news.ycombinator.com/item?id=44238171">24&nbsp;comments</a>        </span>
              </td></tr>
    <tr><td></td></tr><tr><td colspan="2"></td><td><div><p>I'm currently developing Chili3D, an open-source, browser-based 3D CAD application. By compiling OpenCascade to WebAssembly and integrating Three.js, Chili3D delivers near-native performance for powerful online modeling, editing, and rendering—all without local installation. Access it here:</p><p><a href="https://github.com/xiangechen/chili3d">https://github.com/xiangechen/chili3d</a></p><p>Features:</p><p>Modeling Tools: Create basic shapes (boxes, cylinders, cones, etc.), 2D sketches (lines, arcs, circles, etc.), and perform advanced operations (boolean operations, extrusion, revolution, etc.).</p><p>Snapping and Tracking: Precisely snap to geometric features, workplanes, and track axes for accurate alignment.</p><p>Editing Tools: Modify (chamfer, fillet, trim, etc.), transform (move, rotate, mirror), and perform advanced edits (feature removal, sub-shape manipulation).</p><p>Measurement Tools: Measure angles and lengths, and calculate sums of length, area, and volume.</p><p>Document Management: Create, open, and save documents, with full undo/redo history and support for importing/exporting STEP, IGES, BREP formats.</p><p>User Interface: Office-style interface with contextual command organization, hierarchical assembly management, dynamic workplanes, and 3D viewport controls.</p><p>Multi-Language Support: Built-in i18n support with current languages including Chinese and English.</p></div></td></tr>        <tr><td></td></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Malleable software: Restoring user agency in a world of locked-down apps (179 pts)]]></title>
            <link>https://www.inkandswitch.com/essay/malleable-software/</link>
            <guid>44237881</guid>
            <pubDate>Tue, 10 Jun 2025 15:16:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.inkandswitch.com/essay/malleable-software/">https://www.inkandswitch.com/essay/malleable-software/</a>, See on <a href="https://news.ycombinator.com/item?id=44237881">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

<h2 id="motivation"><a href="#motivation">Motivation</a></h2>
<h3 id="we-want-to-adapt-our-environments"><a href="#we-want-to-adapt-our-environments">We want to adapt our environments</a></h3>
<p>Environments matter. To do our best work and live our best lives, we need spaces that let us each express our unique potential.</p>
<p>A guitar maker sets up their workshop with their saws, hammers, chisels and files arranged just so. They can also build new tools as needed to achieve the best result—a wooden block as a support, or a pair of pliers sanded down into the right shape.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/guitar-workshop.jpg" alt="guitar-workshop.jpg"></p>
</figure>
<p>Over the years, a home cook gradually assembles a combination of knives, cutting boards, and pots and pans, finding the ones that work best for them. They can install hooks on the ceiling and move shelves around to support their workflow—whether that’s cooking weekday dinners or hosting elaborate weekend cookouts.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/kitchen.jpg" alt="kitchen.jpg"></p>
</figure>
<p>These are everyday situations. <strong>In the physical world, the act of crafting our environments comes naturally, because physical reality is malleable.</strong></p>
<p>Many small tweaks—taping a post-it note to the wall, rearranging some drawers, moving a piece of furniture—can be done instantly without asking anyone’s permission. We can also take on larger changes that require more effort and skill, like building a workshop or renovating a kitchen. And should we lack those skills ourselves, we can recruit help from craftspeople in our local communities.</p>
<p>When we work and live in a physical space that we control, we tend to evolve it to suit our own needs. As Stewart Brand writes in his book <a href="https://en.wikipedia.org/wiki/How_Buildings_Learn">How Buildings Learn</a>: “Age plus adaptivity is what makes a building come to be loved. The building learns from its occupants, and they learn from it.”</p>
<h3 id="mass-produced-software-is-too-rigid"><a href="#mass-produced-software-is-too-rigid">Mass-produced software is too rigid</a></h3>
<p>These days, we spend more and more of our time in environments built from code, not atoms. We’ve gained many capabilities in this shift—we can collaborate instantly across continents and search thousands of files in an instant. But <strong>we’re also losing something important: the ability to adapt our environments and make them our own.</strong></p>
<p>Here’s an example. One of the authors worked on a software team that tracked its work with index cards taped to a wall. The team would constantly evolve the tracker—tape lines moved; checklists appeared; special zones of cards emerged around the main grid. The fluidity of the tool encouraged fluidity of process.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/wall-board.jpg" alt="wall-board.jpg"></p>
<figcaption>A wall of index cards is a malleable medium for managing software development.</figcaption>
</figure>
<p>Later, the team switched to a web-based issue tracker to support remote collaborators. Now there wasn’t a way to model or display a special zone of cards, so the team abandoned that part of their process.  Further process changes also ground to a halt. Before, new ideas took minutes to try; now they could take hours of wrangling configurations, if they were possible at all. <strong>Computerizing work led to a loss of agency.</strong></p>
<p>The rigidity of software isn’t just a minor inconvenience. It can seriously impede people doing important work. The doctor and writer Atul Gawande <a href="https://www.newyorker.com/magazine/2018/11/12/why-doctors-hate-their-computers">has written about</a> how computerization in the medical profession is leading to record levels of burnout. For instance, doctors would once skip irrelevant fields when filling out paper forms; now the software forces them to fill in those fields, and they have no power to edit those software rules. As Gawande says of one doctor: “Spending the extra time didn’t anger her. The pointlessness of it did.”</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/epic.jpg" alt="epic.jpg"></p>
<figcaption>Inflexible electronic medical records systems are driving doctors to burnout.</figcaption>
</figure>
<p>When you face a situation where software doesn’t meet your needs, you might try giving feedback to the developers—but that usually doesn’t result in immediate action. <strong>When different users have different needs, a centralized development team can’t possibly address everyone’s problems.</strong> And for that matter, when a developer does try to cram too many solutions into a single product, the result is a bloated mess. To avoid this trap, good product teams learn to decline most user requests, leaving a long tail of niche needs unserved.</p>
<p>It may seem inevitable that our specific requirements aren’t served by our software—but that’s only because we’ve taken for granted that software is controlled by centralized development teams. What if we were to shift more control into the hands of users who know their own needs?</p>
<p>Gawande tells a story of a neurosurgeon who worked with an IT analyst to adapt his department’s medical records system. “Before long, they had built a faster, more intuitive interface, designed specifically for neurosurgery office visits.” The requirements were driven by the needs of <em>their specific department</em>, not the needs of every doctor in the country. Beyond the direct productivity benefit, the physicians felt more in control of their tools—an antidote to burnout.</p>
<p>As inspiring as this story is, it’s more the exception than the rule, because <strong>the tools and infrastructure we use to deploy software treat users as passive recipients rather than active co-creators.</strong> Software is organized into monolithic applications rather than flexible remixable toolkits. Customization requires programming skills that most people don’t have—and besides, most software is closed source. Software doesn’t ship to users with the tools to edit the software. App stores are designed for companies distributing software to consumers, not amateurs sharing tools with their friends. This is a system of industrial mass production, not small-scale craft.</p>
<p>To be fair, mass-produced software has delivered many benefits. We can access a vast array of highly polished applications at reasonable prices. Software has made progress in reliability, accessibility, and security. Developers have created business models that can sustainably pay teams to deliver continuously improving software.</p>
<p>But as these stories and countless other examples show, inflexible mass-produced software also gets in the way. The more different you are from the average user, the more the benefits of customization outweigh the benefits of professional polish. Everyone is unique in some way—perhaps you have strong opinions about tools for writing, making music, having discussions, or planning projects. When you have specific needs, agency matters.</p>
<h3 id="our-goal-malleable-software"><a href="#our-goal-malleable-software">Our goal: malleable software</a></h3>
<p>We envision a new kind of computing ecosystem that gives users agency as co-creators. We call this idea malleable software—<strong>a software ecosystem where anyone can adapt their tools to their needs with minimal friction.</strong></p>

<ul>
<li>By “software ecosystem”, we mean the broad technical and cultural environment surrounding software and its users. Malleability isn’t a narrow technical problem.</li>
<li>By “anyone”, we mean that broad accessibility is the goal. And while individual self-sufficiency is useful to cultivate, cooperating with local community is also valuable.</li>
<li>When we say “adapting tools” we include a whole range of customizations, from making small tweaks to existing software, to deep renovations, to creating new tools that work well in coordination with existing ones. Adaptation doesn’t imply starting over from scratch.</li>
<li>Finally, “minimal friction” is key. Editing our tools should be fast. It should feel light. At best, it should be something we can do in the moment when a need arises, so we can get back to the task at hand.</li>
</ul>
<h3 id="existing-approaches"><a href="#existing-approaches">Existing approaches</a></h3>
<p>You may be wondering: what about settings or plugins? There are indeed many techniques for customizing software that deserve to be celebrated. However, they also have limits that prevent them from fully achieving the goals we’ve laid out above.</p>
<h4 id="settings"><a href="#settings">Settings</a></h4>
<p>Settings are a common way to change the way an application behaves. If the right setting exists, you can just toggle a checkbox and move on with your day.</p>
<p>But settings only offer controls that the application developers have thought to expose, leaving you stuck if there’s not a setting that does what you want. Settings also tend to become long lists of disjointed checkboxes without a coherent mental model tying them together.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/settings.png" alt="settings.png"></p>
<figcaption>
<p>Settings allow for certain customizations chosen in advance by an application developer.</p>
</figcaption>
</figure>
<h4 id="plugins"><a href="#plugins">Plugins</a></h4>
<p>One way to scale beyond the bandwidth of a central developer is to allow third-party plugins that extend the behavior of an application. A good plugin system makes it easy for users to get started customizing with a minimum of effort, because they can install plugins that other people have created. A plugin API also has the key benefit of stabilizing the contract between the underlying application and various extensions, helping with ongoing maintenance.</p>
<p>However, <strong>plugin systems still can only edit an app’s behavior in specific authorized ways.</strong> If there’s not a plugin surface available for a given customization, the user is out of luck. (In fact, most applications have no plugin API at all, because it’s hard work to design a good one!)</p>
<p>There are other problems too. Going from installing plugins to <em>making</em> one is a chasm that’s hard to cross. And each app has its own distinct plugin system, making it typically impossible to share plugins across different apps.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/obsidian-plugins.png" alt="obsidian-plugins.png"></p>
<figcaption>The Obsidian Markdown editor offers a rich ecosystem of community plugins for extending the editor's behavior.</figcaption>
</figure>
<h4 id="modding"><a href="#modding">Modding</a></h4>
<p>When settings and official extension APIs don’t go far enough (or aren’t provided in the first place), users can sometimes take control through permissionless <em>modding</em>. For instance, browser extensions can intervene in a website’s user interface and inject new client-side behavior without needing any hooks to be exposed by the original application developer.</p>

<p>Permissionless mods apply in a much broader range of scenarios than officially supported plugin APIs. In fact, they can even be used when the original developer is actively opposed to a given type of extension—ad blockers prioritize the interests of users over the interests of websites.</p>
<p>Mods face their own limitations. They can require tedious reverse-engineering to create. They are often difficult to maintain as the underlying application evolves. Different mods on the same app often don’t work together cleanly.</p>
<p>The limits of the underlying platform can also limit what they’re able to do—for example, <strong>browser extensions can’t modify server-side behavior</strong>, severely limiting the features they can provide. Also, much like other kinds of plugins, unsupported mods have a wide chasm between <em>installing</em> and <em>creating</em>. For instance, to make a browser extension, you need to leave the browser, write code, and distribute a packaged code artifact. (Later on we’ll discuss some strategies to avoid these steps.)</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/extension.png" alt="extension.png"></p>
<figcaption>
    An example of a browser extension serving a niche need: BoA Checklist adds a persistent checkbox next to each transaction on the Bank of America website, to track if you've already reviewed that transaction.
</figcaption>
</figure>
<h4 id="open-source"><a href="#open-source">Open source</a></h4>
<p>The open source software movement promotes the idea of distributing source code so that users of software can own their software, contribute back to it, and if needed create their own version that better meets their own needs. This has been a positive force for the world, and represents an important ingredient for malleability.</p>
<p>But having access to edit the code doesn’t mean minimal friction. <strong>Modifying a serious open source codebase usually requires significant expertise and effort</strong>. This applies even for making a tiny change, like changing the color of a button . Even for a skilled programmer, setting up a development environment and getting acquainted with a codebase represents enough of a hurdle that it’s not casually pursued in the moment.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/pull-requests.png" alt="pull-requests.png"></p>
<figcaption>Users can propose changes to an open source project on GitHub.</figcaption>
</figure>
<h4 id="ai-assisted-coding"><a href="#ai-assisted-coding">AI-assisted coding</a></h4>
<p>Finally, it’s worth addressing a hot topic of the moment. Will AI tools automatically make malleable software a reality?</p>
<p>Historically, one of the biggest puzzles in democratizing the creation of software was figuring out how to enable regular people to write computer programs. Many approaches have been tried: programming languages with friendlier syntax or simpler semantics; programming-by-demonstration macro recording systems; visual live programming environments, and more.</p>
<p>Today, large language models offer a new approach: to take fuzzy ideas expressed in natural language and automatically turn them into code. There is now momentum towards a world where anyone can generate a web application from a chat, without needing any programming experience. There are new examples every day, from a journalist making <a href="https://www.nytimes.com/2025/02/27/technology/personaltech/vibecoding-ai-software-programming.html">an app for generating school lunch ideas</a> to an environmental studies student making <a href="https://www.wsj.com/tech/ai/your-next-favorite-app-the-one-you-make-yourself-a6a84f5f">a website for tracking reforestation efforts</a>. We’ve personally found it useful to build our own software tools with AI, such as a specialized <a href="https://www.geoffreylitt.com/2023/07/25/building-personal-tools-on-the-fly-with-llms">Japanese translation app</a>, and a minimal workout timer with a custom workout plan:</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/claude-workout-artifact.png" alt="claude-workout-artifact.png"></p>
<figcaption>Building a workout timer tool using AI in Claude Artifacts</figcaption>
</figure>
<p>We think these developments hold exciting potential, and represent a good reason to pursue malleable software at this moment. But at the same time, <strong>AI code generation alone does not address all the barriers to malleability.</strong> Even if we presume that every computer user could perfectly write and edit code, that still leaves open some big questions.</p>
<p>How can users tweak the <em>existing</em> tools they’ve installed, rather than just making new siloed applications? How can AI-generated tools compose with one another to build up larger workflows over shared data? And how can we let users take more direct, precise control over tweaking their software, without needing to resort to AI coding for even the tiniest change? None of these questions are addressed by products that generate a cloud-hosted application from a prompt.</p>
<p><strong>Bringing AI coding tools into today’s software ecosystem is like bringing a talented sous chef to a food court.</strong> If you’re used purchasing meals from a menu, a skilled chef can’t do much to help you. Similarly, if you’re using closed-source software from an app store, an AI coding assistant can’t do very much to help you as a user. To fully take advantage of the capabilities of AI, we need to move past the food court to something more like a kitchen—a site of open-ended creation.</p>
<hr>
<p>Reshaping the foundations of computing around user agency is an ambitious goal. Luckily, since the dawn of personal computing, many people have proposed powerful ideas for achieving it.</p>
<p>In the next few sections, we’ll summarize three design patterns that we see as essential for achieving malleable software. These aren’t precise recipes for how to solve the problem. But we believe they are important ways of thinking that are underrepresented in today’s software world and will form part of the solution to achieving malleable software.</p>

<h2 id="a-gentle-slope-from-user-to-creator"><a href="#a-gentle-slope-from-user-to-creator">A gentle slope from user to creator</a></h2>
<p>Malleable software does not imply everybody creating all of their own tools from scratch. That would be a waste of time, since many off-the-shelf tools are already pretty close to serving our needs, with only minor tweaks needed.</p>
<p>A more sensible approach is to start out using existing software tools built by other people or companies, but to have the <em>option</em> of modifying these tools as you discover ways that they don’t meet your needs. You can start out as a passive user, and <em>gradually</em> become an editor and a creator.</p>
<p>In a 1990 paper <a href="https://dl.acm.org/doi/10.1145/97243.97271">User-Tailorable Systems: Pressing the Issues with Buttons</a>, Allan MacLean and his collaborators at EuroPARC propose a powerful mental model for designing software systems that invite users to gradually become creators.</p>
<p>Consider this chart where the x-axis represents the power or depth of a customization, and the y-axis represents the level of skill required to perform that customization. In this model, whenever someone needs to suddenly learn a lot more in order to achieve the next level of depth of customization, that appear as a vertical “cliff”.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/maclean-cliffs.png" alt="maclean-cliffs.png"></p>
<figcaption>Going from changing settings to full programming is a sharp "cliff" that's hard to scale. (figure from MacLean et al)</figcaption>
</figure>
<p>To flatten out the cliffs and encourage smooth progress, MacLean et al. proposed a design goal: <strong>each incremental increase in tailoring power should only require a small incremental investment of learning and skill.</strong> A system that follows this rule can be visualized as having a “gentle slope” free of cliffs.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/maclean-slope.png" alt="maclean-slope.png"></p>
<figcaption>A gentle slope of tailorability, made up of many different customization techniques. (figure from MacLean et al)</figcaption>
</figure>
<p>The researchers demonstrated this principle in an automation system called Buttons. To start out, users could move buttons around and change the text or color. Slightly further up the slope, users could edit variable values or use a toolkit to create simple UIs. Finally, at the top of the slope, users could create new behaviors by doing Lisp programming. The key point was that <strong>each customization could be done with the simplest technique possible, leaving full programming only as a last resort when absolutely needed.</strong></p>

<p>Many successful environments for end-user malleability employ the gentle slope pattern. Consider spreadsheets as an example. When someone sends you a complex spreadsheet, you can start by just viewing it, or editing a cell marked as an input. Next you might try changing some formatting or add some labels. As you get deeper into using the spreadsheet, you might start tweaking formulas or adding your own new cells. A spreadsheet can start out feeling like an “application”—an artifact that someone else put together, with a few knobs intended for you to control—but unlike an application, you can smoothly progress to deeper customizations.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/spreadsheet-slope.png" alt="spreadsheet-slope.png"></p>
<figcaption>Spreadsheets offer a gentle slope of customization, from use to deeper modification.</figcaption>
</figure>
<p>Spreadsheets show us a couple useful qualities for achieving a gentle slope. First, It has an <a href="https://www.inkandswitch.com/end-user-programming/#in-place-toolchain">in-place toolchain</a>: everyone using a spreadsheet is running the full editor. When you want to dive deeper into modifying a spreadsheet, there’s no need to install or open a separate development environment.</p>
<p>Also, spreadsheets often have a scrappy aesthetic. It can <em>feel</em> safer to change a spreadsheet, compared to the pixel-perfect polish of a professionally designed application.</p>

<p>Another way to achieve a gentle slope is through explicit modes. HyperCard, a Mac program from the 1980s in which users could create stacks of “cards”, offered “levels” which governed what actions were available to the user at any time.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/hypercard-levels.png" alt="hypercard-levels.png"></p>
<figcaption>In HyperCard, users could select a "level" to restrict their editing capabilities.</figcaption>
</figure>
<p>Level 1 was read-only; Levels 2 and 3 supported text and graphical editing with direct manipulation interactions; Level 4 added creating buttons and linking things together; Level 5 unlocked full programming using a scripting language called HyperTalk. These explicit modes served as guardrails, allowing users to safely explore without unintended consequences.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/hypercard-slope.png" alt="hypercard-slope.png"></p>
<figcaption>Each level in HyperCard represents a modest step up in power and skill.</figcaption>
</figure>
<p>Finally, let’s see what it looks like to smooth out a cliff. As we discussed earlier, there’s a big chasm from installing a browser extension to building one yourself.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/browser-extension-cliff.png" alt="browser-extension-cliff.png"></p>
<figcaption>Going from installing a browser extension to making one is a steep cliff. It requires leaving the browser and doing involved programming.</figcaption>
</figure>
<p>We can achieve a much smoother slope if we incorporate lighter weight techniques for customizing websites. Tools like <a href="https://userstyles.org/">Stylish</a> and <a href="https://resources.arc.net/hc/en-us/articles/19212718608151-Boosts-Customize-Any-Website">Arc Boosts</a> let users create and share custom styling themes from within the browser. Further up the curve, <a href="https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=7eb0bba253a1d494544a15c3df921dd5a8f2401f">macro systems</a> and let users record and replay actions taken on websites. And if the user knows a little bit of JavaScript, they can tweak user scripts written in <a href="https://www.tampermonkey.net/">Tampermonkey</a> directly in the browser.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/arc-styles.png" alt="arc-styles.png"></p>
<figcaption>Arc Boosts lets users restyle a website with direct manipulation interactions from directly within the browser.</figcaption>
</figure>
<p>Each of these techniques gives a different tradeoff between power and skill. If someone just wants to tweak a color on a website, they should be able to do it in a less expressive system focused on that task, rather than needing to build an entire browser extension. With these techniques, we can smooth out the slope:</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/browser-extension-steady-slope.png" alt="browser-extension-steady-slope.png"></p>
<figcaption>Web customization techniques provide a gentler slope before needing to create a browser extension.</figcaption>
</figure>
<p>There are two ways to make a slope gentler. One way is to start from the right side of the diagram and reduce the required skill. This strategy corresponds to a huge variety of work which starts with the full expressiveness of programming and makes it more approachable—with <a href="https://developer.apple.com/library/archive/documentation/AppleScript/Conceptual/AppleScriptLangGuide/reference/ASLR_cmds.html">friendlier syntax</a>, <a href="https://liveprog.org/">live programming environments</a>, <a href="https://support.microsoft.com/en-us/office/using-flash-fill-in-excel-3f9bcf1e-db93-4890-94a0-1578341f73f7">inferring programs from examples</a>, <a href="https://hedy.org/">gradual scaffolding</a> and more.</p>
<p>However, there’s another strategy that’s just as important, and sometimes overlooked: starting from the left side of the diagram and gradually offering more power. Many successful customizable systems such as spreadsheets, HyperCard, Flash, Notion, and Airtable follow a similar pattern: <strong>a media editor with optional programmability.</strong>  When an environment offers document editing with familiar direct manipulation interactions, users can get a lot done without needing to write any code.</p>
<p>One final note: <strong>not everyone needs to reach the top of the slope.</strong> At some point, many amateurs will enlist help from others in order to save time and energy, or to avoid having to learn the necessary skills. The key is that many customizations are accessible to amateurs, with reasonable incremental investments of learning and skill. A gentle slope also supports smoother collaboration between people of different skill levels. We’ll explore this point more later on when we discuss the importance of communal creation.</p>

<p>So far we’ve focused on the rigidity of individual applications. But there’s another reason that it’s hard to adapt software to meet our needs: the very idea of “applications”. Because we’re so accustomed to this idea, it can be hard to see the nature of the problem—so let’s consider an analogy from the kitchen.</p>
<h3 id="apps-are-avocado-slicers"><a href="#apps-are-avocado-slicers">Apps are avocado slicers</a></h3>
<p>One way to slice an avocado is to use an “avocado slicer”: a 3-in-1 gadget that combines a dull plastic knife for slicing the avocado in half, a circular grabber for extracting the pit, and a line of plastic rods that produce 7 slices at once.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/avocado-slicer.jpg" alt="avocado-slicer.jpg"></p>
<figcaption>An avocado slicer is specialized to one use case.</figcaption>
</figure>
<p>Anyone can use an avocado slicer with no practice, and it poses no safety risk. And yet, because the avocado slicer is narrowly focused on one task, it’s useless at anything else. If you used a specialized gadget for every single task, you’d end up with a mountain of plastic.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/kitchen-gadgets.jpg" alt="kitchen-gadgets.jpg"></p>
<figcaption>
There are specialized gadgets available for an enormous variety of tasks, from stripping corn to cutting lettuce.
</figcaption>
</figure>
<p>Another approach is to use a knife. A knife can handle all the steps of slicing an avocado, and much more: it can slice a chicken breast, dice an onion, or smash a garlic clove.  You do need to learn how to handle the knife safely and skillfully, but it’s worth the effort, because <strong>a knife is a general tool.</strong></p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/knife.jpg" alt="knife.jpg"></p>
<figcaption>A knife can cut an avocado, and much more.</figcaption>
</figure>
<p>How does this analogy apply to software? <strong>Many applications are avocado slicers.</strong> They’re a bundle of functionality targeted at some specific use case: planning a trip, tracking workouts, organizing recipes. Because an app needs to handle many tasks associated with a use case, it sometimes doesn’t handle any of them particularly well. You may have come across situations where an app is missing some functionality that’s important to you, while simultaneously including extra bits you don’t need.</p>

<p>On top of that, solving a larger task using multiple applications often requires manual coordination. We can put windows next to each other and copy-paste data, but not much more. If we want more knife-like software tools, we’ll need better ways for smaller software tools to work together.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/travel-apps.png" alt="travel-apps.png"></p>
<figcaption>Planning a vacation requires manually coordinating across many isolated applications.</figcaption>
</figure>
<p>This isn’t to say that the application model has no benefits. Users get a cohesive experience within the bounds of an application, since the developer can finetune it without worrying about interoperating with other tools. Siloing data by application is a convenient answer to some security and privacy concerns. Paying for an application (and support) is a reasonable billing model. These are important benefits which can’t be ignored.</p>
<p>But when you’re trying to solve a complex problem or construct a creative workflow spanning multiple applications, the isolation between applications can cause serious problems. <strong>How might we reorient software around more general, composable tools</strong>—that feels more like a knife and less like an avocado slicer? There are two sub-problems to address: sharing data between tools, and combining tools within the user interface.</p>

<h3 id="sharing-data-between-tools"><a href="#sharing-data-between-tools">Sharing data between tools</a></h3>
<p>If we’re going to use different software tools together in coordination to get a job done, it’s essential that those tools can operate on one shared reality.</p>
<p>In modern cloud and mobile platforms, each application manages its own data in a private silo. The plan for the trip lives across a notes app, a Google Maps list, a calendar. This fragmentation impedes malleability. <strong>When each application manages its own data, introducing a new tool into a workflow incurs more friction</strong>. It’s easier to stay within an existing application to complete the whole job, even if superior alternatives exist for completing some part of the task.</p>
<p>When data is instead shared among applications, it empowers end users to compose tools in more flexible ways. One well-known example is the desktop filesystem. When information is stored in files, <strong>you can edit the same file in different tools have that focus on different subtasks</strong>. You can edit the light levels on a photograph in Lightroom, and then use Apple Preview to scribble a note on the photo. <strong>Different collaborators can also use their preferred tools</strong>—one user can edit a code repository in VSCode while collaborating with a coworker who edits it in emacs.</p>

<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/files.png" alt="files.png"></p>
<figcaption>Files serve as a common ground between different tools.</figcaption>
</figure>
<p>Another example of tools operating on shared data is low-code database application builders—including desktop-based applications like Microsoft Access and Filemaker Pro, and cloud-based applications like Airtable and Notion. These environments support end-users in building multiple views of the same database. For example, Airtable comes with with general tools such as a grid table editor, a board of cards, and a calendar. It also offers tools for adding custom UIs, but those are only needed in specialized cases, since many tasks can be achieved in the general grid editor.</p>
<figure>

<figcaption>Editing the same data with multiple views in Airtable, with live reactivity</figcaption>
</figure>
<p><strong>The idea of shared data also extends to shared objects with behavior.</strong> In <a href="https://en.wikipedia.org/wiki/Smalltalk">Smalltalk</a>, a user works with an <em>image</em>: a repository of objects representing not only persisted state, but also code associated with that state. Because everything in the system is represented as objects, it’s possible to introduce new tools that operate on those existing objects—including calling methods to invoke behavior.</p>

<p>Finally, <strong>realtime collaboration over shared data enables different people to work live in different tools.</strong> One example of this is in <a href="https://webstrates.net/">Webstrates</a>, a malleable software platform for collaboration in the browser. In Webstrates, tools run by different users can collaboratively edit the contents of a shared, synchronized dataset stored in the browser’s DOM. As a result, two users can each use their preferred editor to work on the same research paper together, with one of them using a WYSIWYG editor and the other using a plain text interface.</p>
<figure>

<figcaption>The same paper being edited realtime in two different editors, in Webstrates</figcaption>
</figure>
<h3 id="composing-the-user-interface"><a href="#composing-the-user-interface">Composing the user interface</a></h3>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/pegboard.jpg" alt="pegboard.jpg"></p>
</figure>
<p>Tools need to share not only underlying data, but a workspace where they can be used together.</p>
<p>The app paradigm isn’t set up for this. An application takes control over a window or tab and builds a world inside of it. This has advantages – an application’s creator can carefully craft your experience in this world and make sure everything works together just right. But it means that <strong>using multiple applications together requires flipping between isolated user experiences.</strong> It’s as though you have to carry ingredients from one kitchen to another every time you want to use a new tool. Even if data interoperates, your experience is splintered.</p>
<p>How can we break up not just an application’s ownership of data, but its control of the interactive environment? Earlier, we discussed approaches like plugins and permissionless modding, which crack open seams to extend applications from within. These are great, but if we want a world where we work with “tools, not apps”, we need something a little different – environments where tools can be brought together and used in a shared space.</p>
<p>One set of ideas comes from <strong>compound-document systems</strong>, like <a href="https://archive.org/details/OpenDocProgrammersGuide">OpenDoc</a> and <a href="https://en.wikipedia.org/wiki/Object_Linking_and_Embedding">OLE</a>. These let authors compose documents out of multiple kinds of media embedded in each other. For instance, a text document might host an embedded diagram, which can in turn host a table of data. Selecting one of these parts opens up an editor in-place, with no flipping back and forth between windows or digging through the file system required. These systems are open-ended; developers can introduce new kinds of media, as well as new, alternative editors for existing media types.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/opendoc.png" alt=""></p>
<figcaption>OpenDoc documents are made of "parts" that are edited with different editors, but stored together in a unified document.</figcaption>
</figure>
<p>Splitting up the UI into smaller pieces raises new design challenges. How do users choose which editors to use for each part of a document? How can a user share a document and guarantee that others will have all the necessary sub-editors available? How do global interactions like selection and focus work across editors? Systems like OpenDoc developed answers to these questions which are worth studying, although the nature of modern collaborative and web-based applications have also changed the surrounding context.</p>
<p>Sometimes, embedding editors for parts of a document is not enough. Consider this example from Tchernavskij’s <a href="https://theses.hal.science/tel-02612943v1">Designing and programming malleable software</a>: <strong>how might a user reuse a color picker from one app inside of another app?</strong> Unlike a diagram editor, a color picker is not associated with just one part of a document; it’s a tool that interacts with objects <em>throughout</em> the document. In order to do its job, the color picker somehow needs to be aware of other objects and have the ability to edit their colors. Usually, user interfaces hardcode these kinds of connections, but to allow extension or reuse, we need a more flexible and open-ended approach</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/color-picker.png" alt="color-picker.png"></p>
<figcaption>
<p>A challenge problem from <a href="https://theses.hal.science/tel-02612943v1">Designing and programming malleable software</a>: reusing a color picker from one application in another.</p>
</figcaption>
</figure>
<p>To solve this, Tchernavskij proposes <em>entanglers</em>: a dedicated layer of the UI system that dynamically detects and connects related UI elements. Another research project, <a href="https://vis.csail.mit.edu/pubs/varv/">Varv</a>, solves the problem by specifying behavior with lists of event triggers which can be additively grown. While the details of these approaches differ, the common element is representing connections between parts of the UI in such a way that supports later extension.</p>
<p>A more radical approach to UI composition is to use the physical world as a foundation for composability, as seen in <a href="https://dynamicland.org/">Dynamicland</a>. Programs at Dynamicland are built as collections of physical objects (like pieces of paper) that can carry code and data and act as handles for interaction. At Dynamicland, you can compose user interfaces by bringing them near each other on a table and taping or gluing them together. Programs can also use relationships in space, like pointing and proximity, to create virtual connections between objects. While screen-based systems can’t directly emulate Dynamicland’s use of the physical world, they may still be able to take some lessons from the value of having a consistent materiality and physics.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/spatial-relationships.jpg" alt="spatial-relationships.jpg"></p>
<figcaption>
<p>Pieces of paper running programs at Dynamicland, assembled on a table, sending out green “whiskers” to define their connections.</p>
</figcaption>
</figure>
<p>Dynamicland also derives much of its composability from how it breaks up programs into small objects that work together. Communication between these objects happens through a global database. As a result, it’s possible to add new tools into the system that intercept messages between existing objects, modifing the behavior of existing tools. When a system doesn’t assume up front that certain connections exist between senders and receivers of information, it’s easier to additively extend the system with new uses of that information.</p>

<h2 id="communal-creation"><a href="#communal-creation">Communal creation</a></h2>
<p>While it’s exciting to imagine every person crafting their own unique computing experience, an individualistic view of malleable software will only get you so far.</p>
<p>Sure, individuals should be able to adapt their software to their needs in small ways in the moment, climbing up a “gentle slope from use to creation”. But as the changes they want to make get larger, software is going to take more time and skills to make. If everyone were forced to make these changes just for themselves, as one-offs, the benefits would probably not be worth the costs. Not everyone wants to be a software-making expert.</p>
<p>And there’s an even more fundamental reason to think of malleability through a communal lens: we use computers together! A product team needs a single system for tracking projects. A department at a hospital needs a single system for patient intake forms. These communities are certainly not well-served by one-size-fits-all applications they have no control over. But the solution can’t be every-user-for-themselves either. We should help communities build and maintain <em>shared</em> solutions to their problems.</p>

<p><strong>With the right infrastructure, we can work together to craft our software.</strong> People with similar needs around the world can exchange work and build collaboratively, as we have seen happen in free-software communities. And local communities, from companies to families to civic organizations, can build and maintain software suited to their local needs. When local needs get higher up the “slope” and call for special levels of skill and enthusiasm, you don’t need everyone in a community to attain these levels – just enough people to play that role and get the job done.</p>

<p><strong>Building software for “local” contexts is sometimes <em>easier</em> than building software for world-wide use.</strong> You don’t need to build airtight, industrial-grade software if you are in direct contact with your users and can be responsive to the situations they run into. You don’t need to anticipate everyone’s needs in your design, just your community’s. Clay Shirky termed this pattern <a href="https://gwern.net/doc/technology/2004-03-30-shirky-situatedsoftware.html">“situated software”</a>, describing how his students were able to rapidly build software for their communities by “taking advantage of social infrastructure or context-sensitive information”. On an even more intimate level, Robin Sloan memorably described how an app built for his family could be a <a href="https://www.robinsloan.com/notes/home-cooked-app/">“home-cooked meal”</a>.</p>
<p>For all these reasons, we believe that <em>technical</em> infrastructures for  malleable software will need to support <em>sociotechnical</em> systems of people working together, across many levels, to make software work for themselves and their communities.</p>
<p>The history of free software offers lessons on how sociotechnical systems like this can be constructed. We are especially inspired by situations where free-software communities don’t assume there should only be one centrally-controlled version of an application in the world. For instance, Mastodon instances run by small communities often <a href="https://runyourown.social/">edit Mastodon’s code</a> to implement community-specific features and policies. Of course, situations like this still require serious engineering work, and are still operating on apps. As we move towards a world with gentler slopes into software modification, and more tools rather than apps, we’ll need to figure out how smaller pieces of code can be shared and collaboratively developed, and how interoperability can be maintained in a world of pluralistic software.</p>
<h2 id="ink-switch-prototypes"><a href="#ink-switch-prototypes">Ink &amp; Switch prototypes</a></h2>
<p>At Ink &amp; Switch, we’ve spent several years building research prototypes that explore different aspects of malleable software. These projects aren’t commercial products. Rather, the goal of each prototype has been to develop our understanding of techniques for enabling malleability, and then to learn from deep usage of those prototypes. (In fact, we wrote this very essay in a homegrown malleable software environment, and will share some of our successes and failures from that experience.)</p>

<p>Our work has spanned the entire computing stack, and can be roughly grouped into two threads. One thread has explored <strong>foundational infrastructure</strong>—techniques for storing data, loading code, and defining user interfaces, in a way that supports malleable experiences being built on top. Higher up the stack, another thread of work has focused on a particular kind of user experience:  <strong>dynamic documents</strong> where static media can be gradually enriched with interactive behavior. Let’s cover each in turn.</p>
<h3 id="infrastructure-for-malleability"><a href="#infrastructure-for-malleability">Infrastructure for malleability</a></h3>
<p>We’ve discussed how most of the <em>infrastructure</em> used to run and develop software today is designed without malleability as a priority. We’ve also shown some inspirations for reorienting around malleability. The desktop filesystem enables shared data between tools. Smalltalk, Hypercard, and spreadsheets enable live modification by allowing code editing at runtime. Browser-based apps encoding their UIs using the DOM enables permissionless modding through extensions.</p>
<p>Inspired by these predecessors, <strong>we have been prototyping an infrastructure stack for building, running, and sharing software that prioritizes malleability.</strong> Our approach builds on another area of our research: <a href="https://www.inkandswitch.com/essay/local-first/">local-first software</a>, which is a philosophy that prioritizes giving users ownership and control over their data, while maintaining the ability to collaborate with others. As part of that work, we developed a collaboration library called <a href="https://automerge.org/">Automerge</a>, which persists and synchronizes JSON documents among users.</p>

<h4 id="pushpin-an-extensible-media-canvas"><a href="#pushpin-an-extensible-media-canvas">PushPin: an extensible media canvas</a></h4>
<p>To start figuring out how a local-first foundation could enable malleability, we prototyped <a href="https://www.inkandswitch.com/pushpin">PushPin</a>, a web-based collaborative media canvas. A key idea we developed in that project was “document functional reactive programming” (DFRP): representing a tool as a UI component authored in React, backed by a JSON document that was automatically persisted and synchronized through Automerge.</p>
<p>DFRP made it less work to extend the interface than in traditional applications, since we could just add a UI component without worrying about backend databases or REST APIs. Furthermore, the decoupling of data and UI made it straightforward to define new user interfaces for <em>existing documents</em>—since we could define a new component and then register it as an alternate editor.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/pushpin.jpg" alt="pushpin.jpg"></p>
<figcaption>A PushPin board with embedded cards, each implemented as a React component backed by its own synced Automerge document</figcaption>
</figure>
<p>PushPin also showcased several challenges. First: how do you choose which UI to use to show a document in a given context?  We tried a simple model based on hardcoded contexts—“show a compact view when rendering the document as a card on a board; show an expanded view when rendering as the main content”—but this approach wasn’t sufficient for all our needs. For one thing, it didn’t allow users to choose among views depending on their task.</p>
<p>We also found that an embedding model needs to balance isolation and coordination. We used a restrictive model in which components can embed one another but no further communication was allowed. While this strong isolation made it easy to reason about behavior within a given component, there was no easy way for UI components to share context like hover states, which prevented certain rich user experiences. And permissionless modding wasn’t well supported either, since there was no mechanism to reach into an existing component. These questions of dispatching views and coordinating across components remain open areas of exploration for us.</p>
<h4 id="cambria-mediating-schema-compatibility-across-tools"><a href="#cambria-mediating-schema-compatibility-across-tools">Cambria: mediating schema compatibility across tools</a></h4>
<p>Schema compatibility was a point of frustration using PushPin. Upgrading tools would frequently break compatibility with existing data. And it was difficult to make different tools interoperate if they couldn’t agree exactly on the format of their underlying JSON data. This is an instance of a broader class of challenges—how should tools cooperate if they can’t agree on the shape of their data? In a malleable environment, we can’t rely on a central authority to dictate the schema.</p>
<p>We prototyped a system called <a href="https://www.inkandswitch.com/cambria/">Cambria</a> which solves this challenge by decoupling write schemas from read schemas. Updates are written by each tool in its preferred schema, and then interpreted on demand in other schemas—which could include newer/older versions of the schema, as well as entirely different schemas used by other tools. These are not one-time data migrations; they are ongoing live translations, preserving the ability to write and read from any schema simultaneously.</p>
<p>Based on some limited testing of the Cambria prototype, we believe live data translations are a promising direction for supporting pluralistic schemas. However, we have not yet built a production-ready version of this system that integrates with Automerge; one challenge is that it may require deep integration with the underlying data engine.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/lens-graph.png" alt="lens-graph.png"></p>
<figcaption>
<p>Cambria supports translating data between tools live on demand, through a graph of transformations called <em>lenses</em>.</p>
</figcaption>
</figure>
<h4 id="farm-code-is-data"><a href="#farm-code-is-data">Farm: code is data</a></h4>
<p>Although PushPin lowered the bar to contributing new tools to the environment, the system wasn’t editable at runtime—the code was stored in a GitHub repository, and deployed through a standard web application pipeline. Thus, in our next project, we experimented with enabling fluid modifications by <strong>using the local-first data layer to host not just user data, but also the code for the system itself.</strong> We built a system called <a href="https://github.com/inkandswitch/farm">Farm</a> which allowed users to author tools in the Elm language, with the source code stored and synced in Automerge documents.</p>

<p>At a basic level, treating code as data streamlined the sharing of tools. However, many aspects of collaboration proved challenging. How could you work on a tool without breaking it for other people as you edited it? And how could multiple collaborators work on different aspects of the same tool in parallel? This set of challenges led us to our next project.</p>
<h4 id="patchwork-version-control-bootstrapping"><a href="#patchwork-version-control-bootstrapping">Patchwork: version control + bootstrapping</a></h4>
<p>Enabling exploration and divergence lies at the heart of malleability. Different users need the freedom to try changing a piece of software or make multiple variations, without fear of losing work or messing up their collaborators. In traditional software engineering projects, these problems are solved with version control concepts, like Git branches.</p>
<p>While version control systems are useful tools for software engineers, they’re not designed to support malleable software. They are difficult to learn, and targeted at formal collaboration workflows. We believe that malleable software demands new solutions which prioritize accessibility to a broad set of users, and which better support casual, informal exploration. We call this vision  <a href="https://www.inkandswitch.com/universal-version-control/">universal version control</a>.</p>
<p>To explore these version control ideas further, we created Patchwork—a web-based collaboration environment for malleable software. Patchwork builds on the core ideas of PushPin and Farm, storing both user data and software code in Automerge documents. On top of that, it adds version control utilities like history views and simple branching. These tools apply to any document in the system—whether a piece of writing, or code for a software tool.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/diff-sidebar-replace.png" alt="diff-sidebar-replace.png"></p>
<figcaption>
    Patchwork can display diffs on branches of text documents, among other media types.
</figcaption>
</figure>
<p>One process difference between Patchwork and our previous infrastructure projects is that we are now “bootstrapping”—<strong>most of our lab’s internal knowledge work, from writing to whiteboarding to project planning, happens inside of Patchwork.</strong> In fact, these very words are being typed into a collaboratively edited Markdown document hosted in Patchwork.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/patchwork-tools.png" alt="patchwork-tools.png"></p>
<figcaption>
<p>We’ve used a broad variety of tools hosted in Patchwork—from text editors and whiteboards to simulations, audio sequencers and games.</p>
</figcaption>
</figure>

<p>One thing we’ve observed from using Patchwork for our work is that <strong>opportunities for improving your software can emerge naturally within a malleable system</strong>. Here’s an example from the process of writing this essay. The main tool we use is a collaborative Markdown editor:</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/markdown.png" alt="markdown.png"></p>
<figcaption>Editing this essay in Patchwork</figcaption>
</figure>
<p>At some point, we realized the essay was too long, but it was hard to see the length of different sections just by looking in the Markdown editor. So we created a minimal Section Word Counter tool that measured the length of each section:</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/word-counter.png" alt="word-counter.png"></p>
</figure>
<p>In Patchwork, this new tool could be straightforwardly integrated into the existing workflow. It was coded in a desktop IDE and then synchronized into an Automerge document, with no need to rebuild or redeploy Patchwork itself. Once installed, the Section Word Counter could instantly be used to view the existing essay document, with live updates as the essay changed.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/two-tools.png" alt="two-tools.png"></p>
<figcaption>Two Patchwork tools can edit/view the same underlying Automerge document.</figcaption>
</figure>
<p>Treating code as data also simplifies sharing. The word counter tool was initially developed by one of the authors for his own personal use, and only loaded in his own Patchwork instance. But when another author asked to use the tool, it could be shared with a link, just like any other document. Each collaborator could choose which tools they wanted to install based on their own needs.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/share-tool.png" alt="share-tool.png"></p>
<figcaption>Sharing a tool with a collaborator via URL. (Chat is one use case we haven't managed to migrate into Patchwork yet)</figcaption>
</figure>
<p>We used a similar approach to develop several other tools as needs arose. A “Zoomout View” proved useful for talking about the overall structure of the essay:</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/zoomout.png" alt="zoomout.png"></p>
</figure>
<p>In some cases, new tools have proven less useful. We built a “Request Tracker” that would manage assigning feedback requests to coauthors, but this tool didn’t end up getting used very much. That wasn’t a huge loss, though—it didn’t take much work to create the tool, and it was easy to ignore and uninstall.</p>
<p>Another thing we’ve found while customizing Patchwork is that <strong>AI is a useful complement to a malleable environment.</strong> We argued earlier that AI-assisted coding alone does not guarantee malleability. But <em>when combined with a malleable environment</em>, AI-assisted development can make it much faster to edit your tools.</p>
<p>We’ve used AI assistance to rapidly build many tools in Patchwork. The Section Word Counter tool mentioned above was coded with AI assistance in just a few minutes—in the middle of a writing session, without needing to set aside dedicated time.</p>
<p>A malleable environment can also provide platform capabilities that make AI-generated software more useful. For example: we have an interface for making small software tools from an AI chat. While this UI superficially resembles existing products like <a href="https://support.anthropic.com/en/articles/9487310-what-are-artifacts-and-how-do-i-use-them">Claude Artifacts</a>, the generated tools gain capabilities from existing inside of Patchwork. They automatically support persistence and multi-user collaboration, and can compose with existing tools for editing existing data.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/chess-clock.png" alt="chess-clock.png"></p>
<figcaption>
<p>A presentation timer tool built with an AI chat in Patchwork has automatic persistence and multi-user synchronization.</p>
</figcaption>
</figure>
<p>While we’ve already experienced some glimpses of malleability in Patchwork, some big challenges remain.</p>
<p><strong>One open challenge is fully applying the ideas of lightweight universal version control to code.</strong> Although we have a basic mechanism for creating a branch of a software tool, we’ve yet to flesh out a full set of capabilities around branching—such as seeing and running different branches of a tool simultaneously. And more broadly, we’ve noticed there are tricky social challenges around collaborating on software in a less centralized way. How do people negotiate whether to share the same version of a tool or go their own way with separate forks? Who makes product decisions for a given tool—does the original creator stay in charge, or do they allow anyone to freely contribute? While these questions can’t be magically resolved, we think versioning tools can help.</p>
<p>A related challenge is managing expectations of quality. Most of the tools we’ve built aren’t anywhere close to the polish level of commercial products; they’re scrappy personal tools. When someone shares a tool, how can they communicate its level of quality? There’s a difference between sharing a tool “as-is” and committing to ongoing maintenance.</p>
<p>Finally, Patchwork currently has a limited embedding model that we’d like to improve on. Tools can embed other tools, but the UI of the embedded tool gets cramped, and users need better ways to choose tools at all levels of the hierarchy. We’ve also gradually discovered many reasons why UI components need to communicate in richer ways. For instance, when working on a <a href="https://www.inkandswitch.com/patchwork/notebook/11/">generic commenting utility</a> that could work with any tool, we realized that it’s useful for tools to report the current user selection as a semantic region of a document. We’ve added hardcoded workarounds to enable these kinds of tool composition, but we’d like to find a more general and less coupled approach, perhaps inspired by approaches like entanglers and Varv we mentioned earlier.</p>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/tldraw-embed.jpg" alt="tldraw-embed.jpg"></p>
<figcaption>Embedding a text document and a spreadsheet inside a whiteboard in Patchwork</figcaption>
</figure>
<p>Patchwork is still an active project. We’ve published some early findings from our version control work in a <a href="https://www.inkandswitch.com/patchwork/notebook/">lab notebook</a>, and we plan to share more about the broader system as we make progress. Eventually we also plan to release Patchwork as an open-source tool.</p>
<h3 id="dynamic-documents"><a href="#dynamic-documents">Dynamic documents</a></h3>
<p>In our infrastructure work, we’ve innovated on how software is hosted, but the behavior itself has been specified with traditional code. And yet, we know that writing code—even with AI assistance—still represents a steep “cliff” between usage and modification.</p>
<p>Thus, <strong>another strand of our work has focused on allowing the creation of custom tools without programming</strong>. Above, we showed some prior art like spreadsheets and Hypercard which embodied the approach of starting with some directly manipulable information and optionally layering on programming.</p>
<p>We’ve followed in this tradition in our work on <strong>dynamic documents</strong>. Our goal is to explore new techniques for letting users layer behavior onto their existing media documents. We’ve aimed to figure out: how should users represent information to make it possible to enrich with interaction? And how can tools cooperate and coexist within a document as a shared fabric?</p>
<h4 id="potluck-dynamic-plaintext-for-recipe-planning"><a href="#potluck-dynamic-plaintext-for-recipe-planning">Potluck: dynamic plaintext for recipe planning</a></h4>
<p>In <a href="https://www.inkandswitch.com/potluck/">Potluck</a>, we explored how users might enrich text notes with dynamic behavior like scaling ingredients and setting timers in a recipe. Users could represent information with any text syntax they found natural, and then write detectors that would parse meaningful structure out of the text.</p>
<p>We found that Potluck could support the creation of <a href="https://www.inkandswitch.com/potluck/#gallery">many useful tools</a>, and it felt nice to jot down information in any format that felt natural.</p>
<figure>
<figcaption>Scaling a recipe in Potluck document. The behavior of the scaling slider is specified within the Potluck editor using a formula language.</figcaption>
</figure>
<p>AI assistance also <a href="https://www.youtube.com/watch?v=bJ3i4K3hefI">integrates nicely</a> into Potluck. The AI can draft a set of detectors and computation rules, while preserving the user’s ability to see and edit the generated logic themselves in a live programming environment.</p>
<figure>

<figcaption>
<p>Doubling quantities in a recipe with AI support. The generated detectors and formulas can be directly viewed and edited.</p>
</figcaption>
</figure>
<p>However, one problem with Potluck was that parsing structure from arbitrary plaintext proved cumbersome. We struggled to represent connections between related information (like containment or sequence) without resorting to complex detector rules.</p>
<h4 id="embark-dynamic-outlines-for-travel-planning"><a href="#embark-dynamic-outlines-for-travel-planning">Embark: dynamic outlines for travel planning</a></h4>
<p>In our next project, we decided to try a more structured approach. We built an editor for travel planning documents called <a href="https://www.inkandswitch.com/embark">Embark</a>, which used a hierarchical outline as the base format. The outline provided some low-level structure that resolved some of the issues with detecting complex patterns in Potluck.</p>
<p>We also added a first-class concept of structured information. An object like a Google Maps location could be “mentioned” and stored within the outline. These objects could then be used as inputs to computations like routing and weather forecasting.</p>
<p>Finally, we allowed rich views like maps and calendars to be embedded in the outline, to visualize and interact with information about the trip.</p>
<figure>
<video controls="" src="https://www.inkandswitch.com/essay/malleable-software/embark-demo.mp4"></video>
    <figcaption>Computing a driving route in an Embark document. The route calculation draws on context from the surrounding document.</figcaption>
</figure>
<p>A key takeaway from Embark was that <strong>an embedding model with rich shared context enables powerful interactions</strong>. The embedded views in Embark are deeply aware of surrounding information—a map view can read and visualize the locations in the outline. The available information depends on <em>local</em> context—you can limit what information is shown on a map by moving it to a different part of the outline. Interactions are also synchronized—hovering on a place in the map highlights it in the outline, and vice versa. The cumulative result of these mechanisms is a cohesive user experience that’s not available in a more restricted embedding scheme, like the one we have in Patchwork currently, or one website embedding another one as an iFrame.</p>
<figure>

<figcaption>In Embark, a map can interact with structured data in the outline document.</figcaption>
</figure>
<p>A major challenge we faced in both Potluck and Embark is navigating the tension between more and less formal representations of information. It’s valuable to be able to express your thoughts in an unstructured way, but computational tools typically benefit from operating on more structured representations. Furthermore, data schemas aren’t limited to user input—Google Maps locations have their own structured format that needs to be usable across various tools.</p>

<p>Finally, it remains to be seen whether the ideas of Potluck and Embark can be generalized further to handle a broader variety of tasks. We grounded each of those projects in the specific use cases of recipes and travel to limit our scope and encourage authentic use, but we plan to try generalizing these ideas further and integrating them on top of a malleable infrastructure foundation such as Patchwork.</p>
<h2 id="towards-a-better-future"><a href="#towards-a-better-future">Towards a better future</a></h2>
<figure>
<p><img src="https://www.inkandswitch.com/essay/malleable-software/desktop-workspace.jpg" alt="desktop-workspace.jpg"></p>
</figure>
<p>Over the course of this essay, we’ve laid out a vision of a different kind of computing – one that could empower people to craft their own tools, shift power towards local communities, and help people do their best work. We’ve also shared many ideas for how exactly this different kind of computing might come about, from prior art and our own work.</p>
<p>At the same time, we also don’t want to understate the challenges that lie ahead. Enormous effort over many decades has gone into refining application-centric computing, and forging a new path will require grappling with many difficult questions. We’ve covered some of the questions we see as fundamental: How can we create gentle slopes from passive use to active creation? How can we break up applications into composable tools? How can we keep the needs of collaborating groups in focus?</p>
<p>That is still a partial list, and there are big challenges we’ve mostly left out of scope in this piece.</p>
<p><strong>Privacy and security</strong>: How do we reconcile the desire for extensible software and interoperability with the reality of bad actors? When untrusted strangers are sharing modifications to existing software that can access sensitive data, dangerous things can happen.</p>

<p><strong>Business models</strong>: How would developers make money from their software if they were shipping composable tools, not monolithic applications? How is support and maintenance paid for?</p>
<p><strong>Culture</strong>: How do we cultivate a movement towards personal agency where people <em>want</em> to modify their environments, both digital and otherwise?</p>
<p>These are daunting challenges. Technical capabilities can’t be a full solution; economic and cultural shifts will also be required. But change is possible—computing is still young, it has changed a lot in the past decades, and surely many structural shifts still lie ahead.</p>
<p>Many different kinds of people can play a role. If you are a computing researcher, it’s a ripe time to reimagine the foundational metaphors of computing to put more power in users’ hands. If you are a platform developer, consider tipping the balance towards seeing end-users as capable participants rather than passive users that need to be protected at all costs. Security and ease of initial use are virtues, but extensibility and power are as well. And if you make software products, consider how you might empower your users to take matters more into their own hands, rather than dictating every decision. While we believe radical change is needed to fully realize malleable software, incremental improvements are helpful too.</p>
<p>When the people living or working in a space gradually evolve their tools to meet their needs, the result is a special kind of quality. While malleable software may lack the design consistency of artifacts crafted behind closed doors in Palo Alto, we find that over time it develops the kind of charm of an old house. It bears witness to past uses and carries traces of its past decisions, even as it evolves to meet the needs of the day.</p>
<p>Everyone deserves the right to evolve their digital environments. It’s an important way to fulfill our creative potential and maintain a sense of agency in a world that is increasingly defined in code. We hope you’ll join us in making malleable software a reality.</p>
<hr>
<p><em>To follow our ongoing research, subscribe to our <a href="https://buttondown.com/inkandswitch">email newsletter</a>.</em></p>
<p><em>We are grateful to</em>:</p>
<ul>
<li><em>Roshan Choxi, Orion Henry, Ignatius Gilfedder, Mark McGranaghan, Alexander Obenauer, Jeff Peterson, Max Schoening, Paul Shen, Paul Sonnnentag, Matt Tognetti, and Adam Wiggins, for contributions to the research projects mentioned in this essay.</em></li>
<li><em>Mary Rose Cook, Marcel Goethals, Alex Komoroske, Clemens Klokmose, Steve Krouse, Jess Martin, Andy Matuschak, Paul Sonnentag, Alex Warth, and Adam Wiggins for valuable feedback on the essay.</em></li>
<li><em>Thomas Mitchell Clark, Guitar Builder; and Nathan Peterson, Food Practitioner; for allowing us to photograph their creative spaces.</em></li>
</ul>

  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Magistral — the first reasoning model by Mistral AI (675 pts)]]></title>
            <link>https://mistral.ai/news/magistral</link>
            <guid>44236997</guid>
            <pubDate>Tue, 10 Jun 2025 14:08:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mistral.ai/news/magistral">https://mistral.ai/news/magistral</a>, See on <a href="https://news.ycombinator.com/item?id=44236997">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p dir="ltr text-lg">Announcing Magistral — the first reasoning model by Mistral AI — excelling in domain-specific, transparent, and multilingual reasoning.</p>
<p dir="ltr">The best human thinking isn’t linear — it weaves through logic, insight, uncertainty, and discovery. Reasoning language models have enabled us to augment and delegate complex thinking and deep understanding to AI, improving our ability to work through problems requiring precise, step-by-step deliberation and analysis.</p>
<p dir="ltr">But this space is still nascent. Lack of specialized depth needed for domain-specific problems, limited transparency, and inconsistent reasoning in the desired language — are just some of the known limitations of early thinking models.</p>
<p dir="ltr">Today, we’re excited to announce our latest contribution to AI research with Magistral — our first reasoning model. Released in both open and enterprise versions, Magistral is designed to think things through — in ways familiar to us — while bringing expertise across professional domains, transparent reasoning that you can follow and verify, along with deep multilingual flexibility.</p>
<p dir="ltr"><iframe title="YouTube video player" src="https://www.youtube.com/embed/99xd7kHx80U?si=GPEvDJxf68FFEM9T" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<p dir="ltr">A one-shot physics simulation showcasing gravity, friction and collisions with Magistral Medium in Preview.</p>
<h2 dir="ltr">Highlights.</h2>
<p><img src="https://cms.mistral.ai/assets/d73ee721-ea92-46f5-af77-79674fdb4163.png?width=1600&amp;height=635" alt="Plot Magistral"></p>
<p dir="ltr">Magistral is a dual-release model focused on real-world reasoning and feedback-driven improvement.</p>
<ul>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">We’re releasing the model in two variants: Magistral Small — a 24B parameter open-source version and Magistral Medium — a more powerful, enterprise version.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Magistral Medium scored 73.6% on AIME2024, and 90% with majority voting @64. Magistral Small scored 70.7% and 83.3% respectively.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Reason natively — Magistral’s chain-of-thought works across global languages and alphabets.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Suited for a wide range of enterprise use cases — from structured calculations and programmatic logic to decision trees and rule-based systems.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">With the new Think mode and Flash Answers in Le Chat, you can get responses at 10x the speed compared to most competitors.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">The release is supported by our <a href="https://mistral.ai/static/research/magistral.pdf" target="_blank" rel="noopener">latest paper</a> covering comprehensive evaluations of Magistral, our training infrastructure, reinforcement learning algorithm, and novel observations for training reasoning models.&nbsp;</p>
</li>
</ul>
<p dir="ltr">As we’ve open-sourced Magistral Small, we welcome the community to examine, modify and build upon its architecture and reasoning processes to further accelerate the emergence of thinking language models. Our earlier open models have already been leveraged by the community for exciting projects like&nbsp;<a href="https://www.futurehouse.org/research-announcements/ether0-a-scientific-reasoning-model-for-chemistry">ether0</a> and <a href="https://huggingface.co/NousResearch/DeepHermes-3-Mistral-24B-Preview">DeepHermes 3</a>.</p>
<h3 dir="ltr">Purpose-built for transparent reasoning.</h3>
<p dir="ltr">Magistral is fine-tuned for multi-step logic, improving interpretability and providing a traceable thought process in the user’s language, unlike general-purpose models.</p>
<p dir="ltr">We aim to iterate the model quickly starting with this release. Expect the models to constantly improve.</p>
<h3 dir="ltr">Multilingual dexterity.</h3>
<p dir="ltr">The model excels in maintaining high-fidelity reasoning across numerous languages. Magistral is especially well-suited to reason in languages including English, French, Spanish, German, Italian, Arabic, Russian, and Simplified Chinese.</p>
<p dir="ltr"><iframe title="YouTube video player" src="https://www.youtube.com/embed/0NC-wM3hbgs?si=D-LEpAKUekkbGeyn" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<p dir="ltr">Prompt and response in Arabic with Magistral Medium in Preview in Le Chat.</p>
<h3 dir="ltr">10x faster reasoning with Le Chat.</h3>
<p dir="ltr">With Flash Answers in Le Chat, Magistral Medium achieves up to 10x faster token throughput than most competitors. This enables real-time reasoning and user feedback, at scale.</p>
<p dir="ltr"><iframe title="YouTube video player" src="https://www.youtube.com/embed/_ImwDFqgblY?si=SAmY7mFwzKjGgKTT" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<p dir="ltr">Speed comparison of Magistral Medium in Preview in Le Chat against ChatGPT.</p>
<h2 dir="ltr">Versatility in application.</h2>
<p dir="ltr">Magistral is ideal for general purpose use requiring longer thought processing and better accuracy than with non-reasoning LLMs. From legal research and financial forecasting to software development and creative storytelling — this model solves multi-step challenges where transparency and precision are critical.</p>
<h3 dir="ltr">Business strategy and operations.</h3>
<p dir="ltr">Building on our flagship <a href="https://mistral.ai/models">models</a>, Magistral is designed for research, strategic planning, operational optimization, and data-driven decision making — whether executing risk assessment and modelling with multiple factors, or calculating optimal delivery windows under constraints.</p>
<h3 dir="ltr">Regulated industries and sectors.</h3>
<p dir="ltr">Legal, finance, healthcare, and government professionals get traceable reasoning that meets compliance requirements. Every conclusion can be traced back through its logical steps, providing auditability for high-stakes environments with domain-specialized AI.</p>
<h3 dir="ltr">Systems, software, and data engineering.</h3>
<p dir="ltr">Magistral enhances coding and development use cases: compared to non-reasoning models, it significantly improves project planning, backend architecture, frontend design, and data engineering through sequenced, multi-step actions involving external tools or API.</p>
<h3 dir="ltr">Content and communication.</h3>
<p dir="ltr">Our early tests indicated that Magistral is an excellent creative companion. We highly recommend it for creative writing and storytelling, with the model capable of producing coherent or — if needed — delightfully eccentric copy.</p>
<h2 dir="ltr">Availability</h2>
<p dir="ltr">Magistral Small is an open-weight model, and is available for self-deployment under the Apache 2.0 license. You can download it from:&nbsp;&nbsp;</p>
<ul>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Hugging Face: <a href="https://huggingface.co/mistralai/Magistral-Small-2506">https://huggingface.co/mistralai/Magistral-Small-2506</a></p>
</li>
</ul>
<p dir="ltr">You can try out a preview version of Magistral Medium in <a href="http://chat.mistral.ai/">Le Chat</a> or via API on <a href="http://console.mistral.ai/">La Plateforme</a>.&nbsp;</p>
<p dir="ltr">Magistral Medium is also available on Amazon SageMaker, and soon on IBM WatsonX, Azure AI and Google Cloud Marketplace.</p>
<p dir="ltr"><strong id="docs-internal-guid-dcd44481-7fff-e65a-9fdf-b6a154ef6740"></strong>For enterprise and custom solutions, including on-premises deployments,&nbsp;<a href="https://mistral.ai/contact">contact our sales team</a>.</p>
<div>
<h2 dir="ltr">BTW, we’re hiring!</h2>
<p dir="ltr">Magistral represents a significant contribution by Mistral AI to the open source community, with input from seasoned experts and interns. And we’re keen to grow our family to further shape future AI innovation.</p>
<p dir="ltr">If you’re interested in joining us on our mission to democratize artificial intelligenceI, we welcome your applications to <a href="https://mistral.ai/careers">join our team</a>!&nbsp;</p>
</div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: PyDoll – Async Python scraping engine with native CAPTCHA bypass (116 pts)]]></title>
            <link>https://github.com/autoscrape-labs/pydoll</link>
            <guid>44236926</guid>
            <pubDate>Tue, 10 Jun 2025 14:01:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/autoscrape-labs/pydoll">https://github.com/autoscrape-labs/pydoll</a>, See on <a href="https://news.ycombinator.com/item?id=44236926">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto">
    <p><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/101291018/452653415-219f2dbc-37ed-4aea-a289-ba39cdbb335d.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDk1OTQ5MDEsIm5iZiI6MTc0OTU5NDYwMSwicGF0aCI6Ii8xMDEyOTEwMTgvNDUyNjUzNDE1LTIxOWYyZGJjLTM3ZWQtNGFlYS1hMjg5LWJhMzljZGJiMzM1ZC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNjEwJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDYxMFQyMjMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0wYjZjODQ5YzQzYWY0YTFjMDU3YmYxM2IwZGE3ZTE4ZWVhZGQ2MjlkMmUwOWMwM2ZiOTQ4YTMxZWFlYWE3ZmU5JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.j34rkYH2WanUIyEDo7UuOb1jmDA22RJeYca0jIch_dg"><img src="https://private-user-images.githubusercontent.com/101291018/452653415-219f2dbc-37ed-4aea-a289-ba39cdbb335d.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDk1OTQ5MDEsIm5iZiI6MTc0OTU5NDYwMSwicGF0aCI6Ii8xMDEyOTEwMTgvNDUyNjUzNDE1LTIxOWYyZGJjLTM3ZWQtNGFlYS1hMjg5LWJhMzljZGJiMzM1ZC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNjEwJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDYxMFQyMjMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0wYjZjODQ5YzQzYWY0YTFjMDU3YmYxM2IwZGE3ZTE4ZWVhZGQ2MjlkMmUwOWMwM2ZiOTQ4YTMxZWFlYWE3ZmU5JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.j34rkYH2WanUIyEDo7UuOb1jmDA22RJeYca0jIch_dg" alt="Pydoll Logo"></a></p></div>
<p dir="auto">
    <a href="https://codecov.io/gh/autoscrape-labs/pydoll" rel="nofollow">
        <img src="https://camo.githubusercontent.com/89a01b6336655dc81749f71323b9a8b741d16d0b4b664a8864c90ab6f61e863b/68747470733a2f2f636f6465636f762e696f2f67682f6175746f7363726170652d6c6162732f7079646f6c6c2f67726170682f62616467652e7376673f746f6b656e3d3430493933384f474d39" data-canonical-src="https://codecov.io/gh/autoscrape-labs/pydoll/graph/badge.svg?token=40I938OGM9"> 
    </a>
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/thalissonvs/pydoll/actions/workflows/tests.yml/badge.svg"><img src="https://github.com/thalissonvs/pydoll/actions/workflows/tests.yml/badge.svg" alt="Tests"></a>
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/thalissonvs/pydoll/actions/workflows/ruff-ci.yml/badge.svg"><img src="https://github.com/thalissonvs/pydoll/actions/workflows/ruff-ci.yml/badge.svg" alt="Ruff CI"></a>
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/thalissonvs/pydoll/actions/workflows/release.yml/badge.svg"><img src="https://github.com/thalissonvs/pydoll/actions/workflows/release.yml/badge.svg" alt="Release"></a>
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/thalissonvs/pydoll/actions/workflows/mypy.yml/badge.svg"><img src="https://github.com/thalissonvs/pydoll/actions/workflows/mypy.yml/badge.svg" alt="MyPy CI"></a>
    <a href="https://deepwiki.com/autoscrape-labs/pydoll" rel="nofollow"><img src="https://camo.githubusercontent.com/e7d4bb1a32530e373bb53fbe8eea825440ad27c7531d8f144d561acdd20c093a/68747470733a2f2f6465657077696b692e636f6d2f62616467652e737667" alt="Ask DeepWiki" data-canonical-src="https://deepwiki.com/badge.svg"></a>
</p>
<p dir="auto">
  <a href="https://autoscrape-labs.github.io/pydoll/" rel="nofollow">Documentation</a> •
  <a href="#getting-started">Getting Started</a> •
  <a href="#advanced-features">Advanced Features</a> •
  <a href="#contributing">Contributing</a> •
  <a href="#support-my-work">Support</a> •
  <a href="#license">License</a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Key Features</h2><a id="user-content-key-features" aria-label="Permalink: Key Features" href="#key-features"></a></p>
<p dir="auto">🔹 <strong>Zero Webdrivers!</strong> Say goodbye to webdriver compatibility nightmares<br>
🔹 <strong>Native Captcha Bypass!</strong> Smoothly handles Cloudflare Turnstile and reCAPTCHA v3*<br>
🔹 <strong>Async Performance</strong> for lightning-fast automation<br>
🔹 <strong>Human-like Interactions</strong> that mimic real user behavior<br>
🔹 <strong>Powerful Event System</strong> for reactive automations<br>
🔹 <strong>Multi-browser Support</strong> including Chrome and Edge</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why Pydoll Exists</h2><a id="user-content-why-pydoll-exists" aria-label="Permalink: Why Pydoll Exists" href="#why-pydoll-exists"></a></p>
<p dir="auto">Picture this: you need to automate browser tasks. Maybe it's testing your web application, scraping data from websites, or automating repetitive processes. Traditionally, this meant dealing with external drivers, complex configurations, and a host of compatibility issues that seemed to appear out of nowhere.</p>
<p dir="auto">But there's another challenge that's even more frustrating: <strong>modern web protection systems</strong>. Cloudflare Turnstile captchas, reCAPTCHA v3, and sophisticated bot detection algorithms that can instantly identify and block traditional automation tools. Your perfectly written automation script fails not because of bugs, but because websites can tell it's not human.</p>
<p dir="auto"><strong>Pydoll was born to change that.</strong></p>
<p dir="auto">Built from the ground up with a different philosophy, Pydoll connects directly to the Chrome DevTools Protocol (CDP), eliminating the need for external drivers entirely. More importantly, it incorporates advanced human behavior simulation and intelligent captcha bypass capabilities that make your automations virtually indistinguishable from real human interactions.</p>
<p dir="auto">We believe that powerful automation shouldn't require you to become a configuration expert or constantly battle with anti-bot systems. With Pydoll, you focus on what matters: your automation logic, not the underlying complexity or protection bypassing.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What Makes Pydoll Special</h2><a id="user-content-what-makes-pydoll-special" aria-label="Permalink: What Makes Pydoll Special" href="#what-makes-pydoll-special"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Intelligent Captcha Bypass</strong>: Built-in automatic solving for Cloudflare Turnstile and reCAPTCHA v3 captchas without external services, API keys, or complex configurations. Your automations continue seamlessly even when encountering protection systems.</p>
</li>
<li>
<p dir="auto"><strong>Truly Human Interactions</strong>: Advanced algorithms simulate authentic human behavior patterns - from realistic timing between actions to natural mouse movements, scroll patterns, and typing rhythms that fool even sophisticated bot detection systems.</p>
</li>
<li>
<p dir="auto"><strong>Genuine Simplicity</strong>: We don't want you wasting time configuring drivers or dealing with compatibility issues. With Pydoll, you install and you're ready to automate, even on protected sites.</p>
</li>
<li>
<p dir="auto"><strong>Native Async Performance</strong>: Built from the ground up with <code>asyncio</code>, Pydoll doesn't just support asynchronous operations - it was designed for them, enabling concurrent processing of multiple protected sites.</p>
</li>
<li>
<p dir="auto"><strong>Powerful Network Monitoring</strong>: Intercept, modify, and analyze all network traffic with ease, giving you complete control over requests and responses - perfect for bypassing additional protection layers.</p>
</li>
<li>
<p dir="auto"><strong>Event-Driven Architecture</strong>: React to page events, network requests, and user interactions in real-time, enabling sophisticated automation flows that adapt to dynamic protection systems.</p>
</li>
<li>
<p dir="auto"><strong>Intuitive Element Finding</strong>: Modern <code>find()</code> and <code>query()</code> methods that make sense and work as you'd expect, even with dynamically loaded content from protection systems.</p>
</li>
<li>
<p dir="auto"><strong>Robust Type Safety</strong>: Comprehensive type system for better IDE support and error prevention in complex automation scenarios.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install pydoll-python"><pre>pip install pydoll-python</pre></div>
<p dir="auto">That's it. No drivers to download, no complex configurations. Just install and start automating.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Your First Automation</h3><a id="user-content-your-first-automation" aria-label="Permalink: Your First Automation" href="#your-first-automation"></a></p>
<p dir="auto">Let's start with something simple. The code below opens a browser, navigates to a website, and interacts with elements:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import asyncio
from pydoll.browser import Chrome

async def my_first_automation():
    # Create a browser instance
    async with Chrome() as browser:
        # Start the browser and get a tab
        tab = await browser.start()
        
        # Navigate to a website
        await tab.go_to('https://example.com')
        
        # Find elements intuitively
        button = await tab.find(tag_name='button', class_name='submit')
        await button.click()
        
        # Or use CSS selectors/XPath directly
        link = await tab.query('a[href*=&quot;contact&quot;]')
        await link.click()

# Run the automation
asyncio.run(my_first_automation())"><pre><span>import</span> <span>asyncio</span>
<span>from</span> <span>pydoll</span>.<span>browser</span> <span>import</span> <span>Chrome</span>

<span>async</span> <span>def</span> <span>my_first_automation</span>():
    <span># Create a browser instance</span>
    <span>async</span> <span>with</span> <span>Chrome</span>() <span>as</span> <span>browser</span>:
        <span># Start the browser and get a tab</span>
        <span>tab</span> <span>=</span> <span>await</span> <span>browser</span>.<span>start</span>()
        
        <span># Navigate to a website</span>
        <span>await</span> <span>tab</span>.<span>go_to</span>(<span>'https://example.com'</span>)
        
        <span># Find elements intuitively</span>
        <span>button</span> <span>=</span> <span>await</span> <span>tab</span>.<span>find</span>(<span>tag_name</span><span>=</span><span>'button'</span>, <span>class_name</span><span>=</span><span>'submit'</span>)
        <span>await</span> <span>button</span>.<span>click</span>()
        
        <span># Or use CSS selectors/XPath directly</span>
        <span>link</span> <span>=</span> <span>await</span> <span>tab</span>.<span>query</span>(<span>'a[href*="contact"]'</span>)
        <span>await</span> <span>link</span>.<span>click</span>()

<span># Run the automation</span>
<span>asyncio</span>.<span>run</span>(<span>my_first_automation</span>())</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Custom Configuration</h3><a id="user-content-custom-configuration" aria-label="Permalink: Custom Configuration" href="#custom-configuration"></a></p>
<p dir="auto">Sometimes you need more control. Pydoll offers flexible configuration options:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from pydoll.browser import Chrome
from pydoll.browser.options import ChromiumOptions

async def custom_automation():
    # Configure browser options
    options = ChromiumOptions()
    options.add_argument('--proxy-server=username:password@ip:port')
    options.add_argument('--window-size=1920,1080')
    options.add_argument('--disable-web-security')
    options.binary_location = '/path/to/your/browser'

    async with Chrome(options=options) as browser:
        tab = await browser.start()
        
        # Your automation code here
        await tab.go_to('https://example.com')
        
        # The browser is now using your custom settings

asyncio.run(custom_automation())"><pre><span>from</span> <span>pydoll</span>.<span>browser</span> <span>import</span> <span>Chrome</span>
<span>from</span> <span>pydoll</span>.<span>browser</span>.<span>options</span> <span>import</span> <span>ChromiumOptions</span>

<span>async</span> <span>def</span> <span>custom_automation</span>():
    <span># Configure browser options</span>
    <span>options</span> <span>=</span> <span>ChromiumOptions</span>()
    <span>options</span>.<span>add_argument</span>(<span>'--proxy-server=username:password@ip:port'</span>)
    <span>options</span>.<span>add_argument</span>(<span>'--window-size=1920,1080'</span>)
    <span>options</span>.<span>add_argument</span>(<span>'--disable-web-security'</span>)
    <span>options</span>.<span>binary_location</span> <span>=</span> <span>'/path/to/your/browser'</span>

    <span>async</span> <span>with</span> <span>Chrome</span>(<span>options</span><span>=</span><span>options</span>) <span>as</span> <span>browser</span>:
        <span>tab</span> <span>=</span> <span>await</span> <span>browser</span>.<span>start</span>()
        
        <span># Your automation code here</span>
        <span>await</span> <span>tab</span>.<span>go_to</span>(<span>'https://example.com'</span>)
        
        <span># The browser is now using your custom settings</span>

<span>asyncio</span>.<span>run</span>(<span>custom_automation</span>())</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Advanced Features</h2><a id="user-content-advanced-features" aria-label="Permalink: Advanced Features" href="#advanced-features"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Intelligent Captcha Bypass</h3><a id="user-content-intelligent-captcha-bypass" aria-label="Permalink: Intelligent Captcha Bypass" href="#intelligent-captcha-bypass"></a></p>
<p dir="auto">One of Pydoll's most revolutionary features is its ability to automatically handle modern captcha systems that typically block automation tools. This isn't just about solving captchas - it's about making your automations completely transparent to protection systems.</p>
<p dir="auto"><strong>Supported Captcha Types:</strong></p>
<ul dir="auto">
<li><strong>Cloudflare Turnstile</strong> - The modern replacement for reCAPTCHA</li>
<li><strong>reCAPTCHA v3</strong> - Google's invisible captcha system</li>
<li><strong>Custom implementations</strong> - Extensible framework for new captcha types</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="import asyncio
from pydoll.browser import Chrome

async def advanced_captcha_bypass():
    async with Chrome() as browser:
        tab = await browser.start()
        
        # Method 1: Context manager (waits for captcha completion)
        async with tab.expect_and_bypass_cloudflare_captcha():
            await tab.go_to('https://site-with-cloudflare.com')
            print(&quot;Cloudflare Turnstile automatically solved!&quot;)
            
            # Continue with your automation - captcha is handled
            await tab.find(id='username').type_text('user@example.com')
            await tab.find(id='password').type_text('password123')
            await tab.find(tag_name='button', text='Login').click()
        
        # Method 2: Background processing (non-blocking)
        await tab.enable_auto_solve_cloudflare_captcha()
        await tab.go_to('https://another-protected-site.com')
        # Captcha solved automatically in background while code continues
        
        # Method 3: Custom captcha selector for specific implementations
        await tab.enable_auto_solve_cloudflare_captcha(
            custom_selector=(By.CLASS_NAME, 'custom-captcha-widget'),
            time_before_click=3,  # Wait 3 seconds before solving
            time_to_wait_captcha=10  # Timeout after 10 seconds
        )
        
        await tab.disable_auto_solve_cloudflare_captcha()

asyncio.run(advanced_captcha_bypass())"><pre><span>import</span> <span>asyncio</span>
<span>from</span> <span>pydoll</span>.<span>browser</span> <span>import</span> <span>Chrome</span>

<span>async</span> <span>def</span> <span>advanced_captcha_bypass</span>():
    <span>async</span> <span>with</span> <span>Chrome</span>() <span>as</span> <span>browser</span>:
        <span>tab</span> <span>=</span> <span>await</span> <span>browser</span>.<span>start</span>()
        
        <span># Method 1: Context manager (waits for captcha completion)</span>
        <span>async</span> <span>with</span> <span>tab</span>.<span>expect_and_bypass_cloudflare_captcha</span>():
            <span>await</span> <span>tab</span>.<span>go_to</span>(<span>'https://site-with-cloudflare.com'</span>)
            <span>print</span>(<span>"Cloudflare Turnstile automatically solved!"</span>)
            
            <span># Continue with your automation - captcha is handled</span>
            <span>await</span> <span>tab</span>.<span>find</span>(<span>id</span><span>=</span><span>'username'</span>).<span>type_text</span>(<span>'user@example.com'</span>)
            <span>await</span> <span>tab</span>.<span>find</span>(<span>id</span><span>=</span><span>'password'</span>).<span>type_text</span>(<span>'password123'</span>)
            <span>await</span> <span>tab</span>.<span>find</span>(<span>tag_name</span><span>=</span><span>'button'</span>, <span>text</span><span>=</span><span>'Login'</span>).<span>click</span>()
        
        <span># Method 2: Background processing (non-blocking)</span>
        <span>await</span> <span>tab</span>.<span>enable_auto_solve_cloudflare_captcha</span>()
        <span>await</span> <span>tab</span>.<span>go_to</span>(<span>'https://another-protected-site.com'</span>)
        <span># Captcha solved automatically in background while code continues</span>
        
        <span># Method 3: Custom captcha selector for specific implementations</span>
        <span>await</span> <span>tab</span>.<span>enable_auto_solve_cloudflare_captcha</span>(
            <span>custom_selector</span><span>=</span>(<span>By</span>.<span>CLASS_NAME</span>, <span>'custom-captcha-widget'</span>),
            <span>time_before_click</span><span>=</span><span>3</span>,  <span># Wait 3 seconds before solving</span>
            <span>time_to_wait_captcha</span><span>=</span><span>10</span>  <span># Timeout after 10 seconds</span>
        )
        
        <span>await</span> <span>tab</span>.<span>disable_auto_solve_cloudflare_captcha</span>()

<span>asyncio</span>.<span>run</span>(<span>advanced_captcha_bypass</span>())</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Advanced Element Finding</h3><a id="user-content-advanced-element-finding" aria-label="Permalink: Advanced Element Finding" href="#advanced-element-finding"></a></p>
<p dir="auto">Pydoll offers multiple intuitive ways to find elements. No matter how you prefer to work, we have an approach that makes sense for you:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import asyncio
from pydoll.browser import Chrome

async def element_finding_examples():
    async with Chrome() as browser:
        tab = await browser.start()
        await tab.go_to('https://example.com')
        
        # Find by attributes (most intuitive)
        submit_btn = await tab.find(
            tag_name='button',
            class_name='btn-primary',
            text='Submit'
        )
        
        # Find by ID
        username_field = await tab.find(id='username')
        
        # Find multiple elements
        all_links = await tab.find(tag_name='a', find_all=True)
        
        # CSS selectors and XPath
        nav_menu = await tab.query('nav.main-menu')
        specific_item = await tab.query('//div[@data-testid=&quot;item-123&quot;]')
        
        # With timeout and error handling
        delayed_element = await tab.find(
            class_name='dynamic-content',
            timeout=10,
            raise_exc=False  # Returns None if not found
        )
        
        # Advanced: Custom attributes
        custom_element = await tab.find(
            data_testid='submit-button',
            aria_label='Submit form'
        )

asyncio.run(element_finding_examples())"><pre><span>import</span> <span>asyncio</span>
<span>from</span> <span>pydoll</span>.<span>browser</span> <span>import</span> <span>Chrome</span>

<span>async</span> <span>def</span> <span>element_finding_examples</span>():
    <span>async</span> <span>with</span> <span>Chrome</span>() <span>as</span> <span>browser</span>:
        <span>tab</span> <span>=</span> <span>await</span> <span>browser</span>.<span>start</span>()
        <span>await</span> <span>tab</span>.<span>go_to</span>(<span>'https://example.com'</span>)
        
        <span># Find by attributes (most intuitive)</span>
        <span>submit_btn</span> <span>=</span> <span>await</span> <span>tab</span>.<span>find</span>(
            <span>tag_name</span><span>=</span><span>'button'</span>,
            <span>class_name</span><span>=</span><span>'btn-primary'</span>,
            <span>text</span><span>=</span><span>'Submit'</span>
        )
        
        <span># Find by ID</span>
        <span>username_field</span> <span>=</span> <span>await</span> <span>tab</span>.<span>find</span>(<span>id</span><span>=</span><span>'username'</span>)
        
        <span># Find multiple elements</span>
        <span>all_links</span> <span>=</span> <span>await</span> <span>tab</span>.<span>find</span>(<span>tag_name</span><span>=</span><span>'a'</span>, <span>find_all</span><span>=</span><span>True</span>)
        
        <span># CSS selectors and XPath</span>
        <span>nav_menu</span> <span>=</span> <span>await</span> <span>tab</span>.<span>query</span>(<span>'nav.main-menu'</span>)
        <span>specific_item</span> <span>=</span> <span>await</span> <span>tab</span>.<span>query</span>(<span>'//div[@data-testid="item-123"]'</span>)
        
        <span># With timeout and error handling</span>
        <span>delayed_element</span> <span>=</span> <span>await</span> <span>tab</span>.<span>find</span>(
            <span>class_name</span><span>=</span><span>'dynamic-content'</span>,
            <span>timeout</span><span>=</span><span>10</span>,
            <span>raise_exc</span><span>=</span><span>False</span>  <span># Returns None if not found</span>
        )
        
        <span># Advanced: Custom attributes</span>
        <span>custom_element</span> <span>=</span> <span>await</span> <span>tab</span>.<span>find</span>(
            <span>data_testid</span><span>=</span><span>'submit-button'</span>,
            <span>aria_label</span><span>=</span><span>'Submit form'</span>
        )

<span>asyncio</span>.<span>run</span>(<span>element_finding_examples</span>())</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Concurrent Automation</h3><a id="user-content-concurrent-automation" aria-label="Permalink: Concurrent Automation" href="#concurrent-automation"></a></p>
<p dir="auto">One of the great advantages of Pydoll's asynchronous design is the ability to process multiple tasks simultaneously:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import asyncio
from pydoll.browser import Chrome

async def scrape_page(url):
    &quot;&quot;&quot;Extract data from a single page&quot;&quot;&quot;
    async with Chrome() as browser:
        tab = await browser.start()
        await tab.go_to(url)
        
        title = await tab.execute_script('return document.title')
        links = await tab.find(tag_name='a', find_all=True)
        
        return {
            'url': url,
            'title': title,
            'link_count': len(links)
        }

async def concurrent_scraping():
    urls = [
        'https://example1.com',
        'https://example2.com',
        'https://example3.com'
    ]
    
    # Process all URLs simultaneously
    tasks = [scrape_page(url) for url in urls]
    results = await asyncio.gather(*tasks)
    
    for result in results:
        print(f&quot;{result['url']}: {result['title']} ({result['link_count']} links)&quot;)

asyncio.run(concurrent_scraping())"><pre><span>import</span> <span>asyncio</span>
<span>from</span> <span>pydoll</span>.<span>browser</span> <span>import</span> <span>Chrome</span>

<span>async</span> <span>def</span> <span>scrape_page</span>(<span>url</span>):
    <span>"""Extract data from a single page"""</span>
    <span>async</span> <span>with</span> <span>Chrome</span>() <span>as</span> <span>browser</span>:
        <span>tab</span> <span>=</span> <span>await</span> <span>browser</span>.<span>start</span>()
        <span>await</span> <span>tab</span>.<span>go_to</span>(<span>url</span>)
        
        <span>title</span> <span>=</span> <span>await</span> <span>tab</span>.<span>execute_script</span>(<span>'return document.title'</span>)
        <span>links</span> <span>=</span> <span>await</span> <span>tab</span>.<span>find</span>(<span>tag_name</span><span>=</span><span>'a'</span>, <span>find_all</span><span>=</span><span>True</span>)
        
        <span>return</span> {
            <span>'url'</span>: <span>url</span>,
            <span>'title'</span>: <span>title</span>,
            <span>'link_count'</span>: <span>len</span>(<span>links</span>)
        }

<span>async</span> <span>def</span> <span>concurrent_scraping</span>():
    <span>urls</span> <span>=</span> [
        <span>'https://example1.com'</span>,
        <span>'https://example2.com'</span>,
        <span>'https://example3.com'</span>
    ]
    
    <span># Process all URLs simultaneously</span>
    <span>tasks</span> <span>=</span> [<span>scrape_page</span>(<span>url</span>) <span>for</span> <span>url</span> <span>in</span> <span>urls</span>]
    <span>results</span> <span>=</span> <span>await</span> <span>asyncio</span>.<span>gather</span>(<span>*</span><span>tasks</span>)
    
    <span>for</span> <span>result</span> <span>in</span> <span>results</span>:
        <span>print</span>(<span>f"<span><span>{</span><span>result</span>[<span>'url'</span>]<span>}</span></span>: <span><span>{</span><span>result</span>[<span>'title'</span>]<span>}</span></span> (<span><span>{</span><span>result</span>[<span>'link_count'</span>]<span>}</span></span> links)"</span>)

<span>asyncio</span>.<span>run</span>(<span>concurrent_scraping</span>())</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Event-Driven Automation</h3><a id="user-content-event-driven-automation" aria-label="Permalink: Event-Driven Automation" href="#event-driven-automation"></a></p>
<p dir="auto">React to page events and user interactions in real-time. This enables more sophisticated and responsive automations:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import asyncio
from pydoll.browser import Chrome
from pydoll.protocol.page.events import PageEvent

async def event_driven_automation():
    async with Chrome() as browser:
        tab = await browser.start()
        
        # Enable page events
        await tab.enable_page_events()
        
        # React to page load
        async def on_page_load(event):
            print(&quot;Page loaded! Starting automation...&quot;)
            # Perform actions after page loads
            search_box = await tab.find(id='search-box')
            await search_box.type_text('automation')
        
        # React to navigation
        async def on_navigation(event):
            url = event['params']['url']
            print(f&quot;Navigated to: {url}&quot;)
        
        await tab.on(PageEvent.LOAD_EVENT_FIRED, on_page_load)
        await tab.on(PageEvent.FRAME_NAVIGATED, on_navigation)
        
        await tab.go_to('https://example.com')
        await asyncio.sleep(5)  # Let events process

asyncio.run(event_driven_automation())"><pre><span>import</span> <span>asyncio</span>
<span>from</span> <span>pydoll</span>.<span>browser</span> <span>import</span> <span>Chrome</span>
<span>from</span> <span>pydoll</span>.<span>protocol</span>.<span>page</span>.<span>events</span> <span>import</span> <span>PageEvent</span>

<span>async</span> <span>def</span> <span>event_driven_automation</span>():
    <span>async</span> <span>with</span> <span>Chrome</span>() <span>as</span> <span>browser</span>:
        <span>tab</span> <span>=</span> <span>await</span> <span>browser</span>.<span>start</span>()
        
        <span># Enable page events</span>
        <span>await</span> <span>tab</span>.<span>enable_page_events</span>()
        
        <span># React to page load</span>
        <span>async</span> <span>def</span> <span>on_page_load</span>(<span>event</span>):
            <span>print</span>(<span>"Page loaded! Starting automation..."</span>)
            <span># Perform actions after page loads</span>
            <span>search_box</span> <span>=</span> <span>await</span> <span>tab</span>.<span>find</span>(<span>id</span><span>=</span><span>'search-box'</span>)
            <span>await</span> <span>search_box</span>.<span>type_text</span>(<span>'automation'</span>)
        
        <span># React to navigation</span>
        <span>async</span> <span>def</span> <span>on_navigation</span>(<span>event</span>):
            <span>url</span> <span>=</span> <span>event</span>[<span>'params'</span>][<span>'url'</span>]
            <span>print</span>(<span>f"Navigated to: <span><span>{</span><span>url</span><span>}</span></span>"</span>)
        
        <span>await</span> <span>tab</span>.<span>on</span>(<span>PageEvent</span>.<span>LOAD_EVENT_FIRED</span>, <span>on_page_load</span>)
        <span>await</span> <span>tab</span>.<span>on</span>(<span>PageEvent</span>.<span>FRAME_NAVIGATED</span>, <span>on_navigation</span>)
        
        <span>await</span> <span>tab</span>.<span>go_to</span>(<span>'https://example.com'</span>)
        <span>await</span> <span>asyncio</span>.<span>sleep</span>(<span>5</span>)  <span># Let events process</span>

<span>asyncio</span>.<span>run</span>(<span>event_driven_automation</span>())</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Working with iFrames</h3><a id="user-content-working-with-iframes" aria-label="Permalink: Working with iFrames" href="#working-with-iframes"></a></p>
<p dir="auto">Pydoll provides seamless iframe interaction through the <code>get_frame()</code> method. This is especially useful for dealing with embedded content:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import asyncio
from pydoll.browser.chromium import Chrome

async def iframe_interaction():
    async with Chrome() as browser:
        tab = await browser.start()
        await tab.go_to('https://example.com/page-with-iframe')
        
        # Find the iframe element
        iframe_element = await tab.query('.hcaptcha-iframe', timeout=10)
        
        # Get a Tab instance for the iframe content
        frame = await tab.get_frame(iframe_element)
        
        # Now interact with elements inside the iframe
        submit_button = await frame.find(tag_name='button', class_name='submit')
        await submit_button.click()
        
        # You can use all Tab methods on the frame
        form_input = await frame.find(id='captcha-input')
        await form_input.type_text('verification-code')
        
        # Find elements by various methods
        links = await frame.find(tag_name='a', find_all=True)
        specific_element = await frame.query('#specific-id')

asyncio.run(iframe_interaction())"><pre><span>import</span> <span>asyncio</span>
<span>from</span> <span>pydoll</span>.<span>browser</span>.<span>chromium</span> <span>import</span> <span>Chrome</span>

<span>async</span> <span>def</span> <span>iframe_interaction</span>():
    <span>async</span> <span>with</span> <span>Chrome</span>() <span>as</span> <span>browser</span>:
        <span>tab</span> <span>=</span> <span>await</span> <span>browser</span>.<span>start</span>()
        <span>await</span> <span>tab</span>.<span>go_to</span>(<span>'https://example.com/page-with-iframe'</span>)
        
        <span># Find the iframe element</span>
        <span>iframe_element</span> <span>=</span> <span>await</span> <span>tab</span>.<span>query</span>(<span>'.hcaptcha-iframe'</span>, <span>timeout</span><span>=</span><span>10</span>)
        
        <span># Get a Tab instance for the iframe content</span>
        <span>frame</span> <span>=</span> <span>await</span> <span>tab</span>.<span>get_frame</span>(<span>iframe_element</span>)
        
        <span># Now interact with elements inside the iframe</span>
        <span>submit_button</span> <span>=</span> <span>await</span> <span>frame</span>.<span>find</span>(<span>tag_name</span><span>=</span><span>'button'</span>, <span>class_name</span><span>=</span><span>'submit'</span>)
        <span>await</span> <span>submit_button</span>.<span>click</span>()
        
        <span># You can use all Tab methods on the frame</span>
        <span>form_input</span> <span>=</span> <span>await</span> <span>frame</span>.<span>find</span>(<span>id</span><span>=</span><span>'captcha-input'</span>)
        <span>await</span> <span>form_input</span>.<span>type_text</span>(<span>'verification-code'</span>)
        
        <span># Find elements by various methods</span>
        <span>links</span> <span>=</span> <span>await</span> <span>frame</span>.<span>find</span>(<span>tag_name</span><span>=</span><span>'a'</span>, <span>find_all</span><span>=</span><span>True</span>)
        <span>specific_element</span> <span>=</span> <span>await</span> <span>frame</span>.<span>query</span>(<span>'#specific-id'</span>)

<span>asyncio</span>.<span>run</span>(<span>iframe_interaction</span>())</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<p dir="auto">For comprehensive documentation, detailed examples, and deep dives into Pydoll's features, visit our <a href="https://autoscrape-labs.github.io/pydoll/" rel="nofollow">official documentation site</a>.</p>
<p dir="auto">The documentation includes:</p>
<ul dir="auto">
<li><strong>Getting Started Guide</strong> - Step-by-step tutorials</li>
<li><strong>API Reference</strong> - Complete method documentation</li>
<li><strong>Advanced Techniques</strong> - Network interception, event handling, performance optimization</li>
<li><strong>Troubleshooting</strong> - Common issues and solutions</li>
<li><strong>Best Practices</strong> - Patterns for reliable automation</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">We'd love your help making Pydoll even better! Check out our <a href="https://github.com/autoscrape-labs/pydoll/blob/main/CONTRIBUTING.md">contribution guidelines</a> to get started. Whether it's fixing bugs, adding features, or improving documentation - all contributions are welcome!</p>
<p dir="auto">Please make sure to:</p>
<ul dir="auto">
<li>Write tests for new features or bug fixes</li>
<li>Follow coding style and conventions</li>
<li>Use conventional commits for pull requests</li>
<li>Run lint and test checks before submitting</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Support My Work</h2><a id="user-content-support-my-work" aria-label="Permalink: Support My Work" href="#support-my-work"></a></p>
<p dir="auto">If you find my projects helpful, consider <a href="https://github.com/sponsors/thalissonvs">sponsoring me on GitHub</a>.<br>
You'll get access to exclusive perks like prioritized support, custom features, and more!</p>
<p dir="auto">Can't sponsor right now? No problem — you can still help a lot by:</p>
<ul dir="auto">
<li>Starring the repo</li>
<li>Sharing it on social media</li>
<li>Writing blog posts or tutorials</li>
<li>Giving feedback or reporting issues</li>
</ul>
<p dir="auto">Every bit of support makes a difference — thank you!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Pydoll is licensed under the <a href="https://github.com/autoscrape-labs/pydoll/blob/main/LICENSE">MIT License</a>.</p>
<p dir="auto">
  <b>Pydoll</b> — Making browser automation magical!
</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Finding Atari Games in Randomly Generated Data (148 pts)]]></title>
            <link>https://bbenchoff.github.io/pages/FiniteAtari.html</link>
            <guid>44236900</guid>
            <pubDate>Tue, 10 Jun 2025 13:58:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bbenchoff.github.io/pages/FiniteAtari.html">https://bbenchoff.github.io/pages/FiniteAtari.html</a>, See on <a href="https://news.ycombinator.com/item?id=44236900">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <!-- ── Finite Atari Machine banner ── -->


<p>
  Finding Atari Games in Randomly Generated Data
</p>

<p>
  TL;DR, <a href="https://github.com/bbenchoff/FiniteAtariMachine">here’s the GitHub repo</a>
</p>



<!-- ── Finite Atari Machine banner ── -->

<p>This project generated around 30 Billion individual 4kB files of random data. These files were winnowed down to about 10,000 through some heuristics gleaned from the complete collection of Atari ROM files. Finally, a classifier system scanned them using an Atari 2600 emulator to see if any of these random files were actually an Atari game. This project answers a question no one asked, no one wanted, and is a massive waste of resources: What if I shove a billion monkeys in a GPU and asked them to write a game for the Atari 2600?</p>

<p>Thanks to advances in GPUs, AI, and machine learning, we can now (very quickly) write a Python script that dumps garbage into 4KB ROMs and asks, <em>“does this look like a game?”</em>  This isn’t nostalgia, because my first console was an NES. This is about exploring something unimaginably vast and seeing if anything weird falls out.</p>

<h2 id="results-first">Results First</h2>

<p>Because no one reads below the fold, here’s an interactive emulator showcasing the most interesting Atari ROMs discovered. There’s no genetic algorithm here; just billions of random files run through an emulator. These are the best of the weird:</p>

<div>
  <p>
    <strong>WARNING: turn your volume down. There’s a bug in <a href="https://github.com/EmulatorJS/EmulatorJS">EmulatorJS</a>.</strong>
  </p>

  
</div>

<h2 id="problem-scope">Problem Scope</h2>

<p>Assume each Atari 2600 cartridge is a 4 kilobyte chunk of data. It’s a maximum of 4096 bytes, or 32,768 bits. That means there are $2^{32768}$ possible ROMs. For perspective:</p>

<ul>
  <li>That’s $10^{10159}$ potential Atari games.</li>
  <li>There are about $10^{20}$ grains of sand on Earth.</li>
  <li>And roughly $10^{80}$ protons in the visible universe.</li>
</ul>

<p>If you turned an entire datacenter of AI compute boxes onto this problem, it would likely take years before anything interesting was found. But with a little bit of smarts and actually reading a datasheet, the problem set is massively reduced. The basic search path to finding a ‘random’ Atari game would be to:</p>

<ol>
  <li>Generate a ROM, by dumping 4kB of data from /dev/random into a file.</li>
  <li>Run that file in an emulator</li>
  <li>Capture a screenshot or five</li>
  <li>Filter or score them with AI</li>
  <li>Save the best results for further investigation.</li>
</ol>

<p>This would work, if we had enough time to wait for black holes to devour the Universe. A better idea would be to front-load the pipeline with some simple checks to discard the absolute garbage before spinning up an emulator. It would help to know what a real Atari ROM would look like, simply to build some heuristics.</p>

<h2 id="heuristics">Heuristics</h2>

<p>I’m not going to emulate every possible ROM. I’m trying to find the <em>interesting</em> ones. This means filtering, and being smart about what we’re doing:</p>

<p><strong>Opcode Sanity</strong> The 6507 CPU (from here on out I’m calling it a 6502, to make you, specifically, angry) has 151 valid opcodes, and these opcodes are going to be all over the first half of the ROM. First I should check if there are a lot of opcodes in the data. These opcodes are:</p>

<p><code>
    0x00, 0x01, 0x05, 0x06, 0x08, 0x09, 0x0A, 0x0D, 0x0E, 0x10, 0x11, 0x15, 0x16, 0x18,
    0x19, 0x1D, 0x1E, 0x20, 0x21, 0x24, 0x25, 0x26, 0x28, 0x29, 0x2A, 0x2C, 0x2D, 0x2E,
    0x30, 0x31, 0x35, 0x36, 0x38, 0x39, 0x3D, 0x3E, 0x40, 0x41, 0x45, 0x46, 0x48, 0x49,
    0x4A, 0x4C, 0x4D, 0x4E, 0x50, 0x51, 0x55, 0x56, 0x58, 0x59, 0x5D, 0x5E, 0x60, 0x61,
    0x65, 0x66, 0x68, 0x69, 0x6A, 0x6C, 0x6D, 0x6E, 0x70, 0x71, 0x75, 0x76, 0x78, 0x79,
    0x7D, 0x7E, 0x81, 0x84, 0x85, 0x86, 0x88, 0x8A, 0x8C, 0x8D, 0x8E, 0x90, 0x91, 0x94,
    0x95, 0x96, 0x98, 0x99, 0x9A, 0x9D, 0xA0, 0xA1, 0xA2, 0xA4, 0xA5, 0xA6, 0xA8, 0xA9,
    0xAA, 0xAC, 0xAD, 0xAE, 0xB0, 0xB1, 0xB4, 0xB5, 0xB6, 0xB8, 0xB9, 0xBA, 0xBC, 0xBD,
    0xBE, 0xC0, 0xC1, 0xC4, 0xC5, 0xC6, 0xC8, 0xC9, 0xCA, 0xCC, 0xCD, 0xCE, 0xD0, 0xD1,
    0xD5, 0xD6, 0xD8, 0xD9, 0xDD, 0xDE, 0xE0, 0xE1, 0xE4, 0xE5, 0xE6, 0xE8, 0xE9, 0xEA,
    0xEC, 0xED, 0xEE, 0xF0, 0xF1, 0xF5, 0xF6, 0xF8, 0xF9, 0xFD, 0xFE
</code></p>

<p>Random data has about a 59% chance of being a valid opcode (151 out of 256 possible bytes). Real games should do much better than that. The structure of an Atari ROM has the first kilobyte as executable, with everything after that being data and graphics data. Analysing the full set commercial Atari ROMs reveals $&gt;$ 75% of the first kilobyte should be opcodes.</p>

<p><strong>Reset Vector Tomfoolery</strong> Atari ROMs need a valid reset vector to the code’s entry point. In other words, the last two bytes of the code should be between <code>0xF000</code> and <code>0xFFFF</code>. I can cheat on this by generating a 4k ROM minus two bytes, and then try every possible reset vector during emulation. <em>That’s only 4096 times as much work</em>.</p>

<p><strong>Input <em>and</em> Output?!</strong> I can look for access to the TIA (Television Interface Adapter) to see if it will output to the screen and the RIOT (RAM-I/O-Timer) to see if it will use any input or output. The TIA handles all graphics and sound, and does so with extremely specific patterns, discovered by looking at the patterns in all real Atari games. The pattern analysis revealed:</p>

<ul>
  <li>90% use zero page addressing (<code>STA $02</code>, <code>STX $06</code>, <code>STY $00</code>)</li>
  <li>80% are STA instructions, 10% STX, 10% STY</li>
  <li>Indexed addressing is common (<code>STA $00,X</code>, <code>STY $10,X</code>)</li>
  <li>WSYNC ($02) dominates - 18.8% of all TIA accesses (games constantly sync to the TV)</li>
</ul>

<p>The most critical TIA registers games actually use:
<code>
$02 (WSYNC) - 18.8% of accesses - TV synchronization
$1B (GRP0)  - 8.4% of accesses  - Player 0 graphics  
$1C (GRP1)  - 7.0% of accesses  - Player 1 graphics
$2A (HMOVE) - 4.9% of accesses  - Horizontal movement
$0E/$0F (PF1/PF2) - 7.8% combined - Playfield graphics
</code></p>

<p>Instead of blindly counting any store to the TIA range <code>$00-$2F</code>, I look for the specific instruction patterns real games use.</p>

<p>The RIOT registers are more complex due to memory mirroring. The Atari 2600 uses incomplete address decoding, causing the same hardware to appear at multiple addresses. The RIOT chip contains:</p>

<ul>
  <li>Timer registers: Canonical addresses <code>$0280-$0287</code>, but due to mirroring also appear at <code>$80-$87</code>, <code>$180-$187</code>, <code>$380-$387</code>, etc.</li>
  <li>I/O registers: Canonical addresses <code>$0294-$0297</code>, also mirrored at <code>$94-$97</code>, <code>$194-$197</code>, etc.</li>
</ul>

<p>In actual ROM files, you’ll find programmers using the shorter mirrored addresses because they’re more efficient. A typical instruction like <code>STA $80</code> (set timer) appears in the ROM as <code>85 80    ; STA $80 (zero page addressing)</code> rather than the wasteful <code>8D 80 02    ; STA $0280 (absolute addressing)</code>. My heuristics look for this.</p>

<p><strong>Branches and Jumps</strong> We’re looking for games here, and every game has loops and structure. These show up as branch instructions (for loops and conditionals) and jump instructions (for subroutines and major flow control). These show up as backwards branches (loops) and forward branches (conditionals).</p>

<ul>
  <li>Branch opcodes: <code>0x10, 0x30, 0x50, 0x70, 0x90, 0xB0, 0xD0, 0xF0</code></li>
  <li>Jump opcodes: <code>0x4C</code> (JMP absolute), <code>0x6C</code> (JMP indirect), <code>0x20</code> (JSR - jump to subroutine)</li>
</ul>

<p>Take all of this together, and we can assign some heuristics to validate what counts as a “game”.</p>

<h2 id="calibrating-against-reality">Calibrating Against Reality</h2>

<p>To validate these heuristics, I analyzed the <a href="https://archive.org/details/Atari2600FullRomCollectionReuploadByDataghost">Atari 2600 Full ROM Collection</a> from the Internet Archive - all 1,530 commercial Atari ROMs ever made. A Python script analyzed each ROM to count the incidence of these heuristics in commercial games.</p>

<h3 id="rom-characteristics-by-metric">ROM Characteristics by Metric</h3>

<p>Here’s what real Atari games actually look like:</p>

<table>
  <thead>
    <tr>
      <th>Metric</th>
      <th>Min</th>
      <th>5th %</th>
      <th>10th %</th>
      <th>25th %</th>
      <th>Median</th>
      <th>75th %</th>
      <th>90th %</th>
      <th>95th %</th>
      <th>Max</th>
      <th>Mean</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Valid Opcodes (%)</strong></td>
      <td>42.1%</td>
      <td>65.6%</td>
      <td>70.0%</td>
      <td>74.0%</td>
      <td>76.0%</td>
      <td>77.9%</td>
      <td>79.6%</td>
      <td>81.4%</td>
      <td>90.7%</td>
      <td>74.8%</td>
    </tr>
    <tr>
      <td><strong>TIA Accesses</strong></td>
      <td>12</td>
      <td><strong>93</strong></td>
      <td>118</td>
      <td>186</td>
      <td>282</td>
      <td>398</td>
      <td>567</td>
      <td>743</td>
      <td>2,847</td>
      <td><strong>341</strong></td>
    </tr>
    <tr>
      <td><strong>RIOT Accesses</strong></td>
      <td>3</td>
      <td><strong>34</strong></td>
      <td>47</td>
      <td>72</td>
      <td>111</td>
      <td>158</td>
      <td>219</td>
      <td>287</td>
      <td>891</td>
      <td><strong>134</strong></td>
    </tr>
    <tr>
      <td><strong>RIOT Timer Access</strong></td>
      <td>1</td>
      <td>22</td>
      <td>31</td>
      <td>51</td>
      <td>78</td>
      <td>115</td>
      <td>161</td>
      <td>211</td>
      <td>723</td>
      <td><strong>95</strong></td>
    </tr>
    <tr>
      <td><strong>RIOT I/O Access</strong></td>
      <td>0</td>
      <td>8</td>
      <td>12</td>
      <td>18</td>
      <td>28</td>
      <td>41</td>
      <td>58</td>
      <td>74</td>
      <td>201</td>
      <td><strong>33</strong></td>
    </tr>
    <tr>
      <td><strong>Branch Instructions</strong></td>
      <td>28</td>
      <td>177</td>
      <td>200</td>
      <td>296</td>
      <td>364</td>
      <td>528</td>
      <td>789</td>
      <td>1,066</td>
      <td>5,928</td>
      <td>457</td>
    </tr>
    <tr>
      <td><strong>Jump Instructions</strong></td>
      <td>3</td>
      <td>37</td>
      <td>54</td>
      <td>76</td>
      <td>111</td>
      <td>172</td>
      <td>260</td>
      <td>351</td>
      <td>1,495</td>
      <td>142</td>
    </tr>
    <tr>
      <td><strong>Unique Opcodes</strong></td>
      <td>29</td>
      <td>125</td>
      <td>129</td>
      <td>137</td>
      <td>143</td>
      <td>148</td>
      <td>151</td>
      <td>151</td>
      <td>151</td>
      <td>141</td>
    </tr>
  </tbody>
</table>

<h3 id="instruction-distribution">Instruction Distribution</h3>
<ul>
  <li><strong>STA (Store A)</strong>: 71.8% - Writing graphics data, colors, positions</li>
  <li><strong>STX (Store X)</strong>: 9.3% - Often used for indexed operations</li>
  <li><strong>STY (Store Y)</strong>: 8.5% - Similar to STX patterns</li>
  <li><strong>LDA (Load A)</strong>: 6.7% - Games also <em>read</em> from TIA (collision detection, etc.)</li>
  <li><strong>Other</strong>: 3.7% - Indexed addressing, absolute mode</li>
</ul>

<h3 id="addressing-modes">Addressing Modes</h3>
<ul>
  <li><strong>Zero page</strong>: 82.1% - <code>STA $02</code>, <code>STX $1B</code> (fastest, most common)</li>
  <li><strong>Zero page indexed</strong>: 13.2% - <code>STA $00,X</code>, <code>STY $10,X</code> (sprite positioning)</li>
  <li><strong>Absolute</strong>: 4.7% - <code>STA $001B</code> (rare, but exists)</li>
</ul>

<h3 id="most-accessed-tia-registers">Most Accessed TIA Registers</h3>
<div><pre><code>$02 (WSYNC) - 18.8% - TV horizontal sync (critical timing)
$1B (GRP0)  - 8.4%  - Player 0 graphics data
$1C (GRP1)  - 7.0%  - Player 1 graphics data  
$2A (HMOVE) - 4.9%  - Horizontal movement strobe
$0E (PF1)   - 4.1%  - Playfield graphics register 1
$0F (PF2)   - 3.7%  - Playfield graphics register 2
</code></pre></div>

<h3 id="riot-pattern-analysis">RIOT Pattern Analysis</h3>

<p>RIOT usage splits into two clear categories:</p>

<p><strong>Timer Operations (78% of RIOT usage)</strong></p>
<ul>
  <li><strong>Registers</strong>: <code>$80-$87</code> (1T, 8T, 64T, 1024T intervals plus timer read)</li>
  <li><strong>Purpose</strong>: Timing loops, delays, frame counting</li>
  <li><strong>Pattern</strong>: Write to set timer, read <code>$84</code> to check status</li>
</ul>

<p><strong>I/O Operations (22% of RIOT usage)</strong></p>
<ul>
  <li><strong>Registers</strong>: <code>$94-$97</code> (joystick/paddle inputs, console switches)</li>
  <li><strong>Purpose</strong>: Reading player input, detecting game reset</li>
  <li><strong>Pattern</strong>: Mostly reads (<code>LDA $94</code>), occasional writes for configuration</li>
</ul>

<h3 id="composite-scoring-updated">Composite Scoring (Updated)</h3>

<p>The corrected composite score uses realistic weights based on actual game analysis:</p>

<div><pre><code>Score = (Opcode Ratio × 0.25) + 
        (min(TIA_Accesses/150, 1.0) × 0.30) + 
        (min(RIOT_Accesses/50, 1.0) × 0.20) + 
        (min(Branches/200, 1.0) × 0.15) + 
        (min(Jumps/40, 1.0) × 0.10)
</code></pre></div>

<p>Real games scored between 0.393 and 1.004, with an average of 0.853. This composite score helps rank how “game-like” any ROM appears based on multiple characteristics rather than relying on a single metric. The weights prioritize opcodes and graphics capability (TIA) as the most important indicators, with control flow and I/O capability as secondary factors.</p>

<h2 id="mining-atari-games">Mining Atari Games</h2>

<p>The first implementation of this project was extremely simple – a single thread Python script that generated 4kB minus two bytes of random data, counted the number of branches, jumps, the number of valid opcodes, backwards branches (or a loop), and the number of vectors pointing to the ROM. This was very slow, around 300-400 ROMs checked per second.</p>

<p>This is a massively parallel search, though. My GTX 1070 (I know, except I exclusively play TF2, Rocket League, and Kerbal Space Program, <a href="https://bbenchoff.github.io/pages/SXM2PCIe.html">nvidia plz gib H200 + SXM5 PCIe carrier board</a>) has 1,920 CUDA cores compared to my CPU’s 20 cores. More importantly, each CUDA core can independently generate and analyze a ROM simultaneously. Instead of generating ROMs sequentially and passing them through a pipeline, I can generate a million ROMs in parallel, analyze them all at once, and only transfer the promising candidates back to the CPU.</p>

<p>The CUDA implementation moves all the heuristics directly onto the GPU. Each thread generates one 4KB ROM using CUDA’s random number generator, then immediately applies the same analysis pipeline: counting valid opcodes, detecting TIA/RIOT register accesses, finding branch patterns, and calculating the composite score. This was written with the the CuPy library:</p>

<div><pre><code><span>"""
CUDA Atari ROM Generator
"""</span>

<span>import</span> <span>cupy</span> <span>as</span> <span>cp</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>time</span>
<span>from</span> <span>pathlib</span> <span>import</span> <span>Path</span>

<span># Constants
</span><span>ROM_SIZE</span> <span>=</span> <span>4094</span>  <span># Reset vector tested later
</span><span>BATCH_SIZE</span> <span>=</span> <span>1024</span> <span>*</span> <span>256</span>

<span># Discovery thresholds based on observed patterns
</span><span>OPCODE_THRESHOLD</span> <span>=</span> <span>0.58</span>
<span>TIA_THRESHOLD</span> <span>=</span> <span>50</span>
<span>RIOT_THRESHOLD</span> <span>=</span> <span>13</span>
<span>BRANCH_THRESHOLD</span> <span>=</span> <span>150</span>
<span>JUMP_THRESHOLD</span> <span>=</span> <span>37</span>
<span>INSTRUCTION_VARIETY</span> <span>=</span> <span>100</span>
<span>MIN_SCORE</span> <span>=</span> <span>0.52</span>

<span># Valid 6502 opcodes (151 total)
</span><span>VALID_OPCODES</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>([</span>
    <span>0x00</span><span>,</span> <span>0x01</span><span>,</span> <span>0x05</span><span>,</span> <span>0x06</span><span>,</span> <span>0x08</span><span>,</span> <span>0x09</span><span>,</span> <span>0x0A</span><span>,</span> <span>0x0D</span><span>,</span> <span>0x0E</span><span>,</span> <span>0x10</span><span>,</span> <span>0x11</span><span>,</span> <span>0x15</span><span>,</span> <span>0x16</span><span>,</span> <span>0x18</span><span>,</span>
    <span>0x19</span><span>,</span> <span>0x1D</span><span>,</span> <span>0x1E</span><span>,</span> <span>0x20</span><span>,</span> <span>0x21</span><span>,</span> <span>0x24</span><span>,</span> <span>0x25</span><span>,</span> <span>0x26</span><span>,</span> <span>0x28</span><span>,</span> <span>0x29</span><span>,</span> <span>0x2A</span><span>,</span> <span>0x2C</span><span>,</span> <span>0x2D</span><span>,</span> <span>0x2E</span><span>,</span>
    <span>0x30</span><span>,</span> <span>0x31</span><span>,</span> <span>0x35</span><span>,</span> <span>0x36</span><span>,</span> <span>0x38</span><span>,</span> <span>0x39</span><span>,</span> <span>0x3D</span><span>,</span> <span>0x3E</span><span>,</span> <span>0x40</span><span>,</span> <span>0x41</span><span>,</span> <span>0x45</span><span>,</span> <span>0x46</span><span>,</span> <span>0x48</span><span>,</span> <span>0x49</span><span>,</span>
    <span>0x4A</span><span>,</span> <span>0x4C</span><span>,</span> <span>0x4D</span><span>,</span> <span>0x4E</span><span>,</span> <span>0x50</span><span>,</span> <span>0x51</span><span>,</span> <span>0x55</span><span>,</span> <span>0x56</span><span>,</span> <span>0x58</span><span>,</span> <span>0x59</span><span>,</span> <span>0x5D</span><span>,</span> <span>0x5E</span><span>,</span> <span>0x60</span><span>,</span> <span>0x61</span><span>,</span>
    <span>0x65</span><span>,</span> <span>0x66</span><span>,</span> <span>0x68</span><span>,</span> <span>0x69</span><span>,</span> <span>0x6A</span><span>,</span> <span>0x6C</span><span>,</span> <span>0x6D</span><span>,</span> <span>0x6E</span><span>,</span> <span>0x70</span><span>,</span> <span>0x71</span><span>,</span> <span>0x75</span><span>,</span> <span>0x76</span><span>,</span> <span>0x78</span><span>,</span> <span>0x79</span><span>,</span>
    <span>0x7D</span><span>,</span> <span>0x7E</span><span>,</span> <span>0x81</span><span>,</span> <span>0x84</span><span>,</span> <span>0x85</span><span>,</span> <span>0x86</span><span>,</span> <span>0x88</span><span>,</span> <span>0x8A</span><span>,</span> <span>0x8C</span><span>,</span> <span>0x8D</span><span>,</span> <span>0x8E</span><span>,</span> <span>0x90</span><span>,</span> <span>0x91</span><span>,</span> <span>0x94</span><span>,</span>
    <span>0x95</span><span>,</span> <span>0x96</span><span>,</span> <span>0x98</span><span>,</span> <span>0x99</span><span>,</span> <span>0x9A</span><span>,</span> <span>0x9D</span><span>,</span> <span>0xA0</span><span>,</span> <span>0xA1</span><span>,</span> <span>0xA2</span><span>,</span> <span>0xA4</span><span>,</span> <span>0xA5</span><span>,</span> <span>0xA6</span><span>,</span> <span>0xA8</span><span>,</span> <span>0xA9</span><span>,</span>
    <span>0xAA</span><span>,</span> <span>0xAC</span><span>,</span> <span>0xAD</span><span>,</span> <span>0xAE</span><span>,</span> <span>0xB0</span><span>,</span> <span>0xB1</span><span>,</span> <span>0xB4</span><span>,</span> <span>0xB5</span><span>,</span> <span>0xB6</span><span>,</span> <span>0xB8</span><span>,</span> <span>0xB9</span><span>,</span> <span>0xBA</span><span>,</span> <span>0xBC</span><span>,</span> <span>0xBD</span><span>,</span>
    <span>0xBE</span><span>,</span> <span>0xC0</span><span>,</span> <span>0xC1</span><span>,</span> <span>0xC4</span><span>,</span> <span>0xC5</span><span>,</span> <span>0xC6</span><span>,</span> <span>0xC8</span><span>,</span> <span>0xC9</span><span>,</span> <span>0xCA</span><span>,</span> <span>0xCC</span><span>,</span> <span>0xCD</span><span>,</span> <span>0xCE</span><span>,</span> <span>0xD0</span><span>,</span> <span>0xD1</span><span>,</span>
    <span>0xD5</span><span>,</span> <span>0xD6</span><span>,</span> <span>0xD8</span><span>,</span> <span>0xD9</span><span>,</span> <span>0xDD</span><span>,</span> <span>0xDE</span><span>,</span> <span>0xE0</span><span>,</span> <span>0xE1</span><span>,</span> <span>0xE4</span><span>,</span> <span>0xE5</span><span>,</span> <span>0xE6</span><span>,</span> <span>0xE8</span><span>,</span> <span>0xE9</span><span>,</span> <span>0xEA</span><span>,</span>
    <span>0xEC</span><span>,</span> <span>0xED</span><span>,</span> <span>0xEE</span><span>,</span> <span>0xF0</span><span>,</span> <span>0xF1</span><span>,</span> <span>0xF5</span><span>,</span> <span>0xF6</span><span>,</span> <span>0xF8</span><span>,</span> <span>0xF9</span><span>,</span> <span>0xFD</span><span>,</span> <span>0xFE</span>
<span>],</span> <span>dtype</span><span>=</span><span>np</span><span>.</span><span>uint8</span><span>)</span>

<span># Control flow opcodes
</span><span>BRANCH_OPCODES</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>([</span><span>0x10</span><span>,</span> <span>0x30</span><span>,</span> <span>0x50</span><span>,</span> <span>0x70</span><span>,</span> <span>0x90</span><span>,</span> <span>0xB0</span><span>,</span> <span>0xD0</span><span>,</span> <span>0xF0</span><span>],</span> <span>dtype</span><span>=</span><span>np</span><span>.</span><span>uint8</span><span>)</span>
<span>JUMP_OPCODES</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>([</span><span>0x4C</span><span>,</span> <span>0x6C</span><span>,</span> <span>0x20</span><span>],</span> <span>dtype</span><span>=</span><span>np</span><span>.</span><span>uint8</span><span>)</span>

<span>def</span> <span>create_lookup_tables</span><span>():</span>
    <span>"""Create GPU lookup tables for ROM analysis"""</span>
    <span>valid_lut</span> <span>=</span> <span>cp</span><span>.</span><span>zeros</span><span>(</span><span>256</span><span>,</span> <span>dtype</span><span>=</span><span>cp</span><span>.</span><span>bool_</span><span>)</span>
    <span>valid_lut</span><span>[</span><span>VALID_OPCODES</span><span>]</span> <span>=</span> <span>True</span>
    
    <span>branch_lut</span> <span>=</span> <span>cp</span><span>.</span><span>zeros</span><span>(</span><span>256</span><span>,</span> <span>dtype</span><span>=</span><span>cp</span><span>.</span><span>bool_</span><span>)</span>
    <span>branch_lut</span><span>[</span><span>BRANCH_OPCODES</span><span>]</span> <span>=</span> <span>True</span>
    
    <span>jump_lut</span> <span>=</span> <span>cp</span><span>.</span><span>zeros</span><span>(</span><span>256</span><span>,</span> <span>dtype</span><span>=</span><span>cp</span><span>.</span><span>bool_</span><span>)</span>
    <span>jump_lut</span><span>[</span><span>JUMP_OPCODES</span><span>]</span> <span>=</span> <span>True</span>
    
    <span># TIA instruction lookups
</span>    <span>tia_store_lut</span> <span>=</span> <span>cp</span><span>.</span><span>zeros</span><span>(</span><span>256</span><span>,</span> <span>dtype</span><span>=</span><span>cp</span><span>.</span><span>bool_</span><span>)</span>
    <span>tia_store_lut</span><span>[[</span><span>0x85</span><span>,</span> <span>0x86</span><span>,</span> <span>0x84</span><span>,</span> <span>0x95</span><span>,</span> <span>0x96</span><span>,</span> <span>0x94</span><span>]]</span> <span>=</span> <span>True</span>
    
    <span>tia_load_lut</span> <span>=</span> <span>cp</span><span>.</span><span>zeros</span><span>(</span><span>256</span><span>,</span> <span>dtype</span><span>=</span><span>cp</span><span>.</span><span>bool_</span><span>)</span>
    <span>tia_load_lut</span><span>[[</span><span>0xA5</span><span>,</span> <span>0xA6</span><span>,</span> <span>0xA4</span><span>,</span> <span>0xB5</span><span>,</span> <span>0xB6</span><span>,</span> <span>0xB4</span><span>]]</span> <span>=</span> <span>True</span>
    
    <span>tia_abs_lut</span> <span>=</span> <span>cp</span><span>.</span><span>zeros</span><span>(</span><span>256</span><span>,</span> <span>dtype</span><span>=</span><span>cp</span><span>.</span><span>bool_</span><span>)</span>
    <span>tia_abs_lut</span><span>[[</span><span>0x8D</span><span>,</span> <span>0x8E</span><span>,</span> <span>0x8C</span><span>,</span> <span>0xAD</span><span>,</span> <span>0xAE</span><span>,</span> <span>0xAC</span><span>]]</span> <span>=</span> <span>True</span>
    
    <span># RIOT instruction lookups
</span>    <span>riot_access_lut</span> <span>=</span> <span>cp</span><span>.</span><span>zeros</span><span>(</span><span>256</span><span>,</span> <span>dtype</span><span>=</span><span>cp</span><span>.</span><span>bool_</span><span>)</span>
    <span>riot_access_lut</span><span>[[</span><span>0x85</span><span>,</span> <span>0x86</span><span>,</span> <span>0x84</span><span>,</span> <span>0xA5</span><span>,</span> <span>0xA6</span><span>,</span> <span>0xA4</span><span>]]</span> <span>=</span> <span>True</span>
    
    <span># Address range masks
</span>    <span>tia_range_mask</span> <span>=</span> <span>cp</span><span>.</span><span>arange</span><span>(</span><span>256</span><span>,</span> <span>dtype</span><span>=</span><span>cp</span><span>.</span><span>uint8</span><span>)</span> <span>&lt;=</span> <span>0x2F</span>
    <span>riot_timer_mask</span> <span>=</span> <span>(</span><span>cp</span><span>.</span><span>arange</span><span>(</span><span>256</span><span>,</span> <span>dtype</span><span>=</span><span>cp</span><span>.</span><span>uint8</span><span>)</span> <span>&gt;=</span> <span>0x80</span><span>)</span> <span>&amp;</span> <span>(</span><span>cp</span><span>.</span><span>arange</span><span>(</span><span>256</span><span>,</span> <span>dtype</span><span>=</span><span>cp</span><span>.</span><span>uint8</span><span>)</span> <span>&lt;=</span> <span>0x87</span><span>)</span>
    <span>riot_io_mask</span> <span>=</span> <span>(</span><span>cp</span><span>.</span><span>arange</span><span>(</span><span>256</span><span>,</span> <span>dtype</span><span>=</span><span>cp</span><span>.</span><span>uint8</span><span>)</span> <span>&gt;=</span> <span>0x94</span><span>)</span> <span>&amp;</span> <span>(</span><span>cp</span><span>.</span><span>arange</span><span>(</span><span>256</span><span>,</span> <span>dtype</span><span>=</span><span>cp</span><span>.</span><span>uint8</span><span>)</span> <span>&lt;=</span> <span>0x97</span><span>)</span>
    
    <span>return</span> <span>{</span>
        <span>'valid'</span><span>:</span> <span>valid_lut</span><span>,</span>
        <span>'branch'</span><span>:</span> <span>branch_lut</span><span>,</span>
        <span>'jump'</span><span>:</span> <span>jump_lut</span><span>,</span>
        <span>'tia_store'</span><span>:</span> <span>tia_store_lut</span><span>,</span>
        <span>'tia_load'</span><span>:</span> <span>tia_load_lut</span><span>,</span>
        <span>'tia_abs'</span><span>:</span> <span>tia_abs_lut</span><span>,</span>
        <span>'riot_access'</span><span>:</span> <span>riot_access_lut</span><span>,</span>
        <span>'tia_range'</span><span>:</span> <span>tia_range_mask</span><span>,</span>
        <span>'riot_timer'</span><span>:</span> <span>riot_timer_mask</span><span>,</span>
        <span>'riot_io'</span><span>:</span> <span>riot_io_mask</span>
    <span>}</span>

<span>def</span> <span>analyze_roms</span><span>(</span><span>roms</span><span>,</span> <span>lut</span><span>):</span>
    <span>"""Analyze ROMs for game-like patterns"""</span>
    <span>batch_size</span> <span>=</span> <span>roms</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span>
    
    <span># Opcode analysis
</span>    <span>valid_opcodes_count</span> <span>=</span> <span>cp</span><span>.</span><span>sum</span><span>(</span><span>lut</span><span>[</span><span>'valid'</span><span>][</span><span>roms</span><span>],</span> <span>axis</span><span>=</span><span>1</span><span>)</span>
    <span>opcode_ratio</span> <span>=</span> <span>valid_opcodes_count</span><span>.</span><span>astype</span><span>(</span><span>cp</span><span>.</span><span>float32</span><span>)</span> <span>/</span> <span>ROM_SIZE</span>
    
    <span># Control flow analysis
</span>    <span>branch_count</span> <span>=</span> <span>cp</span><span>.</span><span>sum</span><span>(</span><span>lut</span><span>[</span><span>'branch'</span><span>][</span><span>roms</span><span>],</span> <span>axis</span><span>=</span><span>1</span><span>)</span>
    <span>jump_count</span> <span>=</span> <span>cp</span><span>.</span><span>sum</span><span>(</span><span>lut</span><span>[</span><span>'jump'</span><span>][</span><span>roms</span><span>],</span> <span>axis</span><span>=</span><span>1</span><span>)</span>
    
    <span># TIA analysis
</span>    <span>tia_accesses</span> <span>=</span> <span>cp</span><span>.</span><span>zeros</span><span>(</span><span>batch_size</span><span>,</span> <span>dtype</span><span>=</span><span>cp</span><span>.</span><span>int32</span><span>)</span>
    
    <span># Zero page addressing
</span>    <span>tia_store_zp</span> <span>=</span> <span>lut</span><span>[</span><span>'tia_store'</span><span>][</span><span>roms</span><span>[:,</span> <span>:</span><span>-</span><span>1</span><span>]]</span> <span>&amp;</span> <span>lut</span><span>[</span><span>'tia_range'</span><span>][</span><span>roms</span><span>[:,</span> <span>1</span><span>:]]</span>
    <span>tia_load_zp</span> <span>=</span> <span>lut</span><span>[</span><span>'tia_load'</span><span>][</span><span>roms</span><span>[:,</span> <span>:</span><span>-</span><span>1</span><span>]]</span> <span>&amp;</span> <span>lut</span><span>[</span><span>'tia_range'</span><span>][</span><span>roms</span><span>[:,</span> <span>1</span><span>:]]</span>
    <span>tia_zp_total</span> <span>=</span> <span>cp</span><span>.</span><span>sum</span><span>(</span><span>tia_store_zp</span> <span>|</span> <span>tia_load_zp</span><span>,</span> <span>axis</span><span>=</span><span>1</span><span>)</span>
    <span>tia_accesses</span> <span>+=</span> <span>tia_zp_total</span>
    
    <span># Absolute addressing
</span>    <span>tia_abs_positions</span> <span>=</span> <span>lut</span><span>[</span><span>'tia_abs'</span><span>][</span><span>roms</span><span>[:,</span> <span>:</span><span>-</span><span>2</span><span>]]</span>
    <span>tia_abs_targets</span> <span>=</span> <span>lut</span><span>[</span><span>'tia_range'</span><span>][</span><span>roms</span><span>[:,</span> <span>1</span><span>:</span><span>-</span><span>1</span><span>]]</span> <span>&amp;</span> <span>(</span><span>roms</span><span>[:,</span> <span>2</span><span>:]</span> <span>==</span> <span>0x00</span><span>)</span>
    <span>tia_abs_total</span> <span>=</span> <span>cp</span><span>.</span><span>sum</span><span>(</span><span>tia_abs_positions</span> <span>&amp;</span> <span>tia_abs_targets</span><span>,</span> <span>axis</span><span>=</span><span>1</span><span>)</span>
    <span>tia_accesses</span> <span>+=</span> <span>tia_abs_total</span>
    
    <span># RIOT analysis
</span>    <span>riot_accesses</span> <span>=</span> <span>cp</span><span>.</span><span>zeros</span><span>(</span><span>batch_size</span><span>,</span> <span>dtype</span><span>=</span><span>cp</span><span>.</span><span>int32</span><span>)</span>
    
    <span># Timer access
</span>    <span>riot_timer_positions</span> <span>=</span> <span>lut</span><span>[</span><span>'riot_access'</span><span>][</span><span>roms</span><span>[:,</span> <span>:</span><span>-</span><span>1</span><span>]]</span>
    <span>riot_timer_targets</span> <span>=</span> <span>lut</span><span>[</span><span>'riot_timer'</span><span>][</span><span>roms</span><span>[:,</span> <span>1</span><span>:]]</span>
    <span>riot_timer_hits</span> <span>=</span> <span>cp</span><span>.</span><span>sum</span><span>(</span><span>riot_timer_positions</span> <span>&amp;</span> <span>riot_timer_targets</span><span>,</span> <span>axis</span><span>=</span><span>1</span><span>)</span>
    <span>riot_accesses</span> <span>+=</span> <span>riot_timer_hits</span>
    
    <span># I/O access
</span>    <span>riot_io_positions</span> <span>=</span> <span>lut</span><span>[</span><span>'riot_access'</span><span>][</span><span>roms</span><span>[:,</span> <span>:</span><span>-</span><span>1</span><span>]]</span>
    <span>riot_io_targets</span> <span>=</span> <span>lut</span><span>[</span><span>'riot_io'</span><span>][</span><span>roms</span><span>[:,</span> <span>1</span><span>:]]</span>
    <span>riot_io_hits</span> <span>=</span> <span>cp</span><span>.</span><span>sum</span><span>(</span><span>riot_io_positions</span> <span>&amp;</span> <span>riot_io_targets</span><span>,</span> <span>axis</span><span>=</span><span>1</span><span>)</span>
    <span>riot_accesses</span> <span>+=</span> <span>riot_io_hits</span>
    
    <span># Unique opcode counting in first 1KB (code section)
</span>    <span>unique_opcodes</span> <span>=</span> <span>cp</span><span>.</span><span>zeros</span><span>(</span><span>batch_size</span><span>,</span> <span>dtype</span><span>=</span><span>cp</span><span>.</span><span>int32</span><span>)</span>
    <span>first_kb</span> <span>=</span> <span>roms</span><span>[:,</span> <span>:</span><span>1024</span><span>]</span>  <span># First 1KB where code typically resides
</span>    
    <span># Count unique valid opcodes in the code section
</span>    <span>for</span> <span>opcode</span> <span>in</span> <span>VALID_OPCODES</span><span>:</span>
        <span>has_opcode</span> <span>=</span> <span>cp</span><span>.</span><span>any</span><span>(</span><span>first_kb</span> <span>==</span> <span>opcode</span><span>,</span> <span>axis</span><span>=</span><span>1</span><span>)</span>
        <span>unique_opcodes</span> <span>+=</span> <span>has_opcode</span><span>.</span><span>astype</span><span>(</span><span>cp</span><span>.</span><span>int32</span><span>)</span>
    
    <span># Composite score
</span>    <span>scores</span> <span>=</span> <span>(</span>
        <span>opcode_ratio</span> <span>*</span> <span>0.25</span> <span>+</span> 
        <span>cp</span><span>.</span><span>minimum</span><span>(</span><span>tia_accesses</span> <span>/</span> <span>150.0</span><span>,</span> <span>1.0</span><span>)</span> <span>*</span> <span>0.30</span> <span>+</span>
        <span>cp</span><span>.</span><span>minimum</span><span>(</span><span>riot_accesses</span> <span>/</span> <span>50.0</span><span>,</span> <span>1.0</span><span>)</span> <span>*</span> <span>0.20</span> <span>+</span>
        <span>cp</span><span>.</span><span>minimum</span><span>(</span><span>branch_count</span> <span>/</span> <span>200.0</span><span>,</span> <span>1.0</span><span>)</span> <span>*</span> <span>0.15</span> <span>+</span>
        <span>cp</span><span>.</span><span>minimum</span><span>(</span><span>jump_count</span> <span>/</span> <span>40.0</span><span>,</span> <span>1.0</span><span>)</span> <span>*</span> <span>0.10</span>
    <span>)</span>
    
    <span># Promising ROM detection
</span>    <span>promising</span> <span>=</span> <span>(</span>
        <span>(</span><span>opcode_ratio</span> <span>&gt;=</span> <span>OPCODE_THRESHOLD</span><span>)</span> <span>&amp;</span>
        <span>(</span><span>tia_accesses</span> <span>&gt;=</span> <span>TIA_THRESHOLD</span><span>)</span> <span>&amp;</span>
        <span>(</span><span>riot_accesses</span> <span>&gt;=</span> <span>RIOT_THRESHOLD</span><span>)</span> <span>&amp;</span>
        <span>(</span><span>branch_count</span> <span>&gt;=</span> <span>BRANCH_THRESHOLD</span><span>)</span> <span>&amp;</span>
        <span>(</span><span>jump_count</span> <span>&gt;=</span> <span>JUMP_THRESHOLD</span><span>)</span> <span>&amp;</span>
        <span>(</span><span>unique_opcodes</span> <span>&gt;=</span> <span>INSTRUCTION_VARIETY</span><span>)</span> <span>&amp;</span>
        <span>(</span><span>scores</span> <span>&gt;=</span> <span>MIN_SCORE</span><span>)</span>
    <span>)</span>
    
    <span>return</span> <span>{</span>
        <span>'scores'</span><span>:</span> <span>scores</span><span>,</span>
        <span>'opcode_ratio'</span><span>:</span> <span>opcode_ratio</span><span>,</span>
        <span>'tia_accesses'</span><span>:</span> <span>tia_accesses</span><span>,</span>
        <span>'riot_accesses'</span><span>:</span> <span>riot_accesses</span><span>,</span>
        <span>'branch_count'</span><span>:</span> <span>branch_count</span><span>,</span>
        <span>'jump_count'</span><span>:</span> <span>jump_count</span><span>,</span>
        <span>'unique_opcodes'</span><span>:</span> <span>unique_opcodes</span><span>,</span>
        <span>'promising'</span><span>:</span> <span>promising</span>
    <span>}</span>

<span>def</span> <span>save_promising_rom</span><span>(</span><span>rom_data</span><span>,</span> <span>score</span><span>,</span> <span>rom_id</span><span>,</span> <span>output_dir</span><span>):</span>
    <span>"""Save promising ROM with: number_score_timestamp.bin"""</span>
    <span>timestamp</span> <span>=</span> <span>int</span><span>(</span><span>time</span><span>.</span><span>time</span><span>())</span>
    <span>filename</span> <span>=</span> <span>f</span><span>"</span><span>{</span><span>rom_id</span><span>:</span><span>06</span><span>d</span><span>}</span><span>_</span><span>{</span><span>score</span><span>:</span><span>.</span><span>3</span><span>f</span><span>}</span><span>_</span><span>{</span><span>timestamp</span><span>}</span><span>.bin"</span>
    <span>filepath</span> <span>=</span> <span>output_dir</span> <span>/</span> <span>filename</span>
    
    <span>with</span> <span>open</span><span>(</span><span>filepath</span><span>,</span> <span>'wb'</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
        <span>f</span><span>.</span><span>write</span><span>(</span><span>rom_data</span><span>.</span><span>tobytes</span><span>())</span>
    
    <span>return</span> <span>filename</span>

<span>def</span> <span>main</span><span>():</span>
    <span>print</span><span>(</span><span>"Finite Atari Machine - Streamlined CUDA Generator"</span><span>)</span>
    <span>print</span><span>(</span><span>"="</span> <span>*</span> <span>60</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>"Batch size: </span><span>{</span><span>BATCH_SIZE</span><span>:</span><span>,</span><span>}</span><span> ROMs per batch"</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>"ROM size: </span><span>{</span><span>ROM_SIZE</span><span>:</span><span>,</span><span>}</span><span> bytes"</span><span>)</span>
    <span>print</span><span>()</span>
    <span>print</span><span>(</span><span>"Thresholds:"</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>"  Opcodes: </span><span>{</span><span>OPCODE_THRESHOLD</span><span>:</span><span>.</span><span>1</span><span>%</span><span>}</span><span>"</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>"  TIA: </span><span>{</span><span>TIA_THRESHOLD</span><span>}</span><span>+"</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>"  RIOT: </span><span>{</span><span>RIOT_THRESHOLD</span><span>}</span><span>+"</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>"  Branches: </span><span>{</span><span>BRANCH_THRESHOLD</span><span>}</span><span>+"</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>"  Jumps: </span><span>{</span><span>JUMP_THRESHOLD</span><span>}</span><span>+"</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>"  Unique opcodes: </span><span>{</span><span>INSTRUCTION_VARIETY</span><span>}</span><span>+"</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>"  Min score: </span><span>{</span><span>MIN_SCORE</span><span>:</span><span>.</span><span>2</span><span>f</span><span>}</span><span>"</span><span>)</span>
    <span>print</span><span>()</span>
    
    <span># GPU info
</span>    <span>try</span><span>:</span>
        <span>gpu_props</span> <span>=</span> <span>cp</span><span>.</span><span>cuda</span><span>.</span><span>runtime</span><span>.</span><span>getDeviceProperties</span><span>(</span><span>0</span><span>)</span>
        <span>gpu_name</span> <span>=</span> <span>gpu_props</span><span>[</span><span>'name'</span><span>].</span><span>decode</span><span>()</span>
        <span>total_mem</span> <span>=</span> <span>cp</span><span>.</span><span>cuda</span><span>.</span><span>runtime</span><span>.</span><span>memGetInfo</span><span>()[</span><span>1</span><span>]</span> <span>//</span> <span>1024</span><span>**</span><span>2</span>
        <span>print</span><span>(</span><span>f</span><span>"GPU: </span><span>{</span><span>gpu_name</span><span>}</span><span>"</span><span>)</span>
        <span>print</span><span>(</span><span>f</span><span>"Memory: </span><span>{</span><span>total_mem</span><span>:</span><span>,</span><span>}</span><span> MB"</span><span>)</span>
    <span>except</span> <span>Exception</span><span>:</span>
        <span>print</span><span>(</span><span>"GPU: CuPy device detected"</span><span>)</span>
    
    <span>print</span><span>(</span><span>"</span><span>\n</span><span>Initializing lookup tables..."</span><span>)</span>
    
    <span># Setup
</span>    <span>output_dir</span> <span>=</span> <span>Path</span><span>(</span><span>"finite_atari_roms"</span><span>)</span>
    <span>output_dir</span><span>.</span><span>mkdir</span><span>(</span><span>exist_ok</span><span>=</span><span>True</span><span>)</span>
    
    <span>lookup_tables</span> <span>=</span> <span>create_lookup_tables</span><span>()</span>
    
    <span># Statistics
</span>    <span>total_generated</span> <span>=</span> <span>0</span>
    <span>promising_found</span> <span>=</span> <span>0</span>
    <span>start_time</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>
    <span>last_report</span> <span>=</span> <span>start_time</span>
    <span>best_score_ever</span> <span>=</span> <span>0.0</span>
    
    <span>print</span><span>(</span><span>"Starting ROM generation..."</span><span>)</span>
    <span>print</span><span>(</span><span>"="</span> <span>*</span> <span>60</span><span>)</span>
    
    <span>try</span><span>:</span>
        <span>while</span> <span>True</span><span>:</span>
            <span>batch_start</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>
            
            <span># Generate batch of ROMs
</span>            <span>roms</span> <span>=</span> <span>cp</span><span>.</span><span>random</span><span>.</span><span>randint</span><span>(</span><span>0</span><span>,</span> <span>256</span><span>,</span> <span>size</span><span>=</span><span>(</span><span>BATCH_SIZE</span><span>,</span> <span>ROM_SIZE</span><span>),</span> <span>dtype</span><span>=</span><span>cp</span><span>.</span><span>uint8</span><span>)</span>
            
            <span># Analyze ROMs
</span>            <span>analysis</span> <span>=</span> <span>analyze_roms</span><span>(</span><span>roms</span><span>,</span> <span>lookup_tables</span><span>)</span>
            
            <span># Track best score
</span>            <span>current_best</span> <span>=</span> <span>float</span><span>(</span><span>cp</span><span>.</span><span>max</span><span>(</span><span>analysis</span><span>[</span><span>'scores'</span><span>]))</span>
            <span>if</span> <span>current_best</span> <span>&gt;</span> <span>best_score_ever</span><span>:</span>
                <span>best_score_ever</span> <span>=</span> <span>current_best</span>
            
            <span># Check for promising ROMs
</span>            <span>promising_indices</span> <span>=</span> <span>cp</span><span>.</span><span>where</span><span>(</span><span>analysis</span><span>[</span><span>'promising'</span><span>])[</span><span>0</span><span>]</span>
            
            <span>if</span> <span>len</span><span>(</span><span>promising_indices</span><span>)</span> <span>&gt;</span> <span>0</span><span>:</span>
                <span># Save promising ROMs
</span>                <span>promising_roms</span> <span>=</span> <span>cp</span><span>.</span><span>asnumpy</span><span>(</span><span>roms</span><span>[</span><span>promising_indices</span><span>])</span>
                <span>promising_scores</span> <span>=</span> <span>cp</span><span>.</span><span>asnumpy</span><span>(</span><span>analysis</span><span>[</span><span>'scores'</span><span>][</span><span>promising_indices</span><span>])</span>
                
                <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>len</span><span>(</span><span>promising_indices</span><span>)):</span>
                    <span>filename</span> <span>=</span> <span>save_promising_rom</span><span>(</span>
                        <span>promising_roms</span><span>[</span><span>i</span><span>],</span> <span>promising_scores</span><span>[</span><span>i</span><span>],</span> <span>promising_found</span><span>,</span> <span>output_dir</span>
                    <span>)</span>
                    <span>promising_found</span> <span>+=</span> <span>1</span>
            
            <span>total_generated</span> <span>+=</span> <span>BATCH_SIZE</span>
            <span>batch_time</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span> <span>-</span> <span>batch_start</span>
            
            <span># Progress reporting
</span>            <span>current_time</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>
            <span>if</span> <span>current_time</span> <span>-</span> <span>last_report</span> <span>&gt;=</span> <span>4</span><span>:</span>
                <span># Get best ROM stats for this batch
</span>                <span>scores</span> <span>=</span> <span>cp</span><span>.</span><span>asnumpy</span><span>(</span><span>analysis</span><span>[</span><span>'scores'</span><span>])</span>
                <span>best_idx</span> <span>=</span> <span>np</span><span>.</span><span>argmax</span><span>(</span><span>scores</span><span>)</span>
                <span>best_opcodes</span> <span>=</span> <span>float</span><span>(</span><span>analysis</span><span>[</span><span>'opcode_ratio'</span><span>][</span><span>best_idx</span><span>])</span>
                <span>best_tia</span> <span>=</span> <span>int</span><span>(</span><span>analysis</span><span>[</span><span>'tia_accesses'</span><span>][</span><span>best_idx</span><span>])</span>
                <span>best_riot</span> <span>=</span> <span>int</span><span>(</span><span>analysis</span><span>[</span><span>'riot_accesses'</span><span>][</span><span>best_idx</span><span>])</span>
                <span>best_branches</span> <span>=</span> <span>int</span><span>(</span><span>analysis</span><span>[</span><span>'branch_count'</span><span>][</span><span>best_idx</span><span>])</span>
                <span>best_jumps</span> <span>=</span> <span>int</span><span>(</span><span>analysis</span><span>[</span><span>'jump_count'</span><span>][</span><span>best_idx</span><span>])</span>
                
                <span>elapsed</span> <span>=</span> <span>current_time</span> <span>-</span> <span>start_time</span>
                <span>rate</span> <span>=</span> <span>total_generated</span> <span>/</span> <span>elapsed</span>
                <span>success_rate</span> <span>=</span> <span>promising_found</span> <span>/</span> <span>total_generated</span> <span>*</span> <span>100</span> <span>if</span> <span>total_generated</span> <span>&gt;</span> <span>0</span> <span>else</span> <span>0</span>
                
                <span>print</span><span>(</span><span>f</span><span>"</span><span>\r</span><span>Generated: </span><span>{</span><span>total_generated</span><span>:</span><span>,</span><span>}</span><span> | Found: </span><span>{</span><span>promising_found</span><span>}</span><span> | "</span>
                      <span>f</span><span>"Success: </span><span>{</span><span>success_rate</span><span>:</span><span>.</span><span>8</span><span>f</span><span>}</span><span>% | Rate: </span><span>{</span><span>rate</span><span>:</span><span>,.</span><span>0</span><span>f</span><span>}</span><span>/sec | "</span>
                      <span>f</span><span>"Best: </span><span>{</span><span>best_score_ever</span><span>:</span><span>.</span><span>3</span><span>f</span><span>}</span><span> | "</span>
                      <span>f</span><span>"Op:</span><span>{</span><span>best_opcodes</span><span>:</span><span>.</span><span>1</span><span>%</span><span>}</span><span> TIA:</span><span>{</span><span>best_tia</span><span>}</span><span> RIOT:</span><span>{</span><span>best_riot</span><span>}</span><span> Br:</span><span>{</span><span>best_branches</span><span>}</span><span> Jmp:</span><span>{</span><span>best_jumps</span><span>}</span><span>"</span><span>,</span> 
                      <span>end</span><span>=</span><span>""</span><span>,</span> <span>flush</span><span>=</span><span>True</span><span>)</span>
                
                <span>last_report</span> <span>=</span> <span>current_time</span>
    
    <span>except</span> <span>KeyboardInterrupt</span><span>:</span>
        <span>elapsed</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span> <span>-</span> <span>start_time</span>
        <span>rate</span> <span>=</span> <span>total_generated</span> <span>/</span> <span>elapsed</span>
        <span>success_rate</span> <span>=</span> <span>promising_found</span> <span>/</span> <span>total_generated</span> <span>*</span> <span>100</span> <span>if</span> <span>total_generated</span> <span>&gt;</span> <span>0</span> <span>else</span> <span>0</span>
        
        <span>print</span><span>(</span><span>f</span><span>"</span><span>\n\n</span><span>Stopped after </span><span>{</span><span>elapsed</span><span>:</span><span>.</span><span>1</span><span>f</span><span>}</span><span> seconds"</span><span>)</span>
        <span>print</span><span>(</span><span>f</span><span>"Total ROMs generated: </span><span>{</span><span>total_generated</span><span>:</span><span>,</span><span>}</span><span>"</span><span>)</span>
        <span>print</span><span>(</span><span>f</span><span>"Promising ROMs found: </span><span>{</span><span>promising_found</span><span>}</span><span>"</span><span>)</span>
        <span>print</span><span>(</span><span>f</span><span>"Success rate: </span><span>{</span><span>success_rate</span><span>:</span><span>.</span><span>8</span><span>f</span><span>}</span><span>%"</span><span>)</span>
        <span>print</span><span>(</span><span>f</span><span>"Average rate: </span><span>{</span><span>rate</span><span>:</span><span>,.</span><span>0</span><span>f</span><span>}</span><span> ROMs/second"</span><span>)</span>
        <span>print</span><span>(</span><span>f</span><span>"Best score achieved: </span><span>{</span><span>best_score_ever</span><span>:</span><span>.</span><span>4</span><span>f</span><span>}</span><span>"</span><span>)</span>
        <span>print</span><span>(</span><span>f</span><span>"Results saved in: </span><span>{</span><span>output_dir</span><span>}</span><span>"</span><span>)</span>

<span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span><span>:</span>
    <span>main</span><span>()</span>

</code></pre></div>

<p>…Which gave me a whopping 60,000 ‘random’ ROMs checked per second. With the heuristics, I was finding one ‘promising’ ROM for every 2.59 million ROMs generated. It’s one ROM every few minutes.</p>

<h2 id="first-results-and-why-machine-learning-didnt-work">First Results And Why Machine Learning Didn’t Work</h2>

<p>After checking <em>billions and billions</em> of potential ROMs, I had a collection of about 10,000 that passed the heuristics laid out above. I could move onto the next step: checking them all in an emulator.</p>

<p>I tried two methods of running these 10,000 ROMs in an emulator to see if there was anything ‘game-like’. The first was a classifier, trained on ~1,500 real commercial Atari ROMs (positives) and ~1,500 GPU-generated random ROMs (negatives). These trained a model (Random Forest) with features ranging from “Would the emulator execute the ROM”, to more pertinate features such as, “how many times did the registers of the TIA change during 2 seconds of execution time.”</p>

<p>This is, academically, the correct way to do this. By scripting in output from <a href="https://stella-emu.github.io/">Stella</a>, and <a href="https://www.mamedev.org/">MAME</a>, I was able to build a classifier that would tell me if a random ROM <em>could</em> run on an Atari. Unfortunately, it didn’t work. The top-scoring results were mostly all black screens when run on an emulator. This made sense when I looked at the model. The most important features were:</p>

<table>
  <thead>
    <tr>
      <th>Feature</th>
      <th>Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>execution_time</td>
      <td>0.9847</td>
    </tr>
    <tr>
      <td>output_lines</td>
      <td>0.0086</td>
    </tr>
    <tr>
      <td>stdout_length</td>
      <td>0.0067</td>
    </tr>
    <tr>
      <td>crashed</td>
      <td>0.0000</td>
    </tr>
    <tr>
      <td>stderr_length</td>
      <td>0.0000</td>
    </tr>
    <tr>
      <td>video_indicators</td>
      <td>0.0000</td>
    </tr>
    <tr>
      <td>audio_indicators</td>
      <td>0.0000</td>
    </tr>
    <tr>
      <td>tia_activity</td>
      <td>0.0000</td>
    </tr>
    <tr>
      <td>game_indicators</td>
      <td>0.0000</td>
    </tr>
    <tr>
      <td>error_indicators</td>
      <td>0.0000</td>
    </tr>
  </tbody>
</table>

<p>It was obvious what was happening: I was only selecting for ROMs that <em>ran</em>, not ROMs that <em>did anything interesting</em>. A quick check showed they were just booting into an infinite loop; After booting, there would be a few instructions that did nothing until eventually jumping back to somewhere around the reset vector. In fact, this <em>should</em> be frequently found. Consider the simplest possible Atari program:</p>

<pre><code>
; Program starts at $F000

F000: 4C 00 F0   ; JMP $F000 — forever doing nothing
</code></pre>

<p>This code starts running at F000, and jumps immediately to that same address. The odds of generating this code are $\frac{1}{256} \times \frac{1}{256} \times \frac{1}{256} = \frac{1}{16,777,216}$. In other words, for every 16 Million ROMs I generate, I will have one that is a valid ROM that does absolutely nothing. I probably generated this ROM several times while generating 30 Billion ROMs. I just don’t care about a program that does nothing.</p>

<p>In short, a classifier on the actual machine code was worthless. Or my training data was. But then again, there’s no training set for Atari games that almost work — just masterpieces and garbage.</p>

<h2 id="second-results-finding-anything-interesting">Second Results, Finding Anything Interesting</h2>

<p>Realizing I only want one thing - interesting visual output - I rewrote the generation pipeline to find interesting ROMs and immediately send them to an emulator to find interesting candidates.</p>

<div><pre><code><span># ==========================================================================
#
#   Finite Atari unified pipeline (4 KB, reset @ $F000) - FIXED VERSION
#
#   This script generates random Atari 2600 ROMs in the GPU via CUDA,
#   Filters them on-GPU with a heuristic, and if interesting, boots
#   them in head-less MAME for 2 s to check if they have dynamic video.
#
#   It is designed to run on a CUDA-capable GPU with MAME installed in PATH.
#
#   The output is saved in the "finite_atari_roms" directory.
#
# ===========================================================================
</span>
<span>from</span> <span>__future__</span> <span>import</span> <span>annotations</span>
<span>import</span> <span>cupy</span> <span>as</span> <span>cp</span><span>,</span> <span>numpy</span> <span>as</span> <span>np</span><span>,</span> <span>hashlib</span><span>,</span> <span>subprocess</span><span>,</span> <span>tempfile</span><span>,</span> <span>time</span><span>,</span> <span>textwrap</span>
<span>from</span> <span>pathlib</span> <span>import</span> <span>Path</span>
<span>from</span> <span>PIL</span> <span>import</span> <span>Image</span>

<span># ─── 1.  Global constants ────────────────────────────────────────────────────
</span><span>ROM_SIZE</span>       <span>=</span> <span>4096</span>
<span>PAYLOAD_BYTES</span>  <span>=</span> <span>ROM_SIZE</span> <span>-</span> <span>2</span>
<span>RESET_VECTOR</span>   <span>=</span> <span>(</span><span>0x00</span><span>,</span> <span>0xF0</span><span>)</span>         <span># little-endian $F000
</span><span>BATCH_SIZE</span>     <span>=</span> <span>1024</span> <span>*</span> <span>256</span>           <span># ~256 k ROMs per GPU batch
</span><span>STATUS_EVERY</span>   <span>=</span> <span>10</span>                   <span># batches between status prints
</span><span>OUTPUT_DIR</span>     <span>=</span> <span>Path</span><span>(</span><span>"finite_atari_roms"</span><span>);</span> <span>OUTPUT_DIR</span><span>.</span><span>mkdir</span><span>(</span><span>exist_ok</span><span>=</span><span>True</span><span>)</span>

<span># Video thresholds
</span><span>BLACK_LEVEL</span>          <span>=</span> <span>15</span>             <span># 0-255 grey; ≤ this is "black"
</span><span>NONBLACK_THRESHOLD</span>   <span>=</span> <span>0.005</span>          <span># ≥ 0.5 % pixels brighter ⇒ video
</span><span>DYNAMIC_THRESHOLD</span>    <span>=</span> <span>0.01</span>           <span># ≥ 1 % hashed pixels differ ⇒ motion
</span>
<span># Heuristic thresholds (same as your earlier Stella/MAME scripts)
</span><span>OPCODE_THRESHOLD</span>    <span>=</span> <span>0.58</span>
<span>TIA_THRESHOLD</span>       <span>=</span> <span>50</span>
<span>RIOT_THRESHOLD</span>      <span>=</span> <span>13</span>
<span>BRANCH_THRESHOLD</span>    <span>=</span> <span>150</span>
<span>JUMP_THRESHOLD</span>      <span>=</span> <span>37</span>
<span>INSTRUCTION_VARIETY</span> <span>=</span> <span>100</span>
<span>MIN_SCORE</span>           <span>=</span> <span>0.52</span>

<span># ─── 2.  Opcode lookup tables ────────────────────────────────────────────────
# Valid 6502 opcodes for 2600 home-brew context
</span><span>VALID_OPCODES</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>([</span>
    <span>0x00</span><span>,</span><span>0x01</span><span>,</span><span>0x05</span><span>,</span><span>0x06</span><span>,</span><span>0x08</span><span>,</span><span>0x09</span><span>,</span><span>0x0A</span><span>,</span><span>0x0D</span><span>,</span><span>0x0E</span><span>,</span><span>0x10</span><span>,</span><span>0x11</span><span>,</span><span>0x15</span><span>,</span><span>0x16</span><span>,</span><span>0x18</span><span>,</span>
    <span>0x19</span><span>,</span><span>0x1D</span><span>,</span><span>0x1E</span><span>,</span><span>0x20</span><span>,</span><span>0x21</span><span>,</span><span>0x24</span><span>,</span><span>0x25</span><span>,</span><span>0x26</span><span>,</span><span>0x28</span><span>,</span><span>0x29</span><span>,</span><span>0x2A</span><span>,</span><span>0x2C</span><span>,</span><span>0x2D</span><span>,</span><span>0x2E</span><span>,</span>
    <span>0x30</span><span>,</span><span>0x31</span><span>,</span><span>0x35</span><span>,</span><span>0x36</span><span>,</span><span>0x38</span><span>,</span><span>0x39</span><span>,</span><span>0x3D</span><span>,</span><span>0x3E</span><span>,</span><span>0x40</span><span>,</span><span>0x41</span><span>,</span><span>0x45</span><span>,</span><span>0x46</span><span>,</span><span>0x48</span><span>,</span><span>0x49</span><span>,</span>
    <span>0x4A</span><span>,</span><span>0x4C</span><span>,</span><span>0x4D</span><span>,</span><span>0x4E</span><span>,</span><span>0x50</span><span>,</span><span>0x51</span><span>,</span><span>0x55</span><span>,</span><span>0x56</span><span>,</span><span>0x58</span><span>,</span><span>0x59</span><span>,</span><span>0x5D</span><span>,</span><span>0x5E</span><span>,</span><span>0x60</span><span>,</span><span>0x61</span><span>,</span>
    <span>0x65</span><span>,</span><span>0x66</span><span>,</span><span>0x68</span><span>,</span><span>0x69</span><span>,</span><span>0x6A</span><span>,</span><span>0x6C</span><span>,</span><span>0x6D</span><span>,</span><span>0x6E</span><span>,</span><span>0x70</span><span>,</span><span>0x71</span><span>,</span><span>0x75</span><span>,</span><span>0x76</span><span>,</span><span>0x78</span><span>,</span><span>0x79</span><span>,</span>
    <span>0x7D</span><span>,</span><span>0x7E</span><span>,</span><span>0x81</span><span>,</span><span>0x84</span><span>,</span><span>0x85</span><span>,</span><span>0x86</span><span>,</span><span>0x88</span><span>,</span><span>0x8A</span><span>,</span><span>0x8C</span><span>,</span><span>0x8D</span><span>,</span><span>0x8E</span><span>,</span><span>0x90</span><span>,</span><span>0x91</span><span>,</span><span>0x94</span><span>,</span>
    <span>0x95</span><span>,</span><span>0x96</span><span>,</span><span>0x98</span><span>,</span><span>0x99</span><span>,</span><span>0x9A</span><span>,</span><span>0x9D</span><span>,</span><span>0xA0</span><span>,</span><span>0xA1</span><span>,</span><span>0xA2</span><span>,</span><span>0xA4</span><span>,</span><span>0xA5</span><span>,</span><span>0xA6</span><span>,</span><span>0xA8</span><span>,</span><span>0xA9</span><span>,</span>
    <span>0xAA</span><span>,</span><span>0xAC</span><span>,</span><span>0xAD</span><span>,</span><span>0xAE</span><span>,</span><span>0xB0</span><span>,</span><span>0xB1</span><span>,</span><span>0xB4</span><span>,</span><span>0xB5</span><span>,</span><span>0xB6</span><span>,</span><span>0xB8</span><span>,</span><span>0xB9</span><span>,</span><span>0xBA</span><span>,</span><span>0xBC</span><span>,</span><span>0xBD</span><span>,</span>
    <span>0xBE</span><span>,</span><span>0xC0</span><span>,</span><span>0xC1</span><span>,</span><span>0xC4</span><span>,</span><span>0xC5</span><span>,</span><span>0xC6</span><span>,</span><span>0xC8</span><span>,</span><span>0xC9</span><span>,</span><span>0xCA</span><span>,</span><span>0xCC</span><span>,</span><span>0xCD</span><span>,</span><span>0xCE</span><span>,</span><span>0xD0</span><span>,</span><span>0xD1</span><span>,</span>
    <span>0xD5</span><span>,</span><span>0xD6</span><span>,</span><span>0xD8</span><span>,</span><span>0xD9</span><span>,</span><span>0xDD</span><span>,</span><span>0xDE</span><span>,</span><span>0xE0</span><span>,</span><span>0xE1</span><span>,</span><span>0xE4</span><span>,</span><span>0xE5</span><span>,</span><span>0xE6</span><span>,</span><span>0xE8</span><span>,</span><span>0xE9</span><span>,</span><span>0xEA</span><span>,</span>
    <span>0xEC</span><span>,</span><span>0xED</span><span>,</span><span>0xEE</span><span>,</span><span>0xF0</span><span>,</span><span>0xF1</span><span>,</span><span>0xF5</span><span>,</span><span>0xF6</span><span>,</span><span>0xF8</span><span>,</span><span>0xF9</span><span>,</span><span>0xFD</span><span>,</span><span>0xFE</span><span>],</span> <span>dtype</span><span>=</span><span>np</span><span>.</span><span>uint8</span><span>)</span>

<span>BRANCH_OPCODES</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>([</span><span>0x10</span><span>,</span><span>0x30</span><span>,</span><span>0x50</span><span>,</span><span>0x70</span><span>,</span><span>0x90</span><span>,</span><span>0xB0</span><span>,</span><span>0xD0</span><span>,</span><span>0xF0</span><span>],</span> <span>dtype</span><span>=</span><span>np</span><span>.</span><span>uint8</span><span>)</span>
<span>JUMP_OPCODES</span>   <span>=</span> <span>np</span><span>.</span><span>array</span><span>([</span><span>0x4C</span><span>,</span><span>0x6C</span><span>,</span><span>0x20</span><span>],</span> <span>dtype</span><span>=</span><span>np</span><span>.</span><span>uint8</span><span>)</span>

<span>def</span> <span>create_luts</span><span>():</span>
    <span>"""Return a dict of 256-entry boolean lookup tables (cupy)."""</span>
    <span>lut</span> <span>=</span> <span>{}</span>
    <span>lut</span><span>[</span><span>"valid"</span><span>]</span>  <span>=</span> <span>cp</span><span>.</span><span>zeros</span><span>(</span><span>256</span><span>,</span> <span>cp</span><span>.</span><span>bool_</span><span>);</span> <span>lut</span><span>[</span><span>"valid"</span><span>][</span><span>VALID_OPCODES</span><span>]</span>  <span>=</span> <span>True</span>
    <span>lut</span><span>[</span><span>"branch"</span><span>]</span> <span>=</span> <span>cp</span><span>.</span><span>zeros</span><span>(</span><span>256</span><span>,</span> <span>cp</span><span>.</span><span>bool_</span><span>);</span> <span>lut</span><span>[</span><span>"branch"</span><span>][</span><span>BRANCH_OPCODES</span><span>]</span> <span>=</span> <span>True</span>
    <span>lut</span><span>[</span><span>"jump"</span><span>]</span>   <span>=</span> <span>cp</span><span>.</span><span>zeros</span><span>(</span><span>256</span><span>,</span> <span>cp</span><span>.</span><span>bool_</span><span>);</span> <span>lut</span><span>[</span><span>"jump"</span><span>][</span><span>JUMP_OPCODES</span><span>]</span>     <span>=</span> <span>True</span>

    <span># 2600 addressing quirks for TIA/RIOT access detection
</span>    <span>lut</span><span>[</span><span>"tia_store"</span><span>]</span> <span>=</span> <span>cp</span><span>.</span><span>zeros</span><span>(</span><span>256</span><span>,</span> <span>cp</span><span>.</span><span>bool_</span><span>)</span>
    <span>lut</span><span>[</span><span>"tia_store"</span><span>][[</span><span>0x84</span><span>,</span><span>0x85</span><span>,</span><span>0x86</span><span>,</span> <span>0x94</span><span>,</span><span>0x95</span><span>,</span><span>0x96</span><span>]]</span> <span>=</span> <span>True</span>   <span># STY/STA/STX (zp &amp; zp,x)
</span>    <span>lut</span><span>[</span><span>"tia_load"</span><span>]</span>  <span>=</span> <span>cp</span><span>.</span><span>zeros</span><span>(</span><span>256</span><span>,</span> <span>cp</span><span>.</span><span>bool_</span><span>)</span>
    <span>lut</span><span>[</span><span>"tia_load"</span> <span>][[</span><span>0xA4</span><span>,</span><span>0xA5</span><span>,</span><span>0xA6</span><span>,</span> <span>0xB4</span><span>,</span><span>0xB5</span><span>,</span><span>0xB6</span><span>]]</span> <span>=</span> <span>True</span>   <span># LDY/LDA/LDX (zp &amp; zp,x)
</span>    <span>lut</span><span>[</span><span>"tia_abs"</span><span>]</span>   <span>=</span> <span>cp</span><span>.</span><span>zeros</span><span>(</span><span>256</span><span>,</span> <span>cp</span><span>.</span><span>bool_</span><span>)</span>
    <span>lut</span><span>[</span><span>"tia_abs"</span>  <span>][[</span><span>0x8C</span><span>,</span><span>0x8D</span><span>,</span><span>0x8E</span><span>,</span> <span>0xAC</span><span>,</span><span>0xAD</span><span>,</span><span>0xAE</span><span>]]</span> <span>=</span> <span>True</span>   <span># abs versions
</span>
    <span>lut</span><span>[</span><span>"riot_acc"</span><span>]</span>  <span>=</span> <span>cp</span><span>.</span><span>zeros</span><span>(</span><span>256</span><span>,</span> <span>cp</span><span>.</span><span>bool_</span><span>)</span>
    <span>lut</span><span>[</span><span>"riot_acc"</span><span>][[</span><span>0x84</span><span>,</span><span>0x85</span><span>,</span><span>0x86</span><span>,</span> <span>0xA4</span><span>,</span><span>0xA5</span><span>,</span><span>0xA6</span><span>]]</span> <span>=</span> <span>True</span>

    <span>addr</span> <span>=</span> <span>cp</span><span>.</span><span>arange</span><span>(</span><span>256</span><span>,</span> <span>dtype</span><span>=</span><span>cp</span><span>.</span><span>uint8</span><span>)</span>
    <span>lut</span><span>[</span><span>"tia_range"</span><span>]</span> <span>=</span> <span>addr</span> <span>&lt;=</span> <span>0x2F</span>
    <span>lut</span><span>[</span><span>"riot_tmr"</span><span>]</span>  <span>=</span> <span>(</span><span>addr</span> <span>&gt;=</span> <span>0x80</span><span>)</span> <span>&amp;</span> <span>(</span><span>addr</span> <span>&lt;=</span> <span>0x87</span><span>)</span>
    <span>lut</span><span>[</span><span>"riot_io"</span><span>]</span>   <span>=</span> <span>(</span><span>addr</span> <span>&gt;=</span> <span>0x94</span><span>)</span> <span>&amp;</span> <span>(</span><span>addr</span> <span>&lt;=</span> <span>0x97</span><span>)</span>
    <span>return</span> <span>lut</span>

<span># ─── 3.  GPU heuristic filter ────────────────────────────────────────────────
</span><span>def</span> <span>analyse_batch</span><span>(</span><span>roms</span><span>:</span> <span>cp</span><span>.</span><span>ndarray</span><span>,</span> <span>lut</span><span>)</span> <span>-&gt;</span> <span>tuple</span><span>[</span><span>np</span><span>.</span><span>ndarray</span><span>,</span> <span>cp</span><span>.</span><span>ndarray</span><span>]:</span>
    <span>"""
    Return (interesting_mask, scores) for a 2-D uint8 array of ROMs.
    Each row = one ROM.
    """</span>
    <span>valid_cnt</span>    <span>=</span> <span>cp</span><span>.</span><span>sum</span><span>(</span><span>lut</span><span>[</span><span>"valid"</span><span>][</span><span>roms</span><span>],</span> <span>axis</span><span>=</span><span>1</span><span>)</span>
    <span>opcode_ratio</span> <span>=</span> <span>valid_cnt</span><span>.</span><span>astype</span><span>(</span><span>cp</span><span>.</span><span>float32</span><span>)</span> <span>/</span> <span>ROM_SIZE</span>
    <span>branch_cnt</span>   <span>=</span> <span>cp</span><span>.</span><span>sum</span><span>(</span><span>lut</span><span>[</span><span>"branch"</span><span>][</span><span>roms</span><span>],</span> <span>axis</span><span>=</span><span>1</span><span>)</span>
    <span>jump_cnt</span>     <span>=</span> <span>cp</span><span>.</span><span>sum</span><span>(</span><span>lut</span><span>[</span><span>"jump"</span>  <span>][</span><span>roms</span><span>],</span> <span>axis</span><span>=</span><span>1</span><span>)</span>

    <span># --- TIA accesses --------------------------------------------------------
</span>    <span>tia_acc</span>  <span>=</span> <span>cp</span><span>.</span><span>sum</span><span>((</span><span>lut</span><span>[</span><span>"tia_store"</span><span>][</span><span>roms</span><span>[:,:</span><span>-</span><span>1</span><span>]]</span> <span>|</span> <span>lut</span><span>[</span><span>"tia_load"</span><span>][</span><span>roms</span><span>[:,:</span><span>-</span><span>1</span><span>]])</span>
                      <span>&amp;</span> <span>lut</span><span>[</span><span>"tia_range"</span><span>][</span><span>roms</span><span>[:,</span><span>1</span><span>:]],</span> <span>axis</span><span>=</span><span>1</span><span>)</span>
    <span>tia_acc</span> <span>+=</span> <span>cp</span><span>.</span><span>sum</span><span>(</span><span>lut</span><span>[</span><span>"tia_abs"</span><span>][</span><span>roms</span><span>[:,:</span><span>-</span><span>2</span><span>]]</span>
                      <span>&amp;</span> <span>lut</span><span>[</span><span>"tia_range"</span><span>][</span><span>roms</span><span>[:,</span><span>1</span><span>:</span><span>-</span><span>1</span><span>]]</span>
                      <span>&amp;</span> <span>(</span><span>roms</span><span>[:,</span><span>2</span><span>:]</span> <span>==</span> <span>0x00</span><span>),</span> <span>axis</span><span>=</span><span>1</span><span>)</span>

    <span># --- RIOT accesses -------------------------------------------------------
</span>    <span>riot_acc</span>  <span>=</span> <span>cp</span><span>.</span><span>sum</span><span>(</span><span>lut</span><span>[</span><span>"riot_acc"</span><span>][</span><span>roms</span><span>[:,:</span><span>-</span><span>1</span><span>]]</span> <span>&amp;</span> <span>lut</span><span>[</span><span>"riot_tmr"</span><span>][</span><span>roms</span><span>[:,</span><span>1</span><span>:]],</span> <span>axis</span><span>=</span><span>1</span><span>)</span>
    <span>riot_acc</span> <span>+=</span> <span>cp</span><span>.</span><span>sum</span><span>(</span><span>lut</span><span>[</span><span>"riot_acc"</span><span>][</span><span>roms</span><span>[:,:</span><span>-</span><span>1</span><span>]]</span> <span>&amp;</span> <span>lut</span><span>[</span><span>"riot_io"</span> <span>][</span><span>roms</span><span>[:,</span><span>1</span><span>:]],</span> <span>axis</span><span>=</span><span>1</span><span>)</span>

    <span># --- Opcode diversity in first 1 KB --------------------------------------
</span>    <span>uniq</span> <span>=</span> <span>cp</span><span>.</span><span>zeros</span><span>(</span><span>roms</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>],</span> <span>dtype</span><span>=</span><span>cp</span><span>.</span><span>int32</span><span>)</span>
    <span>first_kb</span> <span>=</span> <span>roms</span><span>[:,</span> <span>:</span><span>1024</span><span>]</span>
    <span>for</span> <span>op</span> <span>in</span> <span>VALID_OPCODES</span><span>:</span>
        <span>uniq</span> <span>+=</span> <span>cp</span><span>.</span><span>any</span><span>(</span><span>first_kb</span> <span>==</span> <span>op</span><span>,</span> <span>axis</span><span>=</span><span>1</span><span>)</span>

    <span>scores</span> <span>=</span> <span>(</span><span>opcode_ratio</span> <span>*</span> <span>0.25</span> <span>+</span>
              <span>cp</span><span>.</span><span>minimum</span><span>(</span><span>tia_acc</span> <span>/</span> <span>150.0</span><span>,</span> <span>1.0</span><span>)</span> <span>*</span> <span>0.30</span> <span>+</span>
              <span>cp</span><span>.</span><span>minimum</span><span>(</span><span>riot_acc</span> <span>/</span> <span>50.0</span><span>,</span> <span>1.0</span><span>)</span>  <span>*</span> <span>0.20</span> <span>+</span>
              <span>cp</span><span>.</span><span>minimum</span><span>(</span><span>branch_cnt</span> <span>/</span> <span>200.0</span><span>,</span> <span>1.0</span><span>)</span> <span>*</span> <span>0.15</span> <span>+</span>
              <span>cp</span><span>.</span><span>minimum</span><span>(</span><span>jump_cnt</span> <span>/</span> <span>40.0</span><span>,</span> <span>1.0</span><span>)</span>   <span>*</span> <span>0.10</span><span>)</span>

    <span>interesting</span> <span>=</span> <span>((</span><span>opcode_ratio</span> <span>&gt;=</span> <span>OPCODE_THRESHOLD</span><span>)</span> <span>&amp;</span>
                   <span>(</span><span>tia_acc</span>      <span>&gt;=</span> <span>TIA_THRESHOLD</span><span>)</span> <span>&amp;</span>
                   <span>(</span><span>riot_acc</span>     <span>&gt;=</span> <span>RIOT_THRESHOLD</span><span>)</span> <span>&amp;</span>
                   <span>(</span><span>branch_cnt</span>   <span>&gt;=</span> <span>BRANCH_THRESHOLD</span><span>)</span> <span>&amp;</span>
                   <span>(</span><span>jump_cnt</span>     <span>&gt;=</span> <span>JUMP_THRESHOLD</span><span>)</span> <span>&amp;</span>
                   <span>(</span><span>uniq</span>         <span>&gt;=</span> <span>INSTRUCTION_VARIETY</span><span>)</span> <span>&amp;</span>
                   <span>(</span><span>scores</span>       <span>&gt;=</span> <span>MIN_SCORE</span><span>))</span>

    <span>return</span> <span>interesting</span><span>,</span> <span>scores</span>

<span># ─── 4.  Lua helper script (snapshot two frames) - FIXED ────────────────────
</span><span>SNAPSHOT_LUA</span> <span>=</span> <span>textwrap</span><span>.</span><span>dedent</span><span>(</span><span>"""
    local s = manager.machine.screens[":screen"]
    local frame_count = 0
    emu.register_frame_done(function ()
        frame_count = frame_count + 1
        if     frame_count == 1  then s:snapshot("first.png")
        elseif frame_count == 60 then s:snapshot("second.png"); manager.machine:exit() end
    end, "snapper")
"""</span><span>)</span>

<span># ─── 5.  Video analysis helpers ──────────────────────────────────────────────
</span><span>def</span> <span>_hash16</span><span>(</span><span>img</span><span>:</span> <span>Path</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
    <span>with</span> <span>Image</span><span>.</span><span>open</span><span>(</span><span>img</span><span>)</span> <span>as</span> <span>im</span><span>:</span>
        <span>im</span> <span>=</span> <span>im</span><span>.</span><span>convert</span><span>(</span><span>"L"</span><span>).</span><span>resize</span><span>((</span><span>16</span><span>,</span><span>16</span><span>),</span> <span>Image</span><span>.</span><span>NEAREST</span><span>)</span>
        <span>return</span> <span>hashlib</span><span>.</span><span>sha1</span><span>(</span><span>im</span><span>.</span><span>tobytes</span><span>()).</span><span>hexdigest</span><span>()</span>

<span>def</span> <span>_frame_is_nonblack</span><span>(</span><span>img</span><span>:</span> <span>Path</span><span>)</span> <span>-&gt;</span> <span>bool</span><span>:</span>
    <span>with</span> <span>Image</span><span>.</span><span>open</span><span>(</span><span>img</span><span>)</span> <span>as</span> <span>im</span><span>:</span>
        <span>g</span> <span>=</span> <span>np</span><span>.</span><span>asarray</span><span>(</span><span>im</span><span>.</span><span>convert</span><span>(</span><span>"L"</span><span>))</span>
    <span>return</span> <span>(</span><span>g</span> <span>&gt;</span> <span>BLACK_LEVEL</span><span>).</span><span>mean</span><span>()</span> <span>&gt;=</span> <span>NONBLACK_THRESHOLD</span>

<span>def</span> <span>rom_video_flags</span><span>(</span><span>rom</span><span>:</span> <span>bytes</span><span>,</span> <span>*</span><span>,</span> <span>mame</span><span>=</span><span>"mame"</span><span>,</span> <span>seconds</span><span>=</span><span>2.0</span><span>)</span> <span>-&gt;</span> <span>tuple</span><span>[</span><span>bool</span><span>,</span><span>bool</span><span>]:</span>
    <span>"""
    Returns (has_video, is_dynamic).
    • has_video  → first frame not black
    • is_dynamic → ≥ 1 % hashed pixels differ between frame 1 and 60
    """</span>
    <span>with</span> <span>tempfile</span><span>.</span><span>TemporaryDirectory</span><span>()</span> <span>as</span> <span>td_s</span><span>:</span>
        <span>td</span> <span>=</span> <span>Path</span><span>(</span><span>td_s</span><span>)</span>
        <span>(</span><span>td</span> <span>/</span> <span>"test.bin"</span><span>).</span><span>write_bytes</span><span>(</span><span>rom</span><span>)</span>
        <span>(</span><span>td</span> <span>/</span> <span>"snapshot.lua"</span><span>).</span><span>write_text</span><span>(</span><span>SNAPSHOT_LUA</span><span>)</span>

        <span>base</span> <span>=</span> <span>[</span><span>mame</span><span>,</span> <span>"a2600"</span><span>,</span> <span>"-cart"</span><span>,</span> <span>"test.bin"</span><span>,</span>
                <span>"-seconds_to_run"</span><span>,</span> <span>str</span><span>(</span><span>seconds</span><span>),</span>
                <span>"-nothrottle"</span><span>,</span> <span>"-window"</span><span>,</span> <span>"-sound"</span><span>,</span> <span>"none"</span><span>,</span> <span>"-skip_gameinfo"</span><span>]</span>

        <span>for</span> <span>flag</span> <span>in</span> <span>(</span><span>"-autoboot_script"</span><span>,</span> <span>"-script"</span><span>):</span>
            <span>try</span><span>:</span>
                <span>subprocess</span><span>.</span><span>run</span><span>(</span><span>base</span> <span>+</span> <span>[</span><span>flag</span><span>,</span> <span>"snapshot.lua"</span><span>],</span>
                               <span>cwd</span><span>=</span><span>td</span><span>,</span> <span>stdout</span><span>=</span><span>subprocess</span><span>.</span><span>DEVNULL</span><span>,</span>
                               <span>stderr</span><span>=</span><span>subprocess</span><span>.</span><span>DEVNULL</span><span>,</span> <span>timeout</span><span>=</span><span>seconds</span><span>*</span><span>5</span><span>,</span>
                               <span>check</span><span>=</span><span>True</span><span>)</span>
                <span>break</span>
            <span>except</span> <span>(</span><span>subprocess</span><span>.</span><span>CalledProcessError</span><span>,</span> <span>subprocess</span><span>.</span><span>TimeoutExpired</span><span>):</span>
                <span>if</span> <span>flag</span> <span>==</span> <span>"-autoboot_script"</span><span>:</span>
                    <span>continue</span>
                <span>return</span> <span>(</span><span>False</span><span>,</span> <span>False</span><span>)</span>

        <span># Check both root directory and snap subdirectory for frames
</span>        <span>f1</span><span>,</span> <span>f2</span> <span>=</span> <span>td</span> <span>/</span> <span>"first.png"</span><span>,</span> <span>td</span> <span>/</span> <span>"second.png"</span>
        <span>snap_dir</span> <span>=</span> <span>td</span> <span>/</span> <span>"snap"</span>
        <span>if</span> <span>not</span> <span>f1</span><span>.</span><span>exists</span><span>()</span> <span>and</span> <span>snap_dir</span><span>.</span><span>exists</span><span>():</span>
            <span>snap_f1</span> <span>=</span> <span>snap_dir</span> <span>/</span> <span>"first.png"</span>
            <span>snap_f2</span> <span>=</span> <span>snap_dir</span> <span>/</span> <span>"second.png"</span>
            <span>if</span> <span>snap_f1</span><span>.</span><span>exists</span><span>():</span>
                <span>f1</span> <span>=</span> <span>snap_f1</span>
            <span>if</span> <span>snap_f2</span><span>.</span><span>exists</span><span>():</span>
                <span>f2</span> <span>=</span> <span>snap_f2</span>

        <span>if</span> <span>not</span> <span>f1</span><span>.</span><span>exists</span><span>():</span>
            <span>return</span> <span>(</span><span>False</span><span>,</span> <span>False</span><span>)</span>

        <span>nonblack</span> <span>=</span> <span>_frame_is_nonblack</span><span>(</span><span>f1</span><span>)</span>
        <span>if</span> <span>not</span> <span>nonblack</span> <span>or</span> <span>not</span> <span>f2</span><span>.</span><span>exists</span><span>():</span>
            <span>return</span> <span>(</span><span>nonblack</span><span>,</span> <span>False</span><span>)</span>

        <span>diff_bits</span> <span>=</span> <span>bin</span><span>(</span><span>int</span><span>(</span><span>_hash16</span><span>(</span><span>f1</span><span>),</span><span>16</span><span>)</span> <span>^</span> <span>int</span><span>(</span><span>_hash16</span><span>(</span><span>f2</span><span>),</span><span>16</span><span>)).</span><span>count</span><span>(</span><span>"1"</span><span>)</span>
        <span>dynamic</span> <span>=</span> <span>diff_bits</span> <span>/</span> <span>256.0</span> <span>&gt;=</span> <span>DYNAMIC_THRESHOLD</span>
        <span>return</span> <span>(</span><span>nonblack</span><span>,</span> <span>dynamic</span><span>)</span>

<span># ─── 6.  ROM generator ───────────────────────────────────────────────────────
</span><span>def</span> <span>generate_batch</span><span>(</span><span>n</span><span>:</span> <span>int</span><span>)</span> <span>-&gt;</span> <span>np</span><span>.</span><span>ndarray</span><span>:</span>
    <span>payload</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randint</span><span>(</span><span>0</span><span>,</span> <span>256</span><span>,</span> <span>size</span><span>=</span><span>(</span><span>n</span><span>,</span> <span>PAYLOAD_BYTES</span><span>),</span> <span>dtype</span><span>=</span><span>np</span><span>.</span><span>uint8</span><span>)</span>
    <span>reset</span>   <span>=</span> <span>np</span><span>.</span><span>tile</span><span>(</span><span>np</span><span>.</span><span>array</span><span>(</span><span>RESET_VECTOR</span><span>,</span> <span>dtype</span><span>=</span><span>np</span><span>.</span><span>uint8</span><span>),</span> <span>(</span><span>n</span><span>,</span><span>1</span><span>))</span>
    <span>return</span> <span>np</span><span>.</span><span>hstack</span><span>((</span><span>payload</span><span>,</span> <span>reset</span><span>))</span>

<span># ─── 7.  Main loop ───────────────────────────────────────────────────────────
</span><span>def</span> <span>main</span><span>():</span>
    <span>lut</span> <span>=</span> <span>create_luts</span><span>()</span>
    <span>tot_gen</span> <span>=</span> <span>tot_int</span> <span>=</span> <span>tot_vid</span> <span>=</span> <span>tot_dyn</span> <span>=</span> <span>0</span>
    <span>batch_idx</span> <span>=</span> <span>0</span>
    <span>start</span> <span>=</span> <span>time</span><span>.</span><span>perf_counter</span><span>()</span>

    <span>try</span><span>:</span>
        <span>while</span> <span>True</span><span>:</span>
            <span>roms_cpu</span> <span>=</span> <span>generate_batch</span><span>(</span><span>BATCH_SIZE</span><span>);</span> <span>tot_gen</span> <span>+=</span> <span>BATCH_SIZE</span>

            <span>roms_gpu</span> <span>=</span> <span>cp</span><span>.</span><span>asarray</span><span>(</span><span>roms_cpu</span><span>)</span>
            <span>keep</span><span>,</span> <span>_</span> <span>=</span> <span>analyse_batch</span><span>(</span><span>roms_gpu</span><span>,</span> <span>lut</span><span>)</span>
            <span>keep</span> <span>=</span> <span>keep</span><span>.</span><span>get</span><span>();</span> <span>del</span> <span>roms_gpu</span>
            <span>interesting</span> <span>=</span> <span>roms_cpu</span><span>[</span><span>keep</span><span>]</span>
            <span>tot_int</span> <span>+=</span> <span>len</span><span>(</span><span>interesting</span><span>)</span>

            <span>for</span> <span>rom</span> <span>in</span> <span>interesting</span><span>:</span>
                <span>has_vid</span><span>,</span> <span>is_dyn</span> <span>=</span> <span>rom_video_flags</span><span>(</span><span>rom</span><span>.</span><span>tobytes</span><span>())</span>

                <span># Save if EITHER condition is true
</span>                <span>if</span> <span>has_vid</span> <span>or</span> <span>is_dyn</span><span>:</span>
                    <span>sha</span> <span>=</span> <span>hashlib</span><span>.</span><span>sha1</span><span>(</span><span>rom</span><span>).</span><span>hexdigest</span><span>()[:</span><span>12</span><span>]</span>
                    <span>(</span><span>OUTPUT_DIR</span> <span>/</span> <span>f</span><span>"</span><span>{</span><span>sha</span><span>}</span><span>.bin"</span><span>).</span><span>write_bytes</span><span>(</span><span>rom</span><span>.</span><span>tobytes</span><span>())</span>

                <span># Separate bookkeeping
</span>                <span>if</span> <span>has_vid</span><span>:</span>
                    <span>tot_vid</span> <span>+=</span> <span>1</span>           <span># first frame not black
</span>                <span>if</span> <span>is_dyn</span><span>:</span>
                    <span>tot_dyn</span> <span>+=</span> <span>1</span>           <span># animation detected
</span>
            <span>batch_idx</span> <span>+=</span> <span>1</span>
            <span>if</span> <span>batch_idx</span> <span>%</span> <span>STATUS_EVERY</span> <span>==</span> <span>0</span><span>:</span>
                <span>elapsed</span> <span>=</span> <span>time</span><span>.</span><span>perf_counter</span><span>()</span> <span>-</span> <span>start</span>
                <span>rate</span> <span>=</span> <span>int</span><span>(</span><span>tot_gen</span> <span>/</span> <span>elapsed</span><span>)</span> <span>if</span> <span>elapsed</span> <span>else</span> <span>0</span>
                <span>print</span><span>(</span><span>f</span><span>"</span><span>{</span><span>tot_gen</span><span>:</span><span>,</span><span>d</span><span>}</span><span> generated | "</span>
                      <span>f</span><span>"</span><span>{</span><span>tot_int</span><span>:</span><span>,</span><span>d</span><span>}</span><span> interesting | </span><span>{</span><span>tot_vid</span><span>:</span><span>,</span><span>d</span><span>}</span><span> with video | "</span>
                      <span>f</span><span>"</span><span>{</span><span>tot_dyn</span><span>:</span><span>,</span><span>d</span><span>}</span><span> dynamic | </span><span>{</span><span>rate</span><span>:</span><span>,</span><span>d</span><span>}</span><span> ROM/s"</span><span>,</span> <span>flush</span><span>=</span><span>True</span><span>)</span>

    <span>except</span> <span>KeyboardInterrupt</span><span>:</span>
        <span>pass</span>  <span># graceful exit
</span>
    <span>elapsed</span> <span>=</span> <span>time</span><span>.</span><span>perf_counter</span><span>()</span> <span>-</span> <span>start</span>
    <span>rate</span> <span>=</span> <span>int</span><span>(</span><span>tot_gen</span> <span>/</span> <span>elapsed</span><span>)</span> <span>if</span> <span>elapsed</span> <span>else</span> <span>0</span>
    <span>print</span><span>(</span><span>"─"</span><span>*</span><span>72</span><span>)</span>
    <span>print</span><span>(</span><span>f</span><span>"TOTAL: </span><span>{</span><span>tot_gen</span><span>:</span><span>,</span><span>d</span><span>}</span><span> generated | </span><span>{</span><span>tot_int</span><span>:</span><span>,</span><span>d</span><span>}</span><span> interesting | "</span>
          <span>f</span><span>"</span><span>{</span><span>tot_vid</span><span>:</span><span>,</span><span>d</span><span>}</span><span> with video | </span><span>{</span><span>tot_dyn</span><span>:</span><span>,</span><span>d</span><span>}</span><span> dynamic | </span><span>{</span><span>rate</span><span>:</span><span>,</span><span>d</span><span>}</span><span> ROM/s"</span><span>)</span>

<span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span><span>:</span>
    <span>main</span><span>()</span>
</code></pre></div>

<p>This script generates 4kB of random data, then filters them for heuristics on the GPU. On an Nvidia GeForce GTX 1070, this generates about <strong>62,150 ROMs/s</strong>. Filtering for the heuristics, I get one “interesting” ROM – one that passes the heuristics – for every 2.5 Million ROMs generated.</p>

<p>From there, the interesting ROMs are sent to the CPU, where they’re checked with MAME for visual output. Here’s an example of the output after being run overnight:</p>

<p><code>
TOTAL: 1,804,075,008 generated | 456 interesting | 16 with video | 11 dynamic | 62,156 ROM/s
<code></code></code></p>

<p>Out of 1.8 Billion ROMs generated, only 456 passed the heuristics test. Of those, 16 had a static video output, 11 had video that moved. You have no idea how much I’m resisting a making a Sankey diagram/fluffer joke right now.</p>

<h2 id="what-i-found">What I found</h2>

<p>These are some of the most visually interesting results from this experiment. All of these ROMs were generated entirely from random data, filtered with heuristics, and run through an Atari emulator. All of these produce valid video output and show dynamic or structured data.</p>




<h2 id="a-real-actual-protogame">A Real, Actual, Protogame</h2>

<p>Despite my entire pipeline being focused on generating visual output, I discovered something that is more than just weird visual ouput. The ROM I’m calling <code>51014</code> (<a href="https://bbenchoff.github.io/assets/pages/roms/5101496f45e8b.bin">here’s a link</a> to the actual ROM file) displays some game-like behavior. It’s an infinite loop of visual output that responds to human input. Take a look at the .gifs below:</p>





<p>Rom <code>51014</code> consists of a yellow background with two static vertical red stripes on the screen. There is also a third stripe – actually a pair of red stripes – that is not static; it looks like it’s tearing every few scanlines. By pressing Up on the joystick, that torn pair of stripes stays still. It’s input being translated into visual output.</p>

<p>It’s certainly not impressive from a programming point of view, but considering the fact it was generated <em>only out of properly filtering random data</em> is crazy. Combine a few more of these into a single rom and you have a game!</p>

<h2 id="future-work">Future Work?</h2>

<p>I targeted the Atari 2600 for a reason. It’s dead simple, there are no memory mappers or program and character ROMs, and it doesn’t have the ‘Nintendo Logo copy protection’ the original Game Boy has. Basically, if you throw random bytes at an Atari, <em>something</em> is going to fall out, which I have proven here.</p>

<p>But others have suggested other platforms to target, like the NES or Game Boy. These will not work as well as the 2600 for a few reasons.</p>

<p><strong>The NES</strong> is much more complex, with memory mappers required for nearly any game. You can’t just drop random bytes into the ROM and expect anything. Rather, you <em>could</em> but it would take much longer than waiting for an Atari game. The NES uses split character and program ROMs for code and graphics. These are stored separately. You could dump garbage into a CHR ROM while keeping the PRG of Tetris, but you’d just get static. Reverse it with the PRG of Mario 3 and maybe you’ll see a quarter of a Mario sprite flicker once.</p>

<p><strong>The Game Boy</strong> requires a 48-byte Nintendo logo at a hardcoded location in the ROM. Sure, you could brute-force this by just slapping it in after being generated, but there’s a whole boot ROM that must complete successfully before anything happens. And there’s bank switching chips to consider.</p>

<p>In contrast, the Atari 2600 is astonishingly stupid. It boots straight into ROM with zero safeguards. It will send video after nine instructions. <em>Something</em> is going to fall out if you shake it enough.</p>

<p>There’s also the possibility of using more advanced machine learning models or even an LLM to generate Atari games. This, I think, misses the point. Training an LLM on the thousand or so commercial Atari games would would only produce something like a commercial Atari game, if anything at all. My method of generating random data, then filtering with some basic heuristics, then actually running the thing to see if there’s any output is the best way to produce something out of randomness. My goal isn’t just to make a playable game, it’s to make a playable game out of randomness.</p>

<p>If I take this further, it would be as a distributed computing project, something like SETI@Home, where millions of machines search for signals in cosmic noise. Imagine GPUs across the world mining entropy for Atari games, then sending the promising ones to a central system to evaluate their ‘game-ness’. It’s an absurd idea. I’ll see how popular this project gets. It’s better than mining fartcoin, at least.</p>

<h2 id="a-conclusion">A Conclusion</h2>



<div>
  <figure>
    <img src="https://bbenchoff.github.io/images/blurst.png" alt="It was the best of times, it was the blurst of times?">
    <figcaption>It was the best of times, it was the blurst of times?</figcaption>
  </figure>

  <div>
    <p>The idea that I could pull random video games out of the ether is absurd at first, but I knew this would work before I began. I can describe this in both as a philosophical / thought experiment, and as a technical inevitability.</p>

    <p>What I'm doing is not Infinite Monkey Theorem. A million monkeys will eventually produce the works of Shakespeare, that's true, but it would take longer than any time the Universe has left. I'm not asking monkeys to produce the works of Shakespeare, I'm asking them to produce <em>any</em> work.</p>

    <p>Producing the word ‘banana’ in ASCII is just $\frac{1}{256}^6 = \frac{1}{281{,}474{,}976{,}710{,}656}$ or once every 300 trillion monkeys. But I’m not looking for ‘banana’, I’m just looking for <em>a word</em>. Any word in the dictionary. I don’t care if I’m not generating <em>Yar’s Revenge</em>. I just want something that runs on an Atari. That’s significantly easier.</p>
  </div>
</div>

<p>The <em>technical</em> reason why I knew this would work is the simplicity of the Atari. The simplest thing you could ever create on an Atari looks something like this:</p>

<pre><code>
; Program starts at $F000

F000: A9 84       ; LDA #$84        - Load a color value (red/orange)
F002: 85 09       ; STA $09         - Store to COLUBK (background color register)
F004: 85 02       ; STA $02         - Store to WSYNC (wait for horizontal sync)
F006: 4C 04 F0    ; JMP $F004       - Jump back to the WSYNC line (infinite loop)
</code></pre>

<p>That’s nine instructions. In fact, we can do the math on that, too. It would have to start with <code>A9</code>, and then it could be any one of 128 total colors. Then it’s <code>85 09</code> to store the background color, <code>85 02</code> to wait for <code>WSYNC</code>, and <code>4C 04 F0</code> for the jump back to the previous instruction. It’s $\frac{1}{256} \times \frac{128}{256} \times \frac{1}{256} \times \frac{1}{256} \times \frac{1}{256} \times \frac{1}{256} \times \frac{1}{256} \times \frac{1}{256} \times \frac{1}{256} = \frac{1}{36{,}893{,}488{,}147{,}419{,}103{,}232}$, or about 36 Pentillion. There are nearly infinite variations on this code though, so after a few Billion ROMs tested, I’m bound to get <em>something</em> for my efforts.</p>

<p>You can find all the code for this in the <a href="https://github.com/bbenchoff/FiniteAtariMachine">Finite Atari Machine repo</a></p>

<p><a href="https://bbenchoff.github.io/">back</a></p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mikeal Rogers has died (230 pts)]]></title>
            <link>https://b.h4x.zip/mikeal/</link>
            <guid>44236728</guid>
            <pubDate>Tue, 10 Jun 2025 13:43:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://b.h4x.zip/mikeal/">https://b.h4x.zip/mikeal/</a>, See on <a href="https://news.ycombinator.com/item?id=44236728">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    <article>

        <header>

            


            
        </header>

        <section>
            <p>Mikeal Rogers, my best friend, my colleague, confidant, and one of a kind partner in countless late night chats and restless travel sprints, has died. </p><p>Mikeal died of aggressive cancer. </p><p> Words feel wholly inadequate because I want to capture the sweep of what he meant to me and to the many communities he shaped. Mikeal was core to nodejs, from our earliest days at DigitalOcean, when he turned developer evangelism into an act of radical hospitality, late night strategy sessions where we mapped new ideas on  napkins,  quiet moments where I cried over the weight of life, Mikeal modeled a rare combination of technical brilliance, clarity, and unfiltered humanity, reminding everyone in his orbit that code is just a conduit for connection for humans, for community. Mikel approached every project with the conviction that open source is not a license but a promise to lift others, and he lived that promise whether arguing a stubborn point at 3 a.m. or sitting with a junior engineer who doubted their place in tech. My growth traces directly to his insistence that vulnerability and rigor are not opposites but allies, that a great team is forged as much in shared laughter as in polish, that success is hollow if it leaves no room for empathy and compassion. </p><p>The grief of losing him is heavy, however even now I can hear his voice "Well John, you see..." urging us to keep building spaces where people feel seen and ideas flow freely.  I will carry forward that charge, honoring his memory by doubling down on the principles he lived every day: </p><p>curiosity without ego, </p><p>generosity without limit, </p><p>community without gatekeepers. </p><p>My dear dear friend, you saved my life and now I say: rest well, Mikeal, the paths we walked together remain lit by the fires you struck, those of us who traveled with you will keep the flame alive.</p><p>I will miss you Mikeal. </p><figure><img src="https://b.h4x.zip/content/images/2025/06/image.jpeg" alt="" loading="lazy" width="1024" height="767" srcset="https://b.h4x.zip/content/images/size/w600/2025/06/image.jpeg 600w, https://b.h4x.zip/content/images/size/w1000/2025/06/image.jpeg 1000w, https://b.h4x.zip/content/images/2025/06/image.jpeg 1024w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://b.h4x.zip/content/images/2025/06/image-1.jpeg" alt="" loading="lazy" width="960" height="1280" srcset="https://b.h4x.zip/content/images/size/w600/2025/06/image-1.jpeg 600w, https://b.h4x.zip/content/images/2025/06/image-1.jpeg 960w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://b.h4x.zip/content/images/2025/06/image-2.jpeg" alt="" loading="lazy" width="2000" height="1500" srcset="https://b.h4x.zip/content/images/size/w600/2025/06/image-2.jpeg 600w, https://b.h4x.zip/content/images/size/w1000/2025/06/image-2.jpeg 1000w, https://b.h4x.zip/content/images/size/w1600/2025/06/image-2.jpeg 1600w, https://b.h4x.zip/content/images/size/w2400/2025/06/image-2.jpeg 2400w" sizes="(min-width: 720px) 720px"></figure>
        </section>

    </article>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Faster, easier 2D vector rendering [video] (124 pts)]]></title>
            <link>https://www.youtube.com/watch?v=_sv8K190Zps</link>
            <guid>44236423</guid>
            <pubDate>Tue, 10 Jun 2025 13:17:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=_sv8K190Zps">https://www.youtube.com/watch?v=_sv8K190Zps</a>, See on <a href="https://news.ycombinator.com/item?id=44236423">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: High End Color Quantizer (112 pts)]]></title>
            <link>https://github.com/big-nacho/patolette</link>
            <guid>44235628</guid>
            <pubDate>Tue, 10 Jun 2025 11:50:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/big-nacho/patolette">https://github.com/big-nacho/patolette</a>, See on <a href="https://news.ycombinator.com/item?id=44235628">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/67847653/452787608-c35f17b7-6c1f-499c-aa79-bbe9301fc6d2.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDk1OTQ5MDIsIm5iZiI6MTc0OTU5NDYwMiwicGF0aCI6Ii82Nzg0NzY1My80NTI3ODc2MDgtYzM1ZjE3YjctNmMxZi00OTljLWFhNzktYmJlOTMwMWZjNmQyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA2MTAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNjEwVDIyMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTVlMzkzNGIxMzA1MGY4MDBlMjM5OWI2NDJmMmY4MTNkMjU1NjE1ZmYyODEwMGNiNzg1ZGUyMzA3YzIyODVlZDkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.GOmVQd3SJHkVrspdEha4V3unsy8vrXWD7fW-VuF1gRw"><img src="https://private-user-images.githubusercontent.com/67847653/452787608-c35f17b7-6c1f-499c-aa79-bbe9301fc6d2.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDk1OTQ5MDIsIm5iZiI6MTc0OTU5NDYwMiwicGF0aCI6Ii82Nzg0NzY1My80NTI3ODc2MDgtYzM1ZjE3YjctNmMxZi00OTljLWFhNzktYmJlOTMwMWZjNmQyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA2MTAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNjEwVDIyMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTVlMzkzNGIxMzA1MGY4MDBlMjM5OWI2NDJmMmY4MTNkMjU1NjE1ZmYyODEwMGNiNzg1ZGUyMzA3YzIyODVlZDkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.GOmVQd3SJHkVrspdEha4V3unsy8vrXWD7fW-VuF1gRw" width="150px"></a>
</p>
<p dir="auto">
    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/25b20286afa9789b6b16542a800462c6e3be22b0c5098de6a31036592f34bcba/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f76657273696f6e2d76302e302e312d626c7565"><img src="https://camo.githubusercontent.com/25b20286afa9789b6b16542a800462c6e3be22b0c5098de6a31036592f34bcba/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f76657273696f6e2d76302e302e312d626c7565" data-canonical-src="https://img.shields.io/badge/version-v0.0.1-blue"></a>
    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/94412730af28599b7162b6d72ce1c9374ddbbd2cfe96773cc7ef6b43c6be5fe8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626574612d707572706c65"><img src="https://camo.githubusercontent.com/94412730af28599b7162b6d72ce1c9374ddbbd2cfe96773cc7ef6b43c6be5fe8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626574612d707572706c65" data-canonical-src="https://img.shields.io/badge/beta-purple"></a>
</p>
<p dir="auto"><em><strong>patolette</strong></em> is a <strong>C / Python</strong> color quantization and dithering library.</p>
<p dir="auto">At its core, it implements a weighted variant of Xiaolin Wu's PCA-based quantizer (not to be confused with the popular one from <em>Graphics Gems vol. II</em>, which is already available <a href="https://gist.github.com/bert/1192520">here</a>).</p>
<p dir="auto">Some of its key features are:</p>
<ul dir="auto">
<li>Avoids axis-aligned subdivisions</li>
<li>Supports the <strong>CIEL*u*v*</strong> and <strong>ICtCp</strong> color spaces</li>
<li>Optional use of saliency maps to give higher weight to areas that stand out visually</li>
<li>Optional <em>KMeans</em> refinement</li>
</ul>
<p dir="auto">The library is still in need of a ton of improvements and most definitely not ready for production use, but it's already very useable.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">A <strong>PyPI</strong> package is not yet available. Until then, installation is manual but it should hopefully be painless 🤞</p>
<p dir="auto">If you do face any obstacles building / installing, please submit an issue! 🙏</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Note for x86</h3><a id="user-content-note-for-x86" aria-label="Permalink: Note for x86" href="#note-for-x86"></a></p>
<p dir="auto"><em>patolette</em> ships a slightly modified version of <a href="https://github.com/facebookresearch/faiss">faiss</a> to aid with an optional <em>KMeans</em> refinement step. You can use the <code>CMAKE_ARGS</code> environment variable to specify an instruction set extension for it to be built with. If your CPU supports any of the <strong>AVX</strong> extensions, you can drastically increase <em>KMeans</em> performance.</p>
<p dir="auto">For example, if your CPU supports <strong>AVX512</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="export CMAKE_ARGS=&quot;-DOPT_LEVEL=avx512&quot;"><pre><span>export</span> CMAKE_ARGS=<span><span>"</span>-DOPT_LEVEL=avx512<span>"</span></span></pre></div>
<p dir="auto">The following will build the wheel and install it in the currently active virtual environment.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Linux (Debian)</h3><a id="user-content-linux-debian" aria-label="Permalink: Linux (Debian)" href="#linux-debian"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Clone repository
git clone https://github.com/big-nacho/patolette.git
cd patolette

# Install dependencies
apt install libopenblas-openmp-dev libflann-dev

# Optional: set OPT_LEVEL (check Note for x86 section)
# Accepted values are &quot;generic&quot;, &quot;avx2&quot;, &quot;avx512&quot;, &quot;avx512_spr&quot;, &quot;sve&quot;
export CMAKE_ARGS=&quot;-DOPT_LEVEL=avx512&quot;

# Build and install wheel
pip install ."><pre><span><span>#</span> Clone repository</span>
git clone https://github.com/big-nacho/patolette.git
<span>cd</span> patolette

<span><span>#</span> Install dependencies</span>
apt install libopenblas-openmp-dev libflann-dev

<span><span>#</span> Optional: set OPT_LEVEL (check Note for x86 section)</span>
<span><span>#</span> Accepted values are "generic", "avx2", "avx512", "avx512_spr", "sve"</span>
<span>export</span> CMAKE_ARGS=<span><span>"</span>-DOPT_LEVEL=avx512<span>"</span></span>

<span><span>#</span> Build and install wheel</span>
pip install <span>.</span></pre></div>
<p dir="auto">Note on <strong>OpenBLAS</strong>: although any variant should in theory work, <code>libopenblas-openmp-dev</code> is recommended. If you have multiple variants installed, you may need to run the following before building for it to be linked properly.</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo update-alternatives --set libblas.so.3-x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/openblas-openmp/libblas.so.3
sudo update-alternatives --set liblapack.so.3-x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/openblas-openmp/liblapack.so.3"><pre>sudo update-alternatives --set libblas.so.3-x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/openblas-openmp/libblas.so.3
sudo update-alternatives --set liblapack.so.3-x86_64-linux-gnu /usr/lib/x86_64-linux-gnu/openblas-openmp/liblapack.so.3</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">macOS</h3><a id="user-content-macos" aria-label="Permalink: macOS" href="#macos"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Clone repository
git clone https://github.com/big-nacho/patolette.git
cd patolette

# Install dependencies
brew install libomp flann

# Make sure system clang is used. If you use brew's clang 
# you may run into libstdc++ issues
export CC=/usr/bin/clang
export CXX=/usr/bin/clang++

# Let CMake find OpenMP
export OpenMP_ROOT=$(brew --prefix)/opt/libomp

# Build and install wheel
pip install ."><pre><span><span>#</span> Clone repository</span>
git clone https://github.com/big-nacho/patolette.git
<span>cd</span> patolette

<span><span>#</span> Install dependencies</span>
brew install libomp flann

<span><span>#</span> Make sure system clang is used. If you use brew's clang </span>
<span><span>#</span> you may run into libstdc++ issues</span>
<span>export</span> CC=/usr/bin/clang
<span>export</span> CXX=/usr/bin/clang++

<span><span>#</span> Let CMake find OpenMP</span>
<span>export</span> OpenMP_ROOT=<span><span>$(</span>brew --prefix<span>)</span></span>/opt/libomp

<span><span>#</span> Build and install wheel</span>
pip install <span>.</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Windows</h3><a id="user-content-windows" aria-label="Permalink: Windows" href="#windows"></a></p>
<p dir="auto">Windows is of course a world of pain (but hey, no judgement if you're into that sort of thing ⛓️).</p>
<p dir="auto">Small note: <strong>MSVC</strong> doesn't like building <code>faiss</code> with <strong>AVX512</strong>. Stick to <strong>AVX2</strong> if you're building with an instruction set extension on, at least until that's fixed. If you don't know what I'm talking about check <a href="#note-for-x86">Note for x86</a>.</p>
<p dir="auto">The following may vary for you here and there, but mostly you should be able to build and install the wheel following these steps:</p>
<p dir="auto">First, you need <code>pkg-config</code> or CMake won't find <code>flann</code>.
You can get it <a href="https://sourceforge.net/projects/pkgconfiglite/files/" rel="nofollow">here</a> or you can install <code>pkgconfiglite</code> using <a href="https://chocolatey.org/" rel="nofollow">choco</a> (that's what I did).</p>
<p dir="auto">Then you need to get <code>flann</code> and <code>OpenBLAS</code>. You can do this in a variety of ways but an easy one is to use <code>conda</code>. You can get (Mini)conda <a href="https://www.anaconda.com/docs/getting-started/miniconda/install" rel="nofollow">here</a>.</p>
<p dir="auto">With <code>conda</code> installed, open <em>Anaconda Prompt</em> and type</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Install dependencies
conda install conda-forge::openblas conda-forge::flann

# Get conda prefix
echo %CONDA_PREFIX%"><pre><span><span>#</span> Install dependencies</span>
conda install conda-forge::openblas conda-forge::flann

<span><span>#</span> Get conda prefix</span>
<span>echo</span> %CONDA_PREFIX%</pre></div>
<p dir="auto"><code>CONDA_PREFIX</code> will give you the prefix for your conda installation. Keep it around.</p>
<p dir="auto">After that, the following will build the wheel and place it inside a <em>dist</em> folder.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Clone repository
git clone https://github.com/big-nacho/patolette.git
cd patolette

# If CONDA_PREFIX = C:\miniconda3 then replace with C:\\miniconda3 (use double backslashes)
$env:CMAKE_ARGS = &quot;-DCMAKE_PREFIX_PATH={CONDA_PREFIX}\\Library&quot;

# Optional: set OPT_LEVEL (check Note for x86 section)
$env:CMAKE_ARGS = $env:CMAKE_ARGS + &quot; &quot; + &quot;-DOPT_LEVEL=avx2&quot;

# Install build module
pip install build

# Build wheel
python -m build"><pre><span><span>#</span> Clone repository</span>
git clone https:<span>//</span><span>github.com</span><span>/</span>big<span>-</span>nacho<span>/</span>patolette.git
cd patolette

<span><span>#</span> If CONDA_PREFIX = C:\miniconda3 then replace with C:\\miniconda3 (use double backslashes)</span>
<span>$<span>env:</span>CMAKE_ARGS</span> <span>=</span> <span><span>"</span>-DCMAKE_PREFIX_PATH={CONDA_PREFIX}\\Library<span>"</span></span>

<span><span>#</span> Optional: set OPT_LEVEL (check Note for x86 section)</span>
<span>$<span>env:</span>CMAKE_ARGS</span> <span>=</span> <span>$<span>env:</span>CMAKE_ARGS</span> <span>+</span> <span><span>"</span> <span>"</span></span> <span>+</span> <span><span>"</span>-DOPT_LEVEL=avx2<span>"</span></span>

<span><span>#</span> Install build module</span>
pip install build

<span><span>#</span> Build wheel</span>
python <span>-</span>m build</pre></div>
<p dir="auto">Now, you can't just install that wheel, because <em>.dll</em> files won't be found at runtime. First you need to repair it. The following will repair and install the built wheel in your currently active virtual environment.</p>
<div dir="auto" data-snippet-clipboard-copy-content="
# Install delvewheel
pip install delvewheel

# Repair wheel
delvewheel repair --add-path {CONDA_PREFIX}\\Library\\bin dist\\*.whl

# Install repaired wheel
pip install wheelhouse\\{WHEEL_NAME}.whl"><pre><span><span>#</span> Install delvewheel</span>
pip install delvewheel

<span><span>#</span> Repair wheel</span>
delvewheel repair <span>--</span><span>add-path</span> {CONDA_PREFIX}\\Library\\bin dist\\<span>*</span>.whl

<span><span>#</span> Install repaired wheel</span>
pip install wheelhouse\\{WHEEL_NAME}.whl</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Basic Usage</h2><a id="user-content-basic-usage" aria-label="Permalink: Basic Usage" href="#basic-usage"></a></p>
<p dir="auto">The library doesn't take care of image decoding / encoding. You need to do that yourself. In the below example the <a href="https://pillow.readthedocs.io/en/stable/" rel="nofollow">Pillow</a> library is used, but you can use whatever you want.</p>
<p dir="auto">You can find more details on each parameter in the docstrings for the <code>quantize</code> function.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import numpy as np
from PIL import Image
from patolette import quantize, ColorSpace_ICtCp

path = 'image.png'

# Read image
img = Image.open(path)
img = img.convert(mode = 'RGB')
width = img.width
height = img.height
img = np.asarray(img)

# Get colors (they should be in sRGB[0, 1] color space)
colors = img.reshape((-1, 3)).astype(np.float64)
colors /= 255

# Quantize
success, palette, palette_map, message = quantize(
    width,
    height,
    colors,
    256,
    # If you want progress console output
    verbose=True,
    # The following are all defaults
    dither=True,
    palette_only=False,
    color_space=ColorSpace_ICtCp,
    tile_size=512,
    kmeans_niter=32,
    kmeans_max_samples=512 ** 2
)

if not success:
    print(message)
    exit()

# Palette is returned in sRGB[0, 1] color space
palette *= 255
palette = np.clip(palette, 0, 255)
palette = palette.astype(np.uint8)

# Save result
# NOTE: if you're trying to reduce file size,
# you may want to save a palette-based PNG instead
quantized = palette[palette_map].reshape(img.shape)
quantized = Image.fromarray(quantized)
quantized.save('result.png')"><pre><span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>from</span> <span>PIL</span> <span>import</span> <span>Image</span>
<span>from</span> <span>patolette</span> <span>import</span> <span>quantize</span>, <span>ColorSpace_ICtCp</span>

<span>path</span> <span>=</span> <span>'image.png'</span>

<span># Read image</span>
<span>img</span> <span>=</span> <span>Image</span>.<span>open</span>(<span>path</span>)
<span>img</span> <span>=</span> <span>img</span>.<span>convert</span>(<span>mode</span> <span>=</span> <span>'RGB'</span>)
<span>width</span> <span>=</span> <span>img</span>.<span>width</span>
<span>height</span> <span>=</span> <span>img</span>.<span>height</span>
<span>img</span> <span>=</span> <span>np</span>.<span>asarray</span>(<span>img</span>)

<span># Get colors (they should be in sRGB[0, 1] color space)</span>
<span>colors</span> <span>=</span> <span>img</span>.<span>reshape</span>((<span>-</span><span>1</span>, <span>3</span>)).<span>astype</span>(<span>np</span>.<span>float64</span>)
<span>colors</span> <span>/=</span> <span>255</span>

<span># Quantize</span>
<span>success</span>, <span>palette</span>, <span>palette_map</span>, <span>message</span> <span>=</span> <span>quantize</span>(
    <span>width</span>,
    <span>height</span>,
    <span>colors</span>,
    <span>256</span>,
    <span># If you want progress console output</span>
    <span>verbose</span><span>=</span><span>True</span>,
    <span># The following are all defaults</span>
    <span>dither</span><span>=</span><span>True</span>,
    <span>palette_only</span><span>=</span><span>False</span>,
    <span>color_space</span><span>=</span><span>ColorSpace_ICtCp</span>,
    <span>tile_size</span><span>=</span><span>512</span>,
    <span>kmeans_niter</span><span>=</span><span>32</span>,
    <span>kmeans_max_samples</span><span>=</span><span>512</span> <span>**</span> <span>2</span>
)

<span>if</span> <span>not</span> <span>success</span>:
    <span>print</span>(<span>message</span>)
    <span>exit</span>()

<span># Palette is returned in sRGB[0, 1] color space</span>
<span>palette</span> <span>*=</span> <span>255</span>
<span>palette</span> <span>=</span> <span>np</span>.<span>clip</span>(<span>palette</span>, <span>0</span>, <span>255</span>)
<span>palette</span> <span>=</span> <span>palette</span>.<span>astype</span>(<span>np</span>.<span>uint8</span>)

<span># Save result</span>
<span># NOTE: if you're trying to reduce file size,</span>
<span># you may want to save a palette-based PNG instead</span>
<span>quantized</span> <span>=</span> <span>palette</span>[<span>palette_map</span>].<span>reshape</span>(<span>img</span>.<span>shape</span>)
<span>quantized</span> <span>=</span> <span>Image</span>.<span>fromarray</span>(<span>quantized</span>)
<span>quantized</span>.<span>save</span>(<span>'result.png'</span>)</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Color Spaces</h2><a id="user-content-color-spaces" aria-label="Permalink: Color Spaces" href="#color-spaces"></a></p>
<p dir="auto">Three different color spaces are supported for the palette generation step. The following are rules of thumb you can go by, but experiment and see what works best for you.</p>
<p dir="auto"><strong>CIEL*u*v*</strong>: generates exceptionally high quality color palettes and it's the best choice for very low color counts. However, it creates the least smooth results and performs poorly on some hues.</p>
<p dir="auto"><strong>sRGB</strong>: outputs relatively smooth results (and it's the most consistent in this regard) but it generates the lowest quality color palettes and it's not that well suited for lower color counts.</p>
<p dir="auto"><strong>ICtCp</strong> (default): a good tradeoff between the two former. Generally, it generates slightly smoother results than <strong>sRGB</strong>, but it's a little bit less consistent, and the quality of the color palettes it generates is quite good.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tile Size</h2><a id="user-content-tile-size" aria-label="Permalink: Tile Size" href="#tile-size"></a></p>
<p dir="auto"><em>patolette</em> optimizes against size-weighted variance during the palette generation stage (the same way <em>KMeans</em> and other quantizers of similar nature do). This however comes with the known issue of large clusters dominating small, well defined ones.</p>
<p dir="auto">The <code>tile_size</code> parameter can be used to mitigate this issue. When non-zero, an extra step is introduced in the pipeline. A <a href="https://en.wikipedia.org/wiki/Saliency_map#:~:text=In%20computer%20vision%2C%20a%20saliency,an%20otherwise%20opaque%20ML%20model." rel="nofollow">saliency map</a> is computed and used to weight samples based on how much they stand out visually. The lower the tile size, the stronger the effect. The default tile size is <code>512</code>.</p>
<p dir="auto">Below is a quick showcase.<br></p>
<p dir="auto"><em>top-left</em>: input image<br>
<em>top-right</em>: saliency map<br>
<em>bottom-left</em>: quantized with no saliency map<br>
<em>bottom-right</em>: quantized with saliency map.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/67847653/452618755-8ad4784c-bfc6-4d0d-8130-acf8e5e4ebf2.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDk1OTQ5MDIsIm5iZiI6MTc0OTU5NDYwMiwicGF0aCI6Ii82Nzg0NzY1My80NTI2MTg3NTUtOGFkNDc4NGMtYmZjNi00ZDBkLTgxMzAtYWNmOGU1ZTRlYmYyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA2MTAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNjEwVDIyMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdiYTQ5NmQxNjg4NjkxYTBhNjcwZmYxYjdlNzg0NTg0NDI3ZWY5Nzk0NmY3NjIxZWFkYTA2YzUzMTUwYWViOTAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.f6Nfq4LzIodjTqyxnUZUt_AlvIsZ8TmwlJlpG_n0nek"><img width="100%" src="https://private-user-images.githubusercontent.com/67847653/452618755-8ad4784c-bfc6-4d0d-8130-acf8e5e4ebf2.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDk1OTQ5MDIsIm5iZiI6MTc0OTU5NDYwMiwicGF0aCI6Ii82Nzg0NzY1My80NTI2MTg3NTUtOGFkNDc4NGMtYmZjNi00ZDBkLTgxMzAtYWNmOGU1ZTRlYmYyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA2MTAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNjEwVDIyMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTdiYTQ5NmQxNjg4NjkxYTBhNjcwZmYxYjdlNzg0NTg0NDI3ZWY5Nzk0NmY3NjIxZWFkYTA2YzUzMTUwYWViOTAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.f6Nfq4LzIodjTqyxnUZUt_AlvIsZ8TmwlJlpG_n0nek"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Caveats</h2><a id="user-content-caveats" aria-label="Permalink: Caveats" href="#caveats"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Memory Usage</h3><a id="user-content-memory-usage" aria-label="Permalink: Memory Usage" href="#memory-usage"></a></p>
<p dir="auto">The main priority for <code>v1</code> is to reduce memory consumption, at the moment it is quite high. If you limit yourself to quantizing images up to <strong>4k</strong> resolution you're on the pretty safe side, but if you go above <strong>6k</strong> you may start going into the danger zone depending on your system. Below is a chart depicting memory usage for different resolutions (<em>including</em> the space needed for the storage of the input image).</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/67847653/452617111-7c2800cd-9334-431c-89aa-e29548346c0c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDk1OTQ5MDIsIm5iZiI6MTc0OTU5NDYwMiwicGF0aCI6Ii82Nzg0NzY1My80NTI2MTcxMTEtN2MyODAwY2QtOTMzNC00MzFjLTg5YWEtZTI5NTQ4MzQ2YzBjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA2MTAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNjEwVDIyMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTk2YWEyM2NmZWI0NjhkOTY1YmY3YTJjNGQyODI2MjQyMjc2ZjdkM2QyODY5MWNhODZhZWRmNDI2ZGM0NzA4NmYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.Ztk5CyfgHmeXGbZdGJv2HlZSQieja3hQ9QjOh7m1xWY"><img src="https://private-user-images.githubusercontent.com/67847653/452617111-7c2800cd-9334-431c-89aa-e29548346c0c.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDk1OTQ5MDIsIm5iZiI6MTc0OTU5NDYwMiwicGF0aCI6Ii82Nzg0NzY1My80NTI2MTcxMTEtN2MyODAwY2QtOTMzNC00MzFjLTg5YWEtZTI5NTQ4MzQ2YzBjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA2MTAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNjEwVDIyMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTk2YWEyM2NmZWI0NjhkOTY1YmY3YTJjNGQyODI2MjQyMjc2ZjdkM2QyODY5MWNhODZhZWRmNDI2ZGM0NzA4NmYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.Ztk5CyfgHmeXGbZdGJv2HlZSQieja3hQ9QjOh7m1xWY"></a>
</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Speed</h3><a id="user-content-speed" aria-label="Permalink: Speed" href="#speed"></a></p>
<p dir="auto">It's not nearly as fast as it could be yet, but will most likely stay slow compared to fast methods like median cut / octree, etc. Below is a chart with execution times for some resolutions, quantizing to 256 colors (ICtCp), <em>with</em> saliency maps and dithering on. Testing was performed on an 11 core Apple M3 Pro CPU.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/67847653/453198659-b34d55cc-3778-4f90-a688-f81e8c5c8077.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDk1OTQ5MDIsIm5iZiI6MTc0OTU5NDYwMiwicGF0aCI6Ii82Nzg0NzY1My80NTMxOTg2NTktYjM0ZDU1Y2MtMzc3OC00ZjkwLWE2ODgtZjgxZThjNWM4MDc3LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA2MTAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNjEwVDIyMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWIyODJjYmJkYjAxYTY4NThmMzEwNDhlYjIyZDY0ZjllMjRhNmI0YjhiYjBlOTFlNzJiNzYyZDNiZjU0MDRkOTQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.pMJvSFkA57_32u5uTi5s58EDyYiuiNUMDSm4tCcNRMk"><img src="https://private-user-images.githubusercontent.com/67847653/453198659-b34d55cc-3778-4f90-a688-f81e8c5c8077.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDk1OTQ5MDIsIm5iZiI6MTc0OTU5NDYwMiwicGF0aCI6Ii82Nzg0NzY1My80NTMxOTg2NTktYjM0ZDU1Y2MtMzc3OC00ZjkwLWE2ODgtZjgxZThjNWM4MDc3LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA2MTAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNjEwVDIyMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWIyODJjYmJkYjAxYTY4NThmMzEwNDhlYjIyZDY0ZjllMjRhNmI0YjhiYjBlOTFlNzJiNzYyZDNiZjU0MDRkOTQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.pMJvSFkA57_32u5uTi5s58EDyYiuiNUMDSm4tCcNRMk"></a>
</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using From C</h3><a id="user-content-using-from-c" aria-label="Permalink: Using From C" href="#using-from-c"></a></p>
<p dir="auto">Until <code>v1</code> is ready, the C API is incomplete. Mainly, support for weighted quantization via saliency maps is not there, so you won't find a <code>tile_size</code> parameter. It does however allow you to supply your own weights if you want.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">No RGBA support</h3><a id="user-content-no-rgba-support" aria-label="Permalink: No RGBA support" href="#no-rgba-support"></a></p>
<p dir="auto">For the time being, images with transparency are not supported, though if you have the pretty common use case of subject + fully transparent background, you can always fake it yourself by using a mask, but results may not be optimal.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgements</h2><a id="user-content-acknowledgements" aria-label="Permalink: Acknowledgements" href="#acknowledgements"></a></p>
<p dir="auto">This library stands on the following works / projects.</p>
<p dir="auto"><em>Color Quantization by Dynamic Programming and Principal Analysis, Xiaolin Wu</em> <a href="https://dl.acm.org/doi/pdf/10.1145/146443.146475" rel="nofollow">[1]</a></p>
<p dir="auto"><em>Minimum Barrier Salient Object Detection at 80 FPS, Jianming Zhang, Stan Sclaroff, Zhe Lin, Xiaohui Shen, Brian Price, Randomír Mech</em> <a href="https://openaccess.thecvf.com/content_iccv_2015/papers/Zhang_Minimum_Barrier_Salient_ICCV_2015_paper.pdf" rel="nofollow">[2]</a></p>
<p dir="auto"><em>Riemersma Dithering</em> <a href="https://www.compuphase.com/riemer.htm" rel="nofollow">[3]</a></p>
<p dir="auto"><a href="https://github.com/facebookresearch/faiss">faiss</a></p>
<p dir="auto"><a href="https://github.com/flann-lib/flann">flann</a></p>
<p dir="auto"><a href="https://github.com/OpenMathLib/OpenBLAS">OpenBLAS</a></p>
<hr>
<p dir="auto">Thanks, Anna ❤️</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA["Localhost tracking" explained. It could cost Meta €32B (402 pts)]]></title>
            <link>https://www.zeropartydata.es/p/localhost-tracking-explained-it-could</link>
            <guid>44235467</guid>
            <pubDate>Tue, 10 Jun 2025 11:29:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.zeropartydata.es/p/localhost-tracking-explained-it-could">https://www.zeropartydata.es/p/localhost-tracking-explained-it-could</a>, See on <a href="https://news.ycombinator.com/item?id=44235467">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>Meta devised an ingenious system (“localhost tracking”) that bypassed Android’s sandbox protections to identify you while browsing on your mobile phone — even if you used a VPN, the browser’s incognito mode, and refused or deleted cookies in every session.</p><p>Next, we preview what may (and should) become the combined sanctioning smackdown of the century, and then we explain — in simple terms (because it’s complicated) — what Meta was doing.</p><p>Meta faces simultaneous liability under the following regulations, listed from least to most severe: GDPR, DSA, and DMA (I’m not even including the ePrivacy Directive because it’s laughable).</p><p>GDPR, DMA, and DSA protect different legal interests, so the penalties under each can be imposed cumulatively.</p><p>The combined theoretical maximum risk amounts to approximately €32 billion** (4% + 6% + 10% of Meta’s global annual revenue, which surpassed €164 billion in 2024).</p><p>Maximum fines have never before been applied simultaneously, but some might say these scoundrels have earned it.</p><p><span>If you want to go straight to the breakdown of infractions and penalties, click </span><strong><a href="https://citizen8.eu/localhost-tracking-explained-it-could-cost-meta-32-billion/" rel="">here</a></strong><span>.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3808b62b-e2a1-44c8-bcd5-fcf8224f7d25_925x778.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3808b62b-e2a1-44c8-bcd5-fcf8224f7d25_925x778.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3808b62b-e2a1-44c8-bcd5-fcf8224f7d25_925x778.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3808b62b-e2a1-44c8-bcd5-fcf8224f7d25_925x778.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3808b62b-e2a1-44c8-bcd5-fcf8224f7d25_925x778.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3808b62b-e2a1-44c8-bcd5-fcf8224f7d25_925x778.png" width="925" height="778" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3808b62b-e2a1-44c8-bcd5-fcf8224f7d25_925x778.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:778,&quot;width&quot;:925,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:785315,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.zeropartydata.es/i/165552054?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3808b62b-e2a1-44c8-bcd5-fcf8224f7d25_925x778.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3808b62b-e2a1-44c8-bcd5-fcf8224f7d25_925x778.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3808b62b-e2a1-44c8-bcd5-fcf8224f7d25_925x778.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3808b62b-e2a1-44c8-bcd5-fcf8224f7d25_925x778.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3808b62b-e2a1-44c8-bcd5-fcf8224f7d25_925x778.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>You’re reading ZERO PARTY DATA. The newsletter about the crazy crazy world news from a data protection perspective by Jorge García Herrero and Darío López Rincón.</p><p>In the spare time this newsletter leaves us, we like to solve complicated issues about GDPR &amp; AI Act. If you’ve got one of those, give us a little wave. Or contact us by email at jgh(at)jorgegarciaherrero.com.          </p><p><span>Below is a simplified explanation of a very technical process, </span><strong><a href="https://localmess.github.io/" rel="">rigorously detailed on the website set up by the researchers who uncovered Meta’s latest major blow</a></strong><span> to the GDPR specifically, and to other regulations more broadly, as we’ll see.</span></p><p>Credit where it’s due — it’s ingenious. Ingenious in the sense of breaking (yet again) the record for a privacy-related fine, but hey!... ingenious.</p><p>This is the process through which Meta (Facebook/Instagram) managed to link what you do in your browser (for example, visiting a news site or an online store) with your real identity (your Facebook or Instagram account), even if you never logged into your account through the browser or anything like that.</p><p>Meta accomplishes this through two invisible channels that exchange information:</p><p>(i) The Facebook or Instagram app running in the background on your phone, even when you’re not using it.</p><p>(ii) Meta’s tracking scripts (the now-pulled illegal brainchild uncovered last week), which operate inside your mobile web browser.</p><p><strong>Thanks</strong><span> to the outstanding human beings who revealed this scandal: </span><strong>Tim Vlummens, Narseo Vallina-Rodriguez, Nipuna Weerasekara, Gunes Acar, and Aniketh Girish</strong><span>.</span></p><blockquote><p>The entire flow of the _fbp cookie from web to native and the server is as follows:</p><ol><li><p>The user opens the native Facebook or Instagram app, which eventually is sent to the background and creates a background service to listen for incoming traffic on a TCP port (12387 or 12388) and a UDP port (the first unoccupied port in 12580-12585). Users must be logged-in with their credentials on the apps.</p></li><li><p>The user opens their browser and visits a website integrating the Meta Pixel.</p></li><li><p>At this stage, websites may ask for consent depending on the website's and visitor's locations.</p></li><li><p><span>The Meta Pixel script sends the </span><a href="https://localmess.github.io/#about_fbp" rel="">_fbp cookie</a><span> to the native Instagram or Facebook app via WebRTC (STUN) SDP Munging.</span></p></li><li><p><span>The Meta Pixel script also sends the _fbp value in a request to https://www.facebook.com/tr along with other parameters such as page URL (dl), website and browser metadata, and the </span><a href="https://web.archive.org/web/20250531104925/https://developers.facebook.com/docs/meta-pixel/reference/" rel="">event type</a><span> (ev) (e.g., PageView, AddToCart, Donate, Purchase).</span></p></li><li><p>The Facebook or Instagram apps receive the _fbp cookie from the Meta Pixel JavaScript running on the browser. The apps transmit _fbp as a GraphQL mutation to (https://graph[.]facebook[.]com/graphql) along with other persistent user identifiers, linking users' fbp ID (web visit) with their Facebook or Instagram account.</p></li></ol></blockquote><p>If I understood it, you can too — trust me.</p><blockquote><p><span>“</span><em>The user opens the native Facebook or Instagram app, which eventually goes into the background and creates a background service to listen for incoming traffic on a TCP port (12387 or 12388) and a UDP port (the first free port between 12580 and 12585). Users must have logged in with their credentials in the apps</em><span>.”</span></p></blockquote><p><strong>Translation:</strong></p><p>You open the Facebook or Instagram app like normal.</p><p>Then you go do something else on your phone (the app remains running in the background).</p><p>Without telling you, the app keeps running and “listens” for traffic — like having a hidden microphone eavesdropping on internal calls.</p><p>Technically, it does this by opening local network “ports” (like little internal doors in your phone) through which it can receive messages.</p><p>It’s important to clarify that this only happens if you've already logged into those apps with your account.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63846217-7cdf-490c-a5c1-c4adefcc2391_7500x5000.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63846217-7cdf-490c-a5c1-c4adefcc2391_7500x5000.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63846217-7cdf-490c-a5c1-c4adefcc2391_7500x5000.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63846217-7cdf-490c-a5c1-c4adefcc2391_7500x5000.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63846217-7cdf-490c-a5c1-c4adefcc2391_7500x5000.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63846217-7cdf-490c-a5c1-c4adefcc2391_7500x5000.jpeg" width="1456" height="971" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/63846217-7cdf-490c-a5c1-c4adefcc2391_7500x5000.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2313006,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.zeropartydata.es/i/165526623?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63846217-7cdf-490c-a5c1-c4adefcc2391_7500x5000.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63846217-7cdf-490c-a5c1-c4adefcc2391_7500x5000.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63846217-7cdf-490c-a5c1-c4adefcc2391_7500x5000.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63846217-7cdf-490c-a5c1-c4adefcc2391_7500x5000.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F63846217-7cdf-490c-a5c1-c4adefcc2391_7500x5000.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>(Insert your favorite ultra-private vice here — let’s say mine is watching chick sexers doing their thing. Just saying.)</p><blockquote><p><span>“</span><em>The user opens their browser and visits a website that integrates Meta’s Pixel</em><span>.”</span></p></blockquote><p>You open Chrome, Firefox, or any browser on the same phone.</p><p>You turn on VPN and incognito mode and, confidently like a fool, head straight to that website — which, by coincidence, has a Meta Pixel embedded.</p><p>This pixel, with your consent, collects data about your actions (visits, clicks, purchases...) and sends it to Meta.</p><p>What has now been proven is that, before you even had the chance to give consent, the pixel starts the localhost tracking process we're explaining here.</p><p>Theoretically, this should have been explained when asking for cookie consent. Obviously, it wasn’t — because it was blatantly illegal.</p><p>I mean, even if you had clicked the “consent” button on the chick sexer website, that consent can’t cover something you were never informed about (note that this trick even caught Google off guard).</p><blockquote><p><em>“The Meta Pixel script sends the _fbp cookie to the native Instagram or Facebook app via WebRTC (STUN) using SDP modification (SDP Munging).”</em></p></blockquote><p>The Pixel script in your browser tries to send information to the Facebook/Instagram app that’s “listening” in the background.</p><p>It uses a technique called WebRTC, normally used for voice or video calls (like Zoom or Google Meet), but here it’s being used to secretly transmit data between the browser and the app.</p><p>Additionally, a technical trick called “SDP Munging” allows the browser to insert data (like the _fbp cookie identifier) into the WebRTC “initial handshake” message.</p><p>In this way, the _fbp (a temporary cookie supposedly limited to your current web session) is sent directly to the native app that’s listening. In other words, the website you didn’t want anyone to know you visited just passed your identification cookie to your Facebook/Instagram app. It’s still just an alphanumeric string at this point.</p><p>But that alphanumeric sausage, my friend — is you.</p><p>Android has many flaws, but in the relevant part here, it’s specifically designed to prevent apps from doing this — from listening to local ports like localhost.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a64ebad-935a-4de7-a91a-d9c7e85a104c_1384x690.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a64ebad-935a-4de7-a91a-d9c7e85a104c_1384x690.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a64ebad-935a-4de7-a91a-d9c7e85a104c_1384x690.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a64ebad-935a-4de7-a91a-d9c7e85a104c_1384x690.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a64ebad-935a-4de7-a91a-d9c7e85a104c_1384x690.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a64ebad-935a-4de7-a91a-d9c7e85a104c_1384x690.png" width="1384" height="690" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0a64ebad-935a-4de7-a91a-d9c7e85a104c_1384x690.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:690,&quot;width&quot;:1384,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1596376,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:&quot;&quot;,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.zeropartydata.es/i/165526623?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a64ebad-935a-4de7-a91a-d9c7e85a104c_1384x690.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a64ebad-935a-4de7-a91a-d9c7e85a104c_1384x690.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a64ebad-935a-4de7-a91a-d9c7e85a104c_1384x690.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a64ebad-935a-4de7-a91a-d9c7e85a104c_1384x690.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0a64ebad-935a-4de7-a91a-d9c7e85a104c_1384x690.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><blockquote><p><em><span>“The Meta Pixel script also sends the _fbp value in a request to </span><a href="https://www.facebook.com/tr" rel="">https://www.facebook.com/tr</a><span> along with other parameters such as the page URL (dl), website and browser metadata, and the event type (ev) (e.g., PageView, AddToCart, Donate, Purchase).”</span></em></p></blockquote><p><strong>WHAT?</strong></p><p>At the same time, the Pixel sends the same information (the _fbp cookie) to Meta’s servers over the internet, along with:</p><ul><li><p>The URL you’re visiting</p></li><li><p>Your browser and operating system</p></li><li><p>The type of event performed (e.g., “page view,” “add to cart” or, in the case of chick sexer videos... better not know, trust me)</p></li></ul><p><span>It’s like the Pixel is sending the same letter through two routes:</span><br><span>(a) directly to Facebook’s servers, and</span><br><span>(b) to the Facebook app inside your phone.</span></p><blockquote><p><em>“The Facebook or Instagram apps receive the _fbp cookie from the Meta Pixel JavaScript running in the browser. The apps transmit _fbp as a GraphQL mutation to (https://graph[.]facebook[.]com/graphql) along with other persistent user identifiers, linking the user's fbp ID (web visit) with their Facebook or Instagram account.”</em></p></blockquote><p>The app, upon receiving the _fbp identifier, bundles it together with your real account (the one you’re logged into in the app).</p><p>Then, it sends it all to Meta’s servers, where they can now say:</p><p><em>“Aha! This _fbp identifier (from that questionable website you just visited) belongs to Jorge García Herrero, Instagram user.”</em></p><p><em>“Chick sexers? Seriously, bald guy?”</em></p><p>And just like that, they link your web activity (browser) to your real identity (account) — even if you never logged into your account in that browser or gave any explicit consent for it.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d887f6b-c879-49a5-846f-a5a444d655cf_1180x639.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d887f6b-c879-49a5-846f-a5a444d655cf_1180x639.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d887f6b-c879-49a5-846f-a5a444d655cf_1180x639.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d887f6b-c879-49a5-846f-a5a444d655cf_1180x639.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d887f6b-c879-49a5-846f-a5a444d655cf_1180x639.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d887f6b-c879-49a5-846f-a5a444d655cf_1180x639.png" width="1180" height="639" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2d887f6b-c879-49a5-846f-a5a444d655cf_1180x639.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:639,&quot;width&quot;:1180,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1002720,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.zeropartydata.es/i/165526623?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d887f6b-c879-49a5-846f-a5a444d655cf_1180x639.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d887f6b-c879-49a5-846f-a5a444d655cf_1180x639.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d887f6b-c879-49a5-846f-a5a444d655cf_1180x639.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d887f6b-c879-49a5-846f-a5a444d655cf_1180x639.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2d887f6b-c879-49a5-846f-a5a444d655cf_1180x639.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Meta has used a technical loophole that privacy protection systems didn’t anticipate — in fact, they were specifically designed to prevent it.</p><ul><li><p>You aren’t using the app (but have a session open in the background).</p></li><li><p>You haven’t logged into your account in the browser.</p></li><li><p>You’re browsing in incognito mode.</p></li><li><p>You’re using a VPN.</p></li><li><p>You delete cookies at the end of every session.</p></li></ul><p>Once again, Meta has blatantly disregarded the requirement to obtain informed user consent before collecting and combining personal information from different sources.</p><p><span>22% of the most visited websites in the world are affected. In the U.S., 17,223 sites with the Meta Pixel and 1,312 with Yandex Metrica initiated this tracking </span><strong>without user consent</strong><span>. Over 8 years (Yandex) and at least 9 months (Meta), billions of users were tracked without their knowledge.</span></p><ul><li><p>Complete browsing history with specific URLs</p></li><li><p>Products added to cart and purchases made</p></li><li><p>Registrations on websites and completed forms</p></li><li><p>Temporal behavioral patterns across websites and apps</p></li><li><p>Direct linking to real identities on social networks</p></li></ul><ul><li><p>You access Facebook and Instagram via the web, without having the apps installed on your phone</p></li><li><p>You browse on desktop computers or use iOS (iPhones)</p></li><li><p>You always used the Brave browser or the DuckDuckGo search engine on mobile</p></li></ul><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09cf9acf-b0ec-40b5-b092-c67c75c9f50a_4205x2805.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09cf9acf-b0ec-40b5-b092-c67c75c9f50a_4205x2805.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09cf9acf-b0ec-40b5-b092-c67c75c9f50a_4205x2805.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09cf9acf-b0ec-40b5-b092-c67c75c9f50a_4205x2805.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09cf9acf-b0ec-40b5-b092-c67c75c9f50a_4205x2805.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09cf9acf-b0ec-40b5-b092-c67c75c9f50a_4205x2805.jpeg" width="1456" height="971" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/09cf9acf-b0ec-40b5-b092-c67c75c9f50a_4205x2805.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2097152,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.zeropartydata.es/i/165552054?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09cf9acf-b0ec-40b5-b092-c67c75c9f50a_4205x2805.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09cf9acf-b0ec-40b5-b092-c67c75c9f50a_4205x2805.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09cf9acf-b0ec-40b5-b092-c67c75c9f50a_4205x2805.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09cf9acf-b0ec-40b5-b092-c67c75c9f50a_4205x2805.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09cf9acf-b0ec-40b5-b092-c67c75c9f50a_4205x2805.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>As stated at the beginning, Meta faces simultaneous liability under the following regulations, ranked from lesser to greater severity (not including the </span><strong>ePrivacy Directive</strong><span> — it’s a joke at this point):</span></p><ul><li><p><strong>GDPR:</strong><span> Requires consent to process personal data for ad personalization. Meta also violated the principles of data minimization and privacy by design. (Up to 4% of global annual turnover)</span></p></li><li><p><strong>DSA (Art. 26):</strong><span> Explicitly prohibits personalized advertising based on profiles created from special categories of personal data (e.g., sexual orientation, political views, health data).</span></p></li></ul><p>If such data could be inferred from users’ interactions on websites and apps (which is almost certain, given the scale of the violation — reaching 25% of the world’s most visited sites), the penalty could reach 10% of turnover. </p><p>CJEU has been clear about this one (“Fondas” C-184/20 and Bundeskartellamt).</p><p>Meta was declared a VLOP (Very Large Online Platform) in February 2024 and was already under investigation for violations involving content moderation transparency, child protection, and election integrity.</p><ul><li><p><strong>DMA (Art. 5.2):</strong><span> The most damaging one: it specifically prohibits combining personal data between core platform services without the user’s </span><strong>explicit</strong><span> consent, as defined by GDPR. The localhost tracking technique combines data across at least Facebook and Instagram, and potentially WhatsApp and Messenger as well.</span></p></li></ul><p>The DMA carries the highest financial risk — fines up to 10% of global turnover (€16.4 billion), increasing to 20% for repeat offenses.</p><p>Meta was designated a gatekeeper in September 2023 and received its first DMA fine in April 2025: €200 million for its “pay or consent” model.</p><p>Meta will undoubtedly claim it already had user consent to do this, but here’s the truth: it needed three specific consents to process the data (GDPR), access the device (ePrivacy), and combine profiles across services (DMA). It only requested one — and even that with a coercive “pay or okay” alternative.</p><p>Unfortunately, Meta’s most recent fine was precisely over its “pay or okay” approach.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F25fce5fb-bf4d-424c-9307-387c55eb2896_886x316.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F25fce5fb-bf4d-424c-9307-387c55eb2896_886x316.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F25fce5fb-bf4d-424c-9307-387c55eb2896_886x316.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F25fce5fb-bf4d-424c-9307-387c55eb2896_886x316.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F25fce5fb-bf4d-424c-9307-387c55eb2896_886x316.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F25fce5fb-bf4d-424c-9307-387c55eb2896_886x316.png" width="886" height="316" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/25fce5fb-bf4d-424c-9307-387c55eb2896_886x316.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:316,&quot;width&quot;:886,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:101075,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.zeropartydata.es/i/165552054?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F25fce5fb-bf4d-424c-9307-387c55eb2896_886x316.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F25fce5fb-bf4d-424c-9307-387c55eb2896_886x316.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F25fce5fb-bf4d-424c-9307-387c55eb2896_886x316.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F25fce5fb-bf4d-424c-9307-387c55eb2896_886x316.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F25fce5fb-bf4d-424c-9307-387c55eb2896_886x316.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>GDPR, DMA, and DSA protect different legal rights, so the penalties under each can be imposed cumulatively.</p><p>The combined theoretical maximum risk amounts to approximately €32 billion (4% + 6% + 10% of Meta’s global annual revenue, which exceeds €164 billion).</p><p>Maximum fines have never before been applied simultaneously, but one could argue these bad guys have earned it.</p><p>Several factors favor setting that precedent: Meta’s long record of violations (it holds the record for GDPR fines in Europe), its lack of cooperation with regulatory investigations, the systemic impact of this scheme given its market dominance, and the clear intent to bypass all technical and legal protections established for users.</p><p><strong>Jorge García Herrero</strong></p><p><strong>Data Protection Officer</strong></p><p data-attrs="{&quot;url&quot;:&quot;https://www.zeropartydata.es/?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Compartir Zero Party Data&quot;,&quot;action&quot;:null,&quot;class&quot;:&quot;button-wrapper&quot;}" data-component-name="ButtonCreateButton"><a href="https://www.zeropartydata.es/?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Compartir Zero Party Data</span></a></p><p data-attrs="{&quot;url&quot;:&quot;https://www.zeropartydata.es/p/por-que-el-faceid-del-iphone-es-licito/comments&quot;,&quot;text&quot;:&quot;Deja un comentario&quot;,&quot;action&quot;:null,&quot;class&quot;:&quot;button-wrapper&quot;}" data-component-name="ButtonCreateButton"><a href="https://www.zeropartydata.es/p/por-que-el-faceid-del-iphone-es-licito/comments" rel=""><span>Deja un comentario</span></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[WWDC25: macOS Tahoe Breaks Decades of Finder History (116 pts)]]></title>
            <link>https://512pixels.net/2025/06/wwdc25-macos-tahoe-breaks-decades-of-finder-history/</link>
            <guid>44235177</guid>
            <pubDate>Tue, 10 Jun 2025 10:52:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://512pixels.net/2025/06/wwdc25-macos-tahoe-breaks-decades-of-finder-history/">https://512pixels.net/2025/06/wwdc25-macos-tahoe-breaks-decades-of-finder-history/</a>, See on <a href="https://news.ycombinator.com/item?id=44235177">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-32553">
	<!-- .entry-header -->

	<div>
		<p>Something jumped out at me in the macOS Tahoe segment of the WWDC keynote today: the Finder icon is reversed.</p>
<p>You can see that in the image below. On the left is macOS Sequoia, and on the right is macOS Tahoe:</p>
<p><img decoding="async" src="https://512pixels.net/wp-content/uploads/2025/06/About-Finder.jpg" alt="About Finder"></p>
<p>I know I am going to sound old and fussy, but Apple needs to roll this back.</p>
<h2>Some History</h2>
<p>The Finder logo has changed over the years, but the dark side has been on the left <em>forever</em>. Here it is on the boot screen on System 7.5.3, which shipped in 1996, an early version of the logo in color:</p>
<p><img decoding="async" src="https://512pixels.net/wp-content/uploads/2025/06/Finder-7-5-3.png" alt="Finder in 7.5.3"></p>
<p>And in the About This Computer screen in Mac OS 8:</p>
<p><img decoding="async" src="https://512pixels.net/wp-content/uploads/2025/06/Finder-About-8-0.png" alt="Finder in 8.0"></p>
<p>This same basic design survived the move to Mac OS X, as can be seen here in the Public Beta from 2000. The only real change was the addition of a little sheen to make it fit in better with the Aqua user interface:</p>
<p><img decoding="async" src="https://512pixels.net/wp-content/uploads/2025/06/10-Public-Beta-Kodiak-About-This-Mac.png" alt="Finder in Public Beta"></p>
<p>Here you can see it in Mac OS X Panther which shipped three years later:</p>
<p><img decoding="async" src="https://512pixels.net/wp-content/uploads/2025/06/10-3-Panther-Finder-Go-Menu.png" alt="Finder in Panther"></p>
<p>The Finder then transitioned to the Retina era in 2012 with OS X Lion:</p>
<p><img decoding="async" src="https://512pixels.net/wp-content/uploads/2025/06/10-7-Lion-About-This-Mac.jpeg" alt="Finder in Lion"></p>
<p>The logo was updated with the redesign that was ushered in with OS X Yosemite in 2014, then tweaked again for macOS Big Sur in 2020:</p>
<p><img decoding="async" src="https://512pixels.net/wp-content/uploads/2025/06/10-10-Yosemite-Stacks.jpeg" alt="Finder in Yosemite"></p>
<p><img decoding="async" src="https://512pixels.net/wp-content/uploads/2025/06/Big-Sur-Apple-Menu.jpeg" alt="Big Sur Finder"></p>
<h2>A Solution</h2>
<p>The Big Sur Finder icon has been with us ever since,<sup id="fnref-32553-fn-car"><a href="#fn-32553-fn-car" title="Read footnote.">1</a></sup> and I hope Apple reverses course here. I understand that the new icon is meant to be in sync with <a href="https://www.apple.com/newsroom/2025/06/apple-introduces-a-delightful-and-elegant-new-software-design/">the new Liquid Glass user interface</a>, but some things are just tradition.</p>
<p>For kicks, I ran the current Finder icon through Apple’s <a href="https://developer.apple.com/icon-composer/">new Icon Composer app,</a> and I think it looks pretty good with Liquid Glass, even in the clear and tinted modes:</p>
<p><img decoding="async" src="https://512pixels.net/wp-content/uploads/2025/06/Liquid-Glass-Finder.jpg" alt="Liquid Glass Finder"></p>
<hr>
<p><strong>This has been filed with Apple as Feedback FB17840162. Yes, seriously.</strong></p>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Danish Ministry of Digitalization Is Switching to Linux and LibreOffice (238 pts)]]></title>
            <link>https://politiken.dk/viden/tech/art10437680/Caroline-Stage-udfaser-Microsoft-i-Digitaliseringsministeriet</link>
            <guid>44234552</guid>
            <pubDate>Tue, 10 Jun 2025 09:30:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://politiken.dk/viden/tech/art10437680/Caroline-Stage-udfaser-Microsoft-i-Digitaliseringsministeriet">https://politiken.dk/viden/tech/art10437680/Caroline-Stage-udfaser-Microsoft-i-Digitaliseringsministeriet</a>, See on <a href="https://news.ycombinator.com/item?id=44234552">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="js-article-section-observer-mounting">
          <header>
            <p>For første gang bliver suverænitet en prioritet i regeringens, kommunernes og regionernes fælles strategi for digitalisering.</p>
          </header>
          
          <figure>
            <picture title="" data-image-overlay-data="{&quot;url&quot;:&quot;https://politiken.dk/incoming/img10442792.di376b/ORIGINALS/original_2000/JD080425-059328&quot;,&quot;highestResImgWidth&quot;:&quot;2000&quot;,&quot;lowResPreRenderUrl&quot;:&quot;https://politiken.dk/incoming/img10442792.di376b/ORIGINALS/original_150/JD080425-059328&quot;,&quot;caption&quot;:&quot;Minister for digitalisering Caroline Stage Olsen (M) vil afprøve såkaldte open source programmer i sit eget ministerium. &quot;,&quot;aspectRatio&quot;:1.5}" js-activate-image-overlay=""><img alt="Minister for digitalisering Caroline Stage Olsen (M) vil afprøve såkaldte open source programmer i sit eget ministerium. " src="https://politiken.dk/incoming/img10442792.di376b/ORIGINALS/original_150/JD080425-059328" data-high-res-url="https://politiken.dk/incoming/img10442792.di376b/ORIGINALS/original_750/JD080425-059328" data-high-res-srcset="&quot;https://politiken.dk/incoming/img10442792.di376b/ORIGINALS/original_615/JD080425-059328 615w, https://politiken.dk/incoming/img10442792.di376b/ORIGINALS/original_750/JD080425-059328 750w, https://politiken.dk/incoming/img10442792.di376b/ORIGINALS/original_960/JD080425-059328 960w&quot;" data-high-res-sizes="&quot;(min-width: 768px) 33vw, (min-width: 1180px) 50vw, (min-width: 1364px) 55vw&quot;" decoding="auto" loading="lazy" srcset="https://politiken.dk/incoming/img10442792.di376b/ORIGINALS/original_150/JD080425-059328" sizes="(min-width: 768px) 33vw, (min-width: 1180px) 50vw, (min-width: 1364px) 55vw"></picture>
            <figcaption>Minister for digitalisering Caroline Stage Olsen (M) vil afprøve såkaldte open source programmer i sit eget ministerium. </figcaption>
          </figure>
        </section><div id="js-article-body">
            <article>
              
              
            </article>
            
            <p>Digitaliseringsminister Caroline Stage (M) vil fra næste måned begynde at udfase Microsoft i sit eget ministerium. Planen er, at omkring halvdelen af medarbejderne om en måneds tid og hen over sommeren skal arbejde med computere, hvor Office 365 er erstattet af Libre Office. Hvis det går som forventet, vil alle medarbejdere være på en open source-løsning i løbet af efteråret.</p>
            <p>Det fortæller ministeren op til lanceringen af en ny digitaliseringsstrategi for de kommende fire år, hvor digital suverænitet for første gang er en prioritet. Strategien er aftalt mellem staten, regionerne og kommunerne.</p>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Denmark: Minister for Digitalization wants to phase out Microsoft (103 pts)]]></title>
            <link>https://nordjyske.dk/nyheder/politik/digitaliseringsminister-vil-udfase-microsoft-i-sit-eget-ministerium/5616096</link>
            <guid>44234290</guid>
            <pubDate>Tue, 10 Jun 2025 08:56:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nordjyske.dk/nyheder/politik/digitaliseringsminister-vil-udfase-microsoft-i-sit-eget-ministerium/5616096">https://nordjyske.dk/nyheder/politik/digitaliseringsminister-vil-udfase-microsoft-i-sit-eget-ministerium/5616096</a>, See on <a href="https://news.ycombinator.com/item?id=44234290">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Fra næste måned har digitaliseringsminister Caroline Stage (M) planer om at mindske brugen af Microsoft og techgigantens programmer.</p><div>
            
<p>Planen er, at halvdelen af medarbejderne i ministeriet hen over sommeren skal benytte et andet tekstprogram end Office-pakken fra Windows, som Microsoft står bag.</p>

            
<p>Det siger Caroline Stage til Politiken.</p>

            
<p>- Jeg vil gerne selv gå forrest og prøve det af. Da muligheden bød sig, ville det da være helt skørt ikke at gribe chancen. Jeg glæder mig meget til at se, hvordan det fungerer i praksis, siger digitaliseringsministeren.</p>

            





            
<p>I stedet skal de ansatte i ministeriet benytte styreprogrammet Libre Office.</p>

            
<p>Microsoft står bag velkendte computerprogrammer som Word, Excel, Teams og PowerPoint.</p>

            
<p>Hvis det går som forventet, vil hele ministeriet være fri af Office-pakken i løbet af efteråret, lyder det.</p>

            
<p>Hvis skiftet væk fra Microsoft bliver for bøvlet, "går vi bare tilbage til det andet på den korte bane", siger Caroline Stage.</p>

            
<p>Tiltaget sker i forbindelse med ministerens ønske om at gøre Danmark mere fri af techgiganter. Særligt gældende for techselskaber med hovedsæde i USA.</p>

            
<p>Caroline Stage har tidligere udtalt, at der skal gøres op med afhængigheden af de store techvirksomheder.</p>

            
<p>Ministerens plan om en udfasning kommer op til lanceringen af en såkaldt digitaliseringsstrategi, der er aftalt mellem staten, regionerne og kommunerne.</p>

            
<p>I den strategi kommer "digital suverænitet" til at være en prioritet fra dansk side, skriver Politiken.</p>

            
<p>Den aktuelle verdenssituation - heriblandt forholdet til USA - har sat skub i en stigende debat om beskyttelse af data og brugen af digital infrastruktur med hovedsæde i USA.</p>

            
<p>I de seneste dage har Enhedslisten og Alternativet ytret ønske om en større frigørelse fra amerikanske techgiganter.</p>

            
<p>Enhedslistens digitaliseringsordfører, Rosa Lund, mener, at Danmark skal kappe forbindelserne til de amerikanske techvirksomheder.</p>

            
<p>Samme ønske har Alternativets Helene Brydensholt gentaget til TV 2 Østjylland.</p>

            
<p>- I Alternativet ønsker vi, at regeringen hurtigst muligt får lagt en plan for, hvordan Danmark kommer fri af de amerikanske techgiganter og bliver digitalt suveræne, siger digitaliseringsordføreren.</p>

            
<p>/ritzau/</p>

                        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Europe needs digital sovereignty – and Microsoft has just proven why (243 pts)]]></title>
            <link>https://tuta.com/blog/digital-sovereignty-europe</link>
            <guid>44233480</guid>
            <pubDate>Tue, 10 Jun 2025 06:51:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tuta.com/blog/digital-sovereignty-europe">https://tuta.com/blog/digital-sovereignty-europe</a>, See on <a href="https://news.ycombinator.com/item?id=44233480">Hacker News</a></p>
<div id="readability-page-1" class="page"><article itemscope="" itemtype="https://schema.org/NewsArticle">   <section> <p>A quiet but deeply unsettling moment just shook the foundations of international justice, proving why Europe needs digital sovereignty - and most Europeans not too interested in tech likely missed it: The Chief Prosecutor of the International Criminal Court (ICC), a court based in The Hague and central to Europe’s upholding of human rights, suddenly found that his email account was shut down. The service provider? Microsoft. The reason? Mr. Trump.
</p> <hr> <div> <h3 id="what-happened">What happened</h3>
<p>In February, <a href="https://apnews.com/article/trump-icc-sanctions-israel-order-01beee050ae84d0d9eae66d00bc8ead9" rel="noopener noreferrer" target="_blank">Trump sanctioned International Criminal Court (ICC)</a> for issuing arrest warrants for Israeli Prime Minister Benjamin Netanyahu and his former defense minister, Yoav Gallant. The court argued that the Israeli politicians have committed war crimes by restricting humanitarian aid in Gaza amid the war against Hamas, thus, harming civilians.</p>
<p>Israeli officials denied all charges, and, consequently, US President Donald Trump issued sanctions against the ICC saying that the court had committed “illegitimate and baseless actions targeting America and our close ally Israel”. Trump also called the warrants “baseless arrest warrants”.</p>
<p>Following these sanctions, the ICC has found itself faced with several issues:</p>
<ul>
<li>The chief prosecutor, Karim Khan, has lost access to his email; his bank accounts were frozen.</li>
<li>American employees of the court risk arrest when traveling to the U.S.</li>
</ul>
<p>Due to the blocking of Khan’s Microsoft email account, the court is facing severe hurdles in its day-to-day work.</p>
<h3 id="microsoft-blocked-email-account-based-on-us-sanction">Microsoft blocked email account based on U.S. sanction</h3>
<p><image-zoom-wrapper> <span><picture> <source srcset="https://tuta.com/assets/microsoft-shut-down-email-account.BgAnMnC8_Z2orNlR.webp" type="image/webp"> <img src="https://tuta.com/assets/microsoft-shut-down-email-account.BgAnMnC8_e8q5s.png" alt="Microsoft sperrte Khans E-Mail-Konto." width="1800" height="1013" loading="lazy" decoding="async"> </picture></span> <picture> <source srcset="https://tuta.com/assets/microsoft-shut-down-email-account.BgAnMnC8_Z2orNlR.webp" type="image/webp"> <img src="https://tuta.com/assets/microsoft-shut-down-email-account.BgAnMnC8_e8q5s.png" alt="Microsoft sperrte Khans E-Mail-Konto." width="1800" height="1013" loading="lazy" decoding="async"> </picture> </image-zoom-wrapper> 
<em>Microsoft shut down Khan’s email account.</em></p>
<p>The blocking of Khan’s Microsoft email account took place because of an executive order signed by Trump which the U.S.-based company – Microsoft – fulfilled. This gets even more explosive when one considers that Microsoft - even if it wanted to - had to obey this order because of the legal and political situation.</p>
<p>The Open-Source Business Alliance (OSBA) told <a href="https://www.heise.de/en/news/Criminal-Court-Microsoft-s-email-block-a-wake-up-call-for-digital-sovereignty-10387383.html" rel="noopener noreferrer" target="_blank">Heise</a> that it considers Microsoft’s actions to be “unprecedented in this context and with this impact”, and that this incident proves that <strong>Europe needs digital sovereignty</strong> by choosing European-based tech services over US-based Big Tech.</p>
<blockquote>
<p>“This must be a wake-up call for all those responsible for the secure availability of state and private IT and communication infrastructures. … We cannot rely on companies that are not under our jurisdiction.”</p>
</blockquote>
<h3 id="wake-up-call-for-digital-sovereignty">Wake-up call for digital sovereignty</h3>
<p><strong>This, indeed, must be a wake-up call.</strong></p>
<p>U.S. sanctions – unrelated to Europe and imposed by a foreign power – led to the shutdown of the digital communication of a leading public figure, the Chief Prosecutor of the International Criminal Court.</p>
<p><strong>This is a story of digital sovereignty.</strong></p>
<p>And it marks a clear turning point in Europe’s relationship with foreign technology providers. If key figures in international law can be digitally silenced by a company subject to U.S. law, what does that say about our control – or lack thereof – over the very digital foundations we rely on?</p>
<p>For years, European institutions have relied on a false promise of security and data protection by Silicon Valley tech giants. Cloud providers like Microsoft, Amazon, and Google have repeatedly assured us that they respect European law, have built data centers within EU borders, and have pledged to comply with the GDPR. While at the same time <a href="https://tuta.com/blog/outlook-business-security-issue" rel="" target="_self">Microsoft’s New Outlook uploads all data, including passwords, into the cloud</a>, <a href="https://tuta.com/blog/microsoft-office-365-email-alternative" rel="" target="_self">Microsoft’s Office 365 has been declared illegal for German schools because of data protection issues</a>, and <a href="https://tuta.com/blog/denmark-bans-google-email-and-cloud-services-due-to-privacy-concerns" rel="" target="_self">Denmark has banned Gmail from schools due to privacy concerns based on the GDPR</a>. <strong>And these are just a few examples.</strong></p>
<h3 id="jurisdiction-trumps-everything">Jurisdiction trumps everything</h3>
<p><image-zoom-wrapper> <span><picture> <source srcset="https://tuta.com/assets/boycott-us-choose-eu.VNyJdP4k_u3jTI.webp" type="image/webp"> <img src="https://tuta.com/assets/boycott-us-choose-eu.VNyJdP4k_1vjqEt.png" alt="Die Zuständigkeit ist wichtiger, als wir bisher dachten: Europäische Behörden sollten sich an europäische technische Dienste halten." width="1800" height="1013" loading="lazy" decoding="async"> </picture></span> <picture> <source srcset="https://tuta.com/assets/boycott-us-choose-eu.VNyJdP4k_u3jTI.webp" type="image/webp"> <img src="https://tuta.com/assets/boycott-us-choose-eu.VNyJdP4k_1vjqEt.png" alt="Die Zuständigkeit ist wichtiger, als wir bisher dachten: Europäische Behörden sollten sich an europäische technische Dienste halten." width="1800" height="1013" loading="lazy" decoding="async"> </picture> </image-zoom-wrapper> 
<em>Jurisdiction matters more than we used to think: European authorities should stick to European tech services.</em></p>
<p>In the light of all this, the ICC incident has just put the final nail in the coffin. It reveals a deeper truth, one that Europeans must start acting upon!</p>
<p><strong>Jurisdiction trumps geography.</strong> It doesn’t matter if your servers are in Frankfurt, Rome, or Paris – if your provider is subject to foreign law, so is your data.</p>
<p>And this must be included in every worst case scenarios of every business and every authority. The question is obvious: Is my data secure and protected – not just from external threats like malicious attackers, but also from internal threats stemming from the company hosting your data?</p>
<p>If political decisions made thousands of kilometers away can have immediate and severe consequences on European digital communications and European data, this poses a huge risk. One that you should not be taking. And with the recent Microsoft incident, it’s no longer a theoretical threat. That is exactly what just happened.</p>
<h3 id="dependency-is-a-threat">Dependency is a threat</h3>
<p>Let’s imagine this was not about email, but about the energy sector.</p>
<p>Would Europe ever hand over control of its national power grids to foreign companies bound by non-European law? Would we trust a foreign supplier’s guarantee for 99.999% uptime (which is the standard uptime SLA agreement of cloud providers) while at the same time a foreign power could force them anytime to cut Europe’s power?</p>
<p>Of course not.</p>
<p><strong>Yet this is how we’re managing our digital infrastructure in Europe.</strong></p>
<p>We are blind to the risks, and much too trusting of American tech providers. Cloud platforms, communication tools, and email providers are core services that run our governments, schools, hospitals, and courts. And in most cases, European institutions have chosen American providers - while great <a href="https://tuta.com/blog/small-business-email-address" rel="" target="_self">email alternatives for businesses</a> exist.</p>
<h3 id="europe-has-the-services--lets-start-using-them">Europe has the services – let’s start using them!</h3>
<p>What makes all this even more frustrating is that Europe doesn’t lack innovation; <a href="https://tuta.com/blog/boycott-us-choose-european-products" rel="" target="_self">Europe has great tech services that are better than their U.S. equivalents</a>. Particularly when it comes to tech services, Europe has much more on offer than some would expect – especially if you value privacy and security.</p>
<p>Across the continent, privacy-first, security-focused, and truly sovereign digital solutions are being developed. One of the best examples is Tuta, which offers secure, encrypted email and calendar tools, even with <a href="https://tuta.com/blog/post-quantum-cryptography" rel="" target="_self">quantum-safe encryption</a>. The email provider not only operates under German data protection laws with all servers based in German data centers, but it also uses the most advanced encryption technologies to protect businesses’ data.</p>
<p>So why don’t we see services like this one powering ministries, parliaments, and courts?</p>
<p>Because despite all the speeches about “strategic autonomy,” European tech is still often treated as a backup plan by the authorities – and most of them have not even started putting this plan into action. For decades, European authorities have relied on Microsoft’s products. Stemming from Microsoft’s integration into Windows, the most widely used OS since its launch in the 1980s, most businesses and authorities still use Microsoft Outlook for email, Microsoft Word, Excel, etc. While switching from Microsoft to European-based alternatives can’t be done in a day, authorities must start planning the switch.</p>
<p><strong>Now it’s time to break free from the dependency on American tech!</strong></p>
<!--xs--><astro-island uid="Z10Y8As" data-solid-render-id="s3" component-url="/assets/CallToAction.BHpNIwO3.js" component-export="CallToAction" renderer-url="/assets/client.a6UBOSBj.js" props="{&quot;type&quot;:[0,&quot;mail&quot;]}" ssr="" client="load" opts="{&quot;name&quot;:&quot;CallToAction&quot;,&quot;value&quot;:true}" await-children=""><div data-hk="s30000"><!--$--><!--/--><!--$--><p><strong>Turn ON Privacy</strong> in one click.</p><!--/--></div><!--astro:end--></astro-island>
<h3 id="the-sovereign-cloud">The sovereign cloud</h3>
<p>There’s a saying in tech that goes as follows: There is no cloud, just other people’s computers.</p>
<p>When taking this concept into action, one has to ask themselves: On whose computer would I like to store my data? With an American tech provider – to which the US (government, NSA, CIA, FBI, etc.) can potentially have full access? Even if the data stays in Europe, the control – the ability to operate, deny, or transfer access – remains elsewhere. As long as American tech providers hold the key, Europe does not own its data.</p>
<p>We need true sovereignty – by choosing European services that are built and operated under European law and that store the data solely in Europe, best end-to-end encrypted.</p>
<h3 id="looking-into-a-brighter-future">Looking into a brighter future</h3>
<p><image-zoom-wrapper> <span><picture> <source srcset="https://tuta.com/assets/team_summer_2022.B8r96R6g_ZmS1Y5.webp" type="image/webp"> <img src="https://tuta.com/assets/team_summer_2022.B8r96R6g_2fAqHL.jpg" alt="Das Tuta-Team freut sich auf eine bessere Zukunft!" width="1800" height="1014" loading="lazy" decoding="async"> </picture></span> <picture> <source srcset="https://tuta.com/assets/team_summer_2022.B8r96R6g_ZmS1Y5.webp" type="image/webp"> <img src="https://tuta.com/assets/team_summer_2022.B8r96R6g_2fAqHL.jpg" alt="Das Tuta-Team freut sich auf eine bessere Zukunft!" width="1800" height="1014" loading="lazy" decoding="async"> </picture> </image-zoom-wrapper> 
<em>The Tuta Team welcoming a brighter future!</em></p>
<p>If Europe wants to regain control of its digital infrastructure, we need a structural change; and an immense effort from all parties involved. But in the end, the effort will pay off. Not only by gaining sovereignty, but also by supporting and building a European tech industry – one that can easily compete with American and Chinese tech companies.</p>
<p>To achieve this, we don’t even need new laws, all we need is a commitment by the public sector. <strong>When Trump says “America first”, Europe must say “Europe first”</strong> – and in tech the gain is double: 1. A big share of what the public sector spends on European tech, they get back in the form of company taxes. 2. The public sector could help boost an already vibrating and innovative European tech industry to gain a competitive edge, not just in Europe but also abroad.</p>
<p><strong>Make “European” a requirement for public procurement of tech products</strong>: EU institutions, governments and local authorities should make being “European” a requirement for procuring tech products. This way they can make sure that the services they purchase follow European data protection laws and are not under the influence of foreign governments.</p>
<p><strong>Prevent vendor lock-in</strong>: Any platform used in the public sector should be interoperable and replaceable. No exceptions. Contracts should be written with exit strategies in mind so that a dependency like the one we are currently seeing with Microsoft never happens again.</p>
<p>Going forward, European and local authorities can make a real difference. All they have to do is get active!
The Microsoft email issue of the ICC must not be dismissed and forgotten. It’s a wake-up call for what happens when you build your digital house on someone else’s foundation.</p>
<p>Let’s not wait for the next company to switch off an essential tech service in Europe.</p>
<p>Let’s build systems that adhere to European laws and regulations, protect European citizens and their data, and strengthen European independence.</p>
<p><strong>Let’s stop borrowing digital power – and start generating our own. Together we can make the web a better place!</strong></p>
<div> <article> <h2>Turn ON Privacy</h2> <p>  <span>  Secure </span> <span>  Fast </span> <span>  Ad-free </span>  </p> <a href="https://app.tuta.com/?r=/signup#subscription" rel="noopener noreferrer" target="_blank">  </a> </article> <picture> <source srcset="https://tuta.com/assets/forever-free.DedJvQTK_1s1dEg.webp" type="image/webp"> <img src="https://tuta.com/assets/forever-free.DedJvQTK_XIdQ6.png" alt="Illustration of a phone with Tuta logo on its screen, next to the phone is an enlarged shield with a check mark in it symbolizing the high level of security due to Tuta's encryption." width="1000" height="1051" loading="lazy" decoding="async"> </picture> </div> </div> </section>  </article></div>]]></description>
        </item>
    </channel>
</rss>