<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 05 Jul 2023 06:00:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Simple Unix Chat (161 pts)]]></title>
            <link>https://the-dam.org/docs/explanations/suc.html</link>
            <guid>36594916</guid>
            <pubDate>Wed, 05 Jul 2023 02:34:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://the-dam.org/docs/explanations/suc.html">https://the-dam.org/docs/explanations/suc.html</a>, See on <a href="https://news.ycombinator.com/item?id=36594916">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">

<p>
The title oversells the content a bit:
</p>
<ul>
<li>first, Slack (or Mattermost, or even the Internet Relay Chat (IRC)) offer
slightly more features than the <i>Simple Unix Chat</i> system (<code>suc</code>), the topic
of this piece;</li>
<li>then, <code>suc</code>’s actual line count exceeds five.</li>
</ul>

<p>
Nevertheless, <code>suc</code>’s core indeed consists of five lines of bash;
and <code>suc</code> provides Slack, Mattermost, <i>etc.</i>’s core features:
</p>
<ul>
<li>Real-time, rich-text chat,</li>
<li>File sharing,</li>
<li>Fine-grained access control,</li>
<li>Straightforward automation and integration with other tools,</li>
<li>Data encryption in transit</li>
<li>and optionally at rest,</li>
<li>state-of-the-art user authentication.</li>
</ul>


<p>
This paper shows how <code>suc</code> implements those features.
<code>suc</code> stays small by leveraging the consistent and composable primitives offered by modern UNIX implementations
<sup><a id="fnr.1" href="#fn.1" role="doc-backlink">1</a></sup>.
</p>

<div id="outline-container-orgefe782e">
<h2 id="orgefe782e">Line count matters</h2>
<div id="text-orgefe782e">
<blockquote>
<p>
One of my most productive days was throwing away 1000 lines of code.
– Ken Thompson, <a href="https://skeptics.stackexchange.com/questions/43800/did-the-creator-of-unix-say-one-of-my-most-productive-days-was-throwing-away-10">apparently</a>
</p>
</blockquote>
<blockquote>
<p>
Measuring programming progress by lines of code is like measuring aircraft
building progress by weight.
– Bill Gates, (probably apocryphal)
</p>
</blockquote>
<blockquote>
<p>
Some of the managers decided that it would be a good idea to track the progress
of each individual engineer in terms of the amount of code that they wrote from
week to week.
[…]
When he got to the lines of code part, [Bill Atkinson] […] wrote in the number: -2000.
– <a href="https://www.folklore.org/StoryView.py?story=Negative_2000_Lines_Of_Code.txt">https://www.folklore.org/StoryView.py?story=Negative_2000_Lines_Of_Code.txt</a>
</p>
</blockquote>
<blockquote>
<p>
Their fundamental design flaws are completely hidden by their superficial design
flaws.
– Douglas Adams
</p>
</blockquote>
<blockquote>
<p>
There are two ways of constructing a software design: One way is to make it so
simple that there are obviously no deficiencies, and the other way is to make it
so complicated that there are no obvious deficiencies.
– Tony Hoare
</p>
</blockquote>
<p>
Despite the wide consensus among competent programmers that <a href="https://wiki.c2.com/?SoftwareAsLiability">code is a liability</a>,
almost every widely-distributed piece of software is a complexity behemoth.
</p>

<p>
Case in point, let’s examine Mattermost’s line count:
</p>
<div>
<pre><span>cd</span> /tmp
<span>git</span> clone --depth=<span>1</span> https://github.com/mattermost/mattermost-server
<span>cd</span> mattermost-server
guix shell cloc -- cloc --quiet --timeout <span>0</span> .
</pre>
</div>

<pre id="org6c7ec21">github.com/AlDanial/cloc v 1.96  T=14.34 s (606.7 files/s, 139790.0 lines/s)
-------------------------------------------------------------------------------
Language                     files          blank        comment           code
-------------------------------------------------------------------------------
Go                            1805          96705          26782         501249
JSON                           177              5              0         492604
TypeScript                    4125          74236          24557         480491
JavaScript                     811          21494          20745          68653
SCSS                           557           9164            359          51464
HTML                            54           6108           1167          37814
JSX                             92           3473           1054          29707
SQL                            807           3553           2253          18266
Text                            11           3824              0          10638
YAML                            45            126             96           7972
SVG                             68              6             12           2586
Markdown                        73            906             88           2168
make                             8            234             68            974
GraphQL                          4             65              2            596
XML                             29             10              1            572
Bourne Shell                    18            128             17            492
CSS                              5             70              0            385
Dockerfile                       4             14              8             46
CSV                              2              0              0             25
diff                             2              1             13              9
INI                              1              2              0              7
-------------------------------------------------------------------------------
SUM:                          8698         220124          77222        1706718
-------------------------------------------------------------------------------
</pre>

<p>
<b><b>Half a million lines</b></b> of Go, and again <b><b>half a million</b></b> lines of
TypeScript. Just for the server !
</p>

<p>
Let’s compare with <code>suc</code>:
</p>
<div>
<pre><span>cd</span> /tmp
<span>git</span> clone --depth=<span>1</span>  https://gitlab.com/edouardklein/suc
<span>cd</span> suc
guix shell cloc -- cloc --quiet --timeout <span>0</span> .
</pre>
</div>

<pre id="orga4ac3ca">github.com/AlDanial/cloc v 1.96  T=0.01 s (475.8 files/s, 8207.6 lines/s)
--------------------------------------------------------------------------------
Language                      files          blank        comment           code
--------------------------------------------------------------------------------
Bourne Again Shell                1              2              2             19
C                                 1              3              3             17
make                              1              3              0             14
Bourne Shell                      1              0              1              5
--------------------------------------------------------------------------------
SUM:                              4              8              6             55
--------------------------------------------------------------------------------
</pre>
<p>
<code>suc</code> can implement Mattermost’s core features <b><b>with 0.005% of the code</b></b>. This is madness !
</p>
</div>
</div>
<div id="outline-container-orga8279f6">
<h2 id="orga8279f6"><code>suc</code>’s core loop</h2>
<div id="text-orga8279f6">
<p>
Behold the five lines of bash that do as much as half a million lines of Go:
</p>
<div>
<pre><span>while</span> /usr/bin/true
<span>do</span>
    <span>read</span> -r line || <span>exit</span> <span>0</span>  <span># </span><span>EOF</span>
    /usr/bin/echo <span>"</span><span>$(/usr/bin/date --iso-8601=seconds)</span><span>"</span><span>\</span>
        <span>"</span><span>$(printf "%-9s" "$(/usr/bin/id --user --name --real)</span><span>")"</span> <span>\</span>
        <span>"</span><span>$</span><span>line</span><span>"</span> &gt;&gt; /var/lib/suc/<span>"</span><span>$</span><span>1</span><span>"</span>
<span>done</span>
</pre>
</div>
<p>
This infinite loop:
</p>
<ul>
<li>reads a line from standard input,</li>
<li>prefixes it with:
<ul>
<li>the date,</li>
<li>the real user name,</li>
</ul></li>
<li>and appends it to a file in <code>/var/lib/suc/</code></li>
</ul>


<p>
Surely, you think, this cannot do. What about authentication, access control, encryption, rich text, <i>etc.</i> ?
</p>

<p>
<code>suc</code> does all that by leveraging SSH, UNIX’s access control API, and UNIX’s text-based modularity.
</p>
</div>
</div>
<div id="outline-container-org14b6181">
<h2 id="org14b6181">Authentication</h2>
<div id="text-org14b6181">
<p>
The <code>suc</code> process can only be launched by an authenticated user
<sup><a id="fnr.2" href="#fn.2" role="doc-backlink">2</a></sup>.
Therefore, <code>suc</code> contains no authentication code at all.
All the authentication stuff happens before <code>suc</code> even starts.
</p>

<p>
As with almost all UNIX servers nowadays,
remote authentication is handled by <code>ssh</code>.
Before granting them the ability to start <code>suc</code>, <code>ssh</code> requires users to prove their identity.
</p>

<p>
This proof can take the form
</p>
<ul>
<li>of a shared secret (<i>i.e.</i> a password),</li>
<li>of a cryptographic challenge (as is the case on <a href="https://the-dam.org/">the dam</a>),</li>
<li>of the use of a One-Time-Passord (OTP) generating device,</li>
<li>or of any combination of the above (also known as Multi-Factor Authentication, MFA).</li>
</ul>


<p>
<code>ssh</code> also authenticates the server to the client,
thus preventing <i>Man-in-the-Middle</i> (MitM) attacks.
</p>

<p>
Last but not least, <code>ssh</code> encrypts all data between the clients and the server.
</p>

<p>
A successful installation of <code>suc</code> therefore depends on a correct configuration
of the UNIX host and its <code>ssh</code> server.
To use <code>suc</code>, a user needs to exist on the system;
and the <code>ssh</code> server needs to be configured to let her remotely log in.
</p>

<p>
Most UNIX distribution provide the <code>useradd</code>, <code>passwd</code>, <i>etc.</i> commands for user management
(creation, deletion, assignation to one or more groups, <i>etc.</i>).
The <code>ssh</code> server reads its configuration from a text file in <code>/etc/</code>
(typically <code>/etc/ssh/sshd_config</code>), and from public key files
(typically in <code>/home/&lt;user&gt;/.ssh/authorized_keys</code>).
</p>

<p>
<a href="https://the-dam.org/">The dam</a> server uses GNU Guix.
GNU Guix differs from almost all other UNIX distributions,
because it uses declarative configuration.
This means that <code>root</code> just has to say what she wishes the configuration to be.
The system then complies and reconfigures itself to match <code>root</code>’s declaration.
</p>

<p>
For example, granting <code>ssh</code> access to <code>alice</code> on a GNU Guix system
<sup><a id="fnr.3" href="#fn.3" role="doc-backlink">3</a></sup>
requires only the following line in the system’s configuration file:
</p>
<div>
<pre> (ssh-user <span>"alice"</span> <span>#:groups</span> '(<span>"c3n"</span> <span>"frenchies"</span>)
                   <span>#:keys</span> '((plain-file <span>"alice.pub"</span> <span>"SOMESSHKEY"</span>)))
</pre>
</div>
<p>
User <code>alice</code> exists on the system only as long as the line exists in the configuration file.
When the line disappears, the reconfiguration process removes user <code>alice</code>, and she can no longer log in.
</p>

<p>
Some big advantages of declarative configuration systems include:
</p>
<ul>
<li>removing the need for clean up actions when removing functionality:
once it is no longer part of the declaration,
it will be removed from the system automatically.</li>
<li>the ability to clone a specific configuration
by just replicating the declaration;
useful for back-ups, failovers, <i>etc.</i>.</li>
</ul>


<p>
Among the disadvantages,
one counts an increased difficulty for quick and dirty setups
(usually for a quick test to try out a piece of software).
New tools (such as e.g. <code>guix shell</code>) allows one to sidestep this difficulty.
</p>

<p>
In such a declarative system,
<code>suc</code>’s overhead per user is limited to a single line in the global configuration file.
One cannot need less,
and current chat systems need more.
</p>
</div>
</div>
<div id="outline-container-orgc7dc063">
<h2 id="orgc7dc063">Access control</h2>
<div id="text-orgc7dc063">
<p>
As with authentication, <code>suc</code> contains no access control code whatsoever.
This combination of caring about neither authentication nor access control is called <i>security agnosticism</i>.
<i>Security anosticism</i> allows <code>suc</code> to be lean,
and therefore more probably correct (and so, paradoxically, more secure) than its heavier counterparts.
</p>

<p>
On UNIX, software can afford to be <i>security agnostic</i>
because the system provides a clean and powerful API for access control:
the kernel knows about
</p>
<ul>
<li>users and groups,</li>
<li>processes and files.</li>
</ul>


<p>
Let’s dive in.
</p>

<p>
UNIX veterans will have noticed that <code>suc</code> prefixes the user’s messages with her <i>real</i> name.
Indeed, files have an owner (a user),
whereas processes have two owners (two users). The <i>real</i> one and the <i>effective</i> one.
</p>

<p>
Most of the time, <i>real</i> and <i>effective</i> owners are the same.
<code>suc</code>’s ownership differs:  it <i>effectively</i> belongs to a special user also named <code>suc</code>;
it <i>really</i> belongs to whoever (<i>e.g.</i> user <code>alice</code>) launched the <code>suc</code> command
<sup><a id="fnr.4" href="#fn.4" role="doc-backlink">4</a></sup>.
</p>

<p>
The kernel examines the <i>effective</i> ownership of a process
to determine said process’ ability to read or write to files.
</p>

<p>
With that in mind, let’s examine the content of <code>/var/lib/suc</code> on <a href="https://the-dam.org/">the dam</a>:
</p>
<div>
<pre>ssh -i ~/.ssh/id_rsa edk@the-dam.org <span>ls</span> -l /var/lib/suc
</pre>
</div>

<pre>total 92
-rw-r----- 1 suc c3n            44368 Apr 13 19:18 banane
-rw-r----- 1 suc forbiddenlands  6234 Apr 13 21:04 forbiddenlands
-rw-r----- 1 suc frenchies         62 Apr 21 22:23 frenchies
-rw-r----- 1 suc guixdevs           0 Apr 22 15:39 guix
-rw-r----- 1 suc iwp9            4181 Apr 21 21:46 iwp9
-rw-r----- 1 suc users          18241 Jun 30 07:14 the-dam
-rw-r----- 1 suc wb3c             188 May 10 11:56 wb3c
</pre>


<p>
The files in <code>/var/lib/suc</code> belong to <code>suc</code>;
only <code>suc</code> can read and write those files
<sup><a id="fnr.5" href="#fn.5" role="doc-backlink">5</a></sup>.
</p>

<p>
Any other user, such as <code>alice</code>, may read some of the files (e.g. <code>banane</code>),
provided she belongs to the appropriate <i>group</i> (e.g. <code>c3n</code>).
</p>

<p>
With this configuration,
<code>suc</code> does not need to care about access control at all.
For example <code>suc</code> need not match a user against the list of authorized readers or writers of a <i>channel</i>.
</p>

<p>
Instead, <code>usuc</code><sup><a id="fnr.6" href="#fn.6" role="doc-backlink">6</a></sup>
will just happily always <i>try</i> to read or write the file.
The kernel will do the matching and prevent any unauthorized access.
</p>

<p>
On <a href="https://the-dam.org/">the dam</a>, everyone can start <code>suc</code>, whose <i>effective</i> owner will be the user
<code>suc</code>, who has the right to write into any channel. By design, any user on <a href="https://the-dam.org/">the dam</a>
can request membership into a group by blindly writing a request to the
group’s channel.
</p>

<p>
Less loosely-managed communities may wish to restrict channel write access to members only.
<code>root</code> achieves this by maintaining multiple copies of the <code>suc</code> binary.
</p>

<p>
Let’s assume that
</p>
<ul>
<li><code>alice</code> and <code>bob</code> belong to the <code>blue</code> group,</li>
<li>while <code>eve</code> and <code>mallory</code> belong to the <code>red</code> group.</li>
</ul>


<p>
<code>root</code> creates <code>nobody</code>-like<sup><a id="fnr.7" href="#fn.7" role="doc-backlink">7</a></sup> users <code>red</code> and <code>blue</code>. She then creates two copies of <code>suc</code>, one for
each group:
</p>
<div>
<pre><span>ls</span> -l /usr/bin/suc*
total <span>32</span>
-rwsr-xr-- <span>1</span> red     red      <span>15624</span> Jun  <span>4</span> 10:51 suc_red
-rwsr-xr-- <span>1</span> blue    blue     <span>15624</span> Jun  <span>4</span> 10:56 suc_blue
</pre>
</div>
<p>
And she also creates one channel for each team:
</p>
<div>
<pre><span>ls</span> -l /var/lib/suc/
total <span>16</span>
-rw-r----- <span>1</span> blue     blue     <span>11027</span> Jun  <span>4</span> 11:30 blue
-rw-r----- <span>1</span> red      red      <span>17</span>    Jun  <span>4</span> 10:53 red
</pre>
</div>
<p>
One can see that:
</p>
<ul>
<li><code>alice</code> and <code>bob</code> belong to group <code>blue</code>.
<ul>
<li>They can read the <code>blue</code> channel. Indeed the file <code>/var/lib/suc/blue</code>
belongs to group <code>blue</code> and has mode <code>-rw-r-----</code> : the second <code>r</code> means
that members of the owning group (here, <code>blue</code>), can read the file (but not
write to it).</li>
<li>They cannot directly write to the file.
Only user <code>blue</code> can.</li>
<li>They can however launch the <code>/usr/bin/suc_blue</code> program,
because group <code>blue</code> owns it,
and it has mode <code>-rwsr-xr--</code> .
The <code>x</code> means that members of the owning group (here, <code>blue</code>) can start the program.</li>
<li>This program will run with user <code>blue</code> as the <i>effective</i> owner:
User <code>blue</code> owns the file
and <code>root</code> has set its setuid bit
(the <code>s</code> in the mode line says so).</li>
<li>Therefore, <code>alice</code> and <code>bob</code>, being members of the <code>blue</code> group, can launch the <code>/usr/bin/suc_blue</code> program,
which being <i>effectively</i> owned by user <code>blue</code>
(despite being launched by <code>alice</code> or <code>bob</code> who will be the <i>real</i>, but not <i>effective</i> owner)
can write to the <code>/var/lib/suc/blue</code> file.</li>
</ul></li>
<li><code>eve</code> and <code>mallory</code> belong to group <code>red</code> (but not group <code>blue</code>).
<ul>
<li>They cannot read the <code>blue</code> channel.
Indeed, people other than user <code>blue</code> or members of group <code>blue</code> have no rights on the <code>/var/lib/suc/blue</code> file
(the end of its mode line is <code>---</code>).</li>
<li>They cannot write to the <code>blue</code> channel directly,
only user <code>blue</code> can.</li>
<li>They cannot start the <code>/usr/bin/suc_blue</code> program,
because they do not belong to group <code>blue</code>.
The only thing they can do to this file is read it (its mode line ends in <code>r--</code>).</li>
<li>Therefore they can neither read nor write the <code>blue</code> channel.</li>
</ul></li>
</ul>


<p>
To relieve <code>root</code> from the cumbersome and error-prone process of setting this all up,
<code>suc</code> provides an 80-something-lines long helper script called <a href="https://gitlab.com/edouardklein/suc/-/blob/master/suc_channel.sh"><code>suc_channel.sh</code></a>.
</p>

<p>
GNU Guix users can create a <code>suc</code> channel by
adding a single line to the system’s configuration file:
</p>
<pre>(suc-private-channel "red" "red")
</pre>

<p>
This line takes care of creating the necessary
</p>
<ul>
<li><code>suc_red</code> setuid binary,</li>
<li><code>red</code> user</li>
<li><code>red</code> group</li>
<li><code>red</code> channel file.</li>
</ul>


<p>
Here, GNU Guix’s declarative configuration paradigm shines again. The
<code>suc_channel.sh</code> script may fail halfway, leaving the system in an undetermined
state, whereas GNU Guix provides <i>transactional</i> updates: either the transition
happens fully or it does not at all. The system always stays in a known clean
state. One can even roll-back to a previous working state (see <a href="https://guix.gnu.org/en/blog/2018/multi-dimensional-transactions-and-rollbacks-oh-my/">Multi-dimensional
transactions and rollbacks, oh my!</a>).
</p>

<p>
GNU Guix also automatically computes which groups, users, and setuid binaries
should exist on the system. When <code>root</code> removes a private channel (e.g. <code>red</code>),
she must assess whether the associated group (also named <code>red</code>), user (also
<code>red</code>), and setuid binary (<code>suc_red</code>) should stay or go. That entails looking at
the other channels to see if any of them is still owned by user <code>red</code> or group
<code>red</code>. Again, a cumbersome and error prone task whereas on GNU Guix, <code>root</code> just
removes the channel’s line from the system declaration. The <code>red</code> group, <code>red</code>
user, and <code>suc_red</code> binary will stay if and only if another part of the system
needs them.
</p>

<p>
As an illustration, here is a full system declaration for the above example. One
can hardly be simpler than that.
</p>
<div>
<pre>(<span>begin</span> (use-modules
        (gnu packages base)
        (guix gexp)
        (beaver system)
        (beaver packages plan9)
        (beaver functional-services))
       (-&gt; (minimal-ovh)
           (ssh-user <span>"alice"</span>   <span>#:groups</span> '(<span>"suc"</span> <span>"blue"</span>) <span>#:keys</span> '())
           (ssh-user <span>"bob"</span>     <span>#:groups</span> '(<span>"suc"</span> <span>"blue"</span>) <span>#:keys</span> '())
           (ssh-user <span>"eve"</span>     <span>#:groups</span> '(<span>"suc"</span> <span>"red"</span>)  <span>#:keys</span> '())
           (ssh-user <span>"mallory"</span> <span>#:groups</span> '(<span>"suc"</span> <span>"red"</span>)  <span>#:keys</span> '())
           (suc-private-channel <span>"red"</span> <span>"red"</span>)
           (suc-private-channel <span>"blue"</span> <span>"blue"</span>)
           (suc-public-channel <span>"purple"</span>)))
</pre>
</div>
</div>
</div>
<div id="outline-container-org76ce31c">
<h2 id="org76ce31c">Fancy text</h2>
<div id="text-org76ce31c">
<p>
We have seen how <code>suc</code> is <i>security-agnostic</i>, relying on:
</p>
<ul>
<li><code>ssh</code> for authentication,</li>
<li>UNIX’s file and process ownership and permission model for access control.</li>
</ul>


<p>
Let’s now dive into the featureful side of things by first looking at some bells
and whistles: rich text.
</p>

<p>
Most chat applications nowadays piggyback on an HTML engine to render the chat’s
text. For example <a href="https://github.com/mattermost/desktop">mattermost’s client</a> uses <a href="https://www.electronjs.org/">Electron</a>. There go another few tens of
thousand of lines of code.
</p>

<p>
On the one hand, this adds tremendous complexity and increases the attack
surface of the application. On the other hand it lets the chat display elements
in a complex layout, or embed interactive widgets within the messages (such as
emoji reactions), etc.
</p>

<p>
<code>suc</code> uses one file per channel. This text file is meant to be displayed to the
user with a command-line tool such as <code>tail</code> or <code>cat</code>.
</p>

<p>
Before everything got shoehorned into an HTML rendering engine, people managed
to display rich text, boxes, and even primitive graphics on their terminals.
These capabilities more-or-less coalesced into something called ANSI escape
codes<sup><a id="fnr.8" href="#fn.8" role="doc-backlink">8</a></sup>. Almost all terminal emulators support
those. Together with proper UTF-8 support, they allow for the colorful,
emoji-filled experience of your average corporate slack channel, with ~5% of the
memory footprint.
</p>

<p>
If you paid attention to the 5 lines of bash that <code>suc</code> consists of, you have
noticed that while <code>suc</code> writes into the channel file, it does not read from it.
</p>

<p>
This job befalls to <code>usuc</code>. Why two separate binaries ? Because <code>suc</code> is a
privileged binary, which runs under the powerful effective ownership of whoever
can write to a channel. One must be careful to keep the logic and external
dependencies of <code>suc</code> to a bare minimum to minimize the attack surface, and
avoid any complex logic where bugs like to hide.
</p>

<p>
<code>usuc</code>, conversely, runs with both effective and real owners set to the
calling user. It can go crazy with the features, as whatever happens can not
impact the channel file, except through <code>suc</code>, whose logic is so simple
there should not be any bugs in it.
</p>

<p>
Here is as of <span><span>&lt;2023-06-29 Thu&gt; </span></span> the code for usuc:
</p>
<div>
<pre><span>#</span><span>!/usr/bin/</span><span>bash</span>
<span>set</span> -euo pipefail

<span># </span><span>Autowrap self in rlwrap</span>
<span>if</span> [ -z <span>"</span><span>$</span><span>{RLWRAP:-}</span><span>"</span> ]
<span>then</span>
    <span>RLWRAP</span>=<span>1</span> rlwrap <span>"</span><span>$</span><span>0</span><span>"</span> <span>"</span><span>$</span><span>@</span><span>"</span>
    <span>exit</span> <span>0</span>
<span>fi</span>

<span>chan_owner</span>=$(<span>ls</span> -l /var/lib/suc/<span>"</span><span>$</span><span>1</span><span>"</span> | cut -d<span>' '</span> -f <span>3</span>)
<span>if</span> [ <span>"</span><span>$</span><span>chan_owner</span><span>"</span> != suc ]
<span>then</span>
    <span>SUC</span>=suc_<span>"</span><span>$</span><span>chan_owner</span><span>"</span>
<span>else</span>
    <span>SUC</span>=suc
<span>fi</span>
<span># </span><span>Tail the channel</span>
tail -f -n <span>20</span> /var/lib/suc/<span>"</span><span>$</span><span>1</span><span>"</span>&amp;
<span>while</span> true
<span>do</span>
    <span>read</span> -r line || <span>exit</span> <span>0</span>
    <span>if</span> [ <span>"</span><span>$</span><span>{line::1}</span><span>"</span> == <span>":"</span> ]
    <span>then</span>
        <span>echo</span> <span>'*runs* `'</span> <span>"</span><span>$</span><span>{line:1}</span><span>"</span> <span>'`'</span> | pygmentize -l md -f <span>256</span> | <span>"</span><span>$</span><span>SUC</span><span>"</span> <span>"</span><span>$</span><span>1</span><span>"</span>
        bash -c <span>"</span><span>$</span><span>{line:1}</span><span>"</span> | <span>"</span><span>$</span><span>SUC</span><span>"</span> <span>"</span><span>$</span><span>1</span><span>"</span>
    <span>else</span>
        <span>echo</span> <span>"</span><span>$</span><span>line</span><span>"</span> | pygmentize -l md -f <span>256</span> | <span>"</span><span>$</span><span>SUC</span><span>"</span> <span>"</span><span>$</span><span>1</span><span>"</span>
    <span>fi</span>
<span>done</span>
</pre>
</div>
<p>
<code>usuc</code>:
</p>
<ul>
<li>makes sure to prefix its own call with <code>rlwrap</code>, which provides history and line
editing capabilities,</li>
<li>selects the correct setuid <code>suc</code> binary to run depending on who owns the channel file,</li>
<li>calls <code>tail -f</code>, displaying the last 20 lines of the channel and then
anything that get subsequently written to it,</li>
<li>check whether the line typed by the user starts with “:” (see the next section),</li>
<li>pipe anything the user typed through <code>pygmentize</code>.</li>
</ul>


<p>
Pygmentize is a nifty Python module for syntax coloring. Here it runs expecting
markdown on its standard input, and outputting ANSI color coded text on its
standard output. That way, a user can use markup syntax like <code>**bold**</code>, and get
<b>bold</b> output. <code>suc</code> gets markdown support in a single line of code.
</p>
</div>
</div>
<div id="outline-container-orgabf779c">
<h2 id="orgabf779c">Chat commands</h2>
<div id="text-orgabf779c">
<p>
Other tools can, like <code>pygmentize</code>, output ANSI-styled text. One of those is e.g.
<a href="https://github.com/charmbracelet/gum"><code>gum</code></a>.
</p>

<p>
To invoke <code>gum</code> directly from the chat interface, one just has to start a
message with <code>:</code>. <code>usuc</code> will catch that and will not pipe the text to <code>suc</code>
like it would for a normal message. It will instead run the command, and pipe
its <i>output</i> to <code>suc</code>.
</p>

<p>
One can therefore type:
</p>
<pre>: gum style --border=rounded --bold --foreground=#F00 "Hello World !"
</pre>

<p>
as a <code>suc</code> message and see something that looks like the following appear in the channel:
</p>
<pre>╭─────────────╮
│<span>Hello World !</span>│
╰─────────────╯
</pre>

<p>
Any command that exists in the namespace of the user who called <code>usuc</code> can run
that way. Its output will appear in the chat.
</p>

<p>
We use that on <a href="https://the-dam.org/">the dam</a> to roll dice when we play table-top role playing games:
</p>
<pre>: roll 2d6
2023-04-13T21:04:57+00:00 gm        *runs* ` roll 2d6 `
2023-04-13T21:04:58+00:00 gm        [6, 2]
</pre>


<p>
Again, it all happens in the namespace of the user. Any user can customize
her environment to keep useful chat macros on hand, without any impact on the
other users.
</p>
</div>
</div>
<div id="outline-container-orgd2b464b">
<h2 id="orgd2b464b">Piping text to <code>suc</code></h2>
<div id="text-orgd2b464b">
<p>
Instead of using <code>usuc</code>’s command-calling facility, one can pipe right into
<code>suc</code> the output of any command, from one’s shell.
</p>

<p>
For example if you want to pretty-print a piece of source code to a relevant
channel, you can invoke <a href="https://github.com/sharkdp/bat"><code>bat</code></a>:
</p>
<pre>bat --force-colorization --paging=never --style=full toto.c | suc greybeards
</pre>

<p>
and you will get a syntactically-colored listing of your code in the channel.
</p>

<p>
Complex chat system like Mattermost, Slack, etc. offer many
<a href="https://mattermost.com/integrations-overview/">integrations</a>, that is, ways to interact with other software.
</p>

<p>
<code>suc</code> is text-based ; integrating it with other tools feels natural in a UNIX
environment. For example consider the following bash one-liner:
</p>
<div>
<pre><span>make</span> test &gt; testlog || (suc devops &lt; testlog ; <span>exit</span> <span>1</span>)
</pre>
</div>
<p>
This code will run the tests of a software project, and send the logs to the
<code>devops</code> channel on failure.
</p>

<p>
With the necessary boilerplate, this oneliner fits into the <a href="https://www.atlassian.com/git/tutorials/git-hooks">git hook</a> <code>update</code> of
a git repo:
</p>
<div>
<pre><span>#</span><span>!/usr/bin/</span><span>bash</span>
<span>set</span> -euxo pipefail
<span>newrev</span>=<span>"</span><span>$</span><span>3</span><span>"</span>

<span>GIT_DIR</span>=$(realpath <span>"</span><span>$</span><span>GIT_DIR</span><span>"</span>)
<span>cd</span> <span>"</span><span>$(mktemp -d)</span><span>"</span>
<span>git</span> clone <span>"</span><span>$</span><span>GIT_DIR</span><span>"</span> .
<span>git</span> checkout <span>"</span><span>$</span><span>newrev</span><span>"</span>

<span>make</span> test &gt; test_log || (suc devops &lt; test_log ;  <span>exit</span> <span>1</span>)
<span>exit</span> <span>0</span>
</pre>
</div>
<p>
And voilà ! You get a <code>git/suc</code> integration in 11 lines of bash. Any push to
the repo will trigger the test, reject the update on failure, and ring the
DevOps team so they can solve the problem.
</p>
</div>
</div>
<div id="outline-container-org26050c9">
<h2 id="org26050c9">Reading from a <code>suc</code> channel</h2>
<div id="text-org26050c9">
<p>
<code>suc</code> users continually update a text file (the channel). By calling <code>tail -f</code>
on that text file, you can process the new lines as they arrive.
</p>

<p>
For example, to get notified when a new message gets posted in a channel, just run:
</p>
<div>
<pre>tail -n0 -f /var/lib/suc/some-chan | (<span>while</span> true;
                                      <span>do </span><span>read</span> -r line;
                                         notify-send <span>"</span><span>$</span><span>line</span><span>"</span>;
                                      <span>done</span>)
</pre>
</div>

<p>
Too many notifications ? Reduce the noise by grepping for keywords:
</p>
<div>
<pre>tail -n0 -f /var/lib/suc/some-chan | <span>\</span>
    stdbuf -i0 -o0 <span>grep</span> -E <span>"(myname|build failure|fire)"</span> | <span>\</span>
    (<span>while</span> true; <span>do </span><span>read</span> -r line; notify-send <span>"</span><span>$</span><span>line</span><span>"</span>; <span>done</span>)
</pre>
</div>

<p>
Don’t want to open as many windows as channels you follow ? Coalesce them all in
a single feed:
</p>
<pre>tail -f /var/lib/suc/*
</pre>

<p>
Or use the more powerful <a href="https://lnav.org/">lnav</a> (a log file viewer), which will
</p>
<ul>
<li>remember where you left off,</li>
<li>set bookmarks,</li>
<li>assign a color to each channel,</li>
<li>parse the date, username, or any custom field that may appear in the text,</li>
<li>let you filter the messages,</li>
<li>run SQL queries on the messages.</li>
</ul>


<p>
Try to do that with Slack…
</p>
</div>
</div>
<div id="outline-container-orgfc27392">
<h2 id="orgfc27392">Bots</h2>
<div id="text-orgfc27392">
<p>
If you can write and read to a <code>suc</code> channel, you can do both at once. Chat
systems often host bots and semi-automated “assistants”. These provide a text-based
interface to e.g. tickets, continuous integration, corporate directory, server
logs, etc. Have a look below at the code of a bot that convert into meters any
length given in feet:
</p>
<div>
<pre><span>#</span><span>!/usr/bin/</span><span>bash</span>
<span>feet_to_meters</span> (){
    <span>feetexpr</span>=<span>"</span><span>$</span><span>1</span><span>"</span>
    <span>echo</span> -e <span>"</span><span>$</span><span>feetexpr</span><span> \n m"</span> | units | <span>grep</span> -Eo <span>"\* [0-9.]*"</span> | tr -d <span>'*'</span>
}

tail -n0 -f /var/lib/suc/<span>"</span><span>$</span><span>1</span><span>"</span> | <span>\</span>
    stdbuf -i0 -o0 <span>grep</span> -v <span>"metric_bot"</span>  | <span>\</span>
    stdbuf -i0 -o0 <span>grep</span> -Eo <span>"[0-9]+[[:blank:]]*(feet|ft)"</span> | <span>\</span>
    (<span>while</span> true;
     <span>do </span><span>read</span> -r line;
        <span>echo</span> <span>"[metric_bot] </span><span>$</span><span>line</span><span> is </span><span>$(feet_to_meters "</span><span>$</span><span>line</span><span>")</span><span> meters."</span> | suc <span>"</span><span>$</span><span>1</span><span>"</span>
     <span>done</span>)
</pre>
</div>
<pre id="org5024b6d">2023-06-30T11:20:47+02:00 edouard   The plane flew at 33000 ft.
2023-06-30T11:20:47+02:00 bots      [metric_bot] 33000 ft is  10058.4 meters.
</pre>
</div>
</div>
<div id="outline-container-org2edb71a">
<h2 id="org2edb71a">Conclusion</h2>
<div id="text-org2edb71a">
<p>
<code>suc</code> piggybacks on SSH for authentication and on UNIX for access control and
composability. It provides almost all the features offered by Mattermost,
Slack, <i>etc.</i> with such a ridiculously small fraction of the code that one
wonders why such complex systems even exist.
</p>

<p>
Using text files as the base for <code>suc</code> channels lets user leverage UNIX tools
for reading (<code>tail</code>, <code>bat</code>, <code>lnav</code>, <code>less</code>, <code>grep</code>, etc.), writing (<code>gum</code>,
<code>bat</code>, <code>pygmentize</code>, etc.), or semi-automated extension with bots, hooks, and
scripts.
</p>

<p>
Tools can be written in any language, as long as they read and write text.
</p>
</div>
</div>
<div id="outline-container-org26136f6">
<h2 id="org26136f6">Advertisement</h2>
<div id="text-org26136f6">
<p>
If you want to play with <code>suc</code> but don’t want to bother with installing it, or
if you don’t have any friends to share a <code>suc</code> instance with, come and join us
at <a href="https://the-dam.org/">the dam</a> ! For a measly 10€/year, you can enjoy sharing <code>suc</code> on a GNU Guix
server with people from all over the world.
</p>

<p>
If you would like your own instance of <code>suc</code>, don’t hesitate and rent a VPS from
<a href="https://guix-hosting.com/">Guix hosting</a> ! For 100€/year, you get a GNU Guix VPS. Adding <code>suc</code> is just one
line of configuration away. There are no usage-based restrictions, your data
stays yours, and you can use your VPS to provide other services as well.
</p>
</div>
</div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bottles – Easily run Windows software on Linux (208 pts)]]></title>
            <link>https://usebottles.com/</link>
            <guid>36592930</guid>
            <pubDate>Tue, 04 Jul 2023 21:47:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://usebottles.com/">https://usebottles.com/</a>, See on <a href="https://news.ycombinator.com/item?id=36592930">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><a rel="me" href="https://mastodon.online/@usebottles">


</a><section><a rel="me" href="https://mastodon.online/@usebottles">
</a>
</section>
<div>
<div>
<h2>Gaming <u>ready</u></h2>
<p>Bottles' Gaming Environment comes preconfigured to support a large set of Windows video games on Linux.</p>
<p>Thanks to our <span>installers</span> you can have immediate access to the most famous game stores (e.g. Epic Games Store,
EA Launcher, Battle.net etc.) and then play your favorite games, just like on Windows.</p>
<p><a href="https://usebottles.com/gaming">
More about</a>
</p></div>
<p><img alt="Bottles highly customisable" src="https://usebottles.com/uploads/bottles-gaming.png">
<img alt="Bottles highly customisable" src="https://usebottles.com/uploads/bottles-gaming-dark.png">
</p></div>
<div>
<div>
<h2>Empowered by <u>environments</u></h2>
<p>Bottles introduces a new way to handle Windows prefixes using
environments, a combination of ready-to-use settings, libraries and
dependencies.</p>
<p>Choose between <span>Gaming</span> and
<span>Software</span> environment based on the type of
software you want to start.</p>
<p>More advanced users can choose the <span>Custom</span>
environment to configure the bottle on their own.</p>
<p><a href="https://docs.usebottles.com/getting-started/environments">
More about</a>
</p></div>
<p><img alt="Bottles highly customisable" src="https://usebottles.com/uploads/bottles-environments.png">
<img alt="Bottles highly customisable" src="https://usebottles.com/uploads/bottles-environments-dark.png">
</p></div>
<div>
<div>
<h2>Highly <u>tweakable</u></h2>
<p>Customize your Windows environment with ease.</p>
<p>Choose whether to use dxvk, vkd3d, gamemode, esync, fsync or other,
Bottles will handle it all for you.</p>
<p>Change runners on the fly or install new ones for all your tests.</p>
<p><a href="https://docs.usebottles.com/bottles/preferences">
More about</a>
</p></div>
<p><img alt="Bottles highly customisable" src="https://usebottles.com/uploads/bottles-customizable.png">
<img alt="Bottles highly customisable" src="https://usebottles.com/uploads/bottles-customizable-dark.png">
</p></div>
<div>
<div>
<h2>Integrated <u>dependency manager</u></h2>
<p>Windows software need dependencies to work properly.</p>
<p>Bottles comes with a powerful and easy-to-use dependency manager that
automates this task.</p>
<p>Just look for the package you need and then "install", Bottles will
take care of everything for you.</p>
<p><a href="https://docs.usebottles.com/bottles/dependencies">
More about</a>
</p></div>
<p><img alt="Bottles highly customisable" src="https://usebottles.com/uploads/bottles-dependencies-manager.png">
<img alt="Bottles highly customisable" src="https://usebottles.com/uploads/bottles-dependencies-manager-dark.png">
</p></div>
<div>
<div>
<h2>Install programs <u>in one click</u><span>New</span></h2>
<p>Installers (introduced in 2022.2.14) are an easy way to install games
and applications into your bottles.</p>
<p>Installers are instruction sets written by our community, which
automate the entire dependency setup and installation process. You
won't have to worry about anything anymore.</p>
<p><a href="https://docs.usebottles.com/bottles/installers">
More about</a>
<a href="https://usebottles.com/appstore">
Apps</a>
</p></div>
<p><img alt="Bottles highly customisable" src="https://usebottles.com/uploads/bottles-installers.png">
<img alt="Bottles highly customisable" src="https://usebottles.com/uploads/bottles-installers-dark.png">
</p></div>
<div>
<div>
<h2>Easy <u>to restore</u></h2>
<p>The Snapshots manager allows you to easily restore a previous state
of your bottle.</p>
<p>If enabled, Bottles will automatically create a new snapshot when you
install a new dependency.</p>
<p>If something goes wrong, go to the Snapshots section of your bottle
and restore the previous state.</p>
<p><a href="https://docs.usebottles.com/bottles/versioning">
More about</a>
</p></div>
<p><img alt="Bottles highly customisable" src="https://usebottles.com/uploads/bottles-versioning.png">
<img alt="Bottles highly customisable" src="https://usebottles.com/uploads/bottles-versioning-dark.png">
</p></div>
<div>
<h2>
<ion-icon name="shield-checkmark-outline"></ion-icon>
Safe. <u>Sandboxed.</u>
</h2>
<p>Your bottles are isolated from the system and will only hit your
personal files when you decide.</p>
<p>The full-sandbox is provided and pre-configured only using the
<a href="https://flathub.org/apps/details/com.usebottles.bottles">
Flatpak package</a> (highly recommended).</p>
<p>All other packages still have access to the partial sandbox which
isolates the bottle files and prevents them from accessing your
homedir.</p>
<p><a href="https://docs.usebottles.com/flatpak/expose-directories">
More about</a>
</p></div>
<div>
<h2>Sponsors</h2>

<p>Plus all the donations from the awesome users who support Bottles!</p>
<p><a href="https://usebottles.com/funding/">
Show more</a>
</p></div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LXD is now under Canonical (144 pts)]]></title>
            <link>https://linuxcontainers.org/lxd/</link>
            <guid>36592343</guid>
            <pubDate>Tue, 04 Jul 2023 20:48:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://linuxcontainers.org/lxd/">https://linuxcontainers.org/lxd/</a>, See on <a href="https://news.ycombinator.com/item?id=36592343">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content">
            <h2 id="lxd-is-now-under-canonical">LXD is now under Canonical<a href="#lxd-is-now-under-canonical" title="Permanent link">¶</a></h2>
<p>The LXD project is no longer part of the LinuxContainers project but can now be found directly on Canonical's websites.</p>
<p>Website: <a href="https://ubuntu.com/lxd">https://ubuntu.com/lxd</a><br>
Github: <a href="https://github.com/canonical/lxd">https://github.com/canonical/lxd</a><br>
Forum: <a href="https://discourse.ubuntu.com/c/lxd/">https://discourse.ubuntu.com/c/lxd/</a><br>
Documentation: <a href="https://documentation.ubuntu.com/lxd/">https://documentation.ubuntu.com/lxd/</a></p>
<h2 id="project-announcement">Project announcement<a href="#project-announcement" title="Permanent link">¶</a></h2>
<p>Date: 4th of July 2023</p>
<p>Hello,</p>
<p>Canonical, the creator and main contributor of the LXD project has decided that after over 8 years as part of the Linux Containers community, the project would now be better served directly under Canonical’s own set of projects.</p>
<p>While the team behind Linux Containers regrets that decision and will be missing LXD as one of its projects, it does respect Canonical’s decision and is now in the process of moving the project over.</p>
<p>Concretely, the expected changes are:</p>
<ul>
<li><a href="https://github.com/lxc/lxd">https://github.com/lxc/lxd</a> will now become <a href="https://github.com/canonical/lxd">https://github.com/canonical/lxd</a></li>
<li><a href="https://linuxcontainers.org/lxd">https://linuxcontainers.org/lxd</a> will disappear and be replaced with a mention directing users to <a href="https://canonical.com/lxd">https://ubuntu.com/lxd</a></li>
<li>The LXD YouTube channel will be handed over to the Canonical team</li>
<li>The LXD section on the LinuxContainers community forum will slowly be sunset in favor of the Ubuntu Discourse forum run by Canonical</li>
<li>The LXD CI infrastructure will be moved under Canonical’s care</li>
<li>Image building for Linux Containers will no longer be relying on systems provided by Canonical, limiting image building to <code>x86_64</code> and <code>aarch64</code>.</li>
</ul>
<p>What will not be changing:</p>
<ul>
<li>The rest of the Linux Containers projects remain unaffected</li>
<li>The image server, currently used by both LXC and LXD will keep operating as normal, though with less architectures available as mentioned above</li>
</ul>
<p>Those changes will likely all happen pretty rapidly as everything is relatively tightly integrated together. As a result, you may notice a bit of bumpiness while Canonical sets up the replacement infrastructure.</p>
<p>Sincerely,</p>
<p>The Linux Containers team</p>
<p>&nbsp;&nbsp;  Christian Brauner<br>
&nbsp;&nbsp;  Serge Hallyn<br>
&nbsp;&nbsp;  Stéphane Graber</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[“How is your thesis going?” Students’ perspectives on mental health and stress (101 pts)]]></title>
            <link>https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0288103</link>
            <guid>36592033</guid>
            <pubDate>Tue, 04 Jul 2023 20:20:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0288103">https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0288103</a>, See on <a href="https://news.ycombinator.com/item?id=36592033">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content">

<header>





<ul id="almSignposts">
  <li id="loadingMetrics">
    <p>Loading metrics</p>
  </li>
</ul>







    <div>
  <p id="licenseShort">Open Access</p>
  <p id="peerReviewed">Peer-reviewed</p>

<p id="artType">Research Article</p>


</div>
    <div>



<div>
  

<ul data-js-tooltip="tooltip_container" id="author-list">



<li data-js-tooltip="tooltip_trigger">
       
</li>

<li data-js-tooltip="tooltip_trigger">
   <a data-author-id="1">
Anna Bareis,</a>    
</li>

<li data-js-tooltip="tooltip_trigger">
   <a data-author-id="2">
Moritz Bross,</a>    
</li>

<li data-js-tooltip="tooltip_trigger">
   <a data-author-id="3">
Zoé Bürger,</a>    
</li>

<li data-js-tooltip="tooltip_trigger">
   <a data-author-id="4">
Álvaro Cortés Rodríguez,</a>    
</li>

<li data-js-tooltip="tooltip_trigger">
   <a data-author-id="5">
Nina Effenberger,</a>    
</li>

<li data-js-tooltip="tooltip_trigger">
   <a data-author-id="6">
Markus Kleinhansl,</a>    
</li>

<li data-js-tooltip="tooltip_trigger">
   <a data-author-id="7">
Fabienne Kremer,</a>    
</li>

<li data-js-tooltip="tooltip_trigger">
   <a data-author-id="8">
Cornelius Schröder</a>    
</li>

</ul>


</div>


<div id="floatTitleTop" data-js-floater="title_author" role="presentation">
    <div>
      <h2><!--?xml version="1.0" encoding="UTF-8"?-->“How is your thesis going?”–Ph.D. students’ perspectives on mental health and stress in academia</h2>

<ul id="floatAuthorList" data-js-floater="floated_authors">

  <li data-float-index="1">Julian Friedrich,&nbsp;

  </li>
  <li data-float-index="2">Anna Bareis,&nbsp;

  </li>
  <li data-float-index="3">Moritz Bross,&nbsp;

  </li>
  <li data-float-index="4">Zoé Bürger,&nbsp;

  </li>
  <li data-float-index="5">Álvaro Cortés Rodríguez,&nbsp;

  </li>
  <li data-float-index="6">Nina Effenberger,&nbsp;

  </li>
  <li data-float-index="7">Markus Kleinhansl,&nbsp;

  </li>
  <li data-float-index="8">Fabienne Kremer,&nbsp;

  </li>
  <li data-float-index="9">Cornelius Schröder

  </li>

</ul>



    </div>
    <div id="titleTopCloser">
      <p><img src="https://journals.plos.org/resource/img/logo-plos.png" alt="PLOS"></p><p>x</p>
    </div>
  </div>

      <ul>
        <li id="artPubDate">Published: July 3, 2023</li>
        <li id="artDoi">
<a href="https://doi.org/10.1371/journal.pone.0288103">https://doi.org/10.1371/journal.pone.0288103</a>
        </li>
        <li></li>
      </ul>

    </div>
  
</header>
  <div>






<div id="figure-carousel-section">
  <h2>Figures</h2>

  
</div>





        <div id="artText">
          



<div xmlns:plos="http://plos.org"><h2>Abstract</h2><div><p>Mental health issues among Ph.D. students are prevalent and on the rise, with multiple studies showing that Ph.D. students are more likely to experience symptoms of mental health-related issues than the general population. However, the data is still sparse. This study aims to investigate the mental health of 589 Ph.D. students at a public university in Germany using a mixed quantitative and qualitative approach. We administered a web-based self-report questionnaire to gather data on the mental health status, investigated mental illnesses such as depression and anxiety, and potential areas for improvement of the mental health and well-being of Ph.D. students. Our results revealed that one-third of the participants were above the cut-off for depression and that factors such as perceived stress and self-doubt were prominent predictors of the mental health status of Ph.D. students. Additionally, we found job insecurity and low job satisfaction to be predictors of stress and anxiety. Many participants in our study reported working more than full-time while being employed part-time. Importantly, deficient supervision was found to have a negative effect on Ph.D. students’ mental health. The study’s results are in line with those of earlier investigations of mental health in academia, which likewise reveal significant levels of depression and anxiety among Ph.D. students. Overall, the findings provide a greater knowledge of the underlying reasons and potential interventions required for advancing the mental health problems experienced by Ph.D. students. The results of this research can guide the development of effective strategies to support the mental health of Ph.D. students.</p>
</div></div>


<div xmlns:plos="http://plos.org"><p><strong>Citation: </strong>Friedrich J, Bareis A, Bross M, Bürger Z, Cortés Rodríguez Á, Effenberger N, et al.  (2023) “How is your thesis going?”–Ph.D. students’ perspectives on mental health and stress in academia. PLoS ONE 18(7):
           e0288103.
        
        https://doi.org/10.1371/journal.pone.0288103</p><p><strong>Editor: </strong>Khader Ahmad Almhdawi, Jordan University of Science and Technology Faculty of Applied Medical Science, JORDAN</p><p><strong>Received: </strong>March 23, 2023; <strong>Accepted: </strong>June 20, 2023; <strong>Published: </strong> July 3, 2023</p><p><strong>Copyright: </strong> © 2023 Friedrich et al. This is an open access article distributed under the terms of the <a href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</a>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</p><p><strong>Data Availability: </strong>The anonymized data set is available at <a href="https://doi.org/10.23668/psycharchives.12914">https://doi.org/10.23668/psycharchives.12914</a>. All code for the analysis can be found at <a href="https://github.com/coschroeder/mental_health_analysis">https://github.com/coschroeder/mental_health_analysis</a>.</p><p><strong>Funding: </strong>We acknowledge support by the Open Access Publishing Fund of University of Tübingen. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p><p><strong>Competing interests: </strong> The authors have declared that no competing interests exist.</p></div>





<div xmlns:plos="http://plos.org" id="section1"><h2>Introduction</h2><p>Work situations can be demanding and have a profound influence on employees’ mental health and well-being across different sectors and disciplines [<a href="#pone.0288103.ref001">1</a>]. Multiple studies show that the mental health status of people working in academia and especially that of Ph.D. students seems to be particularly detrimental when compared to the public [e.g., <a href="#pone.0288103.ref002">2</a>,<a href="#pone.0288103.ref003">3</a>]. Disorders such as anxiety and depression are on the rise in the general population [<a href="#pone.0288103.ref004">4</a>,<a href="#pone.0288103.ref005">5</a>]. Multiple studies show that this is even more severe in academia [<a href="#pone.0288103.ref006">6</a>–<a href="#pone.0288103.ref010">10</a>] and in particular Ph.D. students are affected by mental health problems [<a href="#pone.0288103.ref011">11</a>,<a href="#pone.0288103.ref012">12</a>]. Worldwide surveys grant support for Ph.D. students’ suboptimal and alarming mental health situations [<a href="#pone.0288103.ref013">13</a>,<a href="#pone.0288103.ref014">14</a>].</p>
<p>A comprehensive study with more than 2000 participants (90% Ph.D. students, 10% Master students) from over 200 institutions across different countries showed that graduate students were more than six times more likely to experience symptoms of depression and anxiety than the general public [<a href="#pone.0288103.ref002">2</a>]. Furthermore, a global-scale meta-analysis [<a href="#pone.0288103.ref003">3</a>] and several other studies concerned with the mental health of Ph.D. students in different countries, e.g., the United States [<a href="#pone.0288103.ref007">7</a>,<a href="#pone.0288103.ref009">9</a>], the United Kingdom [<a href="#pone.0288103.ref006">6</a>], France [<a href="#pone.0288103.ref015">15</a>], Poland [<a href="#pone.0288103.ref008">8</a>], Belgium [<a href="#pone.0288103.ref016">16</a>] or Germany [<a href="#pone.0288103.ref011">11</a>,<a href="#pone.0288103.ref012">12</a>] voice concerns about the mental health situation of Ph.D. students. Recent research conducted in Belgium has consistently found a higher prevalence of mental health problems among Ph.D. students compared to different groups of other highly educated individuals [<a href="#pone.0288103.ref016">16</a>]. In the same study, 50% of the Ph.D. students reported that they suffer from some form of mental health problem, and every third is at risk of a common psychiatric disorder [<a href="#pone.0288103.ref016">16</a>]. A similar picture is forming in Germany. For example, the prevalence of at least moderate depression among doctoral researchers at the Max Planck Society, one of the biggest academic societies in Germany, was between 9.6% and 11.6% higher than in the age-related general population [<a href="#pone.0288103.ref011">11</a>].</p>

<div id="section1"><h3>Increasing numbers of anxiety and depression among Ph.D. students</h3>
<p>Recent studies describe not only a high prevalence but also a rising tendency of mental health issues among Ph.D. students. In a study from 2017, 12% of the respondents reported seeking help for depression or anxiety related to their Ph.D. [<a href="#pone.0288103.ref013">13</a>], while in 2019, the result was even more drastic, as 36% of the respondents reported that having searched for help for those same reasons [<a href="#pone.0288103.ref014">14</a>]. Several studies among doctoral researchers within the Max Planck Society show similar results. For instance, a survey in 2019 showed that the average of the Ph.D. students were at risk for an anxiety disorder and another sample from 2020 provided even more robust support for this claim [<a href="#pone.0288103.ref011">11</a>,<a href="#pone.0288103.ref012">12</a>]. Furthermore, the mean depression score increased from 2019 to 2020 in both samples [<a href="#pone.0288103.ref011">11</a>].</p>
</div>

<div id="section2"><h3>Risk factors and resources</h3>
<p>Given these alarming statistics, several studies addressed risks and resources for increased mental health issues. Other studies have revealed that gender, perceived work-life balance, and mentorship quality are correlated with mental health issues [<a href="#pone.0288103.ref002">2</a>,<a href="#pone.0288103.ref017">17</a>]. Specifically, female gender [<a href="#pone.0288103.ref017">17</a>] and transgender/gender-nonconforming Ph.D. students are, on average, more likely to suffer from mental health issues [<a href="#pone.0288103.ref002">2</a>]. In contrast, a positive and supportive mentoring relationship or a supervisor’s leadership style, and a good work-life balance are positively associated with better mental health [<a href="#pone.0288103.ref002">2</a>,<a href="#pone.0288103.ref016">16</a>]. While some authors [<a href="#pone.0288103.ref018">18</a>] reported a negative correlation between the Ph.D. stage and mental health, with students at later stages disclosing greater levels of distress, others [<a href="#pone.0288103.ref016">16</a>] did not find significant differences in this regard. Moreover, another report identified that Ph.D. students’ satisfaction levels strongly correlate with their relationship with their supervisors, number of publications, hours worked, and received guidance from advisors [<a href="#pone.0288103.ref019">19</a>]. Furthermore, several studies showed a positive correlation between job satisfaction [<a href="#pone.0288103.ref020">20</a>,<a href="#pone.0288103.ref021">21</a>] as well as a negative correlation between job insecurity [<a href="#pone.0288103.ref022">22</a>] and mental health or perceived stress, also in Ph.D. students.</p>
</div>

<div id="section3"><h3>Aim and research questions</h3>
<p>Taken together, the alarming findings on the psychological status of Ph.D. students around the globe cannot be denied. However, data on the situation of Ph.D. students in Germany are scarce [<a href="#pone.0288103.ref011">11</a>,<a href="#pone.0288103.ref012">12</a>,<a href="#pone.0288103.ref023">23</a>]; thus, comparisons of different universities within a country can hardly be made. However, addressing those differences is particularly relevant since the working conditions, concerning contract types, financial situations or supervision vary strongly among different countries, geographical regions and universities or institutions [<a href="#pone.0288103.ref024">24</a>]. Furthermore, little is known about the reasons for this precarious situation and where exactly the need for action lies [<a href="#pone.0288103.ref025">25</a>]. Therefore, the aim of this study was to conduct a survey among Ph.D. students at a university in the southwest of Germany to assess Ph.D. students’ mental health status. Additionally, the present study also reveals information on the extent of the need for additional support services and pinpoints the specific areas where these services ought to be emphasized. In order to help identify relevant indicators, this investigation provides empirically sound findings on the mental health situation of Ph.D. students in Germany.</p>
</div>
</div>

<div xmlns:plos="http://plos.org" id="section2"><h2>Materials and methods</h2>
<div id="section1"><h3>Sample and procedure</h3>
<p>Overall, 589 participants (60.3% female, 0.8% of diverse gender, <em>M</em><sub>Age</sub> = 28.8, <em>SD</em><sub>Age</sub> = 3.48, range 17–48 years) out of a total of enrolled 2552 Ph.D. students (response rate: 23.1%; actual numbers of Ph.D. students at the University of Tübingen higher as some Ph.D. students are not enrolled) took part in an online survey from October to December 2021. Instructions, items, and scales were all presented in English. Participants could answer the open questions in German or English and were comprised of Ph.D. students across various stages of their Ph.D. at the University of Tübingen without further exclusion criteria. The online questionnaire was sent to Ph.D. students’ email addresses via mailing distribution lists in cooperation with the central institution for strategic researcher development (Graduate Academy) of the University of Tübingen and with Ph.D. representatives of different faculties. Ethics approval was obtained by the “Ethics Committee of the Faculty of Economics and Social Science of the University of Tübingen” and written informed consent was given by the participants.</p>
<p>The distribution of faculty affiliation of the participants was heterogeneous with shares of 61.8% Science, 12.4% Humanities, 11.7% Economics and Social Sciences. These numbers reflect the different sizes of faculties and are roughly aligned with the relative numbers of students (41.7% Science, 24.8% Medicine, 16.2% Humanities, 7.5% Economics and Social Sciences), with a clear underrepresentation of the Medical Faculty. Faculties with less than 20 participants or participants with multiple answers were grouped into one category for further analysis (Others 14.1%, see <a href="#pone.0288103.s001">S1 Table</a>). 67.9% of the participants were German and in total, 82.9% came from European countries. During data collection, the participants were at different stages of their Ph.D. ranging from 0 to over 130 months with a mean time of two and a half years (30.0 months) of Ph.D. progress.</p>
</div>

<div id="section2"><h3>Measures</h3>
<p>First, demographic data and background information on the current Ph.D. situation were collected. In a second part, to get a differentiated view, we included different measures to operationalize the mental health status of Ph.D. students. The quantitative questionnaire assessed 1) general health, generalized anxiety disorder, as well as internally reviewed self-generated questions, 2) life and job satisfaction, and quantitative job insecurity, and 3) stressors (institutional and systemic), causes of stress and potential solutions. This study also collected information regarding the degree of participants’ familiarity with the mental health resources available at the university, e.g., points of contacts for counseling, in order to evaluate whether Ph.D. students make use of these services. Moreover, participants were asked to name additional services that they may consider necessary.</p>

<div id="section1"><h4>General health and stressors.</h4><p>General health was assessed by two items of the Perceived Health Questionnaire (PHQ-2) [<a href="#pone.0288103.ref026">26</a>]. Participants were asked to indicate how frequently they had experienced depressed moods and anhedonia over the past four weeks on a scale from 1 (not at all) to 4 (nearly every day). Additionally, they were presented with seven items of the Generalized Anxiety Disorder scale (GAD-7) [<a href="#pone.0288103.ref027">27</a>] capturing the severity of various anxiety signs like nervousness, restlessness, and easy irritation on a scale from 1 (not at all) to 4 (nearly every day). Both scales were used in this combination in a previous study in German higher education [<a href="#pone.0288103.ref028">28</a>]. Furthermore, we included two binary questions on whether the participants are currently in psychotherapy and if they have ever been diagnosed with a mental disorder.</p>
<p>The condensed version of the Perceived Stress Scale (PSS) [<a href="#pone.0288103.ref029">29</a>] was used to get the degree of stressful situations in life in the last twelve months or since the start of the Ph.D. [<a href="#pone.0288103.ref030">30</a>]. The response scale ranged from 0 (never) to 4 (very often), the following being a sample item: “… how often have you felt that you were unable to control the important things in your life?” To check the internal consistency of the four items, we calculated Cronbach’s alpha which was .79.</p>
</div>

<div id="section2"><h4>Job satisfaction and life satisfaction.</h4><p>Three items on a scale from 1 (strongly disagree) to 5 (strongly agree) were used to measure job satisfaction [<a href="#pone.0288103.ref031">31</a>], where a higher mean score indicated higher job satisfaction. A sample item is: “I am satisfied with my job.” Cronbach’s alpha was .86. Additionally, we added one item concerning general life satisfaction [adapted from <a href="#pone.0288103.ref032">32</a>] with the same response categories to get a more holistic insight.</p>
</div>

<div id="section3"><h4>Job insecurity.</h4><p>To assess the fear of losing the job itself, quantitative job insecurity was measured with three items (e.g., “I am worried about having to leave my job before I would like to.”) [<a href="#pone.0288103.ref033">33</a>] on a scale from 1 (strongly disagree) to 5 (strongly agree). We calculated a mean score with higher scores indicating higher job insecurity. Cronbach’s alpha was .80.</p>
</div>

<div id="section4"><h4>Institutional and systemic stressors.</h4><p>For institutional stressors, we focused mainly on the role of supervision and included eight questions, four were framed using positive wording and four with negative wording, each with a scale from 1 (not at all) to 5 (all of the time). We summarized these questions in two constructs (positive support/negative support) which had Cronbach’s alphas of .85 and .76, respectively. As for systemic stressors, we included two questions on long-term contracts and on future perspectives, again using a scale from 1 (strongly disagree) to 5 (strongly agree).</p>
</div>

<div id="section5"><h4>COVID-19.</h4><p>To cover the potential impacts of the COVID-19 pandemic and the implemented regulations, we included two questions to evaluate whether the pandemic affected the students’ general situation. On the one hand, participants were asked to pick the statement that best describes the effects of the pandemic in general (“yes, it improved my general situation”, “yes, it worsened my general situation”, “yes, but it neither worsened nor improved my general situation”, “no”), and on the other hand, they were asked to evaluate whether the particular answers provided in this survey had been affected by the pandemic from 1 (very likely) to 5 (very unlikely).</p>
</div>
</div>

<div id="section3"><h3>Rating procedure and open answers</h3>

<div id="section1"><h4>Causes of stress and potential solutions.</h4><p>We included three open-ended questions in the questionnaire to get a deeper understanding of the perceived causes of stress, potential ways to improve mental health, and ways to improve the overall situation of Ph.D. students. The questions were: (1) “What is/are the cause(s) of your stress?” (2) “What would need to change to improve your mental health status?” (3) “What could be done to improve your situation?” Participants could mention as many points as they wanted (without any word limit). To analyze these questions, we built categories by following the model of inductive category development [<a href="#pone.0288103.ref034">34</a>]. Two raters screened the first and last 20 responses in the data set and created categories for reoccurring topics (for a list containing all categories see <a href="#pone.0288103.s005">S5</a>–<a href="#pone.0288103.s007">S7</a> Tables). In the next steps, two new raters rated all open answers with the developed categories and added additional categories if needed. Applicable categories were rated with 1 (“category was mentioned”) or 0 (“category was not mentioned”). For example, the following response to question (1) “[My] supervisor is on maternity leave with open end, i.e. I have no one to talk to about my topic and have almost nothing so far […] I feel like I’m not good enough at this, not sure I will be able to succeed–everyone else has other projects and publications except me–no topic-related network” was rated with 1 in the following four categories: supervision (quality &amp; quantity), social integration &amp; interactions (private &amp; professional), self-perception (internal factors), and perceived lack of relevant competences &amp; experience–(sense) of progress and success. The full list of categories and inter-rater reliability as measured by Krippendorf’s Alpha is reported in <a href="#pone-0288103-t003">Table 3</a> [<a href="#pone.0288103.ref035">35</a>].</p>
</div>
</div>
</div>

<div xmlns:plos="http://plos.org" id="section3"><h2>Results</h2>
<div id="section1"><h3>Descriptive statistics of work environment and workload</h3>
<p>The largest part of the participants (65.5%) was temporarily employed, 12.1% got a scholarship, 7.6% were permanently employed, and 6.5% were not employed at all. The mean for total contract length was 34.3 months, with a range between two and 72 months. About 10.5% of the participants had a contract for only 12 months or shorter. A similar large variation was found in the percentage of employment with a mean of 63%, ranging from 10% to 100% of employment. For workload, we found a mean of 36.0 hours of Ph.D.-related work per week with a standard deviation of 15.6 hours. After taking a closer look at high workloads, we found that 31.3% of the participants work 45 hours or more (21.5% work 50 hours and more) per week. On top of their Ph.D. work, many Ph.D. students work in other jobs, which combined with the hours spent for Ph.D.-related work, summed up to the mean of 44.1 overall working hours per week. A detailed description can be found in <a href="#pone.0288103.s001">S1 Table</a>.</p>
</div>

<div id="section2"><h3>Faculty-wise comparison</h3>
<p>In an explorative manner, we compared the mean differences of the most important variables between different faculties. Most of the analyzed variables did not show significant differences. Still, we want to stress that the highly imbalanced sample sizes (see <a href="#pone.0288103.s003">S3 Table</a>) could lead to false negative outcomes due to the small numbers of participants in some groups. However, we found that the mean job insecurity was significantly different between faculties (<em>p</em> &lt; .001, Kruskal-Wallis rank sum test) with comparable low job insecurity in the faculties of law (<em>M</em> = 2.10, <em>SD</em> = 1.22) and theology (<em>M</em> = 2.38, <em>SD</em> = 1.19) and high insecurity in the faculty of humanities (<em>M</em> = 3.32, <em>SD</em> = 0.91).</p>
</div>

<div id="section3"><h3>COVID-19</h3>
<p>In total, 41.9% of the participants stated that their general situation worsened due to the pandemic, while 28.5% stated that the pandemic affected but it neither worsened nor improved their general situation. 33.5% of the participants stated that their responses in this study were “very likely” or “likely” to be affected by the pandemic, with a mean of 2.97 (<em>SD</em> = 1.26).</p>
</div>

<div id="section4"><h3>General health and stressors</h3>
<p>The mean of the sum score for PHQ-2 in our study was 2.32 which is below the cut-off of three for major depression [<a href="#pone.0288103.ref026">26</a>]. Yet, 33.1% of the participants were above the cut-off. For the GAD-7, the sum score for the study’s sample was 8.49. Cut points of 5 might be interpreted as mild, cut points of 10 as moderate and 15 as severe levels of anxiety [<a href="#pone.0288103.ref027">27</a>], which implies a mild risk level for generalized anxiety with the suggestion of a follow-up examination in this sample. When asking for mental disorders, we found that 19.9% of the participants (<em>n</em> = 99) have already been diagnosed with a mental disorder and 15.5% (<em>n</em> = 77) are currently in psychotherapy. The sum score for the Perceived Stress Scale (PSS) of 7.79 (with <em>Min</em> = 0, <em>Max</em> = 15) was above the total sum score compared to a representative British sample (6.11) [<a href="#pone.0288103.ref036">36</a>] and a representative German community sample (4.79 for PSS-4) [<a href="#pone.0288103.ref037">37</a>]. Job satisfaction of our participants with a total sum score of 10.06 was lower compared to a sum score of 12.79 in a German sample of workers in small- and medium sized enterprises [<a href="#pone.0288103.ref038">38</a>]. The mean score for job satisfaction was 3.35, also lower than in a sample of Ph.D. students in Belgium (3.9) [<a href="#pone.0288103.ref039">39</a>]. Job insecurity was with a total sum score of 8.76 higher compared to the German small- and medium sized enterprises sample (5.67) [<a href="#pone.0288103.ref038">38</a>]. Consistently, more than 80% of the Ph.D. students in our study were worried about the lack of permanent or long-term contracts in academia (<em>M</em> = 4.25, <em>SD</em> = 1.09; 5 indicating a strong agreement). Nevertheless, around half of the participants (54.5%) believed that having a Ph.D. would help them find a good job (<em>M</em> = 3.49, <em>SD</em> = 0.97). We found a mean score of 3.48 (<em>SD</em> = 0.98) for the positive support questions which is above average over response levels. Around 57.1% of the Ph.D. students felt supported by their supervisor “most” or “all of the time”. Around 55.7% felt comfortable when contacting the supervisor for support. The negative support construct was with a mean score of 2.18 below average: 46.7% of the participants had never felt looked down, and 62.6% had never felt mistreated by their supervisor. Nevertheless, 28.6% of the Ph.D. students answered feelings of degradation and 19.1% felt mistreated more than “some of the time”. When it comes to the frequency of the meetings with the supervisor, the mean reported a value of 2.4 laying somewhere between having meetings once a month (2) and at least every three months (3). However, 18.2% reported meeting their supervisor only once every six months or less. For sample items and detailed values see <a href="#pone.0288103.s002">S2 Table</a>.</p>
<p>When we analyzed the relationship between the studied outcomes, we found that all major constructs correlated significantly (see <a href="#pone-0288103-t001">Table 1</a>). High correlations occurred between the items of the related PHQ-2 and GAD-7 as well as their connections to the PSS. Understandably, the two institutional support dimensions were highly correlated (<em>r</em> = -.69).</p>
</div>

<div id="section5"><h3>Regression for perceived stress, depression, and anxiety</h3>
<p>To predict potential driving factors for the two more direct mental health measurements, namely depression and anxiety, and for perceived stress, we employed linear regression models with these three constructs as response variables controlling for age and gender. We included relevant risk factors and stressors such as job insecurity, perceived stress, negative support and resources such as job and life satisfaction, and positive support to get a comprehensible overview over predictors. All analyses were carried out in R statistics version 4.1.3.</p>
<p>For depression, significant predictors were job satisfaction (β = -0.1, <em>SE</em> = 0.04, <em>p</em> &lt; .05), life satisfaction (β = -0.3, <em>SE</em> = 0.04, <em>p</em> &lt; .001), perceived stress (β = 0.4, <em>SE</em> = 0.05, <em>p</em> &lt; .001) and negative institutional support (β = 0.11, <em>SE</em> = 0.05, <em>p</em> &lt; .05, see <a href="#pone-0288103-t002">Table 2</a>). The model explained 46.7% of the variance, <em>F</em>(8, 482) = 54.5, <em>p</em> &lt; .01.</p>
<p>For anxiety, all studied variables except job satisfaction and positive support were significant predictors with a variance explanation of 36.0%, <em>F</em>(8, 392) = 29.5, <em>p</em> &lt; .01 (see <a href="#pone-0288103-t002">Table 2</a>). Noticeable was the strong influence of perceived stress on anxiety. Specifically, we observed that with an increase of one unit in perceived stress, the level of GAD-7 increased by 2.02 units and was in line with the high correlation (<em>r</em> = .52, <em>p</em> &lt; .01, <a href="#pone-0288103-t002">Table 2</a>).</p>
<p>For perceived stress, we found that job insecurity (β = 0.15, <em>SE</em> = 0.02, <em>p</em> &lt; .01), life satisfaction (β = -0.32, <em>SE</em> = 0.03, <em>p</em> &lt; .01) as well as negative institutional support (β = 0.13, <em>SE</em> = 0.04, <em>p</em> &lt; .01) were significant predictors with a model variance explanation of 42.7%, <em>F</em>(4, 486) = 53.5, <em>p</em> &lt; .01. The detailed results for this regression analysis can be found in <a href="#pone.0288103.s004">S4 Table</a>.</p>
</div>

<div id="section6"><h3>Qualitative answers</h3>
<p>In the following, we report the main categories with short sample quotes as well as the mean frequency of the two raters (see <a href="#pone-0288103-t003">Table 3</a>; details in <a href="#pone.0288103.s005">S5</a>–<a href="#pone.0288103.s007">S7</a> Tables). The inter-rater reliability as indicated by Krippendorff’s alpha for the top five categories of all questions was above α ≥ .67, except for the category <em>Manageable Workload</em> for question MH06_1 (see <a href="#pone-0288103-t003">Table 3</a>) with α = .62; CI [0.50; 0.74]. A threshold of .67 is commonly considered as the lower conceivable limit that still allows tentative conclusions [<a href="#pone.0288103.ref040">40</a>].</p>

<div id="section1"><h4>Causes of stress.</h4><p>The question “What is/are the cause(s) of your stress?” was answered by <em>n</em> = 446 participants. To cover the breadth of the responses, we built 18 categories. The most frequently mentioned categories were <em>Workload &amp; Time Pressure</em> (mean rating frequency = 211), <em>Self-Perception</em> (<em>M</em> = 132.5), <em>Job-Insecurity</em> (<em>M</em> = 93), <em>Social Integration &amp; Interactions</em> (<em>M</em> = 91), and <em>Supervision Quality &amp; Quantity</em> (<em>M</em> = 88.5). The category <em>Workload &amp; Time Pressure</em> includes all responses referring to the amount of work and/or deadlines. The category <em>Self-Perception</em> includes responses that indicate a perceived lack of competences or other personal doubts, concerns, and worries (e.g., “Since I started my Ph.D. I have almost constantly felt stupid”, “feeling like not belonging in academia, lack of self-confidence, feeling of making too little progress”). The category <em>Job Insecurity</em> reflects responses regarding contract length and general uncertainty about future employment (e.g., “scholarship is to be ended”, “Not knowing how things will work out after the PhD”, “Hopelessness of scientific career because there are too few full-time positions”). The category <em>Social Integration &amp; Interactions</em> covers responses regarding the integration and sense of belonging in the work environment (e.g., “not valued by colleagues”, “being socially isolated at work”) as well as social issues in the private life (e.g., “Mostly my personal life, or often the lack thereof”, “problems with parents”). The category <em>Supervision Quality &amp; Quantity</em> was used to capture all supervision-related responses including comments about the lack of support, feedback, frequency of meetings, or supervisors’ interest in the topics (e.g., “no clear communication with supervisor”, “lack of support from supervisor, even gossiping about me behind my back”).</p>
</div>

<div id="section2"><h4>Potential ways to improve the mental health status.</h4><p>When asked “What would need to change to improve your mental health status?”, the Ph.D. students’ responses (<em>n</em> = 307) included various topics, some addressing compensation and income-related aspects, others highlighting supportive supervision. Overall, the responses lead to twelve different categories. Most answers referred to <em>Supportive Supervision</em> (<em>M</em> = 98.5), followed by <em>Job Security/Contract</em> (<em>M</em> = 59). Sample quotes with respect to supervision are e.g., “more feedback from supervisor or even more interest in my topic” or “more regular support by supervisor”. The category <em>Job Security/Contract</em> contains comments with respect to contract length and aspects for future employment (e.g., “no more worries about not being able to get my contract renewed”). The category <em>Manageable Workload</em> (<em>M</em> = 56.5) includes all responses around work-life balance (e.g., “having also activities beside work”, “clear work hours”). The fourth category was <em>Compensation &amp; Financial Security</em> (<em>M</em> = 35) and included all income- and compensation-related aspects of the job (e.g., “Be paid 100% would be a start”, “Get paid for all the time at work”). The category <em>Less Additional Tasks</em> (<em>M</em> = 27.5) was used to specifically cover responses mentioning the number of additional tasks within the job (“Less work in teaching/work unrelated to PhD”).</p>
</div>

<div id="section3"><h4>Ways to improve the personal situation.</h4><p>In addition to the previous question, which focused on general ways to improve the mental health status, we asked the Ph.D. students the following question: “What could be done to improve your situation?” Based on the themes and topics mentioned in the responses (<em>n</em> = 281) we built eleven categories. The categories mentioned the most were <em>Job-Security &amp; Compensation</em> (<em>M</em> = 85.5), followed by <em>Supportive Supervision</em> (<em>M</em> = 68), <em>Services and Support System</em> (<em>M</em> = 39.5), <em>Decrease Pressure to Perform</em> (<em>M</em> = 39.5), and <em>Manageable Workload</em> (<em>M</em> = 36). The category <em>Job-Security &amp; Compensation</em> includes responses like “chances of getting a long-term job in academia, not just the three-year programs” or “Fair payment (half of students get 50% others 65% even at the same institute)”. For the category <em>Supportive Supervision</em> “Regular meetings with people who are supportive &amp; have an expertise in my research topic” can serve as a sample quote. The category <em>Services and Support System</em> was built to cover the responses named a solution outside the working group and team, such as “it would be helpful to see a university-based psychologist outside of the regular working hours” or “more courses (or better communications about them) about stress management”. The next category was labeled <em>Decrease Pressure to Perform</em> and included all responses that highlighted a high level of perceived pressure, such as “the performance pressure (every talk at a seminar is a job talk) is a big problem” or “Instead of pressuring academics to publish as much as possible, there should be more focus on the quality instead of the quantity of their articles/publication”. The last category, <em>Manageable Workload</em>, contained answers with respect to the amount of work (e.g., “Normal working hours, having really free-time without having the feeling that I should be working, it should be normal to take all vacation days”).</p>
</div>

<div id="section4"><h4>Summary of the qualitative answers.</h4><p>With respect to the open answers, it can be summarized that the factors named as causes for stress and the possible solutions cover a wide range of topics. However, there are reoccurring topics across all three questions, such as supervision, workload, and job security. The role of supervision is a reemerging motif in the qualitative content analysis. While the quality and quantity of supervision were seen as a cause of stress, supportive supervision has a positive impact on the mental health status as well as the whole situation of the Ph.D. students. Furthermore, job insecurity was mentioned as an important stressor, while stable contracts and appropriate compensation for the work and fewer extra tasks were also added for improvement. Workload and time pressure were the most often stated causes of stress, followed by self-doubts and worries about not having enough competencies for the job. A manageable workload, fewer additional tasks, and a lower pressure to perform were indicated by the participants as valuable improvements.</p>
</div>
</div>
</div>

<div xmlns:plos="http://plos.org" id="section4"><h2>Discussion</h2>
<div id="section1"><h3>Summary of the main findings</h3>
<p>The conducted survey investigates the mental health of Ph.D. students at a university in the southwest of Germany and gives insights into what causes stress and mental health disorders and where there is a need for further support services. Our qualitative and quantitative analyses revealed interesting and consistent results on the alarming situation of the mental health of Ph.D. students.</p>
<p>First, our quantitative results revealed that one-third of the participants were above the cut-off for depression which is an indicator of a high risk of depression that should be checked by a health professional. On average, the surveyed Ph.D. students were at a mild risk level for an anxiety disorder. While our study design does not allow us to diagnose mental illnesses, it identifies problems that need to be pursued further. It reveals some unhealthy working conditions and increased risks for mental illnesses. Our qualitative and quantitative results showed consistently that many of the most prominent issues for our study’s participants are personal factors such as perceived stress, life satisfaction and self-doubt, but modulated by structural deficits such as financial and job security as well as workload and time pressure. The quantitative analyses revealed that life satisfaction, perceived stress and negative support are the main predictors for anxiety disorders as well as depression. Additionally, low job satisfaction was a significant predictor of depression and job insecurity for anxiety. Furthermore, we identified job insecurity, life satisfaction as well as negative institutional support as predictors for perceived stress.</p>
<p>Second and besides mental health problems, our quantitative analyses showed how supervision and the work environment played a role in the mental health and general well-being of Ph.D. students. Deficient supervision could affect Ph.D. students’ perceived job insecurity and job dissatisfaction. Although good supervision was not a predictor for satisfaction, being comfortable with contacting the supervisor could lower the perceived stress. This shows the importance of the supervisor-student relationship and highlights the importance of the social work environment, which was also mentioned by study participants in the open-end questions. While the categories in the qualitative analyses mainly served to find recurring themes, they can also be used to distinguish between different levels. Some participants reflected causes of stress on a personal level (e.g., self-perception). In contrast, others set the focus on the supervisor level or working group level, or even on the more structural abstract level of the academic system.</p>
<p>Third, our study does not only investigate the mental health situation of Ph.D. students, but we also analyze how the situation and mental health status could be improved. Many suggestions were straightforward given the results of the causes of stress, i.e., bad supervision should be improved, and a secure income should be guaranteed. However, we were also able to show that Ph.D. students wish to make use of services and support systems that could be provided by the university. Furthermore, less pressure to perform and a manageable workload with fewer additional tasks besides the Ph.D. project might decrease the stress level and improve mental health status.</p>
<p>Overall, detrimental mental health is a known problem in academia, and we show another example of its extent as well as opportunities for improvement at a German university.</p>
</div>

<div id="section2"><h3>Comparison to other studies</h3>
<p>Data on Ph.D. students’ situation in Germany are scarce, and we, therefore, perform a broader comparison with Ph.D. students around the world. However, the results of this comparison should be taken with caution as our questionnaire and time of survey conduction are unique. We focus mainly on PHQ-2 [<a href="#pone.0288103.ref026">26</a>] and GAD-7 [<a href="#pone.0288103.ref027">27</a>], for which other studies in Germany during the pandemic showed that–compared to pre-COVID-19 reference values–these measurements were significantly increased [<a href="#pone.0288103.ref041">41</a>]. Two studies conducted during the COVID-19 pandemic include the same scales [<a href="#pone.0288103.ref041">41</a>,<a href="#pone.0288103.ref042">42</a>] and reveal similar results for the general population in Germany, while in our later study from October to December 2021, the risk for anxiety and depression is slightly higher. In our study, one-third of the participants (33.1%) was above the cut-off for major depression, compared to the studies in a 1.5-year earlier timeframe, where 14.1% (March to May 2020; <em>n</em> = 15704, 70.7% female gender; 42.6% university education) [<a href="#pone.0288103.ref042">42</a>] and 21.4% (March to July 2020; <em>n</em> = 16918; 69.7% female gender; 42.4% university education [<a href="#pone.0288103.ref041">41</a>] of the participants with diverse occupations were above the cut-off. Furthermore, in our study, 39.2% of the participants were at the mild risk level for anxiety compared to 27.4% of the participants in an earlier study [<a href="#pone.0288103.ref041">41</a>]. This shows the increase in depression and anxiety during the pandemic and even higher numbers in our study compared with the German general population. Nevertheless, compared to a survey at public research universities in the United States from May to July 2020, the number of doctoral students screened for major depressive disorder symptoms with the same measurements PHQ-2 was higher with 36% [<a href="#pone.0288103.ref043">43</a>], indicating high numbers of mental issues in academia in several countries.</p>
<p>While using the same scales and items for job satisfaction and job insecurity, our study showed worse sum scores compared to a sample of employers and employees in small- and medium sized enterprises in Germany (December 2020 to May 2021; <em>n</em> = 828; 53.7% female gender, <em>M</em> = 41.5 years; 38.8% higher education entrance qualification) [<a href="#pone.0288103.ref038">38</a>]. It seems that Ph.D. students have higher job insecurity and job dissatisfaction compared to workers in diverse branches and occupations. This may result from different contract types, as workers, especially in industrial sectors, have long-term contracts. The recurrent factor of time pressure and workload, also mentioned in the open-end questions, is backed up by the raw numbers of the contract types and working hours, which may also lead to job dissatisfaction. Although the mean contract type in our study is 63%, the mean number of hours dedicated to Ph.D. work (<em>M</em> = 36.0, <em>SD</em> = 15.6 hours) is almost in the range of a full-time position. What is more, the participants reported a total weekly workload (<em>M</em> = 44.1, <em>SD</em> = 11.4 hours) that exceeds a typical full-time position in Germany [<a href="#pone.0288103.ref044">44</a>]. The discrepancy between Ph.D. work and corresponding contract types results in a mean of 12.1 hours of overwork per week (based on a 38.5-hour full-time contract, which is the standard contract for Ph.D. students in Germany). This is in line with previous studies where the authors found a mean of 12.6 hours of overwork per week for Ph.D. students in Science, Technology, Engineering, and Mathematics disciplines in Germany [<a href="#pone.0288103.ref045">45</a>]. However, the authors did not include any further work obligations and corrected for contract types with low percentages, and thus the results are difficult to compare directly. Furthermore, we used gender as a control variable, which turned out to be statistically significant for anxiety and stress. This is in line with related work where the female gender was reported to be higher correlated with mental disorders [<a href="#pone.0288103.ref002">2</a>,<a href="#pone.0288103.ref017">17</a>,<a href="#pone.0288103.ref046">46</a>,<a href="#pone.0288103.ref047">47</a>].</p>
</div>

<div id="section3"><h3>Strengths and limitations</h3>

<div id="section1"><h4>Generalization.</h4><p>While we aimed for our study to reflect the current situation for Ph.D. students as best as possible, there are points that are limiting the generalization of the results or are beyond the scope of this survey. First, we collected the data between October and December 2021, a time at which the ordinance on protection against risks of infection with the SARS-CoV-2 virus (“Coronavirus-Schutzverordnung”) [<a href="#pone.0288103.ref048">48</a>] was still in place in Germany and influenced private and working life. About one-third (33.5%) of our study population stated that it is very likely or likely that the pandemic affected their answers. Nonetheless, a pandemic is a situation that can reoccur and is only one more reason to proactively set up a resilient Ph.D. graduation system. Another research group [<a href="#pone.0288103.ref049">49</a>] investigated how mental health care should change as a consequence of the COVID-19 pandemic and concluded that the pandemic could even be seen as a chance to improve mental health services [<a href="#pone.0288103.ref049">49</a>]. Nevertheless, we would like to point out that generalizing from a mental health study conducted during a pandemic may be difficult.</p>
<p>Overall, around 23% of all Ph.D. students at the University of Tübingen [<a href="#pone.0288103.ref050">50</a>] participated in our study, which is slightly below the response rate in other similar studies [e.g., <a href="#pone.0288103.ref016">16</a>]. Considering that university students are very frequently invited to various questionnaires and studies, and given that our survey lasted approximately 20 minutes, it can be argued that the participants were motivated to invest time into their responses. However, our study population remains small compared to the total number of Ph.D. students in Germany. Moreover, we want to emphasize the likely sample bias in our data. We recruited participants mainly via mailing lists and our project therefore probably has especially appealed to people who are already interested in health or aware of mental health issues. However, given our relatively large coverage of almost a quarter of all Ph.D. students at the University of Tübingen, even a selective sample can give us insights into overall tendencies. The transferability of our results to other German universities or even universities in other countries is also not guaranteed as the academic systems can largely differ. Additionally, the results of this study are influenced by the overall living conditions the Ph.D. students experience. As Tübingen is a small town in the southwest of Germany, a comparison to larger cities or other countries might not be viable as the conditions probably differ largely.</p>
<p>Finally, even within one university, the generalization of our results is further limited by the uneven distribution of the participants across faculties. Most participants (61.8%) were from the Science Faculty, which is also the largest department (in terms of the highest total number of students) at the University of Tübingen. This skewness limits the faculty-wise comparisons, and we would expect to find interesting insights into the different graduate programs by conducting detailed comparisons. These differences could not only arise from different academic traditions but also from the highly varying expectations on the scope of a Ph.D. thesis. It follows that more detailed and systematic monitoring and data collection in national and international surveys are needed.</p>
</div>

<div id="section2"><h4>Methodology.</h4><p>In a cross-sectional study, we investigate the current situation of Ph.D. students. While this is a valid and important instrument to access the current state, it cannot give us information about the dynamic changes in the transition phase between undergraduate studies and the Ph.D. as well as across the Ph.D. [<a href="#pone.0288103.ref051">51</a>]. To track these changes or make comparisons over time, a longitudinal study design or propensity score matching procedures [<a href="#pone.0288103.ref052">52</a>] could give further insights. It is therefore desirable to establish regular surveys and monitoring systems either on a university level or in a national survey to provide information on the impact of undertaken actions and implemented changes. We used a mixed quantitative and qualitative research approach. While this provides information on distinct levels, there are some pitfalls. For example, the open answer categories were defined post-hoc. While this gives the possibility for the participants to express their thoughts freely, it makes a systematic analysis more difficult, and the analysis might be biased by the evaluators. Overall, it is important to summarize and statistically analyze our study results on an overall level, but it must not be forgotten that every person and Ph.D. project is individual.</p>
</div>
</div>

<div id="section4"><h3>Implications for research and practice</h3>

<div id="section1"><h4>Research.</h4><p>The overall scarce data, paired with worrisome flashlights on the mental health situation of Ph.D. students in different countries, highlights the need for more systematic monitoring of mental health in academia. For this purpose, standardized as well as domain-specific scales for Ph.D. students need to be established and longitudinal data needs to be collected. This would enable researchers to measure the effect of larger environmental changes (such as the COVID-19 pandemic or economic developments) and to measure the impact of interventions targeted to improve the situation. At the same time, we propose including qualitative measurements to assess unknown variables and the unique situation each Ph.D. student faces. These could also inform the development of additional quantitative measurable constructs to reflect the dynamic situation in academia. Such monitoring systems can either be implemented at the university level to give detailed insights into the situation at a specific university or on a national level to get an overall impression of Ph.D. students’ health issues. Optimally, a survey should be promoted from an independent self-governing institution dedicated to advancing science and research. While the demands for a better mental health situation for Ph.D. students are obvious, systematical and political changes need to be addressed in the research community and in academia.</p>
</div>

<div id="section2"><h4>Practice.</h4><p>Our mixed methods research approach allows us not only to find out more about the issues of Ph.D. students but also to draw conclusions about what is needed to improve their situation. However, finding solutions to a recognized problem is not a straightforward task, and complex problems often require a step-by-step solution. Therefore, we assume that more practical implications, which could be indicated by an established monitoring system, will be necessary once the first steps have been taken.</p>
<p>In general, we can group interventions into at least four levels that can influence each other: the Ph.D. students themselves, the supervisors, the universities or research institutions, and the greater political context and academic culture. Building on the responses about potential improvements and additional services, we identified the following practical implications:</p>
<p>On an individual level, the main interventions could happen in capacity building (e.g., in time/project management, self-reflection or mental health awareness) but also by being more proactive about changing working modes (e.g., establishing collaborations or a peer counseling system) or by improving the social environment. This could additionally lead to a change in self-perception, for which direct interventions might be more difficult. At this point, we want to highlight that changes on the individual level aim to prevent the development of mental health problems and strengthen the resilience of Ph.D. students. They can at no point replace professional support once such problems have been manifested.</p>
<p>The level of supervision seems to be the most urgent and promising target for an improvement of Ph.D. students’ situation. As supervisors are usually defining a project and its goals, but also additional teaching or other tasks, they are responsible for setting the workload and time constraints. Not only the hard constraints of the working conditions but also the quality of supervision was often mentioned to be highly deficient. Possible interventions could target improving the skills in personnel management of supervisors. But also, clear supervision requirements and guidelines could be imposed by the university. Such agreements (including expectations on the thesis, supervision times and conciliation mechanisms) might be an option to enhance the agreements in a supervisor-student relationship. While these suggestions are not new, and some of them are theoretically established in some university departments, our study results suggest that they are often ignored or not properly implemented, and more binding agreements and control mechanisms need to be made. Establishing additional external supervision, where for example the personnel management is reflected, might also give new perspectives and enhance demanding situations. At this point, it has to be considered that there are strong dependencies between Ph.D. students and their supervisors since, in many cases, it is the supervisors who have a major impact on the outcome of a Ph.D. thesis, such as the final grade. It remains challenging how Ph.D. students can criticize the supervising situation without negatively impacting the personal relationship with their supervisors.</p>
<p>Further interventions on the level of universities and research institutions might include support in bureaucratic processes and providing more information on different contact points (e.g., for mental health services). It is obvious that the aforementioned interventions (such as capacity building courses for Ph.D. students and supervisors) are dependent on the support of the central facilities of the research institution. Furthermore, highlighting the high prevalence of mental health problems, for example, at mandatory introductory sessions for Ph.D. students, might help to raise awareness about this topic. This could help unexperienced young researchers to notice signs of anxiety and depression early on before these mental disorders manifest. Finally, public events on this topic could reduce the stigma associated with it, making it easier for affected Ph.D. students to seek help. Such events might also be used to remind the students that it is important to take care not only of their physical but also mental health, for instance, by strengthening social relationships and pursuing hobbies which are not work-related.</p>
<p>Lastly, there are also changes in the political setting and academic culture needed. This includes a fair payment system, reasonable control of contract lengths and extensions, and more perspectives for long-term positions in academia. Considering that the vast majority of Ph.D. students will end up in positions outside of academia, it could be beneficial to better prepare students for careers in alternative job markets, such as industry. Such interventions might directly influence the job insecurity and job dissatisfaction of Ph.D. students. In Germany, the current regulations for temporary academic employment are being evaluated [<a href="#pone.0288103.ref053">53</a>], but even propositions from the conference of university rectors [<a href="#pone.0288103.ref054">54</a>] seem not to be sufficient for fundamental changes. These changes would also need a shift in the academic culture [<a href="#pone.0288103.ref055">55</a>], in which “publish or perish” is still a guiding theme leading to high pressure to perform. Working on a cultural shift is a task for all scientists. This will lead to a more sustainable work culture from which all stakeholders might benefit.</p>
<p>All in all, there is an interplay and dependence of all mentioned levels. Importantly, most problems mentioned in the survey can result from shortcomings on multiple levels, and therefore interventions on more than one level are needed for a satisfying solution. For example, changes to improve the mental health situation on an individual level can be dependent on the consent of the supervisor and can also be negatively impacted by already existing mental health issues. In addition to individual responsibility for health, it is important to systematically target prevention and change the system on the aforementioned levels so that Ph.D. students are better and more quickly supported when mental health problems arise.</p>
</div>
</div>
</div>

<div xmlns:plos="http://plos.org" id="section5"><h2>Conclusion</h2><p>This study shows once again the detrimental mental health situation of Ph.D. students in academia. By analyzing the mental health of Ph.D. students at a German university, we found alarming hints of depressive and anxious tendencies that are in line with other comparable studies. Furthermore, we have identified main stressors, such as perceived stress or self-doubts, and resources, such as a positive student-supervisor relationship. Understanding conditional factors and being able to improve the situation depend on such identifications. With our study, we provide first insights of the status quo for the University chair, the Graduate Academy, and other stakeholders in the academic system. We invite them to inspect the results and suggestions responsibly so that actions to assess and improve the conditions for Ph.D. students’ mental health and well-being can be taken in the future. Based on our data, additional offers for Ph.D. students, as well as their supervisors, should be created and existing ones sustainably modified. Positive conditions and resources for mental health and well-being will not restrict to academia but will affect all areas of life. While an increased mental health state is an indispensable value on its own, additional benefits can be created for research, teaching, practice, and society. As such, mental health is a big part of sustainable living and should have a high priority for all people. While this is already acknowledged in the sustainable development goals, further steps need to be taken to raise awareness and provide support throughout society.</p>
</div>

<div xmlns:plos="http://plos.org" id="section6"><h2>Supporting information</h2></div>





<div xmlns:plos="http://plos.org"><h2>Acknowledgments</h2>
<p>We would like to express our gratitude to all participants of the survey as well to the <em>sustainAbility</em> Ph.D. initiative at the University of Tübingen. We thank Dr. Stephanie Rosenstiel for support with the ethics approval and Prof. Dr. Birgit Derntl and Prof. Dr. Andreas Fallgatter for their helpful feedback on the conception of the questionnaire. We thank Mumina Javed and Monja Neuser for their support in the early phase of the project.</p>
</div><div xmlns:plos="http://plos.org"><h2>References</h2><ol><li id="ref1"><span>1.
            </span><a name="pone.0288103.ref001" id="pone.0288103.ref001"></a>World Health Organization, editor. Mental health: facing the challenges, building solutions: report from the WHO European Ministerial Conference. Copenhagen, Denmark: World Health Organization, Regional Office for Europe; 2005. <ul></ul></li><li id="ref2"><span>2.
            </span><a name="pone.0288103.ref002" id="pone.0288103.ref002"></a>Evans TM, Bira L, Gastelum JB, Weiss LT, Vanderford NL. Evidence for a mental health crisis in graduate education. Nat Biotechnol. 2018;36(3): 282284.  pmid:29509732 <ul data-doi="10.1038/nbt.4089"><li><a href="https://doi.org/10.1038/nbt.4089" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/29509732" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=Evidence+for+a+mental+health+crisis+in+graduate+education+Evans+2018" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref3"><span>3.
            </span><a name="pone.0288103.ref003" id="pone.0288103.ref003"></a>Satinsky EN, Kimura T, Kiang MV, Abebe R, Cunningham S, Lee H, et al. Systematic review and meta-analysis of depression, anxiety, and suicidal ideation among Ph.D. students. Sci Rep. 2021;11(1): 14370.  pmid:34257319 <ul data-doi="10.1038/s41598-021-93687-7"><li><a href="https://doi.org/10.1038/s41598-021-93687-7" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/34257319" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=Systematic+review+and+meta-analysis+of+depression%2C+anxiety%2C+and+suicidal+ideation+among+Ph.D.+students+Satinsky+2021" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref4"><span>4.
            </span><a name="pone.0288103.ref004" id="pone.0288103.ref004"></a>Baxter AJ, Scott KM, Vos T, Whiteford HA. Global prevalence of anxiety disorders: a systematic review and meta-regression. Psychol Med. 2013;43(5): 897–910.  pmid:22781489 <ul data-doi="10.1017/S003329171200147X"><li><a href="https://doi.org/10.1017/S003329171200147X" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/22781489" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=Global+prevalence+of+anxiety+disorders%3A+a+systematic+review+and+meta-regression+Baxter+2013" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref5"><span>5.
            </span><a name="pone.0288103.ref005" id="pone.0288103.ref005"></a>Ferrari AJ, Somerville AJ, Baxter AJ, Norman R, Patten SB, Vos T, et al. Global variation in the prevalence and incidence of major depressive disorder: a systematic review of the epidemiological literature. Psychol Med. 2013;43(3): 471–481.  pmid:22831756 <ul data-doi="10.1017/S0033291712001511"><li><a href="https://doi.org/10.1017/S0033291712001511" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/22831756" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=Global+variation+in+the+prevalence+and+incidence+of+major+depressive+disorder%3A+a+systematic+review+of+the+epidemiological+literature+Ferrari+2013" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref6"><span>6.
            </span><a name="pone.0288103.ref006" id="pone.0288103.ref006"></a>Byrom NC, Dinu L, Kirkman A, Hughes G. Predicting stress and mental wellbeing among doctoral researchers. Journal of Mental Health. 2020; 1–9.  pmid:32967498 <ul data-doi="10.1080/09638237.2020.1818196"><li><a href="https://doi.org/10.1080/09638237.2020.1818196" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/32967498" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=Predicting+stress+and+mental+wellbeing+among+doctoral+researchers+Byrom+2020" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref7"><span>7.
            </span><a name="pone.0288103.ref007" id="pone.0288103.ref007"></a>El-Ghoroury NH, Galper DI, Sawaqdeh A, Bufka LF. Stress, coping, and barriers to wellness among psychology graduate students. Training and Education in Professional Psychology. 2012;6(2): 122–134. <ul><li><a href="#" data-author="El-Ghoroury" data-cit="El-GhorouryNH%2C%20GalperDI%2C%20SawaqdehA%2C%20BufkaLF.%20Stress%2C%20coping%2C%20and%20barriers%20to%20wellness%20among%20psychology%20graduate%20students.%20Training%20and%20Education%20in%20Professional%20Psychology.%202012%3B6%282%29%3A%20122%E2%80%93134." data-title="Stress%2C%20coping%2C%20and%20barriers%20to%20wellness%20among%20psychology%20graduate%20students" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Stress%2C+coping%2C+and+barriers+to+wellness+among+psychology+graduate+students+El-Ghoroury+2012" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref8"><span>8.
            </span><a name="pone.0288103.ref008" id="pone.0288103.ref008"></a>Kowalczyk M, Karbownik MS, Kowalczyk E, Sienkiewicz M, Talarowska M. Mental Health of PhD Students at Polish Universities–Before the COVID-19 Outbreak. IJERPH. 2021;18(22): 12068.  pmid:34831821 <ul data-doi="10.3390/ijerph182212068"><li><a href="https://doi.org/10.3390/ijerph182212068" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/34831821" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=Mental+Health+of+PhD+Students+at+Polish+Universities%E2%80%93Before+the+COVID-19+Outbreak+Kowalczyk+2021" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref9"><span>9.
            </span><a name="pone.0288103.ref009" id="pone.0288103.ref009"></a>Smith E, Brooks Z. Graduate Student Mental Health (University of Arizona). National Association of Graduate-Professional Students [Internet]. 2015. Available from: <a href="http://nagps.org/wordpress/wp-content/uploads/2015/06/NAGPS_Institute_mental_health_survey_report_2015.pdf">http://nagps.org/wordpress/wp-content/uploads/2015/06/NAGPS_Institute_mental_health_survey_report_2015.pdf</a>. <ul><li><a href="#" data-author="Smith" data-cit="SmithE%2C%20BrooksZ.%20Graduate%20Student%20Mental%20Health%20%28University%20of%20Arizona%29.%20National%20Association%20of%20Graduate-Professional%20Students%20%5BInternet%5D.%202015.%20Available%20from%3A%20http%3A%2F%2Fnagps.org%2Fwordpress%2Fwp-content%2Fuploads%2F2015%2F06%2FNAGPS_Institute_mental_health_survey_report_2015.pdf." data-title="Graduate%20Student%20Mental%20Health%20%28University%20of%20Arizona%29" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Graduate+Student+Mental+Health+%28University+of+Arizona%29+Smith+2015" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref10"><span>10.
            </span><a name="pone.0288103.ref010" id="pone.0288103.ref010"></a>Williams S. 2019 Postgraduate Research Experience Survey [Internet]. 2019. Available from: <a href="https://s3.eu-west-2.amazonaws.com/assets.creode.advancehe-document-manager/documents/advance-he/AdvanceHE-Postgraduate_Research_%20Survey_%202019_1574338111.pdf">https://s3.eu-west-2.amazonaws.com/assets.creode.advancehe-document-manager/documents/advance-he/AdvanceHE-Postgraduate_Research_%20Survey_%202019_1574338111.pdf</a>. <ul></ul></li><li id="ref11"><span>11.
            </span><a name="pone.0288103.ref011" id="pone.0288103.ref011"></a>Majev PG, Vieira RM, Carollo A, Liu H, Stutz D, Fahrenwaldt A, et al. PhDnet Report 2020. 2021. <ul><li><a href="#" data-author="Majev" data-cit="MajevPG%2C%20VieiraRM%2C%20CarolloA%2C%20LiuH%2C%20StutzD%2C%20FahrenwaldtA%2C%20et%20al.%20PhDnet%20Report%202020.%202021." data-title="PhDnet%20Report%202020" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=PhDnet+Report+2020+Majev+2021" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref12"><span>12.
            </span><a name="pone.0288103.ref012" id="pone.0288103.ref012"></a>Olsthoorn LHM, Heckmann LA, Filippi A, Vieira RM, Varanasi RS, Lasser J, et al. PhDnet Report 2019. 2020. <ul><li><a href="#" data-author="Olsthoorn" data-cit="OlsthoornLHM%2C%20HeckmannLA%2C%20FilippiA%2C%20VieiraRM%2C%20VaranasiRS%2C%20LasserJ%2C%20et%20al.%20PhDnet%20Report%202019.%202020." data-title="PhDnet%20Report%202019" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=PhDnet+Report+2019+Olsthoorn+2020" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref13"><span>13.
            </span><a name="pone.0288103.ref013" id="pone.0288103.ref013"></a>Woolston C. Graduate survey: A love–hurt relationship. Nature. 2017;550(7677): 549–552. <ul><li><a href="#" data-author="Woolston" data-cit="WoolstonC.%20Graduate%20survey%3A%20A%20love%E2%80%93hurt%20relationship.%20Nature.%202017%3B550%287677%29%3A%20549%E2%80%93552." data-title="Graduate%20survey%3A%20A%20love%E2%80%93hurt%20relationship" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Graduate+survey%3A+A+love%E2%80%93hurt+relationship+Woolston+2017" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref14"><span>14.
            </span><a name="pone.0288103.ref014" id="pone.0288103.ref014"></a>Woolston C. PhDs: the tortuous truth. Nature. 2019;575(7782): 403–406.  pmid:31723297 <ul data-doi="10.1038/d41586-019-03459-7"><li><a href="https://doi.org/10.1038/d41586-019-03459-7" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/31723297" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=PhDs%3A+the+tortuous+truth+Woolston+2019" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref15"><span>15.
            </span><a name="pone.0288103.ref015" id="pone.0288103.ref015"></a>Marais GAB, Shankland R, Haag P, Fiault R, Juniper B. A Survey and a Positive Psychology Intervention on French PhD Student Well-being. IJDS. 2018;13: 109–138. <ul><li><a href="#" data-author="Marais" data-cit="MaraisGAB%2C%20ShanklandR%2C%20HaagP%2C%20FiaultR%2C%20JuniperB.%20A%20Survey%20and%20a%20Positive%20Psychology%20Intervention%20on%20French%20PhD%20Student%20Well-being.%20IJDS.%202018%3B13%3A%20109%E2%80%93138." data-title="A%20Survey%20and%20a%20Positive%20Psychology%20Intervention%20on%20French%20PhD%20Student%20Well-being" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=A+Survey+and+a+Positive+Psychology+Intervention+on+French+PhD+Student+Well-being+Marais+2018" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref16"><span>16.
            </span><a name="pone.0288103.ref016" id="pone.0288103.ref016"></a>Levecque K, Anseel F, De Beuckelaer A, Van der Heyden J, Gisle L. Work organization and mental health problems in PhD students. Research Policy. 2017;46(4): 868–879. <ul><li><a href="#" data-author="Levecque" data-cit="LevecqueK%2C%20AnseelF%2C%20De%20BeuckelaerA%2C%20Van%20der%20HeydenJ%2C%20GisleL.%20Work%20organization%20and%20mental%20health%20problems%20in%20PhD%20students.%20Research%20Policy.%202017%3B46%284%29%3A%20868%E2%80%93879." data-title="Work%20organization%20and%20mental%20health%20problems%20in%20PhD%20students" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Work+organization+and+mental+health+problems+in+PhD+students+Levecque+2017" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref17"><span>17.
            </span><a name="pone.0288103.ref017" id="pone.0288103.ref017"></a>Auerbach RP, Mortier P, Bruffaerts R, Alonso J, Benjet C, Cuijpers P, et al. WHO World Mental Health Surveys International College Student Project: Prevalence and distribution of mental disorders. Journal of Abnormal Psychology. 2018;127(7): 623638.  pmid:30211576 <ul data-doi="10.1037/abn0000362"><li><a href="https://doi.org/10.1037/abn0000362" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/30211576" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=WHO+World+Mental+Health+Surveys+International+College+Student+Project%3A+Prevalence+and+distribution+of+mental+disorders+Auerbach+2018" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref18"><span>18.
            </span><a name="pone.0288103.ref018" id="pone.0288103.ref018"></a>Sverdlik A, Hall NC. Not just a phase: Exploring the role of program stage on well-being and motivation in doctoral students. Journal of Adult and Continuing Education. 2020;26(1): 97–124. <ul><li><a href="#" data-author="Sverdlik" data-cit="SverdlikA%2C%20HallNC.%20Not%20just%20a%20phase%3A%20Exploring%20the%20role%20of%20program%20stage%20on%20well-being%20and%20motivation%20in%20doctoral%20students.%20Journal%20of%20Adult%20and%20Continuing%20Education.%202020%3B26%281%29%3A%2097%E2%80%93124." data-title="Not%20just%20a%20phase%3A%20Exploring%20the%20role%20of%20program%20stage%20on%20well-being%20and%20motivation%20in%20doctoral%20students" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Not+just+a+phase%3A+Exploring+the+role+of+program+stage+on+well-being+and+motivation+in+doctoral+students+Sverdlik+2020" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref19"><span>19.
            </span><a name="pone.0288103.ref019" id="pone.0288103.ref019"></a>The mental health of PhD researchers demands urgent attention. Nature. 2019;575(7782): 257–258.  pmid:31723298 <ul data-doi="10.1038/d41586-019-03489-1"><li><a href="https://doi.org/10.1038/d41586-019-03489-1" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/31723298" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=The+mental+health+of+PhD+researchers+demands+urgent+attention++2019" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref20"><span>20.
            </span><a name="pone.0288103.ref020" id="pone.0288103.ref020"></a>Mark G, Smith AP. Effects of occupational stress, job characteristics, coping, and attributional style on the mental health and job satisfaction of university employees. Anxiety, Stress &amp; Coping. 2012;25(1): 63–78.  pmid:21271408 <ul data-doi="10.1080/10615806.2010.548088"><li><a href="https://doi.org/10.1080/10615806.2010.548088" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/21271408" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=Effects+of+occupational+stress%2C+job+characteristics%2C+coping%2C+and+attributional+style+on+the+mental+health+and+job+satisfaction+of+university+employees+Mark+2012" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref21"><span>21.
            </span><a name="pone.0288103.ref021" id="pone.0288103.ref021"></a>Pyhältö K, Stubb J, Lonka K. Developing scholarly communities as learning environments for doctoral students. International Journal for Academic Development. 2009;14(3): 221–232. <ul><li><a href="#" data-author="Pyh%C3%A4lt%C3%B6" data-cit="Pyh%C3%A4lt%C3%B6K%2C%20StubbJ%2C%20LonkaK.%20Developing%20scholarly%20communities%20as%20learning%20environments%20for%20doctoral%20students.%20International%20Journal%20for%20Academic%20Development.%202009%3B14%283%29%3A%20221%E2%80%93232." data-title="Developing%20scholarly%20communities%20as%20learning%20environments%20for%20doctoral%20students" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Developing+scholarly+communities+as+learning+environments+for+doctoral+students+Pyh%C3%A4lt%C3%B6+2009" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref22"><span>22.
            </span><a name="pone.0288103.ref022" id="pone.0288103.ref022"></a>Urbanaviciute I, Christina Roll L, Tomas J, Witte H. Proactive strategies for countering the detrimental outcomes of qualitative job insecurity in academia. Stress and Health. 2021;37(3): 557571.  pmid:33377270 <ul data-doi="10.1002/smi.3023"><li><a href="https://doi.org/10.1002/smi.3023" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/33377270" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=Proactive+strategies+for+countering+the+detrimental+outcomes+of+qualitative+job+insecurity+in+academia+Urbanaviciute+2021" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref23"><span>23.
            </span><a name="pone.0288103.ref023" id="pone.0288103.ref023"></a>Dadaczynski K, Okan O, Messer M, Rathmann K. University students’ sense of coherence, future worries and mental health: findings from the German COVID-HL-survey. Health Promotion International. 2022;37(1): daab070.  pmid:34214156 <ul data-doi="10.1093/heapro/daab070"><li><a href="https://doi.org/10.1093/heapro/daab070" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/34214156" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=University+students%E2%80%99+sense+of+coherence%2C+future+worries+and+mental+health%3A+findings+from+the+German+COVID-HL-survey+Dadaczynski+2022" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref24"><span>24.
            </span><a name="pone.0288103.ref024" id="pone.0288103.ref024"></a>Nicholls H, Nicholls M, Tekin S, Lamb D, Billings J. The impact of working in academia on researchers’ mental health and well-being: A systematic review and qualitative meta-synthesis. Serraino GF, editor. PLoS ONE. 2022;17(5): e0268890.  pmid:35613147 <ul data-doi="10.1371/journal.pone.0268890"><li><a href="https://doi.org/10.1371/journal.pone.0268890" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/35613147" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=The+impact+of+working+in+academia+on+researchers%E2%80%99+mental+health+and+well-being%3A+A+systematic+review+and+qualitative+meta-synthesis+Nicholls+2022" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref25"><span>25.
            </span><a name="pone.0288103.ref025" id="pone.0288103.ref025"></a>Mackie SA, Bates GW. Contribution of the doctoral education environment to PhD candidates’ mental health problems: a scoping review. Higher Education Research &amp; Development. 2019;38(3): 565–578. <ul><li><a href="#" data-author="Mackie" data-cit="MackieSA%2C%20BatesGW.%20Contribution%20of%20the%20doctoral%20education%20environment%20to%20PhD%20candidates%E2%80%99%20mental%20health%20problems%3A%20a%20scoping%20review.%20Higher%20Education%20Research%20%26%20Development.%202019%3B38%283%29%3A%20565%E2%80%93578." data-title="Contribution%20of%20the%20doctoral%20education%20environment%20to%20PhD%20candidates%E2%80%99%20mental%20health%20problems%3A%20a%20scoping%20review" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Contribution+of+the+doctoral+education+environment+to+PhD+candidates%E2%80%99+mental+health+problems%3A+a+scoping+review+Mackie+2019" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref26"><span>26.
            </span><a name="pone.0288103.ref026" id="pone.0288103.ref026"></a>Kroenke K, Spitzer RL, Williams JBW. The Patient Health Questionnaire-2: Validity of a Two-Item Depression Screener. Medical Care. 2003;41(11): 1284–1292.  pmid:14583691 <ul data-doi="10.1097/01.MLR.0000093487.78664.3C"><li><a href="https://doi.org/10.1097/01.MLR.0000093487.78664.3C" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/14583691" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=The+Patient+Health+Questionnaire-2%3A+Validity+of+a+Two-Item+Depression+Screener+Kroenke+2003" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref27"><span>27.
            </span><a name="pone.0288103.ref027" id="pone.0288103.ref027"></a>Spitzer RL, Kroenke K, Williams JBW, Löwe B. A Brief Measure for Assessing Generalized Anxiety Disorder: The GAD-7. Arch Intern Med. 2006;166(10): 1092.  pmid:16717171 <ul data-doi="10.1001/archinte.166.10.1092"><li><a href="https://doi.org/10.1001/archinte.166.10.1092" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/16717171" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=A+Brief+Measure+for+Assessing+Generalized+Anxiety+Disorder%3A+The+GAD-7+Spitzer+2006" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref28"><span>28.
            </span><a name="pone.0288103.ref028" id="pone.0288103.ref028"></a>Bach M. Substance use for neuroenhancement or coping with stress: An epidemiological study on university students and clients of a University counseling service in Germany [Internet]. RWTH Aachen; 2016. Available from: <a href="http://publications.rwth-aachen.de/record/679004/files/679004.pdf">http://publications.rwth-aachen.de/record/679004/files/679004.pdf</a>. <ul><li><a href="#" data-author="Bach" data-cit="BachM.%20Substance%20use%20for%20neuroenhancement%20or%20coping%20with%20stress%3A%20An%20epidemiological%20study%20on%20university%20students%20and%20clients%20of%20a%20University%20counseling%20service%20in%20Germany%20%5BInternet%5D.%20RWTH%20Aachen%3B%202016.%20Available%20from%3A%20http%3A%2F%2Fpublications.rwth-aachen.de%2Frecord%2F679004%2Ffiles%2F679004.pdf." data-title="Substance%20use%20for%20neuroenhancement%20or%20coping%20with%20stress%3A%20An%20epidemiological%20study%20on%20university%20students%20and%20clients%20of%20a%20University%20counseling%20service%20in%20Germany" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Substance+use+for+neuroenhancement+or+coping+with+stress%3A+An+epidemiological+study+on+university+students+and+clients+of+a+University+counseling+service+in+Germany+Bach+2016" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref29"><span>29.
            </span><a name="pone.0288103.ref029" id="pone.0288103.ref029"></a>Cohen S, Kamarck T, Mermelstein R. A Global Measure of Perceived Stress. Journal of Health and Social Behavior. 1983;24(4): 385–396. pmid:6668417 <ul><li><a href="#" data-author="Cohen" data-cit="CohenS%2C%20KamarckT%2C%20MermelsteinR.%20A%20Global%20Measure%20of%20Perceived%20Stress.%20Journal%20of%20Health%20and%20Social%20Behavior.%201983%3B24%284%29%3A%20385%E2%80%93396.%206668417" data-title="A%20Global%20Measure%20of%20Perceived%20Stress" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/6668417" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=A+Global+Measure+of+Perceived+Stress+Cohen+1983" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref30"><span>30.
            </span><a name="pone.0288103.ref030" id="pone.0288103.ref030"></a>Büssing A. Translation of Cohen’s 10 Item Perceived Stress Scale (PSS). University of Witten/Herdecke; 2011. <ul></ul></li><li id="ref31"><span>31.
            </span><a name="pone.0288103.ref031" id="pone.0288103.ref031"></a>Hellgren J, Sjöberg A, Sverke M. Intention to quit: Effects of job satisfaction and job perceptions. In: Avallone F, Arnold J, de Witte K, editors. Feelings work in Europe. Milano: Guerini; 1997. pp. 415–423. <ul><li><a href="#" data-author="Hellgren" data-cit="HellgrenJ%2C%20Sj%C3%B6bergA%2C%20SverkeM.%20Intention%20to%20quit%3A%20Effects%20of%20job%20satisfaction%20and%20job%20perceptions.%20In%3A%20AvalloneF%2C%20ArnoldJ%2C%20de%20WitteK%2C%20editors.%20Feelings%20work%20in%20Europe.%20Milano%3A%20Guerini%3B%201997.%20pp.%20415%E2%80%93423." data-title="Intention%20to%20quit%3A%20Effects%20of%20job%20satisfaction%20and%20job%20perceptions" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Intention+to+quit%3A+Effects+of+job+satisfaction+and+job+perceptions+Hellgren+1997" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref32"><span>32.
            </span><a name="pone.0288103.ref032" id="pone.0288103.ref032"></a>Ahrendt D, Anderson R, Dubois H, Jungblut JM, Leončikas T, Pöntinen L, et al. European quality of live survey 2016: quality of life, quality of public services, and quality of society. Luxembourg: Publications Office of the European Union; 2017. <ul></ul></li><li id="ref33"><span>33.
            </span><a name="pone.0288103.ref033" id="pone.0288103.ref033"></a>Hellgren J, Sverke M, Isaksson K. A Two-dimensional Approach to Job Insecurity: Consequences for Employee Attitudes and Well-being. European Journal of Work and Organizational Psychology. 1999;8(2): 179–195. <ul><li><a href="#" data-author="Hellgren" data-cit="HellgrenJ%2C%20SverkeM%2C%20IsakssonK.%20A%20Two-dimensional%20Approach%20to%20Job%20Insecurity%3A%20Consequences%20for%20Employee%20Attitudes%20and%20Well-being.%20European%20Journal%20of%20Work%20and%20Organizational%20Psychology.%201999%3B8%282%29%3A%20179%E2%80%93195." data-title="A%20Two-dimensional%20Approach%20to%20Job%20Insecurity%3A%20Consequences%20for%20Employee%20Attitudes%20and%20Well-being" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=A+Two-dimensional+Approach+to+Job+Insecurity%3A+Consequences+for+Employee+Attitudes+and+Well-being+Hellgren+1999" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref34"><span>34.
            </span><a name="pone.0288103.ref034" id="pone.0288103.ref034"></a>Mayring P. Qualitative Inhaltsanalyse: Grundlagen und Techniken. 13., überarbeitete Auflage. Weinheim Basel: Beltz; 2022. <ul></ul></li><li id="ref35"><span>35.
            </span><a name="pone.0288103.ref035" id="pone.0288103.ref035"></a>Hayes AF, Krippendorff K. Answering the Call for a Standard Reliability Measure for Coding Data. Communication Methods and Measures. 2007;1(1): 77–89. <ul><li><a href="#" data-author="Hayes" data-cit="HayesAF%2C%20KrippendorffK.%20Answering%20the%20Call%20for%20a%20Standard%20Reliability%20Measure%20for%20Coding%20Data.%20Communication%20Methods%20and%20Measures.%202007%3B1%281%29%3A%2077%E2%80%9389." data-title="Answering%20the%20Call%20for%20a%20Standard%20Reliability%20Measure%20for%20Coding%20Data" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Answering+the+Call+for+a+Standard+Reliability+Measure+for+Coding+Data+Hayes+2007" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref36"><span>36.
            </span><a name="pone.0288103.ref036" id="pone.0288103.ref036"></a>Warttig SL, Forshaw MJ, South J, White AK. New, normative, English-sample data for the Short Form Perceived Stress Scale (PSS-4). J Health Psychol. 2013;18(12): 1617–1628.  pmid:24155195 <ul data-doi="10.1177/1359105313508346"><li><a href="https://doi.org/10.1177/1359105313508346" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/24155195" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=New%2C+normative%2C+English-sample+data+for+the+Short+Form+Perceived+Stress+Scale+%28PSS-4%29+Warttig+2013" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref37"><span>37.
            </span><a name="pone.0288103.ref037" id="pone.0288103.ref037"></a>Klein EM, Brähler E, Dreier M, Reinecke L, Müller KW, Schmutzer G, et al. The German version of the Perceived Stress Scale–psychometric characteristics in a representative German community sample. BMC Psychiatry. 2016;16(1): 1–10. <ul><li><a href="#" data-author="Klein" data-cit="KleinEM%2C%20Br%C3%A4hlerE%2C%20DreierM%2C%20ReineckeL%2C%20M%C3%BCllerKW%2C%20SchmutzerG%2C%20et%20al.%20The%20German%20version%20of%20the%20Perceived%20Stress%20Scale%E2%80%93psychometric%20characteristics%20in%20a%20representative%20German%20community%20sample.%20BMC%20Psychiatry.%202016%3B16%281%29%3A%201%E2%80%9310." data-title="The%20German%20version%20of%20the%20Perceived%20Stress%20Scale%E2%80%93psychometric%20characteristics%20in%20a%20representative%20German%20community%20sample" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=The+German+version+of+the+Perceived+Stress+Scale%E2%80%93psychometric+characteristics+in+a+representative+German+community+sample+Klein+2016" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref38"><span>38.
            </span><a name="pone.0288103.ref038" id="pone.0288103.ref038"></a>Friedrich J, Münch AK, Thiel A, Voelter-Mahlknecht S, Sudeck G. Occupational Health Literacy Scale (OHLS): development and validation of a domain-specific measuring instrument. Health Promotion International. 2023;38(1): daac182.  pmid:36738454 <ul data-doi="10.1093/heapro/daac182"><li><a href="https://doi.org/10.1093/heapro/daac182" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/36738454" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=Occupational+Health+Literacy+Scale+%28OHLS%29%3A+development+and+validation+of+a+domain-specific+measuring+instrument+Friedrich+2023" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref39"><span>39.
            </span><a name="pone.0288103.ref039" id="pone.0288103.ref039"></a>Levecque K, De Beuckelaer A, Van Overbeke K, Mortier A. How satisfied are PhD students with their job? A focus on Flanders. ECCOM-brief. 2019;18: 1–5. <ul><li><a href="#" data-author="Levecque" data-cit="LevecqueK%2C%20De%20BeuckelaerA%2C%20Van%20OverbekeK%2C%20MortierA.%20How%20satisfied%20are%20PhD%20students%20with%20their%20job%3F%20A%20focus%20on%20Flanders.%20ECCOM-brief.%202019%3B18%3A%201%E2%80%935." data-title="How%20satisfied%20are%20PhD%20students%20with%20their%20job%3F%20A%20focus%20on%20Flanders" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=How+satisfied+are+PhD+students+with+their+job%3F+A+focus+on+Flanders+Levecque+2019" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref40"><span>40.
            </span><a name="pone.0288103.ref040" id="pone.0288103.ref040"></a>Krippendorff K. Content Analysis: An Introduction to Its Methodology [Internet]. SAGE Publications; 2019 [cited 2023 Jun 6]. Available from: <a href="https://methods.sagepub.com/book/content-analysis-4e">https://methods.sagepub.com/book/content-analysis-4e</a>. <ul></ul></li><li id="ref41"><span>41.
            </span><a name="pone.0288103.ref041" id="pone.0288103.ref041"></a>Skoda EM, Spura A, De Bock F, Schweda A, Dörrie N, Fink M, et al. Veränderung der psychischen Belastung in der COVID-19-Pandemie in Deutschland: Ängste, individuelles Verhalten und die Relevanz von Information sowie Vertrauen in Behörden. Bundesgesundheitsbl. 2021r;64(3): 322–333. <ul><li><a href="#" data-author="Skoda" data-cit="SkodaEM%2C%20SpuraA%2C%20De%20BockF%2C%20SchwedaA%2C%20D%C3%B6rrieN%2C%20FinkM%2C%20et%20al.%20Ver%C3%A4nderung%20der%20psychischen%20Belastung%20in%20der%20COVID-19-Pandemie%20in%20Deutschland%3A%20%C3%84ngste%2C%20individuelles%20Verhalten%20und%20die%20Relevanz%20von%20Information%20sowie%20Vertrauen%20in%20Beh%C3%B6rden.%20Bundesgesundheitsbl.%202021r%3B64%283%29%3A%20322%E2%80%93333." data-title="Ver%C3%A4nderung%20der%20psychischen%20Belastung%20in%20der%20COVID-19-Pandemie%20in%20Deutschland%3A%20%C3%84ngste%2C%20individuelles%20Verhalten%20und%20die%20Relevanz%20von%20Information%20sowie%20Vertrauen%20in%20Beh%C3%B6rden" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Ver%C3%A4nderung+der+psychischen+Belastung+in+der+COVID-19-Pandemie+in+Deutschland%3A+%C3%84ngste%2C+individuelles+Verhalten+und+die+Relevanz+von+Information+sowie+Vertrauen+in+Beh%C3%B6rden+Skoda+2021" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref42"><span>42.
            </span><a name="pone.0288103.ref042" id="pone.0288103.ref042"></a>Bäuerle A, Steinbach J, Schweda A, Beckord J, Hetkamp M, Weismüller B, et al. Mental Health Burden of the COVID-19 Outbreak in Germany: Predictors of Mental Health Impairment. J Prim Care Community Health. 2020 Jan;11: 1–8.  pmid:32865107 <ul data-doi="10.1177/2150132720953682"><li><a href="https://doi.org/10.1177/2150132720953682" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/32865107" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=Mental+Health+Burden+of+the+COVID-19+Outbreak+in+Germany%3A+Predictors+of+Mental+Health+Impairment+B%C3%A4uerle+2020" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref43"><span>43.
            </span><a name="pone.0288103.ref043" id="pone.0288103.ref043"></a>Chrikov I, Soria KM, Horgos B, Jones-White D. Undergraduate and graduate students’ mental health during the COVID-19 pandemic. [Internet]. University of California—Berkeley and University of Minnesota: SERU Consortium; 2020. Available from: <a href="https://hdl.handle.net/11299/215271">https://hdl.handle.net/11299/215271</a>. <ul><li><a href="#" data-author="Chrikov" data-cit="ChrikovI%2C%20SoriaKM%2C%20HorgosB%2C%20Jones-WhiteD.%20Undergraduate%20and%20graduate%20students%E2%80%99%20mental%20health%20during%20the%20COVID-19%20pandemic.%20%5BInternet%5D.%20University%20of%20California%E2%80%94Berkeley%20and%20University%20of%20Minnesota%3A%20SERU%20Consortium%3B%202020.%20Available%20from%3A%20https%3A%2F%2Fhdl.handle.net%2F11299%2F215271." data-title="Undergraduate%20and%20graduate%20students%E2%80%99%20mental%20health%20during%20the%20COVID-19%20pandemic" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Undergraduate+and+graduate+students%E2%80%99+mental+health+during+the+COVID-19+pandemic+Chrikov+2020" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref44"><span>44.
            </span><a name="pone.0288103.ref044" id="pone.0288103.ref044"></a>Federal Statistical Office. Qualität der Arbeit: Wöchentliche Arbeitszeit [Internet]. Wiesbaden: Statistisches Bundesamt; 2021. Available from: <a href="https://www.destatis.de/DE/Themen/Arbeit/Arbeitsmarkt/Qualitaet-Arbeit/Dimension-3/woechentliche-arbeitszeitl.html">https://www.destatis.de/DE/Themen/Arbeit/Arbeitsmarkt/Qualitaet-Arbeit/Dimension-3/woechentliche-arbeitszeitl.html</a>. <ul></ul></li><li id="ref45"><span>45.
            </span><a name="pone.0288103.ref045" id="pone.0288103.ref045"></a>Frei I, Grund C. Antecedents of overtime work: The case of junior academics. German Journal of Human Resource Management. 2020;34(4): 371–397. <ul><li><a href="#" data-author="Frei" data-cit="FreiI%2C%20GrundC.%20Antecedents%20of%20overtime%20work%3A%20The%20case%20of%20junior%20academics.%20German%20Journal%20of%20Human%20Resource%20Management.%202020%3B34%284%29%3A%20371%E2%80%93397." data-title="Antecedents%20of%20overtime%20work%3A%20The%20case%20of%20junior%20academics" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Antecedents+of+overtime+work%3A+The+case+of+junior+academics+Frei+2020" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref46"><span>46.
            </span><a name="pone.0288103.ref046" id="pone.0288103.ref046"></a>Mauvais-Jarvis F, Bairey Merz N, Barnes PJ, Brinton RD, Carrero JJ, DeMeo DL, et al. Sex and gender: modifiers of health, disease, and medicine. The Lancet. 2020;396(10250): 565–582.  pmid:32828189 <ul data-doi="10.1016/S0140-6736(20)31561-0"><li><a href="https://doi.org/10.1016/S0140-6736(20)31561-0" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/32828189" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=Sex+and+gender%3A+modifiers+of+health%2C+disease%2C+and+medicine+Mauvais-Jarvis+2020" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref47"><span>47.
            </span><a name="pone.0288103.ref047" id="pone.0288103.ref047"></a>Prowse R, Sherratt F, Abizaid A, Gabrys RL, Hellemans KGC, Patterson ZR, et al. Coping With the COVID-19 Pandemic: Examining Gender Differences in Stress and Mental Health Among University Students. Front Psychiatry. 2021;12: 650759.  pmid:33897499 <ul data-doi="10.3389/fpsyt.2021.650759"><li><a href="https://doi.org/10.3389/fpsyt.2021.650759" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/33897499" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=Coping+With+the+COVID-19+Pandemic%3A+Examining+Gender+Differences+in+Stress+and+Mental+Health+Among+University+Students+Prowse+2021" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref48"><span>48.
            </span><a name="pone.0288103.ref048" id="pone.0288103.ref048"></a>Federal Ministry of Health. Ordinance on protection against infection risks related to entry to Germany with regard to novel mutations of the SARS-CoV-2 coronavirus subsequent to the determination of an epidemic situation of national significance by the German Bundestag (Coronavirus-Schutzverordnung–CoronaSchV) [Internet]. Berlin: Federal Ministry of Health; 2021. Available from: <a href="https://www.bundesgesundheitsministerium.de/fileadmin/Dateien/3_Downloads/C/Coronavirus/Verordnungen/EN_Corona-Schutzverordnung_konsolidierte_Reinfassung_BAnz_bf.pdf">https://www.bundesgesundheitsministerium.de/fileadmin/Dateien/3_Downloads/C/Coronavirus/Verordnungen/EN_Corona-Schutzverordnung_konsolidierte_Reinfassung_BAnz_bf.pdf</a>. <ul></ul></li><li id="ref49"><span>49.
            </span><a name="pone.0288103.ref049" id="pone.0288103.ref049"></a>Moreno C, Wykes T, Galderisi S, Nordentoft M, Crossley N, Jones N, et al. How mental health care should change as a consequence of the COVID-19 pandemic. The Lancet Psychiatry. 2020;7(9): 813–824.  pmid:32682460 <ul data-doi="10.1016/S2215-0366(20)30307-2"><li><a href="https://doi.org/10.1016/S2215-0366(20)30307-2" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/32682460" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=How+mental+health+care+should+change+as+a+consequence+of+the+COVID-19+pandemic+Moreno+2020" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref50"><span>50.
            </span><a name="pone.0288103.ref050" id="pone.0288103.ref050"></a>Eberhard Karls Universität Tübingen. Studierendenstatistik Wintersemester 2021/2022 [Internet]. Tübingen: Eberhard Karls Universität; 2021. Available from: <a href="https://uni-tuebingen.de/securedl/sdl-eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpYXQiOjE2NzI4MzQ4NTgsImV4cCI6MTY3MjkyNDg0OCwidXNlciI6MCwiZ3JvdXBzIjpbMCwtMV0sImZpbGUiOiJmaWxlYWRtaW5cL1VuaV9UdWViaW5nZW5cL0RlemVybmF0ZVwvRGV6ZXJuYXRfSUlcL3N0dWRlbnRlbnN0YXRpc3Rpa2VuXC9zdGF0aXN0aWstd3MtMjAyMTIwMjIucGRmIiwicGFnZSI6NTk3fQ.4gH9ESxTCgdSWpi0dMxRLnZPB_xrL4MVm46k8wtB3IY/statistik-ws-20212022.pdf">https://uni-tuebingen.de/securedl/sdl-eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpYXQiOjE2NzI4MzQ4NTgsImV4cCI6MTY3MjkyNDg0OCwidXNlciI6MCwiZ3JvdXBzIjpbMCwtMV0sImZpbGUiOiJmaWxlYWRtaW5cL1VuaV9UdWViaW5nZW5cL0RlemVybmF0ZVwvRGV6ZXJuYXRfSUlcL3N0dWRlbnRlbnN0YXRpc3Rpa2VuXC9zdGF0aXN0aWstd3MtMjAyMTIwMjIucGRmIiwicGFnZSI6NTk3fQ.4gH9ESxTCgdSWpi0dMxRLnZPB_xrL4MVm46k8wtB3IY/statistik-ws-20212022.pdf</a>. <ul></ul></li><li id="ref51"><span>51.
            </span><a name="pone.0288103.ref051" id="pone.0288103.ref051"></a>Scarf D, Winter T, Riordan B, Hunter J, Tustin K, Gollop M, et al. A longitudinal study of mental wellbeing in students that transition into PhD study. PsyArXiv [Preprint]. 2021 [cited 2023 Jun 6]. Available from: <a href="https://osf.io/eq6xg">https://osf.io/eq6xg</a>. <ul><li><a href="#" data-author="Scarf" data-cit="ScarfD%2C%20WinterT%2C%20RiordanB%2C%20HunterJ%2C%20TustinK%2C%20GollopM%2C%20et%20al.%20A%20longitudinal%20study%20of%20mental%20wellbeing%20in%20students%20that%20transition%20into%20PhD%20study.%20PsyArXiv%20%5BPreprint%5D.%202021%20%5Bcited%202023%20Jun%206%5D.%20Available%20from%3A%20https%3A%2F%2Fosf.io%2Feq6xg." data-title="A%20longitudinal%20study%20of%20mental%20wellbeing%20in%20students%20that%20transition%20into%20PhD%20study" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=A+longitudinal+study+of+mental+wellbeing+in+students+that+transition+into+PhD+study+Scarf+2021" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref52"><span>52.
            </span><a name="pone.0288103.ref052" id="pone.0288103.ref052"></a>Rosenbaum PR, Rubin DB. The central role of the propensity score in observational studies for causal effects. Biometrika. 1983;70(1): 41–55. <ul><li><a href="#" data-author="Rosenbaum" data-cit="RosenbaumPR%2C%20RubinDB.%20The%20central%20role%20of%20the%20propensity%20score%20in%20observational%20studies%20for%20causal%20effects.%20Biometrika.%201983%3B70%281%29%3A%2041%E2%80%9355." data-title="The%20central%20role%20of%20the%20propensity%20score%20in%20observational%20studies%20for%20causal%20effects" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=The+central+role+of+the+propensity+score+in+observational+studies+for+causal+effects+Rosenbaum+1983" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref53"><span>53.
            </span><a name="pone.0288103.ref053" id="pone.0288103.ref053"></a>Sommer J, Jongmanns G, Book A, Rennert C. Evaluation des novellierten Wissenschaftszeitvertragsgesetzes [Internet]. Hannover: HIS-Institut für Hochschulentwicklung e. V.; 2022. Available from: <a href="https://www.bmbf.de/SharedDocs/Downloads/de/2022/abschlussbericht-evaluation-wisszeitvg.pdf?__blob=publicationFile&amp;v=2">https://www.bmbf.de/SharedDocs/Downloads/de/2022/abschlussbericht-evaluation-wisszeitvg.pdf?__blob=publicationFile&amp;v=2</a>. <ul><li><a href="#" data-author="Sommer" data-cit="SommerJ%2C%20JongmannsG%2C%20BookA%2C%20RennertC.%20Evaluation%20des%20novellierten%20Wissenschaftszeitvertragsgesetzes%20%5BInternet%5D.%20Hannover%3A%20HIS-Institut%20f%C3%BCr%20Hochschulentwicklung%20e.%20V.%3B%202022.%20Available%20from%3A%20https%3A%2F%2Fwww.bmbf.de%2FSharedDocs%2FDownloads%2Fde%2F2022%2Fabschlussbericht-evaluation-wisszeitvg.pdf%3F__blob%3DpublicationFile%26v%3D2." data-title="Evaluation%20des%20novellierten%20Wissenschaftszeitvertragsgesetzes" target="_new" title="Go to article in CrossRef">
                      View Article
                    </a></li><li><a href="http://scholar.google.com/scholar?q=Evaluation+des+novellierten+Wissenschaftszeitvertragsgesetzes+Sommer+2022" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li><li id="ref54"><span>54.
            </span><a name="pone.0288103.ref054" id="pone.0288103.ref054"></a>Hochschulrektorenkonferenz. Diskussionsvorschlag der Mitgliedergruppe Universitäten der Hochschulrektorenkonferenz zur Weiterentwicklung des Wissenschaftszeitvertragsgesetzes (Berlin, 06.07.2022) [Internet]. Bonn: Stiftung zur Förderung der Hochschulrektorenkonferenz; 2022. Available from: <a href="https://www.hrk.de/fileadmin/redaktion/hrk/02-Dokumente/02-01-Beschluesse/20220706_MGU_WissZeitVG_Diskussionsvorschlag.pdf">https://www.hrk.de/fileadmin/redaktion/hrk/02-Dokumente/02-01-Beschluesse/20220706_MGU_WissZeitVG_Diskussionsvorschlag.pdf</a>. <ul></ul></li><li id="ref55"><span>55.
            </span><a name="pone.0288103.ref055" id="pone.0288103.ref055"></a>Hall S. A mental-health crisis is gripping science–toxic research culture is to blame. Nature. 2023;617(7962): 666–668.  pmid:37221336 <ul data-doi="10.1038/d41586-023-01708-4"><li><a href="https://doi.org/10.1038/d41586-023-01708-4" data-author="doi-provided" data-cit="doi-provided" data-title="doi-provided" target="_new" title="Go to article">
                      View Article
                    </a></li><li><a href="http://www.ncbi.nlm.nih.gov/pubmed/37221336" target="_new" title="Go to article in PubMed">
                        PubMed/NCBI
                      </a></li><li><a href="http://scholar.google.com/scholar?q=A+mental-health+crisis+is+gripping+science%E2%80%93toxic+research+culture+is+to+blame+Hall+2023" target="_new" title="Go to article in Google Scholar">
                      Google Scholar
                    </a></li></ul></li></ol></div>



          

        </div>
      </div>
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Iridescent crystal with raymarching and signed distance fields (103 pts)]]></title>
            <link>https://varun.ca/ray-march-sdf/</link>
            <guid>36591767</guid>
            <pubDate>Tue, 04 Jul 2023 19:52:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://varun.ca/ray-march-sdf/">https://varun.ca/ray-march-sdf/</a>, See on <a href="https://news.ycombinator.com/item?id=36591767">Hacker News</a></p>
<div id="readability-page-1" class="page"><div tabindex="-1" id="___gatsby"><nav></nav><article><header><time datetime="2023-06-03T00:00:00.000Z" color="neutral.2" font-size="1" font-family="systemSans">3rd June, 2023</time></header><p font-family="systemSans" color="neutral.0" font-size="2,3">When building a 3D scene using libraries such as Three.js we generally use meshes. You define a geometry attach some material to it to create a mesh. Then add that mesh to the scene to render it. This is also how 3D modelling software like Blender and Cinema4D work. However, in the demoscene world—where the goal of is to create stuff using extremely small and self-contained computer programs—this approach didn’t work. They’d have to package a 3D library or engine along with the demo code which takes up a lot of memory. So, those folks came up with a pretty innovative approach. They used signed distance fields (SDFs) to define the geometry and then use raymarching to render the scene. The whole thing runs in a single shader program.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">If you’ve ever come across demos on <a href="https://www.shadertoy.com/" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">Shadertoy</a> or <a href="http://glslsandbox.com/" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">GLSL Sandbox</a>, you’ve seen this approach in action. While the initial goal was a small file size, it also allows you to create some <a href="https://www.shadertoy.com/user/tdhooper/sort=popular&amp;from=0&amp;num=8" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">really cool effects</a> and use boolean operations to create complex shapes. In this article, I’ll show you how to create an iridescent crystal using raymarching and SDFs.</p><p font-size="2" color="neutral.1" font-family="systemSans">ℹ️ This post assumes foundational knowledge of shaders. If you're not familiar with shaders or the GLSL API, check out:<!-- --> <a href="https://typefully.com/DanHollick/gpnhhud" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">Dan Hollick's twitter thread</a> <!-- -->for a brief overview,<!-- --> <a href="https://youtu.be/f4s1h2YETNY" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">kishimisu's intro tutorial</a> that breaks down basic GLSL concepts, or<!-- --> <a href="https://blog.maximeheckel.com/posts/the-study-of-shaders-with-react-three-fiber/" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">Maxime Heckel's tutorial</a> <!-- -->on shaders with React Three Fiber.</p><h2 id="ray-marching" font-family="systemSans" color="neutral.0" font-size="4,5" font-weight="7"><a href="#ray-marching" aria-label="ray marching permalink" color="brand.main" font-family="systemSans"></a>Ray Marching</h2><p font-family="systemSans" color="neutral.0" font-size="2,3">Ray Marching is a rendering technique that involves sending rays into a scene and checking for collisions with objects. Here’s how it works:</p><p font-family="systemSans" color="neutral.0" font-size="2,3">First, we select a position for the camera. Then, we send rays from the camera to each pixel in the output image. Along each ray, we step bit by bit, checking if there is a collision with an object in the scene. If a collision occurs, we’re done! If not, we continue stepping along the ray up to a maximum number of steps.</p><figure><img src="https://varun.ca/static/ray-march-41bd80ce90cdf1dde6084381abf07d6f.svg" alt="" width="100%,75%,50%" display="block"><figcaption font-size="1" font-family="systemSans" color="neutral.0"><a href="https://en.wikipedia.org/wiki/Ray_tracing_(graphics)" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">from "Ray tracing" on Wikipedia</a></figcaption></figure><p font-family="systemSans" color="neutral.0" font-size="2,3">The other important distinction is that we’re not using vertices &amp; triangles to define the geometry. If you’ve done any kind of 3D work, you’re probably familiar with the idea of defining geometry using vertices. For example, a cube is defined by 8 vertices and 12 triangles. But with raymarching, we use something called “signed distance field” to represent the geometry.</p><h3 id="signed-distance-field-sdf" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#signed-distance-field-sdf" aria-label="signed distance field sdf permalink" color="brand.main" font-family="systemSans"></a>Signed Distance Field (SDF)</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">While the term SDF may sound daunting, it’s just a function that calculates the shortest distance from any point in space to a shape’s surface. The distance is negative for points within the shape, positive for points outside the shape, and zero for points exactly on the surface of the shape.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">For example, a circle can be defined by the following function:</p><div data-language="glsl"><pre><code><span>float</span> <span>sdCircle</span><span>(</span><span>vec2</span> point<span>,</span> <span>float</span> radius<span>)</span> <span>{</span>
  <span>return</span> <span>length</span><span>(</span>point<span>)</span> <span>-</span> radius<span>;</span>
<span>}</span></code></pre></div><p font-family="systemSans" color="neutral.0" font-size="2,3">You can find functions for various <a href="https://iquilezles.org/articles/distfunctions2d/" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">2D</a> and <a href="https://iquilezles.org/articles/distfunctions/" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">3D</a> SDFs on Inigo Quilez’s website. Or use the <a href="https://github.com/marklundin/glsl-sdf-primitives" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">glsl-sdf-primitives</a> library. I’ll explain how to use these functions later in the article.</p><p width="50%" font-family="systemSans" color="neutral.0" font-size="2,3">
  <img src="https://varun.ca/baf8094ed68d7efbc78649ba655b5a69/sdf-marching.svg" alt="" display="block">
</p><p font-family="systemSans" color="neutral.0" font-size="2,3">Back to raymarching. When stepping along the ray, the obvious option is to take a tiny step at a time and check for collisions. But since SDF provides us with the distance to the surface, we know that we can step by that distance without going through the surface. Doing so both speeds up the process and improves accuracy.</p><p font-size="2" color="neutral.1" font-family="systemSans">🤔 <b>Raytracing vs Raymarching</b><br>Raytracing is a very similar process to raymarching, the key difference is that geometry is typically defined as triangles, spheres, etc. To find the intersection between the view ray and the scene, we conduct a series of geometric intersection tests. For example, does the ray intersect with a triangle and, if so, which part of the triangle.</p><h2 id="implementing-a-raymarched-scene" font-family="systemSans" color="neutral.0" font-size="4,5" font-weight="7"><a href="#implementing-a-raymarched-scene" aria-label="implementing a raymarched scene permalink" color="brand.main" font-family="systemSans"></a>Implementing a raymarched scene</h2><p font-family="systemSans" color="neutral.0" font-size="2,3">Alright, onto the crystal. Let’s take the technique I shared above and implement it in GLSL. We’ll start with a basic shader scene, add raymarching to it, and then implement lighting and materials.</p><div><figure display="none,none,block" width="400"></figure><div display="none,none,block"><h3 id="basic-shader-scene" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#basic-shader-scene" aria-label="basic shader scene permalink" color="brand.main" font-family="systemSans"></a>Basic shader scene</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">My goto tool for creative coding is <a href="https://github.com/mattdesl/canvas-sketch" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">canvas-sketch</a>. It offers a <a href="https://github.com/mattdesl/canvas-sketch-util/blob/master/docs/shader.md#shader--createshaderopt" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">utility function</a> that creates a full-screen GLSL shader renderer using <a href="https://regl.party/" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">regl</a>. You can pass in your shader code and uniforms and it takes care of the rest. Here’s an example of a shader that renders a gradient.</p><div data-language="js"><pre><code><span>const</span> canvasSketch <span>=</span> <span>require</span><span>(</span><span>'canvas-sketch'</span><span>)</span><span>;</span>
<span>const</span> createShader <span>=</span> <span>require</span><span>(</span><span>'canvas-sketch-util/shader'</span><span>)</span><span>;</span>
<span>const</span> glsl <span>=</span> <span>require</span><span>(</span><span>'glslify'</span><span>)</span><span>;</span>

<span>const</span> settings <span>=</span> <span>{</span>
  dimensions<span>:</span> <span>[</span><span>1080</span><span>,</span> <span>1080</span><span>]</span><span>,</span>
  context<span>:</span> <span>'webgl'</span><span>,</span>
  animate<span>:</span> <span>true</span><span>,</span>
<span>}</span><span>;</span>

<span>const</span> frag <span>=</span> <span>glsl</span><span>(</span><span><span>`</span><span>
  precision highp float;

  uniform float time;
  varying vec2 vUv;

  void main () {
    vec3 col = 0.5 + 0.5 * cos(time + vUv.xyx + vec3(0,2,4));
    gl_FragColor = vec4(col, 1.0);
  }
</span><span>`</span></span><span>)</span><span>;</span>

<span>const</span> <span>sketch</span> <span>=</span> <span>(</span><span><span>{</span> gl<span>,</span> canvas <span>}</span></span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>return</span> <span>createShader</span><span>(</span><span>{</span>
    gl<span>,</span>
    frag<span>,</span>
    uniforms<span>:</span> <span>{</span>
      <span>resolution</span><span>:</span> <span>(</span><span><span>{</span> width<span>,</span> height <span>}</span></span><span>)</span> <span>=&gt;</span> <span>[</span>width<span>,</span> height<span>]</span><span>,</span>
      <span>time</span><span>:</span> <span>(</span><span><span>{</span> time <span>}</span></span><span>)</span> <span>=&gt;</span> time<span>,</span>
      <span>playhead</span><span>:</span> <span>(</span><span><span>{</span> playhead <span>}</span></span><span>)</span> <span>=&gt;</span> playhead<span>,</span>
    <span>}</span><span>,</span>
  <span>}</span><span>)</span><span>;</span>
<span>}</span><span>;</span>

<span>canvasSketch</span><span>(</span>sketch<span>,</span> settings<span>)</span><span>;</span></code></pre></div><p font-family="systemSans" color="neutral.0" font-size="2,3">Couple of things to note here. <code>createShader</code> bootstraps a default vertex shader (see below) that provides a varying <code>vUv</code>. This essentially maps the pixel coordinates to a value between 0 and 1. You can override this by specifying a custom vertex shader. But for most cases, this is sufficient.</p><p>vert.glsl</p><div data-language="glsl"><pre><code><span>precision</span> <span>highp</span> <span>float</span><span>;</span>
<span>attribute</span> <span>vec3</span> position<span>;</span>
<span>varying</span> <span>vec2</span> vUv<span>;</span>

<span>void</span> <span>main</span> <span>(</span><span>)</span> <span>{</span>
  gl_Position <span>=</span> <span>vec4</span><span>(</span>position<span>.</span>xyz<span>,</span> <span>1.0</span><span>)</span><span>;</span>
  vUv <span>=</span> gl_Position<span>.</span>xy <span>*</span> <span>0.5</span> <span>+</span> <span>0.5</span><span>;</span>
<span>}</span></code></pre></div><p font-family="systemSans" color="neutral.0" font-size="2,3">I’m also using a tool called <code>glslify</code> to wrap the shader code. This enables us to import GLSL modules into our shader. We’ll use it to import SDF functions and other raymarching utilities.</p><h3 id="the-raymarching-algorithm" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#the-raymarching-algorithm" aria-label="the raymarching algorithm permalink" color="brand.main" font-family="systemSans"></a>The Raymarching Algorithm</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">Below is an implementation of the ray marching algorithm. The camera is positioned as the <code>rayOrigin</code>, and pointed towards the <code>rayTarget</code>—the center of the scene.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">The <code>rayDirection</code> is a vector that points from the origin towards a a pixel on the screen, while accounting for the camera’s orientation and field of view. It requires a bit of fancy math to figure out this direction. We’ll be using the <code>glsl-camera-ray</code> module to run that calculation.</p><p><img src="https://varun.ca/static/ray-direction-8b0a68215b4c83cd9236ca43e204a9da.svg" alt="Ray starts at the camera, goes through the pixel on the screen and moves through the scene" display="block"></p><p font-family="systemSans" color="neutral.0" font-size="2,3">Once we obtain the ray direction, we proceed along it, checking for collisions. If a collision is detected, the distance to the surface is returned. Otherwise, we return <code>-1.0</code> to signify that no collision was found.</p><div data-language="glsl"><pre><code><span>precision</span> <span>highp</span> <span>float</span><span>;</span>
<span>varying</span> <span>vec2</span> vUv<span>;</span>
<span>uniform</span> <span>float</span> lensLength<span>;</span>

<span><span>#</span><span>pragma</span> <span>glslify<span>:</span> camera <span>=</span> <span>require</span><span>(</span></span><span>'glsl-camera-ray'</span><span><span>)</span></span></span>

<span>float</span> <span>sdSphere</span><span>(</span><span>vec3</span> point<span>,</span> <span>float</span> radius<span>)</span> <span>{</span>
  <span>return</span> <span>length</span><span>(</span>point<span>)</span> <span>-</span> radius<span>;</span>
<span>}</span>

<span>const</span> <span>int</span> steps <span>=</span> <span>90</span><span>;</span>
<span>const</span> <span>float</span> maxdist <span>=</span> <span>20.0</span><span>;</span>
<span>const</span> <span>float</span> precis <span>=</span> <span>0.001</span><span>;</span>

<span>float</span> <span>raymarch</span><span>(</span><span>vec3</span> rayOrigin<span>,</span> <span>vec3</span> rayDir<span>)</span> <span>{</span>
  <span>float</span> latest <span>=</span> precis <span>*</span> <span>2.0</span><span>;</span>
  <span>float</span> dist <span>=</span> <span>0.0</span><span>;</span>
  <span>float</span> res <span>=</span> <span>-</span><span>1.0</span><span>;</span>

  <span>// March along the ray</span>
  <span>for</span> <span>(</span><span>int</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> steps<span>;</span> i<span>++</span><span>)</span> <span>{</span>
    <span>// Break if we're close enough or too far away</span>
    <span>if</span> <span>(</span>latest <span>&lt;</span> precis <span>||</span> dist <span>&gt;</span> maxdist<span>)</span> <span>break</span><span>;</span>
    <span>// Get the SDF distance</span>
    <span>float</span> latest <span>=</span> <span>sdSphere</span><span>(</span>rayOrigin <span>+</span> rayDir <span>*</span> dist<span>,</span> <span>1.0</span><span>)</span><span>;</span>
    <span>// Increment by the latest SDF distance</span>
    dist <span>+=</span> latest<span>;</span>
  <span>}</span>
  <span>// if we're still within bounds,</span>
  <span>// set the result to the distance</span>
  <span>if</span> <span>(</span>dist <span>&lt;</span> maxdist<span>)</span> <span>{</span>
    res <span>=</span> dist<span>;</span>
  <span>}</span>

  <span>return</span> res<span>;</span>
<span>}</span>

<span>void</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>vec3</span> color <span>=</span> <span>vec3</span><span>(</span><span>0.0</span><span>)</span><span>;</span>

  <span>// Bootstrap a raymarching scene</span>
  <span>vec3</span> rayOrigin <span>=</span> <span>vec3</span><span>(</span><span>3.5</span><span>,</span> <span>0.</span><span>,</span> <span>3.5</span><span>)</span><span>;</span>
  <span>vec3</span> rayTarget <span>=</span> <span>vec3</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>)</span><span>;</span>
  <span>// map from 0 to 1 to -1. to 1.</span>
  <span>vec2</span> screenPos <span>=</span> vUv <span>*</span> <span>2.0</span> <span>-</span> <span>1.</span><span>;</span>
  <span>vec3</span> rayDirection <span>=</span> <span>camera</span><span>(</span>rayOrigin<span>,</span> rayTarget<span>,</span> screenPos<span>,</span> lensLength<span>)</span><span>;</span>

  <span>float</span> collision <span>=</span> <span>raymarch</span><span>(</span>rayOrigin<span>,</span> rayDirection<span>)</span><span>;</span>

  <span>// If the ray collides, draw the surface</span>
  <span>if</span> <span>(</span>collision <span>&gt;</span> <span>-</span><span>0.5</span><span>)</span> <span>{</span>
    color <span>=</span> <span>vec3</span><span>(</span><span>0.678</span><span>,</span> <span>0.106</span><span>,</span> <span>0.176</span><span>)</span><span>;</span>
  <span>}</span>

  gl_FragColor <span>=</span> <span>vec4</span><span>(</span>color<span>,</span> <span>1</span><span>)</span><span>;</span>
<span>}</span></code></pre></div><p font-family="systemSans" color="neutral.0" font-size="2,3"><code>lensLength</code> here determines the field of view. Try changing it to see how it affects the scene.</p><h3 id="using-glsl-modules-for-raymarching" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#using-glsl-modules-for-raymarching" aria-label="using glsl modules for raymarching permalink" color="brand.main" font-family="systemSans"></a>Using GLSL modules for raymarching</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">Implementing your own raymarching function is cool. It’s especially useful when you want to tweak the inner workings to achieve a specific effect. However, in most cases, you can probably just use an off-the-shelf module.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">Below, I’ve updated the sketch to use the <code>glsl-raytrace</code> module. Additionally, I’m using a <code>glsl-sdf-primitives</code> module to generate a torus and <code>glsl-rotate</code> to rotate it.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">The mechanics remain largely similar. The key difference is that geometry is now defined within a function called <code>doModel</code>, and raymarch returns a <code>vec2</code> containing the distance and material index. This is useful if you want to render multiple types of objects in a scene.</p><div data-language="glsl"><pre><code><span>precision</span> <span>highp</span> <span>float</span><span>;</span>
<span>varying</span> <span>vec2</span> vUv<span>;</span>
<span>uniform</span> <span>float</span> lensLength<span>;</span>
<span>uniform</span> <span>float</span> time<span>;</span>

<span>vec2</span> <span>doModel</span><span>(</span><span>vec3</span> p<span>)</span><span>;</span>

<span><span>#</span><span>pragma</span> <span>glslify<span>:</span> camera <span>=</span> <span>require</span><span>(</span></span><span>'glsl-camera-ray'</span><span><span>)</span></span></span>
<span><span>#</span><span>pragma</span> <span>glslify<span>:</span> raymarch <span>=</span> <span>require</span><span>(</span></span><span>'glsl-raytrace'</span><span><span>,</span> map <span>=</span> doModel<span>,</span> steps <span>=</span> <span>90</span><span>)</span></span></span>
<span><span>#</span><span>pragma</span> <span>glslify<span>:</span> sdTorus <span>=</span> <span>require</span><span>(</span></span><span>'glsl-sdf-primitives/sdTorus'</span><span><span>)</span></span></span>
<span><span>#</span><span>pragma</span> <span>glslify<span>:</span> rotate <span>=</span> <span>require</span><span>(</span></span><span>'glsl-rotate/rotate'</span><span><span>)</span></span></span>

<span>vec2</span> <span>doModel</span><span>(</span><span>vec3</span> p<span>)</span> <span>{</span>
  <span>// Spin the shape</span>
  p<span>.</span>xy <span>=</span> <span>rotate</span><span>(</span>p<span>.</span>xy<span>,</span> time<span>)</span><span>;</span>
  p<span>.</span>yz <span>=</span> <span>rotate</span><span>(</span>p<span>.</span>yz<span>,</span> time<span>)</span><span>;</span>
  <span>// Calculate SDF distance</span>
  <span>float</span> d <span>=</span> <span>sdTorus</span><span>(</span>p<span>,</span> <span>vec2</span><span>(</span><span>0.75</span><span>,</span> <span>0.35</span><span>)</span><span>)</span><span>;</span>
  <span>return</span> <span>vec2</span><span>(</span>d<span>,</span> <span>0.0</span><span>)</span><span>;</span>
<span>}</span>

<span>void</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>vec3</span> color <span>=</span> <span>vec3</span><span>(</span><span>0.0</span><span>)</span><span>;</span>
  <span>// Bootstrap a raytracing scene</span>
  <span>vec3</span> rayOrigin <span>=</span> <span>vec3</span><span>(</span><span>3.5</span><span>,</span> <span>0</span><span>,</span> <span>3.5</span><span>)</span><span>;</span>
  <span>vec3</span> rayTarget <span>=</span> <span>vec3</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>)</span><span>;</span>
  <span>// map from 0 to 1 to -1. to 1.</span>
  <span>vec2</span> screenPos <span>=</span> vUv <span>*</span> <span>2.0</span> <span>-</span> <span>1.</span><span>;</span>
  <span>vec3</span> rayDirection <span>=</span> <span>camera</span><span>(</span>rayOrigin<span>,</span> rayTarget<span>,</span> screenPos<span>,</span> lensLength<span>)</span><span>;</span>

  <span>vec2</span> collision <span>=</span> <span>raymarch</span><span>(</span>rayOrigin<span>,</span> rayDirection<span>)</span><span>;</span>

  <span>// If the ray collides, draw the surface</span>
  <span>if</span> <span>(</span>collision<span>.</span>x <span>&gt;</span> <span>-</span><span>0.5</span><span>)</span> <span>{</span>
    color <span>=</span> <span>vec3</span><span>(</span><span>0.678</span><span>,</span> <span>0.106</span><span>,</span> <span>0.176</span><span>)</span><span>;</span>
  <span>}</span>

  gl_FragColor <span>=</span> <span>vec4</span><span>(</span>color<span>,</span> <span>1</span><span>)</span><span>;</span>
<span>}</span></code></pre></div><p font-family="systemSans" color="neutral.0" font-size="2,3">Check it out! We’ve got a spinning donut 🍩 But it looks kinda flat. Let’s add some depth to the scene.</p><h3 id="calculating-normals" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#calculating-normals" aria-label="calculating normals permalink" color="brand.main" font-family="systemSans"></a>Calculating normals</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">For the classic material and lighting combination, we need to calculate surface normals. That is, a vector that points away from the surface at a given point.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">With SDFs, we calculate the normal by taking the gradient of the SDF function (f) at a specific point, denoted as ∇f. I don’t know about you, but the last time I took a gradient was in <a href="https://apps.ualberta.ca/catalogue/course/mec_e/537" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">MEC E 537 - Aerodynamics</a>. And that was a while ago 😅</p><p font-family="systemSans" color="neutral.0" font-size="2,3">Luckily for us, we can use the <code>glsl-sdf-normal</code> module to compute normals for us. The module uses the same <code>doModel</code> function that we defined for raymarching. If you’re curious about the underlying math, check out <a href="https://jamie-wong.com/2016/07/15/ray-marching-signed-distance-functions/#surface-normals-and-lighting" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">Jamie Wong’s explanation</a>.</p><div data-language="glsl"><pre><code><span><span>#</span><span>pragma</span> <span>glslify<span>:</span> normal <span>=</span> <span>require</span><span>(</span></span><span>'glsl-sdf-normal'</span><span><span>,</span> map <span>=</span> doModel<span>)</span></span></span>

<span>// ...</span>

<span>if</span> <span>(</span>collision<span>.</span>x <span>&gt;</span> <span>-</span><span>0.5</span><span>)</span> <span>{</span>
  <span>// Determine the point of collision</span>
  <span>vec3</span> pos <span>=</span> rayOrigin <span>+</span> rayDirection <span>*</span> collision<span>.</span>x<span>;</span>
  <span>// Calculate the normal</span>
  <span>vec3</span> nor <span>=</span> <span>normal</span><span>(</span>pos<span>)</span><span>;</span>
  <span>// Convert the normal to a color</span>
  color <span>=</span> nor <span>*</span> <span>0.5</span> <span>+</span> <span>0.5</span><span>;</span>
<span>}</span>

<span>// ...</span></code></pre></div><h3 id="phong-lighting" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#phong-lighting" aria-label="phong lighting permalink" color="brand.main" font-family="systemSans"></a>Phong lighting</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">My personal philosophy is very much:</p><p><img alt="Fuck around find out" src="https://varun.ca/static/fuck-around-find-out-cc2e14bf2895e5634f02f2f2475d8531.jpg" display="block"></p><p font-family="systemSans" color="neutral.0" font-size="2,3">It’s important to understand how things work, but I’m less focused on implementing everything from scratch and more intrigued by applying those concepts to create my own sketches and scenes. That’s why I was super excited to come across <a href="http://stack.gl/packages" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">stack.gl/packages</a>.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">The stackgl ecosystem is full of little GLSL modules that you can glue these together to create all kinds of effects.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">Interested in adding lighting to the scene? What type would you prefer? Lambert, Phong, Beckmann, or Specular? Just grab the associated module and plug it into the scene.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">I chose <code>glsl-specular-blinn-phong</code></p><div data-language="glsl"><pre><code><span><span>#</span><span>pragma</span> <span>glslify<span>:</span> blinnPhongSpec <span>=</span> <span>require</span><span>(</span></span><span>'glsl-specular-blinn-phong'</span><span><span>)</span></span></span>

<span>// ...</span>

<span>vec3</span> lightPos <span>=</span> <span>vec3</span><span>(</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span><span>;</span>
<span>vec3</span> tint <span>=</span> <span>vec3</span><span>(</span><span>0.05</span><span>,</span> <span>0.0</span><span>,</span> <span>0.97</span><span>)</span><span>;</span> <span>// color of the shape</span>

<span>vec2</span> collision <span>=</span> <span>raymarch</span><span>(</span>rayOrigin<span>,</span> rayDirection<span>)</span><span>;</span>

<span>// If the ray collides, draw the surface</span>
<span>if</span> <span>(</span>collision<span>.</span>x <span>&gt;</span> <span>-</span><span>0.5</span><span>)</span> <span>{</span>
  <span>// Determine the point of collision</span>
  <span>vec3</span> pos <span>=</span> rayOrigin <span>+</span> rayDirection <span>*</span> collision<span>.</span>x<span>;</span>
  <span>// Calculate the normal</span>
  <span>vec3</span> nor <span>=</span> <span>normal</span><span>(</span>pos<span>)</span><span>;</span>

  <span>// Calculate light intensity</span>
  <span>vec3</span> eyeDirection <span>=</span> <span>normalize</span><span>(</span>rayOrigin <span>-</span> pos<span>)</span><span>;</span>
  <span>vec3</span> lightDirection <span>=</span> <span>normalize</span><span>(</span>lightPos <span>-</span> pos<span>)</span><span>;</span>
  <span>float</span> power <span>=</span> <span>blinnPhongSpec</span><span>(</span>lightDirection<span>,</span> eyeDirection<span>,</span> nor<span>,</span> <span>0.5</span><span>)</span><span>;</span>
  <span>// light intensity * color of the shape</span>
  color <span>=</span> power <span>*</span> tint<span>;</span>
<span>}</span></code></pre></div><h3 id="iridescent-material" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#iridescent-material" aria-label="iridescent material permalink" color="brand.main" font-family="systemSans"></a>Iridescent material</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">Stackgl isn’t the only place where you can find useful code. My other favourite option is Shadertoy. I’m not going to lie, most things on shadertoy were too daunting for me. I couldn’t even begin to figure out what the code was doing.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">That is, until I discovered that most work on shadertoy uses a combo of raymarching + SDF. This was certainly a lightbulb moment for me. It’s like suddenly this cryptic code was deciphered and I could understand what it said.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">I’ve been obsessed with iridescence and have been bookmarking cool shaders. Once I learnt the raymarching technique, that was it. I could revisit these shaders and try to understand how they work.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">One such shader was <a href="https://www.shadertoy.com/view/llcXWM" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">Thomas Hooper’s Crystals</a>. It’s way more complex than our scene but the general structure is the same. There’s a function for generating the geometry, there’s raymarching loop and after checking for collision is the bit where the iridescence effect is applied.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">Let’s add that to our scene.</p><div data-language="glsl"><pre><code><span>vec3</span> <span>pal</span><span>(</span> <span>in</span> <span>float</span> t<span>,</span> <span>in</span> <span>vec3</span> a<span>,</span> <span>in</span> <span>vec3</span> b<span>,</span> <span>in</span> <span>vec3</span> c<span>,</span> <span>in</span> <span>vec3</span> d <span>)</span> <span>{</span>
  <span>return</span> a <span>+</span> b<span>*</span><span>cos</span><span>(</span> <span>6.28318</span><span>*</span><span>(</span>c<span>*</span>t<span>+</span>d<span>)</span> <span>)</span><span>;</span>
<span>}</span>

<span>vec3</span> <span>spectrum</span><span>(</span><span>float</span> n<span>)</span> <span>{</span>
  <span>return</span> <span>pal</span><span>(</span> n<span>,</span> <span>vec3</span><span>(</span><span>0.5</span><span>,</span><span>0.5</span><span>,</span><span>0.5</span><span>)</span><span>,</span><span>vec3</span><span>(</span><span>0.5</span><span>,</span><span>0.5</span><span>,</span><span>0.5</span><span>)</span><span>,</span><span>vec3</span><span>(</span><span>1.0</span><span>,</span><span>1.0</span><span>,</span><span>1.0</span><span>)</span><span>,</span><span>vec3</span><span>(</span><span>0.0</span><span>,</span><span>0.33</span><span>,</span><span>0.67</span><span>)</span> <span>)</span><span>;</span>
<span>}</span>

<span>const</span> <span>float</span> GAMMA <span>=</span> <span>2.2</span><span>;</span>

<span>vec3</span> <span>gamma</span><span>(</span><span>vec3</span> color<span>,</span> <span>float</span> g<span>)</span> <span>{</span>
  <span>return</span> <span>pow</span><span>(</span>color<span>,</span> <span>vec3</span><span>(</span>g<span>)</span><span>)</span><span>;</span>
<span>}</span>

<span>vec3</span> <span>linearToScreen</span><span>(</span><span>vec3</span> linearRGB<span>)</span> <span>{</span>
  <span>return</span> <span>gamma</span><span>(</span>linearRGB<span>,</span> <span>1.0</span> <span>/</span> GAMMA<span>)</span><span>;</span>
<span>}</span>

<span>// ...</span>

<span>if</span> <span>(</span>collision<span>.</span>x <span>&gt;</span> <span>-</span><span>0.5</span><span>)</span> <span>{</span>
  <span>// Determine the point of collision</span>
  <span>vec3</span> pos <span>=</span> rayOrigin <span>+</span> rayDirection <span>*</span> collision<span>.</span>x<span>;</span>
  <span>vec3</span> nor <span>=</span> <span>normal</span><span>(</span>pos<span>)</span><span>;</span>

  <span>vec3</span> eyeDirection <span>=</span> <span>normalize</span><span>(</span>rayOrigin <span>-</span> pos<span>)</span><span>;</span>
  <span>vec3</span> lightDirection <span>=</span> <span>normalize</span><span>(</span>lightPos <span>-</span> pos<span>)</span><span>;</span>

  <span>// Iridescent lighting</span>
  <span>vec3</span> reflection <span>=</span> <span>reflect</span><span>(</span>rayDirection<span>,</span> nor<span>)</span><span>;</span>
  <span>vec3</span> dome <span>=</span> <span>vec3</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>)</span><span>;</span>
  <span>// base layer</span>
  <span>vec3</span> perturb <span>=</span> <span>sin</span><span>(</span>pos <span>*</span> <span>10.</span><span>)</span><span>;</span>
  color <span>=</span> <span>spectrum</span><span>(</span><span>dot</span><span>(</span>nor <span>+</span> perturb <span>*</span> <span>.05</span><span>,</span> eyeDirection<span>)</span> <span>*</span> <span>2.</span><span>)</span><span>;</span>
  <span>// specular</span>
  <span>float</span> specular <span>=</span> <span>clamp</span><span>(</span><span>dot</span><span>(</span>reflection<span>,</span> lightDirection<span>)</span><span>,</span> <span>0.</span><span>,</span> <span>1.</span><span>)</span><span>;</span>
  specular <span>=</span> <span>pow</span><span>(</span><span>(</span><span>sin</span><span>(</span>specular <span>*</span> <span>20.</span> <span>-</span> <span>3.</span><span>)</span> <span>*</span> <span>.5</span> <span>+</span> <span>.5</span><span>)</span> <span>+</span> <span>.1</span><span>,</span> <span>32.</span><span>)</span> <span>*</span> specular<span>;</span>
  specular <span>*=</span> <span>.1</span><span>;</span>
  specular <span>+=</span> <span>pow</span><span>(</span><span>clamp</span><span>(</span><span>dot</span><span>(</span>reflection<span>,</span> lightDirection<span>)</span><span>,</span> <span>0.</span><span>,</span> <span>1.</span><span>)</span> <span>+</span> <span>.3</span><span>,</span> <span>8.</span><span>)</span> <span>*</span> <span>.1</span><span>;</span>
  <span>// shadow</span>
  <span>float</span> shadow <span>=</span> <span>pow</span><span>(</span><span>clamp</span><span>(</span><span>dot</span><span>(</span>nor<span>,</span> dome<span>)</span> <span>*</span> <span>.5</span> <span>+</span> <span>1.2</span><span>,</span> <span>0.</span><span>,</span> <span>1.</span><span>)</span><span>,</span> <span>3.</span><span>)</span><span>;</span>
  color <span>=</span> color <span>*</span> shadow <span>+</span> specular<span>;</span>

  <span>// gamma correction</span>
  color <span>=</span> <span>linearToScreen</span><span>(</span>color<span>)</span><span>;</span>
<span>}</span></code></pre></div><p font-family="systemSans" color="neutral.0" font-size="2,3">There are three layers to the iridescent material: the base layer (the funky gradients), a little bit of shadow and specular (the concentric light bands). Try toggling them on and off with the slider see their effects.</p><h3 id="mix-phong-and-iridescence" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#mix-phong-and-iridescence" aria-label="mix phong and iridescence permalink" color="brand.main" font-family="systemSans"></a>Mix Phong and Iridescence</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">One last little tweak with the lighting. We can actually blend the phong and iridescence effects. Which enables you to have tinted iridescent objects.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">There’s not a whole lot to it. Calculate the colors for the two effects and then blend them with the <code>mix</code> function.</p><div data-language="glsl"><pre><code><span>if</span> <span>(</span>collision<span>.</span>x <span>&gt;</span> <span>-</span><span>0.5</span><span>)</span> <span>{</span>
  <span>// ...</span>
  <span>// Basic blinn phong lighting</span>
  <span>float</span> power <span>=</span> <span>blinnPhongSpec</span><span>(</span>lightDirection<span>,</span> eyeDirection<span>,</span> nor<span>,</span> <span>0.5</span><span>)</span><span>;</span>
  <span>vec3</span> baseColor <span>=</span> power <span>*</span> tint<span>;</span>

  <span>// Iridescent lighting</span>
  <span>// ...</span>
  color <span>=</span> color <span>*</span> shadow <span>+</span> specular<span>;</span>

  <span>// mix blinn phong lighting and iridescent lighting</span>
  color <span>=</span> <span>mix</span><span>(</span>baseColor<span>,</span> color<span>,</span> mixBaseAndIridescent<span>)</span><span>;</span>
  <span>// gamma correction</span>
  color <span>=</span> <span>linearToScreen</span><span>(</span>color<span>)</span><span>;</span>
<span>}</span></code></pre></div><h3 id="crystal-geometry" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#crystal-geometry" aria-label="crystal geometry permalink" color="brand.main" font-family="systemSans"></a>Crystal geometry</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">We’ve nailed the look, but what about the crystal shape?</p><p font-family="systemSans" color="neutral.0" font-size="2,3">You can file this under “stuff I don’t quite understand, but that’s not going to stop me from using it.” The crystal geometry is a Rhombic Triacontahedron, which I discovered in a <a href="https://www.youtube.com/watch?v=0RWaR7zApEo&amp;t=50s" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">The Art Of Code tutorial</a>.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">This shape is created by folding a plane onto itself using some “magic numbers” and along a “magic direction.” We repeat the process a few times until we achieve the desired crystal shape.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">Try using the slider to observe how the shape changes with each fold.</p><div data-language="glsl"><pre><code><span>float</span> <span>sdCrystal</span><span>(</span><span>vec3</span> p<span>)</span> <span>{</span>
  <span>float</span> c <span>=</span> <span>cos</span><span>(</span><span>3.1415</span><span>/</span><span>5.</span><span>)</span><span>,</span> s<span>=</span><span>sqrt</span><span>(</span><span>0.75</span><span>-</span>c<span>*</span>c<span>)</span><span>;</span> <span>// magic numbers</span>
  <span>vec3</span> n <span>=</span> <span>vec3</span><span>(</span><span>-</span><span>0.5</span><span>,</span> <span>-</span>c<span>,</span> s<span>)</span><span>;</span> <span>// magic direction</span>

  <span>// fold the space to add symmetry</span>
  p <span>=</span> <span>abs</span><span>(</span>p<span>)</span><span>;</span>
  <span>// fold along the n direction</span>
  p <span>-=</span> <span>2.</span><span>*</span><span>min</span><span>(</span><span>0.</span><span>,</span> <span>dot</span><span>(</span>p<span>,</span> n<span>)</span><span>)</span><span>*</span>n<span>;</span>

  <span>// fold the space again and along the n direction</span>
  p<span>.</span>xy <span>=</span> <span>abs</span><span>(</span>p<span>.</span>xy<span>)</span><span>;</span>
  p <span>-=</span> <span>2.</span><span>*</span><span>min</span><span>(</span><span>0.</span><span>,</span> <span>dot</span><span>(</span>p<span>,</span> n<span>)</span><span>)</span><span>*</span>n<span>;</span>

  <span>// repeat the process</span>
  p<span>.</span>xy <span>=</span> <span>abs</span><span>(</span>p<span>.</span>xy<span>)</span><span>;</span>
  p <span>-=</span> <span>2.</span><span>*</span><span>min</span><span>(</span><span>0.</span><span>,</span> <span>dot</span><span>(</span>p<span>,</span> n<span>)</span><span>)</span><span>*</span>n<span>;</span>

  <span>// distance to the surface</span>
  <span>float</span> d <span>=</span> p<span>.</span>z <span>-</span> <span>1.</span><span>;</span>
  <span>return</span> d<span>;</span>
<span>}</span></code></pre></div></div><div display="block,block,none"><h3 id="basic-shader-scene" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#basic-shader-scene" aria-label="basic shader scene permalink" color="brand.main" font-family="systemSans"></a>Basic shader scene</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">My goto tool for creative coding is <a href="https://github.com/mattdesl/canvas-sketch" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">canvas-sketch</a>. It offers a <a href="https://github.com/mattdesl/canvas-sketch-util/blob/master/docs/shader.md#shader--createshaderopt" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">utility function</a> that creates a full-screen GLSL shader renderer using <a href="https://regl.party/" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">regl</a>. You can pass in your shader code and uniforms and it takes care of the rest. Here’s an example of a shader that renders a gradient.</p><div data-language="js"><pre><code><span>const</span> canvasSketch <span>=</span> <span>require</span><span>(</span><span>'canvas-sketch'</span><span>)</span><span>;</span>
<span>const</span> createShader <span>=</span> <span>require</span><span>(</span><span>'canvas-sketch-util/shader'</span><span>)</span><span>;</span>
<span>const</span> glsl <span>=</span> <span>require</span><span>(</span><span>'glslify'</span><span>)</span><span>;</span>

<span>const</span> settings <span>=</span> <span>{</span>
  dimensions<span>:</span> <span>[</span><span>1080</span><span>,</span> <span>1080</span><span>]</span><span>,</span>
  context<span>:</span> <span>'webgl'</span><span>,</span>
  animate<span>:</span> <span>true</span><span>,</span>
<span>}</span><span>;</span>

<span>const</span> frag <span>=</span> <span>glsl</span><span>(</span><span><span>`</span><span>
  precision highp float;

  uniform float time;
  varying vec2 vUv;

  void main () {
    vec3 col = 0.5 + 0.5 * cos(time + vUv.xyx + vec3(0,2,4));
    gl_FragColor = vec4(col, 1.0);
  }
</span><span>`</span></span><span>)</span><span>;</span>

<span>const</span> <span>sketch</span> <span>=</span> <span>(</span><span><span>{</span> gl<span>,</span> canvas <span>}</span></span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>return</span> <span>createShader</span><span>(</span><span>{</span>
    gl<span>,</span>
    frag<span>,</span>
    uniforms<span>:</span> <span>{</span>
      <span>resolution</span><span>:</span> <span>(</span><span><span>{</span> width<span>,</span> height <span>}</span></span><span>)</span> <span>=&gt;</span> <span>[</span>width<span>,</span> height<span>]</span><span>,</span>
      <span>time</span><span>:</span> <span>(</span><span><span>{</span> time <span>}</span></span><span>)</span> <span>=&gt;</span> time<span>,</span>
      <span>playhead</span><span>:</span> <span>(</span><span><span>{</span> playhead <span>}</span></span><span>)</span> <span>=&gt;</span> playhead<span>,</span>
    <span>}</span><span>,</span>
  <span>}</span><span>)</span><span>;</span>
<span>}</span><span>;</span>

<span>canvasSketch</span><span>(</span>sketch<span>,</span> settings<span>)</span><span>;</span></code></pre></div><p font-family="systemSans" color="neutral.0" font-size="2,3">Couple of things to note here. <code>createShader</code> bootstraps a default vertex shader (see below) that provides a varying <code>vUv</code>. This essentially maps the pixel coordinates to a value between 0 and 1. You can override this by specifying a custom vertex shader. But for most cases, this is sufficient.</p><p>vert.glsl</p><div data-language="glsl"><pre><code><span>precision</span> <span>highp</span> <span>float</span><span>;</span>
<span>attribute</span> <span>vec3</span> position<span>;</span>
<span>varying</span> <span>vec2</span> vUv<span>;</span>

<span>void</span> <span>main</span> <span>(</span><span>)</span> <span>{</span>
  gl_Position <span>=</span> <span>vec4</span><span>(</span>position<span>.</span>xyz<span>,</span> <span>1.0</span><span>)</span><span>;</span>
  vUv <span>=</span> gl_Position<span>.</span>xy <span>*</span> <span>0.5</span> <span>+</span> <span>0.5</span><span>;</span>
<span>}</span></code></pre></div><p font-family="systemSans" color="neutral.0" font-size="2,3">I’m also using a tool called <code>glslify</code> to wrap the shader code. This enables us to import GLSL modules into our shader. We’ll use it to import SDF functions and other raymarching utilities.</p><h3 id="the-raymarching-algorithm" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#the-raymarching-algorithm" aria-label="the raymarching algorithm permalink" color="brand.main" font-family="systemSans"></a>The Raymarching Algorithm</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">Below is an implementation of the ray marching algorithm. The camera is positioned as the <code>rayOrigin</code>, and pointed towards the <code>rayTarget</code>—the center of the scene.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">The <code>rayDirection</code> is a vector that points from the origin towards a a pixel on the screen, while accounting for the camera’s orientation and field of view. It requires a bit of fancy math to figure out this direction. We’ll be using the <code>glsl-camera-ray</code> module to run that calculation.</p><p><img src="https://varun.ca/static/ray-direction-8b0a68215b4c83cd9236ca43e204a9da.svg" alt="Ray starts at the camera, goes through the pixel on the screen and moves through the scene" display="block"></p><p font-family="systemSans" color="neutral.0" font-size="2,3">Once we obtain the ray direction, we proceed along it, checking for collisions. If a collision is detected, the distance to the surface is returned. Otherwise, we return <code>-1.0</code> to signify that no collision was found.</p><div data-language="glsl"><pre><code><span>precision</span> <span>highp</span> <span>float</span><span>;</span>
<span>varying</span> <span>vec2</span> vUv<span>;</span>
<span>uniform</span> <span>float</span> lensLength<span>;</span>

<span><span>#</span><span>pragma</span> <span>glslify<span>:</span> camera <span>=</span> <span>require</span><span>(</span></span><span>'glsl-camera-ray'</span><span><span>)</span></span></span>

<span>float</span> <span>sdSphere</span><span>(</span><span>vec3</span> point<span>,</span> <span>float</span> radius<span>)</span> <span>{</span>
  <span>return</span> <span>length</span><span>(</span>point<span>)</span> <span>-</span> radius<span>;</span>
<span>}</span>

<span>const</span> <span>int</span> steps <span>=</span> <span>90</span><span>;</span>
<span>const</span> <span>float</span> maxdist <span>=</span> <span>20.0</span><span>;</span>
<span>const</span> <span>float</span> precis <span>=</span> <span>0.001</span><span>;</span>

<span>float</span> <span>raymarch</span><span>(</span><span>vec3</span> rayOrigin<span>,</span> <span>vec3</span> rayDir<span>)</span> <span>{</span>
  <span>float</span> latest <span>=</span> precis <span>*</span> <span>2.0</span><span>;</span>
  <span>float</span> dist <span>=</span> <span>0.0</span><span>;</span>
  <span>float</span> res <span>=</span> <span>-</span><span>1.0</span><span>;</span>

  <span>// March along the ray</span>
  <span>for</span> <span>(</span><span>int</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> steps<span>;</span> i<span>++</span><span>)</span> <span>{</span>
    <span>// Break if we're close enough or too far away</span>
    <span>if</span> <span>(</span>latest <span>&lt;</span> precis <span>||</span> dist <span>&gt;</span> maxdist<span>)</span> <span>break</span><span>;</span>
    <span>// Get the SDF distance</span>
    <span>float</span> latest <span>=</span> <span>sdSphere</span><span>(</span>rayOrigin <span>+</span> rayDir <span>*</span> dist<span>,</span> <span>1.0</span><span>)</span><span>;</span>
    <span>// Increment by the latest SDF distance</span>
    dist <span>+=</span> latest<span>;</span>
  <span>}</span>
  <span>// if we're still within bounds,</span>
  <span>// set the result to the distance</span>
  <span>if</span> <span>(</span>dist <span>&lt;</span> maxdist<span>)</span> <span>{</span>
    res <span>=</span> dist<span>;</span>
  <span>}</span>

  <span>return</span> res<span>;</span>
<span>}</span>

<span>void</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>vec3</span> color <span>=</span> <span>vec3</span><span>(</span><span>0.0</span><span>)</span><span>;</span>

  <span>// Bootstrap a raymarching scene</span>
  <span>vec3</span> rayOrigin <span>=</span> <span>vec3</span><span>(</span><span>3.5</span><span>,</span> <span>0.</span><span>,</span> <span>3.5</span><span>)</span><span>;</span>
  <span>vec3</span> rayTarget <span>=</span> <span>vec3</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>)</span><span>;</span>
  <span>// map from 0 to 1 to -1. to 1.</span>
  <span>vec2</span> screenPos <span>=</span> vUv <span>*</span> <span>2.0</span> <span>-</span> <span>1.</span><span>;</span>
  <span>vec3</span> rayDirection <span>=</span> <span>camera</span><span>(</span>rayOrigin<span>,</span> rayTarget<span>,</span> screenPos<span>,</span> lensLength<span>)</span><span>;</span>

  <span>float</span> collision <span>=</span> <span>raymarch</span><span>(</span>rayOrigin<span>,</span> rayDirection<span>)</span><span>;</span>

  <span>// If the ray collides, draw the surface</span>
  <span>if</span> <span>(</span>collision <span>&gt;</span> <span>-</span><span>0.5</span><span>)</span> <span>{</span>
    color <span>=</span> <span>vec3</span><span>(</span><span>0.678</span><span>,</span> <span>0.106</span><span>,</span> <span>0.176</span><span>)</span><span>;</span>
  <span>}</span>

  gl_FragColor <span>=</span> <span>vec4</span><span>(</span>color<span>,</span> <span>1</span><span>)</span><span>;</span>
<span>}</span></code></pre></div><p font-family="systemSans" color="neutral.0" font-size="2,3"><code>lensLength</code> here determines the field of view. Try changing it to see how it affects the scene.</p><h3 id="using-glsl-modules-for-raymarching" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#using-glsl-modules-for-raymarching" aria-label="using glsl modules for raymarching permalink" color="brand.main" font-family="systemSans"></a>Using GLSL modules for raymarching</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">Implementing your own raymarching function is cool. It’s especially useful when you want to tweak the inner workings to achieve a specific effect. However, in most cases, you can probably just use an off-the-shelf module.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">Below, I’ve updated the sketch to use the <code>glsl-raytrace</code> module. Additionally, I’m using a <code>glsl-sdf-primitives</code> module to generate a torus and <code>glsl-rotate</code> to rotate it.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">The mechanics remain largely similar. The key difference is that geometry is now defined within a function called <code>doModel</code>, and raymarch returns a <code>vec2</code> containing the distance and material index. This is useful if you want to render multiple types of objects in a scene.</p><div data-language="glsl"><pre><code><span>precision</span> <span>highp</span> <span>float</span><span>;</span>
<span>varying</span> <span>vec2</span> vUv<span>;</span>
<span>uniform</span> <span>float</span> lensLength<span>;</span>
<span>uniform</span> <span>float</span> time<span>;</span>

<span>vec2</span> <span>doModel</span><span>(</span><span>vec3</span> p<span>)</span><span>;</span>

<span><span>#</span><span>pragma</span> <span>glslify<span>:</span> camera <span>=</span> <span>require</span><span>(</span></span><span>'glsl-camera-ray'</span><span><span>)</span></span></span>
<span><span>#</span><span>pragma</span> <span>glslify<span>:</span> raymarch <span>=</span> <span>require</span><span>(</span></span><span>'glsl-raytrace'</span><span><span>,</span> map <span>=</span> doModel<span>,</span> steps <span>=</span> <span>90</span><span>)</span></span></span>
<span><span>#</span><span>pragma</span> <span>glslify<span>:</span> sdTorus <span>=</span> <span>require</span><span>(</span></span><span>'glsl-sdf-primitives/sdTorus'</span><span><span>)</span></span></span>
<span><span>#</span><span>pragma</span> <span>glslify<span>:</span> rotate <span>=</span> <span>require</span><span>(</span></span><span>'glsl-rotate/rotate'</span><span><span>)</span></span></span>

<span>vec2</span> <span>doModel</span><span>(</span><span>vec3</span> p<span>)</span> <span>{</span>
  <span>// Spin the shape</span>
  p<span>.</span>xy <span>=</span> <span>rotate</span><span>(</span>p<span>.</span>xy<span>,</span> time<span>)</span><span>;</span>
  p<span>.</span>yz <span>=</span> <span>rotate</span><span>(</span>p<span>.</span>yz<span>,</span> time<span>)</span><span>;</span>
  <span>// Calculate SDF distance</span>
  <span>float</span> d <span>=</span> <span>sdTorus</span><span>(</span>p<span>,</span> <span>vec2</span><span>(</span><span>0.75</span><span>,</span> <span>0.35</span><span>)</span><span>)</span><span>;</span>
  <span>return</span> <span>vec2</span><span>(</span>d<span>,</span> <span>0.0</span><span>)</span><span>;</span>
<span>}</span>

<span>void</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>vec3</span> color <span>=</span> <span>vec3</span><span>(</span><span>0.0</span><span>)</span><span>;</span>
  <span>// Bootstrap a raytracing scene</span>
  <span>vec3</span> rayOrigin <span>=</span> <span>vec3</span><span>(</span><span>3.5</span><span>,</span> <span>0</span><span>,</span> <span>3.5</span><span>)</span><span>;</span>
  <span>vec3</span> rayTarget <span>=</span> <span>vec3</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>)</span><span>;</span>
  <span>// map from 0 to 1 to -1. to 1.</span>
  <span>vec2</span> screenPos <span>=</span> vUv <span>*</span> <span>2.0</span> <span>-</span> <span>1.</span><span>;</span>
  <span>vec3</span> rayDirection <span>=</span> <span>camera</span><span>(</span>rayOrigin<span>,</span> rayTarget<span>,</span> screenPos<span>,</span> lensLength<span>)</span><span>;</span>

  <span>vec2</span> collision <span>=</span> <span>raymarch</span><span>(</span>rayOrigin<span>,</span> rayDirection<span>)</span><span>;</span>

  <span>// If the ray collides, draw the surface</span>
  <span>if</span> <span>(</span>collision<span>.</span>x <span>&gt;</span> <span>-</span><span>0.5</span><span>)</span> <span>{</span>
    color <span>=</span> <span>vec3</span><span>(</span><span>0.678</span><span>,</span> <span>0.106</span><span>,</span> <span>0.176</span><span>)</span><span>;</span>
  <span>}</span>

  gl_FragColor <span>=</span> <span>vec4</span><span>(</span>color<span>,</span> <span>1</span><span>)</span><span>;</span>
<span>}</span></code></pre></div><p font-family="systemSans" color="neutral.0" font-size="2,3">Check it out! We’ve got a spinning donut 🍩 But it looks kinda flat. Let’s add some depth to the scene.</p><h3 id="calculating-normals" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#calculating-normals" aria-label="calculating normals permalink" color="brand.main" font-family="systemSans"></a>Calculating normals</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">For the classic material and lighting combination, we need to calculate surface normals. That is, a vector that points away from the surface at a given point.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">With SDFs, we calculate the normal by taking the gradient of the SDF function (f) at a specific point, denoted as ∇f. I don’t know about you, but the last time I took a gradient was in <a href="https://apps.ualberta.ca/catalogue/course/mec_e/537" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">MEC E 537 - Aerodynamics</a>. And that was a while ago 😅</p><p font-family="systemSans" color="neutral.0" font-size="2,3">Luckily for us, we can use the <code>glsl-sdf-normal</code> module to compute normals for us. The module uses the same <code>doModel</code> function that we defined for raymarching. If you’re curious about the underlying math, check out <a href="https://jamie-wong.com/2016/07/15/ray-marching-signed-distance-functions/#surface-normals-and-lighting" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">Jamie Wong’s explanation</a>.</p><div data-language="glsl"><pre><code><span><span>#</span><span>pragma</span> <span>glslify<span>:</span> normal <span>=</span> <span>require</span><span>(</span></span><span>'glsl-sdf-normal'</span><span><span>,</span> map <span>=</span> doModel<span>)</span></span></span>

<span>// ...</span>

<span>if</span> <span>(</span>collision<span>.</span>x <span>&gt;</span> <span>-</span><span>0.5</span><span>)</span> <span>{</span>
  <span>// Determine the point of collision</span>
  <span>vec3</span> pos <span>=</span> rayOrigin <span>+</span> rayDirection <span>*</span> collision<span>.</span>x<span>;</span>
  <span>// Calculate the normal</span>
  <span>vec3</span> nor <span>=</span> <span>normal</span><span>(</span>pos<span>)</span><span>;</span>
  <span>// Convert the normal to a color</span>
  color <span>=</span> nor <span>*</span> <span>0.5</span> <span>+</span> <span>0.5</span><span>;</span>
<span>}</span>

<span>// ...</span></code></pre></div><h3 id="phong-lighting" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#phong-lighting" aria-label="phong lighting permalink" color="brand.main" font-family="systemSans"></a>Phong lighting</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">My personal philosophy is very much:</p><p><img alt="Fuck around find out" src="https://varun.ca/static/fuck-around-find-out-cc2e14bf2895e5634f02f2f2475d8531.jpg" display="block"></p><p font-family="systemSans" color="neutral.0" font-size="2,3">It’s important to understand how things work, but I’m less focused on implementing everything from scratch and more intrigued by applying those concepts to create my own sketches and scenes. That’s why I was super excited to come across <a href="http://stack.gl/packages" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">stack.gl/packages</a>.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">The stackgl ecosystem is full of little GLSL modules that you can glue these together to create all kinds of effects.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">Interested in adding lighting to the scene? What type would you prefer? Lambert, Phong, Beckmann, or Specular? Just grab the associated module and plug it into the scene.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">I chose <code>glsl-specular-blinn-phong</code></p><div data-language="glsl"><pre><code><span><span>#</span><span>pragma</span> <span>glslify<span>:</span> blinnPhongSpec <span>=</span> <span>require</span><span>(</span></span><span>'glsl-specular-blinn-phong'</span><span><span>)</span></span></span>

<span>// ...</span>

<span>vec3</span> lightPos <span>=</span> <span>vec3</span><span>(</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span><span>;</span>
<span>vec3</span> tint <span>=</span> <span>vec3</span><span>(</span><span>0.05</span><span>,</span> <span>0.0</span><span>,</span> <span>0.97</span><span>)</span><span>;</span> <span>// color of the shape</span>

<span>vec2</span> collision <span>=</span> <span>raymarch</span><span>(</span>rayOrigin<span>,</span> rayDirection<span>)</span><span>;</span>

<span>// If the ray collides, draw the surface</span>
<span>if</span> <span>(</span>collision<span>.</span>x <span>&gt;</span> <span>-</span><span>0.5</span><span>)</span> <span>{</span>
  <span>// Determine the point of collision</span>
  <span>vec3</span> pos <span>=</span> rayOrigin <span>+</span> rayDirection <span>*</span> collision<span>.</span>x<span>;</span>
  <span>// Calculate the normal</span>
  <span>vec3</span> nor <span>=</span> <span>normal</span><span>(</span>pos<span>)</span><span>;</span>

  <span>// Calculate light intensity</span>
  <span>vec3</span> eyeDirection <span>=</span> <span>normalize</span><span>(</span>rayOrigin <span>-</span> pos<span>)</span><span>;</span>
  <span>vec3</span> lightDirection <span>=</span> <span>normalize</span><span>(</span>lightPos <span>-</span> pos<span>)</span><span>;</span>
  <span>float</span> power <span>=</span> <span>blinnPhongSpec</span><span>(</span>lightDirection<span>,</span> eyeDirection<span>,</span> nor<span>,</span> <span>0.5</span><span>)</span><span>;</span>
  <span>// light intensity * color of the shape</span>
  color <span>=</span> power <span>*</span> tint<span>;</span>
<span>}</span></code></pre></div><h3 id="iridescent-material" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#iridescent-material" aria-label="iridescent material permalink" color="brand.main" font-family="systemSans"></a>Iridescent material</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">Stackgl isn’t the only place where you can find useful code. My other favourite option is Shadertoy. I’m not going to lie, most things on shadertoy were too daunting for me. I couldn’t even begin to figure out what the code was doing.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">That is, until I discovered that most work on shadertoy uses a combo of raymarching + SDF. This was certainly a lightbulb moment for me. It’s like suddenly this cryptic code was deciphered and I could understand what it said.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">I’ve been obsessed with iridescence and have been bookmarking cool shaders. Once I learnt the raymarching technique, that was it. I could revisit these shaders and try to understand how they work.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">One such shader was <a href="https://www.shadertoy.com/view/llcXWM" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">Thomas Hooper’s Crystals</a>. It’s way more complex than our scene but the general structure is the same. There’s a function for generating the geometry, there’s raymarching loop and after checking for collision is the bit where the iridescence effect is applied.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">Let’s add that to our scene.</p><div data-language="glsl"><pre><code><span>vec3</span> <span>pal</span><span>(</span> <span>in</span> <span>float</span> t<span>,</span> <span>in</span> <span>vec3</span> a<span>,</span> <span>in</span> <span>vec3</span> b<span>,</span> <span>in</span> <span>vec3</span> c<span>,</span> <span>in</span> <span>vec3</span> d <span>)</span> <span>{</span>
  <span>return</span> a <span>+</span> b<span>*</span><span>cos</span><span>(</span> <span>6.28318</span><span>*</span><span>(</span>c<span>*</span>t<span>+</span>d<span>)</span> <span>)</span><span>;</span>
<span>}</span>

<span>vec3</span> <span>spectrum</span><span>(</span><span>float</span> n<span>)</span> <span>{</span>
  <span>return</span> <span>pal</span><span>(</span> n<span>,</span> <span>vec3</span><span>(</span><span>0.5</span><span>,</span><span>0.5</span><span>,</span><span>0.5</span><span>)</span><span>,</span><span>vec3</span><span>(</span><span>0.5</span><span>,</span><span>0.5</span><span>,</span><span>0.5</span><span>)</span><span>,</span><span>vec3</span><span>(</span><span>1.0</span><span>,</span><span>1.0</span><span>,</span><span>1.0</span><span>)</span><span>,</span><span>vec3</span><span>(</span><span>0.0</span><span>,</span><span>0.33</span><span>,</span><span>0.67</span><span>)</span> <span>)</span><span>;</span>
<span>}</span>

<span>const</span> <span>float</span> GAMMA <span>=</span> <span>2.2</span><span>;</span>

<span>vec3</span> <span>gamma</span><span>(</span><span>vec3</span> color<span>,</span> <span>float</span> g<span>)</span> <span>{</span>
  <span>return</span> <span>pow</span><span>(</span>color<span>,</span> <span>vec3</span><span>(</span>g<span>)</span><span>)</span><span>;</span>
<span>}</span>

<span>vec3</span> <span>linearToScreen</span><span>(</span><span>vec3</span> linearRGB<span>)</span> <span>{</span>
  <span>return</span> <span>gamma</span><span>(</span>linearRGB<span>,</span> <span>1.0</span> <span>/</span> GAMMA<span>)</span><span>;</span>
<span>}</span>

<span>// ...</span>

<span>if</span> <span>(</span>collision<span>.</span>x <span>&gt;</span> <span>-</span><span>0.5</span><span>)</span> <span>{</span>
  <span>// Determine the point of collision</span>
  <span>vec3</span> pos <span>=</span> rayOrigin <span>+</span> rayDirection <span>*</span> collision<span>.</span>x<span>;</span>
  <span>vec3</span> nor <span>=</span> <span>normal</span><span>(</span>pos<span>)</span><span>;</span>

  <span>vec3</span> eyeDirection <span>=</span> <span>normalize</span><span>(</span>rayOrigin <span>-</span> pos<span>)</span><span>;</span>
  <span>vec3</span> lightDirection <span>=</span> <span>normalize</span><span>(</span>lightPos <span>-</span> pos<span>)</span><span>;</span>

  <span>// Iridescent lighting</span>
  <span>vec3</span> reflection <span>=</span> <span>reflect</span><span>(</span>rayDirection<span>,</span> nor<span>)</span><span>;</span>
  <span>vec3</span> dome <span>=</span> <span>vec3</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>0</span><span>)</span><span>;</span>
  <span>// base layer</span>
  <span>vec3</span> perturb <span>=</span> <span>sin</span><span>(</span>pos <span>*</span> <span>10.</span><span>)</span><span>;</span>
  color <span>=</span> <span>spectrum</span><span>(</span><span>dot</span><span>(</span>nor <span>+</span> perturb <span>*</span> <span>.05</span><span>,</span> eyeDirection<span>)</span> <span>*</span> <span>2.</span><span>)</span><span>;</span>
  <span>// specular</span>
  <span>float</span> specular <span>=</span> <span>clamp</span><span>(</span><span>dot</span><span>(</span>reflection<span>,</span> lightDirection<span>)</span><span>,</span> <span>0.</span><span>,</span> <span>1.</span><span>)</span><span>;</span>
  specular <span>=</span> <span>pow</span><span>(</span><span>(</span><span>sin</span><span>(</span>specular <span>*</span> <span>20.</span> <span>-</span> <span>3.</span><span>)</span> <span>*</span> <span>.5</span> <span>+</span> <span>.5</span><span>)</span> <span>+</span> <span>.1</span><span>,</span> <span>32.</span><span>)</span> <span>*</span> specular<span>;</span>
  specular <span>*=</span> <span>.1</span><span>;</span>
  specular <span>+=</span> <span>pow</span><span>(</span><span>clamp</span><span>(</span><span>dot</span><span>(</span>reflection<span>,</span> lightDirection<span>)</span><span>,</span> <span>0.</span><span>,</span> <span>1.</span><span>)</span> <span>+</span> <span>.3</span><span>,</span> <span>8.</span><span>)</span> <span>*</span> <span>.1</span><span>;</span>
  <span>// shadow</span>
  <span>float</span> shadow <span>=</span> <span>pow</span><span>(</span><span>clamp</span><span>(</span><span>dot</span><span>(</span>nor<span>,</span> dome<span>)</span> <span>*</span> <span>.5</span> <span>+</span> <span>1.2</span><span>,</span> <span>0.</span><span>,</span> <span>1.</span><span>)</span><span>,</span> <span>3.</span><span>)</span><span>;</span>
  color <span>=</span> color <span>*</span> shadow <span>+</span> specular<span>;</span>

  <span>// gamma correction</span>
  color <span>=</span> <span>linearToScreen</span><span>(</span>color<span>)</span><span>;</span>
<span>}</span></code></pre></div><p font-family="systemSans" color="neutral.0" font-size="2,3">There are three layers to the iridescent material: the base layer (the funky gradients), a little bit of shadow and specular (the concentric light bands). Try toggling them on and off with the slider see their effects.</p><h3 id="mix-phong-and-iridescence" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#mix-phong-and-iridescence" aria-label="mix phong and iridescence permalink" color="brand.main" font-family="systemSans"></a>Mix Phong and Iridescence</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">One last little tweak with the lighting. We can actually blend the phong and iridescence effects. Which enables you to have tinted iridescent objects.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">There’s not a whole lot to it. Calculate the colors for the two effects and then blend them with the <code>mix</code> function.</p><div data-language="glsl"><pre><code><span>if</span> <span>(</span>collision<span>.</span>x <span>&gt;</span> <span>-</span><span>0.5</span><span>)</span> <span>{</span>
  <span>// ...</span>
  <span>// Basic blinn phong lighting</span>
  <span>float</span> power <span>=</span> <span>blinnPhongSpec</span><span>(</span>lightDirection<span>,</span> eyeDirection<span>,</span> nor<span>,</span> <span>0.5</span><span>)</span><span>;</span>
  <span>vec3</span> baseColor <span>=</span> power <span>*</span> tint<span>;</span>

  <span>// Iridescent lighting</span>
  <span>// ...</span>
  color <span>=</span> color <span>*</span> shadow <span>+</span> specular<span>;</span>

  <span>// mix blinn phong lighting and iridescent lighting</span>
  color <span>=</span> <span>mix</span><span>(</span>baseColor<span>,</span> color<span>,</span> mixBaseAndIridescent<span>)</span><span>;</span>
  <span>// gamma correction</span>
  color <span>=</span> <span>linearToScreen</span><span>(</span>color<span>)</span><span>;</span>
<span>}</span></code></pre></div><h3 id="crystal-geometry" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#crystal-geometry" aria-label="crystal geometry permalink" color="brand.main" font-family="systemSans"></a>Crystal geometry</h3><p font-family="systemSans" color="neutral.0" font-size="2,3">We’ve nailed the look, but what about the crystal shape?</p><p font-family="systemSans" color="neutral.0" font-size="2,3">You can file this under “stuff I don’t quite understand, but that’s not going to stop me from using it.” The crystal geometry is a Rhombic Triacontahedron, which I discovered in a <a href="https://www.youtube.com/watch?v=0RWaR7zApEo&amp;t=50s" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">The Art Of Code tutorial</a>.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">This shape is created by folding a plane onto itself using some “magic numbers” and along a “magic direction.” We repeat the process a few times until we achieve the desired crystal shape.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">Try using the slider to observe how the shape changes with each fold.</p><div data-language="glsl"><pre><code><span>float</span> <span>sdCrystal</span><span>(</span><span>vec3</span> p<span>)</span> <span>{</span>
  <span>float</span> c <span>=</span> <span>cos</span><span>(</span><span>3.1415</span><span>/</span><span>5.</span><span>)</span><span>,</span> s<span>=</span><span>sqrt</span><span>(</span><span>0.75</span><span>-</span>c<span>*</span>c<span>)</span><span>;</span> <span>// magic numbers</span>
  <span>vec3</span> n <span>=</span> <span>vec3</span><span>(</span><span>-</span><span>0.5</span><span>,</span> <span>-</span>c<span>,</span> s<span>)</span><span>;</span> <span>// magic direction</span>

  <span>// fold the space to add symmetry</span>
  p <span>=</span> <span>abs</span><span>(</span>p<span>)</span><span>;</span>
  <span>// fold along the n direction</span>
  p <span>-=</span> <span>2.</span><span>*</span><span>min</span><span>(</span><span>0.</span><span>,</span> <span>dot</span><span>(</span>p<span>,</span> n<span>)</span><span>)</span><span>*</span>n<span>;</span>

  <span>// fold the space again and along the n direction</span>
  p<span>.</span>xy <span>=</span> <span>abs</span><span>(</span>p<span>.</span>xy<span>)</span><span>;</span>
  p <span>-=</span> <span>2.</span><span>*</span><span>min</span><span>(</span><span>0.</span><span>,</span> <span>dot</span><span>(</span>p<span>,</span> n<span>)</span><span>)</span><span>*</span>n<span>;</span>

  <span>// repeat the process</span>
  p<span>.</span>xy <span>=</span> <span>abs</span><span>(</span>p<span>.</span>xy<span>)</span><span>;</span>
  p <span>-=</span> <span>2.</span><span>*</span><span>min</span><span>(</span><span>0.</span><span>,</span> <span>dot</span><span>(</span>p<span>,</span> n<span>)</span><span>)</span><span>*</span>n<span>;</span>

  <span>// distance to the surface</span>
  <span>float</span> d <span>=</span> p<span>.</span>z <span>-</span> <span>1.</span><span>;</span>
  <span>return</span> d<span>;</span>
<span>}</span></code></pre></div></div></div><h2 id="and-thats-that" font-family="systemSans" color="neutral.0" font-size="4,5" font-weight="7"><a href="#and-thats-that" aria-label="and thats that permalink" color="brand.main" font-family="systemSans"></a>And that’s that!</h2><p font-family="systemSans" color="neutral.0" font-size="2,3">Raymarching with SDF isn’t better than the conventional mesh based approach; it’s just different. However, it offers the ability to create unique and visually striking effects, making it a fantastic tool to have in your creative coding toolbox. Plus, with glslify and the <a href="http://stack.gl/packages" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">stack.gl ecosystem</a> you can use off-the-shelf modules to get going quickly.</p><p font-family="systemSans" color="neutral.0" font-size="2,3">Checkout the <a href="https://github.com/winkerVSbecks/shader-sketches/blob/main/sketches/sdf-iridescent-crystal.js" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">full source</a> for the crystal sketch on Github. Want to take it a step further? I’ve expanded this sketch to combine refraction and iridescence to make a <a href="https://github.com/winkerVSbecks/shader-sketches/blob/main/sketches/refraction-iridescent.js" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">see through crystal</a>.</p><h3 id="reference" font-family="systemSans" color="neutral.0" font-size="3,4" font-weight="7"><a href="#reference" aria-label="reference permalink" color="brand.main" font-family="systemSans"></a>Reference</h3><ul><li font-family="systemSans" color="neutral.0" font-size="2,3"><a href="https://jasmcole.com/2019/10/03/signed-distance-fields/" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">Signed distance fields by Jason Cole</a></li><li font-family="systemSans" color="neutral.0" font-size="2,3"><a href="https://iquilezles.org/articles/distfunctions/" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">3D distance functions by Inigo Quilez</a></li><li font-family="systemSans" color="neutral.0" font-size="2,3"><a href="https://www.shadertoy.com/view/ldfSWs" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">Raymarching template</a></li><li font-family="systemSans" color="neutral.0" font-size="2,3"><a href="https://youtu.be/NCpaaLkmXI8" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">Bending Light by The Art of Code (part 1)</a> &amp; <a href="https://youtu.be/0RWaR7zApEo" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">part 2</a></li></ul></article><p font-size="2" font-family="systemSans" color="neutral.0">Questions, Comments or Suggestions?<!-- --> <a href="https://github.com/winkerVSbecks/varun.ca/issues/new?title=Iridescent%20crystal%20with%20raymarching%20and%20signed%20distance%20fields" target="_blank" rel="noopener noreferrer" color="brand.main" font-family="systemSans">Open an Issue</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Monday was hottest day for global average temperature, as climate crisis bites (126 pts)]]></title>
            <link>https://www.theguardian.com/world/2023/jul/04/monday-was-hottest-day-for-global-average-temperature-on-record-as-climate-crisis-bites</link>
            <guid>36591402</guid>
            <pubDate>Tue, 04 Jul 2023 19:18:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/world/2023/jul/04/monday-was-hottest-day-for-global-average-temperature-on-record-as-climate-crisis-bites">https://www.theguardian.com/world/2023/jul/04/monday-was-hottest-day-for-global-average-temperature-on-record-as-climate-crisis-bites</a>, See on <a href="https://news.ycombinator.com/item?id=36591402">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>This Monday, 3 July 2023, was the hottest day ever recorded globally, according to data from the US National Centers for Environmental Prediction.</p><p>The average global temperature reached 17.01C (62.62F), surpassing the August 2016 record of 16.92C (62.46F), as heatwaves sizzled around the world.</p><figure id="80976557-4cfe-4dfe-a401-391b7535fb9d" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" deferuntil="idle" props="{&quot;richLinkIndex&quot;:2,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/environment/2023/jul/04/climate-heating-el-nino-has-arrived-and-threatens-lives-declares-un&quot;,&quot;text&quot;:&quot;Climate-heating El Niño has arrived and threatens lives, declares UN&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;elementId&quot;:&quot;80976557-4cfe-4dfe-a401-391b7535fb9d&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0}}"></gu-island></figure><p>The southern US has <a href="https://www.theguardian.com/us-news/2023/jul/01/texas-extreme-heat-heatwave">been suffering</a> under an <a href="https://www.theguardian.com/us-news/2023/jul/03/heat-dome-keeps-new-orleans-broiling-with-heat-index-as-high-as-110f">intense heat dome</a> in recent weeks amid <a href="https://www.theguardian.com/world/extreme-weather">extreme weather</a>, probably driven by the human-caused climate crisis, <a href="https://www.theguardian.com/environment/2023/jun/27/heatwave-human-caused-climate-crisis-texas-louisiana-mexico">experts said</a>. In parts of China, an <a href="https://www.theguardian.com/world/2023/jun/30/as-beijing-swelters-activists-hope-the-heat-will-prompt-climate-action">enduring heatwave</a> continued, with temperatures above 35C (95F). North Africa has seen temperatures near 50C (122F), with, in the Middle East, <a href="https://www.theguardian.com/world/2023/jun/30/thousands-suffer-heat-stress-on-hajj-pilgrimage-as-temperatures-reach-48c">thousands suffering</a> from unusually scorching heat during the hajj religious pilgrimage in Saudi Arabia.</p><p>And even <a href="https://www.theguardian.com/world/antarctica">Antarctica</a>, currently in its winter, registered anomalously high temperatures, as <a href="https://www.theguardian.com/science/2023/may/25/slowing-ocean-current-caused-by-melting-antarctic-ice-could-have-drastic-climate-impact-study-says">glacier melt</a> accelerates and the sun intensifies. Ukraine’s Vernadsky research base, in the vast frozen continent’s Argentine Islands, recently broke its July temperature record with a reading of 8.7C (47.6F).</p><p>Jeni Miller, executive director of the California-based Global Climate and Health Alliance, an international consortium of health organizations, said: “People around the world are already enduring climate impacts, from heatwaves, wildfires and air pollution to floods and extreme storms. Global warming is also exacerbating crop losses and the spread of infectious diseases, as well as migration.”</p><p>She added: “The extraction and use of coal, oil and gas harm people’s health, are the primary driver of warming and are incompatible with a healthy climate future. That’s all the more reason that governments must prepare to deliver a commitment at <a href="https://www.theguardian.com/environment/cop28">Cop28</a> to phase out all fossil fuels, and a just transition to renewable energy for all.”</p><p>Climate scientist Friederike Otto of the Grantham Institute for Climate Change and the Environment at Britain’s Imperial College London, said: “It’s a death sentence for people and ecosystems.”</p><p>Scientists lamented the climate crisis, accelerated by the <a href="https://www.theguardian.com/environment/2023/jul/04/climate-heating-el-nino-has-arrived-and-threatens-lives-declares-un">El Niño weather pattern</a>, the latest of which the United Nations’ World Meteorological Organization (WMO) warned this week had begun. The last major <a href="https://www.theguardian.com/environment/elnino">El Niño</a> was in 2016, which was the hottest year on record – until now.</p><figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.NewsletterSignupBlockElement"><a data-ignore="global-link-styling" href="#EmailSignup-skip-link-9">skip past newsletter promotion</a><p id="EmailSignup-skip-link-9" tabindex="0" aria-label="after newsletter promotion" role="note">after newsletter promotion</p></figure><p>Of the new temperature record announced on Tuesday, Zeke Hausfather, a research scientist at Berkeley Earth, said: “Unfortunately, it promises to only be the first in a series of new records set this year as increasing emissions of [carbon dioxide] and greenhouse gases, coupled with a growing El Niño event, push temperatures to new highs.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Type system updates: moving from research into development (193 pts)]]></title>
            <link>https://elixir-lang.org/blog/2023/06/22/type-system-updates-research-dev/</link>
            <guid>36591313</guid>
            <pubDate>Tue, 04 Jul 2023 19:11:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://elixir-lang.org/blog/2023/06/22/type-system-updates-research-dev/">https://elixir-lang.org/blog/2023/06/22/type-system-updates-research-dev/</a>, See on <a href="https://news.ycombinator.com/item?id=36591313">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
        <p>A year ago, at ElixirConf EU 2022, we announced an effort to research
and develop a type system for Elixir (<a href="https://www.youtube.com/watch?v=Jf5Hsa1KOc8">video presentation</a>)
(<a href="https://elixir-lang.org/blog/2022/10/05/my-future-with-elixir-set-theoretic-types/">written report</a>).</p>

<p>This work is happening under the lead of <a href="https://www.irif.fr/~gc/">Giuseppe Castagna</a>,
CNRS Senior Researcher, and taken by
<a href="https://www.irif.fr/users/gduboc/index">Guillaume Duboc</a> as part of his
PhD studies, with further guidance from myself (José Valim).</p>

<p>This article is a summary of where we are in our efforts and where we
are going.</p>

<h2 id="out-of-research">Out of research</h2>

<p>Our main goal during research is to find a type system that can model
most of Elixir’s functional semantics and develop brand new theory on
the areas we found to be incompatible or lacking. We believe we were
able to achieve this goal with a gradual set-theoretic type system
and we are now ready to head towards development. Over the last 2 months,
we have published plenty of resources on our results:</p>

<ul>
  <li><a href="https://arxiv.org/abs/2306.06391">A technical report on the design principles of the Elixir type system</a></li>
  <li><a href="https://youtube.com/watch?v=gJJH7a2J9O8">A technical presentation by Guillaume Duboc at ElixirConf 2023 on the work above</a></li>
  <li><a href="https://smartlogic.io/podcast/elixir-wizards/s10-e12-jose-guillaume-giuseppe-types-elixir/">An informal discussion with Giuseppe Castagna, Guillaume Duboc, and José Valim on the SmartLogic podcast</a></li>
  <li><a href="https://www.twitch.tv/videos/1841707383">An informal Q&amp;A with Guillaume Duboc, José Valim, and the community on Twitch</a></li>
</ul>

<p>Our focus so far has been on the semantics. While we have introduced a
new syntax capable of expressing the semantics of the new set-theoretic
type system, the syntax is not final as there are still no concrete
plans for user-facing changes to the language. Once we are confident
those changes will happen, we will have plenty of discussion with the
community about the type system interface and its syntax.</p>

<p>The work so far has been made possible thanks to a partnership between
the <a href="https://www.cnrs.fr/fr">CNRS</a> and <a href="https://remote.com/">Remote</a>,
with sponsorships from <a href="https://www.fresha.com/">Fresha</a>,
<a href="https://supabase.com/">Supabase</a>, and <a href="https://dashbit.co/">Dashbit</a>.</p>



<p>While there is still on-going research, our focus for the second semester
of 2023 onwards is on development.</p>

<p>Incorporating a type system into a language used at scale can be a daunting
task. Our concerns range from how the community will interact and use the
type system to how it will perform on large codebases. Therefore, our plan
is to gradually introduce our gradual (pun intended) type system into the
Elixir compiler.</p>

<p>In the first release, types will be used just internally by the compiler.
The type system will extract type information from patterns and guards to
find the most obvious mistakes, such as typos in field names or type
mismatches from attempting to add an integer to a string, without introducing
any user-facing changes to the language. At this stage, our main goal is
to assess the performance impact of the type system and the quality of
the reports we can generate in case of typing violations. If we are
unhappy with the results, we still have time to reassess our work or drop
the initiative altogether.</p>

<p>The second milestone is to introduce type annotations only in structs,
which are named and statically-defined in Elixir codebases. Elixir programs
frequently pattern match on structs, which reveals information about
the struct fields, but it knows nothing about their respective types.
By propagating types from structs and their fields throughout the program,
we will increase the type system’s ability to find errors while further
straining our type system implementation.</p>

<p>The third milestone is to introduce the (most likely) <code>$</code>-prefixed type
annotations for functions, with no or very limited type reconstruction:
users can annotate their code with types, but any untyped parameter
will be assumed to be of the <code>dynamic()</code> type. If successful, then we
will effectively have introduced a type system into the language.</p>

<p>This new exciting development stage is sponsored by <a href="https://www.fresha.com/">Fresha</a> (<a href="https://www.fresha.com/careers/openings?department=engineering">they are hiring!</a>),
<a href="https://starfish.team/">Starfish*</a> (<a href="https://starfish.team/jobs/experienced-elixir-developer">they are hiring!</a>),
and <a href="https://dashbit.co/">Dashbit</a>.</p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to build a website without frameworks and tons of libraries (393 pts)]]></title>
            <link>https://www.kodingkitty.com/blog/how-to-build-a-website/</link>
            <guid>36591032</guid>
            <pubDate>Tue, 04 Jul 2023 18:47:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.kodingkitty.com/blog/how-to-build-a-website/">https://www.kodingkitty.com/blog/how-to-build-a-website/</a>, See on <a href="https://news.ycombinator.com/item?id=36591032">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>
An innocent question <a href="https://www.indiehackers.com/post/21-websites-for-free-illustrations-29a45232db" target="_blank">was posted</a> on IndieHackers the other day:
<span>"I'm asking what did you use to build your website"</span>.
    </p><p>
The question also had a second part.
So just to be fair, here it is in its entirety: <span>"I'm asking what did you use to build your website, I really love the design and feeling of kodingkitty."</span></p><p>
But this post is not about people loving our website.
Although we're obviously happy about that.
    </p><p>
Too lazy to read? <a href="#kittys-tool-chain">Check out Koding Kitty's simple toolchain</a>.
      </p><h2>The shocking truth</h2><p>
The question sparked an idea to write about the tech stack that KodingKitty team uses for its own web.
And we warn you beforehand: it's so simple that some of you might find it shocking.
    </p><p>
You have been warned.
    </p><h2>Hype is just a coincidence</h2><p>
Our tech stack has nothing to do with the current hype about lightweight or simplified web development.
Not everyone rides that wave, and that's fine.
    </p><p>
On the other hand, we believe that in many cases, "back to the roots" or "simplicity is the ultimate perfection" is a better solution for customers than convoluted web of overused frameworks and libraries.
    </p><p>
To put it another way, the solution we designed for our website and the current hype is just a coincidence.
Our stack is simple because we wanted something pragmatic with minimal friction for the developers.
    </p><p>
And even though we wanted Koding Kitty website to have a distinctive yet subtle design, it is important to mention that it could have been achieved in many other ways.
    </p><h2>Comparing options</h2><p>
Our website and the way it is built comes from our past experience.
    </p><p>
We had the chance to work with different web frameworks in the past.
We know this is a luxury not everyone has.
It has allowed us to compare different technologies and decide what works best for us.
    </p><p>
From the beginning we agreed to start with a static website.
After all, what does a kitty's web really need?
A front page, a showcase, a blog ... and probably not much more.
At least in the beginning.
    </p><h2>Our requirements</h2><p>
We set the following set of requirements:
    </p><ul><li>Fast website</li><li>Fast to develop</li><li>Inexpensive hosting</li><li>Minimal complexity</li></ul><p>
What are the options today to have a website with the above requirements?
    </p><h2>Wordpress (and similar CMS)</h2><p>
Nothing against WordPress, it's done a tremendous job for the internet but&nbsp;...<br>
...&nbsp;honestly, it's a bit overkill for our modest needs.
    </p><p>
We don't need to store our content in a database.
We don't need to deal with plugins.
We don't need a visual editor to write our content.
    </p><h2>No-Code</h2><p>
Yes, that's one area where there's a lot of the hype these days.
    </p><p>
But to be a web coder and use a no-code tool?
Seriously?
It sounds weird.
    </p><p>
We want to own our content.
We want to do whatever we want with our web.
We can code a website faster than we can build it in the no-code WYSIWYG editor.
    </p><p>
The last point is that such tool still requires initial (and then ongoing) learning.
    </p><h2>Frameworks</h2><p>
We have an experience with frameworks.
    </p><p>
But, did we want to do the whole setup?
Although it can be done quickly, we would end up with too many parts.
Like a database, configuration, libraries, admin, and so on.
Yes, it is a fully customizable solution, but we would end up with something that resembles WordPress.
    </p><p>
And that's not what we wanted.
    </p><h2>Jamstack (aka Site generators)</h2><p>
Static site generators look like a tempting option for our needs, don't they?
    </p><p>
Just pick a programming language, do some coding, press a button (or run a script) and voila&nbsp;...<br>
...&nbsp;your fast static site is generated.
    </p><p>
Unfortunately, Jamstack tools require an initial setup and an initial (and continuous) learning.
    </p><p>
We understand, that writing a blog in markdown is convenient, but taking all things into consideration we decided for simpler solution.
    </p><h2>KittyStack</h2><p>
Our solution is obvious, when you review our requirements (repeated below for your convenience):
    </p><ul><li>Fast website</li><li>Fast to develop</li><li>Inexpensive hosting</li><li>Minimal complexity</li></ul><p>
Let's discuss them one by one:
    </p><h2>Fast website</h2><p>
Is a static website fast?<br>
Yes, it is!
    </p><h2>Fast development</h2><p>
Now, you may be thinking: "If you're not writing your content in markdown, you're not using a fancy editor, then what are you using?"
    </p><p>
We write our content in HTML!
    </p><p>
Take a look at our website.
For the kind of posts we publish there, HTML is ideal.
We mix the text with HTML/CSS/JS widgets, so it makes sense to have a post written directly in HTML.
    </p><h2>Inexpensive hosting</h2><p>
Is hosting a static site inexpensive?
    </p><p>
It depends on the provider and all the bells and whistles you decide you need.
    </p><p>
We decided to go with the absolute minimum, because hosting static sites doesn't require a massive hardware setup.
    </p><p>
Mind you, Hetzner <a href="https://www.hetzner.com/webhosting" target="_blank">webhosting</a> starts at 2 EUR!
How crazy is that?
    </p><p>
And if you are worried that your site will not survive a massive spike in traffic - like when your post hits the front page of Hacker News - it probably will.
At least our site did.
    </p><h2>Minimal complexity</h2><p>
We insisted on minimal complexity, but some of our pages and posts have repeating patterns.
    </p><p>
While it is possible to use a copy+paste routine, it can quickly get out of control.
Using some form of loops would help a lot.
Also, the ability to include some blocks of code - like header, footer, and the alike - would be beneficial.
    </p><h2>Templating to the rescue</h2><p>
And so we come to the last piece of the puzzle.
    </p><p>
Meet <a href="https://palletsprojects.com/p/jinja/" target="_blank">Jinja</a> templates, which make our life much easier.
Jinja allows us to use loops, include files (navigation bar, footer, etc.) and much more.
    </p><p>
Plus, we didn't have to learn a new system as we were already using frameworks based on Jinja before.
    </p><h2 id="kittys-tool-chain">A simple toolchain</h2><p>
Now you might be wondering how we generate the final, static page.
    </p><p>
We use a short Python script with exactly 45 lines of code.
<span>Including comments and blank lines.</span></p><p>
In summary, this is the simple toolchain for building our web:
    </p><ul><li>Developer updates index.src.html</li><li>Watchdog.py detects the file change and ...</li><li>... renders Jinja template into index.html and ...</li><li>... calls <a href="https://tailwindcss.com/blog/standalone-cli" target="_blank">Tailwind CSS CLI</a> to generate styles.min.css.</li></ul><!-- Widget --><div><svg viewBox="0 0 24 24" stroke-width="0.5" stroke="#ffffff" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"></path><path d="M10 2l-.15 .005a2 2 0 0 0 -1.85 1.995v6.999l-2.586 .001a2 2 0 0 0 -1.414 3.414l6.586 6.586a2 2 0 0 0 2.828 0l6.586 -6.586a2 2 0 0 0 .434 -2.18l-.068 -.145a2 2 0 0 0 -1.78 -1.089l-2.586 -.001v-6.999a2 2 0 0 0 -2 -2h-4z" stroke-width="0" fill="currentColor"></path></svg><div><svg viewBox="0 0 24 24" stroke-width="1.5" stroke="#ffffff" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"></path><path d="M10.325 4.317c.426 -1.756 2.924 -1.756 3.35 0a1.724 1.724 0 0 0 2.573 1.066c1.543 -.94 3.31 .826 2.37 2.37a1.724 1.724 0 0 0 1.065 2.572c1.756 .426 1.756 2.924 0 3.35a1.724 1.724 0 0 0 -1.066 2.573c.94 1.543 -.826 3.31 -2.37 2.37a1.724 1.724 0 0 0 -2.572 1.065c-.426 1.756 -2.924 1.756 -3.35 0a1.724 1.724 0 0 0 -2.573 -1.066c-1.543 .94 -3.31 -.826 -2.37 -2.37a1.724 1.724 0 0 0 -1.065 -2.572c-1.756 -.426 -1.756 -2.924 0 -3.35a1.724 1.724 0 0 0 1.066 -2.573c-.94 -1.543 .826 -3.31 2.37 -2.37c1 .608 2.296 .07 2.572 -1.065z"></path><path d="M9 12a3 3 0 1 0 6 0a3 3 0 0 0 -6 0"></path></svg><p><span>watchdog.py</span><span>renders Jinja template</span><span>calls Tailwind CLI</span></p></div><svg viewBox="0 0 24 24" stroke-width="0.5" stroke="#ffffff" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"></path><path d="M10 2l-.15 .005a2 2 0 0 0 -1.85 1.995v6.999l-2.586 .001a2 2 0 0 0 -1.414 3.414l6.586 6.586a2 2 0 0 0 2.828 0l6.586 -6.586a2 2 0 0 0 .434 -2.18l-.068 -.145a2 2 0 0 0 -1.78 -1.089l-2.586 -.001v-6.999a2 2 0 0 0 -2 -2h-4z" stroke-width="0" fill="currentColor"></path></svg></div><p>
It's also important to mention following:
    </p><ul><li>During development, <a href="https://www.npmjs.com/package/live-server" target="_blank">Live Server</a> serves files and reloads them as they change.</li><li>When it's time to publish, the files are uploaded <span>manually</span> via <a href="https://en.wikipedia.org/wiki/File_Transfer_Protocol" target="_blank">FTP</a>.</li></ul><h2>Conclusion</h2><p>
Web development can be kept simple without sacrificing too much.
    </p><p>
In fact, it can be liberating to limit yourself to just a few options.
And based on what we've seen so far, many customers would benefit from having solutions that are faster, simpler and cheaper.
    </p><p>
But don't just take our word for it.
Take a look around the web and ask yourself: could the same result be achieved using a less complex tech stack?
    </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: MongoDB Protocol for SQLite (110 pts)]]></title>
            <link>https://github.com/FerretDB/FerretDB</link>
            <guid>36590834</guid>
            <pubDate>Tue, 04 Jul 2023 18:35:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/FerretDB/FerretDB">https://github.com/FerretDB/FerretDB</a>, See on <a href="https://news.ycombinator.com/item?id=36590834">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">FerretDB</h2>
<p dir="auto"><a href="https://pkg.go.dev/github.com/FerretDB/FerretDB/ferretdb" rel="nofollow"><img src="https://camo.githubusercontent.com/300b5958449c8a6351a204c43e55669a0befcfb8c6fe925a1d73487636421088/68747470733a2f2f706b672e676f2e6465762f62616467652f6769746875622e636f6d2f46657272657444422f46657272657444422f66657272657464622e737667" alt="Go Reference" data-canonical-src="https://pkg.go.dev/badge/github.com/FerretDB/FerretDB/ferretdb.svg"></a></p>
<p dir="auto"><a href="https://github.com/FerretDB/FerretDB/actions/workflows/go.yml"><img src="https://github.com/FerretDB/FerretDB/actions/workflows/go.yml/badge.svg?branch=main" alt="Go"></a>
<a href="https://codecov.io/gh/FerretDB/FerretDB" rel="nofollow"><img src="https://camo.githubusercontent.com/e3b356c5102c6a029736b7b9995e1efc212f16c550eab9c4f54c99e0820b12e4/68747470733a2f2f636f6465636f762e696f2f67682f46657272657444422f46657272657444422f6272616e63682f6d61696e2f67726170682f62616467652e7376673f746f6b656e3d4a5a353658465433444d" alt="codecov" data-canonical-src="https://codecov.io/gh/FerretDB/FerretDB/branch/main/graph/badge.svg?token=JZ56XFT3DM"></a></p>
<p dir="auto"><a href="https://github.com/FerretDB/FerretDB/actions/workflows/security.yml"><img src="https://github.com/FerretDB/FerretDB/actions/workflows/security.yml/badge.svg?branch=main" alt="Security"></a>
<a href="https://github.com/FerretDB/FerretDB/actions/workflows/packages.yml"><img src="https://github.com/FerretDB/FerretDB/actions/workflows/packages.yml/badge.svg?branch=main" alt="Packages"></a>
<a href="https://github.com/FerretDB/FerretDB/actions/workflows/docs.yml"><img src="https://github.com/FerretDB/FerretDB/actions/workflows/docs.yml/badge.svg?branch=main" alt="Docs"></a></p>
<p dir="auto">FerretDB was founded to become the de-facto open-source substitute to MongoDB.
FerretDB is an open-source proxy, converting the MongoDB 6.0+ wire protocol queries to SQL -
using PostgreSQL or SQLite as a database engine.</p>
<h2 tabindex="-1" dir="auto">Why do we need FerretDB?</h2>
<p dir="auto">MongoDB was originally an eye-opening technology for many of us developers,
empowering us to build applications faster than using relational databases.
In its early days, its ease-to-use and well-documented drivers made MongoDB one of the simplest database solutions available.
However, as time passed, MongoDB abandoned its open-source roots;
changing the license to <a href="https://www.mongodb.com/licensing/server-side-public-license" rel="nofollow">SSPL</a> - making it unusable for many open source and early-stage commercial projects.</p>
<p dir="auto">Most MongoDB users do not require any advanced features offered by MongoDB;
however, they need an easy-to-use open-source document database solution.
Recognizing this, FerretDB is here to fill that gap.</p>
<h2 tabindex="-1" dir="auto">Scope and current state</h2>
<p dir="auto">FerretDB is compatible with MongoDB drivers and popular MongoDB tools.
It functions as a drop-in replacement for MongoDB 6.0+ in many cases.
Features are constantly being added to further increase compatibility and performance.</p>
<p dir="auto">We welcome all contributors.
See our <a href="https://github.com/orgs/FerretDB/projects/2/views/1">public roadmap</a>,
a list of <a href="https://docs.ferretdb.io/diff/" rel="nofollow">known differences with MongoDB</a>,
and <a href="https://github.com/FerretDB/FerretDB/blob/main/CONTRIBUTING.md">contributing guidelines</a>.</p>
<h2 tabindex="-1" dir="auto">Quickstart</h2>
<p dir="auto">Run this command to start FerretDB with PostgreSQL backend:</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker run -d --rm --name ferretdb -p 27017:27017 ghcr.io/ferretdb/all-in-one"><pre>docker run -d --rm --name ferretdb -p 27017:27017 ghcr.io/ferretdb/all-in-one</pre></div>
<p dir="auto">Alternatively, run this command to start FerretDB with SQLite backend:</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker run -d --rm --name ferretdb -p 27017:27017 \
  -v ./data:/data/ -e FERRETDB_HANDLER=sqlite -e FERRETDB_SQLITE_URL=file:/data/ \
  ghcr.io/ferretdb/all-in-one"><pre>docker run -d --rm --name ferretdb -p 27017:27017 \
  -v ./data:/data/ -e FERRETDB_HANDLER=sqlite -e FERRETDB_SQLITE_URL=file:/data/ \
  ghcr.io/ferretdb/all-in-one</pre></div>
<p dir="auto">This command will start a container with FerretDB, PostgreSQL, and MongoDB Shell for quick testing and experiments.
However, it is unsuitable for production use cases because it keeps all data inside and loses it on shutdown.
See our <a href="https://docs.ferretdb.io/quickstart-guide/docker/" rel="nofollow">Docker quickstart guide</a> for instructions
that don't have those problems.</p>
<p dir="auto">With that container running, you can:</p>
<ul dir="auto">
<li>Connect to it with any MongoDB client application using MongoDB URI <code>mongodb://127.0.0.1:27017/</code>.</li>
<li>Connect to it using MongoDB Shell by just running <code>mongosh</code>.
If you don't have it installed locally, you can run <code>docker exec -it ferretdb mongosh</code>.</li>
<li>For PostgreSQL backend, connect to it by running <code>docker exec -it ferretdb psql -U username ferretdb</code>.
FerretDB uses PostgreSQL schemas for MongoDB databases.
So, if you created some collections in the <code>test</code> database using any MongoDB client,
you can switch to it by running <code>SET search_path = 'test';</code> query
and see a list of PostgreSQL tables by running <code>\d</code> <code>psql</code> command.</li>
<li>For the SQLite backend, database files will be created on a host in the <code>data</code> directory.
You can access them by running <code>sqlite3 data/&lt;filename&gt;.sqlite</code> after some data is inserted into FerretDB.</li>
</ul>
<p dir="auto">You can stop the container with <code>docker stop ferretdb</code>.</p>
<p dir="auto">We also provide binaries and packages for various Linux distributions,
as well as <a href="https://pkg.go.dev/github.com/FerretDB/FerretDB/ferretdb" rel="nofollow">Go library package</a> that embeds FerretDB into your application.
See <a href="https://docs.ferretdb.io/quickstart-guide/" rel="nofollow">our documentation</a> for more details.</p>
<h2 tabindex="-1" dir="auto">Building and packaging</h2>
<p dir="auto">We strongly advise users not to build FerretDB themselves.
Instead, use binaries, Docker images, or <code>.deb</code>/<code>.rpm</code> packages provided by us.</p>
<p dir="auto">If you want to package FerretDB for your operating system or distribution,
the recommended way to build the binary is to use the <code>build-release</code> task;
see our <a href="https://github.com/FerretDB/FerretDB/blob/main/CONTRIBUTING.md">instructions for contributors</a> for more details.
FerretDB could also be built as any other Go program,
but a few generated files and build tags could affect it.
See <a href="https://pkg.go.dev/github.com/FerretDB/FerretDB/build/version" rel="nofollow">there</a> for more details.</p>
<h2 tabindex="-1" dir="auto">Managed FerretDB at cloud providers</h2>
<ul dir="auto">
<li><a href="https://www.civo.com/" rel="nofollow">Civo</a> (see <a href="https://www.civo.com/marketplace/FerretDB" rel="nofollow">here</a>).</li>
<li><a href="https://www.scaleway.com/" rel="nofollow">Scaleway</a> (request access <a href="https://www.scaleway.com/en/betas/#managed-document-database" rel="nofollow">here</a>).</li>
</ul>
<h2 tabindex="-1" dir="auto">Documentation</h2>
<ul dir="auto">
<li><a href="https://docs.ferretdb.io/" rel="nofollow">Documentation for users</a>.</li>
<li><a href="https://pkg.go.dev/github.com/FerretDB/FerretDB/ferretdb" rel="nofollow">Documentation for Go developers about embeddable FerretDB</a>.</li>
</ul>
<h2 tabindex="-1" dir="auto">Community</h2>
<ul dir="auto">
<li>Website and blog: <a href="https://ferretdb.io/" rel="nofollow">https://ferretdb.io</a>.</li>
<li>Twitter: <a href="https://twitter.com/ferret_db" rel="nofollow">@ferret_db</a>.</li>
<li>Mastodon: <a href="https://techhub.social/@ferretdb" rel="nofollow">@ferretdb@techhub.social</a>.</li>
<li><a href="https://join.slack.com/t/ferretdb/shared_invite/zt-zqe9hj8g-ZcMG3~5Cs5u9uuOPnZB8~A" rel="nofollow">Slack chat</a> for quick questions.</li>
<li><a href="https://github.com/FerretDB/FerretDB/discussions">GitHub Discussions</a> for longer topics.</li>
<li><a href="https://github.com/FerretDB/FerretDB/issues">GitHub Issues</a> for bugs and missing features.</li>
<li><a href="https://calendar.google.com/event?action=TEMPLATE&amp;tmeid=NjNkdTkyN3VoNW5zdHRiaHZybXFtb2l1OWtfMjAyMTEyMTNUMTgwMDAwWiBjX24zN3RxdW9yZWlsOWIwMm0wNzQwMDA3MjQ0QGc&amp;tmsrc=c_n37tquoreil9b02m0740007244%40group.calendar.google.com&amp;scp=ALL" rel="nofollow">Open Office Hours meeting</a>
every Monday at 18:00 UTC at <a href="https://meet.google.com/mcb-arhw-qbq" rel="nofollow">Google Meet</a>.</li>
</ul>
<p dir="auto">If you want to contact FerretDB Inc., please use <a href="https://www.ferretdb.io/contact/" rel="nofollow">this form</a>.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dark Waters of Self-Delusion: The crash of Transair flight 810 (134 pts)]]></title>
            <link>https://admiralcloudberg.medium.com/dark-waters-of-self-delusion-the-crash-of-transair-flight-810-a4eeb033bc00</link>
            <guid>36590806</guid>
            <pubDate>Tue, 04 Jul 2023 18:32:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://admiralcloudberg.medium.com/dark-waters-of-self-delusion-the-crash-of-transair-flight-810-a4eeb033bc00">https://admiralcloudberg.medium.com/dark-waters-of-self-delusion-the-crash-of-transair-flight-810-a4eeb033bc00</a>, See on <a href="https://news.ycombinator.com/item?id=36590806">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a rel="noopener follow" href="https://admiralcloudberg.medium.com/?source=post_page-----a4eeb033bc00--------------------------------"><div aria-hidden="false"><p><img alt="Admiral Cloudberg" src="https://miro.medium.com/v2/resize:fill:88:88/2*pZPMtIONqtJYi2xHYD_Ivg.jpeg" width="44" height="44" loading="lazy"></p></div></a></div><figure><figcaption>The forward fuselage of Transair flight 810, as seen at the bottom of the sea. (NTSB)</figcaption></figure><p id="92bd">On the 2nd of July 2021, a Boeing 737–200 hauling cargo between the Hawaiian Islands lost power in one engine shortly after takeoff from Honolulu. As the pilots attempted to turn back toward the airport, they reported the unthinkable: their second engine was going too, and they weren’t going to make it. While the Coast Guard scrambled to respond, the crew carried out an extraordinary ditching at sea in the dark of night, successfully bringing their 737 down on the heaving waters of Mamala Bay, 3.3 kilometers off the coast of Oahu. Although the plane broke into two pieces on impact, both pilots managed to escape, and in a harrowing rescue they were plucked from the water just as the remains of the airplane slipped beneath the waves.</p><p id="193e">Two years later, the publication of the National Transportation Safety Board’s final report has confirmed what many long suspected: that the crash of Transair flight 810 was not a story of exemplary airmanship, but quite the opposite, as a relatively minor engine failure snowballed into a dangerous ditching that need never have been attempted. The unfortunate truth was that the pilots never properly addressed the emergency, and in their confusion, reduced power on their functioning engine — a tale as old as the very concept of multi-engine airplanes. The cockpit voice recording and interviews with the pilots revealed the factors which may or may not have contributed, from their muddled attempts to declare an emergency, to an incomplete control handover, to simple stress, as the captain delivered a heated and sometimes sexist 32-minute pre-flight monologue about a fellow pilot. In any case, the findings raised questions about the safety culture at Transair, a scrappy (and now defunct) cargo airline operating 50-year-old airplanes — and highlighted how a breakdown in communication and critical thinking can turn a minor failure into a potentially deadly crash.</p><p id="1194">◊◊◊</p><figure><figcaption>Transair 737s on the ramp in Honolulu. (Transair)</figcaption></figure><p id="c619">In the archipelago of Hawaii, modern life depends on the fast and efficient transfer of goods between the state’s seven inhabited islands, especially by air. Numerous small companies have historically competed for this market, including — until recently — Rhoades Aviation, better known under its public-facing name Transair, which branded itself as “Hawaii’s leader in interisland air cargo.” Founded in 1982 by Iranian-born businessman Teimour Riahi, the airline slowly grew from a few small turboprops to a fleet of several first-generation Boeing 737–200 jets, surviving for decades despite its small size and even a failed attempt to expand into passenger services in 2005.</p><p id="2cbd">For Transair pilots, the pay was mediocre and the hours were unpredictable, but by the 2020s, Transair was one of at most two or three remaining operators of the ancient Boeing 737–200 left in the United States, and anyone who wanted to fly the classic jets would have had few other options. Others were simply attracted by the promise of working in Hawaii, including one of the main characters of this story, 58-year-old Captain Henry Okai. Born in the West African nation of Ghana, he came to the United States decades ago to pursue his dream of flying, which was met with success as he passed pilot training and got a job with regional carrier Allegheny Airlines. Over the years he flew for a variety of companies, both in the United States and abroad, until he finally landed with Transair, having been drawn to the airline in a spur-of-the-moment decision.</p><figure><figcaption>N810TA, the aircraft involved in the accident. (Li Cheng Tsai)</figcaption></figure><p id="9353">Just after midnight on the 2nd of July, 2021, Captain Okai reported for duty at Honolulu International Airport to fly Transair flight 810, a regular service from Hawaii’s capital and largest city, to Kahului, the largest town on the island of Maui. Joining him was 50-year-old First Officer Gregory Ryan, founder of the local Honolulu law firm Greg Ryan and Associates. Ryan first flew for commuter carrier Mesa Airlines from 1991 to 1995, before switching careers to become a divorce lawyer. In 2019, however, he decided to get back into flying, and for the last two years he had been splitting his time between Transair and his legal practice.</p><p id="72f6">That night they would be flying a Boeing 737–200 built in 1975 and registered as N810TA (at Transair, the flight number was based on the registration number — any route that N810TA happened to be flying was “flight 810”). When they arrived at the ramp, cargo handlers were loading the plane with several tons of frozen seafood, pharmaceuticals, and other perishable items typically shipped by air in Hawaii. After performing the pre-flight checks, the pilots sat down in the cockpit to wait for the cargo loading to finish, at which point Captain Okai began to vent about an incident that had allegedly occurred on July 1st, less than 24 hours previously. First Officer Ryan appears to have been already aware of what happened, suggesting that the conversation may actually have begun earlier, but what is known is that the issue would come to dominate the cockpit conversation almost until the moment of takeoff.</p><p id="45da">Most of the information about what happened comes from Captain Okai’s own statements captured by the cockpit voice recorder, but what is known is that on the morning of the 1st, Okai had been rostered to fly with the airline’s sole female First Officer, identified as Gina Moore. After a fraught disagreement over procedures, the two apparently found themselves in a shouting match in the cockpit, at which point Moore announced that she would not fly with Captain Okai, and walked away from the flight in the middle of the after start checklist. A new first officer had to be found, and the flight was delayed. (According to Moore’s own testimony, which is very sparse in detail, she did not ask to be replaced — rather, the Chief Pilot replaced her as soon as she told him she was uncomfortable with Captain Okai. Okai may have been unaware of this.)</p><figure><figcaption>Another photo of N810TA at Honolulu International Airport. (Chris Hoare)</figcaption></figure><p id="3c87">From the transcript, Captain Okai clearly had not mentally moved on from the incident. The conflict seemed to have arisen because Okai and Moore had different interpretations of the procedures in the manual, and neither was willing to compromise with the other, a hallmark of poor crew resource management. As First Officer Ryan listened, interjecting only occasionally to affirm his captain, Okai described his interpretation of the procedures, then discussed how Moore walked out in the middle of the checklist, which apparently prompted him to say a number of hostile words, including “what’s wrong with you,” “this is a joke,” and “you’re going to finish the checklist.” A shouting match ensued, which Ryan recognized as a safety issue, although neither pilot pointed out Okai’s own role in the altercation. In fact, he said, “<em>This is the way we work when I am with her, you know, you have to yell at her to force her to do things.”</em></p><p id="ca03">This incident had apparently been escalated all the way to the airline’s owner, but Okai accused the Chief Pilot of favoring Moore at his expense. He then professed a belief that First Officers needed to acquiesce to their captains regardless of what they thought “the book” said. Again, not a hallmark of an effective team player.</p><p id="68c6">At around quarter past 1:00, the cargo loading concluded, and the pilots paused the conversation to conduct the departure briefing, complete the before start checklist, and start the engines — although Okai interrupted the checklist to mention that he was going to use his cell phone to send pictures of the wording in the manual to the Chief Pilot in order to prove Moore wrong.</p><p id="b372">Several minutes later, the flight was ready to taxi, and the pilots proceeded toward the runway — only for Okai’s mind to come back to Moore again. Spotting a pothole in the runway, Okai began to describe how he accidently ran through that same pothole during a landing rollout because he was distracted arguing with Moore. “This girl is driving me crazy, you know!” he said.</p><p id="9272">Moments later, he brought the rant to a new level, graduating from personal animosity to outright misogyny. “These are the kind of women you don’t wanna get married to,” he said. “You know, some men, they lose their temper and the next thing you know, the wife is dead, you know… they start punching them and kicking them, and they lost their minds, you know… they kill the woman… it’s the woman who can drive you to do crazy stuff, you know?”</p><blockquote><p id="3de9">(Public service announcement: if a husband murders his wife because he thinks she’s annoying, that’s the husband’s fault. I shouldn’t need to say this.)</p></blockquote><p id="2704">◊◊◊</p><p id="89f1">Minutes later, at 1:33 a.m., flight 810 arrived at the head of the runway with takeoff clearance in hand, and Captain Okai handed over control to First Officer Ryan. Working together, they pushed the thrust levers to takeoff power, and the engine instruments responded normally. Okai observed that the exhaust gas temperatures, or EGTs, were hovering very close to the yellow “caution” zone on the gauge, but he had seen this indication many times before on multiple Transair planes, and he wasn’t concerned.</p><p id="e467">As the 737 accelerated down the runway, Okai made the standard callout, “Eighty knots,” followed by “V1,” or decision speed, and then “rotate.” Ryan pulled the nose back, and the plane lifted off, prompting Okai to call out, “positive rate.”</p><p id="e1b7">“Gear up,” Ryan ordered, and Okai complied.</p><p id="59a9">Then, just as the gear finished retracting, a loud “thud” was heard, accompanied by vibrations and a long “whooshing” sound, like an engine rolling back.</p><p id="b2fa">“Oh shit,” Ryan exclaimed.</p><p id="40e9">“Lost an engine, you got it?” Okai asked.</p><p id="1ad6">“Okay, I got it, yep,” Ryan said, instinctively stepping on the rudder to counteract the developing asymmetric thrust.</p><p id="2ee7">“Yep, you lost number…” Okai started to say, trying to determine which engine had failed.</p><p id="d720">“Number two, yep,” said Ryan, referring to the right engine.</p><p id="21e9">“Number two,” Okai agreed.</p><figure><figcaption>The damage to the turbine blades that precipitated the emergency. (NTSB)</figcaption></figure><p id="a09a">The pilots’ assessment was correct. Inside the high pressure turbine within the right (№2) engine, corrosion had been eating away at two of the turbine blades from the inside, expanding outward around each blade’s internal lightening holes — voids in the material designed to reduce the weight of the blades. The corrosion steadily weakened the blades, until one or both failed under the stresses of normal operation. The broken blade tips were then sucked back through the low pressure turbine, causing further damage that reduced the engine’s ability to produce power. In fact, within seconds of the failure, the Engine Pressure Ratio, or EPR, for the right engine — a proxy for its power output — decreased from 1.97, which is approximately takeoff power, to 1.43, which is closer to cruise.</p><p id="ceef">When an engine failure occurs on takeoff in a twin-engine jet like the 737, the procedure is to declare an emergency, climb to a safe altitude, level off, identify which engine has failed, complete the “engine failure or shutdown” checklist, and then return to the airport. Therefore, to start things off, Captain Okai jumped on the radio and said, “Rhoades eight ten, we have an emergency, stand by.”</p><p id="04f4">“Rhoades Express eight ten, radar contact, fly heading of one one zero to join victor two, resume own navigation,” the controller said, having apparently missed the content of the transmission.</p><p id="e4aa">“Eight twenty [sic] has emergency, on a two twenty heading, stand by,” Okai repeated. Turning to his first officer, he added, “Okay, you can inch up to two thousand.” 2,000 feet would be an excellent safe altitude at which to level off while they completed the engine failure procedure.</p><p id="fb7d">About 12 seconds later, Okai said, “Okay, coming up on two thousand, we’ll level at two thousand… you have two twenty heading, right?”</p><p id="0edd">In addition to flying with less power on the right side, First Officer Ryan was also navigating through a procedure turn to the right following takeoff, but he seemed to be handling it just fine, so he simply said, “Yes.”</p><p id="b11b">Moments later, the flight reached 2,000 feet, and Ryan began leveling the plane. At the same time, the controller called them again to repeat her earlier clearance. “Rhoades Express eight ten, radar contact, turn left heading zero niner zero, join victor two, resume own navigation, climb and maintain one three thousand, say altitude,” she said.</p><p id="6fa4">Wondering whether the controller wasn’t able to hear them, Okai said, “Okay, Rhoaaades eight ten, radio check, how do you read?”</p><p id="9f9b">“Rhoades Express eight ten, loud and clear, how do you hear? Turn left heading one eight zero,” the controller replied, again without mentioning the emergency. The simple truth, which Okai would later realize, was that the controller was handling a large volume of traffic, and other planes were stepping on his transmissions, making them hard to understand. But in the moment, her failure to appreciate the emergency declaration was probably frustrating.</p><p id="359b">“Okay, Rhoades eight ten, we’ve lost an engine, we are on a two twenty heading, maintaining two thousand, declaring an emergency, how do you read?” Okai repeated.</p><p id="a674">But the controller was in the middle of talking to their sister aircraft, Transair flight 809, and when Okai stopped talking, he heard only the end of their conversation: “…say again, heading two four zero?”</p><p id="4ea2">“Okay, two four zero heading, Rhoades eight ten,” Okai replied, thinking the transmission was for him.</p><p id="449b">“No, Rhoades eight oh nine, Rhoades eight oh nine, left two four zero,” the controller clarified. Then, finally recognizing that flight 810 was in trouble, she added, “Rhoades Express eight ten, you are cleared visual approach runway four right, you can turn in towards the airport.”</p><p id="a709">“Okay, Rhoades eight ten, we’re gonna have to run a checklist, if we can get a delay vector and uh, we’ll let you know when we’re ready to come into the airport,” Okai replied.</p><p id="a97d">“Just keep me advised and maintain two thousand if that’s the altitude you’d like,” said the controller.</p><p id="2fbb">“Okay, two thousand is good for now,” said Okai. “We’ll stay around fifteen miles from the airport and uh, maintaining two thousand, Rhoades eight ten.”</p><figure><figcaption>The EPR gauges on the accident airplane, which would have been the primary instrument indication of engine performance. The values depicted are not what was shown at any point during the accident sequence; the photo is illustrative of the concept only. (NTSB)</figcaption></figure><p id="f7d4">By the time the conversation concluded, a minute and forty seconds had passed with little to no discussion between the pilots. First Officer Ryan spent that time leveling off at 2,000 feet and trying to achieve the target airspeed for an engine-out scenario, which was about 220 knots. He initially overshot both, climbing to 2,100 feet and reaching a speed of 250 knots, so he began incrementally reducing power in both engines in order to slow down. In accordance with standard procedures, he moved both thrust levers together, since they had not formally carried out the identification process for the failed engine.</p><p id="da2a">Returning his attention to the cockpit, Captain Okai now said, “Okay, let’s uh… two forty heading.” He appeared not to have understood that this heading was not for him. He then added a question: “You want me to take over, or you got it?”</p><p id="aa5d">“No, I’m okay, thank you,” said Ryan.</p><p id="1cf9">In an emergency, it’s normal for the First Officer to fly while the Captain develops a strategy and completes the abnormal checklists. This was not an official rule nor was it set in stone, but Okai’s offer contradicted it nonetheless.</p><p id="4267">At that moment, the controller called again. “Rhoades Express eight ten, uh, when you get a chance can I get the nature of the emergency, I know you said an engine out, which one? Uh, how many souls on board, and fuel?”</p><p id="17b6">“Okay, all that is good, we’ll give you all that in a little bit, in a little bit, Rhoades eight ten,” Okai replied. Turning back to First Officer Ryan, he said, “Okay, so we’ll plan for two.. say two twenty speed, eh?”</p><p id="c734">“Kay,” said Ryan. By now, both thrust levers had been rolled all the way back to flight idle, the lowest flight setting, and the left and right EPRs had dropped to 1.05 and 1.09 respectively, indicating very little forward thrust. Their speed was dropping nicely toward 220 knots, which was what they wanted.</p><p id="e59f">Now, about 45 seconds after his first offer to take control, Okai said, “Let me take over briefly, and you…”</p><p id="efb2">“Okay,” First Officer Ryan agreed. He would later state that he perceived Okai’s statement as an order, so he agreed to hand over control, even though he was having no issues flying the plane. In fact, with both engines at idle, the asymmetric thrust had disappeared, and it was trivial to keep the plane straight and level.</p><p id="eb32">“You set your things up, I have control,” said Captain Okai.</p><p id="6855">“Okay, you have control,” Ryan acknowledged.</p><figure><figcaption>This 3-D reconstruction shows how the plane began slowly losing altitude just minutes after takeoff. (FlightAware)</figcaption></figure><p id="254a">Now that he was flying the plane, Okai immediately noticed that not all was as it should be. Their speed had dropped to the target of 220 knots, but they were losing altitude, having fallen from 2,100 down to 1,700 feet. Okai tried pitching up to regain their planned altitude, but as a result their speed dropped even more, to 196 knots, and the plane barely climbed. Of course, the reason was because First Officer Ryan had set both thrust levers to idle, and because of the control handover, no one pushed them back up again. But Okai didn’t realize that. Instead, he said, “Okay, let’s see what is the problem. Which one… what’s going on with the gauges? Read the gauges and see which one… who one… which… who has the EGT?”</p><p id="58f8">Glancing over at the engine gauges, First Officer Ryan attempted to determine which engine had abnormal parameters, including but not limited to the exhaust gas temperature (EGT). But with both engines still running at idle power, it was quite difficult to tell. Out of the indicated parameters, engine pressure ratio (EPR) was usually the biggest clue, but the EPR for both engines was almost the same. Instead, Ryan attempted to recall what symptoms he had noticed when the engine first failed: he heard a sound which seemed to come from the left, and the plane yawed left — didn’t it? So it must have been the left engine. Its indicated EPR, slightly below that of the right engine, was consistent with such an interpretation. And so he said, “Yep, so it looks like the number one.”</p><p id="34d2">“Number one is gone?” Okai asked.</p><p id="53b6">“It’s gone, yep,” said Ryan. “So we have number two.”</p><p id="810e">“So we have number two, okay,” said Okai.</p><p id="8443">You might have already noticed what’s wrong with this picture. When the failure first happened, didn’t both pilots identify the problem as being with the right engine? First Officer Ryan even used the rudder to prevent the plane from yawing right! But, as it turns out, human memory is more fallible than we would sometimes like to admit, and in the intervening four minutes, both pilots had somehow entirely forgotten their initial impressions. First Officer Ryan even seemingly forgot that the left engine was at idle power because he put it there himself not even two minutes earlier. If at that moment some outside observer had asked Ryan why he thought the number one (left) engine was faulty, he might not even have been able to give a straight answer, and yet in the moment he expressed his determination with unquestioned conviction, and Captain Okai, believing Ryan to be a competent and trustworthy pilot, accepted his conclusion unconditionally.</p><figure><figcaption>The 737–200 Engine Failure or Shutdown checklist. (NTSB)</figcaption></figure><p id="00f4">Having concluded that the left engine was at fault, Okai advanced the right thrust lever in order to stabilize their flight path, then moved to their next priority: completing the engine failure checklist. His plan was to fly 15 miles out from the airport on their assigned heading before turning back, which would give them plenty of time to complete the procedure, so he said, “Alright, uh, two forty heading, I have control.”</p><p id="ceb1">“Okay, should we head back toward the airport though, before we get too far away?”</p><p id="1164">“Yeah, we’ll stay within fifteen… alright, I have controls, you run the checklist, let’s do the engine failure shutdown checklist.”</p><p id="3a69">First Officer Ryan would later assert that he disagreed with the decision to spend so much time in the air, but that Okai was the captain, so he obeyed him. Besides, given their earlier conversation, he surely knew where arguing with Okai would get him (which was nowhere). Okai, for his part, would later note that he had been reprimanded by the Chief Pilot for landing without performing the checklist after a previous engine failure, and had promised not to do so again.</p><p id="e5c0">Some 30 seconds later, Okai asked air traffic control for permission to begin turning in, and received a new heading. Meanwhile, First Officer Ryan started reading off the conditions for performing the checklist. “Okay, engine failure or shutdown,” he recited. “When these occurs… engine failure, engine flameout, or another checklist directs an engine failure…”</p><p id="59e1">At that moment, Ryan seemed to notice that the EGT on the right engine was abnormally high, almost inside the red “warning” zone on the gauge. If they let the exhaust gas temperature climb into the red zone, severe engine damage could occur. Of course, the reason for this was that the right engine was already damaged and was not running properly, causing its internal temperature to rise, but in the moment it appeared to First Officer Ryan that they were simply demanding too much of the old, somewhat underpowered engine. “We’re… we’re red line here, we should pull the right one back a little bit,” he said.</p><p id="ce16">Captain Okai immediately recognized that this was a serious issue. He had already moved the right thrust lever to a reasonable power setting, but the EPR was much lower than it should have been, only about 1.22, which was not enough to keep them airborne for long. And yet even at this low power setting, the engine was overheating. His immediate conclusion was that they were about to lose thrust in both engines, and that they needed to get on the ground as soon as possible, so he said, “Okay, shoot, we should head towards the airport.”</p><figure><figcaption>The location and appearance of the exhaust gas temperature (EGT) gauges on a Boeing 737–200. (Chris Brady)</figcaption></figure><p id="6aa3">As the gravity of the situation set in, First Officer Ryan began setting up for the approach, while Captain Okai informed air traffic control that they were turning in and did not have the airport in sight.</p><p id="ab6d">“Rhoades Express eight ten, fly heading of zero two zero and would you like to intercept the localizer or do you want vectors?” the controller asked.</p><p id="aad8">“No, vectors straight to the airport,” Okai said. “We might lose the other engine too.”</p><p id="5c4d">Back in the cockpit, Okai asked, “We are clean, right?” His concern was that the flaps or landing gear might be extended, causing drag that was reducing their performance (a plane with no flaps or gear is referred to as “clean”). But they were in fact clean, so that wasn’t the problem.</p><p id="5d77">“Okay,” said Ryan.“Just have to watch this though, the number two.”</p><p id="2230">By now they had fallen to 1,000 feet, their speed was down to 157 knots, and both parameters were still decreasing. “Damn,” Okai said. Suddenly, the stick shaker activated, warning that they were flying too slowly and could stall if they didn’t increase their airspeed. With their only working engine redlined — or so they thought — the only way to gain speed was by pitching down, but that would only hasten their already alarming descent.</p><p id="3df3">“What’s this?” Okai exclaimed. “Hey man, we can’t keep going down!”</p><p id="23ec">“We’re descending,” Ryan agreed.</p><p id="a48b">Okai advanced the right thrust lever even more, and the EPR crept up to a still meager 1.37, but the temperature only continued rising into the red zone, until finally it reached the maximum that gauge could indicate.</p><p id="7f6e">“Okay, see, see if you can see the airport now,” Okay said, growing worried.</p><p id="03eb">“Uh, we’re descending, we have to climb!” said Ryan.</p><p id="e0dd">“Double check the airplane is cleaned up,” said Okai.</p><p id="290b">“Yeah, flaps are up, speedbrakes…” Ryan replied.</p><p id="f650">“How is the EGT?” Okai asked.</p><p id="a1e5">“It’s max, it’s beyond max,” said Ryan.</p><p id="cdd6">“Okay, we’re barely holding altitude,” Okai said. “Okay, see what you can do in the checklist, finish as much as possible.”</p><p id="c1df">“This says, uh, airframe vibrations, abnormal engines exist…” Ryan said, speed reading the checklist introductions. “It says do the engine shutdown only when flight conditions — we have to fly the airplane though.”</p><p id="5c09">The full phrase was “when flight conditions allow” — and in Ryan’s view, that meant when their altitude and speed were stable, which they were not. And that meant flying the airplane had to come before finishing the checklist.</p><p id="414f">“Okay,” said Okai. “Damn.”</p><p id="aaa0">“We’re losing altitude,” Ryan repeated.</p><p id="b519">“Yeah. Fifteen miles out,” Okai said. They were on their way back to the airport now, but they were so low that it was difficult to make out the airport lights on the horizon, and they were still dropping. Unless they managed to find some more thrust, they weren’t going to make it. Of course, if someone had simply advanced the left thrust lever, all their problems would have been solved, but nobody even thought to try, so down they went.</p><figure><figcaption>The full annotated flight path of flight 810. (NTSB)</figcaption></figure><p id="b8ec">Desperate now to avoid losing altitude, First Officer Ryan thought it was time to start deploying the flaps, knowing that while they would allow them to fly at a lower speed, they would also increase drag. “Do we go flaps, flaps one?” he asked.</p><p id="6bcb">“No no, not yet,” said Okai.</p><p id="13ef">“Kay, we’re, we’re very slow though,” said Ryan. If they didn’t deploy the flaps, Okai would have to keep pitching down to avoid stalling.</p><p id="88b6">“Shoot, okay, flaps one,” Okai agreed.</p><p id="94ed">“Five hundred,” an automated voice called out, reciting their height above the water. It was followed by a callout from the Enhanced Ground Proximity Warning System, or EGPWS: “TOO LOW, GEAR!”</p><p id="aa09">Keying his mic, Captain Okai said to air traffic control, “Okay, Rhoades eight ten, uh situation, we’ve lost number one engine and um, we’re coming straight to the airport… we’re gonna need the fire department, there’s a chance we’re gonna lose the other engine too, it’s running very hot. And um, speed is um, we’re pretty low on the speed and it doesn’t look good out here… you might want to let the Coast Guard know as well.” This request would probably end up being the best decision Captain Okai made during the entire emergency.</p><p id="75c0">“TOO LOW, GEAR!” the EGPWS repeated.</p><p id="0e80">“Just fly, fly the airplane please!” said Ryan.</p><p id="6a3c">“TOO LOW, TERRAIN,” said the EGPWS. “TOO LOW, GEAR! TERRAIN! TERRAIN!</p><p id="7b36">“Do you have the airport?” Okai desperately asked.</p><p id="940b">“PULL UP,” the EGPWS blared.</p><p id="c1fc">“Pull up, we’re low!” Ryan repeated.</p><p id="ffad">“PULL UP! PULL UP!”</p><p id="09f8">“Rhoades Express eight ten, do you have the airport in sight?” the controller asked.</p><p id="157c">“Negative!” Ryan replied.</p><p id="7aea">“And Rhoades Express eight ten, low altitude alert, are you able to climb at all?”</p><p id="3603">“No, negative,” Ryan again replied.</p><p id="690e">“Rhoades Express eight ten, roger, proceed direct to the airport and you are cleared to land any runway,” the controller said, followed by a heading. But they were running out of time.</p><figure><figcaption>A graph of the engine pressure ratios over time shows how both engines were reduced to near idle, before the right thrust lever was advanced again. (NTSB)</figcaption></figure><p id="5e9a">As flight 810 dropped the last few hundred feet toward the ocean, the EGPWS continued to blare: “TOO LOW, TERRAIN! Three hundred! TOO LOW, GEAR!”</p><p id="056d">“Rhoades Express eight ten, the trucks are rolling,” said the controller.</p><p id="24a8">Jumping on the radio again, Okai replied, “Roger, you wanna — you wanna let the Coast — Coast Guard know as well?</p><p id="5895">“Say that again?”</p><p id="194a">“Can you let the Coast Guard know, we cannot maintain altitude,” Okai repeated.</p><p id="3591">“We will,” said the controller.</p><p id="983a">At that moment, the EPR on the right engine increased to over 1.4, and for a brief moment the plane seemed to level off, before entering an extremely shallow climb. “Hold that please, it’s climbing, hold that, hold that,” First Officer Ryan exclaimed. “Pull back, we’ve got a climb! Pull back to the stick shaker!”</p><p id="93f2">“Shoot, the three hundred feet…” Captain Okai started to say.</p><p id="8240">“It’s okay, we’re climbing — ” Ryan began, but at that moment the right engine started losing power again, and they began descending once more, having gained only 50 feet. “Oh, we’re not climbing, damn,” Ryan concluded.</p><p id="4665">“How’s the EGT?” Okai asked again.</p><p id="9104">“Hot, way over,” said Ryan.</p><p id="44c4">“TOO LOW, TERRAIN!” said the EGPWS. “TOO LOW, GEAR! TOO LOW, GEAR! TOO LOW, GEAR!”</p><p id="4c09">“Rhoades Express eight ten, the Coast Guard is on the way,” said the controller.</p><p id="c814">“TOO LOW, GEAR! TOO LOW, TERRAIN!”</p><p id="ef86">“Pull back please!” said Ryan.</p><p id="dc4a">“Rhoades Express eight ten, if you can get to runway eight right or Kalaeloa, do you want Kalaeloa?” the controller asked, referring to a military airfield off their left side. It was closer than Honolulu International, but probably still too far away.</p><p id="37fe">“We’d like the closest airport runway please,” Ryan replied.</p><p id="016f">“Anything we can land on,” Okai interjected.</p><p id="29ec">“[Kalaeloa air]port is three miles north of you, uh, off your nine to ten o’clock,” said the controller.</p><p id="258f">“Wanna go there?” Ryan asked. The stick shaker stall warning activated for two seconds, prompting Okai to pitch down again.</p><p id="b70f">“Can you get that, Rhoades Express eight ten, it’s three uh, to your left about three miles northwest of you,” the controller said.</p><p id="33bf">“TOO LOW, GEAR! TOO LOW, GEAR!”</p><p id="0f38">“Okay, give me a heading,” Captain Okai transmitted.</p><p id="e9ab">“TOO LOW, GEAR! TOO LOW, GEAR!” the EGPWS blared, followed again by the stick shaker.</p><p id="77f9">“Rhoades Express eight ten, uh the airport is about a three one zero heading from you,” said the controller.</p><p id="5b4e">But it was too late even for this last-ditch effort. As Captain Okai turned left toward the airbase, the pace of the EGPWS alerts became even more frenetic: “TERRAIN! TERRAIN! PULL UP! PULL UP!”</p><p id="0df6">“Three one zero, thank you,” Okai said to the controller. It would be the last transmission from flight 810.</p><p id="1b57">“PULL UP,” the EGPWS screamed. “PULL UP! PULL UP! PULL UP! PULL UP!”</p><p id="09f6">“You have control and you have control!” Okai exclaimed. It’s unclear what he meant, since he retained control of the plane and neither pilot would be able to recall the statement later.</p><p id="5633">“PULL UP!”</p><p id="419b">“Okay,” said Ryan.</p><p id="b608">“Shoot, this is the water, we in the water,” Okai said, spotting the shining black waters of Mamala Bay rising beneath them.</p><p id="5f52">“PULL UP!” The stick shaker rattled briefly again. “PULL UP! PULL UP! PULL UP! TOO LOW, TERRAIN!”</p><p id="f257">“Oh man, we’re in the water, we’re in the water, we can’t…” Okai said, on the verge of hyperventilation.</p><p id="3ce1">The stick shaker started rattling continuously now, punctuated by more EGPWS alerts: “TERRAIN! TERRAIN! PULL UP!”</p><p id="3c76">“Damn!” Okai shouted.</p><p id="eac7">The EGPWS mustered one last “pull up,” and then, with a tremendous shudder, the plane hit the water.</p><figure><figcaption>First Officer Ryan’s seat collapsed forward, causing him to strike his head. It was found still in that position when the plane was recovered. (NTSB)</figcaption></figure><p id="2ea2">The impact was hard, and over quickly. Within seconds, the plane ground to a halt, but its fuselage had cracked in two just ahead of the wings, and water was pouring in. By the time Captain Okai managed to undo his seatbelt, the water outside the plane was half way up his window, and it came rushing into the cockpit when he slid it open. Fighting against the inflow, he forced his way out the window and into the heaving ocean. Meanwhile, First Officer Ryan’s seat had collapsed forward on impact, causing him to strike his head, but he too managed to open his window and clamber out into the watery darkness. Now only one objective remained: to survive.</p><p id="ca82">In search of something to hang onto, Captain Okai swam toward the tail section, but no cargo or panels had come loose, so he simply grabbed the automatic direction finder antenna on the vertical stabilizer and hauled himself onto the top of the sinking empennage, where he clung to the tail as waves crashed over him. At the same time, First Officer Ryan held onto the nose section, but as it began to slip beneath the surface, he spotted a loose cargo pallet and climbed aboard, using it as a makeshift raft. He called his captain’s name, and Okai called his name in return, but Okai was in trouble, as waves repeatedly knocked him off his perch, forcing him to swim back again.</p><figure><figcaption>A Coast Guard helicopter and boat respond to the scene of the crash. (US Coast Guard)</figcaption></figure><p id="6569">Suddenly, the roar of a helicopter overcame the rumble of the waves, and floodlights illuminated the desperate scene. The Coast Guard had arrived! At that moment, a wave again swept Captain Okai into the water, but this time he became disoriented; he could no longer find the tail, which was rapidly sinking. Floundering in the heaving sea, he began inhaling water and jet fuel. Realizing that his captain’s life was in danger, First Officer Ryan pointed the helicopter toward the tail section, and the rescuers got the message. An elite rescue swimmer jumped from the hovering helicopter and swam to Okai’s aid, pulling him back from the brink at the last possible moment. The swimmer and the unconscious captain were then winched back aboard — at which point the rescue swimmer jumped right back in again to save First Officer Ryan. With Captain Okai in apparently critical condition, the helicopter departed without them, but the Coast Guard had a plan B: a rescue boat, which was just now arriving at the scene. Grabbing onto the First Officer’s cargo pallet, the rescue swimmer swam through the ocean, pushing the improvised raft ahead of him, until they reached the boat and were hoisted aboard.</p><p id="5445">Against all odds, having ditched their plane in the ocean in the middle of the night, both pilots had been saved in the nick of time.</p><p id="24ce">◊◊◊</p><figure><figcaption>The aft section of N810TA as seen on the bottom of the ocean. (NTSB)</figcaption></figure><p id="6b1c">When National Transportation Safety Board investigators arrived in Hawaii later that day, they knew from the publicly available air traffic control tapes that the pilots of flight 810 reported an inability to maintain altitude and a possible dual engine failure, leading to a forced landing on water at night. Although it was clear that the pilots were lucky to be alive — in fact both were released from hospital within 48 hours — little else about the nature of the events was immediately obvious. And with the plane, and its black boxes, sitting somewhere on the bottom of Mamala Bay, the only way to find out what happened was to ask the two men who were there.</p><p id="ff31">The interviews with the pilots, which have been publicly released, provide a glimpse into what the crew thought was going on during the emergency. Captain Okai reported believing that the number two (right) engine had failed, but that when First Officer Ryan told him the faulty engine was number one (left), he had no reason to disbelieve him. After all, Ryan was the one flying the plane, so he would have been in a better position to detect which side was lacking thrust. First Officer Ryan, for his part, stated in full confidence that the sound of the “thud” came from the left side, that the plane yawed to the left, and that he had always known it was the left engine that failed. Only after this did it become clear that the right engine was running very hot and was not producing enough thrust to keep them in the air. But both pilots agreed on one thing: they had no idea why the plane wouldn’t fly, and were eager to find out.</p><figure><figcaption>The forward fuselage and cockpit of N810TA came to rest some distance away. (NTSB)</figcaption></figure><p id="33d0">The recovery of the plane from under 110 to 130 meters (360 to 420 feet) of water ultimately took four months, but when the NTSB finally received the flight data and cockpit voice recordings, their contents underscored just how unreliable witness testimony can often be. In fact, the data showed that the right engine suddenly lost power about 7 seconds after liftoff, confirming Captain Okai’s initial impression that this engine had failed. Furthermore, the resulting yaw to the right was countered correctly by First Officer Ryan, showing that he knew which side had lost thrust. The cockpit voice recorder was even more unequivocal: in fact, both pilots explicitly stated that the right engine had failed. This was confirmed by metallurgical analysis, which showed that corrosion had led to at least one blade failure in the right engine’s high pressure turbine, but that no defects were present in the left engine until it hit the water.</p><p id="eaad">The error chain began minutes after the initial failure, when First Officer Ryan began reducing thrust on both engines toward idle in order to slow the plane from 250 to 220 knots. After this occurred, the pilots again revisited the question of which engine had failed, and came to a startlingly different conclusion. In his interview, Ryan said that in addition to the symptoms described earlier, he saw that the left engine’s EPR and other parameters had fallen to idle, leading him to a conclusion that this engine had failed. But the left engine was at idle because he put it there! How was it possible for him to have become so confused? In the end, we may never know for sure — but it is possible to say a lot more about why Captain Okai failed to notice.</p><figure><figcaption>Part of one of N810TA’s two JT8D engines lies on the sea floor. (NTSB)</figcaption></figure><p id="cbca">As pilot monitoring during the takeoff, it was Captain Okai’s primary responsibility to watch the instruments and note any abnormalities. But almost as soon as the failure occurred, he took it upon himself to declare an emergency to air traffic control, an effort which he admitted “became a project.” In fact, Okai spent one minute and 40 seconds in a confused exchange with the oversaturated controller before he finally returned his attention to the cockpit, demonstrating rather poor task prioritization. Ideally, he should have analyzed the situation first and declared an emergency second, and if the controller did not hear his emergency declaration, he could have used the transponder to “squawk” 7700, the universal emergency code, instead of wasting more time on the radio. But he did not.</p><p id="1e83">By the time Captain Okai returned his attention to the cockpit, First Officer Ryan had already rolled back both engines to idle and leveled off at 2,000 feet, eliminating the most salient clues as to which engine had failed. At this point, they found themselves outside the boundaries of the assumptions built into their training scenarios and emergency checklists. The procedures for responding to an engine failure on takeoff assumed two things: first, that one engine would stop producing power entirely, resulting in warnings and zeroes on gauges; and second, that the adverse yaw from the asymmetric thrust would persist, providing a powerful clue about which engine had failed. But in this case, neither of these assumptions held, because the right engine only suffered a partial loss of power, and by the time the pilots got around to formally identifying the failed engine some four minutes after takeoff, both engines were producing the same amount of thrust (very little), so the adverse yaw was gone. At that point the only obvious difference between the two sets of gauges would have been a higher temperature on the right engine. As a result, there was nothing to obviously indicate to Captain Okai that First Officer Ryan’s conclusion about the failed engine was wrong. There was nothing to indicate that it was right, either, but Okai’s trust in Ryan was apparently good enough. Had he attempted to verify this by advancing both thrust levers in turn, which is a prescribed procedure for identifying a failed engine, he would have realized that the left engine was fine, but he never tried.</p><figure><figcaption>A closer view of the damaged nose section. (NTSB)</figcaption></figure><p id="8224">Because the pilots never increased power on the left engine, the plane did not have enough thrust to maintain altitude, even with the right thrust lever fully forward, because they were relying only on the damaged right engine. At any point, the pilots could have averted the accident by simply moving the left thrust lever forward, which would be a sensible thing to do when one is about to hit the water, even if one believes that that engine has failed. After all, the worst that can happen is it doesn’t work, and in the best case scenario, it could save lives. But when the NTSB conducted follow-up interviews in March 2022 to clarify why, among other points, the pilots did not move the left thrust lever, both replied that it simply never occurred to them. By the time it had become clear that they could not maintain altitude, both pilots were suffering from tunnel vision, and were singularly focused on flying the airplane to the end, rather than thinking outside the box for solutions. And with their focus so consumed by the task of flying, no one even looked at the thrust levers, let alone considered moving them.</p><p id="66fa">Had the pilots completed the engine failure and shutdown checklist, which required moving the affected thrust lever to idle before cutting fuel, the pilots might have noticed that the left thrust lever had been at idle the whole time, and might have tried advancing it. But in the event, they never actually started the checklist, because by the time they got around to it, their flight path was no longer stable, and First Officer Ryan had decided that flying the plane was a higher priority. Captain Okai, for his part, told the NTSB that he thought the checklist would be useless once the second engine started to fail, so he didn’t order Ryan to finish it.</p><figure><figcaption>The aft section of N810TA is recovered from the water in November 2021. (NTSB)</figcaption></figure><p id="f4e3">In the end, the fact that the pilots rolled back the wrong engine was attributed to poor communication and insufficient procedural discipline. The flight operations manual included the following prescient warning: “<em>Any time an engine shutdown is required in flight, good crew coordination is essential. Airplane incidents have turned into airplane accidents as a result of the flight crew shutting down the incorrect engine. When the flight path is under complete control, the crew should proceed with a deliberate, systematic process that identifies the correct engine and ensures that the operating engine is not shut down.”</em> In the event, the flight path was stable at 2,000 feet for several minutes, but no “deliberate” or “systematic” attempt to identify the correct engine was ever carried out. Ultimately, this was the pilots’ biggest and most unfortunate mistake.</p><p id="899f">The NTSB also criticized Captain Okai for demonstrating poor task prioritization (communicating with ATC instead of analyzing the situation, failing to ensure that the checklist was performed in a timely manner); poor crew resource management (failing to trust but verify, failing to monitor his First Officer’s actions); and poor leadership (failing to establish a plan, failing to enforce adherence to procedures). However, investigators also wrote that many of his mistakes could have been influenced by stress, which is known to have effects similar to fatigue, including inhibited decision-making and reduced ability to conduct critical thinking.</p><p id="27a5">Although the NTSB pointed to the nature of the emergency itself as the possible source of his stress, it’s also worth noting that the cockpit voice recorder transcript supports a hypothesis that Captain Okai was already stressed before the flight even took off. He had been in a shouting match with another pilot less than 24 hours earlier and may have felt hurt or insulted by her refusal to fly with him. The salience of this event was clear, given that Okai spent a total of 32 minutes before the flight talking about his experiences with First Officer Moore, including after starting the engines and during taxi, in violation of the sterile cockpit rule, which prohibits off-topic conversations between engine start and 10,000 feet. This violation almost certainly had no effect on the course of events, but it did suggest that Okai was having difficulty focusing on the task at hand. In the end, the NTSB declined to mention these conversations in its final report, which is normal — most of the time, the agency doesn’t wade into pilots’ personal disputes — but when taken in context, it’s difficult to ignore.</p><p id="fa8b">◊◊◊</p><figure><figcaption>The nose section is loaded onto a barge. (NTSB)</figcaption></figure><p id="b3e4">Although the crash was the direct result of the flight crew’s actions, it’s worth summarizing the mechanical aspects before bowing out. The final report and its supporting documentation are light on details, but the cause of the failure seems to have been simple corrosion of either one or two high pressure turbine blades. The question of whether this corrosion was detectable during routine inspections, and why the corrosion appeared in the first place, don’t seem to have been addressed. However, given that the corrosion was internal to the blades, it’s possible that it was difficult to detect, which is supported by the NTSB’s explicit conclusion, stated in its report, that “maintenance was not a factor in this accident.” Furthermore, corrosion is an inevitability on airplanes and engines operating in Hawaii’s humid, salty climate, especially over long timeframes. The engine that failed was built in 1968 and was 53 years old at the time of the crash, plenty long enough to develop all manner of problems, especially if the maintenance was not always up to par.</p><p id="3bc1">There was plenty of circumstantial evidence to suggest that maintenance was a major problem area for Transair. Captain Okai said he had experienced five engine failures while flying 737s for Transair, which is a lot, and issues like high engine temperatures on takeoff were common. The airline’s chief maintenance inspector had also resigned two weeks before the crash, citing insufficient staffing, time, and experience. And according to a colleague, First Officer Ryan had previously called the airline’s safety culture “screwed up” and “beyond help.” These problems had been brewing in the background for some time, and in May 2022, the Federal Aviation Administration revoked Rhoades Aviation’s air operator certificate, permanently grounding Transair, after an investigation found numerous maintenance violations, including 33 flights performed with unairworthy engines. However, the investigation and its findings were said to have nothing to do with the accident, which was caused by an apparently undetectable issue.</p><p id="4122">◊◊◊</p><figure><figcaption>The underside of the nose section was heavily damaged during the impact. (NTSB)</figcaption></figure><p id="5789">With Transair having ceased to exist by the time the investigation concluded, and with very few Boeing 737–200s remaining in service in the United States, the NTSB did not issue any safety recommendations as a result of the accident. Nevertheless, as the latest example in a series of crashes involving shutdown of an incorrect engine, it’s worth extracting some lessons anyway. The crash of Transair flight 810 in particular evokes the 1989 disaster involving <a rel="noopener" href="https://admiralcloudberg.medium.com/lefts-rights-and-wrongs-the-crash-of-british-midland-flight-92-or-the-kegworth-air-disaster-a3989feb4d3a#:%7E:text=On%20the%208th%20of%20January,height%20of%20just%20900%20feet">British Midland flight 92</a>, another Boeing 737 that suffered a partial engine failure, only to crash short of the airport after the pilots mistakenly shut down the wrong engine. The reasons for the engine failures and for the pilots’ mistakes in both crashes were different — for instance, the British Midland investigation cited poorly designed gauges that were not installed on earlier 737–200s like that involved in the Transair crash. However, both cases were characterized by a lack of due care in determining the failed engine, including captains who uncritically believed their first officers’ unsupported and incorrect determinations.</p><figure><figcaption>An NTSB investigator examines the recovered nose section. (NTSB)</figcaption></figure><p id="967e">The fact that the same mistakes could occur again after 32 years underscores the need for pilots to double and triple check which engine has failed, but it also highlights the limitations of better training and words of caution in manuals as a solution to this recurring issue. As I mentioned in my article on the British Midland crash, the most effective way to prevent this kind of accident is by fitting airplanes with an Engine Indicating and Crew Alerting System, known as EICAS, or similar equipment. These systems automatically monitor engine performance and, should an engine fail, will produce a message informing the pilots which engine is the cause of the problem, dramatically reducing the probability of an incorrect identification. However, retrofitting the systems onto older 737s, which are most at risk, is not required and may be impractical or impossible. For that reason, as long as first and second generation 737s continue to fly, a safety risk still exists, and now that the findings of the Transair investigation have been released, that fact bears repeating: as long as pilots rely on context clues to determine which engine has failed, the opportunity for this type of error will remain. Let us merely be thankful that this latest warning did not come to us at the cost of lives — and let us not squander it.</p><p id="482b">_______________________________________________________________</p><p id="2a7e"><a href="https://www.reddit.com/r/CatastrophicFailure/comments/14nxu5c/2021_the_crash_of_transair_flight_810_a_boeing/?" rel="noopener ugc nofollow" target="_blank">Join the discussion of this article on Reddit</a></p><p id="72db"><a href="https://www.patreon.com/Admiral_Cloudberg" rel="noopener ugc nofollow" target="_blank">Support me on Patreon</a> (Note: I do not earn money from views on Medium!)</p><p id="b1bb"><a href="https://twitter.com/KyraCloudy" rel="noopener ugc nofollow" target="_blank">Follow me on Twitter</a></p><p id="5a52">Visit <a href="https://www.reddit.com/r/AdmiralCloudberg/" rel="noopener ugc nofollow" target="_blank">r/admiralcloudberg</a> to read and discuss over 240 similar articles</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What gets to the front page of Hacker News? (124 pts)]]></title>
            <link>https://randomshit.dev/posts/what-gets-to-the-front-page-of-hacker-news</link>
            <guid>36590226</guid>
            <pubDate>Tue, 04 Jul 2023 17:53:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://randomshit.dev/posts/what-gets-to-the-front-page-of-hacker-news">https://randomshit.dev/posts/what-gets-to-the-front-page-of-hacker-news</a>, See on <a href="https://news.ycombinator.com/item?id=36590226">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><img src="https://randomshit.dev/images/hacker-news/front-page.png"></p>
<p>In my job as technical writer / marketer<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup>, the most common question I get from companies I work with is “how do we get to the front page of Hacker News?” And as someone whose writing has been on said front page many times, I’ll tell you: <strong>I have no clue!</strong></p>
<p>Sometimes it seems like good, high quality writing always finds its way to the front page; other times, it feels like the mods are out to get you. So I started (very manually) collecting data on what the top 30 posts on HN are at the end of any given day.</p>
<p>Here are the highlights (FP = Front Page):</p>
<ul>
<li><strong>Blog posts</strong> (45%) are the most popular type of content on the FP</li>
<li>A blog post from a <strong>corporate entity</strong> only has a 8% shot at making the FP</li>
<li>25% of FP posts are blog posts from engineers on their <strong>personal blogs/sites or OSS</strong></li>
<li>36% of FP posts are <strong>news articles</strong>, and the (slight) majority of them are actually not about software/hardware</li>
<li>ShowHN posts almost never make the front page (&lt;2%)</li>
</ul>
<p>Here’s the breakdown more visually:</p>
<p><img src="https://randomshit.dev/images/hacker-news/top-30-by-category.png"></p>
<p>Before some more analysis and a few more charts, I want to preface this post by saying that I don’t mean to comment on the <em>inherent value</em> of getting your content to the front page of Hacker News. Whether this is the right goal, or if perhaps you should pursue a different goal like number of upvotes, or maybe comments, or maybe <em>angry</em> comments, is a discussion for another post.</p>
<h2>How I gathered and categorized the data</h2>
<p>The way I gathered this (small) data set was by manually<sup><a href="#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup> combing through the top 30 posts on Hacker News using the <a href="https://news.ycombinator.com/front"><code>past</code></a> feature. For each post, I clicked on the link to see what the content was about, who published it, and where. Partially in advance, and then partially on the fly the more stuff I saw, I classified each post into a category. Since my main focus is technical writing and marketing, the categories I chose relate to that lens:</p>
<ul>
<li>News / opinion articles in media publications</li>
<li>Academic journals and papers</li>
<li>Blog posts
<ul>
<li>Personal blog vs. a corporate blog vs. an open source entity</li>
<li>Types of content: tutorials, thought leadership, etc.</li>
</ul>
</li>
<li>Hiring announcements</li>
<li>ShowHN</li>
<li>Misc.
<ul>
<li>Repo links</li>
<li>Non-blog websites</li>
<li>Tweets, Reddit posts, etc.</li>
</ul>
</li>
</ul>
<p>These categories have excellent coverage (Misc. &lt;5%) despite them being oddly specific. You can see that I wasn’t particularly concerned with the <em>subject matter</em> per se (everything is about Rust anyway) but more the format and the authoring entity.</p>
<p>The astute reader will note several limitations of the data set. </p>
<p>First, the data I collected represents what <em>finished</em> the day on the front page of Hacker News. But many items will <em>be</em> on the front page over the course of a given day, and then end the day somewhere else (perhaps number 35, or 67). What “gets to” the front page – a group that contains, and exceeds the size of, what “ends” on the front page - is a richer data set but I do not have access to it / it may not exist.</p>
<p>Second, and perhaps more importantly, the dataset doesn’t record the <em>attempts</em> made to get to the front page, i.e. all posts on Hacker News in a given day. It’s possible that there are orders of magnitude more blog posts <em>posted</em>  but fewer that <em>make</em> the FP, whereas 95% of any academic paper submitted makes the front page (extreme figures used for illustrative purposes). So for simplicity, I’ll say “the likelihood of making the FP” which assumes a constant rate of conversion from post to FP across different categories.</p>
<p>Limitations aside, the results started to converge very clearly after only 5 or 6 days of data, although there were a few outlier days with spikes in a particular category. In total I collected and sifted through 30 days worth of data, and hope to add more in the future.</p>
<h2>What kinds of blog posts get to the front page?</h2>
<p>Statistically, your best shot of getting your writing to the front page of Hacker News is by writing something (with nothing to promote) on your personal website or blog. 26% of total FP posts are blogs like this, while only 11% of total FP posts (or 24% of FP <em>blog</em> posts) came from corporate<sup><a href="#user-content-fn-3" id="user-content-fnref-3" data-footnote-ref="" aria-describedby="footnote-label">3</a></sup> entities on their corporate blogs or websites. 20% of blog posts are from some sort of open source entity (usually launches).</p>
<p>On the subject of what to post, <a href="https://news.ycombinator.com/newsguidelines.html">the Hacker News guidelines</a> say:</p>
<blockquote>
<p><em>On-Topic: Anything that good hackers would find interesting. That includes more than hacking and startups. If you had to reduce it to a sentence, the answer might be: anything that gratifies one's intellectual curiosity.</em></p>
</blockquote>
<p>and this is pretty much the story with what blog posts make the FP. </p>
<p><img src="https://randomshit.dev/images/hacker-news/blog-posts.png"></p>
<p>Of those corporate blog posts, about 40% of them are product announcements or launches; the rest are less promotional content formats like technical tutorials. A common question I get is “how do we get our product launch on the front page of HackerNews?” and the answer is that it’s statistically<sup><a href="#user-content-fn-4" id="user-content-fnref-4" data-footnote-ref="" aria-describedby="footnote-label">4</a></sup> highly unlikely (~4%) for that to happen. And of those product announcements that made the FP, a good deal of them are (a) from established companies and products like Apple, (b) posted organically by the community, and (c) about hardware and gaming. Not your software startup.</p>
<p>Personal blog posts, though, are highly popular on the FP. They span the gamut from tutorials to “how I built ___” type posts, and of course the perennial “I made a thing.” Here are a few examples of personal blog posts that made the FP:</p>
<ul>
<li><a href="https://tavianator.com/2023/futex.html">You could have invented Futexes</a></li>
<li><a href="https://jingnanshi.com/blog/groebner_basis.html">Use Gröbner Bases To Solve Polynomial Equations</a></li>
<li><a href="https://www.milanvit.net/post/my-ultimate-shell-setup-with-fish-shell-and-tmux/">My ultimate shell setup with Fish shell and Tmux</a></li>
<li><a href="https://ariadne.space/2023/04/13/writing-portable-arm64-assembly/">Writing portable ARM64 assembly</a></li>
</ul>
<p>The common thread is that they’re non-promotional, and typically focus on a personal pursuit of the author<sup><a href="#user-content-fn-5" id="user-content-fnref-5" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup>.</p>
<p>My personal experience writing for corporate entities says that useful tutorials and interesting stories do the best. The most recent post I wrote that made it to #1 was a tutorial for PlanetScale about how database sharding works (HN post <a href="https://news.ycombinator.com/item?id=35476518">here</a>). A few others I wrote that made the FP were all non-promotional:</p>
<ul>
<li>My two stories for Retool about why Accenture (<a href="https://news.ycombinator.com/item?id=26969364">link</a>) and Oracle (<a href="https://news.ycombinator.com/item?id=29004597">link</a>) are worth so much money</li>
<li>My blog post for WorkOS about best practices for building webhooks (<a href="https://news.ycombinator.com/item?id=26401838">link</a>)</li>
<li>My “thought leadership” for PlanetScale about DBA experience (<a href="https://news.ycombinator.com/item?id=28330297">link</a>)</li>
</ul>
<p>These successes live next door to a massive graveyard of blog posts I’ve written that <em>I</em> thought were really good, but Hacker News did not. Or perhaps randomness just reared its ugly head. </p>
<h2>What kinds of news gets to the front page?</h2>
<p>The second biggest category of posts that make the front page of Hacker News is (shocker) news, which I define here as a story or opinion piece published by a media organization. 36% of FP items are news, which is a lot!</p>
<p>While almost all of the news that makes the FP is STEM related, the majority of it (well, by a few percentage points) doesn’t relate to software or hardware. There are a lot of articles about space exploration and rockets, biology and chemistry, and physics, but fewer about code and SaaS and things like that. </p>
<p><img src="https://randomshit.dev/images/hacker-news/news.png"></p>
<p>It’s worth noting that I didn’t see a single article from TechCrunch in the entire dataset I gathered, despite there being plenty of articles for places like the Verge, Wired, etc. A cursory search using <a href="https://hn.algolia.com/?dateRange=all&amp;page=0&amp;prefix=true&amp;query=techcrunch&amp;sort=byPopularity&amp;type=story">Algolia’s Search HackerNews tool</a>, ordered by number of upvotes, reveals that HackerNews really does not like TechCrunch very much.</p>
<p><img src="https://randomshit.dev/images/hacker-news/techcrunch.png"></p>
<h2>Miscellaneous findings and other things</h2>
<p>6% of items on the front page are academic papers, which is more than I thought.</p>
<p>ShowHN is very valuable, but is not likely to land your product on the front page.</p>
<p>Tweets and tweet threads sometimes make the front page.</p>
<p>It’s uncommon for hiring or launch posts - the two types of posts that are reserved for YC companies, and “artificially” promoted by moderators - to make the front page.</p>
<p>You can access the underlying dataset <a href="https://docs.google.com/spreadsheets/d/1iUYmm4PRFbRi6KmDztRyCDiaHOLjsze4zT6Ts4-qbxk/edit?usp=sharing">here</a>.</p>
<p>I want to thank <a href="https://github.com/minimaxir">Max Woolf</a> (who may recall interviewing me for a Data Science job at Buzzfeed that I thankfully did not take) for the excellent <a href="https://github.com/minimaxir/hacker-news-undocumented">“Hacker News Undocumented”</a> resource. It was tremendously helpful. </p>
<hr>
<h2>Footnotes</h2>
<section data-footnotes="">
<p id="user-content-fn-1">1. With an undergrad Data Science degree for some reason <a href="#user-content-fnref-1" data-footnote-backref="" aria-label="Back to content">↩</a></p>
<p id="user-content-fn-2">2. For the empathetic reader wondering why I did this manually when there are tons of ways for the author (who, as mentioned in the previous footnote, has a Data Science degree) to access historical Hacker News data via <a href="https://console.cloud.google.com/marketplace/details/y-combinator/hacker-news?project=flowing-bonito-366719">BigQuery</a>, <a href="https://github.com/HackerNews/API">API</a>, etc. – the amount of effort it would have taken to train a classifier would have been highly impractical, plus I’d need to manually label the data anyway. <a href="#user-content-fnref-2" data-footnote-backref="" aria-label="Back to content">↩</a></p>
<p id="user-content-fn-3">3. By this I mean closed source, basically. Anything written on the blog of a company that is selling something. <a href="#user-content-fnref-3" data-footnote-backref="" aria-label="Back to content">↩</a></p>
<p id="user-content-fn-4">4. Noting once again that this framing isn’t entirely fair, since the dataset is missing attempts. <a href="#user-content-fnref-4" data-footnote-backref="" aria-label="Back to content">↩</a></p>
<p id="user-content-fn-5">5. Which makes me wonder if the best “front page strategy” might be to encourage your engineering team to work on their personal blogs? <a href="#user-content-fnref-5" data-footnote-backref="" aria-label="Back to content">↩</a></p>
</section>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Turning my hobby into a business made me hate it (319 pts)]]></title>
            <link>https://shant.nu/turning-my-passion-hobby-into-a-business-made-me-hate-it/</link>
            <guid>36588514</guid>
            <pubDate>Tue, 04 Jul 2023 16:06:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shant.nu/turning-my-passion-hobby-into-a-business-made-me-hate-it/">https://shant.nu/turning-my-passion-hobby-into-a-business-made-me-hate-it/</a>, See on <a href="https://news.ycombinator.com/item?id=36588514">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>This is a problem many people who love doing creative stuff (writing, music, programming, painting, pottery, calligraphy, anything creative and original) will face:</p>



<blockquote>
<p><em>“This is good, why don’t you make money from it?”</em></p>
</blockquote>



<p>As if the only value anything has is by how much dollars it makes.</p>



<p>You could create the most beautiful painting, the most moving music, the most engaging novel, but if you don’t have the big dolla’s in your bank account, you are a failure.</p>



<p>And all of it is complicated by the fact that, yes, like most creatives, I <em>do want</em> to make money from my writing. Maybe not millions, but a little would help. Especially when the day job is going shit, and you know the fantasy that online entrepreneurs sell:</p>



<blockquote>
<p><em>Quit the day job! Start your own business! Don’t depend on one person for all your income! Blah blah blah! Now buy my book/course, so at least one of us can get rich.</em></p>
</blockquote>



<p>It doesn’t help with all these online “gurus” who claim you can make the big $$$ by selling anything (yes sir, ANYTHING!) online, if only you buy their expensive course.</p>



<p>One guru (and why name him, since they all do the same) says you can make money online (BIG MONEY!) even if you are selling things like crotchet kits or dog training. All you have to do is <em>(in thunderous manly voice)</em>:</p>



<p><strong>FOLLOW MY FORMULA!</strong></p>



<p>His formula was, in a nutshell: Create training courses and sell them to others, just as he was doing. And at least one of us made big money (<em>hint, it wasn’t me</em>).</p>



<p><strong>My story</strong></p>



<p>I loved writing fiction– novels, short stories, interactive fiction. At first, I would just self-publish them on Amazon, no care whether anyone bought them.</p>



<p>Then I joined a few writer groups, and they were all like “You need to market your work”.</p>



<p>And so I spent hours every week building my email list, running ads, asking for reviews (as you need them to sell books), blogs/podcasts.</p>



<p>I found the type of fiction that sells is in a few mainstream genres, and in series (so you write a dozen books, all with a hard-boiled detective, for example). That’s why every book nowadays is in a series because publishers (traditional and indie)have figured out this is the “formula” to success.</p>



<p>I like to experiment and play—one genre I love writing is comedy-horror. This is one of those super niche genres that have a few hardcore fans but isn’t mainstream. Think <em>Shaun of the Dead</em> in movies, or one of my favourite books <em>John Dies at the End.</em></p>



<p>Other books I wrote were supernatural detective series, a fantasy comedy (a teddy bear that solves crime). Now, there are books like these and sell (and where do you think I got ideas from?), but they are not mainstream.</p>



<p>If you want to make the big money, you at least have to try writing for the “market” or trying to write in a way that appeals to the mainstream, or at least a large number of people.</p>



<p>So that’s what I did. Why not? Everyone else was doing it. They were pasting screenshots of how much money they were making online in Facebook groups.</p>



<p>And while all the above I tried worked in the short term (and yes, it DOES work), soon I began to hate what I was doing and one day, I just couldn’t type anymore.</p>



<p>And one day, I couldn’t take it anymore. Couldn’t type one more word. Quit 2 years ago, after 7-8 years of writing.</p>



<p>Have tried to restart many times, but each time, I feel disgusted and quit.</p>



<p><strong>Trying to make money from your “passion” is hard</strong></p>



<p><em>Just follow your passion and you won’t have to work a day!</em></p>



<p>Sure, if your passion is online marketing or making WordPress sites for cash-rich, time-poor business owners.</p>



<p>When I was writing, I hit all the clichés about “passion”:</p>



<ul>
<li>I would be lost for hours in writing</li>



<li>I loved doing it</li>



<li>I did it for several years non-stop, including training to become better</li>
</ul>



<p>And yet, in spite of my passionate “passion”, I never made enough money to quit the day job. I followed my passion and all it gave my was wrist pain.</p>



<p>And it is a field where people make money— but like many other creative fields (music, sports, art), it’s a winner-take-all field. 5-10% of authors make 90% of the money. And that’s fine, I knew the statistics before I started.</p>



<p>But I was still hoping to make some money. To be honest, I do, but it’s never been more than a fancy night out each month.</p>



<p>I never cracked the Amazon algorithm; I never got 10,000 fans on Facebook; I never got a huge email list of people <em>Oh gosh! Just waiting to buy my book.</em></p>



<p>And in trying to hit these targets, I started hating what I was actually doing — writing.</p>



<p><strong>My advice is</strong>: If you love someone, do it for love, don’t always try to make money from it.</p>



<p>It all comes back to doing it for the love and accepting that perhaps this will always remain a hobby. Do it with a craftsman’s mindset, always improving for the sake of improving.</p>



<p>And don’t let anyone shame you if you don’t want to make money.</p>



<p><em>Note: I wrote this post 2–3 years ago, and it had been sitting on my hard drive since then.</em> <em>I have given up fiction writing, though my books are still online I don’t do anything to promote them, nor am I writing new ones. I wrote this post as a warning: If you love something, do it for the love and don’t let the Get-Rich-Types make you lose your focus.</em></p>



<p>Read more posts on <strong><a href="https://shant.nu/creativity-series/">Creativity</a></strong></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ZFS 2.2.0 (RC): Block Cloning merged (228 pts)]]></title>
            <link>https://github.com/openzfs/zfs/pull/13392</link>
            <guid>36588240</guid>
            <pubDate>Tue, 04 Jul 2023 15:46:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/openzfs/zfs/pull/13392">https://github.com/openzfs/zfs/pull/13392</a>, See on <a href="https://news.ycombinator.com/item?id=36588240">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  <task-lists disabled="" sortable="">
    <div>
      


<h3 dir="auto">Motivation and Context</h3>
<p dir="auto">Block Cloning allows to clone a file (or a subset of its blocks) into another (or the same) file by just creating additional references to the data blocks without copying the data itself. Block Cloning can be described as a fast, manual deduplication.</p>
<h3 dir="auto">Description</h3>
<p dir="auto">In many ways Block Cloning is similar to the existing deduplication, but there are some important differences:</p>
<ul dir="auto">
<li>Deduplication is automatic and Block Cloning is not - one has to use a dedicated system call(s) to clone the given file/blocks.</li>
<li>Deduplication keeps all data blocks in its table, even those referenced just ones. Block Cloning creates an entry in its tables only when there are at least two references to the given data block. If the block was never explicitly cloned or the second to last reference was dropped, there will be neither space nor performance overhead.</li>
<li>Deduplication needs data to work - one needs to pass real data to the write(2) syscall, so hash can be calculated. Block Cloning doesn't require data, just block pointers to the data, so it is extremely fast, as we pay neither the cost of reading the data, nor the cost of writing the data - we operate exclusively on metadata.</li>
<li>If the D (dedup) bit is not set in the block pointer, it means that the block is not in the dedup table (DDT) and we won't consult the DDT when we need to free the block. Block Cloning must be consulted on every free, because we cannot modify the source BP (eg. by setting something similar to the D bit), thus we have no hint if the block is in the Block Reference Table (BRT), so we need to look into the BRT. There is an optimization in place that allows to eliminate majority of BRT lookups that is described below in the "Minimizing free penalty" section.</li>
<li>The BRT entry is much smaller than the DDT entry - for BRT we only store 64bit offset and 64bit reference counter.</li>
<li>Dedup keys are cryptographic hashes, so two blocks that are close to each other on disk are most likely in totally different parts of the DDT.  The BRT entry keys are offsets into a single top-level VDEV, so data blocks from one file should have BRT entries close to each other.</li>
<li>Scrub will only do a single pass over a block that is referenced multiple times in the DDT. Unfortunately it is not currently (if at all) possible with Block Cloning and block referenced multiple times will be scrubbed multiple times.</li>
<li>Deduplication requires cryptographically strong hash as a checksum or additional data verification. Block Cloning works with any checksum algorithm or even with checksumming disabled.</li>
</ul>
<p dir="auto">As mentioned above, the BRT entries are much smaller than the DDT entries.  To uniquely identify a block we just need its vdevid and offset. We also need to maintain a reference counter. The vdevid will often repeat, as there is a small number of top-level VDEVs and a large number of blocks stored in each VDEV. We take advantage of that to reduce the BRT entry size further by maintaining one BRT for each top-level VDEV, so we can then have only offset and counter as the BRT entry.</p>
<p dir="auto">Minimizing free penalty.</p>
<p dir="auto">Block Cloning allows to clone any existing block. When we free a block there is no hint in the block pointer whether the block was cloned or not, so on each free we have to check if there is a corresponding entry in the BRT or not. If there is, we need to decrease the reference counter. Doing BRT lookup on every free can potentially be expensive by requiring additional I/Os if the BRT doesn't fit into memory. This is the main problem with deduplication, so we've learn our lesson and try not to repeat the same mistake here. How do we do that? We divide each top-level VDEV into 64MB regions. For each region we maintain a reference counter that is a sum of all reference counters of the cloned blocks that have offsets within the region. This creates the regions array of 64bit numbers for each top-level VDEV. The regions array is always kept in memory and updated on disk in the same transaction group as the BRT updates to keep everything in-sync. We can keep the array in memory, because it is very small. With 64MB regions and 1TB VDEV the array requires only 128kB of memory (we may decide to decrease the region size in the future). Now, when we want to free a block, we first consult the array. If the counter for the whole region is zero, there is no need to look for the BRT entry, as there isn't one for sure. If the counter for the region is greater than zero, only then we will do a BRT lookup and if an entry is found we will decrease the reference counters in the entry and in the regions array.</p>
<p dir="auto">The regions array is small, but can potentially be larger for very large VDEVs or smaller regions. In this case we don't want to rewrite entire array on every change. We then divide the regions array into 128kB chunks and keep a bitmap of dirty chunks within a transaction group. When we sync the transaction group we can only update the parts of the regions array that were modified. Note: Keeping track of the dirty parts of the regions array is implemented, but updating only parts of the regions array on disk is not yet implemented - for now we will update entire regions array if there was any change.</p>
<p dir="auto">The implementation tries to be economic: if BRT is not used, or no longer used, there will be no entries in the MOS and no additional memory used (eg.  the regions array is only allocated if needed).</p>
<p dir="auto">Interaction between Deduplication and Block Cloning.</p>
<p dir="auto">If both functionalities are in use, we could end up with a block that is referenced multiple times in both DDT and BRT. When we free one of the references we couldn't tell where it belongs, so we would have to decide what table takes the precedence: do we first clear DDT references or BRT references? To avoid this dilemma BRT cooperates with DDT - if a given block is being cloned using BRT and the BP has the D (dedup) bit set, BRT will lookup DDT entry and increase the counter there. No BRT entry will be created for a block that resides on a dataset with deduplication turned on.  BRT may be more efficient for manual deduplication, but if the block is already in the DDT, then creating additional BRT entry would be less efficient. This clever idea was proposed by Allan Jude.</p>
<p dir="auto">Block Cloning across datasets.</p>
<p dir="auto">Block Cloning is not limited to cloning blocks within the same dataset.  It is possible (and very useful) to clone blocks between different datasets.<br>
One use case is recovering files from snapshots. By cloning the files into dataset we need no additional storage. Without Block Cloning we would need additional space for those files.<br>
Another interesting use case is moving the files between datasets (copying the file content to the new dataset and removing the source file).  In that case Block Cloning will only be used briefly, because the BRT entries will be removed when the source is removed.<br>
Note: currently it is not possible to clone blocks between encrypted datasets, even if those datasets use the same encryption key (this includes snapshots of encrypted datasets). Cloning blocks between datasets that use the same keys should be possible and should be implemented in the future.</p>
<p dir="auto">Block Cloning flow through ZFS layers.</p>
<p dir="auto">Note: Block Cloning can be used both for cloning file system blocks and ZVOL blocks. As of this writing no interface is implemented that allows for ZVOL blocks cloning.<br>
Depending on the operating system there might be different interfaces to clone blocks. On FreeBSD we have two syscalls:</p>
<div data-snippet-clipboard-copy-content=" ssize_t fclonefile(int srcfd, int dstfd);
 ssize_t fclonerange(int srcfd, off_t srcoffset, size_t length, int dstfd, off_t dstoffset);"><pre><code> ssize_t fclonefile(int srcfd, int dstfd);
 ssize_t fclonerange(int srcfd, off_t srcoffset, size_t length, int dstfd, off_t dstoffset);
</code></pre></div>
<p dir="auto">Even though fclonerange() takes byte offsets and length, they have to be block-aligned.<br>
Both syscalls call OS-independent zfs_clone_range() function. This function was implemented based on zfs_write(), but instead of writing the given data we first read block pointers using the new dmu_read_l0_bps() function from the source file. Once we have BPs from the source file we call the dmu_brt_addref() function on the destination file. This function allocates BPs for us. We iterate over all source BPs. If the given BP is a hole or an embedded block, we just copy BP. If it points to a real data we place this BP on a BRT pending list using the brt_pending_add() function.</p>
<p dir="auto">We use this pending list to keep track of all BPs that got new references within this transaction group.</p>
<p dir="auto">Some special cases to consider and how we address them:</p>
<ul dir="auto">
<li>The block we want to clone may have been created within the same transaction group as we are trying to clone. Such block has no BP allocated yet, so it is too early to clone it. In this case the dmu_read_l0_bps() function will return EAGAIN and in the zfs_clone_range() function we will wait for the transaction group to be synced to disks and retry.</li>
<li>The block we want to clone may have been modified within the same transaction group. We could potentially clone the previous version of the data, but that doesn't seem right. We handle it as the previous case.</li>
<li>A block may be cloned multiple times during one transaction group (that's why pending list is actually a tree and not an append-only list - this way we can figure out faster if this block is cloned for the first time in this txg or consecutive time).</li>
<li>A block may be cloned and freed within the same transaction group (see dbuf_undirty()).</li>
<li>A block may be cloned and within the same transaction group the clone can be cloned again (see dmu_read_l0_bps()).</li>
<li>A file might have been deleted, but the caller still has a file descriptor open to this file and clones it.</li>
</ul>
<p dir="auto">When we free a block we have additional step in the ZIO pipeline where we call the zio_brt_free() function. We then call the brt_entry_decref() that loads the corresponding BRT entry (if one exists) and decreases reference counter. If this is not the last reference we will stop ZIO pipeline here. If this is the last reference or the block is not in the BRT, we continue the pipeline and free the block as usual.</p>
<p dir="auto">At the beginning of spa_sync() where there can be no more block cloning, but before issuing frees we call brt_pending_apply(). This function applies all the new clones to the BRT table - we load BRT entries and update reference counters. To sync new BRT entries to disk, we use brt_sync() function. This function will sync all dirty top-level-vdev BRTs, regions arrays, etc.</p>
<p dir="auto">Block Cloning and ZIL.</p>
<p dir="auto">Every clone operation is divided into chunks (similar to write) and each chunk is cloned in a separate transaction. To keep ZIL entries small, each chunk clones at most 254 blocks, which makes ZIL entry to be 32kB.  Replaying clone operation is different from the regular clone operation, as when we log clone operation we cannot use the source object - it may reside on a different dataset, so we log BPs we want to clone.<br>
The ZIL is replayed when we mount the given dataset, not when the pool is imported. Taking this into account it is possible that the pool is imported without mounting datasets and the source dataset is destroy before the destination dataset is mounted and its ZIL replayed.<br>
To address this situation we leverage zil_claim() mechanism where ZFS will parse all the ZILs on pool import. When we come across TX_CLONE_RANGE entries, we will bump reference counters for their BPs in the BRT and then on mount and ZIL replay we will just attach BPs to the file without bumping reference counters.<br>
Note it is still possible that after zil_claim() we never mount the destination, so we never replay its ZIL and we destroy it. This way we would end up with leaked references in BRT. We address that too as ZFS gives as a chance to clean this up on dataset destroy (see zil_free_clone_range()).</p>
<h3 dir="auto">How Has This Been Tested?</h3>
<p dir="auto">I have a test program that can make use of this functionality that I have been using for manual testing.</p>
<h3 dir="auto">Types of changes</h3>

<ul>
<li> Bug fix (non-breaking change which fixes an issue)</li>
<li> New feature (non-breaking change which adds functionality)</li>
<li> Performance enhancement (non-breaking change which improves efficiency)</li>
<li> Code cleanup (non-breaking change which makes code smaller or more readable)</li>
<li> Breaking change (fix or feature that would cause existing functionality to change)</li>
<li> Library ABI change (libzfs, libzfs_core, libnvpair, libuutil and libzfsbootenv)</li>
<li> Documentation (a change to man pages or other documentation)</li>
</ul>
<h3 dir="auto">Checklist:</h3>


<ul>
<li> My code follows the OpenZFS <a href="https://github.com/openzfs/zfs/blob/master/.github/CONTRIBUTING.md#coding-conventions">code style requirements</a>.</li>
<li> I have updated the documentation accordingly.</li>
<li> I have read the <a href="https://github.com/openzfs/zfs/blob/master/.github/CONTRIBUTING.md"><strong>contributing</strong> document</a>.</li>
<li> I have added <a href="https://github.com/openzfs/zfs/tree/master/tests">tests</a> to cover my changes.</li>
<li> I have run the ZFS Test Suite with this change applied.</li>
<li> All commit messages are properly formatted and contain <a href="https://github.com/openzfs/zfs/blob/master/.github/CONTRIBUTING.md#signed-off-by"><code>Signed-off-by</code></a>.</li>
</ul>
    </div>
  </task-lists>
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Makie, a modern and fast plotting library for Julia (230 pts)]]></title>
            <link>https://makie.org</link>
            <guid>36587875</guid>
            <pubDate>Tue, 04 Jul 2023 15:22:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://makie.org">https://makie.org</a>, See on <a href="https://news.ycombinator.com/item?id=36587875">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-jscall-id="21">
        <div data-jscall-id="22">
              <p><span data-jscall-id="27">Makie</span> is a modern plotting library for 
                <a href="https://julialang.org/" target="_blank" data-jscall-id="28">Julia</a>.
It is easy to use, fast and powerful. Packed with features,
it is a general-purpose tool that makes as few compromises for specialized use cases as possible.

              </p>
            </div>
        <div data-jscall-id="49">
            <h2 data-jscall-id="51">Features</h2>
            <div data-jscall-id="52">
                  <h2 data-jscall-id="55">Surgical updates &amp; high performance</h2><p>Makie uses Observables.jl to only update what's necessary at a given point in time.
This example animates hundreds of thousands of points just through a colormap update, modifying only a few bytes per frame directly on the GPU.
There's no faster way to animate large data. Combining the power of GPUs and Julia's high performance, Makie is fit for any task!

                  </p>
                </div>
            
            <div data-jscall-id="66">
              <div data-jscall-id="67">
                  <h2 data-jscall-id="69">Powerful Layouting</h2><p>Makie has one of the most powerful layouting systems compared to other plotting
libraries, allowing you to tweak any possible attribute and place your plots
and subplots freely.

                  </p>
                </div>
              <p><a href="https://docs.makie.org/stable/tutorials/layout-tutorial/" target="_blank" data-jscall-id="76">
                  <img src="https://makie.org/jsserve/png/layouting.png" data-jscall-id="77">
                </a>
              </p>
            </div>
            
            <div data-jscall-id="79">
                  <h2 data-jscall-id="82">2D, 3D, Volumes, Meshes, Sliders, Buttons and more</h2><p>Makie has support for all kind of primitives for interactive data exploration. This makes it simple to quickly build up dashboards for any kind of data.

                  </p>
                </div>
            
            <div data-jscall-id="93">
              <div data-jscall-id="94">
                  <h2 data-jscall-id="96">Powerful event system and rendering engine</h2><p>Makie is certainly not a game engine, but its rich rendering and interaction features allow the creation of simple, interactive games such as Minecraft.
While Makie might not be the go-to for more complex games, using it to build a Minecraft-like game highlights its versatility for complex, interactive visualizations.
Many use cases, such as AI gyms or complex, interactive 3D simulations, greatly benefit from this.

                </p></div>
              <p><a href="https://github.com/ashwani-rathee/Miner.jl" target="_blank" data-jscall-id="98">
                  <img src="https://makie.org/jsserve/png/miner.png" data-jscall-id="99">
                </a>
              </p>
            </div>
            
          </div>
        <div data-jscall-id="101">
            <h2 data-jscall-id="103">Backends</h2>
            <p>Makie's backends are the reason why we can have high quality vector graphics for publication while also delivering fast GPU accelerated renderings.
Use exactly the same code and change how your interactive graphic is displayed simply by switching the backend.
</p>
            <div data-jscall-id="105">
              <div data-jscall-id="106">
                  <h2 data-jscall-id="108">GLMakie</h2>
                  <p><span data-jscall-id="109">The backend for fast, interactive desktop applications.
It was Makie's first backend and uses the GPU via OpenGL for fast 3D animations.
It supports basic UI elements for simple Dashboards.
Either a hardware or virtual GPU (e.g. Mesa, VirtualGL) is necessary to use GLMakie.
(Image from:

                    <a href="https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2022MS003527" target="_blank" data-jscall-id="110">A. N. Souza</a>)
                  </span>
                </p></div>
              <p><a href="https://docs.makie.org/stable/documentation/backends/glmakie/" target="_blank" data-jscall-id="112">
                  <img src="https://makie.org/jsserve/png/glmakie.png" data-jscall-id="113">
                </a>
              </p>
            </div>
            
            <div data-jscall-id="115">
              <div data-jscall-id="116">
                  <h2 data-jscall-id="118">CairoMakie</h2>
                  <p><span data-jscall-id="119">CairoMakie runs anywhere on the CPU and is Makie's backend for SVG and PDF vector graphics output.
With CairoMakie, you can achieve the highest quality output for publications and reports.
Because it uses vector graphics primitives, CairoMakie does not support 3D rendering the same way as GLMakie
and has no interactive mode.
(Image from:

                    <a href="https://beautiful.makie.org/" target="_blank" data-jscall-id="120">beautiful.makie.org</a>)
                  </span>
                </p></div>
              <p><a href="https://docs.makie.org/stable/documentation/backends/cairomakie/" target="_blank" data-jscall-id="122">
                  <img src="https://makie.org/jsserve/svg/cairomakie.svg" data-jscall-id="123">
                </a>
              </p>
            </div>
            
            <div data-jscall-id="125">
                  <h2 data-jscall-id="128">WGLMakie</h2>
                  <p><span data-jscall-id="129">WGLMakie puts your visualizations in the browser using Threejs and WebGL.
It runs almost anywhere on the GPU and is great for working on remote machines,
with Pluto or Jupyter notebooks, or in browser-like IDEs such as VSCode.
Like with all javascript-based visualization tools, there is an overhead when transferring large amounts of data to the browser.
(Image from:

                    <a href="https://www.visus.uni-stuttgart.de/" target="_blank" data-jscall-id="130">VISUS</a>)
                  </span>
                </p></div>
            
            <div data-jscall-id="136">
              <div data-jscall-id="137">
                  <h2 data-jscall-id="139">RPRMakie</h2>
                  <p><span data-jscall-id="140">RPRMakie is the newest experimental backend for raytraced images using RadeonProRender.
With appropriately fast hardware, you can render beautiful visualizations that show off your data
using physically accurate materials and lights.
(Image from:

                    <a href="https://github.com/lazarusA" target="_blank" data-jscall-id="141">Lazaro Alonso</a>)
                  </span>
                </p></div>
              <p><a href="https://docs.makie.org/stable/documentation/backends/rprmakie/" target="_blank" data-jscall-id="143">
                  <img src="https://makie.org/jsserve/png/earths_creditst.png" data-jscall-id="144">
                </a>
              </p>
            </div>
          </div>
        <div data-jscall-id="145">
            <h2 data-jscall-id="147">Rich Ecosystem</h2>
            <p>Makie is highly modular and extensible.
Many use cases are already covered by its inbuilt plot types and interactive elements.
For more specialized applications, have a look at the rich third-party ecosystem that has developed around Makie:
</p>
            
          </div>
        <div data-jscall-id="316">
            <p>Users</p>
            
            <p>Supporters</p>
            
            <p>Follow us</p>
            
          </div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sao Paulo: A city with no outdoor advertisements (2013) (581 pts)]]></title>
            <link>https://www.amusingplanet.com/2013/07/sao-paulo-city-with-no-outdoor.html</link>
            <guid>36586632</guid>
            <pubDate>Tue, 04 Jul 2023 13:50:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.amusingplanet.com/2013/07/sao-paulo-city-with-no-outdoor.html">https://www.amusingplanet.com/2013/07/sao-paulo-city-with-no-outdoor.html</a>, See on <a href="https://news.ycombinator.com/item?id=36586632">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-version="2" id="Blog1">
<article data-postid="2347375719013220143">

<div id="post-body-2347375719013220143"><p>In September 2006, the mayor of São Paulo passed the so-called “Clean City Law" that outlawed the use of all outdoor advertisements, including on billboards, transit, and in front of stores. Within a year, 15,000 billboards were taken down and store signs had to be shrunk so as not to violate the new law. Outdoor video screens and ads on buses were stripped. Even pamphleteering in public spaces has been made illegal. Nearly $8 million in fines were issued to cleanse São Paulo of the blight on its landscape. Seven years on, the world's fourth-largest metropolis and South America’s most important city remains free of visual clutter and eye sore that plagues the majority of cities around the world.</p>  <p>When the law was passed, it triggered wild alarm among city businesses and advertisement groups. Critics worried that the advertising ban would entail a revenue loss of $133 million and 20,000 people would lose jobs. Others predicted that the city would look like a bland concrete jungle with the ads removed. </p>  <p><img title="sao-paulo-billboard-ban-2" alt="sao-paulo-billboard-ban-2" src="https://lh3.ggpht.com/-TYoPCASlqVo/UepisNtsvEI/AAAAAAAAqhk/elNkMuvwKDY/sao-paulo-billboard-ban-26.jpg?imgmax=800" width="790" height="526"></p>  <p><a href="http://www.flickr.com/photos/ndecam/6155859365/" rel="nofollow">Photo credit</a></p><p>"I think this city is going to become a sadder, duller place,” said Dalton Silvanom, the lone councilman to vote against the law, and who (unsurprisingly) is in the advertising business. “Advertising is both an art form and, when you're in your car or alone on foot, a form of entertainment that helps relieve solitude and boredom," Silvanom added.</p>  <p>Despite the forebodings, São Paulo’s economy didn’t run aground although the city did look alien and war-torn for a few months following the tear down. The breakneck speed at which the law was enacted caused the city to resemble a battlefield strewn with blank marquees, partially torn-down frames and hastily painted-over storefront facades.</p>  <p>In a survey conducted in 2011 among the city’s 11 million residents, 70 percent found the ban beneficial. Unexpectedly, the removal of logos and slogans exposed previously overlooked architecture, revealing a rich urban beauty that had been long hidden. “My old reference was a big Panasonic billboard,” said Vinicius Galvao, a reporter with Folha de São Paulo, Brazil’s largest newspaper, in an interview with NPR. “But now my reference is an art deco building that was covered [by the massive sign]. So you start getting new references in the city. The city’s now got new language, a new identity.”</p>  <p>Photographer <a href="http://www.flickr.com/photos/tonydemarco" rel="nofollow">Tony de Marco</a> documented the transformation the city underwent in 2007 in a sequence of images published on Flickr. </p>  <p>Sao Paulo isn’t the only city to have banned outdoor advertisements. Bans on billboards exist in other parts of the world, such as Vermont, Alaska, Hawaii, and Maine in the US, as well as some 1,500 towns. In Europe, the Norwegian city of Bergen does the same and many others have imposed severe restrictions on billboards or declared no-billboard zones within the city.</p>  <p><img title="sao-paulo-billboard-ban-4" alt="sao-paulo-billboard-ban-4" src="https://lh3.ggpht.com/-ZM2pOpipWoU/Uepiu-a9viI/AAAAAAAAqhs/DXZ4oekG5K8/sao-paulo-billboard-ban-42.jpg?imgmax=800" width="790" height="592"></p>  <p><img title="sao-paulo-billboard-ban-5" alt="sao-paulo-billboard-ban-5" src="https://lh5.ggpht.com/-OX_nt4ucheU/UepiybZdBdI/AAAAAAAAqh0/EeLcZCyq6go/sao-paulo-billboard-ban-52.jpg?imgmax=800" width="790" height="592"></p>  <p><img title="sao-paulo-billboard-ban-6" alt="sao-paulo-billboard-ban-6" src="https://lh4.ggpht.com/-Qa4wXnNE_5w/Uepi1x86XZI/AAAAAAAAqh8/UaV1Tj-xkm8/sao-paulo-billboard-ban-62.jpg?imgmax=800" width="790" height="592"></p>  <p><img title="sao-paulo-billboard-ban-7" alt="sao-paulo-billboard-ban-7" src="https://lh4.ggpht.com/-FX6vTTY1s7g/Uepi30VO9JI/AAAAAAAAqiE/A9rEu2PB-sM/sao-paulo-billboard-ban-72.jpg?imgmax=800" width="790" height="592"></p>  <p><img title="sao-paulo-billboard-ban-8" alt="sao-paulo-billboard-ban-8" src="https://lh4.ggpht.com/-DJg66H-KPDs/UepjMO-lkSI/AAAAAAAAqiU/tWK9RNK3DQo/sao-paulo-billboard-ban-82.jpg?imgmax=800" width="790" height="592"></p>  <p><img title="sao-paulo-billboard-ban-9" alt="sao-paulo-billboard-ban-9" src="https://lh6.ggpht.com/-5VquaBRt4Vc/UepjQbTGZmI/AAAAAAAAqic/9ZulQL7gcMw/sao-paulo-billboard-ban-92.jpg?imgmax=800" width="790" height="592"></p>  <p><img title="sao-paulo-billboard-ban-10" alt="sao-paulo-billboard-ban-10" src="https://lh6.ggpht.com/-tzgz9EgoWMU/UepjTAWH4HI/AAAAAAAAqik/fXYFWJJp2po/sao-paulo-billboard-ban-102.jpg?imgmax=800" width="790" height="592"></p>  <p><img title="sao-paulo-billboard-ban-11" alt="sao-paulo-billboard-ban-11" src="https://lh5.ggpht.com/-6O3y2DllMlc/Uepj3lswdMI/AAAAAAAAqi0/Fr9XmPNQXMA/sao-paulo-billboard-ban-112.jpg?imgmax=800" width="790" height="592"></p>  <p><img title="sao-paulo-billboard-ban-12" alt="sao-paulo-billboard-ban-12" src="https://lh3.ggpht.com/-Pxw2cBLrBKA/Uepj8h96N1I/AAAAAAAAqi8/S9bWMXwQzg4/sao-paulo-billboard-ban-122.jpg?imgmax=800" width="790" height="592"></p>  <p><img title="sao-paulo-billboard-ban-13" alt="sao-paulo-billboard-ban-13" src="https://lh5.ggpht.com/-_2PgvPxP1Cs/UepkAZPhNzI/AAAAAAAAqjE/XEwdMvJ_q6o/sao-paulo-billboard-ban-132.jpg?imgmax=800" width="790" height="592"></p>  <p><img title="sao-paulo-billboard-ban-3" alt="sao-paulo-billboard-ban-3" src="https://lh3.ggpht.com/-8ylIbVYwavw/UepkDv9WeII/AAAAAAAAqjM/RC7mBOR6Np8/sao-paulo-billboard-ban-36.jpg?imgmax=800" width="790" height="592"></p>  <p>Sources: <a href="http://www.newdream.org/resources/sao-paolo-ad-ban">Newdream</a>, <a href="http://www.businessweek.com/stories/2007-06-18/s-o-paulo-the-city-that-said-no-to-advertisingbusinessweek-business-news-stock-market-and-financial-advice">Businessweek</a>, <a href="https://www.adbusters.org/magazine/73/Sao_Paulo_A_City_Without_Ads.html">Adbusters</a>, <a href="http://www.economist.com/node/9963268">Economist</a></p>  </div>


</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Firefox 115 Now Available with Intel GPU Video Decoding on Linux (162 pts)]]></title>
            <link>https://www.phoronix.com/news/Mozilla-Firefox-115</link>
            <guid>36586481</guid>
            <pubDate>Tue, 04 Jul 2023 13:38:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.phoronix.com/news/Mozilla-Firefox-115">https://www.phoronix.com/news/Mozilla-Firefox-115</a>, See on <a href="https://news.ycombinator.com/item?id=36586481">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><img alt="MOZILLA" src="https://www.phoronix.com/assets/categories/mozilla.webp" width="100" height="100"></p><p>
Mozilla Firefox 115.0 official builds are now available for this notable update to this open-source web browser while also marking the new Extended Support Release (ESR) series.
</p><p>
Most prominent for Linux users of Firefox 115.0 is Intel graphics video decoding being enabled by default. Mozilla has finally blessed Intel graphics hardware with the open-source VA-API video decode stack to enable that hardware acceleration by default.
</p><p><img src="https://www.phoronix.net/image.php?id=intel-arc-nov&amp;image=intel_arc_0_med"></p>
<p>Also on the video acceleration front with Firefox 115 is now supporting Cisco's OpenH264 plug-in for platforms lacking H.264 video decoding otherwise.
</p><p>
Firefox 115 under Linux also now treats middle clicks on the new tab button as opening the xclipboard contents into the new tab. If the xclipboard contents is a URL it will open that URL otherwise it will seed the contents to the default search provider. Firefox 115 also allows undo and redo actions on password fields.
</p><p>
Firefox 115.0 also adds support for migrating payment methods saved in Chrome into Firefox, UI improvements for data importing from other browsers, and various other usability enhancements.
</p><p>
Grab Firefox 115 from <a href="https://ftp.mozilla.org/pub/firefox/releases/115.0/">Mozilla.org</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[More than 75% of Steam games tested are playable or verified on the Steam Deck (587 pts)]]></title>
            <link>https://mastodon.cloud/@boilingsteam/110655979942850128</link>
            <guid>36586346</guid>
            <pubDate>Tue, 04 Jul 2023 13:27:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mastodon.cloud/@boilingsteam/110655979942850128">https://mastodon.cloud/@boilingsteam/110655979942850128</a>, See on <a href="https://news.ycombinator.com/item?id=36586346">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Anti-ageing protein injection boosts monkeys’ memories (162 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-023-02214-3</link>
            <guid>36586262</guid>
            <pubDate>Tue, 04 Jul 2023 13:18:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-023-02214-3">https://www.nature.com/articles/d41586-023-02214-3</a>, See on <a href="https://news.ycombinator.com/item?id=36586262">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <header>
        <div>
            <ul data-test="article-identifier">
                <li data-test="article-category"><span>NEWS</span></li>
                <li><time datetime="2023-07-04">04 July 2023</time></li>
                
            </ul>

            

            <div>
                
                <p>
                    First primate studies to show cognitive benefits of the protein klotho could be a step towards clinical applications.
                </p>
            </div>
        </div>
        
            <div data-test="author-info">
    <ol>
        
            <li>
                
                    <span>Lilly Tozer</span>
                
                
                
                    
                
            </li>
        
    </ol>
</div>
        
    </header>
    
</div><div>
                    <figure>
 <picture>
  <source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-023-02214-3/d41586-023-02214-3_25567502.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-023-02214-3/d41586-023-02214-3_25567502.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px">
  <img alt="Rhesus macaque &quot;Joe&quot; lies on a rock at the zoo in Dresden, Germany." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-023-02214-3/d41586-023-02214-3_25567502.jpg">
  <figcaption>
   <p><span>Old rhesus monkeys perform better in memory tests after being given an injection of klotho. </span><span>Credit: Arno Burgi/AFP via Getty</span></p>
  </figcaption>
 </picture>
</figure><p>Injecting ageing monkeys with a ‘longevity factor’ protein can improve their cognitive function, a study reveals.</p><p>The findings, published on 3 July in <i>Nature Aging</i><sup><a href="#ref-CR1" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">1</a></sup>, could lead to new treatments for neurodegenerative diseases.</p><p>It is the first time that restoring levels of klotho — a naturally occurring protein that declines in our bodies with age — has been shown to improve cognition in a primate. Previous research on mice had shown that injections of klotho can extend the animals’ lives and increases synaptic plasticity<sup><a href="#ref-CR2" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">2</a></sup> — the capacity to control communication between neurons, at junctions called synapses.</p><p>“Given the close genetic and physiological parallels between primates and humans, this could suggest potential applications for treating human cognitive disorders,” says Marc Busche, a neurologist at the UK Dementia Research Institute group at University College London.</p><p>The protein is named after the Greek goddess Clotho, one of the Fates, who spins the thread of life.</p><h2>Monkey memory tests</h2><p>The study involved testing the cognitive abilities of old rhesus macaques (<i>Macaca mulatta</i>), aged around 22 years on average, before and after a single injection of klotho. To do this, researchers used a behavioural experiment to test for spatial memory: the monkeys had to remember the location of an edible treat, placed in one of several wells by the investigator, after it was hidden from them.</p><p>Study co-author Dena Dubal, a physician-researcher at the University of California, San Francisco, compares the test to recalling where you left your car in a car park, or remembering a sequence of numbers a couple of minutes after hearing it. Such tasks become harder with age.</p><p>The monkeys performed significantly better in these tests after receiving klotho — before the injections they identified the correct wells around 45% of the time, compared with around 60% of the time after injection. The improvement was sustained for at least two weeks. Unlike in previous studies involving mice, relatively low doses of klotho were effective. This adds an element of complexity to the findings, which suggests a more nuanced mode of actions than was previously thought, Busche says.</p><h2>Unclear mechanism</h2><p>It is still unclear exactly how injecting klotho has this effect on cognition or why it lasts this long. Klotho itself cannot cross the barrier from blood to brain, and uncovering its mechanism is a matter of finding what intermediates are involved, explains Dubal. But this study “certainly gives us hope”, she says, “and there’s a very strong reason to jump into human clinical trials now”.</p><p>Gøril Rolfseng Grøntvedt, a neurologist at the Norwegian University of Science and Technology in Trondheim, agrees that further work is needed to answer such questions. Grøntvedt and her team previously found that people with Alzheimer’s who have naturally higher klotho levels tend to experience less cognitive impairment than do those with lower levels<sup><a href="#ref-CR3" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">3</a></sup>.</p><p>This raises the possibility that artificially increasing klotho might have beneficial effects. A better understanding of the protein’s mode of action will be “crucial” for realizing its clinical potential, Grøntvedt says.</p>
                </div><div id="references" aria-labelledby="Bib1"><h2 id="Bib1">References</h2><div data-container-section="references" id="Bib1-content"><ol data-track-component="outbound reference"><li data-counter="1."><p id="ref-CR1">Castner, S. A. <i>et al.</i> <i>Nature Aging </i>https://doi.org/10.1038/s43587-023-00441-x (2023).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s43587-023-00441-x" data-track-action="article reference" href="https://doi.org/10.1038%2Fs43587-023-00441-x" aria-label="Article reference 1" data-doi="10.1038/s43587-023-00441-x">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=&amp;journal=Nature%20Aging&amp;doi=10.1038%2Fs43587-023-00441-x&amp;publication_year=2023&amp;author=Castner%2CS.%20A.">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="2."><p id="ref-CR2">Dubal, D. B. <i>et al.</i> <i>J. Neurosci.</i> 35, 2358–2371 (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.5791-12.2015" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.5791-12.2015" aria-label="Article reference 2" data-doi="10.1523/JNEUROSCI.5791-12.2015">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25673831" aria-label="PubMed reference 2">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.5791-12.2015&amp;volume=35&amp;pages=2358-2371&amp;publication_year=2015&amp;author=Dubal%2CD.%20B.">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="3."><p id="ref-CR3">Grøntvedt, G. R. <i>et al.</i> <i>JAMA Netw. Open</i> <b>5</b>, e2243232 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1001/jamanetworkopen.2022.43232" data-track-action="article reference" href="https://doi.org/10.1001%2Fjamanetworkopen.2022.43232" aria-label="Article reference 3" data-doi="10.1001/jamanetworkopen.2022.43232">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36413367" aria-label="PubMed reference 3">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 3" href="http://scholar.google.com/scholar_lookup?&amp;title=&amp;journal=JAMA%20Netw.%20Open&amp;doi=10.1001%2Fjamanetworkopen.2022.43232&amp;volume=5&amp;publication_year=2022&amp;author=Gr%C3%B8ntvedt%2CG.%20R.">
                    Google Scholar</a>&nbsp;
                </p></li></ol><p><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/d41586-023-02214-3?format=refman&amp;flavour=references">Download references</a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tips for programmers to stay ahead of generative AI (203 pts)]]></title>
            <link>https://spectrum.ieee.org/ai-programming</link>
            <guid>36586248</guid>
            <pubDate>Tue, 04 Jul 2023 13:17:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/ai-programming">https://spectrum.ieee.org/ai-programming</a>, See on <a href="https://news.ycombinator.com/item?id=36586248">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-elid="2662065692" data-post-url="https://spectrum.ieee.org/ai-programming" data-authors="Rina Diane Caballar" data-headline="How Coders Can Survive—and Thrive—in a ChatGPT World" data-page-title="How Coders Can Survive—and Thrive—in a ChatGPT World - IEEE Spectrum"><p><a href="https://spectrum.ieee.org/topic/artificial-intelligence/" target="_self">Artificial intelligence</a>, particularly generative AI powered by large language models (LLMs), <a href="https://spectrum.ieee.org/artificial-general-intelligence" target="_blank">could upend</a> many <a href="https://spectrum.ieee.org/ai-code-generation-language-models" target="_self">coders’ livelihoods</a>. But some experts argue that AI won’t replace human programmers—not immediately, at least.</p><p>“You will have to worry about people who are using AI replacing you,” says <a href="https://www.tanishq.ai/" rel="noopener noreferrer" target="_blank">Tanishq Mathew Abraham</a>, a Ph.D. candidate in <a href="https://spectrum.ieee.org/topic/biomedical/">biomedical</a> engineering at the University of California, Davis and the CEO of medical AI research center <a href="https://medarc.ai/" rel="noopener noreferrer" target="_blank">MedARC</a>.</p><p>So how can software developers make themselves more useful and relevant in what appears to be a coming age of LLM-centered coding? Here are some tips and techniques for coders to survive and thrive in a generative AI world.</p><h2>Stick to Basics and Best Practices</h2><p>While the myriad AI-based coding assistants could help with code completion and code generation, the fundamentals of programming remain: the ability to read and reason about your own and others’ code, and understanding how the code you write fits into a larger system.</p><p>“I believe AI can dramatically increase the productivity of software developers, but there is a lot more to software engineering than just generating code—from eliciting user requirements to debugging, testing, and more,” says <a href="https://hci.seas.harvard.edu/people/priyan-vaithilingam" rel="noopener noreferrer" target="_blank">Priyan Vaithilingam</a>, a Ph.D. student working in the intersection of human-computer interaction and programming languages at Harvard University’s <a href="https://seas.harvard.edu/" rel="noopener noreferrer" target="_blank">John A. Paulson School of Engineering and Applied Sciences</a>.</p><p>One of the most integral programming skills continues to be the domain of human coders: problem solving. Analyzing a problem and finding an elegant solution for it is still a highly regarded coding expertise.</p><p>“There’s a creative aspect to it, and a lot of those skills of approaching a problem are more important than the actual language or tools,” says <a href="https://ines.io/" rel="noopener noreferrer" target="_blank">Ines Montani</a>, a Fellow of the <a href="https://www.python.org/psf/fellows/" target="_blank">Python Software Foundation</a> and cofounder and CEO of <a href="https://explosion.ai/" rel="noopener noreferrer" target="_blank">Explosion</a>, a software company specializing in developer tools for AI and natural-language processing. “Don’t fall into the trap of comparing yourself to the AI, which is more or less a statistical output of a large model. There are differences in what a developer does versus what the model outputs—there’s more to being a developer than just writing arbitrary lines of code.”</p><p>Additionally, good software-engineering practices are proving even more valuable than before. These practices include planning out the system design and software architecture, which serves as a good context for AI-based tools to more effectively predict what code you need next.</p><p>“A human coder is still the one who has to figure out the structure of a piece of code, the right abstractions around which to organize it, and the requirements for different interfaces,” says <a href="https://www.csail.mit.edu/person/armando-solar-lezama" rel="noopener noreferrer" target="_blank">Armando Solar-Lezama</a>, an associate director and chief operating officer of MIT’s <a href="https://www.csail.mit.edu/" rel="noopener noreferrer" target="_blank">Computer Science and Artificial Intelligence Laboratory</a>, and who leads the lab’s computer-aided programming group. “All of those are central to software-engineering practice, and they’re not going to go away soon.”</p><h2>Find the Tool That Fits Your Needs</h2><p>Finding the right AI-based tool is essential. Each tool has its own ways to interact with it, and there are different ways to incorporate each tool into your development workflow—whether that’s automating the creation of unit tests, generating test data, or writing documentation.</p><p><a href="https://github.com/features/copilot" rel="noopener noreferrer" target="_blank">GitHub Copilot</a> and other AI coding assistants, for instance, can augment programming, offering suggestions as you code. <a href="https://openai.com/blog/chatgpt" rel="noopener noreferrer" target="_blank">ChatGPT</a> and Google’s <a href="https://bard.google.com/" rel="noopener noreferrer" target="_blank">Bard</a>, on the other hand, act more like conversational AI programmers and can be used to answer questions about APIs (application programming interfaces) or generate code snippets.</p><p>The trick is to experiment. Play around with the AI tool, get a feel for how it works, consider the quality of its outputs—but keep an open mind for other tools. “AI is such a fast-moving field. You don’t want to just settle on a tool and then use that for the rest of your life, so you’ll need to adapt quickly to new ones,” Abraham says.</p><p>Think about appropriate use cases as well. Generative AI tools can provide a swift route to learning new programming languages or frameworks, and they can also be a quicker way to kick off small projects and create prototypes.</p><h2>Clear and Precise Conversations Are Key</h2><p>When using AI coding assistants, be detailed about what you need and view it as an iterative process. Abraham proposes writing a comment that explains the code you want so the assistant can generate relevant suggestions that meet your requirements.</p><p>For conversational AI programmers, you’ll need to know the best way to frame your prompts. This is where <a href="https://learnprompting.org/docs/basics/prompting" rel="noopener noreferrer" target="_blank">prompt engineering</a> comes in.</p><p>One approach Abraham suggests is <a href="https://www.promptingguide.ai/techniques/cot" rel="noopener noreferrer" target="_blank">chain-of-thought prompting</a>. This involves a divide-and-conquer strategy where you break down a problem into multiple steps and tackle each one to solve the entire problem. “Asking the model to do too much at a given time can lead to disaster. You want it to be able to work with manageable chunks of information and produce manageable chunks of code,” he says.</p><p>Instead of asking an AI programmer to code an entire program from scratch, for example, consider the different tasks the program is trying to accomplish. Divide those tasks further and ask the model to write specific functions for each. You might need to reason with the model about the steps it needs to take to achieve a task, resulting in a back-and-forth conversation.</p><p>“Treat it almost like a smart intern who knows a lot about a subject but isn’t that experienced,” Abraham says.</p><p>Precision and clarity are vital with prompt engineering. “You need to ask the model very clearly what you want, be very precise about what you’re asking it to do, and make sure you’re following up,” Abraham says.</p><p>It can also be valuable to learn the basic concepts of <a href="https://spectrum.ieee.org/topic/artificial-intelligence/">artificial intelligence</a> and machine learning, as well as get a sense of how large language models work and their strengths and weaknesses. You don’t need to dive deep, but having some general knowledge can give you important context about the results.</p><p>To help you get started, Abraham recommends the <a href="https://github.com/openai/openai-cookbook" rel="noopener noreferrer" target="_blank">OpenAI Cookbook</a>, which has sections on prompting libraries and tools, prompting guides, and video courses, while Vaithilingam suggests reading up on <a href="http://jalammar.github.io/illustrated-transformer/" rel="noopener noreferrer" target="_blank">the Illustrated Transformer</a> to find out more about models and machine-learning basics.</p><h2>Be Critical and Understand the Risks</h2><p>Software engineers should be <a href="https://spectrum.ieee.org/ai-software" target="_self">critical of the outputs of large language models</a>, as they tend to <a href="https://spectrum.ieee.org/ai-hallucination" target="_self">hallucinate</a> and produce inaccurate or incorrect code. “It’s easy to get stuck in a debugging rabbit hole when blindly using AI-generated code, and subtle bugs can be difficult to spot,” Vaithilingam says.</p><p>That’s why checking generated code is crucial, though it adds an extra step, which might harm more than help productivity. But Abraham argues that “it’s easier to verify the code than it is to write it from scratch in some cases, and it’s a faster approach to generate and then verify before incorporating into whatever codebase you have.”</p><p>It might be worth putting the outputs of these models into perspective, asking the following questions: What data was this model trained on? What was filtered out and not included in that data? How old is the training data, and what version of a programming language, software package, or library was the model trained on? The answers to these questions could impact the results and provide more context about them.</p><p>Developers should also be wary of entering proprietary code into these models. Some companies, such as <a href="https://www.tabnine.com/" rel="noopener noreferrer" target="_blank">Tabnine</a>, offer enterprise versions of their AI coding assistants, providing <a href="https://spectrum.ieee.org/ai-and-data-privacy" target="_self">privacy</a> while still learning an organization’s coding patterns and style.</p><p><a href="https://spectrum.ieee.org/generative-ai-ip-problem" target="_self">Copyright</a> is another factor to consider, though it’s less of a worry if you’re using these tools to complete a few lines of code or generate code for common or trivial tasks compared to producing bigger chunks of code.</p><p>“Programmers should have some sense of how original what they’re trying to do is and to what extent is it unique to their context,” Solar-Lezama says. “If the model is producing a somewhat original piece of code, it’s important to be suspicious and skeptical before putting that in a production codebase.”</p><p>An even larger issue is security, as these models may generate code containing vulnerabilities. According to Vaithilingam, software-development best practices such as code reviews and strong test pipelines can help safeguard against this risk.</p><p>“One of the things that more experienced software engineers bring to the table is the awareness of the most common vulnerabilities in code and the most common ways in which code can be made vulnerable,” says Solar-Lezama. “They build this intuition about what to pay attention to and what raises red flags. Moving forward, these kinds of techniques are going to become more important parts of the software engineering mix.”</p><p>For programmers to survive in a generative AI world, they’ll need to embrace AI as a tool and incorporate AI into their workflow while recognizing the opportunities and limitations of these tools—and still relying on their human coding capabilities to thrive.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google's updated privacy policy states it can use public data to train its AI (162 pts)]]></title>
            <link>https://www.engadget.com/googles-updated-privacy-policy-states-it-can-use-public-data-to-train-its-ai-models-095541684.html</link>
            <guid>36586170</guid>
            <pubDate>Tue, 04 Jul 2023 13:08:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.engadget.com/googles-updated-privacy-policy-states-it-can-use-public-data-to-train-its-ai-models-095541684.html">https://www.engadget.com/googles-updated-privacy-policy-states-it-can-use-public-data-to-train-its-ai-models-095541684.html</a>, See on <a href="https://news.ycombinator.com/item?id=36586170">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Google has updated its privacy policy to state that it can use publicly available data to help train its AI models. The tech giant has changed the wording of its policy over the weekend and switched "AI models" for "language models." It also stated that it could use publicly available information to build not just features, but full products like "Google Translate, <a data-i13n="cpos:1;pos:1" href="https://www.engadget.com/googles-bard-ai-is-getting-better-at-programming-160034882.html" data-ylk="elm:context_link;cpos:1;pos:1;itc:0">Bard</a>, and Cloud AI capabilities." By updating its policy, it's letting people know and making it clear that anything they publicly post online could be used to train Bard, its future versions and any other generative AI product Google develops.</p>
<p>The tech giant has highlighted the changes to its privacy policy on its <a data-i13n="cpos:2;pos:1" href="https://policies.google.com/privacy/archive/20221215-20230701" rel="nofollow noopener" target="_blank" data-ylk="elm:context_link;cpos:2;pos:1;itc:0">archive</a>, but here's a copy of the pertinent part:</p>
<figure><img src="https://mysterio.yahoo.com/api/res/1.2/KlZSw76QRsecI.2xOhyTWA--/ZHByPTI7dz04NzU7YXBwaWQ9ZW5nYWRnZXQ-/https://s.yimg.com/os/creatr-uploaded-images/2023-07/726f2c40-1a48-11ee-9f37-710bb6919367.cf.webp" alt="Google's privacy policy, which reads: " data-uuid="7bb5def7-6813-30f2-ae91-37379c33fa92" loading="lazy"><figcaption></figcaption><p>Google</p></figure>
<p>Critics have been raising concerns about companies' use of information posted online to train their large language models for generative AI use. Recently, a proposed class action lawsuit was <a data-i13n="cpos:3;pos:1" href="https://edition.cnn.com/2023/06/28/tech/openai-chatgpt-microsoft-data-sued/index.html" rel="nofollow noopener" target="_blank" data-ylk="elm:context_link;cpos:3;pos:1;itc:0">filed against OpenAI</a>, accusing it of scraping "massive amounts of personal data from the internet," including "stolen private information," to train its GPT models without prior consent. As <a data-i13n="cpos:4;pos:1" href="https://www.searchenginejournal.com/google-updates-privacy-policy-to-collect-public-data-for-ai-training/490715/#close" rel="nofollow noopener" target="_blank" data-ylk="elm:context_link;cpos:4;pos:1;itc:0"><em>Search Engine Journal</em></a> notes, we'll likely see plenty of similar lawsuits in the future as more companies develop their own generative AI products.&nbsp;</p>
<p>Owners of websites that could be considered public squares in the digital age have also taken steps to either prevent or profit from the generative AI boom. Reddit has started charging for access to its API, leading third-party clients to <a data-i13n="cpos:5;pos:1" href="https://www.engadget.com/apollo-and-other-popular-third-party-reddit-apps-have-shut-down-123149140.html" data-ylk="elm:context_link;cpos:5;pos:1;itc:0">shut down</a> over the weekend. Meanwhile, Twitter <a data-i13n="cpos:6;pos:1" href="https://www.engadget.com/twitter-puts-strict-cap-on-how-many-tweets-users-can-read-each-day-182623928.html" data-ylk="elm:context_link;cpos:6;pos:1;itc:0">put a restriction</a> on how many tweets a user sees per day to "address extreme levels of data scraping [and] system manipulation."</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to pass any first-round interview (even in a terrible talent market) (172 pts)]]></title>
            <link>https://www.lennysnewsletter.com/p/how-to-pass-any-first-round-interview</link>
            <guid>36586129</guid>
            <pubDate>Tue, 04 Jul 2023 13:04:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lennysnewsletter.com/p/how-to-pass-any-first-round-interview">https://www.lennysnewsletter.com/p/how-to-pass-any-first-round-interview</a>, See on <a href="https://news.ycombinator.com/item?id=36586129">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><em><span>👋 Hey,&nbsp;Lenny&nbsp;here!&nbsp;Welcome to this month’s&nbsp;✨&nbsp;</span><strong>free edition&nbsp;</strong><span>✨ of Lenny’s Newsletter. Each week I tackle reader questions about building product, driving growth, and accelerating your career.</span></em></p><p><em>If you’re not a subscriber, here’s what you missed this month:</em></p><ol><li><p><em><a href="https://www.lennysnewsletter.com/p/the-unconventional-palantir-principles" rel="">The unconventional Palantir principles that catalyzed a generation of startups</a></em></p></li><li><p><em><a href="https://www.lennysnewsletter.com/p/what-5-years-at-reddit-taught-us" rel="">What 5 years at Reddit taught us about building for a highly opinionated user base</a></em></p></li><li><p><em><a href="https://www.lennysnewsletter.com/p/how-a-traumatic-brain-injury-made" rel="">How a traumatic brain injury made me a better PM—and person</a></em></p></li><li><p><em><a href="https://www.lennysnewsletter.com/p/how-to-create-an-exceptional-coverage" rel="">How to create an exceptional coverage plan for your parental leave</a></em></p></li></ol><p><em>Subscribe to get access to these posts, and every post.</em></p><p><span>This week’s post comes from the amazing </span><a href="https://coacherika.co/" rel="">Coach Erika</a><span>. Since 2020, Erika has coached 200+ job seekers on how to land their dream jobs. In today’s post, she shares a step-by-step guide for passing your first-round interview—with practical frameworks, tons of practice questions (with answers), and even a daily schedule to help you make the most of your available prep time. If you’re currently interviewing, or plan to, this will change your life.</span></p><p><span>For more, follow Coach Erika on </span><a href="https://www.linkedin.com/in/egemzer/" rel="">LinkedIn</a><span>, </span><a href="https://twitter.com/ErikaCoaches/" rel="">Twitter</a><span>, and definitely check out her newsletter, </span><a href="https://thecareerwhispers.substack.com/" rel="">The Career Whispers</a><span>.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3cbfb8d-5a19-41db-83bb-454801ac8d4c_8000x4000.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3cbfb8d-5a19-41db-83bb-454801ac8d4c_8000x4000.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3cbfb8d-5a19-41db-83bb-454801ac8d4c_8000x4000.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3cbfb8d-5a19-41db-83bb-454801ac8d4c_8000x4000.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3cbfb8d-5a19-41db-83bb-454801ac8d4c_8000x4000.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3cbfb8d-5a19-41db-83bb-454801ac8d4c_8000x4000.png" width="1456" height="728" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f3cbfb8d-5a19-41db-83bb-454801ac8d4c_8000x4000.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:728,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:4881236,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3cbfb8d-5a19-41db-83bb-454801ac8d4c_8000x4000.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3cbfb8d-5a19-41db-83bb-454801ac8d4c_8000x4000.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3cbfb8d-5a19-41db-83bb-454801ac8d4c_8000x4000.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff3cbfb8d-5a19-41db-83bb-454801ac8d4c_8000x4000.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Today I’m going to teach you how to pass any first-round interview in tech, even in a difficult talent market.</p><p>I’ve coached over 200 people in tech job searches (from APMs to eng managers to chief product officers, and everything in between). 93% percent of them landed jobs at Google, Meta, Uber, Airbnb, Stripe, or a similar top-tier tech company—without burning themselves to the ground endlessly preparing, or winging it and hoping for the best.</p><p>I’m not a recruiter or HR leader. I’m an engineer and product manager, like many of you. In 2013, I landed my first job in Big Tech (at Google), and my career took off. Over the next 10 years, I moved into management and leadership roles, where I learned about how the sausage is made when it comes to interviews, offers, and talent assessments. Now, I’m a chief product officer, and&nbsp;I moonlight as a career coach to help people unlock outsized career opportunities.</p><p>My goal in sharing this Minimum Viable Interview Prep (MVIP) process is to arm you with the employer and interviewer perspective so that you can build confidence in your job search. I’m passionate about helping people with job searching because I know how much the right role can set you up for success in your career and financial life.</p><p>First rounds are designed to filter out candidates who are unlikely to be a contender for an offer.</p><p><span>Interviews are</span><em> very</em><span> expensive for employers (time, coordination, resources, opportunity cost). The singular goal of a first-round interview (from the employer’s perspective) is to determine if they want to invest in additional interviews with that candidate.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe24a39eb-70f0-4521-8536-7fc73f709c48_1408x1056.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe24a39eb-70f0-4521-8536-7fc73f709c48_1408x1056.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe24a39eb-70f0-4521-8536-7fc73f709c48_1408x1056.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe24a39eb-70f0-4521-8536-7fc73f709c48_1408x1056.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe24a39eb-70f0-4521-8536-7fc73f709c48_1408x1056.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe24a39eb-70f0-4521-8536-7fc73f709c48_1408x1056.png" width="1408" height="1056" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e24a39eb-70f0-4521-8536-7fc73f709c48_1408x1056.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1056,&quot;width&quot;:1408,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:183898,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe24a39eb-70f0-4521-8536-7fc73f709c48_1408x1056.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe24a39eb-70f0-4521-8536-7fc73f709c48_1408x1056.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe24a39eb-70f0-4521-8536-7fc73f709c48_1408x1056.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe24a39eb-70f0-4521-8536-7fc73f709c48_1408x1056.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>By the time you get to a first-round interview, you likely have already:</p><ul><li><p>Applied or been referred by an employee</p></li><li><p>Spoken to a recruiter or HR representative (phone screen)</p></li></ul><p>If you pass a first-round interview, the next step is often second rounds (another single interview), or even final-round interviews (three to six interviews back-to-back in one day or split over two days).</p><p><strong>Most first-round interviews in tech are:</strong></p><ul><li><p>30 minutes to 1 hour</p></li><li><p>on the phone or via video chat</p></li><li><p>with just one interviewer (not panel-style)</p></li><li><p>conducted by a hiring manager, peer, or another person familiar with the role</p></li></ul><p><strong>The standard time breakdown is typically:</strong></p><ul><li><p>10% intro</p></li><li><p>70% questions from the interviewer</p></li><li><p>20% questions from the candidate</p></li></ul><p><strong>For a 45-minute interview, this looks like:</strong></p><ul><li><p>3-5 minutes intros</p></li><li><p>35 minutes questions from the interviewer</p></li><li><p>5-7 minutes questions from the candidate</p></li></ul><p><strong>Most first-round interviews stick to behavioral questions</strong><span>, i.e. questions that ask you about your own experiences, like</span><em> “Tell me about a time when you had a conflict with a colleague.”</em></p><p><strong>Generally, the first-round interview scope isn’t comprehensive.</strong><span> Employers aren’t going to be able to fully assess your fit for the role/team/company in less than 60 minutes!&nbsp;</span></p><p><em>Note: It’s a bit of a hot take, but I advise people to run if a company gives you an offer at this stage. (Just imagine how undiscerning they will have been with your future peers as well!)&nbsp;</em></p><p>On-the-spot offers in tech are rare, but all of us who build products know that systems fail at the edge cases—few of you will get an offer in your first or second interview (and this is a good thing), but my advice is to walk away (or at least ask a lot of questions) if you get an offer on the spot.</p><p><strong>Common first-round interview question themes:</strong></p><ul><li><p>Your resume and online content (including expertise posts and thought leadership)</p></li><li><p>1-2 core competencies for the role (usually the P0s, not the P2s and P3s)</p></li><li><p><span>Culture fit (these can be direct questions, e.g. “</span><em>Describe your ideal team culture,” </em><span>or indirect assessments based on your behavior, mannerisms, or speech: what you say and how you say it)</span></p></li></ul><p><strong>Special cases</strong></p><p><em>Are you a software engineer or data scientist? </em><span>Your first-round interview will likely be a technical screen (coding or system design or experimental design). Note that the way you problem-solve and communicate are assessed, not just whether you arrive at a working solution!</span></p><p><em>Are you a PM?</em><span> Your first-round interview will likely focus more on product design, product sense/execution, and data analysis or estimation questions (PM core competencies).</span></p><p>It’s time to talk about tactics for interview preparation.&nbsp;</p><p>Now is a good time to introduce Minimum Viable Interview Prep (MVIP). Below is a quick summary of the approach, with links to dive deeper before your next interview.</p><p><strong>Know your digital footprint</strong></p><p>Anything and everything on the open web is fair game for an employer or interviewer to read and bring up in your interviews. This includes LinkedIn posts, Medium or Substack articles, GitHub, tweets, old blog posts, quotes in newspaper articles, etc.&nbsp;</p><p>A useful to-do list:</p><ol><li><p>Know what’s out there (about you or authored by you)</p></li><li><p>Assess whether it fits how you’d like to present yourself</p></li><li><p>Modify as needed to represent yourself as you’d prefer</p></li></ol><p>For example: If I were looking for a data science role, I’d want to spend a few hours organizing the Python code in my public machine learning GitHub repo. It was written under timeline duress (!) and needs some refactoring so I can put my best foot forward if someone skims the code.</p><p><strong>Know your (strategic and compelling) reasons for wanting this role</strong></p><p>When you go for an interview, you should assume the company is assessing at least two to four other people for the role. Like any competition, you want to get out front quickly and take the lead. One way to do this is to be clear and concise about why you want this job.</p><p>Generally, avoid reasons that revolve around work hygiene or professional conveniences, e.g. compensation, short commute, remote work. This advice may seem obvious, but yes, people bring these up often. Don’t be one of them.</p><p>Avoid reasons that sound like complaints about your current or past employer, e.g. “better company,” “smarter colleagues,” “kinder boss,” “escaping a toxic culture.”</p><p>Stick to reasons that:&nbsp;</p><ol><li><p>convey what you bring to the role (the compelling ones for the employer)</p></li><li><p>explain how this role will accelerate your career (the strategic reasons)</p></li></ol><p><span>You don’t need 10 reasons. One single, decisive reason will do: </span><em>“I’ve spent eight years building large-scale, distributed systems for products used by about 100 million users. An exciting and progressive step for me would be to build similar technologies for the billion-user scale.”</em></p><p><strong>Know the role (map it)</strong></p><p>One of the oldest sales tricks in the book is a tactic called “mirroring.” It’s a psychological concept that involves physically and verbally doing what the other person is doing. People are comfortable with their own mannerisms. When you mirror them, you make them comfortable and subconsciously make them feel you are like them.</p><p><span>You can use mirroring in your interview process. How? Use </span><em>their</em><span> language when describing </span><em>your</em><span> experiences.</span></p><p><strong>How to do this (interview pre-work)</strong></p><ol><li><p>Paste the job description into a doc, then highlight keywords and concepts.</p></li><li><p><span>Put the keywords into a table (one row per keyword or concept). Then add a column to the right. </span><a href="https://docs.google.com/spreadsheets/d/16rMkstp5LsN99TEGALCBE4_bM7KqxpOW35swrIRzyD8/copy" rel="">Here’s a template to get you started</a><span>.</span></p></li><li><p>In the right column, write down parts of your experience that map to that concept.</p></li><li><p>Read this before your interview.</p></li><li><p>In the interview, when you talk about your experience (right column), use their language (left column) to explain what you did.</p></li></ol><p><strong>Example:</strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc0f0ea-c0a4-41d9-bd5e-b8a066f9cd8d_926x840.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc0f0ea-c0a4-41d9-bd5e-b8a066f9cd8d_926x840.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc0f0ea-c0a4-41d9-bd5e-b8a066f9cd8d_926x840.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc0f0ea-c0a4-41d9-bd5e-b8a066f9cd8d_926x840.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc0f0ea-c0a4-41d9-bd5e-b8a066f9cd8d_926x840.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc0f0ea-c0a4-41d9-bd5e-b8a066f9cd8d_926x840.png" width="476" height="431.792656587473" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cdc0f0ea-c0a4-41d9-bd5e-b8a066f9cd8d_926x840.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:840,&quot;width&quot;:926,&quot;resizeWidth&quot;:476,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc0f0ea-c0a4-41d9-bd5e-b8a066f9cd8d_926x840.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc0f0ea-c0a4-41d9-bd5e-b8a066f9cd8d_926x840.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc0f0ea-c0a4-41d9-bd5e-b8a066f9cd8d_926x840.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcdc0f0ea-c0a4-41d9-bd5e-b8a066f9cd8d_926x840.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>The job description with key concepts highlighted</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12908a0e-5733-479c-95d7-e5cab50dfa48_1422x1002.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12908a0e-5733-479c-95d7-e5cab50dfa48_1422x1002.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12908a0e-5733-479c-95d7-e5cab50dfa48_1422x1002.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12908a0e-5733-479c-95d7-e5cab50dfa48_1422x1002.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12908a0e-5733-479c-95d7-e5cab50dfa48_1422x1002.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12908a0e-5733-479c-95d7-e5cab50dfa48_1422x1002.png" width="1422" height="1002" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/12908a0e-5733-479c-95d7-e5cab50dfa48_1422x1002.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1002,&quot;width&quot;:1422,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:567437,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12908a0e-5733-479c-95d7-e5cab50dfa48_1422x1002.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12908a0e-5733-479c-95d7-e5cab50dfa48_1422x1002.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12908a0e-5733-479c-95d7-e5cab50dfa48_1422x1002.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12908a0e-5733-479c-95d7-e5cab50dfa48_1422x1002.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Job description keywords mapped to your experience</figcaption></figure></div><p><span>In the interview, use their language when you describe your experiences: </span><em><span>“When I was </span><strong>on-call </strong><span>for a</span><strong> multi-datacenter system</strong><span>, I diagnosed and </span><strong>resolved a major technical issue</strong><span> and ensured services were restored. Later, I wrote </span><strong>automation</strong><span> to programmatically detect this type of issue in the future.”</span></em></p><p>The more familiar the interviewer is with the job description and the role requirements, the more effective this technique will be (at subconsciously reinforcing your fit for the role).</p><p>The vast majority of interview questions will ask you to dive into your past experiences and describe how you handled a specific situation. When you’ve been working for five or more years, it can be really tough to index your memory and pull out the perfect example on a dime.</p><p><em>(By the way: It’s not you. It’s everyone. We all struggle with this. It’s a neurobiological limitation with the way our brains store memories.)</em></p><p>Writing down the answers to hundreds of behavioral questions is a common way I see candidates try to remember all the things they’ve accomplished. This is exhausting and can actually overload your brain and cause you to freeze up or even “blackout” in an interview.</p><p><span>To avoid burnout and get better results, I instead coach candidates to pick three to five recent major projects in their careers, and then remember </span><em>every single detail they can recall </em><span>about those projects, for example:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa89baa80-568b-4c2f-830e-89fb76cf488a_1528x1172.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa89baa80-568b-4c2f-830e-89fb76cf488a_1528x1172.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa89baa80-568b-4c2f-830e-89fb76cf488a_1528x1172.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa89baa80-568b-4c2f-830e-89fb76cf488a_1528x1172.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa89baa80-568b-4c2f-830e-89fb76cf488a_1528x1172.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa89baa80-568b-4c2f-830e-89fb76cf488a_1528x1172.png" width="1456" height="1117" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a89baa80-568b-4c2f-830e-89fb76cf488a_1528x1172.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1117,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa89baa80-568b-4c2f-830e-89fb76cf488a_1528x1172.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa89baa80-568b-4c2f-830e-89fb76cf488a_1528x1172.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa89baa80-568b-4c2f-830e-89fb76cf488a_1528x1172.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa89baa80-568b-4c2f-830e-89fb76cf488a_1528x1172.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Example prompts to walk down memory lane and reposition memories for better interview storytelling. See the references section at the end for a detailed walkthrough and example.</figcaption></figure></div><p>Writing all of this down will help you reference the details before future interviews (especially if you have an extended job search, as is common in difficult talent markets like the one we’re experiencing this year).</p><p>When you are asked about past work experiences, your brain will more easily pull from one of these projects. And you’ll be able to provide high-resolution details on the context, what happened, and the results (quantified!).</p><p><strong>What counts as major?</strong></p><p>Large and complex, ideally.</p><ul><li><p>Large in scope (important to the business, strategic, involves lots of stakeholders, significant revenue or user impact)</p></li><li><p>Complex (in terms of the stakeholders, core team, tech, timeline, resources, etc.)</p></li></ul><p><strong>Why large and complex?</strong><span>&nbsp;</span></p><p>Demonstrating your maximum capacity will enable you to validate your ability to handle larger scope and responsibilities, which typically correspond to higher titles and compensation (if that matters to you).</p><p><strong>What counts as recent?</strong></p><p>Ideally the past two to four years. The two-to-four-year guideline is largely pragmatic. Memories aren’t stable, and they do experience neural “bit rot”—which means even if you resurrect those memories, it’ll be hard to recall the details.</p><p><span>A second reason to aim for recent projects: Assuming your career has been growing, recent projects will likely also be larger and more significant (see:</span><em> Why large and complex?).</em></p><p>Most people know that interviews are chock-full of behavioral questions, and most candidates either know (or quickly research) the STAR method during their interview prep.</p><p>A refresher on the STAR method if you’re unfamiliar or haven’t interviewed recently:</p><ul><li><p><strong>S:</strong><span> Situation—what was happening at the time (context)</span></p></li><li><p><strong>T:</strong><span> Tasks—what you were responsible for</span></p></li><li><p><strong>A: </strong><span>Action—what you did to solve the problem and deliver outcomes</span></p></li><li><p><strong>R:</strong><span> Result—the impact of your actions</span></p></li></ul><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3807284-9c75-4e8e-a246-fc8477c43660_1418x572.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3807284-9c75-4e8e-a246-fc8477c43660_1418x572.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3807284-9c75-4e8e-a246-fc8477c43660_1418x572.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3807284-9c75-4e8e-a246-fc8477c43660_1418x572.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3807284-9c75-4e8e-a246-fc8477c43660_1418x572.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3807284-9c75-4e8e-a246-fc8477c43660_1418x572.png" width="1418" height="572" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b3807284-9c75-4e8e-a246-fc8477c43660_1418x572.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:572,&quot;width&quot;:1418,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3807284-9c75-4e8e-a246-fc8477c43660_1418x572.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3807284-9c75-4e8e-a246-fc8477c43660_1418x572.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3807284-9c75-4e8e-a246-fc8477c43660_1418x572.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3807284-9c75-4e8e-a246-fc8477c43660_1418x572.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>A recent </span><a href="https://twitter.com/ErikaCoaches/status/1625272928118927360" rel="">tweet</a><span> where I walked through the STAR method in detail and my unique improvements that demonstrate your growth mindset.</span></figcaption></figure></div><p>Simple, right? Yet there’s more to it…</p><p>Behavioral interview questions were invented 50 years ago, in the 1970s. Studies quickly found that these questions were 55% more effective at predicting on-the-job performance than the prevailing interview questions at the time. They took the business world by storm and became the de facto interview technique. Today, they are used extensively in tech interviews (by my estimate, more than 60% of interview questions are behavioral). Amazon actually sends candidates a STAR primer before their interviews!</p><p><span>But it’s been half a century, and behavioral question formats </span><em>have</em><strong> </strong><span>evolved. Your approach to answering them needs to evolve too.</span></p><p>In tech, I see 3 main formats for behavioral questions:</p><ol><li><p><strong>Pure </strong><span>— “Tell me about a time when…”&nbsp;</span></p></li><li><p><strong>Situational </strong><span>— “Put yourself in this situation; what would you do?”</span></p></li><li><p><strong>Theoretical </strong><span>— “What’s your general approach to doing X?”</span></p></li></ol><p><span>All of them ask what you </span><strong>have done</strong><span> or what you </span><strong>would do </strong><span>(in a situation) or what you </span><strong>generally do</strong><span>, to extrapolate and predict on-the-job performance. To interview effectively in tech today, you need to know how to answer each of these questions.&nbsp;</span></p><p>Below is a primer you can use to answer each type of behavioral interview question.</p><p><strong>Why they ask: </strong><span>Understanding how you’ve behaved in the past can be used to extrapolate how you might perform in this role</span></p><p><strong>What they ask: </strong><span>Share a specific career experience from the past</span></p><p><strong>How to respond:</strong><span> Start with</span><strong> </strong><span>STAR, then add two improvements. First, what you learned. Then, how you evolved your approach and incorporated these learnings in a future situation. </span><strong>(I call this STAR++)</strong></p><p>Tell me about a time you had to work quickly to deliver a result.</p><p><strong>S:</strong><span> Start with context (strategic, business, project)</span></p><p><em><strong>Answer: Situation</strong></em></p><blockquote><p><em>“I was at a pre-IPO company in an eng leadership role. To prep for the IPO, we needed to update compensation bands and ensure all 250 engineers were being paid fairly.</em></p><p><em>This was complex, because comp is a charged issue and I only had six weeks to deliver.”</em></p></blockquote><p><strong>T: </strong><span>Explain your role in the situation</span></p><p><em><strong>Answer: Tasks</strong></em></p><blockquote><p><em>“The project was driven by HR. They were doing the analysis and proposing the new comp bands.</em></p><p><em>My job was to test the new comp bands against the current comp for every engineer in the company and ensure that the new comp bands were both equitable and attractive for current and future talent.”</em></p></blockquote><p><strong>A:</strong><span> Share the actions you took to ensure success</span></p><p><em><strong>Answer: Actions</strong></em></p><blockquote><p><em>“As HR pushed new draft engineering comp bands:</em></p><ul><li><p><em>I analyzed them against the career ladder to detect issues</em></p></li><li><p><em>I verified that no employee would have a compensation regression</em></p></li><li><p><em>I identified and corrected errors</em></p></li><li><p><em>I messaged the comp changes to the 250-person eng team”</em></p></li></ul></blockquote><p><strong>R: </strong><span>Quantify the results (from a short- and longer-term strategic perspective)</span></p><p><em><strong>Answer: Results</strong></em></p><blockquote><p><em>“I rolled out the engineering comp bands on time.</em></p><ul><li><p><em>Engineers were happy with the changes (no comp regressions, most got pay increases)</em></p></li><li><p><em>Finance could accurately forecast headcount spending with the new comp</em></p></li><li><p><em>Comp was ready for IPO 🎉”</em></p></li></ul></blockquote><p><span>Then add the growth mindset </span><strong>(the ++ in STAR++)</strong></p><p><strong>+ (learnings): </strong><span>Expose what you learned</span></p><p><em><strong>Answer: + (learnings)</strong></em></p><blockquote><p><em>“There was an uncaught error in the Sr. Mgr comp bands that resulted in above-market comp for some employees.</em></p><p><em>The project goal just set a minimum, no maximum, so I didn’t look for outliers. I learned to ask for success criteria in a range, not just the target!”</em></p></blockquote><p><strong>+ (future improvements): </strong><span>Share how you’ve adapted your approach for future projects (given the learnings)</span></p><p><em><strong>Answer: + (future improvements)</strong></em></p><blockquote><p><em>“I recently ran a project to reduce our platform web page load times. Initially the executive sponsor set the success criteria as loading in less than 1 second. I inquired about the success criteria as a range and was able to set a clearer target: 0.3 to 1 second.</em></p><p><em>Setting the success criteria as a range saved us from major misalignment that would have doubled the development efforts and led to exorbitant ongoing server costs.”</em></p></blockquote><p><strong>Try this at home!</strong><span> (with these handy practice questions):</span></p><ul><li><p>“Tell me about a time when you failed.”</p></li><li><p>“Walk me through an experience where you had to give difficult feedback.”</p></li><li><p>“Share an example of an excellent team culture that you were part of.”</p></li></ul><p><strong>💡 Tip: </strong><span>If you’re in a time pinch, focus your prep time on pure behavioral questions (70% of all behavioral questions).</span></p><p><strong>Why they ask: </strong><span>Learning how you generally go about doing tasks or activities that are central to the role</span></p><p><strong>What they ask: </strong><span>Your general approach to a core element of the role and your craft</span></p><p><strong>How to respond:</strong></p><ol><li><p>Outline your general approach (3-5 elements)</p></li><li><p>Describe your approach for each in detail&nbsp;</p></li><li><p>End with an example (use STAR) that exemplifies your use of this framework</p></li></ol><p><em>How do you give feedback (as a manager)?</em></p><p><em><strong>Answer, part 1: Outline your general approach (3-5 elements)</strong></em></p><p><em>Three major considerations:</em></p><blockquote><ol><li><p><em><strong>Behavior</strong><span> — what specific behavior am I trying to change?</span></em></p></li><li><p><em><strong>Messaging</strong><span> — how can I give the feedback in the way it will be most effectively heard, understood, and actioned?</span></em></p></li><li><p><em><strong>Alignmen</strong><span>t — how can I ensure that me and the team member are in agreement with the need to change, how we’re going to measure success, and how we’ll check in to monitor the change?</span></em></p></li></ol></blockquote><p><em><strong>Answer, part 2: Describe your approach for each in detail&nbsp;(with tactics)</strong></em></p><blockquote><p><em>For each of these major considerations, here’s how I would specifically go about doing this:</em></p><ol><li><p><em>Behavior</em></p><ol><li><p><em>What is the specific behavior that needs to change?</em></p></li><li><p><em>What are the impacts of that behavior (on the individual, team, project, product, business, or company strategy)?</em></p></li><li><p><em>If this specific behavior changes, what will improve (for the individual, team, project, product, business)?</em></p></li></ol></li><li><p><em>Messaging</em></p><ol><li><p><em>Direct</em></p><ol><li><p><em>What do I need them to hear?</em></p></li><li><p><em>What words must be said?</em></p></li><li><p><em>How will I know if they understand the message?</em></p></li></ol></li><li><p><em>Empathetic</em></p><ol><li><p><em>How can I respect the vulnerability of the situation?</em></p></li><li><p><em>What do I need them to not hear? (avoid creating defensive behavior)</em></p></li><li><p><em>What words should I avoid?</em></p></li></ol></li></ol></li><li><p><em>Alignment</em></p><ol><li><p><em>What questions can I ask to ensure they understood?</em></p></li><li><p><em>What questions can I ask to ensure we’re aligned on the problem and what needs to change?</em></p></li><li><p><em>What questions can I ask to collaborate on a definition of what success looks like so we know if the feedback is being actioned?</em></p></li><li><p><em>Create a check-in plan (activities, frequency)"</em></p></li></ol></li></ol></blockquote><p><em><strong>Answer, part 3: End with an example (use STAR) that exemplifies your use of this framework</strong></em></p><p>Situational Context and Tasks:</p><blockquote><p><em>“At Google, I managed a team of technical program managers (TPMs) who owned critical, strategic programs for the organization. One of the TPMs on the team was chatty and often made other team members late to meetings or distracted with their work. Their intent was to build relationships at work, but the reality was that other team members got distracted, anxious, and even stressed by my team member’s chattiness.”</em></p></blockquote><p>Actions:</p><blockquote><p><em>“I came up with a plan, first by clearly identifying the behavior that needed to change. Because the problem was caused by a personality trait, it was important to isolate the specific problem being caused and the specific action that needed to change. In this case, it was having personal chats with colleagues during core work hours.</em></p><p><em>Next, I needed to plan the messaging, to avoid making the person feel attacked or defensive. I decided to express the problem in terms of how it impacted both their project success and their teammate’s stress levels. Then, I planned some alignment questions to ensure we were in agreement on the problem, the change that needed to happen, and how we were going to hold ourselves accountable to measure success and check in.</em></p><p><em>Then, I had the conversation with the team member.”</em></p></blockquote><p>Results:</p><blockquote><p><em>“The team member immediately acknowledged the issue, since they knew themselves to be chatty, and thanked me for bringing the impacts (to others) to their attention. We aligned quickly on a plan to check in monthly, and the team member agreed to let me periodically probe the team to ensure that the change was taking place.</em></p><p><em>Within two months, the issue was resolved. Team members felt less stressed, more focused, and more confident in the team dynamics. My team member continued to connect with colleagues at lunch and after work hours, to build meaningful relationships (which was their personality). Today, that team member is a successful TPM leader at Google and thanked me for helping them see this blindspot.”</em></p></blockquote><p><strong>Try this at home!</strong><span> (with these handy practice questions):</span></p><ul><li><p>“What’s your general approach to building respectful, delightful products?”</p></li><li><p>“How do you go about building team culture?”</p></li><li><p>“How do you give feedback?”</p></li></ul><p><strong>Why they ask: </strong><span>To see how you gather and synthesize information to create a reasonable path forward using strong judgment</span></p><p><strong>What they ask: </strong><span>In a hypothetical (but realistic) work situation, tell me what you’d do</span></p><p><strong>How to respond:</strong></p><ol><li><p>Ask clarifying questions to fully understand the situation (enough that you can create an action plan)&nbsp;</p></li><li><p>State any assumptions you’re making&nbsp;</p></li><li><p>Outline a plan, then expand with specific details on your approach&nbsp;</p></li><li><p>Check in with the interviewer to see if you missed anything or if they want to dive deeper into a given area&nbsp;</p></li><li><p>Summarize</p></li></ol><p><em>You found out the project you are leading is being canceled. What do you do?</em></p><p><em><strong>Answer, part 1: Ask clarifying questions</strong></em></p><blockquote><p><em>Some clarifying questions</em><span> </span><strong>(and answers from interviewer)</strong><em>:</em></p><ul><li><p><span>what stage of completion is the project (beginning / middle / end)? </span><strong>(end)</strong></p></li><li><p><em>how long has the team been working on this?</em><span> </span><strong>(a while)</strong></p></li><li><p><em>how important is this project to the team (strategic priority)?</em><span> </span><strong>(it’s the only work that the team has on its plate)</strong></p></li><li><p><em>how many people are working on this?</em><span> </span><strong>(30)</strong></p></li><li><p><span>any users / clients / customers affected? </span><strong>(no)</strong></p></li><li><p><em>other internal teams affected?</em><span> </span><strong>(yes)</strong></p></li></ul></blockquote><p><em><strong>Answer, part 2: State your assumptions</strong></em></p><blockquote><p><em>I’m going to assume:</em></p><ul><li><p><em>there’s an open dialogue with the leadership team</em></p></li><li><p><em>there are data available to confirm the validity of this decision</em></p></li><li><p><em>the team doesn’t know yet</em></p></li><li><p><em>the team is not going to be fired, laid off, or otherwise disbanded (thus will be available to work on other high priority efforts)</em></p></li></ul></blockquote><p><em><strong>Answer, part 3: Outline a plan, then expand (3-5 items)</strong></em></p><blockquote><p><em>Three major considerations:</em></p><ol><li><p><em>Trust but Validate the Decision (before communicating further)</em></p><ol><li><p><em>Meet with exec leaders</em></p></li><li><p><em>Ask about assumptions</em></p></li><li><p><em>(if I don’t agree with the conclusion, gather data, and present it back with alternative solutions)</em></p></li><li><p><em>(if agreed on the conclusion, move forward)</em></p></li></ol></li><li><p><em>Team (communication, landing the change, setting the team up for future success)</em></p><ol><li><p><em>make a wind-down plan</em></p></li><li><p><em>communication plan — crisp, clear, direct, state assumptions, preemptively address likely FAQs</em></p></li><li><p><em>announce to everyone at once, in person</em></p></li><li><p><em>make information available in written, transparent, discoverable format</em></p></li><li><p><em>address individual concerns, leverage managers (align with them)</em></p></li><li><p><em>develop a future plan for the team (replace the strategy void)</em></p></li></ol></li><li><p><em>Internal customers (communication, partnering to problem solve &amp; land the change)</em></p><ol><li><p><em>communication plan — crisp, clear, direct, state assumptions, preemptively address likely FAQs</em></p></li><li><p><em>announce in person with each internal customer</em></p></li><li><p><em>make information available in written, transparent, discoverable format, add FAQs as they come in</em></p></li><li><p><em>partner to problem-solve and ensure they land on their feet.</em></p></li></ol></li></ol></blockquote><p><em><strong>Answer, part 4: Check back with the interviewer</strong></em></p><blockquote><p><em>“Did I miss any key steps from your perspective, or is there any area you’d like to dive into together?”</em></p></blockquote><p><em><strong>Answer, part 5: Summarize the question prompt and key items</strong></em></p><blockquote><p><em>“You asked me what I would do if I found out that a project that I was leading was canceled. I walked you through my process of validating the decision, then creating a plan, communicating to both the team working on the project and the internal customers of the project, then my goal to land the wind-down effort in a timely and effective manner, and ensure the future direction and productivity of the team.”</em></p></blockquote><p><strong>Try this at home!</strong><span> (with these handy practice questions):</span></p><ul><li><p>“You just started on a new team. Tell me your approach to ramping up.”</p></li><li><p>“You just found out the project you are leading is being canceled. What do you do?”</p></li><li><p>“You get a report that your product is crashing. What do you do?”</p></li></ul><p><em><strong>💡 </strong></em><strong>Want more examples?</strong><span> Check out the reference posts at the end for detailed walk-throughs for each of these behavioral question types.</span></p><p>If you’re a running fan, you know that the Boston Marathon is often won or lost at one single point in the race—Heartbreak Hill—including in this year’s marathon.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F411e91cc-8d95-41ec-965c-7205be82bb44_1600x1200.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F411e91cc-8d95-41ec-965c-7205be82bb44_1600x1200.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F411e91cc-8d95-41ec-965c-7205be82bb44_1600x1200.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F411e91cc-8d95-41ec-965c-7205be82bb44_1600x1200.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F411e91cc-8d95-41ec-965c-7205be82bb44_1600x1200.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F411e91cc-8d95-41ec-965c-7205be82bb44_1600x1200.png" width="1456" height="1092" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/411e91cc-8d95-41ec-965c-7205be82bb44_1600x1200.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1092,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F411e91cc-8d95-41ec-965c-7205be82bb44_1600x1200.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F411e91cc-8d95-41ec-965c-7205be82bb44_1600x1200.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F411e91cc-8d95-41ec-965c-7205be82bb44_1600x1200.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F411e91cc-8d95-41ec-965c-7205be82bb44_1600x1200.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>The Boston Marathon’s Heartbreak Hill is so tough that neighbors at the top of the hill marked it with this wooden sculpture.</figcaption></figure></div><p><span>Interviews are often won or lost by the questions </span><em>you</em><span> ask the interviewer at the end. Half of the battle is preparing well and showing up to answer </span><em>the interviewer’s</em><strong> </strong><span>questions; the other half is asking </span><em>them</em><strong> </strong><span>questions that get them thinking (and make you stand out).</span></p><p>We all want to work with exceptional colleagues who work hard, get things done, and push us to greater heights. Interviewers are exactly the same. You need to get them thinking (in a good way).</p><p>Formulate questions that are interesting and thoughtful, and you’ll end the interview on a high note and possibly put yourself in the lead.</p><p>3 steps to formulating great questions for interviewers:</p><ol><li><p><strong>Define the signals you need (to determine if you want the role). </strong><span>Bring questions whose answers are actually important to you. Anyone can grab a question from a listicle. Only you can ask questions that will answer your open questions about the role.</span></p></li><li><p><strong>Do your research. </strong><span>On the industry, company, competitive landscape, team/product, and even the interviewers. Look for trends, competitive landscape changes, and news. You can find these on consulting firm dossiers, VC thought-leadership white papers, the company’s website, Yahoo Finance, and competitive landscape engines like G2 and Capterra.</span></p></li><li><p><strong>Formulate questions</strong><span> that highlight that you’ve done your homework and that give you the signal you want.</span></p></li></ol><p>You can do this in an hour or two, and it’s well worth the investment. You can even reuse some of these “first-round” questions in later interviews to get diverse perspectives from the full panel.</p><p>An example of a high-signal question that one of my coaching clients formulated for an interview at Cruise, a self-driving car company: </p><blockquote><p><em>In your three years at Cruise, the privacy world has expanded, with the CCPA and other states discussing more regulations for consumer privacy—how has this impacted the nature of your work, and what do you see as the biggest challenge or area of focus as Cruise continues to expand to new geos?</em></p></blockquote><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f60af5f-e193-4008-a225-c39cd2439e3c_1001x599.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f60af5f-e193-4008-a225-c39cd2439e3c_1001x599.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f60af5f-e193-4008-a225-c39cd2439e3c_1001x599.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f60af5f-e193-4008-a225-c39cd2439e3c_1001x599.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f60af5f-e193-4008-a225-c39cd2439e3c_1001x599.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f60af5f-e193-4008-a225-c39cd2439e3c_1001x599.png" width="1001" height="599" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7f60af5f-e193-4008-a225-c39cd2439e3c_1001x599.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:599,&quot;width&quot;:1001,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f60af5f-e193-4008-a225-c39cd2439e3c_1001x599.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f60af5f-e193-4008-a225-c39cd2439e3c_1001x599.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f60af5f-e193-4008-a225-c39cd2439e3c_1001x599.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f60af5f-e193-4008-a225-c39cd2439e3c_1001x599.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Tony the Tiger is an unofficial and unpaid supporter of MVIP and formulating GR-R-REAT questions for interviewers.</figcaption></figure></div><p><strong>🎉 Voilà!</strong><span> You’re ready for your next interview.</span></p><p>Here’s a recap checklist you can use for your next first-round interview prep:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c83e45-ddbf-45e9-a336-b429af8edfa0_2000x1882.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c83e45-ddbf-45e9-a336-b429af8edfa0_2000x1882.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c83e45-ddbf-45e9-a336-b429af8edfa0_2000x1882.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c83e45-ddbf-45e9-a336-b429af8edfa0_2000x1882.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c83e45-ddbf-45e9-a336-b429af8edfa0_2000x1882.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c83e45-ddbf-45e9-a336-b429af8edfa0_2000x1882.png" width="1456" height="1370" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f0c83e45-ddbf-45e9-a336-b429af8edfa0_2000x1882.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1370,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:259578,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c83e45-ddbf-45e9-a336-b429af8edfa0_2000x1882.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c83e45-ddbf-45e9-a336-b429af8edfa0_2000x1882.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c83e45-ddbf-45e9-a336-b429af8edfa0_2000x1882.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0c83e45-ddbf-45e9-a336-b429af8edfa0_2000x1882.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><strong>Some timing guidelines:</strong></p><ul><li><p><span>Cleaning up your resume, LinkedIn, and online presence: </span><strong>1-2 hours</strong><span>*</span></p></li><li><p><span>Crafting a strategic, compelling career story: </span><strong>1-1.5 hours</strong></p></li><li><p><span>Mining the job description: </span><strong>30 minutes</strong></p></li><li><p><span>Walking down memory lane: </span><strong>1-2 hours</strong><span> the first time; </span><strong>30 minutes</strong><span> to refresh for any additional interviews</span></p></li><li><p><span>Mastering behavioral questions: </span><strong>4-6 hours</strong><span>*</span></p></li><li><p><span>Formulating high-signal questions for interviewers: </span><strong>1-2 hours</strong></p></li></ul><p><em>* A one-time task for your entire job search, not for every single interview</em></p><p>If you use MVIP, you can prepare for a first-round interview in three or four days (with about four hours per day of prep). If you’re working full-time, you can do it in a week with two to three hours a day. Much of what you learn with this MVIP interview prep system is reusable across interviews, so you will quickly see the effect of your preparation in later interviews.</p><p><span>Now you know how to prepare for and pass any first-round interview, even in a tough talent market. I’d love to hear your success stories using MVIP. Feel free to reach out at </span><a href="mailto:hello@coacherika.co" rel="">hello@coacherika.co</a><span>.</span></p><p>That’s a wrap!</p><p><span>Everything we discussed today is available in greater detail in my Substack, </span><a href="https://thecareerwhispers.substack.com/" rel="">The Career Whispers</a><span>. Useful deep-dive posts are linked below:</span></p><ol><li><p><em>Craft a Strategic and Compelling Career Story </em><span>using The Career Whispers issue #001 </span><a href="https://thecareerwhispers.substack.com/p/001" rel="">here</a><span>.</span></p></li><li><p><em>Walk Down Memory Lane </em><span>with The Career Whispers issue #002 </span><a href="https://thecareerwhispers.substack.com/p/002" rel="">here</a><span>.</span></p></li><li><p><em>Master Behavioral Interview Questions </em><span>in The Career Whispers issue #003 </span><a href="https://thecareerwhispers.substack.com/p/003" rel="">here</a><span>.</span></p></li><li><p><em>Formulate G-R-R-REAT High-Signal Questions for Interviewers </em><span>in The Career Whispers issue #004 </span><a href="https://thecareerwhispers.substack.com/p/004" rel="">here</a><span>.</span></p></li></ol><p><em>Thanks, Erika!</em></p><p><em>Have a fulfilling and productive week 🙏</em></p><p><strong><span>If you’re finding this newsletter valuable, share it with a friend, and consider subscribing if you haven’t already. Check out </span><a href="https://www.lennysnewsletter.com/subscribe?group=true" rel="">group discounts</a><span> and </span><a href="https://www.lennysnewsletter.com/subscribe?gift=true" rel="">gift options</a><span>.</span></strong></p><p>Sincerely,</p><p>Lenny 👋</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dutch rules will soon prevent schoolchildren from having a phone in classroom (311 pts)]]></title>
            <link>https://nltimes.nl/2023/07/04/dutch-rules-will-soon-prevent-schoolchildren-phone-classroom</link>
            <guid>36586127</guid>
            <pubDate>Tue, 04 Jul 2023 13:04:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nltimes.nl/2023/07/04/dutch-rules-will-soon-prevent-schoolchildren-phone-classroom">https://nltimes.nl/2023/07/04/dutch-rules-will-soon-prevent-schoolchildren-phone-classroom</a>, See on <a href="https://news.ycombinator.com/item?id=36586127">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <article data-history-node-id="66937" role="article">

      
  
  

  <div>
          
    
          <p>
                Tuesday, 4 July 2023 - 14:26
      </p>
    
        


  </div>

  
  
      
    
      
  
   
      
      <div><p>Children will soon be prevented from bringing mobile phones into Dutch classrooms. Sources close to the Cabinet confirmed that schools will have until October 1 figure out how they can arrange the restriction on their own. If that fails, national rules may be introduced to restrict the use of telephones in schools.</p>

<p>Unnamed sources also confirmed the story to ANP, after it was first reported by AD and RTL Nieuws.</p>

<p>Smartphones may still be used if they are needed for class, or if there is a medical need. One example of the latter is if a student with diabetes needs to measure sugar levels.</p>

<p>Schools and teachers have been asking for rules to restrict the use of mobile phones in the classroom for some time. The debate about this issue gained momentum at the end of last year when CDA Member of Parliament René Peters advocated on behalf of a ban. The largest opposition party in the Tweede Kamer, PVV, has been outspoken in favor of a ban for an extended period, and has joined forces with the CDA, a coalition party.</p>

<p>Initially, the plea from the CDA and PVV was warmly received in the Tweede Kamer, the lower house of Parliament, with a degree of support from two other coalition parties. These include Prime Minister Mark Rutte's VVD, and the smallest party in the coalition, ChristenUnie. However, former Education Minister Dennis Wiersma and the two parties thought it was better for the schools themselves to set limits in this regard.</p>

<p>Gradually, the number of supporters seemed to increase. A large group of teachers appeared to support the proposal, teachers union AOb announced after commissioning a poll.</p>

<p>Due to persistent signals from teachers that they are unable to keep smartphones out of the classroom on their own, Wiersma left the door open at the beginning of this year to examine the policy. He promised discuss the issue with schools and said he would be open to a ban if there was a great need for it.</p></div>
  
      <p><em>Reporting by ANP</em></p>
          
  

</article>










  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stable Diffusion XL technical report [pdf] (172 pts)]]></title>
            <link>https://github.com/Stability-AI/generative-models/blob/main/assets/sdxl_report.pdf</link>
            <guid>36586079</guid>
            <pubDate>Tue, 04 Jul 2023 13:00:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Stability-AI/generative-models/blob/main/assets/sdxl_report.pdf">https://github.com/Stability-AI/generative-models/blob/main/assets/sdxl_report.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=36586079">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="repo-content-turbo-frame" target="_top" data-turbo-action="advance">
  

  



    
<p><a data-hotkey="y" href="https://github.com/Stability-AI/generative-models/blob/ae18ba3e874c1a71152e0f0cc01b78ff61fbb59c/assets/sdxl_report.pdf">Permalink</a></p><div>
  
<div>
  <details id="branch-select-menu" data-hydro-click-payload="{&quot;event_type&quot;:&quot;repository.click&quot;,&quot;payload&quot;:{&quot;target&quot;:&quot;REFS_SELECTOR_MENU&quot;,&quot;repository_id&quot;:656933936,&quot;originating_url&quot;:&quot;https://github.com/Stability-AI/generative-models/blob/main/assets/sdxl_report.pdf&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="6c93ae5a2f316862d81e54b0ec8f59d409de6051758711bfa34315078488ea70">
    <summary data-hotkey="w" title="Switch branches or tags">
      
      <span data-menu-button="">main</span>
      <span></span>
    </summary>

    
<div>
    <header>
      <span>Switch branches/tags</span>
      
    </header>

    <input-demux data-action="tab-container-change:input-demux#storeInput tab-container-changed:input-demux#updateInput">
      <tab-container>
        

        

        <div role="tabpanel" id="ref-list-branches" data-filter-placeholder="Filter branches/tags" tabindex="">
          <ref-selector type="branch" data-targets="input-demux.sinks" data-action="
              input-entered:ref-selector#inputEntered
              tab-selected:ref-selector#tabSelected
              focus-list:ref-selector#focusFirstListMember
            " query-endpoint="/Stability-AI/generative-models/refs" cache-key="v0:1687736273.0" current-committish="bWFpbg==" default-branch="bWFpbg==" name-with-owner="U3RhYmlsaXR5LUFJL2dlbmVyYXRpdmUtbW9kZWxz" prefetch-on-mouseover="">

            <template data-target="ref-selector.fetchFailedTemplate">
              <div class="SelectMenu-message" data-index="{{ index }}">Could not load branches</div>
            </template>

              <template data-target="ref-selector.noMatchTemplate">
    <div class="SelectMenu-message">Nothing to show</div>
</template>


            

              

<template data-target="ref-selector.itemTemplate">
  <a href="https://github.com/Stability-AI/generative-models/blob/{{ urlEncodedRefName }}/assets/sdxl_report.pdf" class="SelectMenu-item" role="menuitemradio" rel="nofollow" aria-checked="{{ isCurrent }}" data-index="{{ index }}">
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check SelectMenu-icon SelectMenu-icon--check">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    <span class="flex-1 css-truncate css-truncate-overflow {{ isFilteringClass }}">{{ refName }}</span>
    <span hidden="{{ isNotDefault }}" class="Label Label--secondary flex-self-start">default</span>
  </a>
</template>


              
          </ref-selector>

        </div>

        
      </tab-container>
    </input-demux>
  </div>

  </details>

</div>


<div data-modal-dialog-overlay="">
  <modal-dialog role="dialog" id="warn-tag-match-create-branch-dialog" aria-modal="true" aria-labelledby="warn-tag-match-create-branch-dialog-header" data-view-component="true">
      <header>
        <div>
          <p>
            <h2 id="warn-tag-match-create-branch-dialog-header">Name already in use</h2>
          </p>
          
        </div>
      </header>
    <div>
      
          <p>      A tag already exists with the provided branch name. Many Git commands accept both tag and branch names, so creating this branch may cause unexpected behavior. Are you sure you want to create this branch?
</p>

    </div>
      
</modal-dialog></div>


  
    <p><a href="https://github.com/Stability-AI/generative-models/find/main" data-pjax="" data-hotkey="t" data-view-component="true">    Go to file
</a></p><details id="blob-more-options-details" data-view-component="true">
      <summary role="button" data-view-component="true">    <svg aria-label="More options" role="img" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M8 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3ZM1.5 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Zm13 0a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z"></path>
</svg>
</summary>
    <div data-view-component="true">      <ul>
        <li>
          <a data-hydro-click="{&quot;event_type&quot;:&quot;repository.click&quot;,&quot;payload&quot;:{&quot;target&quot;:&quot;FIND_FILE_BUTTON&quot;,&quot;repository_id&quot;:656933936,&quot;originating_url&quot;:&quot;https://github.com/Stability-AI/generative-models/blob/main/assets/sdxl_report.pdf&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="498fedcda38c565a3b542008d7f29d5ff25e23848098476453ccc698321811a3" data-ga-click="Repository, find file, location:repo overview" data-hotkey="t" href="https://github.com/Stability-AI/generative-models/find/main">
            <span>Go to file</span>
            
</a>        </li>
        <li data-toggle-for="blob-more-options-details">
                    </li>
        <li role="none"></li>
        <li>
          <clipboard-copy data-toggle-for="blob-more-options-details" aria-label="Copy path" value="assets/sdxl_report.pdf" data-view-component="true">
    
            Copy path

</clipboard-copy>        </li>
        <li>
          <clipboard-copy data-toggle-for="blob-more-options-details" aria-label="Copy permalink" value="https://github.com/Stability-AI/generative-models/blob/ae18ba3e874c1a71152e0f0cc01b78ff61fbb59c/assets/sdxl_report.pdf" data-view-component="true">
    
            <span>
              <span>Copy permalink</span>
            </span>

</clipboard-copy>        </li>
      </ul>
</div>
</details></div>





    

    <include-fragment src="/Stability-AI/generative-models/spoofed_commit_check/ae18ba3e874c1a71152e0f0cc01b78ff61fbb59c" data-test-selector="spoofed-commit-check"></include-fragment>

    <div>
  
  <div>
        <p><span>
          <a rel="contributor" href="https://github.com/rromb"><img skip_hovercard="13" src="https://avatars.githubusercontent.com/u/38811725?s=48&amp;v=4" width="24" height="24" alt="@rromb"></a>
        </span></p><div>
            <p><a rel="contributor" href="https://github.com/rromb">rromb</a>

              <span>
                <a data-pjax="true" title="add sdxl report" href="https://github.com/Stability-AI/generative-models/commit/ae18ba3e874c1a71152e0f0cc01b78ff61fbb59c">add sdxl report</a>
              </span>
          </p></div>
        <div>
          <p><span>
            <span>Latest commit</span>
            <a href="https://github.com/Stability-AI/generative-models/commit/ae18ba3e874c1a71152e0f0cc01b78ff61fbb59c" data-pjax="">ae18ba3</a>
            <span itemprop="dateModified"><relative-time datetime="2023-07-04T11:21:13Z">Jul 4, 2023</relative-time></span>
          </span></p><a data-pjax="" href="https://github.com/Stability-AI/generative-models/commits/main/assets/sdxl_report.pdf">
            
            <span>
              <strong>History</strong>
            </span>
          </a>
        </div>
      </div>

  <div>
    <details id="blob_contributors_box">
      <summary>
        
        <strong>1</strong>
        
        contributor
      </summary>
      <details-dialog aria-label="Users who have contributed to this file" src="/Stability-AI/generative-models/contributors-list/main/assets/sdxl_report.pdf" preload="">
        <div>
          <h3>
            Users who have contributed to this file
          </h3>
        </div>
        <include-fragment>
          <svg style="box-sizing: content-box; color: var(--color-icon-primary);" width="32" height="32" viewBox="0 0 16 16" fill="none" data-view-component="true">
  <circle cx="8" cy="8" r="7" stroke="currentColor" stroke-opacity="0.25" stroke-width="2" vector-effect="non-scaling-stroke"></circle>
  <path d="M15 8a7.002 7.002 0 00-7-7" stroke="currentColor" stroke-width="2" stroke-linecap="round" vector-effect="non-scaling-stroke"></path>
</svg>
        </include-fragment>
      </details-dialog>
    </details>
  </div>
</div>








  
    <div data-target="readme-toc.content">
      
  <div>


  <p>

    17.3 MB
  </p>

  <div>
        <p><a data-permalink-href="/Stability-AI/generative-models/raw/ae18ba3e874c1a71152e0f0cc01b78ff61fbb59c/assets/sdxl_report.pdf" href="https://github.com/Stability-AI/generative-models/raw/main/assets/sdxl_report.pdf" id="raw-url" group_item="true" data-view-component="true">    <span>
      <span>Download</span>
    </span>
</a>  
    </p></div>

    <div>
      <details>
        <summary aria-haspopup="true" aria-label="Possible actions" data-dropdown-tracking="{&quot;type&quot;:&quot;blob_edit_dropdown.more_options_click&quot;,&quot;context&quot;:{&quot;repository_id&quot;:656933936,&quot;actor_id&quot;:null,&quot;github_dev_enabled&quot;:false,&quot;edit_enabled&quot;:false,&quot;small_screen&quot;:true}}">
          
        </summary>

        <ul>
            <li>
                <a data-platforms="windows,mac" href="https://desktop.github.com/">
                  Open with Desktop
                </a>
            </li>
          <li>
            <a href="https://github.com/Stability-AI/generative-models/raw/main/assets/sdxl_report.pdf">
              Download
            </a>
          </li>

            <li>
              <a href="https://github.com/Stability-AI/generative-models/delete/main/assets/sdxl_report.pdf">Delete file</a>
            </li>
        </ul>
      </details>
    </div>
</div>


      
    <div data-identity="8e6b93d9-6b11-4fba-920d-67257282c3e9" data-host="https://viewscreen.githubusercontent.com" data-type="pdf" itemprop="text">
      <svg style="box-sizing: content-box; color: var(--color-icon-primary);" width="64" height="64" viewBox="0 0 16 16" fill="none" data-view-component="true">
  <circle cx="8" cy="8" r="7" stroke="currentColor" stroke-opacity="0.25" stroke-width="2" vector-effect="non-scaling-stroke"></circle>
  <path d="M15 8a7.002 7.002 0 00-7-7" stroke="currentColor" stroke-width="2" stroke-linecap="round" vector-effect="non-scaling-stroke"></path>
</svg>
      <p>Sorry, something went wrong. <a href="https://github.com/Stability-AI/generative-models/blob/main/assets/sdxl_report.pdf">Reload?</a></p>
      <p>Sorry, we cannot display this file.</p>
      <p>Sorry, this file is invalid so it cannot be displayed.</p>
      
    </div>

    </div>


  

  <details id="jumpto-line-details-dialog">
    <summary data-hotkey="l" aria-label="Jump to line"></summary>
    <details-dialog aria-label="Jump to line">
      <!-- '"` --><!-- </textarea></xmp> --><form data-turbo="false" action="" accept-charset="UTF-8" method="get">
        
          
</form>    </details-dialog>
  </details>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Red Hat Is Not Linux (2020) (138 pts)]]></title>
            <link>https://web.archive.org/web/20000815063125/http://www.redhatisnotlinux.org/</link>
            <guid>36585940</guid>
            <pubDate>Tue, 04 Jul 2023 12:45:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://web.archive.org/web/20000815063125/http://www.redhatisnotlinux.org/">https://web.archive.org/web/20000815063125/http://www.redhatisnotlinux.org/</a>, See on <a href="https://news.ycombinator.com/item?id=36585940">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
 <tbody><tr>
  <td><span size="2">
  <span color="RED"><b>Attention: This is not an Anti-Red Hat Linux site</b></span><p>

  <u><b><a name="top">Table of Contents</a></b></u></p><ol>
  <li><a href="#news">News</a></li>
  <li><a href="#Introduction">Introduction</a></li>
  <li><a href="#rhsupport">Commercial Hardware/Software That Supports ONLY Red Hat Linux</a></li>
  <li><a href="#independent">Commerical Hardware/Software That Is Distribution Independent</a></li>
  <li><a href="#othersupport">Commerical Hardware/Software That Supports Multiple Distributions</a></li>
  <li><a href="#mediaredhat">Media Coverage of Red Hat Linux <i> - Coming Soon</i></a></li>
  <li><a href="#mediaother">Media Coverage of other distributions <i> - Coming Soon</i></a></li>
  <li><a href="#suggestions">Our suggestions</a></li>
  <li><a href="#petition">Support Petition</a></li>
  <li><a href="https://web.archive.org/web/20000815063125/http://www.redhatisnotlinux.org/phorum/">Message Board</a></li>
  <li><a href="#retractions">Updates &amp; Retractions</a></li>
  <li><a href="#breakdown">Petition Distribution Breakdown</a></li>
  </ol><p>
  <u><b><a name="news">News</a></b></u></p><blockquote>
  6/23/2000 - <b>Lack of Updates</b><br>
  Sorry about the lack of updates since early May.  May and June have been extremely busy for me, and I haven't been able to give the site the attention it needs and deserves.  I am doing some minor list updates, and have been redesigning the site to make it a little easier to navigate.  This isn't my best design work, I promise.  I made the site like this as function over form to start.  I am gathering contact people for the first petition email.  I have been talking with the people at Sendmail, Inc, and that have been interested in seeing what you folks have to say about their decision to only support Red Hat.  I saw something funny yesterday... Dell's online ordering system will let you buy "Linux 6.2"...  I was thinking this must be some new distribution or maybe they got the kernel version wrong, but then a light went off... Silly me, they meant Red Hat 6.2!  Doh!<p>
  5/2/2000 - <b>Minor Updates</b><br>
  I have added a few companies to the various lists, made some spelling corrections, and added the Petition Distribution Breakdown.  Thanks to everyone who has sent emails concerning corrections, suggestions, opinions, etc... Keep them coming.  I will be doing some major updates in the near future.</p><p>
  4/28/2000 - <b>Update #2</b><br>
  Thanks to Tim Riker for pointing out that RPM is not RedHat Package Manager but rather RPM Package Manager.  Seems a bit recursive if you ask me ;-) But on the official <a href="https://web.archive.org/web/20000815063125/http://www.rpm.org/RPM-HOWTO/index.html#INTRO" target="_new">RPM FAQ</a> It does list it as such.  Seems like traffic is dying down a little.  I guess it's a good thing, in that we'll have less people trying to be distruptive.  I have about 5-10 vendors to update, and hope to do so this weekend.  Thanks for stopping by.</p><p>
  4/28/2000 - <b>Heavy Traffic and more</b><br> 
  As you can imagine with over 30,000 people visiting us in the last 12 hours, we have gotten a log of email.  If you have sent us mail, and you haven't gotten a reply, we will do our best to reply to all the emails sent.  From what we have read, there have been some very good suggestions, additions to our list, and outright anger to to what we're doing.  A lot of email has been sent about VA Linux, and our placing them on the Red Hat only list.  I know they support the development of Debian and run Debian on their web server, but when you buy something through their web site, currently you can only get Red Hat.  I have a call in to them to confirm that we're not just blind and not seeing other distributions.  Thank you for your zeal in response to our efforts.  On a more disappointing side, someone thought it would be cute to write a program to continually vote for their favourite distribution, which is why the poll went away.  Please check back often as we are updating the page through out the day.</p><p>
  4/27/2000 (5:00pm Update) - <b>We've been /.'ed</b><br>Well we have just been posted on Slashdot, and from the comments I am seeing, I only ask that you Read before you Roast, as it seems many don't understand the context of the domain name, and the name of our Effort.</p><p>
  4/27/2000 - <b>Linux.Com, Geeknews.org Report on RedHatIsNotLinux.org</b><br>Thanks to Linux.com and Geeknews.org for reporting on our efforts here.  I think it shows a true effort to show journalistic integrity on the part of Linux.com to list us, as VA is on our Red Hat Only List.  Kudos to them!</p><p>
  4/18/2000 - <b>redhatisnotlinux.org seeks volunteers</b><br>We are currently looking for volunteers to help compile our different lists.  If you are interested in helping us out, please let us know at <a href="https://web.archive.org/web/20000815063125/mailto:info@redhatisnotlinux.org">info@redhatisnotlinux.org</a>.</p><p>
  4/16/2000 - <b>redhatisnotlinux.org goes live</b><br>In an attempt to gain support for other distributions of GNU/Linux, redhatisnotlinux.org is established.  We're currently filling out our database of products that support Linux, both distribution specific and distribution non-specific.  It is our hope to show the disproportionate amount of support for Red Hat over ALL other Distributions.  If you find any errors on this site, please report them to <a href="https://web.archive.org/web/20000815063125/mailto:info@redhatisnotlinux.org">info@redhatisnotlinux.org</a>.  Please not our purpose is to point out commercial support.  We are well aware of the community activity focused around other distributions.
  </p><p><a href="#top">Return to Top</a>
  </p></blockquote><p>
  <u><b><a name="Introduction">Introduction</a></b></u></p><blockquote>
  <b>If this is not an Anti-Red Hat Linux site, what is it?</b><br>
  This is an attempt to call attention to the fact that companies who are writing commercial applications for Linux are ignoring part of the professional GNU/Linux community, which does not use Red Hat Linux.<p>
  <b>What do you mean "Red Hat Is Not Linux"</b><br>
  The easiest way to explain this is to create some definitions or premises, and then come up with a result:</p><p>
  Linux, as <a href="https://web.archive.org/web/20000815063125/http://everything.slashdot.org/everything.pl?sid=&amp;lastnode=&amp;node=linux">defined</a> by <a href="https://web.archive.org/web/20000815063125/http://cmdrtaco.net/">CmdrTaco</a> of Slashdot is: 
 "the GNU license operating system created by Linus Torvalds and the rest of the internet. Unix-like and free, it powers power systems maintained by power users."</p><p>  
  Linux as we define it is the kernel of the GNU/Linux OS and various Distributions.</p><p>
  A Distribution of the GNU/Linux OS, of which Red Hat is one (and the most popular in the media), is the packaging of the Linux kernel, utilities, and programs to make a usable operating system, which can be installed on any number of computers.</p><p>
  This is how we first of all derive that 1) Red Hat != GNU/Linux, and 2) Red Hat is a Distribution of GNU/Linux.</p><p>
  Because of the fragementation of commands, security methodologies, package management, and file layouts among distributions, we feel it is not in the best interest of GNU/Linux to consider one Distribution, and its way of doing things as "Linux."</p><p>
  <b>What do you hope to accomplish by this?</b><br>
  Better support by commercial vendors for GNU/Linux, not just Red Hat Linux and support for GNU/Linux hardware platforms other than Intel based chipsets (PPC, Alpha, etc).</p><p>
  <b>Why do you think that commercial vendors ignore GNU/Linux?</b><br>
  A majority of applications being written today are not distribution independent.  Not only are companies developing solely for Red Hat Linux, they are not aware that other distributions exist.</p><p>
  <b>I'm not convinced, but how do you expect your goals to be accomplished?</b><br>
  Our main goal is to point out incompatibilities between distributions, as well as to provide a petition facility for non-Red Hat users to voice their distress with the continued trend of software that only supports Red Hat.  By doing so, we hope that enough attention can be created for our cause that commercial vendors would consider support for Linux as a whole, not just Red Hat Linux, including all major distributions and binary platforms (x86, PPC, Alpha, etc).
  </p><p><b>What's With This GNU/Linux Stuff Anyway?</b><br>
  There is a political issue in the Linux community as to the relevance of GNU to Linux.  Our position is that without GNU and their tools such as GCC, Linux would not be a mainstream operating system.  We feel that indeed GNU has done more for Linux than Red Hat has, as I am sure Red Hat themselves would admit.  We refer to GNU/Linux in respect to the importance and impact GNU has on Linux.
  </p><p><a href="#top">Back to Top</a></p></blockquote><p>
  <u><b><a name="rhsupport">Commerical Hardware/Software That Supports ONLY Red Hat Linux</a></b></u></p><ul>
   <li><a href="https://web.archive.org/web/20000815063125/http://www.tuxtops.com/" target="_new">TuxTops</a> - Laptops</li>
   <li><a href="https://web.archive.org/web/20000815063125/http://www.dell.com/" target="_new">Dell</a> - All Dell Products</li>
   <li><a href="https://web.archive.org/web/20000815063125/http://www-4.ibm.com/software/data/db2/linux/" target="_new">IBM</a> - DB2 appears to only support Red Hat</li>
   <li><a href="https://web.archive.org/web/20000815063125/http://www.sendmail.com/" target="_new">Sendmail, Inc's</a> Sendmail Switch Line of Products</li>
   <li><a href="https://web.archive.org/web/20000815063125/http://www.cryptocard.com/" target="_new">CRYPTOCard</a> - CRYPTOAdmin 4.0</li>
   <li><a href="https://web.archive.org/web/20000815063125/http://www.hummingbird.com/" target="_new">Hummingbird, Inc.</a> - Hummingbird EIP - Multiple Distribution Support to Come</li> 
   <li><a href="https://web.archive.org/web/20000815063125/http://www.starbox.net/" target="_new">Star Box Net Systems</a> - All Server Products</li>
   <li><a href="https://web.archive.org/web/20000815063125/http://www.penguincomputing.com/" target="_new">Penguin Computing</a> - All Products</li>
   <li><a href="https://web.archive.org/web/20000815063125/http://www.lonetar.com/" target="_new">Lone Tar Software</a> - Air Bag</li>
   <li><a href="https://web.archive.org/web/20000815063125/http://www.valinux.com/" target="_new">VA Linux</a> - Server Products <i>6/20/00 Update - as of today if you order online you can still only order "VA Enhanced Red Hat 6.2"</i></li>
   <li><a href="https://web.archive.org/web/20000815063125/http://www.netmax.com/" target="_new">Net Max</a> - All Net Max Products</li>
   <li><a href="https://web.archive.org/web/20000815063125/http://www.hp.com/" target="_new">HP</a> -  Hewlett Packard Print Servers</li>
   <li><a href="https://web.archive.org/web/20000815063125/http://www.macromedia.com/software/generator" target="_new">Macromedia</a> - Macromedia Generator - Investigating other Products</li>
   <li><a href="https://web.archive.org/web/20000815063125/http://www.checkpoint.com/products/firewall-1/sysrequire.html">Checkpoint</a> Firewall-1</li>
  </ul><blockquote><a href="#top">Back to Top</a></blockquote><p>
  <u><b><a name="independent">Commerical Hardware/Software That Is Distribution Independent</a></b></u></p><ul>
   <li><a href="https://web.archive.org/web/20000815063125/http://www.c2.net/">C2 Net</a> Stronghold</li>
   <li><a href="https://web.archive.org/web/20000815063125/http://www.micronetics.net/">Micronetics</a>  SecureNet PRO v3.0</li> 
   <li><a href="https://web.archive.org/web/20000815063125/http://www.oracle.com/">Oracle</a> Oracle8i</li>
  </ul><blockquote><a href="#top">Back to Top</a></blockquote><p>
  <u><b><a name="othersupport">Commerical Hardware/Software That Supports Multiple Distributions</a></b></u></p><ul>
   <li><a href="https://web.archive.org/web/20000815063125/http://www.apcc.com/products/management/pcp_linux.cfm">APC PowerChute Plus</a> <i>(Red Hat, Caldera, TurboLinux, SuSE)</i></li>
   <li><a href="https://web.archive.org/web/20000815063125/http://www.ca.com/">Computer Associates</a> ArcServeIT <i>(Red Hat, Caldera, TurboLinux, SuSe)</i></li>
   <li><a href="https://web.archive.org/web/20000815063125/http://www.ca.com/">Computer Associates</a> Ingres II <i>(Slackware, Red Hat, Debian, TurboLinux, SuSe)</i></li>
   <li><a href="https://web.archive.org/web/20000815063125/http://www.ca.com/">Computer Associates</a> Unicenter TNG <i>(RedHat, SuSe)</i></li>
   <li><a href="https://web.archive.org/web/20000815063125/http://www.vsi.com/" target="_new">VSI</a> - VSI-Fax (Red Hat, Caldera)</li> 
   <li><a href="https://web.archive.org/web/20000815063125/http://www.hp.com/" target="_new">Hewlett Packard</a> - Officially supports Red Hat, Turbolinux, Caldera, and SuSE, though many products are Red Hat Only</li>
   <li><a href="https://web.archive.org/web/20000815063125/http://www.enlightendsm.com/" target="_new">Enlighten Software Solutions, Inc.</a> EnlightenDSM (SuSe, Turbo Linux, Caldera, Mandrake)</li>
   <li><a href="https://web.archive.org/web/20000815063125/http://www.sunsetsystems.com/" target="_new">Sunset Systems</a> preconfigured Linux boxes with Slackware, RedHat, Mandrake, and will preconfigure any Distro upon Request.</li>
   <li><a href="https://web.archive.org/web/20000815063125/http://www.compaq.com/linux">Compaq</a> has alliances with Caldera, Red Hat, S.U.S.E., and TurboLinux</li>
   <li><a href="https://web.archive.org/web/20000815063125/http://www.ibm.com/">IBM</a> supports Caldera, Red Hat, SuSE and TurboLinux</li>

  </ul><blockquote><a href="#top">Back to Top</a></blockquote><p>
  <u><b><a name="mediaredhat">Red Hat in the Media</a></b></u></p><ul>
   <li><a href="https://web.archive.org/web/20000815063125/http://www.msnbc.com/news/399125.asp?cp1=1" target="_new">Linux open to backdoor password</a> - This is a good example of what we are trying to address.   When this article first was posted the headline read "Linux open to backdoor password."  It has since been changed to the more responsible "Red Hat open to backdoor password."  In its first revision it could place mistrust in the consumer market as to the security of ALL Linux distributions, or much, much worse, the Linux Kernel itself!</li>
  </ul>
  <blockquote><a href="#top">Back to Top</a></blockquote><p>
  <u><b><a name="suggestions">Our Suggestions</a></b></u></p><blockquote>
  We are currently gathering information on different community efforts to standardize Linux Distribution structure.  We feel that companies can do various things to insure support for all major distributions of Linux including:<ul>
 <li>Outsourcing Technical Support to Organizations like <a href="https://web.archive.org/web/20000815063125/http://www.linuxcare.com/">LinuxCare</a></li>
 <li>Providing non-distribution specific binary releases (glibc-2.0, shadow passwords, glibc-2.1, shadow passwords, glibc-2.0 PAM, glibc-2.1 PAM) - C2Net does an excellent job of this with their distributions of Stronghold.
 </li><li>Provide RPM, DEB, and  Tarball distribution of Binary Applications.</li>
 <li>Create a Media Awareness kit to avoid sterotyping of different distributions as "LINUX."  We would be happy to spearhead this, but would love some help in creating it from professional writers and media people.</li>
 <li>VA Linux, or another company with the same ability, should setup a commercial server farm of different distributions, similar to VA's <a href="https://web.archive.org/web/20000815063125/http://www.valinux.com/about/news/releases/030700.html" target="_new">SourceForge<sup>TM</sup> CompileFarm</a>, for comercial entities to build binary distributions for ALL MAJOR Linux distributions.</li>
 <li>Support the <a href="https://web.archive.org/web/20000815063125/http://www.linuxbase.org/">Linux Standards Base</a></li>
</ul>
  <p><a href="#top">Back to Top</a></p></blockquote><p>
  <u><b><a name="petition">Support Petition</a></b></u></p><blockquote>
  The petition currently has 5255 entries.</blockquote><ul> 
  <li><a href="https://web.archive.org/web/20000815063125/http://www.redhatisnotlinux.org/petition.php4">Sign the Petition</a></li>
  <li><a href="https://web.archive.org/web/20000815063125/http://www.redhatisnotlinux.org/readPetition.php4">View the Petition</a></li>
  </ul><blockquote>
  <p><a href="#top">Back to Top</a></p></blockquote><p>
  <u><b><a name="retractions">Updates &amp; Retractions</a></b></u></p><blockquote>
  If you or your company feel we have misrepresented your products or services as to only support Red Hat Linux or you would like your hardware/software added to our list, please contact us so we may remove you from our list, and note your support of other Distributions.  Please <a href="https://web.archive.org/web/20000815063125/mailto:info@redhatisnotlinux.org">Email</a> your comments to info@redhatisnotlinux.org.
 <p><a href="#top">Back to Top</a></p></blockquote><p>
  <u><b><a name="breakdown">Petition Distribution Breakdown</a></b></u></p><blockquote>
  We have written a little script which attempts to break out the Favorite Distributions of the people who signed the petition.  By doing simple LIKE queries on the petition we have broken out the following numbers for each distribution:<ul>
<li><b>Caldera</b> is preferred by <b>127</b> petitioners</li>
<li><b>Corel</b> is preferred by <b>87</b> petitioners</li>
<li><b>Debian</b> is preferred by <b>1486</b> petitioners</li>
<li><b>LinuxPPC</b> is preferred by <b>55</b> petitioners</li>
<li><b>Mandrake</b> is preferred by <b>539</b> petitioners</li>
<li><b>Red Hat</b> is preferred by <b>928</b> petitioners</li>
<li><b>Slackware</b> is preferred by <b>1364</b> petitioners</li>
<li><b>Storm</b> is preferred by <b>27</b> petitioners</li>
<li><b>SuSE</b> is preferred by <b>1668</b> petitioners</li>
<li><b>TurboLinux</b> is preferred by <b>33</b> petitioners</li>
<li><b>Yellowdog</b> is preferred by <b>11</b> petitioners</li>
  </ul></blockquote><p><a href="#top">Back to Top</a></p></span></td>
</tr></tbody></div><p>
Hosting Kindly Provided By <a href="https://web.archive.org/web/20000815063125/http://www.readysetnet.com/">Ready Set Net</a>, An Open Source, Linux Based, Internet Development Company.</p><p>
Linux is a registered trademark of Linus Torvalds. All trademarks and registered trademarks on redhatisnotlinux.com are owned by their respective companies.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A curated list of uBlock origin filters (236 pts)]]></title>
            <link>https://letsblock.it/filters</link>
            <guid>36585371</guid>
            <pubDate>Tue, 04 Jul 2023 11:43:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://letsblock.it/filters">https://letsblock.it/filters</a>, See on <a href="https://news.ycombinator.com/item?id=36585371">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p role="alert">
                <form method="POST" action="/user/action/loginOrRegistration">
                    
                    <span>This website is a collaborative repository of uBlock content filters
                        you can customize and sync across your browsers.
                        <a href="https://letsblock.it/help/about">Learn more about it</a> and</span>
                    
                    <span>to start building your filter list.</span>
                </form>
            </p>
        
            
            <p>Check these new filters and customize them for your use:</p>
            <ul>
                    <li>
                        <div>
                                <p><a href="https://letsblock.it/filters/amazon-products">Amazon: filter out products by name</a>
                                                </p></div>
                    </li>
                    <li>
                        <div>
                                <p><a href="https://letsblock.it/filters/github-cleanup">GitHub: interface cleanups</a>
                                                </p></div>
                    </li>
                    <li>
                        <div>
                                <p><a href="https://letsblock.it/filters/google-search-cleanup">Google Search: interface cleanups</a>
                                                </p></div>
                    </li>
                    <li>
                        <div>
                                <p><a href="https://letsblock.it/filters/hackernews-darkmode">Hacker News: unofficial dark mode</a>
                                                </p></div>
                    </li>
                    <li>
                        <div>
                                <p><a href="https://letsblock.it/filters/linkedin-posts-by-link">Linkedin: filter out posts by link target</a>
                                                </p></div>
                    </li>
                    <li>
                        <div>
                                <p><a href="https://letsblock.it/filters/linuxfr-cleanup">LinuxFr: interface cleanups</a>
                                                </p></div>
                    </li>
                    <li>
                        <div>
                                <p><a href="https://letsblock.it/filters/nebula-creators">Nebula: filter out videos by creator</a>
                                                </p></div>
                    </li>
                    <li>
                        <div>
                                <p><a href="https://letsblock.it/filters/search-results">Search engines: filter out results by website</a>
                                                </p></div>
                    </li>
                    <li>
                        <div>
                                <p><a href="https://letsblock.it/filters/soundcloud-reposts">Soundcloud: hide reposts</a>
                                                </p></div>
                    </li>
                    <li>
                        <div>
                                <p><a href="https://letsblock.it/filters/youtube-shorts">YouTube: filter out Shorts</a>
                                                </p></div>
                    </li>
                    <li>
                        <div>
                                <p><a href="https://letsblock.it/filters/youtube-mixes">YouTube: filter out mixes and radios</a>
                                                </p></div>
                    </li>
                    <li>
                        <div>
                                <p><a href="https://letsblock.it/filters/youtube-upcoming-videos">YouTube: filter out upcoming videos and streams</a>
                                                </p></div>
                    </li>
                    <li>
                        <div>
                                <p><a href="https://letsblock.it/filters/youtube-channel">YouTube: filter out videos by channel</a>
                                                </p></div>
                    </li>
                    <li>
                        <div>
                                <p><a href="https://letsblock.it/filters/youtube-video-title">YouTube: filter out videos by title</a>
                                                </p></div>
                    </li>
                    <li>
                        <div>
                                <p><a href="https://letsblock.it/filters/youtube-watched">YouTube: filter out videos you already watched</a>
                                                </p></div>
                    </li>
                    <li>
                        <div>
                                <p><a href="https://letsblock.it/filters/youtube-recommendations">YouTube: hide video recommendations</a>
                                                </p></div>
                    </li>
                    <li>
                        <div>
                                <p><a href="https://letsblock.it/filters/youtube-search-cleanup">YouTube: search interface cleanups</a>
                                                </p></div>
                    </li>
                    <li>
                        <div>
                                <p><a href="https://letsblock.it/filters/youtube-cleanup">YouTube: video playback interface cleanups</a>
                                                </p></div>
                    </li>
                    <li>
                        <div>
                                <p><a href="https://letsblock.it/filters/custom-rules">Add custom blocking rules</a>
                                                </p></div>
                    </li>
                    <li>
                        <div>
                                <p><a href="https://letsblock.it/filters/url-param-remover">Remove tracking URL parameters from links</a>
                                                </p></div>
                    </li>
            </ul>        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Ancient Roman Secret to Concrete Resilience in Seawater (114 pts)]]></title>
            <link>https://als.lbl.gov/ancient-roman-secret-concrete-resilience-seawater/</link>
            <guid>36585331</guid>
            <pubDate>Tue, 04 Jul 2023 11:39:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://als.lbl.gov/ancient-roman-secret-concrete-resilience-seawater/">https://als.lbl.gov/ancient-roman-secret-concrete-resilience-seawater/</a>, See on <a href="https://news.ycombinator.com/item?id=36585331">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><span><a href="https://als.lbl.gov/"><span>Home</span></a><meta></span> <span aria-label="breadcrumb separator">/</span> <span><a href="https://als.lbl.gov/category/news/"><span>News</span></a><meta></span> <span aria-label="breadcrumb separator">/</span> <span><a href="https://als.lbl.gov/category/news/science-briefs/"><span>Science Briefs</span></a><meta></span> <span aria-label="breadcrumb separator">/</span> The Ancient Roman Secret to Concrete Resilience in Seawater</p><article aria-label="The Ancient Roman Secret to Concrete Resilience in Seawater"><div><p>Unlike modern concrete, which can rapidly deteriorate in marine environments, Roman concrete thrives in open chemical exchange with seawater. Most modern concrete is a mix of Portland cement and aggregates—materials such as sand or crushed stone that are not intended to chemically react over time. Roman concrete was made from volcanic ash, lime (calcium oxide), and seawater. <a href="https://als.lbl.gov/learning-from-roman-concrete/">Previous ALS studies</a> showed that the lime, upon exposure to seawater, reacted with the volcanic ash to produce aluminous tobermorite (Al-tobermorite), a layered mineral that forms fine fibers and plates.</p>
<p>To better understand the longer-term chemical processes in the concrete, researchers studied samples from ancient pier and breakwater sites using a variety of techniques, including electron microscopy and Raman spectroscopy. At ALS <a href="https://als.lbl.gov/beamlines/12-3-2/">Beamline 12.3.2</a>, they used x-ray microdiffraction to trace the complex sequences of crystal growth at the micron scale. The results indicate that Al-tobermorite and a related zeolite mineral called phillipsite continue to form over millennia as seawater percolates through the massive structures, reinforcing the cementing matrix in a kind of regenerative process that strengthens the concrete.</p>
<p>The researchers suggest that a reformulated recipe for Roman concrete could be tested for applications such as seawalls and other ocean-facing structures, and may be useful for safeguarding hazardous wastes, since Al-tobermorite has special cation-exchange properties. The work ultimately could lead to a wider adoption of concrete manufacturing techniques with less environmental impact than modern cement manufacturing processes, which require high-temperature kilns. These are a significant contributor to industrial carbon dioxide emissions, which add to the buildup of greenhouse gases in Earth’s atmosphere.</p>
<figure id="attachment_15325" aria-describedby="caption-attachment-15325"><img decoding="async" src="https://als.lbl.gov/wp-content/uploads/2017/07/transparent-line-710px.png" alt="" width="710" height="1" srcset="https://als.lbl.gov/wp-content/uploads/2017/07/transparent-line-710px.png 710w, https://als.lbl.gov/wp-content/uploads/2017/07/transparent-line-710px-170x1.png 170w, https://als.lbl.gov/wp-content/uploads/2017/07/transparent-line-710px-450x1.png 450w, https://als.lbl.gov/wp-content/uploads/2017/07/transparent-line-710px-600x1.png 600w, https://als.lbl.gov/wp-content/uploads/2017/07/transparent-line-710px-360x1.png 360w" sizes="(max-width: 710px) 100vw, 710px"><figcaption id="caption-attachment-15325"><iframe loading="lazy" src="https://www.youtube.com/embed/ikH6Vmb0pog" width="710" height="399" frameborder="0" allowfullscreen="allowfullscreen"></iframe><br>The ancient Romans had a recipe for concrete that won’t corrode in seawater. Scientists are trying to figure it out. Video credit: University of Utah. Also, listen to the Science Friday segment with Marie D. Jackson, “<a href="https://www.sciencefriday.com/person/marie-d-jackson/">Drilling Into The Secrets Of Roman Concrete</a>.”</figcaption></figure>
<div>
<p><strong>Work performed at ALS <a href="https://als.lbl.gov/beamlines/12-3-2/">Beamline 12.3.2</a>.</strong><strong>&nbsp;</strong></p>
<p>M.D. Jackson, S.R. Mulcahy, H. Chen, Y. Li, Q. Li, P. Cappppelletti, and H.-R. Wenk, “<a href="http://ammin.geoscienceworld.org/content/102/7/1435">Phillipsite and Al-tobermorite mineral cements produced through low-temperature water-rock reactions in Roman marine concrete</a>,” <em>Am. Mineral.</em> <strong>102</strong>, 1435 (2017), doi:10.2138/am-2017-5993CCBY.</p>
<p>Adapted from the Berkeley Lab news release, “<a href="http://newscenter.lbl.gov/2017/07/03/ancient-concrete-could-teach-us-to-do-as-romans-did/">New Studies of Ancient Concrete Could Teach Us to Do as the Romans Did</a>”&nbsp;and the University of Utah news release, “<a href="https://unews.utah.edu/roman-concrete/">How Seawater Strengthens Ancient Roman Concrete</a>.”</p>
</div>
<!-- Simple Share Buttons Adder (8.4.6) simplesharebuttons.com --></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[An Architectural Overview of QNX – inside the industry's only true microkernel [pdf] (137 pts)]]></title>
            <link>https://cseweb.ucsd.edu/~voelker/cse221/papers/qnx-paper92.pdf</link>
            <guid>36584692</guid>
            <pubDate>Tue, 04 Jul 2023 10:26:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cseweb.ucsd.edu/~voelker/cse221/papers/qnx-paper92.pdf">https://cseweb.ucsd.edu/~voelker/cse221/papers/qnx-paper92.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=36584692">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Sourcegraph is no longer Open Source (367 pts)]]></title>
            <link>https://github.com/sourcegraph/sourcegraph/blob/main/CHANGELOG.md</link>
            <guid>36584656</guid>
            <pubDate>Tue, 04 Jul 2023 10:21:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/sourcegraph/sourcegraph/blob/main/CHANGELOG.md">https://github.com/sourcegraph/sourcegraph/blob/main/CHANGELOG.md</a>, See on <a href="https://news.ycombinator.com/item?id=36584656">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
          <p>      A tag already exists with the provided branch name. Many Git commands accept both tag and branch names, so creating this branch may cause unexpected behavior. Are you sure you want to create this branch?
</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Passwords Are Fine (114 pts)]]></title>
            <link>https://herman.bearblog.dev/passwords-are-fine/</link>
            <guid>36584615</guid>
            <pubDate>Tue, 04 Jul 2023 10:16:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://herman.bearblog.dev/passwords-are-fine/">https://herman.bearblog.dev/passwords-are-fine/</a>, See on <a href="https://news.ycombinator.com/item?id=36584615">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>
<i>
<time datetime="2023-07-04">
04 Jul, 2023
</time>
</i>
</p>
<p>I've spent too much of my professional life trying to build a better means of authentication.</p>
<p>For a while I was fixated on Magic Links, then I built a few prototypes of authentication using a combination of token passing and TOTP. And finally, I built a storage-less password manager (another story for another day). When proposals for systems like WebAuthn or Apple Passkeys were published I got excited. To see the world move away from the dated and insecure email/password combo would have really made my day.</p>
<p>But after a while I lost my fervour. There was a lack of implementation of these strong password-less authentication methods across web-services and apps. There was no transition. Also, my opinions around authentication changed...somewhat.</p>
<p>I had an article pop up on my feed recently titled "<a href="https://sec.okta.com/articles/2020/04/webauthn-great-and-it-sucks" target="_blank">WebAuthn is great and it sucks</a>" which describes the problem succinctly. While the tech is great, the problem is that nothing supports these new-fangled methods of authentication. I've run into a few other problems as well:</p>
<ol>
<li>Multi-devicing for authentication is a poor user experience. Even having to go click a link in your mailbox sucks.</li>
<li>People don't have their phone on them all the time (and some don't even have a smartphone).</li>
<li>New users don't understand these methods of authentication.</li>
<li>They're generally much more complicated to implement than a basic email/password combo.</li>
</ol>
<p><em>As a side note, I'm not a fan of single sign-on using Twitter/Google/Facebook due to the inability to migrate to a different service if need be. If Twitter locks you out of your account you're locked out of all your connected services as well. This is a broader topic, but I just wanted to touch on it before continuing.</em></p>
<p>Passwords are simple and affordable. We were using them prior to computers ("Open sesame!") and their understandability transferred easily. "But wait!" you say. "Aren't passwords insecure and easy to compromise?". Well yes...if managed poorly.</p>
<h4 id="let-s-explore-the-common-pitfalls-of-passwords">Let's explore the common pitfalls of passwords:</h4>
<ol>
<li>People can't remember passwords for their dozens of services.</li>
<li>Due to #1 people tend to re-use passwords, which makes one compromised service a more wide-spread problem.</li>
<li>People can have their passwords stolen (generally also due to #1 since they write them down or store them insecurely).</li>
<li>Services can have their user's passwords stolen if not stored as a hash (this is a solved problem though, services need to do better).</li>
</ol>
<p>Notice that all of these problems are solved by fairly simple password hygiene.</p>
<p>I personally have one obnoxiously long and complicated password for my password manager, but then all of my other passwords are random lengthly strings which are impossible to guess.</p>
<p>I don't ever see them.</p>
<p>The passwords also aren't re-used, which solves #2 and my login flow is a super convenient fingerprint scan on both my phone and my laptop. And if I have to manually enter my password on a different device (which is very rare) I can easily pull up my password on my password manager and type it in.</p>
<p>Not only does a good password manager make people safer, it makes logins much easier since you don't have to remember "which password I used for this service", then follow the "forgot password" flow.</p>
<p>I guess the point I'm trying to make here is that the problem with passwords is password hygiene, not with the method itself.</p>
<p>When ebola was wreaking havoc in Central Africa the most effective intervention was to implement a culture of hand-washing. The UN send healthcare workers out to cities, towns and villages armed with plastic basins and soap, but most importantly, knowledge. It was an effective intervention and the culture of hand-washing persists to this day.</p>
<p>Password hygiene is imperative for our digital world. Fact is that even if we create the perfect new authentication method, passwords will persist on the vast majority of services. If it ain't broke...</p>
<p>Finally, when sharing passwords, it is important to do so securely. Slack is not a secure channel for these kinds of things. I've <a href="https://herman.bearblog.dev/thinking-about-passwords/" target="_blank">written</a> about this before and built out a completely free <a href="https://horuspass.com/send/" target="_blank">service</a> to share passwords and API keys securely, but any good password manager should have similar functionality.</p>
<h4 id="recommendation-time">Recommendation time:</h4>
<p>If you're an Apple user, then the built in Apple password manager is probably the best solution for you. It's close to perfect since it allows biometric authentication, syncs between your devices, and is well integrated into their products.</p>
<p>Alternatively, there are also a bunch of great apps that have similar functionality. <a href="https://1password.com/" target="_blank">1Password</a> is a good choice. So is <a href="https://www.dashlane.com/" target="_blank">Dashlane</a>. There are others.</p>
<p>Good passwords combined with an authentication app for 2FA like <a href="https://authy.com/" target="_blank">Authy</a> or Google Authenticator are great security. You'll probably never have an issue. On this note, SMS 2FA is bad. Not only are SIM-swap scams prevalent and fairly easy to execute, but it is also a fragile system and breaks easily ("Didn't receive the SMS? Click here to retry.").</p>
<p>On top of that, SMS isn't universal. My bank only supports SMS 2FA so while I'm travelling I'm effectively cut off from certain functionality. I hate it and have tried to change it, but banks move slowly.</p>
<p>It's important for us to get this right. If you have parents (or grandparents) who aren't particularly tech-savvy, sit them down for an afternoon and teach them about password hygiene. Let's create a better authentication culture. It will keep everyone safer.</p>
<hr>
<h5 id="enjoyed-the-article-i-write-about-1-2-a-month-subscribe-via-email-or-rss-feed">Enjoyed the article? I write about 1-2 a month. Subscribe via <a href="https://herman.bearblog.dev/subscribe/">email</a> or <a href="https://herman.bearblog.dev/feed/">RSS feed</a>.</h5>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPT-4 is great at infuriating telemarketing scammers (132 pts)]]></title>
            <link>https://www.theregister.com/2023/07/03/jolly_roger_telephone_company/</link>
            <guid>36583969</guid>
            <pubDate>Tue, 04 Jul 2023 08:48:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/07/03/jolly_roger_telephone_company/">https://www.theregister.com/2023/07/03/jolly_roger_telephone_company/</a>, See on <a href="https://news.ycombinator.com/item?id=36583969">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Every week there seems to be another cynical implementation of AI that devalues the human experience so it is with a breath of fresh air that we report on a bedroom venture that uses GPT-4 technology to frustrate telemarketers.</p>
<p>"Fight back against annoying telemarketers and evil scammers!" the Jolly Roger Telephone Company rails on its <a target="_blank" href="https://jollyrogertelephone.com/">website</a>. "Our robots talk to telemarketers so humans don't have to!"</p>
<p>While no one can put a price on slamming the phone down on a call center worker, some among us might get a perverse joy out of listening to them squirm under the non sequiturs of AI. And it seems to be working for Jolly Roger, which has thousands of customers subscribed for $23.80 a year.</p>

    

<p>The company has a <a target="_blank" href="https://jollyrogertelephone.com/our-robots/">number of bots</a> at its disposal all with unique voices and quirks that makes them utterly infuriating to speak to from the original Jolly Roger, based on the voice of Californian founder Roger Anderson, to distracted mother Salty Sally, who keeps wanting to talk about a talent show she won, to feisty senior citizen Whitey Whitebeard and more. Samples of toe-curling conversations are all over Jolly Roger's website.</p>

        


        

<p>"Oh jeez, hang on, there's a bee on me, hang on," Jolly Roger tells one scammer. "There's a bee on my arm. OK, you know what? You keep talking, I'm not gonna talk, though. You keep talking, say that part again, and I'm just gonna stay quiet because of the bee."</p>
<ul>

<li><a href="https://www.theregister.com/2023/07/03/mozilla_developer_network_adds_ai/">Mozilla Developer Network adds AI Help that does the opposite</a></li>

<li><a href="https://www.theregister.com/2023/07/01/microsoft_github_copilot/">Microsoft and GitHub are still trying to derail Copilot code copyright legal fight</a></li>

<li><a href="https://www.theregister.com/2023/06/30/lords_ai_weapons/">Experts scoff at UK Lords' suggestion that AI could one day make battlefield decisions</a></li>

<li><a href="https://www.theregister.com/2023/06/28/microsoft_openai_sued_privacy/">Microsoft, OpenAI sued for $3B after allegedly trampling privacy with ChatGPT</a></li>
</ul>
<p>Sprinkle in gratuitous salvos of "Suuuure" and "Mhm" and "Sorry, I was having trouble concentrating because you're EXACTLY like somebody I went to high school with so, sorry, say that part again." Five minutes later you have a cold caller pulling their hair out and hanging up.</p>
<p>Here's Salty Sally in action:</p>
<p>
  <a href="https://youtu.be/dtO7jvS-pxA?t=39" data-media="x-videoplayer">Youtube Video</a>
</p>

        

<p>Customers provide the phone numbers they want to protect and the subscription activates immediately. Users login to the website where they can set up whichever bot or bots they want to employ. Then, when a telemarketer calls, the user is able to merge the call with a specified or random bot. The customer can then listen to the fruits of their labor in Jolly Roger's "Pirate Porthole."</p>
<p>YouTubers like Kitboga have made a name for themselves by infuriating and hacking computer-based scammers in real time while they try to swindle him over the telephone, but now regular folk can do similar without having to lift a finger.</p>
<p>At a time when AI grifters are trying to convince the gullible to <a target="_blank" href="https://www.youtube.com/watch?v=BI3Bt-pIkfA&amp;lc=UgzWPfD9JScCLI0vA5R4AaABAg">flood the ebook market with ChatGPT-generated joke books</a>, it is heartening to see something related that is both funny and actually effective. ®</p>                                


                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Companies must stop using Google Analytics (561 pts)]]></title>
            <link>https://www.imy.se/en/news/companies-must-stop-using-google-analytics/</link>
            <guid>36583906</guid>
            <pubDate>Tue, 04 Jul 2023 08:41:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.imy.se/en/news/companies-must-stop-using-google-analytics/">https://www.imy.se/en/news/companies-must-stop-using-google-analytics/</a>, See on <a href="https://news.ycombinator.com/item?id=36583906">Hacker News</a></p>
<div id="readability-page-1" class="page">
    



<header id="imy-header" aria-label="Header">
    <a href="#maincontent">
        <span>
            Skip to content
        </span>
        <i></i>
    </a>

    <div id="imy-header__container">
            <nav id="imy-menu-container-scripted" aria-label="Main menu">
                
                
                <i id="imy-header-border-burger" aria-hidden="true"></i>
                <ul>
                    <li>
                        
                        
                    </li>
                    <li>
                        
                        
                    </li>
                    <li>
                        <hr id="imy-header-border-business" aria-hidden="true">
                    </li>
                </ul>
            </nav>
            <nav id="imy-menu-container-noscript">
                
                
                
                
                
                
                <label for="menu3">
                    <i aria-hidden="true"></i>
                    <span>Menu</span>
                    <span>Main menu</span>
                </label>
                <label for="menuC">
                    <i aria-hidden="true"></i>
                    <span>Menu</span>
                    <span>Main menu</span>
                </label>
                <i aria-hidden="true"></i>
                <ul>
                    <li>
                        
                    </li>
                    <li>
                        <div id="sn_menu_icon_2">
                            <label for="menu2">
                                <i aria-hidden="true"></i>
                                <span>Organisations</span>
                            </label>
                            <label for="menuB">
                                <i aria-hidden="true"></i>
                                <span>Organisations</span>
                            </label>
                            <hr aria-hidden="true">
                        </div>
                    </li>
                    <li>
                        <hr aria-hidden="true">
                    </li>
                </ul>
                <nav id="imy_menu_panel" aria-label="Main menu">







<div id="imy-menu-mobile">

    
    
    
    
    <ul>
        <li>
            
        </li>
        <li>
            <div id="sn_menu_icon_5">
                <label for="menu5">
                    <i aria-hidden="true"></i>
                    <span>Organisations</span>
                </label>
                <label for="menuE">
                    <i aria-hidden="true"></i>
                    <span>Organisations</span>
                </label>
            </div>
        </li>
    </ul>
    <ul>
        <li>
            
        </li>
        <li>
            
        </li>
    </ul>
    <hr id="imy-menu-mobile-border" aria-hidden="true">
    
</div>
                </nav>
            </nav>
            <a href="https://www.imy.se/en/" aria-label="IMY Swedish Authority for Privacy Protection (to startpage)"></a>
            
        </div>
</header>


    <main id="maincontent">
        <div id="readspeaker-content">
            
            


<div>
        <div>
                

            
            <h2>Companies must stop using Google Analytics </h2>
        </div>
        
        <div>
            The Swedish Authority for Privacy Protection (IMY) has audited how four companies use Google Analytics for web statistics. IMY issues administrative fines against two of the companies. One of the companies has recently stopped using the statistics tool on its own initiative, while IMY orders the other three to also stop using it.
        </div>
        <div>
            <p>IMY has audited how four companies transfer personal data to the US via Google Analytics, which is a tool for measuring and analysing traffic on websites. The companies audited are CDON, Coop, Dagens Industri and Tele2. The audits concerns a version of Google Analytics from 14th of August 2020.</p>
<p>The audits are based on complaints from the organisation None of Your Business (NOYB) in the light of the Schrems II ruling by the European Court of Justice (CJEU). The complaints allege that the companies, in violation of the law, transfer personal data to the United States.</p>
<p>According to the data protection regulation, GDPR, personal data may be transferred to third countries, i.e. countries outside the EU/EEA, if the European Commission has decided that the country in question has an adequate level of protection for personal data that corresponds to that within the EU/EEA. However, the CJEU ruled through the Schrems II ruling that the United States could not be considered to have such an adequate level of protection at the time of the ruling.</p>
<p>In its audits, IMY considers that the data transferred to the US via Google's statistics tool is personal data because the data can be linked with other unique data that is transferred. The authority also concludes that the technical security measures that the companies have taken are not sufficient to ensure a level of protection that essentially corresponds to that guaranteed within the EU/EEA.</p>
<p>– By the fact that IMY has decided on these cases at the same time, it is made clear what requirements are placed on technical security measures and other measures when transferring personal data to a third country, in this case the United States, says legal advisor Sandra Arvidsson, who led the audits of the companies.</p>
<p>If there is no decision on an adequate level of protection by the European Commission, data may be transferred based on standard contractual clauses that the European Commission has decided on. However, according to the CJEU, such standard contractual clauses may need to be supplemented with additional safeguards if it is necessary for the protection that the clauses are intended to provide to be maintained in practice.</p>
<p>All four companies have based their decisions on the transfer of personal data via Google Analytics on standard contractual clauses. From IMY's audits, it appears that none of the companies' additional technical security measures are sufficient. IMY issues an administrative fine of 12 million SEK against Tele2 and 300,000 SEK against CDON, which has not taken the same extensive protective measures as Coop and Dagens Industri. Tele2 has recently stopped using the statistics tool on its own initiative. IMY orders the other three companies to stop using the tool.</p>
<p>– These decisions have implications not only for these four companies, but can also provide guidance for other organisations that use Google Analytics, says Sandra Arvidsson.</p>



            
<div>
                <h2>
                    For more information contact
                </h2>
                <div>
                    <p>Legal advisor Sandra Arvidsson, telephone 08-515 154 14<br>Press service, telephone 08-515 15 415</p>
                </div>
            </div>
        </div>
        <div>
                    <i aria-hidden="true"></i>
                    Latest update: 3 July 2023
                </div>
        <div>
                <h2>More news on this topic</h2>
                <ul>
                        <li>
                            <a href="https://www.imy.se/link/b77df0c41ffc4dd394cde97df44d4465.aspx"><h3>Administrative fee against Spotify <br></h3>13 June 2023</a>
                            <hr aria-hidden="true">
                        </li>
                        <li>
                            <a href="https://www.imy.se/link/c7ca1c058f1a4281b534e01d0b1572f3.aspx"><h3>Data protection officers point to problems applying GDPR <br></h3>31 January 2023</a>
                            <hr aria-hidden="true">
                        </li>
                        <li>
                            <a href="https://www.imy.se/link/f12b0540458145a69dacf2c51ace09d6.aspx"><h3>Administrative fine against Klarna after investigation<br></h3>31 March 2022</a>
                            <hr aria-hidden="true">
                        </li>
                        <li>
                            <a href="https://www.imy.se/link/5c79a2d4af314fe59eae3105c5dfa336.aspx"><h3>Administrative fine to the Swedish Customs for deficient routines <br></h3>16 March 2022</a>
                            <hr aria-hidden="true">
                        </li>
                </ul>
                
            </div>
    </div>
<div>
        <h2>More news on this topic</h2>
        <ul>
                <li>
                    <a href="https://www.imy.se/link/b77df0c41ffc4dd394cde97df44d4465.aspx"><h3>Administrative fee against Spotify <br></h3>13 June 2023</a>
                    <hr aria-hidden="true">
                </li>
                <li>
                    <a href="https://www.imy.se/link/c7ca1c058f1a4281b534e01d0b1572f3.aspx"><h3>Data protection officers point to problems applying GDPR <br></h3>31 January 2023</a>
                    <hr aria-hidden="true">
                </li>
                <li>
                    <a href="https://www.imy.se/link/f12b0540458145a69dacf2c51ace09d6.aspx"><h3>Administrative fine against Klarna after investigation<br></h3>31 March 2022</a>
                    <hr aria-hidden="true">
                </li>
                <li>
                    <a href="https://www.imy.se/link/5c79a2d4af314fe59eae3105c5dfa336.aspx"><h3>Administrative fine to the Swedish Customs for deficient routines <br></h3>16 March 2022</a>
                    <hr aria-hidden="true">
                </li>
        </ul>
        
    </div>
<div>
                <i aria-hidden="true"></i>
                Latest update: 3 July 2023
            </div>

        </div>
    </main>





    

    

    





</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why there may never be a libjpeg-turbo 3.1 (108 pts)]]></title>
            <link>https://groups.google.com/g/libjpeg-turbo-announce/c/YZ2wRgB0zIE</link>
            <guid>36583406</guid>
            <pubDate>Tue, 04 Jul 2023 07:30:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://groups.google.com/g/libjpeg-turbo-announce/c/YZ2wRgB0zIE">https://groups.google.com/g/libjpeg-turbo-announce/c/YZ2wRgB0zIE</a>, See on <a href="https://news.ycombinator.com/item?id=36583406">Hacker News</a></p>
<div id="readability-page-1" class="page"><div jsname="yjbGtf" aria-labelledby="i4" role="region"><p>Binaries and source tarball are here:
<br><a href="https://sourceforge.net/projects/libjpeg-turbo/files/3.0.0/" target="_blank" rel="nofollow" data-saferedirecturl="https://www.google.com/url?hl=en-US&amp;q=https://sourceforge.net/projects/libjpeg-turbo/files/3.0.0/&amp;source=gmail&amp;ust=1688565604346000&amp;usg=AOvVaw1uMIgkA-mX0Kyng9Jm0hyS">https://sourceforge.net/projects/libjpeg-turbo/files/3.0.0/</a></p><p>
Change log is here:
<br><a href="https://github.com/libjpeg-turbo/libjpeg-turbo/releases/tag/3.0.0" target="_blank" rel="nofollow" data-saferedirecturl="https://www.google.com/url?hl=en-US&amp;q=https://github.com/libjpeg-turbo/libjpeg-turbo/releases/tag/3.0.0&amp;source=gmail&amp;ust=1688565604347000&amp;usg=AOvVaw2GXGHP0hW7w3Y8sL7P5MWh">https://github.com/libjpeg-turbo/libjpeg-turbo/releases/tag/3.0.0</a></p><p>
Sorry for the delay, the reasons for which were expressed in previous 
<br>emails 
<br>(<a href="https://groups.google.com/g/libjpeg-turbo-announce/c/zXCK0qw1pIE/m/yMLo__OuAAAJ" target="_blank" rel="nofollow" data-saferedirecturl="https://www.google.com/url?hl=en-US&amp;q=https://groups.google.com/g/libjpeg-turbo-announce/c/zXCK0qw1pIE/m/yMLo__OuAAAJ&amp;source=gmail&amp;ust=1688565604347000&amp;usg=AOvVaw27CfQu_N8aKruqGkcsHDTs">https://groups.google.com/g/libjpeg-turbo-announce/c/zXCK0qw1pIE/m/yMLo__OuAAAJ</a>). 
<br>  SignPath is still having issues with their upstream CA, so the Windows 
<br>installers for libjpeg-turbo 3.0.0 are temporarily unsigned until those 
<br>issues can be resolved.  Ultimately, however, the delay produced a more 
<br>stable 3.0.0 release, since most of the bug reports against 3.0 beta 
<br>were filed after the beta cycle was supposed to have ended.
</p><p>
On that subject, I want to remind everyone that, while I do my best to 
<br>maintain this project with the highest possible quality standards and 
<br>using industry best practices, I cannot test for every possible usage 
<br>scenario.  The three-month beta testing phase is intended to allow the 
<br>community ample time to thoroughly test a new release series.  *Please* 
<br>use that time to test the new release series rather than waiting until 
<br>after the .0 release!
</p><p>
Why there may never be a libjpeg-turbo 3.1
<br>------------------------------------------
</p><p>
I will continue to fix bugs in libjpeg-turbo and issue bug-fix releases 
<br>in the 3.0.x release series, but there will not be a libjpeg-turbo 3.1 
<br>release series *unless* this project can secure more general funding. 
<br>As it stands, libjpeg-turbo only has general funding for about 8-10 
<br>hours of labor per month.  Finishing the 3.0 beta release required 
<br>borrowing against all expected general funding for 2023, and fixing all 
<br>of the 3.0 post-beta bugs required borrowing against all expected 
<br>general funding through September of 2024.  If things continue apace, 
<br>then libjpeg-turbo is effectively in "maintenance mode".  That means 
<br>that no new features (even minor ones) can be considered, and tech 
<br>support will be limited, for at least the next 15 months.
</p><p>
I maintain three open source projects for a living.  Those projects have 
<br>saved companies many millions of dollars in labor and IT costs, but I 
<br>take home less pay than that of a typical starting teacher.  (For those 
<br>outside of the U.S., a starting teacher's salary is a rhetorical 
<br>benchmark for very low pay.  We criminally underfund education here just 
<br>like we criminally underfund open source development.)  What I earn 
<br>through independent open source development is about 20-25% of what my 
<br>skills would be worth to a corporate employer, and I have turned down 
<br>numerous offers from such employers over the years in order to continue 
<br>working on these OSS projects full-time.  I don't expect to get rich 
<br>from open source development, but it is also unfair for organizations to 
<br>profit handsomely from my work while I am expected to do that work for free.
</p><p>
Because the majority of my income is from VirtualGL and TurboVNC, 
<br>uncompensated labor on libjpeg-turbo forces me to steal time away from 
<br>those more lucrative projects.  Thus, I simply can't eat labor cost on 
<br>libjpeg-turbo anymore.  (I ate hundreds of thousands of dollars' worth 
<br>of it from 2010-2018, but when the libjpeg-turbo 2.0 release caused me 
<br>to go into debt in 2018, I had to stop.)  However, major releases still 
<br>require a lot of general labor.  Because the project is so high-profile 
<br>(used by literally billions of people every day through major web 
<br>browsers, operating systems, and image viewers/editors) and is an 
<br>ISO/ITU-T reference implementation, it undergoes intense scrutiny. 
<br>Unfortunately, that scrutiny typically lags the development of new 
<br>features by enough time that specific funding is no longer available to 
<br>fix unanticipated bugs in the new features.  Thus, it has become 
<br>increasingly difficult to estimate the labor costs of new features 
<br>upfront.  In order to adequately cushion against unforeseen bugs, I 
<br>would have to grossly overestimate every new feature to the point that 
<br>no one would be willing to fund the feature.  Instead, I have had to 
<br>accept the risk of unforeseen bugs in order to keep libjpeg-turbo moving 
<br>forward, and that has forced me to perform many hours of general labor 
<br>on the run-up to every new release series.  The companies that have 
<br>partially (but unfortunately not fully) funded each new release series 
<br>have pressured me to put out the .0 releases in a timely manner, so that 
<br>has left me with no choice but to borrow against expected future 
<br>funding.  Specific to 3.0, I had to spend more than 70 uncompensated 
<br>hours fixing bugs discovered in the beta release.  Most of those hours 
<br>were spent fixing bugs in the lossless JPEG feature, but I also spent a 
<br>significant amount of time fixing bugs in the partial image 
<br>decompression and RGB565 features (both of which were integrated to 
<br>support Android and both of which have required me to eat the cost of 
<br>bug fixes or beg for money a handful of times since they were integrated.)
</p><p>
This project has only been kept alive because of the libjpeg-turbo 
<br>General Fund, which is funded by Cendio AB and Crimson Vista and your ad 
<br>hoc donations, as well as a few large ad hoc donations from Google. 
<br>However, the current General Fund is only enough to pay for general 
<br>project maintenance and support.  To keep libjpeg-turbo moving forward 
<br>in any meaningful way, including providing community support, 
<br>integrating or implementing minor features, supporting popular new 
<br>platforms, etc. requires more general funding.  To keep libjpeg-turbo 
<br>moving forward in a more proactive/progressive way, including expanding 
<br>the coverage of the JPEG spec (3.0 essentially expands our coverage of 
<br>the JPEG spec by a factor of five), expanding SIMD coverage to new 
<br>algorithms or instruction sets or CPU architectures, supporting less 
<br>popular new platforms, improving the APIs, hardening security, improving 
<br>fuzzer coverage, enhancing the build system, improving automation, etc. 
<br>requires even more general funding.  Essentially I have been expected to 
<br>keep libjpeg-turbo moving forward in a proactive/progressive way, but 
<br>the amount of general funding only allows for maintenance mode.  In the 
<br>best case, that puts me in the position of begging for funding on a 
<br>regular basis, which distracts from meaningful open source development. 
<br>In the worst case (where we are now), that puts me in the position of 
<br>stalling the project for potentially more than a year until funding can 
<br>catch up to the labor I've already contributed.  It just isn't working, 
<br>and I don't know how to fix it.  It's ironic that the most 
<br>popular/ubiquitous open source project I maintain (by at least four or 
<br>five orders of magnitude) is much more difficult to fund than the 
<br>others.  Maybe a JPEG codec isn't "sexy" enough?  Maybe people take it 
<br>for granted because the complexity of it is hidden behind higher-level 
<br>interfaces and applications?  Still, though, the organizations that 
<br>develop those higher-level interfaces and applications should not be 
<br>taking libjpeg-turbo for granted, particularly when most of the recent 
<br>issues I was expected to fix for free were security-related.
</p><p>
I have expressed in the past that the business model necessitated by 
<br>independent open source development may not be the best fit for a 
<br>critical infrastructure project such as libjpeg-turbo.  Thus, I am open 
<br>to acquisition by a larger organization, if that organization is both 
<br>O/S-agnostic and CPU-agnostic and has a vested interest in both the 
<br>survival and the openness of libjpeg-turbo.  However, I also don't 
<br>expect such an offer to ever materialize.  I have built significant 
<br>value in libjpeg-turbo-- including its reputation, its ubiquity, and its 
<br>user community-- over the past 13 years, but it is obviously not a cash 
<br>cow.  Still, though, unless I can secure enough general funding to move 
<br>the project forward in a meaningful way, the only other options are 
<br>acquisition (however unlikely) or putting the project into maintenance 
<br>mode for the foreseeable future.  The latter is where we are now.
</p><p>
How can you help?  If every individual developer who used libjpeg-turbo 
<br>on a regular basis donated just $5-10/month to the project through 
<br>GitHub Sponsors (<a href="https://github.com/sponsors/libjpeg-turbo" target="_blank" rel="nofollow" data-saferedirecturl="https://www.google.com/url?hl=en-US&amp;q=https://github.com/sponsors/libjpeg-turbo&amp;source=gmail&amp;ust=1688565604347000&amp;usg=AOvVaw3jbm3wa_QqbfwzSb_bOlOU">https://github.com/sponsors/libjpeg-turbo</a>), we'd have a 
<br>healthy amount of general funding.  But that requires everyone to take 
<br>responsibility for the health of this project, not to rely on the few 
<br>corporate benefactors that have kept libjpeg-turbo on life support for 
<br>the past five years.
</p><p>
DRC
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Lone Banana Problem in AI (121 pts)]]></title>
            <link>https://www.digital-science.com/tldr/article/the-lone-banana-problem-or-the-new-programming-speaking-ai/</link>
            <guid>36582937</guid>
            <pubDate>Tue, 04 Jul 2023 06:26:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.digital-science.com/tldr/article/the-lone-banana-problem-or-the-new-programming-speaking-ai/">https://www.digital-science.com/tldr/article/the-lone-banana-problem-or-the-new-programming-speaking-ai/</a>, See on <a href="https://news.ycombinator.com/item?id=36582937">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-63721">
                    <div>
                        
<figure><picture decoding="async">
<source type="image/webp" srcset="https://www.digital-science.com/wp-content/uploads/2023/06/image1-crop-1024x512.jpg.webp 1024w, https://www.digital-science.com/wp-content/uploads/2023/06/image1-crop-300x150.jpg.webp 300w, https://www.digital-science.com/wp-content/uploads/2023/06/image1-crop-768x384.jpg.webp 768w, https://www.digital-science.com/wp-content/uploads/2023/06/image1-crop.jpg.webp 1378w" sizes="(max-width: 1024px) 100vw, 1024px">
<img decoding="async" width="1024" height="512" src="https://www.digital-science.com/wp-content/uploads/2023/06/image1-crop-1024x512.jpg" alt="" srcset="https://www.digital-science.com/wp-content/uploads/2023/06/image1-crop-1024x512.jpg 1024w, https://www.digital-science.com/wp-content/uploads/2023/06/image1-crop-300x150.jpg 300w, https://www.digital-science.com/wp-content/uploads/2023/06/image1-crop-768x384.jpg 768w, https://www.digital-science.com/wp-content/uploads/2023/06/image1-crop.jpg 1378w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<blockquote>
<p>The subtle biases of LLM training are difficult to detect but can manifest themselves in unexpected places. I call this the ‘Lone Banana Problem’ of AI.</p>
<cite>Daniel Hook, CEO, Digital Science</cite></blockquote>



<p>Think of all the tools that the information age has brought us…</p>



<p>Think of all the people whose diseases have become manageable or which have been cured. Think of all the economic benefits that have been generated through increased productivity. Think of all the routes that we have to express ourselves and share our creativity. Think of all the skills that were needed to power that revolution – the hardware engineering, and the software engineering – the development of whole new fields of knowledge and understanding.&nbsp;</p>



<p>Then think of all the wealth disparity that has been introduced into our world.&nbsp; Think of the social anxiety of always being online.&nbsp; Think of the undermining of our democratic institutions.</p>



<p>The effects of new technology are seldom either solely positive or solely negative and, as such, there is a responsibility that sits with those that develop technology to consider how it will be used.&nbsp; Underlying that responsibility sits a need to deeply understand technology.&nbsp; The recent rise of Large Language Models (LLMs) and its rapid adoption begs many questions about whether we understand the technology and whether we understand how it will impact us at a cultural, societal, or economic level.</p>



<p>It is clear that the experience that we have of programming and existing technologies will give way to different skills with this new technology.&nbsp; The command of a programmer mindset and skill with languages such as C++ and Python will give way to the need to understand a dynamic meta language that is drawn from the patterns of online human interaction.&nbsp; The new skill for the present technology is “speaking” language in the way that AI determines that language to be spoken from the inputs that it has consumed.</p>



<p>In that context, knowing that LLMs are not producing something new or creative, but rather that they are producing (or reproducing) the statistical average of the inputs that they have consumed in the context of the question they have been asked is important. Understanding that AIs do not understand us the way that we think they do is an important step in taking responsibility for developing on top of these technologies when creating new tools.</p>



<p>What follows attempts to illustrate this point.</p>



<h3>Going Bananas</h3>



<p>When I have written before on this topic I have noted that it is not these large biases that are concerning to me, rather it is the subtle biases that are difficult to detect that I think should be of more concern. I found recently what I regard to be an excellent illustration of the phrase that I have chosen to describe the output of AI. I call this the ‘Lone Banana Problem’.</p>



<p>Bananas are attractive fruits, they have a jolly colour, and they taste great. I have had a running joke for several years with a friend of mine that due to his love of bananas he should use them more significantly in the branding of his business. When I signed up to <a href="https://midjourney-app.com/">Midjourney</a> I saw the perfect opportunity to generate an idealised banana image for him to use. I started with a simple prompt: “A single banana casting a shadow on a grey background”. The result is shown in Figure 1.</p>



<figure><picture decoding="async" loading="lazy">
<source type="image/webp" srcset="https://www.digital-science.com/wp-content/uploads/2023/06/image1-1024x1024.jpg.webp 1024w, https://www.digital-science.com/wp-content/uploads/2023/06/image1-300x300.jpg.webp 300w, https://www.digital-science.com/wp-content/uploads/2023/06/image1-150x150.jpg.webp 150w, https://www.digital-science.com/wp-content/uploads/2023/06/image1-768x768.jpg.webp 768w, https://www.digital-science.com/wp-content/uploads/2023/06/image1.jpg.webp 1378w" sizes="(max-width: 1024px) 100vw, 1024px">
<img decoding="async" loading="lazy" width="1024" height="1024" src="https://www.digital-science.com/wp-content/uploads/2023/06/image1-1024x1024.jpg" alt="" srcset="https://www.digital-science.com/wp-content/uploads/2023/06/image1-1024x1024.jpg 1024w, https://www.digital-science.com/wp-content/uploads/2023/06/image1-300x300.jpg 300w, https://www.digital-science.com/wp-content/uploads/2023/06/image1-150x150.jpg 150w, https://www.digital-science.com/wp-content/uploads/2023/06/image1-768x768.jpg 768w, https://www.digital-science.com/wp-content/uploads/2023/06/image1.jpg 1378w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
<figcaption><em>1: Four initial outputs generated by Midjourney in response to the prompt “A single banana casting a shadow on a grey background”.</em></figcaption></figure>



<p>Now, the more astute amongst you may notice an issue with the outputs that Midjourney has produced in Figure 1. While the bananas are beautiful and look extremely tasty in their artistic pose casting their shadow on the grey background, you may notice that I asked for a single solitary banana, on its own, but none of the variants that I received contained just one banana. Of course, I thought, the error must be mine, I clearly must not have been sufficiently precise in my prompt. So, I tried variants – from “a perfect ripe banana on a pure grey background casting a light shadow, hyperrealistic”, to the more specific “a single perfect ripe banana alone on a pure grey background casting a light shadow, hyperrealistic photographic”, and even to the emphatic (even pleading) “ONE perfect banana alone on a uniform light grey surface, shot from above, hyperrealistic photographic”.</p>



<h3>The Invisible Monkey Problem?</h3>



<p>I mentioned this challenge to a friend of mine who has much more of a programmer’s brain than I. He asked me if I tried to get Midjourney to render a monkey with a banana and then asking Midjourney to imagine that the monkey was invisible. (You see what I mean about a programmer’s brain?) He (my friend, not the monkey) was surmising that the data around monkeys holding bananas, or bananas in a different context might yield different results. The depressing result is included in Figure 2.</p>



<figure><picture decoding="async" loading="lazy">
<source type="image/webp" srcset="https://www.digital-science.com/wp-content/uploads/2023/06/image2.png.webp 1024w, https://www.digital-science.com/wp-content/uploads/2023/06/image2-300x300.png.webp 300w, https://www.digital-science.com/wp-content/uploads/2023/06/image2-150x150.png.webp 150w, https://www.digital-science.com/wp-content/uploads/2023/06/image2-768x768.png.webp 768w" sizes="(max-width: 1024px) 100vw, 1024px">
<img decoding="async" loading="lazy" width="1024" height="1024" src="https://www.digital-science.com/wp-content/uploads/2023/06/image2.png" alt="" srcset="https://www.digital-science.com/wp-content/uploads/2023/06/image2.png 1024w, https://www.digital-science.com/wp-content/uploads/2023/06/image2-300x300.png 300w, https://www.digital-science.com/wp-content/uploads/2023/06/image2-150x150.png 150w, https://www.digital-science.com/wp-content/uploads/2023/06/image2-768x768.png 768w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
<figcaption><em>Figure 2: One of the outputs of&nbsp; the experimental prompt: “An invisible monkey with a single banana”.</em></figcaption></figure>



<p>You are quite right, that monkey (in Figure 2) should look sheepish! Firstly, he should be invisible and is conspicuous by well…his conspicuousness.&nbsp; Secondly, he is holding not <em>one</em> but <em>two</em> bananas!&nbsp; The results were the same with aliens holding bananas and other animals.&nbsp; Slightly bizarrely, several of the monkeys ended up wearing bananas or being banana-coloured.</p>



<p>Every image that I asked Midjourney to produce contained 2 (or more) bananas seemingly no matter how I asked.</p>



<p>I began to suspect that bananas, like quarks in the Standard Model of physics, might not naturally occur on their own as through some obscure binding principle they might only occur in pairs. I checked the kitchen. Experimental evidence suggested that bananas can definitely appear individually. Phew! But, the fact remained that I couldn’t get an individual banana as an output from the AI. So, what was going on?</p>



<h3>Bias Training</h3>



<p>One of the problems of generative AI is that understanding what is going on inside the machine’s brain is almost impossible. There are interesting approaches such as <a href="https://www.quantamagazine.org/been-kim-is-building-a-translator-for-artificial-intelligence-20190110/">TCAV</a> that attempt to give us more of an insight, but as with a human brain, we don’t fully understand the process that goes on inside a deep learning algorithm.&nbsp;&nbsp;</p>



<p>Testing and understanding the outputs for a given input is critical when deciding how this type of technology can be applied in real-world applications. Anyone who has studied chaos theory or who has heard of the butterfly effect will know that naturally complex systems are often highly sensitive to initial conditions. The Large Language Models (LLMs) that we are building have highly complex inputs in the form of vast amounts of data that are used to train these intelligences. However, like the Mandelbrot set and other complex-looking fractals, the rules that are then applied to the data to do the training are deceptively simple.</p>



<p>The bias to two bananas in a picture is, I believe, an example of a subtle bias (OK, it’s not <em>that</em> subtle, but it is more subtle than many of the more concerning news-grabbing biases that we regularly read about). A naïve explanation may be that in the training dataset there have been many pictures of bananas added to Midjourney’s database that have been labelled “banana” but not labelled “two bananas”. It may also be that Midjourney has never seen an individual banana, so it doesn’t know that a single banana is possible.</p>



<p>The danger here is that due to the convincing nature of our interactions with AIs, we begin to believe that they understand the world in the way that we do.&nbsp; They don’t.&nbsp; AIs, at their current level of development, don’t perceive objects in the way that we do – they understand commonly occurring patterns.&nbsp; Their reality is fundamentally different to ours – it is not born in the physical world but in a logical world. Certainly, as successive generations of AI develop, it is easy for us to have interactions with them that suggest that they do understand. Some of the results of textual analysis that I’ve done with ChatGPT definitely give the impression of understanding. And yet, without a sense of the physical world, an AI has a problem with the concept of a single banana.</p>



<p>Of course, the point of this article is not to be vexed about the lack of individual bananas in the AI’s virtual world. It is to point out that even though this technology is developing rapidly and that the output is impressive, there are still gaps and, while they are not always immediately notable, they are not small. Ethical and responsible use of AI is easy to forget when faced with the speed of innovation and the constant press hype around AI. The lone banana problem is, in some sense, a less scary version of HAL the AI in Arthur C. Clarke’s 2001 where instead of killing the crew of the Odyssey, I have merely discovered a virtual universe in which bananas only appear in pairs.</p>



<p>While humans are amazing pattern matchers, that skill is augmented by common sense (in many but not all cases), context and an evolved and subtle understanding of the physical world around us. AIs don’t yet have those augmentations – they are pure pattern matching power. And hence, they are only as good as the data that we input into the training set and hence can be no more than the statistical average of those inputs. In the lone banana problem, the statistics suggested that bananas only appear in twos (or more) and so the AI could not imagine a single banana, because the data and parametric tuning that had gone on didn’t allow it to consider that approach, on average.</p>



<h3>Existential Questions</h3>



<p>But this line of thinking does beg certain uncomfortable questions such as, is human intelligence just the result of pattern matching in the context of an enriched relationship with a physical world? Is human morality simply the result of a pattern matching type feature with a sense of its own mortality? Or, is there something deeper going on? Is inspiration or intuition something that an AI will be able to master either through its learnt experiences or a richer relationship with the physical world? In a philosophical sense, what is creativity? And, does human creativity differ fundamentally from that of machine creativity?&nbsp;</p>



<p>Certainly human creativity has limits (and, perhaps paradoxically, appears to become more limited with age – precisely as we have been exposed to more experiences). Some of those limits are, for example, the amount of data that we can perceive and process. Others appear in the extent to which we can imagine beyond our everyday experiences. Machine creativity appears to have different limits – not ones of data processing, but rather limits on what can be perceived to be relevant or important, and similar to human experience, on imagining beyond experience. Despite the alluring implication of the command “\imagine” used to initiate a new prompt when getting Midjourney to create a set of images, to what extent is the AI able to imagine beyond the patterns that have been fed to it?</p>



<p>It also points to a deeper issue of the underlying nature of this technology. When programming became a more mainstream job in the 1980s and people started studying for computer science degrees, it was noted that programming required a certain way of thinking.&nbsp; It is the same for prompt engineering, but the type of thinking behind prompt engineering is not the same as for programming. Prompt engineering requires a deep understanding of language and not only that, a deep understanding of how a large language model understands language. In the same way that deep learning algorithms have a deep understanding of chess and <a href="https://en.wikipedia.org/wiki/Go_(game)">Go</a> and consequently make surprising moves due to their perception of the game, the same will be true of large language models and their perception of the world. Their use of language and interpretation will be considerably more nuanced than ours, loaded with a myriad of cultural references that none of us can possibly have assimilated.</p>



<p>While I appreciate that AIs are a good deal more complex than my simple example shows, and indeed my example may even just be a facet of clumsy prompt engineering, it still demonstrates that you have to be incredibly careful about your assumptions when using AI. What it tells you may not be what you think it is telling you and it may not be for the reasons that you think either.</p>



<p>At Digital Science, we believe that we have a responsibility to ensure that the technologies that we release are well tested and well understood. The use cases where we deploy AI have to be appropriate for the level at which we know the AI can perform and any functionality needs to come with a “health warning” so that people know what they need to look for – when they can trust an AI and when they shouldn’t.</p>



<h3>Postlog</h3>



<p>After two weeks in despair of ever finding a lone banana, I tried a different style of prompt in Midjourney (either it has learnt some new tricks, or I might be getting better at “prompt thinking”). The prompt “A single banana on its own casting a shadow on a grey background” yielded Figure 3.</p>



<p>This shows two things: Firstly, that initial conditions, by which I mean the prompt given can be very sensitive – the difference between the phrases “A single banana casting a shadow on a grey background” and “A single banana on its own casting a shadow on a grey background” is not large, either in the semantics or the words used. However, the outcome is significantly different in its level of accuracy.&nbsp; Secondly, even with this improved prompt formulation coupled with whatever upgrades that may have been implemented by the Midjourney team in the prior two weeks, there is still one output that contains two bananas, and if you look closely, one attempted banana is trying to split itself in two!!</p>



<figure><picture decoding="async" loading="lazy">
<source type="image/webp" srcset="https://www.digital-science.com/wp-content/uploads/2023/06/image3-1024x1024.jpg.webp 1024w, https://www.digital-science.com/wp-content/uploads/2023/06/image3-300x300.jpg.webp 300w, https://www.digital-science.com/wp-content/uploads/2023/06/image3-150x150.jpg.webp 150w, https://www.digital-science.com/wp-content/uploads/2023/06/image3-768x768.jpg.webp 768w, https://www.digital-science.com/wp-content/uploads/2023/06/image3.jpg.webp 1378w" sizes="(max-width: 1024px) 100vw, 1024px">
<img decoding="async" loading="lazy" width="1024" height="1024" src="https://www.digital-science.com/wp-content/uploads/2023/06/image3-1024x1024.jpg" alt="" srcset="https://www.digital-science.com/wp-content/uploads/2023/06/image3-1024x1024.jpg 1024w, https://www.digital-science.com/wp-content/uploads/2023/06/image3-300x300.jpg 300w, https://www.digital-science.com/wp-content/uploads/2023/06/image3-150x150.jpg 150w, https://www.digital-science.com/wp-content/uploads/2023/06/image3-768x768.jpg 768w, https://www.digital-science.com/wp-content/uploads/2023/06/image3.jpg 1378w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
<figcaption><em>Figure 3: Four initial outputs generated by Midjourney in response to the prompt “A single banana on its own casting a shadow on a grey background”.</em></figcaption></figure>

                    </div>
                </article></div>]]></description>
        </item>
    </channel>
</rss>