<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 26 Apr 2024 02:00:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Jeff Lawson Buys The Onion (103 pts)]]></title>
            <link>https://www.nytimes.com/2024/04/25/business/media/the-onion-sold.html</link>
            <guid>40164199</guid>
            <pubDate>Thu, 25 Apr 2024 23:11:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/04/25/business/media/the-onion-sold.html">https://www.nytimes.com/2024/04/25/business/media/the-onion-sold.html</a>, See on <a href="https://news.ycombinator.com/item?id=40164199">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/04/25/business/media/the-onion-sold.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Open Sourcing DOS 4 (269 pts)]]></title>
            <link>https://www.hanselman.com/blog/open-sourcing-dos-4</link>
            <guid>40163405</guid>
            <pubDate>Thu, 25 Apr 2024 21:42:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.hanselman.com/blog/open-sourcing-dos-4">https://www.hanselman.com/blog/open-sourcing-dos-4</a>, See on <a href="https://news.ycombinator.com/item?id=40163405">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
        <section>
            
            <p><img title="Beta DOS Disks" alt="Beta DOS Disks" src="https://hanselmanblogcontent.azureedge.net/Windows-Live-Writer/Open-Sourcing-DOS-4_E712/clip_image002_5b6e1c02-95d8-4ee1-87af-ca53a8b0bd56.png" width="500" height="342"><em>See <a href="https://cloudblogs.microsoft.com/opensource/2024/04/25/open-sourcing-ms-dos-4-0/">the canonical version of this blog post at the Microsoft Open Source Blog</a>!</em>  </p><p>Ten years ago, <a href="https://devblogs.microsoft.com/commandline/re-open-sourcing-ms-dos-1-25-and-2-0/">Microsoft released the source for MS-DOS 1.25 and 2.0</a> to the Computer History Museum, and then <a href="https://github.com/microsoft/MS-DOS">later republished them</a> for reference purposes. This code holds an important place in history and is a fascinating read of an operating system that was written entirely in 8086 assembly code nearly 45 years ago. </p> <p>Today, in partnership with IBM and in the spirit of open innovation, we're releasing the source code to MS-DOS 4.00 under the MIT license. There's a somewhat complex and fascinating history behind the 4.0 versions of DOS, as Microsoft partnered with IBM for portions of the code but also created a branch of DOS called Multitasking DOS that did not see a wide release. </p> <p><a title="https://github.com/microsoft/MS-DOS?WT.mc_id=-blog-scottha" href="https://github.com/microsoft/MS-DOS?WT.mc_id=-blog-scottha"><strong>https://github.com/microsoft/MS-DOS</strong></a></p> <p>A young English researcher named <a href="https://starfrost.net/blog/001-mdos4-part-1/">Connor "Starfrost" Hyde</a> recently corresponded with former Microsoft Chief Technical Officer Ray Ozzie about some of the software in his collection. Amongst the floppies, Ray found unreleased beta binaries of DOS 4.0 that he was sent while he was at Lotus. Starfrost reached out to the Microsoft Open Source Programs Office (OSPO) to explore releasing DOS 4 source, as he is working on documenting the relationship between DOS 4, MT-DOS, and what would eventually become OS/2. Some later versions of these Multitasking DOS binaries can be found around the internet, but these new Ozzie beta binaries appear to be much earlier, unreleased, and also include the ibmbio.com source.&nbsp; </p> <p>Scott Hanselman, with the help of internet archivist and enthusiast Jeff Sponaugle, has imaged these original disks and carefully scanned the original printed documents from this "Ozzie Drop". Microsoft, along with our friends at IBM, think this is a fascinating piece of operating system history worth sharing.&nbsp; </p> <p>Jeff Wilcox and OSPO went to the Microsoft Archives, and while they were unable to find the full source code for MT-DOS, they did find MS DOS 4.00, which we're releasing today, alongside these additional beta binaries, PDFs of the documentation, and disk images. We will continue to explore the archives and may update this release if more is discovered.&nbsp; </p> <p>Thank you to Ray Ozzie, Starfrost, Jeff Sponaugle, Larry Osterman, our friends at the IBM OSPO, as well as the makers of such digital archeology software including, but not limited to Greaseweazle, Fluxengine, Aaru Data Preservation Suite, and the HxC Floppy Emulator. Above all, thank you to the original authors of this code, some of whom still work at Microsoft and IBM today! </p> <p>If you'd like to run this software yourself and explore, we have successfully run it directly on an original IBM PC XT, a newer Pentium, and within the open source PCem and 86box emulators.&nbsp; </p>



            <div>
                <div>
                    <h4>About Scott</h4>
                    <div>
                        <p>Scott Hanselman is a former professor, former Chief Architect in finance, now speaker, consultant, father, diabetic, and Microsoft employee. He is a failed stand-up comic, a cornrower, and a book author.</p>
                        <p><a href="https://facebook.com/shanselman"><img src="https://images.hanselman.com/main/icon-fb.png" alt="facebook"></a>
                        <a href="https://twitter.com/shanselman"><img src="https://images.hanselman.com/main/icon-twitter.png" alt="twitter"></a>
                        <a href="http://feeds.hanselman.com/ScottHanselman"><img src="https://images.hanselman.com/main/icon-rss.png" alt="subscribe"></a><br>
                        <a href="http://hanselman.com/about">About</a> &nbsp; <a href="http://www.hanselman.com/newsletter">Newsletter</a>
                    </p></div>
                </div>

                <div>
                    <p><strong>Hosting By</strong><br>
                        <a rel="nofollow" href="https://azure.microsoft.com/free"><img alt="Hosted in an Azure App Service" width="125" height="125" src="https://images.hanselman.com/main/azure-250x250.png"></a>
                    </p>

                </div>
            </div>

            


            

            
        </section>
            



















    

<a name="#comments-start"></a>





    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Judge acquits Backpage co-founder Michael Lacey on most counts (146 pts)]]></title>
            <link>https://reason.com/2024/04/25/judge-acquits-backpage-co-founder-michael-lacey-on-most-counts/</link>
            <guid>40162433</guid>
            <pubDate>Thu, 25 Apr 2024 20:14:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reason.com/2024/04/25/judge-acquits-backpage-co-founder-michael-lacey-on-most-counts/">https://reason.com/2024/04/25/judge-acquits-backpage-co-founder-michael-lacey-on-most-counts/</a>, See on <a href="https://news.ycombinator.com/item?id=40162433">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
																		<article>
	<header>
							<p>
				<a href="https://reason.com/tag/backpage/">Backpage</a>
			</p>
				
		
					<h2>The court found insufficient evidence to sustain 53 of 84 remaining counts against Lacey.</h2>
				<p>
								
				
						<span>|</span>
			<time datetime="2024-04-25T13:06:35-04:00">4.25.2024 1:06 PM</time>
			
</p>
					
										<div>
						<div>
			<picture>
									<source type="image/webp" data-lazy-srcset="https://d2eehagpk5cl65.cloudfront.net/img/c2400x1350-w2400-q80/uploads/2024/04/Screen-Shot-2024-04-25-at-11.49.05-AM-2400x1350.png.webp 2400w,https://d2eehagpk5cl65.cloudfront.net/img/c1200x675-w1200-q80/uploads/2024/04/Screen-Shot-2024-04-25-at-11.49.05-AM-1200x675.png.webp 1200w,https://d2eehagpk5cl65.cloudfront.net/img/c800x450-w800-q80/uploads/2024/04/Screen-Shot-2024-04-25-at-11.49.05-AM-800x450.png.webp 800w,https://d2eehagpk5cl65.cloudfront.net/img/c600x338-w600-q80/uploads/2024/04/Screen-Shot-2024-04-25-at-11.49.05-AM-600x338.png.webp 600w,https://d2eehagpk5cl65.cloudfront.net/img/c331x186-w331-q80/uploads/2024/04/Screen-Shot-2024-04-25-at-11.49.05-AM-331x186.png.webp 331w,https://d2eehagpk5cl65.cloudfront.net/img/c1200x675-w1200-q80/uploads/2024/04/Screen-Shot-2024-04-25-at-11.49.05-AM-1200x675.png.webp 1200w,https://d2eehagpk5cl65.cloudfront.net/img/c1920x1080-w1920-q80/uploads/2024/04/Screen-Shot-2024-04-25-at-11.49.05-AM-1920x1080.png.webp 1920w" sizes="(min-width: 753px) 70vw, (min-width: 1190px) 768px, 100vw">
											<source type="image/jpeg" data-lazy-srcset="https://d2eehagpk5cl65.cloudfront.net/img/c2400x1350-w2400-q80/uploads/2024/04/Screen-Shot-2024-04-25-at-11.49.05-AM-2400x1350.png 2400w,https://d2eehagpk5cl65.cloudfront.net/img/c1200x675-w1200-q80/uploads/2024/04/Screen-Shot-2024-04-25-at-11.49.05-AM-1200x675.png 1200w,https://d2eehagpk5cl65.cloudfront.net/img/c800x450-w800-q80/uploads/2024/04/Screen-Shot-2024-04-25-at-11.49.05-AM-800x450.png 800w,https://d2eehagpk5cl65.cloudfront.net/img/c600x338-w600-q80/uploads/2024/04/Screen-Shot-2024-04-25-at-11.49.05-AM-600x338.png 600w,https://d2eehagpk5cl65.cloudfront.net/img/c331x186-w331-q80/uploads/2024/04/Screen-Shot-2024-04-25-at-11.49.05-AM-331x186.png 331w,https://d2eehagpk5cl65.cloudfront.net/img/c1200x675-w1200-q80/uploads/2024/04/Screen-Shot-2024-04-25-at-11.49.05-AM-1200x675.png 1200w,https://d2eehagpk5cl65.cloudfront.net/img/c1920x1080-w1920-q80/uploads/2024/04/Screen-Shot-2024-04-25-at-11.49.05-AM-1920x1080.png 1920w" sizes="(min-width: 753px) 70vw, (min-width: 1190px) 768px, 100vw">
													<img src="https://d2eehagpk5cl65.cloudfront.net/img/c800x450-w800-q80/uploads/2024/04/Screen-Shot-2024-04-25-at-11.49.05-AM-800x450.png" width="1200" height="675" title="U.S. District Judge Diane Humetewa" alt="U.S. District Judge Diane Humetewa | screenshot from U.S. Courts video" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201200%20675'%3E%3C/svg%3E" data-lazy-src="https://d2eehagpk5cl65.cloudfront.net/img/c800x450-w800-q80/uploads/2024/04/Screen-Shot-2024-04-25-at-11.49.05-AM-800x450.png">
			</picture>
		</div>
							<p><span>
					 (screenshot from U.S. Courts video)				</span>
					</p>
								</div>
							
	</header>
	<div>
							<p>A federal judge has <a href="https://reason.com/wp-content/uploads/2024/04/usa-v-lacey-order-of-acquittal.pdf">acquitted</a> Backpage co-founder Michael Lacey of dozens of counts, including a majority of those on which federal prosecutors planned to retry Lacey later this year. U.S. District Judge Diane Humetewa also acquitted former Backpage executives Jed Brunst and Scott Spear on multiple counts of which they were convicted by a jury last fall.</p> <p>"After viewing the record in the light most favorable to the Government, the Court finds there is insufficient of evidence to support convictions under Counts 19–51 as to Mr. Lacey and Counts 66–99 as to Messrs. Lacey, Brunst, and Spear," concluded Humetewa.</p> <p>In November, <a href="https://reason.com/2023/11/29/the-backpage-defendants-never-stood-a-chance/">a jury found Lacey guilty</a> of just one the 86 counts against him and not guilty of one count as well. The jury was hung on the other 84 counts, including all charges that Lacey actively facilitated prostitution or participated in a conspiracy to facilitate prostitution via the online classifieds site he founded with his longtime newspaper partner James Larkin. (Larkin <a href="https://reason.com/2023/08/02/backpage-publisher-alt-weekly-entrepreneur-and-free-speech-warrior-james-larkin-has-died/">took his own life last summer</a> a few days before the trial was scheduled to begin.)</p> <p>The feds then decided to retry Lacey on those 84 counts, despite the fact that there had already been two trials on the same charges. (The first, in 2021, was <a href="https://reason.com/2021/09/14/biased-testimony-in-backpage-trial-triggers-more-calls-for-a-mistrial/">declared a mistrial</a> after prosecutors and their witnesses couldn't stop talking about sex trafficking despite none of the defendants facing sex trafficking charges.)</p> <p>Now, Humetewa has acquitted Lacey on 53 of the remaining 84 counts against him. Additionally, Humetewa acquitted Spear, former executive vice president of Backpage, of 10 of the counts on which he was found guilty by the jury and acquitted former Chief Financial Officer Brunst of 18 of the counts on which he was convicted.</p> <p>Two of the other defendants were acquitted on all charges by the jury.</p> <p>Lacey, Spear, and Brunst could still be in serious trouble.</p> <p>Lacey is still looking at a retrial later this year on the remaining counts against him, which include one count of conspiracy to violate the federal Travel Act by facilitating prostitution, 17 counts of violating the Travel Act by facilitating prostitution, and several different money laundering counts.</p> <p>And on June 17, Lacey is scheduled to be sentenced on the one count—international concealment of money laundering—on which the jury found him guilty. It comes with a possible sentence of up to 20 years in federal prison. Lacey plans to appeal his conviction on this count, and there seems like a good chance it will be successful, since the money he allegedly "concealed" was reported to the federal government with all the proper paperwork. But he could still face prison time as that appeals process plays out.</p> <p>Brunst is scheduled to be sentenced along with Lacey in June and even with Humetewa's acquittals, he still faces sentencing on 14 counts. And Spear, who is scheduled to be sentenced on July 9, still faces sentencing on 29 counts.</p>						</div>
		
</article>
<nav>
	
		<p>
        <a href="https://reason.com/2024/04/25/greenpeace-crusade-will-blind-and-kill-children/" data-ga-click="true" data-ga-action="Next Article Click" data-ga-label="Greenpeace Crusade Will Blind and Kill Children"><span>NEXT:</span> Greenpeace Crusade Will Blind and Kill Children</a>
    </p>
	
	<span><a rel="tag" href="https://reason.com/tag/backpage/">Backpage</a><a rel="tag" href="https://reason.com/category/nanny-state/prostitution/">Prostitution</a><a rel="tag" href="https://reason.com/category/civil-liberties/free-speech/">Free Speech</a><a rel="tag" href="https://reason.com/tag/first-amendment/">First Amendment</a><a rel="tag" href="https://reason.com/category/criminal-justice/law-enforcement/">Law enforcement</a><a rel="tag" href="https://reason.com/tag/advertising/">Advertising</a><a rel="tag" href="https://reason.com/category/nanny-state/sex-work/">Sex Work</a><a rel="tag" href="https://reason.com/category/immigration/trafficking/">Sex Trafficking</a><a rel="tag" href="https://reason.com/tag/money-laundering/">Money Laundering</a><a rel="tag" href="https://reason.com/tag/federal-courts/">Federal Courts</a><a rel="tag" href="https://reason.com/tag/department-of-justice/">Department of Justice</a><a rel="tag" href="https://reason.com/category/criminal-justice/">Criminal Justice</a></span>			
					</nav>
				
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Earning Q1 2024 [pdf] (117 pts)]]></title>
            <link>https://abc.xyz/assets/91/b3/3f9213d14ce3ae27e1038e01a0e0/2024q1-alphabet-earnings-release-pdf.pdf</link>
            <guid>40162354</guid>
            <pubDate>Thu, 25 Apr 2024 20:07:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://abc.xyz/assets/91/b3/3f9213d14ce3ae27e1038e01a0e0/2024q1-alphabet-earnings-release-pdf.pdf">https://abc.xyz/assets/91/b3/3f9213d14ce3ae27e1038e01a0e0/2024q1-alphabet-earnings-release-pdf.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=40162354">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Asian American women are getting lung cancer despite never smoking (126 pts)]]></title>
            <link>https://www.nbcnews.com/news/us-news/asian-american-women-lung-cancer-rcna138895</link>
            <guid>40161811</guid>
            <pubDate>Thu, 25 Apr 2024 19:16:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nbcnews.com/news/us-news/asian-american-women-lung-cancer-rcna138895">https://www.nbcnews.com/news/us-news/asian-american-women-lung-cancer-rcna138895</a>, See on <a href="https://news.ycombinator.com/item?id=40161811">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>It was fall 2021, and Aurora Lucas had a stubborn cough and chest pain. However, her doctors dismissed the symptoms, telling her to drink hot water and honey.&nbsp;</p><p>After three months of hospital visits, Lucas was diagnosed with stage 3 lung cancer at 28 years old, despite never having smoked. Lucas, who is Filipina American, represents a concerning trend for researchers.&nbsp;</p><p>According to a California study, lung cancer rates are dropping for every group except <a href="https://www.ajmc.com/view/digging-into-the-increasing-lung-cancer-rate-for-female-asian-never-smokers-dr-jeffrey-velotta" target="_blank">nonsmoking Asian American women</a> — for whom they’re actually increasing <a href="https://pubmed.ncbi.nlm.nih.gov/36934804/" target="_blank">by 2% per year</a>.&nbsp;</p><p>While lung cancer is traditionally associated with cigarettes, as many as 20% of U.S. cases happen in never-smokers every year. Among Asian American women who have lung cancer, more than <a href="https://pubmed.ncbi.nlm.nih.gov/34001502/" target="_blank">50%</a> have never smoked. And for Chinese and Indian American women who have lung cancer, the nonsmoking percentage rises to 80% to 90%.&nbsp;</p><p>Scientists are baffled by this pattern, and it has led to a recent surge of research. In two ongoing blockbuster studies at the University of California, San Francisco, and New York University, they’ve been searching for reasons why Asian American women are at especially high risk and for ways to catch their tumors earlier.</p><p>“It’s such a high rate; there <em>has</em> to be an explanation there,” Lucas said.</p><p>In May, the NYU researchers shared <a href="https://ascopubs.org/doi/abs/10.1200/JCO.2023.41.16_suppl.8510" target="_blank">preliminary data</a> at the American Society of Clinical Oncology conference showing that lung cancer screening in nonsmoking Asian American women works as well, if not better, than screening elderly, mostly white smokers. </p><p>Now, doctors are raising the alarm about increasing numbers of lung cancer cases in this community and working to reform the screening guidelines to better include Asian American women.</p><p>“As an Asian woman, I was taught to be quiet,” Lucas said. “I had a high respect for doctors and medical staff, so I would never really question what they were telling me,” even when they didn’t understand what was wrong.</p><h2><strong>Understanding the risk factors</strong></h2><p>UCSF epidemiologist Scarlett Gomez was born in Taiwan before she immigrated to the U.S. at 7 years old, her parents working in Chinese restaurants in Washington state. But that also meant they were continuously, unknowingly exposed to <a href="https://link.springer.com/article/10.1007/s13530-022-00163-4#:~:text=At%20high%20temperature%2C%20COF%20produced,meats%20and%20vegetables%20were%20studied." target="_blank">toxic</a> cooking oil fumes. </p><p>“Like many immigrant families, my parents were working in industries that were beneath their training,” Gomez said. “That was the job that they had to do to make it here.”</p><p>To date, studies of female nonsmokers in Asia have identified risk factors <a href="https://tlcr.amegroups.org/article/view/21745/17752" target="_blank">such</a> <a href="https://www.sciencedirect.com/science/article/pii/S095461111300320X" target="_blank">as</a> cooking oil fumes, secondhand smoke, air pollution and indoor heating with coal, but no research has focused on Asian <em>American</em> women, Gomez said.&nbsp;</p><p>Nevertheless, there’s probably some overlap. For example, a 2019 study <a href="https://www.ucsusa.org/sites/default/files/attach/2019/06/Inequitable-Exposure-to-Vehicle-Pollution-Northeast-Mid-Atlantic-Region.pdf" target="_blank">found</a> that Asian Americans breathe in 73% more tiny pollution particles than white Americans, most likely because of <a href="https://www.science.org/doi/10.1126/sciadv.abf4491" target="_blank">greater exposure</a> to construction, industry and vehicle emissions where they live. </p><p>Air pollution may also lead to <a href="https://www.nature.com/articles/s41586-023-05874-3" target="_blank">genetic changes</a> such that Asian patients have some of the <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4132036/" target="_blank">highest rates</a> of the cancer-causing epidermal growth factor receptor mutation, which leads healthy cells to divide uncontrollably and grow into tumors.&nbsp;</p><p>“I hope we’ll see more studies to address these unusual, emerging disparities among Asian Americans that we previously haven’t paid attention to,” Gomez said.</p><p>Given the lack of clarity, Gomez and Iona Cheng, a fellow epidemiologist at UCSF, launched the <a href="https://fansstudy.ucsf.edu/home" target="_blank">Female Asian Never Smokers, or FANS, study</a> in 2021. It’s a case-control study, in which the team is studying nonsmoking Asian American women who were either recently diagnosed with lung cancer (the cases) or who never had lung cancer (the controls).&nbsp;</p><p>Although the two groups are matched in terms of ethnicity and age, the researchers hope to find some differences in genetics, as assessed by saliva samples, and environmental exposure, determined through surveys asking about people’s pasts. “The whole goal of this study is to identify risk factors,” Gomez said.</p><p>However, FANS can’t show cause-and-effect relationships, said Dr. Latha Palaniappan, a physician at Stanford University, who isn’t involved with the study. </p><p>For one, women with lung cancer may be more likely to remember their exposure to chemicals and toxins than women without lung cancer because they’ve been thinking harder about their risk factors —&nbsp;something known as “<a href="https://pubmed.ncbi.nlm.nih.gov/28846237/" target="_blank">recall bias</a>.” </p><p>Still, Palaniappan emphasized FANS’ groundbreaking nature, because “we can definitely understand associations, and the study can give us an idea for more rigorous analyses going forward.”</p><h2><strong>Making lung cancer screening more equitable</strong></h2><p>At NYU, Dr. Elaine Shum, an oncologist, has seen dozens of nonsmoking Asian American women with lung cancer, many with stage 4 disease. And it’s always frustrating: Lung cancer screening, via the low-dose CT scan, could have helped those women find their tumors earlier, at more treatable stages.&nbsp;</p><p>But insurance plans typically cover screening only for <a href="https://www.uspreventiveservicestaskforce.org/uspstf/recommendation/lung-cancer-screening" target="_blank">people ages 50 to 80 with heavy smoking histories</a> — all but excluding Asian American women. And the recommendations were based on the National Lung Screening Trial, a <a href="https://www.nejm.org/doi/full/10.1056/nejmoa1102873" target="_blank">clinical trial</a> of 53,000 elderly smokers, over 90% of whom were white.</p><p>So Shum started her own clinical trial in 2021, giving lung cancer screening to 1,000 never-smoking Asian American women. Her <a href="https://ascopubs.org/doi/abs/10.1200/JCO.2023.41.16_suppl.8510" target="_blank">initial results</a>, which she presented at a major cancer conference, showed that Asian women had a higher lung cancer detection rate than the original national trial — 1.5% versus 1%. “Based on this preliminary data and other ongoing efforts, ​​Asian women do represent another high-risk population that warrants screening,” Shum said.</p><p>Palaniappan, who is also not affiliated with Shum’s trial, tends to agree: “It’s extraordinary that screening in this population yielded a similar incidence of lung cancer” to the original trial. But Palaniappan also cautioned that better inclusion of Asian American women in the screening guidelines is still a long way off, with many more studies needed to confirm and build on Shum’s findings. “We’re just at the beginning,” she said.&nbsp;</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[No Abstractions: our API design principle (192 pts)]]></title>
            <link>https://increase.com/articles/no-abstractions</link>
            <guid>40161794</guid>
            <pubDate>Thu, 25 Apr 2024 19:15:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://increase.com/articles/no-abstractions">https://increase.com/articles/no-abstractions</a>, See on <a href="https://news.ycombinator.com/item?id=40161794">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><span>API resources</span> are the nouns of your API. Deciding how to name and model these nouns is arguably the hardest and most important part of designing an API. The resources you expose organize your users’ mental model of how your product works and what it can do. At Increase, our team has used a principle called “no abstractions” to help. What do we mean by this?</p><p>Much of our team came from Stripe, and when designing our API we considered the same values that have been successful there. Stripe excels at designing</p><!-- --> <p><span>abstractions</span> in their API — extracting the essential features of a complex domain into something their users can easily understand and work with. In their case this most notably means</p><!-- --> <p><a href="https://stripe.com/blog/payment-api-design">modeling</a></p><!-- --><p>payments across many different networks into an API resource called a</p><!-- --> <p><a href="https://docs.stripe.com/api/payment_intents">PaymentIntent</a></p><!-- --><p>. For example, Visa and Mastercard have subtly different reason codes for why a chargeback can be initiated, but Stripe combines those codes into a single enum so that their users don’t need to consider the two networks separately.</p><p>This makes sense because many of Stripe’s users are early startups working on products totally unrelated to payments. They don't necessarily know, or need to know, about the nuances of credit cards. They want to integrate Stripe quickly, get back to building their product, and stop thinking about payments.</p></div><div><p>“For Increase users, trying to hide the underlying complexity of these networks would irritate them, not simplify their lives.”</p></div><div><p>Increase’s users are not like this. They often have deep existing knowledge of payment networks, think about financial technology all the time, and come to us because of our direct network connections and the depth of integration that lets them build. They want to know</p><!-- --> <p><a href="https://status.increase.com/#ach-submission-timeline">exactly</a></p><!-- --><p>when the FedACH window closes and when transfers will land. They understand that setting a different Standard Entry Class code on an ACH transfer can result in different return timing. Trying to hide the underlying complexity of these networks (by, for example, modeling ACH transfers and wire transfers with a single API resource) would irritate them, not simplify their lives.</p><p>Early conversations with these users helped us articulate what we dubbed the “no abstractions” principle as we built the first version of our API. Some examples of the way this mindset has subsequently affected its design:</p></div><p>Real-world naming</p><div><p>Instead of inventing our own names for API resources and their attributes, we tend to use the vocabulary of the underlying networks. For example, the parameters we expose when making an ACH transfer via our API are named after fields in the</p><!-- --> <p><a href="https://achdevguide.nacha.org/ach-file-details">Nacha specification</a>.</p></div><p>Immutability</p><div><p>Similar to how we use network nomenclature, we try to model our resources after real-world events like an action taken or a message sent. This results in more of our API resources being immutable. An approach that’s worked well for our API is to take a cluster of these immutable resources (all of the network messages that can be sent as part of the ACH transfer lifecycle, for example) and group them together under a state machine “lifecycle object”. For example, the <code>ach_transfer</code></p><!-- --><p>object in our API has a field called</p><!-- --> <p><code>status</code> that changes over time, and several immutable sub-objects that are created as the transfer moves through its lifecycle. A newly-minted</p><!-- --> <p><code>ach_transfer</code> object looks like:</p></div><div><pre><p><span>{</span>
  <span>"id"</span><span>:</span> <span>"ach_transfer_abc123"</span><span>,</span>
  <span>"created_at"</span><span>:</span> <span>"2024-04-24T00:00:00+00:00"</span><span>,</span>
  <span>"amount"</span><span>:</span> <span>1000</span><span>,</span>
  <span>"status"</span><span>:</span> <span>"pending_approval"</span><span>,</span>
  <span>"approval"</span><span>:</span> <span><span>null</span></span><span>,</span>
  <span>"submission"</span><span>:</span> <span><span>null</span></span><span>,</span>
  <span>"acknowledgement"</span><span>:</span> <span><span>null</span></span>
  
<span>}</span></p></pre></div><p>After that same transfer has moved through our pipeline and we’ve submitted it to FedACH, it looks like:</p><div><pre><p><span>{</span>
  <span>"id"</span><span>:</span> <span>"ach_transfer_abc123"</span><span>,</span>
  <span>"created_at"</span><span>:</span> <span>"2024-04-24T00:00:00+00:00"</span><span>,</span>
  <span>"amount"</span><span>:</span> <span>1000</span><span>,</span>
  <span>"status"</span><span>:</span> <span>"submitted"</span><span>,</span>
  
  <span>"approval"</span><span>:</span> <span>{</span>
    <span>"approved_by"</span><span>:</span> <span>"administrator@yourcompany.com"</span><span>,</span>
    <span>"approved_at"</span><span>:</span> <span>"2024-04-24T01:00:00+00:00"</span>
  <span>}</span><span>,</span>
  
  <span>"submission"</span><span>:</span> <span>{</span>
    <span>"trace_number"</span><span>:</span> <span>"058349238292834"</span><span>,</span>
    <span>"submitted_at"</span><span>:</span> <span>"2024-04-24T02:00:00+00:00"</span>
  <span>}</span><span>,</span>
  
  <span>"acknowledgement"</span><span>:</span> <span>{</span>
    <span>"acknowledged_at"</span><span>:</span> <span>"2024-04-24T03:00:00+00:00"</span>
  <span>}</span>
  
<span>}</span></p></pre></div><p>Separating resources by use case</p><div><p>If, for a given API resource, the set of actions a user can take on different instances of the resource varies a lot, we tend to split it into multiple resources. For example, the set of actions you can take on an originated ACH transfer is different (the complete opposite, really) than the actions you can take on a received ACH transfer, so we separate these into</p><!-- --> <p><code>ach_transfer</code> and</p><!-- --> <p><code>inbound_ach_transfer</code> resources.</p><hr></div><div><p>This approach can make our API more verbose and intimidating at first glance — there are a lot of resources on the left-hand side of our</p><!-- --> <p><a href="https://increase.com/documentation/api">documentation</a></p><!-- --><p>page! We think it makes things more predictable over the long-term, though.</p><p>Importantly, our engineering team has committed to this approach. When you design a complex API over several years, you make small incremental decisions all the time. Committing to foundational principles upfront has reduced the cognitive load for these decisions. For example, when sending a wire transfer to the Federal Reserve, there’s a required field called</p><!-- --> <p><a href="https://increase.com/documentation/fedwire#technical-implementation">Input Message Accountability Data</a></p><!-- --><p>which serves as a globally-unique ID for that transfer. When building support for wire transfers, an engineer in an abstraction-heavy API might have to deliberate how to name this field in a “user-friendly” way -</p><!-- --> <p><code>trace_number</code>?</p><!-- --> <p><code>reference_number</code>?</p><!-- --> <p><code>id</code>? At Increase that hypothetical engineer names the field</p><!-- --> <p><code>input_message_accountability_data</code> and moves on. When an Increase user encounters this field for the first time, while it might not be the most immediately recognizable name at first, it helps them understand immediately how this maps to the underlying system.</p><p>No Abstractions isn’t right for every API, but considering the level of abstraction that’s appropriate for the developers integrating against it is a valuable exercise. This will depend on their level of experience working with your product domain and the amount of energy they’ll be committing to the integration, among other things. If you’re building an abstraction-heavy API, be prepared to think hard before adding new features. If you’re building an abstraction-light API, commit to it and resist the temptation to add abstractions when it comes along.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Start Your Own ISP (204 pts)]]></title>
            <link>https://startyourownisp.com/</link>
            <guid>40161697</guid>
            <pubDate>Thu, 25 Apr 2024 19:06:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://startyourownisp.com/">https://startyourownisp.com/</a>, See on <a href="https://news.ycombinator.com/item?id=40161697">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
		<div>
			
				

				<p>This site is dedicated to helping you start your own Internet Service Provider. Specifically this guide is about building a Wireless ISP (<a href="https://en.wikipedia.org/wiki/Wireless_Internet_service_provider">WISP</a>).</p>
<p>This guide is focused on the very earliest stages of starting a WISP - determining feasibility up through connecting the first few customers. There are many challenges that will come up at 100, 1,000 or 10,000 customers that are not (yet) covered in this guide.</p>
<div>
    <p>Recent Webinar: <b>Vertical Real Estate For ISPs</b></p>
    <p>Check out a recording of our latest webinar collaboration with <a href="https://outpost.plus/">Outpost Plus</a> on 30 Aug 2023 at 12:00PM Pacific. </p>
    <p>Learn about strategies and solutions for aproaching MDU owners and managers, installing and building out MDU sites, and converting residents into subscribers.</p>
    <a href="https://attendee.gotowebinar.com/recording/5216831262199372120?utm_source=syoisp&amp;utm_medium=website"><p><u>Recorded Webinar</u></p></a>
    </div>
    

<h2 id="whats-new">What’s New</h2>
<ul>
<li>Check out our <a href="https://www.gotostage.com/channel/2c4ef258c411488eae8c04e2481d7a00?medium=web&amp;campaign=evergreen&amp;source=syoisp">past webinars here</a>.</li>
<li>Get a head start on marketing in Q1 with our <a href="https://startyourownisp.com/partnerships">60% off sale on Q1 sponsorship packages</a> right now.</li>
</ul>

<p>If you’d like personalized assistance with a project feel free to <a href="https://clarity.fm/grahamcastleton">book some time</a> with me.</p>
<p><a href="https://startyourownisp.com/community"><strong>Join the discussion!</strong></a> Chat with me (the author) and others interested in this kind of thing here: <a href="https://startyourownisp.com/community">SYOISP Discord Server</a>.</p>
<p><a href="https://twitter.com/syoisp"><strong>Follow Along</strong></a> on Twitter <a href="https://twitter.com/syoisp">@syoisp</a></p>
<h2 id="getting-started">Getting Started</h2>
<p><a href="https://startyourownisp.com/posts/introduction/"><strong>What is a WISP?</strong></a>
And why might you want to build one? Also defines some terminology.</p>
<p><a href="https://docs.google.com/spreadsheets/d/1jjUYOQMuZ4cRyTv1M5X8HGtrKFiW96_gNlfG8BBzRN0/edit?usp=sharing"><strong>Costs</strong></a>
What does it cost to build a wireless Internet Service Provider? (Link to a Google Sheet that you can copy and customize.)</p>
<p><a href="https://startyourownisp.com/posts/about-me/"><strong>About Me</strong></a>
Who am I? Why am I doing this?</p>
<h2 id="step-by-step-guide">Step by Step Guide</h2>
<p><a href="https://startyourownisp.com/posts/location-location-location/"><strong>Step 1: Evaluate an Area</strong></a>: Make sure your area is a good candidate for a Wireless Internet network.</p>
<p><a href="https://startyourownisp.com/posts/fiber-provider/"><strong>Step 2: Find a Fiber Provider</strong></a>: Find a building where you can purchase a fiber connection and use the rooftop to start your wireless network.</p>
<p><a href="https://startyourownisp.com/posts/relay-sites/"><strong>Step 3: Find Relay Sites</strong></a>:
Extend your network wirelessly toward your customers.</p>
<p><a href="https://startyourownisp.com/posts/hardware-platform/"><strong>Step 4: Pick a Hardware Platform</strong></a>:
Evaluate available options for wireless hardware.</p>
<p><a href="https://startyourownisp.com/posts/billing-customer-management/"><strong>Step 5: Billing and Customer Management</strong></a>:
Make sure you’re able to get paid and support your customers.</p>
<p><a href="https://startyourownisp.com/posts/network-topology/"><strong>Step 6: Network Topology</strong></a>:
Design your network topology to make your network reliable and scalable. Routers, switches, IP addresses, VLANs, etc.</p>
<p><a href="https://startyourownisp.com/posts/build-your-infrastructure/"><strong>Step 7: Build your Infrastructure</strong></a>:
Install hardware for your fiber connection and your relay sites.</p>
<p><a href="https://startyourownisp.com/posts/install-a-customer/"><strong>Step 8: Install a Customer</strong></a>:
Get your first customer online!</p>
<p><a href="https://startyourownisp.com/posts/marketing/"><strong>Step 9: Marketing</strong></a>:
Let people know about your service so they can experience a better Internet connection!</p>
<p><a href="https://startyourownisp.com/posts/maintenance/"><strong>Step 10: Maintenance</strong></a>:
Keep your network running smoothly, even in bad weather.</p>


<p>
    <h2>Signup for our monthly newsletter</h2>
    <br>
    

</p>

<h2 id="miscellaneous">Miscellaneous</h2>
<p><a href="https://startyourownisp.com/posts/form477/"><strong>Form 477: How to prepare and file with the FCC</strong></a>
Form 477 is used by the FCC to determine which providers are servicing which areas. ISPs must file this form twice a year.</p>
<p><a href="https://startyourownisp.com/posts/tool-list/"><strong>Tools you’ll want to have</strong></a>
A list of the tools you’ll need to install relays sites and customers.</p>
<p><a href="https://startyourownisp.com/posts/aim-backhaul/"><strong>Aim a Backhaul</strong></a> COMING SOON
A guide describing the proper techniques for aiming backhauls. Designed to be printed out and taken to the site for reference.</p>
<p><a href="https://startyourownisp.com/posts/backhaul-picker/"><strong>Backhaul List</strong></a>
If you just need to get a solid wireless connection from Point A to Point B then use this list to pick the right equipment and get it set up.</p>
<p><a href="https://startyourownisp.com/posts/channel-planning/"><strong>RF Basics and Channel Planning</strong></a> COMING SOON
Avoid self interference by carefully choosing channels for your access points and backhauls.</p>
<p><a href="https://startyourownisp.com/posts/mdus/"><strong>MDUs (Multiple Dwelling Units)</strong></a>
Best practices for providing service to apartment buildings, condos, attached townhomes, etc.</p>
<p><a href="https://startyourownisp.com/posts/guide-to-google-earth/"><strong>Guide to Google Earth</strong></a>
Some tips and tricks for using Google Earth to plan and build your network.</p>
<p><a href="https://startyourownisp.com/posts/roof-and-ladder-safety/"><strong>Roof and Ladder Safety</strong></a> COMING SOON
Stay safe out there!</p>
<div>
<p>How can we help?</p>
<p><a href="https://outpost.plus/">Outpost Plus</a> is the organization behind startyourownisp.com. 
Our experienced professionals are happy to discuss your needs and offer advice and assistance.
 <a href="https://outpost.plus/pages/contact/">Contact us</a> to discuss your project. </p>
</div>


			

			

			
		</div>
	</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Xz sshd backdoor collecting usernames from logs (132 pts)]]></title>
            <link>https://isc.sans.edu/diary/30802</link>
            <guid>40161334</guid>
            <pubDate>Thu, 25 Apr 2024 18:36:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://isc.sans.edu/diary/30802">https://isc.sans.edu/diary/30802</a>, See on <a href="https://news.ycombinator.com/item?id=40161334">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Unless you took the whole weekend off, you must have seen by now that Andres Freund published an amazing discovery on Friday on the Openwall mailing list (<a href="https://www.openwall.com/lists/oss-security/2024/03/29/4">https://www.openwall.com/lists/oss-security/2024/03/29/4</a>).<br>
The whole story around this is both fascinating and scary – and I’m sure will be told around numerous time, so in this diary I will put some technical things about the backdoor that I reversed for quite some time (and I have a feeling I could spend 2 more weeks on this).<br>
There is also a nice gist by smx-smx <a href="https://gist.github.com/smx-smx/a6112d54777845d389bd7126d6e9f504">here</a>&nbsp;that gets updated regularly so keep an eye there as well.<br>
The author(s) of the backdoor went a long way to make the backdoor look as innocent as possible. This is also why all the reversing effort is taking such a long(er) time. Let’s take a look at couple of fascinating things in this backdoor.</p>

<p><strong>String comparison</strong></p>

<p>One of the first things a reverse engineer will do is to search for strings in the code they are looking at. If strings are visible, they can usually tell a lot about the target binary. But if we take a look at the library (and for this diary I am using the one originally sent by Andres) we will see practically no visible strings.<br>
The authors decided to obfuscate all strings – in order to do that, they stored strings as a radix tree (also known as prefix tree or trie, more info at <a href="https://en.wikipedia.org/wiki/Radix_tree">https://en.wikipedia.org/wiki/Radix_tree</a>). This allows them to store all strings as obfuscated, however now one of the challenges they had was to lookup strings – they implemented a function that checks whether a string exists in the radix tree table, and if it does, it returns back the offset:</p>

<p><img alt="" src="https://isc.sans.edu/diaryimages/images/xz1.png"><br>
The image above shows start of the function (originally called Lsimple_coder_update_0) where I also expanded one of the radix tree tables (_Llzip_decode_1). So as input we send a string, and if it exists in the radix tree, we get back its offset. The code needs to do this for every single string lookup, but that should not cause the delay as radix tree lookups are quite fast.</p>

<p><strong>Anti-debugging</strong></p>

<p>Anti-debugging efforts were implemented on several levels. The simplest one includes code where the backdoor is checking if a function starts with the ‘endbr64’ instruction. Let’s check how this works – first the snippet below shows how the .Llzma_block_buffer_encode.0 function gets called. Notice the value 0x0E230 being passed in rdx:</p>

<div><p><img alt="" src="https://isc.sans.edu/diaryimages/images/xz2.png"></p><p>

The following figure shows how the backdoor checks whether the ‘endbr64’ instruction is still there (if not – it has been probably changed by a debugger which signals the backdoor to abort):</p></div>

<p><img alt="" src="https://isc.sans.edu/diaryimages/images/xz3.png"></p>

<p>Another important register here is rdi, which will points to the location of the ‘endbr64’ instruction. In other words, if everything is OK, value of [rdi] must be 0xFA1E0FF3, which is the opcode for the ‘endbr64’ instruction.<br>
So now when we go through code, the line add eax, [rdi] should sum 0xFA1E0FF3 and 0x5E2E230 which results in 0xF223. If that is correct 1 is returned, otherwise 0 (indicating that the 'endbr64' instruction was not there). Quite cool.<br>
There is more another function that dynamically modifies code, but that is horrible for reversing – perhaps later ?</p>

<p><strong>Collecting usernames and IP addresses?</strong></p>

<p>The final function we’ll take a look at is also interesting – it will parse every log created by the sshd service and will try to extract valid usernames and IP addresses. The function is .Llzma12_mode_map.part.1 and we can see the initial comparisons (with my comments) here:</p>

<p><img alt="" src="https://isc.sans.edu/diaryimages/images/xz4.png"></p>

<p>So with this, the attacker is parsing a log line such as the following:</p>

<p><span>Accepted password for root from 192.168.14.1 port 62405 ssh2</span></p>

<p>Further below in the function we can see that they match on the ‘from’ and ‘ssh2’ keywords and extract what’s between them:</p>

<p><img alt="" src="https://isc.sans.edu/diaryimages/images/xz5.png"></p>

<p>Finally, they pass this to another function, however that’s not visible in static analysis so this is where I lost it.</p>

<p>Guess that’s it for today – depending on developments we might update this diary but in any case check the resources posted at the beginning as they get updated quite often.<br>
If you are looking at this too - hope you're having fun. I quite enjoyed this (too bad it's back to dayjob soon heh), but I'm also scared about how *<strong>close</strong>* this was to infect zillion servers.</p>

<p>--<br>
Bojan<br>
<a href="https://x.com/bojanz">@bojanz</a>&nbsp;|&nbsp;<a href="https://www.linkedin.com/in/bojanz/">@linkedin</a><br>
<a href="http://www.infigo.hr/">INFIGO IS</a></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FCC restores net neutrality rules that ban blocking and throttling in 3-2 vote (129 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2024/04/fcc-restores-net-neutrality-rules-that-ban-blocking-and-throttling-in-3-2-vote/</link>
            <guid>40160824</guid>
            <pubDate>Thu, 25 Apr 2024 17:52:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2024/04/fcc-restores-net-neutrality-rules-that-ban-blocking-and-throttling-in-3-2-vote/">https://arstechnica.com/tech-policy/2024/04/fcc-restores-net-neutrality-rules-that-ban-blocking-and-throttling-in-3-2-vote/</a>, See on <a href="https://news.ycombinator.com/item?id=40160824">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/09/getty-rosenworcel-net-neutrality-800x533.jpg" alt="FCC Commissioner Jessica Rosenworcel speaks outside in front of a sign that says " net="" neutrality="" wake="" up="" call.""="">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/09/getty-rosenworcel-net-neutrality.jpg" data-height="1000" data-width="1500">Enlarge</a> <span>/</span> Federal Communication Commission Chairwoman Jessica Rosenworcel, then a commissioner, rallies against repeal of net neutrality rules in December 2017.</p><p>Getty Images | Chip Somodevilla</p></figcaption>  </figure>

  




<!-- cache hit 402:single/related:8dac2a52de2c4855444f71790f3583c9 --><!-- empty -->
<p>The Federal Communications Commission voted 3–2 to impose net neutrality rules today, restoring the common-carrier regulatory framework enforced during the Obama era and then abandoned while Trump was president.</p>
<p>The rules prohibit Internet service providers from blocking and throttling lawful content and ban paid prioritization. Cable and telecom companies plan to fight the rules in court, but they <a href="https://arstechnica.com/tech-policy/2016/06/net-neutrality-and-title-ii-win-in-court-as-isps-lose-case-against-fcc/">lost a similar battle</a> during the Obama era when judges upheld the FCC's ability to regulate ISPs as common carriers under Title II of the Communications Act.</p>
<p>"Consumers have made clear to us they do not want their broadband provider cutting sweetheart deals, with fast lanes for some services and slow lanes for others," FCC Chairwoman Jessica Rosenworcel said at today's meeting. "They do not want their providers engaging in blocking, throttling, and paid prioritization. And if they have problems, they expect the nation's expert authority on communications to be able to respond. Because we put national net neutrality rules back on the books, we fix that today."</p>
<p>ISPs insist the rules aren't necessary because they already follow net neutrality principles yet also claim the rules are so burdensome that they will be prevented from investing more in their networks. Lobby group USTelecom today <a href="https://www.ustelecom.org/ustelecom-statement-on-the-fcc-title-ii-vote/">said</a> the "relentless regulation" comes at the cost of "failing to achieve Internet for all."</p>
<p>"This is a nonissue for broadband consumers, who have enjoyed an open Internet for decades," USTelecom CEO Jonathan Spalter said. "Rather than pushing this harmful regulatory land grab, policymakers should keep their eyes on the real-world prize of building opportunity for everyone in a hyperconnected world."                                            </p>
                                                        
<h2>NCTA: Net neutrality is “net fatality”</h2>
<p>Cable lobby group NCTA-The Internet &amp; Television Association <a href="https://www.ncta.com/media/media-room/statement-of-michael-powell-president-ceo-of-ncta-the-internet-television-association-regarding-the-fccs-unnecessary-and-unlawful-broadband-regulation-order">claimed</a> that "the FCC's marketplace intrusion comes at the worst possible time for our massive national effort to finally close the digital divide—just as billions in federal funding are dedicated to extending internet access to America's unserved communities."</p>
<p>That is a reference to a <a href="https://arstechnica.com/tech-policy/2023/06/us-allocates-42b-in-broadband-funding-find-out-how-much-your-state-will-get/">$42 billion program</a> that is paying ISPs to deploy networks in unserved and underserved areas. "Instead of clearing obstacles to speed broadband deployment where it is most needed, this ill-timed and unlawful order threatens to hinder progress," NCTA CEO Michael Powell said. "This will not deliver net neutrality; it will risk a net fatality."</p>
<p>The court battle against the FCC will center on whether the commission can define broadband as a telecommunications service, a necessary step for imposing Title II common-carrier regulations. <a href="https://arstechnica.com/tech-policy/2023/10/is-net-neutrality-doomed-at-supreme-court-fcc-and-isps-prepare-for-epic-battle/">ISPs hope</a> that the Supreme Court's evolving approach to "major questions" will prevent the FCC from defining broadband as telecommunications without explicit instructions from Congress.</p>
<p>FCC Commissioner Geoffrey Starks, a Democrat, said that "major questions review is reserved for only 'extraordinary cases'—and this one doesn't come close. There's no 'unheralded power' that we're purporting to discover in the annals of an old, dusty statute—we've been classifying communications services one way or the other for decades, and the 1996 [Telecommunications] Act expressly codified our ability to continue that practice."</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FCC Votes to Restore Net Neutrality Rules (641 pts)]]></title>
            <link>https://www.nytimes.com/2024/04/25/technology/fcc-net-neutrality-open-internet.html</link>
            <guid>40160429</guid>
            <pubDate>Thu, 25 Apr 2024 17:23:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/04/25/technology/fcc-net-neutrality-open-internet.html">https://www.nytimes.com/2024/04/25/technology/fcc-net-neutrality-open-internet.html</a>, See on <a href="https://news.ycombinator.com/item?id=40160429">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/04/25/technology/fcc-net-neutrality-open-internet.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Jeff Geerling: Corporate Open Source Is Dead (200 pts)]]></title>
            <link>https://www.jeffgeerling.com/blog/2024/corporate-open-source-dead</link>
            <guid>40160331</guid>
            <pubDate>Thu, 25 Apr 2024 17:16:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jeffgeerling.com/blog/2024/corporate-open-source-dead">https://www.jeffgeerling.com/blog/2024/corporate-open-source-dead</a>, See on <a href="https://news.ycombinator.com/item?id=40160331">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>IBM is <a href="https://www.reuters.com/markets/deals/ibm-buy-hashicorp-64-billion-deal-expand-cloud-software-2024-04-24/">buying HashiCorp for $6.4 <em>billion</em></a>.</p>

<p>That's four months after <a href="https://www.hashicorp.com/blog/hashicorp-adopts-business-source-license">HashiCorp rugpulled their <em>entire</em> development community</a> and ditched open source for the 'Business Source License.'</p>

<p>As <a href="https://news.ycombinator.com/item?id=40135490">someone on Hacker News</a> pointed out so eloquently:</p>

<blockquote>
  <p>IBM is like a juicer that takes all the delicious flavor out of a fruit</p>
</blockquote>

<p>skywhopper replied:</p>

<blockquote>
  <p>"HashiCorp already did a great job pre-draining all their flavor."</p>
</blockquote>

<p><a href="https://twitter.com/jgunnink/status/1783303926042996928">Some people wonder</a> if HashiCorp's decision to drop open source was <em>because</em> they wanted to juice the books for a higher price. I mean, <em>six billion dollars?</em> And they're not even a pointless AI company!</p>

<blockquote>
  <p>This blog post is a transcript of the video I posted today, <a href="https://www.youtube.com/watch?v=hNcBk6cwim8">Corporate Open Source is Dead</a>. You can watch it on YouTube.</p>
</blockquote>

<p>Meanwhile, <a href="https://redis.io/blog/redis-adopts-dual-source-available-licensing/">Redis dropped the open BSD license</a> and invented their own 'Source Available' license.</p>

<p>And last year, I covered how <a href="https://www.jeffgeerling.com/blog/2023/im-done-red-hat-enterprise-linux">Red Hat found a way to just <em>barely</em> comply</a> with the open source GPL license for their Enterprise Linux distro.</p>

<p>Other companies like MongoDB, Cockroach Labs, Confluent, Elasticsearch, and Sentry <a href="https://thenewstack.io/hashicorp-abandons-open-source-for-business-source-license/">also went 'Source Available'</a>. It started with some of the smaller players, but as rot sets in at even the biggest 'open source' companies, open source devs are choosing the nuclear option.</p>

<p>When a company rug pulls? Fork 'em. Literally!</p>

<p>Terraform, HashiCorp's bread and butter, was <a href="https://opentofu.org/blog/the-opentofu-fork-is-now-available/">forked into OpenTofu</a>, and adopted by the Linux Foundation. Companies who built their businesses on top of Terraform quickly switched over. Even juicier, OpenBao—a fork of HashiCorp's other big project Vault—is <a href="https://www.techtarget.com/searchitoperations/news/366563095/IBM-engineers-hatch-Linux-Foundation-HashiCorp-Vault-fork">backed by IBM</a>! What's going to happen with <em>that</em> fork now?</p>

<p>At least forks seem pretty straightforward in Hashi-land. In the wake of Redis' wanton destruction, it seems like there's a <a href="https://arstechnica.com/information-technology/2024/04/redis-license-change-and-forking-are-a-mess-that-everybody-can-feel-bad-about/">new fork every week</a>!</p>

<p>And some developers are even exploring ditching the Redis code entirely, like <a href="https://github.com/nalgeon/redka">redka</a>'s an API-compatible wrapper on top of SQLite!</p>

<p>After Red Hat closed its door—most of the way, at least they didn't try pulling a switcheroo on the license itself! Oracle, SUSE, and CIQ <a href="https://www.suse.com/news/OpenELA-for-a-Collaborative-and-Open-Future/">scrapped together the OpenELA alliance</a> to maintain forks of Enterprise Linux. And CentOS users who'll be left in a lurch as June marks the end of CentOS 7 support have to decide whether to use AlmaLinux or one of the ELA projects now.</p>

<p>All these moves shattered the playbook startups and megacorps used—and now we're seeing, abused—to build up billions in revenue over the past decade.</p>

<p>It was all in the name of 'open source'.</p>

<p>As free money dries up and profits slow, companies <a href="https://www.cnbc.com/2024/03/12/ibm-tells-employees-of-job-cuts-in-marketing-and-communications.html">slash headcount</a> almost as fast as community trust.</p>

<h2>2024 is the year corporate open source died</h2>

<p>2024 is the year Corporate Open Source—or at least any remaining illusions about it—finally died.</p>

<p>It's one thing to build a product with a proprietary codebase, and charge for licenses. You can still build communities around that model, and it's worked for decades.</p>

<p>But it's totally different when you build your product under an open source license, foster a community of users who then build their own businesses on top of that software, then yoink the license when your revenue is affected.</p>

<p>That's called a bait-and-switch.</p>

<p>Brian Cantrill's been sounding the alarm for years—yes, <em>that Brian Cantrill</em>, the one who posted this gem:</p>

<div>
<p><iframe src="https://www.youtube.com/embed/tDacjrSCeq4" frameborder="0" allowfullscreen=""></iframe></p>
</div>

<p><a href="https://www.youtube.com/watch?v=-zRN7XLCRhc">Brian's presentation</a> from 12 years ago is worth a watch, and the bottom line is summed up by <a href="https://drewdevault.com/2023/07/04/Dont-sign-a-CLA-2.html">Drew DeVault</a>:</p>

<blockquote>
  <p>[Contributor License Agreements are] a strategy employed by commercial companies with one purpose only: to place a rug under the project, so that they can pull at the first sign of a bad quarter. This strategy exists to subvert the open source social contract.</p>
</blockquote>

<p>By working on a project with a CLA, where you sign away your code, you're giving carte blanche for the company to take away your freedom to use their software.</p>

<p>From a company's perspective, if they want CLAs or if they want to use an anti-open-source license, they do <em>not</em> care about your freedoms. They're protecting revenue streams. They'll often talk about freeloaders, whether it's Amazon building a competing hosted solution, or some startup that found a way to monetize support.</p>

<p>But in the end, even if you have GPL code and you charge people to get it, it's not truly free as in freedom, if the company restricts how you can use, modify, and share the code.</p>

<p>But there's a distinction here, and I know a few people watching this are already yelling at me. There's "free" software, and there's "open source."</p>

<p>People in the free software community <a href="https://www.gnu.org/philosophy/open-source-misses-the-point.html">correctly identified the danger</a> of calling free software 'open source.'</p>

<p>I don't think we have to be so dogmatic about it, but there <em>is</em> a fundamental <em>philosophical</em> difference between the free software community, with organizations like the Free Software Foundation and Software Freedom Conservancy behind it, and the more business-oriented 'open source' culture.</p>

<p>Open source culture relies on trust. Trust that companies <em>you and I helped build</em> (even without being on the payroll) wouldn't rugpull.</p>

<p>But time and time again, that trust is shattered.</p>

<p>Is this slow death of corporate open source <em>bad</em>? Well, it's certainly been annoying, especially for devs like me who felt connected to these communities in the past. But it's not <em>all</em> bad.</p>

<h2>Why it's not bad for corporate open source to die</h2>

<p>In fact, this could be a huge opportunity; what happened to the spunky startups like Ansible, HashiCorp, Elasticsearch, or Redis? They were lighting their industries on fire with great new software.</p>

<p>What happened to building up communities of developers, crossing cultural and economic barriers to make software that changed the world?</p>

<p>There are still projects doing that, but so many succumb to enterprise money, where eye-watering amounts of revenue puts profit over philosophy.</p>

<p>But as money dries up, as more developers get laid off after the insane hiring trends of the past five years, maybe small dev teams can move the needle.</p>

<p>The AI bubble hasn't popped yet, so some great people are getting sucked into that vortex.</p>

<p>But someone else could be on the cusp of the next great open source project. Just... don't add a CLA, okay?</p>

<p>And it's not just devs; big companies can join in. Historically bad players like Microsoft and <em>maybe even Oracle</em>—man, it pains me to say that. They've even made strides in the past decade!</p>

<p>IBM could even mend some wounds, like they could reunite OpenTofu and Terraform. There's precedent, like when <a href="https://thenewstack.io/io-js-and-node-js-have-united-and-thats-a-good-thing/">IO.js merged back into Node.js</a> after a fork in 2015.</p>

<p>People asked what Red Hat could do to get me interested in Enterprise Linux again. It's simple: stop treating people who don't bring revenue to the table like garbage. Freeloaders are part of open source—whether they're running homelab or a competing business.</p>

<p>Companies who want to befriend open source devs need to show they care about more than just money. Unfortunately, the trend right now is to rugpull to juice the quarterlies, because money line always goes up!</p>

<p>But you know what? I'd just prefer honesty. If revenue is so dependent on selling software, just... make the software proprietary. Don't be so coy!</p>

<p>But to anyone who's not a multi-billion dollar corporation, don't be a victim of the next rugpull. The warning signs are clear: Don't sign a CLA. Stay away from projects that require them.</p>

<p>Stick to open source licenses that respect your freedom, not licenses written to juice revenue and prep a company for a billion-dollar-buyout.</p>

<p>Maybe it's time for a new open source rebellion. Maybe this time, money <em>won't</em> change company culture as new projects arise from the ash heap. Maybe not, but at least we can try.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Big telecom used fake and dead people to fight net neutrality, New York AG says (139 pts)]]></title>
            <link>https://www.vice.com/en/article/3aqq7b/big-telecom-used-fake-and-dead-people-to-fight-net-neutrality-ny-ag-says</link>
            <guid>40160292</guid>
            <pubDate>Thu, 25 Apr 2024 17:14:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vice.com/en/article/3aqq7b/big-telecom-used-fake-and-dead-people-to-fight-net-neutrality-ny-ag-says">https://www.vice.com/en/article/3aqq7b/big-telecom-used-fake-and-dead-people-to-fight-net-neutrality-ny-ag-says</a>, See on <a href="https://news.ycombinator.com/item?id=40160292">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>NY AG Letitia James. Image:&nbsp;Bloomberg / Contributor via Getty Images</p></div><div data-component="BodyComponentRenderer"><p><span data-component="TextBlock"><div><p><a href="https://morningconsult.com/2017/06/21/poll-shows-broad-bipartisan-support-net-neutrality-rules/" target="_blank"><span>Survey</span></a> after <a href="https://publicconsultation.org/united-states/overwhelming-bipartisan-public-opposition-to-repealing-net-neutrality-persists/" target="_blank"><span>survey</span></a> has shown that the public overwhelmingly opposed the Trump FCC’s 2017 repeal of net neutrality rules designed to protect consumers from telecom monopolies. So the broadband industry engaged in a practice that’s becoming more and more common: it used fake <a href="https://www.vice.com/en/article/evg3xw/dead-people-are-posting-anti-net-neutrality-comments-to-the-fcc-website"><span>and even dead people</span></a> to generate bogus support for the industry’s unpopular plan. </p><p>A <a href="https://ag.ny.gov/sites/default/files/oag-fakecommentsreport.pdf" target="_blank"><span>new report</span></a> by New York Attorney General Letitia James investigated this practice and found that the broadband industry used three marketing firms to create artificial support for the repeal:&nbsp; Fluent, Opt-Intelligence, and React2Media. As part of an agreement with NY’s AG, the companies were required to implement “comprehensive reforms” and pay $4.4 million in penalties. The campaign was operated by a non-profit organization funded by the broadband industry called <a href="https://www.broadbandforamerica.com/" target="_blank"><span>Broadband for America</span></a>, according to the report.</p></div></span><span></span><span data-component="TextBlock"><p>The NY AG office did not respond to a request for comment asking why the broadband providers that hired these firms were neither named nor penalized.&nbsp;</p></span><span data-component="TextBlock"><p>“Americans’ voices are being drowned out by masses of fake comments and messages being submitted to the government to sway decision-making,” James said <a href="https://ag.ny.gov/press-release/2021/attorney-general-james-issues-report-detailing-millions-fake-comments-revealing" target="_blank"><span>in a statement</span></a>. “Instead of actually looking for real responses from the American people, marketing companies are luring vulnerable individuals to their websites with freebies, co-opting their identities, and fabricating responses that giant corporations are then using to influence the policies and laws that govern our lives.”</p></span><span data-component="TextBlock"><p>First passed in 2015, the FCC’s net neutrality rules prevented regional broadband monopolies from abusing their gatekeeper power to harm competitors and consumers. The 2017 repeal not only eliminated those rules, it <a href="https://www.vice.com/en/article/yw5d5g/net-neutrality-big-telecom-broadband-deregulation"><span>neutered much of the FCC’s consumer protection authority</span></a>, while also attempting to ban state regulators from filling the consumer protection void. </p></span></p><p><span data-component="TextBlock"><div><p>All told, the investigation found that nearly 18 million of the more than 22 million comments the FCC received in its 2017 proceeding to repeal net neutrality rules were fake. About 8.5 million of those comments were sent by people who simply didn’t exist. Many, however, simply used the names of real people without their knowledge.</p><p>Many consumers were <a href="https://www.buzzfeednews.com/article/jsvine/net-neutrality-fcc-fake-comments-impersonation" target="_blank"><span>shocked to learn</span></a> their names had been used in such a fashion. Even Senators Patrick Toomey and Jeff Merkley found their identities used <a href="https://www.washingtonpost.com/news/the-switch/wp/2018/05/23/two-senators-say-their-identities-were-stolen-in-fake-net-neutrality-comments-to-the-fcc/" target="_blank"><span>in support of the repeal</span></a>. Even this reporter's identity was also used to submit <a href="https://www.fcc.gov/ecfs/filing/1042876702862" target="_blank"><span>a fake comment</span></a> supporting the FCC’s proposal. When I contacted the agency to ask it be removed, I was told <a href="https://www.techdirt.com/articles/20170710/10071737756/fcc-insists-it-cant-stop-impostors-lying-about-my-views-net-neutrality.shtml" target="_blank"><span>there was nothing it could do</span></a>. </p><p>The NY AG inquiry found that several of these lead-generating companies used prizes like gift cards and sweepstakes entries to lure consumers to their websites and provide their personal information. That information was then used to petition the government in support of the net neutrality repeal without those users’ consent or approval.</p></div></span><span data-component="TextBlock"><div><p>The creation of fake grass roots support for corporation-backed policies is frequently dubbed “astroturf,” a tactic that has become increasingly common as corporations push for policies broadly opposed by the general public. </p><p>One <a href="https://www.wsj.com/articles/many-comments-critical-of-fiduciary-rule-are-fake-1514370601" target="_blank"><span>2017 effort at the Labor Department</span></a> to prevent conflicts of interest in retirement advice was plagued by similar bogus public comments. Fake comments also inundated the <a href="https://www.wsj.com/articles/lawmaker-seeks-probe-into-fake-comments-on-payday-lending-rule-1517862004" target="_blank"><span>Consumer Financial Protection Bureau</span></a> when it proposed a rule in 2018 trying to rein in some of the nastier habits of the payday lending industry.</p></div></span><span data-component="TextBlock"><div><p>Data obtained by FOIA request also showed the NFL was involved in <a href="https://www.theverge.com/2018/9/10/17840960/nfl-fake-fan-letters-fcc-2014-sports-blackout-rule" target="_blank"><span>sending fake fan comments to the FCC</span></a> as early as 2014 as the league tried to fight agency efforts to eliminate the so-called "black out rule," requiring that broadcasters black out certain game broadcasts if real-world game attendance didn’t meet the league's liking.</p><p>All told, the AG’s office found that such tactics were used by corporations to influence government decision making in more than 100 different, unrelated policy campaigns. </p></div></span><span data-component="TextBlock"><p>“From net neutrality rules to laws affecting criminal justice reform, health care, and more, these fake comments have simply been generated to influence too many government policies, which is why we are cracking down on this illegal and deceptive behavior,” James said. “My office will continue to shine a spotlight on abuses and disinformation and ensure those who break the law are held accountable.”</p></span><span data-component="TextBlock"></span></p></div><div><p><h3>ONE EMAIL. ONE STORY. EVERY WEEK. SIGN UP FOR THE VICE NEWSLETTER.</h3></p><p>By signing up, you agree to the<!-- --> <a href="https://vice-web-statics-cdn.vice.com/privacy-policy/en_us/page/terms-of-use.html">Terms of Use</a> <!-- -->and<!-- --> <a href="https://vice-web-statics-cdn.vice.com/privacy-policy/en_us/page/privacy-policy.html">Privacy Policy</a> <!-- -->&amp; to receive electronic communications from Vice Media Group, which may include marketing promotions, advertisements and sponsored content.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DDC OLED: how to drive a tiny display from an HDMI port. (2022) (150 pts)]]></title>
            <link>https://mitxela.com/projects/ddc-oled</link>
            <guid>40159766</guid>
            <pubDate>Thu, 25 Apr 2024 16:42:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mitxela.com/projects/ddc-oled">https://mitxela.com/projects/ddc-oled</a>, See on <a href="https://news.ycombinator.com/item?id=40159766">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="mxmain"><p><a href="https://mitxela.com/projects/hardware"><img onload="this.style.opacity=1;" src="https://mitxela.com/img/titles/mitxela_dot_com-65.png" title="Back to Hardware" alt="Back to Hardware"></a></p><p>31 Mar 2022<br><b>Progress: Complete</b></p><p>
I have a proclivity to stupid and/or pointless projects. This is one of them. Conceived from a conversation that ended with "Hey, it would technically be possible to..." – sure, let's do it.</p><p>

DDC, display data channel, is a protocol for reading information about what resolutions and so on a monitor supports. It was later extended to DDC/CI, that lets you set brightness and other parameters, but fundamentally, the original idea was to stick a cheap i2c eeprom on each device with some basic info on it. (Technically, the <i>original</i> idea was even simpler than that, but let's not get into that.)</p><p>

It began in the VGA days, but has become so entrenched that even modern hardware with HDMI or DisplayPort supports it. That's right, in an HDMI cable, nestled amongst the high-speed differential pairs, there's an exceedingly slow i2c bus.</p><p>

Tiny OLED dot-matrix displays often have an i2c controller, so I had the idea to try and plug one <i>directly</i> into an HDMI port. Hilarious! Let's do it.</p><h3>Wiring</h3><p>
I chopped up a broken HDMI cable and found the pins we care about: SCL, SDA, 5V, DDC-GND, and HPD (Hot Plug Detect). A quick google got us the pinout:</p><p>

<img src="https://mitxela.com/img/uploads/blinken/oled/hdmi-pinout.png" alt="HDMI pinout"></p><p>

This diagram shows an HDMI socket, if you're poking pins into the cable then flip left to right.</p><table>
<tbody><tr><th>HDMI Pin Number</th><th>Signal</th></tr>
<tr><td>1</td><td>TMDS Date 2+</td></tr>
<tr><td>2</td><td>TMDS Data 2 shield</td></tr>
<tr><td>3</td><td>TMDS Data 2-</td></tr>
<tr><td>4</td><td>TMDS Data 1+</td></tr>
<tr><td>5</td><td>TMDS Data 1 shield</td></tr>
<tr><td>6</td><td>TMDS Data 1-</td></tr>
<tr><td>7</td><td>TMDS Data 0+</td></tr>
<tr><td>8</td><td>TMDS Data 0 shield</td></tr>
<tr><td>9</td><td>TMDS Data 0-</td></tr>
<tr><td>10</td><td>TMDS Clock+</td></tr>
<tr><td>11</td><td>TMDS Clock shield</td></tr>
<tr><td>12</td><td>TMDS Clock-</td></tr>
<tr><td>13</td><td>CEC</td></tr>
<tr><td>14</td><td>HEC Data-</td></tr>
<tr><td>15</td><td>SCL (Serial Clock for DDC</td></tr>
<tr><td>16</td><td>SDA (Serial Data Line for DDC</td></tr>
<tr><td>17</td><td>DDC / CEC / HEC Ground</td></tr>
<tr><td>18</td><td>+5 V Power (50 mA max)</td></tr>
<tr><td>19</td><td>Hot Plug Detect (1.3) / HEC Data+ (1.4)</td></tr>
</tbody></table><p>

I've a tendency to choose low-risk options when it comes to hardware hacking, no one likes seeing blue smoke, especially if the dev board was expensive. Today though I feel like living on the edge, and I'm going to solder this display directly onto the severed HDMI cable coming out of my reasonably new laptop. What a thrill! If we mess up, this stupid experiment could be very expensive.</p><p>

You have to register to download the HDMI spec which is more effort than I have for this, but the Hot Plug Detect pin has a pretty descriptive name. I guessed that this either has to be pulled up or pulled down to signal that a cable is connected. Sticking a 20K resistor to the 5V pin seemed to do the trick. With the oscilloscope, we can now see activity on the SCL/SDA lines when it's plugged into the laptop.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/oled/hdmi1.jpg" alt="Scoping the HDMI cable"></p><p>

I then boldly soldered a header connector to the four lines we care about. I'd ordered a couple of OLED screens for this experiment, they both use the SSD1306 controller, and come on breakout boards with the four pins on a header.</p><h3>i2c and SMBus</h3><p>
On linux we can access i2c devices by loading the i2c-dev module (<code>modprobe i2c-dev</code>) which makes a bunch of i2c devices appear at <code>/dev/i2c-*</code>. My laptop shows nine i2c devices.</p><p>

Some of these are in fact SMBus, which is a subset of i2c. As far as we're concerned it's just i2c with a bunch of extra restrictions, such as limiting transactions to 32 bytes. </p><p>

It's also worth installing the <code>i2c-tools</code> package which comes with the i2cdetect utility and sets a udev rule for group permissions. To access i2c devices without sudo, add yourself to the i2c group (<code>sudo usermod -G i2c -a username</code>) and log in again for it to take effect. I also had to run <code>udevadm trigger</code> for the udev rule to take effect. Might have been simpler to reboot (never!).</p><p>

Beware: the i2c device naming is not consistent. I figured out that <code>/dev/i2c-3</code> was the HDMI DDC line I'd soldered to, but after unloading and re-loading the module, it became <code>/dev/i2c-4</code>. We need to be <i>really</i> careful about this, writing (or even reading) to the wrong i2c device could easily muck up some of the laptop hardware. </p><p>

I installed another package, <code>ddcutil</code>, only to be able to do <code>ddcutil detect</code>. This lists displays and their associated i2c bus. It's also possible to do <code>i2cdetect -l</code> which lists the i2c devices and their description. In my case, three of the i2c lines had "i915 gmbus" in their description, i915 is the intel graphics driver. <code>ddcutil</code> is still probably the easiest way to figure it out.</p><h3>Initial tests</h3><p>
The scope showed the SCL/SDA lines are already pulled up, so we should be able to connect the screen without any other hardware. The 5V line on an HDMI port can apparently source up to 50mA, so we don't even need a power supply. Neat!</p><p>

<img src="https://mitxela.com/img/uploads/blinken/oled/hdmi2.jpg" alt="OLED display connected to the severed cable"></p><p>

<code>i2cdetect</code> can scan an i2c bus for devices. As expected, without the cable connected, it detected nothing on the bus. But when I connected my severed cable, with the hot plug detect resistor in place, a whole load of responses appeared. I don't know quite what's going on here (does the video hardware expose a bunch of stuff when the cable is connected?) but the important point is that when I connected the display, an extra device showed up at <code>0x3c</code>.</p><p>

The quickest way to talk to the display is with a python script. The bundled smbus library lets us get going very quickly.</p><pre>import smbus

bus = smbus.SMBus(4) # for /dev/i2c-4
i2caddr = 0x3c

bus.write_i2c_block_data(i2caddr, 0, [0xaf] ) # turn display on
</pre><p>

There's a bunch of commands we need to send before we can actually display anything, including enabling the charge pump. Note that the SSD1306 datasheet, at least the copy I found, has an appnote appended onto the end of it that explains the initialization process more clearly than the main document (some of the commands are not documented in the main command table). As always, the fastest way to get going is to look at the source code to existing libraries, so I found somebody else's library for the SSD1306 and copied their init commands. The display sprang to life!</p><p>

<img src="https://mitxela.com/img/uploads/blinken/oled/hdmi3.jpg" alt="OLED display showing static"></p><p>

I also found a script to draw text to an SSD1306, and quickly patched in my smbus stuff. Success!</p><p>

<img src="https://mitxela.com/img/uploads/blinken/oled/hdmi4.jpg" alt="Hello World and some other junk on the screen, with laptop in view"></p><p>

No microcontroller, no other hardware, just an SSD1306 OLED plugged straight into the HDMI port. I find this <i>very satisfying</i>.</p><h3>Dumping data to it</h3><p>
Sticking with the python script for now, I'd like to be able to take a 128x64 pixel image and dump it onto the display. The text-drawing routine I borrowed uses SSD1306 commands to control the column and page address that data is being written to, so a single character can be drawn without affecting the rest of the display (hence the uninitialized background pixels remaining in that image above).</p><p>

There's a whole load of different memory addressing modes for this thing, along with confusing terminology. SEG or COL is the X coordinate, COM is the Y coordinate, but these are grouped into pages. The datasheet has some diagrams.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/oled/com-pages.png" alt="Explanation of SEG, COM and PAGE"></p><p>

<img src="https://mitxela.com/img/uploads/blinken/oled/horiz-address-mode.png" alt="Horizontal addressing mode"></p><p>

The display is monochrome, each page is 8 rows (COMs) and when we pipe data to the display, each byte is one page, one column of pixels. It may have made more sense to configure the display for vertical addressing mode, so the bits would all be in order, but I figured it would be quickest to just do the bit-shuffling at our end.</p><p>

With python PIL (pillow) we can convert an image to monochrome with <code>.convert(1)</code> and serialize it with <code>.tobytes()</code>. This will have each byte represent 8 horizontal pixels, but we want each byte to represent 8 vertical pixels. Instead of doing some tedious bitwise logic, the fastest way to fix this is by rotating the image 90 degrees before we serialize it, then loading those bytes into a numpy matrix and transposing it. It's the kind of thing that either works perfectly first time, or outputs a complete mess, in which case you just permute the order of operations until it works. So much easier than thinking.</p><p>

As I mentioned, SMBus won't let us send more than 32 bytes at a time, even though this device is just plain i2c. We can get around this by accessing the i2c device directly from python. The trick is to use <code>ioctl</code> to configure the slave address. In the kernel header file <code>i2c-dev.h</code> there are definitions for the constants needed, we only care about <code>I2C_SLAVE</code>.</p><pre>import io, fcntl

dev = "/dev/i2c-4"
I2C_SLAVE=0x0703 # from i2c-dev.h
i2caddr = 0x3c

bus = io.open(dev, "wb", buffering=0)
fcntl.ioctl(bus, I2C_SLAVE, i2caddr)

bus.write(bytearray([0x00, 0xaf]))
</pre><p>

By alternately sending 1024 bytes of zero or 0xFF, I could gauge how quickly this updated the display. Seemed to work fastest by sending 256 bytes at a time, not sure if that's a limitation of the i2c hardware (is there some extra layer of buffering?).</p><p>

With this I could get between 5 and 10 frames per second (compared to about 2FPS with the SMBus limitation). I think the DDC is running at 100kHz, but regardless this is certainly pushing the limits of what it was intended for.</p><h3>Make it a monitor</h3><p>
We could just write our application to draw directly to this screen, but that's not good enough, I want it to be a monitor.</p><p>

(I'm not sure what our application here even is, but that's beside the point. I want it to be a monitor!)</p><p>

We could write our own video driver. As educational as this sounds, it would be a colossal amount of work and I was rather hoping to have this wrapped up within the evening.</p><p>

There are a bunch of dummy video drivers in existence, these are intended for headless machines in order to enable VNC and so on. <code>xserver-xorg-video-dummy</code> may function for us, but I have a terrible feeling this won't play well at all with us also having real display outputs. There's <code>Xvfb</code>, a virtual framebuffer, but this won't do us much good if we want to have our desktop extend onto it. </p><p>

Since I'm using xorg, it seems the right way to fake a monitor, without spending days on it, is to go through xrandr.</p><p>

xrandr is both a library, and a userspace commandline utility.</p><p>

It took me a while to get to grips with the xrandr terminology. It's not particularly well explained.</p><ul>
<li> The "framebuffer" is the whole desktop, i.e. what gets saved if you take a screenshot. 
</li><li> An "output" is a physical video output.
</li><li> A "monitor" is virtual concept, that normally is mapped to all or part of the framebuffer, and normally corresponds to one output. If you maximize a window, it fills the dimensions of the monitor.
  <ul>
  <li> However, you can have one display output be more than one monitor (for instance, to split a widescreen display into effectively two monitors)
  </li><li> Or, multiple outputs can be one monitor, i.e. multiple physical screens can be treated as if they were a single display, maximizing a window would cover all of them.
  </li></ul>
</li><li> a "mode" is a video format, consisting of at least width, height and framerate. Specifically, VESA CVT modelines are used, and can be generated with the <code>cvt</code> utility.
  <ul>
  <li> xrandr's addmode and delmode refer to associating an existing mode with a display output
  </li><li> xrandr's newmode and rmmode refer to adding a new mode to the server, that can then be associated with an output
  </li></ul>
</li></ul><p>

Note that this list is specific to xrandr, in other aspects of linux, the terms "output", "display", "monitor" and "screen" are often used differently. </p><p>

On my laptop, calling xrandr shows five video outputs: eDP-1, which is the main screen with a bazillion modes available, and four disconnected (HDMI-1, HDMI-2, DP-1, DP-2), presumably three of which are available via thunderbolt or something.</p><h3>Faking a monitor, attempt 1</h3><p>
Looking around, it seems the recommended way to do this is to convince xrandr that one of the unused video outputs is connected. For things like VNC there's a whole market for "dummy plugs" which make a video card think a monitor is connected. We obviously don't want or need to do that, we should be able to coax xrandr into behaving through software. </p><p>

In order to output our abnormally low resolution of 128x64 on HDMI, in theory we first generate a CVT modeline:</p><pre>$ cvt 128 64
# 128x64 39.06 Hz (CVT) hsync: 3.12 kHz; pclk: 0.50 MHz
Modeline "128x64_60.00"    0.50  128 136 144 160  64 67 77 80 -hsync +vsync
</pre><p>

then we add this mode to the x server:</p><pre>$ xrandr --newmode "128x64_60.00"    0.50  128 136 144 160  64 67 77 80 -hsync +vsync
</pre><p>

At this point, xrandr shows the unused mode at the end of its output. Confusingly it looks like the mode is part of the last output listed, but it isn't (yet). We next add this mode to one of the outputs:</p><pre>xrandr --addmode HDMI-1 128x64_60.00
</pre><p>

and finally try to use it:</p><pre>xrandr --output HDMI-1 --mode 128x64_60.00 --right-of eDP-1
</pre><p>

I should point out, I've a hotkey on my laptop which cycles through sane display modes, so I'm comfortable trying whatever here, but otherwise there's a chance you end up unable to see anything. It should still be possible to access the other virtual terminals with ctrl+alt+F2 etc, since these configure the display using KMS (Kernel Mode Setting) that sits a layer below the X server.</p><p>

I tried this with both HDMI-1 and HDMI-2. Both of them are listed as disconnected. Our cable connected to HDMI-1 is pulling the Hot Plug Detect pin high, but not responding to regular DDC queries.</p><p>

I may not have exhausted all possibilities, but I couldn't get this to work. I suspect the video driver simply can't cope with this ludicrously nonstandard resolution, and the modeline is just junk. The 39.06Hz certainly raised one of my eyebrows. I tried again specifically setting the framerate to 39.06Hz also, to no avail.</p><p>

Honestly, abusing the video outputs like this feels like a poor solution anyway.</p><p>

To clean up this mess, first use <code>--delmode</code> to free up the modes from any outputs, then <code>--rmmode</code> to remove them from the X server.</p><h3>Faking a monitor, attempt 2</h3><p>
When you change display settings xrandr generally sets all the relevant settings automatically, but if we go deeper we can manually fiddle with them. Following another idea on the internet, we should be able to make a virtual monitor by simply extending the framebuffer, and defining a monitor to be there, without bothering to associate it with an output.</p><p>

Interestingly, if you make the framebuffer bigger than needed, by default it will automatically pan when your mouse approaches the border. Useful to know, but here we need to specifically stop that happening. The <code>--panning</code> option takes up to twelve parameters, for panning area, tracking area, and border. Tracking is the area our mouse cursor is limited to. Normally, panning, tracking and framebuffer are all set to the same size. I'm not sure what "border" represents in the context of panning, it didn't seem to have any effect when I played with it.</p><p>

Setting panning to 0x0 will disable it, but that also limits the tracking area, so our mouse won't be able to reach the new bit of framebuffer. Instead we limit panning to the size of the main monitor, effectively disabling it, and extend the tracking area into our new chunk of framebuffer. The full command:</p><pre>xrandr --fb 2048x1080 --output eDP-1 --panning 1920x1080/2048x1080
</pre><p>

Then we can define a new monitor to exist in this new chunk of framebuffer:</p><pre>xrandr --setmonitor virtual 128/22x64/11+1920+0 none
</pre><p>

The size is set in both pixels and mm, I guessed it's approximately 22m by 11mm, it doesn't really matter though. "virtual" is the name of this monitor, we could call it anything. "none" is the output. We can see monitors with <code>xrandr --listmonitors</code> and later undo this muck with <code>xrandr --delmonitor virtual</code>.</p><p>

I can now point my script to dump that bit of framebuffer onto the OLED screen. Hurrah! One slight issue with this method is that the tracking is not L-shaped, my mouse can access the strip of framebuffer that doesn't correspond to any monitor. I don't know if there's an easy fix for this, but if it really bothered us we could enforce valid cursor positions through Xlib in our script.</p><h3>Reading the framebuffer</h3><p>
I assumed I'd need to throw away the python script at this point but there's <code>python-xlib</code> which gives us access to most of what we need. It's a little irritating that there isn't really any documentation, and the method names are not identical, for instance <code>XGetImage</code> is now <code>root.get_image</code>.</p><p>

Here is some trivia: did you know that the mouse cursor is rendered by hardware? It makes sense, I suppose. It also explains why the mouse cursor isn't normally captured when you take a screenshot. But we want to capture the framebuffer <i>and the mouse on top of it</i> so there's a lot more work involved.</p><p>

Getting the cursor image would normally be achieved through <code>XFixesCursorImage</code> but <code>python-xlib</code> hasn't yet implemented all of XFixes. I was prepared to start over in C until I spotted someone's done all the work for me with <a href="https://github.com/zorvios/PyXCursor">this repo</a> which binds to X11/XFixes using ctypes specifically to get the cursor information.</p><p>

We now have everything we need to capture the new virtual monitor image, superimpose the cursor in the right place (remembering to adjust for xhot and yhot, the pointer/cursor image offset), convert the result to a monochrome image with the right amount of bit-shuffling and pipe it to the display continuously.</p><p>

<img src="https://mitxela.com/img/uploads/blinken/oled/hdmi5.jpg" alt="OLED screen showing desktop, cursor and status bar"></p><p>

That's i3 workspace four, with a completely crushed i3status and incomprehensible dithered top corner of my background image. Beautiful!</p><h3>Demo</h3><p>

<iframe width="704" height="396" src="https://www.youtube.com/embed/8UbVgUFfN8U" allowfullscreen=""></iframe></p><h3>Conclusion</h3><p>
To improve the framerate, we could enhance our script and only send the changes instead of redrawing the display each frame. As fantastic as this could be, given that I have absolutely no use for this tiny second screen anyway, I'm not particularly inclined to make it happen.</p><p>

If for some mad reason you want to try this out yourself, the script can be <a href="https://github.com/mitxela/ddc-oled">found on github</a>.</p><p>

<b>Update:</b> How can we make the smallest and worst "HDMI" display even sillier? Make it <a href="https://mitxela.com/projects/steampunk-oled">steampunk</a>.</p><nav>
<a href="https://mitxela.com/projects/random" title="random project">~</a>
<span typeof="v:Breadcrumb"><a rel="v:url" property="v:title" href="https://mitxela.com/">mitxela.com</a></span> » 
<span typeof="v:Breadcrumb"><a rel="v:url" property="v:title" href="https://mitxela.com/projects">Projects</a></span> » 
<span typeof="v:Breadcrumb"><a rel="v:url" property="v:title" href="https://mitxela.com/projects/hardware">Hardware</a></span> »
<span typeof="v:Breadcrumb"><a rel="v:url" property="v:title" href="https://mitxela.com/projects/ddc-oled">DDC OLED</a></span>
<p>Questions? Comments? Check out the <a href="https://mitxela.com/forum">Forum</a>
</p><p><a href="https://mitxela.com/support">Support mitxela.com</a>
</p></nav></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I made a programmable computer from NAND gates (223 pts)]]></title>
            <link>https://github.com/ArhanChaudhary/NAND</link>
            <guid>40159278</guid>
            <pubDate>Thu, 25 Apr 2024 16:08:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ArhanChaudhary/NAND">https://github.com/ArhanChaudhary/NAND</a>, See on <a href="https://news.ycombinator.com/item?id=40159278">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/ArhanChaudhary/NAND/blob/main/media/logo.png"><img src="https://github.com/ArhanChaudhary/NAND/raw/main/media/logo.png" width="200"></a>
</p>
<hr>

<p dir="auto"><b>N</b> ot<br>
<b>A</b> <br>
<b>N</b> and-powered<br>
<b>D</b> evice</p>

<p dir="auto">is a Turing equivalent 16-bit computer made entirely from a <a href="https://en.wikipedia.org/wiki/Clock_rate" rel="nofollow">clock</a> and <a href="https://en.wikipedia.org/wiki/NAND_gate" rel="nofollow">NAND gates</a> emulated on the web. NAND features its own CPU, machine code language, assembly language, assembler, virtual machine language, virtual machine translator, programming language, compiler, IDE, and user interface. NAND is based on the Jack-VM-Hack platform specified in the <a href="https://www.nand2tetris.org/" rel="nofollow">Nand to Tetris course</a> and its <a href="https://www.amazon.com/Elements-Computing-Systems-second-Principles-dp-0262539802/dp/0262539802/ref=dp_ob_title_bk" rel="nofollow">associated book</a>.</p>
<details open="">
  <summary>
    
    <span aria-label="Video description demo.mp4">demo.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/57512390/318906352-7bedf191-d42c-4553-920f-01a539161bd3.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTQwNzU1MDcsIm5iZiI6MTcxNDA3NTIwNywicGF0aCI6Ii81NzUxMjM5MC8zMTg5MDYzNTItN2JlZGYxOTEtZDQyYy00NTUzLTkyMGYtMDFhNTM5MTYxYmQzLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA0MjUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNDI1VDIwMDAwN1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTEwMzNmMWM3Mzk0YzlhOGUxNzI5MzYyMTBhMGUzMjBlN2MzOGZhODQ0ZWZhMTQ1NTZkODQ5ZGJlNTYyMjIwN2MmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.RYMwa-nB36VvkpxtK4ayIs3uUrzZdn__kMPveEFJ47s" data-canonical-src="https://private-user-images.githubusercontent.com/57512390/318906352-7bedf191-d42c-4553-920f-01a539161bd3.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTQwNzU1MDcsIm5iZiI6MTcxNDA3NTIwNywicGF0aCI6Ii81NzUxMjM5MC8zMTg5MDYzNTItN2JlZGYxOTEtZDQyYy00NTUzLTkyMGYtMDFhNTM5MTYxYmQzLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA0MjUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNDI1VDIwMDAwN1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTEwMzNmMWM3Mzk0YzlhOGUxNzI5MzYyMTBhMGUzMjBlN2MzOGZhODQ0ZWZhMTQ1NTZkODQ5ZGJlNTYyMjIwN2MmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.RYMwa-nB36VvkpxtK4ayIs3uUrzZdn__kMPveEFJ47s" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h3 tabindex="-1" dir="auto">Table of Contents</h3><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#example-programs">Example programs</a>
<ul dir="auto">
<li><a href="#average">Average</a></li>
<li><a href="#pong">Pong</a></li>
<li><a href="#2048">2048</a></li>
<li><a href="#overflow">Overflow</a></li>
<li><a href="#secretpassword">SecretPassword</a></li>
<li><a href="#geneticalgorithm">GeneticAlgorithm</a></li>
</ul>
</li>
<li><a href="#writing-programs-for-nand">Writing programs for NAND</a>
<ul dir="auto">
<li><a href="#jack-introduction">Jack Introduction</a></li>
<li><a href="#custom-data-types">Custom Data Types</a></li>
<li><a href="#weak-type-coercions">Weak Type Coercions</a></li>
<li><a href="#manual-memory-management">Manual Memory Management</a></li>
<li><a href="#undefined-behavior">Undefined Behavior</a>
<ul dir="auto">
<li><a href="#operator-priority">Operator Priority</a></li>
<li><a href="#lesser-and-greater-than-operators">Lesser and Greater than Operators</a></li>
<li><a href="#-32768">-32768</a></li>
<li><a href="#calling-a-function-with-too-few-arguments">Calling a Function with Too Few Arguments</a></li>
<li><a href="#improper-type-casting">Improper Type Casting</a></li>
<li><a href="#stack-overflows">Stack Overflows</a></li>
<li><a href="#modifying-stack-frames-or-internal-registers">Modifying Stack Frames or Internal Registers</a></li>
</ul>
</li>
<li><a href="#hardware-specification">Hardware Specification</a></li>
<li><a href="#beyond-the-jack-os">Beyond the Jack OS</a></li>
</ul>
</li>
<li><a href="#how-does-nand-work">How does NAND work?</a></li>
<li><a href="#jack-reference">Jack Reference</a>
<ul dir="auto">
<li><a href="#program-structure">Program Structure</a></li>
<li><a href="#syntax">Syntax</a></li>
<li><a href="#variables">Variables</a></li>
<li><a href="#statements">Statements</a></li>
</ul>
</li>
<li><a href="#jack-os-reference">Jack OS Reference</a>
<ul dir="auto">
<li><a href="#array">Array</a></li>
<li><a href="#keyboard">Keyboard</a></li>
<li><a href="#math">Math</a></li>
<li><a href="#memory">Memory</a></li>
<li><a href="#output">Output</a></li>
<li><a href="#screen">Screen</a></li>
<li><a href="#string">String</a></li>
<li><a href="#sys">Sys</a></li>
<li><a href="#error-codes">Error Codes</a></li>
</ul>
</li>
<li><a href="#faq">FAQ</a>
<ul dir="auto">
<li><a href="#whoa-is-everything-made-from-nand-gates">Whoa, is <em>everything</em> made from NAND gates?</a></li>
<li><a href="#did-you-design-nand-by-yourself">Did you design NAND by yourself?</a></li>
<li><a href="#if-theres-only-one-type-what-is-the-point-of-specifying-types-at-all">If there's only one type, what is the point of specifying types at all?</a></li>
<li><a href="#why-does-the-ide-feel-finnicky">Why does the IDE feel finnicky?</a></li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Example programs</h2><a id="user-content-example-programs" aria-label="Permalink: Example programs" href="#example-programs"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Average</h3><a id="user-content-average" aria-label="Permalink: Average" href="#average"></a></p>
<p dir="auto">A simple program that inputs some numbers and computes their average, showing off control flow, arithmetic operations, I/O, and dynamic memory allocation.</p>
<p dir="auto">Program output:</p>
<div data-snippet-clipboard-copy-content="How many numbers? 4
Enter a number: 100
Enter a number: 42
Enter a number: 400
Enter a number: 300
The average is 210"><pre><code>How many numbers? 4
Enter a number: 100
Enter a number: 42
Enter a number: 400
Enter a number: 300
The average is 210
</code></pre></div>
<p dir="auto"><em>This program was supplied by the Nand to Tetris software suite.</em></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Pong</h3><a id="user-content-pong" aria-label="Permalink: Pong" href="#pong"></a></p>
<p dir="auto">The game of Pong, showing off the language's object-oriented model. Use the arrow keys to move the paddle left and right to bounce a ball. Every bounce, the paddle becomes smaller, and the game ends when the ball hits the bottom of the screen.</p>
<p dir="auto"><em>This program was supplied by the Nand to Tetris software suite.</em></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">2048</h3><a id="user-content-2048" aria-label="Permalink: 2048" href="#2048"></a></p>
<p dir="auto">The game of 2048, showing off recursion and complex application logic. Use the arrow keys to move the numbers around the 4x4 grid. The same numbers combine into their sum when moved into each other. Once the 2048 tile is reached, you win the game, though you can keep playing on until you lose. You lose the game when the board is full and you can't make any more moves.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Overflow</h3><a id="user-content-overflow" aria-label="Permalink: Overflow" href="#overflow"></a></p>
<p dir="auto">A program that deliberately causes a stack overflow via infinite recursion to perform a <a href="https://en.wikipedia.org/wiki/Virtual_machine_escape" rel="nofollow">virtual machine escape</a>. It leverages the fact that there are no runtime checks to prevent a stack overflow. No other modern platform will let you do this :-)</p>
<p dir="auto">Upon running, the program will constantly print the stack pointer to the screen. Once this displayed value exceeds 2048, the stack will have reached the end of its intended memory space and spill onto the heap memory space, causing the print statement to malfunction in explosive fashion:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ArhanChaudhary/NAND/blob/main/media/overflow.png"><img src="https://github.com/ArhanChaudhary/NAND/raw/main/media/overflow.png" width="700"></a></p>
<p dir="auto">Two things of noteworthy interest are worth pointing out.</p>
<p dir="auto">If you reload the page and run this program on an empty RAM (a RAM full of zeroes), you will notice that the program resets itself halfway through its execution despite not pressing the "Reset" button. Why this happens is simple: the jailbroken runtime executes an instruction that sets the <a href="https://en.wikipedia.org/wiki/Program_counter" rel="nofollow">program counter</a>'s value to 0, effectively telling the program to jump to the first instruction and start over.</p>
<p dir="auto">If you run the GeneticAlgorithm example program and then run this immediately afterwards, the program in its rampage reads old RAM memory that was simply never overwritten.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ArhanChaudhary/NAND/blob/main/media/old_memory.png"><img src="https://github.com/ArhanChaudhary/NAND/raw/main/media/old_memory.png" width="700"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">SecretPassword</h3><a id="user-content-secretpassword" aria-label="Permalink: SecretPassword" href="#secretpassword"></a></p>
<p dir="auto">A program that exploits the fact that the runtime doesn't prevent <a href="https://en.wikipedia.org/wiki/Stack_buffer_overflow" rel="nofollow">stack smashing</a> to call a function that would otherwise be inaccessible. In order to understand how this works, let's examine this illustration of NAND's stack frame layout.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ArhanChaudhary/NAND/blob/main/media/stack_layout.png"><img src="https://github.com/ArhanChaudhary/NAND/raw/main/media/stack_layout.png" width="700"></a></p>
<p dir="auto"><em>taken from the <a href="https://www.amazon.com/Elements-Computing-Systems-second-Principles-dp-0262539802/dp/0262539802/ref=dp_ob_title_bk" rel="nofollow">Nand to Tetris book</a>.</em></p>
<p dir="auto">If you're unfamiliar with stack layouts, here's the main idea behind the exploit. Whenever a function returns, it needs to know where (which machine code instruction memory address) it should go to proceed with execution flow. So, when the function is first called, this memory address, along with some other unimportant data, is temporarily stored on the stack in a memory region referred to as the <a href="https://en.wikipedia.org/wiki/Call_stack#STACK-FRAME" rel="nofollow">stack frame</a> as a reference for where to return. The illustration describes the exact position of this return address relative to the function call, a position that can be reverse engineered.</p>
<p dir="auto">The program enables the user to overwrite a single memory address in the RAM to any value. Putting two and two together, if the user were to overwrite the return address of a stack frame with the address of another function, they essentially gain the ability to execute arbitrary code included in the program.</p>
<p dir="auto">Indeed, if you enter 267 as the memory location and 1715 as the value to overwrite, two numbers reverse engineered by manually inspecting the stack memory space and the assembler, you'll see this idea in working action.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ArhanChaudhary/NAND/blob/main/media/secret_password.png"><img src="https://github.com/ArhanChaudhary/NAND/raw/main/media/secret_password.png" width="700"></a></p>
<p dir="auto">This isn't a vulnerability unique to NAND. <a href="https://en.wikipedia.org/wiki/Buffer_overflow" rel="nofollow">It exists in C as well</a>! How cool!</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">GeneticAlgorithm</h3><a id="user-content-geneticalgorithm" aria-label="Permalink: GeneticAlgorithm" href="#geneticalgorithm"></a></p>
<p dir="auto">Believe it or not, out of the many, <em>many</em> different components of NAND, this single-handedly took the longest to develop!</p>
<p dir="auto">This program is a creature simulation that utilizes simple machine learning. It follows the artificial intelligence coded series (parts <a href="https://www.youtube.com/watch?v=VnwjxityDLQ" rel="nofollow">one</a> and <a href="https://www.youtube.com/watch?v=BOZfhUcNiqk" rel="nofollow">two</a>) from <a href="https://www.youtube.com/@CodeBullet" rel="nofollow">Code Bullet</a>. Make sure to check out his channel, he makes some really cool stuff!</p>
<details open="">
  <summary>
    
    <span aria-label="Video description 2024-04-20.18-02-35.mp4">2024-04-20.18-02-35.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/57512390/324208258-c0ecf5e9-26d0-4367-a1a9-0ed2ebc4098d.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTQwNzU1MDcsIm5iZiI6MTcxNDA3NTIwNywicGF0aCI6Ii81NzUxMjM5MC8zMjQyMDgyNTgtYzBlY2Y1ZTktMjZkMC00MzY3LWExYTktMGVkMmViYzQwOThkLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA0MjUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNDI1VDIwMDAwN1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTNmNWZkYzgyM2FiYzc5ZDllNTQ1M2Q5Njg0OTk5N2YyYTAzZTdjYTRmYjNiN2Q3MWZhMmE0NTliMTkwMmZiM2YmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.pabXH4zcZgCDclHFHDK3AlyJKYYIPzEiN-DHl0DoyVc" data-canonical-src="https://private-user-images.githubusercontent.com/57512390/324208258-c0ecf5e9-26d0-4367-a1a9-0ed2ebc4098d.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTQwNzU1MDcsIm5iZiI6MTcxNDA3NTIwNywicGF0aCI6Ii81NzUxMjM5MC8zMjQyMDgyNTgtYzBlY2Y1ZTktMjZkMC00MzY3LWExYTktMGVkMmViYzQwOThkLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA0MjUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNDI1VDIwMDAwN1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTNmNWZkYzgyM2FiYzc5ZDllNTQ1M2Q5Njg0OTk5N2YyYTAzZTdjYTRmYjNiN2Q3MWZhMmE0NTliMTkwMmZiM2YmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.pabXH4zcZgCDclHFHDK3AlyJKYYIPzEiN-DHl0DoyVc" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">Simply explained:</p>
<p dir="auto">Every dot has its own "brain" of acceleration vectors, and they evolve to reach a goal through natural selection. Every generation, dots that "die" closer to the goal are more likely to be selected as the parents for the next generation. Reproduction inherently causes some of the brain to mutate, wholly effectively simulating natural evolution.</p>
<p dir="auto">Nevertheless, there is much to be desired. Due to performance, the only factor dots use to evolve is their closeness to the goal upon death, endowing the natural selection algorithm with low entropy. Due to memory usage, there are smaller than satisfactory limits on the number of dots and the sizes of their brains. Lastly, due to technical complexity, re-placing obstacles during the simulation does not guarantee that the dots will have large enough brains to reach the goal. Brain sizes are only determined at the beginning of the program.</p>
<p dir="auto">I've utilized a myriad of optimization techniques to snake around the following hardware restrictions and make this possible:</p>
<ul dir="auto">
<li>NAND has a limited ROM memory space, meaning the program won't compile if there's too much code. In fact, the final version of this program uses 99.2% of the instruction memory space.</li>
<li>NAND has a limited RAM memory space, meaning the program has to be careful to optimize heap memory usage. In fact, the reason why the screen fills with static between generations is to use the screen memory space as temporary swap memory for the next generation — the RAM is already completely full!</li>
<li>NAND has no floating point type (decimal numbers) and can only represent the integers between -32768 and 32767, making calculating fitness less precise and more challenging to implement. <a href="https://en.wikipedia.org/wiki/Integer_overflow" rel="nofollow">Integer overflows</a> must also be accounted for.</li>
</ul>
<p dir="auto">To avoid beating around the bush, I've stuck to documenting these techniques and additional insights in this program's <a href="https://github.com/ArhanChaudhary/NAND/blob/main/src/example-programs/GeneticAlgorithm">codebase</a> for those interested.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Writing programs for NAND</h2><a id="user-content-writing-programs-for-nand" aria-label="Permalink: Writing programs for NAND" href="#writing-programs-for-nand"></a></p>
<p dir="auto"><strong>Before we start, the most important detail to remember about writing programs in Jack is that there is no operator priority; this is probably why your program isn't working.</strong></p>
<p dir="auto">For example, you should change: <br>
<code>4 * 2 + 3</code> to <code>(4 * 2) + 3</code> <br>
<code>if (~x &amp; y)</code> to <code>if ((~x) &amp; y)</code></p>
<p dir="auto">but you can keep <code>if (y &amp; ~x)</code> the same as there is no operator ambiguity.</p>
<p dir="auto">Without parenthesis, the evaluation value of an ambiguous expression is <strong>undefined</strong>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Jack Introduction</h3><a id="user-content-jack-introduction" aria-label="Permalink: Jack Introduction" href="#jack-introduction"></a></p>
<p dir="auto">NAND boasts its own complete tech stack. As a consequence, NAND can only be programmed in Jack, its weakly typed object-oriented programming language. In layman's terms, Jack is C with Java's syntax.</p>
<p dir="auto">Let's take the approach of example-based learning and dive right in.</p>
<div dir="auto" data-snippet-clipboard-copy-content="/**
 * This program prompts the user to enter a phrase
 * and an energy level. Program output:
 *
 * Whats on your mind? Superman
 * Whats your energy level? 3
 * Superman!
 * Superman!
 * Superman!
 */
class Main {
    function void main() {
        var String s;
        var int energy, i;
        let s = Keyboard.readLine(&quot;Whats on your mind? &quot;);
        let energy = Keyboard.readInt(&quot;Whats your energy level? &quot;);
        let i = 0;
        let s = s.appendChar(33); // Appends the character '!'
        while (i < energy) {
            do Output.printString(s);
            do Output.println();
            let i = i + 1;
        }
    }
}"><pre><span>/**</span>
<span> * This program prompts the user to enter a phrase</span>
<span> * and an energy level. Program output:</span>
<span> *</span>
<span> * Whats on your mind? Superman</span>
<span> * Whats your energy level? 3</span>
<span> * Superman!</span>
<span> * Superman!</span>
<span> * Superman!</span>
<span> */</span>
<span>class</span> <span>Main</span> <span>{</span>
    <span>function</span> <span>void</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
        <span>var</span> <span>String</span> <span>s</span><span>;</span>
        <span>var</span> <span>int</span> <span>energy</span><span>,</span> <span>i</span><span>;</span>
        <span>let</span> <span>s</span> <span>=</span> <span>Keyboard</span><span>.</span><span>readLine</span><span>(</span><span>"Whats on your mind? "</span><span>)</span><span>;</span>
        <span>let</span> <span>energy</span> <span>=</span> <span>Keyboard</span><span>.</span><span>readInt</span><span>(</span><span>"Whats your energy level? "</span><span>)</span><span>;</span>
        <span>let</span> <span>i</span> <span>=</span> <span>0</span><span>;</span>
        <span>let</span> <span>s</span> <span>=</span> <span>s</span><span>.</span><span>appendChar</span><span>(</span><span>33</span><span>)</span><span>;</span> <span>// Appends the character '!'</span>
        <span>while</span> <span>(</span><span>i</span> <span>&lt;</span> <span>energy</span><span>)</span> <span>{</span>
            <span>do</span> <span>Output</span><span>.</span><span>printString</span><span>(</span><span>s</span><span>)</span><span>;</span>
            <span>do</span> <span>Output</span><span>.</span><span>println</span><span>(</span><span>)</span><span>;</span>
            <span>let</span> <span>i</span> <span>=</span> <span>i</span> <span>+</span> <span>1</span><span>;</span>
        <span>}</span>
    <span>}</span>
<span>}</span></pre></div>
<p dir="auto"><em>taken from the <a href="https://drive.google.com/file/d/1CAGF8d3pDIOgqX8NZGzU34PPEzvfTYrk/view" rel="nofollow">Nand to Tetris lecture slides</a>.</em></p>
<p dir="auto">If you've already had some experience with programming, this should look very familiar; it is clear that Jack was heavily inspired by Java. <code>Main.main</code> is the entry point to the program. The code segment demonstrates basic usage of variables as well as the while loop for control flow.</p>
<p dir="auto">Additionally, it uses <code>Keyboard.readLine</code> and <code>Keyboard.readInt</code> to read input from the user, and <code>Output.printString</code> and <code>Output.println</code> to print output to the screen — all of which are defined in detail in the <a href="#jack-os">Jack OS Reference</a>. By default, the Jack OS is bundled with your program during compilation to enable interfacing with strings, memory, hardware, and more.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Custom Data Types</h3><a id="user-content-custom-data-types" aria-label="Permalink: Custom Data Types" href="#custom-data-types"></a></p>
<p dir="auto">Every programming language has a fixed set of primitive data types. Jack supports three: <code>int</code>, <code>char</code>, and <code>boolean</code>. You can extend this basic repertoire with your own abstract data types as needed. Prior knowledge about <a href="https://en.wikipedia.org/wiki/Object-oriented_programming" rel="nofollow">object-oriented programming</a> directly carries over to this section.</p>

<div dir="auto" data-snippet-clipboard-copy-content="/** Represents a point in 2D plane. */
class Point {
    // The coordinates of the current point instance:
    field int x, y;
    // The number of point objects constructed so far:
    static int pointCount;
    /** Constructs a point and initializes
        it with the given coordinates */
    constructor Point new(int ax, int ay) {
      let x = ax;
      let y = ay;
      let pointCount = pointCount + 1;
      return this;
    }
    /** Returns the x coordinate of the current point instance */
    method int getx() { return x; }
    /** Returns the y coordinate of the current point instance */
    method int gety() { return y; }
    /** Returns the number of Points constructed so far */
    function int getPointCount() {
        return pointCount;
    }
    /** Returns a point which is this
        point plus the other point */
    method Point plus(Point other) {
        return Point.new(x + other.getx(),
                         y + other.gety());
    }
    /** Returns the Euclidean distance between the
        current point instance and the other point */
    method int distance(Point other) {
        var int dx, dy;
        let dx = x - other.getx();
        let dy = y - other.gety();
        return Math.sqrt((dx * dx) + (dy * dy));
    }
    /** Prints the current point instance, as &quot;(x, y)&quot; */
    method void print() {
        var String tmp;
        let tmp = &quot;(&quot;;
        do Output.printString(tmp);
        do tmp.dispose();
        do Output.printInt(x);
        let tmp = &quot;, &quot;;
        do Output.printString(tmp);
        do tmp.dispose();
        do Output.printInt(y);
        let tmp = &quot;)&quot;;
        do Output.printString(tmp);
        do tmp.dispose();
    }
}"><pre><span>/** Represents a point in 2D plane. */</span>
<span>class</span> <span>Point</span> <span>{</span>
    <span>// The coordinates of the current point instance:</span>
    <span>field</span> <span>int</span> <span>x</span><span>,</span> <span>y</span><span>;</span>
    <span>// The number of point objects constructed so far:</span>
    <span>static</span> <span>int</span> <span>pointCount</span><span>;</span>
    <span>/** Constructs a point and initializes</span>
<span>        it with the given coordinates */</span>
    <span>constructor</span> <span>Point</span> <span>new</span><span>(</span><span>int</span> <span>ax</span><span>,</span> <span>int</span> <span>ay</span><span>)</span> <span>{</span>
      <span>let</span> <span>x</span> <span>=</span> <span>ax</span><span>;</span>
      <span>let</span> <span>y</span> <span>=</span> <span>ay</span><span>;</span>
      <span>let</span> <span>pointCount</span> <span>=</span> <span>pointCount</span> <span>+</span> <span>1</span><span>;</span>
      <span>return</span> <span>this</span><span>;</span>
    <span>}</span>
    <span>/** Returns the x coordinate of the current point instance */</span>
    <span>method</span> <span>int</span> <span>getx</span><span>(</span><span>)</span> <span>{</span> <span>return</span> <span>x</span><span>;</span> <span>}</span>
    <span>/** Returns the y coordinate of the current point instance */</span>
    <span>method</span> <span>int</span> <span>gety</span><span>(</span><span>)</span> <span>{</span> <span>return</span> <span>y</span><span>;</span> <span>}</span>
    <span>/** Returns the number of Points constructed so far */</span>
    <span>function</span> <span>int</span> <span>getPointCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>pointCount</span><span>;</span>
    <span>}</span>
    <span>/** Returns a point which is this</span>
<span>        point plus the other point */</span>
    <span>method</span> <span>Point</span> <span>plus</span><span>(</span><span>Point</span> <span>other</span><span>)</span> <span>{</span>
        <span>return</span> <span>Point</span><span>.</span><span>new</span><span>(</span><span>x</span> <span>+</span> <span>other</span><span>.</span><span>getx</span><span>(</span><span>)</span><span>,</span>
                         <span>y</span> <span>+</span> <span>other</span><span>.</span><span>gety</span><span>(</span><span>)</span><span>)</span><span>;</span>
    <span>}</span>
    <span>/** Returns the Euclidean distance between the</span>
<span>        current point instance and the other point */</span>
    <span>method</span> <span>int</span> <span>distance</span><span>(</span><span>Point</span> <span>other</span><span>)</span> <span>{</span>
        <span>var</span> <span>int</span> <span>dx</span><span>,</span> <span>dy</span><span>;</span>
        <span>let</span> <span>dx</span> <span>=</span> <span>x</span> <span>-</span> <span>other</span><span>.</span><span>getx</span><span>(</span><span>)</span><span>;</span>
        <span>let</span> <span>dy</span> <span>=</span> <span>y</span> <span>-</span> <span>other</span><span>.</span><span>gety</span><span>(</span><span>)</span><span>;</span>
        <span>return</span> <span>Math</span><span>.</span><span>sqrt</span><span>(</span><span>(</span><span>dx</span> <span>*</span> <span>dx</span><span>)</span> <span>+</span> <span>(</span><span>dy</span> <span>*</span> <span>dy</span><span>)</span><span>)</span><span>;</span>
    <span>}</span>
    <span>/** Prints the current point instance, as "(x, y)" */</span>
    <span>method</span> <span>void</span> <span>print</span><span>(</span><span>)</span> <span>{</span>
        <span>var</span> <span>String</span> <span>tmp</span><span>;</span>
        <span>let</span> <span>tmp</span> <span>=</span> <span>"("</span><span>;</span>
        <span>do</span> <span>Output</span><span>.</span><span>printString</span><span>(</span><span>tmp</span><span>)</span><span>;</span>
        <span>do</span> <span>tmp</span><span>.</span><span>dispose</span><span>(</span><span>)</span><span>;</span>
        <span>do</span> <span>Output</span><span>.</span><span>printInt</span><span>(</span><span>x</span><span>)</span><span>;</span>
        <span>let</span> <span>tmp</span> <span>=</span> <span>", "</span><span>;</span>
        <span>do</span> <span>Output</span><span>.</span><span>printString</span><span>(</span><span>tmp</span><span>)</span><span>;</span>
        <span>do</span> <span>tmp</span><span>.</span><span>dispose</span><span>(</span><span>)</span><span>;</span>
        <span>do</span> <span>Output</span><span>.</span><span>printInt</span><span>(</span><span>y</span><span>)</span><span>;</span>
        <span>let</span> <span>tmp</span> <span>=</span> <span>")"</span><span>;</span>
        <span>do</span> <span>Output</span><span>.</span><span>printString</span><span>(</span><span>tmp</span><span>)</span><span>;</span>
        <span>do</span> <span>tmp</span><span>.</span><span>dispose</span><span>(</span><span>)</span><span>;</span>
    <span>}</span>
<span>}</span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="var Point p1, p2, p3;
let p1 = Point.new(1, 2);
let p2 = Point.new(3, 4);
let p3 = p1.plus(p2);
do p3.print(); // prints (4, 6)
do Output.println();
do Output.printInt(p1.distance(p2)); // prints 5
do Output.println();
do Output.printInt(getPointCount()); // prints 3"><pre><span>var</span> <span>Point</span> <span>p1</span><span>,</span> <span>p2</span><span>,</span> <span>p3</span><span>;</span>
<span>let</span> <span>p1</span> <span>=</span> <span>Point</span><span>.</span><span>new</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span><span>;</span>
<span>let</span> <span>p2</span> <span>=</span> <span>Point</span><span>.</span><span>new</span><span>(</span><span>3</span><span>,</span> <span>4</span><span>)</span><span>;</span>
<span>let</span> <span>p3</span> <span>=</span> <span>p1</span><span>.</span><span>plus</span><span>(</span><span>p2</span><span>)</span><span>;</span>
<span>do</span> <span>p3</span><span>.</span><span>print</span><span>(</span><span>)</span><span>;</span> <span>// prints (4, 6)</span>
<span>do</span> <span>Output</span><span>.</span><span>println</span><span>(</span><span>)</span><span>;</span>
<span>do</span> <span>Output</span><span>.</span><span>printInt</span><span>(</span><span>p1</span><span>.</span><span>distance</span><span>(</span><span>p2</span><span>)</span><span>)</span><span>;</span> <span>// prints 5</span>
<span>do</span> <span>Output</span><span>.</span><span>println</span><span>(</span><span>)</span><span>;</span>
<span>do</span> <span>Output</span><span>.</span><span>printInt</span><span>(</span><span>getPointCount</span><span>(</span><span>)</span><span>)</span><span>;</span> <span>// prints 3</span></pre></div>
<p dir="auto"><em>taken from the <a href="https://drive.google.com/file/d/1CAGF8d3pDIOgqX8NZGzU34PPEzvfTYrk/view" rel="nofollow">Nand to Tetris lecture slides</a>.</em></p>
<p dir="auto">We define a <code>Point</code> class to represent an abstract point in space. It uses <code>field</code> variables to declare per-instance attributes of the data type. It exposes public <code>method</code> functions we can use to interface with the point, giving the caller the functionality to add two points together and calculate the distance between two points.</p>
<p dir="auto">All <code>field</code> variables are privately scoped. If you wish to get or set these variables from outside the class declaration, these variables must have corresponding <code>method</code> functions to provide this functionality.</p>
<p dir="auto">Omitted from the code sample to stay on-topic, it is customary for data classes to define <code>dispose</code> methods for deallocation once objects are no longer needed. See <a href="#manual-memory-management">Manual Memory Management</a>.</p>
<p dir="auto">If needed, here's a reference for <code>function</code> and <code>method</code> calling syntax.</p>

<div dir="auto" data-snippet-clipboard-copy-content="class Foo {
    ...
    method void f() {
        var Bar b; // Declares a local variable of class type Bar
        var int i; // Declares a local variable of primitive type int

        do g(); // Calls method g of the current class on the current object instance
                // Note: Cannot be called from within a function (static method)

        do Foo.p(3); // Calls function p of the current class;
                     // Note: A function call must be preceded by the class name

        do Bar.h();      // Calls function h of class Bar
        let b = Bar.r(); // Calls function or constructor r of class Bar
        do b.q();        // Calls method q of class Bar on the b object
    }
}"><pre><span>class</span> <span>Foo</span> <span>{</span>
    ...
    <span>method</span> <span>void</span> <span>f</span><span>(</span><span>)</span> <span>{</span>
        <span>var</span> <span>Bar</span> <span>b</span><span>;</span> <span>// Declares a local variable of class type Bar</span>
        <span>var</span> <span>int</span> <span>i</span><span>;</span> <span>// Declares a local variable of primitive type int</span>

        <span>do</span> <span>g</span><span>(</span><span>)</span><span>;</span> <span>// Calls method g of the current class on the current object instance</span>
                <span>// Note: Cannot be called from within a function (static method)</span>

        <span>do</span> <span>Foo</span><span>.</span><span>p</span><span>(</span><span>3</span><span>)</span><span>;</span> <span>// Calls function p of the current class;</span>
                     <span>// Note: A function call must be preceded by the class name</span>

        <span>do</span> <span>Bar</span><span>.</span><span>h</span><span>(</span><span>)</span><span>;</span>      <span>// Calls function h of class Bar</span>
        <span>let</span> <span>b</span> <span>=</span> <span>Bar</span><span>.</span><span>r</span><span>(</span><span>)</span><span>;</span> <span>// Calls function or constructor r of class Bar</span>
        <span>do</span> <span>b</span><span>.</span><span>q</span><span>(</span><span>)</span><span>;</span>        <span>// Calls method q of class Bar on the b object</span>
    <span>}</span>
<span>}</span></pre></div>
<p dir="auto"><em>taken from the <a href="https://drive.google.com/file/d/1CAGF8d3pDIOgqX8NZGzU34PPEzvfTYrk/view" rel="nofollow">Nand to Tetris lecture slides</a>.</em></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Weak Type Coercions</h3><a id="user-content-weak-type-coercions" aria-label="Permalink: Weak Type Coercions" href="#weak-type-coercions"></a></p>
<p dir="auto">Remember how we said Jack was similar to Java? That was a facade, or at best misleading. While Java is strongly-typed and as such supports complex type features such as down casting, polymorphism, and inheritance, Jack supports none of these and only has one type under the hood: the signed 16-bit integer. This is the primary reason why Jack is so weakly-typed. In effect, the compiler won't care if you mix and match different types in assignments and operations.</p>
<div dir="auto" data-snippet-clipboard-copy-content="var char c;
var String s;
let c = 65; // 'A'
// Equivalently
let s = &quot;A&quot;;
let c = s.charAt(0);"><pre><span>var</span> <span>char</span> <span>c</span><span>;</span>
<span>var</span> <span>String</span> <span>s</span><span>;</span>
<span>let</span> <span>c</span> <span>=</span> <span>65</span><span>;</span> <span>// 'A'</span>
<span>// Equivalently</span>
<span>let</span> <span>s</span> <span>=</span> <span>"A"</span><span>;</span>
<span>let</span> <span>c</span> <span>=</span> <span>s</span><span>.</span><span>charAt</span><span>(</span><span>0</span><span>)</span><span>;</span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="var Array a;
let a = 5000;
let a[100] = 77; // RAM[5100] = 77"><pre><span>var</span> <span>Array</span> <span>a</span><span>;</span>
<span>let</span> <span>a</span> <span>=</span> <span>5000</span><span>;</span>
<span>let</span> <span>a</span><span></span><span>[</span><span>100</span><span>]</span> <span>=</span> <span>77</span><span>;</span> <span>// RAM[5100] = 77</span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="var Array arr;
var String helloWorld;
let helloWorld = &quot;Hello World!&quot;
let arr = Array.new(4); // Arrays are not strictly typed
let arr[0] = 12;
let arr[1] = false;
let arr[2] = Point.new(5, 6);
let arr[3] = helloWorld;"><pre><span>var</span> <span>Array</span> <span>arr</span><span>;</span>
<span>var</span> <span>String</span> <span>helloWorld</span><span>;</span>
<span>let</span> <span>helloWorld</span> <span>=</span> <span>"Hello World!"</span>
<span>let</span> <span>arr</span> <span>=</span> <span>Array</span><span>.</span><span>new</span><span>(</span><span>4</span><span>)</span><span>;</span> <span>// Arrays are not strictly typed</span>
<span>let</span> <span>arr</span><span></span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>12</span><span>;</span>
<span>let</span> <span>arr</span><span></span><span>[</span><span>1</span><span>]</span> <span>=</span> <span>false</span><span>;</span>
<span>let</span> <span>arr</span><span></span><span>[</span><span>2</span><span>]</span> <span>=</span> <span>Point</span><span>.</span><span>new</span><span>(</span><span>5</span><span>,</span> <span>6</span><span>)</span><span>;</span>
<span>let</span> <span>arr</span><span></span><span>[</span><span>3</span><span>]</span> <span>=</span> <span>helloWorld</span><span>;</span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="class Complex {
    field int real;
    field int imaginary;
    ...
}
...
var Complex c;
var Array a;
let a = Array.new(2);
let a[0] = 7;
let a[1] = 8;
let c = a; // c == Complex(7, 8)
           // Works because it matches the memory layout
           // of the Complex type"><pre><span>class</span> <span>Complex</span> <span>{</span>
    <span>field</span> <span>int</span> <span>real</span><span>;</span>
    <span>field</span> <span>int</span> <span>imaginary</span><span>;</span>
    ...
<span>}</span>
<span>.</span><span>.</span><span>.</span>
<span>var</span> <span>Complex</span> <span>c</span><span>;</span>
<span>var</span> <span>Array</span> <span>a</span><span>;</span>
<span>let</span> <span>a</span> <span>=</span> <span>Array</span><span>.</span><span>new</span><span>(</span><span>2</span><span>)</span><span>;</span>
<span>let</span> <span>a</span><span></span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>7</span><span>;</span>
<span>let</span> <span>a</span><span></span><span>[</span><span>1</span><span>]</span> <span>=</span> <span>8</span><span>;</span>
<span>let</span> <span>c</span> <span>=</span> <span>a</span><span>;</span> <span>// c == Complex(7, 8)</span>
           <span>// Works because it matches the memory layout</span>
           <span>// of the Complex type</span></pre></div>
<p dir="auto"><em>all code segments taken from the <a href="https://drive.google.com/file/d/1CAGF8d3pDIOgqX8NZGzU34PPEzvfTYrk/view" rel="nofollow">Nand to Tetris lecture slides</a>.</em></p>
<p dir="auto">Don't take this the wrong way — Jack still provides a powerful and functional object-oriented model. This insight intends to help you understand when and how you should perform type conversions as needed.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Manual Memory Management</h3><a id="user-content-manual-memory-management" aria-label="Permalink: Manual Memory Management" href="#manual-memory-management"></a></p>
<p dir="auto">Let's say you're a crazy cat lover, just like me! And you wanted to write this program to show off just how much you absolutely adore cats.</p>
<div dir="auto" data-snippet-clipboard-copy-content="class Main {
    function void main() {
        while (true) {
          do Output.printString(&quot;Kittens are so adorable! &quot;);
        }
    }
}"><pre><span>class</span> <span>Main</span> <span>{</span>
    <span>function</span> <span>void</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
        <span>while</span> <span>(</span><span>true</span><span>)</span> <span>{</span>
          <span>do</span> <span>Output</span><span>.</span><span>printString</span><span>(</span><span>"Kittens are so adorable! "</span><span>)</span><span>;</span>
        <span>}</span>
    <span>}</span>
<span>}</span></pre></div>
<p dir="auto">You may be startled to notice that after a few seconds, the program will crash with "ERR6", or a <a href="https://en.wikipedia.org/wiki/Heap_overflow" rel="nofollow">heap overflow</a>!</p>
<p dir="auto">Jack is a <a href="https://en.wikipedia.org/wiki/Manual_memory_management" rel="nofollow">manually memory managed</a> programming language. This means you must be vigilant to properly deallocate memory that is no longer needed, or else the Jack OS will think otherwise and facilitate a <a href="https://en.wikipedia.org/wiki/Memory_leak" rel="nofollow">memory leak</a>. The best practice advice is to feature a <code>dispose</code> method for each class that represents an object that properly encapsulates this deallocation. Thus, when objects are no longer needed, you can call their <code>dispose</code> methods to ensure you won't eventually run out of heap memory.</p>
<p dir="auto">If you've programmed in other manually memory managed languages, like C, this should look very familiar. One key difference is the Jack OS stores arrays and strings on the heap rather than on the stack, hinting to why the program crashes with a heap overflow.</p>
<p dir="auto">Let's fix this program for our fellow feline fanatics.</p>
<div dir="auto" data-snippet-clipboard-copy-content="class Main {
    function void main() {
        var String s;
        while (true) {
            let s = &quot;Kittens are so adorable! &quot;;
            do Output.printString(s);
            do s.dispose();
        }
    }
}"><pre><span>class</span> <span>Main</span> <span>{</span>
    <span>function</span> <span>void</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
        <span>var</span> <span>String</span> <span>s</span><span>;</span>
        <span>while</span> <span>(</span><span>true</span><span>)</span> <span>{</span>
            <span>let</span> <span>s</span> <span>=</span> <span>"Kittens are so adorable! "</span><span>;</span>
            <span>do</span> <span>Output</span><span>.</span><span>printString</span><span>(</span><span>s</span><span>)</span><span>;</span>
            <span>do</span> <span>s</span><span>.</span><span>dispose</span><span>(</span><span>)</span><span>;</span>
        <span>}</span>
    <span>}</span>
<span>}</span></pre></div>
<p dir="auto">Alternatively, you could allocate memory for the string only once.</p>
<div dir="auto" data-snippet-clipboard-copy-content="class Main {
    function void main() {
        var String s;
        let s = &quot;Kittens are so adorable! &quot;;
        while (true) {
            do Output.printString(s);
        }
    }
}"><pre><span>class</span> <span>Main</span> <span>{</span>
    <span>function</span> <span>void</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
        <span>var</span> <span>String</span> <span>s</span><span>;</span>
        <span>let</span> <span>s</span> <span>=</span> <span>"Kittens are so adorable! "</span><span>;</span>
        <span>while</span> <span>(</span><span>true</span><span>)</span> <span>{</span>
            <span>do</span> <span>Output</span><span>.</span><span>printString</span><span>(</span><span>s</span><span>)</span><span>;</span>
        <span>}</span>
    <span>}</span>
<span>}</span></pre></div>
<p dir="auto">You'll notice that not only do these alternative versions print the string much faster, but this time they'll actually print forever! Hooray!</p>
<p dir="auto">Let's quickly peek into <code>String.dispose</code> so you can better understand how to write your own <code>dispose</code> methods.</p>
<div dir="auto" data-snippet-clipboard-copy-content="method void dispose() {
    do stringArray.dispose();
    do Memory.deAlloc(this);
}"><pre><span>method</span> <span>void</span> <span>dispose</span><span>(</span><span>)</span> <span>{</span>
    <span>do</span> <span>stringArray</span><span>.</span><span>dispose</span><span>(</span><span>)</span><span>;</span>
    <span>do</span> <span>Memory</span><span>.</span><span>deAlloc</span><span>(</span><span>this</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto"><code>Array.dispose</code> called by <code>stringArray</code></p>
<div dir="auto" data-snippet-clipboard-copy-content="method void dispose() {
    do Memory.deAlloc(this);
}"><pre><span>method</span> <span>void</span> <span>dispose</span><span>(</span><span>)</span> <span>{</span>
    <span>do</span> <span>Memory</span><span>.</span><span>deAlloc</span><span>(</span><span>this</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto">Proper <code>dispose</code> methods must first appropriately call <code>dispose</code> on their field variables and then finish with <code>do Memory.deAlloc(this);</code> to deallocate the object instance itself.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Undefined Behavior</h3><a id="user-content-undefined-behavior" aria-label="Permalink: Undefined Behavior" href="#undefined-behavior"></a></p>
<p dir="auto">With how primitive Jack and NAND are, footguns within the language are inevitable. I've compiled the following instances of undefined behavior you should be aware of, ordered from (in my opinion) most important to least important.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Operator Priority</h4><a id="user-content-operator-priority" aria-label="Permalink: Operator Priority" href="#operator-priority"></a></p>
<p dir="auto">I found this caveat to be so important that I've moved it towards the <a href="#writing-programs-for-nand">beginning of this section</a>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Lesser and Greater than Operators</h4><a id="user-content-lesser-and-greater-than-operators" aria-label="Permalink: Lesser and Greater than Operators" href="#lesser-and-greater-than-operators"></a></p>
<p dir="auto">The Jack expressions</p>

<p dir="auto">are deceptively simple. They aren't always mathematically correct, and are respectively equivalent to the Java expressions</p>
<div dir="auto" data-snippet-clipboard-copy-content="((a - b) &amp; (1 << 15)) == 0 &amp;&amp; a != b
((a - b) &amp; (1 << 15)) != 0"><pre><span>(</span><span>(</span><span>a</span> <span>-</span> <span>b</span><span>)</span> <span>&amp;</span> <span>(</span><span>1</span> <span>&lt;&lt;</span> <span>15</span><span>)</span><span>)</span> <span>==</span> <span>0</span> <span>&amp;&amp;</span> <span>a</span> <span>!=</span> <span>b</span>
<span>(</span><span>(</span><span>a</span> <span>-</span> <span>b</span><span>)</span> <span>&amp;</span> <span>(</span><span>1</span> <span>&lt;&lt;</span> <span>15</span><span>)</span><span>)</span> <span>!=</span> <span>0</span></pre></div>
<p dir="auto">What's up with the nuance? The virtual machine implementation converts <code>a &gt; b</code> to <code>a - b &gt; 0</code>. Here's the problem: <code>a - b</code> can <a href="https://en.wikipedia.org/wiki/Integer_overflow" rel="nofollow">overflow</a> :(</p>
<p dir="auto">What does <code>20000 &gt; -20000</code> evaluate to? The virtual machine transpiles this to <code>20000 - (-20000) &gt; 0</code> which evaluates to <code>-25336 &gt; 0</code>. Unfortunately, the answer is <code>false</code>.</p>
<p dir="auto">However, <code>20000 &gt; -10000</code> evaluates to <code>30000 &gt; 0</code>, or <code>true</code>.</p>
<p dir="auto">As you may have figured, if the absolute distance between <code>a</code> and <code>b</code> is more than 32767, <code>a &gt; b</code> and <code>a &lt; b</code> are wrong. Otherwise, you're fine.</p>
<p dir="auto">This isn't an implementation bug, but rather an inconsistency with Nand to Tetris itself. More about it <a href="http://nand2tetris-questions-and-answers-forum.52.s1.nabble.com/Project-7-gt-and-lt-behavior-not-clearly-specified-for-signed-operands-td4036926.html#google_vignette" rel="nofollow">here</a>. For compatibility reasons, this behavior won't be fixed.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">-32768</h4><a id="user-content--32768" aria-label="Permalink: -32768" href="#-32768"></a></p>
<p dir="auto">-32768 is one of its kind. It is the only number that holds the property such that -(-32768) = -32768, a singleton without a positive counterpart<sup>*</sup>. This can lead to unsoundness and logic errors.</p>
<div dir="auto" data-snippet-clipboard-copy-content="/**
 * Program output:
 * --.)*(
 */
class Main {
    function void main() {
        // Note that -32768 must instead be written as ~32767
        // because the CPU can't load a number that large
        do Output.printInt(~32767);
    }
}"><pre><span>/**</span>
<span> * Program output:</span>
<span> * --.)*(</span>
<span> */</span>
<span>class</span> <span>Main</span> <span>{</span>
    <span>function</span> <span>void</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
        <span>// Note that -32768 must instead be written as ~32767</span>
        <span>// because the CPU can't load a number that large</span>
        <span>do</span> <span>Output</span><span>.</span><span>printInt</span><span>(</span><span>~</span><span>32767</span><span>)</span><span>;</span>
    <span>}</span>
<span>}</span></pre></div>
<p dir="auto"><code>Output.printInt</code> internally expects <code>Math.abs</code> to return a positive number. This isn't the case with -32768, so the Jack OS malfunctions.</p>
<p dir="auto">Your main concern should be handling logic errors with the negative operator. As the programmer, if you want to guarantee the negative of a negative number is positive, it is your responsibility to check for the case of -32768 and take appropriate action.</p>
<p dir="auto"><span id="user-content-note-1">*</span> This holds true because NAND's ALU internally processes the Jack expression <code>-x</code> as  <code>~(x - 1)</code>. Let's set <code>x</code> to <code>-32768</code> and evaluate it step by step. Here are the corresponding 16-bit <a href="https://en.wikipedia.org/wiki/Two%27s_complement" rel="nofollow">two's complement</a> binary representations of the computation:</p>
<p dir="auto"><code>x</code> = <code>1000 0000 0000 0000</code> <br>
<code>x - 1</code> = <code>0111 1111 1111 1111</code> <br>
<code>~(x - 1)</code> = <code>1000 0000 0000 0000</code> = <code>x</code></p>
<p dir="auto">It's the same thing! What happened here? Because NAND is a 16-bit machine, -32768 is the only number such that if you subtract one from it, you get its flipped bits. In other words, -32768 satisfies <code>x - 1 = ~x</code>, simplifying the expression to <code>~(~x)</code> or just <code>x</code>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Calling a Function with Too Few Arguments</h4><a id="user-content-calling-a-function-with-too-few-arguments" aria-label="Permalink: Calling a Function with Too Few Arguments" href="#calling-a-function-with-too-few-arguments"></a></p>
<p dir="auto">This one is self-explanatory, so here's a brief demonstration.</p>
<div dir="auto" data-snippet-clipboard-copy-content="/**
 * Program output:
 * I have 818 cookies.
 */
class Main {
    function void main() {
        do Main.cookies();
    }

    function void cookies(int a) {
        do Output.printString(&quot;I have &quot;);
        do Output.printInt(a);
        do Output.printString(&quot; cookies.&quot;);
    }
}"><pre><span>/**</span>
<span> * Program output:</span>
<span> * I have 818 cookies.</span>
<span> */</span>
<span>class</span> <span>Main</span> <span>{</span>
    <span>function</span> <span>void</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
        <span>do</span> <span>Main</span><span>.</span><span>cookies</span><span>(</span><span>)</span><span>;</span>
    <span>}</span>

    <span>function</span> <span>void</span> <span>cookies</span><span>(</span><span>int</span> <span>a</span><span>)</span> <span>{</span>
        <span>do</span> <span>Output</span><span>.</span><span>printString</span><span>(</span><span>"I have "</span><span>)</span><span>;</span>
        <span>do</span> <span>Output</span><span>.</span><span>printInt</span><span>(</span><span>a</span><span>)</span><span>;</span>
        <span>do</span> <span>Output</span><span>.</span><span>printString</span><span>(</span><span>" cookies."</span><span>)</span><span>;</span>
    <span>}</span>
<span>}</span></pre></div>
<p dir="auto">On the other hand, calling a function with too <em>many</em> arguments is perfectly valid. You can use the <code>arguments</code> keyword to index extra function arguments. Note that there is no indicator for the argument count.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Improper Type Casting</h4><a id="user-content-improper-type-casting" aria-label="Permalink: Improper Type Casting" href="#improper-type-casting"></a></p>
<p dir="auto">You can utilize <code>Array</code> to cast a variable into any other type. Calling instance methods that don't exist on type casted variables is undefined behavior; the compiler isn't smart enough to realize when you're doing this.</p>
<div dir="auto" data-snippet-clipboard-copy-content="/**
 * Program output:
 * 4
 */
class Main {
    constructor Main new() {
        return this;
    }

    function void main() {
        var Array a;
        var Main b;
        var String c;
        let a = Array.new(1);
        let b = Main.new();
        let a[0] = b;
        let c = a[0];
        // Invalidly calling `String.length` on an instance of `Main`.
        do Output.printInt(c.length());
    }
}"><pre><span>/**</span>
<span> * Program output:</span>
<span> * 4</span>
<span> */</span>
<span>class</span> <span>Main</span> <span>{</span>
    <span>constructor</span> <span>Main</span> <span>new</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>;</span>
    <span>}</span>

    <span>function</span> <span>void</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
        <span>var</span> <span>Array</span> <span>a</span><span>;</span>
        <span>var</span> <span>Main</span> <span>b</span><span>;</span>
        <span>var</span> <span>String</span> <span>c</span><span>;</span>
        <span>let</span> <span>a</span> <span>=</span> <span>Array</span><span>.</span><span>new</span><span>(</span><span>1</span><span>)</span><span>;</span>
        <span>let</span> <span>b</span> <span>=</span> <span>Main</span><span>.</span><span>new</span><span>(</span><span>)</span><span>;</span>
        <span>let</span> <span>a</span><span></span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>b</span><span>;</span>
        <span>let</span> <span>c</span> <span>=</span> <span>a</span><span>[</span><span>0</span><span>]</span><span>;</span>
        <span>// Invalidly calling `String.length` on an instance of `Main`.</span>
        <span>do</span> <span>Output</span><span>.</span><span>printInt</span><span>(</span><span>c</span><span>.</span><span>length</span><span>(</span><span>)</span><span>)</span><span>;</span>
    <span>}</span>
<span>}</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Stack Overflows</h4><a id="user-content-stack-overflows" aria-label="Permalink: Stack Overflows" href="#stack-overflows"></a></p>
<p dir="auto">See the <a href="#overflow">Overflow</a> program for an in-depth example.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Modifying Stack Frames or Internal Registers</h4><a id="user-content-modifying-stack-frames-or-internal-registers" aria-label="Permalink: Modifying Stack Frames or Internal Registers" href="#modifying-stack-frames-or-internal-registers"></a></p>
<p dir="auto">Modifying stack frames or the internal registers that respectively reside at memory addresses <code>256</code> to <code>2047</code> and <code>1</code> to <code>15</code> may lead to undefined behavior. This typically isn't possible without misusing <code>Memory.poke</code> or negative array indexing. See the <a href="#secretpassword">SecretPassword</a> program for an in-depth example.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Hardware Specification</h3><a id="user-content-hardware-specification" aria-label="Permalink: Hardware Specification" href="#hardware-specification"></a></p>
<p dir="auto">Since its rise in the 1970s, there's a good reason why 16-bit computing has fallen from grace in the modern era. Compared to 32-bit or 64-bit computing, 16-bit computing offered limited processing power and memory capacity that simply weren't meeting the demands of contemporary software and applications.</p>
<p dir="auto">NAND is no exception to this reality.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ArhanChaudhary/NAND/blob/main/media/memory_layout.png"><img src="https://github.com/ArhanChaudhary/NAND/raw/main/media/memory_layout.png" width="700"></a></p>
<p dir="auto"><em>taken from the <a href="https://drive.google.com/file/d/1BexrNmdqYhKPkqD_Y81qNAUeyfzl-ZtO/view" rel="nofollow">Nand to Tetris lecture slides</a>.</em></p>
<p dir="auto">Compared to your 16 GiB MacBook, NAND enjoys a meager 4 KiB of RAM, a ratio of <em>0.00002%</em>! In spite of this, <a href="https://www.metroweekly.com/2014/07/to-the-moon-and-back-on-4kb-of-memory/" rel="nofollow">it was enough to take us to the moon</a>, so who's to say NAND can't either.</p>
<p dir="auto">The Jack OS reserves 14,336 memory addresses of the 4 KiB for the heap, a number that is abnormally small. This is why it's so important to ensure complex Jack applications allocate and deallocate their memory efficiently. If you're overly ambitious, you might run out of heap memory and be forced to completely rewrite your data types and logic.</p>
<p dir="auto">The hardware reserves 8,192 memory addresses of the 4 KiB for the screen. Each bit of each address linearly maps to a corresponding pixel on the provided 512x256 screen, in <a href="https://en.wikipedia.org/wiki/Bit_numbering#LSb_0_bit_numbering" rel="nofollow">LSb 0 bit numbering</a>.</p>
<p dir="auto">The hardware reserves memory address 24,576 for the keyboard, at which the currently pressed key is reflected. Though, you shouldn't directly access this location to handle user input. You should use the provided <a href="#keyboard">Keyboard</a> class from the Jack OS and its associated functions.</p>
<p dir="auto">NAND's keyboard recognizes all ASCII characters, as well as the following keys.</p>
<ul dir="auto">
<li>new line = 128 = <code>String.newline()</code></li>
<li>backspace = 129 = <code>String.backspace()</code></li>
<li>left arrow = 130</li>
<li>up arrow = 131</li>
<li>right arrow = 132</li>
<li>down arrow = 133</li>
<li>home = 134</li>
<li>end = 135</li>
<li>page up = 136</li>
<li>page down = 137</li>
<li>insert = 138</li>
<li>delete = 139</li>
<li>ESC = 140</li>
<li>F1 - F12 = 141 - 152</li>
</ul>
<p dir="auto">Lastly, the hardware reserves 240 memory addresses for static class variables and 1,792 memory addresses for the global stack. Unless you perform deep recursion, you probably won't find these limitations troublesome.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Beyond the Jack OS</h3><a id="user-content-beyond-the-jack-os" aria-label="Permalink: Beyond the Jack OS" href="#beyond-the-jack-os"></a></p>
<p dir="auto">By default, the Jack OS is bundled with your program during compilation to enable interfacing with strings, memory, hardware, and more. To the extraordinarily dedicated, it is possible to provide your own OS implementation with your own hardware interfaces. The IDE treats Jack OS files the same as typical program files; they can likewise be deleted or overwritten. There are a few core functions you <em>must</em> implement for your program to compile if you choose to do so. You're free to copy my implementations of these functions as needed.</p>
<p dir="auto"><code>Sys.init</code>: rather than <code>Main.main</code>, this is the <em>real</em> entry point of the program, hardcoded in the virtual machine implementation. For context, the provided Jack OS implementation looks like this:</p>
<div dir="auto" data-snippet-clipboard-copy-content="function void init() {
    do Memory.init();
    do Math.init();
    do Screen.init();
    do Screen.clearScreen();
    do Output.init();
    do Main.main();
    do Sys.halt();
}"><pre><span>function</span> <span>void</span> <span>init</span><span>(</span><span>)</span> <span>{</span>
    <span>do</span> <span>Memory</span><span>.</span><span>init</span><span>(</span><span>)</span><span>;</span>
    <span>do</span> <span>Math</span><span>.</span><span>init</span><span>(</span><span>)</span><span>;</span>
    <span>do</span> <span>Screen</span><span>.</span><span>init</span><span>(</span><span>)</span><span>;</span>
    <span>do</span> <span>Screen</span><span>.</span><span>clearScreen</span><span>(</span><span>)</span><span>;</span>
    <span>do</span> <span>Output</span><span>.</span><span>init</span><span>(</span><span>)</span><span>;</span>
    <span>do</span> <span>Main</span><span>.</span><span>main</span><span>(</span><span>)</span><span>;</span>
    <span>do</span> <span>Sys</span><span>.</span><span>halt</span><span>(</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto"><code>Memory.alloc</code>: A heap memory allocator internally used by class constructors to create objects. NAND inherently places emphasis on the heap for data storage, so this function is useful in many other contexts too.</p>
<p dir="auto"><code>String.newWithStr</code>: An internal constructor for string literals.</p>
<p dir="auto"><code>Math.multiply</code>: This function is internally called in lieu of the multiplication operator <code>*</code>. In other words, the Jack expression <code>x * y</code> and <code>Math.multiply(x, y)</code> are equivalent.</p>
<p dir="auto"><code>Math.divide</code>: This function is internally called in lieu of the floored division operator <code>/</code>. In other words, the Jack expression <code>x / y</code> and <code>Math.divide(x, y)</code> are equivalent.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How does NAND work?</h2><a id="user-content-how-does-nand-work" aria-label="Permalink: How does NAND work?" href="#how-does-nand-work"></a></p>
<p dir="auto">I'm glad you asked! I've found the following illustrations quite illuminating:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ArhanChaudhary/NAND/blob/main/media/computer.png"><img src="https://github.com/ArhanChaudhary/NAND/raw/main/media/computer.png" width="700"></a></p>
<p dir="auto"><em>taken from <a href="https://commons.wikimedia.org/wiki/File:Hack_Computer_Block_Diagram_2.png" rel="nofollow">Wikipedia</a>.</em></p>
<p dir="auto">The NAND computer follows the <a href="https://en.wikipedia.org/wiki/Harvard_architecture" rel="nofollow">Harvard architecture</a>. That is, the instruction memory (ROM) and the data memory (RAM) are separately stored, brought to function in unison by the CPU.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ArhanChaudhary/NAND/blob/main/media/cpu.png"><img src="https://github.com/ArhanChaudhary/NAND/raw/main/media/cpu.png" width="700"></a></p>
<p dir="auto"><em>taken from <a href="https://commons.wikimedia.org/wiki/File:Hack_Computer_Block_Diagram_2.png" rel="nofollow">Wikipedia</a>.</em></p>
<p dir="auto">NAND's CPU is an <a href="https://en.wikipedia.org/wiki/Accumulator_(computing)#Accumulator_machines" rel="nofollow">accumulator machine</a>, meaning that it is heavily dependent on its built-in registers for control flow (in this case the accumulator is the D register). Don't worry if you don't fully understand what the CPU visualization depicts. Instead, take the perspective of appreciation for how this elegantly simple design powers the entirety of NAND — in your web browser!</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ArhanChaudhary/NAND/blob/main/media/alu.png"><img src="https://github.com/ArhanChaudhary/NAND/raw/main/media/alu.png" width="700"></a></p>
<p dir="auto">We've reached the instruction set, the nitty-gritty. As indicated, NAND's CPU only has <em>two</em> opcodes! This makes the instruction set relatively simple while providing a rich functionality. NAND's ALU is additionally specified with the expressions it can compute in a single instruction.</p>
<p dir="auto">Phew! That was a lot to take in, but I promise you NAND is far less complicated than I've made it out to be. From a relatively simple logical foundation, Turing equivalence is achieved! If you want see my implementation of the NAND computer architecture, <a href="https://github.com/ArhanChaudhary/NAND/blob/main/src/core">you're more than welcome to</a>! If you find yourself still curious, check out the <a href="https://drive.google.com/file/d/1Z_fxYmmRNXTkAzmZ6YMoX9NXZIRVCKiw/view" rel="nofollow">Nand to Tetris lecture slides</a> for further elaboration on every aspect of the architecture.</p>
<p dir="auto">Let's briefly talk about the compiler and the virtual machine to make this section feel complete. These concepts are nothing unique to NAND, hence their brevity. Some of NAND's strange syntactical features are a direct consequence of making the compiler easier to implement. The compiler is a <a href="https://en.wikipedia.org/wiki/Recursive_descent_parser" rel="nofollow">recursive descent parser</a> on an <a href="https://en.wikipedia.org/wiki/LL_parser" rel="nofollow">LL(1) grammar</a>, generating virtual machine code to be utilized as a <a href="https://en.wikipedia.org/wiki/Stack_machine" rel="nofollow">simple stack machine</a> (a technique that also handles managing <a href="https://en.wikipedia.org/wiki/Call_stack" rel="nofollow">call stacks</a>). Each virtual machine instruction is then trivially mapped to assembly and machine code. Once again, you're more than welcome to see my <a href="https://github.com/ArhanChaudhary/NAND/blob/main/src/compiler">compiler implementation</a> for yourself.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Jack Reference</h2><a id="user-content-jack-reference" aria-label="Permalink: Jack Reference" href="#jack-reference"></a></p>
<p dir="auto">This majority of this section was taken from the <a href="https://drive.google.com/file/d/1CAGF8d3pDIOgqX8NZGzU34PPEzvfTYrk/view" rel="nofollow">Nand to Tetris lecture slides</a> and the <a href="https://www.csie.ntu.edu.tw/~cyy/courses/introCS/18fall/lectures/handouts/lec13_Jack.pdf" rel="nofollow">National Taiwan University lecture slides</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Program Structure</h3><a id="user-content-program-structure" aria-label="Permalink: Program Structure" href="#program-structure"></a></p>
<pre><b>class</b> ClassName {
    <b>field</b> <i>variable declarations</i>;
    <b>static</b> <i>variable declarations</i>;

    <b>constructor</b> <i>type</i> ( <i>parameterList</i> ) {
        <i>local variable declarations</i>;
        <i>statements</i>
    }

    <b>method</b> <i>type</i> ( <i>parameterList</i> ) {
        <i>local variable declarations</i>;
        <i>statements</i>
    }

    <b>function</b> <i>type</i> ( <i>parameterList</i> ) {
        <i>local variable declarations</i>;
        <i>statements</i>
    }
}
</pre>
<p dir="auto">About this layout:</p>
<ul dir="auto">
<li>Every part in this layout can appear 0 or more times</li>
<li>The order of the field / static
declarations is arbitrary</li>
<li>The order of the subroutine declarations is arbitrary</li>
<li>Each type is either <code>void</code>, <code>int</code>, <code>boolean</code>, <code>char</code>, or a class name</li>
</ul>
<p dir="auto">A Jack program:</p>
<ul dir="auto">
<li>Defines classes in separate files</li>
<li>Consists of a collection of one or more classes, one of which must be named <code>Main</code></li>
<li>Must define the <code>main</code> function in the <code>Main</code> class, the entry point of the program defined by the Jack OS</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Syntax</h3><a id="user-content-syntax" aria-label="Permalink: Syntax" href="#syntax"></a></p>
<table>
  <tbody>
    <tr>
      <th>White space and comments</th>
      <td>
        Space characters, newline characters, and comments are ignored.<p>
        
        The following comment formats are supported:<br>
        <code>// Comment to end of line</code><br>
        <code>/* Comment until closing */</code><br>
        <code>/** API documentation comment */</code></p></td>
    </tr>
    <tr>
      <th>Symbols</th>
      <td>
        <table>
          <tbody>
            <tr>
              <th>
                <code>(</code>&nbsp;<code>)</code>
              </th>
              <td>
                Used for grouping arithmetic expressions and for enclosing parameter-lists and argument-lists
              </td>
            </tr>
            <tr>
              <th>
                <code>[</code>&nbsp;<code>]</code>
              </th>
              <td>
                Used for array indexing
              </td>
            </tr>
            <tr>
              <th>
                <code>{</code>&nbsp;<code>}</code>
              </th>
              <td>
                Used for grouping program units and statements
              </td>
            </tr>
            <tr>
              <th>
                <code>,</code>
              </th>
              <td>
                Variable list separator
              </td>
            </tr>
            <tr>
              <th>
                <code>;</code>
              </th>
              <td>
                Statement terminator
              </td>
            </tr>
            <tr>
              <th>
                <code>.</code>
              </th>
              <td>
                Class membership
              </td>
            </tr>
            <tr>
              <th>
                <code>=</code>
              </th>
              <td>
                Assignment and comparison operator
              </td>
            </tr>
            <tr>
              <th>
                <code>+</code>&nbsp;<code>-</code>&nbsp;<code>*</code><br>
                <code>/</code>&nbsp;<code>&amp;</code>&nbsp;<code>|</code><br>
                <code>-</code>&nbsp;<code>&lt;</code>&nbsp;<code>&gt;</code>
              </th>
              <td>
                Operators. Note that <code>&amp;</code> and <code>|</code> are bitwise and do not short-circuit
              </td>
            </tr>
          </tbody>
        </table>
      </td>
    </tr>
    <tr>
      <th>Reserved words</th>
      <td>
        <table>
          <tbody>
            <tr>
              <th>
                <code>class</code>,
                <code>constructor</code>,
                <code>method</code>,
                <code>function</code>
              </th>
              <td>
                Program components
              </td>
            </tr>
            <tr>
              <th>
                <code>int</code>,
                <code>boolean</code>,
                <code>char</code>
              </th>
              <td>
                Primitive types
              </td>
            </tr>
            <tr>
              <th>
                <code>var</code>,
                <code>static</code>,
                <code>field</code>
              </th>
              <td>
                Variable declarations
              </td>
            </tr>
            <tr>
              <th>
                <code>let</code>,
                <code>do</code>,
                <code>if</code>,
                <code>else</code>,
                <code>while</code>,
                <code>return</code>
              </th>
              <td>
                Statements
              </td>
            </tr>
            <tr>
              <th>
                <code>true</code>,
                <code>false</code>,
                <code>null</code>
              </th>
              <td>
                Constant values (-1. 0, and 0 respectively)
              </td>
            </tr>
            <tr>
              <th>
                <code>this</code>
              </th>
              <td>
                Object reference
              </td>
            </tr>
            <tr>
              <th>
                <code>arguments</code>
              </th>
              <td>
                Function arguments array reference
              </td>
            </tr>
          </tbody>
        </table>
      </td>
    </tr>
    <tr>
      <th>Constants</th>
      <td>
          <i>Integer</i> constants must be positive and in standard decimal notation, e.g., <code>1984</code>. Negative integers like <code>-13</code> are not constants but rather expressions consisting of a unary negative operator applied to an integer constant.<p>
          
          <i>String</i> constants are enclosed within quotation marks and may contain any characters except new lines or quotation marks. Unlike typical programming languages, these characters cannot be escaped within a string, so these characters are instead supplied by the functions <code>String.newLine()</code> and <code>String.doubleQuote()</code> from the OS. <sub><sup>If you manage to read this, say <a href="https://files.bithole.dev/nandy.png" rel="nofollow">hi</a> to Nandy</sup></sub></p><p>
          
          <i>Boolean</i> constants can be true or false.</p><p>
          
          <i>null</i> signifies a null reference (a value of 0).
      </p></td>
    </tr>
    <tr>
      <th>Identifiers</th>
      <td>
          Identifiers are composed from arbitrarily long sequences of letters, digits, and "_". The first character cannot be a digit.<p>
          
          Case sensitivity matters. Thus <code>x</code> and <code>X</code> are treated as different identifiers.
      </p></td>
    </tr>
  </tbody>
</table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Variables</h3><a id="user-content-variables" aria-label="Permalink: Variables" href="#variables"></a></p>
<table>
<thead>
<tr>
<th>Variable kind</th>
<th>Description</th>
<th>Declared in</th>
<th>Scope</th>
</tr>
</thead>
<tbody>
<tr>
<td>static variables</td>
<td><code>static</code> <em>type varName1, varName2, ...</em>;<br>Only one copy of each static variable exists, and this copy is shared by all the object instances of the class (like <em>private static variables</em> in Java)</td>
<td>class declaration</td>
<td>The class in which they are declared.</td>
</tr>
<tr>
<td>field variables</td>
<td><code>field</code> <em>type varName1, varName2, ...</em>;<br>Every object (instance of the class) has a private copy of the field variables (like <em>member variables</em> in Java)</td>
<td>class declaration</td>
<td>The class in which they are declared, except for functions, where they are undefined.</td>
</tr>
<tr>
<td>local variables</td>
<td><code>var</code> <em>type varName1, varName2, ...</em>;<br>Local variables are created just before the subroutine starts running and are deallocated when it returns (like <em>local variables</em> in Java)</td>
<td>subroutine declaration</td>
<td>The subroutine in which they are declared.</td>
</tr>
<tr>
<td>parameter variables</td>
<td><em>type varName1, varName2, ...</em><br>Used to pass arguments to the subroutine. Treated like local variables whose values are initialized "from the outside", just before the subroutine starts running.</td>
<td>subroutine signature</td>
<td>The subroutine in which they are declared.</td>
</tr>
</tbody>
</table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Statements</h3><a id="user-content-statements" aria-label="Permalink: Statements" href="#statements"></a></p>
<table>
<thead>
<tr>
<th>Statement</th>
<th>Syntax</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>let</td>
<td><code>let</code> <em>varName = expression</em>;<br>or<br><code>let</code> <em>varName</em>[<em>expression1</em>] = <em>expression2</em>;</td>
<td>An assignment operation (where <em>varName</em> is either single-valued or an array). The variable kind may be <em>static, local, field, or parameter</em>.</td>
</tr>
<tr>
<td>if</td>
<td><code>if</code> (expression1) {<br>&nbsp;&nbsp;&nbsp;&nbsp;statements1<br>} <code>else if</code> (expression2) {<br>&nbsp;&nbsp;&nbsp;&nbsp;statements2<br>} <code>else</code> {<br>&nbsp;&nbsp;&nbsp;&nbsp;statements3<br>}</td>
<td>Typical <em>if</em> statement with an optional <em>else</em> or <em>else if</em> clause. The brackets are optional if there's only one statement.</td>
</tr>
<tr>
<td>while</td>
<td><code>while</code> (expression) {<br>&nbsp;&nbsp;&nbsp;&nbsp;<em>statements</em><br>}</td>
<td>Typical <em>while</em> statement. The brackets are optional if there's only one statement.</td>
</tr>
<tr>
<td>do</td>
<td><code>do</code> <em>function-or-method-call</em>;</td>
<td>Used to call a function or a method for its effect, ignoring the returned value.</td>
</tr>
<tr>
<td>return</td>
<td><code>return</code> expression;<br>or<br><code>return</code>;</td>
<td>Used to return a value from a subroutine. Constructors must return the expression <code>this</code>.</td>
</tr>
</tbody>
</table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Jack OS Reference</h2><a id="user-content-jack-os-reference" aria-label="Permalink: Jack OS Reference" href="#jack-os-reference"></a></p>
<p dir="auto">This section was adapted from the supplied Nand to Tetris software suite.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Array</h3><a id="user-content-array" aria-label="Permalink: Array" href="#array"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="/**
 * Represents an array.
 * In the Jack language, arrays are instances of the Array class.
 * Once declared, the array entries can be accessed using the usual
 * syntax arr[i]. Each array entry can hold a primitive data type as
 * well as any object type. Different array entries can have different
 * data types.
 */
class Array {
    /**
     * Constructs a new array of the given size.
     */
    function Array new(int size);

    /**
     * Deallocates an instance of Array and frees its memory space.
     */
    method void dispose();
}"><pre><span>/**</span>
<span> * Represents an array.</span>
<span> * In the Jack language, arrays are instances of the Array class.</span>
<span> * Once declared, the array entries can be accessed using the usual</span>
<span> * syntax arr[i]. Each array entry can hold a primitive data type as</span>
<span> * well as any object type. Different array entries can have different</span>
<span> * data types.</span>
<span> */</span>
<span>class</span> <span>Array</span> <span>{</span>
    <span>/**</span>
<span>     * Constructs a new array of the given size.</span>
<span>     */</span>
    <span>function</span> <span>Array</span> <span>new</span><span>(</span><span>int</span> <span>size</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Deallocates an instance of Array and frees its memory space.</span>
<span>     */</span>
    <span>method</span> <span>void</span> <span>dispose</span><span>(</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Keyboard</h3><a id="user-content-keyboard" aria-label="Permalink: Keyboard" href="#keyboard"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="/**
 * The Keyboard class provides an interface for reading inputs from
 * a standard keyboard.
 */
class Keyboard {
    /**
     * Returns the character code of the currently pressed key,
     * or 0 if no key is currently pressed.
     */
    function char keyPressed();

    /**
     * Waits until a keyboard key is pressed and released, then displays the
     * corresponding character on the screen and returns the character.
     */
    function char readChar();

    /**
     * Prints the message on the screen, reads the next line (until a newLine
     * character) from the keyboard, and returns its value.
     */
    function String readLine(String message);

    /**
     * Prints the message on the screen, reads the next line (until a newline
     * character) from the keyboard, and returns its integer value (until the
     * first non numeric character).
     */
    function int readInt(String message);
}"><pre><span>/**</span>
<span> * The Keyboard class provides an interface for reading inputs from</span>
<span> * a standard keyboard.</span>
<span> */</span>
<span>class</span> <span>Keyboard</span> <span>{</span>
    <span>/**</span>
<span>     * Returns the character code of the currently pressed key,</span>
<span>     * or 0 if no key is currently pressed.</span>
<span>     */</span>
    <span>function</span> <span>char</span> <span>keyPressed</span><span>(</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Waits until a keyboard key is pressed and released, then displays the</span>
<span>     * corresponding character on the screen and returns the character.</span>
<span>     */</span>
    <span>function</span> <span>char</span> <span>readChar</span><span>(</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Prints the message on the screen, reads the next line (until a newLine</span>
<span>     * character) from the keyboard, and returns its value.</span>
<span>     */</span>
    <span>function</span> <span>String</span> <span>readLine</span><span>(</span><span>String</span> <span>message</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Prints the message on the screen, reads the next line (until a newline</span>
<span>     * character) from the keyboard, and returns its integer value (until the</span>
<span>     * first non numeric character).</span>
<span>     */</span>
    <span>function</span> <span>int</span> <span>readInt</span><span>(</span><span>String</span> <span>message</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Math</h3><a id="user-content-math" aria-label="Permalink: Math" href="#math"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="/**
 * A library of commonly used mathematical functions.
 */
class Math {
    /**
     * Returns the absolute value of x.
     */
    function int abs(int x);

    /**
     * Returns the product of x and y.
     * This function is internally called in lieu of the multiplication
     * operator '*'. In other words, the Jack expression x * y and
     * Math.multiply(x, y) are equivalent.
     */
    function int multiply(int x, int y);

    /**
     * Returns the integer part of x / y.
     * This function is internally called in lieu of the division
     * operator '/'. In other words, the Jack expression x / y and
     * Math.divide(x, y) are equivalent.
     */
    function int divide(int dividend, int divisor);

    /**
     * Returns the integer part of the square root of x.
     */
    function int sqrt(int x);

    /**
     * Returns the greater of the two arguments.
     */
    function int max(int a, int b);

    /**
     * Returns the smaller of the two arguments.
     */
    function int min(int a, int b);
}"><pre><span>/**</span>
<span> * A library of commonly used mathematical functions.</span>
<span> */</span>
<span>class</span> <span>Math</span> <span>{</span>
    <span>/**</span>
<span>     * Returns the absolute value of x.</span>
<span>     */</span>
    <span>function</span> <span>int</span> <span>abs</span><span>(</span><span>int</span> <span>x</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Returns the product of x and y.</span>
<span>     * This function is internally called in lieu of the multiplication</span>
<span>     * operator '*'. In other words, the Jack expression x * y and</span>
<span>     * Math.multiply(x, y) are equivalent.</span>
<span>     */</span>
    <span>function</span> <span>int</span> <span>multiply</span><span>(</span><span>int</span> <span>x</span><span>,</span> <span>int</span> <span>y</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Returns the integer part of x / y.</span>
<span>     * This function is internally called in lieu of the division</span>
<span>     * operator '/'. In other words, the Jack expression x / y and</span>
<span>     * Math.divide(x, y) are equivalent.</span>
<span>     */</span>
    <span>function</span> <span>int</span> <span>divide</span><span>(</span><span>int</span> <span>dividend</span><span>,</span> <span>int</span> <span>divisor</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Returns the integer part of the square root of x.</span>
<span>     */</span>
    <span>function</span> <span>int</span> <span>sqrt</span><span>(</span><span>int</span> <span>x</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Returns the greater of the two arguments.</span>
<span>     */</span>
    <span>function</span> <span>int</span> <span>max</span><span>(</span><span>int</span> <span>a</span><span>,</span> <span>int</span> <span>b</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Returns the smaller of the two arguments.</span>
<span>     */</span>
    <span>function</span> <span>int</span> <span>min</span><span>(</span><span>int</span> <span>a</span><span>,</span> <span>int</span> <span>b</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Memory</h3><a id="user-content-memory" aria-label="Permalink: Memory" href="#memory"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="/**
 * This library provides two services: direct access to the computer's main
 * memory (RAM), and allocation and recycling of memory blocks. The NAND RAM
 * consists of 32,768 words, each holding a 16-bit binary number.
 */
class Memory {
    /**
     * Returns the RAM value at the given address.
     */
    function int peek(int address);

    /**
     * Sets the value of the given RAM address to the given value.
     */
    function void poke(int address, int value);

    /**
     * Finds and allocates from the heap a memory block of the specified size and
     * returns a reference to its base address.
     */
    function int alloc(int size);

    /**
     * Deallocates the given object (cast as an array) by making it available for
     * future allocations.
     */
    function void deAlloc(Array o);
}"><pre><span>/**</span>
<span> * This library provides two services: direct access to the computer's main</span>
<span> * memory (RAM), and allocation and recycling of memory blocks. The NAND RAM</span>
<span> * consists of 32,768 words, each holding a 16-bit binary number.</span>
<span> */</span>
<span>class</span> <span>Memory</span> <span>{</span>
    <span>/**</span>
<span>     * Returns the RAM value at the given address.</span>
<span>     */</span>
    <span>function</span> <span>int</span> <span>peek</span><span>(</span><span>int</span> <span>address</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Sets the value of the given RAM address to the given value.</span>
<span>     */</span>
    <span>function</span> <span>void</span> <span>poke</span><span>(</span><span>int</span> <span>address</span><span>,</span> <span>int</span> <span>value</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Finds and allocates from the heap a memory block of the specified size and</span>
<span>     * returns a reference to its base address.</span>
<span>     */</span>
    <span>function</span> <span>int</span> <span>alloc</span><span>(</span><span>int</span> <span>size</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Deallocates the given object (cast as an array) by making it available for</span>
<span>     * future allocations.</span>
<span>     */</span>
    <span>function</span> <span>void</span> <span>deAlloc</span><span>(</span><span>Array</span> <span>o</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Output</h3><a id="user-content-output" aria-label="Permalink: Output" href="#output"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="/**
 * A library of functions for writing text on the screen.
 * The NAND physical screen consists of 512 rows of 256 pixels each.
 * The library uses a fixed font, in which each character is displayed
 * within a frame which is 11 pixels high (including 1 pixel for inter-line
 * spacing) and 8 pixels wide (including 2 pixels for inter-character spacing).
 * The resulting grid accommodates 23 rows (indexed 0..22, top to bottom)
 * of 64 characters each (indexed 0..63, left to right). The top left
 * character position on the screen is indexed (0,0). A cursor, implemented
 * as a small filled square, indicates where the next character will be displayed.
 */
class Output {
    /**
     * Moves the cursor to the j'th column of the i'th row, erasing the character
     * that was there.
     */
    function void moveCursor(int i, int j);

    /**
     * Displays the given character at the cursor location,
     * and advances the cursor one column forward.
     */
    function void printChar(char c);

    /**
     * Displays the given string starting at the cursor location, and advances
     * the cursor appropriately.
     */
    function void printString(String str);

    /**
     * Displays the given integer starting at the cursor location, and advances
     * the cursor appropriately.
     */
    function void printInt(int i);

    /**
     * Advances the cursor to the beginning of the next line.
     */
    function void println();

    /**
     * Erases the character that was last written and moves the cursor one column
     * back.
     */
    function void backSpace();
}"><pre><span>/**</span>
<span> * A library of functions for writing text on the screen.</span>
<span> * The NAND physical screen consists of 512 rows of 256 pixels each.</span>
<span> * The library uses a fixed font, in which each character is displayed</span>
<span> * within a frame which is 11 pixels high (including 1 pixel for inter-line</span>
<span> * spacing) and 8 pixels wide (including 2 pixels for inter-character spacing).</span>
<span> * The resulting grid accommodates 23 rows (indexed 0..22, top to bottom)</span>
<span> * of 64 characters each (indexed 0..63, left to right). The top left</span>
<span> * character position on the screen is indexed (0,0). A cursor, implemented</span>
<span> * as a small filled square, indicates where the next character will be displayed.</span>
<span> */</span>
<span>class</span> <span>Output</span> <span>{</span>
    <span>/**</span>
<span>     * Moves the cursor to the j'th column of the i'th row, erasing the character</span>
<span>     * that was there.</span>
<span>     */</span>
    <span>function</span> <span>void</span> <span>moveCursor</span><span>(</span><span>int</span> <span>i</span><span>,</span> <span>int</span> <span>j</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Displays the given character at the cursor location,</span>
<span>     * and advances the cursor one column forward.</span>
<span>     */</span>
    <span>function</span> <span>void</span> <span>printChar</span><span>(</span><span>char</span> <span>c</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Displays the given string starting at the cursor location, and advances</span>
<span>     * the cursor appropriately.</span>
<span>     */</span>
    <span>function</span> <span>void</span> <span>printString</span><span>(</span><span>String</span> <span>str</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Displays the given integer starting at the cursor location, and advances</span>
<span>     * the cursor appropriately.</span>
<span>     */</span>
    <span>function</span> <span>void</span> <span>printInt</span><span>(</span><span>int</span> <span>i</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Advances the cursor to the beginning of the next line.</span>
<span>     */</span>
    <span>function</span> <span>void</span> <span>println</span><span>(</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Erases the character that was last written and moves the cursor one column</span>
<span>     * back.</span>
<span>     */</span>
    <span>function</span> <span>void</span> <span>backSpace</span><span>(</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Screen</h3><a id="user-content-screen" aria-label="Permalink: Screen" href="#screen"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="/**
 * A library of functions for displaying graphics on the screen.
 * The NAND physical screen consists of 256 rows (indexed 0..255, top to bottom)
 * of 512 pixels each (indexed 0..511, left to right). The top left pixel on
 * the screen is indexed (0,0).
 */
class Screen {
    /**
     * Erases the entire screen.
     */
    function void clearScreen();

    /**
     * Sets the current color to be used for all subsequent drawXXX commands.
     * Black is represented by true, white by false.
     */
    function void setColor(boolean b);

    /**
     * Draws the (x, y) pixel using the current color.
     */
    function void drawPixel(int x, int y);

    /**
     * Draws a line from pixel (x1, y1) to pixel (x2, y2) using the current color.
     */
    function void drawLine(int x1, int y1, int x2, int y2);

    /**
     * Draws a filled rectangle whose top left corner is (x1, y1) and bottom
     * right corner is (x2, y2) using the current color.
     */
    function void drawRectangle(int x1, int y1, int x2, int y2);

    /**
     * Draws a filled circle of radius r <= 181 around (x, y) using the current
     * color.
     */
    function void drawCircle(int x, int y, int r);
}"><pre><span>/**</span>
<span> * A library of functions for displaying graphics on the screen.</span>
<span> * The NAND physical screen consists of 256 rows (indexed 0..255, top to bottom)</span>
<span> * of 512 pixels each (indexed 0..511, left to right). The top left pixel on</span>
<span> * the screen is indexed (0,0).</span>
<span> */</span>
<span>class</span> <span>Screen</span> <span>{</span>
    <span>/**</span>
<span>     * Erases the entire screen.</span>
<span>     */</span>
    <span>function</span> <span>void</span> <span>clearScreen</span><span>(</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Sets the current color to be used for all subsequent drawXXX commands.</span>
<span>     * Black is represented by true, white by false.</span>
<span>     */</span>
    <span>function</span> <span>void</span> <span>setColor</span><span>(</span><span>boolean</span> <span>b</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Draws the (x, y) pixel using the current color.</span>
<span>     */</span>
    <span>function</span> <span>void</span> <span>drawPixel</span><span>(</span><span>int</span> <span>x</span><span>,</span> <span>int</span> <span>y</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Draws a line from pixel (x1, y1) to pixel (x2, y2) using the current color.</span>
<span>     */</span>
    <span>function</span> <span>void</span> <span>drawLine</span><span>(</span><span>int</span> <span>x1</span><span>,</span> <span>int</span> <span>y1</span><span>,</span> <span>int</span> <span>x2</span><span>,</span> <span>int</span> <span>y2</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Draws a filled rectangle whose top left corner is (x1, y1) and bottom</span>
<span>     * right corner is (x2, y2) using the current color.</span>
<span>     */</span>
    <span>function</span> <span>void</span> <span>drawRectangle</span><span>(</span><span>int</span> <span>x1</span><span>,</span> <span>int</span> <span>y1</span><span>,</span> <span>int</span> <span>x2</span><span>,</span> <span>int</span> <span>y2</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Draws a filled circle of radius r &lt;= 181 around (x, y) using the current</span>
<span>     * color.</span>
<span>     */</span>
    <span>function</span> <span>void</span> <span>drawCircle</span><span>(</span><span>int</span> <span>x</span><span>,</span> <span>int</span> <span>y</span><span>,</span> <span>int</span> <span>r</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">String</h3><a id="user-content-string" aria-label="Permalink: String" href="#string"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="/**
 * Represents character strings. In addition for constructing and
 * deallocating strings, the class features methods for getting and setting
 * individual characters of the string, for erasing the string's last character,
 * for appending a character to the string's end, and more typical
 * string-oriented operations.
 */
class String {
    /**
     * Constructs a new empty string with a maximum length of maxLength and
     * initial length of 0.
     */
    constructor String new(int maxLength);

    /**
     * Deallocates an instance of String and frees its memory space.
     */
    method void dispose();

    /**
     * Returns the current length of an instance of String.
     */
    method int length();

    /**
     * Returns the character at the j-th location of an instance of String.
     */
    method char charAt(int j);

    /**
     * Sets the character at the j-th location of an instance of String to c.
     */
    method void setCharAt(int j, char c);

    /**
     * Appends the given character to the end of an instance of String and
     * returns the same instance.
     */
    method String appendChar(char c);

    /**
     * Erases the last character from an instance of String.
     */
    method void eraseLastChar();

    /**
     * Returns the integer value of an instance of String until the first
     * non-numeric character.
     */
    method int intValue();

    /**
     * Sets an instance of String to the representation of the given number.
     */
    method void setInt(int number);

    /**
     * Returns the new line character.
     */
    function char newLine();

    /**
     * Returns the backspace character.
     */
    function char backSpace();

    /**
     * Returns the quotation mark character.
     */
    function char doubleQuote();
}"><pre><span>/**</span>
<span> * Represents character strings. In addition for constructing and</span>
<span> * deallocating strings, the class features methods for getting and setting</span>
<span> * individual characters of the string, for erasing the string's last character,</span>
<span> * for appending a character to the string's end, and more typical</span>
<span> * string-oriented operations.</span>
<span> */</span>
<span>class</span> <span>String</span> <span>{</span>
    <span>/**</span>
<span>     * Constructs a new empty string with a maximum length of maxLength and</span>
<span>     * initial length of 0.</span>
<span>     */</span>
    <span>constructor</span> <span>String</span> <span>new</span><span>(</span><span>int</span> <span>maxLength</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Deallocates an instance of String and frees its memory space.</span>
<span>     */</span>
    <span>method</span> <span>void</span> <span>dispose</span><span>(</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Returns the current length of an instance of String.</span>
<span>     */</span>
    <span>method</span> <span>int</span> <span>length</span><span>(</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Returns the character at the j-th location of an instance of String.</span>
<span>     */</span>
    <span>method</span> <span>char</span> <span>charAt</span><span>(</span><span>int</span> <span>j</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Sets the character at the j-th location of an instance of String to c.</span>
<span>     */</span>
    <span>method</span> <span>void</span> <span>setCharAt</span><span>(</span><span>int</span> <span>j</span><span>,</span> <span>char</span> <span>c</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Appends the given character to the end of an instance of String and</span>
<span>     * returns the same instance.</span>
<span>     */</span>
    <span>method</span> <span>String</span> <span>appendChar</span><span>(</span><span>char</span> <span>c</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Erases the last character from an instance of String.</span>
<span>     */</span>
    <span>method</span> <span>void</span> <span>eraseLastChar</span><span>(</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Returns the integer value of an instance of String until the first</span>
<span>     * non-numeric character.</span>
<span>     */</span>
    <span>method</span> <span>int</span> <span>intValue</span><span>(</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Sets an instance of String to the representation of the given number.</span>
<span>     */</span>
    <span>method</span> <span>void</span> <span>setInt</span><span>(</span><span>int</span> <span>number</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Returns the new line character.</span>
<span>     */</span>
    <span>function</span> <span>char</span> <span>newLine</span><span>(</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Returns the backspace character.</span>
<span>     */</span>
    <span>function</span> <span>char</span> <span>backSpace</span><span>(</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Returns the quotation mark character.</span>
<span>     */</span>
    <span>function</span> <span>char</span> <span>doubleQuote</span><span>(</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Sys</h3><a id="user-content-sys" aria-label="Permalink: Sys" href="#sys"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="/**
 * A library that supports various program execution services.
 */
class Sys {
    /**
     * Halts the program execution.
     */
    function void halt();

    /**
     * Displays the given error code in the format &quot;ERR[errorCode]&quot;, and halts
     * the program's execution.
     */
    function void error(int errorCode);

    /**
     * Waits approximately duration milliseconds and returns. Note that this is
     * runtime dependent and may not be accurate.
     */
    function void wait(int duration);
}"><pre><span>/**</span>
<span> * A library that supports various program execution services.</span>
<span> */</span>
<span>class</span> <span>Sys</span> <span>{</span>
    <span>/**</span>
<span>     * Halts the program execution.</span>
<span>     */</span>
    <span>function</span> <span>void</span> <span>halt</span><span>(</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Displays the given error code in the format "ERR[errorCode]", and halts</span>
<span>     * the program's execution.</span>
<span>     */</span>
    <span>function</span> <span>void</span> <span>error</span><span>(</span><span>int</span> <span>errorCode</span><span>)</span><span>;</span>

    <span>/**</span>
<span>     * Waits approximately duration milliseconds and returns. Note that this is</span>
<span>     * runtime dependent and may not be accurate.</span>
<span>     */</span>
    <span>function</span> <span>void</span> <span>wait</span><span>(</span><span>int</span> <span>duration</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Error Codes</h3><a id="user-content-error-codes" aria-label="Permalink: Error Codes" href="#error-codes"></a></p>
<p dir="auto">If you do something that forces the computer into an invalid state, like computing the result of <code>1 / 0</code>, the Jack OS will display one of these error codes in the format "ERR[N]" and immediately terminate the program.</p>
<table>
<thead>
<tr>
<th>Code</th>
<th>Method/Function</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Sys.wait</td>
<td>Duration must be positive</td>
</tr>
<tr>
<td>2</td>
<td>Array.new</td>
<td>Array size must be positive</td>
</tr>
<tr>
<td>3</td>
<td>Math.divide</td>
<td>Division by zero</td>
</tr>
<tr>
<td>4</td>
<td>Math.sqrt</td>
<td>Cannot compute square root of a negative number</td>
</tr>
<tr>
<td>5</td>
<td>Memory.alloc</td>
<td>Allocated memory size must be positive</td>
</tr>
<tr>
<td>6</td>
<td>Memory.alloc</td>
<td>Heap overflow</td>
</tr>
<tr>
<td>7</td>
<td>Screen.drawPixel</td>
<td>Illegal pixel coordinates</td>
</tr>
<tr>
<td>8</td>
<td>Screen.drawLine</td>
<td>Illegal line coordinates</td>
</tr>
<tr>
<td>9</td>
<td>Screen.drawRectangle</td>
<td>Illegal rectangle coordinates</td>
</tr>
<tr>
<td>12</td>
<td>Screen.drawCircle</td>
<td>Illegal center coordinates</td>
</tr>
<tr>
<td>13</td>
<td>Screen.drawCircle</td>
<td>Illegal radius</td>
</tr>
<tr>
<td>14</td>
<td>String.new</td>
<td>Maximum length must be non-negative</td>
</tr>
<tr>
<td>15</td>
<td>String.charAt</td>
<td>String index out of bounds</td>
</tr>
<tr>
<td>16</td>
<td>String.setCharAt</td>
<td>String index out of bounds</td>
</tr>
<tr>
<td>17</td>
<td>String.appendChar</td>
<td>String is full</td>
</tr>
<tr>
<td>19</td>
<td>String.setInt</td>
<td>Insufficient string capacity</td>
</tr>
<tr>
<td>20</td>
<td>Output.moveCursor</td>
<td>Illegal cursor location</td>
</tr>
</tbody>
</table>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQ</h2><a id="user-content-faq" aria-label="Permalink: FAQ" href="#faq"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Whoa, is <em>everything</em> made from NAND gates?</h3><a id="user-content-whoa-is-everything-made-from-nand-gates" aria-label="Permalink: Whoa, is everything made from NAND gates?" href="#whoa-is-everything-made-from-nand-gates"></a></p>
<p dir="auto">Well..., I admit the description and title are a little misleading, but still in good faith. The compiler and virtual machine translator are written in Typescript, while the kernel and hardware are emulated in Rust. Just the logic simulator runs computations and memory accesses from NAND gates. Bootstrapping the full tech stack is a feat that isn't unheard of, but such a massive project by itself probably deserves its own separate project.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Did you design NAND by yourself?</h3><a id="user-content-did-you-design-nand-by-yourself" aria-label="Permalink: Did you design NAND by yourself?" href="#did-you-design-nand-by-yourself"></a></p>
<p dir="auto">NAND follows the <a href="https://www.nand2tetris.org/" rel="nofollow">Nand to Tetris course</a> and its <a href="https://www.amazon.com/Elements-Computing-Systems-second-Principles-dp-0262539802/dp/0262539802/ref=dp_ob_title_bk" rel="nofollow">associated book</a> (you should definitely check it out, it's an absolutely incredible read). I solely implemented the specification for CPU, assembler, virtual machine translator, and compiler, while porting the platform to the web with its own IDE and user interface.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">If there's only one type, what is the point of specifying types at all?</h3><a id="user-content-if-theres-only-one-type-what-is-the-point-of-specifying-types-at-all" aria-label="Permalink: If there's only one type, what is the point of specifying types at all?" href="#if-theres-only-one-type-what-is-the-point-of-specifying-types-at-all"></a></p>
<p dir="auto">This question references the fact that under the hood, the signed 16-bit integer is Jack's only real type. We anyways need to be so explicit with types to help the compiler figure out which class certain instance methods belong to. If we declare the Jack variable <code>s</code> with the type <code>String</code>, <code>s.appendChar(33)</code> is transformed during compilation into <code>String.appendChar(s, 33)</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Why does the IDE feel finnicky?</h3><a id="user-content-why-does-the-ide-feel-finnicky" aria-label="Permalink: Why does the IDE feel finnicky?" href="#why-does-the-ide-feel-finnicky"></a></p>
<p dir="auto">NAND's IDE unfortunately trades implementation simplicity for a worse user experience. It uses the unorthodox <a href="https://medium.engineering/why-contenteditable-is-terrible-122d8a40e480" rel="nofollow">contenteditable</a> and hacky cursor positioning logic to get syntax highlighting to work. I myself was surprised that I managed to even bring it to a functional state. As a result, it's slow and noticeably buggy, plus common keybinds don't work. I'm sorry, but for now you'll just need to bear with me.</p>
<hr>
<p dir="auto">You now know how to program NAND in Jack! And wow! It's been grand voyage of discovery. This write-up only begins to do justice the pure genius behind the computer architecture of the modern world. Hopefully, you gain a newfound appreciation for the Herculean amount of technical complexity it takes to bridge the gap between your code and program output on the screen.</p>
<p dir="auto">Press "Start" to compile and run your code. The OS will typically take a little under a second to initialize memory and set up its services before you're off to see your program running!</p>
<p dir="auto">If you've read this far, my heartfelt thank you! Happy coding!</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MemoryDB: A fast and durable memory-first cloud database (122 pts)]]></title>
            <link>https://www.amazon.science/publications/amazon-memorydb-a-fast-and-durable-memory-first-cloud-database</link>
            <guid>40158794</guid>
            <pubDate>Thu, 25 Apr 2024 15:34:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.amazon.science/publications/amazon-memorydb-a-fast-and-durable-memory-first-cloud-database">https://www.amazon.science/publications/amazon-memorydb-a-fast-and-durable-memory-first-cloud-database</a>, See on <a href="https://news.ycombinator.com/item?id=40158794">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-no-media="" data-image-align="top">
        
            
        

        

        
    <p>The JP Economics and Decision Science Team is looking for an Intern Economist with experience in empirical economic analysis to conduct research on the impact evaluation and prediction of marketing campaigns in Amazon Japan's online retail business. The successful candidate will work closely with the team to improve the efficiency of designing marketing campaigns. We are looking for detail-oriented, organized, and responsible individuals who are eager to learn how to work with large and complicated data sets. Knowledge of econometrics and applied microeconomics and familiarity with Stata, R, or Python are necessary. Experience with SQL would be a plus, but not required. These are full-time positions at 40 hours per week, with compensation being awarded on an hourly basis. You will work in a team of economists, data scientists, and engineers and in collaboration with product and finance managers. These skills will translate well into writing applied chapters in your dissertation and provide you with work experience that may help you with placement. Roughly 85% of interns from previous cohorts have converted to full time economics employment at Amazon. If you are interested, please send your CV to our mailing list at econ-internship@amazon.com. Key job responsibilities • Use regression analysis to estimate econometric models and develop forecasting solutions that can predict marketing campaign effectiveness. • Collaborate with other economists and data scientists to validate and refine the econometric models. • Work with product managers and software developers to integrate the forecasting models into the campaign management system. • Monitor the accuracy and effectiveness of the forecasting models and make adjustments as necessary. • Communicate your findings and recommendations to team members and stakeholders. A day in the life - Discussions with business partners, as well as product managers and tech leaders to understand the business problem. - Brainstorming with other scientists and economists to design the right model for the problem in hand. - Present the results and new ideas for existing or forward looking problems to leadership. - Deep dive into the data. - Modeling and creating working prototypes. - Analyze the results and review with partners. About the team We are a team of economists, data scientists, and business intelligence engineers supporting Amazon Japan's Customer Growth and Engagement (CGE) org as the one-stop data science enabler. We use analytical insights and products to empower CGE and align strategic decisions across partner teams (e.g., Operations, Delivery Experience, Pricing). We are open to hiring candidates to work out of one of the following locations: Seattle, WA, USA</p>



        

        

        

        
    </div><div data-no-media="" data-image-align="top">
        
            
        

        

        
    <p>The Fulfillment by Amazon (FBA) team is looking for a passionate, curious, and creative Senior Applied Scientist, with expertise in machine learning and a proven record of solving business problems through scalable ML solutions, to join our top-notch cross-domain FBA science team. We want to learn seller behaviors, understand seller experience, build automated LLM-based solutions to sellers, design seller policies and incentives, and develop science products and services that empower third-party sellers to grow their businesses. We also predict potentially costly defects that may occur during packing, shipping, receiving and storing the inventory. We aim to prevent such defects before occurring while we are also fulfilling customer demand as quickly and efficiently as possible, in addition to managing returns and reimbursements. To do so, we build and innovate science solutions at the intersection of machine learning, statistics, economics, operations research, and data analytics. As a senior applied scientist, you will propose and deploy solutions that will likely draw from a range of scientific areas such as supervised and unsupervised learning, recommendation systems, statistical learning, LLMs, and reinforcement learning. This role has high visibility to senior Amazon business leaders and involves working with other scientists, and partnering with engineering and product teams to integrate scientific work into production systems. Key job responsibilities - As a senior member of the science team, you will play an integral part in building Amazon's FBA management system. - Research and develop machine learning models to solve diverse business problems faced in Seller inventory management systems. - Define a long-term science vision and roadmap for the team, driven fundamentally from our customers' needs, translating those directions into specific plans for research and applied scientists, as well as engineering and product teams. - Drive and execute machine learning projects/products end-to-end: from ideation, analysis, prototyping, development, metrics, and monitoring. - Review and audit modeling processes and results for other scientists, both junior and senior. - Advocate the right ML solutions to business stakeholders, engineering teams, as well as executive level decision makers A day in the life In this role, you will be a technical leader in machine learning with significant scope, impact, and high visibility. Your solutions may lead to billions of dollars impact on either the topline or the bottom line of Amazon third-party seller business. As a senior scientist on the team, you will be involved in every aspect of the process - from idea generation, business analysis and scientific research, through to development and deployment of advanced models - giving you a real sense of ownership. From day one, you will be working with experienced scientists, engineers, and designers who love what they do. You are expected to make decisions about technology, models and methodology choices. You will strive for simplicity, and demonstrate judgment backed by mathematical proof. You will also collaborate with the broader decision and research science community in Amazon to broaden the horizon of your work and mentor engineers and scientists. The successful candidate will have the strong expertise in applying machine learning models in an applied environment and is looking for her/his next opportunity to innovate, build, deliver, and impress. We are seeking someone who wants to lead projects that require innovative thinking and deep technical problem-solving skills to create production-ready machine learning solutions. The candidate will need to be entrepreneurial, wear many hats, and work in a fast-paced, high-energy, highly collaborative environment. We value highly technical people who know their subject matter deeply and are willing to learn new areas. We look for individuals who know how to deliver results and show a desire to develop themselves, their colleagues, and their career. About the team Fulfillment by Amazon (FBA) is a service that allows sellers to outsource order fulfillment to Amazon, allowing sellers to leverage Amazon’s world-class facilities to provide customers Prime delivery promise. Sellers gain access to Prime members worldwide, see their sales lift, and are free to focus their time and resources on what they do best while Amazon manages fulfillment. Over the last several years, sellers have enjoyed strong business growth with FBA shipping more than half of all products offered by Amazon. FBA focuses on helping sellers with automating and optimizing the third-party supply chain. FBA sellers leverage Amazon’s expertise in machine learning, optimization, data analytics, econometrics, and market design to deliver the best inventory management experience to sellers. We work full-stack, from foundational backend systems to future-forward user interfaces. Our culture is centered on rapid prototyping, rigorous experimentation, and data-driven decision-making. We are open to hiring candidates to work out of one of the following locations: Bellevue, WA, USA</p>



        

        

        

        
    </div><div data-no-media="" data-image-align="top">
        
            
        

        

        
    <p>The Fulfillment by Amazon (FBA) team is looking for a passionate, curious, and creative Applied Scientist, with expertise and experience in machine learning, to join our top-notch cross-domain FBA science team. We want to learn seller behaviors, understand seller experience, build automated LLM-based solutions to sellers, design seller policies and incentives, and develop science products and services that empower third-party sellers to grow their businesses. We also predict potentially costly defects that may occur during packing, shipping, receiving and storing the inventory. We aim to prevent such defects before occurring while we are also fulfilling customer demand as quickly and efficiently as possible, in addition to managing returns and reimbursements. To do so, we build and innovate science solutions at the intersection of machine learning, statistics, economics, operations research, and data analytics. As an applied scientist, you will design and implement ML solutions that will likely draw from a range of scientific areas such as supervised and unsupervised learning, recommendation systems, statistical learning, LLMs, and reinforcement learning. This role has high visibility to senior Amazon business leaders and involves working with other senior and principal scientists, and partnering with engineering and product teams to integrate scientific work into production systems. Key job responsibilities - Research and develop machine learning models to solve diverse FBA business problems. - Translate business requirements/problems into specific plans for research and applied scientists, as well as engineering and product teams. - Drive and execute machine learning projects/products end-to-end: from ideation, analysis, prototyping, development, metrics, and monitoring. - Work closely with teams of scientists, product managers, program managers, software engineers to drive production model implementations. - Build scalable, efficient, automated processes for large scale data analyses, model development, model validation and model implementation. - Advocate technical solutions to business stakeholders, engineering teams, as well as executive level decision makers A day in the life In this role, you will work in machine learning with significant scope, impact, and high visibility. Your solutions may lead to billions of dollars impact on either the topline or the bottom line of Amazon third-party seller business. As an applied scientist, you will be involved in every aspect of the scientific development process - from idea generation, business analysis and scientific research, through to development and deployment of advanced models - giving you a real sense of ownership. From day one, you will be working with experienced scientists, engineers, and designers who love what they do. You are expected to make decisions about technology, models and methodology choices. You will strive for simplicity, and demonstrate judgment backed by mathematical proof. You will also collaborate with the broader decision and research science community in Amazon to broaden the horizon of your work and mentor engineers and scientists. The successful candidate will have the strong expertise in applying machine learning models in an applied environment and is looking for her/his next opportunity to innovate, build, deliver, and impress. We are seeking someone who wants to lead projects that require innovative thinking and deep technical problem-solving skills to create production-ready machine learning solutions. We value highly technical people who know their subject matter deeply and are willing to learn new areas. We look for individuals who know how to deliver results and show a desire to develop themselves, their colleagues, and their career. About the team Fulfillment by Amazon (FBA) is a service that allows sellers to outsource order fulfillment to Amazon, allowing sellers to leverage Amazon’s world-class facilities to provide customers Prime delivery promise. Sellers gain access to Prime members worldwide, see their sales lift, and are free to focus their time and resources on what they do best while Amazon manages fulfillment. Over the last several years, sellers have enjoyed strong business growth with FBA shipping more than half of all products offered by Amazon. FBA focuses on helping sellers with automating and optimizing the third-party supply chain. FBA sellers leverage Amazon’s expertise in machine learning, optimization, data analytics, econometrics, and market design to deliver the best inventory management experience to sellers. We work full-stack, from foundational backend systems to future-forward user interfaces. Our culture is centered on rapid prototyping, rigorous experimentation, and data-driven decision-making. We are open to hiring candidates to work out of one of the following locations: Bellevue, WA, USA</p>



        

        

        

        
    </div><div data-no-media="" data-image-align="top">
        
            
        

        

        
    <p>Outbound Communications own the worldwide charter for delighting our customers with timely, relevant notifications (email, mobile, SMS and other channels) to drive awareness and discovery of Amazon’s products and services. We meet customers at their channel of preference with the most relevant content at the right time and frequency. We directly create and operate marketing campaigns, and we have also enabled select partner teams to build programs by reusing and extending our infrastructure. We optimize for customers to receive the most relevant and engaging content across all of Amazon worldwide, and apply the appropriate guardrails to ensure a consistent and high-quality CX. Outbound Communications seek a talented Applied Scientist to join our team to develop the next generation of automated and personalized marketing programs to help Amazon customers in their shopping journeys worldwide. Come join us in our mission today! Key job responsibilities As an Applied Scientist on the team, you will lead the roadmap and strategy for applying science to solve customer problems in the automated marketing domain. This is an opportunity to come in on Day 0 and lead the science strategy of one of the most interesting problem spaces at Amazon - understanding the Amazon customer to build deeply personalized and adaptive messaging experiences. You will be part of a multidisciplinary team and play an active role in translating business and functional requirements into concrete deliverables. You will work closely with product management and the software development team to put solutions into production. You will apply your skills in areas such as deep learning and reinforcement learning while building scalable industrial systems. You will have a unique opportunity to produce and deliver models that help build best-in-class customer experiences and build systems that allow us to deploy these models to production with low latency and high throughput. We are open to hiring candidates to work out of one of the following locations: Seattle, WA, USA</p>



        

        

        

        
    </div><div data-no-media="" data-image-align="top">
        
            
        

        

        
    <p>The Artificial General Intelligence (AGI) team is looking for a passionate, talented, and inventive Applied Scientist with a strong deep learning background, to help build industry-leading technology with multimodal systems. Key job responsibilities As an Applied Scientist with the AGI team, you will work with talented peers to develop novel algorithms and modeling techniques to advance the state of the art with multimodal systems. Your work will directly impact our customers in the form of products and services that make use of vision and language technology. You will leverage Amazon’s heterogeneous data sources and large-scale computing resources to accelerate development with multimodal Large Language Models (LLMs) and Generative Artificial Intelligence (Gen AI) in Computer Vision. About the team The AGI team has a mission to push the envelope with multimodal LLMs and Gen AI in Computer Vision, in order to provide the best-possible experience for our customers. We are open to hiring candidates to work out of one of the following locations: Seattle, WA, USA</p>



        

        

        

        
    </div><div data-no-media="" data-image-align="top">
        
            
        

        

        
    <p>Economic Decision Science is a central science team working across a variety of topics in the EU Stores business and beyond. We work closely EU business leaders to drive change at Amazon. We focus on solving long-term, ambiguous and challenging problems, while providing advisory support to help solve short-term business pain points. Key topics include pricing, product selection, delivery speed, profitability, and customer experience. We tackle these issues by building novel econometric models, machine learning systems, and high-impact experiments which we integrate into business, financial, and system-level decision making. Our work is highly collaborative and we regularly partner with EU- and US-based interdisciplinary teams. We are looking for a Senior Economist who is able to provide structure around complex business problems, hone those complex problems into specific, scientific questions, and test those questions to generate insights. The ideal candidate will work with various science, engineering, operations and analytics teams to estimate models and algorithms on large scale data, design pilots and measure their impact, and transform successful prototypes into improved policies and programs at scale. If you have an entrepreneurial spirit, you know how to deliver results fast, and you have a deeply quantitative, highly innovative approach to solving problems, and long for the opportunity to build pioneering solutions to challenging problems, we want to talk to you. Key job responsibilities - Provide data-driven guidance and recommendations on strategic questions facing the EU Retail leadership - Scope, design and implement version-zero (V0) models and experiments to kickstart new initiatives, thinking, and drive system-level changes across Amazon - Build a long-term research agenda to understand, break down, and tackle the most stubborn and ambiguous business challenges - Influence business leaders and work closely with other scientists at Amazon to deliver measurable progress and change We are open to hiring candidates to work out of one of the following locations: London, GBR</p>



        

        

        

        
    </div><div data-no-media="" data-image-align="top">
        
            
        

        

        
    <p>We’re working to improve shopping on Amazon using the conversational capabilities of LLMs, and are searching for pioneers who are passionate about technology, innovation, and customer experience, and are ready to make a lasting impact on the industry. You'll be working with talented scientists, engineers, across the breadth of Amazon Shopping and AGI to innovate on behalf of our customers. If you're fired up about being part of a dynamic, driven team, then this is your moment to join us on this exciting journey! We are open to hiring candidates to work out of one of the following locations: Seattle, WA, USA</p>



        

        

        

        
    </div><div data-no-media="" data-image-align="top">
        
            
        

        

        
    <p>Amazon is looking for a passionate, talented, and inventive Applied Scientist with background in Natural Language Processing (NLP), Deep Learning, Generative AI (GenAI) to help build industry-leading technology in contact center. The ideal candidate should have a robust foundation in NLP and machine learning and a keen interest in advancing the field. The ideal candidate would also enjoy operating in dynamic environments, have the self-motivation to take on challenging problems to deliver big customer impact, and move fast to ship solutions and innovate along the development process. As part of our Transcribe science team in Amazon AWS AI, you will have the opportunity to build the next generation call center analytic solutions. You will work along side a supportive and collaborative team with a healthy mix of scientists, software engineers and language engineers to research and develop state-of-the-art technology for natural language processing. A day in the life AWS Utility Computing (UC) provides product innovations — from foundational services such as Amazon’s Simple Storage Service (S3) and Amazon Elastic Compute Cloud (EC2), to consistently released new product innovations that continue to set AWS’s services and features apart in the industry. As a member of the UC organization, you’ll support the development and management of Compute, Database, Storage, Internet of Things (Iot), Platform, and Productivity Apps services in AWS, including support for customers who require specialized security solutions for their cloud services. Diverse Experiences AWS values diverse experiences. Even if you do not meet all of the qualifications and skills listed in the job description, we encourage candidates to apply. If your career is just starting, hasn’t followed a traditional path, or includes alternative experiences, don’t let it stop you from applying. Why AWS? Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating — that’s why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses. Inclusive Team Culture Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster a culture of inclusion that empower us to be proud of our differences. Ongoing events and learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences, inspire us to never stop embracing our uniqueness. Mentorship &amp; Career Growth We’re continuously raising our performance bar as we strive to become Earth’s Best Employer. That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing resources here to help you develop into a better-rounded professional. Work/Life Balance We value work-life harmony. Achieving success at work should never come at the expense of sacrifices at home, which is why we strive for flexibility as part of our working culture. When we feel supported in the workplace and at home, there’s nothing we can’t achieve in the cloud. Hybrid Work We value innovation and recognize this sometimes requires uninterrupted time to focus on a build. We also value in-person collaboration and time spent face-to-face. Our team affords employees options to work in the office every day or in a flexible, hybrid work model near one of our U.S. Amazon offices. We are open to hiring candidates to work out of one of the following locations: Bellevue, WA, USA | Seattle, WA, USA</p>



        

        

        

        
    </div><div data-no-media="" data-image-align="top">
        
            
        

        

        
    <p>The Automated Reasoning Group in AWS Platform is looking for an Applied Scientist with experience in building scalable solver solutions that delight customers. You will be part of a world-class team building the next generation of automated reasoning tools and services. AWS has the most services and more features within those services, than any other cloud provider–from infrastructure technologies like compute, storage, and databases–to emerging technologies, such as machine learning and artificial intelligence, data lakes and analytics, and Internet of Things. You will apply your knowledge to propose solutions, create software prototypes, and move prototypes into production systems using modern software development tools and methodologies. In addition, you will support and scale your solutions to meet the ever-growing demand of customer use. You will use your strong verbal and written communication skills, are self-driven and own the delivery of high quality results in a fast-paced environment. Each day, hundreds of thousands of developers make billions of transactions worldwide on AWS. They harness the power of the cloud to enable innovative applications, websites, and businesses. Using automated reasoning technology and mathematical proofs, AWS allows customers to answer questions about security, availability, durability, and functional correctness. We call this provable security, absolute assurance in security of the cloud and in the cloud. See https://aws.amazon.com/security/provable-security/ As an Applied Scientist in AWS Platform, you will play a pivotal role in shaping the definition, vision, design, roadmap and development of product features from beginning to end. You will: - Define and implement new solver applications that are scalable and efficient approaches to difficult problems - Apply software engineering best practices to ensure a high standard of quality for all team deliverables - Work in an agile, startup-like development environment, where you are always working on the most important stuff - Deliver high-quality scientific artifacts - Work with the team to define new interfaces that lower the barrier of adoption for automated reasoning solvers - Work with the team to help drive business decisions The AWS Platform is the glue that holds the AWS ecosystem together. From identity features such as access management and sign on, cryptography, console, builder &amp; developer tools, to projects like automating all of our contractual billing systems, AWS Platform is always innovating with the customer in mind. The AWS Platform team sustains over 750 million transactions per second. Learn and Be Curious. We have a formal mentor search application that lets you find a mentor that works best for you based on location, job family, job level etc. Your manager can also help you find a mentor or two, because two is better than one. In addition to formal mentors, we work and train together so that we are always learning from one another, and we celebrate and support the career progression of our team members. Inclusion and Diversity. Our team is diverse! We drive towards an inclusive culture and work environment. We are intentional about attracting, developing, and retaining amazing talent from diverse backgrounds. Team members are active in Amazon’s 10+ affinity groups, sometimes known as employee resource groups, which bring employees together across businesses and locations around the world. These range from groups such as the Black Employee Network, Latinos at Amazon, Indigenous at Amazon, Families at Amazon, Amazon Women and Engineering, LGBTQ+, Warriors at Amazon (Military), Amazon People With Disabilities, and more. Key job responsibilities Work closely with internal and external users on defining and extending application domains. Tune solver performance for application-specific demands. Identify new opportunities for solver deployment. About the team Solver science is a talented team of scientists from around the world. Expertise areas include solver theory, performance, implementation, and applications. Diverse Experiences AWS values diverse experiences. Even if you do not meet all of the qualifications and skills listed in the job description, we encourage candidates to apply. If your career is just starting, hasn’t followed a traditional path, or includes alternative experiences, don’t let it stop you from applying. Why AWS? Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating — that’s why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses. Inclusive Team Culture Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster a culture of inclusion that empower us to be proud of our differences. Ongoing events and learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences, inspire us to never stop embracing our uniqueness. Mentorship &amp; Career Growth We’re continuously raising our performance bar as we strive to become Earth’s Best Employer. That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing resources here to help you develop into a better-rounded professional. Work/Life Balance We value work-life harmony. Achieving success at work should never come at the expense of sacrifices at home, which is why we strive for flexibility as part of our working culture. When we feel supported in the workplace and at home, there’s nothing we can’t achieve in the cloud. Hybrid Work We value innovation and recognize this sometimes requires uninterrupted time to focus on a build. We also value in-person collaboration and time spent face-to-face. Our team affords employees options to work in the office every day or in a flexible, hybrid work model near one of our U.S. Amazon offices. We are open to hiring candidates to work out of one of the following locations: Portland, OR, USA | Seattle, WA, USA</p>



        

        

        

        
    </div><div data-no-media="" data-image-align="top">
        
            
        

        

        
    <p>Amazon Search JP builds features powering product search on the Amazon JP shopping site and expands the innovations to world wide. As an Applied Scientist on this growing team, you will take on a key role in improving the NLP and ranking capabilities of the Amazon product search service. Our ultimate goal is to help customers find the products they are searching for, and discover new products they would be interested in. We do so by developing NLP components that cover a wide range of languages and systems. As an Applied Scientist for Search JP, you will design, implement and deliver search features on Amazon site, helping millions of customers every day to find quickly what they are looking for. You will propose innovation in NLP and IR to build ML models trained on terabytes of product and traffic data, which are evaluated using both offline metrics as well as online metrics from A/B testing. You will then integrate these models into the production search engine that serves customers, closing the loop through data, modeling, application, and customer feedback. The chosen approaches for model architecture will balance business-defined performance metrics with the needs of millisecond response times. Key job responsibilities - Designing and implementing new features and machine learned models, including the application of state-of-art deep learning to solve search matching, ranking and Search suggestion problems. - Analyzing data and metrics relevant to the search experiences. - Working with teams worldwide on global projects. Your benefits include: - Working on a high-impact, high-visibility product, with your work improving the experience of millions of customers - The opportunity to use (and innovate) state-of-the-art ML methods to solve real-world problems with tangible customer impact - Being part of a growing team where you can influence the team's mission, direction, and how we achieve our goals We are open to hiring candidates to work out of one of the following locations: Beijing, 11, CHN | Shanghai, 31, CHN</p>



        

        

        

        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We have 4 days to contest KYC being required by internet services (438 pts)]]></title>
            <link>https://www.federalregister.gov/documents/2024/01/29/2024-01580/taking-additional-steps-to-address-the-national-emergency-with-respect-to-significant-malicious</link>
            <guid>40158752</guid>
            <pubDate>Thu, 25 Apr 2024 15:31:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.federalregister.gov/documents/2024/01/29/2024-01580/taking-additional-steps-to-address-the-national-emergency-with-respect-to-significant-malicious">https://www.federalregister.gov/documents/2024/01/29/2024-01580/taking-additional-steps-to-address-the-national-emergency-with-respect-to-significant-malicious</a>, See on <a href="https://news.ycombinator.com/item?id=40158752">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
        <h3>Request Access</h3>
        

        <p>
  Due to aggressive automated scraping of FederalRegister.gov and eCFR.gov, programmatic access to these sites is limited to access to our extensive developer APIs.
</p>

<p>
  If you are human user receiving this message, we can add your IP address to a set of IPs that can access FederalRegister.gov &amp; eCFR.gov; complete the CAPTCHA (bot test) below and click "Request Access". This process will be necessary for each IP address you wish to access the site from, requests are valid for approximately one quarter (three months) after which the process may need to be repeated.
</p>

<form action="/request" method="post">
  

          

  
</form>

<p>
  <em>An official website of the United States government.</em>
</p>

<p>
  If you want to request a wider IP range, first request access for your current IP, and then use the "Site Feedback" button found in the lower left-hand side to make the request.
</p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Launch HN: Nango (YC W23) – Source-available unified API (146 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=40158481</link>
            <guid>40158481</guid>
            <pubDate>Thu, 25 Apr 2024 15:09:02 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=40158481">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="40158481">
      <td><span></span></td>      <td><center><a id="up_40158481" href="https://news.ycombinator.com/vote?id=40158481&amp;how=up&amp;goto=item%3Fid%3D40158481"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=40158481">Launch HN: Nango (YC W23) – Source-available unified API</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_40158481">107 points</span> by <a href="https://news.ycombinator.com/user?id=rguldener">rguldener</a> <span title="2024-04-25T15:09:02"><a href="https://news.ycombinator.com/item?id=40158481">3 hours ago</a></span> <span id="unv_40158481"></span> | <a href="https://news.ycombinator.com/hide?id=40158481&amp;goto=item%3Fid%3D40158481">hide</a> | <a href="https://hn.algolia.com/?query=Launch%20HN%3A%20Nango%20(YC%20W23)%20%E2%80%93%20Source-available%20unified%20API&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=40158481&amp;auth=3e790d79d449d3b4c831cdedc309e0340089c37e">favorite</a> | <a href="https://news.ycombinator.com/item?id=40158481">59&nbsp;comments</a>        </span>
              </td></tr>
    <tr></tr><tr><td colspan="2"></td><td><div><p>Hey everyone, we are Bastien and Robin from Nango (<a href="https://www.nango.dev/">https://www.nango.dev</a>). We take care of the annoyances of external APIs (167 and counting) so you can quickly build custom integrations for your SaaS, while retaining full control over how they work.
2 min demo video: <a href="https://www.loom.com/share/d04c67b47e284e86b91b4b99fba548ec" rel="nofollow">https://www.loom.com/share/d04c67b47e284e86b91b4b99fba548ec</a></p><p>SaaS engineering teams face a tough choice: they can build each integration in-house from scratch, which gives them full control but takes a lot of time and maintenance effort. Or they can use pre-built solutions, which are fast and easy but less flexible and might not fulfill all customer needs.</p><p>Nango combines the best of both worlds. We let you quickly ship custom integrations without building complex infrastructure or diving deep into the quirks of each API. You control the business logic, data models, and customer-specific configurations, like custom field mappings. We handle (O)Auth and run your integrations reliably in production.</p><p>Under the hood, your integrations run as typescript “lambdas” on Nango. A typical integration has 3-5 lambdas of 20-50 lines of code each. These lambdas live inside your git repo, are version-controlled with the rest of your app, and get deployed to Nango with a CLI (<a href="https://docs.nango.dev/understand/core-concepts">https://docs.nango.dev/understand/core-concepts</a>).</p><p>Our runtime has a built-in scheduler for continuous background syncs, monitoring to know if your integrations run as expected, detailed logging of everything that happens in Nango, and pre-built infrastructure to deal with (O)auth, retries, rate-limit handling, webhook floods, data caching, de-duplication, etc. More here: <a href="https://docs.nango.dev/understand/architecture">https://docs.nango.dev/understand/architecture</a></p><p>We have found that ChatGPT and Copilot let you build integrations on Nango very fast without having to learn each API’s intricacies. LLMs are great at figuring out which endpoint to use, what parameters it takes, etc. Paired with our runtime, this lets you build complex, high-scale integrations in hours instead of weeks.</p><p>We’ve put a ton of effort into dealing with API complexities, so you don’t have to. Even integrations that looked simple at first ended up forcing us to extend our infra to deal with their quirks and gotchas.</p><p>For example, we had to figure out 100+ different OAuth implementations (see <a href="https://www.nango.dev/blog/why-is-oauth-still-hard">https://www.nango.dev/blog/why-is-oauth-still-hard</a> and <a href="https://news.ycombinator.com/item?id=35713518">https://news.ycombinator.com/item?id=35713518</a>). We had to deal with a half-dozen non-standard auth methods (Github apps, Stripe apps, Netsuite, etc.), expiring webhooks, ways to deal with data dependencies, weird pagination methods, API keys that change with every API call, dozens of different ways to register for webhooks, etc. It’s a constantly moving target, but it is a challenge we have come to love, and we think the approach makes sense: we specialize in finicky details that vary from API to API—you specialize in making your product great and offering more integrations to your users.</p><p>Last but not least, Nango is open source (<a href="https://github.com/NangoHQ/nango">https://github.com/NangoHQ/nango</a>) under the ELv2 license (allows most use cases, except for direct copy-cats). Anybody can contribute new APIs &amp; share their integration templates with the community.</p><p>The fastest way to see Nango in action is with our interactive demo here (no signup required): <a href="https://app.nango.dev/hn-demo">https://app.nango.dev/hn-demo</a></p><p>Or take a look at our docs: <a href="https://docs.nango.dev/">https://docs.nango.dev</a></p><p>We would love to hear your feedback and look forward to the comments!</p></div></td></tr>        <tr></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ex-athletic director arrested for framing principal with AI-generated voice (178 pts)]]></title>
            <link>https://www.thebaltimorebanner.com/education/k-12-schools/eric-eiswert-ai-audio-baltimore-county-YBJNJAS6OZEE5OQVF5LFOFYN6M/</link>
            <guid>40158183</guid>
            <pubDate>Thu, 25 Apr 2024 14:43:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thebaltimorebanner.com/education/k-12-schools/eric-eiswert-ai-audio-baltimore-county-YBJNJAS6OZEE5OQVF5LFOFYN6M/">https://www.thebaltimorebanner.com/education/k-12-schools/eric-eiswert-ai-audio-baltimore-county-YBJNJAS6OZEE5OQVF5LFOFYN6M/</a>, See on <a href="https://news.ycombinator.com/item?id=40158183">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Baltimore County Police arrested<b> </b>Pikesville High School’s former athletic director Thursday morning and charged him with using artificial intelligence to impersonate Principal Eric Eiswert, leading the public to believe Eiswert made <a href="https://www.thebaltimorebanner.com/education/k-12-schools/pikesville-high-principal-eric-eiswert-NT7K7N4K6RDEJNL5Z7ULTEG7VY/" target="_blank">racist and antisemitic comments</a> behind closed doors.</p><p>Dazhon Darien, 31, was charged with disrupting school activities, after investigators determined Darien faked Eiswert’s voice and circulated the audio on social media in January, according to the Baltimore County State’s Attorney’s Office.<b> </b>Darien’s nickname, DJ, was among the names mentioned in the audio clips he allegedly faked.</p><p>“The audio clip ... had profound repercussions,” police wrote in charging documents. “It not only led to Eiswert’s temporary removal from the school but also triggered a wave of hate-filled messages on social media and numerous calls to the school. The recording also caused significant disruptions for the PHS staff and students.”</p><p>He is also charged with theft and retaliating against a witness, related to alleged illicit payments he made to a school athletics coach, as well as stalking, prosecutors said.</p><p>Baltimore County Police Chief Robert McCullough, County Executive Johnny Olszewski, and School Superintendent Myriam Rogers announced a 1:30 pm press conference to discuss the case.</p><p>Eiswert’s voice, which police and <a href="https://www.thebaltimorebanner.com/education/k-12-schools/eric-eiswert-ai-deepfake-YUNO6ITYM5FWZPQAE24RIBV5CQ/" target="_blank">AI experts believe was simulated</a>, made disparaging comments toward Black students and the surrounding Jewish community, was widely circulated on social media.</p><div id="blueconic--fallback"><p><h3>Read More</h3></p></div><p>Questions about the audio’s authenticity quickly followed. Police wrote in charging documents that Darien had accessed the school’s network on multiple occasions in December and January searching for OpenAI tools, and used “Large Language Models” that practice “deep learning, which involves pulling in vast amounts of data from various sources on the internet, can recognize text inputted by the user, and produce conversational results.” They also connected Darien to an email account that had distributed the recording.</p><p>Many current and former students <a href="https://www.thebaltimorebanner.com/education/k-12-schools/pikesville-high-principal-eric-eiswert-recording-ai-DZ6ZURS3Y5F7HEQMMGBH244Y3E/" target="_blank">believed Eiswert was responsible</a> for the offensive remarks, while former colleagues denounced the audio and defended Eiswert’s character. Eiswert himself has denied making those comments and said the comments do not align with his views.</p><p>The audio, posted to the popular Instagram account<b> </b><a href="https://www.instagram.com/reel/C2NEEDrMo8_/?igsh=MTYwZWE4MnpxdDFvbA%3D%3D" target="_blank">murder_ink_bmore</a>, prompted a Baltimore County Public Schools and Baltimore County Police investigation. Eiswert has not been working in the school since the investigation began.</p><p>The voice refers to “ungrateful Black kids who can’t test their way out of a paper bag” and questions how hard it is to get those students to meet grade-level expectations. The speaker<b> </b>uses names of people who appear to be staff members and says they should not have been hired, and that<b> </b>he should get rid of another person “one way or another.”</p><p>“And if I have to get one more complaint from one more Jew in this community, I’m going to join the other side,” the voice said.</p><p>Darien was being investigated as of December in a theft investigation that had been initiated by Eiswert. Police say Darien had authorized a $1,916 payment to the school’s junior varsity basketball coach, who was also his roommate, under the pretense that he was an assistant girls soccer coach. He was not, school officials said. Eiswert determined that Darien had submitted the payment to the school payroll system, bypassing proper procedures. Darien had been notified of the investigation, police said.</p><p>Police say the clip was received by three teachers the night before it went viral. The first was Darien; a third said she received the email and then got a call from Darien and teacher Shaena Ravenell telling her to check her email. Ravenell told police that she had forwarded the email to a student’s cell phone, “who she knew would rapidly spread the message around various social media outlets and throughout the school,” and also sent it to the media and the NAACP, police said.</p><p>She did not mention receiving it from Darien until confronted about his involvement. Ravenell has not been charged with a crime and could not immediately be reached for comment.</p><p>Rogers, the superintendent, in January called the comments “disturbing” and “highly offensive and inappropriate statements about African American students, Pikesville High School staff, and Pikesville’s Jewish community.”</p><p>Billy Burke, head of the Council of Administrative &amp; Supervisory Employee, the union that represents Eiswert, was the only official to suggest the audio was AI-generated.</p><p>Burke said he was disappointed in the public’s assumption of Eiswert’s guilt. At a January school board meeting, he said the principal needed police presence at his home because he and his family have been harassed and threatened. Burke had also received harassing emails, he said at the time.</p><p>Police said the school’s front desk staff was “inundated with phone calls from parents and students expressing concern and disparaging remarks toward school staff and administrators.” The flood of calls made it difficult to field phone calls from parents trying to make arrangements for their children and other school functions, officials told police.</p><p>“The school leadership expressed that staff did not feel safe, which required an increase in police presence at the school to address safety concerns and fears,” police said.</p><p>Teachers, under the impression the recording was authentic, “expressed fears that recording devices could have been planted in various places in the school,” police said.</p><p>“The recording’s release deeply affected the trust between teachers and the administration,” police said. “One individual shared that they fielded sensitive phone calls in their vehicle in the parking lot instead of speaking in school.”</p><p>Experts in detecting audio and video fakes told The Banner in March that there was <a href="https://www.thebaltimorebanner.com/education/k-12-schools/eric-eiswert-ai-deepfake-YUNO6ITYM5FWZPQAE24RIBV5CQ/" target="_blank">overwhelming evidence</a> the voice is AI-generated. They noted its flat tone, unusually clean background sounds and lack of consistent breathing sounds or pauses as hallmarks of AI. They also ran the audio through several different AI-detection techniques, which consistently concluded it was a fake, though they could not be 100% sure.</p><p>AI voice-generation tools are now widely available online, and a single minute’s recording of someone’s voice can be enough to simulate it with a $5-a-month AI tool, the <a href="https://www.niemanlab.org/2024/02/with-elections-looming-worldwide-heres-how-to-identify-and-investigate-ai-audio-deepfakes/" target="_blank">Nieman Journalism Lab reported</a> in February.</p><p>There are few regulations to prevent AI imitations, called deepfakes, and few perpetrators are prosecuted.</p><div id="article_eoa_container"><p><h3>More From The Banner</h3></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Digital Wood Joints (113 pts)]]></title>
            <link>https://openup.design/we-learn/50-digital-wood-joints/</link>
            <guid>40157530</guid>
            <pubDate>Thu, 25 Apr 2024 13:46:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openup.design/we-learn/50-digital-wood-joints/">https://openup.design/we-learn/50-digital-wood-joints/</a>, See on <a href="https://news.ycombinator.com/item?id=40157530">Hacker News</a></p>
<div id="readability-page-1" class="page">

	<a href="#content">Skip to content</a>
	
<header id="masthead">
    
        
        
        
    
    

    
    

    
    <div><ul id="top-menu"><li id="menu-item-51"><a href="https://openup.design/we-are/">we are</a></li>
<li id="menu-item-209"><a href="https://openup.design/we-learn/">we learn</a></li>
<li id="menu-item-53"><a href="https://openup.design/we-share/">we share</a></li>
<li id="menu-item-54"><a href="https://openup.design/we-talk/">we talk</a></li>
</ul></div>



    
</header>
<nav id="site-navigation" data-bg-color="#000000" data-color="#f9f6f5" data-body-color="#000000">
	
	
    
	

</nav>	
<div data-bg-color="#ffffff" data-color="#000000" data-namespace="default" id="barba-wrapper">
		
		
		
		

		

		
<main>
	
		
	
<article id="post-1464">
	
	
<header>  
    
    <div>
        
        
        
        <div>
            
            
            
                
            
            
            
                        
            <figure><img width="654" height="500" src="https://openup.design/wp-content/uploads/Jigsaw-Mitre-Joint.jpg" alt="" decoding="async" fetchpriority="high" srcset="https://openup.design/wp-content/uploads/Jigsaw-Mitre-Joint.jpg 654w, https://openup.design/wp-content/uploads/Jigsaw-Mitre-Joint-300x229.jpg 300w, https://openup.design/wp-content/uploads/Jigsaw-Mitre-Joint-600x459.jpg 600w" sizes="(max-width: 654px) 100vw, 654px"></figure>
            
                    
        </div>
        
        <div>
            
            
            
                                
                    <h2>50 Digital Wood Joints</h2>
        
                            
            
            
            <div>
                    
                    <p><span>Published: </span><time datetime="2023-10-24T16:25:12+02:00">October, 2023</time></p>                    
                                        
                                        
                    <div>
                        <p>Wood Joints are fascinating! They embellish old furniture and wood constructions of ancient Japanese temples alike. Every time we come across them, we are filled with admiration: Admiration for the skill of the master craftsman, as their creator, but also admiration for the balance between function and beauty, which turns the furniture or temple into a work of art.</p>
<p>With the onset of industrialization, the traditional wood joints have been banned more and more to the background. Manufacturing has to be above all efficient, so there is no more room for traditional wood joints. Or is there?</p>
<p>As computer-controlled wood processing machines move into the cabinet-makers‘ workshops, the way two pieces of wood are joined together in a construction needs to be reconsidered. The digital wood joints were developed in the course of several years of research at the C…Lab of the Hochschule für Gestaltung Offenbach, a project headed by Prof. Jochen Gros and Designer Friedrich Sulzer.</p>
<p>The result of this research are 50 digital wood joints, divided into frame joints, board joints and carcass joints. These wood joints are meant to inspire you, so that you will experiment and use them for your projects or develop your own digital wood joints. And they provide each wood joint in various data formats.</p>
                    </div>
                    
                                        
                </div>
            
        </div>
        
    </div>
    
</header>

	
	<!-- .entry-content -->
	
		
</article><!-- #post-1464 -->
<div><ul>
	<li><a href="https://openup.design/category/we-learn/teaching-materials/" rel="category tag">Teaching materials</a></li>
	<li><a href="https://openup.design/category/we-learn/" rel="category tag">we learn</a></li></ul></div> 

</main><!-- .site-main -->


	</div><!-- #barba-wrapper -->







  

  


	
	






























</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ubuntu 24.04 Noble Numbat (131 pts)]]></title>
            <link>https://releases.ubuntu.com/noble/</link>
            <guid>40157111</guid>
            <pubDate>Thu, 25 Apr 2024 13:12:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://releases.ubuntu.com/noble/">https://releases.ubuntu.com/noble/</a>, See on <a href="https://news.ycombinator.com/item?id=40157111">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="pageWrapper">

<h2>Select an image</h2>

<p>Ubuntu is distributed on three types of images described below.

</p><div>
<div>
<h3>Desktop image</h3>

<p>The desktop image allows you to try Ubuntu without changing your computer at all, and at your option to install it permanently later.  This type of image is what most people will want to use.  You will need at least 1024MiB of RAM to install from this image.</p>


</div>
<div>
<p><a href="https://releases.ubuntu.com/noble/ubuntu-24.04-desktop-amd64.iso">64-bit PC (AMD64) desktop image</a></p><p>Choose this if you have a computer based on the AMD64 or EM64T architecture (e.g., Athlon64, Opteron, EM64T Xeon, Core 2).  Choose this if you are at all unsure.</p>

</div>
</div>
<div>
<div>
<h3>Server install image</h3>

<p>The server install image allows you to install Ubuntu permanently on a computer for use as a server.  It will not install a graphical user interface.</p>


</div>
<div>
<p><a href="https://releases.ubuntu.com/noble/ubuntu-24.04-live-server-amd64.iso">64-bit PC (AMD64) server install image</a></p><p>Choose this if you have a computer based on the AMD64 or EM64T architecture (e.g., Athlon64, Opteron, EM64T Xeon, Core 2).  Choose this if you are at all unsure.</p>

</div>
</div>
<div>
<div>
<h3>Netboot tarball</h3>

<p>The netboot tarball contains files needed to boot the Ubuntu installer over the network.</p>


</div>
<div>
<p><a href="https://releases.ubuntu.com/noble/ubuntu-24.04-netboot-amd64.tar.gz">64-bit PC (AMD64) netboot tarball</a></p><p>Choose this if you have a computer based on the AMD64 or EM64T architecture (e.g., Athlon64, Opteron, EM64T Xeon, Core 2).  Choose this if you are at all unsure.</p>

</div>
</div>
<p>A full list of available files, including <a href="https://help.ubuntu.com/community/BitTorrent">BitTorrent</a> files, can be found below.</p>

<p>If you need help burning these images to disk, see the <a href="https://help.ubuntu.com/community/BurningIsoHowto">Image Burning Guide</a>.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rust Stream API visualized and exposed (163 pts)]]></title>
            <link>https://github.com/alexpusch/rust-magic-patterns/blob/master/rust-stream-visualized/Readme.md</link>
            <guid>40156890</guid>
            <pubDate>Thu, 25 Apr 2024 12:51:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/alexpusch/rust-magic-patterns/blob/master/rust-stream-visualized/Readme.md">https://github.com/alexpusch/rust-magic-patterns/blob/master/rust-stream-visualized/Readme.md</a>, See on <a href="https://news.ycombinator.com/item?id=40156890">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <!-- BEGIN app/components/site/header_dropdown_item_component.rb --><li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>
<!-- END app/components/site/header_dropdown_item_component.rb -->
                <!-- BEGIN app/components/site/header_dropdown_item_component.rb --><li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>
<!-- END app/components/site/header_dropdown_item_component.rb -->
                <!-- BEGIN app/components/site/header_dropdown_item_component.rb --><li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>
<!-- END app/components/site/header_dropdown_item_component.rb -->
                <!-- BEGIN app/components/site/header_dropdown_item_component.rb --><li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>
<!-- END app/components/site/header_dropdown_item_component.rb -->
                <!-- BEGIN app/components/site/header_dropdown_item_component.rb --><li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>
<!-- END app/components/site/header_dropdown_item_component.rb -->
                <!-- BEGIN app/components/site/header_dropdown_item_component.rb --><li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>
<!-- END app/components/site/header_dropdown_item_component.rb -->
                <!-- BEGIN app/components/site/header_dropdown_item_component.rb --><li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>
<!-- END app/components/site/header_dropdown_item_component.rb -->
                <!-- BEGIN app/components/site/header_dropdown_item_component.rb --><li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>
<!-- END app/components/site/header_dropdown_item_component.rb -->
            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <!-- BEGIN app/components/site/header_dropdown_item_component.rb --><li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>
<!-- END app/components/site/header_dropdown_item_component.rb -->
            </ul>
          </div>
          <div>
            <ul>
                <!-- BEGIN app/components/site/header_dropdown_item_component.rb --><li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>
<!-- END app/components/site/header_dropdown_item_component.rb -->
            </ul>
          </div>
          
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:alexpusch/rust-magic-patterns" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="cgtWq8zWaqVU9LaHc_atZwtmGgee2bH0ptjPqWvkG4ai4_G4AxXmio0hmxxYCIEy2yjZkW3xU2A0NTO0RLpZLg" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="alexpusch/rust-magic-patterns" data-current-org="" data-current-owner="alexpusch" data-logged-in="false" data-copilot-chat-enabled="false" data-blackbird-indexed-repo-csrf="<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=QZOo8MSvalP4%2FuOCm0JCOhqf9g7sUSSKqOFAfKd%2FKIIekZfs2hHR2VZEvrT0pAqgsiwTFifG7sO8sF%2Bgj2tcnUUWVjTb8cyLQRJ4doPEXw07E7YG2lzD6p%2Fg0Gpwy1bE0IB5kIgBmUBTuwzN%2B55nzxuSKbUT1VGOvAcyn8Ig7gLwrRNLw8UljZiVFQ5cpS6rkrZiWGWjmwxaztUW9OnKyIF%2BSh64D1ThXyxy%2FSosfUKzbpe53VRAWC3Wea2yj84nnLtttDhpwaTncn8XXeju6aDF9XZUYhifVyO6E2Efp%2Bn6Btq27pWXiuJ%2FJ345obckPy75Es5l5YrzssQs%2BGBq1e6gmhV5YYbNzlQBFT87hjHRVhsjI0AmzaQfoM%2FV%2BYCt8PyOQqMvldtMBrfKsDVzIklXBE00WgXPdU3m9%2FL4p9CKjkPU%2BPrbDLCMOfkchnZP%2Fxjn46DV%2FSEUgSzw76QLwxSTnM3mRnxZOvP5n9%2FP4PmBPTHkq1u5e6ootQEKyXDITbOZgBcH4ASn%2Bc8Z9%2FGbdDTeN%2F6QG1Fq214ia0Vuvb85P%2FmuyURscimjB5Fb38U12RXK%2FuRHoLZ7h9%2FZRVaB4ro9HhcdIAHl80GBzXiyTlsoB6%2BjvT6KjkKA--wITilZTkVsYweYGc--e4Rl0ALzE35dAJcNwnrmbQ%3D%3D&quot; />">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&amp;source=header-repo&amp;source_repo=alexpusch%2Frust-magic-patterns" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/alexpusch/rust-magic-patterns/blob/master/rust-stream-visualized/Readme.md&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="47d244594374ac167a65ea78709da707c8702cc2e569e41530820579f71a761f" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/blob/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Palm OS and the devices that ran it (136 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2024/04/palm-os-and-the-devices-that-ran-it-an-ars-retrospective/</link>
            <guid>40156569</guid>
            <pubDate>Thu, 25 Apr 2024 12:16:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2024/04/palm-os-and-the-devices-that-ran-it-an-ars-retrospective/">https://arstechnica.com/gadgets/2024/04/palm-os-and-the-devices-that-ran-it-an-ars-retrospective/</a>, See on <a href="https://news.ycombinator.com/item?id=40156569">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <header>
            <h4>
      palm of your hand    —
</h4>
            
            <h2 itemprop="description">Before smartphones, we had PDAs in our pockets. Palm did them best. </h2>
                    </header>
        <section>
            <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/palm-pilot-retrospective-800x450.jpg" alt="Palm OS and the devices that ran it: An Ars retrospective">
      <figcaption><p>Aurich Lawson</p></figcaption>  </figure>

  




<!-- cache miss 386:single/related:8e1406f73e58a704cf7b0ac7d7e2fc33 --><!-- empty -->
<p>“Gadgets aren’t fun anymore,” sighed my wife, watching me tap away on my Palm Zire 72 as she sat on the couch with her MacBook Air, an iPhone, and an Apple Watch.</p>
<p>And it’s true: The smartphone has all but eliminated entire classes of gadgets, from point-and-shoot cameras to MP3 players, GPS maps, and even flashlights. But arguably no style of gadget has been so thoroughly superseded as the personal digital assistant, the handheld computer that dominated the late '90s and early 2000s. The PDA even set the template for <i>how</i> its smartphone successors would render it obsolete, moving from simple personal information management to encompass games, messaging, music, and photos.</p>
<p>But just as smartphones would do, PDAs offered a dizzying array of operating systems and applications, and a great many of them ran Palm OS. (I bought my first Palm, an m505, new in 2001, upgrading from an HP 95LX.) Naturally, there’s no way we could enumerate every single such device in this article. So in this Ars retrospective, we’ll look back at some notable examples of the technical evolution of the Palm operating system and the devices that ran it—and how they paved the way for what we use now.</p>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/04/palmfeature2-scaled.jpg" data-height="1928" data-width="2560" alt="You never forget your first(s). Here were my Palms from back in the day, my original m505, and later, my first Zire 72.&nbsp;They’re beat up, but with new batteries, they still work great."><img alt="You never forget your first(s). Here were my Palms from back in the day, my original m505, and later, my first Zire 72.&nbsp;They’re beat up, but with new batteries, they still work great." src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/palmfeature2-640x482.jpg" width="640" height="482" srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/04/palmfeature2-1280x964.jpg 2x"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/04/palmfeature2-scaled.jpg" data-height="1928" data-width="2560">Enlarge</a> <span>/</span> You never forget your first(s). Here were my Palms from back in the day, my original m505, and later, my first Zire 72.&nbsp;They’re beat up, but with new batteries, they still work great.</p><p>Cameron Kaiser</p></figcaption></figure>
<h2>When Zoom(er) wasn’t meeting software</h2>
<p>In the mid-to-late 1980s, portable computing primarily meant either heavy, luggable workstations or a unique class of pocket computers with tiny screens, small memories, and calculator-like keyboards. Jeff Hawkins, then vice president of research at portable systems builder GRiD, thought he could do better. He wanted to build a system where the screen itself becomes the input device, replacing keyboards with pens and styluses.</p>                                            
                                                        
<p>While handwriting recognition was an even bigger challenge for systems back then, Hawkins’ PalmPrint system simplified the task by merely matching strokes to characters instead of trying to recognize entire words. PalmPrint became GridPen, the core of the 1989 GriDPad 1900, or what we would call today the first commercially successful tablet computer. Using a resistive 10-inch black-and-white LCD as the screen and writing surface, it ran MS-DOS on a lower-power 10 MHz Intel 80C86 and weighed just about two kilograms (4.5 pounds), selling at an MSRP of $2,500 (about $6,200 in 2024 dollars).</p>
<p>The GriDPad line went on to be very successful for GRiD, but Hawkins increasingly considered his own creation to be too bulky and expensive. Surveying existing GriDPad corporate customers about a portable machine they would <i>personally</i> use, the feedback was unanimous: It had to be a lot lighter, a lot smaller, and under a cool grand.</p>
<p>GRiD itself wasn’t interested in producing a low-end mass-market device, but such a unit was well within the market range of Tandy Corporation, GRiD’s parent since 1988 and the owners of Radio Shack. Tandy management was entranced by the concept of what Hawkins called the “Zoomer,” so much so that the company was willing to invest $300,000 in Hawkins’ new venture to develop it, which he called Palm Computing.</p>
<p>Hawkins selected GeoWorks’ PC/GEOS as the operating system based on <a href="https://oldvcr.blogspot.com/2023/06/o-brother-geobook-lets-get-thou-back-on.html">its proven ability</a> to run on inexpensive hardware, and Tandy brought on longtime partner Casio (also a major pocket computer manufacturer) as the new device’s OEM. To manage the growing company, Hawkins hired Apple-Claris alumnus Donna Dubinsky as CEO and later Ed Colligan as VP of marketing, fresh from Macintosh peripherals maker Radius.</p>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/04/palmfeature3-scaled.jpg" data-height="2560" data-width="1928" alt="The Tandy Zoomer, here in the Casio Z-7000 OEM version."><img alt="The Tandy Zoomer, here in the Casio Z-7000 OEM version." src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/palmfeature3-640x850.jpg" width="640" height="850" srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/04/palmfeature3-1280x1700.jpg 2x"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/04/palmfeature3-scaled.jpg" data-height="2560" data-width="1928">Enlarge</a> <span>/</span> The Tandy Zoomer, here in the Casio Z-7000 OEM version.</p><p>Cameron Kaiser</p></figcaption></figure>
<p>Unfortunately, the Zoomer’s development became increasingly troubled due to corporate interference and software churn, and although underclocking its x86-compatible CPU to 7 MHz dramatically extended its battery life, it also made the unit slow and ponderous. Still, the Zoomer got to market in October 1993 at a pound in weight (less than half a kilogram) and for $599 ($1,240 in 2024), markedly undercutting Apple’s Newton MessagePad. On the other hand, it was still too large and was basically treated (and judged) as a PC, and even though its handwriting recognition was better than the Newton’s, it was still outsold four to one.</p>

                                                </div>

            
            
                            <nav>Page: <span>1 <a href="https://arstechnica.com/gadgets/2024/04/palm-os-and-the-devices-that-ran-it-an-ars-retrospective/2/">2</a> <a href="https://arstechnica.com/gadgets/2024/04/palm-os-and-the-devices-that-ran-it-an-ars-retrospective/3/">3</a> <a href="https://arstechnica.com/gadgets/2024/04/palm-os-and-the-devices-that-ran-it-an-ars-retrospective/4/">4</a> <a href="https://arstechnica.com/gadgets/2024/04/palm-os-and-the-devices-that-ran-it-an-ars-retrospective/5/">5</a> <span>...</span> <a href="https://arstechnica.com/gadgets/2024/04/palm-os-and-the-devices-that-ran-it-an-ars-retrospective/11/">11</a> <a href="https://arstechnica.com/gadgets/2024/04/palm-os-and-the-devices-that-ran-it-an-ars-retrospective/12/">12</a> <a href="https://arstechnica.com/gadgets/2024/04/palm-os-and-the-devices-that-ran-it-an-ars-retrospective/2/"><span>Next <span>→</span></span></a></span></nav>
            
        </section>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tribler: An attack-resilient micro-economy for media (225 pts)]]></title>
            <link>https://github.com/Tribler/tribler/wiki</link>
            <guid>40156534</guid>
            <pubDate>Thu, 25 Apr 2024 12:13:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Tribler/tribler/wiki">https://github.com/Tribler/tribler/wiki</a>, See on <a href="https://news.ycombinator.com/item?id=40156534">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wiki-body" data-view-component="true">
                <p><h2>Tribler: an attack-resilient micro-economy for media</h2><a id="user-content-tribler-an-attack-resilient-micro-economy-for-media" aria-label="Permalink: Tribler: an attack-resilient micro-economy for media" href="#tribler-an-attack-resilient-micro-economy-for-media"></a></p>
<ul>
<li>Anonymous Tor-like downloads and fast search</li>
<li>Earn <em>seeding</em> tokens</li>
<li>Reward content creators</li>
</ul>
<p><img src="https://camo.githubusercontent.com/fa24f6586363adda54210b8fcd595e9207b7cf1f14d240d1c5d7ade721d7d6c5/68747470733a2f2f666f72756d2e747269626c65722e6f72672f75706c6f6164732f64656661756c742f6f726967696e616c2f31582f353634376365613935316338383837333663326634633738653031323039363730303830353038382e706e67" alt="Tribler Search V7.0" data-canonical-src="https://forum.tribler.org/uploads/default/original/1X/5647cea951c888736c2f4c78e012096700805088.png"></p>
<p>Tribler is a Bittorrent-compatible alternative to Youtube.
It is designed to protect your privacy, build a web-of-trust, be attack-resilient, and
reward content creators directly.
We are building a micro-economy without banks, without advertisers,
and without any government.
Together <a href="http://news.harvard.edu/gazette/story/2007/08/creating-a-computer-currency/" rel="nofollow">with Harvard University</a>, the Tribler team deployed one of the first
fully distributed ledgers in August 2007, see <a href="http://news.bbc.co.uk/2/hi/technology/6971904.stm" rel="nofollow">BBC News coverge</a> and a <a href="http://www.newscientist.com/article/dn12565-bandwidth-could-be-a-new-global-currency.html" rel="nofollow">New Scientist article</a>.
In coming years we will further expand our micro-economy based on <em>bandwidth tokens</em>.
We aim to become the key place where audiences find their torrents, creative talents
get discovered, and artists get financial rewards from their fans.
Tribler is the place where 100 percent of the money goes to artists and the people that run the infrastructure.</p>
<p>Our mission: <em>re-inventing media and money</em>.</p>
<p>Over 2 million people have used Tribler over the years.
The Tribler project was started in 2005 at Delft University of Technology
and over 100+ developers contributed code to it.
We are continuously improving it and further expanding the scientific developers team.</p>
<p>Technical foundations of Tribler are the Bittorrent protocol,
an overlay for P2P communication across NAT/firewalls,
gradual building of trust in public keys with Bittorrent seeding,
and our token economy with incentives for Tor-like relaying and hidden seeding.
For 12 years we have been building a very robust self-organising Peer-to-Peer system.
Today Tribler is robust: "the only way to take Tribler down is to take The Internet down" (but a single software bug could end everything).</p>
<p><h2>Current items under active development</h2><a id="user-content-current-items-under-active-development" aria-label="Permalink: Current items under active development" href="#current-items-under-active-development"></a></p>
<p>This wiki page contains our main technical documentation, highlights:</p>
<ul>
<li>Trustchain: our 10.000 transactions per second ledger</li>
<li>Token economy and decentral market</li>
</ul>
<table role="table">
<thead>
<tr>
<th>Topic and open Github issue</th>
<th>Researcher</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/7586">On-device decentralised AI</a> - phd level</td>
<td>Petru</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/7290">Trustworthy data for generative AI</a> - phd level</td>
<td>Marcel</td>
</tr>
<tr>
<td><a href="https://github.com/Tribler/tribler/issues/7258">5G overlay network for decentralised On-Device Machine Learning</a></td>
<td>Orestis Kanaris</td>
</tr>
<tr>
<td><a href="https://github.com/Tribler/tribler/issues/7254">True decentralised on-device machine learning</a></td>
<td>Quinten</td>
</tr>
<tr>
<td><a href="https://github.com/Tribler/tribler/issues/7435">exploring LLM as a database</a></td>
<td>Xueyuan Chen</td>
</tr>
<tr>
<td><a href="https://github.com/Tribler/tribler/issues/7431">Offline digital Euro: a first design and implementation</a></td>
<td>Leon</td>
</tr>
<tr>
<td><a href="https://github.com/Tribler/tribler/issues/7481">passport-grade digital identity with DDoS protection using IP reputation</a></td>
<td>Adrian</td>
</tr>
<tr>
<td><a href="https://github.com/Tribler/tribler/issues/6942">Web3Recommend: Decentralised Web3 social recommendations with trust and relevance balance</a></td>
<td><a href="https://github.com/rmadhwal">Rohan Madhwal</a></td>
</tr>
<tr>
<td>Making Trustchain scale to enterprise level <a href="https://github.com/Tribler/tribler/issues/4140">with a large stress testing experiment</a>
</td>
<td>Bulat Nasrulin</td>
</tr>
<tr>
<td>IPv8 resilient overlay: <a href="https://github.com/Tribler/tribler/issues/2541">Sybil-resilience through latency-based shadow-banning</a>
</td>
<td>Quinten Stokkink</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/5576">Universal wallet</a> for identity, attestations, and money</td>
<td>Rowdy Chotkan</td>
</tr>
<tr>
<td><a href="https://github.com/Tribler/tribler/issues/4256">Gossiping torrent popularity to scale to millions of torrents</a></td>
<td>Sandip, Alexander and Andrei</td>
</tr>
</tbody>
</table>
<p>Open projects for new TUDelft master thesis students: Tor-like streaming, self-sovereign identity and authentication on Android, relevance ranking of search results (+swarm popularity), perfect metadata through distributed crowdsourcing, self-reinforcing trust, and perfect network connectivity using NAT/Firewall traversal.
Speculative projects with long-term focus: <a href="https://github.com/Tribler/tribler/issues/2882">prediction market for climate change</a>. A <a href="https://www.google.nl/search?q=anti+hft" rel="nofollow">market designed against</a> frontrunners and high-frequency trading abusers in general.</p>
<table role="table">
<thead>
<tr>
<th>Project: Waiting for new developers</th>
<th>Prior Dev</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/Tribler/tribler/issues/4481">Deceptively simple trust model</a></td>
<td>Alexander Stannat</td>
</tr>
<tr>
<td>Beyond decentral exchanges: <a href="https://github.com/Tribler/tribler/issues/5221">Single universal global market</a>
</td>
<td>Joost V.</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/4629">EuroToken - an open alternative to Facebook Libra</a> and JPMorgan coin</td>
<td>Wessel Blokzijl</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/5134">ArtistCoin - Fairness for artists</a>, audio streaming service without any intermediaries</td>
<td>Tim W.</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/10">Real-time updates to the trust model and visualisation</a> of random walks</td>
<td>Can Umut</td>
</tr>
<tr>
<td>Youtube-like scale: <a href="https://github.com/Tribler/tribler/issues/3971">Gigachannels with 1 billion magnet links</a>
</td>
<td>Vadim</td>
</tr>
<tr>
<td>A <a href="https://github.com/Tribler/tribler/issues/3337">live token economy</a> and distributed <a href="https://github.com/Tribler/tribler/issues/2559">marketplace for bandwidth tokens</a>
</td>
<td>Martijn de Vos</td>
</tr>
<tr>
<td>Low-level debugging of <a href="https://github.com/Tribler/tribler/issues/2620">Tor-like tunnels</a> and <a href="https://github.com/Tribler/tribler/issues/2548">performance in general</a>
</td>
<td>Vadim</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/2571">Blockchain: detect freeriders, refuse service</a>; anon compatible</td>
<td>Ewout Bongers</td>
</tr>
<tr>
<td>self-sovereign identity+trust: <a href="https://github.com/Tribler/tribler/issues/2682">overview</a>, <a href="https://github.com/Tribler/tribler/issues/2812">biometric validation</a>, boosted <a href="https://github.com/Tribler/tribler/issues/3013">privacy</a>, and <a href="https://github.com/Tribler/tribler/issues/2918">voting pass</a>
</td>
<td>8 students</td>
</tr>
<tr>
<td>Distributed Apps: <a href="https://github.com/Tribler/tribler/issues/2943">autonomous code execution using IPv8 plugins</a>
</td>
<td>Mitchell Olsthoorn</td>
</tr>
<tr>
<td>P2P 4G - <a href="https://github.com/Tribler/tribler/issues/4827">Universal connectivity using imperfect hardware</a>
</td>
<td>Matt S.</td>
</tr>
<tr>
<td>Financial Engineering: <a href="https://github.com/Tribler/tribler/issues/4044">decentralised non-profit payment services</a>
</td>
<td>Jetse Brouwer</td>
</tr>
<tr>
<td>Walker infrastructure with <a href="https://github.com/Tribler/tribler/issues/2754">48 NAT boxes and automated NAT puncturing</a>
</td>
<td>Remko Naber</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/2925">Autonomous self-replicating code</a> buy servers with Bitcoins</td>
<td>4 students</td>
</tr>
<tr>
<td>Prototype projects "Blockchain Engineering" Master course around <a href="https://github.com/Tribler/tribler/issues?q=is%3Aissue++label%3A%22MSc+course+work%22">threshold encryption, trustchain, self-sovereign ID, etc</a>
</td>
<td>45 master students</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/2457">Bottom-up consensus model with full scalability</a> using checkpointing</td>
<td>Kelong Cong</td>
</tr>
<tr>
<td>PageRank-like trust model with <a href="https://github.com/Tribler/tribler/issues/1844">Sybil-attack resilience</a>
</td>
<td>Pim Otte</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/3357">Towards global consensus on trust</a> within the Tribler micro-economy</td>
<td>Jan-Gerrit Harms</td>
</tr>
<tr>
<td>Decentral market primitives: <a href="https://github.com/Tribler/tribler/issues/3486">market order and execution engine fairness</a>
</td>
<td>Marc Juchli</td>
</tr>
<tr>
<td>Decentral market: <a href="https://github.com/Tribler/tribler/issues/2887">privacy for traders and spam-resilience</a>
</td>
<td>Bas van Ijzendoorn</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/3064">Secure hardware storage</a> of keys using PUF hardware</td>
<td>Ade Ade Setyawan Sajim</td>
</tr>
<tr>
<td>Blockchain: <a href="https://github.com/Tribler/tribler/issues/2533">self-reinforcing trust</a> with collection of credit records</td>
<td>Pim Veldhuisen</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/1882">Fast anonymous streaming</a> with Tor-like onion routing</td>
<td>Quinten Stokkink</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/2231">Attack-resilient social media</a> on mobile devices, using LibTribler</td>
<td>Paul Brussee</td>
</tr>
<tr>
<td>Blockchain walker with attack-resilience and integrated NAT puncturing, <a href="https://github.com/Tribler/tribler/issues/2623">trusted peer discovery</a>
</td>
<td>Changliang</td>
</tr>
<tr>
<td>Blockchain: <a href="https://github.com/Tribler/tribler/issues/1842">earn credits with seeding</a> on Kodi-like devices</td>
<td>Bohao Zhang</td>
</tr>
<tr>
<td><a href="https://github.com/Tribler/tribler/issues/2455">crowdsourcing of rich metadata</a></td>
<td>Stijn van Schooten</td>
</tr>
<tr>
<td>Determine popularity+age of content with spam and attack resilience, <a href="https://github.com/Tribler/tribler/issues/2783">swarm size community</a>
</td>
<td>Chengxin Ma</td>
</tr>
<tr>
<td>
<a href="https://github.com/Tribler/tribler/issues/2547">Adversarial search</a>: blockchain-based spam resilience in Youtube-like systems</td>
<td>Jelle Licht</td>
</tr>
<tr>
<td>Scalability: <a href="https://github.com/Tribler/tribler/issues/21">donating TeraBytes</a> to crowdsourcing projects</td>
<td>Wouter Smit</td>
</tr>
<tr>
<td>Connecting banks to decentral markets through PSD2 open APIs</td>
<td>Kypianou</td>
</tr>
<tr>
<td>Crowdsourcing and investments</td>
<td>Bart Gout</td>
</tr>
<tr>
<td>re-use our decentral market platform for real-world business case, <a href="https://github.com/Tribler/tribler/issues/2606">crowdsourcing real-estate</a>
</td>
<td>4 bsc students</td>
</tr>
<tr>
<td>Establish + Real-time display of <a href="https://github.com/Tribler/tribler/issues/2905">Blockchain trust</a>
</td>
<td>20 Context project students</td>
</tr>
</tbody>
</table>
<p><h2>Aim: solving trust</h2><a id="user-content-aim-solving-trust" aria-label="Permalink: Aim: solving trust" href="#aim-solving-trust"></a></p>
<p>Social media today is obsessed with profit, filled with advertisements,
overflowing with falsehoods, and infested with fake news.
We're trying to fix these hard problems in a unique way: by building trust.
Our audacious ambition is a clean-slate re-creation of The Internet itself with
foundations of trust.
Craiglist and eBay showed us in 1995 that trustworthy trade was possible online.
Uber, Etsy, and AirBnB show that entire industries can be disrupted by
a single platform with a natural monopoly.</p>
<p>For the past 18 years we have build and deployed platforms to create trust.
Before Wikipedia and Youtube existed we studied the mechanisms behind trust and user-generated content on a small scale.
Several years before Wikipedia emerged we <a href="https://static.usenix.org/events/usenix2000/freenix/full_papers/pouwelse/pouwelse.pdf" rel="nofollow">deployed a music encyclopedia with unconstrained write access</a>, it never became popular because we focused too much on software, instead community growth.</p>
<p>Today we keep a narrow focus and continuously expand Tribler with trustworthy
decentralized technology. We launched sub-second keyword search for
Bittorrent swarms without any server back in 2010 (see <a href="https://www.youtube.com/watch?v=ZXWMhreGiAU" rel="nofollow">our old Google Tech Talk</a> on this topic). One of our operational trust browsing prototypes:
<img src="https://user-images.githubusercontent.com/15870543/27395330-b5621bce-56af-11e7-9ee8-60edb4b0e091.png" alt="trust browser"></p>
<p>Further reading:</p>
<ul>
<li>Our work from 2004, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.76.3107&amp;rep=rep1&amp;type=pdf" rel="nofollow">2-year in-depth measurement and analysis of Bittorrent (.pdf 25 pages)</a>, largest measurement to date.  Covers eight months of the BitTorrent/Suprnova.org file sharing ecosystem. In particular, we show measurement results of the popularity and the availability of BitTorrent, of its download performance, of the content lifetime, and of the structure of the community responsible for verifying uploaded content.</li>
</ul>
<p><h2>Tribler features and innovations</h2><a id="user-content-tribler-features-and-innovations" aria-label="Permalink: Tribler features and innovations" href="#tribler-features-and-innovations"></a></p>
<p>Tribler supports torrent search without websites, anonymous downloading, torrent streaming, channels of torrents, and sharing content for tokens. <a href="http://sigmm.org/records/records1201/featured03.html" rel="nofollow">Overview of Tribler (.html 5 pages)</a>.
All Tribler features are implemented in a completely distributed manner, not relying on any centralized component.
Still, Tribler manages to remain fully backwards compatible with BitTorrent. <a href="http://iptps06.cs.ucsb.edu/papers/Pouw-Tribler06.pdf" rel="nofollow">The 2006 overview of Tribler (.pdf 6 pages)</a> featuring taste groups, friends, friends-of-friends and faster downloads by donating bandwidth to friends (<a href="http://svn.tribler.org/bt2-design/coop-download/trunk/note.tex" rel="nofollow">protocol spec</a> of friend boosting).
Note that <a href="http://svn.tribler.org/bt2-design/proto-spec-unified/trunk/proto-spec-current.pdf" rel="nofollow">the 2006-2009 Tribler protocol specification (.pdf 47 pages)</a> is now mostly outdated, as we switched to our new synchronization protocol called Dispersy (see below).</p>
<p>Trust in social media content is essential for a sustainable ecosystem.
We introduced channels of Bittorrent swarms <a href="https://www.tribler.org/LivePlaylists/" rel="nofollow">in 2009</a> with the Tribler 4.x release.
Each user can vote on channels to increase their visibility and tell everybody the
channel owner is not a spammer and not spreading fake items.
The reputation of both the voters and channel owner are important.</p>
<p>Tribler protects your privacy by not storing anything on any server.
To protect your privacy even more, we have prototyped search algorithms
based on homomorphic cryptography.
We presented a <a href="https://github.com/Tribler/tribler/files/1649968/privacy_overlay.pdf">new algorithm system for privacy-respecting
scalable Gnutella-like search</a> in 2014.
Our approach to scalability is a similarity function in the encrypted domain (homomorphic), enabling semantic clustering with privacy.</p>
<p>Back in 2006 we introduced long-lived identities to separate trustworthy peers from
freeriders and spammers (<a href="https://www.tribler.org/PermID/" rel="nofollow">PermID</a>). To protect your
privacy further we also devised an alternative to onion routing which potentially
could have stronger security guarantees (correlation attack).
See the details in this thesis on
<a href="https://repository.tudelft.nl/islandora/object/uuid%3A3c7f869c-44b9-41f7-8deb-36ba284606cd" rel="nofollow">Multi-core architecture for anonymous Internet streaming</a>
which includes a performance analysis of running code.</p>
<p>Further reading for developers:</p>
<ul>
<li><a href="https://github.com/Tribler/tribler/wiki/Compiling-Tribler-from-sources-under-Eclipse">Running Tribler from sources in Eclipse</a></li>
<li>
<a href="http://jenkins.tribler.org/" rel="nofollow">Jenkins server for continuous integration, unit tests, installer builders and performance testing</a>. You will find a lot of automatic running scripts there for things like correctness, NAT puncture performance and GUI tests.</li>
<li><a href="https://github.com/Tribler/tribler/wiki/Tribler-Development-Pointers">Tribler development pointers / starting point for new developers</a></li>
<li><a href="https://github.com/Tribler/tribler/tree/devel/doc">Python source code doc directory</a></li>
<li><a href="https://github.com/Tribler/tribler/blob/devel/doc/restapi/introduction.rst">Tribler can run as a background process with this API</a></li>
</ul>
<p><h2>Our primitive 2007 distributed ledger and Trustchain (2012)</h2><a id="user-content-our-primitive-2007-distributed-ledger-and-trustchain-2012" aria-label="Permalink: Our primitive 2007 distributed ledger and Trustchain (2012)" href="#our-primitive-2007-distributed-ledger-and-trustchain-2012"></a></p>
<p>We deployed one of the worlds first fully distributed ledgers in August of <a href="http://news.bbc.co.uk/2/hi/technology/6971904.stm" rel="nofollow">2007</a>.
For over a decade we meticulously measured, analysed, improved, and enhanced this live system.
Today it defines the state-of-the-art in blockchain research, but in the early days it barely functioned at all.
A total of five Ph.D. students of Delft contributed key parts and upgrades.</p>
<p>At launch we called our initiative "<em>bandwidth-as-a-currency</em>". Today we have specific terminology for what we did: a token economy.
We are making Internet bandwidth a tradable commodity without any middleman or need for any centralised governance.
Our efforts span over a decade, making us the veterans in the field.
Our ledger provides an incentive for Bittorrent seeding and Tor-like relaying.
For numerous years the tit-for-tat algorithm provided the only incentive for contributions in Bittorrent.
No incentive for seeding existed, except when central servers kept track of your uploads and downloads.
We measured closed invite-only communities for numerous years and mathematically showed their rich-get-richer properties. For details see <a href="http://publicatio.bibl.u-szeged.hu/2509/1/SRE-p2p11-final-version.pdf" rel="nofollow">Fast download but eternal seeding: the reward and punishment of sharing ratio enforcement</a> and our measurement paper <a href="http://www.usenix.org/event/iptps10/tech/full_papers/Meulpolder.pdf" rel="nofollow">understanding bandwidth economics and ratio enforcement (.pdf 5 pages)</a>.
We measured 508,269 peers in 444 swarms within five BitTorrent communities, ranging from public to highly elite. We observe download performance, connectability, seeder/leecher ratios, seeding duration, and statistics regarding the resource supply.</p>
<p>We got inspiration for a novel blockchain design based on operating our own ledger and studying token economies.
Our current work is called Trustchain, a unique design from 2012 where all participants have their own personal blockchain and create their own genesis block.
Our older work used a graph-based approach and graph-based reputation algorithms.
Trustchain records transactions in a tamper-proof and scalable manner.
It does not require mining and does not try to solve the double spending problem.
Our primitive 2007 ledger pre-dates Bitcoin, additionally our 2012 DAG-based approach pre-dates IOTA and the Texas DAG patents.</p>
<p>We are fans of Bitcoin, but also showed in <a href="https://web.archive.org/web/20141218123940/http://www.pds.ewi.tudelft.nl/~victor/bitcoin.html" rel="nofollow">an early analysis</a> the flaws in this concept.
Our approach to digital signatures is the essential difference which sets us apart from others.
Mono-signatures form the foundation of all other projects we have seen in the past decade.
Meaning, in systems such as Bitcoin a transaction is already valid with a single signature.
Our Trustchain design does not permit transactions with merely a single signature.
Trustchain only supports multi-party agreement recording, others are not valid.
We believe that we created a more powerful system by removing single-signature transactions.
Only time can tell the usefullness of this academically-pure and minimal design.</p>
<p>The foundation of our approach is making repeated successful interactions between actors explicit and durable.
Cryptographically signed records of successful encounters serve as proof-of-work certificates.
The validity and value of these certificates is determined by a trust and reputation system.
Relaying for anonymity and seeding in Tribler constitutes work which is rewarded with a signed certificate.
Helping others and uploading in Bittorrent swarms is rewarded with bandwidth tokens (e.g. signed certificates).
Mining in our system becomes download parts of a swarm and uploading them to multiple interested parties.
In 2013 we got the credit mining part of our system operational in early Beta.
The screenshot below from November 2013 shows the boosting of various swarms.
Note the investment yields of "struck gold" and "poor" in the right column.</p>
<p><img src="https://cloud.githubusercontent.com/assets/325224/2731498/e3ac1522-c62d-11e3-9711-dd2ba72652d0.png" alt="Screenshot of our credit mining Beta code from November 2013, showing the boosting of various swarms"></p>
<p>Further reading:</p>
<ul>
<li><a href="https://tools.ietf.org/html/draft-pouwelse-trustchain-00" rel="nofollow">Trustchain IETF Draft Internet Standards proposal</a></li>
<li>
<a href="http://www.asci.tudelft.nl/media/proceedings_asci_conference_2010/asci2010_submission_14.pdf" rel="nofollow">Scientific 2010 publication on BarterCast ledger (.pdf 8 pages)</a>.</li>
<li>Our <a href="http://www.pds.ewi.tudelft.nl/~epema/Papers/2009/HotP2P2009.pdf" rel="nofollow">original BarterCast protocol</a> publication 2009.</li>
<li>The <a href="http://www.ifi.uzh.ch/ce/publications/Accounting_Mechanisms.pdf" rel="nofollow">DropEdge enhancement was proposed to BarterCast together with Harvard and Berkeley scientists (.pdf 42 pages)</a> which makes the ledger harder to attack.</li>
<li>
<a href="https://link.springer.com/content/pdf/10.1007/978-3-642-30054-7_19.pdf" rel="nofollow">Reducing the storage cost of our ledger and reputation system</a> form 2012.</li>
<li>Key Internet deployment evaluation: <a href="https://ieeexplore.ieee.org/document/6663517" rel="nofollow">A Network Science Perspective of a Distributed Reputation Mechanism (.pdf 9 pages)</a>, from 2013.</li>
</ul>
<p><h2>Our methodology: keep focus and dream big</h2><a id="user-content-our-methodology-keep-focus-and-dream-big" aria-label="Permalink: Our methodology: keep focus and dream big" href="#our-methodology-keep-focus-and-dream-big"></a></p>
<p>For our narrow focus of a Bittorrent client we are exploring the fundamentals of
identity, trust, and trade. With over 1 billion users of Youtube and Bittorrent we know there
is a mass audience ready for something better.</p>
<p>Our approach has very boring foundations, when compared to newer and more sexy work, like IPFS, FileCoin, or Storj.
We first measured Bittorrent in 2002, it is a flourishing mature ecosystem and ready for an upgrade.
Bootstrapping an ecosystem is hard, we designed and deployed a superior alternative to Bittorrent.
It became an official <a href="https://datatracker.ietf.org/doc/rfc7574/" rel="nofollow">IETF Internet Standard</a>, but completely flopped.
This formed our preference for simplicity, elegance and our allergy for bloatware, clean-slate work, and over-engineering.
Numerous other projects try to create a generic approach using an ICO for funding and
promising the early adopters a dazzling return-on-investment.
Tribler is different. <em>rant warning</em>. We are non-profit academics.
We do not want to replace the old elite with a new crypto-currency elite.
What is changed if we replace backroom deals, lobbyists, middleman, and legal monopolies with the tools of the new elite:
algorithms, early investor rewards, proof-of-dominating-stake, and smart contracts?
Replacing the analog world and breading digital-native inequality does not make the world a better place.
We are creating a micro-economy based on fairness, trust, equality, and self-governance.
By design we banish rent-seeking. Critical infrastructure rarely makes profit. We are trying to build critical infrastructure.</p>
<p><h2>Tor-inspired onion routing</h2><a id="user-content-tor-inspired-onion-routing" aria-label="Permalink: Tor-inspired onion routing" href="#tor-inspired-onion-routing"></a></p>
<p>As of December 2014 Tribler has a build-in version of a Tor-like anonymity system. This is completely disconnected from 'The' Tor network. It is still ongoing work. It gives you probably superior protection than a VPN, but no protection against resourceful spying agencies.</p>
<p>We have implemented the <a href="https://github.com/Tribler/tribler/blob/v6.3.1/Tribler/community/tunnel/community.py#L271">main parts of the Tor wire protocol within Tribler</a>.
Instead of the TCP protocol that 'the' Tor network uses, we use UDP.
The enables us to do NAT puncturing and traversal.
We have created our own network using this Tor variant, our code is not compatible with normal Tor.
Work started as a <a href="https://github.com/Tribler/tribler/issues/119">small trial</a> in December 2013 with anonymous Bittorrent downloading.
Essential part of our work is that everybody who downloads anonymously also becomes a relay.
This brings the Bittorrent tit-for-tat idea to darknets.
With this ongoing work we aim to offer in 2018 with Tribler V7.0 proxied downloading for any Bittorrent swarm.</p>
<p><img src="https://camo.githubusercontent.com/399d6eeb8c0a4d7b34ae8df87f56f11ca97ed253280754a1608cdacdac4777b3/68747470733a2f2f662e636c6f75642e6769746875622e636f6d2f6173736574732f313536343235372f313730353337342f65653265623265612d363064632d313165332d383937372d3138313138353431366136332e706e67" alt="December 2013 trial with TOR-like onion routing for anonymous swarm downloading" data-canonical-src="https://f.cloud.github.com/assets/1564257/1705374/ee2eb2ea-60dc-11e3-8977-181185416a63.png"></p>
<p>Lengthy documentation in the form of two master thesis documents is available. First is a general documentation of the tunnel and relay mechanism, <a href="http://repository.tudelft.nl/islandora/object/uuid%3A997890d1-4141-4597-92eb-3dbaa4dc44a1?collection=education" rel="nofollow">Anonymous HD video streaming, .pdf 68 pages</a>.
Second is focused on encryption part, called <a href="http://repository.tudelft.nl/islandora/object/uuid%3Ace3bd867-6540-426d-87d0-348bdf78279d?collection=education" rel="nofollow">Anonymous Internet: Anonymizing peer-to-peer traffic using applied cryptography, .pdf 85 pages</a>.
In addition, there are the specifications for the protocols
for <a href="https://github.com/Tribler/tribler/wiki/Anonymous-Downloading-and-Streaming-specifications">anonymous downloading</a> and <a href="https://github.com/Tribler/tribler/wiki/Hidden-Services-Specifications-for-anonymous-seeding">hidden seeding</a> on this wiki.</p>
<p><h2>overlay protocol for synchronization</h2><a id="user-content-overlay-protocol-for-synchronization" aria-label="Permalink: overlay protocol for synchronization" href="#overlay-protocol-for-synchronization"></a></p>
<p>The current foundation of Tribler is the Dispersy overlay. Dispersy functionality includes: making connections, sending messages, puncturing NAT boxes, and distributed database synchronization. Every 5 seconds Dispersy sends out a message to establish a new connection or re-connect to a known peer.
Note that <a href="https://github.com/qstokkink/py-ipv8">we are transitioning to a new overlay</a> for the durations of 2018.</p>
<p>Overlay communication, peer discovery and content discovery (keyword search) are essential building blocks of a peer-to-peer system. Tribler preserves the content and peers it discovered in the past. Every Tribler client runs a full SQL database engine. Several times per second each Tribler peer sends and receives updates for this database. Our protocol for distributed database synchronization is called Dispersy.
See a simple messaging client written with just a few lines of code as <a href="https://github.com/jarradh/DispersyExample">a simple tutorial example</a>; <a href="https://github.com/Tribler/dispersy/blob/devel/doc/tutorial-part1.org">outdated broken tutorial</a>.</p>
<p>The detailed wire protocol specification:
<a href="https://github.com/Tribler/dispersy/blob/devel/docs/wire_protocol.rst#dispersy-introduction-request">introduction-request-1</a></p>
<p><a href="https://d2k0ddhflgrk1i.cloudfront.net/EWI/Over%20de%20faculteit/Afdelingen/Software%20Technology/Distributed%20Systems/Technical%20Reports/2013/PDS-2013-002.pdf" rel="nofollow">Dispersy is a fully decentralized system for synchronization (.pdf)</a>, capable of running in challenged network environments. Key features of Dispersy are stateless synchronization using Bloomfilters, decentralized NAT traversal, and data bundle selection algorithms that allow the system to scale over 100,000 bundles in the presence of high churn and high-load scenario's.</p>
<p>Dispersy uses a simple database schema, with the <em>sync</em> table containing the data bundles to synchronise across peers in the <em>packet</em> field.
<img src="https://cloud.githubusercontent.com/assets/325224/3511069/a4b9d182-06ac-11e4-827b-69c71374492a.png" alt="dispersy1"></p>
<p><h2>Android port of LibTribler</h2><a id="user-content-android-port-of-libtribler" aria-label="Permalink: Android port of LibTribler" href="#android-port-of-libtribler"></a></p>
<p>Android porting teams are working on the <a href="https://github.com/rjagerman/AT3">downloading and Tor-like protocol part</a> of Tribler and the <a href="https://github.com/wtud/tsap">overlay, channels and search</a> portions. As of June 2014 there is initial running code. The focus is on stability and creating a mature build environment using Jenkins. See below two actual screenshot of current running code. Download the alpha  .APK here: <a href="https://jenkins.tribler.org/job/Build-Tribler_Android-Python/lastBuild/" rel="nofollow">https://jenkins.tribler.org/job/Build-Tribler_Android-Python/lastBuild/</a></p>
<p><img src="https://raw.githubusercontent.com/wtud/tsap/39add25ce1533be02cf5e544f096d15ee71e0c30/screenshots/home_screen_portrait_readme.png" alt="LibTribler running as an CML-RPC service on Android"></p>
<p><img src="https://camo.githubusercontent.com/a18b5cd459e4ba97f4bc3b55e7e92b31d4b20ce7/687474703a2f2f666f72756d2e747269626c65722e6f72672f646f776e6c6f61642f66696c652e7068703f69643d323033" alt="TOR-like tunnels on Android with Bittorrent downloading"></p>
<p><h2>Stealth app for Android</h2><a id="user-content-stealth-app-for-android" aria-label="Permalink: Stealth app for Android" href="#stealth-app-for-android"></a></p>
<p>The following work is ongoing. We have an <a href="https://github.com/AlexKolpa/AndroidStealth/issues?state=open">operational Android app</a> that can spread itself via NFC. The app can spread viral via friends, even if it is blocked from a central app store.</p>
<p>Original student assignment: <em>The aim is to create an Open Source Android smartphone app to help bypass restrictions by non-democratic governments.  The Arab Spring showed the importance of video recording of mass protests. However, possession of a video recording on your phone of human rights violations and mass uprisings brings grave danger. The idea is to make this app “check-point-proof”, meaning that a somewhat knowledgeable person will not detect the presence of the app and will not discover any video content. The app itself should be hidden, you can make a “stealth” app by somehow removing the app icon from your app list (sadly it simply still shows up in the uninstall app list). The app is activated simply by “dialing” a secret telephone number or other method your deem secure. Starting point for your work can be found here: <a href="http://stackoverflow.com/questions/5921071/how-to-create-a-stealth-like-android-app" rel="nofollow">http://stackoverflow.com/questions/5921071/how-to-create-a-stealth-like-android-app</a>.
Your Stealth app need to be able to virally spread and be able to bypass an government restrictions on the official app store. Include the feature for NFC and direct-wifi transfer of the .apk with an easy on-screen manual and steps. Thus users can pass your app along to their friends.</em></p>
<p><h2>NAT Traversal: 80% success rate</h2><a id="user-content-nat-traversal-80-success-rate" aria-label="Permalink: NAT Traversal: 80% success rate" href="#nat-traversal-80-success-rate"></a></p>
<p>Peer-to-Peer (P2P) networks work on the presumption that all nodes in the network are connectable. However, NAT boxes and firewalls prevent connections to many nodes on the Internet.
We created a method to puncture NATs which does not require a server. Our method is therefore a simple no-server-needed alternative to the complex STUN, TURN and <a href="http://tools.ietf.org/html/rfc5245" rel="nofollow">ICE</a> approaches.
<a href="https://dl.ifip.org/db/conf/networking/networking2011-2/HalkesP11.pdf" rel="nofollow">We conducted one of the largest measurements of NAT/Firewall behavior and puncture efficiency in the wild</a>. Our method is a UDP hole-punching technique. We measured the success rate using volunteers running Tribler. Number of users in our trials are 907 and 1531 people. Our results show that UDP hole punching is an effective method to increase the connectability of peers on the Internet: approximately 64% of all peers are behind a NAT box or firewall. More than 80% of hole punching attempts between these peers succeed.</p>
<p><a href="http://tools.ietf.org/html/draft-ietf-ppsp-peer-protocol-03#section-3.10.2" rel="nofollow">Brief description of our UDP puncture method in IETF draft</a></p>
<p><a href="http://kayapo.tribler.org/trac/raw-attachment/wiki/NATtraversal/remko_1035363_Onderzoekstaak_-_Final_Version.pdf" rel="nofollow">Lengthy thesis work on UDP puncturing from 2005</a></p>
<p><h2>Roadmap 2030: a proven alternative model for capitalism</h2><a id="user-content-roadmap-2030-a-proven-alternative-model-for-capitalism" aria-label="Permalink: Roadmap 2030: a proven alternative model for capitalism" href="#roadmap-2030-a-proven-alternative-model-for-capitalism"></a></p>
<p>As Tribler scientists and engineer we are actively trying to make a better world.
Our micro-economy is our living lab for experimenting with alternative models for capitalism.
We aim to re-invent money by creating the first sustainable economy without
any moral hazards from bankers, politicians, and megacorporation.
Citizens and only the citizens are in control with self-governance.</p>
<p><strong><a href="http://www.youtube.com/watch?v=JQiLaKdzD0E" rel="nofollow">Our grand vision in a 1+ hour lecture given at Stanford University, via their Youtube channel</a></strong>.
We want to do more then be a Youtube alternative.
Our grand vision is liberating both media and money.
See the talk <a href="http://www.stanford.edu/class/ee380/Abstracts/120530.html" rel="nofollow">Abstract</a> and <a href="http://www.tribler.org/trac/raw-attachment/wiki/P2P-Collective/EE380_Tribler_talk_Stanford__Pouwelse_Delft_University.pdf" rel="nofollow">slides (.pdf 78 pages)</a>. Keywords: transform money, “Bank-of-Bits”, global financial meltdown isolation. Use cooperation&amp;stability, not volatility&amp;greed.
Alter the essence of capitalism (rich get richer) by abolishing compound interest rate and facilitation of safe zero-cost money transfers &amp; lending.
We aim for a direct assault on the essence of capitalism, aiming even further then the Bitcoin accomplishment (bypassing the central bank).</p>
<p>Further reading:</p>
<ul>
<li>Our writup on InternetSociety.org on <a href="http://www.internetsociety.org/articles/moving-toward-censorship-free-internet" rel="nofollow">liberating the media and Internet itself</a>.</li>
<li>The challenge is to design a micro-economy where the attacker might even control the underlying infrastructure. <a href="http://torrentfreak.com/researchers-anonymous-bittorrent-client-120601/" rel="nofollow">Our 2012 annoucement of our new focus on attack-resilience</a> was covered by numerous news organisations. <a href="http://www.foxnews.com/tech/2012/02/10/forget-megaupload-researchers-call-new-file-sharing-network-invincible/" rel="nofollow">Fox News</a> and Russian Today called us the <a href="http://rt.com/usa/internet-war-new-tribler-941/" rel="nofollow">the new weapon in the battle for Internet liberty</a>.</li>
</ul>
<p><h2>Tribler history</h2><a id="user-content-tribler-history" aria-label="Permalink: Tribler history" href="#tribler-history"></a></p>
<ul>
<li>2019: Release of Gigachannels and Python3 compatibility</li>
<li>2018: Release of Tribler 7</li>
<li>2017: Release of IPv8 digital identity framework, successor of Dispersy</li>
<li>2017: First live tests with decentral marketplace</li>
<li>2016: New blockchain deployment testing</li>
<li>2014: Test network goes live for anonymous Tor-like downloading (not connected in any with with 'the' Tor project)</li>
<li>2013: Anonymous Tor-like download trial</li>
<li>2012: Tribler Mobile live streaming from a phone camera</li>
<li>2011: Libswift accepted as an upcoming IETF Internet Standard</li>
<li>2010: Release of Dispersy network overlay framework</li>
<li>2010: <a href="https://repository.tudelft.nl/islandora/object/uuid:52b586ea-6144-4b4e-a5a1-b05255ce493a/datastream/OBJ" rel="nofollow">Splash</a> framework for data synchronization tested</li>
<li>2010: Wikipedia.org uses our technology for live trial</li>
<li>2009: Large HD streaming trial with BBC</li>
<li>2008: Social network without servers and "easy" invites</li>
<li>2007: Our distributed ledger launched in the wild</li>
<li>2006: Tribler 1st release</li>
<li>2005: First Tribler code = social Bittorrent</li>
<li>2004: Slashdot for first time with largest Bittorrent study</li>
</ul>

              </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[David Frankel is a man on a mission against robocalls (167 pts)]]></title>
            <link>https://spectrum.ieee.org/how-to-stop-robocalls</link>
            <guid>40156527</guid>
            <pubDate>Thu, 25 Apr 2024 12:13:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/how-to-stop-robocalls">https://spectrum.ieee.org/how-to-stop-robocalls</a>, See on <a href="https://news.ycombinator.com/item?id=40156527">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="Why One Man Spent 12 Years Fighting Robocalls" data-elid="2667800049" data-post-url="https://spectrum.ieee.org/how-to-stop-robocalls" data-authors="Michael Koziol" data-page-title="Why One Man Spent 12 Years Fighting Robocalls - IEEE Spectrum"><p>
	At some point, our phone habits changed. It used to be that if the phone rang, you answered it. With the advent of caller ID, you’d only pick up if it was someone you recognized. And now, with spoofing and robocalls, it can seem like a gamble to pick up the phone, period. In 2023, <a href="https://robocallindex.com/" rel="noopener noreferrer" target="_blank"><u>robocall blocking service Youmail</u></a> estimates there were <a href="https://www.techdirt.com/2024/01/16/americans-received-55-million-robocalls-in-2023-a-9-jump-from-2022/" rel="noopener noreferrer" target="_blank"><u>more than 55 billion robocalls</u></a> in the United States. How did robocalls proliferate so much that now they seem to be dominating phone networks? And <a href="https://spectrum.ieee.org/how-your-phone-company-aims-to-stop-robocalls" target="_self"><u>can any of this be undone</u></a>? <em><em><a href="https://spectrum.ieee.org/">IEEE Spectrum</a></em></em>spoke with <a href="https://www.linkedin.com/in/davidfrankel2" rel="noopener noreferrer" target="_blank"><u>David Frankel of ZipDX</u></a>, who’s been fighting robocalls for over a decade, to find out.
</p><p>David Frankel is<a href="https://www.zipdx.info/about/team-members/" rel="noopener noreferrer" target="_blank"><u>the founder of ZipDX</u></a>, a company that provides audioconferencing solutions. He also created the <a href="https://legalcallsonly.org/what-is-rraptor/" rel="noopener noreferrer" target="_blank"><u>Rraptor</u></a> automated robocall surveillance system.</p><p><strong>How did you get involved in trying to stop robocalls?</strong></p><p><strong>David Frankel: </strong>Twelve years ago, I was working in <a href="https://spectrum.ieee.org/topic/telecommunications/">telecommunications</a> and a friend of mine called me <a href="https://www.ftc.gov/news-events/news/press-releases/2013/04/ftc-announces-robocall-challenge-winners" rel="noopener noreferrer" target="_blank"><u>about a contest</u></a> that the Federal Trade Commission (FTC) was starting. They were seeking the public’s help to find solutions to the robocall problem. I spent time and energy putting together a contest entry. I didn’t win, but I became so engrossed in the problem, and like a dog with a bone, I just haven’t let go of it.
</p><p><strong>How can we successfully combat robocalls?</strong></p><p><strong>Frankel: </strong>Well, I don’t know the answer, because I don’t feel like we’ve succeeded yet. I’ve been very involved in something called<a href="https://tracebacks.org/" rel="noopener noreferrer" target="_blank"><u>traceback</u></a>—in fact, it was my FTC contest entry. It’s a semiautomated process where, in fact, with the cooperation of individual phone companies, you go from telco A to B to C to D, until you ultimately get somebody that sent that call. And then you can find the customer who paid them to put this call on the network.
</p><p>
	I’ve got a second tool—a <a href="https://legalcallsonly.org/what-is-rraptor/" rel="noopener noreferrer" target="_blank"><u>robocall surveillance network</u></a>. We’ve got tens of thousands of telephone numbers that just wait for robocalls. We can correlate that with other data and reveal where these calls are coming from. Ideally, we stop them at the source. It’s a sort of sewage that’s being pumped into the telephone network. We want to go upstream to find the source of the sewage and deal with it there.
</p><p><strong>Can </strong><a href="https://spectrum.ieee.org/ai-robocalls-2667266649" target="_self"><u><strong>more regulation</strong></u></a><strong> help?</strong></p><p><strong>Frankel: </strong>Well, regulations are really, really tough for a couple of reasons. One is, it’s a bureaucratic, slow-moving process. It’s also a cat-and-mouse game, because, as quick as you start talking about new regulations, people start talking about how to circumvent them.
</p><p>
	There’s also this notion of regulatory capture. At the Federal Communications Committee, the loudest voices come from the telecommunications operators. There’s an imbalance in the control that the consumer ultimately has over who gets to invade their telephone versus these other interests.
</p><p><strong>Is the robocall situation getting better or worse?</strong></p><p><strong>Frankel: </strong>It’s been fairly steady state. I’m just disappointed that it’s not substantially reduced from where it’s been. We made progress on explicit fraud calls, but we still have too many of these lead-generation calls. We need to get this whacked down by 80 percent. I always think that we’re on the cusp of doing that, that this year is going to be the year. There are people attacking this from a number of different angles. Everybody says there’s no silver bullet, and I believe that, but I hope that we’re about to crest the hill.
</p><p><strong>Is this a fight that’s ultimately winnable?</strong></p><p><strong>Frankel: </strong>I think we’ll be able to take back our phone network. I’d love to retire, having something to show for our efforts. I don’t think we’ll get it to zero. But I think that we’ll be able to push the genie a long way back into the bottle. The measure of success is that we all won’t be scared to answer our phone. It’ll be a surprise that it’s a robocall—instead of the expectation that it’s a robocall.
</p><p><em>This article appears in the May 2024 issue as “5 Questions for David Frankel.”</em><br></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A useful front-end confetti animation library (385 pts)]]></title>
            <link>https://github.com/catdad/canvas-confetti</link>
            <guid>40156330</guid>
            <pubDate>Thu, 25 Apr 2024 11:53:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/catdad/canvas-confetti">https://github.com/catdad/canvas-confetti</a>, See on <a href="https://news.ycombinator.com/item?id=40156330">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><h2 tabindex="-1" dir="auto"><a href="https://github.com/catdad/canvas-confetti/"><img src="https://camo.githubusercontent.com/eb786c99b352202fd6215ba451ff5a45f1d77973e4d5217742702e108510e097/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f6361746461642d6578706572696d656e74732f6361746461642d6578706572696d656e74732d6f7267403565643738622f63616e7661732d636f6e66657474692f6c6f676f2e6a7067" alt="Canvas Confetti" data-canonical-src="https://cdn.jsdelivr.net/gh/catdad-experiments/catdad-experiments-org@5ed78b/canvas-confetti/logo.jpg"></a></h2><a id="" aria-label="Permalink: " href="#"></a></div>
<p dir="auto"><a href="https://github.com/catdad/canvas-confetti/actions/workflows/ci.yml?query=branch%3Amaster"><img src="https://github.com/catdad/canvas-confetti/actions/workflows/ci.yml/badge.svg" alt="github actions ci"></a>
<a href="https://www.jsdelivr.com/package/npm/canvas-confetti" rel="nofollow"><img src="https://camo.githubusercontent.com/b4d4962066dbc03d8bdaf0fb0a4f62e9fa6e8ec8ef395eee6f529d04b2274da3/68747470733a2f2f646174612e6a7364656c6976722e636f6d2f76312f7061636b6167652f6e706d2f63616e7661732d636f6e66657474692f62616467653f7374796c653d726f756e646564" alt="jsdelivr" data-canonical-src="https://data.jsdelivr.com/v1/package/npm/canvas-confetti/badge?style=rounded"></a>
<a href="https://www.npmjs.com/package/canvas-confetti" rel="nofollow"><img src="https://camo.githubusercontent.com/c1b0ce113e31fce5713bd1f7b5653dd3243260c93e1e27837d3cc27bc51ded60/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f646d2f63616e7661732d636f6e66657474692e737667" alt="npm-downloads" data-canonical-src="https://img.shields.io/npm/dm/canvas-confetti.svg"></a>
<a href="https://www.npmjs.com/package/canvas-confetti" rel="nofollow"><img src="https://camo.githubusercontent.com/a237711cc7988d9297c6b690272b0ebd0fc0ea896bd5eae4198447ec4542fa8b/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f762f63616e7661732d636f6e66657474692e737667" alt="npm-version" data-canonical-src="https://img.shields.io/npm/v/canvas-confetti.svg"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo</h2><a id="user-content-demo" aria-label="Permalink: Demo" href="#demo"></a></p>
<p dir="auto"><a href="https://catdad.github.io/canvas-confetti/" rel="nofollow">catdad.github.io/canvas-confetti</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Install</h2><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<p dir="auto">You can install this module as a component from NPM:</p>
<div dir="auto" data-snippet-clipboard-copy-content="npm install --save canvas-confetti"><pre>npm install --save canvas-confetti</pre></div>
<p dir="auto">You can then <code>require('canvas-confetti');</code> to use it in your project build. <em>Note: this is a client component, and will not run in Node. You will need to build your project with something like <a href="https://github.com/webpack/webpack">webpack</a> in order to use this.</em></p>
<p dir="auto">You can also include this library in your HTML page directly from a CDN:</p>
<div dir="auto" data-snippet-clipboard-copy-content="<script src=&quot;https://cdn.jsdelivr.net/npm/canvas-confetti@1.9.2/dist/confetti.browser.min.js&quot;></script>"><pre><span>&lt;</span><span>script</span> <span>src</span>="<span>https://cdn.jsdelivr.net/npm/canvas-confetti@1.9.2/dist/confetti.browser.min.js</span>"<span>&gt;</span><span>&lt;/</span><span>script</span><span>&gt;</span></pre></div>
<p dir="auto"><em>Note: you should use the latest version at the time that you include your project. You can see all versions <a href="https://github.com/catdad/canvas-confetti/releases">on the releases page</a>.</em></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Reduced Motion</h2><a id="user-content-reduced-motion" aria-label="Permalink: Reduced Motion" href="#reduced-motion"></a></p>
<p dir="auto">Thank you for joining me in this very important message about motion on your website. See, <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-reduced-motion" rel="nofollow">not everyone likes it, and some actually prefer no motion</a>. They have <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-reduced-motion" rel="nofollow">ways to tell us about it</a> and we should listen. While I don't want to go as far as tell you not to have confetti on your page just yet, I do want to make it easy for you to respect what your users want. There is a <code>disableForReducedMotion</code> option you can use so that users that have trouble with chaotic animations don't need to struggle on your website. This is disabled by default, but I am considering changing that in a future major release. If you have strong feelings about this, <a href="https://github.com/catdad/canvas-confetti/issues/new">please let me know</a>. For now, please confetti responsibly.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">API</h2><a id="user-content-api" aria-label="Permalink: API" href="#api"></a></p>
<p dir="auto">When installed from <code>npm</code>, this library can be required as a client component in your project build. When using the CDN version, it is exposed as a <code>confetti</code> function on <code>window</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>confetti([options {Object}])</code> → <code>Promise|null</code></h3><a id="user-content-confettioptions-object--promisenull" aria-label="Permalink: confetti([options {Object}]) → Promise|null" href="#confettioptions-object--promisenull"></a></p>
<p dir="auto"><code>confetti</code> takes a single optional object. When <code>window.Promise</code> is available, it will return a Promise to let you know when it is done. When promises are not available (like in IE), it will return <code>null</code>. You can polyfill promises using any of the popular polyfills. You can also provide a promise implementation to <code>confetti</code> through:</p>
<div dir="auto" data-snippet-clipboard-copy-content="const MyPromise = require('some-promise-lib');
const confetti = require('canvas-confetti');
confetti.Promise = MyPromise;"><pre><span>const</span> <span>MyPromise</span> <span>=</span> <span>require</span><span>(</span><span>'some-promise-lib'</span><span>)</span><span>;</span>
<span>const</span> <span>confetti</span> <span>=</span> <span>require</span><span>(</span><span>'canvas-confetti'</span><span>)</span><span>;</span>
<span>confetti</span><span>.</span><span>Promise</span> <span>=</span> <span>MyPromise</span><span>;</span></pre></div>
<p dir="auto">If you call <code>confetti</code> multiple times before it is done, it will return the same promise every time. Internally, the same canvas element will be reused, continuing the existing animation with the new confetti added. The promise returned by each call to <code>confetti</code> will resolve once all animations are done.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto"><code>options</code></h4><a id="user-content-options" aria-label="Permalink: options" href="#options"></a></p>
<p dir="auto">The <code>confetti</code> parameter is a single optional <code>options</code> object, which has the following properties:</p>
<ul dir="auto">
<li><code>particleCount</code> <em>Integer (default: 50)</em>: The number of confetti to launch. More is always fun... but be cool, there's a lot of math involved.</li>
<li><code>angle</code> <em>Number (default: 90)</em>: The angle in which to launch the confetti, in degrees. 90 is straight up.</li>
<li><code>spread</code> <em>Number (default: 45)</em>: How far off center the confetti can go, in degrees. 45 means the confetti will launch at the defined <code>angle</code> plus or minus 22.5 degrees.</li>
<li><code>startVelocity</code> <em>Number (default: 45)</em>: How fast the confetti will start going, in pixels.</li>
<li><code>decay</code> <em>Number (default: 0.9)</em>: How quickly the confetti will lose speed. Keep this number between 0 and 1, otherwise the confetti will gain speed. Better yet, just never change it.</li>
<li><code>gravity</code> <em>Number (default: 1)</em>: How quickly the particles are pulled down. 1 is full gravity, 0.5 is half gravity, etc., but there are no limits. You can even make particles go up if you'd like.</li>
<li><code>drift</code> <em>Number (default: 0)</em>: How much to the side the confetti will drift. The default is 0, meaning that they will fall straight down. Use a negative number for left and positive number for right.</li>
<li><code>flat</code> <em>Boolean (default: false)</em>: Optionally turns off the tilt and wobble that three dimensional confetti would have in the real world. Yeah, they look a little sad, but y'all asked for them, so don't blame me.</li>
<li><code>ticks</code> <em>Number (default: 200)</em>: How many times the confetti will move. This is abstract... but play with it if the confetti disappear too quickly for you.</li>
<li><code>origin</code> <em>Object</em>: Where to start firing confetti from. Feel free to launch off-screen if you'd like.
<ul dir="auto">
<li><code>origin.x</code> <em>Number (default: 0.5)</em>: The <code>x</code> position on the page, with <code>0</code> being the left edge and <code>1</code> being the right edge.</li>
<li><code>origin.y</code> <em>Number (default: 0.5)</em>: The <code>y</code> position on the page, with <code>0</code> being the top edge and <code>1</code> being the bottom edge.</li>
</ul>
</li>
<li><code>colors</code> <em>Array&lt;String&gt;</em>: An array of color strings, in the HEX format... you know, like <code>#bada55</code>.</li>
<li><code>shapes</code> <em>Array&lt;String|Shape&gt;</em>: An array of shapes for the confetti. There are 3 built-in values of <code>square</code>, <code>circle</code>, and <code>star</code>. The default is to use both squares and circles in an even mix. To use a single shape, you can provide just one shape in the array, such as <code>['star']</code>. You can also change the mix by providing a value such as <code>['circle', 'circle', 'square']</code> to use two third circles and one third squares. You can also create your own shapes using the <a href="#confettishapefrompath-path-matrix---shape"><code>confetti.shapeFromPath</code></a> or <a href="#confettishapefromtext-text-scalar-color-fontfamily---shape"><code>confetti.shapeFromText</code></a> helper methods.</li>
<li><code>scalar</code> <em>Number (default: 1)</em>: Scale factor for each confetti particle. Use decimals to make the confetti smaller. Go on, try teeny tiny confetti, they are adorable!</li>
<li><code>zIndex</code> <em>Integer (default: 100)</em>: The confetti should be on top, after all. But if you have a crazy high page, you can set it even higher.</li>
<li><code>disableForReducedMotion</code> <em>Boolean (default: false)</em>: Disables confetti entirely for users that <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-reduced-motion" rel="nofollow">prefer reduced motion</a>. The <code>confetti()</code> promise will resolve immediately in this case.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>confetti.shapeFromPath({ path, matrix? })</code> → <code>Shape</code></h3><a id="user-content-confettishapefrompath-path-matrix---shape" aria-label="Permalink: confetti.shapeFromPath({ path, matrix? }) → Shape" href="#confettishapefrompath-path-matrix---shape"></a></p>
<p dir="auto">This helper method lets you create a custom confetti shape using an <a href="https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/d" rel="nofollow">SVG Path string</a>. Any valid path should work, though there are a few caveats:</p>
<ul dir="auto">
<li>All paths will be filed. If you were hoping to have a stroke path, that is not implemented.</li>
<li>Paths are limited to a single color, so keep that in mind.</li>
<li>All paths need a valid transform matrix. You can pass one in, or you can leave it out and use this helper to calculate the matrix for you. Do note that calculating the matrix is a bit expensive, so it is best to calculate it once for each path in development and cache that value, so that production confetti remain fast. The matrix is deterministic and will always be the same given the same path value.</li>
<li>For best forward compatibility, it is best to re-generate and re-cache the matrix if you update the <code>canvas-confetti</code> library.</li>
<li>Support for path-based confetti is limited to browsers which support <a href="https://developer.mozilla.org/en-US/docs/Web/API/Path2D" rel="nofollow"><code>Path2D</code></a>, which should really be all major browser at this point.</li>
</ul>
<p dir="auto">This method will return a <code>Shape</code> -- it's really just a plain object with some properties, but shhh... we'll pretend it's a shape. Pass this <code>Shape</code> object into the <code>shapes</code> array directly.</p>
<p dir="auto">As an example, here's how you might do a triangle confetti:</p>
<div dir="auto" data-snippet-clipboard-copy-content="var triangle = confetti.shapeFromPath({ path: 'M0 10 L5 0 L10 10z' });

confetti({
  shapes: [triangle]
});"><pre><span>var</span> <span>triangle</span> <span>=</span> <span>confetti</span><span>.</span><span>shapeFromPath</span><span>(</span><span>{</span> <span>path</span>: <span>'M0 10 L5 0 L10 10z'</span> <span>}</span><span>)</span><span>;</span>

<span>confetti</span><span>(</span><span>{</span>
  <span>shapes</span>: <span>[</span><span>triangle</span><span>]</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>confetti.shapeFromText({ text, scalar?, color?, fontFamily? })</code> → <code>Shape</code></h3><a id="user-content-confettishapefromtext-text-scalar-color-fontfamily---shape" aria-label="Permalink: confetti.shapeFromText({ text, scalar?, color?, fontFamily? }) → Shape" href="#confettishapefromtext-text-scalar-color-fontfamily---shape"></a></p>
<p dir="auto">This is the highly anticipated feature to render emoji confetti! Use any standard unicode emoji. Or other text, but... maybe don't use other text.</p>
<p dir="auto">While any text should work, there are some caveats:</p>
<ul dir="auto">
<li>For flailing confetti, something that is mostly square works best. That is, a single character, especially an emoji.</li>
<li>Rather than rendering text every time a confetti is drawn, this helper actually rasterizes the text. Therefore, it does not scale well after it is created. If you plan to use the <code>scalar</code> value to scale your confetti, use the same <code>scalar</code> value here when creating the shape. This will make sure the confetti are not blurry.</li>
</ul>
<p dir="auto">The options for this method are:</p>
<ul dir="auto">
<li><code>options</code> <em><code>Object</code></em>:
<ul dir="auto">
<li><code>text</code> <em><code>String</code></em>: the text to be rendered as a confetti. If you can't make up your mind, I suggest "🐈".</li>
<li><code>scalar</code> <em><code>Number, optional, default: 1</code></em>: a scale value relative to the default size. It matches the <code>scalar</code> value in the confetti options.</li>
<li><code>color</code> <em><code>String, optional, default: #000000</code></em>: the color used to render the text.</li>
<li><code>fontFamily</code> <em><code>String, optional, default: native emoji</code></em>: the font family name to use when rendering the text. The default follows <a href="https://nolanlawson.com/2022/04/08/the-struggle-of-using-native-emoji-on-the-web/" rel="nofollow">best practices for rendring the native OS emoji of the device</a>, falling back to <code>sans-serif</code>. If using a web font, make sure this <a href="https://developer.mozilla.org/en-US/docs/Web/API/FontFace/load" rel="nofollow">font is loaded</a> before rendering your confetti.</li>
</ul>
</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="var scalar = 2;
var pineapple = confetti.shapeFromText({ text: '🍍', scalar });

confetti({
  shapes: [pineapple],
  scalar
});"><pre><span>var</span> <span>scalar</span> <span>=</span> <span>2</span><span>;</span>
<span>var</span> <span>pineapple</span> <span>=</span> <span>confetti</span><span>.</span><span>shapeFromText</span><span>(</span><span>{</span> <span>text</span>: <span>'🍍'</span><span>,</span> scalar <span>}</span><span>)</span><span>;</span>

<span>confetti</span><span>(</span><span>{</span>
  <span>shapes</span>: <span>[</span><span>pineapple</span><span>]</span><span>,</span>
  scalar
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>confetti.create(canvas, [globalOptions])</code> → <code>function</code></h3><a id="user-content-confetticreatecanvas-globaloptions--function" aria-label="Permalink: confetti.create(canvas, [globalOptions]) → function" href="#confetticreatecanvas-globaloptions--function"></a></p>
<p dir="auto">This method creates an instance of the <code>confetti</code> function that uses a custom canvas. This is useful if you want to limit the area on your page in which confetti appear. By default, this method will not modify the canvas in any way (other than drawing to it).</p>
<p dir="auto"><em>Canvas can be misunderstood a bit though, so let me explain why you might want to let the module modify the canvas just a bit. By default, a <code>canvas</code> is a relatively small image -- somewhere around 300x150, depending on the browser. When you resize it using CSS, this sets the display size of the canvas, but not the image being represented on that canvas. Think of it as loading a 300x150 jpeg image in an <code>img</code> tag and then setting the CSS for that tag to <code>1500x600</code> -- your image will end up stretched and blurry. In the case of a canvas, you need to also set the width and height of the canvas image itself. If you don't want to do that, you can allow <code>confetti</code> to set it for you.</em></p>
<p dir="auto">Note also that you should persist the custom instance and avoid initializing an instance of confetti with the same canvas element more than once.</p>
<p dir="auto">The following global options are available:</p>
<ul dir="auto">
<li><code>resize</code> <em>Boolean (default: false)</em>: Whether to allow setting the canvas image size, as well as keep it correctly sized if the window changes size (e.g. resizing the window, rotating a mobile device, etc.). By default, the canvas size will not be modified.</li>
<li><code>useWorker</code> <em>Boolean (default: false)</em>: Whether to use an asynchronous web worker to render the confetti animation, whenever possible. This is turned off by default, meaning that the animation will always execute on the main thread. If turned on and the browser supports it, the animation will execute off of the main thread so that it is not blocking any other work your page needs to do. Using this option will also modify the canvas, but more on that directly below -- do read it. If it is not supported by the browser, this value will be ignored.</li>
<li><code>disableForReducedMotion</code> <em>Boolean (default: false)</em>: Disables confetti entirely for users that <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-reduced-motion" rel="nofollow">prefer reduced motion</a>. When set to true, use of this confetti instance will always respect a user's request for reduced motion and disable confetti for them.</li>
</ul>
<p dir="auto"><em><strong>Important: If you use <code>useWorker: true</code>, I own your canvas now. It's mine now and I can do whatever I want with it (don't worry... I'll just put confetti inside it, I promise). You must not try to use the canvas in any way (other than I guess removing it from the DOM), as it will throw an error. When using workers for rendering, control of the canvas must be transferred to the web worker, preventing any usage of that canvas on the main thread. If you must manipulate the canvas in any way, do not use this option.</strong></em></p>
<div dir="auto" data-snippet-clipboard-copy-content="var myCanvas = document.createElement('canvas');
document.body.appendChild(myCanvas);

var myConfetti = confetti.create(myCanvas, {
  resize: true,
  useWorker: true
});
myConfetti({
  particleCount: 100,
  spread: 160
  // any other options from the global
  // confetti function
});"><pre><span>var</span> <span>myCanvas</span> <span>=</span> <span>document</span><span>.</span><span>createElement</span><span>(</span><span>'canvas'</span><span>)</span><span>;</span>
<span>document</span><span>.</span><span>body</span><span>.</span><span>appendChild</span><span>(</span><span>myCanvas</span><span>)</span><span>;</span>

<span>var</span> <span>myConfetti</span> <span>=</span> <span>confetti</span><span>.</span><span>create</span><span>(</span><span>myCanvas</span><span>,</span> <span>{</span>
  <span>resize</span>: <span>true</span><span>,</span>
  <span>useWorker</span>: <span>true</span>
<span>}</span><span>)</span><span>;</span>
<span>myConfetti</span><span>(</span><span>{</span>
  <span>particleCount</span>: <span>100</span><span>,</span>
  <span>spread</span>: <span>160</span>
  <span>// any other options from the global</span>
  <span>// confetti function</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>confetti.reset()</code></h3><a id="user-content-confettireset" aria-label="Permalink: confetti.reset()" href="#confettireset"></a></p>
<p dir="auto">Stops the animation and clears all confetti, as well as immediately resolves any outstanding promises. In the case of a separate confetti instance created with <a href="#confetticreatecanvas-globaloptions--function"><code>confetti.create</code></a>, that instance will have its own <code>reset</code> method.</p>
<div dir="auto" data-snippet-clipboard-copy-content="confetti();

setTimeout(() => {
  confetti.reset();
}, 100);"><pre><span>confetti</span><span>(</span><span>)</span><span>;</span>

<span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>confetti</span><span>.</span><span>reset</span><span>(</span><span>)</span><span>;</span>
<span>}</span><span>,</span> <span>100</span><span>)</span><span>;</span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="var myCanvas = document.createElement('canvas');
document.body.appendChild(myCanvas);

var myConfetti = confetti.create(myCanvas, { resize: true });

myConfetti();

setTimeout(() => {
  myConfetti.reset();
}, 100);"><pre><span>var</span> <span>myCanvas</span> <span>=</span> <span>document</span><span>.</span><span>createElement</span><span>(</span><span>'canvas'</span><span>)</span><span>;</span>
<span>document</span><span>.</span><span>body</span><span>.</span><span>appendChild</span><span>(</span><span>myCanvas</span><span>)</span><span>;</span>

<span>var</span> <span>myConfetti</span> <span>=</span> <span>confetti</span><span>.</span><span>create</span><span>(</span><span>myCanvas</span><span>,</span> <span>{</span> <span>resize</span>: <span>true</span> <span>}</span><span>)</span><span>;</span>

<span>myConfetti</span><span>(</span><span>)</span><span>;</span>

<span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>myConfetti</span><span>.</span><span>reset</span><span>(</span><span>)</span><span>;</span>
<span>}</span><span>,</span> <span>100</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto">Launch some confetti the default way:</p>

<p dir="auto">Launch a bunch of confetti:</p>
<div dir="auto" data-snippet-clipboard-copy-content="confetti({
  particleCount: 150
});"><pre><span>confetti</span><span>(</span><span>{</span>
  <span>particleCount</span>: <span>150</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto">Launch some confetti really wide:</p>
<div dir="auto" data-snippet-clipboard-copy-content="confetti({
  spread: 180
});"><pre><span>confetti</span><span>(</span><span>{</span>
  <span>spread</span>: <span>180</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto">Get creative. Launch a small poof of confetti from a random part of the page:</p>
<div dir="auto" data-snippet-clipboard-copy-content="confetti({
  particleCount: 100,
  startVelocity: 30,
  spread: 360,
  origin: {
    x: Math.random(),
    // since they fall down, start a bit higher than random
    y: Math.random() - 0.2
  }
});"><pre><span>confetti</span><span>(</span><span>{</span>
  <span>particleCount</span>: <span>100</span><span>,</span>
  <span>startVelocity</span>: <span>30</span><span>,</span>
  <span>spread</span>: <span>360</span><span>,</span>
  <span>origin</span>: <span>{</span>
    <span>x</span>: <span>Math</span><span>.</span><span>random</span><span>(</span><span>)</span><span>,</span>
    <span>// since they fall down, start a bit higher than random</span>
    <span>y</span>: <span>Math</span><span>.</span><span>random</span><span>(</span><span>)</span> <span>-</span> <span>0.2</span>
  <span>}</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto">I said creative... we can do better. Since it doesn't matter how many times we call <code>confetti</code> (just the total number of confetti in the air), we can do some fun things, like continuously launch more and more confetti for 30 seconds, from multiple directions:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// do this for 30 seconds
var duration = 30 * 1000;
var end = Date.now() + duration;

(function frame() {
  // launch a few confetti from the left edge
  confetti({
    particleCount: 7,
    angle: 60,
    spread: 55,
    origin: { x: 0 }
  });
  // and launch a few from the right edge
  confetti({
    particleCount: 7,
    angle: 120,
    spread: 55,
    origin: { x: 1 }
  });

  // keep going until we are out of time
  if (Date.now() < end) {
    requestAnimationFrame(frame);
  }
}());"><pre><span>// do this for 30 seconds</span>
<span>var</span> <span>duration</span> <span>=</span> <span>30</span> <span>*</span> <span>1000</span><span>;</span>
<span>var</span> <span>end</span> <span>=</span> <span>Date</span><span>.</span><span>now</span><span>(</span><span>)</span> <span>+</span> <span>duration</span><span>;</span>

<span>(</span><span>function</span> <span>frame</span><span>(</span><span>)</span> <span>{</span>
  <span>// launch a few confetti from the left edge</span>
  <span>confetti</span><span>(</span><span>{</span>
    <span>particleCount</span>: <span>7</span><span>,</span>
    <span>angle</span>: <span>60</span><span>,</span>
    <span>spread</span>: <span>55</span><span>,</span>
    <span>origin</span>: <span>{</span> <span>x</span>: <span>0</span> <span>}</span>
  <span>}</span><span>)</span><span>;</span>
  <span>// and launch a few from the right edge</span>
  <span>confetti</span><span>(</span><span>{</span>
    <span>particleCount</span>: <span>7</span><span>,</span>
    <span>angle</span>: <span>120</span><span>,</span>
    <span>spread</span>: <span>55</span><span>,</span>
    <span>origin</span>: <span>{</span> <span>x</span>: <span>1</span> <span>}</span>
  <span>}</span><span>)</span><span>;</span>

  <span>// keep going until we are out of time</span>
  <span>if</span> <span>(</span><span>Date</span><span>.</span><span>now</span><span>(</span><span>)</span> <span>&lt;</span> <span>end</span><span>)</span> <span>{</span>
    <span>requestAnimationFrame</span><span>(</span><span>frame</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span><span>(</span><span>)</span><span>)</span><span>;</span></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TSMC unveils 1.6nm process technology with backside power delivery (292 pts)]]></title>
            <link>https://www.tomshardware.com/tech-industry/tsmc-unveils-16nm-process-technology-with-backside-power-delivery-rivals-intels-competing-design</link>
            <guid>40156275</guid>
            <pubDate>Thu, 25 Apr 2024 11:47:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/tech-industry/tsmc-unveils-16nm-process-technology-with-backside-power-delivery-rivals-intels-competing-design">https://www.tomshardware.com/tech-industry/tsmc-unveils-16nm-process-technology-with-backside-power-delivery-rivals-intels-competing-design</a>, See on <a href="https://news.ycombinator.com/item?id=40156275">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">

<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-320-80.jpg" alt="TSMC fire at new plant" srcset="https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV.jpg"></picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/yJ7ShszuRuJKRg7RzCy3rV.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: TSMC)</span>
</figcaption>
</div>

<div id="article-body">
<p>TSMC announced its leading-edge 1.6nm-class process technology today, a new A16 manufacturing process that will be the company's first Angstrom-class production node and promises to outperform its predecessor, N2P, by a significant margin. The technology's most important innovation will be its backside power delivery network (BSPDN).</p><p>Just like TSMC's 2nm-class nodes (N2, N2P, and N2X), the company's 1.6nm-class fabrication process will rely on gate-all-around (GAA) nanosheet transistors, but unlike the current and next-generation nodes, this one uses backside power delivery dubbed Super Power Rail. Transistor and BSPDN innovations enable tangible performance and efficiency improvements compared to TSMC's N2P: the new node promises an up to 10% higher clock rate at the same voltage and a 15% - 20% lower power consumption at the same frequency and complexity. In addition, the new technology could enable 7% - 10% higher transistor density, depending on the actual design.&nbsp;</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-320-80.png.webp 320w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-970-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-1024-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-1200-80.png.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-320-80.png" alt="TSMC" srcset="https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-320-80.png 320w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-970-80.png 970w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-1024-80.png 1024w, https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK-1200-80.png 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/mjEGKugAM7DPXKGJuqdneK.png"></picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: TSMC)</span></figcaption></figure><p>The most important innovation of TSMC's A16 process, which was unveiled at the company's <a data-analytics-id="inline-link" href="https://www.tsmc.com/static/english/campaign/Symposium2024/index.htm" data-url="https://www.tsmc.com/static/english/campaign/Symposium2024/index.htm" target="_blank" rel="sponsored noopener" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">North American Technology Symposium 2024</a>, is the introduction of the Super Power Rail (SPR), a sophisticated backside power delivery network (BSPDN). This technology is tailored specifically for AI and HPC processors that tend to have both complex signal wiring and dense power delivery networks.&nbsp;</p><p>Backside power delivery will be implemented into many upcoming process technologies as it allows for an increase in transistor density and improved power delivery, which affects performance. Meanwhile, there are several ways to implement a BSPDN. TSMC's Super Power Rail plugs the backside power delivery network to each transistor's source and drain using a special contract that also reduces resistance to get the maximum performance and power efficiency possible. From a production perspective, this is one of the most complex BSPDN implementations and is more complex than Intel's Power Via.&nbsp;</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-320-80.png.webp 320w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-970-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-1024-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-1200-80.png.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-320-80.png" alt="TSMC" srcset="https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-320-80.png 320w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-970-80.png 970w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-1024-80.png 1024w, https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L-1200-80.png 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/Rdsbs7yUHSe3YNd8mzMn9L.png"></picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: TSMC)</span></figcaption></figure><p>The choice of backside power rail implementation is perhaps why TSMC decided not to add this feature to its N2P and N2X process technologies, as it would make using the production nodes considerably more expensive. Meanwhile, by offering a 1.6nm-class node with GAA nanosheet transistors and SPR as well as 2nm-class nodes with GAAFETs only, the company will now have two distinct nodes that will not compete with each other directly but offer distinctive advantages for different customers.&nbsp;</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-320-80.png.webp 320w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-970-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-1024-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-1200-80.png.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-320-80.png" alt="TSMC" srcset="https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-320-80.png 320w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-970-80.png 970w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-1024-80.png 1024w, https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK-1200-80.png 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/BuTcfnoEvZU3ymMPWoawoK.png"></picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: TSMC)</span></figcaption></figure><p>The production timeline for A16 indicates that volume production of A16 will commence in the second half of 2026. Therefore, actual A16-made products will likely debut in 2027. This timeline positions A16 to potentially compete with Intel's 14A node, which will be the Intel's most advanced node at the time.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-Bhv28ghXS2smx6QV966UDU"><section><p>Join the experts who read Tom's Hardware for the inside track on enthusiast PC tech news — and have for over 25 years. We'll send breaking news and in-depth reviews of CPUs, GPUs, AI, maker hardware and more straight to your inbox.</p></section></div>
</div>
<div id="slice-container-authorBio-Bhv28ghXS2smx6QV966UDU"><p>Anton Shilov is a Freelance News Writer at Tom’s Hardware US. Over the past couple of decades, he has covered everything from CPUs and GPUs to supercomputers and from modern process technologies and latest fab tools to high-tech industry trends.</p></div>



<!-- Drop in a standard article here maybe? -->


</section>





<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>








</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How NASA Repaired Voyager 1 from 15B Miles Away (141 pts)]]></title>
            <link>https://arstechnica.com/space/2024/04/recoding-voyager-1-nasas-interstellar-explorer-is-finally-making-sense-again/</link>
            <guid>40155293</guid>
            <pubDate>Thu, 25 Apr 2024 09:28:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/space/2024/04/recoding-voyager-1-nasas-interstellar-explorer-is-finally-making-sense-again/">https://arstechnica.com/space/2024/04/recoding-voyager-1-nasas-interstellar-explorer-is-finally-making-sense-again/</a>, See on <a href="https://news.ycombinator.com/item?id=40155293">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
  




<!-- cache miss 366:single/related:7b642dbe541c5baf60cd5beb87e2ab40 --><!-- empty -->
<p>Engineers have partially restored a 1970s-era computer on NASA's Voyager 1 spacecraft after five months of long-distance troubleshooting, building confidence that humanity's first interstellar probe can eventually resume normal operations.</p>
<p>Several dozen scientists and engineers gathered Saturday in a conference room at NASA's Jet Propulsion Laboratory, or connected virtually, to wait for a new signal from Voyager 1. The ground team sent a command up to Voyager 1 on Thursday to recode part of the memory of the <a href="https://arstechnica.com/space/2024/02/humanitys-most-distant-space-probe-jeopardized-by-computer-glitch/">spacecraft's Flight Data Subsystem (FDS)</a>, one of the probe's three computers.</p>
<p>“In the minutes leading up to when we were going to see a signal, you could have heard a pin drop in the room," said Linda Spilker, project scientist for NASA's two Voyager spacecraft at JPL. "It was quiet. People were looking very serious. They were looking at their computer screens. Each of the subsystem (engineers) had pages up that they were looking at, to watch as they would be populated."</p>
<h2>Finally, a breakthrough</h2>
<p>Launched nearly 47 years ago, Voyager 1 is flying on an outbound trajectory more than 15 billion miles (24 billion kilometers) from Earth, and it takes 22-and-a-half hours for a radio signal to cover that distance at the speed of light. This means it takes nearly two days for engineers to uplink a command to Voyager 1 and get a response.</p>
<p>In November, Voyager 1 suddenly stopped transmitting its usual stream of data containing information about the spacecraft's health and measurements from its scientific instruments. Instead, the spacecraft's data stream was entirely unintelligible. Because the telemetry was unreadable, experts on the ground could not easily tell what went wrong. They hypothesized the source of the problem might be in the memory bank of the FDS.</p>
<p>There was a breakthrough last month when engineers sent up a novel command to "poke" Voyager 1's FDS to send back a readout of its memory. This readout allowed engineers to <a href="https://arstechnica.com/space/2024/04/the-diagnosis-is-in-bad-memory-knocked-nasas-aging-voyager-1-offline/">pinpoint the location of the problem in the FDS memory</a>. The FDS is responsible for packaging engineering and scientific data for transmission to Earth.</p>
<p>After a few weeks, NASA was ready to uplink a solution to get the FDS to resume packing engineering data. This data stream includes information on the status of the spacecraft—things like power levels and temperature measurements. This command went up to Voyager 1 through one of NASA's large Deep Space Network antennas Thursday.</p>                                            
                                                        
<p>Then, the wait for a response. Spilker, who started working on Voyager right out of college in 1977, was in the room when Voyager 1's signal reached Earth Saturday.</p>
<p>"When the time came to get the signal, we could clearly see all of a sudden, boom, we had data, and there were tears and smiles and high fives," she told Ars. "Everyone was very happy and very excited to see that, hey, we're back in communication again with Voyager 1. We're going to see the status of the spacecraft, the health of the spacecraft, for the first time in five months."</p>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/04/voyager1team.jpg" data-height="1125" data-width="1500" alt="Voyager 1's team celebrates the arrival of a radio signal from the spacecraft Saturday."><img alt="Voyager 1's team celebrates the arrival of a radio signal from the spacecraft Saturday." src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/voyager1team-640x480.jpg" width="640" height="480" srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/04/voyager1team-1280x960.jpg 2x"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/04/voyager1team.jpg" data-height="1125" data-width="1500">Enlarge</a> <span>/</span> Voyager 1's team celebrates the arrival of a radio signal from the spacecraft Saturday.</p></figcaption></figure>
<p>Throughout the five months of troubleshooting, Voyager's ground team continued to receive signals indicating the spacecraft was still alive. But until Saturday, they lacked insight into specific details about the status of Voyager 1.</p>
<p>“It’s pretty much just the way we left it," Spilker said. "We're still in the initial phases of analyzing all of the channels and looking at their trends. Some of the temperatures went down a little bit with this period of time that's gone on, but we're pretty much seeing everything we had hoped for. And that's always good news.”</p>
<h2>Relocating code</h2>
<p>Through their investigation, Voyager's ground team discovered a single chip responsible for storing a portion of the FDS memory stopped working, probably due to either a cosmic ray hit or a failure of aging hardware. This affected some of the computer's software code.</p>
<p>"That took out a section of memory," Spilker said. "What they have to do is relocate that code into a different portion of the memory, and then make sure that anything that uses those codes, those subroutines, know to go to the new location of memory, for access and to run it."</p>
<p>Only about 3 percent of the FDS memory was corrupted by the bad chip, so engineers needed to transplant that code into another part of the memory bank. But no single location is large enough to hold the section of code in its entirety, NASA said.</p>
<p>So the Voyager team divided the code into sections for storage in different places in the FDS. This wasn't just a copy-and-paste job. Engineers needed to modify some of the code to make sure it will all work together. "Any references to the location of that code in other parts of the FDS memory needed to be updated as well," NASA said in a statement.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Boeing retaliated against its own engineers working for FAA, union says (125 pts)]]></title>
            <link>https://www.seattletimes.com/business/boeing-aerospace/boeing-retaliated-against-its-own-engineers-working-for-faa-union-says/</link>
            <guid>40155240</guid>
            <pubDate>Thu, 25 Apr 2024 09:20:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.seattletimes.com/business/boeing-aerospace/boeing-retaliated-against-its-own-engineers-working-for-faa-union-says/">https://www.seattletimes.com/business/boeing-aerospace/boeing-retaliated-against-its-own-engineers-working-for-faa-union-says/</a>, See on <a href="https://news.ycombinator.com/item?id=40155240">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-content">
    <p>Boeing’s white-collar union alleged Tuesday that company management retaliated against engineers overseeing design work on behalf of the Federal Aviation Administration, heightening concerns about a self-regulation regime that’s come under renewed fire since Jan. 5, when a fuselage panel blew out midair.</p><p>In 2022, as Boeing worked to integrate new avionics packages into its 777 and 787 widebody aircraft,  two of its engineers insisted the company needed to reevaluate prior engineering work completed on the two aircraft. The engineering union contends Boeing managers objected to this on the grounds that it would add costs and slow production.</p><p>After the FAA backed the engineers about how the work should be performed and the dispute was settled, in mid-2023 Boeing gave both men negative performance reviews, which cuts pay raises and promotion prospects.</p><p>The two “did the right thing and stuck to their guns despite heavy pressure from Boeing, and then got hit with career-damaging performance reviews,” said Rich Plunkett, the union’s director of strategic development. “This helps show why Boeing doesn’t have a healthy safety culture.”</p><p>The union said one of the engineers quit Boeing over the way he was treated; it’s appealing the performance downgrade to management on behalf of the other.</p><p>Boeing denies the charge of retaliation. </p><p>“After an extensive review of documentation and interviewing more than a dozen witnesses, our investigators found no evidence of retaliation or interference,” spokesperson Bobbie Egan said Tuesday. “We have determined the allegations are unsubstantiated.” </p>
<p>“We have zero tolerance for retaliation and encourage our employees to speak up when they see an issue,” Egan said.</p><p>If proven, the union allegations would undercut Boeing’s recent insistence that it prioritizes safety over cost and schedule considerations and maintains an open culture that protects employees who flag safety issues.</p><p>The&nbsp;union, the Society of Professional Engineering Employees in Aerospace, SPEEA, has filed a complaint with the National Labor Relations Board demanding access to the report of the internal Boeing investigation that concluded the negative reviews did not amount to interfering in the oversight work of the two engineers.</p><p>Boeing said it is “looking into the union’s requests” but added that investigations into interference claims are typically confidential.</p><p>“Providing the report to any party outside the FAA would be a departure from our standard practice, ” Boeing said.</p>
<h2>Eyes of the FAA</h2><p>More than 1,000 engineers inside Boeing are authorized to act as the FAA’s eyes in overseeing work. They are legally required to have “a commitment to safety above all other priorities” and so must be independent and free of interference from management concerns about added cost and schedule delays.</p><p>But after the two deadly 737 MAX crashes five years ago, some of these engineers alleged management during the MAX’s development had <a href="https://www.seattletimes.com/business/boeing-aerospace/engineers-say-boeing-pushed-to-limit-safety-testing-in-race-to-certify-planes-including-737-max/">interfered to limit safety testing</a>. </p><p>That coupled with the failure of this internal oversight organization to flag the obvious flaws in <a href="https://www.seattletimes.com/seattle-news/times-watchdog/the-inside-story-of-mcas-how-boeings-737-max-system-gained-power-and-lost-safeguards/">the new flight control software that led to the crashes</a> raised serious doubts about Boeing’s ability to certify its own work.</p><p>Congress subsequently began to reverse the yearslong trend of delegating more of the FAA’s safety oversight to Boeing itself. </p><p>After a chain of quality lapses last year and then the fuselage panel blowout on an Alaska Airlines 737 MAX in January, Boeing leadership said it would revamp its safety reporting systems and has repeatedly insisted that all employees can raise safety concerns without fear of retaliation.</p><p>In February, the report of an FAA-appointed panel of independent aviation experts flagged concerns that the employees who represent the FAA fear raising safety issues because Boeing’s internal safety reporting systems fails to ensure “open communication and non-retaliation.”</p>
<p>The findings of that report were <a href="https://www.seattletimes.com/business/boeing-workers-still-scared-to-raise-safety-concerns-says-faa-appointed-experts/">highlighted just last week in a hearing before the U.S. Senate Committee</a> on Commerce, Science and Transportation. One finding was that some employees did not receive a raise they had been expecting after bringing up safety concerns.&nbsp;</p><p>After that hearing, Boeing said retaliation is strictly prohibited.&nbsp;</p><p>“Boeing can tell Congress and the media all it wants about how ‘retaliation is strictly prohibited,’” said Plunkett. “But our union is fighting retaliation cases on a regular basis.”</p><h2>Following FAA guidelines</h2><p>The job of the Boeing engineers authorized to work on behalf of the FAA is to check on the work of company engineers as they develop designs and instruct them what must be accomplished to get those designs approved as compliant with regulations.</p>      <p>The union said when overseeing the 777 and 787 avionics integration in 2022, the two engineers insisted the company reevaluate prior engineering calculations, citing an FAA advisory document updated in 2013 that provided guidelines on how to obtain airworthiness approval&nbsp;for such work.</p><p>An FAA advisory typically outlines a standard way of achieving compliance. It’s not mandatory and does not constitute a regulation.</p><p>According to the union, Boeing managers “strongly objected” to the conclusion that the prior work should be redone, “saying that going back to run calculations using the new assumptions would cost money and cause production delays.”</p>
<p>Eventually, after six months of back and forth, the FAA backed the two engineers and Boeing had to redo the analysis. </p><p>Subsequently, however, “when they came up for their next performance reviews, the two engineers received identical negative evaluations,” the union said.</p><p>SPEEA said that when its staff met with Boeing officials on the matter, “the manager of the two engineers admitted that he had rated them both poorly at the request of the 777 and 787 managers who had been forced to resubmit their work.”</p><p>Still, Boeing refused to change the performance evaluations. </p><p>While one of the engineers chose to leave Boeing, the other filed a complaint in the company’s “Speak Up” reporting system alleging retaliation. </p><p>In a meeting with the engineer, accompanied by a SPEEA official, Boeing labor relations personnel told him that his complaint “did not meet the legal threshold of interference, nor the legal definition of retaliation, and as a result, they were closing his case,” the union said.</p>
<p>Because that internal complaint implied interference with an FAA designee, Boeing had to file a report on the incident with the safety agency. As it appeals the performance downgrade, the union now seeks access to that report.</p><p>In 2022, responding to Congress, the FAA introduced new policies to prevent “undue pressure” on the engineers working on its behalf at aviation manufacturers.</p><p>The new regulations require Boeing to monitor for, report and investigate all allegations of interference and to report the results to the FAA. The agency now has the SPEEA charges.</p><p>“The FAA is investigating these allegations,” spokesperson Ian Gregor said Tuesday. </p>    
        <div>
   <p><span>
         Dominic Gates:      </span>
       <span>206-464-2963</span> or <span><a href="mailto:dgates@seattletimes.com">dgates@seattletimes.com</a>;</span>      <span>Dominic Gates is a Pulitzer Prize-winning aerospace journalist for The Seattle Times.</span>   </p>
</div>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tiny GPU: A minimal GPU implementation in Verilog (236 pts)]]></title>
            <link>https://github.com/adam-maj/tiny-gpu</link>
            <guid>40153815</guid>
            <pubDate>Thu, 25 Apr 2024 05:36:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/adam-maj/tiny-gpu">https://github.com/adam-maj/tiny-gpu</a>, See on <a href="https://news.ycombinator.com/item?id=40153815">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">tiny-gpu</h2><a id="user-content-tiny-gpu" aria-label="Permalink: tiny-gpu" href="#tiny-gpu"></a></p>
<p dir="auto">A minimal GPU implementation in Verilog optimized for learning about how GPUs work from the ground up.</p>
<p dir="auto">Built with &lt;15 files of fully documented Verilog, complete documentation on architecture &amp; ISA, working matrix addition/multiplication kernels, and full support for kernel simulation &amp; execution traces.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Table of Contents</h3><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#overview">Overview</a></li>
<li><a href="#architecture">Architecture</a>
<ul dir="auto">
<li><a href="#gpu">GPU</a></li>
<li><a href="#memory">Memory</a></li>
<li><a href="#core">Core</a></li>
</ul>
</li>
<li><a href="#isa">ISA</a></li>
<li><a href="#execution">Execution</a>
<ul dir="auto">
<li><a href="#core-1">Core</a></li>
<li><a href="#thread">Thread</a></li>
</ul>
</li>
<li><a href="#kernels">Kernels</a>
<ul dir="auto">
<li><a href="#matrix-addition">Matrix Addition</a></li>
<li><a href="https://github.com/adam-maj/tiny-gpu/blob/master/tree/master?tab=readme-ov-file#matrix-multiplication">Matrix Multiplication</a></li>
</ul>
</li>
<li><a href="#simulation">Simulation</a></li>
<li><a href="#advanced-functionality">Advanced Functionality</a></li>
<li><a href="#next-steps">Next Steps</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Overview</h2><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<p dir="auto">If you want to learn how a CPU works all the way from architecture to control signals, there are many resources online to help you.</p>
<p dir="auto">GPUs are not the same.</p>
<p dir="auto">Because the GPU market is so competitive, low-level technical details for all modern architectures remain proprietary.</p>
<p dir="auto">While there are lots of resources to learn about GPU programming, there's almost nothing available to learn about how GPU's work at a hardware level.</p>
<p dir="auto">The best option is to go through open-source GPU implementations like <a href="https://github.com/VerticalResearchGroup/miaow">Miaow</a> and <a href="https://github.com/hughperkins/VeriGPU/tree/main">VeriGPU</a> and try to figure out what's going on. This is challenging since these projects aim at being feature complete and functional, so they're quite complex.</p>
<p dir="auto">This is why I built <code>tiny-gpu</code>!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is tiny-gpu?</h2><a id="user-content-what-is-tiny-gpu" aria-label="Permalink: What is tiny-gpu?" href="#what-is-tiny-gpu"></a></p>
<div dir="auto"><p dir="auto">Important</p>
<p dir="auto"><strong>tiny-gpu</strong> is a minimal GPU implementation optimized for learning about how GPUs work from the ground up.</p>
<p dir="auto">Specifically, with the trend toward general-purpose GPUs (GPGPUs) and ML-accelerators like Google's TPU, tiny-gpu focuses on highlighting the general principles of all of these architectures, rather than on the details of graphics-specific hardware.</p>
</div>
<p dir="auto">With this motivation in mind, we can simplify GPUs by cutting out the majority of complexity involved with building a production-grade graphics card, and focus on the core elements that are critical to all of these modern hardwareaccelerators.</p>
<p dir="auto">This project is primarily focused on exploring:</p>
<ol dir="auto">
<li><strong>Architecture</strong> - What does the architecture of a GPU look like? What are the most important elements?</li>
<li><strong>Parallelization</strong> - How is the SIMD progamming model implemented in hardware?</li>
<li><strong>Memory</strong> - How does a GPU work around the constraints of limited memory bandwidth?</li>
</ol>
<p dir="auto">After understanding the fundamentals laid out in this project, you can checkout the <a href="#advanced-functionality">advanced functionality section</a> to understand some of the most important optimizations made in production grade GPUs (that are more challenging to implement) which improve performance.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Architecture</h2><a id="user-content-architecture" aria-label="Permalink: Architecture" href="#architecture"></a></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/adam-maj/tiny-gpu/blob/master/docs/images/gpu.png"><img src="https://github.com/adam-maj/tiny-gpu/raw/master/docs/images/gpu.png" alt="GPU" width="48%"></a>
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/adam-maj/tiny-gpu/blob/master/docs/images/core.png"><img src="https://github.com/adam-maj/tiny-gpu/raw/master/docs/images/core.png" alt="Core" width="48%"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">GPU</h2><a id="user-content-gpu" aria-label="Permalink: GPU" href="#gpu"></a></p>
<p dir="auto">tiny-gpu is built to execute a single kernel at a time.</p>
<p dir="auto">In order to launch a kernel, we need to do the following:</p>
<ol dir="auto">
<li>Load global program memory with the kernel code</li>
<li>Load data memory with the necessary data</li>
<li>Specify the number of threads to launch in the device control register</li>
<li>Launch the kernel by setting the start signal to high.</li>
</ol>
<p dir="auto">The GPU itself consists of the following units:</p>
<ol dir="auto">
<li>Device control register</li>
<li>Dispatcher</li>
<li>Variable number of compute cores</li>
<li>Memory controllers for data memory &amp; program memory</li>
<li>Cache</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Device Control Register</h3><a id="user-content-device-control-register" aria-label="Permalink: Device Control Register" href="#device-control-register"></a></p>
<p dir="auto">The device control register usually stores metadata specifying how kernels should be executed on the GPU.</p>
<p dir="auto">In this case, the device control register just stores the <code>thread_count</code> - the total number of threads to launch for the active kernel.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Dispatcher</h3><a id="user-content-dispatcher" aria-label="Permalink: Dispatcher" href="#dispatcher"></a></p>
<p dir="auto">Once a kernel is launched, the dispatcher is the unit that actually manages the distribution of threads to different compute cores.</p>
<p dir="auto">The dispatcher organizes threads into groups that can be executed in parallel on a single core called <strong>blocks</strong> and sends these blocks off to be processed by available cores.</p>
<p dir="auto">Once all blocks have been processed, the dispatcher reports back that the kernel execution is done.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Memory</h2><a id="user-content-memory" aria-label="Permalink: Memory" href="#memory"></a></p>
<p dir="auto">The GPU is built to interface with an external global memory. Here, data memory and program memory are separated out for simplicity.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Global Memory</h3><a id="user-content-global-memory" aria-label="Permalink: Global Memory" href="#global-memory"></a></p>
<p dir="auto">tiny-gpu data memory has the following specifications:</p>
<ul dir="auto">
<li>8 bit addressability (256 total rows of data memory)</li>
<li>8 bit data (stores values of &lt;256 for each row)</li>
</ul>
<p dir="auto">tiny-gpu program memory has the following specifications:</p>
<ul dir="auto">
<li>8 bit addressability (256 rows of program memory)</li>
<li>16 bit data (each instruction is 16 bits as specified by the ISA)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Memory Controllers</h3><a id="user-content-memory-controllers" aria-label="Permalink: Memory Controllers" href="#memory-controllers"></a></p>
<p dir="auto">Global memory has fixed read/write bandwidth, but there may be far more incoming requests across all cores to access data from memory than the external memory is actually able to handle.</p>
<p dir="auto">The memory controllers keep track of all the outgoing requests to memory from the compute cores, throttle requests based on actual external memory bandwidth, and relay responses from external memory back to the proper resources.</p>
<p dir="auto">Each memory controller has a fixed number of channels based on the bandwidth of global memory.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Cache (WIP)</h3><a id="user-content-cache-wip" aria-label="Permalink: Cache (WIP)" href="#cache-wip"></a></p>
<p dir="auto">The same data is often requested from global memory by multiple cores. Constantly access global memory repeatedly is expensive, and since the data has already been fetched once, it would be more efficient to store it on device in SRAM to be retrieved much quicker on later requests.</p>
<p dir="auto">This is exactly what the cache is used for. Data retrieved from external memory is stored in cache and can be retrieved from there on later requests, freeing up memory bandwidth to be used for new data.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Core</h2><a id="user-content-core" aria-label="Permalink: Core" href="#core"></a></p>
<p dir="auto">Each core has a number of compute resources, often built around a certain number of threads it can support. In order to maximize parallelization, these resources need to be managed optimally to maximize resource utilization.</p>
<p dir="auto">In this simplified GPU, each core processed one <strong>block</strong> at a time, and for each thread in a block, the core has a dedicated ALU, LSU, PC, and register file. Managing the execution of thread instructions on these resources is one of the most challening problems in GPUs.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Scheduler</h3><a id="user-content-scheduler" aria-label="Permalink: Scheduler" href="#scheduler"></a></p>
<p dir="auto">Each core has a single scheduler that manages the execution of threads.</p>
<p dir="auto">The tiny-gpu scheduler executes instructions for a single block to completion before picking up a new block, and it executes instructions for all threads in-sync and sequentially.</p>
<p dir="auto">In more advanced schedulers, techniques like <strong>pipelining</strong> are used to stream the execution of multiple instructions subsequent instructions to maximize resource utilization before previous instructions are fully complete. Additionally, <strong>warp scheduling</strong> can be use to execute multiple batches of threads within a block in parallel.</p>
<p dir="auto">The main constraint the scheduler has to work around is the latency associated with loading &amp; storing data from global memory. While most instructions can be executed synchronously, these load-store operations are asynchronous, meaning the rest of the instruction execution has to be built around these long wait times.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Fetcher</h3><a id="user-content-fetcher" aria-label="Permalink: Fetcher" href="#fetcher"></a></p>
<p dir="auto">Asynchronously fetches the instruction at the current program counter from program memory (most should actually be fetching from cache after a single block is executed).</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Decoder</h3><a id="user-content-decoder" aria-label="Permalink: Decoder" href="#decoder"></a></p>
<p dir="auto">Decodes the fetched instruction into control signals for thread execution.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Register Files</h3><a id="user-content-register-files" aria-label="Permalink: Register Files" href="#register-files"></a></p>
<p dir="auto">Each thread has it's own dedicated set of register files. The register files hold the data that each thread is performing computations on, which enables the same-instruction multiple-data (SIMD) pattern.</p>
<p dir="auto">Importantly, each register file contains a few read-only registers holding data about the current block &amp; thread being executed locally, enabling kernels to be executed with different data based on the local thread id.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">ALUs</h3><a id="user-content-alus" aria-label="Permalink: ALUs" href="#alus"></a></p>
<p dir="auto">Dedicated arithmetic-logic unit for each thread to perform computations. Handles the <code>ADD</code>, <code>SUB</code>, <code>MUL</code>, <code>DIV</code> arithmetic instructions.</p>
<p dir="auto">Also handles the <code>CMP</code> comparison instruction which actually outputs whether the result of the difference between two registers is negative, zero or positive - and stores the result in the <code>NZP</code> register in the PC unit.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">LSUs</h3><a id="user-content-lsus" aria-label="Permalink: LSUs" href="#lsus"></a></p>
<p dir="auto">Dedicated load-store unit for each thread to access global data memory.</p>
<p dir="auto">Handles the <code>LDR</code> &amp; <code>STR</code> instructions - and handles async wait times for memory requests to be processed and relayed by the memory controller.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">PCs</h3><a id="user-content-pcs" aria-label="Permalink: PCs" href="#pcs"></a></p>
<p dir="auto">Dedicated program-counter for each unit to determine the next instructions to execute on each thread.</p>
<p dir="auto">By default, the PC increments by 1 after every instruction.</p>
<p dir="auto">With the <code>BRnzp</code> instruction, the NZP register checks to see if the NZP register (set by a previous <code>CMP</code> instruction) matches some case - and if it does, it will branch to a specific line of program memory. <em>This is how loops and conditionals are implemented.</em></p>
<p dir="auto">Since threads are processed in parallel, tiny-gpu assumes that all threads "converge" to the same program counter after each instruction - which is a naive assumption for the sake of simplicity.</p>
<p dir="auto">In real GPUs, individual threads can branch to different PCs, causing <strong>branch divergence</strong> where a group of threads threads initially being processed together has to split out into separate execution.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">ISA</h2><a id="user-content-isa" aria-label="Permalink: ISA" href="#isa"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/adam-maj/tiny-gpu/blob/master/docs/images/isa.png"><img src="https://github.com/adam-maj/tiny-gpu/raw/master/docs/images/isa.png" alt="ISA"></a></p>
<p dir="auto">tiny-gpu implements a simple 11 instruction ISA built to enable simple kernels for proof-of-concept like matrix addition &amp; matrix multiplication (implementation further down on this page).</p>
<p dir="auto">For these purposes, it supports the following instructions:</p>
<ul dir="auto">
<li><code>BRnzp</code> - Branch instruction to jump to another line of program memory if the NZP register matches the <code>nzp</code> condition in the instruction.</li>
<li><code>CMP</code> - Compare the value of two registers and store the result in the NZP register to use for a later <code>BRnzp</code> instruction.</li>
<li><code>ADD</code>, <code>SUB</code>, <code>MUL</code>, <code>DIV</code> - Basic arithmetic operations to enable tensor math.</li>
<li><code>LDR</code> - Load data from global memory.</li>
<li><code>STR</code> - Store data into global memory.</li>
<li><code>CONST</code> - Load a constant value into a register.</li>
<li><code>RET</code> - Signal that the current thread has reached the end of execution.</li>
</ul>
<p dir="auto">Each register is specified by 4 bits, meaning that there are 16 total registers. The first 13 register <code>R0</code> - <code>R12</code> are free registers that support read/write. The last 3 registers are special read-only registers used to supply the <code>%blockIdx</code>, <code>%blockDim</code>, and <code>%threadIdx</code> critical to SIMD.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Execution</h2><a id="user-content-execution" aria-label="Permalink: Execution" href="#execution"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Core</h3><a id="user-content-core-1" aria-label="Permalink: Core" href="#core-1"></a></p>
<p dir="auto">Each core follows the following control flow going through different stages to execute each instruction:</p>
<ol dir="auto">
<li><code>FETCH</code> - Fetch the next instruction at current program counter from program memory.</li>
<li><code>DECODE</code> - Decode the instruction into control signals.</li>
<li><code>REQUEST</code> - Request data from global memory if necessary (if <code>LDR</code> or <code>STR</code> instruction).</li>
<li><code>WAIT</code> - Wait for data from global memory if applicable.</li>
<li><code>EXECUTE</code> - Execute any computations on data.</li>
<li><code>UPDATE</code> - Update register files and NZP register.</li>
</ol>
<p dir="auto">The control flow is laid out like this for the sake of simplicity and understandability.</p>
<p dir="auto">In practice, several of these steps could be compressed to be optimize processing times, and the GPU could also use <strong>pipelining</strong> to stream and coordinate the execution of many instructions on a cores resources without waiting for previous instructions to finish.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Thread</h3><a id="user-content-thread" aria-label="Permalink: Thread" href="#thread"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/adam-maj/tiny-gpu/blob/master/docs/images/thread.png"><img src="https://github.com/adam-maj/tiny-gpu/raw/master/docs/images/thread.png" alt="Thread"></a></p>
<p dir="auto">Each thread within each core follows the above execution path to perform computations on the data in it's dedicated register file.</p>
<p dir="auto">This resembles a standard CPU diagram, and is quite similar in functionality as well. The main difference is that the <code>%blockIdx</code>, <code>%blockDim</code>, and <code>%threadIdx</code> values lie in the read-only registers for each thread, enabling SIMD functionality.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Kernels</h2><a id="user-content-kernels" aria-label="Permalink: Kernels" href="#kernels"></a></p>
<p dir="auto">I wrote a matrix addition and matrix multiplication kernel using my ISA as a proof of concept to demonstrate SIMD programming and execution with my GPU. The test files in this repository are capable of fully simulating the execution of these kernels on the GPU, producing data memory states and a complete execution trace.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Matrix Addition</h3><a id="user-content-matrix-addition" aria-label="Permalink: Matrix Addition" href="#matrix-addition"></a></p>
<p dir="auto">This matrix addition kernel adds two 1 x 8 matrices by performing 8 element wise additions in separate threads.</p>
<p dir="auto">This demonstration makes use of the <code>%blockIdx</code>, <code>%blockDim</code>, and <code>%threadIdx</code> registers to show SIMD programming on this GPU. It also uses the <code>LDR</code> and <code>STR</code> instructions which require async memory management.</p>
<p dir="auto"><code>matadd.asm</code></p>
<div dir="auto" data-snippet-clipboard-copy-content=".threads 8
.data 0 1 2 3 4 5 6 7          ; matrix A (1 x 8)
.data 0 1 2 3 4 5 6 7          ; matrix B (1 x 8)

MUL R0, %blockIdx, %blockDim
ADD R0, R0, %threadIdx         ; i = blockIdx * blockDim + threadIdx

CONST R1, #0                   ; baseA (matrix A base address)
CONST R2, #8                   ; baseB (matrix B base address)
CONST R3, #16                  ; baseC (matrix C base address)

ADD R4, R1, R0                 ; addr(A[i]) = baseA + i
LDR R4, R4                     ; load A[i] from global memory

ADD R5, R2, R0                 ; addr(B[i]) = baseB + i
LDR R5, R5                     ; load B[i] from global memory

ADD R6, R4, R5                 ; C[i] = A[i] + B[i]

ADD R7, R3, R0                 ; addr(C[i]) = baseC + i
STR R7, R6                     ; store C[i] in global memory

RET                            ; end of kernel"><pre><span>.threads </span><span>8</span>
<span>.data </span><span>0</span><span> </span><span>1</span><span> </span><span>2</span><span> </span><span>3</span><span> </span><span>4</span><span> </span><span>5</span><span> </span><span>6</span><span> </span><span>7</span><span>          ; matrix A (1 x 8)</span>
<span>.data </span><span>0</span><span> </span><span>1</span><span> </span><span>2</span><span> </span><span>3</span><span> </span><span>4</span><span> </span><span>5</span><span> </span><span>6</span><span> </span><span>7</span><span>          ; matrix B (1 x 8)</span>

<span>MUL</span><span> R0</span><span>,</span><span> %blockIdx</span><span>,</span><span> %blockDim</span>
<span>ADD</span><span> R0</span><span>,</span><span> R0</span><span>,</span><span> %threadIdx</span><span>         ; i = blockIdx * blockDim + threadIdx</span>

<span>CONST R1</span><span>,</span><span> #</span><span>0</span><span>                   ; baseA (matrix A base address)</span>
<span>CONST R2</span><span>,</span><span> #</span><span>8</span><span>                   ; baseB (matrix B base address)</span>
<span>CONST R3</span><span>,</span><span> #</span><span>16</span><span>                  ; baseC (matrix C base address)</span>

<span>ADD</span><span> R4</span><span>,</span><span> R1</span><span>,</span><span> R0</span><span>                 ; addr(A[i]) = baseA + i</span>
<span>LDR R4</span><span>,</span><span> R4</span><span>                     ; load A[i] from global memory</span>

<span>ADD</span><span> R5</span><span>,</span><span> R2</span><span>,</span><span> R0</span><span>                 ; addr(B[i]) = baseB + i</span>
<span>LDR R5</span><span>,</span><span> R5</span><span>                     ; load B[i] from global memory</span>

<span>ADD</span><span> R6</span><span>,</span><span> R4</span><span>,</span><span> R5</span><span>                 ; C[i] = A[i] + B[i]</span>

<span>ADD</span><span> R7</span><span>,</span><span> R3</span><span>,</span><span> R0</span><span>                 ; addr(C[i]) = baseC + i</span>
<span>STR</span><span> R7</span><span>,</span><span> R6</span><span>                     ; store C[i] in global memory</span>

<span>RET</span><span>                            ; end of kernel</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Matrix Multiplication</h3><a id="user-content-matrix-multiplication" aria-label="Permalink: Matrix Multiplication" href="#matrix-multiplication"></a></p>
<p dir="auto">The matrix multiplication kernel multiplies two 2x2 matrices. It performs element wise calculation of the dot product of the relevant row and column and uses the <code>CMP</code> and <code>BRnzp</code> instructions to demonstrate branching within the threads (notably, all branches converge so this kernel works on the current tiny-gpu implementation).</p>
<p dir="auto"><code>matmul.asm</code></p>
<div dir="auto" data-snippet-clipboard-copy-content=".threads 4
.data 1 2 3 4                  ; matrix A (2 x 2)
.data 1 2 3 4                  ; matrix B (2 x 2)

MUL R0, %blockIdx, %blockDim
ADD R0, R0, %threadIdx         ; i = blockIdx * blockDim + threadIdx

CONST R1, #1                   ; increment
CONST R2, #2                   ; N (matrix inner dimension)
CONST R3, #0                   ; baseA (matrix A base address)
CONST R4, #4                   ; baseB (matrix B base address)
CONST R5, #8                   ; baseC (matrix C base address)

DIV R6, R0, R2                 ; row = i // N
MUL R7, R6, R2
SUB R7, R0, R7                 ; col = i % N

CONST R8, #0                   ; acc = 0
CONST R9, #0                   ; k = 0

LOOP:
  MUL R10, R6, R2
  ADD R10, R10, R9
  ADD R10, R10, R3             ; addr(A[i]) = row * N + k + baseA
  LDR R10, R10                 ; load A[i] from global memory

  MUL R11, R9, R2
  ADD R11, R11, R7
  ADD R11, R11, R4             ; addr(B[i]) = k * N + col + baseB
  LDR R11, R11                 ; load B[i] from global memory

  MUL R12, R10, R11
  ADD R8, R8, R12              ; acc = acc + A[i] * B[i]

  ADD R9, R9, R1               ; increment k

  CMP R9, R2
  BRn LOOP                    ; loop while k < N

ADD R9, R5, R0                 ; addr(C[i]) = baseC + i
STR R9, R8                     ; store C[i] in global memory

RET                            ; end of kernel"><pre><span>.threads </span><span>4</span>
<span>.data </span><span>1</span><span> </span><span>2</span><span> </span><span>3</span><span> </span><span>4</span><span>                  ; matrix A (2 x 2)</span>
<span>.data </span><span>1</span><span> </span><span>2</span><span> </span><span>3</span><span> </span><span>4</span><span>                  ; matrix B (2 x 2)</span>

<span>MUL</span><span> R0</span><span>,</span><span> %blockIdx</span><span>,</span><span> %blockDim</span>
<span>ADD</span><span> R0</span><span>,</span><span> R0</span><span>,</span><span> %threadIdx</span><span>         ; i = blockIdx * blockDim + threadIdx</span>

<span>CONST R1</span><span>,</span><span> #</span><span>1</span><span>                   ; increment</span>
<span>CONST R2</span><span>,</span><span> #</span><span>2</span><span>                   ; N (matrix inner dimension)</span>
<span>CONST R3</span><span>,</span><span> #</span><span>0</span><span>                   ; baseA (matrix A base address)</span>
<span>CONST R4</span><span>,</span><span> #</span><span>4</span><span>                   ; baseB (matrix B base address)</span>
<span>CONST R5</span><span>,</span><span> #</span><span>8</span><span>                   ; baseC (matrix C base address)</span>

<span>DIV</span><span> R6</span><span>,</span><span> R0</span><span>,</span><span> R2</span><span>                 ; row = i // N</span>
<span>MUL</span><span> R7</span><span>,</span><span> R6</span><span>,</span><span> R2</span>
<span>SUB</span><span> R7</span><span>,</span><span> R0</span><span>,</span><span> R7</span><span>                 ; col = i % N</span>

<span>CONST </span><span>R8</span><span>,</span><span> #</span><span>0</span><span>                   ; acc = 0</span>
<span>CONST </span><span>R9</span><span>,</span><span> #</span><span>0</span><span>                   ; k = 0</span>

<span>LOOP</span><span>:</span>
<span>  </span><span>MUL</span><span> </span><span>R10</span><span>,</span><span> R6</span><span>,</span><span> R2</span>
<span>  </span><span>ADD</span><span> </span><span>R10</span><span>,</span><span> </span><span>R10</span><span>,</span><span> </span><span>R9</span>
<span>  </span><span>ADD</span><span> </span><span>R10</span><span>,</span><span> </span><span>R10</span><span>,</span><span> R3</span><span>             ; addr(A[i]) = row * N + k + baseA</span>
<span>  LDR </span><span>R10</span><span>,</span><span> </span><span>R10</span><span>                 ; load A[i] from global memory</span>

<span>  </span><span>MUL</span><span> </span><span>R11</span><span>,</span><span> </span><span>R9</span><span>,</span><span> R2</span>
<span>  </span><span>ADD</span><span> </span><span>R11</span><span>,</span><span> </span><span>R11</span><span>,</span><span> R7</span>
<span>  </span><span>ADD</span><span> </span><span>R11</span><span>,</span><span> </span><span>R11</span><span>,</span><span> R4</span><span>             ; addr(B[i]) = k * N + col + baseB</span>
<span>  LDR </span><span>R11</span><span>,</span><span> </span><span>R11</span><span>                 ; load B[i] from global memory</span>

<span>  </span><span>MUL</span><span> </span><span>R12</span><span>,</span><span> </span><span>R10</span><span>,</span><span> </span><span>R11</span>
<span>  </span><span>ADD</span><span> </span><span>R8</span><span>,</span><span> </span><span>R8</span><span>,</span><span> </span><span>R12</span><span>              ; acc = acc + A[i] * B[i]</span>

<span>  </span><span>ADD</span><span> </span><span>R9</span><span>,</span><span> </span><span>R9</span><span>,</span><span> R1</span><span>               ; increment k</span>

<span>  </span><span>CMP</span><span> </span><span>R9</span><span>,</span><span> R2</span>
<span>  BRn </span><span>LOOP</span><span>                    ; loop while k &lt; N</span>

<span>ADD</span><span> </span><span>R9</span><span>,</span><span> R5</span><span>,</span><span> R0</span><span>                 ; addr(C[i]) = baseC + i</span>
<span>STR</span><span> </span><span>R9</span><span>,</span><span> </span><span>R8</span><span>                     ; store C[i] in global memory</span>

<span>RET</span><span>                            ; end of kernel</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Simulation</h2><a id="user-content-simulation" aria-label="Permalink: Simulation" href="#simulation"></a></p>
<p dir="auto">tiny-gpu is setup to simulate the execution of both of the above kernels. Before simulating, you'll need to install <a href="https://steveicarus.github.io/iverilog/usage/installation.html" rel="nofollow">iverilog</a> and <a href="https://docs.cocotb.org/en/stable/install.html" rel="nofollow">cocotb</a>.</p>
<p dir="auto">Once you've installed the pre-requisites, you can run the kernel simulations with <code>make test_matadd</code> and <code>make test_matmul</code>.</p>
<p dir="auto">Executing the simulations will output a log file in <code>test/logs</code> with the initial data memory state, complete execution trace of the kernel, and final data memory state.</p>
<p dir="auto">If you look at the initial data memory state logged at the start of the logfile for each, you should see the two start matrices for the calculation, and in the final data memory at the end of the file you should also see the resultant matrix.</p>
<p dir="auto">Below is a sample of the execution traces, showing on each cycle the execution of every thread within every core, including the current instruction, PC, register values, states, etc.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/adam-maj/tiny-gpu/blob/master/docs/images/trace.png"><img src="https://github.com/adam-maj/tiny-gpu/raw/master/docs/images/trace.png" alt="execution trace"></a></p>
<p dir="auto"><strong>For anyone trying to run the simulation or play with this repo, please feel free to DM me on <a href="https://twitter.com/majmudaradam" rel="nofollow">twitter</a> if you run into any issues - I want you to get this running!</strong></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Advanced Functionality</h2><a id="user-content-advanced-functionality" aria-label="Permalink: Advanced Functionality" href="#advanced-functionality"></a></p>
<p dir="auto">For the sake of simplicity, there were many additional features implemented in modern GPUs that heavily improve performance &amp; functionality that tiny-gpu omits. We'll discuss some of those most critical features in this section.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Multi-layered Cache &amp; Shared Memory</h3><a id="user-content-multi-layered-cache--shared-memory" aria-label="Permalink: Multi-layered Cache &amp; Shared Memory" href="#multi-layered-cache--shared-memory"></a></p>
<p dir="auto">In modern GPUs, multiple different levels of caches are used to minimize the amount of data that needs to get accessed from global memory. tiny-gpu implements only one cache layer between individual compute units requesting memory and the memory controllers which stores recent cached data.</p>
<p dir="auto">Implementing multi-layered caches allows frequently accessed data to be cached more locally to where it's being used (with some caches within individual compute cores), minimizing load times for this data.</p>
<p dir="auto">Different caching algorithms are used to maximize cache-hits - this is a critical dimension that can be improved on to optimize memory access.</p>
<p dir="auto">Additionally, GPUs often use <strong>shared memory</strong> for threads within the same block to access a single memory space that can be used to share results with other threads.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Memory Coalescing</h3><a id="user-content-memory-coalescing" aria-label="Permalink: Memory Coalescing" href="#memory-coalescing"></a></p>
<p dir="auto">Another critical memory optimization used by GPUs is <strong>memory coalescing.</strong> Multiple threads running in parallel often need to access sequential addresses in memory (for example, a group of threads accessing neighboring elements in a matrix) - but each of these memory requests is put in separately.</p>
<p dir="auto">Memory coalescing is used to analyzing queued memory requests and combine neighboring requests into a single transaction, minimizing time spent on addressing, and making all the requests together.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Pipelining</h3><a id="user-content-pipelining" aria-label="Permalink: Pipelining" href="#pipelining"></a></p>
<p dir="auto">In the control flow for tiny-gpu, cores wait for one instruction to be executed on a group of threads before starting execution of the next instruction.</p>
<p dir="auto">Modern GPUs use <strong>pipelining</strong> to stream execution of multiple sequential instructions at once while ensuring that instructions with dependencies on each other still get executed sequentially.</p>
<p dir="auto">This helps to maximize resource utilization within cores as resources are not sitting idle while waiting (ex: during async memory requests).</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Warp Scheduling</h3><a id="user-content-warp-scheduling" aria-label="Permalink: Warp Scheduling" href="#warp-scheduling"></a></p>
<p dir="auto">Another strategy used to maximize resource utilization on course is <strong>warp scheduling.</strong> This approach involves breaking up blocks into individual batches of theads that can be executed together.</p>
<p dir="auto">Multiple warps can be executed on a single core simultaneously by executing instructions from one warp while another warp is waiting. This is similar to pipelining, but dealing with instructions from different threads.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Branch Divergence</h3><a id="user-content-branch-divergence" aria-label="Permalink: Branch Divergence" href="#branch-divergence"></a></p>
<p dir="auto">tiny-gpu assumes that all threads in a single batch end up on the same PC after each instruction, meaning that threads can be executed in parallel for their entire lifetime.</p>
<p dir="auto">In reality, individual threads could diverge from each other and branch to different lines based on their data. With different PCs, these threads would need to split into separate lines of execution, which requires managing diverging threads &amp; paying attention to when threads converge again.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Synchronization &amp; Barriers</h3><a id="user-content-synchronization--barriers" aria-label="Permalink: Synchronization &amp; Barriers" href="#synchronization--barriers"></a></p>
<p dir="auto">Another core functionality of modern GPUs is the ability to set <strong>barriers</strong> so that groups of threads in a block can synchronize and wait until all other threads in the same block have gotten to a certain point before continuing execution.</p>
<p dir="auto">This is useful for cases where threads need to exchange shared data with each other so they can ensure that the data has been fully processed.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Next Steps</h2><a id="user-content-next-steps" aria-label="Permalink: Next Steps" href="#next-steps"></a></p>
<p dir="auto">Updates I want to make in the future to improve the design, anyone else is welcome to contribute as well:</p>
<ul>
<li> Add a simple cache for instructions</li>
<li> Build an adapter to use GPU with Tiny Tapeout 7</li>
<li> Add basic branch divergence</li>
<li> Add basic memory coalescing</li>
<li> Add basic pipelining</li>
<li> Optimize control flow and use of registers to improve cycle time</li>
<li> Write a basic graphics kernel or add simple graphics hardware to demonstrate graphics functionality</li>
</ul>
<p dir="auto"><strong>For anyone curious to play around or make a contribution, feel free to put up a PR with any improvements you'd like to add 😄</strong></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HTML Attributes vs. DOM Properties (321 pts)]]></title>
            <link>https://jakearchibald.com/2024/attributes-vs-properties/</link>
            <guid>40152682</guid>
            <pubDate>Thu, 25 Apr 2024 02:34:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jakearchibald.com/2024/attributes-vs-properties/">https://jakearchibald.com/2024/attributes-vs-properties/</a>, See on <a href="https://news.ycombinator.com/item?id=40152682">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Attributes and properties are <em>fundamentally</em> different things. You can have an attribute and property of the same name set to different values. For example:</p>
<div><pre><code><span><span><span>&lt;</span>div</span> <span>foo</span><span><span>=</span><span>"</span>bar<span>"</span></span><span>&gt;</span></span>…<span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
  <span>const</span> div <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'div[foo=bar]'</span><span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttribute</span><span>(</span><span>'foo'</span><span>)</span><span>)</span><span>;</span> <span>// 'bar'</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span>foo<span>)</span><span>;</span> <span>// undefined</span>

  div<span>.</span>foo <span>=</span> <span>'hello world'</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttribute</span><span>(</span><span>'foo'</span><span>)</span><span>)</span><span>;</span> <span>// 'bar'</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span>foo<span>)</span><span>;</span> <span>// 'hello world'</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre></div><p>It seems like fewer and fewer developers know this, partially thanks to frameworks:</p>
<div><pre><code><span><span><span>&lt;</span>input</span> <span>className</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>aria-label</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>value</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>/&gt;</span></span></code></pre></div><p>If you do the above in a framework's templating language, you're using attribute-like syntax, but under the hood it'll sometimes be setting the property instead, and when it does that differs from framework to framework. In some cases, it'll set a property <em>and</em> an attribute as a side-effect, but that isn't the framework's fault.</p>
<p>Most of the time, these distinctions don't matter. I think it's good that developers can have a long and happy career without caring about the differences between properties and attributes. But, if you need to dig down into the DOM at a lower level, it helps to know. Even if you feel you know the difference, maybe I'll touch on a couple of details you hadn't considered. So let's dig in…</p>
<h2 id="the-key-differences"><a href="#the-key-differences">The key differences</a></h2>
<p>Before we get to the interesting stuff, let's get some of the technical differences out of the way:</p>
<h3 id="html-serialisation"><a href="#html-serialisation">HTML serialisation</a></h3>
<p>Attributes serialise to HTML, whereas properties don't:</p>
<div><pre><code><span>const</span> div <span>=</span> document<span>.</span><span>createElement</span><span>(</span><span>'div'</span><span>)</span><span>;</span>

div<span>.</span><span>setAttribute</span><span>(</span><span>'foo'</span><span>,</span> <span>'bar'</span><span>)</span><span>;</span>
div<span>.</span>hello <span>=</span> <span>'world'</span><span>;</span>

console<span>.</span><span>log</span><span>(</span>div<span>.</span>outerHTML<span>)</span><span>;</span> <span>// '&lt;div foo="bar"&gt;&lt;/div&gt;'</span></code></pre></div><p>So when you're looking at the elements panel in browser developer tools, you're only seeing attributes on elements, not properties.</p>
<h3 id="value-types"><a href="#value-types">Value types</a></h3>
<p>In order to work in the serialised format, attribute values are always strings, whereas properties can be any type:</p>
<div><pre><code><span>const</span> div <span>=</span> document<span>.</span><span>createElement</span><span>(</span><span>'div'</span><span>)</span><span>;</span>
<span>const</span> obj <span>=</span> <span>{</span> <span>foo</span><span>:</span> <span>'bar'</span> <span>}</span><span>;</span>

div<span>.</span><span>setAttribute</span><span>(</span><span>'foo'</span><span>,</span> obj<span>)</span><span>;</span>
console<span>.</span><span>log</span><span>(</span><span>typeof</span> div<span>.</span><span>getAttribute</span><span>(</span><span>'foo'</span><span>)</span><span>)</span><span>;</span> <span>// 'string'</span>
console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttribute</span><span>(</span><span>'foo'</span><span>)</span><span>)</span><span>;</span> <span>// '[object Object]'</span>

div<span>.</span>hello <span>=</span> obj<span>;</span>
console<span>.</span><span>log</span><span>(</span><span>typeof</span> div<span>.</span>hello<span>)</span><span>;</span> <span>// 'object'</span>
console<span>.</span><span>log</span><span>(</span>div<span>.</span>hello<span>)</span><span>;</span> <span>// { foo: 'bar' }</span></code></pre></div><h3 id="case-sensitivity"><a href="#case-sensitivity">Case sensitivity</a></h3>
<p>Attribute names are case-insensitive, whereas property names are case-sensitive.</p>
<div><pre><code><span><span><span>&lt;</span>div</span> <span>id</span><span><span>=</span><span>"</span>test<span>"</span></span> <span>HeLlO</span><span><span>=</span><span>"</span>world<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
  <span>const</span> div <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'#test'</span><span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttributeNames</span><span>(</span><span>)</span><span>)</span><span>;</span> <span>// ['id', 'hello']</span>

  div<span>.</span><span>setAttribute</span><span>(</span><span>'FOO'</span><span>,</span> <span>'bar'</span><span>)</span><span>;</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttributeNames</span><span>(</span><span>)</span><span>)</span><span>;</span> <span>// ['id', 'hello', 'foo']</span>

  div<span>.</span>TeSt <span>=</span> <span>'value'</span><span>;</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span>TeSt<span>)</span><span>;</span> <span>// 'value'</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span>test<span>)</span><span>;</span> <span>// undefined</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre></div><p>However, attribute <em>values</em> are case-sensitive.</p>
<p>Ok, here's where things start to get blurry:</p>
<h2 id="reflection"><a href="#reflection">Reflection</a></h2>
<p>Take a look at this:</p>
<div><pre><code><span><span><span>&lt;</span>div</span> <span>id</span><span><span>=</span><span>"</span>foo<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
  <span>const</span> div <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'#foo'</span><span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttribute</span><span>(</span><span>'id'</span><span>)</span><span>)</span><span>;</span> <span>// 'foo'</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span>id<span>)</span><span>;</span> <span>// 'foo'</span>

  div<span>.</span>id <span>=</span> <span>'bar'</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttribute</span><span>(</span><span>'id'</span><span>)</span><span>)</span><span>;</span> <span>// 'bar'</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span>id<span>)</span><span>;</span> <span>// 'bar'</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre></div><p>This seems to contradict the first example in the post, but the above only works because <code>Element</code> has an <code>id</code> getter &amp; setter that 'reflects' the <code>id</code> attribute.</p>
<p>When a property reflects an attribute, the <em>attribute</em> is the source of the data. When you set the property, it's updating the attribute. When you read from the property, it's reading the attribute.</p>
<p>For convenience, most specs will create a property equivalent for every defined attribute. It didn't work in the example at the start of the article, because <code>foo</code> isn't a spec-defined attribute, so there isn't a spec-defined <code>foo</code> property that reflects it.</p>
<p><a href="https://html.spec.whatwg.org/multipage/grouping-content.html#the-ol-element">Here's the spec for <code>&lt;ol&gt;</code></a>. The "Content attributes" section defines the attributes, and the "DOM interface" defines the properties. If you click on <code>reversed</code> in the DOM interface, it takes you to this:</p>
<blockquote>

<p>The <code>reversed</code> and <code>type</code> IDL attributes must <a href="https://html.spec.whatwg.org/multipage/common-dom-interfaces.html#reflect">reflect</a> the respective content attributes of the same name.</p>
</blockquote>

<p>But not all of these reflectors are as simple as these.</p>
<h3 id="naming-differences"><a href="#naming-differences">Naming differences</a></h3>
<p>Ok, this is relatively minor, but sometimes the property has a different name to the attribute it reflects.</p>
<p>In some cases it's just to add the kind of casing you'd expect from a property:</p>
<ul>
<li>On <code>&lt;img&gt;</code>, <code>el.crossOrigin</code> reflects the <code>crossorigin</code> attribute.</li>
<li>On all elements, <code>el.ariaLabel</code> reflects the <code>aria-label</code> attribute (the aria reflectors became cross browser in late 2023. Before that you could only use the attributes).</li>
</ul>
<p>In some cases, names had to be changed due to old JavaScript reserved words:</p>
<ul>
<li>On all elements, <code>el.className</code> reflects the <code>class</code> attribute.</li>
<li>On <code>&lt;label&gt;</code>, <code>el.htmlFor</code> reflects the <code>for</code> attribute.</li>
</ul>
<h3 id="validation-type-coercion-and-defaults"><a href="#validation-type-coercion-and-defaults">Validation, type coercion, and defaults</a></h3>
<p>Properties come with validation and defaults, whereas attribute don't:</p>
<div><pre><code><span>const</span> input <span>=</span> document<span>.</span><span>createElement</span><span>(</span><span>'input'</span><span>)</span><span>;</span>

console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'type'</span><span>)</span><span>)</span><span>;</span> <span>// null</span>
console<span>.</span><span>log</span><span>(</span>input<span>.</span>type<span>)</span><span>;</span> <span>// 'text'</span>

input<span>.</span>type <span>=</span> <span>'number'</span><span>;</span>

console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'type'</span><span>)</span><span>)</span><span>;</span> <span>// 'number'</span>
console<span>.</span><span>log</span><span>(</span>input<span>.</span>type<span>)</span><span>;</span> <span>// 'number'</span>

input<span>.</span>type <span>=</span> <span>'foo'</span><span>;</span>

console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'type'</span><span>)</span><span>)</span><span>;</span> <span>// 'foo'</span>
console<span>.</span><span>log</span><span>(</span>input<span>.</span>type<span>)</span><span>;</span> <span>// 'text'</span></code></pre></div><p>In this case, the validation is handled by the <code>type</code> getter. The setter allowed the invalid value <code>'foo'</code>, but when the getter saw the invalid value, or no value, it returned <code>'text'</code>.</p>
<p>Some properties perform type coercion:</p>
<div><pre><code><span><span><span>&lt;</span>details</span> <span>open</span><span>&gt;</span></span>…<span><span><span>&lt;/</span>details</span><span>&gt;</span></span>
<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
  <span>const</span> details <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'details'</span><span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>details<span>.</span><span>getAttribute</span><span>(</span><span>'open'</span><span>)</span><span>)</span><span>;</span> <span>// ''</span>
  console<span>.</span><span>log</span><span>(</span>details<span>.</span>open<span>)</span><span>;</span> <span>// true</span>

  details<span>.</span>open <span>=</span> <span>false</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>details<span>.</span><span>getAttribute</span><span>(</span><span>'open'</span><span>)</span><span>)</span><span>;</span> <span>// null</span>
  console<span>.</span><span>log</span><span>(</span>details<span>.</span>open<span>)</span><span>;</span> <span>// false</span>

  details<span>.</span>open <span>=</span> <span>'hello'</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>details<span>.</span><span>getAttribute</span><span>(</span><span>'open'</span><span>)</span><span>)</span><span>;</span> <span>// ''</span>
  console<span>.</span><span>log</span><span>(</span>details<span>.</span>open<span>)</span><span>;</span> <span>// true</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre></div><p>In this case, the <code>open</code> property is a boolean, returning whether the attribute exists. The setter also coerces the type - even though the setter is given <code>'hello'</code>, it's turned to a boolean rather than going directly to the attribute.</p>
<p>Properties like <code>img.height</code> coerce the attribute value to a number. The setter converts the incoming value to a number, and treats negative values as 0.</p>
<h3 id="value-on-input-fields"><a href="#value-on-input-fields"><code>value</code> on input fields</a></h3>
<p><code>value</code> is a fun one. There's a <code>value</code> property and a <code>value</code> attribute. However, the <code>value</code> property does not reflect the <code>value</code> attribute. Instead, the <code>defaultValue</code> property reflects the <code>value</code> attribute.</p>
<p>I know, I know.</p>
<p>In fact, the <code>value</code> property doesn't reflect <em>any</em> attribute. That isn't unusual, there's loads of these (<code>offsetWidth</code>, <code>parentNode</code>, <code>indeterminate</code> on checkboxes for some reason, and many more).</p>
<p>Initially, the <code>value</code> property defers to the <code>defaultValue</code> property. Then, once the <code>value</code> property is set, either via JavaScript or through user interaction, it switches to an internal value. It's as if it's implemented <em>roughly</em> like this:</p>
<div><pre><code><span>class</span> <span>HTMLInputElement</span> <span>extends</span> <span>HTMLElement</span> <span>{</span>
  <span>get</span> <span>defaultValue</span><span>(</span><span>)</span> <span>{</span>
    <span>return</span> <span>this</span><span>.</span><span>getAttribute</span><span>(</span><span>'value'</span><span>)</span> <span>??</span> <span>''</span><span>;</span>
  <span>}</span>

  <span>set</span> <span>defaultValue</span><span>(</span><span>newValue</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span><span>setAttribute</span><span>(</span><span>'value'</span><span>,</span> <span>String</span><span>(</span>newValue<span>)</span><span>)</span><span>;</span>
  <span>}</span>

  #value <span>=</span> <span>undefined</span><span>;</span>

  <span>get</span> <span>value</span><span>(</span><span>)</span> <span>{</span>
    <span>return</span> <span>this</span><span>.</span>#value <span>??</span> <span>this</span><span>.</span>defaultValue<span>;</span>
  <span>}</span>

  <span>set</span> <span>value</span><span>(</span><span>newValue</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span>#value <span>=</span> <span>String</span><span>(</span>newValue<span>)</span><span>;</span>
  <span>}</span>

  <span>// This happens when the associated form resets</span>
  <span>formResetCallback</span><span>(</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span>#value <span>=</span> <span>undefined</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre></div><p>So:</p>
<div><pre><code><span><span><span>&lt;</span>input</span> <span>type</span><span><span>=</span><span>"</span>text<span>"</span></span> <span>value</span><span><span>=</span><span>"</span>default<span>"</span></span> <span>/&gt;</span></span>
<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
  <span>const</span> input <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'input'</span><span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'value'</span><span>)</span><span>)</span><span>;</span> <span>// 'default'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>value<span>)</span><span>;</span> <span>// 'default'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>defaultValue<span>)</span><span>;</span> <span>// 'default'</span>

  input<span>.</span>defaultValue <span>=</span> <span>'new default'</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'value'</span><span>)</span><span>)</span><span>;</span> <span>// 'new default'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>value<span>)</span><span>;</span> <span>// 'new default'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>defaultValue<span>)</span><span>;</span> <span>// 'new default'</span>

  <span>// Here comes the mode switch:</span>
  input<span>.</span>value <span>=</span> <span>'hello!'</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'value'</span><span>)</span><span>)</span><span>;</span> <span>// 'new default'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>value<span>)</span><span>;</span> <span>// 'hello!'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>defaultValue<span>)</span><span>;</span> <span>// 'new default'</span>

  input<span>.</span><span>setAttribute</span><span>(</span><span>'value'</span><span>,</span> <span>'another new default'</span><span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'value'</span><span>)</span><span>)</span><span>;</span> <span>// 'another new default'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>value<span>)</span><span>;</span> <span>// 'hello!'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>defaultValue<span>)</span><span>;</span> <span>// 'another new default'</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre></div><p>This would have made way more sense if the <code>value</code> attribute was named <code>defaultvalue</code>. Too late now.</p>
<h2 id="attributes-should-be-for-configuration"><a href="#attributes-should-be-for-configuration">Attributes should be for configuration</a></h2>
<p>In my opinion, attributes should be for configuration, whereas properties can contain state. I also believe that the light-DOM tree should have a single owner.</p>
<p>In that sense, I think <code>&lt;input value&gt;</code> gets it right (aside from the naming). The <code>value</code> attribute configures the default value, whereas the <code>value</code> property gives you the current state.</p>
<p>It also makes sense that validation applies when getting/setting properties, but never when getting/setting attributes.</p>
<p>I say 'in my opinion', because a couple of recent HTML elements have done it differently.</p>
<p>The <code>&lt;details&gt;</code> and <code>&lt;dialog&gt;</code> elements represent their open state via the <code>open</code> attribute, and the browser will self add/remove this attribute in response to user interaction.</p>
<p>I think this was a design mistake. It breaks the idea that attributes are for configuration, but more importantly it means that the system in charge of maintaining the DOM (a framework, or vanilla JS) needs to be prepared for the DOM to change itself.</p>
<p>I think it should have been:</p>
<div><pre><code><span><span><span>&lt;</span>details</span> <span>defaultopen</span><span>&gt;</span></span>…<span><span><span>&lt;/</span>details</span><span>&gt;</span></span></code></pre></div><p>And a <code>details.open</code> property to get/set the current state, along with a CSS pseudo-class for targeting that state.</p>
<p>I guess <code>contenteditable</code> also breaks that contract, but… well… it's a opt-in to a lot of breakage.</p>
<h2 id="how-frameworks-handle-the-difference"><a href="#how-frameworks-handle-the-difference">How frameworks handle the difference</a></h2>
<p>Back to the example from earlier:</p>
<div><pre><code><span><span><span>&lt;</span>input</span> <span>className</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>aria-label</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>value</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>/&gt;</span></span></code></pre></div><p>How do frameworks handle this?</p>
<h3 id="preact-and-vuejs"><a href="#preact-and-vuejs">Preact and VueJS</a></h3>
<p>Aside from a predefined set of cases where they favour attributes, they'll set the prop as a property if <code>propName in element</code>, otherwise they'll set an attribute. Basically, they prefer properties over attributes. Their render-to-string methods do the opposite, and ignore things that are property-only.</p>
<ul>
<li><a href="https://github.com/preactjs/preact/blob/aa95aa924dd5fe28798f2712acdabdc2e9fa38c9/src/diff/props.js#L37"><code>setProperty</code> in Preact</a>.</li>
<li><a href="https://github.com/vuejs/core/blob/958286e3f050dc707ad1af293e91bfb190bdb191/packages/runtime-dom/src/patchProp.ts#L69"><code>shouldSetAsProp</code> in VueJS</a>.</li>
</ul>
<h3 id="react"><a href="#react">React</a></h3>
<p>React does things the other way around. Aside from a predefined set of cases where they favour properties, they'll set an attribute. This makes their render-to-string method similar in logic.</p>
<p>This explains why custom elements don't seem to work in React. Since they're custom, their properties aren't in React's 'predefined list', so they're set as attributes instead. Anything that's property-only on the custom element simply won't work. This will be fixed in React 19, where they'll switch to the Preact/VueJS model for custom elements.</p>
<p>The funny thing is, React popularised using <code>className</code> instead of <code>class</code> in what <em>looks like</em> an attribute. But, even though you're using the property name rather than the attribute name, <a href="https://github.com/facebook/react/blob/699d03ce1a175442fe3443e1d1bed14f14e9c197/packages/react-dom-bindings/src/client/ReactDOMComponent.js#L388-L389">React will set the <code>class</code> attribute under the hood</a>.</p>
<ul>
<li><a href="https://github.com/facebook/react/blob/699d03ce1a175442fe3443e1d1bed14f14e9c197/packages/react-dom-bindings/src/client/ReactDOMComponent.js#L349"><code>setProp</code> in React</a>.</li>
</ul>
<h3 id="lit-html"><a href="#lit-html">lit-html</a></h3>
<p>Lit does things a little differently:</p>
<div><pre><code><span><span><span>&lt;</span>input</span> <span>type</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>.value</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>/&gt;</span></span></code></pre></div><p>It keeps the distinction between attributes and properties, requiring you to prefix the name with <code>.</code> if you want to set the property rather than the attribute.</p>
<ul>
<li><a href="https://lit.dev/docs/templates/expressions/">Lit's expression docs</a>.</li>
</ul>
<h2 id="and-thats-yer-lot"><a href="#and-thats-yer-lot">And that's yer lot</a></h2>
<p>That's pretty much everything I know about the difference between properties and attributes. If there's something I've missed, or you have a question, let me know in the comments below!</p>
<p>Thanks to my <a href="https://offthemainthread.tech/">podcast husband</a> <a href="https://surma.dev/">Surma</a> for his usual reviewing skills.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fine tune LLAMA3 on million scale dataset in consumer GPU using QLora, DeepSpeed (133 pts)]]></title>
            <link>https://medium.com/@sumandas0/fine-tune-llama3-on-million-scale-dataset-in-consumer-gpu-using-qlora-deepspeed-3ae8ad75299a</link>
            <guid>40152486</guid>
            <pubDate>Thu, 25 Apr 2024 02:03:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medium.com/@sumandas0/fine-tune-llama3-on-million-scale-dataset-in-consumer-gpu-using-qlora-deepspeed-3ae8ad75299a">https://medium.com/@sumandas0/fine-tune-llama3-on-million-scale-dataset-in-consumer-gpu-using-qlora-deepspeed-3ae8ad75299a</a>, See on <a href="https://news.ycombinator.com/item?id=40152486">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a rel="noopener follow" href="https://medium.com/@sumandas0?source=post_page-----3ae8ad75299a--------------------------------"><div aria-hidden="false"><p><img alt="Suman" src="https://miro.medium.com/v2/resize:fill:88:88/1*cPgbuLwwvCkde8ztQQcNFA.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div><h2 id="6688">Highlights,</h2><p id="9884"><strong>Model</strong> : LLAMA-8b-instruct</p><p id="e592"><strong>Dataset</strong>: Openhermes-2.5(700k training, 300k testing)</p><p id="7df9"><strong>GPU</strong>: 4 RTX 4090, 24GB</p><h2 id="88aa">Bit of background about me,</h2><p id="cd1d">I’m a full-time software engineer 2, at the core of our platform team. In my scarce free time, I explore various aspects of the machine learning world, with interests in tabular data, NLP, and sound. Whatever I’m sharing here are scraps from all over the internet consolidated into one place. I have decent experience in training small NLP models and have submitted a solution in a Kaggle competition using DeBERTa v3, scoring enough to be in the top 50%, but I have never tried working with large language models. This is my first time, so please let me know if there are any oversights. Yes, this is my first blog post. Writing this will definitely help me, and hopefully, it will be useful for any readers as well</p><h2 id="023a">LLama</h2><p id="7eff">Who don’t know about this long necked creature revolutionizing the AI field from its birth. Joke apart release of llama where the whole OSS powered LLM kicked of the revolution which don’t seems like stopping in near future.</p><p id="b306">To learn more on llama in depth and technical do checkout this <a href="https://www.linkedin.com/posts/ujamil_llama-explained-kv-cache-rotary-positional-activity-7100620274642866176-XaKO/" rel="noopener ugc nofollow" target="_blank">Post | LinkedIn</a> , this is one of the most technically simplified explanation I can found all over the internet. Few things they implemented in their architecture like Grouped Multi Query Attention, KV-Cache, Rotary Positional Embeddings(RoPE) which are very cool. These are not in scope of this article. They continued releasing their versions of LLama with latest version came few days ago. And this time with massive data compacted into few GBs of parameters.</p><figure><figcaption><a href="https://www.forbes.com/sites/janakirammsv/2024/04/19/meta-unveils-llama-310-key-facts-about-the-advanced-llm/" rel="noopener ugc nofollow" target="_blank">Meta Unveils Llama 3–10 Key Facts About The Advanced LLM (forbes.com)</a></figcaption></figure><h2 id="226e">Deepspeed</h2><blockquote><p id="0a5f"><em>DeepSpeed is a deep learning optimization library that makes distributed training and inference easy, efficient, and effective.</em></p><p id="eddb"><a href="https://github.com/microsoft/DeepSpeed" rel="noopener ugc nofollow" target="_blank"><em>https://github.com/microsoft/DeepSpeed</em></a></p></blockquote><p id="dee0">I will be training this model using four RTX 4090 GPUs that I’ve rented from <a href="http://vast.ai/" rel="noopener ugc nofollow" target="_blank">vast.ai</a>, so we need to take some steps to train the models across multiple GPUs. Training on multiple GPUs is a complex task compared to training on a single GPU. Why? When we train on a single GPU, the Optimizer state, parameters and gradients reside in a single system, which helps iterating over models on one GPU.</p><p id="c422">Now, if we add another GPU, there are two systems that will train the models, each with its own state(Optimizer state, parameters and gradients). After one epoch or several steps, we would like to obtain a single result. Now imagine two systems training two batches of data in parallel; they need to communicate about their state and converge the results with minimal data loss. There are multiple ways to utilize multiple GPUs: we can replicate parameters, gradients, and optimizer state across all GPUs, or we could shard only the optimizer state, or the optimizer state and gradients. DeepSpeed helps in distributing the load over the GPUs without any issues. And accelerate package from Huggingface lets us do this like its piece of cake.</p><p id="91cc">I will use stage 3 which will shard all parameters, gradients and optimizer state which will let us training over less memory requirement,</p><figure></figure><p id="2411">More details in their blog, <a href="https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/" rel="noopener ugc nofollow" target="_blank">ZeRO &amp; DeepSpeed: New system optimizations enable training models with over 100 billion parameters — Microsoft Research</a></p><h2 id="9ade">QLoRA</h2><p id="ebf1">Until I write something about QLoRA, please take a look into this blog to get more technical context <a href="https://wandb.ai/sauravmaheshkar/QLoRA/reports/What-is-QLoRA---Vmlldzo2MTI2OTc5" rel="noopener ugc nofollow" target="_blank">What is QLoRA? | QLoRA — Weights &amp; Biases (wandb.ai)</a>, basically 70B/8B models are very large in size means when you fine tune it you will not be able to fully fine tune with any GPU in normal people’s budget, so we tried to fine tune it with very low resource and came LoRA which helped us just training over parameters with low rank and merging them with original weights, then came QLoRA which helped even more reducing memory consumption by quantizing the pre trained LLM to 4 bit precision, quantizing is a topic in itself so not going beyond this.</p><p id="51ad">Also take a look into this article <a href="https://www.entrypointai.com/blog/lora-fine-tuning/" rel="noopener ugc nofollow" target="_blank">LoRA Fine-tuning &amp; Hyperparameters Explained (in Plain English) | Entry Point AI</a></p><h2 id="50cb">Lets start finetuning LLamA 3</h2><p id="a905">We will be finetuning the llama3 instruct model <a href="https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct" rel="noopener ugc nofollow" target="_blank">meta-llama/Meta-Llama-3–8B-Instruct · Hugging Face</a> over <a href="https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B" rel="noopener ugc nofollow" target="_blank">openhermes</a> dataset provided by teknium.</p><h2 id="0e59">Data preparation</h2><p id="a219">Meta has their own chat format so tried to follow the format they provided and read their encoding algorithm in their llama3 repository,</p><p id="b4df"><strong>Load the dataset</strong></p><pre><span id="0492">from datasets import load_dataset<p>dataset = load_dataset("teknium/OpenHermes-2.5")</p></span></pre><p id="3943"><strong>The encoding utility I took inspiration from</strong><a href="https://github.com/meta-llama/llama3/blob/af6eedf7042fb51d00b2b26d8ef1ceaab73e1670/llama/tokenizer.py#L202" rel="noopener ugc nofollow" target="_blank"><strong> llama3 repo</strong></a><strong>,</strong></p><pre><span id="2427">def _return_header(message)-&gt; str:<br>    role = message["from"]<br>    header = ""<br>    if role == "system":<br>        header = "system"<br>    elif role == "gpt":<br>        header = "assistant"<br>    elif role == "human":<br>        header = "user"<br>    return header<p>def encode_header(message):<br>    text = ''<br>    text = text + "&lt;|start_header_id|&gt;"<br>    header = _return_header(message)<br>    text = text + header<br>    text = text + "&lt;|end_header_id|&gt;"<br>    text = text + "\n\n"<br>    return text</p><p>def encode_message(message)-&gt;str:<br>    text = encode_header(message)<br>    text = text + message["value"].strip()<br>    text = text + "&lt;|eot_id|&gt;"<br>    return text</p><p>def encode_dialog_prompt(dialog):<br>    text = ''<br>    text = text + "&lt;|begin_of_text|&gt;"<br>    for message in dialog:<br>        text = text + encode_message(message)<br>    return text</p></span></pre><pre><span id="c697">ds = dataset.map(lambda x: {"content":encode_dialog_prompt(x['conversations'])}, num_proc=10)</span></pre><p id="6128">Remove redundunt columns and split it into train and validation</p><pre><span id="6147">ds = ds.remove_columns(['custom_instruction', 'topic', 'model_name', 'model', 'skip_prompt_formatting', 'category', 'conversations', 'views', 'language', 'id', 'title', 'idx', 'hash', 'avatarUrl', 'system_prompt', 'source'])<br>train_test_split = ds["train"].train_test_split(test_size=0.3)</span></pre><p id="e8fc"><strong>And push it to hub,</strong></p><pre><span id="c29e">train_test_split.push_to_hub("sumandas/openhermes-2.5-llama3")</span></pre><p id="6614">The resultant dataset, <a href="https://huggingface.co/datasets/sumandas/openhermes-2.5-llama3" rel="noopener ugc nofollow" target="_blank">sumandas/openhermes-2.5-llama3 · Datasets at Hugging Face</a>, example text</p><pre><span id="3556">&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt; You are an AI assistant. Provide a detailed answer so user don’t need to search outside to understand the answer.&lt;|eot_id|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt; Instructions: Given a sentence, generate what should be the most likely next statement. The next statement should be reasonable and logically correct. Input: The screen is full of white bubbles and words, while a pair of hands plays the piano. The bubbles and words disappear and it Output:&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt; Output: becomes apparent that the hands are creating a visual representation of the music being played, captivating the audience with this unique sensory experience.&lt;|eot_id|&gt;</span></pre><h2 id="1ba2">Now its time for training LLama3</h2><p id="cab1">All of the resources were already available in internet I just fine tuned those for my setup and requirements,</p><p id="ebdc"><strong>Prerequisites,</strong></p><ol><li id="0bf2">Install cuda dev kit <code>conda install cuda</code> or follow <a href="https://developer.nvidia.com/cuda-downloads?target_os=Linux" rel="noopener ugc nofollow" target="_blank">developer.nvidia.com/cuda-downloads?target_os=Linux</a></li><li id="0a0a">Install deepspeed</li><li id="cd39">Install flash-attention <em>pip install flash-attn — no-build-isolation</em></li><li id="6a5a">Install these libraries, I use <a href="https://github.com/astral-sh/uv" rel="noopener ugc nofollow" target="_blank">uv</a> for faster dependency resolution,</li></ol><pre><span id="2bb2">git+https://github.com/huggingface/transformers<br>git+https://github.com/huggingface/accelerate<br>git+https://github.com/huggingface/peft<br>git+https://github.com/huggingface/trl<br>huggingface-hub<br>bitsandbytes<br>evaluate<br>datasets<br>einops<br>wandb<br>tiktoken<br>xformers<br>sentencepiece<br>deepspeed<br>torch==2.2.2</span></pre><p id="ebd9"><strong>Training code</strong></p><p id="d43d">This is Swiss knife training code where you can train in multiple mode as per you convenience, found this in this repo <a href="https://github.com/pacman100/LLM-Workshop" rel="noopener ugc nofollow" target="_blank">pacman100/LLM-Workshop: LLM Workshop by Sourab Mangrulkar (github.com)</a>,</p><blockquote><p id="93e4">The <code>training.py</code> file is the one we will launch using accelerate with proper configs, just putting the training.py gist here, <a href="https://gist.github.com/sumandas0/0483db8514ea43e45cc5e5f5525914ab" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/sumandas0/0483db8514ea43e45cc5e5f5525914ab</a></p></blockquote><p id="831b">This training code uses SFTTrainer from huggingface, more details <a href="https://huggingface.co/docs/trl/en/sft_trainer" rel="noopener ugc nofollow" target="_blank">Supervised Fine-tuning Trainer (huggingface.co)</a></p><p id="7822">You can do multiple thing with this, you can train with loftq, unsloth, FFT, normal lora but I will just use QloRa with Deepspeed ZerO stage 3.</p><p id="cc17"><strong>First lets define the accelerate config for using deepspeed</strong></p><figure></figure><blockquote><p id="2bfa">Note, If you increase the number of GPU update number in <em>num_processes</em></p></blockquote><p id="56e5">Now lets just run the accelerate command to start training,</p><pre><span id="7326">accelerate launch --config_file "deepspeed_config.yaml"  train.py \<br>--seed 100 \<br>--model_name_or_path "meta-llama/Meta-Llama-3-8B-Instruct" \<br>--dataset_name "sumandas/openhermes-2.5-llama3" \<br>--chat_template_format "none" \<br>--add_special_tokens False \<br>--append_concat_token False \<br>--splits "train,test" \<br>--max_seq_len 2048 \<br>--num_train_epochs 1 \<br>--logging_steps 5 \<br>--log_level "info" \<br>--logging_strategy "steps" \<br>--evaluation_strategy "epoch" \<br>--save_strategy "steps" \<br>--push_to_hub \<br>--hub_private_repo True \<br>--report_to "wandb" \<br>--hub_strategy "every_save" \<br>--bf16 True \<br>--packing True \<br>--learning_rate 1e-4 \<br>--lr_scheduler_type "cosine" \<br>--weight_decay 1e-4 \<br>--warmup_ratio 0.0 \<br>--max_grad_norm 1.0 \<br>--output_dir "llama3-openhermes-2.5" \<br>--per_device_train_batch_size 4\<br>--per_device_eval_batch_size 4\<br>--gradient_accumulation_steps 2 \<br>--gradient_checkpointing True \<br>--use_reentrant True \<br>--dataset_text_field "content" \<br>--use_flash_attn True \<br>--use_peft_lora True \<br>--lora_r 8 \<br>--lora_alpha 16 \<br>--lora_dropout 0.1 \<br>--lora_target_modules "all-linear" \<br>--use_4bit_quantization True \<br>--use_nested_quant True \<br>--bnb_4bit_compute_dtype "bfloat16" \<br>--bnb_4bit_quant_storage_dtype "bfloat16"</span></pre><p id="85c8"><strong>Notes,</strong></p><ol><li id="7f33">Set env variable HF_HUB_ENABLE_HF_TRANSFER=1 first</li><li id="10d8">output_dir will also be the repo created in huggingface where all the checkpoints will be stored, checkpoints will be created every 500 steps by default</li><li id="e8df">I set chat template format as <code>none</code> , because I already formatted those in my way, if you have other format do use for e.g chatml, zephyr</li><li id="9507"><code>lora_target_modules</code> is set as all-linear which is QLoRa specific where they published paper to show fine tuning all linear layers gives us comparable result to full fine tune.</li><li id="7c14">For setting up hyperparameters for LoRa, take a look into this awesome blog <a href="https://www.entrypointai.com/blog/lora-fine-tuning/" rel="noopener ugc nofollow" target="_blank">LoRA Fine-tuning &amp; Hyperparameters Explained (in Plain English) | Entry Point AI</a></li><li id="c733">Set up WANDB_API_KEY=&lt;key&gt; if you are reporting to wandb else remove <code>report_to='wandb'</code></li></ol><p id="bc6b">This should be it and your training should be running in full force, look for GPU utilization.</p><h2 id="f2df">Observation</h2><p id="38ff">Ran the fine tuning for only 1 epoch, took around 15 hours. Loss curve</p><figure><figcaption>fig: training loss <a href="https://wandb.ai/sumandas0/huggingface/reports/train-loss-24-04-25-02-44-11---Vmlldzo3Njg1NzIw?accessToken=hinzctjy4lbm48zwjoamnmhxs5r56zp8l88iqpss2jb0xo2w2bu049jkiqd59btj" rel="noopener ugc nofollow" target="_blank">train/loss (24/04/25 02:44:11) | huggingface — Weights &amp; Biases (wandb.ai)</a></figcaption></figure><p id="38c3"><strong>WandB summary</strong></p><pre><span id="e856">{<br>  "train/learning_rate": 0.00004551803455482833,<br>  "eval/steps_per_second": 0.893,<br>  "_wandb.runtime": 51487,<br>  "_runtime": 51480.36651659012,<br>  "_timestamp": 1713698971.6200776,<br>  "train/epoch": 1.0571428571428572,<br>  "train/grad_norm": 0.14189070214353952,<br>  "train/global_step": 8325,<br>  "eval/samples_per_second": 7.141,<br>  "_step": 1665,<br>  "eval/loss": 0.963840126991272,<br>  "train/loss": 0.9674,<br>  "eval/runtime": 7532.9797<br>}</span></pre><h2 id="602e">Last steps,</h2><p id="02a5">After the finetuning what model you will get is small adapter model not full model that you can just start using just now, we need to add the adapter to the original meta llama3 weights,</p><p id="d092">Load PEFT adapter model,</p><pre><span id="866d">from peft import PeftModel<br>from transformers import AutoModelForCausalLM<p>base_model = AutoModelForCausalLM.from_pretrained("meta-llama/Meta-Llama-3-8B-Instruct",torch_dtype=torch.bfloat16, device_map="auto")<br>adapter_model = PeftModel.from_pretrained(base_model, "sumandas/llama3-openhermes-2.5")<br>adapter_model.merge_and_unload()</p></span></pre><p id="11a1">Now save the adapter model into hf,</p><pre><span id="c058">adapter_model.push_to_hub("sumandas/llama3-openhermes-2.5")</span></pre><h2 id="6ffe">Inference</h2><pre><span id="2c4c">import torch<br>import transformers<br>from transformers import pipeline<p>pipe = pipeline("text-generation", model="sumandas/llama3-openhermes-2.5",model_kwargs={"torch_dtype": torch.bfloat16},<br>    device="cuda")</p><p>generate_kwargs = {<br>    "do_sample": True,<br>    "temperature": 0.7,<br>    "max_new_tokens": 35,<br>}</p></span></pre><pre><span id="e8fe">pipe("&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt; Describe the food of Thailand&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;",max_length=2048)</span></pre><p id="a1a4">Response,</p><pre><span id="dce7">Thai cuisine is a blend of bold flavors and aromatic ingredients that create a harmonious balance of sweet, sour, salty, bitter, and spicy taste. The food in Thailand varies between different regions, but some common ingredients found throughout include rice, noodles, vegetables, herbs, and spices. Rice is a staple of Thai cuisine and is served with almost every meal, whether it is stir-fried, boiled, or used to make congee or fried rice. Noodles, made from rice or wheat, are also very popular and can be found served with various broths, sauces, and toppings in many Thai dishes. Thai food is known for its use of fresh herbs and spices such as lemongrass, galangal, coriander, basil, kaffir lime leaves, ginger, and garlic, which give the dishes their distinct flavors. Thai chilies are also widely used to add varying levels of heat to the food. Some popular Thai dishes include Tom Yum soup (hot and sour soup with lemongrass, kaffir lime leaves, and chilies), Pad Thai (stir-fried rice noodles with vegetables, peanuts, and a tangy sauce), and green curry (a spicy curry made with green chilies, coconut milk, and Thai basil). Many Thai dishes are also accompanied by a variety of sauces and condiments, including fish sauce, soy sauce, chili paste, and tamarind sauce. Fresh fruits like mango, papaya, and pineapple are also commonly enjoyed as a sweet ending to a meal. Overall, Thai food is a vibrant and flavorful cuisine that combines traditional ingredients and cooking techniques with a balance of flavors that tantalize the taste buds.&lt;|eot_id|&gt;</span></pre><p id="9238">Do send my model and dataset some love if it has any worth :)</p><p id="45d9"><a href="https://huggingface.co/datasets/sumandas/openhermes-2.5-llama3" rel="noopener ugc nofollow" target="_blank">sumandas/openhermes-2.5-llama3 · Datasets at Hugging Face</a></p><p id="2c72"><a href="https://huggingface.co/sumandas/llama3-openhermes-2.5" rel="noopener ugc nofollow" target="_blank">sumandas/llama3-openhermes-2.5 · Hugging Face</a></p></div></div>]]></description>
        </item>
    </channel>
</rss>