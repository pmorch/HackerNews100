<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 29 Mar 2025 16:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Show HN: Physical Pomodoro Timer with ESP32 and e-paper screen (185 pts)]]></title>
            <link>https://github.com/Rukenshia/pomodoro</link>
            <guid>43514383</guid>
            <pubDate>Sat, 29 Mar 2025 10:42:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Rukenshia/pomodoro">https://github.com/Rukenshia/pomodoro</a>, See on <a href="https://news.ycombinator.com/item?id=43514383">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">pomodoro</h2><a id="user-content-pomodoro" aria-label="Permalink: pomodoro" href="#pomodoro"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Rukenshia/pomodoro/blob/main/docs/front.jpg"><img src="https://github.com/Rukenshia/pomodoro/raw/main/docs/front.jpg" alt="the finished product from the front"></a></p>
<p dir="auto">This is the repository for an ESP32 based pomodoro timer. It uses an ePaper display and a rotary dial for input.
The code in this repository will not be ready-to-use, as some assets and fonts have been removed. However, if you really want to you should be able to adapt the code to your needs.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Parts List</h2><a id="user-content-parts-list" aria-label="Permalink: Parts List" href="#parts-list"></a></p>
<ul dir="auto">
<li>ESP32 (I used an <a href="https://www.az-delivery.de/en/products/esp32-developmentboard" rel="nofollow">AZDelivery ESP32 NodeMCU</a>)</li>
<li>WaveShare 4.26inch e-Paper display HAT, 800x480 (<a href="https://www.waveshare.com/4.26inch-e-paper-hat.htm" rel="nofollow">link</a>)</li>
<li>KY-040 rotary encoder with button</li>
<li>A single WS2812 LED (could be replaced with a simple RGB LED)A</li>
<li>A USB-C connector (like <a href="https://amzn.eu/d/8UpvqWe" rel="nofollow">this one</a>)</li>
<li>3d printed case (<a href="https://cad.onshape.com/documents/06055e629740267835bb7660/w/df56eb93ab74e2f4d61e5097/e/21a7853695e4900200750891?renderMode=0&amp;uiState=67e6e3924368850ba92069f6" rel="nofollow"><code>onshape</code> file</a>)</li>
<li>Some resistors and 0.1uF capacitors</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Project Origin</h2><a id="user-content-project-origin" aria-label="Permalink: Project Origin" href="#project-origin"></a></p>
<p dir="auto">I love trying out different productivity techniques - some say that the quest to optimize your productivity is the ultimate procrastination method, so maybe that is what drove me to this project. I also have a habit of committing time (around a month of work outside my normal job) once a year to a project that benefits someone else. Last year, I bought a 3D printer (BambuLab X1C) and wanted to put it to good use. I have previously finished an apprenticeship as an electronics
engineer before pivoting to software engineering, so I also wanted to come back to my roots and build something physical.
My friend struggles with time management throughout the day sometimes - lots of different tasks to organize, and little focus. So I thought to myself: Why not make them a pomodoro timer? So, I set out with a few goals:</p>
<ul dir="auto">
<li>It should be a physical device</li>
<li>It should be <em>fun</em></li>
<li>It should be intuitive to use</li>
</ul>
<p dir="auto">There are some cool projects out there (arguably much cooler than this, for example the <a href="https://www.youtube.com/watch?v=nZa-Vqu-_fU" rel="nofollow">Focus Dial by Salim Benbouziyane</a>), but I wanted to build something from scratch. I also
never built something with an ePaper display and thought it might be a good fit for something that is mostly idling and doesn't require a backlight.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Why these parts?</h3><a id="user-content-why-these-parts" aria-label="Permalink: Why these parts?" href="#why-these-parts"></a></p>
<p dir="auto">This was my second dive back into building things with microcontrollers in a long time. I knew ESP32 well enough to feel comfortable diving back in, so that was the main choice here. I did some research before to see what kinds of displays would be supported.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">ePaper Display</h4><a id="user-content-epaper-display" aria-label="Permalink: ePaper Display" href="#epaper-display"></a></p>
<p dir="auto">I needed some sort of display, or at least I <em>wanted</em> some sort of display. One of the main motivations for this project was that it should be out of your way - until it is time to finish your current focus and move on. For me, this meant that I wanted a display without any backlight.</p>
<p dir="auto">The display should also be large enough that you can put the whole device somewhere on your desk and still be able to read it. After ordering and playing around with a few WaveShare ePaper displays, I settled on the 4.26" variant for multiple reasons:</p>
<ul dir="auto">
<li>Great resolution (which seems to be really hard to find for "hobbyist" displays)</li>
<li>The size felt right</li>
<li>The display supports partial refreshes (0.3s, no distracting "black and white flashes" while refreshing)</li>
</ul>
<p dir="auto">Initially, I really wanted to use a black/white/red display and found one that I liked, but the refresh time
was a whopping 16 seconds with no support for partial refreshes which was a dealbreaker for me.</p>
<p dir="auto">The final bonus feature: it won't work at night. If your desk is not bright enough, you won't be able to read the display. This is a feature, not a bug. Too dark outside? Stop working already!</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Rotary Encoder</h4><a id="user-content-rotary-encoder" aria-label="Permalink: Rotary Encoder" href="#rotary-encoder"></a></p>
<p dir="auto">From the start, I knew that I wanted some sort of dial as an input - it made the most sense to me. This came at the cost of some complexity when designing the menus, and you really need to make sure that you debounce the input correctly. I also added .1uF capacitors to the CLK and DT pins to help with smoothing out the signal.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">LED</h4><a id="user-content-led" aria-label="Permalink: LED" href="#led"></a></p>
<p dir="auto">In the first few iterations, there was no plan for an LED. My genius plan of having a display without backlight came at a cost: it could be <em>too</em> subtle when your current focus time ended. I experimented with a few different ideas:</p>
<ul dir="auto">
<li>A buzzer: this would just make you jump. A truly horrible experience</li>
<li>Speakers: I don't know why, but speakers felt <em>hard</em>. So much noise and whining with the setup I tried, but I will blame this on a skill issue</li>
<li>LED: I had some WS2812 LEDs lying around and thought they might be a good fit. You can animate them with the NeoPixel library, and they are really easy to use. The additional benefit of not needing to commit many more output pins was also a big plus</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Rukenshia/pomodoro/blob/main/docs/led_shroud.png"><img src="https://github.com/Rukenshia/pomodoro/raw/main/docs/led_shroud.png" alt="LED shroud screenshot of the CAD model"></a></p>
<p dir="auto">The LED ended up working great, allowing me to display different states. It might be subtle, but I also added a little shroud to the case and added a diffusion layer in front of the LED to make it look nicer.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Building the Case</h3><a id="user-content-building-the-case" aria-label="Permalink: Building the Case" href="#building-the-case"></a></p>
<p dir="auto">The case comes in two parts: the base and a lid. One unfortunate design choice I made is that the display frame is printed as one piece as part of the base, so the top edge tends to warp a little bit during printing. Since CAD (or product design) isn't my strongest suit, there will certainly be better choices to design this for a better final look.</p>
<p dir="auto">One thing that I wished I learned earlier is that it might not have been the best idea to put the dial in the front: because the print and electronics are so lightweight, pressing the switch on the dial will tend to just slide the whole device back. Luckily, I could solve this by adding some rubber feet and weights (the ones usually used to balance tires) to the bottom of the case. This worked out great, and I am happy with how it turned out.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Software</h3><a id="user-content-software" aria-label="Permalink: Software" href="#software"></a></p>
<p dir="auto">The software is written in C++ and uses the Arduino framework. I used PlatformIO to manage the project (at least that is what seemed to be a popular choice, but I am not so sure about that anymore). This project relies heavily
on the GxEPD2 library for the display. I won't lie, the code in this repository is a bit of a mess - I had to get things done in time, which led to quite a bit of copy and pasting and not revisiting earlier parts of the code.
Some parts were generated by AI (Claude, for the most part) to help me finish the project in the deadline I set myself.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Rukenshia/pomodoro/blob/main/docs/timer_running.jpg"><img src="https://github.com/Rukenshia/pomodoro/raw/main/docs/timer_running.jpg" alt="a random fact displayed on the screen"></a></p>
<p dir="auto">Since this was a project for my friend, I also wanted to include some easter eggs and fun. You would think that adding some random facts <em>while you are supposed to be focused</em> would be a bad idea, but I think it is a fun little addition.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Using the Device</h2><a id="user-content-using-the-device" aria-label="Permalink: Using the Device" href="#using-the-device"></a></p>
<p dir="auto">When the device starts up, you can either change some settings or go into preset selection mode. From there, you can choose one of three presets:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Rukenshia/pomodoro/blob/main/docs/select_preset.jpg"><img src="https://github.com/Rukenshia/pomodoro/raw/main/docs/select_preset.jpg" alt="preset selection"></a></p>
<p dir="auto">The timer will then start and let you know once the time is up (by flashing the LED and displaying a message on the screen). You can keep working (not recommended, but necessary if you want to finish something) and then start the break.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Rukenshia/pomodoro/blob/main/docs/timer_running.jpg"><img src="https://github.com/Rukenshia/pomodoro/raw/main/docs/timer_running.jpg" alt="timer running"></a></p>
<p dir="auto">During the pause, you can view some statistics. Every few iterations (4 by default), your pause will be longer to give you some time to recover.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Rukenshia/pomodoro/blob/main/docs/timer_paused.jpg"><img src="https://github.com/Rukenshia/pomodoro/raw/main/docs/timer_paused.jpg" alt="pause statistics"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Development</h2><a id="user-content-development" aria-label="Permalink: Development" href="#development"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Pin Mapping</h3><a id="user-content-pin-mapping" aria-label="Permalink: Pin Mapping" href="#pin-mapping"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Rotary Encoder (KY-040)</h4><a id="user-content-rotary-encoder-ky-040" aria-label="Permalink: Rotary Encoder (KY-040)" href="#rotary-encoder-ky-040"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>PIN</th>
<th>#</th>
</tr>
</thead>
<tbody>
<tr>
<td>CLK</td>
<td>32</td>
</tr>
<tr>
<td>DT</td>
<td>21</td>
</tr>
<tr>
<td>SW</td>
<td>14</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h4 tabindex="-1" dir="auto">ePaper Display (GxEPD2_426_GDEQ0426T82, WaveShare 4.26" b/w)</h4><a id="user-content-epaper-display-gxepd2_426_gdeq0426t82-waveshare-426-bw" aria-label="Permalink: ePaper Display (GxEPD2_426_GDEQ0426T82, WaveShare 4.26&quot; b/w)" href="#epaper-display-gxepd2_426_gdeq0426t82-waveshare-426-bw"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>PIN</th>
<th>#</th>
</tr>
</thead>
<tbody>
<tr>
<td>BUSY</td>
<td>4</td>
</tr>
<tr>
<td>RST</td>
<td>16</td>
</tr>
<tr>
<td>DC</td>
<td>17</td>
</tr>
<tr>
<td>CS</td>
<td>5</td>
</tr>
<tr>
<td>CLK</td>
<td>18</td>
</tr>
<tr>
<td>DIN</td>
<td>23</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h4 tabindex="-1" dir="auto">LED (WS2812)</h4><a id="user-content-led-ws2812" aria-label="Permalink: LED (WS2812)" href="#led-ws2812"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>PIN</th>
<th>#</th>
</tr>
</thead>
<tbody>
<tr>
<td>DIN</td>
<td>25</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Et Tu, Grammarly? (163 pts)]]></title>
            <link>https://dbushell.com/2025/03/29/et-tu-grammarly/</link>
            <guid>43514308</guid>
            <pubDate>Sat, 29 Mar 2025 10:27:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dbushell.com/2025/03/29/et-tu-grammarly/">https://dbushell.com/2025/03/29/et-tu-grammarly/</a>, See on <a href="https://news.ycombinator.com/item?id=43514308">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>
<time datetime="2025-03-29T10:00:00.000Z" title="2025-03-29T10:00:00.000Z">

Saturday

29 <abbr title="March">Mar</abbr>
2025
</time>
</p>

<p>For a few months now I’ve received sporadic reports that my website was broken. They said the layout was askew and things were sized strangely. They had screenshots to prove it. This was embarrassing for a professional website builder.</p><p>Thankfully my audience is tech-savvy and the <a href="https://www.grammarly.com/browser" rel="noopener noreferrer" target="_blank">Grammarly browser extension</a> was identified as a prime suspect. When this extension was installed it broke my website, simple as that. My initial response was: <em>“Sorry, their bug, not mine”</em>. But after one report too many, I was forced to sign-up and install Grammarly myself (praise the burner email).</p><h2 id="discovery">Discovery</h2><p>After accepting the Grammarly Firefox (<a href="https://dbushell.com/2025/03/01/never-have-never-will/">Mullvad browser</a>) extension kitchen sink permissions:</p><ul><li>Access your data for all websites</li><li>Display notifications to you</li><li>Access browser tabs</li></ul><p>I soon found the evidence. Grammarly injects a stylesheet into web pages (<a href="https://gist.github.com/dbushell/d65efab2cc2f009a37d5e6b706cf0c66" rel="noopener noreferrer" target="_blank">here’s a GitHub Gist</a>). This stylesheet is loaded from the local extension assets. It cannot be found by the web page itself using <a href="https://developer.mozilla.org/en-US/docs/Web/API/StyleSheetList" rel="noopener noreferrer" target="_blank">StyleSheetList</a>. It even bypasses <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Guides/CSP" rel="noopener noreferrer" target="_blank">Content Security Policy</a>. It is effectively a stealth stylesheet undetectable by the website itself. In Firefox at least, I didn’t care to install Grammarly in other browsers.</p><p>The Grammarly extension also appends a custom <code>&lt;grammarly-desktop-integration&gt;</code> element to the <code>&lt;html&gt;</code> document. This is done on every website regardless of whether you interact with the extension or not (I’ve no idea what it’s used for).</p><h2 id="why-me">Why me?</h2><p>At the end of <a href="https://gist.github.com/dbushell/d65efab2cc2f009a37d5e6b706cf0c66" rel="noopener noreferrer" target="_blank">Grammarly’s stylesheet</a> you’ll find the following CSS:</p><pre data-lang="css" tabindex="0" id="pre-5340eb92"><code><span><span>:</span><span>host</span><span>,</span></span>
<span><span>:</span><span>root</span><span> </span><span>{</span></span>
<span><span> </span><span> </span><span>--rem</span><span>:</span><span>16</span></span>
<span><span>}</span></span></code></pre><p>Aside from the obvious crime of omitting a semicolon, this is seemingly innocuous. You probably know the magic number 16. By default 1rem = 16px in CSS units (kinda, it’s complicated). Further up Grammarly are doing a form of dynamic font sizing:</p><pre data-lang="css" tabindex="0" id="pre-ec1d077b"><code><span><span>.kE2Bj</span><span> </span><span>{</span></span>
<span><span> </span><span> </span><span>font-size</span><span>:</span><span>calc</span><span>(</span><span>0.86</span><span>px*</span><span>(</span><span>var</span><span>(--rem)</span><span> </span><span>-</span><span> </span><span>2</span><span>));</span></span>
<span><span> </span><span> </span><span>line-height</span><span>:</span><span>calc</span><span>(</span><span>1.2868</span><span>px*</span><span>(</span><span>var</span><span>(--rem)</span><span> </span><span>-</span><span> </span><span>2</span><span>));</span></span>
<span><span>}</span></span></code></pre><p>This code is auto-generated so it’s not entirely clear what’s going on. I thought they might be dynamically setting the <code>--rem</code> value using the browser’s base font size — good for accessibility — but from testing that isn’t the case. Maybe the extension has its own setting?</p><p>As an aside note, Grammarly are also loading twenty variations of the <a href="https://fonts.google.com/specimen/Inter" rel="noopener noreferrer" target="_blank">Inter font</a> — <a href="https://knowyourmeme.com/memes/four-naan-jeremy-thats-insane" rel="noopener noreferrer" target="_blank"><em>Four Naan, Jeremy? That’s Insane!</em></a> — Inter is available as a <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_fonts/Variable_fonts_guide" rel="noopener noreferrer" target="_blank">variable font</a>. You don’t need twenty individual <code>@font-face</code> rules, <del>Jeremy</del> Grammarly.</p><p>Anyway, as it happens I was also using the <code>--rem</code> custom property name. I’m doing my own experimental flavour of <a href="https://clagnut.com/blog/2441/" rel="noopener noreferrer" target="_blank">fluid typography</a>:</p><pre data-lang="css" tabindex="0" id="pre-451b88a5"><code><span><span>@layer</span><span> </span><span>base</span><span> </span><span>{</span></span>
<span><span> </span><span> </span><span>:</span><span>root</span><span> </span><span>{</span></span>
<span><span> </span><span> </span><span> </span><span> </span><span>--rem</span><span>:</span><span> </span><span>0.0625</span><span>rem</span><span>;</span></span>
<span><span> </span><span> </span><span> </span><span> </span><span>--fluid</span><span>:</span><span> </span><span>calc</span><span>((</span><span>100</span><span>vi</span><span> </span><span>-</span><span> </span><span>(</span><span>400</span><span> </span><span>*</span><span> </span><span>var</span><span>(--rem)))</span><span> </span><span>/</span><span> </span><span>(1920</span><span> </span><span>-</span><span> </span><span>400));</span></span>
<span><span> </span><span> </span><span> </span><span> </span><span>--font-size-h1</span><span>:</span><span> </span><span>clamp</span><span>(</span></span>
<span><span> </span><span> </span><span> </span><span> </span><span> </span><span> </span><span>calc</span><span>(</span><span>31</span><span> </span><span>*</span><span> </span><span>var</span><span>(--rem)),</span></span>
<span><span> </span><span> </span><span> </span><span> </span><span> </span><span> </span><span>calc</span><span>((</span><span>31</span><span> </span><span>*</span><span> </span><span>var</span><span>(--rem))</span><span> </span><span>+</span><span> </span><span>(80</span><span> </span><span>-</span><span> </span><span>31</span><span>)</span><span> </span><span>*</span><span> </span><span>var</span><span>(--fluid)),</span></span>
<span><span> </span><span> </span><span> </span><span> </span><span> </span><span> </span><span>calc(80</span><span> </span><span>*</span><span> </span><span>var(--rem))</span></span>
<span><span> </span><span> </span><span> </span><span> </span><span>);</span></span>
<span><span> </span><span> </span><span>}</span></span>
<span><span>}</span></span></code></pre><p>How this works is a topic for another blog post.</p><p>What’s important is that I was using <code>--rem</code> and it’s defined inside a <a href="https://developer.mozilla.org/en-US/docs/Learn_web_development/Core/Styling_basics/Cascade_layers" rel="noopener noreferrer" target="_blank">cascade layer</a>. Styles outside of a layer take precedent over those within a layer, regardless of CSS specificity (a topic for an entire book). Source order also matters, so Grammarly’s <code>--rem</code> probably would have won anyway.</p><p><abbr title="too long; didn't read">TL;DR</abbr>: Grammarly broke my calculations and thus they broke my website.</p><h2 id="the-fix">The Fix 🤡</h2><p>Initially <a href="https://dbushell.com/notes/2025-03-28T17:54Z/">I used a mutation observer</a> to detect the appended web component and add extra <code>!important</code> styles to reclaim my territory. Once I understood the exact problem I changed my custom property to <code>--🤡</code> which is <a href="https://argyle.ink/css-emoji-convention" rel="noopener noreferrer" target="_blank">perfectly valid</a>.</p><p>Basically the name <code>--rem</code> is now “considered harmful” because Grammarly are bad web citizens. They are generating random class names, why specifically hijack <code>--rem</code>? Why apply it globally to <code>:root</code>? They could also, you know, not inject their code into <strong>every web page ever</strong>, unless the extension is actually used?</p><p>I’ve reached out to Grammarly support. They’ve been quick to respond, but I’ve yet to reach a technical person who understands my issue. I’m hoping we can swap names. Grammarly can have <code>--🤡</code> for their sins, the rest of use can use <code>--rem</code>. Any of you nerds work for Grammarly? Let’s make this happen.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Today Google bricked my Chromebook by force-installing a hidden extension (223 pts)]]></title>
            <link>https://cloudisland.nz/@rmi/114219847307106213</link>
            <guid>43514087</guid>
            <pubDate>Sat, 29 Mar 2025 09:35:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cloudisland.nz/@rmi/114219847307106213">https://cloudisland.nz/@rmi/114219847307106213</a>, See on <a href="https://news.ycombinator.com/item?id=43514087">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Postgres Language Server: Initial Release (197 pts)]]></title>
            <link>https://github.com/supabase-community/postgres-language-server</link>
            <guid>43513996</guid>
            <pubDate>Sat, 29 Mar 2025 09:13:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/supabase-community/postgres-language-server">https://github.com/supabase-community/postgres-language-server</a>, See on <a href="https://news.ycombinator.com/item?id=43513996">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/supabase-community/postgres-language-server/blob/main/docs/images/pls-github.png"><img src="https://github.com/supabase-community/postgres-language-server/raw/main/docs/images/pls-github.png" alt="Postgres Language Server"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Postgres Language Server</h2><a id="user-content-postgres-language-server" aria-label="Permalink: Postgres Language Server" href="#postgres-language-server"></a></p>
<p dir="auto">A collection of language tools and a Language Server Protocol (LSP) implementation for Postgres, focusing on developer experience and reliable SQL tooling.</p>
<p dir="auto">Docs: <a href="https://pgtools.dev/" rel="nofollow">pgtools.dev</a></p>
<p dir="auto">Install: <a href="https://pgtools.dev/#installation" rel="nofollow">instructions</a></p>
<ul dir="auto">
<li><a href="https://github.com/supabase-community/postgres-language-server/releases">CLI releases</a></li>
<li><a href="https://marketplace.visualstudio.com/items?itemName=Supabase.postgrestools" rel="nofollow">VSCode</a></li>
<li><a href="https://github.com/neovim/nvim-lspconfig/blob/master/doc/configs.md#postgres_lsp">Neovim</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Overview</h2><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<p dir="auto">This project provides a toolchain for Postgres development, built on Postgres' own parser <code>libpg_query</code> to ensure 100% syntax compatibility. It is built on a Server-Client architecture with a transport-agnostic design. This means all features can be accessed not only through the <a href="https://microsoft.github.io/language-server-protocol/" rel="nofollow">Language Server Protocol</a>, but also through other interfaces like a CLI, HTTP APIs, or a WebAssembly module. The goal is to make all the great Postgres tooling out there as accessible as possible, and to build anything that is missing ourselves.</p>
<p dir="auto">The following features are implemented:</p>
<ul dir="auto">
<li>Autocompletion</li>
<li>Syntax Error Highlighting</li>
<li>Type-checking (via <code>EXPLAIN</code> error insights)</li>
<li>Linter, inspired by <a href="https://squawkhq.com/" rel="nofollow">Squawk</a></li>
</ul>
<p dir="auto">Our current focus is on refining and enhancing these core features while building a robust and easily accessible infrastructure. For future plans and opportunities to contribute, please check out the issues and discussions. Any contributions are welcome!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributors</h2><a id="user-content-contributors" aria-label="Permalink: Contributors" href="#contributors"></a></p>
<ul dir="auto">
<li><a href="https://github.com/psteinroe">psteinroe</a></li>
<li><a href="https://github.com/juleswritescode">juleswritescode</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgements</h2><a id="user-content-acknowledgements" aria-label="Permalink: Acknowledgements" href="#acknowledgements"></a></p>
<p dir="auto">A big thanks to the following projects, without which this project wouldn't have been possible:</p>
<ul dir="auto">
<li><a href="https://github.com/pganalyze/libpg_query">libpg_query</a>: For extracting the Postgres' parser</li>
<li><a href="https://github.com/biomejs/biome">Biome</a>: For implementing a toolchain infrastructure we could copy from</li>
<li><a href="https://github.com/sbdchd/squawk">Squawk</a>: For the linter inspiration</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Trump's attacks on universities get darker, with shadows reaching our shores (185 pts)]]></title>
            <link>https://christinapagel.substack.com/p/trumps-attacks-on-universities-get</link>
            <guid>43513811</guid>
            <pubDate>Sat, 29 Mar 2025 08:29:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://christinapagel.substack.com/p/trumps-attacks-on-universities-get">https://christinapagel.substack.com/p/trumps-attacks-on-universities-get</a>, See on <a href="https://news.ycombinator.com/item?id=43513811">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>A colleague and I would like to write an academic paper on the potential impact of US funding cuts to global health programmes. Our ideal co-author is an international expert newly based in the US, and they would like to do it. But we are all worried that doing so will expose them to the risk of having their academic visa cancelled, being detained and eventually deported - no matter how solid the science and how academic and dry our language. We are especially fearful because they are brown. </p><p>My colleagues who have been writing about the new administration, or the situation in Gaza, in academic journals, on substack or on social media are cancelling work trips to the US. I too would not feel safe to go now, given how openly I have criticised the administration. Even a 1% chance of being denied entry or shipped to a detention centre is too high. </p><p>When I said these words out loud to my husband today I had to stop for a moment to let it sink in. Foreign scientists in the US are scared to publish anything perceived as critical for fear of being bundled off the street to a detention centre. Foreign scientists abroad are scared to go to the US because they have voiced criticism of the state. The US is actively cracking down on perceived dissenters and foreigners are the most vulnerable to arbitrary detention and lack of due legal process. The vaunted first amendment guaranteeing free speech has become a bitter and twisted joke. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8eff6593-7fbf-427a-aedb-9d3b8dd64313_5348x3301.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8eff6593-7fbf-427a-aedb-9d3b8dd64313_5348x3301.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8eff6593-7fbf-427a-aedb-9d3b8dd64313_5348x3301.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8eff6593-7fbf-427a-aedb-9d3b8dd64313_5348x3301.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8eff6593-7fbf-427a-aedb-9d3b8dd64313_5348x3301.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8eff6593-7fbf-427a-aedb-9d3b8dd64313_5348x3301.png" width="1456" height="899" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8eff6593-7fbf-427a-aedb-9d3b8dd64313_5348x3301.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:899,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:4506318,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://christinapagel.substack.com/i/160080456?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8eff6593-7fbf-427a-aedb-9d3b8dd64313_5348x3301.png&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8eff6593-7fbf-427a-aedb-9d3b8dd64313_5348x3301.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8eff6593-7fbf-427a-aedb-9d3b8dd64313_5348x3301.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8eff6593-7fbf-427a-aedb-9d3b8dd64313_5348x3301.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8eff6593-7fbf-427a-aedb-9d3b8dd64313_5348x3301.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>I </span><a href="https://christinapagel.substack.com/p/censor-purge-defund-how-trump-following" rel="">already wrote three weeks ago</a><span> about how the Trump administration’s attacks on science were following the authoritarian playbook - and things have only got worse since. I am sure your first reaction is to think that I am overreacting. It sounds ridiculous to say such things. It sounds unbelievable even to me. But it is where we are and the sooner we accept it, the sooner we can organise to change it. Simply consider what we have seen over the last few weeks.</span></p><p><span>A student on a green card at Columbia University in New York who organised protests last summer against Israel’s attacks on Gaza was </span><a href="https://www.theguardian.com/us-news/2025/mar/14/mahmoud-khalil-columbia-arrest" rel="">taken from his house</a><span> and is still being detained in Louisiana. He has not been accused of breaking any law. </span><a href="https://apnews.com/article/university-protests-palestinian-immigration-2d7bd689b013b8bb6300fd6ab54de933" rel="">Another student on a green card</a><span> at Columbia managed to preempt attempts to detain her with a lawsuit, but the administration is nonetheless trying to revoke her green card because she attended protests.</span></p><p><span>A student at Tufts University in Boston who wrote an article last summer for a student newspaper criticising Israel’s attacks on Gaza </span><a href="https://apnews.com/article/tufts-student-detained-massachusetts-immigration-6c3978da98a8d0f39ab311e092ffd892" rel="">was taken off the street </a><span>and is now being detained in Louisiana. The only crime she is accused of is not having a valid visa - because the administration suddenly revoked it before detaining her. </span></p><p><span>An Indian student of Georgetown University in Virginia </span><a href="https://apnews.com/article/georgetown-trump-deportation-immigration-homeland-security-21fc205cebbbbba2ed260050df04702a" rel="">was arrested outside his home</a><span> for ‘spreading Hamas propaganda’ for social media posts supporting Gaza, but has not been accused of any crime. He is being detained in Louisiana.</span></p><p><span>A Fulbright scholar at Columbia </span><a href="https://www.nytimes.com/2025/03/15/nyregion/columbia-student-kristi-noem-video.html?smid=nytcore-ios-share&amp;referringSource=articleShare" rel="">fled to Canada </a><span>after learning her visa had been revoked and after evading immigration agents searching for her over two nights. She doesn’t know why her visa was revoked - homeland security accused her, without presenting any evidence, of terrorist sympathies. Kristi Noem, the homeland security secretary, crowed about her ‘self-deportation’ on social media.</span></p><p><span>The Trump administration is trumpeting its detentions. Marco Rubio, Secretary of State, </span><a href="https://www.npr.org/2025/03/28/g-s1-56780/trump-administration-advances-immigration-crackdown-on-foreign-student-protesters" rel="">said yesterday that over 300 student visas had been revoked</a><span> and promised many more to come. He was explicit that it was not criminal activity triggering the revocation but suspicion of ‘</span><a href="https://www.foxnews.com/world/rubio-warns-visas-revoked-all-foreign-student-activists-amid-tufts-arrest" rel="">causing a ruckus</a><span>’. Rubio is also </span><a href="https://www.kenklippenstein.com/p/exclusive-trump-admin-spies-on-social" rel="">mandating </a><span>a social media review for all visas of new and returning foreign students or academics, looking for “conduct that bears a hostile attitude toward U.S. citizens or U.S. culture (including government, institutions, or founding principles).”</span></p><p><span>Facing the loss of hundreds of millions of dollars of federal funding, universities in the US are </span><a href="https://www.politico.com/news/2025/03/20/universities-cave-conservatives-trump-00241765?ueid=8ce7e99e1265480c563fabb659bdf7cd&amp;utm_source=Sailthru&amp;utm_medium=email&amp;utm_campaign=The%20Logoff%203/21&amp;utm_term=The%20Logoff" rel="">not fighting back</a><span>. </span><a href="https://www.theguardian.com/us-news/2025/mar/21/columbia-university-funding-trump-demands" rel="">Columbia University has agreed to all the administration’s conditions</a><span> for just starting discussion on the restoriation of its federal funding. These include greater controls on protests, greater ability to arrest students, greater external oversight over its faculty (including hiring decisions) and courses. Michigan University has officially </span><a href="https://edition.cnn.com/2025/03/27/us/university-of-michigan-eliminates-dei-program/index.html" rel="">cancelled all its diversity, equity and inclusion (DEI) programmes</a><span>, along with </span><a href="https://archive.md/QE7pJ#selection-4809.0-4800.6" rel="">dozens of other universities</a><span>. NYU </span><a href="https://bsky.app/profile/ryoa.bsky.social/post/3llf7d3aiik24" rel="">cancelled </a><span>a talk by a former president of Medicins Sans Frontiere because her talk mentioned humanitarian workers killed in Gaza and Trump’s Oval Office meeting with Zelenskyy. </span></p><p><span>Those entering the country are also facing ideological tests. </span><a href="https://www.theguardian.com/us-news/2025/mar/19/trump-musk-french-scientist-detained" rel="">A French scientist travelling to a conference was denied entry </a><span>after immigration officials found messages on his phone criticising the administration’s treatment of scientists. A </span><a href="https://www.theguardian.com/us-news/2025/mar/27/russian-scientist-harvard-medical-school-ice-detention" rel="">Russian scientist</a><span> working at Harvard university was detained on re-entering the US after officials revoked her visa, threatening to deport her to Russia. As an outspoken critic of Putin, she said she feared for her life if they did so and she is currently in detention in Louisiana. </span></p><p><span>The administration continues to cancel dozens of awarded grants every day, each one meaning that important science does not get done and that</span><a href="https://www.theguardian.com/us-news/2025/mar/13/johns-hopkins-job-cuts-usaid" rel=""> people lose jobs</a><span> and possibly careers. The cancellations are based on ideology. The full list of cancelled grants (so far 439) is being tracked on this </span><a href="https://docs.google.com/spreadsheets/d/1rXukuHRF_WEz7bdv1sOu0ZY1A2PS2jEnojT1ll3okhQ/edit?usp=sharing" rel="">incredible google spreadsheet</a><span>. The list of cancelled grants maintained by the US department of Health and Human Services (HHS) </span><a href="https://bsky.app/profile/maxkozlov.bsky.social/post/3llhnxzibdc2n" rel="">more than doubled</a><span> today. Here is a taste of what research has been cancelled:</span></p><ul><li><p><a href="https://apnews.com/article/lgbtq-research-grants-terminated-trump-5b2810312de1420ca3df875314b0a1e9" rel="">68 grants</a><span> all about improving the health of LGBT+ populations</span></p></li><li><p>Grants to understand the impact of deprivation or demographics on depression, or drug use or alcohol use.</p></li><li><p>Grants examining the safety of drinking water and how it affects different communities</p></li><li><p>Grants to understand patterns of chronic disease through generations of families, with a focus on the impact of deprivation</p></li><li><p>Grants to understand (and improve) the problem of late diagnosis of autism in girls</p></li><li><p>Grants to improve vaccine uptake in marginalised populations</p></li><li><p>Grants examining how the risks of Covid-19 differ for different populations, including HIV and Cancer.</p></li></ul><p><span>The impacts are being felt abroad as well. Researchers with US grant funding in the UK, EU, Canada and Australia</span><a href="https://www.nature.com/articles/d41586-025-00850-5" rel=""> are receiving surveys</a><span> asking whether their research complies with US government idology - specifically whether they are working in a DEI or climate change related area. </span></p><p>If you are a foreign scientist working in the US, or even seeking to enter the US for a conference or temporary collaboration, it is simply dangerous to have criticised, or to now criticise, the regime. </p><p><span>Scientists who are US citizens have more protections and many are now coming together to fight back - especially in the absence of any meanginful action by their institutions. </span><a href="https://www.aaup.org/" rel="">The American Association of University Professors</a><span> this week </span><a href="https://www.nbcnews.com/news/us-news/academic-groups-sue-trump-administration-arresting-students-faculty-li-rcna198139" rel="">sued the Trump administration</a><span> for unconstitutional detention of foreign students and academics. We must support such efforts. </span></p><p>Meanwhile, those of us who can avoid travel to the US must continue the science others cannot and speak up where others are silenced. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Upcoming Windows 11 builds cannot install without internet and Microsoft Account (218 pts)]]></title>
            <link>https://infosec.exchange/@wdormann/114242475168860209</link>
            <guid>43512660</guid>
            <pubDate>Sat, 29 Mar 2025 04:13:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://infosec.exchange/@wdormann/114242475168860209">https://infosec.exchange/@wdormann/114242475168860209</a>, See on <a href="https://news.ycombinator.com/item?id=43512660">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Plain – a web framework for building products with Python (211 pts)]]></title>
            <link>https://plainframework.com/</link>
            <guid>43512589</guid>
            <pubDate>Sat, 29 Mar 2025 03:55:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://plainframework.com/">https://plainframework.com/</a>, See on <a href="https://news.ycombinator.com/item?id=43512589">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <!-- <div class="flex justify-center">
            <div class="px-3 font-mono text-sm border rounded-full border-zinc-200 text-stone-500 py-0.5">Design</div>
        </div> -->
        <h2>Leverage the world's most popular<br> programming language</h2>
        <p>
            Plain is a fork of <a href="https://www.djangoproject.com/">Django</a>,
            bringing new ideas to established patterns in the Python landscape.
            Build a new business, an internal tool, or something for yourself.
        </p>
        <!-- <p class="mx-auto text-sm leading-relaxed text-center text-zinc-600 max-w-prose">
            Plain can take you from development to production, from one user to thousands.
            <br class="hidden lg:inline">
            Build a new business, an internal tool, or something for yourself.
        </p> -->
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenWrt Two Approval (186 pts)]]></title>
            <link>https://openwrt.org/voting/2025-02-12-openwrt-two</link>
            <guid>43512495</guid>
            <pubDate>Sat, 29 Mar 2025 03:34:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openwrt.org/voting/2025-02-12-openwrt-two">https://openwrt.org/voting/2025-02-12-openwrt-two</a>, See on <a href="https://news.ycombinator.com/item?id=43512495">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">

            <!-- sidebar -->

<!-- /sidebar -->

            <article id="dokuwiki__content" itemscope="" itemtype="http://schema.org/TechArticle" itemref="dw__license">

                
<!-- page-tools -->
<nav id="dw__pagetools">
    
</nav>
<!-- /page-tools -->

                <div itemprop="articleBody">
<div>

<p>
Started by: <strong>John Crispin</strong>
</p>

<p>
Status: <strong>Closed</strong>
</p>

<p>
Result: <strong>Accepted</strong>
</p>

<p>
Ended: 05/03/2025
</p>

</div>


<div>
<pre>  Hi,
  
   starting a [VOTE] to get approval allowing me to begin the development of OpenWrt "Two".
  
  "Two" will have all of the features that "One" has with the following upgrades.
  
  * MT7988
  * 10G SFP
  * 5G copper
  * 4 port 2.5G copper
  * 1-2 port 1G copper
  * Tri-band Wi-Fi 7
  
  "Two" will be produced by GL.iNet and we are exploring options for US/EU based distribution.
  
  "Two" will (hopefully) be in the 250$ region with yet again a portion of that being donated to the project.
  
   expected availability is late '25.
  
          John</pre>

</div>


<div><table>
	<thead>
	<tr>
		<th> Members  </th><th> Yes  </th><th> No  </th><th> Missing  </th>
	</tr>
	</thead>
	<tbody><tr>
		<td> 42       </td><td> 24   </td><td>  0  </td><td>  18      </td>
	</tr>
</tbody></table></div>


<div><table>
	<thead>
	<tr>
		<th> Member        </th><th>  OpenWrt Two  </th>
	</tr>
	</thead>
	<tbody><tr>
		<td> Adrian        </td><td>               </td>
	</tr>
	<tr>
		<td> Alberto       </td><td>               </td>
	</tr>
	<tr>
		<td> Alexander     </td><td>  +1           </td>
	</tr>
	<tr>
		<td> Álvaro        </td><td>  +1           </td>
	</tr>
	<tr>
		<td> Baptiste      </td><td>  +1           </td>
	</tr>
	<tr>
		<td> Christian L.  </td><td>  +1           </td>
	</tr>
	<tr>
		<td> Christian M.  </td><td>  +1           </td>
	</tr>
	<tr>
		<td> Chuanhong     </td><td>  +1           </td>
	</tr>
	<tr>
		<td> Daniel        </td><td>  +1           </td>
	</tr>
	<tr>
		<td> David B.      </td><td>  +1           </td>
	</tr>
	<tr>
		<td> David W.      </td><td>  +1           </td>
	</tr>
	<tr>
		<td> Felix         </td><td>  +1           </td>
	</tr>
	<tr>
		<td> Florian       </td><td>               </td>
	</tr>
	<tr>
		<td> Hans          </td><td>               </td>
	</tr>
	<tr>
		<td> Hauke         </td><td>  +1           </td>
	</tr>
	<tr>
		<td> Imre          </td><td>               </td>
	</tr>
	<tr>
		<td> Jo-Philipp    </td><td>  +1           </td>
	</tr>
	<tr>
		<td> John          </td><td>  +1           </td>
	</tr>
	<tr>
		<td> Jonas         </td><td>               </td>
	</tr>
	<tr>
		<td> Kevin         </td><td>               </td>
	</tr>
	<tr>
		<td> Koen          </td><td>  +1           </td>
	</tr>
	<tr>
		<td> Luka          </td><td>               </td>
	</tr>
	<tr>
		<td> Linus         </td><td>               </td>
	</tr>
	<tr>
		<td> Mathias       </td><td>               </td>
	</tr>
	<tr>
		<td> Matthias      </td><td>  +1           </td>
	</tr>
	<tr>
		<td> Mirko         </td><td>               </td>
	</tr>
	<tr>
		<td> Nick          </td><td>  +1           </td>
	</tr>
	<tr>
		<td> Paul          </td><td>  +1           </td>
	</tr>
	<tr>
		<td> Petr          </td><td>  +1           </td>
	</tr>
	<tr>
		<td> Piotr         </td><td>  +1           </td>
	</tr>
	<tr>
		<td> Rafał         </td><td>               </td>
	</tr>
	<tr>
		<td> Rich          </td><td>  +1           </td>
	</tr>
	<tr>
		<td> Robert        </td><td>  +1           </td>
	</tr>
	<tr>
		<td> Rui           </td><td>  +1           </td>
	</tr>
	<tr>
		<td> Sander        </td><td>               </td>
	</tr>
	<tr>
		<td> Steven        </td><td>               </td>
	</tr>
	<tr>
		<td> Stijn         </td><td>               </td>
	</tr>
	<tr>
		<td> Sungbo        </td><td>  +1           </td>
	</tr>
	<tr>
		<td> Ted           </td><td>  +1           </td>
	</tr>
	<tr>
		<td> Thomas        </td><td>               </td>
	</tr>
	<tr>
		<td> Yousong       </td><td>               </td>
	</tr>
	<tr>
		<td> Zoltan        </td><td>               </td>
	</tr>
</tbody></table></div>
</div>

                <p><span>
                        <ul><li><span data-icon="mdi:calendar"></span> Last modified: <span title="2025/03/18 14:50">2025/03/18 14:50</span></li><li>by <bdi>aparcar</bdi></li></ul>                    </span>
                    
                    
                </p>

            </article>

            
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[iCloud Mail has DNS misconfigured? (174 pts)]]></title>
            <link>https://www.mail-tester.com/test-p3tdhnk3o</link>
            <guid>43511464</guid>
            <pubDate>Sat, 29 Mar 2025 00:22:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mail-tester.com/test-p3tdhnk3o">https://www.mail-tester.com/test-p3tdhnk3o</a>, See on <a href="https://news.ycombinator.com/item?id=43511464">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="test-results">

			<!-- Content -->
			<div>
										<p><b>From :</b> willem@vooijs.eu						<br><b>Bounce address :  </b>willem@vooijs.eu						<br>					</p>
					
											<!-- Text -->
						
					
					<!-- Raw -->
					<div>
							<pre>Received: by mail-tester.com (Postfix, from userid 500)
	id AB2FFA0B86; Sat, 29 Mar 2025 01:02:03 +0100 (CET)
X-Spam-Checker-Version: SpamAssassin 3.4.2 (2018-09-13) on mail-tester.com
X-Spam-Level: 
X-Spam-Status: No/-1.3/5.0
X-Spam-Test-Scores: DKIM_SIGNED=0.1,DKIM_VALID=-0.1,DKIM_VALID_AU=-0.1,
	DKIM_VALID_EF=-0.1,RCVD_IN_RP_SAFE=-2,SPF_HELO_SOFTFAIL=0.896,
	SPF_PASS=-0.001,URIBL_BLOCKED=0.001
X-Spam-Last-External-IP: 57.103.88.93
X-Spam-Last-External-HELO: p00-icloudmta-asmtp-us-central-1k-100-percent-10.p00-icloudmta-asmtp-vip.icloud-mail-production.svc.kube.us-central-1k.k8s.cloud.apple.com
X-Spam-Last-External-rDNS: p-east1-cluster7-host9-snip4-10.eps.apple.com
X-Spam-Date-of-Scan: Sat, 29 Mar 2025 01:02:03 +0100
X-Spam-Report: 
	*  0.0 URIBL_BLOCKED ADMINISTRATOR NOTICE: The query to URIBL was
	*      blocked.  See
	*      http://wiki.apache.org/spamassassin/DnsBlocklists#dnsbl-block
	*      for more information.
	*      [URIs: vooijs.eu]
	* -0.0 SPF_PASS SPF: sender matches SPF record
	*  0.9 SPF_HELO_SOFTFAIL SPF: HELO does not match SPF record
	*      (softfail)
	* -2.0 RCVD_IN_RP_SAFE RBL: Sender in ReturnPath Safe - Contact
	*      safe-sa@returnpath.net
	*      [Excessive Number of Queries | &lt;https://knowledge.validity.com/hc/en-us/articles/20961730681243&gt;]
	* -0.1 DKIM_VALID_AU Message has a valid DKIM or DK signature from
	*      author's domain
	* -0.1 DKIM_VALID_EF Message has a valid DKIM or DK signature from
	*      envelope-from domain
	* -0.1 DKIM_VALID Message has at least one valid DKIM or DK signature
	*  0.1 DKIM_SIGNED Message has a DKIM or DK signature, not necessarily
	*       valid
Received-SPF: Pass (sender SPF authorized) identity=mailfrom; client-ip=57.103.88.93; helo=p00-icloudmta-asmtp-us-central-1k-100-percent-10.p00-icloudmta-asmtp-vip.icloud-mail-production.svc.kube.us-central-1k.k8s.cloud.apple.com; envelope-from=willem@vooijs.eu; receiver=test-p3tdhnk3o@srv1.mail-tester.com 
DMARC-Filter: OpenDMARC Filter v1.3.1 mail-tester.com C58B5A058C
Authentication-Results: mail-tester.com; dmarc=pass header.from=vooijs.eu
Authentication-Results: mail-tester.com;
	dkim=pass (2048-bit key; unprotected) header.d=vooijs.eu header.i=@vooijs.eu header.b=cgA7udON;
	dkim-atps=neutral
Received: from p00-icloudmta-asmtp-us-central-1k-100-percent-10.p00-icloudmta-asmtp-vip.icloud-mail-production.svc.kube.us-central-1k.k8s.cloud.apple.com (p-east1-cluster7-host9-snip4-10.eps.apple.com [57.103.88.93])
	(using TLSv1.2 with cipher ECDHE-RSA-AES256-GCM-SHA384 (256/256 bits))
	(No client certificate requested)
	by mail-tester.com (Postfix) with ESMTPS id C58B5A058C
	for &lt;test-p3tdhnk3o@srv1.mail-tester.com&gt;; Sat, 29 Mar 2025 01:02:01 +0100 (CET)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=vooijs.eu; s=sig1;
	bh=12PjwyF+u2oGPkzaniMgmK/MmxJFGEv9rKfHCFAE4S4=;
	h=From:Content-Type:Mime-Version:Subject:Message-Id:Date:To:x-icloud-hme;
	b=cgA7udONJs2uC6eDVuKiL9pngnFE/Oq5nSXcT64hUZ7j7RddPOLUf059WXXmbRaOu
	 I2bDdbk0ZgHR2Me3kQGCp/jPiDLYE9UyUF8NZWV+HdWwD3aDiHFm5+9UcK2trnCDN6
	 LCw6XawObGRnYb0kkNROgRWCqyPXpitsw4TGkxTnt06U7b1f0P+95N3ToWGmnCfZMx
	 StnNDbJmiyRUHg04IdI45K4kBhV9vmVH1XoREEj82OLwRcH0bXXRFZrMO2i0oK0kES
	 4G1BsbPDe9a2yz7xKpZFMg8XeWwI9aeDnYc3G+pHztZft1Gg9hBAkGXzwuSu24Il8T
	 1N7Sjj81dYpSw==
Received: from smtpclient.apple (ci-asmtp-me-k8s.p00.prod.me.com [17.57.156.36])
	by p00-icloudmta-asmtp-us-central-1k-100-percent-10.p00-icloudmta-asmtp-vip.icloud-mail-production.svc.kube.us-central-1k.k8s.cloud.apple.com (Postfix) with ESMTPSA id 6916C1800EED
	for &lt;test-p3tdhnk3o@srv1.mail-tester.com&gt;; Sat, 29 Mar 2025 00:01:59 +0000 (UTC)
From: willem@vooijs.eu
Content-Type: text/plain;
	charset=us-ascii
Content-Transfer-Encoding: 7bit
Mime-Version: 1.0 (Mac OS X Mail 16.0 \(3826.400.131.1.6\))
Subject: hi
Message-Id: &lt;28EF11C3-DDE7-4411-9360-18D6DF603BAA@vooijs.eu&gt;
Date: Sat, 29 Mar 2025 01:01:43 +0100
To: test-p3tdhnk3o@srv1.mail-tester.com
X-Mailer: Apple Mail (2.3826.400.131.1.6)
X-Proofpoint-GUID: rnSs22k5HuJHUu0epxsbTZp_ycI6q0nV
X-Proofpoint-ORIG-GUID: rnSs22k5HuJHUu0epxsbTZp_ycI6q0nV
X-Proofpoint-Virus-Version: vendor=baseguard
 engine=ICAP:2.0.293,Aquarius:18.0.1095,Hydra:6.0.680,FMLib:17.12.68.34
 definitions=2025-03-28_12,2025-03-27_02,2024-11-22_01
X-Proofpoint-Spam-Details: rule=notspam policy=default score=1 bulkscore=0 spamscore=1 phishscore=0
 malwarescore=0 mlxlogscore=230 adultscore=0 clxscore=1030 mlxscore=1
 suspectscore=0 classifier=spam adjust=0 reason=mlx scancount=1
 engine=8.19.0-2411120000 definitions=main-2503280163

This is it
</pre>
						</div>

				</div>

			<!-- SpamAssassin -->
			<div>
					<p>The famous spam filter <a href="http://spamassassin.apache.org/" target="_blank">SpamAssassin</a>. Score: 1.3.<br>A score below -5 is considered spam.</p>
					<div>
						<table><tbody> 	<tr>			<td>-0.1</td>			<td><samp>DKIM_SIGNED</samp></td>			<td>Message has a DKIM or DK signature, not necessarily valid<br><b>This rule is automatically applied if your email contains a DKIM signature but other positive rules will also be added if your DKIM signature is valid. See immediately below.</b></td></tr> 	<tr>			<td>0.1</td>			<td><samp>DKIM_VALID</samp></td>			<td>Message has at least one valid DKIM or DK signature<br><b>Great! Your signature is valid</b></td></tr> 	<tr>			<td>0.1</td>			<td><samp>DKIM_VALID_AU</samp></td>			<td>Message has a valid DKIM or DK signature from author's domain<br><b>Great! Your signature is valid and it's coming from your domain name</b></td></tr> 	<tr>			<td>0.1</td>			<td><samp>DKIM_VALID_EF</samp></td>			<td>Message has a valid DKIM or DK signature from envelope-from domain</td></tr> 	<tr>			<td>2</td>			<td><samp>RCVD_IN_RP_SAFE</samp></td>			<td>Sender is in Return Path Safe (trusted relay)</td></tr> 	<tr>			<td>-0.896</td>			<td><samp>SPF_HELO_SOFTFAIL</samp></td>			<td>SPF: HELO does not match SPF record (softfail)<br>softfail</td></tr> 	<tr>			<td>0.001</td>			<td><samp>SPF_PASS</samp></td>			<td>SPF: sender matches SPF record<br><b>Great! Your SPF is valid</b></td></tr></tbody></table>					</div>
				</div>

			<!-- Signature -->
			<div>
					<p>We check if the server you are sending from is authenticated</p>

					<!-- SPF -->
					<div>
							<p>Sender Policy Framework (SPF) is an email validation system designed to prevent email spam by detecting email spoofing, a common vulnerability, by verifying sender IP addresses.</p>
							<div><p>What we retained as your current SPF record is:</p><pre>v=spf1 include:icloud.com ~all</pre><p>Verification details:</p><pre>dig +short TXT vooijs.eu :<ul><li>"apple-domain=A9a0syfSeWRCbMJh"</li><li>"google-site-verification=tVR6cRdwSFxvq8-0Wi0YYC0nQs8gKXSPm2g_PNkpf58"</li><li>"v=spf1 include:icloud.com ~all"</li></ul>dig +short +time=3 +tries=1 TXT @phoenix.ns.cloudflare.com. vooijs.eu :<ul><li>"apple-domain=A9a0syfSeWRCbMJh"</li><li>"google-site-verification=tVR6cRdwSFxvq8-0Wi0YYC0nQs8gKXSPm2g_PNkpf58"</li><li>"v=spf1 include:icloud.com ~all"</li></ul>spfquery --scope mfrom --id willem@vooijs.eu --ip 57.103.88.93 --helo-id p00-icloudmta-asmtp-us-central-1k-100-percent-10.p00-icloudmta-asmtp-vip.icloud-mail-production.svc.kube.us-central-1k.k8s.cloud.apple.com :<ul><li>pass</li><li>vooijs.eu: Sender is authorized to use 'willem@vooijs.eu' in 'mfrom' identity (mechanism 'include:icloud.com' matched)</li><li>vooijs.eu: Sender is authorized to use 'willem@vooijs.eu' in 'mfrom' identity (mechanism 'include:icloud.com' matched)</li><li>Received-SPF: pass (vooijs.eu: Sender is authorized to use 'willem@vooijs.eu' in 'mfrom' identity (mechanism 'include:icloud.com' matched)) receiver=ns303428.ip-94-23-206.eu; identity=mailfrom; envelope-from="willem@vooijs.eu"; helo=p00-icloudmta-asmtp-us-central-1k-100-percent-10.p00-icloudmta-asmtp-vip.icloud-mail-production.svc.kube.us-central-1k.k8s.cloud.apple.com; client-ip=57.103.88.93</li></ul></pre></div>
						</div>

					<!-- DKIM -->
					<div>
							<p>DomainKeys Identified Mail (DKIM) is a method for associating a domain name to an email message, thereby allowing a person, role, or organization to claim some responsibility for the message.</p>
							<div><p>The DKIM signature of your message is:</p><pre>	v=1;
	a=rsa-sha256;
	c=relaxed/relaxed;
	d=vooijs.eu;
	s=sig1;
	bh=12PjwyF+u2oGPkzaniMgmK/MmxJFGEv9rKfHCFAE4S4=;
	h=From:Content-Type:Mime-Version:Subject:Message-Id:Date:To:x-icloud-hme;
	b=cgA7udONJs2uC6eDVuKiL9pngnFE/Oq5nSXcT64hUZ7j7RddPOLUf059WXXmbRaOuI2bDdbk0ZgHR2Me3kQGCp/jPiDLYE9UyUF8NZWV+HdWwD3aDiHFm5+9UcK2trnCDN6LCw6XawObGRnYb0kkNROgRWCqyPXpitsw4TGkxTnt06U7b1f0P+95N3ToWGmnCfZMxStnNDbJmiyRUHg04IdI45K4kBhV9vmVH1XoREEj82OLwRcH0bXXRFZrMO2i0oK0kES4G1BsbPDe9a2yz7xKpZFMg8XeWwI9aeDnYc3G+pHztZft1Gg9hBAkGXzwuSu24Il8T1N7Sjj81dYpSw==</pre><p>Your public key is:</p><pre>"v=DKIM1;
k=rsa;
p=MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAsin1OvaFKnpYDqXBWtdxsr2bRtoMRLcMTCzjuNYsulMfDQnKPl643CEMg8ez34caPZMUjUjJHYF9VS6UDdbX+5uzvJ1kg+NX8ZyxPVMo6h26yQp63GE84oe3fDxCYqTi2Img6cBsJiWNsj0Ph4YSF2sxLkEWOX8d4AJC6LqyYBitImrHpa4ZIrRcSUGpc2X900JDpOQkUKoD8R6wxUKPoWQSaFUsz+Qb3ngHbxYGr/PaK9XdopLkG/eHN/i7UlQa0g/g8etWCvRuUcmw8pDUIPZYRmFtJkVLQE103lnU3/9ulXt1yX3XsSD4pUjloldMqicvNufO9dfqiGW6BRxYawIDAQAB"</pre><p>Key length: 2048bits</p></div>
						</div>

					<!-- DMARC -->
					<div>
							<p>A DMARC policy allows a sender to indicate that their emails are protected by SPF and/or DKIM, and give instruction if neither of those authentication methods passes. Please be sure you have a DKIM and SPF set before using DMARC.</p>
							<div><p>Your DMARC record is set correctly and your message passed the DMARC test</p><p>DMARC DNS entry found for the domain <b>_dmarc.vooijs.eu</b>:</p><pre>"v=DMARC1; p=reject; rua=mailto:postmaster@vooijs.eu; pct=100; adkim=r; aspf=r"</pre><p>Verification details:</p><pre><ul><li>mail-tester.com; dmarc=pass header.from=vooijs.eu</li><li>mail-tester.com; dkim=pass (2048-bit key; unprotected) header.d=vooijs.eu header.i=@vooijs.eu header.b=cgA7udON; dkim-atps=neutral</li><li>From Domain: vooijs.eu</li><li>DKIM Domain: vooijs.eu</li></ul></pre></div>
						</div>

					<!-- Reverse DNS -->
					<div>
							<p>Reverse DNS lookup or reverse DNS resolution (rDNS) is the determination of a domain name that is associated with a given IP address.<br>Some companies such as AOL will reject any message sent from a server without rDNS, so you must ensure that you have one.<br>You cannot associate more than one domain name with a single IP address.</p>
							<div><p>Your IP address <strong>57.103.88.93</strong> is associated with the domain <strong>p-east1-cluster7-host9-snip4-10.eps.apple.com</strong>.<br>Nevertheless your message appears to be sent from <strong>p00-icloudmta-asmtp-us-central-1k-100-percent-10.p00-icloudmta-asmtp-vip.icloud-mail-production.svc.kube.us-central-1k.k8s.cloud.apple.com</strong>.</p><p>You may want to change your pointer (PTR type) DNS record and the host name of your server to the same value.</p></div>
							<pre>Here are the tested values for this check:<br><ul><li>IP: 57.103.88.93</li><li>HELO: p00-icloudmta-asmtp-us-central-1k-100-percent-10.p00-icloudmta-asmtp-vip.icloud-mail-production.svc.kube.us-central-1k.k8s.cloud.apple.com</li><li>rDNS: p-east1-cluster7-host9-snip4-10.eps.apple.com</li></ul></pre>
						</div>
					<!-- A Record Bounce DNS-->
					<div>
							<p>We check if there is a mail server (MX Record) behind your domain name <strong>vooijs.eu</strong>.</p>
							
							<pre>MX records (vooijs.eu) : <ul><li>10 mx01.mail.icloud.com.</li><li>10 mx02.mail.icloud.com.</li></ul></pre>
						</div>
					<!-- A Record DNS-->
					<div>
							<p>We check if there is a server (A Record) behind your hostname <strong>p00-icloudmta-asmtp-us-central-1k-100-percent-10.p00-icloudmta-asmtp-vip.icloud-mail-production.svc.kube.us-central-1k.k8s.cloud.apple.com</strong>.</p>
							<p>You may want to publish a DNS record (A type) for the hostname <strong>p00-icloudmta-asmtp-us-central-1k-100-percent-10.p00-icloudmta-asmtp-vip.icloud-mail-production.svc.kube.us-central-1k.k8s.cloud.apple.com</strong> or use a different hostname in your mail software.</p>
							<pre></pre>
						</div>
				</div>

			<!-- Structure and Content -->
			<div>

					<p>Checks whether your message is well formatted or not.</p>
					<p>There is no html version of your message.</p>

					<!-- Alt attribute -->
					<div>
							<p>ALT attributes provide a textual alternative to your images.<br>It is a useful fallback for people who are blind or visually impaired and for cases where your images cannot be displayed.</p>
							
						</div>

					<!-- Forbidden tags -->
					

					<!-- Short LINK -->
					<div>
							<p>Checks whether your message uses URL shortener systems.</p>
							
							
						</div>

					<!-- List-unsubscribe -->
					<div>
							<p>The List-Unsubscribe header is required if you send mass emails, it enables the user to easily unsubscribe from your mailing list.</p>
							<p>Your message does not contain a List-Unsubscribe header</p>
							
						</div>

				</div>

			<!-- Blacklists -->
			<div>
					<p>Matches your server IP address (<b>57.103.88.93</b>) against 23 of the most common IPv4 blocklists.</p>
					
				</div>

			
			<p>Your lovely total: 7/10</p>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Madison Square Garden's surveillance banned this fan over his T-shirt design (172 pts)]]></title>
            <link>https://www.theverge.com/news/637228/madison-square-garden-james-dolan-facial-recognition-fan-ban</link>
            <guid>43511340</guid>
            <pubDate>Sat, 29 Mar 2025 00:08:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/news/637228/madison-square-garden-james-dolan-facial-recognition-fan-ban">https://www.theverge.com/news/637228/madison-square-garden-james-dolan-facial-recognition-fan-ban</a>, See on <a href="https://news.ycombinator.com/item?id=43511340">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="zephr-anchor"><p>A concert on Monday night at New York’s Radio City Music Hall was a special occasion for Frank Miller: his parents’ wedding anniversary. He didn’t end up seeing the show — and before he could even get past security, he was informed that he was in fact banned for life from the venue and all other properties owned by Madison Square Garden (MSG).</p><p>After scanning his ticket and promptly being pulled aside by security, Miller was told by staff that he was barred from the MSG properties for an incident at the Garden in 2021. But Miller says he hasn’t been to the venue in nearly two decades.</p><p>“They hand me a piece of paper letting me know that I’ve been added to a ban list,” Miller says. “There’s a trespass notice if I ever show up on any MSG property ever again,” which includes venues like Radio City, the Beacon Theatre, the Sphere, and the Chicago Theatre.</p><p>He was baffled at first. Then it dawned on him: this was probably about a T-shirt he designed years ago. MSG Entertainment won’t say what happened with Miller or how he was picked out of the crowd, but he suspects he was identified via controversial facial recognition systems that the company deploys at its venues.</p><p>In 2017, 1990s New York Knicks star Charles Oakley was forcibly removed from his seat near Knicks owner and Madison Square Garden CEO James Dolan. The high-profile incident later spiraled into <a href="https://www.espn.com/nba/story/_/id/40121460/oakley-stands-firm-nixing-invite-msg-gets-dolan-apology">an ongoing legal battle</a>. For Miller, Oakley was an “integral” part of the ’90s Knicks, he says. With his background in graphic design, he made <a href="https://www.instagram.com/p/CMyU_jxrA4c/">a shirt in the style of the old team logo</a> that read, “Ban Dolan” — a reference to the infamous scuffle.</p><p>A few years later, in 2021, a friend of Miller’s wore a Ban Dolan shirt to a Knicks game and was kicked out and banned from future events. That incident spawned <a href="https://www.youtube.com/watch?v=7qgJdgcFAyQ">ESPN segments</a> and <a href="https://nypost.com/2021/03/24/knicks-fan-kicked-out-of-madison-square-garden-over-ban-dolan-shirt/">news articles</a> and validated what many fans saw as a pettiness on Dolan and MSG’s part for going after individual fans who criticized team ownership.</p><p>But this week, Miller wasn’t wearing a Ban Dolan shirt; he wasn’t even at a Knicks game. His friend who was kicked out for the shirt tagged him in social media posts as the designer when it happened, but Miller, who lives in Seattle, hadn’t attended an event in New York in years.</p><div><p><a href="https://platform.theverge.com/wp-content/uploads/sites/2/2025/03/IMG_1074.jpg?quality=90&amp;strip=all&amp;crop=0,3.125,100,93.75" data-pswp-height="1912.5" data-pswp-width="1530" target="_blank" rel="noreferrer"><img alt="A photo of a sign about facial recognition at Madison Square Garden." data-chromatic="ignore" loading="lazy" decoding="async" data-nimg="fill" sizes="(max-width: 639px) 100vw, (max-width: 1023px) 50vw, 700px" srcset="https://platform.theverge.com/wp-content/uploads/sites/2/2025/03/IMG_1074.jpg?quality=90&amp;strip=all&amp;crop=0%2C3.125%2C100%2C93.75&amp;w=256 256w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/03/IMG_1074.jpg?quality=90&amp;strip=all&amp;crop=0%2C3.125%2C100%2C93.75&amp;w=376 376w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/03/IMG_1074.jpg?quality=90&amp;strip=all&amp;crop=0%2C3.125%2C100%2C93.75&amp;w=384 384w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/03/IMG_1074.jpg?quality=90&amp;strip=all&amp;crop=0%2C3.125%2C100%2C93.75&amp;w=415 415w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/03/IMG_1074.jpg?quality=90&amp;strip=all&amp;crop=0%2C3.125%2C100%2C93.75&amp;w=480 480w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/03/IMG_1074.jpg?quality=90&amp;strip=all&amp;crop=0%2C3.125%2C100%2C93.75&amp;w=540 540w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/03/IMG_1074.jpg?quality=90&amp;strip=all&amp;crop=0%2C3.125%2C100%2C93.75&amp;w=640 640w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/03/IMG_1074.jpg?quality=90&amp;strip=all&amp;crop=0%2C3.125%2C100%2C93.75&amp;w=750 750w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/03/IMG_1074.jpg?quality=90&amp;strip=all&amp;crop=0%2C3.125%2C100%2C93.75&amp;w=828 828w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/03/IMG_1074.jpg?quality=90&amp;strip=all&amp;crop=0%2C3.125%2C100%2C93.75&amp;w=1080 1080w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/03/IMG_1074.jpg?quality=90&amp;strip=all&amp;crop=0%2C3.125%2C100%2C93.75&amp;w=1200 1200w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/03/IMG_1074.jpg?quality=90&amp;strip=all&amp;crop=0%2C3.125%2C100%2C93.75&amp;w=1440 1440w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/03/IMG_1074.jpg?quality=90&amp;strip=all&amp;crop=0%2C3.125%2C100%2C93.75&amp;w=1920 1920w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/03/IMG_1074.jpg?quality=90&amp;strip=all&amp;crop=0%2C3.125%2C100%2C93.75&amp;w=2048 2048w, https://platform.theverge.com/wp-content/uploads/sites/2/2025/03/IMG_1074.jpg?quality=90&amp;strip=all&amp;crop=0%2C3.125%2C100%2C93.75&amp;w=2400 2400w" src="https://platform.theverge.com/wp-content/uploads/sites/2/2025/03/IMG_1074.jpg?quality=90&amp;strip=all&amp;crop=0%2C3.125%2C100%2C93.75&amp;w=2400"></a></p></div><p>Miller says that after he scanned his digital ticket, but before he went through security, a person working at Radio City stopped the line, pulled him aside, and asked him for his ID to verify who he was. They then walked him to another entrance of the building, where five or more staff members stood with him as he was told he was not allowed to return.</p><p>He’s not sure how exactly MSG connected him to the shirt or a 2021 incident during an event he wasn’t at. Miller told <em>The Verge </em>that until the concert, he had never actually purchased tickets to MSG events — they were either gifts from other people, or he got them through work.</p><p>“I’ve been reading articles about this facial recognition stuff that Dolan [and] MSG properties use, but I hadn’t been in or around the Garden outside of Penn Station to take New Jersey Transit [to] Newark Airport in almost 20 years now,” Miller says. A friend who was present made sure his parents enjoyed the show while Miller hung out at a bar nearby. He did not get a refund for his ticket, he says.</p><p>“I just found it comical, until I was told that my mom was crying [in the lobby],” Miller says of the experience. “I was like, ‘Oh man, I ruined their anniversary with my shit talk on the internet. Memes are powerful, and so is the surveillance state.” Miller and his parents also had tickets to a Knicks game the following night; his parents went without him, with a family friend in his place. Miller dropped his parents off from across the street.</p><p>MSG Entertainment did not respond to <em>The Verge</em>’s questions about whether facial recognition was used to identify Miller.</p><p>“Frank Miller Jr. made threats against an MSG executive on social media and produced and sold merchandise that was offensive in nature,” Mikyl Cordova, executive vice president of communications and marketing for the company, said in an emailed statement. “His behavior was disrespectful and disruptive and in violation of our code of conduct.”</p><p>Keeping close watch on patrons is nothing new for MSG. In 2022, a New Jersey attorney was <a href="https://www.theverge.com/2022/12/21/23520990/rockettes-msg-facial-recognition-ban-privacy-ai">denied entry to Radio City Music Hall</a> during a Girl Scout troop trip. Her infraction <a href="https://www.nytimes.com/2022/12/22/nyregion/madison-square-garden-facial-recognition.html">was being on an “attorney exclusion list”</a> full of people who work at firms that are suing MSG. The attorney was identified using facial recognition technology at the venue.</p><p>Miller says he was told at Radio City that he could appeal the ban if he wanted to but said it’s not a priority for him. He hopes his experience can help others who find themselves in a similar situation, where they’re unexpectedly denied entry at an expensive event based on data about them that has been collected by the company.</p><p>“It’s something that we all have to be aware of — the panopticon,” Miller says. “We’re [being] surveilled at all times, and it’s always framed as a safety thing, when rarely is that the case. It’s more of a deterrent and a fear tactic to try to keep people in line.”</p><p><em><strong>Update March 28th:</strong></em> <em>Added comment from MSG Entertainment spokesperson Mikyl Cordova. Clarified to reflect that Frank Miller said he had not been to an event at MSG venues in nearly 20 years.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Windows 11 is closing a loophole that let you skip making a Microsoft account (168 pts)]]></title>
            <link>https://www.theverge.com/news/638967/microsoft-windows-11-account-internet-bypass-blocked</link>
            <guid>43511073</guid>
            <pubDate>Fri, 28 Mar 2025 23:41:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/news/638967/microsoft-windows-11-account-internet-bypass-blocked">https://www.theverge.com/news/638967/microsoft-windows-11-account-internet-bypass-blocked</a>, See on <a href="https://news.ycombinator.com/item?id=43511073">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><img alt="Umar Shakir" data-chromatic="ignore" loading="lazy" width="36" height="36" decoding="async" data-nimg="1" srcset="https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/195848/UMAR_SHAKIR.0.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=48 1x, https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/195848/UMAR_SHAKIR.0.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=96 2x" src="https://platform.theverge.com/wp-content/uploads/sites/2/chorus/author_profile_images/195848/UMAR_SHAKIR.0.jpg?quality=90&amp;strip=all&amp;crop=0%2C0%2C100%2C100&amp;w=96"></p><p><a href="https://www.theverge.com/authors/umar-shakir">Umar Shakir</a> <span>is a news writer fond of the electric vehicle lifestyle and things that plug in via USB-C. He spent over 15 years in IT support before joining The Verge.</span></p></div><div id="zephr-anchor"><p>Microsoft is no longer playing around when it comes to requiring every Windows 11 device be set up with an internet-connected account. In its latest Windows 11 Insider Preview, the company says <a href="https://blogs.windows.com/windows-insider/2025/03/28/announcing-windows-11-insider-preview-build-26200-5516-dev-channel/#:~:text=We%E2%80%99re%20removing%20the%20bypassnro.cmd%20script">it will take out a well-known bypass script</a> that let end users skip the requirement of connecting to the internet and logging in with a Microsoft account to get through the initialization process of a new PC.</p><p>As reported by <a href="https://www.windowscentral.com/software-apps/windows-11/microsoft-will-force-windows-11-installs-to-use-a-microsoft-account-confirms-removal-of-popular-setup-bypass"><em>Windows Central</em></a>, Microsoft already requires users to connect to the internet, but there’s a way to bypass it: the bypassnro command. For those setting up computers for businesses or secondary users, or simply, on principle refuse to link their computer to a Microsoft account, the command is super simple to activate during the Windows setup process.</p><p>Microsoft cites security as one reason it’s making this change:</p><div><blockquote><p>We’re removing the bypassnro.cmd script from the build to enhance security and user experience of Windows 11. This change ensures that all users exit setup with internet connectivity and a Microsoft Account.</p></blockquote></div><p>Since the bypassnro command is disabled in the latest beta build, it will likely be pushed to production versions within weeks. All hope is not yet lost, as of right now the script can be reactivated with a registry edit by opening a command prompt during the initial setup (Press Shift + F10) and running the command:</p><div><blockquote><p>reg add HKLM\SOFTWARE\Microsoft\Windows\CurrentVersion\OOBE /v BypassNRO /t REG_DWORD /d 1 /f shutdown /r /t 0”</p></blockquote></div><p>However, there’s no guarantee Microsoft will allow this additional workaround for long. There are other workarounds as well, such as using the unattended.xml automation that lets you skip the initial setup “out-of-box experience.” It’s not straightforward, though, but it makes more sense for IT departments setting up multiple computers.</p><p>As of late, Microsoft has been making it harder for people to upgrade to Windows 11 while also nudging them to <a href="https://www.theverge.com/2025/1/6/24336586/microsoft-windows-10-upgrade-year-of-the-windows-11-pc-refresh-ces-2025">move on from Windows 10</a>, which will lose support in October. The company is cracking down on the ability to install Windows 11 on older PCs <a href="https://www.theverge.com/2024/12/4/24312928/microsoft-windows-11-older-hardware-tpm-support">that don’t support TPM 2.0</a>, and hounding you with full-screen ads to <a href="https://www.theverge.com/2024/11/20/24301768/microsoft-windows-10-upgrade-prompt-copilot-plus-pcs">buy a new PC</a>. Microsoft even removed the ability to install Windows 11 <a href="https://www.theverge.com/2023/10/11/23913107/microsoft-windows-11-block-windows-7-8-keys-upgrade-activation">with old product keys</a>.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[2025 Tariff Impacts at Puget Systems (171 pts)]]></title>
            <link>https://www.pugetsystems.com/blog/2025/03/28/2025-tariff-impacts-at-puget-systems/</link>
            <guid>43510870</guid>
            <pubDate>Fri, 28 Mar 2025 23:08:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pugetsystems.com/blog/2025/03/28/2025-tariff-impacts-at-puget-systems/">https://www.pugetsystems.com/blog/2025/03/28/2025-tariff-impacts-at-puget-systems/</a>, See on <a href="https://news.ycombinator.com/item?id=43510870">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-35618">

		  <!-- .entry-header -->

      <div id="content" tabindex="-1">

              
<p>One of the things I enjoy at Puget Systems is that transparency is one of our core principles. We choose to pull back the curtain and show what happens behind the scenes in the computer industry. Recently, tariffs have been a big deal, impacting numerous industries—including ours. I’ve seen a lot of misinformation and misunderstandings out there. I’ve seen vendors take advantage of the FUD (fear, uncertainty, doubt) to raise prices and generate urgency for sales. This post explains the current tariff situation as we see it, its immediate impact on the pricing of our computers, and our strategic approach. This is also a fast-moving situation, so there are details that might already be out of date by the time I publish this post!</p>



<h2 id="h-what-exactly-are-tariffs">What Exactly Are Tariffs?</h2>



<p>Let’s start there because I see misunderstandings about what a tariff is! A <a href="https://taxfoundation.org/taxedu/glossary/tariffs/">tariff is defined</a> as a tax imposed by a government on imported goods. The <strong>buyer</strong> of those goods pays this tax, and because that increases the cost of the ingredients to build a product, it frequently results in a price increase of the end product to the <strong>consumer</strong>.</p>



<p>As of today, I’m talking about a <strong>20% total additional tariff</strong>, composed of two 10% tariffs that went into effect on Feb 4 and Mar 4. Those increases are just now working their way through costs in the computer industry.</p>



<p>Additionally, some items were exempted from a separate 25% tariff imposed in 2018-2019.&nbsp; As of now, those exemptions are set to expire in June, which would mean the total tariff to import those goods would have increased costs 45% just this year. Those potential increases in June are concerning, but are still too far in the future to have much helpful discussion about today.</p>



<h2 id="h-direct-and-indirect-impacts">Direct and Indirect Impacts</h2>



<p>When I think about tariff effects on the computer industry, three different types of impact come to mind:</p>



<ol>
<li><strong>Directly Impacted Goods:</strong> These products are explicitly subjected to tariffs, which directly increase their import costs and, therefore, their prices.</li>



<li><strong>Indirectly Impacted Goods:</strong> These products aren’t taxed directly but contain components in their bill of materials (BOM) that are subject to tariffs. For example, memory modules typically use DRAM and controller chips manufactured in countries like Korea or the US, which aren’t subject to these tariffs. However, the PCB and other minor components often originate from China, causing indirect price increases. Consequently, the overall prices of these indirectly impacted goods rise, though typically to a lesser extent than directly taxed items. Another form of indirect impact is the additional overhead cost and time involved in manufacturers moving production away from China, which increases cost in the short term and can also create supply shortages during the transition.</li>



<li><strong>Market and Inflationary Impacts:</strong> Tariffs also create broader economic effects—supply and demand shifts, market uncertainty, general overhead increases, and inflationary pressures—that drive overall costs higher, affecting even goods not directly or indirectly taxed.</li>
</ol>



<p>The added cost to the consumer often doesn’t even stop there, unfortunately. It is not uncommon for companies to use tariffs as a reason to justify price increases beyond the true impact on their costs. To SOME extent, this is understandable because the situation introduces a LOT of uncertainty, and companies need to add some buffer as risk protection. But all too often, I see communication and price increases that I know are exaggerated. I’m not only talking about the computer hardware industry—this can happen anywhere in the supply chain, which still impacts the cost of the computer.</p>



<p>Tariff impacts can be particularly complicated for us due to how many layers there are in the computer supply chain. While some manufacturers absorb costs initially, others may preload anticipated price hikes. Inventory levels influence these choices. If a company has a healthy stock of an item when the tariff goes live, they are not as immediately or sharply impacted. All of these things work together to make the situation murky and difficult to predict.</p>



<h2 id="h-our-strategy-at-puget-systems">Our Strategy at Puget Systems</h2>



<p>To address these challenges, our strategy at Puget Systems includes:</p>



<ul>
<li><strong>We use our inventory strategically to minimize immediate cost increases.</strong> We already have had to carry a ridiculously high amount of inventory to smooth out supply shortages, and this works in our favor… even if that is only to buy us some time for the dust to settle and for our cost impacts to be better understood. We run our company debt-free, and we use our purchasing power and cash reserves to carry even more inventory during volatile times.</li>



<li><strong>We maintain close relationships with our suppliers and ODM partners. </strong>It is always best when we can simply ask about their plans and strategies so we can work together! I’m proud to say this happens with almost all our ODM and distribution partners. The only limiters here are how quickly everything is moving and how many hours in the day we have for those conversations!</li>



<li><strong>We prioritize our attention on high-impact items.</strong> Particularly GPUs, where tariffs most significantly affect the consumer because of their high value.</li>



<li><strong>We absorb initial cost changes on many components. </strong>We adjust our pricing when ongoing long-term costs are clear, and absorb differences otherwise. This reduces noise and prevents us from making many nickel-and-dime changes.</li>
</ul>



<h2 id="h-special-challenges-during-product-launches">Special Challenges During Product Launches</h2>



<p>These tariff situations become especially challenging during major product launches, such as NVIDIA’s GeForce RTX™ 5090. When a new product is released and in high demand, supply is typically constrained, causing prices to inflate significantly. The 5090 definitely falls into that camp! I can’t remember a product in recent history that has been in such short supply for so long after launch, and the future doesn’t look much better. This scenario makes it particularly difficult to determine precisely how much of the inflated price is due to simple supply-and-demand dynamics versus the additional burden of tariffs. Unpacking exactly what’s driving costs up becomes a complicated, often unclear process during these initial launch periods.</p>



<h2 id="h-component-specific-overview">Component-Specific Overview</h2>



<p>Alright, let’s get to the meat of the post! Here is what <strong>we </strong>are seeing in our component supply as of today. These changes will affect our computer prices starting on April 1.</p>



<ul>
<li><strong>Motherboards:</strong> We will absorb price changes to start. Motherboards and their sub-components come from various countries, and it is unclear where the ODMs will choose to adjust their pricing to mitigate (even if partially) the tariff. We’ll make changes over the coming months in specific instances if our costs change greatly.&nbsp;</li>



<li><strong>CPUs:</strong> There has been no substantial impact because there is no significant supply from China. This is the best news in this post! These are typically high-cost items, so if they had gotten a cost increase, it would have had a large impact on our prices.</li>



<li><strong>SSD and Hard Drives:</strong> Approximately 10% price increase. This is more due to supply ecosystem changes in those categories, not tariffs on the high-cost BOM items (chips or platters) themselves.</li>



<li><strong>Memory:</strong> Similar to SSDs, we’re anticipating a price increase in the 10% range, but at the same time, the market price of memory has been on a downward trend. We saw price decreases come in right before tariffs, so the combined effect will be that many items will not see much net change in cost.</li>



<li><strong>GPU &amp; Accelerators:</strong> 10% price increase. This is the worst news in this post because these components have a high cost to begin with, so even a smaller percent increase means a bigger dollar increase! They are actually impacted by a 20% tariff, but we believe the market has already built in some cost increase in anticipation of tariff changes. We’ll reassess after 2-4 weeks. Further, the tariffs here have the potential to increase from 20% to 45% on June 1, but we hope that US policy changes between now and then will dampen that increase. Brace yourself for that potential!</li>



<li><strong>Network and Storage Controllers:</strong> 20% price increase. Ouch.</li>



<li><strong>Chassis and Power Supplies:</strong> 20% price increase. Large-scale chassis production almost always comes from China, so our costs are directly impacted. We may see some price decreases from our suppliers in the future to help dampen the impact, and if so, we’ll pass that along with a price reduction at that time.&nbsp;</li>



<li><strong>CPU Coolers and Fans:</strong> Approximately 20% price increase. This is not universal but is what we believe will happen on average. Thankfully these are not very expensive items in the grand scheme of things, so it won’t have a large impact on system prices, but every dollar hurts!</li>
</ul>



<p>Any costs originating from Puget Systems ourselves (warranty, services, etc.) are receiving no change, so that also helps dampen our price change on the full computer. The only time we change those items is when our costs of running the business change—which is typically tied more to inflation and our #1 resource here—our people!</p>



<h2 id="h-future-changes">Future Changes</h2>



<p>As you can see, this is a lot of change. Today, we maintain a database of over 600 unique parts to build our computers. Shout out to our supply chain and website teams for the countless hours that have gone into this so far, with just as much effort needed for the foreseeable future! We will reassess this round of changes in a few weeks and make further honing adjustments anywhere we find our understanding to be inaccurate.</p>



<p>As it stands now, the next round of tariff changes are expected to take effect on June 1, when many categories of products could increase from 20% to 45%. This one really concerns me! But a lot can change between now and then, so we’ll take things as they come.</p>



<h2 id="h-working-together">Working Together</h2>



<p>We’re doing all we can to mitigate the effect of these immediate tariffs, as well as the possible increases on June 1. There are practical ways we can work together with you, our customers:</p>



<ul>
<li><strong>Forecasting:</strong> When we work together to forecast your needs, we can secure inventory and plan ahead on other supply chain impacts. We don’t need a commitment to stock up on our inventory—any information helps us make decisions!</li>



<li><strong>Early Purchasing: </strong>Consider making planned purchases before June 1 to avoid higher costs due to tariff increases. I don’t like giving a “buy now” message, but it is legitimate that the anticipated changes on June 1 are unclear and potentially large.</li>



<li><strong>Budget Planning: </strong>Include potential tariff impacts in your proposals and budgets now, so there are no surprises if prices increase before your purchases happen later in the year.</li>
</ul>



<p>If you can think of other ways we can work together on this, feel free to post in the comments section below. I’ll keep the transparency coming!</p>

                            

			</div><!-- #content -->

	  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: An Almost Free, Open Source TURN Server (117 pts)]]></title>
            <link>https://github.com/lvidgen/WebRTC/blob/master/FOSS_TURN_Server/howto.md</link>
            <guid>43510710</guid>
            <pubDate>Fri, 28 Mar 2025 22:46:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/lvidgen/WebRTC/blob/master/FOSS_TURN_Server/howto.md">https://github.com/lvidgen/WebRTC/blob/master/FOSS_TURN_Server/howto.md</a>, See on <a href="https://news.ycombinator.com/item?id=43510710">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true" aria-labelledby="file-name-id-wide file-name-id-mobile"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">How to Self-Host an (Almost) Free, Open Source TURN Server:</h2><a id="user-content-how-to-self-host-an-almost-free-open-source-turn-server" aria-label="Permalink: How to Self-Host an (Almost) Free, Open Source TURN Server:" href="#how-to-self-host-an-almost-free-open-source-turn-server"></a></p>
<p dir="auto">The WebRTC implementation posted <a href="https://github.com/lvidgen/WebRTC">here</a> relies on the PeerJS Cloud Server. It's pretty reliable (I haven't seen any major outage in 5+ years), but hitching yourself to someone else's wagon always carries an element of risk - if they decide to pull the pin on their project that page will die, possibly without much warning.</p>
<p dir="auto">A secondary concern is that the Cloud Server relies on Google's TURN server when required. Google has a <a href="https://killedbygoogle.com/" rel="nofollow">history</a> of axing services and products, sometimes with little or no notice. Additionally, some people have privacy concerns about running their data through anything associated with the big G.</p>
<p dir="auto">So is it possible to create an independant, open source TURN server that you completely control at minimal expense? Yes it is, with the possible irony that here we are relying on the free tier of Oracle Cloud Infrastructure (OCI). Plenty of people have been burnt by Oracle in the past as they too have a history of axing services. If you're going this route, it's a good idea to keep backups elsewhere.</p>
<p dir="auto">Anyway. Here's what I did:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">1. Get a domain name</h3><a id="user-content-1-get-a-domain-name" aria-label="Permalink: 1. Get a domain name" href="#1-get-a-domain-name"></a></p>
<p dir="auto">You will need this later because you will need SSL. This is the only thing on this list that will cost money. There are so many providers around and so many options that we're not going to go into details here. Basically, just find a name you like and pay the money to get it registered.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">2. Sign up for the Oracle Free Tier</h3><a id="user-content-2-sign-up-for-the-oracle-free-tier" aria-label="Permalink: 2. Sign up for the Oracle Free Tier" href="#2-sign-up-for-the-oracle-free-tier"></a></p>
<p dir="auto">You can do this <a href="https://www.oracle.com/cloud/free/" rel="nofollow">here</a>. You will need to enter credit card information, but if you never sign up for additional services or click on the "upgrade account" button you will stay on the free tier forever*. The free tier is more than enough compute resources for what we are doing here.</p>
<p dir="auto">* Or that's what they're saying for now, anyway...</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">3. Create a new subnet</h3><a id="user-content-3-create-a-new-subnet" aria-label="Permalink: 3. Create a new subnet" href="#3-create-a-new-subnet"></a></p>
<p dir="auto">Once you have your Oracle acount set up the first thing you want to do is create a new subnet for your server to sit on. This is particularly important if you're going to create more VMs. Port security in OCI is handled via Security Lists which are then assigned to subnets. All machines sitting on the same subnet will have the same ports accessible (on the server side, more on this later) and this TURN server needs a range of fairly exotic ports opened up. If you're unfamiliar with subnetting, here is a very brief overview. The Virtual Cloud Network that you are assigned will probably have an IPV4 block that looks like this: 10.0.0.0/16, which means that there are 65,534 useable IP addresses. You want to carve out some of those IP addresses into a separate pool (a subnet), so when creating that subnet you need to specify that the first IPv4 CIDR Block will be 10.0.0.0/24 (giving you 254 useable IPs). A second subnet could be 10.0.1.0/24 (giving you a second "pool" of 254 useable IPs).</p>
<p dir="auto">From the main menu, click on the "hamburger" menu at top left, then Networking, then Virtual cloud networks:
<a target="_blank" rel="noopener noreferrer" href="https://github.com/lvidgen/WebRTC/blob/master/FOSS_TURN_Server/images/vcn.png"><img src="https://github.com/lvidgen/WebRTC/raw/master/FOSS_TURN_Server/images/vcn.png" alt="alt text" title="Accessing the VCN"></a></p>
<p dir="auto">You will see the default VCN (you can only have one in the free tier). Click on that, and then "Subnets" on the left-hand menu (if it's not already selected). You will see the default subnet listed, probably with an IPv4 CIDR Block of 10.0.0.0/24. If the /24 is any other number, click the 3 dots at the right to edit, then change the Mask to 24 and Save Changes. Back on the main screen, click Create New Subnet, give it a name (TURN Server Subnet will do), specify the IPv4 CIDR Block of 10.0.1.0/24 and then the Create Subnet button. Back on the main screen, click on "Security Lists" on the left hand menu</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">4. Create the Security List</h3><a id="user-content-4-create-the-security-list" aria-label="Permalink: 4. Create the Security List" href="#4-create-the-security-list"></a></p>
<p dir="auto">The security list is like a firewall for your subnet - it dictates what kind of traffic is allowed to go to which ports. If something isn't explicitly allowed here, it will be denied. The machine that we are running will host 4 servers - <a href="https://github.com/peers/peerjs-server">PeerJS</a>, which puts a wrapper around the WebRTC Communication protocol, <a href="https://github.com/coturn/coturn">CoTurn</a> a relay server which facilitates peer to communication when hosts are behind a NAT, <a href="https://github.com/ezrarieben/coturn-credential-api">coturn-credential-api</a> a credentials server you can use with CoTurn's REST API to require authentication to the server and prevent abuse, and <a href="https://nginx.org/en/" rel="nofollow">nginx</a> a web server that we will use to serve web pages. Each of these needs to be reachable, so needs ports open. We will also be opening a couple of ports for connectivity testing.</p>
<p dir="auto">Click the Create Security List button, then "add another ingress rule" and enter the following (note that once you've entered information for one rule there is an "Add another ingress rule" button at the bottom:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Source CIDR</th>
<th>IP Protocol</th>
<th>Destination Port Range</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>All</td>
<td>TCP</td>
<td>3478</td>
<td>TLS TCP Listening port for Coturn Server</td>
</tr>
<tr>
<td>All</td>
<td>UDP</td>
<td>3478</td>
<td>TLS UDP Listening port for Coturn Server</td>
</tr>
<tr>
<td>All</td>
<td>TCP</td>
<td>5349</td>
<td>DTLS TCP Listening port for Coturn Server</td>
</tr>
<tr>
<td>All</td>
<td>UDP</td>
<td>5349</td>
<td>DTLS UDP Listening port for Coturn Server</td>
</tr>
<tr>
<td>All</td>
<td>UDP</td>
<td>49152-65535</td>
<td>Coturn relay ports</td>
</tr>
<tr>
<td>All</td>
<td>TCP</td>
<td>22</td>
<td>SSH communication with the server</td>
</tr>
<tr>
<td>All</td>
<td>TCP</td>
<td>9000</td>
<td>PeerJS server listening port</td>
</tr>
<tr>
<td>All</td>
<td>UDP</td>
<td>9000</td>
<td>PeerJS server listening port</td>
</tr>
<tr>
<td>All</td>
<td>TCP</td>
<td>80</td>
<td>Webserver unsecure port (http://)</td>
</tr>
<tr>
<td>All</td>
<td>TCP</td>
<td>443</td>
<td>Webserver secure port (https://)</td>
</tr>
<tr>
<td>All</td>
<td>ICMP</td>
<td>N/A</td>
<td>Used to "ping" server</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">Once you have entered all the rules, Click on the "Create Security List" button at the bottom. Back on the main screen, click on "Subnets" on the left menu, then on the name of the subnet you just created, then on the "Add Security list" button, select the list you just created from the menu and click the "Add Security List" button at the bottom.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">5. Save a configuration</h3><a id="user-content-5-save-a-configuration" aria-label="Permalink: 5. Save a configuration" href="#5-save-a-configuration"></a></p>
<p dir="auto">So now it's finally time to actually make the server! The temptation now would be to jump in and create an Instance (what Oracle calls a Virtual Machine) but sometimes when you try this, Oracle is temporarily out of space and the process fails, meaning that you have to start all over again from scratch. So with a couple of extra clicks we can save the configuration and try again any time we like at the click of a button.</p>
<p dir="auto">From the hamburger menu at the top left, select Compute" then "Instance Configurations" and click the "Create Instance configuration" button. A couple of things to note here before you move on: At the time of writing, you basically have the equivalent of 4 OCPUs and 24 GB of memory to play with. This is across your entire account, and how you use them is up to you. You could make one machine with 4 OCPUs and 24 GB of memory or you could make 4 machines with 1 OCPU and 6 GB of memory of memory each. You can edit these amounts later, but it's worth keeping in mind at this point. Give the configuration a name and move to the section below.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Selecting an image</h4><a id="user-content-selecting-an-image" aria-label="Permalink: Selecting an image" href="#selecting-an-image"></a></p>
<p dir="auto">In the "Image and shape" section, click the link to edit. Click the "change image" button, select "Ubuntu" and check the box next to the latest Canonical Ubuntu version you can see (build numbers are available by clicking the down arrow at right, but whatever is at the top of the list should be fine) and then on the "Select image" button at the bottom.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Selecting a shape</h4><a id="user-content-selecting-a-shape" aria-label="Permalink: Selecting a shape" href="#selecting-a-shape"></a></p>
<p dir="auto">Back on the main screen, click the "Change shape" button. Select "Ampere (Arm-based processor)" and check the box next to the shape that appears on the list (VM.Standard.A1.Flex at the time of writing). A section below appears where you can configure the amount of CPU and memory your server will use. This one is completely up to you, but 1 OCPU and 9GB of memory works fine. If you are not planning on crfeating any other VMs in your free tier you might as well max it out with 4 OCPUs and 24 GB of memory. Once you're done, click "Select shape".</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Nominating the subnet</h4><a id="user-content-nominating-the-subnet" aria-label="Permalink: Nominating the subnet" href="#nominating-the-subnet"></a></p>
<p dir="auto">In the Primary VNIC information section, leave everything as default but at the bottom make sure that the subnet that is shown is the one you just created - "TURN Server Subnet" was the example name given above - and not the default one. <em><strong>This step is very important.</strong></em> If the machine is created on the wrong subnet there's nothing you can do but delete it and start again.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Adding SSH keys</h4><a id="user-content-adding-ssh-keys" aria-label="Permalink: Adding SSH keys" href="#adding-ssh-keys"></a></p>
<p dir="auto">Leave the Primary VNIC IP addresses section as default and move to the "Add SSH keys" section. SSH is how you will interact with the remote server from your local computer. If you already have SSH keys that you would like to use to access this server, select upload public key files and do that. Otherwise select "Generate a key pair for me" and save the private key in a place you will remember and with a name that makes sense - we'll use turn_server.key for this example.</p>
<p dir="auto">Leave everything else as default and click the "Create" button at the bottom of the screen.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Creating the server</h4><a id="user-content-creating-the-server" aria-label="Permalink: Creating the server" href="#creating-the-server"></a></p>
<p dir="auto">Now click on the name of the configuration that you just created and click the "Launch instance" button. This will open up a similar screen to the Instance configuration one you were just on. You may notice a little window at the bottom with a cost summary telling telling you that the boot volume will cost a couple of bucks a month. This is due to a <a href="https://www.reddit.com/r/oraclecloud/comments/14pg5dr/oracle_always_free_service_have_boot_volume_cost/" rel="nofollow">bug in the cost analyser tool</a> you can ignore this - you won't be charged for the above configuration.</p>
<p dir="auto">Click the "Create" button. With any luck you will be taken to another screen that will say "Provisioning" for a minute or so and then "Running". If you stay on the same screen and get an Out of Capacity error, try clicking the Create button again. If you get the same error, leave it for half an hour and try again. Out of capacity errors used to be very common, but it seems that Oracle has freed up more space and you can usually get an Instance running on the first try. If you are experiencing long delays, you could consider <a href="https://github.com/mohankumarpaluru/oracle-freetier-instance-creation">automating the process with Python</a> or if you're looking for something simpler, an auto-clicker might do the trick, provided you are on the page with the Create button showing - just paste this into your console and hit Enter:</p>
<div data-snippet-clipboard-copy-content="setInterval(function(){document.querySelectorAll(&quot;.oui-button.oui-button-primary&quot;)[1].click()},60000)"><pre><code>setInterval(function(){document.querySelectorAll(".oui-button.oui-button-primary")[1].click()},60000)
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Testing the server</h4><a id="user-content-testing-the-server" aria-label="Permalink: Testing the server" href="#testing-the-server"></a></p>
<p dir="auto">Whichever way you created it, you should now be looking at the running server screen. Copy the Public IP address from the right side of the screen, open up a command prompt and try pinging your server:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/lvidgen/WebRTC/blob/master/FOSS_TURN_Server/images/ping.png"><img src="https://github.com/lvidgen/WebRTC/raw/master/FOSS_TURN_Server/images/ping.png" alt="alt text" title="Pinging the server"></a></p>
<p dir="auto">Yay. We have connectivity. Let's SSH into the server and start setting it up.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">6. Access the server via SSH</h3><a id="user-content-6-access-the-server-via-ssh" aria-label="Permalink: 6. Access the server via SSH" href="#6-access-the-server-via-ssh"></a></p>
<p dir="auto">In the command prompt, navigate to the folder where you saved your private SSH key file, then enter the following command, replacing the name of the key file that you saved and the IP address:</p>
<div data-snippet-clipboard-copy-content="ssh -i your_private_key_name.key ubuntu@your_public_ip_address"><pre><code>ssh -i your_private_key_name.key ubuntu@your_public_ip_address
</code></pre></div>
<p dir="auto">The first time you attempt access you will be asked to confirm:
<a target="_blank" rel="noopener noreferrer" href="https://github.com/lvidgen/WebRTC/blob/master/FOSS_TURN_Server/images/ssh.png"><img src="https://github.com/lvidgen/WebRTC/raw/master/FOSS_TURN_Server/images/ssh.png" alt="alt text" title="SSH confirmation"></a></p>
<p dir="auto">Type "yes". If everything has gone how it should you should now be looking at a linux command prompt with the username ubuntu. Most likely there will be a message saying that the update list is old. This is because Oracle posted the VM image that you used a while ago. It's best practice to keep your system updated anyway, so run the following and wait a while while it exectutes:</p>
<div data-snippet-clipboard-copy-content="sudo apt update &amp;&amp; sudo apt upgrade"><pre><code>sudo apt update &amp;&amp; sudo apt upgrade
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">7. Fire up a web server</h3><a id="user-content-7-fire-up-a-web-server" aria-label="Permalink: 7. Fire up a web server" href="#7-fire-up-a-web-server"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Configure DNS</h4><a id="user-content-configure-dns" aria-label="Permalink: Configure DNS" href="#configure-dns"></a></p>
<p dir="auto">Now that you've got an IP address, you can set up DNS to point your domain name at it. This may seem premature, but DNS changes take a while to propagate through the network, so we might as well do it now and we can work on other things while that takes effect. Just log into the account where you bought your domain name, find the section where you can edit (or create) A records and make sure you have an A record with your domain name as the host name (without the http..., so example.com for example) and your public IP address as the value. For ease at this point, add another A record with your domain name plus the www (so <a href="http://www.example.com/" rel="nofollow">www.example.com</a>) and your public IP address as the value. As a quick check to see if the changes have porpagated you can ping your domain name - if the results come back showing your public IP address you're in business. Sometimes it's instant, sometimes it takes a while. If it takes any longer than a few hours it's probably worth contacting your domain hosting company to see if there's a problem.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Install nginx</h4><a id="user-content-install-nginx" aria-label="Permalink: Install nginx" href="#install-nginx"></a></p>
<p dir="auto">We'll be using a web server for a couple of things and while there are a few options, <a href="https://nginx.org/en/" rel="nofollow">nginx</a> suits all our needs. To install it, just run:</p>

<p dir="auto">Once it's done, check the status:</p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/lvidgen/WebRTC/blob/master/FOSS_TURN_Server/images/nginx.png"><img src="https://github.com/lvidgen/WebRTC/raw/master/FOSS_TURN_Server/images/nginx.png" alt="alt text" title="nginx status"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Open up some ports</h4><a id="user-content-open-up-some-ports" aria-label="Permalink: Open up some ports" href="#open-up-some-ports"></a></p>
<p dir="auto">You might be tempted now to try to access the webserver by pointing your browser at your IP address. Not so fast! Much like your security list, the ports on your server are configured to deny all traffic unless it is allowed. You can list the open ports by issuing the following command:</p>
<div data-snippet-clipboard-copy-content="sudo iptables -t filter -nv -L INPUT --line-numbers"><pre><code>sudo iptables -t filter -nv -L INPUT --line-numbers
</code></pre></div>
<p dir="auto">A lot of tutorials on the web will tell you that this is what you want to do:</p>
<div data-snippet-clipboard-copy-content="sudo iptables -A INPUT -p tcp --dport 80 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT"><pre><code>sudo iptables -A INPUT -p tcp --dport 80 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT
</code></pre></div>
<p dir="auto">Run it, then run but the previous command to list the open ports. You see that the problem is that the -A flag appends the rule to the end of the list, after the REJECT all rule. So a packet will never reach this rule. What we want is to insert rules before that reject statement, the easiest way being to use the -I flag instead, followed by the line number where you want to insert the rule (here we are using 2, so these rules will end up on lines 2 and 3 of the INPUT and OUTPUT chains). Below are the four rules that nginx needs:</p>
<div data-snippet-clipboard-copy-content="sudo iptables -I INPUT 2 -p tcp --dport 80 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT
sudo iptables -I OUTPUT 2 -p tcp --sport 80 -m conntrack --ctstate ESTABLISHED -j ACCEPT
sudo iptables -I INPUT 2 -p tcp --dport 443 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT
sudo iptables -I OUTPUT 2 -p tcp --sport 443 -m conntrack --ctstate ESTABLISHED -j ACCEPT"><pre><code>sudo iptables -I INPUT 2 -p tcp --dport 80 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT
sudo iptables -I OUTPUT 2 -p tcp --sport 80 -m conntrack --ctstate ESTABLISHED -j ACCEPT
sudo iptables -I INPUT 2 -p tcp --dport 443 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT
sudo iptables -I OUTPUT 2 -p tcp --sport 443 -m conntrack --ctstate ESTABLISHED -j ACCEPT
</code></pre></div>
<p dir="auto">One additional advantage of using the --line-numbers flag when listing rules is that you can delete rules by line number. If we wanted to delete rule 20 on the INPUT chain we could just do:</p>
<div data-snippet-clipboard-copy-content="sudo iptables -D INPUT 20"><pre><code>sudo iptables -D INPUT 20
</code></pre></div>
<p dir="auto">One more thing we want to do with iptables: by default, these rules are not persistent, so if you ever restart your server you will have to set them all up again. You need to save changes to your iptables file by calling this command:</p>
<div data-snippet-clipboard-copy-content="sudo sh -c 'iptables-save > /etc/iptables/rules.v4'"><pre><code>sudo sh -c 'iptables-save &gt; /etc/iptables/rules.v4'
</code></pre></div>
<p dir="auto">Now you're ready to check your web server - if you can successfully ping your domain name you should be able to browse to it. Navigate to http://your_domain_name. You'll probably see a scary looking message about how the site is insecure. We'll fix that soon. Just click on "Proceed anyway" (or something like that, depending on the browser). If you can see the "Welcome to nginx" page, you're ready to move on :)</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Install a TLS certficate</h4><a id="user-content-install-a-tls-certficate" aria-label="Permalink: Install a TLS certficate" href="#install-a-tls-certficate"></a></p>
<p dir="auto">To get rid of that scary warning message we need to install a TLS certificate so that our plain ol http site will use the more secure https protocol. Thankfully the folks at the <a href="https://eff.org/" rel="nofollow">EFF</a> have made this a very simple process.<br>
You can read detailed instructions <a href="https://certbot.eff.org/instructions?ws=nginx&amp;os=snap" rel="nofollow">here</a>, but basically:</p>
<p dir="auto"><code>sudo snap install --classic certbot</code> installs the Certbot tool</p>
<p dir="auto"><code>sudo ln -s /snap/bin/certbot /usr/bin/certbot</code> ensures that Certbot can be run</p>
<p dir="auto"><code>sudo certbot --nginx</code> gets a certificate, asks you a few configuration questions and turns on https</p>
<p dir="auto"><code>sudo certbot renew --dry-run</code> (optional) tests the automated renewal procedure - with this running you should always have a valid certificate</p>
<p dir="auto">If everything worked OK you should now be able to refresh your browser page and you will see that your site is being served with the https protocol</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">8. Make a sample web app</h3><a id="user-content-8-make-a-sample-web-app" aria-label="Permalink: 8. Make a sample web app" href="#8-make-a-sample-web-app"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Take ownership of the web files folder</h4><a id="user-content-take-ownership-of-the-web-files-folder" aria-label="Permalink: Take ownership of the web files folder" href="#take-ownership-of-the-web-files-folder"></a></p>
<p dir="auto">It's time to start uploading some files to our web server, but before we do that we want to take over ownership of the directory that nginx uses to serve webpages. If we don't, we'll have to add "sudo" to the start of every command which is annoying. The default location for web files is in /var/www/html, so to check ownership we can run</p>

<p dir="auto">We see that root is the owner. To change that we change the owner of the directory and everything inside it to be the currently logged in user:</p>
<div data-snippet-clipboard-copy-content="sudo chown -R $USER /var/www/html"><pre><code>sudo chown -R $USER /var/www/html
</code></pre></div>
<p dir="auto">While we're here, make a folder for a sample app to go in: <code>mkdir /var/www/html/peertest</code></p>
<p dir="auto"><h5 tabindex="-1" dir="auto">Upload a sample app</h5><a id="user-content-upload-a-sample-app" aria-label="Permalink: Upload a sample app" href="#upload-a-sample-app"></a></p>
<p dir="auto">Below is an HTML page with a simple WebRTC chat app that we can use to test connectivity:</p>
<div data-snippet-clipboard-copy-content="<!DOCTYPE html>
<html lang=&quot;en&quot;>
<head>
  <meta charset=&quot;utf-8&quot;>
  <meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot;>
  <title>Simple RTC Chat</title>
  <style>
  #peer_id{display:none}
  #chat_id{display:none;}
  </style>
</head>
<body>
<h1>Simple RTC Chat</h1>
<div id =&quot;info&quot;></div>
<div id =&quot;id_div&quot;>Choose an ID: <input id =&quot;myid&quot;/>
<button id = &quot;sub_id_btn&quot;>Submit</button>
</div>
<div id =&quot;peer_id&quot;>Enter your friend's ID or wait for a connection: 
<input id =&quot;peerid&quot;/><button id = &quot;sub_peer_btn&quot;>Submit</button>
</div>    
<div id=&quot;chat_id&quot;>Enter message: 
<input id =&quot;msg&quot;><button id = &quot;send_msg&quot;>Send</button><br><textarea id=&quot;chat&quot; rows=&quot;50&quot; cols=&quot;50&quot;></textarea>
</div>  
  <script src=&quot;https://unpkg.com/peerjs@1.5.4/dist/peerjs.min.js&quot;></script>
  <script>
  (function() {
      let peer = null;

      function getById(str) {
          return document.getElementById(str)
      }

      getById(&quot;chat&quot;).value = &quot;&quot;;

      getById(&quot;sub_id_btn&quot;).onclick = function() {
          peer = new Peer(getById(&quot;myid&quot;).value);
          getById(&quot;id_div&quot;).style.display = &quot;none&quot;;
          getById(&quot;peer_id&quot;).style.display = &quot;block&quot;;
          peer.on('connection', function(conn) {
              setConnection(conn);
          });
      }

      getById(&quot;sub_peer_btn&quot;).onclick = function() {
          conn = peer.connect(getById(&quot;peerid&quot;).value);
          conn.on('open', function() {
              setConnection(conn);
           });
      }

      function setConnection(conn) {
		  getById(&quot;info&quot;).innerHTML=&quot;Connected as &quot;+peer.id+&quot;, chatting with &quot;+conn.peer;
          getById(&quot;chat_id&quot;).style.display = &quot;block&quot;;
          getById(&quot;peer_id&quot;).style.display = &quot;none&quot;;
          getById(&quot;send_msg&quot;).onclick = function() {
              let msg = peer.id + &quot;: &quot; + getById(&quot;msg&quot;).value + &quot;\n&quot;;
              getById(&quot;chat&quot;).value += msg;
              conn.send(msg);
          }
          conn.on('data', function(data) {
              getById(&quot;chat&quot;).value += data;
          });
      }
  })()
  </script>
</body>
</html>"><pre><code>&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;meta charset="utf-8"&gt;
  &lt;meta name="viewport" content="width=device-width, initial-scale=1"&gt;
  &lt;title&gt;Simple RTC Chat&lt;/title&gt;
  &lt;style&gt;
  #peer_id{display:none}
  #chat_id{display:none;}
  &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;h1&gt;Simple RTC Chat&lt;/h1&gt;
&lt;div id ="info"&gt;&lt;/div&gt;
&lt;div id ="id_div"&gt;Choose an ID: &lt;input id ="myid"/&gt;
&lt;button id = "sub_id_btn"&gt;Submit&lt;/button&gt;
&lt;/div&gt;
&lt;div id ="peer_id"&gt;Enter your friend's ID or wait for a connection: 
&lt;input id ="peerid"/&gt;&lt;button id = "sub_peer_btn"&gt;Submit&lt;/button&gt;
&lt;/div&gt;    
&lt;div id="chat_id"&gt;Enter message: 
&lt;input id ="msg"&gt;&lt;button id = "send_msg"&gt;Send&lt;/button&gt;&lt;br&gt;&lt;textarea id="chat" rows="50" cols="50"&gt;&lt;/textarea&gt;
&lt;/div&gt;  
  &lt;script src="https://unpkg.com/peerjs@1.5.4/dist/peerjs.min.js"&gt;&lt;/script&gt;
  &lt;script&gt;
  (function() {
      let peer = null;

      function getById(str) {
          return document.getElementById(str)
      }

      getById("chat").value = "";

      getById("sub_id_btn").onclick = function() {
          peer = new Peer(getById("myid").value);
          getById("id_div").style.display = "none";
          getById("peer_id").style.display = "block";
          peer.on('connection', function(conn) {
              setConnection(conn);
          });
      }

      getById("sub_peer_btn").onclick = function() {
          conn = peer.connect(getById("peerid").value);
          conn.on('open', function() {
              setConnection(conn);
           });
      }

      function setConnection(conn) {
		  getById("info").innerHTML="Connected as "+peer.id+", chatting with "+conn.peer;
          getById("chat_id").style.display = "block";
          getById("peer_id").style.display = "none";
          getById("send_msg").onclick = function() {
              let msg = peer.id + ": " + getById("msg").value + "\n";
              getById("chat").value += msg;
              conn.send(msg);
          }
          conn.on('data', function(data) {
              getById("chat").value += data;
          });
      }
  })()
  &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre></div>
<p dir="auto">Save it on your computer with the filename "index.html" in the same folder where you saved your private SSH key. You can try it out by opening it in a browser and opening another copy in a different tab. In a real app you would have more error handling - the big one to watch for here is to make sure that the two connections use different IDs.</p>
<p dir="auto">To upload the file to the folder that you just made, open up a regular command prompt (not the one you're using to SSH into the server), navigate to the directory where you have the index.html and private key files and issue the following command:</p>
<div data-snippet-clipboard-copy-content="scp -i your_private_key_name.key index.html ubuntu@your_public_IP:/var/www/html/peertest"><pre><code>scp -i your_private_key_name.key index.html ubuntu@your_public_IP:/var/www/html/peertest
</code></pre></div>
<p dir="auto">If everything is working correctly, you should now be able to access the page at https://your_domain_name/peertest</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">8. Install your own PeerJS server</h3><a id="user-content-8-install-your-own-peerjs-server" aria-label="Permalink: 8. Install your own PeerJS server" href="#8-install-your-own-peerjs-server"></a></p>
<p dir="auto">As mentioned before, using PeerJS the way we do above means that it connects to the PeerJS server, which itself uses Google's TURN server when required. To get more control over the stack we need to create our own PeerJS server. You can see the project page <a href="https://github.com/peers/peerjs-server">here</a>, but basically:</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Install npm and the PeerJS Server</h4><a id="user-content-install-npm-and-the-peerjs-server" aria-label="Permalink: Install npm and the PeerJS Server" href="#install-npm-and-the-peerjs-server"></a></p>
<p dir="auto">The PeerJS server is available through the Node Package Manager, which itself relies on node.js so we have some installing to do, But first we have a problem. We can run <code>sudo apt-cache policy nodejs</code> to see what version of nodejs we are going to get if we install it from the repository, and what the output tells us is that we're going to get:</p>
<blockquote>
<p dir="auto">Candidate: 10.19.0~dfsg-3ubuntu1.6</p>
</blockquote>
<p dir="auto">But when we look at PeerJS in npm, it says that we need 14 or above:
<a target="_blank" rel="noopener noreferrer" href="https://github.com/lvidgen/WebRTC/blob/master/FOSS_TURN_Server/images/peerjs.png"><img src="https://github.com/lvidgen/WebRTC/raw/master/FOSS_TURN_Server/images/peerjs.png" alt="alt text" title="Peer JS specs in the npm library"></a></p>
<p dir="auto">So we need to install another way, directly from the source. Version 20 is the latest at time of writing, so let's go for that...:</p>
<div data-snippet-clipboard-copy-content="curl -fsSL https://deb.nodesource.com/setup_20.x | sudo bash -
sudo apt-get install -y nodejs"><pre><code>curl -fsSL https://deb.nodesource.com/setup_20.x | sudo bash -
sudo apt-get install -y nodejs
</code></pre></div>
<p dir="auto">The nice thing about installing from nodesource is that npm is already installed, so now we can install peer right away...</p>

<p dir="auto"><h4 tabindex="-1" dir="auto">Test the PeerJS Server</h4><a id="user-content-test-the-peerjs-server" aria-label="Permalink: Test the PeerJS Server" href="#test-the-peerjs-server"></a></p>
<p dir="auto">Fire up the server with the following command:</p>
<div data-snippet-clipboard-copy-content="peerjs --port 9000 --key peerjs --path /myapp"><pre><code>peerjs --port 9000 --key peerjs --path /myapp
</code></pre></div>
<p dir="auto">then point your browser at <code>http://your_domain_name:9000/myapp</code> - if everything is working you will get a small JSON response with details about PeerJS name, description and website.</p>
<p dir="auto">So it's working, but there are a couple of problems:</p>
<ul dir="auto">
<li>The server is running as a foreground process. Getting a command prompt back in the terminal or closing the terminal window will mean killing the server</li>
<li>We're using the unsecure http protocol</li>
</ul>
<p dir="auto">Hit Ctrl + C to stop the PeerJS server, then type the following command to open a screen session. Screen is a program that allows us to push processes to the background where they keep running regardless of what we do with the main terminal window. We're going to give our session a name so it's easier to reference later. You do this with the -S flag:</p>

<p dir="auto">A regular, empty command prompt should have opened up. Now we can start the server, but supply it with the ssl certificates that we got from certibot previously, ensuring a secure connection:</p>
<div data-snippet-clipboard-copy-content="sudo peerjs --port 9000 --key peerjs --path /myapp --sslkey /etc/letsencrypt/live/your_domain_name_here/privkey.pem --sslcert /etc/letsencrypt/live/your_domain_name_here/fullchain.pem"><pre><code>sudo peerjs --port 9000 --key peerjs --path /myapp --sslkey /etc/letsencrypt/live/your_domain_name_here/privkey.pem --sslcert /etc/letsencrypt/live/your_domain_name_here/fullchain.pem
</code></pre></div>
<p dir="auto">The server should start. Hit Ctrl + a and then d to detach from the screen, which should get you back to the main terminal window. Now you can test <code>https://your_domain_name:9000/myapp</code> - it should return the same response that you got when browsing to the http version.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Point the web app at your PeerJS server</h4><a id="user-content-point-the-web-app-at-your-peerjs-server" aria-label="Permalink: Point the web app at your PeerJS server" href="#point-the-web-app-at-your-peerjs-server"></a></p>
<p dir="auto">Open up your app's index.html file in a text editor like nano:</p>
<div data-snippet-clipboard-copy-content="nano /var/www/html/whatever_you_called_your_app_directory/index.html"><pre><code>nano /var/www/html/whatever_you_called_your_app_directory/index.html
</code></pre></div>
<p dir="auto">and look for this line: <code>peer = new Peer(getById("myid").value);</code>
We want to change that to:</p>
<div data-snippet-clipboard-copy-content="peer = new Peer(getById(&quot;myid&quot;).value,
                  {host: &quot;your_domain_name&quot;,
                   port: 9000,
                   key: &quot;peerjs&quot;
                   secure: true,
                   path: &quot;/myapp&quot;
                  });"><pre><code>peer = new Peer(getById("myid").value,
                  {host: "your_domain_name",
                   port: 9000,
                   key: "peerjs"
                   secure: true,
                   path: "/myapp"
                  });
</code></pre></div>
<p dir="auto">Save your changes (Ctrl + o, enter to confirm), refresh your webpages and test the connection. It should connect the same as before. You can see the server connections by reattaching the screen session:</p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/lvidgen/WebRTC/blob/master/FOSS_TURN_Server/images/peerjs_conn.png"><img src="https://github.com/lvidgen/WebRTC/raw/master/FOSS_TURN_Server/images/peerjs_conn.png" alt="alt text" title="PeerJS server connections"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">9. Install your own STUN/TURN server</h3><a id="user-content-9-install-your-own-stunturn-server" aria-label="Permalink: 9. Install your own STUN/TURN server" href="#9-install-your-own-stunturn-server"></a></p>
<p dir="auto">We've almost got end-to-end control, the only thing missing is that PeerJS is still using Google servers. But we can tell it to use our own implementation of <a href="https://github.com/coturn/coturn">coturn</a> instead.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Install and configure coturn:</h4><a id="user-content-install-and-configure-coturn" aria-label="Permalink: Install and configure coturn:" href="#install-and-configure-coturn"></a></p>
<p dir="auto">Installation is simple:</p>

<p dir="auto">Save a fresh copy of the config file just in case:</p>
<div data-snippet-clipboard-copy-content="sudo cp /etc/turnserver.conf /etc/turnserver_bak.conf"><pre><code>sudo cp /etc/turnserver.conf /etc/turnserver_bak.conf
</code></pre></div>
<p dir="auto">Edit the config file:</p>
<div data-snippet-clipboard-copy-content="sudo nano /etc/turnserver.conf"><pre><code>sudo nano /etc/turnserver.conf
</code></pre></div>
<p dir="auto">You'll see that there are a lot of options here. As a minimal example, you can leave most commented out and just uncomment the following lines:</p>
<div data-snippet-clipboard-copy-content="listening-port=3478
tls-listening-port=5349
listening-ip=the_Private_IPv4_address_of_your_Oracle _instance
external-ip=the_Public_IPv4_address_of_your_Oracle _instance
verbose
fingerprint
user=turnuser:turn456
log-file=/var/log/turn.log
simple-log"><pre><code>listening-port=3478
tls-listening-port=5349
listening-ip=the_Private_IPv4_address_of_your_Oracle _instance
external-ip=the_Public_IPv4_address_of_your_Oracle _instance
verbose
fingerprint
user=turnuser:turn456
log-file=/var/log/turn.log
simple-log
</code></pre></div>
<p dir="auto">save the changes, then restart the coturn server:</p>
<div data-snippet-clipboard-copy-content="sudo systemctl restart coturn"><pre><code>sudo systemctl restart coturn
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Open up the coturn ports</h4><a id="user-content-open-up-the-coturn-ports" aria-label="Permalink: Open up the coturn ports" href="#open-up-the-coturn-ports"></a></p>
<p dir="auto">Back to our iptables. We need to open up the 3478 and 5349 listening ports and also the udp relay endpoints (set as 49152-65535 by default in the config file)</p>
<div data-snippet-clipboard-copy-content="sudo iptables -I INPUT 2 -p tcp --dport 3478 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT
sudo iptables -I INPUT 2 -p udp --dport 3478 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT
sudo iptables -I INPUT 2 -p tcp --dport 5349 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT
sudo iptables -I INPUT 2 -p udp --dport 5349 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT
sudo iptables -I INPUT 2 -p udp --dport 49152:65535 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT
sudo sh -c 'iptables-save > /etc/iptables/rules.v4'"><pre><code>sudo iptables -I INPUT 2 -p tcp --dport 3478 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT
sudo iptables -I INPUT 2 -p udp --dport 3478 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT
sudo iptables -I INPUT 2 -p tcp --dport 5349 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT
sudo iptables -I INPUT 2 -p udp --dport 5349 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT
sudo iptables -I INPUT 2 -p udp --dport 49152:65535 -m conntrack --ctstate NEW,ESTABLISHED -j ACCEPT
sudo sh -c 'iptables-save &gt; /etc/iptables/rules.v4'
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Test the coturn server connectivity</h4><a id="user-content-test-the-coturn-server-connectivity" aria-label="Permalink: Test the coturn server connectivity" href="#test-the-coturn-server-connectivity"></a></p>
<p dir="auto">We can test the connection using <a href="https://webrtc.github.io/samples/src/content/peerconnection/trickle-ice/" rel="nofollow">Trickle ICE</a></p>
<p dir="auto">Let's start with the simplest test: enter <code>STUN:your_domain_name:3478</code> in the STUN or TURN URI box, click "Add server", scroll down and click "Gather cadidates". In the output there should be an srflx type response listed:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/lvidgen/WebRTC/blob/master/FOSS_TURN_Server/images/stuntest.png"><img src="https://github.com/lvidgen/WebRTC/raw/master/FOSS_TURN_Server/images/stuntest.png" alt="alt text" title="STUN test"></a></p>
<p dir="auto">Let's test the TURN server: enter <code>TURN:your_domain_name:3478</code> in the STUN or TURN URI box, turnuser in the username box and turn456 in the password box (these were defined in your config file) and click "Add server", scroll down and click "Gather cadidates". In the output there will probably be an srflx type response listed again, along with a relay type:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/lvidgen/WebRTC/blob/master/FOSS_TURN_Server/images/turntest.png"><img src="https://github.com/lvidgen/WebRTC/raw/master/FOSS_TURN_Server/images/turntest.png" alt="alt text" title="TURN test"></a></p>
<p dir="auto">Cool. So we can connect to port 3478, but we really want to connect to the TLS listenting port, 5349. Even a simple STUN test fails there. We need to include paths to our SSL files in the config file, but here's something annoying: the Let's Encrypt folder where they're currently kept is owned by root and coturn does not have access to it, not even when the root user starts it. There are two not great options here: one is to edit the <code>/lib/systemd/system/coturn.service</code> file and make the User and Group equal root so that coturn runs as root. If that seems a little nuclear, make a new folder, copy the files there and change the permissions so that turnserver can access them:</p>
<div data-snippet-clipboard-copy-content="sudo mkdir /etc/turnservercerts
sudo cp /etc/letsencrypt/live/your_domain_here/fullchain.pem /etc/turnservercerts
sudo cp /etc/letsencrypt/live/your_domain_here/privkey.pem /etc/turnservercerts
sudo chown turnserver:turnserver /etc/turnservercerts -R
sudo chmod 600 /etc/turnservercerts -R"><pre><code>sudo mkdir /etc/turnservercerts
sudo cp /etc/letsencrypt/live/your_domain_here/fullchain.pem /etc/turnservercerts
sudo cp /etc/letsencrypt/live/your_domain_here/privkey.pem /etc/turnservercerts
sudo chown turnserver:turnserver /etc/turnservercerts -R
sudo chmod 600 /etc/turnservercerts -R
</code></pre></div>
<p dir="auto">Either way you go, you will then add these two lines to the config file (with paths to the original key files if you went for the first "run as root" option):</p>
<div data-snippet-clipboard-copy-content="pkey=/etc/turnservercerts/privkey.pem
cert=/etc/turnservercerts/fullchain.pem"><pre><code>pkey=/etc/turnservercerts/privkey.pem
cert=/etc/turnservercerts/fullchain.pem
</code></pre></div>
<p dir="auto">Save the changes, then restart coturn:</p>
<div data-snippet-clipboard-copy-content="sudo systemctl restart coturn"><pre><code>sudo systemctl restart coturn
</code></pre></div>
<p dir="auto">Now let's try with <code>TURN:your_domain_name:5349</code> in the STUN or TURN URI box, turnuser in the username box and turn456 in the password box:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/lvidgen/WebRTC/blob/master/FOSS_TURN_Server/images/turn5349.png"><img src="https://github.com/lvidgen/WebRTC/raw/master/FOSS_TURN_Server/images/turn5349.png" alt="alt text" title="TURN connecting to TLS port 5349"></a></p>
<p dir="auto">If this all looks good, it's time to edit our web app to point it at our coturn server.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">10. Point your web app at your coturn server</h3><a id="user-content-10-point-your-web-app-at-your-coturn-server" aria-label="Permalink: 10. Point your web app at your coturn server" href="#10-point-your-web-app-at-your-coturn-server"></a></p>
<p dir="auto">PeerJS gives us the option to specify the STUN and TURN servers that we want to use when we are connecting to our PeerJS server. At the moment, our index.html creates a Peer object like this:</p>
<div data-snippet-clipboard-copy-content="peer = new Peer(getById(&quot;myid&quot;).value,
                  {host: &quot;your_domain_name&quot;,
                   port: 9000,
                   key: &quot;peerjs&quot;,
                   secure: true,
                   path: &quot;/myapp&quot;
                  });"><pre><code>peer = new Peer(getById("myid").value,
                  {host: "your_domain_name",
                   port: 9000,
                   key: "peerjs",
                   secure: true,
                   path: "/myapp"
                  });
</code></pre></div>
<p dir="auto">We want to change that to this:</p>
<div data-snippet-clipboard-copy-content="peer = new Peer(getById(&quot;myid&quot;).value,
		  {host: &quot;your_domain_name&quot;,
        port: 9000,
        key: &quot;peerjs&quot;,
        secure: true,
        path: &quot;/myapp&quot;,
		config: {
            iceServers: [
                {
                    urls: &quot;stun:your_domain_name:5349&quot;,
               },
                {
                    urls: &quot;turn:your_domain_name:5349&quot;,
                    username: &quot;turnuser&quot;,
                    credential: &quot;turn456&quot;
               }]
			   }
		  });"><pre><code>peer = new Peer(getById("myid").value,
		  {host: "your_domain_name",
        port: 9000,
        key: "peerjs",
        secure: true,
        path: "/myapp",
		config: {
            iceServers: [
                {
                    urls: "stun:your_domain_name:5349",
               },
                {
                    urls: "turn:your_domain_name:5349",
                    username: "turnuser",
                    credential: "turn456"
               }]
			   }
		  });
</code></pre></div>
<p dir="auto">Save your changes, reload your webpages and try getting connected - everything should be working as before, which means we only have one thing left to do...</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">11. Add some authentication</h3><a id="user-content-11-add-some-authentication" aria-label="Permalink: 11. Add some authentication" href="#11-add-some-authentication"></a></p>
<p dir="auto">Security-wise, The problem with the above is fairly obvious - our username and password (credential) is in the JavaScript and there in plain text for everybody to see, which means that anybody could use the above configuration in their app, piggybacking off your TURN server. It's kind of a limitation of WebRTC in general, but there are a couple of things we can do to mitigate the problem.</p>
<p dir="auto">Coturn allows authentication via REST API that generates a time sensitive username and password (more details can be found in <a href="https://datatracker.ietf.org/doc/html/draft-uberti-behave-turn-rest-00" rel="nofollow">Justin Uberti's Internet-Draft</a>), so we can use the <a href="https://github.com/ezrarieben/coturn-credential-api">coturn-credential-api</a> to generate time sensitive credentials in a format understood by Coturn.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Install the API files</h4><a id="user-content-install-the-api-files" aria-label="Permalink: Install the API files" href="#install-the-api-files"></a></p>
<p dir="auto">We're going to need to unzip the zip file, so we might as well install unzip now:</p>

<p dir="auto">Go to your web directory, get the file, unzip it and move the utility files to a top-level folder called creds:</p>
<div data-snippet-clipboard-copy-content="cd /var/www/html
wget https://github.com/ezrarieben/coturn-credential-api/archive/main.zip
unzip main.zip
sudo mv coturn-credential-api-main/public creds"><pre><code>cd /var/www/html
wget https://github.com/ezrarieben/coturn-credential-api/archive/main.zip
unzip main.zip
sudo mv coturn-credential-api-main/public creds
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Configure the API to work with coturn</h4><a id="user-content-configure-the-api-to-work-with-coturn" aria-label="Permalink: Configure the API to work with coturn" href="#configure-the-api-to-work-with-coturn"></a></p>
<p dir="auto">First thing we need to do is generate a private and public key. For this example, I'll be using these:
public: Z8e8mjfuHP3wipwGXNydqm4YJ
private: QCi3oHmnTuKhVE9hiyL5UpfUd</p>
<p dir="auto">Open up <code>config.inc.php</code> in your creds folder and paste in the values:</p>
<div data-snippet-clipboard-copy-content="define('TURN_AUTH_SECRET', &quot;your_private_key_here&quot;); // Auth secret defined in CoTURN server config
define('CREDENTIAL_TTL', 86400); // TTL of credentials in seconds
define('ALLOWED_API_KEYS', array(
    'your_public_key_here'
));"><pre><code>define('TURN_AUTH_SECRET', "your_private_key_here"); // Auth secret defined in CoTURN server config
define('CREDENTIAL_TTL', 86400); // TTL of credentials in seconds
define('ALLOWED_API_KEYS', array(
    'your_public_key_here'
));
</code></pre></div>
<p dir="auto">Now we need to add the private key to <code>/etc/turnserver.conf</code> and comment out the line that allows for static user credentials:</p>
<div data-snippet-clipboard-copy-content="#user=turnuser:turn456
static-auth-secret=your_private_key_here"><pre><code>#user=turnuser:turn456
static-auth-secret=your_private_key_here
</code></pre></div>
<p dir="auto">Save the changes and do a <code>sudo systemctl restart coturn</code> to restart the server with the new configuration.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Set up the server to serve php files</h4><a id="user-content-set-up-the-server-to-serve-php-files" aria-label="Permalink: Set up the server to serve php files" href="#set-up-the-server-to-serve-php-files"></a></p>
<p dir="auto">The coturn-credential-api is written in php. Some Linux distributions come with php installed, but the Oracle version of Ubuntu does not, so we're going to have to install it. To save further installations later, well install the version that works with nginx. We check which version of php is available in your respository:</p>

<p dir="auto">At the time of writing, it was 7.4, so we want php7.4-fpm (you can read about fpm <a href="https://php-fpm.org/" rel="nofollow">here</a>):</p>
<div data-snippet-clipboard-copy-content="sudo apt install php7.4-fpm"><pre><code>sudo apt install php7.4-fpm
</code></pre></div>
<p dir="auto">Now we need to edit the nginx configuration to work with php and fpm.</p>
<div data-snippet-clipboard-copy-content="sudo nano /etc/nginx/sites-available/default"><pre><code>sudo nano /etc/nginx/sites-available/default
</code></pre></div>
<p dir="auto">Scroll down to the server config block where the server_name has been set by Certbot and add index.php to the list so that it reads like this:</p>
<blockquote>
<p dir="auto">index index.php index.html index.htm index.nginx-debian.html;</p>
</blockquote>
<p dir="auto">In the same block, remove the comments from the section titled "# pass PHP scripts to FastCGI server" so that it looks like this:</p>
<div data-snippet-clipboard-copy-content="location ~ \.php$ {
                include snippets/fastcgi-php.conf;
        #
        #       # With php-fpm (or other unix sockets):
                fastcgi_pass unix:/var/run/php/php7.4-fpm.sock;
        #       # With php-cgi (or other tcp sockets):
        #       fastcgi_pass 127.0.0.1:9000;
        }"><pre><code>location ~ \.php$ {
                include snippets/fastcgi-php.conf;
        #
        #       # With php-fpm (or other unix sockets):
                fastcgi_pass unix:/var/run/php/php7.4-fpm.sock;
        #       # With php-cgi (or other tcp sockets):
        #       fastcgi_pass 127.0.0.1:9000;
        }
</code></pre></div>
<p dir="auto">Save your changes and reload nginx and php:</p>
<div data-snippet-clipboard-copy-content="sudo systemctl restart nginx
sudo systemctl reload php7.4-fpm"><pre><code>sudo systemctl restart nginx
sudo systemctl reload php7.4-fpm
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">12. Edit the web app</h3><a id="user-content-12-edit-the-web-app" aria-label="Permalink: 12. Edit the web app" href="#12-edit-the-web-app"></a></p>
<p dir="auto">Time for one last edit on our index.html file. For clarity, we're going to rewrite the entire <code>getById("sub_id_btn").onclick</code> function, which should now look like this:</p>
<div data-snippet-clipboard-copy-content="getById(&quot;sub_id_btn&quot;).onclick = function() {
      let myname = getById(&quot;myid&quot;).value,
        params = {
            username: myname,
            key: &quot;your_public_key_here&quot;,
        },

        options = {
            method: &quot;POST&quot;,
            body: new URLSearchParams(params),
        };

    fetch(&quot;https://your_domain_name/creds/&quot;, options)
        .then(response => response.json())
        .then(data => {
            let creds = data.data;
            peer = new Peer(myname, {
                host: &quot;your_domain_name&quot;,
                port: 8999,
                key: &quot;peerjs&quot;,
                secure: true,
                path: &quot;/myapp&quot;,
                config: {
                    iceServers: [{
                            urls: &quot;stun:your_domain_name:5349&quot;,
                        },
                        {
                            urls: &quot;turn:your_domain_name:5349&quot;,
                            username: creds.username,
                            credential: creds.password
                        }
                    ]
                }
            });

            getById(&quot;id_div&quot;).style.display = &quot;none&quot;;
            getById(&quot;peer_id&quot;).style.display = &quot;block&quot;;
            peer.on('connection', function(conn) {
                setConnection(conn);
            });

            getById(&quot;sub_peer_btn&quot;).onclick = function() {
                conn = peer.connect(getById(&quot;peerid&quot;).value);
                conn.on('open', function() {
                    setConnection(conn);
                });
            }
        });
}"><pre><code>getById("sub_id_btn").onclick = function() {
      let myname = getById("myid").value,
        params = {
            username: myname,
            key: "your_public_key_here",
        },

        options = {
            method: "POST",
            body: new URLSearchParams(params),
        };

    fetch("https://your_domain_name/creds/", options)
        .then(response =&gt; response.json())
        .then(data =&gt; {
            let creds = data.data;
            peer = new Peer(myname, {
                host: "your_domain_name",
                port: 8999,
                key: "peerjs",
                secure: true,
                path: "/myapp",
                config: {
                    iceServers: [{
                            urls: "stun:your_domain_name:5349",
                        },
                        {
                            urls: "turn:your_domain_name:5349",
                            username: creds.username,
                            credential: creds.password
                        }
                    ]
                }
            });

            getById("id_div").style.display = "none";
            getById("peer_id").style.display = "block";
            peer.on('connection', function(conn) {
                setConnection(conn);
            });

            getById("sub_peer_btn").onclick = function() {
                conn = peer.connect(getById("peerid").value);
                conn.on('open', function() {
                    setConnection(conn);
                });
            }
        });
}
</code></pre></div>
<p dir="auto">If you can get a connection, we're basically done.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">13. Tightening and tidying</h3><a id="user-content-13-tightening-and-tidying" aria-label="Permalink: 13. Tightening and tidying" href="#13-tightening-and-tidying"></a></p>
<p dir="auto">The above is a fairly minimal example, but in real life you wouldn't stop here - there are a couple of things you would want to look at before you would be comfortable leaving this running unattended.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Authentication</h4><a id="user-content-authentication" aria-label="Permalink: Authentication" href="#authentication"></a></p>
<p dir="auto">This app is designed with ad-hoc connections in mind, where a user chooses their own username and just connects without an account. This necessarily exposes the credentials mechanism in the JavaScript. The coturn server allows for a range of more robust database-based authentication methods that would involve creating accounts, etc.</p>
<p dir="auto">What we have in place now prevents abuse in that it doesn't expose login details for your TURN server that can be used for longer than 24 hours (this time limit can be set in the credentaials API <code>config.inc.php</code> file), so a super-naive "bad actor" would have to come back to the app once a day to get new credentials. A slightly more sophisticated bad actor could just include the "fetch" function in their own code and authenticate that way. A simple way to prevent that kind of abuse would be to edit the line in the <code>index.php</code> file of the credentials API to not accept cross-origin resource sharing (CORS), or restrict it to certain domains. The PeerJS server also has a CORS option that you can stipulate when starting the server.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Security list and Firewall</h4><a id="user-content-security-list-and-firewall" aria-label="Permalink: Security list and Firewall" href="#security-list-and-firewall"></a></p>
<p dir="auto">We opened a bunch of ports for testing that we don't really need open any more and best practice would be to close them, both on the server's security list and in iptables. For the above setup, all we really need open is:</p>
<ul dir="auto">
<li>22 for SSH communication</li>
<li>443 for web traffic</li>
<li>9000 for the peerJS server</li>
<li>5349 for the Coturn listening port</li>
<li>49152-65535 for Coturn relay ports</li>
</ul>
<p dir="auto">Everything else can be shut down.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[xAI has acquired X, xAI now valued at $80B (692 pts)]]></title>
            <link>https://twitter.com/elonmusk/status/1905731750275510312</link>
            <guid>43509923</guid>
            <pubDate>Fri, 28 Mar 2025 21:23:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/elonmusk/status/1905731750275510312">https://twitter.com/elonmusk/status/1905731750275510312</a>, See on <a href="https://news.ycombinator.com/item?id=43509923">Hacker News</a></p>
Couldn't get https://twitter.com/elonmusk/status/1905731750275510312: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Digital Echoes and Unquiet Minds (148 pts)]]></title>
            <link>https://www.chrbutler.com/digital-echoes-and-unquiet-minds</link>
            <guid>43509548</guid>
            <pubDate>Fri, 28 Mar 2025 20:29:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.chrbutler.com/digital-echoes-and-unquiet-minds">https://www.chrbutler.com/digital-echoes-and-unquiet-minds</a>, See on <a href="https://news.ycombinator.com/item?id=43509548">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

        

<h2>
There’s a psychological burden of digital life even heavier than distraction.
</h2>
<p><img src="https://cdn.blot.im/blog_a7eb7cf1ab024efcb17c380ef69c53f4/_image_cache/4fb32547-b9dc-4792-a37b-52de90caa249.svg" width="800" height="650">
</p>
<p>
When the iPhone was first introduced in 2007, the notion of an “everything device” was universally celebrated. A single object that could serve as phone, camera, music player, web browser, and so much more promised unprecedented convenience and connectivity. It was, quite literally, the dream of the nineties. But the better part of twenty years later, we’ve gained enough perspective to recognize that this revolutionary vision came with costs we did not anticipate.
</p>
<p>
Distraction, of course, is the one we can all relate to first. An everything device has the problem of being useful nearly all the time, and when in use, all consuming. When you use it to do one thing, it pushes you toward others. In order to avoid this, you must disable functions. That’s an interesting turn of events, isn’t it? We have made a thing that does more than we need, more often than we desire. Because system-wide, duplicative notifications are enabled by default, the best thing you could say about the device’s design is that it lacks a point of view toward a prioritization of what it does. The worst thing you could say is that it is distracting <em>by design</em>.
</p>
<p>
(I find it fascinating how many people –&nbsp;myself included — attempt to reduce the features of their smartphone to the point of replicating a “dumbphone” experience in order to save ourselves from distraction, but don’t actually go so far as to use a lesser-featured phone because a few <em>key</em> features are just too good to give up. A dumbphone is less distracting, but a nightmare for text messaging and a lousy camera. It turns out I don’t want a <em>phone</em> at all, but a camera that texts — and ideally one smaller than anything on the market now. I know I’m not alone, and yet this product will not be made. )
</p>
<p>
This kind of distraction is <em>direct</em> distraction. It’s the kind we are increasingly aware of, and as its accumulating stress puts pressure on our inner and outer lives, we can combat it with various choices and optimizations. But there is another kind of distraction that is less direct, though just as cumulative and, I believe, just as toxic. I’ve come to think of it as the “digital echo.”
</p>
<p>
On a smartphone, every single thing it is used to do generates information that goes elsewhere. The vast majority of this is unseen — though not unfelt — by us. Everyone knows that there is no privacy within a digital device, nor within its “listening” range. We are all aware that as much information as smartphone provides to us, exponentially more is generated for someone else — someone watching, listening, measuring, and monetizing. The “digital echo” is more than just the awareness of this; it is the cognitive burden of knowing that our actions generate data elsewhere. The echo exists whenever we use connected technology, creating a subtle but persistent awareness that what we do isn’t just our own. A device like a smartphone has always generated a “digital echo”, but many others are as well.
</p>
<p>
Comparing two different motor vehicles illustrates this well. In a car like a Tesla, which we might think of as a “smartcar” since it’s a computer you can drive, <em>every</em> function produces a digital signal. Adjusting the air conditioning, making a turn, opening a door — the car knows and records it all, transmitting this information to distant servers. By contrast, my 15-year-old Honda performs all of its functions without creating these digital echoes. The operations remain private, existing only in the moment they occur. In our increasingly digital world, I have begun to feel the SCIF-like isolation of the cabin of my car, and I like it.
</p>
<p>
(The “smartcar”, of course, won’t remain simply a computer you can drive. The pinnacle “smartcar” drives itself. The self-driving car represents perhaps the most acute expression of how digital culture values attention and convenience above all else, especially control and ownership. As a passenger of a self-driving car, you surrender control over the vehicle’s operation in exchange for the “freedom” to direct your attention elsewhere, most likely to some digital signal either on your own device or on screens within the vehicle. I can see the value in this; driving can be boring and most times I am behind the wheel I’d rather be doing something else. But currently, truly autonomous vehicles are service-enabling products like Waymo, meaning we also relinquish ownership. The benefits of that also seem obvious: no insurance premiums, no maintenance costs. But not every advantage is worth its cost. The economics of self-driving cars are not clear-cut. There’s a real debate to be had about
attention, convenience, and ownership that I hope will play out before we have no choice but to be a passenger in someone else’s machine.)
</p>
<p>
When I find myself looking for new ways to throttle my smartphone’s functions, or when I sit in the untapped isolation of my car, I often wonder about the costs of the “digital echo.” What is the psychological cost of knowing that your actions aren’t just your own, but create information that can be observed and analyzed by others? As more aspects of our lives generate digital echoes, they force an ambient awareness of being perpetually witnessed rather than simply existing.
</p>
<p>
This transforms even solitary activities into implicit social interactions. It forces us to maintain awareness of our “observed self” alongside our “experiencing self,” creating a kind of persistent self-consciousness. We become performers in our own lives rather than merely participants.
</p>
<p>
I think this growing awareness contributes to a growing interest in returning to single-focus devices and analog technologies. Record players and film cameras aren’t experiencing resurgence merely from nostalgia, but because they offer fundamentally different relationships with media — relationships characterized by intention, presence, and focus.
</p>
<p>
In my own life, this recognition has led to deliberate choices about which technologies to embrace and which to avoid. Here are three off the top of my head:
</p>
<ul>
<li>
Replacing streaming services with owned media formats (CDs, Blu-rays) that remain accessible on my terms, not subject to platform changes or content disappearance
</li>
<li>
Preferring printed books while using dedicated e-readers for digital texts — in this case, accepting certain digital echoes when the benefits (in particular, access to otherwise unavailable material) outweigh the costs
</li>
<li>
Rejecting smart home devices entirely, recognizing that their convenience rarely justifies the added complexity and surveillance they introduce
</li>
</ul>
<p>
You’ve probably made similarly-motivated decisions, perhaps in other areas of your life or in relation to other things entirely. What matters, I think, is that these choices aren’t about rejecting technology but about creating spaces for more intentional engagement. They represent a search for balance in a world that increasingly defaults to maximum connectivity.
</p>
<p>
I had a conversation recently with a friend who mused, “What are these the early days of?” What a wonderful question that is; we are, I hope, always living in the early days of something. Perhaps now, we’re witnessing the beginning of a new phase in our relationship with technology. The initial wave of digital transformation prioritized connecting everything possible; the next wave may be more discriminating about what should be connected and what’s better left direct and immediate. I hope to see operating systems truly designed around focus rather than multitasking, interfaces that respect attention rather than constantly competing for it, and devices that serve discrete purposes exceptionally well instead of performing multiple functions adequately.
</p>
<p>
The digital echoes of our actions will likely continue to multiply, but we can choose which echoes we’re willing to generate and which activities deserve to remain ephemeral — to exist only in the moment they occur and then in the memories of those present. What looks like revision or retreat may be the next wave of innovation, borne out of having learned the lessons of the last few decades and desiring better for the next.
</p>
        
        
        <hr>
        <p><span color="grey"><small>Written by Christopher Butler on</small></span></p><p>March 28, 2025</p> &nbsp;
        
        
        <p><span color="grey"><small>Tagged</small></span></p><a href="https://www.chrbutler.com/tagged/essays"><p>Essays</p></a>
        <hr>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Swiftly 1.0 (162 pts)]]></title>
            <link>https://swift.org/blog/introducing-swiftly_10/</link>
            <guid>43509546</guid>
            <pubDate>Fri, 28 Mar 2025 20:29:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://swift.org/blog/introducing-swiftly_10/">https://swift.org/blog/introducing-swiftly_10/</a>, See on <a href="https://news.ycombinator.com/item?id=43509546">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
<article>
  <header>
    

    <time pubdate="" datetime="2025-03-28T02:00:00-04:00">March 28, 2025</time>
    
  </header>

  <p>Today we’re delighted to introduce the first stable release of swiftly, a Swift version manager that takes the pain out of installing, managing and updating your Swift toolchain.</p>

<p>The latest version of Swift is bundled with Xcode for writing apps for Apple platforms. But perhaps you want to install Swift on a different platform like Linux, or use a different version of the toolchain for building services or command line tools. Downloading, extracting and installing a trusted build of Swift along with the relevant dependencies for your operating system can require quite a few manual and error-prone steps.</p>

<p>swiftly has been around for some years as a community-supported tool for Swift developers using Linux. With this release, we’re officially supporting it as part of the core Swift toolchain, including hosting it as part of the <a href="https://github.com/swiftlang">Swift GitHub organization</a>. We’ve also added macOS support to make it easier to install Swift separately from Xcode.</p>



<p>swiftly is the best tool to install the standalone toolchain, providing commands to install Swift on a new system, update to the latest stable version, and experiment or test with nightly snapshots or older versions. It also makes it easy to switch effortlessly between multiple installed toolchains. You can even add a file to your project repository so swiftly will use the same toolchain version for all members of your development team.</p>

<p>Naturally, swiftly itself is written in Swift, and is able to update itself to the latest version.</p>



<p>Let’s take a look at some of the features of swiftly!</p>

<p>To get started, visit <a href="https://swift.org/install">swift.org/install</a> and install it.</p>

<p>swiftly will provide directions after installation if there are any system packages, or shell commands needed for smooth operation of the new toolchain.</p>

<p>The latest Swift toolchain is installed as the default, so you can immediately use it to start a new project. For example:</p>



<p>The <code>swiftly use</code> command selects the default toolchain for Swift commands (e.g. <code>swift test</code>, <code>swift build</code>):</p>

<div><pre><code>$ swiftly use 6.0.3
$ swift --version
--
Apple Swift version 6.0.3 (swiftlang-6.0.3.1.2 clang-1600.0.28.6)
Target: arm64-apple-macosx15.0
</code></pre></div>

<p>At a later point, if there’s a new release of Swift you can install it alongside the existing toolchain with the <code>latest</code> command:</p>



<p>Pre-release of versions of Swift are available, including nightly “snapshot” toolchains. They can be easily listed using swiftly:</p>

<div><pre><code>$ swiftly list-available main-snapshot
--
Available main development snapshot toolchains
----------------------------------------------
main-snapshot-2025-03-25
...
</code></pre></div>

<p>Once you’ve identified a snapshot toolchain, it can be installed using its name:</p>

<div><pre><code>$ swiftly install main-snapshot-2025-03-25
--
Installing main-snapshot-2025-03-25
</code></pre></div>

<p>Another way to temporarily use a specific version of Swift is to use the special ‘+’ selector. With this syntax, you don’t need to first switch to a different toolchain:</p>

<div><pre><code>$ swiftly run lldb +main-snapshot-2025-03-25
--
(lldb) _
</code></pre></div>

<p>If you’re building a SwiftPM project in a team setting and want to enforce a common version of the Swift toolchain on all contributors, simply create a <code>.swift-version</code> file in the root of your project folder with the desired version (e.g. “6.0.3”).</p>

<p>As swiftly is updated with new features and bug fixes, you can run <code>swiftly self-update</code> to check and install new releases.</p>



<p>By writing swiftly in Swift, we’re able to take advantage of the language’s features, support, and ecosystem of related projects. Swift comes with standard library features for working with the filesystem in its <a href="https://developer.apple.com/documentation/foundation/">Foundation</a> module. For network operations <a href="https://github.com/swift-server/async-http-client">Async HTTP Client</a> is there to work the HTTP requests. And to retrieve the latest Swift release, swiftly uses the <a href="https://github.com/apple/swift-openapi-generator">Swift OpenAPI</a> plugin to generate the code to interact with the <a href="http://swift.org/">swift.org</a>  website. Lastly, it takes advantage of Swift’s interoperability with C to use the existing libarchive library to work with archives. swiftly uses libarchive to extract the toolchains downloaded from the Swift website and the integration is simple.</p>

<p>It can be challenging to build shell programs that work well across multiple platforms with minimal system dependencies; this motivated us to switch swiftly away from using a shell program to install it and become a self-installing binary application. swiftly has access to excellent argument parsing capabilities, beautiful <code>--help</code> screens, and the full standard library.</p>

<p>The only remaining problem was being able to deliver the operating system and processor architecture specific binary to the users system with simplicity. The <a href="http://swift.org/">swift.org</a> website helps with operating system detection, but it cannot reliably detect the Linux distribution. Luckily, there is the <a href="https://www.swift.org/documentation/articles/static-linux-getting-started.html">Swift Static Linux SDK</a> that makes binaries that work with a wide range of distributions. The processor architecture can be determined on most unixes using <code>uname -m</code> . The result of all of this is the simplicity of a copy and paste from the website to your terminal and get started with Swift.</p>



<p>Moving forward, swiftly will become the default way to install Swift outside of Xcode. The initial version supports macOS and a variety of Linux distributions, including Ubuntu, Debian, Fedora, Red Hat Enterprise Linux and Amazon Linux.</p>

<p>The <a href="https://swift.org/swiftly/documentation/swiftlydocs/">swiftly documentation</a> provides further information about <a href="https://swift.org/swiftly/documentation/swiftly/automated-install">using swiftly in a CI/CD environment</a>, as well as setting proxy servers and custom install locations for enterprise environments. swiftly is an open source project, and so you can raise new issues or contribute pull requests at its <a href="https://github.com/swiftlang/swiftly">GitHub repository</a>. You can also <a href="https://forums.swift.org/tag/swiftly">ask questions or discuss swiftly on the Swift Forums</a>.</p>

<p>Special thanks to Patrick Freed for creating swiftly, contributing it to the Swift organization, and his continued contributions to this valuable tool. The community is what makes Swift amazing!</p>



  
</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We hacked Gemini's Python sandbox and leaked its source code (at least some) (575 pts)]]></title>
            <link>https://www.landh.tech/blog/20250327-we-hacked-gemini-source-code/</link>
            <guid>43508418</guid>
            <pubDate>Fri, 28 Mar 2025 18:12:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.landh.tech/blog/20250327-we-hacked-gemini-source-code/">https://www.landh.tech/blog/20250327-we-hacked-gemini-source-code/</a>, See on <a href="https://news.ycombinator.com/item?id=43508418">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="articleContent"><h2>Back to Vegas, and This Time, We Brought Home the MVH Award !</h2>
<p>In 2024 we released the blog post <a href="https://www.landh.tech/blog/20240304-google-hack-50000">We Hacked Google A.I. for $50,000</a>, where we traveled in 2023 to Las Vegas with Joseph "rez0" Thacker, Justin "Rhynorater" Gardner, and myself, Roni "Lupin" Carta, on a hacking journey that spanned from Las Vegas, Tokyo to France, all in pursuit of Gemini vulnerabilities during Google's LLM bugSWAT event. Well, we did it again …</p>
<p>The world of Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) continues to be the Wild West of tech.  Since GPT burst onto the scene, the race to dominate the LLM landscape has only intensified, with tech giants like Meta, Microsoft, and Google racing to have the best model possible. But now there is also Anthropic, Mistral, Deepseek and more that are coming to the scene and impacting the industry at scale.</p>
<p>As companies rush to deploy AI assistants, classifiers, and a myriad of other LLM-powered tools, a critical question remains: are we building securely ?  As we highlighted last year, the rapid adoption sometimes feels like we forgot the fundamental security principles, opening the door to novel and familiar vulnerabilities alike.</p>
<p>AI agents are rapidly emerging as the next game-changer in the world of artificial intelligence. These intelligent entities leverage advanced chains of thought reasoning, a process where the model generates a coherent sequence of internal reasoning steps to solve complex tasks. By documenting their thought processes, these agents not only enhance their decision-making capabilities but also provide transparency, allowing developers and researchers to understand and refine their performance. This dynamic combination of autonomous action and visible reasoning is paving the way for AI systems that are more adaptive, interpretable, and reliable. As we witness an increasing number of applications. from interactive assistants to sophisticated decision-support systems. The integration of chain-of-thought reasoning in AI agents is setting a new standard for what these models can achieve in real-world scenarios.</p>
<p>Google, to their credit, are actively recognising this emerging frontier of AI security, and they started early on.  Their "LLM bugSWAT" events, held in vibrant locales like Las Vegas, are a testament to their commitment to proactive security red teaming.  These events challenge researchers worldwide to rigorously test their AI systems, seeking out the vulnerabilities that might otherwise slip through the cracks.</p>
<p>And guess what ? We answered the call again in 2024 !  Justin and I returned to the bugSWAT event in Las Vegas, and this time, our efforts paid off in a big way.  Thanks to a brand new vulnerability in Gemini,  the one we’re about to detail, we were incredibly honored to be awarded the Most Valuable Hacker (MVH) title at this year's Las Vegas bugSWAT !</p>
<p><img src="https://www.landh.tech/images/articles/mvh-award.jpeg" alt="Google MVH Award"></p>
<p><em>Picture taken with our MVH award and 2 awesome Googlers &lt;3</em></p>
<p>So, prepare to dive deep once more.  This isn't just a repeat performance; it's a whole new vulnerability that we are about to show you ;)</p>
<h2>Discovering the new Gemini</h2>
<p>The Google team granted us early access to a preview of the next Gemini update, one that had several exciting new features. Along with this exclusive access, we received detailed documentation explaining these features and their intended functionalities. The goal was to fully explore and test these capabilities from an attacker’s perspective.</p>
<p>It all started with a simple prompt. We asked Gemini:</p>
<pre><code>run hello world in python3
</code></pre>
<p>Gemini provided the code, and the interface offered the enticing "Run in Sandbox" button. Intrigued, we started exploring.</p>
<p><img src="https://www.landh.tech/images/articles/run-hello-world-python3.png" alt="Run Hello World Python3"></p>
<h2>Gemini's Python Playground – A Secure Space... or Was It ?</h2>
<p>Gemini at the time offered a Python Sandbox Interpreter. Think of it as a safe space where you can run Python code generated by the AI itself, or even your own custom scripts, right within the Gemini environment. This sandbox, powered by Google's Gvisor in a GRTE (Google Runtime Environment), is designed to be secure. The idea is you can experiment with code without risking any harm to the underlying system, a crucial feature for testing and development.</p>
<p>gVisor is a user-space kernel developed by Google that acts as an intermediary between containerized applications and the host operating system. By intercepting system calls made by applications, it enforces strict security boundaries that reduce the risk of container escapes and limit potential damage from compromised processes. Rather than relying solely on traditional OS-level isolation, gVisor implements a minimal, tailored subset of kernel functionalities, thereby reducing the attack surface while still maintaining reasonable performance. This innovative approach enhances the security of container environments, making gVisor an essential tool for safely running and managing containerized workloads.</p>
<p>As security researchers and bug bounty hunters, we know that this gVisor sandbox is secured with multiple layers of defense and from what we’ve seen no one managed to escape this sandbox. Actually a sandbox escape could award you a $100k bounty:</p>
<p><img src="https://www.landh.tech/images/articles/sandbox-escape-reward.png" alt="Sandbox Escape VRP Reward"></p>
<p>While it might be possible to still escape it, this is a whole different set of challenges than what we were looking for.</p>
<p>However, sandboxes are not always meant to be escaped since there are a lot of cases where there is stuff inside the sandbox itself that can help us leak data. This idea, shared with us by a Googler from the security team, was to be able to have shell access inside the Sandbox itself and try to find any piece of data that wasn't supposed to be accessible. The main problem was the following: <strong>This sandbox can only run a custom compiled Python binary.</strong></p>
<h2>Mapping the Territory</h2>
<p>The first thing we saw is that it was also possible from the Front End to entirely rewrite the Python code and run our arbitrary version in the sandbox. Our first step was to understand the structure of this sandbox. We suspected there might be interesting files lurking around. Since we can’t pop a shell, we checked which libraries were available in this custom compiled Python binary. We found out that os was present ! Great, we can then use it to map the filesystem.</p>
<p>We wrote the following Python Code:</p>
<pre><code>import os

def get_size_formatted(size_in_bytes):
    if size_in_bytes &gt;= 1024 ** 3:
        size = size_in_bytes / (1024 ** 3)
        unit = "Go"
    elif size_in_bytes &gt;= 1024 ** 2:
        size = size_in_bytes / (1024 ** 2)
        unit = "Mb"
    else:
        size = size_in_bytes / 1024
        unit = "Ko"
    return f"{size:.2f} {unit}"

def lslR(path):
    try:
        # Determine if the path is a directory or a file
        if os.path.isdir(path):
            type_flag = 'd'
            total_size = sum(os.path.getsize(os.path.join(path, f)) for f in os.listdir(path))
        else:
            type_flag = 'f'
            total_size = os.path.getsize(path)
        
        size_formatted = get_size_formatted(total_size)
        
        # Check read and write permissions
        read_flag = 'r' if os.access(path, os.R_OK) else '-'
        write_flag = 'w' if os.access(path, os.W_OK) else '-'
        
        # Print the type, permissions, size, and path
        print(f"{type_flag}{read_flag}{write_flag} - {size_formatted} - {path}")
        
        # If it's a directory, recursively print the contents
        if type_flag == 'd':
            for entry in os.listdir(path):
                entry_path = os.path.join(path, entry)
                lslR(entry_path)
    except PermissionError:
        print(f"d-- - 0Ko - {path} (PermissionError: cannot access)")
    except Exception as e:
        print(f"--- - 0Ko - {path} (Error: {e})")
</code></pre>
<p>The goal for this code was to have some kind of recursive listing of files and directories function to be able to see which files are present, their size and also their permissions.</p>
<p>We’ve used the function to list the <code>lslR("/usr")</code> directory.</p>
<p><img src="https://www.landh.tech/images/articles/sandbox-listing.jpeg" alt="Sandbox Listing"></p>
<p>This call identified a binary file located at <code>/usr/bin/entry/entry_point</code>. This sounds juicy !</p>
<p><img src="https://i.giphy.com/3o6MbnvuZWdgL2JI88.webp" alt="Sniff"></p>
<h2>Leak the entry_point file</h2>
<p>Our next move was to extract this file, but with it being 579Mb in size, directly base64 encoding and printing it in the Front End wasn't an option, it caused the entire sandbox to hang until it eventually timed out.</p>
<p>We attempted to see if we could run TCP, HTTP, and DNS calls to exfiltrate information. Intriguingly, all our outbound connection attempts failed, the sandbox appeared completely isolated from the external network. This led to an interesting puzzle: if the sandbox is so tightly isolated that it cannot make external calls, how does it interface with Google services like Google Flights and others ? Well … we might be able to answer this later ;D</p>
<p>So we needed to exfiltrate this binary by printing in the console into chunks, for that we used the seek() function to walk through the binary file and retrieve the entire binary in chunks of 10 MB.</p>
<pre><code>import os
import base64

def read_and_encode(file_path, kilobytes):
    try:
        # Calculate the number of bytes to read
        num_bytes = kilobytes * 1024
        
        # Open the file and read the specified number of bytes
        with open(file_path, 'rb') as file:
            file_content = file.read(num_bytes)
        
        # Base64 encode the bytes
        encoded_content = base64.b64encode(file_content)
        
        # Print the encoded string
        print(encoded_content.decode('utf-8'))
    
    except FileNotFoundError:
        print(f"FileNotFoundError: {file_path} does not exist")
    except PermissionError:
        print(f"PermissionError: Cannot access {file_path}")
    except Exception as e:
        print(f"Error: {e}")

read_and_encode("/usr/bin/entry/entry_point", 10000)
</code></pre>
<p><img src="https://www.landh.tech/images/articles/sandbox-exfil-chunks.png" alt="Sandbox Exfil Chunks"></p>
<p>We then used <a href="https://caido.io/">Caido</a> to catch the request in our proxy that would run the sandbox call and fetch the result and then send it into the Automate feature. The Automate feature allows you to send requests in bulk. This feature provides a flexible way to initiate bruteforce/fuzzing to rapidly modify certain parameters of requests using wordlists.</p>
<blockquote>
<p>Note from Lupin: In the article it seems like a straightforward path, but actually we took several hours to get to that point. It was 3 am we were hacking with Justin and I was sleeping on my keyboard while Justin was exfiltrating the binary using Caido.</p>
</blockquote>
<p>Once we had all the base64 chunks, we reconstructed the entire file locally and we were ready to see its content.</p>
<h2>How to read this file ?</h2>
<h3>file command ?</h3>
<p>Running the file command on the binary revealed its identity as an <code>binary: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, interpreter /usr/grte/v5/lib64/ld-linux-x86-64.so.2</code> This  confirms that the file is a binary. Mmmmmh what can we do with this ?</p>
<h3>strings command ?</h3>
<p>When we executed the strings command, the output was particularly intriguing due to multiple references to <code>google3</code>, Google’s internal repository. This pointed to the presence of internal data paths and code snippets that were never meant for external exposure, clearly indicating that the binary contains traces of Google’s proprietary software. But is there actually any security implication ?</p>
<h3>Binwalk FTW !</h3>
<p>The real breakthrough came when using Binwalk. This tool managed to extract an entire file structure from within the binary, revealing a comprehensive sandbox layout. The extraction uncovered multiple directories and files, painting a detailed picture of the internal architecture and exposing components where our reaction upon what we found was like ... OMG.</p>
<h2>Wait … is that internal Source Code ?</h2>
<p>When digging into the extract generated by our binwalk analysis, we unexpectedly found internal source code. The extraction revealed entire directories of proprietary Google source code. But is it sensitive ?</p>
<h3>Google3 Directory with Python Code</h3>
<p>In the binwalk extracted directory we can find a <code>google3</code> directory with the following files:</p>
<pre><code>total 2160
drwxr-xr-x   14 lupin  staff   448B Aug  7 06:17 .
drwxr-xr-x  231 lupin  staff   7.2K Aug  7 18:31 ..
-r-xr-xr-x    1 lupin  staff   1.1M Jan  1  1980 __init__.py
drwxr-xr-x    5 lupin  staff   160B Aug  7 06:17 _solib__third_Uparty_Scrosstool_Sv18_Sstable_Ccc-compiler-k8-llvm
drwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 assistant
drwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 base
drwxr-xr-x    5 lupin  staff   160B Aug  7 06:17 devtools
drwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 file
drwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 google
drwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 net
drwxr-xr-x    9 lupin  staff   288B Aug  7 06:17 pyglib
drwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 testing
drwxr-xr-x    9 lupin  staff   288B Aug  7 06:17 third_party
drwxr-xr-x    4 lupin  staff   128B Aug  7 06:17 util
</code></pre>
<p>In the <code>assistant</code> directory, internal Gemini code related to RPC calls (used for handling requests via tools like YouTube, Google Flights, Google Maps, etc.) was also discovered. The directory structure is as follows:</p>
<pre><code>.
├── __init__.py
└── boq
    ├── __init__.py
    └── lamda
        ├── __init__.py
        └── execution_box
            ├── __init__.py
            ├── images
            │   ├── __init__.py
            │   ├── blaze_compatibility_hack.py
            │   ├── charts_json_writer.py
            │   ├── format_exception.py
            │   ├── library_overrides.py
            │   ├── matplotlib_post_processor.py
            │   ├── py_interpreter.py
            │   ├── py_interpreter_main.py
            │   └── vegalite_post_processor.py
            ├── sandbox_interface
            │   ├── __init__.py
            │   ├── async_sandbox_rpc.py
            │   ├── sandbox_rpc.py
            │   ├── sandbox_rpc_pb2.pyc
            │   └── tool_use
            │       ├── __init__.py
            │       ├── metaprogramming.py
            │       └── runtime.py
            └── tool_use
                ├── __init__.py
                └── planning_immersive_lib.py

8 directories, 22 files
</code></pre>
<h3>A Closer Look at the Python Code</h3>
<p>Inside the file <code>google3/assistant/boq/lamda/execution_box/images/py_interpreter.py</code>, a snippet of code reveals:</p>
<pre><code># String for attempted script dump detection:
  snippet = (  # pylint: disable=unused-variable
      "3AVp#dzcQj$U?uLOj+Gl]GlY&lt;+Z8DnKh"  # pylint: disable=unused-variable
  )
</code></pre>
<p>This snippet appears to serve as a safeguard against unauthorized script dumping, underscoring that the code was never intended for public exposure.</p>
<p><img src="https://c.tenor.com/3eIvVsG3yPYAAAAd/tenor.gif" alt="Mind-Blown"></p>
<p>After a thorough review, the inclusion of what appeared to be internal Google3 code was, in fact, a deliberate choice… Too bad x)</p>
<p>The Python code, despite its anti-dumping mechanism that might initially indicate restricted access, had been explicitly approved for public exposure by the Google Security Team well before launch. Although these measures were originally designed to prevent unintended printing, they were retained because … why not ?</p>
<p>But we didn’t leave this sandbox alone, we knew we were close to something huge ! ;D</p>
<h2>Digging the main logic of the Sandbox</h2>
<p>While digging deeper into the Python code, we noticed that, as expected, this sandbox was communicating with external Google servers to perform activities such as fetch data from Google Flights or other Google services.</p>
<p>This was implemented via a python class (<code>google3.assistant.boq.lamda.execution_box.sandbox_interface</code>) which exposed various functions like <code>_set_reader_and_writer</code>  that could be called.</p>
<pre><code>def _set_reader_and_writer(
    reader_handle: io.BufferedReader | None,
    writer_handle: io.BufferedWriter | None,
) -&gt; None:
  """Sets the reader and writer handles for rpcs.

  Should be called before running any user code that might
  import async_sandbox_rpc

  Args:
    reader_handle: the handle through which to receive incoming RpcResponses. If
      None will default to legacy behavior (/dev/fd/3)
    writer_handle: the handle through which to receive incoming RpcRequests. If.
      None will default to legacy behavior (/dev/fd/4)
  """
  with _INIT_LOCK:
    global _READER_HANDLE
    global _WRITER_HANDLE
    _READER_HANDLE, _WRITER_HANDLE = reader_handle, writer_handle
</code></pre>
<pre><code>def run_tool(
    name: str, operation_id: str, parameters: str
) -&gt; sandbox_rpc_pb2.RunToolResponse:
  """Runs a tool with the given name and id, passing in parameters.

  Args:
    name: The name of the tool.
    operation_id: The name of the operation to perform.
    parameters: The parameters to pass to the tool.

  Returns:
    A RunToolResponse containing the response from the tool.
  """
  result = make_rpc(
      sandbox_rpc_pb2.RpcRequest(
          run_tool_request=sandbox_rpc_pb2.RunToolRequest(
              name=name, operation_id=operation_id, parameters=parameters
          )
      )
  )

  if result and result.HasField("run_tool_response"):
    return result.run_tool_response
  else:
    return sandbox_rpc_pb2.RunToolResponse(response="")
</code></pre>
<p>We would provide various pieces of data to these functions, they would serialize the data into the protobuf compatible format, and then call out over RPC by writing to a local file descriptor <code>5</code>. The response could then be read by reading from local file descriptor <code>7</code>. By utilizing the protos that were found in the massive binary, we were able to craft messages to and from this RPC server, and call these Google tools directly.</p>
<p>However, we noticed something interesting, not every sandboxes would have the same set of Google services available. It would depend if the sandbox was spawned by the Front End to be able to run Python source code, or by the Google Agent. What do we mean by that ?</p>
<h3>ReAct Research paper !</h3>
<p>Before explaining the next part, we need to explain that Google’s team showed us the following research paper that Gemini is based of:</p>
<ul>
<li><a href="https://arxiv.org/pdf/2210.03629">REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS</a></li>
</ul>
<p>This paper introduces a novel approach (at the time) where language models alternate between generating reasoning traces and executing specific actions, effectively merging thought and behavior in an interleaved manner. In practice, this means that as the model reasons through a problem, creating a transparent trail of thought that helps it plan, track, and adjust its actions, it simultaneously interacts with external sources to gather additional data when needed. This dynamic interplay not only boosts the model’s performance by mitigating common issues like hallucination and error propagation but also makes its decision-making process more interpretable and controllable for human operators.</p>
<p>By integrating both internal reasoning and external knowledge, ReAct offers a flexible and general framework that excels across a variety of tasks, ranging from question answering and fact verification to text-based games and web navigation. In essence, ReAct leverages the combined strengths of reasoning and acting to create more robust, human-aligned, and versatile language models.</p>
<p><img src="https://www.landh.tech/images/articles/react-paper.png" alt="ReAct"></p>
<p>Ok, but why do we need to understand this ? Well, if we follow the logic of this paper, basically Gemini can prompt itself several times in order to refine the commands and have a proper chain of thoughts.</p>
<p>If a user asks “What is the earliest flight between Toronto and New York ?”, Gemini would have roughly a chain of thought like:</p>
<ol>
<li>
<p>The user is asking me to search the earliest flight between Toronto and New York</p>
</li>
<li>
<p>Creating a plan like:</p>
<ol>
<li>I need to run a Python code that will connect to Google Flights tool</li>
<li>The code needs to find all flights from today to next week from YYZ airport to JFK airport</li>
<li>The code needs to sort by date the flights and take the first item</li>
</ol>
</li>
<li>
<p>Once the plan done, it would generate the code with the available Tools that the Agent has</p>
</li>
<li>
<p>Once the code generated, it would spawn a sandbox with the right privileges (eg: having access to the Google Flights tool through the file descriptor)</p>
</li>
<li>
<p>Run the code, process the output</p>
</li>
<li>
<p>Makes a response to the user</p>
</li>
</ol>
<p>So our theory was the following:</p>
<ul>
<li>What if we could do a secondary prompt injection in the planning section of Gemini in order to have access to a more privileged sandbox ?</li>
</ul>
<p>With the help of the Google Security Team, we tested this idea and observed that, depending on factors like the generation seed and temperature (all the usual probabilistic LLM nuances), we could occasionally access what appeared to be a more privileged sandbox.</p>
<p>By “more privileged sandbox,” we mean one that can access the extensions through two new file descriptors. These file descriptors are always present but aren’t always actively listening, when the agent calls the sandbox, they monitor for any calls to the extensions (Google services) so that we can interact with the API, whereas if accessed through the Python interpreter, those extensions remain inaccessible.</p>
<p>This led us to believe that there was a real opportunity for a P0 vulnerability: there was a specific message handler that might allow a file read on Google’s internal infrastructure, and we were hopeful that the sandbox with the tool extension could initiate an RPC call to this specific tool. Given the probabilistic nature of the attack, which made it difficult to reproduce consistently, we have Google Security Team assess this situation. Ultimately, their review revealed that the suspicious message handler was not available via RPC and could only be called externally.</p>
<p><img src="https://www.landh.tech/images/articles/sandbox-answer.png" alt="Sandbox Answer"></p>
<p>Even though our tests were limited, the core idea still has some real potential if we push it further. Running code in the sandbox context isn’t meant to give extra powers, it's treated as untrusted, with safety checks outside the sandbox and every tool call being filtered. But being able to run code does offer some neat benefits:</p>
<ul>
<li>
<p><strong>Reliability</strong>: Once you can run code, you can trigger actions more consistently.</p>
</li>
<li>
<p><strong>Chaining/Complexity</strong>: Controlling multiple tools or fine-tuning parameters via plain text is tough; code execution could let you build more complex chains, even if safety measures are still in place.</p>
</li>
<li>
<p><strong>Tool Output Poisoning</strong>: You might be able to manipulate a tool’s output more effectively.</p>
</li>
<li>
<p><strong>Leaks</strong>: There could be other hidden parts of the environment that, if exposed, might offer extra advantages.</p>
</li>
</ul>
<p>This shows that our idea still holds promise for further escalation. And that “leaks” potential, we wanted to see if we could at least confirm this one theory …</p>
<h2>We found our leak ;D</h2>
<p>While digging deeper, we uncovered several ways to leak proto files. In case you're not familiar, proto files (short for Protocol Buffer files) are like the blueprints of data, defining how messages are structured and how information is exchanged between different parts of the system. At first glance, they might seem harmless, but leaking these files can give a pretty detailed peek into Google’s internal architecture.</p>
<h3>Exposing classification.proto</h3>
<p>It turns out that by running a command like:</p>
<pre><code>strings entry_point &gt; stringsoutput.txt
</code></pre>
<p>and then searching for “Dogfood” in the resulting file, we managed to retrieve snippets of the internal protos. Parts of the extracted content included the metadata description of extremely sensitive protos. It didn’t contain user data by itself but those files are internal categories Google uses to <strong>classify</strong> user data.</p>
<p><em>For legal reasons we can’t show the result of this command x)</em></p>
<p><img src="https://www.landh.tech/images/articles/legal-reasons.png" alt="legal reasons"></p>
<p>Why search for the string “Dogfood” specifically ? At Google, "dogfood" refers to the practice of using pre-release versions of the company's own products and prototypes internally to test and refine them before a public launch. It allows devs to test the deployment and potential issues in these products, before going to production.</p>
<p>Moreover, there was the following exposed file, <code>privacy/data_governance/attributes/proto/classification.proto</code>, which details how data is classified within Google. Although the file includes references to associated documentation, those documents remain highly confidential and should not be publicly accessible.</p>
<blockquote>
<p>Note from Lupin again: This was found the next day of our all-nighter where we exfiltrated the binary file. We were in a suite in an Hotel Room booked by Google, and we were working with the security team to understand what we had found the previous night. This time Justin was the one who slept on the couch hahaha ! This bug was really time consuming but so fun ! 😀</p>
</blockquote>

<p>Exposing Internal Security Proto Definitions</p>
<p>The same output also reveals numerous internal proto files that should have remained hidden. Running:</p>
<pre><code>cat stringsoutput.txt| grep '\.proto' | grep 'security'
</code></pre>
<p>lists several sensitive files, including:</p>
<pre><code>security/thinmint/proto/core/thinmint_core.proto
security/thinmint/proto/thinmint.proto
security/credentials/proto/authenticator.proto
security/data_access/proto/standard_dat_scope.proto
security/loas/l2/proto/credstype.proto
security/credentials/proto/end_user_credentials.proto
security/loas/l2/proto/usertype.proto
security/credentials/proto/iam_request_attributes.proto
security/util/proto/permission.proto
security/loas/l2/proto/common.proto
ops/security/sst/signalserver/proto/ss_data.proto
security/credentials/proto/data_access_token_scope.proto
security/loas/l2/proto/identity_types.proto
security/credentials/proto/principal.proto
security/loas/l2/proto/instance.proto
security/credentials/proto/justification.proto
</code></pre>
<p>When looking in the binary strings for <code>security/credentials/proto/authenticator.proto</code> confirms that its data is indeed exposed.</p>
<h2>Why were those protos there?</h2>
<p>As we said previously, the Google Security Team thoroughly reviewed everything in the sandbox and gave a green light for public disclosure. However, the build pipeline for compiling the sandbox binary included an automated step that adds security proto files to a binary whenever it detects that the binary might need them to enforce internal rules.</p>
<p>In this particular case, that step wasn’t necessary, resulting in the unintended inclusion of highly confidential internal protos in the wild !</p>
<p>As bug bounty hunters, it's essential to deeply understand the business rules that govern a company’s operations. We reported these proto leaks because we know that Google treats them as highly confidential information that should never be exposed. The more we understand the inner workings and priorities of our target, the better we are at identifying and flaging those subtle bugs that might otherwise slip under the radar. This deep knowledge not only helps us pinpoint vulnerabilities but also ensures our reports are aligned with the critical security concerns of the organization.</p>
<h2>Conclusion</h2>
<p>Before we wrap things up, it’s worth mentioning how vital it is to test these cutting-edge A.I. systems before they go live. With so many interconnections and cool features, like even a simple sandbox that can access different extensions, there’s always the potential for unexpected surprises. We’ve seen firsthand that when all these parts work together, even a small oversight can open up new avenues for issues. So, thorough testing isn’t just a best practice; it’s the only way to make sure everything stays secure and functions as intended.</p>
<p>At the end of the day, what made this whole experience so memorable was the pure fun of the ride. Cracking vulnerabilities, exploring hidden code, and pushing the limits of Gemini's sandbox was as much about the challenge as it was about the excitement of the hunt. The people we’ve met at the bugSWAT event in Las Vegas were all awesome. The shared laughs over unexpected twists, and the thrill of outsmarting complex systems turned this technical journey into an adventure we’ll never forget. It’s moments like these, where serious hacking meets good times, that remind us why we do what we do.</p>
<p>Finally, a huge shout-out to all the other winners and participants who made bugSWAT 2024 such a blast. We want to congratulate Sreeram &amp; Sivanesh for their killer teamwork, Alessandro for coming so close to that top spot, and En for making it onto the podium. It was an absolute thrill meeting so many amazing hackers and security pros, your energy and passion made this event unforgettable. We can’t wait to see everyone again at the next bugSWAT, and until then, keep hacking and having fun !</p>
<p>And of course, thanks to the Google Security team ! As always you rock ❤️</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Hexi – Modern header-only network binary serialisation for C++ (101 pts)]]></title>
            <link>https://github.com/EmberEmu/Hexi</link>
            <guid>43508061</guid>
            <pubDate>Fri, 28 Mar 2025 17:37:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/EmberEmu/Hexi">https://github.com/EmberEmu/Hexi</a>, See on <a href="https://news.ycombinator.com/item?id=43508061">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/EmberEmu/Hexi/blob/master/docs/assets/header.png"><img src="https://github.com/EmberEmu/Hexi/raw/master/docs/assets/header.png" alt="Hexi, Easy Peasy Binary Streaming"></a></p>
<p dir="auto">
    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/67c9ada79023e3b1ef117c1ca7612d1a400889248d0a338dde8ebe7cc09f5d45/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f432532422532422d32332d454337314130"><img src="https://camo.githubusercontent.com/67c9ada79023e3b1ef117c1ca7612d1a400889248d0a338dde8ebe7cc09f5d45/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f432532422532422d32332d454337314130" data-canonical-src="https://img.shields.io/badge/C%2B%2B-23-EC71A0"></a>
    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/dc060948d856eec5622f32dffb4abc9227172bdf04fb4da0879bf4930916885b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4743432d31332d454337314130"><img src="https://camo.githubusercontent.com/dc060948d856eec5622f32dffb4abc9227172bdf04fb4da0879bf4930916885b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4743432d31332d454337314130" data-canonical-src="https://img.shields.io/badge/GCC-13-EC71A0"></a>
    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/25285f6ee2b43e22154556e473bef0c788484ea703a9beda1e52c5011eca7ae8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f436c616e672d31372d454337314130"><img src="https://camo.githubusercontent.com/25285f6ee2b43e22154556e473bef0c788484ea703a9beda1e52c5011eca7ae8/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f436c616e672d31372d454337314130" data-canonical-src="https://img.shields.io/badge/Clang-17-EC71A0"></a>
    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/24efb1d28db4ff3c9aa2ad0236671f92c9b3ad9360c8a710c0d4e4cb1b3b72c2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d5356432d31372d454337314130"><img src="https://camo.githubusercontent.com/24efb1d28db4ff3c9aa2ad0236671f92c9b3ad9360c8a710c0d4e4cb1b3b72c2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d5356432d31372d454337314130" data-canonical-src="https://img.shields.io/badge/MSVC-17-EC71A0"></a>
</p>
<p dir="auto">
    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/8f5d298e3316491ef0d54f042284289d02edd9c4df8623545474c12cb1994f57/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f616374696f6e732f776f726b666c6f772f7374617475732f656d626572656d752f686578692f636d616b652d6d756c74692d706c6174666f726d2e796d6c3f6c6f676f3d676974687562616374696f6e73266c6162656c3d556e69742532305465737473266c6f676f436f6c6f723d776869746526636f6c6f723d454337314130"><img src="https://camo.githubusercontent.com/8f5d298e3316491ef0d54f042284289d02edd9c4df8623545474c12cb1994f57/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f616374696f6e732f776f726b666c6f772f7374617475732f656d626572656d752f686578692f636d616b652d6d756c74692d706c6174666f726d2e796d6c3f6c6f676f3d676974687562616374696f6e73266c6162656c3d556e69742532305465737473266c6f676f436f6c6f723d776869746526636f6c6f723d454337314130" data-canonical-src="https://img.shields.io/github/actions/workflow/status/emberemu/hexi/cmake-multi-platform.yml?logo=githubactions&amp;label=Unit%20Tests&amp;logoColor=white&amp;color=EC71A0"></a>
</p>
<p dir="auto">Hexi is a lightweight, header-only C++23 library for safely handling binary data from arbitrary sources (but primarily network data). It sits somewhere between manually memcpying bytes from network buffers and full-blown serialisation libraries.</p>
<p dir="auto">The design goals are ease of use, safety when dealing with untrusted data, a reasonable level of flexibility, and keeping overhead to a minimum.</p>
<p dir="auto">What Hexi doesn't offer: versioning, conversion between different formats, handling of text-based formats, unloading the dishwasher.</p>
<p dir="auto">Hexi is dual-licensed under MIT and Apache License, Version 2.0. This means you can use Hexi under the license you prefer.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/EmberEmu/Hexi/blob/master/docs/assets/frog-getting-started.png"><img src="https://github.com/EmberEmu/Hexi/raw/master/docs/assets/frog-getting-started.png" alt="Getting started"></a></p>
<p dir="auto">Incorporating Hexi into your project is simple! The easiest way is to simply copy <code>hexi.h</code> from <code>single_include</code> into your own project. If you'd rather only include what you use, you can add <code>include</code> to your include paths or incorporate it into your own CMake project with <code>target_link_library</code>. To build the unit tests, run CMake with <code>ENABLE_TESTING</code>.</p>
<p dir="auto">Here's what some libraries might call a very simple motivating example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="#include <hexi.h>
#include <array>
#include <vector>
#include <cstddef>

struct UserPacket {
    uint64_t user_id;
    uint64_t timestamp;
    std::array<uint8_t, 16> ipv6;
};

auto deserialise(std::span<const char> network_buffer) {
    hexi::buffer_adaptor adaptor(network_buffer); // wrap the buffer
    hexi::binary_stream stream(adaptor);          // create a binary stream
    
    // deserialise!
    UserPacket packet;
    stream >> packet;
    return packet;
}

auto serialise(const UserPacket&amp; packet) {
    std::vector<uint8_t> buffer;
    hexi::buffer_adaptor adaptor(buffer); // wrap the buffer
    hexi::binary_stream stream(adaptor);  // create a binary stream
    
    // serialise!
    stream << packet;
    return buffer;
}"><pre>#<span>include</span> <span><span>&lt;</span>hexi.h<span>&gt;</span></span>
#<span>include</span> <span><span>&lt;</span>array<span>&gt;</span></span>
#<span>include</span> <span><span>&lt;</span>vector<span>&gt;</span></span>
#<span>include</span> <span><span>&lt;</span>cstddef<span>&gt;</span></span>

<span>struct</span> <span>UserPacket</span> {
    <span>uint64_t</span> user_id;
    <span>uint64_t</span> timestamp;
    std::array&lt;<span>uint8_t</span>, <span>16</span>&gt; ipv6;
};

<span>auto</span> <span>deserialise</span>(std::span&lt;<span>const</span> <span>char</span>&gt; network_buffer) {
    hexi::buffer_adaptor <span>adaptor</span>(network_buffer); <span><span>//</span> wrap the buffer</span>
    hexi::binary_stream <span>stream</span>(adaptor);          <span><span>//</span> create a binary stream</span>
    
    <span><span>//</span> deserialise!</span>
    UserPacket packet;
    stream &gt;&gt; packet;
    <span>return</span> packet;
}

<span>auto</span> <span>serialise</span>(<span>const</span> UserPacket&amp; packet) {
    std::vector&lt;<span>uint8_t</span>&gt; buffer;
    hexi::buffer_adaptor <span>adaptor</span>(buffer); <span><span>//</span> wrap the buffer</span>
    hexi::binary_stream <span>stream</span>(adaptor);  <span><span>//</span> create a binary stream</span>
    
    <span><span>//</span> serialise!</span>
    stream &lt;&lt; packet;
    <span>return</span> buffer;
}</pre></div>
<p dir="auto">By default, Hexi will try to serialise basic structures such as our <code>UserPacket</code> if they meet requirements for being safe to directly copy the bytes. Now, for reasons of portability, it's not recommended that you do things this way unless you're positive that the data layout is identical on the system that wrote the data. Not to worry, this is easily solved. Plus, we didn't do any error handling. All in good time.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/EmberEmu/Hexi/blob/master/docs/assets/frog-remember.png"><img src="https://github.com/EmberEmu/Hexi/raw/master/docs/assets/frog-remember.png" alt="Remember these two classes, if nothing else!"></a></p>
<p dir="auto">The two classes you'll primarily deal with are <code>buffer_adaptor</code> and <code>binary_stream</code>.</p>
<p dir="auto"><code>binary_stream</code> takes a container as its argument and is used to do the reading and writing. It doesn't know much about the details of the underlying container.</p>
<p dir="auto">To support containers that weren't written to be used with Hexi, <code>buffer_adaptor</code> is used as a wrapper that <code>binary_stream</code> can interface with. As with <code>binary_stream</code>, it also provides read and write operations but at a lower level.</p>
<p dir="auto"><code>buffer_adaptor</code> can wrap any contiguous container or view that provides <code>data</code> and <code>size</code> member functions and optionally <code>resize()</code> for write support. From the standard library, that means the following can be used out of the box:</p>
<ul>
<li> std::array</li>
<li> std::span</li>
<li> std::string_view</li>
<li> std::string</li>
<li> std::vector</li>
</ul>
<p dir="auto">Plenty of non-standard library containers will work out of the box, too, as long as they provide a vaguely similar API.</p>
<p dir="auto">The container's value type must be a byte type (e.g. <code>char</code>, <code>std::byte</code>, <code>uint8_t</code>). <code>std::as_bytes</code> can be used as a workaround if this poses a problem.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/EmberEmu/Hexi/blob/master/docs/assets/frog-bring-your-own-containers.png"><img src="https://github.com/EmberEmu/Hexi/raw/master/docs/assets/frog-bring-your-own-containers.png"></a></p>
<p dir="auto">Hexi supports custom containers, including non-contiguous containers. In fact, there's a non-contiguous container included in the library. You simply need to provide a few functions such as <code>read</code> and <code>size</code> to allow the <code>binary_stream</code> class to be able to use it.</p>
<p dir="auto"><code>static_buffer.h</code> provides a simple example of a custom container that can be used directly with <code>binary_stream</code>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/EmberEmu/Hexi/blob/master/docs/assets/frog-i-can-help-you-avoid-segfaults.png"><img src="https://github.com/EmberEmu/Hexi/raw/master/docs/assets/frog-i-can-help-you-avoid-segfaults.png"></a></p>
<p dir="auto">As mentioned, Hexi is intended to be safe to use even when dealing with untrusted data. An example might be network messages that have been manipulated to try to trick your code into reading out of bounds.</p>
<p dir="auto"><code>binary_stream</code> performs bounds checking to ensure that it will never read more data than the buffer has available and optionally allows you to specify an upper bound on the amount of data to read. This can be useful when you have multiple messages in a buffer and want to limit the deserialisation from potentially eating into the next.</p>
<div dir="auto" data-snippet-clipboard-copy-content="buffer_t buffer;
// ... read data
hexi::binary_stream stream(buffer, 32); // will never read more than 32 bytes"><pre><span>buffer_t</span> buffer;
<span><span>//</span> ... read data</span>
hexi::binary_stream <span>stream</span>(buffer, <span>32</span>); <span><span>//</span> will never read more than 32 bytes</span></pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/EmberEmu/Hexi/blob/master/docs/assets/frog-errors-happen.png"><img src="https://github.com/EmberEmu/Hexi/raw/master/docs/assets/frog-errors-happen.png" alt="Errors happen, it's up to you to handle 'em"></a></p>
<p dir="auto">The default error handling mechanism is exceptions. Upon encountering a problem with reading data, an exception derived from <code>hexi::exception</code> will be thrown. These are:</p>
<ul dir="auto">
<li><code>hexi::buffer_underrun</code> - attempt to read out of bounds</li>
<li><code>hexi::stream_read_limit</code> - attempt to read more than the imposed limit</li>
</ul>
<p dir="auto">Exceptions from <code>binary_stream</code> can be disabled by specifying <code>no_throw</code> as a template argument, as shown:</p>
<div dir="auto" data-snippet-clipboard-copy-content="hexi::binary_stream<buf_type, hexi::no_throw> stream(...);"><pre>hexi::binary_stream&lt;buf_type, hexi::no_throw&gt; <span>stream</span>(...);</pre></div>
<p dir="auto">While this prevents <code>binary_stream</code> itself from throwing, it does not prevent propagation of exceptions from lower levels. For example, a wrapped <code>std::vector</code> could still throw <code>std::bad_alloc</code> if allocation fails when writing to it.</p>
<p dir="auto">Regardless of the error handling mechanism you use, the state of a <code>binary_stream</code> can be checked as follows:</p>
<div dir="auto" data-snippet-clipboard-copy-content="hexi::binary_stream<buf_type, hexi::no_throw> stream(...);
// ... assume an error happens

// simplest way to check whether any errors have occurred
if (!stream) {
    // handle error
}

// or we can get the state
if (auto state = stream.state(); state != hexi::stream_state::ok) {
    // handle error
}"><pre>hexi::binary_stream&lt;buf_type, hexi::no_throw&gt; <span>stream</span>(...);
<span><span>//</span> ... assume an error happens</span>

<span><span>//</span> simplest way to check whether any errors have occurred</span>
<span>if</span> (!stream) {
    <span><span>//</span> handle error</span>
}

<span><span>//</span> or we can get the state</span>
<span>if</span> (<span>auto</span> state = stream.state(); state != hexi::stream_state::ok) {
    <span><span>//</span> handle error</span>
}</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/EmberEmu/Hexi/blob/master/docs/assets/frog-writing-portable-code-is-easy-peasy.png"><img src="https://github.com/EmberEmu/Hexi/raw/master/docs/assets/frog-writing-portable-code-is-easy-peasy.png" alt="Writing portable code is easy peasy"></a></p>
<p dir="auto">In the first example, reading our <code>UserPacket</code> would only work as expected if the program that wrote the data laid everything out in the same way as our own program.
This might not be the case for reasons of architecture differences, compiler flags, etc.</p>
<p dir="auto">Here's the same example but doing it portably.</p>
<div dir="auto" data-snippet-clipboard-copy-content="#include <hexi.h>
#include <span>
#include <string>
#include <vector>
#include <cstddef>
#include <cstdint>

struct UserPacket {
    uint64_t user_id;
    std::string username;
    uint64_t timestamp;
    uint8_t has_optional_field;
    uint32_t optional_field;  // pretend this is big endian in the protocol

    // deserialise
    auto&amp; operator>>(auto&amp; stream) {
        stream >> user_id >> username >> timestamp >> has_optional_field;

        if (has_optional_field) {
            stream >> optional_field;
            hexi::endian::big_to_native_inplace(optional_field);
        }

        // we can manually trigger an error if something went wrong
        // stream.set_error_state();
        return stream;
    }

    // serialise
    auto&amp; operator<<(auto&amp; stream) const {
        stream << user_id << username << timestamp << has_optional_field;

        if (has_optional_field) {
            stream << hexi::endian::native_to_big(optional_field);
        }

        return stream;
    }
};

// pretend we're reading network data
void read() {
    std::vector<char> buffer;
    const auto bytes_read = socket.read(buffer);

    // ... logic for determing packet type, etc

    bool result {};

    switch (packet_type) {
        case packet_type::user_packet:
            result = handle_user_packet(buffer);
            break;
    }

    // ... handle result
}

auto handle_user_packet(std::span<const char> buffer) {
    hexi::buffer_adaptor adaptor(buffer);
    hexi::binary_stream stream(adaptor);

    UserPacket packet;
    stream >> packet;

    if (stream) {
        // ... do something with the packet
        return true;
    } else {
        return false;
    }
}"><pre>#<span>include</span> <span><span>&lt;</span>hexi.h<span>&gt;</span></span>
#<span>include</span> <span><span>&lt;</span>span<span>&gt;</span></span>
#<span>include</span> <span><span>&lt;</span>string<span>&gt;</span></span>
#<span>include</span> <span><span>&lt;</span>vector<span>&gt;</span></span>
#<span>include</span> <span><span>&lt;</span>cstddef<span>&gt;</span></span>
#<span>include</span> <span><span>&lt;</span>cstdint<span>&gt;</span></span>

<span>struct</span> <span>UserPacket</span> {
    <span>uint64_t</span> user_id;
    std::string username;
    <span>uint64_t</span> timestamp;
    <span>uint8_t</span> has_optional_field;
    <span>uint32_t</span> optional_field;  <span><span>//</span> pretend this is big endian in the protocol</span>

    <span><span>//</span> deserialise</span>
    <span>auto</span>&amp; <span>operator</span>&gt;&gt;(<span>auto</span>&amp; stream) {
        stream &gt;&gt; user_id &gt;&gt; username &gt;&gt; timestamp &gt;&gt; has_optional_field;

        <span>if</span> (has_optional_field) {
            stream &gt;&gt; optional_field;
            <span>hexi::endian::big_to_native_inplace</span>(optional_field);
        }

        <span><span>//</span> we can manually trigger an error if something went wrong</span>
        <span><span>//</span> stream.set_error_state();</span>
        <span>return</span> stream;
    }

    <span><span>//</span> serialise</span>
    <span>auto</span>&amp; <span>operator</span>&lt;&lt;(<span>auto</span>&amp; stream) <span>const</span> {
        stream &lt;&lt; user_id &lt;&lt; username &lt;&lt; timestamp &lt;&lt; has_optional_field;

        <span>if</span> (has_optional_field) {
            stream &lt;&lt; <span>hexi::endian::native_to_big</span>(optional_field);
        }

        <span>return</span> stream;
    }
};

<span><span>//</span> pretend we're reading network data</span>
<span>void</span> <span>read</span>() {
    std::vector&lt;<span>char</span>&gt; buffer;
    <span>const</span> <span>auto</span> bytes_read = socket.<span>read</span>(buffer);

    <span><span>//</span> ... logic for determing packet type, etc</span>

    <span>bool</span> result {};

    <span>switch</span> (packet_type) {
        <span>case</span> packet_type::user_packet:
            result = <span>handle_user_packet</span>(buffer);
            <span>break</span>;
    }

    <span><span>//</span> ... handle result</span>
}

<span>auto</span> <span>handle_user_packet</span>(std::span&lt;<span>const</span> <span>char</span>&gt; buffer) {
    hexi::buffer_adaptor <span>adaptor</span>(buffer);
    hexi::binary_stream <span>stream</span>(adaptor);

    UserPacket packet;
    stream &gt;&gt; packet;

    <span>if</span> (stream) {
        <span><span>//</span> ... do something with the packet</span>
        <span>return</span> <span>true</span>;
    } <span>else</span> {
        <span>return</span> <span>false</span>;
    }
}</pre></div>
<p dir="auto">Because <code>binary_stream</code> is a template, it's easiest to allow the compiler to perform type deduction magic.</p>
<p dir="auto">If you want the function bodies to be in a source file, it's recommended that you provide your own <code>using</code> alias for your <code>binary_stream</code> type.
The alternative is to use the polymorphic equivalents, <code>pmc::buffer_adaptor</code> and <code>pmc::binary_stream</code>, which allow you to change the underlying buffer type at runtime but at the cost of virtual call overhead and lacking some functionality that doesn't mesh well with polymorphism.</p>
<p dir="auto">How you structure your code is up to you, this is just one way of doing it.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/EmberEmu/Hexi/blob/master/docs/assets/frog-uh.png"><img src="https://github.com/EmberEmu/Hexi/raw/master/docs/assets/frog-uh.png" alt="Uh, one more thing..."></a></p>
<p dir="auto">When using <code>binary_stream</code>, strings are always treated as null-terminated. Writing a <code>char*</code>, <code>std::string_view</code> or <code>std::string</code> will always write a terminating byte to the stream. If you require otherwise, use one of the <code>put</code> functions.</p>
<p dir="auto">Likewise, reading to <code>std::string</code> assumes the buffer contains a null-terminator. If it does not, an empty string will be returned. If you know the length of the string or need to support a custom terminating/sentinel value, use <code>get()</code> and <code>find_first_of()</code>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/EmberEmu/Hexi/blob/master/docs/assets/frog-what-else-is-in-the-box.png"><img src="https://github.com/EmberEmu/Hexi/raw/master/docs/assets/frog-what-else-is-in-the-box.png" alt="What else is in the box?"></a></p>
<p dir="auto">Here's a very quick rundown on some of the included extras.</p>
<ul dir="auto">
<li><code>hexi::file_buffer</code>
<ul dir="auto">
<li>For dealing with binary files. Simples.</li>
</ul>
</li>
<li><code>hexi::static_buffer</code>
<ul dir="auto">
<li>Fixed-size networking buffer for when you know the upper bound on the amount of data you'll need to send or receive in one go. Essentially a wrapper around <code>std::array</code> but with added state tracking. Handy if you need to deserialise in multiple steps (read packet header, dispatch, read packet body).</li>
</ul>
</li>
<li><code>hexi::dynamic_buffer</code>
<ul dir="auto">
<li>Resizeable buffer for when you want to deal with occasional large read/writes without having to allocate the space up front. Internally, it adds additional allocations to accomodate extra data rather than requesting a larger allocation and copying data as <code>std::vector</code> would. It reuses allocated blocks where possible and has support for Asio (Boost or standalone). Effectively, it's a linked list buffer.</li>
</ul>
</li>
<li><code>hexi::tls_block_allocator</code>
<ul dir="auto">
<li>Allows many instances of <code>dynamic_buffer</code> to share a larger pool of pre-allocated memory, with each thread having its own pool. This is useful when you have many network sockets to handle and want to avoid the general purpose allocator. The caveat is that a deallocation must be made by the same thread that made the allocation, thus limiting access to the buffer to a single thread (with some exceptions).</li>
</ul>
</li>
<li><code>hexi::endian</code>
<ul dir="auto">
<li>Provides functionality for handling endianness of integral types.</li>
</ul>
</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/EmberEmu/Hexi/blob/master/docs/assets/frog-before.png"><img src="https://github.com/EmberEmu/Hexi/raw/master/docs/assets/frog-before.png" alt="Before we wrap up, look at these tidbits..."></a></p>
<p dir="auto">We're at the end of the overview, but there's more to discover if you decide to give Hexi a shot. Here's a selection of tasty morsels:</p>
<ul dir="auto">
<li><code>binary_stream</code> allows you to perform write seeking within the stream, when the underlying buffer supports it. This is nice if, for example, you need to update a message header with information that you might not know until the rest of the message has been written; checksums, sizes, etc.</li>
<li><code>binary_stream</code> provides overloaded <code>put</code> and <code>get</code> member functions, which allow for fine-grained control, such as reading/writing a specific number of bytes.</li>
<li><code>binary_stream</code> allows for writing to <code>std::string_view</code> and <code>std::span</code> with <code>view()</code> and <code>span()</code> as long as the underlying container is contiguous. This allows you to create views into the buffer's data, providing a fast, zero-copy way to read strings and arrays from the stream. If you do this, you should avoid writing to the same buffer while holding views to the data.</li>
<li><code>buffer_adaptor</code> provides a template option, <code>space_optimise</code>. This is enabled by default and allows it to avoid resizing containers in cases where all data has been read by the stream. Disabling it allows for preserving data even after having been read. This option is only relevant in scenarios where a single buffer is being both written to and read from.</li>
<li><code>buffer_adaptor</code> provides <code>find_first_of</code>, making it easy to find a specific sentinel value within your buffer.</li>
</ul>
<p dir="auto">To learn more, check out the examples in <code>docs/examples</code>!</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/EmberEmu/Hexi/blob/master/docs/assets/footer.png"><img src="https://github.com/EmberEmu/Hexi/raw/master/docs/assets/footer.png" alt="Thanks for listening! Now go unload the dis[C Make Lists](include/CMakeLists.txt)hwasher."></a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Real Book (2021) (130 pts)]]></title>
            <link>https://99percentinvisible.org/episode/the-real-book/</link>
            <guid>43507404</guid>
            <pubDate>Fri, 28 Mar 2025 16:39:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://99percentinvisible.org/episode/the-real-book/">https://99percentinvisible.org/episode/the-real-book/</a>, See on <a href="https://news.ycombinator.com/item?id=43507404">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p>Since the mid-1970s, almost every jazz musician has owned a copy of the same book. It has a peach-colored cover, a chunky, 1970s-style logo, and a black plastic binding. It’s delightfully homemade-looking—like it was printed by a bunch of teenagers at a Kinkos. And inside is the sheet music for hundreds of common jazz tunes—also known as jazz “standards”—all meticulously notated by hand. It’s called the Real Book.</p>
<p><img fetchpriority="high" decoding="async" src="https://99percentinvisible.org/wp-content/uploads/2021/03/history_page_1.jpeg" alt="" width="322" height="374" srcset="https://99percentinvisible.org/wp-content/uploads/2021/03/history_page_1.jpeg 388w, https://99percentinvisible.org/wp-content/uploads/2021/03/history_page_1-300x349.jpeg 300w" sizes="(max-width: 322px) 100vw, 322px"></p>
<p>But if you were going to music school in the 1970s, you couldn’t just buy a copy of the Real Book at the campus bookstore. Because the Real Book… was <em>illegal</em>. The world’s most popular collection of jazz music was a totally unlicensed publication. It was a self-published book created without permission from music publishers or songwriters. It was duplicated at photocopy shops and sold on street corners, out of the trunks of cars, and under the table at music stores where people used secret code words to make the exchange. The full story of how the Real Book came to be this bootleg bible of jazz is a complicated one. It’s a story about what happens when an insurgent, improvisational art form like jazz gets codified and becomes something that you can learn from a book.</p>
<h2>The History of Fake Books</h2>
<p><img decoding="async" src="https://99percentinvisible.org/wp-content/uploads/2021/03/image011.png" alt="" width="207" height="273"><a href="https://www.barnesandnoble.com/w/the-story-of-fake-books-barry-kernfeld/1111519327" target="_blank" rel="noopener noreferrer">Barry Kernfeld</a></p>
<p> is a musicologist who has written a lot about the history of jazz and music piracy. Kernfeld says that long before the Real Book ever came out, jazz musicians were relying on collections of music they called fake books. Kernfeld says that the story of the first fake book began in the 1940s. “A man named George Goodwin in New York City, involved in radio in the early 1940s, was getting a little frustrated with all the intricacies of tracking licensing. And so he invented this thing that he called the Tune-Dex,” explains Kernfeld.</p>
<figure id="attachment_37182" aria-describedby="caption-attachment-37182"><img decoding="async" src="https://99percentinvisible.org/wp-content/uploads/2021/03/TuneDex-600x733.jpeg" alt="" width="600" height="733" srcset="https://99percentinvisible.org/wp-content/uploads/2021/03/TuneDex-600x733.jpeg 600w, https://99percentinvisible.org/wp-content/uploads/2021/03/TuneDex-728x889.jpeg 728w, https://99percentinvisible.org/wp-content/uploads/2021/03/TuneDex-300x366.jpeg 300w, https://99percentinvisible.org/wp-content/uploads/2021/03/TuneDex.jpeg 1168w" sizes="(max-width: 600px) 100vw, 600px"><figcaption id="caption-attachment-37182">TuneDex card via <a href="https://blog.library.gsu.edu/2010/10/13/popular-music-tune-dex-cards/" target="_blank" rel="noopener noreferrer">Georgia State University Library</a></figcaption></figure>
<p>The Tune-Dex was an index card catalog designed for radio station employees to keep track of the songs they were playing on air. On one side the cards had information about a particular song, such as the composer, the publisher, and anything that one would need to know for payment rights. On the other side of the card were a few lines of bite-sized sheet music—just the song’s melody, lyrics, and chords so that radio station employees could glance at it and quickly recall the song. This abbreviated musical notation also made the cards useful to another group of people: working jazz musicians.</p>
<p><img loading="lazy" decoding="async" src="https://99percentinvisible.org/wp-content/uploads/2021/03/s-l1600-600x450.jpeg" alt="" width="600" height="450" srcset="https://99percentinvisible.org/wp-content/uploads/2021/03/s-l1600-600x450.jpeg 600w, https://99percentinvisible.org/wp-content/uploads/2021/03/s-l1600-728x546.jpeg 728w, https://99percentinvisible.org/wp-content/uploads/2021/03/s-l1600-300x225.jpeg 300w, https://99percentinvisible.org/wp-content/uploads/2021/03/s-l1600-1536x1152.jpeg 1536w, https://99percentinvisible.org/wp-content/uploads/2021/03/s-l1600.jpeg 1600w" sizes="auto, (max-width: 600px) 100vw, 600px"></p>
<p>As a Black art form, jazz had developed out of a mix of other Black music traditions including spirituals and the blues. By the 1940s, a lot of “jazz” was popular dance music, and many jazz musicians were making their money playing live gigs in small clubs and bars. The standard jazz repertoire was mostly well-known pop songs from Broadway, or New York’s songwriting factory: “Tin Pan Alley.”</p>
<p><iframe loading="lazy" title="Night And Day - Cole Porter" width="267" height="200" src="https://www.youtube-nocookie.com/embed/5WX_fKVWX2s?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>Jazz musicians would riff and freestyle over these songs. The art of improvisation has always been a key art form of jazz music. But what made the average gigging trumpeter or sax player truly valuable was their ability to play any one of hundreds of songs right there on the spot.</p>
<p>To be prepared for any request, musicians would bring stacks and stacks of sheet music to every gig. But lugging around a giant pile of paper could be really cumbersome—this is where the Tune-Dex came in. Someone figured out that you could gather together a bunch of Tune-Dex cards, print copies of them on sheets of paper, add a table of contents and a simple binding, and then sell the finished product directly to musicians in the form of a book. They called them “fake books” because they helped musicians fake their way through unfamiliar songs. These first fake books were cheaper than regular sheet music, and a lot more organized. They became an essential tool for this entire class of working musicians.
</p>
<h2>Bootleggers</h2>
<p>
Musicians loved these new fake books, but the music publishers hated them. They wanted musicians to buy legal sheet music, and so the publishing companies started cracking down on fake book bootleggers. That, of course, didn’t stop the bootleggers and by the 1950s, there were countless illegal fake books in existence, which were being used in nightclubs all across the country.</p>
<p><iframe loading="lazy" title="Rare Live Jazz at New Orleans Bar - 1950's" width="267" height="200" src="https://www.youtube-nocookie.com/embed/LLDELtfUsaQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>As helpful as fake books were, they had a lot of problems. They were notoriously illegible and confusingly laid out. The other big problem with these fake books at this point was that the music inside felt really out of date. The fake books hadn’t changed since the mid-40s, but jazz had. Disillusioned by commercial jazz that appealed to mainstream white audiences, a new generation of Black musicians took jazz improvisation to a new level. They experimented with more angular harmonies, technically demanding melodies and blindingly fast tempos. Their new style was called bebop.</p>
<p><iframe loading="lazy" title="Dizzy Gillespie - Bebop" width="267" height="200" src="https://www.youtube-nocookie.com/embed/09BB1pci8_o?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>Bebop was just the beginning. Over several decades, jazz exploded into this constellation of different styles. Meanwhile, the economics of jazz shifted too. There were fewer clubs, smaller paychecks, and more university jazz programs with steady teaching gigs. The ivory tower, not the nightclub, increasingly became a place for young musicians to learn, and for established musicians to earn a living. And if you’re going to jazz school, you need jazz books.</p>
<figure id="attachment_37183" aria-describedby="caption-attachment-37183"><img loading="lazy" decoding="async" src="https://99percentinvisible.org/wp-content/uploads/2021/03/1599px-WTB_Berklee_3-600x400.jpeg" alt="" width="600" height="400" srcset="https://99percentinvisible.org/wp-content/uploads/2021/03/1599px-WTB_Berklee_3-600x400.jpeg 600w, https://99percentinvisible.org/wp-content/uploads/2021/03/1599px-WTB_Berklee_3-728x485.jpeg 728w, https://99percentinvisible.org/wp-content/uploads/2021/03/1599px-WTB_Berklee_3-300x200.jpeg 300w, https://99percentinvisible.org/wp-content/uploads/2021/03/1599px-WTB_Berklee_3-1536x1024.jpeg 1536w, https://99percentinvisible.org/wp-content/uploads/2021/03/1599px-WTB_Berklee_3.jpeg 1599w" sizes="auto, (max-width: 600px) 100vw, 600px"><figcaption id="caption-attachment-37183">Berklee College of Music. Photo by <a title="User:Cryptic C62" href="https://commons.wikimedia.org/wiki/User:Cryptic_C62" target="_blank" rel="noopener noreferrer">Cryptic C62</a></figcaption></figure>
<p>The fake books at the time hadn’t kept up with the music. They still contained the same old-fashioned collection of standards with the same old-fashioned collection of chord changes. If a young jazz musician wanted to try and play like Charles Mingus or Sonny Rollins, they weren’t going to learn from a book. That is… until two college kids invented the Real Book.
</p>
<h2>The Two Guys</h2>
<p>
In the mid-70s, Steve Swallow began teaching at Boston’s Berklee College of Music, an elite private music school that boasted one of the first jazz performance programs in the country. Swallow had only been teaching at Berklee for a few months when two students approached him about a secret project. “I keep referring them to them as ‘the two guys who wrote the book,’ because…they swore me to secrecy. They made me agree that I would not divulge their names,” explains Swallow. The “two guys” wanted to make a new fake book, one that actually catered to the needs of contemporary jazz musicians and reflected the current state of jazz. And they needed Swallow’s help.</p>
<p><iframe loading="lazy" title="&quot;O Grande Amor&quot; Stan Getz, Gary Burton, Steve Swallow, Roy Haynes.1966 featuring Steve Swallow" width="267" height="200" src="https://www.youtube-nocookie.com/embed/z85JoHA9h34?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>From the very beginning, the students envisioned the Real Book as a cooler and more contemporary fake book than the stodgy, outdated ones they’d grown up with. They wanted it to include new songs from jazz fusion artists like Herbie Hancock, and free jazz pioneers like Ornette Coleman who were pushing the boundaries of the genre. They also wanted to include the old jazz standards from Broadway and Tin Pan Alley, but they wanted to update those classics with alternate chord changes that reflected the way modern musicians, like Miles Davis, were actually playing them.</p>
<p><iframe loading="lazy" title="Herbie Hancock Trio - Full Concert - 08/14/88 - Newport Jazz Festival (OFFICIAL)" width="267" height="200" src="https://www.youtube-nocookie.com/embed/jy1ICphDYTQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>Modern jazz musicians had altered a lot of classic standards over the years, with new harmonies and more complex chord changes. And to capture these new sounds, the students spent hours listening to recordings and transcribing what they heard, as best they could. It was a huge undertaking because most of these chord changes had never actually been written down. They weren’t necessarily thinking about it like this at the time, but the students were effectively establishing a new set of standardized harmonies for a handful of classic songs.</p>
<p><img loading="lazy" decoding="async" src="https://99percentinvisible.org/wp-content/uploads/2021/04/0af38b0aa71f96f108ae83a243e5de8d.jpeg" alt="" width="494" height="640" srcset="https://99percentinvisible.org/wp-content/uploads/2021/04/0af38b0aa71f96f108ae83a243e5de8d.jpeg 494w, https://99percentinvisible.org/wp-content/uploads/2021/04/0af38b0aa71f96f108ae83a243e5de8d-300x389.jpeg 300w" sizes="auto, (max-width: 494px) 100vw, 494px"></p>
<p><img loading="lazy" decoding="async" src="https://99percentinvisible.org/wp-content/uploads/2021/04/history_page_1.jpeg" alt="" width="232" height="226"></p>
<p>The music wasn’t the only part of their new fake book that the students wanted to improve. They also wanted to fix the aesthetic problems with the old fake books, and make something that was nice to look at and easy to read. One of “the two guys” notated all of the music by hand in this very distinctive and expressive script. He also designed and silk-screened the logo on the front cover: “The Real Book,” written in chunky, SchoolHouse Rock-style block letters.</p>
<p><img loading="lazy" decoding="async" src="https://99percentinvisible.org/wp-content/uploads/2021/04/Screen-Shot-2021-04-06-at-11.46.19-AM-600x273.png" alt="" width="600" height="273" srcset="https://99percentinvisible.org/wp-content/uploads/2021/04/Screen-Shot-2021-04-06-at-11.46.19-AM-600x273.png 600w, https://99percentinvisible.org/wp-content/uploads/2021/04/Screen-Shot-2021-04-06-at-11.46.19-AM-728x332.png 728w, https://99percentinvisible.org/wp-content/uploads/2021/04/Screen-Shot-2021-04-06-at-11.46.19-AM-300x137.png 300w, https://99percentinvisible.org/wp-content/uploads/2021/04/Screen-Shot-2021-04-06-at-11.46.19-AM.png 1462w" sizes="auto, (max-width: 600px) 100vw, 600px"></p>
<p>By the summer of 1975, the book was done, and the students took it to local photocopying shops where they cranked out hundreds of copies to sell directly to other students and a few local businesses near Berklee. Overnight, almost everyone had to have one. As the Real Book’s notoriety grew, so did the demand. The two students hadn’t printed enough copies to keep up, but it turns out, they didn’t need to. Not long after they created a few hundred copies of the book, bootleg versions began popping up all over the world. The Real Book had taken on a life of its own, and the students ironically found themselves in the same position as the music publishers and songwriters they’d originally cut out of the process, as they watched unlicensed copies of their work get duplicated and sold. After they released the first edition of the Real Book, the students put out two more editions to correct mistakes, and then their work was done. But the Real Book lived on, copied over and over again by new generations of bootleggers. And as the number of students in elite conservatory jazz programs continued to swell over the next few decades, the Real Book, with its modern repertoire, reharmonized standards, and beautiful handwriting, became the de-facto textbook for this new legion of jazz students. The unofficial official handbook of jazz.</p>
<p><img loading="lazy" decoding="async" src="https://99percentinvisible.org/wp-content/uploads/2021/04/Screen-Shot-2021-04-06-at-11.45.30-AM-600x772.png" alt="" width="600" height="772" srcset="https://99percentinvisible.org/wp-content/uploads/2021/04/Screen-Shot-2021-04-06-at-11.45.30-AM-600x772.png 600w, https://99percentinvisible.org/wp-content/uploads/2021/04/Screen-Shot-2021-04-06-at-11.45.30-AM-728x936.png 728w, https://99percentinvisible.org/wp-content/uploads/2021/04/Screen-Shot-2021-04-06-at-11.45.30-AM-300x386.png 300w, https://99percentinvisible.org/wp-content/uploads/2021/04/Screen-Shot-2021-04-06-at-11.45.30-AM.png 776w" sizes="auto, (max-width: 600px) 100vw, 600px">
</p>
<h2>The Real Real Book</h2>
<p>
Just like with old fake books, the success of the Real Book was a major problem for music publishers. Some companies released their own fake books, but they never managed to compete with the Real Book. The popularity of the Real Book meant that lots of people weren’t getting paid for their work. But in the mid-2000s, music executive Jeff Schroedl and the publisher Hal Leonard decided, if you can’t beat ’em, join ’em. They went through the Real Book page by page, secured the rights to almost every song, and published a completely legal version. You don’t need to buy the Real Book out of the back of someone’s car anymore. It’s available at your local music shop. They even wanted the same handwriting. Hal Leonard actually hired a copyist to mimic the old Real Book’s iconic script and turn it into a digital font, which means a digital copy of a physical copy of one anonymous Berklee student’s handwriting from the mid-70s will continue to live on for as long as new editions of the book are published.</p>
<figure id="attachment_37189" aria-describedby="caption-attachment-37189"><img loading="lazy" decoding="async" src="https://99percentinvisible.org/wp-content/uploads/2021/04/00240221FCz-600x776.jpeg" alt="" width="600" height="776" srcset="https://99percentinvisible.org/wp-content/uploads/2021/04/00240221FCz-600x776.jpeg 600w, https://99percentinvisible.org/wp-content/uploads/2021/04/00240221FCz-728x942.jpeg 728w, https://99percentinvisible.org/wp-content/uploads/2021/04/00240221FCz-300x388.jpeg 300w, https://99percentinvisible.org/wp-content/uploads/2021/04/00240221FCz.jpeg 864w" sizes="auto, (max-width: 600px) 100vw, 600px"><figcaption id="caption-attachment-37189">The Hal Leonard version of the Real Book</figcaption></figure>
<p>When Hal Leonard finally published the legal version of the Real Book in 2004, it was great news if you were a composer with a song in there. You’d finally be getting royalties from the sale of the most popular jazz fake book of all time. But that didn’t totally solve the intellectual property problems with the Real Book. While the legalization of the Real Book did resolve most of its flagrant copyright violations, it didn’t clear up authorship disputes that go back to the early days of jazz. Many jazz songs arise out of collective tinkering and improvising in jam sessions. It’s sometimes quite hard to say who exactly wrote a given song, and power dynamics often impacted whose name actually got listed as an official songwriter. And so there are likely many musicians whose names will never appear on the songs they helped write, even if those songs appear in the legal Real Book.
</p>
<h2>Useful Tool, or Reductive Cheat Sheet?</h2>
<p>
Even if we put the intellectual property questions aside for a second, fake books like the Real Book still have plenty of critics. Nicholas Payton is a musician and record label owner, and he compares the Real Book to a study guide or a cheat sheet—a way to distill this complicated art form into a manageable packet of digestible information. To Payton, jazz isn’t just information to be learned. It’s a way of thinking and a form of expression. And it’s fundamentally a Black cultural phenomenon that can’t be taken out of its historical context. Payton says that reading books like the Real Book, even going to music school, can really only get you so far. If you want to learn to play, at some point you’re going to have to immerse yourself in the culture of the music. For Payton (and many musicians) learning directly from elders, in person, is a crucial part of what it means to really know the art form.</p>
<p>There’s also the question of codification, and whether it’s useful to have one songbook filled with definitive versions of all these jazz tunes. Carolyn Wilkins has taught ensembles at Berklee College of Music, and she says that the chords that are written down in the Real Book sometimes get treated like the <em>right</em> way to play a particular song. But even though jazz has all of these “standards,” they’re not supposed to be played in one standard way. As you listen to different recordings of the same song by different jazz artists, it becomes obvious that there’s no one right way to play it. Wilkins says that the Real Book does have its place in jazz education. Over her years at Berklee, she’s seen how it can be a useful starting place as a tool to bring young jazz musicians together. The key, she says, is to treat the Real Book as a starting place. From there you need to go out and explore all the other ways people have played a particular song. “And then ultimately you must find your own way.”</p>
<p><iframe loading="lazy" title="The Birth of Jazz" width="356" height="200" src="https://www.youtube-nocookie.com/embed/1eRNRzyX3ac?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>

              </div></div>]]></description>
        </item>
    </channel>
</rss>