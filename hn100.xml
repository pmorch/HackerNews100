(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 23 Nov 2024 17:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[The 'Return to Office' Lies (147 pts)]]></title>
            <link>https://blog.avas.space/rto/</link>
            <guid>42221623</guid>
            <pubDate>Sat, 23 Nov 2024 16:17:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.avas.space/rto/">https://blog.avas.space/rto/</a>, See on <a href="https://news.ycombinator.com/item?id=42221623">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    

    
        
    

    
        

        <p>
            <i>
                <time datetime="2024-11-22T12:10Z">
                    22 Nov, 2024
                </time>
            </i>
        </p>
    

    <blockquote>
<p>Edit: Sorry for the people seeing it on HackerNews, didn‚Äôt post it there and it wasn‚Äôt intended for that audience ü§∑üèª‚Äç‚ôÄÔ∏è yes, it‚Äôs an ‚Äúimmature rant‚Äù, because it starts with ‚ÄúI have to rant about the home office situation [‚Ä¶] specifically at my place of employment‚Äù. This is not a professional article, it‚Äôs a personal blog; it was written after I was on the phone with the disability rep, talking to each other about these matters. I fear since this isn‚Äôt the US private sector I‚Äôm talking about, it may not match your experiences.</p>
</blockquote>
<p>I have to rant about the home office situation in general, but also specifically at my place of employment and similar places.</p>
<p>I cannot stand the fake positivity and cute-sounding arguments for returning to the office. It falls flat for so many and it‚Äôs trying to make it sound more legitimate by evoking this image of collaboration, being social, kindness, having a good time together when that‚Äôs not the point. The point is micromanagement and needing to justify the large office spaces they invested into. Very rarely are there positions or departments who truly need to collab in person, and then they can just do that for the occasion, not a fixed amount of days per week or month where they need to go in at all times.</p>
<p>It‚Äôs a joke. At my place, we don‚Äôt innovate, we don‚Äôt develop new products for a mass market; we do lots of data entry, emails, and writing reports in SharePoint or with comments and track changes in Word. Excel spreadsheets and databases. Absolutely everything is digitized, we send auto-emails and all communication is via Teams or Mail and very rarely over phone. Documents arrive digitally. All the collaboration is already online and there is no need for an office presence. Even when you are in office, you don‚Äôt even see the people for the work since it‚Äôs all online!</p>
<p>But they‚Äôll look at FAANG and be like: ‚ÄúOoh, they‚Äôre asking everyone to be back at the office because of better collaboration!‚Äù You clown, the collaboration happens the same regardless where my ass sits and we are not designers or knowledge workers solving issues, we handle data! We are not pioneers or a Silicon Valley tech firm!</p>
<p>Asking everyone back to the office for the supposed social aspect is truly the fruit-bowl-ification of it all. It‚Äôs about as convincing to work for you as the mention of the kicker table in your job listings. I like my coworkers, and I call them often just to talk, or create Teams meetings just to catch up in private matters and not a work meeting. But asking people back into the office to be more social and combat supposed isolation is dumb! The people who need this are not prevented to come in and do just that anyway. But you‚Äôre asking people to waste fuel and time commuting there, tired, sitting their ass off at a table for that? You‚Äôre asking me as an immunocompromised and chronically ill person in pain and dealing with fatigue to show up and do the same stuff I do at home so others can play family at work?</p>
<p>Babes, I am less social with the office than without. When I come home from the office I lie in bed and that‚Äôs it. I am drained. I haven‚Äôt had the time or energy to see the people I truly care about much. This isolates me more. When I get sick from it (like last year at the Christmas function when someone brought Covid!) I am isolated at home. And for what, so people who insist on office time have someone they see in the hallway on the way to the toilet?</p>
<p>They haven‚Äôt taken it away yet, but the threat seems to always be there and often serves as a way to enact pressure or as a bargaining chip. Behave or we can‚Äôt do that anymore, it‚Äôs a privilege not a right, we do this out of goodwill, some people abuse this and so on.</p>
<p>Home office is the only way for many people to have a decent work output because family, household, caretaking, further education, illness and free time activities are better taken care of this way and people can work focused in silence without noise and interruption.  It lessens stress and burnout and allows people to see more of their loved ones - much more meaningful socially than office interactions.</p>
<p>If I hadn‚Äôt had home office possibilities, I would‚Äôve been gone from work for 8 months minimum due to my illness. But this way, I was still able to do the daily work, launch new features needed in our database, sign stuff as a representative and more. Home office is so important for disabled and chronically ill people to get and retain employment, and team members and coworkers deserve it as well to not have to take over someone else‚Äôs work for so long just because of a refusal to let people work from home. You cannot dangle what people need to effectively work in front of them like a carrot and subtly threaten to take it away. It‚Äôs ableist. You wouldn‚Äôt dare to do that with elevators or other accessibility features at the office, so don‚Äôt do it with that either.</p>
<p>And that‚Äôs also what I sent the staff council and our disability representative at work. So far, I received positive feedback for that.</p>
<p>The past few years but especially this year, I saw my coworkers bust their ass to make it all work. More work, more responsibilities, no extra hires, no pay increase. I busted my ass to make it all work despite my illness. Twice in a row in my three years in that spot, I got a performance bonus for my great work. Well, they told us all this year there won‚Äôt be any for anyone despite it all.</p>
<p>If they take away or severely limit home office too, I‚Äôm throwing, man. Then do your shit alone and drive all the young capable people away, in the place where like 50% of the work force will retire in the next 5 years. Fuck around and find out.</p>
<blockquote>
<p>Published 22 Nov, 2024, edited 12&nbsp;minutes ago</p>
</blockquote>


    

    
        

        
            


        
    


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Highest-resolution images ever captured of the sun‚Äôs entire surface (191 pts)]]></title>
            <link>https://www.smithsonianmag.com/smart-news/check-out-the-highest-resolution-images-ever-captured-of-the-suns-entire-surface-180985518/</link>
            <guid>42220155</guid>
            <pubDate>Sat, 23 Nov 2024 10:01:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.smithsonianmag.com/smart-news/check-out-the-highest-resolution-images-ever-captured-of-the-suns-entire-surface-180985518/">https://www.smithsonianmag.com/smart-news/check-out-the-highest-resolution-images-ever-captured-of-the-suns-entire-surface-180985518/</a>, See on <a href="https://news.ycombinator.com/item?id=42220155">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-article-body="">
        
          <figure>
            <img src="https://th-thumbnailer.cdn-si-edu.com/cXnfZzc4GdLBBNB7-dpxpqj4Nc8=/1000x750/filters:no_upscale():focal(1394x903:1395x904)/https://tf-cmsv2-smithsonianmag-media.s3.amazonaws.com/filer_public/01/52/0152b828-56b8-4e46-8263-e48660486d42/screenshot_2024-11-21_at_44419_pm.png" alt="a portion of the sun in high resolution depicting a large sunspot" itemprop="image">
            <figcaption>
              
                This view is just part of a new, high-resolution image of the sun's full surface captured by&nbsp;the Polarimetric and Helioseismic Imager (PHI) on the Solar Orbiter spacecraft.
              <span>Screenshot. ESA &amp; NASA / Solar Orbiter / PHI &amp; EUI teams; Data processing: J. Hirzberger (MPS) &amp; E. Kraaikamp (ROB)</span>
            </figcaption>
          </figure>
        

        

        <p>The European Space Agency (ESA) has just <a href="https://www.esa.int/Science_Exploration/Space_Science/Solar_Orbiter/New_full_Sun_views_show_sunspots_fields_and_restless_plasma">released</a> four new, stellar images of the sun, including the highest resolution views to date of its full, visible surface, called the photosphere.</p>

<p>Each image is actually a mosaic of 25 high-resolution shots snapped by the Solar Orbiter mission on March 22, 2023. The spacecraft captured all 100 total images when it was less than 46 million miles from the sun. The process took more than four hours, since the spacecraft had to change position for each individual photograph. In the final mosaics, the sun‚Äôs diameter is almost 8,000 pixels across.</p>

<p>‚ÄúThe closer we look, the more we see,‚Äù <a href="https://cires.colorado.edu/people/mark-miesch">Mark Miesch</a>, an astrophysicist at the National Oceanic and Atmospheric Administration‚Äôs Space Weather Prediction Center who wasn‚Äôt involved with obtaining the images, tells <a href="https://www.cnn.com/2024/11/20/science/solar-orbiter-sun-surface-images/index.html">CNN</a>‚Äôs Ashley Strickland. ‚ÄúTo understand the elaborate interplay between large and small; between twisted magnetic fields and churning flows, we need to behold the sun in all its splendor. These high-resolution images from Solar Orbiter bring us closer to that aspiration than ever before.‚Äù</p><center><blockquote><p lang="en" dir="ltr"><a href="https://twitter.com/ESASolarOrbiter?ref_src=twsrc%5Etfw">@ESASolarOrbiter</a>‚Äôs daring trajectory close to the Sun is paying off, giving us the highest-resolution full views of the Sun‚Äôs surface to date.<br>Full story  <a href="https://t.co/Cy0H6JZmlp">https://t.co/Cy0H6JZmlp</a> <a href="https://t.co/0IyEDeLpX0">pic.twitter.com/0IyEDeLpX0</a></p>‚Äî ESA Science (@esascience) <a href="https://twitter.com/esascience/status/1859175711212228884?ref_src=twsrc%5Etfw">November 20, 2024</a></blockquote> </center>
<p>The <a href="https://www.esa.int/Science_Exploration/Space_Science/Solar_Orbiter">Solar Orbiter</a> is a joint mission between the ESA and NASA, operated by the ESA, that launched in February 2020 and released its first images the <a href="https://www.smithsonianmag.com/smart-news/see-our-suns-surface-unprecedented-detail-180975380/">following July</a>. Since its launch, the program has hit many milestones, capturing both the closest-ever images of the sun and the first close-up images of its polar regions.</p>

<p>While the spacecraft totes six <a href="https://www.esa.int/ESA_Multimedia/Images/2020/01/Solar_Orbiter_s_instruments">imaging instruments</a>, the newly released images were captured with just two: the Polarimetric and Helioseismic Imager (PHI) and the Extreme Ultraviolet Imager (EUI). The PHI is responsible for three of the new solar views‚Äîan image in visible light, a map of the direction of the magnetic field and a velocity map featuring the speed and direction of parts of the sun‚Äôs surface. The EUI, meanwhile, produced an image of our star‚Äôs outer atmosphere, called the corona, in ultraviolet light.</p>

<p>‚ÄúThese new high-resolution maps from Solar Orbiter‚Äôs PHI instrument show the beauty of the sun‚Äôs surface magnetic field and flows in great detail. At the same time, they are crucial for inferring the magnetic field in the sun‚Äôs hot corona, which our EUI instrument is imaging,‚Äù <a href="https://www.cosmos.esa.int/web/personal-profiles/daniel-mueller">Daniel M√ºller</a>, a Solar Orbiter project scientist with the ESA, says in a <a href="https://www.esa.int/Science_Exploration/Space_Science/Solar_Orbiter/New_full_Sun_views_show_sunspots_fields_and_restless_plasma">statement</a>. ‚ÄúThe sun‚Äôs magnetic field is key to understanding the dynamic nature of our home star from the smallest to the largest scales.‚Äù</p>

<p>The four images offer a high-definition tour of the sun. First, the visible light image below depicts the star‚Äôs constantly moving surface of hot plasma‚Äîor charged gas, simply put. This layer has a temperature between 8,132 and 10,832 degrees Fahrenheit and emits most of the sun‚Äôs radiation.</p>

<figure>
  
    <img src="https://th-thumbnailer.cdn-si-edu.com/4DJEHmvvtmxtk7kpl1NPNDcCj6Q=/fit-in/1072x0/filters:focal(990x867:991x868)/https://tf-cmsv2-smithsonianmag-media.s3.amazonaws.com/filer_public/7a/44/7a44b622-f248-443b-b4d0-39eab32f5edc/download.png" alt="The Sun in visible light" loading="lazy">
  

  <figcaption>
    
      The sun in visible light
    
    
      <span>ESA &amp; NASA / Solar Orbiter / PHI Team <a href="https://creativecommons.org/licenses/by-sa/3.0/igo/" target="_blank">CC BY-SA 3.0 IGO</a></span>
    
  </figcaption>
</figure>
<p>Beneath the surface is the sun‚Äôs convection zone, in which dense plasma swirls around, rather like the magma in Earth‚Äôs mantle. This phenomenon makes the sun‚Äôs surface look grainy, and scientists say the star‚Äôs magnetic field is <a href="https://www.smithsonianmag.com/smart-news/researchers-trace-the-origin-of-the-suns-magnetic-field-shedding-light-on-space-weather-and-solar-cycles-180984410/">driven by the churning plasma</a>.</p>

<p>Dark shapes called sunspots are seen in both PHI‚Äôs visible light image and its magnetic map, shown below. The sun‚Äôs <a href="https://www.weather.gov/fsd/sunspots#:~:text=Sunspots%3A%20One%20interesting%20aspect%20of,anywhere%20else%20on%20the%20Sun.">magnetic field is stronger at the sunspots</a>, with red in the image indicating where it moves outward and blue indicating where it moves inward.</p>

<p><a href="https://science.nasa.gov/sun/sunspots/">Sunspots</a> are concentrated tangles of magnetic fields, where plasma is diverted from the sun‚Äôs heat-mixing convective flow, making it cooler than surrounding areas. As a result, the plasma in sunspots gives off less light and appears dark in the visible light image.</p>

<figure>
  
    <img src="https://th-thumbnailer.cdn-si-edu.com/yJwneZrquyDWYJKUCNh7sQyvFwk=/fit-in/1072x0/https://tf-cmsv2-smithsonianmag-media.s3.amazonaws.com/filer_public/87/25/8725fef5-c008-4fda-babf-4657ef0f3d2a/download_1.png" alt="line-of-sight direction of the magnetic field on the Sun's disc" loading="lazy">
  

  <figcaption>
    
      This map, showing the line-of-sight direction of the sun's magnetic field, is also called a magnetogram.
    
    
      <span>ESA &amp; NASA / Solar Orbiter / PHI Team <a href="https://creativecommons.org/licenses/by-sa/3.0/igo/" target="_blank">CC BY-SA 3.0 IGO</a></span>
    
  </figcaption>
</figure>
<p>In the third image‚Äîthe velocity map, shown below‚Äîthe PHI captures the movement of parts of the sun‚Äôs surface, with blue indicating movement toward the Solar Orbiter and red indicating movement away from it.</p>

<p>‚ÄúThis map shows that while the plasma on the surface of the sun generally rotates with the sun‚Äôs overall spin around its axis, it is pushed outward around the sunspots,‚Äù according to the statement.</p>

<figure>
  
    <img src="https://th-thumbnailer.cdn-si-edu.com/YcXVZMWiKc2_fwNOjg9_SrqtFEE=/fit-in/1072x0/filters:focal(4728x4728:4729x4729)/https://tf-cmsv2-smithsonianmag-media.s3.amazonaws.com/filer_public/17/47/17476853-06b8-4554-b304-3fc7bd673b6e/download_2.png" alt="The velocity map" loading="lazy">
  

  <figcaption>
    
      The velocity map, also called a tachogram
    
    
      <span>ESA &amp; NASA / Solar Orbiter / PHI Team <a href="https://creativecommons.org/licenses/by-sa/3.0/igo/" target="_blank">CC BY-SA 3.0 IGO</a></span>
    
  </figcaption>
</figure>
<p>Lastly, the EUI‚Äôs ultraviolet light image captures the sun‚Äôs <a href="https://www.exploratorium.edu/eclipse/what-to-see-during-eclipse#:~:text=This%20stage%20of%20a%20total,outshone%20by%20the%20bright%20photosphere.">corona</a>‚Äîits wispy outer atmosphere that can only be seen from Earth during a total <a href="https://www.smithsonianmag.com/tag/solar-eclipse/">solar eclipse</a>. The image depicts interesting activity once again around the sunspots: plasma shooting outward along magnetic field lines, which occasionally connect sunspots close to each other.</p>

<figure>
  
    <img src="https://th-thumbnailer.cdn-si-edu.com/TcXNipIMTihD7P3K2bZLMSdPhp4=/fit-in/1072x0/filters:focal(4730x4730:4731x4731)/https://tf-cmsv2-smithsonianmag-media.s3.amazonaws.com/filer_public/a7/83/a7832215-21bb-4e2b-b14d-22bf889cda6b/download_3.png" alt="high-resolution image shows the Sun in ultraviolet light" loading="lazy">
  

  <figcaption>
    
      This high-resolution image shows the sun in ultraviolet light, revealing its outer atmosphere, the&nbsp;corona.
    
    
      <span>ESA &amp; NASA / Solar Orbiter / EUI Team <a href="https://creativecommons.org/licenses/by-sa/3.0/igo/" target="_blank">CC BY-SA 3.0 IGO</a></span>
    
  </figcaption>
</figure>
<p>The image processing that produced the PHI‚Äôs images was ‚Äúnew and difficult,‚Äù per the statement, but moving forward, ESA experts expect to produce similar images with greater speed, potentially releasing two a year.</p>

<p>‚ÄúThis mission is such a treasure and important to science,‚Äù <a href="https://esahubble.org/images/hasinger-cc/">G√ºnther Hasinger</a>, director of science for the ESA, told <em><a href="https://www.space.com/solar-orbiter-atlas-v-rocket-launch-success.html">Space.com</a></em>‚Äôs Amy Thompson at the time of its launch.</p>

        

        

        
          
  <div>
      <p>Get the latest stories in your inbox every weekday.</p>
      
    </div>


        

        

        
          


  
    
      
    
  

  


        

        
        
        
        

        
          
            <section>
              <nav>Filed Under:
                
                  
                    <a href="https://www.smithsonianmag.com/tag/nasa/">NASA</a>, 
                  
                
                  
                    <a href="https://www.smithsonianmag.com/tag/outer-space/">Outer Space</a>, 
                  
                
                  
                    <a href="https://www.smithsonianmag.com/tag/photography/">Photography</a>, 
                  
                
                  
                    <a href="https://www.smithsonianmag.com/tag/solar-system/">Solar System</a>, 
                  
                
                  
                    <a href="https://www.smithsonianmag.com/tag/sun/">Sun</a>
                  
                
              </nav>
            </section>
          
        

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Americans see their savings vanish in Synapse fintech crisis (162 pts)]]></title>
            <link>https://www.cnbc.com/2024/11/22/synapse-bankruptcy-thousands-of-americans-see-their-savings-vanish.html</link>
            <guid>42219407</guid>
            <pubDate>Sat, 23 Nov 2024 05:44:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2024/11/22/synapse-bankruptcy-thousands-of-americans-see-their-savings-vanish.html">https://www.cnbc.com/2024/11/22/synapse-bankruptcy-thousands-of-americans-see-their-savings-vanish.html</a>, See on <a href="https://news.ycombinator.com/item?id=42219407">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-107422893" data-test="InlineImage"><p>Oscar Wong | Moment | Getty Images</p></div><div><p>For 15 years, former Texas schoolteacher Kayla Morris put every dollar she could save into a home for her growing family.</p><p>When she and her husband sold the house last year, they stowed away the proceeds, $282,153.87, in what they thought of as a safe place ‚Äî an account at the savings startup <a href="https://www.withyotta.com/" target="_blank">Yotta</a> held at a real bank.</p><p>Morris, like thousands of other customers, was snared in the collapse of a behind-the-scenes fintech firm called Synapse and has been locked out of her account for six months as of November. She held out hope that her money was still secure. Then she learned how much Evolve Bank &amp; Trust, the lender where her funds were <a href="https://www.getevolved.com/open-letter-to-open-banking-customers/" target="_blank">supposed to be held</a>, was prepared to return to her.</p><p>"We were informed last Monday that Evolve was only going to pay us $500 out of that $280,000," Morris said during a court hearing last week, her voice wavering. "It's just devastating."</p><p>The crisis <a href="https://www.cnbc.com/2024/05/22/synapse-bankruptcy-customer-funds.html">started</a> in May when a dispute between Synapse and Evolve Bank over customer balances boiled over and the fintech middleman turned off access to a key system used to process transactions. Synapse helped fintech startups like Yotta and Juno, which are not banks, offer checking accounts and debit cards by hooking them up with small lenders like Evolve.</p><p>In the immediate aftermath of Synapse's bankruptcy, which happened after an exodus of its fintech clients, a court-appointed trustee found that up to $96 million of customer funds was <a href="https://www.cnbc.com/2024/07/02/synapse-fintech-fdic-false-promise.html">missing</a>.</p><p>The mystery of where those funds <a href="https://reconciliationbyevolve.com/FAQ?portalid=0" target="_blank">are</a> hasn't been solved, despite six months of court-mediated efforts between the four banks involved. That's mostly because the estate of <a href="https://a16z.com/" target="_blank">Andreessen Horowitz</a>-backed Synapse doesn't have the money to hire an outside firm to perform a full reconciliation of its ledgers, according to Jelena McWilliams, the bankruptcy trustee.</p><p>But what is now clear is that regular Americans like Morris are bearing the brunt of that shortfall and will receive little or nothing from savings accounts<strong>&nbsp;</strong>that they believed were backed by the&nbsp;<a href="https://www.fdic.gov/resources/deposit-insurance/brochures/insured-deposits#:~:text=Since%20the%20FDIC%20began%20operations,penny%20of%20FDIC%2Dinsured%20deposits.&amp;amp;text=FDIC%20insurance%20covers%20depositor%20accounts,up%20to%20the%20insurance%20limit." target="_blank">full faith and credit of the U.S. government.</a></p><p>The losses demonstrate the risks of a system where customers didn't have direct relationships with banks, instead relying on startups to keep track of their funds, who offloaded that responsibility onto middlemen like Synapse.</p></div><div id="ArticleBody-InlineImage-108065781" data-test="InlineImage"><p>Zach Jacobs, 37, of Tampa, Florida helped form a group called Fight For Our Funds after losing more than $94,000 that he had in a fintech savings account called Yotta.</p><p>Courtesy: Zach Jacobs</p></div><h2><a id="headline0"></a>'Reverse bank robbery'</h2><div><p>There are thousands of others like Morris. While there's not yet a full tally of those left shortchanged, at Yotta alone, 13,725 customers say they are being offered a combined $11.8 million despite putting in $64.9 million in deposits, according to figures shared by Yotta co-founder and CEO <a href="https://www.cnbc.com/2024/06/01/synapse-bankruptcy-yotta-accounts-locked.html">Adam Moelis</a>.</p><p>CNBC spoke to a dozen customers caught in this predicament, people who are owed sums ranging from $7,000 to well over $200,000.</p><p>From FedEx drivers to small business owners, teachers to dentists, they described the loss of years of savings after turning to fintechs like Yotta for the higher interest rates on offer, for innovative features or because they were turned away from traditional banks.</p><p>One Yotta customer, Zach Jacobs, logged onto Evolve's website on Nov. 4 to find he was getting back just $128.68 of the $94,468.92 he had deposited ‚Äî and he decided to act.</p></div><div id="ArticleBody-InlineImage-108066371" data-test="InlineImage"><p>Zach Jacobs decided to act after logging onto Evolve‚Äôs website on Nov. 4 to find he was getting just $128.68 of his $94,468.92 in deposits.</p><p>Courtesy: Zach Jacobs</p></div><div><p>The 37-year-old Tampa, Florida-based business owner began organizing with other victims online, creating a board of volunteers for a group called <a href="https://www.fightforourfunds.org/" target="_blank">Fight For Our Funds</a>. It's his hope that they gain attention from press and politicians.</p><p>So far, 3,454 people have signed on, saying they've lost a combined $30.4 million.</p><p>"When you tell people about this, it's like, 'There's no way this can happen,'" Jacobs said. "A bank just robbed us. This is the first reverse bank robbery in the history of America."</p><p>Andrew Meloan, a chemical engineer from Chicago, said he had hoped to see the return of $200,000 he'd deposited with Yotta. Early this month, he received an unexpected PayPal remittance from Evolve for $5.</p><p>"When I signed up, they gave me an Evolve routing and account number," Meloan said. "Now they're saying they only have $5 of my money, and the rest is someplace else. I feel like I've been conned."</p></div><blockquote data-test="Pullquote"><div><p>A bank just robbed us. This is the first reverse bank robbery in the history of America.‚Äù</p><div><p>Zach Jacobs</p><p>Yotta customer</p></div></div></blockquote><h2><a id="headline1"></a>Cracks in the system</h2><div><p>Unlike meme stocks or crypto bets, in which the user naturally assumes some risk, most customers viewed funds held in Federal Deposit Insurance Corp.-backed accounts as the safest place to keep their money. People relied on accounts powered by Synapse for everyday expenses like buying groceries and paying rent, or for saving for major life events like home purchases or surgeries.</p><p>Several people CNBC interviewed said signing up seemed like a good bet since Yotta and other fintechs advertised that deposits were FDIC-insured through Evolve.</p><p>"We were assured that this was just a savings account," Morris said during last week's hearing. "We are not risk-takers, we're not gamblers."</p><p>A Synapse contract that customers received after signing up for checking accounts stated that user money was insured by the FDIC for up to $250,000, according to a version seen by CNBC.</p><p>"According to the FDIC, no depositor has ever lost a penny of FDIC-insured funds," the 26 page contract states. </p></div><h2><a id="headline2"></a>'We are responsible'</h2><div><p>Abandoned by U.S. regulators who have so far declined to act, they are left with few clear options to recoup their money.</p><p>In June, the FDIC made it <a href="https://www.fdic.gov/banker-resource-center/third-party-relationships" target="_blank">clear</a> that its insurance fund doesn't cover the failure of nonbanks like Synapse, and that in the event of such a firm's failure, recovering funds through the courts wasn't guaranteed.</p><p>The next month, the Federal Reserve <a href="https://www.cravath.com/a/web/77ehdW35iYvqvCtoH43ArB/9ewd1p/9890-304-07_03_2024-pacer304-main-document-012731-00001-central-district-of-california.pdf" target="_blank">said</a> that as Evolve's primary federal regulator it would monitor the bank's progress "in returning all customer funds" to users.</p><p>"We are responsible for working to ensure that the bank operates in a safe and sound manner and complies with applicable laws, including laws protecting consumers," Fed general counsel Mark E. Van Der Weide said in a <a href="https://www.cravath.com/a/web/77ehdW35iYvqvCtoH43ArB/9ewd1p/9890-304-07_03_2024-pacer304-main-document-012731-00001-central-district-of-california.pdf" target="_blank">letter</a>.</p><p>In September, the FDIC <a href="https://www.cnbc.com/2024/09/17/fdic-banks-fintech-customer-data-synapse.html">proposed</a> a new rule that would force banks to keep detailed records for customers of fintech apps, improving the chances that they qualify for coverage in a future calamity and cutting the risk that funds would go missing.</p><p>McWilliams, herself a former FDIC chair during the first Trump presidency, told the California judge handling the Synapse bankruptcy case last week she was "disheartened" that every financial regulator has decided not to help.</p><p>The FDIC and Fed declined to comment for this story, and McWilliams didn't respond to emails.</p></div><div id="ArticleBody-InlineImage-106939343" data-test="InlineImage"><p>Jelena McWilliams, chairman of the Federal Deposit Insurance Corporation, testifies during a House Financial Services Committee hearing in Rayburn Building titled "Oversight of Prudential Regulators: Ensuring the Safety, Soundness and Accountability of Megabanks and Other Depository Institutions," on Thursday, May 16, 2019.</p><p>Tom Williams | CQ-Roll Call, Inc. | Getty Images</p></div><h2><a id="headline3"></a>Winners and losers</h2><div><p>Things hadn't always seemed so dire. Early in the proceedings, McWilliams suggested to Judge <a href="https://www.cacb.uscourts.gov/judges/honorable-martin-r-barash" target="_blank">Martin Barash</a> that customers be given a partial payment, essentially spreading the pain among everyone.</p><p>But that would've required more coordination between Evolve and the other lenders that held customer funds than what ultimately happened.</p><p>As the hearings dragged on, the three other institutions, AMG National Trust, Lineage Bank and American Bank, began disbursing the funds they had, while Evolve took months to perform what it initially said would be a comprehensive reconciliation.</p><p>Around the time Evolve <a href="https://reconciliationbyevolve.com/FAQ?portalid=0" target="_blank">completed</a> its efforts in October, it said it could only figure out the user funds it held, not the location of the missing funds. That's at least partly because of "very large bulk transfers" of funds without identification of who owned the money, a lawyer for Evolve testified last week.</p><p>As a result, the bankruptcy process has minted relative winners and losers.</p><p>Some end users recently received all their funds back, while others, like Indiana FedEx driver <a href="https://www.cnbc.com/2024/07/02/synapse-fintech-fdic-false-promise.html">Natasha Craft</a>, received none, she told CNBC.</p></div><div id="ArticleBody-InlineImage-108000494" data-test="InlineImage"><p>Natasha Craft, a 25-year-old FedEx driver from Mishawaka, Indiana. She has been locked out of her Yotta banking account since May 11.</p><p>Courtesy: Natasha Craft</p></div><div><p>As of Nov. 12, the four banks released $193 million to customers, or more than 85% of what they held earlier in the year.</p><p>The Nov. 13 hearing has provided the only public venue for victims to register their distress; dozens of victims queued up in the hopes they could testify about receiving a tiny fraction of what they're owed. The event went longer than three hours.</p><p>"You can't imagine the panic when it said I was getting 81 cents," said Andreatte Caliguire, who said she is owed $22,000. "I have no money, I have no path forward, I have nothing."</p></div><h2><a id="headline4"></a>'Nothing optimistic'</h2><div><p>Evolve says that "the vast majority" of funds held for Yotta and other customers were moved to other banks in October and November of 2023 on directions from Synapse, according to an Evolve spokesman.&nbsp;</p><p>"Where those end user funds went after that is an important question, but unfortunately not one Evolve can answer with the data it currently has," the spokesman said.</p><p>Yotta says that Evolve has given fintech firms and the trustee no information about how it determined payouts, "despite acknowledging in court that a shortfall existed at Evolve prior to October 2023," according to a spokesman for the startup, who noted that several executives have recently left the bank. "We hope regulators take notice and act."</p><p>In <a href="https://www.cravath.com/a/web/hGJXkWmwK6jd4jVFFM2zHr/9Fa4fn/9890-453-11_12_2024-pacer453-main-document-012731-00001-central-district-of-california.pdf" target="_blank">statements</a> released ahead of this month's hearing, Evolve said that other banks refused to participate in its efforts to create a master ledger, while AMG and Lineage said that Evolve's implication that they had the missing funds was "irresponsible and disingenuous."</p><p>As the banks and other parties hurl accusations at each other and lawsuits pile up, including pending class-action efforts, the window for cooperation is rapidly closing, Barash said last week.</p><p>"As time goes by, my impression is that unless the banks that are involved can sort this out voluntarily, it may not get sorted out," Barash said. "There's nothing optimistic about what I'm telling you."</p></div><div id="RegularArticle-RelatedContent-1"><h2>Don‚Äôt miss these insights from CNBC PRO</h2><div><ul><li><a href="https://www.cnbc.com/2024/11/14/warren-buffetts-berkshire-hathaway-takes-a-stake-in-dominos-pizza.html">Warren Buffett's Berkshire Hathaway takes a stake in Domino's Pizza</a></li><li><a href="https://www.cnbc.com/2024/11/17/wall-street-gears-up-for-ma-boom-these-names-could-be-attractive-targets.html">Wall Street is gearing up for an M&amp;A boom under Trump. These companies could be targets</a></li><li><a href="https://www.cnbc.com/2024/11/13/inflation-report-shows-market-could-have-a-recipe-for-disaster-heading-into-new-year-says-economist.html">Inflation report shows market could have a 'recipe for disaster' heading into new year, says economist</a></li><li><a href="https://www.cnbc.com/2024/11/18/morningstar-strategist-picks-2-stocks-from-a-sector-he-is-betting-on.html">Morningstar names cheap stocks in a sector that ‚Äòdeserves a place in everybody‚Äôs portfolio‚Äô</a></li><li><a href="https://www.cnbc.com/2024/11/18/these-2-active-etfs-have-outperformed-the-sp-500-this-year-last-year-and-over-5-years.html">These 2 active ETFs have outperformed the S&amp;P 500 this year, last year and over 5 years</a><br></li></ul></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Quake 3 Source Code Review: Network Model (2012) (187 pts)]]></title>
            <link>https://fabiensanglard.net/quake3/network.php</link>
            <guid>42218532</guid>
            <pubDate>Sat, 23 Nov 2024 00:55:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fabiensanglard.net/quake3/network.php">https://fabiensanglard.net/quake3/network.php</a>, See on <a href="https://news.ycombinator.com/item?id=42218532">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="content" role="main">



		


<p>
       June 30, 2012</p>
   <a href="https://fabiensanglard.net/quake3/qvm.php">
   </a><div id="paperbox"><p><a href="https://fabiensanglard.net/quake3/qvm.php">
	   	
          </a><a href="https://fabiensanglard.net/quake3/index.php">
          <img src="https://fabiensanglard.net/quake3/quake3_icon.jpg">   
          </a> 
         

The network model of Quake3 is with no doubt the most elegant part of the engine. At the lower level Quake III still abstract communications
with the <a href="https://fabiensanglard.net/quakeSource/quakeSourceNetWork.php">NetChannel module that first appeared in Quake World</a>.
The most important thing to understand is:</p><p>
In a fast paced environment any information that is not received on first transmission is not worth sending again because it will be too old anyway.</p><p>

As a result the engine relies essentially on UDP/IP: There is no trace of TCP/IP anywhere since the "Reliable transmission" 
aspect introduced intolerable latency. The network stack has been augmented with two mutually exclusive layers:
</p></div><ul>
    <li>Encryption using preshared key.</li>
    <li>Compression with pre-computed huffman key.</li>
</ul>
<div>

<p><img src="https://fabiensanglard.net/lazy_load/grey.gif" data-original="/fd_proxy/quake3/q3_netstack.png"></p><p>

But where the design really shine is on the server side where an elegant system minimize the size of each UDP datagram while 
compensating for the unreliablity of UDP:
An history of snapshots generate deltas packets via memory introspection.

</p></div>



<h3>Architecture</h3>
<div id="paperbox"><p>
The Client side of the network model is fairly simple: Client sends commands to the Server each frame and receive update for the gamestate. The Server side is as bit more complex since it has to propagate the Master gamestate to each Client while accounting for lost UDP packets. This mechanism features three key elements:<br>
<img src="https://fabiensanglard.net/lazy_load/grey.gif" data-original="/fd_proxy/quake3/q3_network_archi.png"></p></div><ul>
  <li>A <b>Master Gamestate</b> that is the universal true state of things. Clients send theirs commands on the Netchannel. They are transformed in event_t which will modifiy the state of the game when they arrive on the Server.</li>
  <li>For each Client the server keeps the <b>32 last gamestate</b> sent over the network in a cycling array: They are called snapshots. The array cycle with the famous binary mask trick I mentioned in Quake World Network (<a href="http://fabiensanglard.net/quakeSource/quakeSourceNetWork.php">Some elegant things</a>).</li>
  <li>The server also features <b>a "dummy" gamestate</b> with every single field set to zero. This is used to delta snapshots when there is no "previous state" available.</li>
 </ul>
 <div><p>
When the server decides to send an update to a client it uses each three elements in order to generate a message that is then carried over the NetChannel.</p><u><b>Trivia :</b></u><p> To keep so many gamestate for each players consumes a lot of memory: 8 MB for 4 players according to my measurements.  
</p></div>


<h3>Snapshot systems</h3>
<p id="paperbox">
In order to understand the snapshop system, here is an example with the following conditions:
</p><ul>
    <li>The server is sending update to a Client1.</li>
    <li>The server is attempting to propagate the state of Client2 which has four 4  fields (3 ints position[X], position[Y], position[Z] and one int health).</li>
    <li>Communication are done over UDP/IP: Those messages gets lost quite often on the internet.</li>
</ul>
<div>
<u>Server Frame 1:</u><p>

The Server has received a few updates from every client. They have impacted the Master gamestate (in green). It is now time to propagate the state to Client1:
<img src="https://fabiensanglard.net/lazy_load/grey.gif" data-original="/fd_proxy/quake3/q3_network_t1.png"></p><p>

In order to generate a message the network module will ALWAYS do the following :
</p></div><ol>
   <li>Copy the Master gamestate in the next Client history slot.</li>
   <li>Compare it with an other snapshot.</li>
</ol>
<p>
This is what we can see in the next drawing:
</p><ol>
   <li> Master gamestate is copied at index 0 in Client1 history: It is now called"Snapshot1".</li>
   <li> Since this is the first udpate, there are no valid snapshot in Client1 history so the engine is going to use the "Dummy snapshot" where all fields are always ZEROed. This results in a FULL update since every single field is sent to the NetChannel.</li>
 </ol>
 <div>
<p><img src="https://fabiensanglard.net/lazy_load/grey.gif" data-original="/fd_proxy/quake3/q3_network_t2.png"><br>
The key point to understand here is that if no valid snapshots are available in the client history the engine will pick "dummy snapshot" to
 generate a delta message. This will result in a full udpate sent to the Client using 132 bits (each field is <a href="https://github.com/id-Software/Quake-III-Arena/blob/master/code/qcommon/msg.c#L1200">
preceeded by a bit marker</a>): <code>[1 A_on32bits 1 B_on32bits 1 B_on32bits 1 C_on32bits]</code>.
</p><u>Server Frame 2:</u><p>

Now let's move forward in time: this is the Server second frame. As we can see each client have sent commands and they have impacted the Master gamestate: Client2 has moved on the Y axis so pos[1] is now equal to E (in blue). Client1 has also sent commands but more important it has also acknowledged receiving the previous udpate so Snapshot1 has been marked as "ACK":
<img src="https://fabiensanglard.net/lazy_load/grey.gif" data-original="/fd_proxy/quake3/q3_network_t3.png"><br>

The process is the same:</p></div><ol>
   <li>Copy the Master gamestate in the next Client history slot: (index 1): This is Snapshot2</li>
   <li>This time we have a valid snapshot in the client history (snapshot1). Compare those two snapshots</li>
</ol>
<div><p>
As result only a partial update (   pos[1] = E ) is sent over the network. This is the beauty of the design: The process is always the same.
<img src="https://fabiensanglard.net/lazy_load/grey.gif" data-original="/fd_proxy/quake3/q3_network_t4.png"></p><u>Note :</u><p> Since each field is <a href="https://github.com/id-Software/Quake-III-Arena/blob/master/code/qcommon/msg.c#L1200">
preceeded by a bit marker</a> (1=changed, 0=not changed) the partial update above would uses 36 bits: <code>[0 1 32bitsNewValue 0 0]</code>. 
</p><u>Server Frame 3:</u><p>

Let's move forward one more step in order to see how the system deals with lost packets. This is now Frame 3. Clients have kept on sending commands to the server.
Client2 has lost life and health is now equal to H. But Client1 has not acknowledged the last update. Maybe the Server's UDP got lost, maybe the ACK from the Client
got lost but bottom line is that it cannot be used.

<img src="https://fabiensanglard.net/lazy_load/grey.gif" data-original="/fd_proxy/quake3/q3_network_t5.png"></p><p>


Regardless the process remains the same:
</p></div><ol>
   <li>Copy the Master gamestate in the next Client history slot: (index 2): This is Snapshot3</li>
   <li>Compare with the last valid acknowledged snapshot (snapshot1).</li>
</ol>
<div>
<p><img src="https://fabiensanglard.net/lazy_load/grey.gif" data-original="/fd_proxy/quake3/q3_network_t6.png"></p><p>

As a result the message sent it partial and contains a combination of old changes and new changes: (pos[1]=E and health=H). Note that snapshot1 could have been too old to be used. In this case the engine would have used the "dummy snapshot" again, resulting in a full update.</p><p>

The beauty and elegance of the system resides in its simplicity. The same algorithm automatically:
</p></div><ul>
   <li>Generate partial or full update.</li>
   <li>Resend OLD information that were not received and NEW information in a single message.</li>
</ul>



<h3>Memory introspection with C</h3>
<div id="paperbox"><p>
You may wonder how Quake3 is comparing snapshots with introspection...since C does not have introspection.<br>
The answer is that each field locations for a <code>netField_t</code> is preconstructed via an array and some clever 
preprocessing directives:</p></div><pre>

    typedef struct {
        <span>char</span>    *name;
        <span>int</span>     offset;
        <span>int</span>     bits;
    } netField_t; 

    // using the stringizing operator to save typing...
    #define	NETF(x) #x,(<span>int</span>)&amp;((entityState_t*)0)-&gt;x

    netField_t	entityStateFields[] = 
    {
    { NETF(pos.trTime), <span>32</span> },
    { NETF(pos.trBase[0]), <span>0</span> },
    { NETF(pos.trBase[1]), <span>0</span> },
    ...
    }

</pre>
<div><p>
The full code of this part can be found in <a href="https://github.com/id-Software/Quake-III-Arena/blob/master/code/qcommon/msg.c">snapshot.c</a>'s 
<code>MSG_WriteDeltaEntity</code>. Quake3 does not even know what it is comparing: It just blindly follow <code>entityStateFields</code>'s index,offset and size...and
sends the difference over the network.

</p></div>





<h3>Pre-fragmentation</h3>
<p id="paperbox">
Digging into the code we see that the NetChannel module slices messages in chunks of 1400 bytes (<a href="https://github.com/id-Software/Quake-III-Arena/blob/master/code/qcommon/net_chan.c">
<code>Netchan_Transmit</code></a>), even though the maximum size of an UDP datagram is 65507 bytes. Doing so the engine avoid having its packets
fragmented by routers while traveling over the internet since most network MTU are 1500 bytes. Avoiding router fragmentation is very important since:<br>
</p><ul>
   <li>Upon entering the network the router must block the packet while it is fragmenting it.</li>
   <li>Upon leaving the network problems are even worse since every part of the datagram have to be waited on and then time-costly re-assembled.</li>
</ul>










<h3>Reliable and Unreliable messages</h3>
<div id="paperbox"><p>
If the snapshot system compensate for UDP datagrams lost over the network,  some messages and commands must be GUARANTEED to be delivered (when
a player quits or when the Server needs the Client to load a new level).</p><p>

	This guarantee is abstracted by the NetChannel: I wrote about it <a href="https://fabiensanglard.net/quakeSource/quakeSourceNetWork.php">a few years ago</a> (wow my drawings have come a long way !!).
</p></div>  






<h3>Recommended readings</h3>








<h3>Next part</h3>
<p id="paperbox">

<a href="https://fabiensanglard.net/quake3/qvm.php">The Virtual Machine system</a>
</p>

			
	<!-- <h2>Comments</h2>
<p> -->


     <!-- <div id="disqus_thread"></div> -->
    <!-- <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'fabiensanglardswebsite'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || 
                document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript> -->
    <!--<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a> -->
<!--     




</p> -->

 
<p>@</p>

		</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MaXX Interactive Desktop -- the little brother of the great SGI Desktop on IRIX (122 pts)]]></title>
            <link>https://docs.maxxinteractive.com/</link>
            <guid>42218184</guid>
            <pubDate>Fri, 22 Nov 2024 23:21:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://docs.maxxinteractive.com/">https://docs.maxxinteractive.com/</a>, See on <a href="https://news.ycombinator.com/item?id=42218184">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content">
        <main>
            <div dir="auto" page-display="34">

    <h2 id="bkmrk-page-title">Welcome to MaXX Interactive Desktop</h2>

    

            <blockquote id="bkmrk-new-version-of-maxx-">
<h3 id="bkmrk-%C2%A0-1"><strong><em>New Release Available Today<br>November&nbsp; 21st&nbsp; 9PM EST</em></strong></h3>
<h5 id="bkmrk-%3E%3E-link-to-release-n"><em><strong><a title="November 21st 2024 - Octane Alpha Release" href="https://docs.maxxinteractive.com/books/whats-new/page/november-21st-2024-octane-v220-alpha">&gt;&gt; Release information &lt;&lt;</a></strong></em></h5>
</blockquote>
<hr id="bkmrk-"><h5 id="bkmrk-yes-the-maxx-interac"><em><strong>MaXX Interactive Desktop is the little brother of the great SGI Desktop on IRIX<br></strong></em></h5>

<p id="bkmrk-maxx-desktop-v2.1.1-"><strong>MaXXdesktop v2.2.0 (alpha) running in Modern Look &amp; Feel with Indigo Magic SGI Scheme (4K @120Hz)</strong></p>

<h3 id="bkmrk-introduction">Introduction</h3>
<p id="bkmrk-the-maxx-interactive">The MaXX Interactive Desktop a.k.a. MaXX<strong>desktop</strong> is the continuation of the 5Dwm project released many years back. So don't be mistaken, there is only one real&nbsp; re-implementation of the IRIX Interactive Desktop found on SGI systems, and&nbsp; it's MaXX<strong>desktop</strong>!</p>
<p id="bkmrk-maxx-desktop-is-a-tr">MaXX<strong>desktop</strong> is a true re-implementation of the "SGI Desktop" with the added benefits of using a modern software stack of highly tuned loosely-coupled components delivering maximum performance and stability while using as little resources as possible. We believe that high performance&nbsp; computing and energy friendly are not mutually exclusive. What if you could run applications in a smarter, greener and sustainable way? MaXX<strong>desktop</strong> aims at improving just that, do more with less.</p>
<p id="bkmrk-while-respecting-the">While respecting the original retro CLASSIC SGI look and feel, which is very important for us to get it right,&nbsp; we created a newer and more modern user experience called the MODERN look that feels like a natural evolution of the original SGI look, as if SGI did it themselves throughout the years perfecting an already pretty awesome recipe. The MODERN look still supports SGI Colour Schemes but introduce Unicode and UTF-8 support, anti-aliased font rendering, more hardware acceleration and a new virtual-desktop manager. The user can switch between looks with one mouse-click, now that's cool.</p>
<h3 id="bkmrk-goals-and-features-l">Goals and Features List</h3>
<p id="bkmrk-so-there-is-no-surpr">We believe in the need of&nbsp; a highly tuned workstation environment where performance, robustness, low resources consumption are at the core of everything.</p>
<p id="bkmrk-here-are-the-goals-w">Here are the goals we want to achieve and features that makes a great modern desktop:</p>
<ul id="bkmrk-it%27s-learn%2C-very-fas"><li>Lean, very fast and robust. Basically MaXX<strong>desktop</strong> gets out of your way.</li>
<li>Smart and efficient multi-cores workload management with CPU and Core partitioning which help reduce process bouncing of&nbsp; CPU cores and computation resources allocation/partitioning translate in better throughput (<a title="MaXX Scope" href="https://docs.maxxinteractive.com/books/software-architecture/page/maxx-scope" target="_blank" rel="noopener">MaXXscope</a>).</li>
<li>Built on solid and time proven foundations.</li>
<li>Desktop Applications are distributed as self contained AppImages.</li>
<li>Provides a robust modern and high performance asynchronous multi-threaded messaging sub-system (with Shared Memory support and Zero copy principle for local communications) for fast and efficient inter-processes communications (<a title="MaXX Links" href="https://docs.maxxinteractive.com/books/software-architecture/page/maxx-links" target="_blank" rel="noopener">MaXXlinks</a>).</li>
<li>Based on a modular micro-services like architecture that allow decentralization of core desktop services as we rapidly moving toward containerization for better security.</li>
<li>Modern Configuration Management sub-system with both a command line interface (CLI) or C/C++/Java API for easy application integration (<a title="MaXX Settings" href="https://docs.maxxinteractive.com/books/software-architecture/page/maxx-settings" target="_blank" rel="noopener">MaXXsettings</a>).</li>
<li>Highly focused on facilitating quick and easy access to your content with fast content previewers right from the file-manager.</li>
<li>Leverage hardware acceleration and optimization for CPU&nbsp; and GPU.</li>
<li>Centralized system monitoring sub-system (<a title="MaXX Monitor" href="https://docs.maxxinteractive.com/books/software-architecture/page/maxx-monitor">MaXXmonitor</a>).</li>
<li>HiDPI supports for X/Motif applications and easy presets control for applications.</li>
<li>Much needed Motif<sup>TM</sup> face-lift and modernization of the ViewKit framework with new modern components that are fully integrated with all MaXX Desktop sub-systems.</li>
<li>Developer friendly software development environment with integration to <strong>CLion</strong>,<strong> Intelli-J</strong> and PyCharm IDEs from Jetbrains which translate into building better and faster applications.</li>
<li>To support multiple CPU architectures (x86, Arm64 and RISC-V)</li>
<li>To run on multiple OS: Linux, FreeBSD and Windows11 WSL2.</li>
<li>To provide a source code compatibility for IRIX visual applications.</li>
</ul><p id="bkmrk-more-info-on-the-ori"><a title="Not just a theme..." href="https://docs.maxxinteractive.com/books/misc/page/not-just-a-theme"><strong>&gt;&gt; More details on what MaXXdesktop is made of</strong></a></p>
<h3 id="bkmrk-our-mission">Our Mission</h3>
<p id="bkmrk-more-for-your-creati"><em>More for your creativity.</em></p>
<p id="bkmrk-our-goal-is-to-bring">Our mission is to bring back this great user experience which focused on performance, stability and productivity while sporting a smooth-clean-minimalism look and feel with low-resources consumption. A <strong>smart</strong> and <strong>green</strong> Desktop that puts the user's application in the forefront.&nbsp;&nbsp;</p>
<p id="bkmrk-we-believe-in-a-high">We believe in a High Performance Desktop Environment that provides the right set of tools to maximize creativity and productivity without sacrificing&nbsp; your system resources to some eye candy nonsense.&nbsp;<em> <strong>Again, less is more... And it keeps you focused.<br></strong></em></p>
<h3 id="bkmrk-from-the-ground-up">From the Ground Up</h3>
<p id="bkmrk-our-design-philosoph"><em>Our design philosophy is simple, do more with less...</em></p>
<p id="bkmrk-maxx-desktop-is-desi">The MaXX<strong>desktop</strong> is designed from the ground up for speed,&nbsp; fast/responsive, lightweight/simplicity over eye-candidness, but more importantly, to get the heck out of your way... The name <em>MaXX Interactive</em> doesn't mean maximum visual interaction, which are distractions or so what we call, UI noises. It's means maximum creativity with interactive assistance from the Desktop. In many ways, it's made for you and your brain so that it can relax, focus on let the creative juice flowing with far fewer distractions. We see desktop notifications in a very different way, but this is for another discussion. In short, the MaXX<strong>desktop</strong> let you focus on the creative&nbsp; tasks ahead without interference or visual distractions.<em><strong>&nbsp; <br></strong></em></p>
<h3 id="bkmrk-experience-matter">Experience Matters</h3>
<p id="bkmrk-finally%2C-our-team-me">Our team is sharing the same vision of making use of the right set of technologies with industry proven best practices and guidelines to build the right software, the right way.&nbsp; We aim at providing a consistent and pleasant user experience built on top of modern and stable foundations.&nbsp; Every good and useful piece of tech deserves to be future-proof and this is where several decades of experience in building battle-proven mission critical systems for high performance Enterprise class applications comes in. If it's architect-ed properly,&nbsp; it can evolve without breaking apart!</p>
<h3 id="bkmrk-is-maxx-desktop-for-">Is MaXX Desktop for you?</h3>
<p id="bkmrk-maxx-desktop%27s-typic">MaXX<strong>desktop</strong>'s typical users are old IRIX users/sysadmins, Computer Graphics Artists, Motion Pictures and Special Effects Studios, Software/Game Developers, Visualization/Simulation, Virtual Reality power-users or Oil and Gas research to name a few. MaXX<strong>desktop</strong> is also for anyone who wants get a break from all the surrounding noises and create stuff while sporting a very unique/cool daily driver.<strong> If it is the case, then MaXX is for you.</strong></p>
<hr id="bkmrk--1"><h3 id="bkmrk-navigation">Navigation</h3>
<p id="bkmrk-this-site-is-powered"><em>This site is powered by <a href="https://www.bookstackapp.com/" target="_blank" rel="noopener"><strong>BookStack</strong></a> (a type of Wiki engine) and you can navigate it by using the upper-right links 'Shelves and Books'.&nbsp; You may use the search bar on top or the convenient links below.</em></p>
<p id="bkmrk-the-maxx-desktop-tea">The MaXX<strong>desktop</strong> team</p>
    </div>
        </main>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[RGFW: Single-header C99 window abstraction library (135 pts)]]></title>
            <link>https://github.com/ColleagueRiley/RGFW</link>
            <guid>42217535</guid>
            <pubDate>Fri, 22 Nov 2024 21:31:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ColleagueRiley/RGFW">https://github.com/ColleagueRiley/RGFW</a>, See on <a href="https://news.ycombinator.com/item?id=42217535">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Riley's Graphics library FrameWork</h2><a id="user-content-rileys-graphics-library-framework" aria-label="Permalink: Riley's Graphics library FrameWork" href="#rileys-graphics-library-framework"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ColleagueRiley/RGFW/blob/main/logo.png?raw=true"><img src="https://github.com/ColleagueRiley/RGFW/raw/main/logo.png?raw=true" alt="THE RGFW Logo"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Build statuses</h2><a id="user-content-build-statuses" aria-label="Permalink: Build statuses" href="#build-statuses"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ColleagueRiley/RGFW/actions/workflows/linux.yml/badge.svg"><img src="https://github.com/ColleagueRiley/RGFW/actions/workflows/linux.yml/badge.svg" alt="workflow"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/ColleagueRiley/RGFW/actions/workflows/windows.yml/badge.svg"><img src="https://github.com/ColleagueRiley/RGFW/actions/workflows/windows.yml/badge.svg" alt="workflow windows"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/ColleagueRiley/RGFW/actions/workflows/macos.yml/badge.svg"><img src="https://github.com/ColleagueRiley/RGFW/actions/workflows/macos.yml/badge.svg" alt="workflow macOS"></a></p>
<p dir="auto">A cross-platform lightweight single-header very simple-to-use window abstraction library for creating graphics Libraries or simple graphical programs. Written in pure C99.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">About</h2><a id="user-content-about" aria-label="Permalink: About" href="#about"></a></p>
<p dir="auto">RGFW is a free multi-platform single-header very simple-to-use window abstraction framework for creating graphics Libraries or simple graphical programs. it is meant to be used as a very small and flexible alternative library to GLFW.</p>
<p dir="auto">The window backend supports XLib (UNIX), Cocoas (MacOS), webASM (emscripten) and WinAPI (tested on windows <em>XP</em>, 10 and 11, and reactOS)<br>
Windows 95 &amp; 98 have also been tested with RGFW, although results are iffy</p>
<p dir="auto">Wayland: to compile wayland add (RGFW_WAYLAND=1). Wayland support is very experimental and broken.</p>
<p dir="auto">The graphics backend supports OpenGL (EGL, software, OSMesa, GLES), Vulkan, DirectX, <a href="https://github.com/RSGL/RGFW-Metal">Metal</a> and software rendering buffers.</p>
<p dir="auto">RGFW was designed as a backend for RSGL, but it can be used standalone or for other libraries, such as Raylib which uses it as an optional alternative backend.</p>
<p dir="auto">RGFW is multi-paradigm,<br>
By default RGFW uses a flexible event system, similar to that of SDL, however you can use callbacks if you prefer that method.</p>
<p dir="auto">This library</p>
<ol dir="auto">
<li>is single header and portable (written in C99 in mind)</li>
<li>is very small compared to other libraries</li>
<li>only depends on system API libraries, Winapi, X11, Cocoa</li>
<li>lets you create a window with a graphics context (OpenGL, Vulkan or DirectX) and manage the window and its events only with a few function calls</li>
</ol>
<p dir="auto">This library does not</p>
<ol dir="auto">
<li>Handle any rendering for you (other than creating your graphics context)</li>
<li>do anything above the bare minimum in terms of functionality</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Officially tested Platforms</h2><a id="user-content-officially-tested-platforms" aria-label="Permalink: Officially tested Platforms" href="#officially-tested-platforms"></a></p>
<ul dir="auto">
<li>Linux</li>
<li>Raspberry PI OS</li>
<li>Windows, (XP, Windows 10, 11, ReactOS)</li>
<li>MacOS, (10.13, 10.14, 14.5) (x86_64)</li>
<li>HTML5 (webasm / Emscripten)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Supported GUI libraries</h2><a id="user-content-supported-gui-libraries" aria-label="Permalink: Supported GUI libraries" href="#supported-gui-libraries"></a></p>
<p dir="auto">A list of GUI libraries that can be used with RGFW can be found on the RGFW wiki <a href="https://github.com/ColleagueRiley/RGFW/wiki/GUI-libraries-that-can-be-used-with-RGFW">here</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">examples</h2><a id="user-content-examples" aria-label="Permalink: examples" href="#examples"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ColleagueRiley/RGFW/blob/main/screenshot.PNG?raw=true"><img src="https://github.com/ColleagueRiley/RGFW/raw/main/screenshot.PNG?raw=true" alt="examples"></a></p>
<p dir="auto">The examples can also <a href="https://colleagueriley.github.io/RGFW/" rel="nofollow">run in your browser</a> with emscripten</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">compiling</h2><a id="user-content-compiling" aria-label="Permalink: compiling" href="#compiling"></a></p>
<p dir="auto">The examples can be compiled by using <code>make debug</code>, which compiles them in debug mode and then runs them<br>
or <code>make</code> which simply compiles them.</p>
<p dir="auto">The dx11 example has its own Makefile functions because it is Windows only, those include
<code>make DX11</code> and <code>make debugDX11</code></p>
<p dir="auto">You can do CC=<code>compiler</code> to specify a specific compiler<br>
Tested and supported compilers include, <code>gcc</code>, <code>clang</code>, <code>[x86_64 / i686-w64]-w64-mingw32-gcc</code>, <code>cl</code> (linux AND windows)</p>
<p dir="auto"><code>tcc</code> has also been tested but work on linux only</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">basic</h2><a id="user-content-basic" aria-label="Permalink: basic" href="#basic"></a></p>
<p dir="auto">A basic example can be found in <code>examples/basic</code>, it includes a basic OpenGL example of just about all of RGFW's functionalities.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">events</h2><a id="user-content-events" aria-label="Permalink: events" href="#events"></a></p>
<p dir="auto">The event example can be found in <code>examples/events</code>, it shows all the events and the data they send.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">callbacks</h2><a id="user-content-callbacks" aria-label="Permalink: callbacks" href="#callbacks"></a></p>
<p dir="auto">The callback example can be found in <code>examples/callbacks</code>, it shows all the events and the data they send, but processed with callbacks instead.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">dx11</h2><a id="user-content-dx11" aria-label="Permalink: dx11" href="#dx11"></a></p>
<p dir="auto"><code>examples/dx11</code> is a minimalistic example of the use of DirectX with RGFW</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">gl33</h2><a id="user-content-gl33" aria-label="Permalink: gl33" href="#gl33"></a></p>
<p dir="auto"><code>examples/gl33</code> is a minimalistic example of the use of OpenGL 3.3 with RGFW, this example was made by <a href="https://github.com/THISISAGOODNAME">AICDG</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">gles2</h2><a id="user-content-gles2" aria-label="Permalink: gles2" href="#gles2"></a></p>
<p dir="auto"><code>examples/gles2</code> is a minimalistic example of the use of OpenGL ES 2 with RGFW</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">vk10</h2><a id="user-content-vk10" aria-label="Permalink: vk10" href="#vk10"></a></p>
<p dir="auto"><code>examples/vk10</code> is a minimalistic example of the use of Vulkan with RGFW, this example was made by <a href="https://github.com/THISISAGOODNAME">AICDG</a></p>
<p dir="auto">It also includes <code>examples/vk10/RGFW_vulkan.h</code> which can be used to create a basic vulkan context for RGFW.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">basic</h2><a id="user-content-basic-1" aria-label="Permalink: basic" href="#basic-1"></a></p>
<p dir="auto">A basic example can be found in <code>examples/basic</code>, it includes a basic OpenGL example of just about all of RGFW's functionalities.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">buff</h2><a id="user-content-buff" aria-label="Permalink: buff" href="#buff"></a></p>
<p dir="auto"><code>examples/buffer</code> is an example that shows how you can use software rendering with RGFW using RGFW_BUFFER mode which allows you to render directly to the window's draw buffer.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">PortableGL</h2><a id="user-content-portablegl" aria-label="Permalink: PortableGL" href="#portablegl"></a></p>
<p dir="auto"><code>examples/PortableGL</code> is an example that shows how you'd use RGFW with <code>portablegl.h</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">first person camera</h2><a id="user-content-first-person-camera" aria-label="Permalink: first person camera" href="#first-person-camera"></a></p>
<p dir="auto"><code>examples/first-person-camera</code> is an example that shows how you'd make a game with a first person camera with RGFW</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">a very simple example</h2><a id="user-content-a-very-simple-example" aria-label="Permalink: a very simple example" href="#a-very-simple-example"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="#define RGFW_IMPLEMENTATION
#include &quot;RGFW.h&quot;

u8 icon[4 * 3 * 3] = {0xFF, 0x00, 0x00, 0xFF,    0xFF, 0x00, 0x00, 0xFF,     0xFF, 0x00, 0x00, 0xFF,   0xFF, 0x00, 0x00, 0x00, 0xFF, 0xFF, 0x00, 0xFF, 0xFF, 0xFF, 0x00, 0xFF,     0xFF, 0x00, 0x00, 0xFF, 0xFF, 0x00, 0x00, 0xFF, 0xFF, 0x00, 0x00, 0xFF};

void keyfunc(RGFW_window* win, u32 keycode, char keyName[16], u8 lockState, u8 pressed) {
    printf(&quot;this is probably early\n&quot;);
}

int main() {
    RGFW_window* win = RGFW_createWindow(&quot;name&quot;, RGFW_RECT(500, 500, 500, 500), (u64)RGFW_CENTER);

    RGFW_window_setIcon(win, icon, RGFW_AREA(3, 3), 4);
    
    RGFW_setKeyCallback(keyfunc); // you can use callbacks like this if you want 

    i32 running = 1;

    while (running) {
        while (RGFW_window_checkEvent(win)) { // or RGFW_window_checkEvents(); if you only want callbacks
            if (win->event.type == RGFW_quit || RGFW_isPressed(win, RGFW_Escape)) {
                running = 0;
                break;
            }

            if (win->event.type == RGFW_keyPressed) // this is the 'normal' way of handling an event
                printf(&quot;This is probably late\n&quot;);
        }
        
        glClearColor(0xFF / 255.0f, 0XFF / 255.0f, 0xFF / 255.0f, 0xFF / 255.0f);
        glClear(GL_COLOR_BUFFER_BIT);

        RGFW_window_swapBuffers(win);
    }

    RGFW_window_close(win);
}"><pre><span>#define</span> <span>RGFW_IMPLEMENTATION</span>
<span>#include</span> <span>"RGFW.h"</span>

<span>u8</span> <span>icon</span>[<span>4</span> <span>*</span> <span>3</span> <span>*</span> <span>3</span>] <span>=</span> {<span>0xFF</span>, <span>0x00</span>, <span>0x00</span>, <span>0xFF</span>,    <span>0xFF</span>, <span>0x00</span>, <span>0x00</span>, <span>0xFF</span>,     <span>0xFF</span>, <span>0x00</span>, <span>0x00</span>, <span>0xFF</span>,   <span>0xFF</span>, <span>0x00</span>, <span>0x00</span>, <span>0x00</span>, <span>0xFF</span>, <span>0xFF</span>, <span>0x00</span>, <span>0xFF</span>, <span>0xFF</span>, <span>0xFF</span>, <span>0x00</span>, <span>0xFF</span>,     <span>0xFF</span>, <span>0x00</span>, <span>0x00</span>, <span>0xFF</span>, <span>0xFF</span>, <span>0x00</span>, <span>0x00</span>, <span>0xFF</span>, <span>0xFF</span>, <span>0x00</span>, <span>0x00</span>, <span>0xFF</span>};

<span>void</span> <span>keyfunc</span>(<span>RGFW_window</span><span>*</span> <span>win</span>, <span>u32</span> <span>keycode</span>, <span>char</span> <span>keyName</span>[<span>16</span>], <span>u8</span> <span>lockState</span>, <span>u8</span> <span>pressed</span>) {
    <span>printf</span>(<span>"this is probably early\n"</span>);
}

<span>int</span> <span>main</span>() {
    <span>RGFW_window</span><span>*</span> <span>win</span> <span>=</span> <span>RGFW_createWindow</span>(<span>"name"</span>, <span>RGFW_RECT</span>(<span>500</span>, <span>500</span>, <span>500</span>, <span>500</span>), (<span>u64</span>)<span>RGFW_CENTER</span>);

    <span>RGFW_window_setIcon</span>(<span>win</span>, <span>icon</span>, <span>RGFW_AREA</span>(<span>3</span>, <span>3</span>), <span>4</span>);
    
    <span>RGFW_setKeyCallback</span>(<span>keyfunc</span>); <span>// you can use callbacks like this if you want </span>

    <span>i32</span> <span>running</span> <span>=</span> <span>1</span>;

    <span>while</span> (<span>running</span>) {
        <span>while</span> (<span>RGFW_window_checkEvent</span>(<span>win</span>)) { <span>// or RGFW_window_checkEvents(); if you only want callbacks</span>
            <span>if</span> (<span>win</span><span>-&gt;</span><span>event</span>.<span>type</span> <span>==</span> <span>RGFW_quit</span> <span>||</span> <span>RGFW_isPressed</span>(<span>win</span>, <span>RGFW_Escape</span>)) {
                <span>running</span> <span>=</span> <span>0</span>;
                <span>break</span>;
            }

            <span>if</span> (<span>win</span><span>-&gt;</span><span>event</span>.<span>type</span> <span>==</span> <span>RGFW_keyPressed</span>) <span>// this is the 'normal' way of handling an event</span>
                <span>printf</span>(<span>"This is probably late\n"</span>);
        }
        
        <span>glClearColor</span>(<span>0xFF</span> / <span>255.0f</span>, <span>0</span><span>XFF</span> / <span>255.0f</span>, <span>0xFF</span> / <span>255.0f</span>, <span>0xFF</span> / <span>255.0f</span>);
        <span>glClear</span>(<span>GL_COLOR_BUFFER_BIT</span>);

        <span>RGFW_window_swapBuffers</span>(<span>win</span>);
    }

    <span>RGFW_window_close</span>(<span>win</span>);
}</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="linux : gcc main.c -lX11 -lXcursor -lGL
windows : gcc main.c -lopengl32 -lshell32 -lgdi32
macos : gcc main.c -framework Foundation -framework AppKit -framework OpenGL -framework CoreVideo"><pre>linux <span>:</span> gcc main.c -lX11 -lXcursor -lGL
windows <span>:</span> gcc main.c -lopengl32 -lshell32 -lgdi32
macos <span>:</span> gcc main.c -framework Foundation -framework AppKit -framework OpenGL -framework CoreVideo</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<p dir="auto">There is a lot of in-header-documentation, but more documentation can be found at <a href="https://colleagueriley.github.io/RGFW/docs/index.html" rel="nofollow">https://colleagueriley.github.io/RGFW/docs/index.html</a>
If you wish to build the documentation yourself, there is also a Doxygen file attached.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Bindings</h2><a id="user-content-bindings" aria-label="Permalink: Bindings" href="#bindings"></a></p>
<p dir="auto">A list of bindings can be found on the RGFW wiki <a href="https://github.com/ColleagueRiley/RGFW/wiki/Bindings">here</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">projects</h2><a id="user-content-projects" aria-label="Permalink: projects" href="#projects"></a></p>
<p dir="auto">A list of projects that use RGFW can be found on the RGFW wiki <a href="https://github.com/ColleagueRiley/RGFW/wiki/Projects-that-use-RGFW">here</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contacts</h2><a id="user-content-contacts" aria-label="Permalink: Contacts" href="#contacts"></a></p>
<ul dir="auto">
<li>email : <a href="mailto:ColleagueRiley@gmail.com">ColleagueRiley@gmail.com</a></li>
<li>discord : ColleagueRiley</li>
<li>discord server : <a href="https://discord.gg/pXVNgVVbvh" rel="nofollow">https://discord.gg/pXVNgVVbvh</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Supporting RGFW</h2><a id="user-content-supporting-rgfw" aria-label="Permalink: Supporting RGFW" href="#supporting-rgfw"></a></p>
<p dir="auto">There is a RGFW wiki page about things you can do if you want to support the development of RGFW <a href="https://github.com/ColleagueRiley/RGFW/wiki/Supporting-RGFW">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">RGFW vs GLFW</h2><a id="user-content-rgfw-vs-glfw" aria-label="Permalink: RGFW vs GLFW" href="#rgfw-vs-glfw"></a></p>
<p dir="auto">A comparison of RGFW and GLFW can be found at <a href="https://github.com/ColleagueRiley/RGFW/wiki/RGFW-vs-GLFW">on the wiki</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">RGFW uses the Zlib/libPNG license, this means you can use RGFW freely as long as you do not claim you wrote this software, mark altered versions as such and keep the license included with the header.</p>
<div data-snippet-clipboard-copy-content="Permission is granted to anyone to use this software for any purpose,
including commercial applications, and to alter it and redistribute it
freely, subject to the following restrictions:
  
1. The origin of this software must not be misrepresented; you must not
   claim that you wrote the original software. If you use this software
   in a product, an acknowledgment in the product documentation would be
   appreciated but is not required. 
2. Altered source versions must be plainly marked as such, and must not be
   misrepresented as being the original software.
3. This notice may not be removed or altered from any source distribution."><pre><code>Permission is granted to anyone to use this software for any purpose,
including commercial applications, and to alter it and redistribute it
freely, subject to the following restrictions:
  
1. The origin of this software must not be misrepresented; you must not
   claim that you wrote the original software. If you use this software
   in a product, an acknowledgment in the product documentation would be
   appreciated but is not required. 
2. Altered source versions must be plainly marked as such, and must not be
   misrepresented as being the original software.
3. This notice may not be removed or altered from any source distribution.
</code></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Against the Dark Forest (101 pts)]]></title>
            <link>https://www.wrecka.ge/against-the-dark-forest/</link>
            <guid>42217484</guid>
            <pubDate>Fri, 22 Nov 2024 21:24:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wrecka.ge/against-the-dark-forest/">https://www.wrecka.ge/against-the-dark-forest/</a>, See on <a href="https://news.ycombinator.com/item?id=42217484">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
	
	<div>
		<p>The complex of ideas I‚Äôm going to call the Dark Internet Forest emerges from mostly insidery tech thinking, but from multiple directions‚Äîinitially in Kickstarter co-founder Yancey Strickler‚Äôs <a href="https://www.ystrickler.com/the-dark-forest-theory-of-the-internet/" rel="noreferrer">freeform noticings</a> that apply science fiction writer Liu Cixin's dark forest theory of the universe to social media, then in humanist all-arounder Maggie Appleton‚Äôs <a href="https://maggieappleton.com/cozy-web" rel="noreferrer">illustrated tech notes</a>. It names an experience of paranoia and anxiety that by the end of the 2010s was widespread among people with meaningful connections between their online personas and their ability to maintain their standard of living. It hit a nerve, especially within some corners of tech-and-society thinking that influence internet makers. It even shows up in a <a href="https://www.nybooks.com/online/2024/05/04/more-real-than-life-i-saw-the-tv-glow/"><em>New York Review of Books</em> piece</a>: a coup for something so initially modest.</p><p>It‚Äôs tedious and a bit unfair to point out that an informal notion that escaped containment is flawed or incomplete, because of course it is. I‚Äôm going to do it anyway, because it describes a common set of experiences and reactions to our fraught moment in social technology. And also because analogies are tools to think with, and the tools we think with have weirdly intense shaping effects on what we do and make: <a href="https://aeon.co/essays/the-tragedy-of-the-commons-is-a-false-and-dangerous-myth" rel="noreferrer">see "the tragedy of the commons." </a></p><p><a href="https://www.ystrickler.com/the-dark-forest-theory-of-the-internet/">Strickler‚Äôs initial formulation</a>, published in 2019, translates a central idea from Liu‚Äôs <em>Three Body</em> series into a way of understanding the social internet. Liu‚Äôs dark forest theory resolves <a href="https://waitbutwhy.com/2014/05/fermi-paradox.html">the Fermi Paradox</a> (which is, roughly, "If the universe is so full of intelligent life, as statistics suggest it must be, where is everyone?") by explaining that all advanced galactic civilizations are locked into a bit of real-life game theory in which the annihilation of any other civilization they encounter is the only correct move. As Liu's characters discover, the universe is a dark forest filled with unstoppable monsters; the only viable strategy is to stay quiet and hide. </p><p>For Strickler, the internet was becoming just such a perilous dark forest, stalked by shadowy forces. Or, one sentence later, it was becoming a series of beneficial dark forests that provide refuge for the imperiled. These protective forests included newsletters and podcasts, but also, ‚ÄúSlack channels, private Instagrams, invite-only message boards, text groups, Snapchat, WeChat, and on and on.‚Äù</p><p>I found it difficult to focus on the initial post when it came out‚Äîsomething about its statement that before the 2016 US election, ‚Äúwe all lived in rounded filter bubbles of happiness,‚Äù only afterward learning that ‚Äúthe tools we thought were only life-giving could be weaponized as well,‚Äù kept making me gap out. But if you press on, there‚Äôs the idea that ‚Äúdark forest‚Äù internet spaces serve as refuges because they‚Äôre ‚Äúnon-indexed, non-optimized, and non-gamified.‚Äù And further, that dark forest spaces grow ‚Äúbecause they provide psychological and reputational cover. They allow us to be ourselves because we know who else is there.‚Äù </p><p>Now we're getting somewhere. This focus on places of reputational and psychological safety‚Äîwhich are safer both because of who‚Äôs ‚Äúthere‚Äù and because the shape of the space hasn‚Äôt been tuned for what I‚Äôd just call <em>extraction</em>‚Äîis an inside-out way of talking about <em>context collapse</em>. Context collapse‚Äîcommunication tuned for one socially distinct group but encountered by another, with uncomfortable and mind-bending and sometimes life-ruining results‚Äîemerges from <a href="https://en.wikipedia.org/wiki/The_Presentation_of_Self_in_Everyday_Life" rel="noreferrer">Erving Goffman‚Äôs work in the 1950s</a>, as expanded by Joshua Meyrowitz in his <a href="https://global.oup.com/academic/product/no-sense-of-place-9780195042313?cc=us&amp;lang=en&amp;" rel="noreferrer"><em>No Sense of Place</em></a> in the 1980s, and which danah boyd <a href="https://www.zephoria.org/thoughts/archives/2013/12/08/coining-context-collapse.html?utm_content=buffer5e438&amp;utm_source=buffer&amp;utm_medium=twitter&amp;utm_campaign=Buffer" rel="noreferrer">began resuscitating and applying to the internet</a> in the early 2000s.</p><p>The longer I work in networked spaces, the more convinced I become that increasingly inescapable and seemingly innocuous forms of context collapse in our media and social internet systems secretly explain a shockingly large proportion of every weirding, every derangement, and every rollercoaster terror/joy of the systems we live in online. So no surprise, I think this part of the Dark Internet Forest complex is sharp and important. It also should make everyone working in tech flinch‚Äîbecause, of course, who built all those indexed, optimized, and gamified environments?</p><figure><img src="https://www.wrecka.ge/content/images/2024/11/who.jpg" alt="A screenshot from Untitled Goose Game in which the geese are yelling &quot;who built them&quot; and &quot;who built them motherfucker&quot; at the persecuted boy NPC." loading="lazy" width="1592" height="856" srcset="https://www.wrecka.ge/content/images/size/w600/2024/11/who.jpg 600w, https://www.wrecka.ge/content/images/size/w1000/2024/11/who.jpg 1000w, https://www.wrecka.ge/content/images/2024/11/who.jpg 1592w" sizes="(min-width: 720px) 720px"></figure><p><a href="https://maggieappleton.com/cozy-web">Appleton‚Äôs follow-on post</a> synthesizes Strickler‚Äôs sense of both dangerous and useful dark forests with <a href="https://contraptions.venkateshrao.com/p/the-extended-internet-universe">Venkatesh Rao‚Äôs ‚Äúcozyweb‚Äù</a> and sketches an ecosystem that includes the perilous aboveground‚Äîthe ‚Äúdark forest of the clear web, inhabited by data scavengers, marketers, &amp; trolls‚Äù‚Äîand the cozyweb refuge underground. Appleton‚Äôs formulation is admirably clear:</p><blockquote>The predators here are the advertisers, tracking bots, clickbait creators, attention-hungry influencers, reply guys, and trolls. It's unsafe to reveal yourself to them in any authentic way. So we retreat into private spaces. We hide in the cozy web.</blockquote><p>Restructuring the analogy to make the dark forest represent the dangerous and compromised place, rather than the desired refuge, gives Appleton more to work with. The <a href="https://maggieappleton.com/ai-dark-forest">second of her Dark Forest posts is especially good</a>‚Äîit extends, without hype or theology, into the coming degradation of the public surfaces of the internet by antisocial actors wielding generative AI and the real paucity of ways to handle the damage those actors inflict, not only on the internet, but on our ability to believe that the people we meet there are real.</p><p>For my purposes, the Dark Internet Forest complex is one that uses the forest to contrast the feeling of a psychologically dangerous landscape with the one of spaces of retreat, and which‚Äîinescapably, because of its roots in Liu‚Äôs heavily philosophical fiction‚Äîpresents retreat as the only real option. Above all, it‚Äôs a series of descriptions of anxiety and of awakening to a sense of loss. Even for those of us spared the worst things the internet can do, this is a feeling most of us know‚Äîin 2019, I was almost entirely offline myself. Then <a href="https://erinkissane.com/xoxo" rel="noreferrer">2020 happened and rewired my sense of what we can and can't afford to surrender</a>, which is what keeps me circling around these ideas like a dazed shark.</p><p>As a description of personal anxieties and of a collective recoiling from extractive and predatory systems, I think the Dark Internet Forest is useful, because it gets us thinking about place. That‚Äôs maybe all it was ever meant to be, which is fine. I need something to one side of that, though‚Äîsomething that shares characteristics with thick description and frame analysis. And as a framing of the problems with our networks <em>for people in a position to do something about them</em>, the Dark Internet Forest pushes most of what I care about out of the picture. I want to bring them back.</p><h2 id="who-got-eaten">who got eaten</h2><p>The Dark Internet Forest focuses on harm to individual well-being and social status‚Äîto mental health, to reputation, to productivity. Those harms are real. And whether we‚Äôre talking about casual brigading or organized attempts to, for instance, prepare the ground for genocide, the platforms‚Äô extractive structures incentivize the loudest and most damaging behavior both directly and indirectly. But some products of mega-platforms of the social internet are much, much worse than others, and the first and second-order harms they create and incentivize have fallen hardest on those outside the sheltered sphere of US technology production.</p><p>First, whatever happens to social media users in the US, it‚Äôs much, much worse almost everywhere else. In 2017, Facebook‚Äôs <a href="https://erinkissane.com/meta-in-myanmar-full-series">years of active damage to the media landscape and startling neglect in the face of increasingly desperate warnings from experts</a> contributed‚Äö according to the United Nations, to <a href="https://erinkissane.com/meta-in-myanmar-part-ii-the-crisis">ethnic cleansing and genocide in Myanmar</a>. <a href="https://www.technologyreview.com/2021/07/29/1030260/facebook-whistleblower-sophie-zhang-global-political-manipulation/">Sophie Zhang‚Äôs whistleblower disclosures</a> reveal the extent of Meta‚Äôs longstanding failure to prevent its machinery from being <a href="https://www.theguardian.com/technology/2021/apr/12/facebook-fake-engagement-whistleblower-sophie-zhang">used with impunity to power covert influence campaigns and target journalists and opposition parties all over the world</a>‚Äî<em>except</em> in the US, Canada, and parts of Western Europe. Some of Frances Haugen‚Äôs disclosures touch on this exceptionalism as well: As of a few years ago, more than 90% of Facebook‚Äôs users live outside the US and Canada, but <a href="https://www.wsj.com/articles/facebook-drug-cartels-human-traffickers-response-is-weak-documents-11631812953">the company allocated that massive global userbase only 13% of its content moderation resources</a>.</p><p>Then there‚Äôs what was happening to women on social platforms closer to US tech workers' homes. In 2018, Amnesty International released a report <a href="https://www.amnesty.org/en/latest/research/2018/03/online-violence-against-women-chapter-1-1/">summarizing the misogynist abuse women experienced on Twitter</a>; they followed up with <a href="https://web.archive.org/web/20190203002740/https://decoders.amnesty.org/projects/troll-patrol/findings#inf_12">a crowd-powered data analysis</a> which found that women of color were 34% more likely to be sent abusive (and otherwise "problematic") messages than white women, and that Black women specifically were 84% more likely to be sent these messages. As a kicker, <a href="https://www.amnesty.org/en/latest/news/2024/06/united-states-social-media-companies-removal-of-abortion-related-content-may-hinder-access-to-accurate-health-information/">Amnesty recently released a report</a> on social media megaplatforms‚Äô removal of abortion-related content ‚Äúwith inadequate or unclear justification‚Äù after the overturning of Roe vs. Wade in the United States.</p><p>And despite objections from social media companies and some researchers stating that <a href="https://www.theatlantic.com/technology/archive/2023/08/youtube-rabbit-holes-american-politics/675186/">YouTube‚Äôs recommendation systems don‚Äôt encourage ‚Äúrabbit-hole‚Äù spirals</a>‚Äîor <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC10468141/"><em>no longer</em> encourage them</a>, at least‚Äîa 2021 <em>Wall Street Journal</em> study finds <a href="https://www.wsj.com/articles/how-tiktok-inundates-teens-with-eating-disorder-videos-11639754848">TikTok‚Äôs algorithms serving young women content encouraging starvation</a>, a 2021 Media Matters study traces the way <a href="https://www.mediamatters.org/tiktok/tiktoks-algorithm-leads-users-transphobic-videos-far-right-rabbit-holes">TikTok leads the viewers of anti-trans content into a cornucopia of extremist videos</a>, including ‚Äúmisogynistic content, racist and white supremacist content, anti-vaccine videos, antisemitic content, ableist narratives, conspiracy theories, hate symbols, and videos including general calls to violence‚Äù and a 2023 Amnesty study shows TikTok‚Äôs algorithms dropping proxies for young users into <a href="https://cdn.amnesty.at/media/11311/amnesty-report_driven_into_the_darkness_how-tiktoks-for-you-feed-encourages-self-harm-and-suicidal-ideation_november-2023.pdf">deep wells of suicidal-ideation content</a>. Studies like these absolutely get oversimplified into moral-panic‚Äìtinged political grandstanding, but the machinery is still out there, grinding away.</p><p>In a framework for thinking about our networks, to leave out the majority of people sustaining real damage is a failure of <em>perception</em> and of <em>proportion</em>. It matters because the remedies available to people like me‚Äîa white, tech-ish worker in the US‚Äîare not necessarily going to do much for the people bearing the brunt of the mega-platforms‚Äô worst actions.</p><p>And speaking of those actions‚Ä¶</p><h2 id="who-ate-them">who ate them</h2><p>On one hand, the predators in the Dark Internet Forest are the mega-platforms themselves, at the core of which are machines for turning human action and feeling into saleable data objects.</p><p>On the other hand, the predators are clearly <em>us</em>: Individual people doing galaxy-brain bad-faith readings of other people‚Äôs banal posts for the juice and swarms of people looking for ideological opponents to mob, largely as a way of claiming or defending quasi-spatial territory: <em>This is ours, not yours. We don‚Äôt do that here</em>. </p><p>There are also the industrialized battalions running variously sophisticated ops to make the ‚Äúpublic conversation‚Äù look like something it isn‚Äôt‚Äîto accelerate discord, to fake overwhelming support or opposition for an entity or idea, to make a group look stupid or <a href="https://www.nytimes.com/2018/10/15/technology/myanmar-facebook-genocide.html?unlocked_article_code=KARVJapYvl1Y6L1cieWmNoOFxPgEAC2ZMHtfiZ7BsjuB4MSBfeTmmw8qAgf_LqJHnCEapaMqECHmO3q7kvvtYwii2910C_u_Kg-_EbNKEiyYglifgsfqSOQjuBB7jIpIGMYoG6yhsVeZ870Qc4PGIb0GNsypqYsMOY73_yzGrn79cFHQfEzvYPBJATppRHCHK-qy3gOmuLY0Tw_NmiDBDrF9veQ5xyjMCtfYXjNOJ1IbzxXuzCFUPMwscGe1WwM8-g_f-Byy-zbYVnSYx_wTJYPcCcrp7KppFt6NpxbBbVHLO0e-2gd2LKxotalTNVYGXiHq2mJYNaVhoDJaixTf6GADI3oUnA&amp;smid=url-share" rel="noreferrer">dangerous-and-therefore-worthy-of-extermination</a>, often <a href="https://www.wired.com/story/russian-black-activist-facebook-accounts/" rel="noreferrer">by pretending to be a member</a> and posting <a href="https://www.adl.org/disinformation-propaganda-advocating-violence-against-white-people-using-hashtags-associated-black" rel="noreferrer">stupid or dangerous things</a>. (I'm linking to old stories, but these campaigns have only revved up, globally, since then.)</p><p>If you believe that the shape of the mega-platforms has no bearing on these specific, internet-optimized antisocial behaviors‚Äîif you think that‚Äôs <em>just how people are</em>‚Äîthere‚Äôs genuinely not much to do about the PvP stuff. You can ban some fake accounts, build teams to look out for particularly successful covert influence campaigns, and give end-users rudimentary safety tools for when the mob turns on them, but beyond that, well. Can‚Äôt fix people problems with software. </p><p>If this truly is the case‚Äîif the only way to improve our public internet is to convert all humans one by one to a state of greater enlightenment‚Äîthen a full retreat into the bushes is the only reasonable course.</p><p>But it <strong>isn</strong>‚Äôt the case. Because yes, the existence of dipshits is indeed unfixable, but building arrays of Dipshit Accelerators that allow a small number of bad actors to build destructive empires defended by Dipshit Armies is a choice. The refusal to genuinely remodel that machinery when its harms first appear is another choice. Mega-platform executives, themselves frequently dipshits, who make these choices, lie about them to governments and ordinary people, and refuse to materially alter them. But in the Dark Internet Forest, the mega-platforms and their leaders are missing from the frame except as shadowy super-predators‚Äîthe equivalent of Liu‚Äôs inevitably annihilating aliens. </p><p>In truth, the mega-platforms and their pocket-warlord leaders fell into their roles largely by chance and have since attempted to rule as though extraordinarily consequential global rulemaking and governance by a handful of US companies built to exploit human feeling for financial gain were a sensible way to arrange the world. Facebook was born from a website made for elite students to rank their classmates‚Äô sexual attractiveness; Twitter was a watercooler where bored office workers could get attention by telling jokes in public. It‚Äôs as if 3M‚Äôs accidental invention of Post-It notes while failing to make space glue landed them a UN veto.</p><p>The dangers of the situation are obvious and real, but it matters that we remember that the world‚Äôs big platforms are steered not by shadowy forces, but by teams of gold-rush-addled dorks whose sometimes-well-meaning employees are stuck frantically LARPing world government on internal forum software. </p><p>It‚Äôs equally important to remember that the patterns we‚Äôve experienced on mega-platforms are not the only way to do networks but the result of specific combinations of under-thinking and malign commercial pressures‚Äîand that the currently ascendant systems are not inevitably annihilating forces, but legal and financial constructs that can be brought to heel, forcibly reconfigured, or just replaced. Keeping these basic facts in mind is oddly difficult, because there‚Äôs so much money involved, and money is a spell for blurring the truth.</p><p>But all these platforms and attendant dipshits <em>will</em> be replaced, eventually, and what happens next isn't guaranteed. The British East India company was a commercial atrocity factory at near-global scale; what came after it was direct colonial rule. The assumption that "Twitter but decentralized" or "Facebook but open-source and federated" will necessarily be good‚Äîrather than <em>differently bad</em>‚Äîis a weak one. </p><p>So the necessary counterpart to understanding that the Dark Forest Internet complex obscures the arbitrary and temporary nature of the current situation might be accepting that there is no moral arc of the world. Our systems bend toward justice when we bend them, and keep on bending them, forever.</p><p>I think our failure to remember that the mega-platforms are just intentionally extractive constructs run by brainmelted but very human weirdos is a failure of <em>accountability</em>, but our failure to remember that it doesn‚Äôt have to be this way is a failure not only of imagination, but of <em>nerve</em>.</p><h2 id="networking-as-if-people-mattered">networking as if people mattered</h2><p>The last and most most dangerous weakness of the Dark Internet Forest as a frame is that it positions the broad landscape of connection as something that ‚Äúwe‚Äù can simply do without‚Äîand without which we will indeed feel better and be more productive.</p><p>On the level of the individual, this is true for certain values of ‚Äúwe‚Äù: for people who are, in any sense, <em>established</em>; people who already have the social status they required to succeed in their field; people whose work doesn‚Äôt depend on them needing to find (and re-find and re-find) readers or customers; people whose professional and personal networks are already strong enough to catch them if they slip; people with money.</p><p>So what about everyone else? Should people without those forms of access and capital simply forgo all the benefits afforded by access to broad networks? Or, alternately, should we expect the new people, the young people, and the less-established people to just hack their way through that forest‚Äîwhich is so much gnarlier now than it was when we built it‚Äîto bootstrap their way to a nice bunker of their own? That rhymes, at least, with the patterns of generational disdain toward the people born into financial systems that strip away stabilities (affordable education, affordable housing, retirement funds, seasons with weather) their parents could take for granted, if they were white enough and within spitting range of middle class. The Avocado Toast Theory of the Internet, maybe.</p><p>This all stops being an individual problem and becomes a collective one when bad products of the social internet get worse, as when platform turmoil and manipulation helps remodel the offline world in the image of the most grotesque parts of the online one. And also when previously good products of the social internet are lost, as when it becomes impossible for people to find sustaining work, learn from one another, or organize responses to the rolling crises in which we live. </p><p>Given all of this, it seems questionable for technologists to cede the territory of the public internet to their <em>fellow-but-worse</em> technologists and the predatory forces they assemble and arm. This was always true, but maybe it's clearer now, as we watch the recreational troll armies and mega-platform leaders and openly supremacist policymakers and the next US presidential administration glop together like a bad special effect. But I would argue that socio-technical systems that invite and facilitate proto-fascist programs of universal surveillance, control, and dehumanization aren't safe in <em>any</em> hands.</p><p>The public social internet is worth designing and governing in a way that demonstrates less than total amnesia about the history of human civilizations and the ways we‚Äôve learned to be together without killing each other. For people with the ability and willingness to work on network problems, the real choice isn't between staying on the wasteland surfaces of the internet and going underground, but between making safer and better places for human sociability and not doing that.</p><p>Unfortunately, the business of building systems for civilization is as complicated and <em>as intrinsically political</em> online as it is offline. If retreat seems easier, that‚Äôs because it is. But here we are.</p><h2 id="what-is-a-forest-in-a-world-on-fire">what is a forest in a world on fire</h2><p>Shortly before he died in 2022, the great activist and writer Mike Davis said this to journalist Lois Beckett: ‚ÄúThere is so much unmobilized love out there. It‚Äôs really moving to see how much.‚Äù He was talking about the outpourings of gratitude from people whose lives he'd changed or set on better courses, after they learned he was dying. It's also a central truth of his life, and the way he worked in the world.</p><p><a href="https://www.haymarketbooks.org/books/791-hope-in-the-dark" rel="noreferrer">Rebecca Solnit has written movingly</a> about the freedom to care that arises during and after disaster, but living through it will rewire you for good. The arbitrary restrictions of normal life fall away. The need for broad connection becomes literally vital: people live or die based on the resources and help they receive or don‚Äôt receive. <a href="https://erinkissane.com/xoxo" rel="noreferrer">I said what I needed to say about that at XOXO</a>, but this explosive upwelling of care manifests in so many ways, starting with the mutual aid work that emerges overnight like mushrooms in the aftermath of ~natural disasters. But the mushrooms‚Äîthe fruiting bodies of vast subterranean networks‚Äîcan only pull off that magic trick because the hyphal infrastructure is already there, invisibly connected, waiting for the moment to emerge.</p><p>Collective action requires that we find each other, both beforehand and in the moment, and build human networks resilient enough to withstand every kind of weather. This becomes wickedly hard to do when the public social surfaces of the internet teem with predators‚Äîand also when they‚Äôre structured by root-level design decisions that make the simplest patterns of communication harder and worse in service of the systems‚Äô underlying anti-human purposes.</p><p>We make the human world by experimenting with ways to work together and then connecting those ways: villages and cities, hedge funds and labor unions, global conglomerates and volunteer rural fire departments, nation-states and communities of practice. We move between apartments and schools and sidewalks and shops and parks and airports and we understand, for the most part, who is there with us. Given the chance, we‚Äôd be moving freely between the surfaces and burrows of the internet, but many of those surfaces are on fire.</p><p>Back in the spring of this year, in an interview for the <a href="https://fediverse-governance.github.io/" rel="noreferrer">network governance project</a> I was working on, media and governance scholar Nathan Schneider‚Äîwhose <a href="https://www.ucpress.edu/books/governable-spaces/epub-pdf" rel="noreferrer">Governable Spaces</a> I am always recommending‚Äîsaid something that‚Äôs been ringing in my ears ever since:</p><blockquote>I think of tech as a wildfire‚Äîit burns really quickly. And we get a lot of wildfires out here, and there's the front of it, where the blaze is, and then once it's burnt over, that's when cool things start growing up. They grow much slower, and they find their way through‚Ä¶the burned trees and new life happens. I kind of hope we're entering that phase of social media that we're done with the fast burn. And maybe it had to happen.</blockquote><p>What‚Äôs there after the fire passes over if not that <a href="https://press.princeton.edu/books/paperback/9780691220550/the-mushroom-at-the-end-of-the-world?srsltid=AfmBOoo6gvYwtVe6T7BbGX1RUsXTiclm0eDbLvZJ_ZKexsUNQ_iUrLiY" rel="noreferrer">goddamn mushroom at the end of a world</a>?</p><h2 id="forestry-for-beginners">forestry for beginners</h2><p>Here are some things I have come to believe.</p><p>Few, if any, of this moment‚Äôs apparently unstoppable tech platforms will survive for long. The people on them will eventually leave‚Äîwhen they‚Äôre forced to do so by the continuous degradation of their experience, or because they‚Äôre forced to do so because their governments put the hammer down, as Brazil recently demonstrated‚Äîor sometimes when they just get tired of platform leaders acting like clowns and boosting troll-agents of openly fascist chaos into power. And that there is therefore not only an opportunity to provide more humane places for those people to go, but a responsibility to do so. </p><p>Global mega-platforms under capitalism are <em>structurally incapable</em> of handling the business of civilization: of governance, of providing genuinely public infrastructure, of making knife-edge decisions about the balance of liberties and securities. It‚Äôs not what they do or what they <em>want</em> to do, and in many cases it‚Äôs in opposition to their actual interests. But even if they wanted to, even if they pulled off the trick of freeing themselves from the gravitational pull of capital and extraction, I don't think <em>any</em> centrally governed platform at global scale is capable of doing the work, even if they hired the best and sharpest people I know.* Even if they put real effort into humanist upstream product design, rather than tossing loose change to trust and safety teams sent in to clean up after the fact. </p><p>Local norms matter too much for global governance of the social internet to make sense; the flattening of global diversity to fit the norms and interests of any given American techno-culture‚Äîcorporate or otherwise‚Äîis both a baldly colonial aspiration and one we should scorn for the same reason that we leave the idea of effective, monolithic, planetary-scale government‚Äîbenevolent or otherwise‚Äîto underbaked science fiction. Home rule and genuine resilience both require the existence of <em>many places</em>, many of them at least partially interconnected. Decades down the road, I think the notion that a pack of mostly-American mega-corporations could ever have stood in for the complexities of governing a new layer of global public life, with all the opportunities and dangers it brings, will be obviously laughable. I think it already is.</p><p>And most of all: The social internet <em>should</em> be a forest‚Äînot The Dark Forest, but something much more like a real one: Interconnected from the densely mycelial underground to light-filtering overstory but <em>also</em> offering infinite niches and multi-scale zones of sheltered exchange and play. Deeply human in the way that real forests are the  result of human and other-than-human collaboration running back into unrecorded time. Balanced, neither extracting too much from its component organisms nor pretending that a pantomime of a return to a pristine and ungoverned state will solve any problems at all. (Predation is inevitable in any system, but a working ecosystem starves out the ones who overfeed and provides cover for growth and for the long, continuous experiment of evolutionary change.)</p><p>The obstacles to these life-sustaining internet forests are fundamentally the same forces that threaten the real forests and our whole living world: unbounded extraction; unaccountable leadership; societal refusal to take on the responsibilities of governing our increasingly complex commons, instead of burying them deeper and deeper in pretenses to action. </p><p> I no longer think that it's possible to mount an effective defense of the physical world‚Äîand of each other, in our fleshy vulnerability‚Äîwithout unfucking our networks. I find this both terrifying and clarifying. </p><h2 id="the-burrow-and-the-upper-world">the burrow and the upper world</h2><p>In the introduction of his <em>Cosmos &amp; Hearth</em>, the wonderful humanist geographer Yi-Fu Tuan briefly refers to a passage about Mole‚Äôs homecoming in <em>The Wind in the Willows</em>. In that scene, Mole, who has been adventuring broadly with Rat and company, gazes around his home before sleeping:</p><blockquote>He saw clearly how plain and simple‚Äîhow narrow, even‚Äîit all was; but clearly, too, how much it all meant to him, and the special value of some such anchorage in one's existence. He did not at all want to abandon the new life and its splendid spaces, to turn his back on sun and air and all they offered him and creep home and stay there; the upper world was all too strong, it called to him still, even down there, and he&nbsp;knew he must return to the larger stage. But it was good to think he had this to come back to, this place which was all his own‚Ä¶</blockquote><p>Mole‚Äôs contentment at this point, midway through the novel, is quite different from his state at its beginning, which finds him spring-cleaning his cozy, dozy network of tunnels, but struck with a sudden longing for something more. By the middle of the novel, Mole‚Äôs experience has opened out to encompass the whole of the wood and countryside and his friendships with Rat, Badger, and the born poster, Mr. Toad, along with his encounters with the book‚Äôs few real villains and dangers.</p><p>As he slides into sleep, Mole‚Äôs beloved Rat is already snoozing across the burrow; his friendship is by far the greatest gift of the world beyond Mole‚Äôs comfortable tunnels. In the morning, they will venture out together.</p><h2 id="notes">notes</h2><p>(*) I'd love to be wrong about this, and I have a list of those best and sharpest people you can hire if you're serious‚Äîyou know where to find me.</p><p>I keep coming back to Ucello's <em>Hunt in the Forest</em> because it's such a great, creepy painting‚Äîthe streamlined deer and hounds, especially, echoing each other so closely it's hard to tell them apart. Most all the human faces are transfixed, staring, shouting or blowing the hunting horn. It's so loud in that moment, but the painting is, of course, perfectly still. The hunt goes back forever. (That horse in the right foreground is about to fuck someone up.)<strong> </strong>I saw it at the Ashmolean once and I don't know if I will ever get to see it again.</p><p>There's another essay applying Dark Forest theory to the internet that I only encountered much later‚Äî<a href="https://flugschriften.com/wp-content/uploads/2020/07/flugschriften-6-bogna-konior-the-dark-forest-theory-of-the-internet-v.2.pdf" rel="noreferrer">Bogna Konior's 2020 essay</a> (<a href="https://blokmagazine.com/the-dark-forest-theory-of-the-internet/" rel="noreferrer">alt version in HTML but without the accompanying photos</a>) was commissioned for an exhibition in Slovenia. Konior‚Äôs piece engages with Liu's work before leaping into the <a href="https://exmilitai.re/flatline-constructs.pdf" rel="noreferrer">void-flavored Mark Fisher zone</a>. In its language and logic, Konior‚Äôs piece works in a Cronenberg-tinged mode of <a href="https://thepointmag.com/criticism/when-nothing-is-cool/">academic cool</a>‚Äîedgy, a little squelchy, heavy on longing and sensation, but only at a distance and within the frame of inevitability. It was still fun to read. Konior doesn't acknowledge prior adaptations of Liu‚Äôs theories to the internet; as far as I can tell, the tech scene has ignored her back. </p><h2 id="thank-you">thank you</h2><p>Huge thanks to the people who've signed up to <a href="https://www.wrecka.ge/on-memberships/" rel="noreferrer">support this site and my work</a>. You can <a href="https://www.wrecka.ge/#/portal" rel="noreferrer">sign up for free emails or a paid membership here</a>, but all the research and essays will be available here for free. </p>
			</div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Understanding Google's Quantum Error Correction Breakthrough (162 pts)]]></title>
            <link>https://www.quantum-machines.co/blog/understanding-googles-quantum-error-correction-breakthrough/</link>
            <guid>42215910</guid>
            <pubDate>Fri, 22 Nov 2024 17:53:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantum-machines.co/blog/understanding-googles-quantum-error-correction-breakthrough/">https://www.quantum-machines.co/blog/understanding-googles-quantum-error-correction-breakthrough/</a>, See on <a href="https://news.ycombinator.com/item?id=42215910">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Imagine trying to balance thousands of spinning tops at the same time‚Äîeach top representing a qubit, the fundamental building block of a quantum computer. Now imagine these tops are so sensitive that even a slight breeze, a tiny vibration, or a quick peek to see if they‚Äôre still spinning could make them wobble or fall. That‚Äôs the challenge of quantum computing: Qubits are incredibly fragile, and even the process of controlling or measuring them introduces errors.</p>
<p>This is where Quantum Error Correction (QEC) comes in. By combining multiple fragile physical qubits into a more robust logical qubit, QEC allows us to correct errors faster than they accumulate. The goal is to operate below a critical threshold‚Äîthe point where adding more qubits reduces, rather than increases, errors. That‚Äôs precisely what <a href="https://arxiv.org/abs/2408.13687">Google Quantum AI has achieved with their recent breakthrough [1]</a>.</p>

<h2 aria-level="1"><strong>Google‚Äôs Breakthrough Achievement&nbsp;</strong></h2>
<p><span data-contrast="auto">To grasp the significance of Google‚Äôs result, let‚Äôs first understand what success in error correction looks like. In classical computers, error-resistant memory is achieved by duplicating bits to detect and correct errors. A method called majority voting is often used, where multiple copies of a bit are compared, and the majority value is taken as the correct bit. In quantum systems, physical qubits are combined to create logical qubits, where errors are corrected by monitoring correlations among qubits instead of directly observing the qubits themselves. It involves redundancy like majority voting, but does not rely on observation but rather entanglement. This indirect approach is crucial because directly measuring a qubit‚Äôs state would disrupt its quantum properties. Effective quantum error correction maintains the integrity of logical qubits, even when some physical qubits experience errors, making it essential for scalable quantum computing.</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">However, this only works if the physical error rate is below a critical threshold. In fact, intuition says that increasing the number of physical qubits that make a logical qubit should allow for better error correction. In truth if each physical qubit is very error-prone, adding qubits makes errors accumulate faster than we can detect and correct them. In other words, quantum error correction works only if each qubit can operate below an error threshold even before any error correction. Having more physical qubits allows to increase the QEC code distance, which is a measure of a quantum code‚Äôs ability to detect and correct errors.</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">By showing logical error decreased by a factor of 2.14 when increasing code distance from five to seven, Google has now demonstrated below-threshold operation using surface codes‚Äîa specific type of quantum error correction code.&nbsp; This reduction in errors (which is exponential with increasing code distance) is the smoking gun proving that their QEC strategy works. With this, Google could show that their logical qubit lasted more than twice as long as their best physical qubit, as shown in Figure 1, demonstrating that logical qubits didn‚Äôt just survive‚Äîthey outperformed physical ones.</span><span data-ccp-props="{}">&nbsp;</span></p>

<div id="attachment_16103"><p><img decoding="async" aria-describedby="caption-attachment-16103" src="https://www.quantum-machines.co/wp-content/uploads/2024/11/Screenshot-2024-11-17-091724-1024x388.png" alt="An adapted plot showing logical qubit error rates versus code distance, highlighting exponential suppression of logical errors as the code distance increases." width="800" height="303" srcset="https://www.quantum-machines.co/wp-content/uploads/2024/11/Screenshot-2024-11-17-091724-1024x388.png 1024w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Screenshot-2024-11-17-091724-300x114.png 300w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Screenshot-2024-11-17-091724-768x291.png 768w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Screenshot-2024-11-17-091724.png 1470w" sizes="(max-width: 800px) 100vw, 800px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20800%20303'%3E%3C/svg%3E" data-lazy-srcset="https://www.quantum-machines.co/wp-content/uploads/2024/11/Screenshot-2024-11-17-091724-1024x388.png 1024w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Screenshot-2024-11-17-091724-300x114.png 300w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Screenshot-2024-11-17-091724-768x291.png 768w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Screenshot-2024-11-17-091724.png 1470w" data-lazy-src="https://www.quantum-machines.co/wp-content/uploads/2024/11/Screenshot-2024-11-17-091724-1024x388.png"></p><p id="caption-attachment-16103">Fig. 1 ‚Äì An adapted plot showing logical qubit error rates versus code distance, highlighting exponential suppression of logical errors as the code distance increases. The figure illustrates the transition to below-threshold performance and the ‚Äúbeyond break-even‚Äù behavior achieved with distance-7 codes. (Adapted from [1] by Google Quantum AI, CC BY 4.0)</p></div>
<p><span data-contrast="auto" xml:lang="EN-US" lang="EN-US"><span>A distance-7 surface code on 101 qubits effectively doubled the logical qubit‚Äôs lifetime</span><span> (blue line in Figure 1c)</span><span> compared to uncorrected physical qubits</span><span> (green line in Figure 1c)</span><span>. This accomplishment </span><span>demonstrates</span><span> that error-corrected qubits can preserve coherence </span><span>for longer periods, which is crucial for running extended quantum algorithms and computations. </span></span><span data-ccp-props="{}">&nbsp;</span></p>

<h2 aria-level="1"><span data-contrast="none">A Control Engineering Perspective: How Google Made It Work. </span><span data-ccp-props="{&quot;134245418&quot;:true,&quot;134245529&quot;:true,&quot;335559738&quot;:360,&quot;335559739&quot;:80}">&nbsp;</span></h2>
<p><span data-contrast="auto">The experiment wasn‚Äôt just a test of surface codes‚Äîit was a carefully orchestrated feat of engineering and control. The control system had to deliver flawless precision on multiple fronts‚Äîsynchronization, frequency control, measurement fidelity, real-time decoding, and stability‚Äîover many hours of operation. Let‚Äôs stop for a second to talk about some of these interesting challenges.</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">At the heart of the system was </span><b><span data-contrast="auto">real-time synchronization</span></b><span data-contrast="auto">. Every correction cycle had to complete within 1.1 ¬µs‚Äîa narrow window in which the qubits were measured. The precision of this synchronization was critical to preventing errors from accumulating and destabilizing the computation. Achieving this required precise coordination of control signals across the qubit array, ensuring that every gate operation, measurement, was perfectly aligned.</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">One of the most important components was </span><b><span data-contrast="auto">real-time decoding</span></b><span data-contrast="auto">. Decoding refers to the process of analyzing measurement data to determine where and how errors have occurred. To use logical qubits to perform universal quantum computation, certain gates called non-Clifford gates must be applied. Applying these gates, required correcting errors in real-time based on the real-time decoding. In Google‚Äôs system, the real-time decoder maintained a constant latency of about 63 ¬µs while operating over one million correction cycles. Namely, the real-time error correction pipeline could process the measurements fast enough to avoid congestion. This rapid decoding process was essential, as any delay could allow errors to propagate and accumulate, potentially destabilizing the logical qubits. </span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">The experiment also demanded </span><b><span data-contrast="auto">high-fidelity gate operations</span></b><span data-contrast="auto">. Errors in qubit gates could easily propagate through the system, jeopardizing the stability of the logical qubit. Google achieved single-qubit gate errors below 0.1% and two-qubit CZ gate errors around 0.3%‚Äîthresholds essential to keeping logical qubits stable over time. For this goal, high performance of the control electronics is paramount, as fidelity can directly be impaired by errors of control pulses. These fidelities are especially critical when scaling surface codes, where even minor gate errors could degrade the effectiveness of error correction.</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">As quantum computers scale to more qubits and longer computations, these and more control requirements will only grow more demanding, making the development of advanced control hardware essential for the future of fault-tolerant quantum computing.&nbsp;</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">Out of the requirements above, real-time decoding, in particular, is fundamental for any scalable quantum computing system, as it provides the rapid response required to keep quantum information stable.</span><span data-ccp-props="{}">&nbsp;</span></p>

<h2 aria-level="1"><span data-contrast="none">A deeper dive into real-time decoding&nbsp;</span><span data-ccp-props="{&quot;134245418&quot;:true,&quot;134245529&quot;:true,&quot;335559738&quot;:360,&quot;335559739&quot;:80}">&nbsp;</span></h2>
<p><span data-contrast="auto">Google‚Äôs work highlights that the feasibility of the decoding depends on the decoder latency and throughput, as one of the most important pieces for running QEC below threshold.</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">Decoding is a classical compute task, and it can be done effectively on various classical architectures, such as FPGAs or GPUs. However, there is usually a trade-off between computational resources. FPGAs for example, are limited in computing power, but operate deterministically and in strict timing, making them suitable to manage the qubit control and measurement tasks as well as perform dedicated classical computations with low latency. On the other hand, CPUs or GPUs might have increased latency but enable far more advanced and larger computation. At Quantum Machines, </span><a href="https://www.quantum-machines.co/blog/quantum-machines-announces-deep-quantum-classical-integration-to-power-quantum-accelerated-supercomputers-with-nvidia/"><span data-contrast="none">we partnered with NVIDIA</span></a><span data-contrast="auto"> to deliver a unique platform, called DGX Quantum, that provides a unique combination of ultra-low controller-decoder latency, high-performance computational power, and flexible SW programmability. Our platform, which includes a less than 4 ¬µs communication between our controller, OPX1000 and the CPU/GPU, allows to easily program and execute QEC workflows, including real-time decoding such as Google‚Äôs decoding. The SW programmability allows iterating over the decoding algorithm and scheme very quickly. A feature we believe is key for faster progress towards scalable and effective QEC. The truth is that a lot more experimentation and benchmarking is needed to learn what decoders to use, which classical resources optimize performance and meet requirements and how to design systems that can eventually run QEC on a much larger scale. What we know so far is that the latency of decoders should be less than 10 ¬µs for QEC schemes to converge. </span><a href="https://qm.quantum-machines.co/factoring21"><span data-contrast="none">Watch our CEO Itamar Sivan explaining this further</span></a><span data-contrast="auto"> with the example of Shor‚Äôs algorithm for factorizing the number 21. </span><span><br>
</span><span><br>
</span><span data-contrast="auto">DGX-quantum is already live, showcasing less than 4 ¬µs round-trip latency between controller and GPU. To learn more, <a href="https://www.quantum-machines.co/resources/tutorials/tightly-integrating-gpus-and-qpus-for-quantum-error-correction-and-optimal-control-part-1/">watch the IEEE QCE 2024 tutorial below</a>, on DGX-quantum, co-authored by QM and NVIDIA.</span><span data-ccp-props="{}">&nbsp;</span></p>

<div id="attachment_16105"><p><a href="https://www.quantum-machines.co/resources/tutorials/tightly-integrating-gpus-and-qpus-for-quantum-error-correction-and-optimal-control-part-1/"><img decoding="async" aria-describedby="caption-attachment-16105" src="https://www.quantum-machines.co/wp-content/uploads/2024/11/Link-video-icon-1024x563.png" alt="Video tutorial: Tightly integrating GPUs and QPUs for Quantum Error Correction and Optimal Control." width="800" height="440" srcset="https://www.quantum-machines.co/wp-content/uploads/2024/11/Link-video-icon-1024x563.png 1024w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Link-video-icon-300x165.png 300w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Link-video-icon-768x422.png 768w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Link-video-icon-1536x844.png 1536w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Link-video-icon-2048x1126.png 2048w" sizes="(max-width: 800px) 100vw, 800px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20800%20440'%3E%3C/svg%3E" data-lazy-srcset="https://www.quantum-machines.co/wp-content/uploads/2024/11/Link-video-icon-1024x563.png 1024w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Link-video-icon-300x165.png 300w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Link-video-icon-768x422.png 768w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Link-video-icon-1536x844.png 1536w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Link-video-icon-2048x1126.png 2048w" data-lazy-src="https://www.quantum-machines.co/wp-content/uploads/2024/11/Link-video-icon-1024x563.png"></a></p><p id="caption-attachment-16105">Video tutorial: Tightly integrating GPUs and QPUs for Quantum Error Correction and Optimal Control.</p></div>

<h2 aria-level="1"><span data-contrast="none">So, what‚Äôs next?&nbsp;</span><span data-ccp-props="{&quot;134245418&quot;:true,&quot;134245529&quot;:true,&quot;335559738&quot;:360,&quot;335559739&quot;:80}">&nbsp;</span></h2>
<p><span data-contrast="auto">Google‚Äôs demonstration of below-threshold quantum error correction marks a milestone towards fault-tolerant quantum computing. By demonstrating that logical qubits can outperform physical qubits and showing that errors can be corrected faster than they accumulate, they‚Äôve paved the way for scalable quantum processors.</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">However, this is just the beginning. In the future, to perform universal quantum computation with error corrected logical qubits, the full feedback loop must be closed, meaning that the control system needs to make decisions in real-time based on the decoder computation. Future developments will require faster decoders, better error mitigation strategies, automated calibrations embedded within&nbsp;quantum programs to stabilize parameters, and control hardware that tightly integrates and manages classical and quantum workflows.&nbsp;</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">Google‚Äôs achievement signifies a substantial step toward fault-tolerant quantum computing. By demonstrating that logical error rates can be exponentially suppressed through the use of surface codes, the work provides a scalable and practical pathway to reliable quantum computing. As code distance increases, errors decrease at a rapid rate, setting the stage for quantum processors capable of handling complex operations with higher fidelity. Furthermore, this implementation of&nbsp;fast&nbsp;decoding represents a fundamental advancement in QEC. This technique allows for correction of errors faster than their propagation, minimizing the chance for errors to propagate through the quantum system.</span><span data-ccp-props="{&quot;134233117&quot;:false,&quot;134233118&quot;:false,&quot;201341983&quot;:0,&quot;335551550&quot;:1,&quot;335551620&quot;:1,&quot;335559685&quot;:0,&quot;335559737&quot;:0,&quot;335559738&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p>

<h2 aria-level="1"><span data-contrast="none">Quantum Error Correction and the Vision for Fault Tolerance</span><span data-ccp-props="{&quot;134245418&quot;:true,&quot;134245529&quot;:true,&quot;335559738&quot;:360,&quot;335559739&quot;:80}">&nbsp;</span></h2>
<p><span data-contrast="auto">Real-time, low-latency feedback loops are going to be an essential element of future fault tolerant quantum devices, to ensure that errors are corrected faster than they accumulate. This principle resonates across the broader quantum computing community, where rapid and robust control mechanisms are viewed as the key to achieving large-scale, reliable quantum operations.</span><span data-ccp-props="{}">&nbsp;</span></p>
<p><span data-contrast="auto">By focusing on low-latency, high-fidelity feedback and decoding, the broader quantum technology field is advancing toward the shared goal of fault-tolerant quantum computing, just as Google‚Äôs milestone achievement shows. The evolution of quantum control systems that support agile error correction and real-time adaptability will continue to play a central role in the pursuit of stable, scalable quantum computing systems that can be deployed in practical applications. And with DGX-quantum, we are just starting this exciting journey, so stay tuned for what‚Äôs to come! </span><span data-contrast="auto">‚Äã</span><span data-ccp-props="{}">&nbsp;</span></p>

<div id="attachment_16104"><p><img decoding="async" aria-describedby="caption-attachment-16104" src="https://www.quantum-machines.co/wp-content/uploads/2024/11/Picture1.png" alt="The DGX-Quantum solution, co-developed by NVIDIA and Quantum Machines, enables quantum error correction (QEC), calibration, and fast retuning for large-scale quantum computers. It leverages classical resources (GPUs and CPUs) for quantum computing, with ultra-fast data round-trip delays of under 4 microseconds." width="800" height="306" srcset="https://www.quantum-machines.co/wp-content/uploads/2024/11/Picture1.png 602w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Picture1-300x115.png 300w" sizes="(max-width: 800px) 100vw, 800px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20800%20306'%3E%3C/svg%3E" data-lazy-srcset="https://www.quantum-machines.co/wp-content/uploads/2024/11/Picture1.png 602w, https://www.quantum-machines.co/wp-content/uploads/2024/11/Picture1-300x115.png 300w" data-lazy-src="https://www.quantum-machines.co/wp-content/uploads/2024/11/Picture1.png"></p><p id="caption-attachment-16104">The DGX Quantum solution, co-developed by NVIDIA and Quantum Machines, enables quantum error correction, calibration, and fast retuning for large-scale quantum computers. It allows the use of robust classical resources (GPUs and CPUs) for quantum computer operation, with ultra-fast data round-trip delays of under 4 ¬µs.</p></div>

<h2><strong>Reference</strong></h2>
<p>[1] Acharya, Rajeev, et al. <a href="https://arxiv.org/abs/2408.13687">‚ÄúQuantum error correction below the surface code threshold.‚Äù arXiv preprint arXiv:2408.13687</a> (2024).</p>

</div></div>]]></description>
        </item>
    </channel>
</rss>