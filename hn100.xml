<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 18 Apr 2024 21:00:09 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Windows 10 will start nagging you to switch from local account to MS Account (102 pts)]]></title>
            <link>https://www.neowin.net/news/windows-10-will-soon-start-nagging-you-to-switch-from-local-account-to-microsoft-account/</link>
            <guid>40078686</guid>
            <pubDate>Thu, 18 Apr 2024 17:37:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.neowin.net/news/windows-10-will-soon-start-nagging-you-to-switch-from-local-account-to-microsoft-account/">https://www.neowin.net/news/windows-10-will-soon-start-nagging-you-to-switch-from-local-account-to-microsoft-account/</a>, See on <a href="https://news.ycombinator.com/item?id=40078686">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                                    <span>When you purchase through links on our site, we may earn an affiliate commission. <a href="https://www.neowin.net/terms">Here’s how it works</a>.</span>
                        
                        
                        <p>
    
    <time datetime="Apr 18, 2024 04:02 EDT" pubdate="pubdate">
    Apr 18, 2024 04:02 EDT
    </time>
         · <span>Hot!</span>    
    </p>

                    </div><div itemprop="articleBody">
                                                                        <p><img alt="A late prototype of the Windows 10 stock wallpaper found in a leaked Windows 11 build" src="https://cdn.neowin.com/news/images/uploaded/2023/06/1686472481_img19_story.jpg"></p>

<p>Earlier this week, Microsoft released a new Release Preview update for Windows Insiders who are still using Windows 10. Build 19045.4353 does not contain anything all too exciting, but there is one change that might raise a few eyebrows. Microsoft is now testing new banners in the Settings app to make users with local accounts switch to Microsoft Accounts. <a href="https://www.neowin.net/news/micosoft-account-notifications-are-part-of-windows-10-22h2-release-preview-build-190454353/">The tech giant writes</a>:</p>

<blockquote>


<p><strong>New!</strong> This update starts the rolls out of account-related notifications for Microsoft accounts in Settings &gt; Home. A Microsoft account connects Windows to your Microsoft apps. The account also backs up all your data and helps you to manage your subscriptions. You can also add extra security steps to keep you from being locked out of your account. This feature displays notifications across the Start menu and Settings.</p>
</blockquote>

<p>The change seems to be rolling out gradually, which means not everyone on build 19045.4353 has it yet. However, you can force-enable it using a command for the ViVeTool app. Here is what the new banner looks like:</p>

                            <!-- PLACE THIS SECTION INSIDE OF YOUR BODY WHERE YOU WANT THE VIDEO PLAYER TO RENDER -->
            <figure><a href="https://cdn.neowin.com/news/images/uploaded/2024/04/1713425412_settings_ad.jpg"><img alt="A Microsoft account prompt in the Settings app on Windows 10" height="790" src="https://cdn.neowin.com/news/images/uploaded/2024/04/1713425412_settings_ad.jpg" width="1116"></a></figure><p>If you do not want the Settings app to nag you with Microsoft Account prompts, go to <strong>Privacy &gt; General </strong>and toggle off the "<strong>Show me suggested content </strong><strong>in the Settings app</strong>" option. Also, you can also simply click the close button next to the "Sign in now" button to get rid of the banner.</p>

<p>Here is how to turn the new banner on in case you want to witness it yourself on build 19045.4353:</p>

<ol>
<li>Download ViveTool <a href="https://github.com/thebookisclosed/ViVe/releases">from </a><a href="https://github.com/thebookisclosed/ViVe/releases">GitHub</a> and unpack the files in a convenient and easy-to-find folder.</li>
	<li>Press <strong>Win + R</strong>, type <strong>cmd</strong>, and press <strong>Ctrl + Shift + Enter</strong> to open Command Prompt as Administrator.</li>
	<li>Navigate to the folder containing the ViveTool files with the <strong>CD</strong> command. For example, if you have placed ViveTool in C:\Vive, type <strong>CD C:\Vive</strong>.</li>
	<li>Type <strong>vivetool /enable /id:42563876</strong> and press <strong>Enter</strong>. In order to turn off the new banners in the Settings app, use <strong>vivetool /disable /id:42563876</strong>. Credit for the ID goes to <a href="https://twitter.com/thebookisclosed/status/1780205879209406686">Albacore</a> on X.</li>
	<li>Restart your computer.</li>
</ol>
<p>Microsoft's ongoing fight against local accounts in consumer versions of Windows annoys pretty much everyone, <a href="https://www.neowin.net/news/elon-musk-just-found-out-they-cant-install-windows-11-without-msa-and-is-having-none-of-it/">including Elon Musk</a>. However, Windows 10 still offers a relatively easy way to bypass the MSA requirement during the initial setup. Windows 11, on the other hand, won't let you use a local profile unless you know a magic command (oobe\bypassnro).</p>
                        
                        
                                                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You Need a "WTF Notebook" (295 pts)]]></title>
            <link>https://www.simplermachines.com/why-you-need-a-wtf-notebook/</link>
            <guid>40078106</guid>
            <pubDate>Thu, 18 Apr 2024 16:42:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.simplermachines.com/why-you-need-a-wtf-notebook/">https://www.simplermachines.com/why-you-need-a-wtf-notebook/</a>, See on <a href="https://news.ycombinator.com/item?id=40078106">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
                    <p>I keep a <a href="https://bulletjournal.com/?ref=simplermachines.com">bullet journal</a>. I'm not one of those people you see on Pinterest with the fancy spreads – I mostly just use black ink, the standard setup, and the occasional custom collection.</p><p>Every time I join a new team, I go to the next fresh page, and on top of that page I write: "WTF - [Team Name]." Then I make a note every time I run into something that makes me go "wtf," and a task every time I come up with something I want to change.</p><p>For two weeks, that's all I do. <em>I</em> <em>just write it down. </em>I don't tell the team everything that I think they're doing wrong. I don't show up at retro with all the stuff I think they need to change. I just watch, and listen, and I write down everything that seems deeply weird.</p><p>This is a trick I picked up from <a href="https://www.linkedin.com/in/aramprice?ref=simplermachines.com">a team lead</a> a few years ago, who learned it from a previous lead of his in turn. It's one of my most powerful techniques for making changes on a team, and managing myself while I do it. So I'm going to walk you through how I use that list, and how it helps me to build a reputation as someone who's really effective at getting stuff done, and avoid being someone who's complaining all the time.</p><p>There's always stuff that makes me go "wtf" on a new team. The team talks for an hour in retro about a serious problem, and then leaves without making any action items. The tests don't run locally and no one seems to notice. Big chunks of the build board are always red. Only one person can do some critical, time-sensitive thing. The team is spending a bunch of time on some feature, but when I ask around no one can seems to know why it's important or how it'll help a customer.</p><p>Once I've got a nice big list, I start crossing things off. There are four reasons at this point that I might cross off something I've put on that list:</p><ol><li>There's actually a good reason for it</li><li>The team is already working on a fix</li><li>The team doesn't care about it</li><li>It's really easy to fix</li></ol><p>If the tests don't run locally, for instance, that might be a known issue that there's an ongoing effort to address. The team might do all of their work on virtual machines, and have a simple chat command that provisions those machines for them. Or they might have a pretty good continuous integration system and good habits around making small changes, so not being able to run the tests locally isn't stopping them from deploying multiple times a day.</p><p>Sometimes, it'll turn out that there's a really simple fix for some of the things I've identified. Maybe there's some documentation I can write, once I know where it is, or maybe there's an easy change once I find the right scripts. That's not always immediately obvious when I first see a problem. When I do see an easy fix, though, I'll just go ahead and make it.</p><p>After a few weeks, though, I'll still have a bunch of weird, unresolved issues on that list. At this point I'll start talking about it with other people on the team, the team lead, and my manager.</p><p>I'll ask why things on the list are that way, and how they got to be that way. I'm trying to establish credibility as someone who's genuinely curious and empathetic, who's patient, and who respects the expertise of my coworkers. That's the reputation that's going to let me make changes later.</p><p>Generally, I'll find out that the things that problems I've noticed are around for one of a few reasons.</p><ol><li>The team hasn't noticed it</li><li>The team has gotten used to it</li><li>The problem is relatively new, and the old problem it replaced was much worse</li><li>They don't know how to fix the problem</li><li>They've tried to fix the problem before and failed</li></ol><p>On a lot of teams, when I ask some questions about things that turn out to be in the first few questions, the person I ask will just fix them immediately. Or they'll help me figure out how to fix them. If it's a technical problem, that means writing a story or a ticket together, and then we'll work on it. If it's more process or social, it means bringing the problem up at retro and talking about it with the whole team.</p><p>At this point I'm looking for one or two problems that have been bugging one of my new teammates for a while, and that have relatively simple solutions. I'm looking for something I can put on the retro board and know I won't be the only person who's bothered by that problem. Then, during the team conversation about the problem, I'll identify something that teammate suggests as an action item that we could try immediately. That way the team starts to see me as someone who helps them solve their problems.</p><p>The feeling that I want to create, the association I want people to have with me, is, "Oh, Nat joined the team and little things started to get better, almost immediately. It feels like we're starting to make some progress. And it's not like they showed up and started telling me what to do, either. They're really listening to me, they're helping me explain myself to the rest of the team."</p><p>Pretty soon, I'll start to get in to the really sticky issues. The problems the team knows about but is afraid of dealing with. The things that aren't "that bad," but that no one wants to talk about. Maybe they're missing the technical skills to deal with the problem. Maybe there's a knotty people problem at the center of it.</p><p>At this point I'm going to be talking to my manager. I'm going to bring them that list I've been working on, and I'm going to say something like, "Now that I've been on the team for a few weeks, this is what I'm seeing. We're making progress on some of it, but some of these seem like they're going to take longer. I wanted to get your thoughts before I try to do anything about them. Is there something I'm missing? Is there a particular area I'd like you to focus?"</p><p>The reaction I'm looking for from my manager, at this point, is something like, "Wow. This is really validating. I've been concerned about these things but the team doesn't seem really bothered by them, so I didn't want to push too hard. I'm glad you're bringing this up."</p><p>Then we can have a conversation about what their concerns and problems are. I can do some reflective listening to help them organize their thoughts, and I can talk about what I've seen work well, or not, in the past. They'll start to see me as someone with good judgement, and someone they can come to for help solving their harder problems.</p><p>There's a very specific reputation I want to have on a team: "Nat helps<em> <em>me</em></em> solve <em>my</em> problems. Nat get things <em>I care about</em> done." That's the reputation that's going to get me the results I want in next year's performance review. That's the reputation that's going to get me a referral a few years from now.</p><p>Before I started keeping this kind of list, I brought up problem I saw immediately, as soon as I noticed it. The reputation I got was, "Nat's always complaining about things. Nat thinks we're never doing things right." People stopped listening to me. I was personally frustrated, and professionally ineffective.</p><p>There's no faster way to totally sink my credibility, as a new team member, by making a huge fuss over something that's not a problem, or that the team doesn't see as a problem, or that there's already an effort to fix, or that there's a really simple way to fix that I just didn't see at first. There are always so many problems on a team,&nbsp;so many things that could be better, that I'm only ever going to solve a handful of them. Working on problems in the order I noticed them is rarely the most effective order. So the WTF Notebook gives me a place to park the impulse to <em>fix it now, damn it!</em> until I have more context for deciding what to work on first.</p><p>Instead, for two weeks, I just write things down.</p><!--kg-card-begin: html--><!--kg-card-end: html--><hr><h2 id="jobs">Jobs</h2><p>Periodic reminder that Code for America is usually hiring, and they pair and write tests. Until the end of this month they have a <a href="https://www.codeforamerica.org/jobs/posting/?gh_jid=3400762&amp;ref=simplermachines.com">Software Engineer</a> role up for a team that works San Francisco hours. If you're looking for a "show up, write code, go home" experience, and want to help Americans access food stamps and other safety net services, this is a team that can deliver it – especially if you have some experience with Rails or Spring.</p><p>If, on the other hand, you're interested in gnarly cloud infrastructure and software problems for the Department of Defense, check out <a href="https://rise8.us/careers?ref=simplermachines.com">Rise8</a>. If you've heard about Kessel Run, or Pivotal's work with the Air Force generally, Rise8 is where many of those folks ended up. They also practice design thinking, test-driven development, and continuous deployment, but they're teaching them to folks who have never used these practices before, and pairing with military service people. Their job listings mention experience at Pivotal Labs by name.</p><p>If you've got an active job search running and you're struggling to keep track of it all, check out <a href="https://dwf.bigpencil.net/job-search-obsidian-update/?ref=simplermachines.com">Davis Frank's guide to Job Search Journaling with Obsidian.</a></p><p><a href="https://www.simplermachines.com/jobs/">Job listings from previous issues</a></p><hr><h2 id="reading">Reading</h2><p>I've mentioned <em><a href="https://politicalscience.yale.edu/publications/seeing-state-how-certain-schemes-improve-human-condition-have-failed?ref=simplermachines.com">Seeing Like a State</a> </em>before but I reread it while we were on the road, and, and, man, seriously, if there's one book I wish everyone I talk to had read, it's this one. Nothing explains systems thinking in action better. Nothing has more useful anecdotes for illustrating how large organizations work, and why they work the way they do.</p><p>The other book I've read by James C. Scott is <a href="https://politicalscience.yale.edu/publications/against-grain-deep-history-earliest-states-1st-edition?ref=simplermachines.com"><em>Against the Grain</em>,</a> and if you're at all interested in the history of the earliest states and the initial development of human civilization, that book will absolutely blow your mind.</p><p>Ed Zitron's piece recently about <a href="https://ez.substack.com/p/how-our-need-for-attention-online?ref=simplermachines.com">How Our Need For Attention Online Drives Us Crazy</a> articulated a bunch of half-formed thoughts I've been chewing on and trying to figure out how to write about. It doesn't mention Slack explicitly, but I've seen Slack drive a lot of these same processes at work.</p>
                    
                </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta Llama 3 (1070 pts)]]></title>
            <link>https://llama.meta.com/llama3/</link>
            <guid>40077533</guid>
            <pubDate>Thu, 18 Apr 2024 15:57:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://llama.meta.com/llama3/">https://llama.meta.com/llama3/</a>, See on <a href="https://news.ycombinator.com/item?id=40077533">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Hermit is a hermetic and reproducible sandbox for running programs (104 pts)]]></title>
            <link>https://github.com/facebookexperimental/hermit</link>
            <guid>40076848</guid>
            <pubDate>Thu, 18 Apr 2024 14:46:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/facebookexperimental/hermit">https://github.com/facebookexperimental/hermit</a>, See on <a href="https://news.ycombinator.com/item?id=40076848">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Hermit: A reproducible container</h2><a id="user-content-hermit-a-reproducible-container" aria-label="Permalink: Hermit: A reproducible container" href="#hermit-a-reproducible-container"></a></p>
<p dir="auto">Hermit forces deterministic execution of arbitrary programs and acts like a
reproducible container. That is, it <em>hermetically</em> isolates the program from
sources of non-determinism such as time, thread interleavings, random number
generation, etc. Guaranteed determinism is a powerful tool and it serves as a
basis for a number of applications, including concurrency stress testing,
record/replay, reproducible builds, and automatic diagnosis of concurrency bugs,
and more.</p>
<p dir="auto">Hermit cannot isolate the guest program from sources of non-determinism such as
file system changes or external network responses. Instead, in order to provide
complete determinism, the user should provide a fixed file system base image
(e.g., with Docker) and disable external networking.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How it works</h2><a id="user-content-how-it-works" aria-label="Permalink: How it works" href="#how-it-works"></a></p>
<p dir="auto">Hermit sits between the guest process and the OS intercepting system calls made
by the guest (using <a href="https://github.com/facebookexperimental/reverie">Reverie</a>). In some cases, it can completely replace the
functionality of the kernel and suppress the original system call. In other
cases, it forwards the system call to the kernel and sanitizes the response such
that it is made deterministic.</p>
<p dir="auto">As a concrete example, lets say we have a program that reads random bytes from
<code>/dev/urandom</code>. Hermit will see that the guest opened this file (a known source
of non-determinism) and intercept subsequent reads to this file. Instead of
letting the OS fill a buffer with random bytes, Hermit uses a deterministic
pseudorandom number generator with a fixed seed to fill in the buffer. The
contents of the buffer are then guaranteed to be the same upon every execution
of the program.</p>
<p dir="auto">The most complex source of non-determinism is in the thread scheduler. The way
threads are scheduled by the kernel depends on many external factors, including
the number of physical CPUs or other threads running on the system that require
CPU time. To ensure that the threads of the guest process (and all of its child
processes) are scheduled in a repeatable way, we first make sure that all thread
executions are serialized so that there is effectively only one CPU. Then, we
deterministically pick which thread is allowed to run next. In order to only
allow a thread to run for a fixed number of instructions, we use the CPU's
Performance Monitoring Unit (PMU) to stop execution after a fixed number of
retired conditional branches (RCBs).</p>
<p dir="auto">Read below about how to build Hermit, and you can get an idea of what it does
from running examples in the <a href="https://github.com/facebookexperimental/hermit/blob/main/examples">./examples</a> folder.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building and running Hermit</h2><a id="user-content-building-and-running-hermit" aria-label="Permalink: Building and running Hermit" href="#building-and-running-hermit"></a></p>
<p dir="auto">Hermit is built with the standard Rust cargo tool.</p>

<p dir="auto">This builds the whole cargo workspace. The actual binary is located in target
directory (<code>target/debug/hermit</code>).</p>
<p dir="auto">Then, once you've built Hermit, all you need to run your program
deterministically is:</p>

<p dir="auto">After that you can try running it in a concurrency stress testing (chaos) mode,
or varying other parameters of the configuration such as the speed at which
virtual time passes inside the container, or the random number generation seed:</p>
<div dir="auto" data-snippet-clipboard-copy-content="hermit run --chaos --sched-seed=3 <prog>"><pre>hermit run --chaos --sched-seed=3 <span>&lt;</span>prog<span>&gt;</span></pre></div>
<p dir="auto">You can use hermit as a replay-debugger as well, either recording a
non-deterministic execution (real time, real randomness, etc), or repeatedly
running a controlled, deterministic one (virtual time, pseudo-randomness, etc).</p>
<div dir="auto" data-snippet-clipboard-copy-content="hermit record start <prog>
hermit replay"><pre>hermit record start <span>&lt;</span>prog<span>&gt;</span>
hermit replay</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Example programs</h2><a id="user-content-example-programs" aria-label="Permalink: Example programs" href="#example-programs"></a></p>
<p dir="auto">See the <a href="https://github.com/facebookexperimental/hermit/blob/main/examples/README.md">the examples folder</a> for example programs and
instructions on how to run them.  These showcase different sources of
nondeterminism, and how hermit eliminates or controls them.</p>
<p dir="auto">In order to explore more advanced examples, you can look at some of
the integration tests built from <a href="https://github.com/facebookexperimental/hermit/blob/main/tests">./tests/</a> or <a href="https://github.com/facebookexperimental/hermit/blob/main/flaky-tests">./flaky-tests/</a>.
For example, using the commands below you can run a racey example
multiple times to see its nondeterminism.  Then run it under hermit to
watch that nondeterminism disappear.  Then run it under hermit <code>--chaos</code>
to bring that nondeterminism back, but in a controlled way that can be
reproduced based on the input seed.</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo build
for ((i=0; i<20; i++)); do ./target/debug/hello_race; done

for ((i=0; i<20; i++)); do hermit run ./target/debug/hello_race; done

for ((i=0; i<20; i++)); do
  hermit run --chaos --seed-from=SystemRandom ./target/debug/hello_race;
done"><pre>cargo build
<span>for</span> <span><span>((</span>i<span>=</span><span>0</span>; i<span>&lt;</span><span>20</span>; i<span>++</span><span>))</span></span><span>;</span> <span>do</span> ./target/debug/hello_race<span>;</span> <span>done</span>

<span>for</span> <span><span>((</span>i<span>=</span><span>0</span>; i<span>&lt;</span><span>20</span>; i<span>++</span><span>))</span></span><span>;</span> <span>do</span> hermit run ./target/debug/hello_race<span>;</span> <span>done</span>

<span>for</span> <span><span>((</span>i<span>=</span><span>0</span>; i<span>&lt;</span><span>20</span>; i<span>++</span><span>))</span></span><span>;</span> <span>do</span>
  hermit run --chaos --seed-from=SystemRandom ./target/debug/hello_race<span>;</span>
<span>done</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">The state of CI and testing</h2><a id="user-content-the-state-of-ci-and-testing" aria-label="Permalink: The state of CI and testing" href="#the-state-of-ci-and-testing"></a></p>
<p dir="auto">At Meta, this repository is built using buck.  We have over 700 integration
tests that run under this setup. But as of this initial release (2022-11-21), we
have not ported these tests to an external build system yet.</p>
<p dir="auto">A few unit tests run under <code>cargo test</code>, but the integration tests are more
complicated because they combine various run modes with each of the test
binaries (which are built from <code>tests/</code>, <code>flaky-tests/</code>, and the rr test suite
too).</p>
<p dir="auto">We plan to get the internal Buck configuration files building externally with
buck or bazel.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Applications</h2><a id="user-content-applications" aria-label="Permalink: Applications" href="#applications"></a></p>
<p dir="auto">Hermit translates normal, non-deterministic Linux behavior, into deterministic,
repeatable behavior. This can be used for various applications, including:
record/replay debugging, simple reproducibility, "chaos mode" to expose
concurrency bugs in a controlled and repeatable way. Generally, Hermit makes
implicit inputs into explicit ones, and so enables searching over possible
executions by explicitly varying these inputs and study the changes in outcomes.
This can be used for either searching for bugs or trying to narrow down their
causes.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Diagnosing concurrency bugs</h2><a id="user-content-diagnosing-concurrency-bugs" aria-label="Permalink: Diagnosing concurrency bugs" href="#diagnosing-concurrency-bugs"></a></p>
<p dir="auto">One experimental application that Hermit has built-in support for is diagnosing
concurrency bugs, in terms of identifying the stack traces of racing critical
operations which, if their order is flipped in the schedule, cause the program
to crash (also called an "order violation" bug). Hermit can detect these even if
the racing instructions are in different processes and written in different
programming languages.</p>
<p dir="auto">You can kick off analyze with any program invocation, and tell it to search for
failing (and passing) executions, and then diagnose the difference between them.</p>
<div data-snippet-clipboard-copy-content="hermit analyze --search -- <run_args> <prog>"><pre><code>hermit analyze --search -- &lt;run_args&gt; &lt;prog&gt;
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Hermit is licensed under a BSD-3 clause license, included in the <code>LICENSE</code> file
in this directory.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Support</h2><a id="user-content-support" aria-label="Permalink: Support" href="#support"></a></p>
<p dir="auto">Hermit currently supports x86_64 Linux. Aarch64 support is a
work in progress.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Halo 2 in HD: Pushing the Original Xbox to the Limit (278 pts)]]></title>
            <link>https://icode4.coffee/?p=738</link>
            <guid>40076345</guid>
            <pubDate>Thu, 18 Apr 2024 14:01:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://icode4.coffee/?p=738">https://icode4.coffee/?p=738</a>, See on <a href="https://news.ycombinator.com/item?id=40076345">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
									
									
<p>This blog post goes over all of the work I’ve done to add HD resolution support to the Original Xbox version of Halo 2. From patching the game to modifying the hardware of the Xbox console to writing custom tools for performance benchmarking, my goal with this project was to push the limits of both and see how far I could go. I’ve tried to keep this blog post as short as I could and only include the most technically interesting parts but even then it ended up quite long.</p>



<h2>Prelude</h2>



<p>A long time friend who goes by the handle “doom” has spent the past few years reverse engineering and researching the hardware and software on the original Xbox. His end goal was to learn more about PC hardware and see how far he could push the console. Some of his work includes swapping out the stock Pentium 3 CPU running at 733Mhz for a variant of the Pentium 3 CPU running at 1.4Ghz using a custom made CPU interposer board, and even being able to overclock it upwards of ~2Ghz. </p>



<div><figure><a href="https://icode4.coffee/wp-content/uploads/xbox_upgraded_cpu.png" target="_blank" rel="noopener"><img loading="lazy" width="960" height="720" src="https://icode4.coffee/wp-content/uploads/xbox_upgraded_cpu.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/xbox_upgraded_cpu.png 960w, https://icode4.coffee/wp-content/uploads/xbox_upgraded_cpu-300x225.png 300w, https://icode4.coffee/wp-content/uploads/xbox_upgraded_cpu-768x576.png 768w" sizes="(max-width: 960px) 100vw, 960px"></a><figcaption>Pentium 3 Tualatin on Doom’s custom interposer</figcaption></figure></div>



<p>Doom also wrote custom patches for the Xbox kernel in order to on-the-fly patch timing calculations for games so they ran properly with the faster CPU. Combined with a few other hardware upgrades such as additional RAM and an SSD, doom started to refer to these as “god boxes”. These god boxes were also running a custom kernel (or BIOS image) that doom made to support all of the hardware modifications and push the hardware and software as far as they could go. One of his demos for his work was showing the opening sequence in Half-Life 2 which is notorious for abysmally slow loading times and poor performance on the Xbox, running at a solid 30 FPS and loading in a matter of seconds. But there were still additional benefits to be had. Doom wanted someone to create a proper HD resolution patch for a popular game and really utilize the hardware upgrades he performed. </p>



<p>One night while talking over Discord doom asked if I would be interested in developing an HD patch for Halo 2 and in exchange he would provide me with a god box to develop it on. Halo 2 has a max supported video resolution of 480p and patching in support for 720p (and possibly 1080i) would get a lot of attention to demonstrate the benefits of all this work. We both knew that many of the community “HD” or “720p” game patches were not actually functioning correctly and that patching in HD resolution support for a game was more work than just searching for 640/480 in a disassembler and changing the resolution. These patches require a deep understanding of 3D graphics, DirectX APIs, and a lot of specific knowledge about the game and Xbox console. Having spent years reverse engineering the Xbox and Halo 2’s game engine I had the perfect background to take on the task. As doom would put it “there’s nobody more qualified than you to do it for halo 2 so that’s why I asked”. While it piqued my interest (and I was pretty jealous of these god boxes and all the experience he’d gotten developing them), I made a request/requirement before I would even entertain the idea. </p>



<p>The upgraded CPU has more than double the processing power compared to the stock CPU, however, the GPU was going to take on most of the increased processing load once the video resolution was increased. After all, each additional pixel in the output image would result in more pixel shader calculations which meant more work the GPU would have to do. If he could manage to overclock the GPU I would do it, but at stock clock speeds it wasn’t worth the time it would take to develop this patch just to have it fall over on the GPU. He said he would look into it, and after a few weeks time he came back and said it was done. He managed to overclock the GPU by ~15%, and said he had the “GENESIS-3” console ready for me (a nickname for the 3rd iteration of the “god box” upgrades he’d been working on).</p>



<h2>Part 1: Rendering in HD</h2>



<p>Having spent the past few years reverse engineering and re-implementing the Halo 2 rendering engine I already had a mental list of things I’d need to change to support higher video resolutions. The first thing that needed to be changed was the size of the D3D front and back buffers. The setup for the D3D device has 3 functions that need to be modified in order to use the proper resolution for the current video mode. The first is _rasterizer_detect_video_mode which checks the video mode and sets some global variables for widescreen and progressive video modes. Next is _rasterizer_init_screen_bounds which sets up the screen dimensions used for creating the D3D device, view frustum, and a number of other things. Lastly is rasterizer_device_initialize which is responsible for setting up the D3D device. Below is a shortened version of these 3 functions with the lines of interest highlighted. All of the code shown in this post has been reverse engineered from assembly back into C for ease of understanding.</p>



<div id="urvanov-syntax-highlighter-662143868a2df916053336" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p><p>28</p><p>29</p><p>30</p><p>31</p><p>32</p><p>33</p><p>34</p><p>35</p><p>36</p><p>37</p><p>38</p><p>39</p><p>40</p><p>41</p><p>42</p><p>43</p><p>44</p><p>45</p><p>46</p><p>47</p><p>48</p><p>49</p><p>50</p><p>51</p><p>52</p><p>53</p><p>54</p><p>55</p><p>56</p><p>57</p><p>58</p><p>59</p><p>60</p><p>61</p><p>62</p><p>63</p><p>64</p><p>65</p></div>
				</td>
						<td><div><p><span>void</span><span> </span><span>_rasterizer_detect_video_mode</span><span>(</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>DWORD </span><span>videoStandard</span><span> </span><span>=</span><span> </span><span>XGetVideoStandard</span><span>(</span><span>)</span><span>;</span></p><p><span>	</span><span>DWORD </span><span>videoFlags</span><span> </span><span>=</span><span> </span><span>XGetVideoFlags</span><span>(</span><span>)</span><span>;</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>videoStandard</span><span> </span><span>==</span><span> </span><span>XC_VIDEO_STANDARD_PAL_I</span><span>)</span></p><p><span>		</span><span>g_refresh_rate_hz</span><span> </span><span>=</span><span> </span><span>(</span><span>videoFlags</span><span> </span><span>&amp;</span><span> </span><span>XC_VIDEO_FLAGS_PAL_60Hz</span><span>)</span><span> </span><span>!=</span><span> </span><span>0</span><span> </span><span>?</span><span> </span><span>60</span><span> </span><span>:</span><span> </span><span>50</span><span>;</span></p><p><span>	</span><span>g_letterbox_enabled</span><span> </span><span>=</span><span> </span><span>(</span><span>videoFlags</span><span> </span><span>&amp;</span><span> </span><span>XC_VIDEO_FLAGS_LETTERBOX</span><span>)</span><span> </span><span>!=</span><span> </span><span>0</span><span>;</span></p><p><span>	</span><span>g_widescreen_enabled</span><span> </span><span>=</span><span> </span><span>(</span><span>videoFlags</span><span> </span><span>&amp;</span><span> </span><span>XC_VIDEO_FLAGS_WIDESCREEN</span><span>)</span><span> </span><span>!=</span><span> </span><span>0</span><span>;</span></p><p><span>	</span><span>g_progressive_scan_enabled</span><span> </span><span>=</span><span> </span><span>(</span><span>videoFlags</span><span> </span><span>&amp;</span><span> </span><span>XC_VIDEO_FLAGS_HDTV_480p</span><span>)</span><span> </span><span>!=</span><span> </span><span>0</span><span>;</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>}</span></p><p><span>void</span><span> </span><span>_rasterizer_init_screen_bounds</span><span>(</span><span>int</span><span> </span><span>x_off</span><span>,</span><span> </span><span>int</span><span> </span><span>y_off</span><span>,</span><span> </span><span>float</span><span> </span><span>scale</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>float</span><span> </span><span>width</span><span> </span><span>=</span><span> </span><span>640.0f</span><span> </span><span>*</span><span> </span><span>scale</span><span>;</span></p><p><span>	</span><span>float</span><span> </span><span>height</span><span> </span><span>=</span><span> </span><span>480.0f</span><span> </span><span>*</span><span> </span><span>scale</span><span>;</span></p><p><span>	</span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>x0</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></p><p><span>	</span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>y0</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></p><p><span>	</span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>x1</span><span> </span><span>=</span><span> </span><span>(</span><span>int</span><span>)</span><span>width</span><span>;</span></p><p><span>	</span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>y1</span><span> </span><span>=</span><span> </span><span>(</span><span>int</span><span>)</span><span>height</span><span>;</span></p><p><span>	</span><span>rasterizer_globals</span><span>.</span><span>frame_bounds</span><span>.</span><span>x0</span><span> </span><span>=</span><span> </span><span>x_off</span><span>;</span></p><p><span>	</span><span>rasterizer_globals</span><span>.</span><span>frame_bounds</span><span>.</span><span>y0</span><span> </span><span>=</span><span> </span><span>y_off</span><span>;</span></p><p><span>	</span><span>rasterizer_globals</span><span>.</span><span>frame_bounds</span><span>.</span><span>x1</span><span> </span><span>=</span><span> </span><span>(</span><span>int</span><span>)</span><span>width</span><span> </span><span>-</span><span> </span><span>x_off</span><span>;</span></p><p><span>	</span><span>rasterizer_globals</span><span>.</span><span>frame_bounds</span><span>.</span><span>y1</span><span> </span><span>=</span><span> </span><span>(</span><span>int</span><span>)</span><span>height</span><span> </span><span>-</span><span> </span><span>y_off</span><span>;</span></p><p><span>}</span></p><p><span>bool</span><span> </span><span>rasterizer_device_initialize</span><span>(</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>	</span><span>D3DPRESENT_PARAMETERS </span><span>PresentParams</span><span> </span><span>=</span><span> </span><span>{</span><span>0</span><span>}</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>BackBufferWidth</span><span> </span><span>=</span><span> </span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>x1</span><span> </span><span>-</span><span> </span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>x0</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>BackBufferHeight</span><span> </span><span>=</span><span> </span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>y1</span><span> </span><span>-</span><span> </span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>y1</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>BackBufferFormat</span><span> </span><span>=</span><span> </span><span>D3DFMT_A8R8G8B8</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>EnableAutoDepthStencil</span><span> </span><span>=</span><span> </span><span>TRUE</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>AutoDepthStencilFormat</span><span> </span><span>=</span><span> </span><span>D3DFMT_D24S8</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>Flags</span><span> </span><span>=</span><span> </span><span>D3DPRESENTFLAG_LOCKABLE_BACKBUFFER</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>FullScreen_RefreshRateInHz</span><span> </span><span>=</span><span> </span><span>g_refresh_rate_hz</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>FullScreen_PresentationInterval</span><span> </span><span>=</span><span> </span><span>D3DPRESENT_INTERVAL_IMMEDIATE</span><span>;</span></p><p><span>	</span><span>switch</span><span> </span><span>(</span><span>g_presentation_interval</span><span>)</span></p><p><span>	</span><span>{</span></p><p><span>		</span><span>case</span><span> </span><span>0</span><span>:</span></p><p><span>			</span><span>PresentParams</span><span>.</span><span>SwapEffect</span><span> </span><span>=</span><span> </span><span>D3DSWAPEFFECT_FLIP</span><span>;</span></p><p><span>			</span><span>PresentParams</span><span>.</span><span>FullScreen_PresentationInterval</span><span> </span><span>=</span><span> </span><span>D3DPRESENT_INTERVAL_IMMEDIATE</span><span>;</span></p><p><span>			</span><span>break</span><span>;</span></p><p><span>		</span><span>case</span><span> </span><span>1</span><span>:</span></p><p><span>			</span><span>PresentParams</span><span>.</span><span>SwapEffect</span><span> </span><span>=</span><span> </span><span>D3DSWAPEFFECT_DISCARD</span><span>;</span></p><p><span>			</span><span>PresentParams</span><span>.</span><span>FullScreen_PresentationInterval</span><span> </span><span>|=</span><span> </span><span>g_present_immediately</span><span> </span><span>!=</span><span> </span><span>0</span><span> </span><span>?</span><span> </span><span>D3DPRESENT_INTERVAL_ONE</span><span> </span><span>:</span><span> </span><span>0</span><span>;</span></p><p><span>			</span><span>break</span><span>;</span></p><p><span>		</span><span>case</span><span> </span><span>2</span><span>:</span></p><p><span>			</span><span>PresentParams</span><span>.</span><span>SwapEffect</span><span> </span><span>=</span><span> </span><span>D3DSWAPEFFECT_DISCARD</span><span>;</span></p><p><span>			</span><span>PresentParams</span><span>.</span><span>FullScreen_PresentationInterval</span><span> </span><span>|=</span><span> </span><span>g_present_immediately</span><span> </span><span>!=</span><span> </span><span>0</span><span> </span><span>?</span><span> </span><span>D3DPRESENT_INTERVAL_TWO</span><span> </span><span>:</span><span> </span><span>0</span><span>;</span></p><p><span>			</span><span>break</span><span>;</span></p><p><span>	</span><span>}</span></p><p><span>	</span><span>g_pDirect3D</span><span>-&gt;</span><span>CreateDevice</span><span>(</span><span>0</span><span>,</span><span> </span><span>D3DDEVTYPE_HAL</span><span>,</span><span> </span><span>NULL</span><span>,</span><span> </span><span>D3DCREATE_HARDWARE_VERTEXPROCESSING</span><span>,</span><span> </span><span>&amp;</span><span>PresentParams</span><span>,</span><span> </span><span>&amp;</span><span>g_pD3DDevice</span><span>)</span><span>;</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>}</span></p></div></td>
					</tr>
				</tbody></table>
			</div>



<h4>Halo 2 already supports 480p, or does it…</h4>



<p>If you’ve ever looked at the back of the game case for Halo 2 you might have seen it supports 480p. However, looking at line 42 above, the D3DPRESENTFLAG_PROGRESSIVE flag is not being set on the present parameters. And, if we look at the call site for the _rasterizer_init_screen_bounds function we see this:</p>



<div><figure><a href="https://icode4.coffee/wp-content/uploads/ida_init_screen_bounds.png" target="_blank" rel="noopener"><img loading="lazy" width="605" height="471" src="https://icode4.coffee/wp-content/uploads/ida_init_screen_bounds.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/ida_init_screen_bounds.png 605w, https://icode4.coffee/wp-content/uploads/ida_init_screen_bounds-300x234.png 300w" sizes="(max-width: 605px) 100vw, 605px"></a><figcaption>Call site for _rasterizer_init_screen_bounds</figcaption></figure></div>



<p>The scale parameter is always set to 1.0f, which means the screen_bounds are always set to 640×480 regardless of what the video mode is set to on the console. On the Original Xbox 480p is considered to be 720×480, which means that <strong>Halo 2 does not render in 480p natively</strong> regardless of what the video settings are set to. If you enable 480p mode on the console you’ll get a 480p signal out but that’s because after the game is done drawing to the 640×480 back buffer it’ll get up-scaled to 720×480 by the GPU before being fed to the video encoder. I often get comments saying “that’s not not a 16:9 resolution” or “that’s not real 480p”, but “480p” <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/480p#Resolutions" target="_blank">encapsulates a range of resolutions and aspect ratios</a> and 720×480 is the resolution the Xbox considers to be 480p (so take it up with Microsoft, not me…).</p>



<p>If you’ve ever played Halo 2 in 480p mode with wide screen enabled you may have noticed that things look a little weird. That’s because when wide screen mode is enabled the game will use an anamorphic camera with an aspect ratio of 1.33:1. That means it renders 1.3x the width into the same 640×480 surface as it would when wide screen mode is disabled. Here is a comparison showing the effect anamorphic scaling has on the Zanzibar wheel:</p>







<p>I’m not entirely sure why it does this and my only guess is if you set your TV to stretch mode it would “cancel out” the horizontal “squish” introduced by the anamorphic scaling and look somewhat normal. However, I personally hate it and wanted the cleanest image I could get out of the console so I added an option to disable the anamorphic scaling entirely.</p>



<h4>Back to the back buffer…</h4>



<p>To create the D3D front/back buffers with the right dimensions we’ll need to change g_progressive_scan_enabled to be set when 720p is enabled, set the screen_bounds and frame_bounds variables based on the proper video resolution for the video mode set, and finally set some additional flags on the D3D present parameters depending on if the video mode is progressive or interlaced (1080i mode). The pseudo code for the modifications is shown below with the changed lines highlighted. I ignored the scale variable in _rasterizer_init_screen_bounds because it’s only ever set to 1.0 anyway.</p>



<div id="urvanov-syntax-highlighter-662143868a2ec296228442" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p><p>28</p><p>29</p><p>30</p><p>31</p><p>32</p><p>33</p><p>34</p><p>35</p><p>36</p><p>37</p><p>38</p><p>39</p><p>40</p><p>41</p><p>42</p><p>43</p><p>44</p><p>45</p><p>46</p><p>47</p><p>48</p><p>49</p><p>50</p><p>51</p><p>52</p><p>53</p><p>54</p><p>55</p><p>56</p><p>57</p><p>58</p><p>59</p><p>60</p><p>61</p><p>62</p><p>63</p><p>64</p><p>65</p><p>66</p><p>67</p><p>68</p><p>69</p><p>70</p><p>71</p><p>72</p><p>73</p><p>74</p><p>75</p><p>76</p><p>77</p><p>78</p><p>79</p><p>80</p><p>81</p><p>82</p><p>83</p><p>84</p></div>
				</td>
						<td><div><p><span>void</span><span> </span><span>_rasterizer_detect_video_mode</span><span>(</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>DWORD </span><span>videoStandard</span><span> </span><span>=</span><span> </span><span>XGetVideoStandard</span><span>(</span><span>)</span><span>;</span></p><p><span>	</span><span>DWORD </span><span>videoFlags</span><span> </span><span>=</span><span> </span><span>XGetVideoFlags</span><span>(</span><span>)</span><span>;</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>videoStandard</span><span> </span><span>==</span><span> </span><span>XC_VIDEO_STANDARD_PAL_I</span><span>)</span></p><p><span>		</span><span>g_refresh_rate_hz</span><span> </span><span>=</span><span> </span><span>(</span><span>videoFlags</span><span> </span><span>&amp;</span><span> </span><span>XC_VIDEO_FLAGS_PAL_60Hz</span><span>)</span><span> </span><span>!=</span><span> </span><span>0</span><span> </span><span>?</span><span> </span><span>60</span><span> </span><span>:</span><span> </span><span>50</span><span>;</span></p><p><span>	</span><span>g_letterbox_enabled</span><span> </span><span>=</span><span> </span><span>(</span><span>videoFlags</span><span> </span><span>&amp;</span><span> </span><span>XC_VIDEO_FLAGS_LETTERBOX</span><span>)</span><span> </span><span>!=</span><span> </span><span>0</span><span>;</span></p><p><span>	</span><span>g_widescreen_enabled</span><span> </span><span>=</span><span> </span><span>(</span><span>videoFlags</span><span> </span><span>&amp;</span><span> </span><span>XC_VIDEO_FLAGS_WIDESCREEN</span><span>)</span><span> </span><span>!=</span><span> </span><span>0</span><span>;</span></p><p><span>	</span><span>g_progressive_scan_enabled</span><span> </span><span>=</span><span> </span><span>(</span><span>videoFlags</span><span> </span><span>&amp;</span><span> </span><span>(</span><span>XC_VIDEO_FLAGS_HDTV_480p</span><span> </span><span>|</span><span> </span><span>XC_VIDEO_FLAGS_HDTV_720p</span><span>)</span><span>)</span><span> </span><span>!=</span><span> </span><span>0</span><span>;</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>}</span></p><p><span>void</span><span> </span><span>_rasterizer_init_screen_bounds</span><span>(</span><span>int</span><span> </span><span>x_off</span><span>,</span><span> </span><span>int</span><span> </span><span>y_off</span><span>,</span><span> </span><span>float</span><span> </span><span>scale</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>// Set default resolution to 640x480.</span></p><p><span>	</span><span>float</span><span> </span><span>width</span><span> </span><span>=</span><span> </span><span>640.0f</span><span>;</span></p><p><span>	</span><span>float</span><span> </span><span>height</span><span> </span><span>=</span><span> </span><span>480.0f</span><span>;</span></p><p><span>	</span><span>// Adjust resolution based on current video mode set.</span></p><p><span>	</span><span>DWORD </span><span>videoFlags</span><span> </span><span>=</span><span> </span><span>XGetVideoFlags</span><span>(</span><span>)</span><span>;</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>(</span><span>videoFlags</span><span> </span><span>&amp;</span><span> </span><span>XC_VIDEO_FLAGS_HDTV_1080i</span><span>)</span><span> </span><span>!=</span><span> </span><span>0</span><span>)</span></p><p><span>	</span><span>{</span></p><p><span>		</span><span>width</span><span> </span><span>=</span><span> </span><span>1920</span><span>;</span></p><p><span>		</span><span>height</span><span> </span><span>=</span><span> </span><span>1080</span><span>;</span></p><p><span>	</span><span>}</span></p><p><span>	</span><span>else</span><span> </span><span>if</span><span> </span><span>(</span><span>(</span><span>videoFlags</span><span> </span><span>&amp;</span><span> </span><span>XC_VIDEO_FLAGS_HDTV_720p</span><span>)</span><span> </span><span>!=</span><span> </span><span>0</span><span>)</span></p><p><span>	</span><span>{</span></p><p><span>		</span><span>width</span><span> </span><span>=</span><span> </span><span>1280</span><span>;</span></p><p><span>		</span><span>height</span><span> </span><span>=</span><span> </span><span>720</span><span>;</span></p><p><span>	</span><span>}</span></p><p><span>	</span><span>else</span><span> </span><span>if</span><span> </span><span>(</span><span>(</span><span>videoFlags</span><span> </span><span>&amp;</span><span> </span><span>XC_VIDEO_FLAGS_HDTV_480p</span><span>)</span><span> </span><span>!=</span><span> </span><span>0</span><span>)</span></p><p><span>	</span><span>{</span></p><p><span>		</span><span>width</span><span> </span><span>=</span><span> </span><span>720</span><span>;</span></p><p><span>	</span><span>}</span></p><p><span>	</span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>x0</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></p><p><span>	</span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>y0</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></p><p><span>	</span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>x1</span><span> </span><span>=</span><span> </span><span>(</span><span>int</span><span>)</span><span>width</span><span>;</span></p><p><span>	</span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>y1</span><span> </span><span>=</span><span> </span><span>(</span><span>int</span><span>)</span><span>height</span><span>;</span></p><p><span>	</span><span>rasterizer_globals</span><span>.</span><span>frame_bounds</span><span>.</span><span>x0</span><span> </span><span>=</span><span> </span><span>x_off</span><span>;</span></p><p><span>	</span><span>rasterizer_globals</span><span>.</span><span>frame_bounds</span><span>.</span><span>y0</span><span> </span><span>=</span><span> </span><span>y_off</span><span>;</span></p><p><span>	</span><span>rasterizer_globals</span><span>.</span><span>frame_bounds</span><span>.</span><span>x1</span><span> </span><span>=</span><span> </span><span>(</span><span>int</span><span>)</span><span>width</span><span> </span><span>-</span><span> </span><span>x_off</span><span>;</span></p><p><span>	</span><span>rasterizer_globals</span><span>.</span><span>frame_bounds</span><span>.</span><span>y1</span><span> </span><span>=</span><span> </span><span>(</span><span>int</span><span>)</span><span>height</span><span> </span><span>-</span><span> </span><span>y_off</span><span>;</span></p><p><span>}</span></p><p><span>bool</span><span> </span><span>rasterizer_device_initialize</span><span>(</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>	</span><span>D3DPRESENT_PARAMETERS </span><span>PresentParams</span><span> </span><span>=</span><span> </span><span>{</span><span>0</span><span>}</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>BackBufferWidth</span><span> </span><span>=</span><span> </span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>x1</span><span> </span><span>-</span><span> </span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>x0</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>BackBufferHeight</span><span> </span><span>=</span><span> </span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>y1</span><span> </span><span>-</span><span> </span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>y1</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>BackBufferFormat</span><span> </span><span>=</span><span> </span><span>D3DFMT_A8R8G8B8</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>EnableAutoDepthStencil</span><span> </span><span>=</span><span> </span><span>TRUE</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>AutoDepthStencilFormat</span><span> </span><span>=</span><span> </span><span>D3DFMT_D24S8</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>Flags</span><span> </span><span>=</span><span> </span><span>D3DPRESENTFLAG_LOCKABLE_BACKBUFFER</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>FullScreen_RefreshRateInHz</span><span> </span><span>=</span><span> </span><span>g_refresh_rate_hz</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>FullScreen_PresentationInterval</span><span> </span><span>=</span><span> </span><span>D3DPRESENT_INTERVAL_IMMEDIATE</span><span>;</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>	</span><span>// Check if wide screen mode is enabled.</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>g_widescreen_enabled</span><span> </span><span>!=</span><span> </span><span>0</span><span>)</span></p><p><span>		</span><span>PresentParams</span><span>.</span><span>Flags</span><span> </span><span>|=</span><span> </span><span>D3DPRESENTFLAG_WIDESCREEN</span><span>;</span></p><p><span>	</span><span>// Check if the video mode supports progressive scan.</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>g_progressive_scan_enabled</span><span> </span><span>!=</span><span> </span><span>0</span><span>)</span></p><p><span>		</span><span>PresentParams</span><span>.</span><span>Flags</span><span> </span><span>|=</span><span> </span><span>D3DPRESENTFLAG_PROGRESSIVE</span><span>;</span></p><p><span>	</span><span>// Check the resolution width to see if 1080i is enabled.</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>x1</span><span> </span><span>==</span><span> </span><span>1920</span><span>)</span></p><p><span>	</span><span>{</span></p><p><span>		</span><span>PresentParams</span><span>.</span><span>Flags</span><span> </span><span>&amp;=</span><span> </span><span>~</span><span>D3DPRESENTFLAG_PROGRESSIVE</span><span>;</span></p><p><span>		</span><span>PresentParams</span><span>.</span><span>Flags</span><span> </span><span>|=</span><span> </span><span>D3DPRESENTFLAG_INTERLACED</span><span>;</span></p><p><span>	</span><span>}</span></p><p><span>	</span><span>g_pDirect3D</span><span>-&gt;</span><span>CreateDevice</span><span>(</span><span>0</span><span>,</span><span> </span><span>D3DDEVTYPE_HAL</span><span>,</span><span> </span><span>NULL</span><span>,</span><span> </span><span>D3DCREATE_HARDWARE_VERTEXPROCESSING</span><span>,</span><span> </span><span>&amp;</span><span>PresentParams</span><span>,</span><span> </span><span>&amp;</span><span>g_pD3DDevice</span><span>)</span><span>;</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>}</span></p></div></td>
					</tr>
				</tbody></table>
			</div>



<p>Booting up the game with these changes gives some less than pleasing results. Looking at the main menu the first thing we can see is the blue filter is now gone, and there’s some repeating line pattern strewn across the screen. Looking a bit closer and we can see part of the water geometry is also cut off, suspiciously at where the old 640 width would be compared to the new width of 720.</p>



<div><figure><a href="https://icode4.coffee/wp-content/uploads/main_menu_issues.png" target="_blank" rel="noopener"><img loading="lazy" width="720" height="480" src="https://icode4.coffee/wp-content/uploads/main_menu_issues.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/main_menu_issues.png 720w, https://icode4.coffee/wp-content/uploads/main_menu_issues-300x200.png 300w" sizes="(max-width: 720px) 100vw, 720px"></a><figcaption>Rendering issues in the main menu</figcaption></figure></div>



<h2>Making efficient use of D3D memory</h2>



<p>The Xbox uses a unified memory architecture meaning the CPU and GPU share the same RAM. Unlike a PC there’s no concept of creating a D3D allocation in VRAM and having the GPU manage it. On Xbox the CPU can create an allocation for textures, render targets, vertex buffers, etc, and pass the allocation address directly to the GPU. This gives developers the ability to allocate one buffer and have multiple resource “views” that utilize the memory. Consider the following code which shows how to create a render target letting D3D do all the work and how to create a render target by hand:</p>



<div id="urvanov-syntax-highlighter-662143868a2f2073411409" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>// How to create a render target with D3D:</span></p><p><span>IDirect3DSurface8</span><span>*</span><span> </span><span>pRenderTarget</span><span> </span><span>=</span><span> </span><span>NULL</span><span>;</span></p><p><span>g_pD3DDevice</span><span>-&gt;</span><span>CreateRenderTarget</span><span>(</span><span>/* width */</span><span> </span><span>1024</span><span>,</span><span> </span><span>/* height */</span><span> </span><span>1024</span><span>,</span><span> </span><span>/* format */</span><span> </span><span>D3DFMT_A8R8G8B8</span><span>,</span><span> </span><span>NULL</span><span>,</span><span> </span><span>FALSE</span><span>,</span><span> </span><span>&amp;</span><span>pRenderTarget</span><span>)</span><span>;</span></p><p><span>// How to create a render target by hand:</span></p><p><span>// Allocate and initialize the texture header.</span></p><p><span>IDirect3DSurface8</span><span>*</span><span> </span><span>pRenderTarget</span><span> </span><span>=</span><span> </span><span>(</span><span>IDirect3DSurface8</span><span>*</span><span>)</span><span>malloc</span><span>(</span><span>sizeof</span><span>(</span><span>IDirect3DSurface8</span><span>)</span><span>)</span><span>;</span></p><p><span>DWORD </span><span>textureSize</span><span> </span><span>=</span><span> </span><span>XGSetTextureHeader</span><span>(</span><span>/* width */</span><span> </span><span>1024</span><span>,</span><span> </span><span>/* height */</span><span> </span><span>1024</span><span>,</span><span> </span><span>/* levels */</span><span> </span><span>0</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span><span>/* format */</span><span> </span><span>D3DFMT_A8R8G8B8</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span><span>pRenderTarget</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span><span>0</span><span>)</span><span>;</span></p><p><span>// Allocate memory for the pixel buffer.</span></p><p><span>void</span><span>*</span><span> </span><span>pSurfaceBuffer</span><span> </span><span>=</span><span> </span><span>D3D_AllocContiguousMemory</span><span>(</span><span>/* size */</span><span> </span><span>textureSize</span><span>,</span><span> </span><span>/* alignment */</span><span> </span><span>D3DSURFACE_ALIGNMENT</span><span>)</span><span>;</span></p><p><span>pRenderTarget</span><span>-&gt;</span><span>Register</span><span>(</span><span>pSurfaceBuffer</span><span>)</span><span>;</span></p></div></td>
					</tr>
				</tbody></table>
			</div>



<p>While the latter looks more messy it provides greater control to the developer and is something Halo 2 makes great use of to conserve memory for all the render targets it uses. In total Halo 2 has approximately 25 different render targets it uses but there’s only 4-5 unique buffers allocated for them which saves a lot of memory. So what does this have to do with the issues we saw in the main menu? Well if Halo 2 is creating render targets by hand it’ll need to encode the width and height of the surface into the header of the render target structure. If it’s hard coded to use 640×480 resolution it would cause issues that could result in cut off images or repeating line patterns as the pitch of the surface would not match the pitch of the back buffer. Essentially, there’s two different “views” for the same memory but the views see the memory as being of different widths which results in misplaced pixels when spanning each scan line. </p>



<p>Looking around the D3D/raster initialization code I found a function I called rasterizer_primary_targets_initialize that does exactly this. It takes the back, front, and depth buffers created by D3D and creates additional render targets and texture views from them, using hard coded dimensions of 640×480. Here is the C representation of the disassembly:</p>



<div id="urvanov-syntax-highlighter-662143868a2f5014285151" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p><p>28</p><p>29</p><p>30</p><p>31</p><p>32</p><p>33</p><p>34</p><p>35</p></div>
				</td>
						<td><div><p><span>bool</span><span> </span><span>rasterizer_primary_targets_initialize</span><span>(</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>// Get the back buffer, front buffer, and depth buffer surfaces.</span></p><p><span>	</span><span>global_d3d_device</span><span>-&gt;</span><span>GetBackBuffer</span><span>(</span><span>0</span><span>,</span><span> </span><span>D3DBACKBUFFER_TYPE_MONO</span><span>,</span><span> </span><span>&amp;</span><span>global_d3d_surface_render_primary</span><span>[</span><span>0</span><span>]</span><span>)</span><span>;</span></p><p><span>	</span><span>global_d3d_device</span><span>-&gt;</span><span>GetBackBuffer</span><span>(</span><span>-</span><span>1</span><span>,</span><span> </span><span>D3DBACKBUFFER_TYPE_MONO</span><span>,</span><span> </span><span>&amp;</span><span>global_d3d_surface_render_primary</span><span>[</span><span>1</span><span>]</span><span>)</span><span>;</span></p><p><span>	</span><span>global_d3d_device</span><span>-&gt;</span><span>GetDepthStencilSurface</span><span>(</span><span>&amp;</span><span>global_d3d_surface_render_primary_z</span><span>)</span><span>;</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>	</span><span>global_d3d_texture_render_primary</span><span>[</span><span>0</span><span>]</span><span> </span><span>=</span><span> </span><span>(</span><span>IDirect3DTexture8</span><span>*</span><span>)</span><span>malloc</span><span>(</span><span>sizeof</span><span>(</span><span>IDirect3DTexture8</span><span>)</span><span>)</span><span>;</span></p><p><span>	</span><span>global_d3d_texture_render_primary</span><span>[</span><span>1</span><span>]</span><span> </span><span>=</span><span> </span><span>(</span><span>IDirect3DTexture8</span><span>*</span><span>)</span><span>malloc</span><span>(</span><span>sizeof</span><span>(</span><span>IDirect3DTexture8</span><span>)</span><span>)</span><span>;</span></p><p><span>	</span><span>// Setup texture views for back/front buffers.</span></p><p><span>	</span><span>for</span><span> </span><span>(</span><span>int</span><span> </span><span>i</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span><span> </span><span>i</span><span> </span><span>&lt;</span><span> </span><span>2</span><span>;</span><span> </span><span>i</span><span>++</span><span>)</span></p><p><span>	</span><span>{</span></p><p><span>		</span><span>XGSetTextureHeader</span><span>(</span><span>640</span><span>,</span><span> </span><span>480</span><span>,</span><span> </span><span>1</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span><span>D3DFMT_LIN_A8R8G8B8</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span></p><p><span>			</span><span>global_d3d_texture_render_primary</span><span>[</span><span>i</span><span>]</span><span>,</span><span> </span><span>global_d3d_surface_render_primary</span><span>[</span><span>i</span><span>]</span><span>-&gt;</span><span>Data</span><span>,</span><span> </span><span>0</span><span>)</span><span>;</span></p><p><span>	</span><span>}</span></p><p><span>	</span><span>// Create a render target surface for the depth buffer that matches the size and format of the back buffer.</span></p><p><span>	</span><span>global_d3d_surface_z_as_target</span><span> </span><span>=</span><span> </span><span>(</span><span>IDirect3DSurface8</span><span>*</span><span>)</span><span>malloc</span><span>(</span><span>sizeof</span><span>(</span><span>IDirect3DSurface8</span><span>)</span><span>)</span><span>;</span></p><p><span>	</span><span>memcpy</span><span>(</span><span>global_d3d_surface_z_as_target</span><span>,</span><span> </span><span>global_d3d_surface_render_primary</span><span>,</span><span> </span><span>sizeof</span><span>(</span><span>IDirect3DSurface8</span><span>)</span><span>)</span><span>;</span></p><p><span>	</span><span>global_d3d_surface_z_as_target</span><span>-&gt;</span><span>Data</span><span> </span><span>=</span><span> </span><span>global_d3d_surface_render_primary_z</span><span>-&gt;</span><span>Data</span><span>;</span></p><p><span>	</span><span>// Create two textures for the depth buffer, one in ARGB format and one in ABGR format.</span></p><p><span>	</span><span>global_d3d_texture_z_as_target</span><span>[</span><span>0</span><span>]</span><span> </span><span>=</span><span> </span><span>(</span><span>IDirect3DTexture8</span><span>*</span><span>)</span><span>malloc</span><span>(</span><span>sizeof</span><span>(</span><span>IDirect3DTexture8</span><span>)</span><span>)</span><span>;</span></p><p><span>	</span><span>XGSetTextureHeader</span><span>(</span><span>640</span><span>,</span><span> </span><span>480</span><span>,</span><span> </span><span>1</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span><span>D3DFMT_LIN_A8R8G8B8</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span></p><p><span>		</span><span>global_d3d_texture_z_as_target</span><span>[</span><span>0</span><span>]</span><span>,</span><span> </span><span>global_d3d_surface_render_primary_z</span><span>-&gt;</span><span>Data</span><span>,</span><span> </span><span>0</span><span>)</span><span>;</span></p><p><span>	</span><span>global_d3d_texture_z_as_target</span><span>[</span><span>1</span><span>]</span><span> </span><span>=</span><span> </span><span>(</span><span>IDirect3DTexture8</span><span>*</span><span>)</span><span>malloc</span><span>(</span><span>sizeof</span><span>(</span><span>IDirect3DTexture8</span><span>)</span><span>)</span><span>;</span></p><p><span>	</span><span>XGSetTextureHeader</span><span>(</span><span>640</span><span>,</span><span> </span><span>480</span><span>,</span><span> </span><span>1</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span><span>D3DFMT_LIN_A8B8G8R8</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span></p><p><span>		</span><span>global_d3d_texture_z_as_target</span><span>[</span><span>1</span><span>]</span><span>,</span><span> </span><span>global_d3d_surface_render_primary_z</span><span>-&gt;</span><span>Data</span><span>,</span><span> </span><span>0</span><span>)</span><span>;</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>}</span></p></div></td>
					</tr>
				</tbody></table>
			</div>



<p>This is relatively easy to fix, we simply need to hook this function, let it run normally, and then fix up the dimensions of the textures/surfaces afterwards. The pseudo code for this hook can be seen below:</p>



<div id="urvanov-syntax-highlighter-662143868a2f8039876927" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p></div>
				</td>
						<td><div><p><span>bool</span><span> </span><span>Hook_rasterizer_primary_targets_initialize</span><span>(</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>// Call the trampoline and let the real function complete.</span></p><p><span>	</span><span>bool</span><span> </span><span>result</span><span> </span><span>=</span><span> </span><span>rasterizer_primary_targets_initialize_trampoline</span><span>(</span><span>)</span><span>;</span></p><p><span>	</span><span>// Update the dimensions of the surface/textures created to match the resolution of the back buffer.</span></p><p><span>	</span><span>Hack_UpdateD3dPixelContainerForScreenResolution</span><span>(</span><span>global_d3d_texture_render_primary</span><span>[</span><span>0</span><span>]</span><span>)</span><span>;</span></p><p><span>	</span><span>Hack_UpdateD3dPixelContainerForScreenResolution</span><span>(</span><span>global_d3d_texture_render_primary</span><span>[</span><span>1</span><span>]</span><span>)</span><span>;</span></p><p><span>	</span><span>Hack_UpdateD3dPixelContainerForScreenResolution</span><span>(</span><span>global_d3d_texture_z_as_target</span><span>[</span><span>0</span><span>]</span><span>)</span><span>;</span></p><p><span>	</span><span>Hack_UpdateD3dPixelContainerForScreenResolution</span><span>(</span><span>global_d3d_texture_z_as_target</span><span>[</span><span>1</span><span>]</span><span>)</span><span>;</span></p><p><span>	</span><span>return</span><span> </span><span>result</span><span>;</span></p><p><span>}</span></p><p><span>void</span><span> </span><span>Hack_UpdateD3dPixelContainerForScreenResolution</span><span>(</span><span>D3DBaseTexture</span><span>*</span><span> </span><span>pResource</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>// Calculate the correct pitch for the texture with tiling enabled. This can be different than the normal pitch</span></p><p><span>	</span><span>// value and if set incorrectly will cause a "striping" effect on the back buffer.</span></p><p><span>	</span><span>DWORD </span><span>format</span><span> </span><span>=</span><span> </span><span>(</span><span>pResource</span><span>-&gt;</span><span>Format</span><span> </span><span>&gt;&gt;</span><span> </span><span>8</span><span>)</span><span> </span><span>&amp;</span><span> </span><span>0xFF</span><span>;</span></p><p><span>	</span><span>DWORD </span><span>pitch</span><span> </span><span>=</span><span> </span><span>D3D_CalcTilePitch</span><span>(</span><span>/* width */</span><span> </span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>x1</span><span>,</span><span> </span><span>/* texture format */</span><span> </span><span>format</span><span>)</span><span>;</span></p><p><span>	</span><span>// Set the new dimensions of the texture using the size of the back buffer.</span></p><p><span>	</span><span>XGSetTextureHeader</span><span>(</span><span>/* width */</span><span> </span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>x1</span><span>,</span><span> </span><span>/* height */</span><span> </span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>y1</span><span>,</span></p><p><span>		</span><span>1</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span><span>format</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span><span>pResource</span><span>,</span><span> </span><span>pResource</span><span>-&gt;</span><span>Data</span><span>,</span><span> </span><span>pitch</span><span>)</span><span>;</span></p><p><span>}</span></p></div></td>
					</tr>
				</tbody></table>
			</div>



<p>There’s one additional thing to note here and it’s that the memory used for the back, front, and depth buffers is a special type of memory known as “tiled” memory. Tiled memory stores the pixel data in a way that’s more efficient to read and write to based on the design of the actual RAM chip’s memory cells. Storing the pixel data in tiled memory decreases the overall bandwidth required when reading and writing these buffers. The gotcha here is that the pitch value for the surface/texture is not always the same as it would be for a texture in normal memory (width * bpp). This is why I call D3D_CalcTilePitch in the the Hack_UpdateD3dPixelContainerForScreenResolution helper function. It will calculate the correct pitch for tiled memory based on the width and bits per pixel for the texture format. If the pitch value is calculated incorrectly (ex: by doing width * bpp) you’ll end up getting a “striping” effect on the back buffer (which affects 1080i video resolutions specifically). If you’re curious what tiled memory looks like if you don’t “un-tile” it here you go:</p>



<div><figure><a href="https://icode4.coffee/wp-content/uploads/tiled_back_buffer.png" target="_blank" rel="noopener"><img loading="lazy" width="1095" height="616" src="https://icode4.coffee/wp-content/uploads/tiled_back_buffer.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/tiled_back_buffer.png 1095w, https://icode4.coffee/wp-content/uploads/tiled_back_buffer-300x169.png 300w, https://icode4.coffee/wp-content/uploads/tiled_back_buffer-768x432.png 768w" sizes="(max-width: 1095px) 100vw, 1095px"></a><figcaption>D3D back buffer of the main menu in tiled form</figcaption></figure></div>



<p>This is the main menu image from earlier (only in 720p) dumped straight from the back buffer without un-tiling the data. If you squint hard enough you can almost make out the Halo 2 logo in the center. That aside it’s time to test the new patches and see if the modifications to the surface dimensions fixed our issues. Loading up the game with this new set of modifications gives us this:</p>



<div><figure><a href="https://icode4.coffee/wp-content/uploads/main_menu_issues2.png" target="_blank" rel="noopener"><img loading="lazy" width="720" height="480" src="https://icode4.coffee/wp-content/uploads/main_menu_issues2.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/main_menu_issues2.png 720w, https://icode4.coffee/wp-content/uploads/main_menu_issues2-300x200.png 300w" sizes="(max-width: 720px) 100vw, 720px"></a><figcaption>Main menu with some issues fixed</figcaption></figure></div>



<p>Okay so the striping effect from using the incorrect pitch value in the back/front buffer surfaces is now fixed. However, the water geometry is still cutoff even after we changed the resolutions of all the render targets/textures, right? Well we only updated the <em>primary</em> render targets, we still need to update the intermediate render targets used by the game’s rasterizer, and this is where having game engine specific knowledge comes in handy.</p>



<h2>Resizing the rasterizer targets</h2>



<p>As I mentioned earlier there’s ~25 render targets Halo 2 uses for different passes in the render loop such as detail texture blending, water, reflections, fog, shadows, etc. The game’s rasterizer system allows for creating a render target with child render targets that utilize the same underlying memory. The 25 render targets the game creates are backed by only 4-5 unique memory allocations and uses this parent/child relationship to make efficient use of the memory. When one render target is no longer in use the others are free to use that memory. While most render targets are smaller than the back buffer (ranging from 512×512 all the way down to 64×64) there’s one in particular that needs to match the back buffer resolution which is the texture accumulator target, or taxaccum for short.</p>



<p>The DirectX implementation on Xbox only allows for sampling from 4 textures per pixel shader pass. If you want to render something that uses more than 4 input textures you’ll need to do it in two or more passes. This is what the texaccum layer is for. Objects in the game that use more than 4 textures will first render all the detail textures to the texaccum layer. When the texaccum pass is completed the taxaccum render target will be fed into the lightmap pass as an input and combined with any additional textures for the object along with the lightmap texture to get the final output.</p>



<div><figure><a href="https://icode4.coffee/wp-content/uploads/taxaccum_lightmap_pass.png" target="_blank" rel="noopener"><img loading="lazy" width="1901" height="1080" src="https://icode4.coffee/wp-content/uploads/taxaccum_lightmap_pass-1901x1080.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/taxaccum_lightmap_pass-1901x1080.png 1901w, https://icode4.coffee/wp-content/uploads/taxaccum_lightmap_pass-300x170.png 300w, https://icode4.coffee/wp-content/uploads/taxaccum_lightmap_pass-768x436.png 768w, https://icode4.coffee/wp-content/uploads/taxaccum_lightmap_pass-1536x873.png 1536w, https://icode4.coffee/wp-content/uploads/taxaccum_lightmap_pass-2048x1164.png 2048w" sizes="(max-width: 1901px) 100vw, 1901px"></a><figcaption>Texaccum and lightmap shader passes</figcaption></figure></div>



<p>Here’s an example using the ground geometry in coagulation. In the texaccum pass the detail textures for the ground geometry are blended together into the texaccum render target. Then in the lightmap pass the texaccum render target is used as an input texture along with a bump map and lightmap texture to create the final image. The reason the water geometry in the main menu is cut off is because it’s being rendered to the texaccum render target which has a hard coded size of 640×480. Now that we’re rendering in larger video resolutions the dimensions of the texaccum target will need to be increased. Looking through the rasterizer initialization code we’ll find a function I called rasterizer_targets_initialize that allocates buffers for the various render targets and initializes them:</p>



<div id="urvanov-syntax-highlighter-662143868a2fb981828718" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p></div>
				</td>
						<td><div><p><span>bool</span><span> </span><span>rasterizer_targets_initialize</span><span>(</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>// Allocate and initialize the texaccum render target.</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>!</span><span>_rasterizer_alloc_and_create_render_target</span><span>(</span><span>1</span><span>,</span><span> </span><span>640</span><span>,</span><span> </span><span>480</span><span>,</span><span> </span><span>1</span><span>,</span><span> </span><span>false</span><span>)</span><span>)</span></p><p><span>		</span><span>return</span><span> </span><span>false</span><span>;</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>}</span></p><p><span>bool</span><span> </span><span>_rasterizer_alloc_and_create_render_target</span><span>(</span><span>int</span><span> </span><span>target_index</span><span>,</span><span> </span><span>int</span><span> </span><span>width</span><span>,</span><span> </span><span>int</span><span> </span><span>height</span><span>,</span><span> </span><span>int</span><span> </span><span>unk</span><span>,</span><span> </span><span>bool</span><span> </span><span>z_surface</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>// Calculate the allocation size rounded up to the nearest page size.</span></p><p><span>	</span><span>int</span><span> </span><span>allocationSize</span><span> </span><span>=</span><span> </span><span>(</span><span>(</span><span>(</span><span>(</span><span>width</span><span> </span><span>+</span><span> </span><span>63</span><span>)</span><span> </span><span>&amp;</span><span> </span><span>~</span><span>64</span><span>)</span><span> </span><span>*</span><span> </span><span>height</span><span> </span><span>*</span><span> </span><span>4</span><span>)</span><span> </span><span>+</span><span> </span><span>4095</span><span>)</span><span> </span><span>&amp;</span><span> </span><span>~</span><span>4096</span><span>;</span></p><p><span>	</span><span>// Allocate memory from the game's self-managed memory pool.</span></p><p><span>	</span><span>void</span><span>*</span><span> </span><span>pPhysicalAllocPtr</span><span> </span><span>=</span><span> </span><span>physical_memory_globals</span><span>.</span><span>hi_stage_address</span><span>[</span><span>physical_memory_globals</span><span>.</span><span>current_stage</span><span>]</span><span> </span><span>-</span><span> </span><span>allocationSize</span><span>;</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>pPhysicalAllocPtr</span><span> </span><span>&gt;</span><span> </span><span>physical_memory_globals</span><span>.</span><span>low_stage_address</span><span>[</span><span>physical_memory_globals</span><span>.</span><span>current_stage</span><span>]</span><span>)</span></p><p><span>	</span><span>{</span></p><p><span>		</span><span>physical_memory_globals</span><span>.</span><span>hi_stage_address</span><span>[</span><span>physical_memory_globals</span><span>.</span><span>current_stage</span><span>]</span><span> </span><span>=</span><span> </span><span>pPhysicalAllocPtr</span><span>;</span></p><p><span>		</span><span>// Mark the allocated memory as RW write-combine memory.</span></p><p><span>		</span><span>pPhysicalAllocPtr</span><span> </span><span>|=</span><span> </span><span>PHYSICAL_MEM_ADDRESS_MASK</span><span>;</span></p><p><span>		</span><span>XPhysicalProtect</span><span>(</span><span>pPhysicalAllocPtr</span><span>,</span><span> </span><span>allocationSize</span><span>,</span><span> </span><span>PAGE_READWRITE</span><span> </span><span>|</span><span> </span><span>PAGE_WRITECOMBINE</span><span>)</span><span>;</span></p><p><span>	</span><span>}</span></p><p><span>	</span><span>return</span><span> </span><span>_rasterizer_create_render_target</span><span>(</span><span>target_index</span><span>,</span><span> </span><span>/* type */</span><span> </span><span>1</span><span>,</span><span> </span><span>width</span><span>,</span><span> </span><span>height</span><span>,</span><span> </span><span>z_surface</span><span>,</span><span> </span><span>/* linear */</span><span> </span><span>true</span><span>,</span><span> </span><span>true</span><span>,</span><span> </span><span>pPhysicalAllocPtr</span><span>)</span><span>;</span></p><p><span>}</span></p></div></td>
					</tr>
				</tbody></table>
			</div>



<p>To fix the hard coded dimensions I simply hook the _rasterizer_alloc_and_create_render_target function, check the target_index parameter for the texaccum index, and change the dimensions to match the back buffer size. The pseudo code for the hook looks like this:</p>



<div id="urvanov-syntax-highlighter-662143868a2ff522909558" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>bool</span><span> </span><span>Hook__rasterizer_alloc_and_create_render_target</span><span>(</span><span>int</span><span> </span><span>target_index</span><span>,</span><span> </span><span>int</span><span> </span><span>width</span><span>,</span><span> </span><span>int</span><span> </span><span>height</span><span>,</span><span> </span><span>int</span><span> </span><span>unk</span><span>,</span><span> </span><span>bool</span><span> </span><span>z_surface</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>// Check the rasterizer target index and adjust the surface dimensions accordingly.</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>target_index</span><span> </span><span>==</span><span> </span><span>1</span><span>)</span></p><p><span>	</span><span>{</span></p><p><span>		</span><span>// Texaccum rasterizer target:</span></p><p><span>		</span><span>width</span><span> </span><span>=</span><span> </span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>x1</span><span>;</span></p><p><span>		</span><span>height</span><span> </span><span>=</span><span> </span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>y1</span><span>;</span></p><p><span>	</span><span>}</span></p><p><span>	</span><span>// Call the trampoline and create the render target.</span></p><p><span>	</span><span>return</span><span> </span><span>_rasterizer_alloc_and_create_render_target_trampoline</span><span>(</span><span>target_index</span><span>,</span><span> </span><span>width</span><span>,</span><span> </span><span>height</span><span>,</span><span> </span><span>unk</span><span>,</span><span> </span><span>z_surface</span><span>)</span><span>;</span></p><p><span>}</span></p></div></td>
					</tr>
				</tbody></table>
			</div>



<p>Running the game with these modifications we can see the water geometry is no longer cutoff, and loading into a map doesn’t show any noticeable rendering issues:</p>



<div><figure><a href="https://icode4.coffee/wp-content/uploads/main_menu_texaccum_fixed.png" target="_blank" rel="noopener"><img loading="lazy" width="720" height="480" src="https://icode4.coffee/wp-content/uploads/main_menu_texaccum_fixed.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/main_menu_texaccum_fixed.png 720w, https://icode4.coffee/wp-content/uploads/main_menu_texaccum_fixed-300x200.png 300w" sizes="(max-width: 720px) 100vw, 720px"></a><figcaption>Main menu with the texaccum layer fixed</figcaption></figure></div>



<p>The game looks okay in 480p but the real goal of this work is to get the game playing decently in 720p, and maybe booting in 1080p, even though it won’t play well at that resolution nor will the Xbox output a 1080p video signal (but I can still take some sweet screenshots!). We still need to fix the missing blue filter on the main menu but in the interest of keeping this post as short as possible I’m going to skip the blue filter fix as it’s not very interesting anyway (spoiler: it was just a simple size check that needed updating). Changing the video settings on my console to 720p and booting the game results in… well it results in the game crashing on startup. The reason? Due to the increased size of the front/back/depth buffers and rasterizer targets we’re out of memory, or at least, out of memory that the game is able to use.</p>



<h2>Part 2: Memory Management and RAM Upgrades</h2>



<p>The original Xbox had two different console types, the retail consoles that consumers would buy with 64MB of RAM, and a development console (or dev kit/debug console) that was used by game developers with 128MB of RAM. The extra RAM on the development console helped developers debug their games and run additional test code during the development process. The motherboard used by both console types is nearly identical with the main difference being the software they run and the additional RAM chips on the dev kit motherboards (they also have a slightly different south bridge for security purposes but that’s not really important here). However, retail motherboards still had the placements for the 4 additional RAM chips and over the years people found that they could solder in the missing RAM chips and run a modified Xbox kernel to give them access to the extra memory. Retail games won’t make any use of that extra memory, but homebrew applications like Xbox Media Center will use it for things like video decoding when watching movies or streaming media. </p>



<p>I’ve neglected to mention that up until this point the only way I was able to get the game to boot with the increased back buffer size is by running it on a console with 128MB of RAM and using an Xbox kernel with support for the additional 64MB of RAM. As-is the game will not utilize any of the additional memory, however, this kernel has additional logic to “force” certain types of memory allocations into the upper 64MB region to make space for allocations that must be in the lower 64MB region. Going into this project I already knew that the only way this game would boot in 720p would be with the RAM upgrade. In fact, the only way to get it to boot in proper 480p resolution without the RAM upgrade was to steal some memory back from the game’s in-memory texture cache which ends up causing additional texture pop-in. But all of this can be fixed by patching the game’s memory allocator to support the additional 64MB of RAM.</p>



<h2>Halo 2’s memory management</h2>



<p>It’s quite common for game developers to write their own memory management system, especially on older hardware where the built-in memory allocator may be slow or even buggy. Developers would use the built-in memory allocator to make a couple large allocations that they’d wrap in their own allocator to chunk it up and dish out as needed. At startup Halo 2 creates one large allocation that uses ~48.9MB of the available 64MB of RAM on the console, basically, every last page of memory they could possibly get once you account for the Xbox kernel and game executable. This region of memory is then chunked up for various subsystems in the game such as level metadata, texture, geometry, animation, and sound caches, rasterizer targets, network and simulation resources, etc. </p>



<p>In order to patch Halo 2’s memory allocator I was going to need a way to visualize memory usage so I could see where things are located and how much space is being used. I spent a few nights working on a tool (<a rel="noreferrer noopener" href="https://github.com/grimdoomer/XboxImageGrabber" data-type="URL" data-id="https://github.com/grimdoomer/XboxImageGrabber" target="_blank">GitHub: XboxImageGrabber</a>) that would walk the page table entries for all the RAM on the console and create a crude bitmap that color codes various chunks of data, allowing me to create a visualization of what memory looks like:</p>



<div><figure><a href="https://icode4.coffee/wp-content/uploads/h2_retail_runtime_data.png" target="_blank" rel="noopener"><img loading="lazy" width="1697" height="1080" src="https://icode4.coffee/wp-content/uploads/h2_retail_runtime_data-1697x1080.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/h2_retail_runtime_data-1697x1080.png 1697w, https://icode4.coffee/wp-content/uploads/h2_retail_runtime_data-300x191.png 300w, https://icode4.coffee/wp-content/uploads/h2_retail_runtime_data-768x489.png 768w, https://icode4.coffee/wp-content/uploads/h2_retail_runtime_data-1536x977.png 1536w, https://icode4.coffee/wp-content/uploads/h2_retail_runtime_data-2048x1303.png 2048w, https://icode4.coffee/wp-content/uploads/h2_retail_runtime_data-110x70.png 110w" sizes="(max-width: 1697px) 100vw, 1697px"></a><figcaption>Memory profile of Halo 2</figcaption></figure></div>



<p>This might look like pixel barf and be hard to interpret but it was really only intended for my own use so I never bothered to make it pretty. The first column on the left shows the memory usage by the Xbox OS. At the very beginning is the Xbox kernel, down in the 0x83000000 region we have the Halo 2 executable and some virtual memory allocations, and at 0x84000000 is the end of the 64MB retail RAM region. This was taken on a console with 128MB of memory so everything after 0x84000000 is the “debug” memory region. The center column shows Halo 2’s memory usage for runtime data and d3d resources. This particular image doesn’t have color coding enabled so you can get an idea of how much memory the game reserves for this runtime data region. That blue blob? That’s the ~49MB allocation the game makes on startup. The column on the right shows combined memory usage, basically what has been allocated and what is free with no further classification for what the memory is used for. We can see that the stock version of the game uses almost every available page of memory it can get, sparing only a few as a safety net.</p>



<div><figure><a href="https://icode4.coffee/wp-content/uploads/h2_retail_memory_profile.png" target="_blank" rel="noopener"><img loading="lazy" width="1697" height="1080" src="https://icode4.coffee/wp-content/uploads/h2_retail_memory_profile-1697x1080.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/h2_retail_memory_profile-1697x1080.png 1697w, https://icode4.coffee/wp-content/uploads/h2_retail_memory_profile-300x191.png 300w, https://icode4.coffee/wp-content/uploads/h2_retail_memory_profile-768x489.png 768w, https://icode4.coffee/wp-content/uploads/h2_retail_memory_profile-1536x977.png 1536w, https://icode4.coffee/wp-content/uploads/h2_retail_memory_profile-2048x1303.png 2048w, https://icode4.coffee/wp-content/uploads/h2_retail_memory_profile-110x70.png 110w" sizes="(max-width: 1697px) 100vw, 1697px"></a><figcaption>Halo 2 memory profile with data classification</figcaption></figure></div>



<p>Here’s the same memory profile image with the runtime data region color coded to show the various subsystem allocations. There’s actually a few more not pictured here but they aren’t too important. The ones we’re concerned with are going to be tag data, texture cache, geometry cache, and rasterizer buffer. The runtime data allocation appearing immediately after the Xbox kernel is not a coincidence, it’s purposefully allocated at a hard coded address of 0x80061000. The “tag data” region is actually all the metadata for every object in a map file in the form of C-structs that have been serialized using the predetermined base address of 0x80061000. The tag data system is designed to be as flexible and performant as possible, and, in my opinion the inner workings are really a feat of engineering. I could write an entire blog post about the inner workings of the tag data system and why I think it makes the Blam engine one of the most flexible engines ever made, but that isn’t relevant to this post. The key takeaway here is that this data needs to always be at the same address or else the game won’t work. But all of the other data in the runtime region can be moved around at will.</p>



<h4>Patching the memory allocator</h4>



<p>The regions we’ll want to move out of the runtime data buffer are the rasterizer targets (at least the ones we’ll be increasing in size), and the texture and geometry caches so we can increase their size to help reduce pop-in issues. We’ll also want to reduce the size of the runtime data buffer to account for the things we’re removing so we don’t waste any memory by not filling it. The patches for the memory allocator will consist of 3 main changes:</p>



<ol><li>Hooking certain allocation calls and moving them to the debug memory region. </li><li>When these allocations are “released” (ex: when loading a new level) we’ll need to call the appropriate free function.</li><li>Adjusting the size of the runtime data region to reclaim memory that’s no longer being used.</li></ol>



<p>I’ve called the memory allocation function we’ll need to hook physical_memory_malloc, and it’s unfortunately inlined by the compiler which means each “call site” for it will need a unique patch, and the same is true for when an allocation is free’d. The pseudo code for the memory allocator patches looks like this:</p>



<div id="urvanov-syntax-highlighter-662143868a302749205471" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p><p>28</p><p>29</p><p>30</p><p>31</p><p>32</p><p>33</p><p>34</p><p>35</p><p>36</p><p>37</p><p>38</p><p>39</p><p>40</p><p>41</p><p>42</p><p>43</p><p>44</p><p>45</p><p>46</p><p>47</p><p>48</p><p>49</p><p>50</p><p>51</p><p>52</p><p>53</p><p>54</p><p>55</p><p>56</p><p>57</p><p>58</p></div>
				</td>
						<td><div><p><span>struct</span><span> </span><span>physical_memory_alloc_info</span></p><p><span>{</span></p><p><span>	</span><span>const</span><span> </span><span>char</span><span>*</span><span> </span><span>name</span><span>;</span><span>				</span><span>// Name for the allocation, ex: "texture cache"</span></p><p><span>	</span><span>unsigned</span><span> </span><span>int</span><span> </span><span>override_size</span><span>;</span><span>		</span><span>// If non-zero use this size for the allocation</span></p><p><span>	</span><span>void</span><span>*</span><span> </span><span>address</span><span>;</span><span>					</span><span>// Allocation address</span></p><p><span>}</span><span>;</span></p><p><span>// Enum used to index into Hack_PhysicalMemoryRegionInfoTable</span></p><p><span>enum</span></p><p><span>{</span></p><p><span>	</span><span>PHYS_MEM_REGION_RASTERIZER_TEXACCUM_TARGET</span><span>,</span></p><p><span>	</span><span>PHYS_MEM_REGION_GEOMETRY_CACHE</span><span>,</span></p><p><span>	</span><span>PHYS_MEM_REGION_TEXTURE_CACHE</span><span>,</span></p><p><span>}</span><span>;</span></p><p><span>// Global array of tracked allocations:</span></p><p><span>physical_memory_alloc_info </span><span>Hack_PhysicalMemoryRegionInfoTable</span><span>[</span><span>]</span><span> </span><span>=</span></p><p><span>{</span></p><p><span>	</span><span>{</span><span> </span><span>"rasterizer texaccum target"</span><span>,</span><span> 	</span><span>0</span><span>,</span><span> </span><span>NULL</span><span> </span><span>}</span><span>,</span></p><p><span>	</span><span>{</span><span> </span><span>"geometry cache"</span><span>,</span><span> 				</span><span>0</span><span>,</span><span> </span><span>NULL</span><span> </span><span>}</span><span>,</span></p><p><span>	</span><span>{</span><span> </span><span>"texture cache"</span><span>,</span><span> 					</span><span>0</span><span>,</span><span> </span><span>NULL</span><span> </span><span>}</span><span>,</span></p><p><span>}</span><span>;</span></p><p><span>void</span><span>*</span><span> </span><span>Hack_PhysicalMemoryAlloc</span><span>(</span><span>unsigned</span><span> </span><span>int</span><span> </span><span>regionIndex</span><span>,</span><span> </span><span>unsigned</span><span> </span><span>int</span><span> </span><span>size</span><span>,</span><span> </span><span>int</span><span> </span><span>protect</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>// Get a pointer to the allocation info structure.</span></p><p><span>	</span><span>physical_memory_alloc_info</span><span>*</span><span> </span><span>pAllocInfo</span><span> </span><span>=</span><span> </span><span>&amp;</span><span>Hack_PhysicalMemoryRegionInfoTable</span><span>[</span><span>regionIndex</span><span>]</span><span>;</span></p><p><span>	</span><span>// If the override size is specified use it for the allocation.</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>pAllocInfo</span><span>-&gt;</span><span>override_size</span><span> </span><span>!=</span><span> </span><span>0</span><span>)</span></p><p><span>		</span><span>size</span><span> </span><span>=</span><span> </span><span>pAllocInfo</span><span>-&gt;</span><span>override_size</span><span>;</span></p><p><span>	</span><span>// Round the size up to the nearest page interval.</span></p><p><span>	</span><span>size</span><span> </span><span>=</span><span> </span><span>(</span><span>size</span><span> </span><span>+</span><span> </span><span>PAGE_SIZE</span><span>-</span><span>1</span><span>)</span><span> </span><span>&amp;</span><span> </span><span>~</span><span>(</span><span>PAGE_SIZE</span><span>-</span><span>1</span><span>)</span><span>;</span></p><p><span>	</span><span>// TODO: Allocate memory from the debug region...</span></p><p><span>	</span><span>pAllocInfo</span><span>-&gt;</span><span>address</span><span> </span><span>=</span><span> </span><span>NULL</span><span>;</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>pAllocInfo</span><span>-&gt;</span><span>address</span><span> </span><span>==</span><span> </span><span>NULL</span><span>)</span></p><p><span>		</span><span>DebugBreak</span><span>(</span><span>)</span><span>;</span></p><p><span>	</span><span>// Debug print the allocation info.</span></p><p><span>	</span><span>DbgPrint</span><span>(</span><span>"physical_memory_malloc %s %ld at 0x%08x\n"</span><span>,</span><span> </span><span>pAllocInfo</span><span>-&gt;</span><span>name</span><span>,</span><span> </span><span>size</span><span>,</span><span> </span><span>pAllocInfo</span><span>-&gt;</span><span>address</span><span>)</span><span>;</span></p><p><span>	</span><span>return</span><span> </span><span>pAllocInfo</span><span>-&gt;</span><span>address</span><span>;</span></p><p><span>}</span></p><p><span>void</span><span> </span><span>Hack_PhysicalMemoryFree</span><span>(</span><span>unsigned</span><span> </span><span>int</span><span> </span><span>regionIndex</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>// Get a pointer to the allocation info structure.</span></p><p><span>	</span><span>physical_memory_alloc_info</span><span>*</span><span> </span><span>pAllocInfo</span><span> </span><span>=</span><span> </span><span>&amp;</span><span>Hack_PhysicalMemoryRegionInfoTable</span><span>[</span><span>regionIndex</span><span>]</span><span>;</span></p><p><span>	</span><span>// If the allocation is valid free it.</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>pAllocInfo</span><span>-&gt;</span><span>address</span><span> </span><span>!=</span><span> </span><span>NULL</span><span>)</span></p><p><span>	</span><span>{</span></p><p><span>		</span><span>// TODO: Free the allocation...</span></p><p><span>		</span><span>pAllocInfo</span><span>-&gt;</span><span>address</span><span> </span><span>=</span><span> </span><span>NULL</span><span>;</span></p><p><span>	</span><span>}</span></p><p><span>}</span></p></div></td>
					</tr>
				</tbody></table>
			</div>



<p>This allows me to hook individual call sites where the physical_memory_malloc function is inlined using a patch like so:</p>



<div id="urvanov-syntax-highlighter-662143868a307402357472" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>push</span><span>	</span><span>404h</span><span>								</span><span>; PAGE_WRITECOMBINE | PAGE_READWRITE</span></p><p><span>push</span><span>	</span><span>ecx</span><span>									</span><span>; size, calculated earlier in function</span></p><p><span>push</span><span>	</span><span>PHYS</span><span>_</span><span>MEM</span><span>_</span><span>REGION</span><span>_</span><span>GEOMETRY</span><span>_</span><span>CACHE</span><span>		</span><span>; regionIndex</span></p><p><span>mov</span><span>		</span><span>eax</span><span>,</span><span> </span><span>Hack</span><span>_</span><span>PhysicalMemoryAlloc</span></p><p><span>call</span><span>	</span><span>eax</span><span>									</span><span>; Call our helper function to perform the allocation</span></p><p><span>; Jump over code we no longer need to execute.</span></p><p><span>push</span><span>	</span><span>0012DA73h</span></p><p><span>ret</span></p></div></td>
					</tr>
				</tbody></table>
			</div>



<p>Now you’re probably wondering why the lines that perform the allocation and free calls in the pseudo code above are labeled as “TODO”, and that’s because allocating physical contiguous memory in the debug memory region is problematic… </p>



<h2>Xbox memory architecture</h2>



<p>Earlier I mentioned that the original Xbox uses a unified memory design allowing the CPU and GPU to share the same RAM. When the CPU provides a memory address to the GPU (ex: address of a texture or vertex buffer) it must use a physical memory address and the memory span must be contiguous (meaning the pages backing the allocation are all consecutive with no gaps). This is because the GPU doesn’t have any concept of page tables or virtual memory addresses so it’s unable to translate virtual addresses to perform memory accesses. It simply treats the memory address as an offset from the start of RAM and reads data as needed starting from this offset. There’s specific APIs for allocating “video” or “GPU” memory but these are all wrappers for allocating memory that is physical and contiguous.</p>



<p>The Xbox kernel provides various functions for allocating memory but there’s two main types of memory allocations that can be made. Physical memory which is also contiguous, and virtual memory which is not explicitly contiguous (it can end up being contiguous by chance but it’s virtual memory so it’s not required to be contiguous). On an unmodified retail Xbox console there’s only 64MB of RAM and the entire 64MB region can be used to make physical or virtual allocations. When using a console with 128MB of RAM and kernel with extra RAM support only the first 64MB of RAM can be used for physical allocations, but virtual allocations can be made anywhere in the 128MB region. If you try to make a physical allocation and there’s not enough free contiguous memory in the first 64MB of RAM, the kernel will attempt to relocate virtual allocations into the upper 64MB region to satisfy the allocation request.</p>



<p>This was done on purpose to provide a closer experience to the retail hardware for developers to work with. The additional 64MB of “debug” memory was to allow developers to run extra code and profiling tools that consumed memory without having to take away from the memory their game would normally have. There’s no benefit to allowing developers to allocate more “video” memory in the debug region as it doesn’t exist on retail hardware and can’t be used in a final version of the game. However, this limits me in terms of how much additional memory I can give Halo 2 for video allocations.</p>



<h2>Hot patching the Xbox kernel</h2>



<p>Looking at the memory profile image above we can see the “runtime data region” consumes most of the first 64MB of RAM. Not everything allocated in this region is required to be “video” memory (and thus needs to be in physical memory), so I could move as many things as possible out of that region and into the upper 64MB of RAM as a virtual allocation. But this gets quite messy to track down all of the allocations being made and patch each call site, and it won’t give us as much memory as we really need for additional performance tweaks later on. Rather than go for a sub-par solution I decided to take matters (or memory) into my own hands and try something crazy.</p>



<p>I ran some tests where I made a video memory allocation “by hand” and just stole some unused page table entries for the upper 64MB address space. Instead of asking the kernel to allocate the memory for me, I just “commandeered” the page tables and did it myself. Feeding this address to the GPU for rendering worked just fine which meant that the limitation of only being able to allocate “video” memory in the lower 64MB of RAM is not a hardware limitation it’s a software one. The only thing preventing me from making physical memory allocations in the upper 64MB of RAM is the kernel. After spending a few nights digging through the memory management functions in the Xbox kernel I found the blocker that was preventing me from making physical allocations passed the 64MB mark:</p>



<div><figure><a href="https://icode4.coffee/wp-content/uploads/max_pfn_check-1.png" target="_blank" rel="noopener"><img loading="lazy" width="879" height="516" src="https://icode4.coffee/wp-content/uploads/max_pfn_check-1.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/max_pfn_check-1.png 879w, https://icode4.coffee/wp-content/uploads/max_pfn_check-1-300x176.png 300w, https://icode4.coffee/wp-content/uploads/max_pfn_check-1-768x451.png 768w" sizes="(max-width: 879px) 100vw, 879px"></a><figcaption>Max PFN check in MmAllocateContiguousMemoryEx</figcaption></figure></div>



<p>The MmAllocateContiguousMemoryEx function used to allocate contiguous physical memory takes in two parameters that let the caller specify the lowest and highest acceptable addresses for the memory allocation. This is how Halo 2 gets the runtime data region to always be at the address 0x80061000, by specifying the highest acceptable address as 0x61000 (the upper most bits are masked out). The kernel takes both of these parameters and converts them into page frame numbers (basically an index for the page of memory that corresponds to that address), and checks they’re less than or equal to this constant I called MAX_USABLE_PFN. The MAX_USABLE_PFN constant corresponds to the address 0x83FE0000, which is equal to 64MB – 128KB. What is the significance of this value? The top 128kb of RAM is always reserved with 64KB used as a “scratch” region for the GPU and the other 64KB used for the CPU page tables. I believe the GPU “scratch” region is used for storing data related to depth buffer compression tags and possibly processed vertex data that is still passing through the shader pipeline, but I’ve never actually confirmed this myself.</p>



<p>This check is our blocker for allocating physical memory in the upper 64MB of RAM. I changed this value at runtime after my test application loaded and confirmed I was able to allocate memory in the upper 64MB of RAM using MmAllocateContiguousMemoryEx, and the GPU was able to use that memory just fine. So now all I needed to do is write a function to hot patch the Xbox kernel when the game boots, no big deal right? For this patch I’ll first make sure the console has 128MB of RAM installed, then resolve the address of the MmAllocateContiguousMemoryEx function, search for the “mov edx, 0x3FDF” instruction, and patch it to use a new “MAX_USABLE_PFN” value suitable for 128MB RAM configuration. Here’s the pseudo code for the patch:</p>



<div id="urvanov-syntax-highlighter-662143868a309300802937" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p><p>28</p><p>29</p><p>30</p><p>31</p><p>32</p><p>33</p><p>34</p><p>35</p><p>36</p><p>37</p><p>38</p><p>39</p><p>40</p><p>41</p></div>
				</td>
						<td><div><p><span>bool</span><span> </span><span>PatchMaxPFN</span><span>(</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>// Search for the max PFN value.</span></p><p><span>	</span><span>BYTE</span><span>*</span><span> </span><span>pPtr</span><span> </span><span>=</span><span> </span><span>(</span><span>BYTE</span><span>*</span><span>)</span><span>pMmAllocateContiguousMemoryEx</span><span>;</span></p><p><span>	</span><span>BYTE</span><span>*</span><span> </span><span>pEndPtr</span><span> </span><span>=</span><span> </span><span>(</span><span>BYTE</span><span>*</span><span>)</span><span>pMmAllocateContiguousMemoryEx</span><span> </span><span>+</span><span> </span><span>0x80</span><span>;</span></p><p><span>	</span><span>while</span><span> </span><span>(</span><span>pPtr</span><span> </span><span>&lt;</span><span> </span><span>pEndPtr</span><span>)</span></p><p><span>	</span><span>{</span></p><p><span>		</span><span>// Check for the max PFN value.</span></p><p><span>		</span><span>if</span><span> </span><span>(</span><span>*</span><span>(</span><span>DWORD</span><span>*</span><span>)</span><span>pPtr</span><span> </span><span>==</span><span> </span><span>0x00003FDF</span><span>)</span></p><p><span>		</span><span>{</span></p><p><span>			</span><span>_asm</span></p><p><span>			</span><span>{</span></p><p><span>				</span><span>// Disable write protect.</span></p><p><span>				</span><span>pushf</span></p><p><span>				</span><span>cli</span><span>							</span><span>// Disable interrupts</span></p><p><span>				</span><span>mov		</span><span>eax</span><span>,</span><span> </span><span>cr0</span><span>			</span><span>// Get the control register value</span></p><p><span>				</span><span>push	</span><span>eax</span><span>					</span><span>// Save it for later</span></p><p><span>				</span><span>and</span><span>		</span><span>eax</span><span>,</span><span> </span><span>0xFFFEFFFF</span><span>		</span><span>// Disable write-protect</span></p><p><span>				</span><span>mov		</span><span>cr0</span><span>,</span><span> </span><span>eax</span></p><p><span>				</span><span>// Update the max PFN to use the 128MB limit value.</span></p><p><span>				</span><span>mov		</span><span>eax</span><span>,</span><span> </span><span>pPtr</span></p><p><span>				</span><span>mov		</span><span>dword </span><span>ptr</span><span> </span><span>[</span><span>eax</span><span>]</span><span>,</span><span> </span><span>0x00007FCF</span></p><p><span>				</span><span>// Re-enable write-protect.</span></p><p><span>				</span><span>pop		</span><span>eax</span></p><p><span>				</span><span>mov		</span><span>cr0</span><span>,</span><span> </span><span>eax</span><span>			</span><span>// Re-enable write-protect</span></p><p><span>				</span><span>popf</span></p><p><span>			</span><span>}</span></p><p><span>			</span><span>return</span><span> </span><span>true</span><span>;</span></p><p><span>		</span><span>}</span></p><p><span>		</span><span>// Next round.</span></p><p><span>		</span><span>pPtr</span><span>++</span><span>;</span></p><p><span>	</span><span>}</span></p><p><span>	</span><span>// Failed to patch max PFN value.</span></p><p><span>	</span><span>return</span><span> </span><span>false</span><span>;</span></p><p><span>}</span></p></div></td>
					</tr>
				</tbody></table>
			</div>



<p>Now that the memory allocation problems are solved we can fill in the two missing lines from the Hack_PhysicalMemoryAlloc/Hack_PhysicalMemoryFree functions above to use MmAllocateContiguousMemoryEx and MmFreeContiguousMemory. Once we hot patch the kernel we can call MmAllocateContiguousMemoryEx using a lowest acceptable address of 0 and highest acceptable address of 0xFFFFFFFF (which the function will override with our new MAX_USABLE_PFN value). The kernel will walk the page tables in reverse starting from the highest acceptable page number and search for a span of free pages large enough to satisfy the allocation request. This will guarantee the upper 64MB of RAM will take preference during allocation but allows using any available space in all 128MB of RAM to satisfy the request.</p>



<div id="urvanov-syntax-highlighter-662143868a30c283487506" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p><p>28</p><p>29</p><p>30</p><p>31</p><p>32</p><p>33</p><p>34</p><p>35</p><p>36</p></div>
				</td>
						<td><div><p><span>void</span><span>*</span><span> </span><span>Hack_PhysicalMemoryAlloc</span><span>(</span><span>unsigned</span><span> </span><span>int</span><span> </span><span>regionIndex</span><span>,</span><span> </span><span>unsigned</span><span> </span><span>int</span><span> </span><span>size</span><span>,</span><span> </span><span>int</span><span> </span><span>protect</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>// Get a pointer to the allocation info structure.</span></p><p><span>	</span><span>physical_memory_alloc_info</span><span>*</span><span> </span><span>pAllocInfo</span><span> </span><span>=</span><span> </span><span>&amp;</span><span>Hack_PhysicalMemoryRegionInfoTable</span><span>[</span><span>regionIndex</span><span>]</span><span>;</span></p><p><span>	</span><span>// If the override size is specified use it for the allocation.</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>pAllocInfo</span><span>-&gt;</span><span>override_size</span><span> </span><span>!=</span><span> </span><span>0</span><span>)</span></p><p><span>		</span><span>size</span><span> </span><span>=</span><span> </span><span>pAllocInfo</span><span>-&gt;</span><span>override_size</span><span>;</span></p><p><span>	</span><span>// Round the size up to the nearest page interval.</span></p><p><span>	</span><span>size</span><span> </span><span>=</span><span> </span><span>(</span><span>size</span><span> </span><span>+</span><span> </span><span>PAGE_SIZE</span><span>-</span><span>1</span><span>)</span><span> </span><span>&amp;</span><span> </span><span>~</span><span>(</span><span>PAGE_SIZE</span><span>-</span><span>1</span><span>)</span><span>;</span></p><p><span>	</span><span>// Allocate physical contiguous memory (using the entire 128MB address space).</span></p><p><span>	</span><span>pAllocInfo</span><span>-&gt;</span><span>address</span><span> </span><span>=</span><span> </span><span>MmAllocateContiguousMemoryEx</span><span>(</span><span>size</span><span>,</span><span> </span><span>/* LowestAcceptableAddress */</span><span> </span><span>0</span><span>,</span><span> </span><span>/* HighestAcceptableAddress */</span><span> </span><span>0xFFFFFFFF</span><span>,</span><span> </span><span>/* Alignment */</span><span> </span><span>PAGE_SIZE</span><span>,</span><span> </span><span>/* PageAccess */</span><span> </span><span>protect</span><span>)</span><span>;</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>pAllocInfo</span><span>-&gt;</span><span>address</span><span> </span><span>==</span><span> </span><span>NULL</span><span>)</span></p><p><span>		</span><span>DebugBreak</span><span>(</span><span>)</span><span>;</span></p><p><span>	</span><span>// Debug print the allocation info.</span></p><p><span>	</span><span>DbgPrint</span><span>(</span><span>"physical_memory_malloc %s %ld at 0x%08x\n"</span><span>,</span><span> </span><span>pAllocInfo</span><span>-&gt;</span><span>name</span><span>,</span><span> </span><span>size</span><span>,</span><span> </span><span>pAllocInfo</span><span>-&gt;</span><span>address</span><span>)</span><span>;</span></p><p><span>	</span><span>return</span><span> </span><span>pAllocInfo</span><span>-&gt;</span><span>address</span><span>;</span></p><p><span>}</span></p><p><span>void</span><span> </span><span>Hack_PhysicalMemoryFree</span><span>(</span><span>unsigned</span><span> </span><span>int</span><span> </span><span>regionIndex</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>// Get a pointer to the allocation info structure.</span></p><p><span>	</span><span>physical_memory_alloc_info</span><span>*</span><span> </span><span>pAllocInfo</span><span> </span><span>=</span><span> </span><span>&amp;</span><span>Hack_PhysicalMemoryRegionInfoTable</span><span>[</span><span>regionIndex</span><span>]</span><span>;</span></p><p><span>	</span><span>// If the allocation is valid free it.</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>pAllocInfo</span><span>-&gt;</span><span>address</span><span> </span><span>!=</span><span> </span><span>NULL</span><span>)</span></p><p><span>	</span><span>{</span></p><p><span>		</span><span>// Free the allocation.</span></p><p><span>		</span><span>MmFreeContiguousMemory</span><span>(</span><span>pAllocInfo</span><span>-&gt;</span><span>address</span><span>)</span><span>;</span></p><p><span>		</span><span>pAllocInfo</span><span>-&gt;</span><span>address</span><span> </span><span>=</span><span> </span><span>NULL</span><span>;</span></p><p><span>	</span><span>}</span></p><p><span>}</span></p></div></td>
					</tr>
				</tbody></table>
			</div>



<h4>Visualizing the results</h4>



<p>That was a lot of work but the results are well worth it. As I mentioned earlier the only way to get the game to run in 720p or higher is with a RAM upgrade. Even running the game in proper 480p on a console without the RAM upgrade requires stealing memory back from the game to offset the additional memory requirements, which exacerbates the texture pop-in issues that are prevalent even in the game’s unmodified form. I’ve rambled on about memory management enough, here’s what the game looks like in 720p:</p>



<div><figure><a href="https://icode4.coffee/wp-content/uploads/halo_2_720p.png" target="_blank" rel="noopener"><img loading="lazy" width="1280" height="720" src="https://icode4.coffee/wp-content/uploads/halo_2_720p.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/halo_2_720p.png 1280w, https://icode4.coffee/wp-content/uploads/halo_2_720p-300x169.png 300w, https://icode4.coffee/wp-content/uploads/halo_2_720p-768x432.png 768w" sizes="(max-width: 1280px) 100vw, 1280px"></a><figcaption>Zanzibar beach in 720p</figcaption></figure></div>



<p>It looks great! But it doesn’t play great… The FPS is noticeably lower to the point where it’s dipping to 10 FPS or lower in heavy scenes. While I was expecting a performance hit I wasn’t expecting it to be this bad, but that’s okay because there’s things we can do to improve this quite a bit. Before that, lets give 1080p a try and see what it looks like. Remember that while the game is rendering natively in 1080p the Xbox console is only able to output a 1080i video signal. However, by dumping the D3D back buffer directly I’m able to get a proper 1080p screenshot before the GPU converts it into half frames for the video encoder to display on screen:</p>



<div><figure><a href="https://icode4.coffee/wp-content/uploads/1080p_zanzibar.png" target="_blank" rel="noopener"><img loading="lazy" width="1920" height="1080" src="https://icode4.coffee/wp-content/uploads/1080p_zanzibar-1920x1080.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/1080p_zanzibar.png 1920w, https://icode4.coffee/wp-content/uploads/1080p_zanzibar-300x169.png 300w, https://icode4.coffee/wp-content/uploads/1080p_zanzibar-768x432.png 768w, https://icode4.coffee/wp-content/uploads/1080p_zanzibar-1536x864.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px"></a><figcaption>Zanzibar beach in 1080p</figcaption></figure></div>



<h4>Unforeseen consequences</h4>



<p>Okay so this kernel hot patching does have some undesirable side effects which is understandable since I just changed a pretty crucial aspect of how memory management works mid-execution. Hot patching the kernel and letting Halo 2 run works fine until you exit the game without cold rebooting the console. If you do a warm reboot (returning to the dashboard, ejecting the dvd tray, etc) the console is basically “hosed” and the next application/game to run will have severe graphical artifacting, and the console will most likely crash shortly after. This is likely because there’s more changes required to expand the physical memory region outside of the single change I made. I have some theories as to what the remaining issues are but having spent a significant amount of time on memory management patches I decided to take the cop out solution here. To make this more “robust” I added additional patches that would cold reboot the console (which reloads the kernel) whenever you exit the game so all of the side effects of this hot patching are hidden from the end user. This would prove useful later on as there’s additional changes I make that really should be reset after exiting the game and cold rebooting the console solves all of this.</p>



<h2>Part 3: Performance Improvements and Overclocking</h2>



<p>Now that the game is rendering in 720p and 1080p it’s time to address the performance issues and make it playable, at least in 720p. Adding 1080p support is really just a bonus to get nice screenshots and I have no expectations that the console will be able to run the game at that resolution and be “playable”, regardless of what performance improvements I can make. The first step was to get some baseline performance measurements on a stock Xbox console and the god box that doom sent me. The god box also had two different BIOS images, one that overclocked just the CPU, and one that overclocked both CPU and GPU. This would let me get three different measurements: one for stock hardware (no overclocking), one for CPU overclocking, and one for CPU + GPU overclocking. From these measurements I could determine where the performance bottlenecks were and start from there.</p>



<p>I found a particularly heavy area on Zanzibar that I’ll refer to as the “zanzibar benchmark scene”, which was a decent test case for performance benchmarks. While collecting the performance measurements I immediately realized that the FPS between all three setups was almost identical when under heavy load which was extremely suspicious. If overclocking the CPU and GPU show no improvement in performance then the bottleneck was certainly elsewhere. My first thought was I might be maxing the memory bandwidth now that the GPU has a lot more pixel calculations to do and thus a lot more memory to read and write. However, after spending a few nights running tests and bouncing ideas off doom I realized I’d overlooked something very obvious while staring at a performance graph.</p>



<div><figure><a href="https://icode4.coffee/wp-content/uploads/stock_perf_double_buffer-2.png" target="_blank" rel="noopener"><img loading="lazy" width="1920" height="961" src="https://icode4.coffee/wp-content/uploads/stock_perf_double_buffer-2-1920x961.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/stock_perf_double_buffer-2-1920x961.png 1920w, https://icode4.coffee/wp-content/uploads/stock_perf_double_buffer-2-300x150.png 300w, https://icode4.coffee/wp-content/uploads/stock_perf_double_buffer-2-768x384.png 768w, https://icode4.coffee/wp-content/uploads/stock_perf_double_buffer-2-1536x769.png 1536w, https://icode4.coffee/wp-content/uploads/stock_perf_double_buffer-2-2048x1025.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a><figcaption>Performance graph for stock console at 720p (double buffered)</figcaption></figure></div>



<p>This graph shows GPU use (yellow), CPU use (red), frames per second (blue), and swap stall rate (teal). Initially I didn’t know what “swap stall” was and I couldn’t find any documentation about it in the Xbox SDK docs. But after I realized the game was running with vsync on it made perfect sense, swap stall = swap chain stall, the GPU was stalling because the swap chain was full and vsync was on.</p>



<h4>VSync and swap chains</h4>



<p>Halo 2 runs with vsync on and uses double buffering so it only has 2 buffers in the swap chain (one front buffer and one back buffer). The back buffer is used by the GPU to render the current frame while the front buffer is the previous frame that was rendered and is now being displayed on screen. When the GPU finishes drawing the current frame it needs to swap the back and front buffers (or rotate the swap chain) so the newly completed frame can be drawn on screen and the old one can be used by the GPU for the next frame. But when vsync is on the GPU can only rotate the swap chain at the start of a vertical blanking (vblank) period (when the TV retraces to the top and starts drawing the image from the beginning). If you turn vsync off the GPU can rotate the swap chain at any time, but if the front buffer is only partially displayed on screen when you rotate the swap chain it’ll result in a “tearing” effect on screen (hence why you want vsync on as it prevents this).</p>



<p>The swap stall line in the graph above is the rate at which the GPU had to stall and wait for a vblank period in order to rotate the swap chain. Basically, the GPU isn’t able to render frames fast enough to keep up with the refresh rate of the screen and it ends up having to wait until the next screen refresh to rotate the swap chain. In hindsight this seems so obvious but at the time I was preoccupied with all the hardware modifications I completely forgot about vsync.</p>



<h2>From double to triple buffering</h2>



<p>This is relative easy to fix as we can just increase the number of buffers in the swap chain to 3 which allows us to queue a completed frame and immediately begin processing the next frame, even if the GPU needs to wait for the next vblank before rotating the swap chain. Here’s the updated pseudo code for the rasterizer_device_initialize hook:</p>



<div id="urvanov-syntax-highlighter-662143868a30f384347295" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p><p>28</p><p>29</p><p>30</p><p>31</p><p>32</p><p>33</p><p>34</p><p>35</p><p>36</p><p>37</p><p>38</p><p>39</p><p>40</p></div>
				</td>
						<td><div><p><span>bool</span><span> </span><span>rasterizer_device_initialize</span><span>(</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>	</span><span>D3DPRESENT_PARAMETERS </span><span>PresentParams</span><span> </span><span>=</span><span> </span><span>{</span><span>0</span><span>}</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>BackBufferWidth</span><span> </span><span>=</span><span> </span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>x1</span><span> </span><span>-</span><span> </span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>x0</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>BackBufferHeight</span><span> </span><span>=</span><span> </span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>y1</span><span> </span><span>-</span><span> </span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>y1</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>BackBufferFormat</span><span> </span><span>=</span><span> </span><span>D3DFMT_A8R8G8B8</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>EnableAutoDepthStencil</span><span> </span><span>=</span><span> </span><span>TRUE</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>AutoDepthStencilFormat</span><span> </span><span>=</span><span> </span><span>D3DFMT_D24S8</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>Flags</span><span> </span><span>=</span><span> </span><span>D3DPRESENTFLAG_LOCKABLE_BACKBUFFER</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>FullScreen_RefreshRateInHz</span><span> </span><span>=</span><span> </span><span>g_refresh_rate_hz</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>FullScreen_PresentationInterval</span><span> </span><span>=</span><span> </span><span>D3DPRESENT_INTERVAL_IMMEDIATE</span><span>;</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>	</span><span>// Setup back buffer count and swap effect for triple buffering.</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>BackBufferCount</span><span> </span><span>=</span><span> </span><span>2</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>SwapEffect</span><span> </span><span>=</span><span> </span><span>D3DSWAPEFFECT_DISCARD</span><span>;</span></p><p><span>	</span><span>PresentParams</span><span>.</span><span>PresentationInterval</span><span> </span><span>=</span><span> </span><span>D3DPRESENT_INTERVAL_ONE</span><span>;</span></p><p><span>	</span><span>// Check if wide screen mode is enabled.</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>g_widescreen_enabled</span><span> </span><span>!=</span><span> </span><span>0</span><span>)</span></p><p><span>		</span><span>PresentParams</span><span>.</span><span>Flags</span><span> </span><span>|=</span><span> </span><span>D3DPRESENTFLAG_WIDESCREEN</span><span>;</span></p><p><span>	</span><span>// Check if the video mode supports progressive scan.</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>g_progressive_scan_enabled</span><span> </span><span>!=</span><span> </span><span>0</span><span>)</span></p><p><span>		</span><span>PresentParams</span><span>.</span><span>Flags</span><span> </span><span>|=</span><span> </span><span>D3DPRESENTFLAG_PROGRESSIVE</span><span>;</span></p><p><span>	</span><span>// Check the resolution width to see if 1080i is enabled.</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>rasterizer_globals</span><span>.</span><span>screen_bounds</span><span>.</span><span>x1</span><span> </span><span>==</span><span> </span><span>1920</span><span>)</span></p><p><span>	</span><span>{</span></p><p><span>		</span><span>PresentParams</span><span>.</span><span>Flags</span><span> </span><span>&amp;=</span><span> </span><span>~</span><span>D3DPRESENTFLAG_PROGRESSIVE</span><span>;</span></p><p><span>		</span><span>PresentParams</span><span>.</span><span>Flags</span><span> </span><span>|=</span><span> </span><span>D3DPRESENTFLAG_INTERLACED</span><span>;</span></p><p><span>	</span><span>}</span></p><p><span>	</span><span>g_pDirect3D</span><span>-&gt;</span><span>CreateDevice</span><span>(</span><span>0</span><span>,</span><span> </span><span>D3DDEVTYPE_HAL</span><span>,</span><span> </span><span>NULL</span><span>,</span><span> </span><span>D3DCREATE_HARDWARE_VERTEXPROCESSING</span><span>,</span><span> </span><span>&amp;</span><span>PresentParams</span><span>,</span><span> </span><span>&amp;</span><span>g_pD3DDevice</span><span>)</span><span>;</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>}</span></p></div></td>
					</tr>
				</tbody></table>
			</div>



<p>Here I’ve increased the back buffer count to 2 (default is 1), and set the swap effect such that the swap chain will be rotated on each present call. This will give us 3 buffers to work with (2 back and 1 front), but we’ll need to make another modification to the game’s rendering engine to account for this additional buffer. Earlier when I was going through the process of resizing the game’s render targets I showed some code for how the game sets up texture views for the back and front buffers for use in rendering passes:</p>



<div id="urvanov-syntax-highlighter-662143868a312449942468" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p></div>
				</td>
						<td><div><p><span>bool</span><span> </span><span>rasterizer_primary_targets_initialize</span><span>(</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>// Get the back buffer, front buffer, and depth buffer surfaces.</span></p><p><span>	</span><span>global_d3d_device</span><span>-&gt;</span><span>GetBackBuffer</span><span>(</span><span>0</span><span>,</span><span> </span><span>D3DBACKBUFFER_TYPE_MONO</span><span>,</span><span> </span><span>&amp;</span><span>global_d3d_surface_render_primary</span><span>[</span><span>0</span><span>]</span><span>)</span><span>;</span></p><p><span>	</span><span>global_d3d_device</span><span>-&gt;</span><span>GetBackBuffer</span><span>(</span><span>-</span><span>1</span><span>,</span><span> </span><span>D3DBACKBUFFER_TYPE_MONO</span><span>,</span><span> </span><span>&amp;</span><span>global_d3d_surface_render_primary</span><span>[</span><span>1</span><span>]</span><span>)</span><span>;</span></p><p><span>	</span><span>global_d3d_device</span><span>-&gt;</span><span>GetDepthStencilSurface</span><span>(</span><span>&amp;</span><span>global_d3d_surface_render_primary_z</span><span>)</span><span>;</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>	</span><span>global_d3d_texture_render_primary</span><span>[</span><span>0</span><span>]</span><span> </span><span>=</span><span> </span><span>(</span><span>IDirect3DTexture8</span><span>*</span><span>)</span><span>malloc</span><span>(</span><span>sizeof</span><span>(</span><span>IDirect3DTexture8</span><span>)</span><span>)</span><span>;</span></p><p><span>	</span><span>global_d3d_texture_render_primary</span><span>[</span><span>1</span><span>]</span><span> </span><span>=</span><span> </span><span>(</span><span>IDirect3DTexture8</span><span>*</span><span>)</span><span>malloc</span><span>(</span><span>sizeof</span><span>(</span><span>IDirect3DTexture8</span><span>)</span><span>)</span><span>;</span></p><p><span>	</span><span>// Setup texture views for back/front buffers.</span></p><p><span>	</span><span>for</span><span> </span><span>(</span><span>int</span><span> </span><span>i</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span><span> </span><span>i</span><span> </span><span>&lt;</span><span> </span><span>2</span><span>;</span><span> </span><span>i</span><span>++</span><span>)</span></p><p><span>	</span><span>{</span></p><p><span>		</span><span>XGSetTextureHeader</span><span>(</span><span>640</span><span>,</span><span> </span><span>480</span><span>,</span><span> </span><span>1</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span><span>D3DFMT_LIN_A8R8G8B8</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span></p><p><span>			</span><span>global_d3d_texture_render_primary</span><span>[</span><span>i</span><span>]</span><span>,</span><span> </span><span>global_d3d_surface_render_primary</span><span>[</span><span>i</span><span>]</span><span>-&gt;</span><span>Data</span><span>,</span><span> </span><span>0</span><span>)</span><span>;</span></p><p><span>	</span><span>}</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>}</span></p></div></td>
					</tr>
				</tbody></table>
			</div>



<p>Each frame after the game calls Present() it’ll swap the Data field in global_d3d_surface_render_primary[0]/[1] and global_d3d_texture_render_primary[0]/[1] so they point to the correct memory for the new back and front buffers. This works fine when the game is double buffered but now that we introduced a third buffer into the swap chain we’ll need to account for this after the game calls Present(). We’ll also need to update the rasterizer_primary_targets_initialize hook from earlier to initialize these buffers correctly before the first frame is drawn. Here is the pseudo code for these functions:</p>



<div id="urvanov-syntax-highlighter-662143868a315969332592" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p><p>28</p><p>29</p><p>30</p><p>31</p><p>32</p><p>33</p><p>34</p><p>35</p><p>36</p><p>37</p><p>38</p><p>39</p><p>40</p><p>41</p><p>42</p><p>43</p><p>44</p><p>45</p><p>46</p><p>47</p></div>
				</td>
						<td><div><p><span>void</span><span> </span><span>Hook_IDirect3DDevice8_Swap</span><span>(</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>// Call the trampoline and let the real function run.</span></p><p><span>	</span><span>IDirect3DDevice8_Swap_trampoline</span><span>(</span><span>)</span><span>;</span></p><p><span>	</span><span>// Check if triple buffering is enable.</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>Hack_TripleBufferingEnabled</span><span> </span><span>==</span><span> </span><span>false</span><span>)</span></p><p><span>		</span><span>return</span><span>;</span></p><p><span>	</span><span>// Release references to the old back buffer.</span></p><p><span>	</span><span>global_d3d_surface_render_primary</span><span>[</span><span>0</span><span>]</span><span>-&gt;</span><span>Release</span><span>(</span><span>)</span><span>;</span></p><p><span>	</span><span>global_d3d_surface_render_primary</span><span>[</span><span>1</span><span>]</span><span>-&gt;</span><span>Release</span><span>(</span><span>)</span><span>;</span></p><p><span>	</span><span>// Get the new back buffer and increment the reference count twice.</span></p><p><span>	</span><span>global_d3d_device</span><span>-&gt;</span><span>GetBackBuffer</span><span>(</span><span>0</span><span>,</span><span> </span><span>D3DBACKBUFFER_TYPE_MONO</span><span>,</span><span> </span><span>&amp;</span><span>global_d3d_surface_render_primary</span><span>[</span><span>0</span><span>]</span><span>)</span><span>;</span></p><p><span>	</span><span>global_d3d_device</span><span>-&gt;</span><span>GetBackBuffer</span><span>(</span><span>0</span><span>,</span><span> </span><span>D3DBACKBUFFER_TYPE_MONO</span><span>,</span><span> </span><span>&amp;</span><span>global_d3d_surface_render_primary</span><span>[</span><span>1</span><span>]</span><span>)</span><span>;</span></p><p><span>	</span><span>// Update the Data field for the back buffer textures.</span></p><p><span>	</span><span>global_d3d_texture_render_primary</span><span>[</span><span>0</span><span>]</span><span>-&gt;</span><span>Data</span><span> </span><span>=</span><span> </span><span>global_d3d_surface_render_primary</span><span>[</span><span>0</span><span>]</span><span>-&gt;</span><span>Data</span><span>;</span></p><p><span>	</span><span>global_d3d_texture_render_primary</span><span>[</span><span>1</span><span>]</span><span>-&gt;</span><span>Data</span><span> </span><span>=</span><span> </span><span>global_d3d_surface_render_primary</span><span>[</span><span>0</span><span>]</span><span>-&gt;</span><span>Data</span><span>;</span></p><p><span>}</span></p><p><span>bool</span><span> </span><span>Hook_rasterizer_primary_targets_initialize</span><span>(</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>// Call the trampoline and let the real function complete.</span></p><p><span>	</span><span>bool</span><span> </span><span>result</span><span> </span><span>=</span><span> </span><span>rasterizer_primary_targets_initialize_trampoline</span><span>(</span><span>)</span><span>;</span></p><p><span>	</span><span>// Check if triple buffering is enabled.</span></p><p><span>	</span><span>if</span><span> </span><span>(</span><span>Hack_TripleBufferingEnabled</span><span> </span><span>!=</span><span> </span><span>true</span><span>)</span></p><p><span>	</span><span>{</span></p><p><span>		</span><span>// Set both primary render surfaces to point to the active back buffer.</span></p><p><span>		</span><span>global_d3d_device</span><span>-&gt;</span><span>GetBackBuffer</span><span>(</span><span>0</span><span>,</span><span> </span><span>D3DBACKBUFFER_TYPE_MONO</span><span>,</span><span> </span><span>&amp;</span><span>global_d3d_surface_render_primary</span><span>[</span><span>0</span><span>]</span><span>)</span><span>;</span></p><p><span>		</span><span>global_d3d_device</span><span>-&gt;</span><span>GetBackBuffer</span><span>(</span><span>0</span><span>,</span><span> </span><span>D3DBACKBUFFER_TYPE_MONO</span><span>,</span><span> </span><span>&amp;</span><span>global_d3d_surface_render_primary</span><span>[</span><span>1</span><span>]</span><span>)</span><span>;</span></p><p><span>		</span><span>// Update the Data field for the back buffer textures.</span></p><p><span>		</span><span>global_d3d_texture_render_primary</span><span>[</span><span>0</span><span>]</span><span>-&gt;</span><span>Data</span><span> </span><span>=</span><span> </span><span>global_d3d_surface_render_primary</span><span>[</span><span>0</span><span>]</span><span>-&gt;</span><span>Data</span><span>;</span></p><p><span>		</span><span>global_d3d_texture_render_primary</span><span>[</span><span>1</span><span>]</span><span>-&gt;</span><span>Data</span><span> </span><span>=</span><span> </span><span>global_d3d_surface_render_primary</span><span>[</span><span>0</span><span>]</span><span>-&gt;</span><span>Data</span><span>;</span></p><p><span>	</span><span>}</span></p><p><span>	</span><span>// Update the dimensions of the surface/textures created to match the resolution of the back buffer.</span></p><p><span>	</span><span>Hack_UpdateD3dPixelContainerForScreenResolution</span><span>(</span><span>global_d3d_texture_render_primary</span><span>[</span><span>0</span><span>]</span><span>)</span><span>;</span></p><p><span>	</span><span>Hack_UpdateD3dPixelContainerForScreenResolution</span><span>(</span><span>global_d3d_texture_render_primary</span><span>[</span><span>1</span><span>]</span><span>)</span><span>;</span></p><p><span>	</span><span>Hack_UpdateD3dPixelContainerForScreenResolution</span><span>(</span><span>global_d3d_texture_z_as_target</span><span>[</span><span>0</span><span>]</span><span>)</span><span>;</span></p><p><span>	</span><span>Hack_UpdateD3dPixelContainerForScreenResolution</span><span>(</span><span>global_d3d_texture_z_as_target</span><span>[</span><span>1</span><span>]</span><span>)</span><span>;</span></p><p><span>	</span><span>return</span><span> </span><span>result</span><span>;</span></p><p><span>}</span></p></div></td>
					</tr>
				</tbody></table>
			</div>



<p>With this change global_d3d_surface_render_primary[0]/[1] and global_d3d_texture_render_primary[0]/[1] will always reference the current back buffer. After the Swap hook returns the game will still swap global_d3d_surface_render_primary[0]/[1] and global_d3d_texture_render_primary[0]/[1] internally but this is basically a no-op since they point to the same underlying memory. Now, you might be thinking global_d3d_surface_render_primary[1] is supposed to point to the front buffer per the game’s original implementation, so what happens now that global_d3d_surface_render_primary[1] always points to the back buffer? And the answer, is nothing. The game never used the front buffer because it can’t do anything meaningful with it while it’s being drawn to screen. It only held the pointer so it could swap the surfaces every frame. With these changes in place I loaded up the Zanzibar benchmark scene and collected some new performance measurements:</p>



<figure><a href="https://icode4.coffee/wp-content/uploads/stock_perf_triple_buffer-1.png" target="_blank" rel="noopener"><img loading="lazy" width="1920" height="962" src="https://icode4.coffee/wp-content/uploads/stock_perf_triple_buffer-1-1920x962.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/stock_perf_triple_buffer-1-1920x962.png 1920w, https://icode4.coffee/wp-content/uploads/stock_perf_triple_buffer-1-300x150.png 300w, https://icode4.coffee/wp-content/uploads/stock_perf_triple_buffer-1-768x385.png 768w, https://icode4.coffee/wp-content/uploads/stock_perf_triple_buffer-1-1536x769.png 1536w, https://icode4.coffee/wp-content/uploads/stock_perf_triple_buffer-1-2048x1026.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a><figcaption>Performance graph for stock console at 720p (triple buffered)</figcaption></figure>



<p>As we can see the swap stall line is gone and the FPS is sitting at ~22 which is +~3 FPS higher than before. You might be thinking that a 3 FPS increase isn’t really much but when the game is capped at 30 FPS this is actually a 10% increase which is pretty nice. Also remember that the main goal here was to eliminate the swap stall which prevented the GPU from running as fast as it could. Looking at the graph some more we can see the GPU is now maxed! This might seem bad but we now know the GPU is the bottleneck. We’re still running on stock GPU clock speed and once we overclock the GPU the performance should increase quite a bit.</p>



<h2>Overclocking the GPU</h2>



<p>I spent a few nights digging through some PIX traces, running tests, and trying to find any other low hanging fruit for cheap performance gains. I was able to get another +1-2 FPS by tiling the texaccum render target but it seemed like that was all I was going to get for cheap gains. There’s one or two ideas I had that might get some performance increase but they required a decent amount of changes and I wasn’t sure if the end result would even get me a 1 FPS increase, so I decided to leave it alone and maybe loop back on it another day. With the changes to tile the texaccum render target the Zanzibar benchmark scene was sitting at 23-24 FPS which was a solid improvement over the original ~19 FPS. Now it was time to turn to overclocking, and running the Zanzibar benchmark scene on the god box with overclocked GPU gave a solid 27-28 FPS. Running around the map felt smooth and the FPS was typically holding at a steady 30 FPS, though there were still some areas (like the benchmark scene) where the FPS would drop. Overall I considered it to be highly playable and was relatively satisfied with the results. </p>



<p>The only problem is that the god box is running a one-off bespoke BIOS image that doom made for it. While the GPU overclocking settings could be patched into other community BIOS images it wouldn’t be great if the requirement to run this HD patch was “patch your BIOS image and reflash it to your console”. Luckily I wouldn’t have to resort to that because the GPU clock generator can be controlled entirely by memory mapped IO registers. Using these registers you can control the coefficients for the clock generator and change the clock speed on the fly. So for this next patch I’m going to have the game dynamically overclock the GPU on startup.</p>



<h4>Adjusting the clock speed</h4>



<p>The clock signal for the GPU is calculated as follows:</p>



<div id="urvanov-syntax-highlighter-662143868a319551302372" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p>NVPLL_COEFF (32 bits):</p><p>	Bits 0-7: M</p><p>	Bits 8-15: N</p><p>	Bits 16-18: P</p><p>BASE_CLK = 16.6667 Mhz</p><p>nvclk = (N * BASE_CLK / (1 &lt;&lt; P) / M)</p></div></td>
					</tr>
				</tbody></table>
			</div>



<p>The M and P values are set to 1 by default, and BASE_CLK is always 16.6667 Mhz which is sourced from a crystal on the motherboard. So the formula can be shortened to: (N * 16.6667) / 2. We’ll be modifying the N component which is set to 28 by default for a GPU clock speed of 233.33 Mhz. This will let us step the clock speed in increments of ~8 Mhz which I made configurable via an ini file that the patch loads on startup. The pseudo code for overclocking the GPU looks like this:</p>



<div id="urvanov-syntax-highlighter-662143868a31c754659487" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p></div>
				</td>
						<td><div><p><span>void</span><span> </span><span>Util_OverclockGPU</span><span>(</span><span>int</span><span> </span><span>step</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>/*</span></p><p><span>		NVPLL_COEFF (32 bits):</span></p><p><span>			Bits 0-7: M</span></p><p><span>			Bits 8-15: N</span></p><p><span>			Bits 16-18: P</span></p><p><span>		BASE_CLK = 16.6667 Mhz</span></p><p><span>		nvclk = (N * BASE_CLK / (1 &lt;&lt; P) / M)</span></p><p><span>	*/</span></p><p><span>	</span><span>// Read the current clock config from the NVPLL_COEFF register.</span></p><p><span>	</span><span>DWORD </span><span>clockConfig</span><span> </span><span>=</span><span> </span><span>*</span><span>(</span><span>DWORD</span><span>*</span><span>)</span><span>(</span><span>NV_GPU_BASE_ADDRESS</span><span> </span><span>+</span><span> </span><span>NVPLL_COEFF</span><span>)</span><span>;</span></p><p><span>	</span><span>// Mask out the old N value.</span></p><p><span>	</span><span>clockConfig</span><span> </span><span>&amp;=</span><span> </span><span>~</span><span>0xFF00</span><span>;</span></p><p><span>	</span><span>// Mask in the new N value.</span></p><p><span>	</span><span>clockConfig</span><span> </span><span>|=</span><span> </span><span>(</span><span>(</span><span>step</span><span> </span><span>&amp;</span><span> </span><span>0xFF</span><span>)</span><span> </span><span>&lt;&lt;</span><span> </span><span>8</span><span>)</span><span>;</span></p><p><span>	</span><span>// Write the new NVPLL_COEFF value.</span></p><p><span>	</span><span>*</span><span>(</span><span>DWORD</span><span>*</span><span>)</span><span>(</span><span>NV_GPU_BASE_ADDRESS</span><span> </span><span>+</span><span> </span><span>NVPLL_COEFF</span><span>)</span><span> </span><span>=</span><span> </span><span>clockConfig</span><span>;</span></p><p><span>}</span></p></div></td>
					</tr>
				</tbody></table>
			</div>



<p>That’s it, the GPU is now overclocked. Kind of lack luster I know, but you’re probably wondering how far can we overclock the GPU? And what does the new performance graph look like?</p>



<div><figure><a href="https://icode4.coffee/wp-content/uploads/oc_perf_triple_buffer.png" target="_blank" rel="noopener"><img loading="lazy" width="1920" height="961" src="https://icode4.coffee/wp-content/uploads/oc_perf_triple_buffer-1920x961.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/oc_perf_triple_buffer-1920x961.png 1920w, https://icode4.coffee/wp-content/uploads/oc_perf_triple_buffer-300x150.png 300w, https://icode4.coffee/wp-content/uploads/oc_perf_triple_buffer-768x384.png 768w, https://icode4.coffee/wp-content/uploads/oc_perf_triple_buffer-1536x769.png 1536w, https://icode4.coffee/wp-content/uploads/oc_perf_triple_buffer-2048x1025.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a><figcaption>Performance graph for 300Mhz GPU OC at 720p (triple buffered)</figcaption></figure></div>



<p>With the GPU overclocked to 300 Mhz (up from 233.33 Mhz stock) there’s a solid 3 FPS increase in performance in the Zanzibar benchmark scene compared to stock GPU clock speed. This doesn’t seem very impressive but remember this is the “benchmark” test, it was chosen because it puts a massive load on the GPU. Outside of this area there’s a noticeable increase in FPS and running around Zanzibar the game stays at 30 FPS most of the time, dipping slightly in a few heavy areas. So how far can we push the GPU? More speed better performance, right? </p>



<p>Semiconductor fabrication is not a perfect process and every chip has imperfections in it. While every GPU that made it into an Xbox console has minimum functional and quality requirements it had to meet, the maximum capabilities of each chip varies greatly. A lot of the GPUs in the 1.0-1.4 revision consoles are on the weaker end and seem to cap out in the low 300 Mhz range, while the GPUs in the 1.6 revision consoles have been able to go upwards of 400 Mhz stable. That’s almost a 100% increase in clock speed which is very impressive, but this won’t really improve the FPS much more (or so I think). There’s another bottleneck here, and one that can’t easily be worked around.</p>



<h4>Another chip, another clock…</h4>



<p>I spent a large amount of time throughout this project wondering if part of the bottleneck issue was memory bandwidth. There’s a number of articles in the Xbox SDK docs that go into great detail about the hardware in the console, the rendering pipeline, and all the gotchas you can hit that will hurt your game’s performance. There’s a number of times that memory bandwidth is mentioned and it seems the engineers believed you could max the memory bus bandwidth fairly easily. The bus has a theoretical maximum throughput of 6.4GB/s but only about 70% of that is usable in practice, for a practical max throughput of ~4.5GB/s. I captured a number of PIX traces on the game and the estimated memory usage for a single frame was never higher than low 40MBs. No matter how I ran the numbers I just could not see the memory bus bandwidth being maxed out. In my most generous calculation I estimated max throughput of 4GB/s / 30 FPS = ~135MB/frame. Even if we assume the CPU is consuming something like 50MBs that still gives ~80MBs for GPU data. Yeah 1280×720 is a lot of pixels but this would mean each frame is accessing more data than there is RAM on the console, and it was just hard to believe. However, I know very little in this area and it was very well possible that one of these numbers was off (perhaps PIX?). The engineers certainly believed it was possible so I was most likely missing or misunderstanding something.</p>



<p>Doom suggested I try increasing the RAM clock speed and see if FPS increases, which would indicate that memory is the likely bottleneck. The only problem is the RAM is already clocked at the practical maximum frequency of 200Mhz so you can only increase the speed by about ~10Mhz before it becomes unstable and the console crashes. After running some calculations I wrote the following snippet of code to change the memory clock speed:</p>



<div id="urvanov-syntax-highlighter-662143868a31e597178597" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p><p>28</p><p>29</p><p>30</p><p>31</p><p>32</p></div>
				</td>
						<td><div><p><span>void</span><span> </span><span>OverclockRAM</span><span>(</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>DWORD </span><span>MPLLCoeff</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></p><p><span>	</span><span>// Read CR_CPU_MPLL_COEFF</span></p><p><span>	</span><span>HalReadWritePCISpace</span><span>(</span><span>0</span><span>,</span><span> </span><span>0x60</span><span>,</span><span> </span><span>0x6C</span><span>,</span><span> </span><span>&amp;</span><span>MPLLCoeff</span><span>,</span><span> </span><span>sizeof</span><span>(</span><span>MPLLCoeff</span><span>)</span><span>,</span><span> </span><span>0</span><span>)</span><span>;</span></p><p><span>	</span><span>/*</span></p><p><span>		CR_CPU_MPLL_COEFF</span></p><p><span>			Bits 0-7: M</span></p><p><span>			Bits 8-15: N</span></p><p><span>			Bits 16-19: FSB_P</span></p><p><span>			Bits 20-23: MEM_P</span></p><p><span>		BASE_CLK = 16.6667 Mhz</span></p><p><span>		VCOFreq = (BASE_CLK / M) * FSB_P * 2 * N</span></p><p><span>		MEMCLK = VCOFreq / (2 * MEM_P)</span></p><p><span>	*/</span></p><p><span>	</span><span>// M/N values for 208 Mhz MEMCLK:</span></p><p><span>	</span><span>DWORD</span><span> </span><span>M</span><span> </span><span>=</span><span> </span><span>3</span><span>;</span></p><p><span>	</span><span>DWORD</span><span> </span><span>N</span><span> </span><span>=</span><span> </span><span>25</span><span>;</span></p><p><span>	</span><span>// Update PLL coefficients.</span></p><p><span>	</span><span>MPLLCoeff</span><span> </span><span>=</span><span> </span><span>(</span><span>MPLLCoeff</span><span> </span><span>&amp;</span><span> </span><span>~</span><span>0xFF</span><span>)</span><span> </span><span>|</span><span> </span><span>(</span><span>M</span><span> </span><span>&amp;</span><span> </span><span>0xFF</span><span>)</span><span>;</span></p><p><span>	</span><span>MPLLCoeff</span><span> </span><span>=</span><span> </span><span>(</span><span>MPLLCoeff</span><span> </span><span>&amp;</span><span> </span><span>~</span><span>0xFF00</span><span>)</span><span> </span><span>|</span><span> </span><span>(</span><span>(</span><span>N</span><span> </span><span>&amp;</span><span> </span><span>0xFF</span><span>)</span><span> </span><span>&lt;&lt;</span><span> </span><span>8</span><span>)</span><span>;</span></p><p><span>	</span><span>// Update PPL value.</span></p><p><span>	</span><span>HalReadWritePCISpace</span><span>(</span><span>0</span><span>,</span><span> </span><span>0x60</span><span>,</span><span> </span><span>0x6C</span><span>,</span><span> </span><span>&amp;</span><span>MPLLCoeff</span><span>,</span><span> </span><span>sizeof</span><span>(</span><span>MPLLCoeff</span><span>)</span><span>,</span><span> </span><span>1</span><span>)</span><span>;</span></p><p><span>}</span></p></div></td>
					</tr>
				</tbody></table>
			</div>



<p>The M and N values above are chosen such that the resulting memory clock speed will be ~208 Mhz. I could adjust them some more and get closer to 210 Mhz but this was good enough to test. With these changes in place I booted up Halo 2, loaded up the Zanzibar benchmark scene and watched the perf monitor. I ran this test a number of times with and without the memory overclocking and the result was a solid 0.7 FPS increase when the memory overclocking was active. These test results aren’t conclusive but they’re definitely compelling. </p>



<p>There’s different RAM chips that work on the Xbox console and have a maximum clock speed of 250 Mhz. I searched around online and placed an order for some, but at the time of writing this I haven’t gotten to installing them or running any further tests. Doom has already tried using these memory chips and said he had trouble getting them above ~230 Mhz while the GPU was overclocked, and that there’s likely another piece to the puzzle to get them running any higher. I wanted to “push the console to the limits” with this patch but I was now 3 months into development of it and needed a break. Ultimately, even if I could get these other RAM chips running close to 250 Mhz I’d more or less be the only person able to utilize it as they’re hard to come by, quite costly, and require removing any existing RAM chips from the console motherboard before installing. With the chips on order I decided to save this experiment for future me and continue on with finishing the patch.</p>



<h2>Reducing pop-in</h2>



<p>Halo 2 had some notoriously bad pop-in issues with textures and geometry and this issue has only been exacerbated on consoles that are still running the original mechanical HDDs from the early 2000s. But now that we have all this extra RAM this should be easy to solve. Earlier I talked about the game making a single large memory allocation of ~48.9MB that I referred to as the “runtime data region”. This memory region is divided up into smaller sections for various subsystems in the game such as network resources, geometry cache, texture cache, sound cache, level data, etc. </p>



<div><figure><a href="https://icode4.coffee/wp-content/uploads/h2_retail_memory_profile.png" target="_blank" rel="noopener"><img loading="lazy" width="1697" height="1080" src="https://icode4.coffee/wp-content/uploads/h2_retail_memory_profile-1697x1080.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/h2_retail_memory_profile-1697x1080.png 1697w, https://icode4.coffee/wp-content/uploads/h2_retail_memory_profile-300x191.png 300w, https://icode4.coffee/wp-content/uploads/h2_retail_memory_profile-768x489.png 768w, https://icode4.coffee/wp-content/uploads/h2_retail_memory_profile-1536x977.png 1536w, https://icode4.coffee/wp-content/uploads/h2_retail_memory_profile-2048x1303.png 2048w, https://icode4.coffee/wp-content/uploads/h2_retail_memory_profile-110x70.png 110w" sizes="(max-width: 1697px) 100vw, 1697px"></a><figcaption>Halo 2 retail memory profile</figcaption></figure></div>



<p>The ones we’re interested in are the texture cache and geometry cache. The geometry cache is given 6.5MB of space for single player maps and 7MB for multiplayer maps. The texture cache size varies and is given all the remaining data after the “tag data” section and before the “low detail texture cache”. The larger the map the smaller the texture cache will be and the more pressure that’ll be put on it (especially for single player maps). These caches are “least recently used” data structures (or “lruv caches” as the game refers to them, not sure what the v is…), and work by evicting the least recently used data after a certain time period has elapsed. Every 30 frames (~1 second) the game will iterate through each cache and evict any data that hasn’t been used in the last 30 frames to free up space. If a request is made to load in data and there’s enough free space in the cache the data is loaded immediately (typically asynchronously, though it can block) and the request is satisfied once the read completes. If the cache is full there’s two code paths that can be taken:</p>



<ol><li>The caller can specify a parameter that indicates they want to force eviction on some other data. In this case the game will iterate through every entry in the cache and forcefully evict the least recently used items until there’s enough free space to satisfy the load request. If those items are currently being displayed on screen they’ll disappear in the next frame (and most likely submit new cache load requests). </li><li>The caller specifies they don’t want to force eviction and the load request fails. The object will not appear on screen this frame and the game will try to load it again next frame.</li></ol>



<p>Almost every call site for a load request falls down code path #2 with very few locations falling down code path #1. This is the first cause of pop-in, a request to load data is made and fails resulting in the object not being displayed on screen at the proper time. When the data is successfully loaded it will “pop” on screen and typically be far enough into the players field of view that they notice it. In the case of texture loads the map file can have up to 3 different texture buffers for low, medium, and high level of detail (LOD) versions of the same image. This is not to be confused with mip maps because each texture LOD will have its own set of mip maps. When a request is made to load in a texture the game will default to using the highest LOD possible, and if the load request fails it will try again using medium and low LOD buffers in hope that they require less memory and the load request may be possible to satisfy without waiting for memory to become available. If a load for a lower LOD version of the texture succeeds the game will attempt to load the highest LOD possible in the next few frames when more memory (hopefully) becomes available. When this happens the texture will be visible immediately at lower detail and then “pop” to higher detail when it becomes available. This is typically noticeable in cut-scenes which have the highest on-demand load requirements compared to normal game play.</p>



<div><figure><a href="https://icode4.coffee/wp-content/uploads/pop_in_fbf.png" target="_blank" rel="noopener"><img loading="lazy" width="1439" height="480" src="https://icode4.coffee/wp-content/uploads/pop_in_fbf.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/pop_in_fbf.png 1439w, https://icode4.coffee/wp-content/uploads/pop_in_fbf-300x100.png 300w, https://icode4.coffee/wp-content/uploads/pop_in_fbf-768x256.png 768w" sizes="(max-width: 1439px) 100vw, 1439px"></a><figcaption>Master chief texture popping from low to high LOD</figcaption></figure></div>



<h4>Using cache eviction to find super bounces</h4>



<p>One additional note is that each map file also contains a “low detail texture cache” which contains an “emergency” version of almost every bitmap the map uses, in sizes from 2×2 pixels to at largest 8×8 pixels, which is always resident in memory while playing. This is used in cases where a model is present in memory but the load request for the texture(s) failed at all LODs. In this scenario there would normally be no textures to render the model with but the emergency low detail texture cache can be used temporarily to get the model on screen until the normal texture can be loaded into memory. Back in the Xbox Live days of Halo 2 there used to be a “glitch” where if you pulled up the Xbox Live friends menu and then closed it the level geometry would be rendered with extremely low detail textures. If you looked closely enough you could see “cracks” in the geometry (really, just where non-co-planar triangles were joined together) that you could try and use for super bounces. This technique was used to find suitable places for performing super bounces and I even remember finding a few myself using this method. It turns out this isn’t actually a “glitch” but the game using the emergency low detail texture cache because the normal textures for geometry were evicted and the geometry needs to be rendered this frame.</p>



<div><figure><a href="https://icode4.coffee/wp-content/uploads/low_detail_textures.png" target="_blank" rel="noopener"><img loading="lazy" width="720" height="480" src="https://icode4.coffee/wp-content/uploads/low_detail_textures.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/low_detail_textures.png 720w, https://icode4.coffee/wp-content/uploads/low_detail_textures-300x200.png 300w" sizes="(max-width: 720px) 100vw, 720px"></a><figcaption>Foundation with low detail textures</figcaption></figure></div>



<h4>Visualizing cache usage</h4>



<p>When I first started adjusting the geometry and texture cache sizes I could definitely see pop-in was being reduced but I didn’t really have any good indication of when the caches were large enough and further tweaks were just redundant. After scraping through every Halo 2 build I had along with the Vista and MCC versions on PC, I was able to find enough info to recreate a debugging feature that Bungie had implemented in their debug builds of the game (this was such a pita). Using this graph visualization I could see exactly how much of the cache memory was being used at any given time which let me fine tune the sizes to what I felt was a pretty good result.</p>



<div><figure><a href="https://icode4.coffee/wp-content/uploads/texture_cache_stock_chief.png" target="_blank" rel="noopener"><img loading="lazy" width="720" height="480" src="https://icode4.coffee/wp-content/uploads/texture_cache_stock_chief.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/texture_cache_stock_chief.png 720w, https://icode4.coffee/wp-content/uploads/texture_cache_stock_chief-300x200.png 300w" sizes="(max-width: 720px) 100vw, 720px"></a><figcaption>Halo 2 Outskirts stock texture cache</figcaption></figure></div>



<p>On the stock version of the game the campaign map Outskirts (old mombasa) has a texture cache size of ~19MB. I chose this map as my test map because the opening cinematic had pretty noticeable pop-in and with the original HDD in the console it could be comically bad at times. The image above shows the texture cache graph visualization. The graph is broken up into pairs of 2 lines. The first line indicates how the memory is being used: gray = free, red = in use high detail, purple = in use medium or lower detail (aka memory pressure), pink = stolen. The second line indicates when the memory was last used: green = in use this frame, blue = in use the last 30 frames. As a side note the game can steal memory from the texture cache for other purposes such as for rasterizer render targets that are only used in cinematic cutscenes, playing the intro/attraction/credits videos, etc. As we can see in the image above master chief is being rendered using the low detail texture cache because the normal texture cache is full and there’s no memory to satisfy the texture load request. Every single texture in the cache is either in use this frame or some time in the last 30 frames. So until enough textures age out and get evicted, master chief will be stuck in low detail.</p>



<div><figure><a href="https://icode4.coffee/wp-content/uploads/texture_cache_stock_sniper.png" target="_blank" rel="noopener"><img loading="lazy" width="720" height="480" src="https://icode4.coffee/wp-content/uploads/texture_cache_stock_sniper.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/texture_cache_stock_sniper.png 720w, https://icode4.coffee/wp-content/uploads/texture_cache_stock_sniper-300x200.png 300w" sizes="(max-width: 720px) 100vw, 720px"></a><figcaption>Halo 2 Outskirts stock texture cache</figcaption></figure></div>



<p>This scene with the sniper team is one of the heavier scenes in the opening cutscene and would often result in model and texture pop-in. We can see from the texture cache graph that almost all of the memory is in use and there’s quite a few textures that are being loaded at medium or lower detail (in purple) due to the memory pressure. I also implemented an almost identical graph view for the geometry cache and using both of these I began to fine tune the cache sizes until the pop-in issues were more or less gone. </p>



<h4>Increasing the cache sizes</h4>



<p>The final result is the geometry cache being increased from 6.5/7MB to 20MB, and the texture cache increased to a static size of 30MB, nearly doubling both caches in size from the stock version of the game. At these sizes I felt the caches had adequate space and texture and model pop-in was more or less resolved. </p>



<div><figure><a href="https://icode4.coffee/wp-content/uploads/texture_cache_upgrade.png" target="_blank" rel="noopener"><img loading="lazy" width="1439" height="480" src="https://icode4.coffee/wp-content/uploads/texture_cache_upgrade.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/texture_cache_upgrade.png 1439w, https://icode4.coffee/wp-content/uploads/texture_cache_upgrade-300x100.png 300w, https://icode4.coffee/wp-content/uploads/texture_cache_upgrade-768x256.png 768w" sizes="(max-width: 1439px) 100vw, 1439px"></a><figcaption>Halo 2 Outskirts upgraded texture cache</figcaption></figure></div>



<p>As we can see the scene where master chief would appear with low detail textures now appears with high detail textures immediately (no more pop-in!) and there’s even plenty of free space in the texture cache. For the sniper scene we can see that in the previous frames all of the cache memory was being utilized, but not all at the same time as there’s plenty of chunks where the texture data has aged out of the cache. However, there were still a few cases where things would pop-in even though there was free space in the caches. To further fix this I ended up adding support to increase the HDD transfer speed from the stock UDMA 2 speed (~33.3MB/s) to UDMA 3 (~44.4MB/s) or UDMA 5 (~100MB/s) if your console had an 80 pin IDE cable. This provided a 10% increase in transfer speeds for consoles running the stock IDE cable and up to a 300% increase (theoretically, the actual transfer speeds depend greatly on the size of data being transferred) for consoles with an upgraded IDE cable. This not only helped with the remaining pop-in issues but greatly reduced loading times for the game as well. At this point I was pretty satisfied with the result.</p>



<h4>The final memory profile</h4>



<p>So after all these changes what does the final memory profile look like for Halo 2 in 720p on a console with 128MB of RAM?</p>



<div><figure><a href="https://icode4.coffee/wp-content/uploads/720p_memory_profile.png" target="_blank" rel="noopener"><img loading="lazy" width="1697" height="1080" src="https://icode4.coffee/wp-content/uploads/720p_memory_profile-1697x1080.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/720p_memory_profile-1697x1080.png 1697w, https://icode4.coffee/wp-content/uploads/720p_memory_profile-300x191.png 300w, https://icode4.coffee/wp-content/uploads/720p_memory_profile-768x489.png 768w, https://icode4.coffee/wp-content/uploads/720p_memory_profile-1536x977.png 1536w, https://icode4.coffee/wp-content/uploads/720p_memory_profile-2048x1303.png 2048w, https://icode4.coffee/wp-content/uploads/720p_memory_profile-110x70.png 110w" sizes="(max-width: 1697px) 100vw, 1697px"></a><figcaption>Halo 2 720p memory profile</figcaption></figure></div>



<p>The geometry and texture caches are now huge, and more than 75% of the available 128MB of RAM has been utilized. For 1080p mode I actually had to dial the geometry and texture cache sizes back a bit as the memory used by the swap chain and rasterizer targets was so large there wasn’t enough memory remaining for the increased caches, and more or less all 128MB of RAM was in use.</p>



<h2>Conclusion</h2>



<p>I wanna thank everyone that took the time to read all the way through this blog post. This is the longest post I’ve written to date and I tried to keep it as short as possible and even cut a bunch of smaller, less interesting things out. I also wanna give a huge thanks to Doom for encouraging me to do this work, providing hardware for testing, and insight into some deep technical areas. This project was a ton of fun to work on and I learned a lot throughout the process. I always wanted to work at Bungie on a game like Halo but never got the chance to do so, and working on this project in some ways felt like I actually got to work on the game. There’s still room for improvement with a lot of the performance and memory changes I made. But overall I feel this HD patch has pushed Halo 2 and the Xbox console to their limits and I’m satisfied with the results without trying to go any further.</p>



<p>You can find the download and source code for the Halo 2 HD patch here: <a rel="noreferrer noopener" href="https://github.com/grimdoomer/Halo-2-HD" data-type="URL" data-id="https://github.com/grimdoomer/Halo-2-HD" target="_blank">GitHub</a></p>



<p>I also made a video showing side-by-side comparisons of the stock game vs the HD patch, and performance metrics for each video resolution:</p>



<figure><p>
<iframe loading="lazy" title="Halo 2 in HD on the Original Xbox" width="470" height="264" src="https://www.youtube.com/embed/O_nk21389u8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p><figcaption>YouTube video showing a comparison between stock game and HD patch</figcaption></figure>
									
																		
								</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My mother declared my bedroom a disaster area (1984) (115 pts)]]></title>
            <link>https://news.lettersofnote.com/p/my-mother-declared-my-bedroom-a-disaster</link>
            <guid>40075598</guid>
            <pubDate>Thu, 18 Apr 2024 12:43:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.lettersofnote.com/p/my-mother-declared-my-bedroom-a-disaster">https://news.lettersofnote.com/p/my-mother-declared-my-bedroom-a-disaster</a>, See on <a href="https://news.ycombinator.com/item?id=40075598">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><em><span>The following exchange can be found in the </span><a href="https://books.lettersofnote.com/products/more-letters-of-note" rel="">second volume of Letters of Note</a><span>. Reprinted by kind permission of the Reagan Library. The picture of Ronald Reagan peering into a child’s messy bedroom—which I’m now realising, as I type, is mildly sinister?—is in fact, believe it or not, two photos mashed together</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-143702151" href="https://news.lettersofnote.com/p/my-mother-declared-my-bedroom-a-disaster#footnote-1-143702151" target="_self" rel="">1</a></span><span>. Both are from Getty who I’m sure won’t mind. </span></em></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F549d7677-b6e0-4c3b-8aa7-8fb95b9d72e7_1000x667.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F549d7677-b6e0-4c3b-8aa7-8fb95b9d72e7_1000x667.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F549d7677-b6e0-4c3b-8aa7-8fb95b9d72e7_1000x667.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F549d7677-b6e0-4c3b-8aa7-8fb95b9d72e7_1000x667.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F549d7677-b6e0-4c3b-8aa7-8fb95b9d72e7_1000x667.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F549d7677-b6e0-4c3b-8aa7-8fb95b9d72e7_1000x667.jpeg" width="1000" height="667" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/549d7677-b6e0-4c3b-8aa7-8fb95b9d72e7_1000x667.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:667,&quot;width&quot;:1000,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:516484,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F549d7677-b6e0-4c3b-8aa7-8fb95b9d72e7_1000x667.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F549d7677-b6e0-4c3b-8aa7-8fb95b9d72e7_1000x667.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F549d7677-b6e0-4c3b-8aa7-8fb95b9d72e7_1000x667.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F549d7677-b6e0-4c3b-8aa7-8fb95b9d72e7_1000x667.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>As one would expect, Ronald Reagan was the recipient of thousands of letters each month during his presidency; a mailbag so voluminous, in fact, that a gang of patient volunteers were tasked with opening them all on his behalf and passing him approximately 30 each week to read and respond to. Letters arrived from all over the world, written by a diverse group of people: men, women, fans, critics, average Joes, celebrities, world leaders, and, marking a moment in history, a letter from a 13-year-old boy from South Carolina named Andy Smith, written exactly 40 years ago on 18 April 1984. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F00d4dd7d-dec1-4c09-b1ca-4e2718dc172c_773x895.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F00d4dd7d-dec1-4c09-b1ca-4e2718dc172c_773x895.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F00d4dd7d-dec1-4c09-b1ca-4e2718dc172c_773x895.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F00d4dd7d-dec1-4c09-b1ca-4e2718dc172c_773x895.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F00d4dd7d-dec1-4c09-b1ca-4e2718dc172c_773x895.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F00d4dd7d-dec1-4c09-b1ca-4e2718dc172c_773x895.png" width="773" height="895" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/00d4dd7d-dec1-4c09-b1ca-4e2718dc172c_773x895.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:895,&quot;width&quot;:773,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:424951,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F00d4dd7d-dec1-4c09-b1ca-4e2718dc172c_773x895.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F00d4dd7d-dec1-4c09-b1ca-4e2718dc172c_773x895.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F00d4dd7d-dec1-4c09-b1ca-4e2718dc172c_773x895.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F00d4dd7d-dec1-4c09-b1ca-4e2718dc172c_773x895.png 1456w" sizes="100vw"></picture></div></a><figcaption>Andy Smith to U.S. President Ronald Reagan, 18th April 1984</figcaption></figure></div><blockquote><p><span>Andy Smith</span><br><span>400 London Pride Road</span><br><span>Irmo, South Carolina 29063</span></p><p>April 18, 1984</p><p>Dear Mr. President,</p><p>My name is Andy Smith. I am a seventh grade student at Irmo Middle School, in Irmo, South Carolina.</p><p>Today my mother declared my bedroom a disaster area. I would like to request federal funds to hire a crew to clean up my room. I am prepared to provide the initial funds if you will provide matching funds for this project.</p><p>I know you will be fair when you consider my request. I will be awaiting your reply.</p><p><span>Sincerely yours,</span><br><span>Andy Smith</span></p></blockquote><blockquote><p>May 11, 1984</p><p>Dear Andy:</p><p>I’m sorry to be so late in answering your letter but, as you know, I’ve been in China and found your letter here upon my return.</p><p>Your application for disaster relief has been duly noted but I must point out one technical problem: the authority declaring the disaster is supposed to make the request. In this case, your mother.</p><p>However, setting that aside, I’ll have to point out the larger problem of available funds. This has been a year of disasters: 539 hurricanes as of May 4th and several more since, numerous floods, forest fires, drought in Texas and a number of earthquakes. What I’m getting at is that funds are dangerously low.</p><p>May I make a suggestion? This Administration, believing that government has done many things that could better be done by volunteers at the local level, has sponsored a Private Sector Initiative Program, calling upon people to practice voluntarism in the solving of a number of local problems.</p><p>Your situation appears to be a natural. I’m sure your mother was fully justified in proclaiming your room a disaster. Therefore, you are in an excellent position to launch another volunteer program to go along with the more than 3000 already underway in our nation. Congratulations.</p><p>Give my best regards to your mother.</p><p><span>Sincerely,</span><br><span>Ronald Reagan</span></p></blockquote></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Inside Amazon’s Secret Operation to Gather Intel on Rivals (149 pts)]]></title>
            <link>https://www.wsj.com/business/retail/amazon-secret-operation-intel-rivals-eb82ea3c</link>
            <guid>40075539</guid>
            <pubDate>Thu, 18 Apr 2024 12:35:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/business/retail/amazon-secret-operation-intel-rivals-eb82ea3c">https://www.wsj.com/business/retail/amazon-secret-operation-intel-rivals-eb82ea3c</a>, See on <a href="https://news.ycombinator.com/item?id=40075539">Hacker News</a></p>
Couldn't get https://www.wsj.com/business/retail/amazon-secret-operation-intel-rivals-eb82ea3c: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[The invisible seafaring industry that keeps the internet afloat (206 pts)]]></title>
            <link>https://www.theverge.com/c/24070570/internet-cables-undersea-deep-repair-ships</link>
            <guid>40075402</guid>
            <pubDate>Thu, 18 Apr 2024 12:16:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/c/24070570/internet-cables-undersea-deep-repair-ships">https://www.theverge.com/c/24070570/internet-cables-undersea-deep-repair-ships</a>, See on <a href="https://news.ycombinator.com/item?id=40075402">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

	
	
	

	
			<p><span>O</span><span>n</span><span>On</span>  the afternoon of March 11th, 2011, Mitsuyoshi Hirai, the chief engineer of the cable maintenance ship Ocean Link,<em> </em>was sitting in his cabin 20 miles off Japan’s eastern coast, completing the paperwork that comes at the end of every repair. Two weeks earlier, something — you rarely knew what — damaged the 13,000-mile fiber optic cable connecting Kitaibaraki, Japan, and Point Arena, California. Alarms went off; calls were made; and the next day, Hirai was sailing out of the port in Yokohama to fix it.</p>
	
					


	
			<div>
								<p>The repair was now nearly done. All that remained was to rebury the cable on the seafloor, which they were doing using a bulldozer-sized remotely operated submersible named Marcas — and, of course, the paperwork.&nbsp;</p>


								<p>Suddenly, the ship began to shudder. Hirai got to his feet, found he could barely stand, and staggered out of his cabin, grasping the handrail as he pulled himself up the narrow stairway to the bridge. “Engine trouble?” Hirai asked the captain, who’d already checked and replied that everything seemed normal. The ship continued to tremble. Looking out from the bridge, the sea appeared to be boiling.</p>


			</div>
	
					<div>
				<video muted="" loop="" autoplay="" playsinline="" data-sourcedesktop="https://s3.amazonaws.com/assets.sbnation.com/csk/uploads/verge-features/underwater-cables/236543_Deep_sea_cable_repair_GTakayama_0199_shrunk_1.mp4" data-sourcetablet="https://s3.amazonaws.com/assets.sbnation.com/csk/uploads/verge-features/underwater-cables/236543_Deep_sea_cable_repair_GTakayama_0199_shrunk_1.mp4" data-sourcemobile="https://s3.amazonaws.com/assets.sbnation.com/csk/uploads/verge-features/underwater-cables/236543_Deep_sea_cable_repair_GTakayama_0199_shrunk_1.mp4" type="video/mp4">
				</video>
				
				
				
					<p>
						A sketch of the Ocean Link in port in Yokohama transitions into a video of the ship. A bird flies overhead and waves lap at its hull.
					</p>
			</div>



	
			<div>
								<p>They turned on the television. An emergency alert showed that an earthquake had struck 130 miles northeast of their location. The shaking finally stopped, and in the silence, Hirai’s mind leapt to what would come next: a tsunami.</p>


								<p>Hirai feared these waves more than most people. He had grown up hearing the story of how one afternoon in 1923, his aunt felt the ground shake, swept up her two-year-old brother, and sprinted uphill to the cemetery, narrowly escaping floods and fires that killed over 100,000 people. That child became Hirai’s father, so he owed his existence to his aunt’s quick thinking. Now, he found himself in the same position. He knew tsunamis become dangerous when all the water displaced by the quake reaches shallow water and slows and grows taller. The Ocean Link, floating in less than 500 feet of water, was too shallow for comfort. </p>


			</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/01_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/01_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/01_mobile_min.jpg" alt="A photo of Mitsuyoshi Hirai, the former chief engineer of the Ocean Link. He sits at a table, his hands folded on a chart." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/01_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
			<div>
								<p>In the family tree of professions, submarine cable work occupies a lonely branch somewhere between heavy construction and neurosurgery. It’s precision engineering on a shifting sea using heavy metal hooks and high-tension lines that, if they snap, can cut a person in half. In Hirai’s three decades with Kokusai Cable Ship Company (KCS), he had learned that every step must be followed, no matter how chaotic the situation. Above all else, he often said, “you must always be cool.”&nbsp;</p>


								<p>Across Ocean Link’s 400-foot deck, the ship’s 50 crew members were emerging from their cabins and workstations, trying to figure out what had just occurred. Over the intercom, the captain announced that there had been an earthquake, a tsunami was coming, and the crew should ready the ship to evacuate to deeper water. The crew fanned out to check fuel tanks and lash down machinery. Inside a darkened, monitor-filled shipping container on the starboard deck, the submersible’s pilot steered Marcas back toward the ship as fast as the bulky robot’s propellers could carry it. Minutes later, the submersible was hoisted aboard and the Ocean Link was underway. </p>


			</div>
	

						<div>
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/02_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/02_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/02_mobile_min.jpg" alt="The controls on the bridge of the Ocean Link. A video screen shows a complicated output; there are many gauges and buttons." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/02_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/03_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/03_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/03_mobile_min.jpg" alt="Rows of binoculars sit next to a window as the Ocean Link looks out over the port." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/03_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/04_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/04_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/04_mobile_min.jpg" alt="A bright orange lifeboat on the deck of the Ocean Link." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/04_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/05_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/05_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/05_mobile_min.jpg" alt="Two large wheels guide a cable attached to the Marcas submersible (not pictured)." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/05_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
								</div>
	
			<div>
								<p>The tsunami passed under them imperceptibly on their way out to sea, and when they came to a stop three hours later, the television was showing the first images of destruction. Members of the crew who weren’t working gathered on the bridge to watch the news, which continued to display a tsunami warning, a map of Japan with its eastern seaboard glowing red. They took turns trying to reach loved ones using the ship’s satellite phone, but no calls went through.&nbsp;</p>


								<p>As night fell, periodic aftershocks thumped against the hull. Hirai thought about his wife, who was working at a department store in Yokohama near the Ocean Link’s port; his son, a junior in high school at the time; and his parents, whom the family lived with in his hometown of Yokosuka — none of whom he’d been able to reach. Everyone had someone they were worried about.</p>


								<p>But Hirai also began to think about the work he knew lay ahead. The Ocean Link was one of a small number of ships that maintain the subsea cables that carry 99 percent of the world’s data. Positioned in strategic locations around the planet, these ships stand ready to sail out and fix faults the moment they are detected, and most of the time, they are more than equal to the task. But earthquakes, Hirai knew from experience, were different. They didn’t just break one cable — they broke many, and badly. If what he feared had happened, Japan risked being cut off from the world in its moment of need.</p>


								<p>Sure enough, that night, a call came from headquarters confirming the Ocean Link was safe and directing them to remain at sea until further notice, followed by messages announcing cable failure after cable failure, including the one they had just finished repairing. </p>


			</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/06_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/06_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/06_mobile_min.jpg" alt="Fumihide Kobayashi standing in front of the submersible Marcas." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/06_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
			<div>
								<p>Cable industry professionals tend to be pragmatic people, preoccupied with the material realities of working planet-scale construction. But in conversations about landing high-bandwidth cables in digitally neglected regions or putting millions of people back in contact with every fiber strand melted together, they often hint at a sense of larger purpose, an awareness that they are performing a function vital to a world that, if they do their jobs well, will continue to be unaware of their service.</p>


								<p>For the Ocean Link crew, this awareness was bound up in a still unfolding national tragedy. They knew that whenever they returned to land, they would have to care for their loved ones quickly, because they would soon be going back out to sea. For how long, no one knew. </p>


							

			</div>
	
			<div>
								<p><span>T</span><span>he</span><span>The</span>  world’s emails, TikToks, classified memos, bank transfers, satellite surveillance, and FaceTime calls travel on cables that are about as thin as a garden hose. There are about 800,000 miles of these skinny tubes crisscrossing the Earth’s oceans, representing nearly 600 different systems, according to the industry tracking organization TeleGeography. The cables are buried near shore, but for the vast majority of their length, they just sit amid the gray ooze and alien creatures of the ocean floor, the hair-thin strands of glass at their center glowing with lasers encoding the world’s data.&nbsp;</p>


								<p>If, hypothetically, all these cables were to simultaneously break, modern civilization would cease to function. The financial system would immediately freeze. Currency trading would stop; stock exchanges would close. Banks and governments would be unable to move funds between countries because the Swift and US interbank systems both rely on submarine cables to settle over $10 trillion in transactions each day. In large swaths of the world, people would discover their credit cards no longer worked and ATMs would dispense no cash. As US Federal Reserve staff director Steve Malphrus said at a 2009 cable security conference, “When communications networks go down, the financial services sector does not grind to a halt. It snaps to a halt.”</p>


			</div>
	
			
<div>
	<p>A map of the world showing the dozens of fibre optic cable systems which stretch across the oceans, connecting continents and island chains. Some of these cables are extremely long. The map animates to show the cables laid down between 1989 and the present, with planned cables up to 2027 also displayed.</p>
	
	
	
</div>
	
			<div>
								<p>Corporations would lose the ability to coordinate overseas manufacturing and logistics. Seemingly local institutions would be paralyzed as outsourced accounting, personnel, and customer service departments went dark. Governments, which rely on the same cables as everyone else for the vast majority of their communications, would be largely cut off from their overseas outposts and each other. Satellites would not be able to pick up even half a percent of the traffic. Contemplating the prospect of a mass cable cut to the UK, then-MP Rishi Sunak concluded, “Short of nuclear or biological warfare, it is difficult to think of a threat that could be more justifiably described as existential.”</p>


								<p>Fortunately, there is enough redundancy in the world’s cables to make it nearly impossible for a well-connected country to be cut off, but cable breaks do happen. On average, they happen every other day, about 200 times a year. The reason websites continue to load, bank transfers go through, and civilization persists is because of the thousand or so people living aboard 20-some ships stationed around the world, who race to fix each cable as soon as it breaks.</p>


			</div>
	

						<div>
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/07_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/07_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/07_mobile_min.jpg" alt="Bright yellow grapnel flukes of varying lengths on the deck of the Ocean Link." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/07_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/08_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/08_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/08_mobile_min.jpg" alt="A zoomed out view of the grapnels, situating them relative to the ship." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/08_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/09_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/09_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/09_mobile_min.jpg" alt="Mushroom anchors aboard the Ocean Link. The lack of flukes helps to avoid entangling cables." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/09_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/10_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/10_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/10_mobile_min.jpg" alt="The two wide channels of the Ocean Link’s bow sheave help guide cables and grapnels as they pass over into the sea. " src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/10_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/11_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/11_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/11_mobile_min.jpg" alt="A view of the Ocean Link’s bridge from the foredeck." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/11_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
								</div>
	
			<div>
								<p>The industry responsible for this crucial work traces its origins back far beyond the internet, past even the telephone, to the early days of telegraphy. It’s invisible, underappreciated, analog. Few people set out to join the profession, mostly because few people know it exists.&nbsp;</p>


								<p>Hirai’s career path is characteristic in its circuitousness. Growing up in the 1960s in the industrial city of Yokosuka, just down the Miura Peninsula from the Ocean Link’s port in Yokohama, he worked at his parents’ fish market from the age of 12. A teenage love of American rock ‘n’ roll led to a desire to learn English, which led him to take a job at 18 as a switchboard operator at the telecom company KDDI as a means to practice. When he was 26, he transferred to a cable landing station in Okinawa because working on the beach would let him perfect his windsurfing. This was his introduction to cable maintenance and also where he met his wife. Six years later, his English proficiency got him called back to KDDI headquarters to help design Ocean Link for KCS, a KDDI subsidiary. Once it was built, he decided to go to sea with it, eventually becoming the ship’s chief engineer.</p>


			</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/12_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/12_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/12_mobile_min.jpg" alt="Captain Shoichi Suzuki sits in front of the control panels in the bridge of the Ocean Link." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/12_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
			<div>
								<p>Others come to the field from merchant navies, marine construction, cable engineering, geology, optics, or other tangentially related disciplines. When Fumihide Kobayashi, the submersible operator — a tall and solidly built man from the mountain region of Nagano — joined KCS at the age of 20, he thought he would be working on ship maintenance, not working aboard a maintenance ship. He had never been on a boat before, but Hirai enticed him to stay with stories of all the whales and other marine creatures he would see on the remote ocean.</p>


								<p>Once people are in, they tend to stay. For some, it’s the adventure — repairing cables in the churning currents of the Congo Canyon, enduring hull-denting North Atlantic storms. Others find a sense of purpose in maintaining the infrastructure on which society depends, even if most people’s response when they hear about their job is, <em>But isn’t the internet all satellites by now?</em> The sheer scale of the work can be thrilling, too. People will sometimes note that these are the largest construction projects humanity has ever built or sum up a decades-long resume by saying they’ve laid enough cable to circle the planet six times.</p>


								<p>KCS has around 80 employees, many of whom, like Hirai, have worked there for decades. Because the industry is small and careers long, it can seem like everyone knows one another. People often refer to it as a family. Shipboard life lends itself to a strong sense of camaraderie, with periods of collaboration under pressure followed by long stretches — en route to a worksite or waiting for storms to pass — without much to do but hang out. Kobayashi learned to fish off the side of the ship and attempted to improve the repetitive cuisine by serving his crewmates sashimi. (His favorite is squid, but his colleagues would prefer he use the squid to catch mackerel.) Hirai, an enthusiastic athlete, figured out how to string up a net on the Ocean Link’s<em> </em>helideck and play tennis. Other times, he would join the crew for karaoke in the lounge, a wood-paneled room behind an anomalous stained-glass door containing massage chairs, a DVD library, and a bar. A self-described “walking jukebox,” Hirai favored Simon &amp; Garfunkel and Billy Joel, though he said the younger members of the fleet didn’t go in for it as much.</p>


			</div>
	

						<div>
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/13_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/13_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/13_mobile_min.jpg" alt="The Ocean Link’s galley features enough tables and chairs for 20 or more people." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/13_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/14_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/14_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/14_mobile_min.jpg" alt="Pale green curtains frame an on-ship shrine with decorated figures and a plant." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/14_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/15_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/15_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/15_mobile_min.jpg" alt="The lounge aboard the Ocean Link, including a large recliner, a bar, and a dartboard." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/15_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/16_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/16_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/16_mobile_min.jpg" alt="Dozens of condiments on one of the tables in the Ocean Link’s galley." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/16_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
								</div>
	
			<div>
								<p>The world is in the midst of a cable boom, with multiple new transoceanic lines announced every year. But there is growing concern that the industry responsible for maintaining these cables is running perilously lean. There are 77 cable ships in the world, according to data supplied by SubTel Forum, but most are focused on the more profitable work of laying new systems. Only 22 are designated for repair, and it’s an aging and eclectic fleet. Often, maintenance is their second act. Some, like Alcatel’s Ile de Molene, are converted tugs. Others, like Global Marine’s Wave Sentinel, were once ferries. Global Marine <a href="https://www.datacenterdynamics.com/en/analysis/the-cable-ship-capacity-crunch/">recently told Data Centre Dynamics</a> that it’s trying to extend the life of its ships to 40 years, citing a lack of money. One out of 4 repair ships have already passed that milestone. The design life for bulk carriers and oil tankers, by contrast, is 20 years.&nbsp;</p>


								<p>“We’re all happy to spend billions to build new cables, but we’re not really thinking about how we’re going to look after them,” said Mike Constable, the former CEO of Huawei Marine Networks, who gave a presentation on the state of the maintenance fleet at an industry event in Singapore last year. “If you talk to the ship operators, they say it’s not sustainable anymore.”</p>


								<p>He pointed to a case last year when four of Vietnam’s five subsea cables <a href="https://vietnaminsider.vn/vietnams-internet-connection-disrupted-as-four-of-five-undersea-cables-broken/">went down</a>, slowing the internet to a crawl. The cables hadn’t fallen victim to some catastrophic event. It was just the usual entropy of fishing, shipping, and technical failure. But with nearby ships already busy on other repairs, the cables didn’t get fixed for six months. (One promptly <a href="https://e.vnexpress.net/news/news/vietnam-s-undersea-cable-malfunctions-right-after-getting-fixed-4623749.html">broke again</a>.)&nbsp;</p>


								<p>But perhaps a greater threat to the industry’s long-term survival is that the people, like the ships, are getting old. In a profession learned almost entirely on the job, people take longer to train than ships to build. </p>


			</div>
	
			<div>
			<p><span>Key components of the KDDI Ocean Link</span></p><p><span>Drum engine</span>
			      	<span>A powerful but delicate 12-foot diameter electro-hydraulic steel drum used for paying out and recovering cables and grapnels during repairs.</span>
				</p>
				<p><span>Linear cable engine</span>
			      	<span>A conveyor comprised of 21 pairs of cable-gripping tires used for laying and retrieving cables.</span>
				</p>
				<p><span>Cable control room</span>
			      	<span>A command center adjoining the bridge where cable tension is monitored and all cable operations are managed.</span>
				</p>
				<p><span>Cable tanks</span>
			      	<span>Three tanks capable of holding a total of 2,800 miles of cable.</span>
				</p>
				<p><span>Bow Sheave</span>
			      	<span>A rolling sheave that cables and grapnel ropes are passed over.</span>
				</p>
				<p><span>Thrusters</span>
			      	<span>Bow and stern thrusters are used to maneuver into wind, waves, and currents to keep the ship stationary during repairs.</span>
				</p>
				<p><span>MARCAS ROV</span>
			      	<span>Remote submersible capable of operating at up to 8,000ft. Equipped with cameras, sensors, a robotic arm, and a powerful water jet for burying cables.</span>
				</p>
		</div>
	
			<div>
								<p>“One of the biggest problems we have in this industry is attracting new people to it,” said Constable. He recalled another panel he was on in Singapore meant to introduce university students to the industry. “The audience was probably about 10 university kids and 60 old gray people from the industry just filling out their day,” he said. When he speaks with students looking to get into tech, he tries to convince them that subsea cables are also part — a foundational part — of the tech industry. “They all want to be data scientists and that sort of stuff,” he said. “But for me, I find this industry fascinating. You’re dealing with the most hostile environment on the planet, eight kilometers deep in the oceans, working with some pretty high technology, traveling all over the world. You’re on the forefront of geopolitics, and it’s critical for the whole way the world operates now.”</p>


								<p>The lifestyle can be an obstacle. A career in subsea means enduring long stretches far from home, unpredictable schedules, and ironically, very poor internet.</p>


			</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/17_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/17_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/17_mobile_min.jpg" alt="Kaida Takashi stands on the foredeck of the Ocean Link." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/17_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
			<div>
								<p>“Everyone complains about that,” said Kaida Takashi, a senior advisor at KCS, who is trying to get the Ocean Link<em> </em>set up with Starlink. It’s a generational difference, he said. For someone like him, a 62-year-old ham radio enthusiast, Wi-Fi barely fast enough to email is a luxury. Other industry veterans reminisced about the days when they felt fortunate to get faxes on board, or waiting for the mailbag in port, or the novelty of using the very cable they were laying to make calls from the middle of the ocean. But for people who grew up with an expectation of constant connectivity, the disconnection of shipboard life can cause visible discomfort. “It’s a part of them,” one industry veteran marveled of his younger colleagues. “They can’t let it go.”&nbsp;</p>


								<p>The industry’s biggest recruiting challenge, however, is the industry’s invisibility. It’s a truism that people don’t think about infrastructure until it breaks, but they tend not to think about the fixing of it, either. In his 2014 essay, “Rethinking Repair,” professor of information science Steven Jackson argued that contemporary thinking about technology romanticizes moments of invention over the ongoing work of maintenance, though it is equally important to the deployment of functional technology in the world. There are few better examples than the subsea cable industry, which, for over a century, has been so effective at quickly fixing faults that the public has rarely had a chance to notice. Or as one industry veteran put it, “We are one of the best-kept secrets in the world, because things just work.”&nbsp;  </p>


							

			</div>
	
			<div>
								<p><span>T</span><span>he</span><span>The</span>  Ocean Link spent two nights at sea before receiving orders to return. As they neared land, Hirai saw debris from the tsunami’s backwash floating in the water: fishing nets, tires, the roofs of buildings, the bloated body of what he guessed was a cow.&nbsp;</p>


								<p>The earthquake measured 9.1 on the Richter scale, the fourth largest ever recorded and the largest to ever hit Japan. But it was the series of tsunami waves that arrived half an hour later that dealt the most destruction, surging miles inland and sweeping buildings, cars, and thousands of people out to sea. The death toll would eventually climb to nearly 20,000, and the day would become a national tragedy referred to simply as “3/11.”</p>


								<p>The full extent of the devastation was still becoming clear when the Ocean Link returned, but the disaster had already entered a new phase. One hundred and sixty miles north of Tokyo, a 50-foot tsunami wave overtopped a seawall protecting the Fukushima power plant, swamping the emergency generators that were cooling the reactors through its automatic post-quake shutdown and precipitating a nuclear meltdown.&nbsp;</p>


								<p>Hirai’s wife and son had made it back home to their house in Yokosuka, where they lived with Hirai’s parents. Kobayashi’s family, too, was safe. Some crew lost loved ones; others sent family to stay with relatives in the south out of fear of radiation. They all knew that they had only a few days before they would be sent back out to sea.</p>


			</div>
	
					<div>
				
				
				
					<p>
						The Ocean Link in a storm in the North Pacific. The ship pitches wildly in the heavy swell, the waves crashing over its bow.&nbsp;
					</p>
			</div>


	
			<div>
								<p>The disaster had severed phone lines and wrecked cell towers, causing phone service to cut out almost immediately after the earthquake struck. Instead, people turned to email, Skype, and other online services that were mostly able to route around damage to the network. There was a sense, according to one engineer’s postmortem <a href="https://www.ausnog.net/sites/default/files/ausnog-05/presentations/ausnog-05-d01p03-tomoya-yoshida-ntt.pdf">presentation</a>, that the internet was the only media that survived.</p>


								<p>But its survival was more tenuous than the public knew. While the cables connecting Japan to the rest of the world survived the initial destruction, later that night, as millions of people tried to find their way home with trains stopped and power intermittent, engineers in Tokyo network operation centers watched as one cable after another failed. By the next morning, seven of Japan’s 12 transpacific cables were severed. Engineers working through the night and following days managed to shift traffic to those that remained, but the new routes were near their maximum capacity. The head of telecom company NTT’s operation center at the time estimated that if another cable failed, it would have lost all traffic to the US. With servers for most major internet companies located there, Japan would have effectively lost the internet.&nbsp;</p>


								<p>Normally, the sequence of repairs would be determined by whichever cable owner reported the fault first, but given the extraordinary circumstances, the usually self-interested cable owners agreed to defer to KCS. The priority was to repair a cable — any cable — as fast as possible.&nbsp;</p>


								<p>It was impossible to know the state of the cables on the ocean floor, so like forensic investigators, Hirai and the other engineers had to work with the sparse facts available. By having the cable landing stations on either side of the ocean beam light down their end of the line and time the reflections back, they were able to locate the faults nearest to them within a few meters. Most of the faults lay in deep water, in the canyons channeling into the Japan Trench. This, plus the timing of the faults, indicated it wasn’t the quake that broke them but the underwater avalanches it triggered. </p>


			</div>
	
			<section>
	
	
	<p>“It hasn’t changed in 150 years... The Victorians did it that way and we’re doing it the same way.”</p>
</section>
	
			<div>
								<p>Submarine landslides are awesome events whose existence was only discovered in the 1950s, when scientists analyzed the timing of 12 cable faults that severed communication between Europe and North America two decades earlier. Before then, according to oceanographer Mike Clare, “It was assumed that deep water was boring and nothing happens down there.” In fact, the ocean floor is riven with mountains and canyons that experience avalanches that dwarf anything found on land, cascades of sediment and debris racing for hundreds of miles. Hirai had dealt with them in Taiwan in 2006, one of the most notorious events in the annals of cable repair.&nbsp;</p>


								<p>On December 26th, an earthquake dislodged sediment on Taiwan’s southern coast and sent it rushing 160 miles into the Luzon Strait, one of several global cable chokepoints. Nine cables were severed and Taiwan was knocked almost entirely offline. Banking, airlines, and communications were disrupted throughout the region. Trading of the Korean won was halted. The cables, buried under mountains of debris, were nearly impossible to find. It took 11 ships, including the Ocean Link, nearly two months to finish repairs.</p>


								<p>Often in a multi-cable disaster like the Taiwan earthquake, every ship in the region comes to assist. But with Japan, there was an unprecedented complication: the majority of the faults were located offshore of the ongoing nuclear meltdown at Fukushima. Ship operators deemed assistance too risky, which meant that, for the time being, the Ocean Link was on its own.&nbsp;</p>


						
								<p>The crew felt not only duty bound to work but uniquely capable of doing so. They had dealt with radiation before, though not at this scale. In 1993, shortly before the Ocean Link was to lay a cable linking Japan, Korea, and Russia, they learned the Soviets had dumped radioactive waste in the ocean along the planned route. With some trepidation, KCS proceeded with the job. They bought Geiger counters and protective gear, flew in nurses from the US with chemical weapons training, and scanned the water for radiation as they went. When none was detected, they put the gear in storage.&nbsp;</p>


								<p>Now, as they readied the ship for departure, an employee was dispatched to the depot to find the old radiation gear. A local university donated a few more sensors and trained the crew on how to use them.&nbsp;</p>


								<p>They decided to begin with the same cable they had just finished repairing when the earthquake struck. On a drizzling afternoon eight days after returning to port, with smoke still rising from the Fukushima power plant, the Ocean Link set back out to sea. </p>


			</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/18_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/18_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/18_mobile_min.jpg" alt="Cables are wrapped around a large metal structure in the KCS depot." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/18_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
			<div>
								<p><span>T</span><span>o</span><span>To</span>  the extent he is remembered, Cyrus Field is known to history as the person responsible for running a telegraph cable across the Atlantic Ocean, but he also conducted what at the time was considered an equally great technical feat: the first deep-sea cable repair.&nbsp;</p>


								<p>Field, a 35-year-old self-made paper tycoon, had no experience in telegraphy — which helps explain why, in 1854, he embarked on such a quixotic mission. Though small bodies of water like the English Channel had been bridged by telegraph, failure was routine and costly. Cables shorted out, snapped under tension, snagged on rocks, were sliced by anchors, twisted by currents, tangled around whales, attacked by swordfish, and devoured by a <a href="https://atlantic-cable.com/Article/Clifford/teredo.htm">“miserable little mollusc”</a> called the Teredo worm with an appetite for jute insulation.&nbsp;</p>


								<p>Field fared no better. Twelve years after he began, he had endured severed cables, near sinkings, and had one “success”: a cable laid in 1858 that prompted celebrations so enthusiastic that revelers set fire to New York City Hall. The cable failed weeks later.</p>


			</div>
	

						<div>
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/19_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/19_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/19_mobile_min.jpg" alt="A woodcut illustration of the SS Great Eastern as it attempts to recover the broken transatlantic telegraph cable in 1865. Men line the decks to watch the operation." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/19_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/20_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/20_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/20_mobile_min.jpg" alt="A woodcut illustration of sailors aboard the SS Great Eastern in 1865. Eighteen figures work to coil a cable around a large capstan." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/20_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/21_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/21_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/21_mobile_min.jpg" alt="A photograph of a display showing cables of various thickness as well as a model of a grapnel." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/21_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/22_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/22_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/22_mobile_min.jpg" alt="An illustration of Cyrus West Field sitting in an armchair reading a book." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/22_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
								</div>
	
			<div>
								<p>Field tried again seven years later only for the cable to snap halfway across the Atlantic. The next year, he set out yet again, promising not only to finally lay a working transatlantic cable but to recover the broken cable and finish that one, too.&nbsp;</p>


								<p>By that time, a crude method had been developed for fixing cables in shallow water. A ship would drag a hooked grapnel anchor across the seafloor, until, like the tremor of a fishing line, increasing tension showed they’d caught the cable, which they would then haul on board to fix. Field’s plan was basically this but bigger: bigger hooks, stronger rope, more powerful winding engine, all aboard the largest ship afloat, a passenger liner called the SS Great Eastern that had been retrofitted for the mission. William Thomson, the project’s scientific adviser and the future Lord Kelvin, did the math and deemed it feasible.&nbsp;</p>


								<p>“When it was first proposed to drag the bottom of the Atlantic for a cable lost in waters two and a half miles deep, the project was so daring that it seemed to be almost a war of the Titans upon the gods,” wrote Cyrus’ brother Henry. “Yet never was anything undertaken less in the spirit of reckless desperation. The cable was recovered as a city is taken by siege — by slow approaches, and the sure and inevitable result of mathematical calculation.”</p>


			</div>
	
			<section>
	
	
	<p>Humans continue to be by far the single greatest threat to cables</p>
</section>
	
			<div>
								<p>Field’s crew caught the cable on the first try and nearly had it aboard when the rope snapped and slipped back into the sea. After 28 more failed attempts, they caught it again. When they brought it aboard and found it still worked, the crew fired rockets in celebration. Field withdrew to his cabin, locked the door, and wept.</p>


								<p>Cable repair today works more or less the same as in Field’s day. There have been some refinements: ships now hold steady using automated dynamic positioning systems rather than churning paddle wheels in opposite directions, and Field’s pronged anchor has spawned a medieval-looking arsenal of grapnels — long chains called “rennies,” diamond-shaped “flat fish,” spring-loaded six-blade “son of sammys,” three-ton detrenchers with seven-foot blades for digging through marine muck — but at its core, cable repair is still a matter of a ship dragging a big hook along the ocean floor. Newfangled technologies like remotely operated submersibles can be useful in shallow water, but beyond 8,000 feet or so, conditions are so punishing that simple is best.</p>


			</div>
	
			<section>
	
	<span>A schematic view of the ocean depths, with the Ocean Link at the surface. A cable leads down from the ship into the depths. We pass through the Euphotic (Sunlight) zone where familiar animals live, before hitting the twilight zone 656 ft below sea level. The fauna gets more exotic and the light dimmer until we reach the Bathypelagic (Midnight) zone, at 3,280 ft. Here we see giant squid and anglerfish. Travelling further, the Abyssopelagic (abyssal) zone starts at 13,123 ft, and features a couple of weird fish and cephalopods. Finally, the cable terminates in a grapnel in the Hadopelagic (hadal) zone at 19,685 ft. It has hooked its target.</span>
	<p>The deepest repair the Ocean Link conducted in the aftermath of the 2011 earthquake was 6,200 meters (20,340 feet).</p>
</section>
	
			<div>
								<p>“It hasn’t changed in 150 years,” said Alasdair Wilkie, chair of the Atlantic Cable Maintenance &amp; Repair Agreement (ACMA). “The Victorians did it that way and we’re doing it the same way. I just think it’s one of those things that, if it ain’t broke, don’t fix it.”</p>


								<p>Nor have the causes of faults changed in the last century and a half. The first submarine cable, strung across the English Channel in 1850, survived for a single day before — in what may be apocryphal cable industry <a href="https://atlantic-cable.com/stamps/Cableships/indexstc.htm">slander</a> — a French eel fisherman accidentally hooked it, sliced off a piece, and came ashore bragging about his discovery of a new type of metal seaweed. In his history of global telecommunications, <em>How the World Was One</em>, Arthur C. Clarke declared this the first blow in a war between cable companies and other users of the sea that has continued to this day. </p>


			</div>
	
					<div>
				<video muted="" loop="" autoplay="" playsinline="" data-sourcedesktop="https://s3.amazonaws.com/assets.sbnation.com/csk/uploads/verge-features/underwater-cables/236543_Deep_sea_cable_repair_GTakayama_0199_shrunk.mp4" data-sourcetablet="https://s3.amazonaws.com/assets.sbnation.com/csk/uploads/verge-features/underwater-cables/236543_Deep_sea_cable_repair_GTakayama_0199_shrunk.mp4" data-sourcemobile="https://s3.amazonaws.com/assets.sbnation.com/csk/uploads/verge-features/underwater-cables/236543_Deep_sea_cable_repair_GTakayama_0199_shrunk.mp4" type="video/mp4">
				</video>
				
				
				
					<p>
						A sketch of the Ocean Link from the foredeck transitions into a video of the ship in port.
					</p>
			</div>



	
			<p>Humans continue to be by far the single greatest threat to cables. Fishing accounts for about 40 percent of faults, according to the International Cable Protection Committee (ICPC). Bottom trawling, particularly as it extends into new regions and deeper water in pursuit of depleting fish stocks, is especially damaging. Last year, <a href="https://apnews.com/article/matsu-taiwan-internet-cables-cut-china-65f10f5f73a346fa788436366d7a7c70#:~:text=The%20National%20Communications%20Commission%2C%20citing,cut%20the%20second%2C%20NCC%20said.">Chinese fishing vessels</a> severed cables to one of Taiwan’s outlying islands, triggering an international incident. (Severing Taiwan’s cables is one of the first moves in war games of a Chinese siege.) The year before, trawlers cut multiple cables <a href="https://www.bloomberg.com/news/articles/2023-04-24/fishing-boats-keep-running-over-ocean-internet-cables">off the coast of Scotland</a>, knocking several islands offline. Dragged anchors from cruise ships, cargo vessels, and pleasure boats are another common culprit. Last year, an improperly moored mega yacht knocked out <a href="https://nationwideradiojm.com/mega-yacht-causes-islandwide-communications-meltdown-in-anguilla/">all communication for the Caribbean island of Anguilla</a>.</p>
	

						
	
			<div>
								<p>One thing that is not a threat to cables, many in the industry are eager to emphasize, is sharks. The idea that sharks eat submarine cables — repeated in news stories and even some government reports — stems from an incident in the late 1980s when AT&amp;T was testing one of the first subsea fiber optic cables off the coast of the Canary Islands. The cable kept suffering mysterious faults, and when a repair ship hauled it up, teeth were found embedded near the breaks. A study was launched. Bell Labs scientists measured jaw radii and bite strength and, at one point, tried to feed captured sharks samples of cable. The culprit turned out to be a deepwater crocodile shark, possibly attracted to the electromagnetic field emitted from the power repeaters.&nbsp;</p>


								<p>Wrapping cables in metal tape seems to have solved any shark problems. Nevertheless, when an old YouTube video of a shark biting a cable went viral in 2014, it incited global news coverage. The ICPC issued a statement (“Sharks are not the nemesis of the internet — ICPC findings”) saying that it didn’t even look like a data cable, fish bites haven’t caused a fault in many years, and that humans are almost always to blame. Yet the myth endures, possibly because there is something satisfying about the idea of the modern world being brought down by the appetites of a prehistoric creature, and possibly because the idea of sharks eating the internet seems only slightly less improbable than the internet consisting of tubes on the bottom of the sea. </p>


							

			</div>
	
			<div>
								<p><span>O</span><span>n</span><span>On</span>  March 22nd, with the world’s attention fixed on the crisis at Fukushima, the<em> </em>Ocean Link reached its worksite 160 miles to the south. They had chosen one of the faults farthest from the meltdown, but the winter wind was blowing from the north and the crew remained inside the ship until it was deemed safe to go outside.&nbsp;</p>


								<p>As the chief engineer and one of the oldest members of the crew, Hirai felt it was his duty to perform the radiation checks. He pulled on the slick yellow coveralls and boots, strapped on a mask and goggles, and opened the heavy steel door leading to the foredeck.&nbsp;</p>


								<p>The sky was overcast and low, and the ship rocked on a building swell as Hirai walked out onto the pocked green-painted deck and held out the wand of his Geiger counter to see what the wind carried. To his relief, it registered only background radiation. Next, he walked to the side and lowered a sensor into the sea. Again, nothing. He would do it all again in two hours, but for now, work could begin.&nbsp;</p>


								<p>They spent the first day and night surveying the worksite, moving slowly along the cable route while measuring the depth and current. Conditions worsened overnight and dawn greeted them with 15-foot waves and gale-force winds, too violent for delicate cable work. They would have to wait.</p>


								<p>At the most basic level, a broken cable is fixed by patching the break with a piece of new cable, but because the break is miles away on the ocean floor, this must be done in several steps. The first step is to cut the cable near the break (often, the cable will have been damaged but not cleanly severed, and cables are laid with so little slack that they cannot be pulled to the surface in one piece). This is done by dragging a bladed grapnel across the cable in a so-called “cutting drive.” The ship then swaps the bladed grapnel for a hooked one and catches one end of the severed cable, hoists it to the surface, and attaches it to a buoy. Then they catch the other cable end, splice the spare cable to it, and tow the spare cable back to the first buoyed cable to complete the patch. The ship is now holding a working cable but one that is considerably longer than it used to be. This process of bringing each cable end to the surface separately means that every repair makes a cable longer — in deep water, by several miles. In order to minimize slack that could get tangled and snagged, the loop of new cable is towed to the side of the original route until it can lay taut on the ocean floor once again.</p>


			</div>
	

						<div>
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/25_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/25_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/25_mobile_min.jpg" alt="A hatch leading below deck in the Ocean Link. The room below is brightly illuminated." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/25_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/26_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/26_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/26_mobile_min.jpg" alt="The interior of the Ocean Link. Netted-off areas lead to the cable tanks. To the left is the jointing station, where cables are spliced." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/26_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/27_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/27_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/27_mobile_min.jpg" alt="The Ocean Link’s two powerful drum cable engines, used for paying out and reeling in cables and grapnel ropes." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/27_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/28_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/28_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/28_mobile_min.jpg" alt="A large collection of bright yellow tools stored on shelves." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/28_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/29_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/29_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/29_mobile_min.jpg" alt="A side view of a drum cable engine." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/29_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
								</div>
	
			<div>
								<p>The Ocean Link had repaired this same stretch of cable five years earlier, which meant they had already added the slack required to bring it to the surface, no cutting required. It should have been sitting on the seafloor in the form of a 12-mile loop. If they could catch it, Hirai reasoned, they would save time and — this was important — precious spare cable. Every cable ship is stationed next to a depot with a certain amount of spare cable for each system in its jurisdiction. If the Ocean Link used too much on their first repair, it would take six months to manufacture and deliver enough new cable to fix the remaining faults.</p>


								<p>By the afternoon, the Ocean Link was still plunging through heavy seas, but with the storm predicted to pass overnight, they decided to begin. From the arsenal of yellow-enameled grapnels strapped to the foredeck, Hirai selected a “jamming-type sliding prong,” a mace-like implement comprised of two metal bars studded with foot-long barbs, well suited for dragging across rocky seabed without getting stuck. They lowered it over the bow sheave and into the water. The ocean floor was more than three miles down, and it took the grapnel more than six hours to hit bottom. The Ocean Link began to move slowly forward.</p>


								<p>From this point onward, Hirai or another engineer would be in the cable control room — an instrument-filled command center behind the bridge — their attention fixed on the tension meter, a circular dial set into a pale green wall. The retro-looking analog gauge was less precise than a digital one but far better for intuitively conveying changes in tension than a jittery numerical readout. The steady wavering of its arm would mean the grapnel was plowing through the gray ooze of the ocean floors. A staccato spike; they had hooked a rock. A steady rise; the cable had been caught. Part of being an effective chief engineer, Hirai found, was the ability to read what was happening on the ocean floor from the limited information of the moving dial.&nbsp;</p>


								<p>At 6AM the next day, the engineer on duty saw the telltale rise of a caught cable, and the Ocean Link came to a stop. They had hooked the cable on the first run — rare in an earthquake repair — and began to reel it in.</p>


			</div>
	
			<section>
	
	
	<p>The ships are aging; the people are aging; and it’s unclear where the money will come from to turn things around</p>
</section>
	
			<div>
								<p>Almost immediately, there was a sign something was amiss. The tension was rising too high too fast. The cable must be pinned under debris, Hirai thought. He ordered the winding engine to slow lest the cable snap, reeling in the grapnel at a grinding 10 feet per minute.&nbsp;</p>


								<p>The morning passed, then the afternoon, Hirai suiting up every few hours to check for radiation. The drum engine continued its slow rotation. Night fell. Half past midnight, after 19 hours of winding, the cable reached the surface.&nbsp;</p>


								<p>The grapnel came over the bow and was illuminated by the deck lights. Hirai was horrified at what he saw. They had caught the cable, but it was mangled unlike anything he had seen before. Hooked around one of the grapnel’s lower barbs, the cable’s polyethylene and wire sheath had been stripped by extreme tension and sprang in coiled loops like Slinkys put through a dryer.&nbsp;</p>


						
								<p>It was a dangerous situation. There was no telling how much tension a cable this badly damaged could withstand. It was like a three-mile rubber band stretched tight from the ocean floor, being tested with every rocking wave. If it snapped, the grapnel would fly across the deck, killing anyone it hit before smashing into the cable engine room.&nbsp;</p>


								<p>They had to get the cable off the ship, but doing so involved working closely with the explosive bundle hovering, taut, above the deck. First, crew members lashed chains to either end of the cable to take the tension off the grapnel, which they then swapped for a version with a sharp blade at its center, typically used for severing cables on the ocean floor. This done, they evacuated the foredeck.&nbsp;</p>


								<p>The grapnel, cable, and chains were slowly lowered back over the prow and into the sea, the ship maneuvering delicately to minimize any sudden changes in tension. Once the cable was safely beneath the waves, they released the chains. Suddenly, pulled tight over the blade, the cable split and sank back to the ocean floor.&nbsp;</p>


								<p>For Hirai, relief at a disaster averted was soon followed by foreboding. The landslides created by the earthquake must have been far greater than he had imagined, dragging the cable for miles, mangling it, and burying it beneath who knew how much debris. He couldn’t think how to proceed. </p>


			</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/30_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/30_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/30_mobile_min.jpg" alt="The cable tension meter and other indicators in the Ocean Link’s cable control room." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/30_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
			<div>
								<p><span>D</span><span>ebates</span><span>Debates</span>  about the future of cable repair have become a staple of industry events. They typically begin with a few key facts: the ships are aging; the people are aging; and it’s unclear where the money will come from to turn things around.&nbsp;</p>


								<p>For much of the 20th century, cable maintenance wasn’t a distinct business; it was just something giant, vertically integrated telecom monopolies had to do in order to function. As they started laying coaxial cables in the 1950s, they decided to pool resources. Rather than each company having its own repair vessel mostly sitting idle, they divided the oceans into zones, each with a few designated repair ships.&nbsp;</p>


								<p>When the telcos were split up at the turn of the century, their marine divisions were sold off. Cable &amp; Wireless Marine became Global Marine. AT&amp;T’s division is now the New Jersey-based SubCom. (Both are now owned by private equity companies; KCS remains a subsidiary of KDDI.) The zone system continued, now governed by contracts between cable owners and ship operators. Cable owners can sign up with a nonprofit cooperative, like the Atlantic Cable Maintenance &amp; Repair Agreement, and pay an annual fee plus a day rate for repairs. In exchange, the zone’s three ships — a Global Marine vessel in Portland, UK, another in Curaçao, and an Orange Marine vessel in Brest, France — will stand ready to sail out within 24 hours of being notified of a fault.</p>


						
								<p>This system has been able to cope with the day-to-day cadence of cable breaks, but margins are thin and contracts are short-term, making it difficult to convince investors to spend $100 million on a new vessel.</p>


								<p>“The main issue for me in the industry has to do with hyperscalers coming in and saying we need to reduce costs every year,” said Wilkie, the chair of the ACMA, using the industry term for tech giants like Google and Meta. “We’d all like to have maintenance cheaper, but the cost of running a ship doesn’t actually change much from year to year. It goes up, actually. So there has been a severe lack of investment in new ships.”</p>


								<p>At the same time, there are more cables to repair than ever, also partly a result of the tech giants entering the industry. Starting around 2016, tech companies that previously purchased bandwidth from telcos began pouring billions of dollars into cable systems of their own, seeking to ensure their cloud services were always available and content libraries synced. The result has been not just a boom in new cables but a change in the topology of the internet. “In the old days we connected population centers,” said Constable, the former Huawei Marine executive. “Now we connect data centers. Eighty percent of traffic crossing the Atlantic is probably machines talking to machines.” </p>


			</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/31_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/31_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/31_mobile_min.jpg" alt="A black and white photograph of the bow of a cable ship." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/31_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
			<div>
								<p>Maintenance providers regard these changes with ambivalence. The cable boom means there will be no shortage of cables to fix, but it also means a future of negotiating with a handful of tech giants that can use their tremendous buying power to squeeze ship operators further.&nbsp;</p>


								<p>Market forces pose one challenge; geopolitics another. Tensions with China, including the increasing difficulty of getting permission to repair cables in the contested waters of the South China Sea, are contributing to decisions to route new systems through the Philippines and other less direct passages. Conflict in the Middle East has the industry looking nervously at the Red Sea, an infamous cable chokepoint: in February, a freighter struck by Houthi rockets dragged its anchor across three crucial connections between Asia and Europe, degrading connectivity and raising the frightening prospect of conducting repairs under fire. The Red Sea vulnerability has in turn renewed interest in an Arctic route, made potentially feasible by melting sea ice, though, for years, one of the fatal flaws of this proposal has been the question of who would repair such a cable, there being no ice-capable maintenance vessels.</p>


								<p>These and other recent events, like the 2022 Nord Stream pipeline explosion, have led governments to take a greater interest in cable security, often focusing on the specter of a deliberate attack. Late last year, NATO convened a symposium on undersea infrastructure and the future of “seabed warfare,” while the UK commissioned naval vessels to patrol their subsea connections. Meanwhile, the <a href="https://digital-strategy.ec.europa.eu/en/library/recommendation-security-and-resilience-submarine-cable-infrastructures">European Union</a>, India, and other governments have proposed investing in maintenance vessels directly.</p>


						
								<p>“The amount of ships is relatively limited, and there are a number of places where it could get critical,” said Christian Bueger, the lead author of a 2022 EU Parliament study on threats to subsea data infrastructure. As part of the study, he visited a cable repair ship in Cape Town, South Africa. It was old, he said, with oily, clanging machinery demanding hard physical labor — the opposite of the clean digital space he associated with the internet. One of his recommendations was that governments figure out a way to invest in cable fleets rather than rely on companies focused on cost cutting and efficiency.</p>


								<p>The situation of SubCom illustrates the industry’s strange moment. The company has been withdrawing from maintenance work, according to industry sources, in order to focus on more lucrative installations, many of which are for Google. At the same time, the company is <a href="https://www.reuters.com/investigates/special-report/us-china-tech-subcom/">increasingly intertwined with the US government</a>, which waged a pressure campaign to help SubCom beat China’s HMN Tech for the contract to build a major Asia-to-Europe cable, according to <em>Reuters</em>. SubCom also recently won a contract to operate the US’s first “cable security fleet.”</p>


								<p>Like the involvement of the tech giants, industry veterans regard this new government interest with ambivalence. More funding would be welcome, but the world of subsea cables is one of unforgiving tradeoffs, and it’s easy for well-intentioned policies to go awry. One often proposed solution, for example, is to corral cables into protected corridors, which can make them easier to guard against malicious actors but also makes it possible for a single landslide to take them all out at once. </p>


			</div>
	
			<section>
	
	
	<p>“Did any of us know that we went viral on TikTok?”</p>
</section>
	
			<div>
								<p>Secrecy, too, is a double-edged sword. Classifying cable locations might make them more difficult to attack while worsening exposure to what is their actual greatest threat: fishing accidents and other forms of human negligence. Greater secrecy could also heighten the tension between the industry’s near-total obscurity and its need for new recruits. Ships are a relatively easy problem to solve; they just take money. People take years to train.</p>


								<p>The submarine cable world has never been particularly public. The industry is small and competitive, and cable owners don’t want their cables to get a reputation for breaking, so they bind maintenance providers with nondisclosure agreements. The result is that in the rare case that a fault reaches public awareness, ship operators almost never talk about it. Add in national security concerns, and the result is a code of silence that pervades the entire business. (Which is also why many of the sources in this story are “industry veterans” or other anonymous descriptors.) The industry has begun to recognize that this poses a recruiting challenge.</p>


								<p>In 2022, the industry organization SubOptic gathered six cable employees in their 20s and 30s for a panel on the future of the industry. Most of them had stumbled into their jobs inadvertently after college, and the consensus was that the industry needed to be much better about raising public awareness, especially among the young.&nbsp;</p>


						
								<p>“I don’t know if anyone saw, but during the pandemic, submarine cables actually went viral on TikTok,” said one panelist, a young cable engineer from Vodafone. “People didn’t know they existed, and then suddenly, out of nowhere, they were viral. I think it’s engaging with youth and children through their own avenues — yes, you can have science museums and things like that, but they are online, they are on their iPads, they’re on their phones.”</p>


								<p>“We’ve got some pretty senior decision-makers and influencers in the subsea cable industry here,” said one audience member. “Did any of us know that we went viral on TikTok?” he asked, to laughter.&nbsp;</p>


								<p>“As this panel rightfully said upfront, it’s not that we have a brand problem,” said another audience member, “we just don’t have a brand at all.”</p>


							

			</div>
	
			<div>
								<p><span>I</span><span>t</span><span>It</span>  took the Ocean Link a month to complete its first repair. Failed grapnel runs, fishing gear entanglements, repeated radiation checks, and storms: it had been among the most difficult repairs Hirai had faced. They continued to work through the spring, but by June, they faced a dilemma.&nbsp;</p>


								<p>Many of the remaining faults lay 50 miles off the coast of Chiba, deep in the Japan Trench, where eight different cable lines passed near and sometimes over each other. It was a cable chokepoint, and a landslide must have crashed down and wrecked them all. It would be difficult to catch one without cutting its neighbor. Even if they could, it wasn’t clear they had enough spare cable to fix each fault individually, with all the loops of slack they would need to add to bring the cables to the surface.&nbsp;</p>


								<p>Hirai decided the only solution was to abandon the tangled mess and lay a new system on top of it. It would mean abandoning miles of cable as well as a branching unit: a 2,000-pound device that splits one cable into two different lines going to two destinations. But by reducing the number of loops, it would reduce the amount of cable required. Even then, it wasn’t clear they had enough. They did, however, have a lot of small bits of cable they had been careful to salvage during previous repairs — three miles here, five miles there. With a lot of work, they could be spliced together.</p>


								<p>Takashi Kurokawa had joined KCS 12 years earlier, after hearing about the company from a teacher while in engineering school. Unlike many of his colleagues who moved roles every few years, after Kurokawa learned to joint, he just kept jointing. He enjoyed the way jointing’s strict rules and standards for success created a structure within which he could push himself to attain ever greater precision and speed. </p>


			</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/32_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/32_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/32_mobile_min.jpg" alt="Takashi Kurokawa preparing to splice a fiber." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/32_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
			<div>
								<p>The work is extraordinarily delicate. Cables must be stripped of their polyurethane sheaths, copper conducting tubes, wire armor, and enamel coating until the clear glass threads themselves are exposed. Kurokawa then takes a glass strand from each cable, cleans them in a sonic bath (touching them risks damage and splinters), cleaves their ends at perfect right angles, and places them inside a black toaster-sized box called a fusion splicer, their ends almost but not quite touching. In an instant, the device aligns the ends and zaps an electric arc between them, melting the glass together. Kurokawa then winds the newly spliced fiber into a metal tube called a joint box and does it all again for the next fiber strand. The entire process can take 20 hours, with Kurokawa and his team working in shifts. Every step demands hunched, jeweler-like focus as they seek perfect precision — not in a seismically isolated clean room but in the belly of a rocking ship. Each joint is expected to function untouched under crushing pressure for at least 25 years.</p>


								<p>To speed matters, they decided to assemble what they could in port at Yokohama, with the Ocean Link moored and relatively stable. Working in shifts over 10 days, Kurokawa and his colleagues spliced 10 joints, four repeaters, and a branching unit — assembling a three-part, 100-mile system from the spare bits of cable they had on hand. At night, he dreamed of winding cables back and forth between storage tanks to get at the segments he needed. On June 26th, they tested the apparatus. It worked. They set sail the same day, with no estimate for how long it would take.</p>


								<p>Hirai had mapped out the plan to a meticulous 23 steps. They began by severing the cable running from the branching unit to Murayama in the south, catching the landward end, splicing the new cable to it, and sailing northward to the point where they planned to deposit the new branching unit. There, they attached the cable to a buoy and lowered it into the ocean. Then they were off to the northern cable, which they caught, spliced, and pulled back to the buoy. It took 12 days to get here, and now came the difficult part.</p>


			</div>
	

						<div>
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/33_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/33_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/33_mobile_min.jpg" alt="The cable jointing station aboard the Ocean Link. A large tarpaulin hangs over the station." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/33_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/34_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/34_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/34_mobile_min.jpg" alt="A close-up view of a metal vise, used to hold cables during repairs." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/34_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/44_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/44_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/44_mobile_min.jpg" alt="A cable is mounted in a vise and stripped to reveal the fiber strands at its core." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/44_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/45_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/45_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/45_mobile_min.jpg" alt="Each fiber is coated in colored enamel so workers can tell which is which." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/45_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/35_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/35_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/35_mobile_min.jpg" alt="Kurokawa selects a fiber to splice." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/35_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/36_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/36_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/36_mobile_min.jpg" alt="The colored enamel coating of the fiber is stripped, revealing the glass itself." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/36_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/37_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/37_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/37_mobile_min.jpg" alt="Kurokawa holds the stripped glass fiber close to the camera." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/37_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/38_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/38_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/38_mobile_min.jpg" alt="The fiber is cleaned in an ultrasound bath." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/38_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/39_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/39_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/39_mobile_min.jpg" alt="The fiber is cleaved at a right angle." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/39_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/40_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/40_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/40_mobile_min.jpg" alt="The fiber is placed inside the splicing machine. The stripping, cleaning, and cleaving process is repeated with the other fiber to be spliced and placed end to end with the first strand inside the machine." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/40_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/46_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/46_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/46_mobile_min.jpg" alt="" src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/46_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/41_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/41_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/41_mobile_min.jpg" alt="A plastic sheath is placed over the splice to reinforce it." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/41_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/42_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/42_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/42_mobile_min.jpg" alt="Each completed fiber splice is placed inside a sealed enclosure called a “joint box.”" src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/42_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
								</div>
	
			<div>
								<p>The final splice is the most precarious moment of the repair. On the first splice, the ship can pivot 360 degrees around the dangling cable in order to angle into the wind and waves and maintain position. But on the second splice, there are two cables hanging off the prow, and the ship’s maneuverability is far more restricted should the weather turn foul.</p>


								<p>With the branching unit, they had to complete two final splices — one for each leg — then deposit the whole apparatus to the ocean floor intact. This, the Ocean Link crew knew, would be its own challenge. A 2,000-pound weight dangling for miles through the water column can do funny things. In 2008, the Ocean Link was called to recover a branching unit that another cable ship accidentally dropped into the Japan Trench while trying to deploy it. With a typhoon approaching, they caught the cable, brought up the unit, and fashioned a webbing loincloth-like harness between the unit’s two legs for additional support before lowering it back to the bottom.</p>


								<p>They would again be working in deep water — nearly four miles — but what troubled Hirai was the current. A powerful river of warm water called the Kuroshio Current snakes unpredictably up from the south along Japan’s coast, and it happened to be racing through the worksite at four knots, aquamarine and glittering in the summer sun. The Ocean Link would have to constantly adjust its thrusters to maintain position against the stream and prevent the branching unit from banging against the hull as it descended. But the weather was fair and the swell was light, so they decided to proceed.&nbsp;</p>


								<p>Hirai, Kurokawa, Kobayashi, and more than a dozen other members of the crew assembled on the foredeck. The white-painted prow glared bright in the sun as the branching unit was brought out, a metal tube with two black accordion legs that tapered to slender cables. They had drilled this maneuver before leaving port. Clad in hard hats, the crew gingerly placed it on a metal dolly and strapped it down. Hirai tied yellow webbing between its legs to form a harness and affixed a safety rope. Kurokawa stood by the prow, watching the unit as it was rolled toward him. Kobayashi stood back by the drum engine, watching the cable unspool and worrying what would happen if it snapped, envisioning weeks of splicing plunging to the ocean floor. </p>


			</div>
	
					<div>
	<picture>
		<img data-sourcedesktop="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/47_min.jpg" data-sourcetablet="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/47_min.jpg" data-sourcemobile="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/47_mobile_min.jpg" alt="A group photo of the crew of the Ocean Link in 2011. The ship itself is in the background." src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/photos/min/47_mobile_min.jpg">
    	
    	
		<div>
					<p><img src="https://cdn.vox-cdn.com/csk/fe4f780a-1a25-4bcc-8489-4ea4403cece8/740a5e3d-5577-4a46-a47b-5580b718c574/images/logomark.svg" alt=""></p><p>Loading <span>.</span><span>.</span><span>.</span></p>
				</div>

	</picture>
	
</div>
	
			<div>
								<p>The ship’s thrusters hummed and moved the Ocean Link ever so slowly backward. One end of the branching unit lifted off the dolly as it was pulled up onto the bow sheave. To an observer, the ship would look nearly stationary as the current flowed around it. The unit went over the top of the prow and descended, hanging from its harness, until it slipped below the surface and out of sight.</p>


								<p>It was August by the time the Ocean Link finished the branching unit repair. Other ships, deeming the crisis at Fukushima stable enough to work, had arrived to help. Hirai sometimes advised them on the area’s tricky currents and rugged bathymetry, but mostly, they stayed out of each other’s way; the last thing you want to do is tangle two grapnels.</p>


								<p>The final repair was an easy one. They had to finish the job that had been interrupted by the earthquake nearly five months earlier. They returned to the site where they had made their rushed escape, deployed the submersible, and buried the rest of the cable beneath the sand.&nbsp;</p>


								<p>The repair was so close to port that there was no time to celebrate during their return, nor was there much of a mood to do so. The earthquake had caused more than 20 faults, and the Ocean Link had repaired 11 of them. It had taken 154 days of continuous work. They had missed a time of national mourning, school graduations, harvest celebrations, and the slow resumption of normalcy.&nbsp;</p>


								<p>After they docked, the crew departed for their homes. Hirai stayed behind to finish writing his final daily report, then made for home as well. As he rode the train back to Yokosuka, he watched his fellow passengers absorbed in their phones. <em>We completed the job,</em> he thought with satisfaction, <em>and they have no idea</em>. </p>


			</div>
<p><span>Creative Director: Kristen Radtke</span><span>Photo Editor: Amelia Holowaty Krales</span><span>Engineer: Graham MacAree</span>
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Know the secret to the quiet mind. I wish I'd never learned it (2021) (170 pts)]]></title>
            <link>https://www.theatlantic.com/health/archive/2021/06/car-accident-brain-injury/619227/</link>
            <guid>40074520</guid>
            <pubDate>Thu, 18 Apr 2024 09:50:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theatlantic.com/health/archive/2021/06/car-accident-brain-injury/619227/">https://www.theatlantic.com/health/archive/2021/06/car-accident-brain-injury/619227/</a>, See on <a href="https://news.ycombinator.com/item?id=40074520">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-event-module="article body" data-flatplan-body="true"><p data-flatplan-paragraph="true"><small><i data-stringify-type="italic">This article was featured in the One Story to Read Today newsletter. </i><i data-stringify-type="italic"><a data-event-element="inline link" data-sk="tooltip_parent" data-stringify-link="https://www.theatlantic.com/newsletters/sign-up/one-story-to-read-today/" delay="150" href="https://www.theatlantic.com/newsletters/sign-up/one-story-to-read-today/" rel="noopener noreferrer" target="_blank">Sign up for it here</a></i><i data-stringify-type="italic">.</i></small></p><p data-flatplan-paragraph="true">The worst things can happen on the most beautiful days. My family’s worst day was a perfect one in the summer of 2019. We picked my daughter up from camp and talked about where to go for lunch: the diner or the burger place. I don’t remember which we chose. What I do remember: being woken up, again and again, by doctors who insist on asking me the same questions—my name, where I am, what month it is—and telling me the same story, a story that I am sure is wrong.</p><p data-flatplan-paragraph="true">“You were in a car accident,” they say. But this cannot be. We’re having lunch and then going on a hike. I had promised the think tank where I work that I’d call in to a 4 p.m. meeting.</p><p data-flatplan-paragraph="true">“You are in Dartmouth-Hitchcock Hospital in New Hampshire.” Another ludicrous statement. I started the day in Vermont. Surely if I had crossed the river to New Hampshire I would know it.</p><p data-flatplan-paragraph="true">“What’s your name?” they ask me, and I tell them and tell them and tell them.</p><p data-flatplan-paragraph="true">“Where are you?” “New Hampshire,” I say, except for one time when I say “Vermont.” “New Hampshire,” they correct, and I want to say, “Really, we are so close to the border here, can’t you just give it to me this once?”</p><p data-flatplan-paragraph="true">“You were in a car accident,” they tell me again. “Your husband broke his leg and your son broke his collarbone.” These do not seem like horrible injuries, so I am waiting for the worse news, the news that my daughter is dead. She is the youngest and the smallest. She was born with albinism, and her existence has always felt improbable, and so now it must be over.</p><p data-flatplan-paragraph="true">But—thank God—it’s not. “Your daughter has fractures in her spine and damage to her lower intestine from the seat belt.” They tell me that my lower intestine was also injured, and that I’ve had surgery. I lift up my hospital gown and am surprised to see an angry red line and industrial-size staples. I remember an article I’d read about seat belts not being designed for women, and I ask the doctor if he sees more women with these injuries than men. I have yet to take in the reality of what has happened to me, to my family. Instead I am thinking about writing an exposé about the sexist seat-belt industry.</p><p data-flatplan-paragraph="true">They wake me up and ask me where I am and what my name is. A doctor asks me who the president is. “I don’t want to say,” I reply. He smiles. I am at Dartmouth for three days before I am transferred to the University of Vermont, where my husband and children are. The days pass like minutes, a loop of sleep interrupted by people asking me questions and telling me terrible things.</p><p id="injected-recirculation-link-0" data-view-action="view link - injected link - item 1" data-event-element="injected link" data-event-position="1"><a href="https://www.theatlantic.com/ideas/archive/2021/05/car-accident/618766/">Joshua Sharpe: </a><a href="https://www.theatlantic.com/ideas/archive/2021/05/car-accident/618766/">We should all be more afraid of driving</a></p><p data-flatplan-paragraph="true">One of the things I am told is that I have a brain bleed and a traumatic brain injury. I wonder if this is why I am slurring my words, but am told that the slurring is from the anti-seizure medication I am on. This sounds good. The slurring will stop. A doctor tells me I “got my bell rung.” This is a bad analogy. Bell clappers are meant to slam against the side of the bell. The brain is not meant to slam against the side of the skull.</p><p data-flatplan-paragraph="true" data-flatplan-dropcap="true">O<span>f all the injuries</span> my family is suffering from, mine is the worst. This is my totally biased opinion. My husband’s leg will take almost a year to heal. My daughter would have died if not for the surgery to repair her flayed abdomen. She is 10, and one of her friends tells her that because of the scar she will never be able to wear a bikini. She spends many days attempting to suss out whether she cares. She doesn’t yet know if she is the bikini-wearing type.</p><p data-flatplan-paragraph="true">My 13-year-old son is the only one who remembers the accident. He remembers a woman in a ponytail calling 911, the smell of gasoline and burnt metal. He remembers his father yelling “Jesus Christ.” He will have to live with the memory of his sister looking at my body and asking, “Is Mama dead?”</p><p data-flatplan-paragraph="true">These are terrible injuries, and yet, the other members of my family don’t walk around thinking, <em>Am I still me?</em> My brain injury has shaken my confidence in my own personality, my own existence. This is the worst injury.</p><p data-flatplan-paragraph="true">When we leave the hospital and move into a hotel, I frequently get lost in the hallway. The first time I roll into occupational therapy with my walker, I am grateful for the obvious signage pointing me toward the check-in desk. It’s almost as though the clinic is expecting people with brain damage.</p><p data-flatplan-paragraph="true">My therapist is a smiling, 40-something woman with dirty-blond hair. She reminds me of me before the accident. She asks if I am having any thinking problems or memory problems. I tell her about an incident with Parmesan cheese.</p><p data-flatplan-paragraph="true">“Can you get the Parmesan?” my husband asked.</p><p data-flatplan-paragraph="true">I opened the fridge and looked. I looked and looked.</p><p data-flatplan-paragraph="true">“I can’t find it,” I said with a shrug.</p><p data-flatplan-paragraph="true">My son opened the fridge and pulled out a block of Parmesan.</p><p data-flatplan-paragraph="true">It hadn’t occurred to me that this was a brain issue. Sometimes you just can’t find the Parmesan. Right?</p><p data-flatplan-paragraph="true">A test confirms that I have trouble<a data-event-element="inline link" href="https://msktc.org/tbi/factsheets/vision-problems-and-traumatic-brain-injury"> scanning a visual field</a> for objects. My brain is struggling to recognize what I see, but without a pre-accident baseline to judge from, there is no way to know how much worse I am at it now. Have I always been bad at finding things? Maybe? There are limits to how well an injured brain can scrutinize an injured brain.</p><p data-flatplan-paragraph="true">I have other visual-processing issues. At first I can’t watch television because my brain is unable to merge the images from my two eyes, so I see doubles of everything—two Phoebes, two Chandlers. I can watch with one eye closed, but I’m distracted, seething at my brain for failing to do such a simple task.</p><div data-flatplan-inline_image="true"><figure><picture><img alt="a face inside of a spiral" loading="lazy" sizes="(min-width: 729px) 655px, (min-width: 576px) calc(100vw - 48px), 100vw" srcset="https://cdn.theatlantic.com/thumbor/eiRQDwubiDbd9u68hFAUvHoFBho=/0x0:1080x1350/655x819/media/img/posts/2021/06/Patricia_Voulgaris/original.jpg 655w, https://cdn.theatlantic.com/thumbor/Xi73piGUB7i8lgSL109MioUqZ90=/0x0:1080x1350/750x938/media/img/posts/2021/06/Patricia_Voulgaris/original.jpg 750w, https://cdn.theatlantic.com/thumbor/J60ROHpmk9--89tS_nmkAFl22-g=/0x0:1080x1350/850x1063/media/img/posts/2021/06/Patricia_Voulgaris/original.jpg 850w, https://cdn.theatlantic.com/thumbor/3QBYBw90bCLgpcA-Zsh9DT5PWS0=/0x0:1080x1350/928x1160/media/img/posts/2021/06/Patricia_Voulgaris/original.jpg 928w" src="https://cdn.theatlantic.com/thumbor/eiRQDwubiDbd9u68hFAUvHoFBho=/0x0:1080x1350/655x819/media/img/posts/2021/06/Patricia_Voulgaris/original.jpg" width="655" height="819"></picture><figcaption>Patricia Voulgaris</figcaption></figure></div><p data-flatplan-paragraph="true">In one session, the therapist tells me we are going to play a game. She pulls out a deck of cards and asks me to turn cards over while saying the number or the color or the suit. The game is so difficult, I want to physically remove my brain from my skull and hurl it against a wall. I will never play this game again as long as I live.</p><p data-flatplan-paragraph="true">Eventually I graduate from occupational therapy. But occupational therapy isn’t about getting people back on their feet so they can return to think tanks. It is about making sure they can run errands without getting lost. I am someone who has always taken pride in my intelligence, and now I am not so smart. I am just a functional human being, according to occupational therapy.</p><p data-flatplan-paragraph="true" data-flatplan-dropcap="true">W<span>hen we go out in public</span> as a family, we are a walking nightmare. “Wow,” a stranger says, marveling at the device that is bolted into my husband’s femur. And then my son appears with his arm in a sling, my daughter limps over in her back brace. An injured couple is potentially funny. There is nothing funny about an injured family. “What happened to you guys?”</p><p data-flatplan-paragraph="true">When we tell the story, we explain that we were in no way at fault, which feels important. We wore our seat belts and drove the speed limit and the weather wasn’t bad and yet this happened to us. Someone was driving a pickup truck in the opposite direction. He was late to a job interview or to get his kid, or maybe he was just antsy. In front of him was a motorcycle slowing him down. Maybe he’d been behind that motorcycle for miles. Maybe he liked to take risks. He pulled into our lane and passed the motorcycle while going up a hill at 70 miles per hour. I don’t know who makes this kind of decision. Did he think, <em>I can’t believe I did something this stupid?</em> Did he also yell “Jesus Christ”?</p><p data-flatplan-paragraph="true">Because we are not at fault, <em>accident</em> feels like the wrong word. Not just wrong, but unfair. My husband starts calling it <em>the incident</em>, but an <em>incident</em> is a small thing, not something that scars you for life. <em>The smashing</em>? <em>The destruction</em>? <em>Newbury</em>, after the town where it occurred? The only thing that comes close is <em>the devastation</em>.</p><p data-flatplan-paragraph="true">The devastated me is different. My brain used to race, making lists and plans, skipping from an article I was researching to whether my kids were in appropriate after-school programs to what vacation we should take in February. Now it does none of that. There are no plans to make.</p><p data-flatplan-paragraph="true">A few days after regaining consciousness, I check my Twitter feed. I have always been a news junkie. But I have missed nothing. The news seems to be not just familiar but actually repeating itself. Something bonkers happened in the White House. People are dying in a country I’ve never been to. A company did something possibly illegal. There was a house fire in the Bronx. Are these the things I used to care about?</p><p data-flatplan-paragraph="true">The most interesting piece of news is the one I am experiencing. In the hospital we are waiting to make sure my daughter can poop through her reconstructed colon. This article isn’t in <em>The New York Times.</em></p><p data-flatplan-paragraph="true">When we return to New York I take the subway to doctor appointments. I don’t take out my phone, I just sit. My brain is quiet, which I find suspicious, but also soothing. Before the accident I went to yoga retreats and tried meditation. I said things like “I just need to unplug.” Apparently what I needed was to get hit by a truck. Perhaps I have discovered the secret to a peaceful mind, and it is traumatic brain injury. I fantasize about opening an expensive spa where busy people pay me money to whack them on the head with a baseball bat.</p><p data-flatplan-paragraph="true">The day of the accident I had been working on a project to improve how homeless people are placed into shelters. I say out loud, “I don’t care about homeless people” to see how it feels. It doesn’t ring true; I do care about homeless people. I just don’t feel like working. I have always been a regular exerciser. Now I can’t imagine wanting to do a burpee, let alone 10 of them. I always ate healthy things. But did you know that you can eat whole grains and still get hit by a truck?</p><p data-flatplan-paragraph="true">I have strange cravings. I think about apple cider all the time. Apple cider is not a normal part of my diet. I have a very detailed dream about eating chocolate cake. I eat the cake. That’s the entire dream. I find myself foraging in the fridge for flavors that don’t exist.</p><p data-flatplan-paragraph="true">I don’t know which symptoms are permanent and which are temporary. At first, the doctors say that after a year or two I’m likely to have a full return to my normal brain function. Or not. They don’t really know about the brain. It might be more like 95 percent. If I broke my elbow and someone told me I’d get 95 percent of my elbow function back, I’d be satisfied. But 95 percent of my brain function sounds terrifying. Which pieces will be missing?</p><p data-flatplan-paragraph="true">Some days I feel like myself. Other days all I can think about is the old life that is gone. Then, halfway through my recuperation, the coronavirus comes. The stores close, the schools close, the traffic on the avenue dwindles to a sporadic whoosh. And my busy friends who were always texting me about their crazy schedules are suddenly as quiet as I am. Together we wait for normal to return. The difference is that they know what normal looks like.</p><p data-flatplan-paragraph="true">In July it will be two years since the accident. The world is now coming back to life, my days slowly filling up with work and chores and exercise. Soon I will go back to in-person meetings and travel, and I wonder: Will I be up to the challenge? Or will I get lost in office buildings and airports?</p><p data-flatplan-paragraph="true">For now, in this liminal space between the old life and the new one, I often catch myself staring at my children. They have never been more beautiful. I chalk this up to the magic of braces––their teeth are finally coming into alignment––but I know this is ridiculous. They are beautiful because they are alive. I look at them, and I sit with the silence. Today, it is mine. Tomorrow, it may not be.</p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cosmic Desktop: Hammering Out New Cosmic Features (194 pts)]]></title>
            <link>https://blog.system76.com/post/hammering-out-cosmic-features</link>
            <guid>40074383</guid>
            <pubDate>Thu, 18 Apr 2024 09:24:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.system76.com/post/hammering-out-cosmic-features">https://blog.system76.com/post/hammering-out-cosmic-features</a>, See on <a href="https://news.ycombinator.com/item?id=40074383">Hacker News</a></p>
Couldn't get https://blog.system76.com/post/hammering-out-cosmic-features: Error: Request failed with status code 404]]></description>
        </item>
        <item>
            <title><![CDATA[OpenBSD – Coming soon to a -current system near you: parallel raw IP input (124 pts)]]></title>
            <link>https://www.undeadly.org/cgi?action=article;sid=20240418050520</link>
            <guid>40073139</guid>
            <pubDate>Thu, 18 Apr 2024 05:05:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.undeadly.org/cgi?action=article;sid=20240418050520">https://www.undeadly.org/cgi?action=article;sid=20240418050520</a>, See on <a href="https://news.ycombinator.com/item?id=40073139">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Contributed by
<a href="http://bsdly.blogspot.com/">Peter N. M. Hansteen</a>
on <time datetime="2024-04-11T22:05:42Z">2024-04-11</time>
from the all the packets all at once dept.</p>
<p>The work to improve the capabilities of the network stack is about to take a noticeable step forward. In a message to <code>tech@</code> titled <a href="https://marc.info/?l=openbsd-tech&amp;m=171286702531925&amp;w=2">parallel raw IP input</a>, Alexander Bluhm (<code>bluhm@</code>) posted a patch that he describes as</p>
<blockquote><pre>List:       openbsd-tech
Subject:    parallel raw IP input
From:       Alexander Bluhm &lt;bluhm () openbsd ! org&gt;
Date:       2024-04-11 20:24:39

Hi,

As mvs@ mentioned, running raw IP in parallel is easier as it is
less complex than UDP.  Especially there is no socket splicing.

So I fixed one race in rip_input() and reused my shared net lock
ip_deliver() loop.
</pre></blockquote>

<blockquote><pre>The idea is that ip_deliver() may run with shared or exclusive net
lock.  The last parameter indicates the mode.  If is is running
with shared netlock and encounters a protocol that needs exclusive
lock, the packet is queued.

Before ip_ours() always queued the packet.  Now it tries to deliver
with shared net lock, and if that is not possible, it queues the
packet.

In case we have an IPv6 header chain that must switch from shared
to exclusive processing, the next protocol and mbuf offset are
stored in a mbuf tag.

The only drawback is that we have very limited test coverage for
raw IP.  The ip_deliver() shared locking change works also with
UDP, Hvroje has tested it in 2022.

ok?

bluhm
</pre></blockquote>
<p>Followed by the patch itself, which should apply to a then-recent -current checkout.</p>
<p>a little later, the patch was 
<a href="https://marc.info/?l=openbsd-cvs&amp;m=171312744110261&amp;w=2">committed</a>:</p>
<blockquote>
<pre>CVSROOT:	/cvs
Module name:	src
Changes by:	bluhm@cvs.openbsd.org	2024/04/14 14:46:27

Modified files:
	sys/net        : if_bridge.c 
	sys/netinet    : in_proto.c ip_input.c ip_var.h 
	sys/netinet6   : ip6_input.c 
	sys/sys        : mbuf.h protosw.h 

Log message:
Run raw IP input in parallel.

Running raw <abbr>IPv4</abbr> input with shared net lock in parallel is less
complex than <abbr>UDP</abbr>.  Especially there is no socket splicing.

New ip_deliver() may run with shared or exclusive net lock.  The
last parameter indicates the mode.  If is is running with shared
netlock and encounters a protocol that needs exclusive lock, the
packet is queued.  Old ip_ours() always queued the packet.  Now it
calls ip_deliver() with shared net lock, and if that cannot handle
the packet completely, the packet is queued and later processed
with exclusive net lock.

In case of an <abbr>IPv6</abbr> header chain, that switches from shared to
exclusive processing, the next protocol and mbuf offset are stored
in a mbuf tag.

OK mvs@
</pre>
</blockquote>
<p>
Via email, <code>bluhm@</code> added some further explanation:
</p><blockquote><pre>The commit from January is sending UDP in parallel.  Socket send,
when called from userland, uses shared net lock.  You need multiple
UDP sockets and threads writing to them to see an effect.

Now we are working on parallel input.  When traffic is directed to
different IP or ports, the network hardware can distribute flows
to different receive queues.  These queues are processed by one CPU
each.  Goal is to keep procssing parallel until data reaches userland.

IP input and forward runs parallel for a while.  Until last week
all protocol input was single threaded.  Now raw IP can run in
parallel.

Next step is UDP input in parallel.  It kind of works, but locking
in socket splicing is wrong.  In my experiments I see increase in
UDP througput of factor 4 to 7.  But the locking problems are quite
nasty.  I think we need more tests that agressively splice and
unsplice sockets.

Advantage of UDP over raw IP would be that testing is much easier.

Final protocol will be TCP, but that is hardest of all.  Single
stream TCP performance already got a performance boost by hardware
offloading.

hardware receive =&gt; IP input -&gt; protocol input =&gt; userland =&gt;
protocol output =&gt; IP output =&gt; hardware transmit

bluhm@ is working on -&gt; protocol input to make it parallel for more
protocols.  It is the final bottle neck.

mvs@ is looking at =&gt; to and from userland.  They behave differently
for UNIX domain, raw IP, UDP, and TCP, the latter is still single
threaded.
</pre></blockquote>
<p>
This all boils down to <em>faster packets</em>, due to the system's now ever more increasing ability to fully utilize multiple cores to process network traffic.
</p><p>
Testing is of course still appreciated, but this code is anyway destined to be in the next release.
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lions OS: secure – fast – adaptable (130 pts)]]></title>
            <link>https://trustworthy.systems/publications/papers/Heiser_24:eo.abstract</link>
            <guid>40072731</guid>
            <pubDate>Thu, 18 Apr 2024 03:39:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://trustworthy.systems/publications/papers/Heiser_24:eo.abstract">https://trustworthy.systems/publications/papers/Heiser_24:eo.abstract</a>, See on <a href="https://news.ycombinator.com/item?id=40072731">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <main id="page-content">



<h2>Authors</h2>


<p>         &nbsp;&nbsp;&nbsp;&nbsp;School of Computer Science and Engineering <br>
             &nbsp;&nbsp;&nbsp;&nbsp;UNSW,<br>
         &nbsp;&nbsp;&nbsp;&nbsp;Sydney 2052, Australia
</p>

<h2>Abstract</h2><p>
  seL4 is the world's most secure operating system (OS) kernel, but
  it is a far cry from being an OS. As a microkernel, it provides core
  mechanisms for securely multiplexing the hardware, but none of the
  services application programmers expect, so adopters are forced to
  develop those themselves. Furthermore, a high level of expertise is
  required to design performant systems on top of seL4. The result is
  frequently a poor design, and far too often people giving up.
</p>

<p>
  The Trustworthy Systems team at UNSW has now decided to build Lions
  OS, a complete seL4-based OS aimed to support the needs of
  developers of cyberphysical, IoT and other embedded systems. Lions
  OS, named after John Lions (of Lions Book fame, arguably one of the
  fathers of open source), is being designed and implemented from
  scratch, with the seemingly conflicting goals of high performance,
  high security and adaptability to a wide class of use
  cases. Specifically we plan to prove the correct implementation of
  its critical components.
</p>

<p>
  In the talk I explain why I think this is not only achievable, but
  will be achieved within 2-3 years, by strictly adhering to the
  time-honoured engineering principle KISS – keep it simple, stupid! I
  will present our initial results that show that, with the right
  design, this simplicity can not only achieve excellent performance
  (outperforming Linux networking) but also enable proofs of
  implementation correctness. The talk serves as the public launch of
  Lions OS -- needless to say, it's open source.
</p>
<h2>BibTeX Entry</h2><pre>  @inproceedings{Heiser_24:eo,
    address          = {Gladstone, QLD, AU},
    author           = {Gernot Heiser},
    booktitle        = {Everything Open},
    month            = apr,
    organization     = {Linux Australia},
    title            = {{Lions OS}: Secure -- Fast -- Adaptable},
    year             = {2024}
  }</pre>
<h2>Download</h2>



      </main>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google fires 28 employees involved in sit-in protest over $1.2B Israel contract (145 pts)]]></title>
            <link>https://nypost.com/2024/04/17/business/google-fires-28-employees-involved-in-sit-in-protest-over-1-2b-israel-contract/</link>
            <guid>40072295</guid>
            <pubDate>Thu, 18 Apr 2024 02:17:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nypost.com/2024/04/17/business/google-fires-28-employees-involved-in-sit-in-protest-over-1-2b-israel-contract/">https://nypost.com/2024/04/17/business/google-fires-28-employees-involved-in-sit-in-protest-over-1-2b-israel-contract/</a>, See on <a href="https://news.ycombinator.com/item?id=40072295">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							


<p>Google has fired 28 employees over their participation in a 10-hour sit-in <a href="https://nypost.com/2024/04/16/business/google-staffers-storm-nyc-california-seattle-offices-to-protest-israel-ties/">at the search giant’s offices in New York and Sunnyvale, California</a>, to protest the company’s business ties with the Israel government, The Post has learned.</p>



<p>The pro-Palestinian staffers — who had donned traditional Arab headscarves as they stormed and occupied the office of a top executive in California on Tuesday — were terminated late Wednesday after an internal investigation, Google vice president of global security Chris Rackow said in a companywide memo.</p>



<p>“They took over office spaces, defaced our property, and physically impeded the work of other Googlers,” Rackow wrote in the memo obtained by The Post. “Their behavior was unacceptable, extremely disruptive, and made co-workers feel threatened.”</p>



<p>In New York, protesters had occupied the 10th floor of Google’s offices in the Chelsea section of Manhattan as part of a protest that also extended to the company’s offices in Seattle for what it called&nbsp;<a href="https://nypost.com/2024/03/05/business/google-engineer-accuses-company-exec-of-powering-genocide-over-israel-ties/">“No Tech for Genocide Day of Action.”</a></p>



<figure><div><p><a href="#" aria-controls="nyp-slideshow-modal" data-slideshow-modal="trigger" title="Open a slideshow of all 6 article images." aria-label="Open a slideshow of all 6 article images." data-slideshow-slide-number="1" data-slideshow-slides-total="6"><img decoding="async" fetchpriority="high" width="787" height="590" src="https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80168863.jpg?w=1024" alt="A large group of Google employees hold signs protesting their company's participation in &quot;Project Nimbus.&quot;" srcset="https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80168863.jpg?quality=75&amp;strip=all 1600w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80168863.jpg?resize=300,225&amp;quality=75&amp;strip=all 300w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80168863.jpg?resize=768,576&amp;quality=75&amp;strip=all 768w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80168863.jpg?resize=1024,768&amp;quality=75&amp;strip=all 1024w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80168863.jpg?resize=1536,1152&amp;quality=75&amp;strip=all 1536w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80168863.jpg?resize=945,709&amp;quality=75&amp;strip=all 945w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80168863.jpg?resize=333,250&amp;quality=75&amp;strip=all 333w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80168863.jpg?resize=785,589&amp;quality=75&amp;strip=all 785w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80168863.jpg?resize=661,496&amp;quality=75&amp;strip=all 661w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80168863.jpg?resize=120,90&amp;quality=75&amp;strip=all 120w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80168863.jpg?resize=576,432&amp;quality=75&amp;strip=all 576w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80168863.jpg?resize=440,330&amp;quality=75&amp;strip=all 440w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80168863.jpg?resize=376,282&amp;quality=75&amp;strip=all 376w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80168863.jpg?resize=180,135&amp;quality=75&amp;strip=all 180w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80168863.jpg?resize=124,93&amp;quality=75&amp;strip=all 124w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80168863.jpg?resize=95,71&amp;quality=75&amp;strip=all 95w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80168863.jpg?resize=200,150&amp;quality=75&amp;strip=all 200w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80168863.jpg?resize=231,173&amp;quality=75&amp;strip=all 231w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80168863.jpg?resize=322,242&amp;quality=75&amp;strip=all 322w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80168863.jpg?resize=77,58&amp;quality=75&amp;strip=all 77w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80168863.jpg?resize=208,156&amp;quality=75&amp;strip=all 208w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80168863.jpg?resize=150,113&amp;quality=75&amp;strip=all 150w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80168863.jpg?resize=50,38&amp;quality=75&amp;strip=all 50w" sizes="(max-width: 1024px) 100vw, 1024px"></a></p></div><figcaption>A large group of Google employees hold signs protesting their company’s participation in “Project Nimbus.” <span>X/@NoTechApartheid</span></figcaption></figure>



<p>“Behavior like this has no place in our workplace and we will not tolerate it,” Rackow wrote. “It clearly violates multiple policies that all employees must adhere to – including our&nbsp;code of conduct&nbsp;and&nbsp;policy on harassment, discrimination, retaliation, standards of conduct, and workplace concerns.”</p>



<p>Rackow added that the company “takes this extremely seriously, and we will continue to apply our longstanding policies to take action against disruptive behavior – up to and including termination.”</p>


		
		


<p>The fired staffers are affiliated with a group called No Tech For Apartheid, which has been critical of Google’s response to the Israel-Hamas war. </p>



<p>The group had posted several videos and livestreams of the protests on its X account — including the exact moment that employees were issued final warnings and arrested by local police for trespassing.</p>



<p>The protesters have demanded that Google pull out of a $1.2 billion “Project Nimbus” contract — in which Google Cloud and Amazon Web Services provide cloud-computing and artificial intelligence services for the Israeli government and military.</p>



<figure><div><p><a href="#" aria-controls="nyp-slideshow-modal" data-slideshow-modal="trigger" title="Open a slideshow of all 6 article images." aria-label="Open a slideshow of all 6 article images." data-slideshow-slide-number="2" data-slideshow-slides-total="6"><img decoding="async" loading="lazy" width="989" height="590" src="https://nypost.com/wp-content/uploads/sites/2/2024/04/protester-pictured-wearing-har-says-80167973_05525c.jpg?w=1024" alt="Protester pictured wearing a har that says &quot;You are on Native land&quot; " srcset="https://nypost.com/wp-content/uploads/sites/2/2024/04/protester-pictured-wearing-har-says-80167973_05525c.jpg?quality=75&amp;strip=all 1044w, https://nypost.com/wp-content/uploads/sites/2/2024/04/protester-pictured-wearing-har-says-80167973_05525c.jpg?resize=300,179&amp;quality=75&amp;strip=all 300w, https://nypost.com/wp-content/uploads/sites/2/2024/04/protester-pictured-wearing-har-says-80167973_05525c.jpg?resize=768,458&amp;quality=75&amp;strip=all 768w, https://nypost.com/wp-content/uploads/sites/2/2024/04/protester-pictured-wearing-har-says-80167973_05525c.jpg?resize=1024,611&amp;quality=75&amp;strip=all 1024w, https://nypost.com/wp-content/uploads/sites/2/2024/04/protester-pictured-wearing-har-says-80167973_05525c.jpg?resize=419,250&amp;quality=75&amp;strip=all 419w, https://nypost.com/wp-content/uploads/sites/2/2024/04/protester-pictured-wearing-har-says-80167973_05525c.jpg?resize=878,524&amp;quality=75&amp;strip=all 878w, https://nypost.com/wp-content/uploads/sites/2/2024/04/protester-pictured-wearing-har-says-80167973_05525c.jpg?resize=744,444&amp;quality=75&amp;strip=all 744w, https://nypost.com/wp-content/uploads/sites/2/2024/04/protester-pictured-wearing-har-says-80167973_05525c.jpg?resize=151,90&amp;quality=75&amp;strip=all 151w, https://nypost.com/wp-content/uploads/sites/2/2024/04/protester-pictured-wearing-har-says-80167973_05525c.jpg?resize=576,344&amp;quality=75&amp;strip=all 576w, https://nypost.com/wp-content/uploads/sites/2/2024/04/protester-pictured-wearing-har-says-80167973_05525c.jpg?resize=440,263&amp;quality=75&amp;strip=all 440w, https://nypost.com/wp-content/uploads/sites/2/2024/04/protester-pictured-wearing-har-says-80167973_05525c.jpg?resize=424,253&amp;quality=75&amp;strip=all 424w, https://nypost.com/wp-content/uploads/sites/2/2024/04/protester-pictured-wearing-har-says-80167973_05525c.jpg?resize=180,107&amp;quality=75&amp;strip=all 180w, https://nypost.com/wp-content/uploads/sites/2/2024/04/protester-pictured-wearing-har-says-80167973_05525c.jpg?resize=140,84&amp;quality=75&amp;strip=all 140w, https://nypost.com/wp-content/uploads/sites/2/2024/04/protester-pictured-wearing-har-says-80167973_05525c.jpg?resize=107,64&amp;quality=75&amp;strip=all 107w, https://nypost.com/wp-content/uploads/sites/2/2024/04/protester-pictured-wearing-har-says-80167973_05525c.jpg?resize=200,119&amp;quality=75&amp;strip=all 200w, https://nypost.com/wp-content/uploads/sites/2/2024/04/protester-pictured-wearing-har-says-80167973_05525c.jpg?resize=231,138&amp;quality=75&amp;strip=all 231w, https://nypost.com/wp-content/uploads/sites/2/2024/04/protester-pictured-wearing-har-says-80167973_05525c.jpg?resize=322,192&amp;quality=75&amp;strip=all 322w, https://nypost.com/wp-content/uploads/sites/2/2024/04/protester-pictured-wearing-har-says-80167973_05525c.jpg?resize=87,52&amp;quality=75&amp;strip=all 87w, https://nypost.com/wp-content/uploads/sites/2/2024/04/protester-pictured-wearing-har-says-80167973_05525c.jpg?resize=234,140&amp;quality=75&amp;strip=all 234w, https://nypost.com/wp-content/uploads/sites/2/2024/04/protester-pictured-wearing-har-says-80167973_05525c.jpg?resize=150,90&amp;quality=75&amp;strip=all 150w, https://nypost.com/wp-content/uploads/sites/2/2024/04/protester-pictured-wearing-har-says-80167973_05525c.jpg?resize=50,30&amp;quality=75&amp;strip=all 50w" sizes="(max-width: 1024px) 100vw, 1024px"></a></p></div><figcaption>The unruly staffers were terminated late Wednesday. <span>Twitch/notech4apartheid</span></figcaption></figure>



<p>Critics at the company raised concerns that the technology would be weaponized against Palestinians in Gaza.</p>



<p>The impacted workers blasted Google over the firings in a statement shared by No Tech For Apartheid spokesperson Jane Chung.</p>



<p>“This evening, Google indiscriminately fired 28 workers, including those among us who did not directly participate in yesterday’s historic, bicoastal 10-hour sit-in protests,” the workers said in the statement.</p>



<p>“This flagrant act of retaliation is a clear indication that Google values its $1.2 billion contract with the genocidal Israeli government and military more than its own workers — the ones who create real value for executives and shareholders.”</p>



<figure><div><p><a href="#" aria-controls="nyp-slideshow-modal" data-slideshow-modal="trigger" title="Open a slideshow of all 6 article images." aria-label="Open a slideshow of all 6 article images." data-slideshow-slide-number="3" data-slideshow-slides-total="6"><img decoding="async" loading="lazy" width="1024" height="574" src="https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167355_aae76b.jpg?w=1024" alt="Possibly inside Thomas Kurian's office " srcset="https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167355_aae76b.jpg?quality=75&amp;strip=all 1971w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167355_aae76b.jpg?resize=300,168&amp;quality=75&amp;strip=all 300w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167355_aae76b.jpg?resize=768,430&amp;quality=75&amp;strip=all 768w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167355_aae76b.jpg?resize=1024,574&amp;quality=75&amp;strip=all 1024w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167355_aae76b.jpg?resize=1536,860&amp;quality=75&amp;strip=all 1536w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167355_aae76b.jpg?resize=1064,596&amp;quality=75&amp;strip=all 1064w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167355_aae76b.jpg?resize=446,250&amp;quality=75&amp;strip=all 446w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167355_aae76b.jpg?resize=878,492&amp;quality=75&amp;strip=all 878w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167355_aae76b.jpg?resize=744,417&amp;quality=75&amp;strip=all 744w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167355_aae76b.jpg?resize=161,90&amp;quality=75&amp;strip=all 161w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167355_aae76b.jpg?resize=576,323&amp;quality=75&amp;strip=all 576w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167355_aae76b.jpg?resize=440,246&amp;quality=75&amp;strip=all 440w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167355_aae76b.jpg?resize=424,237&amp;quality=75&amp;strip=all 424w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167355_aae76b.jpg?resize=180,101&amp;quality=75&amp;strip=all 180w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167355_aae76b.jpg?resize=140,78&amp;quality=75&amp;strip=all 140w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167355_aae76b.jpg?resize=107,60&amp;quality=75&amp;strip=all 107w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167355_aae76b.jpg?resize=200,112&amp;quality=75&amp;strip=all 200w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167355_aae76b.jpg?resize=231,129&amp;quality=75&amp;strip=all 231w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167355_aae76b.jpg?resize=322,180&amp;quality=75&amp;strip=all 322w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167355_aae76b.jpg?resize=87,49&amp;quality=75&amp;strip=all 87w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167355_aae76b.jpg?resize=234,131&amp;quality=75&amp;strip=all 234w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167355_aae76b.jpg?resize=150,84&amp;quality=75&amp;strip=all 150w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167355_aae76b.jpg?resize=50,28&amp;quality=75&amp;strip=all 50w" sizes="(max-width: 1024px) 100vw, 1024px"></a></p></div><figcaption>Some donned traditional Arab headscarves as they stormed and occupied the office of a top executive in California. <span>Twitch/notech4apartheid</span></figcaption></figure>



<p>“Sundar Pichai and Thomas Kurian are genocide profiteers,” the statement added, referring to Google’s CEO and the CEO of its cloud unit, respectively. </p>



<p>“We cannot comprehend how these men are able to sleep at night while their tech has enabled 100,000 Palestinians killed, reported missing, or wounded in the last six months of Israel’s genocide — and counting.”</p>



<div>
			
			<div>
				<h3>
					Start your day with the latest business news right at your fingertips				</h3>
				<p>
					Subscribe to our daily Business Report newsletter!				</p>
			</div>
			<p>
				<h3>
					Thanks for signing up!				</h3>
			</p>
		</div>



<p>An NYPD spokesperson said the Tuesday protest “involved approximately 50 participants” in total and confirmed “four arrests were made for trespassing inside the Google building.”</p>



<p>The Sunnyvale Department of Public Safety said the protest in California “consisted of around 80 participants.”&nbsp;A total of five protesters who refused to leave the Google office were “arrested without incident for criminal trespassing,” booked and released, a spokesperson added.</p>



<p>It couldn’t immediately be learned if all nine arrested employees were among those who were fired. Google had earlier placed the employees on administrative leave and cut their access to internal systems.</p>



<figure><div><p><a href="#" aria-controls="nyp-slideshow-modal" data-slideshow-modal="trigger" title="Open a slideshow of all 6 article images." aria-label="Open a slideshow of all 6 article images." data-slideshow-slide-number="4" data-slideshow-slides-total="6"><img decoding="async" loading="lazy" width="437" height="590" src="https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167211_935306.jpg?w=759" alt="Possibly inside Thomas Kurian's office " srcset="https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167211_935306.jpg?quality=75&amp;strip=all 999w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167211_935306.jpg?resize=222,300&amp;quality=75&amp;strip=all 222w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167211_935306.jpg?resize=768,1036&amp;quality=75&amp;strip=all 768w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167211_935306.jpg?resize=759,1024&amp;quality=75&amp;strip=all 759w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167211_935306.jpg?resize=525,709&amp;quality=75&amp;strip=all 525w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167211_935306.jpg?resize=185,250&amp;quality=75&amp;strip=all 185w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167211_935306.jpg?resize=437,589&amp;quality=75&amp;strip=all 437w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167211_935306.jpg?resize=368,496&amp;quality=75&amp;strip=all 368w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167211_935306.jpg?resize=67,90&amp;quality=75&amp;strip=all 67w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167211_935306.jpg?resize=477,644&amp;quality=75&amp;strip=all 477w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167211_935306.jpg?resize=364,491&amp;quality=75&amp;strip=all 364w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167211_935306.jpg?resize=209,282&amp;quality=75&amp;strip=all 209w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167211_935306.jpg?resize=300,405&amp;quality=75&amp;strip=all 300w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167211_935306.jpg?resize=153,206&amp;quality=75&amp;strip=all 153w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167211_935306.jpg?resize=69,93&amp;quality=75&amp;strip=all 69w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167211_935306.jpg?resize=53,71&amp;quality=75&amp;strip=all 53w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167211_935306.jpg?resize=148,200&amp;quality=75&amp;strip=all 148w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167211_935306.jpg?resize=231,312&amp;quality=75&amp;strip=all 231w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167211_935306.jpg?resize=322,434&amp;quality=75&amp;strip=all 322w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167211_935306.jpg?resize=43,58&amp;quality=75&amp;strip=all 43w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167211_935306.jpg?resize=116,156&amp;quality=75&amp;strip=all 116w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167211_935306.jpg?resize=150,202&amp;quality=75&amp;strip=all 150w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167211_935306.jpg?resize=37,50&amp;quality=75&amp;strip=all 37w" sizes="(max-width: 759px) 100vw, 759px"></a></p></div><figcaption>When reached for comment, a Google spokesperson confirmed the firings. <span>X/@NoTechApartheid</span></figcaption></figure>



<p>Last month,&nbsp;<a href="https://nypost.com/2024/03/08/business/google-fires-engineer-who-claimed-company-powering-genocide/">Google fired a software engineer</a>&nbsp;who publicly blasted one of the company’s Israel-based executives during a tech conference in New York City.</p>



<p>When reached for comment, a Google spokesperson confirmed the firings.</p>



<p>“These protests were part of a longstanding campaign by a group of organizations and people who largely don’t work at Google,” the spokesperson said in a statement. </p>



<figure><div><p><a href="#" aria-controls="nyp-slideshow-modal" data-slideshow-modal="trigger" title="Open a slideshow of all 6 article images." aria-label="Open a slideshow of all 6 article images." data-slideshow-slide-number="5" data-slideshow-slides-total="6"><img decoding="async" loading="lazy" width="443" height="590" src="https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167203_698d91.jpg?w=768" alt="Possibly inside Thomas Kurian's office " srcset="https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167203_698d91.jpg?quality=75&amp;strip=all 1536w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167203_698d91.jpg?resize=225,300&amp;quality=75&amp;strip=all 225w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167203_698d91.jpg?resize=768,1024&amp;quality=75&amp;strip=all 768w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167203_698d91.jpg?resize=1152,1536&amp;quality=75&amp;strip=all 1152w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167203_698d91.jpg?resize=532,709&amp;quality=75&amp;strip=all 532w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167203_698d91.jpg?resize=188,250&amp;quality=75&amp;strip=all 188w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167203_698d91.jpg?resize=442,589&amp;quality=75&amp;strip=all 442w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167203_698d91.jpg?resize=372,496&amp;quality=75&amp;strip=all 372w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167203_698d91.jpg?resize=68,90&amp;quality=75&amp;strip=all 68w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167203_698d91.jpg?resize=483,644&amp;quality=75&amp;strip=all 483w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167203_698d91.jpg?resize=368,491&amp;quality=75&amp;strip=all 368w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167203_698d91.jpg?resize=212,282&amp;quality=75&amp;strip=all 212w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167203_698d91.jpg?resize=300,400&amp;quality=75&amp;strip=all 300w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167203_698d91.jpg?resize=155,206&amp;quality=75&amp;strip=all 155w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167203_698d91.jpg?resize=70,93&amp;quality=75&amp;strip=all 70w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167203_698d91.jpg?resize=53,71&amp;quality=75&amp;strip=all 53w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167203_698d91.jpg?resize=150,200&amp;quality=75&amp;strip=all 150w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167203_698d91.jpg?resize=231,308&amp;quality=75&amp;strip=all 231w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167203_698d91.jpg?resize=322,429&amp;quality=75&amp;strip=all 322w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167203_698d91.jpg?resize=44,58&amp;quality=75&amp;strip=all 44w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167203_698d91.jpg?resize=117,156&amp;quality=75&amp;strip=all 117w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167203_698d91.jpg?resize=640,853&amp;quality=75&amp;strip=all 640w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167203_698d91.jpg?resize=38,50&amp;quality=75&amp;strip=all 38w" sizes="(max-width: 768px) 100vw, 768px"></a></p></div><figcaption>“These protests were part of a longstanding campaign by a group of organizations and people who largely don’t work at Google,” the spokesperson said in a statement. <span>X/@NoTechApartheid</span></figcaption></figure>



<p>“A small number of employee protesters entered and disrupted a few of our locations. Physically impeding other employees’ work and preventing them from accessing our facilities is a clear violation of our policies, and completely unacceptable behavior.”</p>



<p>“We have so far concluded individual investigations that resulted in the termination of employment for 28 employees, and will continue to investigate and take action as needed,” the spokesperson added.</p>



<p>The demonstrators stormed the personal office of Google Cloud CEO Thomas Kurian in Sunnyvale.</p>



<p>Kurian’s custom-made, framed Golden State Warriors jersey was visible on the office wall in the background of the livestream, and employees wrote a list of their demands on his white board.</p>



<figure><div><p><a href="#" aria-controls="nyp-slideshow-modal" data-slideshow-modal="trigger" title="Open a slideshow of all 6 article images." aria-label="Open a slideshow of all 6 article images." data-slideshow-slide-number="6" data-slideshow-slides-total="6"><img decoding="async" loading="lazy" width="444" height="590" src="https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?w=771" alt="Possibly inside Thomas Kurian's office " srcset="https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?quality=75&amp;strip=all 1542w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?resize=226,300&amp;quality=75&amp;strip=all 226w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?resize=768,1020&amp;quality=75&amp;strip=all 768w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?resize=771,1024&amp;quality=75&amp;strip=all 771w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?resize=1157,1536&amp;quality=75&amp;strip=all 1157w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?resize=534,709&amp;quality=75&amp;strip=all 534w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?resize=188,250&amp;quality=75&amp;strip=all 188w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?resize=443,589&amp;quality=75&amp;strip=all 443w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?resize=373,496&amp;quality=75&amp;strip=all 373w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?resize=68,90&amp;quality=75&amp;strip=all 68w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?resize=485,644&amp;quality=75&amp;strip=all 485w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?resize=370,491&amp;quality=75&amp;strip=all 370w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?resize=212,282&amp;quality=75&amp;strip=all 212w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?resize=300,398&amp;quality=75&amp;strip=all 300w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?resize=155,206&amp;quality=75&amp;strip=all 155w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?resize=70,93&amp;quality=75&amp;strip=all 70w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?resize=53,71&amp;quality=75&amp;strip=all 53w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?resize=151,200&amp;quality=75&amp;strip=all 151w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?resize=231,307&amp;quality=75&amp;strip=all 231w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?resize=322,428&amp;quality=75&amp;strip=all 322w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?resize=44,58&amp;quality=75&amp;strip=all 44w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?resize=117,156&amp;quality=75&amp;strip=all 117w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?resize=150,199&amp;quality=75&amp;strip=all 150w, https://nypost.com/wp-content/uploads/sites/2/2024/04/possibly-inside-thomas-kurians-office-80167204_f8dd20.jpg?resize=38,50&amp;quality=75&amp;strip=all 38w" sizes="(max-width: 771px) 100vw, 771px"></a></p></div><figcaption>Critics at the company raised concerns that the technology would be weaponized against Palestinians in Gaza. <span>X/@NoTechApartheid</span></figcaption></figure>



<p>The companywide memo can be read in its entirety below.</p>



<p><em>Googlers,</em></p>



<p><em>You may have seen reports of protests at some of our offices yesterday. Unfortunately, a number of employees brought the event into our buildings in New York and Sunnyvale. They took over office spaces, defaced our property, and physically impeded the work of other Googlers. Their behavior was unacceptable, extremely disruptive, and made co-workers feel threatened. We placed employees involved under investigation and cut their access to our systems. Those who refused to leave were arrested by law enforcement and removed from our offices.&nbsp;</em></p>



<p><em>Following investigation, today we terminated the employment of twenty-eight employees found to be involved.&nbsp;We will continue to investigate and take action as needed.</em></p>



<p><em>Behavior like this has no place in our workplace and we will not tolerate it. It clearly violates multiple policies that all employees must adhere to – including our&nbsp;Code of Conduct&nbsp;and&nbsp;Policy on Harassment, Discrimination, Retaliation, Standards of Conduct, and Workplace Concerns.</em></p>







<p><em>We are a place of business and every Googler is expected to read our policies and apply them to how they conduct themselves and communicate in our workplace. The overwhelming majority of our employees do the right thing. If you’re one of the few who are tempted to think we’re going to overlook conduct that violates our policies, think again. The company takes this extremely seriously, and we will continue to apply our longstanding policies to take action against disruptive behavior – up to and including termination.&nbsp;</em></p>



<p><em>You should expect to hear more from leaders about standards of behavior and discourse in the workplace.</em></p>



<p><em>Chris</em></p>
						</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Goldene: A single atom layer of gold (200 pts)]]></title>
            <link>https://liu.se/en/news-item/ett-atomlager-guld-liu-forskare-skapar-gulden</link>
            <guid>40071956</guid>
            <pubDate>Thu, 18 Apr 2024 01:09:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://liu.se/en/news-item/ett-atomlager-guld-liu-forskare-skapar-gulden">https://liu.se/en/news-item/ett-atomlager-guld-liu-forskare-skapar-gulden</a>, See on <a href="https://news.ycombinator.com/item?id=40071956">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
                <header>
                    <p>16 April 2024</p>

                        
                </header>
                <p>
                    For the first time, scientists have managed to create sheets of gold only a single atom layer thick. The material has been termed goldene. According to researchers from Linköping University, Sweden, this has given the gold new properties that can make it suitable for use in applications such as carbon dioxide conversion, hydrogen production, and production of value-added chemicals.
                </p>
                    <figure>
                        <img src="https://liu.se/dfsmedia/dd35e243dfb7406993c1815aaf88a675/83338-50063/lars-hultman-och-shun-kashiwaya-20240223-19" alt="Two researchers in a lab.">
                            <figcaption>
                                    <span>Together with colleagues researchers Lars Hultman and Shun Kashiwaya have created goldene.</span>
                                                                                                    <span>Olov Planthaber</span>
                            </figcaption>
                    </figure>
                


                <div data-component="textfade">
                        <p>Scientists have long tried to make single-atom-thick sheets of gold but failed because the metal’s tendency to lump together. But researchers from Linköping University have now succeeded thanks to a hundred-year-old method used by Japanese smiths.</p>
<p>“If you make a material extremely thin, something extraordinary happens – as with graphene. The same thing happens with gold. As you know, gold is usually a metal, but if single-atom-layer thick, the gold can become a semiconductor instead,” says Shun Kashiwaya, researcher at the Materials Design Division at Linköping University.</p>
<h2>3D base material</h2>
<p>To create goldene, the researchers used a three-dimensional base material where gold is embedded between layers of titanium and carbon. But coming up with goldene proved to be a challenge. According to Lars Hultman, professor of thin film physics at Linköping University, part of the progress is due to serendipidy.</p>
<figure><img src="https://liu.se/dfsmedia/dd35e243dfb7406993c1815aaf88a675/83341-50063/lars-hultman-20240223-16" alt="Researcher holds small disc with tweezers close to face."><figcaption><span>Lars Hultman, professor of thin film physics at the Department of physics, chemistry and biology (IFM).</span><span aria-label="Photo credit">Olov Planthaber</span> </figcaption></figure>
<p>“We had created the base material with completely different applications in mind. We started with an electrically conductive ceramics called titanium silicon carbide, where silicon is in thin layers. Then the idea was to coat the material with gold to make a contact. But when we exposed the component to high temperature, the silicon layer was replaced by gold inside the base material,” says Lars Hultman.</p>
<p>This phenomenon is called intercalation and what the researchers had discovered was titanium gold carbide. For several years, the researchers have had titanium gold carbide without knowing how the gold can be exfoliated or panned out, so to speak.</p>
<h2>Japanese forging art</h2>
<p>By chance, Lars Hultman found a method that has been used in Japanese forging art for over a hundred years. It is called Murakami’s reagent, which etches away carbon residue and changes the colour of steel in knife making, for example. But it was not possible to use the exact same recipe as the smiths did. Shun Kashiwaya had to look at modifications:</p>
<figure><img src="https://liu.se/dfsmedia/dd35e243dfb7406993c1815aaf88a675/83345-50063/shun-kashiwaya-20240223-9" alt="Researcher in lab."><figcaption><span>Shun Kashiwaya, researcher at IFM.</span><span aria-label="Photo credit">Olov Planthaber</span> </figcaption></figure>
<p>“I tried different concentrations of Murakami’s reagent and different time spans for etching. One day, one week, one month, several months. What we noticed was that the lower the concentration and the longer the etching process, the better. But it still wasn’t enough,” he says.</p>
<p>The etching must also be carried out in the dark as cyanide develops in the reaction when it is struck by light, and it dissolves gold. The last step was to get the gold sheets stable. To prevent the exposed two-dimensional sheets from curling up, a surfactant was added. In this case, a long molecule that separates and stabilises the sheets, i.e. a tenside.</p>
<p>“The goldene sheets are in a solution, a bit like cornflakes in milk. Using a type of “sieve”, we can collect the gold and examine it using an electron microscope to confirm that we have succeeded. Which we have,” says Shun Kashiwaya.</p>
<h2>Many possible applications</h2>
<p>The new properties of goldene are due to the fact that the gold has two free bonds when two-dimensional. Thanks to this, future applications could include carbon dioxide conversion, hydrogen-generating catalysis, selective production of value-added chemicals, hydrogen production, water purification, communication, and much more.</p>
<figure><img src="https://liu.se/dfsmedia/dd35e243dfb7406993c1815aaf88a675/83344-50063/lars-hultman-och-shun-kashiwaya-20240223-21" alt="Researchers pour liquid into a beaker."><figcaption><span>To create goldene, the researchers used a three-dimensional base material where gold is embedded between layers of titanium and carbon.</span><span aria-label="Photo credit">Olov Planthaber</span> </figcaption></figure><p> Moreover, the amount of gold used in applications today can be much reduced.
</p><p>The next step for the LiU researchers is to investigate whether it is possible to do the same with other noble metals and identify additional future applications.</p>
<p>The research was funded by the Swedish Research Council, the Swedish Government Strategic Research Area in Materials Science (AFM) at Linköping University, the Knut and Alice Wallenberg Foundation, the Åforsk Foundation, the Olle Enqvist Foundation, the Carl Trygger Foundation, the Göran Gustafsson Foundations, MIRAI 2.0, the Swedish National Infrastructure for Computing (SNIC), and the National Academic Infrastructure for Supercomputing in Sweden (NAISS).</p>
<p><strong>Article:</strong> <a rel="noopener noreferrer" href="https://www.nature.com/articles/s44160-024-00518-4" target="_blank">Synthesis of goldene comprising single-atom layer gold</a>,&nbsp;Shun Kashiwaya, Yuchen Shi, Jun Lu, Davide G. Sangiovanni, Grzegorz Greczynski, Martin Magnuson, Mike Andersson, Johanna Rosen, and Lars Hultman; <em>Nature Synthesis</em>, published online 16 April 2024, DOI: 10.1038/s44160-024-00518-4</p>
<figure><img src="https://liu.se/dfsmedia/dd35e243dfb7406993c1815aaf88a675/83342-50063/lars-hultman-och-shun-kashiwaya-20240223-17" alt="Two researchers in a lab."><figcaption><span>LiU-researchers Shun Kashiwaya and Lars Hultman have succeeded in creating goldene thanks to a hundred-year-old method used by Japanese smiths.</span><span aria-label="Photo credit">Olov Planthaber</span> </figcaption></figure><br>
                    </div>
                
            </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Implementing Natural Conversational Agents with Elixir (174 pts)]]></title>
            <link>https://seanmoriarity.com/2024/02/25/implementing-natural-conversational-agents-with-elixir/</link>
            <guid>40071843</guid>
            <pubDate>Thu, 18 Apr 2024 00:53:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://seanmoriarity.com/2024/02/25/implementing-natural-conversational-agents-with-elixir/">https://seanmoriarity.com/2024/02/25/implementing-natural-conversational-agents-with-elixir/</a>, See on <a href="https://news.ycombinator.com/item?id=40071843">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<p>In <a href="https://seanmoriarity.com/2024/02/25/nero-part-1-home-automations/">my last post</a>, I discussed some work I had done building Nero, the assistant of the future that I’ve always wanted. I ended up creating an end-to-end example which used Nx, OpenAI APIs, and ElevenLabs to create an in-browser home automation assistant. For a first product, it’s decent. Nero is a neat little party trick that I can use to impress my non-tech friends. I am, however, not in this business to impress my friends. I want Nero to <em>actually help me</em> and <em>actually feel like an assistant</em>. My previous version is not that.</p>



<p>One missing piece is the ability to converse naturally without browser interaction. The first implementation of Nero’s “conversational” abilities relied on user interaction with the screen every time we wanted to initiate a response or action. Nero also did not retain any conversational history. In short, Nero was not a great conversational assistant. It was one of the things I wanted to fix; however, I was motivated to do it sooner rather than later after watching <a href="https://beta.retellai.com/home-agent">an impressive demo from Retell</a>.</p>



<p>The Retell demo implements a conversational agent backed by their WebSocket API in a browser. The demonstration has:</p>



<ul>
<li>“Always on” recording</li>



<li>Low latency</li>



<li>Support for interrupts</li>



<li>Impressive filtering (e.g. snapping and other non-voice activity doesn’t seem to throw off the agent)</li>
</ul>



<p>Their documentation suggests they also have support for <a href="https://www.cs.utep.edu/nigel/bc/#:~:text=What%20is%20a%20Backchannel%3F,utterances%20such%20as%20uh%2Dhuh.">backchanneling</a> and intelligent end of turn detection—two things that are essential to natural conversational feel but which are very difficult to express programmatically.</p>



<p>I had previously convinced myself that I could implement a passable conversational agent experience in a short amount of time. So that is what I set out to do.</p>



<h2>Always On Recording</h2>



<p>The first thing that needed to change about Nero’s design was the speech to text pipeline. My original demonstration relied on an <a href="https://github.com/elixir-nx/bumblebee/blob/main/examples/phoenix/speech_to_text.exs">example from Bumblebee</a> which implemented a speech to text pipeline using Whisper. The pipeline uses mouse events in a <a href="https://hexdocs.pm/phoenix_live_view/js-interop.html#client-hooks-via-phx-hook">Phoenix LiveView Hook</a> to start and stop recordings before sending them to the server to initiate transcription. If you’re not familiar, <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html">Phoenix LiveView</a> is a server-side rendering framework built on top of Elixir. LiveView has support for client-side JavaScript hooks which support bidirectional communication between client and server.</p>



<p>The original speech to text implementation used a hook with an event listener attached to <code>mousedown</code> and <code>mouseup</code> on a button to start and stop recording. After recording stops, the hook decodes the recorded buffer into a PCM buffer, converts the endianness, and then pushes the buffer to the server with an upload. The original hook implements most of the functionality we want; however, we need to make some minor tweaks. Rather than trigger recordings to stop and start on mouse events, we want to trigger recordings to start and stop exactly when a person starts and stops speaking. Simple, right?</p>



<p>My first idea in implementing what I called “always on recording” was to monitor the microphone’s volume, and trigger a recording when the volume reached a certain threshold. The recording would stop when the volume dipped below that threshold. At this point, I learned about <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia">getUserMedia</a>. <code>getUserMedia</code> prompts the user for permission to access media devices such as a microphone and/or webcam, and then produces a <code>MediaStream</code>. A <code>MediaStream</code> is a stream of media content containing information about audio and video tracks in the stream. We can use data from the <code>MediaStream</code> to determine speaker activity and thus trigger recordings.</p>



<p>To determine the volume for a given sample, we can use an <a href="https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode">AnalyserNode</a>. Per the documentation <code>AnyalyserNode</code> is designed for processing generated audio data for visualization purposes, but we can use it to determine spikes in audio:</p>


<div><pre title="">navigator.mediaDevices.getUserMedia({ audio: true }).then((stream) =&gt; {
  this.stream = stream;
  const analyser = this.audioContext.createAnalyser();
  const microphone = this.audioContext.createMediaStreamSource(this.stream);

  microphone.connect(analyser);

  analyser.fftSize = 512;
  const bufferLength = analyser.frequencyBinCount;
  const dataArray = new Uint8Array(bufferLength);

  const checkAudio = () =&gt; {
    analyser.getByteTimeDomainData(dataArray);

    let sum = 0;
    for (let i = 0; i &lt; bufferLength; i++) {
      sum += (dataArray[i] - 128) * (dataArray[i] - 128);
    }
    const volume = Math.sqrt(sum / bufferLength);

    if (volume &gt; VOLUME_THRESHOLD &amp;&amp; !this.isRecording) {
      this.startRecording();
    } else if (this.isRecording()) {
      this.stopRecording();
    }

    if (this.isMonitoring) {
      requestAnimationFrame(checkAudio);
    }
  }

  checkAudio();
})
</pre></div>


<p>This uses an analyser and repeatedly checks if the volume of the microphone at a given frame exceeds the given <code>VOLUME_THRESHOLD</code>. If it does, it checks to see if we are recording and if not, starts the recording.</p>



<p>After testing a bit, I realized this implementation sucked. Of the many issues with this approach, the biggest is that there are many natural dips in a person’s volume. Checking a single frame doesn’t account for these natural dips. To fix this, I thought it would be a good idea to introduce a timeout which only stopped recording after the volume was below a threshold for a certain amount of time:</p>


<div><pre title="">navigator.mediaDevices.getUserMedia({ audio: true }).then((stream) =&gt; {
  this.stream = stream;
  const analyser = this.audioContext.createAnalyser();
  const microphone = this.audioContext.createMediaStreamSource(this.stream);

  microphone.connect(analyser);

  analyser.fftSize = 512;
  const bufferLength = analyser.frequencyBinCount;
  const dataArray = new Uint8Array(bufferLength);

  this.silenceTimeout = null;

  const checkAudio = () =&gt; {
    analyser.getByteTimeDomainData(dataArray);

    let sum = 0;
    for (let i = 0; i &lt; bufferLength; i++) {
      sum += (dataArray[i] - 128) * (dataArray[i] - 128);
    }
    const volume = Math.sqrt(sum / bufferLength);

    if (volume &gt; VOLUME_THRESHOLD) {
      if (!this.isRecording()) {
        this.startRecording();
      }
      
      clearTimeout(this.silenceTimeout);

      this.silenceTimeout = setTimeout(() =&gt; {
        if (this.isRecording()) {
          this.stopRecording();
        }
      }, SILENCE_TIMEOUT);
    }

    if (this.isMonitoring) {
      requestAnimationFrame(checkAudio);
    }
  }

  checkAudio();
})
</pre></div>


<p>This actually ended up working decent, but required tuning hyperparameters for both <code>VOLUME_THRESHOLD</code> and <code>SILENCE_TIMEOUT</code>. The challenge here is that higher <code>SILENCE_TIMEOUT</code> introduces additionally latency in transition time between a speaker and Nero; however, lower timeouts might be too sensitive to speakers with slower and quieter speaking rhythms. Additionally, a static <code>VOLUME_THRESHOLD</code> does not account for ambient noise. Now, despite these shortcomings, I found I was able to passably detect a single speaker in a quiet room.</p>



<p>After hooking this up to my existing LiveView and trying some end-to-end conversations, I realized something was significantly off. The transcriptions I was getting were off. I soon realized that they were always off at the beginning of a transcription. Shorter audio sequences were especially affected. It turns out that the detection algorithm always resulted in some amount of truncation at the beginning of an audio clip. When a speaker starts talking, their volume ramps up – it’s not an instantaneous spike. To account for this, I introduced a pre-recording buffer which always tracked the previous 150ms of audio. After recording started, I would stop the pre-recording buffer and start the actual recording, and then eventually splice these 2 together to send to the server for transcription.</p>



<p>Overall, this <em>actually</em> worked okay. While there are some obvious failure modes, it worked well enough to get a passable demonstration. If you can’t tell by now, I am not an audio engineer. I learned later that this is a very naive attempt at <a href="https://en.wikipedia.org/wiki/Voice_activity_detection">voice activity detection</a>. Later on in this post, I’ll run through some of the improvements I made based on my research into the field of VAD.</p>



<h2>End-to-End Implementation</h2>



<p>The demonstration I built for Nero in my <a href="https://seanmoriarity.com/2024/02/25/nero-part-1-home-automations/">first post</a> already contained the scaffolding for an end-to-end transcription -&gt; response -&gt; speech pipeline. I only needed to make some slight modifications to get the phone call demo to work. The end-to-end the pipeline looks like this:</p>



<p>When our algorithm detects that speech has stopped, it invokes the <code>stopRecording</code> method. <code>stopRecording</code> takes the recorded audio, does some client-side pre-processing, and uploads it to the server. The server consumes the uploaded entry as a part of <a href="https://hexdocs.pm/phoenix_live_view/uploads.html">LiveView’s normal uploads lifecycle</a> and then invokes an <a href="https://hexdocs.pm/phoenix_live_view/Phoenix.LiveView.html#module-arbitrary-async-operations">async task</a> to start transcription:</p>


<div><pre title="">  defp handle_progress(:audio, entry, socket) when entry.done? do
    binary =
      consume_uploaded_entry(socket, entry, fn %{path: path} -&gt;
        {:ok, File.read!(path)}
      end)

    audio = Nx.from_binary(binary, :f32)

    socket =
      start_async(socket, :transcription, fn -&gt;
        Nero.SpeechToText.transcribe(audio)
      end)

    {:noreply, socket}
  end
</pre></div>


<p>Note that because we did most of the pre-processing client-side, we can just consume the audio binary as an <code>Nx.Tensor</code>, without any additional work. The <code>SpeechToText</code> module implements transcription using <a href="https://hexdocs.pm/nx/Nx.Serving.html">Nx.Serving</a>:</p>


<div><pre title="">defmodule Nero.SpeechToText do
  @repo "distil-whisper/distil-medium.en"

  def serving() do
    {:ok, model_info} = Bumblebee.load_model({:hf, @repo})

    {:ok, featurizer} = Bumblebee.load_featurizer({:hf, @repo})
    {:ok, tokenizer} = Bumblebee.load_tokenizer({:hf, @repo})
    {:ok, generation_config} = Bumblebee.load_generation_config({:hf, @repo})

    Bumblebee.Audio.speech_to_text_whisper(model_info, featurizer, tokenizer, generation_config,
      task: nil,
      compile: [batch_size: 1],
      defn_options: [compiler: EXLA]
    )
  end

  def transcribe(audio) do
    output = Nx.Serving.batched_run(__MODULE__, audio)
    output.chunks |&gt; Enum.map_join(&amp; &amp;1.text) |&gt; String.trim()
  end
end
</pre></div>


<p><code>Nx.Serving</code> is an abstraction in the Elixir Nx ecosystem for serving machine learning models directly in an Elixir application. It implements dynamic batching, encapsulates pre-processing, inference, and post-processing, supports distribution and load-balancing between multiple GPUs natively, and in general is an extremely easy way to serve machine learning models.</p>



<p>After transcription completes, we get an async result we can handle to initiate a response:</p>


<div><pre title="">  def handle_async(:transcription, {:ok, transcription}, socket) do
    chat = socket.assigns.chat ++ [%{role: "user", content: transcription}]
    response = Nero.Agent.respond(chat)

    {:noreply,
     socket
     |&gt; assign(chat: chat)
     |&gt; speak(response)}
  end
</pre></div>


<p>Here <code>Nero.Agent.respond/1</code> returns an Elixir <code>Stream</code> of text. For my original demonstration I just used the Elixir OpenAI library to produce a stream from a GPT-3.5 response:</p>


<div><pre title="">  def respond(chat) do
    prompt = Nero.Prompts.response()

    response_stream =
      OpenAI.chat_completion(
        model: "gpt-3.5-turbo",
        messages: [%{role: "system", content: prompt} | chat],
        max_tokens: 400,
        stream: true
      )

    response_stream
    |&gt; Stream.map(&amp;get_in(&amp;1, ["choices", Access.at(0), "delta", "content"]))
    |&gt; Stream.reject(&amp;is_nil/1)
  end
</pre></div>


<p>The response stream is consumed by <code>speak/2</code>. <code>speak/2</code> implements the text to speech pipeline:</p>


<div><pre title="">  defp speak(socket, text) do
    start_async(socket, :speak, fn -&gt;
      Nero.TextToSpeech.stream(text)
    end)
  end
</pre></div>


<p>Where <code>Nero.TextToSpeech.stream/1</code> uses the <a href="https://elevenlabs.io/docs/api-reference/websockets">ElevenLabs WebSocket API</a> to stream text in and speech out. You can read a bit more about the implementation in my previous post.</p>



<p><code>Nero.TextToSpeech.stream/1</code> returns the consumed response as text so we can append that to the chat history after the <code>:speak</code> task finishes:</p>


<div><pre title="">def handle_async(:speak, {:ok, response}, socket) do
  chat = socket.assigns.chat ++ [%{role: "assistant", content: response}]
  {:noreply, assign(socket, :chat, chat)}
end
</pre></div>


<p>This is basically all of the scaffolding needed for an end-to-end demo, but I wanted to add a few more features. First, I wanted to support “intelligent” hang-ups. Basically, I wanted to be able to detect when a conversation was finished, and stop the recording. To do that, I used <a href="https://github.com/thmsmlr/instructor_ex">Instructor</a>:</p>


<div><pre title="">  def hang_up?(chat) do
    {:ok, %{hang_up: hang_up}} =
      Instructor.chat_completion(
        model: "gpt-3.5-turbo",
        messages: [
          %{
            role: "system",
            content:
              "Decide whether or not to hang up the phone given this transcript. You should hang up after the user says goodbye or that there's nothing else you can help them with. DO NOT HANG UP ON THE USER UNLESS THEY SAY GOODBYE."
          }
          | chat
        ],
        response_model: %{hang_up: :boolean}
      )

    hang_up
  end
</pre></div>


<p>Please ignore my wonderfully engineered prompt. This uses GPT-3.5 to determine whether or not a given conversation has ended. After every one of Nero’s turns, we check the transcript to possibly end the call:</p>


<div><pre title="">  def handle_async(:speak, {:ok, response}, socket) do
    chat = socket.assigns.chat ++ [%{role: "assistant", content: response}]

    socket =
      if Nero.Agent.hang_up?(chat) do
        push_event(socket, "hang_up", %{})
      else
        socket
      end

    {:noreply, assign(socket, :chat, chat)}
  end
</pre></div>


<p>This pushes a <code>hang_up</code> event to the socket:</p>


<div><pre title="">    this.handleEvent('hang_up', () =&gt; {
      hook.pushEvent("toggle_conversation");

      if (this.audioContext) {
        this.audioContext.close();
        this.audioContext = null;
      }

      if (this.isMonitoring) {
        this.stopMonitoring();
      }
    });
</pre></div>


<p>Which stops the recording, and then pushes an event to <code>toggle_conversation</code> back to the server. <code>toggle_conversation</code> implements the start/stop logic from the server:</p>


<div><pre title="">  def handle_event("toggle_conversation", _params, socket) do
    socket =
      if socket.assigns.conversing do
        stop_conversation(socket)
      else
        start_conversation(socket)
      end

    {:noreply, socket}
  end
</pre></div>


<p>Finally, I wanted to implement information extraction from the transcript. Again, I used instructor and defined an extraction schema:</p>


<div><pre title="">  defmodule Appointment do
    use Ecto.Schema

    embedded_schema do
      field :booked, :boolean
      field :date, :string
      field :time, :string
      field :name, :string
      field :phone_number, :string
      field :reason_for_visit, :string
    end
  end
</pre></div>


<p>And used GPT-3.5 with a rough prompt to get the necessary information from the transcript:</p>


<div><pre title="">  def extract_appointment(chat) do
    Instructor.chat_completion(
      model: "gpt-3.5-turbo",
      messages: [
        %{
          role: "system",
          content:
            "Extract appointemnt information from the transcript. If info is missing, leave it blank. If it seems like no appointment was booked, mark booked as false and leave everything else blank. An appointment is not booked if there's no established date."
        }
        | chat
      ],
      response_model: Appointment
    )
  end
</pre></div>


<p>And then anytime a conversation ends, we attempt to retrieve appointment information:</p>


<div><pre title="">defp stop_conversation(socket) do
  case Nero.Agent.extract_appointment(socket.assigns.chat) do
    {:ok, %{booked: true} = appointment} -&gt;
      assign(socket,
        message: "You made an appointment! Details:",
        appointment: appointment,
        conversing: false
      )

    _ -&gt;
      assign(socket,
        message: "Looks like you didn't actually book an appointment. Try again",
        conversing: false
      )
  end
end
</pre></div>


<p>Now this is essentially the exact implementation that produced <a href="https://twitter.com/sean_moriarity/status/1760435005119934862">this demonstration</a>. End-to-end this amounted to a couple of hours of work; however, I already had most of the basic scaffold implemented from my previous work on Nero. In my biased opinion, I think my demo is pretty good, but as others have pointed out Retell’s demo kicks my ass in:</p>



<ul>
<li>Latency</li>



<li>Reliability</li>



<li>Natural sounding voice</li>
</ul>



<p>And so, I set out to improve my implementation – starting with latency.</p>



<h2>Reducing Latency</h2>



<p>Human conversations have extremely tight “time-to-turn.” In-person conversations are especially rapid because we rely on visual as well as audio signals to determine when it’s our time to participate in a conversation. The “average” time-to-turn in a conversation can be as quick as 200ms. That means for a conversational agent to feel realistic, it needs an extremely quick turn around time for “time to first spoken word.”</p>



<p>After posting my original demonstration, I already knew there were some very easy optimizations I could make, so I set out to improve the average latency of my implementation as much as possible in a short amount of time. First, I needed at least some method for determining whether an optimization worked. My rudimentary approach was to use <a href="https://developer.mozilla.org/en-US/docs/Web/API/Performance/now">JavaScript Performance Timers</a> and logging. Basically, I computed a <code>startTime</code> from the exact moment an audio recording stopped and an <code>endTime</code> from the exact moment an audio output started, and then I logged that time to the console.</p>



<p>This is a very unscientific way of doing business. In the future, I’d like to implement a much more involved profiling and benchmarking methodology. For this process though, it worked well enough.</p>



<p>Next, I considered all of the areas that could introduce latency into the pipeline. From the moment a recording stops, these are all of the steps we take:</p>



<ol>
<li>Pre-process recording by converting to PCM buffer, and then converting endianness to match server (if necessary)</li>



<li>Upload buffer to server</li>



<li>Perform speech to text on buffer to produce text</li>



<li>Send text to LLM</li>



<li>Send streamed text to ElevenLabs</li>



<li>Receive streamed audio from ElevenLabs</li>



<li>Broadcast audio to client</li>



<li>Decode audio on client and play</li>
</ol>



<p>That’s a lot of steps that can introduce latency, including potentially 3 (in our case 2 because we own the STT pipeline) network calls.</p>



<p>Next, I wanted to esablish a “baseline” of performance. To demonstrate this iterative process, I did a baseline example on my M3 Mac CPU. Note that this is going to be slow relative to my previous demo because the previous demo runs on a GPU. The baseline performance I got from the original demo running on my mac was <code>4537 ms</code>. 4.5 seconds turn around time. Yikes. Lots of work to do.</p>



<p>To start, I knew that the <code>SILENCE_TIMEOUT</code> used to wait for speech to end was rather long. For the original demo, I used 1000 ms, which basically means a speaker has to stop talking for a full second before we’ll even start the long response process. After some trial and error, I figured 500 ms was a “passable” hyperparameter. After adjusting this down, the latency change was almost exactly correlated to the dip: <code>4079 ms</code>.</p>



<p>I had a hunch that my text to speech pipeline was not efficient. Fortunately, ElevenLabs gives us a nice <a href="https://elevenlabs.io/docs/api-reference/reducing-latency">Latency Guide</a>. The first suggestion is to use their turbo model by specifying <code>eleven_turbo_v2</code>. I set that and we got a slight performance boost: <code>4014 ms</code>.</p>



<p>Next, they suggest adding <code>optimize_streaming_latency</code>. I set the value to <code>3</code> and we get: <code>3791 ms</code>. Their next suggestion is to use a pre-made voice. I actually didn’t realize until much later that I was not using a pre-made voice so I don’t have a comparison for how that change impacted latency.</p>



<p>Now it says to limit closing WebSocket connections. my current implementation opens a connection everytime it speaks – which is not good. Basically every “turn” has to establish a new websocket connection. Additionally, ElevenLabs has a timeout of 20s from when you connect. So you need to send a message at least every 20s. I considered 2 options at this point:</p>



<ol>
<li>Open a global WebSocket connection, or maybe even a pool of connections, and try to keep the connection alive. But that seems really wasteful, and I don’t think is the intended use of their API</li>



<li>Open a WebSocket connection when convo starts. We don’t have to worry about 20s pauses</li>
</ol>



<p>I decided to go with option 2, but I still think there are some drawbacks and considerations for a production system. The implementation I used opens a websocket connection on first “speak” and stores the connection PID as an assign in the LiveView socket. If you have a system with potentially many concurrent users speaking, you run the risk of creating a potentially unbounded number of connections. A more robust solution would probably use connection pools; however, I’m not really worried about traffic or scaling here.</p>



<p>While adding this optimization, I struggled a bit because ElevenLabs would send the first frame back, then cut off. Then I realized that it was waiting to generate becuase it thought I was going to send more frames. So I needed to “flush” the generation after I finished sending my tokens. This also seemed to fix unnatural audio problems I was having. After applying this optimization, our time to first spoken word was slightly lower in the <code>3700 ms</code> range.</p>



<p>After perusing their docs a bit more, I learned that ElevenLabs will send PCM buffers instead of MP3. Web Browser’s have to decode MP3 to PCM, which potentially introduces some overhead. One drawback is that you need to be on the independent creator tier to receive PCM instead of MP3. Now, if you’re wondering if I spent $99 to save some milliseconds for a meaningless demo, the answer is absolutely yes I did.</p>



<p>At this point, I believe I’ve exhausted a lot of the “easy” optimizations for TTS latency. One thing that does bother me about the ElevenLabs Websocket API is that there’s no way to receive binary payloads instead of JSON payloads. This is probably because they send alignment data, but I’m not using the alignment data here. When handling an incoming frame from their API we have to first decode the JSON, and then decode the Base64 encoded audio buffer. I’m not sure what the latency impact is, but I’m sure we could shave <em>some</em> time by avoiding both of these conversions. I also think the Base64 representation results in slightly larger buffers which could impact network latency.</p>



<p>The next area I looked to improve was the speech-to-text pipeline. I am using <code>Nx.Serving</code> specifically for Speech-to-Text. The benefit of this approach is that we can avoid an additional network call just for transcription. Of course, that assumes our transcription pipeline can run fast enough on our own hardware. XLA is notoriously slow on CPUs (it’s getting better). The first “optimization” I did was to switch to my GPU: <code>2050 ms</code></p>



<p>And that right there is a bitter lesson, because it’s the largest performance boost we’re going to get.</p>



<p>Next, I realized the model isn’t using F16, which can introduce some solid speed-ups: <code>1800 ms</code>. Now, there are probably some additional optimizations we could add to Nx and EXLA specifically. For example, we don’t have a flash attention implementation. Of course, XLA does a great job of applying similar optimizations as a baseline, so I’m not sure how much it would help. There’s also <a href="https://github.com/sanchit-gandhi/whisper-jax">fast JAX implementations of Whisper</a> that claim up to 70x speed ups. One issue with a lof of these claimed speed-ups; however, is that they are almost <strong>always</strong> for long audio sequences. GPUs and TPUs do well with large batch sizes and sequence lengths, but not for batch size 1 and short sequence lengths like we care about in this implementation. One day I may go down the performance hole of fast batch size 1 transcription, but today is not that day.</p>



<p>At this point, I had moved on to improving some of the failure modes of my demo. While doing so, I learned much more about audio than I had previously known, and realized that the configuration I used to record audio can significantly improve whisper performance as well. Turns out there’s a <a href="https://dev.to/mxro/optimise-openai-whisper-api-audio-format-sampling-rate-and-quality-29fj">nice guide</a> of somebody discussing parameters that work. Specifically, you should use 16 kHz sample rate for transcriptions. Reducing the sample rate also should reduce network overhead because we have less data, but it could reduce quality of the transcription. Oh well. Additionally, I realized I wasn’t using a pre-made ElevenLabs voice. After introducing both of these optimizations, I was able to achieve <code>1520 ms</code> turn time.</p>



<p>Finally, I realized I was doing all of my benchmarks on a development server. I switched my phoenix environment from <code>dev</code> to <code>prod</code> and got: <code>1375 ms</code>. So, with all of these optimizations we’re sitting at about 1.3s turn around time in a conversation. When conversing, it starts to feel somewhat close to natural. I should also point out that this is also running over Tailscale, so there is about 100 ms ping between my Mac and the server running on my GPU. When I run this locally on my GPU, I can consistently get about <code>1000 ms</code> and sometimes <code>900 ms</code> turn around time. Still, unfortunately, this does not match Retell’s latency. According to them, they are able to achieve <code>800 ms</code> consistently. I have some musings at the end about how this is possible.</p>



<p>I believe the biggest area I could improve the implementation is to use a better VAD implementation that relies on small rolling windows of activity rather than frames. We could probably get away with using 20-30 ms windows, which could theoretically offer a 480 ms latency improvement. I would like to eventually explore this.</p>



<p>In all honesty though, I think that is a significant improvement, and I could <em>probably</em> stop right here and be done with it.</p>



<p>If I were to keep going, I would explore using a local LLM with Nx and Bumblebee. Nx and Bumblebee support LLMs like Mistral and Llama out-of-the box. And our text generation servings support streaming. That means we can possibly eliminate any network latency to OpenAI, and instead run 2 of the 3 models locally. One issue with this is that Nx currently does not have any quantized inference support (it’s coming I promise), so my single 4090 is not sufficient to deploy both Whisper and Mistral. Fortunately, the folks at <a href="https://fly.io/gpu">Fly.io</a> were kind enough to give me access to some 80GB A100s. I will post a demo when I get one deployed 🙂</p>



<p>Maybe one day I will implement StyleTTS2 and see how efficient we can get with an entirely local inference pipeline.</p>



<h2>Improving the Conversational Experience</h2>



<p>Some people pointed out that my original demo did not have the same conversational experience as Retell’s, and they are absolutely right. Aside from latency, mine was prone to failure, picks up system sounds, picks up random noises like keyboard and mouse clicks, and doesn’t do well with ambient noise. They also have support for backchanneling, fillers and interruptions which introduces some element of “realness” when interacting with their agent.</p>



<p>Now I didn’t get around to adding backchannels or fillers, but I was able to make some slight improvements to the VAD algorithm I used, and I added support for interruptions.</p>



<h3>Fixing Some Failure Modes with VAD</h3>



<p>The first failure mode that seems to happen is echo from the system sounds. Nero always records and will start transcribing after audio spikes over a certain threshold. After some digging into the <code>getUserMedia</code> API, I found options for <code>echoCancellation</code>, <code>noiseSuppression</code>, and <code>autoGainControl</code>. This is the same point I realized that I could specify the microphone sample rate for the optimization I could added from the last section. Most of these options are on by default depending on your browser, but I added them explicitly anyway:</p>


<div><pre title="">const audioOptions = {
  sampleRate: SAMPLING_RATE,
  echoCancellation: true,
  noiseSuppression: true,
  autoGainControl: true,
  channelCount: 1,
};

navigator.mediaDevices.getUserMedia({ audio: audioOptions }).then((stream) =&gt; {
  ...
}
</pre></div>


<p>Now that somewhat helped, but Nero still picks up it’s own audio. This probably requires a more sophisticated solution, but I moved on to the next problem.</p>



<p>The second obvious failure mode is the fact that it picks up keyboard clicks, and the silence timeout is hard to tune. My first attempt to fix this was to “ignore” large spikes in audio by “smoothing” the volume at each frame:</p>


<div><pre title="">let sum = 0;
for (let i = 0; i &lt; bufferLength; i++) {
  sum += (dataArray[i] - 128) * (dataArray[i] - 128);
}
const volume = Math.sqrt(sum / bufferLength);
const smoothedVolume = SMOOTHING_ALPHA * volume + (1 - SMOOTHING_ALPHA) * lastSmoothedVolume;

lastSmoothedVolume = smoothedVolume;
</pre></div>


<p>Then, with some advice from <a href="https://twitter.com/polvalente">Paulo Valente</a>, I implemented a biquad filter to with a low and high-pass in order to filter audio to the range of human speech:</p>


<div><pre title="">this.stream = stream;
const analyser = this.audioContext.createAnalyser();
const microphone = this.audioContext.createMediaStreamSource(this.stream);

var highPassFilter = this.audioContext.createBiquadFilter();
highPassFilter.type = 'highpass';
highPassFilter.frequency.value = FILTER_LOWER_BOUND;

var lowPassFilter = this.audioContext.createBiquadFilter();
lowPassFilter.type = 'lowpass';
lowPassFilter.frequency.value = FILTER_UPPER_BOUND;

microphone.connect(highPassFilter);
highPassFilter.connect(lowPassFilter);
lowPassFilter.connect(analyser);
</pre></div>


<p>In practice, both of these solutions actually seemed to work decent, but they could absolutely be better. I know it’s possible to improve the client-side filtering using a rolling-window that looks energy of the speaking frequences relative to energy of an entire sample. But, there are also machine learning models that perform VAD, and have <code>1ms</code> inference times. I realized that it’s probably quicker to just send all of the data over the websocket in chunks, and perform VAD on the server. I’ll discuss that implementation a little later.</p>



<h3>Supporting Interruptions</h3>



<p>Next I wanted to add support for interruptions. In the Retell example, the speaker will cut off mid-speech if it detects that you are speaking. To implement this feature in Nero, I added a <code>pushEvent</code> to the Microphone hook which would push an <code>interrupt</code> event to the server anytime speech is detectected:</p>


<div><pre title="">if (smoothedVolume &gt; VOLUME_THRESHOLD) {
  if (!this.isRecording()) {
    // To handle interrupts, push an event to the LV which will
    // then push an event to the TTS channel. Not sure how much
    // these round trips will lag. Alternatively we could create
    // a global audio context and stop that, but we would need
    // a different way to push alignment info to the server
    this.pushEvent("interrupt");
    this.startRecording();
  }
  ...
}
</pre></div>


<p>The server handles this event and broadcasts an event to the TTS channel to stop speaking:</p>


<div><pre title="">  def handle_event("interrupt", _params, socket) do
    NeroWeb.Endpoint.broadcast_from(
      self(),
      socket.assigns.audio_channel,
      "phx:audio-stop",
      %{}
    )

    {:noreply, socket}
  end
</pre></div>


<p>And the channel handles the event by clearing out the output audio stream and queue:</p>


<div><pre title="">  this.channel.on("phx:audio-stop", () =&gt; {
    if (hook.audioContext.state === 'running') {
      hook.audioContext.suspend().then(() =&gt; {
        if (hook.source) {
          hook.source.onended = null;
          hook.source.stop();
          hook.source = null;
        }
        hook.isPlaying = false;
        hook.audioQueue = [];
      });
    }
  });
</pre></div>


<p>Unfortunately, this does create a race condition. There’s a potential situation where a speaker interrupts and the speaking queue gets cleared on the client, but ElevenLabs is still streaming audio back to the server. The server is always going to just broadcast this info to the client, and as is the client will process it. This potentially creates a situation with weird continutations in the audio. To get around this, I refactored the TTS implementation so that each audio broadcast appends a 6 digit token to the payload. Then, all we need to do is keep the token in sync with the client and server. On the client, when processing the audio queue, it simply checks whether or not the token at the beginning of the payload matches, and if it doesn’t it ignores that sample.</p>



<p>The limitation with this implementation is it does not update the chat transcript. It’s entirely possible because we have access to the alignment information from ElevenLabs, but I just didn’t implement it at this time.</p>



<h3>Time-based Hang Ups</h3>



<p>Another thing the Retell demo has support for is cues and hang ups after a duration of silence. If you are silent for too long, you’ll get a cue from the AI speaker asking you if you’re still there. After another duration of silence, it will hang up. This is something that’s pretty easy to do with LiveView and <code>Process.send_after/4</code>:</p>


<div><pre title="">  defp nudge(socket) do
    nudge_pid = Process.send_after(self(), :nudge, @nudge_ms)
    assign(socket, :nudge_pid, nudge_pid)    
  end
</pre></div>


<p>And then we can cancel the timer anytime we receive a transcription, and restart it after every turn speaking. Note that we can’t depend on the Phoenix <code>speak</code> async task ending as the trigger to send nudges. Instead, we need to push an event from the speaker hook that the audio has ended. This avoids a case where the speaker initiates a really long speech, which overlaps with the <code>nudge_ms</code> duration. Now, we can control the number of nudges with an assign. In my case, I just used a boolean:</p>


<div><pre title="">  def handle_info(:nudge, socket) do
    socket =
      if socket.assigns.nudged? do
        stop_conversation(socket)
      else
        socket
        |&gt; speak(["Are ", "you ", "still ", "there? "])
        |&gt; assign(nudged?: true)
      end

    {:noreply, socket}
  end
</pre></div>


<figure></figure>



<h2>Re-doing the Entire Thing</h2>



<p>Somewhere along the line I realized that my attempts at engineering solid VAD client-side were never going to deliver the experience that I wanted. I discussed with <a href="https://twitter.com/ac_alejos">Andres Alejos</a> a bit, and he found a <a href="https://github.com/snakers4/silero-vad">Silero VAD</a> model which is capable of performing VAD in <code>1ms</code> on a single CPU thread. They also had an ONNX model—and we have a library in the Elixir ecosystem called <a href="https://github.com/elixir-nx/ortex">Ortex</a> which allows us to execute ONNX models.</p>



<p>To accomodate for the new VAD model, I ended up re-implementing the original LiveView I had as a WebSocket. This actually works out well because the WebSocket server is generic, and can be consumed by any language with a WebSocket client. The implementation is also relatively simple, and easily expanded to accomodate for other LLMs, TTS, and STT models. The WebSocket implementation has low latency (when running on a GPU), and supports interrupts.</p>



<p>You can find the <a href="https://github.com/seanmor5/echo">project on my GitHub</a> as well as an <a href="https://github.com/seanmor5/echo_example">example using the server</a>.</p>



<h2>Musings</h2>



<p>The final implementation I ended up with still does not match the quality of the Retell demo. That said, I think it’s a solid start for future work. I believe I acted with some hubris when first posting about this project, and I would like to say that Retell’s work should not be understated. I can appreciate the attention to detail that goes into making an effective conversational agent, and Retell’s demo shows they paid a lot of attention to the details. Kudos to them and their team.</p>



<p>I will also admit that my demo is playing to one benchmark. I’m optimizing the hell out of latency to support a single user—me. I think this solution would change if it needed to accomodate for multiple concurrent users.</p>



<p>Retell’s website claims they have a conversation orchestration model under the hood to manage the complexities of conversation. I had my doubts about that going into this, but I believe it now. Whether or not this model is actually a single model or a series of models for VAD, adding backchannels, etc. I’m not sure. I think eventually it <em>will</em> be a single model, but I’m not sure if it is now, which leads me to my next point.</p>



<h3>Another Bitter Lesson</h3>



<p>While doing all of these optimizations, I could not help but think that it will eventually be all for naught. Not because I don’t think people will find it useful, but because large models trained on lots of data simply seem to always beat engineering effort. I believe the future of this area of work is in joint models. I think the only way to achieve real-time conversations is to merge parts of the stack. I predict in less than a year we will see an incredibly capable joint speech/text model. I recently saw a large audio model called <a href="https://github.com/QwenLM/Qwen-Audio">Qwen-Audio</a> that I believe is similar to what I envision.</p>



<p>Specifically, if somebody were kind enough to give me some money to throw at this problem, here is exactly what I would do:</p>



<ol>
<li>Generate an <a href="https://github.com/tatsu-lab/stanford_alpaca/blob/main/alpaca_data.json">Alpaca-style</a> and/or LLaVA-style dataset of synthetic speech. Note that it would require a bit of pre-processing to change Alpaca inputs to mirror a style compatible with spoken-word. I would use ElevenLabs to generate the dataset in mulitple voices. Of course this dataset would be a bit too “clean,” so we’d need to apply some augmentations which add ambient noise, change speaking pitch and speed, etc. Bonus points: adding samples of “noise” which require no response to merge the VAD part of the pipeline in as well. You can even throw in text prompts that dictate when and when not to respond to support things like <a href="https://picovoice.ai/platform/porcupine/">wake word detection</a> without needing to train a separate model.</li>



<li>Create a LLaVA-style model with a Whisper or equivalent base, an LLM, and a projection layer.</li>



<li>Secure H100s, train model, and “turn H100s into $100s” (thank you <a href="https://twitter.com/thmsmlr?lang=en">@thmsmlr</a>)</li>
</ol>



<p>If you want to give me some $$$, my e-mail is smoriarity.5@gmail.com 🙂</p>



<p>I believe we are also close to just having full-on speech-to-speech models. A specific challenge I can see when creating these models is coming up with a high-quality dataset. I think if you make a deliberate attempt at “recording conversations” for the purposes of training, you will actually probably end up with a lower-quality dataset. People tend to change their behavior under observation. Additionally, conversations from movies and TV shows aren’t actually very natural. Even some podcasts have an unnatural converastional rhythm.</p>



<p>While watching <a href="https://en.wikipedia.org/wiki/Love_Is_Blind_(TV_series)">Love is Blind</a> with my fiancé, I realized you could probably get a decent amount of quality data from reality tv shows. The conversations in reality TV are overly dramatic and chaotic, but are (I think) closer to realistic than anything else.</p>



<h3>Conversational Knowledge Base?</h3>



<p>I do wonder what a solid RAG implementation looks like on top of a conversational agent. RAG and complex CoT pipelines will introduce latency which could deteriorate the conversational experience. However, there are clever ways you can hide this. In conversations that require “search” between humans, e.g. like scheduling an appointment, you’ll often have one party saying “one moment please” before performing a system search. Building something like that in is entirely possible. Additionally, if your agent requires information up front about an individual, it’s possible to include that in the initial prompt.</p>



<h3>You Should Use Elixir</h3>



<p>I was very excited for this problem in particular because it’s literally the perfect application of Elixir and Phoenix. If you are building conversational agents, you should seriously consider giving Elixir a try. A large part of how quick this demo was to put together is because of how productive Elixir is.</p>



<h2>Conclusion</h2>



<p>This was a fun technical challenge. I am pleased with the performance of the final demonstration. I’m also happy I was able to OSS a small library for others to build off of. If you are interested in conversational agents, I encourage you to check it out, give feedback, and contribute! I know it’s very rough right now, but it will get better with time.</p>



<p>Additionally, I plan to periodically build out the rest of the Nero project, so please follow me on <a href="https://twitter.com/sean_moriarity">Twitter</a> if you’d like to stay up to date.</p>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Short Stack: World’s smallest Nintendo Wii (555 pts)]]></title>
            <link>https://github.com/loopj/short-stack</link>
            <guid>40071826</guid>
            <pubDate>Thu, 18 Apr 2024 00:51:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/loopj/short-stack">https://github.com/loopj/short-stack</a>, See on <a href="https://news.ycombinator.com/item?id=40071826">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto">
  
  <p dir="auto"><h4 tabindex="-1" dir="auto">World's Smallest Nintendo Wii, using a trimmed motherboard and custom stacked PCBs</h4><a id="user-content-worlds-smallest-nintendo-wii-using-a-trimmed-motherboard-and-custom-stacked-pcbs" aria-label="Permalink: World's Smallest Nintendo Wii, using a trimmed motherboard and custom stacked PCBs" href="#worlds-smallest-nintendo-wii-using-a-trimmed-motherboard-and-custom-stacked-pcbs"></a></p>
  <p dir="auto">
    <a href="#features">Features</a> ·
    <a href="#size--scale">Size &amp; Scale</a> ·
    <a href="#components">Components</a> ·
    <a href="#build-guide">Build Guide</a>
  </p>
</div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/loopj/short-stack/blob/main/images/render-blue.jpg"><img src="https://github.com/loopj/short-stack/raw/main/images/render-blue.jpg" alt="Short Stack Render"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>World's smallest "to scale" Wii console</li>
<li>Powered by USB-C</li>
<li>HDMI for lossless digital audio and video (powered by <a href="https://github.com/ikorb/gcvideo">GCVideo</a>)</li>
<li>Bluetooth for Wii remotes and accessories</li>
<li>MicroSD card stores games and saves, instead of disc drive &amp; memory cards</li>
<li>4 GameCube controller ports</li>
<li>Power, reset, and sync buttons</li>
<li>Power indicator LED and iconic blue glowing disc slot</li>
<li>Soft shutdown, power on/off via Wiimote</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Size &amp; Scale</h2><a id="user-content-size--scale" aria-label="Permalink: Size &amp; Scale" href="#size--scale"></a></p>
<p dir="auto">This is a <strong>1:2.38 scale</strong> model of an original Nintendo Wii console, but since that is hard to visualize here are some other stats:</p>
<ul dir="auto">
<li>Same size as a typical deck of playing cards</li>
<li><strong>7.4% the volume</strong> of an original Wii console</li>
<li>You could fit <strong>13.5</strong> of these inside an original Wii</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/loopj/short-stack/blob/main/images/deck-of-cards.jpg"><img src="https://github.com/loopj/short-stack/raw/main/images/deck-of-cards.jpg" alt="Size comparison"></a></p>
<p dir="auto">I'm pretty sure this sets the record for the smallest functional scale-model Wii console, but let me know if I'm wrong!</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Could we go smaller?</h3><a id="user-content-could-we-go-smaller" aria-label="Permalink: Could we go smaller?" href="#could-we-go-smaller"></a></p>
<p dir="auto">Yes! It is definitely possible to go smaller than this. My <a href="https://github.com/loopj/short-stack/blob/main/images/trim.png">version of the Omega trim</a> keeps all four main mounting holes, which makes it around 7mm wider than a classic Omega trim. Additionally <a href="https://twitter.com/Weskmods" rel="nofollow">Wesk</a> has managed to get a Wii motherboard down to 52x52mm on his final destination trim, which is a a full 10mm narrower than my trim. I estimate you could reduce the volume by a further 25-30% without losing any functionality, but it would be an incredibly tight fit and tricky to assemble.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Components</h2><a id="user-content-components" aria-label="Permalink: Components" href="#components"></a></p>
<p dir="auto">As the name implies, <em>Short Stack</em> is built from a stack of custom PCBs, and a custom heatsink, that are all designed to fit together in a compact and modular way.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">A modular motherboard</h3><a id="user-content-a-modular-motherboard" aria-label="Permalink: A modular motherboard" href="#a-modular-motherboard"></a></p>
<p dir="auto">Making a tiny build like this is made possible by trimming the Wii motherboard down to the bare essentials. The result is a board which is just <em>62x62mm</em>, but still contains the CPU, GPU, RAM and flash memory.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/loopj/short-stack/blob/main/images/motherboard-front.jpg"><img src="https://github.com/loopj/short-stack/raw/main/images/motherboard-front.jpg" width="45%"></a> <a target="_blank" rel="noopener noreferrer" href="https://github.com/loopj/short-stack/blob/main/images/motherboard-back.jpg"><img src="https://github.com/loopj/short-stack/raw/main/images/motherboard-back.jpg" width="45%"></a></p>
<p dir="auto">Since we removed the original power circuitry and trimmed off the USB, Bluetooth, and GameCube connectors, we need to provide power and data to the board another way. I designed a couple of boards which solder directly to the front of a trimmed Wii motherboard to provide power and data, which help avoid a tangled mess of wires.</p>
<p dir="auto">The <a href="https://github.com/loopj/wii-power-strip">Wii Power Strip</a> supplies power to the Wii motherboards using a Molex Pico-Lock connector, and additionally has footprints to help relocate of a couple of capacitors which are typically removed when trimming a Wii.</p>
<p dir="auto"><a href="https://github.com/loopj/periphlex">Periphlex</a> is a flex PCB which breaks out the Bluetooth, USB and GameCube controller data lines, as well as the power, shutdown, and reset GPIOs. These are then made available via a 14-pin FFC connector. This approach replaces 11 magnet wires with a single, removable ribbon cable.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/loopj/short-stack/blob/main/images/periphlex-render.png"><img src="https://github.com/loopj/short-stack/raw/main/images/periphlex-render.png" alt="Periphlex"></a></p>
<p dir="auto">On the back of the motherboard, I'm using two open-source boards designed by the very talented <a href="https://github.com/mackieks">YveltalGriffin</a>. <a href="https://github.com/mackieks/fujiflex">fujiflex</a> provides digital A/V output using GCVideo, and <a href="https://github.com/mackieks/nandFlex">nandFlex</a> relocates the Wii's NAND memory chip, to enable the tight trim.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Custom PCBs</h3><a id="user-content-custom-pcbs" aria-label="Permalink: Custom PCBs" href="#custom-pcbs"></a></p>
<p dir="auto">In addition to the modular boards on the motherboard, I designed two PCBs specific to Short Stack which provide the rest of the functionality for the console.</p>
<p dir="auto">The <em>main board</em> PCB hosts the power regulators, USB to microSD logic, HDMI connector, GameCube ports, and a microcontroller for power management. A 14-pin ribbon cable connects this board to the Wii motherboard via <em>Periphlex</em>, and a power cable delivers power to the <em>Power Strip</em>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/loopj/short-stack/blob/main/images/main-board.jpg"><img src="https://github.com/loopj/short-stack/raw/main/images/main-board.jpg" alt="Main Board"></a></p>
<p dir="auto">The <em>front panel</em> PCB hosts the power, reset, and sync buttons, as well as the power LED and disc slot LEDs. This board connects to the main board via a short 8-pin ribbon cable.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/loopj/short-stack/blob/main/images/front-panel.jpg"><img src="https://github.com/loopj/short-stack/raw/main/images/front-panel.jpg" alt="Front Panel Board"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Cooling</h3><a id="user-content-cooling" aria-label="Permalink: Cooling" href="#cooling"></a></p>
<p dir="auto">The final part of the "stack" is a custom heatsink which is designed to be as low profile as possible, while still providing adequate cooling for the Wii's CPU and GPU. The heatsink is designed to be machined from aluminum or copper, and incorporates mounting holes which align with those on the Wii motherboard.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/loopj/short-stack/blob/main/images/heatsink.jpg"><img src="https://github.com/loopj/short-stack/raw/main/images/heatsink.jpg" alt="Heatsink"></a></p>
<p dir="auto">I managed to find a tiny 5V blower fan (<a href="https://catalog.pelonistechnologies.com/item/air-g-series-micro-fans-and-micro-blowers/micro-fans-and-micro-blowers/agb208n" rel="nofollow">Pelonis AGB208N</a>) which measures just 20x20x8mm and somehow puts out 0.84 CFM of air. This blows air through the heasink fins, out the side of the case.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Case</h3><a id="user-content-case" aria-label="Permalink: Case" href="#case"></a></p>
<p dir="auto">The stack is housed in a custom 3D printed case, secured with four M2.5 screws and spacers. The rest of case is assembled using self-tapping M1.2 screws. The screw locations and fan vents are positioned to match the original Wii case as closely as possible, to minimize visible screws.</p>
<p dir="auto">You can access files on the SD card by connecting the console to a computer via USB, but I also included an access panel on the front of the case where the original Wii SD card slot is found. This panel is held in place by magnets and can be removed to access the SD card without opening the case. Shout out to Wesk for the magnet idea!</p>
<p dir="auto">To keep the clean aesthetic of the original Wii I wanted to hide the GameCube controller ports behind a panel. I always hated the hinged design of the original, and it is quite difficult to replicate at this scale, so I redesigned this panel to be a sliding panel.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/loopj/short-stack/blob/main/images/gamecube-ports.png"><img src="https://github.com/loopj/short-stack/raw/main/images/gamecube-ports.png" alt="GameCube Ports"></a></p>
<p dir="auto">The Wii's iconic disc slot lights are recreated using a 1.5mm thick custom cut acrylic light diffuser, which is illuminated by two side-mounted addressable LEDs on the front panel board. The power, reset, and sync buttons are all also 3D printed, and the power button hosts a tiny light pipe to allow the power LED to shine through.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/loopj/short-stack/blob/main/images/front-assembly.png"><img src="https://github.com/loopj/short-stack/raw/main/images/front-assembly.png" alt="Front assembly"></a></p>
<p dir="auto">I FDM printed the case on a Voron 2.4 in ABS using a 0.4mm nozzle at 0.1mm layer height, but it should print fine in PLA or PETG on a well-tuned printer. At this scale, dimensional accuracy is important. In theory it should be possible to print this on an SLA printer, but I haven't tried it.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Build Guide</h2><a id="user-content-build-guide" aria-label="Permalink: Build Guide" href="#build-guide"></a></p>
<div dir="auto"><p dir="auto">Caution</p><p dir="auto">This is not a beginner project! This build requires performing a challenging motherboard trim, fine pitch soldering, and PCB assembly. If you are not comfortable with these tasks, I would recommend starting with a simpler project and working your way up - check out the <a href="https://bitbuilt.net/" rel="nofollow">BitBuilt forums</a> for some awesome project worklogs.</p>
</div>
<p dir="auto"><h3 tabindex="-1" dir="auto">What you'll need</h3><a id="user-content-what-youll-need" aria-label="Permalink: What you'll need" href="#what-youll-need"></a></p>
<ul dir="auto">
<li>4-layer Wii motherboard</li>
<li><a href="https://github.com/mackieks/nandFlex">nandFlex</a> board (or <a href="https://4layertech.com/products/rvl-nand-flex-board-pack-of-2" rel="nofollow">4Layer Technologies RVL-NAND</a>)</li>
<li>Assembled <a href="https://github.com/mackieks/fujiflex">fujiflex</a> (or <a href="https://electron-shepherd.com/products/electronave-kit" rel="nofollow">ElectronAVE</a>)</li>
<li>Assembled <a href="https://github.com/loopj/wii-power-strip/tree/r1">Wii Power Strip</a> - <strong>must be revision 1!</strong></li>
<li>Assembled <a href="https://github.com/loopj/periphlex">Periphlex</a></li>
<li><a href="https://github.com/loopj/short-stack/blob/main/main-board/KiCad">Short Stack main board</a> - 1.2mm thickness, stencil recommended</li>
<li><a href="https://github.com/loopj/short-stack/blob/main/front-panel/KiCad">Short Stack front panel</a> - 0.8mm thickness, black soldermask, stencil recommended</li>
<li><a href="https://github.com/loopj/short-stack/blob/main/case/heatsink.step">Heatsink</a> - machined from aluminum or copper</li>
<li><a href="https://github.com/loopj/short-stack/blob/main/case/disc-light-diffuser.dxf">Light diffuser</a> - cut from 1.5mm thick acrylic</li>
<li>The components and hardware from the <a href="https://github.com/loopj/short-stack/blob/main/full-bom.xlsx">bill of materials</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Assembly</h3><a id="user-content-assembly" aria-label="Permalink: Assembly" href="#assembly"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/loopj/short-stack/blob/main/images/case-assembly.gif"><img src="https://github.com/loopj/short-stack/raw/main/images/case-assembly.gif" alt="Case Exploded" data-animated-image=""></a></p>
<ul dir="auto">
<li>Assemble main board and front panel PCBs
<ul dir="auto">
<li>I recommend using a solder stencil and a hot plate or reflow oven</li>
<li>If using a hot plate, hand solder the headphone connectors after reflowing the rest of the components</li>
<li>Secure two 3 x 1mm magnets inside the holes on the front panel board using a dab of CA glue</li>
</ul>
</li>
<li>Flash the <a href="https://github.com/loopj/short-stack/blob/main/main-board/firmware">main board firmware</a></li>
<li>Prepare and trim the Wii motherboard
<ul dir="auto">
<li>Relocate the NAND, test it still boots</li>
<li>Perform a wireless U10 relocation, test it still boots - you may wish to wire a magnet wire to the <a href="https://bitbuilt.net/forums/index.php?threads/soft-shutdown-power-on-via-bluetooth.6239/" rel="nofollow"><code>SHUTDOWN</code> via</a> first</li>
<li>Install fujiflex, and test digital A/V output works</li>
<li>Trim the motherboard (see <a href="https://github.com/loopj/short-stack/blob/main/images/trim.png">trim dimensions</a>)</li>
</ul>
</li>
<li>Assemble and install <em>Power Strip</em> (<a href="https://github.com/loopj/wii-power-strip/tree/r1#installation">see instructions</a>)</li>
<li>Assemble and install <em>Periphlex</em> (<a href="https://github.com/loopj/periphlex#installation">see instructions</a>)</li>
<li>Connect the boards
<ul dir="auto">
<li>Connect the main board to the motherboard via a 14-pin FFC cable to <em>Periphlex</em></li>
<li>Connect the main board to the motherboard via a 5-pin Molex Pico-Lock cable to <em>Power Strip</em></li>
<li>Connect the front panel board to the main board via an 8-pin FFC cable</li>
<li>Connect the fan to the main board</li>
<li>Apply thermal paste to the CPU and GPU</li>
<li>Stack the components: heatsink, motherboard, M2.5 x 3mm spacers, main board</li>
<li>Install the stack to the case bottom using M2.5 x 12mm wafer head screws</li>
</ul>
</li>
<li>Secure the top of the case to the bottom using four M1.2 x 4mm screws</li>
<li>Secure the front panel PCB to the front of the case using two M1.2 x 3mm screws</li>
<li>Secure the front of the case to the bottom of the case using two M1.2 x 4mm screws</li>
<li>Press-fit two 3 x 1mm magnets into the holes on the sd card cover, make sure they match polarity with the magnets on the front panel PCB</li>
<li>Slide the side panel into the case</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Permissively released under the Solderpad Hardware License v2.1</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Math Puzzles (162 pts)]]></title>
            <link>https://jrmf.org/puzzle/</link>
            <guid>40071463</guid>
            <pubDate>Wed, 17 Apr 2024 23:59:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jrmf.org/puzzle/">https://jrmf.org/puzzle/</a>, See on <a href="https://news.ycombinator.com/item?id=40071463">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ajax">
                                        <div>
                            <p><span>For All Ages</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/iconV4.png" alt="3-in-a-Row">
                            </p>
                            <p>
                                3-in-a-Row                            </p>
                            <p>Can you be the first player to get 3-in-a-row?</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/JRMF-IconsActApplePickingNoBdr.png" alt="Apple Picking">
                            </p>
                            <p>
                                Apple Picking                            </p>
                            <p>After a long day of picking apples, can you eat the last, juiciest apple?</p>
                            
                        </div>

                                        <div>
                            <p><span>3rd - 12th Grade</span>
                                <span>Shape </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/3ae305b14698922c3f311f606a2288f4bd520551-1303x776-1-e1656533075857.webp" alt="Billiards Geometry">
                            </p>
                            <p>
                                Billiards Geometry                            </p>
                            <p>Embrace your inner pool shark and try to make every shot.
</p>
                            
                        </div>

                                        <div>
                            
                            <p><img src="https://jrmf.org/wp-content/uploads/JRMF-IconAct-BlueDotSolitaireNoBdr-e1702649166246.png" alt="Blue Dot Solitaire">
                            </p>
                            <p>
                                Blue Dot Solitaire                            </p>
                            <p>Can you remove all the dots?</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/Bridges-Icon.png" alt="Bridges">
                            </p>
                            <p>
                                Bridges                            </p>
                            <p>Can you build a bridge that connects the stars?</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Number </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/CatchUpIcon.png" alt="Catch Up">
                            </p>
                            <p>
                                Catch Up                            </p>
                            <p>Can you make the longest line?</p>
                            
                        </div>

                                        <div>
                            <p><span>3rd - 12th Grade</span>
                                <span>Number </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/JRMF-IconsActChameleonIslandNoBdr.png" alt="Chameleon Island">
                            </p>
                            <p>
                                Chameleon Island                            </p>
                            <p>Help all the chameleons on the island change into the same color.</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/JRMF-IconsActChocolateFixNoBdr.png" alt="Chocolate Fix">
                            </p>
                            <p>
                                Chocolate Fix                            </p>
                            <p>Can you make the perfect chocolate box for your customers?</p>
                            
                        </div>

                                        <div>
                            <p><span>3rd - 12th Grade</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/chomp-e1656535652106.png" alt="Chomp">
                            </p>
                            <p>
                                Chomp                            </p>
                            <p>Can you avoid taking the yucky chocolate piece?</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Shape </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/JRMF-IconAct-ColorTrianglesNoBdr.png" alt="Color Triangles">
                            </p>
                            <p>
                                Color Triangles                            </p>
                            <p>Create beautiful, colorful triangular patterns.</p>
                            
                        </div>

                                        <div>
                            <p><span>3rd - 12th Grade</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/colored-loops-e1656535434264.png" alt="Colored Loops">
                            </p>
                            <p>
                                Colored Loops                            </p>
                            <p>Create colorful loops so that you can always find your way back to the beginning of the path.</p>
                            
                        </div>

                                        <div>
                            <p><span>3rd - 12th Grade</span>
                                <span>Number </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/JRMF-IconsActCountdownNoBdr.png" alt="Countdown">
                            </p>
                            <p>
                                Countdown                            </p>
                            <p>Be the player to take the last token!</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/JRMF-IconAct-CrackTheCodeNoBdr.png" alt="Crack the Code">
                            </p>
                            <p>
                                Crack the Code                            </p>
                            <p>Crack the secret code in as few guesses as you can!</p>
                            
                        </div>

                                        <div>
                            <p><span>3rd - 12th Grade</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/JRMF-IconsActCupStackingNoBdr.png" alt="Cup Stacking">
                            </p>
                            <p>
                                Cup Stacking                            </p>
                            <p>Can you find a way to stack every cup?</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Number </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/Dice-Bingo-Icon.png" alt="Dice Bingo">
                            </p>
                            <p>
                                Dice Bingo                            </p>
                            <p>Can you make a winning bingo card?</p>
                            
                        </div>

                                        <div>
                            
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/digit-sums.png" alt="Digit Sums">
                            </p>
                            <p>
                                Digit Sums                            </p>
                            <p>Use every digit of your numbers to solve these unique and challenging number puzzles.</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/IconV2-1.png" alt="Domino Dissection">
                            </p>
                            <p>
                                Domino Dissection                            </p>
                            <p>Can you tile the board using each domino exactly once?</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Shape </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/DoodlesIcon-1.png" alt="Doodles">
                            </p>
                            <p>
                                Doodles                            </p>
                            <p>Can you trace each doodle without lifting your marker?</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Number </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/Asset-30-1.png" alt="Dueling Dice">
                            </p>
                            <p>
                                Dueling Dice                            </p>
                            <p>Can you make a better die than your partner?</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/JRMF-IconAct-FrogsNToadsNoBdr.png" alt="Frogs and Toads">
                            </p>
                            <p>
                                Frogs and Toads                            </p>
                            <p>Can you help the frogs and toads get to the other side of the pond?</p>
                            
                        </div>

                                        <div>
                            <p><span>3rd - 12th Grade</span>
                                <span>Shape </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/icon-2.png" alt="Gerrymandering">
                            </p>
                            <p>
                                Gerrymandering                            </p>
                            <p>Can you split up each puzzle so that more than half of the groups are purple groups?</p>
                            
                        </div>

                                        <div>
                            <p><span>3rd - 12th Grade</span>
                                <span>Number </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/JRMF-IconAct-GraceGraphsAutumn2.png" alt="Graceful Gourds">
                            </p>
                            <p>
                                Graceful Gourds                            </p>
                            <p>Can you gracefully label these pumpkin patches?</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Shape </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/JRMF-IconAct-Flexagons.png" alt="Hexaflexagons">
                            </p>
                            <p>
                                Hexaflexagons                            </p>
                            <p>Learn the mysteries of the simple yet surprising hexaflexagon, and take one home to show your friends!</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/JRMF-IconsActJuiceJumbleNoBdr.png" alt="Juice Jumble">
                            </p>
                            <p>
                                Juice Jumble                            </p>
                            <p>Order these jumbled juices to make a beautiful rainbow.</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/JRMF-IconsActJumpJuliaBunnyNoBdr.png" alt="Jumping Julia">
                            </p>
                            <p>
                                Jumping Julia                            </p>
                            <p>Can you jump your way from start to finish?</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Shape </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/JRMF-IconsActKonigsbergNoBdr.png" alt="Königsberg">
                            </p>
                            <p>
                                Königsberg                            </p>
                            <p>Everything is made up of one, continuous line. Can you figure out what belongs in town?</p>
                            
                        </div>

                                        <div>
                            <p><span>3rd - 12th Grade</span>
                                <span>Number </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/JRMF-IconsActLadybugsNoBdr.png" alt="Ladybugs">
                            </p>
                            <p>
                                Ladybugs                            </p>
                            <p>Help as many ladybugs as possible land on the leaves.</p>
                            
                        </div>

                                        <div>
                            <p><span>3rd - 12th Grade</span>
                                <span>Shape </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/JRMF-IconAct-LotsOPlotsNoBdr.png" alt="Lots o’ Plots">
                            </p>
                            <p>
                                Lots o’ Plots                            </p>
                            <p>Fill your entire garden with plots of carrots.</p>
                            
                        </div>

                                        <div>
                            <p><span>3rd - 12th Grade</span>
                                <span>Number </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/final-flower-image.png" alt="Magic Flowers">
                            </p>
                            <p>
                                Magic Flowers                            </p>
                            <p>Can you arrange 5 numbers into a Magic Flower in which every group of three numbers in a line adds up to the same magic number?</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Shape </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/JRMF-IconAct-MapColoringNoBdr.png" alt="Map Coloring">
                            </p>
                            <p>
                                Map Coloring                            </p>
                            <p>Can you color each map so that no two neighboring states are colored the same color?</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/meepletownicon_1.png" alt="Meeple Town">
                            </p>
                            <p>
                                Meeple Town                            </p>
                            <p>Can you find all the places where the Meeple can live?</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/JRMF-IconsAct-MonsterTownNoBdr.png" alt="Monster Town">
                            </p>
                            <p>
                                Monster Town                            </p>
                            <p>Race your friends to find the patterns in these Halloween-themed SET cards!</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/IconV3.png" alt="Mosaics">
                            </p>
                            <p>
                                Mosaics                            </p>
                            <p>Can you make each mosaic?</p>
                            
                        </div>

                                        <div>
                            <p><span>3rd - 12th Grade</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/palindromeicon.png" alt="Palindrome Swap">
                            </p>
                            <p>
                                Palindrome Swap                            </p>
                            <p>Can you make palindromes in the fewest number of swaps?</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/JRMF-IconAct-PanningForGoldNoBdr.png" alt="Panning for Gold">
                            </p>
                            <p>
                                Panning for Gold                            </p>
                            <p>Among all the counterfeits there is only one true gold bar. Can you find it?</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Shape </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/icon.png" alt="Pentominoes">
                            </p>
                            <p>
                                Pentominoes                            </p>
                            <p>Can you find a way to cover the shapes with pentominoes?</p>
                            
                        </div>

                                        <div>
                            <p><span>3rd - 12th Grade</span>
                                <span>Shape </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/icon-5.png" alt="Poly Puzzles">
                            </p>
                            <p>
                                Poly Puzzles                            </p>
                            <p>Can you build a polyhedron using the shapes in each puzzle?</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/JRMF-IconAct-PoolTestingNoBdr.png" alt="Pool Testing">
                            </p>
                            <p>
                                Pool Testing                            </p>
                            <p>Learn how doctors help patients using pool testing through this engaging game.</p>
                            
                        </div>

                                        <div>
                            <p><span>3rd - 12th Grade</span>
                                <span>Number </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/JRMF-IconsActPrimeCubesNoBdr.png" alt="Prime Cubes">
                            </p>
                            <p>
                                Prime Cubes                            </p>
                            <p>Armed with only your understanding of prime numbers, play against your friends to find the best way to fill in our colorful cube.</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/JRMF-IconsActRiverCrossingsNewWebsite.png" alt="River Crossings">
                            </p>
                            <p>
                                River Crossings                            </p>
                            <p>Help your wolf, goat, and cabbage cross the river.</p>
                            
                        </div>

                                        <div>
                            <p><span>3rd - 12th Grade</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/RooksMoveIcon2.png" alt="Rook’s Move">
                            </p>
                            <p>
                                Rook’s Move                            </p>
                            <p>Race your friends to get the rook to the end of the chessboard. Can you find a way to win every time?</p>
                            
                        </div>

                                        <div>
                            <p><span>3rd - 12th Grade</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/icon-4.png" alt="Rubik’s Riddles">
                            </p>
                            <p>
                                Rubik’s Riddles                            </p>
                            <p>Can you make the pattern in the puzzle by rotating the cube?</p>
                            
                        </div>

                                        <div>
                            <p><span>3rd - 12th Grade</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/JRMF-IconAct-SkyscrapersBeginNoBdr.png" alt="Skyscrapers">
                            </p>
                            <p>
                                Skyscrapers                            </p>
                            <p>Help the city planner build up the city with new skyscrapers.</p>
                            
                        </div>

                                        <div>
                            <p><span>3rd - 12th Grade</span>
                                <span>Shape </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/JRMF-IconsActSmileysNoBdr.png" alt="Smileys">
                            </p>
                            <p>
                                Smileys                            </p>
                            <p>Smiling is contagious! Can you turn every frown upside down?</p>
                            
                        </div>

                                        <div>
                            <p><span>3rd - 12th Grade</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/JRMF-IconAct-SprigsGPurp.png" alt="Sprigs">
                            </p>
                            <p>
                                Sprigs                            </p>
                            <p>Take turns drawing curves to connect dots. Can you be the one to draw the last curve?</p>
                            
                        </div>

                                        <div>
                            <p><span>3rd - 12th Grade</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/StarBattleIcon.png" alt="Star Battle">
                            </p>
                            <p>
                                Star Battle                            </p>
                            <p>Can you place the stars on the grid?</p>
                            
                        </div>

                                        <div>
                            <p><span>3rd - 12th Grade</span>
                                <span>Number </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/IconNew.png" alt="Stepping Stones">
                            </p>
                            <p>
                                Stepping Stones                            </p>
                            <p>Can you find a way to place the next stepping stone?</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Shape </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/icon-1.png" alt="Tile with Style">
                            </p>
                            <p>
                                Tile with Style                            </p>
                            <p>Can you cover the entire square with pattern blocks?</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Shape </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/JRMF-IconsActTippyToadsNoBdr.png" alt="Tippy Toads">
                            </p>
                            <p>
                                Tippy Toads                            </p>
                            <p>How many toads can you help sunbathe by balancing them on a lilypad?</p>
                            
                        </div>

                                        <div>
                            <p><span>3rd - 12th Grade</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/IconV2-2.png" alt="Toothpick Squares">
                            </p>
                            <p>
                                Toothpick Squares                            </p>
                            <p>Can you make the right number of squares out of toothpicks?</p>
                            
                        </div>

                                        <div>
                            <p><span>3rd - 12th Grade</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/TriangleIcon.png" alt="Toothpick Triangles">
                            </p>
                            <p>
                                Toothpick Triangles                            </p>
                            <p>Can you make the right number of triangles out of toothpicks?</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Logic </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/2022/06/JRMF-IconsActTowersOfHanoiNoBdr.png" alt="Tower of Hanoi">
                            </p>
                            <p>
                                Tower of Hanoi                            </p>
                            <p>Can you solve these puzzles based on an ancient legend, golden disks, and the end of the world?</p>
                            
                        </div>

                                        <div>
                            <p><span>For All Ages</span>
                                <span>Shape </span>
                            </p>
                            <p><img src="https://jrmf.org/wp-content/uploads/wolvesandsheepicon_1.png" alt="Wolves and Sheep">
                            </p>
                            <p>
                                Wolves and Sheep                            </p>
                            <p>Keep your sheep safe from the wolves!</p>
                            
                        </div>

                    
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Wayfair fired a bunch of people again today, after using them to train AI (134 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=40070566</link>
            <guid>40070566</guid>
            <pubDate>Wed, 17 Apr 2024 22:07:48 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=40070566">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="40074546"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40074546" href="https://news.ycombinator.com/vote?id=40074546&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><p><span>Oh yes, Wayfair. In this case I’m pretty sure AI will be an improvement. Their customer support was abysmal. I needed to send a package back, they sent a company to get it and then refused to refund me because they somehow lost a piece of furniture and it never arrived.<p>I sent them the documents showing that the package was collected and then came a reply if I could check the apartment better, maybe I’ll end up finding the missing piece of furniture
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="40074513"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40074513" href="https://news.ycombinator.com/vote?id=40074513&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><br><div>
                  <p><span>To me was always weird how a company whose only means of doing business is a website, always had friction towards testability, to the point where I was continuously told by managers “we’re not a tech company”, while also having to revert multiple commits per day because of broken / untested code</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40071903"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40071903" href="https://news.ycombinator.com/vote?id=40071903&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><p><span>A friend of mine was just fired after he worked on a 6-month death march project.  He worked until 2am almost every night with meetings at 7am the next day, including weekends. He missed New years, Christmas events, kids birthdays/other family events, and any planned vacations.<p>His reward was the elimination of his position at the end of the project.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40074537"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40074537" href="https://news.ycombinator.com/vote?id=40074537&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><br><div>
                  <p><span>These kind of people are detrimental to the whole sector, I am kinda happy when I hear these stories, maybe in his next job he will work contract hours</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40073069"><td></td></tr>
            <tr id="40072392"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40072392" href="https://news.ycombinator.com/vote?id=40072392&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><p><span>NEVER sacrifice your life for an artificial deadline.<p>How to determine if something is an artificial deadline? Because if it were a real deadline with significance to the business, they'd pull more hands on deck, remove roadblocks relentlessly day after day, and even offer to take portions of your work on themselves so that the deadlines can be met.</p><p>If they are not making such moves, rest assured that the deadline is not critical - but only required for some BS stack ranking, or for the management's own promotion. They WILL fire you after putting all the work if it fits their BS processes.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40073021"><td></td></tr>
                <tr id="40074248"><td></td></tr>
                  <tr id="40073569"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40073569" href="https://news.ycombinator.com/vote?id=40073569&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><br><div>
                  <p><span>I'd go further and say to never sacrifice your life for any deadline at all. Part of having a work contract specifically means that all risks rests on capital holders shoulders and not yourself.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40073874"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40073874" href="https://news.ycombinator.com/vote?id=40073874&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><br><div>
                  <p><span>That is an incredibly succinct way of summarising the way I started to see the world about a decade ago (and more than a decade into my career as a developer).</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40074450"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40074450" href="https://news.ycombinator.com/vote?id=40074450&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><p><span>This seems trivially false.  The risk that a worker stops being paid because their capital holder no longer has income is always going to be there, and that could be because one or more workers were unable to accomplish one or more tasks necessary for the capital holders to sell a product or service.<p>Of course, some workers are also capital holders, and should be negotiating appropriate terms such that their mission critical contribution is appropriately rewarded.  And no one should be compelled to sacrifice their life without this “appropriate reward”, but exactly what that is is always in flux depending on many parameters.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40074540"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_40074540" href="https://news.ycombinator.com/vote?id=40074540&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><p><span>It's on the capital holders to make sure that the deadlines are reachable and appropriate to the amount of time you actually have working normally, rushing as a worker doesn't make any sense.<p>Either they miscalculated the number of employees they needed or they just aren't profitable enough to sustain the workload, both cases are failures on the company side.</p><p>And sure, if the company is willing to, they can share some of that risk and reward associated with it to the employees
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="40073287"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40073287" href="https://news.ycombinator.com/vote?id=40073287&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><p><span>Just adding more people to a team isn't useful if you don't have the time to integrate them well in a project.<p>Even then, it might be what you call a "real deadline", doesn't mean you should overwork for months, a couple of days or even some weeks is okay, but you should also be compensated for it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="40074019"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40074019" href="https://news.ycombinator.com/vote?id=40074019&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><br><div>
                  <p><span>Seeing people working overtime with the idea it may pay in the future always put a smile on my face. Luckilly new generations are not that stupid and they are much more hesitant to do it than boomers or even millenials.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40073529"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40073529" href="https://news.ycombinator.com/vote?id=40073529&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><br><div>
                  <p><span>It seems that senior management in these companies you are talking about are following Royce du Pont's advice.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40073593"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40073593" href="https://news.ycombinator.com/vote?id=40073593&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><br><div>
                  <p><span>I had to double check the reference just to make sure you were in fact talking about business luminary Royce du Pont. His negotiation tactics are second to none.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40074438"><td></td></tr>
            <tr id="40072431"><td></td></tr>
                <tr id="40074134"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40074134" href="https://news.ycombinator.com/vote?id=40074134&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><br><div>
                  <p><span>I don't really understand the moral issue with a company eliminating jobs. Similarly, I also don't think these companies are doing a moral good for creating jobs in the first place.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40074410"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40074410" href="https://news.ycombinator.com/vote?id=40074410&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><p><span>I think the issue that most people have is also that companies expect a certain level of respect and dedication from their employees but are not willing to reciprocate.<p>Make sure to work as hard as possible for us, pleas work extra hours if the company is doing bad. Don't take your vacations when it might impact team performance badly. If you leave give up a big heads up.</p><p>However we'll refuse your raises and bonuses if we feel like it. Also must be willing to move and uproot your whole life with no guarantee we'll keep you for long. We'll fire you one day after telling you your job was safe, and close all your company accounts before you get to save any of your documents or say bye to your colleagues. And remember no complaining after you leave, or we'll get you. Happened to quite a few people I know, not me thankfully.</p><p>And just "get an other job if you company sucks" doesn't always work. You might not know that your company sucks until you're out the door, or finding a new job in your field or without moving your whole family might not be easy
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="40074274"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40074274" href="https://news.ycombinator.com/vote?id=40074274&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><br><div>
                  <p><span>The moral issue comes because these jobs are tied to people's livelihoods and ability to provide essentials like food, housing, healthcare, etc for themselves and their families.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40074285"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40074285" href="https://news.ycombinator.com/vote?id=40074285&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><br><div>
                  <p><span>So is the company doing a morally good thing when it provides the ability for someone to have food, housing, healthcare, etc? If not, it doesn't make sense to blame the company for eliminating jobs if they also don't get credit for employing people for however many years.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="40074422"><td></td></tr>
                <tr id="40074521"><td></td></tr>
                        <tr id="40070991"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40070991" href="https://news.ycombinator.com/vote?id=40070991&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><p><span>Wasn’t this the company where the ceo urged everyone to work insane hours?<p>These people only care about themselves.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40073008"><td></td></tr>
                <tr id="40074283"><td></td></tr>
                  <tr id="40073204"><td></td></tr>
                  <tr id="40070647"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40070647" href="https://news.ycombinator.com/vote?id=40070647&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><br><div>
                  <p><span>It seems one of AI's major successes will be the production of schadenfreude (as when this effort goes disastrously pear shaped.)</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40074532"><td></td></tr>
                  <tr id="40071502"><td></td></tr>
                <tr id="40074472"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40074472" href="https://news.ycombinator.com/vote?id=40074472&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><br><div>
                  <p><span>It's not a new thing, every time a new consultancy is hired to "help you" and begins process of "discovery" it's a signal to get your CVs updated.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40074001"><td></td></tr>
            <tr id="40074483"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40074483" href="https://news.ycombinator.com/vote?id=40074483&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><br><div>
                  <p><span>Buyers choosing to buy equivalent or sufficiently “good“ products or services sold at the lowest price is a very, very old thing.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40074318"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40074318" href="https://news.ycombinator.com/vote?id=40074318&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><br><div>
                  <p><span>It's similar to how people buy meat all nicely wrapped in plastic from the supermarket and pretend the slaughter and cruelty doesn't happen. Many of them claim to be "animal lovers" too. Self-delusion is a powerful thing. It lets people do things they wouldn't otherwise feel comfortable with. Treating people like humans, getting to know them, making friends etc. means you inevitably start thinking of them like equals. That's no way to get on top.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40074550"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40074550" href="https://news.ycombinator.com/vote?id=40074550&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><br><div>
                  <p><span>In an opposite way, a process of abstraction also protects the top from the bottom. We keep talking about this fictitious entity called "Wayfair", yet this thread does not yet mention the name of the CEO, Niraj S. Shah, even omce, or anything about him. Yet he is the actual person who exists in the material world.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="40073053"><td></td></tr>
            <tr id="40072852"><td></td></tr>
                <tr id="40074478"><td></td></tr>
            <tr id="40073065"><td></td></tr>
                <tr id="40073521"><td></td></tr>
                <tr id="40074229"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40074229" href="https://news.ycombinator.com/vote?id=40074229&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><br><div>
                  <p><span>With the right system prompt, you can also have it answer questions wrong and then insist to you that the correct information must be mistaken or malicious.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40073787"><td></td></tr>
            <tr id="40074292"><td></td></tr>
                              <tr id="40073473"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40073473" href="https://news.ycombinator.com/vote?id=40073473&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><p><span>Step 1: have a moral compass and don’t work for shit tier companies.<p>Is it really that hard?</p><p>I find it hilarious when people work for these garbage companies in the first place. And then I’m supposed to do what when they turn on you? Cool story?</p><p>It’s really on them imo. There are other jobs out there. Better yet you can do your own thing. But nah fam.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="40074108"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40074108" href="https://news.ycombinator.com/vote?id=40074108&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><br><div>
                  <p><span>Ex-Wayfair engineer here. Problem is that not every company is shit from the start. They were pretty cool when I joined. Not so much when they cut my entire department 7 months later. (They started getting noticeably less cool 3 mo in to my tenure, but still.)</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40074489"><td></td></tr>
                  <tr id="40073814"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40073814" href="https://news.ycombinator.com/vote?id=40073814&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><p><span>Step 1: have parents rich enough to support you for a while so you don’t have to take a job with the shit company that exploits you<p>Is it really that hard?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="40073577"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40073577" href="https://news.ycombinator.com/vote?id=40073577&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><br><div>
                  <p><span>Although I don't disagree with what you said, I disagree with how you said it. Some people are in a though spot and need a job fast. And not everyone else is able to create a startup and be an entrepreneur. It's never that simple.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40074365"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40074365" href="https://news.ycombinator.com/vote?id=40074365&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><br><div>
                  <p><span>As much as I agree that people should try to avoid companies with bad ethics, it is not always that simple. I know some junior in tech that need to send 300+ applications for even just an internship and it is not uncommon for even more seasoned people to have to send 100s of applications to just even get a decent number of interviews. It is just hard to get a perfect view of the ethics of these hundred of companies. And if you just do that check at the interview step, which I am sure quite a few people will do, it can be tough to refuse 80% of your interviews because of companies have bad practices, when you struggled badly to land these few interviews.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40073225"><td></td></tr>
            <tr id="40071174"><td></td></tr>
                      <tr id="40074238"><td></td></tr>
            <tr id="40073083"><td></td></tr>
                <tr id="40073176"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40073176" href="https://news.ycombinator.com/vote?id=40073176&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><br><div>
                  <p><span>Wayfair is like a retail outlet for garbage products right? Why wouldn't they sell to anyone with money?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40073930"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40073930" href="https://news.ycombinator.com/vote?id=40073930&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><br><div>
                  <p><span>Eh idk, I've had some Wayfair stuff in the past and it's all been solid. I'm sure a lot of it is subpar though.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40074235"><td></td></tr>
            <tr id="40074260"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40074260" href="https://news.ycombinator.com/vote?id=40074260&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><br><div>
                  <p><span>ICE as in the US federal law enforcement agency? Yes, US companies do sell products to the US government sometimes.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40074102"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40074102" href="https://news.ycombinator.com/vote?id=40074102&amp;how=up&amp;goto=item%3Fid%3D40070566"></a></center>    </td><td><br><div>
                  <p><span>It this really an issue? It's selling chairs to a legitimate government agency. People's politics have become so skewed. That's just completely normal behavior.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  </tbody></div></div>]]></description>
        </item>
    </channel>
</rss>