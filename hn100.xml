<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 15 Apr 2025 01:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Intel sells 51% stake in Altera to private equity firm on a $8.75B valuation (183 pts)]]></title>
            <link>https://newsroom.intel.com/corporate/intel-partner-deal-news-april2025</link>
            <guid>43686773</guid>
            <pubDate>Mon, 14 Apr 2025 21:59:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newsroom.intel.com/corporate/intel-partner-deal-news-april2025">https://newsroom.intel.com/corporate/intel-partner-deal-news-april2025</a>, See on <a href="https://news.ycombinator.com/item?id=43686773">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Raghib Hussain appointed chief executive officer of Altera.</p><div nonce="ijCpSEMuRnL490hOs/kXNA==">

					
						

					<!--?xml encoding="utf-8" ?--><p>SANTA CLARA, Calif.; SAN JOSE, Calif.; and MENLO PARK, Calif., April 14, 2025 – Intel Corporation today announced that it has entered into a definitive agreement to sell 51% of its Altera business to Silver Lake, a global leader in technology investing.</p><p>The transaction, which values Altera at $8.75 billion, establishes Altera’s operational independence and makes it the largest pure-play FPGA (field programmable gate array) semiconductor solutions company. Altera offers a proven and highly scalable architecture and tool chain and is focused on driving growth and FPGA innovation to meet the demands and opportunities of an AI-driven market.</p><p>Intel will own the remaining 49% of the Altera business, enabling it to participate in Altera’s future success while focusing on its core business.</p><p>Intel also announced that Raghib Hussain will succeed Sandra Rivera as chief executive officer of Altera, effective May 5, 2025. Hussain is a highly accomplished and visionary technology executive with strong business acumen and engineering credentials. He joins Altera from his previous role as president of Products and Technologies at Marvell. Prior to joining Marvell in 2018, Hussain served as chief operating officer of Cavium, a company he co-founded. Prior to Cavium, Hussain held engineering roles at both Cisco and Cadence and helped found VPNet, an enterprise security company.</p><p>“Today’s announcement reflects our commitment to sharpening our focus, lowering our expense structure and strengthening our balance sheet,” said Lip-Bu Tan, chief executive officer of Intel. “Altera continues to make progress repositioning its product portfolio to participate in the fastest growing and most profitable segments of the FPGA market. We are grateful for Sandra’s strong leadership and lasting impact throughout her 25-year Intel career and wish her continued success as she begins a new chapter. Raghib is a superb executive we selected to lead the business forward based on his vast industry experience and proven track record of success. We look forward to partnering with Silver Lake upon closing of the transaction, as their industry expertise will help to accelerate Altera's efforts and unlock additional economic value for Intel.”</p><p>“This investment represents a once-in-a-generation opportunity to invest in a scale leader in advanced semiconductors. Together with Raghib, we will be focused on strengthening Altera’s technology leadership position and investing in emerging AI-driven markets such as edge computing and robotics,” said Kenneth Hao, chairman and managing partner of Silver Lake. “We look forward to working closely with Intel as a strategic partner who will continue to provide U.S.-based foundry services and complementary engagement with customers.”</p><p>“I am excited to lead Altera in its next chapter, and this milestone with Silver Lake furthers Altera’s journey to be the world's No. 1 FPGA solutions provider,” said Hussain. “Backed by Silver Lake’s strong track record and now with clarity of focus as an independent company, Altera is well-positioned to build on its momentum and deliver breakthrough FPGA-based solutions that are shaping the future of compute driven by AI. I am grateful for the impact Sandra has made and the team she has built as we begin Altera’s next phase of growth.”</p><p>Altera has been at the forefront of driving FPGA innovations for more than 40 years. The company provides leading programmable solutions that are easy-to-use and deploy in a range of strategically important segments such as industrial, communications, data center and military, aerospace, and government, as well as emerging markets such as AI/edge and robotics. Its broad portfolio of programmable semiconductor solutions, software and development tools deliver the reliability and flexibility needed to accelerate customer technology innovation.</p><p>The transaction is expected to close in the second half of 2025, subject to customary closing conditions.</p><p>Upon closing, Intel expects to deconsolidate Altera’s financial results from Intel’s consolidated financial statements. In Fiscal Year 2024, Altera generated revenues of $1.54 billion, GAAP gross margin of $361 million and GAAP operating loss of $615 million. Altera’s Fiscal Year 2024 non-GAAP gross margin was $769 million and non-GAAP operating income was $35&nbsp;million. Reconciliations between the GAAP and non-GAAP measures are provided below.</p><p>Morgan Stanley &amp; Co. LLC acted as financial advisor to Intel.</p><p><strong>Forward-Looking Statements</strong></p><p>This release contains forward-looking statements that involve a number of risks and uncertainties, including with respect to the terms and anticipated timing of closing the agreed upon sale of a controlling interest in Altera and the potential benefits of such sale to Intel and Altera. Such statements involve risks and uncertainties that could cause actual results to differ materially from those expressed or implied, including:&nbsp; the risk that the transaction may not be completed in a timely manner or at all, including as a result of a failure to receive regulatory approvals; the occurrence of any event, change or other circumstance that could give rise to the termination of the transaction; the risk that the expected benefits of the transaction, including as a result of the increased independence of Altera, may not be realized; the risk of future loss of the Altera business by Intel as a result of the sale of a controlling interest in Altera; disputes or potential litigation related to the transaction or the ownership, control and operation of the Altera business, including as it relates to Intel; unanticipated costs related to the transaction or the Altera business that may be incurred; risks as to the retention of key Altera personnel and customers; risks related to the diversion of management’s attention during the pendency of the transaction; potential adverse reactions or changes to business relationships resulting from the announcement or completion of the transaction; changes in demand for Altera’s semiconductor products; the high level of competition and rapid technological change in the semiconductor industry; and other risks and uncertainties described in Intel’s 2024 Form 10-K and our other filings with the SEC.</p><p>Given these risks and uncertainties, readers are cautioned not to place undue reliance on such forward-looking statements. Readers are urged to carefully review and consider the various disclosures made in this release and in other documents we file from time to time with the SEC that disclose risks and uncertainties that may affect our business.</p><p>All information in this press release reflects Intel management views as of the date hereof unless an earlier date is specified. Intel does not undertake, and expressly disclaims any duty, to update such statements, whether as a result of new information, new developments, or otherwise, except to the extent that disclosure may be required by law.</p><p><strong>Non-GAAP Financial Measures</strong></p><p>This release contains references to non-GAAP financial measures: Altera non-GAAP gross margin and Altera non-GAAP operating income / (loss) measures. Set out below are reconciliations of these measures to the most directly comparable GAAP financial measures. The non-GAAP financial measures disclosed herein should not be considered a substitute for, or superior to, the financial measures prepared in accordance with GAAP. Please refer to “Explanation of Non-GAAP Measures” in Intel’s earnings release dated Jan. 30, 2025 for a detailed explanation of the adjustments made to the comparable GAAP measures, the ways management uses the non-GAAP measures, and the reasons why management believes the non-GAAP measures provide investors with useful supplemental information.</p><table nonce="ijCpSEMuRnL490hOs/kXNA==">
<tbody>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Twelve Months Ended</td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">(in Millions; Unaudited)</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Dec 28, 2024</td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">GAAP gross margin</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="><strong>$ 361</strong></td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Acquisition-related adjustments</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">402</td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Share-based compensation</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">6</td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Non-GAAP gross margin</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">$ 769</td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">GAAP operating income / (loss)</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="><strong>$ (615)</strong></td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Acquisition-related adjustments</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">491</td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Share-based compensation</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">122</td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Restructuring and other charges</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">37</td>
</tr>
<tr>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">Non-GAAP operating income / (loss)</td>
<td nonce="ijCpSEMuRnL490hOs/kXNA=="></td>
<td nonce="ijCpSEMuRnL490hOs/kXNA==">$ 35</td>
</tr>
</tbody>
</table><p><strong>About Intel</strong></p><p>Intel (Nasdaq: INTC) is an industry leader, creating world-changing technology that enables global progress and enriches lives. Inspired by Moore’s Law, we continuously work to advance the design and manufacturing of semiconductors to help address our customers’ greatest challenges. By embedding intelligence in the cloud, network, edge and every kind of computing device, we unleash the potential of data to transform business and society for the better. To learn more about Intel’s innovations, go to <a href="https://newsroom.intel.com/">newsroom.intel.com</a> and <a href="https://intel.com/">intel.com</a>.</p><p><strong>About Altera</strong><br>
Altera is a leading supplier of programmable hardware, software, and development tools that empower designers of electronic systems to innovate, differentiate, and succeed in their markets. With a broad portfolio of industry-leading FPGAs, SoCs, and design solutions, Altera enables customers to achieve faster time-to-market and unmatched performance in applications spanning data centers, communications, industrial, automotive, and more. For more information, visit&nbsp;<a href="http://www.altera.com./">www.altera.com.</a></p><p><strong>About Silver Lake</strong><br>
Silver Lake is a global technology investment firm, with approximately $104 billion in combined assets under management and committed capital and a team of professionals based in North America, Europe and Asia. Silver Lake’s portfolio companies collectively generate nearly $252 billion of revenue annually and employ approximately 433,000 people globally.</p>
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What Is Entropy? (136 pts)]]></title>
            <link>https://jasonfantl.com/posts/What-is-Entropy/</link>
            <guid>43684560</guid>
            <pubDate>Mon, 14 Apr 2025 18:32:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jasonfantl.com/posts/What-is-Entropy/">https://jasonfantl.com/posts/What-is-Entropy/</a>, See on <a href="https://news.ycombinator.com/item?id=43684560">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>People say many things about entropy: entropy increases with time, entropy is disorder, entropy increases with energy, entropy determines the arrow of time, etc.. But I have no idea what entropy is, and from what I find, neither do most other people. This is the introduction I wish I had when first told about entropy, so hopefully you find it helpful. My goal is that by the end of this long post we will have a rigorous and intuitive understanding of those statements, and in particular, why the universe looks different when moving forward through time versus when traveling backward through time.</p><p>This journey begins with defining and understanding entropy. There are multiple formal definitions of entropy across disciplines—thermodynamics, statistical mechanics, information theory—but they all share a central idea: <strong>entropy quantifies uncertainty</strong>. The easiest introduction to entropy is through Information Theory, which will lead to entropy in physical systems, and then finally to the relationship between entropy and time.</p><h2 id="information-theory"><span>Information Theory</span><a href="#information-theory"><i></i></a></h2><p>Imagine you want to communicate to your friend the outcome of some random events, like the outcome of a dice roll or the winner of a lottery, but you want to do it with the fewest number of bits (only 1s and 0s) as possible. How few bits could you use?</p><p>The creator of Information Theory, Claude Shannon, was trying to answer questions such as these during his time at Bell labs. He was developing the mathematical foundations of communication and compression, and eventually he discovered that the minimum number of bits required for a message was directly related to the uncertainty of the message. He was able to then formulate an equation to quantify the uncertainty of a message. When he shared it with his physicist colleague at Bell Labs, John von Neumann, von Neumann suggested calling it <em>entropy</em> for two reasons:</p><blockquote><p>Von Neumann, Shannon reports, suggested that there were two good reasons for calling the function “entropy”. “It is already in use under that name,” he is reported to have said, “and besides, it will give you a great edge in debates because nobody really knows what entropy is anyway.” Shannon called the function “entropy” and used it as a measure of “uncertainty,” interchanging the two words in his writings without discrimination.<br> — <em>Harold A. Johnson (ed.),</em> <em>Heat Transfer, Thermodynamics and Education: Boelter Anniversary Volume</em> (New York: McGraw-Hill, 1964), p. 354.</p></blockquote><p>Later we will see that the relationship between Shannon’s entropy and the pre-existing definition of entropy was more than coincidental, they are deeply intertwined.</p><p>But now let us see how Shannon found definitions for these usually vague terms of “information” and “uncertainty”.</p><p>In Information Theory, the information of an observed state is formally defined as the number of bits needed to communicate that state (at least for a system with equally likely outcomes with powers of two, we’ll see shortly how to generalize this). Here are some examples of information:</p><ul><li>If I flip a fair coin, it will take one bit of information to tell you the outcome: I use a <code>0</code> for head and a <code>1</code> for tails.</li><li>If I roll a fair 8-sided dice, I can represent the outcome with 3 bits: I use <code>000</code> for a 1, <code>001</code> for 2, <code>010</code> for 3, etc.</li></ul><p>The more outcomes a system can have, the more bits (information) it will require to represent its outcome. If a system has $N$ equally likely outcomes, then it will take $\text{log}_2(N)$ bits of information to represent an outcome of that system.</p><p>Entropy is defined as the expected number of bits of information needed to represent the state of a system (this is a lie, but it’s the most useful definition for the moment, we’ll fix it later). So the entropy of a coin is 1 since on average we expect it to take 1 bit of information to represent the outcome of the coin. An 8-sided dice will have an entropy of 3 bits, since we expect it to take an average of 3 bits to represent the outcome.</p><p>It initially seems that entropy is an unnecessary definition since we can just look at how many bits it takes to represent the outcome of our system and use that value, but this is only true when the chance of the outcomes are all equally likely.</p><p>Imagine now that I have a weighted 8-sided dice, so the number 7 comes up $50$% of the time while the rest of the faces come up $\approx 7.14$% of the time. Now, if we are clever, we can reduce the expected number of bits needed to communicate the outcome of the dice. We can decide to represent a 7 with a <code>0</code>, and all the other numbers will be represented with <code>1XXX</code> where the <code>X</code>s are some unique bits. This would mean that $50$% percent of the time we only have to use 1 bit of information to represent the outcome, and the other $50$% of the time we use 4 bits, so the expected number of bits (the entropy of the dice) is 2.5. This is lower than the 3 bits of entropy for the fair 8-sided dice.</p><p>Fortunately, we don’t need to come up with a clever encoding scheme for every possible system, there exists a pattern to how many bits of information it takes to represent a state with probability $p$. We know if $p=0.5$ such as in the case of a coin landing on heads, then it takes 1 bit of information to represent that outcome. If $p=0.125$ such as in the case of a fair 8-sided dice landing on the number 5, it takes 3 bits of information to represent that outcome. If $p=0.5$ such as in the case of our unfair 8-sided dice landing on the number 7, then it takes 1 bit of information, just like the coin, which shows us that all that matters is the probability of the outcome. With this, we can discover an equation for the number of bits of information needed for a state with probability $p$.</p><p>\[I(p) = -\text{log}_2(p)\]</p><p>This value $I$ is usually called <em>information content</em> or <em>surprise</em>, since the lower the probability of a state occurring, the higher the surprise when it does occur.</p><p>When the probability is low, the surprise is high, and when the probability is high, the surprise is low. This is a more general formula then “the number of bits needed” since it allows for states that are exceptionally likely (such as $99$% likely) to have surprise less then 1, which would make less sense if we tried to interpret the value as “the number of needed bits to represent the outcome”.</p><p>And now we can fix our definition of entropy (the lie I told earlier). Entropy is not necessarily the expected number of bits used to represent a system (although it is when you use an optimal encoding scheme), but more generally the entropy is the expected <em>surprise</em> of the system.</p><p>And now we can calculate the entropy of systems like a dice or a coin or any system with known probabilities for its outcomes. The expected surprise (entropy) of a system with $N$ possible outcomes each with probability $p_i$ (all adding up to 1) can be calculated as</p><p>\[\begin{align} \sum_{i=1}^{N} p_i \cdot I(p_i) = - \sum_{i=1}^{N} p_i \cdot \text{log}_2(p_i)\label{shannon_entropy}\tag{Shannon entropy}\\ \end{align}\]</p><p>And notice that if all the $N$ probabilities are the same (so $p_i = \frac{1}{N}$), then the entropy equation can simplify to</p><p>\[- \sum_{i=1}^{N} p_i \cdot \text{log}_2(p_i) \Rightarrow \text{log}_2(N)\]</p><p>Here are some basic examples using $\eqref{shannon_entropy}$.</p><ul><li>The entropy of a fair coin is</li></ul><p>\[- ( 0.5 \cdot \text{log}_2(0.5) + 0.5 \cdot \text{log}_2(0.5)) = \text{log}_2(2) = 1\]</p><ul><li>The entropy of a fair 8-sided dice is</li></ul><p>\[- \sum_{i=1}^{8} 0.125 \cdot \text{log}_2(0.125) = \text{log}_2(8) = 3\]</p><ul><li>The entropy of an unfair 8-sided dice, where the dice lands on one face $99$% of the time and lands on the other faces the remaining $1$% of the time with equal probability (about $0.14$% each), is</li></ul><p>\[- (0.99 \cdot \text{log}_2(0.99) + \sum_{i=1}^{7} 0.0014 \cdot \text{log}_2(0.0014)) = 0.10886668511648723\]</p><p>Hopefully it is a bit more intuitive now that entropy represents uncertainty. An 8-sided dice would have higher entropy than a coin since we are more uncertain about the outcome of the 8-sided dice than we are about the coin (8 equally likely outcomes are more uncertain than only 2 equally likely outcomes). But a highly unfair 8-sided dice has less entropy than even a coin since we have very high certainty about the outcome of the unfair dice. Now we have an actual equation to quantify that uncertainty (entropy) about a system.</p><p>It is not clear right now how this definition of entropy has anything to do with disorder, heat, or time, but this idea of entropy as uncertainty is fundamental to understanding the entropy of the universe which we will explore shortly. For reference, this definition of entropy is called Shannon entropy.</p><p>We will move on now, but I recommend looking further into Information Theory. It has many important direct implications for data compression, error correction, cryptography, and even linguistics, and touches nearly any field that deals with uncertainty, signals, or knowledge.</p><h2 id="physical-entropy"><span>Physical Entropy</span><a href="#physical-entropy"><i></i></a></h2><p>Now we will see entropy from a very different lens, that of Statistical Mechanics. We begin with the tried-and-true introduction to entropy which every student is given.</p><h3 id="balls-in-a-box"><span>Balls in a box</span><a href="#balls-in-a-box"><i></i></a></h3><p>I shall give you a box with 10 balls in it, $p_0$ through $p_9$, and we will count how many balls are on the left side of the box and on the right side of the box. Assume every ball is equally likely to be on either side. Immediately we can see it is highly unlikely that we count all the balls are on the left side of the box, and more likely that we count an equal number of balls on each side. Why is that?</p><p>Well, there is only one state in which we count all the balls on the left, and that is if every ball is on the left (truly astounding, but stay with me). But there are many ways in which the box is balanced: We could have $p_0$ through $p_4$ one side and the rest on the other, or the same groups but flipped from left to right, or we could have all the even balls on one side and the odd on the other, or again flipped, or any of the other many possible combinations.</p><p>This box is a system that we can measure the entropy of, at least once I tell you how many balls are counted on each side. It can take a moment to see, but imagine the box with our left and right counts as a system where the outcome will be finding out where all the individual balls are in the box, similar to rolling a dice and seeing which face it lands on.</p><p>This would mean that the box where we count all the balls on the left side only has one possible outcome: all the balls are on the left side. We would take this to mean that this system has $0$ entropy (no expected surprise) since we already know where we will find each individual ball.</p><p>The box with balanced sides (5 on each) has many possible equally likely outcomes, and in fact, we can count them. A famous equation in combinatorics is the N-choose-k equation, which calculates exactly this scenario. It tells us that there are 252 possible ways in which we can place 5 balls on each side. The entropy for this system would then be $- \sum_{i=1}^{252} \frac{1}{252} \cdot \text{log}_2(\frac{1}{252}) = \text{log}_2(252) = 7.9772799235$. This is the same as calculating the entropy of a 252-sided dice.</p><p>And if we were to increase the number of balls, the entropy of the balanced box would increase since there would then be even more possible combinations that could make up a balanced box.</p><p>We should interpret these results as: The larger the number of ways there are to satisfy the large-scale measurement (counting the number of balls on each side), the higher the entropy of the system. When all the balls are on the left, there is only one way to satisfy that measurement and so it has a low entropy. When there are many ways to balance it on both sides, it has high entropy.</p><p>Here we see 1000 balls bouncing around in a box. They will all start on the left, so the box would have 0 entropy, but once the balls start crossing to the right and changing the count on each side, the entropy will increase.</p><p><a href="https://jasonfantl.com/assets/img/posts/Entropy/2_cell_box.gif"><img data-src="/assets/img/posts/Entropy/2_cell_box.gif" alt=" balls in a box with its entropy " width="300" data-proofer-ignore=""></a></p><p>In Statistical Mechanics, the formal term for the large-scale measurement is the <em>macrostate</em>, and the specific states that can satisfy that measurement are <em>microstates</em>. We would call the measurement of the number of balls on each side of the box the macrostate, and the different combinations of positions of individual balls the microstates. So rephrasing the above: There is only one microstate representing the macrostate of all balls being counted on one side, and there are many microstates representing the macrostate of a balanced box.</p><p>But why did we decide to measure the number of balls on the left and right? We could have measured a different macrostate, and the entropy would be different.</p><h3 id="macrostates"><span>Macrostates</span><a href="#macrostates"><i></i></a></h3><p>Imagine instead of selecting the left and right halves of the box to count the number of balls, we instead count how many balls are in each pixel of the box. In this scenario, the entropy would almost always be maximized, as the balls rarely share a pixel. Even if all the balls were on the left side of the box, they would likely still each occupy a different pixel, and the measured entropy would be the same as if the balls were evenly distributed in the box.</p><p>If we use an expensive instrument to measure the box and track the balls with high precision, then the entropy would rarely change and would be very high. If we instead use an inexpensive instrument that can only tell if a ball is on the left or right of the box, then the entropy will be low and could very easily fluctuate if some of the balls temporarily end up on the same side of the box.</p><p>Let’s run exactly the same simulation of 1000 balls in the box again, still starting with the balls on the left. But, this time we count how many balls are in each cell in a 50x50 grid, as opposed to the previous two cells (the left and right cells). The entropy will be high since there are many microstates that represent a bunch of cells with only 1 ball in it, and the entropy won’t change much since two balls rarely share the same cell. Recall that if two balls share the same cell, the count would go up, and there are fewer microstates that satisfy a cell with a count of 2 compared to two cells with a count of 1 in each.</p><p><a href="https://jasonfantl.com/assets/img/posts/Entropy/50_cell_box.gif"><img data-src="/assets/img/posts/Entropy/50_cell_box.gif" alt=" balls in a box with its entropy " width="300" data-proofer-ignore=""></a></p><p>Entropy is not intrinsic to the physical system alone, but rather to our description of it as well — i.e., the macrostate we’re measuring, and the resolution at which we observe it.</p><p>This process of measuring a lower-resolution version of our system (like counting how many balls are on the left or right side of a box) is called <em>coarse-graining</em>.</p><p>How we choose/measure the macrostate, that is, how we coarse-grain the system, is dependent on the problem we are solving.</p><ul><li>Imagine you have a box of gas (like our balls in a box, but at the scale of $10^{25}$ balls in the box), and we place a temperature-reader on the left and right side of the box. This gives us a macrostate of two counts of the average ball speed on the left and right sides of the box. We can then calculate the entropy by comparing when the temperature-readers are equal to when they are different by $T$ degrees. Once we learn how time and entropy interact, we will use this model to show that the two temperature-readers are expected to converge to the same value over time.</li><li>Imagine you sequence the genome of many different people in a population, you could choose many different macrostates based on what you care about. You could count how many of each nucleotide there are in all the sequences, allowing you to quantify how variable the four nucleotides are in DNA. You could calculate the entropy of every individual position in the DNA sequence by counting how many nucleotide types are used in that position across the population, allowing you to identify portions of DNA that are constant across individuals or vary across individuals.</li></ul><p>How you choose to measure the macrostate can come in many forms for the same system, depending on what you are capable of measuring and/or what you care about measuring.</p><p>But once we have a macrostate, we need a way to identify all the microstates and assign probabilities to them.</p><h3 id="microstates"><span>Microstates</span><a href="#microstates"><i></i></a></h3><p>When we were looking at the positions of balls in a box in equally sized cells, it was easy to see that every ball was equally likely to be in any of the cells, so each microstate was equally likely. This made calculating the entropy very simple, we just used the simplified version of $\eqref{shannon_entropy}$ to find that for $W$ microstates that satisfy a given macrostate, the entropy of the system is $\text{log}_{2}(W)$. It isn’t too hard to extend this idea to microstates that are not equally likely.</p><p>For example, let’s calculate the entropy of a box with 5 balls on the left and 5 balls on the right, but we replace one of the balls in the box with a metal ball that is pulled by a magnet to the left. In this case, the probability of each microstate is no longer equally likely. If we assume there is an $80$% chance that the metal ball is on the left side instead of the right side, then the entropy of the box can be calculated as follows: For all of the 252 microstates, 126 of them have the metal ball on the left, which has a $0.8$ chance of being true, and the other 126 have the metal ball on the right with a $0.2$ chance. This means using the $\eqref{shannon_entropy}$ we get an entropy of</p><p>\[- \sum_{i=1}^{126} \frac{0.2}{126} \cdot \text{log}_2(\frac{0.2}{126}) - \sum_{i=1}^{126} \frac{0.8}{126} \cdot \text{log}_2(\frac{0.8}{126}) = 7.69921\]</p><p>This is a little less than the box with normal balls which had $7.9772799235$ entropy. This is exactly what we should expect, we are a bit more certain about the outcome of this system since we knew where one of the balls was more likely to be.</p><p>But this raises a subtle question: why did we choose this particular set of microstates? For example, if we have the macrostate of 5 balls on the left and 5 balls on the right, but we decide to use the 50x50 grid of cells to describe the microstates, then there are far more microstates that satisfy the macrostate compared to when we were using the 2x1 grid of left and right.</p><p>Let’s calculate the entropy for those two examples. Keep in mind they both have the same macrostate: 5 balls on the left and 5 balls on the right.</p><ul><li>If we choose to use the microstates of looking at the position of individual balls between two cells splitting the box in half, then we can use n-choose-k to calculate that there are 252 possible combinations of balls across the two cells. This gives us an entropy of $\text{log}_2(252) = 7.977279923$.</li><li>If we choose to use the microstates of looking at the position of individual balls between 50x50 (2500) cells splitting the box into a grid, then we can use n-choose-k to calculate that there are 252 possible combinations of balls across the two halves of the box, for each of which every ball could be in any of 50x25 (1250) cells. This gives us an entropy of $\text{log}_2(252*1250^{10}) = 110.8544037$.</li></ul><p>This result lines up very well with our Information-theoretic understanding of entropy: when we allow more microstates to represent the same macrostate, we are more uncertain about the microstate our system is in. But this result does raise some concerns.</p><p>If different microstates give different entropy, how do we choose the right microstates for our problem? Unlike the macrostate, this decision of which microstates to use is not determined by our instruments or the scope of the problem, it has to be determined by the person making the calculation. Often for physical systems people will use the set of microstates that capture all the relevant information related to the macrostate. For example, if our macrostate is about balls on the left or right side of a box, then we probably don’t care about the ball’s velocity or mass or anything else but the ball position.</p><p>Another concern is that it feels wrong that the same physical system with the same macrostate can have different entropies depending on the microstate representation we use. Usually, we expect physical systems to have invariant measurements regardless of the internal representation we decide to use for our measurement. But this is incorrect for entropy. We need to recall that entropy is the uncertainty of a system and that the definition of entropy is completely dependent on what we are uncertain about, which for physical systems are the microstates. This would be similar to someone asking “How many parts make up that machine?”, to which we should respond “How do you define a ‘part’?”. When we ask “What is the entropy of this macrostate?”, we need to respond with “What microstates are we using?”.</p><p>With all that said, there is some small truth to what our intuition is telling us, although it doesn’t apply to the general case. While the entropy of the system changes when we change the microstates, the relative differences in entropy across macrostates will be equal <em>if</em> the new microstates uniformly multiply the old microstates. That is, if each original microstate is split into the same number of refined microstates, then the entropy of every macrostate increases by a constant. We’re getting lost in the terminology, an example will demonstrate.</p><p>Let us again take the 10 balls in a box, and we will calculate the entropy of the system for a few different macrostates and microstate representations. We indicate the number of balls on each side of the box with <code>(L, R)</code>, where <code>L</code> is the number of balls on the left and <code>R</code> is the number of balls on the right. Then we calculate the entropy using the microstate of a 2x1 grid of cells (just the left and right halves of the box) and for the 50x50 grid of cells.</p><div><table><thead><tr><th>&nbsp;</th><th>(10,0)</th><th>(9,1)</th><th>(8,2)</th><th>(7,3)</th><th>(6,4)</th><th>(5,5)</th><th>(4,6)</th><th>(3,7)</th><th>(2,8)</th><th>(1,9)</th><th>(0,10)</th></tr></thead><tbody><tr><td>2x1</td><td>0.00000</td><td>3.32193</td><td>5.49185</td><td>6.90689</td><td>7.71425</td><td>7.97728</td><td>7.71425</td><td>6.90689</td><td>5.49185</td><td>3.32193</td><td>0.00000</td></tr><tr><td>50x50</td><td>102.87712</td><td>106.19905</td><td>108.36898</td><td>109.78401</td><td>110.59137</td><td>110.85440</td><td>110.59137</td><td>109.78401</td><td>108.36898</td><td>106.19905</td><td>102.87712</td></tr></tbody></table></div><p>And if we look, we will see that the entropy in the 50x50 grid microstate values is just the 2x1 grid values plus a constant. The relative entropy in both cases would be identical. This is even more clear if we mathematically show how the entropy is calculated. For the 2x1 grid we use the equation $\text{log}_2({10 \choose L})$, and for the 50x50 grid we use $\text{log}_2(1250^{10} {10 \choose L}) = \text{log}_2(1250^{10}) + \text{log}_2({10 \choose L})$. Mathematically we can see that it is the same as the entropy of the 2x1 grid offset by $\text{log}_2(1250^{10})$.</p><p>You can imagine if we added another dimension along the microstates that we would increase the entropy again by a constant. For example, if each of the 10 balls could be one of 3 colors, then the number of microstates would grow by a factor of $3^{10}$, and so the entropy of the whole system would increase by $\text{log}_2(3^{10})$.</p><p>Our intuition was correct when we used different microstates that are multiples of each other, but that intuition fails if the microstates are not so neatly multiples of each other. An easy example of this is if we represent the left side of the box as one cell and the right as a 50x25 grid of cells, then the entropy looks very different. Below is the table again, but with the added row of our non-homogenous microstates. An example of how we calculate the entropy of macrostate $(3, 7)$ is: there are 120 equally likely ways to place 3 balls on the left and 7 balls on the right, but the balls on the right can also be in $1250^7$ different states, so the entropy is $\text{log}_2(120 \cdot 1250^7) = 78.920877252$.</p><div><table><thead><tr><th>&nbsp;</th><th>(10,0)</th><th>(9,1)</th><th>(8,2)</th><th>(7,3)</th><th>(6,4)</th><th>(5,5)</th><th>(4,6)</th><th>(3,7)</th><th>(2,8)</th><th>(1,9)</th><th>(0,10)</th></tr></thead><tbody><tr><td>2x1</td><td>0.00000</td><td>3.32193</td><td>5.49185</td><td>6.90689</td><td>7.71425</td><td>7.97728</td><td>7.71425</td><td>6.90689</td><td>5.49185</td><td>3.32193</td><td>0.00000</td></tr><tr><td>50x50</td><td>102.87712</td><td>106.19905</td><td>108.36898</td><td>109.78401</td><td>110.59137</td><td>110.85440</td><td>110.59137</td><td>109.78401</td><td>108.36898</td><td>106.19905</td><td>102.87712</td></tr><tr><td>mixed</td><td>0.00000</td><td>13.60964</td><td>26.06728</td><td>37.77003</td><td>48.86510</td><td>59.41584</td><td>69.44052</td><td>78.92088</td><td>87.79355</td><td>95.91134</td><td>102.87712</td></tr></tbody></table></div><p>A funny thing to note is that when all the balls are on the left, the entropy is zero, but when all the balls are on the right, the entropy is maximized. And again, hopefully, this makes sense from our understanding of entropy, that it measures uncertainty relative to our microstates. If we know all the balls are on the left, then we know they must be in the single left cell, so no uncertainty. If we know the balls are all on the right, then they could be in any of $1250^{10}$ microstates, so high uncertainty.</p><p>Clearly, we need to be careful and aware of what microstates we are choosing when measuring the entropy of a system. Fortunately, for most physical systems we use the standard microstates of a uniform grid of positions and momentums of the balls (particles) in the system. Another standard microstate to use is the continuous space of position and momentum.</p><h3 id="continuous-microstates"><span>Continuous Microstates</span><a href="#continuous-microstates"><i></i></a></h3><p>So far, we’ve looked at discrete sets of microstates — such as balls in cells. But in physical systems, microstates are often continuous: positions and momenta can vary over a continuum. How do we compute entropy in this setting? This is not related to the rest of the explanation, but it is an interesting tangent to explore.</p><p>Let’s return to our 10 balls in a 2D box. If each ball can occupy any position in the square, then the microstate of the system is a point in a $20$-dimensional space (2 dimensions per ball). The number of possible microstates is infinite — and each individual one has infinitesimal probability.</p><p>In this setting, we use a probability density function $\rho(x)$, and entropy becomes a continuous integral:</p><p>\[S = - \int_X \rho(x) \log_2 \rho(x) \, dx\]</p><p>This is called differential entropy. It generalizes Shannon entropy to continuous systems, though it has some subtleties — it can be negative, and it’s not invariant under coordinate transformations.</p><p>If the density is uniform, say $\rho(x) = \frac{1}{V}$ over a region of volume $V$, then the entropy becomes:</p><p>\[S = - \int_X \frac{1}{V} \log_2 \left( \frac{1}{V} \right) dx = \log_2(V)\]</p><p>So entropy still grows with the logarithm of the accessible state volume, just as in the discrete case.</p><p>This formalism is particularly natural in quantum mechanics, where the wavefunction $\psi(x)$ defines a probability density $\rho(x) = |\psi(x)|^2$. Consider a 1D Gaussian wavefunction:</p><p>\[\psi(x) = \left( \frac{1}{\pi \sigma^2} \right)^{1/4} e^{-x^2 / (2 \sigma^2)}\]</p><p>Its entropy (in bits) is:</p><p>\[S = - \int_{-\infty}^{\infty} \rho(x) \log_2 \rho(x) \, dx = \frac{1}{2} \log_2(2 \pi e \sigma^2)\]</p><p>This shows that wider distributions have higher entropy, as expected: a more spread-out wavefunction indicates more uncertainty in the particle’s location.</p><p>For instance:</p><ul><li>If $\sigma = 1$, then $S \approx 2.047$</li><li>If $\sigma = 3$, then $S \approx 3.600$</li></ul><p>Which again should make sense: When we are less certain about a system, like where a particle will be when measured, the more entropy it has.</p><p>And a quick issue to address: If the state space is unbounded, like momentum in classical mechanics, then the entropy can diverge. This isn’t a problem in practice because physical systems typically have probability distributions (like Gaussians) that decay quickly enough at infinity to keep the entropy finite. When that’s not the case, we either limit the system to a finite region or focus on entropy differences, which remain well-defined even when absolute entropy diverges.</p><p>But let’s get back to our main topic, and we’ll get back into it with a historical overview.</p><h3 id="standard-usage-of-entropy"><span>Standard Usage of Entropy</span><a href="#standard-usage-of-entropy"><i></i></a></h3><p>Eighty years before Claude Shannon developed Information Theory, <a href="https://en.wikipedia.org/wiki/Ludwig_Boltzmann">Ludwig Boltzmann</a> formulated a statistical definition of entropy for an ideal gas. He proposed that the entropy $S$ of a system is proportional to the logarithm of the number of microstates $W$ consistent with a given macrostate:</p><p>\[\begin{align} S = k_{B} \ln(W) \label{boltzmann_entropy}\tag{Boltzmann entropy} \end{align}\]</p><p>This equation should look familiar: it’s the equal-probability special case of the Shannon entropy we’ve been using, just with a change of base (from $\log_2$ to $\ln$) and a scaling factor $k_B$ (Boltzmann’s constant). The connection between Boltzmann’s statistical mechanics and Shannon’s information theory is more than historical coincidence—both quantify uncertainty, whether in physical states or messages.</p><p>A few years later, <a href="https://en.wikipedia.org/wiki/Josiah_Willard_Gibbs">Josiah Willard Gibbs</a> generalized Boltzmann’s definition to cases where microstates are not equally likely. His formulation remains the standard definition of entropy in modern physics:</p><p>\[\begin{align} S = -k_B \sum_{i} p_i \ln(p_i) \label{gibbs_entropy}\tag{Gibbs entropy} \end{align}\]</p><p>This is formally identical to Shannon entropy, again differing only in logarithm base and physical units. But Gibbs’s generalization was a profound leap: it enabled thermodynamics to describe systems in contact with heat baths, particle reservoirs, and other environments where probability distributions over microstates are non-uniform. This made entropy applicable far beyond ideal gases—covering chemical reactions, phase transitions, and statistical ensembles of all kinds.</p><p>Now that we have a formal understanding of entropy with some historical background, let’s try to understand how entropy relates to our universe and in particular to time.</p><h3 id="time"><span>Time</span><a href="#time"><i></i></a></h3><p>How does time play a role in all of this?</p><p>When you drop a spot of milk into tea, it always spreads and mixes, and yet you never see the reverse where the milk molecules spontaneously separate and return to a neat droplet. When ocean waves crash into the shore, the spray and foam disperse, but we never see that chaos reassemble into a coherent wave that launches back into the sea. These examples are drawn from this <a href="https://www.youtube.com/watch?v=ROrovyJXSnM">lecture on entropy</a> by Richard Feynman. If you were shown a reversed video of these events, you’d immediately recognize something was off. This sounds obvious at first, but it actually isn’t clear this should be true if we just look at the laws of physics. All the known laws of physics are time-reversible (the wave function collapse seems to be debatable), which just means that they <em>do</em> look the same playing forward and backward. The individual molecules all obey these time-reversible laws, and yet the cup of tea gets murky from the milk always mixing in.</p><p>This highlights a fundamental paradox: the microscopic laws of physics are time-reversible, but the macroscopic world is not. If you took a video of two atoms bouncing off each other and played it backward, it would still look physically valid, but play a video of milk mixing into coffee backward, and it looks obviously wrong.</p><p>We want to build a simplified model of time in a way that reflects both the time-reversibility of microscopic laws and the time-asymmetry of macroscopic behavior. Let’s imagine the complete state of a physical system, like a box of particles, as a single point in a high-dimensional space called phase space, with each dimension corresponding to a particle’s position and momentum. As time evolves, the system traces out a continuous trajectory through this space.</p><p>The laws of physics, such as Newton’s equations, Hamiltonian mechanics, or Schrödinger’s equation, all govern this trajectory. They are deterministic and time-reversible. That means if you reverse the momenta of all particles at any moment, the system will retrace its path backward through state space.</p><p>So far everything is time-reversible, including this view of how the universe moves through time. But we will see that even in this toy model, time appears to have a preferred direction, an <em>arrow of time</em>.</p><p>The key lies in coarse-graining. When we observe the world, we don’t see every microscopic detail. Instead, we measure macrostates: aggregate properties like temperature, pressure, position of an object, or color distribution in a cup of tea. Each macrostate corresponds to many underlying microstates — and not all macrostates are created equal.</p><p>For example, consider a box sliding across the floor and coming to rest due to friction. At the microscopic level, the system is just particles exchanging momentum, and all time-reversible. But we certainly would not call this action time-reversible, we never see a box spontaneously start speeding up from stand-still. But, if we took the moment after the box comes to a rest due to friction, and you reversed the velocities of all the particles (including those in the floor that absorbed the box’s kinetic energy as heat), the box <em>would</em> spontaneously start moving and slide back to its original position. This would obey Newton’s laws, but it’s astronomically unlikely. Why?</p><p>The number of microstates where the energy is spread out as heat (the box is at rest, and the molecules in the floor are jiggling) vastly outnumber the microstates where all that energy is coordinated to move the box. The stand-still macrostate has high entropy while the spontaneous-movement macrostate has low entropy. When the system evolves randomly or deterministically from low entropy, it is overwhelmingly likely to move toward higher entropy simply because there are more such microstates.</p><p>If you had perfect knowledge of all particles in the universe (i.e., you lived at the level of microstates), time wouldn’t seem to have a direction. But from the perspective of a coarse-grained observer, like us, entropy tends to increase. And that’s why a movie of tea mixing looks natural, but the reverse looks fake. At the level of physical laws, both are valid. But one is typical, and one is astronomically rare, all because we coarse-grained.</p><p>To drive the point home, let’s again look at the balls in a box. We’ll define macrostates by dividing the box into a grid of cells and counting how many balls are in each bin.</p><p>Now suppose the balls move via random small jitters (our toy model of microscopic dynamics). Over time, the system will naturally tend to explore the most probable macrostates, as the most probable macrostates have far more microstates for you to wander into. That is, entropy increases over time, not because of any fundamental irreversibility in the laws, but because high-entropy macrostates are far more typical.</p><p>If we started the simulation with all the balls packed on the left, that’s a very specific (low entropy) macrostate. As they spread out, the number of compatible microstates grows, and so does the entropy.</p><p>This leads to a crucial realization: Entropy increases because we started in a low-entropy state. This is often called the <a href="https://en.wikipedia.org/wiki/Past_hypothesis">Past Hypothesis</a>, the postulate that the universe began in an extremely low-entropy state. Given that, the Second Law of Thermodynamics follows naturally. The arrow of time emerges not from the dynamics themselves, but from the statistical unlikelihood of reversing them after coarse-graining, and the fact that we began in a low-entropy state.</p><p>You could imagine once a system reaches near-maximum entropy that it no longer looks time-irreversible. The entropy of such a system would <a href="https://en.wikipedia.org/wiki/Fluctuation_theorem">fluctuate a tiny bit</a> since entropy is an inherently statistical measure, but they would be small enough not to notice. For example, while it is clear when a video of milk being poured into tea (a low-entropy macrostate) is playing forward as opposed to backward, you couldn’t tell if a video of already-combined milk and tea (a high-entropy macrostate) being swirled around is playing forward or backward.</p><p>While there are tiny fluctuations in entropy, they are not enough to explain the large-scale phenomena that sometimes seem to violate this principle that we just established of entropy always increasing with time.</p><h3 id="violations-of-the-second-law"><span>Violations of the Second Law?</span><a href="#violations-of-the-second-law"><i></i></a></h3><p>Some real-world examples seem to contradict the claim that entropy always increases. For instance, oil and water separate after mixing, dust clumps into stars and planets, and we build machines like filters and refrigerators that separate mixed substances. Aren’t these violations?</p><p>The issue is we have only been considering the position of molecules, while physical systems have many different properties which allow for more microstates. For example, if we start considering both the position and velocity of balls in a box, then the entropy can be high even while all the balls are on the left side of the box since every ball could have a different velocity. If the balls were all on the left <em>and</em> the velocities were all the same, then the entropy would be low. Once we consider velocity as well, entropy can increase both from more spread out positions and more spread out velocities.</p><p>When water and oil separate, the positions of the molecules separate into top and bottom, which appears to decrease positional entropy. However, this separation actually increases the total entropy of the system. Why? Water molecules strongly prefer to form hydrogen bonds with other water molecules rather than interact with oil molecules. When water molecules are forced to be near oil molecules in a mixed state, they must adopt more constrained arrangements to minimize unfavorable interactions, reducing the number of available microstates. When water and oil separate, water molecules can interact freely with other water molecules in more configurations, and oil molecules can interact with other oil molecules more freely. This increase in available microstates for molecular arrangements and interactions more than compensates for the decrease in positional mixing entropy. So, while the entropy decreases if we only consider the general positions of molecules (mixed versus separated), the total entropy increases when we account for all the molecular interactions, orientations, and local arrangements. This demonstrates why we need to consider all properties of a system when calculating its entropy.</p><p>When stars or planets form together from dust particles floating around in space and clump together from gravity, it would seem that even when we consider position and velocity of the particles that the entropy might be decreasing. Even though the particles speed up to clump together, they slow down after they collide, seemingly decreasing entropy. This is because we are again failing to consider the entire system. When particles collide with each other, their speed decreases a bit by turning that kinetic energy into radiation, causing photons to get sent out into space. If we considered a system where radiation isn’t allowed, then the kinetic energy would just get transferred from one particle to another through changes in velocity, and the entropy of the system would still be increasing because of the faster velocities. Once we start considering the entropy of the position, velocity, and <em>all</em> particles in a system, we can consider <em>all</em> the microstates that are equally likely and calculate the correct entropy.</p><p>Similarly, once we consider the entire system around a refrigerator, the decrease in entropy disappears. The entropy from the power generated to run the refrigerator and the heat moved from the inside to the outside of the refrigerator will offset the decrease in entropy caused by cooling the inside of the refrigerator. Local decreases in entropy <em>can</em> be generated, as long as the entropy of the entire system is still increasing.</p><p>Ensure that the entire system is being considered when analyzing the entropy of a system, with the position, velocity, other interactions of particles, that all particles are included, and that the entire system is actually being analyzed.</p><h3 id="disorder"><span>Disorder</span><a href="#disorder"><i></i></a></h3><p>Entropy is sometimes described as “disorder,” but this analogy is imprecise and often misleading. In statistical mechanics, entropy has a rigorous definition: it quantifies the number of microstates compatible with a given macrostate. That is, entropy measures our uncertainty about the exact microscopic configuration of a system given some coarse-grained, macroscopic description.</p><p>So where does the idea of “disorder” come from?</p><p>Empirically, macrostates we label as “disordered” often correspond to a vastly larger number of microstates than those we consider “ordered”. For example, in a child’s room, there are many more configurations where toys are scattered randomly than ones where everything is neatly shelved. Since the scattered room corresponds to more microstates, it has higher entropy.</p><p>But this connection between entropy and disorder is not fundamental. The problem is that “disorder” is subjective—it depends on human perception, context, and labeling. For instance, in our earlier example of 1000 balls bouncing around a box, a perfectly uniform grid of balls would have high entropy due to the huge number of possible microstates realizing it. And yet to a human observer, such a grid might appear highly “ordered.”</p><p>The key point is: entropy is objective and well-defined given a macrostate and a set of microstates, while “disorder” is a human-centric heuristic concept that sometimes, but not always, tracks entropy. Relying on “disorder” to explain entropy risks confusion, especially in systems where visual symmetry or regularity masks the underlying statistical structure.</p><h2 id="conclusion"><span>Conclusion</span><a href="#conclusion"><i></i></a></h2><p>So here are some thoughts in regard to some common statements made about entropy:</p><ul><li>Entropy is a measure of disorder.<ul><li>“disorder” is a subjective term for states of a system that humans don’t find useful/nice, and usually has much higher entropy than the “ordered” macrostate that humans create. Because of this, when entropy increases, it is more likely that we end up in disordered state, although not guaranteed.</li></ul></li><li>Entropy always increases in a closed system.<ul><li>This is a statistical statement that for all practical purposes is true, but is not guaranteed and can fail when you look at very small isolated systems or measure down to the smallest details of a system. It also assumes you started in a low-entropy state, giving your system space to increase in entropy. This has the neat implication that since our universe has been observed to be increasing in entropy, it must have begun in a low-entropy state.</li></ul></li><li>Heat flows from hot to cold because of entropy.<ul><li>Heat flows from hot to cold because the number of ways in which the system can be non-uniform in temperature is much lower than the number of ways it can be uniform in temperature, and so as the system “randomly” moves to new states, it will statistically end up in states that are more uniform.</li></ul></li><li>Entropy is the only time-irreversible law of physics.<ul><li>All the fundamental laws of physics are time-reversible, but by coarse-graining and starting from a lower-entropy state, a system will statistically move to a higher-entropy state. This means if a system is already in a near-maximum entropy state (either because of its configuration or because of the choice for coarse-graining) or we don’t coarse-grain, then entropy will not look time-irreversible.</li></ul></li></ul><p>And here is some further reading, all of which I found supremely helpful in learning about entropy.</p><ul><li><a href="https://www.youtube.com/watch?v=ROrovyJXSnM">Lecture on entropy by Richard Feynman</a></li><li><a href="https://scholar.harvard.edu/files/schwartz/files/6-entropy.pdf">Lecture notes on entropy from the Statistical Mechanics course at Harvard taught by Matthew Schwartz</a></li><li><a href="https://math.ucr.edu/home/baez/what_is_entropy.pdf">A both friendly and rigorous textbook on entropy by John C. Baez</a></li><li><a href="https://www.youtube.com/watch?v=VCXqELB3UPg">A youtube video on entropy using actual balls bouncing in a box</a></li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Harvard's response to federal government letter demanding changes (883 pts)]]></title>
            <link>https://www.harvard.edu/president/news/2025/the-promise-of-american-higher-education/</link>
            <guid>43684536</guid>
            <pubDate>Mon, 14 Apr 2025 18:28:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.harvard.edu/president/news/2025/the-promise-of-american-higher-education/">https://www.harvard.edu/president/news/2025/the-promise-of-american-higher-education/</a>, See on <a href="https://news.ycombinator.com/item?id=43684536">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

			<div>
				
<div><p>Dear Members of the Harvard Community,</p><p>&nbsp;For three-quarters of a century, the federal government has awarded grants and contracts to Harvard and other universities to help pay for work that, along with investments by the universities themselves, has led to groundbreaking innovations across a wide range of medical, engineering, and scientific fields. These innovations have made countless people in our country and throughout the world healthier and safer. In recent weeks, the federal government has threatened its partnerships with several universities, including Harvard, over accusations of antisemitism on our campuses. These partnerships are among the most productive and beneficial in American history. New frontiers beckon us with the prospect of life-changing advances—from treatments for diseases such as Alzheimer’s, Parkinson’s, and diabetes, to breakthroughs in artificial intelligence, quantum science and engineering, and numerous other areas of possibility. For the government to retreat from these partnerships now risks not only the health and well-being of millions of individuals but also the economic security and vitality of our nation.</p><p>&nbsp;Late Friday night, the administration issued an updated and expanded list of demands, warning that Harvard must comply if we intend to “maintain [our] financial relationship with the federal government.” It makes clear that the intention is not to work with us to address antisemitism in a cooperative and constructive manner. Although some of the demands outlined by the government are aimed at combating antisemitism, the majority represent direct governmental regulation of the “intellectual conditions” at Harvard.</p><p>&nbsp;I encourage you to&nbsp;<a href="https://www.harvard.edu/research-funding/wp-content/uploads/sites/16/2025/04/Letter-Sent-to-Harvard-2025-04-11.pdf" target="_blank" rel="noreferrer noopener">read the letter</a>&nbsp;to gain a fuller understanding of the unprecedented demands being made by the federal government to control the Harvard community. They include requirements to “audit” the viewpoints of our student body, faculty, staff, and to “reduc[e] the power” of certain students, faculty, and administrators targeted because of their ideological views. We have informed the administration through our legal counsel that&nbsp;<a href="https://www.harvard.edu/research-funding/wp-content/uploads/sites/16/2025/04/Harvard-Response-2025-04-14.pdf" target="_blank" rel="noreferrer noopener">we will not accept their proposed agreement</a>. The University will not surrender its independence or relinquish its constitutional rights.</p><p>&nbsp;The administration’s prescription goes beyond the power of the federal government. It violates Harvard’s First Amendment rights and exceeds the statutory limits of the government’s authority under Title VI. And it threatens our values as a private institution devoted to the pursuit, production, and dissemination of knowledge. No government—regardless of which party is in power—should dictate what private universities can teach, whom they can admit and hire, and which areas of study and inquiry they can pursue.</p><p>&nbsp;Our motto—Veritas, or truth—guides us as we navigate the challenging path ahead. Seeking truth is a journey without end. It requires us to be open to new information and different perspectives, to subject our beliefs to ongoing scrutiny, and to be ready to change our minds. It compels us to take up the difficult work of acknowledging our flaws so that we might realize the full promise of the University, especially when that promise is threatened.</p><p>&nbsp;We have made it abundantly clear that we do not take lightly our moral duty to fight antisemitism. Over the past fifteen months, we have taken many steps to address antisemitism on our campus. We plan to do much more. As we defend Harvard, we will continue to:&nbsp;</p></div>



<ul>
<li>nurture a thriving culture of open inquiry on our campus; develop the tools, skills, and practices needed to engage constructively with one another; and broaden the intellectual and viewpoint diversity within our community;&nbsp;</li>



<li>affirm the rights and responsibilities we share; respect free speech and dissent while also ensuring that protest occurs in a time, place, and manner that does not interfere with teaching, learning, and research; and enhance the consistency and fairness of disciplinary processes; and&nbsp;</li>



<li>work together to find ways, consistent with law, to foster and support a vibrant community that exemplifies, respects, and embraces difference. As we do, we will also continue to comply with&nbsp;<em>Students For Fair Admissions v. Harvard</em>, which ruled that Title VI of the Civil Rights Act makes it unlawful for universities to make decisions “on the basis of race.”&nbsp;</li>
</ul>



<div><p>These ends will not be achieved by assertions of power, unmoored from the law, to control teaching and learning at Harvard and to dictate how we operate. The work of addressing our shortcomings, fulfilling our commitments, and embodying our values is ours to define and undertake as a community. Freedom of thought and inquiry, along with the government’s longstanding commitment to respect and protect it, has enabled universities to contribute in vital ways to a free society and to healthier, more prosperous lives for people everywhere. All of us share a stake in safeguarding that freedom. We proceed now, as always, with the conviction that the fearless and unfettered pursuit of truth liberates humanity—and with faith in the enduring promise that America’s colleges and universities hold for our country and our world.</p><p>&nbsp;Sincerely,<br>Alan M. Garber</p></div>
			</div>

			

			
		</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Federal Government's letter to Harvard demanding changes [pdf] (114 pts)]]></title>
            <link>https://www.harvard.edu/research-funding/wp-content/uploads/sites/16/2025/04/Letter-Sent-to-Harvard-2025-04-11.pdf</link>
            <guid>43684386</guid>
            <pubDate>Mon, 14 Apr 2025 18:13:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.harvard.edu/research-funding/wp-content/uploads/sites/16/2025/04/Letter-Sent-to-Harvard-2025-04-11.pdf">https://www.harvard.edu/research-funding/wp-content/uploads/sites/16/2025/04/Letter-Sent-to-Harvard-2025-04-11.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=43684386">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[AudioX: Diffusion Transformer for Anything-to-Audio Generation (108 pts)]]></title>
            <link>https://zeyuet.github.io/AudioX/</link>
            <guid>43683907</guid>
            <pubDate>Mon, 14 Apr 2025 17:35:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zeyuet.github.io/AudioX/">https://zeyuet.github.io/AudioX/</a>, See on <a href="https://news.ycombinator.com/item?id=43683907">Hacker News</a></p>
<div id="readability-page-1" class="page">
  <!-- <section class="hero"> -->
  <section>
    <!-- <div class="hero-body"> -->
    <div>
          
          

          <p><span><sup>1</sup>HKUST</span>
          </p>

          <p><span><sup>†</sup>Corresponding authors
            </span>
          </p>
          
        </div>
    
    <!-- </section> -->

    <div>
        <!-- Abstract. -->
        <div>
            <h2>Abstract</h2>
            <p>
                Audio and music generation have emerged as crucial tasks in many applications, yet existing approaches face significant limitations: they operate in isolation without unified capabilities across modalities, suffer from scarce high-quality, multi-modal training data, and struggle to effectively integrate diverse inputs. In this work, we propose AudioX, a unified Diffusion Transformer model for Anything-to-Audio and Music Generation. Unlike previous domain-specific models, AudioX can generate both general audio and music with high quality, while offering flexible natural language control and seamless processing of various modalities including text, video, image, music, and audio. Its key innovation is a multi-modal masked training strategy that masks inputs across modalities and forces the model to learn from masked inputs, yielding robust and unified cross-modal representations. To address data scarcity, we curate two comprehensive datasets: vggsound-caps with 190K audio captions based on the VGGSound dataset, and V2M-caps with 6 million music captions derived from the V2M dataset. Extensive experiments demonstrate that AudioX not only matches or outperforms state-of-the-art specialized models, but also offers remarkable versatility in handling diverse input modalities and generation tasks within a unified architecture. 
              </p>
          </div>
        <!--/ Abstract. -->

        <!-- Paper video. -->
        <div>
            <h2>Demo Video</h2>
    
            
    
          </div>

        <!--/ Paper video. -->
      </div>

    <div>
    

            

            
  <!-- 单个任务示例：Text-to-Audio Generation -->
  <div>
    <!-- 外层容器，带边框 -->


      <!-- 任务标题 -->
      <h2>Text-to-Audio Generation</h2>

      <!-- 预览区域：2-3个示例 -->
      <div>
          <!-- 示例3 -->
          <div>
            <p><strong>Prompt:</strong>
              <br>  
              Thunder and rain during a sad piano solo</p>
            </div>          
          <!-- 示例1 -->
          <div>
            <p><strong>Prompt:</strong>
              <br>  
              Typing on a keyboard</p>
            </div>
          <!-- 示例2 -->
          <div>
            <p><strong>Prompt:</strong> 
              <br>  
              Ocean waves crashing</p>
            </div>           
     

        </div>

      <!-- 折叠按钮：点击展开更多样本 -->
      <!-- 折叠内容：更多 sample，带 carousel -->
      <div>

            <div>
              <p><strong>Prompt:</strong>
                A person is snoring</p>
              </div>              
            <div>
              <p><strong>Prompt:</strong> A toilet flushing</p>
              </div>

            <div>
              <p><strong>Prompt:</strong> Rain falling on a rooftop</p>
              </div>
            <div>
              <p><strong>Prompt:</strong> An airplane is taking flight</p>
              </div>                                                   
            <div>
              <p><strong>Prompt:</strong> An explosion and crackling</p>
              </div>
            
            <div>
              <p><strong>Prompt:</strong> Footsteps in snow</p>
              </div>

            <div>
              <p><strong>Prompt:</strong> A cat meowing repeatedly</p>
              </div>

            <div>
              <p><strong>Prompt:</strong> Food and oil sizzling</p>
              </div>
            <!-- 继续添加更多 sample-item ... -->
          </div>

  </div>


  <!-- 单个任务示例：Text-to-Music Generation -->
  <div>
    <!-- 外层容器，带边框 -->

      <!-- 任务标题 -->
      <h2>Text-to-Music Generation</h2>

      <!-- 预览区域：2-3个示例 -->
      <div>
          <!-- 示例1 -->
          <div>
            <p><strong>Prompt:</strong> 
              <br>  
              Orchestral, epic, with drums, strings, 
              <br>  
              and brass</p>
            </div>
          <!-- 示例2 -->
          <div>
            <p><strong>Prompt:</strong> 
              <br>  
              Electronic dance music with synthesizers, bass, drums, and a slow build-up</p>
            </div>
          <!-- 示例3 -->
          <div>
            <p><strong>Prompt:</strong> 
              <br>  
              Sad emotional soundtrack with ambient textures and solo cello</p>
            </div>
        </div>

      <!-- 折叠按钮：点击展开更多样本 -->
      <!-- 折叠按钮：点击展开更多样本 -->
      <!-- 折叠内容：更多 sample，带 carousel -->
      <div>
            <div>
              <p><strong>Prompt:</strong> 
                A suspenseful scene in a haunted mansion</p>
              </div>
            <div>
              <p><strong>Prompt:</strong> 
                An orchestral music piece for a fantasy world</p>
              </div>
            <div>
              <p><strong>Prompt:</strong> 
                
                Uplifting ukulele tune for a travel vlog</p>
              </div>
            <div>
              <p><strong>Prompt:</strong> 
                
                Romantic acoustic guitar music for a sunset scene</p>
              </div>                                                
            <div>
              <p><strong>Prompt:</strong> 
                Smooth urban R&amp;B beat with a mellow groove</p>
              </div>

            <div>
              <p><strong>Prompt:</strong> 
                Produce upbeat electronic music for a dance party</p>
              </div>
            
            <div>
              <p><strong>Prompt:</strong> 
                Playful 8-bit chiptune music for a retro platformer game</p>
              </div> 
            
            <div>
              <p><strong>Prompt:</strong> 
                Ambient synth music in a deep space setting</p>
              </div>             
            <!-- 继续添加更多 sample-item ... -->
          </div>


  </div>




    
            <!-- Video-to-Audio Generation -->
            <div>

                <h2>Video-to-Audio Generation</h2>
                

      <!-- 折叠按钮：点击展开更多样本 -->
      <!-- 折叠内容：更多 sample，带 carousel -->
      

            </div>
    
            <!-- Video-to-Music Generation -->
            <div>

                <h2>Video-to-Music Generation</h2>
                
      <!-- 折叠按钮：点击展开更多样本 -->
      <!-- 折叠内容：更多 sample，带 carousel -->
      
          </div>
    




    </div>
    
    
    
    
    

    
    <div>
            <h2>Teaser</h2>
            <!-- <div class="columns is-centered"> -->
            <p><img src="https://zeyuet.github.io/AudioX/static/images/teaser.png" alt="Teaser." height="100%" width="100%"></p><p>
                (a) Overview of AudioX, illustrating its capabilities across various tasks. (b) Radar chart comparing the performance of different methods across multiple benchmarks. AudioX demonstrates superior Inception Scores (IS) across a diverse set of datasets in audio and music generation tasks.
              </p>
          </div>

    <div>
            <h2>Method</h2>
            <!-- <div class="columns is-centered"> -->
            <p><img src="https://zeyuet.github.io/AudioX/static/images/method-.png" alt="Method." height="100%" width="100%"></p><p>
                The AudioX Framework.
              </p>
          </div>


    <div id="BibTeX">
        <h2>BibTeX</h2>
        <p>
          If you find our work useful, please consider citing:</p>
        <pre><code>@article{tian2025audiox,
          title={AudioX: Diffusion Transformer for Anything-to-Audio Generation},
          author={Tian, Zeyue and Jin, Yizhu and Liu, Zhaoyang and Yuan, Ruibin and Tan, Xu and Chen, Qifeng and Xue, Wei and Guo, Yike},
          journal={arXiv preprint arXiv:2503.10522},
          year={2025}
        }</code></pre>
      </div>



    
    
    
    

    






</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPT-4.1 in the API (449 pts)]]></title>
            <link>https://openai.com/index/gpt-4-1/</link>
            <guid>43683410</guid>
            <pubDate>Mon, 14 Apr 2025 17:01:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/gpt-4-1/">https://openai.com/index/gpt-4-1/</a>, See on <a href="https://news.ycombinator.com/item?id=43683410">Hacker News</a></p>
Couldn't get https://openai.com/index/gpt-4-1/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[U.S. and El Salvador Say They Won't Return Man Who Was Mistakenly Deported (224 pts)]]></title>
            <link>https://www.nytimes.com/live/2025/04/14/us/trump-news-tariffs</link>
            <guid>43683405</guid>
            <pubDate>Mon, 14 Apr 2025 17:01:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/live/2025/04/14/us/trump-news-tariffs">https://www.nytimes.com/live/2025/04/14/us/trump-news-tariffs</a>, See on <a href="https://news.ycombinator.com/item?id=43683405">Hacker News</a></p>
Couldn't get https://www.nytimes.com/live/2025/04/14/us/trump-news-tariffs: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI Is a Systemic Risk to the Tech Industry (108 pts)]]></title>
            <link>https://www.wheresyoured.at/openai-is-a-systemic-risk-to-the-tech-industry-2/</link>
            <guid>43683071</guid>
            <pubDate>Mon, 14 Apr 2025 16:28:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wheresyoured.at/openai-is-a-systemic-risk-to-the-tech-industry-2/">https://www.wheresyoured.at/openai-is-a-systemic-risk-to-the-tech-industry-2/</a>, See on <a href="https://news.ycombinator.com/item?id=43683071">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
      <p><strong><em>Before we go any further: I hate to ask you to do this, but I need your help — I'm up for this year's Webbys for the best business podcast award. I know it's a pain in the ass, but</em></strong><a href="https://vote.webbyawards.com/PublicVoting?ref=wheresyoured.at#/2025/podcasts/individual-episode/business"><strong><em> <u>can you sign up and vote for Better Offline</u></em></strong></a><strong><em>? I have never won an award in my life, so help me win this one.</em></strong></p><hr><p><strong><em>Soundtrack: </em></strong><a href="https://www.youtube.com/watch?v=L4PztrhXkXohttps%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DL4PztrhXkXo&amp;ref=wheresyoured.at"><strong><em><u>Mastodon - High Road</u></em></strong></a></p><hr><p>I wanted to start this newsletter with a pithy anecdote about chaos, both that caused by Donald Trump's tariffs and the brittle state of the generative AI bubble.</p><p>Instead, I am going to write down some questions, and make an attempt to answer them.</p><h2 id="how-much-cash-does-openai-have"><strong>How Much Cash Does OpenAI Have?</strong></h2><p>Last week, OpenAI closed "<a href="https://www.cnbc.com/2025/03/31/openai-closes-40-billion-in-funding-the-largest-private-fundraise-in-history-softbank-chatgpt.html?ref=wheresyoured.at"><u>the largest private tech funding round in history</u></a>," where it "raised"&nbsp; an astonishing "$40 billion," and the reason that I've put quotation marks around it is that OpenAI has only raised $10 billion of the $40 billion, with the rest arriving by "the end of the year."&nbsp;</p><p>The remaining $30 billion — $20 billion of which will (allegedly) be provided by SoftBank — is partially contingent on OpenAI's conversion from a non-profit to a for-profit by the end of 2025, and if it fails,<a href="https://www.cnbc.com/2025/03/31/openai-funding-could-be-cut-by-10-billion-if-for-profit-move-lags.html?ref=wheresyoured.at"> <u>SoftBank will only give OpenAI a further $20 billion</u></a>. The round also valued OpenAI at $300 billion.</p><p>To put that in context, OpenAI had revenues of $4bn in 2024. This deal <em>values OpenAI at 75 times its revenue</em>. That’s a bigger gulf than Tesla at its peak market cap — a company that was, in fact, worth more than all other legacy car manufacturers combined, despite making far less than them, and shipping a fraction of their vehicles.&nbsp;</p><p>I also want to add that, as of writing this sentence,<strong> this money is yet to arrive.</strong><a href="https://group.softbank/en/news/press/20250401?ref=wheresyoured.at"><strong> </strong><u>SoftBank's filings</u></a> say that the money will arrive mid-April — and that SoftBank would be borrowing as much as $10 billion to finance the round, with the option to syndicate part of it to other investors. For the sake of argument, I'm going to assume this money actually arrives.</p><p>Filings also suggest that "in certain circumstances" the second ($30 billion) tranche could arrive "in early 2026." This isn't great. <strong>It also seems that SoftBank's $10 billion commitment is contingent on getting a loan, "...financed through borrowings from Mizuho Bank, Ltd., among other financial institutions."</strong></p><p><a href="https://www.theverge.com/openai/640894/chatgpt-has-hit-20-million-paid-subscribers?ref=wheresyoured.at"><u>OpenAI also revealed it now has 20 million paying subscribers</u></a> and over 500 million weekly active users. If you're wondering why it doesn’t talk about <em>monthly</em> active users, it's because they'd likely be much higher than 500 million, which would<a href="https://www.wheresyoured.at/wheres-the-money/#:~:text=It%20would%20also%20suggest%20a%20conversion%20rate%20of%202.583%25%20from%20free%20to%20paid%20users%20on%20ChatGPT%20%E2%80%94%20an%20astonishingly%20bad%20number%2C%20one%20made%20worse%20by%20the%20fact%20that%20every%20single%20user%20of%20ChatGPT%2C%20regardless%20of%20whether%20they%20pay%2C%20loses%20the%20company%20money."> <u>reveal exactly how poorly OpenAI converts free ChatGPT users to paying ones</u></a>, and how few people use ChatGPT in their day-to-day lives.</p><p>The Information reported back in January that<a href="https://www.theinformation.com/articles/openai-tightens-grip-on-high-end-of-app-market-muratis-startup-gets-a-name?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>OpenAI was generating $25 million in revenue a month from its $200-a-month "Pro" subscribers</u></a> (<a href="https://techcrunch.com/2025/01/05/openai-is-losing-money-on-its-pricey-chatgpt-pro-plan-ceo-sam-altman-says/?ref=wheresyoured.at"><u>it still loses money on every one of them</u></a>), suggesting around 125,000 ChatGPT Pro subscribers. Assuming the other 19,875,000 users are paying $20 a month, that puts its revenue at about $423 million a month, or about $5 billion a year, from ChatGPT subscriptions.&nbsp;</p><p>This is what reporters mean when they say "annualized revenue" by the way — it's literally the monthly revenue multiplied by 12.</p><p><a href="https://www.bloomberg.com/news/articles/2025-03-26/openai-expects-revenue-will-triple-to-12-7-billion-this-year?ref=wheresyoured.at"><u>Bloomberg reported recently that OpenAI expects its 2025 revenue to "triple" to $12.7 billion this year</u></a>.<a href="https://www.wheresyoured.at/oai-business/#:~:text=Licensing%20Access%20To%20Models%20And%20Services%20%E2%80%94%2027%25%20of%20revenue%20(approximately%20%241%20billion)."> <u>Assuming a similar split of revenue to 2024</u></a>, this would require OpenAI to nearly double its annualized subscription revenue from Q1 2025 (from $5 billion to around $9.27 billion) <strong>and nearly quadruple API revenue </strong>(from 2024's revenue of $1 billion, which includes Microsoft's 20% payment for access to OpenAI's models, to $3.43 billion).</p><p>While these are messy numbers, it's unclear how OpenAI intends to pull this off.</p><p>The Information reported in February<a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>that it planned to do so by making $3 billion a year selling "agents,"</u></a> with ChatGPT subscriptions ($7.9 billion) and API calls ($1.8 billion) making up the rest. This, of course, is utter bollocks.<a href="https://www.wheresyoured.at/wheres-the-money/#:~:text=Counterpoint%3A%20OpenAI%20has%20a%20new%20series%20of%20products%20that%20could%20open%20up%20new%20revenue%20streams%20such%20as%20Operator%2C%20its%20%22agent%22%20product%2C%20and%20%22Deep%20Research%2C%22%20their%20research%20product."> <u>OpenAI's "agents" can't do even the simplest tasks,</u></a> and<a href="https://www.cnbc.com/2025/02/03/softbank-commits-to-joint-venture-with-openai.html?ref=wheresyoured.at"> <u>three billion dollars of the $12.7 billion figure appears to be a commitment made by SoftBank to purchase</u></a> OpenAI's tech for its various subsidiaries and business units.&nbsp;</p><p>Let's say out the numbers precisely:</p><ul><li><strong>Incoming monthly revenue: </strong>roughly $425 million, give or take.</li><li><strong>Theoretical revenue from Softbank:</strong> $250 million a month. However, I can find no proof that SoftBank has begun to make these payments or, indeed, that it intends to make them.</li><li><strong>Liquidity:</strong><ul><li>$10 billion <strong>that it is yet to receive</strong> from SoftBank and a syndicate of investors including Microsoft, <strong>potentially.</strong></li><li><a href="https://openai.com/index/new-credit-facility-enhances-financial-flexibility/?ref=wheresyoured.at"><u>An indeterminate amount of remaining capital on the $4 billion credit facility provided by multiple banks</u></a> back in October 2024, raised alongside a funding round that valued the company at $157 billion.<ul><li>As a note, this announcement stated that OpenAI had "access to over $10 billion in liquidity."</li></ul></li><li><strong>Based on reports, OpenAI will not have access to the rest of its $40bn funding until "the end of the year," and it's unclear what part of the end of the year.</strong></li></ul></li></ul><p>We can assume, in this case, that OpenAI likely has, in the best case scenario, <strong>access to roughly $16 billion in liquidity at any given time. </strong>It's reasonable to believe that OpenAI will raise more <em>debt</em> this year, and I'd estimate it does so to the tune of around $5 billion or $6 billion. Without it, I am not sure what it’s going to do.</p><p><strong>As a reminder: OpenAI loses money on every single user.</strong></p><h2 id="what-are-openais-obligations"><strong>What Are OpenAI's Obligations?</strong></h2><p>When I wrote "<a href="https://www.wheresyoured.at/to-serve-altman/"><u>How Does OpenAI Survive</u></a>?" and "<a href="https://www.wheresyoured.at/oai-business/"><u>OpenAI Is A Bad Business</u></a>," I used reported information to explain how this company was, at its core, unsustainable.</p><p>Let's refresh our memories.</p><h3 id="compute-costs-at-least-13-billion-in-2025-with-microsoft-alone-and-as-much-as-594-million-to-coreweave"><strong>Compute Costs: at least $13 billion in 2025 <em>with Microsoft alone</em>, and as much as $594 million to CoreWeave.</strong></h3><ul><li><strong>In 2024,</strong><a href="https://www.wheresyoured.at/wheres-the-money/#:~:text=As%20a%20note,run%20this%20company."><strong> <u>OpenAI spent $9 billion to lose $5 billion</u></strong></a><strong>.</strong><ul><li>This figure includes the $3 billion spent on training new models and $2 billion on running them.</li></ul></li></ul><p>It seems, from even a cursory glance, that OpenAI's costs are increasing dramatically. The Information reported earlier in the year that<a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at#:~:text=more%20than%20doubling%20from%20%2413%20billion%20this%20year"> <u>OpenAI projects to spend <strong>$13 billion on compute with Microsoft alone in 2025</strong></u></a><strong>,</strong><a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at#:~:text=more%20than%20doubling%20from%20%2413%20billion%20this%20year"><strong> </strong><u>nearly <em>tripling</em> what it spent in total on compute in 2024 ($5 billion)</u></a>.</p><p>This suggests that OpenAI's costs are skyrocketing, and that was before<a href="https://techcrunch.com/2025/03/31/openais-new-image-generator-is-now-available-to-all-users/?ref=wheresyoured.at"> <u>the launch of its new image generator</u></a> which led to multiple complaints from Altman<a href="https://x.com/sama/status/1905296867145154688?ref=wheresyoured.at"> <u>about a lack of available GPUs</u></a>,<a href="https://x.com/sama/status/1907098207467032632?ref=wheresyoured.at"> <u>leading to OpenAI's CEO saying to expect "stuff to break" and delays in new products</u></a>. Nevertheless, even if we assume OpenAI factored in the compute increases into its projections, <strong>it still expects to pay Microsoft $13 billion for compute this year.</strong></p><p>This number, however, doesn't include the $12.9 billion five-year-long compute deal signed with CoreWeave,<a href="https://www.semafor.com/article/03/20/2025/microsoft-chose-not-to-exercise-12-billion-coreweave-option?ref=wheresyoured.at"> <u>a deal that was a result of Microsoft declining to pick up the option to buy said compute itself</u></a>.<a href="https://www.theinformation.com/articles/coreweave-faces-reality-check-bullish-growth-forecasts?rc=kz8jh3&amp;ref=wheresyoured.at#:~:text=The%20recent%20analyst%20forecasts%20took%20into%20account%20its%20largest%20ever%20single%20contract%2C%20a%20%2411.9%20billion%20deal%20with%20OpenAI%20that%20CoreWeave%20said%20would%20begin%20in%20October.%20That%20means%20it%20will%20only%20be%20able%20to%20book%20those%20revenues%20toward%20the%20tail%20end%20of%20this%20year."> <u>Payments for this deal, according to The Information, start in October 2025</u></a>, and assuming that it's evenly paid (the terms of these contracts are generally secret, even in the case of public companies), this would <strong>still amount to roughly $2.38 billion a year.</strong></p><p>However, for the sake of argument, let's consider the payments are around $198 million a month, though there are scenarios — such as, say,<a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Number%20Four%20%2D%20CoreWeave%20Is%20Using%20A%20Suspicious%20and%20Unproven%20Partner%20To%20Build%20its%20Entire%20Infrastructure"> <u>CoreWeave's buildout partner not being able to build the data centers</u></a> or<a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Number%20Three%3A%20CoreWeave%20Does%20Not%20Have%20Access%20To%20The%20Capital%20Necessary%20To%20Meet%20Its%20Obligations"> <u>CoreWeave not having the money to pay to build them</u></a> — where OpenAI might pay less.</p><p>To be clear, and I’ll explain in greater detail later, this wouldn’t be a good thing, either. While it would be off the hook for some of its payments, it would also be without the compute that’s essential for it to continue growing, serving existing customers, and building new AI models. Cash and compute are <em>both</em> essential to OpenAI’s survival.&nbsp;&nbsp;</p><h3 id="stargate-1-billion"><strong>Stargate: $1 Billion+</strong></h3><p><a href="https://www.reuters.com/technology/openai-softbank-each-commit-19-bln-stargate-data-center-venture-information-2025-01-23/?ref=wheresyoured.at"><u>OpenAI has dedicated somewhere in the region of $19 billion to the Stargate data center project</u></a>, along with another $19 billion provided by SoftBank and an indeterminate amount by other providers.</p><p><a href="https://www.datacenterdynamics.com/en/news/openai-and-oracle-to-deploy-64000-gb200-gpus-at-stargate-abilene-data-center-by-2026-report/?ref=wheresyoured.at"><u>Based on reporting from Bloomberg</u></a>, OpenAI plans to have 64,000 Blackwell GPUs running "by the end of 2026," or roughly $3.84 billion worth of them. I should also note that Bloomberg said that 16,000 of these chips would be operational by Summer 2025, though it's unclear if that will actually happen.</p><p>Though it's unclear who actually pays for what parts of Stargate, it's safe to assume that OpenAI will have to, <strong>at the very least, put a billion dollars into a project that is meant to be up and running by the end of 2026,</strong> if not more.</p><p>As of now, Stargate has exactly one data center under development in Abilene, Texas, and as above, it's unclear how that's going, though <a href="https://www.theinformation.com/articles/pressure-rises-oracle-finish-openai-data-center?rc=kz8jh3&amp;ref=wheresyoured.at"><u>a recent piece from The Information reported</u></a> that it was currently "empty and incomplete," and that if it stays that way, "OpenAI could walk away from the deal, which would cost Oracle billions of dollars." Though the article takes pains to assure the reader that won't be likely, even an <em>inkling</em> of such a possibility is a bad sign.</p><p><a href="https://www.businessinsider.com/texas-stargate-data-center-build-cost-2025-1?ref=wheresyoured.at"><u>Business Insider's reporting on the site in Abilene calls it a</u></a> "$3.4 billion data center development" (<a href="https://crusoe.ai/newsroom/crusoe-blue-owl-capital-primary-digital-joint-venture/?ref=wheresyoured.at"><u>as did the press release from site developer Crusoe</u></a>), though these numbers don't include GPUs, hardware, or the labor necessary to run them. Right now, Crusoe is (according to Business Insider) building "six new data centers, each with a minimum square footage...[which will] join the two it is already constructing for Oracle." Oracle has signed, according to The Information, a 15-year-long lease with Crusoe for its data centers, all of which will be rented to OpenAI.</p><p>In any case, OpenAI’s exposure could be much, much higher than the $1bn posited at the start of this section (and I’ll explain in greater depth how I reached that figure at the bottom of this section). If OpenAI has to contribute significantly to the costs associated with building Stargate, it could be on the hook for <em>billions</em>.<a href="https://www.datacenterdynamics.com/en/news/crusoe-begins-construction-on-second-phase-of-abilene-texas-data-center-campus-will-add-six-buildings/?ref=wheresyoured.at">&nbsp;</a></p><p><a href="https://www.datacenterdynamics.com/en/news/crusoe-begins-construction-on-second-phase-of-abilene-texas-data-center-campus-will-add-six-buildings/?ref=wheresyoured.at"><u>Data Center Dynamics reports that the Abilene site is meant to have 200MW of compute capacity in the first half of 2025, and then as much as 1.2GW by "mid-2026."</u></a><u> To give you a sense of total costs for this project, </u><a href="https://www.latitudemedia.com/news/catalyst-explaining-the-watt-bit-spread/?ref=wheresyoured.at#:~:text=But%20I%20think%20that,the%20CapEx%20deployment%20opportunity."><u>former Microsoft VP of Energy Brian Janous said in January</u></a> that it costs about $25 million a megawatt (or $25 billion a gigawatt), meaning that the initial capital expenditures for Stargate to spin up its first 200MW data center will be around $5 billion, spiraling to $30 billion for the entire project.&nbsp;</p><p>Or perhaps even more. The Information has reported that the site, which could be "...potentially one of the world's biggest AI data centers," could cost "$50 billion to $100 billion in the coming years."&nbsp;</p><p><strong>Assuming we stick with the lower end of the cost estimates, it’s likely that OpenAI is on the hook for over $5 billion for the Abilene site based on the $19 billion it has agreed to contribute to the <em>entire </em>Stargate project, the (often disagreeing) cost projections of the facility), and the contributions of other partners.&nbsp;</strong></p><p>This expenditure won’t come all at once, and will be spread across several years. Still, assuming even the rosiest numbers, it's hard to see how OpenAI doesn't have to pony up $1 billion in 2025, with similar annual payments going forward until its completion, and that is likely because the development of this site is going to be heavily delayed by both tariffs, labor shortages, and Oracle's (as reported by The Information) trust in "scrappy but unproven startups to develop the project."</p><h3 id="other-costs-at-least-35-billion"><strong>Other costs: at least $3.5 billion</strong></h3><p><a href="https://www.theinformation.com/articles/openai-projections-imply-losses-tripling-to-14-billion-in-2026?rc=kz8jh3&amp;ref=wheresyoured.at"><u>Based on reporting from The Information last year</u></a>, OpenAI will spend <em>at least $2.5 billion</em> across salaries, "data" (referring to buying data from other companies), hosting and other cost of sales, and sales and marketing, and then another billion on what infrastructure OpenAI owns.</p><p>I expect the latter cost to balloon with OpenAI's investment in physical infrastructure for Stargate.</p><figure><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdTLWNPUZ-Y3kviQD7Sn0ojL9bEazTw2r7G-JOiNtwC8ac3-d_DsBNExz6VYKwjyo6C2Tp1K6h1-4KeAT0bY89YsF7HFhQHZI7l-ok8rNK1AuoeynifiUxsvRPbVSQUYUPxs0l1?key=MFOPt-R0auIdYEYVFbbAfdWf" alt="" loading="lazy" width="624" height="564"></figure><h2 id="how-does-openai-meet-its-obligations"><strong>How Does OpenAI Meet Its Obligations?</strong></h2><h3 id="openai-could-spend-28-billion-or-more-in-2025-and-lose-over-14-billion-while-having-an-absolute-maximum-of-20-billion-in-liquidity"><strong>OpenAI Could Spend $28 Billion Or More In 2025, and Lose over $14 Billion while having an absolute maximum of $20 billion in liquidity</strong></h3><p><a href="https://www.wheresyoured.at/wheres-the-money/#:~:text=The%20New%20York%20Times%20reports%20that%20OpenAI%20projects%20it%27ll%20make%20%2411.6%20billion%20in%202025%2C%20and%20assuming%20that%20OpenAI%20burns%20at%20the%20same%20rate%20it%20did%20in%202024%20%E2%80%94%20spending%20%242.25%20to%20make%20%241"><u>Based on previous estimates, OpenAI spends about $2.25 to make $1.</u></a> At that rate, it's likely that OpenAI's costs <em>in its rosiest revenue projections of $12.7 billion </em>are at least $28 billion — <strong>meaning that it’s on course to burn at least $14 billion in 2025.</strong></p><p>Assuming that OpenAI has <strong>all of its liquidity from last year </strong>(it doesn't, but for sake of argument, let’s pretend it still has the full $10 billion), <strong>as well as the $10 billion from SoftBank</strong>, it is <em>still</em> unclear how it meets its obligations.</p><p>While OpenAI likely has preferential payment structures with all vendors, such as its discounted rates with Microsoft for Azure cloud services, it will still have to pay them, especially in the case of costs related to Stargate, many of which will be up-front costs. In the event that its costs are as severe as reporting suggests, it’s likely the company will find itself needing to raise more capital — whether through equity (or the weird sort-of equity that it issues) or through debt.&nbsp;</p><p>And yes, while OpenAI has some revenue, it comes at a terrible cost, and anything that isn’t committed to paying for salaries and construction fees will likely be immediately funnelled directly into funding the obscene costs behind inference and training models like GPT 4.5 — a "<a href="https://www.wheresyoured.at/power-cut/#:~:text=The%20bad%20news%20was%20that%2C%20and%20I%20quote%2C%20GPT%204.5%20is%20%E2%80%9C...a%20giant%2C%20expensive%20model%2C%E2%80%9D"><u>giant expensive model</u></a>" to run that<a href="https://help.openai.com/en/articles/10658365-gpt-4-5-in-chatgpt?ref=wheresyoured.at"> <u>the company has nevertheless pushed to every user</u></a>.</p><p>Worse still, OpenAI has, while delaying its next model (GPT-5),<a href="https://techcrunch.com/2025/04/04/openai-says-itll-release-o3-after-all-delays-gpt-5/?ref=wheresyoured.at"> <u>promised to launch its o3 reasoning model after saying it wouldn't do so</u></a>, which is strange, because it turns out that o3 is actually <em>way</em> more expensive to run than people thought.&nbsp;</p><p>Reasoning models are almost always more expensive to operate, as they involve the model “checking” its work, which, in turn, requires more calculations and more computation. Still, o3 is ludicrously expensive even for this category, with the Arc Prize Foundation (a non-profit that makes the ARC-AGI test for benchmarking models) estimating that it will cost<a href="https://techcrunch.com/2025/04/02/openais-o3-model-might-be-costlier-to-run-than-originally-estimated/?ref=wheresyoured.at"> <em><u>$30,000 a task.</u></em></a></p><h3 id="softbank-has-to-borrow-money-to-meet-its-openai-and-stargate-obligations-leading-to-softbanks-financial-condition-likely-deteriorating"><strong>SoftBank Has To Borrow Money To Meet Its OpenAI and Stargate Obligations, leading to SoftBank's  "...financial condition likely deteriorating."</strong></h3><p>As of right now, SoftBank has committed to the following:</p><ul><li>At least $30 billion ($7.5 of the initial $10 billion, and $22.5 billion of the remaining $30 billion) in funding as part of OpenAI's recent $40bn funding round.<ul><li>This assumes that SoftBank finds others to invest with it. <a href="https://group.softbank/en/news/press/20250401?ref=wheresyoured.at"><u>SoftBank's filings surrounding OpenAI's funding</u></a> also suggest that SoftBank is, ultimately, on the hook for the entire $40 billion, but <em>can</em> syndicate with other investors.<a href="https://www.cnbc.com/2025/03/31/openai-closes-40-billion-in-funding-the-largest-private-fundraise-in-history-softbank-chatgpt.html?ref=wheresyoured.at"> <u>Reporting suggests that syndication will happen with Coatue, Microsoft and other investors</u></a>.</li><li>If OpenAI fails to convert to a for-profit, that $40bn figure is slashed to $30, although, again, SoftBank’s share of the final sum is contingent upon whether it finds other investors to join the deal.&nbsp;</li></ul></li><li><a href="https://www.cnbc.com/2025/02/03/softbank-commits-to-joint-venture-with-openai.html?ref=wheresyoured.at"><u>$3 billion in spend on OpenAI "tech."</u></a></li><li>$19 billion for the Stargate data center project,<a href="https://www.theinformation.com/articles/softbanks-son-goes-on-a-new-borrowing-binge-to-fund-ai?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>which SoftBank takes financial responsibility for</u></a>.<ul><li><strong>Total: $52 billion or $62 billion, with at least $20 billion due by the end of 2025.</strong></li></ul></li></ul><p>SoftBank's exposure to OpenAI is materially harming the company.<a href="https://www.wsj.com/business/deals/openai-softbank-investment-debt-51b4a130?ref=wheresyoured.at"> <u>To quote the Wall Street Journal:</u></a></p><blockquote>Ratings agency S&amp;P Global said last week that SoftBank’s “financial condition will likely deteriorate” as a result of the OpenAI investment and that its plans to add debt could lead the agency to consider downgrading SoftBank’s ratings.&nbsp;</blockquote><p>While one might argue that SoftBank has a good amount of cash, the Journal also adds that it’s&nbsp; somewhat hamstrung in its use as a result of CEO Masayoshi Son's reckless gambles:</p><blockquote>SoftBank had a decent buffer of $31 billion of cash as of Dec. 31, but the company has also pledged to hold much of that in reserve to quell worried investors. SoftBank has committed not to borrow more than 25% of the value of all of its holdings, which means it will likely need to sell some of the other parts of its empire to pay for the rest of the OpenAI deal.</blockquote><p>Worse still, it seems, as mentioned before, that SoftBank will be financing the entirety of the first $10 billion — or $7.5 billion, assuming it finds investors to syndicate the first tranche, and they follow through right until the moment Masayoshi Son hits ‘send’ on the wire transfer .</p><p>As a result, SoftBank will likely have to start selling off parts of its valuable holdings in companies like Alibaba and ARM, or, worse still,<a href="https://www.wheresyoured.at/power-cut/#:~:text=On%20the%20subject%20of%20Softbank%E2%80%99s%20holdings"> <u>parts of its ailing investments from its Vision Fund</u></a>, resulting in a material loss on its underwater deals.</p><p>This is an untenable strategy, and I'll explain why.</p><h3 id="openai-needs-at-least-40-billion-a-year-to-survive-and-its-costs-are-increasing"><strong>OpenAI Needs At Least $40 billion A Year To Survive, And Its Costs Are Increasing</strong></h3><p>While we do not have much transparency into OpenAI's actual day-to-day finances, we can make the educated guess that its costs are <em>increasing</em> based on the amount of capital it’s raising. If OpenAI’s costs were flat, or only mildly increasing, we’d expect to see raises roughly the same size as previous ones. Its $40bn raise is nearly <em>six</em> times the previous funding round.&nbsp;</p><p>Admittedly, multiples like that aren’t particularly unusual. If a company raises $300,000 in a pre-seed round, and $3m in a Series A round, that’s a tenfold increase. But we’re not talking about hundreds of thousands of dollars, or even millions of dollars. We’re talking about <em>billions</em> of dollars. If OpenAI’s funding round with Softbank goes as planned, it’ll raise the equivalent of the entire GDP of Estonia — a fairly wealthy country itself, and one that’s also a member of Nato and the European Union. That alone should give you a sense of the truly insane scale of this.&nbsp;</p><p>Insane, sure, but undoubtedly necessary. <a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at#:~:text=this%20year%20to-,%2428%20billion%20in%202028,-.%20The%20spending%20forecast"><u>Per The Information</u></a>, OpenAI expects to spend as much as $28 billion in compute on Microsoft's Azure cloud in 2028. Over a third of OpenAI's revenue, per the same article, will come from SoftBank's (alleged) spend.It's reasonable to believe that OpenAI will, as a result, need to raise in excess of $40 billion in funding a year, though it's reasonable to believe that it will need to raise more along the lines of $50 billion or more a year until it reaches profitability. This is due to both its growing cost of business, as well as its various infrastructure commitments, both in terms of Stargate, as well as with third-party suppliers like CoreWeave and Microsoft.&nbsp;</p><blockquote><strong>Counterpoint: OpenAI could reduce costs:</strong> While this is <u>theoretically</u> possible, there is no proof that this is taking place.<a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>The Information claims that</u></a> "...OpenAI would turn profitable by the end of the decade after the buildout of Stargate," but there is no suggestion as to how it might do so, or how building more data centers would somehow reduce its costs.This is especially questionable when you realize that<a href="https://www.wheresyoured.at/wheres-the-money/#:~:text=OpenAI%20pays%20just%20over%2025%25%20of%20the%20cost%20of%20Azure%E2%80%99s%20GPU%20compute%20as%20part%20of%20its%20deal%20with%20Microsoft%20%E2%80%94%20around%20%241.30%2Dper%2DGPU%2Dper%2Dhour%20versus%20the%20regular%20Azure%20cost%20of%20%243.40%20to%20%244."> <u>Microsoft is already providing discounted pricing on Azure compute</u></a>. We don’t know if these discounts are below Microsoft’s break-even point — which it wouldn’t, nor would any other company offer, if they didn’t have something else to incentivize it, such as equity or a profit-sharing program. Microsoft, for what it’s worth, has both of those things.&nbsp;</blockquote><p>OpenAI CEO Sam Altman's statements around costs also suggest that they're increasing. In late February,<a href="https://techcrunch.com/2025/02/27/openai-ceo-sam-altman-says-the-company-is-out-of-gpus/?ref=wheresyoured.at"> <u>Altman claimed that OpenAI was "out of GPUs</u></a>." While this suggests that there’s demand for some products — like its image-generating tech, which enjoyed a viral day in the sun in March — it also means that to meet the demand it needs to spend more. And, at the risk of repeating myself, that demand doesn’t necessarily translate into profitability.&nbsp;</p><h3 id="softbank-cannot-fund-openai-long-term-as-openais-costs-are-projected-to-be-320-billion-in-the-next-five-years"><strong>SoftBank Cannot Fund OpenAI Long-Term, as OpenAI's costs are projected to be $320 billion in the next five years</strong></h3><p>As discussed above, SoftBank has to overcome significant challenges to fund both OpenAI and Stargate, and when I say "fund," I mean <strong>fund the current state of both projects, assuming no further obligations.</strong></p><p>The Information reports that<a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>OpenAI forecasts that it will spend $28 billion on compute with Microsoft alone in 2028</u></a>. The same article also reports that OpenAI "would turn profitable by the end of the decade after the buildout of Stargate," suggesting that OpenAI's operating expenses will grow exponentially year-over-year.</p><p>These costs, per The Information, are astronomical:</p><blockquote>The reason for the expanding cash burn is simple: OpenAI is spending whatever revenue comes in on computing needs for operating its existing models and developing new models. The company expects those costs to surpass $320 billion overall between 2025 and 2030.<p>The company expects more than half of that spending through the end of the decade to fund research-intensive compute for model training and development. That spending will rise nearly sixfold from current rates to around $40 billion per year starting in 2028. OpenAI projects its spending on running AI models will surpass its training costs in 2030.</p></blockquote><p>SoftBank has had to (and will continue having to) go to remarkable lengths to fund OpenAI's current ($40 billion) round, lengths so significant that it may lead to its credit rating being further downgraded.</p><p>Even if we assume the best case scenario — OpenAI successfully converts to a for-profit entity by the end of the year, and receives the full $30 billion — it seems unlikely (if not impossible) for it to continue raising the amount of capital they need to continue operations. As I’ve argued in previous newsletters, there are only a few entities that can provide the kinds of funding that OpenAI needs. These include big tech-focused investment firms like Softbank, sovereign wealth funds (like those of Saudi Arabia and the United Emirates), and perhaps the largest tech companies.</p><p>These entities can meet OpenAI’s needs, but not all the time. It’s not realistic to expect Softbank, or Microsoft, or the Saudis, or Oracle, or whoever, to provide $40bn <em>every year</em> for the foreseeable future.&nbsp;</p><p>This is especially true for Softbank. Based on its current promise to not borrow more than 25% of its holdings, it is near-impossible that SoftBank will be able to continue funding OpenAI at this rate ($40 billion a year), and $40 billion a year may not actually be enough.</p><p>Based on<a href="https://group.softbank/en/ir/stock/sotp?ref=wheresyoured.at"> <u>its last reported equity value of holdings</u></a>, SoftBank's investments and other assets are worth around $229 billion, meaning that it can borrow just over $57bn while remaining compliant with these guidelines.</p><p>In any case, it is unclear how SoftBank can fund OpenAI, but it's far clearer that <em>nobody else is willing to.</em></p><h3 id="openai-is-running-into-capacity-issues-suggesting-material-instability-in-its-business-or-infrastructure-%E2%80%94-and-its-unclear-how-it-expands-further"><strong>OpenAI Is Running Into Capacity Issues, Suggesting Material Instability In Its Business or Infrastructure — And It's Unclear How It Expands Further</strong></h3><p>Before we go any further, it's important to note that OpenAI does not really have its own compute infrastructure. The majority of its compute is provided by Microsoft, though, as mentioned above,<a href="https://www.semafor.com/article/03/20/2025/microsoft-chose-not-to-exercise-12-billion-coreweave-option?ref=wheresyoured.at"> <u>OpenAI now has a deal with CoreWeave to take over Microsoft's future options for more capacity</u></a>.</p><p>Anyway, in the last 90 days, Sam Altman has complained about a lack of GPUs and pressure on OpenAI's servers multiple times. Forgive me for repeating stuff from above, but this is necessary.</p><ul><li><a href="https://x.com/sama/status/1895203654103351462?ref=wheresyoured.at"><u>On February 27,</u></a> he lamented how GPT 4.5 was a "giant, expensive model," adding that it was "hard to perfectly predict growth surges that lead to GPU shortages." He also added that they would be adding tens of thousands of GPUs in the following week, then hundreds of thousands of GPUs "soon."</li><li><a href="https://x.com/sama/status/1905000759336620238?ref=wheresyoured.at"><u>On March 26</u></a>, he said that "images in chatgpt are wayyyy more popular than [OpenAI] expected," delaying the free tier launch as a result.</li><li><a href="https://x.com/sama/status/1905296867145154688?ref=wheresyoured.at"><u>On March 27</u></a>, he said that OpenAI's "GPUs [were] melting," adding that it was "going to introduce some temporary rate limits" while it worked out how to "make it more efficient."</li><li><a href="https://x.com/rohanjamin/status/1905721967216599199?ref=wheresyoured.at"><u>On March 28</u></a>, he retweeted Rohan Sahai, the product team lead on OpenAI's Sora video generation model, who said "The 4o image gen demand has been absolutely incredible. Been super fun to watch the Sora feed fill up with great content...GPUs are also melting in Sora land unfortunately so you may see longer wait times / capacity issues over coming days."</li><li><a href="https://x.com/sama/status/1906210479695126886?ref=wheresyoured.at"><u>On March 30</u></a>, he said "can yall please chill on generating images this is insane our team needs sleep."</li><li><a href="https://x.com/sama/status/1907098207467032632?ref=wheresyoured.at"><u>On April 1</u></a>, he said that "we are getting things under control, but you should expect new releases from openai [sic] to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges." He also added that OpenAI is "working as fast we can to really get stuff humming; if anyone has GPU capacity in 100k chunks we can get asap please call!"</li></ul><p>These statements, in a bubble, seem either harmless or like OpenAI's growth is skyrocketing — the latter of which might indeed be true, but bodes ill for a company that burns money on every single user.</p><p>Any mention of rate limits or performance issues suggests that OpenAI is having significant capacity issues, and at this point it's unclear what further capacity it can actually expand to outside of that currently available. Remember,<a href="https://www.datacenterdynamics.com/en/news/microsoft-cancels-up-to-2gw-of-data-center-projects-says-td-cowen/?ref=wheresyoured.at"> <u>Microsoft has now pulled out of as much as 2GW of data center projects</u></a>,<a href="https://www.datacenterdynamics.com/en/news/microsoft-backs-away-from-1bn-data-center-plans-in-licking-county-ohio/?ref=wheresyoured.at"> <u>walked away from a $1 billion data center development in Ohio</u></a>, and<a href="https://www.semafor.com/article/03/20/2025/microsoft-chose-not-to-exercise-12-billion-coreweave-option?ref=wheresyoured.at"> <u>declined the option on $12bn of compute from CoreWeave that OpenAI had to pick up</u></a> — meaning that it may be pushing up against the limits of what is physically available.</p><p>While the total available capacity of GPUs at many providers like Lambda and Crusoe is unknown, we know that CoreWeave has approximately 360MWavailable,<a href="https://www.wheresyoured.at/power-cut/#:~:text=For%20some%20context,at%20this%20time."> <u>compared to Microsoft's 6.5 to 7.5 Gigawatts</u></a>, a large chunk of which already powers OpenAI.</p><p>If OpenAI is running into capacity issues, it could be one of the following:</p><ul><li>OpenAI is running up against the limit of what Microsoft has available, or is willing to offer the company.<a href="https://www.theinformation.com/articles/openai-eases-away-from-microsoft-data-centers?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>The Information reported in October 2024</u></a> that OpenAI was frustrated with Microsoft, which said it wasn’t moving fast enough to supply it with servers.</li><li>While OpenAI's capacity is sufficient, It does not have the resources available to easily handle bursts in user growth in a stable manner.</li></ul><p>Per The Information's reporting, Microsoft "promised OpenAI 300,000 NVIDIA GB200 (Blackwell) chips by the end of 2025," or roughly $18 billion of chips. It's unclear if this has changed<a href="https://techcrunch.com/2025/01/21/microsoft-is-no-longer-openais-exclusive-cloud-provider/?ref=wheresyoured.at"> <u>since Microsoft allowed OpenAI to seek other compute in late January 2025</u></a>.</p><p>I also don't believe that OpenAI has any other viable options for <em>existing compute infrastructure outside of Microsoft.</em><a href="https://www.cnbc.com/2025/03/26/the-concern-with-coreweaves-250000-nvidia-chips-ahead-of-its-ipo.html?ref=wheresyoured.at"><em> </em><u>CoreWeave's current data centers mostly feature NVIDIA's aging "Hopper" GPUs</u></a>, and while it could — and likely is! — retrofitting its current infrastructure with Blackwell chips, doing so is not easy. Blackwell chips require far more powerful cooling and server infrastructure to make them run smoothly (<a href="https://www.theinformation.com/articles/nvidias-top-customers-face-delays-from-glitchy-ai-chip-racks?rc=kz8jh3&amp;ref=wheresyoured.at"><u>a problem which led to a delay in their delivery to most customers</u></a>), and even if CoreWeave was able to replace every last Hopper GPU with Blackwell (it won't), it still wouldn't match what OpenAI needs to expand.</p><p>One might argue that it simply needs to wait for the construction of the Stargate data center, or for CoreWeave to finish the gigawatt or so of construction it’s working on.</p><p><a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Per%20its%20S,its%20current%20commitments."><u>As I've previously written</u></a>, I have serious concerns over the viability of CoreWeave ever completing its (alleged) contracted 1.3 Gigawatts of capacity.</p><p>Per my article:</p><blockquote>Per its S-1, CoreWeave has contracted for around 1.3 Gigawatts of capacity, which it expects to roll out over the coming years, and based on NextPlatform's math, <strong>CoreWeave will have to spend in excess of $39 billion to build its contracted compute. It is unclear how it will fund doing so, and it's fair to assume that CoreWeave does not currently have the capacity to cover its current commitments.</strong></blockquote><p>However, even if I were to humour the idea, it is impossible that any of this project is done by the end of the year, or even in 2026. I can find no commitments to any timescale, other than the fact that OpenAI will allegedly start paying CoreWeave in October (<a href="https://www.theinformation.com/articles/coreweave-faces-reality-check-bullish-growth-forecasts?rc=kz8jh3&amp;ref=wheresyoured.at#:~:text=The%20recent%20analyst%20forecasts%20took%20into%20account%20its%20largest%20ever%20single%20contract%2C%20a%20%2411.9%20billion%20deal%20with%20OpenAI%20that%20CoreWeave%20said%20would%20begin%20in%20October.%20That%20means%20it%20will%20only%20be%20able%20to%20book%20those%20revenues%20toward%20the%20tail%20end%20of%20this%20year."><u>per The Information</u></a>), which could very well be using current capacity.</p><p>I can also find no evidence that Crusoe, the company building the Stargate data center, has <em>any</em> compute available. Lambda,<a href="https://lambda.ai/blog/lambda-raises-320m-to-build-a-gpu-cloud-for-ai?srsltid=AfmBOopeWiVs7rtdEu5gHfszLlR2caTYw9u_avGGz6Go2D-izzkM5CBL&amp;ref=wheresyoured.at"> <u>a GPU compute company that raised $320 million earlier in this year</u></a>, and<a href="https://www.datacenterdynamics.com/en/analysis/true-believers-lambda-labs-ai-cloud-dreams/?ref=wheresyoured.at"> <u>according to Data Center Dynamics</u></a> "operates out of colocation data centers in San Francisco, California, and Allen, Texas, and is backed by more than $820 million in funds raised just this year," suggesting that it may not have their own data centers at all. Its ability to scale is entirely contingent on the availability of whatever data center providers it has relationships with.&nbsp;</p><p>In any case, this means that OpenAI's only real choice for GPUs is CoreWeave or Microsoft. While it's hard to calculate precisely,<a href="https://www.datacenterdynamics.com/en/news/openai-and-oracle-to-deploy-64000-gb200-gpus-at-stargate-abilene-data-center-by-2026-report/?ref=wheresyoured.at"> <u>OpenAI's best case scenario is that 16,000 GPUs come online in the summer of 2025</u></a> as part of the Stargate data center project.</p><p>That's a drop in the bucket compared to the 300,000 Blackwell GPUs that Microsoft had previously promised.</p><h3 id="any-capacity-or-expansion-issues-threaten-to-kneecap-openai"><strong>Any capacity or expansion issues threaten to kneecap OpenAI</strong></h3><p>OpenAI is, regardless of how you or I may feel about generative AI, one of the fastest-growing companies of all time. It currently has, according to its own statements, 500 million weekly active users. Putting aside that each user is unprofitable, such remarkable growth — especially as it's partially a result of its extremely resource-intensive image generator — is also a strain on its infrastructure.</p><p>The vast majority of OpenAI's users are free customers using ChatGPT, with only around 20 million paying subscribers, and the vast majority on the cheapest $20 plan. OpenAI's services — even in the case of image generation — are relatively commoditized, meaning that users can, if they really care, go and use any number of other different Large Language Model services. They can switch to Bing Image Creator, or Grok, or Stable Diffusion, or whatever.</p><p>Free users are also a burden on the company — especially with such a piss-poor conversion rate — losing it money with each prompt (which is also the case with paying customers), and the remarkable popularity of its image generation service only threatens to bring more burdensome one-off customers that will generate a few abominable Studio Ghibli pictures and then never return.</p><p>If OpenAI's growth continues at this rate, it will run into capacity issues, and it does not have much room to expand. While we do not know how much capacity it’s taking up with Microsoft, or indeed whether Microsoft is approaching capacity or otherwise limiting how much of it OpenAI can take, we do know that OpenAI has seen reason to beg for access to more GPUs.</p><p>In simpler terms, even if OpenAI wasn’t running out of money, even if OpenAI wasn’t horrifyingly unprofitable, it also may not have enough GPUs to continue providing its services in a reliable manner.</p><p>If that's the case, there really isn't much that can be done to fix it other than:</p><ul><li>Significantly limiting free users' activity on the platform, which is OpenAI's primary mechanism for revenue growth and customer acquisition.</li><li>Limiting activity or changing the economics behind its paid product, to quote Sam Altman, "<a href="https://x.com/sama/status/1889679681047482730?ref=wheresyoured.at"><u>find[ing] some way to let people to pay for compute they want to use more dynamically.</u></a>"<ul><li><a href="https://x.com/sama/status/1897036361506689206?ref=wheresyoured.at"><u>On March 4th</u></a>, Altman solicited feedback on "...an idea for paid plans: your $20 plus subscription converts to credits you can use across features like deep research, o1, gpt-4.5, sora, etc...no fixed limits per feature and you choose what you want; if you run out of credits you can buy more."</li><li><a href="https://x.com/sama/status/1876104315296968813?ref=wheresyoured.at"><u>On January 5th</u></a>, Sam Altman revealed that OpenAI is currently losing money on every paid subscription, including its $200-a-month "pro" subscription.</li><li><a href="https://www.theinformation.com/articles/openai-plots-charging-20-000-a-month-for-phd-level-agents?rc=kz8jh3&amp;ref=wheresyoured.at#:~:text=OpenAI%20CEO%20Sam,200%20a%20month.%E2%80%9D"><u>Buried in an article from The Information from March 5</u></a> is a comment that suggests it’s considering measures like changing its pricing model, with "...Sam Altman reportedly [telling] developers in London [in February] that OpenAI is primed to charge 20% or 30% of Pro customers a higher price because of how many research queries they’re doing, but he suggested an “a la carte” or pay-as-you-go approach. When it comes to agents, though, “we have to charge much more than $200 a month.”</li></ul></li></ul><p>The problem is that these measures, even if they succeed in generating more money for the company, <strong>also need to reduce the burden on OpenAI's available infrastructure.</strong></p><p><a href="https://www.wheresyoured.at/power-cut/#:~:text=Data%20center%20buildouts,a%20year%20ago."><u>Remember: data centers can take three to six years to build</u></a>, and even with the Stargate's accelerated (and I'd argue unrealistic) timelines, OpenAI isn't even unlocking a tenth of Microsoft's promised compute (16,000 GPUs online this year versus the 300,000 GPUs promised by Microsoft).</p><h3 id="what-might-capacity-issues-look-like-and-what-are-the-consequences"><strong>What Might Capacity Issues Look Like? And What Are The Consequences?</strong></h3><p>Though downtime might be an obvious choice, capacity issues at OpenAI will likely manifest in hard limits on what free users can do, some of which I've documented above. Nevertheless, I believe the real pale horses of capacity issues come from <strong>arbitrary limits on any given user group,</strong> meaning both free and paid users. Sudden limits on what a user can do — a reduction in the number of generations of images of videos for paid users, any introduction of "peak hours," or any increases in prices are a sign that OpenAI is running out of GPUs, which it has already publicly said is happening.</p><p>However, the really obvious one would be <em>service degradation</em> — delays in generations of any kind,<a href="https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/http-500-internal-server-error.html?ref=wheresyoured.at#:~:text=An%20HTTP%20500%20status%20code,it%20from%20fulfilling%20the%20request."> <u>500 status code errors</u></a>, or ChatGPT failing to fully produce an answer. OpenAI has, up until this point, had fairly impressive uptime. Still, if it is running up against a wall, this streak will end.</p><p>The consequences depend on how often these issues occur, and to whom they occur. If free users face service degradation, they will bounce off the product, as their use is likely far more fleeting than a paid user, which will begin to erode OpenAI's growth. Ironically, rapid (and especially unprecedented) growth in one of OpenAI’s competitors, like xAI or Anthropic, could also represent a pale horse for OpenAI.&nbsp;</p><p>If <em>paid</em> users face service degradation, it's likely this will cause the most harm to the company, as while paid users still lose OpenAI money in the end, <em>it at least receives some money in exchange.</em></p><p>OpenAI has effectively one choice here: getting more GPUs from Microsoft, and its future depends heavily both on its generosity <em>and</em> there being enough of them at a time when Microsoft<a href="https://www.wheresyoured.at/power-cut/"> <u>has pulled back</u></a><a href="https://sherwood.news/tech/microsoft-cancels-2-gigawatts-worth-of-data-centers-analysts-say/?ref=wheresyoured.at"> <u>from two gigawatts of data centers</u></a><a href="https://www.reuters.com/technology/microsoft-pulls-back-more-data-center-leases-us-europe-analysts-say-2025-03-26/?ref=wheresyoured.at"> <em><u>specifically because of it moving away from providing compute for OpenAI</u></em></a><em>.</em></p><p>Admittedly, OpenAI has previously spent more on training models than inference (actually running them) and the company might be able to smooth downtime issues by shifting capacity. This would, of course, have a knock-on effect on its ability to continue developing new models, and the company is already losing ground, particularly when it comes to Chinese rivals like DeepSeek.</p><h3 id="openai-must-convert-to-a-for-profit-entity-by-the-end-of-2025-or-it-loses-10-billion-in-funding-and-doing-so-may-be-impossible"><strong>OpenAI Must Convert To A For-Profit Entity By The End of 2025 Or It Loses $10 Billion In Funding, And Doing So May Be Impossible</strong></h3><p>As part of its deal with SoftBank, OpenAI must convert its bizarre non-profit structure into a for-profit entity by December 2025, or it’ll lose $10 billion from its promised funding.&nbsp;</p><p>Furthermore, in the event that OpenAI fails to convert to a for-profit by October 2026,<a href="https://www.wsj.com/tech/ai/open-ai-division-for-profit-da26c24b?st=yvhGAx&amp;ref=wheresyoured.at"> <u>investors in its previous $6.6 billion round can claw back their investment</u></a>, with it converting into a loan with an attached interest rate. Naturally, this represents a nightmare scenario for the company, as it’ll increase both its costs and its outgoings.</p><p>This is a complex situation that almost warrants its own newsletter, but the long and short of it is that OpenAI would have to effectively dissolve itself, <a href="https://www.upcounsel.com/converting-non-profit-to-for-profit?ref=wheresyoured.at#:~:text=Converting%20a%20nonprofit%20to%20a,a%20new%20for%2Dprofit%20entity."><u>start the process of forming an entirely new entity</u></a>, and distribute its assets to other nonprofits (or sell/license them to the for-profit company at fair market rates). It would require valuing OpenAI's assets, which in and of itself would be a difficult task, as well as getting past the necessary state regulators, the IRS, state revenue agencies, and<a href="https://www.inc.com/reuters/legal-battle-between-musk-and-openai-heads-to-trial-in-2026/91172454?ref=wheresyoured.at"> <u>the upcoming trial with Elon Musk only adds further problems</u></a>.</p><p>I’ve simplified things here, and that’s because (as I said) this stuff is complex. Suffice to say, this isn’t as simple as liquidating a company and starting afresh, or submitting a couple of legal filings. It’s a long, fraught process and one that will be — and has been — subject to legal challenges, both from OpenAI’s business rivals, as well as from civil society organizations in California.</p><p>Based on discussions with experts in the field and my own research, I simply do not know how OpenAI pulls this off <em>by October 2026,</em> let alone by the end of the year.</p><h2 id="openai-has-become-a-systemic-risk-to-the-tech-industry"><strong>OpenAI Has Become A Systemic Risk To The Tech Industry</strong></h2><p>OpenAI has become a load-bearing company for the tech industry, both as a narrative —<a href="https://www.wheresyoured.at/wheres-the-money/"> <u>as previously discussed, ChatGPT is the only Large Language Model company with any meaningful userbase</u></a> — and as a financial entity.&nbsp;</p><p>Its ability to meet its obligations and its future expansion plans are critical to the future health — or, in some cases, survival — of multiple large companies, and that's before the after-effects that will affect its customers as a result of any financial collapse.&nbsp;</p><p>The parallels to the 2007-2008 financial crisis are startling. Lehman Brothers wasn’t the largest investment bank in the world (although it was certainly big), just like OpenAI isn’t the largest tech company (though, again, it’s certainly large in terms of market cap and expenditure). Lehman Brothers’ collapse sparked a contagion that would later spread throughout the global financial services industry, and consequently, the global economy.&nbsp;</p><p>I can see OpenAI’s failure having a similar systemic effect. While there is a vast difference between OpenAI’s involvement in people’s lives compared to the millions of subprime loans issued to real people, the stock market’s dependence on the value of the Magnificent 7 stocks (Apple, Microsoft, Amazon, Alphabet, NVIDIA and Tesla), and in turn the Magnificent 7’s reliance on the stability of the AI boom narrative still threatens material harm to millions of people, and that’s before the ensuing layoffs.&nbsp;</p><p>And as I’ve said before, this entire narrative is based off of OpenAI’s success, because OpenAI <em>is</em> the generative AI industry.&nbsp;</p><p>I want to lay out the direct result of any kind of financial crisis at OpenAI, because I don't think anybody is taking this seriously.</p><h3 id="oracle-will-lose-at-least-1-billion-if-openai-doesnt-fulfil-its-obligations"><strong>Oracle Will Lose At Least $1 Billion If OpenAI Doesn't Fulfil Its Obligations</strong></h3><p><a href="https://www.theinformation.com/articles/pressure-rises-oracle-finish-openai-data-center?rc=kz8jh3&amp;ref=wheresyoured.at"><u>Per The Information</u></a>, Oracle, which has taken responsibility for organizing the construction of the Stargate data centers with unproven data center builder Crusoe, "...may need to raise more capital to fund its data center ambitions."</p><p>Oracle has signed a 15-year lease with Crusoe, and, to quote The Information, "...is on the hook for $1 billion in payments to that firm."</p><p>To further quote The Information:</p><blockquote>...while that’s a standard deal length, the unprecedented size of the facility Oracle is building for just one customer makes it riskier than a standard cloud data center used by lots of interchangeable customers with more predictable needs, according to half a dozen people familiar with these types of deals.</blockquote><p>In simpler terms, Oracle is building a giant data center for one customer — OpenAI — and has taken on the financial burden associated with it. If OpenAI fails to expand, or lacks the capital to actually pay for its share of the Stargate project, Oracle is on the hook for at least a billion dollars, and, based on The Information's reporting, is also on the hook to buy the GPUs for the site.</p><blockquote>Even before the Stargate announcement, Oracle and OpenAI had agreed to expand their Abilene deal from two to eight data center buildings, which can hold 400,000 Nvidia Blackwell GPUs, adding tens of billions of dollars to the total cost of the facility.</blockquote><p>In reality, this development will likely cost tens of billions of dollars, $19 billion of which is due from OpenAI, which does not have the money until it receives its second tranche of funding in December 2025, which is contingent partially on its ability to convert into a for-profit entity, which, as mentioned, is a difficult and unlikely proposition.</p><p>It's unclear how many of the Blackwell GPUs that Oracle has had to purchase in advance, but in the event of any kind of financial collapse at OpenAI, Oracle would likely <strong>take a loss of at least a billion dollars, if not several billion dollars.</strong></p><h3 id="coreweaves-expansion-is-likely-driven-entirely-by-openai-and-it-cannot-survive-without-openai-fulfilling-its-obligations-and-may-not-anyway"><strong>CoreWeave's Expansion Is Likely Driven Entirely By OpenAI, And It Cannot Survive Without OpenAI Fulfilling Its Obligations (And May Not Anyway)</strong></h3><p><a href="https://www.wheresyoured.at/core-incompetency/"><u>I have written a lot about publicly-traded AI compute firm CoreWeave</u></a>, and it would be my greatest pleasure to never mention it again.</p><p>Nevertheless, I have to.</p><p>The Financial Times revealed a few weeks ago that<a href="https://www.ft.com/content/163c6927-2032-4346-857e-8e3787e4babc?ref=wheresyoured.at"> <u>CoreWeave's debt payments could balloon to over $2.4 billion a year by the end of 2025</u></a>, far outstripping its cash reserves, and<a href="https://www.theinformation.com/articles/coreweave-faces-reality-check-bullish-growth-forecasts?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>The Information reported that its cash burn would increase to $15 billion in 2025</u></a>.</p><p>As per its IPO filings, 62% of CoreWeave's 2024 revenue (a little under $2 billion, with losses of $863 million) was Microsoft compute, and based on conversations with sources, a good amount of this was Microsoft running compute for OpenAI.</p><p>Starting October 2025,<a href="https://www.semafor.com/article/03/20/2025/microsoft-chose-not-to-exercise-12-billion-coreweave-option?ref=wheresyoured.at"> <u>OpenAI will start paying Coreweave as part of its five-year-long $12 billion contract</u></a>, picking up the option that Microsoft declined.<a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Starting%20from%20October%202025"> <u>This is also when</u></a> CoreWeave will have to start making payments on<a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Problem%20Loan%20Number%202%3A%20DDTL%202.0"> <u>its massive, multi-billion dollar DDTL 2.0 loan</u></a>, which likely makes these payments critical to CoreWeave's future.</p><p>This deal also suggests that OpenAI will become CoreWeave's largest customer. Microsoft had previously committed to spending $10 billion on CoreWeave's services "<a href="https://www.datacenterdynamics.com/en/news/microsoft-to-invest-10bn-in-coreweave-by-end-of-decade/?ref=wheresyoured.at"><u>by the end of the decade</u></a>," but CEO Satya Nadella added a few months later on a podcast that its relationship with CoreWeave was a "<a href="https://www.youtube.com/watch?v=9NtsnzRFJ_o&amp;ref=wheresyoured.at"><u>one-time thing</u></a>." Assuming Microsoft keeps spending at its previous rate — something that isn't guaranteed — it would still be only half of OpenAI's potential revenue.</p><p>CoreWeave's expansion, at this point, is entirely driven by OpenAI. 77% of its 2024 revenue came from two customers — Microsoft being the largest, and using CoreWeave as an auxiliary supplier of compute for OpenAI. As a result, the future expansion efforts —<a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Per%20its%20S,its%20current%20commitments."> <u>the theoretical 1.3 gigawatts of contracted (translation: does not exist yet) compute</u></a> — are largely (if not entirely) for the benefit of OpenAI.</p><p><strong>In the event that OpenAI cannot fulfil its obligations, CoreWeave will collapse.</strong> It is that simple.&nbsp;</p><h3 id="nvidia-relies-on-coreweave-for-more-than-6-of-its-revenue-and-coreweaves-future-creditworthiness-to-continue-receiving-it-%E2%80%94-much-of-which-is-dependent-on-openai"><strong>NVIDIA Relies On CoreWeave For More Than 6% Of Its Revenue, And CoreWeave's Future Creditworthiness To Continue Receiving It — Much Of Which Is Dependent On OpenAI</strong></h3><p>I’m basing this on a comment I received from Gil Luria, Managing Director and Head of Technology Research at analyst D.A. Davidson &amp; Co:</p><blockquote>Since CRWV bought 200,000 GPUs last year and those systems are around $40,000 we believe CRWV spent $8 billion on NVDA last year. That represents more than 6% of NVDA’s revenue last year.&nbsp;</blockquote><p>CoreWeave receives preferential access to NVIDIA's GPUs, and makes up billions of dollars of its revenue.<a href="https://www.ft.com/content/41bfacb8-4d1e-4f25-bc60-75bf557f1f21?ref=wheresyoured.at"> <u>CoreWeave then takes those GPUs and raises debt using them as collateral</u></a>, then proceeds to buy more of those GPUs from NVIDIA. NVIDIA was the anchor for CoreWeave's IPO, and CEO Michael Intrator said that the IPO "wouldn't have closed" without NVIDIA buying $250 million worth of shares.<a href="https://www.theinformation.com/articles/project-osprey-how-nvidia-seeded-coreweaves-rise?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>NVIDIA invested $100 million in the early days of CoreWeave</u></a>, and, for reasons I cannot understand, also agreed to spend $1.3 billion over four years to, and I quote The Information, "rent its own chips from CoreWeave."</p><p><a href="https://www.wheresyoured.at/core-incompetency/#:~:text=potentially%20fatal%20%E2%80%94%20vulnerability.-,Sidenote,-%3A%20On%20the%20subject"><u>Buried in CoreWeave's S-1 — the document every company publishes before going public —&nbsp; was a warning about counterparty credit risk</u></a>, which is when one party provides services or goods to another with specific repayment terms, and the other party not meeting their side of the deal. While this was written as a theoretical (as it could, in theoretically, come from any company to which CoreWeave acts as a creditor) it only named one company: OpenAI.&nbsp;</p><p>As discussed previously, CoreWeave is saying that, should a customer — any customer, but really, it means OpenAI — fail to pay its bills for infrastructure built on their behalf, or for services rendered, it could have a material risk to the business.</p><blockquote><strong>Aside:</strong><a href="https://www.theinformation.com/articles/google-advanced-talks-rent-nvidia-ai-servers-coreweave?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>The Information reported that Google is in "advanced talks" to rent GPUs from CoreWeave</u></a>. It also, when compared to Microsoft and OpenAI's deals with CoreWeave, noted that "...Google's potential deal with CoreWeave is "significantly smaller than those commitments, according to one of the people briefed on it, but could potentially expand in future years."</blockquote><p>CoreWeave's continued ability to do business hinges heavily on its ability to raise further debt (<a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Number%20Two%20%E2%80%94%20CoreWeave%20Has%20Taken%20On%20A%20Fatal%20Amount%20of%20Debt"><u>which I have previously called into question</u></a>), and its ability to raise further debt is,<a href="https://www.ft.com/content/163c6927-2032-4346-857e-8e3787e4babc?ref=wheresyoured.at"> <u>to quote the Financial Times</u></a>, "secured against its more than 250,000 Nvidia chips and its contracts with customers, such as Microsoft." Any future debt that CoreWeave raises would be based upon its contract with OpenAI (you know, the counterparty credit risk threat that represents a disproportionate share of its revenue) and whatever GPUs it still has to collateralize.</p><p>As a result, a chunk of NVIDIA's future revenue is dependent on OpenAI's ability to fulfil its obligations to CoreWeave, both in its ability to pay them and their timeliness in doing so. If OpenAI fails, then CoreWeave fails, which then hurts NVIDIA.&nbsp;</p><p>Contagion.&nbsp;</p><h3 id="openais-expansion-is-dependent-on-two-unproven-startups-who-are-also-dependent-on-openai-to-live"><strong>OpenAI's Expansion Is Dependent On Two Unproven Startups, Who Are Also Dependent on OpenAI To Live</strong></h3><p>With Microsoft's data center pullback and OpenAI's intent to become independent from Redmond, future data center expansion is based on two partners supporting CoreWeave and Oracle: Crusoe and Core Scientific, neither of which appear to have ever built an AI data center.</p><p>I also must explain how <em>difficult</em> building a data center is, and how said difficulty increases when you're building an AI-focused data center. For example,<a href="https://www.theinformation.com/articles/nvidia-customers-worry-about-snag-with-new-ai-chip-servers?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>NVIDIA had to delay the launch of its Blackwell GPUs because of how finicky the associated infrastructure</u></a> (the accompanying servers and cooling them) is. <em>For customers that already had experience handling GPUs, and therefore likely know how to manage the extreme temperatures created by them.</em></p><p><em>As another reminder,</em> OpenAI is on the hook for $19 billion of funding behind Stargate, money that neither it nor SoftBank has right now.</p><p>Imagine if you didn't have any experience, and effectively had to learn from scratch? How do you think that would go?</p><p>We're about to find out!</p><h3 id="crusoestargateabilene-texas"><strong>Crusoe - Stargate - Abilene Texas</strong></h3><p><strong>Crusoe </strong>is a former cryptocurrency mining company that<a href="https://techcrunch.com/2024/11/21/crusoe-a-rumored-openai-data-center-supplier-has-secured-686m-in-new-funds-filing-shows/?ref=wheresyoured.at"> <u>has now raised hundreds of millions of dollars</u></a> to build data centers for AI companies, starting with<a href="https://www.theinformation.com/briefings/crusoe-in-talks-to-raise-several-billion-dollars-for-oracle-openai-data-center?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>a $3.4 billion data center financing deal with asset manager Blue Owl Capital</u></a>. This (yet-to-be-completed) data center has now been leased by Oracle, which will, allegedly, fill it full of GPUs for OpenAI.</p><p>Despite calling itself "the industry’s first vertically integrated AI infrastructure provider," with the company using <a href="https://www.datacenterdynamics.com/en/news/crusoe-to-deploy-gas-flare-data-centers-in-utah/?ref=wheresyoured.at"><u>flared gas (a waste byproduct of oil production) to power IT infrastructure</u></a>, Crusoe does not appear to have built an AI data center, and is now being tasked with<a href="https://crusoe.ai/blog/crusoe-expands-ai-data-center-campus-in-abilene-to-1-2-gigawatts/?ref=wheresyoured.at"> <u>building a 1.2 Gigawatt data center campus for OpenAI</u></a>.</p><p>Crusoe is the sole developer and operator of the Abilene site, meaning, according to<a href="https://www.theinformation.com/articles/why-openai-and-oracles-ai-data-center-plan-hinges-on-a-little-known-startup?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>The Information</u></a>, "...is in charge of contracting with construction contractors and data center customers, as well as running the data center after it is built."</p><p>Oracle, it seems, will be responsible for<a href="https://www.theinformation.com/articles/why-openai-and-oracles-ai-data-center-plan-hinges-on-a-little-known-startup?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>filling said data center with GPUs and the associated hardware</u></a>.</p><p>Nevertheless, the project appears to be behind schedule.</p><p>The Information reported in October 2024 that Abeline was meant to have "...<a href="https://www.theinformation.com/articles/why-openai-and-oracles-ai-data-center-plan-hinges-on-a-little-known-startup?rc=kz8jh3&amp;ref=wheresyoured.at"><u>50,000 of NVIDIA's [Blackwell] AI chips...in the first quarter of [2025</u></a>]," and also suggested that the site was projected to have 100,000 Blackwell chips by the end of 2025.</p><p>Here in reality,<a href="https://www.datacenterdynamics.com/en/news/openai-and-oracle-to-deploy-64000-gb200-gpus-at-stargate-abilene-data-center-by-2026-report/?ref=wheresyoured.at"> <u>a report from Bloomberg in March 2025</u></a> (that I cited previously) said that OpenAI and Oracle were expected to have <em>16,000 GPUs</em> available <em>by the Summer of 2025, </em>with "...OpenAI and oracle are expected to deploy 64,000 NVIDIA GB200s at the Stargate data center...by the end of 2026."</p><p>As discussed above, OpenAI <em>needs this capacity</em>.<a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>According to The Information</u></a>, OpenAI expects Stargate to handle three-quarters of its compute by 2030, and these delays call into question at the very least whether this schedule is reasonable, if not whether Stargate, as a project, is actually possible.</p><h3 id="core-scientificcoreweavedenton-texas"><strong>Core Scientific - CoreWeave - Denton Texas</strong></h3><p>I've written a great deal about CoreWeave in the past,<a href="https://www.wheresyoured.at/optimistic-cowardice/"> <u>and specifically about its buildout partner Core Scientific</u></a>, a cryptocurrency mining company (yes, <em>another one</em>) that has exactly one customer for AI data centers — CoreWeave.</p><p>A few notes:</p><ul><li>Core Scientific was bankrupt last year.</li><li>Core Scientific has never built an AI data center, and its cryptocurrency mining operations were built around ASICs — specialist computers for mining Bitcoin —<a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Needham%20analysts%20wrote%20in%20a%20report%20in%20May%20that%20almost%20all%20infrastructure%20that%20miners%20currently%20have%20would%20%E2%80%9Cneed%20to%20be%20bulldozed%20and%20built%20from%20the%20ground%20up%20to%20accommodate%20HPC%2C%E2%80%9D%20or%20high%2Dperformance%20computing.%C2%A0"> <u>which led an analyst to tell CNBC</u></a> that said data centers would "<a href="https://www.cnbc.com/2024/08/06/bitcoin-miner-core-scientific-expands-coreweave-deal-to-6point7-billion.html?ref=wheresyoured.at#:~:text=Needham%20analysts%20wrote%20in%20a%20report%20in%20May%20that%20almost%20all%20infrastructure%20that%20miners%20currently%20have%20would%20%E2%80%9Cneed%20to%20be%20bulldozed%20and%20built%20from%20the%20ground%20up%20to%20accommodate%20HPC%2C%E2%80%9D%20or%20high%2Dperformance%20computing."><u>need to be bulldozed and built up from the ground up</u></a>" to accommodate AI compute.</li><li>Core Scientific does not appear to have any meaningful AI compute of any kind. Its AI/HPC (high-performance computing) revenue represents a tiny, tiny percentage of its overall revenue, which still comes primarily from mining crypto, both for itself and for third-parties.&nbsp;</li><li><a href="https://investors.corescientific.com/news-events/press-releases/detail/110/core-scientific-and-coreweave-announce-1-2-billion-expansion-at-denton-tx-site?ref=wheresyoured.at"><u>CoreWeave's entire 1.3 Gigawatt buildout appears to be being handled by Core Scientific</u></a>.</li></ul><p>Core Scientific is also, it seems, taking on $1.14 billion of capital expenditures to build out these data centers,<a href="https://www.wheresyoured.at/core-incompetency/#:~:text=Core%20Scientific%2C%20according%20to%20its%2010%2DK%20form%3A"> <u>with CoreWeave promising to reimburse $899.3 million of these costs</u></a>.</p><p>It's also unclear how Core Scientific intends to do this. While it’s taken on a good amount of debt in the past —<a href="https://investors.corescientific.com/news-events/press-releases/detail/102/core-scientific-prices-upsized-550-million-convertible-senior-notes-offering?ref=wheresyoured.at"> <u>$550 million in a convertible note toward the end of 2024</u></a> — this would be more debt than it’s ever taken on.</p><p>It also, as with Crusoe, does not appear to have any experience building AI data centers, except unlike Crusoe, Core Scientific is a barely-functioning recently-bankrupted bitcoin miner pretending to be a data center company.</p><p>How important is CoreWeave to OpenAI exactly?<a href="https://www.semafor.com/article/03/20/2025/microsoft-chose-not-to-exercise-12-billion-coreweave-option?ref=wheresyoured.at#:~:text=%E2%80%9CCoreWeave%20has%20been,very%2C%20very%20quickly.%E2%80%9D"> <u>From Semafor</u></a>:</p><blockquote>“CoreWeave has been one of our earliest and largest compute partners,” OpenAI chief Sam Altman said in CoreWeave’s roadshow <a href="https://www.netroadshow.com/custom/IPO/CoreWeave/retail/disclaimer.html?ref=wheresyoured.at"><u>video</u></a>, adding that CoreWeave’s computing power “led to the creation of some of the models that we’re best known for.”<p>“Coreweave figured out how to innovate on hardware, to innovate on data center construction, and to deliver results very, very quickly.”</p></blockquote><p>But will it survive long term?</p><p>Going back to the point of contagion: If OpenAI fails, and CoreWeave fails, so too does Core Scientific. And I don’t fancy Crusoe’s chances, either. At least Crusoe isn’t public.</p><h3 id="an-open-question-does-microsoft-book-openais-compute-as-revenue"><strong>An Open Question: Does Microsoft Book OpenAI's Compute As Revenue?</strong></h3><p>Up until fairly recently, Microsoft has been the entire infrastructural backbone of OpenAI, but recently (to free OpenAI up to work with Oracle)<a href="https://techcrunch.com/2025/01/21/microsoft-is-no-longer-openais-exclusive-cloud-provider/?ref=wheresyoured.at"> <u>released it from its exclusive cloud compute deal</u></a>. Nevertheless,<a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at#:~:text=more%20than%20doubling%20from%20%2413%20billion%20this%20year"> <u>per The Information</u></a>, OpenAI still intends to spend $13 billion on compute on Microsoft Azure this year.</p><p>What's confusing, however, is whether any of this is booked as <em>revenue.</em> Microsoft claimed earlier in this year that it surpassed $13 billion in annual recurring revenue — by which it means its last month multiplied by 12 —<a href="https://www.marketwatch.com/livecoverage/microsoft-earnings-stock-results-azure-cloud-ai-deepseek/card/microsoft-says-ai-revenue-has-surpassed-13-billion-annual-run-rate-4d7JEBh564bN1pCGbGI6?ref=wheresyoured.at"> <u>from artificial intelligence</u></a>.<a href="https://www.theinformation.com/articles/openai-projections-imply-losses-tripling-to-14-billion-in-2026?ref=wheresyoured.at&amp;rc=kz8jh3"> <u>OpenAI's compute costs in 2024 were $5 billion</u></a>, at a<a href="https://www.wheresyoured.at/wheres-the-money/#:~:text=OpenAI%20pays%20just%20over%2025%25%20of%20the%20cost%20of%20Azure%E2%80%99s%20GPU%20compute%20as%20part%20of%20its%20deal%20with%20Microsoft%20%E2%80%94%20around%20%241.30%2Dper%2DGPU%2Dper%2Dhour%20versus%20the%20regular%20Azure%20cost%20of%20%243.40%20to%20%244."> <u>discounted Azure rate</u></a>, which, on an annualized basis, would be around $416 million in revenue a month for Microsoft.</p><p>It isn't, however, clear whether Microsoft counts OpenAI's compute spend as revenue.</p><p>Microsoft's earnings do not include an "artificial intelligence" section, but<a href="https://www.microsoft.com/en-us/investor/segment-information?ref=wheresyoured.at"> <u>three separate segments</u></a>:</p><ul><li>Productivity and Business Processes, which includes things like Microsoft 365, LinkedIn, Dynamics 365 and other business processing software.</li><li>More Personal Computing, which includes Windows and Gaming Products</li><li>Intelligent Cloud, Including server products and cloud services like Azure, which is likely where OpenAI's compute is included.</li></ul><p>As a result, it's hard to say specifically where OpenAI's revenue sits, but based on an analysis of Microsoft's Intelligent Cloud segment from FY23 Q1 (note, financial years don’t always correspond with the calendar year,<a href="https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q2/press-release-webcast?os=httpwww.szxlp.xyz&amp;ref=app"> <u>so we just finished FY25 Q2 in January</u></a>) through to its most recent earnings, and found that there was a spike in revenue from FY23 Q1 to FY24 Q1.&nbsp;</p><p>In FY23 Q1 (which ended on <a href="https://www.microsoft.com/en-us/investor/earnings/fy-2023-q1/press-release-webcast?ref=wheresyoured.at"><u>September 30, 2022</u></a>, a month before ChatGPT's launch),&nbsp; the segment made $20.3 billion. The following year, in FY24 Q1, it made $24.3 billion — a 19.7% year-over-year (or roughly $4 billion) increase.</p><p>This could represent the massive increase in training and inference costs associated with hosting ChatGPT,<a href="https://www.microsoft.com/en-us/investor/earnings/fy-2024-q4/press-release-webcast?ref=wheresyoured.at"> <u>peaking at $28.5 billion in revenue in FY24 Q4</u></a> — before dropping dramatically to $24.1 billion in<a href="https://www.microsoft.com/en-us/investor/earnings/fy-2025-q1/press-release-webcast?ref=wheresyoured.at"> <u>FY25 Q1</u></a> and raising a little to $25.5 billion in<a href="https://www.microsoft.com/en-us/Investor/earnings/FY-2025-Q2/press-release-webcast?os=httpwww.szxlp.xyz&amp;ref=app"> <u>FY25 Q2</u></a>.</p><p>OpenAI spent 2023 training its GPT-4o model before transitioning to its massive, expensive "Orion" model which would eventually become GPT 4.5, as well as its video generation model "Sora."<a href="https://www.wsj.com/tech/ai/openai-gpt5-orion-delays-639e7693?ref=wheresyoured.at"> <u>According to the Wall Street Journal</u></a>, training GPT 4.5 involved at least one training run costing "around half a billion dollars in computing costs alone."</p><p>These are huge sums, but it’s worth noting a couple of things. First, Microsoft licenses OpenAI’s models to third parties, so some of this revenue could be from other companies using GPT on Azure. And there’s also other companies running their own models on Azure. We’ve seen a lot of companies launch AI products, and not all of them are based on LLMs.</p><p>Muddling things further, Microsoft provides OpenAI access to Azure cloud services at a discounted rate. And so, there’s a giant question mark over OpenAI’s contribution to the various spikes in revenue for Microsoft’s Intelligent Cloud segment, or whether other third-parties played a significant role.&nbsp;</p><p>Furthermore, Microsoft’s investment in OpenAI isn’t entirely in cold, hard cash. Rather, it has provided the company with credits to be redeemed on Azure services. I’m not entirely sure how this would be represented on accounting terms, and if anyone can shed light on this, please get in touch.&nbsp;</p><p>Would it be noted as revenue, or something else? OpenAI isn’t paying Microsoft, but rather doing the tech equivalent of redeeming some airmiles, or spending a gift card.&nbsp;</p><p>Additionally, while equity is often treated as income for tax purposes — as is the case when an employee receives RSUs as part of their compensation package — under the existing OpenAI structure, Microsoft isn’t a shareholder but rather the owner of profit-sharing units. This is a distinction worth noting.&nbsp;&nbsp;</p><p>These profit-sharing units are treated as analogous to equity, at least in terms of OpenAI’s ability to raise capital, but in practice they aren’t the same thing. They don’t represent ownership in the company as directly as, for example, a normal share unit would. They lack the liquidity of a share, and the upside they provide — namely, dividends — is purely theoretical.&nbsp;</p><p>Another key difference: when a company goes bankrupt and enters liquidation, shareholders can potentially receive a share of the proceeds (after other creditors, employees, etc are paid). While that often doesn’t happen (as in, the liabilities far exceed the assets of the company), it’s at least theoretically possible. Given that profit-sharing units aren’t actually shares, where does that leave Microsoft?</p><p>This stuff is confusing, and I’m not ashamed to say that complicated accounting questions like these are far beyond my understanding. If anyone can shed some light, drop me an email, or a message on Twitter or BlueSky, or post on the Better Offline subreddit.&nbsp;</p><h2 id="the-future-of-generative-ai-rests-on-openai-and-openais-future-rests-on-near-impossible-financial-requirements"><strong>The Future of Generative AI Rests On OpenAI, And OpenAI's Future Rests On Near-Impossible Financial Requirements</strong></h2><p>I have done my best to write this piece in as objective a tone as possible, regardless of my feelings about the generative AI bubble and its associated boosters.</p><p>OpenAI,<a href="https://www.wheresyoured.at/wheres-the-money/#:~:text=Is%20Generative%20AI%20A%20Real%20Industry%3F"> <u>as I've written before</u></a>, is effectively the entire generative AI industry, with its nearest competitor being less than five percent of its 500 million weekly active users.</p><p>Its future is dependent — and this is not an opinion, but objective fact — on effectively infinite resources.</p><h3 id="financial-resources"><strong>Financial Resources</strong></h3><p>If it required $40 billion to continue operations this year, it is reasonable to believe it will need at least another $40 billion next year, and based on its internal projections, will need at least that every single other year until 2030, when it claims, somehow, it will be profitable "with the completion of the Stargate data center."</p><h3 id="compute-resources-and-expansion"><strong>Compute Resources and Expansion</strong></h3><p>OpenAI requires more compute resources than anyone has ever needed, and will continue to do so in perpetuity. Building these resources is now dependent on two partners — Core Scientific and Crusoe — that have never built a data center, as Microsoft has materially pulled back on data center development, which have (as well as the aforementioned pullback on 2GW of data centers)<a href="https://www.linkedin.com/posts/noelle-walsh-b29356108_microsoftcloud-datacenters-activity-7315439628562423808-W67e/?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAACNp-u0B8oyS6pLtatitYCwLv1mvyLXiCvk"> <u>"slowed or paused" some of its "early stage" data center projects</u></a>. This shift is directly linked to Microsoft’s relationship with OpenAI, withTD Cowen's recent analyst report saying that data center pullbacks were, and I quote its March 26 2025 data center channel checks letter, "...driven by the decision to not support incremental OpenAI training workloads."</p><p>In simpler terms, OpenAI needs more compute at a time when its lead backer,<a href="https://www.datacenterdynamics.com/en/news/microsoft-bought-twice-as-many-nvidia-hopper-gpus-as-other-big-tech-companies-report/?ref=wheresyoured.at"> <u>which has the most GPUs in the world</u></a>, has specifically walked away from building it.</p><p>Even in my most optimistic frame of mind, it isn't realistic to believe that Crusoe or Core Scientific can build the data centers necessary for OpenAI's expansion.</p><p>Even if SoftBank and OpenAI had the money to invest in Stargate <em>today</em>, dollars do not change the fabric of reality. Data centers take time to build, requiring concrete, wood, steel and other materials to be manufactured and placed, and that's after the permitting required to get these deals done. Even if that succeeds, getting the power necessary is a challenge unto itself, to the point that even Oracle, an established and storied cloud compute company,<a href="https://www.theinformation.com/articles/pressure-rises-oracle-finish-openai-data-center?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>to quote The Information</u></a>, "...has less experience than its larger rivals in dealing with utilities to secure power and working with powerful and demanding cloud customers whose plans change frequently."</p><p>A partner like Crusoe or Core Scientific simply doesn't have the muscle memory or domain expertise that Microsoft has when it comes to building and operating data centers. As a result, it's hard to imagine even in the <em>best case scenario</em> that they're able to match the hunger for compute that OpenAI has.</p><p>Now, I want to be clear — I believe OpenAI will still continue to use Microsoft's compute, and even expand further into whatever remaining compute Microsoft may have. However, there is now a hard limit on how much of it there's going to be, both literally (in what's physically available) and in what Microsoft itself will actually OpenAI them to use, especially given how unprofitable GPU compute might be.</p><h2 id="how-does-this-end"><strong>How Does This End?</strong></h2><p>Last week, a truly offensive piece of fan fiction — framed as a "report" —<a href="https://ai-2027.com/?ref=wheresyoured.at"> <u>called AI 2027 went viral</u></a>, garnering press coverage with<a href="https://www.dwarkesh.com/p/scott-daniel?ref=wheresyoured.at"> <u>the Dwarkesh Podcast</u></a> and<a href="https://www.nytimes.com/2025/04/03/technology/ai-futures-project-ai-2027.html?ref=wheresyoured.at"> <u>gormless, child-like wonder from the New York Times' Kevin Roose</u></a>. Its predictions vaguely suggest a theoretical company called OpenBrain will invent a self-teaching agent of some sort.</p><p>It's bullshit, but it captured the hearts and minds of AI boosters because it vaguely suggests that somehow Large Language Models and their associated technology will become something entirely different.</p><p>I don't like making predictions like these because the future — especially in our current political climate — is so chaotic, but I will say that I do not see, and I say this with complete objectivity, how any of this continues.</p><p>I want to be <strong>extremely blunt</strong> with the following points, as I feel like both members of the media and tech analysts have failed to express how ridiculous things have become. I will be repeating myself, but it's necessary, as I <strong>need you to understand how untenable things are.</strong></p><ul><li>SoftBank is putting itself in dire straits <em>simply to fund OpenAI once. </em>This deal threatens its credit rating, with SoftBank having to take on what will be multiple loans <strong>to fund OpenAI's $40 billion round.<u> OpenAI will need at least another $40 billion in the next year.</u></strong><ul><li>This is before you consider the other $19 billion that SoftBank has agreed to contribute to the Stargate data center project, money that it does not currently have available.</li></ul></li><li>OpenAI has promised $19 billion to the Stargate data center project, money it <strong>does not have</strong> and <strong>cannot get without SoftBank's funds.</strong><ul><li><strong><u>Again, neither SoftBank nor OpenAI has the money for Stargate right now.</u></strong></li></ul></li><li>OpenAI <em>needs Stargate to get built to grow much further.</em></li></ul><p>I see no way in which OpenAI can continue to raise money at this rate, <em>even if OpenAI somehow actually receives the $40 billion, which will require it becoming a for-profit entity. </em>While it could theoretically stretch that $40 billion to last multiple years,<a href="https://www.theinformation.com/articles/openai-forecast-shows-shift-from-microsoft-to-softbank?rc=kz8jh3&amp;ref=wheresyoured.at"> <u>projections say it’ll burn $320 billion in the next five years</u></a>.</p><p>Or, more likely, I can’t see a realistic way in which OpenAI gets the resources it needs to survive. It’ll need a streak of unlikely good fortune, the kind of which you only ever hear about in Greek epic poems:&nbsp;</p><ul><li>SoftBank somehow gets the resources (and loses the constraints) required to bankroll it indefinitely.&nbsp;</li><li>The world’s wealthiest entities — those sovereign wealth funds mentioned earlier, the Saudis and so on&nbsp; — pick up the slack each year until OpenAI reaches productivity (assuming it does).</li><li>It has enough of those mega-wealthy benefactors to provide the $320bn it needs before it reaches profitability.</li><li>Crusoe and CoreScientific turn out to be really good at building AI infrastructure — something they’ve never done before.&nbsp;</li><li>Microsoft walks-back its walk-back on building new AI infrastructure and recommits to the tens of billions of dollars of capex spending it previously floated.&nbsp;</li><li>Stargate construction happens faster than expected, and there are no supply chain issues (in terms of labor, building materials, GPUs, and so on).</li></ul><p>If those things happen, I’ll obviously find myself eating crow. But I’m not worried.&nbsp;</p><p>In the present conditions, OpenAI is on course to run out of money or compute capacity, and it's unclear which will happen first.</p><h2 id="its-time-to-wake-up"><strong>It's Time To Wake Up</strong></h2><p>Even in a hysterical bubble where everybody is agreeing that this is the future, OpenAI currently requires more money and more compute than is reasonable to acquire. <em>Nobody</em> has ever raised as much as OpenAI needs to, and based on the sheer amount of difficulty that SoftBank is having in raising the funds to meet <em>the lower tranche ($10bn) of its commitment, </em>it may simply not be possible for this company to continue.</p><p>Even with <em>extremely</em> preferential payment terms — months-long deferred payments, for example — at some point somebody is going to need to get paid.</p><p>I will give Sam Altman credit. He's found many partners to shoulder the burden of the rotten economics of OpenAI, with Microsoft, Oracle, Crusoe and CoreWeave handling the up-front costs of building the infrastructure, SoftBank finding the investors for its monstrous round, and the tech media mostly handling his marketing for him.</p><p>He is, however, over-leveraged. OpenAI has never been forced to stand on its own two feet or focus on efficiency, and I believe the constant enabling of its ugly, nonsensical burnrate has doomed this company. OpenAI has acted like it’ll always have more money and compute, and that people will always believe its bullshit, mostly because up until recently <em>everybody has.</em></p><p>OpenAI cannot "make things cheaper" at this point, because the money has always been there to make things more expensive, as has the compute to make larger language models that burn billions of dollars a year. This company is not built to reduce its footprint in any way, nor is it built for a future in which it wouldn't have access to, as I've said before, infinite resources.</p><p>Worse still, investors and the media have run cover for the fact that these models don't really do much more than they did a year ago and for<a href="https://www.wheresyoured.at/godot-isnt-making-it/"> <u>the overall diminishing returns of Large Language Models</u></a>.</p><p>I have had many people <em>attack</em> my work about OpenAI, but none have provided any real counterpoint to<a href="https://www.wheresyoured.at/to-serve-altman/"> <u>the underlying economic argument I've made since July of last year</u></a> that OpenAI is unsustainable. This is likely because there really isn't one, other than "OpenAI will continue to raise more money than anybody has ever raised in history, in perpetuity, and will somehow turn from the least-profitable company of all time to a profitable one."</p><p>This isn’t a rational argument. It’s a religious one. It’s a call for faith.&nbsp;</p><p>And I see no greater pale horse of the apocalypse than Microsoft's material pullback on data centers. While the argument might be that Microsoft wants OpenAI to have an independent future, that's laughable when you consider Microsoft's deeply monopolistic tendencies — and, for that matter, it owns a massive proportion of OpenAI’s pseudo-equity. At one point, Microsoft’s portion was valued at 49 percent. And while additional fundraising has likely diluted Microsoft’s stake, it still “owns” a massive proportion of what is (at least) the most valuable private startup of all time.</p><p>And we’re supposed to believe that Microsoft’s pullback — which limits OpenAI’s access to the infrastructure it needs to train and run its models, and thus (as mentioned) represents an existential threat to the company — is because of some paternal desire to see OpenAI leave the childhood bedroom, spread its wings, and enter the real world? Behave.&nbsp;</p><p>More likely, Microsoft got what it needed out of OpenAI, which has reached the limit of the models it can develop, and which Microsoft already retains the IP of. There’s probably no reason to make any further significant investments, though they allegedly may be part of the initial $10 billion tranche of OpenAI’s next round.</p><p>It's also important to note that absolutely nobody <em>other than NVIDIA </em>is making any money from generative AI. CoreWeave loses billions of dollars, OpenAI loses billions of dollars, Anthropic loses billions of dollars, and I can't find a single company providing generative AI-powered software that's making a profit. The only companies even <em>close</em> to doing so are consultancies providing services to train and create data for models like Turing and Scale AI — and<a href="https://www.bloomberg.com/news/articles/2025-04-02/scale-ai-expects-to-more-than-double-sales-to-2-billion-in-2025?ref=wheresyoured.at"> <u>Scale isn't even profitable</u></a>.</p><p>The knock-on effects of OpenAI's collapse will be wide-ranging. Neither CoreWeave nor Crusoe will have tenants for their massive, unsustainable operations, and Oracle will have nobody to sell the compute it’s leased from Crusoe for the next 15 years. CoreWeave will likely collapse under the weight of its abominable debt, which will lead to a 7%+ revenue drop for NVIDIA at a time when revenue growth has already begun to slow.</p><p>On a philosophical level, OpenAI's health is what keeps this industry alive.<a href="https://www.wheresyoured.at/wheres-the-money/"> <u>OpenAI has the only meaningful userbase in generative AI</u></a>, and this entire hype-cycle has been driven by its success, meaning any deterioration (or collapse) of OpenAI will tell the market what I've been saying for over a year: that generative AI is not the next hyper-growth market, and its underlying economics do not make sense.</p><p>I am not writing this to be "right" or "be a hater."</p><p>If something changes, and I am wrong somehow, I will write exactly how, and why, and what mistakes I made to come to the conclusions I have in this piece.</p><p>I do not believe that my peers in the media will do the same when this collapses, but I promise you that they will be held accountable, because all of this abominable waste could have been avoided.</p><p>Large Language Models are not, on their own, the problem. They're tools, capable of some outcomes, doing some things, but the problem, ultimately, are the extrapolations made about their abilities, and the unnecessary drive to make them larger, even if said largeness never amounted to much.</p><p>Everything that I'm describing is the result of a tech industry — including media and analysts — that refuses to do business with reality, trafficking in ideas and ideology, celebrating victories that have yet to take place, applauding those who have yet to create the things they're talking about, cheering on men lying about what's possible so that they can continue to burn billions of dollars and increase their wealth and influence.</p><p>I understand why others might not have written this piece. What I am describing is a systemic failure, one at a scale hereto unseen, one that has involved so many rich and powerful and influential people agreeing to ignore reality, and that’ll have crushing impacts for the wider tech ecosystem when it happens.</p><p>Don't say I didn't warn you.</p>
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scientists: Protein IL-17 fights infection, acts on the brain, inducing anxiety (102 pts)]]></title>
            <link>https://medicalxpress.com/news/2025-04-scientists-protein-il-infection-brain.html</link>
            <guid>43682686</guid>
            <pubDate>Mon, 14 Apr 2025 15:54:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medicalxpress.com/news/2025-04-scientists-protein-il-infection-brain.html">https://medicalxpress.com/news/2025-04-scientists-protein-il-infection-brain.html</a>, See on <a href="https://news.ycombinator.com/item?id=43682686">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
									    
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2025/anxiety.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2025/anxiety.jpg" data-sub-html="Credit: Andrew Neel from Pexels">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2025/anxiety.jpg" alt="anxiety" title="Credit: Andrew Neel from Pexels" width="800" height="530">
             <figcaption>
                Credit: Andrew Neel from Pexels
            </figcaption>        </figure>
    </div><p>Immune molecules called cytokines play important roles in the body's defense against infection, helping to control inflammation and coordinating the responses of other immune cells. A growing body of evidence suggests that some of these molecules also influence the brain, leading to behavioral changes during illness.</p>

                                        
                                                                                  
                                         

                                                                                                                                    <p>Two new studies from MIT and Harvard Medical School, focusing on a cytokine called IL-17, now add to that evidence. The researchers found that IL-17 acts on two distinct brain regions—the amygdala and the somatosensory cortex—to exert two divergent effects. In the amygdala, IL-17 can elicit feelings of anxiety, while in the cortex it promotes sociable behavior.</p>
<p>These findings suggest that the immune and nervous systems are tightly interconnected, says Gloria Choi, an associate professor of brain and cognitive sciences, a member of MIT's Picower Institute for Learning and Memory, and one of the senior authors of the studies.</p>
<p>"If you're sick, there's so many more things that are happening to your internal states, your mood, and your behavioral states, and that's not simply you being fatigued physically. It has something to do with the brain," she says.</p>
<p>Jun Huh, an associate professor of immunology at Harvard Medical School, is also a senior author of both studies, which appear in <i>Cell</i>. One of the papers was led by Picower Institute Research Scientist Byeongjun Lee and former Picower Institute research scientist Jeong-Tae Kwon, and the other was led by Harvard Medical School postdoc Yunjin Lee and Picower Institute postdoc Tomoe Ishikawa.</p>
<h2>Behavioral effects</h2>
<p>Choi and Huh became interested in IL-17 several years ago, when they found it was involved in a phenomenon known as the fever effect. Large-scale studies of autistic children have found that for many of them, their behavioral symptoms temporarily diminish when they have a fever.</p>

                                                                                                                                                         
                                                                                                                                                                                                <p>In a <a href="https://medicalxpress.com/news/2019-12-infections-autism-symptoms.html">2019 study</a> in mice, Choi and Huh showed that in some cases of infection, IL-17 is released and suppresses a small region of the brain's cortex known as S1DZ. Overactivation of neurons in this region can lead to autism-like behavioral symptoms in mice, including repetitive behaviors and reduced sociability.</p>
<p>"This molecule became a link that connects immune system activation, manifested as a fever, to changes in <a href="https://medicalxpress.com/tags/brain+function/" rel="tag">brain function</a> and changes in the animals' behavior," Choi says.</p>
<p>IL-17 comes in six different forms, and there are five different receptors that can bind to it.</p>
<p>In their two new papers, the researchers set out to map which of these receptors are expressed in different parts of the brain. This mapping revealed that a pair of receptors known as IL-17RA and IL-17RB is found in the cortex, including in the S1DZ region that the researchers had previously identified. The receptors are located in a population of neurons that receive proprioceptive input and are involved in controlling behavior.</p>
<p>When a type of IL-17 known as IL-17E binds to these receptors, the neurons become less excitable, which leads to the behavioral effects seen in the 2019 study.</p>
<p>"IL-17E, which we've shown to be necessary for behavioral mitigation, actually does act almost exactly like a neuromodulator in that it will immediately reduce these neurons' excitability," Choi says.</p>
<p>"So, there is an immune molecule that's acting as a neuromodulator in the brain, and its main function is to regulate excitability of neurons."</p>
<p>Choi hypothesizes that IL-17 may have originally evolved as a neuromodulator, and later on was appropriated by the immune system to play a role in promoting inflammation.</p>
<p>That idea is consistent with previous work showing that in the worm C. elegans, IL-17 has no role in the immune system but instead acts on neurons. Among its effects in worms, IL-17 promotes aggregation, a form of social behavior. Additionally, in mammals, IL-17E is actually made by neurons in the cortex, including S1DZ.</p>
<p>"There's a possibility that a couple of forms of IL-17 perhaps evolved first and foremost to act as a neuromodulator in the brain, and maybe later were hijacked by the immune system also to act as immune modulators," Choi says.</p>

                                                                                                                                            <h2>Provoking anxiety</h2>
<p>In the other <i>Cell</i> paper, the researchers explored another brain location where they found IL-17 receptors—the amygdala. This almond-shaped structure plays an important role in processing emotions, including fear and anxiety.</p>
<p>That study revealed that in a region known as the basolateral amygdala (BLA), the IL-17RA and IL-17RE receptors, which work as a pair, are expressed in a discrete population of neurons. When these receptors bind to IL-17A and IL-17C, the neurons become more excitable, leading to an increase in anxiety.</p>
<p>The researchers also found that, counterintuitively, if animals are treated with antibodies that block IL-17 receptors, it actually increases the amount of IL-17C circulating in the body. This finding may help to explain unexpected outcomes observed in a clinical trial of a drug targeting the IL-17-RA receptor for psoriasis treatment, particularly regarding its potential adverse effects on mental health.</p>
<p>"We hypothesize that there's a possibility that the IL-17 ligand that is upregulated in this patient cohort might act on the brain to induce suicide ideation, while in animals there is an anxiogenic phenotype," Choi says.</p>
<p>During infections, this anxiety may be a beneficial response, keeping the sick individual away from others to whom the infection could spread, Choi hypothesizes.</p>
<p>"Other than its main function of fighting pathogens, one of the ways that the immune system works is to control the host behavior, to protect the host itself and also protect the community the host belongs to," she says. "One of the ways the immune system is doing that is to use cytokines, secreted factors, to go to the brain as communication tools."</p>
<p>The researchers found that the same BLA neurons that have receptors for IL-17 also have receptors for IL-10, a cytokine that suppresses inflammation. This molecule counteracts the excitability generated by IL-17, giving the body a way to shut off anxiety once it's no longer useful.</p>

                                                                                                                                                                                                                                                                                                    <h2>Distinctive behaviors</h2>
<p>Together, the two studies suggest that the immune system, and even a single family of cytokines, can exert a variety of effects in the brain.</p>
<p>"We have now different combinations of IL-17 receptors being expressed in different populations of neurons, in two different brain regions, that regulate very distinct behaviors. One is actually somewhat positive and enhances social behaviors, and another is somewhat negative and induces anxiogenic phenotypes," Choi says.</p>
<p>Her lab is now working on additional mapping of IL-17 receptor locations, as well as the IL-17 molecules that bind to them, focusing on the S1DZ region. Eventually, a better understanding of these neuro-immune interactions may help researchers develop new treatments for neurological conditions such as autism or depression.</p>
<p>"The fact that these molecules are made by the immune system gives us a novel approach to influence brain function as a means of therapeutics," Choi says. "Instead of thinking about directly going for the brain, can we think about doing something to the immune system?"</p>

                                                                                                                                                                            
                                        											<div>
												                                                    <p><strong>More information:</strong>
                                                    Inflammatory and anti-inflammatory cytokines bidirectionally modulate amygdala circuits regulating anxiety, <i>Cell</i> (2025). <a data-doi="1" href="https://dx.doi.org/10.1016/j.cell.2025.03.005" target="_blank">DOI: 10.1016/j.cell.2025.03.005</a>. <a href="https://www.cell.com/cell/fulltext/S0092-8674(25)00278-8" target="_blank">www.cell.com/cell/fulltext/S0092-8674(25)00278-8</a>
</p><p>Brain-wide mapping of immune receptors uncovers a neuro-modulatory role of interleukin-17E and the receptor IL-17RB., <i>Cell</i> (2025). <a data-doi="1" href="https://dx.doi.org/10.1016/j.cell.2025.03.006" target="_blank">DOI: 10.1016/j.cell.2025.03.006</a>. <a href="https://www.cell.com/cell/fulltext/S0092-8674(25)00279-X" target="_blank">www.cell.com/cell/fulltext/S0092-8674(25)00279-X</a></p>

																								
																								<div>
													<p><strong>Journal information:</strong>
																											<a href="https://medicalxpress.com/journals/cell/"><cite>Cell</cite></a></p><a href="http://www.cell.com/" target="_blank" rel="nofollow">
															<svg>
																<use href="https://medx.b-cdn.net/tmpl/v6/img/svg/sprite.svg#icon_open" x="0" y="0"></use>
															</svg>
														</a> 
																									</div>
																							</div>
                                        											
																					
                                                                                                                            <p>
                                                <i>This story is republished courtesy of MIT News (<a href="http://web.mit.edu/newsoffice/" target="_blank">web.mit.edu/newsoffice/</a>), a popular site that covers news about MIT research, innovation and teaching.</i>
                                            </p>
                                                                                
                                        <!-- print only -->
                                        <div>
                                            <p><strong>Citation</strong>:
                                                 Scientists discover the protein IL-17 that fights infection also acts on the brain, inducing anxiety or sociability (2025, April 7)
                                                 retrieved 14 April 2025
                                                 from https://medicalxpress.com/news/2025-04-scientists-protein-il-infection-brain.html
                                            </p>
                                            <p>
                                            This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
                                            part may be reproduced without the written permission. The content is provided for information purposes only.
                                            </p>
                                        </div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Path to Open-Sourcing the DeepSeek Inference Engine (368 pts)]]></title>
            <link>https://github.com/deepseek-ai/open-infra-index/tree/main/OpenSourcing_DeepSeek_Inference_Engine</link>
            <guid>43682088</guid>
            <pubDate>Mon, 14 Apr 2025 15:03:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/deepseek-ai/open-infra-index/tree/main/OpenSourcing_DeepSeek_Inference_Engine">https://github.com/deepseek-ai/open-infra-index/tree/main/OpenSourcing_DeepSeek_Inference_Engine</a>, See on <a href="https://news.ycombinator.com/item?id=43682088">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">The Path to Open-Sourcing the DeepSeek Inference Engine</h2><a id="user-content-the-path-to-open-sourcing-the-deepseek-inference-engine" aria-label="Permalink: The Path to Open-Sourcing the DeepSeek Inference Engine" href="#the-path-to-open-sourcing-the-deepseek-inference-engine"></a></p>
<p dir="auto">A few weeks ago,
during <a href="https://github.com/deepseek-ai/open-infra-index?tab=readme-ov-file#202502-open-source-week">Open Source Week</a>,
we open-sourced several libraries.
The response from the community has been incredibly positive - sparking inspiring collaborations, productive
discussions, and valuable bug fixes.
Encouraged by this, we’ve decided to take another step forward: contributing our internal inference engine back to the
open-source community.</p>
<p dir="auto">We are deeply grateful for the open-source ecosystem, without which our progress toward AGI would not be possible.
Our training framework relies on <a href="https://github.com/pytorch/pytorch">PyTorch</a>, and our inference engine is built
upon <a href="https://github.com/vllm-project/vllm">vLLM</a>,
both of which have been instrumental in accelerating the training and deployment of DeepSeek models.</p>
<p dir="auto">Given the growing demand for deploying models like <a href="https://github.com/deepseek-ai/DeepSeek-V3">DeepSeek-V3</a>
and <a href="https://github.com/deepseek-ai/DeepSeek-R1">DeepSeek-R1</a>, we want to give back to the community as much as we can.
While we initially considered open-sourcing our full internal inference engine, we identified several challenges:</p>
<ul dir="auto">
<li><strong>Codebase Divergence</strong>: Our engine is based on an early fork of vLLM from over a year ago. Although structurally
similar, we’ve heavily customized it for DeepSeek models, making it difficult to extend for broader use cases.</li>
<li><strong>Infrastructure Dependencies</strong>: The engine is tightly coupled with our internal infrastructure, including cluster
management tools, making it impractical for public deployment without significant modifications.</li>
<li><strong>Limited Maintenance Bandwidth</strong>: As a small research team focused on developing better models, we lack bandwidth to
maintain a large open-source project.</li>
</ul>
<p dir="auto">Considering these challenges, we’ve decided to collaborate with existing open-source projects as more sustainable alternatives.</p>
<p dir="auto">Moving forward, we will work closely with existing open-source projects to:</p>
<ul dir="auto">
<li><strong>Extract Standalone Features</strong>: Modularize and contribute reusable components as independent libraries.</li>
<li><strong>Share Optimizations</strong>: Contribute design improvements and implementation details directly.</li>
</ul>
<p dir="auto">We are profoundly grateful for the open-source movement - from operating systems and programming languages to machine
learning frameworks and inference engines. It’s an honor to contribute to this thriving ecosystem and to see our models
and code embraced by the community. Together, let’s push the boundaries of AGI and ensure its benefits serve all of
humanity.</p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto"><strong>To clarify, this article outlines our approach to open-sourcing of our DeepSeek-Inference-Engine codebase only.
Regarding future model releases, we maintain an open and collaborative stance towards both the open-source community
and hardware partners.
We commit to proactively synchronizing inference-related engineering efforts prior to new model launches, with the
goal of enabling the community to achieve state-of-the-art (SOTA) support from Day-0. Our ultimate aim is to foster a
synchronized ecosystem where cutting-edge AI capabilities can be seamlessly implemented across diverse hardware
platforms upon official model releases.</strong></p>
</div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SQLite File Format Viewer (155 pts)]]></title>
            <link>https://sqlite-internal.pages.dev</link>
            <guid>43682006</guid>
            <pubDate>Mon, 14 Apr 2025 14:55:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sqlite-internal.pages.dev">https://sqlite-internal.pages.dev</a>, See on <a href="https://news.ycombinator.com/item?id=43682006">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[How to Bike Across the Country (140 pts)]]></title>
            <link>https://www.brooks.team/posts/how-to-bike-across-the-country/</link>
            <guid>43681936</guid>
            <pubDate>Mon, 14 Apr 2025 14:49:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.brooks.team/posts/how-to-bike-across-the-country/">https://www.brooks.team/posts/how-to-bike-across-the-country/</a>, See on <a href="https://news.ycombinator.com/item?id=43681936">Hacker News</a></p>
<div id="readability-page-1" class="page">
  
  
  <p>Loading...</p>

  
  
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[A hackable AI assistant using a single SQLite table and a handful of cron jobs (473 pts)]]></title>
            <link>https://www.geoffreylitt.com/2025/04/12/how-i-made-a-useful-ai-assistant-with-one-sqlite-table-and-a-handful-of-cron-jobs</link>
            <guid>43681287</guid>
            <pubDate>Mon, 14 Apr 2025 13:52:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.geoffreylitt.com/2025/04/12/how-i-made-a-useful-ai-assistant-with-one-sqlite-table-and-a-handful-of-cron-jobs">https://www.geoffreylitt.com/2025/04/12/how-i-made-a-useful-ai-assistant-with-one-sqlite-table-and-a-handful-of-cron-jobs</a>, See on <a href="https://news.ycombinator.com/item?id=43681287">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>There’s a lot of hype these days around patterns for building with AI. Agents, memory, RAG, assistants—so many buzzwords! But the reality is, <strong>you don’t need fancy techniques or libraries to build useful personal tools with LLMs.</strong></p>

<p>In this short post, I’ll show you how I built a useful AI assistant for my family using a dead simple architecture: a single SQLite table of memories, and a handful of cron jobs for ingesting memories and sending updates, all hosted on <a href="https://www.val.town/">Val.town</a>. The whole thing is so simple that you can easily copy and extend it yourself.</p>

<h2 id="meet-stevens">Meet Stevens</h2>

<p>The assistant is called Stevens, named after the butler in the great Ishiguro novel <a href="https://en.wikipedia.org/wiki/The_Remains_of_the_Day">Remains of the Day</a>. Every morning it sends a brief to me and my wife via Telegram, including our calendar schedules for the day, a preview of the weather forecast, any postal mail or packages we’re expected to receive, and any reminders we’ve asked it to keep track of. All written up nice and formally, just like you’d expect from a proper butler.</p>

<p>Here’s an example. (I’ll use fake data throughout this post, beacuse our actual updates contain private information.)</p>

<p><img src="https://www.geoffreylitt.com/images/article_images/stevens/telegram.png?1744560139" alt=""></p>

<p>Beyond the daily brief, we can communicate with Stevens on-demand—we can forward an email with some important info, or just leave a reminder or ask a question via Telegram chat.</p>

<p><img src="https://www.geoffreylitt.com/images/article_images/stevens/coffee.png?1744560139" alt=""></p>

<p>That’s Stevens. It’s rudimentary, but already more useful to me than Siri!</p>

<h2 id="behind-the-scenes">Behind the scenes</h2>

<p>Let’s break down the simple architecture behind Stevens. The whole thing is hosted on <a href="https://www.val.town/">Val.town</a>, a lovely platform that offers SQLite storage, HTTP request handling, scheduled cron jobs, and inbound/outbound email: a perfect set of capabilities for this project.</p>

<p>First, how does Stevens know what goes in the morning brief? The key is the butler’s notebook, a log of everything that Stevens knows. There’s an admin view where we can see the notebook contents—let’s peek and see what’s in there:</p>

<p><img src="https://www.geoffreylitt.com/images/article_images/stevens/notebook.png?1744560139" alt=""></p>

<p>You can see some of the entries that fed into the morning brief above—for example, the parent-teacher conference has a log entry.</p>

<p>In addition to some text, entries can have a <em>date</em> when they are expected to be relevant.  There are also entries with no date that serve as general background info, and are always included. You can see these particular background memories came from a Telegram chat, because Stevens does an intake interview via Telegram when you first get started:</p>

<p><img src="https://www.geoffreylitt.com/images/article_images/stevens/background.png?1744560139" alt=""></p>

<p><strong>With this notebook in hand, sending the morning brief is easy</strong>: just run a cron job which makes a call to the Claude API to write the update, and then sends the text to a Telegram thread. As context for the model, we include any log entries dated for the coming week, as well as the undated background entries.</p>

<p>Under the hood, the “notebook” is just a single SQLite table with a few columns. Here’s a more boring view of things:</p>

<p><img src="https://www.geoffreylitt.com/images/article_images/stevens/db.png?1744560139" alt=""></p>

<p>But wait: how did the various log entries get there in the first place? In the admin view, we can watch Stevens buzzing around entering things into the log from various sources:</p>

<video width="100%" controls="">
  <source src="https://www.geoffreylitt.com/images/article_images/stevens/cron.mp4" type="video/mp4">
</video>

<p>This is just some data importers populating the table:</p>

<ul>
<li>An hourly data pull from the Google Calendar API</li>
<li>An hourly check of the local weather forecast using a weather API</li>
<li>I forward <a href="https://www.usps.com/manage/informed-delivery.htm">USPS Informed Delivery</a> containing scans of our postal mail, and Stevens OCRs them using Claude</li>
<li>Inbound Telegram and email messages can also result in log entries</li>
<li>Every week, some “fun facts” get added into the log, as a way of adding some color to future daily updates.</li>
</ul>

<p><strong>This system is easily extensible with new importers.</strong> An importer is just any process that adds/edits memories in the log. The memory contents can be any arbitrary text, since they’ll just be fed back into an LLM later anyways.</p>

<h2 id="reflections">Reflections</h2>

<p>A few quick reflections on this project:</p>

<p><strong>It’s very useful for personal AI tools to have access to broader context from other information sources.</strong> Awareness of things like my calendar and the weather forecast turns a dumb chatbot into a useful assistant. ChatGPT recently added memory of past conversations, but there’s lots of information not stored within that silo. I’ve <a href="https://x.com/geoffreylitt/status/1810442615264796864">written before</a> about how the endgame for AI-driven personal software isn’t more app silos, it’s small tools operating on a shared pool of context about our lives.</p>

<p><strong>“Memory” can start simple.</strong> In this case, the use cases of the assistant are limited, and its information is inherently time-bounded, so it’s fairly easy to query for the relevant context to give to the LLM. It also helps that some modern models have long context windows. As the available information grows in size, RAG and <a href="https://x.com/sjwhitmore/status/1910439061615239520">fancier</a> <a href="https://arxiv.org/abs/2304.03442">approaches</a> to memory may be needed, but you can start simple.</p>

<p><strong>Vibe coding enables sillier projects.</strong> Initially, Stevens spoke with a dry tone, like you might expect from a generic Apple or Google product. But it turned out it was just more <em>fun</em> to have the assistant speak like a formal butler. This was trivial to do, just a couple lines in a prompt. Similarly, I decided to make the admin dashboard views feel like a video game, because why not? I generated the image assets in ChatGPT, and vibe coded the whole UI in Cursor + Claude 3.7 Sonnet; it took a tiny bit of extra effort in exchange for a lot more fun.</p>

<h2 id="try-it-yourself">Try it yourself</h2>

<p>Stevens isn’t a product you can run out of the box, it’s just a personal project I made for myself.</p>

<p>But if you’re curious, you can check out the code and fork the project <a href="https://www.val.town/x/geoffreylitt/stevensDemo">here</a>. You should be able to apply this basic pattern—a single memories table and an extensible constellation of cron jobs—to do lots of other useful things.</p>

<p>I recommend editing the code using your AI editor of choice with the <a href="https://github.com/pomdtr/vt">Valtown CLI</a> to sync to local filesystem.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta antitrust trial kicks off in federal court (238 pts)]]></title>
            <link>https://www.axios.com/pro/tech-policy/2025/04/14/ftc-meta-antitrust-trial-kicks-off-in-federal-court</link>
            <guid>43680957</guid>
            <pubDate>Mon, 14 Apr 2025 13:18:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.axios.com/pro/tech-policy/2025/04/14/ftc-meta-antitrust-trial-kicks-off-in-federal-court">https://www.axios.com/pro/tech-policy/2025/04/14/ftc-meta-antitrust-trial-kicks-off-in-federal-court</a>, See on <a href="https://news.ycombinator.com/item?id=43680957">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content"><div data-theme="pro"><div data-vars-content-id="cff1ef1d-a5d1-4ba0-b14e-f2c9500f3c62" data-vars-event-name="story_view" data-vars-deprecated-content-id="cff1ef1d-a5d1-4ba0-b14e-f2c9500f3c62" data-vars-deprecated-headline="Meta antitrust trial kicks off in federal court" data-vars-deprecated-category="story" data-vars-deprecated-sub-category="story" data-vars-headline="Meta antitrust trial kicks off in federal court" data-vars-latitude="47.23" data-vars-longitude="8.84" data-vars-postal-code="8645"><div><p><span>Axios Pro Exclusive Content</span></p><div><p><img alt="" loading="lazy" width="52" height="52" decoding="async" data-nimg="1" srcset="https://www.axios.com/_next/image?url=https%3A%2F%2Fimages.axios.com%2FC_Z_frNtxeJxkMDSsXJSCdXj6w0%3D%2F52x0%2Fsmart%2F2023%2F03%2F24%2F1679666155723.jpg&amp;w=64&amp;q=75 1x, https://www.axios.com/_next/image?url=https%3A%2F%2Fimages.axios.com%2FC_Z_frNtxeJxkMDSsXJSCdXj6w0%3D%2F52x0%2Fsmart%2F2023%2F03%2F24%2F1679666155723.jpg&amp;w=128&amp;q=75 2x" src="https://www.axios.com/_next/image?url=https%3A%2F%2Fimages.axios.com%2FC_Z_frNtxeJxkMDSsXJSCdXj6w0%3D%2F52x0%2Fsmart%2F2023%2F03%2F24%2F1679666155723.jpg&amp;w=128&amp;q=75"></p></div></div><figure data-cy="au-image" data-chromatic="ignore"><img data-cy="StoryImage" alt="Mark Zuckerberg taking an oath in Congress with a black backdrop" fetchpriority="high" width="1920" height="1080" decoding="async" data-nimg="1" sizes="100vw" srcset="https://images.axios.com/dZ2sVpFnmwMBZaPT7ZQc8qfwTSw=/0x0:7555x4250/640x360/2025/04/11/1744384586720.jpg?w=640 640w, https://images.axios.com/mIftE3zydXa1hmCjzI7bWDEyCOc=/0x0:7555x4250/1920x1080/2025/04/11/1744384586720.jpg?w=750 750w, https://images.axios.com/mIftE3zydXa1hmCjzI7bWDEyCOc=/0x0:7555x4250/1920x1080/2025/04/11/1744384586720.jpg?w=828 828w, https://images.axios.com/mIftE3zydXa1hmCjzI7bWDEyCOc=/0x0:7555x4250/1920x1080/2025/04/11/1744384586720.jpg?w=1080 1080w, https://images.axios.com/mIftE3zydXa1hmCjzI7bWDEyCOc=/0x0:7555x4250/1920x1080/2025/04/11/1744384586720.jpg?w=1200 1200w, https://images.axios.com/mIftE3zydXa1hmCjzI7bWDEyCOc=/0x0:7555x4250/1920x1080/2025/04/11/1744384586720.jpg?w=1920 1920w, https://images.axios.com/mIftE3zydXa1hmCjzI7bWDEyCOc=/0x0:7555x4250/1920x1080/2025/04/11/1744384586720.jpg?w=2048 2048w, https://images.axios.com/mIftE3zydXa1hmCjzI7bWDEyCOc=/0x0:7555x4250/1920x1080/2025/04/11/1744384586720.jpg?w=3840 3840w" src="https://images.axios.com/mIftE3zydXa1hmCjzI7bWDEyCOc=/0x0:7555x4250/1920x1080/2025/04/11/1744384586720.jpg?w=3840"><figcaption data-cy="image-caption"><p>Mark Zuckerberg on Jan. 31, 2024 on Capitol Hill. Photo: Tom Williams/CQ-Roll Call, Inc via Getty Images</p></figcaption></figure><div data-chromatic="ignore"><p><span data-schema="smart-brevity"><p>The Federal Trade Commission and Meta will square off in a long-awaited antitrust trial on Monday over the tech giant's past acquisitions of WhatsApp and Instagram.</p><p><strong>Why it matters: </strong>The trial will be a major test of the FTC's ability to take on tech behemoths for<strong> </strong>allegedly breaking antitrust law and comes as Meta CEO Mark Zuckerberg<strong> </strong>tries to <a data-vars-link-text="cozy up" data-vars-click-url="https://www.axios.com/pro/tech-policy/2025/04/03/zuckerberg-gets-closer-to-dc" data-vars-content-id="cff1ef1d-a5d1-4ba0-b14e-f2c9500f3c62" data-vars-headline="Meta antitrust trial kicks off in federal court" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/pro/tech-policy/2025/04/03/zuckerberg-gets-closer-to-dc" target="_self">cozy up</a> to President Trump.</p></span></p><ul><li>The case could result in Meta having to spin off WhatsApp and Instagram. </li><li>If Meta wins, the company would be vindicated in its longtime argument that the two apps couldn't have thrived without the company's backing and that Meta has plenty of competition in the social networking space.</li><li>The lawsuit's main question is whether Meta acted illegally in its WhatsApp and Instagram acquisitions, done in 2014 and 2012.</li></ul><p><strong>Federal judge <a data-vars-link-text="James Boasberg" data-vars-click-url="https://www.axios.com/2025/03/18/judge-trump-impeachment-james-boasberg" data-vars-content-id="cff1ef1d-a5d1-4ba0-b14e-f2c9500f3c62" data-vars-headline="Meta antitrust trial kicks off in federal court" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/2025/03/18/judge-trump-impeachment-james-boasberg" target="_self">James Boasberg</a> </strong>will hear the case, which was <a data-vars-link-text="first filed" data-vars-click-url="https://www.axios.com/2020/12/09/ftc-sues-facebookstate-ags-sue-facebook" data-vars-content-id="cff1ef1d-a5d1-4ba0-b14e-f2c9500f3c62" data-vars-headline="Meta antitrust trial kicks off in federal court" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/2020/12/09/ftc-sues-facebookstate-ags-sue-facebook" target="_self">first filed</a> in December 2020 under Trump's first administration.</p><ul><li>A judge <a data-vars-link-text="dismissed" data-vars-click-url="https://www.axios.com/2021/06/28/judge-dismisses-ftcs-antitrust-complaint-against-facebook" data-vars-content-id="cff1ef1d-a5d1-4ba0-b14e-f2c9500f3c62" data-vars-headline="Meta antitrust trial kicks off in federal court" data-vars-event-category="story" data-vars-sub-category="story" data-vars-item="in_content_link" href="https://www.axios.com/2021/06/28/judge-dismisses-ftcs-antitrust-complaint-against-facebook" target="_self">dismissed</a> that original lawsuit in June 2021 for lacking sufficient evidence of Meta's market power.</li><li>Under Lina Khan, FTC chair under President Biden, the case was re-filed and expanded in August 2021. </li><li>Boasberg allowed that case to proceed in January 2022, and rejected a bid from Meta<strong> </strong>last year to have the case dismissed, paving way for this trial.</li></ul><p><strong>What they're saying: </strong>The FTC says Meta has illegally monopolized the market for "personal social networking services" through those acquisitions, in a bid to "neutralize" its rivals, per legal filings. </p><ul><li>"Acquiring these competitive threats has enabled Facebook to sustain its dominance—to the detriment of competition and users—not by competing on the merits, but by avoiding competition," the FTC wrote in a filing.</li><li>Meta could have chosen to compete with then-upstart photo sharing app Instagram in 2012, a senior FTC official said on a call with reporters ahead of the trial, but instead it bought it, and did the same with WhatsApp. </li></ul><p><strong>The other side: </strong>"The FTC's lawsuit against Meta defies reality. The evidence at trial will show what every 17-year-old in the world knows: Instagram, Facebook and WhatsApp compete with Chinese-owned TikTok, YouTube, X, iMessage and many others," Meta spokesperson Chris Sgro said in a statement.</p><ul><li>"More than 10 years after the FTC reviewed and cleared our acquisitions, the Commission's action in this case sends the message that no deal is ever truly final."</li><li>"Regulators should be supporting American innovation, rather than seeking to break up a great American company and further advantaging China on critical issues like AI."</li></ul><p><strong>What we're watching:</strong> The case could take eight weeks or more. There'll be a slew of high-profile witnesses, including Zuckerberg.</p><ul><li>Former COO Sheryl Sandberg, chief technology officer Andrew Bosworth, and WhatsApp and Instagram leadership past and present, will also testify, per court filings.</li><li>Representatives from Snap, TikTok and Pinterest are expected to testify as well.</li></ul><p><strong>Our thought bubble: </strong>Tech firms have gotten much closer with Trump in his second term.</p><ul><li>But unless Trump tells the FTC to shut the whole trial down, Meta's overtures may not do the company any good here.</li></ul></div></div><h5>Go deeper</h5></div><div data-theme="pro" data-cy="pro-paywall" data-vars-event-name="paywall_view" data-vars-content-id="cff1ef1d-a5d1-4ba0-b14e-f2c9500f3c62" data-vars-latitude="47.23" data-vars-longitude="8.84" data-vars-postal-code="8645" data-vars-deprecated-category="cta" data-vars-deprecated-experiment="pro-paywall" data-vars-deprecated-experiment-variant="tech-policy"><p>This article is currently free.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DolphinGemma: How Google AI is helping decode dolphin communication (247 pts)]]></title>
            <link>https://blog.google/technology/ai/dolphingemma/</link>
            <guid>43680899</guid>
            <pubDate>Mon, 14 Apr 2025 13:12:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.google/technology/ai/dolphingemma/">https://blog.google/technology/ai/dolphingemma/</a>, See on <a href="https://news.ycombinator.com/item?id=43680899">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

    
    





    

    
      

<div data-analytics-module="{
    &quot;module_name&quot;: &quot;Hero Menu&quot;,
    &quot;section_header&quot;: &quot;DolphinGemma: How Google AI is helping decode dolphin communication&quot;
  }">
  
  <div>
      <div>
          
            <p>Apr 14, 2025</p>
          
          
            <p data-reading-time-render="">[[read-time]] min read</p>
          
        </div>
      
        <p>
          DolphinGemma, a large language model developed by Google, is helping scientists study how dolphins communicate — and hopefully find out what they're saying, too.
        </p>
      
    </div>
  
  <div>
      
  
    <figure>
        <picture>
            


    

    
        <source media="(max-resolution: 1.5dppx)" sizes="122px" srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1517757973355.max-122x92.format-webp.webp 122w">
    
        <source media="(min-resolution: 1.5dppx)" sizes="244px" srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1517757973355.max-244x184.format-webp.webp 244w">
    

    <img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1517757973355.max-244x184.format-webp.webp" alt="thad headshot" sizes=" 122px,  244px" srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1517757973355.max-122x92.format-webp.webp 122w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/1517757973355.max-244x184.format-webp.webp 244w" data-target="image" loading="lazy">
    


        </picture>
    </figure>



<div>
  <p>Dr. Thad Starner</p>
  
    <p>
      Google DeepMind Research Scientist and Georgia Tech Professor
    </p>
  
  
</div>

    </div>
</div>

    

    
      


  <uni-youtube-player-hero index="0" thumbnail-alt="DolphinGemma text over a picture of dolphins" component-title="DolphinGemma: How Google AI is helping decode dolphin communication" video-id="T8GdEVVvXyE" video-type="video" image="DolphinGemma_SocialExplainers_16x9_DolphinGemma" video-image-url-lazy="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_SocialExplainers_16x.width-100.format-webp.webp" video-image-url-mobile="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_SocialExplainers_16x.width-700.format-webp.webp" video-image-url-desktop="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_SocialExplainers_16.width-1000.format-webp.webp">
  </uni-youtube-player-hero>


    

    
    <div data-reading-time="true" data-component="uni-article-body">

            
              





<uni-article-speakable page-title="DolphinGemma: How Google AI is helping decode dolphin communication" listen-to-article="Listen to article" data-date-modified="2025-04-14T17:08:29.525540+00:00" data-tracking-ids="G-HGNBTNCHCQ,G-6NKTLKV14N" data-voice-list="en.ioh-pngnat:Cyan,en.usb-pngnat:Lime" data-script-src="https://www.gstatic.com/readaloud/player/web/api/js/api.js"></uni-article-speakable>

            

            
            
<!--article text-->

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;DolphinGemma: How Google AI is helping decode dolphin communication&quot;
         }"><p data-block-key="6q2c0">For decades, understanding the clicks, whistles and burst pulses of dolphins has been a scientific frontier. What if we could not only listen to dolphins, but also understand the patterns of their complex communication well enough to generate realistic responses?</p><p data-block-key="4o0o1">Today, on National Dolphin Day, Google, in collaboration with researchers at Georgia Tech and the field research of the <a href="https://www.wilddolphinproject.org/">Wild Dolphin Project</a> (WDP), is announcing progress on DolphinGemma: a foundational AI model trained to learn the structure of dolphin vocalizations and generate novel dolphin-like sound sequences. This approach in the quest for interspecies communication pushes the boundaries of AI and our potential connection with the marine world.</p></div>
  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;DolphinGemma: How Google AI is helping decode dolphin communication&quot;
         }"><h2 data-block-key="6q2c0">Researching dolphin society for decades</h2><p data-block-key="ae8k9">Understanding any species requires deep context, and that's one of the many things the WDP provides. Since 1985, WDP has conducted the world's longest-running underwater dolphin research project, studying a specific community of wild Atlantic spotted dolphins (Stenella frontalis) in the Bahamas across generations. This non-invasive, "In Their World, on Their Terms" approach yields a rich, unique dataset: decades of underwater video and audio meticulously paired with individual dolphin identities, life histories and observed behaviors.</p></div>
  

  
    






<uni-image-full-width alignment="full" alt-text="Dolphins swimming in the water" external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="DolphinGemma: How Google AI is helping decode dolphin communication" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="27106">A pod of Atlantic spotted dolphins, Stenella frontalis</p>
    </div>
  
  
    <p><img alt="Dolphins swimming in the water" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/dolphins.width-100.format-webp.webp" loading="lazy" data-loading="{
            &quot;mobile&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/dolphins.width-500.format-webp.webp&quot;,
            &quot;desktop&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/dolphins.width-1000.format-webp.webp&quot;
          }">
    </p>
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;DolphinGemma: How Google AI is helping decode dolphin communication&quot;
         }"><p data-block-key="iocbw">A primary focus for WDP is observing and analyzing the dolphins' natural communication and social interactions. Working underwater allows researchers to directly link sounds to specific behaviors in ways surface observation cannot. For decades, they have correlated sound types with behavioral contexts. Here are some examples:</p><ul><li data-block-key="fu0nf">Signature whistles (unique names) that can be used by mothers and calves to reunite</li><li data-block-key="b63q5">Burst-pulse "squawks" often seen during fights</li><li data-block-key="bseip">Click "buzzes" often used during courtship or chasing sharks</li></ul><p data-block-key="2ar36">Knowing the individual dolphins involved is crucial for accurate interpretation. The ultimate goal of this observational work is to understand the structure and potential meaning within these natural sound sequences — seeking patterns and rules that might indicate language. This long-term analysis of natural communication forms the bedrock of WDP's research and provides essential context for any AI analysis.</p></div>
  

  
    






<uni-image-full-width alignment="full" alt-text="A split image: left, a dolphin touching the sandy seabed underwater; right, a spectrogram with bright vertical streaks indicating high-frequency sounds." external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="DolphinGemma: How Google AI is helping decode dolphin communication" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="s704z">Left: A mother spotted dolphin observes her calf while foraging. She will use her unique signature whistle to call the calf back after he is finished. Right: Spectrogram to visualize the whistle.</p>
    </div>
  
  
    <p><img alt="A split image: left, a dolphin touching the sandy seabed underwater; right, a spectrogram with bright vertical streaks indicating high-frequency sounds." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Keyword1_RD3_V02.width-100.format-webp.webp" loading="lazy" data-loading="{
            &quot;mobile&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Keyword1_RD3_V02.width-500.format-webp.webp&quot;,
            &quot;desktop&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Keyword1_RD3_V02.width-1000.format-webp.webp&quot;
          }">
    </p>
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;DolphinGemma: How Google AI is helping decode dolphin communication&quot;
         }"><h2 data-block-key="iocbw">Introducing DolphinGemma</h2><p data-block-key="2m8ks">Analyzing dolphins' natural, complex communication is a monumental task, and WDP's vast, labeled dataset provides a unique opportunity for cutting-edge AI.</p><p data-block-key="bgerj">Enter DolphinGemma. Developed by Google, this AI model makes use of specific Google audio technologies: the SoundStream tokenizer efficiently represents dolphin sounds, which are then processed by a model architecture suited for complex sequences. This ~400M parameter model is optimally-sized to run directly on the Pixel phones WDP uses in the field.</p></div>
  

  
    






<uni-image-full-width alignment="full" alt-text="Two spectrograms: left shows three arching sound patterns; right shows a more uniform sound pattern." external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="DolphinGemma: How Google AI is helping decode dolphin communication" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="30sb2">Left: Whistles (left) and burst pulses (right) generated during early testing of DolphinGemma.</p>
    </div>
  
  
    <p><img alt="Two spectrograms: left shows three arching sound patterns; right shows a more uniform sound pattern." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Keyword2_RD3_V01.width-100.format-webp.webp" loading="lazy" data-loading="{
            &quot;mobile&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Keyword2_RD3_V01.width-500.format-webp.webp&quot;,
            &quot;desktop&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Keyword2_RD3_V01.width-1000.format-webp.webp&quot;
          }">
    </p>
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;DolphinGemma: How Google AI is helping decode dolphin communication&quot;
         }"><p data-block-key="3p158">This model builds upon insights from <a href="https://ai.google.dev/gemma">Gemma</a>, Google’s collection of lightweight, state-of-the-art open models that are built from the same research and technology that powers our Gemini models. Trained extensively on WDP’s acoustic database of wild Atlantic spotted dolphins, DolphinGemma functions as an audio-in, audio-out model, processes sequences of natural dolphin sounds to identify patterns, structure and ultimately predict the likely subsequent sounds in a sequence, much like how large language models for human language predict the next word or token in a sentence.</p><p data-block-key="a754e">WDP is beginning to deploy DolphinGemma this field season with immediate potential benefits. By identifying recurring sound patterns, clusters and reliable sequences, the model can help researchers uncover hidden structures and potential meanings within the dolphins' natural communication — a task previously requiring immense human effort. Eventually, these patterns, augmented with synthetic sounds created by the researchers to refer to objects with which the dolphins like to play, may establish a shared vocabulary with the dolphins for interactive communication.</p></div>
  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;DolphinGemma: How Google AI is helping decode dolphin communication&quot;
         }"><h2 data-block-key="3p158">Using Pixel phones to listen to and analyze dolphin sounds</h2><p data-block-key="7vd3s">In addition to analyzing natural communication, WDP is also pursuing a distinct, parallel path: exploring potential two-way interaction using technology in the ocean. This effort led to the development of the <a href="https://www.wilddolphinproject.org/our-research/chat-research/">CHAT</a> (Cetacean Hearing Augmentation Telemetry) system, in partnership with the Georgia Institute of Technology. CHAT is an underwater computer designed not to directly decipher the dolphins' complex natural language, but to establish a simpler, shared vocabulary.</p><p data-block-key="6avcn">The concept first relies on associating novel, synthetic whistles (created by CHAT, distinct from natural dolphin sounds) with specific objects the dolphins enjoy, like sargassum, seagrass or scarves the researchers use. By demonstrating the system between humans, researchers hope the naturally curious dolphins will learn to mimic the whistles to request these items. Eventually, as more of the dolphins’ natural sounds are understood, they can also be added to the system.</p></div>
  

  
    
  
    


  <uni-youtube-player-article index="10" thumbnail-alt="CHAT explainer video" video-id="YhopeQKbpZA" video-type="video">
  </uni-youtube-player-article>


  


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;DolphinGemma: How Google AI is helping decode dolphin communication&quot;
         }"><p data-block-key="3p158">To enable two-way interaction, the CHAT system first needs to:</p><ol><li data-block-key="9is9o">Hear the mimic accurately amid ocean noise.</li><li data-block-key="5qsu4">Identify which whistle was mimicked in real-time.</li><li data-block-key="48nl7">Inform the researcher (via bone-conducting headphones that work underwater) which object the dolphin "requested."</li><li data-block-key="2f5o">Enable the researcher to respond quickly by offering the correct object, reinforcing the connection.</li></ol><p data-block-key="c9b4">A Google Pixel 6 handled the high-fidelity analysis of dolphin sounds in real time. The upcoming generation, centered around a Google Pixel 9 (research slated for summer 2025), builds on this effort by integrating speaker/microphone functions and using the phone's advanced processing to run both deep learning models and template matching algorithms simultaneously.</p></div>
  

  
    






<uni-image-full-width alignment="full" alt-text="Two portraits: left, a woman on a boat holding a device; right, a man indoors wearing headphones and holding a similar device." external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="DolphinGemma: How Google AI is helping decode dolphin communication" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="pdphj">Left: Dr. Denise Herzing wearing “Chat Senior, 2012”, Right: Georgia Tech PhD Student Charles Ramey wearing “Chat Junior, 2025”</p>
    </div>
  
  
    <p><img alt="Two portraits: left, a woman on a boat holding a device; right, a man indoors wearing headphones and holding a similar device." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Researchers_RD2_V01.width-100.format-webp.webp" loading="lazy" data-loading="{
            &quot;mobile&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Researchers_RD2_V01.width-500.format-webp.webp&quot;,
            &quot;desktop&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DolphinGemma_Researchers_RD2_V01.width-1000.format-webp.webp&quot;
          }">
    </p>
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;DolphinGemma: How Google AI is helping decode dolphin communication&quot;
         }">
        <p data-block-key="su54v">Using Pixel smartphones dramatically reduces the need for custom hardware, improves system maintainability, lowers power consumption and shrinks the device's cost and size — crucial advantages for field research in the open ocean. Meanwhile, DolphinGemma’s predictive power can help CHAT anticipate and identify potential mimics earlier in the vocalization sequence, increasing the speed at which researchers can react to the dolphins and making interactions more fluid and reinforcing.</p>
      </div>
  

  
    






<uni-image-full-width alignment="full" alt-text="Pixel phone inside a case hooked up to cables" external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="DolphinGemma: How Google AI is helping decode dolphin communication" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="qfo9j">A Google Pixel 9 inside the latest CHAT system hardware.</p>
    </div>
  
  
    <p><img alt="Pixel phone inside a case hooked up to cables" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CHAT_Pixel.width-100.format-webp.webp" loading="lazy" data-loading="{
            &quot;mobile&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CHAT_Pixel.width-500.format-webp.webp&quot;,
            &quot;desktop&quot;: &quot;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CHAT_Pixel.width-1000.format-webp.webp&quot;
          }">
    </p>
  
</uni-image-full-width>


  

  
    <div data-component="uni-article-paragraph" role="presentation" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;DolphinGemma: How Google AI is helping decode dolphin communication&quot;
         }"><h2 data-block-key="su54v">Sharing DolphinGemma with the research community</h2><p data-block-key="2ad01">Recognizing the value of collaboration in scientific discovery, we’re planning to share DolphinGemma as an open model this summer. While trained on Atlantic spotted dolphin sounds, we anticipate its potential utility for researchers studying other cetacean species, like bottlenose or spinner dolphins. Fine-tuning may be required for different species' vocalizations, and the open nature of the model facilitates this adaptation.</p><p data-block-key="40nps">By providing tools like DolphinGemma, we hope to give researchers worldwide the tools to mine their own acoustic datasets, accelerate the search for patterns and collectively deepen our understanding of these intelligent marine mammals.</p><p data-block-key="e2jq7">The journey to understanding dolphin communication is long, but the combination of dedicated field research by WDP, engineering expertise from Georgia Tech and the power of Google's technology is opening exciting new possibilities. We're not just listening anymore. We're beginning to understand the patterns within the sounds, paving the way for a future where the gap between human and dolphin communication might just get a little smaller.</p><p data-block-key="esrl0">You can learn more about the<a href="https://www.wilddolphinproject.org/"> Wild Dolphin Project</a> on their website.</p></div>
  


            
            

            
              




            
          </div>
  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meilisearch – search engine API bringing AI-powered hybrid search (127 pts)]]></title>
            <link>https://github.com/meilisearch/meilisearch</link>
            <guid>43680699</guid>
            <pubDate>Mon, 14 Apr 2025 12:46:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/meilisearch/meilisearch">https://github.com/meilisearch/meilisearch</a>, See on <a href="https://news.ycombinator.com/item?id=43680699">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a href="https://www.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=logo#gh-light-mode-only" rel="nofollow">
    <img src="https://github.com/meilisearch/meilisearch/raw/main/assets/meilisearch-logo-light.svg?sanitize=true#gh-light-mode-only">
  </a>
  <a href="https://www.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=logo#gh-dark-mode-only" rel="nofollow">
    <img src="https://github.com/meilisearch/meilisearch/raw/main/assets/meilisearch-logo-dark.svg?sanitize=true#gh-dark-mode-only">
  </a>
</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">
  <a href="https://www.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav" rel="nofollow">Website</a> |
  <a href="https://roadmap.meilisearch.com/tabs/1-under-consideration" rel="nofollow">Roadmap</a> |
  <a href="https://www.meilisearch.com/pricing?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav" rel="nofollow">Meilisearch Cloud</a> |
  <a href="https://blog.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav" rel="nofollow">Blog</a> |
  <a href="https://www.meilisearch.com/docs?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav" rel="nofollow">Documentation</a> |
  <a href="https://www.meilisearch.com/docs/faq?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav" rel="nofollow">FAQ</a> |
  <a href="https://discord.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav" rel="nofollow">Discord</a>
</h4><a id="user-content---website---roadmap---meilisearch-cloud---blog---documentation---faq---discord" aria-label="Permalink: Website |
  Roadmap |
  Meilisearch Cloud |
  Blog |
  Documentation |
  FAQ |
  Discord" href="#--website---roadmap---meilisearch-cloud---blog---documentation---faq---discord"></a></p>
<p dir="auto">
  <a href="https://deps.rs/repo/github/meilisearch/meilisearch" rel="nofollow"><img src="https://camo.githubusercontent.com/0b51de54cdba053bdde0478c1ffc91dbc30d279d73e71c78088e77e98f41735e/68747470733a2f2f646570732e72732f7265706f2f6769746875622f6d65696c697365617263682f6d65696c697365617263682f7374617475732e737667" alt="Dependency status" data-canonical-src="https://deps.rs/repo/github/meilisearch/meilisearch/status.svg"></a>
  <a href="https://github.com/meilisearch/meilisearch/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/60e4fe2b4b86adf9d06832e9dcbbe27eddf7f46bc4af612f3dda01c9907a7a07/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d696e666f726d6174696f6e616c" alt="License" data-canonical-src="https://img.shields.io/badge/license-MIT-informational"></a>
  <a href="https://github.com/meilisearch/meilisearch/queue"><img alt="Merge Queues enabled" src="https://camo.githubusercontent.com/4fc74073767004f08ce185305a7295b9e062871fb144ca0fa35592b02a3fcac0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4d657267655f5175657565732d656e61626c65642d2532333537636636303f6c6f676f3d676974687562" data-canonical-src="https://img.shields.io/badge/Merge_Queues-enabled-%2357cf60?logo=github"></a>
</p>
<p name="user-content-ph-banner" dir="auto">
  <a href="https://www.producthunt.com/posts/meilisearch-ai" rel="nofollow">
    <img src="https://github.com/meilisearch/meilisearch/raw/main/assets/ph-banner.png" alt="Meilisearch AI-powered search general availability announcement on ProductHunt">
  </a>
</p>
<p dir="auto">⚡ A lightning-fast search engine that fits effortlessly into your apps, websites, and workflow 🔍</p>
<p dir="auto"><a href="https://www.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=intro" rel="nofollow">Meilisearch</a> helps you shape a delightful search experience in a snap, offering features that work out of the box to speed up your workflow.</p>
<p name="user-content-demo" dir="auto">
  <a href="https://where2watch.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demo-gif#gh-light-mode-only" rel="nofollow">
    <img src="https://github.com/meilisearch/meilisearch/raw/main/assets/demo-light.gif#gh-light-mode-only" alt="A bright colored application for finding movies screening near the user" data-animated-image="">
  </a>
  <a href="https://where2watch.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demo-gif#gh-dark-mode-only" rel="nofollow">
    <img src="https://github.com/meilisearch/meilisearch/raw/main/assets/demo-dark.gif#gh-dark-mode-only" alt="A dark colored application for finding movies screening near the user" data-animated-image="">
  </a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🖥 Examples</h2><a id="user-content--examples" aria-label="Permalink: 🖥 Examples" href="#-examples"></a></p>
<ul dir="auto">
<li><a href="https://where2watch.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=organization" rel="nofollow"><strong>Movies</strong></a> — An application to help you find streaming platforms to watch movies using <a href="https://www.meilisearch.com/solutions/hybrid-search?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos" rel="nofollow">hybrid search</a>.</li>
<li><a href="https://ecommerce.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos" rel="nofollow"><strong>Ecommerce</strong></a> — Ecommerce website using disjunctive <a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/faceted_search?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos" rel="nofollow">facets</a>, range and rating filtering, and pagination.</li>
<li><a href="https://music.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos" rel="nofollow"><strong>Songs</strong></a> — Search through 47 million of songs.</li>
<li><a href="https://saas.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos" rel="nofollow"><strong>SaaS</strong></a> —&nbsp;Search for contacts, deals, and companies in this <a href="https://www.meilisearch.com/docs/learn/security/multitenancy_tenant_tokens?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos" rel="nofollow">multi-tenant</a> CRM application.</li>
</ul>
<p dir="auto">See the list of all our example apps in our <a href="https://github.com/meilisearch/demos">demos repository</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">✨ Features</h2><a id="user-content--features" aria-label="Permalink: ✨ Features" href="#-features"></a></p>
<ul dir="auto">
<li><strong>Hybrid search:</strong> Combine the best of both <a href="https://www.meilisearch.com/docs/learn/experimental/vector_search?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features" rel="nofollow">semantic</a> &amp; full-text search to get the most relevant results</li>
<li><strong>Search-as-you-type:</strong> Find &amp; display results in less than 50 milliseconds to provide an intuitive experience</li>
<li><strong><a href="https://www.meilisearch.com/docs/learn/relevancy/typo_tolerance_settings?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features" rel="nofollow">Typo tolerance</a>:</strong> get relevant matches even when queries contain typos and misspellings</li>
<li><strong><a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/filtering?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features" rel="nofollow">Filtering</a> and <a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/faceted_search?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features" rel="nofollow">faceted search</a>:</strong> enhance your users' search experience with custom filters and build a faceted search interface in a few lines of code</li>
<li><strong><a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/sorting?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features" rel="nofollow">Sorting</a>:</strong> sort results based on price, date, or pretty much anything else your users need</li>
<li><strong><a href="https://www.meilisearch.com/docs/learn/relevancy/synonyms?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features" rel="nofollow">Synonym support</a>:</strong> configure synonyms to include more relevant content in your search results</li>
<li><strong><a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/geosearch?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features" rel="nofollow">Geosearch</a>:</strong> filter and sort documents based on geographic data</li>
<li><strong><a href="https://www.meilisearch.com/docs/learn/what_is_meilisearch/language?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features" rel="nofollow">Extensive language support</a>:</strong> search datasets in any language, with optimized support for Chinese, Japanese, Hebrew, and languages using the Latin alphabet</li>
<li><strong><a href="https://www.meilisearch.com/docs/learn/security/master_api_keys?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features" rel="nofollow">Security management</a>:</strong> control which users can access what data with API keys that allow fine-grained permissions handling</li>
<li><strong><a href="https://www.meilisearch.com/docs/learn/security/multitenancy_tenant_tokens?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features" rel="nofollow">Multi-Tenancy</a>:</strong> personalize search results for any number of application tenants</li>
<li><strong>Highly Customizable:</strong> customize Meilisearch to your specific needs or use our out-of-the-box and hassle-free presets</li>
<li><strong><a href="https://www.meilisearch.com/docs/reference/api/overview?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features" rel="nofollow">RESTful API</a>:</strong> integrate Meilisearch in your technical stack with our plugins and SDKs</li>
<li><strong>AI-ready:</strong> works out of the box with <a href="https://www.meilisearch.com/with/langchain" rel="nofollow">langchain</a> and the <a href="https://github.com/meilisearch/meilisearch-mcp">model context protocol</a></li>
<li><strong>Easy to install, deploy, and maintain</strong></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">📖 Documentation</h2><a id="user-content--documentation" aria-label="Permalink: 📖 Documentation" href="#-documentation"></a></p>
<p dir="auto">You can consult Meilisearch's documentation at <a href="https://www.meilisearch.com/docs/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=docs" rel="nofollow">meilisearch.com/docs</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Getting started</h2><a id="user-content--getting-started" aria-label="Permalink: 🚀 Getting started" href="#-getting-started"></a></p>
<p dir="auto">For basic instructions on how to set up Meilisearch, add documents to an index, and search for documents, take a look at our <a href="https://www.meilisearch.com/docs?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=get-started" rel="nofollow">documentation</a> guide.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🌍 Supercharge your Meilisearch experience</h2><a id="user-content--supercharge-your-meilisearch-experience" aria-label="Permalink: 🌍 Supercharge your Meilisearch experience" href="#-supercharge-your-meilisearch-experience"></a></p>
<p dir="auto">Say goodbye to server deployment and manual updates with <a href="https://www.meilisearch.com/cloud?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch" rel="nofollow">Meilisearch Cloud</a>. Additional features include analytics &amp; monitoring in many regions around the world. No credit card is required.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🧰 SDKs &amp; integration tools</h2><a id="user-content--sdks--integration-tools" aria-label="Permalink: 🧰 SDKs &amp; integration tools" href="#-sdks--integration-tools"></a></p>
<p dir="auto">Install one of our SDKs in your project for seamless integration between Meilisearch and your favorite language or framework!</p>
<p dir="auto">Take a look at the complete <a href="https://www.meilisearch.com/docs/learn/what_is_meilisearch/sdks?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=sdks-link" rel="nofollow">Meilisearch integration list</a>.</p>
<p dir="auto"><a href="https://www.meilisearch.com/docs/learn/what_is_meilisearch/sdks?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=sdks-logos" rel="nofollow"><img src="https://github.com/meilisearch/meilisearch/raw/main/assets/integrations.png" alt="Logos belonging to different languages and frameworks supported by Meilisearch, including React, Ruby on Rails, Go, Rust, and PHP"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">⚙️ Advanced usage</h2><a id="user-content-️-advanced-usage" aria-label="Permalink: ⚙️ Advanced usage" href="#️-advanced-usage"></a></p>
<p dir="auto">Experienced users will want to keep our <a href="https://www.meilisearch.com/docs/reference/api/overview?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced" rel="nofollow">API Reference</a> close at hand.</p>
<p dir="auto">We also offer a wide range of dedicated guides to all Meilisearch features, such as <a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/filtering?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced" rel="nofollow">filtering</a>, <a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/sorting?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced" rel="nofollow">sorting</a>, <a href="https://www.meilisearch.com/docs/learn/fine_tuning_results/geosearch?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced" rel="nofollow">geosearch</a>, <a href="https://www.meilisearch.com/docs/learn/security/master_api_keys?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced" rel="nofollow">API keys</a>, and <a href="https://www.meilisearch.com/docs/learn/security/tenant_tokens?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced" rel="nofollow">tenant tokens</a>.</p>
<p dir="auto">Finally, for more in-depth information, refer to our articles explaining fundamental Meilisearch concepts such as <a href="https://www.meilisearch.com/docs/learn/core_concepts/documents?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced" rel="nofollow">documents</a> and <a href="https://www.meilisearch.com/docs/learn/core_concepts/indexes?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced" rel="nofollow">indexes</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">📊 Telemetry</h2><a id="user-content--telemetry" aria-label="Permalink: 📊 Telemetry" href="#-telemetry"></a></p>
<p dir="auto">Meilisearch collects <strong>anonymized</strong> user data to help us improve our product. You can <a href="https://www.meilisearch.com/docs/learn/what_is_meilisearch/telemetry?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=telemetry#how-to-disable-data-collection" rel="nofollow">deactivate this</a> whenever you want.</p>
<p dir="auto">To request deletion of collected data, please write to us at <a href="mailto:privacy@meilisearch.com">privacy@meilisearch.com</a>. Remember to include your <code>Instance UID</code> in the message, as this helps us quickly find and delete your data.</p>
<p dir="auto">If you want to know more about the kind of data we collect and what we use it for, check the <a href="https://www.meilisearch.com/docs/learn/what_is_meilisearch/telemetry?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=telemetry#how-to-disable-data-collection" rel="nofollow">telemetry section</a> of our documentation.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">📫 Get in touch!</h2><a id="user-content--get-in-touch" aria-label="Permalink: 📫 Get in touch!" href="#-get-in-touch"></a></p>
<p dir="auto">Meilisearch is a search engine created by Meili, a software development company headquartered in France and with team members all over the world. Want to know more about us? <a href="https://blog.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=contact" rel="nofollow">Check out our blog!</a></p>
<p dir="auto">🗞 <a href="https://meilisearch.us2.list-manage.com/subscribe?u=27870f7b71c908a8b359599fb&amp;id=79582d828e" rel="nofollow">Subscribe to our newsletter</a> if you don't want to miss any updates! We promise we won't clutter your mailbox: we only send one edition every two months.</p>
<p dir="auto">💌 Want to make a suggestion or give feedback? Here are some of the channels where you can reach us:</p>
<ul dir="auto">
<li>For feature requests, please visit our <a href="https://github.com/meilisearch/product/discussions">product repository</a></li>
<li>Found a bug? Open an <a href="https://github.com/meilisearch/meilisearch/issues">issue</a>!</li>
<li>Want to be part of our Discord community? <a href="https://discord.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=contact" rel="nofollow">Join us!</a></li>
</ul>
<p dir="auto">Thank you for your support!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">👩‍💻 Contributing</h2><a id="user-content--contributing" aria-label="Permalink: 👩‍💻 Contributing" href="#-contributing"></a></p>
<p dir="auto">Meilisearch is, and will always be, open-source! If you want to contribute to the project, please look at <a href="https://github.com/meilisearch/meilisearch/blob/main/CONTRIBUTING.md">our contribution guidelines</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">📦 Versioning</h2><a id="user-content--versioning" aria-label="Permalink: 📦 Versioning" href="#-versioning"></a></p>
<p dir="auto">Meilisearch releases and their associated binaries are available on the project's <a href="https://github.com/meilisearch/meilisearch/releases">releases page</a>.</p>
<p dir="auto">The binaries are versioned following <a href="https://semver.org/" rel="nofollow">SemVer conventions</a>. To know more, read our <a href="https://github.com/meilisearch/engine-team/blob/main/resources/versioning-policy.md">versioning policy</a>.</p>
<p dir="auto">Differently from the binaries, crates in this repository are not currently available on <a href="https://crates.io/" rel="nofollow">crates.io</a> and do not follow <a href="https://semver.org/" rel="nofollow">SemVer conventions</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Omnom: Self-hosted bookmarking with searchable, wysiwyg snapshots [showcase] (143 pts)]]></title>
            <link>https://omnom.zone/?src=hn</link>
            <guid>43680232</guid>
            <pubDate>Mon, 14 Apr 2025 11:42:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://omnom.zone/?src=hn">https://omnom.zone/?src=hn</a>, See on <a href="https://news.ycombinator.com/item?id=43680232">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<article>
  <p>Warning</p>
  <p>This is a read-only demo instance - check out our <a href="https://github.com/asciimoo/omnom">GitHub</a> for more details</p>
</article>

            <h3>Download extension</h3>
            <p>
                Browser extensions are required to create bookmarks &amp; snapshots. Install the extension to your browser and enjoy Omnoming.
            </p>
            
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hacktical C: practical hacker's guide to the C programming language (125 pts)]]></title>
            <link>https://github.com/codr7/hacktical-c</link>
            <guid>43679781</guid>
            <pubDate>Mon, 14 Apr 2025 10:20:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/codr7/hacktical-c">https://github.com/codr7/hacktical-c</a>, See on <a href="https://news.ycombinator.com/item?id=43679781">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Hacktical C</h2><a id="user-content-hacktical-c" aria-label="Permalink: Hacktical C" href="#hacktical-c"></a></p>
<p dir="auto">A practical hacker's guide to the C programming language.</p>
<p dir="auto"><em>In memory of <a href="https://en.wikipedia.org/wiki/Dennis_Ritchie" rel="nofollow">Dennis Ritchie</a>,
one of the greatest hackers this world has known.</em></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">About the book</h2><a id="user-content-about-the-book" aria-label="Permalink: About the book" href="#about-the-book"></a></p>
<p dir="auto">This book assumes basic programming knowledge. We're not going to spend a lot of time and space on explaining basic features, except where they behave differently in important ways compared to other mainstream languages. Instead we're going to focus on practical techniques for making the most out of the power and flexibility C offers.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">About the author</h2><a id="user-content-about-the-author" aria-label="Permalink: About the author" href="#about-the-author"></a></p>
<p dir="auto">You could say that there are two kinds of programmers, with very different motivations; academics and hackers. I've always identified as a hacker. I like solving tricky problems, and I prefer using powerful tools that don't get in my way. To me; software is all about practical application, about making a change in the real world.</p>
<p dir="auto">I've been writing code for fun on a mostly daily basis since I got a Commodore 64 for Christmas in 1985, professionally in different roles/companies since 1998.</p>
<p dir="auto">I started out with Basic on the Commodore 64, went on to learn Assembler on an Amiga 500, Pascal on PC; C++, Modula-3, Prolog, Ruby, Python, Perl, JavaScript, Common Lisp, Forth, Haskell, SmallTalk, Go, Swift.</p>
<p dir="auto">For a long time, I didn't care much about C at all, it felt very primitive compared to other languages. But gradually over time, I learned that the worst enemy in software is complexity, and started taking C more seriously.</p>
<p dir="auto">Since then I've written a ton of C; and along the way I've picked up many interesting, lesser known techniques that helped me make the most out of the language and appreciate it for its strengths.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Donations</h2><a id="user-content-donations" aria-label="Permalink: Donations" href="#donations"></a></p>
<p dir="auto">If you would like to see this project succeed, all contributions are welcome.</p>
<p dir="auto">I've decided to release the project using an open license to benefit as many as possible, because I believe knowledge should be shared freely. But I also believe in compensation for creators; and the less economic pressure I have to deal with, the more time and energy I can put into the project.</p>
<p dir="auto">The repository is set up for sponsoring via Stripe and Liberapay, alternatively you may use BTC (bitcoin:18k7kMcvPSSSzQtJ6hY5xxCt5U5p45rbuh) or ETH (0x776001F33F6Fc07ce9FF70187D5c034DCb429811).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why C?</h2><a id="user-content-why-c" aria-label="Permalink: Why C?" href="#why-c"></a></p>
<p dir="auto">The reason I believe C is and always will be important is that it stands in a class of its own as a mostly portable assembler language, offering similar levels of freedom.</p>
<p dir="auto">C doesn't try very hard to prevent you from making mistakes. It has very few opinions about your code and happily assumes that you know exactly what you're doing. Freedom with responsibility.</p>
<p dir="auto">These days; many programmers will recommend choosing a stricter language, regardless of the problem being solved. Most of those programmers wouldn't trust themselves with the kind of freedom C offers, many haven't even bothered to learn the language properly.</p>
<p dir="auto">Since most of the foundation of the digital revolution, including the Internet was built using C; it gets the blame for many problems that are more due to our immaturity in designing and building complicated software than about programming languages.</p>
<p dir="auto">The truth is that any reasonably complicated software system created by humans will have bugs, regardless of what technology was used to create it. Using a stricter language helps with reducing some classes of bugs, at the cost of reduced flexibility in expressing a solution and increased effort creating the software.</p>
<p dir="auto">Programmers like to say that you should pick 'the right tool for the job'; what many fail to grasp is that the only people who have the capability to decide which tools are right, are the people creating the software. Much effort has been wasted on arguing and bullying programmers into picking tools other people prefer.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building</h2><a id="user-content-building" aria-label="Permalink: Building" href="#building"></a></p>
<p dir="auto">The makefile requires <code>gcc</code>, <code>ccache</code> and <code>valgrind</code> to do its thing.</p>
<div data-snippet-clipboard-copy-content="git clone https://github.com/codr7/hacktical-c.git
cd hacktical-c
mkdir build
make"><pre><code>git clone https://github.com/codr7/hacktical-c.git
cd hacktical-c
mkdir build
make
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Platforms</h2><a id="user-content-platforms" aria-label="Permalink: Platforms" href="#platforms"></a></p>
<p dir="auto">Since Unix is all about C, and Linux is currently the best supported Unix out there; Linux is the platform I would recommend for writing C. Just having access to <code>valgrind</code> is priceless. Microsoft has unfortunately chosen to neglect C for a long time, its compilers dragging far behind the rest of the pack. Windows does however offer a way of running Linux in the form of WSL2, which works very well from my experience.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Extensions</h2><a id="user-content-extensions" aria-label="Permalink: Extensions" href="#extensions"></a></p>
<p dir="auto">The code in this book uses several GNU extensions that are not yet in the C standard. Cleanup attributes, multi-line expressions and nested functions specifically.</p>
<p dir="auto">Some developers avoid extensions like the plague, some are happy to use them for everything and anything. I fall somewhere in the middle of the spectrum; comfortable with using extensions when there are no good standard alternatives, especially if they're supported by both <code>gcc</code> and <code>clang</code>. All of the extensions used in this book except nested functions (which is currently only supported by <code>gcc</code>) fall in that category.</p>
<p dir="auto">I can think of one feature, <code>hc_defer()</code>, which would currently be absolutely impossible to do without extensions. In other cases, alternative solutions are simply less convenient.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Benchmarks</h2><a id="user-content-benchmarks" aria-label="Permalink: Benchmarks" href="#benchmarks"></a></p>
<p dir="auto">Some chapters come with benchmarks, <code>make build/benchmark</code> builds and runs all of them.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Chapters</h2><a id="user-content-chapters" aria-label="Permalink: Chapters" href="#chapters"></a></p>
<p dir="auto">The content is arranged to form a natural progression, where later chapters build on concepts that have already been introduced. That being said; feel free to skip around, just be prepared to backtrack to fill in blanks.</p>
<ul dir="auto">
<li><a href="https://github.com/codr7/hacktical-c/tree/main/macro">Macros</a></li>
<li><a href="https://github.com/codr7/hacktical-c/tree/main/fix">Fixed-Point Arithmetic</a></li>
<li><a href="https://github.com/codr7/hacktical-c/tree/main/list">Intrusive Doubly Linked Lists</a></li>
<li><a href="https://github.com/codr7/hacktical-c/tree/main/task">Lightweight Concurrent Tasks</a></li>
<li><a href="https://github.com/codr7/hacktical-c/tree/main/malloc1">Composable Memory Allocators - Part 1</a></li>
<li><a href="https://github.com/codr7/hacktical-c/tree/main/vector">Vectors</a></li>
<li><a href="https://github.com/codr7/hacktical-c/tree/main/error">Exceptions</a></li>
<li><a href="https://github.com/codr7/hacktical-c/tree/main/set">Ordered Sets and Maps</a></li>
<li><a href="https://github.com/codr7/hacktical-c/tree/main/malloc2">Composable Memory Allocators - Part 2</a></li>
<li><a href="https://github.com/codr7/hacktical-c/tree/main/dynamic">Dynamic Compilation</a></li>
<li><a href="https://github.com/codr7/hacktical-c/tree/main/stream1">Extensible Streams - Part 1</a></li>
<li><a href="https://github.com/codr7/hacktical-c/tree/main/slog">Structured Logs</a></li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zig's new LinkedList API (it's time to learn fieldParentPtr) (167 pts)]]></title>
            <link>https://www.openmymind.net/Zigs-New-LinkedList-API/</link>
            <guid>43679707</guid>
            <pubDate>Mon, 14 Apr 2025 10:06:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.openmymind.net/Zigs-New-LinkedList-API/">https://www.openmymind.net/Zigs-New-LinkedList-API/</a>, See on <a href="https://news.ycombinator.com/item?id=43679707">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
  
  
  
<p>In a recent, post-Zig 0.14 commit, Zig's <code>SinglyLinkedList</code> and <code>DoublyLinkedList</code> saw <a href="https://github.com/ziglang/zig/commit/1639fcea43549853f1fded32aa1d711d21771e1c">significant changes</a>.</p>

<p>The previous version was a generic and, with all the methods removed, looked like:</p>

<pre><code><span>pub</span> <span>fn</span> <span>SinglyLinkedList</span><span>(</span><span>comptime</span> T<span>:</span> <span><span>type</span></span><span>)</span> <span><span>type</span></span> <span>{</span>
  <span>return</span> <span>struct</span> <span>{</span>
    first<span>:</span> <span><span>?</span><span>*</span>Node</span> <span>=</span> <span>null</span><span>,</span>

    <span>pub</span> <span>const</span> <span>Node</span> <span>=</span> <span>struct</span> <span>{</span>
      next<span>:</span> <span><span>?</span><span>*</span>Node</span> <span>=</span> <span>null</span><span>,</span>
      data<span>:</span> <span>T</span><span>,</span>
    <span>}</span><span>;</span>
  <span>}</span><span>;</span>
<span>}</span></code></pre>

<p>The new version isn't generic. Rather, you embed the linked list node with your data. This is known as an intrusive linked list and tends to perform better and require fewer allocations. Except in trivial examples, the data that we store in a linked list is typically stored on the heap. Because an intrusive linked list has the linked list node embedded in the data, it doesn't need its own allocation. Before we jump into an example, this is what the new structure looks like, again, with all methods removed:</p>

<pre><code><span>pub</span> <span>const</span> <span>SinglyLinkedList</span> <span>=</span> <span>struct</span> <span>{</span>
  first<span>:</span> <span><span>?</span><span>*</span>Node</span> <span>=</span> <span>null</span><span>,</span>

  <span>pub</span> <span>const</span> <span>Node</span> <span>=</span> <span>struct</span> <span>{</span>
    next<span>:</span> <span><span>?</span><span>*</span>Node</span> <span>=</span> <span>null</span><span>,</span>
  <span>}</span><span>;</span>
<span>}</span><span>;</span></code></pre>

<p>Much simpler, and, notice that this has no link or reference to any of our data. Here's a working example that shows how you'd use it:</p>

<pre><code><span>const</span> std <span>=</span> <span>@import</span><span>(</span><span>"std"</span><span>)</span><span>;</span>
<span>const</span> SinglyLinkedList <span>=</span> std<span>.</span>SinglyLinkedList<span>;</span>

<span>pub</span> <span>fn</span> <span>main</span><span>(</span><span>)</span> <span><span>!</span><span>void</span></span> <span>{</span>
    <span>// GeneralPurposeAllocator is being renamed</span>
    <span>// to DebugAllocator. Let's get used to that name</span>
    <span>var</span> gpa<span>:</span> std<span>.</span>heap<span>.</span><span>DebugAllocator</span><span>(</span><span>.</span><span>{</span><span>}</span><span>)</span> <span>=</span> <span>.</span>init<span>;</span>
    <span>const</span> allocator <span>=</span> gpa<span>.</span><span>allocator</span><span>(</span><span>)</span><span>;</span>

    <span>var</span> list<span>:</span> <span>SinglyLinkedList</span> <span>=</span> <span>.</span><span>{</span><span>}</span><span>;</span>

    <span>const</span> user1 <span>=</span> <span>try</span> allocator<span>.</span><span>create</span><span>(</span>User<span>)</span><span>;</span>
    <span>defer</span> allocator<span>.</span><span>destroy</span><span>(</span>user1<span>)</span><span>;</span>
    user1<span>.*</span> <span>=</span> <span>.</span><span>{</span>
        <span>.</span>id <span>=</span> <span>1</span><span>,</span>
        <span>.</span>power <span>=</span> <span>9000</span><span>,</span>
        <span>.</span>node <span>=</span> <span>.</span><span>{</span><span>}</span><span>,</span>
    <span>}</span><span>;</span>
    list<span>.</span><span>prepend</span><span>(</span><span>&amp;</span>user1<span>.</span>node<span>)</span><span>;</span>

    <span>const</span> user2 <span>=</span> <span>try</span> allocator<span>.</span><span>create</span><span>(</span>User<span>)</span><span>;</span>
    <span>defer</span> allocator<span>.</span><span>destroy</span><span>(</span>user2<span>)</span><span>;</span>
    user2<span>.*</span> <span>=</span> <span>.</span><span>{</span>
        <span>.</span>id <span>=</span> <span>2</span><span>,</span>
        <span>.</span>power <span>=</span> <span>9001</span><span>,</span>
        <span>.</span>node <span>=</span> <span>.</span><span>{</span><span>}</span><span>,</span>
    <span>}</span><span>;</span>
    list<span>.</span><span>prepend</span><span>(</span><span>&amp;</span>user2<span>.</span>node<span>)</span><span>;</span>

    <span>var</span> node <span>=</span> list<span>.</span>first<span>;</span>
    <span>while</span> <span>(</span>node<span>)</span> <span>|</span>n<span>|</span> <span>{</span>
        std<span>.</span>debug<span>.</span><span>print</span><span>(</span><span>"{any}\n"</span><span>,</span> <span>.</span><span>{</span>n<span>}</span><span>)</span><span>;</span>
        node <span>=</span> n<span>.</span>next<span>;</span>
    <span>}</span>
<span>}</span>

<span>const</span> <span>User</span> <span>=</span> <span>struct</span> <span>{</span>
    id<span>:</span> <span><span>i64</span></span><span>,</span>
    power<span>:</span> <span><span>u32</span></span><span>,</span>
    node<span>:</span> <span>SinglyLinkedList<span>.</span>Node</span><span>,</span>
<span>}</span><span>;</span></code></pre>

<p>To run this code, you'll need a nightly release from within the last week. What do you think the output will be? You should see something like:</p>

<pre><code>SinglyLinkedList.Node{ .next = SinglyLinkedList.Node{ .next = null } }
SinglyLinkedList.Node{ .next = null }</code></pre>

<p>We're only getting the nodes, and, as we can see here and from the above skeleton structure of the new <code>SinglyLinkedList</code>, there's nothing about our users. Users have nodes, but there's seemingly nothing that links a node back to its containing user. Or is there?</p>

<p>In the past, we've described how <a href="https://www.openmymind.net/learning_zig/pointers/">the compiler uses the type information</a> to figure out how to access fields. For example, when we execute <code>user1.power</code>, the compiler knows that:</p>

<ol>
  <li><code>id</code> is +0 bytes from the start of the structure,
  </li><li><code>power</code> is +8 bytes from the start of the structure (because id is an i64), and
  </li><li><code>power</code> is an i32
</li></ol>

<p>With this information, the compiler knows how to access <code>power</code> from <code>user1</code> (i.e. jump forward 8 bytes, read 4 bytes and treat it as an i32). But if you think about it, that logic is simple to reverse. If we know the address of <code>power</code>, then the address of <code>user</code> has to be <code>address_of_power - 8</code>. We can prove this:</p>

<pre><code><span>const</span> std <span>=</span> <span>@import</span><span>(</span><span>"std"</span><span>)</span><span>;</span>

<span>pub</span> <span>fn</span> <span>main</span><span>(</span><span>)</span> <span><span>!</span><span>void</span></span> <span>{</span>
    <span>var</span> user <span>=</span> <span>User</span><span>{</span>
        <span>.</span>id <span>=</span> <span>1</span><span>,</span>
        <span>.</span>power <span>=</span> <span>9000</span><span>,</span>
    <span>}</span><span>;</span>
    std<span>.</span>debug<span>.</span><span>print</span><span>(</span><span>"address of user: {*}\n"</span><span>,</span> <span>.</span><span>{</span><span>&amp;</span>user<span>}</span><span>)</span><span>;</span>

    <span>const</span> address_of_power <span>=</span> <span>&amp;</span>user<span>.</span>power<span>;</span>
    std<span>.</span>debug<span>.</span><span>print</span><span>(</span><span>"address of power: {*}\n"</span><span>,</span> <span>.</span><span>{</span>address_of_power<span>}</span><span>)</span><span>;</span>

    <span>const</span> power_offset <span>=</span> <span>8</span><span>;</span>
    <span>const</span> also_user<span>:</span> <span><span>*</span>User</span> <span>=</span> <span>@ptrFromInt</span><span>(</span><span>@intFromPtr</span><span>(</span>address_of_power<span>)</span> <span>-</span> power_offset<span>)</span><span>;</span>
    std<span>.</span>debug<span>.</span><span>print</span><span>(</span><span>"address of also_user: {*}\n"</span><span>,</span> <span>.</span><span>{</span>also_user<span>}</span><span>)</span><span>;</span>

    std<span>.</span>debug<span>.</span><span>print</span><span>(</span><span>"also_user: {}\n"</span><span>,</span> <span>.</span><span>{</span>also_user<span>}</span><span>)</span><span>;</span>
<span>}</span>

<span>const</span> <span>User</span> <span>=</span> <span>struct</span> <span>{</span>
    id<span>:</span> <span><span>i64</span></span><span>,</span>
    power<span>:</span> <span><span>u32</span></span><span>,</span>
<span>}</span><span>;</span></code></pre>

<p>The magic happens here:</p>

<pre><code><span>const</span> power_offset <span>=</span> <span>8</span><span>;</span>
<span>const</span> also_user<span>:</span> <span><span>*</span>User</span> <span>=</span> <span>@ptrFromInt</span><span>(</span><span>@intFromPtr</span><span>(</span>address_of_power<span>)</span> <span>-</span> power_offset<span>)</span><span>;</span></code></pre>

<p>We're turning the address of our user's power field, <code>&amp;user.power</code> into an integer, subtracting 8 (8 bytes, 64 bits), and telling the compiler that it should treat that memory as a <code>*User</code>. This code will <em>probably</em> work for you, but it isn't safe. Specifically, unless we're using a packed or extern struct, Zig makes no guarantees about the layout of a structure. It could put <code>power</code> BEFORE <code>id</code>, in which case our <code>power_offset</code> should be 0. It could add padding after every field. It can do anything it wants. To make this code safer, we use the <code>@offsetOf</code> builtin to get the actual byte-offset of a field with respect to its struct:</p>

<pre><code><span>const</span> power_offset <span>=</span> <span>@offsetOf</span><span>(</span>User<span>,</span> <span>"power"</span><span>)</span><span>;</span></code></pre>

<p>Back to our linked list, given that we have the address of a <code>node</code> and we know that it is part of the <code>User</code> structure, we <em>are</em> able to get the <code>User</code> from a node. Rather than use the above code though, we'll use the <em>slightly</em> friendlier <code>@fieldParentPtr</code> builtin. Our <code>while</code> loop changes to:</p>

<pre><code><span>while</span> <span>(</span>node<span>)</span> <span>|</span>n<span>|</span> <span>{</span>
  <span>const</span> user<span>:</span> <span><span>*</span>User</span> <span>=</span> <span>@fieldParentPtr</span><span>(</span><span>"node"</span><span>,</span> n<span>)</span><span>;</span>
  std<span>.</span>debug<span>.</span><span>print</span><span>(</span><span>"{any}\n"</span><span>,</span> <span>.</span><span>{</span>user<span>}</span><span>)</span><span>;</span>
  node <span>=</span> n<span>.</span>next<span>;</span>
<span>}</span></code></pre>

<p>We give <code>@fieldParentPtr</code> the name of the field, a pointer to that field as well as a return type (which is inferred above by the assignment to a <code>*User</code> variable), and it gives us back the instance that contains that field.</p>

<p>Performance aside, I have mixed feelings about the new API. My initial reaction is that I dislike exposing, what I consider, a complicated builtin like <code>@fieldParentPtr</code> for something as trivial as using a linked list. However, while <code>@fieldParentPtr</code> seems esoteric, it's quite useful and developers should be familiar with it because it can help solve problems which are otherwise problematic.</p>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kezurou-Kai #39 (261 pts)]]></title>
            <link>https://www.bigsandwoodworking.com/kezurou-kai-39/</link>
            <guid>43679004</guid>
            <pubDate>Mon, 14 Apr 2025 07:47:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bigsandwoodworking.com/kezurou-kai-39/">https://www.bigsandwoodworking.com/kezurou-kai-39/</a>, See on <a href="https://news.ycombinator.com/item?id=43679004">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Last weekend I went to the 39th annual Kezurou-kai event in Itoigawa, Niigata.  It was my first time going to the event here in Japan, and it was such a blast.  For those who are unfamiliar with kezurou-kai, it’s an event where people compete to take the thinnest shavings of wood using Japanese planes.  But more than that it’s really a gathering of people who are passionate about woodworking and carpentry, sharpening and hand tools, who are pushing their skills to the absolute limits of what is possible.  </p><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0301.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0301.jpg?resize=1024%2C683&amp;ssl=1" alt="70mm kanna kezuroukai preliminary" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0301.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0301.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0301.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0301.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0301.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0301.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><p>The event takes place over two days, with preliminary planing running all through the first day, and ending around mid-day on day 2.  Throughout that time competitors have three chances each day to bring a plane shaving up for official measurement.  5 individuals with the thinnest shavings then go on to the final planing contest toward the end of the day on day 2.  </p><p>The main contest required using 70 mm kanna, and the material was limited to hinoki at 55 mm wide by 1800 mm long.   Hinoki has become the standard wood for thin planing, since it cuts beautifully and can be planed down to an extreme level without breaking up.  For preliminary planing each competitor or group was required to bring their own material for planing.  The final contest however involved planing material selected by the event organizers, with the final 5 competitors all planing the same board.  </p><p>The event took place in a gymnasium which was filled with planing benches shared by teams and individuals.  When I arrived on day 1 I met up with my friends from Somakosha and we pretty much started taking shavings right away.  Here’s Yamamoto-san getting things started.</p><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0304.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0304.jpg?resize=1024%2C683&amp;ssl=1" alt="Team Somakosha taking thin shavings at Kezuroukai" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0304.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0304.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0304.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0304.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0304.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0304.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><p>We all came with a few different planes, and myself I brought 2 kanna, an old Ishido blue steel blade and another from an unknown maker which I’m pretty confident is some type of white steel.  We also had a Mitutoyo digital micrometer for measuring our shavings.  </p><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0436.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0436.jpg?resize=1024%2C683&amp;ssl=1" alt="Ishido and Unknown kanna used at kezuroukai" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0436.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0436.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0436.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0436.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0436.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0436.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0438.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0438.jpg?resize=1024%2C683&amp;ssl=1" alt="Mitutoyo digital micrometee" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0438.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0438.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0438.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0438.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0438.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0438.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><p>Given than none of us had been doing any kind of practice our shavings on day one were pretty decent.  We were all able to take really clean and consistent shavings in the 10-12 micron range without too much trouble.  It was getting under 10 microns that was the real challenge.  </p><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0302.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0302.jpg?resize=1024%2C683&amp;ssl=1" alt="70mm kanna taking thin shaving of hinoki" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0302.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0302.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0302.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0302.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0302.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0302.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><p>This is something that I’ve faced before when having “kezurou-kai nights” with friends.  With careful sharpening and tuning of the dai, it’s fairly straightforward to get really clean consistent shavings in the 10-15 micron range.  But pushing past 10 microns requires a whole other level a fastidiousness when it comes to every aspect of planing.  In any case, on that first day at Kezuroukai we struggled a bit, but we kept sharpening and adjusting out planes trying to break the sub-10 micron barrier.  </p><p>Once you had a good shaving you could take it up for official measurement.  The shaving needed to be full length and free of tears, splits, etc.  Simple jigs were provided which allowed you to clamp a 1 meter section of the shaving for the purpose of bringing it up for official measurement.  Here’s a line of people waiting to get their shavings measured on day 1.  You can see everyone holding a the jig with their shavings clamped.  </p><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0309.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0309.jpg?resize=1024%2C683&amp;ssl=1" alt="waiting to get plane shaving thickness measured" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0309.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0309.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0309.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0309.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0309.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0309.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><p>And here is the official measuring device; three digital calipers which were pneumatically controlled to measure each shaving with a consistent pressure.  When you brought your shaving up, you had to carefully set it below the calipers, and when everything was set the operator would push a button and all three calipers simultaneously plunged down.  The calipers were offset along the length of the shaving, but also across the width, giving measurements which revealed the overall consistency.  </p><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0331.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0331.jpg?resize=1024%2C683&amp;ssl=1" alt="" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0331.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0331.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0331.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0331.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0331.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0331.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><p>If the measurement was satisfactory you could then take it over and paste it on the boards seen below.  Shavings on the far right were all 5 microns and less.  The other two boards were for the remainder of the shavings, most of which were between 6-12 microns.  </p><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0325-1.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0325-1.jpg?resize=1024%2C683&amp;ssl=1" alt="kezuroukai shaving board on day 1" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0325-1.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0325-1.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0325-1.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0325-1.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0325-1.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0325-1.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><p>Outside the venue was a space setup for sharpening.  There was a good mix of people using synthetic and natural stones.  I personally stuck with a variation on my usual routine, 1000 grit Hibiki, an 8000 King or 8000 Hibiki, and a 12000 grit Kagayaki stone, doing a micro-bevel on the 8000 and 12000 stones.  </p><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0333.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0333.jpg?resize=1024%2C683&amp;ssl=1" alt="kezuroukai sharpening area" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0333.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0333.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0333.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0333.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0333.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0333.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0335.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0335.jpg?resize=1024%2C683&amp;ssl=1" alt="sharpening kanna at kezuroukai" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0335.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0335.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0335.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0335.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0335.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0335.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><p>Day 1 went fast.  I planed a lot but I also spent a fair amount of time catching up with old friends.  In terms of shaving I wasn’t able to break through the 10 micron barrier with a consistent shaving.  It’s easy enough to have parts of a shaving break below that barrier, but getting a consistent shaving for the full length and width of the board is really difficult.  On one hand it’s frustrating but it’s also becomes an interesting puzzle figuring out how to improve things.  At the Izakaya that night pretty much all we talked about was sharpening and how to improve our results.</p><hr><p>Day 2 was a fair amount busier, with more people showing up to plane.  All of us from team Somakosha experimented with some different sharpening techniques to see if we could get thinner shavings.  Some things seemed to work better than others, but more than our sharpening technique or dai adjustments, it became clear that our material was a big limiting factor.  As you approach ultra thin sub-10 micron shavings the quality of the material becomes a huge factor in how thin you can go.  The evenness and density of the grain, and especially the moisture content of the wood are really important factors.  </p><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0342.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0342.jpg?resize=1024%2C683&amp;ssl=1" alt="kezuroukai day 2 planing" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0342.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0342.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0342.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0342.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0342.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0342.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><p>Overall we had really nice material, with nice even straight grain, but it was definitely on the drier side.  It was really interesting to see how much other competitors cared for and maintained their material.  Most people had their planing blanks wrapped in plastic to prevent moisture loss, and many went to great lengths to protect the wood when not planing by protecting it with blankets or foam packing.  </p><p>The two guys who we shared a bench with were Kezurou-kai veterans, having started some 20 years ago, and they had 2 planing beams that they were rotating in and out as they planed.  Whenever they set aside a board they would cover it will moist towels to maintain a high moisture content in the wood.  In another case Yamamoto-san went over to a friend’s bench and was able to take some shavings from their hinoki which was definitely higher quality and well maintained.  He had been pulling shavings in the 10-12 micron range on our board, but taking the same plane, without resharpening to the his friend’s higher quality board, he was able to plane down to 6 microns.  Pretty amazing how much of a difference the quality of material and moisture content makes.  </p><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0311.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0311.jpg?resize=1024%2C683&amp;ssl=1" alt="hinoki wrapped and protected in preparation for planinng" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0311.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0311.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0311.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0311.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0311.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0311.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><p>As day 2 went on you could sense the energy level rising as everyone worked to take ultra-thin shaving before time was up.  About an hour before the deadline for preliminary planing and the leaderboards really started to fill up.  </p><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0343.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0343.jpg?resize=1024%2C683&amp;ssl=1" alt="thin hinoki plane shavings entered into the competion" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0343.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0343.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0343.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0343.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0343.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0343.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0347.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0347.jpg?resize=1024%2C683&amp;ssl=1" alt="planing hinoki kezuroukai 39" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0347.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0347.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0347.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0347.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0347.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0347.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0346.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0346.jpg?resize=1024%2C683&amp;ssl=1" alt="group of people watching at kezuroukai" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0346.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0346.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0346.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0346.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0346.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0346.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0345.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0345.jpg?resize=1024%2C683&amp;ssl=1" alt="kezuroukai planing benches and venue" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0345.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0345.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0345.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0345.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0345.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0345.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><hr><p>Back at our bench we started to try every possible trick we could think of to improve our results.  What seemed to work best was simply wiping the board with a lightly damp rag prior to planing.  It would definitley be better to have the wood “pre-soaked” rather than wiping the wood before hand, since exceess moisture on the surface of the wood can cause the dai to move, but given the situation and with time running out we did what we needed to do.  And it did help, a lot.  The quality of shaving between really dry wood and moist wood is completely different.  </p><p>In the end one of my last shavings turned out to be my best.  With a freshly sharpened blade, and a touch of moisture on the wood, I was able to pull a really clean shaving.  I took it up to the judges for measurement and the results were 10, 6, and 9 microns.  I’m pretty happy with that result.  It’d be great if the whole thing came out around 6, but I’m glad to have gotten a really clean full length/width shaving at that level.  </p><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0349.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0349.jpg?resize=1024%2C683&amp;ssl=1" alt="Jon Billing hinoki shaving at kezuroukai" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0349.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0349.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0349.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0349.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0349.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0349.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><p>Here are the top 5 winners from the preliminary contest and their numbers.  Insanity!  Crazy thin and consistent.  </p><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0350.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0350.jpg?resize=1024%2C683&amp;ssl=1" alt="thinnest shavings from preliminary competition" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0350.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0350.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0350.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0350.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0350.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0350.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><p>With the preliminary contest over, the top 5 went on to the final challenge which was planing a 3 meter quartersawn piece of sugi (Japanese cedar).  Compared to hinoki, sugi is not an easy wood to plane, especially thin.  This time the rules for the final round also changed, and each person had just a few minutes (I think it was 3-4) for both setting their planes and planing.  In otherwords, before the timer started your blade had to be loose in the dai.  Then once the clock started ticking you could begin setting the blade in dai and start planing.  Kind of intense given the time allotted and overall pressure of the situation.  </p><p>Here’s the first person up, taking a fairly thick shaving.  </p><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0357.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0357.jpg?resize=1024%2C683&amp;ssl=1" alt="final kezuroukai competition planing sugi" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0357.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0357.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0357.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0357.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0357.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0357.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><p> With sugi theres a fine line between planing too thick and too thin.  Too thin and the shaving just falls apart.  </p><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0370.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0370.jpg?resize=1024%2C683&amp;ssl=1" alt="difficult to plane sugi from final competition" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0370.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0370.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0370.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0370.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0370.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0370.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0371.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0371.jpg?resize=1024%2C683&amp;ssl=1" alt="competitor focusing on getting a clean sugi shaving" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0371.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0371.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0371.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0371.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0371.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0371.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><p>Each person only had one chance to have a complete shaving measured, which means you have to really gauge the material and your capabilities.  It’s all about taking the thinnest shaving you can manage and knowing when to stop.   Spend too much time trying to get a thin shaving and you risk running out of time.  But it’s also tricky to gauge the thickness of the shaving until you ask the judges to measure it.  In reality it may look thinner than it actually is.  </p><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0380.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0380.jpg?resize=1024%2C683&amp;ssl=1" alt="measuring the thickness of a sugi shaving" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0380.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0380.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0380.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0380.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0380.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0380.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0384.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0384.jpg?resize=1024%2C683&amp;ssl=1" alt="final competitor shaving sugi" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0384.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0384.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0384.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0384.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0384.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0384.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0385.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0385.jpg?resize=1024%2C683&amp;ssl=1" alt="measuring the last sugi shaving from final at kezuroukai 39" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0385.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0385.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0385.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0385.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0385.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0385.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><p>The winning shaving from the final round of 5 competitors was somewhere around 50 microns (it may have been 48), which just goes to show you how different sugi is from hinoki.  It also reveals how different it is to plane material that is of unknown quality versus planing your own moisture controlled material.  </p><p>I love the challenge of ultra-thin planing, and it’s fascinating to see the skill and dedication it takes to plane at a this level.  But planing in the sub-10 micron range really requires a high level of control over the material (not to mention the kanna), which as a woodworker/carpenter is pretty far from the reality of day-to-day work.  So I like the idea of a contest which requires people to plane an unknown piece of wood, which is more or less how the final competition here goes.  I’d also love to see some sort of tear-out challenge, where the goal is to plane a really gnarly piece of wood with knots or difficult grain, and try to perfect the surface.  A challenge like that would be really beneficial for folks looking to use kanna for real work.  </p><hr><p>Throughout the event I was pretty focused on visiting with friends and planing, but I did take a quick lap towards the end of day 2 to snap some photos of other some of the other things taking place.  </p><p>In one corner of the venue a craftsman was demonstrating carving a sumitsubo.  (I didn’t realize until later when I edited these photos that he also had carved wooden shoes in the foreground!)</p><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0315.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0315.jpg?resize=1024%2C683&amp;ssl=1" alt="kezuroukai sumitsubo carving demonstration" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0315.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0315.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0315.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0315.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0315.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0315.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><p>Next to him was a guy demonstrating how to cut a new kanna dai.  If you search for Kezuroukai videos you can find a good video of this same person chopping a dai at a previous event.  </p><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0316.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0316.jpg?resize=1024%2C683&amp;ssl=1" alt="kezuroukai kanna dai fabrication demonstration" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0316.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0316.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0316.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0316.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0316.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0316.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0317.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0317.jpg?resize=1024%2C683&amp;ssl=1" alt="chopping a kanna dai demo at kezuroukai" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0317.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0317.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0317.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0317.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0317.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0317.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><p>Outside near the sharpening area were several people demonstrating hewing, and brave spectators could also give it a go with a bit of supervision.  </p><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0340.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0340.jpg?resize=1024%2C683&amp;ssl=1" alt="hewing demonstration at kezuroukai" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0340.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0340.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0340.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0340.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0340.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0340.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><p>Back inside the venue were also plenty of vendors selling anything and everything related to planes and handtools.  Here was one of the natural sharpening stone vendors.  </p><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0320.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0320.jpg?resize=1024%2C683&amp;ssl=1" alt="natural stone shop at kezuroukai" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0320.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0320.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0320.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0320.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0320.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0320.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><p>The NSK company who are making a new variety of diamond sharpening stones were also present.  They made their stones available to try for anyone who was interested.  </p><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0319.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0319.jpg?resize=1024%2C683&amp;ssl=1" alt="nsk diamond stones for sale at kezuroukai 39" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0319.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0319.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0319.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0319.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0319.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0319.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><p>And of course there were plenty of kanna for sale…</p><figure><img data-recalc-dims="1" decoding="async" width="1024" height="683" src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0318.jpg?resize=1024%2C683&amp;ssl=1" data-src="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0318.jpg?resize=1024%2C683&amp;ssl=1" alt="kanna for sale at kezuroukai 39" data-srcset="https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0318.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0318.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0318.jpg?resize=18%2C12&amp;ssl=1 18w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0318.jpg?resize=930%2C620&amp;ssl=1 930w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0318.jpg?resize=325%2C217&amp;ssl=1 325w, https://i0.wp.com/www.bigsandwoodworking.com/wp-content/uploads/2023/11/DSCF0318.jpg?resize=600%2C400&amp;ssl=1 600w" data-sizes="auto, (max-width: 1024px) 100vw, 1024px"></figure><hr><p>There’s a lot I wasn’t able to cover but that’s the quick story behind Kezuroukai #39.  It really was a busy couple of days, and hard to take everything in.  I’d love to go back and try my hand at planing again, but I’d also love to just go as a spectator and spend more time watching.  There’s so much you can learn at Kezuroukai, and also so many really passionate and inspired people to meet.  I highly recommend a visit to anyone who can make the trip to Japan, but if not then definitely seek out a more local event or start one up!  In the US now we have Kezuroua-kai USA along with a few other kez events like Jason Fox’s Maine event.  So go, plane wood, and help spread the joy of hand tools and craft!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Albert Einstein's theory of relativity in words of four letters or less (225 pts)]]></title>
            <link>https://www.muppetlabs.com/~breadbox/txt/al.html</link>
            <guid>43678312</guid>
            <pubDate>Mon, 14 Apr 2025 05:22:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.muppetlabs.com/~breadbox/txt/al.html">https://www.muppetlabs.com/~breadbox/txt/al.html</a>, See on <a href="https://news.ycombinator.com/item?id=43678312">Hacker News</a></p>
<div id="readability-page-1" class="page">
<center><h2>Albert Einstein's Theory of Relativity</h2></center>
<center><h2>In Words of Four Letters or Less</h2></center>
<hr>
<center><h4>[ 0 ]</h4></center>
<p>
So, have a seat. Put your feet up. This may take some time. Can I get
you some tea? Earl Grey? You got it.
</p><p>
Okay. How do I want to do this? He did so much. It's hard to just dive
in. You know? You pick a spot to go from, but soon you have to back up
and and go over this or that item, and you get done with <em>that</em> only
to see that you have to back up some more. So if you feel like I'm off
to the side of the tale half the time, well, this is why. Just bear
with me, and we'll get to the end in good time. Okay?
</p><p>
Okay. Let's see....
</p><center><h4>[ I ]</h4></center>
<p>
Say you woke up one day and your bed was gone. Your room, too. Gone.
It's <em>all</em> gone. You wake up in an inky void. Not even a star. Okay,
yes, it's a dumb idea, but just go with it. Now say you want to know
if you move or not. Are you held fast in one spot? Or do you, say,
list off to the left some? What I want to ask you is: Can you find
out? Hell no. You can see that, sure. You don't need me to tell
you. To move, you have to move <em>to</em> or <em>away</em> from ... well, from
what? You'd have to say that you don't even get to use a word like
"move" when you are the only body in that void. Sure. Okay.
</p><p>
Now, let's add the bed back. Your bed is with you in the void. But not
for long -- it goes away from you. You don't have any way to get it
back, so you just let it go. But so now we have a body in the void
with you. So does the bed move, or do you move? Or both? Well, you can
see as well as I that it can go any way you like. Flip a coin. Who's
to say? It's best to just say that you move away from the bed, and
that the bed goes away from you. No one can say who's held fast and
who isn't.
</p><p>
Now, if I took the bed back but gave you the <em>sun</em> -- just you and the
sun in the void, now -- I'll bet you'd say that the sun is so big,
next to you, that odds are you move and not the sun. It's easy to move
a body like ours, and not so easy to kick a sun to and fro. But that
isn't the way to see it. Just like with the bed, no one can say who's
held fast.
</p><p>
In a word, you can't find any one true "at rest". Izzy was the one who
told us that. Izzy said that you can't tell if you move or are at rest
at any time. You can say that you go and all else is at rest, or you
can say that you are at rest and all else goes. It all adds up the
same both ways. So we all knew that much from way back when.
</p><p>
Aha, but now wait! The sun puts off rays! So: why not look at how fast
the rays go past you? From that you'd see how fast you move, yes? For
you see, rays move just the same if what puts them off is held fast or
not. (Make a note of that, now.) Izzy had no way to know that, back
then, but it's true. Rays all move the same. We call how fast that is:
<i>c</i>. So, you can see how fast the rays go by you, and how far off that
is from <i>c</i> will tell you how fast you move! Hell, you don't even need
the sun for that. You can just have a lamp with you -- the one by your
bed that you use to read by. You can have that lamp in your hand, and
see how fast the rays go by you when you turn it on. The lamp will
move with you, but the rays will move at <i>c</i>. You will see the rays
move a bit more or less than <i>c</i>, and that will be how fast you move.
An open-and-shut case, yes?
</p><p>
Well, and so we went to test this idea out. Hey, you don't need to be
in a void to do this test. We move all the time, even as we sit here.
We spin, in fact. So they shot some rays off and took note of how fast
they went east, and how fast they went west, and so on. Well, what do
you know? The rays went just as fast both ways. All ways, in fact.
They all went at <i>c</i>, just the same. Not an iota more or less.
</p><p>
To say that we were less than glad to find that out is to be kind. It
blew the mind, is more like it. "What is up with <em>that</em>?" we said. And
here is when old Al came in.
</p><center><h4>[ II ]</h4></center>
<p>
Old Al, he came out the blue and said, "Not only do rays move at <i>c</i>
if what puts them out is held fast or not: they move at <i>c</i> even if
<em>you</em> are held fast or not." Now that may not look like such a big
deal on the face of it, but hold on. What this says is that you can
move as fast or as slow as you want, and rays will go by you at <i>c</i>
all the time. You can have a pal run past you and when you both look
at a ray go by at the same time, you will both see the <em>same</em> ray go
by at <i>c</i>! That is a bit wild, no? You, back in that void, you just
can <em>not</em> say if you move or not -- with the lamp or no. Not that you
can't tell: it can't be <em>said</em>. It's moot!
</p><p>
But for that to be true, then <em>time</em> also has to get in on the
act. For you and your pal to see the same ray go by at the same clip,
her idea of time must be off from your idea of time!
</p><p>
I can hear you say, "No <em>way</em>. That <em>can't</em> be!" But I tell you it
is. Old Al said so. He said, here, I'll show you. Get a load of
this. We have Bert and Dana. Take a bus, and put Bert on the bus. The
bus goes down the road. Dana, she sits here, on the side of the
road. He's in the bus and she's on her ass. And now take a rock off of
the moon, and let it fall at them. It hits the air and cuts in
two. The two bits burn, and then land just as Bert and Dana are side
by side. One hits the dirt up the road a ways, and one hits down the
road a ways. Dana sees each rock at the same time, but Bert sees one
rock and <em>then</em> sees the next rock. Now: if Bert and Dana both see
Dana as the one who is "at rest", they both will say that the two bits
came down at the same time. Dana will say, "I am 'at rest', and I saw
them both land at the same time, so they both did, in fact, land at
the same time." And Bert will say, "I move away from the rock <em>down</em>
the road, so when I add that fact in, I can see that if I were 'at
rest', I'd have seen both land at the same time. So it must be the
case that they did land at the same time." Okay, but what if Bert and
Dana now see <em>Bert</em> as the one who is "at rest"? Eh? You get to pick
who is "at rest" and who isn't, no? So make Bert be "at rest". Now
Bert will say, "I am 'at rest', so the one up the road beat the one
down the road, on the way to the dirt, just the way I saw it." And
Dana will say, "I saw them land at the same time, but I move away from
the rock <em>up</em> the road, so when I add that fact in, I can see that the
rock up the road must have beat the one down the road."
</p><p>
So you see, when you give up on the idea of a one true "at rest", then
you <em>have</em> to give up on the idea of a one true time as well!
And even that is not the end of it. If you lose your one true way to
see time, then you also lose your one true way to see size
<em>and</em> your one true way to see mass. You can't talk of
<em>any</em> of that, if you don't also say what it is you call "at
rest". If you don't, then Bert or Dana can pick an "at rest" that
isn't the same as what you used, and then what they will get for time
and size and mass won't be the same.
</p><p>
What a snag, eh? I hope you can see how that gave some of them the
fits, back when old Al told us that one. But even so, that ain't the
half of it. I mean, most of us know that if old Al had got hit by a
bus at age ten, we'd have got this far on our own in good time. No, it
was what came <em>next</em> that was the real slap in the face.
</p><center><h4>[ III ]</h4></center>
<p>
Now, I've said a lot here on how to see (or how not to see) how fast
you "move". What I need to tell you now is just what I mean by that
word "move". When I say "move", I also mean that you don't slow down
or get sped up at any time, <em>and</em> that you don't veer to one
side at all. When you move, you just keep all that the same as you
go. How we say it is, you don't have any "pull". Why do I make a big
deal out of that, you ask? Okay, let me tell you.
</p><p>
Cast your mind back to Ari, from way way back when. He's the one who
said that if you are at rest, you tend to stay at rest, and if you
move, you tend to come to rest. He was off, you know, as he had no way
to know that it was the air that has you come to rest. We had to wait
a long time for Izzy to come by and say, "No, Ari: if you move, you
tend to just go on and on. To come to rest, you need to have a
<em>pull</em>." The air will give you a pull, a pull that has you come to
rest. Then we also have the big pull, the one that says what is down
and what is up, the one that has all of us in its grip. Izzy saw that
this pull was the same pull that has the moon in its grip, too. I said
that a pull can be a veer, yes? That is what the pull on the moon
does. The moon has to veer all the time for it to stay with us. Were
it not for that pull, it'd just go off in a line -- no veer -- and
we'd just sit here and wave bye bye. Same with us and the sun. We
veer, each hour, or else we'd get real cold real fast.
</p><p>
But then, see, Izzy had to deal with the way that the pull acts. If a
body has more mass, then it also has more pull, yes? That is why the
sun is the axis we spin upon, and we are not the axis for the sun.
But then why can't it go both ways? You take your ball of lead and
your ball of wood and drop them, they land at the same time. But the
lead ball has more mass, so it must get more pull. Izzy said, "Well,
see, a body has one <em>more</em> kind of pull. This pull is such that it
will want to stay put all the time. And the more mass it has, the more
it will want to stay put. That pull is the 'a body at rest will tend
to stay at rest' part of the deal. So you see, that pull and the big
pull are in a tug-of-war, and they work out so that any mass will fall
just as fast."
</p><p>
I call it a "new kind of pull", but it isn't so new: you feel it all
the time. Get in a car and step on the gas -- you feel a pull back
into your seat. Let up on the gas a bit, and the pull goes away. Make
a left, and you feel a pull to the side. Stop, and you feel a pull out
of your seat as you slow down. Or, go to the fair and get on a ride.
As you spin, you feel a pull out, away from the ride. You spin: that
is to say you veer, and veer and veer and veer, just like the moon. If
you had no seat belt, you'd fly off the ride, and you'd fly off in a
line. (Well, that is to say, you'd fly off in a line as a bird sees
it. To be fair you'd also arc down at the same time. But put that to
one side.)
</p><p>
Okay but now, see, old Al's big idea did not work when you look at
pull. Go back to when you were lost in the void. You can't say if you
move or not, yeah, but you sure can say if you have a <em>pull</em> on you or
not. If you did, you'd feel it, no? Sure. So then you have no one true
"at rest", no one true way to look at time, or mass, or size, but you
<em>do</em> have one true way to look at a pull? Old Al said, "Erm. I don't
buy that." We all said, "Aah, why not? Just give it a rest, Al." You
can see why Al did not want to give it a rest, I bet. But this one
was not such an easy nut.
</p><center><h4>[ IV ]</h4></center>
<p>
Izzy once said, Look here: say you have a disk that can spin, and so
you put a pail of milk on it and you make it spin. You will see the
milk go up the side of the pail, and fly over and out onto the disk.
No big deal, eh? The spin will make a pull. But now what if you said
that the pail of milk is your "at rest"? Then you have you and the sky
and all that in a big huge spin, and the disk with its pail of milk is
the only body that is "at rest", yes? How can you say then why the
milk goes up? What can make the at-rest milk fly out of the pail like
that?
</p><p>
This is why Izzy came to say: Yes, we have no one true "at rest", and
when you move, some may say you do move and some may say you don't,
and that is okay -- but not so with a pull! A pull is a pull, damn it.
</p><p>
But old Al's mind was set. And he had a big clue that that was not the
full tale. I told you that Izzy put a new kind of pull next to the old
kind. Well, even he felt that this new pull was a tad bit odd. Not to
put it down, mind you -- just that this new kind of pull was so much
like the old kind of pull in a lot of ways. You know? Say I put you in
a box, and then put that box out in a void. (But this time I don't
need to have you in a true void. I just want you to be well away from
any pull. You can have a star or two, or as many as you like, as long
as you keep them far off. Okay?) Now, say I tied a rope from the box
to a ship, and then I got in that ship and sent it up, so that it went
fast, and more fast, and more fast ... I just burn up fuel as long as
I have any left. As long as I see to it that you get sped up all the
time, and at the same rate, you will feel a pull that will feel just
like the pull you'd feel if you were back here, at home. If you have a
ball of lead and a ball of wood in that box with you, you can drop
them and they will both land at the same time. That is a bit odd, no?
Puts a bug in your ear, yes? You can bet it put bugs in our ears. But
no one had come up with a good way to say why that was so. Not yet.
</p><p>
Old Al, he took that ball and ran with it. He went off for a year, and
then ten more. Yep. That long. This was no walk in the park, let me
tell you. In fact, some of us said that it was more like a walk off
the deep end! For you see, when old Al came back, he said, "This 'new'
pull that Izzy gave us, it is just the old pull. Not just <em>like</em>
it. It <em>is</em> it. The two are one and the same. And from this, you will
then see that we have no 'one true pull'."
</p><p>
Do you see what he said, here? When you are in that box with the rope
on the ship, the pull you feel won't just <em>act</em> like the pull back
home: it is in fact the same <em>kind</em> of pull! So when you say, "Hey!
What if I want this box to be my 'at rest', huh? What then? Why does
this ball fall down if I'm at rest and all?" -- old Al will say back
at you, "Well, you see, you have this big old <em>void</em> that goes by, and
gets sped up all the time, and <em>that</em> has a pull on you and your box."
You'd say, "Get out of here! The mass in this void is too far away to
give me that big of a pull!" But old Al'd say, "Nope. You don't get
it. How much mass you have in your void is moot. It's the fact that
it's <em>all the mass in the void</em>. All of it but you and your box, that
is."
</p><p>
Same with the milk in the pail. If you say that the pail is at rest,
then old Al will say that the spin of all else will pull on the milk,
and make it jump out over the side.
</p><p>
So here is what we get when we boil it all down. Izzy said that you
can't tell if you move or are at rest at any time. You can say that
you go and all else is at rest, or you can say that you are at rest
and all else goes. It all adds up the same both ways. But old Al then
said not only that, but that you can't even tell if you have a pull on
you or not. So, at no time, in no way, can you act so that you can't
be seen as "at rest". You can go this way or that way or jump up or
down or what have you: even so, you can say that you are at rest --
and it will all add up just the same.
</p><p>
This was the big one for old Al. He'd like to jump for joy, it all
came out just so. But the rest of us, well, we felt more like it was
time to lock Al up, what he said was so wild.
</p><center><h4>[ V ]</h4></center>
<p>
So some of us said, "Al, you are mad. Look here: you want to make this
pull, this pull that we need to keep next to the sun -- you want to
make this very real pull into some kind of <em>fake</em> pull! I mean, what
kind of pull is it that can go away and come back as you pick what to
call your 'at rest'? That is no way for a pull to act." And old Al
said, "Yeah, you hit the nail on the head. It <em>is</em> a fake pull." And
we said, "Okay, that is it. You, Al, have lost it." And old Al said,
"Feh. Read this and weep." And we read it, or we gave it a try, more
like. It was a real mess. Some of us got it, but most of us just went,
"Huh?" And some of us said that even if it was true, we'd just as soon
stay with the old lie, Al's idea was so hard to make head or tail of.
</p><p>
But Herb -- what? No, Herb isn't his real name, but I like to call him
that -- But so then Herb was one of the ones who got it, and he went
in with old Al and his new idea, and what they came up with goes like
this.
</p><p>
You know all the ways you can move, here. You have your up-and-down,
and you have your east-and-west, and you have your fore-and-back.
Well, Herb had said, we want to add one more way here: time. Yeah,
time as just one more way to move in. Four ways, all told. And now
Herb and old Al said, "Let's take a look at what we can do when we
look at here as a four-way here. Like, what if this four-way here can
be <em>bent</em>? We don't mean that what is <em>in</em> a four-way spot gets bent:
what if the very <em>spot</em> gets bent?" Some of us said, "You two have got
bent, is more like it." But they said, "Ha. Get a load of this."
</p><p>
They said, what if mass puts a bend in this four-way here of ours?
The more mass you have in one spot, the more bent that spot gets. So
now pick out a spot A and a spot B, one on each side of some mass, and
each at its own time. What does it look like when a body goes from A
to B? You will say: A line. Well, yes and no. It <em>is</em> a line, but it's
also bent, as it goes past the bent spot. You see, this line will only
look like a line if you can see all four ways! If you can't see one of
the ways, if for you the way you can't see is what you call <em>time</em>,
then you will see it as a line with a big old <em>veer</em> in it, half way
in. Now, take a lot of mass, as much as our sun has, and pick spot A
and spot B to be near the mass, and to be the same spot but for the
time. Well, when you do that, the line from A to B in the four-way
here will be an arc to you and me! An arc that will spin on and on,
with that mass as the axis!
</p><p>
"You see?" old Al said. "<em>You</em> say that the sun has a pull, but when
we spin with the sun as our axis, in the bent-up four-way here we just
move in a line! We don't veer off at all! <em>That</em> is why I say that
your pull is a fake pull. You don't need any pull if you just want to
stay on a <em>line</em>!"
</p><p>
A few more of us got it, then. But most of us just said, "What are you
two <em>on</em>? Put down the bong and get <em>real</em>! This is way too wild to be
true." But they just said, "Just try and see if it isn't true."
</p><p>
So we came up with ways to test old Al's idea, and each time Al hit
the gold. His idea had the sun's rays a tiny bit more red than what
Izzy said. They were. His idea put Mars a tiny bit off from how Izzy
had Mars. It was.
</p><p>
The big one, the one that got told over and over, was the one with the
dark-at-day time. You know, when the moon gets in the way of the sun.
At that time you can get a real good look at a star when it's up next
to the sun. (Next to it in the sky, that is. Not next to it for real.
You know what I mean.) They went off and got a good look at a star
that was very near the sun, and then they used a book to see just what
spot that star was in. You see, the rays from the star pass so near
the sun that they get bent, on the way to us. Old Al, his idea said
just how much the rays get bent. With Izzy, the rays get bent, too,
but only by half as much. So they took a look at the star, and they
took at look at the big book, and ... well, I'll bet you can tell me
as well as I can tell you just how far off that star was.
</p><p>
A-yup.
</p><p>
And then all of us, we all just sat back and said: "<em>Whoa</em>."
</p><p>
And then we all went back to old Al and said to him, "Al, you must
have some kind of head on you, to pull an idea like that out of thin
air." We said, "Why don't you quit this dumb job you have here and
come with us?" We said, "You know what, Al? We <em>like</em> you."
</p><center><h4>[ end ]</h4></center>
<p>
And that is just the way it was. (Well, that is to say, more or less.)
Oh dear me, look at the time! Sigh. I do know how to run on, don't I?
It must be well past time to turn in. Let me show you out. It was very
nice to have you over, and I hope I was of help.
</p><p>
And y'all come back now, hear?
</p><hr>
<p>
Note: "Herb" actually refers to Hermann Minkowski. (And "Izzy" and
"Ari" are, of course, Isaac Newton and Aristotle.)
</p><p>
<br>
<small><a href="http://www.muppetlabs.com/~breadbox/txt/">Texts</a></small>
<br>
<small><a href="http://www.muppetlabs.com/~breadbox/">Brian Raiter</a></small>


</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mario Vargas Llosa has died (201 pts)]]></title>
            <link>https://www.nytimes.com/2025/04/13/books/review/mario-vargas-llosa-appraisal.html</link>
            <guid>43677917</guid>
            <pubDate>Mon, 14 Apr 2025 03:52:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2025/04/13/books/review/mario-vargas-llosa-appraisal.html">https://www.nytimes.com/2025/04/13/books/review/mario-vargas-llosa-appraisal.html</a>, See on <a href="https://news.ycombinator.com/item?id=43677917">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2025/04/13/books/review/mario-vargas-llosa-appraisal.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Resurrecting Infocom's Unix Z-Machine with Cosmopolitan (141 pts)]]></title>
            <link>https://christopherdrum.github.io/posts/2025/04/porting-infocom-with-cosmo</link>
            <guid>43677909</guid>
            <pubDate>Mon, 14 Apr 2025 03:51:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://christopherdrum.github.io/posts/2025/04/porting-infocom-with-cosmo">https://christopherdrum.github.io/posts/2025/04/porting-infocom-with-cosmo</a>, See on <a href="https://news.ycombinator.com/item?id=43677909">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
  <p>
    <time datetime="2025-04-12 13:35:50 +0900">2025-04-12</time>
  </p>
  
  

  <div><p><img src="https://christopherdrum.github.io/assets/images/cosmo_zork.png" alt="Title Screenshot" width="100%"></p><p>
I made standalone executables of the <a href="https://en.wikipedia.org/wiki/Zork">Zork trilogy</a>, ported from original Infocom UNIX source to Cosmopolitan, are available for Windows/Mac/Linux/bsd for arm/x86 machines. These require no further installation nor external files to play.</p></div>

<p>Here’s how to download and play Zork on the CLI:</p>
<div><pre><code>wget https://github.com/ChristopherDrum/pez/releases/download/v1.0.0/zork1
<span>chmod</span> +x zork1
./zork1

<span># This one executable runs on any and all targetted platforms</span>
<span># `zork2` and `zork3` are available, for trilogy completionists</span>
<span># Windows users, add `.exe` to the downloaded file to make Windows happy</span>
</code></pre></div>

<p>Want to run an arbitrary .z3 text adventure file?<br>
<a href="https://github.com/ChristopherDrum/pez/releases">Download the z-machine from here</a></p>

<h2 id="about-the-project">About the project</h2>

<p>Recently I published v3.0 of <a href="https://christopherdrum.itch.io/statusline">Status Line</a>, a project which makes <em>Zork</em> playble on the Pico-8, onto three major operating systems. With that deployed successfully (is there a ‘knock on wood’ emoji?) I turned to porting <a href="https://github.com/ChristopherDrum/pez/blob/main/zip/infocom_source/phg_zip.c">Infocom’s original UNIX z-machine source code</a> through the use of <a href="https://github.com/jart/cosmopolitan">Cosmopolitan</a>. After about six hours on a lazy Sunday I had it ported to six major operating systems, including Windows.</p>

<p> Unlike Status Line which relies on the Pico-8 virtual machine host, this port runs <strong>natively</strong> on all supported systems. Even better, thanks to Cosmopolitan magic, there is only <strong>one</strong> distributable to maintain which can conform itself to run on whichever operating system is running it.</p>

<p>Here’s the story of how and why I decided to do this project and what I learned along the way.</p>

<h2 id="what-is-a-z-machine">What is a Z-Machine?</h2>

<p>Over the years I’ve spent a lot of time looking at and thinking about the Infocom z-machine. Briefly put, Infocom text adventures were released as platform-independent game files which ran within platform-specific virtual machines for every system the company supported. The spec for that virtual machine is known as the “z-machine.”</p>

<p> I don’t know if they were “the first” to ship a commercial product using a VM on home computers, but they were definitely one of the first. In the 1980’s, unique computer platforms were released at a dizzying rate (<a href="https://www.mobygames.com/game/50/zork-the-great-underground-empire/releases/">Zork 1 released on at least 18 platforms</a>) so it was important to be able to pivot onto new systems quickly. By using a VM, Infocom could rapidly bring their entire library of games to any new machine.</p>

<p> These days gamers have a plethora of choice for modern z-machine interpreters, but back then it was proprietary code. Only Infocom could make a z-machine interpreter which they dubbed ZIP, “Zork Interpreter Program.”</p>

<p> ZIPs were mostly written in hand-tooled assembly, unique to each platform, to squeeze maximum performance out of minimal (16K?! 1.774Mhz?!) hardware. But they weren’t all written in assembly; there also existed a UNIX ZIP, written in C. I don’t know assembly very well at all, but I absolutely know enough C to be a reckless tinkerer. I lazily wondered if that C code would build for me, unchanged, as-is. One compile later I had my answer: <em>no.</em></p>

<p> I’m nothing if not tenacious, and the z-machine is an area in which I have better-than-average knowledge. Bringing this back to life felt like a perfect project to help me continue exploring the historical side of Infocom while also being simple enough to let me explore the potential of Cosmopolitan.</p>

<h2 id="what-is-cosmopolitan">What is Cosmopolitan?</h2>

<p>Put simply, <a href="https://justine.lol/cosmopolitan/">Cosmpolitan</a> is Justine Tunney’s brainchild to transform plain ole’ C into a “write once, run anywhere” language. Consider the typical approach to achieving such a goal, for example Java, WASM, and even the Infocom z-machine itself.</p>

<p> In the typical case, code is written in a unique (even domain-specific) language and compiled into custom byte-code. In the Java/z-machine cases, the promise of “run anywhere” is facilitated by a bespoke virtual machine, custom built for each target platform, which consumes the custom byte-code and runs the program. For WASM, that virtual machine is typically the web browser, though standalone options exist.</p>

<p> In Infocom’s case, a compact interpreter was bundled on disk with each game. Running it was a transparent experience, because launching the interpreter would auto-launch the bundled game file. From the user perspective, she was just launching a game. In reality she was launching a VM which launched the game.</p>

<h3 id="that-which-unites-us">That which unites us</h3>

<p>Cosmopolitan takes a different approach to “write once, run anywhere.” Rather than creating a virtual machine tuned to each machine’s unique differences, instead it flips the script and evaluates the <em>similarities</em> of modern machines; what has stayed consistent over time? A common ABI, using standard C library calls, is designed around those shared roots.</p>

<p> Justine also noticed that executables on each platform have more in common than not. The APE format she developed, <a href="https://justine.lol/ape.html">Actually Portable Executable</a>, is structured very much like a .zip archive (not the Infocom ZIP!) and contains native code for all targeted platforms. After a build and compile, the resulting application will “run anywhere” because it is native everywhere; no virtual machine needed.</p>

<h3 id="bananas-for-ape">Bananas for APE</h3>

<p>An APE file built against the Cosmopolitan project’s libraries can be given to almost anyone on a 64-bit machine, of any OS, by any maker and it will run. We do not need to do separate builds for macOS x64, macOS M-series, Windows 8, 9, 10, 11, Ubuntu, pick-a-Linux, BSD, etc. A single build can run on almost any modern machine.</p>

<p> For this project, this meant that whatever weekend effort I put into getting Infocom’s ZIP to work again could potentially serve a disproportionately large audience. As well, I wouldn’t need to worry about tweaking things per-platform, or crafting complex makefile incantations. I could focus on game correctness and ignore the platform-specific vagaries. I found this approach to be mentally freeing.</p>

<p> An additional benefit of the APE’s .zip archive roots is that we can take things further and create self-contained executables which embed the z-machine and a game data file into one standalone package. This makes for a very interesting distribution option, IMHO.</p>

<h2 id="coding-like-its-1985">Coding Like It’s 1985</h2>

<p>My day job is in Swift and Objective-C, and <a href="https://www.lexaloffle.com/bbs/?tid=54517">my</a> <a href="https://christopherdrum.itch.io/picocalc">weekend</a> <a href="https://christopherdrum.itch.io/mystery-house">projects</a> tend to be in Lua for the Pico-8. I dip into C from time to time, but my experience is firmly within modern coding conventions. I had never been introduced to K&amp;R-style C, but this code from 1985 quickly forced the acquaintance.</p>

<p> As a first-timer to the K&amp;R style, the main thing I noticed is how much is “assumed.” For example, for functions which don’t declare a return type, <code>int</code> is assumed. even if the function <em>actually</em> returns nothing. Some do return ints. Some return <code>char</code> but do not declare a return value, so the calling function assumes int in a kind of implicit casting.</p>

<p> Function parameters are only enforced by “trust” in forward declarations; they don’t need to be declared. And heck, why even bother with a shared forward declaration at all when you can locally forward declare external functions within a calling function?</p>

<p> <code>if</code> statements using <code>THEN</code> instead of braces? I guess you had to be there.</p>

<p> This is all to say that it took time to adjust my reading comprehension skills for the code and make sense of what I was looking at.</p>

<h2 id="the-repairs">The Repairs</h2>

<p>The repairs necessary to get this source code to compile and work were, honestly, quite simple. The changes boiled down to three areas:</p>

<ul>
  <li>Handling NULL</li>
  <li>Function declarations</li>
  <li>Deprecations</li>
</ul>

<h3 id="null-and-null-and-null">NULL and NULL and NULL</h3>

<p>NULL in the original codebase was defined as:</p>


<p>Then again later, in the same file:</p>

<div><pre><code><span>#define NULL 0 --not a typo; it was double-defined.
</span></code></pre></div>
<p>Of course in modern C libraries we define NULL as:</p>



<p>This gave us three definitions of NULL for the project. Fun! But we only need one. Untouched, this caused compilation to fail with code such as this (that K&amp;R if/THEN works fine!):</p>

<div><pre><code><span>newlin</span><span>()</span>
<span>{</span>  
    <span>*</span><span>chrptr</span> <span>=</span> <span>NULL</span><span>;</span>        <span>/* indicate end of line */</span>
    <span>if</span> <span>(</span><span>scripting</span><span>)</span> <span>THEN</span>
        <span>*</span><span>p_chrptr</span> <span>=</span> <span>NULL</span><span>;</span>
    <span>dumpbuf</span><span>();</span>
<span>}</span>
</code></pre></div>

<p>The assumption and kind of “contract” for NULL in the year the source was written was, as we saw, <code>#define NULL 0</code>. If that’s what they wanted, then that’s what we’ll give them.</p>

<div><pre><code><span>newlin</span><span>()</span>
<span>{</span>  
    <span>*</span><span>chrptr</span> <span>=</span> <span>0</span><span>;</span>        <span>/* indicate end of line */</span>
    <span>if</span> <span>(</span><span>scripting</span><span>)</span> <span>THEN</span>
        <span>*</span><span>p_chrptr</span> <span>=</span> <span>0</span><span>;</span>
    <span>dumpbuf</span><span>();</span>
<span>}</span>
</code></pre></div>

<h3 id="function-declarations-and-the-lack-thereof">Function declarations (and the lack thereof)</h3>

<p>A lot of compilation errors were related to functions being called that hadn’t been declared yet. This was fairly trivial to handle; here’s an example of the pattern used in the original code.</p>

<div><pre><code><span>char</span> <span>*</span><span>getpag</span><span>(</span><span>ptr</span><span>,</span> <span>page</span><span>)</span>
<span>char</span> <span>*</span><span>ptr</span><span>,</span> <span>*</span><span>page</span><span>;</span>
<span>{</span>  
    <span>short</span> <span>blk</span><span>,</span> <span>byt</span><span>,</span> <span>oldblk</span><span>;</span>
    <span>char</span> <span>*</span><span>makeptr</span><span>();</span>

    <span>pagfault</span> <span>=</span> <span>1</span><span>;</span>                       <span>/* set flag */</span>
    <span>byt</span> <span>=</span> <span>(</span><span>ptr</span> <span>-</span> <span>dataspace</span><span>)</span> <span>&amp;</span> <span>BYTEBITS</span><span>;</span> <span>/* isolate byte offset in block */</span>
    <span>if</span> <span>(</span><span>curblk</span><span>)</span> <span>THEN</span> <span>{</span>                  <span>/* in print immediate, so use */</span>
        <span>blk</span> <span>=</span> <span>curblk</span> <span>+</span> <span>1</span><span>;</span>               <span>/* curblk to find page */</span>
        <span>curblk</span><span>++</span><span>;</span>                       <span>/* and increment it */</span>
        <span>}</span>
    <span>else</span>
        <span>blk</span> <span>=</span> <span>nxtblk</span><span>(</span><span>ptr</span><span>,</span> <span>page</span><span>);</span>        <span>/* get block offset from last */</span>
    <span>ptr</span> <span>=</span> <span>makeptr</span><span>(</span><span>blk</span><span>,</span> <span>byt</span><span>);</span>            <span>/* get page and pointer for this pair */</span>
    <span>return</span><span>(</span><span>ptr</span><span>);</span>
<span>}</span>
</code></pre></div>

<p> OK, first we have to wrap our heads around how type declarations for passed values are declared <strong>after</strong> the function header. Again, we’ll let our eyes glaze past the use of THEN. Rather, please notice <code>char *makeptr()</code>. That is a locally scoped forward declaration for a function that is defined later; its real header looked like this:</p>

<div><pre><code><span>char</span> <span>*</span><span>makeptr</span><span>(</span><span>blk</span><span>,</span> <span>byt</span><span>)</span>
<span>short</span> <span>blk</span><span>,</span> <span>byt</span><span>;</span>
<span>{...}</span>
</code></pre></div>

<p> Notice how the previous forward declaration didn’t bother with pesky function parameters. What does makeptr() take? Wishes and dreams, from the looks of it!</p>

<p> I switched all functions headers to use modern conventions, turning the makeptr definition into a format I’m sure most reading this have at least a passing familiarity with.</p>

<div><pre><code><span>char</span> <span>*</span><span>makeptr</span><span>(</span><span>short</span> <span>blk</span><span>,</span> <span>short</span> <span>byt</span><span>)</span>
<span>{...}</span>
</code></pre></div>

<p> I collected all function headers into a big block of forward declarations at the top of the .c file and swiftly (well, tediously) eliminated perhaps 80% of compiler warnings and errors. With a clean set of forward declarations, all locally scoped declarations threw errors, making them easy to target for elimination.</p>

<h3 id="deprecations">Deprecations</h3>

<p>The times they are (were) a changing. There were a few things that simply shifted how they needed to be done.</p>

<ul>
  <li><code>srand()</code> seeding was quite complicated. I don’t know if this was just “how things worked” back then or what, but here’s what was in place.
    <div><pre><code><span>mtime</span><span>()</span>
<span>{</span>  <span>/* mtime get the machine time for setting the random seed. */</span>
  <span>long</span> <span>time</span><span>(),</span> <span>tloc</span><span>;</span>
    
  <span>rseed</span> <span>=</span> <span>time</span><span>(</span><span>tloc</span><span>);</span> <span>/* get system time */</span>
  <span>srand</span><span>(</span><span>rseed</span><span>);</span>       <span>/* get a random seed based on time */</span>
  <span>return</span><span>;</span>
<span>}</span>
</code></pre></div>

    <p>which I replaced simply with the below. “Good enough for government work” as the saying goes.</p>

    <div><pre><code><span>mtime</span><span>()</span>
<span>{</span>  
  <span>srand</span><span>(</span><span>time</span><span>(</span><span>0</span><span>));</span>
<span>}</span>
</code></pre></div>
  </li>
  <li>The <code>backspace</code> key on my particular keyboard sends ASCII 128, but the original source code only ever expects ASCII 8. Simple enough to add another value check to allow backspacing on game input (to erase your typed command).</li>
  <li><code>sys/termio.h</code> has been supplanted by <code>termios.h</code> and its attribute set/get calls were updated accordingly.
    <div><pre><code><span>struct</span> <span>termio</span> <span>ttyinfo</span><span>;</span>
<span>ttyfd</span> <span>=</span> <span>fileno</span><span>(</span><span>stdin</span><span>);</span>        <span>/* get a file descriptor */</span>
<span>if</span> <span>(</span><span>ioctl</span><span>(</span><span>ttyfd</span><span>,</span> <span>TCGETA</span><span>,</span> <span>&amp;</span><span>ttyinfo</span><span>)</span> <span>==</span> <span>-</span><span>1</span><span>)</span> <span>THEN</span>
  <span>printf</span><span>(</span><span>"</span><span>\n</span><span>IOCTL - TCGETA failed"</span><span>);</span>
</code></pre></div>

    <p>becomes</p>

    <div><pre><code><span>struct</span> <span>termios</span> <span>ttyinfo</span><span>;</span>
<span>ttyfd</span> <span>=</span> <span>fileno</span><span>(</span><span>stdin</span><span>);</span>        <span>/* get a file descriptor */</span>
<span>if</span> <span>(</span><span>tcgetattr</span><span>(</span><span>ttyfd</span><span>,</span> <span>&amp;</span><span>ttyinfo</span><span>)</span> <span>==</span> <span>-</span><span>1</span><span>)</span> <span>{</span>
  <span>printf</span><span>(</span><span>"</span><span>\n</span><span>tcgetattr failed"</span><span>);</span>
<span>}</span>
</code></pre></div>
  </li>
</ul>

<h2 id="cosmocc--o-zm-phg_zipc--mtiny">cosmocc -o zm phg_zip.c -mtiny</h2>

<p>Thanks to cosmocc, Cosmpolitan’s compilation tool, that single line got the z-machine up and running on 6 modern operating systems. No makefile, no per-system compilation shenanigans, no conditional code on my part. Almost embarrassingly simple, Cosmopolitan allowed me to target a hardware-agnostic ABI, and apply only minimal (often superficial) patches to the original source code.</p>

<p> Let me just say that seeing Zork’s famous introduction spring to life from within the sleeping source code of the very company that created it was a really special moment. After spending so much time on Status Line over the years, I expected to be jaded by “West of House” yet again. To be honest, it was quite the opposite. Knowing the history of the codebase and its place in the legacy of computer gaming only enhanced that feeling of discovery and exploration.</p>

<h2 id="but-we-can-go-further">But We Can Go Further</h2>

<p>APE files have a secret hidden superpower. The Infocom z-machine takes a <code>-g</code> flag at the command line, followed by the path to a <code>.z3</code> data file to launch a given game. It is actually possible to embed that launch flag, and its related data file, into the APE file itself. The game will then, on launch, check itself internally for pre-populated launch arguments, which can reference internal data structures for specific data files.</p>

<p> Think of a macOS app, and how it is actually just a folder of executables and data which can be trivially viewed as such. We can use the APE format similarly. To make this work, we need two pieces:</p>

<h4 id="embed-the-args-and-data">Embed the .args and data</h4>

<p>Create a file called .args which reads <code>-g/zip/game_filename.z3</code>. This is similar to how we would launch a game from the command line, but with a zip/ path prefix. That is the internal, relative position where these data files live. To make further manipulation of the executable easier, rename <code>zm</code> to <code>zm.zip</code>. Copy your <code>.args</code> file and related <code>.z3</code> game file into the <code>zm.zip</code> file with</p>

<div><pre><code>zip <span>-j</span> zm.zip .args /path/to/game_filename.z3
</code></pre></div>

<h4 id="tell-the-app-to-look-for-embedded-args">Tell the app to look for embedded .args</h4>

<p>The executable proper needs to be told to look for embedded .args. Cosmopolitan has a handy command which does precisely that, which we call at the very start of main()</p>

<div><pre><code><span>#include 
</span><span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span> <span>**</span><span>argv</span><span>)</span>  
<span>{</span>
<span>int</span> <span>_argc</span> <span>=</span> <span>cosmo_args</span><span>(</span><span>"/zip/.args"</span><span>,</span> <span>&amp;</span><span>argv</span><span>);</span>
<span>if</span> <span>(</span><span>_argc</span> <span>!=</span> <span>-</span><span>1</span><span>)</span> <span>argc</span> <span>=</span> <span>_argc</span><span>;</span>
<span>...</span>
</code></pre></div>

<p> That will populate <code>argv</code> with the embedded args as though they had been manually passed by the user at the command line. The repo includes a makefile with an <code>embed</code> command which will do all of this busywork for you. Rename the <code>zm.zip</code> to whatever you want to call this standalone build. If you’re on Windows, don’t forget the <code>.exe</code> file extension.</p>

<h2 id="some-unsolicited-advice">Some Unsolicited Advice</h2>

<p>As a first project to understand both the process of porting older UNIX code to modern C as well as how to use Cosmopolitan, it proved invaluable to work on something within my wheelhouse. I knew intimately what a z-machine should do, and how it should look and feel. I understood ahead of time the scope and goal of the project, and I also knew when something wasn’t working right (looking at you <code>fflush(stdout)</code>). Subject familiarity is invaluable in providing intuition when something is wrong, and can even provide foreknowledge for how to tackle certain classes of repairs.</p>

<p> When you compile and see a huge list of warnings and errors, don’t panic. Don’t fret. Don’t feel defeated. Rather, think of it as your “to do” checklist, then buckle down, and attack those compiler errors one by one. In the compiler, you can use the <code>-w</code> flag to turn off warnings and solely focus on errors. We don’t really want to do that for shipping products, but if you’re only interested in getting something kick-started and working for fun, it can definitely pare a “to do” list down into something manageable as you acclimate to the source code.</p>

<p> Lastly, I really cannot stress enough the ease of development that Cosmopolitan provided. The <code>cosmocc</code> compiler, itself built upon <code>gcc</code>, is an APE and as-such is a self-contained compilation ecosystem, bundled with the Cosmopolitan Libc drop-in replacement to the C standard library.</p>

<p> I’ve spent so much time in the past getting $PATHs set up, putting libraries in the right place, installing dependencies, trying to get MSYS2 to behave, and more that to have the convenience of a single APE application unified across my machines was a feeling of, “Yes, this is how things should be. It should be this simple.”</p>

<p> I hope you have the same positive experience.</p>

<h2 id="playing-z-machine-games">Playing Z-Machine Games</h2>
<p>A <a href="https://github.com/ChristopherDrum/pez/releases">pre-compiled APE build of the z-machine is available for 64-bit systems on my github</a> along with notes about how to use it. Standalone builds of the Zork trilogy are also available there, to demonstrate the power of the APE format. Remember, this project essentially reflects the state the code was in in 1985; I make no guarantees of its robustness nor accuracy! But that’s not really the reason to check it out, I think. If you seriously want to play interactive fiction, there are numerous better options than this port.</p>

<p> No, the reason to play this for yourself is to appreciate a singular, historical moment; to experience that brief feeling of reaching back in time and making a connection to a significant object from the past.</p>

<p> That’s not without merit, I think.</p>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Nissan's Leaf app doesn't have a home screen widget so I made my own (113 pts)]]></title>
            <link>https://kevintechnology.com/posts/leaf-widget/</link>
            <guid>43677610</guid>
            <pubDate>Mon, 14 Apr 2025 02:42:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kevintechnology.com/posts/leaf-widget/">https://kevintechnology.com/posts/leaf-widget/</a>, See on <a href="https://news.ycombinator.com/item?id=43677610">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Nissan’s official <a href="https://apps.apple.com/us/app/nissanconnect-ev-services/id407814405" target="_blank">NissanConnect® EV &amp; Services iPhone app</a>:</p><blockquote><p>lets you manage the unique features of your LEAF like charging the battery, adjusting climate controls and checking the battery status, all from your mobile device</p></blockquote><p>Here is a screenshot of what it looks like for my car:</p><p><picture><source srcset="https://kevintechnology.com/posts/leaf-widget/iphone_app_hu02aa61ae1d9de35cbe238d2676170cb9_55766_295x639_resize_q75_h2_box.webp" type="image/webp"><img src="https://kevintechnology.com/posts/leaf-widget/iphone_app.33b3eb1b00b2fb91e7339751cb7fead2.jpg" alt="Screenshot of Nissan LEAF iPhone app showing vehicle information" loading="lazy" height="639" width="295"></picture></p><p>The app is…fine. Here is one representative review from the <a href="https://apps.apple.com/us/app/nissanconnect-ev-services/id407814405?see-all=reviews" target="_blank">Apple App Store</a>:</p><p><picture><source srcset="https://kevintechnology.com/posts/leaf-widget/review_hubeffdf57ec7c17671af28cc042015401_140363_1122x474_resize_q75_h2_box_3.webp" type="image/webp"><img src="https://kevintechnology.com/posts/leaf-widget/review.3c39cd2839da9e51e8e7edb1d11fc4d6.png" alt="On 10/11/2023 SugimotoKoitsu reviewed the app: “Slow communication with the car: This app is pretty limited in what it does, the most useful to me being setting the cabin temperature in winter and checking charging status at work so I don’t hog one of the only two level 2 chargers at work all day. I like to take my 2023 Leaf SV+ off the charger as it nears 100%. But the app is very slow to update the status of the battery. I guess Nissan is polling the car through its cellular connection or a satellite connection, because I can’t log the car into the WiFi network at work. So maybe those methods are time consuming but it takes about five minutes to update the battery status, which is very annoying. It seems like there’s room for improvement in efficiency.”" loading="lazy" height="474" width="1122"></picture></p><p>My main issue with the app is that it lacks a home screen widget I could use to quickly check my car’s battery status, unlike apps for other electric car brands like <a href="https://riviantrackr.com/news/rivian-release-mobile-app-2-8-0-update/" target="_blank">Rivian</a>, <a href="https://9to5mac.com/2024/11/12/fordpass-control-center-home-screen-widget/" target="_blank">Ford</a>, and <a href="https://apps.apple.com/us/app/lucid-motors/id1579793272" target="_blank">Lucid</a>.</p><h2>Third-Party Apps<span><a href="#third-party-apps" aria-label="Anchor">#</a></span></h2><p>Meanwhile, others have developed their own Nissan LEAF apps with a custom user interface and additional features (some with a home screen widget!):</p><ul><li><a href="https://mynissanleaf.com/threads/leaf-manager-alternative-carwings-app-for-android.11476/#post-264808" target="_blank">LEAF Manager by Gyathaar</a></li><li><a href="https://www.speakev.com/threads/beta-testers-wanted.12259/" target="_blank">EVA: Leaf by Rob Winters</a></li><li><a href="https://wkjeldsen.dk/myleaf/" target="_blank">My Leaf by Tobias Westergaard Kjeldsen</a></li></ul><p>Unfortunately, I understand that none of these apps are still available to use where I live in North America. 😞</p><p>The developer of “My Leaf” <a href="https://tobis.dk/blog/the-farce-of-nissanconnect-north-america/" target="_blank">shared his frustration in a blog post</a>, explaining how Nissan’s deliberate changes to their North American API forced him to discontinue support for users in the region:</p><blockquote><p>I simply won’t support it any longer because of Nissan of North America’s persistant work on blocking third party clients. I continued to try and support the API during the last 12 months. Playing cat and mouse with Nissan. I simply don’t have the time and honestly the drive to continue when I know Nissan are consistently trying to break third party clients on purpose. It’s a sad and foolishness reality indeed.</p></blockquote><h2>Project Goals<span><a href="#project-goals" aria-label="Anchor">#</a></span></h2><p>Nevertheless, I decided to take on the challenge of developing an iPhone home screen widget that could show me the battery charge status of my Nissan LEAF car.</p><p>I added one more constraint to the project: no spending money. I believe Nissan’s app should already provide a home screen widget, so it didn’t seem fair to have to spend any money on this project. However, using tools/devices I already had access to was fair game.</p><p>Notably, that ruled out using something like <a href="https://sidecar.clutch.engineering/" target="_blank">Sidecar</a> which appears to provide a home screen widget. I think it looks very slick, but it requires the purchase of a wireless <a href="https://en.wikipedia.org/wiki/On-board_diagnostics" target="_blank">On-board Diagnostics (OBD)</a> scanner plus a $6.99 USD/month subscription. 😓</p><p>It also ruled out using the popular <a href="https://apps.apple.com/us/app/leafspy-pro/id967376861" target="_blank">LeafSpyPro app</a> which similarly requires the purchase of a wireless OBD scanner and costs $19.99 USD. To my knowledge, it doesn’t provide a home screen widget itself, but I think you could probably develop one using its data syncing feature.</p><h2>Results<span><a href="#results" aria-label="Anchor">#</a></span></h2><p>I am happy to report I was successful and spent no money! Here is a screenshot of the widget:</p><p><picture><source srcset="https://kevintechnology.com/posts/leaf-widget/widget_hu02aa61ae1d9de35cbe238d2676170cb9_26955_249x250_resize_q75_h2_box.webp" type="image/webp"><img src="https://kevintechnology.com/posts/leaf-widget/widget.ee53de28b5fba496dd2445d7a29ee726.jpg" alt="Screenshot of Nissan LEAF widget on phone home screen displaying battery state of charge, available range, plugged-in status, cabin temperature range, estimated charge time, and date/time last refreshed" loading="lazy" height="250" width="249"></picture></p><p>And if you tap the widget, it opens the NissanConnect app. You’ll notice in the following video that there are a few extra non-ideal screen transitions (more on that below), but hey, you get what you pay for!</p><video controls="" preload="auto" width="50%" loop="" playsinline="">
<source src="https://kevintechnology.com/posts/leaf-widget/tap_widget.mp4" type="video/mp4"><span>Your browser doesn't support embedded videos, but don't worry, you can <a href="https://kevintechnology.com/posts/leaf-widget/tap_widget.mp4">download it</a> and watch it with your favorite video player!</span></video><h2>How it Works<span><a href="#how-it-works" aria-label="Anchor">#</a></span></h2><p>To reduce the risk of any API-breaking changes, I’m just using the official NissanConnect app without any modifications:</p><ol><li>I created a GitHub repo containing a GitHub Action that:<ul><li>uses <a href="https://github.com/EFForg/apkeep" target="_blank"><code>apkeep</code></a> to download the NissanConnect app</li><li>uses <a href="https://appium.io/" target="_blank">Appium</a> to:<ul><li>install and launch the app on an Android device connected to the host via the Android Debugger (ADB)</li><li>automate tapping through the app’s screen to sign into the app using provided account credentials</li><li>scrape and output the text of the vehicle’s status after it refreshes
<a id="github-f4d12b676fe663c52327ee72818560aa" target="_blank" href="https://github.com/kevincon/nissan-connect-scraper"><div><div><p>kevincon/nissan-connect-scraper</p></div><p id="github-f4d12b676fe663c52327ee72818560aa-description">GitHub Action that scrapes the NissanConnect® Android app for info about a Nissan LEAF vehicle.</p></div></a></li></ul></li></ul></li><li>I created a separate GitHub repo containing a GitHub Actions workflow scheduled to run a job multiple times throughout the day that:<ul><li>uses <a href="https://tailscale.com/" target="_blank">Tailscale</a> to ephemerally connect the job’s GitHub runner host to a <a href="https://tailscale.com/kb/1136/tailnet" target="_blank">tailnet</a> on which there is already connected a <a href="https://en.wikipedia.org/wiki/Raspberry_Pi_4" target="_blank">Raspberry Pi 4B</a> with 2 GB RAM (sitting on my desk at home) that is running <a href="https://konstakang.com/devices/rpi4/AOSP15/" target="_blank">Android 15</a> with ADB turned on</li><li>connects to the Raspberry Pi via ADB</li><li>runs the GitHub Action from (1) using my Nissan account credentials stored in <a href="https://docs.github.com/en/actions/security-for-github-actions/security-guides/using-secrets-in-github-actions" target="_blank">GitHub Actions secrets</a></li><li>formats the scraped vehicle data and sends it in an email to <a href="https://ifttt.com/" target="_blank">IFTTT</a>
<a id="github-9bd3a31169b1be037950bc6e95acb758" target="_blank" href="https://github.com/kevincon/nissan-leaf-widget-updater"><div><div><p>kevincon/nissan-leaf-widget-updater</p></div><p id="github-9bd3a31169b1be037950bc6e95acb758-description">GitHub Actions workflow that runs on a schedule to update a widget on my phone with information about my Nissan LEAF.</p></div></a></li></ul></li><li>I created an Apple Shortcut on my iPhone named <code>OpenNissanConnect</code> that opens the NissanConnect app: <a href="https://www.icloud.com/shortcuts/fd139fa01719483a89fcbde391435ff7" target="_blank">https://www.icloud.com/shortcuts/fd139fa01719483a89fcbde391435ff7</a>
<picture><source srcset="https://kevintechnology.com/posts/leaf-widget/apple_shortcut_hu02aa61ae1d9de35cbe238d2676170cb9_120958_1178x717_resize_q75_h2_box.webp" type="image/webp"><img src="https://kevintechnology.com/posts/leaf-widget/apple_shortcut.0700865d3f6127e7aa6d941879c3d0fb.jpg" alt="Apple shortcut configuration showing that it opens the NissanConnect EV &amp; Services app and then stops and outputs nothing&quot;" loading="lazy" height="717" width="1178"></picture></li><li>I created a free IFTTT applet that triggers on the email sent by the workflow from (2) and displays the body of the email within a <a href="https://help.ifttt.com/hc/en-us/articles/115010361688-How-do-I-manage-or-add-new-widgets-on-my-device" target="_blank">“Notification Widget”</a> on my iPhone’s home screen
<picture><source srcset="https://kevintechnology.com/posts/leaf-widget/ifttt_steps_hu385b88504cffe4ceca3bb8aec228cbc8_65368_1138x754_resize_q75_h2_box_3.webp" type="image/webp"><img src="https://kevintechnology.com/posts/leaf-widget/ifttt_steps.fb839f138bfe4e6309c648765e617907.png" alt="IFTTT configuration showing the “If” condition is “Send IFTTT an email tagged” and the “Then” action is “Send a rich notification to the IFTTT mobile widget”" loading="lazy" height="754" width="1138"></picture></li></ol><p><picture><source srcset="https://kevintechnology.com/posts/leaf-widget/ifttt_email_config_hu010179562c2768a9dedd95755de8ab13_109284_944x1160_resize_q75_h2_box_3.webp" type="image/webp"><img src="https://kevintechnology.com/posts/leaf-widget/ifttt_email_config.7ff94c9e5a7089ce89c395cb9d9260e4.png" alt="IFTTT configuration for the “Then” action, the Message is set to the Body of the email received, the title is set to “Nissan LEAF® 🍃”, and the Link URL is set to a TinyURL (described below). The optional Image URL field is left blank." loading="lazy" height="1160" width="944">
</picture>The <code>Link URL</code> field contains a <a href="https://tinyurl.com/" target="_blank">TinyURL</a> that redirects to <code>shortcuts://run-shortcut?name=OpenNissanConnect</code> which uses the <a href="https://support.apple.com/guide/shortcuts/run-a-shortcut-from-a-url-apd624386f42/ios" target="_blank">Shortcuts URL scheme</a> to run the Apple Shortcut from (3). I did this because IFTTT seems to check that the <code>Link URL</code> you provide actually resolves to a valid web URL; otherwise, the IFTTT website just opens and displays an error when you tap on the widget.</p><p>The NissanConnect app developers could definitely make changes that would break how this widget works, but those changes would by definition probably negatively affect regular human users too which I hope they would want to avoid.</p><h2>Future Work<span><a href="#future-work" aria-label="Anchor">#</a></span></h2><p>My original plan was to <a href="https://github.com/ReactiveCircus/android-emulator-runner" target="_blank">run an Android emulator on the GitHub Actions runner in the cloud</a> so I wouldn’t need to maintain my own Android device, and that <em>almost</em> works (in fact, it does work on my M3 Apple Silicon macOS laptop using an <code>arm</code> Android emulator), but it seems like the NissanConnect app (or maybe the server it connects to) may detect when <code>x86_64</code> Android is being used and then refuse to sign in. Or at least, I always saw the following error when I tried both in the cloud and on an old <code>x86_64</code> laptop I had:</p><p><picture><source srcset="https://kevintechnology.com/posts/leaf-widget/unauthorized_hu427daf76cdb694d7cbb4bae00ccd751d_85662_362651fbcfba6d2631859724bbf27163.webp" type="image/webp"><img src="https://kevintechnology.com/posts/leaf-widget/unauthorized_hu427daf76cdb694d7cbb4bae00ccd751d_85662_400x0_resize_box_3.602121f903180517fe8c7266aa71c3c5.png" alt="Screenshot of Nissan Connect app sign in window with “< html > < head > < title > Error</title > </ head > < body > Unauthorized</body> </ html >” error pop-up" loading="lazy" height="535" width="400"></picture></p><p>And unfortunately, at the time of writing, I understand:</p><ol><li>a cloud VM environment must support nested virtualization in order to run an Android emulator with hardware acceleration</li><li>the only macOS <code>arm</code> runners GitHub provides are M1 and <a href="https://github.com/github/roadmap/issues/985" target="_blank">M2</a> machines, but <a href="https://developer.apple.com/documentation/virtualization/vzgenericplatformconfiguration/isnestedvirtualizationsupported#:~:text=Nested%20virtualization%20is%20available%20for%20Mac%20with%20the%20M3%20chip%2C%20and%20later." target="_blank">nested virtualization is only available on M3 and later</a></li><li>the only other <code>arm</code> runner GitHub supports is a <a href="https://github.blog/changelog/2025-01-16-linux-arm64-hosted-runners-now-available-for-free-in-public-repositories-public-preview/" target="_blank">Linux <code>arm64</code> runner</a> whose <a href="https://github.com/orgs/community/discussions/19197#discussioncomment-12012161" target="_blank">hardware does not support nested virtualization</a></li></ol><p>Luckily, the NissanConnect app has a “demo mode” that does not require signing into an account to use, so I was able to run an Android emulator in the cloud as part of <a href="https://github.com/kevincon/nissan-connect-scraper/blob/main/.github/workflows/prci.yml" target="_blank">the automated continuous integration testing for the GitHub Action</a>.</p><p>Maybe <a href="https://github.com/TryQuiet/quiet/issues/1879#issuecomment-2318276431" target="_blank">if GitHub Actions adds support for M3 Apple Silicon runners</a> in the future, then I might be able to switch to running all of this in the cloud for free… 🤞</p><p>…or I might trade in my Nissan LEAF and get a different electric car with a better app experience before that happens. 😅</p></div></div>]]></description>
        </item>
    </channel>
</rss>