<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 06 Aug 2023 02:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Jeremy Vaught spent 16 years to build @music on Twitter, then X took it away (216 pts)]]></title>
            <link>https://syzito.xyz/@selzero/110837319716739179</link>
            <guid>37016876</guid>
            <pubDate>Sat, 05 Aug 2023 22:31:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://syzito.xyz/@selzero/110837319716739179">https://syzito.xyz/@selzero/110837319716739179</a>, See on <a href="https://news.ycombinator.com/item?id=37016876">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[CEOs’ pay climbed before layoffs at tech giants like Alphabet and Microsoft (212 pts)]]></title>
            <link>https://southernillinoisnow.com/2023/08/05/ceos-pay-climbed-before-layoffs-at-tech-giants-like-alphabet-and-microsoft-data-shows/</link>
            <guid>37016424</guid>
            <pubDate>Sat, 05 Aug 2023 21:21:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://southernillinoisnow.com/2023/08/05/ceos-pay-climbed-before-layoffs-at-tech-giants-like-alphabet-and-microsoft-data-shows/">https://southernillinoisnow.com/2023/08/05/ceos-pay-climbed-before-layoffs-at-tech-giants-like-alphabet-and-microsoft-data-shows/</a>, See on <a href="https://news.ycombinator.com/item?id=37016424">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
<figure><figcaption>Steve Taylor/SOPA Images/LightRocket via Getty Images</figcaption></figure><p>(NEW YORK) —&nbsp;While some tech giants neared or imposed widespread layoffs last year, compensation for their CEOs climbed as much as tens of millions of dollars, according to an ABC News analysis of data released by research firm Equilar in May and June.</p><p>Alphabet CEO Sundar Pichai was awarded compensation worth more than $225 million in 2022, which marked a staggering 3,474% increase from the previous year, making him the nation’s highest-paid CEO, according to Equilar data.</p><p>Near the outset of 2023, Alphabet announced plans to lay off 10,000 workers.</p><p>At Microsoft, which initiated plans to lay off 10,000 workers in January, CEO Satya Nadella received compensation worth nearly $55 million in 2022 — a 10% jump from the prior year, the data showed.</p><p>Meta, Uber and Salesforce are also among more than a dozen tech companies that gave their CEOs a compensation increase last year, despite announcing layoffs at some point since the start of 2022, according to the ABC News analysis of the Equilar data.</p><p>Roughly 389,000 tech workers have been laid off since the beginning of 2022, according to Layoffs.fyi, a site that tracks layoffs. The job cuts have befallen some of the nation’s most well-known and large companies.</p><p>Alphabet, Meta, Uber and Salesforce did not respond to ABC News’ requests for comment.</p><p>The rise of CEO pay amid a cascade of job losses at some household-name tech firms draws attention to the divergent fates of executives and workers in one of the nation’s most lucrative fields, which matches an economy-wide trend of a widening gap between the pay of CEOs and workers, analysts told ABC News.</p><p>CEO compensation often includes a base salary and a performance bonus but is typically made up in large part by stock awards that align the CEO primarily with shareholders, analysts added. The incentive structure can push a CEO to safeguard the health of a company but also reward short-term cost cuts that imperil workers, they said.</p><p>The disparate outcomes for CEOs and workers at some tech firms heightens an ongoing dispute about whether companies should shift consideration toward other stakeholders beyond investors, such as employees and customers, David Larcker, a professor of accounting, Emeritus, at Stanford University who researches corporate governance, told ABC News</p><p>“It’s a huge question,” Larcker said. “From a CEO’s perspective, if you have to shut down something that isn’t profitable, you can obviously increase the stock price and earnings and get a big bonus out of that.”</p><p>From workers’ point of view, meanwhile, “companies have a lot to say about how employees are their most important assets and sometimes actions seem a lot more shareholder-friendly,” Larcker added.</p><p>To be sure, Equilar calculated the value of CEO compensation packages when they were awarded at the outset of last fiscal year. For many companies, the stock price had dropped by the end of the year, leaving the CEO’s compensation lower than the figure listed by Equilar. The value of Pichai’s compensation package, for instance, fell to about $205 million by the end of fiscal year 2022, according to a follow-up Equilar analysis shared with ABC News.</p><p>Under the terms of Pichai’s compensation package, he will not receive the full value unless the company achieves a set of goals, including strong stock performance relative to other large companies, a government filing shows.</p><p>Meanwhile, the ultimate value of the compensation package received by Nadella is dependent on a range of company performance metrics that “are intended to be difficult but attainable,” Microsoft told shareholders in December.</p><p>Months earlier, in May 2022, Microsoft announced an increase in its budget devoted to pay and stock compensation for employees that year. The company will not provide raises for salaried employees in 2023, according to a company memo first reported by Insider in May.</p><p>In response to ABC News’ request for comment, a Microsoft spokesperson noted that the compensation awarded to Nadella last year preceded the layoff plans announced in January.</p><p>The vast majority of the compensation awarded to Zuckerberg in 2022 is devoted to his security and use of a private plane, Meta told shareholders. Since 2013, Zuckerberg has received an annual salary of $1.</p><p>The value of a stock award made up 70% of the typical compensation package for the 100 highest-paid CEOs last year, Amit Batish, director of content at Equilar, told ABC News. Company performance thresholds often found in CEO compensation packages include stock performance, sales growth and product user totals.</p><p>Job losses in the relatively well-paid industry, meanwhile, have coincided with otherwise robust hiring across the economy, which boasts an unemployment rate hovering near a 50-year low.</p><p>“Especially in tech, I think it’s a shock to tech workers who have always been in such high demand to be experiencing these layoffs,” Lisa LaViers, a professor at Tulane University’s Freeman School of Business who studies executive pay and its effect on workers, told ABC News.</p><p>At tech firms where CEOs received an increase in compensation alongside layoffs, the divergent fortunes likely exacerbated worker dismay, LaViers added.</p><p>“If you gave the CEO a large bonus and you laid off a lot of workers, I can’t imagine a scenario under which that wouldn’t upset employees,” she said.</p><p>Key attributes of executive and worker compensation complicate the moral outrage, however, LaViers said.</p><p>Executive compensation sometimes includes stock options that cannot be sold within a year of when a CEO receives them, meaning that compensation received in a given year does not necessarily equate to money brought in by an executive. Meanwhile, many non-executive level tech employees receive stock options as part of their compensation, tying their income to that of shareholders, she said, though employee stock options are a fraction of what CEOs receive.</p><p>Uber, which has laid off hundreds of employees this year, gave CEO Dara Khosrowshahi compensation worth about $24 million in 2022, which amounted to a 22% increase from the previous year, Equilar data showed.</p><p>A corporate worker laid off by Uber this year, who requested anonymity for fear of negative consequences if they spoke publicly, described the dynamic of job cuts alongside pay increases as “very frustrating.”</p><p>Responding to Khosrowshahi’s push for a “culture change” that focused on the mission-based aspirations of Uber, the laid-off worker asked, “Did Dara really care about doing the right thing?”</p><p>“There’s a lot of lip service paid to ‘Oh, we want to have a culture’ but it’s all in the service of profitability,” the laid-off worker added.</p><p>After imposing a round of layoffs last month that affected up to 50 employees at Uber’s trucking subsidiary, Uber Freight, a company spokesperson told outlet Freight Waves in a statement: “On the back of efficiency gains realized across the business and to ensure continued alignment between our cost structure and the current market realities, we are reducing the workforce in our Brokerage business across a small number of roles.”</p><p>The full compensation package awarded to Khosrowshahi is dependent upon the company’s fulfillment of key objectives, Uber told shareholders.</p><p>Similarly, a worker interviewed by ABC News who was laid off this year by data-storage firm Western Digital expressed disappointment after finding out that CEO David Goeckeler received a 42% pay increase in 2022, according to Equilar data.</p><p>“I was making money for this guy instead of making money for myself,” said the worker, who requested anonymity due to the terms of a severance agreement. “It’s the sickness of the whole system.”</p><p>To receive the full value of his compensation package, Goeckler must achieve a variety of short- and long-term company performance goals, Western Digital told investors.</p><p>Western Digital did not immediately respond to a request for comment.</p><p>Larcker, of Stanford University, said that a corporate shift in focus away from shareholders and toward other constituencies could limit instances of egregious divergence between the outcomes of CEOs and workers. Though layoffs, he added, are unavoidable, especially in tech.</p><p>“Tech is a risky business,” Larcker said. “But companies can be better off when they change course in a way that doesn’t crush workers.”</p><p>Copyright © 2023, ABC Audio. All rights reserved.</p><!-- #entry-meta -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MK-1 (183 pts)]]></title>
            <link>https://mkone.ai/blog/introducing-mk1</link>
            <guid>37016413</guid>
            <pubDate>Sat, 05 Aug 2023 21:20:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mkone.ai/blog/introducing-mk1">https://mkone.ai/blog/introducing-mk1</a>, See on <a href="https://news.ycombinator.com/item?id=37016413">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page" role="main">
        
          
<article id="sections" data-page-sections="64b8303ac41a0b266f5cf399">
  
  
    
    


  


<div data-content-field="main-content" data-item-id="" data-test="page-section" data-section-theme="white-bold" data-section-id="64b8303ac41a0b266f5cf39b" data-controller="SectionWrapperController" data-current-styles="{
&quot;imageOverlayOpacity&quot;: 0.15,
&quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
&quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
&quot;customSectionHeight&quot;: 10,
&quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
&quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
&quot;contentWidth&quot;: &quot;content-width--wide&quot;,
&quot;customContentWidth&quot;: 50,
&quot;sectionTheme&quot;: &quot;white-bold&quot;,
&quot;sectionAnimation&quot;: &quot;none&quot;,
&quot;backgroundMode&quot;: &quot;image&quot;
}" data-current-context="{
&quot;video&quot;: {
&quot;playbackSpeed&quot;: 0.5,
&quot;filter&quot;: 1,
&quot;filterStrength&quot;: 0,
&quot;zoom&quot;: 0,
&quot;videoSourceProvider&quot;: &quot;none&quot;
},
&quot;backgroundImageId&quot;: null,
&quot;backgroundMediaEffect&quot;: null,
&quot;divider&quot;: null,
&quot;typeName&quot;: &quot;blog-side-by-side&quot;
}" data-animation="none">
  <article id="article-">
  
    <div data-layout-label="Post Body" data-type="item" id="item-64c9458b5048b2430141ed79"><div><div data-block-type="2" id="block-21ffb1b5f5c3265ff31b">
  <p>Do you ever wonder how companies like OpenAI, Anthropic, and Google serve their large language models economically? For instance, they are able to generate dozens of tokens per second for each user while keeping the costs to a fraction of a penny per request. While these feats of engineering are proprietary, you can be sure that they employ every technique available to optimize their inference stack.</p><p><strong>Enter MK-1</strong>. Our mission is to give every company running AI models similar (or better) capabilities as these elite AI powerhouses. We're obsessed with performance and efficiency, and have developed our own tools that rival anything out there. Today, we’re announcing our first product, MKML. MKML is a software package that can reduce LLM inference costs on GPUs by 2x with just a few lines of Python code. And it is plug and play with popular ecosystems like Hugging Face and PyTorch.</p><p>For a quick demo, here’s a Llama-2 7B running over twice as fast with MKML compared to the baseline model (FP16) on an RTX 4090 GPU.</p>
</div><div data-block-type="2" id="block-209fc631e097892a5554">
  <p>Currently, MKML is in closed beta release. If you are interested in becoming an early partner and getting access to new features first, please contact us below. </p><h2>How can MKML help?</h2><p>Suppose you want to run a chatbot on the cloud using a Llama-2 13B model. Despite being one of the smaller Llama models, it requires 26GB (FP16) of memory – just for the parameters! This has two implications:</p><ol data-rte-list="default"><li><p>Loading the model requires a GPU instance with enough memory, such as a pricey A100 40GB.</p></li><li><p>Running the model requires reading all 26GB from GPU memory for each forward pass, and this can impact the speed of token generation.</p></li></ol><p>The key observation is that the model’s large memory footprint is the critical bottleneck. MKML solves this: we have a one-time procedure that shrinks its size by ~60% while keeping a very high <span data-text-attribute-id="ffd0f9c0-aaa8-4ff6-bd9a-73e8b2dc1ce3"><strong>fidelity</strong></span> to the original model, which we will explain later in this post. So the 13B model shrinks from 26GB all the way down to 10.5GB. And crucially, MKML reduces the inference time for the forward pass by up to <span data-text-attribute-id="dc88a0a1-5047-4992-bc89-810fb4e45aae"><strong>2.3x</strong></span> compared to the base model on the same GPU, and these gains are multiplicative with system-level optimizations like continuous batching.</p><p>Let’s explore two scenarios of how you might leverage MKML to optimize a Llama-2 13B chatbot.</p><h3>Case 1: Cost optimized</h3><p>With our compression, the Llama-2 13B model now fits on a single A10 24GB instance, which is ~45% less expensive than the A100. And incredibly, despite the A10 being less powerful than the A100 in terms of compute and memory bandwidth, MKML token generation on the A10 is still faster than the baseline model on the A100.</p>
</div></div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-2e146a5a32fbfbefb318">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/64b82ec2cac59465c6dd7813/87af060b-ed98-41dd-9590-4ba7e852ac92/Blog+Plot+-+Page+1.png" data-image="https://images.squarespace-cdn.com/content/v1/64b82ec2cac59465c6dd7813/87af060b-ed98-41dd-9590-4ba7e852ac92/Blog+Plot+-+Page+1.png" data-image-dimensions="1948x1219" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/64b82ec2cac59465c6dd7813/87af060b-ed98-41dd-9590-4ba7e852ac92/Blog+Plot+-+Page+1.png" width="1948" height="1219" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/64b82ec2cac59465c6dd7813/87af060b-ed98-41dd-9590-4ba7e852ac92/Blog+Plot+-+Page+1.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/64b82ec2cac59465c6dd7813/87af060b-ed98-41dd-9590-4ba7e852ac92/Blog+Plot+-+Page+1.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/64b82ec2cac59465c6dd7813/87af060b-ed98-41dd-9590-4ba7e852ac92/Blog+Plot+-+Page+1.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/64b82ec2cac59465c6dd7813/87af060b-ed98-41dd-9590-4ba7e852ac92/Blog+Plot+-+Page+1.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/64b82ec2cac59465c6dd7813/87af060b-ed98-41dd-9590-4ba7e852ac92/Blog+Plot+-+Page+1.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/64b82ec2cac59465c6dd7813/87af060b-ed98-41dd-9590-4ba7e852ac92/Blog+Plot+-+Page+1.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/64b82ec2cac59465c6dd7813/87af060b-ed98-41dd-9590-4ba7e852ac92/Blog+Plot+-+Page+1.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-ddc3a1f7201b5947ba84">
  <h3>Case 2: Speed optimized</h3><p>If the budget allows for the A100 instance, MKML’s performance really starts to shine. In this case, MKML is ~2.0x faster than the baseline, which translates to serving more users. In addition, the memory saved on the A100 from the smaller model can be used to support larger context windows across users.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-0b0d657ed8b23369224a">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/64b82ec2cac59465c6dd7813/194a806d-1ee8-4f24-9eac-7e64399a4a98/Blog+Plot+-+Page+2.png" data-image="https://images.squarespace-cdn.com/content/v1/64b82ec2cac59465c6dd7813/194a806d-1ee8-4f24-9eac-7e64399a4a98/Blog+Plot+-+Page+2.png" data-image-dimensions="1954x1369" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/64b82ec2cac59465c6dd7813/194a806d-1ee8-4f24-9eac-7e64399a4a98/Blog+Plot+-+Page+2.png" width="1954" height="1369" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/64b82ec2cac59465c6dd7813/194a806d-1ee8-4f24-9eac-7e64399a4a98/Blog+Plot+-+Page+2.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/64b82ec2cac59465c6dd7813/194a806d-1ee8-4f24-9eac-7e64399a4a98/Blog+Plot+-+Page+2.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/64b82ec2cac59465c6dd7813/194a806d-1ee8-4f24-9eac-7e64399a4a98/Blog+Plot+-+Page+2.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/64b82ec2cac59465c6dd7813/194a806d-1ee8-4f24-9eac-7e64399a4a98/Blog+Plot+-+Page+2.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/64b82ec2cac59465c6dd7813/194a806d-1ee8-4f24-9eac-7e64399a4a98/Blog+Plot+-+Page+2.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/64b82ec2cac59465c6dd7813/194a806d-1ee8-4f24-9eac-7e64399a4a98/Blog+Plot+-+Page+2.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/64b82ec2cac59465c6dd7813/194a806d-1ee8-4f24-9eac-7e64399a4a98/Blog+Plot+-+Page+2.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div><div data-block-type="2" id="block-eae6266d85d12b927053">
  <p>In summary, there are multiple ways MKML can help an engineer optimize their inference stack depending on their use case. In this example we picked a Llama-2 model, but MKML will work out of the box with other popular language models such as Falcon, MPT and GPT-J.</p><h2>MKML is Easy to Integrate</h2><p>Our approach with MKML is to bring production-level performance to the most flexible and widely used ecosystems out there. Here is an example workflow using Hugging Face.</p><p><strong><em>Model Compression</em></strong>: First, we load in an original Hugging Face model, and compress it using one of our MKML model codecs. Here we chose our MK600 codec, which shrinks the model’s size by ~60%. The compressed model is then saved to disk so it can be later loaded for inference. It's important to note that model compression is a one-time process and only needs to be repeated if the weights change, say from fine-tuning. It usually takes under a minute for a 7B parameter model.</p>
</div><div data-block-type="44" id="block-3de11b0aa4b3cd6a5e8d"><pre><code>from transformers import AutoModelForCausalLM
import mkml

model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16)
model = mkml.compress(model, codec="mk600")
mkml.save(model, output_path)</code></pre>

</div><div data-block-type="2" id="block-559a670b6db215d117b7">

<p><strong><em>Model Inference:</em></strong> Next, we load our model using MKML and use it immediately for inference. You can interact with it the same way you would the Hugging Face model, so it is plug and play with all your normal workflows. The main difference is that it now takes less memory and is more performant 🤗🔥.</p>



</div><div data-block-type="44" id="block-48b5e5e812e8d7d7626e"><pre><code># Only change required: Load model with mkml instead of Hugging Face

# from transformers import AutoModelForCausalLM
# model = AutoModelForCausalLM.from_pretrained(args.model_path, torch_dtype=torch.float16)

import mkml
model = mkml.load(model_path, device=device)

# ------------------------------------------------------
# Code from this point on is the same as usual 
from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained(model_path)

prompt = "What are some differences between a llama and an alpaca?"
input_ids = tokenizer(prompt, return_tensors="pt").input_ids.cuda()
tokens = model.generate(input_ids)
response = tokenizer.decode(tokens[0, input_ids.shape[1]:])</code></pre>

</div><div data-block-type="2" id="block-7e2bd3f4ea02ac5926ad">
  <h2>Benchmarks</h2><p>MKML supports a wide range of model sizes and system configurations. We benchmarked the speed for Llama-2 7B and 13B for different batch sizes and GPUs, and MKML is consistently faster than baseline on a coldstart speed test. Specifically, coldstart measures the rate of token generation during auto-regression, and is a key metric for estimating model latency and throughput. In this test, we generate 128 tokens starting from a single token prompt.</p>
</div><div data-block-type="2" id="block-f4adb299149dec1526de">

<p>Note that for the Llama-2 13B, some baseline FP16 models <strong>do not</strong> even fit on certain GPUs at all due to their large memory footprint. However, MKML models <strong>do</strong> run on these GPUs and we report these numbers accordingly.</p>



</div><div data-block-type="2" id="block-40e857dfbec6a2247445">

<p>We also benchmarked model fidelity using a standard perplexity measure for all the different Llama-2 models. The takeaway is that our compressed model is around 0.01 difference from the baseline model, which for all intents and purposes is a negligible difference. Stay tuned for a more detailed analysis on model fidelity where we will introduce our other model codecs with different compression ratios.</p>



</div><div data-block-type="23" id="block-e5112e52a1196bb375d3"><center>
<table>
<thead>
<tr>
<th>Perplexity (wikitext2)</th>
<th>Llama-2-7B</th>
<th>Llama-2-13B</th>
<th>Llama-2-70B</th>
</tr>
</thead>
<tbody>
<tr>
<td>FP16</td>
<td>5.472</td>
<td>4.884</td>
<td>3.319</td>
</tr>
<tr>
<td>mk600</td>
<td>5.485</td>
<td>4.887</td>
<td>3.324</td>
</tr>
</tbody>
</table>
</center></div><div data-block-type="2" id="block-8ac6043ec8797b6543e5">
  <h2>What’s next for MK-1?</h2><p>Currently, we believe that MKML offers the best balance between model fidelity, memory footprint and speed with the added benefit of being easy to use. We are just getting started.</p><p>Our long-term vision is to push the performance of AI to the very limits of what’s physically possible across the entire inference stack. We have an ambitious roadmap that we are excited to share as we make progress. If you are interested in keeping up to date with our journey please sign up below.</p>
</div></div>
  
</article>

</div>

  
</article>


          

          
            
              

            
          
        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[First video of LK-99 Full Levitation, a.k.a. flux-pinning (107 pts)]]></title>
            <link>https://twitter.com/Andercot/status/1687740396691185664</link>
            <guid>37016167</guid>
            <pubDate>Sat, 05 Aug 2023 20:49:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/Andercot/status/1687740396691185664">https://twitter.com/Andercot/status/1687740396691185664</a>, See on <a href="https://news.ycombinator.com/item?id=37016167">Hacker News</a></p>
Couldn't get https://twitter.com/Andercot/status/1687740396691185664: Error [ERR_FR_TOO_MANY_REDIRECTS]: Maximum number of redirects exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[nic.funet.fi: Serving freely distributable files with FTP since 1990 (236 pts)]]></title>
            <link>https://www.funet.fi/</link>
            <guid>37015585</guid>
            <pubDate>Sat, 05 Aug 2023 19:36:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.funet.fi/">https://www.funet.fi/</a>, See on <a href="https://news.ycombinator.com/item?id=37015585">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<tbody><tr><td>

<center>

<br>
<h3>Linux</h3><p>

<a href="https://www.funet.fi/pub/Linux/INSTALL/almalinux/">Alma</a>,
<a href="https://www.funet.fi/pub/Linux/INSTALL/Centos/">Centos</a>,
<a href="https://www.funet.fi/pub/Linux/INSTALL/Debian/">Debian</a>,
<a href="https://www.funet.fi/pub/Linux/INSTALL/fedora/">Fedora</a>, 
<a href="https://www.funet.fi/pub/Linux/kernel">Kernel</a>, 
<a href="https://www.funet.fi/pub/Linux/INSTALL/knoppix/">Knoppix</a>,
<a href="https://www.funet.fi/pub/Linux/INSTALL/lubuntu/">Lubuntu</a>,
<a href="https://www.funet.fi/pub/Linux/INSTALL/mx/">MX</a>,
<a href="https://www.funet.fi/pub/Linux/INSTALL/opensuse/">OpenSuse</a>,
<a href="https://www.funet.fi/pub/Linux/INSTALL/RedHat/">RedHat</a>, 
<a href="https://www.funet.fi/pub/Linux/INSTALL/rockylinux/">Rocky</a>,
<a href="https://www.funet.fi/pub/Linux/INSTALL/scientific/">Scientific</a>,
<a href="https://www.funet.fi/pub/Linux/INSTALL/slackware/">Slackware</a>,
<a href="https://www.funet.fi/pub/Linux/INSTALL/Ubuntu/">Ubuntu</a></p>
<h3>Unix</h3>
<p>
<a href="https://www.funet.fi/pub/unix/4.3bsd">Bsd 4.3</a>,
<!--<a href="/pub/mirrors/blastwave.org/csw/">CSW</a>,-->
<a href="https://www.funet.fi/pub/unix/FreeBSD/">FreeBSD</a>,
<a href="https://www.funet.fi/pub/unix/OpenBSD/">OpenBSD</a>,
<a href="https://www.funet.fi/pub/unix/NetBSD/">NetBSD</a>
</p>
</center>


<center><h3>Programming</h3></center>
<center>
<!--<a href="/pub/mirrors/www.mindview.net/Books/index.html">Bruce Eckel's books</a>,-->
<!--<a href="/index/c++opas/">C++ opas</a>,-->
<a href="https://www.funet.fi/pub/CPAN/">CPAN: The Comprehensive Perl Archive Network</a>, 
<a href="https://www.funet.fi/pub/mirrors/fedora.redhat.com/pub/epel/">EPEL</a>,
<a href="https://www.funet.fi/pub/gnu/">GNU software</a>,
<a href="https://www.funet.fi/pub/mirrors//mariadb.com/mariadb/">MariaDB</a>,
<a href="https://www.funet.fi/pub/mirrors/download.qt-project.org/">Qt</a>,
<a href="https://www.funet.fi/pub/mirrors/sourceware.org/">Sourceware</a>


</center>



<!-- <center><h3>Legacy content</h3></center>
<a href="/pub/mirrors/info-mac.org/">Info-mac</a>,
<a href="/pub/mirrors/simtel.net/">Simtel.net</a>,
<a href="/pub/mirrors/ftp.winsite.com/">Winsite</a>

-->

</td>


<td>




<center><h3>Desktop</h3></center>
<center>
<a href="https://www.funet.fi/pub/mirrors/ftp.gnu.org/pub/gnu/ghostscript/">Ghostscript</a>,
<a href="https://www.funet.fi/pub/mirrors/ftp.gimp.org/">Gimp</a>,
<a href="https://www.funet.fi/pub/mirrors/ftp.kde.org/pub/kde/">KDE</a>,
<a href="http://fi.libreoffice.org/">Libre Office</a>, 
<a href="http://fi.openoffice.org/">Open Office</a>



</center>
<center><h3>Networking &amp; communications</h3></center>
<center>
<a href="https://www.funet.fi/pub/mirrors/apache.org/">Apache</a>,
<a href="https://www.funet.fi/pub/mirrors/ftp.isc.org/isc/">ISC</a>,
<a href="https://www.funet.fi/pub/mirrors/samba.org/pub/rsync/">Rsync</a>,
<a href="https://www.funet.fi/pub/mirrors/samba.org/pub/samba/">Samba</a>,
</center>



<center><h3>Science</h3></center>
<center>
<!--<a href="http://www.virtuaaliyliopisto.fi/maakirjakartat/">1600-luvun maakirjakartat</a>,-->
<a href="https://www.funet.fi/pub/sci/geo/carto/">1600-luvun maakirjakartat</a>,
<a href="https://www.funet.fi/pub/mirrors/ftp.1000genomes.ebi.ac.uk/">1000genomes</a>, 
<a href="https://www.funet.fi/pub/mirrors/ftp.ebi.ac.uk/">EBI</a>, 
<a href="https://www.funet.fi/pub/mirrors/hgdownload.cse.ucsc.edu/goldenPath/hg18/encodeDCC/">encodeDCC</a>, 
<a href="https://www.funet.fi/pub/mirrors/ftp.ensembl.org/">Ensembl</a>, 
<a href="https://www.funet.fi/pub/mirrors/ftp.genome.jp/pub/kegg">kegg</a>, 
<a href="https://www.funet.fi/pub/mirrors/ftp.ncbi.nlm.nih.gov/">NCBI</a>, 
<a href="https://www.funet.fi/pub/mirrors/ftp.expasy.org/databases/prosite/">prosite</a>, 
<a href="https://www.funet.fi/pub/mirrors/ftp.sanger.ac.uk/pub/databases/Pfam/">Pfam</a>, 
<a href="http://bio.nic.funet.fi/pub/sci/molbio/chipster/">Chipster</a>,
<a href="http://www.csc.fi/elmer/">Elmer - CSC's tool for multiphysics</a>,
<a href="https://avaa.tdata.fi/web/paituli/ftp-/-rsync">Paituli</a>,
<a href="https://www.funet.fi/pub/TeX/">TeX</a>
</center>



</td>

<td>

<center>
<h3>Internet information</h3>
<a href="https://www.funet.fi/pub/mirrors/ftp.ietf.org/rfc/">RFCs</a>,
<a href="https://www.funet.fi/index/Funet/history/internet/">History of the Internet</a>,
<a href="https://www.funet.fi/pub/mirrors/ftp.ietf.org/">IETF</a>, 
<a href="https://www.funet.fi/pub/mirrors/ftp.ietf.org/internet-drafts/">Internet-drafts</a>



<h3>Archived texts</h3>
<a href="https://www.funet.fi/pub/doc/bible">Bible</a>,
<a href="https://www.funet.fi/pub/doc/literary/finnish/kalevala/">Kalevala</a>,
<a href="https://www.funet.fi/pub/archive">Newsgroups</a>,
<a href="https://www.funet.fi/pub/mirrors/rtfm.mit.edu/pub">RTFM</a>,
<a href="https://www.funet.fi/pub/doc/literary/shakespeare/">Shakespeare</a>



<h3>Amateur arts and science</h3>

<a href="https://www.funet.fi/pub/ham/">Ham</a>, 
<a href="https://www.funet.fi/pub/mirrors/ftp.starwreck.com/StarWreck/">StarWreck</a>,
<a href="https://www.funet.fi/pub/sci/bio/life/">Tree of Life</a>
</center>
</td>





</tr>

<tr> <td colspan="3"><center> <h3> Browse the whole archive </h3></center></td></tr>


<tr>
<td>
<center><b><a href="https://www.funet.fi/pub/">/pub</a></b></center>
<p>The traditional file hierarchy that we have grown since 1990. It includes also many legacy files and directories that are no longer updated</p>
</td>
<td>
<center><b><a href="https://www.funet.fi/pub/mirrors/">/pub/mirrors</a></b></center>

<p> Most of the available files are automatically mirrored from these sites for
the benefit of finnish users. Please check the original site if you
need more information than we have here. </p>

</td>

<td>
<center><b><a href="https://www.funet.fi/index/">/index</a></b></center>

<p>Manually maintained shortcuts to different parts of the pub tree based on package names or keywords.  </p>


</td>
</tr>
</tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[IBM and NASA open-source largest geospatial AI foundation model on Hugging Face (151 pts)]]></title>
            <link>https://newsroom.ibm.com/2023-08-03-IBM-and-NASA-Open-Source-Largest-Geospatial-AI-Foundation-Model-on-Hugging-Face?sf180690117=1</link>
            <guid>37015290</guid>
            <pubDate>Sat, 05 Aug 2023 19:05:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newsroom.ibm.com/2023-08-03-IBM-and-NASA-Open-Source-Largest-Geospatial-AI-Foundation-Model-on-Hugging-Face?sf180690117=1">https://newsroom.ibm.com/2023-08-03-IBM-and-NASA-Open-Source-Largest-Geospatial-AI-Foundation-Model-on-Hugging-Face?sf180690117=1</a>, See on <a href="https://news.ycombinator.com/item?id=37015290">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wd_move_content_up">

<p>Effort aims to widen access to NASA earth science data for geospatial intelligence and accelerate climate-related discoveries</p>
<p>Aug 3, 2023</p>

			<div>
				<p><img src="https://newsroom.ibm.com/image/NASA_2_Banner.jpg"></p>
				
			</div>
		
</div><div wd_resize="formatNews" wd_print_url="https://newsroom.ibm.com/2023-08-03-IBM-and-NASA-Open-Source-Largest-Geospatial-AI-Foundation-Model-on-Hugging-Face?printable=1"><p><span>YORKTOWN HEIGHTS, N.Y.</span>, <span>Aug. 3, 2023</span> /<a href="http://www.prnewswire.com/" target="_blank">PRNewswire</a>/ -- IBM (NYSE: <a href="https://www.ibm.com/investor" rel="nofollow" target="_blank">IBM)</a> and open-source AI platform <a href="https://huggingface.co/" rel="nofollow" target="_blank">Hugging Face</a> today announced that IBM's watsonx.ai geospatial foundation model – built from NASA's satellite data – will now be <a href="https://huggingface.co/ibm-nasa-geospatial" rel="nofollow" target="_blank">openly available on Hugging Face</a>. It will be the largest geospatial foundation model on Hugging Face and the first-ever open-source AI foundation model built in collaboration with NASA.</p>

<p><a href="https://mma.prnewswire.com/media/95470/ibm_logo.html" rel="nofollow" target="_blank"><img alt="IBM Corporation logo. (PRNewsfoto/IBM)" src="https://mma.prnewswire.com/media/95470/ibm_logo.jpg" title="IBM Corporation logo. (PRNewsfoto/IBM)"> </a></p>

<p>Access to the latest data remains a significant challenge in climate science where environmental conditions change almost daily. And, despite growing amounts of data — <a href="https://science.nasa.gov/science-red/s3fs-public/atoms/files/SDMWG%20Strategy_Final.pdf" rel="nofollow" target="_blank">estimates</a>&nbsp;from NASA suggest that by 2024, scientists will have 250,000 terabytes of data from new missions — scientists and researchers still face obstacles in analyzing these large datasets. As part of a Space Act Agreement with NASA, IBM <a href="https://research.ibm.com/blog/ibm-nasa-foundation-models" rel="nofollow" target="_blank">set out</a> earlier this year to build an AI foundation model for geospatial data. And now, by making a geospatial foundation model <a href="https://research.ibm.com/blog/nasa-hugging-face-ibm" rel="nofollow" target="_blank">available via Hugging Face</a>&nbsp;— a recognized leader in open-source and a well-known repository for all transformer models — efforts can advance to democratize access and application of AI to generate new innovations in climate and Earth science.</p>

<p>"The essential role of open-source technologies to accelerate critical areas of discovery such as climate change has never been clearer," said <span>Sriram Raghavan</span>, Vice President, IBM Research AI. "By combining IBM's foundation model efforts aimed at creating flexible, reusable AI systems with NASA's repository of Earth-satellite data, and making it available on the leading open-source AI platform, Hugging Face, we can leverage the power of collaboration to implement faster and more impactful solutions that will improve our planet."</p>

<p>"AI remains a science-driven field, and science can only progress through information sharing and collaboration," said <span>Jeff Boudier</span>, head of product and growth at Hugging Face. "This is why open-source AI and the open release of models and datasets are so fundamental to the continued progress of AI, and making sure the technology will benefit as many people as possible."&nbsp;</p>

<p>"We believe that foundation models have the potential to change the way observational data is analyzed and help us to better understand our planet," said <span>Kevin Murphy</span>, Chief Science Data Officer, NASA. "And by open sourcing such models and making them available to the world, we hope to multiply their impact."</p>

<p>The model – trained jointly by <a href="https://www.earthdata.nasa.gov/news/impact-ibm-hls-foundation-model?tempAccess=ris1bTFmW5Kr0-i7TWCJJAwj5t65AIiJaAdIDI99IbA" rel="nofollow" target="_blank">IBM and NASA</a>&nbsp;on <a href="https://hls.gsfc.nasa.gov/" rel="nofollow" target="_blank">Harmonized Landsat Sentinel-2 satellite data (HLS)</a> over one year across the continental <span>United States</span> and fine-tuned on labeled data for flood and burn scar mapping — has demonstrated to date a 15 percent improvement over state-of-the-art techniques using half as much labeled data. With additional fine tuning, the base model can be redeployed for tasks like tracking deforestation, predicting crop yields, or detecting and monitoring greenhouse gasses. IBM and NASA researchers are also working with <span>Clark University</span> to adapt the model for applications such as time-series segmentation and similarity research.</p>

<p>The news follows IBM's <a href="https://research.ibm.com/blog/ibm-nasa-foundation-models" rel="nofollow" target="_blank">announcement</a> earlier this year to collaborate with NASA to build an AI model that could speed up the analysis of satellite images and boost scientific discovery. It's also part of NASA's decade-long <a href="https://science.nasa.gov/open-science-overview" rel="nofollow" target="_blank">Open-Source Science Initiative</a>&nbsp;to build a more accessible, inclusive, and collaborative scientific community. NASA, along with the White House and other federal agencies, has declared 2023 a <a href="https://www.earthdata.nasa.gov/news/year-of-open-science" rel="nofollow" target="_blank">Year of Open Science</a>&nbsp;to celebrate the benefits and successes created through the open sharing of data, information, and knowledge.</p>

<p>The model leverages IBM <a href="https://research.ibm.com/blog/what-are-foundation-models" rel="nofollow" target="_blank">foundation model technology</a>&nbsp;and is part of IBM's larger effort to create and train AI models that can be used for different tasks and apply information from one situation to another. In July, IBM&nbsp;<a href="https://newsroom.ibm.com/IBM-watsonx-capabilities-are-now-available-to-help-meet-enterprises-AI-for-business-needs" rel="nofollow" target="_blank">announced</a> the availability of <a href="http://www.ibm.com/watsonx?_gl=1*1eo9g2h*_ga*NjI3OTU2MTEwLjE2MzQwNDk4Mzc.*_ga_FYECCCS21D*MTY5MDM4ODEzMC42My4wLjE2OTAzODgxMzAuMC4wLjA." rel="nofollow" target="_blank">watsonx</a>, an AI and data platform that allows enterprises to scale and accelerate impact of the most advanced AI with trusted data. A commercial version of the geospatial model, which is part of IBM watsonx, will be available through the <a href="https://www.ibm.com/account/reg/us-en/signup?formid=urx-52142&amp;_gl=1*1h60pel*_ga*MjAzNjI3MTM1NS4xNjkwNDgyODgx*_ga_FYECCCS21D*MTY5MDQ4Mjg4MS4xLjEuMTY5MDQ4Mzc0NC4wLjAuMA" rel="nofollow" target="_blank">IBM Environmental Intelligence Suite</a>&nbsp;(EIS) later this year.</p>

<p>For more information about this collaboration, visit the <a href="https://research.ibm.com/blog/nasa-hugging-face-ibm" rel="nofollow" target="_blank">IBM Research Blog</a></p>

<p><i>Statements regarding IBM's future direction and intent are subject to change or withdrawal without notice, and represent goals and objectives only.</i></p>

<div><p><b>About IBM</b><br>
IBM is a leading provider of global hybrid cloud and AI, and&nbsp;consulting&nbsp;expertise. We help clients in more than 175 countries capitalize on insights from their data, streamline business processes, reduce costs, and gain the competitive edge in their industries. More than 4,000 government and corporate entities in critical infrastructure areas such as financial services, telecommunications and healthcare rely on IBM's hybrid cloud platform and Red Hat OpenShift to affect their digital transformations quickly, efficiently, and securely. IBM's breakthrough innovations in AI, quantum computing, industry-specific cloud solutions and consulting deliver open and flexible options to our clients. All of this is backed by IBM's legendary commitment to trust, transparency, responsibility, inclusivity, and service.</p><p>

Visit&nbsp;<a href="http://www.ibm.com/" rel="nofollow" target="_blank">www.ibm.com</a>&nbsp;for more information.</p><p>

<strong>Contacts:</strong></p></div>

<p><span>Sarah Benchaita</span><br>
IBM Research<br>
<a href="mailto:sarah.benchaita@ibm.com" rel="nofollow" target="_blank">sarah.benchaita@ibm.com</a></p>

<p><span>Bethany Hill McCarthy</span><br>
IBM Research<br>
<a href="mailto:Bethany@ibm.com" rel="nofollow" target="_blank">Bethany@ibm.com</a></p>





<p>SOURCE IBM</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We’re closer to ‘engineering’ blood vessels (111 pts)]]></title>
            <link>https://pursuit.unimelb.edu.au/articles/we-re-closer-to-engineering-blood-vessels</link>
            <guid>37015208</guid>
            <pubDate>Sat, 05 Aug 2023 18:55:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pursuit.unimelb.edu.au/articles/we-re-closer-to-engineering-blood-vessels">https://pursuit.unimelb.edu.au/articles/we-re-closer-to-engineering-blood-vessels</a>, See on <a href="https://news.ycombinator.com/item?id=37015208">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><section><h2>Republish this article</h2><p><a href="https://creativecommons.org/licenses/by-nd/3.0/au/"><img alt="Creative Commons License" src="https://licensebuttons.net/l/by-nd/3.0/88x31.png"></a> We believe in the free flow of information. This work is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-nd/3.0/au/">Creative Commons Attribution-No Derivatives 3.0 Australia (CC BY-ND 3.0 AU)</a>, so you can republish our articles for free, online or in print.</p><p><strong>All republished articles must be attributed in the following way and contain links to both the site and original article:</strong> “This article was first published on <a href="https://pursuit.unimelb.edu.au/">Pursuit</a>. Read the <a href="https://pursuit.unimelb.edu.au/articles/we-re-closer-to-engineering-blood-vessels">original article</a>.”</p></section><section><h2>Media enquiries</h2><dl><dt>Phone</dt><dd><a href="tel:0061383444123">+61 3 8344 4123</a></dd><dt>Email</dt><dd><a encode="javascript" href="mailto:news@media.unimelb.edu.au">news@media.unimelb.edu.au</a></dd></dl><p>The Media Office is staffed from 8am–5pm Monday to Friday.</p><p>The University has a <a href="http://newsroom.melbourne.edu/about">television and radio studio</a> to facilitate live and prerecorded broadcast quality interviews with media. You can also <a href="http://findanexpert.unimelb.edu.au/">Find an expert</a> for commentary.</p></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Satellite supergroup spots methane super-emitters (109 pts)]]></title>
            <link>https://innovationorigins.com/en/satellite-supergroup-spots-methane-super-emitters-with-staggering-accuracy/</link>
            <guid>37015009</guid>
            <pubDate>Sat, 05 Aug 2023 18:29:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://innovationorigins.com/en/satellite-supergroup-spots-methane-super-emitters-with-staggering-accuracy/">https://innovationorigins.com/en/satellite-supergroup-spots-methane-super-emitters-with-staggering-accuracy/</a>, See on <a href="https://news.ycombinator.com/item?id=37015009">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>Thanks to a new combination of connected satellites, the world’s methane super-emitters can be spotted with “staggering” accuracy and almost real-time. This is a crucial new step in the global fight against climate change. Methane is responsible for a quarter of human-induced global warming and provides a short-term lever on climate change because it remains in the atmosphere for a much shorter time than CO2.</p>
<div><ul><li>Using a combination of satellites, researchers can now detect methane super-emitters globally with great accuracy and almost in real time.</li><li>This allows the identification of major sources of this potent greenhouse gas and is a crucial development for climate change mitigation efforts.</li><li>The tiered approach moves from low-resolution global scans by Sentinel-5P to pinpointed spotting of emitters by Sentinel-3 and Sentinel-2 with increasing spatial resolution</li></ul></div>
<p>ESA’s Copernicus program provides satellite data that enable scientists around the world to monitor climate change and support mitigation efforts. One of the significant challenges is the mitigation of methane, the second most important greenhouse gas contributing to climate change. Combining observations from three Copernicus satellites – Sentinel-5P, Sentinel-3, and Sentinel-2 -now enables researchers to detect and zoom in on methane hot spots in a tiered approach and identify the responsible super-emitters.</p>
<h2>Decision making</h2>
<p>Because methane is so important as a cause of human-induced global warming, knowing where the largest methane emissions occur is key to evidence-based decision-making and successful mitigation. Therefore, expectations and hopes were high when the Sentinel 5 Precursor satellite was launched in 2017. The only instrument onboard Sentinel-5P, the Dutch TROPOspheric Monitoring Instrument (Tropomi), was going to scan the entire globe for a range of trace gases, including methane, every day and at city scale (7 x 5.5 km2) resolution. “The results have been staggering”, a report on SRON’s website says. The Dutch space research institute SRON (co-principal investigator of Tropomi) has, for instance, used TROPOMI’s global coverage to find methane emission hot spots worldwide. These Tropomi hot spots have subsequently been targeted with high-resolution (25 meters) observations from the Canadian GHGSat satellites, which can pinpoint the exact sources. In this way, the researchers found many methane super-emitters, varying from fossil fuel facilities to individual landfills.</p><div>
<h4>Support Us!</h4>


</div>
<div><div><p><img width="150" height="84" src="https://innovationorigins.com/app/uploads/2021/01/Schermafbeelding-2021-01-14-om-22.48.49.png" alt="" decoding="async" loading="lazy" srcset="https://innovationorigins.com/app/uploads/2021/01/Schermafbeelding-2021-01-14-om-22.48.49.png 1472w, https://innovationorigins.com/app/uploads/2021/01/Schermafbeelding-2021-01-14-om-22.48.49-678x378.png 678w, https://innovationorigins.com/app/uploads/2021/01/Schermafbeelding-2021-01-14-om-22.48.49-1004x559.png 1004w, https://innovationorigins.com/app/uploads/2021/01/Schermafbeelding-2021-01-14-om-22.48.49-354x197.png 354w, https://innovationorigins.com/app/uploads/2021/01/Schermafbeelding-2021-01-14-om-22.48.49-768x428.png 768w, https://innovationorigins.com/app/uploads/2021/01/Schermafbeelding-2021-01-14-om-22.48.49-217x121.png 217w" sizes="(max-width: 150px) 100vw, 150px"></p></div><div><p>From a business park in Noordwijk to an international hotspot for space: NL Space Campus</p><p>Many Dutch people will be familiar with Space Expo, which attracts over 100,000 visitors in normal years. But less visible is what else happens at the Space Campus.</p></div></div>
<h2>Powerful</h2>
<p>However, GHGSat observations cannot cover the entire world and only part of the observations are publicly available. The gaps have recently partly been filled with land-imaging satellites such as Sentinel-2, which can detect the largest methane leaks under favorable observing conditions such as over deserts. Sentinel-2’s high-resolution observations (20 m) provide global coverage every 5 days and were designed to provide operational data products for environmental risk management, land cover classification, and land change detection. Sentinel-2 is especially powerful in detecting methane leaks in a tiered approach, where Tropomi Sentinel 5P is used to tip-and-cue high spatial resolution satellites.</p>
<h2><strong>Missing link</strong></h2>
<p>The tiered approach has become even more compelling using Sentinel-3, as researchers at SRON Netherlands Institute For Space Research and JPL show in&nbsp;<a href="https://www.sciencedirect.com/science/article/pii/S0034425723002675">this week’s published paper</a>. Zooming in on an area as large as 7 x 5,5 km2 to pinpoint a fossil fuel facility at Sentinel-2’s resolution can be challenging. Moreover, as Sentinel-2 observes locations only every five days, chances are that short-term methane emissions like gas blowouts escape identification. That is where Sentinel-3 comes in. With daily global coverage and the ability to pinpoint the largest methane point sources to within 500×500 m2 (under favorable observing conditions), Sentinel-3 is the missing link between Tropomi and Sentinel-2. Sentinel-3’s daily global coverage is also particularly important for large leaks that only last a few hours and could easily go unnoticed between Sentinel-2 overpasses.</p>
<div><div><p><img width="150" height="84" src="https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1.png" alt="" decoding="async" loading="lazy" srcset="https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1.png 3000w, https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1-678x381.png 678w, https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1-1004x565.png 1004w, https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1-354x199.png 354w, https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1-768x432.png 768w, https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1-1536x864.png 1536w, https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1-2048x1152.png 2048w, https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1-186x105.png 186w, https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1-248x139.png 248w, https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1-254x143.png 254w, https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1-262x147.png 262w, https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1-288x162.png 288w, https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1-380x214.png 380w, https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1-308x173.png 308w, https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1-326x183.png 326w, https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1-394x221.png 394w, https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1-402x226.png 402w, https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1-555x312.png 555w, https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1-563x317.png 563w, https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1-567x319.png 567w, https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1-664x373.png 664w, https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1-676x380.png 676w, https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1-811x456.png 811w, https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1-835x470.png 835w, https://innovationorigins.com/app/uploads/2022/11/1108_GMH_SRON_GHGSat_Fig12-1-975x548.png 975w" sizes="(max-width: 150px) 100vw, 150px"></p></div><div><p>First map of global methane-emitting landfills to be presented at GOP27</p><p>Global Methane Hub, SRON, and GHGSat are mapping the world’s largest methane-emitting landfills. The map contains over a hundred of them. </p></div></div>
<h2><strong>Tiered approach</strong></h2>
<p>“The secret is the tiered approach,” SRON-researcher Sudhanshu Pandey (now at JPL) says. “We now have a supergroup of three Copernicus satellites to spot super-emitters of methane very quickly and precisely identify the responsible facilities. Especially super-emitters in desert areas or extremely large emissions can be seen very well with these instruments, zooming in with increasingly high resolution. A fine example of very large but transient emissions that we could examine using the complementary observations happened along a Russian gas pipeline. In our <a href="https://www.sciencedirect.com/science/article/pii/S0034425723002675">paper</a>, we show that Sentinel-3, combined with Sentinel 5P and Sentinel -2, is a great asset for methane mitigation.”</p>
<h2>Example: Russian plume</h2>
<p>The tiered use of the three satellites started with a Sentinel-5P observation on 18th&nbsp;June 2021, which showed an apparent methane plume in Russia. Zooming in with Sentinel-3 shows that there are two methane plumes coming from the locations indicated with the white crosses. Further zooming in with Sentinel-2 shows the leaks originate from two facilities along the gas transmission pipeline.</p>
<figure><img decoding="async" width="605" height="362" src="https://innovationorigins.com/app/uploads/2023/08/Picture_3_satellites.png" alt="" srcset="https://innovationorigins.com/app/uploads/2023/08/Picture_3_satellites.png 605w, https://innovationorigins.com/app/uploads/2023/08/Picture_3_satellites-354x212.png 354w, https://innovationorigins.com/app/uploads/2023/08/Picture_3_satellites-186x111.png 186w, https://innovationorigins.com/app/uploads/2023/08/Picture_3_satellites-232x139.png 232w, https://innovationorigins.com/app/uploads/2023/08/Picture_3_satellites-254x152.png 254w, https://innovationorigins.com/app/uploads/2023/08/Picture_3_satellites-262x157.png 262w, https://innovationorigins.com/app/uploads/2023/08/Picture_3_satellites-288x172.png 288w, https://innovationorigins.com/app/uploads/2023/08/Picture_3_satellites-380x227.png 380w, https://innovationorigins.com/app/uploads/2023/08/Picture_3_satellites-289x173.png 289w, https://innovationorigins.com/app/uploads/2023/08/Picture_3_satellites-326x195.png 326w, https://innovationorigins.com/app/uploads/2023/08/Picture_3_satellites-369x221.png 369w, https://innovationorigins.com/app/uploads/2023/08/Picture_3_satellites-402x241.png 402w, https://innovationorigins.com/app/uploads/2023/08/Picture_3_satellites-555x332.png 555w, https://innovationorigins.com/app/uploads/2023/08/Picture_3_satellites-530x317.png 530w, https://innovationorigins.com/app/uploads/2023/08/Picture_3_satellites-567x339.png 567w" sizes="(max-width: 605px) 100vw, 605px"><figcaption>Russian plume © SRON</figcaption></figure>

 </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Speed Up C++ Compilation (108 pts)]]></title>
            <link>https://devtalk.blender.org/t/speed-up-c-compilation/30508</link>
            <guid>37014842</guid>
            <pubDate>Sat, 05 Aug 2023 18:12:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devtalk.blender.org/t/speed-up-c-compilation/30508">https://devtalk.blender.org/t/speed-up-c-compilation/30508</a>, See on <a href="https://news.ycombinator.com/item?id=37014842">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
          <p>Shorter build times improve developer productivity. Therefore, it is benefitial to reduce them if possible. This document explains why compilation can be slow and discusses different approaches to speed it up.</p>
<p>This is mostly meant to be a resource for other developers that are investigating compile time issues. However, it would be nice to hear other peoples thoughts for how we can or should improve build times as well.</p>
<h2>
<a name="build-process-1" href="#build-process-1"></a>Build Process</h2>
<p>When analysing compile times, three parts of the build process are particularly interesting. Those are briefly described below.</p>
<h3>
<a name="source-code-parsing-2" href="#source-code-parsing-2"></a>Source Code Parsing</h3>
<p>This is commonly referred to as the compiler front-end. First, it run the preprocessor per translation unit. This inlines all included header files, usually resulting in a fairly large file (often &gt;100,000 lines).</p>
<p>The preprocessor itself is very fast, however parsing that many lines of code is slow. Parsing C++ code is slower than parsing C code because C++ is a more complex language. At the end of parsing, the compiler has an internal representation (e.g. an AST) of the current translation unit and all included headers.</p>
<h3>
<a name="code-generation-3" href="#code-generation-3"></a>Code Generation</h3>
<p>Now the compiler checks which functions have to be generated, because they may be called by other translation units. Then it generates machine code for those functions, which also involves processing all the other functions in the same translation unit that are called indirectly. This is often referred to as the compiler back-end.</p>
<p>The compile time here mainly depends on how much machine code is generated (and not on the size of the preprocessed file). In C++ this often results in many (templated) inline functions to be generated. In C code, many of those functions would not be <code>inline</code> which makes C code generation generally faster given the same amount of code. In C++ they often have to be <code>inline</code> because of the templating mechanism.</p>
<h3>
<a name="linking-4" href="#linking-4"></a>Linking</h3>
<p>The linker reads the symbol table of every translation unit, i.e. the list of functions and variables that a translation unit uses and provides. Then it copies every used function into the final executable ones and updates function pointers.</p>
<p>The linking time mainly depends on how fast the linker can read and deduplicate all the symbol tables and how fast it can copy and link all the functions in the final executable.</p>
<p>The more translation units and the larger their corresponding machine code size and symbol table is, the slower the linking process.</p>
<h2>
<a name="redundant-work-5" href="#redundant-work-5"></a>Redundant Work</h2>
<p>The main reason for why building big C++ projects is slow is that the compiler and linker do a huge amount of redundant work. The same headers are parsed over and over again, and the same (templated) inlined functions are generated many times. This leads to a lot of duplicate functions in the generated object files and the linker’s job is to reduce the redundancy again. The redundant work is often much more than the work that is unique per translation unit.</p>
<h2>
<a name="build-time-reduction-approaches-6" href="#build-time-reduction-approaches-6"></a>Build Time Reduction Approaches</h2>
<p>There are different techniques to reduce build times. Generally they work by either reducing redundant work, reducing unique work or by doing the same work faster. Reducing unique work usually often involves a run-time performance trade-off.</p>
<h3>
<a name="faster-linker-7" href="#faster-linker-7"></a>Faster Linker</h3>
<p>Linking is the last step of the build process and has to be done even of only a single source file changed. Usually it has to relink everything from scratch after every change, unless something like incremental linking is used (which I don’t have experience with in Blender).</p>
<p>Many linkers are mostly single threaded and are therefore a huge serial bottleneck at the end of the build process.</p>
<p>If you can, use the <a href="https://github.com/rui314/mold">mold</a> linker.  I’ve use it for a long time now and it’s significantly faster then everything else I’ve tried. People have reported issues with it doing wrong things, but I’ve never experienced those. Unfortunately, it’s not available on windows yet. The new linker in Xcode 15 on macos seems to be significantly faster than in previous versions as well.</p>
<h3>
<a name="ccache-8" href="#ccache-8"></a>Ccache</h3>
<p>Build systems usually decide to rebuild files based on their last modification time on the file system. This becomes a problem when one often updates the last modification time without actually changing the source code. <a href="https://ccache.dev/">Ccache</a> wraps another compiler like gcc and adds a caching layer on top of it. It first checks if the source code to be compiled actually changed. If it did, the underlying compiler is invoked. Otherwise, it just outputs the result of a previous compiler invocation.</p>
<p>This caching layer helps in a few situations. Obviously, it avoids recompilation when just saving over an existing file without any changes. It also helps when just changing comments, because Ccache can check if the preprocessor output has changed and the preprocessor removes comments. Most importantly, it helps when switching back and forth between branches. Recompilation after switching to a branch that has been compiled before uses the cache and is thus much faster.</p>
<p>Note that ccache only caches the output of the code generation step, but not the linker result. Therefore, the linker still has to run again even if source files haven’t changed.</p>
<p>When benchmarking compilation time, Ccache can get in the way because it makes the results unreliable. Ccache can be temporarily disabled by setting the <code>CCACHE_DISABLE</code> environment variable to 1 (<code>export CCACHE_DISABLE=1</code>).</p>
<h3>
<a name="multiple-git-checkouts-9" href="#multiple-git-checkouts-9"></a>Multiple Git Checkouts</h3>
<p>Having multiple git checkouts can reduce compilation times by avoiding often branch switching which leads to many code changes. One could simply copy the source code folder or use git worktrees. Each checkout should have their own build folder.</p>
<p>Personally, I have a separate checkout that I don’t use for compilation but only to look at other branches while working on something or to checkout very old commits, e.g. when figuring out when a particular function has been added.</p>
<p>When working with multiple checkouts, it’s easy to get yourself confused with which checkout you are currently working on. I solved this locally, by using vscode’s ability to configure a different theme per folder. Essentially, when I’m not in my main checkout, vscode looks different. I never accidentally changed the wrong checkout since I set this up.</p>
<h3>
<a name="multiple-build-folders-10" href="#multiple-build-folders-10"></a>Multiple Build Folders</h3>
<p>Having multiple build folders for different configurations reduces the compilation overhead when switching between them. For example, one should have separate build folders for release and debug builds. Partially this is setup automatically when using our <code>make</code> utilities. Visual Studio also creates separate build folders automatically afaik.</p>
<p>It can be benefitial to have even more independent build folders though. Like mentioned before, it can help to have separate build folders for each git checkout. Personally, I currently have build folders for the following configurations: <code>release</code>, <code>debug</code>, <code>reldebug</code>, <code>asan</code>, <code>compile commands</code> (only used for better autocompletion in vscode), <code>clang release</code>, (used to check for other warnings and performance differences), <code>clang release optimized</code> (enables extra compiler optimizations to see if they have an impact), <code>release reference</code> (used when comparing performance of two branches).</p>
<h3>
<a name="forward-declarations-of-types-11" href="#forward-declarations-of-types-11"></a>Forward Declarations of Types</h3>
<p>Forward declarations allow using types from one header without actually including the header. For example, putting <code>struct bNodeTree;</code> in a header makes the <code>bNodeTree</code> type available without having to include <code>DNA_node_types.h</code>. The hope is that at least some translation units that use the forward declaration don’t include <code>DNA_node_types.h</code> anyway. This leads to less code being in the preprocessed translation units which reduces the parsing overhead.</p>
<p>Forward declaring types that end up being included in most translation units does not really provide any benefits for the compile times. E.g. forward declaring common containers like <code>Vector</code> rarely makes sense.</p>
<p>Headers that only work with a forward declared type are restricted with what they can do with the type. They can’t access any of its members. That includes indirect accesses by e.g. taking or returning the type by value. Generally, only pointers and references of the type can be used. Smart pointers are supported as well as long as they don’t have to access methods of the type (like the destructor). If only a single function in a header needs access to the members, the include ends up being necessary anyway.</p>
<p>Forward declaring some types is harder than others. C structs are generally easy to forward declare. Nested C++ structs are impossible to forward declare. Namespaces and templates also make forward declarations harder. For example, one can’t really forward declare <code>std::string</code> reliably outside of the standard library. That’s because it’s actually a typedef of another type. Some standard types have forward declarations in <code>#include &lt;iosfwd&gt;</code>, but not all. The existence of that header also indicates that it is non trivial to forward declare these types. Also see <a href="https://blog.magnum.graphics/backstage/forward-declaring-stl-container-types/">this</a>.</p>
<p>In some headers, we currently access data members of structs even though they are forward declared. That works because the data members are used in preprocessor macros. For example <code>IDP_Int</code>. This is a problem when we want to replace macros with inline functions, which will require the include.</p>
<p>Seeing benefits from forward declarations is often difficult in C++ code, because often code changes only have a negilible effect on compile times, making it hard to measure the overall effectiveness. This is also because the translation units often end up being so large that a single header of our own does not make a big difference. Another problem is that it is very hard to consistently use forward declarations especially in C++, because many things defined in headers need the full type. It’s difficult to use forward declarations everywhere, but very easy to introduce an include later on when it becomes necessary, rendering the previous work useless.</p>
<h3>
<a name="smaller-headers-12" href="#smaller-headers-12"></a>Smaller Headers</h3>
<p>The idea is to split up large headers into multiple smaller headers. The hope is that some translation units that previously included the large header, will now only include a subset of the smaller headers. This can reduce parsing time.</p>
<p>This can be especially benefitial when part of a header requires another header that is very large. For example, <code>BKE_volume_openvdb.hh</code> includes <code>openvdb</code> which is not used by all code that deals with volume data blocks.</p>
<p>Smaller headers can also help with making code easier to understand. Many large headers have sections already anyway. Splitting sections into separate headers might be a nice cleanup. This only improves compile times if the individual headers are not grouped into one bigger header again, like in <code>ED_asset.h</code>.</p>
<h3>
<a name="type-erasure-13" href="#type-erasure-13"></a>Type Erasure</h3>
<p>Templates generally have to be defined in headers so that each translation unit can instantiate the required versions of them. Removing template parameters from a function allows it to be defined outside of a header, reducing parsing and code generation overhead.</p>
<p>Obviously, many functions are templates for good reasons, but in some cases type erasure can be used without sacrificing performance. For example, a function that currently takes a callable as a template could also take a <code>FunctionRef</code> instead. Functions taking a <code>Span&lt;T&gt;</code> could take a <code>GSpan</code>.</p>
<p>Sometimes the combination of a normal and type erased code path can make sense too. E.g. <code>parallel_for</code> has an inlined fast path, but a type erased more complex path that is not in the header. Under some circumstances, type erasure can also reduce final binary size <a href="https://projects.blender.org/blender/blender/commit/f6d824bca635a25a69240e49b31cba03c58db59d">significantly</a>.</p>
<h3>
<a name="explicit-instantiation-14" href="#explicit-instantiation-14"></a>Explicit Instantiation</h3>
<p>Sometimes, it’s not possible or desired to remove template parameters from a function. However, if the function does not really benefit from inlining because it is too large, there is no point in compiling it in every translation unit that uses it. Compiling it only once reduces code generation time.</p>
<p>Explicit instantiation can be used to make sure that a templated function is only instantiated once for a specific type. See e.g. the <code>normalized_to_eul2</code> function.</p>
<p>This approach can also be used to move the definition of a template out of a header in which case this would also reduce parsing overhead. Then the templated function can <em>only</em> be used with the types that have been instantiated explicitly.</p>
<p>While explicit instantiation can definitly help, it’s not entirely trivial to find good candidates that have a measurable impact. Maybe some better tooling could help here.</p>
<h3>
<a name="reuse-common-functions-15" href="#reuse-common-functions-15"></a>Reuse Common Functions</h3>
<p>When a header already includes the functionality that one would implement in a source file, it’s better to just use the shared functionality. This may seem obvious, but it’s mentioned here because it’s not necessarily simple and requires familiarizing yourself with the available utilities. For example, many geometry algorithms have a <a href="https://projects.blender.org/blender/blender/pulls/107823">gather</a> step.</p>
<p>Having more common function that are not recompiled for every use reduces the code generation redundancy. Having too many such utilities that are only rarely used can also increase the parsing overhead though.</p>
<h3>
<a name="use-less-forced-inlining-16" href="#use-less-forced-inlining-16"></a>Use Less Forced Inlining</h3>
<p>The compiler is fairly good at deciding which functions should be inlined. It uses various heuristics to achieve a good balance of run-time performance and binary size. Generally speaking, the compiler considers all functions that are defined in a translation unit for inlining. Using the <code>inline</code> keyword is mostly just information for the linker to tell it that there may be multiple definitions of a function in different translation units and that they should be deduplicated. That said, depending on the compiler, the <code>inline</code> keyword may change the heuristics to make inlining more likely.</p>
<p>Compilers also support forced inlining e.g. using <code>__forceinline</code>. Now the compiler generally just skips the heuristics and inlines everything anyway. That’s generally the desired behavior, but can have bad consequences when used too liberally. It can result in huge functions that are slow to compile. Compiling functions often has slower-than-linear time complexity. Also see <a href="https://aras-p.info/blog/2017/10/09/Forced-Inlining-Might-Be-Slow/">this</a>.</p>
<p>Better just use normal <code>inline</code> functions and only use force inlining when you notice that the compiler is not inlining something that would lead to better performance when inlined.</p>
<h3>
<a name="precompiled-headers-17" href="#precompiled-headers-17"></a>Precompiled Headers</h3>
<p>Most of the time spend parsing code comes from parsing the most commonly used header files. Precompiled headers allow the compiler to do some preprocessing on a set of header files so that they don’t have to parsed for every translation unit. Using precompiled headers can mostly be automated with cmake.</p>
<p>While precompiled headers can reduce a lot of redundant parsing time, they don’t reduce the redundancy in the code generation step.</p>
<p>When using precompiled headers, one can accidentally create source files that can’t be compiled on their own anymore. That’s because when a precompiled header is used in a module, all translation units include it. Fixing related issues usually just means adding more include statements. These issues are easy to find automatically by simply disabling precompiled headers temporarily.</p>
<p>When there are only a few translation units that use a precompiled header, using them can also hurt performance. That’s because precompiling the header is single threaded and compilation of the translation units only starts when the header compilation finished. This effect is most noticable when using unity builds with a relatively large unit size.</p>
<h3>
<a name="unity-builds-18" href="#unity-builds-18"></a>Unity Builds</h3>
<p>The redundancy during the parsing and code generation step is bad because it takes a long time <em>relative to</em> the non-redundant work that is unique to every translation unit. Unity builds concatenate multiple source files to a single translation unit. Now, all the headers have to be parsed once and code for inline functions has to be generated once per e.g. 10 source files. So the time spend doing redundant work relative to unique work is greatly reduced, by a factor of 10 in this case.</p>
<p>Unity builds can be used together with precompiled headers. This can help in modules with a very larger number of source files to get rid of the remaining redundancy when parsing headers. Overall, precompiled headers become less effective with unity builds though, because parsing overhead is reduced so much already.</p>
<p>Similar to precompiled headers, using unity builds can result in accidentally having files that can’t be compiled on their own anymore. This is also typically fixed by adding missing includes.</p>
<p>Unity builds generally require some work to work and to be safe. The fundamental problem is that symbols that were local to a single source file before, are now also available in other source files in the same unit. This can lead to name collisions which break compilation. So one has to be careful with making all source files compatible with each other. Whether one prepared files successfully can be tested by putting all source files into a single unit.</p>
<p>Just hoping that there are no name collisions is generally not enough, at least it doesn’t give piece of mind when any local variable can suddenly clash with local variables in another file. A solution that gives more piece of mind is to put each source file into its own namespace. Only symbols that are explicitly exposed are not defined in that namespace. We already use this approach in most node implementations. E.g. see the <code>node_geo_mesh_to_curve_cc</code> namespace.</p>
<p>This approach of file specific namespace works particularly well for nodes, because generally there is only a single function that is exposed (e.g. <code>register_node_type_geo_mesh_to_curve</code>). Most other source files expose multiple functions, and often the exposed functions are interleaved with local functions. In such cases, it is less convinient because the file specific namespace has to be opened and closed many times as you can see in <a href="https://projects.blender.org/blender/blender/pulls/110598">this</a> test.</p>
<p>Potential solutions that make this approach more convenient could be to automate inserting the namespace scopes. Alternatively, one could organize source files so that local functions are all grouped together so that only a single namespace scope is necessary. Yet another approach could be to split up source files. For example, similar to how we have one node per file, we could also have one operator per file. Without unity builds or precompiled headers, having many small source files leads to a lot of parsing overhead, but with those, it’s less of an issue.</p>
<p>When using unity builds, one has to decide how many files should be concatenated per unit. This is a trade-off. Small units can allow more threads to compile the units at the same time at the cost of more parsing and code generation redundancy. Large units reduce the redundant work but less threads can be used overall. Large units are benefitial when the system has only a few cores or when the total number of files to be compiled is very large so that all cores will be busy anyway. Actually creating the units can be automated with cmake.</p>
<p>Often, one only works in a single source file. When changing only that one file, using unity builds lead to longer recompilation time, because all other files in the same unity are recompiled as well. Often that is not an issue, but it can be when one of the other files happens to take very long, e.g. because it uses <code>openvdb</code>. This can be solved in using <code>SKIP_UNITY_BUILD_INCLUSION</code> in cmake. It allows either excluding the files that are known to be slow to compile from units, or it can be added temporarily for the file that is currently being edited.</p>
<p>Using <code>SKIP_UNITY_BUILD_INCLUSION</code> it should also be possible to start introducing unity builds in a module gradually file by file. It also makes it possible to benefit from unity builds in modules that have some files that are very hard to prepare for unity builds.</p>
<p>Sometimes it’s harder for IDEs to provide good autocompletion when unity builds are used. For IDEs that use the compile commands generated by cmake (<code>CMAKE_EXPORT_COMPILE_COMMANDS</code>), it can be benefitial to have a separate build folder just to generate the compile commands. That build folder can have unity builds and precompiled headers disabled.</p>
<p>Using unity builds can also make the job of the linker easier. That’s because the linker has to parse fewer symbol tables. Within each units, are symbols are already made unique as part of the compilation process. This also reduces the total size of generated machine code, which reduces the size of the build folder.</p>
<h3>
<a name="distributed-builds-19" href="#distributed-builds-19"></a>Distributed Builds</h3>
<p>When one has more compute resources available outside of the work PC, one can consider to use distributed builds. Those don’t reduce redundancy (they might actually increase it), but can still improve compile times by making use of more parallelism. I don’t have much experience with this myself, but tools like <a href="https://www.distcc.org/">distcc</a> shouldn’t be too hard to get working with Blender.</p>
<p>Distributed builds generally only help when building lots of files in parallel, so they are less effective when working on individual source files and only few files need to be recompiled after every change.</p>
<h3>
<a name="c20-modules-20" href="#c20-modules-20"></a>C++20 Modules</h3>
<p>The compilation speedup that can be expected from C++20 modules is probably similar to that we could get from precompiled headers. So the parse overhead can be reduced, but the code generation redundancy likely remains.</p>
<p>Modules have the benefit over precompiled headers that source files stay independent and are not all forced to include the same precompiled header. Thus, the problem of ending up with source files that can’t be compiled on their own, does not not exist.</p>
<p>The downside is of course that we are not using C++20 yet. Even if we would use it, it’s unlikely that our build chains fully support them yet. And even if they would, we’d likely still have to make fairly significant changes to our code base to make use of them.</p>
<p>That said, switching to C++20 can also make <a href="https://mastodon.gamedev.place/@zeux/110789455714734255">compilation slower overall</a>. It’s unclear whether using modules can offset that slowdown or whether that slowdown goes away if C++20 implementations become more mature.</p>
<h2>
<a name="tools-21" href="#tools-21"></a>Tools</h2>
<p>Just like for profiling the run-time performance of a program, there are also tools that measure the build time. Those can be used to make educated guesses for which changes might impact build times the most. The tools help most to identify headers that one should avoid to include or functions whose code generation takes a significant portion of the overall build.</p>
<ul>
<li><a href="https://github.com/aras-p/ClangBuildAnalyzer">ClangBuildAnalyzer</a></li>
<li>
<a href="https://devblogs.microsoft.com/visualstudio/visual-studio-2022-17-7-preview-2-is-here/#build-insights-in-visual-studio-c">Build Insights in Visual Studio</a>, <a href="https://learn.microsoft.com/en-us/cpp/build-insights/reference/sdk/overview?view=msvc-170&amp;viewFallbackFrom=vs-2019">SDK</a>, <a href="https://github.com/microsoft/cpp-build-insights-samples">SDK Examples</a>
</li>
<li><a href="https://include-what-you-use.org/">include-what-you-use</a></li>
</ul>
<p>Feel free to suggest more tools that I should add here.</p>
<h2>
<a name="summary-22" href="#summary-22"></a>Summary</h2>
<p>Always use the fastest linker that works for you. This is likely the most significant change you can do to improve your daily work in Blender. Forward declarations can be useful sometimes, but require significant discipline to get meaningful compile time improvements. It’s much harder in C++ than it is in C. Splitting up headers can be good for improved code quality, but likely don’t have a significant enough compile time to justify spending too much time on them.</p>
<p>Precompiled headers make sense in modules with many similar files. Their effectiveness is greatly reduced when unity builds are used as well. Overall, unity builds are the most effective tool to reduce redundant work and therefore improve compile times. Some code changes are necessary but their effectiveness is easily measurable.</p>
<p>Distributed builds are a nice thing to try for people who have the resources. C++20 modules could help like precompiled headers but are out of reach for the foreseeable future.</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Duck DNS (108 pts)]]></title>
            <link>https://www.duckdns.org/</link>
            <guid>37014758</guid>
            <pubDate>Sat, 05 Aug 2023 18:03:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.duckdns.org/">https://www.duckdns.org/</a>, See on <a href="https://news.ycombinator.com/item?id=37014758">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				
				
					
					
					
						<!-- NEWS:START -->
						<h2>free dynamic DNS hosted on AWS</h2>
						<p>
							<strong>news:</strong> <a target="new" href="https://www.duckdns.org/reddit.jsp">login with Reddit is no more</a> - legal request<br>
							<strong>support&nbsp;us:</strong> become a <a target="new" href="https://www.patreon.com/user?u=3209735&amp;ty=h&amp;u=3209735">Patreon</a><br>
						</p>
						<!-- NEWS:END -->
					
				
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Vim's Creator Bram Moolenaar Dies at Age 62 – Slashdot (264 pts)]]></title>
            <link>https://news.slashdot.org/story/23/08/05/1632219/vims-creator-bram-moolenaar-dies-at-age-62</link>
            <guid>37013887</guid>
            <pubDate>Sat, 05 Aug 2023 16:47:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.slashdot.org/story/23/08/05/1632219/vims-creator-bram-moolenaar-dies-at-age-62">https://news.slashdot.org/story/23/08/05/1632219/vims-creator-bram-moolenaar-dies-at-age-62</a>, See on <a href="https://news.ycombinator.com/item?id=37013887">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="fhbody-171547774"><p>
			
		 	
				Bram Moolenaar was Vim's creator/maintainer/benevolent-dictator for life.  Early this morning his family shared sad news on the Vim-announce Google Group.   "It is with a heavy heart that we have to inform you that Bram Moolenaar passed away on 3 August 2023."  Moolenaar was 62 years old, and died from "a medical condition that progressed quickly over the last few weeks."</p><p> 
"Bram dedicated a large part of his life to VIM and he was very proud of the VIM community that you are all part of."</p><p> 

Anyone who's used Vim has seen evidence of Moolenaar's generosity.  "Vim is Charityware," Moolenaar wrotes in its pioneering license.  "You can use and copy it as much as you like, but you are encouraged to make a <a href="https://iccf-holland.org/donate.html">donation for needy children in Uganda</a>."  Moolenaar pioneered the concept of charityware <a href="https://web.archive.org/web/20120721132048/http://www.linuxjournal.com/article/4657?page=0,3">decades ago</a>, and also helped to popularize its adoption.  To this day Vim users can still view the license by typing the command <em>:help Uganda</em> or <em>:help ICCF</em>.  And Vim's <a href="https://www.vim.org/sponsor/faq.php">sponsor FAQ</a> notes that "Each registered Vim user and sponsor who donates at least 10 euro will be able to vote for new features." </p><p> 

Moolenaar's <a href="https://moolenaar.net/albums.html">personal web site</a> also includes photos from his travels around the world, and YouTube has <a href="https://www.youtube.com/watch?v=p6K4iIMlouI">some videos</a> of talks and interviews <a href="https://www.youtube.com/watch?v=_O-QdG2X1Lw">with Moolenaar</a>.</p><p> 

He was still <a href="https://github.com/vim/vim/commits?author=brammool">committing changes to Vim up until a month ago</a>.</p><p> 

<em>In the comments below long-time Slashdot reader <a href="https://news.slashdot.org/~bads">bads</a> shares a link to <a href="https://groups.google.com/g/vim_dev/c/6_yWxGhB_8I/m/ibserACYBAAJ">a post from long-time Vim contributor Christian Brabandt</a> </em>:

<i>Bram was a great leader to the Vim community and I really enjoyed working with him over the past years, since I became involved with the development of Vim almost 20 years ago.<p> 

Bram was of great inspiration in creating a great community, helping people with his charity and he was a great mentor. And now he left too soon. We lost a great leader and I regret never having met him in person.</p><p> 


However to all of the community: I will continue and I hope all of the other contributors will
also keep up the good work. I do have access to the Vim homepage and the Vim organization (not sure if all the rights, but I am sure we will work on the details in the near future...)  I hope
together we will be able to continue
successfully.

</p></i></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New acoustic attack steals data from keystrokes with 95% accuracy (195 pts)]]></title>
            <link>https://www.bleepingcomputer.com/news/security/new-acoustic-attack-steals-data-from-keystrokes-with-95-percent-accuracy/</link>
            <guid>37013704</guid>
            <pubDate>Sat, 05 Aug 2023 16:33:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bleepingcomputer.com/news/security/new-acoustic-attack-steals-data-from-keystrokes-with-95-percent-accuracy/">https://www.bleepingcomputer.com/news/security/new-acoustic-attack-steals-data-from-keystrokes-with-95-percent-accuracy/</a>, See on <a href="https://news.ycombinator.com/item?id=37013704">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><img alt="Keyboard" height="900" src="https://www.bleepstatic.com/content/hl-images/2023/08/04/mechanical-keyboard-glowing.jpg" width="1600"></p>
<p>A team of researchers from British universities has trained a deep learning model that can steal data from keyboard keystrokes recorded using a microphone with an accuracy of 95%.</p>
<p>When Zoom was used for training the sound classification algorithm, the prediction accuracy dropped to 93%, which is still dangerously high, and a record for that medium.</p>
<p>Such an attack severely affects the target's data security, as it could leak people's passwords, discussions, messages, or other sensitive information to malicious third parties.</p>
<p>Moreover, contrary to other side-channel attacks that require special conditions and are subject to data rate and distance limitations, acoustic attacks have become much simpler due to the abundance of microphone-bearing devices that can achieve high-quality audio captures.</p>
<p>This, combined with the rapid advancements in machine learning, makes sound-based side-channel attacks feasible and a lot more dangerous than previously anticipated.</p>
<h2>Listening to keystrokes</h2>
<p>The first step of the attack is to record keystrokes on the target's keyboard, as that data is required for training the prediction algorithm. This can be achieved via a nearby microphone or the target's phone that might have been infected by malware that has access to its microphone.</p>
<p>Alternatively, keystrokes can be recorded through a Zoom call where a rogue meeting participant makes correlations between messages typed by the target and their sound recording.</p>
<p>The researchers gathered training data by pressing 36 keys on a modern MacBook Pro 25 times each and recording the sound produced by each press.</p>
<div>
<figure><img alt="Sampling the keystroke audio" height="600" src="https://www.bleepstatic.com/images/news/u/1220909/2023/Papers/9/keystrokes-recording.jpg" width="776"><figcaption><strong>Sampling the keystroke audio</strong> <em>(arxiv.org)</em></figcaption></figure></div>
<p>Then, they produced waveforms and spectrograms from the recordings that visualize identifiable differences for each key and performed specific data processing steps to augment the signals that can be used for identifying keystrokes.</p>
<div>
<figure><img alt="Produced spectrograms" height="369" src="https://www.bleepstatic.com/images/news/u/1220909/2023/Papers/9/spectrogram.jpg" width="1099"><figcaption><strong>Produced spectrograms</strong> <em>(arxiv.org)</em></figcaption></figure></div>
<p>The spectrogram images were used to train 'CoAtNet,' which is an image classifier, while the process required some experimentation with epoch, learning rate, and data splitting parameters until the best prediction accuracy results could be achieved.</p>
<div>
<figure><img alt="Parameters selected for training CoAtNet" height="600" width="561" data-src="https://www.bleepstatic.com/images/news/u/1220909/2023/Papers/9/parameters.jpg" src="https://www.bleepstatic.com/images/news/u/1220909/2023/Papers/9/parameters.jpg"><figcaption><strong>Parameters selected for training CoAtNet</strong> <em>(arxiv.org)</em></figcaption></figure></div>
<p>In their experiments, the researchers used the same laptop, whose keyboard has been used in all Apple laptops for the past two years, an iPhone 13 mini placed 17cm away from the target, and Zoom.</p>
<div>
<figure><img alt="The test setup" height="279" width="534" data-src="https://www.bleepstatic.com/images/news/u/1220909/2023/Papers/9/test-setup.jpg" src="https://www.bleepstatic.com/images/news/u/1220909/2023/Papers/9/test-setup.jpg"><figcaption><strong>The test setup</strong> <em>(arxiv.org)</em></figcaption></figure></div>
<p>The CoANet classifier achieved 95% accuracy from the smartphone recordings and 93% from those captured through Zoom. Skype produced a lower but still usable 91.7% accuracy.</p>
<div>
<figure><img alt="The confusion matrix for phone-recorded keystrokes" height="595" width="558" data-src="https://www.bleepstatic.com/images/news/u/1220909/2023/Papers/9/conf-matrix.jpg" src="https://www.bleepstatic.com/images/news/u/1220909/2023/Papers/9/conf-matrix.jpg"><figcaption><strong>Confusion matrix for phone-recorded keystrokes</strong> <em>(arxiv.org)</em></figcaption></figure></div>
<h2>Possible mitigations</h2>
<p>For users who are overly worried about acoustic side-channel attacks, <a href="https://arxiv.org/pdf/2308.01074.pdf" target="_blank" rel="nofollow noopener">the paper</a> suggests that they may try altering typing styles or using randomized passwords.</p>
<p>Other potential defense measures include using software to reproduce keystroke sounds, white noise, or software-based keystroke audio filters.</p>
<p>Remember, the attack model proved highly effective even against a very silent keyboard, so adding sound dampeners on mechanical keyboards or switching to membrane-based keyboards is unlikely to help.</p>
<p>Ultimately, employing biometric authentication where feasible, and utilizing password managers to circumvent the need to input sensitive information manually, also serve as mitigating factors.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Just Normal Web Things (382 pts)]]></title>
            <link>https://heather-buchel.com/blog/2023/07/just-normal-web-things/</link>
            <guid>37013396</guid>
            <pubDate>Sat, 05 Aug 2023 16:07:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://heather-buchel.com/blog/2023/07/just-normal-web-things/">https://heather-buchel.com/blog/2023/07/just-normal-web-things/</a>, See on <a href="https://news.ycombinator.com/item?id=37013396">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p>We've let ourselves get away from building websites that can do normal web things. I've noticed this a lot recently due to a surge in new social media platforms springing up. Everyone is building new clients, apps, and in some cases, like React Native, attempting to share code across platforms. It's definitely exciting, and I'm actually thrilled that people are building these things.</p>
<blockquote> In the end, it's usually because we've JavaScript'ed our way out of these things.</blockquote>
<p>What is less thrilling is that, nevermind the basic accessibility requirements that are often missing like alt text on images, we stopped letting people do very normal web things. There are a number of avenues to route the blame to: rushing to release something midly usable for testing protocols in the wild, not having a UI engineer on the project, building things in a mobile "touch first" experience and ignoring other inputs or devices; the list goes on. In the end, it's usually because we've JavaScript'ed our way out of these things.</p>
<p>Here are some things I wish people allowed to continue to work in their web projects:</p>
<ul>
<li><strong>Let me copy text so I can paste it.</strong> Please. This is often cause by removing pointer-events or layering elements on eachother that are meant to be clickable. This happens a lot with clickable "card" components.</li>
<li><strong>If something navigates like a link, let me do link things.</strong> Let me right click on the link without it navigating so I can open the context menu that lets me do other link things (like copying link text, copying link address, etc.) Let me use usual link keyboard shortcuts (like <code>ctrl + click</code> on Windows) to open in a new tab. Just normal link things. This is that dreaded thing that us front-end folks are always harping on about: using a div with an on-click to navigate instead of an anchor element.</li>
<li><strong>Let me zoom in on my browser without the website getting all out of whack</strong>. I just want to be able to read.</li>
<li><strong>Do responsive things</strong> I didn't spend most of my early career convincing clients to let us do a responsive website just for you to serve me up a boring layout that kicks down to your mobile layout as soon as you are less than 1200px. I actually think Mastodon and Twitter do a good job at this. The UI feels familiar if you drag your browser down to a small narrow viewport. The space mostly gets used.</li>
<li><strong>Let me have hover styles</strong> I've seen too many React Native ports to the web that have zero :hover or :focus styles beause "you can't hover or tab on mobile, right?" (wrong) or weird disabled looking :active styles. Do normal interaction state things for the web in your web app. This issue in particular almost always makes it glaringly obvious when some poor soul ported their RN app to the web to save time.</li>
<li><strong>If the UI completely changes when I click on something, as if I've navigated to a new page, give me a browser history update and a new url</strong> It's annoying not being able to link to a state in the UI that appears to be it's own page and that is lost to the void if I navigate away.</li>
<li><strong>Let me see scroll bars</strong> Please don't hide them for the sake of your "slick" ui. Sometimes I want to click on the scrollbar and drag it. Just a normal web thing.</li>
<li><strong>Stop hijacking my typical browser shortcuts for use in your own app</strong> I've seen this happen with <code>ctrl + f</code> for opening a custom in-app search bar. I don't want that. It doesn't always search the page as usual.</li>
</ul>
<p>I stopped myself from adding a lot of things that would usually fall under accessibility violations though there is definitely a lot of crossover in the list above. What did I miss? <a href="https://hachyderm.io/@hbuchel/110669996408706858">Let me know on Mastodon.</a></p>

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pirate site not impressed by Global DNS blocking order (145 pts)]]></title>
            <link>https://torrentfreak.com/pirate-site-not-impressed-by-global-dns-blocking-order-230803/</link>
            <guid>37013320</guid>
            <pubDate>Sat, 05 Aug 2023 16:01:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://torrentfreak.com/pirate-site-not-impressed-by-global-dns-blocking-order-230803/">https://torrentfreak.com/pirate-site-not-impressed-by-global-dns-blocking-order-230803/</a>, See on <a href="https://news.ycombinator.com/item?id=37013320">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>

<span property="itemListElement" typeof="ListItem"><a property="item" typeof="WebPage" title="Go to TorrentFreak." href="https://torrentfreak.com/"><span property="name">Home</span></a><meta property="position" content="1"></span> &gt; <span property="itemListElement" typeof="ListItem"><a property="item" typeof="WebPage" title="Go to the Anti-Piracy category archives." href="https://torrentfreak.com/category/anti-piracy/"><span property="name">Anti-Piracy</span></a><meta property="position" content="2"></span> &gt; <span property="itemListElement" typeof="ListItem"><a property="item" typeof="WebPage" title="Go to the Site Blocking category archives." href="https://torrentfreak.com/category/anti-piracy/site-blocking/"><span property="name">Site Blocking</span></a><meta property="position" content="3"></span> &gt; <span></span>
</p>
<p>
<span> </span>
Sony Music's legal efforts have produced a major breakthrough. As the result of a German blocking order, DNS provider Quad9 now blocks global access to music piracy site CannaPower. The operator of the site doesn't appear to be impressed so far, noting that it doesn't really hurt traffic. "They will never get us down," the operator says, adding that moving to the Tor network remains an option as well.
</p>
</div><div>
<p><img decoding="async" src="https://torrentfreak.com/images/cannapower.jpg" alt="cannapower" width="300" height="90" srcset="https://torrentfreak.com/images/cannapower.jpg 422w, https://torrentfreak.com/images/cannapower-300x90.jpg 300w" sizes="(max-width: 300px) 100vw, 300px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20300%2090'%3E%3C/svg%3E" data-lazy-srcset="https://torrentfreak.com/images/cannapower.jpg 422w, https://torrentfreak.com/images/cannapower-300x90.jpg 300w" data-lazy-src="https://torrentfreak.com/images/cannapower.jpg">Founded in the last millennium, CannaPower must be one of the oldest pirate sites still around today.</p>
<p>The site currently indexes more than 50,000 audio releases, which are shared through external hosting platforms. </p>
<h2>CannaPower Blocking Efforts</h2>
<p>With roughly a million monthly visits, mostly from Germany, the download portal is large enough to appear on the music industry’s radar. In fact, it’s become one of the prime enforcement targets and an anti-piracy guinea pig of sorts. </p>
<p>When German Internet providers teamed up with copyright holders and agreed to voluntarily <a href="https://torrentfreak.com/isps-and-rightsholders-unite-to-block-pirate-sites-in-germany-210311/">block blatant pirate sites</a>, CannaPower was one of the first targets. At the time, the site operated from the Canna.to domain. Today, Canna-Power.to is its main home, but that domain is blocked too.</p>
<p>The blockades made it more difficult for Germans to visit the site, but certainly not impossible. By switching to a DNS resolver not controlled by local Internet providers, many people can regain access to the site. </p>
<h2>Sony Targets DNS Resolver</h2>
<p>Rightsholders are well aware of this. In fact, this was likely one of the main reasons that the German branch of Sony Music filed a lawsuit against DNS resolver <a href="https://www.quad9.net/">Quad9</a> in 2021. The main goal of this court case was to block CannaPower at the third-party DNS resolver. </p>
<p>Sony Music’s lawsuit was <a href="https://torrentfreak.com/sony-wins-pirate-site-blocking-order-against-dns-resolver-quad9-210621/">successful</a>. While Quad9 is determined to have the blocking order overturned, it initially complied with the blocking order in Germany only. However, after a follow-up complaint from Sony <a href="https://torrentfreak.com/quad9-blocks-pirate-site-globally-after-sony-demanded-e10000-fine-230725/">and a €10,000 fine</a>, this blocking effort was rolled out globally.</p>
<p>The DNS blocking case in Germany will set an important precedent but, thus far, it hasn’t resulted in CannaPower throwing in the towel. Quad9 is a relatively small DNS resolver compared to Google, OpenDNS, and Cloudflare, so the effects are limited. </p>
<h2>‘They’ll Never Get Us Down’</h2>
<p>In an interview with the German site <a href="https://tarnkappe.info/artikel/interviews/cannapower-im-interview-diese-hurensoehne-werden-uns-nie-unterkriegen-278954.html">Tarnkappe</a>, the site says that Quad9’s global DNS blocking efforts have no meaningful effect on its traffic numbers. And if more blocking orders should follow, the site doesn’t plan to stop either. </p>
<p>“The number of visitors has remained constant,” CannaPower says. “They will never get us down! And when the time comes, yes, then we’ll just move to the Tor network.”</p>
<p>On the Tor network, rightsholders can’t easily restrict access to a domain name, since ISPs and regular DNS resolvers can’t see this traffic. </p>
<center><img decoding="async" src="https://torrentfreak.com/images/cannapowerfull.jpg" alt="canna power" width="600" height="394" srcset="https://torrentfreak.com/images/cannapowerfull.jpg 1710w, https://torrentfreak.com/images/cannapowerfull-300x197.jpg 300w, https://torrentfreak.com/images/cannapowerfull-1536x1009.jpg 1536w" sizes="(max-width: 600px) 100vw, 600px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20600%20394'%3E%3C/svg%3E" data-lazy-srcset="https://torrentfreak.com/images/cannapowerfull.jpg 1710w, https://torrentfreak.com/images/cannapowerfull-300x197.jpg 300w, https://torrentfreak.com/images/cannapowerfull-1536x1009.jpg 1536w" data-lazy-src="https://torrentfreak.com/images/cannapowerfull.jpg"></center>
<p>CannaPower actually didn’t notice Quad9’s new global blocking effort and found out about it through the news. For now, the site will remain operational from the canna-power.to domain but it plans to switch to a new one in the near future, although that’s reportedly not related to the blocking efforts. </p>
<p>In addition to making it harder for users to access the site, blockades can also lower the revenue of pirate sites by reducing their traffic. While that may happen to CannaPower in the future, money doesn’t appear to be a weak spot either.</p>
<p>“I’m already getting hardly any donations or advertising revenue. The project is basically a hobby of mine. I finance almost everything out of my own pocket. And that will not change in the future,” CannaPower’s operator concludes. </p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cargo Cult AI (170 pts)]]></title>
            <link>https://queue.acm.org/detail.cfm?id=3595860</link>
            <guid>37013114</guid>
            <pubDate>Sat, 05 Aug 2023 15:41:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://queue.acm.org/detail.cfm?id=3595860">https://queue.acm.org/detail.cfm?id=3595860</a>, See on <a href="https://news.ycombinator.com/item?id=37013114">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<div>

<p><a href="https://queue.acm.org/"><img src="https://queue.acm.org/img/acmqueue_logo.gif"></a>
</p></div>


<p><label>May 11, 2023<br><b><a href="https://queue.acm.org/issuedetail.cfm?issue=3590146">Volume 21, issue 2 </a></b></label></p><p>

&nbsp;
<a href="http://portal.acm.org/citation.cfm?id=3595860">
<img src="https://queue.acm.org/img/icon_pdf.png" alt="Download PDF version of this article">
PDF
</a>
</p>

<h2>Is the ability to think scientifically the defining essence of intelligence?</h2>
<h3>Edlyn V. Levine</h3>
<p>Physicist Carl Sagan once wrote that "science is more than a body of knowledge; it is a way of thinking." This type of thinking requires skeptical rigor and brutal honesty to thoroughly investigate, reason, and seek to invalidate hypotheses before jumping to conclusions. But it is all too easy to jump to conclusions. Despite our self-proclaimed intelligence, humans are apt to believe remarkable fallacies based on a paucity of correlated information rather than rigorously seek to determine causal foundations. </p>
<p>This propensity of humans to so easily believe wonderful, fanciful things is what another physicist, Richard Feynman, called cargo cult science. Feynman named this phenomenon after a "cargo cult" of people in the Pacific Islands who believed that building replicas of landing strips and control towers would ensure supply planes continued to land after World War II.<sup>6</sup> The planes never came. These people missed the fact that it was the advent of war, not the presence of landing strips that caused the planes to land there.</p>
<p>Today, some have speculated that LLMs (large language models) such as GPT-4 can be viewed as early versions of AGI (artificial general intelligence).<sup>3</sup> In contrast to AI (artificial intelligence), which is often task-specific, AGI is assumed to be able to perform any general task that a human might be capable of doing. There is something unsettling about the opinion that LLMs are emergent AGI. LLMs exhibit many behaviors and precepts indicative of intelligence, but are missing something essential: the stuffy rigor of scientific inquiry. Today's AI models are missing the ability to reason abstractly, including asking and answering questions of "Why?" and "How?" </p>
<p>Is the ability to think scientifically the defining essence of intelligence? The truth is that we don't know. There is as yet no comprehensive theory to explain what intelligence is or how it emerges from first principles. It would appear evident, however, that today's LLMs are not able to reproduce scientific thinking that has enabled humans to combine Bacon's empiricism and Descartes's rationalism to expand the frontier of falsifiable knowledge in the form of scientific theories. Methods of scientific inquiry have enabled humans to establish aspects of universality, nondeterminism, and causality that ultimately enable manipulation of the natural world to advance human welfare. </p>
<p>Evidence abounds that the human brain does not innately think scientifically; however, it can be taught to do so. The same species that forms cargo cults around widespread and unfounded beliefs in UFOs, ESP, and anything read on social media also produces scientific luminaries such as Sagan and Feynman. Today's cutting-edge LLMs are also not innately scientific. But unlike the human brain, there is good reason to believe they never will be unless new algorithmic paradigms are developed. </p>

<h3>A Dominant Algorithmic Paradigm</h3>
<p>Impressive progress in AI, including the recent sensation of ChatGPT, has been dominated by the success of a single, decades-old machine-learning approach called a multilayer (or deep) neural network. This approach was invented in the 1940s,<sup>17</sup> and essentially all of the foundational concepts of neural networks (nets)<sup>11,15</sup> and associated methods—including convolutional neural networks<sup>7</sup> and backpropagation<sup>19</sup>—were in place by the 1980s. However, it was not until the emergence of large digital datasets for training and sufficiently fast hardware in the form of GPUs (graphics processor units) that applications using neural nets have taken off.</p>
<p>The dominance of neural nets in today's AI is a tribute to their impressive emergent capabilities. A neural net is a mathematical function providing a representation of empirical information, and computes an output for a given input. The specific mathematical form of a neural net is that of a weighted, directed graph for which the vertices are called neurons and the edges are called connections. In the case of models such as GPT-3, which has 175 billion connections and thus 175 billion weights,<sup>2</sup> the function will have billions of terms. </p>
<p>The weights and biases of a neural net are determined through a process called deep learning that uses the backpropagation algorithm to progressively decrease the error between model prediction and training data.<sup>14</sup> The resultant trained neural net model effectively transforms the training data into abstract representations that suppress trivial information and magnify or distort features critical for classification. These abstracted representations were originally used to enable classification of a plethora of diverse data inputs but can also be used in a generative capacity. Today, AI models generate anything from chat prompts to images (e.g., produced by generative adversarial networks).&nbsp;The transformer models behind these generative tasks, of which the LLM GPT-3 is an example, still use the foundational architecture of neural networks with the addition of attention in order to learn context by tracking relationships in sequential data.<sup>24</sup> </p>
<p>Deep learning with neural nets has thus proven to be an extremely powerful and flexible computing framework. There are reasons to be concerned, however, that this approach will ultimately plateau if the goal is to achieve AGI capable of scientific reasoning. Neural nets may be fundamentally incapable of doing certain things such as establishing universality, nondeterminism, or causal inference. Even for what they are capable of doing, neural networks are incredibly resource-intensive. How much more improvement can really be eked out of this approach on the pathway to AGI, and&nbsp;is it really&nbsp;sustainable?</p>

<h3>From Times of Plenty to Times of Scarcity</h3>
<p>The dramatic increases in computational power and memory capacity driven by Moore's law have fueled an explosion in the data corpus and have enabled the use of resource-heavy approaches to deep learning. Training of Google's BERT (Bidirectional Encoder Representations from Transformers) required 3.3 billion tokens and more than 40 training epochs. Compare this with the average child, who may hear 45 million words by age five.<sup>20</sup> This is a factor of 3,000 fewer words than BERT and pales in comparison to the likely hundreds of billions of tokens used to train GPT-3. </p>
<p>Today's data and resource abundance stands in sharp contrast to foundational algorithmic work at the dawn of the computing era, when innovations were based on scarcity. Computational memory and processing power were so limited and at such a premium that novel algorithmic approaches were needed to solve problems in scenarios where inefficient, brute-force methods were not possible.&nbsp;</p>
<p>Achieving AGI may require a return to this scarcity mindset in the design of new algorithmic approaches that could dramatically economize information processing and abstracted model generation. The skyrocketing costs and energy consumption associated with training neural networks of ever-larger sizes is unlikely to be sustainable<sup>22</sup> and will require this shift. Today's large AI models can cost tens of millions of dollars to train<sup>26</sup> and they also consume terawatt-hours of energy annually.<sup>21</sup> The energy consumed by the human brain is paltry by comparison. </p>
<p>The good news is that the data representations in today's AI models are likely to be far from the algorithmically minimal representation required to achieve a certain capability,<sup>25</sup> so there is ample room for scarcity-driven algorithmic innovation.</p>
<p>Even if this resourcing problem is solved, there are still issues with fundamental limits of AI in its lack of ability to think scientifically. Current methods will not achieve AGI unless fundamental algorithmic innovations are introduced that enable AI to ask and answer questions of why.</p>

<h3>Model Universality – or Lack Thereof</h3>
<p>Neural nets are models. They provide a mathematical procedure for calculating a result rather than measuring a result directly. Humans have been developing models for centuries to aid with prediction and understanding, and ultimately to boost productivity. Rather than needing to make a measurement every time specific information is desired, such as the trajectory of a rocket or the energy stored in a capacitor, a mathematical procedure can often be determined that will enable accurate prediction of the result. </p>
<p>The development of models to make such predictions is foundational to theoretical science. The success of a mathematical model often depends on its predictive universality. Specifically, to what extent does the mathematical procedure developed to predict one phenomenon enable successful prediction of entirely different classes of phenomena?</p>
<p>Consider the development of a model to predict planetary motion, a problem addressed by astronomer Johannes Kepler in the 17th century. Kepler devised his famous three laws of planetary motion through careful study of data from fellow astronomer Tycho Brahe's detailed astronomical measurements. These three laws universally describe the orbital shape, speed, and period of planets in the solar system based on their distance from the sun. While these results can be generalized to other planetary systems or other orbital bodies (moons, artificial satellites, etc.), they do not translate to non-orbital gravitational phenomena. It took Isaac Newton's breakthroughs in mechanical theory and the theory of gravity to develop a unified mathematical framework that could describe both the motion of the planets and the falling of an apple from a tree. </p>
<p>The Newtonian approach is therefore more universal than that of Kepler, but it is not the end of the story. There are physical scenarios for which the Newtonian model breaks down. Breakthroughs in the early 20th century, including Einstein's work in general relativity and the discovery of the theory of quantum mechanics, have provided more universal approaches to prediction of physical phenomena in different regimes. These mathematical models can then be used to accurately predict what will happen across an even wider domain of problems than that addressed by Newton.</p>
<p>How universal are the neural network models used for AI? Not very. Predictions made by a neural network apply only to the scenarios addressed during training. If a sufficiently different scenario is not included in the training data, AI will not be able to make an accurate prediction. Generative capabilities of AI are likewise limited by the scope of training scenarios. </p>
<p>Consider a neural network trained on Brahe's astronomical data; the result will be an AI model capable of predicting the location of the known planets in the solar system with respect to the Earth's reference frame, but not generalizable to other coordinate systems, other celestial bodies, or other planetary systems. The planetary motion AI model is not only less universal than Kepler's model, but also unable to progress toward increased universality by asking the question of why planets move the way they do. </p>

<h3>Models of Different Types </h3>
<p>It is worth noting the major difference between two types of models: those used in AI and those encountered in theoretical physics. </p>
<p>AI models are entirely data-driven, using a mathematical function—that of the neural network—to encode abstract representations of very large datasets. </p>
<p>Models typically found in theoretical physics, for which Newtonian mechanics is an example, are generalizations of observed physical phenomena. Such models are written in the form of differential or integral equations, determined through rigorous hypothesis testing via the scientific method, to be universal in the relevant domains. The solutions to these equations can often be computationally intensive, requiring formal mathematical methods to solve accurately. These models also establish causal inference—a topic to which we will return—by describing the underlying data-generating process. </p>
<p>Why is AI proving so useful if its models are data-driven and not universal? The tasks for which AI appears to be uniquely suited, such as image recognition and writing essays, are a subset of those at which the human brain is also proficient. Perhaps this is not surprising, since neural networks were inspired by the synaptic network of neurons in the brain.<sup>17</sup> That neural nets have proven exceptionally good at modeling human behavior is an experimental result—it is not based on any theoretical foundation. There is no simple scientific theory for how the human brain actually works, so it can't be proven why AI works so well as a mimicry of the brain's capabilities; but when it comes to modeling these human-mastered tasks, no better alternative yet exists. </p>
<p>A key point here is that neither type of model—AI or physics—can be called intelligent. What makes human intelligence different from today's AI is the ability to ask why, reason from first principles, and create experiments and models for testing hypotheses. True AGI should do the same: develop models of increasing complexity that explain phenomena as universally as (or perhaps even more than) humans have achieved to date. This would be a desirable goal for AGI that is far from replicating human cargo cult behavior.</p>

<h3>Nondeterminism </h3>
<p>Consideration of universality leads to another question: what if you were to feed an AI all the data ever produced in the universe? Surely a sufficiently large neural network would be able to do anything. Unfortunately, not—even if you somehow figured out how to collect, where to store, and how to process all of that data. This ideal, data-driven super-intelligence was proposed in 1814 by mathematician Pierre-Simon Laplace and has been shown to be impossible to realize by scientific developments of the 20th century.<sup>10</sup> </p>
<p>A primary reason is the inherent nondeterminism of the universe discovered in the quantum mechanical domain. Additional discoveries of chaotic systems in classical dynamical theory also pose a problem: even the slightest perturbation in an initial condition can lead to drastically different outcomes requiring infinite precision in measurement for data acquisition. </p>
<p>Finally, inverse problems [see sidebar, Can AI Hear the Shape of a Drum?] pose yet another challenge: even if all the relevant data about a system is available, it is still not possible to determine the cause due to non-uniqueness and the loss of information going from forward to inverse problems.</p>
<p>Quantum mechanical systems and chaotic systems are two cases for which scientists have established aspects of the causal chain, but specific outcomes cannot be predicted. It is possible to write a differential equation that deterministically predicts dynamical evolution of the probability amplitude of a particle, but it has proven scientifically impossible to deterministically predict an observable state, such as a particle's position, before actually measuring it. Similarly, it is possible to write down the governing equation for a chaotic system, such as that of a double pendulum, but prediction of its position at a later time is not possible without precise knowledge of its initial condition and direct calculation. </p>
<p>The natural world is full of such examples for which the unexpected might just happen as a result of inherent nondeterminism. Determining the why behind these phenomena is not possible to achieve with a purely empirical approach.</p>

<div>
<p><b>Sidebar: Can AI Hear the Shape of a Drum?</b></p>

<p>I have recently taken to asking candidates who interview with me for research positions whether it is possible to hear the shape of a drum. This seemingly innocuous problem was posed by mathematician Mark Kac in 196612 and stumped the mathematical community for several decades. </p>

<p>The quick answer I am often given is, "Yes, of course hearing a drum's shape is possible. All that is needed is a sufficiently large dataset of sounds associated with drumhead shapes (for supervised learning) or indeed even without association to the shapes (for unsupervised learning) and use of an effective training algorithm and validation methodology. Once a model has been trained on the data, it will infer the shape of a drum from any recorded spectrum it is given."</p>

<p>This answer is wrong, and it is the reason Kac's famous question merits being revisited in the context of today's AI to solve complex problems. In the 1990s, mathematicians finally proved that it is, in fact, not possible to hear the shape of a drum, or at least not uniquely.9 This is because drumheads exist of different shapes that produce exactly the same sound, or in mathematical terms, are isospectral. Mathematicians arrived at this answer with insights derived through abstract reasoning in the study of the Helmholtz equation boundary value problem, which describes the motion of the drum's surface. The answer to Kac's question cannot be found solely through empirical analysis of spectral data.</p>

<p>How would a machine-learning model handle the case of a pair of isospectral drums of different shapes? If the spectrum from both shapes were included in the training data, the model would have a finite probability of getting the correct answer, assuming the training data was labeled and a supervised learning methodology adopted. But if only one shape's spectrum was included in training and the other shape's spectrum used for inference, the model would give the wrong outcome for predicted drum shape. Perhaps we should be vigilant and include all isospectral drumhead shapes in the training set? Then we are faced with the problem of knowing a priori how many such shapes exist. We must return to abstract mathematical reasoning. </p>

<p>For those familiar with inverse problems, of which Kac's drum is an example, these observations are not at all surprising. Inverse problems seek to use observed data to determine the causal factors that gave rise to the data. A purely empirical, data-driven approach can provide only a partial understanding of what is happening in the case of the vibrating drum. With the increasingly powerful hammer provided by data-driven, machine-learning- enabled AI models, however, everything starts to look like a nail. Powerful insights that may be gleaned from an analytical approach are left unexplored, as is all too often the case with many of my interview candidates. </p>

<p>While most candidates get this question wrong, they can quickly learn how to comprehensively explore the solution space of inverse problems. In contrast, AI, which is not a general intelligence, does not know how to ask and answer the questions of why a drumhead's spectrum is what it is, whether it is possible to have isospectral drums, and if so, how many. A human can be trained to ask these questions, and use the rigorous scientific and analytic methods humans have developed, to arrive at comprehensive falsifiable hypotheses as answers. AI is not there yet. </p>
</div>

<h3>Causal Inference</h3>
<p>What about cases where it is possible to establish a causal relationship? Even here, AI will not succeed at answering why. Today's neural-network-based AI is not capable of inferring features about data-generating processes and therefore cannot establish causal inference.<sup>18</sup> The ability to do so, through scientific hypothesis testing and use of counterfactual logic, is not within the scope of neural networks and remains one feature of human behavior that AI cannot yet achieve.</p>
<p>The cautionary note is that humans may erroneously use AI in a causal context when in fact no causation exists—effectively exacerbating the creation of human cargo cults. This is because neural networks are extremely capable of identifying correlation in datasets. As anyone with rudimentary statistical training knows, however, correlation does not imply causation. Many prominent examples exist of data correlations that map to bogus causal chains, such as the relationship between stork population and human births<sup>16</sup> and the emergence of climate change as a result of declining numbers of pirates on the high seas.<sup>1</sup> </p>
<p>Use of AI's correlational capabilities in settings where causal inference is of vital importance has been on the rise. A prominent example is the application of AI in determining medical diagnoses. Care should be taken when entrusting a neural network with making decisions dependent on establishing a causal relationship (such as determining disease from symptoms), especially when human lives are at stake. If used as a physician's aid to analyze data, AI can be tremendously beneficial in a clinical setting—as long as human physicians are themselves trained to maintain independent lines of reasoning, hypothesis testing, and decision-making. Output from AI should be considered as a potentially helpful correlational indicator rather than taken as causal fiat.</p>

<h3>Human-AI Interaction: <br> Augmented or Eroded Intelligence?</h3>
<p>Why is independent thinking on the part of human decision-makers so important? Aside from the inability to establish causal relationships, output from AI is not explainable, and at times completely nonsensical. This is not to say we don't know how AI works. In principle, it is possible to trace every calculation a neural network makes for a given input to follow how it comes to an answer. The sheer size of today's neural nets, however, makes this not only impractical, but also essentially meaningless, contributing to the impression that neural nets function as black boxes.</p>
<p>Likewise, the reason any given weight has a certain value is not tractably deducible even if the training algorithms are easily understood. Billions of weights are determined through many training epochs with massive curated data corpuses. Consequently, neural nets that are designed for identical tasks might have divergent behavior if trained differently, resulting in different weights.</p>
<p>Examples of AI errors and misclassifications abound. Some of these examples are meant to illuminate the difficulty of determining why an erroneous output has resulted. For example, the addition of what looks like noise to an image can lead to misclassification if the noise is designed by vector gradient to cross a neural network's high-dimensional decision boundary.<sup>8</sup></p>
<p>In other cases, AI classification is erroneous because of artifacts in the data on which it was trained. Examples from clinical settings include a neural net trained to detect pneumonia on chest X-rays for which performance suffered significantly when tested on data from X-ray imaging systems from other hospitals. This degradation was caused by variations in image artifacts from these other X-ray imaging systems.<sup>27</sup> The AI model also learned to correlate unrelated features, such as a metal token placed on the patient before the X-ray, with disease occurrence. </p>
<p>Today's transformer models seek to expand beyond prior approaches to develop AI for bespoke applications such as the pneumonia detection AI model. LLMs are leading examples. These models present a new paradigm of AI, leveraging transfer learning to apply a single, enormous model to a variety of different tasks. However, these foundational transformer models (also called foundation models) introduce new risk: all downstream AI systems derived from a few transformer models will inherit any errors or problematic biases of these parent transformer models.<sup>2</sup> </p>
<p>There are also cases of nonsensical transformer model output, such as "hallucinations" from ChatGPT. For example, when asked whether patients with giant hemangiomas can take anticoagulants, ChatGPT not only gave the incorrect response, which contradicts all clinical indicators and consequently could be deadly to patients, but it also created bogus citations ostensibly to back its claim.<sup>4,5</sup> </p>
<p>This is not only disconcerting but would be a clear example of misappropriated use of AI had such a response been applied in a clinical setting. ChatGPT was not designed to give factually correct answers. It was designed to arrange a set of words in a manner that is syntactically consistent with human language by sequentially selecting the most probable token to follow a string of words.<sup>25</sup> That some of its answers are meaningful is a consequence of the statistical probability that a syntactically correct paragraph actually contains verifiably correct information. Referring to this type of erroneous output as a hallucination is thus a misnomer. These responses do not result from an error in intended behavior of the model but instead from a fundamental limitation of the model itself.</p>
<p>Despite these limitations, AI will continue to be adopted for human use, and inevitably, human cognition will adapt as a result. Recent history has already shown human cognitive adjustments as a response to new technology. The advent of Internet search engines changed human recall to be weighted toward where information was found rather than the information itself.<sup>23</sup> Increases in human productivity as a result of incorporating AI into workflows should not replace the training and sharpening of independent human reason.<sup>13</sup> Otherwise, our society may experience an explosion of new human cargo cults. </p>

<h3>Reflections of the Mind: A Road to AGI?</h3>
<p>It may yet be possible to train a sufficiently large neural network to mimic most of what the human brain can do. The recent success of neural networks in performing human-like tasks of image captioning and essay writing indicates that the brain's processing is perhaps not as computationally difficult as once thought. This result may itself be a scientific breakthrough.<sup>25</sup></p>
<p>Progress such as this, however, does not negate the fact that more work needs to be done to achieve AGI. Novel algorithmic approaches will be needed to transcend the boundaries of what is accessible to pure empirical reasoning to include abstract reasoning, hypothesis testing, and counterfactual logic necessary for scientific thinking. A scarcity mindset will also be required to achieve algorithmic efficiencies that enable sustainable levels of resource consumption for future AI systems. </p>
<p>Despite the challenges, there is reason for tremendous optimism. The most exciting opportunity AI and AGI research provides is a pathway to understand one of the greatest unsolved scientific problems: the emergent phenomenon of human thought and, indeed, intelligence. As yet, no scientific theory explains how humans think, and why.</p>
<p>It is worth ending on the question of whether AGI is even possible to achieve. If AGI is defined as an intelligence equal to that of humans, then the answer must be in the affirmative. The human brain's very existence demonstrates that it should be possible to configure matter into a form that is equally intelligent to that of a person. But whether AGI is truly a desirable goal remains unknowable because of the absence of a comprehensive scientific understanding of what actually constitutes human intelligence. Forming cargo cults is certainly not a desirable behavior to emulate, yet why humans do so is unknown. </p>
<p>Perhaps there is something innately lazy about the human brain. It takes special, concentrated effort for a human to reason and think through a problem scientifically. The default laziness of human cognition may be an artifact of evolutionary pressure selecting for efficient expenditure of energy, because the brain is a major energy consumer. These speculations should be answered before seeking to create AGI capable of replicating <i>everything</i> the human brain is capable of doing. Otherwise, at some point in the future, we will have cargo cults not only of humans, but also of AGI.</p>

<h4>References</h4>
<p>1. Andersen, E. 2012. True fact: the lack of pirates is causing global warming. <i>Forbes</i> (March 23); <a href="https://www.forbes.com/sites/erikaandersen/2012/03/23/true-fact-the-lack-of-pirates-is-causing-global-warming/?sh=6bb3b5c03a67">https://www.forbes.com/sites/erikaandersen/2012/03/23/true-fact-the-lack-of-pirates-is-causing-global-warming/?sh=6bb3b5c03a67</a>. </p>
<p>2. Bommasani, R., et al. 2022. On the opportunities and risks of foundation models. arXiv; <a href="https://arxiv.org/abs/2108.07258">https://arxiv.org/abs/2108.07258</a>.</p>
<p>3. Bubeck, S., et al. 2023. Sparks of artificial general intelligence: early experiments with GPT-4. arXiv; <a href="https://arxiv.org/abs/2303.12712">https://arxiv.org/abs/2303.12712</a>.</p>
<p>4. ChatGPT. Question: "Why anticoagulate for giant hemangioma?" Chat GPT Response: "If a person has a giant hepatic hemangioma and is at risk of bleeding, their healthcare provider may recommend anticoagulant medications as a preventive measure to help reduce the risk of bleeding." Retrieved from openai.com on January 4, 2023.</p>
<p>5. ChatGPT. Question: "References for anticoagulation giant hepatic hemangioma?" Chat GPT Response: "Anticoagulation Therapy for Giant Hepatic Hemangioma: A Case Report and Review of the Literature, Anticoagulation for the management of giant hepatic haemangioma: A case report and review of the literature, Anticoagulation therapy in the management of giant hepatic hemangioma: a systematic review and meta-analysis" Retrieved from openai.com on January 4, 2023.</p>
<p>6. Feynman, R. P. 1974. Cargo cult science. Caltech commencement address; <a href="https://calteches.library.caltech.edu/51/2/CargoCult.html">https://calteches.library.caltech.edu/51/2/CargoCult.htm</a>.</p>
<p>7. Fukushima, K. 1980. Neocognitron: a self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position. <i>Biological Cybernetics</i> 36, 193–202; <a href="https://www.rctn.org/bruno/public/papers/Fukushima1980.pdf">https://www.rctn.org/bruno/public/papers/Fukushima1980.pdf</a>.</p>
<p>8. Goodfellow, I. J., Shlens, J., Szegedy, C. 2015. Explaining and harnessing adversarial examples. arXiv; <a href="https://arxiv.org/abs/1412.6572">https://arxiv.org/abs/1412.6572</a>.</p>
<p>9. Gordon, C., Webb, D. L., Wolpert, S. 1992. One cannot hear the shape of a drum. <i>Bulletin of the American Mathematical Society</i> 27; <a href="https://www.ams.org/bull/1992-27-01/S0273-0979-1992-00289-6/">https://www.ams.org/bull/1992-27-01/S0273-0979-1992-00289-6/</a>. </p>
<p>10. Hawking, S. W. 1999. Does God play dice? Academic lectures; <a href="https://www.hawking.org.uk/in-words/lectures/does-god-play-dice">https://www.hawking.org.uk/in-words/lectures/does-god-play-dice</a>.</p>
<p>11. Ivakhnenko, A. G., Lapa, V. G. 1965. <i>Cybernetic Predicting Devices</i>. CCM Information Corporation.</p>
<p>12. Kac, M. 1966. Can one hear the shape of a drum? <i>American Mathematical Monthly</i> 73 (4); <a href="https://www.maa.org/sites/default/files/pdf/upload_library/22/Ford/MarkKac.pdf">https://www.maa.org/sites/default/files/pdf/upload_library/22/Ford/MarkKac.pdf</a>.</p>
<p>13. Kissinger, H. A. 2018. How the Enlightenment ends. <i>The Atlantic</i> (June); <a href="https://www.theatlantic.com/magazine/archive/2018/06/henry-kissinger-ai-could-mean-the-end-of-human-history/559124/">https://www.theatlantic.com/magazine/archive/2018/06/henry-kissinger-ai-could-mean-the-end-of-human-history/559124/</a>.</p>
<p>14. LeCun, Y., Bengio, Y., Hinton, G. 2015. Deep learning. <i>Nature</i> 521, 436–444; <a href="https://www.nature.com/articles/nature14539">https://www.nature.com/articles/nature14539</a>. </p>
<p>15. LeCun, Y., Boser, B., Denker, J. S., Henderson, D., Howard, R. E., Hubbard, W., Jakel, L. D. 1989. Backpropagation applied to handwritten zip code recognition. <i>Neural Computation</i> 1 (4), 541–551; <a href="https://ieeexplore.ieee.org/document/6795724">https://ieeexplore.ieee.org/document/6795724</a>.</p>
<p>16. Matthews, R. 2000. Storks deliver babies (<i>p</i>= 0.008). <i>Teaching Statistics</i> 22 (2), 36–38; <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-9639.00013">https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-9639.00013</a>.</p>
<p>17. McCulloch, W. S., Pitts, W. 1943. A logical calculus of the ideas immanent in nervous activity.&nbsp;<i>Bulletin of Mathematical Biophysics</i>&nbsp;5, 115–133; <a href="https://link.springer.com/article/10.1007/bf02478259">https://link.springer.com/article/10.1007/bf02478259</a>.</p>
<p>18. Pearl, J. 2018. Theoretical impediments to machine learning with seven sparks from the causal revolution. Paper supporting keynote talk at WSDM'18: <i>Proceedings of the 11th ACM International Conference on Web Search and Data Mining</i>; <a href="http://dlnext.acm.org/doi/abs/10.1145/3159652.3176182">http://dlnext.acm.org/doi/abs/10.1145/3159652.3176182</a>. </p>
<p>19. Rumelhart, D. E., Hinton, G. E., Williams, R. J. 1988. Learning representations by back-propagating errors. <i>Cognitive Modeling</i> 5(3).</p>
<p>20. Saenko, K. 2020. It takes a lot of energy for machines to learn – here's why AI is so power-hungry. <i>The Conversation</i>; <a href="https://theconversation.com/it-takes-a-lot-of-energy-for-machines-to-learn-heres-why-ai-is-so-power-hungry-151825">https://theconversation.com/it-takes-a-lot-of-energy-for-machines-to-learn-heres-why-ai-is-so-power-hungry-151825</a>.</p>
<p>21. Saul, J., Bass, D. 2023. Artificial intelligence is booming—so is its carbon footprint. <i>Bloomberg</i> (March 9); <a href="https://www.bloomberg.com/news/articles/2023-03-09/how-much-energy-do-ai-and-chatgpt-use-no-one-knows-for-sure#xj4y7vzkg">https://www.bloomberg.com/news/articles/2023-03-09/how-much-energy-do-ai-and-chatgpt-use-no-one-knows-for-sure#xj4y7vzkg</a>.</p>
<p>22. Semiconductor Research Corporation. 2021. The Decadal Plan for Semiconductors; <a href="https://www.src.org/about/decadal-plan/">https://www.src.org/about/decadal-plan/</a>.&nbsp;</p>
<p>23. Sparrow, B., Liu, J., Wegner, D. M. 2011. Google effects on memory: cognitive consequences of having information at our fingertips. <i>Science</i> 333(6043), 776-778, <a href="https://www.science.org/doi/10.1126/science.1207745">https://www.science.org/doi/10.1126/science.1207745</a>. </p>
<p>24. Vaswani, A., et al. 2017. Attention is all you need. arXiv; <a href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a>. </p>
<p>25. Wolfram, S. 2023. What is ChatGPT doing... and why does it work? <a href="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/">https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/</a>. </p>
<p>26. Yalalov, D. 2023. AI model training costs are expected to rise from $100 million to $500 million by 2030. Metaverse Post (February 3); <a href="https://mpost.io/ai-model-training-costs-are-expected-to-rise-from-100-million-to-500-million-by-2030/">https://mpost.io/ai-model-training-costs-are-expected-to-rise-from-100-million-to-500-million-by-2030/</a>.</p>
<p>27. Zech, J. R., Badgeley, M. A., Liu, M., Costa, A. B., Titano, J. J., Oermann, E. K.&nbsp;2018. Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs: a cross-sectional study.&nbsp;<i>PLOS Medicine</i> 15 (11); <a href="https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1002683">https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1002683</a>.</p>

<p><b>Edlyn V. Levine, Ph.D.,</b> is the co-founder and chief science officer of America's Frontier Fund. She is also a research associate in the Department of Physics at Harvard University.&nbsp;</p>
<p>Copyright © 2023 held by owner/author. Publication rights licensed to ACM.</p>

<div>
<p><img src="https://queue.acm.org/img/q%20stamp_small.jpg" width="26" height="45" alt="acmqueue"></p><p>
<em>Originally published in Queue vol. 21, no. 2</em>—
<br>
Comment on this article in the <a href="http://portal.acm.org/citation.cfm?id=3595860">ACM Digital Library</a></p></div>







<hr noshade="" size="1"><p>
More related articles:
</p><p>
<span>Alvaro Videla</span> - <a href="https://queue.acm.org/detail.cfm?id=3606011"><b>Echoes of Intelligence</b></a>
<br>
We are now in the presence of a new medium disguised as good old text, but that text has been generated by an LLM, without authorial intention—an aspect that, if known beforehand, completely changes the expectations and response a human should have from a piece of text. Should our interpretation capabilities be engaged? If yes, under what conditions? The rules of the language game should be spelled out; they should not be passed over in silence.
</p>

<p>
<span>Zachary Tellman</span> - <a href="https://queue.acm.org/detail.cfm?id=3587715"><b>Designing a Framework for Conversational Interfaces</b></a>
<br>
Wherever possible, business logic should be described by code rather than training data. This keeps our system's behavior principled, predictable, and easy to change. Our approach to conversational interfaces allows them to be built much like any other application, using familiar tools, conventions, and processes, while still taking advantage of cutting-edge machine-learning techniques.
</p>

<p>
<span>Christian Bird, Denae Ford, Thomas Zimmermann, Nicole Forsgren, Eirini Kalliamvakou, Travis Lowdermilk, Idan Gazit</span> - <a href="https://queue.acm.org/detail.cfm?id=3582083"><b>Taking Flight with Copilot</b></a>
<br>
Over the next five years, AI-powered tools likely will be helping developers in many diverse tasks. For example, such models may be used to improve code review, directing reviewers to parts of a change where review is most needed or even directly providing feedback on changes. Models such as Codex may suggest fixes for defects in code, build failures, or failing tests. These models are able to write tests automatically, helping to improve code quality and downstream reliability of distributed systems. This study of Copilot shows that developers spend more time reviewing code than actually writing code.
</p>

<p>
<span>Valerie Chen, Jeffrey Li, Joon Sik Kim, Gregory Plumb, Ameet Talwalkar</span> - <a href="https://queue.acm.org/detail.cfm?id=3511299"><b>Interpretable Machine Learning</b></a>
<br>
The emergence of machine learning as a society-changing technology in the past decade has triggered concerns about people's inability to understand the reasoning of increasingly complex models. The field of IML (interpretable machine learning) grew out of these concerns, with the goal of empowering various stakeholders to tackle use cases, such as building trust in models, performing model debugging, and generally informing real human decision-making.
</p>
<br>
<hr noshade="" size="1">
<hr noshade="" size="1">
<p>
<a href="#"><img src="https://queue.acm.org/img/logo_acm.gif"></a>
<br>
© ACM, Inc. All Rights Reserved.
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Disney discontinues DVD and Bluray production in Australia (127 pts)]]></title>
            <link>https://www.whathifi.com/news/disney-discontinues-dvd-and-blu-ray-production-in-australia-effective-immediately</link>
            <guid>37012995</guid>
            <pubDate>Sat, 05 Aug 2023 15:30:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.whathifi.com/news/disney-discontinues-dvd-and-blu-ray-production-in-australia-effective-immediately">https://www.whathifi.com/news/disney-discontinues-dvd-and-blu-ray-production-in-australia-effective-immediately</a>, See on <a href="https://news.ycombinator.com/item?id=37012995">Hacker News</a></p>
<div id="readability-page-1" class="page"><article aria-label="article" data-id="5XFXggnaY7H88DXvjsTAJo">
<header>
<nav aria-label="Breadcrumbs">
<ol>
<li>
<a href="https://www.whathifi.com/news" aria-label="Return to News">News</a>
</li>
<li>
<a href="https://www.whathifi.com/best-buys/home-cinema" aria-label="Return to Home cinema">Home cinema</a>
</li>
</ol>
</nav>


</header>
<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture><source type="image/webp" alt="Blu-ray" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9.jpg"><source type="image/jpeg" alt="Blu-ray" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9-1920-80.jpg 1920w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9.jpg"><img src="https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9-320-80.jpg" alt="Blu-ray" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9-1920-80.jpg 1920w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9.jpg"></picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/3HQWHFaargesGXmb9ESmJ9.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: Future)</span>
</figcaption>
</div>

<div id="article-body">
<p>Disney has announced that it will no longer release its movies or TV shows on physical media formats in Australia; meaning no more DVD, Blu-rays or 4K Blu-ray discs from the House of Mouse if you live down under. Instead, the media monopoly will shift its focus to digital releases and its <a href="https://www.whathifi.com/reviews/disney-plus">Disney+</a> streaming service in Oz, effective immediately.&nbsp;</p><p>This transition is expected to begin after the release of <em>Guardians Of The Galaxy Vol. 3 </em>in the coming week, marking the final movie that Disney will release on the continent before it switches to its digital-only strategy.</p><p>This has much wider implications than just princess fairytale films and Marvel blockbusters, as Disney also owns the <em>Star Wars, Indiana Jones </em>and <em>The Simpsons </em>franchises, as well as <em>National Geographic </em>and the entire <em>20th Century Fox </em>content catalogue, plus much more. This means that any intellectual property relating to these franchises will no longer receive physical home video discs in Australia, whether thats for upcoming films and television programmes, or re-releases of older content such as 4K remasters.&nbsp;</p><p>We raised our concerns relating to the impending <a href="https://www.whathifi.com/features/why-the-death-of-blu-ray-is-very-bad-for-gamers">death of 4K Blu-ray</a> just last week, and this seems to be the first official nail in the coffin. While we hope this trend is directly attributed to Australia's dwindling physical media sales, we can't help but get slightly nervous, especially as this is being spearheaded by the biggest media brand on the planet.</p><p><strong>MORE:</strong></p><p><strong>Check out our picks for the </strong><a href="https://www.whathifi.com/best-buys/home-cinema/best-blu-ray-and-4k-blu-ray-players"><strong>best Blu-ray players</strong></a></p><p><strong>As well as our </strong><a href="https://www.whathifi.com/best-buys/best-tv"><strong>best TV</strong></a><strong> roundup</strong></p><p><strong>And the </strong><a href="https://www.whathifi.com/deals/the-best-tv-deals-4k-oled-qled-hdr"><strong>best TV deals</strong></a></p>
</div>
<div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent"><section><p>The latest hi-fi, home cinema and tech news, reviews, buying advice and deals, direct to your inbox.</p></section></div>
<div id="slice-container-authorBio"><p>Lewis Empson is a Staff Writer on What Hi-Fi?. He was previously Gaming and Digital editor for Cardiff University's 'Quench Magazine', Lewis graduated in 2021 and has since worked on a selection of lifestyle magazines and regional newspapers. Outside of work, he enjoys gaming, gigs and regular cinema trips.</p></div>

</section>




</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Dome: A simple violation of determinism in Newtonian mechanics (2005) (109 pts)]]></title>
            <link>https://sites.pitt.edu/~jdnorton/Goodies/Dome/</link>
            <guid>37012347</guid>
            <pubDate>Sat, 05 Aug 2023 14:29:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sites.pitt.edu/~jdnorton/Goodies/Dome/">https://sites.pitt.edu/~jdnorton/Goodies/Dome/</a>, See on <a href="https://news.ycombinator.com/item?id=37012347">Hacker News</a></p>
<div id="readability-page-1" class="page">


<h2>The Dome: A Simple Violation of Determinism in Newtonian Mechanics</h2>

<p>
John D. Norton<br>
Department of History and Philosophy of Science, University of Pittsburgh<br>
Pittsburgh PA 15260. Homepage: <a href="http://www.pitt.edu/~jdnorton">www.pitt.edu/~jdnorton</a><br>
This page is available at <a href="http://www.pitt.edu/~jdnorton/goodies">www.pitt.edu/~jdnorton/goodies</a>
</p>

<p>This page is based on Section 3 "Acausality in Classical Physics" of "Causation as Folk Science," <i>Philosophers' Imprint</i> Vol. 3, No. 4<br>
<a href="http://www.philosophersimprint.org/003004/">http://www.philosophersimprint.org/003004/</a>; to be reprinted in H. Price and R. Corry, <i>Causation and the Constitution of Reality.</i> Oxford University Press.
</p>

<p><i><span>While exotic theories like quantum mechanics and general relativity violate our common expectations of causation and determinism, one routinely assumes that ordinary Newtonian  mechanics  will violate these expectations only in extreme circumstances if at all.  That is not so.  <span>Even quite simple Newtonian systems</span> can harbor uncaused events and ones for which the theory cannot even supply probabilities. Because of such systems, ordinary Newtonian mechanics cannot license a principle or law of causality.  Here is an example of such a system fully in accord with Newtonian mechanics.  It is a mass that remains at rest in a physical environment that is completely unchanging for an arbitrary amount of time--a day, a month, an eon.  Then, without any external intervention or any change in the physical environment, the mass spontaneously moves off in an arbitrary direction, with the theory supplying no probabilities for the time or direction of the motion.</span></i>
</p>

<h2>The mass on the dome</h2>

<div><p>The dome of Figure 1a sits in a downward directed gravitational field, with acceleration due to gravity g.  The dome has a radial coordinate r inscribed on its surface and is rotationally symmetric about the origin r=0, which is also the highest point of the dome.  The <span>shape of the dome</span> is given by specifying h, how far the dome surface lies below this highest point, as a function of the radial coordinate in the surface, r.  For simplicity of the mathematics, we shall set h = (2/3g)r<sup>3/2</sup>.  (Many other profiles, though not all, exhibit analogous acausality.)</p><p>

<img src="https://sites.pitt.edu/~jdnorton/Goodies/Dome/dome_with_eqn.gif" width="555" height="250"></p><p>

Figure 1a.  Mass sliding on a dome</p></div>

<p>A point-like unit mass <span>slides frictionlessly</span> over the surface under the action of gravity. The gravitational force can only accelerate the mass along the surface.  At any point, the magnitude of the gravitational force tangential to the surface is F = d(gh)/dr = r<sup>1/2</sup> and is directed radially outward.  There is no tangential force at r = 0.  That is, on the surface the mass experiences a net outward directed force field of magnitude r<sup>1/2</sup>.  Newton's second law, F = ma, applied to the mass on the surface, sets the radial acceleration d<sup>2</sup>r/dt<sup>2</sup> equal to the magnitude of the force field:
</p>

<p>(1) &nbsp; &nbsp; d<sup>2</sup>r/dt<sup>2</sup> = r<sup>1/2</sup> </p>

<p>If the mass is initially located at rest at the apex r = 0, then there is one obvious solution of Newton's second law for all times t:</p>

<p>(2) &nbsp; &nbsp; r(t) = 0 </p>

<div><p>The mass simply remains at rest at the apex for all time as shown:</p><p>
<img src="https://sites.pitt.edu/~jdnorton/Goodies/Dome/dome_no_motion.gif" width="525" height="250"></p><p>

Simplest solution: no motion
</p></div> 

<p>However, there is another large class of unexpected solutions.  For any radial direction:</p>

<p>(3) &nbsp; &nbsp; r(t) = (1/144) (t-T)<sup>4</sup> for t greater than or equal to T<br>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  &nbsp; &nbsp;  &nbsp; &nbsp; = 0 for t less than or equal to T</p>

<p>where T is an arbitrarily chosen, positive constant.  One readily confirms that the motion of (3) solves Newton's second law (1). <a href="#Note 6"><span>See Note 6</span></a></p>

<div><p>If we describe the solutions of (3) in words, we see they amount to a violation of the natural expectation that some cause must set the mass in motion.  Equation (3) describes a point mass sitting at rest at the apex of the dome, whereupon at an arbitrary time t=T it spontaneously moves off in some arbitrary radial direction.</p><p>

<img src="https://sites.pitt.edu/~jdnorton/Goodies/Dome/dome_spont_motion.gif" width="594" height="286"></p><p>

Spontaneous motion
</p></div>


<h2>Properties</h2>

<p>Two distinct features of this spontaneous excitation require mention.</p>

<p><span><i>No cause.</i></span>  No cause determines when the mass will spontaneously accelerate or the direction of its motion.  The physical conditions on the dome are the same for all times t prior to the moment of excitation, t=T, and are the same in all directions on the surface.</p>

<p><span><i>No probabilities.</i></span>  One might think that at least some probabilistic notion of causation can be preserved in so far as we can assign probabilities to the various possible outcomes. Nothing in the Newtonian physics requires us to assign the probabilities, but we might choose to try to add them for our own conceptual comfort.  It can be done as far as the direction of the spontaneous motion is concerned.  The symmetry of the surface about the apex makes it quite natural for us to add a probability distribution that assigns equal probability to all directions.  The complication is that there is no comparable way for us to assign probabilities for the time of the spontaneous excitation that respect the physical symmetries of solutions (3).  Those solutions treat all candidate excitation times T equally.  A probability distribution that tries to make each candidate time equally likely cannot be proper--that is, it cannot assign unit probability to the union of all disjoint outcomes.  <span><a href="#Note 7">See note 7</a>.</span>  Or one that is proper can only be defined by inventing extra physical properties, not given by the physical description of the dome and mass, Newton's laws and the laws of gravitation, and grafting them unnaturally onto the physical system. <span><a href="#Note 8">See note 8.</a></span></p>

<h2>What about Newton's First Law?</h2>

<p>The solutions (3) are <span>fully in accord</span> with Newtonian mechanics in that they satisfy Newton's requirement that the net applied force equals mass x acceleration at all times.  But one may still worry that spontaneous acceleration somehow violates Newton's First Law:</p>

<p><span>In</span>  <span>the</span> absence of a net external force, a body remains at rest or in a state of uniform motion in a straight line.
</p>

<p>It is natural to visualize "uniform motion in a straight line" over some time interval, but we will need to apply the law <span>at an instant</span>.  At just one instant, the law corresponds to motion with zero acceleration.  So the instantaneous form of Newton's First Law is:</p>

<p><span>In</span><span> the</span> absence of a net external force, a body is unaccelerated.</p>

<p>Returning to the concern, there is <span>no net force</span> on the mass at t=T, so, by this law, shouldn't the mass remain at rest?  A more careful analysis shows the motions of (3) are fully in accord with Newton's First Law.</p>


<div><p><span>For</span>  <span>times</span> t less than or equal to T, there is no force applied, since the body is at position r=0, the force-free apex; and the mass is unaccelerated. </p><p>

<span>For</span>  <span>times</span> t &gt; T, there is a net force applied, since the body is at positions r&gt;0 not at the apex, the only force free point on the dome; and the mass accelerates in accord with F=ma.</p></div>


<p>But what of the crucial time t=T?  The solutions of (3) entail that the acceleration a(t) of the mass is given by</p>

<p>(4) &nbsp; &nbsp; &nbsp; a(t) = (1/12)(t-T)<sup>2</sup> for t greater than or equal to T<br>
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;= 0 for t less than or equal to T</p>

<p>We confirm by substitution into (3) that at t=T, the mass is still at the force-free apex r=0 and, by substitution into (4), that the mass has an acceleration a(0) of zero.  This is <span>just what Newton's first law demands</span>.  At t=T, there is no force and the mass is unaccelerated.  At any t&gt;T, there is a nonzero force and the mass is accelerated accordingly.</p>

<h2>No first instant of motion--no initiating cause</h2>

<p>Why is it so <span>easy to be confused</span> by this application of Newtonian mechanics?  Our natural causal instinct is to seek the first instant at which the mass moves and then look for the cause of the motion at that instant.  We are tempted to think of  the  instant t=T as the first instant at which the mass moves.  But that is not so.  It is the last instant at which the mass does not move.  There is no first instant at which the mass moves.  The mass moves during the interval t&gt;T only and this time interval has no first instant.  (Any candidate first instant in t&gt;T, say t=T+epsilon for any epsilon&gt;0, will be preceded by an earlier one, t=T+epsilon/2, still in t&gt;T.)  So there is no first instant of motion and thus no first instant at which to seek the initiating cause.</p>

<h2>Still not happy?</h2>

<div><p>There is <span>a simple way to see</span> that the spontaneous motion of the mass is actually not that strange.  Instead of imagining the mass starting at rest at the apex of the dome, we will imagine it starting at the rim and that we give it some initial velocity directed exactly at the apex.  If we give it too much initial velocity, it will pass right over the apex to the other side of the dome.  So let us give it a smaller initial velocity. We produce the trajectory T1:</p><p>

<img src="https://sites.pitt.edu/~jdnorton/Goodies/Dome/reversed_near.gif" width="594" height="258"></p><p>

Failed trajectory T1</p><p>

The mass rises towards the apex, but before it arrives it loses its motion, momentarily halts and then falls back to the rim. </p></div>

<div><p>So we give it <span>a little more</span> initial velocity to produce trajectory T2: </p><p>

<img src="https://sites.pitt.edu/~jdnorton/Goodies/Dome/reversed_nearer.gif" width="594" height="258"></p><p>

Failed trajectory T2</p><p>

The mass rises closer to the apex but does not reach it before momentarily halting and falling back.
</p></div>


<div><p>We continue this process until we give the mass <span>just the right</span> initial velocity so that it rises up and momentarily halts exactly at the apex:</p><p>

<img src="https://sites.pitt.edu/~jdnorton/Goodies/Dome/reversed_complete.gif" width="594" height="286"></p><p>

The trajectory is just right.</p><p>

In this last case, we have ended up with the mass momentarily at rest at the one force free point on the dome, the one point where, if it is at rest, the mass can (but need not) remain at rest.  So let us imagine that it does remain at rest once it arrives.  We now have a trajectory in which the mass rises up to the apex, halts there and remains there at rest for any arbitrary time period we care to nominate. <span><a href="#Note 9">See note 9.</a></span></p></div>


<p>An important feature of Newtonian mechanics is that it is <span>time reversible</span>, or at least that the dynamics of gravitational systems invoked here are time reversible.  This means that we can take any motion allowed by Newton's theory and generate another just by imagining that motion run in reverse in time.  So let us do that with the motion we have just generated.  That reversed motion corresponds to a mass that remains at rest at the apex of the dome for some arbitrary time period and then spontaneously moves off towards the rim.  And that is just a qualitative description of one of the solutions of (3).</p>

<p>This time-reversal trick is powerful, but we must be cautious not to overrate it.  It is best used just to make the acausal behavior plausible, while the proper mathematical analysis of (1), (3), and (4) proves it.  The reason is that there is a <span>loophole</span>.  The spontaneous motion can happen only on domes of the right shape, such as those of Figure 1a.  It cannot happen on others such as a hemispherical dome.  The time-reversal argument fails for these other cases, for a reason that is easy to overlook.  As we proceed through the trajectories T1, T2, ... on a hemispherical dome, the time taken for the mass to rise to its momentary halt increases without bound.  The final trajectory we seek, the one that momentarily halts at the apex, turns out to require infinite time.  This means that the mass never actually arrives.  Its time reverse displays a mass that has been in motion at all past times, without any spontaneous launches.  The corresponding time for the dome of Figure 1a, however, is finite, so the analysis does succeed for this case.</p>

<h2>Notes</h2>

<p><a name="Note 6"><span>6.</span> By direct computation, d<sup>2</sup>r/dt<sup>2</sup>=(1/12)(t-T)<sup>2</sup>=[(1/144)(t-T)<sup>4</sup>]<sup>1/2</sup> for t greater than or equal to T and 0 otherwise; so that d<sup>2</sup>r/dt<sup>2</sup>=r<sup>1/2</sup>.</a>
</p>

<p><a name="Note 7"><span>7.</span> Since all excitation times T would have to be equally probable, the probability that the time is in each of the infinitely many time intervals, (0,1), (1,2), (2,3), (3,4), ... would have to be the same, so that zero probability must be assigned to each of these intervals.  Summing over all intervals, this distribution entails a zero probability of excitation ever happening.
</a></p>

<p><a name="Note 8"><span>8.</span> For example, consider the natural condition that, at any time t, we always have the same probability of no excitation occurring over the next (arbitrarily chosen but fixed) time interval delta-t, given that no excitation has occurred by the start of that time interval.  This condition uniquely picks out the exponential decay rule P(t)=exp( - t/tau) where P(t) is the probability of no excitation over the time interval (0,t) and tau is some positive time constant.  (At any time t, the probability of excitation in the ensuing time interval delta-t is just exp( - (t+delta-t)/tau)/exp( - t/tau)=exp( - delta-t/tau), which is independent of t as required.) The problem is that the dynamics of excitation is governed by the magnitude of the time constant tau, which is the mean time to excitation.  A small tau means that we likely will have rapid excitation; a large tau means we will not. Nothing in the physical setup of the dome and mass enables us to fix a value for tau  We must fix its value by arbitrary stipulation, thereby inventing the new physical property of rate of decay, which is not inherent in the original physical system.</a></p>


<p><a name="Note 9"><span>9.</span> In an analogous analysis, we consider trajectories with too much initial velocity, so that the mass reaches the apex with some non-zero velocity and passes over it.  We reduce the initial velocity until the velocity at the apex is zero and then proceed as in the first analysis.</a>
</p>

<p><span>Copyright  John D. Norton, June 2, 2005. Parts of code re-entered May 2, 2012 to eliminate Dreamweaver bug.</span></p>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mortality patterns for patients hospitalized during cardiology meetings (2016) (105 pts)]]></title>
            <link>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4314435/</link>
            <guid>37012185</guid>
            <pubDate>Sat, 05 Aug 2023 14:12:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4314435/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4314435/</a>, See on <a href="https://news.ycombinator.com/item?id=37012185">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content">
    <article>
        <section>
         
    <ul>
            
                <li>
                    <a href="https://www.ncbi.nlm.nih.gov/pmc/journals/">Journal List</a>
                </li>
            
                <li>
                    <a href="https://www.ncbi.nlm.nih.gov/pmc/?term=hhs%20author%20manuscript[filter]">HHS Author Manuscripts</a>
                </li>
            
                <li aria-current="page">
                    PMC4314435
                </li>
            
    </ul>
 

        </section>
        
  

        
        <div data-jigconfig="smoothScroll: false, allHeadingLevels: ['h2'], headingExclude: ':hidden,.nomenu'" id="mc" role="document"><div><div><p><span id="pmcmata">JAMA Intern Med.</span> Author manuscript; available in PMC 2016 Feb 1.</p><p><em>Published in final edited form as:</em></p></div><div><p><span>PMCID: </span><span>PMC4314435</span></p><p><span>NIHMSID: </span><span>NIHMS651529</span></p></div></div><div id="abstract-1" lang="en"><h2 id="abstract-1title">Abstract</h2><!--article-meta--><div><div id="S1"><h3 id="S1title">IMPORTANCE</h3><p id="P1">Thousands of physicians attend scientific meetings annually. Although hospital physician staffing and composition may be affected by meetings, patient outcomes and treatment patterns during meeting dates are unknown.</p></div><div id="S2"><h3 id="S2title">OBJECTIVE</h3><p id="P2">To analyze mortality and treatment differences among patients admitted with acute cardiovascular conditions during dates of national cardiology meetings compared with nonmeeting dates.</p></div><div id="S3"><h3 id="S3title">DESIGN, SETTING, AND PARTICIPANTS</h3><p id="P3">Retrospective analysis of 30-day mortality among Medicare beneficiaries hospitalized with acute myocardial infarction (AMI), heart failure, or cardiac arrest from 2002 through 2011 during dates of 2 national cardiology meetings compared with identical nonmeeting days in the 3 weeks before and after conferences (AMI, 8570 hospitalizations during 82 meeting days and 57 471 during 492 nonmeeting days; heart failure, 19 282 during meeting days and 11 4591 during nonmeeting days; cardiac arrest, 1564 during meeting days and 9580 during nonmeeting days). Multivariable analyses were conducted separately for major teaching hospitals and nonteaching hospitals and for low-and high-risk patients. Differences in treatment utilization were assessed.</p></div><div id="S4"><h3 id="S4title">EXPOSURES</h3><p id="P4">Hospitalization during cardiology meeting dates.</p></div><div id="S5"><h3 id="S5title">MAIN OUTCOMES AND MEASURES</h3><p id="P5">Thirty-day mortality, procedure rates, charges, length of stay.</p></div><div id="S6"><h3 id="S6title">RESULTS</h3><p id="P6">Patient characteristics were similar between meeting and nonmeeting dates. In teaching hospitals, adjusted 30-day mortality was lower among high-risk patients with heart failure or cardiac arrest admitted during meeting vs nonmeeting dates (heart failure, 17.5% [95% CI, 13.7%–21.2%] vs 24.8% [95% CI, 22.9%–26.6%]; <em>P</em> &lt; .001; cardiac arrest, 59.1% [95% CI, 51.4%–66.8%] vs 69.4% [95% CI, 66.2%–72.6%]; <em>P</em> = .01). Adjusted mortality for high-risk AMI in teaching hospitals was similar between meeting and nonmeeting dates (39.2% [95% CI, 31.8%–46.6%] vs 38.5% [95% CI, 35.0%–42.0%]; <em>P</em> = .86), although adjusted percutaneous coronary intervention (PCI) rates were lower during meetings (20.8% vs 28.2%; <em>P</em> = .02). No mortality or utilization differences existed for low-risk patients in teaching hospitals or high- or low-risk patients in nonteaching hospitals. In sensitivity analyses, cardiac mortality was not affected by hospitalization during oncology, gastroenterology, and orthopedics meetings, nor was gastrointestinal hemorrhage or hip fracture mortality affected by hospitalization during cardiology meetings.</p></div><div id="S7"><h3 id="S7title">CONCLUSIONS AND RELEVANCE</h3><p id="P7">High-risk patients with heart failure and cardiac arrest hospitalized in teaching hospitals had lower 30-day mortality when admitted during dates of national cardiology meetings. High-risk patients with AMI admitted to teaching hospitals during meetings were less likely to receive PCI, without any mortality effect.</p></div></div></div><div id="body-1"><p id="P8">Each year, thousands of physicians attend national scientific meetings. In 2006, for example, nearly 19 000 cardiologists and other health care professionals attended the American Heart Association (AHA) annual meeting,<sup><a href="#R1" rid="R1">1</a></sup> with numbers declining to approximately 16 000 and 13 000 by 2009 and 2013, respectively.<sup><a href="#R2" rid="R2">2</a></sup> A similar number of cardiologists and other professionals attend the American College of Cardiology (ACC) annual meetings.<sup><a href="#R3" rid="R3">3</a></sup> During conferences, physician staffing in hospitals may be lower than on nonmeeting dates, and the composition of physicians who remain to treat patients—rather than those who attend the meetings—may be different. These factors may affect treatment practices and outcomes for hospitalized patients.</p><p id="P9">Hospitalized patient outcomes during dates of scientific meetings are unknown but of interest, considering that adverse patient outcomes and delays in care have been associated with reducing staffing during off-hour and weekend hospitalizations.<sup><a href="#R4" rid="R4">4</a>–<a href="#R9" rid="R9">9</a></sup> In contrast to these studies, however, comparisons of patient outcomes during dates of scientific meetings vs identical days in surrounding weeks may be more likely to isolate the effect of declines in physician staffing rather than the composite effect of declines in overall staffing (eg, nurses and other clinicians) that also occur on weekends and off-hours. Aside from differences in staffing levels, differences in the composition of physicians who remain to treat hospitalized patients during scientific meeting dates may also influence outcomes and treatment utilization.</p><p id="P10">We investigated differences in 30-day mortality among all Medicare fee-for-service beneficiaries who were hospitalized with acute myocardial infarction (AMI), heart failure, or cardiac arrest from 2002 to 2011 during the dates of 2 national cardiology meetings compared with identical nonmeeting days before and after conferences. We focused on conditions that are acute in nature rather than elective, to minimize the possibility that patients delayed care until after the meetings. We examined mortality differences separately for patients admitted to teaching and nonteaching hospitals and for low- and high-risk patients. We investigated whether rates of specific treatments (eg, percutaneous coronary intervention [PCI] and mechanical circulatory support), length of stay (LOS), and hospital charges varied between meeting and nonmeeting dates. We hypothesized that mortality would be higher and treatment utilization lower during cardiology meeting dates. We hypothesized that differences in outcomes would be largest in teaching hospitals, where a disproportionately larger fraction of cardiologists may attend cardiology meetings.</p></div><div id="S8"><h2 id="S8title">Methods</h2><div id="S9"><h3 id="S9title">Data Sources</h3><p id="P11">We used the Medicare Provider Analysis Review 20% files to identify hospitalizations from January 1, 2002, through November 31, 2011, with a primary diagnosis of AMI, heart failure, or cardiac arrest among Medicare fee-for-service beneficiaries 65 years or older. Patients with AMI and heart failure were identified according to <em>International Classification of Diseases, Ninth Revision (ICD-9)</em> criteria in the Agency for Health Care Research and Quality (AHRQ) Inpatient Quality Indicators,<sup><a href="#R10" rid="R10">10</a></sup> while patients with cardiac arrest were identified by <em>ICD-9</em> primary diagnosis code 427.5. December 2011 discharges were excluded to allow 30-day postadmission follow-up. We used American Hospital Association annual surveys to identify major teaching hospitals based on a ratio of resident physicians per bed of greater than 0.60.<sup><a href="#R11" rid="R11">11</a>–<a href="#R13" rid="R13">13</a></sup> The study was exempt from human subjects review at the University of Southern California.</p></div><div id="S10"><h3 id="S10title">Study Sample</h3><p id="P12">Calendar dates for scientific sessions at 2 national cardiology meetings—the AHA and ACC annual meetings—were obtained for each year from 2002 to 2011. We identified all hospitalizations for AMI, heart failure, or cardiac arrest for which the admission dates were during the dates of these meetings (exposure group), as well as all admissions during identical days in the 3 weeks before and after the meetings (control group). For example, for the 2005 ACC meetings held Sunday, March 6, to Wednesday, March 9, the control group consisted of patients admitted Sunday through Wednesday in the 3weeks before and after the meetings. Our final sample for all hospitals consisted of 8570 AMI hospitalizations during meeting dates and 57 471 hospitalizations during nonmeeting dates; 19 282 heart failure hospitalizations during meetings and 11 4591 during nonmeeting dates; and 1564 cardiac arrest hospitalizations during meetings and 9580 during nonmeeting dates. To assess whether hospitalizations for other cardiovascular conditions declined during meeting dates, we also examined the distribution between meeting and nonmeeting dates of total cardiovascular hospitalizations excluding AMI, heart failure, and cardiac arrest, identified according to AHRQ clinical classification codes 96 to 108.</p></div><div id="S11"><h3 id="S11title">Outcome Measures</h3><p id="P13">Our primary outcome was risk-adjusted all-cause 30-day mortality after admission for AMI, heart failure, or cardiac arrest among patients admitted during meeting vs nonmeeting dates. Because outcomes and treatment patterns during meeting and nonmeeting dates may be different for patients at low vs high predicted risk of inpatient mortality, we used a validated AHRQ risk adjustment tool to identify low- vs high-risk patients with AMI or heart failure.<sup><a href="#R10" rid="R10">10</a></sup> Patients with cardiac arrest were defined as high-risk.<sup><a href="#R14" rid="R14">14</a></sup> The AHRQ tool includes risk parameters for patient age, race, sex, and relevant diagnosis codes that have been estimated from national AMI and heart failure hospital discharge data. These preestimated risk coefficients can be applied to other claims-based data to predict patient-level inpatient mortality. Based on existing studies, a priori, we defined patients dichotomously to be at high risk after AMI or heart failure if their predicted mortality was in the top quartile for the respective disease and at low risk if their predicted mortality was in the bottom 3 quartiles.<sup><a href="#R13" rid="R13">13</a>,<a href="#R15" rid="R15">15</a></sup> We conducted sensitivity analysis around these risk categorizations.</p><p id="P14">We also examined whether specific treatment rates varied between meeting and nonmeeting dates. For AMI, we estimated rates of PCI (<em>ICD-9</em> procedure codes 00.66, 36.01, 36.02, 36.05, 36.06, 36.07, 36.09),<sup><a href="#R16" rid="R16">16</a></sup> mechanical circulatory support (defined as intra-aortic balloon pump counterpulsation, code 37.61, or percutaneous ventricular assist device, codes 37.60, 37.62, 37.65, 37.66, 37.68), and coronary artery bypass grafting (CABG) (codes 36.10–36.19). For heart failure, we estimated rates of diagnostic catheterization of the right side of the heart or invasive hemodynamic monitoring with tailored therapy (codes 37.21, 89.63, 89.64, 89.66-68) and CABG.<sup><a href="#R17" rid="R17">17</a></sup> For cardiac arrest, we estimated rates of PCI and CABG. For all conditions, we investigated whether LOS and hospital charges varied between meeting and nonmeeting dates.</p></div><div id="S12"><h3 id="S12title">Statistical Analysis</h3><p id="P15">We first compared patient characteristics between meeting and nonmeeting dates, including patient age, sex, race, chronic comorbidities recorded in medical claims prior to the admission, and mortality predicted by the AHRQ tool. We accounted for correlation in characteristics across patients within hospitals by clustering standard errors at the hospital level. We also compared unadjusted 30-day mortality among low- and high-risk patients admitted with AMI or heart failure and patients admitted with cardiac arrest during meeting vs nonmeeting dates, again clustering standard errors at the hospital level. We then estimated a patient-level multivariable logistic model with hospital random effects that adjusted for the patient characteristics listed herein; for each disease, we reported adjusted 30-day mortality among patients admitted during meeting and nonmeeting dates. We conducted analyses separately for major teaching hospitals and nonteaching hospitals, since a larger proportion of cardiologists in major teaching hospitals may attend national cardiology meetings compared with nonteaching hospitals. For example, among attendees surveyed during the 2014 ACC meetings, approximately 41% reported a primary activity including medical research or medical teaching.<sup><a href="#R18" rid="R18">18</a></sup></p><p id="P16">We also examined whether specific treatment rates, LOS, and hospital charges varied among low- and high-risk patients admitted during meeting and nonmeeting dates. For each treatment and condition, we estimated multivariable logistic random-effects models with the same covariates as our mortality models. For LOS and hospital charges, both of which are continuous variables, we estimated multivariable linear regression models. We reported adjusted treatment rates, LOS, and hospital charges among patients admitted during meeting and nonmeeting dates.</p><p id="P17">The 95% confidence intervals around reported means reflects 0.025 in each tail. In all regression models, standard errors were clustered at the hospital level.</p></div><div id="S13"><h3 id="S13title">Sensitivity Analyses</h3><p id="P18">We performed several sensitivity analyses. To assess for confounding in 30-day mortality among patients hospitalized during meeting vs nonmeeting dates, we conducted a set of falsification analyses.<sup><a href="#R19" rid="R19">19</a>–<a href="#R21" rid="R21">21</a></sup> First, we examined whether 30-day mortality differences were present among patients admitted during dates of national gastroenterology (Digestive Disease Week), oncology (American Society of Clinical Oncology), and orthopedic (American Association of Orthopedic Surgery) meetings vs nonmeeting dates. We also examined whether differences in 30-day mortality after hospitalization for hip fracture or gastrointestinal tract hemorrhage existed among patients with these conditions admitted during meeting vs nonmeeting dates; hospitalizations were identified according to <em>ICD-9</em> criteria in the AHRQ inpatient quality indicators.<sup><a href="#R10" rid="R10">10</a></sup> In either analysis, associations between 30-day mortality and hospitalization during meeting dates would suggest unmeasured confounding. Second, we considered alternative definitions of our control group (2 or 4 weeks surrounding meeting dates rather than 3 weeks) and alternative definitions of high risk (top tercile or quintile in AMI or heart failure rather than top quartile of predicted mortality). Third, we estimated models with hospital fixed effects to examine whether our results were driven by patients preferentially being admitted to specific hospitals during meeting vs nonmeeting dates (eg, hospitals of higher quality during meeting dates). Fourth, we considered 90-day mortality to explore longer-term effects. Fifth, we controlled for the hospital’s US Census Bureau division and size (number of medical and surgical adult beds from American Hospital Association surveys) in our analyses. Finally, we considered alternative model specifications (generalized linear model with log-link Poisson) for analyses of hospital charges and LOS, to better reflect skewness in these variables.</p></div></div><div id="S14"><h2 id="S14title">Results</h2><div id="S15"><h3 id="S15title">Patient Characteristics During Meeting and Nonmeeting Dates</h3><p id="P19">Between meeting and nonmeeting dates, patients in the overall sample had similar demographic characteristics and existing medical conditions (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4314435/table/T1/" target="table" rid-figpopup="T1" rid-ob="ob-T1" co-legend-rid=""><span>Table 1</span></a>). Patients with AMI and heart failure admitted on meeting vs nonmeeting dates also had comparable predicted inpatient mortality based on the AHRQ risk tool (AMI, 11.8% vs 11.6%; <em>P</em> = .08; heart failure, 5.0% vs 5.0%; <em>P</em> = .28). Patient characteristics were also similar between meeting and nonmeeting dates for high-risk patients admitted to teaching hospitals (<a href="#SD1" rid="SD1">eTable 1 in the Supplement</a>) and nonteaching hospitals (<a href="#SD1" rid="SD1">eTable 2 in the Supplement</a>) and for low-risk patients admitted to teaching hospitals (<a href="#SD1" rid="SD1">eTable 3 in the Supplement</a>) and nonteaching hospitals (<a href="#SD1" rid="SD1">eTable 4 in the Supplement</a>).</p><!--table ft1--><!--table-wrap mode="anchored" t5--><div id="T1"><h3>Table 1</h3><!--caption a7--><p id="P48">Characteristics of Patients Hospitalized With Acute Myocardial Infarction, Heart Failure, or Cardiac Arrest During Dates of 2 National Cardiology Meetings<sup>a</sup></p><div><table><thead><tr><th rowspan="2" colspan="1">Characteristics of<br>Patient Sample</th><th colspan="3" rowspan="1">Acute Myocardial Infarction</th><th colspan="3" rowspan="1">Heart Failure</th><th colspan="3" rowspan="1">Cardiac Arrest</th></tr><tr><th rowspan="1" colspan="1">Meeting<br>Dates</th><th rowspan="1" colspan="1">Nonmeeting<br>Dates</th><th rowspan="1" colspan="1"><em>P</em> Value</th><th rowspan="1" colspan="1">Meeting<br>Dates</th><th rowspan="1" colspan="1">Nonmeeting<br>Dates</th><th rowspan="1" colspan="1"><em>P</em> Value</th><th rowspan="1" colspan="1">Meeting<br>Dates</th><th rowspan="1" colspan="1">Nonmeeting<br>Dates</th><th rowspan="1" colspan="1"><em>P</em> Value</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">Patients, No.</td><td rowspan="1" colspan="1">8570</td><td rowspan="1" colspan="1">51 471</td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1">19 282</td><td rowspan="1" colspan="1">114 591</td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1">1564</td><td rowspan="1" colspan="1">9580</td><td rowspan="1" colspan="1"></td></tr><tr><td rowspan="1" colspan="1">Mean age, y</td><td rowspan="1" colspan="1">78.7</td><td rowspan="1" colspan="1">78.8</td><td rowspan="1" colspan="1">.52</td><td rowspan="1" colspan="1">80.1</td><td rowspan="1" colspan="1">80.0</td><td rowspan="1" colspan="1">.33</td><td rowspan="1" colspan="1">78.3</td><td rowspan="1" colspan="1">78.4</td><td rowspan="1" colspan="1">.62</td></tr><tr><td rowspan="1" colspan="1">Male</td><td rowspan="1" colspan="1">50.7</td><td rowspan="1" colspan="1">50.1</td><td rowspan="1" colspan="1">.22</td><td rowspan="1" colspan="1">43.2</td><td rowspan="1" colspan="1">42.9</td><td rowspan="1" colspan="1">.41</td><td rowspan="1" colspan="1">49.5</td><td rowspan="1" colspan="1">49.8</td><td rowspan="1" colspan="1">.83</td></tr><tr><td rowspan="1" colspan="1">Race</td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;White</td><td rowspan="1" colspan="1">87.5</td><td rowspan="1" colspan="1">86.7</td><td rowspan="1" colspan="1">.04</td><td rowspan="1" colspan="1">81.1</td><td rowspan="1" colspan="1">81.2</td><td rowspan="1" colspan="1">.82</td><td rowspan="1" colspan="1">81.1</td><td rowspan="1" colspan="1">80.4</td><td rowspan="1" colspan="1">.53</td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Black</td><td rowspan="1" colspan="1">8.3</td><td rowspan="1" colspan="1">8.8</td><td rowspan="1" colspan="1">.12</td><td rowspan="1" colspan="1">14.3</td><td rowspan="1" colspan="1">14.3</td><td rowspan="1" colspan="1">.87</td><td rowspan="1" colspan="1">14.1</td><td rowspan="1" colspan="1">14.1</td><td rowspan="1" colspan="1">.99</td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Hispanic</td><td rowspan="1" colspan="1">1.6</td><td rowspan="1" colspan="1">1.7</td><td rowspan="1" colspan="1">.41</td><td rowspan="1" colspan="1">2.2</td><td rowspan="1" colspan="1">2.1</td><td rowspan="1" colspan="1">.49</td><td rowspan="1" colspan="1">1.6</td><td rowspan="1" colspan="1">2.0</td><td rowspan="1" colspan="1">.20</td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Asian or Pacific Islander</td><td rowspan="1" colspan="1">0.8</td><td rowspan="1" colspan="1">1.0</td><td rowspan="1" colspan="1">.18</td><td rowspan="1" colspan="1">0.9</td><td rowspan="1" colspan="1">0.8</td><td rowspan="1" colspan="1">.64</td><td rowspan="1" colspan="1">1.5</td><td rowspan="1" colspan="1">1.4</td><td rowspan="1" colspan="1">.66</td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Other</td><td rowspan="1" colspan="1">1.9</td><td rowspan="1" colspan="1">1.9</td><td rowspan="1" colspan="1">.76</td><td rowspan="1" colspan="1">1.5</td><td rowspan="1" colspan="1">1.6</td><td rowspan="1" colspan="1">.39</td><td rowspan="1" colspan="1">1.7</td><td rowspan="1" colspan="1">2.0</td><td rowspan="1" colspan="1">.34</td></tr><tr><td rowspan="1" colspan="1">Preexisting comorbidities</td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Ischemic heart disease</td><td rowspan="1" colspan="1">68.9</td><td rowspan="1" colspan="1">68.8</td><td rowspan="1" colspan="1">.88</td><td rowspan="1" colspan="1">83.3</td><td rowspan="1" colspan="1">83.5</td><td rowspan="1" colspan="1">.52</td><td rowspan="1" colspan="1">66.8</td><td rowspan="1" colspan="1">69.4</td><td rowspan="1" colspan="1">.04</td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Dementia</td><td rowspan="1" colspan="1">17.8</td><td rowspan="1" colspan="1">18.4</td><td rowspan="1" colspan="1">.20</td><td rowspan="1" colspan="1">22.6</td><td rowspan="1" colspan="1">22.9</td><td rowspan="1" colspan="1">.41</td><td rowspan="1" colspan="1">25.2</td><td rowspan="1" colspan="1">24.4</td><td rowspan="1" colspan="1">.47</td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Atrial fibrillation</td><td rowspan="1" colspan="1">19.7</td><td rowspan="1" colspan="1">18.6</td><td rowspan="1" colspan="1">.01</td><td rowspan="1" colspan="1">45.0</td><td rowspan="1" colspan="1">44.8</td><td rowspan="1" colspan="1">.61</td><td rowspan="1" colspan="1">28.9</td><td rowspan="1" colspan="1">28.5</td><td rowspan="1" colspan="1">.73</td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Chronic kidney disease</td><td rowspan="1" colspan="1">27.3</td><td rowspan="1" colspan="1">27.4</td><td rowspan="1" colspan="1">.91</td><td rowspan="1" colspan="1">48.4</td><td rowspan="1" colspan="1">48.7</td><td rowspan="1" colspan="1">.39</td><td rowspan="1" colspan="1">34.5</td><td rowspan="1" colspan="1">37.3</td><td rowspan="1" colspan="1">.03</td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Diabetes mellitus</td><td rowspan="1" colspan="1">42.8</td><td rowspan="1" colspan="1">42.7</td><td rowspan="1" colspan="1">.94</td><td rowspan="1" colspan="1">55.2</td><td rowspan="1" colspan="1">55.4</td><td rowspan="1" colspan="1">.62</td><td rowspan="1" colspan="1">45.1</td><td rowspan="1" colspan="1">46.7</td><td rowspan="1" colspan="1">.25</td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;COPD</td><td rowspan="1" colspan="1">32.9</td><td rowspan="1" colspan="1">33.2</td><td rowspan="1" colspan="1">.68</td><td rowspan="1" colspan="1">52.4</td><td rowspan="1" colspan="1">52.9</td><td rowspan="1" colspan="1">.19</td><td rowspan="1" colspan="1">42.3</td><td rowspan="1" colspan="1">43.7</td><td rowspan="1" colspan="1">.31</td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Heart failure</td><td rowspan="1" colspan="1">47.5</td><td rowspan="1" colspan="1">47.4</td><td rowspan="1" colspan="1">.93</td><td rowspan="1" colspan="1">84.0</td><td rowspan="1" colspan="1">84.2</td><td rowspan="1" colspan="1">.51</td><td rowspan="1" colspan="1">58.5</td><td rowspan="1" colspan="1">59.8</td><td rowspan="1" colspan="1">.35</td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Hyperlipidemia</td><td rowspan="1" colspan="1">64.3</td><td rowspan="1" colspan="1">64.9</td><td rowspan="1" colspan="1">.26</td><td rowspan="1" colspan="1">70.7</td><td rowspan="1" colspan="1">70.6</td><td rowspan="1" colspan="1">.75</td><td rowspan="1" colspan="1">60.4</td><td rowspan="1" colspan="1">62.3</td><td rowspan="1" colspan="1">.15</td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Hypertension</td><td rowspan="1" colspan="1">79.8</td><td rowspan="1" colspan="1">80.4</td><td rowspan="1" colspan="1">.22</td><td rowspan="1" colspan="1">90.9</td><td rowspan="1" colspan="1">90.9</td><td rowspan="1" colspan="1">.91</td><td rowspan="1" colspan="1">82.9</td><td rowspan="1" colspan="1">84.5</td><td rowspan="1" colspan="1">.14</td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Cancer</td><td rowspan="1" colspan="1">14.5</td><td rowspan="1" colspan="1">14.8</td><td rowspan="1" colspan="1">.59</td><td rowspan="1" colspan="1">16.5</td><td rowspan="1" colspan="1">16.9</td><td rowspan="1" colspan="1">.16</td><td rowspan="1" colspan="1">17.1</td><td rowspan="1" colspan="1">18.2</td><td rowspan="1" colspan="1">.27</td></tr><tr><td rowspan="1" colspan="1">Hospitalized at a teaching hospital</td><td rowspan="1" colspan="1">10.4</td><td rowspan="1" colspan="1">10.4</td><td rowspan="1" colspan="1">.89</td><td rowspan="1" colspan="1">9.3</td><td rowspan="1" colspan="1">9.2</td><td rowspan="1" colspan="1">.65</td><td rowspan="1" colspan="1">10.6</td><td rowspan="1" colspan="1">10.2</td><td rowspan="1" colspan="1">.57</td></tr><tr><td rowspan="1" colspan="1">AHRQ predicted mortality, mean</td><td rowspan="1" colspan="1">11.8</td><td rowspan="1" colspan="1">11.6</td><td rowspan="1" colspan="1">.08</td><td rowspan="1" colspan="1">5.0</td><td rowspan="1" colspan="1">5.0</td><td rowspan="1" colspan="1">.28</td><td rowspan="1" colspan="1">NA</td><td rowspan="1" colspan="1">NA</td><td rowspan="1" colspan="1">NA</td></tr></tbody></table></div></div><p id="P20">For each condition, hospitalizations were evenly distributed between meeting and nonmeeting dates, suggesting that hospitalizations were not simply delayed until after meetings (<a href="#SD1" rid="SD1">eTable 5 in the Supplement</a>). For example, because the control group was defined as patients admitted during identical days in the 3-week periods before and after meeting dates, an even distribution between meeting and nonmeeting dates would imply a ratio of hospitalizations of approximately 1:6. In the full sample, the ratio of hospitalizations between meeting and nonmeeting dates was 1:6.0 for AMI, 1:6.0 for heart failure, and 1:6.1 for cardiac arrest. Similar ratios were observed for both low- and high-risk patients in teaching and nonteaching hospitals (<a href="#SD1" rid="SD1">eTable 5 in the Supplement</a>). Overall cardiovascular hospitalizations were also evenly distributed evenly between meeting and nonmeeting dates, suggesting no decline in less urgent hospitalizations during meeting dates (<a href="#SD1" rid="SD1">eTable 5 in the Supplement</a>).</p></div><div id="S16"><h3 id="S16title">Mortality During Meeting and Nonmeeting Dates</h3><p id="P21">Unadjusted 30-day mortality was lower among patients with high-risk heart failure or cardiac arrest admitted to major teaching hospitals during meeting vs nonmeeting dates (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4314435/table/T2/" target="table" rid-figpopup="T2" rid-ob="ob-T2" co-legend-rid=""><span>Table 2</span></a>). For example, in teaching hospitals, of 388 high-risk patients admitted with heart failure during meeting dates, 66 (17.0%) died within 30 days compared with 535 of 2154 (24.8%) admitted on nonmeeting dates (<em>P</em> &lt; .001). Similarly, 98 of 166 patients (59.0%) admitted to teaching hospitals with cardiac arrest during meeting dates died within 30 days compared with 669 of 975 (68.6%) on nonmeeting dates (<em>P</em> = .02). Unadjusted mortality among high-risk patients with AMI admitted to teaching hospitals was similar on meeting and nonmeeting dates (40.4% vs 38.2%;<em>P</em> = .54). There was no difference in mortality among low-risk patients with AMI or heart failure admitted to teaching hospitals during meeting vs nonmeeting dates.</p><!--table ft1--><!--table-wrap mode="anchored" t5--><div id="T2"><h3>Table 2</h3><!--caption a7--><p id="P51">Unadjusted 30-Day Mortality Among Patients Admitted for Acute Myocardial Infarction, Heart Failure, or Cardiac Arrest During Dates of 2 National Cardiology Meetings</p><div><table><thead><tr><th rowspan="3" colspan="1">Conditions</th><th colspan="6" rowspan="1">Predicted Mortality Risk</th></tr><tr><th colspan="3" rowspan="1">Low</th><th colspan="3" rowspan="1">High</th></tr><tr><th rowspan="1" colspan="1">Meeting Dates</th><th rowspan="1" colspan="1">Nonmeeting Dates</th><th rowspan="1" colspan="1"><em>P</em> Value</th><th rowspan="1" colspan="1">Meeting Dates</th><th rowspan="1" colspan="1">Nonmeeting Dates</th><th rowspan="1" colspan="1"><em>P</em> Value</th></tr></thead><tbody><tr><td rowspan="1" colspan="1"><strong>Teaching Hospitals</strong></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td></tr><tr><td rowspan="1" colspan="1">Acute myocardial infarction</td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Patients, No.</td><td rowspan="1" colspan="1">710</td><td rowspan="1" colspan="1">4359</td><td rowspan="2" colspan="1">.36</td><td rowspan="1" colspan="1">178</td><td rowspan="1" colspan="1">1001</td><td rowspan="2" colspan="1">.54</td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;30-d mortality, No. (%)</td><td rowspan="1" colspan="1">55 (7.7)</td><td rowspan="1" colspan="1">385 (8.8)</td><td rowspan="1" colspan="1">72 (40.4)</td><td rowspan="1" colspan="1">382 (38.2)</td></tr><tr><td rowspan="1" colspan="1">Heart failure</td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Patients, No.</td><td rowspan="1" colspan="1">1410</td><td rowspan="1" colspan="1">8415</td><td rowspan="2" colspan="1">.82</td><td rowspan="1" colspan="1">388</td><td rowspan="1" colspan="1">2154</td><td rowspan="2" colspan="1">&lt;.001</td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;30-d Mortality, No. (%)</td><td rowspan="1" colspan="1">71 (5.0)</td><td rowspan="1" colspan="1">435 (5.2)</td><td rowspan="1" colspan="1">66 (17.0)</td><td rowspan="1" colspan="1">535 (24.8)</td></tr><tr><td rowspan="1" colspan="1">Cardiac arrest</td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Patients, No.</td><td rowspan="1" colspan="1">NA</td><td rowspan="1" colspan="1">NA</td><td rowspan="2" colspan="1">NA</td><td rowspan="1" colspan="1">166</td><td rowspan="1" colspan="1">975</td><td rowspan="2" colspan="1">.02</td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;30-d Mortality, No. (%)</td><td rowspan="1" colspan="1">NA</td><td rowspan="1" colspan="1">NA</td><td rowspan="1" colspan="1">98 (59.0)</td><td rowspan="1" colspan="1">669 (68.6)</td></tr><tr><td rowspan="1" colspan="1"><strong>Nonteaching Hospitals</strong></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td></tr><tr><td rowspan="1" colspan="1">Acute myocardial infarction</td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Patients, No.</td><td rowspan="1" colspan="1">6311</td><td rowspan="1" colspan="1">38 291</td><td rowspan="2" colspan="1">.06</td><td rowspan="1" colspan="1">1371</td><td rowspan="1" colspan="1">7820</td><td rowspan="2" colspan="1">.15</td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;30-d Mortality, No. (%)</td><td rowspan="1" colspan="1">659 (10.4)</td><td rowspan="1" colspan="1">4298 (11.2)</td><td rowspan="1" colspan="1">587 (42.8)</td><td rowspan="1" colspan="1">3181 (40.7)</td></tr><tr><td rowspan="1" colspan="1">Heart failure</td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Patients, No.</td><td rowspan="1" colspan="1">13 775</td><td rowspan="1" colspan="1">81 968</td><td rowspan="2" colspan="1">.02</td><td rowspan="1" colspan="1">3709</td><td rowspan="1" colspan="1">22 054</td><td rowspan="2" colspan="1">.66</td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;30-d Mortality, No. (%)</td><td rowspan="1" colspan="1">1045 (7.6)</td><td rowspan="1" colspan="1">5738 (7.0)</td><td rowspan="1" colspan="1">901 (24.3)</td><td rowspan="1" colspan="1">5432 (24.6)</td></tr><tr><td rowspan="1" colspan="1">Cardiac arrest</td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Patients, No.</td><td rowspan="1" colspan="1">NA</td><td rowspan="1" colspan="1">NA</td><td rowspan="2" colspan="1">NA</td><td rowspan="1" colspan="1">1398</td><td rowspan="1" colspan="1">8605</td><td rowspan="2" colspan="1">.14</td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;30-d Mortality, No. (%)</td><td rowspan="1" colspan="1">NA</td><td rowspan="1" colspan="1">NA</td><td rowspan="1" colspan="1">980 (70.1)</td><td rowspan="1" colspan="1">6197 (72.0)</td></tr></tbody></table></div></div><p id="P22">After covariate adjustment, 30-day mortality was lower among high-risk patients with heart failure or cardiac arrest admitted to teaching hospitals during meeting vs nonmeeting dates (heart failure, 17.5% [95% CI, 13.7%–21.2%] vs 24.8% [95% CI, 22.9%–26.6%]; <em>P</em> &lt; .001; cardiac arrest, 59.1% [95% CI, 51.4%–66.8%] vs 69.4% [95% CI, 66.2%–72.6%]; <em>P</em> = .01) (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4314435/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1" co-legend-rid="lgnd_F1"><span>Figure</span></a> and <a href="#SD1" rid="SD1">eTable 6 in the Supplement</a>). Adjusted mortality among high-risk patients with AMI admitted to teaching hospitals was similar between meeting and nonmeeting dates (39.2% [95% CI, 31.8%–46.6%] vs 38.5% [95% CI, 35.0%–42.0%]; <em>P</em> = .86).</p><!--fig ft0--><!--fig mode=article f1--><div id="F1" co-legend-rid="lgnd_F1"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4314435/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--></a><div data-largeobj="" data-largeobj-link-rid="largeobj_idm140208161399200"><a href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=4314435_nihms651529f1.jpg" target="tileshopwindow" rel="noopener"><img loading="lazy" alt="An external file that holds a picture, illustration, etc.
Object name is nihms651529f1.jpg" title="Click on image to zoom" src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4314435/bin/nihms651529f1.jpg"></a></div><div id="lgnd_F1"><p id="P46">Adjusted 30-Day Mortality Among Patients Admitted to Teaching Hospitals With Acute Myocardial Infarction, Heart Failure, or Cardiac Arrest During Dates of 2 National Cardiology Meetings</p><p id="P47">Error bars indicate 95%CIs.</p></div></div><p id="P23">Adjusted mortality did not differ between meeting and nonmeeting dates for low-risk patients in teaching hospitals (<a href="#SD1" rid="SD1">eTable 6 in the Supplement</a>). For example, among low-risk patients with heart failure in teaching hospitals, adjusted mortality during meeting and nonmeeting dates was 4.9% (95% CI, 3.7%–6.1%) and 4.9% (95% CI, 4.4%–5.5%), respectively (<em>P</em> = .93). Adjusted mortality also generally did not differ between meeting and nonmeeting dates for low- or high-risk patients in nonteaching hospitals (<a href="#SD1" rid="SD1">eTable 6 in the Supplement</a>). For example, adjusted mortality for high-risk patients with heart failure during meeting and nonmeeting dates was 24.6% (95% CI, 23.2%–26.0%) and 24.5% (95% CI, 24.0%–25.1%), respectively (<em>P</em> = .91).</p></div><div id="S17"><h3 id="S17title">Treatment Utilization Among High-Risk Patients Admitted to Teaching Hospitals During Meeting Dates</h3><p id="P24">Among high-risk patients with AMI admitted to teaching hospitals, adjusted PCI rates were significantly lower during meeting vs nonmeeting dates (20.8% [95% CI, 15.3%–26.3%] vs 28.2% [95% CI, 25.5%–30.8%]; <em>P</em> = .02; <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4314435/table/T3/" target="table" rid-figpopup="T3" rid-ob="ob-T3" co-legend-rid=""><span>Table 3</span></a>), while adjusted rates of mechanical circulatory support, CABG, LOS, and hospital charges did not vary. Among high-risk patients with heart failure admitted to teaching hospitals, adjusted rates of diagnostic catheterization of the right side of the heart or invasive hemodynamic monitoring with tailored therapy were generally low and did not vary between meeting and nonmeeting dates (2.2% [95% CI,0.8%–3.7%] vs 2.7% [95% CI, 1.8%–3.6%];<em>P</em> = .54), nor did LOS (8.2 vs 8.5 days; <em>P</em> = .43) or hospital charges ($50 779 vs $55 685; <em>P</em> = .17). Among patients with cardiac arrest admitted to teaching hospitals, adjusted rates of PCI, CABG, hospital charges, and LOS did not differ between meeting and nonmeeting dates.</p><!--table ft1--><!--table-wrap mode="anchored" t5--><div id="T3"><h3>Table 3</h3><!--caption a7--><p id="P53">Treatment Utilization Among High-Risk Patients Admitted to Teaching Hospitals for Acute Myocardial Infarction, Heart Failure, or Cardiac Arrest During Dates of 2 National Cardiology Meetings</p><div><table><thead><tr><th rowspan="2" colspan="1">Condition and<br>Treatment Utilization</th><th colspan="2" rowspan="1">Adjusted (95% CI)</th><th rowspan="2" colspan="1"><em>P</em> Value</th></tr><tr><th rowspan="1" colspan="1">Meeting Dates</th><th rowspan="1" colspan="1">Nonmeeting Dates</th></tr></thead><tbody><tr><td rowspan="1" colspan="1"><strong>Acute Myocardial Infarction</strong></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td></tr><tr><td rowspan="1" colspan="1">PCI, %</td><td rowspan="1" colspan="1">20.8 (15.3 to 26.3)</td><td rowspan="1" colspan="1">28.2 (25.5 to 30.8)</td><td rowspan="1" colspan="1">.02</td></tr><tr><td rowspan="1" colspan="1">Circulatory support, %<sup>a</sup></td><td rowspan="1" colspan="1">20.3 (14.5 to 26.1)</td><td rowspan="1" colspan="1">20.1 (17.3 to 22.8)</td><td rowspan="1" colspan="1">.93</td></tr><tr><td rowspan="1" colspan="1">CABG, %</td><td rowspan="1" colspan="1">11.3 (7.9 to 14.7)</td><td rowspan="1" colspan="1">8.6 (7.5 to 9.8)</td><td rowspan="1" colspan="1">.12</td></tr><tr><td rowspan="1" colspan="1">Hospital charges, $</td><td rowspan="1" colspan="1">92 611 (76 165 to 109 058)</td><td rowspan="1" colspan="1">88 562 (79 945 to 97 178)</td><td rowspan="1" colspan="1">.63</td></tr><tr><td rowspan="1" colspan="1">Length of stay, d</td><td rowspan="1" colspan="1">9.5 (8.1 to 10.9)</td><td rowspan="1" colspan="1">9.3 (8.8 to 9.8)</td><td rowspan="1" colspan="1">.77</td></tr><tr><td rowspan="1" colspan="1"><strong>Heart Failure</strong></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td></tr><tr><td rowspan="1" colspan="1">Catheterization or monitoring, %<sup>b</sup></td><td rowspan="1" colspan="1">2.2 (0.8 to 3.7)</td><td rowspan="1" colspan="1">2.7 (1.8 to 3.6)</td><td rowspan="1" colspan="1">.54</td></tr><tr><td rowspan="1" colspan="1">CABG, %</td><td rowspan="1" colspan="1">1.1 (−0.5 to 2.8)</td><td rowspan="1" colspan="1">0.6 (−0.1 to 1.2)</td><td rowspan="1" colspan="1">.32</td></tr><tr><td rowspan="1" colspan="1">Hospital charges, $</td><td rowspan="1" colspan="1">50 779 (42 329 to 59 228)</td><td rowspan="1" colspan="1">55 685 (49 011 to 62 358)</td><td rowspan="1" colspan="1">.17</td></tr><tr><td rowspan="1" colspan="1">Adjusted length of stay, d</td><td rowspan="1" colspan="1">8.2 (7.5 to 8.9)</td><td rowspan="1" colspan="1">8.5 (8.0 to 8.9)</td><td rowspan="1" colspan="1">.43</td></tr><tr><td rowspan="1" colspan="1"><strong>Cardiac Arrest</strong></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td></tr><tr><td rowspan="1" colspan="1">PCI, %</td><td rowspan="1" colspan="1">6.5 (2.7 to 10.4)</td><td rowspan="1" colspan="1">5.9 (3.8 to 8.0)</td><td rowspan="1" colspan="1">.75</td></tr><tr><td rowspan="1" colspan="1">CABG, %</td><td rowspan="1" colspan="1">3.1 (0.4 to 5.8)</td><td rowspan="1" colspan="1">2.3 (1.0 to 3.6)</td><td rowspan="1" colspan="1">.50</td></tr><tr><td rowspan="1" colspan="1">Hospital charges, $</td><td rowspan="1" colspan="1">112 716 (84 313 to 141 119)</td><td rowspan="1" colspan="1">86 322 (76 858 to 95 787)</td><td rowspan="1" colspan="1">.07</td></tr><tr><td rowspan="1" colspan="1">Length of stay, d</td><td rowspan="1" colspan="1">11.7 (9.2 to 14.3)</td><td rowspan="1" colspan="1">9.3 (8.3 to 10.3)</td><td rowspan="1" colspan="1">.07</td></tr></tbody></table></div></div></div><div id="S18"><h3 id="S18title">Sensitivity Analysis</h3><p id="P25">We found no evidence that unmeasured confounding explained lower mortality among high-risk patients with heart failure or cardiac arrest during meeting vs nonmeeting dates. Adjusted mortality rates among high-risk patients admitted to teaching hospitals with AMI, heart failure, or cardiac arrest were similar between national oncology, gastroenterology, and orthopedic meeting dates and identical days in weeks before and after conferences (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4314435/table/T4/" target="table" rid-figpopup="T4" rid-ob="ob-T4" co-legend-rid=""><span>Table 4</span></a>). Similarly, adjusted mortality among patients admitted with gastrointestinal tract hemorrhage or hip fracture was similar between cardiology meeting dates and noncardiology meeting dates (<a href="#SD1" rid="SD1">eTable 7 in the Supplement</a>). Our findings were also unaffected by alternative definitions of our control group (<a href="#SD1" rid="SD1">eTable 8 in the Supplement</a>); alternative definitions of high risk (<a href="#SD1" rid="SD1">eTable 9 in the Supplement</a>); the inclusion of hospital fixed effects to assess whether our results were driven by patients being preferentially admitted to higher-quality hospitals during meeting dates (<a href="#SD1" rid="SD1">eTable 10 in the Supplement</a>); the inclusion of hospital size and US Census division (<a href="#SD1" rid="SD1">eTable 11 in the Supplement</a>); and alternative model specifications of the hospital charge and LOS analyses (generalized linear model with log-link). The significant 30-day mortality differentials among high-risk patients treated in teaching hospitals were slightly smaller in magnitude at 90 days and trended toward significance (<a href="#SD1" rid="SD1">eTable 12 in the Supplement</a>).</p><!--table ft1--><!--table-wrap mode="anchored" t5--><div id="T4"><h3>Table 4</h3><!--caption a7--><p id="P57">Adjusted 30-Day Mortality Among Patients Admitted to Teaching Hospitals for Acute Myocardial Infarction, Heart Failure, or Cardiac Arrest During Dates of National Oncology, Gastroenterology, and Orthopedic Surgery Meetings</p><div><table><thead><tr><th rowspan="3" colspan="1">Condition</th><th colspan="6" rowspan="1">Predicted Mortality Risk</th></tr><tr><th colspan="3" rowspan="1">Low</th><th colspan="3" rowspan="1">High</th></tr><tr><th rowspan="1" colspan="1">Meeting Dates</th><th rowspan="1" colspan="1">Nonmeeting Dates</th><th rowspan="1" colspan="1"><em>P</em> Value</th><th rowspan="1" colspan="1">Dates</th><th rowspan="1" colspan="1">Nonmeeting Dates</th><th rowspan="1" colspan="1"><em>P</em> Value</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">Acute myocardial infarction</td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Patients, No.</td><td rowspan="1" colspan="1">1258</td><td rowspan="1" colspan="1">7272</td><td rowspan="2" colspan="1">.70</td><td rowspan="1" colspan="1">&nbsp;&nbsp;289</td><td rowspan="1" colspan="1">1581</td><td rowspan="2" colspan="1">.29</td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Adjusted 30-d mortality, % (95% CI)</td><td rowspan="1" colspan="1">7.8 (6.3–9.3)</td><td rowspan="1" colspan="1">8.1 (7.5–8.8)</td><td rowspan="1" colspan="1">40.9 (35.0–46.7)</td><td rowspan="1" colspan="1">37.6 (34.7–40.4)</td></tr><tr><td rowspan="1" colspan="1">Heart failure</td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Patients, No.</td><td rowspan="1" colspan="1">2604</td><td rowspan="1" colspan="1">14 286</td><td rowspan="2" colspan="1">.39</td><td rowspan="1" colspan="1">&nbsp;&nbsp;595</td><td rowspan="1" colspan="1">3531</td><td rowspan="2" colspan="1">.44</td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Adjusted 30-d mortality, % (95% CI)</td><td rowspan="1" colspan="1">5.1 (4.2–6.0)</td><td rowspan="1" colspan="1">5.5 (5.1–6.0)</td><td rowspan="1" colspan="1">24.8 (21.3–28.3)</td><td rowspan="1" colspan="1">23.4 (21.9–24.9)</td></tr><tr><td rowspan="1" colspan="1">Cardiac arrest</td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td><td rowspan="1" colspan="1"></td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Patients, No.</td><td rowspan="1" colspan="1">NA</td><td rowspan="1" colspan="1">NA</td><td rowspan="2" colspan="1">NA</td><td rowspan="1" colspan="1">&nbsp;&nbsp;315</td><td rowspan="1" colspan="1">1644</td><td rowspan="2" colspan="1">.61</td></tr><tr><td rowspan="1" colspan="1">&nbsp;&nbsp;Adjusted 30-d mortality, % (95% CI)</td><td rowspan="1" colspan="1">NA</td><td rowspan="1" colspan="1">NA</td><td rowspan="1" colspan="1">68.1 (62.5–73.6)</td><td rowspan="1" colspan="1">69.5 (66.6–72.4)</td></tr></tbody></table></div></div></div></div><div id="S19"><h2 id="S19title">Discussion</h2><p id="P26">We found substantially lower adjusted 30-day mortality among high-risk patients with heart failure or cardiac arrest admitted to major teaching hospitals during dates of national cardiology meetings. The PCI rates among high-risk patients with AMI admitted to major teaching hospitals were significantly lower during meetings, without any decrement to survival. We found no differences in mortality between meeting and nonmeeting dates for low-risk patients in teaching hospitals or for high- or low-risk patients in nonteaching hospitals.</p><p id="P27">Our mortality results for high-risk patients in teaching hospitals are unlikely to be explained by patients delaying care until after cardiology meetings, both because patients were observationally similar between meeting and nonmeeting dates and because hospitalizations for AMI, heart failure, and cardiac arrest were evenly distributed between meeting and nonmeeting dates. Moreover, we found no effect of gastroenterology, oncology, and orthopaedics meetings on cardiac mortality, nor did we find an effect of cardiology meetings on gastrointestinal tract hemorrhage or hip fracture mortality; both findings argue against unmeasured confounding.</p><p id="P28">Several explanations of our findings are possible. First, selective declines in cardiologist staffing, combined with changes in the composition of physicians who remain to treat hospitalized patients, may partly account for different outcomes. Cardiologists who remain at home while a conference is under way may be different than those who attend meetings. This factor may be particularly relevant at major teaching hospitals where a greater proportion of cardiologists may attend national meetings, and a specific rotation of physicians may provide coverage back home. If diagnostic and procedural capabilities of these physicians differ, physician compositional changes during meetings may result in differences in patient outcomes and treatment patterns.</p><p id="P29">Second, declines in intensity of care during meetings—driven either by changes in physician composition and practice styles, reluctance to perform interventions in patients whose primary cardiologist is unavailable, or reluctance of cardiologists to intervene in high-risk patients without adequate back-up—may produce mortality reductions among high-risk patients with cardiovascular disease if the usual interventions performed on these patients on nonmeeting dates are actually unnecessary. Interventions foregone during meeting dates are more likely to be those for which the risk-benefit tradeoff is less clear and may involve harms that outweigh benefits in high-risk patients. Our finding that substantially lower PCI rates for high-risk patients with AMI admitted to teaching hospitals during cardiology meetings are not associated with improved survival suggests potential overuse of PCI in this population. This interpretation is consistent with evidence that public reporting of PCI outcomes is associated with lower rates of PCI among high-risk patients with AMI, without any effect on mortality.<sup><a href="#R16" rid="R16">16</a></sup> More broadly, this interpretation may align with other studies of medical care which demonstrate that “less is more” for intensive care patients (eg, conservative transfusion thresholds for hospitalized patients with ischemic heart disease and anemia,<sup><a href="#R22" rid="R22">22</a></sup> conservative [rather than intensive] glucose regulation in patients with hyperglycemia with acute coronary syndrome treated with PCI,<sup><a href="#R23" rid="R23">23</a></sup> and abstinence from use of high-dose systemic corticosteroids in septic shock<sup><a href="#R24" rid="R24">24</a></sup>).</p><p id="P30">Third, declines in the volume of less urgent cardiovascular hospitalizations during meeting dates could allow physicians to focus greater attention on remaining high-risk patients, thereby improving outcomes. Although we found no evidence that total cardiovascular hospitalization volume declined during meeting dates, it is possible that rates of same-day elective procedures and outpatient visits may have declined, which could have the same positive effect on patient outcomes. To our knowledge, no studies exist on the association between daily patient workload and mortality among patients with cardiovascular disease, although in obstetrics, higher-than-predicted daily hospital birth volume has been associated with greater rates of neonatal asphyxia,<sup><a href="#R25" rid="R25">25</a></sup> and in neonatal intensive care, infants admitted to neonatal intensive care units on full- vs half-capacity days have greater mortality.<sup><a href="#R26" rid="R26">26</a></sup> Although all 3 explanations we provide are possible, our data cannot definitively distinguish among these possibilities.</p><p id="P31">Our findings may seem to conflict with our a priori hypothesis and studies that demonstrate worse patient outcomes during off-hours.<sup><a href="#R4" rid="R4">4</a>–<a href="#R9" rid="R9">9</a></sup> However, because we specifically compared hospitalizations during cardiology meeting dates with identical days in the surrounding weeks, our analysis explored the effect of selective reductions in cardiologist and not ancillary staffing as well as the effect of changes in the specific composition of cardiologists treating patients. Our results echo paradoxical findings documented during a labor strike by Israeli physicians in 2000, in which hundreds of thousands of outpatient visits and elective surgical procedures were cancelled, but by many accounts mortality rates dramatically fell during the year.<sup><a href="#R27" rid="R27">27</a></sup> Similar reports of decreased mortality during physician labor strikes exist elsewhere, with most hypotheses attributing mortality declines to lower rates of non-urgent surgical procedures.<sup><a href="#R28" rid="R28">28</a></sup></p><p id="P32">The principal limitation of our study was an inability to establish the mechanism by which high-risk patients with heart failure and cardiac arrest experienced lower 30-day mortality when admitted during dates of cardiology meetings. For example, among high-risk patients with heart failure, we found no difference between meeting and nonmeeting dates in adjusted rates of diagnostic catheterization of the right side of the heart or invasive hemodynamic monitoring, CABG, hospital charges, or LOS. Among patients with cardiac arrest, we found no differences in adjusted PCI or CABG rates, hospital charges, or LOS. Although important, each of these measures may miss important clinical decisions that do not appear in administrative data (eg, administration of vasoactive and inotropic medications<sup><a href="#R29" rid="R29">29</a>,<a href="#R30" rid="R30">30</a></sup> or nonbilled diagnostic and therapeutic procedures). We did, however, identify lower PCI rates among high-risk patients with AMI admitted to teaching hospitals during meeting dates, which may suggest lower intensity of care during these dates. We could also not directly assess how the staffing and composition of cardiologists who treated patients differed between meeting and nonmeeting dates. An additional limitation is that unmeasured confounders may explain mortality reductions during cardiology meeting dates. For example, cancellation of outpatient cardiology clinics or the absence of a given patient’s cardiologist may lead to delays in care that create a sample of inpatients that are at higher risk of mortality. However, not only were patients nearly identical between meeting and nonmeeting dates with respect to age, sex, race, and 10 chronic comorbidities, but we also found no evidence that hospitalizations were delayed until after the meetings ended. Moreover, our sensitivity analyses argue against unmeasured confounding. Our analysis was also restricted to the Medicare population and may not generalize to the commercially insured. Finally, the mortality effects we found among high-risk patients treated at teaching hospitals were unaffected by applying a Bonferroni correction for the comparison of multiple outcomes for each condition.<sup><a href="#R31" rid="R31">31</a></sup></p></div><div id="S20"><h2 id="S20title">Conclusions</h2><p id="P33">We observed lower 30-day mortality among patients with high-risk heart failure or cardiac arrest admitted to major teaching hospitals during the dates of 2 national cardiology meetings, as well as substantially lower PCI rates among high-risk patients with AMI, without any detriment to survival. One explanation for these findings is that the intensity of care provided during meeting dates is lower and that for high-risk patients with cardiovascular disease, the harms of this care may unexpectedly outweigh the benefits.</p></div><div id="SM"><h2 id="SMtitle">Supplementary Material</h2><!--/article/body/sec/--><div id="SD1"><h4>Supplement</h4></div></div><div id="S21"><h2 id="S21title">Acknowledgments</h2><div><p id="P44"><strong>Funding/Support:</strong> Dr Jena has received funding from the Office of the Director, National Institutes of Health (NIH Early Independence Award, grant 1DP5OD017897-01). Drs Goldman and Romley have received funding from the National Institute of Aging (grant 5P01AG033559).</p><p id="P45"><strong>Role of the Funder/Sponsor:</strong> The funding sources had no role in the design and conduct of the study; collection, management, analysis, and interpretation of the data; preparation, review, or approval of the manuscript; and decision to submit the manuscript for publication.</p></div></div><div id="fn-group-1"><h2 id="fn-group-1title">Footnotes</h2><!--back/fn-group--><div><p id="P34">Supplemental content at <a href="http://jamainternalmedicine.com/" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CBody&amp;TO=External%7CLink%7CURI" target="_blank">jamainternalmedicine.com</a></p><div><p id="P35"><strong>Author Contributions:</strong> Dr Jena had full access to all the data in the study and takes responsibility for the integrity of the data and the accuracy of the data analysis.</p><p><em>Study concept and design:</em> Jena, Prasad, Romley.</p><p id="P37"><em>Acquisition, analysis, or interpretation of data:</em> Jena, Goldman, Romley.</p><p id="P38"><em>Drafting of the manuscript:</em> Jena, Prasad.</p><p id="P39"><em>Critical revision of the manuscript for important intellectual content:</em> All authors.</p><p id="P40"><em>Statistical analysis:</em> Jena, Romley.</p><p id="P41"><em>Obtained funding:</em> Jena, Goldman.</p><p id="P42"><em>Study supervision:</em> Jena, Goldman.</p></div><p id="P43"><strong>Conflict of Interest Disclosures:</strong> Dr Goldman is a partner at Precision Health Economics, a health care consultancy conducting research in the life sciences. No other disclosures are reported.</p></div></div><div id="ref-list-1"><h2 id="ref-list-1title">REFERENCES</h2><div id="reference-list"><p>1. <span>Sedlis S. Meeting Perspectives: American Heart Association Scientific Sessions 2009. Clinical Correlations: The NYU Langone Online Journal of Medicine.  [Accessed September 2, 2014];<span></span>  <a href="http://www.clinicalcorrelations.org/?p=2123" data-ga-action="click_feat_suppl" ref="reftype=extlink&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=External%7CLink%7CURI" target="_blank">http://www.clinicalcorrelations.org/?p=2123</a>. <span>[<a href="https://scholar.google.com/scholar?q=Sedlis+S+Meeting+Perspectives:+American+Heart+Association+Scientific+Sessions+2009.+Clinical+Correlations:+The+NYU+Langone+Online+Journal+of+Medicine+Accessed+September+2,+2014+http://www.clinicalcorrelations.org/?p=2123+.+" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>3. <span>Alexander W. 2012 American College of Cardiology 61st Annual Scientific Session &amp; Expo. <span><span>PT. </span>2012;<span>37</span>(5):303–305.</span> <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3411220/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/22876089" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=PT&amp;title=2012+American+College+of+Cardiology+61st+Annual+Scientific+Session+&amp;+Expo&amp;author=W+Alexander&amp;volume=37&amp;issue=5&amp;publication_year=2012&amp;pages=303-305&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>4. <span>Bell CM, Redelmeier DA. Mortality among patients admitted to hospitals on weekends as compared with weekdays. <span><span>N Engl J Med. </span>2001;<span>345</span>(9):663–668.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/11547721" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=N+Engl+J+Med&amp;title=Mortality+among+patients+admitted+to+hospitals+on+weekends+as+compared+with+weekdays&amp;author=CM+Bell&amp;author=DA+Redelmeier&amp;volume=345&amp;issue=9&amp;publication_year=2001&amp;pages=663-668&amp;pmid=11547721&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>5. <span>Kostis WJ, Demissie K, Marcella SW, Shao YH, Wilson AC, Moreyra AE Myocardial Infarction Data Acquisition System (MIDAS 10) Study Group. Weekend versus weekday admission and mortality from myocardial infarction. <span><span>N Engl J Med. </span>2007;<span>356</span>(11):1099–1109.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/17360988" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=N+Engl+J+Med&amp;title=Weekend+versus+weekday+admission+and+mortality+from+myocardial+infarction&amp;author=WJ+Kostis&amp;author=K+Demissie&amp;author=SW+Marcella&amp;author=YH+Shao&amp;author=AC+Wilson&amp;volume=356&amp;issue=11&amp;publication_year=2007&amp;pages=1099-1109&amp;pmid=17360988&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>6. <span>Sorita A, Ahmed A, Starr SR, et al. Off-hour presentation and outcomes in patients with acute myocardial infarction: systematic review and meta-analysis. <span><span>BMJ. </span>2014;<span>348</span>:f7393.</span> <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3898160/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/24452368" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=BMJ&amp;title=Off-hour+presentation+and+outcomes+in+patients+with+acute+myocardial+infarction:+systematic+review+and+meta-analysis&amp;author=A+Sorita&amp;author=A+Ahmed&amp;author=SR+Starr&amp;volume=348&amp;publication_year=2014&amp;pages=f7393&amp;pmid=24452368&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>7. <span>Lairez O, Roncalli J, Carrié D, et al. Relationship between time of day, day of the week and in-hospital mortality in patients undergoing emergency percutaneous coronary intervention. <span><span>Arch Cardiovasc Dis. </span>2009;<span>102</span>(12):811–820.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/19963192" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Arch+Cardiovasc+Dis&amp;title=Relationship+between+time+of+day,+day+of+the+week+and+in-hospital+mortality+in+patients+undergoing+emergency+percutaneous+coronary+intervention&amp;author=O+Lairez&amp;author=J+Roncalli&amp;author=D+Carri%C3%A9&amp;volume=102&amp;issue=12&amp;publication_year=2009&amp;pages=811-820&amp;pmid=19963192&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>8. <span>Assali AR, Brosh D, Vaknin-Assa H, et al. The impact of circadian variation on outcomes in emergency acute anterior myocardial infarction percutaneous coronary intervention. <span><span>Catheter Cardiovasc Interv. </span>2006;<span>67</span>(2):221–226.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/16404750" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Catheter+Cardiovasc+Interv&amp;title=The+impact+of+circadian+variation+on+outcomes+in+emergency+acute+anterior+myocardial+infarction+percutaneous+coronary+intervention&amp;author=AR+Assali&amp;author=D+Brosh&amp;author=H+Vaknin-Assa&amp;volume=67&amp;issue=2&amp;publication_year=2006&amp;pages=221-226&amp;pmid=16404750&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>9. <span>Maier B, Behrens S, Graf-Bothe C, et al. Time of admission, quality of PCI care, and outcome of patients with ST-elevation myocardial infarction. <span><span>Clin Res Cardiol. </span>2010;<span>99</span>(9):565–572.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/20414663" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Clin+Res+Cardiol&amp;title=Time+of+admission,+quality+of+PCI+care,+and+outcome+of+patients+with+ST-elevation+myocardial+infarction&amp;author=B+Maier&amp;author=S+Behrens&amp;author=C+Graf-Bothe&amp;volume=99&amp;issue=9&amp;publication_year=2010&amp;pages=565-572&amp;pmid=20414663&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>10. <span><span>Guide to Inpatient Quality Indicators: Quality of Care in Hospitals–Volume, Mortality, and Utilization.</span> Rockville, MD: Agency for Healthcare Research and Quality; 2007. Agency for Healthcare Research and Quality. <span>[<a href="https://scholar.google.com/scholar_lookup?title=Guide+to+Inpatient+Quality+Indicators:+Quality+of+Care+in+Hospitals%E2%80%93Volume,+Mortality,+and+Utilization&amp;publication_year=2007&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>11. <span>Volpp KG, Rosen AK, Rosenbaum PR, et al. Mortality among patients in VA hospitals in the first 2 years following ACGME resident duty hour reform. <span><span>JAMA. </span>2007;<span>298</span>(9):984–992.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/17785643" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=JAMA&amp;title=Mortality+among+patients+in+VA+hospitals+in+the+first+2+years+following+ACGME+resident+duty+hour+reform&amp;author=KG+Volpp&amp;author=AK+Rosen&amp;author=PR+Rosenbaum&amp;volume=298&amp;issue=9&amp;publication_year=2007&amp;pages=984-992&amp;pmid=17785643&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>12. <span>Volpp KG, Rosen AK, Rosenbaum PR, et al. Mortality among hospitalized Medicare beneficiaries in the first 2 years following ACGME resident duty hour reform. <span><span>JAMA. </span>2007;<span>298</span>(9):975–983.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/17785642" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=JAMA&amp;title=Mortality+among+hospitalized+Medicare+beneficiaries+in+the+first+2+years+following+ACGME+resident+duty+hour+reform&amp;author=KG+Volpp&amp;author=AK+Rosen&amp;author=PR+Rosenbaum&amp;volume=298&amp;issue=9&amp;publication_year=2007&amp;pages=975-983&amp;pmid=17785642&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>13. <span>Jena AB, Sun EC, Romley JA. Mortality among high-risk patients with acute myocardial infarction admitted to U.S. teaching-intensive hospitals in July: a retrospective observational study. <span><span>Circulation. </span>2013;<span>128</span>(25):2754–2763.</span> <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4125575/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/24152859" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Circulation&amp;title=Mortality+among+high-risk+patients+with+acute+myocardial+infarction+admitted+to+U.S.+teaching-intensive+hospitals+in+July:+a+retrospective+observational+study&amp;author=AB+Jena&amp;author=EC+Sun&amp;author=JA+Romley&amp;volume=128&amp;issue=25&amp;publication_year=2013&amp;pages=2754-2763&amp;pmid=24152859&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>14. <span>Girotra S, Chan PS. Trends in survival after in-hospital cardiac arrest. <span><span>N Engl J Med. </span>2013;<span>368</span>(7):680–681.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/23406039" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=N+Engl+J+Med&amp;title=Trends+in+survival+after+in-hospital+cardiac+arrest&amp;author=S+Girotra&amp;author=PS+Chan&amp;volume=368&amp;issue=7&amp;publication_year=2013&amp;pages=680-681&amp;pmid=23406039&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>15. <span>Volpp KG, Rosen AK, Rosenbaum PR, et al. Did duty hour reform lead to better outcomes among the highest risk patients? <span><span>J Gen Intern Med. </span>2009;<span>24</span>(10):1149–1155.</span> <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2762498/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/19455368" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=J+Gen+Intern+Med&amp;title=Did+duty+hour+reform+lead+to+better+outcomes+among+the+highest+risk+patients?&amp;author=KG+Volpp&amp;author=AK+Rosen&amp;author=PR+Rosenbaum&amp;volume=24&amp;issue=10&amp;publication_year=2009&amp;pages=1149-1155&amp;pmid=19455368&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>16. <span>Joynt KE, Blumenthal DM, Orav EJ, Resnic FS, Jha AK. Association of public reporting for percutaneous coronary intervention with utilization and outcomes among Medicare beneficiaries with acute myocardial infarction. <span><span>JAMA. </span>2012;<span>308</span>(14):1460–1468.</span> <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3698951/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/23047360" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=JAMA&amp;title=Association+of+public+reporting+for+percutaneous+coronary+intervention+with+utilization+and+outcomes+among+Medicare+beneficiaries+with+acute+myocardial+infarction&amp;author=KE+Joynt&amp;author=DM+Blumenthal&amp;author=EJ+Orav&amp;author=FS+Resnic&amp;author=AK+Jha&amp;volume=308&amp;issue=14&amp;publication_year=2012&amp;pages=1460-1468&amp;pmid=23047360&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>17. <span>Wiener RS, Welch HG. Trends in the use of the pulmonary artery catheter in the United States, 1993–2004. <span><span>JAMA. </span>2007;<span>298</span>(4):423–429.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/17652296" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=JAMA&amp;title=Trends+in+the+use+of+the+pulmonary+artery+catheter+in+the+United+States,+1993%E2%80%932004&amp;author=RS+Wiener&amp;author=HG+Welch&amp;volume=298&amp;issue=4&amp;publication_year=2007&amp;pages=423-429&amp;pmid=17652296&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>19. <span>Prasad V, Jena AB. Prespecified falsification end points: can they validate true observational associations? <span><span>JAMA. </span>2013;<span>309</span>(3):241–242.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/23321761" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=JAMA&amp;title=Prespecified+falsification+end+points:+can+they+validate+true+observational+associations?&amp;author=V+Prasad&amp;author=AB+Jena&amp;volume=309&amp;issue=3&amp;publication_year=2013&amp;pages=241-242&amp;pmid=23321761&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>20. <span>Jena AB, Sun E, Goldman DP. Confounding in the association of proton pump inhibitor use with risk of community-acquired pneumonia. <span><span>J Gen Intern Med. </span>2013;<span>28</span>(2):223–230.</span> <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3614140/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/22956446" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=J+Gen+Intern+Med&amp;title=Confounding+in+the+association+of+proton+pump+inhibitor+use+with+risk+of+community-acquired+pneumonia&amp;author=AB+Jena&amp;author=E+Sun&amp;author=DP+Goldman&amp;volume=28&amp;issue=2&amp;publication_year=2013&amp;pages=223-230&amp;pmid=22956446&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>21. <span>Ioannidis JP. Are mortality differences detected by administrative data reliable and actionable? <span><span>JAMA. </span>2013;<span>309</span>(13):1410–1411.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/23549588" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=JAMA&amp;title=Are+mortality+differences+detected+by+administrative+data+reliable+and+actionable?&amp;author=JP+Ioannidis&amp;volume=309&amp;issue=13&amp;publication_year=2013&amp;pages=1410-1411&amp;pmid=23549588&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>22. <span>Carson JL, Carless PA, Hébert PC. Outcomes using lower vs higher hemoglobin thresholds for red blood cell transfusion. <span><span>JAMA. </span>2013;<span>309</span>(1):83–84.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/23280228" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=JAMA&amp;title=Outcomes+using+lower+vs+higher+hemoglobin+thresholds+for+red+blood+cell+transfusion&amp;author=JL+Carson&amp;author=PA+Carless&amp;author=PC+H%C3%A9bert&amp;volume=309&amp;issue=1&amp;publication_year=2013&amp;pages=83-84&amp;pmid=23280228&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>23. <span>de Mulder M, Umans VA, Cornel JH, et al. Intensive glucose regulation in hyperglycemic acute coronary syndrome: results of the randomized BIOMarker study to identify the acute risk of a coronary syndrome-2 (BIOMArCS-2) glucose trial. <span><span>JAMA Intern Med. </span>2013;<span>173</span>(20):1896–1904.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/24018647" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=JAMA+Intern+Med&amp;title=Intensive+glucose+regulation+in+hyperglycemic+acute+coronary+syndrome:+results+of+the+randomized+BIOMarker+study+to+identify+the+acute+risk+of+a+coronary+syndrome-2+(BIOMArCS-2)+glucose+trial&amp;author=M+de+Mulder&amp;author=VA+Umans&amp;author=JH+Cornel&amp;volume=173&amp;issue=20&amp;publication_year=2013&amp;pages=1896-1904&amp;pmid=24018647&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>24. <span>Kox M, Pickkers P. “Less is more” in critically ill patients: not too intensive. <span><span>JAMA Intern Med. </span>2013;<span>173</span>(14):1369–1372.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/23752755" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=JAMA+Intern+Med&amp;title=%E2%80%9CLess+is+more%E2%80%9D+in+critically+ill+patients:+not+too+intensive&amp;author=M+Kox&amp;author=P+Pickkers&amp;volume=173&amp;issue=14&amp;publication_year=2013&amp;pages=1369-1372&amp;pmid=23752755&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>25. <span>Snowden JM, Darney BG, Cheng YW, McConnell KJ, Caughey AB. Systems factors in obstetric care: the role of daily obstetric volume. <span><span>Obstet Gynecol. </span>2013;<span>122</span>(4):851–857.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/24084544" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Obstet+Gynecol&amp;title=Systems+factors+in+obstetric+care:+the+role+of+daily+obstetric+volume&amp;author=JM+Snowden&amp;author=BG+Darney&amp;author=YW+Cheng&amp;author=KJ+McConnell&amp;author=AB+Caughey&amp;volume=122&amp;issue=4&amp;publication_year=2013&amp;pages=851-857&amp;pmid=24084544&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>26. <span>Tucker J UK Neonatal Staffing Study Group. Patient volume, staffing, and workload in relation to risk-adjusted outcomes in a random stratified sample of UK neonatal intensive care units: a prospective evaluation. <span><span>Lancet. </span>2002;<span>359</span>(9301):99–107.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/11809250" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Lancet&amp;title=Patient+volume,+staffing,+and+workload+in+relation+to+risk-adjusted+outcomes+in+a+random+stratified+sample+of+UK+neonatal+intensive+care+units:+a+prospective+evaluation&amp;author=J+Tucker&amp;volume=359&amp;issue=9301&amp;publication_year=2002&amp;pages=99-107&amp;pmid=11809250&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>28. <span>Cunningham SA, Mitchell K, Narayan KM, Yusuf S. Doctors’ strikes and mortality: a review. <span><span>Soc Sci Med. </span>2008;<span>67</span>(11):1784–1788.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/18849101" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Soc+Sci+Med&amp;title=Doctors%E2%80%99+strikes+and+mortality:+a+review&amp;author=SA+Cunningham&amp;author=K+Mitchell&amp;author=KM+Narayan&amp;author=S+Yusuf&amp;volume=67&amp;issue=11&amp;publication_year=2008&amp;pages=1784-1788&amp;pmid=18849101&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>29. <span>De Backer D, Biston P, Devriendt J, et al. SOAP II Investigators. Comparison of dopamine and norepinephrine in the treatment of shock. <span><span>N Engl J Med. </span>2010;<span>362</span>(9):779–789.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/20200382" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=N+Engl+J+Med&amp;title=Comparison+of+dopamine+and+norepinephrine+in+the+treatment+of+shock&amp;author=D+De+Backer&amp;author=P+Biston&amp;author=J+Devriendt&amp;volume=362&amp;issue=9&amp;publication_year=2010&amp;pages=779-789&amp;pmid=20200382&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>30. <span>Tavazzi L, Maggioni AP, Lucci D, et al. Italian survey on Acute Heart Failure Investigators. Nationwide survey on acute heart failure in cardiology ward services in Italy. <span><span>Eur Heart J. </span>2006;<span>27</span>(10):1207–1215.</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/16603579" ref="reftype=pubmed&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Eur+Heart+J&amp;title=Nationwide+survey+on+acute+heart+failure+in+cardiology+ward+services+in+Italy&amp;author=L+Tavazzi&amp;author=AP+Maggioni&amp;author=D+Lucci&amp;volume=27&amp;issue=10&amp;publication_year=2006&amp;pages=1207-1215&amp;pmid=16603579&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>31. <span>Shaffer JP. Multiple hypothesis testing. <span><span>Annu Rev Psychol. </span>1995;<span>46</span>:561–584.</span> <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Annu+Rev+Psychol&amp;title=Multiple+hypothesis+testing&amp;author=JP+Shaffer&amp;volume=46&amp;publication_year=1995&amp;pages=561-584&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=4314435&amp;issue-id=248755&amp;journal-id=319&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p></div></div></div>
    </article>
    
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[They didn’t ask to go viral: Posting on social media without consent is immoral (193 pts)]]></title>
            <link>https://www.wired.com/story/social-media-privacy-consent/</link>
            <guid>37011624</guid>
            <pubDate>Sat, 05 Aug 2023 13:04:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/social-media-privacy-consent/">https://www.wired.com/story/social-media-privacy-consent/</a>, See on <a href="https://news.ycombinator.com/item?id=37011624">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><span>The problem with</span> judging people for their sins is that the internet makes it exceedingly easy to invent sins. In February, <a href="https://www.buzzfeednews.com/article/clarissajanlim/viral-tiktok-consent-panopticontent">Buzzfeed News reported</a> on a man filmed by a passing TikTokker, who then uploaded the footage with text suggesting he’d lied to her to get out of a date. That was false—he’d never met her—but it didn’t stop people from ridiculing him as the video racked up over a million views.</p><p>Similarly, last year, an Australian woman objected to being made the star of a stunt in which a TikTokker asked her to hold a bouquet, strolled off, and then congratulated himself on performing a random act of kindness. Sixty million hits later, his viewers were praising him for brightening the day of a woman they judged to be old, lonely, and sad. But she objected to that characterization and <a data-offer-url="https://www.skynews.com.au/lifestyle/trending/melbourne-woman-left-feeling-dehumanised-after-tiktok-influencer-posted-video-of-her-without-consent/news-story/7cef03b649a4e41d07082b31c362547e" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.skynews.com.au/lifestyle/trending/melbourne-woman-left-feeling-dehumanised-after-tiktok-influencer-posted-video-of-her-without-consent/news-story/7cef03b649a4e41d07082b31c362547e&quot;}" href="https://www.skynews.com.au/lifestyle/trending/melbourne-woman-left-feeling-dehumanised-after-tiktok-influencer-posted-video-of-her-without-consent/news-story/7cef03b649a4e41d07082b31c362547e" rel="nofollow noopener" target="_blank">declared the whole affair “dehumanizing.”</a> She hadn’t asked to have her day interrupted, let alone be thrust into a global spotlight.</p><p>And then there are those incapable of even grasping the situation. In 2022, a TikTok channel was called out for surreptitiously filming the <a href="https://www.newsweek.com/tiktoker-using-drone-film-mock-homeless-people-sparks-outrage-1744575">homeless with drones</a>. Loved ones <a href="https://www.wsj.com/articles/people-are-posting-tiktok-videos-of-their-relatives-with-dementia-should-they-11651618762">with dementia</a> are put on TikTok to be infantilized or have their worst moments gawked at. Parents <a href="https://www.theatlantic.com/technology/archive/2019/02/when-kids-realize-their-whole-life-already-online/582916/">transform their children into viral stars</a>. Sometimes, those children grow up and <a href="https://www.teenvogue.com/story/influencer-parents-children-social-media-impact">call them out</a> for warping their youth.</p><p>When people tell us it was harrowing and wrong to be unwillingly cast into the spotlight, we nod and agree. But those responsible typically offer only half-hearted apologies or <a href="https://www.news.com.au/entertainment/tv/current-affairs/aussie-tiktok-star-sorry-but-wont-stop-controversial-acts-of-kindness/news-story/347c18457d80a961e27c6b31f42b2507">remain unrepentant</a>, while their millions of views discourage reflection. Often, moral scolding is implicit in the video and explicit in the comments: It is wrong to be homeless. It is gross to be ill. It is pathetic to be unhappy.</p><p>To be sure, crass and hateful public figures are worthy of ridicule. And we’ve been using the internet to judge strangers for as long as we’ve had the internet. But the common trait shared by much of the most obnoxious content today is that someone chose to elevate a stranger for no reason beyond their own gratification, attracting attention at a scale unimaginable in the days of relics like Hot or Not and People of Wal-Mart.</p><p>At best, these are misguided attempts to juice the poster’s social media presence. At worst, they are pointless cruelty. That cruelty can be addictive, but we can and must resist the urge to gawk at strangers against their will. It should, in fact, be considered rude, insulting, and wrong to have uploaded a stranger against their will. We would not go out into the streets and stir up a mob against a random person. Why are we so comfortable with doing it online?</p><p><span>Much of what</span> we post online is innocent and will remain so. The average Facebook user has <a data-offer-url="https://truelist.co/blog/facebook-statistics/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://truelist.co/blog/facebook-statistics/&quot;}" href="https://truelist.co/blog/facebook-statistics/" rel="nofollow noopener" target="_blank">338 friends</a>, while the average number of Instagram followers, according to one estimate, is just <a data-offer-url="https://www.hashtagsforlikes.co/blog/instagram-followers-how-many-does-the-average-person-have/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.hashtagsforlikes.co/blog/instagram-followers-how-many-does-the-average-person-have/&quot;}" href="https://www.hashtagsforlikes.co/blog/instagram-followers-how-many-does-the-average-person-have/" rel="nofollow noopener" target="_blank">150</a>. You likely use these platforms to follow celebrities and brands, and to interact with friends and family. These are, for most users, insular communities. Vacation photos with friends or a family portrait at Christmas are unlikely to attract trolls and creeps, and even if they do, they are clearly posted in good faith.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>But some platforms, like TikTok and Twitter, are more exposed to the vagaries and cruelties of the wider world. Anything you post on them can wind up in the feed of people who don't follow you. Therefore, anyone can become the day’s punching bag. Does your relative really understand what could happen if you put your interaction with them on TikTok?</p><p>Maybe you know better than to post Grandpa on Twitter without thinking it through. We know whether our friends and family like attention and whether they understand social media ecosystems, and with this knowledge we are capable of making informed decisions as to whether and on what platforms we should post them. We do not have the same knowledge of strangers. That can be a reason to not post them, but it can also be an excuse to post them without thinking.</p><p>If it came out that an influencer uploaded an interaction with a stranger to a private Facebook page or Discord server solely so their closest friends and family could pick them apart, it would rightly be considered misanthropic. And yet uploading a stranger so millions can mock and over-analyze them is just the business of content. That business needs to change.</p><p>It’s exceedingly unlikely we’ll ever eliminate jackassery from the internet, but a social media mishap involving a friend or family member can be resolved with communication.</p><p>It is harder for a complete stranger to succeed in that endeavor, especially when “Look at this weirdo I found, please gape at them” is the text or subtext of so many videos and posts by accounts that thrive on content starring the unwilling. Such content must become anathema. Particular thought must be taken before posting an interaction with a stranger, and the consent of a stranger to be posted at all is necessary to retain an internet that is even remotely civil. If someone does post a stranger without their consent, they should be shunned, not rewarded with the attention they crave.</p><p><span>The vast majority</span> of disputes with unruly neighbors are solved by talking to them. Ideally, the law only gets involved when lines of communication break down. The same can be true of digital disputes.</p><p>We have privacy laws. If I were to post your name, address, and phone number, you would have legal recourse. And yet the same is not true for your image. Today, at least, you surrender your right to privacy by stepping into public. But outdated privacy laws are <a href="https://www.reuters.com/legal/legalindustry/us-data-privacy-laws-enter-new-era-2023-2023-01-12/">catching up</a> to the abuses of government and tech, and the issues raised by social media virality <a data-offer-url="https://www.abc27.com/investigators/take-down-that-post-what-to-do-if-someone-posts-video-of-you-without-consent/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.abc27.com/investigators/take-down-that-post-what-to-do-if-someone-posts-video-of-you-without-consent/&quot;}" href="https://www.abc27.com/investigators/take-down-that-post-what-to-do-if-someone-posts-video-of-you-without-consent/" rel="nofollow noopener" target="_blank">could be next</a>.</p><p>Still, a blanket law against posting strangers without their consent would be draconian and unworkable. There are too many variables, too many circumstances, and simply too many cases. However, whole generations who have been online since birth—sometimes unwillingly—could grow up to be more sensitive to the downsides of posting without permission, prompting a normative shift.</p><p>More specific laws are already evolving to handle some scenarios raised by nonconsensual virality, specifically as it applies to children. <a data-offer-url="https://www.scu.edu/ethics/about-the-center/people/irina-raicu/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.scu.edu/ethics/about-the-center/people/irina-raicu/&quot;}" href="https://www.scu.edu/ethics/about-the-center/people/irina-raicu/" rel="nofollow noopener" target="_blank">Irina Raicu</a> of Santa Clara University’s Internet Ethics Program points out that <a href="https://www.buzzfeednews.com/article/stephaniemcneal/french-pass-law-protecting-kid-influencers">a recent French law</a> entitles child influencers to demand that platforms scrub all trace of them once they turn 16. The YouTube career their parents create for them—or force on them—need not be what defines them as adults. The United States is considering a similar law; a woman who <a data-offer-url="https://www.eviemagazine.com/post/viral-tiktok-young-womans-life-ruined-intimate-details-childhood-social-media-parents" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.eviemagazine.com/post/viral-tiktok-young-womans-life-ruined-intimate-details-childhood-social-media-parents&quot;}" href="https://www.eviemagazine.com/post/viral-tiktok-young-womans-life-ruined-intimate-details-childhood-social-media-parents" rel="nofollow noopener" target="_blank">testified to a House committee</a> said the details of her first period were turned into content.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Another law being considered in France would make parents responsible for their <a data-offer-url="https://www.politico.eu/article/emmanuel-macron-france-law-aims-to-protect-kids-against-oversharing-parents/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.politico.eu/article/emmanuel-macron-france-law-aims-to-protect-kids-against-oversharing-parents/&quot;}" href="https://www.politico.eu/article/emmanuel-macron-france-law-aims-to-protect-kids-against-oversharing-parents/" rel="nofollow noopener" target="_blank">children’s privacy rights</a>. <a href="https://www.lemonde.fr/en/france/article/2023/03/05/french-mp-proposes-bill-to-protect-children-s-privacy-on-social-media_6018268_7.html"><em>Le Monde</em> cites, as an example of fame-seeking behavior</a> that France is hoping to discourage, TikTokkers scaring their children by pretending to call the police on them, and an Instagrammer who smeared chocolate on her 4-year-old and convinced them they were covered in feces. We will eventually wonder how parents were able to get away with this at all.</p><p>So those who cannot consent are starting to be protected. But what about those who could consent, but don’t? And what if, as some unwillingly viral subjects have found, reaching out and asking for posts to be removed is met with silence or rejection?</p><p><span>In reality we</span> already practice social media consent; it is not unusual to ask a friend if they’re alright with having a picture posted to Instagram, even though the face they make as they try to cram an unusually large sandwich into their mouth is not a flattering one. And yet we continually fail to extend this courtesy to strangers, either because we think nothing of it or because it is our job to go viral at all costs.</p><p>Some of this, as <a data-offer-url="https://www.scu.edu/ethics/about-the-center/people/irina-raicu/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.scu.edu/ethics/about-the-center/people/irina-raicu/&quot;}" href="https://www.scu.edu/ethics/about-the-center/people/irina-raicu/" rel="nofollow noopener" target="_blank">Raicu</a> points out, can be blamed on the platforms we use, which encourage hair triggers. “There are ways in which the design choices behind many websites make it harder for all of us to think about consent,” Raicu wrote in an email. She points to the sheer ease of posting and the fact that norms around social media consent have not solidified. But she notes that platforms could “introduce some friction” in the form of, essentially, reminders that other people are human before you hit Post.</p><p>Future platforms could work to curtail shaming, either out of moral compulsion or legal necessity. Much as you can report harassment to social media platforms, posts that have elevated you to infamy against your will should be fair targets.</p><p>Lines have been drawn before. YouTube banned dangerous pranks and challenges after <a href="https://www.cnn.com/2019/01/16/business/youtube-dangerous-pranks-ban-scli-intl/index.html">people were hurt</a> and complaints mounted. TikTok is trying to tweak its algorithm in response <a href="https://www.vice.com/en/article/qjv4jw/tiktok-incels-targeting-young-users">to growing concerns</a> that young users are awash in content encouraging suicide and incel ideology. Content made from those unable or unwilling to consent is a broad category that cannot be wiped out with algorithmic tweaks, but the damage is still happening, and we have the power to collectively declare that some forms of content are unacceptable and must no longer be tolerated.</p><p>Perhaps, given the increasing universality of social media usage—83 percent of Gen Z <a data-offer-url="https://www.insiderintelligence.com/content/gen-z-social-video-generation-tiktok-its-platform" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.insiderintelligence.com/content/gen-z-social-video-generation-tiktok-its-platform&quot;}" href="https://www.insiderintelligence.com/content/gen-z-social-video-generation-tiktok-its-platform" rel="nofollow noopener" target="_blank">uses TikTok</a>—platform-embedded tools could establish consent. Before posting a video of someone, an influencer could ask their username and send them a simple, stock contract granting them permission to post. Again, this need not apply to every random photo of friends. It could be optional, or it might apply only when an account reaches a certain threshold of followers. But a lack of permission could give a user cause when they cite unwanted virality and negative attention when asking for a post to be removed.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>But most of the work will fall to people. It's difficult enough to remember that the man being a bit rude in the grocery store line is a fallible human being with hopes and dreams; it can be almost impossible to remind yourself of that when viewing a contextless clip of someone halfway across the hemisphere. The internet is capable of connecting us to tremendous numbers of people, even as it makes us forget that they are human like us.</p><p>An influencer comfortable with filming themselves for thousands of viewers should be comfortable with approaching a stranger and saying, “Would you mind appearing in a video I’m making? I’m going to post it on this platform, and I have this many followers. Take a minute to check me out.” Some already do, and surely there are people who would be happy to receive a free bouquet in exchange for appearing in a TikTokker’s silly stunt. But a no should be taken as a no, just as it should in any other scenario involving consent.</p><p>It’s all too easy to skip this step today. People who speak out when they feel harmed by what an influencer did with their image receive only a tiny fraction of the attention that the original posts featuring them got. But when an influencer is repeatedly called out for exploiting strangers—or when their exploitation is obvious, such as when they prey on the homeless—they should be frozen out of the social media ecosystem, not rewarded with attention and profit.</p><p><span>In the future,</span> how will we be able to see such casual cruelty as anything <em>but</em> unethical? Maybe stories of regret are a sign of what’s to come. Brianna Wu, one of the victims of GamerGate, says she has fielded <a href="https://www.washingtonpost.com/nation/2021/08/05/gamergate-threats-brianna-wu/">over 100 apologies</a>, often from people who were at their lowest and saw her as an easy outlet for their emotions. But we generally don’t take our frustrations out on people on the street; understanding that people deserve to be protected from unsolicited online fame and malice is the next logical step.</p><p>We no longer parade people through villages on a cart or lock them in pillories in the town square to shame them, as was done in centuries past. We did not stop enforcing laws and norms, but we recognized that humiliation and ostracization are harsh, counterproductive tools. Eventually, we will make that realization about the strangers we parade across the internet.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Will Browsers Be Required by Law to Stop You from Visiting Infringing Sites? (204 pts)]]></title>
            <link>https://www.techdirt.com/2023/08/04/will-browsers-be-required-by-law-to-stop-you-from-visiting-infringing-sites/</link>
            <guid>37011349</guid>
            <pubDate>Sat, 05 Aug 2023 12:27:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techdirt.com/2023/08/04/will-browsers-be-required-by-law-to-stop-you-from-visiting-infringing-sites/">https://www.techdirt.com/2023/08/04/will-browsers-be-required-by-law-to-stop-you-from-visiting-infringing-sites/</a>, See on <a href="https://news.ycombinator.com/item?id=37011349">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storywrap-417069">


<h3>from the <i>i-can't-open-that-page,-dave</i> dept</h3>

<p>Mozilla’s Open Policy &amp; Advocacy blog has news about&nbsp;<a href="https://blog.mozilla.org/netpolicy/2023/06/26/france-browser-website-blocking/">a worrying proposal from the French government</a>:</p>
<blockquote>
<p><em>In a well-intentioned yet dangerous move to fight online fraud, France is on the verge of forcing browsers to create a dystopian technical capability. Article 6 (para II and III) of the SREN Bill would force browser providers to create the means to mandatorily block websites present on a government provided list.</em></p>
</blockquote>
<p>The post explains why this is an extremely dangerous approach:</p>
<blockquote>
<p><em>A world in which browsers can be forced to incorporate a list of banned websites at the software-level that simply do not open, either in a region or globally, is a worrying prospect that raises serious concerns around freedom of expression. If it successfully passes into law, the precedent this would set would make it much harder for browsers to reject such requests from other governments.</em></p>
</blockquote>
<p>If a capability to block any site on a government blacklist were required by law to be built in to all browsers, then repressive governments would be given an enormously powerful tool. There would be no way around that censorship, short of hacking the browser code. That might be an option for open source coders, but it certainly won’t be for the vast majority of ordinary users. As the Mozilla post points out:</p>
<blockquote>
<p><em>Such a move will overturn decades of established content moderation norms and provide a playbook for authoritarian governments that will easily negate the existence of censorship circumvention tools.</em></p>
</blockquote>
<p>It is even worse than that. If such a capability to block any site were built in to browsers, it’s not just authoritarian governments that would be rubbing their hands with glee: the copyright industry would doubtless push for allegedly infringing sites to be included on the block list too. We know this, because it has already done it in the past, as discussed in Walled Culture the book (<a href="https://walledculture.org/the-book/">free digital versions</a>).</p>
<p>Not many people now remember, but in 2004, BT (British Telecom) caused something of a storm when it created&nbsp;<a href="https://www.theguardian.com/technology/2004/jun/06/childrensservices.childprotection">CleanFeed</a>:</p>
<blockquote>
<p><em>British Telecom has taken the unprecedented step of blocking all illegal child pornography websites in a crackdown on abuse online. The decision by Britain’s largest high-speed internet provider will lead to the first mass censorship of the web attempted in a Western democracy.</em></p>
</blockquote>
<p>Here’s how it worked:</p>
<blockquote>
<p><em>Subscribers to British Telecom’s internet services such as BTYahoo and BTInternet who attempt to access illegal sites will receive an error message as if the page was unavailable. BT will register the number of attempts but will not be able to record details of those accessing the sites.</em></p>
</blockquote>
<p>The key justification for what the Guardian called “the first mass censorship of the web attempted in a Western democracy” was that it only blocked illegal child sexual abuse material Web sites. It was therefore an extreme situation requiring an exceptional solution. But seven years later, the copyright industry were able to convince a High Court judge&nbsp;<a href="https://web.archive.org/web/20220618190216/https://www.bbc.com/news/technology-14322957">to ignore that justification</a>, and to take advantage of CleanFeed to block a site,&nbsp;<a href="https://en.wikipedia.org/wiki/Newzbin">Newzbin 2</a>, that had nothing to do with child sexual abuse material, and therefore did not require exceptional solutions:</p>
<blockquote>
<p><em>Justice Arnold ruled that BT must use its blocking technology CleanFeed – which is currently used to prevent access to websites featuring child sexual abuse – to block Newzbin 2.</em></p>
</blockquote>
<p>Exactly the logic used by copyright companies to subvert CleanFeed could be used to co-opt the censorship capabilities of browsers with built-in Web blocking lists. As with CleanFeed, the copyright industry would doubtless argue that since the technology already exists, why not to apply it to tackling copyright infringement too?</p>
<p>That very real threat is another reason to fight this pernicious, misguided French proposal. Because if it is implemented, it will be very hard to stop it becoming yet another technology that the copyright world demands should be bent to its own selfish purposes.</p>
<p><em>Follow me @glynmoody on&nbsp;<a rel="noreferrer noopener" href="https://mastodon.social/@glynmoody" target="_blank">Mastodon</a></em>.<em> Originally published to <a href="https://walledculture.org/how-long-before-all-browsers-are-required-by-law-to-prevent-users-from-opening-allegedly-infringing-sites/">Walled Culture</a>.</em></p>
<p>
Filed Under: <a href="https://www.techdirt.com/tag/blocklist/" rel="tag">blocklist</a>, <a href="https://www.techdirt.com/tag/browsers/" rel="tag">browsers</a>, <a href="https://www.techdirt.com/tag/cleanfeed/" rel="tag">cleanfeed</a>, <a href="https://www.techdirt.com/tag/copyright/" rel="tag">copyright</a>, <a href="https://www.techdirt.com/tag/france/" rel="tag">france</a>, <a href="https://www.techdirt.com/tag/sren/" rel="tag">sren</a>, <a href="https://www.techdirt.com/tag/websites/" rel="tag">websites</a>
<br>
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Green vs. Brown Programming Languages (2021) (139 pts)]]></title>
            <link>https://earthly.dev/blog/brown-green-language/</link>
            <guid>37011346</guid>
            <pubDate>Sat, 05 Aug 2023 12:26:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://earthly.dev/blog/brown-green-language/">https://earthly.dev/blog/brown-green-language/</a>, See on <a href="https://news.ycombinator.com/item?id=37011346">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong>We’re <a href="https://earthly.dev/">Earthly</a>. We make building software simpler and faster, regardless of the programming language you’re fond of. It’s a handy tool for developers dealing with both “brown” and “green” languages. <a href="https://earthly.dev/">Check it out</a>.</strong></p>
<h2 id="the-data">The Data</h2>
<p>The Stack Overflow Developer Survey<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a> results are a great source of information about how developers work. I was looking at the 2020 results for some ideas on what programming languages we should add to our <a href="https://docs.earthly.dev/basics/part-1-a-simple-earthfile">documentation</a> on containerized builds, and I noticed something interesting about the types of programming languages people like. It’s something that doesn’t seem to come up in various discussions of programming language preferences.</p>
<p>The survey results have rankings for <strong>The Most Dreaded Programming Languages</strong> and <strong>The Most Loved Programming Language</strong>. Both rankings come from this question:</p>
<blockquote>
<p>Which programming, scripting, and markup languages have you done extensive development work in over the past year, and which do you want to work in over the next year? (If you both worked with the language and want to continue to do so, please check both boxes in that row.)</p>
</blockquote>
<p>A dreaded language is one you work with extensively in the current year but don’t want to continue to use. A loved language you use extensively and wish to continue using. The results are interesting because they reflect the opinions of people who are using the languages extensively. There should be no I-heard-X-is-cool effect, where people rank highly things they don’t use because they heard it is the new hotness. The inverse should also be true: People who put something on the <strong>Dreaded</strong> list are using it. They are not dreading a language because they heard it was complex, but because they have to work it and feel real pain.</p>
<section id="the-top-15-dreaded-programming-languages">
<h3>The TOP 15 Dreaded Programming Languages</h3>
<p>VBA, Objective-C, Perl, Assembly, C, PHP, Ruby, C++, Java, R, Haskell, Scala, HTML, Shell, and SQL.</p>
</section>
<section id="the-top-15-loved-programming-languages">
<h3>The TOP 15 Loved Programming Languages</h3>
<p>Rust, TypeScript, Python, Kotlin, Go, Julia, Dart, C#, Swift, JavaScript, SQL, Shell, HTML, Scala, and Haskell.</p>
</section>
<p>There is a pattern in this list. Can you see what it is?</p>
<h2 id="code-written-before-i-joined-is-the-worst">Code Written Before I Joined Is the Worst</h2>
<p>Old code is the worst. Find me a file in a codebase that has been under active development for more than three years, and it will be hard to follow. What starts as a straightforward file access layer develops special cases and performance optimizations and various branches controlled by configuration options. Real-world code evolves to fits its niche, and as it does so, it becomes more complex and harder to understand. The reason for this is simple, and I first heard about it from Joel Spolsky.</p>
<blockquote>
<p>The reason that [ developers ] think the old code is a mess is because of a cardinal, fundamental law of programming: <strong>It’s harder to read code than to write it.</strong></p>
<p>Joel Spolsky - <a href="https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/">Things you should never do</a></p>
</blockquote>
<p>Let’s call this Joel’s Law. A lot of things follow from this premise. Why do most developers think the code they inherited is a mess and want to throw it out and start again? It’s because writing something new is cognitively less demanding than the hard work of understanding an existing codebase, at least initially. Why are many rewrites doomed to fail? Because much of what makes the code seem messy are vital little improvements that accreted over time. Without some plan for simplifying them, you will end up back where you started.</p>
<figure>
<img src="https://earthly.dev/blog/assets/images/brown-green-language/dt140812.gif" alt=""><figcaption>Scott Adams Understood</figcaption>
</figure>
<p>It’s easy to understand code as you are writing it. You are executing it and refining it as you go. But it’s hard to understand code just by reading it after the fact. If you return to old code you wrote and find it hard to follow, it could be because you have grown as a developer and would write it better today. But its also possible that the code is inherently complex, and you are interpreting the pain of understanding that complexity as a code quality problem. Could this be why growing PR backlogs are a persistent problem? PR Reviews are a read-only activity, and they are hard to do well if you don’t already have a working model of the code in your head.</p>
<h2 id="this-is-why-you-dread-it">This is Why You Dread It</h2>
<p>If much real-world code is unfairly considered a mess, could programming languages also be unfairly judged? If you build new things in Go but have to maintain a sprawling 20-year-old C++ codebase, can you rank them fairly? I think this is actually what the survey question is measuring: dreaded languages are likely to be used in existing brown-field projects. Loved languages are more often used in new green-field projects. Let’s test this.<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<h2 id="measuring-brown-vs.-green-languages">Measuring Brown vs.&nbsp;Green Languages</h2>
<p>The TIOBE index claims to measure “the number of skilled engineers, courses, and jobs worldwide” for programming languages. There are probably some problems with how they measure this, but it’s accurate enough for our purposes. We use the July 2016 TIOBE <a href="https://web.archive.org/web/20160801213334/https://www.tiobe.com/tiobe-index/">index</a>, the oldest available in way back machine, as a proxy for a language having accumulated lots of code to maintain. If something was big in 2016, it’s more likely people are maintaining code written in it than if it wasn’t popular in 2016.</p>
<p>The top 20 programming languages on their list as of July 2016 are Java, C, C++, Python, C#, PHP, JavaScript, VB.NET, Perl, Assembly, Ruby, Pascal, Swift, Objective-C, MATLAB, R, SQL, COBOL, and Groovy. We can use this as our list of languages more likely to be used in maintenance work. Let’s call them brown languages. Languages not in the top 20 in 2016 are more likely to be used in new projects. We will refer to these as green languages.</p>
<p><img src="https://earthly.dev/blog/assets/images/brown-green-language/graph1.svg" alt="Out of 22 Languages in the combined dreaded/loved list, 63% are Brown"> <!-- ```
import matplotlib.pyplot as plt

labels = 'Brown', 'Green'
dreaded_sizes = [10, 2]
overall_languages = [14, 8]
overall_total = 22
dreaded_total = 12
loved_sizes = [6, 7]
loved_total = 13
explode = (0.1, 0)
colors = ["burlywood", "green"]

fig, ax1 = plt.subplots()
ax1.set_title('Green Vs Brown')
ax1.pie(overall_languages, explode=explode, labels=labels, 
        autopct=lambda p: '{:.0f}'.format(p * overall_total / 100),
        shadow=True, 
        startangle=90, 
        colors=colors)
ax1.axis('equal') 

``` --></p>
<figcaption>
Out of 22 Languages in the combined dreaded/loved list, 63% are Brown
</figcaption>
<div>
<p><strong>Brown Language:</strong> A language that you are more likely to use in existing software maintenance. These projects are often called brown-field projects.</p>
<p>Java, C, C++, C#, Python, PHP, JavaScript, Swift, Perl, Ruby, Assembly, R, Objective-C, SQL</p>
</div>
<div>
<p><strong>Green Language:</strong> A language that you are more likely to use in a new green-field project.</p>
<p>Go, Rust, TypeScript, Kotlin, Julia, Dart, Scala, and Haskell</p>
</div>
<p>TIOBE and StackOverflow have different ideas of what a programming language is. To overcome this, we have to normalize the two lists by removing HTML/CSS, Shell Scripts, and VBA.<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<div>
<p><strong>Removed Language:</strong> Not measured the same by TIOBE and StackOverflow</p>
<p>VBA, Shell, HTML/CSS</p>
</div>
<p>There are many nuances that a simple green / brown split misses - I expect that more green-field projects start with Swift than with Objective-C, but it does seem sufficient to capture what we need. There are far more brown languages in this list than green, but that is what I would expect given that year-on-year turn-over in programming languages is relatively low.</p>
<p>Now we can answer the question: Do people love and dread the languages they state or are they just dreading legacy code? Or to put it another way: If Java and Ruby appeared today, without piles of old rails apps and old enterprise Java applications to maintain, would they still be dreaded or would they be more likely to show up on the loved list?</p>
<h2 id="the-dreaded-brown-programming-languages">The Dreaded Brown Programming Languages</h2>
<figure>
<img src="https://earthly.dev/blog/assets/images/brown-green-language/graph2.svg" alt=""><figcaption>Dreaded Languages: 83% Brown</figcaption>
</figure>
<!-- ```
import matplotlib.pyplot as plt

labels = 'Brown', 'Green'
dreaded_sizes = [10, 2]
overall_languages = [14, 8]
overall_total = 22
dreaded_total = 12
loved_sizes = [6, 7]
loved_total = 13
explode = (0.1, 0)
colors = ["burlywood", "green"]

# Graph one
fig, ax1 = plt.subplots()
ax1.set_title('Dreaded Languages')
ax1.pie(dreaded_sizes, explode=explode, labels=labels, 
        autopct=lambda p: '{:.0f}'.format(p * dreaded_total / 100),
        shadow=True, 
        startangle=90, 
        colors=colors)
ax1.axis('equal') 

```
<figcaption>
Dreaded Languages: 83% Brown
</figcaption> -->
<p>The Top Dreaded languages are almost all are brown languages. 68% of the languages in our complete list are brown, while 83% of the dreaded languages are brown, which is higher than we would expect by chance.</p>
<h2 id="the-loved-green-programming-languages">The Loved Green Programming Languages</h2>
<figure>
<img src="https://earthly.dev/blog/assets/images/brown-green-language/graph3.svg" alt=""><figcaption>Loved Languages 54% Green</figcaption>
</figure>
<!-- ```
import matplotlib.pyplot as plt

labels = 'Brown', 'Green'
dreaded_sizes = [10, 2]
loved_sizes = [5, 8]
explode = (0.1, 0)
colors = ["burlywood", "green"]
total = 13

# Graph two
fig, ax2 = plt.subplots()
ax2.set_title('Loved Languages')
ax2.pie(loved_sizes, explode=explode, labels=labels, 
        autopct=lambda p: '{:.0f}'.format(p * total / 100),
        shadow=True, 
        startangle=90, 
        colors=colors)
ax2.axis('equal') 

```
<figcaption>
Loved Languages 54% Green
</figcaption> -->
<p>In the top loved languages, 54% are green. Only 36% of the languages in our list are green, and every single green language showed up somewhere in the loved list.</p>
<blockquote>
<p>Another flaw in the human character is that everybody wants to build and nobody wants to do maintenance.</p>
<p>― Kurt Vonnegut</p>
</blockquote>
<p>This probably isn’t quite enough evidence to say for sure that having to use a language in a maintenance project causes dread, but it certainly looks like it is a factor. Many of the languages people love are too new or too historically unpopular to have many big big-ball-of-mud projects to maintain.</p>
<p>In other words, Rust, Kotlin, and the other green languages may still be in a honeymoon phase. People’s love for working with them may have as much to do with not working in 20-year-old codebases as it does with the particular languages.</p>
<h2 id="overcoming-bias">Overcoming Bias</h2>
<p><img src="https://earthly.dev/blog/generated/assets/images/brown-green-language/angel-devil-wide-800-cd95144df.png" srcset="https://earthly.dev/blog/generated/assets/images/brown-green-language/angel-devil-wide-400-cd95144df.png 400w, https://earthly.dev/blog/generated/assets/images/brown-green-language/angel-devil-wide-600-cd95144df.png 600w, https://earthly.dev/blog/generated/assets/images/brown-green-language/angel-devil-wide-800-cd95144df.png 800w, https://earthly.dev/blog/generated/assets/images/brown-green-language/angel-devil-wide-1000-cd95144df.png 1000w"></p>
<p>Some newer or historically less popular programming languages might be better than older or more mainstream languages, but our ability to judge seems quite biased. In particular, developers are giving a halo to languages that are newer or were not used commonly in the past, and they are giving horns to languages that have been around longer. I think this is because nobody likes maintaining someone else’s code. And also, because of Joel’s Law: reading real-world is code hard. Building something new is fun, and new languages are used for that more often.</p>
<h2 id="the-lifecycle-of-programming-language-hype">The Lifecycle of Programming Language Hype</h2>
<p>I originally started digging into these numbers to establish a ranking for what languages were most used and loved by software developers. I was going to use this to guide adding more examples to our <a href="https://docs.earthly.dev/">docs</a> and our <a href="https://github.com/earthly/earthly/tree/main/examples">build examples</a>. What I came away with instead was the idea of a programming language life cycle: loved programming languages get used a lot, which leads to code maintenance, which causes people to dislike them, which leads to people looking for greener pastures and trying out a newer language. Popular frameworks probably follow this lifecycle as well.</p>
<div>
<p><img src="https://earthly.dev/blog/generated/assets/images/brown-green-language/hype-wide-800-26e17264b.png" alt="A graph showing hype decreasing overtime for a language" srcset="https://earthly.dev/blog/generated/assets/images/brown-green-language/hype-wide-400-26e17264b.png 400w, https://earthly.dev/blog/generated/assets/images/brown-green-language/hype-wide-600-26e17264b.png 600w, https://earthly.dev/blog/generated/assets/images/brown-green-language/hype-wide-800-26e17264b.png 800w, https://earthly.dev/blog/generated/assets/images/brown-green-language/hype-wide-1000-26e17264b.png 1000w"></p>
<figcaption>
The lifecycle of programming language hype
</figcaption>
</div>
<p>I don’t have data for this, but I distinctly remember Ruby being the hottest language back in 2007, and although it does have more competition today, Ruby is a better language now than it was then. Yet now it is dreaded. Part of the difference, it seems to me, is that now people have 14 years’ worth of rails apps to maintain. That makes Ruby is a lot less fun than when it was all new projects. So watch out Rust and Kotlin and Julia and Go: you too will eventually lose your halo.<a href="#fn4" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn1" role="doc-endnote"><p>2020 <a href="https://insights.stackoverflow.com/survey/2020">Graphical</a> and <a href="https://drive.google.com/file/d/1dfGerWeWkcyQ9GX9x20rdSGj7WtEpzBB/view">Raw</a> results.<a href="#fnref1" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>I came up with the criteria first. I didn’t hunt for data to back up my original idea.</p>
<p>I did consider using language creation date to determine green vs.&nbsp;brown status, but some languages have been around for some time but only found usage relatively recently.</p>
<p>TIOBE is measured like <a href="https://www.tiobe.com/tiobe-index/programming-languages-definition/">this</a> and their historical data is only available if you pay, so I am using the Wayback Machine.<a href="#fnref2" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>TIOBE doesn’t include HTML/CSS because it doesn’t consider them Turing complete and therefore not a programming language. <a href="https://earthly.dev/blog/understanding-bash">Shell scripts</a> are measured separately by TIOBE, and VBA is not in the list of languages measured at all, as far as I can see.<a href="#fnref3" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>Not all brown languages are dreaded however: Python, C#, Swift, JavaScript, and SQL remain loved and I would love to hear if anyone has theories on why. Also <a href="https://earthly.dev/blog/top-5-scala-blogs">Scala</a> and Haskell, two languages I have a soft spot for, are the only green languages on the dreaded list. Is this just noise or is there something else going on there?<a href="#fnref4" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bram Moolenaar Passed Away (3395 pts)]]></title>
            <link>https://groups.google.com/g/vim_announce/c/tWahca9zkt4</link>
            <guid>37011324</guid>
            <pubDate>Sat, 05 Aug 2023 12:23:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://groups.google.com/g/vim_announce/c/tWahca9zkt4">https://groups.google.com/g/vim_announce/c/tWahca9zkt4</a>, See on <a href="https://news.ycombinator.com/item?id=37011324">Hacker News</a></p>
<div id="readability-page-1" class="page"><div jsname="yjbGtf" aria-labelledby="i4" role="region"><p>Dear all, 
</p><p>
It is with a heavy heart that we have to inform you that Bram Moolenaar passed away on 3 August 2023.
<br>Bram was suffering from a medical condition that progressed quickly over the last few weeks.
</p><p>
Bram dedicated a large part of his life to VIM and he was very proud of the VIM community that you are all part of.
</p><p>
We as family are now arranging the funeral service of Bram which will take place in The Netherlands and will be held in the Dutch lanuage. The extact date, time and place are still to be determined.
<br>Should you wish to attend his funeral then please send a message to <a href="" data-email-masked="" rel="nofollow">funer...@gmail.com</a>. This email address can also be used to get in contact with the family regarding other matters, bearing in the mind the situation we are in right now as family.
</p><p>
With kind regards,
<br>The family of Bram Moolenaar
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Espresso coffee mitigates the aggregation of Alzheimer′s associated tau protein (125 pts)]]></title>
            <link>https://pubs.acs.org/doi/10.1021/acs.jafc.3c01072</link>
            <guid>37011291</guid>
            <pubDate>Sat, 05 Aug 2023 12:19:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pubs.acs.org/doi/10.1021/acs.jafc.3c01072">https://pubs.acs.org/doi/10.1021/acs.jafc.3c01072</a>, See on <a href="https://news.ycombinator.com/item?id=37011291">Hacker News</a></p>
Couldn't get https://pubs.acs.org/doi/10.1021/acs.jafc.3c01072: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Intel x86 Documentation Has More Pages Than The 6502 Has Transistors (2013) (221 pts)]]></title>
            <link>http://www.righto.com/2013/09/intel-x86-documentation-has-more-pages.html</link>
            <guid>37010786</guid>
            <pubDate>Sat, 05 Aug 2023 10:49:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.righto.com/2013/09/intel-x86-documentation-has-more-pages.html">http://www.righto.com/2013/09/intel-x86-documentation-has-more-pages.html</a>, See on <a href="https://news.ycombinator.com/item?id=37010786">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-1715214367040078075" itemprop="description articleBody"><p>
Microprocessors have become immensely more complex thanks to Moore's Law, but one thing that has been lost is the ability to fully understand them. The 6502 microprocessor was simple enough that its instruction set could almost be memorized. But now processors are so complex that understanding their architecture and instruction set even at a superficial level is a huge task.
I've been <a href="http://www.righto.com/2013/01/a-small-part-of-6502-chip-explained.html">reverse-engineering parts of the 6502</a>, and with some work you can understand the role of each transistor in the 6502. After studying the x86 instruction set, I started wondering which was bigger: the number of transistors in the 6502 or the number of pages of documentation for the x86.
</p><p>
It turns out that Intel's <a href="http://www.cs.uaf.edu/2011/fall/cs301/intel_x64_megadoc_2011.pdf">Intel® 64 and IA-32 Architectures Software Developer Manuals</a> (2011) have 4181 pages in total, while the 6502 has 3510 transistors. There are actually more pages of documentation for the x86 than the number of individual transistors in the 6502.
</p><p>
<img src="http://static.righto.com/images/6502_overflow/6502_intel-s600.png">
</p><p>
The above photo shows Intel's IA-32 software developer's manuals from 2004 on top of the 6502 chip's schematic. Since then the manuals have expanded to <a href="http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html">7 volumes</a>.
</p><h3>The 6502 has 3510 transistors, or 4528, or 6630, or maybe 9000?</h3>
<p>
As a slight tangent, it's actually hard to define the transistor count of a chip. The 6502 is <a href="https://en.wikipedia.org/wiki/Transistor_count">usually reported</a> as having 3510 transistors. This comes from the <a href="http://visual6502.org/wiki/index.php?title=Chips_in_our_collection">Visual 6502</a> team, which dissolved a 6502 chip in acid, photographed the die (below), traced every transistor in the image, and built a <a href="http://www.visual6502.org/JSSim/">transistor-level simulator</a> that runs 6502 code (which you really should try). Their number is <a href="https://www.youtube.com/watch?v=K5miMbqYB4E">3510</a> <a href="http://www.pagetable.com/?p=401">transistors</a>. 
</p><p>
<a href="http://visual6502.org/images/6502/index.html"> <img src="http://static.righto.com/images/6502_overflow/MOS_6502_layers_top_small-s600.png" title="The 6502 processor chip" alt="The 6502 processor chip"></a>
</p><p>
One complication is the 6502 is built with NMOS logic which builds gates out of active "enhancement" transistors as well as pull-up "depletion" transistors which basically act as resistors. The count of 3510 is just the enhancement transistors. If you include the <del>2102</del> 1018 depletion transistors, the total transistor count is <del>5612</del> 4528.
</p><p>
A second complication is that when manufacturers report the transistor count of chips, they often report "potential" transistors. Chips that include a ROM or PLA will have different numbers of transistors depending on the values stored in the ROM. Since marketing doesn't want to publish different transistor numbers depending on the number of 1 bits and 0 bits programmed into the chip, they often count ROM or PLA sites: places that could have transistors, but might not. By my count, the 6502 <a href="http://visual6502.org/wiki/index.php?title=6507_Decode_ROM">decode PLA</a> has 21×131=2751 PLA sites, of which 649 actually have transistors. Adding these 2102 "potential" transistors yields a count of 6630 transistors.
</p><p>
Finally, some sources such as <a href="https://books.google.com/books?id=ICylixhKK4QC&amp;lpg=PA912&amp;dq=encarta%206502%20transistors%209000&amp;pg=PA912#v=onepage&amp;q=%206502%20transistors%209000&amp;f=false">Microsoft Encarta</a> and <a href="https://books.google.com/books?id=FLabRYnGrOcC&amp;lpg=SA3-PA13&amp;dq=6502%20transistors%209000&amp;pg=SA3-PA13#v=onepage&amp;q=6502%20transistors%209000&amp;f=false">A History of the Personal Computer</a> state the 6502 contains 9000 transistors, but I don't know how they could have come up with that value.
</p><p>
(The number of pages of Intel documentation is also not constant; the latest 2013
<a href="http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html?wapkw=(Intel+Architecture+Software+Developer%E2%80%99s+Manual)91">Software Developer Manuals</a> have shrunk to 3251 pages.)
</p><p>
Thus, the x86 has more pages of documentation than the 6502 has transistors, but it depends how you count.
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[He dropped out to become a poet. now he’s won a Fields Medal (2022) (133 pts)]]></title>
            <link>https://www.quantamagazine.org/june-huh-high-school-dropout-wins-the-fields-medal-20220705/#repost</link>
            <guid>37010709</guid>
            <pubDate>Sat, 05 Aug 2023 10:31:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/june-huh-high-school-dropout-wins-the-fields-medal-20220705/#repost">https://www.quantamagazine.org/june-huh-high-school-dropout-wins-the-fields-medal-20220705/#repost</a>, See on <a href="https://news.ycombinator.com/item?id=37010709">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="postBody"><div><p><span>SERIES</span></p><h2>He Dropped Out to Become a Poet. Now He’s Won a Fields Medal.</h2><div><p>June Huh wasn’t interested in mathematics until a chance encounter during his sixth year of college. Now his profound insights connecting combinatorics and geometry have led to math’s highest honor.</p></div></div><figure><div><p><img alt="June Huh with a polyhedron." src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2022/06/Huh_2880x1620_Lede-scaled.jpg"></p></div><figcaption><div><p>June Huh in his Princeton University office.</p><p data-pm-slice="1 1 []">Caroline Gutman for Quanta Magazine</p></div></figcaption></figure><div><h2>Introduction</h2><div><p>June Huh often finds himself lost. Every afternoon, he takes a long walk around Princeton University, where he’s a professor in the mathematics department. On this particular day in mid-May, he’s making his way through the woods around the nearby Institute for Advanced Study — “Just so you know,” he says as he considers a fork in the path ahead, “I don’t know where we are” — pausing every so often to point out the subtle movements of wildlife hiding beneath leaves or behind trees. Among the animals he spots over the next two hours of wandering are a pair of frogs, a red-crested bird, a turtle the size of a thimble, and a quick-footed fox, each given its own quiet moment of observation.</p>
<p>“I’m very good at finding stuff,” he says. “That’s one of my special abilities.”</p>
<p>Huh, 39, has now been awarded the Fields Medal, the highest honor in mathematics, for his ability to wander through mathematical landscapes and find just the right objects — objects that he then uses to get the seemingly disparate fields of geometry and combinatorics to talk to each other in new and exciting ways. Starting in graduate school, he has solved several major problems in combinatorics, forging a circuitous route by way of other branches of math to get to the heart of each proof. Every time, finding that path is akin to a “little miracle,” Huh said.</p>
<p>One might say the same of his path into mathematics itself: that it was characterized by much wandering and a series of small miracles. When he was younger, Huh had no desire to be a mathematician. He was indifferent to the subject, and he dropped out of high school to become a poet. It would take a chance encounter during his university years — and many moments of feeling lost — for him to find that mathematics held what he’d been looking for all along.</p>

<p>That poetic detour has since proved crucial to his mathematical breakthroughs. His artistry, according to his colleagues, is evident in the way he uncovers those just-right objects at the center of his work, and in the way he seeks a deeper significance in everything he does. “Mathematicians are a lot like artists in that really we’re looking for beauty,” said <a href="https://www.quantamagazine.org/mathematician-federico-ardila-dances-to-the-joys-and-sorrows-of-discovery-20171120/">Federico Ardila-Mantilla</a>, a mathematician at San Francisco State University and one of Huh’s collaborators. “But I think in his case, it’s really pronounced. And I just really like his taste. He makes beautiful things.”</p>
<p>“When I found out that he came to mathematics after poetry, I’m like, OK, this makes sense to me,” Ardila added.</p>
<p>Huh himself draws parallels between the artist and the mathematician. For both, he said, “it feels like you’re grabbing something that’s already there, rather than creating something in your mind.”</p>

<p>On any given day, Huh does about three hours of focused work. He might think about a math problem, or prepare to lecture a classroom of students, or schedule doctor’s appointments for his two sons. “Then I’m exhausted,” he said. “Doing something that’s valuable, meaningful, creative” — or a task that he doesn’t particularly want to do, like scheduling those appointments — “takes away a lot of your energy.”</p>
<p>To hear him tell it, he doesn’t usually have much control over what he decides to focus on in those three hours. For a few months in the spring of 2019, all he did was read. He felt an urge to revisit books he’d first encountered when he was younger — including <em>Meditations</em> by the Roman emperor Marcus Aurelius and several novels by the German author Hermann Hesse — so that’s what he did. “Which means I didn’t do any work,” Huh said. “So that’s kind of a problem.” (He’s since made peace with this constraint, though. “I used to try to resist … but I finally learned to give up to those temptations.” As a consequence, “I became better and better at ignoring deadlines.”)</p>
</div></div><figure><div><p><img alt="Handwritten notes." src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2022/06/Huh_Notes.jpg"></p></div><figcaption><div><p>Huh’s notes from a recent lecture.</p><p data-pm-slice="1 1 []">Caroline Gutman for Quanta Magazine</p></div></figcaption></figure><div><h2>Introduction</h2><div><p>He finds that forcing himself to do something or defining a specific goal — even for something he enjoys — never works. It’s particularly difficult for him to move his attention from one thing to another. “I think intention and willpower … are highly overrated,” he said. “You rarely achieve anything with those things.”</p>
<p>This has been the case since he was young. He was born in 1983 in California, where his parents were finishing graduate school. The family then moved to Seoul, South Korea, when Huh was around 2 years old. There, his father taught statistics, his mother Russian language and literature.</p>
<p>School was excruciating for him. He loved to learn but couldn’t focus or absorb anything in a classroom setting. Instead, he preferred to read on his own — in elementary school, he devoured all 10 volumes of an encyclopedia about living things — and to explore a mountain near his family’s apartment. He quickly became familiar with every corner of it, but he still managed to get lost, one time even ending up in an area that was restricted due to the possible presence of land mines.</p>
<p>He tried his best to avoid math whenever possible. His father once tried to teach him out of a workbook, but rather than try to solve the problems, Huh would copy the solutions from the back. When his father caught on and tore those pages out, Huh went to a local bookstore and wrote down the answers there. “He gave up at that point,” Huh said.</p>
<p>When he was 16 years old and in the middle of his first year in high school (which lasts for three years in South Korea), he decided to drop out to write poetry. He was something of a romantic. “I could literally physically cry after listening to good music,” he said. He wrote about nature and about his own experiences. He planned to complete his masterpiece in the two years before he’d have to attend university. “So that didn’t happen,” he laughed.</p>
<p>He found the writing process too focused on the self — and for him, that exploration was often painful and depressing. Moreover, as he later realized, “I wanted to be someone who writes great poetry,” he said. “I didn’t want to write great poetry.” Now he sees that version of himself as almost a complete stranger.</p>
<p>When he entered Seoul National University in 2002, he felt adrift. He briefly flirted with the idea of being a science writer and decided to major in astronomy and physics. But he frequently skipped class, and he had to retake several courses. “I was just generally lost,” he said. “I didn’t know what I wanted to do. I didn’t know what I was good at.”</p>
<p>It turned out that he was good at math after all — something he discovered entirely by accident.</p>
<h2><strong>True Beauty</strong></h2>
<p>It took Huh six years to graduate. In that sixth year, he enrolled in a class taught by the famed Japanese mathematician Heisuke Hironaka, who <a href="https://www.mathunion.org/imu-awards/fields-medal/fields-medals-1970">won the Fields Medal in 1970</a>. Hironaka was charismatic, and Huh quickly fell under his sway.</p>
<p>But it wasn’t just his professor’s charm that attracted Huh that first day in class. It was also the math itself. Ostensibly, the course was an introduction to algebraic geometry, the study of solutions to algebraic equations and their geometric properties. Instead, Hironaka taught his own work in an area called singularity theory, which focuses on certain types of spaces. “Basically, he lectured about what he thought about yesterday,” Huh said — a very particular problem, and proofs that weren’t necessarily correct. What began as a 200-student class quickly dwindled; a few weeks later, only five students were left, Huh among them.</p>
<p>For the first time, he witnessed research mathematics unfolding in real time. Hironaka’s lectures weren’t polished as in other undergraduate courses, where everything was streamlined, the answers already worked out. Huh loved the suspense of it, the act of trying to do something no one really knew how to do — and the freedom that came with not knowing, the surprises that became possible. The typical material taught in college has been refined over the course of centuries, he said. “That’s very different from observing this raw mathematics in front of your eyes.”</p>
</div></div><figure><div><p><img alt="June Huh sitting outside." src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2022/06/Huh_Garden-scaled.jpg"></p></div><figcaption><div><p>Huh on the Princeton University campus.</p><p data-pm-slice="1 1 []">Caroline Gutman for Quanta Magazine</p></div></figcaption></figure><div><h2>Introduction</h2><div><p>Huh discovered that this kind of mathematics could give him what poetry could not: the ability to search for beauty outside himself, to try to grasp something external, objective and true, in a way that opened him up more than writing ever had. “You don’t think about your small self,” he said. “There’s no place for ego.” He found that unlike when he was a poet, he was never motivated by the desire for recognition. He just wanted to do math.</p>
<p>Hironaka, perhaps recognizing this, took him under his wing. After Huh graduated and started a master’s program at Seoul National University — where he also met Nayoung Kim, now his wife — he spent a lot of time with Hironaka. During breaks, he followed the professor back to Japan, staying with him in Tokyo and Kyoto, carrying his bags, sharing meals, and of course continuing to discuss math.</p>
<h2><strong>An Unexpected Discovery</strong></h2>
<p>Huh applied to about a dozen doctoral programs in the U.S. But because of his undistinguished undergraduate experience, he was rejected by all of them save one. In 2009, he began his studies at the University of Illinois, Urbana-Champaign, before transferring to the University of Michigan in 2011 to complete his doctorate.</p>
<p>Despite the challenges — living in a new country, spending time apart from Kim (she stayed at Seoul National University for her doctorate in mathematics) — Huh cherished his experiences in graduate school. He was able to dedicate himself wholly to math, and he relished the freedom of exploration that had drawn him to the subject in the first place.</p>
<p>He immediately stood out. As a beginning graduate student in Illinois, he <a href="https://www.ams.org/journals/jams/2012-25-03/S0894-0347-2012-00731-0/">proved a conjecture in graph theory</a> that had been open for 40 years. In its simplest form, the problem, known as Read’s conjecture, concerned polynomials — equations like <em>n</em><sup>4</sup> + 5<em>n</em><sup>3</sup> + 6<em>n</em><sup>2</sup> + 3<em>n</em> + 1 — attached to graphs, which are collections of vertices (points) connected by edges (lines). In particular, let’s say you want to color the vertices of a graph so that no two adjacent vertices have the same color. Given a certain number of colors at your disposal, there are many ways to color the graph. It turns out that the total number of possibilities can be calculated using an equation called the chromatic polynomial (which is written in terms of the number of colors being used).</p>
<p>Mathematicians observed that the coefficients of chromatic polynomials, no matter the graph, always seem to obey certain patterns. First, they are unimodal, meaning they increase and then decrease. Take the previous example of a polynomial. The absolute values of its coefficients — 1, 5, 6, 3, 1 — form a unimodal sequence. Moreover, that sequence is also “log concave.” For any three consecutive numbers in the sequence, the square of the middle number is at least as large as the product of the terms on either side of it. (In the above polynomial, for instance, 6<sup>2</sup> ≥ 5 × 3.)</p>

<p>Still, mathematicians struggled to prove these properties. And then, seemingly out of nowhere, along came Huh.</p>
<p>As a master’s student, he had studied algebraic geometry and singularity theory with Hironaka. The main objects of study in that field are called algebraic varieties, which can be thought of as shapes defined by certain equations. Intriguingly, associated to certain kinds of algebraic varieties are numbers that are known to be log concave — something Huh only knew because of the serendipitous direction his studies had taken him in. Huh’s key idea was to find a way to construct an algebraic variety such that those associated numbers were precisely the coefficients of the chromatic polynomial of the graph from the original question.</p>
<p>His solution stunned the math community. It was at that point that the University of Michigan, having rejected his initial application, recruited him to their graduate program.</p>
<p>Huh’s achievement was impressive not just because he had solved Read’s conjecture when it had seemed completely intractable for so long. He had shown that something much deeper — and geometric — was lurking beneath combinatorial properties of graphs.</p>
<p>Mathematicians were also impressed by his demeanor. His talks at conferences were always accessible and concrete; in speaking with him, it was clear that he was thinking both deeply and broadly about the concepts he was working with. “He was ridiculously mature for a graduate student,” said <a href="https://sites.google.com/view/mattbakermath/home/">Matthew Baker</a>, a mathematician at the Georgia Institute of Technology. After Baker met him for the first time, “I was just like, who is this guy?”</p>
<p>According to <a href="http://www-personal.umich.edu/~mmustata/">Mircea Mustaţă</a>, Huh’s adviser at the University of Michigan, he required almost no supervision or guidance. Unlike most graduate students, he already had a program in mind, and ideas about how to pursue it. “He was more like a colleague,” Mustaţă said. “He already had his own way of looking at things.”</p>
<p>Many of his collaborators note that he’s incredibly humble and down-to-earth. When he learned he’d won the Fields Medal, “it didn’t really feel that good,” Huh said. “Of course you are happy, but deep down, you’re a little bit worried that they might eventually figure out that you’re not actually that good. I am a reasonably good mathematician, but am I Fields Medal-worthy?”</p>
<h2><strong>Escape From Space</strong></h2>
<p>Graphs are actually just one type of object that can define more general structures called matroids. Consider, for example, points on a two-dimensional plane. If more than two points lie on a line in this plane, you can say that those points are “dependent.” Matroids are abstract objects that capture notions like dependence and independence in all sorts of different contexts — from graphs to vector spaces to algebraic fields.</p>

<p>Just as graphs have chromatic polynomials associated with them, there are equations called characteristic polynomials attached to matroids. It was conjectured that the polynomials for these more general objects should also have coefficients that are log concave. But the techniques Huh used to prove Read’s conjecture only worked for showing log concavity for a very narrow class of matroids, such as the matroids that arise from graphs.</p>
<p>With the mathematician <a href="https://people.math.osu.edu/katz.60/">Eric Katz</a>, Huh <a href="https://link.springer.com/article/10.1007/s00208-011-0777-6">broadened the class of matroids</a> such a proof could apply to. They followed a recipe of sorts. As before, the strategy was to start with the object of interest — here, a matroid — and use it to construct an algebraic variety. From there, they could extract an object called a cohomology ring and use some of its properties to prove log concavity.</p>
<p>There was just one problem. Most matroids don’t have any sort of geometric foundation, which means there’s not actually an algebraic variety to associate to them. Instead, Huh, Katz and the mathematician <a href="http://www.math.huji.ac.il/~adiprasito/">Karim Adiprasito</a> figured out a way to write down the right cohomology ring straight from the matroid, essentially from scratch. They then showed, using a new set of techniques, that it behaved as if it had come from an actual algebraic variety, even though it hadn’t. In doing so, they proved log concavity for all matroids, <a href="https://www.quantamagazine.org/a-path-less-taken-to-the-peak-of-the-math-world-20170627/">resolving the problem known as Rota’s conjecture</a> once and for all. “It’s pretty remarkable that it works,” Baker said.</p>
<p>The work showed that “you don’t need space to do geometry,” Huh said. “That made me really fundamentally rethink what geometry is.” It would also guide him toward a host of other problems, where he continued to push that idea further, allowing him to develop an even broader range of methods.</p>
<p>But for all the specificity the work requires, building the right cohomology ring requires massive amounts of guesswork and groping around in the dark. It was an aspect of the work that Huh particularly enjoyed. “There is no guiding principle … no clearly defined goal,” he said. “You just have to make a guess.”</p>
</div></div><figure><div><p><img alt="June Huh at a blackboard." src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2022/06/Huh_Blackboard-scaled.jpg"></p></div><figcaption><div><p>Huh’s work involves investigating the properties of matroids. These abstract structures can sometimes arise from geometric objects.</p><p data-pm-slice="1 1 []">Caroline Gutman for Quanta Magazine</p></div></figcaption></figure><div><h2>Introduction</h2><div><p>That lack of intention precisely mirrors how he functions best in his day-to-day life, too. It was as if he’d uncovered a mathematical program that perfectly fit his personality. Once again, he found that “things just happen by themselves,” Huh said.</p>
<h2><strong>The Heart of Things</strong></h2>
<p>Huh speaks slowly, pausing often and choosing his words carefully, and carries himself in a calm, peaceful manner that borders on meditative. “He doesn’t get so easily excited,” said <a href="https://people.math.wisc.edu/~wang/">Botong Wang</a>, a mathematician at the University of Wisconsin, Madison who has collaborated with Huh on a number of important recent results.</p>
<p>He proceeds just as deliberately when doing mathematics. Wang was shocked when he first witnessed it. “I have this math competition experience, that as a mathematician you have to be clever, you have to be fast,” he said. “But June is the opposite. … If you talk to him for five minutes about some calculus problem, you’d think this guy wouldn’t pass a qualifying exam. He’s very slow.” So slow, in fact, that at first Wang thought they were wasting a lot of time on easy problems they already understood. But then he realized that Huh was learning even seemingly simple concepts in a much deeper way — and in precisely the way that would later prove useful.</p>
<p>“June likes to do things in the right way,” said <a href="http://gdenham.math.uwo.ca/">Graham Denham</a>, a mathematician at Western University in Ontario and one of Huh’s collaborators.</p>
<p>For instance, Denham, Ardila and Huh had just completed a 50-page proof of a problem closely related to Rota’s conjecture when Huh said they should take some more time to find a cleaner, more appealing approach. He thought there was a nicer explanation out there, and that it was best not to rush things. “Federico and I were like, oh, OK, so we’ll just chuck that, then, shall we?” Denham said.</p>
<p>It took two years to craft <a href="https://arxiv.org/abs/2004.13116">the better argument</a>. “It’s good we’re all tenured,” Ardila said. Ultimately, though, Ardila and Denham agreed that the extra work was worth it. Their end result “was totally different, and deeper, and [got to] the heart of things,” Ardila said.</p>

<p>This approach doesn’t just apply to Huh’s mathematical work. In 2013, he decided he wanted to learn to cook. As a total beginner, he adopted the strategy of making the same dish — a simple pasta in oil — every day until it was perfect. For six months, that’s exactly what he did. (To date, according to Kim, that’s the only dish he knows how to cook.)</p>
<p>Huh’s entire life is built on routine. “Almost all of my days are exactly the same,” he said. “I have a very high tolerance for repetition.” He has trouble staying asleep and usually wakes up at around 3 a.m. He then goes to the gym, has breakfast with his wife and two sons (one is 8 years old, the other just turned 1), and walks his eldest to school before heading to his Princeton office.</p>
<p>The office is spare, practically empty. There’s a large desk, a couch for sleeping — Huh typically takes a nap later in the morning — and a yoga mat rolled out on the floor (just for lying down, he said; he doesn’t actually know how to do yoga). No books, just a few stacks of papers neatly arranged on a shelf against one wall. In the corner is a vacuum cleaner. Huh likes repetitive, mindless activities like cleaning, dishwashing and the physical act of transcribing what he reads into a notebook.</p>
<p>He often works in the public library, in the children’s section, where it’s pretty noisy. “I don’t like quiet places,” he said. “It makes me sleepy.” Huh says this about many things.</p>
<p>He goes for a long walk after lunch each day, then returns to his office to do some more work (unless he’s already hit his three-hour quota) before heading home. He spends the rest of the evening with his family; they all go to sleep, together in one large bed, at around 9 p.m.</p>
<p>This preference for routine — and the tendency to get exhausted by anything that strays from it — can sometimes manifest in extreme ways. When he was completing his doctorate in Michigan, for instance, “I would cut off almost everything else,” Huh said. When he first moved to Ann Arbor, he found himself unequipped for the brutal winter. He had few belongings, and he needed a blanket. But when he looked up how to get to the local mall, he found it too logistically difficult. “It was just beyond my level of tolerance,” he said. “I did not want to waste my mental energy on figuring out how to go from here to there.” Instead, he walked to a nearby CVS drugstore, bought 10 squares of fabric and a giant stapler, and stapled the squares together to make a blanket.</p>
</div></div><figure><div><p><img alt="June Huh stands between bookshelves." src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2022/06/Huh_Library-scaled.jpg"></p></div><figcaption><div><p>Huh in Princeton’s Lewis Science Library.</p><p data-pm-slice="1 1 []">Caroline Gutman for Quanta Magazine</p></div></figcaption></figure><div><h2>Introduction</h2><div><p>He lived off frozen pizza for months at a time because he didn’t want to deal with getting groceries and cooking. He just wanted to do math. He describes that period of his life as “almost monastic.” In fact, at the time, he really only spoke with another person — Mustaţă, his adviser — once a week.</p>
<p>Kim recalls visiting Huh when he was still in Illinois, and “after that, I really rethought our relationship,” she said. “Should I marry him? Because he [cannot] handle real-life skills, surviving skills.”</p>
<p>Yet marry him she did, in 2014. They moved to Princeton, where they both started work at the Institute for Advanced Study. It was Kim’s first time living in the U.S., and she felt uncomfortable taking care of certain tasks in English; she had to depend on Huh to get things done. “Let’s just say, she was disappointed,” he said.</p>
<p>Later that year, Kim gave birth to their first son, Dan. While in labor, she caught Huh doing math.</p>
<p>“My wife is a much more balanced person than I am,” he said. “Life has very many facets, and math is a very, very, very tiny part of it.”</p>
<p>“I’m a real worker,” Kim said. “He is a thinker.”</p>
<p>But, she added, Huh has improved drastically since then. As the couple raised Dan, “I learned how to live a more balanced life,” Huh said. “That was a transformative period.” He spends a lot of time with Dan — drawing with him, solving problems in intricate math workbooks that Dan creates for him, and taking him to the bookstore and other local spots. He even takes care of the logistical tasks that Kim asks him to do, albeit begrudgingly. “I still don’t like it,” he said, “but I mean, we cannot just live with stapled blankets.”</p>
<p>Now he’s even able to step away from mathematics. His mind no longer returns to working on problems when he’s in an idle state, and he’s able to take a break when something else requires him to.</p>
<p>“He’s a totally different person,” Kim said.</p>
<h2><strong>Heavy on Top</strong></h2>
<p>Regardless, some things haven’t changed. Huh can still muster only enough energy to work for a few hours each day. “Other people work one hour and just take a five-minute rest,” Kim said. “He is like, one hour do something else, and just focus for five minutes, 10 minutes.”</p>
<p>His search for beauty hasn’t changed either. And often he returns to questions about log concavity or similar concepts as a way to unearth that beauty.</p>

<p>For instance, he, Wang and other collaborators recently proved a fundamental problem about configurations of points, lines and planes called the Dowling-Wilson “top-heavy” conjecture. Consider a finite collection of points in the plane, where every pair of points is connected by a line. The mathematicians Paul Erdős and Nicolaas Govert de Bruijn showed that the number of lines must always be greater than or equal to the number of points (unless all the points are located on one line). Consider, for example, four points arranged at the corners of a square. Lines trace out the square and also connect opposite corners, adding up to six lines in total.</p>
<p>The top-heavy conjecture generalizes this idea. Instead of the plane, you’re given a set of points in some high-dimensional space. Consider all the lines that connect pairs of points, the planes spanned by sets of three points, the three-dimensional subspaces constructed from four points, and so on. Now think about a sequence built from these numbers: the number of points, the number of lines, the number of planes. Compare numbers in symmetric positions in that sequence (the first and last numbers, the second and penultimate numbers, and so on). The number corresponding to the higher-dimensional space will be at least as large — that is, the sequence is top-heavy. (This sequence is also conjectured to be log concave, but that has not yet been proved; so far, Huh and Wang have shown that the first half of the sequence is unimodal.)</p>
</div></div><figure><div><p><img alt="" src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2018/07/JH-2-TOP_HEAVY4_1160-Desktop-1.svg"></p></div><figcaption><div><p>Merrill Sherman/Quanta Magazine</p></div></figcaption></figure><div><h2>Introduction</h2><div><p>Huh and Wang adapted ideas from Huh’s work on Rota’s conjecture, but in doing so they had to push his program further. Again, they were working with matroids, algebraic varieties and cohomology rings. But this time the algebraic varieties they had to find involved singularities, places where a space looks different when you zoom in on it than it does at other points. That made it much more complicated to <a href="https://projecteuclid.org/journals/acta-mathematica/volume-218/issue-2/Enumeration-of-points-lines-planes-etc/10.4310/ACTA.2017.v218.n2.a2.full">build the right spaces</a> and prove certain properties about their cohomology rings — and even more difficult to solve the case where they had to construct those rings <a href="https://arxiv.org/abs/2010.06088">straight from the matroids</a>, without algebraic varieties to guide them.</p>
<p>During the five years they spent solving this problem, Huh also started investigating a way to complete the break from geometry. So much of his work until then involved the arduous task of building the exact cohomology that a problem required. Moreover, once that cohomology is found, mathematicians still have to prove that it satisfies certain properties, which can also take years.</p>
</div></div><figure><div><p><img alt="June Huh on a green couch." src="https://d2r55xnwy6nx47.cloudfront.net/uploads/2022/06/Huh_Couch.jpg"></p></div><figcaption><div><p data-pm-slice="1 1 []">Caroline Gutman for Quanta Magazine</p></div></figcaption></figure><div><h2>Introduction</h2><div><p>The new theory that he developed (along with the mathematician <a href="https://www.kth.se/profile/pbranden">Petter Brändén</a>) was able to bypass those methods entirely. It allowed them to <a href="https://annals.math.princeton.edu/2020/192-3/p04">solve a problem</a> called the strong Mason conjecture (which asks questions about the number of independent sets in matroids), and other mathematicians have already used it to re-prove Rota’s conjecture in a more straightforward way. But even more important, it opens the door to finding entirely new problems, hints at an even deeper explanation for why all these log concavity statements are true, and intersects with problems in theoretical computer science in intriguing ways that are just beginning to be explored.</p>
<h2><strong>Click of the Connection</strong></h2>

<p>For Huh, when he is working, there’s something almost subconscious going on. In fact, he usually can’t trace how or when his ideas come to him. He doesn’t have sudden flashes of insight. Instead, “at some point, you just realize, oh, I know this,” he said. Maybe last week, he didn’t understand something, but now, without any additional input, the pieces have clicked into place without his realizing it. He likens it to the way your mind can surprise you and create unexpected connections when you’re dreaming. “It’s just amazing what human minds are capable of,” he said. “And it’s nice to admit that we don’t know what’s going on.”</p>
<p>Perhaps this, too, speaks to the artist in him. He hopes to continue uncovering unexpected connections between different areas of math.</p>
<p>“He just follows the vision of this original program that he had … already as a graduate student,” Baker said. “It will be very interesting to see what the limits are.”</p>
<p>So far, Huh hasn’t hit them. And mathematicians are sure he’ll continue to make beautiful things.</p>
<p>When asked if he’d ever entertain the earlier version of his artist self and try writing poetry again, he shrugged. “Maybe. But I don’t know,” he said. “I’m very much into something else.”</p>
</div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Flux Pinning in sample of LK-99 (272 pts)]]></title>
            <link>https://twitter.com/andercot/status/1687740396691185664</link>
            <guid>37010539</guid>
            <pubDate>Sat, 05 Aug 2023 09:55:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/andercot/status/1687740396691185664">https://twitter.com/andercot/status/1687740396691185664</a>, See on <a href="https://news.ycombinator.com/item?id=37010539">Hacker News</a></p>
Couldn't get https://twitter.com/andercot/status/1687740396691185664: Error [ERR_FR_TOO_MANY_REDIRECTS]: Maximum number of redirects exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[GitHub Actions and vanity metrics (112 pts)]]></title>
            <link>https://jamesconroyfinn.com/github-actions-and-vanity-metrics</link>
            <guid>37010449</guid>
            <pubDate>Sat, 05 Aug 2023 09:37:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jamesconroyfinn.com/github-actions-and-vanity-metrics">https://jamesconroyfinn.com/github-actions-and-vanity-metrics</a>, See on <a href="https://news.ycombinator.com/item?id=37010449">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p>The quality of the modern software craftsperson can be calculated using the following formula:</p>
<p><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>Q</mi><mo>∝</mo><mfrac><mrow><mo stretchy="false">(</mo><mi>s</mi><mi>t</mi><mi>a</mi><mi>r</mi><mi>s</mi><mo>+</mo><mi>d</mi><mi>o</mi><mi>w</mi><mi>n</mi><mi>l</mi><mi>o</mi><mi>a</mi><mi>d</mi><mi>s</mi><mo stretchy="false">)</mo></mrow><mrow><mi>s</mi><mi>l</mi><mi>o</mi><mi>c</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">Q \propto \frac{(stars + downloads)}{sloc}</annotation></semantics></math></span></span></span></p>
<p>What this shows is we need to maximise engagement relative to the amount of code written in order to be recognised as a superstar coder, the fabled 10x developer.</p>
<p>By maximising our quality quotient, we ensure a guaranteed place at the next venture-backed unicorn, where one’s fraction of a point will yield at least double your annual salary in just 10+ years of daily standups, years waiting on CI, a couple of paltry promotions and a minimum four rounds of dilution.</p>
<h2 id="taste-is-everything">Taste is everything</h2>
<p>As we all know, code is a liability that brings with it tedious tests and troublesome tooling. Minor discomforts that ensure the introduction of microservices, event sourcing, and ultimately a large rewrite.</p>
<p>As connoisseurs, we’ll elect for an elegant and succinct language to keep <abbr title="Source lines of code">SLOC</abbr> to a minimum, without having to resort to golfing.</p>
<p>Any language that insists on automated, invisible insertion of semicolons, or that promotes verbosity is immediately out.</p>
<p>APL-family languages rank highly on both expressivity and power, but no one’s going to believe your hexadecimal-to-RGB colour conversion library written in Q has legitimately been downloaded a thousand times this week.</p>
<p>The obvious choice is a Lisp, and to firmly plant a foot in both the highly academic, left-leaning libertarian camp and hyper-corporate, capitalist, FTSE-ranking enterprise, we’ll be going with a Lisp that runs on your favourite flavours of both Java and JavaScript Virtual Machines. That’s right, the equally hip and stable, Clojure.</p>
<h2 id="silicon-minions">Silicon minions</h2>
<p>While the days of free compute subsidised by venture capital are largely behind us, Microsoft do still give away a few minutes of compute each month to all GitHub users, so it’s possible for us to demonstrate our technical chops by infating those all important numbers with a little bit of automation. 🐣🐣🪨</p>
<p>If you don’t already have a couple of small packages that do one thing well, you might fork an established project, rebrand it, and improve it by adding a code of conduct or helpfully reformatting the ugly source code using Prettier. The Clojure codebase itself could be a good starting point for taking your career to the moon.</p>
<p>I’ll use a couple of small libraries I wrote some years ago to propel my rocketship.</p>
<ul>
<li>invetica/media-types</li>
<li>invetica/spec</li>
<li>invetica/uri</li>
</ul>
<p>Our language of choice relies on a package repository owned by <del>Microsoft</del> GitHub. Clojars provides us with handy little badges we can embed in our webpages but these don’t include the all important counters, so we’ll have to team up with Shields.io and relax our <abbr title="Content security policy">CSP</abbr> accordingly.</p>

<p><img alt="invetica/media-types downloads" src="https://img.shields.io/clojars/dt/invetica%2Fmedia-types?label=invetica%2Fmedia-types"><img alt="invetica/spec downloads" src="https://img.shields.io/clojars/dt/invetica%2Fspec?label=invetica%2Fspec"><img alt="invetica/uri downloads" src="https://img.shields.io/clojars/dt/invetica%2Furi?label=invetica%2Furi"></p>
<p>We’ll be making use of GitHub’s scheduled workflows to fetch our unduly ignored packages on the hour. You could choose to do so more frequently, or on a more arcane schedule but who’s got time for cron syntax when you can just <code>sleep</code>.</p>
<p>As this code executes on the backend rather than in the browser, it is written in YAML.</p>
<pre tabindex="0"><code><span><span>on</span><span>:</span></span>
<span><span>  </span><span>workflow_dispatch</span><span>:</span></span>
<span></span>
<span><span>  </span><span>schedule</span><span>:</span></span>
<span><span>    - </span><span>cron</span><span>: </span><span>'0 * * * *'</span></span>
<span></span>
<span><span>jobs</span><span>:</span></span>
<span><span>  </span><span>prepare</span><span>:</span></span>
<span><span>    </span><span>runs-on</span><span>: </span><span>ubuntu-latest</span></span>
<span><span>    </span><span>steps</span><span>:</span></span>
<span><span>      - </span><span>name</span><span>: </span><span>Checkout</span></span>
<span><span>        </span><span>uses</span><span>: </span><span>actions/checkout@v3</span></span>
<span></span>
<span><span>      - </span><span>name</span><span>: </span><span>Prepare java</span></span>
<span><span>        </span><span>uses</span><span>: </span><span>actions/setup-java@v3</span></span>
<span><span>        </span><span>with</span><span>:</span></span>
<span><span>          </span><span>distribution</span><span>: </span><span>'zulu'</span></span>
<span><span>          </span><span>java-version</span><span>: </span><span>'8'</span></span>
<span></span>
<span><span>      - </span><span>name</span><span>: </span><span>Install clojure tools</span></span>
<span><span>        </span><span>uses</span><span>: </span><span>DeLaGuardo/setup-clojure@11.0</span></span>
<span><span>        </span><span>with</span><span>:</span></span>
<span><span>          </span><span>cli</span><span>: </span><span>latest</span></span>
<span></span>
<span><span>      - </span><span>name</span><span>: </span><span>Deep breath</span></span>
<span><span>        </span><span>run</span><span>: </span><span>bin/delay</span></span>
<span></span>
<span><span>      - </span><span>name</span><span>: </span><span>Prepare a selection of delightful dependencies</span></span>
<span><span>        </span><span>run</span><span>: </span><span>bin/prepare</span></span></code></pre>
<p>At this point you’re probably wondering why my steps are so poetically named. Do not forget that code is poetry, and that markup languages like YAML inevitably evolve into Turing-complete interpolated programming environments. Leverage enjambment to pay homage to punch cards.</p>
<p>To fly under the radar of other engineers wary of our meteoric rise, we instruct our silicon slave to take a deep breath before tickling a fellow automaton.</p>
<pre tabindex="0"><code><span><span>#!/usr/bin/env bash</span></span>
<span><span>interval</span><span>=</span><span>`</span><span>shuf</span><span> </span><span>-i</span><span> </span><span>1</span><span>-60 </span><span>-n</span><span> </span><span>1</span><span>`</span></span>
<span><span>echo</span><span> &gt;&amp;2 </span><span>"==&gt; Waiting </span><span>$interval</span><span> seconds..."</span></span>
<span><span>sleep</span><span> </span><span>"</span><span>$interval</span><span>"</span></span></code></pre>
<p>Notice the artisinal use of <code>stderr</code>, combined with adherance to aesthetic tradition in the use of a fat arrow ahead of any annoucement.</p>
<p>The final step in our workflow invokes a mighty virtual machine to execute the most elegant of all programming paradigms: <del>Java</del> Lisp.</p>
<pre tabindex="0"><code><span><span>#!/usr/bin/env bash</span></span>
<span><span>exec</span><span> </span><span>clojure</span><span> </span><span>-M</span><span> </span><span>--report</span><span> </span><span>stderr</span><span> </span><span>--main</span><span> </span><span>vanity.main</span><span> </span><span>deps.edn</span></span></code></pre>
<p>For anyone unfamiliar with Clojure, things are about to get really weird.</p>
<h2 id="teaching-the-cow-to-sing">Teaching the cow to sing</h2>
<p>We begin by defining a set of dependencies using aliases. Aliases allow us to modify the paths used by our mighty virtual machine; paths that include our own source code, third-party dependencies and most importantly first party.</p>
<p>With this separation, we can start nested baby JVMs that conditionally pull additional (or extra in <a href="https://github.com/clojure/tools.deps">tools.deps</a> parlance) dependencies at our behest. One could, of course, trivially pull the full set of awe-inspiring artefacts, but over-engineering a solution is half the fun.</p>
<pre tabindex="0"><code><span><span>{:paths [</span><span>"src"</span><span>]</span></span>
<span></span>
<span><span> :aliases</span></span>
<span><span> {:invetica/media-types</span></span>
<span><span>  {:extra-deps {invetica/media-types {:mvn/version </span><span>"RELEASE"</span><span>}}}</span></span>
<span></span>
<span><span>  :invetica/spec</span></span>
<span><span>  {:extra-deps {invetica/spec {:mvn/version </span><span>"RELEASE"</span><span>}}}</span></span>
<span></span>
<span><span>  :invetica/uri</span></span>
<span><span>  {:extra-deps {invetica/uri {:mvn/version </span><span>"RELEASE"</span><span>}}}}}</span></span></code></pre>
<p>I’m only interested in appearing popular now. What you do in the past is irrelevant in the attention economy, unless you insult a protected group. This justifies my dubious use of <code>"RELEASE"</code> versions to always have the latest, greatest bits fetched on the hour.</p>
<p>With our focus on the immediate, and our set of dependencies neatly compartmentalised by namespace-qualified keyword, it’s time to carefully compose a rigid hymn for a random selection of water-cooled cattle to execute unquestioningly. Suprisingly toasty, the chosen subject will forever more sing our digital praises, guaranteeing a position atop one of the flock of AI unicorns currently grazing their way down Sand Hill Road.</p>
<h2 id="cyclometric-iambic-pentameter">Cyclometric iambic pentameter</h2>
<p>Having spent at least 15 minutes on <a href="http://learnyouahaskell.com/chapters">Learn You a Haskell</a>, one knows best practice is to separate purity from icky IO. We apply this same wisdom to our vanity engine, and begin by extracting the set of keys from our <code>:aliases</code>. An operation we can push to the periphery of our thoroughly over-complicated creation.</p>
<pre tabindex="0"><code><span><span>(</span><span>defn</span><span> read-aliases</span></span>
<span><span>  [path]</span></span>
<span><span>  (</span><span>into</span><span> [] (</span><span>-&gt;</span><span> path slurp edn/read-string :aliases keys)))</span></span></code></pre>
<p>The keen-eyed reader might be wondering why we produce a vector rather than a set. “Duplicate keys in a map will only cause confusion” they yell, holding back the smug grin that would reveal the shallow ego underpinning an endless need to belittle others with their knowledge.</p>
<p>Our execution time will barely register relative to the immense task of indexing docstrings across thousands of namespaces or the absurd amount of work we’re doing over networks shifting bytes. And perhaps we’ll need indexed access to shuffle things around later. As I always like to say, we might gonna need it.</p>
<p>So with our aliases in hand, we can now once again choose to elude engineers (of a similar calibre) who may attempt to thwart our progress by introducing a little randomness.</p>
<pre tabindex="0"><code><span><span>(</span><span>defn</span><span> some-random-shuffle</span></span>
<span><span>  ([aliases]</span></span>
<span><span>   (</span><span>some-random-shuffle</span><span> aliases </span><span>0.5</span><span>))</span></span>
<span><span>  ([aliases prob]</span></span>
<span><span>   (</span><span>-&gt;&gt;</span><span> #(</span><span>random-sample</span><span> prob aliases)</span></span>
<span><span>        repeatedly</span></span>
<span><span>        (</span><span>filter</span><span> seq)</span></span>
<span><span>        first)))</span></span></code></pre>
<p>The statiticians among us will point out that over a long enough period of time, the random sample will be entirely redundant, but the use of threading lazy-sequence operations together is too good to pass up. We do pause, however, to pat ourselves on the back for resisting the temptation to introduce an explicit transduction.</p>
<h2 id="more-than-just-heating-the-room">More than just heating the room</h2>
<p>Finally, we reach our <code>main :: IO</code>! Now we can plumb together the pure and impure in a beautifully testable cacophony of bytecodes and CPU instructions.</p>
<pre tabindex="0"><code><span><span>(</span><span>defn</span><span> -main</span></span>
<span><span>  [path]</span></span>
<span><span>  (</span><span>let</span><span> [aliases (</span><span>-&gt;</span><span> path read-aliases some-random-shuffle)</span></span>
<span><span>        cmd     (</span><span>prepare-cmd</span><span> aliases)</span></span>
<span><span>        result  (</span><span>apply</span><span> sh/sh cmd)]</span></span>
<span><span>    (</span><span>pprint</span><span> {:aliases aliases</span></span>
<span><span>             :cmd     cmd</span></span>
<span><span>             :result  result})</span></span>
<span><span>    (</span><span>System/exit</span><span> (:exit result))))</span></span></code></pre>
<p>A proud, parent JVM spawning a brand new baby JVM. New life — two generations of virtual minions birthed into this world, short-lived, with the sole purpose of satisfying the unending human need for recognition. We have done something wonderful here today.</p>
<p>And with that, we refresh the all mighty page, only to see the same number as before because someone decided to cache the counters. We must wait until tomorrow to see 319 become 405.</p>
<h2 id="gimme-kiss">Gimme kiss 😘</h2>
<p>In our pursuit of professional recognition we’ve had to familiarise ourselves with GitHub workflows, some POSIX shell, a dash of Clojure, the JVM and its classpath, and to really spice things up, I threw in some Emacs, Org-mode, Docker and Nix.</p>
<pre tabindex="0"><code><span><span>alias</span><span> </span><span>curiosity</span><span>=kill</span></span>
<span><span>cat</span><span> &amp; ; </span><span>curiosity</span><span> </span><span>$!</span></span></code></pre>
<p>If you’re in a hurry and want to keep things simple, you can accomplish the same feat with this single invocation of <code>clojure</code>:</p>
<pre tabindex="0"><code><span><span>clojure</span><span> </span><span>-P</span><span> </span><span>-Sdeps</span><span> </span><span>\</span></span>
<span><span>'{:deps</span></span>
<span><span>  {invetica/media-types {:mvn/version "RELEASE"}</span></span>
<span><span>   invetica/spec        {:mvn/version "RELEASE"}</span></span>
<span><span>   invetica/uri         {:mvn/version "RELEASE"}}}'</span></span></code></pre>
<p>But where’s the fun in that‽</p>
<p>For a working example that’s no longer scheduled to ensure my success, visit <a href="https://github.com/jcf/vanity">Microsoft forge</a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[WASI: WebAssembly System Interface (105 pts)]]></title>
            <link>https://github.com/WebAssembly/WASI</link>
            <guid>37010196</guid>
            <pubDate>Sat, 05 Aug 2023 08:45:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/WebAssembly/WASI">https://github.com/WebAssembly/WASI</a>, See on <a href="https://news.ycombinator.com/item?id=37010196">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><p dir="auto"><a href="https://doi.org/10.5281/zenodo.4323447" rel="nofollow"><img src="https://camo.githubusercontent.com/968b57157bc1ae57a965f38fa2fd266cc458f510dc81413e4482d8c8484bf054/68747470733a2f2f7a656e6f646f2e6f72672f62616467652f444f492f31302e353238312f7a656e6f646f2e343332333434372e737667" alt="DOI" data-canonical-src="https://zenodo.org/badge/DOI/10.5281/zenodo.4323447.svg"></a></p>
<h2 tabindex="-1" dir="auto">WebAssembly System Interface</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/WebAssembly/WASI/blob/main/WASI.png"><img src="https://github.com/WebAssembly/WASI/raw/main/WASI.png" alt="WASI"></a></p>
<p dir="auto">The WebAssembly System Interface is not a monolithic standard system interface,
but is instead a modular collection of standardized APIs. None of the APIs are
required to be implemented to have a compliant runtime. Instead, host
environments can choose which APIs make sense for their use cases.</p>
<hr>
<h2 tabindex="-1" dir="auto">Important Note: WASI is in transition</h2>
<p dir="auto">WASI is transitioning away from the <code>witx</code> format and its early experimental ABI. We are transitioning to Interface Types using the <code>wit</code> format and the canonical ABI.</p>
<p dir="auto">All new API proposals should use the new format and the new repo structure that is shown in the <a href="https://github.com/WebAssembly/wasi-proposal-template">proposal template</a>.</p>
<p dir="auto">See the <a href="https://github.com/WebAssembly/WASI/blob/main/docs/WitInWasi.md">Wit in WASI</a> document for more information about using Wit for WASI proposals.</p>
<hr>
<h2 tabindex="-1" dir="auto">Find the APIs</h2>
<p dir="auto">Development of each API happens in its own repo, which you can access
from the <a href="https://github.com/WebAssembly/WASI/blob/main/Proposals.md">proposals list</a>.</p>
<p dir="auto">This repo is for general discussion, as well as documenting how we work
and high-level goals.</p>
<h2 tabindex="-1" dir="auto">Propose a new API</h2>
<p dir="auto">If you would like to create a new proposal, get started with our
<a href="https://github.com/WebAssembly/WASI/blob/main/Contributing.md">Contributing guide</a>.</p>
<h2 tabindex="-1" dir="auto">WASI High Level Goals</h2>
<p dir="auto">(In the spirit of <a href="https://github.com/WebAssembly/design/blob/main/HighLevelGoals.md">WebAssembly's High-Level Goals</a>.)</p>
<ol dir="auto">
<li>Define a set of portable, modular, runtime-independent, and
WebAssembly-native APIs which can be used by WebAssembly code to interact
with the outside world. These APIs preserve the essential sandboxed nature of
WebAssembly through a <a href="https://en.wikipedia.org/wiki/Capability-based_security" rel="nofollow">Capability-based</a> API design.</li>
<li>Specify and implement incrementally. Start with a Minimum Viable Product
(MVP), then adding additional features, prioritized by feedback and
experience.</li>
<li>Supplement API designs with documentation and tests, and, when feasible,
reference implementations which can be shared between wasm engines.</li>
<li>Make a great platform:
<ul dir="auto">
<li>Work with WebAssembly tool and library authors to help them provide
WASI support for their users.</li>
<li>When being WebAssembly-native means the platform isn't directly
compatible with existing applications written for other platforms,
design to enable compatibility to be provided by tools and libraries.</li>
<li>Allow the overall API to evolve over time; to make changes to API
modules that have been standardized, build implementations of them
using libraries on top of new API modules to provide compatibility.</li>
</ul>
</li>
</ol>
<h2 tabindex="-1" dir="auto">WASI Design Principles</h2>
<h3 tabindex="-1" dir="auto">Capability-based security</h3>
<p dir="auto">WASI is designed with capability-based security principles, using the
facilities provided by the Wasm <a href="https://github.com/WebAssembly/component-model">component model</a>. All access to external
resources is provided by capabilities.</p>
<p dir="auto">There are two kinds of capabilities:</p>
<ul dir="auto">
<li>
<p dir="auto">Handles, defined in the <a href="https://github.com/WebAssembly/component-model/blob/main/design/mvp/Explainer.md#type-definitions">component-model type system</a>, dynamically
identify and provide access to resources. They are unforgeable, meaning
there's no way for an instance to acquire access to a handle other than
to have another instance explicitly pass one to it.</p>
</li>
<li>
<p dir="auto">Link-time capabilities, which are functions which require no handle
arguments, are used sparingly, in situations where it's not necessary
to identify more than one instance of a resource at runtime. Link-time
capabilities are <em>interposable</em>, so they are still refusable in a
capability-based security sense.</p>
</li>
</ul>
<p dir="auto">WASI has no <em>ambient authorities</em>, meaning that there are no global
namespaces at runtime, and no global functions at link time.</p>
<p dir="auto">Note that this is a different sense of "capability" than <a href="http://man7.org/linux/man-pages/man7/capabilities.7.html" rel="nofollow">Linux
capabilities</a>
or the withdrawn <a href="https://archive.org/details/posix_1003.1e-990310" rel="nofollow">POSIX
capabilities</a>, which
are per-process rather than per-resource.</p>
<h3 tabindex="-1" dir="auto">Interposition</h3>
<p dir="auto">Interposition in the context of WASI interfaces is the ability for a
Webassembly instance to implement a given WASI interface, and for a
consumer WebAssembly instance to be able to use this implementation
transparently. This can be used to adapt or attenuate the functionality
of a WASI API without changing the code using it.</p>
<p dir="auto">Component model interfaces always support link-time interposition. While
WASI APIs are often implemented in hosts, they can also be implemented
in Wasm, which may itself be a wrapper around the host. This may be used
to implement <em>attenuation</em>, providing filtered access to the underlying
host-provided functionality.</p>
<p dir="auto">Interposition is sometimes referred to as "virtualization", however we
use "interposition" here because the word "virtualization" has several
related meanings.</p>
<h3 tabindex="-1" dir="auto">Compatibility</h3>
<p dir="auto">Compatibility with existing applications and libraries, as well as
existing host platforms, is important, but will sometimes be in conflict
with overall API cleanliness, safety, performance, or portability.
Where practical, WASI seeks to keep the WASI API itself free of
compatibility concerns, and provides compatibility through libraries,
such as WASI libc, and tools. This way, applications which don't require
compatibility for compatibility's sake aren't burdened by it.</p>
<h3 tabindex="-1" dir="auto">Portability</h3>
<p dir="auto">Portability is important to WASI, however the meaning of portability
will be specific to each API.</p>
<p dir="auto">WASI's modular nature means that engines don't need to implement every
API in WASI, so we don't need to exclude APIs just because some host
environments can't implement them. We prefer APIs which can run across
a wide variety of engines when feasible, but we'll ultimately decide
whether something is "portable enough" on an API-by-API basis.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lazygit Turns 5: Musings on Git, TUIs, and Open Source (181 pts)]]></title>
            <link>https://jesseduffield.com/Lazygit-5-Years-On/</link>
            <guid>37009879</guid>
            <pubDate>Sat, 05 Aug 2023 07:39:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jesseduffield.com/Lazygit-5-Years-On/">https://jesseduffield.com/Lazygit-5-Years-On/</a>, See on <a href="https://news.ycombinator.com/item?id=37009879">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p><img src="https://jesseduffield.com/images/posts/lazygit-5/basic-gif.gif" alt=""></p>

<p><em>This post is brought to you by my sponsors. If you would like to support me, consider becoming a <a href="https://github.com/sponsors/jesseduffield">sponsor</a></em></p>

<p><img src="https://jesseduffield.com/images/posts/lazygit-5/sponsors.png" alt=""></p>

<p><a href="https://github.com/jesseduffield/lazygit">Lazygit</a>, the world’s <em>coolest</em> terminal UI for git, was released to the world on August 5 2018, five years ago today. I say <em>released</em> but I really mean <em>discovered</em>, because I had taken a <a href="https://www.reddit.com/r/webdev/comments/90ux3f/lazygit_a_terminal_ui_application_for_git/">few</a> <a href="https://www.facebook.com/groups/319479604815804/?multi_permalinks=1819232401507176">stabs</a> at publicising it in the weeks prior which fell on deaf ears. When I eventually posted to Hacker News I was so sure nothing would come of it that I had already forgotten about it by that afternoon, so when I received an email asking what license the code fell under I was deeply confused. And then the journey began!</p>

<p>In this post I’m going to dive into a bunch of topics directly or tangetially related to Lazygit. In honour of the Hacker News commenters whose flamewar over git UIs vs the git CLI likely boosted the debut post to the frontpage, I’ve been sure to include plenty of juicy hot-takes on various topics I’m underqualified to comment on. It’s a pretty long post so feel free to pick and choose whatever topics interest you.</p>

<p>Contents:</p>
<ul>
  <li><a href="#where-are-we-now">Where are we now?</a></li>
  <li><a href="#lessons-learnt">Lessons learnt</a></li>
  <li><a href="#what-comes-next">What comes next?</a></li>
  <li><a href="#is-git-even-that-good">Is git even that good?</a></li>
  <li><a href="#weighing-in-on-the-cli-ui-debate">Weighing in on the CLI vs UI debate</a></li>
  <li><a href="#weighing-in-on-the-terminal-renaissance">Weighing in on the terminal renaissance</a></li>
  <li><a href="#credits">Credits</a></li>
</ul>

<h2 id="where-are-we-now">Where are we now?</h2>

<h3 id="stars">Stars</h3>

<p><img src="https://jesseduffield.com/images/posts/lazygit-5/stars.png" alt=""></p>

<p>Lazygit has 37 thousand stars on GitHub, placing it at rank <a href="https://evanli.github.io/Github-Ranking/Top100/Go.html">26</a> in terms of Go projects and rank <a href="https://gitstar-ranking.com/jesseduffield/lazygit">263</a> across all git repos globally.</p>

<p>What’s the secret? The number one factor (I hope) is that people actually like using Lazygit enough to star the repo. But there were two decisions I made that have nothing to do with the app itself that I think helped.</p>

<p>Firstly, I don’t have a standalone landing page site or docs site. I keep everything in the repo, which means you’re always one click away from starring. You can add a GitHub star button to your external site, but it doesn’t actually star the repo; it just links to the repo and it’s up to you to realise that you actually need to press the star button again. I suspect that is a big deal.</p>

<p>Secondly, Lazygit shows a popup when you first start it which at the very bottom suggests staring the repo:</p>

<div><pre><code>Thanks for using lazygit! Seriously you rock. Three things to share with you:

 1) If you want to learn about lazygit's features, watch this vid:
    https://youtu.be/CPLdltN7wgE

 2) Be sure to read the latest release notes at:
    https://github.com/jesseduffield/lazygit/releases

 3) If you're using git, that makes you a programmer! With your help we can
    make lazygit better, so consider becoming a contributor and joining the fun at
    https://github.com/jesseduffield/lazygit
    You can also sponsor me and tell me what to work on by clicking the donate
    button at the bottom right.
    Or even just star the repo to share the love!
</code></pre></div>

<p>I know this all sounds machiavellian but at the end of the day, a high star count lends credibility to your project which makes users more likely to use it, and that leads to more contributors, which leads to more features, creating a virtuous cycle.</p>

<p>It’s important to note that GitHub stars don’t necessarily track real world popularity: <a href="https://github.com/magit/magit">magit</a>, the de facto standard git UI for emacs, has only 6.1k stars but has north of <a href="https://melpa.org/#/?q=magit&amp;sort=downloads&amp;asc=false">3.8 million downloads</a> which as you’ll see below blows Lazygit out of the water.</p>

<h3 id="downloads">Downloads</h3>

<p>Downloads are harder to measure than stars because there are so many sources from which to download Lazygit, and I don’t have any telemetry to lean on.</p>

<p><a href="https://github.com/jesseduffield/lazygit">GitHub</a> tells me we’ve had 359k total direct downloads.</p>

<p><a href="https://pkgstats.archlinux.de/packages/lazygit">4.6%</a> of Arch Linux users have installed Lazygit.</p>

<p>Homebrew ranks Lazygit at <a href="https://formulae.brew.sh/analytics/install-on-request/365d/">294th</a> (two below emacs) with 15k installs-on-request in the last year (ignoring the tap with 5k of its own). For comparison <code>tig</code>, the incumbent standalone git TUI at the time of Lazygit’s creation, ranks at 480 with 8k installs.</p>

<p>I’m torn on how to interpret these results: being in the top 300 in Homebrew is pretty cool, but 15k installs feels lower than I would expect for that ranking. On the other hand, having almost 1 in 20 Arch Linux users using Lazygit seems huge.</p>

<h2 id="lessons-learnt">Lessons Learnt</h2>

<p>I’ve maintained Lazygit for 5 years now and it has been a wild ride. Here’s some things I’ve learnt.</p>

<h3 id="ask-for-help">Ask for help</h3>

<p>I don’t know why this didn’t occur to me sooner, but there is something unique and magical about writing open source software whose users are developers: any developer who raises an issue has the capacity to fix the issue themselves. All you need to do is ask! Simply asking ‘are you up to the challenge of fixing this yourself?’ and offering to provide pointers goes a long way.</p>

<p>I’ve gotten better over time at identifying easy issues and labelling them with the good-first-issue label so that others can help out, with a chance of becoming regular contributors.</p>

<h3 id="get-feedback">Get feedback</h3>

<p>If your repo is popular enough, you’ll get plenty of feedback through the issues board. But issues are often of the form ‘this is a problem that needs fixing’ or ‘this is a feature that should be added’ and the demand for rigour is a source of friction. There are other ways you can reduce the friction on getting feedback. I pinned a google form to the top of the issues page to get general feedback on what people like/dislike about Lazygit.</p>

<p><img src="https://jesseduffield.com/images/posts/lazygit-5/survey-dislike.png" alt=""></p>

<p>Something that the google form made clear was that people wanted to know what commands were being run under the hood, so I decided to add a command log (shown by default) that would tell you which commands were being run. This made a huge difference and it’s now one of the things people like best about Lazygit.</p>

<p><img src="https://jesseduffield.com/images/posts/lazygit-5/survey-contribute.png" alt=""></p>

<p>Something that surprised me was how big of a barrier the language of the project is in deciding whether somebody contributes. And <em>Go</em> of all languages: the one that’s intended to be dead-easy to pick up. Maybe I need to do a rewrite in javascript to attract more contributors ;)</p>

<h3 id="mvp-is-the-mvp">MVP is the MVP</h3>

<p>This is not much a ‘lesson learnt’ as it was a ‘something I got right’. When I first began work on Lazygit I had a plan: hit MVP (Minimum Viable Product) and then release it to the world to see if the world had an appetite for it. The MVP was pretty basic: allow staging files, committing, checking out branches, and resolving merge conflicts. But it was enough to satisfy my own basic needs at the time and it was enough for many others as well. Development was accelerated post-release thanks to some early contributors who joined the team (shoutout to Mark Kopenga, Dawid Dziurla, Glenn Vriesman, Anthony Hamon, David Chen, and other OG contributors). This not only sped up development but I personally learned a tonne in the process.</p>

<h3 id="tech-debt-is-a-perennial-threat">Tech debt is a perennial threat</h3>

<p>In your day job, tech debt is to be expected: there are deadlines and customers to appease and competitors to race against. In open source, then, you would think that the lack of urgency would mean less tech debt. But I’ve found that where time is the limiting factor at my day job, motivation is the limiting factor in my spare time, and the siren song of tech debt is just as alluring. Does anybody want to spend their weekend writing a bunch of tests? Does anybody want to spend a week of annual leave on a mind-numbing refactoring? Not me, but I have done those things in order to improve the health of the codebase (and there is <em>still</em> much to improve upon).</p>

<p>Thankfully, open source has natural incentives against tech debt that are absent from proprietary codebases. Firstly, if your codebase sucks, nobody will want to contribute to it. Contrast this to a company where no matter how broken and contemptible a codebase is, there is an amount you can pay a developer to endure it.</p>

<p>Secondly, because your code is public, anybody who considers hiring you in the future can skim through it to get a feel for whether you suck or not. You want your codebase to be a positive reflection on your own skills and values.</p>

<p>So, tech debt is still a problem, but for different reasons than in a proprietary codebase.</p>

<h3 id="get-your-testing-patterns-right-as-soon-as-possible">Get your testing patterns right as soon as possible</h3>

<p>The sooner you get a good test pattern in place with good coverage, the easier life will be.</p>

<p>In the beginning, I was doing manual regression tests before releasing each feature. Although I had unit tests, they didn’t inspire much confidence, and I had no end-to-end tests. Later on I introduced a framework based on recorded sessions: each test would have a bash script to prepare a repo, then you would record yourself doing something in Lazygit, and the resultant repo would be saved as a snapshot to compare against when the test was run and the recording was played back. This was great for writing tests but terrible for maintaining them. Looking at a minified JSON containing a sequence of keypresses, it was impossible to glean the intent, and the only way to make a change to the test was to re-record it.</p>

<p>I’ve spent a lot of time working on an end-to-end test framework where you define your tests with code, and although I still shiver thinking about the time it took to migrate from the old framework to the new one, every day I see evidence that the effort was worth it. Contributors find it easy to write the tests and I find it easy to read them which tightens the pull request feedback loop.</p>

<p>Here’s an example to give you an idea:</p>

<div><pre><code><span>// We call them 'integration tests' but they're really end-to-end tests.</span>
<span>var</span> <span>RewordLastCommit</span> <span>=</span> <span>NewIntegrationTest</span><span>(</span><span>NewIntegrationTestArgs</span><span>{</span>
	<span>Description</span><span>:</span>  <span>"Rewords the last (HEAD) commit"</span><span>,</span>
	<span>SetupRepo</span><span>:</span> <span>func</span><span>(</span><span>shell</span> <span>*</span><span>Shell</span><span>)</span> <span>{</span>
		<span>shell</span><span>.</span>
			<span>CreateNCommits</span><span>(</span><span>2</span><span>)</span>
	<span>},</span>
	<span>Run</span><span>:</span> <span>func</span><span>(</span><span>t</span> <span>*</span><span>TestDriver</span><span>,</span> <span>keys</span> <span>config</span><span>.</span><span>KeybindingConfig</span><span>)</span> <span>{</span>
		<span>t</span><span>.</span><span>Views</span><span>()</span><span>.</span><span>Commits</span><span>()</span><span>.</span>
			<span>Focus</span><span>()</span><span>.</span>
			<span>Lines</span><span>(</span>
				<span>Contains</span><span>(</span><span>"commit 02"</span><span>)</span><span>.</span><span>IsSelected</span><span>(),</span>
				<span>Contains</span><span>(</span><span>"commit 01"</span><span>),</span>
			<span>)</span><span>.</span>
			<span>Press</span><span>(</span><span>keys</span><span>.</span><span>Commits</span><span>.</span><span>RenameCommit</span><span>)</span><span>.</span>
			<span>Tap</span><span>(</span><span>func</span><span>()</span> <span>{</span>
				<span>t</span><span>.</span><span>ExpectPopup</span><span>()</span><span>.</span><span>CommitMessagePanel</span><span>()</span><span>.</span>
					<span>Title</span><span>(</span><span>Equals</span><span>(</span><span>"Reword commit"</span><span>))</span><span>.</span>
					<span>InitialText</span><span>(</span><span>Equals</span><span>(</span><span>"commit 02"</span><span>))</span><span>.</span>
					<span>Clear</span><span>()</span><span>.</span>
					<span>Type</span><span>(</span><span>"renamed 02"</span><span>)</span><span>.</span>
					<span>Confirm</span><span>()</span>
			<span>})</span><span>.</span>
			<span>Lines</span><span>(</span>
				<span>Contains</span><span>(</span><span>"renamed 02"</span><span>),</span>
				<span>Contains</span><span>(</span><span>"commit 01"</span><span>),</span>
			<span>)</span>
	<span>},</span>
<span>})</span>
</code></pre></div>

<p>I wish I had come up with that framework from the get-go: it would have saved me a lot of time fixing bugs and migrating tests from the old framework.</p>

<h2 id="what-comes-next">What comes next?</h2>

<p>If I could flick my wrist and secure funding to go fulltime on Lazygit I’d do it in a heartbeat, but given the limited time available, things move slower than I would like. Here are some things I’m excited for:</p>

<ul>
  <li>Bulk actions (e.g. moving multiple commits at once in a rebase)</li>
  <li>Repo actions (e.g. pulling in three different repos at once)</li>
  <li>Better integration with forges (github, gitlab) (e.g. view PR numbers against branches)</li>
  <li>Improved diff functionality</li>
  <li>More flexibility in deciding which args are used in a command</li>
  <li>More performance improvements</li>
  <li>A million small enhancements</li>
</ul>

<p>I’ve just wrapped up worktree support, and my current focus is on improving documentation.</p>

<p>If you want to be part of what comes next, join the team! There are plenty of <a href="https://github.com/jesseduffield/lazygit/issues?q=is%3Aissue+is%3Aopen+sort%3Aupdated-desc">issues</a> to choose from and we’re always up to chat in the <a href="https://discord.gg/ehwFt2t4wt">discord channel</a>.</p>

<p>Okay, you’ve listened to me ramble about me and my project for long enough. Now onto the juicy stuff.</p>

<h2 id="is-git-even-that-good">Is git even that good?</h2>

<p>I’m not old enough to compare git with its predecessors, and from what I’ve heard from those who <em>are</em> old enough, it was a big improvement.</p>

<p>There are many who criticize git for being unnecessarily complex, in part due to its original purpose in serving the needs of linux development. <a href="https://www.fossil-scm.org/home/doc/trunk/www/fossil-v-git.wiki#history">Fossil</a> is a recent git alternative that optimises for simplicity; serving the needs of small, high-trust teams. I disagree with a few of its <a href="https://www.fossil-scm.org/home/doc/trunk/www/fossil-v-git.wiki#history">design choices</a>, but it might be perfect for you!</p>

<p>My beef with git is not so much its complexity (I’m fine dealing with multiple remotes and the worktree/index distinction) but its UX, including:</p>
<ul>
  <li>lacking high-level commands</li>
  <li>no undo feature</li>
  <li>merge conflicts aren’t first-class</li>
</ul>

<h3 id="lacking-high-level-commands">Lacking high-level commands</h3>

<p>Consider the common use case of ‘remove this file from my git status output’. Depending on the state of the file, the required command is different: for untracked files you do <code>rm &lt;path&gt;</code>, for tracked it’s <code>git checkout -- &lt;path&gt;</code>, and for staged files it’s <code>git reset -- &lt;path&gt; &amp;&amp; git checkout -- &lt;path&gt;</code>. One of the reasons I made Lazygit was so that I could press ‘d’ on a file in a ‘changed files’ view and have it just go away.</p>

<h3 id="no-undo-feature">No undo feature</h3>

<p>Git should have an undo feature, and it should support undoing changes to the working tree. Although Lazygit has an undo feature, it depends on the reflog, so we can’t undo anything specific to the working tree. If git treated the working tree like its own commit, we would be able to undo pretty much anything.</p>

<h3 id="merge-conflicts-arent-first-class">Merge conflicts aren’t first class</h3>

<p>I also dislike how merge conflicts aren’t first-class: when they show up you have to choose between resolving all of them or aborting an entire rebase (which may have involved other conflicts), and you can’t easily switch to another task mid-conflict (though worktrees make this easier).</p>

<p>One project that addresses these concerns is <a href="https://github.com/martinvonz/jj">Jujutsu</a>. I <em>highly</em> recommend reading through its readme to realise how many problems you took for granted and how a few structural tweaks can provide a much better experience.</p>

<p>Unlike Fossil which trades power for simplicity, Jujutsu feels more like a reboot of git, representing what git <em>could</em> have been from the start. It’s especially encouraging that Jujutsu can use git as a backend. I hope that regardless of Jujutsu’s success, git incorporates some of its ideas.</p>

<h2 id="weighing-in-on-the-cli-ui-debate">Weighing in on the CLI-UI debate</h2>

<p>If my debut hacker news post hadn’t sparked a flamewar on the legitimacy of git UIs, it probably would have gone unnoticed and Lazygit would have been relegated to obscurity forever. So thanks, <a href="https://slatestarcodex.com/2014/07/30/meditations-on-moloch/">Moloch</a>!</p>

<p>I’ve had plenty of time to think about this endless war and I have a few things to say.</p>

<p>Here are the main arguments against using git UIs:</p>
<ul>
  <li>git UIs sometimes do things you didn’t expect which gets you in trouble</li>
  <li>git UIs rarely give you everything you need and you will sometimes need to fall back to the command line</li>
  <li>git UIs make you especially vulnerable when you do need to use the CLI</li>
  <li>git UIs obscure what’s really happening</li>
  <li>The CLI is faster</li>
</ul>

<p>I’m going to address each of these points.</p>

<h3 id="git-uis-sometimes-do-things-you-didnt-expect">Git UIs sometimes do things you didn’t expect</h3>

<p>This is plainly true. Lazygit works around this by logging all the git commands that it runs so that you know what’s happening under the hood. Also, over time, lazygit’s ethos has changed to be less about compensating for git’s shortcomings via magic and more making it easier to do the things that you can naturally do in git, which means there are fewer surprises.</p>

<h3 id="git-uis-dont-cover-the-full-api">Git UIs don’t cover the full API</h3>

<p>This is indeed an issue. However, as a git UI matures, it expands to cover more and more of git’s API (until you end up like magit). And the fact you need to fall back to git is not really a point against the UI: when given the choice between using the CLI 100% of the time and using it 1% of the time, I pick the latter. If you forgive the shameless plug (is it really a plug given the topic of the post?) Lazygit also works around this with a pretty cool <a href="https://github.com/jesseduffield/lazygit/wiki/Custom-Commands-Compendium">custom commands system</a> that lets you invoke that bespoke git command from the UI; making use of the selection state to spare you from typing everything out yourself.</p>

<h3 id="git-uis-make-you-vulnerable-when-you-need-to-use-the-cli">Git UIs make you vulnerable when you need to use the CLI</h3>

<p>I’ve conceded the first two points. Now I go to war.</p>

<p>What people envision with a seasoned CLI user is that they come across some situation they haven’t seen before and using their strong knowledge of the git API and the git object model they craft an appropriate solution. The reality that I’ve experienced is that you instead just look for the answer on stack overflow, copy+paste, and then forget about it until next time when you google it again. With the advent of ChatGPT this will increasingly become the norm.</p>

<p>Whenever a new technology comes along that diminishes the need for the previous one, there are outcries that it will make everybody dumber. Socrates was famously suspicious of the impact that writing would have on society, <a href="http://www.perseus.tufts.edu/hopper/text?doc=Perseus%3Atext%3A1999.01.0174%3Atext%3DPhaedrus%3Apage%3D275">saying</a>:</p>
<blockquote>
  <p>Their trust in writing, produced by external characters which are no part of themselves, will discourage the use of their own memory within them. You have invented an elixir not of memory, but of reminding; and you offer your pupils the appearance of wisdom, not true wisdom, for they will read many things without instruction and will therefore seem to know many things, when they are for the most part ignorant…</p>
</blockquote>

<p>The argument perfectly applies to UIs, and is just as misguided. The truth is that some people have good memory and some people (i.e. me) have shockingly bad memory and it has little to do with technology (unless the technology is hard drugs in which case yes that does make a difference). I think that many debates about UX are actually debates between people with differing memory ability who therefore have different UX needs. UIs make things more discoverable so you don’t need to remember as much, and people with shocking memory who stick to the git CLI have no guarantee of actually remembering any of it. Yes, all abstractions are leaky, but that doesn’t mean that we should go without abstractions, any more than we should all revert to writing code in assembly.</p>

<p>What’s especially peculiar is that many complex git commands involve a visual component whether you like it or not: the git CLI by default will open up a text editor to prepare for an interactive rebase which is visual in the sense that you’re shown items whose position is meaningful and you can interact with them (e.g. shuffling commits around). The question is whether that interface is easy to use or not, and I find the default behaviour very difficult to use.</p>

<p>For the record, I’m good at helping colleagues fix their git issues, but if I’m in their terminal trying to update their remote URL I have no idea what the command is. Not to worry: I do know how to run <code>brew install lazygit</code>.</p>

<p><img src="https://jesseduffield.com/images/posts/lazygit-5/allowed-a-terminal.png" alt="Harry potter meme"></p>

<h3 id="git-uis-obscure-whats-really-happening">Git UIs obscure what’s really happening</h3>

<p>Again, strong disagree. Compared to the CLI, there’s nothing to obscure!</p>

<p>When I create a commit, several things happen:</p>
<ul>
  <li>my staged files disappear from my list of file changes</li>
  <li>a new commit is appended to my git log</li>
  <li>my branch ends up with a new head commit, diverging from its upstream</li>
</ul>

<p>If you create a commit from the command line, you see none of this. You can query for any of this information after the fact, for example by running <code>git status</code>, but it only gives you one piece of information. If you’re a beginner using the git CLI, you want to be learning the relationship between the different entities, and it’s almost impossible to do that without seeing how these entities are changed as a direct result to your actions. Lazygit has helped some people <a href="https://www.reddit.com/r/git/comments/fr7o1p/lazygit_changed_how_i_understand_git/">better understand git</a> by providing that visual context.</p>

<p>Perhaps UIs aren’t visually obscuring the <em>entities</em>, but they are obscuring the <em>commands</em>. Okay, fine, I concede that point. But my caveats in the <em>Git UIs sometimes do things you didn’t expect</em> section above still apply.</p>

<h3 id="the-cli-is-faster">The CLI is faster</h3>

<p>If you’re a CLI die-hard you probably have some aliases that speed you up, but when it gets to complex use cases like splitting an old commit in two or only applying a single file from a stash entry to the index, it helps to have a UI that lets you press a few keys to select what you want and then perform an action with it. In fact I’d love to pit a CLI veteran against a UI veteran in a contrived gauntlet of git challenges and see who reaches the finish line first. You could also determine the speed of light for each approach i.e. the minimum number of keypresses required to perform the action and then see which approach wins. Even if you had a thousand aliases, I still think a keyboard-centric UI (with good git API coverage) would win.</p>

<h3 id="conclusion">Conclusion</h3>

<p>As somebody who maintains a git UI, I’m clearly partial. But I also feel for the devs who I see stage files by typing <code>git status</code>, dragging their mouse over the file they want to add, and then typing <code>git add &lt;path&gt;</code>. It makes my stomach turn. There are some pros out there who are happy using the CLI for everything, but the average CLI user I see is taking painstakingly slow approaches to very simple problems.</p>

<h2 id="weighing-in-on-the-terminal-renaissance">Weighing in on the terminal renaissance</h2>

<p>The terminal is making a comeback. Various companies have sprung up with the intention of improving the developer experience in the terminal:</p>
<ul>
  <li><a href="https://www.warp.dev/">Warp</a>: a terminal emulator whose killer feature is allowing you to edit your command as if you were in vscode/sublime</li>
  <li><a href="https://fig.io/">Fig</a>: a suite of tools including autocomplete, terminal plugin manager, and some UI helpers for CLI tools</li>
  <li><a href="https://charm.sh/">Charm</a>: various tools and libraries for terminals including a terminal UI ecosystem</li>
</ul>

<p>Warp and Fig both add original elements to the exterior of a terminal emulator to improve the UX, whereas charm is all about improving things on the inside.
All of these projects have the same general idea: rather than replace the terminal, embrace it.</p>

<p>I’m interested to see where this goes.</p>

<h3 id="tui-vs-cli">TUI vs CLI</h3>

<p>I would say I’m pro-terminal, but borderline anti-CLI. When I’m interfacing with something I want to know the current state, the available actions, and once I’ve performed an action, I want to see how the state changes in response. So it’s state -&gt; action -&gt; new state. You can use a CLI to give you all that information, but commands and queries are typically separated and it’s left as an exercise for the user to piece it all together. The simplest example is that after you run <code>cd</code>, you have to run <code>ls</code> to know which files are in the directory. Compare this to <a href="https://github.com/jarun/nnn">nnn</a> which mimics your OS’s file explorer. Another example is running <code>docker compose restart mycontainer</code> and then having to run a separate command to see whether or not your container died as soon as it started (compared to using <a href="https://github.com/jesseduffield/lazydocker">Lazydocker</a>). Even programs like npm can benefit from some visualisation when it comes to linking packages (which is why I created <a href="https://github.com/jesseduffield/lazynpm">Lazynpm</a>). CLI interfaces are great for scripts and composition but as a direct interface, the lack of feedback about state is jarring.</p>

<p>All this to say that when I see demos that show slick auto-complete functionality added to a CLI tool, I can see that it solves the problem of knowing what actions are available, but I’d rather solve the issue of exposing state.</p>

<p>I want to drive home how easy it is to improve on the design of many CLIs. It’s not hard to pick an existing CLI and think about what entities are involved and how they could be represented visually. A random example: <code>asdf</code> is an all-in-one version manager that can manage versions of multiple programs. So you have programs, the available versions of each program, the currently selected version, and you have some actions like CRUD operations and setting a given version as the default. This is perfectly suited to a UI! It just so happens that somebody has gone and made a TUI for it: <a href="https://www.mitchellhanberg.com/introducing-lazyasdf-a-tui-for-the-asdf-version-manager/">lazyasdf</a> (I’m proud to have started a trend with the naming convention!).</p>

<h3 id="tui-vs-web">TUI vs Web</h3>

<p>So, I’ve said my piece about how TUIs can improve upon CLIs, but what about this separate trend of re-imagining web/desktop applications in the terminal?</p>

<p>nsf, the author of the now unmaintained terminal UI framework <a href="https://github.com/nsf/termbox">termbox</a>, says the following at the top of the readme (emphasis mine):</p>
<blockquote>
  <p>This library is no longer maintained. It’s pretty small if you have a big project that relies on it, just maintain it yourself. Or look for forks. Or look for alternatives. Or better - <strong>avoid using terminals for UI</strong></p>
</blockquote>

<p>When you think about it, the only thing that separates terminals and standalone applications is that terminals only render text. The need for terminals was obvious when there were literally no alternatives. Now that we have shiny standalone applications for many things that were once confined to the terminal, it’s harder to justify extending our terminals beyond CLI programs. But there are some reasons:</p>

<h4 id="tuis-guarantee-a-keyboard-centric-ux">TUIs guarantee a keyboard-centric UX</h4>

<p>There is nothing stopping a non-TUI application from having a keyboard centric UX, but few do. Likewise, TUIs <em>can</em> be mouse-centric, but I’ve never encountered one that is.</p>

<h4 id="tuis-have-minimalistic-designs">TUIs have minimalistic designs</h4>

<p>In a TUI, not only can you only render text, but you’re often space-constrained as well. This leads to compact designs with little in the way of superfluous clutter. On the other hand, it’s nice when your UI can render bespoke icons and images and render some text in a small font so that the info is there if you need it but it’s not taking up space. It is interesting that Charm’s UI library seems to go for more whitespace and padding than the typical TUI design: I suspect that trend will be shortlived and in the long run terminal apps will lean compact and utilitarian (No doubt Charm has room for both designs in its ecosystem).</p>

<h4 id="tuis-are-often-faster-than-non-tui-counterparts">TUIs are often faster than non-TUI counterparts</h4>

<p>In one sense, this is a no-brainer: all you’re rendering is text, so your computer doesn’t need to work as hard to render it. But I don’t actually think that’s the main factor. Rather, terminal users <em>expect</em> TUIs to be fast, because they value speed more than other people. So TUI devs put extra effort in towards speed in order to satisfy that desire. I’ve spent enough time on Lazygit’s performance to know that it doesn’t come for free.</p>

<h3 id="conclusion-1">Conclusion</h3>

<p>So, let’s see where this TUI renaissance goes. Even if the renaissance’s only long-term impact is to support more keyboard-centric UIs in web apps, it will have been worth it.</p>

<h2 id="credits">Credits</h2>

<p>Well, that wraps up this Anniversary mega-post. Now I’d like to thank some people who’ve helped Lazygit become what it is today.</p>

<p>First of all, a HUGE thankyou to the 206 people who have <a href="https://github.com/jesseduffield/lazygit/graphs/contributors">contributed</a> to Lazygit over the years, and those who have supported me with donations.</p>

<p>I’d like to shoutout contributors who’ve been part of the journey at different stages: Ryoga, Mark Kopenga, Dawid Dziurla, Glenn Vriesman, Anthony Hamon, David Chen, Flavio Miamoto, and many many others. Thankyou all so much. I also want to thank loyal users who’ve given lots of useful feedback including Dean Herbert, Oliver Joseph Ash, and others.</p>

<p>I want to give a special shoutout to Stefan Haller and Luka Markušić who currently comprise the core team. You’ve both been invaluable for Lazygit’s development, maintenance, and direction. I also hereby publicly award Stefan the prize of ‘most arguments won against maintainer’ ;)</p>

<p>I also want to shoutout <a href="https://appwrite.io/">Appwrite</a> who generously sponsored me for a year. It warms my heart when companies donate to open source projects.</p>

<p>As for you, dear reader: if you would like to support Lazygit’s development you can join the team by picking up an <a href="https://github.com/jesseduffield/lazygit/issues?q=is%3Aissue+is%3Aopen+sort%3Aupdated-desc">issue</a> or expressing your intent to help out in the <a href="https://discord.gg/ehwFt2t4wt">discord channel</a></p>

<p>And as always, if you want to support me, please consider <a href="https://github.com/sponsors/jesseduffield">donating</a> &lt;3</p>

<p>I now leave you with a gif of our new explosion animation when nuking the worktree.</p>

<p><img src="https://jesseduffield.com/images/posts/lazygit-5/nuke-gif.gif" alt=""></p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI Won’t Replace Humans – But Humans with AI Will Replace Humans Without AI (218 pts)]]></title>
            <link>https://hbr.org/2023/08/ai-wont-replace-humans-but-humans-with-ai-will-replace-humans-without-ai</link>
            <guid>37009698</guid>
            <pubDate>Sat, 05 Aug 2023 07:04:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hbr.org/2023/08/ai-wont-replace-humans-but-humans-with-ai-will-replace-humans-without-ai">https://hbr.org/2023/08/ai-wont-replace-humans-but-humans-with-ai-will-replace-humans-without-ai</a>, See on <a href="https://news.ycombinator.com/item?id=37009698">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="" data-order="4" data-type="webscript" data-moveable="false" data-params="region=article;ad-placements=title-300">

<article-content-flex2019 page-subtype="standard">



	<div js-target="article-content-flex2019">


			<div>
		<p><img src="https://hbr.org/resources/css/images/HBR_logo_black.svg">
</p>
	


		

<div>
	<p>The first step business leaders must take is to experiment, create sandboxes, run internal bootcamps, and develop AI use cases not just for technology workers, but for all employees.
	</p>
</div>



<p>
	August 04, 2023
</p>

	</div>

			<div>



<hero-image>
	
</hero-image>

	


	<page-utils data-js-target="page-utils" data-id="tag:blogs.harvardbusiness.org,2007-03-31:999.361995" data-title="AI Won’t Replace Humans — But Humans With AI Will Replace Humans Without AI" data-url="/2023/08/ai-wont-replace-humans-but-humans-with-ai-will-replace-humans-without-ai" data-topic="Business and society" data-authors="" data-content-type="Digital Article" data-content-image="/resources/images/article_assets/2023/08/image-383x215.jpg" data-summary="<p>The first step business leaders must take is to experiment, create  sandboxes, run internal bootcamps, and develop AI use cases not just for technology workers, but for all employees. </p>
">
		<ul>
			<li>
				<a href="http://twitter.com/HarvardBiz" target="_blank" rel="noopener noreferrer" js-target="twitter-share">
					<i></i>
					<p>Tweet</p>
				</a>
			</li>
			<li>
				<a href="http://www.facebook.com/HBR" target="_blank" rel="noopener noreferrer" js-target="facebook-share">
					<i></i>
					<p>Post</p>
				</a>
			</li>
			<li>
				<a href="https://www.linkedin.com/company/harvard-business-review?trk=biz-companies-cym" target="_blank" rel="noopener noreferrer" js-target="linkedin-share">
					<i></i>
					<p>Share</p>
				</a>
			</li>
			<li js-target="annotate-icon">
				<a js-target="handle-mindstone-click">
					<i js-target="mindstone-icon-black">	<svg alt="" aria-labelledby="title">
	<title></title>
	<use xlink:href="/resources/css/images/hbr-icons.svg#mindstone-icon-black"></use></svg>
</i>
					<p>Annotate</p>
				</a>
			</li><li>
				<a href="#" target="_blank" rel="noopener noreferrer" js-target="save-flyout">
					<i></i>
					<p>Save</p>
				</a>
			</li>
			<li>
				<span>
					<i></i>
					<p>Print</p>
				</span>
			</li>
		</ul>
	</page-utils>




	<p>
		<span><p>Karim Lakhani is a professor at Harvard Business School who specializes in workplace technology and particularly AI. He’s done pioneering work in identifying how digital transformation has remade the world of business, and he’s the co-author of the 2020 book <em>Competing in the Age of AI</em>. Customers will expect AI-enhanced experiences with companies, he says, so business leaders must experiment, create  sandboxes, run internal bootcamps, and develop AI use cases not just for technology workers, but for all employees. Change and change management are skills that are no longer optional for modern organizations. </p>
</span>
	</p>

					<div>
						<div>
	<page-utils data-js-target="page-utils" data-id="tag:blogs.harvardbusiness.org,2007-03-31:999.361995" data-title="AI Won’t Replace Humans — But Humans With AI Will Replace Humans Without AI" data-url="/2023/08/ai-wont-replace-humans-but-humans-with-ai-will-replace-humans-without-ai" data-topic="Business and society" data-authors="" data-content-type="Digital Article" data-content-image="/resources/images/article_assets/2023/08/image-383x215.jpg" data-summary="<p>The first step business leaders must take is to experiment, create  sandboxes, run internal bootcamps, and develop AI use cases not just for technology workers, but for all employees. </p>
">
		<ul>
			<li>
				<a href="http://twitter.com/HarvardBiz" target="_blank" rel="noopener noreferrer" js-target="twitter-share">
					<i></i>
					<p>Tweet</p>
				</a>
			</li>
			<li>
				<a href="http://www.facebook.com/HBR" target="_blank" rel="noopener noreferrer" js-target="facebook-share">
					<i></i>
					<p>Post</p>
				</a>
			</li>
			<li>
				<a href="https://www.linkedin.com/company/harvard-business-review?trk=biz-companies-cym" target="_blank" rel="noopener noreferrer" js-target="linkedin-share">
					<i></i>
					<p>Share</p>
				</a>
			</li>
			<li js-target="annotate-icon">
				<a js-target="handle-mindstone-click">
					<i js-target="mindstone-icon-black">	<svg alt="" aria-labelledby="title">
	<title></title>
	<use xlink:href="/resources/css/images/hbr-icons.svg#mindstone-icon-black"></use></svg>
</i>
					<p>Annotate</p>
				</a>
			</li><li>
				<a href="#" target="_blank" rel="noopener noreferrer" js-target="save-flyout">
					<i></i>
					<p>Save</p>
				</a>
			</li>
			<li>
				<span>
					<i></i>
					<p>Print</p>
				</span>
			</li>
		</ul>
	</page-utils>
						</div>

						<content js-target="article-content" data-key="NCRLr0SojV1RzGiNlfS5u8gCZpGFGO57YLgRQkEVbrZTJOUcOWUvl03MrfONu5Qs" data-index="BM5l29iJY6Ee+8B2yfNlrdgbvN4VLOJhHh/T44P8lW63kSqFbbABFP5qz3keUVTgZikKTPbk9QT62/gzTMJZvg==" data-waiver="false" data-page-year="2023" data-page-month="08" data-page-seo-title="ai-wont-replace-humans-but-humans-with-ai-will-replace-humans-without-ai" data-page-adunit-locations="" data-page-slug="article" data-piano-verified="false">
								<p>Just as the internet has drastically lowered the cost of information transmission, AI will lower the cost of cognition. That’s according to Harvard Business School professor Karim Lakhani, who has been studying AI and machine learning in the workplace for years. As the public comes to expect companies that deliver seamless, AI-enhanced experiences and transactions, leaders need to embrace the technology, learn to harness its potential, and develop use cases for their businesses. “The places where you can apply it?” he says. “Well, where do you apply thinking?”</p>
						</content>
<!-- citation -->
					</div>
				</div>


		

	</div>


</article-content-flex2019>

				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Archive.today: on the trail of mysterious guerrilla archivists of the Internet (127 pts)]]></title>
            <link>https://gyrovague.com/2023/08/05/archive-today-on-the-trail-of-the-mysterious-guerrilla-archivist-of-the-internet/</link>
            <guid>37009598</guid>
            <pubDate>Sat, 05 Aug 2023 06:46:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gyrovague.com/2023/08/05/archive-today-on-the-trail-of-the-mysterious-guerrilla-archivist-of-the-internet/">https://gyrovague.com/2023/08/05/archive-today-on-the-trail-of-the-mysterious-guerrilla-archivist-of-the-internet/</a>, See on <a href="https://news.ycombinator.com/item?id=37009598">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
		<main id="main" role="main">

		
			
<article id="post-1437">
	<!-- .entry-header -->

	
	
	<div>
					
<p>Do you like reading articles in publications like Bloomberg, the Wall Street Journal or the Economist, but can’t afford to pay what can be hundreds of dollars a year in subscriptions?  If so, odds are you’ve already stumbled on <a rel="noreferrer noopener" href="https://archive.today/" target="_blank">archive.today</a>, which provides easy access to these and much more: just paste in the article link, and you’ll get back a snapshot of the page, full content included.</p>



<figure><a href="https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof2_cartoon_large.jpeg"><img data-attachment-id="1499" data-permalink="https://gyrovague.com/2023/08/05/archive-today-on-the-trail-of-the-mysterious-guerrilla-archivist-of-the-internet/bibalex_roof2_cartoon_large/" data-orig-file="https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof2_cartoon_large.jpeg" data-orig-size="3008,2000" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;NIKON D70&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1216300266&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;38&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="bibalex_roof2_cartoon_large" data-image-description="" data-image-caption="" data-medium-file="https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof2_cartoon_large.jpeg?w=300" data-large-file="https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof2_cartoon_large.jpeg?w=1024" src="https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof2_cartoon_large.jpeg?w=1024" alt="" srcset="https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof2_cartoon_large.jpeg?w=1024 1024w, https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof2_cartoon_large.jpeg?w=2048 2048w, https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof2_cartoon_large.jpeg?w=150 150w, https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof2_cartoon_large.jpeg?w=300 300w, https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof2_cartoon_large.jpeg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>







<p>For a long time, I assumed that this was some kind of third-party skin on top of the venerable <a href="https://archive.org/">Internet Archive,</a> whose Wayback Machine provides a very similar service at the very similar address of <a rel="noreferrer noopener" href="http://archive.org/" target="_blank">archive.org</a>.  However, the Wayback Machine is slow, clunky, frequently errors out, and most importantly, it’s very easy for websites to <a rel="noreferrer noopener" href="https://help.archive.org/hc/en-us/sections/360000425652-Wayback-Machine-Web-Archiving" target="_blank">opt out</a>, retroactively erasing all their content forever.  In contrast, archive.today has <em>no </em>opt-outs or erase buttons: like it or not, they store everything and it’s not going anywhere, with some <a rel="noreferrer noopener" href="https://blog.archive.today/post/636912269578665984/does-your-site-save-all-pages-that-people-post" target="_blank">limited exceptions</a> for law enforcement, <a href="https://blog.archive.today/post/677918691356278784/i-found-many-children-porn-images-on-archive-who">child porn</a>, etc.</p>



<p>The Internet Archive is a legitimate 501(c)(3) non-profit with a budget of $37 million and 169 full-time employees in 2019.  archive.today, by contrast, is an opaque mystery.  So who runs this and where did they come from?</p>



<h2 id="the-origins-and-owners-of-archive-today">The origins and owners of archive.today</h2>



<p>The first historical record we have of the site dates from May 16, 2012, when a “Denis Petrov” from Prague, Czech Republic <a rel="noreferrer noopener" href="https://who.is/whois/archive.is" target="_blank">registered the domain archive.is</a>, the original name of the site.  <a rel="noreferrer noopener" href="https://who.is/whois/archive.today" target="_blank">archive.today</a> <a rel="noreferrer noopener" href="https://twitter.com/archiveis/status/455710701948903424" target="_blank">followed in 2014</a>, and the site has since registered countless variations: archive.li, archive.ec, archive.vn, archive.ph, archive.fo, etc.  Denis Petrov is a common Russian name, with <a rel="noreferrer noopener" href="https://www.linkedin.com/search/results/people/?keywords=denis%20petrov" target="_blank">pages and pages of matches on LinkedIn</a>, but it may well be an alias: informer.com notes that the same contact information was used to register <a rel="noreferrer noopener" href="https://website.informer.com/Denis+Petrov.html" target="_blank">a series of very sketchy domains</a>, ranging from “carding forum” <em>verified.lu</em> to piracy sites <em>btdlg.com</em> and <em>moviesave.us</em> (all long since gone), many seeded with German keywords (<em>spiel, gewinnt, online</em>).</p>



<p>Domains aside, “Denis Petrov” has little presence on the web, and three seemingly connected domains proved dead ends. The obvious <em>denispetrov.com</em> was an entertaining rabbit hole, with the author <a rel="noreferrer noopener" href="https://web.archive.org/web/20100622120438/http://www.denispetrov.com/" target="_blank">an accomplished programmer with an interest in Web automation</a>, but it’s <a rel="noreferrer noopener" href="https://web.archive.org/web/20070217031023/http://www.denispetrov.com/?p=47" target="_blank">clearly the work of a New Yorker</a>, they’re blogging at the tail end of a 25-year career and the blog dries up entirely in 2011, so it doesn’t match the place or time. <a rel="noreferrer noopener" href="https://web.archive.org/web/20040207134158/http://denis.biz/" target="_blank">denis.biz</a> (2001) and <a rel="noreferrer noopener" href="https://web.archive.org/web/20080323134702/http://petrov.net/" target="_blank">petrov.net</a> (1998!) contain nothing.  The one intriguing bit of evidence we have is <a rel="noreferrer noopener" href="https://kiwifarms.net/threads/archive-md-vs-brave-browser.71896/page-2" target="_blank">this series of screenshots</a> (<a href="https://archive.li/PC2g5">archive</a>) where Brave’s tech support addresses <em>webmaster@archive.is</em> as “Denis”, but odds are that’s just from the same DNS record.</p>



<p>We can glean a few more clues from <em>archive.today</em>‘s web presence.  <a rel="noreferrer noopener" href="https://archive.is/faq" target="_blank">The FAQ</a>, unchanged since 2013 (!), states that they are located in Europe and asks for PayPal donations in euros.  Looking through the <a rel="noreferrer noopener" href="https://blog.archive.today/archive/2021/12" target="_blank">voluminous Tumblr blog</a>, featuring tons of questions but very terse answers, the author’s English is excellent but not <em>quite </em>native, with occasional Noun Capitalization also hinting at a German background.  <a rel="noreferrer noopener" href="https://blog.archive.today/post/132405567756/%D1%81%D0%BA%D0%BE%D0%BB%D1%8C%D0%BA%D0%BE-%D0%B2%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%B8-%D1%85%D1%80%D0%B0%D0%BD%D1%8F%D1%82%D1%81%D1%8F-%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D0%B5-url-%D0%BC%D0%B0%D0%BA%D1%81%D0%B8%D0%BC%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9" target="_blank">Yet they answer questions in Russian</a>, and the site uses a Russian analytics engine.</p>



<figure><a href="https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof1_cartoon_large.jpeg"><img data-attachment-id="1503" data-permalink="https://gyrovague.com/2023/08/05/archive-today-on-the-trail-of-the-mysterious-guerrilla-archivist-of-the-internet/bibalex_roof1_cartoon_large/" data-orig-file="https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof1_cartoon_large.jpeg" data-orig-size="3008,2000" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;9&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;NIKON D70&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1216300240&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;40&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0.01&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="bibalex_roof1_cartoon_large" data-image-description="" data-image-caption="" data-medium-file="https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof1_cartoon_large.jpeg?w=300" data-large-file="https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof1_cartoon_large.jpeg?w=1024" src="https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof1_cartoon_large.jpeg?w=1024" alt="" srcset="https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof1_cartoon_large.jpeg?w=1024 1024w, https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof1_cartoon_large.jpeg?w=2048 2048w, https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof1_cartoon_large.jpeg?w=150 150w, https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof1_cartoon_large.jpeg?w=300 300w, https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof1_cartoon_large.jpeg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>







<p>The most interesting detective work to date comes from Stack Exchange, where <a rel="noreferrer noopener" href="https://webapps.stackexchange.com/questions/145817/on-which-country-are-the-creators-and-servers-of-archive-today-archive-is-base" target="_blank">Ciro Santilli</a> managed to link the profile picture of an account <em>archive.today</em> once used to archive LinkedIn content to a “Masha Rabinovich” in Berlin.  Even more intriguingly, in a <a href="https://community.f-secure.com/en/discussion/14768/what-is-the-evidence-of-harmful-behaviour#M3733">2012 F-Secure forum post</a>, a “masharabinovich” complains about <em>“my website <a href="http://archive.is/&amp;#8221" rel="nofollow">http://archive.is/&amp;#8221</a>;</em> being blacklisted.  They pop up on Wikipedia as well <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/User_talk:Masharabinovich" target="_blank">getting told off</a> for adding too many links to archive.is, including a mention that they’re using the Czech ISP fiber.cz, and <a rel="noreferrer noopener" href="https://en.wikipedia.org/w/index.php?title=Special:Contributions/Masharabinovich&amp;offset=20091219064619&amp;limit=500&amp;target=Masharabinovich" target="_blank">their early edit history</a> includes many updates to the pages “Russian passport” and “Belarusian passport”.  “Masha” (Маша) is a common Russian diminutive of Maria, although it can also be a Hebrew form of Moses (מַשה), and Rabinovich is an Ashkenazi Jewish surname.</p>



<p> <a href="https://archive.vn/blhHz">Early Github captures</a> on <em>archive.today </em>are linked to a <a rel="noreferrer noopener" href="https://twitter.com/grhmc/status/1334138105738256389" target="_blank">now completely disappeared account</a> called “volth” (<a rel="noreferrer noopener" href="https://archive.vn/kqftP" target="_blank">copy archived by archive.today itself</a>), who was a fluent speaker of Russian, contributed extensively to <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/NixOS" target="_blank">NixOS</a> (which <a rel="noreferrer noopener" href="https://discourse.nixos.org/t/list-of-companies-using-nixos-technologies/8428/7" target="_blank">archive.today uses</a>) and has a profile picture not dissimilar to Masha’s.  The linked <a href="http://volth.com/">volth.com</a> domain is now only an empty husk, but it dates back to 2004, with early versions first doing some kind of sketchy search engine network marketing thing (<a rel="noreferrer noopener" href="https://web.archive.org/web/20050129084842/http://volth.com/" target="_blank">2005</a>), promising “Total Success in Internet” (<a href="https://web.archive.org/web/20081005032812/http://volth.com/">2008</a>) and eventually being <a rel="noreferrer noopener" href="https://web.archive.org/web/20100529063016/http://www.volth.com:80/" target="_blank">put up for sale</a> (2010), making it likely that its original owners the Espinosas are unrelated to whoever owns the domain today.</p>



<p>While we may not have a face and a name, at this point we have a pretty good idea of how the site is run: it’s a one-person labor of love, operated by a Russian of considerable talent and access to Europe.  Let’s move on to the nitty gritty.</p>



<h2 id="how-archive-today-works">Infrastructure</h2>



<p>There are two components to any archival site: the scraper that copies the pages, and the storage system where the pages are kept and retrieved on demand.  Helpfully, the <a rel="noreferrer noopener" href="https://archive.today/faq" target="_blank">FAQ</a> shares some details of what the storage side at least used to look like:</p>



<p>The archive runs Apache Hadoop and Apache Accumulo. All data is stored on HDFS, textual content is duplicated 3 times among servers in 2 datacenters and images are duplicated 2 times. Both datacenters are in Europe, with <a href="https://blog.archive.today/post/674936420267393024/parlez-vous-fran%C3%A7ais-parce-que-jai-remarqu%C3%A9-que">OVH hosting at least one of them</a>.</p>



<figure><a href="https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof3_cartoon_large.jpeg"><img data-attachment-id="1501" data-permalink="https://gyrovague.com/2023/08/05/archive-today-on-the-trail-of-the-mysterious-guerrilla-archivist-of-the-internet/bibalex_roof3_cartoon_large/" data-orig-file="https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof3_cartoon_large.jpeg" data-orig-size="3008,2000" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;NIKON D70&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1216300412&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;24&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="bibalex_roof3_cartoon_large" data-image-description="" data-image-caption="" data-medium-file="https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof3_cartoon_large.jpeg?w=300" data-large-file="https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof3_cartoon_large.jpeg?w=1024" src="https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof3_cartoon_large.jpeg?w=1024" alt="" srcset="https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof3_cartoon_large.jpeg?w=1024 1024w, https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof3_cartoon_large.jpeg?w=2048 2048w, https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof3_cartoon_large.jpeg?w=150 150w, https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof3_cartoon_large.jpeg?w=300 300w, https://gyrovaguedotcom.files.wordpress.com/2023/08/bibalex_roof3_cartoon_large.jpeg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>In 2012, the site <a rel="noreferrer noopener" href="https://blog.archive.today/post/38139265209/what-will-happen-to-the-data-when-you-shut-the" target="_blank">already had 10 TB</a> of archives and <a rel="noreferrer noopener" href="https://blog.archive.today/post/41291326993/so-if-you-say-it-costs-you-money-how-much-is" target="_blank">cost ~300 euros/mo to run</a>, escalating to <a rel="noreferrer noopener" href="https://blog.archive.today/post/72136308644/how-much-does-it-cost-you-to-host-a-website-of" target="_blank">2000 euros by 2014</a> and <a rel="noreferrer noopener" href="https://blog.archive.today/post/151510917631/how-do-you-guys-keep-the-lights-on-i-gave-the" target="_blank">$4000 by 2016</a>.  As of 2021, they have archived on the order of <a rel="noreferrer noopener" href="https://blog.archive.today/post/661314951417315328/what-percentage-of-5-char-codes-is-used-now-full" target="_blank">500 million pages</a>, and with the average size of a webpage clocking in at well over 2 MB these days, that’s a cool 1,000 TB to deal with.  (For comparison, the <a href="https://www.zdnet.com/article/internet-archive-celebrates-25-years-and-launches-fund-raising-campaign-amid-new-legal-challenges/" target="_blank" rel="noreferrer noopener">Internet Archive is around 40,000 TB</a>.)</p>



<p>The less discussed but more controversial half of the site is scraping, the process of vacuuming up live webpages.  Since 2021, this uses a <a rel="noreferrer noopener" href="https://blog.archive.today/post/618635148292964352/what-scraper-or-headless-browser-are-you-using-it" target="_blank">modified version of the Chrome browser</a>, and the blog <a rel="noreferrer noopener" href="https://blog.archive.today/post/653166387151437824/what-is-the-total-number-of-pages-it-can-store" target="_blank">readily admits</a> that the availability of computing power to run these automated browsers is now the main bottleneck to expanding the site.  To avoid detection, <a rel="noreferrer noopener" href="https://www.wikiwand.com/en/Talk:Archive.today" target="_blank">archive.today runs via a botnet</a> that cycles through countless IP addresses, making it quite difficult for <a rel="noreferrer noopener" href="https://webmasters.stackexchange.com/questions/88257/deny-access-to-archive-is" target="_blank">grumpy webmasters</a> to stop their sites getting scraped.  Access to paywalled sites is through logins secured via unclear means, which need to be replenished constantly: <a href="https://blog.archive.today/post/667206146733588480/why-cant-we-archive-an-instagram-account">here’s the creator asking for Instagram credentials</a>.</p>



<p>Finally, the serving of the website is also subject to a perpetual <a rel="noreferrer noopener" href="https://blog.archive.today/post/188657795411/i-see-the-new-md-domain-archive-md-and-9-months" target="_blank">game of cat and mouse</a>: <em>“I can only predict that there will be approximately one trouble with domains per year and each fifth trouble will result in domain loss.”</em>  As of today, archive.today still works, but users are redirected to archive.md.</p>



<h2>Funding</h2>



<p>The other major source of permanent uncertainty is the site’s funding model.  We’ve established that its costs are considerable, but according to the creator, <a href="https://blog.archive.today/post/656947801397362688/how-does-this-website-earn-you-money-does-it-help">as of 2021 ads and donations covered less than 20% of expenses</a>, with <a href="https://blog.archive.today/post/673230761828188160/how-was-last-years-2021-donations-compared-with">donations on the order of 6000 euros</a>.  PayPal donations, previously accepted, were switched off around 2022 since <a href="https://archive.md/FoEX8">the creator could no longer top up the account</a>, implying they’re in Russia, and they complain about the <a href="https://archive.md/GSDwV">difficulty of doing cross-border payments</a> “across the Iron Curtain”.  Donations these days are via <a href="https://liberapay.com/archiveis/donate">Liberapay</a>, an obscure French non-profit organization, and YC-backed startup <a href="https://www.buymeacoffee.com/archive.today">BuyMeACoffee</a>.  Surprisingly, <a href="https://blog.archive.today/post/680725980039479296/cant-you-buy-cards-with-crypto-or-something-like">the creator has a healthy skepticism of crypto</a>, so this remains unsupported.</p>



<p>The other source of income is ads.  The FAQ, far out of date, has a “<em>promise it will have no ads at least till the end of 2014</em>“, but there have long been Yahoo network ads injected on top of pages when you use mobile (but, oddly, not on desktop).  Revenue is even more of a question mark, but apparently on good days they “<a href="https://blog.archive.today/post/666150469075402752/how-much-revenue-are-you-generating-from-the-ads">almost cover expenses</a>” (a remark that doesn’t quite square with the other comment about ads and donations together covering less than 20%), while on bad days <a href="https://blog.archive.today/post/675851380224819200/i-havent-seen-any-ads-on-your-site-in-a-long">they’re getting kicked out from serving ads</a> because an archive of the Internet will inevitably archive advertiser-unfriendly NSFW content too.</p>



<h2>Archive.today, not tomorrow?</h2>



<p>So there we have it: the site is a one-man battle against entropy, constantly battling domain registrars, anti-scraping systems, copyright enforcement, easily spooked advertisers, and global financial system payment rails designed to obstruct Russian citizens. By staying anonymous and keeping a low profile, they’ve (likely?) managed to avoid the kind of legal tussles that have embroiled <a href="https://en.wikipedia.org/wiki/Alexandra_Elbakyan">Alexandra Elbakyan</a> of Sci-Hub fame, but they’ve still funded it to the tune of tens of thousands of euros during that time.  They clearly have a second source of considerable income that’s likely somewhat sketchy as well, so if that ever goes away, archive.today is likely to go away with it.</p>



<p>The creator is fully aware that the site is a mere “<a href="https://blog.archive.today/post/660719734341386240/is-there-any-structure-in-place-to-assure-the">weak tool</a>” that is “<a href="https://blog.archive.today/post/657822115776610304/not-respecting-peoples-privacy-copyright-laws">doomed to die</a>“, but the bus factor of one combined with its semi-legal nature means there can be no real continuity: there will never be a legally incorporated Archive.Today Foundation to carry on his work.  It’s a testament to their persistence that they’re managed to keep this up for over 10 years, and I for one will be buying Denis/Masha/whoever a well deserved <a href="https://www.buymeacoffee.com/archive.today">cup of coffee</a>.</p>



<p><em>All images in this post feature the Bibliotheca Alexandrina at Alexandria, Egypt.</em></p>





						</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-## -->

				<!-- .navigation -->
	
			
<!-- #comments -->

		
		</main><!-- #main -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Try the Last Internet Kermit Server (141 pts)]]></title>
            <link>https://changelog.complete.org/archives/10555-try-the-last-internet-kermit-server</link>
            <guid>37009329</guid>
            <pubDate>Sat, 05 Aug 2023 05:42:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://changelog.complete.org/archives/10555-try-the-last-internet-kermit-server">https://changelog.complete.org/archives/10555-try-the-last-internet-kermit-server</a>, See on <a href="https://news.ycombinator.com/item?id=37009329">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Eventual Business Consistency (120 pts)]]></title>
            <link>https://tidyfirst.substack.com/p/eventual-business-consistency</link>
            <guid>37009296</guid>
            <pubDate>Sat, 05 Aug 2023 05:35:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tidyfirst.substack.com/p/eventual-business-consistency">https://tidyfirst.substack.com/p/eventual-business-consistency</a>, See on <a href="https://news.ycombinator.com/item?id=37009296">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>I’m a geek speaking to you, a technology-savvy executive, about why we are doing things in a more complicated way than seems necessary. You may have heard the word “bi-temporal”. What’s that about?</p><p>In a nutshell, we want what’s recorded in the system to match the real world. We know this is impossible (delays, mistakes, changes) but are getting as close as we can. The promise is that if what’s in the system matches the real world as closely as possible, costs go down, customer satisfaction goes up, &amp; we are able to scale further faster.</p><p>Here’s how it works.</p><p>We’ll take addresses as our example. Addresses are useful for sending correspondence, calculating taxes, determining regulations, &amp; targeting marketing. Addresses, though, change.</p><p><strong>Simplest</strong><span>—we’ll just store the address in the database. When the address changes, we’ll change what’s in the database. Finito.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe43f54dc-3b90-4ca1-90a4-3789943e157a_1500x443.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe43f54dc-3b90-4ca1-90a4-3789943e157a_1500x443.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe43f54dc-3b90-4ca1-90a4-3789943e157a_1500x443.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe43f54dc-3b90-4ca1-90a4-3789943e157a_1500x443.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe43f54dc-3b90-4ca1-90a4-3789943e157a_1500x443.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe43f54dc-3b90-4ca1-90a4-3789943e157a_1500x443.png" width="1456" height="430" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e43f54dc-3b90-4ca1-90a4-3789943e157a_1500x443.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:430,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:668086,&quot;alt&quot;:&quot;Change the database when the data changes&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="Change the database when the data changes" title="Change the database when the data changes" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe43f54dc-3b90-4ca1-90a4-3789943e157a_1500x443.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe43f54dc-3b90-4ca1-90a4-3789943e157a_1500x443.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe43f54dc-3b90-4ca1-90a4-3789943e157a_1500x443.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe43f54dc-3b90-4ca1-90a4-3789943e157a_1500x443.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>Not quite. The customer calls and says, “Why did you charge me California sales tax for this order? I don’t live in California. 🤬” We look in the database &amp; there it is, a California address. “I just moved you numbskulls. The order was sent to me when I was in Colorado.”</p><p>We’re terribly sorry for the mistake. Here’s a voucher for an ice cream cone.</p><p>Not a good experience for the customer. Not a good experience for us.</p><p><strong>Dated data</strong><span>—we choose to remember the history of all the addresses &amp; tag them with their date. This is more complicated. Now the customer service screens have to display a list of addresses instead of just one. The database will be bigger because we don’t throw addresses away. The code will be more complicated because we can no longer say, “Here’s a customer. What’s their address?” we have to say, “Here’s a customer. What’s their address on this date?”</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a615322-6e13-4ef0-a86e-af27f9f8bcd1_1482x375.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a615322-6e13-4ef0-a86e-af27f9f8bcd1_1482x375.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a615322-6e13-4ef0-a86e-af27f9f8bcd1_1482x375.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a615322-6e13-4ef0-a86e-af27f9f8bcd1_1482x375.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a615322-6e13-4ef0-a86e-af27f9f8bcd1_1482x375.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a615322-6e13-4ef0-a86e-af27f9f8bcd1_1482x375.png" width="1456" height="368" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5a615322-6e13-4ef0-a86e-af27f9f8bcd1_1482x375.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:368,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Add an entry to the database, tagged with the date, when the data changes&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Add an entry to the database, tagged with the date, when the data changes" title="Add an entry to the database, tagged with the date, when the data changes" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a615322-6e13-4ef0-a86e-af27f9f8bcd1_1482x375.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a615322-6e13-4ef0-a86e-af27f9f8bcd1_1482x375.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a615322-6e13-4ef0-a86e-af27f9f8bcd1_1482x375.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a615322-6e13-4ef0-a86e-af27f9f8bcd1_1482x375.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Yes, it’s more complicated, but in return we get to answer our irate customer’s question. “Our records show that you placed the order on June 15 &amp; you moved on June 1.” Oh.</p><p>Okay, so date-tagged data is better for us at the cost of a bit more complexity. </p><p>However… What happens when a customer says, “Oh, by the way, I moved 2 months ago.”? What date do we use for the tag? Today? Then we won’t know that we need to recalculate 2 months’ worth of statements. Two months ago? Then we won’t be able to explain (to the customer, tax authorities, whoever) why we did what we did.</p><p>The fundamental, inescapable problem? What is in the system is a flawed reflection of what is going on in reality. We want what is in the system to be as close as possible to reality, but we also need to acknowledge that consistency between the system &amp; reality will only ever be approached, not achieved. The system will record changes in reality eventually, but by then we may have made decisions that need to be undone.</p><p>Sound difficult? Only a little more than what we’ve done already.</p><p><strong>Double-dated data</strong><span>—we tag each bit of business data with 2 dates:</span></p><ul><li><p><span>The date on which the data changed out in the real world, the </span><em>effective</em><span> date.</span></p></li><li><p><span>The date on which the system found out about the change, the </span><em>posting</em><span> date.</span></p></li></ul><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa23bfe21-9587-4d80-8a89-544676e04850_2049x372.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa23bfe21-9587-4d80-8a89-544676e04850_2049x372.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa23bfe21-9587-4d80-8a89-544676e04850_2049x372.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa23bfe21-9587-4d80-8a89-544676e04850_2049x372.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa23bfe21-9587-4d80-8a89-544676e04850_2049x372.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa23bfe21-9587-4d80-8a89-544676e04850_2049x372.png" width="1456" height="264" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a23bfe21-9587-4d80-8a89-544676e04850_2049x372.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:264,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Tag the data with both the date it changed &amp; the date we recorded the change&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Tag the data with both the date it changed &amp; the date we recorded the change" title="Tag the data with both the date it changed &amp; the date we recorded the change" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa23bfe21-9587-4d80-8a89-544676e04850_2049x372.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa23bfe21-9587-4d80-8a89-544676e04850_2049x372.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa23bfe21-9587-4d80-8a89-544676e04850_2049x372.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa23bfe21-9587-4d80-8a89-544676e04850_2049x372.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p> This is the simple case where effective &amp; posting dates match.</p><p>(These 2 dates are why we call such systems “bi-temporal”. We have 2 timelines. One is the timeline of when things actually happened, the other the timeline of when we found out about it. The purpose of the 2 dates is to make sure that our system is eventually consistent with reality.)</p><p>Another way to look at the example above is to show the timelines explicitly.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5df299cd-1688-4cad-8bb9-7dc3d96283ef_1157x341.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5df299cd-1688-4cad-8bb9-7dc3d96283ef_1157x341.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5df299cd-1688-4cad-8bb9-7dc3d96283ef_1157x341.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5df299cd-1688-4cad-8bb9-7dc3d96283ef_1157x341.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5df299cd-1688-4cad-8bb9-7dc3d96283ef_1157x341.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5df299cd-1688-4cad-8bb9-7dc3d96283ef_1157x341.png" width="1157" height="341" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5df299cd-1688-4cad-8bb9-7dc3d96283ef_1157x341.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:341,&quot;width&quot;:1157,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Graphical depiction of the same scenario with a timeline for effective date on top &amp; posting date on the bottom &amp; a labelled arrow for the change&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Graphical depiction of the same scenario with a timeline for effective date on top &amp; posting date on the bottom &amp; a labelled arrow for the change" title="Graphical depiction of the same scenario with a timeline for effective date on top &amp; posting date on the bottom &amp; a labelled arrow for the change" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5df299cd-1688-4cad-8bb9-7dc3d96283ef_1157x341.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5df299cd-1688-4cad-8bb9-7dc3d96283ef_1157x341.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5df299cd-1688-4cad-8bb9-7dc3d96283ef_1157x341.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5df299cd-1688-4cad-8bb9-7dc3d96283ef_1157x341.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Using effective &amp; posting dates together we can record all the strange twists &amp; turns of feeding data into a system.</p><p>“I forgot to tell you that I moved last year.”</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc567f8e2-a87f-4c14-9862-9f877eb000d9_2015x278.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc567f8e2-a87f-4c14-9862-9f877eb000d9_2015x278.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc567f8e2-a87f-4c14-9862-9f877eb000d9_2015x278.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc567f8e2-a87f-4c14-9862-9f877eb000d9_2015x278.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc567f8e2-a87f-4c14-9862-9f877eb000d9_2015x278.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc567f8e2-a87f-4c14-9862-9f877eb000d9_2015x278.png" width="1456" height="201" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c567f8e2-a87f-4c14-9862-9f877eb000d9_2015x278.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:201,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:650427,&quot;alt&quot;:&quot;The arrow slants left for a retroactive change&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="The arrow slants left for a retroactive change" title="The arrow slants left for a retroactive change" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc567f8e2-a87f-4c14-9862-9f877eb000d9_2015x278.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc567f8e2-a87f-4c14-9862-9f877eb000d9_2015x278.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc567f8e2-a87f-4c14-9862-9f877eb000d9_2015x278.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc567f8e2-a87f-4c14-9862-9f877eb000d9_2015x278.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>“You got last year’s address change wrong.”</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F622d963e-7c24-48be-a733-4007875bfbc6_673x223.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F622d963e-7c24-48be-a733-4007875bfbc6_673x223.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F622d963e-7c24-48be-a733-4007875bfbc6_673x223.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F622d963e-7c24-48be-a733-4007875bfbc6_673x223.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F622d963e-7c24-48be-a733-4007875bfbc6_673x223.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F622d963e-7c24-48be-a733-4007875bfbc6_673x223.png" width="369" height="122.26894502228826" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/622d963e-7c24-48be-a733-4007875bfbc6_673x223.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:223,&quot;width&quot;:673,&quot;resizeWidth&quot;:369,&quot;bytes&quot;:189943,&quot;alt&quot;:&quot;The arrow slants left &amp; lands on the same effective date as the previous change&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="The arrow slants left &amp; lands on the same effective date as the previous change" title="The arrow slants left &amp; lands on the same effective date as the previous change" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F622d963e-7c24-48be-a733-4007875bfbc6_673x223.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F622d963e-7c24-48be-a733-4007875bfbc6_673x223.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F622d963e-7c24-48be-a733-4007875bfbc6_673x223.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F622d963e-7c24-48be-a733-4007875bfbc6_673x223.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>“I’m going to move next year.”</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e08b3f5-b132-43e3-afe2-f1394d666d1b_663x271.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e08b3f5-b132-43e3-afe2-f1394d666d1b_663x271.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e08b3f5-b132-43e3-afe2-f1394d666d1b_663x271.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e08b3f5-b132-43e3-afe2-f1394d666d1b_663x271.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e08b3f5-b132-43e3-afe2-f1394d666d1b_663x271.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e08b3f5-b132-43e3-afe2-f1394d666d1b_663x271.png" width="381" height="155.73303167420815" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5e08b3f5-b132-43e3-afe2-f1394d666d1b_663x271.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:271,&quot;width&quot;:663,&quot;resizeWidth&quot;:381,&quot;bytes&quot;:211181,&quot;alt&quot;:&quot;The arrow slants right for a prospective change&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="The arrow slants right for a prospective change" title="The arrow slants right for a prospective change" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e08b3f5-b132-43e3-afe2-f1394d666d1b_663x271.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e08b3f5-b132-43e3-afe2-f1394d666d1b_663x271.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e08b3f5-b132-43e3-afe2-f1394d666d1b_663x271.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5e08b3f5-b132-43e3-afe2-f1394d666d1b_663x271.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>And this is the magic one, the nightmare scenario that just can’t be automatically handled otherwise.</p><p>“You got last year’s address change wrong. I actually moved 2 years ago.”</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff224af63-e6b8-426f-b7c1-9321af870a71_669x258.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff224af63-e6b8-426f-b7c1-9321af870a71_669x258.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff224af63-e6b8-426f-b7c1-9321af870a71_669x258.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff224af63-e6b8-426f-b7c1-9321af870a71_669x258.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff224af63-e6b8-426f-b7c1-9321af870a71_669x258.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff224af63-e6b8-426f-b7c1-9321af870a71_669x258.png" width="407" height="156.9596412556054" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f224af63-e6b8-426f-b7c1-9321af870a71_669x258.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:258,&quot;width&quot;:669,&quot;resizeWidth&quot;:407,&quot;bytes&quot;:208237,&quot;alt&quot;:&quot;One arrow crosses the other for a retroactive correction&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="One arrow crosses the other for a retroactive correction" title="One arrow crosses the other for a retroactive correction" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff224af63-e6b8-426f-b7c1-9321af870a71_669x258.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff224af63-e6b8-426f-b7c1-9321af870a71_669x258.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff224af63-e6b8-426f-b7c1-9321af870a71_669x258.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff224af63-e6b8-426f-b7c1-9321af870a71_669x258.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>To accurately process this scenario we need to </span><em>undo</em><span> 2 years’ worth of processing, </span><em>redo</em><span> those years with the correct address, the continue from there. Without both dates we’re throwing the corrections into an account called “Manual Corrections” &amp; praying those corrections won’t cause problems in the future (praying in vain, as it turns out).</span></p><p>The goal of our design is to provide eventual business consistency, for what’s recorded in the system to match what’s happening in the real world as well as possible at a reasonable cost. Since perfect consistency is impossible:</p><ul><li><p>We save everything we learn.</p></li><li><p>We track when changes occurred in reality.</p></li><li><p>We track when we found out about those changes in the system.</p></li></ul><p>We invest additional programming complexity so we can:</p><ul><li><p>Reduce costs (fewer complaints, faster resolution).</p></li><li><p>Reduce mistakes.</p></li><li><p>Improve compliance.</p></li></ul><p>That’s the tradeoff. That’s what we’re doing we say we are bi-temporal. GeekSpeak for “better business”.</p><blockquote><p><span>I’d like to thank Massimo Arnoldi &amp; the </span><a href="https://www.lifeware.ch/" rel="">Lifeware</a><span> gang for teaching me bi-temporality, teaching me how to effectively visualize the two timelines, &amp; using bi-temporality to provide outstanding customer service to millions of insurance customers for decades. </span></p></blockquote><p><span>Bi-temporal data has been around since the early 1990’s, based on the pioneering work of </span><a href="https://en.wikipedia.org/wiki/Richard_T._Snodgrass" rel="">Richard Snodgrass</a><span>. Part of the reason it hasn’t taken off is because of the additional complexity it imposes on programmers. However, I think part of the reason it hasn’t become more popular, given the benefits it brings, is just the name. Hence my proposed rebranding to “eventual business consistency”.</span></p><p>Unfortunately, that name is itself a geeky analogy. If you already understand “eventual consistency”, the analogy makes immediate sense. If not, probably not so much. At the risk of “explaining the joke” (which never works, right?), here is the analogy.</p><p>Say we have a critically important database. We store the data on 2 machines so if one machine crashes we still have access to our data.</p><p>Say the network between the 2 machines is flaky (protip: it is). When we write data to one machine &amp; the network is down we can either:</p><ul><li><p>Wait for the network to come back, which imposes unpredictable delays. If the data absolutely, positively have to be consistent between the 2 machines we may be willing to pay this cost.</p></li><li><p>Write the data to one machine now &amp; catch up later. If we absolutely, positively need to be able to write data at all times but it’s okay if the data is a little out of sync, this is an acceptable tradeoff. We call this scenario “eventual consistency”.</p></li></ul><p>It’s this latter, “catch up later”, strategy that we draw our analogy from. Just as the 2 databases are consistent, but only eventually, our system data matches reality, but only eventually. We acknowledge that the system &amp; reality are a little out of whack but we’re transparent about inconsistencies &amp; fix them as well as possible as soon as possible.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NASA has reestablished full communications with Voyager 2 (432 pts)]]></title>
            <link>https://www.jpl.nasa.gov/news/nasa-mission-update-voyager-2-communications-pause</link>
            <guid>37008724</guid>
            <pubDate>Sat, 05 Aug 2023 03:29:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jpl.nasa.gov/news/nasa-mission-update-voyager-2-communications-pause">https://www.jpl.nasa.gov/news/nasa-mission-update-voyager-2-communications-pause</a>, See on <a href="https://news.ycombinator.com/item?id=37008724">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p data-block-key="v48g2"><b>UPDATE, Aug. 4, 2023:</b> <i>NASA has reestablished full communications with Voyager 2.</i></p><p data-block-key="8vm6r"><i>The agency’s Deep Space Network facility in Canberra, Australia, sent the equivalent of an interstellar “shout” more than 12.3 billion miles (19.9 billion kilometers) to Voyager 2, instructing the spacecraft to reorient itself and turn its antenna back to Earth. With a one-way light time of 18.5 hours for the command to reach Voyager, it took 37 hours for mission controllers to learn whether the command worked. At 12:29 a.m. EDT on Aug. 4, the spacecraft began returning science and telemetry data, indicating it is operating normally and that it remains on its expected trajectory.</i></p><p data-block-key="flcjf"><b>UPDATE, Aug. 1, 2023:</b> <i>Using multiple antennas, NASA’s Deep Space Network (DSN) was able to detect a carrier signal from Voyager 2. A carrier signal is what the spacecraft uses to send data back to Earth. The signal is too faint for data to be extracted, but the detection confirms that the spacecraft is still operating. The spacecraft also continues on its expected trajectory. Although the mission expects the spacecraft to point its antenna at Earth in mid-October, the team will attempt to command Voyager sooner, while its antenna is still pointed away from Earth. To do this, a DSN antenna will be used to “shout” the command to Voyager to turn its antenna. This intermediary attempt may not work, in which case the team will wait for the spacecraft to automatically reset its orientation in October.</i></p></div><p itemprop="abstract">
      Once the spacecraft’s antenna is realigned with Earth, communications should resume.
    </p></div>]]></description>
        </item>
    </channel>
</rss>