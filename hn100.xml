<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 23 Oct 2023 21:00:08 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Google pulls up the ladder on open internet, pushes unconstitutional regulation (221 pts)]]></title>
            <link>https://www.techdirt.com/2023/10/23/google-decides-to-pull-up-the-ladder-on-the-open-internet-pushes-for-unconstitutional-regulatory-proposals/</link>
            <guid>37990031</guid>
            <pubDate>Mon, 23 Oct 2023 18:58:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techdirt.com/2023/10/23/google-decides-to-pull-up-the-ladder-on-the-open-internet-pushes-for-unconstitutional-regulatory-proposals/">https://www.techdirt.com/2023/10/23/google-decides-to-pull-up-the-ladder-on-the-open-internet-pushes-for-unconstitutional-regulatory-proposals/</a>, See on <a href="https://news.ycombinator.com/item?id=37990031">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storywrap-423673">


<h3>from the <i>not-cool</i> dept</h3>

<p>It’s pretty much the way of the world: beyond the basic <a rel="noreferrer noopener" href="https://www.techdirt.com/tag/enshittification/" target="_blank">enshittification</a> story that has been so well told over the past year or so about how companies get worse and worse as they get more and more powerful, there’s also the well known concept of successful innovative companies “pulling up the ladder” behind them, using the regulatory process to make it impossible for other companies to follow their own path to success. We’ve talked about this in the sense of <a rel="noreferrer noopener" href="https://www.techdirt.com/2011/02/03/entrepreneurs-who-create-value-vs-entrepreneurs-who-lock-up-value/" target="_blank"><em>political entrepreneurship</em></a>, which is when the main entrepreneurial effort is not to innovate in newer and better products for customers, but rather using the political system for personal gain and to prevent competitors from havng the same opportunities.</p>
<p>It happens all too frequently. And it’s been happening lately with the big internet companies, which relied on the open internet to become successful, but under massive pressure from regulators (and the media), keep shooting the open internet in the back, each time they can present themselves as “supportive” of some dumb regulatory regime. Facebook did it six years ago by <a rel="noreferrer noopener" href="https://www.techdirt.com/2017/11/08/will-sheryl-sandberg-facebook-help-small-websites-threatened-sesta/" target="_blank">supporting FOSTA wholeheartedly</a>, which was the key tide shift that made the law viable in Congress.</p>
<p>And, now, it appears that Google is going down that same path. There have been hints here and there, such as when it mostly <a rel="noreferrer noopener" href="https://www.techdirt.com/2017/04/14/dont-wait-google-netflix-facebooks-help-if-you-want-to-save-net-neutrality/" target="_blank">gave up the fight</a> on net neutrality six years ago. However, Google had still appeared to be active in various fights to protect an open internet. </p>
<p>But, last week, Google took a big step towards pulling up the open internet ladder behind it, which got almost no coverage (and what coverage it got was misleading). And, for the life of me, I don’t understand why it chose to do this now. It’s one of the dumbest policy moves I’ve seen Google make in ages, and seems like a complete unforced error.</p>
<p>Last Monday, Google announced “<a rel="noreferrer noopener" href="https://blog.google/outreach-initiatives/public-policy/google-legislation-framework-children-teens-safety/" target="_blank">a policy framework to protect children and teens online</a>,” which was echoed by subsidiary YouTube, which posted basically the same thing, talking about it’s “<a rel="noreferrer noopener" href="https://blog.youtube/inside-youtube/youtubes-principled-approach-children-teenagers/" target="_blank">principled approach for children and teenagers</a>.” Both of these pushed not just a “principled approach” for companies to take, but <a rel="noreferrer noopener" href="https://static.googleusercontent.com/media/publicpolicy.google/en//resources/youth-legislative-framework.pdf" target="_blank">a legislative model</a> (and I hear that they’re out pushing “model bills” across legislatures as well).</p>
<p>The “legislative” model is, effectively, California’s Age Appropriate Design Code. Yes, the very law that was<a target="_blank" rel="noreferrer noopener" href="https://www.techdirt.com/2023/09/19/court-says-californias-age-appropriate-design-code-is-unconstitutional-just-as-we-warned/"> just declared unconstitutional</a> just a few weeks before Google basically threw its weight behind the approach. What’s funny is that many, many people have (incorrectly) believed that Google was some sort of legal mastermind behind the NetChoice lawsuits challenging California’s law and other similar laws, when the reality appears to be that Google knows full well that it can handle the requirements of the law, but smaller competitors cannot. Google likes the law. It wants more of them, apparently.</p>
<p>The model includes “age assurance” (which is effectively age verification, though everyone pretends it’s not), greater parental surveillance, and the compliance nightmare of “impact assessments” (we <a rel="noreferrer noopener" href="https://www.techdirt.com/2022/08/24/dear-california-law-makers-how-the-hell-can-i-comply-with-your-new-age-appropriate-design-code/" target="_blank">talked about this nonsense</a> in relation to the California law). <strong>Again, for many companies this is a good idea</strong>. But just because something is a good idea for companies to do <em>does not mean</em> that it should be mandated by law.</p>
<p>But that’s exactly what Google is pushing for here, even as a law that more or less mimics its framework was just found to be unconstitutional. While cynical people will say that maybe Google is supporting these policies hoping that they will continue to be found unconstitutional, I see little evidence to support that. Instead, it really sounds like Google is fully onboard with these kinds of duty of care regulations that will harm smaller competitors, but which Google can handle just fine.</p>
<p>It’s pulling up the ladder behind it.</p>
<p>And yet, the press coverage of this focused on the fact that this was being presented as an “alternative” to a full on ban for kids under 18 to be on social media. The Verge <a rel="noreferrer noopener" href="https://www.theverge.com/2023/10/16/23919221/google-youtube-child-safety-age-verification-laws-privacy" target="_blank">framed this </a>as “Google asks Congress not to ban teens from social media,” leaving out that it was Google asking Congress to basically make it impossible for any site other than the largest, richest companies to be able to allow teens on social media. Same thing with TechCrunch, which framed it as Google <a rel="noreferrer noopener" href="https://techcrunch.com/2023/10/16/google-lobbies-against-legally-mandated-age-verification-for-minors/" target="_blank">lobbying against age verification</a>.</p>
<p>But… it’s not? It’s basically lobbying for age verification, just in the guise of “age assurance,” which is effectively “age verification, but if you’re a smaller company you can get it wrong some undefined amount of time, until someone sues you.” I mean, what’s here is not “lobbying against age verification,” it’s basically saying “here’s how to require age verification.”</p>
<blockquote>
<p><em>A good understanding of user age can help online services offer age-appropriate experiences. That said, any method to determine the age of users across services comes with tradeoffs, such as intruding on privacy interests, requiring more data collection and use, or restricting adult users’ access to important information and services. Where required, age assurance – which can range from declaration to inference and verification – should be risk-based, preserving users’ access to information and services, and respecting their privacy. Where legislation mandates age assurance, it should do so through a workable, interoperable standard that preserves the potential for anonymous or pseudonymous experiences. It should avoid requiring collection or processing of additional personal information, treating all users like children, or impinging on the ability of adults to access information. More data-intrusive methods (such as verification with “hard identifiers” like government IDs) should be limited to high-risk services (e.g., alcohol, gambling, or pornography) or age correction. Moreover, age assurance requirements should permit online services to explore and adapt to improved technological approaches. In particular, requirements should enable new, privacy-protective ways to ensure users are at least the required age before engaging in certain activities. Finally, because age assurance technologies are novel, imperfect, and evolving, requirements should provide reasonable protection from liability for good-faith efforts to develop and implement improved solutions in this space.</em></p>
</blockquote>
<p>Much like Facebook caving on FOSTA, this is Google caving on age verification and other “duty of care” approaches to regulating the way kids have access to the internet. It’s pulling up the ladder behind itself, knowing that it was able to grow without having to take these steps, and making sure that none of the up-and-coming challenges to Google’s position will have the same freedom to do so.</p>
<p>And, for what? So that Google can go to regulators and say “look, we’re not against regulations, here’s our framework”? But Google has smart policy people. They have to know how this plays out in reality. Just as with FOSTA, it completely backfired on Facebook (and the open internet). This approach will do the same.</p>
<p>Not only will these laws inevitably be used against the companies themselves, they’ll also be weaponized and modified by policymakers who will make them even worse and even more dangerous, all while pointing to Google’s “blessing” of this approach as an endorsement.</p>
<p>For years, Google had been somewhat unique in continuing to fight for the open internet long after many other companies were switching over to ladder pulling. There were hints that Google was going down this path in the past, but with this policy framework, the company has now made it clear that it has no intention of being a friend to the open internet any more.</p>
<p>
Filed Under: <a href="https://www.techdirt.com/tag/aadc/" rel="tag">aadc</a>, <a href="https://www.techdirt.com/tag/age-appropriate-design-code/" rel="tag">age appropriate design code</a>, <a href="https://www.techdirt.com/tag/age-assurance/" rel="tag">age assurance</a>, <a href="https://www.techdirt.com/tag/age-estimation/" rel="tag">age estimation</a>, <a href="https://www.techdirt.com/tag/age-verification/" rel="tag">age verification</a>, <a href="https://www.techdirt.com/tag/duty-of-care/" rel="tag">duty of care</a>, <a href="https://www.techdirt.com/tag/for-the-children/" rel="tag">for the children</a>
<br>
Companies: <a href="https://www.techdirt.com/company/google/" rel="category tag">google</a>
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Off-duty pilot tried to crash Alaska Airlines SFO flight, officials say (150 pts)]]></title>
            <link>https://sfstandard.com/2023/10/23/sfo-alaska-airlines-pilot-crash-plane/</link>
            <guid>37989160</guid>
            <pubDate>Mon, 23 Oct 2023 17:53:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sfstandard.com/2023/10/23/sfo-alaska-airlines-pilot-crash-plane/">https://sfstandard.com/2023/10/23/sfo-alaska-airlines-pilot-crash-plane/</a>, See on <a href="https://news.ycombinator.com/item?id=37989160">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>An off-duty pilot riding in the cockpit of an Alaska Airlines' Horizon Air flight bound for San Francisco International Airport (SFO) tried to crash the plane, officials say. </p><p>The San Francisco-bound flight on Sunday diverted to Portland, where it was met by law enforcement officers. The flight took off from Everett, Washington, at 5:23 p.m. and landed in Portland an hour later.</p><p>Federal officials allege Joseph David Emerson tried to shut down the engines in midflight and had to be subdued by the two pilots.</p><p>Authorities in Portland identified the man as Emerson, 44. He was being held Monday on dozens of counts of attempted murder and reckless endangerment, according to the Multnomah County Sheriff’s Office in Oregon.</p><p>The Port of Portland Police Department "is working closely with our partners at the FBI, TSA, FAA, and Multnomah County District Attorney’s Office," the department told The Standard in an emailed statement. </p><figure><span><span></span><img alt="" sizes="(min-width: 1001px) 650px, (min-width: 768px) 550px, 100vw" srcset="https://content.sfstandard.com/wp-content/uploads/2023/10/SFOEats111822_302.jpg?w=2500?w=640&amp;q=75 640w, https://content.sfstandard.com/wp-content/uploads/2023/10/SFOEats111822_302.jpg?w=2500?w=750&amp;q=75 750w, https://content.sfstandard.com/wp-content/uploads/2023/10/SFOEats111822_302.jpg?w=2500?w=768&amp;q=75 768w, https://content.sfstandard.com/wp-content/uploads/2023/10/SFOEats111822_302.jpg?w=2500?w=828&amp;q=75 828w, https://content.sfstandard.com/wp-content/uploads/2023/10/SFOEats111822_302.jpg?w=2500?w=1024&amp;q=75 1024w, https://content.sfstandard.com/wp-content/uploads/2023/10/SFOEats111822_302.jpg?w=2500?w=1080&amp;q=75 1080w, https://content.sfstandard.com/wp-content/uploads/2023/10/SFOEats111822_302.jpg?w=2500?w=1200&amp;q=75 1200w, https://content.sfstandard.com/wp-content/uploads/2023/10/SFOEats111822_302.jpg?w=2500?w=1920&amp;q=75 1920w, https://content.sfstandard.com/wp-content/uploads/2023/10/SFOEats111822_302.jpg?w=2500?w=2048&amp;q=75 2048w, https://content.sfstandard.com/wp-content/uploads/2023/10/SFOEats111822_302.jpg?w=2500?w=3840&amp;q=75 3840w" src="https://content.sfstandard.com/wp-content/uploads/2023/10/SFOEats111822_302.jpg?w=2500?w=3840&amp;q=75" decoding="async" data-nimg="responsive" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span><figcaption>A man loads his luggage into a Tesla at the San Francisco International Airport (SFO). | <span>Source: </span>Benjamin Fanjoy/The Standard</figcaption></figure><p>Emerson is being held in jail on suspicion of 83 counts of attempted murder, 83 counts of reckless endangerment and a single count of endangering an aircraft, according to Oregon jail records.</p><p>Alaska Airlines, which owns Horizon, said Monday that the crew reported “a credible security threat related to an authorized occupant in the flight deck jump seat.” The airline said in a statement that no weapons were involved.</p><p>"All passengers on board were able to travel on a later flight," the airline told The Standard in an emailed statement. "We are grateful for the professional handling of the situation by the Horizon flight crew and appreciate our guests’ calm and patience throughout this event.</p><p>One of the pilots told air traffic controllers that the man who posed the threat had been removed from the cockpit.</p><p>“We’ve got the guy that tried to shut the engines down out of the cockpit. And he—doesn’t sound like he’s causing any issue in the back right now, and I think he’s subdued," one of the pilots said on audio captured by LiveATC.com. "Other than that, we want law enforcement as soon as we get on the ground and parked.”</p><p>The incident occurred on a 76-seat Embraer 175 plane. The FBI is investigating.</p><p>When the jump seat, a third seat in the cockpit, is occupied, it’s often filled by an off-duty pilot, but the seat can be used by other airline employees or federal safety inspectors.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cleveland launches plan to provide cheap broadband (127 pts)]]></title>
            <link>https://www.techdirt.com/2023/10/23/tired-of-being-ripped-off-by-monopolies-cleveland-launches-ambitious-plan-to-provide-citywide-dirt-cheap-broadband/</link>
            <guid>37988483</guid>
            <pubDate>Mon, 23 Oct 2023 17:05:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techdirt.com/2023/10/23/tired-of-being-ripped-off-by-monopolies-cleveland-launches-ambitious-plan-to-provide-citywide-dirt-cheap-broadband/">https://www.techdirt.com/2023/10/23/tired-of-being-ripped-off-by-monopolies-cleveland-launches-ambitious-plan-to-provide-citywide-dirt-cheap-broadband/</a>, See on <a href="https://news.ycombinator.com/item?id=37988483">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storywrap-423274">


<h3>from the <i>do-not-pass-go,-do-not-collect-$200</i> dept</h3>

<p>Cleveland has spent years being dubbed the “<a href="https://www.cleveland.com/news/2020/09/cleveland-ranks-as-worst-connected-large-city-for-internet-in-2019.html" data-type="link" data-id="https://www.cleveland.com/news/2020/09/cleveland-ranks-as-worst-connected-large-city-for-internet-in-2019.html">worst connected city in the U.S.</a>” thanks to expensive, patchy, and slow broadband. Why Cleveland broadband sucks so badly isn’t really a mystery: consolidated monopoly/duopoly power has resulted in a broken market where local giants like AT&amp;T and Charter don’t have to compete on price, speeds, availability, customer service, or much of anything else. </p>
<p><a href="https://www.techdirt.com/2017/05/05/att-takes-heat-avoiding-broadband-upgrades-poor-areas/" data-type="link" data-id="https://www.techdirt.com/2017/05/05/att-takes-heat-avoiding-broadband-upgrades-poor-areas/">Data also shows</a> that despite billions in tax breaks, regulatory favors, and subsidies, companies like AT&amp;T have long refused to upgrade low-income and minority Cleveland neighborhoods to fiber. These companies not only engage in this deployment “redlining,” but data also makes it clear they often charge these low income and minority neighborhoods <a href="https://www.cnet.com/home/internet/features/the-broadband-gaps-dirty-secret-redlining-still-exists-in-digital-form/" data-type="link" data-id="https://www.cnet.com/home/internet/features/the-broadband-gaps-dirty-secret-redlining-still-exists-in-digital-form/">more money for the same or slower broadband</a>. </p>
<p>Last week I spent some time <a href="https://communitynets.org/content/clevelands-two-pronged-attack-make-worse-connected-city-label-relic-past" data-type="link" data-id="https://communitynets.org/content/clevelands-two-pronged-attack-make-worse-connected-city-label-relic-past">talking to Cleveland city leaders and local activists</a> about their plan to do something about it. On one hand, they’ve doled out $20 million in COVID relief broadband funding to local non-profit DigitalC to deliver fixed wireless broadband at speeds of 100 Mbps for as little as $18. </p>
<p>On the other hand, they’ve convinced a company named SiFi Networks to build a $500 million open access fiber network at no cost to taxpayers. SiFi Networks will benefit from a tight relationship with the city, while making its money from leasing access to the network to ISPs. </p>
<p>We’ve noted (see our <a href="https://www.techdirt.com/2022/07/18/just-a-click-away-how-to-improve-broadband-competition/" data-type="link" data-id="https://www.techdirt.com/2022/07/18/just-a-click-away-how-to-improve-broadband-competition/">Copia report on broadband competition</a>) that such open access networks routinely lower the cost for ISP market entry, boost competition, and generally result in lower prices. Monopolies like AT&amp;T, of course, have long opposed the idea, even if they would technically benefit from lower access costs, because it chips away at their consolidated monopoly power. </p>
<p>Local activists like DigitalC CEO Joshua Edmonds tell me they hope the project teaches U.S. towns and cities that there are alternatives to being feckless supplicants to regional telecom mono/duopolies:</p>
<blockquote>
<p><em>“This is a major victory, and I hope that people don’t look at it as just a major victory for Cleveland. Every city where there’s a prevalent digital divide, where there’s political will and ability to execute, people should be paying close attention to what happens in Cleveland, paying close attention to how DigitalC was able to fight and navigate with our coalition of stakeholders.”</em></p>
</blockquote>
<p>We’ll see what the finished network looks like. And now that Cleveland is challenging monopoly power, it will be interesting to see if local monopolies focus on challenging Cleveland. Big ISPs like AT&amp;T and Charter want to have their cake and eat it too; they don’t want to uniformly upgrade their broadband networks to next-gen speeds, but they genuinely don’t want others to do so either. </p>
<p>It’s a lot easier and cheaper to throw a bunch of campaign contributions at corrupt policymakers (<a href="https://www.techdirt.com/2021/02/19/new-bill-tries-to-ban-community-broadband-during-pandemic/" data-type="link" data-id="https://www.techdirt.com/2021/02/19/new-bill-tries-to-ban-community-broadband-during-pandemic/">remember with the GOP wanted to ban all community broadband networks country-wide during the peak of the pandemic?</a> or how the telecom and GOP worked in concert to pass laws in 20 states effectively <a href="https://www.techdirt.com/2021/04/15/washington-state-votes-to-kill-law-that-restricted-community-broadband/" data-type="link" data-id="https://www.techdirt.com/2021/04/15/washington-state-votes-to-kill-law-that-restricted-community-broadband/">banning towns and cities from making these choices for themselves</a>?).</p>
<p>Community-owned broadband networks aren’t a magical panacea. Such efforts are like any other business plan, and require competency in design and implementation. But the community-owned and operated networks in more than 1,000 U.S. cities can (and routinely do) prompt a very broken and federal government-coddled status quo to actually try for once, much to its chagrin. </p>
<p>
Filed Under: <a href="https://www.techdirt.com/tag/broadband/" rel="tag">broadband</a>, <a href="https://www.techdirt.com/tag/cleveland/" rel="tag">cleveland</a>, <a href="https://www.techdirt.com/tag/community-broadband/" rel="tag">community broadband</a>, <a href="https://www.techdirt.com/tag/digital-divide/" rel="tag">digital divide</a>, <a href="https://www.techdirt.com/tag/digitalc/" rel="tag">digitalc</a>, <a href="https://www.techdirt.com/tag/high-speed-internet/" rel="tag">high speed internet</a>, <a href="https://www.techdirt.com/tag/municipal-broadband/" rel="tag">municipal broadband</a>, <a href="https://www.techdirt.com/tag/telecom/" rel="tag">telecom</a>
<br>
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[UK Government Caught Surveilling Social Media of Teaching Assistants (156 pts)]]></title>
            <link>https://reclaimthenet.org/uk-government-caught-surveilling-social-media-of-teaching-assistants-and-librarians</link>
            <guid>37987573</guid>
            <pubDate>Mon, 23 Oct 2023 15:58:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reclaimthenet.org/uk-government-caught-surveilling-social-media-of-teaching-assistants-and-librarians">https://reclaimthenet.org/uk-government-caught-surveilling-social-media-of-teaching-assistants-and-librarians</a>, See on <a href="https://news.ycombinator.com/item?id=37987573">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-id="15a99740" data-element_type="widget" data-widget_type="theme-post-content.default">
			
<p>A startling revelation indicates that the UK government has substantially amplified its surveillance of the online activity of educators. Ranging from leading education experts to teaching assistants and librarians earning modest salaries, the magnifying glass of surveillance closely monitors posts critiquing education policies. The discovery was made by <a href="https://www.theguardian.com/politics/2023/oct/21/uk-government-keeping-files-on-teaching-assistants-and-librarians-internet-activity">The Observer</a>, revealing that the Department for Education is keeping extensive records of such posts, something that we’ve <a href="https://reclaimthenet.org/uk-government-monitored-the-social-media-activity-of-education-critics">previously covered.</a></p>
<p>This revelation highlights the burning issues of free speech and censorship, causing widespread disquiet among the educational community. The surveillance of educators’ online activity portrays a scenario where dissent or criticism of government policy is not only surveilled but also cataloged, potentially affecting the educators’ professional careers.</p>
<p>Educators across the UK have demonstrated a wave of shock and anger in response to the discovery. Many have submitted Subject Access Requests [SARs], a Right to Access provision within the General Data Protection Regulation, requiring the Department of Education to disclose the information it holds under their names. These educators found file lengths spanning up to 60 pages, documenting their tweets and comments opposing the government’s policies and criticizing the schools inspectorate, Ofsted.</p>
<p>Nikki Cleveland, a higher-level teaching assistant and primary school librarian, was astounded to find that even her tweets concerning issues such as inadequate funding for school libraries and criticisms of Ofsted had been flagged and stored by the Department. Her discovery has only raised her cynicism towards the government and the Department of Education, questioning their apathy towards the challenges schools face daily.</p>
<p>This disturbing surveillance operation extends to more than just educators. Jon Biddle, a primary school teacher and English lead, reported that “dozens of other teachers” he knew had also discovered their accounts were under scrutiny. The scope and depth of this surveillance has led to growing skepticism about the Department’s priorities and resource allocation.</p>
<p>Cases have also surfaced of the Department attempting to silence voices critical of government policy. Early years specialists Ruth Swailes and Aaron Bradbury have previously faced attempts from the Department to cancel their conference due to their earlier critiques. Similarly, Dr. Mine Conkbayir, a renowned early childhood author, was allegedly threatened with funding withdrawal for a conference she was scheduled to keynote, due to her criticisms. As she recounts, the Department also attempted to curtail her talk duration and verify her speech contents, pulling the strings of academic dialogue.</p>
<p>In response to these revelations, the Department has chosen to remain largely opaque, stating that it would not be appropriate to comment on individual cases.</p>

<!-- AI CONTENT END 1 -->
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Common fungus candida albicans might fuel Alzheimer's onset (105 pts)]]></title>
            <link>https://neurosciencenews.com/alzheimers-fungus-24955/</link>
            <guid>37987061</guid>
            <pubDate>Mon, 23 Oct 2023 15:26:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://neurosciencenews.com/alzheimers-fungus-24955/">https://neurosciencenews.com/alzheimers-fungus-24955/</a>, See on <a href="https://news.ycombinator.com/item?id=37987061">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main><article><div><p><strong>Summary: </strong>Researchers explored the link between the fungus Candida albicans and Alzheimer’s disease.</p><p>They found that C. albicans produces enzymes breaking down the blood-brain barrier, allowing it to access the brain and produce toxic amyloid beta-like peptides, typically associated with Alzheimer’s.</p><p>These peptides activate microglial brain cells to keep fungal load low but don’t clear the infection.</p><p>The study suggests that the amyloid beta aggregates in Alzheimer’s could be generated both by the brain and by C. albicans.</p><p><strong>Key Facts:</strong></p><ol><li>The fungus <em>Candida albicans</em> produces enzymes that break down the blood-brain barrier and produce toxic amyloid beta-like peptides.</li><li>These peptides activate microglial brain cells, helping in partially controlling the fungal infection.</li><li>Amyloid beta aggregates associated with Alzheimer’s might be produced both by the brain and the fungus <em>C. albicans</em>.</li></ol><p><strong>Source: </strong>Baylor College of Medicine</p><p><strong>Previous research has implicated fungi in chronic neurodegenerative conditions such as Alzheimer’s disease, but there is limited understanding of how these common microbes could be involved in the development of these conditions.</strong></p><p>Working with animal models, researchers at Baylor College of Medicine and collaborating institutions discovered how the fungus&nbsp;<em>Candida albicans</em>&nbsp;enters the brain, activates two separate mechanisms in brain cells that promote its clearance, and, important for the understanding of Alzheimer’s disease development, generates amyloid beta (Ab)-like peptides, toxic protein fragments from the amyloid precursor protein that are considered to be at the center of the development of Alzheimer’s disease.</p><p>The study appears in the journal&nbsp;<em>Cell Reports</em>.</p><figure><picture decoding="async" fetchpriority="high"> <source type="image/webp" srcset="https://neurosciencenews.com/files/2023/10/alzheimers-fungus-neuroscience.jpg.webp 1200w, https://neurosciencenews.com/files/2023/10/alzheimers-fungus-neuroscience-300x200.jpg.webp 300w, https://neurosciencenews.com/files/2023/10/alzheimers-fungus-neuroscience-770x513.jpg.webp 770w, https://neurosciencenews.com/files/2023/10/alzheimers-fungus-neuroscience-1155x770.jpg.webp 1155w, https://neurosciencenews.com/files/2023/10/alzheimers-fungus-neuroscience-370x247.jpg.webp 370w, https://neurosciencenews.com/files/2023/10/alzheimers-fungus-neuroscience-293x195.jpg.webp 293w, https://neurosciencenews.com/files/2023/10/alzheimers-fungus-neuroscience-150x100.jpg.webp 150w" sizes="(max-width: 1200px) 100vw, 1200px"> <img decoding="async" fetchpriority="high" width="1200" height="800" src="https://neurosciencenews.com/files/2023/10/alzheimers-fungus-neuroscience.jpg" alt="This shows a brain." srcset="https://neurosciencenews.com/files/2023/10/alzheimers-fungus-neuroscience.jpg 1200w, https://neurosciencenews.com/files/2023/10/alzheimers-fungus-neuroscience-300x200.jpg 300w, https://neurosciencenews.com/files/2023/10/alzheimers-fungus-neuroscience-770x513.jpg 770w, https://neurosciencenews.com/files/2023/10/alzheimers-fungus-neuroscience-1155x770.jpg 1155w, https://neurosciencenews.com/files/2023/10/alzheimers-fungus-neuroscience-370x247.jpg 370w, https://neurosciencenews.com/files/2023/10/alzheimers-fungus-neuroscience-293x195.jpg 293w, https://neurosciencenews.com/files/2023/10/alzheimers-fungus-neuroscience-150x100.jpg 150w" sizes="(max-width: 1200px) 100vw, 1200px"> </picture><figcaption>Here, the researchers show that the Ab-like peptides also can be generated from a different source – C. albicans. Credit: Neuroscience News</figcaption></figure><p>“Our lab has years of experience studying fungi, so we embarked on the study of the connection between&nbsp;<em>C. albicans</em>&nbsp;and Alzheimer’s disease in animal models,” said corresponding author&nbsp;Dr. David Corry, Fulbright Endowed Chair in Pathology and professor of pathology and immunology and medicine at Baylor. He also is a member of Baylor’s Dan L Duncan Comprehensive Cancer Center.</p><p>“In 2019, we&nbsp;reported&nbsp;that&nbsp;<em>C. albicans</em>&nbsp;does get into the brain where it produces changes that are very similar to what is seen in Alzheimer’s disease. The current study extends that work to understand the molecular mechanisms.”</p><p>“Our first question was, how does&nbsp;<em>C. albicans</em>&nbsp;enter the brain? We found that&nbsp;<em>C. albicans</em>&nbsp;produces enzymes called secreted aspartic proteases (Saps) that breakdown the blood-brain barrier, giving the fungus access to the brain where it causes damage,” said first author&nbsp;Dr. Yifan Wu, postdoctoral scientist in pediatrics working in the Corry lab.</p><p>Next, the researchers asked, how is the fungus effectively cleared from the brain? Corry and his colleagues had&nbsp;previously shown&nbsp;that a&nbsp;<em>C. albicans</em>&nbsp;brain infection is fully resolved in otherwise healthy mice after 10 days. In this study, they reported that this occurred thanks to two mechanisms triggered by the fungus in brain cells called microglia.</p><p>“The same Saps that the fungus uses to break the blood-brain barrier also break down the amyloid precursor protein into AB-like peptides,” Wu said. “These peptides activate microglial brain cells via a cell surface receptor called Toll-like receptor 4, which keeps the fungi load low in the brain, but does not clear the infection.”</p><p><em>C. albicans</em>&nbsp;also produces a protein called candidalysin that also binds to microglia via a different receptor, CD11b. “Candidalysin-mediated activation of microglia is essential for clearance of&nbsp;<em>Candida</em>&nbsp;in the brain,” Wu said. “If we take away this pathway, fungi are no longer effectively cleared in the brain.”</p><p>“This work potentially contributes an important new piece of the puzzle regarding the development of Alzheimer’s disease,” Corry said.</p><p>“The current explanation for this condition is that it is mostly the result of the accumulation of toxic Ab-like peptides in the brain that leads to neurodegeneration. The dominant thinking is that these peptides are produced endogenously, our own brain proteases break down the amyloid precursor proteins generating the toxic Ab peptides.”</p><p>Here, the researchers show that the Ab-like peptides also can be generated from a different source –&nbsp;<em>C. albicans</em>. This common fungus, which has been detected in the brains of people with Alzheimer’s disease and other chronic neurodegenerative disorders, has its own set of proteases that can generate the same Ab-like peptides the brain can generate endogenously.</p><p>“We propose that the brain Ab-peptide aggregates that characterize multiple&nbsp;<em>Candida</em>-associated neurodegenerative conditions including Alzheimer’s disease, Parkinson’s disease and others, may be generated both intrinsically by the brain and by&nbsp;<em>C. albicans</em>,” Corry said.</p><p>“These findings in animal models support conducting further studies to evaluate the role of&nbsp;<em>C. albicans</em>&nbsp;in the development of Alzheimer’s disease in people, which can potentially lead to innovative therapeutic strategies.”</p><h2>About this Alzheimer’s disease research news</h2><p><strong>Author: </strong><a href="https://neurosciencenews.com/cdn-cgi/l/email-protection#c189aeaca0ef96a0b3b3a4af81a3a2acefa4a5b4" target="_blank" rel="noreferrer noopener">Homa Warren</a><br><strong>Source: </strong><a href="https://bcm.edu/" target="_blank" rel="noreferrer noopener">Baylor College of Medicine</a><br><strong>Contact: </strong>Homa Warren – Baylor College of Medicine<br><strong>Image: </strong>The image is credited to Neuroscience News</p><p><strong>Original Research: </strong>Open access.<br>“<a href="https://www.cell.com/cell-reports/pdf/S2211-1247(23)01252-4.pdf" target="_blank" rel="noreferrer noopener">Toll-like receptor 4 and CD11b expressed on microglia coordinate eradication of Candida albicans cerebral mycosis</a>” by David Corry et al. <em>Cell Reports</em></p><hr> <!-- Form created by Optin Forms plugin by WPKube: create beautiful optin forms with ease! --> <!-- https://wpkube.com/ --><!--optinforms-form5-container--> <!-- / Optin Forms --> </div><!-- .entry-content --><!-- .entry-footer --></article><!-- #post-x --></main><!-- .site-main --></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Driver's failure to laugh at odd question during stop not Reasonable Suspicion (122 pts)]]></title>
            <link>http://fourthamendment.com/?p=56109</link>
            <guid>37986083</guid>
            <pubDate>Mon, 23 Oct 2023 14:25:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://fourthamendment.com/?p=56109">http://fourthamendment.com/?p=56109</a>, See on <a href="https://news.ycombinator.com/item?id=37986083">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-56109">
		    
			<!-- .entry-meta -->
			<div>
			    
<p>Defendant’s failure to laugh at the question of whether he had “firearms, drugs, cats, dogs, alligators, and weapons” in his vehicle stop was not reasonable suspicion. United States v. Holloway, 2023 U.S. Dist. LEXIS 187752 (E.D. Pa. Oct. 18, 2023):</p>



<blockquote><p>Officer Smart testified that he regularly asks individuals a question concerning possession of “firearms, drugs, cats, dogs, alligators, and weapons” at vehicle stops because it “helps [him] read people’s body language and their demeanor.” … He further testified that he was trained by other officers to infer that an individual who does not laugh at such a question is nervous about either firearms or narcotics … and that he typically receives a “laughing response” to that question …. While courts “do give considerable deference to police officers’ determinations of reasonable suspicion, … courts do not owe them blind deference.” United States v. Alvin, 701 F. App’x 151, 156 (3d Cir. 2017) (internal quotations omitted). The Court does not find that laughing at a law enforcement officer while being questioned about drugs and weapons would be an appropriate response. Moreover, failing to laugh at a bizarre question while being questioned about drugs and weapons does not create reasonable suspicion to remove an individual from a car after a traffic violation.</p></blockquote>



<p>Note that the officer said he got that from other officers, not from official training.</p>
			    			</div><!-- .entry-content -->


		<div><p>
		    This entry was posted in <a href="http://fourthamendment.com/?cat=35" rel="category">Reasonable suspicion</a>. Bookmark the <a href="http://fourthamendment.com/?p=56109" title="Permalink to E.D.Pa.: Driver’s failure to laugh at odd question during stop not RS" rel="bookmark">permalink</a>.		    		</p></div><!-- .entry-utility -->
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Yarn 4.0 (146 pts)]]></title>
            <link>https://yarnpkg.com/blog/release/4.0</link>
            <guid>37985779</guid>
            <pubDate>Mon, 23 Oct 2023 14:01:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://yarnpkg.com/blog/release/4.0">https://yarnpkg.com/blog/release/4.0</a>, See on <a href="https://news.ycombinator.com/item?id=37985779">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__blog-post-container" itemprop="articleBody"><p>Today is the day! After more than a year of work, our team is excited to finally put a fancy "stable" sticker on the first release from the 4.x release line! To celebrate, let's make together a tour of the major changes; should you look for a more itemized list, take a look at the <a href="https://yarnpkg.com/advanced/changelog#400">changelog</a>.</p><h2 id="breaking-changes">Breaking Changes<a href="#breaking-changes" aria-label="Direct link to Breaking Changes" title="Direct link to Breaking Changes">​</a></h2><p>Here's what you need to know when upgrading from 3.x projects:</p><ul><li>We now require Node.js 18+.</li><li>New projects created with <span><code><span data-type="binary">yarn</span> <a data-tooltip-id="tooltip" data-tooltip-content="Create a new package
" href="https://yarnpkg.com/cli/init"><span data-type="path">init</span></a></code></span> won't enable <a href="https://yarnpkg.com/features/caching#zero-installs">Zero-Install</a> by default anymore.</li><li>New projects created with <span><code><span data-type="binary">yarn</span> <a data-tooltip-id="tooltip" data-tooltip-content="Create a new package
" href="https://yarnpkg.com/cli/init"><span data-type="path">init</span></a></code></span> will use <a href="https://nodejs.org/api/corepack.html" target="_blank" rel="noopener noreferrer">Corepack</a> rather than <code data-tooltip-id="tooltip" data-tooltip-content="Path of a Yarn binary to use instead of the global one."><a href="https://yarnpkg.com/configuration/yarnrc#yarnPath">yarnPath</a></code>.</li><li>All official plugins (<code>typescript</code>, <code>interactive-tools</code>, ...) are now included by default.</li><li>The <span><code><span data-type="binary">yarn</span> <a data-tooltip-id="tooltip" data-tooltip-content="Run a command on all workspaces
" href="https://yarnpkg.com/cli/workspaces/foreach"><span data-type="path">workspaces</span> <span data-type="path">foreach</span></a></code></span> command has a slightly altered syntax.</li></ul><h2 id="installing-yarn">Installing Yarn<a href="#installing-yarn" aria-label="Direct link to Installing Yarn" title="Direct link to Installing Yarn">​</a></h2><p>Ever since the 2.0 our recommendation has been to install Yarn on a per-project basis using the <code data-tooltip-id="tooltip" data-tooltip-content="Path of a Yarn binary to use instead of the global one."><a href="https://yarnpkg.com/configuration/yarnrc#yarnPath">yarnPath</a></code> setting (automatically set either of <span><code><span data-type="binary">yarn</span> <a data-tooltip-id="tooltip" data-tooltip-content="Create a new package
" href="https://yarnpkg.com/cli/init"><span data-type="path">init</span></a> <span data-type="dash">-</span><span data-type="option">2</span></code></span> and <span><code><span data-type="binary">yarn</span> <a data-tooltip-id="tooltip" data-tooltip-content="Lock the yarn version used by the project
" href="https://yarnpkg.com/cli/set/version"><span data-type="path">set</span> <span data-type="path">version</span></a></code></span>). We intentionally don't release modern releases on the npm <span><code><span data-type="binary">yarn</span></code></span> package, <a href="https://yarnpkg.com/getting-started/qa#why-is-the-yarn-package-on-npm-still-on-1x">so as not to break older projects which didn't migrate yet</a>.</p><p>To that end we used to recommend using the <code data-tooltip-id="tooltip" data-tooltip-content="Path of a Yarn binary to use instead of the global one."><a href="https://yarnpkg.com/configuration/yarnrc#yarnPath">yarnPath</a></code> setting pointing to a checked-in binary, but this pattern increased friction more than we liked - many people didn't like the idea of adding a binary to their repository, however small. We listened, and worked conjointely with Node.js on a project called <a href="https://nodejs.org/api/corepack.html" target="_blank" rel="noopener noreferrer">Corepack</a>. Corepack is a tool shipped with Node.js 16+ that will automatically select the right package manager version to run depending on the project you're working on.</p><p>Now that Corepack is shipped with both Node 18 and 20 we no longer need to rely on <code data-tooltip-id="tooltip" data-tooltip-content="Path of a Yarn binary to use instead of the global one."><a href="https://yarnpkg.com/configuration/yarnrc#yarnPath">yarnPath</a></code>, and as a result we updated our <a href="https://yarnpkg.com/getting-started/install">installation guide</a> to reflect that. The <span><code><span data-type="binary">yarn</span> <a data-tooltip-id="tooltip" data-tooltip-content="Create a new package
" href="https://yarnpkg.com/cli/init"><span data-type="path">init</span></a> <span data-type="dash">-</span><span data-type="option">2</span></code></span> and <span><code><span data-type="binary">yarn</span> <a data-tooltip-id="tooltip" data-tooltip-content="Lock the yarn version used by the project
" href="https://yarnpkg.com/cli/set/version"><span data-type="path">set</span> <span data-type="path">version</span></a></code></span> commands have been updated to favor updating the <code data-tooltip-id="tooltip" data-tooltip-content="Define the package manager that should be used when working on this project."><a href="https://yarnpkg.com/configuration/manifest#packageManager">packageManager</a></code> field when possible.</p><div><p><span><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</p><p>Corepack knows which package manager version to use thanks to the standard <code data-tooltip-id="tooltip" data-tooltip-content="Define the package manager that should be used when working on this project."><a href="https://yarnpkg.com/configuration/manifest#packageManager">packageManager</a></code> field in your <code>package.json</code>. This field will typically be set via one of <span><code><span data-type="binary">yarn</span> <a data-tooltip-id="tooltip" data-tooltip-content="Create a new package
" href="https://yarnpkg.com/cli/init"><span data-type="path">init</span></a> <span data-type="dash">-</span><span data-type="option">2</span></code></span>, <span><code><span data-type="binary">yarn</span> <a data-tooltip-id="tooltip" data-tooltip-content="Lock the yarn version used by the project
" href="https://yarnpkg.com/cli/set/version"><span data-type="path">set</span> <span data-type="path">version</span></a> <span data-type="positional">x.y.z</span></code></span>, or the more generic <code>corepack use yarn@x.y.z</code>.</p></div><h2 id="hardened-mode">Hardened Mode<a href="#hardened-mode" aria-label="Direct link to Hardened Mode" title="Direct link to Hardened Mode">​</a></h2><p>Yarn attempts to protect you from common attacks, and this is pushed even further by the introduction of the Hardened Mode. When operating under this mode, Yarn will perform two extra validations:</p><ul><li>It will validate the resolutions stored in the lockfile are consistent with what the ranges could resolve to.</li><li>It will validate that the package metadata stored in the lockfile are consistent the remote registry metadata.</li></ul><p>Together, those checks will prevent any attacker from surreptitiously modifying your lockfiles when making PRs to your project using Yarn (<a href="https://snyk.io/blog/why-npm-lockfiles-can-be-a-security-blindspot-for-injecting-malicious-modules/" target="_blank" rel="noopener noreferrer">https://snyk.io/blog/why-npm-lockfiles-can-be-a-security-blindspot-for-injecting-malicious-modules/</a>).</p><div><p><span><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</p><p>The Hardened Mode is enabled by toggling on <code data-tooltip-id="tooltip" data-tooltip-content="Define whether Yarn should attempt to check for malicious changes."><a href="https://yarnpkg.com/configuration/yarnrc#enableHardenedMode">enableHardenedMode</a></code>, but it's also automatically enabled when Yarn detects that it runs within a GitHub pull request on a public repository. This can be disabled by explicitly toggling off <code data-tooltip-id="tooltip" data-tooltip-content="Define whether Yarn should attempt to check for malicious changes."><a href="https://yarnpkg.com/configuration/yarnrc#enableHardenedMode">enableHardenedMode</a></code> in your yarnrc file.</p></div><div><p><span><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>caution</p><div><p>Installs operating under Hardened Mode constraints are significantly slower than usual as they need to perform many network requests that would be skipped otherwise. We don't recommend enabling it by default - if you need it in a specific CI job, toggle it on via an environment variable:</p><div><pre tabindex="0"><code><span><span>export</span><span> </span><span>YARN_ENABLE_HARDENED_MODE</span><span>=</span><span>1</span><br></span></code></pre></div></div></div><h2 id="javascript-constraints">JavaScript Constraints<a href="#javascript-constraints" aria-label="Direct link to JavaScript Constraints" title="Direct link to JavaScript Constraints">​</a></h2><p>Yarn is the only package manager to implement a <a href="https://yarnpkg.com/features/constraints">constraints engine</a>. If you don't know it, this feature lets you define a set of rules that your project must satisfy. For instance, the Yarn repository enforces that no two workspaces depend on different versions of any given dependencies, unless explicitly allowed.</p><p>Our constraints engine used to be powered by Tau-Prolog, a JavaScript <a href="https://en.wikipedia.org/wiki/Prolog#Rules_and_facts" target="_blank" rel="noopener noreferrer">Prolog</a> implementation. Unlike imperative languages like JavaScript, Prolog uses a different model called logic programming - you define that something exists if a rule is true. It's a very interesting pattern that integrates well with the concept of rule-based linting. Unfortunately, Prolog proved very complex to use, increasing the learning curve of constraints past the threshold we were comfortable with.</p><p>As a result, Prolog constraints are deprecated starting from Yarn 4, and <strong>they have been superseded by a shiny new JavaScript-based engine, with optional TypeScript support!</strong> We have been writing our own rules at <a href="https://www.datadoghq.com/" target="_blank" rel="noopener noreferrer">Datadog</a> with this framework for a couple of months now, with great success. You can also check the public <a href="https://github.com/yarnpkg/berry/blob/c3b319a8943dcc35e689ebff4051c112bfc598f5/yarn.config.cjs#L17-L43" target="_blank" rel="noopener noreferrer">Yarn repository</a> for a practical example of the kind of rules you can enforce at the repository level, and the <a href="https://yarnpkg.com/features/constraints">newly revamped documentation</a> is there to help you quickly get up to speed.</p><div><p><span><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</p><p>The new optional <code data-tooltip-id="tooltip" data-tooltip-content="Define whether constraints should run on every install."><a href="https://yarnpkg.com/configuration/yarnrc#enableConstraintsChecks">enableConstraintsChecks</a></code> setting will make Yarn run your constraints as part of <span><code><span data-type="binary">yarn</span> <a data-tooltip-id="tooltip" data-tooltip-content="Install the project dependencies
" href="https://yarnpkg.com/cli/install"><span data-type="path">install</span></a></code></span>. It's a handy way to surface errors before having to wait for the remote CI to raise them, and since the new engine is so fast, it has almost no impact on your install time 🚀</p></div><p>Various features in Yarn used to be shipped as sideloaded plugins that needed to be managed separately from the main bundle. While this helped us build a plugin ecosystem, it also proved challenging to manage for our users. We implemented some features to make that easier (auto-upgrade plugins when you auto-update Yarn), but in the end the few KiBs we gained by not shipping all the features by default weren't worth the confusion and friction they caused.</p><p>As a result, while Yarn still supports third-party plugins (and will continue to in the future), <strong>all the features and commands we build are now available as part of the main distribution</strong>. You can now use <span><code><span data-type="binary">yarn</span> <a data-tooltip-id="tooltip" data-tooltip-content="Open the upgrade interface
" href="https://yarnpkg.com/cli/upgrade-interactive"><span data-type="path">upgrade-interactive</span></a></code></span> and <span><code><span data-type="binary">yarn</span> <a data-tooltip-id="tooltip" data-tooltip-content="Add all yarn files to your vcs
" href="https://yarnpkg.com/cli/stage"><span data-type="path">stage</span></a></code></span> without plugins and, if you have TypeScript configured in your project, Yarn will now auto-add and remove <code>@types</code> packages as needed whenever you update your dependencies with <span><code><span data-type="binary">yarn</span> <a data-tooltip-id="tooltip" data-tooltip-content="Add dependencies to the project
" href="https://yarnpkg.com/cli/add"><span data-type="path">add</span></a></code></span> and <span><code><span data-type="binary">yarn</span> <a data-tooltip-id="tooltip" data-tooltip-content="Remove dependencies from the project
" href="https://yarnpkg.com/cli/remove"><span data-type="path">remove</span></a></code></span>.</p><h2 id="improved-user-interface">Improved User Interface<a href="#improved-user-interface" aria-label="Direct link to Improved User Interface" title="Direct link to Improved User Interface">​</a></h2><p>Various pieces of the UI got revamped to better convey information. For example, <span><code><span data-type="binary">yarn</span> <a data-tooltip-id="tooltip" data-tooltip-content="Install the project dependencies
" href="https://yarnpkg.com/cli/install"><span data-type="path">install</span></a></code></span> now tells you the packages you added, and their total weight. You will also notice it doesn't print as much warnings around peer dependencies, as we now try to only print warnings for actionable situations:</p><div><pre tabindex="0"><code><div><p><span></span><span>➤</span><span> YN0000: · </span><span>Yarn 4.0.0</span><span></span></p><p><span></span><span>➤</span><span> </span><span>YN0000</span><span>: ┌ Resolution step</span></p><p><span></span><span>➤</span><span> </span><span>YN0085</span><span>: │ </span><span>+</span><span> </span><span>next</span><span>@npm:13.5.4</span><span>, </span><span>react-dom</span><span>@npm:18.2.0</span><span>, and </span><span>24</span><span> more.</span></p><p><span></span><span>➤</span><span> </span><span>YN0000</span><span>: └ Completed in 0s 280ms</span></p><p><span></span><span>➤</span><span> </span><span>YN0000</span><span>: ┌ Fetch step</span></p><p><span></span><span>➤</span><span> </span><span>YN0013</span><span>: │ </span><span>22</span><span> packages were added to the project (</span><span>+ 177.72 MiB</span><span>).</span></p><p><span></span><span>➤</span><span> </span><span>YN0000</span><span>: └ Completed in 3s 723ms</span></p><p><span></span><span>➤</span><span> </span><span>YN0000</span><span>: ┌ Link step</span></p><p><span></span><span>➤</span><span> </span><span>YN0000</span><span>: └ Completed</span></p><p><span></span><span>➤</span><span> YN0000: · Done with warnings in 4s 123ms</span></p></div></code></pre></div><p>Another example is the <span><code><span data-type="binary">yarn</span> <a data-tooltip-id="tooltip" data-tooltip-content="Display the current configuration
" href="https://yarnpkg.com/cli/config"><span data-type="path">config</span></a></code></span> command, which sports a new tree display and now also accepts an arbitrary number of settings as positional arguments, letting you select what you wish to see:</p><div><pre tabindex="0"><code><div><p><span>├─ </span><span>cacheFolder</span><span></span></p><p><span>│  ├─ </span><span>Description</span><span>: Folder where the cache files must be written</span></p><p><span>│  ├─ </span><span>Source</span><span>: </span><span><internal></internal></span><span></span></p><p><span>│  └─ </span><span>Value</span><span>: </span><span>'/Users/global/.yarn/berry/cache'</span><span></span></p><p><span>│</span></p><p><span>└─ </span><span>enableHardenedMode</span><span></span></p><p><span>   ├─ </span><span>Description</span><span>: If true, automatically enable --check-resolutions --refresh-lockfile on installs</span></p><p><span>   ├─ </span><span>Source</span><span>: </span><span><default></default></span><span></span></p><p><span>   └─ </span><span>Value</span><span>: </span><span>null</span><span></span></p></div></code></pre></div><h2 id="performances">Performances<a href="#performances" aria-label="Direct link to Performances" title="Direct link to Performances">​</a></h2><p>The 4.0 isn't lagging behind in performance improvements, and shows to be significantly faster at installs than the 3.6. For instance, here's the difference in time to install Gatsby and its ~350MiB dependency tree from a cold cache. The 3x improved performances are due to a new package metadata cache which significantly improves performances of repeated installs:</p><div><pre tabindex="0"><code><span><span>hyperfine -L v stable,canary --prepare 'rm -rf ~/.yarn/berry/cache' 'cd $(mktemp -d) &amp;&amp; yarn init -2 &amp;&amp; yarn set version {v} &amp;&amp; yarn &amp;&amp; yarn add gatsby --mode=skip-build'</span><br></span></code></pre></div><div><pre tabindex="0"><code><span><span>Benchmark</span><span> </span><span>1</span><span>:</span><span> </span><span>3.6</span><span>.0</span><span></span><br></span><span><span>  </span><span>Time</span><span> </span><span>(</span><span>mean ± σ</span><span>)</span><span>:</span><span>     </span><span>65.599</span><span> s ±  </span><span>2.214</span><span> s    </span><span>[</span><span>User</span><span>:</span><span> </span><span>82.952</span><span> s</span><span>,</span><span> </span><span>System</span><span>:</span><span> </span><span>8.638</span><span> s</span><span>]</span><span></span><br></span><span><span>  </span><span>Range</span><span> </span><span>(</span><span>min … max</span><span>)</span><span>:</span><span>   </span><span>62.167</span><span> s … </span><span>68.277</span><span> s    </span><span>10</span><span> runs</span><br></span><span><span></span><br></span><span><span></span><span>Benchmark</span><span> </span><span>2</span><span>:</span><span> </span><span>4.0</span><span>.0</span><span></span><br></span><span><span>  </span><span>Time</span><span> </span><span>(</span><span>mean ± σ</span><span>)</span><span>:</span><span>     </span><span>16.724</span><span> s ±  </span><span>0.928</span><span> s    </span><span>[</span><span>User</span><span>:</span><span> </span><span>14.622</span><span> s</span><span>,</span><span> </span><span>System</span><span>:</span><span> </span><span>5.743</span><span> s</span><span>]</span><span></span><br></span><span><span>  </span><span>Range</span><span> </span><span>(</span><span>min … max</span><span>)</span><span>:</span><span>   </span><span>15.318</span><span> s … </span><span>18.110</span><span> s    </span><span>10</span><span> runs</span><br></span><span><span></span><br></span><span><span></span><span>Summary</span><span></span><br></span><span><span>  </span><span>4.0</span><span>.0</span><span> ran </span><span>3.92</span><span> ± </span><span>0.25</span><span> times faster than </span><span>3.6</span><span>.0</span><br></span></code></pre></div><p>These changes make Yarn <a href="https://yarnpkg.com/features/performances">as fast as pnpm in most scenarios</a>, although competition is still fierce 🔥</p><h2 id="fancy-website">Fancy Website<a href="#fancy-website" aria-label="Direct link to Fancy Website" title="Direct link to Fancy Website">​</a></h2><p>As you probably noticed, our website received a major overhaul, both style and content! We worked on this new iteration for more than a year now, and we hope it'll help you find better information, faster than before.</p><p>Some particular improvements:</p><ul><li>All referenced commands now link to their documentation (<span><code><span data-type="binary">yarn</span> <a data-tooltip-id="tooltip" data-tooltip-content="Install the project dependencies
" href="https://yarnpkg.com/cli/install"><span data-type="path">install</span></a></code></span>)</li><li>All referenced options now have a tooltip explaining their goal (<span><code><span data-type="binary">yarn</span> <span data-type="dash">--</span><span data-type="option" data-tooltip-id="tooltip" data-tooltip-content="Abort with an error exit code if the cache folder was to be modified">immutable-cache</span><a data-tooltip-id="tooltip" data-tooltip-content="Install the project dependencies
" href="https://yarnpkg.com/cli"></a></code></span>)</li><li>Most pages were rewritten to be both simplified &amp; clarified when needed</li><li>The package page now shows various configurable checks, like whether a package supports CJS, ESM, has types, ...</li></ul><p>Our expertise lies in tooling more than building websites, so I'm sure various hanging fruits remain - especially around loading time. If you're interested to help us, check the <a href="https://github.com/yarnpkg/berry/tree/master/packages/docusaurus" target="_blank" rel="noopener noreferrer">sources</a> and please feel free to send PRs our way!</p><h2 id="closing-words">Closing Words<a href="#closing-words" aria-label="Direct link to Closing Words" title="Direct link to Closing Words">​</a></h2><p>The journey to transition from Yarn 3 to Yarn 4 was a lengthy one, with a whopping 53 release candidates along the way, but we finally made it! Our aim for this new iteration has been to both decrease Yarn's learning curve and improve your user experience, without the migration feeling overwhelming. We made concerted efforts to avoid making significant breaking changes unless we also had ways to automatically migrate projects, so if you encounter any issues that you believe the software should have addressed, share your feedback with us on <a href="https://discord.gg/yarnpkg" target="_blank" rel="noopener noreferrer">Discord</a>.</p><p>As for what lies ahead, it's a bit too early to provide a definitive answer, but I can tell you I'm particularly intrigued by the potential for native Yarn builds. Performances has been under the spotlight lately, and I sometimes wonder how much overhead may have Node.js on the overall execution time. That being said, we don't plan on undertaking another complete rewrite of the codebase, nor do we want to compromise the factors that make Yarn so contributor-friendly, so the specifics, as well as the timeline, are still under consideration.</p><p>In the meantime we'll continue to build upon our existing foundations for the time being. From CLI completion and UI commands to reducing the learning curve and general upkeep, we have a broad array of improvements on our radar. So see you next time!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MSW 2.0 – Mock Service Worker (117 pts)]]></title>
            <link>https://mswjs.io/blog/introducing-msw-2.0/</link>
            <guid>37985777</guid>
            <pubDate>Mon, 23 Oct 2023 14:01:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mswjs.io/blog/introducing-msw-2.0/">https://mswjs.io/blog/introducing-msw-2.0/</a>, See on <a href="https://news.ycombinator.com/item?id=37985777">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>This November marks five years since Mock Service Worker has been first added to a <code>package.json</code>. Over that time, I have learned a lot about building libraries, designing APIs, and cultivating communities, which makes today’s announcement all the more special.</p>
<p>Version 2.0 marks a monumental chapter for MSW. A year in development, dozens of contributors, and thousands of lines changed, this update brings a refined public API with the first-class support for Fetch API primitives and all the features and bug fixes that it unlocks as a side effect. Let’s have a quick look at what changed and why.</p>
<blockquote>
<p>If you prefer consuming changes hands-on, feel free to dive into the <a href="https://mswjs.io/docs/migrations/1.x-to-2.x">Migration guide</a> for version 2.0. But if you’d like to learn more about the motivation, the challenges, behind-the-scenes, sweat and tears, and all that, then keep on reading.</p>
</blockquote>


<h2 id="the-beginnings"><a href="#the-beginnings">The beginnings</a></h2>
<p>If you’ve been using MSW, you are well familiar with this call signature:</p>
<div data-rehype-pretty-code-fragment=""><pre tabindex="0" data-language="js" data-theme="default"><code data-language="js" data-theme="default"><span data-line=""><span>(</span><span>req</span><span>, </span><span>res</span><span>, </span><span>ctx</span><span>) </span><span>=&gt;</span><span> </span><span>res</span><span>(</span><span>...</span><span>)</span></span></code></pre></div>
<p>This is a function called <em>response resolver</em>, and it acts as a callback that receives the intercepted request and decides how to handle it. The shape of the response resolver hasn’t changed a bit since I first wrote it in 2018. Back in the day, I was rather inspired by functional programming paradigms and function composition in particular, which you can clearly see in the way you declare mocked responses using the <code>res</code> function:</p>
<div data-rehype-pretty-code-fragment=""><pre tabindex="0" data-language="js" data-theme="default"><code data-language="js" data-theme="default"><span data-line=""><span>// Constructing a response is a matter of</span></span>
<span data-line=""><span>// composing various response utilities,</span></span>
<span data-line=""><span>// like "ctx.status" and "ctx.json".</span></span>
<span data-line=""><span>res</span><span>(</span></span>
<span data-line=""><span>  ctx.</span><span>status</span><span>(</span><span>201</span><span>),</span></span>
<span data-line=""><span>  ctx.</span><span>json</span><span>({</span></span>
<span data-line=""><span>    id: </span><span>'abc-123'</span><span>,</span></span>
<span data-line=""><span>    title: </span><span>'Introducing MSW 2.0'</span><span>,</span></span>
<span data-line=""><span>  })</span></span>
<span data-line=""><span>)</span></span></code></pre></div>
<p>From the practical standpoint, the <code>res()</code> composition API achieves its goals: it allows for response declaration, it’s readable, it scales and abstracts well. But years of shipping open-source software have taught me there are more aspects to your code than practicality. Despite its apparent benefits, this composition API failed to achieve a rather important characteristic.</p>
<p><strong>It failed to educate</strong>.</p>
<p>The degree of abstraction in the <code>res()</code> function is far too high to teach you, the developer, anything about actual responses on the web. As a maintainer with thousands of projects depending on the software I build, I feel it’s my responsibility to care about what developers learn from that software. I want them to achieve their goals but I also want them to learn concepts and APIs they can apply even outside of MSW because I firmly believe that’s what a good software does.</p>
<h2 id="the-essence"><a href="#the-essence">The essence</a></h2>
<p>MSW allows you to treat each response as a function of request, and that has been precisely what was going on under the hood.</p>
<div data-rehype-pretty-code-fragment=""><pre tabindex="0" data-language="js" data-theme="default"><code data-language="js" data-theme="default"><span data-line=""><span>// An abstract representation of the request -&gt; response flow.</span></span>
<span data-line=""><span>responseSource.</span><span>on</span><span>(</span><span>'request'</span><span>, (</span><span>request</span><span>) </span><span>=&gt;</span><span> {</span></span>
<span data-line=""><span>  </span><span>const</span><span> </span><span>isomorphicRequest</span><span> </span><span>=</span><span> </span><span>toIsomorphicRequest</span><span>(request)</span></span>
<span data-line=""><span>  </span><span>const</span><span> </span><span>response</span><span> </span><span>=</span><span> </span><span>resolver</span><span>(isomorphicRequest, responseComposition, context)</span></span>
<span data-line=""><span>  </span><span>return</span><span> </span><span>respondWith</span><span>(response)</span></span>
<span data-line=""><span>})</span></span></code></pre></div>
<p>While in the browser we receive the Fetch API <code>Request</code> instance to represent a request, things become more tangled once we step into Node.js.</p>
<p>Before version 2.0, MSW supported Node.js v14 - v16, which is a huge spectre of versions. There is no <code>fetch</code> present in those versions, which means we couldn’t rely on the Fetch API to represent outgoing requests. To account for that request class difference, the library coerced all requests to a single isomoprhic request instance, and that is precisely what you got as the <code>req</code> argument in the response resolver.</p>
<p>But that isomorphic request is entirely contrived. Worse still, extending it or adding new features required to manually implement them for every request module the developer could have used in Node.js. That was extremely tedious and lead to all sorts of bugs.</p>
<p>The effort behind v2.0 is precisely to eradicate those contrived APIs and fully embrace JavaScript standards.</p>
<h3 id="polyfills"><a href="#polyfills">Polyfills</a></h3>
<p><em>Why won’t you just use a <code>fetch</code> polyfill?</em> That’s precisely what I tried at first. It wasn’t long until I realized relying on polyfills won’t work at all.</p>
<p>See, as a developer, you can polyfill <code>fetch</code> in your project in many ways, most likely relying on third-party packages. You may be using <code>whatwg-fetch</code>, or <code>node-fetch</code>, or <code>isomorphic-fetch</code>, or <code>undici</code>. But MSW <strong>had to use just one package</strong>. And it’s not a problem of choice but a problem of interoperability.</p>
<p>Every <code>fetch</code> polyfill locks the identity of its internal classes like <code>Request</code>, <code>Response</code> and <code>Headers</code>. This means that none of those classes would pass the <code>instanceof</code> check, as one example, unless both you and MSW use the same polyfill, which is virtually impossible to predict.</p>
<div data-rehype-pretty-code-fragment=""><pre tabindex="0" data-language="js" data-theme="default"><code data-language="js" data-theme="default"><span data-line=""><span>// somewhere/in/msw.js</span></span>
<span data-line=""><span>import</span><span> { Request } </span><span>from</span><span> </span><span>'polyfill-that-msw-uses'</span></span>
<span data-line=""> </span>
<span data-line=""><span>function</span><span> </span><span>isRequest</span><span>(</span><span>request</span><span>:</span><span> </span><span>Request</span><span>) {</span></span>
<span data-line=""><span>  </span><span>// This will produce a lot of false negatives</span></span>
<span data-line=""><span>  </span><span>// if you provide a `request` constructed by</span></span>
<span data-line=""><span>  </span><span>// a different polyfill than "polyfill-that-msw-uses".</span></span>
<span data-line=""><span>  </span><span>return</span><span> request </span><span>instanceof</span><span> </span><span>Request</span></span>
<span data-line=""><span>}</span></span></code></pre></div>
<p>Inferring the polyfilled classes isn’t a reliable route either. It implies that the polyfill is set globally but it may not be the case. It also makes TypeScript definitions insanely difficult to get right as some polyfills deviate from the specification.</p>
<p>I’ve spent almost a month fighting this to arrive at the simple conclusion: this was clearly not the way forward.</p>
<h2 id="the-way-forward"><a href="#the-way-forward">The way forward</a></h2>
<p>I took a call to deprecate support for Node.js ≤ v16 with the new version of MSW and I am glad I did that. By the time I was finished with the rewrite, Node.js v14 has already reached the end-of-life, Node.js v16 reaches the end of life this fall, and Node.js v18 itself goes into maintenance.</p>
<blockquote>
<p>The day I removed Node.js v14 support from MSW will go in history as one of my happiest days as an engineer.</p>
</blockquote>
<p>Node.js evolves fast, and it is thanks fo that evolution that MSW can rely on the standard Fetch API both in the browser and Node.js to represent requests and responses from version 2.0!</p>
<h2 id="the-new-api"><a href="#the-new-api">The new API</a></h2>
<p>Starting from 2.0, the way you declare request handlers (and response resolvers) will change. Here’s how the new API looks like:</p>
<div data-rehype-pretty-code-fragment=""><pre tabindex="0" data-language="js" data-theme="default"><code data-language="js" data-theme="default"><span data-line=""><span>import</span><span> { http } </span><span>from</span><span> </span><span>'msw'</span></span>
<span data-line=""> </span>
<span data-line=""><span>http.</span><span>get</span><span>(</span><span>'/resource'</span><span>, </span><span>async</span><span> ({ </span><span>request</span><span> }) </span><span>=&gt;</span><span> {</span></span>
<span data-line=""><span>  </span><span>const</span><span> </span><span>user</span><span> </span><span>=</span><span> </span><span>await</span><span> request.</span><span>json</span><span>()</span></span>
<span data-line=""><span>  </span><span>return</span><span> </span><span>new</span><span> </span><span>Response</span><span>(</span><span>`Hello, ${</span><span>user</span><span>.</span><span>name</span><span>}`</span><span>)</span></span>
<span data-line=""><span>})</span></span></code></pre></div>
<p>And you’ve guessed it, both <code>request</code> and <code>Response</code> are the standard Fetch API instances! This means feature-rich, standard way of handling requests and defining responses, end-to-end. This may not look like a big deal at first but that changes once you dive deeper.</p>
<p>Let’s say you wish to read the intercepted request’s body as <code>FormData</code>. This used to be a big point of friction in the past, but it’s a matter of using the platform now:</p>
<div data-rehype-pretty-code-fragment=""><pre tabindex="0" data-language="js" data-theme="default"><code data-language="js" data-theme="default"><span data-line=""><span>http.</span><span>post</span><span>(</span><span>'/user'</span><span>, </span><span>async</span><span> ({ </span><span>request</span><span> }) </span><span>=&gt;</span><span> {</span></span>
<span data-line="" data-highlighted-line=""><span>  </span><span>const</span><span> </span><span>data</span><span> </span><span>=</span><span> </span><span>await</span><span> request.</span><span>formData</span><span>()</span></span>
<span data-line="" data-highlighted-line=""><span>  </span><span>const</span><span> </span><span>email</span><span> </span><span>=</span><span> data.</span><span>get</span><span>(</span><span>'email'</span><span>)</span></span>
<span data-line=""><span>})</span></span></code></pre></div>
<p>This change also means that MSW (and <strong>you</strong>!) doesn’t need to rely on any polyfills to get all that functionality. It doesn’t have to keep internal request/response representations or contrive support for features that have been present in the platform for years. This is indeed the future and it has never been brighter.</p>
<p>To make this point stick, let me show you a request handler that emulates a video stream and injects server-side latency between <em>each individual chunk</em> of that stream.</p>
<div data-rehype-pretty-code-fragment=""><pre tabindex="0" data-language="js" data-theme="default"><code data-language="js" data-theme="default"><span data-line=""><span>import</span><span> { http } </span><span>from</span><span> </span><span>'msw'</span></span>
<span data-line=""> </span>
<span data-line=""><span>http.</span><span>get</span><span>(</span><span>'/movie'</span><span>, </span><span>async</span><span> () </span><span>=&gt;</span><span> {</span></span>
<span data-line=""><span>  </span><span>// Fetch a video stream.</span></span>
<span data-line=""><span>  </span><span>const</span><span> </span><span>response</span><span> </span><span>=</span><span> </span><span>await</span><span> </span><span>fetch</span><span>(</span></span>
<span data-line=""><span>    </span><span>'https://nickdesaulniers.github.io/netfix/demo/frag_bunny.mp4'</span></span>
<span data-line=""><span>  )</span></span>
<span data-line=""><span>  </span><span>const</span><span> </span><span>videoStream</span><span> </span><span>=</span><span> response.body</span></span>
<span data-line=""> </span>
<span data-line=""><span>  </span><span>// Create a transform stream that will delay</span></span>
<span data-line=""><span>  </span><span>// each chunk before writing it back to stream.</span></span>
<span data-line=""><span>  </span><span>const</span><span> </span><span>latencyStream</span><span> </span><span>=</span><span> </span><span>new</span><span> </span><span>TransformStream</span><span>({</span></span>
<span data-line=""><span>    </span><span>read</span><span>() {},</span></span>
<span data-line=""><span>    </span><span>async</span><span> </span><span>transform</span><span>(</span><span>chunk</span><span>, </span><span>controller</span><span>) {</span></span>
<span data-line=""><span>      </span><span>await</span><span> </span><span>new</span><span> </span><span>Promise</span><span>((</span><span>resolve</span><span>) </span><span>=&gt;</span><span> </span><span>setTimeout</span><span>(resolve, </span><span>500</span><span>))</span></span>
<span data-line=""><span>      controller.</span><span>enqueue</span><span>(chunk)</span></span>
<span data-line=""><span>    },</span></span>
<span data-line=""><span>  })</span></span>
<span data-line=""> </span>
<span data-line=""><span>  </span><span>// Pipe the original video stream through the latency stream.</span></span>
<span data-line=""><span>  </span><span>return</span><span> </span><span>new</span><span> </span><span>Response</span><span>(videoStream.</span><span>pipeThrough</span><span>(latencyStream), response)</span></span>
<span data-line=""><span>})</span></span></code></pre></div>
<p>There is a lot going on in this request handler! But you know what’s the best part about it? The only MSW-specific part of this entire code snippet is this:</p>
<div data-rehype-pretty-code-fragment=""><pre tabindex="0" data-language="js" data-theme="default"><code data-language="js" data-theme="default"><span data-line=""><span>http.</span><span>get</span><span>(</span><span>'/movie'</span><span>, </span><span>async</span><span> () </span><span>=&gt;</span><span> {})</span></span></code></pre></div>
<p><strong>Everything else is standard JavaScript API</strong>. You can literally copy-paste that entire response resolver to your browser’s console and it will fetch the video and return you the transformed response. I hope you begin to realize how powerful this is.</p>
<p>MSW has already set a new threshold of reusability by allowing you to use the same request handlers across any environment and any tool. With 2.0, that threshold has been pushed through the roof. Use the platform, learn the platform, write code that makes sense even outside of request handlers.</p>
<h2 id="one-more-thing"><a href="#one-more-thing">One more thing</a></h2>
<p>Well, honestly, quite a bunch of things! The Fetch API support may be in the spotlight with this release but it also includes a dozen of bug fixes and improvements. MSW now ships with full compatibility with ESM, has proper code splitting, improves its internal architecture and refines its interception algorithm in Node.js.</p>
<p>You can see the full list of changes in the <a href="https://github.com/mswjs/msw/releases/tag/v2.0.0" rel="noopener noreferrer" target="_blank">Release notes</a>.</p>
<h2 id="migration-guide"><a href="#migration-guide">Migration guide</a></h2>
<p>This release contains quite a number of breaking changes as the public API of the library has been reworked and improved. I know it will take you some time to adopt those changes but, trust me, you will absolutely love how your request handlers will look once you do.</p>
<p>Please follow these detailed migration guidelines to address each and every breaking change relevant to your setup:</p>

<a href="https://mswjs.io/docs/migrations/1.x-to-2.x"><article><div><p>1.x - 2.x</p><p>Migration guidelines for version 2.0</p></div></article></a>
<h2 id="closing-thoughts"><a href="#closing-thoughts">Closing thoughts</a></h2>
<p>MSW went a long way from an overweekend prototype to one of the most used API mocking solutions in JavaScript. Today, it becomes <strong>the first solution to fully rely on the Fetch API primitives</strong>. I can’t wait for you to explore all the possibilities that unlocks. To many of you, MSW is already an inseparable part of their testing and development workflow, and with this release it will become the same for many more.</p>
<p>Working on the library full-time would be my dream. Unfortunately, it is quite far from becoming the reality. But <strong>you</strong> can change that. If you believe in what I’m doing, if you want to see MSW improve and evolve, please <a href="https://github.com/sponsors/mswjs" rel="noopener noreferrer" target="_blank">Sponsor the project</a>. Every contribution brings me a step closer to my dream. Thank you.</p>
<h2 id="special-thanks"><a href="#special-thanks">Special thanks</a></h2>
<p>This release would not be possible without the incredible contributors who submitted issues, tried out the release candidate versions, shared their feedback, and believed in MSW. I will do my best to list everyone involved in this release below, in alphabetical order. Rest assured, these are the true heroes.</p>
<p><a href="https://github.com/95th" rel="noopener noreferrer" target="_blank">95th</a>, <a href="https://github.com/Kosai106" rel="noopener noreferrer" target="_blank">Kosai106</a>, <a href="https://github.com/TeChn4K" rel="noopener noreferrer" target="_blank">TeChn4K</a>, <a href="https://github.com/WesleyYue" rel="noopener noreferrer" target="_blank">WesleyYue</a>, <a href="https://github.com/Xayer" rel="noopener noreferrer" target="_blank">Xayer</a>, <a href="https://github.com/alawiii521" rel="noopener noreferrer" target="_blank">alawiii521</a>, <a href="https://github.com/christoph-fricke" rel="noopener noreferrer" target="_blank">christoph-fricke</a>, <a href="https://github.com/cmolina" rel="noopener noreferrer" target="_blank">cmolina</a>, <a href="https://github.com/colinsullivan" rel="noopener noreferrer" target="_blank">colinsullivan</a>, <a href="https://github.com/committomaster" rel="noopener noreferrer" target="_blank">committomaster</a>, <a href="https://github.com/committomaster" rel="noopener noreferrer" target="_blank">committomaster</a>, <a href="https://github.com/csantos1113" rel="noopener noreferrer" target="_blank">csantos1113</a>, <a href="https://github.com/cwagner22" rel="noopener noreferrer" target="_blank">cwagner22</a>, <a href="https://github.com/danny-does-stuff" rel="noopener noreferrer" target="_blank">danny-does-stuff</a>, <a href="https://github.com/dbritto-dev" rel="noopener noreferrer" target="_blank">dbritto-dev</a>, <a href="https://github.com/ddolcimascolo" rel="noopener noreferrer" target="_blank">ddolcimascolo</a>, <a href="https://github.com/dkobierski" rel="noopener noreferrer" target="_blank">dkobierski</a>, <a href="https://github.com/dxlbnl" rel="noopener noreferrer" target="_blank">dxlbnl</a>, <a href="https://github.com/ealejandrootalvaro" rel="noopener noreferrer" target="_blank">ealejandrootalvaro</a>, <a href="https://github.com/elliotgonzalez123" rel="noopener noreferrer" target="_blank">elliotgonzalez123</a>, <a href="https://github.com/felipefreitag" rel="noopener noreferrer" target="_blank">felipefreitag</a>, <a href="https://github.com/jonnedeprez" rel="noopener noreferrer" target="_blank">jonnedeprez</a>, <a href="https://github.com/jonnedeprez" rel="noopener noreferrer" target="_blank">jonnedeprez</a>, <a href="https://github.com/koddsson" rel="noopener noreferrer" target="_blank">koddsson</a>, <a href="https://github.com/laryro" rel="noopener noreferrer" target="_blank">laryro</a>, <a href="https://github.com/lee-reinhardt" rel="noopener noreferrer" target="_blank">lee-reinhardt</a>, <a href="https://github.com/lee-reinhardt" rel="noopener noreferrer" target="_blank">lee-reinhardt</a>, <a href="https://github.com/lemcii" rel="noopener noreferrer" target="_blank">lemcii</a>, <a href="https://github.com/luisr-carrillo" rel="noopener noreferrer" target="_blank">luisr-carrillo</a>, <a href="https://github.com/markwhitfeld" rel="noopener noreferrer" target="_blank">markwhitfeld</a>, <a href="https://github.com/mattcosta7" rel="noopener noreferrer" target="_blank">mattcosta7</a>, <a href="https://github.com/mattrodak" rel="noopener noreferrer" target="_blank">mattrodak</a>, <a href="https://github.com/mscottnelson" rel="noopener noreferrer" target="_blank">mscottnelson</a>, <a href="https://github.com/negabaro" rel="noopener noreferrer" target="_blank">negabaro</a>, <a href="https://github.com/nickrttn" rel="noopener noreferrer" target="_blank">nickrttn</a>, <a href="https://github.com/piotr-cz" rel="noopener noreferrer" target="_blank">piotr-cz</a>, <a href="https://github.com/ricardocosta" rel="noopener noreferrer" target="_blank">ricardocosta</a>, <a href="https://github.com/skvale" rel="noopener noreferrer" target="_blank">skvale</a>, <a href="https://github.com/the-ult" rel="noopener noreferrer" target="_blank">the-ult</a>, <a href="https://github.com/thepassle" rel="noopener noreferrer" target="_blank">thepassle</a>, <a href="https://github.com/thomasbertet" rel="noopener noreferrer" target="_blank">thomasbertet</a>, <a href="https://github.com/thw0rted" rel="noopener noreferrer" target="_blank">thw0rted</a>, <a href="https://github.com/tomdglenn91" rel="noopener noreferrer" target="_blank">tomdglenn91</a>, <a href="https://github.com/tsteckenborn" rel="noopener noreferrer" target="_blank">tsteckenborn</a>, <a href="https://github.com/wKovacs64" rel="noopener noreferrer" target="_blank">wKovacs64</a>, <a href="https://github.com/weyert" rel="noopener noreferrer" target="_blank">weyert</a>, <a href="https://github.com/xmlking" rel="noopener noreferrer" target="_blank">xmlking</a>, <a href="https://github.com/xxleyi" rel="noopener noreferrer" target="_blank">xxleyi</a>, <a href="https://github.com/zkochan" rel="noopener noreferrer" target="_blank">zkochan</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Was any Starfighter postmortem ever published? (150 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=37985450</link>
            <guid>37985450</guid>
            <pubDate>Mon, 23 Oct 2023 13:39:47 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=37985450">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="37985450">
      <td><span></span></td>      <td><center><a id="up_37985450" href="https://news.ycombinator.com/vote?id=37985450&amp;how=up&amp;goto=item%3Fid%3D37985450"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=37985450">Ask HN: Was any Starfighter postmortem ever published?</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_37985450">104 points</span> by <a href="https://news.ycombinator.com/user?id=xoranth">xoranth</a> <span title="2023-10-23T13:39:47"><a href="https://news.ycombinator.com/item?id=37985450">3 hours ago</a></span> <span id="unv_37985450"></span> | <a href="https://news.ycombinator.com/hide?id=37985450&amp;goto=item%3Fid%3D37985450">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20Was%20any%20Starfighter%20postmortem%20ever%20published%3F&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=37985450&amp;auth=910477e260748993b0bb17c2ca03d28df3ce91b1">favorite</a> | <a href="https://news.ycombinator.com/item?id=37985450">36&nbsp;comments</a>        </span>
              </td></tr>
    <tr></tr><tr><td colspan="2"></td><td><div><p>About seven years ago, HN veterans 'elptacek, 'patio11 and 'tptacek launched an hiring startup called Starfighter.
Their approach aimed to shift away from traditional interviews and instead employ a CTF/Microcorruption kind of test, inspired by 'tptacek experience at Matasano.
Unfortunately, Starfighter eventually wound down.</p><p>Was there ever any post-mortem written on Starfighter? If not, would 'elptacek, 'patio11 and 'tptacek be willing to provide any details?</p></div></td></tr>        <tr></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Software Disenchantment (473 pts)]]></title>
            <link>https://tonsky.me/blog/disenchantment/</link>
            <guid>37985176</guid>
            <pubDate>Mon, 23 Oct 2023 13:17:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tonsky.me/blog/disenchantment/">https://tonsky.me/blog/disenchantment/</a>, See on <a href="https://news.ycombinator.com/item?id=37985176">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
        
        <figure>
<img src="https://tonsky.me/blog/disenchantment/cover.jpg?t=1697909369" width="600" height="337">        </figure>
        <p><em>Translations: <a href="https://tonsky.me/blog/disenchantment/zh/">Chinese</a> <a href="https://tonsky.me/blog/disenchantment/fr/">French</a> <a href="https://tonsky.me/blog/disenchantment/hu/">Hungarian</a> <a href="https://tonsky.me/blog/disenchantment/it/">Italian</a> <a href="https://tonsky.me/blog/disenchantment/ko/">Korean</a> <a href="https://tonsky.me/blog/disenchantment/pt/">Portuguese</a> <a href="https://tonsky.me/blog/disenchantment/ru/">Russian</a> <a href="https://tonsky.me/blog/disenchantment/es/">Spanish</a></em></p>
        <p>I’ve been programming for 15 years now. Recently, our industry’s lack of care for efficiency, simplicity, and excellence started really getting to me, to the point of me getting depressed by my own career and IT in general.</p>
        <p>Modern cars work, let’s say for the sake of argument, at 98% of what’s physically possible with the current engine design. Modern buildings use just enough material to fulfill their function and stay safe under the given conditions. All planes converged to the optimal size/form/load and basically look the same.</p>
        <p>Only in software, it’s fine if a program runs at 1% or even 0.01% of the possible performance. Everybody just seems to be ok with it. People are often even proud about how inefficient it is, as in “why should we worry, computers are fast enough”:</p>
        <blockquote>
          <p><a href="https://twitter.com/tveastman/status/1039002300600147968" target="_blank">@tveastman</a>: I have a Python program I run every day, it takes 1.5 seconds. I spent six hours re-writing it in rust, now it takes 0.06 seconds. That efficiency improvement means I'll make my time back in 41 years, 24 days :-)</p>
        </blockquote>
        <p>You’ve probably heard this mantra: “Programmer time is more expensive than computer time.” What it means basically is that we’re wasting computers at an unprecedented scale. Would you buy a car if it eats 100 liters per 100 kilometers? How about 1000 liters? With computers, we do that all the time.</p>
        <figure>
<a href="https://xkcd.com/2021/" target="_blank"><img src="https://tonsky.me/blog/disenchantment/software_development@2x.gif?t=1697909369" width="349" height="440"></a>        </figure>
        <h2 id="everything-is-unbearably-slow">Everything is unbearably slow</h2>
        <p>Look around: our portable computers are thousands of times more powerful than the ones that brought man to the moon. Yet every other webpage struggles to maintain a smooth 60fps scroll on the latest top-of-the-line MacBook Pro. I can comfortably play games, watch 4K videos, but not scroll web pages? How is that ok?</p>
        <p>Google Inbox, a web app written by Google, running in Chrome browser also by Google, <a href="https://twitter.com/nikitonsky/statuses/968882438024941568" target="_blank">takes 13 seconds to open moderately-sized emails</a>:</p>
        <figure>
          <video autoplay="" muted="" loop="" preload="auto" playsinline="" controls="" width="576" height="360">
            <source src="https://tonsky.me/blog/disenchantment/inbox.mp4?t=1697909369" type="video/mp4">
          </video>
        </figure>
        <p>It also animates empty white boxes instead of showing their content because it’s the only way anything can be animated on a webpage with decent performance. No, decent doesn’t mean 60fps, it’s rather “as fast as this web page could possibly go”. I’m dying to see the web community answer when 120Hz displays become mainstream. Shit barely hits 60Hz already.</p>
        <p>Windows 10 <a href="https://grumpy.website/post/0PeXr1S7N" target="_blank">takes 30 minutes to update</a>. What could it possibly be doing for that long? That much time is enough to fully format my SSD drive, download a fresh build and install it like 5 times in a row.</p>
        <figure>
<img src="https://tonsky.me/blog/disenchantment/windows_update.gif?t=1697909369" width="600" height="435">        </figure>
        <blockquote>
          <p><a href="https://pavelfatin.com/typing-with-pleasure/" target="_blank">Pavel Fatin</a>: Typing in editor is a relatively simple process, so even 286 PCs were able to provide a rather fluid typing experience.</p>
        </blockquote>
        <p>Modern text editors have higher latency than 42-year-old Emacs. Text editors! What can be simpler? On each keystroke, all you have to do is update a tiny rectangular region and modern text editors can’t do that in 16ms. It’s a lot of time. A LOT. A 3D game can fill the whole screen with hundreds of thousands (!!!) of polygons in the same 16ms and also process input, recalculate the world and dynamically load/unload resources. How come?</p>
        <p>As a general trend, we’re not getting faster software with more features. We’re getting faster hardware that runs slower software with the same features. Everything works way below the possible speed. Ever wonder why your phone needs 30 to 60 seconds to boot? Why can’t it boot, say, in one second? There are no physical limitations to that. I would love to see that. I would love to see limits reached and explored, utilizing every last bit of performance we can get for something meaningful in a meaningful way.</p>
        <h2 id="everything-is-huuuuge">Everything is HUUUUGE</h2>
        <p>And then there’s bloat. Web apps could open up to 10 times faster if you just simply blocked all ads. Google begs everyone to stop shooting themselves in the foot with the AMP initiative—a technology solution to a problem that doesn’t need any technology, just a little bit of common sense. If you remove bloat, the web becomes crazy fast. How smart do you have to be to understand that?</p>
        <p>An Android system with no apps <a href="https://grumpy.website/post/0Oz1lDOq5" target="_blank">takes up almost 6 GB</a>. Just think for a second about how obscenely HUGE that number is. What’s in there, HD movies? I guess it’s basically code: kernel, drivers. Some string and resources too, sure, but those can’t be big. So, how many drivers do you need for a phone?</p>
        <figure>
<img src="https://tonsky.me/blog/disenchantment/android_storage.jpg?t=1697909369" width="550" height="489">        </figure>
        <p>Windows 95 was 30MB. Today we have web pages heavier than that! Windows 10 is 4GB, which is 133 times as big. But is it 133 times as superior? I mean, functionally they are basically the same. Yes, we have Cortana, but I doubt it takes 3970 MB. But whatever Windows 10 is, is Android really 150% of that?</p>
        <p>Google's keyboard app routinely eats 150 MB. Is an app that draws 30 keys on a screen really five times more complex than the whole Windows 95? Google app, which is basically just a package for Google Web Search, is 350 MB! Google Play Services, which I do not use (I don’t buy books, music or videos there)—300 MB that just sit there and which I’m unable to delete.</p>
        <figure>
<img src="https://tonsky.me/blog/disenchantment/apps_storage@2x.gif?t=1697909369" width="270" height="480">        </figure>
        <p>All that leaves me around 1 GB for my photos after I install all the essential (social, chats, maps, taxi, banks etc) apps. And that’s with no games and no music at all! Remember times when an OS, apps and all your data fit on a floppy?</p>
        <p>Your desktop todo app is probably written in Electron and thus <a href="https://josephg.com/blog/electron-is-flash-for-the-desktop/" target="_blank">has a userland driver for the Xbox 360 controller in it</a>, can render 3D graphics and play audio and take photos with your web camera.</p>
        <figure>
<img src="https://tonsky.me/blog/disenchantment/slack_memory.jpg?t=1697909369" width="703" height="455">        </figure>
        <p>A simple text chat is notorious for its load speed and memory consumption. Yes, you really have to count Slack in as a resource-heavy application. I mean, chatroom and barebones text editor, those are supposed to be two of the less demanding apps in the whole world. Welcome to 2018.</p>
        <p>At least it works, you might say. Well, bigger doesn’t imply better. Bigger means someone has lost control. Bigger means we don’t know what’s going on. Bigger means complexity tax, performance tax, reliability tax. This is not the norm and should not become the norm. Overweight apps should mean a red flag. They should mean run away scared.</p>
        <h2 id="everything-rots">Everything rots</h2>
        <p>A 16GB Android phone was perfectly fine 3 years ago. Today, with Android 8.1, it’s barely usable because each app has become at least twice as big <em>for no apparent reason</em>. There are no additional features. They are not faster or more optimized. They don’t look different. They just...grow?</p>
        <p>The iPhone 4s was released with iOS 5, but can barely run iOS 9. And it’s not because iOS 9 is that much superior—it’s basically the same. But their new hardware is faster, so they made software slower. Don’t worry—you got exciting new capabilities like...running the same apps with the same speed! I dunno.</p>
        <p>iOS 11 dropped support for 32-bit apps. That means if the developer isn’t around at the time of the iOS 11 release or isn’t willing to go back and update a once-perfectly-fine app, chances are you won’t be seeing their app ever again.</p>
        <blockquote>
          <p>@<a href="https://twitter.com/jckarter/statuses/1017071794245623808" target="_blank">jckarter</a>: A DOS program can be made to run unmodified on pretty much any computer made since the 80s. A JavaScript app might break with tomorrow’s Chrome update</p>
        </blockquote>
        <p>Web pages working today <a href="https://tonsky.me/blog/chrome-intervention/">would not be compatible with any browser in 10 years time</a> (probably sooner).</p>
        <p>“It takes all the running you can do, to keep in the same place”. But what’s the point? I might enjoy occasionally buying a new phone and new MacBook as much as the next guy, but to do so just to be able to run all the same apps which just became slower?</p>
        <p>I think we can and should do better than that. Everyone is busy building stuff for right now, today, rarely for tomorrow. But it would be nice to also have stuff that lasts a little longer than that.</p>
        <h2 id="worse-is-better">Worse is better</h2>
        <p>Nobody understands anything at this point. Neither do they want to. We just throw barely baked shit out there, hope for the best and call it “startup wisdom”.</p>
        <p>Web pages ask you to refresh if anything goes wrong. Who has time to figure out what happened?</p>
        <figure>
<img src="https://tonsky.me/blog/disenchantment/reload.jpg?t=1697909369" width="600" height="185">        </figure>
        <p>Any web app produces a constant stream of “random” JS errors in the wild, even on compatible browsers.</p>
        <p>The whole webpage/SQL database architecture is built on a premise (hope, even) that nobody will touch your data while you look at the rendered webpage.</p>
        <p>Most collaborative implementations are “best effort” and have many common-life scenarios in which they lose data. Ever seen this dialogue “which version to keep?” I mean, the bar is so low today that your users would be happy to at least have a window like that.</p>
        <figure>
<img src="https://tonsky.me/blog/disenchantment/icloud_conflict.jpg?t=1697909369" width="750" height="585">        </figure>
        <p>And no, in my world, an app that says “I’m gonna destroy some of your work, but you get to choose which one” is not okay.</p>
        <p>Linux kills random processes <em>by design</em>. And yet it’s the most popular server-side OS.</p>
        <p>Every device I own fails regularly one way or another. My Dell monitor needs a hard reboot from time to time because there’s software in it. Airdrop? You’re lucky if it’ll detect your device, otherwise, what do I do? Bluetooth? The spec is so complex that devices <a href="https://thewirecutter.com/blog/understanding-bluetooth-pairing-problems/" target="_blank">won’t talk to each other</a> and <a href="http://time.com/4358533/bluetooth-fix-how/" target="_blank">periodic resets are the best way to go</a>.</p>
        <figure>
<img src="https://tonsky.me/blog/disenchantment/plz_connect.jpg?t=1697909369" width="600" height="450">        </figure>
        <p>And I’m not even touching the <a href="https://twitter.com/internetofshit" target="_blank">Internet of Things</a>. It’s so far beyond the laughing point I’m not even sure what to add.</p>
        <p>I want to take pride in my work. I want to deliver working, stable things. To do that, we need to understand what we are building, in and out, and that’s impossible to do in bloated, over-engineered systems.</p>
        <h2 id="programming-is-the-same-mess">Programming is the same mess</h2>
        <p>It just seems that nobody is interested in building quality, fast, efficient, lasting, foundational stuff anymore. Even when efficient solutions have been known for ages, we still struggle with the same problems: package management, build systems, compilers, language design, IDEs.</p>
        <p>Build systems are inherently unreliable and periodically require full clean, even though all info for invalidation is there. Nothing stops us from making build processes reliable, predictable and 100% reproducible. Just nobody thinks its important. NPM has stayed in “sometimes works” state for years.</p>
        <blockquote>
          <p><a href="https://twitter.com/przemyslawdabek/status/940547268729606145" target="_blank">@przemyslawdabek</a>: It seems to me that <code>rm -rf node_modules</code> is indispensable part of workflow when developing Node.js/JavaScript projects.</p>
        </blockquote>
        <p>And build times? Nobody thinks compiler that works minutes or even hours is a problem. What happened to “programmer’s time is more important”? Almost all compilers, pre- and post-processors add significant, sometimes disastrous time tax to your build without providing proportionally substantial benefits.</p>
        <figure>
<a href="https://xkcd.com/303/" target="_blank"><img src="https://tonsky.me/blog/disenchantment/compiling.gif?t=1697909369" width="413" height="360"></a>        </figure>
        <p>You would expect programmers to make mostly rational decisions, yet sometimes they do the exact opposite of that. E.g. choosing Hadoop <a href="https://www.chrisstucchio.com/blog/2013/hadoop_hatred.html" target="_blank">even when it’s slower than running the same task on a single desktop</a>.</p>
        <p>Machine learning and “AI” moved software to guessing in the times when most computers are not even reliable enough in the first place.</p>
        <blockquote>
          <p><a href="https://twitter.com/freetonik/status/1039826129190875136" target="_blank">@rakhim</a>: When an app or a service is described as “AI-powered” or “ML-based”, I read it as “unreliable, unpredictable, and impossible to reason about behavior”. I try to avoid “AI” because I want computers to be the opposite: reliable, predictable, reasonable.</p>
        </blockquote>
        <p>We put virtual machines inside Linux, and then we put Docker inside virtual machines, simply because nobody was able to clean up the mess that most programs, languages and their environment produce. We cover shit with blankets just not to deal with it. “Single binary” is still a HUGE selling point for Go, for example. No mess == success.</p>
        <figure>
<a href="https://xkcd.com/1987/" target="_blank"><img src="https://tonsky.me/blog/disenchantment/python_environment@2x.gif?t=1697909369" width="491" height="487"></a>        </figure>
        <p>And dependencies? People easily add overengineered “full package solutions” to solve the simplest problems without considering their costs. And those dependencies bring other dependencies. You end up with a tree that is something in between of horror story (OMG so big and full of conflicts) and comedy (there’s no reason we include these, <a href="https://medium.com/@jdan/i-peeked-into-my-node-modules-directory-and-you-wont-believe-what-happened-next-b89f63d21558" target="_blank">yet here they are</a>):</p>
        <figure>
<img src="https://tonsky.me/blog/disenchantment/dependencies.gif?t=1697909369" width="600" height="440">        </figure>
        <p>Programs can’t work for years without reboots anymore. Sometimes <a href="https://docs.gitlab.com/ee/administration/operations/unicorn.html#unicorn-worker-killer" target="_blank">even days are too much to ask</a>. Random stuff happens and nobody knows why.</p>
        <p>What’s worse, nobody has time to stop and figure out what happened. Why bother if you can always buy your way out of it. Spin another AWS instance. Restart process. Drop and restore the whole database. Write a watchdog that will restart your broken app every 20 minutes. Include same resources <a href="https://blog.timac.org/2017/0410-analysis-of-the-facebook-app-for-ios-v-87-0/" target="_blank">multiple times, zip and ship</a>. Move fast, don’t fix.</p>
        <p>That is not engineering. That’s just lazy programming. Engineering is understanding performance, structure, limits of what you build, deeply. Combining poorly written stuff with more poorly written stuff goes strictly against that. To progress, we need to understand what and why are we doing.</p>
        <h2 id="were-stuck-with-it">We’re stuck with it</h2>
        <p>So everything is just a pile of barely working code added on top of previously written barely working code. It keeps growing in size and complexity, diminishing any chance for a change.</p>
        <p>To have a healthy ecosystem you <em>need</em> to go back and revisit. You <em>need</em> to occasionally throw stuff away and replace it with better stuff.</p>
        <figure>
<img src="https://tonsky.me/blog/disenchantment/design_process@2x.jpg?t=1697909369" width="492" height="539">        </figure>
        <p>But who has time for that? We haven’t seen new OS kernels in what, 25 years? It’s just too complex to simply rewrite by now. Browsers are so full of edge cases and historical precedents by now that nobody dares to write layout engine from scratch.</p>
        <p>Today’s definition of progress is either <a href="https://twitter.com/sahrizv/status/1018184792611827712" target="_blank">throw more fuel into the fire</a>:</p>
        <blockquote>
          <p>@sahrizv: 2014 - We must adopt #microservices to solve all problems with monoliths.</p>
          <p>2016 - We must adopt #docker to solve all problems with microservices</p>
          <p>2018 - We must adopt #kubernetes to solve all problems with docker</p>
        </blockquote>
        <p>or <a href="https://twitter.com/dr_c0d3/status/1040092903052378112" target="_blank">reinventing the wheel</a>:</p>
        <blockquote>
          <p>@dr_c0d3: 2000: Write 100s of lines of XML to "declaratively" configure your servlets and EJBs.</p>
          <p>2018: Write 100s of lines of YAML to "declaratively" configure your microservices.</p>
          <p>At least XML had schemas...</p>
        </blockquote>
        <p>We’re stuck with what we have, and nobody will ever save us.</p>
        <h2 id="business-wont-care">Business won’t care</h2>
        <p>Neither will users. They are only learned to expect what we can provide. We (engineers) say every Android app takes 350 MB? Ok, they’ll live with that. We say we can’t give them smooth scrolling? Ok, they’ll live with a phone that stutter. We say “if it doesn’t work, reboot”? They’ll reboot. After all, they have no choice.</p>
        <p>There’s no competition either. Everybody is building the same slow, bloated, unreliable products. Occasional jump forward in quality does bring competitive advantage (iPhone/iOS vs other smartphones, Chrome vs other browsers) and forces everybody to regroup, but not for long.</p>
        <p>So it’s our mission as engineers to show the world what’s possible with today’s computers in terms of performance, reliability, quality, usability. If we care, people will learn. And there’s nobody but us to show them that it’s very much possible. If only we care.</p>
        <h2 id="its-not-all-bad">It’s not all bad</h2>
        <p>There are some bright spots indicating that improving over state-of-the-art is not impossible.</p>
        <p>Work <a href="https://twitter.com/mjpt777" target="_blank">Martin Thompson</a> has being doing (<a href="https://github.com/LMAX-Exchange/disruptor" target="_blank">LMAX Disruptor</a>, <a href="https://github.com/real-logic/simple-binary-encoding" target="_blank">SBE</a>, <a href="https://github.com/real-logic/aeron" target="_blank">Aeron</a>) is impressive, refreshingly simple and efficient.</p>
        <p><a href="https://github.com/google/xi-editor" target="_blank">Xi editor</a> by Raph Levien seems to be built with the right principles in mind.</p>
        <p><a href="https://www.youtube.com/user/jblow888" target="_blank">Jonathan Blow</a> has a language he alone develops for his game that can compile 500k lines per second on his laptop. That’s cold compile, no intermediate caching, no incremental builds.</p>
        <p>You don’t have to be a genius to write fast programs. There’s no magic trick. The only thing required is not building on top of a huge pile of crap that modern toolchain is.</p>
        <h2 id="better-world-manifesto">Better world manifesto</h2>
        <p>I want to see progress. I want change. I want state-of-the-art in software engineering to improve, not just stand still. I don’t want to reinvent the same stuff over and over, less performant and more bloated each time. I want something to believe in, a worthy end goal, a future better than what we have today, and I want a community of engineers who share that vision.</p>
        <p>What we have today is not progress. We barely meet business goals with poor tools applied over the top. We’re stuck in local optima and nobody wants to move out. It’s not even a good place, it’s bloated and inefficient. We just somehow got used to it.</p>
        <p>So I want to call it out: where we are today is bullshit. As engineers, we can, and should, and will do better. We can have better tools, we can build better apps, faster, more predictable, more reliable, using fewer resources (orders of magnitude fewer!). We need to understand deeply what we are doing and why. We need to deliver: reliably, predictably, with topmost quality. We can—and should–take pride in our work. Not just “given what we had...”—no buts!</p>
        <p>I hope I’m not alone at this. I hope there are people out there who want to do the same. I’d appreciate if we at least start talking about how absurdly bad our current situation in the software industry is. And then we maybe figure out how to get out.</p>
        
      </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Java implementation of a quantum computing resistant cryptographic algorithm (178 pts)]]></title>
            <link>https://github.com/mthiim/dilithium-java</link>
            <guid>37984404</guid>
            <pubDate>Mon, 23 Oct 2023 11:54:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/mthiim/dilithium-java">https://github.com/mthiim/dilithium-java</a>, See on <a href="https://news.ycombinator.com/item?id=37984404">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" id="user-content-crystals---dilithium" dir="auto"><a href="#crystals---dilithium">CRYSTALS - Dilithium</a></h2>
<p dir="auto">This is a Java implementation of Dilithium, based on the C reference implementation and documentation. Further, I've wrapped it into a JCE provider, making it easy to use via a standardized interface.</p>
<p dir="auto">So what is Dilithium? The cryptographic algorithms RSA and ECC have long been known known to be vulnerable to attacks using quantum computers via Shor's algorithm. While quantum computers of the prerequisite size do not yet exist in practice, there's an ongoing search for algorithms that don't have this vulnerability. In fact, <a href="https://www.nist.gov/" rel="nofollow">NIST</a> has been running a competition for over 6 years in order to identify quantum-safe alternatives. On July 5th NIST <a href="https://www.nist.gov/news-events/news/2022/07/nist-announces-first-four-quantum-resistant-cryptographic-algorithms" rel="nofollow">announced</a> the three picks for Post-quantum digital signature schemes. Dilithium was among the three and was in fact recommended as the primary algorithm. Big congratulations to the authors! I wanted to study this new algorithm, and what better way than to try and implement it. This is what you are looking at :-)</p>
<p dir="auto">Dilithium is part of the CRYSTALS suite of algorithms and is based on algebratic lattices. Think linear algebra but where the matrix/vector entries are polynomials in the ring <math-renderer data-static-url="https://github.githubassets.com/static" data-run-id="d56876d3d9cd8ad22bf1d84727d4e456">$R_q = \mathbb{Z}_q[X]/(X^n+1)$</math-renderer>. For much more information (including the specification and C reference implementation I used), see <a href="https://pq-crystals.org/index.shtml" rel="nofollow">their page</a>.</p>
<p dir="auto">Like the reference implementation, this implementation supports all three documented security levels (levels 2, 3 and 5), all using the deterministic signature scheme. It passes all the KAT tests from the package. It supports serialization and deserialization using the documented formats.</p>
<p dir="auto">I have a dependency on Bouncy castle, which provides the SHAKE128/256 algorithms used internally in Dilithium.</p>
<p dir="auto"><em>IMPORTANT! This is a "for fun" implementation written in a couple of days. It's not intended to be production-grade code. No warranty or support of any kind is provided. However, it can be useful for diving into and experimenting with post-quantum algorithms. Use it at your own risk. If you don't like those terms, you must refrain from using this software.</em></p>
<h2 tabindex="-1" id="user-content-loading-the-security-provider" dir="auto"><a href="#loading-the-security-provider">Loading the security provider</a></h2>
<div dir="auto" data-snippet-clipboard-copy-content="DilithiumProvider provider = new DilithiumProvider();
Security.addProvider(provider);"><pre>DilithiumProvider provider = new <span>DilithiumProvider</span>();
Security.addProvider(provider)<span>;</span></pre></div>
<p dir="auto">If you wish, instead of adding the provider using addProvider(), you can omit this line and explicitly provide the provider-object when calling the .getInstance() methods (see below).</p>
<h2 tabindex="-1" id="user-content-key-pair-generation" dir="auto"><a href="#key-pair-generation">Key pair generation</a></h2>
<p dir="auto">To generate a key pair you use:</p>
<div dir="auto" data-snippet-clipboard-copy-content="SecureRandom sr = new SecureRandom();
KeyPairGenerator kpg = KeyPairGenerator.getInstance(&quot;Dilithium&quot;);
kpg.initialize(DilithiumParameterSpec.LEVEL2, sr);			
KeyPair kp = kpg.generateKeyPair();"><pre>SecureRandom sr = new <span>SecureRandom</span>();
KeyPairGenerator kpg = KeyPairGenerator.getInstance(<span><span>"</span>Dilithium<span>"</span></span>)<span>;</span>
kpg.initialize(DilithiumParameterSpec.LEVEL2, sr)<span>;</span>			
KeyPair kp = <span>kpg.generateKeyPair</span>();</pre></div>
<p dir="auto">Note that you must provide an algorithm parameter spec representing the desired security level - the above example uses level 2, but you can select 3 and 5 as well. The three parameter spec objects are declared as static fields on the DilithiumParameterSpec class. Alternatively, a static method, getSpecForSecurityLevel(), is provided on DilithiumParameterSpec, allowing you to easily retrieve the spec for a given level at runtime.</p>
<h2 tabindex="-1" id="user-content-signing" dir="auto"><a href="#signing">Signing</a></h2>
<p dir="auto">Having generated a key pair, signing works just the same as for other JCE providers. The example below signs a byte representation of "Joy!".</p>
<div dir="auto" data-snippet-clipboard-copy-content="Signature sig = Signature.getInstance(&quot;Dilithium&quot;);
sig.initSign(kp.getPrivate());
sig.update(&quot;Joy!&quot;.getBytes());
byte[] signature = sig.sign();"><pre>Signature sig = Signature.getInstance(<span><span>"</span>Dilithium<span>"</span></span>)<span>;</span>
<span>sig.initSign(kp.getPrivate</span>());
<span>sig.update("Joy!".getBytes</span>());
byte[] signature = <span>sig.sign</span>();</pre></div>
<h2 tabindex="-1" id="user-content-signature-verification" dir="auto"><a href="#signature-verification">Signature verification</a></h2>
<p dir="auto">Just as for signing, verification works as for other JCE providers</p>
<div dir="auto" data-snippet-clipboard-copy-content="Signature sig = Signature.getInstance(&quot;Dilithium&quot;);
sig.initVerify(kp.getPublic());
sig.update(&quot;Joy!&quot;.getBytes());
boolean b = sig.verify(signature);"><pre>Signature sig = Signature.getInstance(<span><span>"</span>Dilithium<span>"</span></span>)<span>;</span>
<span>sig.initVerify(kp.getPublic</span>());
<span>sig.update("Joy!".getBytes</span>());
boolean b = sig.verify(signature)<span>;</span></pre></div>
<p dir="auto">The boolean variable b now contains the outcome of the verification. Note that exceptions may be thrown in case of malformed signatures (as opposed to signatures that are merely incorrect).</p>
<h2 tabindex="-1" id="user-content-key-serializationdeserialization" dir="auto"><a href="#key-serializationdeserialization">Key serialization/deserialization</a></h2>
<p dir="auto">You can use the .getEncoded() method on the public and private key objects to obtain a byte representation of the key. The formats are compatible with the reference implementation.
In order to instantiate the keys from the byte representation, a key factory is provided. You can use this with the provided DilithiumPublicKeySpec and DilithiumPrivateKeySpec classes.
They are constructed using two parameters, namely the parameter spec (same as used for generating) and the byte representation. Note that the parameter spec is not encoded into the byte representation, and I decided to make the parameter choice explit rather than trying to infer it from length. In the future, I anticipate that ASN.1-based formats with OID's etc. will be standardized, and they will then explcitly encode the parameters. Of course, the serialization format could change as well as the standardization process moves along.</p>
<div dir="auto" data-snippet-clipboard-copy-content="byte[] pubkeyBytes = kp.getPublic().getEncoded(); // This is our bytes to be instantiated
KeyFactory kf = KeyFactory.getInstance(&quot;Dilithium&quot;);
PublicKey reconsructedPublicKey = kf.generatePublic(new DilithiumPublicKeySpec(spec, pubkeyBytes));"><pre>byte[] pubkeyBytes = <span>kp.getPublic().getEncoded</span>(); // This is our bytes to be instantiated
KeyFactory kf = KeyFactory.getInstance(<span><span>"</span>Dilithium<span>"</span></span>)<span>;</span>
PublicKey reconsructedPublicKey = kf.generatePublic(new DilithiumPublicKeySpec(spec, pubkeyBytes))<span>;</span></pre></div>
<p dir="auto">The private key may be reconstructed in the same fashion, using the DilithiumPrivateKeySpec class.</p>
<h2 tabindex="-1" id="user-content-low-level-use" dir="auto"><a href="#low-level-use">Low-level use</a></h2>
<p dir="auto">As an alternative to the low-level interface you can also use the static methods in the Dilithium class directly to generate, sign and verify. See e.g. how the JCE classes do it.</p>
<h2 tabindex="-1" id="user-content-running-the-known-answer-tests" dir="auto"><a href="#running-the-known-answer-tests">Running the known-answer tests</a></h2>
<p dir="auto">The official Dilithium package contains a known-answer test generator that generates a request and response file. I've provided a Java utility in KAT.java that can read the
request file generated by the reference implementation, run through the tests and generate a corresponding response file. You can then compare this response file to the one
generated by the official known-answer test generator and verify that they are byte-identical. The KAT.java program is run with parameters:</p>
<div dir="auto" data-snippet-clipboard-copy-content=" <input-request-file> <output-response-file> <level>"><pre> <span>&lt;</span>input-request-file<span>&gt;</span> <span>&lt;</span>output-response-file<span>&gt;</span> <span>&lt;</span>level<span>&gt;</span></pre></div>
<p dir="auto">Note that the desired security level (2, 3 or 5) must be provided as the 3rd argument. This must match what is configured in the config.h file in the C implementation when generating the response file used for comparison.</p>
<h2 tabindex="-1" id="user-content-disclaimer" dir="auto"><a href="#disclaimer">DISCLAIMER</a></h2>
<p dir="auto">This library is available under the Apache 2.0 license (see LICENSE). Note that the code has not been examined by a third party for potential vulnerabilities and as mentioned was not made to be used for production use. No warranty of any kind is provided. If you don't like those terms, you must refrain from using this software.</p>
<h2 tabindex="-1" id="user-content-references" dir="auto"><a href="#references">References</a></h2>
<p dir="auto">For more information on the CRYSTALS project, see their <a href="https://pq-crystals.org/index.shtml" rel="nofollow">website</a>.</p>
<h2 tabindex="-1" id="user-content-contact" dir="auto"><a href="#contact">Contact</a></h2>
<p dir="auto">Mail: <a href="mailto:martin@thiim.net">martin@thiim.net</a></p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Earth Stopped Getting Greener 20 Years Ago (121 pts)]]></title>
            <link>https://www.scientificamerican.com/article/earth-stopped-getting-greener-20-years-ago/</link>
            <guid>37984382</guid>
            <pubDate>Mon, 23 Oct 2023 11:52:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scientificamerican.com/article/earth-stopped-getting-greener-20-years-ago/">https://www.scientificamerican.com/article/earth-stopped-getting-greener-20-years-ago/</a>, See on <a href="https://news.ycombinator.com/item?id=37984382">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><figure aria-label="media" itemscope="" itemid="https://static.scientificamerican.com/sciam/cache/file/3914D19B-BE63-4544-ABA8870574834BCF_source.jpeg?w=590&amp;h=800&amp;D1EF4582-63F6-4373-8160E94B7C4799D5" itemprop="image" itemtype="http://schema.org/ImageObject" id="image-1"><div><picture><source media="(min-width: 768px) and (max-width: 1023px)" srcset="https://static.scientificamerican.com/sciam/cache/file/3914D19B-BE63-4544-ABA8870574834BCF_source.jpeg?w=690&amp;h=930&amp;D1EF4582-63F6-4373-8160E94B7C4799D5"><source media="(max-width: 767px)" srcset="https://static.scientificamerican.com/sciam/cache/file/3914D19B-BE63-4544-ABA8870574834BCF_source.jpeg?w=390&amp;h=520&amp;D1EF4582-63F6-4373-8160E94B7C4799D5"><source media="(min-width: 768px) and (max-width: 1023px)" srcset="https://static.scientificamerican.com/sciam/cache/file/3914D19B-BE63-4544-ABA8870574834BCF_source.jpeg?w=690&amp;h=930&amp;D1EF4582-63F6-4373-8160E94B7C4799D5"><source media="(max-width: 767px)" srcset="https://static.scientificamerican.com/sciam/cache/file/3914D19B-BE63-4544-ABA8870574834BCF_source.jpeg?w=390&amp;h=520&amp;D1EF4582-63F6-4373-8160E94B7C4799D5"><img importance="high" src="https://static.scientificamerican.com/sciam/cache/file/3914D19B-BE63-4544-ABA8870574834BCF_source.jpeg?w=590&amp;h=800&amp;D1EF4582-63F6-4373-8160E94B7C4799D5" width="590" height="800" alt="Earth Stopped Getting Greener 20 Years Ago" itemprop="url"></picture></div><figcaption itemprop="caption description">Scientists say the greening effects from rising levels of carbon dioxide might be over. Credit: <a href="https://earthobservatory.nasa.gov/global-maps/MOD_NDVI_M" target="_blank">NASA</a></figcaption></figure><div data-behavior="newsletter_promo dfp_article_rendering" data-dfp-adword="Advertisement" data-newsletterpromo_article-text="<p>Sign up for <em>Scientific American</em>&amp;rsquo;s free newsletters.</p>" data-newsletterpromo_article-image="https://static.scientificamerican.com/sciam/cache/file/4641809D-B8F1-41A3-9E5A87C21ADB2FD8_source.png" data-newsletterpromo_article-button-text="Sign Up" data-newsletterpromo_article-button-link="https://www.scientificamerican.com/page/newsletter-sign-up/?origincode=2018_sciam_ArticlePromo_NewsletterSignUp" name="articleBody" itemprop="articleBody"><p>The world is gradually becoming less green, scientists have found. Plant growth is declining all over the planet, and new research links the phenomenon to decreasing moisture in the air—a consequence of climate change.</p>

<p>The&nbsp;<a href="https://advances.sciencemag.org/content/5/8/eaax1396" target="_blank">study</a>&nbsp;published yesterday in&nbsp;<em>Science Advances</em>&nbsp;points to satellite observations that revealed expanding vegetation worldwide during much of the 1980s and 1990s. But then, about 20 years ago, the trend stopped.</p>

<p>Since then, more than half of the world’s vegetated landscapes have been experiencing a “browning” trend, or decrease in plant growth, according to the authors.</p>

<p>Climate records suggest the declines are associated with a metric known as vapor pressure deficit—that’s the difference between the amount of moisture the air actually holds versus the maximum amount of moisture it could be holding. A high deficit is sometimes referred to as an atmospheric drought.</p>

<p>Since the late 1990s, more than half of the world’s vegetated landscapes have experienced a growing deficit, or drying pattern.</p>

<p>Climate models indicate that vapor pressure deficit is likely to continue increasing as the world warms—a pattern that “might have a substantially negative impact on vegetation,” the authors write.</p>

<p>It’s not the first study to document the global decline in vegetation. A&nbsp;<a href="https://science.sciencemag.org/content/329/5994/940.abstract" target="_blank">2010 study</a>&nbsp;in&nbsp;<em>Science</em>&nbsp;was among the first to demonstrate that the greening increases of the 1990s had stalled or reversed. That study also suggested that the declines were probably water-related.</p>

<p>That’s not to say every last corner of Earth is losing its vegetation. Some recent studies have revealed that parts of the Arctic are “greening” as the chilly landscape warms. And there’s increasing plant growth still happening in other regions of the world, as well.</p>

<p>But on a global scale, averaged across the entire planet, the trend is pointing downward.</p>

<p>The declines challenge an argument often presented by skeptics of mainstream climate science to downplay the consequences of global warming: the idea that plants will grow faster with larger amounts of carbon dioxide. The argument hinges on the idea that food supplies will increase.</p>

<p>It’s largely a red herring, as climate scientists have patiently explained for years. Rising CO2 does benefit plants, at least up to a point, but it’s just one factor. Plants are also affected by many other symptoms of climate change, including rising temperatures, changing weather patterns, shifts in water availability and so on.</p>

<p>Many researchers have suggested that climate change, on the whole, is likely to be a net negative for much of the world’s vegetation, including agricultural crops. The new study would seem to suggest that those consequences are already in motion.</p>

<p>And as climate change affects plant growth, declining plant growth may also affect the pace of climate change.</p>

<p>Just last week, an anticipated&nbsp;<a href="https://www.ipcc.ch/report/srccl/">report</a>&nbsp;from the Intergovernmental Panel on Climate Change emphasized the importance of land and vegetation as climate mitigation tools (<a href="https://www.eenews.net/stories/1060880385/" target="_blank"><em>Climatewire</em></a>, Aug. 8). Forests and other vegetated landscapes tend to be significant carbon sinks, sucking carbon dioxide out of the atmosphere and storing it away. Less growth, on the other hand, means less carbon storage.</p>

<p>Atmospheric moisture, like carbon dioxide, is just one factor among many that may affect the world’s vegetation in the coming years. But since the drying trends seem to have had a particularly significant impact over the last two decades, the authors suggest that it “must be examined carefully when evaluating future carbon cycle responses.”</p>

<p><em>Reprinted from Climatewire with permission from E&amp;E News. E&amp;E provides daily coverage of essential energy and environmental news at&nbsp;<a href="http://www.eenews.net/" target="_blank">www.eenews.net</a>.</em></p></div><section><h3>ABOUT THE AUTHOR(S)</h3><div><ul></ul><p><strong>Chelsea Harvey</strong> covers climate science for&nbsp;<em>Climatewire</em>. She tracks the big questions being asked by researchers and explains what's known, and what needs to be, about global temperatures. Chelsea began writing about climate science in 2014. Her work has appeared in&nbsp;<em>The Washington Post,&nbsp;Popular Science,&nbsp;Men's Journal</em>&nbsp;and others.</p></div></section></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Woman wins 12-year legal battle against Google (247 pts)]]></title>
            <link>https://www.abc.net.au/news/2023-10-23/janice-duffy-wins-12-year-legal-battle-against-google/103008954</link>
            <guid>37983903</guid>
            <pubDate>Mon, 23 Oct 2023 10:50:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.abc.net.au/news/2023-10-23/janice-duffy-wins-12-year-legal-battle-against-google/103008954">https://www.abc.net.au/news/2023-10-23/janice-duffy-wins-12-year-legal-battle-against-google/103008954</a>, See on <a href="https://news.ycombinator.com/item?id=37983903">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>A line has been finally been drawn under an Adelaide woman's 12-year legal battle against global tech giant Google after she sued the company twice, mostly unrepresented,&nbsp;and won.</p><section role="contentinfo" aria-label="key points" data-component="KeyPoints" data-uri="coremedia://teaser/103012394"><h2 data-component="Heading">Key points:</h2><ul data-component="List" role="list"><li data-component="ListItem"><span></span>Dr Janice Duffy successfully argued in 2015 and 2023 that Google published defamatory extracts</li><li data-component="ListItem"><span></span>She reached a confidential settlement with the&nbsp;company which&nbsp;would pay her damages and legal costs</li><li data-component="ListItem"><span></span>She said&nbsp;it's never been about the money, but holding Google accountable.</li></ul></section><p>Dr Janice Duffy successfully argued in 2015 and 2023 that Google published defamatory extracts from American website RipOff Report on its search engine page, despite her notifying the company and asking for the posts to be removed.</p><p>She was set to start her damages trial on Monday for her most recent case&nbsp;but reached a confidential settlement with the multibillion-dollar company, which&nbsp;would&nbsp;pay her damages and legal costs.</p><p>It's&nbsp;the second time the company will be coughing up, after she received over $100,000 in damages in 2015.</p><p>The former SA Government researcher said it's never been about the money, but holding Google accountable.</p><p>"Google made me feel like I was worth nothing," Dr Duffy said.</p><p>"They just made me feel like I was this nothing human being – because I stood up to them."</p><h2 data-component="Heading">A dark place</h2><p>Dr Duffy said the nightmare began after first discovering defamatory information about her on the widely-used platform.</p><p>"I found it very difficult to leave the house, I used to lay on the couch and watch documentaries about serial killers to make me feel normal," she said.</p><p>She joined a volunteer dog rescuing network during that dark time.</p><p>"I started it because, basically I wanted someone to look after my dog – if I didn't survive it and I honestly didn't think I was going to survive it."</p><figure role="group" data-component="VerticalArticleFigure" aria-labelledby="103008970" data-uri="coremedia://imageproxy/103008970"><img alt="A woman walking outside an Adelaide court." sizes="(max-width: 543px) 543px," srcset="https://live-production.wcms.abc-cdn.net.au/37babfc3d834d60e8d85fcb23897770b?impolicy=wcms_crop_resize&amp;cropH=768&amp;cropW=1024&amp;xPos=0&amp;yPos=0&amp;width=862&amp;height=647 543w, https://live-production.wcms.abc-cdn.net.au/37babfc3d834d60e8d85fcb23897770b?impolicy=wcms_crop_resize&amp;cropH=620&amp;cropW=930&amp;xPos=73&amp;yPos=0&amp;width=862&amp;height=575" src="https://live-production.wcms.abc-cdn.net.au/37babfc3d834d60e8d85fcb23897770b?impolicy=wcms_crop_resize&amp;cropH=620&amp;cropW=930&amp;xPos=73&amp;yPos=0&amp;width=862&amp;height=575" loading="lazy" data-component="Image" data-lazy="true"><p><figcaption id="103008970" data-component="VerticalArticleFigure__figcaption" aria-live="polite"> <!-- -->Janice Duffy successfully sued the Internet giant Google for defamation.<span data-component="Byline"><span data-component="Text">(<span>ABC News: Candice Marcus</span>)</span></span></figcaption></p></figure><p>She contemplated taking her life, saying it destroyed her career in research.</p><p>But she said she pulled together all the strength she had ahead of her first trial, when she realised she would have to represent herself with dwindling finances to afford legal fees.</p><p>"It was just horrific — truly horrific — when I realised I had to do the trial myself… the only things that I had was an old printer and my research skills," she said.</p><p>Google used the defence of innocent dissemination, but even after her David and Goliath-like feat, similar defamatory information continued to appear on the site after her first case.</p><h2 data-component="Heading">Fighting back</h2><p>Paul Heywood-Smith KC helped Dr Duffy after her initial proceeding.</p><p>"[Google] lost the case, but in their arrogance they continued to broadcast it and Janice Duffy wasn't prepared to accept that."</p><figure role="group" data-component="VerticalArticleFigure" aria-labelledby="103012184" data-uri="coremedia://imageproxy/103012184"><img alt="A serious man in a suit staring at the camera " sizes="(max-width: 543px) 543px," srcset="https://live-production.wcms.abc-cdn.net.au/a6124420fc30eaafcacd7fa381b5ef38?impolicy=wcms_crop_resize&amp;cropH=3333&amp;cropW=4444&amp;xPos=278&amp;yPos=0&amp;width=862&amp;height=647 543w, https://live-production.wcms.abc-cdn.net.au/a6124420fc30eaafcacd7fa381b5ef38?impolicy=wcms_crop_resize&amp;cropH=3333&amp;cropW=5000&amp;xPos=0&amp;yPos=0&amp;width=862&amp;height=575" src="https://live-production.wcms.abc-cdn.net.au/a6124420fc30eaafcacd7fa381b5ef38?impolicy=wcms_crop_resize&amp;cropH=3333&amp;cropW=5000&amp;xPos=0&amp;yPos=0&amp;width=862&amp;height=575" loading="lazy" data-component="Image" data-lazy="true"><p><figcaption id="103012184" data-component="VerticalArticleFigure__figcaption" aria-live="polite"> <!-- -->Paul Heywood-Smith KC assisted Janice Duffy in some of her legal proceedings.<span data-component="Byline"><span data-component="Text">(<span>ABC News:&nbsp;Lincoln Rothall</span>)</span></span></figcaption></p></figure><p>Mr Heywood-Smith says her triumphs after fighting the giant mostly unrepresented — are remarkable.</p><p>"Google has the capacity to deep pocket anyone –make their legal costs and the costs of litigating so expensive that most people couldn't even contemplate it," he said.</p><p>The recently retired KC said Dr Duffy's landmark wins could assist other potential plaintiffs.</p><p>"When somebody goes into their solicitor and asks, 'have I got a case?' and the solicitor goes to the law on defamation — they will see the case of Duffy against Google and it's clear cut — and so she's done a wonderful service."</p><h2 data-component="Heading">Emotional toll</h2><p>Independent expert in technology and law,&nbsp;Joel Lisk from Flinders University, said there may not be a large amount of similar proceedings in Australia — given the expense, time and emotional toll it would take on potential plaintiffs.</p><p>"It should be the approach of last resort – you should be able to settle these matters or request Google to remove them – but it does strengthen the defamation position here in Australia."</p><p>He says Dr Duffy's case could put more responsibility on search engine companies to monitor what appears on its websites more closely.</p><p>"Following this proceeding, Google will likely look at the judgement and take steps and look at how it manages and produces data – but there's only so many things you can do without significant technological innovation."</p><p>Google did not&nbsp;respond in time to the ABC's request for comment on Dr Duffy's case.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Shopify Files Lawsuit over Illegal DMCA Takedown Abuse (287 pts)]]></title>
            <link>https://torrentfreak.com/shopify-files-lawsuit-over-illegal-dmca-takedown-abuse-231020/</link>
            <guid>37983386</guid>
            <pubDate>Mon, 23 Oct 2023 09:29:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://torrentfreak.com/shopify-files-lawsuit-over-illegal-dmca-takedown-abuse-231020/">https://torrentfreak.com/shopify-files-lawsuit-over-illegal-dmca-takedown-abuse-231020/</a>, See on <a href="https://news.ycombinator.com/item?id=37983386">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>

<span property="itemListElement" typeof="ListItem"><a property="item" typeof="WebPage" title="Go to TorrentFreak." href="https://torrentfreak.com/"><span property="name">Home</span></a><meta property="position" content="1"></span> &gt; <span property="itemListElement" typeof="ListItem"><a property="item" typeof="WebPage" title="Go to the Piracy category archives." href="https://torrentfreak.com/category/piracy/"><span property="name">Piracy</span></a><meta property="position" content="2"></span> &gt; <span></span>
</p>
<p>
<span> </span>
E-commerce platform Shopify is suing a 'John Doe' defendant for sending numerous false copyright complaints. The DMCA takedown notices have targeted a variety of vendors, who had their legitimate products taken offline as a result of the fraudulent actions. In addition, these vendors risked losing their entire accounts due to multiple false claims.
</p>
</div><div>
<p><img decoding="async" src="https://torrentfreak.com/images/shopify-logo.jpg" alt="shopify" width="300" height="203" srcset="https://torrentfreak.com/images/shopify-logo.jpg 462w, https://torrentfreak.com/images/shopify-logo-300x203.jpg 300w" sizes="(max-width: 300px) 100vw, 300px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20300%20203'%3E%3C/svg%3E" data-lazy-srcset="https://torrentfreak.com/images/shopify-logo.jpg 462w, https://torrentfreak.com/images/shopify-logo-300x203.jpg 300w" data-lazy-src="https://torrentfreak.com/images/shopify-logo.jpg">The DMCA takedown process gives copyright holders the option to remove infringing content from the web.</p>
<p>It’s a powerful, widely-used tool that takes millions of URLs and links offline every day. This often happens for a good reason, but some takedown efforts are questionable.</p>
<h2>Takedown Abuse</h2>
<p><a href="https://www.shopify.com/">Shopify</a> was targeted by a series of problematic DMCA requests earlier this month. The e-commerce platform typically receives thousands of takedown notices per month from rightsholders, which are in part processed automatically. That works well in most instances, but not always. </p>
<p>Starting on October 5, an unknown person created the account “Sacha Go” which was subsequently used to file dozens of DMCA takedown requests. The notices targeted listings on a variety of shops selling perfume products, claiming that they infringe copyright. </p>
<p>After being alerted by one of the targeted merchants Shopify looked into the matter, concluding that all takedowns were false. Instead of containing legitimate claims the DMCA notices were being used to harass Shopify and its merchants.</p>
<h2>Shopify Files Lawsuit</h2>
<p>The account information provided by “Sacha Go” turned out to be false. To stop this activity and any related to future accounts the defendant may create, Shopify filed a complaint alleging DMCA violations at a federal court in New York.</p>
<p>“Defendant Doe has sent Shopify dozens of DMCA takedown notices littered with misrepresentations, claiming that materials Shopify merchants have posted to their online stores supposedly infringe Doe’s copyrights. But Doe does not actually own any of the copyrights to which he claims ownership in these notices,” Shopify writes. </p>
<center><img decoding="async" src="https://torrentfreak.com/images/shop-suit.jpg" alt="shopift suit" width="600" height="485" srcset="https://torrentfreak.com/images/shop-suit.jpg 1115w, https://torrentfreak.com/images/shop-suit-300x242.jpg 300w" sizes="(max-width: 600px) 100vw, 600px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20600%20485'%3E%3C/svg%3E" data-lazy-srcset="https://torrentfreak.com/images/shop-suit.jpg 1115w, https://torrentfreak.com/images/shop-suit-300x242.jpg 300w" data-lazy-src="https://torrentfreak.com/images/shop-suit.jpg"></center>
<p>Shopify says that it’s not feasible for the company to investigate the validity of all takedown notices in detail. As such, these false claims resulted in actual removals and the affected stores also received strikes on their accounts. </p>
<h2>Merchants at Risk</h2>
<p>The strikes will be removed if the merchant files a successful counternotice, but those can take up to two weeks to process. Also, those who are not aware of their right to appeal risk losing their accounts. </p>
<p>“[F]or unsuspecting merchants who may be unfamiliar with the DMCA, a sudden onslaught of takedown notices can result in the termination of their entire store under Shopify’s repeat infringer policy,” Shopify explains. </p>
<p>The defendant stands accused of sending more than 70 fraudulent takedown notices from October 5 to October 13, targeting at least twenty perfume shops with bogus copyright claims. These false claims resulted in 52 strikes against various stores. </p>
<h2>Shopify Seeks Damages and an Injunction</h2>
<p>On October 12, Shopify launched an investigation and the company ultimately restored all items and removed all strikes, but that came at significant cost. </p>
<p>“Those efforts cost Shopify tens of thousands of dollars in personnel time and resources. The loss of goodwill that Shopify suffered from penalizing innocent merchants cannot be quantified,” the company explains.</p>
<p>The defendant’s motivations are currently unknown, but it’s certainly possible that they run a competing perfume store. If that’s the case, these takedown notices were likely intended to harm competitors. </p>
<p>Through discovery, Shopify hopes to identify the John Doe and hold them responsible for the recent wave of DMCA abuse. In addition to requesting damages, Shopify also seeks an injunction to prevent more false DMCA notices going forward. </p>
<p><em>—</em></p><p><em>A copy of Shopify’s complaint, filed at the U.S. District Court for the Southern District of New York is available <a href="https://storage.courtlistener.com/recap/gov.uscourts.nysd.608376/gov.uscourts.nysd.608376.1.0.pdf">here (pdf)</a></em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Raspberry Pi 5: available now (195 pts)]]></title>
            <link>https://www.raspberrypi.com/news/raspberry-pi-5-available-now/</link>
            <guid>37982948</guid>
            <pubDate>Mon, 23 Oct 2023 08:29:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.raspberrypi.com/news/raspberry-pi-5-available-now/">https://www.raspberrypi.com/news/raspberry-pi-5-available-now/</a>, See on <a href="https://news.ycombinator.com/item?id=37982948">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
<p>Three weeks ago, we unveiled the latest generation of our flagship product: <a href="https://www.raspberrypi.com/products/raspberry-pi-5/">Raspberry Pi 5</a>. Since then, we’ve shared insights into the overall <a href="https://www.raspberrypi.com/news/james-adams-and-eben-upton-on-designing-raspberry-pi-5/">architecture</a> of the platform, the <a href="https://www.raspberrypi.com/news/rp1-the-silicon-controlling-raspberry-pi-5-i-o-designed-here-at-raspberry-pi/">RP1</a> I/O controller, the <a href="https://www.raspberrypi.com/news/optimising-raspberry-pi-5s-software-environment/">software stack,</a> the <a href="https://www.raspberrypi.com/news/image-processing-on-raspberry-pi-5-our-new-hardware-image-signal-processor/">image signal processor</a>, and some of our official accessories, including the <a href="https://www.raspberrypi.com/news/designing-the-perfect-case-and-cooling-for-raspberry-pi-5/">case</a>, and the forthcoming updated <a href="https://www.raspberrypi.com/news/designing-the-poe-hat-for-raspberry-pi-5-compact-efficient-power-and-networking/">PoE+ HAT</a>.</p>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="649" src="https://www.raspberrypi.com/app/uploads/2023/10/RPi-5-Featured-Product-copy-1024x649.jpg" alt="Raspberry Pi 5 on a black background with orange, yellow, green , pink and turqouise swirls, circles, patterns exploding from behind it" srcset="https://www.raspberrypi.com/app/uploads/2023/10/RPi-5-Featured-Product-copy-1024x649.jpg 1024w, https://www.raspberrypi.com/app/uploads/2023/10/RPi-5-Featured-Product-copy-300x190.jpg 300w, https://www.raspberrypi.com/app/uploads/2023/10/RPi-5-Featured-Product-copy-768x487.jpg 768w, https://www.raspberrypi.com/app/uploads/2023/10/RPi-5-Featured-Product-copy-1536x974.jpg 1536w, https://www.raspberrypi.com/app/uploads/2023/10/RPi-5-Featured-Product-copy-2048x1298.jpg 2048w, https://www.raspberrypi.com/app/uploads/2023/10/RPi-5-Featured-Product-copy-800x507.jpg 800w, https://www.raspberrypi.com/app/uploads/2023/10/RPi-5-Featured-Product-copy-450x285.jpg 450w, https://www.raspberrypi.com/app/uploads/2023/10/RPi-5-Featured-Product-copy-900x570.jpg 900w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>


<p>Behind the scenes, we’ve been working hard with our friends at the Sony UK Technology Centre in Wales (where your Pi is baked) to ramp up the manufacturing and production test processes. Things have gone a little faster than expected, and we’re happy to announce that the first mass-production units will ship to customers this week. As promised, we’ll be starting with subscribers to The MagPi and HackSpace magazines, who have taken advantage of the Priority Boarding promotion.</p>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="674" src="https://www.raspberrypi.com/app/uploads/2023/10/PI_5_BENCHMARK_LO-1024x674.jpg" alt="" srcset="https://www.raspberrypi.com/app/uploads/2023/10/PI_5_BENCHMARK_LO-1024x674.jpg 1024w, https://www.raspberrypi.com/app/uploads/2023/10/PI_5_BENCHMARK_LO-300x197.jpg 300w, https://www.raspberrypi.com/app/uploads/2023/10/PI_5_BENCHMARK_LO-768x505.jpg 768w, https://www.raspberrypi.com/app/uploads/2023/10/PI_5_BENCHMARK_LO-1536x1010.jpg 1536w, https://www.raspberrypi.com/app/uploads/2023/10/PI_5_BENCHMARK_LO-800x526.jpg 800w, https://www.raspberrypi.com/app/uploads/2023/10/PI_5_BENCHMARK_LO-450x296.jpg 450w, https://www.raspberrypi.com/app/uploads/2023/10/PI_5_BENCHMARK_LO-900x592.jpg 900w, https://www.raspberrypi.com/app/uploads/2023/10/PI_5_BENCHMARK_LO.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>


<p>By the end of next week, all existing Priority Boarding orders will have shipped, and every <a href="https://www.raspberrypi.com/resellers/">Approved Reseller</a> in a country where our compliance paperwork has been signed off by the authorities will have received initial stock of both 4GB and 8GB variants, so those of you who have pre-ordered will start to see parcels arriving in your mailboxes. We are continuing to increase our production rate, with the aim of fulfilling all backorders, and getting Raspberry Pi in stock at all our Approved Resellers, by the end of the year – by then we expect you to be able to just buy one straight off the shelf.</p>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="681" src="https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-06-at-07.45.10-1024x681.png" alt="Close up of RP1 silicon on a Raspberry Pi 5 board" srcset="https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-06-at-07.45.10-1024x681.png 1024w, https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-06-at-07.45.10-300x200.png 300w, https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-06-at-07.45.10-768x511.png 768w, https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-06-at-07.45.10-1536x1022.png 1536w, https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-06-at-07.45.10-800x532.png 800w, https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-06-at-07.45.10-450x299.png 450w, https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-06-at-07.45.10-900x599.png 900w, https://www.raspberrypi.com/app/uploads/2023/10/Screenshot-2023-10-06-at-07.45.10.png 1852w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>


<p>We’ve been excited to see the response of early users to Raspberry Pi 5, and can’t wait to see what you do once you get your hands on it. Let us know when you start tinkering with yours!</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EU Chat Control Bill Postponed (227 pts)]]></title>
            <link>https://tutanota.com/blog/chat-control-criticism</link>
            <guid>37982655</guid>
            <pubDate>Mon, 23 Oct 2023 07:48:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tutanota.com/blog/chat-control-criticism">https://tutanota.com/blog/chat-control-criticism</a>, See on <a href="https://news.ycombinator.com/item?id=37982655">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>The Council of EU Member States has postponed the final vote on the Child Sexual Abuse Regulation (CSAR), which had been
scheduled for Oct. 19th - which is the second postponement already. EU countries simply can't get an agreement on this highly
controversial draft, which then - even if EU Member States come to an agreement eventually - also needs to be discussed in the EU Parliament.
This is great sign that the regulation, also dubbed chat control and one of the most criticized EU laws ever, might fail.
</p><div><p>The fight over chat control continues among the EU member states were a small group of countries - namely Germany,
Austria, Netherlands, Poland, Sweden, Estonia, and Slovenia - are in opposition to the current draft of the EU CSA Regulation.
German politicians have said before that <a href="https://tutanota.com/blog/posts/eu-client-side-scanning">there is no prosecution at any cost</a>, a clear statement
against the EU plans for client-side scanning which would undermine encryption.</p>
<p>This comes at a very important time as the UK just passed the <a href="https://tutanota.com/blog/online-safety-bill-encryption">Online Safety Bill, the so called 'playbook for dictators'</a>.
While it's now theoretically possible for the UK to undermine encryption, the EU still has the chance to take a more
pro-privacy approach when it comes to safeguarding the web.</p>
<h3 id="germany-opposes-chat-control">Germany opposes chat control</h3>
<p>
		<picture>
   			<source type="image/webp" srcset="https://tutanota.com/blog/images/German-parliamant.webp">
    		<img height="773" width="1280" loading="lazy" alt="Germany opposes chat control as illegal mass surveillance." src="https://tutanota.com/blog/images/German-parliamant.jpg">
		</picture></p>
<p>Germany demanded to postpone the vote, as in the previous session, supported by Austria.
The work would not be finished, yet, the measures in the current text are disproportionate and illegal and need to be amended.</p>
<p>Earlier this year the legal experts of the EU Parliament's Scientific Service concluded in a study on the legality of <a href="https://tutanota.com/blog/chat-control">chat control</a>:</p>
<blockquote>
<p>"when weighing the fundamental rights affected by the measures of the CSA proposal, it can be established that
the CSA proposal would violate Articles 7 and 8 of the Charter of Fundamental Rights with regard to users."</p>
</blockquote>
<p>According to the legal services of the EU, the CSAR proposal's parts on chat control via client-side scanning are
disproportionate and contrary to fundamental rights. <strong>The EU CSA Regulation is illegal under EU law.</strong></p>
<h3 id="council-is-divided">Council is divided</h3>
<p>In addition, Poland,
the Netherlands and Sweden wanted changes to the text of the law. Nine other states called for the common position
to be adopted soon. Their argumentation: in the trilogue negotiations with the Commission and the EU Parliament, the states will have to make
further compromises anyway.</p>
<p><strong>But since the start of the debates 18 months ago, surveillance obligations such as client-side scanning, chat control, and encryption aspects - key
points of the draft law - are particularly controversial among EU member states.</strong></p>
<p>Sweden sees "problems with the integrity and legal certainty of the proposal."
Poland called everything
"very complicated," saying the CSA Regulation has not yet "managed to strike the right balance between child protection and data protection."</p>
<p>Poland demanded that only chats of "people under concrete suspicion" should be scanned, not those of innocent citizens.</p>
<p>Several states criticize other provisions as disproportionate. The Netherlands and Germany want to exempt audio telephony, while
Sweden wants to exempt communications over mobile networks. Sweden and the Netherlands want to limit scanning
to known abusive material and exempt unknown material and grooming.</p>
<p>This demonstrates how divided EU member states still are - and how controversial chat control is, one of the most criticized
EU laws of all time.</p>
<h3 id="eu-commissions-conflicting-statements">EU Commission's conflicting statements</h3>
<p><strong>The EU Commission, however, rejects the arguments of the opponents and claims that you can protect and scan chats at the same time - however, giving no evidence
on how this should be done.</strong></p>
<p>At the same time, another formulation within the draft law makes it clear that chat control is a surveillance tool: Non-public communication services are to be
exempted, for example if they are "used for national security purposes." This is to protect "confidential information,
including classified information." <strong>States do not want chat control for their own communications to avoid surveillance.</strong></p>
<h3 id="decision-postponed">Decision postponed</h3>
<p>While the EU Commission is putting pressure on the states to come to a final decision, it has become obvious that
there is no qualified majority for the current proposal. Consequently, <strong>the vote on CSAR has been postponed within the council</strong>.</p>
<p><strong>This comes at no surprise as no other EU law has been criticized as much as
<a href="https://www.patrick-breyer.de/wp-content/uploads/2023/09/LEAK_bf162e8c-5804-479b-972c-d12321bff2c9-Compromise-text-on-CSAM-regulation-on-Sept-8.pdf">CSAR (leaked draft of Spanish Presidency)</a>.</strong></p>
<h2 id="criticism-of-chat-control">Criticism of chat control</h2>
<h4 id="1-chat-control-may-be-illegal">1. Chat control may be illegal</h4>
<p><strong>The core problem of CSAR is the following: scanning the communications of unsuspected persons en masse without cause
is disproportionate and contrary to fundamental rights.</strong></p>
<p>In May last year, the European Commission proposed to introduce mandatory requirements for all chat, messaging and email services,
even when providing end-to-end encryption, to scan messages for illegal child sexual abuse material (CSAM).
But since their publication, the proposed measures are criticized across Europe as these could lead to the de
facto “permanent surveillance of all interpersonal communications”.</p>
<p>The <a href="https://www.citizensinformation.ie/en/government-in-ireland/european-government/eu-law/charter-of-fundamental-rights/">EU Charter of Fundamental Rights</a>
guarantees the right to privacy for all people living in the European Union. Consequently, the EU legal advisors have concluded
that European chat control proposals which would require tech companies to scan private and encrypted messages
for child abuse material (CSAM) are in breach with EU law.</p>
<p>The controversial EU law will enable governments to serve “detection orders” on technology companies,
requiring them to scan private messages and emails for “indicators of child abuse”. This could
undermine encrypted communications, which is criticized by security experts as well as privacy advocates as being
general and indiscriminate mass surveillance.
In addition, one must remember that the German Federal Constitutional Court
has even declared <a href="https://tutanota.com/blog/posts/data-retention-germany">data retention</a> as illegal in Germany for being "disproportionate".</p>
<p>It is highly likely that the CSA Regulation - should it become law - would be <strong>declared illegal by the European Court of
Justice (ECJ)</strong> as well. The requirement for companies such as WhatsApp, Signal and others to scan every
message - even when encrypted - for child abuse material infringes people's right to privacy, which is in conflict with the EU Charter of Fundamental Rights.</p>
<p>While technology companies have unsuccessfully objected to similar UK proposals in the <a href="https://tutanota.com/blog/online-safety-bill-encryption">Online Safety Bill</a>
which just got passed including it's controversial requirement to scan for child sexual abuse material once a "feasible
technology" exists, it seems rather unlikely that something similar will be passed in the EU given the
great resistance, even among EU member states, but even more so among European MPs.</p>
<h4 id="2-lobbying-from-ai-companies">2. Lobbying from AI companies</h4>
<p>In September 2023 a new research was <a href="https://balkaninsight.com/2023/09/25/who-benefits-inside-the-eus-fight-over-scanning-for-child-sex-content/">published</a>
that threw a very different light on chat control - and who would really benefit if all Europeans would be monitored
24/7 on the internet.</p>
<p>Next to Ashton Kutcher and his organization Thorn a long list of organizations, AI companies and law enforcement are lobbying pro chat control in Brussels.
The research for example exposes the WeProtect Global Alliance as a government-affiliated institution that is closely linked to
ex-diplomat Douglas Griffiths and his Oak Foundation. The latter has invested more than 24 million US dollars in lobbying for
chat control since 2019, for example via the Ecpat network, the Brave organization and the PR agency Purpose.</p>
<p>The
research "confirms our worst fears," said Diego Naranjo, head of policy at civil rights organization European Digital Rights (EDRi).
"The most criticized European law on technology in the last decade is the product of lobbying by private companies and law enforcement."
EU commissioner, Ylva Johansson, ignored "science and civil society" and proposed a law to "legalize mass surveillance and break encryption,"
he said. "Child protection is being abused here as a door-opener for an infrastructure for mass surveillance without any reason,"
complains Konstantin Macher of the data protection association Digitalcourage.</p>
<h4 id="3-germany-against-proposal">3. Germany against proposal</h4>
<p>Germany is the strongest opponent of the current CSAR draft - and rightly so. Germany has a track record of defending
people's right to privacy, not least because of its history of
mass surveillance during the German repressive systems of the <a href="https://tutanota.com/blog/posts/germany-unity-day">German Democratic Republic (GDR) and during World War II</a>.</p>
<p>Today, German politicians say: "There is no prosecution at any cost." Meaning: The right to privacy is an important
human right, one that we must not give up.</p>
<h4 id="4-mostly-criticized-eu-law-ever">4. Mostly criticized EU law ever</h4>
<p>According to the non-profit organization EDRi
an "unprecedentedly broad range of stakeholders have raised concerns that despite its important aims, the measures
proposed in the draft EU Child Sexual Abuse Regulation are fundamentally incompatible with human rights".</p>
<p>EDRi has <a href="https://edri.org/our-work/most-criticised-eu-law-of-all-time/">published</a> an impressive collection of 69 opposing
voices from EU politicians, EU member states, tech companies and even child protection experts explaining why chat control must fail.</p>
<p>It also published an open letter signed by over 80 <a href="https://edri.org/our-work/open-letter-eu-countries-should-say-no-to-the-csar-mass-surveillance-proposal/">NGOs</a>
adding to the voice of almost <a href="https://docs.google.com/document/d/13Aeex72MtFBjKhExRTooVMWN9TC-pbH-5LEaAbMF91Y/edit?pli=1">500 scientists</a>
explaining why we must fight for privacy in Europe.</p>
<p><strong>No matter how politicians try to convince the public: Scanning our private message for child sexual abuse material is mass surveillance.
We must never allow this.</strong></p>
<h3 id="tutanota-wont-accept-chat-control">Tutanota won't accept chat control</h3>
<p>At Tutanota we are freedom fighters: We are at the forefront of the privacy revolution by offering everyone in the world
a private email account.</p>
<p>Should the CSA Regulation more forward in its current form, we would be willing to defend people's right to privacy in court
as we have done so before in Germany.</p>
<p>We put your privacy and security first, our code for Tutanota's automatic end-to-end encryption is publicly available
as open source. We would never undermine our privacy promise or our encryption.</p>
<p><strong>Our position remains firm: we will do
whatever it takes to ensure your right to privacy.</strong></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Protomaps – A free and open source map of the world (599 pts)]]></title>
            <link>https://protomaps.com/</link>
            <guid>37982621</guid>
            <pubDate>Mon, 23 Oct 2023 07:44:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://protomaps.com/">https://protomaps.com/</a>, See on <a href="https://news.ycombinator.com/item?id=37982621">Hacker News</a></p>
<div id="readability-page-1" class="page"><div class="page"><main><article><section><blockquote><p>Protomaps is an open source map of the world, deployable as a single static file on cloud storage.<!-- --> <a target="_blank" rel="noreferrer" href="https://docs.protomaps.com/">View docs</a> </p></blockquote></section><div><div><p>Browse the map to view requests...</p><!-- --> </div></div><section><table><thead></thead><tbody><tr><td><div><h3>Open source format</h3><p><a href="https://protomaps.com/docs/pmtiles">PMTiles</a> is an open specification for single-file tile pyramids built on compressed Hilbert ordering and queryable via HTTP Range Requests.</p><p><a href="https://protomaps.com/docs/pmtiles">Learn about PMTiles</a> </p></div></td><td><div><h3>CDN Integration </h3><p>Protomaps can optionally be delivered through an edge network like AWS Cloudfront and Cloudflare for ultra-low latency, using Lambda or Workers.</p><p><a href="https://protomaps.com/docs/cdn">Deploy on CDN</a> </p></div></td><td><div><h3>Frontend Friendly </h3><p>First-class support for mapping libraries like <a href="https://protomaps.com/docs/frontends/leaflet">Leaflet</a> and <a href="https://protomaps.com/docs/frontends/maplibre">MapLibre GL</a> to enable vector cartography and visualization of your own geodata.</p><p><a href="https://protomaps.com/docs/faq#map-rendering">Map Rendering</a> </p></div></td></tr></tbody></table><hr><h3>“Protomaps is the single most exciting development in digital mapping in the past 10 years.” </h3><h4>― <a target="_blank" rel="noreferrer" href="https://millsfield.sfomuseum.org/blog/2022/10/28/nacis/">Aaron Straup Cope</a></h4></section><div aria-live="polite"><pre>import * as pmtiles from 'pmtiles'

let protocol = new pmtiles.Protocol()
maplibregl.addProtocol("pmtiles",protocol.tile)
var style = {
"version": 8,
"sources": {
    "example_source": {
        "type": "vector",
        "url": "pmtiles://https://mysite/mydata.pmtiles",
        "attribution": '© OpenStreetMap'
    }
}
</pre></div><section><div><ul><li><p><strong>A fraction of the cost</strong></p><p>Can reduce your mapping bills from hundreds per month to pennies, all on cloud infrastructure you use already.</p></li><li><p><strong>Take back control</strong></p><p>Your map-based projects and sites don't depend on a third party service or API keys, and work offline, forever.</p></li><li><p><strong>Hosted API</strong></p><p>Protomaps also maintains a Tiles API - <a target="_blank" rel="noreferrer" href="https://app.protomaps.com/signup">get a free API key</a>. It's free for non-commercial use, or commercial use paired with a <a target="_blank" rel="noreferrer" href="https://github.com/sponsors/protomaps">GitHub sponsorship.</a></p></li></ul></div><hr><div><div><h3>A 100% independent software project </h3></div><div><p>Protomaps is a <strong>self-funded, solo developer project</strong> with a mission to make interactive cartography accessible to hobbyists and organizations of all sizes. An essential part of that mission is publishing open source software under commercial-friendly licenses.</p><p>You can support my full-time work on Protomaps in a few ways:</p><ul><li><p>Downloading the <a href="https://protomaps.com/docs/downloads">open source world basemap tileset</a> with a support plan on <a target="_blank" rel="noreferrer" href="https://github.com/sponsors/protomaps">GitHub Sponsors</a>.</p></li><li><p>Paid development of open source features.</p></li></ul><p><a href="mailto:hi@protomaps.com">Contact me</a> </p></div></div></section></article></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why Japan Has Blue Traffic Lights Instead of Green (162 pts)]]></title>
            <link>https://www.rd.com/article/heres-japan-blue-traffic-lights/</link>
            <guid>37982495</guid>
            <pubDate>Mon, 23 Oct 2023 07:21:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rd.com/article/heres-japan-blue-traffic-lights/">https://www.rd.com/article/heres-japan-blue-traffic-lights/</a>, See on <a href="https://news.ycombinator.com/item?id=37982495">Hacker News</a></p>
Couldn't get https://www.rd.com/article/heres-japan-blue-traffic-lights/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Tailwind vs. Semantic CSS (115 pts)]]></title>
            <link>https://nuejs.org/blog/tailwind-vs-semantic-css/</link>
            <guid>37982407</guid>
            <pubDate>Mon, 23 Oct 2023 07:05:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nuejs.org/blog/tailwind-vs-semantic-css/">https://nuejs.org/blog/tailwind-vs-semantic-css/</a>, See on <a href="https://news.ycombinator.com/item?id=37982407">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<article>

<p>This study compares two websites with a similar design: the official Tailwind “spotlight” template from the developers of Tailwind, and the same site crafted with semantic CSS and <a href="https://nuejs.org/docs/nuejs/server-components.html">Nue server components</a>. We’ll take a deep look at what is under the hood and how the sites are built.</p>

<section>
<p>
<a href="https://spotlight.tailwindui.com/">

  <picture>
    <source srcset="https://nuejs.org/blog/tailwind-vs-semantic-css/img/tw-home.png" media="(max-width: 768px)" type="image/png"><source srcset="https://nuejs.org/blog/tailwind-vs-semantic-css/img/tw-home-big.png" media="(min-width: 768px)" type="image/png">
    
  </picture>

  <figcaption>Tailwind UI version →</figcaption>

  

</a>
</p>
<p>

<a href="https://nuejs.org/@spotlight/">

  <picture>
    <source srcset="https://nuejs.org/blog/tailwind-vs-semantic-css/img/nue-home.png" media="(max-width: 768px)" type="image/png"><source srcset="https://nuejs.org/blog/tailwind-vs-semantic-css/img/nue-home-big.png" media="(min-width: 768px)" type="image/png">
    
  </picture>

  <figcaption>Semantic version →</figcaption>

  

</a>
</p>
</section>
<section>
<h4 id="gist">Gist<a href="#gist" title="Permlink for &quot;Gist&quot;"></a></h4>
<p><strong>The semantic version is 8 × smaller, renders faster, and is easier to modify and extend.</strong></p>

</section>
<h2 id="front-page-html">Front page HTML<a href="#front-page-html" title="Permlink for &quot;Front page HTML&quot;"></a></h2>
<p>The main difference is that Tailwind uses “utility” class names and Nue uses semantic class names. That is: Nue gives meaning to the elements like <code>nav</code>, <code>button</code>, and <code>.gallery</code> and styles them with an external stylesheet. Tailwind styles elements inline — directly on the markup.</p>
<p>We can easily see the difference in the HTML markup by drilling down to the first element on the main navigation:</p>

<a>

  <picture>
    <source srcset="https://nuejs.org/blog/tailwind-vs-semantic-css/img/markup.png" media="(max-width: 768px)" type="image/png"><source srcset="https://nuejs.org/blog/tailwind-vs-semantic-css/img/markup-big.png" media="(min-width: 768px)" type="image/png">
    
  </picture>

  <figcaption>Drilling down to the first element on the main navigation</figcaption>

  

</a>
<p>The semantic version is smaller because it utilizes high-level, semantic components like <code>.nav</code> and the external CSS can target elements with CSS selectors like <code>body &gt; header</code>. Tailwind needs significantly more markup because the utility-first approach lacks the power of CSS selectors. You are forced to wrap divs inside divs inside divs and fill the elements with Tailwind-specific class syntax.</p>
<p>Here is the full HTML source code of the front page.</p>

<a>

  <picture>
    <source srcset="https://nuejs.org/blog/tailwind-vs-semantic-css/img/html.jpg" media="(max-width: 768px)" type="image/jpeg"><source srcset="https://nuejs.org/blog/tailwind-vs-semantic-css/img/html-big.jpg" media="(min-width: 768px)" type="image/jpeg">
    
  </picture>

  <figcaption>Full HTML coding on the front page</figcaption>

  

</a>
<p>Tailwind (and Next.js) generate 75K of unminified HTML, while the semantic version is only 8K. While some parts come from Next, it’s pretty clear that Tailwind requires significantly more HTML to render the same design than the semantic version.</p>
<p>With Tailwind the <a href="https://www.siteguru.co/free-seo-tools/text-to-html-ratio?url=spotlight.tailwindui.com">Text to HTML Ratio</a> is only 2.3%, which is “Very low” according to SiteGuru. <a href="https://www.siteguru.co/free-seo-tools/text-to-html-ratio?url=nuejs.org/@spotlight/">Nue ratio</a>, however, is 20.3% which is “Good”.</p>
<h2 id="front-page-css">Front page CSS<a href="#front-page-css" title="Permlink for &quot;Front page CSS&quot;"></a></h2>
<p>Let’s study the difference in CSS coding:</p>

<a>

  <picture>
    <source srcset="https://nuejs.org/blog/tailwind-vs-semantic-css/img/css.jpg" media="(max-width: 768px)" type="image/jpeg"><source srcset="https://nuejs.org/blog/tailwind-vs-semantic-css/img/css-big.jpg" media="(min-width: 768px)" type="image/jpeg">
    
  </picture>

  <figcaption>Full CSS coding on the front page</figcaption>

  

</a>
<p>Blue is semantic CSS, gray is utility classes, and black-bordered is primary CSS (which makes your pages render faster).</p>
<p>Some key takes:</p>
<ol>
<li><p>Tailwind CSS is seven times larger: 33K vs 4.6K. Overall you need eight times more HTML/CSS code with Tailwind to render the page (108K vs 12.6K). The most surprising thing is that Tailwind uses more global/semantic CSS than the semantic approach itself <code>¯\_(ツ)_/¯</code></p>
</li>
<li><p>Most of the semantic CSS is re-usable on other pages and only a fraction of the CSS is specific to the front page. It’s easy to create new pages when the groundwork is already done.</p>
</li>
<li><p>“Spotlight” is just a <em>theme</em> extending a base design. There is an extremely minimalistic <a href="https://nuejs.org/@base/">base-version</a> of the website that can be used to create new themes, like our Spotlight theme.</p>
</li>
</ol>

<a>

  <picture>
    <source srcset="https://nuejs.org/blog/tailwind-vs-semantic-css/img/extending.png" media="(max-width: 768px)" type="image/png"><source srcset="https://nuejs.org/blog/tailwind-vs-semantic-css/img/extending-big.png" media="(min-width: 768px)" type="image/png">
    
  </picture>

  <figcaption>Creating a new design by extending a semantic base design</figcaption>

  

</a>
<p>Theming or “skinning” is a powerful concept in semantic CSS. You can alter your design by swapping parts of your CSS with another one or overriding a <a href="https://nuejs.org/@base/">base version</a>. CSS theming is impossible with Tailwind because the design is coupled to the markup. If you want a new design, you must edit your markup and override your earlier work.</p>
<h2 id="rendering-speed">Rendering speed<a href="#rendering-speed" title="Permlink for &quot;Rendering speed&quot;"></a></h2>
<p>The two metrics that measure page rendering speed are <a href="https://web.dev/articles/fcp">first contentful paint</a> (FCP) and <a href="https://web.dev/articles/lcp">largest contentful paint</a> (LCP). The semantic version is faster than in both metrics and in both mobile and PC. Here’s LCP on mobile for example:</p>

<a>

  <picture>
    <source srcset="https://nuejs.org/blog/tailwind-vs-semantic-css/img/lcp-mobile.png" media="(max-width: 768px)" type="image/png"><source srcset="https://nuejs.org/blog/tailwind-vs-semantic-css/img/lcp-mobile-big.png" media="(min-width: 768px)" type="image/png">
    
  </picture>

  <figcaption>Largest Contentful Paint (LCP) rendering speed on mobile</figcaption>

  

</a>
<p>Please compare <a href="https://pagespeed.web.dev/analysis/https-spotlight-tailwindui-com/cqtnf4xxoy?form_factor=mobile">Tailwind metrics</a> with <a href="https://pagespeed.web.dev/analysis/https-nuejs-org-spotlight/6nnhwwnz8b?form_factor=mobile">Semantic CSS metcis </a>.</p>
<p>Two reasons why the semantic version is faster:</p>
<ol>
<li><p>The primary CSS is <a href="https://imkev.dev/loading-css">inlined</a> on the HTML page so that all the assets for the first viewport are fetched in the initial request. This is probably the most important performance optimization for the perceived page loading experience.</p>
</li>
<li><p>The first request is <a href="https://endtimes.dev/why-your-website-should-be-under-14kb-in-size/">less than 14K</a>, which is the maximum size of the first TCP packet.</p>
</li>
</ol>
<p>The Preview tab on the Developer console is a great way to debug FCP:</p>

<a>

  <picture>
    <source srcset="https://nuejs.org/blog/tailwind-vs-semantic-css/img/first-paint.png" media="(max-width: 768px)" type="image/png"><source srcset="https://nuejs.org/blog/tailwind-vs-semantic-css/img/first-paint-big.png" media="(min-width: 768px)" type="image/png">
    
  </picture>

  <figcaption>Previewing the first paint on the developer console</figcaption>

  

</a>
<h2 id="best-practices">Best practices<a href="#best-practices" title="Permlink for &quot;Best practices&quot;"></a></h2>
<p>The key best practice of Tailwind is <strong>tight coupling</strong>. That is: the structure and styling are tied together. The semantic approach is the opposite: the structure and styling are loosely coupled**. Let’s see what that means by studying the gallery component on the front page:</p>

<a>

  <picture>
    <source srcset="https://nuejs.org/blog/tailwind-vs-semantic-css/img/coupling.png" media="(max-width: 768px)" type="image/png"><source srcset="https://nuejs.org/blog/tailwind-vs-semantic-css/img/coupling-big.png" media="(min-width: 768px)" type="image/png">
    
  </picture>

  <figcaption>Tight coupling vs Loose coupling</figcaption>

  

</a>
<p>The semantic version, allows you to change the design of the gallery freely. You name the component and style it externally. With Tailwind the style cannot be separated from the structure.</p>
<p>Here’s a better example. Let’s look at the “Uses” or “Setup” page on both implementations:</p>

<section>
<p>
<a href="https://spotlight.tailwindui.com/uses">

  <picture>
    <source srcset="https://nuejs.org/blog/tailwind-vs-semantic-css/img/tw-uses.png" media="(max-width: 768px)" type="image/png"><source srcset="https://nuejs.org/blog/tailwind-vs-semantic-css/img/tw-uses-big.png" media="(min-width: 768px)" type="image/png">
    
  </picture>

  <figcaption>Tailwind UI version →</figcaption>

  

</a>
</p>
<p>

<a href="https://nuejs.org/@spotlight/setup/">

  <picture>
    <source srcset="https://nuejs.org/blog/tailwind-vs-semantic-css/img/nue-uses.png" media="(max-width: 768px)" type="image/png"><source srcset="https://nuejs.org/blog/tailwind-vs-semantic-css/img/nue-uses-big.png" media="(min-width: 768px)" type="image/png">
    
  </picture>

  <figcaption>Semantic version →</figcaption>

  

</a>
</p>
</section>
<p>With Tailwind you must create a JavaScript component to construct a suitable HTML structure for the design. With the semantic version, we can use Markdown in place of the custom JSX component because the generated HTML is semantic and can be styled externally with CSS selectors:</p>

<a>

  <picture>
    <source srcset="https://nuejs.org/blog/tailwind-vs-semantic-css/img/content-first.png" media="(max-width: 768px)" type="image/png"><source srcset="https://nuejs.org/blog/tailwind-vs-semantic-css/img/content-first-big.png" media="(min-width: 768px)" type="image/png">
    
  </picture>

  <figcaption>Tight vs loose coupling from a different angle</figcaption>

  

</a>
<p>Loose coupling makes you think <strong>content first</strong>. There is no need to write a component for every situation because you can use external CSS to do the heavy lifting.</p>

<p><em>But …</em></p>
<h3 id="but-naming-things-is-unnecessary">But naming things is unnecessary<a href="#but-naming-things-is-unnecessary" title="Permlink for &quot;But naming things is unnecessary&quot;"></a></h3>
<p>Naming things is a skill. You name things that repeat. Think of function names in JavaScript or component names in Figma. The same goes for CSS class names. Be good at naming, and you can move from repeating things to re-using things. That is: you can move from this:</p>
<pre><code><b>&lt;!-- utility- first css --&gt;</b>
<b>&lt;</b><b>button </b><b>className</b><b>=</b><b>"</b>group mb<b>-</b><b>8</b> flex h<b>-</b><b>10</b> w<b>-</b><b>10</b>
  items<b>-</b>center justify<b>-</b>center rounded<b>-</b>full
  bg<b>-</b>white shadow<b>-</b>md shadow<b>-</b>zinc<b>-</b><b>800</b><b>/</b><b>5</b> ring<b>-</b><b>1</b>
  ring<b>-</b>zinc<b>-</b><b>900</b><b>/</b><b>5</b> transition <b>dark</b><b>:</b>border
  <b>dark</b><b>:</b>border<b>-</b>zinc<b>-</b><b>700</b><b>/</b><b>50</b> <b>dark</b><b>:</b>bg<b>-</b>zinc<b>-</b><b>800</b>
  <b>dark</b><b>:</b>ring<b>-</b><b>0</b> <b>dark</b><b>:</b>ring<b>-</b>white<b>/</b><b>10</b>
  <b>dark</b><b>:</b><b>hover</b><b>:</b>border<b>-</b>zinc<b>-</b><b>700</b>
  <b>dark</b><b>:</b><b>hover</b><b>:</b>ring<b>-</b>white<b>/</b><b>20</b>
  <b>lg</b><b>:</b>absolute <b>lg</b><b>:</b><b>-</b>left<b>-</b><b>5</b>
  <b>lg</b><b>:</b>mb<b>-</b><b>0</b> <b>lg</b><b>:</b><b>-</b>mt<b>-</b><b>2</b>
  <b>xl</b><b>:</b><b>-</b>top<b>-</b><b>1.5</b>
  <b>xl</b><b>:</b>left<b>-</b><b>0</b>
  <b>xl</b><b>:</b>mt<b>-</b><b>0</b><b>"</b><b>&gt;</b>
</code></pre>
<p>To this</p>
<pre><code><b>&lt;!-- semantic css --&gt;</b>
<b>&lt;</b><b>button </b><b>class</b><b>=</b><b>"secondary"</b><b>&gt;</b>
</code></pre>
<p>Without turning into components.</p>
<h3 id="but-co-location-is-important">But co-location is important?<a href="#but-co-location-is-important" title="Permlink for &quot;But co-location is important?&quot;"></a></h3>
<p>Co-location is a catchy name for tight coupling. A term to promote the idea that styling should be tied to the presentation. Repeating things vs. re-using things. See above.</p>
<h3 id="but-tailwind-is-a-great-design-system">But Tailwind is a great design system<a href="#but-tailwind-is-a-great-design-system" title="Permlink for &quot;But Tailwind is a great design system&quot;"></a></h3>
<p>Tailwind has great defaults for colors, spacing, and responsive design. That part is roughly 3% of your Tailwind CSS file. It’s easy to copy these defaults to your semantic design system if needed.</p>
<h3 id="but-i-move-faster-with-tailwind">But I move faster with Tailwind<a href="#but-i-move-faster-with-tailwind" title="Permlink for &quot;But I move faster with Tailwind&quot;"></a></h3>
<p>Yes. You can move faster with Tailwind. But only when:</p>
<ol>
<li><p>You are comparing Tailwind with your earlier, badly structured CSS or you are completely new to CSS development.</p>
</li>
<li><p>You don’t care about building reusable modules for later use. That is: you are not naming things that repeat.</p>
</li>
</ol>
<p>If you really want to move faster, you’ll create a set of CSS components that you can reuse. Like <code>&lt;button class="secondary"&gt;</code>.</p>
<h3 id="but-why-is-tailwind-so-popular-then">But why is Tailwind so popular then?<a href="#but-why-is-tailwind-so-popular-then" title="Permlink for &quot;But why is Tailwind so popular then?&quot;"></a></h3>
<p>Because mastering CSS requires practice. It takes several failed attempts before you get it. Most developers haven’t gone through that so they only remember the bad things. They have never built or used well-structured CSS.</p>
<p>But when you truly master CSS, there is no turning back.</p>
<p>Tailwind, however, forces you to write divs inside divs and fill your elements with an insane amount of class names. I guess that Tailwind’s popularity will eventually fade and the codebases will turn to technical debt. It’s just a matter of time.</p>
<h3 id="where-is-the-source-code">Where is the source code?<a href="#where-is-the-source-code" title="Permlink for &quot;Where is the source code?&quot;"></a></h3>
<p>I’m working on it! I wanted to push out this blog entry quickly without the overhead of making this an open-source project. My next task is to work on the <a href="https://github.com/nuejs/create-nue">Nue starter kit</a> so that it generates a personal blog. I’ll also write a blog entry called “Next.js vs Nue”. It tackles the bigger picture and shows what’s wrong with the current front-end ecosystem. You can join the mailing list, and I’ll notify you when it’s ready:</p>

<nue-island island="join-list">
</nue-island>
<p>I’d appreciate your thoughts. I’d like to understand what people think of all this. You can also participate in the <a href="https://news.ycombinator.com/item?id=37982407">discussion at Hacker News</a>.</p>

</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cooler Screens (315 pts)]]></title>
            <link>https://computer.rip/2023-10-22-cooler-screens.html</link>
            <guid>37982149</guid>
            <pubDate>Mon, 23 Oct 2023 06:11:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://computer.rip/2023-10-22-cooler-screens.html">https://computer.rip/2023-10-22-cooler-screens.html</a>, See on <a href="https://news.ycombinator.com/item?id=37982149">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>


<p>Audible even over the squeal of an HVAC blower with a suffering belt, the whine
of small, high velocity fans pervades the grocery side of this Walgreens. Were
they always this loud? I'm not sure; some of the fans sound distinctly
unhealthy. Still, it's a familiar kind of noise to anyone who regularly works
around kilowatt quantities of commercial IT equipment. Usually, though, it's a
racket set aside for equipment rooms and IDF closets---not the refrigerator
aisle.</p>
<p>The cooler screens came quickly and quietly. Walgreens didn't seem interested
in promoting them. There was no in-store signage, no press announcements that I
heard of. But they were apparently committed. I think I first encountered them
in Santa Fe, and I laughed at this comical, ridiculous-on-its-face "innovation"
in retailing, falsely confident that it would not cross the desert to
Albuquerque's lower income levels. "What a ridiculous idea," I said, walking up
to a blank cooler. The screens turn on in response to proximity, showing you an
image of what is (supposedly) inside of the cooler, but not quickly enough that
you get annoyed with not being able to just see inside.</p>
<p>I would later find that these were the good days, the first phase of the Cooler
Screen's invasion, when they were both limited in number and merely mediocre.
Things would become much worse. Today, the Cooler Screens have expanded their
territory and tightened their grip. The coolers of Walgreens have gone dark,
the opaque, black doors some sort of Kubrickian monolith channeling our basic
primate understanding of Arizona Iced Tea. Like the monolith, they are faceless
representatives of a power beyond our own, here to shape our actions, but not
to explain themselves.</p>
<p>Like the monolith, they are always accompanied by an eery sort of screeching.</p>
<p>Despite my leftist tendencies I am hesitant to refer to "late-stage
capitalism." To attribute our modern situation to such a "late stage" is to
suggest that capitalism is in its death throes, that Marx's contradiction has
indeed heightened and that some popular revolution is sure to follow. What is
to say that things can't get worse? To wave away WeWork as an artifact of
"late-stage capitalism" is an escape to unfounded optimism, to a version of
reality in which things will not spiral further downward.</p>
<p>Still, I find myself looking at a Walgreens cooler that just two years ago was
covered in clear glass, admitting direct inspection of which tall-boy teas were
in stock. Today, it's an impenetrable black void. Some Walgreens employee has
printed a sheet of paper, "TEA" in 96-point Cambria, and taped it to the wall
above the door. Taking in this spectacle, of a multi-million dollar effort that
took our coolers and made them more difficult to use, of a retail employee's
haphazard effort to mitigate the hostility of their employer's merchandising,
it is hard not to indulge in that escape. Surely, things can't get much worse.
<em>Surely, these must be the latter days.</em></p>
<hr>
<p>Gregory Wasson is the sort of All-American success story that you expect from a
neighborhood brand like Walgreens Also Known As Duane Reade In New York City.
Born in 1958, he honed his business sense working the family campground near
Delphi, Indiana. A first-generation college student, he aimed for a sensible
profession, studying pharmacy at Purdue. Straight out of college, he scored a
job as a pharmacy intern at a Walgreens in Houston.</p>
<p>Thirty years later, he was CEO.</p>
<p>A 2012 Chicago Tribune profile of Wasson ends with a few quick notes. One,
"Loves: The desert," could easily go on a profile of myself. Another, "Hobbies:
Visiting Walgreens across the country," is uncomfortably close as well. It's
not that I have any particular affection for Walgreens, in fact, I've long
thought it to very poorly managed, but for reasons unclear to me I cannot
seriously consider entering a CVS. I don't know what they get up to, over there
under the other red drug store sign. I hear it has something to do with long
receipts. I don't want to find out.</p>
<p>I suppose some of Wasson's sensible, farm-and-country upbringing resonates with
me as a consumer. It also makes it all the more surprising that he would become
one of the principle agents behind Walgreen's most publicly embarrassing misstep
to date. There must have been some sort of untoward influence, corruption by
exposure to a Bad Element. Somehow, computers got to him.</p>
<p>Arsen Avakian came from Armenia as a Fulbright scholar. With a background the
most capitalistic corners of technology (software outsourcing and management
consulting), he turned to the food industry and worked in supply chain
management systems for years before deciding to strike out on his own.
Steering sensibly away from technology, he chose tea. Argo Tea started out as a
chain of cafes based in Chicago, but by 2020 had largely shifted focus to a
"ready-to-drink premium tea line derived from one of its most popular café
beverages." This meant bottled tea, sold prominently in Walgreens.</p>
<p>It seems to be this Walgreens connection that brought Wasson and Avakian
together. Wasson retired from Walgreens in 2014, and joined with Avakian and
two other tech-adjacent executives to disrupt the cooler door.</p>
<p>Several publications have investigated the origin of Cooler Screens, taking the
unquestioningly positive view typical of business reporters that do not bother
to actually look into the product. Avakian, researching the branding and
presentation of his packaged premium teas, was dismayed at the appearance of
retail beverage sections. "Where is the innovation?," he is often quoted as
saying, apparently in reference to the glass doors that have long allowed
shoppers to see the products that they might decide to buy.</p>
<p>Avakian reportedly observed that people in store aisles would frequently look
at their phones. I have a theory to explain this behavior; it has more to do
with text messages and Tik Tok and a million other things that distract people
milling around in a Walgreens to kill time (who among us hasn't taken up a
fifteen minute gap by surveying a Walgreens? Fifteen minutes, perhaps, of
waiting for the pharmacy in that very Walgreens to fill a prescription?). To
Avakian's eyes, this was apparently a problem to be solved. People distracted
from the tea are not, he seems to think, purchasing enough tea. The tea needs
to fight back: "How do we make the cooler door a more engaging experience?,"
Cooler Screens CRO Lindell Bennett said in an interview with a consulting firm
called Tinuiti that proclaims in their hero banner that "the funnel has
collapsed."</p>
<p>Engagement is something like the cocaine of the computer industry. Perhaps in
the future we will look back on it as the folly of quack practitioners, a
cure-all for monetization as ill advised as the patent medicines of the 19th
century. At the moment, though, we're still in the honeymoon phase. We are
cramming engagement into <em>everything</em> to see where it sticks. It is fitting,
then, that our cooler screens now obscure the inventory of Coca-Cola. It's
crazy what they'll put into things, claiming it a cure for lethargy (of body or
of sales). Coca into cola. Screens into coolers.</p>
<hr>
<p>It's a little hard to tell what the cooler screens do. It comes down to the
typical struggle of interpreting VC-fueled startups. <em>Built In Chicago</em>
explains that "The company's digital sensors also help brands collect data on
how consumers interact with their items." This is the kind of claim that makes
me suspicious on two fronts: First, it probably strategically simplifies the
nature of the data collected in order to understate the privacy implications.
Second, it probably strategically simplifies how that data will be used in
order to overstate its commercial value.</p>
<p>The simplest part of the cooler screen play is their use as an advertising
medium. There seems to be a popular turn of phrase in the retail industry right
now, that the store is a canvas. Cooler Screens' CRO, in the same interview,
describes the devices as "a six-foot canvas with a 4K resolution where brands
can share their message with a captive audience." I'm not sure that we're
really <em>captive</em> in Walgreens, although the constant need to track down a
Walgreens correction officer to unlock the cell in which they have placed the
hand lotion does create that vibe.</p>
<p>Cooler Screens launched with a slate of advertising partners, basically who you
would expect. Nestlé, MillerCoors, and Conagra headlined. The Wall Street
Journal, referring to a MillerCoors statement, reported that "a big barrier for
MillerCoors is that half of shoppers aren't aware beer is available in
drugstores." I find this a little surprising since it is plainly visible next
to the other beverages, but, well, these days it isn't any more, so I'm sure
there's still a consumer awareness gap to be closed.</p>
<p>The idea of replacing cooler doors with a big television so that you can show
advertising is exactly the kind of thing I would expect to take off in today's
climate, but doesn't yet have that overpromising energy of AdTech or, I am
learning, BevTech. The Cooler Screens are equipped with front-facing sensors,
but no cameras facing the outside world. Cooler Screens seems appropriately
wary of anything that could attract privacy attention, and refers to its
product as "identity-blind." This, of course, makes it a little confusing that
they also refer to targeted advertising and even retargeting as consumers
approach the cooler.</p>
<p>To resolve this apparent contradiction, Cooler Screens describes its approach
as "contextual advertising." They target based not on information about the
customer, but on information about the context. The CRO offers an example:</p>
<blockquote>
<p>When you think about it within the context of "I'm in front of an ice cream
door and I want to buy," you have the ability to isolate the message to exactly
what a consumer is focused on at this point in time based on the distance that
they are from the door.</p>
</blockquote>
<p>Age-old advertising technology would use the context that you are in front of
the ice cream door as a trigger to display the ice cream through the door.  In
the era of the Cooler Screen, though, the ice cream itself is hidden safely out
of view while the screen contacts a cloud service to obtain an advertisement
that is contextually related to it.</p>
<p>It should be clear by this point that the Cooler Screens as an advertising
medium don't really have anything to do with how the items behind them are
perceived by consumers. They have to do with how the advertising space is sold.
Historically, brands looking to achieve prominence in a retail environment have
done so through the set of practices known as "merchandising." Business
agreements between brands and retailers often negotiate the physical shelf
space that stores will devote to the brand's products, and brands throw in
further incentives for retailers to use brand-provided displays and move
products to more lucrative positions in the store. As part of the traditionally
multi-layered structure of the retail industry, the merchandising of beverage
products especially is often managed by the distributor instead of the
retailer. This is one way that brands jockey for more display space: the
retailer is more likely to take the deal if their staff don't have to do the
work.</p>
<p>With Cooler Screens, though, the world of AdTech can entirely disrupt this tie
between placing products and placing advertising. Regardless of what is behind
the door, regardless of what products the store actually chooses to stock,
regardless of the business incentives of the beverage distributor that actually
puts things into the coolers, the coolers will display whatever ads they are
paid for. Are the cooler screens controlled by a real-time auction system, like
many online advertisements? I haven't been able to tell for sure, although
several uses of phrases like "online-like advertising marketplace" make me
think it is at least the goal.</p>
<p>The first, and I suspect primary, purpose of the Cooler Screens is therefore
one of disintermediation and disconnection. By putting a screen in front of the
actual shelves, store display space can function as an advertising market
completely disconnected from the actual stocked products. It's sort of like the
3D online stores that occupied the time of VR entrepreneurs before Mark
Zuckerburg brought us his Metaverse. The actual products in the store aren't
the important thing; the money is in the advertising space.</p>
<p>Second, the Cooler Screens <em>do</em> have cameras on the inside. With these, they
promise to offer value to the distributor. Using internal cameras they can
count inventory of the cooler, providing real-time stock level data and
intriguing information on consumer preference. Cooler Screens promises to tell
you not only which products are out of stock, but also which products a
consumer considers before making their purchase. Reading between the lines here
I assume this means the rear-facing cameras are used not only to take inventory
but also to perform behavioral analysis of individuals who open the doors; the
details here are (probably intentionally) fuzzy.</p>
<p>The idea of reporting real-time inventory data back to distributors is a solid
one, and something that retail technology has pursued for years with ceiling
mounted cameras, robots, and other approaches that always boil down to machine
vision. Whether or not it works is hard to say, the arrival of the Cooler
Screens seems to have coincided with a rapid decline in the actual availability
of cold beverages, but presumably that has more to do with the onset of COVID
and the related national logistical crisis rather than the screens themselves.
The screens are, at least anecdotally, frequently wrong in their front-facing
display of what is and isn't in stock. Generally they present the situation as
being much better than it actually is. That this provides a degree of cover for
Walgreens faltering ability to keep Gatorade in stock is probably a convenient
coincidence.</p>
<hr>
<p>Cooler Screens was born of Walgreens, and seems to have benefited from
familial affection. Placement of Cooler Screens in Walgreens stores started in
2018, the beginning of a multi-year program to install Cooler Screens in 2,500
stores. This would apparently come at an expense of $200 million covered by
Cooler Screens themselves. Cooler Screens was backed by venture funding,
including an $80 million round lead by Verizon and Microsoft. Walgreens
discussed Cooler Screens as part of their digital strategy, and Cooler Screens
used Walgreens as a showcase customer. The Cooler Screens family was not a
happy one, though.</p>
<p>The initial round of installations in 2018 reached 10,300 screens in 700
stores. Following this experience, Walgreens seemed to develop cold feet, with
the pace of installation slowing along with Walgreens broader participation in
the overall joint venture. Walgreens complained of "freezing screens, incorrect
product displays, failure to update stock data accurately, and safety concerns
such as screens sparking and catching fire, according to Walgreens."</p>
<p>In statements to the press, Cooler Screens referred to mention of frozen and
incorrect displays as "false accusations." I can only take that as anything
other than an outright lie if I allow myself to believe that the leadership and
legal counsel of Cooler Screens have never actually seen their product in use.
Given the general tenor of the AdTech industry, that might be true.</p>
<p>If it has not become clear by this point, the poor performance and reliability
of the Cooler Screens is not only a contention by Walgreens but also a firm
belief of probably every Walgreens customer with the misfortune of coming
across them. In an informal survey of four Albuquerque-area Walgreens that I
occasionally use, more than half of the screens are now dark. It varies by
location; in one store, there are two not working. In another, there are two
<em>working.</em> The cooler screens that still cling to life are noticeably infirm.
As best I can remember, animations and video have never played back smoothly,
with over a second sometimes passing between frames.</p>
<p>The screens are supposed to show full-size ads (increasingly rare) or turn off
(now the norm) when idle, and then as a customer approaches they are supposed
to turn on and display a graphical representation of the products in the cooler
that is similar to---but much worse than---what you would see if the cooler
door was simply transparent. Since they were first installed this automatic
transition has been a rocky one. Far from the smooth process shown in Cooler
Screens demo videos, the real item as installed here in the desert (which look
worse than the ones in the demo videos to begin with) noticeably struggle to
update on cue. As you approach they either fail to notice at all or seem to
lock up entirely for a few seconds, animations freezing, as they struggle to
retrieve the images of stock they should display. What then appears is, more
often than not, wrong.</p>
<p>Early on in the Cooler Screens experiment they were wrong in more subtle ways.
They would display one product as out of stock when it was, in fact, physically
present just behind the door. They would display three other products as in
stock when there were none to be found. That was the peak performance the
rear-camera-based intelligence would achieve. Today, it seems like the screens'
basic information on cooler layout is no longer being maintained. They display
the wrong products in the wrong places, sometimes even an entirely wrong
category of products.</p>
<p>It's perhaps hard to understand how they work so poorly, unless you have seen
any of the other innovations that the confluence of AdTech and digital signage
have brought us. There seems to be some widespread problem where designers of
digital advertising products completely forget about basic principles of
mechanical reliability.</p>
<p>It is ironic, given the name and purpose of the cooler screens, that they are
not at all cool. In fact they run very warm, hot to the touch. I cannot be
entirely sure of my own senses but in a recent trip to a Walgreens I swear that
I could feel the heat radiating from the Cooler Screens as I approached the
section, like an evening walk approaching a masonry wall still warm from the
day's sun. As a practical matter they are mounted to the outside of standard
glass cooler doors. Yes, it is deeply ironic that behind the cooler screens are
normal glass doors through which their cameras are allowed to see the contents
the way that customers are not, but at least the door provides some insulation.
Still, somewhere between the cooler refrigeration and the store air
conditioning, the excess thermal output of the new cooler doors is being
removed at Walgreens' expense.</p>
<p>I was a bit baffled at how hot they ran (and how loud the cooling fans can be)
until I considered the impressive brightness of the displays. Cooler Screens
does refer to them as vivid and engaging, and they must have thought that they
needed to compete with store lighting to catch attention. They are bright,
almost uncomfortably so when you are close up, and the wattage of the
backlighting (and attendant heat dissipated) must be considerable. Based on
some experience I have with small SoCs in warm environments, I suspect they
have a thermal problem. The whole system probably worked fine on a bench, but
once manufactured and mounted with one face against an insulated cooler door,
heat accumulates to the point that the SoC goes into thermal throttling and
gives up on real-time playback of 4K video. The punishing temperature of the
display and computer equipment leads to premature failure, and the screens go
dark.</p>
<p>At a level of personal observation, the manufacturing quality of the screens
also seems poor. The fit and finish is lacking, the design much less refined
than the ones Cooler Screens displays in its own marketing material. The
problems may be more than skin-deep, based on Walgreens reports of electrical
problems leading to fire in more than one case. Cooler Screens contends that
these cases were the result of failures on Walgreens part; it can be hard to
tell who to blame in these situations anyway. But design and software problems
must be the fault of Cooler Screens and, besides, Walgreens doesn't even like
them.</p>
<hr>
<p>Walgreens pulled the plug, or at least tried, early this year. In February,
Walgreens terminated the business partnership with Cooler Screens. Only one
third of the planned displays had been installed: Walgreens had started to back
out years earlier. In 2021, Roz Brewer took over as CEO of Walgreens.
According to reporting, she "did not like how the screens looked" and "wanted
them out of the stores." According to Cooler Screens themselves, Brewer
described them as "'Vegas' in a derogatory way."</p>
<p>I am skeptical of corporations in general and especially of their executives,
and I have a natural aversion to the kind of hero worship that brings people to
refer to CEOs as "visionary." Still, how validating it is to find someone,
anyone, in corporate leadership who sees what I see. Cooler Screens alleges
that "when she realized that her opinion on how the doors looked was not enough
to get out of the contract... she and her team began to fabricate excuses." As
would I! They are so evidently terrible, I would be fabricating excuses in the
sense that one gets out of a bad date. "I am sorry about not installing the
Cooler Screens on schedule but I have plans tomorrow with someone else who is
not you." Perhaps I can install cooler screens in 500 more stores some other
time? "Sure, call me, we'll work something out," I say, scrawling 505-FUCK-OFF
on an old receipt.</p>
<p>Still, one does not typically start off a first date with a multi-year
agreement in which one party commits $200 million in exchange for future
revenue. Cooler Screens sued Walgreens, arguing that Walgreens has failed to
perform on their 2018 contract by not installing additional screens. They're
asking for an injunction to prohibit Walgreens removing of the currently
installed units. Walgreens is contending that Cooler Screens failed to perform
by installing screens that broke and occasionally caught fire, Cooler Screens
retorts that the screens would have worked fine if Walgreens stores were in
better condition.</p>
<p>The consumer, as always, is caught in the crossfire. As Cooler Screens continue
to fail it seems unlikely that they will be repaired or replaced. As the
lawsuit is ongoing, it seems unlikely that they will be removed. We just open
every door and look behind it, thinking fondly of a bygone era when the cooler
doors were clear and you could see through them. Now they are heavy and loud
and uncomfortably warm. In the best case, we get to see a few scattered frames
of a Coca Cola animation before they manage to present an almost shelf-like
view of products that may or may not be in the cooler behind them.</p>
<p>Hope springs eternal. Earlier this year, Kroger announced the installation of
Cooler Screens in 500 more of their stores, the result of a three-year pilot
that apparently went better than Walgreens. They have claimed Walgreens as
their territory, leaving destruction in their wake. They are advancing into the
Smith's next.</p>
<hr>
<p>One of the strangest parts of Cooler Screens, to me, is Cooler Screens
insistence that consumers like them. I have never personally seen someone react
to Cooler Screens with anything other than hostility. Everyday shoppers make
rude remarks about the screens, speaking even in somewhat elevated tones,
perhaps to be heard over the fans. Employees look sheepish. Everyone is in
agreement that this is a bad situation.</p>
<p>"The retail experience consumers want and deserve," Cooler Screens says on
their website. I would admire this turn of phrase if it was intended as a
contemptful one. Cooler Screens promise to bring the experience of shopping
online, "ease, relevance, and transparency." "Transparency" seems like a poor
choice of language when promoting a product that infamously compares poorly to
the transparent door it replaces. Relevance, too, is a bold claim given the
unreliability of their inventory information. I suppose I don't have anything
particularly mean to say about ease, although I have seen at least one elderly
person struggle to open the heavy screens.</p>
<p>Still, "90%+ of consumers no longer prefer traditional glass cooler doors."
What an intriguing claim! 90%+? How many plus? No longer prefer traditional
glass? What exactly does that even mean?</p>
<p>Indeed, Cooler Screens presents a set of impressive numbers based on their
market research. 94% of respondents say the screens impacted their shopping
positively or neutrally (and the breakdown of positive/neutral in the graphic
shows that this isn't even relying on a huge amount of neutral response, a good
majority really did say positively). 82% said they found the content on the
screens memorable. I certainly do find them memorable, but perhaps not how
Cooler Screens intends.</p>
<p>I struggle to reconcile these performance numbers with the reality I have
observed. Perhaps Albuquerque is a horrible backwater of Cooler Screens
outcomes; I have not thoroughly inspected many out-of-town Walgreens. Maybe
there exists, somewhere back East, a sort of Walgreens paradise where the
screens are all in working order and actually look good and people like them.
Or perhaps the surveys backing this data were only ever collected in the first
two days following installation at Walgreens locations adjacent to dispensaries
holding free pre-roll promotions. I don't know, because Cooler Screens shares no
information on the methodology used to collect these metrics.</p>
<p>What I can tell you is this: customer experience data collected by Cooler Screens
seems to reflect some world other than the one in which I exist.</p>
<p>I wish I lived there, the Walgreens must be exceptionally well-stocked. Out
here, I am hoping the staff have fabricated crude signs so that I don't have to
manually open every door. I am starting to memorize Walgreens shelf plans as an
adaptation. I am nodding and appropriately chuckling when a stranger says
"remember when you could see through these?" as they fight against retail
innovation to purchase one of the products these things were supposed to
promote. You cannot say they aren't engaged, in a sense.</p>
	</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building a unikernel that runs WebAssembly – part 1 (229 pts)]]></title>
            <link>https://flavio.castelli.me/2023/02/07/building-a-unikernel-that-runs-webassembly---part-1/</link>
            <guid>37982137</guid>
            <pubDate>Mon, 23 Oct 2023 06:08:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://flavio.castelli.me/2023/02/07/building-a-unikernel-that-runs-webassembly---part-1/">https://flavio.castelli.me/2023/02/07/building-a-unikernel-that-runs-webassembly---part-1/</a>, See on <a href="https://news.ycombinator.com/item?id=37982137">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
          
          
          

<p><a href="https://hackweek.opensuse.org/">Hackweek 22</a> took place last week. During
this week all the SUSE employees are free to hack on whatever they want. This one of
the perks of working at SUSE 😎.</p>

<p>This time my personal project has been about
<a href="https://hackweek.opensuse.org/22/projects/build-a-unikernel-that-runs-webassembly">building a unikernel that runs WebAssembly</a>.</p>

<blockquote>
<p>I wanted this blog post to contain all the details about this journey. However
I realized this would have been too much for a single post. I hence decided to
split everything into smaller chunks.
I’ll update this section to keep track of all the posts.</p>

<p>In the meantime, you can find the code of the POC <a href="https://github.com/flavio/hermit-wasm">here</a>.</p>
</blockquote>

<h2 id="why">Why</h2>

<p>There are multiple reasons why I did that, but I don’t want to repeat what I
wrote inside of the <a href="https://hackweek.opensuse.org/22/projects/build-a-unikernel-that-runs-webassembly">project description</a>.
Learning and fun goals aside, I think there’s actually a good reason to mix
unikernels and WebAssembly.</p>

<p>From the application developer POV, porting/writing an application to the
unikernel is not an easy task. The application and all its dependencies
have to support the target unikernel. Some patching might be required inside
of the whole application stack to make it work.</p>

<p>From the unikernel maintainers POV, they have to invest quite some energies
to ensure any kind of application can run in a seamless way on top of their
platform. They don’t know which kind of system primitives the user applications
will leverage, this makes everything harder.</p>

<p>On the other hand, when targeting a WebAssembly platform (think of
<a href="https://github.com/fermyon/spin">Spin</a>
or <a href="https://github.com/deislabs/spiderlightning">Spiderlightning</a>), the
application has a clear set of capabilities that have to be provided by
the WebAssembly runtime.</p>

<p>If you look at the Spiderlightning scenario, an application might be requiring
Key/Value store capabilities at runtime. However, how these capabilities are
implemented on the host side is not relevant to the application. That means
the same <code>.wasm</code> module can be run by a runtime that implements the K/V store
using Redis or using <a href="https://azure.microsoft.com/en-us/products/cosmos-db/">Azure Cosmos DB</a>.
That would be totally transparent to the end user application.</p>

<p>You might see where I’m going with all that…</p>

<p>If we write a unikernel application that runs WebAssembly modules and supports a
set of Spiderlightning APIs, then the same Spiderlightning application could be
run both on top of the regular <code>slight</code> runtime and of this unikernel.</p>

<p>All of that without any additional work from the application developer. The Wasm
module wouldn’t even realize that.
The complexity would fall only on the unikernel developer who, whoever, would
have a clear set of functionalities to implement (as opposed to “let’s try to
make any kind of application work”).</p>

<h2 id="how">How</h2>

<p>Sometimes ago I stumbled over the <a href="https://github.com/hermitcore/rusty-hermit">RustyHermit</a>
project, this is a unikernel written in Rust.
I decided to use it as the foundation to write my unikernel application.</p>

<p>Building a RustyHermit application is pretty straightforward. Their documentation,
even though is a bit scattered, is good and their examples help a lot.</p>

<p>The cool thing is that RustyHermit is part of Rust nightly, which makes the whole
developer experience great. It feels like writing a regular Rust application.</p>

<p>Obviously you cannot expect all kind of Rust crates to just work with RustyHermit.
You will see how that influenced the development of the POC.</p>

<p>The next sections go over some of the major challenges I faced during the last week.
I’ll share more details inside of the upcoming blog posts (see the disclaimer
section at the top of the page).</p>

<h3 id="the-webassembly-runtime">The WebAssembly runtime</h3>

<p>Unfortunately <a href="https://wasmtime.dev/">Wasmtime</a>, my favorite WebAssembly runtime,
does not build on top of RustyHermit. Many of its dependencies expect <code>libc</code>
or other low level libraries to be around.
The same applies to <a href="https://github.com/wasmerio/wasmer">wasmer</a>.</p>

<p>I thought about using something like <a href="https://github.com/bytecodealliance/wasm-micro-runtime">WebAssembly Micro Runtime (WAMR)</a>,
but I preferred to stick with something written in Rust and have the
“full RustyHermit experience”.</p>

<p>After some searching I found <a href="https://crates.io/crates/wasmi">wasmi</a> a pure Rust
WebAssembly runtime. This works fine on top of RustyHermit, plus its design
is inspired by the one of Wasmtime, which allowed me to reuse a lot of my previous
knowledge.</p>

<h3 id="webassembly-component-model">WebAssembly Component Model</h3>

<p>Spiderlightning leverages the <a href="https://github.com/webassembly/component-model">WebAssembly Component Model</a>
proposal to offer capabilities to the WebAssembly guests and
to allow the host to consume capabilities offered by the WebAssembly guest.</p>

<p>The communication between the host and the guest happens using types defined
with the <a href="https://github.com/WebAssembly/component-model/blob/main/design/mvp/WIT.md">Wasm Interface Type</a>.</p>

<p>To give some concrete examples, the demo I’m going to run leverages the
WebAssembly Component Model in these ways:</p>

<ul>
<li>The guest asks the host to start a HTTP server. When doing that, the guest
informs the host about the HTTP routes that have to be registered, plus
the names of its internal handlers (the functions that have to be executed).
This is done by using the <a href="https://github.com/deislabs/spiderlightning/blob/main/wit/http-server.wit"><code>http-server</code></a>
types. In this case it’s the guest that leverages capabilities offered by the
host.</li>
<li>The host handles the incoming HTTP requests using the routing
information provided by the guest. The http handlers mentioned before are
functions exposes by the WebAssembly guest. The server is now consuming
capabilities offered by the guest. The communication is done using the
<a href="https://github.com/deislabs/spiderlightning/blob/main/wit/http-handler.wit"><code>http-handler</code></a>
types.</li>
<li>Some of the http handlers defined by the guest are also interacting with
a Key/Value store. Also in this case the guest is leveraging a set of
capabilities offered by the host. These are defined using the
<a href="https://github.com/deislabs/spiderlightning/blob/main/wit/keyvalue.wit"><code>keyvalue</code></a>
types.</li>
</ul>

<p>As you can see there are many WIT types involved. For each one of them we
need code both inside of the guest (a SDK basically) and on the host (the
code that implements the guest SDK).
This code can be scaffolded by a cli tool called <a href="https://github.com/bytecodealliance/wit-bindgen"><code>wit-bindgen</code></a>,
which generates host/guest code starting from a <code>.wit</code> file.</p>

<p>In this case I only had to implement the host side of these interfaces inside
of the unikernel.</p>

<p>The code generated by <code>wit-bindgen</code> is doing low level operations using the
WebAssembly runtime. The code to be scaffolded depends on the programming language
and on the WebAssembly runtime used on the host side.</p>

<p>Obviously the <code>wasmi</code> WebAssembly runtime was not supported by <code>wit-bindgen</code>,
hence I had to extend <code>wit-bindgen</code> to handle it. The code can be found inside of
<a href="https://github.com/flavio/wit-bindgen/tree/wasmi">this fork</a>, under the <code>wasmi</code>
branch.</p>

<p>With all of that in place, I scaffolded the host side of the Key/Value capability
and I made a simple implementation of the host traits. The host code was just
emitting some debug information.
I was then able run the vanilla <a href="https://github.com/deislabs/spiderlightning/tree/main/examples/keyvalue-demo">keyvalue-demo</a>
from the Spiderlightning project. 🥳</p>

<h2 id="summary">Summary</h2>

<p>You made to the bottom of this long post, kudos! I think you deserve a prize for
that, so here we go…</p>

<p>This is a recording of the unikernel application running the Spiderlightning http-server
demo.</p>

<p><img src="https://flavio.castelli.me/images/unikernel-webassembly/demo.gif" alt="A screencast of the unikernel application running the Spiderlightning http-server demo" title="It's alive!"></p>

<p>I hope you enjoyed the reading.
Stay tuned for the next part of the journey. This will cover Rust async, Redis
and some weird errors.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Excel will allow certain auto data conversions to be turned off (196 pts)]]></title>
            <link>https://insider.microsoft365.com/en-us/blog/control-data-conversions-in-excel-for-windows-and-mac</link>
            <guid>37982049</guid>
            <pubDate>Mon, 23 Oct 2023 05:51:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://insider.microsoft365.com/en-us/blog/control-data-conversions-in-excel-for-windows-and-mac">https://insider.microsoft365.com/en-us/blog/control-data-conversions-in-excel-for-windows-and-mac</a>, See on <a href="https://news.ycombinator.com/item?id=37982049">Hacker News</a></p>
<div id="readability-page-1" class="page"><div _ngcontent-sc9="" id="content"><p>Hi, Microsoft 365 Insiders! My name is Chirag Fifadra, and I’m a Product Manager on the Excel team. I’m thrilled to announce that, based on your feedback, we’ve improved the Automatic Data Conversion settings we made available last year, and are now making them broadly available in both Excel for Windows and Excel for Mac.</p>
<h3>What did we change?</h3>
<p>Last year’s&nbsp;<a href="https://insider.microsoft365.com/en-us/blog/control-data-conversions-in-excel">blog post</a>&nbsp;explains how the initial version of the feature worked. Based on your feedback, we have:</p>
<ul>
	<li>made the feature easier to find</li>
	<li>added more format support</li>
	<li>made the feature available in Excel for Mac</li>
</ul>
<h3>How it works</h3>
<p>We wanted to address customers’ frustration with Excel automatically converting data to specific formats. So, we have now given you the ability to change Excel’s default behavior and disable specific types of automatic data conversions as needed.</p>
<p>To do so, select&nbsp;<strong>File &gt; Options &gt; Data &gt; Automatic Data Conversion</strong>, and then choose the conversion(s) that you’d like to disable.</p>
<p><img loading="lazy" src="https://office-insider-media.azurefd.net/media/2023/10/XL-Conversion-Win-and-Mac_2.png" alt="Excel Options dialog box with Automatic Data Conversion section selected" width="805" height="640" srcset="https://office-insider-media.azurefd.net/media/2023/10/XL-Conversion-Win-and-Mac_2.png 1613w, https://office-insider-media.azurefd.net/media/2023/10/XL-Conversion-Win-and-Mac_2-300x239.png 300w, https://office-insider-media.azurefd.net/media/2023/10/XL-Conversion-Win-and-Mac_2-1024x815.png 1024w, https://office-insider-media.azurefd.net/media/2023/10/XL-Conversion-Win-and-Mac_2-768x611.png 768w, https://office-insider-media.azurefd.net/media/2023/10/XL-Conversion-Win-and-Mac_2-1536x1222.png 1536w" sizes="(max-width: 805px) 100vw, 805px"></p>
<h3>Tips and tricks</h3>
<ul>
	<li>You can enable or disable the following options:

<ul>
	<li>Remove leading zeros from numerical text and convert to a number.</li>
	<li>Truncate numerical data to 15 digits of precision and convert to a number that may be displayed in scientific notation, if needed.</li>
	<li>Convert numerical data surrounding the letter “E” to a number displayed in scientific notation.</li>
	<li>Convert a continuous string of letters and numbers to a date.</li>
</ul>
</li>
</ul>
<ul>
	<li>When you select the&nbsp;<strong>When loading&nbsp;a .csv file or similar&nbsp;file,&nbsp;notify&nbsp;me&nbsp;of&nbsp;any automatic number&nbsp;conversions&nbsp;</strong>check box, Excel displays a warning message when it detects that at least one of the optional automatic data conversions is enabled and about to occur when opening a .csv or .txt file. The message gives the ability to open the file once without converting the data.</li>
</ul>
<h3>Scenarios to try</h3>
<p>Based on the settings you chose above, try some or all of the scenarios below to test the increased control over data conversions.</p>
<ul>
	<li>Type directly into a cell.</li>
	<li>Copy and paste from external sources (e.g., a web page).</li>
	<li>Open a .csv or .txt file.</li>
	<li>Find and replace operations.</li>
	<li>Select&nbsp;<strong>Data&nbsp;</strong>&gt;<strong>&nbsp;Text to Columns</strong>, and then use the&nbsp;<strong>Convert Text to Columns Wizard</strong>.</li>
</ul>
<p><strong>NOTE:&nbsp;</strong>Since the feature works by saving the entered data as text, you might see a green triangle with a&nbsp;<strong>Number stored as text</strong>&nbsp;error. This is expected. You can dismiss the error by selecting&nbsp;<strong>Ignore error</strong>&nbsp;in the context menu. Also, you may not be able to use that data in mathematical operations.</p>
<h3>Known issues</h3>
<ul>
	<li>The feature does not support disabling these conversions during macro execution.</li>
</ul>
<h3>Availability</h3>
<p>This feature is available to all users running:</p>
<ul>
	<li><u>Windows</u>: Version 2309 (Build 16808.10000) or later</li>
	<li><u>Mac</u>: Version 16.77 (Build 23091003) or later</li>
</ul>
<h3>Feedback</h3>
<p>We’d love to hear from you! Click&nbsp;<strong>Help &gt; Feedback</strong>&nbsp;to share your feedback and help us prioritize our work.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Base64 Encoding, Explained (218 pts)]]></title>
            <link>https://www.akshaykhot.com/base64-encoding-explained/</link>
            <guid>37981939</guid>
            <pubDate>Mon, 23 Oct 2023 05:28:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.akshaykhot.com/base64-encoding-explained/">https://www.akshaykhot.com/base64-encoding-explained/</a>, See on <a href="https://news.ycombinator.com/item?id=37981939">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-canvas-grid="content" data-canvas-grid-self="full">
            <p>When you're programming, it's easy to get by with a superficial understanding of many things. You can easily fool yourself by thinking that you are programming when you are blindly copy + pasting code from Stack Overflow or some random article you stumbled upon.</p><p>Base64 encoding was one of these topics that was bugging me for a while. I often came across Base64 encoded images or URLs, and had no idea whatsoever it meant or why it was even used. Finally, I decided to do some research to fill that knowledge gap, and spent the Sunday reading <a href="https://datatracker.ietf.org/doc/html/rfc4648?ref=akshaykhot.com" rel="noreferrer">RFC 4648</a> (my idea of a fun weekend). </p><p>What follows is everything I learned about Base64 encoding.</p><h2 id="what-is-base64-encoding">What is Base64 Encoding?</h2><p>Base64 encoding takes binary data and converts it into text, specifically ASCII text. The resulting text contains only letters from <code>A-Z</code>, <code>a-z</code>, numbers from <code>0-9</code>, and the symbols <code>+</code> and <code>/</code>. </p><p>As there are 26 letters in the alphabet, we have <code>26 + 26 + 10 + 2</code> characters. Hence this encoding is named <strong><code>Base64</code></strong>. These 64 characters are considered "safe", that is, they cannot be misinterpreted by legacy computers and programs unlike characters such as <code>&lt;</code>, <code>&gt;</code>, <code>\n</code> and many others.</p><div><p>💡</p><p>Here's what the text "Ruby on Rails" looks like when Base64 encoded: <b><strong>UnVieSBvbiBSYWlscw==</strong></b>.</p></div><p> <strong>It's important to remember that we are not encrypting the text here.</strong> Given Base64 encoded data, it's very easy to convert it back (decode) to the original text. We are only changing the representation of the data, i.e. encoding.</p><p>In its essence, Base64 encoding uses a specific, reduced set of characters to encode binary data, to prevent against data corruption. </p><figure><img src="https://www.akshaykhot.com/content/images/2023/10/base64_encoding.png" alt="The Base64 Alphabet" loading="lazy" width="474" height="309"><figcaption><span>The Base64 Alphabet</span></figcaption></figure><p>As there are only 64 characters available to encode into, we can represent them using only 6 bits, because <code>2^6 = 64</code>. Every Base64 digit represents 6 bits of data. There are 8 bits in a byte, and the closest common multiple of 8 and 6 is 24. So 24 bits, or 3 bytes, can be represented using four 6-bit Base64 digits. </p><p><em>(If that last paragraph totally went over your head, <strong>don't worry</strong>. Hopefully it should be clear by the end of this post.)</em></p><h2 id="why-base64">Why Base64?</h2><p>You must have included an image in your HTML document using the <code>&lt;img src="nature.jpeg"&gt;</code> tag. <strong>Did you know you can embed the image data directly into the HTML without linking to the external image file?</strong> <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/Data_URLs?ref=akshaykhot.com" rel="noreferrer">Data URLs</a> let you do this, and they use Base64 encoded text to embed files inline.</p><pre><code>&lt;img src="dataimage/gif;base64,xxxxbase64encodedtextxxxx"&gt;

data:[&lt;mime type&gt;][;charset=&lt;charset&gt;][;base64],&lt;encoded data&gt;</code></pre><div><p>Historically it has been used to encode binary data in email messages where the email server might modify line-endings. A more modern example is the use of Base64 encoding to&nbsp;<a href="http://www.sweeting.org/mark/blog/2005/07/12/base64-encoded-images-embedded-in-html?ref=akshaykhot.com" rel="noreferrer">embed image data directly in HTML source code</a>. Here it is necessary to encode the data to avoid characters like '&lt;' and '&gt;' being interpreted as tags.</p><p>From: <a href="https://stackoverflow.com/questions/3538021/why-do-we-use-base64?ref=akshaykhot.com" rel="noreferrer">Why do we use Base64?</a></p></div><p>Another common use case is when we have to store or transmit some binary data over the network that's supposed to handle text, or US-ASCII data. This ensures data remains unchanged during transport. Base64 can also be used for passing data in URLs when that data includes non-URL friendly characters.</p><p>Base encoding is also used in many applications simply because it makes it possible to manipulate objects with text editors.</p><p>You can also transfer files as text, using Base64 encoding. First, get the file's bytes and encode them as Base64. Then transfer the Base64 encoded string, and then decode it back to the original file content on the receiving side. </p><p>Let's take a deeper look into this algorithm in the next section.</p><h2 id="base64-encoding-algorithm">Base64 Encoding Algorithm</h2><p>Here's the simple algorithm that converts some text into Base64. </p><ol><li>Convert the text to its binary representation.</li><li>Divide the bits into groups of 6 bits each.</li><li>Convert each group to a decimal number from 0-63. It cannot be greater than 64 as there are only 6 bits in each group.</li><li>Convert this decimal number to the equivalent Base64 character using the Base64 alphabet.</li></ol><p>That's it. You have a Base64 encoded string. If there're insufficient bits in the final group, you can use <code>=</code> or <code>==</code> as padding.</p><p>Sounds confusing? Don't worry, the following example should make it pretty clear. Let's convert my name "Akshay" to its Base64 equivalent string.</p><ul><li>Convert the text "Akshay" to binary by first converting each character to its corresponding <a href="https://www.ascii-code.com/?ref=akshaykhot.com" rel="noreferrer">ASCII number</a> and then converting that decimal number to binary (or just use <a href="https://www.rapidtables.com/convert/number/ascii-to-binary.html?ref=akshaykhot.com" rel="noreferrer">this tool</a>):</li></ul><pre><code>01000001 01101011 01110011 01101000 01100001 01111001

   A        k        s        h        a        y</code></pre><ul><li>Divide the bits into groups of 6 bits:</li></ul><pre><code>010000 010110 101101 110011 011010 000110 000101 111001</code></pre><ul><li>Convert each group to a decimal number between 0 to 63:</li></ul><pre><code>010000 010110 101101 110011 011010 000110 000101 111001
  
  16     22     45     51     26     6      5      57</code></pre><ul><li>Now use the Base64 alphabet (see above image) to convert each decimal number to its Base64 representation:</li></ul><pre><code>16  22  45  51  26  6  5  57

Q   W   t   z   a   G  F  5</code></pre><p>And we're done. The name "Akshay" is represented in Base64 as <code>QWtzaGF5</code>. </p><p>At first glance, the benefit of Base64 encoding is not quite obvious. <strong>What exactly did we achieve by converting "Akshay" to "QWtzaGF5"?</strong> </p><p>Imagine, instead of my name, you had an image or a sensitive file (PDF, text, video, anything, really), and you wanted to store it as text. You could first convert it to binary, and then Base64 encode it to get corresponding ASCII text. </p><p>Now you could send or store that text anywhere and anyhow you like, without worrying whether some legacy device, protocol or software won't misinterpret the raw binary data to corrupt your file. Makes sense? </p><h2 id="how-to-encode-and-decode-base64">How to Encode and Decode Base64</h2><p>All programming languages have support for encoding and decoding data to and from the Base64 format. </p><p>Here is the Ruby code that takes some text as input and converts it into Base-64 encoded string.</p><pre><code>require "base64"

encoded = Base64.encode64("Ruby on Rails")  # "UnVieSBvbiBSYWlscw==\n"

decoded = Base64.decode64(encoded)  # "Ruby on Rails"</code></pre><p>Here's the equivalent program in C#, my second-most favorite language:</p><pre><code>public static string ToBase64(string value)
{
    byte[] bytes = System.Text.Encoding.ASCII.GetBytes(value);

    string base64 = Convert.ToBase64String(bytes);

    return base64;
}

public static string FromBase64(string encoded)
{
    byte[] data = System.Convert.FromBase64String(encodedString);
    
    string decodedString = System.Text.Encoding.UTF8.GetString(data);
}</code></pre><p>PHP makes it very simple with its <code>base64_encode</code> and <code>base64_decode</code> top-level functions.</p><pre><code>&lt;?php
$str = "Ruby on Rails";
echo base64_encode($str);

$str = "UnVieSBvbiBSYWlscw==\n";
echo base64_decode($str);
?&gt;</code></pre><p>Similarly, in JavaScript, use the <code>btoa()</code> to encode and <code>atob()</code> functions to encode and decode the text.</p><pre><code>const text = "Ruby on Rails"
btoa(text) // "UnVieSBvbiBSYWlscw==\n"

const encoded_text = "UnVieSBvbiBSYWlscw==\n"
atob(encoded_text)  // Ruby on Rails</code></pre><p>What's more, your terminal has built-in support for Base64 encoding. Try this in terminal:</p><pre><code>$ echo "akshay" | base64
YWtzaGF5Cg==

$ echo "YWtzaGF5Cg==" | base64 -d
akshay</code></pre><hr><div><p>That's a wrap. I hope you found this article helpful and you learned something new. If you are interested in learning more, I highly recommend you read <a href="https://datatracker.ietf.org/doc/html/rfc4648?ref=akshaykhot.com" rel="noreferrer">RFC 4648</a>, which describes the Base64 encoding in detail.</p><p>As always, if you have any questions or feedback, didn't understand something, or found a mistake, please leave a comment below or <a href="mailto:akshay.khot@hey.com?ref=akshays-blog" rel="noreferrer">send me an email</a>. I reply to all emails I get from developers, and I look forward to hearing from you.</p><p>If you'd like to receive future articles directly in your email, please <a href="#/portal/signup" rel="noreferrer">subscribe to my blog</a>. If you're already a subscriber, thank you.</p></div>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Pypipe – A Python command-line tool for pipeline processing (168 pts)]]></title>
            <link>https://github.com/bugen/pypipe</link>
            <guid>37981683</guid>
            <pubDate>Mon, 23 Oct 2023 04:35:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/bugen/pypipe">https://github.com/bugen/pypipe</a>, See on <a href="https://news.ycombinator.com/item?id=37981683">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" id="user-content-pypipe-" dir="auto"><a href="#pypipe-">pypipe </a></h2>
<div dir="auto" data-snippet-clipboard-copy-content="$ echo &quot;pypipe&quot; | ppp &quot;line[::2]&quot;
ppp"><pre>$ <span>echo</span> <span><span>"</span>pypipe<span>"</span></span> <span>|</span> ppp <span><span>"</span>line[::2]<span>"</span></span>
ppp</pre></div>
<p dir="auto"><strong>pypipe</strong> is a Python command-line tool for pipeline processing.</p>
<h2 tabindex="-1" id="user-content-demo-" dir="auto"><a href="#demo-">Demo </a></h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/bugen/pypipe/blob/main/docs/demo.svg"><img src="https://github.com/bugen/pypipe/raw/main/docs/demo.svg" alt="Alt text"></a></p>
<h2 tabindex="-1" id="user-content-quick-links-" dir="auto"><a href="#quick-links-">Quick links </a></h2>
<ul dir="auto">
<li><a href="#installation">Installation</a></li>
<li><a href="#basic-usage-and-examples">Basic usage and Examples</a></li>
<li><a href="#pypipe-is-a-code-generator">pypipe is a code generator.</a></li>
</ul>
<h2 tabindex="-1" id="user-content-installation" dir="auto"><a href="#installation">Installation</a></h2>
<p dir="auto">pypipe is a single Python file and uses only the standard library. You can use it by placing pypipe.py in a directory included in your PATH (e.g., ~/.local/bin). If execute permission is not already present, please add it.</p>

<p dir="auto">To make it easier to type, it's recommended to create a symbolic link.</p>

<p dir="auto"><span>Note</span><br>
pypipe requires Python 3.6 or later.</p>
<h2 tabindex="-1" id="user-content-basic-usage-and-examples" dir="auto"><a href="#basic-usage-and-examples">Basic usage and Examples</a></h2>
<h3 tabindex="-1" id="user-content--ppp-line" dir="auto"><a href="#-ppp-line"><code>| ppp line</code></a></h3>
<p dir="auto">Processing line by line. You can get the line string as <code>line</code> or <code>l</code> and the line number as <code>i</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ cat staff.txt |ppp 'i, line.upper()'
1       NAME    WEIGHT  BIRTH   AGE     SPECIES CLASS
2       SIMBA   250     1994-06-15      29      LION    MAMMAL
3       DUMBO   4000    1941-10-23      81      ELEPHANT        MAMMAL
4       GEORGE  20      1939-01-01      84      MONKEY  MAMMAL
5       POOH    1       1921-08-21      102     TEDDY BEAR      ARTIFACT
6       BOB     0       1999-05-01      24      SPONGE  DEMOSPONGE"><pre>$ cat staff.txt <span>|</span>ppp <span><span>'</span>i, line.upper()<span>'</span></span>
1       NAME    WEIGHT  BIRTH   AGE     SPECIES CLASS
2       SIMBA   250     1994-06-15      29      LION    MAMMAL
3       DUMBO   4000    1941-10-23      81      ELEPHANT        MAMMAL
4       GEORGE  20      1939-01-01      84      MONKEY  MAMMAL
5       POOH    1       1921-08-21      102     TEDDY BEAR      ARTIFACT
6       BOB     0       1999-05-01      24      SPONGE  DEMOSPONGE</pre></div>
<h3 tabindex="-1" id="user-content--ppp-rec" dir="auto"><a href="#-ppp-rec"><code>| ppp rec</code></a></h3>
<p dir="auto">Split each line by TAB. You can get the list includes splitted strings as <code>rec</code> or <code>r</code> and the record number as <code>i</code>..</p>
<div dir="auto" data-snippet-clipboard-copy-content="cat staff.txt |ppp rec 'r[:3]'
Name    Weight  Birth
Simba   250     1994-06-15
Dumbo   4000    1941-10-23
George  20      1939-01-01
Pooh    1       1921-08-21
Bob     0       1999-05-01"><pre>cat staff.txt <span>|</span>ppp rec <span><span>'</span>r[:3]<span>'</span></span>
Name    Weight  Birth
Simba   250     1994-06-15
Dumbo   4000    1941-10-23
George  20      1939-01-01
Pooh    1       1921-08-21
Bob     0       1999-05-01</pre></div>
<p dir="auto">Using the <code>-l LENGTH, --length LENGTH</code> option allows you to get the values of each field as <code>f1, f2, f3, ....</code></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ tail -n +2 staff.txt |ppp rec -l5 'f&quot;{f1} is {f4} years old&quot;'
Simba is 29 years old
Dumbo is 81 years old
George is 84 years old
Pooh is 102 years old
Bob is 24 years old"><pre>$ tail -n +2 staff.txt <span>|</span>ppp rec -l5 <span><span>'</span>f"{f1} is {f4} years old"<span>'</span></span>
Simba is 29 years old
Dumbo is 81 years old
George is 84 years old
Pooh is 102 years old
Bob is 24 years old</pre></div>
<p dir="auto">When using the <code>-H, --header</code> option, it treats the first line as a header line and skips it. The header values can be obtained from a list named <code>header</code>, and you can access the values of each field using the format <code>dic["FIELD_NAME"]</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ cat staff.txt |ppp rec -H 'rec[0], dic[&quot;Birth&quot;]'
Simba   1994-06-15
Dumbo   1941-10-23
George  1939-01-01
Pooh    1921-08-21
Bob     1999-05-01"><pre>$ cat staff.txt <span>|</span>ppp rec -H <span><span>'</span>rec[0], dic["Birth"]<span>'</span></span>
Simba   1994-06-15
Dumbo   1941-10-23
George  1939-01-01
Pooh    1921-08-21
Bob     1999-05-01</pre></div>
<p dir="auto">You can change the delimiter by using the <code>-d DELIMITER, --delimiter DELIMITER</code> option.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ cat staff.csv |ppp rec -d , -l6  f1
Name
Simba
Dumbo
George
Pooh
Bob"><pre>$ cat staff.csv <span>|</span>ppp rec -d , -l6  f1
Name
Simba
Dumbo
George
Pooh
Bob</pre></div>
<h3 tabindex="-1" id="user-content--ppp-csv" dir="auto"><a href="#-ppp-csv"><code>| ppp csv</code></a></h3>
<p dir="auto"><code>csv</code> is similar to <code>rec</code>, but the difference is that while <code>rec</code> simply splits the line using the specified DELIMITER like this, <code>'line.split(DELIMITER))'</code>, <code>csv</code> uses the <a href="https://docs.python.org/3/library/csv.html" rel="nofollow">csv</a> library for parsing. Furthermore, <code>rec</code> is tab-separated by default, whereas <code>csv</code> is comma-separated.</p>
<p dir="auto">You can specify options to pass to csv.reader and csv.writer using the <code>-O NAME=VALUE, --csv-opt NAME=VALUE</code> option.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ cat staff.csv |ppp csv -O 'quoting=csv.QUOTE_ALL'
&quot;Name&quot;,&quot;Weight&quot;,&quot;Birth&quot;,&quot;Age&quot;,&quot;Species&quot;,&quot;Class&quot;
&quot;Simba&quot;,&quot;250&quot;,&quot;1994-06-15&quot;,&quot;29&quot;,&quot;Lion&quot;,&quot;Mammal&quot;
&quot;Dumbo&quot;,&quot;4000&quot;,&quot;1941-10-23&quot;,&quot;81&quot;,&quot;Elephant&quot;,&quot;Mammal&quot;
&quot;George&quot;,&quot;20&quot;,&quot;1939-01-01&quot;,&quot;84&quot;,&quot;Monkey&quot;,&quot;Mammal&quot;
&quot;Pooh&quot;,&quot;1&quot;,&quot;1921-08-21&quot;,&quot;102&quot;,&quot;Teddy bear&quot;,&quot;Artifact&quot;
&quot;Bob&quot;,&quot;0&quot;,&quot;1999-05-01&quot;,&quot;24&quot;,&quot;Sponge&quot;,&quot;Demosponge&quot;"><pre>$ cat staff.csv <span>|</span>ppp csv -O <span><span>'</span>quoting=csv.QUOTE_ALL<span>'</span></span>
<span><span>"</span>Name<span>"</span></span>,<span><span>"</span>Weight<span>"</span></span>,<span><span>"</span>Birth<span>"</span></span>,<span><span>"</span>Age<span>"</span></span>,<span><span>"</span>Species<span>"</span></span>,<span><span>"</span>Class<span>"</span></span>
<span><span>"</span>Simba<span>"</span></span>,<span><span>"</span>250<span>"</span></span>,<span><span>"</span>1994-06-15<span>"</span></span>,<span><span>"</span>29<span>"</span></span>,<span><span>"</span>Lion<span>"</span></span>,<span><span>"</span>Mammal<span>"</span></span>
<span><span>"</span>Dumbo<span>"</span></span>,<span><span>"</span>4000<span>"</span></span>,<span><span>"</span>1941-10-23<span>"</span></span>,<span><span>"</span>81<span>"</span></span>,<span><span>"</span>Elephant<span>"</span></span>,<span><span>"</span>Mammal<span>"</span></span>
<span><span>"</span>George<span>"</span></span>,<span><span>"</span>20<span>"</span></span>,<span><span>"</span>1939-01-01<span>"</span></span>,<span><span>"</span>84<span>"</span></span>,<span><span>"</span>Monkey<span>"</span></span>,<span><span>"</span>Mammal<span>"</span></span>
<span><span>"</span>Pooh<span>"</span></span>,<span><span>"</span>1<span>"</span></span>,<span><span>"</span>1921-08-21<span>"</span></span>,<span><span>"</span>102<span>"</span></span>,<span><span>"</span>Teddy bear<span>"</span></span>,<span><span>"</span>Artifact<span>"</span></span>
<span><span>"</span>Bob<span>"</span></span>,<span><span>"</span>0<span>"</span></span>,<span><span>"</span>1999-05-01<span>"</span></span>,<span><span>"</span>24<span>"</span></span>,<span><span>"</span>Sponge<span>"</span></span>,<span><span>"</span>Demosponge<span>"</span></span></pre></div>
<h3 tabindex="-1" id="user-content--ppp-text" dir="auto"><a href="#-ppp-text"><code>| ppp text</code></a></h3>
<p dir="auto">In <code>ppp text</code>, the entire standard input is read as a single piece of text. You can access the read text as <code>text</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ cat staff.txt | ppp text 'len(text)'
231"><pre>$ cat staff.txt <span>|</span> ppp text <span><span>'</span>len(text)<span>'</span></span>
231</pre></div>
<p dir="auto">For example, <code>ppp text</code> is particularly useful when working with a indented JSON file. Using the <code>-j, --json</code> option allows you to decode the text into JSON. The decoded data can be obtained as a <code>dic</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ cat staff.json |ppp text -j 'dic[&quot;data&quot;][0]'
{'Name': 'Simba', 'Weight': 250, 'Birth': '1994-06-15', 'Age': 29, 'Species': 'Lion', 'Class': 'Mammal'}"><pre>$ cat staff.json <span>|</span>ppp text -j <span><span>'</span>dic["data"][0]<span>'</span></span>
{<span><span>'</span>Name<span>'</span></span>: <span><span>'</span>Simba<span>'</span></span>, <span><span>'</span>Weight<span>'</span></span>: 250, <span><span>'</span>Birth<span>'</span></span>: <span><span>'</span>1994-06-15<span>'</span></span>, <span><span>'</span>Age<span>'</span></span>: 29, <span><span>'</span>Species<span>'</span></span>: <span><span>'</span>Lion<span>'</span></span>, <span><span>'</span>Class<span>'</span></span>: <span><span>'</span>Mammal<span>'</span></span>}</pre></div>
<p dir="auto"><span>Note</span><br>
You can also use <code>-j, --json</code> option in <code>line</code> and <code>file</code>.</p>
<h3 tabindex="-1" id="user-content--ppp-file" dir="auto"><a href="#-ppp-file"><code>| ppp file</code></a></h3>
<p dir="auto">In <code>ppp file</code>, it receives a list of file paths from standard input. It then opens each received file path, reads the contents of the file into <code>text</code>, and repeats this process for each received file path in a loop. The received paths can be obtained as <code>path</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ ls staff.txt staff.csv staff.json staff.xml |ppp file 'path, len(text)'
staff.csv       231
staff.json      1046
staff.txt       231
staff.xml       1042"><pre>$ ls staff.txt staff.csv staff.json staff.xml <span>|</span>ppp file <span><span>'</span>path, len(text)<span>'</span></span>
staff.csv       231
staff.json      1046
staff.txt       231
staff.xml       1042</pre></div>
<p dir="auto">For example, <code>ppp file</code> is usuful, especially when processing a large number of JSON files.</p>
<div dir="auto" data-snippet-clipboard-copy-content="find . -name '*.json'| ppp file --json ..."><pre>find <span>.</span> -name <span><span>'</span>*.json<span>'</span></span><span>|</span> ppp file --json ...</pre></div>
<h3 tabindex="-1" id="user-content--ppp-custom--n-name" dir="auto"><a href="#-ppp-custom--n-name"><code>| ppp custom -N NAME</code></a></h3>
<p dir="auto">You can easily create custom commands using pypipe. First, you define custom commands. The definition file is, by default, located at <code>~/.config/pypipe/pypipe_custom.py</code>. You can change the path of this file using the <code>PYPIPE_CUSTOM</code> environment variable.</p>
<p dir="auto">The following is an example of defining custom commands xpath and sum.</p>
<p dir="auto">~/.config/pypipe/pypipe_custom.py</p>
<div dir="auto" data-snippet-clipboard-copy-content="TEMPLATE_XPATH = r&quot;&quot;&quot;
from lxml import etree
{imp}

def output(e):
    if isinstance(e, etree._Element):
        print(etree.tostring(e).decode().rstrip())
    else:
        _print(e)

{pre}

tree = etree.parse(sys.stdin)
for e in tree.xpath('{path}'):
{loop_head}
{loop_filter}
{main}

{post}
&quot;&quot;&quot;

TEMPLATE_SUM = r&quot;&quot;&quot;
import re
import sys
{imp}

ptn = re.compile(r'{pattern}')
s = 0

def add_or_print(*args):
    global s
    rec = args[0]
    if len(args) == 2:
        if isinstance(args[1], int):
            i = args[1]
            if len(rec) >= i:
                s += rec[i-1]
        else:
            print(args[1])
    else:
        print(*args[1:])


for line in sys.stdin:
    line = line.rstrip('\r\n')
    rec = [{type}(e) for e in ptn.findall(line)]
    if not rec:
        continue
{loop_head}
{loop_filter}
{main}

print(s)
&quot;&quot;&quot;

custom_command = {
    &quot;xpath&quot;: {
        &quot;template&quot;: TEMPLATE_XPATH,
        &quot;code_indent&quot;: 1,
        &quot;default_code&quot;: &quot;e&quot;,
        &quot;wrapper&quot;: 'output({})',
        &quot;options&quot;: {
            &quot;path&quot;: {&quot;default&quot;: '/'}
        }
    },
    &quot;sum&quot;: {
        &quot;template&quot;: TEMPLATE_SUM,
        &quot;code_indent&quot;: 1,
        &quot;default_code&quot;: &quot;1&quot;,
        &quot;wrapper&quot;: 'add_or_print(rec, {})',
        &quot;options&quot;: {
            &quot;pattern&quot;: {&quot;default&quot;: r'\d+'},
            &quot;type&quot;: {&quot;default&quot;: 'int'}
        }
    },
}"><pre><span>TEMPLATE_XPATH</span> <span>=</span> <span>r"""</span>
<span>from lxml import etree</span>
<span>{imp}</span>
<span></span>
<span>def output(e):</span>
<span>    if isinstance(e, etree._Element):</span>
<span>        print(etree.tostring(e).decode().rstrip())</span>
<span>    else:</span>
<span>        _print(e)</span>
<span></span>
<span>{pre}</span>
<span></span>
<span>tree = etree.parse(sys.stdin)</span>
<span>for e in tree.xpath('{path}'):</span>
<span>{loop_head}</span>
<span>{loop_filter}</span>
<span>{main}</span>
<span></span>
<span>{post}</span>
<span>"""</span>

<span>TEMPLATE_SUM</span> <span>=</span> <span>r"""</span>
<span>import re</span>
<span>import sys</span>
<span>{imp}</span>
<span></span>
<span>ptn = re.compile(r'{pattern}')</span>
<span>s = 0</span>
<span></span>
<span>def add_or_print(*args):</span>
<span>    global s</span>
<span>    rec = args[0]</span>
<span>    if len(args) == 2:</span>
<span>        if isinstance(args[1], int):</span>
<span>            i = args[1]</span>
<span>            if len(rec) &gt;= i:</span>
<span>                s += rec[i-1]</span>
<span>        else:</span>
<span>            print(args[1])</span>
<span>    else:</span>
<span>        print(*args[1:])</span>
<span></span>
<span></span>
<span>for line in sys.stdin:</span>
<span>    line = line.rstrip('\r\n')</span>
<span>    rec = [{type}(e) for e in ptn.findall(line)]</span>
<span>    if not rec:</span>
<span>        continue</span>
<span>{loop_head}</span>
<span>{loop_filter}</span>
<span>{main}</span>
<span></span>
<span>print(s)</span>
<span>"""</span>

<span>custom_command</span> <span>=</span> {
    <span>"xpath"</span>: {
        <span>"template"</span>: <span>TEMPLATE_XPATH</span>,
        <span>"code_indent"</span>: <span>1</span>,
        <span>"default_code"</span>: <span>"e"</span>,
        <span>"wrapper"</span>: <span>'output({})'</span>,
        <span>"options"</span>: {
            <span>"path"</span>: {<span>"default"</span>: <span>'/'</span>}
        }
    },
    <span>"sum"</span>: {
        <span>"template"</span>: <span>TEMPLATE_SUM</span>,
        <span>"code_indent"</span>: <span>1</span>,
        <span>"default_code"</span>: <span>"1"</span>,
        <span>"wrapper"</span>: <span>'add_or_print(rec, {})'</span>,
        <span>"options"</span>: {
            <span>"pattern"</span>: {<span>"default"</span>: <span>r'\d+'</span>},
            <span>"type"</span>: {<span>"default"</span>: <span>'int'</span>}
        }
    },
}</pre></div>
<p dir="auto">You can use them as follows:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ cat staff.xml |ppp custom -N xpath -O path='./Animal/Age'
<Age>29</Age>
<Age>81</Age>
<Age>84</Age>
<Age>102</Age>
<Age>24</Age>"><pre>$ cat staff.xml <span>|</span>ppp custom -N xpath -O path=<span><span>'</span>./Animal/Age<span>'</span></span>
<span>&lt;</span>Age<span>&gt;</span>2<span>9&lt;</span>/Age<span>&gt;</span>
<span>&lt;</span>Age<span>&gt;</span>8<span>1&lt;</span>/Age<span>&gt;</span>
<span>&lt;</span>Age<span>&gt;</span>8<span>4&lt;</span>/Age<span>&gt;</span>
<span>&lt;</span>Age<span>&gt;</span>1<span>02&lt;</span>/Age<span>&gt;</span>
<span>&lt;</span>Age<span>&gt;</span>2<span>4&lt;</span>/Age<span>&gt;</span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="$ seq 10000| ppp c -Nsum -f 'rec[0] % 3 == 0'
16668333"><pre>$ seq 10000<span>|</span> ppp c -Nsum -f <span><span>'</span>rec[0] % 3 == 0<span>'</span></span>
16668333</pre></div>
<h3 tabindex="-1" id="user-content--c---counter" dir="auto"><a href="#-c---counter"><code>-c, --counter</code></a></h3>
<p dir="auto">Using the <code>-c, --counter</code> option allows for easy data aggregation. When you specify the <code>-c, --counter</code> option, it creates an instance of collections.Counter, which can be accessed as either <code>counter</code> or <code>c</code>. The <code>-c, --counter</code> option is available for use in all commands.</p>
<p dir="auto">An example of aggregating data by the 'Gender' and 'Hobby' fields.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ cat people.csv |ppp csv -H --counter 'dic[&quot;Gender&quot;], dic[&quot;Hobby&quot;]'| head -n10
Female  Cooking 4
Male    Hiking  3
Female  Reading 3
Male    Gardening       3
Female  Traveling       3
Male    Playing Music   3
Female  Dancing 3
Female  Hiking  3
Female  Painting        2
Male    Photography     2"><pre>$ cat people.csv <span>|</span>ppp csv -H --counter <span><span>'</span>dic["Gender"], dic["Hobby"]<span>'</span></span><span>|</span> head -n10
Female  Cooking 4
Male    Hiking  3
Female  Reading 3
Male    Gardening       3
Female  Traveling       3
Male    Playing Music   3
Female  Dancing 3
Female  Hiking  3
Female  Painting        2
Male    Photography     2</pre></div>
<p dir="auto">This is an example to aggregate data based on whether female individuals are 30 years or older.</p>
<div dir="auto" data-snippet-clipboard-copy-content="cat people.csv |ppp csv -H -c -f 'dic[&quot;Gender&quot;] == &quot;Female&quot;' 'int(dic[&quot;Age&quot;]) >= 30'
False   16
True    10"><pre>cat people.csv <span>|</span>ppp csv -H -c -f <span><span>'</span>dic["Gender"] == "Female"<span>'</span></span> <span><span>'</span>int(dic["Age"]) &gt;= 30<span>'</span></span>
False   16
True    10</pre></div>
<p dir="auto">When using the <code>-c, --counter</code> option, it uses <code>counter[{}] += 1</code> as the wrapper. If you want to count in a different way, you can disable the wrapping by using the <code>-n, --no-wrapping</code> option and add your own counting code.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ cat population.csv |ppp csv -H -c -n 'counter[dic[&quot;State&quot;]] += int(dic[&quot;Population&quot;])'
New York        8398748
Texas   7751480
California      7327731
Illinois        2705994
Arizona 1680992
Pennsylvania    1584138
Florida 903889
Ohio    892533
Indiana 876862
North Carolina  792862
Washington      753675
Michigan        673104"><pre>$ cat population.csv <span>|</span>ppp csv -H -c -n <span><span>'</span>counter[dic["State"]] += int(dic["Population"])<span>'</span></span>
New York        8398748
Texas   7751480
California      7327731
Illinois        2705994
Arizona 1680992
Pennsylvania    1584138
Florida 903889
Ohio    892533
Indiana 876862
North Carolina  792862
Washington      753675
Michigan        673104</pre></div>
<p dir="auto">Information about <a href="#code-wrappping">Code wrapping</a>.</p>
<h2 tabindex="-1" id="user-content-pypipe-is-a-code-generator" dir="auto"><a href="#pypipe-is-a-code-generator">pypipe is a code generator.</a></h2>
<p dir="auto">pypipe is a command-line tool for pipeline processing, but it can also be thought of as a code generator. It generates code internally using the given arguments and then executes the generated code using the <code>exec</code> function. Therefore, instead of executing the generated code, you have the option to print it to the standard output or save it to a file.</p>
<h3 tabindex="-1" id="user-content-print-generated-code--p---print" dir="auto"><a href="#print-generated-code--p---print">Print generated code. <code>-p, --print</code></a></h3>
<p dir="auto">To check the generated code, you can use the <code>-p, --print</code> option.</p>
<div dir="auto" data-snippet-clipboard-copy-content="ppp file -m rb -i hashlib -b 'total = 0' -b '_p(&quot;PATH&quot;, &quot;SIZE&quot;, &quot;MD5&quot;)' -e 'size = len(text)' -f 'path.stem == &quot;staff&quot;' 'total += size' 'path, size, hashlib.md5(text).hexdigest()' -a 'print(f&quot;Total size: {total}&quot;, file=sys.stderr)' -p"><pre>ppp file -m rb -i hashlib -b <span><span>'</span>total = 0<span>'</span></span> -b <span><span>'</span>_p("PATH", "SIZE", "MD5")<span>'</span></span> -e <span><span>'</span>size = len(text)<span>'</span></span> -f <span><span>'</span>path.stem == "staff"<span>'</span></span> <span><span>'</span>total += size<span>'</span></span> <span><span>'</span>path, size, hashlib.md5(text).hexdigest()<span>'</span></span> -a <span><span>'</span>print(f"Total size: {total}", file=sys.stderr)<span>'</span></span> -p</pre></div>
<p dir="auto">The generated code is output as follows.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# IMPORT
import sys
from functools import partial
import gzip
from pathlib import Path
import hashlib

def _open(path):
    if path.suffix == '.gz':
        return gzip.open(path, 'rb')
    else:
        return open(path, 'rb')

# PRE
_p = partial(print, sep=&quot;\t&quot;)  # ABBREV
I, S, B, L, D, SET = 0, &quot;&quot;, False, [], {}, set()  # ABBREV

def _print(*args, delimiter='\t'):
    if len(args) == 1 and isinstance(args[0], (list, tuple)):
        print(*args[0], sep=delimiter)
    else:
        print(*args, sep=delimiter)

total = 0
_p(&quot;PATH&quot;, &quot;SIZE&quot;, &quot;MD5&quot;)

for i, line in enumerate(sys.stdin, 1):
    path = Path(line.rstrip('\r\n'))
    with _open(path) as file:
        text = file.read()
        # LOOP HEAD
        size = len(text)
        # LOOP FILTER
        if not (path.stem == &quot;staff&quot;): continue
        # MAIN
        total += size
        _print(path, size, hashlib.md5(text).hexdigest())

# POST
print(f&quot;Total size: {total}&quot;, file=sys.stderr)"><pre><span># IMPORT</span>
<span>import</span> <span>sys</span>
<span>from</span> <span>functools</span> <span>import</span> <span>partial</span>
<span>import</span> <span>gzip</span>
<span>from</span> <span>pathlib</span> <span>import</span> <span>Path</span>
<span>import</span> <span>hashlib</span>

<span>def</span> <span>_open</span>(<span>path</span>):
    <span>if</span> <span>path</span>.<span>suffix</span> <span>==</span> <span>'.gz'</span>:
        <span>return</span> <span>gzip</span>.<span>open</span>(<span>path</span>, <span>'rb'</span>)
    <span>else</span>:
        <span>return</span> <span>open</span>(<span>path</span>, <span>'rb'</span>)

<span># PRE</span>
<span>_p</span> <span>=</span> <span>partial</span>(<span>print</span>, <span>sep</span><span>=</span><span>"<span>\t</span>"</span>)  <span># ABBREV</span>
<span>I</span>, <span>S</span>, <span>B</span>, <span>L</span>, <span>D</span>, <span>SET</span> <span>=</span> <span>0</span>, <span>""</span>, <span>False</span>, [], {}, <span>set</span>()  <span># ABBREV</span>

<span>def</span> <span>_print</span>(<span>*</span><span>args</span>, <span>delimiter</span><span>=</span><span>'<span>\t</span>'</span>):
    <span>if</span> <span>len</span>(<span>args</span>) <span>==</span> <span>1</span> <span>and</span> <span>isinstance</span>(<span>args</span>[<span>0</span>], (<span>list</span>, <span>tuple</span>)):
        <span>print</span>(<span>*</span><span>args</span>[<span>0</span>], <span>sep</span><span>=</span><span>delimiter</span>)
    <span>else</span>:
        <span>print</span>(<span>*</span><span>args</span>, <span>sep</span><span>=</span><span>delimiter</span>)

<span>total</span> <span>=</span> <span>0</span>
<span>_p</span>(<span>"PATH"</span>, <span>"SIZE"</span>, <span>"MD5"</span>)

<span>for</span> <span>i</span>, <span>line</span> <span>in</span> <span>enumerate</span>(<span>sys</span>.<span>stdin</span>, <span>1</span>):
    <span>path</span> <span>=</span> <span>Path</span>(<span>line</span>.<span>rstrip</span>(<span>'<span>\r</span><span>\n</span>'</span>))
    <span>with</span> <span>_open</span>(<span>path</span>) <span>as</span> <span>file</span>:
        <span>text</span> <span>=</span> <span>file</span>.<span>read</span>()
        <span># LOOP HEAD</span>
        <span>size</span> <span>=</span> <span>len</span>(<span>text</span>)
        <span># LOOP FILTER</span>
        <span>if</span> <span>not</span> (<span>path</span>.<span>stem</span> <span>==</span> <span>"staff"</span>): <span>continue</span>
        <span># MAIN</span>
        <span>total</span> <span>+=</span> <span>size</span>
        <span>_print</span>(<span>path</span>, <span>size</span>, <span>hashlib</span>.<span>md5</span>(<span>text</span>).<span>hexdigest</span>())

<span># POST</span>
<span>print</span>(<span>f"Total size: <span><span>{</span><span>total</span><span>}</span></span>"</span>, <span>file</span><span>=</span><span>sys</span>.<span>stderr</span>)</pre></div>
<p dir="auto">Check that there are no issues with the generated code and execute it.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ find . -type f |ppp file -m rb -i hashlib -b 'total = 0' -b '_p(&quot;PATH&quot;, &quot;SIZE&quot;, &quot;MD5&quot;)' -e 'size = len(text)' -f 'path.stem == &quot;staff&quot;' 'total += size' 'path, size, hashlib.md5(text).hexdigest()' -a 'print(f&quot;Total size: {total}&quot;, file=sys.stderr)'
PATH    SIZE    MD5
my_zoo.csv      186     e091408cc9174f1da86b50ee8e2fba96
my_zoo.xml      888     9edd78d97e45eccbac2b80747bd9c70b
my_zoo.json     887     7f15b3b8a23b91b60184113a38fa3e19
my_zoo.txt      186     4581c312d81815c3662f785ba9e7bd50
Total size: 2147"><pre>$ find <span>.</span> -type f <span>|</span>ppp file -m rb -i hashlib -b <span><span>'</span>total = 0<span>'</span></span> -b <span><span>'</span>_p("PATH", "SIZE", "MD5")<span>'</span></span> -e <span><span>'</span>size = len(text)<span>'</span></span> -f <span><span>'</span>path.stem == "staff"<span>'</span></span> <span><span>'</span>total += size<span>'</span></span> <span><span>'</span>path, size, hashlib.md5(text).hexdigest()<span>'</span></span> -a <span><span>'</span>print(f"Total size: {total}", file=sys.stderr)<span>'</span></span>
PATH    SIZE    MD5
my_zoo.csv      186     e091408cc9174f1da86b50ee8e2fba96
my_zoo.xml      888     9edd78d97e45eccbac2b80747bd9c70b
my_zoo.json     887     7f15b3b8a23b91b60184113a38fa3e19
my_zoo.txt      186     4581c312d81815c3662f785ba9e7bd50
Total size: 2147</pre></div>
<h3 tabindex="-1" id="user-content-save-generated-code-to-a-file--o-path---output-path" dir="auto"><a href="#save-generated-code-to-a-file--o-path---output-path">Save generated code to a file. <code>-o PATH, --output PATH</code></a></h3>
<p dir="auto">For writing more complex code, it's a good practice to create a template code with pypipe and edit the templated code manually. Here's the process you can follow:</p>
<ol dir="auto">
<li>Create a template code with pypipe and save it to a file, for example:
<div dir="auto" data-snippet-clipboard-copy-content="ppp line --output /tmp/pipe.py ..."><pre>ppp line --output /tmp/pipe.py ...</pre></div>
</li>
<li>Edit the code in /tmp/pipe.py to suit your needs.</li>
<li>Execute the modified code by piping input to it, for example:
<div dir="auto" data-snippet-clipboard-copy-content="cat sample.txt | /tmp/pipe.py"><pre>cat sample.txt <span>|</span> /tmp/pipe.py</pre></div>
</li>
</ol>
<h3 tabindex="-1" id="user-content-main-codes" dir="auto"><a href="#main-codes">Main codes</a></h3>
<p dir="auto">The main code is specified as positional arguments. You can specify multiple main codes. The placement of the main code varies depending on the command. In commands like <code>line</code>, <code>rec</code>, <code>csv</code>, and <code>file</code>, the main code is added within the loop processing with proper indentation. However, in the <code>text</code> command, where there is no loop processing, the main code is added without indentation.
In the <code>custom</code> command, the main code is added according to the definitions provided in the <code>pypipe_custom.py</code> file.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ ppp text -pqrn &quot;for word in text.split():&quot;  &quot;    print(word)&quot;"><pre>$ ppp text -pqrn <span><span>"</span>for word in text.split():<span>"</span></span>  <span><span>"</span>    print(word)<span>"</span></span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="import sys
from functools import partial

text = sys.stdin.read()
for word in text.split():  # <- HERE
    print(word)            # <- HERE"><pre><span>import</span> <span>sys</span>
<span>from</span> <span>functools</span> <span>import</span> <span>partial</span>

<span>text</span> <span>=</span> <span>sys</span>.<span>stdin</span>.<span>read</span>()
<span>for</span> <span>word</span> <span>in</span> <span>text</span>.<span>split</span>():  <span># &lt;- HERE</span>
    <span>print</span>(<span>word</span>)            <span># &lt;- HERE</span></pre></div>
<p dir="auto">You can also write it with line breaks in the terminal as follows:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ ppp text -pqrn '
> for word in text.split():
>     print(word)
> '"><pre>$ ppp text -pqrn <span><span>'</span></span>
<span>&gt; for word in text.split():</span>
<span>&gt;     print(word)</span>
<span>&gt; <span>'</span></span></pre></div>
<h3 tabindex="-1" id="user-content-default-main-code" dir="auto"><a href="#default-main-code">Default main code</a></h3>
<p dir="auto">If no main code is specified in the arguments, pypipe adds a predefined default code. For example, the default code in Line mode is <code>'line'</code>.</p>

<div dir="auto" data-snippet-clipboard-copy-content="import sys
from functools import partial


def _print(*args, delimiter='\t'):
    if len(args) == 1 and isinstance(args[0], (list, tuple)):
        print(*args[0], sep=delimiter)
    else:
        print(*args, sep=delimiter)


for i, line in enumerate(sys.stdin, 1):
    line = line.rstrip(&quot;\r\n&quot;)
    _print(line)  # Default code with wrappping."><pre><span>import</span> <span>sys</span>
<span>from</span> <span>functools</span> <span>import</span> <span>partial</span>


<span>def</span> <span>_print</span>(<span>*</span><span>args</span>, <span>delimiter</span><span>=</span><span>'<span>\t</span>'</span>):
    <span>if</span> <span>len</span>(<span>args</span>) <span>==</span> <span>1</span> <span>and</span> <span>isinstance</span>(<span>args</span>[<span>0</span>], (<span>list</span>, <span>tuple</span>)):
        <span>print</span>(<span>*</span><span>args</span>[<span>0</span>], <span>sep</span><span>=</span><span>delimiter</span>)
    <span>else</span>:
        <span>print</span>(<span>*</span><span>args</span>, <span>sep</span><span>=</span><span>delimiter</span>)


<span>for</span> <span>i</span>, <span>line</span> <span>in</span> <span>enumerate</span>(<span>sys</span>.<span>stdin</span>, <span>1</span>):
    <span>line</span> <span>=</span> <span>line</span>.<span>rstrip</span>(<span>"<span>\r</span><span>\n</span>"</span>)
    <span>_print</span>(<span>line</span>)  <span># Default code with wrappping.</span></pre></div>
<h3 tabindex="-1" id="user-content-code-wrappping" dir="auto"><a href="#code-wrappping">Code wrappping</a></h3>
<p dir="auto">By default, pypipe wraps the last code specified in the arguments with a predefined wrapper. For example, in <code>ppp line</code>, it uses <code>'_print({})'</code> as the wrapper. However, if the <code>-c, --counter</code> option is specified, it uses <code>'counter[{}] += 1'</code> as the wrapper instead.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ ppp line 'year = int(line)' year -pqr"><pre>$ ppp line <span><span>'</span>year = int(line)<span>'</span></span> year -pqr</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="import sys
from functools import partial


def _print(*args, delimiter='\t'):
    if len(args) == 1 and isinstance(args[0], (list, tuple)):
        print(*args[0], sep=delimiter)
    else:
        print(*args, sep=delimiter)


for i, line in enumerate(sys.stdin, 1):
    line = line.rstrip(&quot;\r\n&quot;)
    year = int(line)
    _print(year)  # Wrapping"><pre><span>import</span> <span>sys</span>
<span>from</span> <span>functools</span> <span>import</span> <span>partial</span>


<span>def</span> <span>_print</span>(<span>*</span><span>args</span>, <span>delimiter</span><span>=</span><span>'<span>\t</span>'</span>):
    <span>if</span> <span>len</span>(<span>args</span>) <span>==</span> <span>1</span> <span>and</span> <span>isinstance</span>(<span>args</span>[<span>0</span>], (<span>list</span>, <span>tuple</span>)):
        <span>print</span>(<span>*</span><span>args</span>[<span>0</span>], <span>sep</span><span>=</span><span>delimiter</span>)
    <span>else</span>:
        <span>print</span>(<span>*</span><span>args</span>, <span>sep</span><span>=</span><span>delimiter</span>)


<span>for</span> <span>i</span>, <span>line</span> <span>in</span> <span>enumerate</span>(<span>sys</span>.<span>stdin</span>, <span>1</span>):
    <span>line</span> <span>=</span> <span>line</span>.<span>rstrip</span>(<span>"<span>\r</span><span>\n</span>"</span>)
    <span>year</span> <span>=</span> <span>int</span>(<span>line</span>)
    <span>_print</span>(<span>year</span>)  <span># Wrapping</span></pre></div>
<h4 tabindex="-1" id="user-content-disable-code-wrappping--n---no-wrapping" dir="auto"><a href="#disable-code-wrappping--n---no-wrapping">Disable code wrappping. <code>-n, --no-wrapping</code></a></h4>
<p dir="auto">If you want to disable the wrapping of the last code specified in the arguments by a predefined wrapper, you can use the <code>-n, --no-wrapping</code> option.</p>
<div dir="auto" data-snippet-clipboard-copy-content="ppp line -n 'n = max(len(line), n)' -a 'print(n)' -pqr"><pre>ppp line -n <span><span>'</span>n = max(len(line), n)<span>'</span></span> -a <span><span>'</span>print(n)<span>'</span></span> -pqr</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="import sys
from functools import partial


for i, line in enumerate(sys.stdin, 1):
    line = line.rstrip(&quot;\r\n&quot;)
    n = max(len(line), n)  # No wrapping

print(n)"><pre><span>import</span> <span>sys</span>
<span>from</span> <span>functools</span> <span>import</span> <span>partial</span>


<span>for</span> <span>i</span>, <span>line</span> <span>in</span> <span>enumerate</span>(<span>sys</span>.<span>stdin</span>, <span>1</span>):
    <span>line</span> <span>=</span> <span>line</span>.<span>rstrip</span>(<span>"<span>\r</span><span>\n</span>"</span>)
    <span>n</span> <span>=</span> <span>max</span>(<span>len</span>(<span>line</span>), <span>n</span>)  <span># No wrapping</span>

<span>print</span>(<span>n</span>)</pre></div>
<h3 tabindex="-1" id="user-content-pre-and-post-codes--b-code---pre-code---a-code---post-code" dir="auto"><a href="#pre-and-post-codes--b-code---pre-code---a-code---post-code">Pre and Post codes. <code>-b CODE, --pre CODE</code>,  <code>-a CODE, --post CODE</code></a></h3>
<p dir="auto">The code specified with <code>-b CODE, --pre CODE</code> will be added before the loop processing or the main code. This can be useful for declaring variables or performing any necessary setup before entering a loop or executing the main code. The code specified with <code>-a CODE, --post CODE</code> will be added after the loop processing or the main code. This can be useful for displaying aggregated results or performing any additional actions after the loop or main code execution.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ ppp rec --pqrn -b 'TOTAL = 0' -b 'MAX = 0'  'TOTAL += int(rec[0])' 'MAX = max(MAX, int(rec[0]))'  -a 'print(f&quot;TOTAL: {TOTAL}&quot;)' -a 'print(f&quot;MAX: {MAX}&quot;)'"><pre>$ ppp rec --pqrn -b <span><span>'</span>TOTAL = 0<span>'</span></span> -b <span><span>'</span>MAX = 0<span>'</span></span>  <span><span>'</span>TOTAL += int(rec[0])<span>'</span></span> <span><span>'</span>MAX = max(MAX, int(rec[0]))<span>'</span></span>  -a <span><span>'</span>print(f"TOTAL: {TOTAL}")<span>'</span></span> -a <span><span>'</span>print(f"MAX: {MAX}")<span>'</span></span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="import sys
from functools import partial


TOTAL = 0   # PRE
MAX = 0     # PRE

for i, line in enumerate(sys.stdin, 1):
    line = line.rstrip(&quot;\r\n&quot;)
    rec = line.split('\t')
    TOTAL += int(rec[0])
    MAX = max(MAX, int(rec[0]))

print(f&quot;TOTAL: {TOTAL}&quot;)  # POST
print(f&quot;MAX: {MAX}&quot;)      # POST"><pre><span>import</span> <span>sys</span>
<span>from</span> <span>functools</span> <span>import</span> <span>partial</span>


<span>TOTAL</span> <span>=</span> <span>0</span>   <span># PRE</span>
<span>MAX</span> <span>=</span> <span>0</span>     <span># PRE</span>

<span>for</span> <span>i</span>, <span>line</span> <span>in</span> <span>enumerate</span>(<span>sys</span>.<span>stdin</span>, <span>1</span>):
    <span>line</span> <span>=</span> <span>line</span>.<span>rstrip</span>(<span>"<span>\r</span><span>\n</span>"</span>)
    <span>rec</span> <span>=</span> <span>line</span>.<span>split</span>(<span>'<span>\t</span>'</span>)
    <span>TOTAL</span> <span>+=</span> <span>int</span>(<span>rec</span>[<span>0</span>])
    <span>MAX</span> <span>=</span> <span>max</span>(<span>MAX</span>, <span>int</span>(<span>rec</span>[<span>0</span>]))

<span>print</span>(<span>f"TOTAL: <span><span>{</span><span>TOTAL</span><span>}</span></span>"</span>)  <span># POST</span>
<span>print</span>(<span>f"MAX: <span><span>{</span><span>MAX</span><span>}</span></span>"</span>)      <span># POST</span></pre></div>
<h3 tabindex="-1" id="user-content-inner-loop--e-code---loop-head-code--f-code---filter-code" dir="auto"><a href="#inner-loop--e-code---loop-head-code--f-code---filter-code">Inner loop. <code>-e CODE, --loop-head CODE</code>, <code>-f CODE, --filter CODE</code></a></h3>
<p dir="auto">In the loop processing of <code>line</code>, <code>rec</code>, <code>csv</code>, and <code>file</code> commands, the code is added in the following positions:</p>
<div data-snippet-clipboard-copy-content="for ... :
    {loop_head}  # Added with the -e CODE, --loop-head CODE option.
    {filter}     # Added with the -f CODE, --filter CODE option.
    {main}       # The main code is added here."><pre><code>for ... :
    {loop_head}  # Added with the -e CODE, --loop-head CODE option.
    {filter}     # Added with the -f CODE, --filter CODE option.
    {main}       # The main code is added here.
</code></pre></div>
<p dir="auto">"loop_head" is added using the <code>-e CODE, --loop-head CODE</code> option, while "filter" is added using the <code>-f CODE, --filter CODE</code> option.
Please note that the "loop_head" code is added as-is, while the "loop_filter" is wrapped with <code>if not ({}): continue</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ ppp line -pqrn -e 'line = line.replace(&quot;foo&quot;, &quot;bar&quot;)' -e 'line = line.upper()' -f '&quot;BAR&quot; in line' 'print(line)'"><pre>$ ppp line -pqrn -e <span><span>'</span>line = line.replace("foo", "bar")<span>'</span></span> -e <span><span>'</span>line = line.upper()<span>'</span></span> -f <span><span>'</span>"BAR" in line<span>'</span></span> <span><span>'</span>print(line)<span>'</span></span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="import sys
from functools import partial

for i, line in enumerate(sys.stdin, 1):
    line = line.rstrip(&quot;\r\n&quot;)
    line = line.replace(&quot;foo&quot;, &quot;bar&quot;)  # LOOP_HEAD
    line = line.upper()                # LOOP_HEAD
    if not (&quot;BAR&quot; in line): continue   # FILTER
    print(line)                        # MAIN"><pre><span>import</span> <span>sys</span>
<span>from</span> <span>functools</span> <span>import</span> <span>partial</span>

<span>for</span> <span>i</span>, <span>line</span> <span>in</span> <span>enumerate</span>(<span>sys</span>.<span>stdin</span>, <span>1</span>):
    <span>line</span> <span>=</span> <span>line</span>.<span>rstrip</span>(<span>"<span>\r</span><span>\n</span>"</span>)
    <span>line</span> <span>=</span> <span>line</span>.<span>replace</span>(<span>"foo"</span>, <span>"bar"</span>)  <span># LOOP_HEAD</span>
    <span>line</span> <span>=</span> <span>line</span>.<span>upper</span>()                <span># LOOP_HEAD</span>
    <span>if</span> <span>not</span> (<span>"BAR"</span> <span>in</span> <span>line</span>): <span>continue</span>   <span># FILTER</span>
    <span>print</span>(<span>line</span>)                        <span># MAIN</span></pre></div>
<h3 tabindex="-1" id="user-content-import-modules--i-module---import-module" dir="auto"><a href="#import-modules--i-module---import-module">Import modules. <code>-i MODULE, --import MODULE</code></a></h3>
<p dir="auto">By using the <code>-i MODULE, --import MODULE</code> option, you can import any modules. If the value specified with <code>--import</code> is in the form of a sentence, like <code>import math</code> or <code>from math import sqrt</code>, it will be added as an import statement just as it is. If only the module name is provided, like <code>math</code>, it will automatically be given an import statement, such as <code>import math</code>.</p>
<p dir="auto">ppp text -i zlib -i 'from base64 import b64encode' 'b64encode(zlib.compress(text.encode()))'</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ ppp text -pqrn -i zlib -i 'from base64 import b64encode' 'print(b64encode(zlib.compress(text.encode())))'"><pre>$ ppp text -pqrn -i zlib -i <span><span>'</span>from base64 import b64encode<span>'</span></span> <span><span>'</span>print(b64encode(zlib.compress(text.encode())))<span>'</span></span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="import sys
from functools import partial
import zlib                    # <- HERE
from base64 import b64encode   # <- HERE

text = sys.stdin.read()
print(b64encode(zlib.compress(text.encode())))"><pre><span>import</span> <span>sys</span>
<span>from</span> <span>functools</span> <span>import</span> <span>partial</span>
<span>import</span> <span>zlib</span>                    <span># &lt;- HERE</span>
<span>from</span> <span>base64</span> <span>import</span> <span>b64encode</span>   <span># &lt;- HERE</span>

<span>text</span> <span>=</span> <span>sys</span>.<span>stdin</span>.<span>read</span>()
<span>print</span>(<span>b64encode</span>(<span>zlib</span>.<span>compress</span>(<span>text</span>.<span>encode</span>())))</pre></div>
<p dir="auto">Usage example.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ seq 5 |ppp -i math 'line, math.sqrt(int(line))'
1       1.0
2       1.4142135623730951
3       1.7320508075688772
4       2.0
5       2.23606797749979"><pre>$ seq 5 <span>|</span>ppp -i math <span><span>'</span>line, math.sqrt(int(line))<span>'</span></span>
1       1.0
2       1.4142135623730951
3       1.7320508075688772
4       2.0
5       2.23606797749979</pre></div>

</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: How's your job search going in this current economy? (114 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=37981149</link>
            <guid>37981149</guid>
            <pubDate>Mon, 23 Oct 2023 03:06:43 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=37981149">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="37981548"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37981548" href="https://news.ycombinator.com/vote?id=37981548&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>Really, really, really bad. I'm a full stack engineer. I took part of the last 4 years "off" due to having savings and finally settling down to pursue my own SaaS attempt.<p>I've been back in the job market since the beginning of the year. I've probably sent out well over a hundred resumes (definitely over this number since I was keeping track until recently). I had a brief respite when I picked up a temp contract but that only lasted about a month.</p><p>I mostly get just rejections. I have over 15 years of experience. I literally know how to build out every part of a normal web/api stack.</p><p>I even have an active ongoing project I've run for 13 years and have scaled to support a couple million requests a day.</p><p>Nothing seems to matter.</p><p>I have maybe managed to get one actual call a week for the last year where I actually speak to someone from the company. And even then, it's been one "thanks for playing" response email after another.</p><p>I honestly don't know what to do. I've <i>never</i> had a problem at least getting interviews to the point where I'm at least in the consideration process.</p><p>I need help.</p><p>I revised my resume a few times and that hasn't helped. I've gotten more involved with LinkedIn and I get more noise but still low results.</p><p>I'm basically getting very desperate.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37982043"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37982043" href="https://news.ycombinator.com/vote?id=37982043&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>I hope you take this in the spirit it's intended.<p>There's 5 links on your HN profile:</p><p>* One to your personal website that is just "work in progress" and nothing more</p><p>* One to your defunct twitter where you didn't appear to have many followers or did much of note</p><p>* One that just returns an opaque blob of json which I'm not sure how I'm meant to interpret</p><p>* One that seems like an intriguing project that seems pretty trivial on the surface but I'm willing to be convinced is more substantial but with a plus feature "coming soon" for I don't know how long and a twitter account with 12 followers</p><p>* One to a github project that you haven't touched in 9 years, also with a bunch of things you've been meaning to work on for a while but clearly haven't.</p><p>I'm willing to be disabused of this notion but my instinct via this gestalt is that you're someone who likes to overpromise and underdeliver. My question would be, what have you been doing in the last 9 months if you haven't had time to polish these bits of your public surface area?</p><p>That's probably an unfair judgement from me and in a hotter hiring environment, I'd be willing to bring you in so you could disabuse me of my prejudice and I could be pleasantly surprised but it's much easier now to filter based on trivial gut feel like this and you should be more conscious of the digital image you're putting out into the world because HMs won't bother telling you this stuff because it's an awkward conversation with no gain on their end.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37982134"><td></td></tr>
                <tr id="37982581"><td></td></tr>
                        <tr id="37981638"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37981638" href="https://news.ycombinator.com/vote?id=37981638&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>Have you tried working with recruiters? In my experience applying directly might as well be sending your resume directly into a black hole. If you turn on the “looking for work” setting on linked in you’ll probably get plenty of opportunities to interview. I was interviewing in the spring and I had a few interviews lined up within a week this way.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37981691"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37981691" href="https://news.ycombinator.com/vote?id=37981691&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>Is location a factor in your search. I'm seeing some openings around bay area but all remote opportunities have dried up.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37981720"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37981720" href="https://news.ycombinator.com/vote?id=37981720&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>Nah. I live in SF. I'm fine with going to an office. I'm fine with anything at this point.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37981807"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37981807" href="https://news.ycombinator.com/vote?id=37981807&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>Take this for what it's worth, but a recruiter that I know has told me that a lot of companies in California are now reaching out to recruiters to hire out of state for the obvious reason - lesser pay. Something to ponder. If you're really desperate maybe look into other regions.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="37981694"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37981694" href="https://news.ycombinator.com/vote?id=37981694&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>Bad.<p>DevOps/Software Engineer with 20+ years experience. ~100 applications this year, a good number of interviews, but no offers yet. (2.5 calls this week scheduled)</p><p>It seems I either get:</p><p>- proto-startups with ~5 people and no concrete revenue stream, or</p><p>- 5k-person enterprises who want someone with a very specific skillset</p><p>Both are fine, but they're picky... as am I, so I'm doing my own consulting for a bit.</p><p>What happened to startups? What happened to the thousands of 50-300 person companies who need tech work done? The other day a headhunter called me... because they were bored! Rather different from last year when they were juggling 4-5 excited companies in front of me.</p><p>Given my experience, I'll be giving a "Fast Developer/Startup" class to a number of companies. That'll turn into a day-long workshop that will be very valuable :)</p><p>Strategies:</p><p>- DON'T TAKE IT PERSONALLY</p><p>- find roles on e.g. LinkedIn, but _never_ do "fast apply": go to the company's site and apply directly</p><p>- use a "highlight positives/negatives" tool to draw certain words in a web page different colors. By interactively seeing a mass of green (or orange) you can quickly make a YES or NO decision on a role. I adore the Chrome plugin Highlight This -- <a href="https://highlightthis.net/" rel="nofollow noreferrer">https://highlightthis.net/</a></p><p>- apply for jobs on a schedule (e.g. Mon-Wed-Fri), don't just struggle for hours at a time, it's soul-sucking.</p><p>- do Studying (job-related tech) interspersed with Fun Programming (generative art!) -- have fun!</p><p>- take care of your health and family, go outside and take walks</p><p>- DON'T TAKE IT PERSONALLY
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37982085"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37982085" href="https://news.ycombinator.com/vote?id=37982085&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>&gt; who want someone with a very specific skillset<p>I’m also probably going to look for a job soon. Do you think that being very skilled in a niche could help if there is work in that niche or would you think that even those jobs are gone?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37981465"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37981465" href="https://news.ycombinator.com/vote?id=37981465&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>There may be a bias here due to some correlation between employment status and participation in online discussion forums.<p>Anyway, for what it's worth, I've heard it is increasingly difficult for experienced devs to get jobs now.  I know that my team has more or less had a hiring freeze for about 18 months now, even though the company is doing better than ever.</p><p>Based on nothing more than headlines I've read, it seems the CEO class got spooked about the economy last year and hasn't eased up yet.  It doesn't help that interest rates are high, which typically bodes poorly for tech(despite megatech having plenty of cash right now due to a number of factors, along with debt held at mostly low, fixed rates).  Many, many smart folks thought the economy would have died last year.  My guess is that we are largely avoiding it thanks to near-record levels of debt-based federal spending(govt debt more or less becomes an asset to private sector). If high rates force the feds to cut spending(unlikely, given war and going into an election year), I think we'll see things cool quickly, but barring that I'm not so sure the economy is going to crash anytime soon. Some sectors, yes.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37981515"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37981515" href="https://news.ycombinator.com/vote?id=37981515&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>CEO class is spooked by either haemorrhaging money during Covid or haemorrhaging after (depending on what kind of company is was).<p>Then economy was “definitely a recession coming” for like 12 months. I think people are waiting for a rate cut to unclench their sphincter and start hiring again.</p><p>That, and likely it all got a bit over the top anyway. When you have Meta product managers with TikTok videos about how cushy their job is, you know there was a bubble.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37981533"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37981533" href="https://news.ycombinator.com/vote?id=37981533&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>Cosign though seeming teleports off the rails in the 3rd para. Never understood peoples obsession with that video</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="37981440"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37981440" href="https://news.ycombinator.com/vote?id=37981440&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>It started great, I thought, then turned bad. Unfortunately I turned down an offer that likely would have been worth taking at this point.<p>I’m probably doing something wrong. I’ve likely made 50 applications at this point. 10-15 were earlier on and went well; I had around 5 roles to interview for and 3 went to final stages. One was a no, the other took too long, and the other was an offer. Things seemed to be going alright and the offer wasn’t great, so I kept at it.</p><p>Of the 30ish applications since, I’ve had 6 responses. 3 no, one bad interview, and two upcoming interviews I don’t feel too confident in. I’m well suited to everything I apply to, but sometimes you can just feel it. I don’t think these companies will see me as a good fit.</p><p>I’m about to ramp it up quite a bit and apply more and more often. Unfortunately I’ve been in the midst of a big move, so finding time to sit and focus on job searching hasn’t been easy. Fortunately, I’m done moving. Here’s hoping it goes well.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37981429"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37981429" href="https://news.ycombinator.com/vote?id=37981429&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>Pretty bad. I’ve got a lot of experience as an IC, manager, and leader, and it doesn’t seem to matter; companies seem much more picky (“you were great but we want someone with more tenure in &lt;specific variant of field&gt;”) or wedded to cargo cult methods (the leetcode places).<p>I haven’t extensively tapped my network for referrals, but I get a bad vibe from those, too. I’ve hit up about six folks and they all came back empty - no opportunities, even though they’d like to work with me again.</p><p>The only success I’ve heard is from folks grinding it out and playing the numbers game. It’s an employer’s market.</p><p>Edit: some data:
Seven months, dozens of applications, four interviews. Two interviews were from applications, one from a recruiter cold-call, and one from networking. Applications to interview was about 4 months. Three were EM positions, one was senior engineer. Got through all rounds and was rejected at the end.</p><p>Fun fact: I have a canary in my resume that will normally raise a clarifying question during an interview. One of ~20 interviewers caught it. Hard to put effort into a resume when few people seem to read it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37981455"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37981455" href="https://news.ycombinator.com/vote?id=37981455&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>My network has been dry as well. I got some contract work, but nothing reliable/full time/long term.<p>So strange to go from too many jobs to even begin considering to nothing at all.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37981561"><td></td></tr>
            <tr id="37981722"><td></td></tr>
                <tr id="37981889"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37981889" href="https://news.ycombinator.com/vote?id=37981889&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>I use one that's to the effect of: migrated legacy Go project to Python2, increasing E2E service latency by 3409ms.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37982057"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37982057" href="https://news.ycombinator.com/vote?id=37982057&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>sounds like a good way to get rejected rather than for someone to want to pry deeper, when faced with a stack of resumes</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37981989"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37981989" href="https://news.ycombinator.com/vote?id=37981989&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>It was a random (and facetious and probably bad) idea to include a bullet point that would elicit a “wait, what?” response from anyone who would read it. My resume highlights, as an academic achievement, that a professor once suspected me of illegal research.<p>If someone brings it up, I’ll know they read through my resume. If they don’t bring it up, it may mean nothing. The former is a green flag, to me.</p><p>I’d suggest something more innocuous sounding, though. “Level 3 pencil twirler” or something that would elicit some conversation.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="37981316"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37981316" href="https://news.ycombinator.com/vote?id=37981316&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>It is taking a while for me. Seemingly lots of jobs out there and I have been interviewing constantly. I've had four final stage interviews and rejected for all of them. I have more screeners lined up, and one promising prospect that is taking a long time. I'm told that everyone is at a summit which is what is slowing down the process.<p>I get a lot of 3rd party recruiters that seem to follow a similar MO: the recruiters are all people with south Asian names, calling from US numbers (I'm in Canada), with a vague job description, they want to hire me hourly, and they are cagey about the company that they are hiring me for. They ask for my CV, my work status, and what "project" I was on. They don't really seem to consider getting hired full time, they only talk about contract work. I have never progressed with them beyond giving them my CV and an authorisation to "represent" me (letting them act as a middle man).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37981414"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37981414" href="https://news.ycombinator.com/vote?id=37981414&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>Im glad I answered such messages from such a type of recruiter.  I work at amazing place because I did and yet I put them through the ringer to prove to me they were legit.  Sorta feel bad some for doing that but protecting myself according then and still now (they did say they wouldn't pay me until 30 days which is how i am pay six years later).  As if any recruiter came to me asking for my social ... asking for money ... asking me to buy something... asking anything outside of how I am qualified for XYZ position the conversation would end.<p>So be very cautious and protect yourself from scams, but from what you describe they sound like the type of recruiters who got me where I am after six very happy and stress free years (UX Engineer).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37981741"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37981741" href="https://news.ycombinator.com/vote?id=37981741&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>Did you get any insight into how and why these recruiters operate? The parent comment makes it sound liked it's all about contacting, but you got a full-time position. What's up with that?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37982247"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37982247" href="https://news.ycombinator.com/vote?id=37982247&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>This was an Indian owned recruiter firm with offices in California and in India.  I work for an Indian IT firm based in the states (remote since Covid but worked in the office for two years).<p>The Indian recruiting firm were a 2ndary / sub contracted firm by the recruiting firm who had the contract with my employer to find a UX Engineer. It was fishy indeed especially saying I wasn't going to get paid for 30 days yet I forced them to pay me in two weeks for the first check to soothe my worries.</p><p>Overall if they are contacting you and only asking normal questions and not ones that ring of scam they could be like the Indian firm and they are fishing for the best candidates to send to their client..the primary contractor.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="37981338"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37981338" href="https://news.ycombinator.com/vote?id=37981338&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>&gt;I get a lot of 3rd party recruiters that seem to follow a similar: the recruiters are all people with south Asian names, calling from US numbers (I'm in Canada), with a vague job description, they want to hire me hourly, and they are cagey about the company that they are hiring me for. They ask for my CV, my work status, and what "project" I was on.<p>I've heard of scams where fake recruiters use real peoples' names and résumés to get hired at remote jobs, then substitute in their own Indian or other non-American worker.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37981408"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37981408" href="https://news.ycombinator.com/vote?id=37981408&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>How would that work? They have to get interviewed by the hiring company. I've never gotten to that stage via these 3rd party recruiters.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37981602"><td></td></tr>
                <tr id="37981682"><td></td></tr>
                                    <tr id="37981454"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37981454" href="https://news.ycombinator.com/vote?id=37981454&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>Pretty rough. I'm a senior manager/director (manage software dev managers), 20 years industry, the last 8 in big tech. I've been searching for 2 months, applied to 80 roles at 50 companies...only had three recruiter calls and trying to schedule my first phone screen. Surprised at how slow going it is. Feels like companies are being very selective about who they hire and or which roles they want to fill. I think I have a good CV and I'm barely getting noticed.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37981360"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37981360" href="https://news.ycombinator.com/vote?id=37981360&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>A counter balance: Mine has been fine. I spent 6 years at Meta and was laid off. I found a better paying position and started last month. I interviewed everywhere. Google was a tough slog, I had 3 recruiters laid off while I was team matching. I'm on my 4th recruiter there, but I don't think they can match my current TC and I very much enjoy my current job.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37981410"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37981410" href="https://news.ycombinator.com/vote?id=37981410&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>A higher paying position than Meta!? Very curious to hear as much as you’re willing to share on which company this is</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37981461"><td></td></tr>
                <tr id="37981732"><td></td></tr>
                        <tr id="37981718"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37981718" href="https://news.ycombinator.com/vote?id=37981718&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>What features about your profile or approach do you think made your experience more reasonable compared to the overwhelming negative consensus here?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37981768"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37981768" href="https://news.ycombinator.com/vote?id=37981768&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>I don't know. Most people on HN are in some dimension, at least, qualified for FAANG or better. I have 6 yoe with quite a bit of impact and I've crossed many domains. I've received quite a few offers over the past year but I've also received my fair share of rejections. I just go through the rejections (it's like dating, and heck I've been through rejection there too).<p>I leetcode daily and have a system design study group. I'm honest in interviews, whether that be about a bad decision I've made or a good one. If an interviewer doesn't want me after I've been honest with them, it probably wasn't a good fit anyway.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="37981245"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37981245" href="https://news.ycombinator.com/vote?id=37981245&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>Seems like a lot of unicorn hunting out there, right now.<p>At least for senior data leadership roles, I’ve hit a lot of JDs that were clearly written for one person (either internally, or the random Meta/Google/whatever layoff that this company is sure will take a 75% salary cut for). Networking has been really invaluable. ATS systems seem slightly more inscrutable than when I was looking two years ago (wonder if there’s some weird effect from LLM-enabled resume spam).</p><p>I dunno, it’s not horrible, but it’s definitely worse right now than I remember it in the last five or six years.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37981673"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37981673" href="https://news.ycombinator.com/vote?id=37981673&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>&gt; Seems like a lot of unicorn hunting out there, right now.<p>Agreed, and I feel this is happening across job families - JDs seem much more domain-specific, especially around ML/AI. I don’t remember it being like this. Yes, there is absolutely a distinction between someone working Eng in payments vs infra vs ML, but I remember those being nice-to-haves, not requisites.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37984560"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37984560" href="https://news.ycombinator.com/vote?id=37984560&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>I wish good luck to all job searchers here!<p>On a related note, now it could be the right time to leave your job and create an opening to searchers if you want to have a software business with upfront development time investment. A lot of great businesses get the ball rolling in a recession. If things don't work out, you will probably face a better market on the way back, and your product has a higher chance of hitting a good market when it's ready.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37981685"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37981685" href="https://news.ycombinator.com/vote?id=37981685&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>(Aus) Going poorly for me. Started my current job a year or so ago, been looking to leave since. Probably into the 100s of applications in the last 12 months now; I will apply for most anything with a tech fit even if (for e.g.) a role requires on-site that I'm not interested in, just to try and get a feel for the market by whether or not I get at least a screening call. I've had 2 final stage interviews: knocked back in one and dropped out of the other (red flags). Have also had 2-3 applications get a "this role now on hold, soz" response. So I'm getting just enough interest to keep hope alive. Even the steady stream of LinkedIn PMs for vaguely-related jobs has dried up.<p>I touched up the resume a little bit but otherwise I'm not doing anything a whole lot differently. I was almost allowing myself to quit this ass job if I instead got some vendor certs, but I'm increasingly concerned that a decent job market might years away, not months, so the suffering continues. :)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37981717"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37981717" href="https://news.ycombinator.com/vote?id=37981717&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>Same location, similar situation. I thought it was just me. At least twenty recruiters on my LinkedIn list, and not a peep since I toggled my 'Open to work' status weeks ago. Used to receive a fairly consistent stream of messages when I wasn't ready.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37981877"><td></td></tr>
                        <tr id="37983210"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37983210" href="https://news.ycombinator.com/vote?id=37983210&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>I finished my job search after 5 months and 1 week. After 179 applications, 22 interviews, 2 offers later, I'd say that it's one of the toughest and miserable job market someone can find into. I job search-ed even during the pandemic, and although it was very difficult, imho this one is order of magnitude worse... The Senior you are the better chance you'll have, but there is no market for JR, and I feel so bad for them because I have a few people that I care about that are in that condition and aren't able to find almost any openings.<p>Unfortunately even if you feel like your resume is super strong, getting a job now requires to literally excel in <i>every single step</i> of the interview and having the luck of having the team feeling you as a <i>perfect fit</i> for the team. Even a single meh would mean instant rejection. There are literally too many great people in job search and companies aren't certainly in a rush to close their openings.</p><p>My perception, and my network seems to confirm this as well, is also that the rate of new opening has slowed down significantly, which means that things are getting harder. I really hope that the market will recover soon for everyone.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37983867"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37983867" href="https://news.ycombinator.com/vote?id=37983867&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>Good. Snapped something up that met my salary expectations after 60 days of searching hard. By hard I mean I abused LinkedIn, I messaged everyone I knew in every company I saw that was actively hiring and asked if they’d refer. Then I messaged everyone else letting them know I was on the market.<p>Then I attended meetups when I wasn’t applying.</p><p>I worked harder getting a job than I am working this current job.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37981176"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37981176" href="https://news.ycombinator.com/vote?id=37981176&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>Its even worse than dot bomb (2000-2004) however is it all github copilot eating these jobs? I think some, but also with the success with remote work I image most roles were simply sent out of the US, and could be an outsourced team with extra help from copilot and other tools.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37981337"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37981337" href="https://news.ycombinator.com/vote?id=37981337&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>&gt; however is it all github copilot eating these jobs?<p>Short answer: No.</p><p>Long answer: No, and it's wild you think this might be the case.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37981551"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37981551" href="https://news.ycombinator.com/vote?id=37981551&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>You're delusional if you think that the rise of Generative AI hasn't been a factor in the relative difficulty of finding a job today.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37981596"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37981596" href="https://news.ycombinator.com/vote?id=37981596&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>I believe it's taking jobs/gigs from creatives, and that we've unfortunately only seen the start of it. But I don't believe it will affect software engineers nearly the same way.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37981793"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37981793" href="https://news.ycombinator.com/vote?id=37981793&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>How do you think the work is getting done now? Are currently employed developers so much faster with GenAI that you need fewer? Are product managers just doing implementation themselves with Copilot?</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37981616"><td></td></tr>
            <tr id="37982131"><td></td></tr>
                        <tr id="37981182"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37981182" href="https://news.ycombinator.com/vote?id=37981182&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>Basically I went back to school to be a pharmacy tech because it seems like a hopeless job market after looking hopelessly for 18 months even after having survived as a web developer since 1995.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37981375"><td></td></tr>
                <tr id="37981417"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37981417" href="https://news.ycombinator.com/vote?id=37981417&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>crazy that they claim to want 10+ years experience but also won't entertain the idea of a 20+ year old veteran. Where are all these mid-30's (assumedly) principles and staff engineers coming from, especially since no one wants to invest in junior engineers the past decade.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37981604"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_37981604" href="https://news.ycombinator.com/vote?id=37981604&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>To be fair, some mid-30s have 20 years of web dev experience. Others have a “lot” of experience because of the quality of the experience gained over a shorter period of time. Some have even fall into both camps.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37981563"><td></td></tr>
                  <tr id="37981317"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37981317" href="https://news.ycombinator.com/vote?id=37981317&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>And companies will still swear up and down that they can't find talent at any price even as talent streams out of the industry to other fields due to being snubbed.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37981666"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37981666" href="https://news.ycombinator.com/vote?id=37981666&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>&gt; Its even worse than dot bomb (2000-2004)<p>I don't know about that, companies were imploding left and right overnight.  Stocks losing 99% of "value" etc.</p><p>With that said, this is the worse I've seen since that time, but really can't say it's worse than dot com meltdown.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37981436"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37981436" href="https://news.ycombinator.com/vote?id=37981436&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>Most of it is the end of free money, super low interest rates, and companies realizing that an unending war for talent isn't needed. More companies are focusing on on making a profit.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37981655"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37981655" href="https://news.ycombinator.com/vote?id=37981655&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>Really slow, more than anything. My own perspective is as a senior technical product manager, mainly dev tools experience, some entrepreneurship, plus coding. I'm only looking for all-remote roles. I've always been a little bit of a unique combo of skills, but for companies that need someone like me, I'm perfect. Now I'm finding there aren't too many jobs posted, that response rates are low, and then hire rates are low at the end of the interview process.<p>I think that the low hire rate comes down to more competition, plus some larger companies maybe have zombie hiring processes where the effort to hire someone continues, but if they find someone the funding disappears.</p><p>I've been trying to supplement with consulting, but I don't have any experience selling myself in that way so progress has been slow. In the meantime I am looking ay it as a good investment to get some experience on that front.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37981586"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37981586" href="https://news.ycombinator.com/vote?id=37981586&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>On the flip side I’m trying to convince my CTO to fire half our engineering team - a group of jokers he hired during the run-up who are now wildly overpaid and massively under-delivering. With all the tech talent out there I’m convinced we’d replace them all within a week.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37983000"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37983000" href="https://news.ycombinator.com/vote?id=37983000&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>&gt;I’m convinced we’d replace them all within a week.<p>If only. It can take a week just to go from recruiter call to the first hiring manager talk. that gauntlet of 4-6 weeks of interviews is what makes me dread the interviewing time the most.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37981617"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37981617" href="https://news.ycombinator.com/vote?id=37981617&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>Extremely rough, getting little-to-no interest on the market with 10+ years of experience. Currently employed but the threat of another massive layoff within my company, and/or the possible elimination of the entire engineering dept. as we know it looms heavy.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37981202"><td></td></tr>
                <tr id="37981216"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37981216" href="https://news.ycombinator.com/vote?id=37981216&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>100% agreed,<p>I have been barely able to land an interview where as in 2022 I remember the situation was very different
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37981382"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37981382" href="https://news.ycombinator.com/vote?id=37981382&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>Doesn’t budget open up more in Q1 as opposed to Q4? Isn’t Q4 just generally a bad time to be looking, with upcoming holidays, at least in the US?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37984595"><td></td></tr>
                  <tr id="37981389"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37981389" href="https://news.ycombinator.com/vote?id=37981389&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>Well yeah, that was the tail end of the crazy times. I have seen an uptick in recruiter messages since August-ish tho</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37982022"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37982022" href="https://news.ycombinator.com/vote?id=37982022&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>Feels like bragging ... but mine went incredibly well. Wrote 4 initiative applications. This is in Germany and without any job experience outside of academia.<p>One quickly came back telling me that they did not do what I was applying for at the location I was applying at. Would I be willing to move for the job? No.</p><p>One invited me for interviews which I messed up.</p><p>One offered me a job after a first interview.</p><p>Then I stumbled upon a perfect match job description. Applied, went through 4 rounds of interviews and got the job.</p><p>So 2.5 out of 4 applications.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37983868"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37983868" href="https://news.ycombinator.com/vote?id=37983868&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>I mean it's not that bad, but companies can be very picky.<p>There is also the issue of job posts that are not real, in the sense that the company isn't actually hiring. Unless maybe a unicorn drops on them I guess.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37981300"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37981300" href="https://news.ycombinator.com/vote?id=37981300&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>My job search has been admittedly limited in scope, but so far I’ve received two rejection letters and from the rest complete silence. I’m not at all optimistic if I have to switch jobs next year.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37981464"><td></td></tr>
                <tr id="37982989"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37982989" href="https://news.ycombinator.com/vote?id=37982989&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>Guessing a lot of companies are on hiring freezes (official or not). economy forecasts are bad and no more low interest rates, so companies are downscaling their growth aspects and switching to focusing on core products.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="37981384"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37981384" href="https://news.ycombinator.com/vote?id=37981384&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>much slower than when I got laid off in 2022 that's for sure. But I'm not changing much of my strategies and I was in fact pickier.<p>got laid off again in May and took a break until September, which of course seemed to be the worst time for my industry. calls were extremely slow in September but I still got a few. got a more typical recruiter reach out in October. More early rejections than last time (i.e. past a recruiter call but not past the first team call), but IDK if that's more on my roles (I am being pickier than last time) or the current state.</p><p>I did get a LOT more auto rejects than before. I feel like I applied to more roles this time despite a narrower selection, so I don't know if that's simply a more representative result compared to last year or not.</p><p>I seem close to an offer I'll take but I have 3 other interviews to go for if it falls through. so, hopefully it ends with 2 months of job searching, which is about as good as last time. I took a break since I got laid off twice in 12 months and didn't want to rush to a new role like last time, but I probably would have accelerated my options if I knew it would get this bad this quickly.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37981773"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37981773" href="https://news.ycombinator.com/vote?id=37981773&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>Not really good. I quit my FAANG job just before the layoffs started (If only I had known...) to pursue a SaaS project. I was the top performer in the team back then. I recently reached out to my manager about getting back into the team but the hiring freeze is still very much ongoing and going to last atleast 6 more months based on his feedback.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37982389"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37982389" href="https://news.ycombinator.com/vote?id=37982389&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>I stopped 3 months ago. It's not worth the effort. Unless you know someone or find a very specific job that you perfectly fit, it's an up-hill battle. For now with the high rates, the economy is doing badly. But it could get worse. I'll wait for a few weeks and see how the situation in the Middle-East will resolve. An enlargement of the conflict is going to send energy prices to the moon. The economy will be an order of magnitude by then.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37982042"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37982042" href="https://news.ycombinator.com/vote?id=37982042&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>Not so great. Not a single call yet. This after having spent over a decade as CTO at a startup, built all products and teams from scratch. Dont know where I am going wrong. But.. hope is what makes the world go round!</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37981577"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37981577" href="https://news.ycombinator.com/vote?id=37981577&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>I am employed and looking to relocate to the Bay area. I’ve been applying for a few weeks and am going into a third round interview this upcoming week. I am getting responses from established startups, nada from big tech. I’m looking at leadership roles for the first time so I’m not sure what to expect. A decade ago when I took my current job, I was looking at 4 offers after 6 weeks of applying.<p>There seem to be a lot of open positions, but I suspect not compared to the number of folks on the market. Big tech just dumped a bunch of folks. “Regular tech” seems to be doing fine.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37983591"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37983591" href="https://news.ycombinator.com/vote?id=37983591&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>Good. 1 Application - 1st Interview - 2nd Interview - Job Offer<p>2 YoE - Cloud Data Engineer - new Job is DevOps Engineer - Location Germany
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37981552"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37981552" href="https://news.ycombinator.com/vote?id=37981552&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>Pretty good, actually, although I've just been using LinkedIn recruiters. It's important to optimize your profile such that you get recruiters to contact you. I usually have 5-10 recruiter messages per day asking me to work for some company or another. A lot of them are startups though, which is risky in this climate, as I've heard many that got fired or laid off from their startup job this year.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37981706"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37981706" href="https://news.ycombinator.com/vote?id=37981706&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>To be honest pretty good. But I made the transition from employee to being an independent contractor just before the market turned around. Now a new project is just a few emails away, because I have quite a bit of clients in my network for whom I already completed a lot of work. But its all temporary (but still enough to fill 6-12 months at any given moment).</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37981742"><td></td></tr>
                <tr id="37982955"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37982955" href="https://news.ycombinator.com/vote?id=37982955&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>It's interesting because most of my first calls came from recuiters, but the role I'm currently farthest in came from an ol' fashioned "find the website and fill out application".<p>I think it depends on company size. large companies are a crapshoot no matter what (and by some point you will probably simply have recruiters come to you). mid sized companies (~200-1000) work best by contacting either a person you know at the company or a recruiter. Small companies that fit your interests and startups (the ones that aren't "growing like crazy") seems to still work fine with the resume submission pipeline in my experience.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37981306"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37981306" href="https://news.ycombinator.com/vote?id=37981306&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>I’m not sure what it’s like in your industry compared to the one I work in, but I have recruiters cold call me all the time asking me if I would be willing to switch jobs. 
Some of the recruiters get my details off of a job seeker website I am on (that’s not LinkedIn), and they contact me. I literally had a recruiter cold call me today.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37982515"><td></td></tr>
                  <tr id="37981846"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37981846" href="https://news.ycombinator.com/vote?id=37981846&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>Could be worse. Happy in current role but explored the market recently with 6 applications and received: 1 no, 2 interviews, and 3 never even replied.<p>Will see how the process unfolds, I definitely noticed a reduced variety of roles compared to last year.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37981661"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37981661" href="https://news.ycombinator.com/vote?id=37981661&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>Terrible (I'm available, React, TS, Python, DevOps and prod support experience. You can find my contacts if you click on my username).<p>I'm curious why you're asking though? Wanting to switch and testing the water? Looking yourself and having a hard time?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37981399"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37981399" href="https://news.ycombinator.com/vote?id=37981399&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>I just can't find anything as a DevOps/SRE. I had only a few technical interviews over the past 3 months, didn't pay enough attention to details when fixing a broken python program during a live coding interview, not sure why I was rejected in another case. Other than that, I can't get past HR interview and even getting to that point is difficult, in most cases my job application are not even answered with a rejection.<p>Surviving only thanks to a food pantry and a house I bought for 30k$ in East Cleveland. Doing some upwork and garden work so that I can pay for utilities and taxes.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37981589"><td></td></tr>
                  <tr id="37982391"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37982391" href="https://news.ycombinator.com/vote?id=37982391&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>Terrible. I am apparently the only front end developer on the planet without at least 3 years of react experience. I’ve got a third interview next week for a company I’m not particularly excited about, but at least it would be a job.<p>I don’t mind interviewing, I just hate the pressure and uncertainty of job hunting in general. Just give me some work to do, already.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37981320"><td></td></tr>
                <tr id="37981439"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37981439" href="https://news.ycombinator.com/vote?id=37981439&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>i’ll get called a paid actor but i legit used rezi when i was laid off in December 22 and it was a big help. I got a job in February 23 with the help of Rezi. Would recommend. Just use it wisely.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37982583"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37982583" href="https://news.ycombinator.com/vote?id=37982583&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><p><span>could you explain how it helped?<p>other than AI support to write your job descriptions and cover letter i don't see anything useful
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37981825"><td></td></tr>
                  <tr id="37981365"><td></td></tr>
                <tr id="37981829"><td></td></tr>
            <tr id="37981450"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37981450" href="https://news.ycombinator.com/vote?id=37981450&amp;how=up&amp;goto=item%3Fid%3D37981149"></a></center>    </td><td><br><div>
                  <p><span>True. Advertising to help people is such a dick move! Much better to provide “there there pet” style comments and harvest some karma.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Thousands of programmable DNA-cutters found in algae, snails and other organisms (142 pts)]]></title>
            <link>https://phys.org/news/2023-10-thousands-programmable-dna-cutters-algae-snails.html</link>
            <guid>37981109</guid>
            <pubDate>Mon, 23 Oct 2023 02:58:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://phys.org/news/2023-10-thousands-programmable-dna-cutters-algae-snails.html">https://phys.org/news/2023-10-thousands-programmable-dna-cutters-algae-snails.html</a>, See on <a href="https://news.ycombinator.com/item?id=37981109">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
										
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2018/amoeba.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2018/amoeba.jpg" data-sub-html="Credit: CC0 Public Domain">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2018/amoeba.jpg" alt="amoeba" title="Credit: CC0 Public Domain" width="800" height="530">
             <figcaption>
                Credit: CC0 Public Domain
            </figcaption>        </figure>
    </div>
<p>A diverse set of species, from snails to algae to amoebas, make programmable DNA-cutting enzymes called Fanzors—and a new study from scientists at MIT's McGovern Institute for Brain Research has identified thousands of them. Fanzors are RNA-guided enzymes that can be programmed to cut DNA at specific sites, much like the bacterial enzymes that power the widely used gene-editing system known as CRISPR. The newly recognized diversity of natural Fanzor enzymes, reported Sept. 27 in the journal <i>Science Advances</i>, gives scientists an extensive set of programmable enzymes that might be adapted into new tools for research or medicine.

										  
											        </p>
										 
										 											  
<p>"RNA-guided biology is what lets you make programmable tools that are really easy to use. So the more we can find, the better," says McGovern Fellow Omar Abudayyeh, who led the research with McGovern Fellow Jonathan Gootenberg.
</p><p>CRISPR, an ancient bacterial defense system, has made it clear how useful RNA-guided enzymes can be when they are adapted for use in the lab. CRISPR-based genome editing tools developed by MIT professor and McGovern investigator Feng Zhang, Abudayyeh, Gootenberg, and others have changed the way scientists modify DNA, accelerating research and enabling the development of many experimental gene therapies.
</p><p>Researchers have since uncovered other RNA-guide enzymes throughout the bacterial world, many with features that make them valuable in the lab. The discovery of Fanzors, whose ability to cut DNA in an RNA-guided manner was reported by Zhang's group earlier this year, opens a new frontier of RNA-guided biology. Fanzors were the first such enzymes to be found in <a href="https://phys.org/tags/eukaryotic+organisms/" rel="tag">eukaryotic organisms</a>—a wide group of lifeforms, including plants, animals, and fungi, defined by the membrane-bound nucleus that holds each cell's genetic material. (Bacteria, which lack nuclei, belong to a group known as prokaryotes.)
</p><p>"People have been searching for interesting tools in prokaryotic systems for a long time, and I think that that has been incredibly fruitful," says Gootenberg. "Eukaryotic systems are really just a whole new kind of playground to work in."
</p><p>One hope, Abudayyeh and Gootenberg say, is that enzymes that naturally evolved in eukaryotic organisms might be better suited to function safely and efficiently in the cells of other eukaryotic organisms, including humans. Zhang's group has shown that Fanzor enzymes can be engineered to precisely cut specific DNA sequences in human cells. In the new work, Abudayyeh and Gootenberg discovered that some Fanzors can target DNA sequences in human cells even without optimization. "The fact that they work quite efficiently in mammalian cells was really fantastic to see," Gootenberg says.
</p><p>Prior to the current study, hundreds of Fanzors had been found among eukaryotic organisms. Through an extensive search of genetic databases led by lab member Justin Lim, Gootenberg and Abudayyeh's team has now expanded the known diversity of these enzymes by an order of magnitude.


											  													    </p>
											  
											  <p>Among the more than 3,600 Fanzors that the team found in eukaryotes and the viruses that infect them, the researchers were able to identify five different families of the enzymes. By comparing these enzymes' precise makeup, they found evidence of a long evolutionary history.
</p><p>Fanzors likely evolved from RNA-guided DNA-cutting bacterial enzymes called TnpBs. In fact, it was Fanzors' genetic similarities to these <a href="https://phys.org/tags/bacterial+enzymes/" rel="tag">bacterial enzymes</a> that first caught the attention of both Zhang's group and Gootenberg and Abudayyeh's team.
</p><p>The evolutionary connections that Gootenberg and Abudayyeh traced suggest that these bacterial predecessors of Fanzors probably entered eukaryotic cells, initiating their evolution, more than once. Some were likely transmitted by viruses, while others may have been introduced by symbiotic bacteria. The research also suggests that after they were taken up by eukaryotes, the enzymes evolved features suited to their new environment, such as a signal that allows them to enter a cell nucleus, where they have access to DNA.
</p><p>Through genetic and biochemical experiments led by biological engineering graduate student Kaiyi Jiang, the team determined that Fanzors have evolved a DNA-cutting active site that is distinct from that of their bacterial predecessors. This seems to allow the <a href="https://phys.org/tags/enzyme/" rel="tag">enzyme</a> to cut its target sequence more precisely the ancestors of TnpB, when targeted to a sequence of DNA in a <a href="https://phys.org/tags/test+tube/" rel="tag">test tube</a>, become activated and cut other sequences in the tube; Fanzors lack this promiscuous activity. When they used an RNA guide to direct the enzymes to cut specific sites in the genome of human cells, they found that certain Fanzors were able to cut these target sequences with about 10 to 20 percent efficiency.
</p><p>With further research, Abudayyeh and Gootenberg hope that a variety of sophisticated genome editing tools can be developed from Fanzors. "It's a new platform, and they have many capabilities," says Gootenberg.
</p><p>"Opening up the whole eukaryotic world to these types of RNA-guided systems is going to give us a lot to work on," Abudayyeh adds.
										 																				
																				</p><div>
																						<p><strong>More information:</strong>
												Kaiyi Jiang et al, Programmable RNA-guided DNA endonucleases are widespread in eukaryotes and their viruses, <i>Science Advances</i> (2023). <a data-doi="1" href="https://dx.doi.org/10.1126/sciadv.adk0171" target="_blank">DOI: 10.1126/sciadv.adk0171</a>
																						
																						</p>
																					</div>
                               											
																					
                              																					 <p>
												  <i>This story is republished courtesy of MIT News (<a href="http://web.mit.edu/newsoffice/" target="_blank">web.mit.edu/newsoffice/</a>), a popular site that covers news about MIT research, innovation and teaching.</i>
											 </p>
										                                        
										<!-- print only -->
										<div>
											 <p><strong>Citation</strong>:
												Thousands of programmable DNA-cutters found in algae, snails, and other organisms (2023, October 13)
												retrieved 23 October 2023
												from https://phys.org/news/2023-10-thousands-programmable-dna-cutters-algae-snails.html
											 </p>
											 <p>
											 This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
											 part may be reproduced without the written permission. The content is provided for information purposes only.
											 </p>
										</div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Killings in the U.S. are dropping at a historic rate (126 pts)]]></title>
            <link>https://www.latimes.com/politics/newsletter/2023-10-20/killings-in-the-u-s-are-dropping-at-an-historic-rate-will-anyone-notice-essential-politics</link>
            <guid>37980609</guid>
            <pubDate>Mon, 23 Oct 2023 01:30:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.latimes.com/politics/newsletter/2023-10-20/killings-in-the-u-s-are-dropping-at-an-historic-rate-will-anyone-notice-essential-politics">https://www.latimes.com/politics/newsletter/2023-10-20/killings-in-the-u-s-are-dropping-at-an-historic-rate-will-anyone-notice-essential-politics</a>, See on <a href="https://news.ycombinator.com/item?id=37980609">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-element="story-body" data-dateline="" data-subscriber-content="">  <p><span>WASHINGTON&nbsp;—&nbsp;</span></p><p>Homicides in the U.S. <a href="https://cde.ucr.cjis.gov/LATEST/webapp/#/pages/explorer/crime/crime-trend" target="_blank">dropped significantly in 2022</a> and have plummeted even faster this year, putting the country on track for one of the biggest declines in killing ever recorded, crime statistics show.</p><p>If that comes as a surprise, you’re not alone.</p><p>Crime did rise nationwide in 2020 and 2021. The disruption caused by a <a href="https://www.latimes.com/world-nation/story/2020-09-22/200000-coronavirus-deaths-in-us">deadly pandemic</a>, a <a href="https://www.latimes.com/world-nation/story/2020-03-15/coronavirus-pandemic-gun-sales-surge-us-california">record increase in the availability of guns</a>, a pullback of policing in some cities and perhaps other factors combined to create a surge in homicides and other crimes.</p><p>That national tide has started to recede, but public perception has not kept pace.</p><div data-click="enhancement" data-align-right=""> <ps-newsletter-module data-id="43" data-module-id="0000016f-686e-de6f-a77f-ed6fa300000c"><div>  <p>Get our Essential Politics newsletter</p>  </div>  <p>The latest news, analysis and insights from our politics team.</p>    <p> You may occasionally receive promotional content from the Los Angeles Times.</p>  </ps-newsletter-module> </div><p>That continues to color the nation’s political debates even as reality increasingly diverges from the rhetoric.</p><h2 id="a-historic-decline">A historic decline</h2>
<p>Let’s start with the numbers.</p><p>The <a href="https://cde.ucr.cjis.gov/LATEST/webapp/#/pages/explorer/crime/crime-trend" target="_blank">FBI’s annual report on the nation’s crime</a> statistics showed a 6% decline in homicides in 2022. The drop exceeded what most crime experts expected, said <b>Jeff Asher</b>, a crime data analyst and consultant whose <a href="https://www.ahdatalytics.com/" target="_blank">AH Datalytics’ site</a> is a widely cited source of information.</p><p>The FBI data, which the bureau compiled from reports filed by 18,888 local police departments, lags nearly a year behind reality. Asher, who puts together data from departments that cover a large majority of the nation’s population, says that so far this year, homicides nationwide have declined 11% to 12%. </p><p>Cities tend to report first and have larger drops than more-rural areas, Asher noted, so he’s projecting the final, nationwide 2023 numbers will show a smaller drop — somewhere between 7% and 10%.</p><p>“A 10% decline would be the largest ever recorded,” he said.</p><p>The decline goes beyond homicides: Violent crime overall ticked down in 2022 across the country, the FBI numbers showed, returning the U.S. pretty much to the level of 2019, before the COVID-19-era increase.</p><p>That’s consistent with the pattern of the last dozen years. Despite some fluctuations, violent crime nationwide has stayed largely at the same level since 2011, when it hit a plateau after 20 years of steady declines.</p><p>That doesn’t mean all categories of crime have declined. Auto thefts, for example, have soared in many parts of the country, in part because of a wave of social media videos publicizing easy <a href="https://www.latimes.com/california/story/2023-05-19/hyundai-kia-reach-settlement-on-vehicles-vulnerable-to-tiktok-theft-challenge">ways to steal Kia and Hyundai cars</a>.</p><p>But “the concept of a violent crime wave — it just really doesn’t exist,” Asher said.</p><h2 id="california-declines-similar-to-u-s">California declines similar to U.S.</h2>
<p>The numbers in California are similar to the national ones: In 2022, the state saw a 6.1% drop in homicides although it had a <a href="https://www.ppic.org/publication/crime-trends-in-california/?utm_source=ppic&amp;utm_medium=email&amp;utm_campaign=epub" target="_blank">5.7% increase in violent crime</a> overall compared with the preceding year, according to data from the Public Policy Institute of California.</p><p>In <a href="https://www.latimes.com/california/story/2023-10-12/violent-crime-is-down-fear-is-up-why-is-la-perceived-as-dangerous">Los Angeles, violent crime has declined</a> nearly 7% so far this year compared with last year, according to Los Angeles Police Department statistics. The city has experienced 1,650 fewer incidents reported as of Sept. 30, the numbers show.</p><p>The public perception is very different. Gallup, for example, has surveyed Americans every fall for years about crime. Last year’s survey found that by <a href="https://news.gallup.com/poll/1603/crime.aspx" target="_blank">56%-28%, Americans said crime had increased</a> in their area. </p><p>That’s almost always true. More Americans said crime increased than decreased in all but four of the last 24 years, Gallup found — the exceptions being 2000, 2001, 2004 and 2018. That was true despite the huge decline in crime nationwide that began in 1991, when crime peaked, and continued through 2011 for violent crime and through 2020 for property crimes.</p><h2 id="anecdotes-shape-perception">Anecdotes shape perception</h2>
<p>Why the gap between perception and reality?</p><p>The power of anecdote explains much of it: In a country of nearly 340 million people, some crime takes place every hour, every day. Those incidents stick in people’s minds, especially when the details are grisly. Vivid stories have far more power than dry numbers to shape how people view their world. And in the social media era, crimes anywhere can be just a click away.</p><p>“Every time there’s a smash-and-grab, it just amplifies in people’s minds that crime’s out of control,” said pollster <b>David Paleologos</b>, director of the Suffolk University polling center, which has <a href="https://www.suffolk.edu/academics/research-at-suffolk/political-research-center/polls/cityview-polls" target="_blank">surveyed residents of many of the country’s major cities</a>.</p><p>Anecdotes have even greater impact when they’re fresh and crime statistics aren’t. Unlike economic statistics, which arrive monthly in real time, the U.S. system for reporting crime data, first set up in the 1930s, remains antiquated and slow. By the time the government reports the data, it’s often too old to inform national debates.</p><p>The localized nature of most crime plays a role too. In any year, whatever the national trend, some city probably will have an uptick in crime — often without a clear cause. This year, for example, Washington, D.C., has suffered a sharp increase in killings, in marked contrast to the nationwide decline. San Francisco has experienced a heavily publicized <a href="https://www.latimes.com/california/story/2023-10-07/san-francisco-police-launches-crackdown-on-retail-crime">rash of retail burglaries</a>. News tends to focus on the unusual, not the routine, so those outliers get disproportionate attention.</p><h2 id="politics-amplifies-fears">Politics amplifies fears</h2>
<p>And, of course, “part of what causes the gap between perception and reality is politics,” said Democratic pollster and strategist <b>Anna Greenberg,</b> whose firm has conducted several studies on public attitudes toward crime.</p><p>Even when crime is declining nationwide, some people live in unsafe neighborhoods and have very real fears about being victimized. Black women, for example, many of whom live in urban neighborhoods with high crime rates, are among the groups who rank crime highest on their list of priorities.</p><p>They’re not, however, the voters who most often back policies traditionally seen as tough on crime — longer sentences, for example, or expanded police powers. Those voters — generally older, conservative and white — often live in relatively low-crime areas. When polled, they frequently rate their own neighborhoods as safe but say crime is rampant elsewhere.</p><p>There’s an obvious racial subtext for many of those voters’ concerns about crime. But race isn’t the only factor. For many voters, worries about crime reflect a concern about “a sense of disorder and chaos” in the world, Greenberg said.</p><p>“That doesn’t come out of nowhere. We’ve been in a very unsettling period in our country,” she added.</p><p>There’s evidence, however, that even if public perceptions of crime remain at odds with reality, voters are less prone to support “lock them up” as a solution.</p><p>Research that Greenberg’s firm has done for Vera Action, a liberal research and advocacy organization, suggests that Democrats often can <a href="https://www.gqrr.com/wp-content/uploads/2023/09/Vera-TrueLine-national-memo-9.18.23-proofed_final-2.pdf" target="_blank">counter Republican messages on crime</a> by stressing their support for measures like expanded mental health treatment and getting guns off the street.</p><p>“A more comprehensive, prevention focus is more popular than just punishing your way out of the problem,” Greenberg said.</p><p>Electoral experience backs up that claim. After the <a href="https://www.latimes.com/world-nation/story/2021-05-21/complete-coverage-death-of-george-floyd-and-trial-of-derek-chauvin">killing of <b>George Floyd</b></a><b> </b>in 2020, when some Democrats on the left embraced <a href="https://www.latimes.com/politics/story/2020-06-08/biden-visits-george-floyd-family-trump-meets-with-police">calls to “defund the police,</a>” Republicans stepped up efforts to tag Democrats as soft on crime. Despite widespread worry among Democratic elected officials, however, that effort fell far short of its goal in both 2020 and 2022, including in the Los Angeles mayoral election, in which <b>Rick Caruso</b> <a href="https://www.latimes.com/california/story/2022-09-21/2022-california-election-los-angeles-mayoral-debate-bass-caruso">leaned heavily on concerns about crime and homelessness</a> in his unsuccessful campaign. </p><p>If that’s true when voters think crime is on the upswing, just imagine what might happen if the country begins noticing that it’s on the way down.</p><div data-click="enhancement" data-border-top="" data-module-id="0000016f-686f-d233-abef-fbff3e3b0008" data-align-left="">    <p>Enjoying this newsletter? Consider subscribing to the Los Angeles Times</p>   <p>Your support helps us deliver the news that matters most. <u><a href="https://www.latimes.com/subscriptions/newsletters.html?utm_source=email&amp;utm_medium=EM&amp;utm_campaign=PNL21&amp;utm_content=essential_politics" target="_blank">Become a subscriber.</a></u></p>    </div><h2 id="replacing-dianne-feinstein">Replacing Dianne Feinstein</h2>
<p><a href="https://www.latimes.com/politics/story/2023-10-16/laphonza-butler-knows-how-to-amass-quiet-power-will-she-win-in-the-public-arena"><b>Laphonza Butler knows how to amass quiet power. Will she win in the public arena?</b></a></p><p>Arriving in California in 2009, <b>Laphonza Butler</b> moved up through the ranks of the state’s powerful labor unions. She wielded her clout quietly, forging connections with politicians and mentors whom she impressed, including now-Vice President <b>Kamala Harris </b>and Gov. <b>Gavin Newsom</b>. An unexpected call from the governor’s office on Sept. 30 suddenly changed Butler’s role. No longer a behind-the-scenes operative, she’s now a front-facing principal, serving the final 15 months of the late Sen. <b>Dianne Feinstein</b>’s term. Noah Bierman, Taryn Luna, Matt Hamilton and Seema Mehta provide this in-depth look at the state’s new senator.</p><p><a href="https://www.latimes.com/politics/story/2023-10-19/laphonza-butler-senate-race-2024-schiff-porter-lee-feinstein-garvey"><b>Sen. Laphonza Butler, caretaker of the late Dianne Feinstein’s seat, won’t run in 2024 election</b></a></p><p>Butler announced Thursday that she would not run for a full Senate term in 2024, Benjamin Oreskes, Mehta and Luna reported.</p><p><a href="https://www.latimes.com/california/story/2023-10-13/california-senator-laphonza-butler-2024-election-feinstein-schiff-porter-lee"><b>In a whirlwind first week, newly appointed Sen. Laphonza Butler acts like a candidate</b></a></p><p>Butler certainly looked like a candidate in her first full week in office, which coincided with a Senate recess. The former EMILY’s List president capitalized on the opportunity, crisscrossing California, attending events — public and private, big and small — in Orange, Los Angeles and San Francisco counties, among other locales, Oreskes, Mehta and Hamilton reported.</p><p><a href="https://www.latimes.com/politics/story/2023-10-16/california-senate-fundraising-update"><b>Adam Schiff outpaces Barbara Lee, Katie Porter in fundraising for California Senate race</b></a></p><p>Rep. <b>Adam B. Schiff</b> continues to hold a strong lead over his rivals in fundraising in the Senate race, bringing in nearly $6 million in campaign contributions in the last three months, according to federal reports released Sunday. Rep. <b>Katie Porter,</b> an Irvine Democrat, raised more than $3.3 million in July, August and September and has brought in about $11 million since joining the race. Rep. <b>Barbara Lee,</b> a Democrat from Oakland, raised about $1 million in the third quarter and has brought in about $3.2 million overall, Laura Nelson reported.</p><p><a href="https://www.latimes.com/politics/story/2023-10-18/los-angeles-newscaster-christina-pascucci-senate-schiff-porter-lee-garvey-feinstein"><b>Los Angeles newscaster Christina Pascucci announces Senate bid</b></a></p><p>Los Angeles newscaster <b>Christina Pascucci</b> announced Wednesday morning that she is joining the Senate race. The 38-year-old Democrat and San Fernando Valley native argues that she offers a centrist option for voters tired of polarization in the nation’s politics, Mehta reported. </p><h2 id="the-latest-from-court">The latest from court</h2>
<p><a href="https://www.latimes.com/politics/story/2023-10-19/sidney-powell-pleads-guilty-to-election-interference-in-georgia-ahead-of-trial"><b>Attorney Sidney Powell pleads guilty in Georgia ahead of trial in Trump 2020 election interference case</b></a></p><p>Attorney <b>Sidney Powell</b> has taken a plea deal in Fulton County, Ga., one day before jury selection was set to begin for her election interference case alongside lawyer <b>Ken Chesebro</b>. Powell is the highest-profile person charged in connection with efforts to keep former <b>President Trump</b> in power to accept a plea deal, Sarah D. Wire reported.</p><h2 id="the-latest-from-washington">The latest from Washington</h2>
<p><a href="https://www.latimes.com/politics/story/2023-10-19/jim-jordan-patrick-mchenry-temporary-house-speaker"><b>Jim Jordan backs empowering Patrick McHenry, a McCarthy ally, as temporary speaker</b></a></p><p>Ohio Rep. <b>Jim Jordan</b> said Thursday he will back empowering North Carolina Rep. <b>Patrick T. McHenry</b>, the House’s temporary speaker, to advance legislation while the GOP continues to squabble over who will lead the House, Erin Logan, Faith Pinho and I reported.</p><p><a href="https://www.latimes.com/politics/story/2023-10-18/jim-jordan-vote-house-speaker"><b>Jim Jordan loses second vote for House speaker but vows to try again</b></a></p><p>On Wednesday the House for the second time declined to elect Jordan as speaker, leaving the chamber in chaos, Logan and Pinho reported.</p><p><a href="https://www.latimes.com/politics/story/2023-10-19/doug-emhoff-jewish-second-gentleman-israel-hamas"><b>Doug Emhoff, America’s Jewish second gentleman, on how he navigated tragedy in Israel and Gaza</b></a></p><p>In his first public remarks since the Oct. 7 Hamas attacks on Israel, an emotional <b>Doug Emhoff</b> spoke of his “deep, visceral connection to Israel and its people,” Courtney Subramanian reported.</p><h2 id="the-latest-from-california">The latest from California</h2>
<p><a href="https://www.latimes.com/environment/story/2023-10-18/newsom-visits-china-to-promote-cooperation-on-climate-change"><b>Despite diplomatic tension, Newsom is going to China to promote cooperation on climate change</b></a></p><p>As rising fossil fuel emissions continue to push global temperatures to record highs, Newsom will head to China next week to meet with officials on such environmental imperatives as offshore wind power, air pollution reduction and the transition to fully electric vehicles, according to the governor’s staff, Hayley Smith, Tony Briscoe and Laurel Rosenhall reported.</p><p><a href="https://www.latimes.com/california/story/2023-10-17/controversial-homeless-shelter-on-l-a-westside"><b>Bass removes commission president after panel delays vote on Westside homeless project</b></a></p><p>Los Angeles Mayor <b>Karen Bass</b> on Monday abruptly removed a veteran city commissioner days after he led his colleagues in delaying a vote on a new Westside homeless facility backed by the mayor, Dakota Smith reported.</p><p><i>Sign up for our </i><b><i>California Politics newsletter</i></b><i> to get </i><a href="https://www.latimes.com/newsletters/california-politics-newsletter" target="_blank"><i>the best of The Times’ state politics reporting</i></a>.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rivian R1T is the first EV to win the longest off-road competition in the US (218 pts)]]></title>
            <link>https://techcrunch.com/2023/10/22/rivian-r1t-is-the-first-ev-to-win-the-longest-off-road-competition-in-the-us/</link>
            <guid>37980323</guid>
            <pubDate>Mon, 23 Oct 2023 00:33:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2023/10/22/rivian-r1t-is-the-first-ev-to-win-the-longest-off-road-competition-in-the-us/">https://techcrunch.com/2023/10/22/rivian-r1t-is-the-first-ev-to-win-the-longest-off-road-competition-in-the-us/</a>, See on <a href="https://news.ycombinator.com/item?id=37980323">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	<p>
						
			<h2>Rebelle Rally has become a proving ground for the EV maker</h2>
		</p>

			
	
			<p><img src="https://techcrunch.com/wp-content/uploads/2023/10/Rivian-rebelle.jpg?w=600">
		</p>
	</div><div>
				<p id="speakable-summary"><span>Motorsports and off-road</span> competition isn’t the typical fodder over here at TechCrunch — unless, of course, there also happens to be a podium-winning team driving an all-electric 2023 Rivian R1T.</p>
<p>The <a href="https://www.rebellerally.com/?playlist=66d89f6&amp;video=559d83d" target="_blank" rel="noopener">Rebelle Rally</a>, the longest off-road map-and-compass rally in the United States, wrapped up Friday evening with a new EV milestone under its belt. This was the first time that a team driving an all-electric vehicle (that would be the Rivian R1T) came in first place. The Rebelle Rally, in which all-women teams competed along a 2,120-kilometer course using only paper maps, compasses, and plotters, is in its eighth year.</p>
<p>The <a href="https://techcrunch.com/2021/09/28/first-drive-rivian-delivers-the-electric-truck-weve-been-waiting-for/" target="_blank" rel="noopener">2023 Rivian R1T</a>, with Lilly Macaruso behind the wheel and Alex Anderson behind the compass and map, took first place in the 4×4 class. (An EV has yet to make the podium in the X Cross class.) Macaruso and Anderson, who are both Rivian employees, came in fourth place in the 2022 Rebelle Rally. This year, in another first, Rivian customer, Many Brezina, took her personally owned R1T in the competition. Brezina, and navigator Alex Gilman, finished 11th.</p>
<div id="attachment_2618403"><p><a href="https://techcrunch.com/wp-content/uploads/2023/10/10-18-23_Day-5_Tim-Sutton_6598.jpg"><img aria-describedby="caption-attachment-2618403" decoding="async" fetchpriority="high" src="https://techcrunch.com/wp-content/uploads/2023/10/10-18-23_Day-5_Tim-Sutton_6598.jpg" alt="Rivian Rebelle Rally" width="1024" height="683" srcset="https://techcrunch.com/wp-content/uploads/2023/10/10-18-23_Day-5_Tim-Sutton_6598.jpg 2000w, https://techcrunch.com/wp-content/uploads/2023/10/10-18-23_Day-5_Tim-Sutton_6598.jpg?resize=150,100 150w, https://techcrunch.com/wp-content/uploads/2023/10/10-18-23_Day-5_Tim-Sutton_6598.jpg?resize=300,200 300w, https://techcrunch.com/wp-content/uploads/2023/10/10-18-23_Day-5_Tim-Sutton_6598.jpg?resize=768,512 768w, https://techcrunch.com/wp-content/uploads/2023/10/10-18-23_Day-5_Tim-Sutton_6598.jpg?resize=680,454 680w, https://techcrunch.com/wp-content/uploads/2023/10/10-18-23_Day-5_Tim-Sutton_6598.jpg?resize=1536,1025 1536w, https://techcrunch.com/wp-content/uploads/2023/10/10-18-23_Day-5_Tim-Sutton_6598.jpg?resize=1200,800 1200w, https://techcrunch.com/wp-content/uploads/2023/10/10-18-23_Day-5_Tim-Sutton_6598.jpg?resize=50,33 50w" sizes="(max-width: 1024px) 100vw, 1024px"></a></p><p id="caption-attachment-2618403"><strong>Image Credits:</strong> Tim Sutton / Rebelle Rally</p></div>
<p>The Rivian R1T, which Anderson and Macaruso playfully nicknamed ‘Timmy,’ is actually considered a bone stock, meaning nothing aside from tires were changed on the vehicle that would affect its performance. However, Macaruso and Anderson, both of whom work Rivian, made a number of modifications to the interior to keep them organized during the event.</p>
<p>Anderson, a senior mechanical engineer at <a href="https://techcrunch.com/tag/rivian/" target="_blank" rel="noopener">Rivian</a>, designed a number of items that her co-workers helped bring to life, including inserts for secure storage of a five-gallon water jug, encasing the interior of the A piller with velcro and fabricating mounts for a shovel and fire extinguisher. Anderson also 3D printed an upper cup holder that hooked onto the center console and a lower tray that sat just below it.</p>
<p>“All of these little changes added up for us,” Anderson said after the Rebelle Rally concluded.</p>
<h2>Proving ground</h2>
<p>The Rebelle has also become a proving ground of sorts for Rivian.</p>
<p>Rivian first came on the Rebelle scene in 2020 when <a href="https://techcrunch.com/author/emme-hall/" target="_blank" rel="noopener">Emme Hall</a>, who is also an automotive journalist and contributor at TechCrunch, drove a pre-production version of the R1T. Rivian has sponsored a team every year since. The EV startup turned publicly traded company has used its experience at Rebelle Rally to workshop ideas and fine tune technology and features that eventually make their way into vehicles that consumers own.</p>
<p>While Rivian engineers told me that <a href="https://stories.rivian.com/software-update-soft-sand-mode" target="_blank" rel="noopener">“sand mode”</a> was always the plan, feedback from Hall as well as Rivian employees who have competed in Rebelle helped the company perfect the drive mode. Rivian’s 2022 Rebelle teams were instrumental in final validation of the software build, according to the company.</p>
<p>The latest example can be found in Rivian’s new 2023.38.0 software. In that OTA software update Rivian added a gauge view, which adapts each drive mode and gives real-time information about the vehicle’s battery <span>and motor temperature, torque, steering angle, pitch and roll and tire pressure.&nbsp;</span></p>
<h2>Charging up in the wilderness</h2>
<div id="attachment_2618402"><p><a href="https://techcrunch.com/wp-content/uploads/2023/10/10-16-23_Day-3_Nicole-Dreon_2717.jpg"><img aria-describedby="caption-attachment-2618402" decoding="async" src="https://techcrunch.com/wp-content/uploads/2023/10/10-16-23_Day-3_Nicole-Dreon_2717.jpg" alt="Rivian Rebelle Rally Renewable Innovations" width="1024" height="681" srcset="https://techcrunch.com/wp-content/uploads/2023/10/10-16-23_Day-3_Nicole-Dreon_2717.jpg 2000w, https://techcrunch.com/wp-content/uploads/2023/10/10-16-23_Day-3_Nicole-Dreon_2717.jpg?resize=150,100 150w, https://techcrunch.com/wp-content/uploads/2023/10/10-16-23_Day-3_Nicole-Dreon_2717.jpg?resize=300,200 300w, https://techcrunch.com/wp-content/uploads/2023/10/10-16-23_Day-3_Nicole-Dreon_2717.jpg?resize=768,511 768w, https://techcrunch.com/wp-content/uploads/2023/10/10-16-23_Day-3_Nicole-Dreon_2717.jpg?resize=680,453 680w, https://techcrunch.com/wp-content/uploads/2023/10/10-16-23_Day-3_Nicole-Dreon_2717.jpg?resize=1536,1022 1536w, https://techcrunch.com/wp-content/uploads/2023/10/10-16-23_Day-3_Nicole-Dreon_2717.jpg?resize=1200,799 1200w, https://techcrunch.com/wp-content/uploads/2023/10/10-16-23_Day-3_Nicole-Dreon_2717.jpg?resize=50,33 50w" sizes="(max-width: 1024px) 100vw, 1024px"></a></p><p id="caption-attachment-2618402"><strong>Image Credits:</strong> Nicole Dreon / Rebelle Rally</p></div>
<p>The Rebelle Rally brings competitors far from established charging stations or gas stations, for that matter. Rebelle has partnered with companies like Pennzoil for gas and Renewable Innovations for green hydrogen. What does green hydrogen have to do with charging an EV?</p>
<p>Renewable Innovations has been providing DC fast chargers for the race since 2020. But until this year, the company used diesel generators to power up the chargers. The intention, Rebelle Rally founder Emily Miller told TechCrunch, was always to use hydrogen.</p>
<p>“The biggest challenge was the EV infrastructure,” Miller told TechCrunch at the finish line of Rebelle Rally 2023.</p>
<p>It took years to find the right partner, build out the infrastructure and secure the 800 kilograms of green hydrogen required for the 10-day event, she added.</p>
<p>Today, there are four charge points available to competitors. These chargers are trailered out to spots along the course for teams driving EVs.</p>
			</div></div>]]></description>
        </item>
    </channel>
</rss>