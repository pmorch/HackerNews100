<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 19 Dec 2023 09:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[The first experimental support for LK99-type superconductivity (110 pts)]]></title>
            <link>https://arxiv.org/abs/2312.10391</link>
            <guid>38691268</guid>
            <pubDate>Tue, 19 Dec 2023 03:01:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2312.10391">https://arxiv.org/abs/2312.10391</a>, See on <a href="https://news.ycombinator.com/item?id=38691268">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2312.10391.pdf">Download PDF</a>
    <a href="https://browse.arxiv.org/html/2312.10391v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>We observe a considerable hysteresis effect of low-field microwave absorption (LFMA) in copper-substituted lead apatite. By continuously rotating samples under external magnetic field, this effect is diminished which can not be renewed by a strong magnetic field but will be spontaneously recovered after two days, indicating its glassy features and excluding possibility of any ferromagnetism. The intensity of LFMA is found to sharply decrease at around 250K, suggesting a phase transition takes place. A lattice gauge model is then employed to assign these effects to the transition between superconducting Meissner phase and vortex glass, and the slow dynamics wherein is calculated as well.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Yao Yao [<a href="https://arxiv.org/show-email/4f44e5db/2312.10391">view email</a>]      <br>    <strong>[v1]</strong>
        Sat, 16 Dec 2023 09:08:54 UTC (1,515 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Unbricking my MacBook took an email to Tim Cook (and a #1 post on Hacker News) (344 pts)]]></title>
            <link>https://www.tokyodev.com/articles/unbricking-my-macbook-took-an-email-to-tim-cook</link>
            <guid>38691025</guid>
            <pubDate>Tue, 19 Dec 2023 02:19:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tokyodev.com/articles/unbricking-my-macbook-took-an-email-to-tim-cook">https://www.tokyodev.com/articles/unbricking-my-macbook-took-an-email-to-tim-cook</a>, See on <a href="https://news.ycombinator.com/item?id=38691025">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>I previously wrote about <a href="https://www.tokyodev.com/articles/not-setting-up-find-my-bricked-my-macbook">how my lost MacBook was returned to me with an Activation Lock on it</a>, and how Apple refused to unlock it for me. Well, I did manage to finally get it unlocked. All it took was an email to Tim Cook. I don’t know how repeatable this process is, but here’s what happened.</p>
<p>After publishing the article, it somehow <a href="https://news.ycombinator.com/item?id=37865941">reached the top of Hacker News</a>. I’d hoped that would trigger someone from Apple to reach out to me, but no one did.</p>
<p>I also shared it with a much smaller audience: a Discord server that I run for English speaking software developers in Japan. <a href="https://www.tokyodev.com/authors/scott-rothrock">Our moderator</a> pointed out that he’d had success in the past by emailing <a href="https://www.tokyodev.com/cdn-cgi/l/email-protection" data-cfemail="a3d7c0ccccc8e3c2d3d3cfc68dc0ccce">[email&nbsp;protected]</a>, as he’d done so in the past and had his assistants escalate things to people who could resolve them for him.</p>
<p>Having exhausted other avenues, I gave it a shot:</p>
<blockquote>
<p>Subject: Activation Lock support requests denied</p>
<p>My lost MacBook was returned to me with Activation Lock on. Despite providing my receipt from the Apple Store, my request to remove the lock has been denied. I wrote an article about my experience that got to the top of the popular social media site “Hacker News”. I’d love to have a happy ending to this frustrating story.</p>
</blockquote>
<p>Four business days later I got a response from one of Tim’s executive assistants in Japan. From there, we exchanged emails and phone calls over the next two weeks, where the assistant was able to get to the bottom of things.</p>
<p>They explained to me that the MacBook was wiped in the middle of August (after I had lost it) and then reported lost by a newly created iCloud account with an email address starting with “p”. My requests to have it unlocked were being rejected as per their policy of not unlocking devices reported as lost, even if an original proof of purchase is provided. However, because of the documentation I was able to provide, they were convinced that it was my MacBook, and thus unlocked it.</p>
<p>Would this have worked had I not been able to reference the article’s performance on Hacker News? I’m not sure, but it seems likely that was at least a contributing factor. After all, I didn’t actually provide the assistant with any more proof than I had submitted with the activation unlock request. That being said, if you have an issue that can’t be resolved via normal channels, emailing Tim Cook is worth a shot.</p>
<h2 id="what-really-happened-to-my-macbook">What really happened to my MacBook</h2>
<p>By this time, I’d already purchased a replacement machine, and so getting the MacBook unlocked was as much about the principle of things as anything else. However, I also wanted my curiosity sated as to what had actually happened.</p>
<p>Apple had provided me with “how” it got locked: the computer was wiped, locked to a new iCloud account, then reported as lost. They didn’t give me the “why” though. Though my original article mentioned it as a theoretical possibility, I saw no incentive for the person who returned my MacBook to do this. So I emailed the person about it reseting the laptop, and after a couple of emails back and forth, I found out more or less what happened.</p>
<p>While the person didn’t reset it themselves, they did take it to a shop, and asked them to unlock it. The shop didn’t unlock it, however, they did reset it. This wasn’t obvious to the person, but they reported that while my login profile information was visible before they gave it to the shop, it wasn’t afterwards, presumably as the Activation Lock was on.</p>
<p>Despite the shop not having unlocked it for the person, they reported that the shop asked to be paid. When pressed on why the shop asked to be paid despite the shop not unlocking it, the person stopped responding.</p>
<p>My theory is that the shop reset the MacBook and reported it as lost with a new Apple ID in order to extort the person.</p>
<p>Perhaps the person didn’t want to admit it, but they actually paid money to the shop, who initially gave it back to them “unlocked”. Later the shop could lock it again by reporting it as lost, as a way to ask for more money from the person again.</p>
<p>Or maybe the shop wanted to ensure they’d be the only one able to unlock it, and so returned the MacBook, telling the person that they found a way to unlock it, but only if the person paid a higher fee than they were willing to pay.</p>
<p>This would explain why the iCloud address started with “p”. The shop saw my name was “Paul McMahon” from the login screen, and so they created an email address that sounded like it could be mine to give them plausible deniability when the person saw the lock screen.</p>
<h2 id="apple-doesnt-consider-this-to-be-a-security-vulnerability-but-maybe-it-should">Apple doesn’t consider this to be a security vulnerability, but maybe it should</h2>
<p>When first activating a MacBook, Apple makes it easy to skip setting up FindMy. But given the severe consequences for not doing so, I think they either need to revise the setup workflow to make this downside abundantly clear, or revisit their unlock policy altogether.</p>
<p>While I was an edge case, having my MacBook taken to an unscrupulous shop by someone who didn’t own it, similarly unscrupulous shops could do the same thing to others. After all, I even wondered about the possibility that I had set up an iCloud email in the past, and had somehow activated the computer with it.</p>
<p>I reported this to <a href="https://security.apple.com/">Apple Security Research</a>, but it was dismissed with “We’re unable to identify a security issue in your report.” I suppose I could have asked my contact at Apple to flag it for further review, but at this point, I’m ready to let it go.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Grindavik [video] (181 pts)]]></title>
            <link>https://www.youtube.com/watch?v=hvcP4kVVOnk</link>
            <guid>38689924</guid>
            <pubDate>Mon, 18 Dec 2023 23:40:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=hvcP4kVVOnk">https://www.youtube.com/watch?v=hvcP4kVVOnk</a>, See on <a href="https://news.ycombinator.com/item?id=38689924">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Lessons from a never-ending personal project (138 pts)]]></title>
            <link>https://siddhesh.substack.com/p/projects</link>
            <guid>38689869</guid>
            <pubDate>Mon, 18 Dec 2023 23:33:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://siddhesh.substack.com/p/projects">https://siddhesh.substack.com/p/projects</a>, See on <a href="https://news.ycombinator.com/item?id=38689869">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F673ab69d-1a20-4aab-8b11-d7387d06e7c8_1682x604.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F673ab69d-1a20-4aab-8b11-d7387d06e7c8_1682x604.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F673ab69d-1a20-4aab-8b11-d7387d06e7c8_1682x604.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F673ab69d-1a20-4aab-8b11-d7387d06e7c8_1682x604.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F673ab69d-1a20-4aab-8b11-d7387d06e7c8_1682x604.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F673ab69d-1a20-4aab-8b11-d7387d06e7c8_1682x604.png" width="1456" height="523" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/673ab69d-1a20-4aab-8b11-d7387d06e7c8_1682x604.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:523,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2173672,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F673ab69d-1a20-4aab-8b11-d7387d06e7c8_1682x604.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F673ab69d-1a20-4aab-8b11-d7387d06e7c8_1682x604.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F673ab69d-1a20-4aab-8b11-d7387d06e7c8_1682x604.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F673ab69d-1a20-4aab-8b11-d7387d06e7c8_1682x604.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption></figcaption></figure></div><p><span>This year I learned that finishing a personal project you’re doing just for yourself is impossible. Irrespective of what it is you’re making and in what medium, it’s impossible to really know what you want and separate it from what you want to want. It’s impossible to set “deadlines” if they’re not real, that is, imposed by an external authority. It’s impossible to start something and, given enough time and input, not have it grow and evolve into something else entirely. It’s impossible to avoid </span><a href="https://en.wikipedia.org/wiki/Scope_creep" rel="">scope creep</a><span>.</span></p><p><span>Some context: I didn’t publish anything on </span><em>Obvious Bicycle</em><span> for the last six months because I’ve been busy writing an essay since March. It’s a piece about music (similar to </span><a href="https://siddhesh.substack.com/p/fav-album-covers" rel="">this one</a><span>), but it’s not meant for this blog, and so I told myself I’d start writing here again </span><em>just as soon </em><span>as I got done with it. Easy peasy.</span></p><p>I thought that piece would take a month or so to write, but I’ve now been at it for nine months, it’s running at 17,000 words (no joke), and is completely out of my control. I used to lie and tell myself that I’d be done with it first by the end of September, then October, and then November, but I eventually learned my lesson. Now I know that it’ll be done when it’s done, whether that’s a month or a decade from now. I’ll keep chipping away at it bits at a time.</p><p>I finally understand what the phrase “it’ll take as long as it takes” means.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F853b475d-2a19-4de4-b9ce-e27e0cf303c3_640x640.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F853b475d-2a19-4de4-b9ce-e27e0cf303c3_640x640.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F853b475d-2a19-4de4-b9ce-e27e0cf303c3_640x640.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F853b475d-2a19-4de4-b9ce-e27e0cf303c3_640x640.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F853b475d-2a19-4de4-b9ce-e27e0cf303c3_640x640.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F853b475d-2a19-4de4-b9ce-e27e0cf303c3_640x640.jpeg" width="330" height="330" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/853b475d-2a19-4de4-b9ce-e27e0cf303c3_640x640.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:640,&quot;width&quot;:640,&quot;resizeWidth&quot;:330,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Nurture - Album by Porter Robinson | Spotify&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Nurture - Album by Porter Robinson | Spotify" title="Nurture - Album by Porter Robinson | Spotify" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F853b475d-2a19-4de4-b9ce-e27e0cf303c3_640x640.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F853b475d-2a19-4de4-b9ce-e27e0cf303c3_640x640.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F853b475d-2a19-4de4-b9ce-e27e0cf303c3_640x640.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F853b475d-2a19-4de4-b9ce-e27e0cf303c3_640x640.jpeg 1456w" sizes="100vw"></picture></div></a><figcaption>Live footage of me once I’m done writing that piece</figcaption></figure></div><p>I generally don’t enjoy writing meta-posts about the process of writing itself or about learning “lessons” from things on this blog (urgh), but exceptions must be made. I learned some weird and valuable stuff from my never-ending-essay.</p><p>The poet Paul Valéry once said that poems are only abandoned, never finished. I’m realizing that every project has a point where the creator, no matter how unsatisfied, has to stop iterating and decide to put what they’ve made out into the world. And it’s always a compromise, because they know every little flaw about the thing they’re making, what about it can and should be improved. They know all the ideas they haven’t had a chance to try out yet, all the features that are yet to be added. There’s always more to do.</p><p><span>Writing my music piece, every time I thought I was happy with a paragraph, I’d read it again in a few weeks and think of something to add to it. Every section in it that I thought was good enough turned out to be not good enough - given enough time, there were </span><em>always, </em><span>always some changes I could think of to make it better. Not a single sentence survived its first-draft stage. Will the piece ever reach a point where I’m perfectly happy with every single thing in it, or do I just have to abandon it and call it quits at some point? Yes.</span></p><p>And if a simple writeup can be iterated and reworked so frequently, I can’t imagine how complex, big budget projects even work. I can’t imagine how film directors must feel watching their own movies, once the dust of production settles. They must hate it, noticing every flaw and every other choice they wanted to make differently but couldn’t due to budget or time constraints. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86a7e758-cbc4-4806-bff5-13204a84c3bc_519x662.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86a7e758-cbc4-4806-bff5-13204a84c3bc_519x662.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86a7e758-cbc4-4806-bff5-13204a84c3bc_519x662.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86a7e758-cbc4-4806-bff5-13204a84c3bc_519x662.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86a7e758-cbc4-4806-bff5-13204a84c3bc_519x662.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86a7e758-cbc4-4806-bff5-13204a84c3bc_519x662.jpeg" width="413" height="526.7938342967245" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/86a7e758-cbc4-4806-bff5-13204a84c3bc_519x662.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:662,&quot;width&quot;:519,&quot;resizeWidth&quot;:413,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;No photo description available.&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="No photo description available." title="No photo description available." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86a7e758-cbc4-4806-bff5-13204a84c3bc_519x662.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86a7e758-cbc4-4806-bff5-13204a84c3bc_519x662.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86a7e758-cbc4-4806-bff5-13204a84c3bc_519x662.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F86a7e758-cbc4-4806-bff5-13204a84c3bc_519x662.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>LMAO</figcaption></figure></div><p>Of course, even this very blog post has better versions that I could continue working towards - I just had to say screw it and hit Publish at one point. It’d be ironic if I never finished the essay about not being able to finish projects.</p><p>Deadlines are great. Anyone who has ever gotten anything done did so because the work was expected from them by a certain date, and not finishing it by then would have consequences.</p><p><span>But there’s another side to it: for any </span><a href="http://www.paulgraham.com/own.html" rel="">project of your own</a><span>, where no one’s really expecting anything, if you simply continue working on it as long as it feels right, it will evolve into something you wouldn’t - and couldn’t - have imagined when you started, in the best possible way. It’ll be unrecognizable from version zero. That’s one reason it’s worth working on something for a long time.</span></p><p>But at some point, if you want said project to be useful and/or seen by the world in any way, you have to stop improoving it and put it out there. Otherwise you’ll end up working on it till eternity with no rewards for your labor. This is what I’m doing now, for better or (mostly) for worse. But where is that “some point”? Nobody knows. If I had the answers I wouldn’t be writing this blog post.</p><p>So the whole thing is basically a push and pull between saying “let’s keep iterating” and saying “this is good enough, let’s ship it”. This is exactly why any product in tech comes out in versions - it’s never perfect, you’re just never done working on it, so you release it in stable chunks and continue iterating. But the same is not possible with art, with paintings and albums and plays - once it’s out, it’s out. So how do directors and writers and musicians decide when something is release-ready? Nobody knows. The answer to that question might be the very definition of having good taste.</p><p><span>One of my favourite sayings is that “if you’re reading it, it’s for you.” Meaning that the things you willingly consume aren’t a coincidence. But I’d go one step further and say that if you’re doing something, then it’s definitely for you, no matter how uncool it is. It’s </span><a href="https://perell.com/note/surrendering-to-your-nature/" rel="">who you are</a><span>.</span></p><p>If I’d been someone cooler than I am, I would’ve spent all this time writing a guitar riff or dirt biking in the desert or something, but instead I wrote an essay on my laptop that I don’t really wanna show anyone. This was an extremely dumb use of my time, and it won’t help me in my career or make me money or get me clout. But I did it anyway, and the best reason for continuing to do it was that I was already doing it in the first place. So it goes.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F64ef41f5-4255-42a2-8835-b6e6672b7e7c_589x139.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F64ef41f5-4255-42a2-8835-b6e6672b7e7c_589x139.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F64ef41f5-4255-42a2-8835-b6e6672b7e7c_589x139.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F64ef41f5-4255-42a2-8835-b6e6672b7e7c_589x139.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F64ef41f5-4255-42a2-8835-b6e6672b7e7c_589x139.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F64ef41f5-4255-42a2-8835-b6e6672b7e7c_589x139.png" width="589" height="139" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/64ef41f5-4255-42a2-8835-b6e6672b7e7c_589x139.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:139,&quot;width&quot;:589,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:15276,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F64ef41f5-4255-42a2-8835-b6e6672b7e7c_589x139.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F64ef41f5-4255-42a2-8835-b6e6672b7e7c_589x139.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F64ef41f5-4255-42a2-8835-b6e6672b7e7c_589x139.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F64ef41f5-4255-42a2-8835-b6e6672b7e7c_589x139.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>PG agrees</figcaption></figure></div><p>So this piece I’m writing is about a topic that requires zero research or further reading. It’s literally me writing about my favourite albums just for the sake of it. So of all things in the world, I should’ve known what I was gonna say, right? Right?! </p><p>This was a topic where I thought I knew what I thought, and all I had to do was write said thoughts down. But that’s not how writing works. It’s not a tool to express what you already perfectly know, but rather a tool to find out what you know by writing down what you think you know. It’s not just a medium of communication, it’s a medium of self-discovery. It’s magic.</p><p>Said Ray Bradbury:</p><blockquote><p>"If you can’t read and write, you can’t think. Your thoughts are dispersed if you don’t know how to read and write. You’ve got to be able to look at your thoughts on paper and discover what a fool you were."</p></blockquote><p><span>A fool indeed. Every time I re-read something I’d written in that piece, I got a more accurate assessment of what I wanted to say and was amazed at how I had </span><em>not conveyed that</em><span> </span><em>at all</em><span>. It was miraculous, honestly, how big the gap was between a) what I thought I thought about a topic, b) what I actually thought about the topic, and c) what I wrote down about the topic. All the rewrites were simply attempts at bridging that gap.</span></p><p>And if this was true for a topic I’m into and spend a lot of time thinking about with no effort, I can’t imagine how shitty my thought process is for all the other issues of the world, like politics and AI and why Manchester United is doing so badly right now. Sure, I have (often strong) opinions on these issues, but how well thought out are these opinions if I haven’t written about them, really? We’re all such fools, we don’t even know it - if we did, we wouldn’t be. Mark Twain knew:</p><blockquote><p>“It ain’t what you don’t know that gets you into trouble. It’s what you know for sure that just ain’t so.”</p></blockquote><p>My boy Bertrand Russel once wrote what is literally my favourite sentence in the English language, which pretty much nails what I’ve been trying to say here but way more succinctly and poetically:</p><blockquote><p>“Everything is vague to a degree you do not realize till you have tried to make it precise, and everything precise is so remote from everything that we normally think, that you cannot for a moment suppose that is what we really mean when we say what we think.”</p></blockquote><p>The more you write, the more you realize how universally true this sentence is. It’s depressing how lossy all our attempts at communication are, written or otherwise. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed00365b-a80e-44f5-bc5c-7bc14f0ca67e_743x192.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed00365b-a80e-44f5-bc5c-7bc14f0ca67e_743x192.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed00365b-a80e-44f5-bc5c-7bc14f0ca67e_743x192.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed00365b-a80e-44f5-bc5c-7bc14f0ca67e_743x192.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed00365b-a80e-44f5-bc5c-7bc14f0ca67e_743x192.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed00365b-a80e-44f5-bc5c-7bc14f0ca67e_743x192.png" width="743" height="192" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ed00365b-a80e-44f5-bc5c-7bc14f0ca67e_743x192.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:192,&quot;width&quot;:743,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:32016,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed00365b-a80e-44f5-bc5c-7bc14f0ca67e_743x192.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed00365b-a80e-44f5-bc5c-7bc14f0ca67e_743x192.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed00365b-a80e-44f5-bc5c-7bc14f0ca67e_743x192.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed00365b-a80e-44f5-bc5c-7bc14f0ca67e_743x192.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Amen</figcaption></figure></div><p>I now understand why construction projects can go billions of dollars over budget, why movies can take decades to produce, why novels take years to write. I don’t judge these as failures anymore. I understand why GTA 6 has taken so long. I forgive you, Rockstar Games.</p><p>Because if writing a stupid essay that requires zero research, zero external coordination, and zero dollars, only my time and focus, is this difficult to finish, I’m astounded that anything ever gets done in the world in the first place, and that too well.</p><p>Finishing anything is a miracle in and of itself. A huge shoutout to anyone who’s ever done anything to completion at all.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Volcanic eruption started just north of the town of Grindavik, Iceland (105 pts)]]></title>
            <link>https://www.visir.is/g/20232505181d/eld-gos-hafid-a-reykja-nes-skaga</link>
            <guid>38689617</guid>
            <pubDate>Mon, 18 Dec 2023 23:01:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.visir.is/g/20232505181d/eld-gos-hafid-a-reykja-nes-skaga">https://www.visir.is/g/20232505181d/eld-gos-hafid-a-reykja-nes-skaga</a>, See on <a href="https://news.ycombinator.com/item?id=38689617">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                <!-- ************** ARTICLE SUMMARY ************** -->
 
<p>Gos hófst um fjóra kílómetra norðaustan Grindavíkur, norðan Sundhnúks í Sundhnúkaröðinni, klukkan 22:17 í kvöld.</p>

<!--AD-MISSING-->

<article>
  
  <div disabled="" itemprop="articleBody" data-element-type="body" data-element-label="Meginmál" data-element-data-type="xml">
    <ul>
      <li>Undanfari eldgoss var skjálftahrina við Sundhnjúkagíga sem hófst skyndilega í kvöld klukkan 21:00.</li>
      <li>Almannavarnir hafa lýst yfir neyðarástandi. Almenningur hefur verið beðinn um að stöðva ekki bíla sína á Reykjanesbraut.</li>
      <li>Grindavíkursvæðið hefur verið rýmt.</li>
      <li>Á öðrum tímanum var var áætluð lengd sprungunnar meira en fjórir kílómetrar. Til samanburðar var lengd sprungunnar í eldgosinu við Litla-Hrút í júlí um 800 til 900 metrar.</li>
      <li>Áætlað hraunflæði í eldgosinu er um 100 til 200 rúmmetrar á sekúndu sem er margfalt meira en í fyrri gosum á Reykjanesskaga síðustu ár.</li>
    </ul>
    <p>
      <i>Nánar í vaktinni hér að neðan. Ráð er að endurhlaða síðuna ef vaktin birtist ekki. Þá má sjá beina útsendingu í spilaranum hér að neðan.</i>
    </p>
    <figure></figure>
  </div>
  
  
</article>                        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Love Ruby (279 pts)]]></title>
            <link>https://eliseshaffer.com/2023/12/18/i-love-ruby/</link>
            <guid>38688453</guid>
            <pubDate>Mon, 18 Dec 2023 21:18:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eliseshaffer.com/2023/12/18/i-love-ruby/">https://eliseshaffer.com/2023/12/18/i-love-ruby/</a>, See on <a href="https://news.ycombinator.com/item?id=38688453">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <a href="https://eliseshaffer.com/writing"><i></i>Back</a>

<span>Dec 18, 2023</span>


<figure>
    <img src="https://eliseshaffer.com/images/2023-12-18-ruby-logo.png" alt="Ruby logo">
    <figcaption>
        The Ruby logo is Copyright © 2006, Yukihiro Matsumoto and is licensed under Creative Commons Attribution-ShareAlike 2.5
    </figcaption>
</figure>

<p>I’ve done a lot in my career. From working on business support software to big backend systems and even robotics. If there’s been a consistent through-line to my career, it’s the Ruby programming language.</p>

<p>In recent years, Ruby has fallen out of favor with the tech industry, but I still love it. It’s a great language with so many strengths that it hurts when I see people trash Ruby or say its time is over. Thankfully, I’m not alone. There are so many Ruby devs still out here. The community is niche, but thriving. People are puzzled by this sometimes. Once, a colleague once said “rubyists really love ruby,” with an air of surprise. I’ve heard others trash ruby for not having types. One person laughed at me when I said Ruby was an “expressive language” and said, “it doesn’t express anything about the implementation.”</p>

<p>So why do myself and others love Ruby so much? I thought I’d explore this a bit.</p>

<h2 id="fostering-programmer-happiness">Fostering Programmer Happiness</h2>
<p>First and foremost, Ruby is a language that strives to make programmers happy. This is an underrated value and one that often gets our community mocked by our peers within other communities. The language is meant be joyful to use. This is a value and an ethos that permeates the language, the ecosystem of gems, and the community. Everything else that Ruby is stems from this value.</p>

<p>When I write Ruby, I take so much joy out of the process. Even the bad parts. In the middle of a high stress incident, Ruby still sparks joy. In fact, the only time I don’t enjoy Ruby is when I’m working on a piece of code that doesn’t follow Ruby practices, patterns, and idioms. Which brings me to the next topic</p>

<h2 id="expressiveness-encouraged">Expressiveness Encouraged</h2>
<p>Ruby is probably the most expressive programming language on Earth. Between its metaprogramming features and cultural idioms, Ruby allows programmers to write code that clearly expresses its intent. Well written ruby code can often read like natural language. Features like predicate methods even give up punctuation. So you can easily write something like:</p>

<div><pre><code><span>if</span> <span>@subscription</span><span>.</span><span>supports_feature?</span><span>(</span><span>:feature_a</span><span>)</span>
  <span>...</span>
<span>else</span>
  <span>...</span>
<span>end</span>
</code></pre></div>

<p>This is often why ruby programmers don’t like comments. In most cases, the language makes comments unnecessary. And when you do need them, it’s often when you’re doing a very specific  or obscure thing that requires context to understand. It’s clear from the code why you need a comment in that case.</p>

<p>Tied into this is the ecosystems embrace of domain specific languages(DSLs), which give us the power to write incredibly expressive code that reads like what it’s doing. For example, RSpec’s DSL reads exactly like how a person might talk about what they want to test:</p>

<div><pre><code><span>RSpec</span><span>.</span><span>describe</span> <span>Ticket</span> <span>do</span>
  <span>context</span> <span>'when the ticket is closed'</span> <span>do</span>
    <span>it</span> <span>'emails the requestor with a confirmation'</span> <span>do</span>
      <span>...</span>
	<span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div>

<p><del>Methods</del>, sorry “approaches,” like this have made Ruby so joyful to use.</p>

<h2 id="a-language-made-just-for-me">A Language Made Just For Me</h2>
<p>Many rubyists, myself included, recount stories of how Ruby and Rails just fit their brain. I recently told this story on <a href="https://www.remoteruby.com/2260490/14003706-unlocking-the-power-of-state-machines-in-code-development-with-elise-schaefer">Remote Ruby</a> about learning ruby. I said that when I was learning Ruby it felt like it was made just for me. I could guess method names and signatures and I would be right most of the time. When I was wrong, I could switch the order of arguments. This was so true that quickly I learned to just try something based on intuition before reading the docs. I know so many rubyists who have similar stories.</p>

<p>Feeling recognition in the language you’re programming is so powerful.</p>

<h2 id="community-and-values">Community And Values</h2>
<p>It’s so hard to talk about Ruby without talking about how the community shapes what Ruby is and how it feels to use the language. Ruby is a great language with so many benefits. There’s lots of features and values built into its core that make it a joy to use.</p>

<p>But as Kent Beck said at RailsConf in 2020, “Software design is an exercise in human relationships.” He was talking about how we think about designing software. But I think this quote applies to our community and our values as well. If you’ve followed this blog or listened to The Ruby on Rails Podcast since I took over, you know that community is a big part of my value system. That value is shared by other rubyists.</p>

<p>I attended RubyConf in San Diego this year. These conferences are always a blast. It feels like I’m coming home to see old friends. The community building that happens at these conferences makes lifelong colleagues and friends. There a spirit of learning, and cooperation. We want to help each other, teach each other, learn from each other. The Ruby community is an incredible group of people of welcoming, kind, and supportive peers. Without the community, Ruby couldn’t be what it is.</p>

<p>There’s a lot of reasons to like ruby. And there’s so many things that rubyists love. I haven’t covered everything. But Ruby’s primary features are joy and community. That’s hard to beat.</p>

<p>Do you love Ruby? <a href="mailto:elise.shaffer+blog@hey.com">Tell me what you love about it</a></p>


    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Librum: Open-Source e-book platform (181 pts)]]></title>
            <link>https://github.com/Librum-Reader/Librum</link>
            <guid>38688127</guid>
            <pubDate>Mon, 18 Dec 2023 20:55:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Librum-Reader/Librum">https://github.com/Librum-Reader/Librum</a>, See on <a href="https://news.ycombinator.com/item?id=38688127">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Librum</h2>
<p dir="auto">Librum is an application designed to make reading <b>enjoyable</b> and <b>straightforward</b> for everyone.</p>
<p dir="auto">It's not <strong>just</strong> an e-book reader. With Librum, you can manage your own online library and access it from any device anytime, anywhere. It has features like note-taking, bookmarking, and highlighting, while offering customization to make it as personal as you want!</p>
<p dir="auto">Librum also provides free access to over 70,000 books and personal reading statistics while being free and completely open source.</p>
<h2 tabindex="-1" dir="auto">Preview</h2>
<p dir="auto">A simple and modern interface</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/69865187/261866073-bf1d0401-62bd-4f4e-b008-523fb2efd275.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDI5NTUxMDUsIm5iZiI6MTcwMjk1NDgwNSwicGF0aCI6Ii82OTg2NTE4Ny8yNjE4NjYwNzMtYmYxZDA0MDEtNjJiZC00ZjRlLWIwMDgtNTIzZmIyZWZkMjc1LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFJV05KWUFYNENTVkVINTNBJTJGMjAyMzEyMTklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjE5VDAzMDAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTM0ZGI5MTM3MTQyOTQ4NjkwZDdkYzZlMWRiMGRkNGRkZTBmMmJiY2QwNmVkMjM3MjdhY2UzNDhmOGJhZmUzMzMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.Yq5oBLzIONA9WhYlWn0nmDo7ABZi5yIUdLhtCIL4RRs"><img src="https://private-user-images.githubusercontent.com/69865187/261866073-bf1d0401-62bd-4f4e-b008-523fb2efd275.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDI5NTUxMDUsIm5iZiI6MTcwMjk1NDgwNSwicGF0aCI6Ii82OTg2NTE4Ny8yNjE4NjYwNzMtYmYxZDA0MDEtNjJiZC00ZjRlLWIwMDgtNTIzZmIyZWZkMjc1LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFJV05KWUFYNENTVkVINTNBJTJGMjAyMzEyMTklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjE5VDAzMDAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTM0ZGI5MTM3MTQyOTQ4NjkwZDdkYzZlMWRiMGRkNGRkZTBmMmJiY2QwNmVkMjM3MjdhY2UzNDhmOGJhZmUzMzMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.Yq5oBLzIONA9WhYlWn0nmDo7ABZi5yIUdLhtCIL4RRs" alt="image"></a></p>

<p dir="auto">Setup and manage your own library</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/69865187/244929153-ea94fc68-1bf0-4933-8d80-43a57c6590c5.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDI5NTUxMDUsIm5iZiI6MTcwMjk1NDgwNSwicGF0aCI6Ii82OTg2NTE4Ny8yNDQ5MjkxNTMtZWE5NGZjNjgtMWJmMC00OTMzLThkODAtNDNhNTdjNjU5MGM1LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFJV05KWUFYNENTVkVINTNBJTJGMjAyMzEyMTklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjE5VDAzMDAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWY3MDRmMzg0NjllMmE4OTA4MWFhY2YzN2IyY2ViODFmODZmMDJkMzdhODFkYTRiZTNiOTNiODcxYTYxNWVlMDQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.aD5NN-xtFZ6hz8A0q0QfKFOkFXj2D4skeUkoMTfUyq8"><img src="https://private-user-images.githubusercontent.com/69865187/244929153-ea94fc68-1bf0-4933-8d80-43a57c6590c5.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDI5NTUxMDUsIm5iZiI6MTcwMjk1NDgwNSwicGF0aCI6Ii82OTg2NTE4Ny8yNDQ5MjkxNTMtZWE5NGZjNjgtMWJmMC00OTMzLThkODAtNDNhNTdjNjU5MGM1LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFJV05KWUFYNENTVkVINTNBJTJGMjAyMzEyMTklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjE5VDAzMDAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWY3MDRmMzg0NjllMmE4OTA4MWFhY2YzN2IyY2ViODFmODZmMDJkMzdhODFkYTRiZTNiOTNiODcxYTYxNWVlMDQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.aD5NN-xtFZ6hz8A0q0QfKFOkFXj2D4skeUkoMTfUyq8" alt="HomeScreenDark"></a></p>

<p dir="auto">Customize Librum to make it personal to you</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/69865187/262316821-b8995cf1-a0e6-4993-8c8b-92f7f8e79ebd.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDI5NTUxMDUsIm5iZiI6MTcwMjk1NDgwNSwicGF0aCI6Ii82OTg2NTE4Ny8yNjIzMTY4MjEtYjg5OTVjZjEtYTBlNi00OTkzLThjOGItOTJmN2Y4ZTc5ZWJkLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFJV05KWUFYNENTVkVINTNBJTJGMjAyMzEyMTklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjE5VDAzMDAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQzOWZjZWFkZGRmZDhhMzZjMjM2MzUxNTBjMDhjYTM0Y2RiMzU2ZGMxNDA1YmZhMDE2MTE2NzQxYWQzOThiOWEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.QYBJLcTLRX9CubnhuSAvrlV2ivZ_jt18WaW84psln1E"><img src="https://private-user-images.githubusercontent.com/69865187/262316821-b8995cf1-a0e6-4993-8c8b-92f7f8e79ebd.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE3MDI5NTUxMDUsIm5iZiI6MTcwMjk1NDgwNSwicGF0aCI6Ii82OTg2NTE4Ny8yNjIzMTY4MjEtYjg5OTVjZjEtYTBlNi00OTkzLThjOGItOTJmN2Y4ZTc5ZWJkLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFJV05KWUFYNENTVkVINTNBJTJGMjAyMzEyMTklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjMxMjE5VDAzMDAwNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQzOWZjZWFkZGRmZDhhMzZjMjM2MzUxNTBjMDhjYTM0Y2RiMzU2ZGMxNDA1YmZhMDE2MTE2NzQxYWQzOThiOWEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.QYBJLcTLRX9CubnhuSAvrlV2ivZ_jt18WaW84psln1E" alt="image"></a></p>
<br>
<h2 tabindex="-1" dir="auto">How can I get Librum?</h2>
<p dir="auto">Simply go to <a href="https://librumreader.com/" rel="nofollow">https://librumreader.com</a> to download Librum.</p>
<p dir="auto">If you want to build Librum from source, follow the instructions <a href="#build-guide">here</a>.</p>
<br>
<h2 tabindex="-1" dir="auto">Translations</h2>
<p dir="auto">Librum is currently available in:</p>
<ul dir="auto">
<li>English</li>
<li>German</li>
<li>Russian</li>
<li>Mandarin</li>
</ul>
<p dir="auto">If you want to translate Librum to another language, follow the steps below:</p>
<ul dir="auto">
<li>Download the file at: <a href="https://github.com/Librum-Reader/Librum/blob/main/src/presentation/translations/librum_en.ts">https://github.com/Librum-Reader/Librum/blob/main/src/presentation/translations/librum_en.ts</a></li>
<li>Rename the file to contain your language's suffix, e.g. "librum_ru.ts" for Russian or "librum_de.ts" for German</li>
<li>Download the translation software (Qt Linguist) either for Windows from <a href="https://github.com/thurask/Qt-Linguist">https://github.com/thurask/Qt-Linguist</a> or using the Qt Installer at <a href="https://www.qt.io/download-open-source" rel="nofollow">https://www.qt.io/download-open-source</a></li>
<li>Now start Qt Linguist, open the downloaded file, set the target language to the language you want to translate to and start translating.
(For a quick guide on Qt Linguist, check out: <a href="https://youtu.be/xNIz78IPBu0?t=347" rel="nofollow">https://youtu.be/xNIz78IPBu0?t=347</a>)</li>
</ul>
<p dir="auto">Once you are done, create a pull request or an issue with your new translation file!<br>
If you run into any problems, need guidance or have questions, feel free to reach out to us at: <a href="mailto:contact@librumreader.com">contact@librumreader.com</a></p>

<p dir="auto">Notes:</p>
<ul dir="auto">
<li>Make sure that your translations are approximately the same length as the original text</li>
<li>Make sure that you keep to the punctuation and capitalisation</li>
<li>Make sure that your translations make sense in the context they are in</li>
</ul>
<br>
<h2 tabindex="-1" dir="auto">Documentation</h2>
<p dir="auto">For documentation go to <a href="https://github.com/Librum-Reader/Librum/wiki">Librum's GitHub-wiki</a></p>
<br>
<h2 tabindex="-1" dir="auto">Donations</h2>
<div dir="auto"><p>Donations make it possible for us to cover our server costs and allow us to make investments into new areas of development.
<br>
If you would like to support us, check out: <a href="https://librumreader.com/contribute/donate" rel="nofollow">https://librumreader.com/contribute/donate</a> or become a github sponsor!
</p><p>

As a team of opensource developers we rely on donations to continue working on projects like Librum. Your help is greatly appreciated.</p></div>
<br>
<h2 tabindex="-1" dir="auto">Contributing</h2>

<ol dir="auto">
<li>Discord (m_david#0631)</li>
<li>Email (<a href="mailto:contact@librumreader.com">contact@librumreader.com</a>)</li>
</ol>
<br>
We are following a pull request workflow where every contribution is sent as a pull request and merged into the dev/develop branch for testing. <br>
Please make sure to run clang format, keep to the conventions used throughout the application and ensure that all tests pass, before submitting any pull request.
<h2 tabindex="-1" dir="auto">Contact</h2>
<p dir="auto">For questions, you can reach us under: <a href="mailto:help@librumreader.com">help@librumreader.com</a>
<br>
For business related contact, reach out to us here: <a href="mailto:contact@librumreader.com">contact@librumreader.com</a></p>
<br>
<h2 tabindex="-1" dir="auto">Details</h2>
<h3 tabindex="-1" dir="auto">Supported platforms</h3>
<p dir="auto">Part of Librum's aim is to work on <strong>any</strong> platform. No matter where you are or which device you use, you can always continue your book with Librum, as it is <b>cross platform</b>.<br>
We support:</p>
<ul dir="auto">
<li>Windows</li>
<li>GNU/Linux</li>
<li>MacOS</li>
<li>IOS (Coming Soon)</li>
<li>Android (Coming Soon)</li>
</ul>
<br>
<h3 tabindex="-1" dir="auto">Supported formats</h3>
<p dir="auto">Librum is the best choice for all kinds of books, since Librum supports <b>all</b> major book formats<br>
including:</p>
<ul dir="auto">
<li>PDF</li>
<li>EPUB</li>
<li>CBZ (Comic books)</li>
<li>XPS</li>
<li>PS</li>
<li>All plain text formats</li>
<li>Images</li>
</ul>
<br>
<h3 tabindex="-1" dir="auto">Features</h3>
<p dir="auto">Librum's objective is to make your reading more <b>productive</b>; to that end, we provide you with a variety of features that you can access via a <b>simple</b> and <b>straightforward</b> interface.<br>
These features include:</p>
<ul dir="auto">
<li>A modern e-reader</li>
<li>A personalized and customizable library</li>
<li>Book meta-data editing</li>
<li>A free in-app bookstore with more than 70.000 books</li>
<li>Book syncing across all of your devices</li>
<li>Highlighting</li>
<li>Bookmarking</li>
<li>Text search</li>
<li>Unlimited customization</li>
<li>Note-taking (Coming Soon)</li>
<li>TTS (Coming Soon)</li>
<li>Personalized reading statistics (Coming Soon)</li>
<li>No-login book reading (Coming Soon)</li>
</ul>
<p dir="auto">Want a new feature? Feel free to leave a feature request ticket!</p>

<h2 tabindex="-1" dir="auto">Build Guide</h2>
<p dir="auto">Follow this guide to build Librum from source.
<br></p>
<h2 tabindex="-1" dir="auto">For GNU/Linux</h2>
<h3 tabindex="-1" dir="auto">Prerequisites</h3>
<ul dir="auto">
<li>cmake                             (<a href="https://cmake.org/download" rel="nofollow">https://cmake.org/download</a>)</li>
<li>make                              (<a href="http://ftp.gnu.org/gnu/make" rel="nofollow">http://ftp.gnu.org/gnu/make</a>)</li>
<li>g++                               (<a href="https://gcc.gnu.org/" rel="nofollow">https://gcc.gnu.org</a>)</li>
<li>python3-venv                      (on ubuntu use <code>sudo apt install python3-venv</code>)</li>
<li>Qt 6.5                            (<a href="https://www.qt.io/download-open-source" rel="nofollow">https://www.qt.io/download-open-source</a>)</li>
</ul>
<h3 tabindex="-1" dir="auto">Installation</h3>
<p dir="auto">The installation is straight forward, just follow the steps below:</p>
<br>
<ol dir="auto">
<li>Clone the repository.
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/Librum-Reader/Librum.git --recursive"><pre>git clone https://github.com/Librum-Reader/Librum.git --recursive</pre></div>
</li>
<li>Step into the cloned project folder.

</li>
<li>Create the build folder and step into it.
<div dir="auto" data-snippet-clipboard-copy-content="mkdir build-Release
cd build-Release"><pre>mkdir build-Release
<span>cd</span> build-Release</pre></div>
</li>
<li>Run cmake.
<div dir="auto" data-snippet-clipboard-copy-content="cmake -DCMAKE_INSTALL_PREFIX=/usr -DCMAKE_BUILD_TYPE=Release -DBUILD_TESTS=Off -DCMAKE_PREFIX_PATH=<path/to/Qt> .."><pre>cmake -DCMAKE_INSTALL_PREFIX=/usr -DCMAKE_BUILD_TYPE=Release -DBUILD_TESTS=Off -DCMAKE_PREFIX_PATH=<span>&lt;</span>path/to/Qt<span>&gt;</span> ..</pre></div>
Set <code>CMAKE_PREFIX_PATH</code> to your Qt installation path. Installing Qt via the online installer usually installs it to <code>/home/&lt;name&gt;/Qt/&lt;version&gt;/gcc_64</code></li>
<li>Build the project
<div dir="auto" data-snippet-clipboard-copy-content="cmake --build . -j $(nproc)"><pre>cmake --build <span>.</span> -j <span><span>$(</span>nproc<span>)</span></span></pre></div>
</li>
<li>Install Librum

</li>
</ol>
<br>
<h3 tabindex="-1" dir="auto">Troubleshooting</h3>
<p dir="auto">Here are solutions to some common errors. If your error is not listed here, please open an issue.
<br></p>
<ul dir="auto">
<li>
<p dir="auto">Error: <code>Failed to find required Qt component "Quick".</code><br></p>
</li>
<li>
<p dir="auto">Solution: Install the libGL mesa dev package, on ubuntu its <code>sudo apt install libgl1-mesa-dev</code> and on fedora its <code>sudo dnf install mesa-libGL-devel</code>.</p>
</li>
<li>
<p dir="auto">Error: <code>Could not load the qt platform plugin "xcb" even though it was found</code></p>
</li>
<li>
<p dir="auto">Solution: Install the libxcb-cursor-dev, on ubuntu its <code>sudo apt install libxcb-cursor-dev</code></p>
</li>
</ul>
<br>
<h2 tabindex="-1" dir="auto">For Windows</h2>
<h3 tabindex="-1" dir="auto">Prerequisites</h3>
<ul dir="auto">
<li>cmake                             (<a href="https://cmake.org/download" rel="nofollow">https://cmake.org/download</a>)</li>
<li>Visual Studio <b>19</b>           (<a href="https://visualstudio.microsoft.com/de/vs/older-downloads" rel="nofollow">https://visualstudio.microsoft.com/de/vs/older-downloads</a>)</li>
<li>Python                            (<a href="https://www.python.org/downloads" rel="nofollow">https://www.python.org/downloads</a>)</li>
<li>Qt 6.5                            (<a href="https://www.qt.io/download-open-source" rel="nofollow">https://www.qt.io/download-open-source</a>)</li>
</ul>
<h3 tabindex="-1" dir="auto">Installation</h3>
<p dir="auto">To build Librum on windows, run the following commands in the Powershell:</p>
<br>
<ol dir="auto">
<li>Clone the repository.
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/Librum-Reader/Librum.git --recursive"><pre>git clone https://github.com/Librum-Reader/Librum.git --recursive</pre></div>
</li>
<li>Step into the cloned project folder.

</li>
<li>Create the build folder and step into it.

</li>
<li>Run cmake.
<div dir="auto" data-snippet-clipboard-copy-content="cmake -DBUILD_TESTS=Off -DCMAKE_PREFIX_PATH=<path/to/qt> .."><pre>cmake -DBUILD_TESTS=Off -DCMAKE_PREFIX_PATH=<span>&lt;</span>path/to/qt<span>&gt;</span> ..</pre></div>
Set <code>CMAKE_PREFIX_PATH</code> to your Qt installation path. Installing Qt via the online installer usually installs it to <code>&lt;Drive&gt;\\Qt\\&lt;version&gt;\\msvc2019_64</code></li>
<li>Build the project
<div dir="auto" data-snippet-clipboard-copy-content="cmake --build . --config Release"><pre>cmake --build <span>.</span> --config Release</pre></div>
</li>
<li>Run the app

</li>
</ol>
<h3 tabindex="-1" dir="auto">Additional Info</h3>
<p dir="auto">Here are some things to keep in mind during the build process.
<br></p>
<ul dir="auto">
<li>Make sure to add cmake and the Qt binaries to the <code>PATH</code> environment variable</li>
<li>You need Visual Studio 2019, newer versions will <strong>not</strong> work</li>
<li>For the Qt installation, you <strong>only</strong> need to choose "MSVC 2019 64-bit", you can untick everything else to reduce the download size</li>
</ul>
<br>
<h2 tabindex="-1" dir="auto">For MacOS</h2>
<h3 tabindex="-1" dir="auto">Prerequisites</h3>
<ul dir="auto">
<li>cmake                             (<a href="https://cmake.org/download" rel="nofollow">https://cmake.org/download</a>)</li>
<li>make                              (<a href="http://ftp.gnu.org/gnu/make" rel="nofollow">http://ftp.gnu.org/gnu/make</a>)</li>
<li>g++                               (<a href="https://gcc.gnu.org/" rel="nofollow">https://gcc.gnu.org</a>)</li>
<li>python3                           (<a href="https://www.python.org/downloads" rel="nofollow">https://www.python.org/downloads</a>)</li>
<li>Qt 6.5                            (<a href="https://www.qt.io/download-open-source" rel="nofollow">https://www.qt.io/download-open-source</a>)</li>
</ul>
<h3 tabindex="-1" dir="auto">Installation</h3>
<p dir="auto">The installation is straight forward, just follow the steps below:</p>
<br>
<ol dir="auto">
<li>Clone the repository.
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/Librum-Reader/Librum.git --recursive"><pre>git clone https://github.com/Librum-Reader/Librum.git --recursive</pre></div>
</li>
<li>Step into the cloned project folder.

</li>
<li>Create the build folder and step into it.
<div dir="auto" data-snippet-clipboard-copy-content="mkdir build-Release
cd build-Release"><pre>mkdir build-Release
<span>cd</span> build-Release</pre></div>
</li>
<li>Run cmake.
<div dir="auto" data-snippet-clipboard-copy-content="cmake -DCMAKE_INSTALL_PREFIX=/usr/local -DCMAKE_BUILD_TYPE=Release -DBUILD_TESTS=Off -DCMAKE_PREFIX_PATH=<path/to/Qt> .."><pre>cmake -DCMAKE_INSTALL_PREFIX=/usr/local -DCMAKE_BUILD_TYPE=Release -DBUILD_TESTS=Off -DCMAKE_PREFIX_PATH=<span>&lt;</span>path/to/Qt<span>&gt;</span> ..</pre></div>
Set <code>CMAKE_PREFIX_PATH</code> to your Qt installation path. Installing Qt via the online installer usually installs it to <code>/Users/&lt;name&gt;/Qt/&lt;version&gt;/macos</code></li>
<li>Build the project
<div dir="auto" data-snippet-clipboard-copy-content="cmake --build . -j $(nproc)"><pre>cmake --build <span>.</span> -j <span><span>$(</span>nproc<span>)</span></span></pre></div>
</li>
<li>Install Librum

</li>
</ol>
<br>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PostgREST: Providing HTML Content Using Htmx (271 pts)]]></title>
            <link>https://postgrest.org/en/stable/how-tos/providing-html-content-using-htmx.html</link>
            <guid>38687997</guid>
            <pubDate>Mon, 18 Dec 2023 20:47:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://postgrest.org/en/stable/how-tos/providing-html-content-using-htmx.html">https://postgrest.org/en/stable/how-tos/providing-html-content-using-htmx.html</a>, See on <a href="https://news.ycombinator.com/item?id=38687997">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="providing-html-content-using-htmx" itemprop="articleBody" role="main" itemscope="itemscope" itemtype="http://schema.org/Article">

<dl>
<dt>author</dt>
<dd><p><a href="https://github.com/laurenceisla">Laurence Isla</a></p>
</dd>
</dl>
<p>This how-to shows a way to return HTML content and use the <a href="https://htmx.org/">htmx library</a> to handle the AJAX requests.
Htmx expects an HTML response and uses it to replace an element inside the DOM (see the <a href="https://htmx.org/docs/#introduction">htmx introduction</a> in the docs).</p>
<p><img alt="../_images/htmx-demo.gif" src="https://postgrest.org/en/stable/_images/htmx-demo.gif"></p><div id="preparatory-configuration">
<h2>Preparatory Configuration<a href="#preparatory-configuration" title="Permalink to this headline"></a></h2>
<p>We will make a to-do app based on the <a href="https://postgrest.org/en/stable/tutorials/tut0.html#tut0"><span>Tutorial 0 - Get it Running</span></a>, so make sure to complete it before continuing.</p>
<p>To simplify things, we won’t be using authentication, so grant all permissions on the <code><span>todos</span></code> table to the <code><span>web_anon</span></code> user.</p>
<div><pre><span></span><span>grant</span><span> </span><span>all</span><span> </span><span>on</span><span> </span><span>api</span><span>.</span><span>todos</span><span> </span><span>to</span><span> </span><span>web_anon</span><span>;</span>
<span>grant</span><span> </span><span>usage</span><span>,</span><span> </span><span>select</span><span> </span><span>on</span><span> </span><span>sequence</span><span> </span><span>api</span><span>.</span><span>todos_id_seq</span><span> </span><span>to</span><span> </span><span>web_anon</span><span>;</span>
</pre></div>
<p>Next, add the <code><span>text/html</span></code> as a <a href="https://postgrest.org/en/stable/references/api/media_type_handlers.html#custom-media"><span>Media Type Handlers</span></a>. With this, PostgREST can identify the request made by your web browser (with the <code><span>Accept:</span> <span>text/html</span></code> header)
and return a raw HTML document file.</p>
<div><pre><span></span><span>create</span><span> </span><span>domain</span><span> </span><span>"text/html"</span><span> </span><span>as</span><span> </span><span>text</span><span>;</span>
</pre></div>
</div>
<div id="creating-an-html-response">
<h2>Creating an HTML Response<a href="#creating-an-html-response" title="Permalink to this headline"></a></h2>
<p>Let’s create a function that returns a basic HTML file, using <a href="https://v2.tailwindcss.com/">Tailwind CSS</a> for styling.</p>
<div><pre><span></span><span>create</span><span> </span><span>or</span><span> </span><span>replace</span><span> </span><span>function</span><span> </span><span>api</span><span>.</span><span>index</span><span>()</span><span> </span><span>returns</span><span> </span><span>"text/html"</span><span> </span><span>as</span><span> </span><span>$$</span>
<span>  </span><span>select</span><span> </span><span>$</span><span>html</span><span>$</span>
<span>    &lt;!DOCTYPE html&gt;</span>
<span>    &lt;html&gt;</span>
<span>    &lt;head&gt;</span>
<span>      &lt;meta charset="utf-8"&gt;</span>
<span>      &lt;meta name="viewport" content="width=device-width, initial-scale=1"&gt;</span>
<span>      &lt;title&gt;PostgREST + HTMX To-Do List&lt;/title&gt;</span>
<span>      &lt;!-- Tailwind for CSS styling --&gt;</span>
<span>      &lt;link href="https://unpkg.com/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet"&gt;</span>
<span>    &lt;/head&gt;</span>
<span>    &lt;body class="bg-gray-900"&gt;</span>
<span>      &lt;div class="flex justify-center"&gt;</span>
<span>        &lt;div class="max-w-lg mt-5 p-6 bg-gray-800 border border-gray-800 rounded-lg shadow-xl"&gt;</span>
<span>          &lt;h5 class="mb-3 text-2xl font-bold tracking-tight text-white"&gt;PostgREST + HTMX To-Do List&lt;/h5&gt;</span>
<span>        &lt;/div&gt;</span>
<span>      &lt;/div&gt;</span>
<span>    &lt;/body&gt;</span>
<span>    &lt;/html&gt;</span>
<span>  $</span><span>html</span><span>$</span><span>;</span>
<span>$$</span><span> </span><span>language</span><span> </span><span>sql</span><span>;</span>
</pre></div>
<p>The web browser will open the web page at <code><span>http://localhost:3000/rpc/index</span></code>.</p>
<p><img alt="../_images/htmx-simple.jpg" src="https://postgrest.org/en/stable/_images/htmx-simple.jpg">
</p></div>
<div id="listing-and-creating-to-dos">
<h2>Listing and Creating To-Dos<a href="#listing-and-creating-to-dos" title="Permalink to this headline"></a></h2>
<p>Now, let’s show a list of the to-dos already inserted in the database.</p>
<div><pre><span></span><span>create</span><span> </span><span>or</span><span> </span><span>replace</span><span> </span><span>function</span><span> </span><span>api</span><span>.</span><span>html_todo</span><span>(</span><span>api</span><span>.</span><span>todos</span><span>)</span><span> </span><span>returns</span><span> </span><span>text</span><span> </span><span>as</span><span> </span><span>$$</span>
<span>  </span><span>select</span><span> </span><span>format</span><span>(</span><span>$</span><span>html</span><span>$</span>
<span>    &lt;li class="py-3"&gt;</span>
<span>      &lt;span class="ml-2 %2$s"&gt;</span>
<span>        %3$s</span>
<span>      &lt;/span&gt;</span>
<span>    &lt;/li&gt;</span>
<span>    $</span><span>html</span><span>$</span><span>,</span>
<span>    </span><span>$1</span><span>.</span><span>id</span><span>,</span>
<span>    </span><span>case</span><span> </span><span>when</span><span> </span><span>$1</span><span>.</span><span>done</span><span> </span><span>then</span><span> </span><span>'line-through text-gray-400'</span><span> </span><span>else</span><span> </span><span>''</span><span> </span><span>end</span><span>,</span>
<span>    </span><span>$1</span><span>.</span><span>task</span>
<span>  </span><span>);</span>
<span>$$</span><span> </span><span>language</span><span> </span><span>sql</span><span> </span><span>stable</span><span>;</span>

<span>create</span><span> </span><span>or</span><span> </span><span>replace</span><span> </span><span>function</span><span> </span><span>api</span><span>.</span><span>html_all_todos</span><span>()</span><span> </span><span>returns</span><span> </span><span>text</span><span> </span><span>as</span><span> </span><span>$$</span>
<span>  </span><span>select</span><span> </span><span>coalesce</span><span>(</span>
<span>    </span><span>'&lt;ul id="todo-list" role="list" class="divide-y divide-gray-700 text-gray-100"&gt;'</span>
<span>      </span><span>||</span><span> </span><span>string_agg</span><span>(</span><span>api</span><span>.</span><span>html_todo</span><span>(</span><span>t</span><span>),</span><span> </span><span>''</span><span> </span><span>order</span><span> </span><span>by</span><span> </span><span>t</span><span>.</span><span>id</span><span>)</span><span> </span><span>||</span>
<span>    </span><span>'&lt;/ul&gt;'</span><span>,</span>
<span>    </span><span>'&lt;p class="text-gray-100"&gt;There is nothing else to do.&lt;/p&gt;'</span>
<span>  </span><span>)</span>
<span>  </span><span>from</span><span> </span><span>api</span><span>.</span><span>todos</span><span> </span><span>t</span><span>;</span>
<span>$$</span><span> </span><span>language</span><span> </span><span>sql</span><span>;</span>
</pre></div>
<p>These two functions are used to build the to-do list template. We won’t use them as PostgREST endpoints.</p>
<ul>
<li><p>The <code><span>api.html_todo</span></code> function uses the table <code><span>api.todos</span></code> as a parameter and formats each item into a list element <code><span>&lt;li&gt;</span></code>.
The PostgreSQL <a href="https://www.postgresql.org/docs/current/functions-string.html#FUNCTIONS-STRING-FORMAT">format</a> is useful to that end.
It replaces the values according to the position in the template, e.g. <code><span>%1$s</span></code> will be replaced with the value of <code><span>$1.id</span></code> (the first parameter).</p></li>
<li><p>The <code><span>api.html_all_todos</span></code> function returns the <code><span>&lt;ul&gt;</span></code> wrapper for all the list elements.
It uses <a href="https://www.postgresql.org/docs/current/functions-aggregate.html">string_arg</a> to concatenate all the to-dos in a single text value.
It also returns an alternative message, instead of a list, when the <code><span>api.todos</span></code> table is empty.</p></li>
</ul>
<p>Next, let’s add an endpoint to register a to-do in the database and modify the <code><span>/rpc/index</span></code> page accordingly.</p>
<div><pre><span></span><span>create</span><span> </span><span>or</span><span> </span><span>replace</span><span> </span><span>function</span><span> </span><span>api</span><span>.</span><span>add_todo</span><span>(</span><span>_task</span><span> </span><span>text</span><span>)</span><span> </span><span>returns</span><span> </span><span>"text/html"</span><span> </span><span>as</span><span> </span><span>$$</span>
<span>  </span><span>insert</span><span> </span><span>into</span><span> </span><span>api</span><span>.</span><span>todos</span><span>(</span><span>task</span><span>)</span><span> </span><span>values</span><span> </span><span>(</span><span>_task</span><span>);</span>
<span>  </span><span>select</span><span> </span><span>api</span><span>.</span><span>html_all_todos</span><span>();</span>
<span>$$</span><span> </span><span>language</span><span> </span><span>sql</span><span>;</span>

<span>create</span><span> </span><span>or</span><span> </span><span>replace</span><span> </span><span>function</span><span> </span><span>api</span><span>.</span><span>index</span><span>()</span><span> </span><span>returns</span><span> </span><span>"text/html"</span><span> </span><span>as</span><span> </span><span>$$</span>
<span>select</span><span> </span><span>$</span><span>html</span><span>$</span>
<span>  &lt;!DOCTYPE html&gt;</span>
<span>  &lt;html&gt;</span>
<span>  &lt;head&gt;</span>
<span>    &lt;meta charset="utf-8"&gt;</span>
<span>    &lt;meta name="viewport" content="width=device-width, initial-scale=1"&gt;</span>
<span>    &lt;title&gt;PostgREST + HTMX To-Do List&lt;/title&gt;</span>
<span>    &lt;!-- Tailwind for CSS styling --&gt;</span>
<span>    &lt;link href="https://unpkg.com/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet"&gt;</span>
<span>    &lt;!-- htmx for AJAX requests --&gt;</span>
<span>    &lt;script src="https://unpkg.com/htmx.org"&gt;&lt;/script&gt;</span>
<span>  &lt;/head&gt;</span>
<span>  &lt;body class="bg-gray-900"</span>
<span>        hx-headers='{"Accept": "text/html"}'&gt;</span>
<span>    &lt;div class="flex justify-center"&gt;</span>
<span>      &lt;div class="max-w-lg mt-5 p-6 bg-gray-800 border border-gray-800 rounded-lg shadow-xl"&gt;</span>
<span>        &lt;h5 class="mb-3 text-2xl font-bold tracking-tight text-white"&gt;PostgREST + HTMX To-Do List&lt;/h5&gt;</span>
<span>        &lt;form hx-post="/rpc/add_todo"</span>
<span>              hx-target="#todo-list-area"</span>
<span>              hx-trigger="submit"</span>
<span>              hx-on="htmx:afterRequest: this.reset()"&gt;</span>
<span>          &lt;input class="bg-gray-50 border text-sm rounded-lg block w-full p-2.5 mb-3 bg-gray-700 border-gray-600 placeholder-gray-400 text-white focus:ring-blue-500 focus:border-blue-500"</span>
<span>                 type="text" name="_task" placeholder="Add a todo..."&gt;</span>
<span>        &lt;/form&gt;</span>
<span>        &lt;div id="todo-list-area"&gt;</span>
<span>          $</span><span>html</span><span>$</span>
<span>            </span><span>||</span><span> </span><span>api</span><span>.</span><span>html_all_todos</span><span>()</span><span> </span><span>||</span>
<span>          </span><span>$</span><span>html</span><span>$</span>
<span>        &lt;div&gt;</span>
<span>      &lt;/div&gt;</span>
<span>    &lt;/div&gt;</span>
<span>  &lt;/body&gt;</span>
<span>  &lt;/html&gt;</span>
<span>  $</span><span>html</span><span>$</span><span>;</span>
<span>$$</span><span> </span><span>language</span><span> </span><span>sql</span><span>;</span>
</pre></div>
<ul>
<li><p>The <code><span>/rpc/add_todo</span></code> endpoint allows us to add a new to-do using the <code><span>_task</span></code> parameter and returns an <code><span>html</span></code> with all the to-dos in the database.</p></li>
<li><p>The <code><span>/rpc/index</span></code> now adds the <code><span>hx-headers='{"Accept":</span> <span>"text/html"}'</span></code> tag to the <code><span>&lt;body&gt;</span></code>.
This will make sure that all htmx elements inside the body send this header, otherwise PostgREST won’t recognize it as HTML.</p>
<p>There is also a <code><span>&lt;form&gt;</span></code> element that uses the htmx library. Let’s break it down:</p>
<ul>
<li><p><code><span>hx-post="/rpc/add_todo"</span></code>: sends an AJAX POST request to the <code><span>/rpc/add_todo</span></code> endpoint, with the value of the <code><span>_task</span></code> from the <code><span>&lt;input&gt;</span></code> element.</p></li>
<li><p><code><span>hx-target="#todo-list-area"</span></code>: the HTML content returned from the request will go inside <code><span>&lt;div</span> <span>id="todo-list-area"&gt;&lt;/div&gt;</span></code> (which is the list of to-dos).</p></li>
<li><p><code><span>hx-trigger="submit"</span></code>: htmx will do this request when submitting the form (by pressing enter while inside the <code><span>&lt;input&gt;</span></code>).</p></li>
<li><p><code><span>hx-on="htmx:afterRequest:</span> <span>this.reset()"&gt;</span></code>: this is a Javascript command that clears the form <a href="https://htmx.org/events/#htmx:afterRequest">after the request is done</a>.</p></li>
</ul>
</li>
</ul>
<p>With this, the <code><span>http://localhost:3000/rpc/index</span></code> page lists all the todos and adds new ones by submitting tasks in the input element.
Don’t forget to refresh the <a href="https://postgrest.org/en/stable/references/schema_cache.html#schema-reloading"><span>schema cache</span></a>.</p>
<p><img alt="../_images/htmx-insert.gif" src="https://postgrest.org/en/stable/_images/htmx-insert.gif">
</p></div>
<div id="editing-and-deleting-to-dos">
<h2>Editing and Deleting To-Dos<a href="#editing-and-deleting-to-dos" title="Permalink to this headline"></a></h2>
<p>Now, let’s modify <code><span>api.html_todo</span></code> and make it more functional.</p>
<div><pre><span></span><span>create</span><span> </span><span>or</span><span> </span><span>replace</span><span> </span><span>function</span><span> </span><span>api</span><span>.</span><span>html_todo</span><span>(</span><span>api</span><span>.</span><span>todos</span><span>)</span><span> </span><span>returns</span><span> </span><span>text</span><span> </span><span>as</span><span> </span><span>$$</span>
<span>select</span><span> </span><span>format</span><span>(</span><span>$</span><span>html</span><span>$</span>
<span>&lt;li class="py-3"&gt;</span>
<span>  &lt;div class="flex justify-between items-center"&gt;</span>
<span>    &lt;div id="todo-edit-area-%1$s" class="pr-5"&gt;</span>
<span>      &lt;form id="edit-task-state-%1$s"</span>
<span>            hx-post="/rpc/change_todo_state"</span>
<span>            hx-vals='{"_id": %1$s, "_done": %4$s}'</span>
<span>            hx-target="#todo-list-area"</span>
<span>            hx-trigger="click"&gt;</span>
<span>        &lt;span class="ml-2 %2$s cursor-pointer"&gt;</span>
<span>          %3$s</span>
<span>        &lt;/span&gt;</span>
<span>      &lt;/form&gt;</span>
<span>    &lt;/div&gt;</span>
<span>    &lt;div&gt;</span>
<span>      &lt;button class="p-1.5 rounded-full hover:bg-gray-700 focus:ring-gray-800"</span>
<span>              hx-get="/rpc/html_editable_task"</span>
<span>              hx-vals='{"_id": "%1$s"}'</span>
<span>              hx-target="#todo-edit-area-%1$s"</span>
<span>              hx-trigger="click"&gt;</span>
<span>        &lt;svg class="w-4 h-4 text-blue-300" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" fill="currentColor" viewBox="0 0 20 18"&gt;</span>
<span>          &lt;path d="M12.687 14.408a3.01 3.01 0 0 1-1.533.821l-3.566.713a3 3 0 0 1-3.53-3.53l.713-3.566a3.01 3.01 0 0 1 .821-1.533L10.905 2H2.167A2.169 2.169 0 0 0 0 4.167v11.666A2.169 2.169 0 0 0 2.167 18h11.666A2.169 2.169 0 0 0 16 15.833V11.1l-3.313 3.308Zm5.53-9.065.546-.546a2.518 2.518 0 0 0 0-3.56 2.576 2.576 0 0 0-3.559 0l-.547.547 3.56 3.56Z"/&gt;</span>
<span>          &lt;path d="M13.243 3.2 7.359 9.081a.5.5 0 0 0-.136.256L6.51 12.9a.5.5 0 0 0 .59.59l3.566-.713a.5.5 0 0 0 .255-.136L16.8 6.757 13.243 3.2Z"/&gt;</span>
<span>        &lt;/svg&gt;</span>
<span>      &lt;/button&gt;</span>
<span>      &lt;button class="p-1.5 rounded-full hover:bg-gray-700 focus:ring-gray-800"</span>
<span>              hx-post="/rpc/delete_todo"</span>
<span>              hx-vals='{"_id": %1$s}'</span>
<span>              hx-target="#todo-list-area"</span>
<span>              hx-trigger="click"&gt;</span>
<span>        &lt;svg class="w-4 h-4 text-red-400" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 18 20"&gt;</span>
<span>          &lt;path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M1 5h16M7 8v8m4-8v8M7 1h4a1 1 0 0 1 1 1v3H6V2a1 1 0 0 1 1-1ZM3 5h12v13a1 1 0 0 1-1 1H4a1 1 0 0 1-1-1V5Z"/&gt;</span>
<span>        &lt;/svg&gt;</span>
<span>      &lt;/button&gt;</span>
<span>    &lt;/div&gt;</span>
<span>  &lt;/div&gt;</span>
<span>&lt;/li&gt;</span>
<span>$</span><span>html</span><span>$</span><span>,</span>
<span>  </span><span>$1</span><span>.</span><span>id</span><span>,</span>
<span>  </span><span>case</span><span> </span><span>when</span><span> </span><span>$1</span><span>.</span><span>done</span><span> </span><span>then</span><span> </span><span>'line-through text-gray-400'</span><span> </span><span>else</span><span> </span><span>''</span><span> </span><span>end</span><span>,</span>
<span>  </span><span>$1</span><span>.</span><span>task</span><span>,</span>
<span>  </span><span>(</span><span>not</span><span> </span><span>$1</span><span>.</span><span>done</span><span>)</span><span>::</span><span>text</span>
<span>);</span>
<span>$$</span><span> </span><span>language</span><span> </span><span>sql</span><span> </span><span>stable</span><span>;</span>
</pre></div>
<p>Let’s deconstruct the new htmx features added:</p>
<ul>
<li><p>The <code><span>&lt;form&gt;</span></code> element is configured as follows:</p>
<ul>
<li><p><code><span>hx-post="/rpc/change_todo_state"</span></code>: does an AJAX POST request to that endpoint. It will toggle the <code><span>done</span></code> state of the to-do.</p></li>
<li><p><code><span>hx-vals='{"_id":</span> <span>%1$s,</span> <span>"_done":</span> <span>%4$s}'</span></code>: adds the parameters to the request.
This is an alternative to using hidden inputs inside the <code><span>&lt;form&gt;</span></code>.</p></li>
<li><p><code><span>hx-trigger="click"</span></code>: htmx does the request after clicking on the element.</p></li>
</ul>
</li>
<li><p>For the first <code><span>&lt;button&gt;</span></code>:</p>
<ul>
<li><p><code><span>hx-get="/rpc/html_editable_task"</span></code>: it does an AJAX GET request to that endpoint.
It returns an HTML with an input that will allow us to edit the task.</p></li>
<li><p><code><span>hx-target="#todo-edit-area"</span></code>: the returned HTML will replace the element with this id.
In this case, this replaces an individual task, not the whole list.</p></li>
<li><p><code><span>hx-vals='{"id":</span> <span>"eq.%1$s"}'</span></code>: adds the query parameters to the GET request.
Note that this needs the <code><span>eq.</span></code> operator because it represents a table column not a function parameter.</p></li>
</ul>
</li>
<li><p>For the second <code><span>&lt;button&gt;</span></code>:</p>
<ul>
<li><p><code><span>hx-post="/rpc/delete_todo"</span></code>: this post request will delete the corresponding to-do.</p></li>
</ul>
</li>
</ul>
<p>Clicking on the first button will enable the task editing.
That’s why we create the <code><span>api.html_editable_task</span></code> function as an endpoint:</p>
<div><pre><span></span><span>create</span><span> </span><span>or</span><span> </span><span>replace</span><span> </span><span>function</span><span> </span><span>api</span><span>.</span><span>html_editable_task</span><span>(</span><span>_id</span><span> </span><span>int</span><span>)</span><span> </span><span>returns</span><span> </span><span>"text/html"</span><span> </span><span>as</span><span> </span><span>$$</span>
<span>select</span><span> </span><span>format</span><span> </span><span>(</span><span>$</span><span>html</span><span>$</span>
<span>&lt;form id="edit-task-%1$s"</span>
<span>      hx-post="/rpc/change_todo_task"</span>
<span>      hx-headers='{"Accept": "text/html"}'</span>
<span>      hx-vals='{"_id": %1$s}'</span>
<span>      hx-target="#todo-list-area"</span>
<span>      hx-trigger="submit,focusout"&gt;</span>
<span>  &lt;input class="bg-gray-50 border text-sm rounded-lg block w-full p-2.5 bg-gray-700 border-gray-600 text-white focus:ring-blue-500 focus:border-blue-500"</span>
<span>         id="task-%1$s" type="text" name="_task" value="%2$s" autofocus&gt;</span>
<span>&lt;/form&gt;</span>
<span>$</span><span>html</span><span>$</span><span>,</span>
<span>  </span><span>id</span><span>,</span>
<span>  </span><span>task</span>
<span>)</span>
<span>from</span><span> </span><span>api</span><span>.</span><span>todos</span>
<span>where</span><span> </span><span>id</span><span> </span><span>=</span><span> </span><span>_id</span><span>;</span>
<span>$$</span><span> </span><span>language</span><span> </span><span>sql</span><span>;</span>
</pre></div>
<p>In this example, this will return an input field that allows us to edit the corresponding to-do task.</p>
<p>Finally, let’s add the endpoints that will modify and delete the to-dos in the database.</p>
<div><pre><span></span><span>create</span><span> </span><span>or</span><span> </span><span>replace</span><span> </span><span>function</span><span> </span><span>api</span><span>.</span><span>change_todo_state</span><span>(</span><span>_id</span><span> </span><span>int</span><span>,</span><span> </span><span>_done</span><span> </span><span>boolean</span><span>)</span><span> </span><span>returns</span><span> </span><span>"text/html"</span><span> </span><span>as</span><span> </span><span>$$</span>
<span>  </span><span>update</span><span> </span><span>api</span><span>.</span><span>todos</span><span> </span><span>set</span><span> </span><span>done</span><span> </span><span>=</span><span> </span><span>_done</span><span> </span><span>where</span><span> </span><span>id</span><span> </span><span>=</span><span> </span><span>_id</span><span>;</span>
<span>  </span><span>select</span><span> </span><span>api</span><span>.</span><span>html_all_todos</span><span>();</span>
<span>$$</span><span> </span><span>language</span><span> </span><span>sql</span><span>;</span>

<span>create</span><span> </span><span>or</span><span> </span><span>replace</span><span> </span><span>function</span><span> </span><span>api</span><span>.</span><span>change_todo_task</span><span>(</span><span>_id</span><span> </span><span>int</span><span>,</span><span> </span><span>_task</span><span> </span><span>text</span><span>)</span><span> </span><span>returns</span><span> </span><span>"text/html"</span><span> </span><span>as</span><span> </span><span>$$</span>
<span>  </span><span>update</span><span> </span><span>api</span><span>.</span><span>todos</span><span> </span><span>set</span><span> </span><span>task</span><span> </span><span>=</span><span> </span><span>_task</span><span> </span><span>where</span><span> </span><span>id</span><span> </span><span>=</span><span> </span><span>_id</span><span>;</span>
<span>  </span><span>select</span><span> </span><span>api</span><span>.</span><span>html_all_todos</span><span>();</span>
<span>$$</span><span> </span><span>language</span><span> </span><span>sql</span><span>;</span>

<span>create</span><span> </span><span>or</span><span> </span><span>replace</span><span> </span><span>function</span><span> </span><span>api</span><span>.</span><span>delete_todo</span><span>(</span><span>_id</span><span> </span><span>int</span><span>)</span><span> </span><span>returns</span><span> </span><span>"text/html"</span><span> </span><span>as</span><span> </span><span>$$</span>
<span>  </span><span>delete</span><span> </span><span>from</span><span> </span><span>api</span><span>.</span><span>todos</span><span> </span><span>where</span><span> </span><span>id</span><span> </span><span>=</span><span> </span><span>_id</span><span>;</span>
<span>  </span><span>select</span><span> </span><span>api</span><span>.</span><span>html_all_todos</span><span>();</span>
<span>$$</span><span> </span><span>language</span><span> </span><span>sql</span><span>;</span>
</pre></div>
<p>All of those functions return an HTML list of to-dos that will replace the outdated one:</p>
<ul>
<li><p>The <code><span>api.change_todo_state</span></code> function updates the <code><span>done</span></code> column using the <code><span>_id</span></code> and the <code><span>_done</span></code> values from the request.</p></li>
<li><p>The <code><span>api.delete_todo</span></code> function deletes a to-do using the <code><span>_id</span></code> value from the request.</p></li>
<li><p>The <code><span>api.change_todo_task</span></code> function modifies the <code><span>task</span></code> column  using the <code><span>_id</span></code> and the <code><span>_task</span></code> value from the request.</p></li>
</ul>
<p>After refreshing the <a href="https://postgrest.org/en/stable/references/schema_cache.html#schema-reloading"><span>schema cache</span></a>, the page at <code><span>http://localhost:3000/rpc/index</span></code> will allow us to edit, delete and complete any to-do.</p>
<p><img alt="../_images/htmx-edit-delete.gif" src="https://postgrest.org/en/stable/_images/htmx-edit-delete.gif"></p><p>With that, we completed the to-do list functionality.</p>
</div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[3Blue1Brown Calculus Blog Series (266 pts)]]></title>
            <link>https://www.3blue1brown.com/topics/calculus</link>
            <guid>38687809</guid>
            <pubDate>Mon, 18 Dec 2023 20:34:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.3blue1brown.com/topics/calculus">https://www.3blue1brown.com/topics/calculus</a>, See on <a href="https://news.ycombinator.com/item?id=38687809">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><a data-active="false" data-mini="false" data-reverse="false" href="https://www.3blue1brown.com/lessons/essence-of-calculus"><div><p><img src="https://img.youtube.com/vi/WUvTyaaNkzM/maxresdefault.jpg" alt=""></p></div><p><span><span>The Essence of Calculus</span></span><span>An overview of what calculus is all about, with an emphasis on making it seem like something students could discover for themselves.  The central example is that of rediscovering the formula for a circle's area, and how this is an isolated instance of the fundamental theorem of calculus</span><span><span data-mini="false">Chapter 1</span><span data-mini="false"><i></i></span><span>Apr 28, 2017</span> </span></p></a><a data-active="false" data-mini="false" data-reverse="false" href="https://www.3blue1brown.com/lessons/derivatives"><div><p><img src="https://img.youtube.com/vi/9vKqVkMQHKk/maxresdefault.jpg" alt=""></p></div><p><span><span>The paradox of the derivative</span></span><span>An introduction to what a derivative is, and how it formalizes an otherwise paradoxical idea.</span><span><span data-mini="false">Chapter 2</span><span data-mini="false"><i></i></span><span>Apr 29, 2017</span> </span></p></a><a data-active="false" data-mini="false" data-reverse="false" href="https://www.3blue1brown.com/lessons/derivatives-power-rule"><div><p><img src="https://img.youtube.com/vi/S0_qX4VJhMQ/maxresdefault.jpg" alt=""></p></div><p><span><span>Power Rule through geometry</span></span><span>Introduction to the derivatives of polynomial terms thought about geometrically and intuitively. The goal is for these formulas to feel like something the student could have discovered, rather than something to be memorized.</span><span><span data-mini="false">Chapter 3</span><span data-mini="false"><i></i></span><span>Apr 30, 2017</span> </span></p></a><a data-active="false" data-mini="false" data-reverse="false" href="https://www.3blue1brown.com/lessons/derivatives-trig-functions"><div><p><img src="https://www.3blue1brown.com/content/lessons/2017/derivatives-trig-functions/thumbnail.png" alt=""></p></div><p><span><span>Trig Derivatives through geometry</span></span><span>Introduction to the derivatives trigonometric functions thought about geometrically and intuitively.</span><span><span data-mini="false">Chapter 4</span><span data-mini="false"><i></i></span><span>Apr 30, 2017</span> </span></p></a><a data-active="false" data-mini="false" data-reverse="false" href="https://www.3blue1brown.com/lessons/chain-rule-and-product-rule"><div><p><img src="https://img.youtube.com/vi/YG15m2VwSjA/maxresdefault.jpg" alt=""></p></div><p><span><span>Visualizing the chain rule and product rule</span></span><span>The product rule and chain rule in calculus can feel like they were pulled out of thin air, but is there an intuitive way to think about them?</span><span><span data-mini="false">Chapter 5</span><span data-mini="false"><i></i></span><span>May 1, 2017</span> </span></p></a><a data-active="false" data-mini="false" data-reverse="false" href="https://www.3blue1brown.com/lessons/eulers-number"><div><p><img src="https://img.youtube.com/vi/m2MIpDrF7Es/maxresdefault.jpg" alt=""></p></div><p><span><span>What's so special about Euler's number e?</span></span><span>What is the derivative of a^x?  Why is e^x its own derivative?  This video shows how to think about the rule for differentiating exponential functions.</span><span><span data-mini="false">Chapter 6</span><span data-mini="false"><i></i></span><span>May 2, 2017</span> </span></p></a><a data-active="false" data-mini="false" data-reverse="false" href="https://www.3blue1brown.com/lessons/implicit-differentiation"><div><p><img src="https://img.youtube.com/vi/qb40J4N1fa4/maxresdefault.jpg" alt=""></p></div><p><span><span>Implicit differentiation, what's going on here?</span></span><span>How to think about implicit differentiation in terms of functions with multiple inputs, and tiny nudges to those inputs.</span><span><span data-mini="false">Chapter 7</span><span data-mini="false"><i></i></span><span>May 3, 2017</span> </span></p></a><a data-active="false" data-mini="false" data-reverse="false" href="https://www.3blue1brown.com/lessons/limits"><div><p><img src="https://img.youtube.com/vi/kfF40MiS7zA/maxresdefault.jpg" alt=""></p></div><p><span><span>Limits and the definition of derivatives</span></span><span>What are limits? How are they defined? How are they used to define the derivative?</span><span><span data-mini="false">Chapter 8</span><span data-mini="false"><i></i></span><span>May 4, 2017</span> </span></p></a><a data-active="false" data-mini="false" data-reverse="false" href="https://www.3blue1brown.com/lessons/epsilon-delta"><div><p><img src="https://www.3blue1brown.com/content/lessons/2017/epsilon-delta/thumbnail.png" alt=""></p></div><p><span><span>(ε, δ) "epsilon delta" definitions of limits</span></span><span>How does (ε, δ) "epsilon delta" help us formalize what exactly it means for one value to approach another?</span><span><span data-mini="false">Chapter 9</span><span data-mini="false"><i></i></span><span>May 4, 2017</span> </span></p></a><a data-active="false" data-mini="false" data-reverse="false" href="https://www.3blue1brown.com/lessons/l-hopitals-rule"><div><p><img src="https://www.3blue1brown.com/content/lessons/2017/l-hopitals-rule/thumbnail.png" alt=""></p></div><p><span><span>L'Hôpital's rule</span></span><span>What is L'Hopital's rule and how does it help us evaluate limits?</span><span><span data-mini="false">Chapter 10</span><span data-mini="false"><i></i></span><span>May 4, 2017</span> </span></p></a><a data-active="false" data-mini="false" data-reverse="false" href="https://www.3blue1brown.com/lessons/integration"><div><p><img src="https://img.youtube.com/vi/rfG8ce4nNh0/maxresdefault.jpg" alt=""></p></div><p><span><span>Integration and the fundamental theorem of calculus</span></span><span>What is integration?  Why is it computed as the opposite of differentiation?  What is the fundamental theorem of calculus?</span><span><span data-mini="false">Chapter 11</span><span data-mini="false"><i></i></span><span>May 5, 2017</span> </span></p></a><a data-active="false" data-mini="false" data-reverse="false" href="https://www.3blue1brown.com/lessons/area-and-slope"><div><p><img src="https://www.3blue1brown.com/content/lessons/2017/area-and-slope/thumbnail-2880-1620.png" alt=""></p></div><p><span><span>What does area have to do with slope?</span></span><span>Derivatives are about slope, and integration is about area. These ideas seem completely different, so why are they inverses?</span><span><span data-mini="false">Chapter 12</span><span data-mini="false"><i></i></span><span>May 6, 2017</span> </span></p></a><a data-active="false" data-mini="false" data-reverse="false" href="https://www.3blue1brown.com/lessons/higher-order-derivatives"><div><p><img src="https://img.youtube.com/vi/BLkz5LGWihw/maxresdefault.jpg" alt=""></p></div><p><span><span>Higher order derivatives</span></span><span>What is the second derivative?  Third derivative?  How do you think about these?</span><span><span data-mini="false">Chapter 13</span><span data-mini="false"><i></i></span><span>May 7, 2017</span> </span></p></a><a data-active="false" data-mini="false" data-reverse="false" href="https://www.3blue1brown.com/lessons/taylor-series"><div><p><img src="https://www.3blue1brown.com/content/lessons/2017/taylor-series/thumbnail.png" alt=""></p></div><p><span><span>Taylor series</span></span><span>Taylor series are extremely useful in engineering and math, but what are they?  This video shows why they're useful, and how to make sense of the formula.</span><span><span data-mini="false">Chapter 14</span><span data-mini="false"><i></i></span><span>May 7, 2017</span> </span></p></a><a data-active="false" data-mini="false" data-reverse="false" href="https://www.3blue1brown.com/lessons/taylor-series-geometric-view"><div><p><img src="https://img.youtube.com/vi/3d6DsjIBzJ4/maxresdefault.jpg" alt=""></p></div><p><span><span>Taylor series (geometric view)</span></span><span>A different perspective of Taylor Series that's related to the fundamental theorem of calculus.</span><span><span data-mini="false">Chapter 15</span><span data-mini="false"><i></i></span><span>May 7, 2017</span> </span></p></a><a data-active="false" data-mini="false" data-reverse="false" href="https://www.3blue1brown.com/lessons/derivatives-and-transforms"><div><p><img src="https://img.youtube.com/vi/CfW845LNObM/maxresdefault.jpg" alt=""></p></div><p><span><span>The other way to visualize derivatives</span></span><span>A visual for derivatives which generalizes more nicely to topics beyond calculus. Thinking of a function as a transformation, the derivative measure how much that function locally stretches or squishes a given region.</span><span><span data-mini="false">Chapter 16</span><span data-mini="false"><i></i></span><span>May 19, 2018</span> </span></p></a></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PostgreSQL 16 Bi-Directional Logical Replication (101 pts)]]></title>
            <link>https://www.highgo.ca/2023/12/18/new-in-postgresql-16-bi-directional-logical-replication/</link>
            <guid>38687357</guid>
            <pubDate>Mon, 18 Dec 2023 19:58:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.highgo.ca/2023/12/18/new-in-postgresql-16-bi-directional-logical-replication/">https://www.highgo.ca/2023/12/18/new-in-postgresql-16-bi-directional-logical-replication/</a>, See on <a href="https://news.ycombinator.com/item?id=38687357">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                        
<h2>Introduction</h2>



<p>In this blog, we’ll be going over some more advanced topics new in Postgres 16. Having some experience with Linux, Postgres, and SQL is necessary as we’ll not only be going over these new features but also how to implement them. This blog was written using PostgreSQL 16 (Development Version) running on Ubuntu 23.04. First I’ll go over some background and a brief introduction to what Bi-Directional Replication is, and why it’s important, then finish off with how we implement Bi-Directional Logical Replication.</p>



<h2>Background</h2>



<p>Before we can start learning about Bi-Directional Logical Replication we first have to understand Logical Replication.</p>



<h3>Basics of Logical Replication</h3>



<p>Logical replication has been supported since PostgreSQL 10 and has received numerous updates and improvements in the following years. Logical Replication is the process of copying (ie. replicating) data objects represented as their changes. This way we can copy only specific changes of objects like tables rather than whole databases, and stream these changes across different platforms and versions. This is all in contrast to Physical replication which uses exact block addresses and as a result, is limited to only copying entire databases and cannot stream across platforms or versions since the data must match in both.</p>



<figure><img decoding="async" loading="lazy" width="701" height="231" src="https://www.highgo.ca/wp-content/uploads/2023/12/logical-replication-1.png" alt="" srcset="https://www.highgo.ca/wp-content/uploads/2023/12/logical-replication-1.png 701w, https://www.highgo.ca/wp-content/uploads/2023/12/logical-replication-1-300x99.png 300w" sizes="(max-width: 701px) 100vw, 701px"><figcaption>Fig 1: Logical Replication Architecture Overview</figcaption></figure>



<p>Logical replication also introduces two very important elements necessary for understanding its Bi-Directional counterpart. These are Publishers and Subscribers, you can think of them as a leader node (Publisher) and a follower node (Subscriber). The Publisher will gather up its recent changes and send them as an ordered list of commands to the Subscriber. Once received the Subscriber takes this series of commands and applies it to its data. If both databases started with the same data, then the Subscriber will be up-to-date with the Publisher.</p>



<h3>Bi-Directional Replication</h3>



<p>Now that we understand what Logical Replication is, what is Bi-Directional Replication doing differently? In short, Bi-Directional Logical Replication is when all nodes in the replication are both Publisher and Subscriber. Each database can now handle read and write requests, and all the changes will be streamed to one another. This is the Bi-Directional aspect, as rather than changes flowing in one direction as before, they flow in both directions.</p>



<figure><img decoding="async" loading="lazy" src="https://www.highgo.ca/wp-content/uploads/2023/12/unnamed.png" alt="" width="434" height="218" srcset="https://www.highgo.ca/wp-content/uploads/2023/12/unnamed.png 401w, https://www.highgo.ca/wp-content/uploads/2023/12/unnamed-300x150.png 300w" sizes="(max-width: 434px) 100vw, 434px"><figcaption>Fig. 2: Bi-Directional Replication Architecture Overview</figcaption></figure>



<p>What Postgres 16 adds is a new parameter to the WITH statement that filters out replication from certain nodes. Bi-Directional Logical Replication uses this parameter WITH(ORIGIN = NONE), this filters out all replication from connections with origins that are not NONE. Essentially, this only allows newly added data to be replicated, you can probably see why this is the case. If one database inserts new data and replicates it to a second, this second database will replicate the data also inserting it thus triggering another replication to the original database. We quickly get an infinite loop of replication, which is why this option is necessary to keep everything finite.</p>



<h4>Benefits</h4>



<p>The main benefit of Bi-Direction Logical Replication is that it allows more availability for both read and write requests since we have two Primary nodes. This can be extremely beneficial for a wide range of applications where writing is especially needed.</p>



<h4>Drawbacks</h4>



<p>Bi-Directional Logical Replication requires a few preconditions to operate correctly, as such many of its drawbacks are from these specific conditions. For example, when setting up replication the tables in each database must follow the same schema. Same name and columns, otherwise the Subscriber will not be able to find the table. Until Logical Replication can support replication of the Data Definition Language (DDL) used to create the tables, the user must do this manually to ensure consistency.</p>



<h2>Setting Up</h2>



<p>Now that we understand the basics of Bi-Directional Logical Replication, we can look into how we implement it between two databases. The beginning will be quite similar to setting up regular Logical Replication, but with a very important difference when we are creating the Publishers and Subscribers.</p>



<p>First, we will create the two primary databases which will follow each other:</p>



<pre><code>$ initdb -D database1
$ initdb -D database2</code></pre>



<p>In each database’s postgres.conf file set each’s way_level to logical and give each one a unique port number:</p>



<h4>postgres.conf database1</h4>



<pre><code>port = 5432
wal_level = logical</code></pre>



<h4>postgres.conf database2</h4>



<pre><code>port = 5433
wal_level = logical</code></pre>



<p>Start both databases:</p>



<pre><code>pg_ctl -D database1 -l database1.log start
pg_ctl -D database2 -l database2.log start</code></pre>



<p>Create the Publishers for each Database:</p>



<pre><code># CREATE PUBLICATION mypub1 FOR TABLE mytable;
# CREATE PUBLICATION mypub2 FOR TABLE mytable;</code></pre>



<p>Create the Subscribers for each Database:</p>



<pre><code># CREATE SUBSCRIPTION mysub1 CONNECTION 'host=127.0.0.1 port=5433 user=postgres dbname=postgres' PUBLICATION mypub2 WITH(ORIGIN = NONE);

# CREATE SUBSCRIPTION mysub2 CONNECTION 'host=127.0.0.1 port=5432 user=postgres dbname=postgres' PUBLICATION mypub1 WITH(ORIGIN = NONE); </code></pre>



<p>Note the order we created the publishers and subscribers, it is very important to first create the Publishers and then the Subscribers. You can refer to Figure 2 if you want a more visual representation, the number in the corner of each component denotes the order of their creation.</p>



<p>Now, when any data is inserted into either database, it should be replicated across both nodes.</p>



<h2>Conclusion</h2>



<p>In this blog, we went over the new Bi-Directional Logical Replication feature in PostgreSQL 16. To start, we went over a brief background on Logical Replication and the Publisher/Subscriber model used for synchronizing data. We then went over how Bi-Directional Logical Replication works and the new parameter that allows it to function without triggering infinite replication loops. Finally, we looked at how to set up Bi-Directional Replication with two primary PostgreSQL databases. With support for synchronization between primary nodes, increasing availability and data persistence should be a breeze for any of your database applications.</p>



<h2>References</h2>



<ul>
<li>C, Vigneshwaran. <em>Bi-Directional Replication Using Origin Filtering in PostgreSQL</em>, Fujitsu, 31 Aug. 2023, www.postgresql.fastware.com/blog/bi-directional-replication-using-origin-filtering-in-postgresql.</li>
</ul>
<div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img alt="Tristen Raab" src="https://secure.gravatar.com/avatar/dc00783f1bcdc3fc1c905031e7fd9373?s=100&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/dc00783f1bcdc3fc1c905031e7fd9373?s=200&amp;d=mm&amp;r=g 2x" height="100" width="100" itemprop="image" loading="lazy" decoding="async"></p><div><p>Tristen received his Bachelor of Applied Science in Computer Engineering from the University of British Columbia in May 2023. He joined HighGo Software Inc. as a Software Engineer fresh out of university and is very excited for his engineering journey to begin. His main interests include Machine Learning, Embedded Systems, and Database Management Systems. With experience in C/C++ and advanced relational databases, Tristen hopes to contribute significantly to the PostgreSQL community as he continues to learn and grow his expertise.</p></div></div>                                                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The teenager who lives like it's the 1940s (213 pts)]]></title>
            <link>https://www.bbc.com/news/articles/crgpjpr35nko</link>
            <guid>38687171</guid>
            <pubDate>Mon, 18 Dec 2023 19:41:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/crgpjpr35nko">https://www.bbc.com/news/articles/crgpjpr35nko</a>, See on <a href="https://news.ycombinator.com/item?id=38687171">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content" data-testid="main-content"><article><header data-component="headline-block"></header><div data-component="video-block"><figure><figcaption><span>Media caption, </span><p>Callum drives his 1938 Austin Cambridge around Kirkcaldy (Video by Georgina Davies)</p></figcaption></figure></div><div data-component="text-block"><p>Callum Grubb is only 19 but he lives his life as if it is the 1940s.</p><p>Nearly everything he owns is from the time period, including his clothes.</p><p>The teenager drives a black 1938 Austin Cambridge, only uses a telephone from the 1940s, and rides a 1952 Raleigh bicycle.</p><p>"I joke to my friend, that it's gone beyond an obsession," he says.</p><p>"I'm as old-fashioned as they come."</p></div><div data-component="image-block"><figure><figcaption><span>Image caption, </span><p>Callum is an avid collector of everything and anything 1940s</p></figcaption></figure></div><div data-component="image-block"><figure><p><span><span></span></span><span role="text"><span>Image source, </span>Ron Walker</span></p><figcaption><span>Image caption, </span><p>Callum's car is 10 years older than his grandmother, Anne</p></figcaption></figure></div><div data-component="text-block"><p>Callum's car is 10 years older than his grandmother, Anne, who he has lived with at her home in Kirkcaldy, Fife, since he was 12.</p><p>And while 75-year-old Anne regularly uses a mobile phone, her grandson does not even own one.</p><p>"I'm rubbish with technology," Callum says.</p><p>"I was forced to have a laptop for college, and I hated it."</p></div><div data-component="image-block"><figure><figcaption><span>Image caption, </span><p>Callum and his grandmother have lived together for seven years</p></figcaption></figure></div><div data-component="text-block"><p>Callum says he fell in love with the 40s during his first year of high school.</p><p>"I've always loved history," he says.</p><p>"When I was younger, I looked at my great grandad's prisoner-of-war diaries and I just love everything about the period."</p><p>He now collects everything related to the period, such as oil lamps and a vintage record player that he uses to listen to his favourites like Vera Lynn, Anne Shelton and Frank Sinatra.</p><p>"I couldn't tell you a modern singer if you asked me," he says.</p><p>However, Callum told the BBC's Good Morning Scotland programme - via his 1940s Bakelite rotary-dial telephone - that there is one thing from the post-war period he definitely does not do.</p><p>"We don’t ration,” he says. “I like my food too much for that."</p></div><div data-component="image-block"><figure><figcaption><span>Image caption, </span><p>Callum with another of his vintage telephone, which will soon be connected to his landline</p></figcaption></figure></div><div data-component="text-block"><p>Callum's latest addition to his vintage collection is his car, a 1938 Austin Cambridge named Poppy.  </p><p>He had been saving up for the purchase since he was 13.</p><p>"Callum just came and told me, 'I want an old Austin'," his mum Claire says.</p><p>"I didn't think it would ever happen."</p><p>He bought the car for £7,000 in early November from a man he met while visiting a museum. </p><p>"It has no seatbelts, but I absolutely love it," Callum says.</p><p>He has the original invoice showing the car cost £215 in 1938, the equivalent of about £18,000 today.</p></div><div data-component="image-block"><figure><figcaption><span>Image caption, </span><p>Callum's car, Poppy, has a bench seat in the back, no seatbelts, and an all-leather interior</p></figcaption></figure></div><div data-component="text-block"><p>It is not illegal to drive a classic car without seatbelts - and Callum has driven his nearly every day since he got it.</p><p>"It's like you are back in time, especially when you get into the old country roads," he says.</p><p>"The car survived the blitz in London but it can only reach 50mph and even that is pushing it," Callum laughs.</p><p>"It's great to drive, there's always a clear road ahead but behind a sea of traffic.</p><p>"But folk don't tend to mind," he adds.</p></div><div data-component="image-block"><figure><p><span><span></span></span><span role="text"><span>Image source, </span>Ron Walker</span></p><figcaption><span>Image caption, </span><p>Callum's car is the most valued piece in his collection</p></figcaption></figure></div><div data-component="text-block"><p>Callum is regularly seen around Kirkcaldy in his car, and has become a local celebrity.</p><p>He was even invited by a local bakery to park his car outside the front of their store for a grand-opening. </p><p> "People of all ages wave at the car, old and young alike," Callum says.</p><p>But he regularly takes the car further afield than Kirkcaldy. </p><p>"We love to run along the coast in the old car, my friend Lynsey and I," he says.</p><p>"I usually stop at the antique shops along the way because it can be hard to get some of my clothes.</p><p>"My gran dreads me coming home because she knows I'll end up bringing something back with me."</p></div><div data-component="image-block"><figure><p><span><span></span></span><span role="text"><span>Image source, </span>Ron Walker</span></p><figcaption><span>Image caption, </span><p>Callum likes to take trips along the coast in his car, with his friend Lynsey</p></figcaption></figure></div><div data-component="text-block"><p>Callum says people used to be shocked when he said he did not have a mobile phone.</p><p>"I keep very busy, I assure you," he says.</p><p>He spends a lot of time with his car, maintaining and servicing it, even though it does not require an MOT or road tax, like all cars manufactured more than 40 years ago.</p><p>When Callum isn't with his car, he's out with friends or working at the local dog kennels.</p><p>He says he has friends of all ages, although he admits he shares more in common with people much older than him.</p><p>"I always get to chat to older people, they tell me they remember their dad or granddad with the car when they were my age," he says.</p></div><div data-component="image-block"><figure><p><span><span></span></span><span role="text"><span>Image source, </span>Ron Walker</span></p><figcaption><span>Image caption, </span><p>Callum and his much-loved rescue dog, Cassie</p></figcaption></figure></div><div data-component="text-block"><p>Callum's gran, Anne Walker, says her house has become the epicentre for Callum's collections.</p><p>"I wake up to a picture of Winston Churchill and an old vintage car," she says.</p><p>Callum has lived at his gran's house since he was 12, after his grandad, John, suddenly passed away. He's kept her company ever since.</p><p>"I've learned more about history from Callum, than I've ever known," the 75-year-old says.</p><p>"We always watch old films together, he's in love with Ginger Rogers," Anne says.</p></div><div data-component="image-block"><figure><figcaption><span>Image caption, </span><p>One of the rarest items in Callum's collection is a coronation mug for King Edward VIII </p></figcaption></figure></div><div data-component="text-block"><p>Callum's mum, Claire, is a nursery officer at Fife Council, and says she has always supported his decision.</p><p>"Callum went away on a school trip when he was about 12 and came back with an old-fashioned hat on," she says.</p><p>"I thought it was funny, and I just asked him, 'Where did you find this?'.</p><p>"He said 'that's the way I want to dress, that's going to be me'.</p><p>"Ever since then, that's just been Callum," his mum says.</p><p>Claire says that Callum is doing great, and she's watched him blossom into a 1940s gentlemen.</p></div><div data-component="image-block"><figure><p><span><span></span></span><span role="text"><span>Image source, </span>Claire Grubb</span></p><figcaption><span>Image caption, </span><p>Callum wasn't always in love with 40s</p></figcaption></figure></div><div data-component="text-block"><p>Callum says he can't understand other people's fascination with his collection.</p><p>"You never think you're that interesting" he says.</p><p>"This is just my life."</p><p>Callum says: "A lot of these cars sit in a museum and are never used, but that's not what they're for, they're meant to be used.</p><p>"So that's what I'm doing.</p><p>"It's good to see the reaction, I always go by and beep the horn." </p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[To be great, be good, repeatably (2019) (127 pts)]]></title>
            <link>https://blog.stephsmith.io/how-to-be-great/</link>
            <guid>38686997</guid>
            <pubDate>Mon, 18 Dec 2023 19:26:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.stephsmith.io/how-to-be-great/">https://blog.stephsmith.io/how-to-be-great/</a>, See on <a href="https://news.ycombinator.com/item?id=38686997">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="site-main">
<article>

<figure>
<img srcset="https://blog.stephsmith.io/content/images/size/w300/2019/06/Screen-Shot-2019-06-01-at-6.19.20-PM-3.png 300w,
                            https://blog.stephsmith.io/content/images/size/w600/2019/06/Screen-Shot-2019-06-01-at-6.19.20-PM-3.png 600w,
                            https://blog.stephsmith.io/content/images/size/w1000/2019/06/Screen-Shot-2019-06-01-at-6.19.20-PM-3.png 1000w,
                            https://blog.stephsmith.io/content/images/size/w2000/2019/06/Screen-Shot-2019-06-01-at-6.19.20-PM-3.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://blog.stephsmith.io/content/images/size/w2000/2019/06/Screen-Shot-2019-06-01-at-6.19.20-PM-3.png" alt="How to Be Great? Just Be Good, Repeatably">
</figure>
<div>
<p><em>Edit: Thank you to the 100k people who have read this piece. It looks like many people are struggling with the concept of "greatness". Let's continue to support one another on the journey there. </em></p><p>Over the years, we’ve all encountered our fair share of successes and failures. As I’ve acquired more of both under my name, I’ve started to contemplate which experiences were truly “great” and why.</p><p>Interestingly enough, I realized that it was not the sporadic highs that were exceptional, but instead the long hauls; the sequences of events that seemed minimal at each juncture, but compounded into major gains. This led me to think further about what <em>greatness</em> truly means. I’ve come to learn that it’s not about overnight successes or flashes of excellence, but periods of repeatable habits.</p><blockquote><em><strong>Perhaps “great’, is just “good”, but repeatable. </strong></em></blockquote><h2 id="consider-this">Consider This</h2><p>Before stepping into the bulk of this article, I want to clarify two things:</p><ul><li>Greatness is not instantaneous</li><li>Greatness is earned</li></ul><p>The first step in becoming great is recognizing that you’re likely not already great. In fact, it comes from recognizing that there is no such thing as greatness at a specific instance in time. Greatness is instead a reflection of a period of effort, since greatness in a single instance can be reduced to luck. </p><p>Moreover, being “great” is not about being better than someone else. It is about being dependable and disciplined, and ultimately it is earned. </p><p>Many people, in theory, want to be “great”. In fact, each month 1000 people search “how to be great”, 260 people search “how to become perfect”, and 2400 people search “how to be the best”, looking for discrete answers on how to get from 0 to 1. Yet, many people in life realistically do not want to put in the effort over a sustained period of time to actually get to 1. They are looking for the “secrets to success” that in many ways, do not exist. You know what brings success? Hard work brings success. </p><p>So before proceeding forward in this article, I implore each of you to consider that if greatness truly is a reflection of non-instantaneous, earned effort, ask yourself if that’s the life you’d like to live. Ask yourself whether you’d like to spend your days, weeks, months, and years in a constant uphill battle. </p><p>If you ultimately find that you don’t want to do that, that’s fine! It doesn’t make you less of a person. At least you’ve broken from the holding pattern of thinking you want to do X but not understanding why you haven’t gotten there yet. And if that’s the case, go enjoy your Netflix and chill completely guilt-free.</p><p>With that in mind, let’s dive into what truly makes someone “great’. </p><h2 id="it-s-hard-to-be-consistent">It’s Hard to be Consistent</h2><p>There’s a false impression that success or notoriety comes with being flashy. This notion comes from the media focusing on outliers, whether it be events or personalities which diverge from the norm. Not only can this encourage people to aim for notoriety just for the sake of it (think Elizabeth Holmes), but it makes the rest of us believe that correlation (of those outliers) is causation; in other words, success of those individuals is due to their offbeat ways. But here’s another storyline: the most sure and therefore the <em>best</em> way to “success” is through consistency.</p><blockquote><em>“Until you work as hard as those you admire, don’t explain away their success as luck.”</em> - James Clear, <a href="https://amzn.to/31t6vQZ">Atomic Habits</a></blockquote><p>To be clear, consistency isn’t necessarily the easiest way to success, but one that can be achieved with a higher level of certainty, rather than hoping for a lottery win or someone to “discover” you. Continuous effort is a more thoughtful approach that leads to greatness when the following statements are true:</p><ol><li>Inputs are consistent over time</li><li>Intentional inputs lead to expected outputs</li></ol><h3 id="consistency">Consistency<br></h3><blockquote><em>“No one who can rise before dawn three hundred sixty days a year fails to make his family rich”</em> - <a href="https://amzn.to/2Fcnn4K">Outliers</a></blockquote><p>There is a famous saying from Napolean Hill which says, <em>“If you cannot do great things, do small things in a great way”</em>. I would actually argue the quote should be, <em>“If you cannot do great things, do small things a great number of times”.</em></p><p>If you don’t have the opportunity to “do great things”, focus on consistently achieving small wins. These small things in fact do not need to be done in a great way, but a good way, repeatably. In fact, I would advise not to focus on perfection, as it is often the enemy of the successful. </p><p>There’s glimmer and hoopla around unpredictability, but in reality, it’s much more difficult and therefore impressive, to be predictably good. For example:</p><ul><li>It’s easy to wake up whenever you “feel like it”. </li><li>It’s hard to stick to a routine of getting up at 6AM.</li><li>It’s easy to pivot from side project to side project, focusing on the new shiny object of the month.</li><li>It’s hard to stick with a side project for years, many of which may not be profitable for a long while. </li><li>It’s easy to give up on someone when you hit a roadblock or the next potential partner becomes available. </li><li>It’s hard to be faithful and invest in a relationship for decades.</li></ul><p>We normally set out in life with good intentions. We <em>intend</em> to set a morning routine or work on a business until it's profitable or to “love someone forever”. We imagine that as we invest in something, we will naturally continue to move in the right direction. If anything, things will get easier, right?</p><figure><img src="https://lh4.googleusercontent.com/NQV_7RXfM2ZYDJsT4E4JAaAW2i9KphrB7-fE8XveJlrW-Msf1aIot9ayls-wSCWIroq155Fzdz6vE3d8br71E6Tc5sTQRyhnT0Zb6EJCUoV41B5EoZSczjtWcHo9KV-T9c6s16Cb"></figure><p>The described trajectory is what we perceive on the left. Predictable, linear, and a direct reflection of effort put in. </p><p><strong>Rarely does success in anything look like that.</strong> Life is a series of tiny nodes that tend to look more like the right hand side. There two key elements worth calling out in the more realistic graph on the right:</p><ul><li>Compounding is always present. The earlier steps in any process will be more strenuous, yet it’s difficult to imagine the potential compounding that comes later on. </li><li>With the ups, there are always downs. This seems obvious, but we often forget this when we are in periods of down. We quit at these local minimums (the highlighted sections in red above), because we cannot see the next peak right around the corner. </li></ul><figure><blockquote><div lang="en" dir="ltr"><p>a friend just emailed me this note in response to my 'burn out' video. wanted to share;</p><p>'the addiction to having success is what makes you feel unsuccessful at the times when you're not feeling the immediate dopamine hit of your work 'succeeding' at that precise moment.'</p></div>— Casey Neistat (@Casey) <a href="https://twitter.com/Casey/status/1093520669286064133?ref_src=twsrc%5Etfw">February 7, 2019</a></blockquote>

</figure><figure><blockquote><p lang="en" dir="ltr">We have lost our ability to appreciate delayed gratification and, some of us who struggle with perfectionism, can either create repeatedly until we ‘get it right’ never truly feeling fulfilled with our work, or, we avoid creating all together in fear of failing.</p>— Marcio Novelli (@MarcioNovelli) <a href="https://twitter.com/MarcioNovelli/status/1093522120536150017?ref_src=twsrc%5Etfw">February 7, 2019</a></blockquote>

</figure><p>The local minima are especially psychologically taxing due to something called the <a href="https://en.m.wikipedia.org/wiki/Hedonic_treadmill">Hedonic treadmill</a> or hedonic adaptation. Essentially, as someone achieves new successes in various aspects of their lives, their baseline shifts to reflect that new level and therefore, their expectations and desires are re-established as well. There is no net gain in happiness and thus, it becomes even more difficult to stay “level-headed” during these down moments. </p><p>That is exactly why a specific search for success can be problematic and instead of looking for unsustainable shortcuts in life, it’s much more effective (and healthy) to aim for continuous habits that bring you success as a byproduct, not as the end goal.</p><blockquote><em>“The only way to become excellent is to be endlessly fascinated by doing the same thing over and over. You have to fall in love with boredom.” - <a href="https://amzn.to/31t6vQZ">Atomic Habits</a>, James Clear</em></blockquote><p>On your journey to greatness, you need to fall in love with the process which includes many local minima and maxima. Staying consistent and pushing through both of these continuously is what will truly differentiate you from those that are simply “good” and isolate you as one of the few that are “great’.</p><h3 id="inputs-outputs">Inputs → Outputs</h3><p>The second important aspect of achieving greatness is acting with intention. Your actions and results will not always reflect your intentions, but as you move towards “greatness”, you should have a better idea of what inputs actually deliver output. You’ll still make mistakes﹣as we all do﹣but you’ll have a better grasp on what is more likely to work out. For example, your success rate may be 30%, versus someone flying blind with a 5% success rate. </p><p>Let’s look at a simple example:</p><p>Imagine company X has two sales people. Salesperson A happens to land a $1M deal in his first week. However, he struggles to land anything substantial for the next 6 months. Meanwhile, salesperson B manages to develop a process over the first month, bringing in only $100k which he’s able to scale up and double month over month.</p><p>After six months, this will be the revenue generated by each party.</p><figure><img src="https://blog.stephsmith.io/content/images/2019/05/image-5.png"></figure><p>You’re probably thinking… "So what? That’s just a classic example of compounding." </p><p>Yes! That’s exactly the point. The best things in life often aren’t miracles, but well-thought out approaches that are sustainable. The same thing is true with businesses, marriages, and just about anything with repeatable elements. If you invest time into solving for what leads to success continuously, you will reap those benefits for years to come. <em>So even in the least quantifiable situations, reflect back on what could’ve made a previous loss a future win. </em></p><p>Consider the best companies over time. None of them emerged overnight, nor was there a single inflection point that determined the success or notoriety of these companies. The line of separation between the “great” companies of all time and the “not so great”, is their ability to stand the test of time. </p><p>Would you rather be Juicero that <a href="https://www.crunchbase.com/organization/juicero">raised $100M</a> and <a href="https://techcrunch.com/2017/09/01/rip-juicero-the-400-venture-backed-juice-machine/">went bankrupt</a> within a year of its Series C, or Zoom, which <a href="https://www.crunchbase.com/organization/zoom-video-communications/funding_rounds/funding_rounds_list#section-funding-rounds">took almost 8 years to take on more funding than $30M</a> and is now one of the most profitable and highly sought after “unicorns” in the valley?</p><p>On top of consistency, greatness comes from asking the right questions and iterating to learn what inputs drive favourable outputs, and ideally <strong>why</strong>. “Greatness” comes from an identified or researched process that when followed, has some degree of certainty in the outcome. </p><p>“Moving fast and breaking things” is not a strategy, unless you are clearly defining a process of learning so that in the future, you can “move fast and break less of the same things”.</p>


<h2 id="a-habit-of-progression">A Habit of Progression</h2><blockquote><em>“The definition of insanity is doing the same thing over and over again, but expecting different results.” </em>- Albert Einstein</blockquote><p>Understand that in order to achieve the things you want in life, you’ll need to establish a <strong>habit of progression</strong>. You literally need to become good at being decent. </p><p>There is one thing to clarify: this habit of progression must come with the right inputs. Being consistent with something leading you in the wrong direction, will <em>unsurprisingly</em> lead you in the wrong direction. So if this is the way you are constantly moving (excluding short periods of local minima), pivot until you determine what the right inputs are. I recently stumbled upon a concept of <a href="https://web.archive.org/web/20200908160755/jdreyespaez.site/zero-acceleration/">zero acceleration, but non-zero velocity</a>, which encapsulates this idea well. </p><p>Before you find the path that you want to double down on, this habit of progression takes the form of iteration. I see many people who are stuck in this stage and feel like they’re moving nowhere. Perhaps they go take a degree for a year and find that wasn’t right. Maybe they go and work for a company for two more and realize that wasn’t right either. </p><p>If you’re struggling to identify the right path, create more nodes of optimization. For example: if you’re making changes every year, you only have maybe 80 in your entire life to make. Instead, try testing things intentionally every month or even every week. Pilot a lot and then double down when you have found your path towards “good”. </p><p>You may ask, “what makes good, good?”. Ask yourself the question: “If I were to continue this every day for the next year, would I be in a better place?” If the answer is yes, you have a path towards “good”. </p><p>Once you have found your inputs, then you’re in a good place to turn those inputs into the right habits through deliberate practice. Ie: you’ll be in a place to shift from good to great. </p><p>This process of shifting between iteration and consistency is all part of developing a habit of progression. Once you make this habit your north star, you are no longer dependent on that &nbsp;“one big break” or that one company to “finally give you a chance”. </p><p>And finally, if you’re reading this advice and think, “I’ve heard this before”, then ask yourself whether you’ve truly acted on this advice. When is the last time you truly iterated and tried new things? When is the last time you found something <em>good</em> and then truly stuck to it for years?</p><h2 id="two-steps-out">Two Steps Out </h2><p>While you’re moving towards “greatness”, keep in mind that it will likely happen slowly and that’s okay.</p><p>When I think about the growth trajectory of my life and similarly, anyone that I’ve been close with, changes have always happened slowly. Whether it was a close family member falling into deep mental illness or friends building businesses to near-unicorn valuations, nothing ever happened overnight. Even more notably, no one would have ever expected those outcomes years prior. </p><p>In the grand scheme of things, I think it’s because you can only ever see two steps out. What do I mean by that?</p><p>Say that in life there are 100 tiers of happiness. Of course, life is more complicated and dynamic than this view, but bear with me for a minute. Let’s say that you’re on “Tier 57”. &nbsp;You may be able to see Tier 58 and 59, but I think it’s nearly impossible to fully empathize or even comprehend level 21 and similarly 89, unless of course you’ve been there before. Even if you have, it becomes a distant memory that’s difficult to fully internalize. Remember, the Hedonic treadmill is almost always at play. </p><figure><img src="https://blog.stephsmith.io/content/images/2019/06/image-3.png"></figure><p>Why is this important? Everyone wishes to elevate their life and in association, their happiness. For us to reach these top tiers, we cannot hope for this to <em>just happen</em>. We must expose ourselves to various inputs that may lead to better outputs, and train ourselves to recognize what’s working. </p><p>And that’s exactly the point of continuous improvement. Since I believe that we can only ever see “two levels out”, we can’t discover these new inputs without slow, but repeatable change. We must explore 58 and then 59 and then all of a sudden, 61 will appear as this new array of opportunity we had never considered before. </p><p>As a more tangible example, when I started working in an office, I simply couldn’t fully visualize remote work. I knew it existed, but I couldn’t truly imagine this new way of living. And even once I started working remotely, it took years of iteration and pivoting to expand into the lifestyle that I now call my own. And of course, there’s probably many more tiers to explore that I simply haven’t visualized yet. </p><blockquote><em>“To exist is to change, to change is to mature, to mature is to go on creating oneself endlessly.” - Henri Bergson</em></blockquote><p>That’s precisely why it’s good to continuously surround yourself with new environments and people, and to focus on slow, but steady compounding. I think this tweet from Michael Nielson captures what I’m trying to communicate. </p><figure><blockquote><p lang="en" dir="ltr">Since reading this 6 months ago, I've come to think it's half a dozen of the best paragraphs I've ever read on how to get much, much better at anything: (by @autotrnslucence ) <a href="https://t.co/dMoEwHtjfU">pic.twitter.com/dMoEwHtjfU</a></p>— michael_nielsen (@michael_nielsen) <a href="https://twitter.com/michael_nielsen/status/1074150124169773056?ref_src=twsrc%5Etfw">December 16, 2018</a></blockquote>

</figure><p>Try to remind yourself as you’re iterating, that there are new levels that you can’t even conceptualize right now. Regardless of how far along you are, know that these new levels of success will appear as you work towards the next one or two. And soon enough, you’ll be 10 levels ahead of what you could have ever imagined. </p>


<h2 id="stop-speculating">Stop Speculating</h2><blockquote><em>“I have seen impractical and improbable things accomplished. All it took to achieve improbable things was an optimistic attitude and a refusal to give up.” - <a href="https://amzn.to/2XwrlzI">The Woman Who Smashed Codes</a></em></blockquote><p>James Clear, from <a href="https://amzn.to/31t6vQZ">Atomic Habits</a>, mentions a study in which students in Jerrey Uelsmann’s University of Florida photography class were divided into two groups. The first group would be the “quantity” group, while the second would be the “quality” group. The former would be judged solely on the number of photographs they submitted, while the latter would be graded on the excellence of a single image.</p><p>The interesting outcome of the experiment was that the best photos were produced not by the quality group, but by the quantity group. Why? While the quality group spent their time speculating what perfection may have been, the quantity group took action in testing what was truly great. </p><blockquote><em>“It is easy to get bogged down trying to find the optimal plan for change: the fastest way to lose weight, the best program to build muscle, the perfect idea for a side hustle. We are so focused on figuring out the best approach that we never get around to taking action” - James Clear, <a href="https://amzn.to/31t6vQZ">Atomic Habits</a></em></blockquote><p>In other words, the “search” for greatness is often misguided, perhaps because what we imagine to be great, is in fact not that great at all. Instead of speculating what may make you great, get out there and start <strong>doing</strong>. Do not look for perfection or even greatness, but instead signs of “good” and start making tangible progress. </p><figure><blockquote><div lang="en" dir="ltr"><p>Building products, writing, and painting are not mental excercises, they are physical ones.</p><p>Reading to improve is like watching someone else workout – it does almost nothing for you. </p><p>To run better, run. <br>To paint better, paint. <br>To write better, write.<br>To build better, build.</p></div>— Sahil Lavingia (@shl) <a href="https://twitter.com/shl/status/1118224158020685824?ref_src=twsrc%5Etfw">April 16, 2019</a></blockquote>

</figure><h2 id="how-do-you-become-great">How Do You Become Great?</h2><p>So if you’re still asking the question, “How do I become great in life?”, I would ask you to reframe the question as “How do I become good in life” or even “How do I become decent” and focus on developing those habits to repeat over time. Transform these habits to be your baseline. </p><p>Remember, there is no “magic moment” when you become great, so if you are looking for your path towards greatness, stop looking for “greatness” and consider that your most probable path there is just to focus on what’s good. </p><p>If you have an understanding of what inputs equal favourable outputs then continue moving in that direction. As you move past the local minima and maxima, you’ll soon be beating out the 50% that quit at X time, the 75% that quit at Y time, and the 90% that quit at Z time. Soon enough, you’ll be the great one that was once just “good” among the rest, but stuck with it and learned something along the way.</p><blockquote>In being consistent over time, you <strong>become</strong> the outlier. </blockquote><p>Remember: <strong>great is just good, but repeatable. </strong></p><hr><div><p>This article was originally inspired by me trying to more deeply understand what “made people great’, but ended up being a dive into some of the psychology I’ve been experiencing more recently. Over the last few months, I think I’ve been on one of my local minimums in terms of direct “success”, but in writing this I feel motivated to keep pushing to my next local maximum, with the understanding that there will be many more of both moving forward. </p><p>If you’re interested in learning more about habit building and long-term progression, I would recommend the following <a href="https://stephsmith.io/books">books</a>:</p></div><ol><li><a href="https://amzn.to/2Xd1MUa">Power of Habit</a></li><li><a href="https://amzn.to/31t6vQZ">Atomic Habits</a></li><li><a href="https://amzn.to/2RCsAYV">Outliers</a></li><li><a href="https://amzn.to/2KiSWOv">Algorithms to Live By</a></li></ol><hr><p>PS: If you liked this article, I have a feeling you'll enjoy this <a href="http://listenandlearn.co/">podcast</a> episode about other narratives that we believe, that may no longer be serving us.</p><hr><p>Related posts about <strong><a href="https://blog.stephsmith.io/tag/personal-growth/">Personal Development</a></strong>:</p><ul><li><a href="https://blog.stephsmith.io/you-dont-need-to-quit-your-job-to-make/">You Don't Need to Quit Your Job to Make</a></li></ul><hr>

</div>
<section>
<h3>Subscribe to Steph | Smith</h3>
<p>Get the latest posts delivered right to your inbox</p>

</section>

</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[VW is putting buttons back in cars (331 pts)]]></title>
            <link>https://www.thedrive.com/news/vw-is-putting-buttons-back-in-cars-because-people-complained-enough</link>
            <guid>38686967</guid>
            <pubDate>Mon, 18 Dec 2023 19:24:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thedrive.com/news/vw-is-putting-buttons-back-in-cars-because-people-complained-enough">https://www.thedrive.com/news/vw-is-putting-buttons-back-in-cars-because-people-complained-enough</a>, See on <a href="https://news.ycombinator.com/item?id=38686967">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-id="page-content" data-og-area="article-blocks" id="incArticle"><p>Whether you've driven a new <a href="https://www.thedrive.com/category/volkswagen-news" target="_blank" rel="noreferrer noopener">Volkswagen</a> or not, there's a good chance you've heard about its interiors. People who care about the German everyman brand have been extremely opinionated about the cars' lack of physical buttons. Customers' cries have even reached VW CEO Thomas Schäfer's ears, as <a href="https://www.thedrive.com/news/vw-ceo-admits-frustrating-golf-id-4-interiors-did-a-lot-of-damage" target="_blank" rel="noreferrer noopener">he said</a> the "frustrating" <a href="https://www.thedrive.com/news/vw-already-talking-about-dumping-touchscreen-controls-in-future-evs" target="_blank" rel="noreferrer noopener">touchscreen controls</a> "definitely did a lot of damage." Now, VW interior designer Darius Watola&nbsp;is reported as saying that the brand is going back to buttons on all new cars.</p><p>The news comes from <em>Autocar</em>, which quotes Watola as saying the ID.2All concept and its buttons "showed a new approach for all models." Like Schäfer, he referenced the public's feedback. There are still touchscreens, to be sure—the infotainment display is large and in charge, and there's also a digital gauge cluster. But instead of all the controls being hidden behind menus in these displays, they're toggled via switches on the center stack.</p><figure data-og-block-area="article-blocks" data-og-block-nth="1" data-og-block-type="core/image"><span data-rawhtml="1">The ID.2All Concept still looks pretty sparse inside, but at least it has physical controls for the HVAC and all four windows. The production ID.4 can't even say that. <em>VW</em></span></figure><p>This is reassuring for the simple fact that actual buttons just work. The <a href="https://www.thedrive.com/news/vw-brings-back-steering-wheel-buttons-after-many-customers-complain" target="_blank" rel="noreferrer noopener">touch sliders and whatnot</a> in the Mk8 Golf and ID.4 are finicky, only operating like they should some of the time. They also aren't backlit, making them difficult to find and use in the dark. Owners and professional critics alike have been tough on modern VWs for these exact reasons; <a href="https://www.thedrive.com/new-cars/43809/2021-volkswagen-id-4-review-a-practical-ev-ruined-by-frustrating-tech" target="_blank" rel="noreferrer noopener">my co-worker Jerry Perez went as far as saying</a> the ID.4's tech "ruined" what was an otherwise practical and livable EV.</p><p>Speaking on the car's infotainment, <a href="https://www.thedrive.com/new-cars/43809/2021-volkswagen-id-4-review-a-practical-ev-ruined-by-frustrating-tech" target="_blank" rel="noreferrer noopener">Jerry said</a>:</p><p>"It's awful, likely the worst I've ever come across. I was never able to find a channel list for the XM satellite radio because there isn't an option to do such a thing—at least not one you can find in under 30 minutes of poking around. Then there's a climate system on/off icon on the screen that you must click to turn the AC or heater on. You can't just push the fan speed icon and expect it to turn on. No, you must tap the "on" button and then adjust the temperature or fan speed separately. This extra step makes no sense—and to add insult to injury, I couldn't turn the heater on countless times because the climate portion of the OS was unresponsive. Other times, it would simply say that the function couldn't be performed at the time. Why? No idea."</p><p>As you can tell based on that blurb, actual buttons will be welcomed back with open arms.</p><p><em>Got a tip or question for the author? Contact them directly: caleb@thedrive.com</em></p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ruby 3.3's YJIT: Faster While Using Less Memory (184 pts)]]></title>
            <link>https://railsatscale.com/2023-12-04-ruby-3-3-s-yjit-faster-while-using-less-memory/</link>
            <guid>38686273</guid>
            <pubDate>Mon, 18 Dec 2023 18:31:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://railsatscale.com/2023-12-04-ruby-3-3-s-yjit-faster-while-using-less-memory/">https://railsatscale.com/2023-12-04-ruby-3-3-s-yjit-faster-while-using-less-memory/</a>, See on <a href="https://news.ycombinator.com/item?id=38686273">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This year, the YJIT team has been working hard to improve and optimize YJIT. We’re proud
to say that the version of YJIT to be included with Ruby 3.3 is leaps and bounds ahead
of Ruby 3.2’s. It provides better performance across the board, while also warming up faster
and using less memory. The 3.3 release is also more robust, including a number of
bug fixes along with an improved test suite. In this blog post, we share some early
numbers.</p>

<h2 id="yjit-33s-optimizations">YJIT 3.3’s Optimizations</h2>

<p>YJIT 3.3 includes several optimizations not present in 3.2. One of the main
differences, performance-wise, is that we have much better JIT coverage. That
is, there are much fewer situations where YJIT needs to fall back to the
interpreter. In particular, YJIT is now able to better handle calls with
splats as well as optional parameters, it’s able to compile exception
handlers, and it can handle megamorphic call sites and instance variable
accesses without falling back to the interpreter.</p>

<p>We’ve also implemented specialized inlined primitives for certain core
method calls such as <code>Integer#!=</code>, <code>String#!=</code>, <code>Kernel#block_given?</code>,
<code>Kernel#is_a?</code>, <code>Kernel#instance_of?</code>, <code>Module#===</code>, and more. It also inlines
trivial Ruby methods that only return a constant value such as <code>#blank?</code> and
<a href="https://github.com/rails/rails/pull/49909">specialized <code>#present?</code></a> from Rails.
These can now be used without needing to perform expensive method calls in
most cases.
Lastly, YJIT has a new register allocator which results in slightly
more efficient machine code.</p>

<p>In terms of reducing YJIT’s memory usage, this may be surprising to
some, but the bulk of the memory used by YJIT is not taken by generated
machine code, but rather by metadata YJIT uses to keep track of various
pieces of information associated with said generated code. As such, we’ve
spent a good amount of effort making multiple incremental improvements
to cut down the size of the metadata that we keep.</p>

<p>Another key piece in terms of memory usage has been the introduction of
a “cold threshold” heuristic. With this new heuristic, YJIT tries to cut
down on the amount of “cold”, rarely used method that get compiled. This
doesn’t make any difference on benchmarks, but it’s important for real-world
production scenarios, because there is often a long tail of rarely used
methods that get compiled, which keeps gradually increasing the size of
the generated machine code, sometimes even multiple days after code has
been deployed to production. With this heuristic, we’ve been able to cut
down the size of the generated machine code and its associated metadata
by about 20%. The key takeaway is, we’ve reduced memory usage not just by
using less memory per piece of compiled code, but also by compiling less
code in the first place.</p>

<p>Finally, this may or may not count as an optimization, but we’ve also
made some changes to try and ship YJIT with better defaults out of the
box. Following the 3.2 release, we’ve received feedback from multiple
production deployments that it was necessary to adjust the YJIT
configuration to change the memory size and call threshold values to
get better performance. With YJIT 3.3, we’ve set default values that
should work better for most production deployments. YJIT should now
automatically increase the call threshold for any deployments that
load more than a trivial amount of code, which should result in
a smoother warm-up.</p>

<h2 id="new-features-in-yjit-33">New Features in YJIT 3.3</h2>

<p>YJIT 3.3 doesn’t just include performance improvements. We’ve also added some
new features to make your life easier. One such feature is that it’s now possible
to enable YJIT at run-time from Ruby code by calling <code>RubyVM::YJIT.enable</code>. This
makes it possible to selectively enable YJIT on some forked processes without
enabling it on all processes. It also makes it
possible to only enable YJIT after your app is done booting, so that you can
completely avoid compiling initialization code. The next Rails release will
take advantage of this to
<a href="https://github.com/rails/rails/pull/49947">automatically enable YJIT</a> in an initializer.</p>

<p>We’ve also improved the way we collect run-time stats.
Prior to this, in order to collect performance statistics, you needed to
rebuild Ruby from source to produce a special stats build. Most end users found
this inconvenient, particularly in a production environment. Most of the stats
provided by <code>--yjit-stats</code> are now available in release builds. This will make
troubleshooting performance issues easier.
Please note here that we are talking about statistics for you to consult about
your programs. For security and privacy reasons, YJIT does not “phone home”.</p>

<p>Another recent addition is a new <code>--yjit-perf</code> command-line option which
enables profiling with Linux perf by setting up frame pointers for YJIT
frames and producing a perf map.
More details about new additions to YJIT and Ruby 3.3 are provided in
the <a href="https://www.ruby-lang.org/en/news/2023/12/11/ruby-3-3-0-rc1-released/">release notes</a> for Ruby 3.3.0-rc1.</p>

<h2 id="performance-on-benchmarks">Performance on benchmarks</h2>

<p>We’ve benchmarked YJIT using the headline benchmarks from the <a href="https://github.com/Shopify/yjit-bench">yjit-bench</a> suite.
These are benchmarks based on real-world gems which aim to be representative of real-world use cases,
with a bias towards things that we believe represent typical web workloads.
The graph below shows a comparison of the performance of the Ruby 3.2 interpreter, Ruby 3.3 interpreter,
Ruby 3.2 + YJIT, and Ruby 3.3 + YJIT. The benchmarks were run on a Ryzen 7 3700X machine running Ubuntu Linux 22.04.
Higher is better, with bars being normalized to 1.0 for the performance
of the Ruby 3.2 interpreter. For these experiments, we used a bleeding edge commit directly from the Ruby/master
branch of the <a href="https://github.com/ruby/ruby">git repository</a>.</p>

<p><img src="https://railsatscale.com/2023-12-04-ruby-3-3-s-yjit-faster-while-using-less-memory/images/bars_speedup.png" alt="" width="95%"></p>

<p>As you can see, YJIT 3.3 delivers a performance boost over YJIT 3.2 on every benchmark,
and the difference is usually quite significant.
Notably, rendering liquid templates is now over 2.5x faster with YJIT enabled than it is using only the
Ruby 3.2 interpreter. Railsbench is about 65% faster with YJIT. We’ve turned the
<a href="https://railsatscale.com/2023-08-25-we-turned-lobsters-into-a-rails-benchmark-for-yjit/">lobste.rs</a> website
into a benchmark, which we can render over 50% faster with YJIT as well, and if you’re using the Ruby LSP
language server in your code editor, YJIT also provides a 50%+ performance boost there too.</p>

<h2 id="memory-usage-on-benchmarks">Memory usage on benchmarks</h2>

<p>JIT compilers typically come with a tradeoff, which is that to some extent, they’re trading slightly
increased memory usage for better performance. As outlined previously, we’ve done a lot to reduce
the amount of memory overhead YJIT incurs. The overhead is still nonzero, but it has been
much improved, to the extent that it’s no longer an issue for our production deployments
at Shopify.</p>

<p><img src="https://railsatscale.com/2023-12-04-ruby-3-3-s-yjit-faster-while-using-less-memory/images/bars_memory.png" alt="" width="95%"></p>

<p>The graph above shows the memory usage on each of our benchmarks running with and without YJIT enabled for
both Ruby 3.2.2 and 3.3.0. The great news is that the memory usage for YJIT 3.3 is below that
of YJIT 3.2 on almost every benchmark. Part of this reduction in memory usage is due to the work the YJIT team put in to
use memory more effectively. YJIT executes a higher percentage of total YARV instructions than before,
it generates more machine code per Ruby method compiled, and manages to do this with less total overhead.</p>

<p>However, much of the credit for the reduced total memory usage goes to my colleagues
Peter Zhu and Matthew Valentine-House. They’ve done some great work on the Ruby Garbage Collector (GC)
to <a href="https://railsatscale.com/2023-08-08-two-garbage-collection-improvements-made-our-storefronts-8-faster/">improve its performance</a>
and reduce CRuby’s memory usage. You can see this in the above graphs too. It’s not just YJIT’s memory usage
that went down. The memory usage of the CRuby 3.3.0 interpreter is below that of the 3.2.2
interpreter for most benchmarks.</p>

<p>In the spirit of transparency, we note that in the graph above, there is an anomaly, which is that YJIT’s
memory overhead on the <code>hexapdf</code> benchmark is much higher than on other benchmarks. This is something
we’ve discovered as we were producing graphs for this blog post, and are currently investigating. As far
as we can tell so far, it seems to be an issue caused by glibc’s malloc not releasing memory to the
operating system often enough in the presence of <code>mmap</code> calls. Manually calling <code>malloc_trim(3)</code> or
using <code>jemalloc</code> seems to fix the issue.</p>

<h2 id="sfr-production-deployment">SFR Production Deployment</h2>

<p>YJIT has been deployed to all of Shopify’s StoreFront Renderer (SFR) infrastructure for all of 2023.
For context, SFR renders all Shopify storefronts, which is the first thing buyers see when they navigate
to a store hosted by Shopify. It is mostly written in Ruby, depends on over 220 Ruby gems, renders millions of
Shopify stores in over 175 countries, and is served by multiple clusters distributed worldwide.
We’ve deployed Ruby 3.2.2 and 3.3.0 (Ruby master) to experimental clusters (a subset of SFR servers) so
we could gather experimental data for this blog post.</p>

<h3 id="performance-yjit-33-vs-the-cruby-33-interpreter">Performance: YJIT 3.3 vs the CRuby 3.3 Interpreter</h3>

<p>The following graph is a snapshot from our dashboard comparing the performance of the Ruby 3.3.0 interpreter vs YJIT 3.3.0
over the last 12 hours. The speedup figures that we see tend to change over time depending on web traffic, but we believe
it’s representative of the kinds of speedups you can hope to get from YJIT 3.3.
The Y-axis shows the speedup YJIT provides compared to the interpreter. This is computed based on the
total end-to-end time needed to generate a response, including time the SFR servers spend doing I/O, waiting on
databases, and other operations YJIT cannot optimize.
As we can see, the amount of speed boost that YJIT provides over the interpreter changes depending on time of
day and web traffic, but YJIT is consistently faster than the interpreter on average, even on the p99 slowest
requests. This is great, because speeding up the slowest requests makes the most difference to user experience.</p>

<p><img src="https://railsatscale.com/2023-12-04-ruby-3-3-s-yjit-faster-while-using-less-memory/images/sfr_interp_33_vs_yjit.png" alt="" width="95%"></p>

<p>YJIT 3.3 is generally quite a bit faster than YJIT 3.2 on average. The difference is especially marked on the p99
slowest requests. This is likely because of targeted optimizations made to reduce the time YJIT takes to generate
code, as well as the addition of a “cold threshold” heuristic to reduce the
long tail of code that YJIT compiles. That is, YJIT 3.3 is more selective about which Ruby code it optimizes.</p>

<h3 id="memory-usage-yjit-33-vs-the-cruby-33-interpreter">Memory usage: YJIT 3.3 vs the CRuby 3.3 Interpreter</h3>

<p><img src="https://railsatscale.com/2023-12-04-ruby-3-3-s-yjit-faster-while-using-less-memory/images/sfr_mem_yjit33_interp.png" alt="" width="75%"></p>

<p>The graph above shows the RSS (Resident Set Size) and PSS (Proportional Set Size) of processes running YJIT
3.3 vs the CRuby 3.3 interpreter over the last 12 hours. When looking at the PSS, which takes into consideration
memory shared between multiple server processes with Unicorn, the memory overhead of enabling YJIT is
currently below 8% for our SFR deployment, which we deem to be a good memory vs performance tradeoff.</p>

<h2 id="optcarrot-and-ruby3x3">Optcarrot and Ruby3x3</h2>

<p>At RubyConf 2015, Yukihiro Matsumoto (aka Matz), chief designer of the Ruby programming language,
<a href="https://www.youtube.com/watch?v=LE0g2TUsJ4U&amp;t=3248s">announced Ruby3x3</a>, the goal of making Ruby 3
three times faster than Ruby 2. He compared this objective to John F. Kennedy’s goal of landing
humans on the moon within the decade. Despite the lack of concrete plans to achieve this, Matz
stated that a JIT compiler may be useful in achieving his inspiring objective.</p>

<p>The <a href="https://github.com/mame/optcarrot">optcarrot benchmark</a> is not one that we look at often at Shopify, because
we don’t consider it to be representative of web workloads, or the workloads that the majority of Ruby users
typically run. This benchmark is a NES emulator. It implements its own interpreter loop, and contains multiple
large methods that perform a lot of bitwise arithmetic, which is something that is almost nonexistent in web
software. However, NES emulators will always be cool, and as self-respecting programmers, we have a moral
duty to ensure that Ruby can make them run fast, akin to the hippocratic oath sworn by doctors.</p>

<p>In December of 2020, Takashi Kokubun’s MJIT achieved <a href="https://k0kubun.medium.com/ruby-3-0-jit-and-beyond-4d9404ce33c">a significant milestone</a> by showing that it could run <code>optcarrot</code>
more than 3 times faster than Ruby 2.0, thereby achieving the Ruby3x3 goal (as long as you accept
performance on <code>optcarrot</code> to be a representative metric of Ruby’s performance).
Today, with the imminent release of YJIT 3.3, we can proudly say that Ruby 3.3 is over 3.3 times
faster than the CRuby 3.3 interpreter on this benchmark, thereby hitting a new major milestone, which
we have coined post-hoc as Ruby3.3x3.3.</p>

<p><img src="https://railsatscale.com/2023-12-04-ruby-3-3-s-yjit-faster-while-using-less-memory/images/bars_optcarrot.png" alt="" width="95%"></p>

<p>As can be seen in the graph above, performance on <code>optcarrot</code> has gone up markedly with every new
YJIT release. According to stats produced by <code>--yjit-stats</code>, YJIT now executes more
than 99.1% of the instructions in this benchmark, and is also able to inline 79.9% of C function calls,
most of which are calls to Ruby runtime functions which YJIT is able to optimize. We hope to be able
to deliver even better performance for Ruby NES emulators next year.</p>

<h2 id="conclusion">Conclusion</h2>

<p>The Ruby 3.3.0 release will be available for you to download <a href="https://www.ruby-lang.org/en/">on ruby-lang.org</a>
on December 25th. In the mean time, if you’re feeling really impatient to play with Ruby 3.3, you can find the latest
release candidate along with its release notes on the <a href="https://www.ruby-lang.org/en/downloads/releases/">Ruby releases page</a>.
With this release comes a much more capable version of YJIT, with multiple major improvements. The bottom line is that YJIT
performs better, while using memory more efficiently and warming up faster.</p>

<p>If you’re interested in learning more about YJIT, we’ve published a paper at the MPLR 2023 conference, which is now freely available
through <a href="https://dl.acm.org/doi/10.1145/3617651.3622982">ACM open access</a>. A video recording of our presentation at MPLR is also
<a href="https://www.youtube.com/watch?v=fMGuQXNqlaE&amp;t=9900s">available on YouTube</a>.
There are also multiple presentations about YJIT available on YouTube, ranging from
<a href="https://www.youtube.com/watch?v=X0JRhh8w_4I">very approachable</a> to <a href="https://www.youtube.com/watch?v=EMchdR9C8XM">deeply technical</a>.</p>

<p>Lastly, I’d like to give a big thanks to Shopify, Ruby &amp; Rails Infrastructure and the YJIT team for making this project possible.
Thank you Aaron Patterson for helping me put together this blog post.
A special shout out goes to Alan Wu and Takashi Kokubun. Two incredibly talented programmers that I have the privilege to work
with on the YJIT project. They’ve worked tirelessly to make the Ruby 3.3 release as performant and stable as possible.
If you’re using YJIT in production, please give us a shout out on Twitter/X. It’s always very rewarding for us to hear about
YJIT being deployed in the wild!</p>

  </div>
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Many options for running Mistral models in your terminal using LLM (144 pts)]]></title>
            <link>https://simonwillison.net/2023/Dec/18/mistral/</link>
            <guid>38686221</guid>
            <pubDate>Mon, 18 Dec 2023 18:27:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonwillison.net/2023/Dec/18/mistral/">https://simonwillison.net/2023/Dec/18/mistral/</a>, See on <a href="https://news.ycombinator.com/item?id=38686221">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>



<p>18th December 2023</p>

<p><a href="https://mistral.ai/">Mistral AI</a> is the most exciting AI research lab at the moment. They’ve now released two extremely powerful smaller Large Language Models under an Apache 2 license, and have a third much larger one that’s available via their API.</p>
<p>I’ve been trying out their models using my <a href="https://llm.datasette.io/">LLM command-line tool tool</a>. Here’s what I’ve figured out so far.</p>

<ul>
  <li><a href="https://simonwillison.net/2023/Dec/18/mistral/#mixtral-llama-cpp">Mixtral 8x7B via llama.cpp and llm-llama-cpp</a></li>
  <li><a href="https://simonwillison.net/2023/Dec/18/mistral/#mistral-7b-local">Mistral 7B via llm-llama-cpp or llm-gpt4all or llm-mlc</a></li>
  <li><a href="https://simonwillison.net/2023/Dec/18/mistral/#mistral-api">Using the Mistral API, which includes the new Mistral-medium</a></li>
  <li><a href="https://simonwillison.net/2023/Dec/18/mistral/#mistral-other-apis">Mistral via other API providers</a></li>
  <li><a href="https://simonwillison.net/2023/Dec/18/mistral/#llamafile-openai">Using Llamafile’s OpenAI API endpoint</a></li>
</ul>

<h4 id="mixtral-llama-cpp">Mixtral 8x7B via llama.cpp and llm-llama-cpp</h4>
<p>On Friday 8th December Mistral AI <a href="https://twitter.com/MistralAI/status/1733150512395038967">tweeted a mysterious magnet</a> (BitTorrent) link. This is the second time they’ve done this, the first was on September 26th when <a href="https://twitter.com/MistralAI/status/1706877320844509405">they released</a> their excellent Mistral 7B model, also as a magnet link.</p>
<p>The new release was an 87GB file containing Mixtral 8x7B—“a high-quality sparse mixture of experts model (SMoE) with open weights”, according to <a href="https://mistral.ai/news/mixtral-of-experts/">the article</a> they released three days later.</p>
<p>Mixtral is a <em>very</em> impressive model. GPT-4 has long been rumored to use a mixture of experts architecture, and Mixtral is the first truly convincing openly licensed implementation of this architecture I’ve seen. It’s already showing impressive benchmark scores.</p>
<p>This <a href="https://github.com/ggerganov/llama.cpp/pull/4406">PR for llama.cpp</a> added support for the new model. <a href="https://github.com/abetlen/llama-cpp-python">llama-cpp-python</a> updated to land that patch shortly afterwards.</p>
<p>Which means... you can now run Mixtral on a Mac (and other platforms too, though I haven’t tested them myself yet) using my <a href="https://github.com/simonw/llm-llama-cpp">llm-llama-cpp plugin</a>.</p>
<p>Here’s how to do that:</p>
<ol>
<li>
<a href="https://llm.datasette.io/en/stable/setup.html">Install LLM</a>:

</li>
<li>Install the plugin:
<div><pre>llm install llm-llama-cpp</pre></div>
</li>
<li>Install <code>llama-cpp-python</code>—this needs to be done manually because the best approach differs for different platforms. On an Apple Silicon Mac I recommend running:
<div><pre>CMAKE_ARGS=<span><span>"</span>-DLLAMA_METAL=on<span>"</span></span> FORCE_CMAKE=1 llm install llama-cpp-python</pre></div>
More details <a href="https://github.com/simonw/llm-llama-cpp">in the llm-llama-cpp README</a>
</li>
<li>Download a GGUF file for Mixtral 8X7B Instruct v0.1. TheBloke has <a href="https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF/tree/main">8 different options</a> for this—I picked the 36GB <code>mixtral-8x7b-instruct-v0.1.Q6_K.gguf</code>:
<div><pre>curl -LO <span><span>'</span>https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF/resolve/main/mixtral-8x7b-instruct-v0.1.Q6_K.gguf?download=true<span>'</span></span></pre></div>
</li>
<li>Run the model like this:
<div><pre>llm -m gguf \
  -o path mixtral-8x7b-instruct-v0.1.Q6_K.gguf \
  <span><span>'</span>[INST] Write a Python function that downloads a file from a URL[/INST]<span>'</span></span></pre></div>
</li>
</ol>
<p>The <code>-m gguf</code> here says to use the <code>gguf</code> model that was installed by the <code>llm-llama-cpp</code> plugin—this is a model which requires you to pass a <code>path</code> option—with <code>-o path filename</code>—specifying which model you would like to run.</p>
<p>The <code>[INST]</code> part there is the format of prompt expected by the Instruct model. I need to update the <code>llm-llama-cpp</code> plugin to make it easier to automatically construct the correct prompt format, see <a href="https://github.com/simonw/llm-llama-cpp/issues/28">this issue</a>.</p>
<p>Here’s what I got for that prompt:</p>
<blockquote>
<p>Sure, here’s an example Python function that downloads a file from a URL using the <code>requests</code> library:</p>
<pre><span>import</span> <span>requests</span>

<span>def</span> <span>download_file</span>(<span>url</span>, <span>save_path</span>):
    <span>"""</span>
<span>    Download a file from a URL and save it to a local path.</span>
<span>
<span>    :param url: The URL of the file to download.</span>
<span>    :param save_path: The local path to save the file.</span>
<span>    """</span>
    <span>response</span> <span>=</span> <span>requests</span>.<span>get</span>(<span>url</span>, <span>stream</span><span>=</span><span>True</span>)
    <span>if</span> <span>response</span>.<span>status_code</span> <span>==</span> <span>200</span>:
        <span>with</span> <span>open</span>(<span>save_path</span>, <span>'wb'</span>) <span>as</span> <span>f</span>:
            <span>for</span> <span>chunk</span> <span>in</span> <span>response</span>.<span>iter_content</span>(<span>1024</span>):
                <span>f</span>.<span>write</span>(<span>chunk</span>)
        <span>print</span>(<span>f"File downloaded successfully at <span><span>{</span><span>save_path</span><span>}</span></span>"</span>)
    <span>else</span>:
        <span>print</span>(<span>f"Failed to download file from <span><span>{</span><span>url</span><span>}</span></span>. Status code: <span><span>{</span><span>response</span>.<span>status_code</span><span>}</span></span>"</span>)</span></pre>
<p>To use this function, simply call it with the URL of the file you want to download and the local path where you want to save it. For example:</p>
<pre><span>download_file</span>(<span>'https://example.com/myfile.txt'</span>, <span>'/path/to/save/myfile.txt'</span>)</pre>
<p>Note that this function uses the <code>stream=True</code> parameter in the <code>requests.get()</code> method to download the file in chunks, which can help prevent memory issues when downloading large files. It also checks the HTTP status code of the response before saving the file, so you can handle any errors that might occur during the download.</p>
</blockquote>
<p>That’s a very solid reply!</p>
<h4 id="mistral-7b-local">Mistral 7B via llm-llama-cpp or llm-gpt4all or llm-mlc</h4>
<p>The smaller Mistral 7B model dropped back in September. It’s since established itself as the most capable model family of that size—a size which is very convenient for running on personal devices.</p>
<p>I’m even running Mistral 7B on my iPhone now, thanks to an update to the <a href="https://apps.apple.com/us/app/mlc-chat/id6448482937">MLC Chat iOS app</a> from a few days ago.</p>
<p>There are a bunch of different options for running this model and its variants locally using LLM on a Mac—and probably other platforms too, though I’ve not tested these options myself on Linux or Windows:</p>
<ul>
<li>Using <a href="https://github.com/simonw/llm-llama-cpp">llm-llama-cpp</a>: download one of <a href="https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF">these Mistral-7B-Instruct GGUF files</a> for the chat-tuned version, or <a href="https://huggingface.co/TheBloke/Mistral-7B-v0.1-GGUF/tree/main">one of these</a> for base Mistral, then follow the steps listed above</li>
<li>Using <a href="https://github.com/simonw/llm-gpt4all">llm-gpt4all</a>. This is the easiest plugin to install:

The model will be downloaded the first time you try to use it:
<div><pre>llm -m mistral-7b-instruct-v0 <span><span>'</span>Introduce yourself<span>'</span></span></pre></div>
</li>
<li>Using <a href="https://github.com/simonw/llm-mlc">llm-mlc</a>. Follow the instructions in the README to install it, then:
<div><pre><span><span>#</span> Download the model:</span>
llm mlc download-model https://huggingface.co/mlc-ai/mlc-chat-Mistral-7B-Instruct-v0.2-q3f16_1
<span><span>#</span> Run it like this:</span>
llm -m mlc-chat-Mistral-7B-Instruct-v0.2-q3f16_1 <span><span>'</span>Introduce yourself<span>'</span></span></pre></div>
</li>
</ul>
<p>Each of these options work, but I’ve not spent time yet comparing them in terms of output quality or performance.</p>
<h4 id="mistral-api">Using the Mistral API, which includes the new Mistral-medium</h4>
<p>Mistral also recently announced <a href="https://mistral.ai/news/la-plateforme/">La plateforme</a>, their early access API for calling hosted versions of their models.</p>
<p>Their new API renames Mistral 7B model “Mistral-tiny”, the new Mixtral model “Mistral-small”... and offers something called <strong>Mistral-medium</strong> as well:</p>
<blockquote>
<p>Our highest-quality endpoint currently serves a prototype model, that is currently among the top serviced models available based on standard benchmarks. It masters English/French/Italian/German/Spanish and code and obtains a score of 8.6 on MT-Bench.</p>
</blockquote>
<p>I got access to their API and used it to build a new plugin, <a href="https://github.com/simonw/llm-mistral">llm-mistral</a>. Here’s how to use that:</p>
<ol>
<li>Install it:

</li>
<li>Set your Mistral API key:
<div><pre>llm keys <span>set</span> mistral
<span><span>#</span> &lt;paste key here&gt;</span></pre></div>
</li>
<li>Run the models like this:
<div><pre>llm -m mistral-tiny <span><span>'</span>Say hi<span>'</span></span>
<span><span>#</span> Or mistral-small or mistral-medium</span>
cat mycode.py <span>|</span> llm -m mistral-medium -s <span><span>'</span>Explain this code<span>'</span></span></pre></div>
</li>
</ol>
<p>Here’s their comparison table pitching Mistral Small and Medium against GPT-3.5:</p>
<p><img src="https://static.simonwillison.net/static/2023/mistral-table.jpg" alt="MMLU (MCQ in 57 subjects): GPT - 3.5 scored 70%, Mistral Small scored 70.6%, Mistral Medium scored 75.3%. HellaSwag (10-shot): GPT - 3.5 scored 85.5%, Mistral Small scored 86.7%, Mistral Medium scored 88%. ARC Challenge (25-shot): GPT - 3.5 scored 85.2%, Mistral Small scored 85.8%, Mistral Medium scored 89.9%. WinoGrande (5-shot): GPT - 3.5 scored 81.6%, Mistral Small scored 81.2%, Mistral Medium scored 88%. MBPP (pass@1): GPT - 3.5 scored 52.2%, Mistral Small scored 60.7%, Mistral Medium scored 62.3%. GSM-8K (5-shot): GPT - 3.5 scored 57.1%, Mistral Small scored 58.4%, Mistral Medium scored 66.7%. MT Bench (for Instruct models): GPT - 3.5 scored 8.32, Mistral Small scored 8.30, Mistral Medium scored 8.61."></p>
<p>These may well be cherry-picked, but note that Small beats GPT-3.5 on almost every metric, and Medium beats it on everything by a wider margin.</p>
<p>Here’s the <a href="https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard">MT Bench leaderboard</a> which includes scores for GPT-4 and Claude 2.1:</p>
<p><img src="https://static.simonwillison.net/static/2023/mt-bench.jpg" alt="GPT-4-Turbo: Arena Elo rating 1217, MT-bench score 9.32. GPT-4-0613: Arena Elo rating 1152, MT-bench score 9.18. GPT-4-0314: Arena Elo rating 1201, MT-bench score 8.96. GPT-3.5-turbo-0613: Arena Elo rating 1112, MT-bench score 8.39. GPT-3.5-Turbo-1106: Arena Elo rating 1074, MT-bench score 8.32. Claude-2.1: Arena Elo rating 1118, MT-bench score 8.18."></p>
<p>That 8.61 score for Medium puts it half way between GPT-3.5 and GPT-4.</p>
<p>Benchmark scores are no replacement for spending time with a model to get a feel for how well it behaves across a wide spectrum of tasks, but these scores are extremely promising. GPT-4 may not hold the best model crown for much longer.</p>
<h4 id="mistral-other-apis">Mistral via other API providers</h4>
<p>Since both Mistral 7B and Mixtral 8x7B are available under an Apache 2 license, there’s been something of a race to the bottom in terms of pricing from other LLM hosting providers.</p>
<p>This trend makes me a little nervous, since it actively disincentivizes future open model releases from Mistral and from other providers who are hoping to offer their own hosted versions.</p>
<p>LLM has plugins for a bunch of these providers already. The three that I’ve tried so far are Replicate, Anyscale Endpoints and OpenRouter.</p>
<p>For <a href="https://replicate.com/">Replicate</a>:</p>
<div><pre>llm install llm-replicate
llm keys <span>set</span> replicate
<span><span>#</span> &lt;paste API key here&gt;</span>
llm replicate add mistralai/mistral-7b-v0.1</pre></div>
<p>Then run prompts like this:</p>
<div><pre>llm -m replicate-mistralai-mistral-7b-v0.1 <span><span>'</span>3 reasons to get a pet weasel:<span>'</span></span></pre></div>
<p>This example is the non-instruct tuned model, so the prompt needs to be shaped such that the model can complete it.</p>
<p>For <a href="https://www.anyscale.com/endpoints">Anyscale Endpoints</a>:</p>
<div><pre>llm install llm-anyscale-endpoints
llm keys <span>set</span> anyscale-endpoints
<span><span>#</span> &lt;paste API key here&gt;</span></pre></div>
<p>Now you can run both the 7B and the Mixtral 8x7B models:</p>
<div><pre>llm -m mistralai/Mixtral-8x7B-Instruct-v0.1 \
  <span><span>'</span>3 reasons to get a pet weasel<span>'</span></span>
llm -m mistralai/Mistral-7B-Instruct-v0.1 \
  <span><span>'</span>3 reasons to get a pet weasel<span>'</span></span></pre></div>
<p>And for <a href="https://openrouter.ai/">OpenRouter</a>:</p>
<div><pre>llm install llm-openrouter
llm keys <span>set</span> openrouter
<span><span>#</span> &lt;paste API key here&gt;</span></pre></div>
<p>Then run the models like so:</p>
<div><pre>llm -m openrouter/mistralai/mistral-7b-instruct \
  <span><span>'</span>2 reasons to get a pet dragon<span>'</span></span>
llm -m openrouter/mistralai/mixtral-8x7b-instruct \
  <span><span>'</span>2 reasons to get a pet dragon<span>'</span></span></pre></div>
<p>OpenRouter are currently offering Mistral and Mixtral via their API for $0.00/1M input tokens—it’s free! Obviously not sustainable, so don’t rely on that continuing, but that does make them a great platform for running some initial experiments with these models.</p>
<h4 id="llamafile-openai">Using Llamafile’s OpenAI API endpoint</h4>
<p>I <a href="https://simonwillison.net/2023/Nov/29/llamafile/">wrote about Llamafile</a> recently, a fascinating option fur running LLMs where the LLM can be bundled up in an executable that includes everything needed to run it, on multiple platforms.</p>
<p>Justine Tunney released <a href="https://huggingface.co/jartine/Mixtral-8x7B-v0.1.llamafile/tree/main">llamafiles for Mixtral</a> a few days ago.</p>
<p>The <a href="https://huggingface.co/jartine/Mixtral-8x7B-v0.1.llamafile/blob/main/mixtral-8x7b-instruct-v0.1.Q5_K_M-server.llamafile">mixtral-8x7b-instruct-v0.1.Q5_K_M-server.llamafile</a> one runs an OpenAI-compatible API endpoints which LLM can talk to.</p>
<p>Here’s how to use that:</p>
<ol>
<li>Download the llamafile:
<div><pre>curl -LO https://huggingface.co/jartine/Mixtral-8x7B-v0.1.llamafile/resolve/main/mixtral-8x7b-instruct-v0.1.Q5_K_M-server.llamafile</pre></div>
</li>
<li>Start that running:
<div><pre>./mixtral-8x7b-instruct-v0.1.Q5_K_M-server.llamafile</pre></div>
You may need to <code>chmod 755 mixtral-8x7b-instruct-v0.1.Q5_K_M-server.llamafile</code> it first, but I found I didn’t need to.</li>
<li>Configure LLM to know about that endpoint, by adding the following to a file at <code>~/Library/Application Support/io.datasette.llm/extra-openai-models.yaml</code>:
<div><pre>- <span>model_id</span>: <span>llamafile</span>
  <span>model_name</span>: <span>llamafile</span>
  <span>api_base</span>: <span><span>"</span>http://127.0.0.1:8080/v1<span>"</span></span></pre></div>
This registers a model called <code>llamafile</code> which you can now call like this:
<div><pre>llm -m llamafile <span><span>'</span>Say hello to the world<span>'</span></span></pre></div>
</li>
</ol>
<p>Setting up that <code>llamafile</code> alias means you’ll be able to use the same CLI invocation for any llamafile models you run on that default 8080 port.</p>
<p>The same exact approach should work for other model hosting options that provide an endpoint that imitates the OpenAI API.</p>
<h4>This is LLM plugins working as intended</h4>
<p>When I <a href="https://simonwillison.net/2023/Jul/12/llm/">added plugin support to LLM</a> this was exactly what I had in mind: I want it to be as easy as possible to add support for new models, both local and remotely hosted.</p>
<p>The <a href="https://llm.datasette.io/en/stable/plugins/directory.html">LLM plugin directory</a> lists 19 plugins in total now.</p>
<p>If you want to build your own plugin—for a locally hosted model or for one exposed via a remote API—the <a href="https://llm.datasette.io/en/stable/plugins/tutorial-model-plugin.html">plugin author tutorial</a> (plus reviewing code from the existing plugins) should hopefully provide everything you need.</p>
<p>You’re also welcome to join us in the <a href="https://datasette.io/discord-llm">#llm Discord channel</a> to talk about your plans for your project.</p>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nikola founder to be sentenced for federal fraud charges (199 pts)]]></title>
            <link>https://www.cnbc.com/2023/12/18/nikola-founder-trevor-milton-sentencing-fraud-charges.html</link>
            <guid>38685607</guid>
            <pubDate>Mon, 18 Dec 2023 17:38:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2023/12/18/nikola-founder-trevor-milton-sentencing-fraud-charges.html">https://www.cnbc.com/2023/12/18/nikola-founder-trevor-milton-sentencing-fraud-charges.html</a>, See on <a href="https://news.ycombinator.com/item?id=38685607">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-6" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-6-2"><div id="Placeholder-ArticleBody-Video-107349039" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000326226" aria-labelledby="Placeholder-ArticleBody-Video-107349039"><p><img src="https://image.cnbcfm.com/api/v1/image/107349040-17029257661702925764-32505946363-1080pnbcnews.jpg?v=1702925766&amp;w=750&amp;h=422&amp;vtcrop=y" alt="Nikola founder Trevor Milton sentenced to four years for fraud"><span></span><span></span></p></div><div><p><span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-1"><a href="https://www.cnbc.com/quotes/NKLA/">Nikola</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> founder <a href="https://www.cnbc.com/2023/10/24/nikola-nkla-trevor-milton-damages.html">Trevor Milton</a> was sentenced Monday to four years in <a href="https://www.cnbc.com/2022/09/13/nikola-founder-trevor-milton-stands-trial-on-fraud-charges.html">prison</a> in connection to defrauding investors of the embattled electric- and hydrogen-powered <a href="https://www.cnbc.com/2022/10/14/nikola-nkla-founder-trevor-milton-found-guilty-of-fraud-.html">truck</a> maker.</p><p>Milton also was fined $1 million and could later be forced to forfeit property<strong> </strong>as part of his sentence.</p><p>The punishment was far lower than the 11 years prosecutors had requested at Milton's sentencing in <a href="https://storage.courtlistener.com/recap/gov.uscourts.nysd.564175/gov.uscourts.nysd.564175.318.0.pdf" target="_blank">U.S. District Court</a> in Manhattan.</p><p>But it was substantially more than the non-jail sentence of probation sought by Milton's attorneys.</p><p>"I did not intend to harm anyone and I did not commit those crimes levied against me," Milton told Judge Edgar Ramos before being sentenced, Reuters reported.</p><p>Milton has shown little to no remorse for his actions, prosecutors said. In a letter to Ramos on Sunday, prosecutors wrote that the judge should take into account Milton's "profound denial of accountability and insistence on blaming others."</p></div><div id="ArticleBody-InlineImage-107349098" data-test="InlineImage"><p>Trevor Milton, founder of Nikola Corp., exits court in New York, US, on Monday, Dec. 18, 2023.</p><p>Yuki Iwamura | Bloomberg | Getty Images</p></div><div><p>Milton was convicted in October 2022 on two counts of wire fraud and one count of securities fraud. He had faced a recommended sentence of 60 years in prison under federal sentencing guidelines for those crimes.</p><p>Restitution will be determined at a future proceeding, according to the U.S. Attorney's Office for the Southern District of New York</p><p>"Trevor Milton lied to investors again and again — on social media, on television, on podcasts, and in print. But today's sentence should be a warning to start-up founders and corporate executives everywhere — 'fake it till you make it' is not an excuse for fraud, and if you mislead your investors, you will pay a stiff price," Damian Williams, U.S. attorney for the Southern District of New York, <a href="https://www.justice.gov/usao-sdny/pr/trevor-milton-sentenced-four-years-prison-securities-fraud-scheme" target="_blank">said in a statement</a>.</p><p>Milton became <a href="https://www.cnbc.com/2021/07/29/us-prosecutors-charge-trevor-milton-founder-of-electric-carmaker-nikola-with-three-counts-of-fraud.html">an overnight billionaire</a> when he took Nikola public through a deal with a special purpose acquisition company in June 2020. The company was quickly considered to be one of the most promising EV startups – valued at its peak at more than $30 billion – until allegations regarding <a href="https://www.cnbc.com/2020/09/14/nikola-details-false-and-misleading-information-of-short-sellers-fraud-claims.html">false and misleading statements</a> were uncovered by short-seller Hindenburg Research.</p><p>Prosecutors compared Milton to disgraced Theranos founder Elizabeth Holmes, who was <a href="https://www.cnbc.com/2022/11/18/former-theranos-ceo-elizabeth-holmes-sentenced-to-more-than-11-years-in-prison.html">sentenced to more than 11 years</a> in prison last year for defrauding investors in her blood-testing startup.</p><p>"Just as Holmes lied about Theranos-manufactured blood analyzers, Milton lied about the operability of the Nikola One semitruck," <a href="https://www.justice.gov/usao-sdny/pr/notice-victims-sentencing-former-nikola-motors-ceo-trevor-milton" target="_blank">prosecutors wrote</a> to Ramos ahead of the sentencing.</p></div><div id="ArticleBody-InlineImage-106803569" data-test="InlineImage"><p>CEO and founder of U.S. Nikola, Trevor Milton speaks during presentation of its new full-electric and hydrogen fuel-cell battery trucks in partnership with CNH Industrial, at an event in Turin, Italy December 2, 2019.</p><p>Massimo Pinca | Reuters</p></div><div><p>Milton has attempted to distinguish himself from Holmes, whose company was private. His lawyers argued "that Nikola is still a real business, while Theranos is not," according to court documents.</p><p>Milton, who was the company's largest shareholder, stepped down as executive chairman of Nikola in September 2020. He did so amid an internal probe after the Hindenburg report, which characterized the company as a house of cards built by Milton.</p><p>Since Milton's resignation, shares of Nikola have crated and the company has failed to retain executives. Nikola Chairman Stephen&nbsp;Girsky, whose SPAC brought the company public, <a href="https://www.prnewswire.com/news-releases/nikola-announces-leadership-transition-appoints-stephen-girsky-as-chief-executive-officer-301893358.html" target="_blank">was named CEO</a> in August.</p><p>Shares of Nikola have recently traded under $1, with a market value of about $327 million. The stock was down by roughly 6% following Milton's sentencing.</p><p>Nikola was among the first heavily publicized companies to go public through a SPAC. It inspired hundreds of other startups to do the same before the Securities and Exchange Commission <a href="https://www.cnbc.com/2021/08/02/nikola-founder-criminal-charges-puts-other-spacs-on-notice.html">cracked down on the practice.</a></p><p>Prosecutors said the SPAC process, rather than a traditional IPO, allowed Milton to make many of the misleading or fraudulent statements. Under the IPO process, he would have not been allowed to make public statements during the time around the company going public.</p><p>SPACs are publicly traded companies that don't have any real assets other than cash. They are formed as investment vehicles with the sole purpose of raising funds and then finding and merging with a privately held company.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Flipboard Begins to Federate (183 pts)]]></title>
            <link>https://flipboard.medium.com/flipboard-begins-to-federate-c56ec788feaa</link>
            <guid>38685598</guid>
            <pubDate>Mon, 18 Dec 2023 17:37:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://flipboard.medium.com/flipboard-begins-to-federate-c56ec788feaa">https://flipboard.medium.com/flipboard-begins-to-federate-c56ec788feaa</a>, See on <a href="https://news.ycombinator.com/item?id=38685598">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a rel="noopener follow" href="https://flipboard.medium.com/?source=post_page-----c56ec788feaa--------------------------------"><div aria-hidden="false"><p><img alt="Flipboard" src="https://miro.medium.com/v2/resize:fill:88:88/1*2z3on8qtkGbX_Jfl745gIQ.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div><figure></figure><p id="28ff"><em>*This post was originally published by </em><a href="https://medium.com/u/4067cf8d4460?source=post_page-----c56ec788feaa--------------------------------" rel="noopener" target="_blank"><em>Mike McCue</em></a><em>.</em></p><p id="5ae5">Today we are beginning to open Flipboard to the <a href="https://about.flipboard.com/press/flipboard-furthers-its-mission-in-the-fediverse/" rel="noopener ugc nofollow" target="_blank">Fediverse</a>, a rapidly emerging part of the Web which includes social services like Mastodon, Threads, Pixelfed, Firefish and PeerTube all built on a revolutionary open protocol called <a href="https://www.theverge.com/2023/4/20/23689570/activitypub-protocol-standard-social-network" rel="noopener ugc nofollow" target="_blank">ActivityPub</a>.</p><p id="2e3a">What does this mean for you? In the next few months, everyone using Flipboard will be able to discover and follow a whole new group of writers, vloggers, artists, scientists, explorers, political leaders and millions of others who are posting content and conversing in the Fediverse. If you curate on Flipboard, not only will you have a lot more content to curate from, there will be millions more people to enjoy the Magazines and Storyboards you are curating. If you’re a publisher, creator or brand on Flipboard, you’ll start to see new visitors and engagement as people discover and share your content across the growing Fediverse.</p><p id="3493">If you’re already using the Fediverse, you’ll be able to discover more articles, videos and podcasts thoughtfully curated by Flipboard’s many publishers and curators around the world. You’ll also be able to follow and converse with them directly from Mastodon, Threads and other ActivityPub apps.</p><p id="b5de">What do you need to do to take advantage of all this? Nothing. Everyone using Flipboard will soon start seeing more content from more interesting people in the same familiar Flipboard experience. And everyone in the Fediverse will start seeing curated content from Flipboard in whatever app or experience they are already using today.</p><p id="2831"><strong>Federation in Three Phases</strong></p><p id="b4d1">When and how is this going to happen? The process of opening Flipboard to the Fediverse is called “federation” and it will happen in three distinct phases between now and April:</p><ul><li id="8ba0">Phase 1 (Today): We are federating 25 publishers and creators so that we can test and gather feedback</li><li id="35dd">Phase 2 (January): We will enable anyone in the Fediverse to follow and engage with any public curator on Flipboard</li><li id="b3fb">Phase 3 (April): We will enable anyone on Flipboard to follow and engage with any public account in the Fediverse</li></ul><p id="3918"><strong>The First 25 to Federate</strong></p><p id="93fa">In this first phase we are partnering with 25 publishers and creators to help them federate their Flipboard accounts and gather feedback from people across the Fediverse. This includes a range of publishers covering global news, tech, music, gaming, travel and science as well as a few content creators like <a href="https://flipboard.com/@ErinBrockovich" rel="noopener ugc nofollow" target="_blank">Erin Brockovich</a> and <a href="https://flipboard.com/@Photowalks" rel="noopener ugc nofollow" target="_blank">Jefferson Graham</a>. We are also federating several non-profits dedicated to advancing non-partisan journalism and combating misinformation. These include <a href="https://flipboard.com/@NewsLitProject" rel="noopener ugc nofollow" target="_blank">The News Literacy Project</a>, <a href="https://flipboard.com/@The74" rel="noopener ugc nofollow" target="_blank">The 74</a> and <a href="https://flipboard.com/@ConversationUS" rel="noopener ugc nofollow" target="_blank">The Conversation</a>. Finally, we are federating <a href="https://flipboard.com/@Medium" rel="noopener ugc nofollow" target="_blank">Medium’s</a> account on Flipboard where they regularly feature great stories from their best writers.</p><p id="ac6a">Here’s the full list:</p><figure><figcaption>The first Flipboard profiles to join the Fediverse.</figcaption></figure><p id="b19f"><strong>Our Approach</strong></p><p id="44b3">As we federate Flipboard we will be guided by the first principles that formed the Fediverse as well as feedback from the many communities there today. Choice, privacy, openness and transparency will be critical to ensure we successfully federate the Flipboard community with the Fediverse. We recognize that we are helping to set a precedent for how other services will federate in the future so we will proceed thoughtfully and collaboratively.</p><p id="c06b">We are taking a number of important steps along these lines:</p><ul><li id="f25e">We have established <a href="http://flipboard.com/" rel="noopener ugc nofollow" target="_blank">flipboard.com</a> as a new instance in the Fediverse where you will find all federated Flipboard accounts. We will also continue to operate our <a href="http://flipboard.social/" rel="noopener ugc nofollow" target="_blank">flipboard.social</a> instance as a way for anyone to create a new Mastodon account and use the native Mastodon UI on a fast, safe and reliable server.</li><li id="6d76">We have signed on to the Mastodon server covenant for both Flipboard instances. This commits us to a standard of moderation, reliabilty and portability that is shared across other high quality instances in the Fediverse.</li><li id="fc44">We are extending our global moderation capabilities to our presence in the Fediverse. We will also continue to innovate and expand upon our “an ounce of prevention is worth a pound of cure” approach to moderation. We acknowledge in advance that we won’t be perfect in dealing with every moderation issue but we commit to working expeditiously to resolve these as they arise.</li><li id="068a">Our recommendation algorithms on Flipboard will honor Mastodon privacy settings and will continue to only surface content from domains that we have vetted in advance. We will continue to block content from domains that we have identified as toxic. We will also continue to grow our “Red/Green” domain list and we will share this with other instance owners in the Fediverse as soon as is practically possible.</li><li id="e5fa">We will collaborate with other instance owners to ensure we are efficiently relaying activity from Flipboard without overwhelming smaller instances. We will also help innovate ways for larger instances to shoulder the burden of expensive tasks like image storage and video streaming.</li><li id="27d3">We think it’s important to respect the spirit of what the follower count and “joined date” means to users on Mastodon today. While the accounts we are federating have tens of thousands or even millions of followers on Flipboard, we think this could be confusing to people in the Fediverse. Accordingly, follower counts will start at zero in the Fediverse and increment as each account accrues new ActivityPub followers. We are also setting the “Joined” date to the day each account is federated instead of when they joined Flipboard. We’ll continue to gather feedback on this as we gear up for phase 2.</li><li id="a51a">In January we will release a new version of Flipboard that will show follows, favorites and boosts from the Fediverse. It will also enable replies to and from the Fediverse as well as blocking, muting and reporting. We will encourage people to use these moderation tools liberally for the health of the overall Fediverse. We believe in the power of decentralized moderation and will continue to innovate new ways to utilize signals from the community to help stop bad actors and prevent toxic content from spreading.</li></ul><p id="1411"><strong>The Future is Federated</strong></p><p id="d5a4">This is the single largest expansion of the Flipboard ecosystem since we launched as a social magazine in 2010. I’m incredibly excited about how federation will benefit everyone on Flipboard and in the Fediverse. More importantly, I hope we can serve as inspiration for other apps and services contemplating the Fediverse. As more services federate the value of the Fediverse will increase exponentially and we will usher in a more vibrant and interoperable era for the people who make great content and everyone who enjoys it.</p><p id="17e5"><em>Note: If you’re interested in learning more about the Fediverse, ActivityPub and the future of the open social Web, check out </em><a href="https://about.flipboard.com/inside-flipboard/dot-social-mike-mccue-hosts-podcast-about-the-future-of-social-media/" rel="noopener ugc nofollow" target="_blank"><em>Dot Social</em></a><em>, my new podcast which features in-depth interviews with many of the pioneers and leaders of this exciting new movement.</em></p><p id="117d">By Mike McCue, Flipboard CEO</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New PFAS discovered with novel testing method (176 pts)]]></title>
            <link>https://research.unc.edu/2023/12/12/carolina-chemists-discover-eight-new-pfas-with-novel-testing-method/</link>
            <guid>38685458</guid>
            <pubDate>Mon, 18 Dec 2023 17:27:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://research.unc.edu/2023/12/12/carolina-chemists-discover-eight-new-pfas-with-novel-testing-method/">https://research.unc.edu/2023/12/12/carolina-chemists-discover-eight-new-pfas-with-novel-testing-method/</a>, See on <a href="https://news.ycombinator.com/item?id=38685458">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p><em>The “forever chemicals” found in the Cape Fear River were detected through a non-targeted testing method developed at UNC-Chapel Hill that broadens researchers’ abilities to identify the hazardous compounds.</em></p>
<figure id="attachment_127077"><a href="https://research.unc.edu/wp-content/uploads/sites/61/2023/12/cape-fear-toned2-1000.jpg" data-slb-active="1" data-slb-asset="1869683395" data-slb-internal="0" data-slb-group="127075"><img fetchpriority="high" decoding="async" src="https://research.unc.edu/wp-content/uploads/sites/61/2023/12/cape-fear-toned2-1000-300x200.jpg" alt="An overhead shot of a river with trees on each side." width="300" height="200" srcset="https://research.unc.edu/wp-content/uploads/sites/61/2023/12/cape-fear-toned2-1000-300x200.jpg 300w, https://research.unc.edu/wp-content/uploads/sites/61/2023/12/cape-fear-toned2-1000-768x512.jpg 768w, https://research.unc.edu/wp-content/uploads/sites/61/2023/12/cape-fear-toned2-1000.jpg 1000w" sizes="(max-width: 300px) 100vw, 300px"></a><figcaption>The Cape Fear River starts in central North Carolina and flows southeast, emptying into the Atlantic Ocean in Cape Fear.</figcaption></figure>
<p>The Environmental Protection Agency (EPA) <a href="https://www.epa.gov/comptox-tools/comptox-chemicals-dashboard">keeps a list</a> of more than 14,000 known or potential per-and polyfluoroalkyl substances (PFAS). Called “forever chemicals” for how long the molecules take to break down, <a href="https://www.epa.gov/pfas/pfas-explained">PFAS can be found</a> just about everywhere, and have been <a href="https://www.atsdr.cdc.gov/pfas/health-effects/index.html">linked to health issues</a> like cancer and infertility.</p>
<p>PFAS are potentially hazardous to people and animals, so detecting them is vital. That’s why <a href="https://chem.unc.edu/faculty/baker-erin/">Erin Baker</a>, associate professor of chemistry within the UNC College of Arts and Sciences, and her lab are expanding testing methods to find them — efforts that were recently published in <a href="https://www.science.org/doi/full/10.1126/sciadv.adj7048"><em>Science Advances</em></a>.</p>
<p>Researchers collaborating with Baker’s lab collected samples from North Carolina’s Cape Fear River in 2016. Using this new detection method, they tested the samples and found 47 different PFAS. Of those, 11 had not been previously detected in the river, and eight had not been detected anywhere outside of a lab.</p>
<p>“Eight of them weren’t on the EPA’s list of PFAS, which makes us think there are many more PFAS than we previously thought,” Baker says.</p>
<p><strong>Expanding the search</strong></p>
<p>For years, PFAS contaminants like GenX have been found in drinking water originating from the Cape Fear River, making it an ideal testing site for Baker and her team. Some of <a href="https://capefearriverwatch.org/genx/">this pollution has been directly linked</a> to production at the Chemours Fayetteville Works site, where chemicals are manufactured. Surrounding residents rely on testing conducted by scientists to understand what types of compounds they are being exposed to.</p>
<p>“Current testing methods used by the EPA can only find the PFAS that we already know exist,” Baker says. “That means we have to rely on chemical companies to provide a list of what they manufacture and hope those samples are comprehensive.”</p>
<figure id="attachment_127078"><a href="https://research.unc.edu/wp-content/uploads/sites/61/2023/12/Figure3-1000.jpg" data-slb-active="1" data-slb-asset="1703905077" data-slb-internal="0" data-slb-group="127075"><img decoding="async" src="https://research.unc.edu/wp-content/uploads/sites/61/2023/12/Figure3-1000-296x300.jpg" alt="The structures of 11 different molecules." width="296" height="300" srcset="https://research.unc.edu/wp-content/uploads/sites/61/2023/12/Figure3-1000-296x300.jpg 296w, https://research.unc.edu/wp-content/uploads/sites/61/2023/12/Figure3-1000-768x780.jpg 768w, https://research.unc.edu/wp-content/uploads/sites/61/2023/12/Figure3-1000-64x64.jpg 64w, https://research.unc.edu/wp-content/uploads/sites/61/2023/12/Figure3-1000.jpg 1000w" sizes="(max-width: 296px) 100vw, 296px"></a><figcaption>Researchers mapped out the structures of the 11 new molecules they found in the Cape Fear River. The underlined compounds represent the eight PFAS that were unknown to the EPA.</figcaption></figure>
<p>PFAS are commonly detected using liquid chromatography-mass spectrometry, a method that looks at the mass, charge, and polarity of ions — positively or negatively charged molecules. The EPA uses targeted mass spectrometry, which requires matching PFAS found in people or the environment with “standards” — PFAS chemicals created in a lab for testing purposes. It’s like combing through a word search puzzle and only being able to search for a specific set of words. Baker’s lab has developed a non-targeted approach, which allows them to search for any word in a puzzle.</p>
<p>“There are so many known PFAS that standards don’t exist for many of them,” says Kaylie Kirkwood-Donelson, who led the study when she was an NC State University PhD student in Baker’s lab. “Having a non-targeted approach lets us have an open-ended search for known and unknown compounds.”</p>
<p>The non-targeted approach uses <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6832852/">ion mobility spectrometry</a> (IMS) to look at how ions move. To do this, ions are placed in gas and an electric field is added. The electric field causes the ions to move differently based on their individual charges. An ion’s size and shape affect the speed at which it moves through the gas, with larger ions moving slower than smaller ones. Information on an ion’s size and shape provides more insight into the structure of the molecule. And in this case, can help researchers determine if a molecule could be considered PFAS.</p>
<p><strong>Sharing the results</strong></p>
<p>As researchers investigate PFAS in the Cape Fear River, the number of known chemicals present in the water continues to grow. More testing is needed to understand the quantities and how toxic they are to people and animals.</p>
<p>“It’s also very important to expand non-targeted testing for PFAS,” says Kirkwood-Donelson, who is now a chemist for the National Institute of Environmental Health Sciences. “Even in this study, there were still some molecules that we could not figure out the chemical structures for, so we believe there are more PFAS in the Cape Fear River to be discovered.”</p>
<p>Baker’s lab is working to streamline their non-targeted testing process to make it more efficient. The technology and equipment needed to conduct ion mobility spectrometry is expensive, but more PFAS-focused labs are getting the special tools needed.</p>
<p>In the meantime, Baker’s lab will keep testing samples from the Cape Fear River. They are currently comparing some collected before and after environmental regulations were <a href="https://www.deq.nc.gov/news/key-issues/genx-investigation/chemours-consent-order">enacted by the state in 2019</a>.</p>
<p>Their work is getting attention from <a href="https://www.theguardian.com/environment/2023/oct/27/chemours-forever-chemicals-pfas-north-carolina-water-pollution">news</a> and <a href="https://popsci.com/environment/news-pfas-chemours-north-carolina/">science</a> outlets, and <a href="https://www.newsobserver.com/news/business/article282184358.html">the United Nations has even weighed in</a> on the issue, issuing letters to Chemours, the U.S. government, and other involved parties stating “serious concern regarding human rights and environmental impacts.” Baker hopes this attention will inspire more investigation by scientists and regulation from government agencies.</p>
<p>“If industries create molecules that they don’t tell the public about, and we only test for the molecules they do tell us about, we could be missing things,” says Baker. “We need to use non-targeted testing to have more information on what our communities are being exposed to.”</p>
<p><em>Erin Baker is an associate professor in the Department of Chemistry within the UNC College of Arts and Sciences.</em></p>
<p><em>Kaylie Kirkwood-Donelson is a former PhD student in Erin Baker’s lab who recently graduated from NC State University. She is now a chemist for the National Institute of Environmental Health Sciences.</em></p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fly Kubernetes (251 pts)]]></title>
            <link>https://fly.io/blog/fks/</link>
            <guid>38685393</guid>
            <pubDate>Mon, 18 Dec 2023 17:21:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fly.io/blog/fks/">https://fly.io/blog/fks/</a>, See on <a href="https://news.ycombinator.com/item?id=38685393">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
         <dl>
             <dt>Author</dt>
             <dd>
                 <img alt="Senyo Simpson" src="https://fly.io/static/images/senyo.webp">
               <dl>
                 <dt>Name</dt>
                 <dd>
                   Senyo Simpson
                 </dd>
               </dl>
             </dd>
         </dl>

        <section>
            <figure>
                <img src="https://fly.io/blog/fks/assets/fks-cover.webp" alt="Frankie, or Linda (I can't tell who's who), the Fly.io hot-air balloon mascot, at the helm of a sailing ship. The ocean is rolling with waves, and two shark fins are visible in pursuit of the ship. There are some unreasonably happy-looking smaller fish leaping out of the water around the ship. Frankie or Linda looks pretty chill and content.">
                <figcaption>
                  <span>Image by</span>
                  
<svg role="img" style="pointer-events: none; width: 17px; height: 17px;" viewBox="0 0 20 20" fill="currentColor" fill-rule="evenodd">
  <g buffered-rendering="static">
    <path fill-rule="evenodd" d="M1 8a2 2 0 012-2h.93a2 2 0 001.664-.89l.812-1.22A2 2 0 018.07 3h3.86a2 2 0 011.664.89l.812 1.22A2 2 0 0016.07 6H17a2 2 0 012 2v7a2 2 0 01-2 2H3a2 2 0 01-2-2V8zm13.5 3a4.5 4.5 0 11-9 0 4.5 4.5 0 019 0zM10 14a3 3 0 100-6 3 3 0 000 6z" clip-rule="evenodd"></path>
  </g>
</svg>

                    <a href="https://annieruygtillustration.com/" target="_blank">
                      Annie Ruygt
                    </a>
                </figcaption>
            </figure>
          <p>We’re Fly.io, and if you’ve been following us awhile you probably just did a double-take. We’re building a new public cloud that runs containerized applications with virtual machine isolation on our own hardware around the world. And we’ve been doing it without any K8s. Until now!</p>
<p>We’ll own it: we’ve been snarky about Kubernetes. We are, at heart, old-school Unix nerds. We’re still scandalized by <code>systemd</code>.</p>

<p>To make matters more complicated, the problems we’re working on <a href="https://fly.io/blog/carving-the-scheduler-out-of-our-orchestrator/">have a lot of overlap with K8s</a>, but <a href="https://fly.io/blog/carving-the-scheduler-out-of-our-orchestrator/#numad">just enough impedance mismatch</a> that it (<a href="https://www.nomadproject.io/">or anything that looks like it</a>) is a bad fit for our own platform.</p>

<p>But, come on: you never took us too seriously about K8s, right? K8s is hard for us to use, but that doesn’t mean it’s not a great fit for what you’re building. We’ve been clear about that all along, right? Sure we have!</p>

<p>Well, good news, everybody! If K8s is important for your project, and that’s all that’s been holding you back from <a href="https://fly.io/docs/speedrun/">trying out Fly.io</a>, we’ve spent the past several months building something for you.</p>
<h2 id="fly-io-for-kubernetians"><a href="#fly-io-for-kubernetians" aria-label="Anchor"></a>Fly.io For Kubernetians</h2>
<p>Fly.io works by transmogrifying Docker containers into filesystems for <a href="https://firecracker-microvm.github.io/">lightweight hypervisors</a>, and running them on servers we rack in dozens of regions around the world.</p>

<p>You can build something like Fly.io with “standard” orchestration tools like K8s. In fact, that’s what we did to start, too. To keep things simple, we used Nomad, and instead of K8s CNIs, we built our own Rust-based TLS-terminating Anycast proxy (and designed a WireGuard/IPv6-based private network system <a href="https://fly.io/blog/bpf-xdp-packet-filters-and-udp/">based on eBPF</a>). But the ideas are the same.</p>

<p>The way we look at it, the signature feature of a “standard” orchestrator is the global scheduler: the global eye in the sky that keeps track of vacancies on servers and optimized placement of new workloads. That’s the problem we ran into. We’re running over 200,000 applications, and we’re doing so on every continent except Antarctica. The speed of light (and a globally distributed network of backhoes) has something to say about keeping a perfectly consistent global picture of hundreds of thousands of applications, and it’s not pleasant.</p>

<p>The other problem we ran into is that our Nomad scheduler kept trying to outsmart us, and, worse, our customers. It turns out that our users have pretty firm ideas of where they’d like their apps to run. If they ask for São Paulo, they want São Paulo, not Rio. But global schedulers have other priorities, like optimally bin-packing resources, and sometimes <code>GIG</code> looks just as good as <code>GRU</code> to them.</p>

<p>To escape the scaling and DX problems we were hitting, we rethought orchestration. Where orchestrators like K8s tend to work through distributed consensus, we keep state local to workers. Each racked server in our fleet is a source of truth about the apps running on it, and provide an API to a market-style “scheduler” that bids on resources in regions. <a href="https://fly.io/blog/carving-the-scheduler-out-of-our-orchestrator/#numad">You can read more about here, if you’re interested.</a> We call this system the <a href="https://fly.io/docs/machines/">Fly Machines API.</a></p>

<p>An important detail to grok about how this all works –&nbsp;a reason we haven’t, like, beaten the CAP theorem by doing this – is that Fly Machines API calls can fail. If Nomad or K8s tries to place a workload on some server, only to find out that it’s filled up or thrown a rod, it will go hunt around for some other place to put it, like a good little robot. The Machines API won’t do this. It’ll just fail the request. In fact, it goes out of its way to fail the request quickly, to deliver feedback; if we can’t schedule work in <code>JNB</code> right now, you might want instead to quickly deploy to <code>BOM</code>.</p>
<h2 id="pluggable-orchestration-and-fks"><a href="#pluggable-orchestration-and-fks" aria-label="Anchor"></a>Pluggable Orchestration and FKS</h2>
<p>In a real sense what we’ve done here is extract a chunk of the scheduling problem out of our orchestrator, and handed it off to other components. For most of our users, that component is <a href="https://github.com/superfly/flyctl"><code>flyctl</code>, our intrepid CLI</a>.</p>

<p>But <a href="https://fly.io/docs/machines/working-with-machines/">Fly Machines is an API</a>, and anything can drive it. A lot of our users want quick answers to requests to schedule apps in specific regions, and <code>flyctl</code> does a fine job of that. But it’s totally reasonable to want something that works more like the good little robots inside of K8s.</p>

<p>You can build your own orchestrator with our API, but if what you’re looking for is literally Kubernetes, we’ve saved you the trouble. It’s called Fly Kubernetes, or FKS for short.</p>

<p>FKS is an implementation of Kubernetes that runs on top of Fly.io. You start it up using <code>flyctl</code>, by running <code>flyctl ext k8s create</code>.</p>

<p>Under the hood, FKS is a straightforward combination of two well-known Kubernetes projects: <a href="https://k3s.io/">K3s, the lightweight CNCF-certified K8s distro</a>, and <a href="https://virtual-kubelet.io/">Virtual Kubelet</a>.</p>

<p>Virtual Kubelet is interesting. In K8s-land, a <code>kubelet</code> is a host agent; it’s the thing that runs on every server in your fleet that knows how to run a K8s Pod. Virtual Kubelet isn’t a host agent; it’s a software component that pretends to be a host, registering itself with K8s as if it was one, but then sneakily proxying the Kubelet API elsewhere.</p>

<p>In FKS, “elsewhere” is <a href="https://fly.io/docs/machines/">Fly Machines</a>. All we have to do is satisfy various APIs that virtual kubelet exposes. For example, the API for the lifecycle of a pod:</p>
<div>
  <pre><code>type PodLifecycleHandler interface {
    CreatePod(ctx context.Context, pod *corev1.Pod) error
    UpdatePod(ctx context.Context, pod *corev1.Pod) error
    DeletePod(ctx context.Context, pod *corev1.Pod) error
    GetPod(ctx context.Context, namespace, name string) (*corev1.Pod, error)
    GetPodStatus(ctx context.Context, namespace, name string) (*corev1.PodStatus, error)
    GetPods(context.Context) ([]*corev1.Pod, error)
}
</code></pre>
</div>

<p>This interface is easy to map to the Fly Machines API. For example:</p>
<div>
  <pre><code>CreatePod -&gt; POST /apps/{app_name}/machines
UpdatePod -&gt; POST /apps/{app_name}/machines/{machine_id}
</code></pre>
</div>

<p>K3s, meanwhile, is a stripped-down implementation of all of K8s that fits into a single binary. K3s does a bunch of clever things to be as streamlined as it is, but the most notable of them is <a href="https://github.com/k3s-io/kine">kine, an API shim that switches <code>etcd</code> out with databases like SQLite</a>. Because of <code>kine</code>, K3s can manage multiple servers, but also gracefully runs on a single server, without distributed state.</p>

<p>So that’s what we do. When you create a cluster, we run K3s and the Virtual Kubelet on a single Fly Machine. We compile a <a href="https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/">kubeconfig</a>, with which you can talk to your K3s via <code>kubectl</code>. We set the whole thing up to run Pods on individual Fly Machines, so your cluster scales out directly using our platform, but with K8s tooling.</p>

<p>One thing we like about this design is how much of the lifting is already done for us by the underlying platform. If you’re a K8s person, take a second to think of all the different components you’re dealing with: <a href="https://etcd.io/">etcd</a>, specifically provisioned nodes, the <a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kube-proxy/">kube-proxy</a>, <a href="https://github.com/flannel-io/flannel">a CNI </a>binary and configuration and its integration with the host network, containerd, registries. But Fly.io already does most of those things. So this project was mostly chipping away components until we found the bare minumum: CoreDNS, SQLite persistence, and Virtual Kubelet.</p>

<p>We ended up with something significantly simpler than K3s, which is saying something.</p>

<p>Fly Kubernetes has some advantages over plain <code>flyctl</code> and <code>fly.toml</code>:</p>

<ul>
<li>Your deployment is more declarative than it is with the <code>fly.toml</code> file. You declare the exact state of everything down to replica counts, autoscaling rules, volume definitions, and more.
</li><li>When you deploy with Fly Kubernetes, Kubernetes will automatically make your definitions match the state of the world. Machines go down? Kubernetes will whack them back online.
</li></ul>

<p>This is a different way to do orchestration and scheduling on Fly.io. It’s not what everyone is going to want. But if you want it, you really want it, and we’re psyched to give it to you: Fly.io’s platform features, with Kubernetes handling configuration and driving your system to its desired state.</p>

<p>We’ve kept things simple to start with. There are K8s use cases we’re a strong fit for today, and others we’ll get better at in the near future, as K8s users drive the underlying platform (and particularly our proxy) forward.</p>

<p><strong>Interested in getting early access? Email us at <a href="mailto:sales@fly.io">sales@fly.io</a> and we’ll hook you up.</strong></p>
<figure>
  <figcaption>
    <h2>Not invested in K8s?</h2>
    <p>Nothing has to change for you! You can deploy apps on Fly.io today, in a matter of minutes, without talking to Sales.</p>
      <a href="https://fly.io/docs/speedrun/">
        Deploy an app in minutes.<span>→</span>
      </a>
  </figcaption>
  <p><img src="https://fly.io/static/images/cta-turtle.webp" srcset="https://fly.io/static/images/cta-turtle@2x.webp 2x" alt="">
  </p>
</figure>

<div><p>
          <iframe width="100%" height="100%" src="https://www.youtube.com/embed/A3vFfZvUiwo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
          </iframe>
        </p>
</div>

<h2 id="what-it-all-means"><a href="#what-it-all-means" aria-label="Anchor"></a>What It All Means</h2>
<p>One obvious thing it means is that you’ve got an investment in Kubernetes tooling, you can keep it while running things on top of Fly.io. So that’s pretty neat. Buy our cereal!</p>

<p>But the computer science story is interesting, too. We placed a bet on an idiosyncratic strategy for doing global orchestration. We replaced global consensus, which is how Borg, Kubernetes, and Nomad all work, with a market-based system. That system was faster and, importantly, dumber than the consensus system it replaced.</p>

<p>This had costs! Nomad’s global consensus would do truly heroic amounts of work to make sure Fly Apps got scheduled somewhere, anywhere. Like a good capitalist, Fly Machines will tell you in no uncertain terms how much work it’s willing to do for you (“less than a Nomad”).</p>

<p>But that doesn’t mean you’re stuck with the answers Fly Machines gives by itself. Because Fly Machines is so simple, and tries so hard to be predictable, we hoped you’d be able to build more sophisticated scheduling and orchestration schemes on top of it. And here you go: Kubernetes scheduling, as a plugin to the platform.</p>

<p>More to come! We’re itching to see just how many different ways this bet might pay off. Or: we’ll perish in flames! Either way, it’ll be fun to watch.</p>

          
        </section>
        <dl>
            <dt>
              Previous post  ↓
            </dt>
            <dd>
              <a href="https://fly.io/blog/fly-io-has-gpus-now/">
                Fly.io has GPUs now
              </a>
            </dd>
        </dl>
      </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Desalination can beat batteries for excess energy (101 pts)]]></title>
            <link>https://spectrum.ieee.org/pumped-water-energy-storage</link>
            <guid>38685239</guid>
            <pubDate>Mon, 18 Dec 2023 17:11:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/pumped-water-energy-storage">https://spectrum.ieee.org/pumped-water-energy-storage</a>, See on <a href="https://news.ycombinator.com/item?id=38685239">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="Desalination Can Beat Out Batteries for Excess Energy" data-elid="2666402973" data-post-url="https://spectrum.ieee.org/pumped-water-energy-storage" data-authors="Michelle Hampson" data-page-title="Desalination Can Beat Out Batteries for Excess Energy - IEEE Spectrum"><p><em>This article is part of our exclusive </em><a href="https://spectrum.ieee.org/collections/journal-watch/" target="_self"><em>IEEE Journal Watch series</em></a><em> in partnership with IEEE Xplore.</em></p><p>In many arid regions around the world, desalination of saltwater is an important means to acquire drinking water. One of the most common desalination techniques is through a process called reverse osmosis. However, the pumps used for reverse osmosis desalination require immense amounts of electricity—which raises questions on how to ensure this process is completed in an economical and energy-efficient way.</p><p>New research shows that hybrid energy grids that rely on a mix of renewable and fossil fuel energy are up to the task, so long as the timing of freshwater production is right. In some situations, it may even be more financially and energy efficient to put that generated energy toward desalination rather than store it in batteries for use later. Money can be saved by only producing freshwater when renewable energy production is high. The results are described in a <a href="https://ieeexplore.ieee.org/document/10272360" rel="noopener noreferrer" target="_blank">study</a> published 5 October in the <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8685265" rel="noopener noreferrer" target="_blank"><em>Journal of Modern Power Systems and Clean Energy</em></a>.</p><p>“If a significant percentage of the electricity demand in a power system is due to freshwater production, it is appropriate to coordinate the operations of the freshwater system and the power system as they are linked, and such coordination may result in economic savings and reduced unserved power and water demand,” explains <a href="https://ise.osu.edu/people/conejo.1" rel="noopener noreferrer" target="_blank">Antonio Conejo</a>, a professor of engineering at Ohio State University.</p><p>Conejo’s Ph.D. student, <a href="https://www.linkedin.com/in/mubarak-al-mubarak-a6b9b711b/?originalSubdomain=kw" rel="noopener noreferrer" target="_blank">Mubarak Almubarak</a>, is from Kuwait and was interested in assessing the energy-grid demands of different scenarios in the Middle East—for example, in a situation where demand for desalination is high and renewable-energy production is still low. In comparison, arid places like California or Texas may still have desalination plants, but a higher portion of their energy comes from renewable sources.</p><p>Their analysis suggests mixed renewable systems like those in California or Texas would see the greatest economic benefit in terms of coordinated desalination times, focused on times when renewable energy is peaking—for example, at noon on a sunny day, when solar power production is highest and costs are lowest.</p><p>However, this economic efficiency “mostly vanishes” under scenarios with 100 percent renewable grids, says Conejo, because the cost of producing electricity is similar throughout the day. Nevertheless, he notes that this approach, whereby the production of freshwater is appropriately timed throughout the day based on energy production, could still be useful for regions that are ramping up their use of renewable sources and are at the hybrid stage of production.</p><p>“[Because] freshwater tanks are cheaper than electrical batteries, it seems appropriate to fully exploit the ability of tanks to displace energy production/consumption, and then, if needed, to use electrical batteries for the same purpose,” Conejo says.</p><p><em>This post was updated on 5 December to clarify that the authors examined the difference between storing excess energy production in batteries for later use on the grid versus using excess production for desalination.</em><br></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Word2Vec Received 'Strong Reject' Four Times at ICLR2013 (341 pts)]]></title>
            <link>https://openreview.net/forum?id=idpCdOWtqXd60</link>
            <guid>38684925</guid>
            <pubDate>Mon, 18 Dec 2023 16:48:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openreview.net/forum?id=idpCdOWtqXd60">https://openreview.net/forum?id=idpCdOWtqXd60</a>, See on <a href="https://news.ycombinator.com/item?id=38684925">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><span>18 Dec 2023 (modified: 17 Jan 2013)</span><span>ICLR 2013 conference submission</span><span>Readers:  Everyone</span></p><div><p><strong>Decision<!-- -->:</strong> <span>conferencePoster-iclr2013-workshop</span></p><p><strong>Abstract<!-- -->:</strong> <span>We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day and one CPU to derive high quality 300-dimensional vectors for one million vocabulary from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring various types of word similarities. We intend to publish this test set to be used by the research community.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Terrapin Attack for prefix truncation in SSH (133 pts)]]></title>
            <link>https://terrapin-attack.com</link>
            <guid>38684904</guid>
            <pubDate>Mon, 18 Dec 2023 16:47:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://terrapin-attack.com">https://terrapin-attack.com</a>, See on <a href="https://news.ycombinator.com/item?id=38684904">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <p>SSH is an internet standard that provides secure access to network services,
      particularly remote terminal login and file transfer within organizational networks
      and to over 15 million servers on the open internet.</p>

    <p><i>Terrapin</i> is a prefix truncation attack targeting the SSH protocol. More precisely,
      Terrapin breaks the integrity of SSH's secure channel. By carefully adjusting
      the sequence numbers during the handshake, an attacker can remove an arbitrary amount
      of messages sent by the client or server at the beginning of the secure channel without
      the client or server noticing it.</p>

    <p>The attack can be performed in practice, allowing an attacker to downgrade the connection's
      security by truncating the extension negotiation message (RFC8308) from the transcript.
      The truncation can lead to using less secure client authentication algorithms and deactivating
      specific countermeasures against keystroke timing attacks in OpenSSH 9.5.</p>

    <p>We also showed that Terrapin can be used to enable the exploitation of implementation flaws.
      For example, we found several weaknesses in the AsyncSSH servers' state machine, allowing an
      attacker to sign a victim's client into another account without the victim noticing. Hence,
      it will enable strong phishing attacks and may grant the attacker Man-in-the-Middle (MitM)
      capabilities within the encrypted session.</p>

    <p>To perform the Terrapin attack in practice, we require MitM capabilities at the network layer
      (the attacker must be able to intercept and modify the connection's traffic). Additionally,
      the connection must be secured by either ChaCha20-Poly1305 or CBC with Encrypt-then-MAC.
      However, our scan indicates an extensive adoption of these encryption modes; therefore,
      Terrapin applies to most real-world SSH sessions.</p>

    <hr>
    <h2>Attack Overview</h2>

    <img src="https://terrapin-attack.com/media/img/terrapin-attack.png">
    <p>The image shows a practical application of the Terrapin attack. The attacker can
      drop the EXT_INFO message, used for negotiating several protocol extensions, without
      the client or server noticing it. Usually, packet deletion would be detected by
      the client when receiving the next binary packet sent by the server, as sequence numbers
      would mismatch. To avoid this, an attacker injects an ignored packet during the handshake
      to offset the sequence numbers accordingly.
    </p>

    <hr>
    <h2 id="paper">Full Technical Paper (preprint; last update: 2023-10-18)</h2>
    <p><a href="https://terrapin-attack.com/TerrapinAttack.pdf">Terrapin Attack: Breaking SSH Channel Integrity
      By Sequence Number Manipulation</a>, Fabian Bäumer, Marcus Brinkmann, Jörg Schwenk.
    </p>
    <p>The artifacts are available on
      <a href="https://github.com/RUB-NDS/Terrapin-Artifacts/">GitHub</a>.</p>

    <hr>
    <h2 id="scanner">Vulnerability Scanner</h2>

    <p>We provide a simple console application, written in Go, which can be used to determine
    whether an SSH server or client is vulnerable to the Terrapin attack. The scanner
    connects to your SSH server (or listens for an incoming client connection)
    to detect whether vulnerable encryption modes are offered and if the strict key exchange
    countermeasure is supported. It does not perform a fully-fledged handshake, nor does it
    actually perform the attack.</p>

    <p>Pre-built binaries for all major platforms and the source code are available on
      <a href="https://github.com/RUB-NDS/Terrapin-Scanner/releases/latest">GitHub</a>.</p>

    <hr>
    <h2 id="question-answer">FAQ</h2>

    <h3>I am an admin, should I drop everything and fix this?</h3>

    <p>Probably not.</p>

    <p>The attack requires an active Man-in-the-Middle attacker that can intercept and
      modify the connection's traffic at the TCP/IP layer. Additionally,
      we require the negotiation of either ChaCha20-Poly1305, or any CBC cipher
      in combination with Encrypt-then-MAC as the connection's encryption mode.
    </p>

    <p>If you feel uncomfortable waiting for your SSH implementation to provide a patch,
      you can workaround this vulnerability by temporarily disabling the affected 
      chacha20-poly1305@openssh.com encryption and -etm@openssh.com MAC algorithms in the configuration
      of your SSH server (or client), and use unaffected algorithms like AES-GCM instead.
    </p>

    <p>Fair word of warning: If configured improperly or your client does not support these algorithms,
      you may lose access to your server. Also, some (very) old versions of OpenSSH (6.2 and 6.3)
      are vulnerable to a <a href="https://www.openssh.com/txt/gcmrekey.adv">buffer overflow when using AES-GCM</a>.</p>

    <h3>What can the attackers gain?</h3>

    <p>Within the paper we describe an extension downgrade attack,
      allowing an attacker to downgrade the security of an SSH connection
      when using SSH extension negotiation. The impact in practice heavily
      depends on the supported extensions. Most commonly, this will impact
      the security of client authentication when using an RSA public key.
      When using OpenSSH 9.5, it may also be used to deactivate certain
      countermeasures to keystroke timing attacks.</p>

    <p>We also showed that the Terrapin attack can be used to enable
      certain attacks that exploit additional implementation flaws. For example,
      we used flaws in the internal state machine of AsyncSSH in combination
      with our attack to obtain a MitM position at the session layer.
    </p>

    <p>However, the potential consequences of the general Terrapin attack are
      dependent on the messages exchanged after the handshake concludes. If you
      are using a custom SSH service and do not resort to the authentication
      protocol, you should check that dropping the first few messages of a connection
      does not yield security risks.
    </p>

    <h3>Who is vulnerable?</h3>
    <p>Almost everyone. The Terrapin attack exploits weaknesses in the SSH transport
      layer protocol in combination with newer cryptographic algorithms and encryption
      modes introduced by OpenSSH over 10 years ago. Since then, these have been adopted
      by a wide range of SSH implementations, therefore affecting a majority of current
      implementations.</p>

    <p>In practice, our attack can be applied against any connection using either
      ChaCha20-Poly1305 or any CBC-mode cipher in combination with the Encrypt-then-MAC paradigm.
      Theoretically, CTR-mode ciphers in combination with the Encrypt-then-MAC paradigm are
      vulnerable as well, although this weakness cannot be exploited in a real-world scenario.</p>

    <h3>So how practical is the attack?</h3>
    <p>The Terrapin attack requires an active Man-in-the-Middle attacker, that means some way
      for an attacker to intercept and modify the data sent from the client or server
      to the remote peer. This is difficult on the Internet, but can be a plausible
      attacker model on the local network.</p>

    <p>Besides that, we also require the use of a vulnerable encryption mode. Encrypt-then-MAC
      and ChaCha20-Poly1305 have been introduced by OpenSSH over 10 years ago. Both have
      become the default for many years and as such spread across the SSH ecosystem. Our scan
      indicated that at least 77% of SSH servers on the internet supported at least one
      mode that can be exploited in practice.</p>

    <h3>Is my SSH client/server vulnerable?</h3>

    <p>Most likely, yes.</p>

    <p>In more technical terms, if your SSH implementations supports (and is configured to offer) the
      <code>chacha20-poly1305@openssh.com</code> encryption algorithm, or any encryption algorithm suffixed
      <code>-cbc</code> in combination with any MAC algorithm suffixed <code>-etm@openssh.com</code>,
      you are vulnerable to Terrapin.
    </p>

    <p>You can use our <a href="#scanner">vulnerability scanner</a> to determine whether your client or server is vulnerable.</p>

    <h3>I patched my SSH client/server, am I safe now?</h3>

    <p>It depends. The strict key exchange countermeasure implemented by OpenSSH and other vendors
      requires both, client and server, to support it, in order to take effect. Connecting a vulnerable
      client to a patched server, and vice versa, still results in a vulnerable connection.</p>
    
    <h3>Does this vulnerability have a CVE number?</h3>

    <p>
      Yes. We got assigned a total of three CVE numbers. These are:
      </p><ul>
        <li>CVE-2023-48795: General Protocol Flaw</li>
        <li>CVE-2023-46445: Rogue Extension Negotiation Attack in AsyncSSH</li>
        <li>CVE-2023-46446: Rogue Session Attack in AsyncSSH</li>
      </ul>
    

    <h3>Is this a new attack?</h3>
    <p>The Terrapin attack can be considered the first attack in a new family of attacks
      targeting cryptographic network protocols and is the first ever practically exploitable
      prefix truncation attack that we know of. The only other mentioning of a prefix truncation
      attack was by Cédric Fournet on behalf of the miTLS team on an
      <a href="https://mailarchive.ietf.org/arch/msg/tls/extoO9ETJLnEm3MRDTO23x70DFM/">IETF mailing list</a>. Fournet
      described potential weaknesses in a draft version of TLS 1.3 that used to not reset sequence
      numbers when activating new keys, although his considerations remained theoretical as "[...]
      prefix truncations will probably cause the handshake to fail". The draft was subsequently
      changed and no prefix truncation attacks in TLS 1.3 are known to this date.
    </p>

    <h3>Why is the attack called "Terrapin"?</h3>

    <p>The name "Terrapin" started as an acronym, but considering how tortured it looked,
      we opted to drop the acronym part and only retained the name. We chose this name
      because SSH and terrapins have one thing in common: Shells. And I think we can all
      agree that terrapins (and turtles in general) are cute animals.</p>

    <h3>How have vendors responded to this vulnerability?</h3>

    <p>Many vendors have updated their SSH implementation to support an optional strict
      key exchange. Strict key exchange is a backwards-incompatible change to the SSH
      handshake which introduces sequence number resets and takes away an attacker's capability
      to inject packets during the initial, unencrypted handshake. However, to take effect, both
      client and server must support this feature.</p>

    <h3>What about other protocols?</h3>

    <p>To this date, we are not aware of any practical prefix truncation in other cryptographic
      network protocols. All versions of TLS reset the message sequence number to zero when
      changing key, therefore decoupling unencrypted and encrypted sequence numbers. Additionally,
      TLS authenticates the entire handshake thus preventing an attacker from inserting
      any message. While IPSec/IKE only authenticates parts of its handshake, the sequence numbers
      are reset similar to TLS, rendering it immune to our attack.</p>

    <h3>What about other cipher modes?</h3>

    <p>AES-GCM (RFC5647) is not affected by Terrapin as it does not use the SSH sequence numbers.
      Instead, AES-GCM uses the IV obtained from key derivation as its nonce, incrementing it
      after sending a binary packet. In a healthy connection, this results in the nonce being
      at a fixed offset from the sequence number.
    </p>

    <p>The original Encrypt-and-MAC paradigma from RFC4253 protects the integrity of the plaintext,
      thus thwarting our attack, which yields one pseudorandom block during decryption.
    </p>

    <h3>Is this vulnerability severe enough to deserve a name, a logo and a web page?</h3>

    <p>Terrapin is not a simple software bug that can be fixed with an update
      to a single library or component. Instead, clients and servers need
      to be updated to protect the connection against prefix truncation
      attacks. This means we need to raise awareness of the issue across all
      SSH client and server implementations, which is a considerable effort. We expect
      that the general Terrapin attack will stay with us for many years, so we
      have a cute animal to keep us company while we help clients and servers
      to adopt the suggested countermeasures!</p>

    <h3>How can I contact you?</h3>

    <p>You can reach us via mail or twitter:</p>
    <ul>
      <li>Fabian Bäumer, Ruhr University Bochum, <a href="https://x.com/TrueSkrillor">@TrueSkrillor</a>, fabian.baeumer@rub.de</li>
      <li>Marcus Brinkmann, Ruhr University Bochum, <a href="https://x.com/lambdafu">@lambdafu</a>,
        marcus.brinkmann@rub.de</li>
      <li>Jörg Schwenk, Ruhr University Bochum, <a href="https://x.com/JoergSchwenk">@JoergSchwenk</a>,
        joerg.schwenk@rub.de</li>
    </ul>

    <h3>Responsible Disclosure Timeline</h3>
    <ul>
      <li>2023-10-17: Initial contact with OpenSSH and Ron Frederick (author of AsyncSSH)</li>
      <li>2023-11-08: AsyncSSH published a patched version fixing the implementation bugs</li>
      <li>2023-11-17: Initial contact with 17 other SSH implementation vendors (round 1)</li>
      <li>2023-11-17: Disclosed findings to the German CERT-Bund. Findings were later forwarded to partnered CERTs by CERT-Bund.</li>
      <li>2023-11-21: Initial contact with 12 other SSH implementations after initial feedback from round 1 (round 2)</li>
      <li>2023-12-11: Disclosed findings to the distros mailing list</li>
      <li>2023-12-18: Public Disclosure</li>
    </ul>
  </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Python, C, Assembly – Faster Cosine Similarity (155 pts)]]></title>
            <link>https://ashvardanian.com/posts/python-c-assembly-comparison/</link>
            <guid>38684461</guid>
            <pubDate>Mon, 18 Dec 2023 16:14:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ashvardanian.com/posts/python-c-assembly-comparison/">https://ashvardanian.com/posts/python-c-assembly-comparison/</a>, See on <a href="https://news.ycombinator.com/item?id=38684461">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a href="https://ashvardanian.com/tags/less-slow/">In this fourth article of the “Less Slow” series</a>, I’m accelerating <a href="https://github.com/unum-cloud">Unum’s open-source Vector Search primitives</a> used by some great database and cloud providers to replace Meta’s <a href="https://github.com/facebookresearch/faiss">FAISS</a> and scale-up search in their products. This time, our focus is on the most frequent operation for these tasks - computing the the Cosine Similarity/Distance between two vectors. It’s so common, even doubling it’s performance can have a noticeable impact on applications economics. But compared to a pure Python baseline our <strong>single-threaded performance grew by a factor of 2'500x</strong>. Let’s go through optimizations one by one:</p><ul><li><a href="#python">Kicking off with basic Python</a>.</li><li><a href="#numpy-between-python-and-c">Noticed a 35x slowdown when not using NumPy right</a>.</li><li><a href="#scipy">Managed a 2-5x speed boost with SciPy</a>.</li><li><a href="#c">Jumped to a 200x speedup using C</a>.</li><li><a href="#assembly">A big leap to 400x faster with SIMD intrinsics</a>.</li><li><a href="#bmi2-and-goto">Touched 747x combining AVX-512 and BMI2</a>.</li><li><a href="#fp16">Climbed to 1,260x adding AVX-512FP16</a>.</li><li><a href="#vnni">The final high: 2,521x faster with AVX-512VNNI</a>.</li></ul><p><img loading="lazy" src="https://ashvardanian.com/python-c-assembly-comparison/python-vs-c-vs-assembly.png" alt="Cover"></p><p>Some highlights:</p><ul><li>Again, <code>goto</code> doesn’t get the love it deserves in C.</li><li>BMI2 instructions on x86 are consistently overlooked… thanks to AMD Zen2, I guess.</li><li>AVX-512FP16 is probably the most important extension in the current AI race.</li></ul><blockquote><p>I’m still scratching my head on the <strong>4VNNI</strong> extensions of AVX-512, and couldn’t find a good way to benefit from them here or even in the polynomial approximations of the <a href="https://ashvardanian.com/posts/gcc-12-vs-avx512fp16/">Jensen Shannon divergence computations in the last post</a>, so please let me know where I should try them 🤗</p></blockquote><p>Cosine Similarity is a way to check if two “vectors” are looking in the same direction, regardless of their magnitude. It is a widespread metric used in Machine Learning and Information Retrieval, and it is defined as:</p><p>$$
\cos(\theta) = \frac{A \cdot B}{|A| |B|} = \frac{\sum_{i=1}^{n} A_i B_i}{\sqrt{\sum_{i=1}^{n} A_i^2} \sqrt{\sum_{i=1}^{n} B_i^2}}
$$</p><p>Where $A$ and $B$ are two vectors with $n$ dimensions. The cosine similarity is a value between $-1$ and $1$, where $1$ means that the two vectors are pointing in the same direction, $-1$ implies that they are pointing in opposite directions and $0$ means that they are orthogonal. Cosine Distance, in turn, is a distance function, which is defined as $1 - \cos(\theta)$. It is a value between $0$ and $2$, where $0$ means that the two vectors are identical, and $2$ means that they are pointing in opposite directions. <em>I may use the terms interchangeably, but they are not exactly the same.</em></p><h2 id="python">Python</h2><p>The first implementation is the most naive one, written in pure Python… by ChatGPT. It is a direct translation of the mathematical formula and is very easy to read and understand.</p><div><table><tbody><tr><td><pre tabindex="0"><code><span id="hl-0-1"><a href="#hl-0-1">1</a>
</span><span id="hl-0-2"><a href="#hl-0-2">2</a>
</span><span id="hl-0-3"><a href="#hl-0-3">3</a>
</span><span id="hl-0-4"><a href="#hl-0-4">4</a>
</span><span id="hl-0-5"><a href="#hl-0-5">5</a>
</span><span id="hl-0-6"><a href="#hl-0-6">6</a>
</span></code></pre></td><td><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>cosine_distance</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>):</span>
</span></span><span><span>    <span>dot_product</span> <span>=</span> <span>sum</span><span>(</span><span>ai</span> <span>*</span> <span>bi</span> <span>for</span> <span>ai</span><span>,</span> <span>bi</span> <span>in</span> <span>zip</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>))</span>
</span></span><span><span>    <span>magnitude_a</span> <span>=</span> <span>math</span><span>.</span><span>sqrt</span><span>(</span><span>sum</span><span>(</span><span>ai</span> <span>*</span> <span>ai</span> <span>for</span> <span>ai</span> <span>in</span> <span>a</span><span>))</span>
</span></span><span><span>    <span>magnitude_b</span> <span>=</span> <span>math</span><span>.</span><span>sqrt</span><span>(</span><span>sum</span><span>(</span><span>bi</span> <span>*</span> <span>bi</span> <span>for</span> <span>bi</span> <span>in</span> <span>b</span><span>))</span>
</span></span><span><span>    <span>cosine_similarity</span> <span>=</span> <span>dot_product</span> <span>/</span> <span>(</span><span>magnitude_a</span> <span>*</span> <span>magnitude_b</span><span>)</span>
</span></span><span><span>    <span>return</span> <span>1</span> <span>-</span> <span>cosine_similarity</span>
</span></span></code></pre></td></tr></tbody></table></div><p>I’ll run on 4th Gen Intel Xeon CPUs, codenamed Sapphire Rapids, and available on AWS as the <code>r7iz</code> instances. Before running a benchmark, let’s generate random numbers and put them into a list, simulating the 1536-dimensional “embeddings” from the OpenAI Ada service.</p><div><table><tbody><tr><td><pre tabindex="0"><code><span id="hl-1-1"><a href="#hl-1-1">1</a>
</span><span id="hl-1-2"><a href="#hl-1-2">2</a>
</span><span id="hl-1-3"><a href="#hl-1-3">3</a>
</span></code></pre></td><td><pre tabindex="0"><code data-lang="py"><span><span><span>np</span><span>.</span><span>random</span><span>.</span><span>seed</span><span>(</span><span>0</span><span>)</span>
</span></span><span><span><span>a_list</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>rand</span><span>(</span><span>1536</span><span>)</span><span>.</span><span>tolist</span><span>()</span>
</span></span><span><span><span>b_list</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>rand</span><span>(</span><span>1536</span><span>)</span><span>.</span><span>tolist</span><span>()</span>
</span></span></code></pre></td></tr></tbody></table></div><p>Running the benchmark with the <code>%timeit</code> utility, we get <strong>93.2 µs</strong> ± 1.75 µs per loop.. Or roughly 100 microseconds per call. Is that good or bad?</p><p>Our solution is Pythonic but inefficient, as it traverses each <code>list</code> twice. So let’s use the common Pythonic <code>zip</code> idiom:</p><div><table><tbody><tr><td><pre tabindex="0"><code><span id="hl-2-1"><a href="#hl-2-1"> 1</a>
</span><span id="hl-2-2"><a href="#hl-2-2"> 2</a>
</span><span id="hl-2-3"><a href="#hl-2-3"> 3</a>
</span><span id="hl-2-4"><a href="#hl-2-4"> 4</a>
</span><span id="hl-2-5"><a href="#hl-2-5"> 5</a>
</span><span id="hl-2-6"><a href="#hl-2-6"> 6</a>
</span><span id="hl-2-7"><a href="#hl-2-7"> 7</a>
</span><span id="hl-2-8"><a href="#hl-2-8"> 8</a>
</span><span id="hl-2-9"><a href="#hl-2-9"> 9</a>
</span><span id="hl-2-10"><a href="#hl-2-10">10</a>
</span></code></pre></td><td><pre tabindex="0"><code data-lang="py"><span><span><span>def</span> <span>cosine_distance</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>):</span>
</span></span><span><span>    <span>dot_product</span> <span>=</span> <span>0</span>
</span></span><span><span>    <span>magnitude_a</span> <span>=</span> <span>0</span>
</span></span><span><span>    <span>magnitude_b</span> <span>=</span> <span>0</span>
</span></span><span><span>    <span>for</span> <span>ai</span><span>,</span> <span>bi</span> <span>in</span> <span>zip</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>):</span>
</span></span><span><span>        <span>dot_product</span> <span>+=</span> <span>ai</span> <span>*</span> <span>bi</span>
</span></span><span><span>        <span>magnitude_a</span> <span>+=</span> <span>ai</span> <span>*</span> <span>ai</span>
</span></span><span><span>        <span>magnitude_b</span> <span>+=</span> <span>bi</span> <span>*</span> <span>bi</span>
</span></span><span><span>    <span>cosine_similarity</span> <span>=</span> <span>dot_product</span> <span>/</span> <span>(</span><span>magnitude_a</span> <span>*</span> <span>magnitude_b</span><span>)</span>
</span></span><span><span>    <span>return</span> <span>1</span> <span>-</span> <span>cosine_similarity</span>
</span></span></code></pre></td></tr></tbody></table></div><p>Running the benchmark, we get <strong>65.3 µs</strong> ± 716 ns per loop., resulting <strong>30% savings!</strong> I believe it’s a fair baseline.</p><blockquote><p>As <a href="https://news.ycombinator.com/item?id=38684461">pointed on HackerNews</a>, I forgot to apply the square root for <code>magnitude_a</code> and <code>magnitude_b</code>.</p></blockquote><h2 id="numpy-between-python-and-c">NumPy: Between Python and C</h2><p>NumPy is a powerful tool in Python’s toolbox, helping folks work fast with arrays. Many people see it as the go-to for doing science stuff in Python. A lot of machine learning tools lean on it. Since it’s built with C, you’d think it’d be speedy. Let’s take our basic Python lists and make them sharper with NumPy. We’re looking at single-precision, half-precision numbers, and 8-bit integers.</p><div><table><tbody><tr><td><pre tabindex="0"><code><span id="hl-3-1"><a href="#hl-3-1">1</a>
</span><span id="hl-3-2"><a href="#hl-3-2">2</a>
</span><span id="hl-3-3"><a href="#hl-3-3">3</a>
</span></code></pre></td><td><pre tabindex="0"><code data-lang="py"><span><span><span>floats</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>rand</span><span>(</span><span>1536</span><span>)</span><span>.</span><span>astype</span><span>(</span><span>np</span><span>.</span><span>float32</span><span>)</span>
</span></span><span><span><span>halfs</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>rand</span><span>(</span><span>1536</span><span>)</span><span>.</span><span>astype</span><span>(</span><span>np</span><span>.</span><span>float16</span><span>)</span>
</span></span><span><span><span>ints</span> <span>=</span> <span>(</span><span>np</span><span>.</span><span>random</span><span>.</span><span>rand</span><span>(</span><span>1536</span><span>)</span> <span>*</span> <span>100</span><span>)</span><span>.</span><span>astype</span><span>(</span><span>np</span><span>.</span><span>int8</span><span>)</span>
</span></span></code></pre></td></tr></tbody></table></div><p>These are popular choices for quantization (making data smaller) in tools like <a href="https://github.com/facebookresearch/faiss">Meta’s FAISS</a> and <a href="https://github.com/unum-cloud/usearch">Unum’s USearch</a>. Half-precision is pretty handy, working well most of the time. But using integers? That depends on the AI model you’re using. Thanks to <a href="https://www.tensorflow.org/model_optimization/guide/quantization/training">Quantization Aware Training</a>, two of my faves — <a href="https://huggingface.co/intfloat/e5-base-v2">Microsoft’s E5</a> for just text and <a href="https://github.com/unum-cloud/uform">Unum’s UForm</a> for multi-modal data — work well even compressed to 8-bit numbers.</p><hr><p>After getting our vectors set up, I used our <code>cosine_distance</code> function to see how similar the three arrays are:</p><ul><li><code>floats</code>: <strong>349 µs</strong> ± 5.71 µs per loop.</li><li><code>halfs</code>: <strong>525 µs</strong> ± 9.69 µs per loop.</li><li><code>ints</code>: <strong>2.31 ms</strong> ± 26 µs per loop.</li></ul><p>But here’s the problem. Instead of getting faster, things went <strong>35x slower</strong> than our <strong>65.3 µs</strong> starting point. Why?</p><ol><li><p><strong>Memory Management</strong>: Sure, NumPy uses C arrays, which are cool. But every time we loop through them, we turn small byte stuff into bigger Python stuff. And with memory being unpredictable, it’s surprising things didn’t go even slower.</p></li><li><p><strong>Half-Precision Support</strong>: Most new devices support half-precision. But the software side? Not so much. Only a few AI tools use it, and they often focus on GPU stuff, leaving out the CPU. So, converting half-precision things on the go can be slow.</p></li><li><p><strong>Integer Overflows</strong>: Doing math with our tiny integers isn’t smooth. We keep getting these annoying overflow warnings. The CPU spends more time checking things than actually doing the math. We often see things like: <em>“RuntimeWarning: overflow encountered in scalar multiply”</em>.</p></li></ol><p>Here’s a tip: If you’re using NumPy, go all in. Mixing it with regular Python can really slow you down!</p><h2 id="scipy">SciPy</h2><p>NumPy is also the foundation of the SciPy library, which provides many valuable functions for scientific computing, including the <code>scipy.distance.spatial.cosine</code>. It will use the native NumPy operations for as much as possible.</p><ul><li><code>floats</code>: <strong>15.8 µs</strong> ± 416 ns per loop.</li><li><code>halfs</code>: <strong>46.6 µs</strong> ± 291 ns per loop.</li><li><code>ints</code>: <strong>12.2 µs</strong> ± 37.5 ns per loop.</li></ul><p>Now, we see the true potential of NumPy, and the underlying Basic Linear Algebra Subroutines (BLAS) libraries implemented in C, Fortran, and Assembly. Our pure Python baseline was <strong>65.3 µs</strong>, and we now got 2-5 times faster, depending on the data type. Notably, <code>halfs</code> are still slow. Checking the specs of a similar CPU, we can clearly see support for <code>f16c</code> instructions, which means that the CPU can at least decode half-precision values without software emulation, and we shouldn’t be experiencing this much throttling.</p><p><a href="https://www.techpowerup.com/cpu-specs/xeon-platinum-8470q.c3091"><img loading="lazy" src="https://ashvardanian.com/python-c-assembly-comparison/sapphire-rapids-specs.png" alt="Sapphire Rapids Features"></a></p><h2 id="c">C</h2><p>C is the lowest-level hardware-agnostic programming language - hence the best way to optimize small numerical functions, like the Cosine Similarity and Distance.
It is also trivial to wrap C functions into pure CPython bindings for the default Python runtime, and if you use the FastCall convention, like we do, you can make your custom code as fast as the built-in Python functions, like what I’ve described recently with StringZilla, replacing Python’s default <code>str</code> string class with a faster alternative.
Unlike C++, however, C doesn’t support “generics” or “template functions”.
So we have to separately implement the <code>cosine_distance</code> function for each data type we want to support, or use the ugly “macros”:</p><div><table><tbody><tr><td><pre tabindex="0"><code><span id="hl-4-1"><a href="#hl-4-1"> 1</a>
</span><span id="hl-4-2"><a href="#hl-4-2"> 2</a>
</span><span id="hl-4-3"><a href="#hl-4-3"> 3</a>
</span><span id="hl-4-4"><a href="#hl-4-4"> 4</a>
</span><span id="hl-4-5"><a href="#hl-4-5"> 5</a>
</span><span id="hl-4-6"><a href="#hl-4-6"> 6</a>
</span><span id="hl-4-7"><a href="#hl-4-7"> 7</a>
</span><span id="hl-4-8"><a href="#hl-4-8"> 8</a>
</span><span id="hl-4-9"><a href="#hl-4-9"> 9</a>
</span><span id="hl-4-10"><a href="#hl-4-10">10</a>
</span><span id="hl-4-11"><a href="#hl-4-11">11</a>
</span><span id="hl-4-12"><a href="#hl-4-12">12</a>
</span><span id="hl-4-13"><a href="#hl-4-13">13</a>
</span></code></pre></td><td><pre tabindex="0"><code data-lang="c"><span><span><span>#define SIMSIMD_MAKE_COS(name, input_type, accumulator_type, converter)                                                \
</span></span></span><span><span><span>    inline static simsimd_f32_t simsimd_##name##_##input_type##_cos(                                                   \
</span></span></span><span><span><span>        simsimd_##input_type##_t const* a, simsimd_##input_type##_t const* b, simsimd_size_t n) {                      \
</span></span></span><span><span><span>        simsimd_##accumulator_type##_t ab = 0, a2 = 0, b2 = 0;                                                         \
</span></span></span><span><span><span>        for (simsimd_size_t i = 0; i != n; ++i) {                                                                      \
</span></span></span><span><span><span>            simsimd_##accumulator_type##_t ai = converter(a[i]);                                                       \
</span></span></span><span><span><span>            simsimd_##accumulator_type##_t bi = converter(b[i]);                                                       \
</span></span></span><span><span><span>            ab += ai * bi;                                                                                             \
</span></span></span><span><span><span>            a2 += ai * ai;                                                                                             \
</span></span></span><span><span><span>            b2 += bi * bi;                                                                                             \
</span></span></span><span><span><span>        }                                                                                                              \
</span></span></span><span><span><span>        return ab != 0 ? 1 - ab * SIMSIMD_RSQRT(a2) * SIMSIMD_RSQRT(b2) : 1;                                           \
</span></span></span><span><span><span>    }
</span></span></span></code></pre></td></tr></tbody></table></div><p>This is a real snippet from the library and depends on yet another macro - <code>SIMSIMD_RSQRT(x)</code>, defined as the <code>1 / sqrtf(x)</code> by default.
We later instantiate it for all the data types we need:</p><div><table><tbody><tr><td><pre tabindex="0"><code><span id="hl-5-1"><a href="#hl-5-1">1</a>
</span><span id="hl-5-2"><a href="#hl-5-2">2</a>
</span><span id="hl-5-3"><a href="#hl-5-3">3</a>
</span></code></pre></td><td><pre tabindex="0"><code data-lang="c"><span><span><span>SIMSIMD_MAKE_COS</span><span>(</span><span>serial</span><span>,</span> <span>f32</span><span>,</span> <span>f32</span><span>,</span> <span>SIMSIMD_IDENTIFY</span><span>)</span> <span>// `simsimd_serial_f32_cos`
</span></span></span><span><span><span></span><span>SIMSIMD_MAKE_COS</span><span>(</span><span>serial</span><span>,</span> <span>f16</span><span>,</span> <span>f32</span><span>,</span> <span>SIMSIMD_UNCOMPRESS_F16</span><span>)</span> <span>// `simsimd_serial_f16_cos`
</span></span></span><span><span><span></span><span>SIMSIMD_MAKE_COS</span><span>(</span><span>serial</span><span>,</span> <span>i8</span><span>,</span> <span>i32</span><span>,</span> <span>SIMSIMD_IDENTIFY</span><span>)</span> <span>// `simsimd_serial_i8_cos`
</span></span></span></code></pre></td></tr></tbody></table></div><p>Those macros will generate the following functions:</p><ul><li><code>simsimd_serial_f32_cos</code>: for 32-bit <code>floats</code>.</li><li><code>simsimd_serial_f16_cos</code>: for 16-bit <code>halfs</code>, accumulating 32-bit values.</li><li><code>simsimd_serial_i8_cos</code>: for 8-bit <code>ints</code>, accumulating 32-bit values.</li></ul><p>We benchmark those using the Google Benchmark library:</p><ul><li><code>floats</code>: 1956 ns ~ <strong>33x</strong> faster than Python.</li><li><code>halfs</code>: 1118 ns ~ <strong>58x</strong> faster than Python.</li><li><code>ints</code>: 299 ns ~ <strong>218x</strong> faster than Python.</li></ul><p>That’s a great result, but this code relies on the compiler to perform heavy lifting and produce efficient Assembly. As we know, sometimes even the most recent compilers, like <a href="https://ashvardanian.com/posts/gcc-12-vs-avx512fp16/">GCC 12, can be 119x slower than hand-written Assembly</a>. Even on the simplest data-parallel tasks, like computing the Jensen Shannon divergence of two discrete probability distributions.</p><blockquote><p lang="en" dir="ltr">I’ve found a fairly simple data-parallel workload, where AVX-512FP16 <a href="https://twitter.com/hashtag/SIMD?src=hash&amp;ref_src=twsrc%5Etfw">#SIMD</a> code beats O3/fast-math assembly produced by GCC 12 by a factor of 118x 🤯🤯🤯<a href="https://t.co/cFftGbMBQe">https://t.co/cFftGbMBQe</a></p>— Ash Vardanian (@ashvardanian) <a href="https://twitter.com/ashvardanian/status/1716581551717433572?ref_src=twsrc%5Etfw">October 23, 2023</a></blockquote><h2 id="assembly">Assembly</h2><p>Assembly is the lowest-level programming language, and it is the closest to the hardware. It is also the most difficult to write and maintain, as it is not portable, and it is very easy to make mistakes. But it is also the most rewarding, as it allows us to write the most efficient code and to use the most advanced hardware features, like AVX-512. AVX-512, in turn, is not a monolith. It’s a very complex instruction set with the following subsets:</p><ul><li>AVX-512F: 512-bit SIMD instructions.</li><li>AVX-512DQ: double-precision floating-point instructions.</li><li>AVX-512BW: byte and word instructions.</li><li>AVX-512VL: vector length extensions.</li><li>AVX-512CD: conflict detection instructions.</li><li>AVX-512ER: exponential and reciprocal instructions.</li><li>AVX-512PF: prefetch instructions.</li><li>AVX-512VBMI: vector byte manipulation instructions.</li><li>AVX-512IFMA: integer fused multiply-add instructions.</li><li>AVX-512VBMI2: vector byte manipulation instructions 2.</li><li><strong>AVX-512VNNI</strong>: vector neural network instructions.</li><li>AVX-512BITALG: bit algorithms instructions.</li><li>AVX-512VPOPCNTDQ: vector population count instructions.</li><li>AVX-5124VNNIW: vector neural network instructions word variable precision.</li><li>AVX-5124FMAPS: fused multiply-add instructions single precision.</li><li>AVX-512VP2INTERSECT: vector pairwise intersect instructions.</li><li>AVX-512BF16: <code>bfloat16</code> instructions.</li><li><strong>AVX-512FP16</strong>: half-precision floating-point instructions.</li></ul><p>Luckily, we won’t need all of them today. If you are curious, you can read more about them in the <a href="https://software.intel.com/content/www/us/en/develop/articles/intel-sdm.html">Intel 64 and IA-32 Architectures Software Developer’s Manual</a>… but be ready, it’s a very long read.</p><p>Moreover, we don’t have to write the Assembly per se, as we can use the <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/">SIMD Intrinsics</a> to essentially write the Assembly instructions without leaving C.</p><div><table><tbody><tr><td><pre tabindex="0"><code><span id="hl-6-1"><a href="#hl-6-1"> 1</a>
</span><span id="hl-6-2"><a href="#hl-6-2"> 2</a>
</span><span id="hl-6-3"><a href="#hl-6-3"> 3</a>
</span><span id="hl-6-4"><a href="#hl-6-4"> 4</a>
</span><span id="hl-6-5"><a href="#hl-6-5"> 5</a>
</span><span id="hl-6-6"><a href="#hl-6-6"> 6</a>
</span><span id="hl-6-7"><a href="#hl-6-7"> 7</a>
</span><span id="hl-6-8"><a href="#hl-6-8"> 8</a>
</span><span id="hl-6-9"><a href="#hl-6-9"> 9</a>
</span><span id="hl-6-10"><a href="#hl-6-10">10</a>
</span><span id="hl-6-11"><a href="#hl-6-11">11</a>
</span><span id="hl-6-12"><a href="#hl-6-12">12</a>
</span><span id="hl-6-13"><a href="#hl-6-13">13</a>
</span><span id="hl-6-14"><a href="#hl-6-14">14</a>
</span><span id="hl-6-15"><a href="#hl-6-15">15</a>
</span><span id="hl-6-16"><a href="#hl-6-16">16</a>
</span><span id="hl-6-17"><a href="#hl-6-17">17</a>
</span><span id="hl-6-18"><a href="#hl-6-18">18</a>
</span><span id="hl-6-19"><a href="#hl-6-19">19</a>
</span><span id="hl-6-20"><a href="#hl-6-20">20</a>
</span><span id="hl-6-21"><a href="#hl-6-21">21</a>
</span><span id="hl-6-22"><a href="#hl-6-22">22</a>
</span><span id="hl-6-23"><a href="#hl-6-23">23</a>
</span><span id="hl-6-24"><a href="#hl-6-24">24</a>
</span><span id="hl-6-25"><a href="#hl-6-25">25</a>
</span><span id="hl-6-26"><a href="#hl-6-26">26</a>
</span></code></pre></td><td><pre tabindex="0"><code data-lang="c"><span><span><span>__attribute__</span><span>((</span><span>target</span><span>(</span><span>"avx512f,avx512vl"</span><span>)))</span> <span>//
</span></span></span><span><span><span></span><span>inline</span> <span>static</span> <span>simsimd_f32_t</span>
</span></span><span><span><span>simsimd_avx512_f32_cos</span><span>(</span><span>simsimd_f32_t</span> <span>const</span><span>*</span> <span>a</span><span>,</span> <span>simsimd_f32_t</span> <span>const</span><span>*</span> <span>b</span><span>,</span> <span>simsimd_size_t</span> <span>n</span><span>)</span> <span>{</span>
</span></span><span><span>    <span>__m512</span> <span>ab_vec</span> <span>=</span> <span>_mm512_set1_ps</span><span>(</span><span>0</span><span>);</span>
</span></span><span><span>    <span>__m512</span> <span>a2_vec</span> <span>=</span> <span>_mm512_set1_ps</span><span>(</span><span>0</span><span>);</span>
</span></span><span><span>    <span>__m512</span> <span>b2_vec</span> <span>=</span> <span>_mm512_set1_ps</span><span>(</span><span>0</span><span>);</span>
</span></span><span><span>
</span></span><span><span>    <span>for</span> <span>(</span><span>simsimd_size_t</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>n</span><span>;</span> <span>i</span> <span>+=</span> <span>16</span><span>)</span> <span>{</span>
</span></span><span><span>        <span>__mmask16</span> <span>mask</span> <span>=</span> <span>n</span> <span>-</span> <span>i</span> <span>&gt;=</span> <span>16</span> <span>?</span> <span>0xFFFF</span> <span>:</span> <span>((</span><span>1u</span> <span>&lt;&lt;</span> <span>(</span><span>n</span> <span>-</span> <span>i</span><span>))</span> <span>-</span> <span>1u</span><span>);</span>
</span></span><span><span>        <span>__m512</span> <span>a_vec</span> <span>=</span> <span>_mm512_maskz_loadu_ps</span><span>(</span><span>mask</span><span>,</span> <span>a</span> <span>+</span> <span>i</span><span>);</span>
</span></span><span><span>        <span>__m512</span> <span>b_vec</span> <span>=</span> <span>_mm512_maskz_loadu_ps</span><span>(</span><span>mask</span><span>,</span> <span>b</span> <span>+</span> <span>i</span><span>);</span>
</span></span><span><span>        <span>ab_vec</span> <span>=</span> <span>_mm512_fmadd_ps</span><span>(</span><span>a_vec</span><span>,</span> <span>b_vec</span><span>,</span> <span>ab_vec</span><span>);</span>
</span></span><span><span>        <span>a2_vec</span> <span>=</span> <span>_mm512_fmadd_ps</span><span>(</span><span>a_vec</span><span>,</span> <span>a_vec</span><span>,</span> <span>a2_vec</span><span>);</span>
</span></span><span><span>        <span>b2_vec</span> <span>=</span> <span>_mm512_fmadd_ps</span><span>(</span><span>b_vec</span><span>,</span> <span>b_vec</span><span>,</span> <span>b2_vec</span><span>);</span>
</span></span><span><span>    <span>}</span>
</span></span><span><span>
</span></span><span><span>    <span>simsimd_f32_t</span> <span>ab</span> <span>=</span> <span>_mm512_reduce_add_ps</span><span>(</span><span>ab_vec</span><span>);</span>
</span></span><span><span>    <span>simsimd_f32_t</span> <span>a2</span> <span>=</span> <span>_mm512_reduce_add_ps</span><span>(</span><span>a2_vec</span><span>);</span>
</span></span><span><span>    <span>simsimd_f32_t</span> <span>b2</span> <span>=</span> <span>_mm512_reduce_add_ps</span><span>(</span><span>b2_vec</span><span>);</span>
</span></span><span><span>
</span></span><span><span>    <span>__m128d</span> <span>a2_b2</span> <span>=</span> <span>_mm_set_pd</span><span>((</span><span>double</span><span>)</span><span>a2</span><span>,</span> <span>(</span><span>double</span><span>)</span><span>b2</span><span>);</span>
</span></span><span><span>    <span>__m128d</span> <span>rsqrts</span> <span>=</span> <span>_mm_mask_rsqrt14_pd</span><span>(</span><span>_mm_setzero_pd</span><span>(),</span> <span>0xFF</span><span>,</span> <span>a2_b2</span><span>);</span>
</span></span><span><span>    <span>double</span> <span>rsqrts_array</span><span>[</span><span>2</span><span>];</span>
</span></span><span><span>    <span>_mm_storeu_pd</span><span>(</span><span>rsqrts_array</span><span>,</span> <span>rsqrts</span><span>);</span>
</span></span><span><span>    <span>return</span> <span>1</span> <span>-</span> <span>ab</span> <span>*</span> <span>rsqrts_array</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>rsqrts_array</span><span>[</span><span>1</span><span>];</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></td></tr></tbody></table></div><p>Let’s start with a relatively simple implementation:</p><ul><li>A single <code>for</code>-loop iterates through 2 vectors, scanning up to 16 entries simultaneously.</li><li>When it reaches the end of the vectors, it uses a mask to load the remaining entries with the <code>((1u &lt;&lt; (n - i)) - 1u)</code> mask.</li><li>It doesn’t expect the vectors to be aligned, so it uses the <code>loadu</code> instructions.</li><li>It avoids separate additions using the <code>fmadd</code> instruction, which computes <code>a * b + c</code>.</li><li>It uses the <code>reduce_add</code> intrinsic to sum all the elements in the vector, which is not a SIMD code, but the compiler can optimize that part for us.</li><li>It uses the <code>rsqrt14</code> instruction to compute the reciprocal square root of the sum of <code>a2</code> and <code>b2</code>, very accurately approximating <code>1/sqrt(a2)</code> and <code>1/sqrt(b2)</code>, and avoiding LibC calls.</li></ul><p>Benchmarking this code and its symmetric counterparts for other data types, we get the following:</p><ul><li><code>floats</code>: 118 ns ~ <strong>553x</strong> faster than Python.</li><li><code>halfs</code>: 79 ns ~ <strong>827x</strong> faster than Python.</li><li><code>ints</code>: 158 ns ~ <strong>413x</strong> faster than Python.</li></ul><p>We are now in the higher three digits.</p><h3 id="bmi2-and-goto">BMI2 and <code>goto</code></h3><p>The world is full of prejudice and unfairness, and some of the biggest ones in programming are:</p><ul><li>considering a <code>goto</code> to be an anti-pattern.</li><li>not using the BMI2 family of assembly instructions.</li></ul><p>The first one is handy when optimizing low-level code and avoiding unnecessary branching. The second is a tiny set of <code>bzhi</code>, <code>pdep</code>, <code>pext</code>, and a few other, convenient for bit manipulation! We will restore fairness and introduce them to our code, replacing double-precision computations with single-precision.</p><div><table><tbody><tr><td><pre tabindex="0"><code><span id="hl-7-1"><a href="#hl-7-1"> 1</a>
</span><span id="hl-7-2"><a href="#hl-7-2"> 2</a>
</span><span id="hl-7-3"><a href="#hl-7-3"> 3</a>
</span><span id="hl-7-4"><a href="#hl-7-4"> 4</a>
</span><span id="hl-7-5"><a href="#hl-7-5"> 5</a>
</span><span id="hl-7-6"><a href="#hl-7-6"> 6</a>
</span><span id="hl-7-7"><a href="#hl-7-7"> 7</a>
</span><span id="hl-7-8"><a href="#hl-7-8"> 8</a>
</span><span id="hl-7-9"><a href="#hl-7-9"> 9</a>
</span><span id="hl-7-10"><a href="#hl-7-10">10</a>
</span><span id="hl-7-11"><a href="#hl-7-11">11</a>
</span><span id="hl-7-12"><a href="#hl-7-12">12</a>
</span><span id="hl-7-13"><a href="#hl-7-13">13</a>
</span><span id="hl-7-14"><a href="#hl-7-14">14</a>
</span><span id="hl-7-15"><a href="#hl-7-15">15</a>
</span><span id="hl-7-16"><a href="#hl-7-16">16</a>
</span><span id="hl-7-17"><a href="#hl-7-17">17</a>
</span><span id="hl-7-18"><a href="#hl-7-18">18</a>
</span><span id="hl-7-19"><a href="#hl-7-19">19</a>
</span><span id="hl-7-20"><a href="#hl-7-20">20</a>
</span><span id="hl-7-21"><a href="#hl-7-21">21</a>
</span><span id="hl-7-22"><a href="#hl-7-22">22</a>
</span><span id="hl-7-23"><a href="#hl-7-23">23</a>
</span><span id="hl-7-24"><a href="#hl-7-24">24</a>
</span><span id="hl-7-25"><a href="#hl-7-25">25</a>
</span><span id="hl-7-26"><a href="#hl-7-26">26</a>
</span><span id="hl-7-27"><a href="#hl-7-27">27</a>
</span><span id="hl-7-28"><a href="#hl-7-28">28</a>
</span><span id="hl-7-29"><a href="#hl-7-29">29</a>
</span><span id="hl-7-30"><a href="#hl-7-30">30</a>
</span><span id="hl-7-31"><a href="#hl-7-31">31</a>
</span><span id="hl-7-32"><a href="#hl-7-32">32</a>
</span><span id="hl-7-33"><a href="#hl-7-33">33</a>
</span><span id="hl-7-34"><a href="#hl-7-34">34</a>
</span><span id="hl-7-35"><a href="#hl-7-35">35</a>
</span></code></pre></td><td><pre tabindex="0"><code data-lang="c"><span><span><span>__attribute__</span><span>((</span><span>target</span><span>(</span><span>"avx512f,avx512vl,bmi2"</span><span>)))</span> <span>//
</span></span></span><span><span><span></span><span>inline</span> <span>static</span> <span>simsimd_f32_t</span>
</span></span><span><span><span>simsimd_avx512_f32_cos</span><span>(</span><span>simsimd_f32_t</span> <span>const</span><span>*</span> <span>a</span><span>,</span> <span>simsimd_f32_t</span> <span>const</span><span>*</span> <span>b</span><span>,</span> <span>simsimd_size_t</span> <span>n</span><span>)</span> <span>{</span>
</span></span><span><span>    <span>__m512</span> <span>ab_vec</span> <span>=</span> <span>_mm512_set1_ps</span><span>(</span><span>0</span><span>);</span>
</span></span><span><span>    <span>__m512</span> <span>a2_vec</span> <span>=</span> <span>_mm512_set1_ps</span><span>(</span><span>0</span><span>);</span>
</span></span><span><span>    <span>__m512</span> <span>b2_vec</span> <span>=</span> <span>_mm512_set1_ps</span><span>(</span><span>0</span><span>);</span>
</span></span><span><span>    <span>__m512</span> <span>a_vec</span><span>,</span> <span>b_vec</span><span>;</span>
</span></span><span><span>
</span></span><span><span><span>simsimd_avx512_f32_cos_cycle</span><span>:</span>
</span></span><span><span>    <span>if</span> <span>(</span><span>n</span> <span>&lt;</span> <span>16</span><span>)</span> <span>{</span>
</span></span><span><span>        <span>__mmask16</span> <span>mask</span> <span>=</span> <span>_bzhi_u32</span><span>(</span><span>0xFFFFFFFF</span><span>,</span> <span>n</span><span>);</span>
</span></span><span><span>        <span>a_vec</span> <span>=</span> <span>_mm512_maskz_loadu_ps</span><span>(</span><span>mask</span><span>,</span> <span>a</span><span>);</span>
</span></span><span><span>        <span>b_vec</span> <span>=</span> <span>_mm512_maskz_loadu_ps</span><span>(</span><span>mask</span><span>,</span> <span>b</span><span>);</span>
</span></span><span><span>        <span>n</span> <span>=</span> <span>0</span><span>;</span>
</span></span><span><span>    <span>}</span> <span>else</span> <span>{</span>
</span></span><span><span>        <span>a_vec</span> <span>=</span> <span>_mm512_loadu_ps</span><span>(</span><span>a</span><span>);</span>
</span></span><span><span>        <span>b_vec</span> <span>=</span> <span>_mm512_loadu_ps</span><span>(</span><span>b</span><span>);</span>
</span></span><span><span>        <span>a</span> <span>+=</span> <span>16</span><span>,</span> <span>b</span> <span>+=</span> <span>16</span><span>,</span> <span>n</span> <span>-=</span> <span>16</span><span>;</span>
</span></span><span><span>    <span>}</span>
</span></span><span><span>    <span>ab_vec</span> <span>=</span> <span>_mm512_fmadd_ps</span><span>(</span><span>a_vec</span><span>,</span> <span>b_vec</span><span>,</span> <span>ab_vec</span><span>);</span>
</span></span><span><span>    <span>a2_vec</span> <span>=</span> <span>_mm512_fmadd_ps</span><span>(</span><span>a_vec</span><span>,</span> <span>a_vec</span><span>,</span> <span>a2_vec</span><span>);</span>
</span></span><span><span>    <span>b2_vec</span> <span>=</span> <span>_mm512_fmadd_ps</span><span>(</span><span>b_vec</span><span>,</span> <span>b_vec</span><span>,</span> <span>b2_vec</span><span>);</span>
</span></span><span><span>    <span>if</span> <span>(</span><span>n</span><span>)</span>
</span></span><span><span>        <span>goto</span> <span>simsimd_avx512_f32_cos_cycle</span><span>;</span>
</span></span><span><span>
</span></span><span><span>    <span>simsimd_f32_t</span> <span>ab</span> <span>=</span> <span>_mm512_reduce_add_ps</span><span>(</span><span>ab_vec</span><span>);</span>
</span></span><span><span>    <span>simsimd_f32_t</span> <span>a2</span> <span>=</span> <span>_mm512_reduce_add_ps</span><span>(</span><span>a2_vec</span><span>);</span>
</span></span><span><span>    <span>simsimd_f32_t</span> <span>b2</span> <span>=</span> <span>_mm512_reduce_add_ps</span><span>(</span><span>b2_vec</span><span>);</span>
</span></span><span><span>
</span></span><span><span>    <span>// Compute the reciprocal square roots of a2 and b2
</span></span></span><span><span><span></span>    <span>__m128</span> <span>rsqrts</span> <span>=</span> <span>_mm_rsqrt14_ps</span><span>(</span><span>_mm_set_ps</span><span>(</span><span>0.f</span><span>,</span> <span>0.f</span><span>,</span> <span>a2</span> <span>+</span> <span>1.e-9</span><span>f</span><span>,</span> <span>b2</span> <span>+</span> <span>1.e-9</span><span>f</span><span>));</span>
</span></span><span><span>    <span>simsimd_f32_t</span> <span>rsqrt_a2</span> <span>=</span> <span>_mm_cvtss_f32</span><span>(</span><span>rsqrts</span><span>);</span>
</span></span><span><span>    <span>simsimd_f32_t</span> <span>rsqrt_b2</span> <span>=</span> <span>_mm_cvtss_f32</span><span>(</span><span>_mm_shuffle_ps</span><span>(</span><span>rsqrts</span><span>,</span> <span>rsqrts</span><span>,</span> <span>_MM_SHUFFLE</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>1</span><span>)));</span>
</span></span><span><span>    <span>return</span> <span>1</span> <span>-</span> <span>ab</span> <span>*</span> <span>rsqrt_a2</span> <span>*</span> <span>rsqrt_b2</span><span>;</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></td></tr></tbody></table></div><p>Result for <code>floats</code>: 87.4 ns ~ <strong>747x</strong> faster than Python.</p><blockquote><p>One of the reasons the BMI2 extensions didn’t take off originally is that, AMD processors before Zen 3 implemented <code>pdep</code> and <code>pext</code> with a latency of 18 cycles. Newer CPUs do it with the latency of 3 cycles.</p></blockquote><h3 id="fp16">FP16</h3><p>Ice Lake CPUs supported all the instructions we’ve used so far. In contrast, the newer Sapphire Rapids instructions add native support for half-precision math.</p><div><table><tbody><tr><td><pre tabindex="0"><code><span id="hl-8-1"><a href="#hl-8-1"> 1</a>
</span><span id="hl-8-2"><a href="#hl-8-2"> 2</a>
</span><span id="hl-8-3"><a href="#hl-8-3"> 3</a>
</span><span id="hl-8-4"><a href="#hl-8-4"> 4</a>
</span><span id="hl-8-5"><a href="#hl-8-5"> 5</a>
</span><span id="hl-8-6"><a href="#hl-8-6"> 6</a>
</span><span id="hl-8-7"><a href="#hl-8-7"> 7</a>
</span><span id="hl-8-8"><a href="#hl-8-8"> 8</a>
</span><span id="hl-8-9"><a href="#hl-8-9"> 9</a>
</span><span id="hl-8-10"><a href="#hl-8-10">10</a>
</span><span id="hl-8-11"><a href="#hl-8-11">11</a>
</span><span id="hl-8-12"><a href="#hl-8-12">12</a>
</span><span id="hl-8-13"><a href="#hl-8-13">13</a>
</span><span id="hl-8-14"><a href="#hl-8-14">14</a>
</span><span id="hl-8-15"><a href="#hl-8-15">15</a>
</span><span id="hl-8-16"><a href="#hl-8-16">16</a>
</span></code></pre></td><td><pre tabindex="0"><code data-lang="c"><span><span><span>simsimd_avx512_f16_cos_cycle</span><span>:</span>
</span></span><span><span>    <span>if</span> <span>(</span><span>n</span> <span>&lt;</span> <span>32</span><span>)</span> <span>{</span>
</span></span><span><span>        <span>__mmask32</span> <span>mask</span> <span>=</span> <span>_bzhi_u32</span><span>(</span><span>0xFFFFFFFF</span><span>,</span> <span>n</span><span>);</span>
</span></span><span><span>        <span>a_i16_vec</span> <span>=</span> <span>_mm512_maskz_loadu_epi16</span><span>(</span><span>mask</span><span>,</span> <span>a</span><span>);</span>
</span></span><span><span>        <span>b_i16_vec</span> <span>=</span> <span>_mm512_maskz_loadu_epi16</span><span>(</span><span>mask</span><span>,</span> <span>b</span><span>);</span>
</span></span><span><span>        <span>n</span> <span>=</span> <span>0</span><span>;</span>
</span></span><span><span>    <span>}</span> <span>else</span> <span>{</span>
</span></span><span><span>        <span>a_i16_vec</span> <span>=</span> <span>_mm512_loadu_epi16</span><span>(</span><span>a</span><span>);</span>
</span></span><span><span>        <span>b_i16_vec</span> <span>=</span> <span>_mm512_loadu_epi16</span><span>(</span><span>b</span><span>);</span>
</span></span><span><span>        <span>a</span> <span>+=</span> <span>32</span><span>,</span> <span>b</span> <span>+=</span> <span>32</span><span>,</span> <span>n</span> <span>-=</span> <span>32</span><span>;</span>
</span></span><span><span>    <span>}</span>
</span></span><span><span>    <span>ab_vec</span> <span>=</span> <span>_mm512_fmadd_ph</span><span>(</span><span>_mm512_castsi512_ph</span><span>(</span><span>a_i16_vec</span><span>),</span> <span>_mm512_castsi512_ph</span><span>(</span><span>b_i16_vec</span><span>),</span> <span>ab_vec</span><span>);</span>
</span></span><span><span>    <span>a2_vec</span> <span>=</span> <span>_mm512_fmadd_ph</span><span>(</span><span>_mm512_castsi512_ph</span><span>(</span><span>a_i16_vec</span><span>),</span> <span>_mm512_castsi512_ph</span><span>(</span><span>a_i16_vec</span><span>),</span> <span>a2_vec</span><span>);</span>
</span></span><span><span>    <span>b2_vec</span> <span>=</span> <span>_mm512_fmadd_ph</span><span>(</span><span>_mm512_castsi512_ph</span><span>(</span><span>b_i16_vec</span><span>),</span> <span>_mm512_castsi512_ph</span><span>(</span><span>b_i16_vec</span><span>),</span> <span>b2_vec</span><span>);</span>
</span></span><span><span>    <span>if</span> <span>(</span><span>n</span><span>)</span>
</span></span><span><span>        <span>goto</span> <span>simsimd_avx512_f16_cos_cycle</span><span>;</span>
</span></span></code></pre></td></tr></tbody></table></div><p>The body of our function has changed:</p><ul><li>we are now scanning 32 entries per cycle, as the scalars are 2x smaller.</li><li>we are using the <code>_ph</code> intrinsics, the half-precision counterparts of the <code>_ps</code> intrinsics.</li></ul><p>Result for <code>halfs</code>: 51.8 ns ~ <strong>1'260x</strong> faster than Python.</p><h3 id="vnni">VNNI</h3><p>Today’s final instruction we’ll explore is the <code>vpdpbusd</code> from the AVX-512VNNI subset. It multiplies 8-bit integers, generating 16-bit intermediate results, which are then added to a 32-bit accumulator. With smaller scalars, we can house 64 of them in a single ZMM register.</p><div><table><tbody><tr><td><pre tabindex="0"><code><span id="hl-9-1"><a href="#hl-9-1"> 1</a>
</span><span id="hl-9-2"><a href="#hl-9-2"> 2</a>
</span><span id="hl-9-3"><a href="#hl-9-3"> 3</a>
</span><span id="hl-9-4"><a href="#hl-9-4"> 4</a>
</span><span id="hl-9-5"><a href="#hl-9-5"> 5</a>
</span><span id="hl-9-6"><a href="#hl-9-6"> 6</a>
</span><span id="hl-9-7"><a href="#hl-9-7"> 7</a>
</span><span id="hl-9-8"><a href="#hl-9-8"> 8</a>
</span><span id="hl-9-9"><a href="#hl-9-9"> 9</a>
</span><span id="hl-9-10"><a href="#hl-9-10">10</a>
</span><span id="hl-9-11"><a href="#hl-9-11">11</a>
</span><span id="hl-9-12"><a href="#hl-9-12">12</a>
</span><span id="hl-9-13"><a href="#hl-9-13">13</a>
</span><span id="hl-9-14"><a href="#hl-9-14">14</a>
</span><span id="hl-9-15"><a href="#hl-9-15">15</a>
</span><span id="hl-9-16"><a href="#hl-9-16">16</a>
</span></code></pre></td><td><pre tabindex="0"><code data-lang="c"><span><span><span>simsimd_avx512_i8_cos_cycle</span><span>:</span>
</span></span><span><span>    <span>if</span> <span>(</span><span>n</span> <span>&lt;</span> <span>64</span><span>)</span> <span>{</span>
</span></span><span><span>        <span>__mmask64</span> <span>mask</span> <span>=</span> <span>_bzhi_u64</span><span>(</span><span>0xFFFFFFFFFFFFFFFF</span><span>,</span> <span>n</span><span>);</span>
</span></span><span><span>        <span>a_vec</span> <span>=</span> <span>_mm512_maskz_loadu_epi8</span><span>(</span><span>mask</span><span>,</span> <span>a</span><span>);</span>
</span></span><span><span>        <span>b_vec</span> <span>=</span> <span>_mm512_maskz_loadu_epi8</span><span>(</span><span>mask</span><span>,</span> <span>b</span><span>);</span>
</span></span><span><span>        <span>n</span> <span>=</span> <span>0</span><span>;</span>
</span></span><span><span>    <span>}</span> <span>else</span> <span>{</span>
</span></span><span><span>        <span>a_vec</span> <span>=</span> <span>_mm512_loadu_epi8</span><span>(</span><span>a</span><span>);</span>
</span></span><span><span>        <span>b_vec</span> <span>=</span> <span>_mm512_loadu_epi8</span><span>(</span><span>b</span><span>);</span>
</span></span><span><span>        <span>a</span> <span>+=</span> <span>64</span><span>,</span> <span>b</span> <span>+=</span> <span>64</span><span>,</span> <span>n</span> <span>-=</span> <span>64</span><span>;</span>
</span></span><span><span>    <span>}</span>
</span></span><span><span>    <span>ab_i32s_vec</span> <span>=</span> <span>_mm512_dpbusd_epi32</span><span>(</span><span>ab_i32s_vec</span><span>,</span> <span>a_vec</span><span>,</span> <span>b_vec</span><span>);</span>
</span></span><span><span>    <span>a2_i32s_vec</span> <span>=</span> <span>_mm512_dpbusd_epi32</span><span>(</span><span>a2_i32s_vec</span><span>,</span> <span>a_vec</span><span>,</span> <span>a_vec</span><span>);</span>
</span></span><span><span>    <span>b2_i32s_vec</span> <span>=</span> <span>_mm512_dpbusd_epi32</span><span>(</span><span>b2_i32s_vec</span><span>,</span> <span>b_vec</span><span>,</span> <span>b_vec</span><span>);</span>
</span></span><span><span>    <span>if</span> <span>(</span><span>n</span><span>)</span>
</span></span><span><span>        <span>goto</span> <span>simsimd_avx512_i8_cos_cycle</span><span>;</span>
</span></span></code></pre></td></tr></tbody></table></div><p>After compiling, you might expect to see three <code>vpdpbusd</code> invocations. However, the compiler had other ideas. Instead of sticking to our expected flow, it duplicated <code>vpdpbusd</code> calls in both branches of the <code>if</code> condition to minimize code sections and jumps. Here’s a glimpse of our main operational section:</p><pre tabindex="0"><code data-lang="assembly">.L2:
        ; Check `if (n &lt; 64)` and jump to the L7 if it's true.
        cmp     rax, rdx                            
        je      .L7
        ; Load 64 bytes from `a` and `b` into `zmm1` and `zmm0`.
        vmovdqu8        zmm1, ZMMWORD PTR [rdi]
        vmovdqu8        zmm0, ZMMWORD PTR [rsi]
        ; Increment `a` and `b` pointers by 64.
        add     rdi, 64
        add     rsi, 64
        ; Perform mixed-precision dot-products.
        vpdpbusd        zmm4, zmm1, zmm0 ; ab = b * a
        vpdpbusd        zmm3, zmm1, zmm1 ; b2 = b * b
        vpdpbusd        zmm2, zmm0, zmm0 ; a2 = a * a
        ; Subtract the number of remaining entries and jump back.
        sub     rdx, 64
        jne     .L2
.L7:
        ; Process the tail, by building the `k1` mask first.
        ; We avoid `k0`, which is a hardcoded constant used to indicate unmasked operations.
        mov     rdx, -1
        bzhi    rax, rdx, rax
        kmovq   k1, rax
        ; Load under 64 bytes from `a` and `b` into `zmm1` and `zmm0`,
        ; using the mask from the `k1`, which can be applied to any AVX-512 argument.
        vmovdqu8        zmm1{k1}{z}, ZMMWORD PTR [rdi]
        vmovdqu8        zmm0{k1}{z}, ZMMWORD PTR [rsi]
        ; Perform mixed-precision dot-products.
        vpdpbusd        zmm3, zmm1, zmm1 ; b2 = b * b
        vpdpbusd        zmm4, zmm1, zmm0 ; ab = b * a
        vpdpbusd        zmm2, zmm0, zmm0 ; a2 = a * a
        ; Exit the loop.
        jmp     .L4
</code></pre><p>It’s often intriguing to see how compilers shuffle around my instructions, especially when it seems somewhat arbitrary in brief code segments. Our heavy SIMD will anyways be decoded into micro-ops, and then the CPU rearranges them all over again, disregarding compiler’s sequence. Still, upon testing this with the Google Benchmark library, we observed the following for <code>ints</code>: <strong>25.9 ns</strong>, which is roughly <strong>2'521 times faster</strong> than our original Python baseline. Delivered as promised 🤗</p><h2 id="conclusion">Conclusion</h2><p>There’s a common belief that you need a massive infrastructure, akin to what giants like OpenAI or Google possess, to create impactful technology. However, I’m a proponent of the idea that many amazing innovations can spring from humble beginnings – even on a shoestring budget. If you share this sentiment and are keen on optimizing and innovating, you might be interested in some other libraries I’ve had a hand in. 😉</p><table><thead><tr><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td><a href="https://github.com/unum-cloud/usearch"><img loading="lazy" src="https://img.shields.io/github/stars/unum-cloud/usearch?style=social&amp;label=USearch%20repository" alt="USearch"></a></td><td><a href="https://github.com/ashvardanian/stringzilla"><img loading="lazy" src="https://img.shields.io/github/stars/ashvardanian/stringzilla?style=social&amp;label=StringZilla%20repository" alt="StringZilla"></a></td><td><a href="https://github.com/unum-cloud/uform"><img loading="lazy" src="https://img.shields.io/github/stars/unum-cloud/uform?style=social&amp;label=UForm%20repository" alt="UForm"></a></td><td><a href="https://github.com/ashvardanian/simsimd"><img loading="lazy" src="https://img.shields.io/github/stars/ashvardanian/simsimd?style=social&amp;label=SimSIMD%20repository" alt="SimSIMD"></a></td><td><a href="https://github.com/unum-cloud/ucall"><img loading="lazy" src="https://img.shields.io/github/stars/unum-cloud/ucall?style=social&amp;label=UCall%20repository" alt="UCall"></a></td></tr></tbody></table><h2 id="appendix-comparing-compilers">Appendix: Comparing Compilers</h2><p>For those eager to delve deeper, examining the Assembly generated by different compilers can be insightful. A popular comparison is between GCC and Intel’s new ICX compiler, with the latter now being based on LLVM. Before diving into the Assembly details, let’s first benchmark their performance.</p><div><table><tbody><tr><td><pre tabindex="0"><code><span id="hl-11-1"><a href="#hl-11-1">1</a>
</span><span id="hl-11-2"><a href="#hl-11-2">2</a>
</span><span id="hl-11-3"><a href="#hl-11-3">3</a>
</span><span id="hl-11-4"><a href="#hl-11-4">4</a>
</span><span id="hl-11-5"><a href="#hl-11-5">5</a>
</span><span id="hl-11-6"><a href="#hl-11-6">6</a>
</span></code></pre></td><td><pre tabindex="0"><code data-lang="sh"><span><span>$ cmake -DCMAKE_C_COMPILER<span>=</span><span>"gcc-12"</span> -DCMAKE_CXX_COMPILER<span>=</span><span>"g++-12"</span> -DCMAKE_BUILD_TYPE<span>=</span>Release -DSIMSIMD_BUILD_BENCHMARKS<span>=</span><span>1</span> -B ./build_release
</span></span><span><span>$ cmake --build build_release --config Release <span>&amp;&amp;</span> ./build_release/simsimd_bench --benchmark_out<span>=</span><span>"gcc-12.json"</span> --benchmark_filter<span>=</span>1536d
</span></span><span><span>
</span></span><span><span>$ <span>source</span> /opt/intel/oneapi/setvars.sh
</span></span><span><span>$ cmake -DCMAKE_C_COMPILER<span>=</span><span>"icx"</span> -DCMAKE_CXX_COMPILER<span>=</span><span>"icpx"</span> -DCMAKE_BUILD_TYPE<span>=</span>Release -DSIMSIMD_BUILD_BENCHMARKS<span>=</span><span>1</span> -B ./build_release
</span></span><span><span>$ cmake --build build_release --config Release <span>&amp;&amp;</span> ./build_release/simsimd_bench --benchmark_out<span>=</span><span>"intel-2023.json"</span> --benchmark_filter<span>=</span>1536d
</span></span></code></pre></td></tr></tbody></table></div><p>The above script compiles the code using both compilers and then runs each binary, exporting the results into distinct JSON files. Afterwards, you can use Google Benchmark’s lesser-known tool, <code>compare.py</code>, to determine if there are significant performance differences and whether a deeper dive into the Assembly is warranted:</p><div><table><tbody><tr><td><pre tabindex="0"><code><span id="hl-12-1"><a href="#hl-12-1"> 1</a>
</span><span id="hl-12-2"><a href="#hl-12-2"> 2</a>
</span><span id="hl-12-3"><a href="#hl-12-3"> 3</a>
</span><span id="hl-12-4"><a href="#hl-12-4"> 4</a>
</span><span id="hl-12-5"><a href="#hl-12-5"> 5</a>
</span><span id="hl-12-6"><a href="#hl-12-6"> 6</a>
</span><span id="hl-12-7"><a href="#hl-12-7"> 7</a>
</span><span id="hl-12-8"><a href="#hl-12-8"> 8</a>
</span><span id="hl-12-9"><a href="#hl-12-9"> 9</a>
</span><span id="hl-12-10"><a href="#hl-12-10">10</a>
</span><span id="hl-12-11"><a href="#hl-12-11">11</a>
</span><span id="hl-12-12"><a href="#hl-12-12">12</a>
</span><span id="hl-12-13"><a href="#hl-12-13">13</a>
</span><span id="hl-12-14"><a href="#hl-12-14">14</a>
</span><span id="hl-12-15"><a href="#hl-12-15">15</a>
</span><span id="hl-12-16"><a href="#hl-12-16">16</a>
</span><span id="hl-12-17"><a href="#hl-12-17">17</a>
</span></code></pre></td><td><pre tabindex="0"><code data-lang="sh"><span><span>$ mkdir -p gbench
</span></span><span><span>$ wget https://github.com/google/benchmark/blob/main/tools/compare.py?raw<span>=</span><span>true</span> -O compare.py
</span></span><span><span>$ wget https://github.com/google/benchmark/blob/main/tools/gbench/report.py?raw<span>=</span><span>true</span> -O gbench/report.py
</span></span><span><span>$ wget https://github.com/google/benchmark/blob/main/tools/gbench/util.py?raw<span>=</span><span>true</span> -O gbench/util.py
</span></span><span><span>$ python compare.py benchmarks gcc-12.json intel-2023.json
</span></span><span><span>
</span></span><span><span>Comparing gcc-12.json to intel-2023.json
</span></span><span><span>Benchmark                                                         Time             CPU      Time Old      Time New       CPU Old       CPU New
</span></span><span><span>----------------------------------------------------------------------------------------------------------------------------------------------
</span></span><span><span>avx2_f16_cos_1536d/min_time:10.000/threads:1                   +0.0002         +0.0002           <span>235</span>           <span>235</span>           <span>235</span>           <span>235</span>
</span></span><span><span>avx2_i8_cos_1536d/min_time:10.000/threads:1                    -0.0034         -0.0034            <span>91</span>            <span>91</span>            <span>91</span>            <span>91</span>
</span></span><span><span>avx512_f16_cos_1536d/min_time:10.000/threads:1                 +0.0024         +0.0024            <span>52</span>            <span>52</span>            <span>52</span>            <span>52</span>
</span></span><span><span>avx512_i8_cos_1536d/min_time:10.000/threads:1                  +0.0110         +0.0110            <span>26</span>            <span>26</span>            <span>26</span>            <span>26</span>
</span></span><span><span>avx512_f32_cos_1536d/min_time:10.000/threads:1                 +0.0206         +0.0206            <span>87</span>            <span>89</span>            <span>87</span>            <span>89</span>
</span></span><span><span>serial_f16_cos_1536d/min_time:10.000/threads:1                 -0.0013         -0.0013          <span>1988</span>          <span>1985</span>          <span>1988</span>          <span>1985</span>
</span></span><span><span>serial_f32_cos_1536d/min_time:10.000/threads:1                 -0.0000         -0.0000          <span>1118</span>          <span>1118</span>          <span>1118</span>          <span>1118</span>
</span></span><span><span>serial_i8_cos_1536d/min_time:10.000/threads:1                  -0.0001         -0.0001           <span>299</span>           <span>299</span>           <span>299</span>           <span>299</span>
</span></span></code></pre></td></tr></tbody></table></div><p>From the results, we observe minimal runtime differences between the two compilers. The generated Assembly is remarkably similar, particularly in the critical sections. Intel’s output is often 10% shorter which is typically advantageous. The most pronounced differences emerge outside of the <code>for</code> loop. Notably, the <code>_mm512_reduce_add_epi32</code> intrinsic doesn’t correspond directly to a specific SIMD instruction, granting the compilers a bit more leeway:</p><ul><li>GCC opts for a lengthier reduction using <code>vextracti64x4</code> and <code>vextracti64x2</code>.</li><li>Intel prefers the succinct <code>vextracti128</code>.</li></ul><p>Both compilers employ the <code>vpshufd</code> for shuffling but use varied masks. For a detailed exploration, visit the <a href="https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAMzwBtMA7AQwFtMQByARg9KtQYEAysib0QXACx8BBAKoBnTAAUAHpwAMvAFYTStJg1DIApACYAQuYukl9ZATwDKjdAGFUtAK4sGIAMwA7KSuADJ4DJgAcj4ARpjEIGYAnKQADqgKhE4MHt6%2BAcEZWY4C4ZExLPGJKbaY9qUMQgRMxAR5Pn5BdQ05za0E5dFxCUmpCi1tHQXdEwNDldVjAJS2qF7EyOwc5v4RyN5YANQm/m54LCwRBMQRAHQIp9gmGgCCL68EAJ5pmFhURyotFQTAIRyyLAh6AA%2BlR/GZoQRTlY3t9fv8jsgEK1wRcodC8AAORHIj5ov6YAFeBhZYCRdBHYFGXGQi4wrIAL0wJP8KPeb2h0NBNzwsS8BG50Kggq8Shh0OWyw%2BguFtzFEsFUEmwEwBAg5jMTAAbqoAKxcMxG2ikY1mi1UG0m81mWIAd0ddstDAYeFIsSuZgNiuWRwA9KGPhFaBFMOCWo5kCz8XCEUi3hD8bbnQTiWgFBAM2yc4jMQIJgAqI5MUhJ">Compiler Explorer</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Transaction Isolation in Postgres (132 pts)]]></title>
            <link>https://www.thenile.dev/blog/transaction-isolation-postgres</link>
            <guid>38684447</guid>
            <pubDate>Mon, 18 Dec 2023 16:13:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thenile.dev/blog/transaction-isolation-postgres">https://www.thenile.dev/blog/transaction-isolation-postgres</a>, See on <a href="https://news.ycombinator.com/item?id=38684447">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Transactions are a key part to many modern databases, relational and non-relational systems alike.
At a basic level, transactions allow us to treat a series of operations as a single unit. The reason transactions are so important is because they provide guarantees that developers can then use as assumptions when writing code. This means that there are entire set of concerns that you, the developer, don't need to worry about because the DB guarantees certain behaviors. This greatly simplifies the code and drastically improves its reliability.</p>
<p>What are these guarantees? You may already be familiar with the term <a href="https://dl.acm.org/doi/10.1145/289.291">ACID</a> - atomicity, consistency, isolation and durability. From these sets of guarantees, “isolation” tends to be the most confusing, which is a shame because it is also the one where a deeper understanding directly translates to making better design decisions, and <a href="http://www.bailis.org/papers/acidrain-sigmod2017.pdf">more secure SaaS</a>.</p>
<p>I'm going to start by explaining what problem transaction isolation is even trying to solve. Then I'll explain the standard isolation levels as they appear in the SQL92 standard and are still mostly used today. Then we'll talk about the problems with SQL92 levels and how Postgres handles isolation and these problems today.
Grab some tea and we'll start.</p>
<h2 id="why-transaction-isolation">Why Transaction Isolation?</h2>
<p>Let's take the classic transactional scenario, moving money from one bank account to another:</p>
<div><pre><code><span>BEGIN</span>;
<span>UPDATE</span> accounts <span>SET</span> balance <span>=</span> balance <span>+</span> <span>100.00</span> <span>WHERE</span> acctnum <span>=</span> <span>12345</span>;
<span>UPDATE</span> accounts <span>SET</span> balance <span>=</span> balance <span>-</span> <span>100.00</span> <span>WHERE</span> acctnum <span>=</span> <span>789</span>;
<span>COMMIT</span>;
</code></pre></div>
<p>For reasons that should be obvious to anyone with a bank account, you really really want both updates to happen, or neither. This is what atomicity guarantees - that the entire transaction will either succeed or fail as a single unit.</p>
<p>While Atomicity provides important guarantees for a single transaction, Isolation guarantees some into play when you have multiple transactions running concurrently.
Suppose we have a scenario where one user ran the transaction above that moves money between accounts, and while that transaction was processing, but before it was committed, someone else ran <code>select balance from accounts where acctnum=12345</code> . What will this query return? Does it matter if it executed before or after the first update?
This is what isolation levels address - how do concurrent transactions and queries affect each other. You can see why isolation can be more complex than atomicity - there are more ways concurrent transactions can interact. So let's look at how the database community approached isolation.</p>
<h2 id="transaction-isolation-in-sql-92-standard">Transaction Isolation in SQL 92 Standard</h2>
<p>Transaction Isolation levels were officially standardized in <a href="https://en.wikipedia.org/wiki/SQL-92">ANSI SQL 92</a>.
The ANSI committee started by defining the logical ideal of isolation. The ideal isolation as they defined it, is that when you have multiple transactions happening at the same time, the resulting state of the DB is one that is possible to achieve by running this set of transactions not concurrently, but sequentially. It doesn't state or mandate any particular order, just that one must exist. <strong>This level of isolation is called “Serializable” because it guarantees that a serial ordering of the transactions with the same results exists</strong>. It lets you think of the database in terms of atomic transactions happening one after another.</p>
<p><strong>Serializable isolation is considered the gold standard in terms of correctness, but why is serializable isolation so great?</strong> Because this guarantee greatly simplifies the way you reason about your application and the way you will test it. You have invariants that you need your system to maintain, for example, an account balance can't go below zero. You can then check that each transaction individually maintains these invariants and serializable isolation guarantees that you don't need to worry about all the ways these transactions will interleave when they run in parallel. You can take transactions as entire units (as we did with atomicity) and only reason about the state of the system before and after each transaction.</p>
<p>Back in 92, the consensus was that serializability is a great ideal, but not something that can be implemented while still delivering adequate performance (spoiler: they were wrong). Since the ideal was not practical, they settled on suggesting multiple levels of isolation and explaining what can happen in each.
The committee came up with a list of weird results you may encounter if you don't have serializability and called these “anomalies”. Then they defined the isolation levels in terms of “which anomalies can happen at each level”:</p>
<table><thead><tr><th>Isolation Level</th><th>Dirty Reads</th><th>Non-repeatable Reads</th><th>Phantom Reads</th></tr></thead><tbody><tr><td>Read Uncommitted</td><td>Possible</td><td>Possible</td><td>Possible</td></tr><tr><td>Read Committed</td><td>Not Possible</td><td>Possible</td><td>Possible</td></tr><tr><td>Repeatable Reads</td><td>Not Possible</td><td>Not Possible</td><td>Possible</td></tr><tr><td>Serializable</td><td>Not Possible</td><td>Not Possible</td><td>Not Possible</td></tr></tbody></table>
<p>This is a practical approach and is useful for developers because it lets us say “I'm okay with some anomalies and I want more speed. Let me go with read committed”. So, as a responsible engineer writing an application with transactions, you should understand the anomalies and make informed decisions. Let's do that!</p>
<h2 id="isolation-levels-and-their-anomalies">Isolation levels and their anomalies</h2>
<h3 id="dirty-reads">Dirty Reads</h3>
<p>"The lowest level of isolation is read uncommitted. Read uncommitted allows a whole slew of anomalies, including the dreaded 'dirty read'. Dirty reads means reading data that has not yet been committed. Remember that if a transaction is not committed yet, it may never get committed. The user may change their mind, there may be an error, the DB can crash. Here's a simple example, lets say that we have two users who connected to the same database and each doing their work around the same time. <a href="https://dba.stackexchange.com/questions/13698/what-is-the-difference-between-a-connection-and-a-session">In database terminology, the state of each connection is called a session</a>, so we are looking at two concurrent sessions:</p>
<table><thead><tr><th>Session A</th><th>Session B</th></tr></thead><tbody><tr><td><pre>BEGIN;</pre></td><td><pre>BEGIN;</pre></td></tr><tr><td><pre><p>INSERT INTO accounts (acctnum, balance)
values (12345, 100);</p></pre></td><td></td></tr><tr><td></td><td><pre>SELECT * from accounts where acctnum = 12345;</pre></td></tr><tr><td><pre>ABORT;</pre></td><td></td></tr></tbody></table>
<p>In isolation level “read uncommitted”, if both these sessions execute concurrently, session B will see an account that does not exist with a balance that does not exist. It looked like it existed, but the transaction was rolled back - which means it never officially existed. If this query is part of a report about the total assets under management for the bank, the report will be incorrect and include non-existing assets.</p>
<p>It sounds so obviously terrible that you'd say who in their right minds would ever do dirty reads?</p>
<p>It is mostly useful in write heavy workloads where you want to support very high write throughput and don't care a ton if reports are not 100% accurate. For example for metrics. Because this level breaks the most basic expectations from transactions. many DBs, including Postgres chose not to support this at all.</p>
<h2 id="non-repeatable-reads">Non-repeatable Reads</h2>
<p>Non-repeatable reads means that the same query within one transaction can return different results if a parallel session committed in between.</p>
<table><thead><tr><th>Session A</th><th>Session B</th></tr></thead><tbody><tr><td><pre>BEGIN;</pre></td><td><pre>BEGIN;</pre></td></tr><tr><td></td><td><pre>SELECT * from accounts where acctnum = 12345;</pre></td></tr><tr><td><pre>UPDATE accounts set balance = 500
where acctnum = 12345;</pre></td><td></td></tr><tr><td><pre>COMMIT;</pre></td><td></td></tr><tr><td></td><td><pre>SELECT * from accounts where acctnum = 12345;</pre></td></tr></tbody></table>
<p>In isolation level “read committed”, the first query in the transaction in session B will return a different result than the second query, because the transaction in session A committed in between. Both results are “correct” in the sense that they reflect a durable state of the database, but they are different.
You may think “why is this even a problem?”</p>
<p>The main problem with non repeatable reads is a classic anti-pattern known as “write after read”. For example, lets say that we want to give 10% bonus to accounts with balance above 1000, and we use the following code:</p>
<table><thead><tr><th>Session A</th><th>Session B</th></tr></thead><tbody><tr><td><pre>BEGIN;</pre></td><td><pre>BEGIN;</pre></td></tr><tr><td></td><td><pre><p>IF (
SELECT balance FROM accounts
WHERE acctnum = 12345 &gt; 1000) THEN</p></pre></td></tr><tr><td><pre>UPDATE accounts set balance = 500
where acctnum = 12345;</pre></td><td></td></tr><tr><td><pre>COMMIT;</pre></td><td></td></tr><tr><td></td><td><pre><p>UPDATE accounts SET balance = balance * 1.1
where acctnum = 12345;</p></pre></td></tr><tr><td></td><td><pre>END IF; COMMIT;</pre></td></tr></tbody></table>
<p>The condition in session B was evaluated to true, and therefore we decided to update the balance in account 12345. But before we had a chance to update the balance, it was updated and committed by session A. The condition is no longer true, but due to the way the code is written, session B will still update the balance. The result will be a state that could not have happened if these sessions ran serially, and account 12345 will have extra 10% bonus in their account that they shouldn't have gotten based on the desired logic.</p>
<p>There are a few ways to get around this problem without changing the isolation level. For example, since the problem occurs when data changes between statements, you may choose to do the entire update in a single statement:</p>
<div><pre><code><span>UPDATE</span> accounts
<span>SET</span> balance <span>=</span> balance <span>*</span> <span>1.1</span>
<span>WHERE</span> acctnum <span>=</span> <span>12345</span> <span>AND</span> balance <span>&gt;</span> <span>1000</span>;
</code></pre></div>
<p>This will behave atomically, as one would expect in a transaction. However, this is not always the case! Consider the following statement:</p>
<div><pre><code><span>UPDATE</span> accounts
<span>SET</span> balance <span>=</span> balance <span>*</span> <span>1.1</span>
<span>WHERE</span> acctnum <span>in</span> (
    <span>SELECT</span> acctnum <span>from</span> accounts <span>where</span> balance <span>&gt;</span> <span>1000</span>)
</code></pre></div>
<p>Here the <code>SELECT</code> will run first and return all rows with balance over 1000. Then the updates run, a row at a time. Suppose that while it is iterating, another session updates account 12345 and commits:</p>
<div><pre><code><span>UPDATE</span> accounts <span>set</span> balance <span>=</span> <span>500</span> <span>where</span> acctnum <span>=</span> <span>12345</span>;
</code></pre></div>
<p>When the first UPDATE gets to account 12345, it will see the new value, and again - account 12345 will get 10% bonus on an account with a balance of 500, which is not what we wanted.</p>
<p>To prevent changes on rows you just read without going to a higher isolation level, you may need to lock the rows while selecting:</p>
<div><pre><code><span>UPDATE</span> accounts
<span>SET</span> balance <span>=</span> balance <span>*</span> <span>1.1</span>
<span>WHERE</span> acctnum <span>in</span> (
    <span>SELECT</span> acctnum <span>from</span> accounts <span>where</span> balance <span>&gt;</span> <span>1000</span> <span>FOR</span> <span>UPDATE</span>)
</code></pre></div>
<p><code>SELECT…. FOR UPDATE</code> locks the rows that it selects. In this example, other sessions won't be able to update the balance in any account while the update is in progress, preventing the inconsistency.</p>
<p>A classic pattern for implementing job queues with Postgres uses <code>FOR UPDATE</code> locks to prevent multiple workers from picking the same job:</p>
<div><pre><code><span>BEGIN</span>;
	<span>SELECT</span> job <span>FROM</span> job_queue <span>FOR</span> <span>UPDATE</span> <span>SKIP</span> LOCKED LIMIT <span>1</span>
    <span>-- do stuff for the job</span>
    <span>DELETE</span> job <span>from</span> job_queue
<span>COMMIT</span>
</code></pre></div>
<p>Here, you pick a job from the queue and lock it for the duration of the transaction. When you are done performing the job, you delete it from the queue and commit. Other processes can use the same logic to pick jobs, while skipping ones that are already in progress. If you run this code in a loop, each <code>SELECT</code> will see which jobs when the select executes - since <code>read committed</code> isolation level allows you to see changes that were committed before the start of the transaction. But the <code>FOR UPDATE</code> lock will prevent other processes from picking the same job.</p>
<p>Read committed is the default isolation level in postgres and as a result it is the most commonly used one. It is quite acceptable to use it, as long as you understand the “write-after-read” anti-pattern and handle it with well-placed locks.</p>
<h2 id="phantom-reads">Phantom Reads</h2>
<p>With the non-repeatable reads anomaly, you can see changes to rows that existed when your transaction began. In contrast, with the phantom reads anomaly, new rows which did not exist earlier suddenly appear in the middle of a transaction.</p>
<table><thead><tr><th>Session A</th><th>Session B</th></tr></thead><tbody><tr><td><pre>BEGIN;</pre></td><td><pre>BEGIN;</pre></td></tr><tr><td><pre>UPDATE accounts set balance = 500
where acctnum = 789;</pre></td><td></td></tr><tr><td></td><td><pre>SELECT * from accounts where balance &gt; 0;</pre></td></tr><tr><td><pre><p>INSERT INTO accounts (acctnum, balance)
values (12345, 100);</p></pre></td><td></td></tr><tr><td><pre>COMMIT;</pre></td><td></td></tr><tr><td></td><td><pre>SELECT * from accounts where balance &gt; 0;</pre></td></tr></tbody></table>
<p>In isolation level “repeatable reads” both queries in session B will show the same balance for account 789. Because the <code>update</code> that was done in session A will not be visible to session B. However, the second query will also include account 12345 that was created by session A. This is a new row suddenly appeared in the middle of a transaction. This means that session B will produce an inconsistent report - both because it has two queries that returned different results, and because the second query shows the data that session A inserted, but not the data it updated.</p>
<h2 id="problems-with-the-sql92-isolation-levels">Problems with the SQL92 isolation levels</h2>
<p>The SQL92 isolation levels have a lot going for them - they are standard, they are not too challenging to understand, and they give developers practical tools to make good decisions in their design. No wonder they are still in use today. But they are also 30 years old and in some aspects, they show their age.</p>
<h3 id="some-isolation-levels-became-obsolete">Some isolation levels became obsolete</h3>
<p>Lets think about “Repeatable Reads” level for a second. Doesn't it look a bit weird? Transactions see a consistent view of the data that already exists, but new data just sort of shows up there. Why have a separate level just for this situation? The reason it exists is because when transaction isolation levels were introduced to SQL 92 standard, “repeatable reads” was the best level of isolation that many DBs could practically support.</p>
<p>These DBs implemented transaction isolation via shared locks. So when we did <code>select * from accounts</code> for the first time in a transaction, it took a lock on the rows we read. This doesn't block readers, but it blocked writers and delayed all updates until the transaction committed. This guaranteed that the data won't change while my transaction executes and the second time the same query ran, it will get the same values. Of course, you can't lock rows that don't exist yet. Therefore new rows will still show up. Leading to phantom reads.</p>
<p>As you can imagine, 30 years later, databases got better. <a href="https://en.wikipedia.org/wiki/Multiversion_concurrency_control">Multi-version concurrency control, MVCC</a>, became widespread and the most common implementation of transaction isolation in relational databases. Including Postgres. MVCC doesn't lock rows. What it does instead is keep multiple versions of each row (hence the name), and use those versions to isolate transactions. We'll discuss Postgres's MVCC implementation and how it impacted the isolation levels in the next section.</p>
<h3 id="new-anomalies-were-discovered">New anomalies were discovered</h3>
<p>OK, so some of the isolation levels don't make sense any more, but at least we have Serializable which is defined as a logical ideal, and not based on implementation concerns. And if we run our DB in Serializable level, anomalies can't happen. Right?</p>
<p><img src="https://www.thenile.dev/blog/2023-12-18-transaction-isolation/anomalies-right.png" alt="Meme with dialog. &quot;We use transaction isolation serializable, so anomalies won't happen, right? right?”"></p>
<p>It turned out that defining a perfect state and then defining some states where certain anomalies can happen has this fundamental problem: There may be anomalies you didn't think of. So, only three years after the SQL92 standard came out, <a href="https://arxiv.org/pdf/cs/0701157.pdf">Microsoft published a paper with a whole list of new anomalies</a>. And because they weren't specified in the standard as something that is prevented in Serializable level, they did in fact happen.</p>
<p>The result of the paper is an extension of the SQL92 isolation levels and anomalies with a lot more anomalies: Lost updates, dirty writes, write skews, read skews, fuzzy reads. And new isolation levels that handle these scenarios.</p>
<p><img src="https://www.thenile.dev/blog/2023-12-18-transaction-isolation/isolation.png" alt="Table with isolation levels and anomalies from Microsoft's 1995 paper"></p>
<p>This paper, coming out after many relational databases implemented SQL92 isolation levels, lead to the rather confusing state of things that we have to this day. Different databases support different isolation levels, and the same isolation level can mean different things in different databases.</p>
<h2 id="isolation-levels-in-postgres">Isolation levels in Postgres</h2>
<p>Postgres handles the new anomalies without adding additional levels. It documented its behavior using the standard table with few notes:</p>
<table><thead><tr><th>Isolation Level</th><th>Dirty Reads</th><th>Non-repeatable Reads</th><th>Phantom Reads</th><th>Serialization Anomalies</th></tr></thead><tbody><tr><td>Read Uncommitted</td><td>Allowed, but not in Postgres</td><td>Possible</td><td>Possible</td><td>Possible</td></tr><tr><td>Read Committed</td><td>Not Possible</td><td>Possible</td><td>Possible</td><td>Possible</td></tr><tr><td>Repeatable Reads</td><td>Not Possible</td><td>Not Possible</td><td>Allowed, but not in Postgres</td><td>Possible</td></tr><tr><td>Serializable</td><td>Not Possible</td><td>Not Possible</td><td>Not Possible</td><td>Not Possible</td></tr></tbody></table>
<p>As you can see, Postgres “repeatable reads” is equivalent to the SQL92 “serializable”. In fact, the current “repeatable reads” behavior was the behavior of “serializable” in Postgres 9.1 and earlier. This level is also called Snapshot Isolation (SI) or even “serializable” in other databases.</p>
<p>Postgres's serializable (also known as Serializable Snapshot Isolation (SSI)) guarantees the “ideal” which is the emulation of serial execution of all committed transactions. It should be resilient to all known anomalies.</p>
<h3 id="mvcc-and-isolation-in-postgres">MVCC and isolation in Postgres</h3>
<p>As we mentioned earlier, Postgres, like most modern databases, implements MVCC. In Postgres's MVCC implementation, when a transaction first writes to the database, it is assigned a sequence number called transaction ID or XID. When the transaction modifies rows, the original version of the row is preserved and a new version is added with this sequence number (you can see the current sequence if you run <code>select txid_current();</code>). Each transaction only sees the newest version of each row that is earlier than its transaction ID.</p>
<p>Let's take another look at one of our examples, and consider which transactions are visible to each session (note: I'm making some assumptions and removing some details for simplicity, see references for more detailed explanations):</p>
<table><thead><tr><th>Session A</th><th>Session B</th></tr></thead><tbody><tr><td><pre>BEGIN;</pre></td><td><pre>BEGIN;</pre></td></tr><tr><td><pre>UPDATE accounts set balance = 500
where acctnum = 789;</pre></td><td></td></tr><tr><td></td><td><pre>SELECT * from accounts where balance &gt; 0;</pre></td></tr><tr><td><pre><p>INSERT INTO accounts (acctnum, balance)
values (12345, 100);</p></pre></td><td></td></tr><tr><td><pre>COMMIT;</pre></td><td></td></tr><tr><td></td><td><pre>SELECT * from accounts where balance &gt; 0;</pre></td></tr></tbody></table>
<p>When session A and session B start their transactions, they both “take a snapshot” - record the highest and lowest IDs of currently active transactions (you can try this yourself with <code>select * from pg_current_snapshot();</code>). Let's say that they both see 190 as the lowest active XID. This means that transactions with higher XID did not commit yet.</p>
<p>In “repeatable read” and “serializable” isolation levels, both select statements in Session B will only show the data as it was committed when the transaction began - version 190 or lower. If you peeked at the Postgres buffer cache when both transactions started, but before any changes were made, you'd see something like this:</p>
<table><thead><tr><th>t_xmin</th><th>t_xmax</th><th>acctnum</th><th>balance</th></tr></thead><tbody><tr><td>125</td><td>0</td><td>789</td><td>3</td></tr></tbody></table>
<p><code>t_xmin</code> represents the xid of the transaction that created this row. And this row will be visible to both transactions since <code>t_xmin</code> is 125 and lower than 190.
When Session A performs its first update, it will be assigned its own XID - lets say 201. Both the new version of account 789 and the new account 12345 will have 201 as their new version. So if you peeked in Postgres memory after session A commits, you'd see something like:</p>
<table><thead><tr><th>t_xmin</th><th>t_xmax</th><th>acctnum</th><th>balance</th></tr></thead><tbody><tr><td>125</td><td>0</td><td>789</td><td>3</td></tr><tr><td>201</td><td>0</td><td>789</td><td>500</td></tr><tr><td>201</td><td>0</td><td>12345</td><td>100</td></tr></tbody></table>
<p>You can see both the new version of account 789, and the newly inserted account 12345. Since they both have t_xmin 201, which is higher than 190, session B is not going to see either of the new versions. Its snapshot only shows the original version of account 789.</p>
<p>As you can see, using MVCC snapshots for transaction isolations means that the same mechanism that hides new versions of existing rows also hides new rows. Neither will show up in snapshots that were taken before those changes were made.
A transaction with “read committed” isolation level will simply take a new snapshot at the start of each query and when conflicts are encountered - which means that each query will be able to see data from transactions that were already committed. Even if they did not commit at the start of the session.</p>
<p>Postgres' infamous vacuum process is responsible for regular maintenance and cleanup of all the different copies of each row: Getting rid of deleted rows that are no longer used and also performing a process known as “freezing”. Freezing process take rows that were last modified by the oldest transactions and indicating that they should always be visible. This process frees up these transaction IDs for reuse - very important since Postgres transaction IDs are limited to 32bit and you can't use more transaction IDs at the same time. This is why long running transactions and very frequent updates/inserts/deletes can cause issues with the vacuum process.</p>
<h3 id="performance-implication-of-serializable-in-postgres">Performance implication of serializable in Postgres</h3>
<p>In Postgres, “repeatable reads” level and “serializable” levels don't require additional locking since they are based on MVCC (implicit and explicit locks held by transaction in progress still exist, just like in "read committed"). Note that Postgres still has to track the rows that are modified by each transaction, as we'll see below, and it describes this tracking as “locks” but those are non-blocking and used for tracking and conflict detection.</p>
<p>Even without locks, serializable (and even repeatable reads) isolation can have performance implications for highly concurrent workloads. This is because transactions in both repeatable reads and serializable levels are more likely to fail and roll back due to serialization errors.</p>
<p>What are serialization errors? They look something like this: <code>ERROR: could not serialize access due to concurrent update</code> and they happen in a scenario like this:</p>
<table><thead><tr><th>Session A</th><th>Session B</th></tr></thead><tbody><tr><td><pre>BEGIN;</pre></td><td><pre>BEGIN;</pre></td></tr><tr><td><pre>UPDATE accounts set balance = 500
where acctnum = 789;</pre></td><td></td></tr><tr><td><pre>COMMIT;</pre></td><td></td></tr><tr><td></td><td><pre><p>UPDATE accounts set balance = balance+200
where acctnum = 789;</p></pre></td></tr></tbody></table>
<p>The transaction in session B is attempting to modify a value that session A modified and committed after session B started. Which means that session B is trying to update a value without being able to see its latest version. Which can lead to a state that would never have happened if the transactions ran serially (this anomaly is called a lost write). Therefore Session B will get an error, the transaction will roll back, and Session B can try again.</p>
<p>Worth noting that in this simple scenario, "read committed" will actually work correctly. Session A will lock the row and session B will wait until the lock is released, then see the new value and update it. And as we've seen, "read committed" will require explicit locks for correctness in more complex situations.</p>
<p>In a system with high concurrency and a lot of updates, the serialization errors in "repeatable reads" and "serializable" levels can lead to a lot of retries, which obviously have a negative effect on performance and require dealing with retry logic in the application. This is performance overhead that exists in addition to the extra checks and monitoring that PG needs to run in order to catch these issues, especially in serializable isolation.</p>
<p>The performance tradeoffs between “read committed”, where in order to maintain consistency you rely on locks - both explicit and implicit, and “repeatable reads” where you rely on failing conflicting transactions and retrying, are specific to each application workload. The advantage of “read committed” is that you can reduce the level of consistency in favor of better performance - the disadvantage is that you may reduce the level of consistency unintentionally and lead to incorrect results.</p>
<h3 id="transaction-isolation-testing-in-postgres">Transaction Isolation Testing in Postgres</h3>
<p>As you already noticed, the Postgres developer community takes transaction isolation very seriously and hold themselves to a very high bar. Part of it is their isolation testing suite. It uses a method that IMO should be a lot more common in systems testing.
You can find the <a href="https://github.com/postgres/postgres/tree/master/src/test/isolation">code for the test suite in github</a> and the README explains it well.</p>
<p>The core idea is simple and brilliant, like many things in Postgres:
The testers define different scenarios, just like the ones we demonstrated above. Session A does <code>update</code> and then <code>commit</code>, Session B does <code>select</code> and then <code>update</code>. You also specify the result you'd expect after all sessions and all transactions committed. The test framework then takes all the sessions and runs all possible ways these could interleave. One such run can be “A updates, then B selects, then A commits, then B updates”. Another can be “B selects, then A updates, then B updates, then A commits”. It then checks that the key invariants like “account 1234 has a balance of 500” are preserved in all permutations.</p>
<p>While PG isn't single threaded and there are other background processes that run, it is very close to deterministic simulation testing because the scenarios themselves with all the different combinations are serialized.</p>
<p>This kind of test framework means that when concurrency bugs are discovered and fixed, it is very easy to add a test with the exact scenario that uncovered them and to be sure it will be covered in the test.</p>
<h2 id="to-sum-things-up">To sum things up</h2>
<p>Hopefully this post didn't leave you more confused than you were at the beginning.
There is a lot of complexity when it comes to the behavior of concurrent transactions in different isolation levels. Serializable guarantees relatively easy reasoning - just imagine that all queries run serially, one after another. But as you saw, the main drawback is the possibility of rollbacks due to conflicts.
Other levels require deeper understanding of all the anomalies. This understanding allows you to know whether the behavior provided in these isolation levels matches the business logic that you are trying to implement. It will also allow you to make good performance tradeoffs.</p>
<p>Since it is still a bit complex to reason about the isolation level, one way to simplify your system is to try and avoid complex multi-step transactions where possible. Normalized data structures help, as do database constraints. Using SQL to try and implement atomic units of business logic in single statements can also help in avoiding complex transactional behaviors. And of course, using techniques such as deterministic simulation testing can help catch and detect cases where concurrent transactions lead to incorrect results.</p>
<p>Last but not least, huge thanks to <a href="https://twitter.com/alexbdebrie">Alex DeBrie</a>, <a href="https://twitter.com/FranckPachot">Franck Pachot</a>, <a href="https://twitter.com/lawrjones">Lawrence Jones</a> and <a href="https://twitter.com/gunnarmorling">Gunnar Morling</a> who reviewed early drafts of this blog, caught mistakes and improved the explanations. The remaining mistakes and confusing explanations are all mine.</p>
<h2 id="additional-references">Additional References:</h2>
<ul>
<li><a href="https://www.postgresql.org/docs/current/transaction-iso.html">Transaction isolation in Postgres' documentation</a></li>
<li><a href="https://www.interdb.jp/pg/pgsql05.html#_5.10.1">Internals of Postgres MVCC, in much greater detail</a></li>
<li><a href="https://blog.lawrencejones.dev/isolation-levels/">Shorter and clearer blog on isolation in Postgres from Lawrence Jones</a></li>
<li><a href="https://brandur.org/postgres-atomicity">Blog post explaining atomicity, isolation and MVCC in Postgres with snippets from Postgres source code</a></li>
<li><a href="https://postgrespro.com/blog/pgsql/5967856">Detailed blog showing various anomalies in postgres</a></li>
<li><a href="https://dev.to/aws-heroes/read-committed-anomalies-in-postgresql-1ieg">Blog by Franck Pachot showing unexpected issues with non-repeatable reads in postgres</a></li>
<li><a href="https://www.postgresql.org/files/developer/concurrency.pdf">Great talk on concurrency and anomalies in Postgres</a></li>
<li><a href="https://www.interdb.jp/pg/pgsql06.html">Internals of the vacuum process</a></li>
<li><a href="https://courses.cs.washington.edu/courses/cse444/08au/544M/READING-LIST/fekete-sigmod2008.pdf">The famous Serializable Snapshot Isolation (SSI) paper</a></li>
<li><a href="https://drkp.net/papers/ssi-vldb12.pdf">Serializable Snapshot Isolation in Postgres</a></li>
<li><a href="https://twitter.com/gunnarmorling/status/1621265967543099393">Great thread on monitoring the vacuum process</a></li>
<li><a href="https://arxiv.org/pdf/cs/0701157.pdf">Microsoft’s famous critique of SQL92 transaction isolation levels</a></li>
<li><a href="https://www.cs.umb.edu/~poneil/ROAnom.pdf">Paper with even more anomalies</a></li>
<li><a href="http://www.bailis.org/papers/acidrain-sigmod2017.pdf">How transaction anomalies can be used to exploit web applications</a></li>
<li><a href="https://github.com/ept/hermitage">Project with tests that check isolation levels in different databases</a></li>
</ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Paged Out Issue #3 (115 pts)]]></title>
            <link>https://pagedout.institute/?page=issues.php</link>
            <guid>38684368</guid>
            <pubDate>Mon, 18 Dec 2023 16:09:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pagedout.institute/?page=issues.php">https://pagedout.institute/?page=issues.php</a>, See on <a href="https://news.ycombinator.com/item?id=38684368">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <h3>What is Paged Out!?</h3>
        <p><b>Paged Out! is a free experimental (one article == one page) technical magazine</b> about programming
            (especially programming tricks!), <a href="https://en.wikipedia.org/wiki/Hacker">hacking</a>, <a href="https://en.wikipedia.org/wiki/Security_hacker">security hacking</a>, retro computers, modern
            computers, electronics, demoscene, and other similar topics.</p>
        <p>It's <b>made by the community for the community</b>. And it's not-for-profit (though in time, we hope it will be self-sustained) - this means that the issues will always be free to download, share, and print.</p>
        <p>If you're interested in more details, check our our <a href="https://pagedout.institute/?page=faq.php">FAQ</a> and <a href="https://pagedout.institute/?page=about.php">About</a> pages!</p>

        <p>Like what you see? See how <a href="https://pagedout.institute/?page=helpout.php">you can help us succeed</a>!</p>

        <h4>Download Issues</h4>
        <div>
                <p><b>Issue #3</b>: The resurrected Paged Out!</p>
                
                <p><b>Note</b>: This is a "beta build" of the PDF, i.e. we will be re-publishing it with various improvements multiple times. What's missing:</p>
                <ul>
                    <li>PDFs for printing (A4+bleed) - we still need to fix the pipeline around this; will come out later</li>
                </ul>
            </div>


        <div>
            <p><a href="https://pagedout.institute/download/PagedOut_002_beta2.pdf"><img src="https://pagedout.institute/static/img/issue_2_cover_small.png" alt="Cover image of Paged Out! issue 2 depicting a cyborg skull with violet-glowing electronic parts and blue-glowing eyes, with a lot of wires going out of - or into - the skull from the blackness of the background. In the top left corner, there is the magazine's logo - an icon of an old computer and text saying Paged Out! in capital letters."></a><br>
                Cover art by Vlad Gradobyk (<a href="https://instagram.com/vladgradobyk">Insta</a>, <a href="https://facebook.com/gradobyk.graphic">FB</a>).<br>
            </p>
            <div>
                <p><b>Issue #2</b>: The second Paged Out!</p>
                
                <p><b>Note</b>: This is a "beta 2 build" of the PDF, i.e. we will be re-publishing it with various improvements multiple times. What's missing:</p>
                <ul>
                    <li>PDFs for printing (A4+bleed, ?US Letter+bleed?) - we need to fix something, but it's almost
                        there.
                    </li>
                </ul>
            </div>
        </div>

        <div>
                <p><b>Issue #1</b>: The first Paged Out! issue has arrived!</p>
                
                <p><b>Note</b>: This is a "beta 1 build" of the PDF, i.e. we will be re-publishing it with various improvements multiple times. What's missing:</p>
                <ul>
                    <li>PDFs for printing (A4+bleed, ?US Letter+bleed?) - we need to fix something, but it's almost
                        there.
                    </li>
                </ul>
            </div>

        <p>Additionally, here's another Paged Out! wallpaper by <a href="https://www.deviantart.com/refiend">ReFiend</a>:</p>
                <p><a href="https://pagedout.institute/download/PagedOut_RC_wallpaper.jpg"><img src="https://pagedout.institute/static/img/t_PagedOut_RC_wallpaper.jpg" alt="Wallpaper miniature"></a></p>

        <h4>Next issue</h4>
        <p>If you like our work, <b><a href="https://pagedout.institute/?page=cfp.php">how about writing an article for Paged Out!</a>?</b> It's
            only one page after all - easy. ;)</p>
        <p>
            <b>Next issue progress tracker</b> (unit of measurement: article count):<br>
        </p>
        <div id="article-counters">
                <p>Ready (50)</p>
                <p>In review (0)</p>
                <p>50</p>
                <p>100</p>
                <p><span>("we got enough to finalize the issue!" zone)</span>
                </p>
            </div>
        <br>

        

        <h4>Notify me when the new issue is out!</h4>
        <p>Sure! There are a couple of ways to get notified when the issue will be out:</p>
        <ul>
            <li>You can subscribe to this newsletter <b>e-mail</b> group: <a href="https://groups.google.com/forum/#!forum/pagedout-notifications">pagedout-notifications
                (googlegroups.com)</a> (be sure to select you want e-mail notifications about every message when
                subscribing).
            </li>
            <li>Or you can use the <b>RSS</b> / <b>Atom</b>:
               <a href="https://pagedout.institute/rss.xml">RSS</a>,
               <a href="https://pagedout.institute/atom.xml">Atom</a>.
            </li>
        </ul>
        <p>We will only send e-mails to this group about new Paged Out! issues (both the free electronic ones and
            special issues
            if we ever get to that). No spam will be sent there and (if you subscribe to the group) your e-mail will be
            visible
            only to group owners.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Facebook Is Being Overrun with Stolen, AI-Gen Images That People Think Are Real (237 pts)]]></title>
            <link>https://www.404media.co/facebook-is-being-overrun-with-stolen-ai-generated-images-that-people-think-are-real/</link>
            <guid>38684309</guid>
            <pubDate>Mon, 18 Dec 2023 16:05:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.404media.co/facebook-is-being-overrun-with-stolen-ai-generated-images-that-people-think-are-real/">https://www.404media.co/facebook-is-being-overrun-with-stolen-ai-generated-images-that-people-think-are-real/</a>, See on <a href="https://news.ycombinator.com/item?id=38684309">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article>
          <div>
              
<!--kg-card-begin: html-->

<!--kg-card-end: html-->

<!--kg-card-begin: html-->
  <div>
    <h5>Subscribe</h5>
    <div>
      <p>Join the newsletter to get the latest updates.</p>
      <form data-members-form="subscribe">
        
        
        <div>
          
          <p>
            Great! Check your inbox and click the link.
          </p>
        </div>
        <div>
          
          <p>
            Please enter a valid email address.
          </p>
        </div>
      </form>
    </div>
  </div>

<!--kg-card-end: html-->
<p>In the photo, a man kneels in an outdoor sawmill next to his painstaking work: An intricate wooden carving of his bulldog, which he proudly gazes at. “Made it with my own hands,” the Facebook caption reads. <a href="https://www.facebook.com/photo.php?fbid=1035803147752348&amp;set=pb.100039680180374.-2207520000&amp;type=3" rel="noreferrer">The image has</a> 1,300 likes, 405 comments, and 47 shares. “Beautiful work of art,” one of the comments reads. “You have an AMAZING talent!,” another says. “Nice work, love it &lt;3!” “Awesome work keep it up.”&nbsp;  </p><p>This incredible work of art, a “wooden monument to my dog,” has been posted dozens of times across dozens of engagement bait Facebook pages. But every time, the man and the dog are different. Sometimes the dog is hyperrealistic. Sometimes the bulldog is a German Shepherd. Sometimes the man’s hair is slicked back, sometimes it stands up. Sometimes the man sits on the other side of the dog. Sometimes the man looks Latino, other times he looks white; clearly, it is a different man, and a different dog, in most of the images.&nbsp;</p><figure><div><div><p><img src="https://www.404media.co/content/images/2023/12/Screenshot-2023-12-16-at-7.04.02-PM.png" width="1212" height="1598" loading="lazy" alt="" srcset="https://www.404media.co/content/images/size/w600/2023/12/Screenshot-2023-12-16-at-7.04.02-PM.png 600w, https://www.404media.co/content/images/size/w1000/2023/12/Screenshot-2023-12-16-at-7.04.02-PM.png 1000w, https://www.404media.co/content/images/2023/12/Screenshot-2023-12-16-at-7.04.02-PM.png 1212w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.404media.co/content/images/2023/12/Screenshot-2023-12-16-at-7.04.09-PM.png" width="1258" height="1592" loading="lazy" alt="" srcset="https://www.404media.co/content/images/size/w600/2023/12/Screenshot-2023-12-16-at-7.04.09-PM.png 600w, https://www.404media.co/content/images/size/w1000/2023/12/Screenshot-2023-12-16-at-7.04.09-PM.png 1000w, https://www.404media.co/content/images/2023/12/Screenshot-2023-12-16-at-7.04.09-PM.png 1258w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.404media.co/content/images/2023/12/Screenshot-2023-12-16-at-7.06.46-PM.png" width="1198" height="1572" loading="lazy" alt="" srcset="https://www.404media.co/content/images/size/w600/2023/12/Screenshot-2023-12-16-at-7.06.46-PM.png 600w, https://www.404media.co/content/images/size/w1000/2023/12/Screenshot-2023-12-16-at-7.06.46-PM.png 1000w, https://www.404media.co/content/images/2023/12/Screenshot-2023-12-16-at-7.06.46-PM.png 1198w" sizes="(min-width: 720px) 720px"></p></div><div><p><img src="https://www.404media.co/content/images/2023/12/Screenshot-2023-12-16-at-7.06.55-PM.png" width="1212" height="1602" loading="lazy" alt="" srcset="https://www.404media.co/content/images/size/w600/2023/12/Screenshot-2023-12-16-at-7.06.55-PM.png 600w, https://www.404media.co/content/images/size/w1000/2023/12/Screenshot-2023-12-16-at-7.06.55-PM.png 1000w, https://www.404media.co/content/images/2023/12/Screenshot-2023-12-16-at-7.06.55-PM.png 1212w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.404media.co/content/images/2023/12/Screenshot-2023-12-16-at-7.07.07-PM.png" width="1204" height="1602" loading="lazy" alt="" srcset="https://www.404media.co/content/images/size/w600/2023/12/Screenshot-2023-12-16-at-7.07.07-PM.png 600w, https://www.404media.co/content/images/size/w1000/2023/12/Screenshot-2023-12-16-at-7.07.07-PM.png 1000w, https://www.404media.co/content/images/2023/12/Screenshot-2023-12-16-at-7.07.07-PM.png 1204w" sizes="(min-width: 720px) 720px"></p></div><div><p><img src="https://www.404media.co/content/images/2023/12/Screenshot-2023-12-16-at-7.07.14-PM.png" width="1210" height="1602" loading="lazy" alt="" srcset="https://www.404media.co/content/images/size/w600/2023/12/Screenshot-2023-12-16-at-7.07.14-PM.png 600w, https://www.404media.co/content/images/size/w1000/2023/12/Screenshot-2023-12-16-at-7.07.14-PM.png 1000w, https://www.404media.co/content/images/2023/12/Screenshot-2023-12-16-at-7.07.14-PM.png 1210w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.404media.co/content/images/2023/12/Screenshot-2023-12-16-at-7.08.08-PM.png" width="1512" height="1588" loading="lazy" alt="" srcset="https://www.404media.co/content/images/size/w600/2023/12/Screenshot-2023-12-16-at-7.08.08-PM.png 600w, https://www.404media.co/content/images/size/w1000/2023/12/Screenshot-2023-12-16-at-7.08.08-PM.png 1000w, https://www.404media.co/content/images/2023/12/Screenshot-2023-12-16-at-7.08.08-PM.png 1512w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption><p><span>All of these images are AI-generated, and stolen from an artist named Michael Jones.</span></p></figcaption></figure><figure><img src="https://lh7-us.googleusercontent.com/w3sJofxBvHvAutTY7HpJM3-cplRD7pW70YmFrtRaAyZRHxKHjmmksQLwqoKi5QpvJvxCAP83N6CouI8BBIEx6eptOd79LvA-qAsLuY6yMlMHqzCA_KLvZcMWcote_Hhkj-32YVy8hDAHI7YSj6M8SLg" alt="" loading="lazy" width="624" height="359"><figcaption><span>One of the images has more than a million likes.</span></figcaption></figure><p>Depending on the image, it is obvious, to me, that the man and the dog are not real. The dog often looks weirdly polygonal, or like some wood carving filter has been applied to an image of a real dog. Sometimes the dog’s ear has obvious artifacts associated with AI-generated images. Other times, it’s the man who looks fake. Variations of this picture are being posted all over Facebook by a series of gigantic meme pages with names like “Go Story,” “Amazing World,” “Did you know?” “Follow me,” “Avokaddo,” and so on.&nbsp;</p><p>Universally, the comment sections of these pages feature hundreds of people who have no idea that these are AI-generated and are truly inspired by the dog carving. <a href="https://www.facebook.com/photo.php?fbid=1035803147752348&amp;set=pb.100039680180374.-2207520000&amp;type=3" rel="noreferrer">A version of this image posted on Dogs 4 life has 1 million likes</a>, 39,000 comments, and 17,000 shares. The Dogs 4 life account has spammed links to buy cheap, dog-branded stuff to the top of the comments section.&nbsp;</p><p>In many ways, this is a tale as old as time: people lie and steal content online in exchange for likes, influence and money all the time. But the spread of this type of content on Facebook over the last several months has shown that the once-prophesized future where cheap, AI-generated trash content floods out the hard work of real humans is already here, and is already taking over Facebook. It also shows Facebook is doing essentially nothing to help its users decipher real content from AI-generated content masquerading as real content, and that huge masses of Facebook users are completely unprepared for our AI-generated future.&nbsp;</p><p>The dog and the carving were real, at one point. The real German Shepherd carving was made by a UK-based <a href="https://www.michaeljonescs.com/?ref=404media.co" rel="noreferrer">professional chainsaw sculptor</a> named Michael Jones, who <a href="https://www.facebook.com/photo/?fbid=1011303903567784&amp;set=pb.100040645523359.-2207520000"><u>detailed his work</u></a> in a series of videos and photos posted over the course of the summer. Jones’ work has since been stolen and turned into endless variations. Those images are then turned into endless inspiration bait by spammy Facebook pages that are presumably looking to monetize the stolen work of artists like Jones.&nbsp;</p><figure><img src="https://lh7-us.googleusercontent.com/70hfTrA3I1ZBGEmSzOB7lStDrWzj86fgC564mNmbkMInm0zCFdZmG3MDJ85HvoSNFJimt_W3adI2rLUDnDLcT7DPo-cCuD09WOwbBi4PzpEsm602vHWm0MlLN2BzcV7-e84CvoU-VuEf36QboOfskLo" alt="" loading="lazy" width="624" height="345"><figcaption><span>Jones' real carving</span></figcaption></figure><figure><img src="https://www.404media.co/content/images/2023/12/Screenshot-2023-12-16-at-7.12.29-PM.png" alt="" loading="lazy" width="1056" height="1344" srcset="https://www.404media.co/content/images/size/w600/2023/12/Screenshot-2023-12-16-at-7.12.29-PM.png 600w, https://www.404media.co/content/images/size/w1000/2023/12/Screenshot-2023-12-16-at-7.12.29-PM.png 1000w, https://www.404media.co/content/images/2023/12/Screenshot-2023-12-16-at-7.12.29-PM.png 1056w" sizes="(min-width: 720px) 720px"><figcaption><span>Another of Jones' real carvings</span></figcaption></figure><figure><img src="https://www.404media.co/content/images/2023/12/Screenshot-2023-12-16-at-7.13.34-PM.png" alt="" loading="lazy" width="1326" height="1344" srcset="https://www.404media.co/content/images/size/w600/2023/12/Screenshot-2023-12-16-at-7.13.34-PM.png 600w, https://www.404media.co/content/images/size/w1000/2023/12/Screenshot-2023-12-16-at-7.13.34-PM.png 1000w, https://www.404media.co/content/images/2023/12/Screenshot-2023-12-16-at-7.13.34-PM.png 1326w" sizes="(min-width: 720px) 720px"><figcaption><span>Another of Jones' real carvings</span></figcaption></figure><p>“This is something that is a huge issue for us and other carvers all over the world who are sadly missing out on the rightful credit exposure to their work,” Jones told me, “as well as setting unrealistic expectations when it comes to creating chainsaw carving art or any art for that matter!”</p><p>The strategy relies on “image-to-image” generative AI, which takes an input image and generates a new one based on that input. “Every time you generate an image, you get something completely different because it’s randomly seeded, and [the model] is looking for semantic consistency,” Hany Farid, a professor at the University of California, Berkeley who specializes in AI disinformation and deepfakes, told me. Different generators let a user select the “strength” of the new image, which is a number between zero and one “where zero essentially means ‘ignore this image,’ and one says ‘give me this image exactly back,’” Farid said.&nbsp;</p><figure><div><p><img src="https://www.404media.co/content/images/2023/12/Screen-Shot-2023-12-18-at-6.16.27-AM.png" width="564" height="1236" loading="lazy" alt=""></p><p><img src="https://www.404media.co/content/images/2023/12/Screen-Shot-2023-12-18-at-6.16.37-AM.png" width="554" height="1152" loading="lazy" alt=""></p></div><figcaption><p><span>A very standard comment section on one of these images.</span></p></figcaption></figure><p>I learned about the dog carvings from Brian Penny, a freelance ghostwriter, who shared Jones’s original image and copies of it on Threads.&nbsp;</p><p>“All these people are engagement farming off really shitty versions of his work and it’s giving his art a bad name,” Penny told me. “He’s having to compete against these versions of his work and it could easily destroy his business.”&nbsp;</p><p>Penny told me that a group of AI enthusiasts, skeptics, researchers, and interested parties had been researching and documenting the fact that stolen, AI-generated clones of viral images are taking over Facebook with impunity, where unaware boomers click “like,” “share,” and say things like “wow, incredible,” all day every day.&nbsp;</p><h3 id="%E2%80%9Cstop-the-exploitation-of-ai-generated-children%E2%80%9D"><strong>“STOP THE EXPLOITATION OF AI-GENERATED CHILDREN”</strong></h3><p>Penny invited me to the Facebook group “Um, isn’t that AI?,” which has 2,700 members documenting Facebook posts containing obviously AI-generated content that is going viral on Facebook (and which are also designed to trick users into thinking they are real). The first thing I saw when <a href="https://www.facebook.com/photo/?fbid=306337185700005&amp;set=a.106940565639669"><u>I joined was this image</u></a>, posted on a page called “Happy day,” which has 261 likes and 71 comments like “This is really beautiful. You are really talented.”</p><figure><img src="https://lh7-us.googleusercontent.com/YQx_Qe5PKx7x9iQ6WVNvfBHIvEYMpB21TGHdRvB80ZnQzvzd5zAXC99l8O_9x3xIKIoewwc9B_tib4vBS7Dv64YHHzMNuL6RqjZt-2R-dMfJUQ8ox5BX4V8z_FQBq42jV4X6Bi6fMlGMct5_mC9c1bY" alt="" loading="lazy" width="624" height="377"></figure><p>If you look at this image, you will notice that the bear is standing on, essentially, an amorphous blob that seems to have a human foot. If you look slightly more closely, you will see two impossibly tiny fake children playing in the dirt.</p><p>The next image I saw was this meme, which made me laugh: “STOP THE EXPLOITATION OF A.I. GENERATED CHILDREN!,” it reads. “Little Juan is forced to carve wooden dogs for FACEBOOK SCAMMERS, and they won’t even share the ‘likes’ with him. By commenting on this page you are contributing to the ongoing abuse of millions of artificially generated children from all over the world, or you could just be a target for future scams. LEARN TO RECOGNIZE AI GENERATED IMAGERY.”&nbsp;</p><figure><img src="https://www.404media.co/content/images/2023/12/Screenshot-2023-12-16-at-7.18.42-PM.png" alt="" loading="lazy" width="812" height="1652" srcset="https://www.404media.co/content/images/size/w600/2023/12/Screenshot-2023-12-16-at-7.18.42-PM.png 600w, https://www.404media.co/content/images/2023/12/Screenshot-2023-12-16-at-7.18.42-PM.png 812w" sizes="(min-width: 720px) 720px"></figure><p>Jason Weiesenbach, the creator of the meme, posted that commenters on AI-generated images “are literally praising—in a religious sense—non-reality … imagine if instead of trying to sell someone an adoption certificate for an AI generated monkey, they started feeding these folks fake news articles, complete with artificially generated photographic evidence, or go to their photos grab a random picture of their grandchild, put into an artificially generated hostage situation, and then uses that to scam them out of their life savings. These are not far-fetched ideas, that's literally the extreme side where this is headed. My point is these people are not ready for the world that is coming.”</p><p>Um, isn’t that AI? grew out of Facebook groups dedicated to Midjourney and other AI image generators. Penny and others in that group, including Um, isn’t that AI? founder Molly Huxley began to notice that images originally posted as AI-generated art were being posted elsewhere on Facebook as though they were real images.</p><p>“People would take the AI images and post them elsewhere as if they were real, and commenters thought they were real,” Penny told me. “Molly started the group and it was originally people from the AI art community who thought it was funny and weird that people were believing this shit, and it grew from there.”&nbsp;</p><p>The group has noticed that many of the “remixes” are posted by the same set of 10 or 15 engagement bait Facebook pages. They often repost the same images or versions of the same images and themes over and over again. There’s “Bread House Man,” “Victoria’s Art,” “Jesus in a Nut Tree, “Sand Castle Kid,” and dozens of other variations of images that get posted over and over again. Penny said his own involvement in the group started as a curiosity but eventually he became alarmed when his family members began commenting on AI fakes on Facebook as though they were real.</p><p>“My own dad shared one of these things, and I thought ‘You cannot think this is real,’” Penny said. “Then I saw my aunts and my dad’s friends share it—it gave me this whole existential crisis.”&nbsp;</p><p><strong>In Search of Victoria and The Bread House Man&nbsp;</strong></p><figure><img src="https://www.404media.co/content/images/2023/12/Screenshot-2023-12-14-at-6.18.12-PM.png" alt="" loading="lazy" width="1222" height="1228" srcset="https://www.404media.co/content/images/size/w600/2023/12/Screenshot-2023-12-14-at-6.18.12-PM.png 600w, https://www.404media.co/content/images/size/w1000/2023/12/Screenshot-2023-12-14-at-6.18.12-PM.png 1000w, https://www.404media.co/content/images/2023/12/Screenshot-2023-12-14-at-6.18.12-PM.png 1222w" sizes="(min-width: 720px) 720px"></figure><p>The MVP of Um, isn’t That AI? is Catherine Hall, a woman from New Zealand who has been systematically trying to trace the different versions of AI-generated duplicates all over Facebook, and has painstakingly searched for the original works that they were based off of.&nbsp;</p><p>I was amazed by Hall’s Google Sheets spreadsheets that trace every version of an image she can find. Originally, I saw her spreadsheet for “Victoria’s Art,” an image in which Victoria stands on a dirt path, proudly holding a self-portrait she painted. “I am a young artist Victoria. Please appreciate :).” Hall has identified 116 different variations of Victoria. In some she’s young, in others she’s a grandma. Sometimes, Victoria is Asian, Black, or mixed. Sometimes she has blonde hair, other times it’s red or gray.&nbsp;</p><figure data-kg-thumbnail="https://www.404media.co/content/media/2023/12/Screenshare---2023-12-14-7_16_16-AM--1-_thumb.jpg" data-kg-custom-thumbnail="">
            <div>
                <video src="https://www.404media.co/content/media/2023/12/Screenshare---2023-12-14-7_16_16-AM--1-.mp4" poster="https://img.spacergif.org/v1/927x846/0a/spacer.png" width="927" height="846" loop="" autoplay="" muted="" playsinline="" preload="metadata"></video>
                
                <div>
                        <p>
                        
                        <span>0:00</span></p><p>
                            /<span>0:53</span>
                        </p>
                        </div>
            </div>
            
        <img src="https://www.404media.co/content/media/2023/12/Screenshare---2023-12-14-7_16_16-AM--1-_thumb.jpg"></figure><p>“I wanted a way to show others how these images are being used. I discovered the majority of them were created from an actual artist’s original work, rather than a text based prompt so I became interested in finding the originals. It is frustrating me that so many mindless ‘wows!’ get spewed out over a fake copy of a real artist’s work,” Hall said. “Basically I will choose an image to research. Then hit up my list of fb pages and search through their back catalog to find all the renditions, I paste the information into a Google Sheet as I go then I can sort by date to see how the image has developed and morphed. Often they will have used a stolen original back at the start of things which can be searched back to find the source. I still am not sure why they do it.”</p><p>Hall has made similar spreadsheets for “<a href="https://docs.google.com/spreadsheets/d/1o2VB8VKpwBl4o691UnpjD2tFW3Iv1a8xTi2-UkXlcN0/edit?fbclid=IwAR1Aij_oV8BKc1S3MhIwVnlJjBYCQUru18lOpFyiqE1OyQygqkKyOrfFAIg&amp;ref=404media.co#gid=0"><u>Leaping Horse</u></a>,” (stolen <a href="https://eqliving.com/the-carving-of-cowboy-casanova-the-work-of-sculptor-brandon-wilson/?ref=404media.co"><u>from an artist named Brandon Wilson</u></a>), “<a href="https://docs.google.com/spreadsheets/d/1nptQ_3Or43_zBmyiYn8HyXhiP5fOog3_xJyBp-DcGks/edit?fbclid=IwAR2B7_WL4Nudbp-WcxdoYLYbnzW_ISJ2rJbizzYJM-9TL9IfZhXwSSkMaMM&amp;ref=404media.co#gid=0"><u>Man/boy with a wooden owl</u></a>,” (original unknown), “<a href="https://docs.google.com/spreadsheets/d/10Jt4IzgEb-ybT537Ysib921EBCFQngguO2_x3Vohzj8/edit?fbclid=IwAR39_Ut3PhPxJ2zv8hFvdL0trfPaSlMKUA8AU-GW45YeHigxbSZdUCPJdpA&amp;ref=404media.co#gid=0"><u>sand sculpting masters</u></a>,” (stolen from an Indian teenager whose name on Facebook is <a href="https://factcheck.afp.com/sculpture-was-created-indian-artist-sand-not-clay?ref=404media.co"><u>Sn Art Sadananda</u></a>), and “<a href="https://docs.google.com/spreadsheets/d/1_Yvp2wIfbM7vYKQnPWI4H4XqUEaUPEuKd21bKnu7rik/edit?fbclid=IwAR3q0TBf24og6ElNFrpjyO6onRh40RHyN5lo3Th6yIh7Ga4ajiLLLKVo9AA&amp;ref=404media.co#gid=0"><u>Jesus in a Nut Tree</u></a>” (artist unknown). I asked Sadananda how he felt after seeing the spreadsheet of clones of his work: “yes, upset,” he said.&nbsp;</p><p>Over the course of two hours on Wednesday, Hall and I chatted and began to try to find Victoria and where she came from. Hall already had a few candidates. I did some additional reverse image searching and found a screenshot of a VKontakte post featuring the image, from 2021, with the caption “Я молодая художница Виктория. Написала свою первую картину,” which translates to “I am a young artist Victoria. I painted my first picture.” I searched this and was able to <a href="https://www.facebook.com/102501845200790/photos/a.105775031540138/115484607235847/?paipv=0&amp;eav=Afa3u3oyqmXNzND49M6a5ndkdlrrAsm3kPPgHsPAlkTbu0RH9dA8TE72rQRxJHKfFDw"><u>find an identical post on Facebook</u></a> from 2021 from a page called “<a href="https://www.facebook.com/profile.php?id=100069933968592&amp;__tn__=-UC*F"><u>Сладкая жизнь</u></a>,” which means “Sweet Life.” This post has 16,000 likes and 829 comments. The image appears to be real, with some light Photoshopping in the grass near the path.</p><figure><img src="https://www.404media.co/content/images/2023/12/Screenshot-2023-12-16-at-7.04.45-PM.png" alt="" loading="lazy" width="1140" height="1432" srcset="https://www.404media.co/content/images/size/w600/2023/12/Screenshot-2023-12-16-at-7.04.45-PM.png 600w, https://www.404media.co/content/images/size/w1000/2023/12/Screenshot-2023-12-16-at-7.04.45-PM.png 1000w, https://www.404media.co/content/images/2023/12/Screenshot-2023-12-16-at-7.04.45-PM.png 1140w" sizes="(min-width: 720px) 720px"><figcaption><span>The original image of "Victoria"</span></figcaption></figure><p>I shared these links with Hall. She started looking at the images Sweet Life had posted over the years. The floodgates opened.&nbsp;</p><p>“Oh wow …..,” she said. “The bread house,” she added. An image of a man with, uhh, <a href="https://www.facebook.com/permalink.php?story_fbid=pfbid02KfS69x3iUqTr21rBQYR1xnskzAzY8zWhBGqfcQsbmat3vSeCyW9Ay9JQg16mh3vcl&amp;id=100069933968592"><u>a bread house popped up</u></a>.&nbsp;&nbsp;</p><figure><img src="https://lh7-us.googleusercontent.com/Ij60J_VjotVBKSKBS3Rh6T0AivyViOcq1OI7mRJczp0goo-fLzBdJaFBVk8Z-MSa7UiOt3weRPRk613mZOi-doeZSsOGC_HqndMeyyzVSQhD0aYVaP9qtGCVSBdm8sNHGrpRN6R5ff54FJ3RxhQfnIs" alt="" loading="lazy" width="606" height="942"></figure><figure><img src="https://lh7-us.googleusercontent.com/XJORxNGWITZagcOB9Q454NtIRJWnEgh9MdD4ZTxuwZx7zFnYA08Y7ilVRKM9stLyzmRz0cnU7jJNoHKKUVfrM7cvzfiSc5Vjv1WvNHYMsYn9EDTt00lXUisbxOzLQlODwlvodDfYh5BYxgDJakpP14c" alt="" loading="lazy" width="624" height="359"><figcaption><span>A document of bread house men Hill created.</span></figcaption></figure><p>She immediately followed up with 15 additional, AI-generated remixes of the bread house, each of which have a different man or different version of the house. “This page you found with ‘Victoria’ has a lot of the mother images that had been used to generate the AI versions,” she said. She sent me a series of real photographs of people that had been used as a “seed” image for future AI clones that she’s been tracking for months.</p><p>“I am finding the source image of so much of this stuff. I wonder if the owners of this page are the same group, but have moved on to generating the AI, or if the AI groups are just using this page as a source,” she said. “This page you found is pure gold.”&nbsp;&nbsp;</p><p>What seems to be happening is that some of the new Facebook pages sharing these AI-generated clones are pulling from old meme pages, which themselves had previously just reposted stuff that went viral on Reddit, Tumblr, or elsewhere.&nbsp;</p><p>We weren’t able to find the actual “Victoria,” or the Bread House Man, but we were at least able to peel back another layer of the onion. No one operating any of the Facebook pages responded to messages for comment. Hall’s theory, a common one in the Um, isn’t That AI? Group is that some of these larger groups will sell their accounts once they’ve amassed large numbers of followers, pivot to political disinformation, or try to monetize what they’re doing. A few of them have begun posting links to sites outside of Facebook, while others add links to online stores in the comment sections of their posts once an image has gone viral. The fact that all of these pages are stealing the work of artists upsets Hall: “Often I feel like I am just shouting my observations into a raging storm and no one hears,” she said.&nbsp;</p><h3 id="artificial-realities"><strong>ARTIFICIAL REALITIES</strong></h3><p>Of all of the awful things <a href="https://www.404media.co/a16z-funded-ai-platform-generated-images-that-could-be-categorized-as-child-pornography-leaked-documents-show/"><u>we’ve seen artificial intelligence used for</u></a>, engagement baiting with stolen content on Facebook is relatively tame. And yet, I couldn’t help but feel a mix of wonder and dread while reporting this story. Every time I started researching the origins of a new stolen image, I would click through dozens and dozens of stolen versions of it.&nbsp;</p><p>There is no polite way to say this, but the comments sections of each of these images are filled with unaware people posting inane encouragement about artwork stolen by robots, a completely constructed reality where thousands of talented AI woodcarvers constantly turn pixels into fucked up German Shepherds for their likes and faves. I tried to determine if the commenters, too, were bots. The vast majority of them clearly are not. Most commenters I looked into are people who have been judiciously posting family photos, political arguments, and status updates on Facebook for decades.&nbsp;</p><figure><img src="https://www.404media.co/content/images/2023/12/Screenshot-2023-12-14-at-7.17.48-AM.png" alt="" loading="lazy" width="918" height="1424" srcset="https://www.404media.co/content/images/size/w600/2023/12/Screenshot-2023-12-14-at-7.17.48-AM.png 600w, https://www.404media.co/content/images/2023/12/Screenshot-2023-12-14-at-7.17.48-AM.png 918w" sizes="(min-width: 720px) 720px"></figure><p>Both Penny and Farid made the same observation I did. Farid said that, currently, “when I look at the harms being perpetrated from generative AI from nonconsensual imagery, child sexual abuse, fraud, and disinformation, this isn’t even on the bottom of the list. Somebody’s posting a photo, real people like it—it’s Facebook, who cares, right?”&nbsp;</p><p>But he added that this AI dreck isn’t <em>good </em>and that in the long term we could see some bad consequences grow out of the rapid spamming of AI-generated crap. Farid published a study on “nepotistic” AI, where generative AI tools are trained on <em>other</em> AI-generated outputs, creating highly-distorted images: “Once poisoned, the models struggle to fully heal even after retraining on only real images,” his study found. “The slightly less kind word is inbreeding, which we didn’t feel we could use in a scientific paper,” Farid said.&nbsp;</p><p>The other big problem is that, while more digitally literate people can tell that these are AI-generated images <em>now</em>, the technology is advancing so quickly that the typical artifacting and deformities seen in AI-generated images today could be gone tomorrow.&nbsp;</p><p>“The images [being generated] are more and more photorealistic,” Farid said. “So we really are entering this era where you can just type and get a hyper photorealistic image. And if it's not true today will eventually be true that it will be devoid of obvious visual artifacts that the average person looking at would be able to discriminate.”</p><p>“There’s something to be said for the fact that our ability to discriminate reality from fiction is important for a functioning society and democracy,” he added. “If every time you see a photo, you think it’s real because it’s a photo, that has consequences beyond the silliness we’re seeing here.”</p><p>Penny said he thinks that studying these images might eventually give him the opposite problem: “20 years from now, I don’t know what it’s going to be like then, but I’m not going to believe a single thing anyone shows me on the internet ever again.”</p>
<!--kg-card-begin: html-->

<!--kg-card-end: html-->

                    <div>
    <div>
      <p>About the author</p>
      <p>Jason is a cofounder of 404 Media. He was previously the editor-in-chief of Motherboard. He loves the Freedom of Information Act and surfing.</p>
      
    </div>
      <p><img data-src="/content/images/2023/08/404-jason-01-copy.jpeg" alt="Jason Koebler" src="https://www.404media.co/content/images/2023/08/404-jason-01-copy.jpeg">  
      </p>
  </div>
          </div>
        </article>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Progress toward a GCC-based Rust compiler (281 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/954787/41470c731eda02a4/</link>
            <guid>38684102</guid>
            <pubDate>Mon, 18 Dec 2023 15:51:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/954787/41470c731eda02a4/">https://lwn.net/SubscriberLink/954787/41470c731eda02a4/</a>, See on <a href="https://news.ycombinator.com/item?id=38684102">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<!-- $Id: slink-none,v 1.2 2005-11-04 22:11:18 corbet Exp $ -->
<blockquote>
<div>
<h3>Welcome to LWN.net</h3>
<p>
The following subscription-only content has been made available to you 
by an LWN subscriber.  Thousands of subscribers depend on LWN for the 
best news from the Linux and free software communities.  If you enjoy this 
article, please consider <a href="https://lwn.net/subscribe/">subscribing to LWN</a>.  Thank you
for visiting LWN.net!
</p></div>
</blockquote>

<p>
The <a href="https://rust-gcc.github.io/">gccrs</a> project is an ambitious
effort started in 2014 to implement a Rust compiler within The GNU Compiler
Collection (GCC).  Even though the task is far from complete, progress has
been made since LWN's <a href="https://lwn.net/Articles/909887/">previous coverage</a>,
according to reports from the project.  Meanwhile, another hybrid and more
mature approach to GCC Rust code generation is available in <a href="https://github.com/rust-lang/rustc_codegen_gcc"><tt>rustc_codegen_gcc</tt></a>.

</p><p>
In 2022, the goal of gccrs was to be included in the GCC 13 release,
but <a href="https://rust-gcc.github.io/2023/04/24/gccrs-and-gcc13-release.html">this expectation has not been met</a>.
The team is currently aiming for inclusion in GCC&nbsp;14 (likely to be
released by mid-2024), judging from its
<a href="https://rust-gcc.github.io/2023/12/05/2023-11-monthly-report.html">November
2023 monthly report</a>.

</p><p>
On October 13, Arthur Cohen gave a talk titled "The road to compiling the
standard library with gccrs" (the <a href="https://www.youtube.com/watch?v=WgqGahDl-sY">video</a> is available)
at EuroRust 2023.  In his talk, Cohen gave a little bit of general
background on gccrs but mainly focused on what work has recently gone into
compiling the Rust standard library, and why gccrs cannot do it yet.

</p><p>
Gccrs targets a specific Rust version, <a href="https://blog.rust-lang.org/2020/12/31/Rust-1.49.0.html">1.49,
released at the end of 2020</a>, rather than trying to keep up with the
rapidly developing Rust language.  This version was chosen because it is
the latest version predating support for <a href="https://doc.rust-lang.org/reference/items/generics.html#const-generics">const
generics</a>, which were introduced in 1.50.  However, Cohen expressed
regret in his talk that the project has not been able to ignore const
generics after all, because they are in use in the standard library, even in
1.49.  They were "stabilized" for general availability in 1.50, but there
is internal standard library usage in earlier versions as well.  Const
generics have since been fully implemented, however, and this issue is no
longer a hindrance.

</p><p>
A lot of care is being put into gccrs not becoming a "superset" of Rust, as
Cohen put it.  The project wants to make sure that it does not create a
special "GNU Rust" language, but is trying instead to replicate the output of
rustc — bugs, quirks, and all.  Both the Rust and GCC test suites
are being used to accomplish this.

</p><p>
The Rust standard library consists of a number of "crates", which is what
software packages are called in Rust lingo.  Cohen explained that gccrs is
working on supporting compilation of the two most important ones: <a href="https://doc.rust-lang.org/core/"><tt>core</tt></a> and <a href="https://doc.rust-lang.org/alloc/"><tt>alloc</tt></a>.  The
<tt>core</tt> crate is the foundation of the standard library, implementing
features such as primitive types and macros; <tt>alloc</tt> deals with
heap-memory allocation and various container types.

</p><p>
Currently gccrs is not able to compile these crates because of various
shortcomings, such as incorrect behavior in macro-name resolution and
incomplete support for decorator macros.  The lack of a borrow checker
(discussed more below), while not blocking compilation, means that the
compiler cannot properly check the safety of the code.  An additional
hurdle is formed by missing compiler intrinsics in GCC. Rustc uses some
intrinsics provided by LLVM that are not supported by GCC, which means the
gccrs team needs to spend time implementing them in GCC.

</p><p>
Another talk (<a href="https://gcc.gnu.org/wiki/cauldron2023talks?action=AttachFile&amp;do=view&amp;target=GCC+Rust+Update.pdf">slides
available</a>) was given by Pierre-Emmanuel Patry at the GNU Tools Cauldron
in September 2023.  He mainly focused on progress toward inclusion in GCC
14 as well as macros, which seem to be an interrelated issue because the
approach to implement procedural macros necessitates changes to the GCC
build system.  <a href="https://doc.rust-lang.org/reference/procedural-macros.html">Procedural
macros</a> are function-like macros that emit token streams rather than
plain source code text like C or C++ macros.  They are implemented in a
built-in crate called <a href="https://doc.rust-lang.org/proc_macro/"><tt>proc_macro</tt></a>.  Such
macros are notoriously tricky to implement but also powerful; they form the
core of features such as <tt>#[attribute]</tt> and <tt>#[derive()]</tt>
decorators, and can be used to create compile-time evaluated,
domain-specific languages.

</p><p>
In the GNU Cauldron talk, Patry also mentioned that gccrs had more than 800
commits waiting to be upstreamed to GCC.

</p><h4>Taking advantage of the GCC ecosystem</h4>

<p>
Cohen's EuroRust talk highlighted that one of the major reasons gccrs is
being developed is to be able to take advantage of GCC's security plugins.
There is a wide range of existing GCC plugins that can aid in debugging,
static analysis, or hardening; these work on the GCC intermediate
representation.  Gccrs intends to support workflows where developers could
reuse these plugins with Rust code.  As an example, Cohen mentioned that "C
programmers have been forgetting to close their file descriptors for 40
years, [so] there are a lot of plugins to catch that".  Gccrs intends to
enable Rust programmers to use existing GCC plugins and static analyzers to
catch bugs in <tt>unsafe</tt> code.

</p><p>
Cohen listed a few things that gccrs is already useful for.
According to him, the Sega Dreamcast homebrew community uses gccrs to
create new games for the Dreamcast gaming console, and GCC
plugins can already be used to perform static analysis on unsafe Rust code.
The Dreamcast community's interest stems from the fact that rustc's LLVM
backend does not support the Hitachi SH-4 architecture of the console,
whereas GCC does; even in its incomplete state, gccrs is helpful for this
embedded use case.


</p><p>
Additionally, he mentioned that the gccrs effort has revealed some
unspecified language features, such as <tt>Deref</tt> and macro name
resolution; in response, the project has been able to contribute additions
to the Rust specification.  Currently Rust does not have a formal
specification, but work is underway to create one, as proposed in <a href="https://rust-lang.github.io/rfcs/3355-rust-spec.html">RFC 3355</a>.
"The gccrs people want to be a part" of that effort, Cohen
said.

</p><p>
One more reason for gccrs to exist is <a href="https://rust-for-linux.com/">Rust for Linux</a>, the initiative to
add Rust support to the Linux kernel.  Cohen said the
Linux kernel is a key motivator for the project because there are a lot of
kernel people who would prefer the kernel to be compiled only by the GNU
toolchain.

</p><h4>Things under development</h4>

<p>
Gccrs is still missing a lot of core functionality.  Cohen listed several
important features, such as <tt>async</tt>/<tt>await</tt>, LLVM intrinsics
that are absent in GCC, and the <tt>format_args!()</tt> macro used by
output macros such as <tt>println!()</tt>.  The borrow checker, which is a
compiler subsystem that enforces the reference rules of the language, is a
key Rust feature that gccrs will need to provide.  Cohen briefly mentioned
that the likely solution is a separate borrow-checker project called <a href="https://github.com/rust-lang/polonius">Polonius</a>, and said Gccrs
will most likely have it integrated a few months down the line.
Contributor Jakub Dupak has <a href="https://rust-gcc.github.io/2023/11/06/2023-10-monthly-report.html">made
progress</a> on this in the past few months.

</p><p>
Polonius is a library that implements a borrow checker that is semantically
equivalent to the (not quite flawlessly implemented) checker in rustc today,
by approaching the computation of reference lifetimes with <a href="https://smallcultfollowing.com/babysteps/blog/2018/04/27/an-alias-based-formulation-of-the-borrow-checker/">a
radically different algorithm</a>.  Polonius aims to one day resolve the
shortcomings and corner cases of rustc's current borrow checker.  Once it
has matured, rustc itself will likely also adopt it in the future.

</p><p>
According to the gccrs monthly report for November 2023, work has begun on
the <tt>format_args!()</tt> macro.  This helper macro is responsible for
constructing parameters for other string-formatting macros.  It involves
the <a href="https://doc.rust-lang.org/std/fmt/trait.Display.html"><tt>Display</tt></a>
and <a href="https://doc.rust-lang.org/std/fmt/trait.Debug.html"><tt>Debug</tt></a>
traits, and is a necessity for preparing arguments that are later passed to
other macros such as <tt>format!()</tt> and <tt>println!()</tt>.  Without
<tt>format_args!()</tt>, a Rust program cannot create formatted output;
this feature is thus necessary before gccrs can compile a "Hello, World"
program.

</p><p>
For a deep dive on <tt>format_args!()</tt>, see Mara Bos's recent <a href="https://blog.m-ou.se/format-args/">blog post</a>.

</p><h4><tt>rustc_codegen_gcc</tt></h4>

<p>
There is another GCC-based Rust project, called <tt>rustc_codegen_gcc</tt>,
that is more mature and more limited in scope compared to gccrs.  It is not
a full implementation of a Rust compiler from the ground up; instead, it
uses the <a href="https://gcc.gnu.org/wiki/JIT">libgccjit</a> library to
hook into an API of the LLVM backend used by rustc.  This approach performs
much of the compilation with rustc and turns to GCC at a later stage.
Despite the "JIT" (just in time) in the name of the library,
<tt>rustc_codegen_gcc</tt> is intended for ahead-of-time compilation.  Its
stated primary goal is to enable Rust code generation on platforms
unsupported by LLVM.

</p><p>
<a href="https://blog.antoyo.xyz/rustc_codegen_gcc-progress-report-26">As
of October 2023</a>, <tt>rustc_codegen_gcc</tt> can now compile Rust for
Linux without any additional patches.  Over the past year, the project
seems to have made good progress on many fronts; for example, it has added
support for SIMD (single instruction, multiple data) operations and
link-time optimization, both of which were earlier identified as causes for
test failures.  Cohen deferred to <tt>rustc_codegen_gcc</tt> at several
points in his EuroRust talk, encouraging attendees to use it instead of
gccrs for now.  It is, in fact, already upstreamed into the Rust language
repository.

</p><h4>Rust for Linux</h4>

<p>
Currently, the Rust for Linux project provides documentation for using
either <a href="https://docs.kernel.org/rust/quick-start.html">rustc</a> or
<a href="https://rust-for-linux.com/rustc_codegen_gcc"><tt>rustc_codegen_gcc</tt></a>
to build Rust code for the kernel.  The kernel also contains <a href="https://docs.kernel.org/process/changes.html">documentation</a> for
the minimal supported versions of various build tools, including compilers.
For rustc, the version is considered an exact match, rather than a minimum.
The currently stated supported rustc version is 1.73.0 (released in October
2023), much more recent than the 1.49 targeted by gccrs.  Rust for Linux
support is also a stated goal for gccrs, but because of this significant
discrepancy, it seems to be quite far off.

</p><p>
Gccrs has progressed nicely in the year since we last looked at it: the
repository has well over 3,000 commits since January&nbsp;1, 2023.
However, it is not yet in a usable state for almost any practical purpose,
since as a complete implementation from the ground up, gccrs is much more
ambitious in scope than <tt>rustc_codegen_gcc</tt>.  The latter is already
merged to the upstream Rust repository and sees real-world use with Rust
for Linux.  We are not yet in a world with multiple implementations of a
compiler for the Rust language, but it is getting closer.<br clear="all"></p><table>
           <tbody><tr><th colspan="2">Index entries for this article</th></tr>
           <tr><td><a href="https://lwn.net/Archives/GuestIndex/">GuestArticles</a></td><td><a href="https://lwn.net/Archives/GuestIndex/#Koistinen_Ronja">Koistinen, Ronja</a></td></tr>
            </tbody></table><br clear="all">

               <br clear="all">
               <hr><p>
           (<a href="https://lwn.net/Login/?target=/Articles/954787/">Log in</a> to post comments)
           </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Using Zig to Unit Test a C Application (137 pts)]]></title>
            <link>https://mtlynch.io/notes/zig-unit-test-c/</link>
            <guid>38683852</guid>
            <pubDate>Mon, 18 Dec 2023 15:36:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mtlynch.io/notes/zig-unit-test-c/">https://mtlynch.io/notes/zig-unit-test-c/</a>, See on <a href="https://news.ycombinator.com/item?id=38683852">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a href="https://ziglang.org/">Zig</a> is a new, independently developed low-level programming language. It’s a modern reimagining of C that attempts to retain C’s performance while embracing improvements from the last 30 years of tooling and language design.</p><p>Zig makes calling into C code easier than any other language I’ve used. Zig also treats unit testing as a first-class feature, which the C language certainly does not.</p><p>These two properties of Zig create an interesting opportunity: Zig allows you to add unit tests to existing C code. You can do this without rewriting any of your C code or build logic.</p><p>To demonstrate how to use Zig to test existing C code, I added unit tests to a real-world C application that I use daily.</p><h2 id="the-real-world-c-application-ustreamer">The real-world C application: uStreamer<a href="#the-real-world-c-application-ustreamer" arialabel="Anchor"> 🔗︎</a></h2><p>For the past three years, I’ve been working on <a href="https://tinypilotkvm.com/">TinyPilot</a>, an open-source KVM over IP. TinyPilot allows you to <a href="https://mtlynch.io/tinypilot">plug a Raspberry Pi into any computer</a> and then control that computer remotely.</p><p>To stream the target computer’s display, TinyPilot uses <a href="https://github.com/pikvm/ustreamer">uStreamer</a>, a video streaming utility that’s optimized for Raspberry Pi’s hardware.</p><figure><a href="https://mtlynch.io/notes/zig-unit-test-c/ustreamer-display.webp"><img sizes="(min-width: 768px) 800px, 98vw" srcset="https://d33wubrfki0l68.cloudfront.net/62c88af50185a1053610a8189ff937dfba1e6da5/34bd9/notes/zig-unit-test-c/ustreamer-display_huc9be7d30c6e5a82d20477fdf5077c027_132828_300x0_resize_q90_h2_lanczos_2.webp 300w,
https://d33wubrfki0l68.cloudfront.net/cd5d701b130b5c46c52f10cadadae9b008a21c78/ef6b7/notes/zig-unit-test-c/ustreamer-display_huc9be7d30c6e5a82d20477fdf5077c027_132828_600x0_resize_q90_h2_lanczos_2.webp 600w,
https://d33wubrfki0l68.cloudfront.net/b5d04354a95ae6a6f623813514dc2cb0cff846eb/e868d/notes/zig-unit-test-c/ustreamer-display_huc9be7d30c6e5a82d20477fdf5077c027_132828_800x0_resize_q90_h2_lanczos_2.webp 800w,
https://d33wubrfki0l68.cloudfront.net/e0a7e07dc7688ee160f48766d808364e68e30640/c6b56/notes/zig-unit-test-c/ustreamer-display_huc9be7d30c6e5a82d20477fdf5077c027_132828_1200x0_resize_q90_h2_lanczos_2.webp 1200w,
https://d33wubrfki0l68.cloudfront.net/c9f820c017c547652186859d92758dca2d497225/4a9b1/notes/zig-unit-test-c/ustreamer-display.webp 1400w" src="https://d33wubrfki0l68.cloudfront.net/c9f820c017c547652186859d92758dca2d497225/4a9b1/notes/zig-unit-test-c/ustreamer-display.webp" alt="Screenshot of TinyPilot in a browser window displaying a Dell boot screen" loading="lazy"></a><figcaption><p>TinyPilot uses the C uStreamer application to stream video</p></figcaption></figure><p>I’ve been working with uStreamer for several years, but I find the codebase difficult to approach. It’s implemented in C, and it doesn’t have any automated tests.</p><p>I learn best by tinkering with code, so exercising uStreamer’s C code through Zig feels like a good way to learn more about both uStreamer and Zig.</p><h2 id="getting-the-ustreamer-source-code">Getting the uStreamer source code<a href="#getting-the-ustreamer-source-code" arialabel="Anchor"> 🔗︎</a></h2><p>To begin, I’ll grab the uStreamer source code. The latest release as of this writing is <code>v5.45</code>, so I’ll grab that version:</p><div><pre tabindex="0"><code data-lang="bash"><span><span><span>USTREAMER_VERSION</span>=<span>'v5.45'</span>
</span></span><span><span>git clone <span>\
</span></span></span><span><span><span></span>  --branch <span>"</span><span>${</span><span>USTREAMER_VERSION</span><span>}</span><span>"</span> <span>\
</span></span></span><span><span><span></span>  https://github.com/pikvm/ustreamer.git
</span></span></code></pre></div><h2 id="whats-the-simplest-c-function-in-ustreamer">What’s the simplest C function in uStreamer?<a href="#whats-the-simplest-c-function-in-ustreamer" arialabel="Anchor"> 🔗︎</a></h2><p>For this exercise, the challenge is going to be using Zig, so I want the C part to be as simple as possible.</p><p>I want to find a dead simple function in uStreamer’s C code — something that I can feed some input, and it gives me some output that I can inspect easily.</p><p>Scanning through the filenames, I noticed <a href="https://github.com/pikvm/ustreamer/blob/v5.45/src/libs/base64.c"><code>base64.c</code></a>. That sounded promising. I know that <a href="https://en.wikipedia.org/wiki/Base64">base64</a> is a scheme for encoding arbitrary data as a printable string.</p><p>For example, if I read 10 bytes from <code>/dev/random</code> into my terminal, I get some unprintable bytes:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ head -c <span>10</span> /dev/random &gt; /tmp/output &amp;&amp; cat /tmp/output
</span></span><span><span>V�1A�����b
</span></span></code></pre></div><p>If I encode the data as base64, I get clean, printable charcters:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ base64 &lt; /tmp/output
</span></span><span><span><span>Vo8xQbWmnsLQYg</span>==
</span></span></code></pre></div><p>Here’s the signature of uStreamer’s base64 function:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>// src/libs/base64.h
</span></span></span><span><span><span></span>
</span></span><span><span><span>void</span> <span>us_base64_encode</span>(<span>const</span> <span>uint8_t</span> *data, <span>size_t</span> size, <span>char</span> **encoded, <span>size_t</span> *allocated);
</span></span></code></pre></div><p>From inspecting the function’s implementation in <a href="https://github.com/pikvm/ustreamer/blob/v5.45/src/libs/base64.c"><code>base64.c</code></a>, here’s what I deduce about the semantics of <code>us_base64_encode</code>:</p><ul><li><code>data</code> is input data to encode with the base64 encoding scheme.</li><li><code>size</code> is the length of the <code>data</code> buffer (in bytes).</li><li><code>encoded</code> is a pointer to an output buffer in which <code>us_base64_encode</code> stores the base64-encoded string.<ul><li><code>us_base64_encode</code> allocates memory for the output, and the caller is responsible for freeing the memory when they’re done with it.</li><li>Technically, <code>us_base64_encode</code> allows the caller to allocate the buffer for <code>encoded</code>, but, for simplicity, I’m ignoring that functionality.</li></ul></li><li><code>allocated</code> is a pointer that <code>us_base64_encode</code> populates with the number of bytes it allocated into <code>encoded</code>.</li></ul><p>Here’s a simple test program to call this function from C:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>// src/test.c
</span></span></span><span><span><span></span>
</span></span><span><span><span>#include</span> <span>&lt;stdio.h&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>#include</span> <span>"libs/base64.h"</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>void</span> <span>main</span>(<span>void</span>) {
</span></span><span><span>  <span>char</span> *input = <span>"hello, world!"</span>;
</span></span><span><span>  <span>char</span> *encoded = <span>NULL</span>;
</span></span><span><span>  <span>size_t</span> encoded_bytes = <span>0</span>;
</span></span><span><span>  <span>us_base64_encode</span>((<span>uint8_t</span> *)input, <span>strlen</span>(input), &amp;encoded, &amp;encoded_bytes);
</span></span><span><span>  <span>printf</span>(<span>"input:        %s</span><span>\n</span><span>"</span>, input);
</span></span><span><span>  <span>printf</span>(<span>"output:       %s</span><span>\n</span><span>"</span>, encoded);
</span></span><span><span>  <span>printf</span>(<span>"output bytes: %lu</span><span>\n</span><span>"</span>, encoded_bytes);
</span></span><span><span>  <span>free</span>(encoded);
</span></span><span><span>}
</span></span></code></pre></div><p>I’ll compile it with gcc, a popular C compiler:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ gcc src/test.c src/libs/base64.c -o /tmp/b64test
</span></span><span><span>In file included from src/libs/base64.h:31,
</span></span><span><span>                 from src/test.c:3:
</span></span><span><span>src/libs/tools.h: In <span>function</span> ‘us_signum_to_string’:
</span></span><span><span>src/libs/tools.h:194:34: warning: implicit declaration of <span>function</span> ‘sigabbrev_np’ [-Wimplicit-function-declaration]
</span></span><span><span>  <span>194</span> |         const char *const <span>name</span> = sigabbrev_np(signum);
</span></span><span><span>      |                                  ^~~~~~~~~~~~
</span></span></code></pre></div><p>Hmm, the code compiles, but I’m getting a lot of compiler warnings about a <code>tools.h</code> header that the uStreamer code includes.</p><p>If I look into <code>src/libs/tools.h</code>, I see that all the errors are around a single function: <a href="https://github.com/pikvm/ustreamer/blob/v5.45/src/libs/tools.h#L192-L210"><code>us_signum_to_string</code></a>. Let me see if I can just comment out that function to clear away the irrelevant warnings.</p><div><pre tabindex="0"><code data-lang="c"><span><span>
</span></span><span><span><span>/*
</span></span></span><span><span><span>DEBUG: Temporarily delete this function to get the build working again.
</span></span></span><span><span><span>INLINE char *us_signum_to_string(int signum) {
</span></span></span><span><span><span>...
</span></span></span><span><span><span>  return buf;
</span></span></span><span><span><span>}
</span></span></span><span><span><span>*/</span>
</span></span></code></pre></div><p>With the pesky <code>us_signum_to_string</code> function removed, I’ll try to compile build again:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ gcc src/test.c src/libs/base64.c -o /tmp/b64test &amp;&amp; /tmp/b64test
</span></span><span><span>input:        hello, world!
</span></span><span><span>output:       <span>aGVsbG8sIHdvcmxkIQ</span>==
</span></span><span><span>output bytes: <span>21</span>
</span></span></code></pre></div><p>Hooray, no more compiler warnings.</p><p>If I were trying to compile all of uStreamer, I’d have to figure out how to get <code>us_signum_to_string</code> to compile. For this exercise, I’m just calling <code>us_base64_encode</code> from Zig, so I don’t need <code>us_signum_to_string</code>.</p><p>If I compare my <code>test.c</code> program’s output to my system’s built-in <code>base64</code> utility, I can verify that I’m producing the correct result:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ <span>printf</span> <span>'hello, world!'</span> | base64
</span></span><span><span><span>aGVsbG8sIHdvcmxkIQ</span>==
</span></span></code></pre></div><p>The complete example at this stage <a href="https://github.com/tiny-pilot/ustreamer/tree/zig-00-c-test">is on Github</a>.</p><h2 id="adding-zig-to-my-ustreamer-project-environment">Adding Zig to my uStreamer project environment<a href="#adding-zig-to-my-ustreamer-project-environment" arialabel="Anchor"> 🔗︎</a></h2><p>My favorite way of installing Zig is <a href="https://zero-to-nix.com/">with Nix</a>, as it allows me to switch Zig versions easily. Feel free to <a href="https://ziglang.org/learn/getting-started/">install Zig</a> any way you prefer.</p><p>I added the following <code>flake.nix</code> file to my project, which pulls Zig 0.11.0 into my environment:</p><div><pre tabindex="0"><code data-lang="nix"><span><span>{
</span></span><span><span>  description = <span>"Dev environment for zig-c-simple"</span>;
</span></span><span><span>
</span></span><span><span>  inputs = {
</span></span><span><span>    flake-utils.url = <span>"github:numtide/flake-utils"</span>;
</span></span><span><span>
</span></span><span><span>    <span># 0.11.0</span>
</span></span><span><span>    zig_dep.url = <span>"github:NixOS/nixpkgs/46688f8eb5cd6f1298d873d4d2b9cf245e09e88e"</span>;
</span></span><span><span>  };
</span></span><span><span>
</span></span><span><span>  outputs = { self, flake-utils, zig_dep }@inputs :
</span></span><span><span>    flake-utils.lib.eachDefaultSystem (system:
</span></span><span><span>    <span>let</span>
</span></span><span><span>      zig_dep = inputs.zig_dep.legacyPackages.<span>${</span>system<span>}</span>;
</span></span><span><span>    <span>in</span>
</span></span><span><span>    {
</span></span><span><span>      devShells.default = zig_dep.mkShell {
</span></span><span><span>        packages = [
</span></span><span><span>          zig_dep.zig
</span></span><span><span>        ];
</span></span><span><span>
</span></span><span><span>        shellHook = <span>''
</span></span></span><span><span><span>          echo "zig" "$(zig version)"
</span></span></span><span><span><span>        ''</span>;
</span></span><span><span>      };
</span></span><span><span>    });
</span></span><span><span>}
</span></span></code></pre></div><p>From here, I can run <code>nix develop</code>, and I see that Nix 0.11.0 is available in my project environment:</p><div><pre tabindex="0"><code data-lang="bash"><span><span><span># There's a weird quirk of Nix flakes that they have to be added to your git</span>
</span></span><span><span><span># repo.</span>
</span></span><span><span>$ git add flake.nix
</span></span><span><span>$ nix develop
</span></span><span><span>zig 0.11.0
</span></span></code></pre></div><h2 id="creating-a-zig-executable">Creating a Zig executable<a href="#creating-a-zig-executable" arialabel="Anchor"> 🔗︎</a></h2><p>The Zig compiler’s <code>init-exe</code> creates a boilerplate Zig application, so I’ll use it to create a simple Zig app within the uStreamer source tree:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ zig init-exe
</span></span><span><span>info: Created build.zig
</span></span><span><span>info: Created src/main.zig
</span></span><span><span>info: Next, try <span>`</span>zig build --help<span>`</span> or <span>`</span>zig build run<span>`</span>
</span></span></code></pre></div><p>If I try compiling and running the boilerplate Zig application, I see that everything works:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ zig build run
</span></span><span><span>All your codebase are belong to us.
</span></span><span><span>Run <span>`</span>zig build <span>test</span><span>`</span> to run the tests.
</span></span></code></pre></div><p>The uStreamer C file I want to call <a href="https://github.com/pikvm/ustreamer/blob/v5.45/src/libs/base64.h#L25-L27">depends on the C standard library</a>, so I need to make a small adjustment to my <code>build.zig</code> file to link against that library. While I’m adjusting, I’ll also replace the boilerplate binary name with <code>base64-encoder</code>:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>    </span><span>const</span><span> </span>exe<span> </span>=<span> </span>b.addExecutable(.{<span>
</span></span></span><span><span><span>        </span>.name<span> </span>=<span> </span><span>"base64-encoder"</span>,<span> </span><span>// Change binary name.
</span></span></span><span><span><span></span><span>        </span>.root_source_file<span> </span>=<span> </span>.{<span> </span>.path<span> </span>=<span> </span><span>"src/main.zig"</span><span> </span>},<span>
</span></span></span><span><span><span>        </span>.target<span> </span>=<span> </span>target,<span>
</span></span></span><span><span><span>        </span>.optimize<span> </span>=<span> </span>optimize,<span>
</span></span></span><span><span><span>    </span>});<span>
</span></span></span><span><span><span>    </span>exe.linkLibC();<span>               </span><span>// Link against C standard library.
</span></span></span><span><span><span></span><span>    </span>exe.addIncludePath(.{<span> </span>.path<span> </span>=<span> </span><span>"src"</span><span> </span>});<span>
</span></span></span></code></pre></div><h2 id="calling-ustreamer-code-from-zig">Calling uStreamer code from Zig<a href="#calling-ustreamer-code-from-zig" arialabel="Anchor"> 🔗︎</a></h2><p>Now, I want to call the <code>us_base64_encode</code> C function from Zig.</p><p>As a reminder, here’s the C function I’m trying to call from Zig, which I explained <a href="http://blog.local:1313/notes/zig-unit-test-c/#whats-the-simplest-c-function-in-ustreamer">above</a>:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>// src/libs/base64.h
</span></span></span><span><span><span></span>
</span></span><span><span><span>void</span> <span>us_base64_encode</span>(<span>const</span> <span>uint8_t</span> *data, <span>size_t</span> size, <span>char</span> **encoded, <span>size_t</span> *allocated);
</span></span></code></pre></div><p>Figuring out how to translate between C types and Zig types turned out to be the hardest part of this process, as I’m still a Zig novice.</p><p>Here was my first attempt:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>// src/main.zig
</span></span></span><span><span><span></span><span>
</span></span></span><span><span><span></span><span>const</span><span> </span>ustreamer<span> </span>=<span> </span><span>@cImport</span>({<span>
</span></span></span><span><span><span>    </span><span>@cInclude</span>(<span>"libs/base64.c"</span>);<span>
</span></span></span><span><span><span></span>});<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>fn</span><span> </span>main()<span> </span>!<span>void</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span>input<span> </span>=<span> </span><span>"hello, world!"</span>;<span>
</span></span></span><span><span><span>    </span><span>var</span><span> </span>cEncoded:<span> </span>*<span>u8</span><span> </span>=<span> </span><span>undefined</span>;<span>
</span></span></span><span><span><span>    </span><span>var</span><span> </span>allocatedSize:<span> </span><span>usize</span><span> </span>=<span> </span><span>0</span>;<span>
</span></span></span><span><span><span>    </span><span>// WRONG: This doesn't compile.
</span></span></span><span><span><span></span><span>    </span>ustreamer.us_base64_encode(&amp;input,<span> </span>input.len,<span> </span>&amp;cEncoded,<span> </span>&amp;allocatedSize);<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>That yielded this compiler error:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ zig build run
</span></span><span><span>zig build-exe b64 Debug native: error: the following <span>command</span> failed with <span>1</span> compilation errors:
</span></span><span><span>...
</span></span><span><span>src/main.zig:17:32: error: expected <span>type</span> <span>'[*c]const u8'</span>, found <span>'*const *const [13:0]u8'</span>
</span></span><span><span>    ustreamer.us_base64_encode(&amp;input, input.len, &amp;cEncoded, &amp;allocatedSize);
</span></span><span><span>                               ^~~~~~
</span></span><span><span>src/main.zig:17:32: note: pointer <span>type</span> child <span>'*const [13:0]u8'</span> cannot cast into pointer <span>type</span> child <span>'u8'</span>
</span></span><span><span>/home/mike/ustreamer/zig-cache/o/9599bf4c636d23e50eddd1a55dd088ff/cimport.zig:1796:43: note: parameter <span>type</span> declared here
</span></span><span><span>pub <span>export</span> fn us_base64_encode(arg_data: [*c]const u8, arg_size: usize, arg_encoded: [*c][*c]u8, arg_allocated: [*c]usize) void {
</span></span></code></pre></div><p>I had trouble understanding this error at first because so much of it was unfamiliar.</p><p>The important bit of the compiler error above is <code>error: expected type '[*c]const u8', found '*const *const [13:0]u8'</code>. It’s telling me that I tried to pass in a <code>*const *const [13:0]u8</code>, but Zig needs me to pass in <code>[*c]const u8</code>.</p><p>What does that mean?</p><h3 id="understanding-the-type-i-used">Understanding the type I used<a href="#understanding-the-type-i-used" arialabel="Anchor"> 🔗︎</a></h3><p>According to the Zig compiler, I passed in a parameter of type <code>'*const *const [13:0]u8</code>. To understand what this means, I’ll go from right to left:</p><p><code>u8</code> is an unsigned byte, which is how Zig represents characters in a string.</p><p><code>[13:0]</code> means a null-terminated array. The <code>13</code> is the length of the array, which Zig calculates at compile-time. <code>:0</code> means that the array has an extra byte with a value of <code>0</code> to indicate the end of the string. For more details about the mechanics of null-terminated strings in Zig, see <a href="https://mtlynch.io/notes/zig-strings-call-c-code/">my previous post</a>.</p><p><code>*const</code> means a constant pointer. A pointer is an address in memory, and the <code>const</code> means that subsequent code may not reassign the variable.</p><p><code>*const *const</code> means a constant pointer to a constant pointer. In other words, <code>input</code> is a constant pointer to a string, so that means <code>&amp;input</code> is a constant pointer to a constant pointer.</p><h3 id="converting-a-zig-type-to-a-c-type">Converting a Zig type to a C type<a href="#converting-a-zig-type-to-a-c-type" arialabel="Anchor"> 🔗︎</a></h3><p>Okay, now I understand how Zig views the string that I passed. What did Zig <em>want</em> me to pass as the <code>input</code> type?</p><div><pre tabindex="0"><code data-lang="text"><span><span>expected type '[*c]const u8'
</span></span></code></pre></div><p>What the heck does <code>[*c]</code> mean?</p><p>This was surprisingly hard to figure out. I eventually pieced it together from a few different sources.</p><p>Here’s the official Zig documentation:</p><blockquote><h3 id="c-pointers">C Pointers<a href="#c-pointers" arialabel="Anchor"> 🔗︎</a></h3><p>This type is to be avoided whenever possible. The only valid reason for using a C pointer is in auto-generated code from translating C code.</p><p>When importing C header files, it is ambiguous whether pointers should be translated as single-item pointers (*T) or many-item pointers ([*]T). C pointers are a compromise so that Zig code can utilize translated header files directly.</p><p><a href="https://ziglang.org/documentation/0.11.0/#C-Pointers">https://ziglang.org/documentation/0.11.0/#C-Pointers</a></p></blockquote><p>I didn’t understand the documentation, as it seemed to be warning against using C pointers rather than explaining what they are.</p><p>More <a href="https://kagi.com/">Kagi</a>‘ing led me to this explanation on reddit, which I found more accessible:</p><blockquote><p><code>[*c]T</code> is just a C pointer to type T, it says that it doesn’t know whether there are multiple elements in that pointer or not. There could be, there could not be. We also don’t know the length of it (it’s not a slice which has pointer+length, it’s just a pointer). And if there are multiple elements, we don’t know if it is say null-terminated or not.</p><p><a href="https://www.reddit.com/r/Zig/comments/11uqo84/comment/jcplxiz/">-/u/slimsag on reddit</a></p></blockquote><p>Okay, that makes more sense.</p><p>In C, a pointer is just a memory address and a data type. A C type of <code>char*</code> could point to a single character like <code>'A'</code>, or it could point to the first character in a sequence like <code>"ABCD"</code>.</p><p>In Zig, a pointer to an array is a different type than a pointer to a single element. When Zig has to infer a data type from C code, Zig can’t tell whether the C code is referring to a single element or an array, so the C pointer type (<code>[*c]T</code>) is Zig’s way of saying, “I don’t know. I got this from C.”</p><p>Through trial and error, I figured out that Zig wanted me to get a pointer to <code>input</code> by referencing <code>input.ptr</code> rather than using the address-of operator <code>&amp;</code>.</p><p>This Zig snippet shows the difference between the <code>.ptr</code> and <code>&amp;</code>:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>const</span><span> </span>input<span> </span>=<span> </span><span>"hello, world!"</span>;<span>
</span></span></span><span><span><span></span>std.debug.print(<span>"input     is type {s}</span><span>\n</span><span>"</span>,<span> </span>.{<span>@typeName</span>(<span>@TypeOf</span>(input))});<span>
</span></span></span><span><span><span></span>std.debug.print(<span>"&amp;input    is type {s}</span><span>\n</span><span>"</span>,<span> </span>.{<span>@typeName</span>(<span>@TypeOf</span>(&amp;input))});<span>
</span></span></span><span><span><span></span>std.debug.print(<span>"input.ptr is type {s}</span><span>\n</span><span>"</span>,<span> </span>.{<span>@typeName</span>(<span>@TypeOf</span>(input.ptr))});<span>
</span></span></span></code></pre></div><div><pre tabindex="0"><code data-lang="text"><span><span>input     is type *const [13:0]u8
</span></span><span><span>&amp;input    is type *const *const [13:0]u8
</span></span><span><span>input.ptr is type [*]const u8
</span></span></code></pre></div><p>Recall that Zig wants me to pass <code>us_base64_encode</code> a parameter of type <code>[*c]const u8</code>, so it looks like it can convert <code>[*]const u8</code> to that type.</p><p>Okay, let me try calling <code>us_base64_encode</code> again:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>const</span><span> </span>input<span> </span>=<span> </span><span>"hello, world!"</span>;<span>
</span></span></span><span><span><span></span><span>var</span><span> </span>cEncoded:<span> </span>*<span>u8</span><span> </span>=<span> </span><span>undefined</span>;<span>
</span></span></span><span><span><span></span><span>var</span><span> </span>allocatedSize:<span> </span><span>usize</span><span> </span>=<span> </span><span>0</span>;<span>
</span></span></span><span><span><span></span>ustreamer.us_base64_encode(input.ptr,<span> </span>input.len,<span> </span>&amp;cEncoded,<span> </span>&amp;allocatedSize);<span>
</span></span></span></code></pre></div><p>That gives me:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ zig build run
</span></span><span><span>zig build-exe b64 Debug native: error: the following <span>command</span> failed with <span>1</span> compilation errors:
</span></span><span><span>...
</span></span><span><span>src/main.zig:12:54: error: expected <span>type</span> <span>'[*c][*c]u8'</span>, found <span>'**u8'</span>
</span></span><span><span>    ustreamer.us_base64_encode(input.ptr, input.len, &amp;cEncoded, &amp;allocatedSize);
</span></span><span><span>                                                     ^~~~~~~~~
</span></span></code></pre></div><p>Progress!</p><p>The code still doesn’t compile, but Zig is now complaining about the third parameter instead of the first. That at least tells me that I’ve supplied the expected types for the first two parameters.</p><h3 id="translating-the-output-parameters-into-zig">Translating the output parameters into Zig<a href="#translating-the-output-parameters-into-zig" arialabel="Anchor"> 🔗︎</a></h3><p>The compiler error also contains a helpful bit of information for calling into the C implementation of <code>us_base64_encode</code>:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>pub <span>export</span> fn us_base64_encode(arg_data: [*c]const u8, arg_size: usize, arg_encoded: [*c][*c]u8, arg_allocated: [*c]usize) void {
</span></span></code></pre></div><p>That’s the signature of the C function translated into Zig, so Zig is telling me exactly the types I need to pass in to call the function.</p><p>Alternatively, I can use the <code>zig translate-c</code> utility to translate this C function signature into Zig. This effectively gives the same results as the compiler error above, but it preserves the original parameter names, whereas the compiler error prefixes them with <code>arg_</code>.</p><div><pre tabindex="0"><code data-lang="bash"><span><span><span># We add --library c to let Zig know the code depends on libc.</span>
</span></span><span><span>$ zig translate-c src/libs/base64.h --library c | grep us_base64
</span></span><span><span>pub extern fn us_base64_encode(data: [*c]const u8, size: usize, encoded: [*c][*c]u8, allocated: [*c]usize) void;
</span></span></code></pre></div><p>From more trial and error, I eventually guessed my way to these semantics for calling <code>us_base64_encode</code> from Zig:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>const</span><span> </span>input<span> </span>=<span> </span><span>"hello, world!"</span>;<span>
</span></span></span><span><span><span></span><span>var</span><span> </span>cEncoded:<span> </span>[*c]<span>u8</span><span> </span>=<span> </span><span>null</span>;<span>
</span></span></span><span><span><span></span><span>var</span><span> </span>allocatedSize:<span> </span><span>usize</span><span> </span>=<span> </span><span>0</span>;<span>
</span></span></span><span><span><span></span>ustreamer.us_base64_encode(input.ptr,<span> </span>input.len,<span> </span>&amp;cEncoded,<span> </span>&amp;allocatedSize);<span>
</span></span></span></code></pre></div><p>And it compiles successfully!</p><h3 id="can-i-do-better-than-c-pointers">Can I do better than C pointers?<a href="#can-i-do-better-than-c-pointers" arialabel="Anchor"> 🔗︎</a></h3><p>Recall what the Zig documentation <a href="https://ziglang.org/documentation/0.11.0/#C-Pointers">said about C pointers</a>:</p><blockquote><p>The only valid reason for using a C pointer is in auto-generated code…</p></blockquote><p>I’m writing this code by hand, so I guess I shouldn’t be using a type reserved for auto-generated code.</p><p>I know that the third parameter to <code>us_base64_encode</code> is a pointer to a null-terminated string. How do I represent that in Zig?</p><p>My first thought was to do this:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>var</span><span> </span>cEncoded:<span> </span>[*:<span>0</span>]<span>u8</span><span> </span>=<span> </span><span>undefined</span>;<span>
</span></span></span><span><span><span></span>ustreamer.us_base64_encode(input.ptr,<span> </span>input.len,<span> </span>&amp;cEncoded,<span> </span>&amp;allocatedSize);<span>
</span></span></span></code></pre></div><p>That seemed reasonable. I know that <code>us_base64_encode</code> will populate <code>cEncoded</code> with a string, and <code>[*:0]u8</code> represents a null-terminated string of unkown length. But when I compile, Zig said no:</p><div><pre tabindex="0"><code data-lang="text"><span><span>error: expected type '[*c][*c]u8', found '*[*:0]u8'
</span></span></code></pre></div><p>I was stumped, so I asked for help on <a href="https://ziggit.dev/">Ziggit</a>, a Zig discussion forum. Within an hour, another user <a href="https://ziggit.dev/t/improving-on-c-u8-when-calling-a-c-function-that-allocates-a-string/2489/4?u=mtlynch">showed me a solution</a>:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>var</span><span> </span>cEncoded:<span> </span>?[*:<span>0</span>]<span>u8</span><span> </span>=<span> </span><span>null</span>;<span>
</span></span></span><span><span><span></span>ustreamer.us_base64_encode(input.ptr,<span> </span>input.len,<span> </span>&amp;cEncoded,<span> </span>&amp;allocatedSize);<span>
</span></span></span></code></pre></div><p>The issue was that in C, a type of <code>char**</code> can be <code>null</code>, whereas a Zig type of <code>[*:0]u8</code> cannot be null. That’s why Zig refused to let me pass in my previous attempt.</p><p>Breaking down the correct type of <code>?[*:0]u8</code>, I see that it’s:</p><ul><li>a null-terminated slice of bytes (<code>:0]u8</code>)</li><li>of unknown length (<code>[*</code>)</li><li>that <a href="https://ziglang.org/documentation/0.11.0/#Optionals">might be null</a> (<code>?</code>)</li></ul><p>The new type allows me to compile the code, but if I try to print the value of <code>cEncoded</code>, I get what appears to be a memory address rather than a string:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ zig build run
</span></span><span><span>input:       hello, world!
</span></span><span><span>output:      u8@2b12a0      <span># &lt;&lt; whoops, not what I expected</span>
</span></span><span><span>output size: <span>21</span>
</span></span></code></pre></div><p>In order to convert <code>cEncoded</code> back to a printable string, I have to unwrap it from its optional variable by verifying in code that its value is non-null:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>var</span><span> </span>cEncoded:<span> </span>?[*:<span>0</span>]<span>u8</span><span> </span>=<span> </span><span>null</span>;<span>
</span></span></span><span><span><span></span>ustreamer.us_base64_encode(input.ptr,<span> </span>input.len,<span> </span>&amp;cEncoded,<span> </span>&amp;allocatedSize);<span>
</span></span></span><span><span><span></span><span>const</span><span> </span>output:<span> </span>[*:<span>0</span>]<span>u8</span><span> </span>=<span> </span>cEncoded<span> </span><span>orelse</span><span> </span><span>return</span><span> </span><span>error</span>.UnexpectedNull;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span>...<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span>std.debug.print(<span>"output:      {s}</span><span>\n</span><span>"</span>,<span> </span>.{output});<span>
</span></span></span></code></pre></div><p>And then it prints the correct result:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ zig build run
</span></span><span><span>input: hello, world!
</span></span><span><span>output: <span>aGVsbG8sIHdvcmxkIQ</span>==
</span></span><span><span>output size: <span>21</span>
</span></span></code></pre></div><h3 id="completing-the-call-to-c-from-zig">Completing the call to C from Zig<a href="#completing-the-call-to-c-from-zig" arialabel="Anchor"> 🔗︎</a></h3><p>At this point, I now have complete working code for calling the C <code>us_base64_encode</code> from Zig. Here’s the full <code>src/main.zig</code> file:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>// src/main.zig
</span></span></span><span><span><span></span><span>
</span></span></span><span><span><span></span><span>const</span><span> </span>std<span> </span>=<span> </span><span>@import</span>(<span>"std"</span>);<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>// Import the base64 implementation from uStreamer's C source file.
</span></span></span><span><span><span></span><span>const</span><span> </span>ustreamer<span> </span>=<span> </span><span>@cImport</span>({<span>
</span></span></span><span><span><span>    </span><span>@cInclude</span>(<span>"libs/base64.c"</span>);<span>
</span></span></span><span><span><span></span>});<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>fn</span><span> </span>main()<span> </span>!<span>void</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>// Create a standard Zig string.
</span></span></span><span><span><span></span><span>    </span><span>const</span><span> </span>input<span> </span>=<span> </span><span>"hello, world!"</span>;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>// Create variables to store the ouput parameters of us_base64_encode.
</span></span></span><span><span><span></span><span>    </span><span>var</span><span> </span>cEncoded:<span> </span>?[*:<span>0</span>]<span>u8</span><span> </span>=<span> </span><span>null</span>;<span>
</span></span></span><span><span><span>    </span><span>var</span><span> </span>allocatedSize:<span> </span><span>usize</span><span> </span>=<span> </span><span>0</span>;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>// Call the uStreamer C function from Zig.
</span></span></span><span><span><span></span><span>    </span>ustreamer.us_base64_encode(input.ptr,<span> </span>input.len,<span> </span>&amp;cEncoded,<span> </span>&amp;allocatedSize);<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>// Get the output as a non-optional type.
</span></span></span><span><span><span></span><span>    </span><span>const</span><span> </span>output:<span> </span>[*:<span>0</span>]<span>u8</span><span> </span>=<span> </span>cEncoded<span> </span><span>orelse</span><span> </span><span>return</span><span> </span><span>error</span>.UnexpectedNull;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>// Free the memory that the C function allocated when this function exits.
</span></span></span><span><span><span></span><span>    </span><span>defer</span><span> </span>std.c.free(cEncoded);<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>// Print the input and output of the base64 encode operation.
</span></span></span><span><span><span></span><span>    </span>std.debug.print(<span>"input:       {s}</span><span>\n</span><span>"</span>,<span> </span>.{input});<span>
</span></span></span><span><span><span>    </span>std.debug.print(<span>"output:      {s}</span><span>\n</span><span>"</span>,<span> </span>.{output});<span>
</span></span></span><span><span><span>    </span>std.debug.print(<span>"output size: {d}</span><span>\n</span><span>"</span>,<span> </span>.{allocatedSize});<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><div><pre tabindex="0"><code data-lang="bash"><span><span>$ zig build run
</span></span><span><span>input:       hello, world!
</span></span><span><span>output:      <span>aGVsbG8sIHdvcmxkIQ</span>==
</span></span><span><span>output size: <span>21</span>
</span></span></code></pre></div><p>Great! That worked. And the results are identical to <a href="#whats-the-simplest-c-function-in-ustreamer">my C implementation above</a>.</p><p>The complete example at this stage <a href="https://github.com/tiny-pilot/ustreamer/tree/zig-10-simple-exe">is on Github</a>.</p><h2 id="creating-a-zig-wrapper-for-the-native-c-implementation">Creating a Zig wrapper for the native C implementation<a href="#creating-a-zig-wrapper-for-the-native-c-implementation" arialabel="Anchor"> 🔗︎</a></h2><p>At this point, I can successfully call the C <code>us_base64_encode</code> function from Zig, but the code is a bit messy. Most of my <code>main()</code> function is dealing with translating values to and from C code.</p><p>One way to improve the code is to add a Zig wrapper function for <code>us_base64_encode</code>. That way, I could encapsulate all the Zig to C interop logic, and callers of my wrapper wouldn’t have to know or care that I’m calling C.</p><p>What should my wrapper function look like?</p><p>It should accept arbitrary bytes and return a null-terminated string, so the function signature should look something like this:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>fn</span><span> </span>base64Encode(data:<span> </span>[]<span>const</span><span> </span><span>u8</span>)<span> </span>[:<span>0</span>]<span>u8</span><span> </span>{...}<span>
</span></span></span></code></pre></div><p>I already have the first few lines of my implementation based on my <code>main()</code> function <a href="#completing-the-call-to-c-from-zig">above</a>:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>fn</span><span> </span>base64Encode(data:<span> </span>[]<span>const</span><span> </span><span>u8</span>)<span> </span>[:<span>0</span>]<span>u8</span><span> </span>{<span>
</span></span></span><span><span><span>  </span><span>var</span><span> </span>cEncoded:<span> </span>?[*:<span>0</span>]<span>u8</span><span> </span>=<span> </span><span>null</span>;<span>
</span></span></span><span><span><span>  </span><span>var</span><span> </span>allocatedSize:<span> </span><span>usize</span><span> </span>=<span> </span><span>0</span>;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>  </span>ustreamer.us_base64_encode(data.ptr,<span> </span>data.len,<span> </span>&amp;cEncoded,<span> </span>&amp;allocatedSize);<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>  </span><span>// TODO: Complete the implementation.
</span></span></span></code></pre></div><h3 id="whos-responsible-for-freeing-the-memory-c-allocated">Who’s responsible for freeing the memory C allocated?<a href="#whos-responsible-for-freeing-the-memory-c-allocated" arialabel="Anchor"> 🔗︎</a></h3><p>There’s a problem I haven’t addressed yet. <code>us_base64_encode</code> allocated memory into the <code>cEncoded</code> pointer. The caller is responsible for either freeing that memory or passing off that responsibility to its callers.</p><p>Normally, it’s fine for a function to declare that the caller is responsible for freeing an output value, but this case is a little trickier. This isn’t a normal Zig-allocated memory buffer — it’s a C-allocated buffer that requires a special free function (<code>std.c.free</code>).</p><p>I want to abstract away the C implementation details, so callers shouldn’t have to use a C-specific memory freeing function.</p><p>That tells me what I need to do to complete the implementation of my Zig wrapper. I use <code>defer std.c.free</code> to free the C-allocated memory, and then I’ll need to copy it into a Zig-managed slice:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>fn</span><span> </span>base64Encode(data:<span> </span>[]<span>const</span><span> </span><span>u8</span>)<span> </span>![:<span>0</span>]<span>u8</span><span> </span>{<span>
</span></span></span><span><span><span>  </span><span>var</span><span> </span>cEncodedOptional:<span> </span>?[*:<span>0</span>]<span>u8</span><span> </span>=<span> </span><span>null</span>;<span>
</span></span></span><span><span><span>  </span><span>var</span><span> </span>allocatedSize:<span> </span><span>usize</span><span> </span>=<span> </span><span>0</span>;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>  </span>ustreamer.us_base64_encode(data.ptr,<span> </span>data.len,<span> </span>&amp;cEncodedOptional,<span> </span>&amp;allocatedSize);<span>
</span></span></span><span><span><span>  </span><span>const</span><span> </span>cEncoded:<span> </span>[*:<span>0</span>]<span>u8</span><span> </span>=<span> </span>cEncodedOptional<span> </span><span>orelse</span><span> </span><span>return</span><span> </span><span>error</span>.UnexpectedNull;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>  </span><span>// Get the output as a non-optional type.
</span></span></span><span><span><span></span><span>  </span><span>const</span><span> </span>output:<span> </span>[*:<span>0</span>]<span>u8</span><span> </span>=<span> </span>cEncoded<span> </span><span>orelse</span><span> </span><span>return</span><span> </span><span>error</span>.UnexpectedNull;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>  </span><span>// Free the C-allocated memory buffer before exiting the function.
</span></span></span><span><span><span></span><span>  </span><span>defer</span><span> </span>std.c.free(cEncoded);<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>  </span><span>// TODO: Copy the contents of cEncoded into a [:0]u8 buffer.
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><h3 id="converting-a-c-string-to-a-zig-string">Converting a C string to a Zig string<a href="#converting-a-c-string-to-a-zig-string" arialabel="Anchor"> 🔗︎</a></h3><p>At this point, I’ve got the string as a <code>[*:0]u8</code> (unknown length, zero-terminated Zig slice), but I want to return <code>[:0]u8</code> (length-aware, null-terminated Zig slice). How do I convert a C-style string to a Zig slice?</p><p>In <a href="https://mtlynch.io/notes/zig-strings-call-c-code/#improving-the-wrapper-with-zig-managed-buffers">my previous post</a>, I converted a C string to a Zig string with this process:</p><ol><li>Create a Zig slice of the C string using <a href="https://ziglang.org/documentation/0.11.0/std/#A;std:mem.span"><code>std.mem.span</code></a>.</li><li>Use <a href="https://ziglang.org/documentation/0.11.0/std/#A;std:mem.Allocator.dupeZ"><code>allocator.dupeZ</code></a> to copy the contents of the slice into a newly allocated Zig slice.</li></ol><p>That process would work here, but I’d be doing a useless work in step (1). <code>std.mem.span</code> has to iterate the string to find the null terminator. In this code, I already know where the null terminator is because <code>us_base64_encode</code> stores that information in the <code>allocatedSize</code> parameter.</p><p>Instead, I create a length-aware Zig slice of the <code>cEncoded</code> slice like this:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>// The allocatedSize includes the null terminator, so subtract 1 to get the
</span></span></span><span><span><span>// number of non-null characters in the string.
</span></span></span><span><span><span></span><span>const</span><span> </span>cEncodedLength<span> </span>=<span> </span>allocatedSize<span> </span>-<span> </span><span>1</span>;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>// Convert cEncoded (unknown length slice) to a length-aware slice.
</span></span></span><span><span><span></span><span>const</span><span> </span>outputLengthAware:<span> </span>[:<span>0</span>]<span> </span>=<span> </span>cEncoded[<span>0</span>..cEncodedLength<span> </span>:<span>0</span>];<span>
</span></span></span></code></pre></div><p>At this point, I can complete the implementation of my wrapper function:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>fn</span><span> </span>base64Encode(allocator:<span> </span>std.mem.Allocator,<span> </span>data:<span> </span>[]<span>const</span><span> </span><span>u8</span>)<span> </span>![:<span>0</span>]<span>u8</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>var</span><span> </span>cEncoded:<span> </span>[*c]<span>u8</span><span> </span>=<span> </span><span>null</span>;<span>
</span></span></span><span><span><span>    </span><span>var</span><span> </span>allocatedSize:<span> </span><span>usize</span><span> </span>=<span> </span><span>0</span>;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span>ustreamer.us_base64_encode(data.ptr,<span> </span>data.len,<span> </span>&amp;cEncoded,<span> </span>&amp;allocatedSize);<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>// Get the output as a non-optional type.
</span></span></span><span><span><span></span><span>    </span><span>const</span><span> </span>output:<span> </span>[*:<span>0</span>]<span>u8</span><span> </span>=<span> </span>cEncoded<span> </span><span>orelse</span><span> </span><span>return</span><span> </span><span>error</span>.UnexpectedNull;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>// Free the C-allocated memory buffer before exiting the function.
</span></span></span><span><span><span></span><span>    </span><span>defer</span><span> </span>std.c.free(cEncoded);<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>// The allocatedSize includes the null terminator, so subtract 1 to get the
</span></span></span><span><span><span></span><span>    </span><span>// number of non-null characters in the string.
</span></span></span><span><span><span></span><span>    </span><span>const</span><span> </span>cEncodedLength<span> </span>=<span> </span>allocatedSize<span> </span>-<span> </span><span>1</span>;<span>
</span></span></span><span><span><span>    </span><span>return</span><span> </span>allocator.dupeZ(<span>u8</span>,<span> </span>cEncoded[<span>0</span>..cEncodedLength<span> </span>:<span>0</span>]);<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>To call <code>dupeZ</code>, I need a Zig allocator, so I adjusted the semantics of my <code>base64Encode</code> wrapper to accept a <code>std.mem.Allocator</code> type.</p><h3 id="tying-it-all-together">Tying it all together<a href="#tying-it-all-together" arialabel="Anchor"> 🔗︎</a></h3><p>With my Zig wrapper in place, it’s now trivial to exercise the C <code>us_base64_encode</code> function from Zig.</p><p>Recall that my previous code looked like this:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>const</span><span> </span>input<span> </span>=<span> </span><span>"hello, world!"</span>;<span>
</span></span></span><span><span><span></span><span>var</span><span> </span>cEncoded:<span> </span>?[*:<span>0</span>]<span>u8</span><span> </span>=<span> </span><span>null</span>;<span>
</span></span></span><span><span><span></span><span>var</span><span> </span>allocatedSize:<span> </span><span>usize</span><span> </span>=<span> </span><span>0</span>;<span>
</span></span></span><span><span><span></span>ustreamer.us_base64_encode(input.ptr,<span> </span>input.len,<span> </span>&amp;cEncoded,<span> </span>&amp;allocatedSize);<span>
</span></span></span><span><span><span></span><span>const</span><span> </span>output:<span> </span>[*:<span>0</span>]<span>u8</span><span> </span>=<span> </span>cEncoded<span> </span><span>orelse</span><span> </span><span>return</span><span> </span><span>error</span>.UnexpectedNull;<span>
</span></span></span><span><span><span></span><span>defer</span><span> </span>std.c.free(cEncoded);<span>
</span></span></span></code></pre></div><p>With my Zig wrapper, the semantics simplify to two lines:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>const</span><span> </span>output<span> </span>=<span> </span><span>try</span><span> </span>base64Encode(allocator,<span> </span><span>"hello, world!"</span>);<span>
</span></span></span><span><span><span></span><span>defer</span><span> </span>allocator.free(output);<span>
</span></span></span></code></pre></div><p>Here’s the full example:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>const</span><span> </span>std<span> </span>=<span> </span><span>@import</span>(<span>"std"</span>);<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>// Import the base64 implementation from uStreamer's C source file.
</span></span></span><span><span><span></span><span>const</span><span> </span>ustreamer<span> </span>=<span> </span><span>@cImport</span>({<span>
</span></span></span><span><span><span>    </span><span>@cInclude</span>(<span>"libs/base64.c"</span>);<span>
</span></span></span><span><span><span></span>});<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span><span> </span>base64Encode(allocator:<span> </span>std.mem.Allocator,<span> </span>data:<span> </span>[]<span>const</span><span> </span><span>u8</span>)<span> </span>![:<span>0</span>]<span>u8</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>var</span><span> </span>cEncodedOptional:<span> </span>?[*:<span>0</span>]<span>u8</span><span> </span>=<span> </span><span>null</span>;<span>
</span></span></span><span><span><span>    </span><span>var</span><span> </span>allocatedSize:<span> </span><span>usize</span><span> </span>=<span> </span><span>0</span>;<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span>ustreamer.us_base64_encode(data.ptr,<span> </span>data.len,<span> </span>&amp;cEncodedOptional,<span> </span>&amp;allocatedSize);<span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span>cEncoded:<span> </span>[*:<span>0</span>]<span>u8</span><span> </span>=<span> </span>cEncodedOptional<span> </span><span>orelse</span><span> </span><span>return</span><span> </span><span>error</span>.UnexpectedNull;<span>
</span></span></span><span><span><span>    </span><span>defer</span><span> </span>std.c.free(cEncodedOptional);<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span>cEncodedLength<span> </span>=<span> </span>allocatedSize<span> </span>-<span> </span><span>1</span>;<span>
</span></span></span><span><span><span>    </span><span>return</span><span> </span>allocator.dupeZ(<span>u8</span>,<span> </span>cEncoded[<span>0</span>..cEncodedLength<span> </span>:<span>0</span>]);<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>pub</span><span> </span><span>fn</span><span> </span>main()<span> </span>!<span>void</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>var</span><span> </span>gpa<span> </span>=<span> </span>std.heap.GeneralPurposeAllocator(.{}){};<span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span>allocator<span> </span>=<span> </span>gpa.allocator();<span>
</span></span></span><span><span><span>    </span><span>defer</span><span> </span>_<span> </span>=<span> </span>gpa.deinit();<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span>input<span> </span>=<span> </span><span>"hello, world!"</span>;<span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span>output<span> </span>=<span> </span><span>try</span><span> </span>base64Encode(allocator,<span> </span>input);<span>
</span></span></span><span><span><span>    </span><span>defer</span><span> </span>allocator.free(output);<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>// Print the input and output of the base64 encode operation.
</span></span></span><span><span><span></span><span>    </span>std.debug.print(<span>"input:       {s}</span><span>\n</span><span>"</span>,<span> </span>.{input});<span>
</span></span></span><span><span><span>    </span>std.debug.print(<span>"output:      {s}</span><span>\n</span><span>"</span>,<span> </span>.{output});<span>
</span></span></span><span><span><span>    </span>std.debug.print(<span>"output size: {d}</span><span>\n</span><span>"</span>,<span> </span>.{output.len});<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><div><pre tabindex="0"><code data-lang="bash"><span><span>$ zig build run
</span></span><span><span>input:       hello, world!
</span></span><span><span>output:      <span>aGVsbG8sIHdvcmxkIQ</span>==
</span></span><span><span>output size: <span>20</span>
</span></span></code></pre></div><p>The output size is now <code>20</code> instead of <code>21</code> because the underlying data type changed. Previously, I was printing the output size parameter that <code>us_base64_encode</code> populated, which included the null terminator. Now, I’m using the <code>.len</code> property of the output string, which does not include the null terminator.</p><p>The complete example at this stage <a href="https://github.com/tiny-pilot/ustreamer/tree/zig-20-wrapper-fn">is on Github</a>.</p><h2 id="creating-the-first-unit-test">Creating the first unit test<a href="#creating-the-first-unit-test" arialabel="Anchor"> 🔗︎</a></h2><p>Now that I can call the C <code>us_base64_encode</code> function through a convenient Zig wrapper, I’m ready to start writing unit tests to verify that the C implementation is correct.</p><p>The first thing I need to do is make a couple of small adjustments to my <code>build.zig</code> file so that the unit tests can access libc and uStreamer’s C source files:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>// build.zig
</span></span></span><span><span><span></span><span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span>unit_tests<span> </span>=<span> </span>b.addTest(.{<span>
</span></span></span><span><span><span>        </span>.root_source_file<span> </span>=<span> </span>.{<span> </span>.path<span> </span>=<span> </span><span>"src/main.zig"</span><span> </span>},<span>
</span></span></span><span><span><span>        </span>.target<span> </span>=<span> </span>target,<span>
</span></span></span><span><span><span>        </span>.optimize<span> </span>=<span> </span>optimize,<span>
</span></span></span><span><span><span>    </span>});<span>
</span></span></span><span><span><span>    </span>unit_tests.linkLibC();<span>                          </span><span>// Link against libc.
</span></span></span><span><span><span></span><span>    </span>unit_tests.addIncludePath(.{<span> </span>.path<span> </span>=<span> </span><span>"src"</span><span> </span>});<span>  </span><span>// Search src path for includes.
</span></span></span></code></pre></div><p>I’ve already done the heavy lifting here by writing my Zig wrapper function, so writing my first unit test is straightforward:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>// src/main.zig
</span></span></span><span><span><span></span><span>
</span></span></span><span><span><span></span><span>test</span><span> </span><span>"encode simple string as base64"</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span>allocator<span> </span>=<span> </span>std.testing.allocator;<span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span>actual<span> </span>=<span> </span><span>try</span><span> </span>base64Encode(allocator,<span> </span><span>"hello, world!"</span>);<span>
</span></span></span><span><span><span>    </span><span>defer</span><span> </span>allocator.free(actual);<span>
</span></span></span><span><span><span>    </span><span>try</span><span> </span>std.testing.expectEqualStrings(<span>"aGVsbG8sIHdvcmxkIQ=="</span>,<span> </span>actual);<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>The <code>zig build test</code> command runs my unit test:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ zig build <span>test</span> --summary all
</span></span><span><span>Build Summary: 3/3 steps succeeded; 1/1 tests passed
</span></span><span><span><span>test</span> success
</span></span><span><span>└─ run <span>test</span> <span>1</span> passed 1ms MaxRSS:1M
</span></span><span><span>   └─ zig <span>test</span> Debug native success 2s MaxRSS:211M
</span></span></code></pre></div><p>Success! My first unit test is working and exercising the C code.</p><p>The complete example at this stage <a href="https://github.com/tiny-pilot/ustreamer/tree/zig-30-unit-test">is on Github</a>.</p><h2 id="checking-for-false-positive-test-results">Checking for false positive test results<a href="#checking-for-false-positive-test-results" arialabel="Anchor"> 🔗︎</a></h2><p>My unit test is succeeding, but I want to ensure that the test is truly executing the C code and not just returning a false positive. I can verify this by intentionally introducing a bug into the C code.</p><p>This is a snippet from the implementation of <a href="https://github.com/pikvm/ustreamer/blob/v5.45/src/libs/base64.c"><code>base64.c</code></a>:</p><div><pre tabindex="0"><code data-lang="c"><span><span><span>#    define OCTET(_name) unsigned _name = (data_index &lt; size ? (uint8_t)data[data_index++] : 0)
</span></span></span><span><span><span></span>    <span>OCTET</span>(octet_a);
</span></span><span><span>    <span>OCTET</span>(octet_b);
</span></span><span><span>    <span>OCTET</span>(octet_c);
</span></span><span><span><span>#    undef OCTET
</span></span></span></code></pre></div><p>Let me try swapping the order of these two lines:</p><div><pre tabindex="0"><code data-lang="c"><span><span>    <span>OCTET</span>(octet_a);
</span></span><span><span>    <span>OCTET</span>(octet_c); <span>// I've swapped these
</span></span></span><span><span><span></span>    <span>OCTET</span>(octet_b); <span>// two lines.
</span></span></span></code></pre></div><p>And here’s what happens when I try re-running my unit test on the C function after my tampering:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>$ zig build <span>test</span> --summary all
</span></span><span><span>run test: error: <span>'test.encode simple string as base64'</span> failed: ====== expected this output: =========
</span></span><span><span><span>aGVsbG8sIHdvcmxkIQ</span>==␃
</span></span><span><span>
</span></span><span><span>======== instead found this: =========
</span></span><span><span><span>aGxlbCxvIG93cmRsIQ</span>==␃
</span></span></code></pre></div><p>Cool, the test works!</p><p>When I introduced a bug into <code>us_base64_encode</code>, my test failed and revealed the bug.</p><h2 id="adding-multiple-unit-tests">Adding multiple unit tests<a href="#adding-multiple-unit-tests" arialabel="Anchor"> 🔗︎</a></h2><p>I’d like to extend my single test case into many test cases to increase my confidence that I’m exercising more of the C function’s logic.</p><p>Half of the lines in my first unit test were boilerplate around managing memory, so I’d like to avoid repeating that for each test. I wrote a utility function to capture the boilerplate:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>fn</span><span> </span>testBase64Encode(<span>
</span></span></span><span><span><span>    </span>input:<span> </span>[]<span>const</span><span> </span><span>u8</span>,<span>
</span></span></span><span><span><span>    </span>expected:<span> </span>[:<span>0</span>]<span>const</span><span> </span><span>u8</span>,<span>
</span></span></span><span><span><span></span>)<span> </span>!<span>void</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span>allocator<span> </span>=<span> </span>std.testing.allocator;<span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span>actual<span> </span>=<span> </span><span>try</span><span> </span>base64Encode(allocator,<span> </span>input);<span>
</span></span></span><span><span><span>    </span><span>defer</span><span> </span>allocator.free(actual);<span>
</span></span></span><span><span><span>    </span><span>try</span><span> </span>std.testing.expectEqualStrings(expected,<span> </span>actual);<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><p>My test utility function allows me to add new tests easily:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>test</span><span> </span><span>"encode strings as base64"</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>try</span><span> </span>testBase64Encode(<span>""</span>,<span> </span><span>""</span>);<span>
</span></span></span><span><span><span>    </span><span>try</span><span> </span>testBase64Encode(<span>"h"</span>,<span> </span><span>"aA=="</span>);<span>
</span></span></span><span><span><span>    </span><span>try</span><span> </span>testBase64Encode(<span>"he"</span>,<span> </span><span>"aGU="</span>);<span>
</span></span></span><span><span><span>    </span><span>try</span><span> </span>testBase64Encode(<span>"hel"</span>,<span> </span><span>"aGVs"</span>);<span>
</span></span></span><span><span><span>    </span><span>try</span><span> </span>testBase64Encode(<span>"hell"</span>,<span> </span><span>"aGVsbA=="</span>);<span>
</span></span></span><span><span><span>    </span><span>try</span><span> </span>testBase64Encode(<span>"hello, world!"</span>,<span> </span><span>"aGVsbG8sIHdvcmxkIQ=="</span>);<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>test</span><span> </span><span>"encode raw bytes as base64"</span><span> </span>{<span>
</span></span></span><span><span><span>    </span><span>try</span><span> </span>testBase64Encode(&amp;[_]<span>u8</span>{<span>0</span>},<span> </span><span>"AA=="</span>);<span>
</span></span></span><span><span><span>    </span><span>try</span><span> </span>testBase64Encode(&amp;[_]<span>u8</span>{<span> </span><span>0</span>,<span> </span><span>0</span><span> </span>},<span> </span><span>"AAA="</span>);<span>
</span></span></span><span><span><span>    </span><span>try</span><span> </span>testBase64Encode(&amp;[_]<span>u8</span>{<span> </span><span>0</span>,<span> </span><span>0</span>,<span> </span><span>0</span><span> </span>},<span> </span><span>"AAAA"</span>);<span>
</span></span></span><span><span><span>    </span><span>try</span><span> </span>testBase64Encode(&amp;[_]<span>u8</span>{<span>255</span>},<span> </span><span>"/w=="</span>);<span>
</span></span></span><span><span><span>    </span><span>try</span><span> </span>testBase64Encode(&amp;[_]<span>u8</span>{<span> </span><span>255</span>,<span> </span><span>255</span><span> </span>},<span> </span><span>"//8="</span>);<span>
</span></span></span><span><span><span>    </span><span>try</span><span> </span>testBase64Encode(&amp;[_]<span>u8</span>{<span> </span><span>255</span>,<span> </span><span>255</span>,<span> </span><span>255</span><span> </span>},<span> </span><span>"////"</span>);<span>
</span></span></span><span><span><span></span>}<span>
</span></span></span></code></pre></div><div><pre tabindex="0"><code data-lang="bash"><span><span>$ zig build <span>test</span> --summary all
</span></span><span><span>Build Summary: 3/3 steps succeeded; 2/2 tests passed
</span></span><span><span><span>test</span> success
</span></span><span><span>└─ run <span>test</span> <span>2</span> passed 2ms MaxRSS:2M
</span></span><span><span>   └─ zig <span>test</span> Debug native success 2s MaxRSS:195M
</span></span></code></pre></div><p>The complete example at this stage <a href="https://github.com/tiny-pilot/ustreamer/tree/zig-40-multi-test">is on Github</a>.</p><h2 id="wrap-up">Wrap up<a href="#wrap-up" arialabel="Anchor"> 🔗︎</a></h2><p>Because of Zig’s excellent interoperability with C, it’s possible to add unit tests to an existing C application without modifying any of the C code or build process.</p><p>In the example I showed, the C code doesn’t know about Zig at all, and it continues to work as-is with no changes to its existing <code>Makefile</code>.</p><p>I found this exercise a useful way of learning more about both the Zig language and the C code I’m testing.</p><hr><p><em>Thanks to the Ziggit community for <a href="https://ziggit.dev/t/improving-on-c-u8-when-calling-a-c-function-that-allocates-a-string/2489?u=mtlynch">their help with this blog post</a>. Excerpts from uStreamer are used under <a href="https://github.com/pikvm/ustreamer/blob/v5.45/LICENSE">the GPLv3 license</a>.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US Steel, once the largest corporation, agrees to sell to Nippon Steel (196 pts)]]></title>
            <link>https://www.cnn.com/2023/12/18/investing/us-steel-nippon-steel-deal/index.html</link>
            <guid>38683493</guid>
            <pubDate>Mon, 18 Dec 2023 15:12:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2023/12/18/investing/us-steel-nippon-steel-deal/index.html">https://www.cnn.com/2023/12/18/investing/us-steel-nippon-steel-deal/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=38683493">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-image-variation="image" data-breakpoints="{&quot;image--eq-extra-small&quot;: 115, &quot;image--eq-small&quot;: 300}" data-uri="cms.cnn.com/_components/image/instances/clqaudfcg0003356h1dsujnml@published" data-name="01 us steel history granite city works" data-component-name="image" data-observe-resizes="" data-original-ratio="0.6666666666666666" data-original-height="2000" data-original-width="3000" data-url="https://media.cnn.com/api/v1/images/stellar/prod/230818192253-01-us-steel-history-granite-city-works.jpg?c=original" data-editable="lede" data-freewheel-lede="true">
       <picture><source height="383" width="680" media="(max-width: 479px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/230818192253-01-us-steel-history-granite-city-works.jpg?c=16x9&amp;q=h_383,w_680,c_fill/f_webp" type="image/webp"><source height="653" width="1160" media="(min-width: 480px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/230818192253-01-us-steel-history-granite-city-works.jpg?c=16x9&amp;q=h_653,w_1160,c_fill/f_webp" type="image/webp"><source height="605" width="1075" media="(min-width: 960px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/230818192253-01-us-steel-history-granite-city-works.jpg?c=16x9&amp;q=h_605,w_1075,c_fill/f_webp" type="image/webp"><source height="833" width="1480" media="(min-width: 1280px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/230818192253-01-us-steel-history-granite-city-works.jpg?c=16x9&amp;q=h_833,w_1480,c_fill/f_webp" type="image/webp"><img src="https://media.cnn.com/api/v1/images/stellar/prod/230818192253-01-us-steel-history-granite-city-works.jpg?c=16x9&amp;q=h_833,w_1480,c_fill" alt="A ladle of molten iron is poured into a Basic Oxygen Process (BOP) furnace at U. S. Steel's Granite City Works, where it will be transformed into liquid steel." onload="this.classList.remove('image__dam-img--loading')" onerror="imageLoadError(this)" height="2000" width="3000"></picture>
    </div><div data-editable="content" itemprop="articleBody" data-reorderable="content">
                    <p><cite>
      <span data-editable="location">New York</span>
      <span data-editable="source">CNN</span>
        &nbsp;—&nbsp;
    </cite>
</p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqau6g79000o83qk690oe970@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      US Steel has agreed to be bought by Nippon Steel, Japan’s largest steelmaker, in a $14.1 billion deal.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqausli800003b6h4yk5fhvq@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      The deal marks the latest step in a gradual decline for the iconic 122-year old company, which was once the largest company on the planet. It was one of the first major conglomerates and a symbol of American industrial might.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqauzxt20000356hlpml0tv5@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      But it is no longer even the largest US steelmaker, having been surpassed by Nucor Steel years ago.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqawd15y000f3b6hk7uzgvmb@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “We are confident that … this combination is truly best for all,” said US Steel CEO David Burritt. “Today’s announcement also benefits the United States — ensuring a competitive, domestic steel industry, while strengthening our presence globally.”
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqaymy0o000l3b6h452uh7cn@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “US Steel’s best days are ahead, together,” Burritt told investors at the conclusion of a conference call Monday.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqauvoht00023b6hxleqlhem@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Under terms of the deal, US Steel’s operations will retain its name and will continue to have a headquarters in Pittsburgh. But the deal could still stir opposition.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqawaixm000d3b6hrk6f7mgd@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Earlier this summer the United Steelworkers union vowed to only support a proposed offer by another unionized American steel company, Cleveland Cliffs, to buy US Steel, in a cash and stock deal then valued at $32.53 a share, or 40% less than Nippon’s all cash offer. The US Steel board <a href="https://www.cnn.com/2023/08/14/investing/us-steel-cleveland-cliffs/index.html">rejected that offer</a> and started considering other bids.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqazth19000b3b6h97ehn3os@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      The union, which has 11,000 members at US Steel, attacked the Nippon Steel deal on Monday.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqazmeox00023b6hjc1cxkgi@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “To say we’re disappointed in the announced deal between U.S. Steel and Nippon is an understatement, as it demonstrates the same greedy, shortsighted attitude that has guided U.S. Steel for far too long,” said USW President David McCall. “We remained open throughout this process to working with U.S. Steel to keep this iconic American company domestically owned and operated, but instead it chose to push aside the concerns of its dedicated workforce and sell to a foreign-owned company.”
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqazq5f400073b6hxwugenli@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      The union made clear it hopes to block the deal.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqazqfy200093b6hh90iajbq@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “We also will strongly urge government regulators to carefully scrutinize this acquisition and determine if the proposed transaction serves the national security interests of the United States and benefits workers,” it said.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqb931qd00003b6h9fnwa3r1@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Some lawmakers from rust belt states joined the union in voicing opposition to a foreign buyer Monday.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqb93tef00023b6hphfh2bk1@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “Today, a critical piece of America’s defense industrial base was auctioned off to foreigners for cash,” said Ohio’s Republican Senator JD Vance, in a statement. “I warned of this outcome months ago and will oppose it in the months ahead.”
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqbbhhff00003b6hbdd5q2cz@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Pennsylvania Democrat Sen. John Fetterman – who lives in and was previously mayor of Braddock, PA, where one of US Steel’s first steel plants still operates – slammed the deal and promised to work to block the transaction.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqbbo3wt00023b6htbm7xis6@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “It’s absolutely outrageous that US Steel has agreed to sell themselves to a foreign company,” Fetterman said in a statement. “Steel is always about security – both our national security and the economic security of our steel communities. I am committed to doing anything I can do, using my platform and my position, to block this foreign sale.”
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqbboqo500043b6hf8g10woc@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Fetterman called the deal another example of “hard-working Americans being blindsided by greedy corporations willing to sell out their communities to serve their shareholders.” He also&nbsp;<a href="https://twitter.com/SenFettermanPA/status/1736823944861110671?s=20" target="_blank">filmed a video</a>&nbsp;from the roof of his home, across the street from the US Steel plant in Braddock, PA, to blast the deal.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqav5xoq00003b6huin9ykp9@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      US Steel’s statement said that Nippon Steel has a strong track record of safety in the workplace and working collaboratively with unions, that all union contracts will remain in place and that Nippon Steel is committed to maintaining these relationships uninterrupted.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqavdblj00023b6h58wf46g9@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      US Steel was created in 1901 through a merger when a group led by J.P. Morgan and Charles Schwab, two of the world’s leading financiers of the time, bought the steel company owned by Andrew Carnegie and combined it with their holdings in its rival Federal Steel company.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqaw5wy300003b6h0ahwo8kc@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      The new company became the world’s first to be valued at more than $1 billion, double the entire US budget that year. The deal made owner Andrew Carnegie the richest man in the world.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqaw7d6h00023b6hsr16y4u7@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      In the early part of the last century, the company produced the steel that helped the United States become a global economic superpower, providing steel not just for skyscrapers, bridges and dams, but also for autos, appliances and other products craved by American consumers.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqaw7dw500043b6h2wbb9nfo@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      US Steel was so dominant, in fact, that its competitive prowess helped lead to the creation of the nation’s antitrust laws, passed in an attempt to keep the company’s strategic and financial might, and that of the Standard Oil’s, in check.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqaxuzmi00003b6hziolsw3j@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      The company’s name entered popular culture, as shorthand for both size and industrial might. In “The Godfather Part II,” mobster Hyman Roth, explaining the growing reach of the mob, tells Michael Corleone, “Michael, we’re bigger than US Steel.” When the Yankees were winning an unprecedented five straight World Series, those baseball fans who hated the team would say that “cheering for the Yankees is like cheering for US Steel.”
  </p>

  

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqawgd1f000h3b6huzxtcws2@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      But in recent years, US Steel has fallen far below other American steel companies in steel output and stock market value.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqay3jov00003b6hlouc4dco@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      And the domestic steel industry is a shell of its former self, with no company among the 10 largest steel producers around the globe.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqawgugn000j3b6h291avl1x@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “That company peaked out in 1916,” longtime steel industry analyst Charles Bradford told CNN in August when the bidding started for US Steel. “It’s been downhill ever sense. Peak output was in the 1970s. It’s done nothing for decades.”
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqay6v7a00023b6hdcsyndsz@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      According to a story in The Pittsburgh Post-Gazette on its 100th anniversary in 2001, the company’s peak employment of 340,000 came in 1943, during World War II, when it played a critical role in the Allied forces’ war efforts.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqayerq7000b3b6h3nicgpn1@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      The same article said peak steel output came in 1953, when the company&nbsp;produced 35.8 million tons of steel while steelmakers in Europe and Japan were still struggling to recover from the war. Last year, US Steel shipped only 11.2 million tons of steel from its US operations and had just under 15,000 US employees.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqay6w5e00043b6hs9aem9um@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      From its peak, the company began to fall behind upstart competitors — both foreign and domestic. First, it fell behind competitors in Japan and Germany, which were forced to rebuild from scratch after World War II and used new technologies that required far less labor and energy.
  </p>

  

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqay6w5e00053b6hinpahdb9@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “What US Steel had was 1940s technology,” Bradford said.
  </p>

  


  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqay6w5e00063b6hy4lccsog@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      US Steel and other steelmakers eventually followed those foreign competitors to upgrade factories and equipment, but they still largely used the older methods to make steel by melting raw materials such as iron ore in giant blast furnaces.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqay6w5e00073b6hhsq4k8l1@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Those “integrated” steelmakers soon lagged behind&nbsp;so-called “mini-mills,” nonunion competitors that use more efficient electric arc furnaces to&nbsp;turn old steel scrap from discarded cars and other products into new steel products.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqay8idh00093b6htuyemmje@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      The industry itself faces pressures from regulators around the globe to cut carbon emissions from a steelmaking process that is incredibly energy intensive and full of carbon emissions.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqaylito000f3b6hjhggjjc8@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      One pioneer of this mini-mill technology, Charlotte-based Nucor has a market capitalization of $42.5 billion compared to US Steel’s value of just over $14 billion as set by this deal.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqayt5o2000x3b6hujiyaa95@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Nucor is also the largest steelmaker in America by output, making an estimated 20.6 million metric tons of steel per year, ranking 16th largest in the world. That compares to 14.49 million metric tons from US Steel, including its operations in Europe, which rank 27th in the world for 2022, according to the World Steel Association.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqayljvz000h3b6hcjk0gair@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      US Steel didn’t open its first electric arc furnace until 2020.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqayljvz000i3b6hfmddgza7@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Bradford said all along the way, US Steel and other US integrated steelmaking rivals with storied names such as Bethlehem Steel, Inland Steel and LTV Steel underestimated the competitive challenge that they faced from overseas and mini-mills at home. In more recent years, steelmakers from China, India and Korea have expanded capacity far beyond US Steel. Those three other integrated steelmakers have already been swallowed up in earlier mergers and are today part of US Steel rival Cleveland Cliffs.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqayljvz000j3b6hvrs78nqb@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      By 1991, after 90 years in the Dow Jones Industrial Average, US Steel&nbsp;was bounced out of that benchmark of the nation’s 30 most important companies. At the same time, Walt Disney and JPMorgan &amp; Co., a Wall Street firm ironically named for US Steel’s founder, joined the index. It was a further sign that the nation’s economy was now focused more on information and finance, not manufacturing.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqavh8bh00043b6hdyxffywy@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Monday’s all-cash offer represents a 40% premium on the closing price for US Steel shares from Friday. Shares of <a href="https://www.cnn.com/markets/stocks/X">US Steel</a> jumped 27% in morning trading. Shares of Nippon were down 1% in trading in Japan, which closed before the deal was announced.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqaud6yp0001356h0ti3d5bn@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      <em>– CNN’s Matt Egan contributed to this report.</em>
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqb9bpg300003b6hsc8n7on6@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      <em>This story has been updated with additional context and developments.</em>
  </p>

                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Send Me to Heaven (125 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/Send_Me_To_Heaven</link>
            <guid>38683256</guid>
            <pubDate>Mon, 18 Dec 2023 14:51:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/Send_Me_To_Heaven">https://en.wikipedia.org/wiki/Send_Me_To_Heaven</a>, See on <a href="https://news.ycombinator.com/item?id=38683256">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							

						<p>From Wikipedia, the free encyclopedia</p>
					</div><div lang="en" dir="ltr" id="mw-content-text">

<table><caption>Send Me To Heaven</caption><tbody><tr><td colspan="2"><span typeof="mw:File/Frameless"><a href="https://en.wikipedia.org/wiki/File:Send_Me_To_Heaven,_logo.svg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Send_Me_To_Heaven%2C_logo.svg/120px-Send_Me_To_Heaven%2C_logo.svg.png" decoding="async" width="120" height="120" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Send_Me_To_Heaven%2C_logo.svg/180px-Send_Me_To_Heaven%2C_logo.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Send_Me_To_Heaven%2C_logo.svg/240px-Send_Me_To_Heaven%2C_logo.svg.png 2x" data-file-width="512" data-file-height="512"></a></span><p>App icon as it appears on Google Play</p></td></tr><tr><th scope="row"><a href="https://en.wikipedia.org/wiki/Programmer" title="Programmer">Developer(s)</a></th><td>Carrot Pop</td></tr><tr><th scope="row">Initial release</th><td>May&nbsp;10, 2013<span>; 10 years ago</span></td></tr><tr><th scope="row"><a href="https://en.wikipedia.org/wiki/Software_release_life_cycle" title="Software release life cycle">Stable release</a></th><td><p>1.8.80
   / September&nbsp;26, 2021<span>; 2 years ago</span></p></td></tr><tr><th scope="row"><a href="https://en.wikipedia.org/wiki/Operating_system" title="Operating system">Operating system</a></th><td><a href="https://en.wikipedia.org/wiki/Android_(operating_system)" title="Android (operating system)">Android</a></td></tr><tr><th scope="row"><a href="https://en.wikipedia.org/wiki/File_size" title="File size">Size</a></th><td><span>15 MB</span></td></tr><tr><th scope="row">Available in</th><td>English</td></tr></tbody></table>
<p><i><b>Send Me To Heaven</b></i> (officially stylized as <i><b>S.M.T.H.</b></i>) is an <a href="https://en.wikipedia.org/wiki/Android_(operating_system)" title="Android (operating system)">Android</a> application developed by Carrot Pop which measures the vertical distance that a <a href="https://en.wikipedia.org/wiki/Mobile_phone" title="Mobile phone">mobile phone</a> is thrown. Players compete against each other by seeking to throw their phones higher than others, often at the risk of damaging their phones. The app was immediately banned from the <a href="https://en.wikipedia.org/wiki/App_Store_(iOS/iPadOS)" title="App Store (iOS/iPadOS)">App Store</a> but remains available from <a href="https://en.wikipedia.org/wiki/Google_Play" title="Google Play">Google Play</a>, where it maintains a <a href="https://en.wikipedia.org/wiki/Cult_following" title="Cult following">cult following</a>.
</p>
<meta property="mw:PageProp/toc">
<h2><span id="Gameplay">Gameplay</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Send_Me_To_Heaven&amp;action=edit&amp;section=1" title="Edit section: Gameplay"><span>edit</span></a><span>]</span></span></h2>
<p>Petr Svarovsky, a Czech-born <a href="https://en.wikipedia.org/wiki/Norway" title="Norway">Norwegian</a> artist who founded Carrot Pop to develop transgressive smartphone apps,<sup id="cite_ref-ArtistProfile_1-0"><a href="#cite_note-ArtistProfile-1">[1]</a></sup> indicated during an interview with <a href="https://en.wikipedia.org/wiki/Wired_(magazine)" title="Wired (magazine)"><i>WIRED</i> magazine</a> that he hoped to have people destroy as many <a href="https://en.wikipedia.org/wiki/IPhone" title="IPhone">iPhones</a> as possible while playing his game. "The original idea was to have very expensive gadgets, which people in certain societies <a href="https://en.wikipedia.org/wiki/Conspicuous_consumption" title="Conspicuous consumption">buy just to show off</a>, and to get them to throw it."<sup id="cite_ref-WiredRigney_2-0"><a href="#cite_note-WiredRigney-2">[2]</a></sup> Nonetheless, the <a href="https://en.wikipedia.org/wiki/Mobile_game" title="Mobile game">mobile game</a> opens with a warning that requests players to be aware of their surroundings, along with a legal disclaimer absolving the developer from any injuries or damages that may result from playing.<sup id="cite_ref-LATimesRodriguez_3-0"><a href="#cite_note-LATimesRodriguez-3">[3]</a></sup><sup id="cite_ref-TimeWaxman_4-0"><a href="#cite_note-TimeWaxman-4">[4]</a></sup>
</p><p>Players are instructed to throw their phones as high as they can, with minimal rotation for most accurate results.<sup id="cite_ref-TimeWaxman_4-1"><a href="#cite_note-TimeWaxman-4">[4]</a></sup> The maximum height is calculated via the phone's <a href="https://en.wikipedia.org/wiki/Accelerometer" title="Accelerometer">accelerometer</a>.<sup id="cite_ref-LATimesRodriguez_3-1"><a href="#cite_note-LATimesRodriguez-3">[3]</a></sup> Because some phones have accelerometers positioned off-center, any rotation in those phones may confound the data.<sup id="cite_ref-WiredRigney_2-1"><a href="#cite_note-WiredRigney-2">[2]</a></sup> "Cheating" by throwing a phone from a tall building typically returns an error message.<sup id="cite_ref-LATimesRodriguez_3-2"><a href="#cite_note-LATimesRodriguez-3">[3]</a></sup> The app's calculations keep track of how long the phone takes to rise and fall, and an error message is displayed if the distance fallen exceeds the length of the ascent.<sup id="cite_ref-WiredRigney_2-2"><a href="#cite_note-WiredRigney-2">[2]</a></sup>
</p><p>Exceptionally good scores may appear on the game's leader board, which is divided into the categories World Top 10, Week Top 10, Day Top 10 and Local Top 10.<sup id="cite_ref-TimeWaxman_4-2"><a href="#cite_note-TimeWaxman-4">[4]</a></sup><sup id="cite_ref-TechTimesKeating_5-0"><a href="#cite_note-TechTimesKeating-5">[5]</a></sup> Some users reported scores as high as 40 meters (131 feet), which Svarovsky discovered was the result of players firing their phones into the air with slingshots.<sup id="cite_ref-WiredRigney_2-3"><a href="#cite_note-WiredRigney-2">[2]</a></sup><sup id="cite_ref-TimeWaxman_4-3"><a href="#cite_note-TimeWaxman-4">[4]</a></sup>
</p>
<h2><span id="Reception">Reception</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Send_Me_To_Heaven&amp;action=edit&amp;section=2" title="Edit section: Reception"><span>edit</span></a><span>]</span></span></h2>
<div>
<blockquote>
<p>No Point On Playing This UNLESS Your  [<i><a href="https://en.wikipedia.org/wiki/Sic" title="Sic">sic</a></i>] Rich And Can Buy A Few More Phones.<sup id="cite_ref-TimeWaxman_4-4"><a href="#cite_note-TimeWaxman-4">[4]</a></sup>
<br>
Already got a good ding on the corner of my <a href="https://en.wikipedia.org/wiki/Motorola_Razr" title="Motorola Razr">RAZR</a> from it. BAHAHAHAHA!<sup id="cite_ref-WiredRigney_2-4"><a href="#cite_note-WiredRigney-2">[2]</a></sup>
</p>
</blockquote>
<p><cite>Reviews for <i>Send Me To Heaven</i></cite>
</p>
</div>
<p>According to Svarovsky, the first demo of the game took place at a music festival in <a href="https://en.wikipedia.org/wiki/Oslo,_Norway" title="Oslo, Norway">Oslo, Norway</a>.<sup id="cite_ref-TimeWaxman_4-5"><a href="#cite_note-TimeWaxman-4">[4]</a></sup> Attendees were so enthusiastic with the idea that many began throwing their phones into the air without bothering to download the app.<sup id="cite_ref-WiredRigney_2-5"><a href="#cite_note-WiredRigney-2">[2]</a></sup>
</p><p>Apple rejected <i>Send Me To Heaven</i> from the <a href="https://en.wikipedia.org/wiki/App_Store_(iOS/iPadOS)" title="App Store (iOS/iPadOS)">App Store</a>, citing policies against encouraging the damage of an <a href="https://en.wikipedia.org/wiki/IOS" title="IOS">iOS</a> device.<sup id="cite_ref-NBCLeJacq_6-0"><a href="#cite_note-NBCLeJacq-6">[6]</a></sup><sup id="cite_ref-LATimesRodriguez_3-3"><a href="#cite_note-LATimesRodriguez-3">[3]</a></sup> The app was accepted by <a href="https://en.wikipedia.org/wiki/Google_Play" title="Google Play">Google Play</a> without comment.
</p><p>Users have left generally positive reviews for the app. An official <a href="https://en.wikipedia.org/wiki/Facebook" title="Facebook">Facebook</a> page allows players to share photos and videos of their attempts.<sup id="cite_ref-TechTimesKeating_5-1"><a href="#cite_note-TechTimesKeating-5">[5]</a></sup> The game attracted notoriety upon its release in 2013 and has experienced brief renewals of popularity since, most recently in 2017.<sup id="cite_ref-IrishTimesBoran_7-0"><a href="#cite_note-IrishTimesBoran-7">[7]</a></sup> As of 2021, the game remains actively updated by its developers.
</p><p>Due to the rejection of <i>Send Me To Heaven</i> from the App Store, the only iOS device currently running a copy of <i>Send Me To Heaven</i> is Petr Svarovsky's personal iPhone, which contains the app prototype. Svarovsky has attempted to sell the badly damaged iPhone multiple times as a "collectible" game item. Although badly damaged, the iPhone is still functional and is marketed as including the following bonus content: Svarovsky's ex-girlfriend's phone number, Svarovsky's dentist's phone number, some cat photographs, and some <a href="https://en.wikipedia.org/wiki/Heavy_metal_music" title="Heavy metal music">heavy metal</a> songs. The phone was offered for $30,000 on <a href="https://en.wikipedia.org/wiki/Etsy" title="Etsy">Etsy</a> and, later, for $100,000 on <a href="https://en.wikipedia.org/wiki/Saatchi_Art" title="Saatchi Art">Saatchi Art</a>.<sup id="cite_ref-8"><a href="#cite_note-8">[8]</a></sup><sup id="cite_ref-9"><a href="#cite_note-9">[9]</a></sup>
</p>
<h2><span id="Similar_applications">Similar applications</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Send_Me_To_Heaven&amp;action=edit&amp;section=3" title="Edit section: Similar applications"><span>edit</span></a><span>]</span></span></h2>
<ul><li><i><a href="https://en.wikipedia.org/wiki/I_Am_Rich" title="I Am Rich">I Am Rich</a></i>, a mobile application that was also banned from the <a href="https://en.wikipedia.org/wiki/App_Store_(iOS/iPadOS)" title="App Store (iOS/iPadOS)">App Store</a></li></ul>
<h2><span id="References">References</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Send_Me_To_Heaven&amp;action=edit&amp;section=4" title="Edit section: References"><span>edit</span></a><span>]</span></span></h2>
<div><ol>
<li id="cite_note-ArtistProfile-1"><span><b><a href="#cite_ref-ArtistProfile_1-0">^</a></b></span> <span><cite id="CITEREFCerpina2016">Cerpina, Zane (November 2, 2016). <a rel="nofollow" href="http://eejournal.no/home/2016/11/3/artist-profile-petr-svarovsky">"Artist Profile: Petr Svarovsky"</a>. <i>EE - Experimental and Emerging Art</i>. No.&nbsp;1. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" href="https://www.worldcat.org/issn/2464-448X">2464-448X</a><span>. Retrieved <span>January 13,</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=EE+-+Experimental+and+Emerging+Art&amp;rft.atitle=Artist+Profile%3A+Petr+Svarovsky&amp;rft.issue=1&amp;rft.date=2016-11-02&amp;rft.issn=2464-448X&amp;rft.aulast=Cerpina&amp;rft.aufirst=Zane&amp;rft_id=http%3A%2F%2Feejournal.no%2Fhome%2F2016%2F11%2F3%2Fartist-profile-petr-svarovsky&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASend+Me+To+Heaven"></span></span>
</li>
<li id="cite_note-WiredRigney-2"><span>^ <a href="#cite_ref-WiredRigney_2-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-WiredRigney_2-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-WiredRigney_2-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-WiredRigney_2-3"><sup><i><b>d</b></i></sup></a> <a href="#cite_ref-WiredRigney_2-4"><sup><i><b>e</b></i></sup></a> <a href="#cite_ref-WiredRigney_2-5"><sup><i><b>f</b></i></sup></a></span> <span><cite id="CITEREFRigney2013">Rigney, Ryan (September 6, 2013). <a rel="nofollow" href="https://www.wired.com/2013/09/send-me-to-heaven-app/">"Banned 'Throw Your Phone' Game Knows if You're Cheating"</a>. <i><a href="https://en.wikipedia.org/wiki/Wired_(magazine)" title="Wired (magazine)">WIRED</a></i><span>. Retrieved <span>January 13,</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=WIRED&amp;rft.atitle=Banned+%27Throw+Your+Phone%27+Game+Knows+if+You%27re+Cheating&amp;rft.date=2013-09-06&amp;rft.aulast=Rigney&amp;rft.aufirst=Ryan&amp;rft_id=https%3A%2F%2Fwww.wired.com%2F2013%2F09%2Fsend-me-to-heaven-app%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASend+Me+To+Heaven"></span></span>
</li>
<li id="cite_note-LATimesRodriguez-3"><span>^ <a href="#cite_ref-LATimesRodriguez_3-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-LATimesRodriguez_3-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-LATimesRodriguez_3-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-LATimesRodriguez_3-3"><sup><i><b>d</b></i></sup></a></span> <span><cite id="CITEREFRodriguez2013">Rodriguez, Salvador (August 7, 2013). <a rel="nofollow" href="https://www.latimes.com/business/technology/la-fi-tn-apple-rejects-throw-phone-game-20130806-story.html">"Apple rejects game app measuring the height of phone tosses"</a>. <i><a href="https://en.wikipedia.org/wiki/Los_Angeles_Times" title="Los Angeles Times">Los Angeles Times</a></i><span>. Retrieved <span>January 13,</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Los+Angeles+Times&amp;rft.atitle=Apple+rejects+game+app+measuring+the+height+of+phone+tosses&amp;rft.date=2013-08-07&amp;rft.aulast=Rodriguez&amp;rft.aufirst=Salvador&amp;rft_id=https%3A%2F%2Fwww.latimes.com%2Fbusiness%2Ftechnology%2Fla-fi-tn-apple-rejects-throw-phone-game-20130806-story.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASend+Me+To+Heaven"></span></span>
</li>
<li id="cite_note-TimeWaxman-4"><span>^ <a href="#cite_ref-TimeWaxman_4-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-TimeWaxman_4-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-TimeWaxman_4-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-TimeWaxman_4-3"><sup><i><b>d</b></i></sup></a> <a href="#cite_ref-TimeWaxman_4-4"><sup><i><b>e</b></i></sup></a> <a href="#cite_ref-TimeWaxman_4-5"><sup><i><b>f</b></i></sup></a></span> <span><cite id="CITEREFWaxman2013">Waxman, Olivia B. (August 9, 2013). <a rel="nofollow" href="https://newsfeed.time.com/2013/08/09/send-me-to-heaven-app-throw-your-phone-in-the-air-to-score-points/">"<span></span>'Send Me to Heaven' App: Throw Your Phone in the Air to Score Points"</a>. <i><a href="https://en.wikipedia.org/wiki/Time_(magazine)" title="Time (magazine)">Time</a></i><span>. Retrieved <span>January 13,</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Time&amp;rft.atitle=%27Send+Me+to+Heaven%27+App%3A+Throw+Your+Phone+in+the+Air+to+Score+Points&amp;rft.date=2013-08-09&amp;rft.aulast=Waxman&amp;rft.aufirst=Olivia+B.&amp;rft_id=https%3A%2F%2Fnewsfeed.time.com%2F2013%2F08%2F09%2Fsend-me-to-heaven-app-throw-your-phone-in-the-air-to-score-points%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASend+Me+To+Heaven"></span></span>
</li>
<li id="cite_note-TechTimesKeating-5"><span>^ <a href="#cite_ref-TechTimesKeating_5-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-TechTimesKeating_5-1"><sup><i><b>b</b></i></sup></a></span> <span><cite id="CITEREFKeating2015">Keating, Lauren (May 26, 2015). <a rel="nofollow" href="https://www.techtimes.com/articles/55566/20150526/send-heaven-android-app-will-last-game-play-phone.htm">"<span></span>'Send Me To Heaven' Android App Will Be The Last Game You Play On Your Phone"</a>. <i>Tech Times</i><span>. Retrieved <span>January 13,</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Tech+Times&amp;rft.atitle=%27Send+Me+To+Heaven%27+Android+App+Will+Be+The+Last+Game+You+Play+On+Your+Phone&amp;rft.date=2015-05-26&amp;rft.aulast=Keating&amp;rft.aufirst=Lauren&amp;rft_id=https%3A%2F%2Fwww.techtimes.com%2Farticles%2F55566%2F20150526%2Fsend-heaven-android-app-will-last-game-play-phone.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASend+Me+To+Heaven"></span></span>
</li>
<li id="cite_note-NBCLeJacq-6"><span><b><a href="#cite_ref-NBCLeJacq_6-0">^</a></b></span> <span><cite id="CITEREFLeJacq2013">LeJacq, Yannick (August 5, 2013). <a rel="nofollow" href="https://www.nbcnews.com/technolog/smartphone-game-may-destroy-your-smartphone-6C10853059">"Smartphone game may destroy your smartphone"</a>. <i><a href="https://en.wikipedia.org/wiki/NBC_News" title="NBC News">NBC News</a></i><span>. Retrieved <span>January 13,</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=NBC+News&amp;rft.atitle=Smartphone+game+may+destroy+your+smartphone&amp;rft.date=2013-08-05&amp;rft.aulast=LeJacq&amp;rft.aufirst=Yannick&amp;rft_id=https%3A%2F%2Fwww.nbcnews.com%2Ftechnolog%2Fsmartphone-game-may-destroy-your-smartphone-6C10853059&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASend+Me+To+Heaven"></span></span>
</li>
<li id="cite_note-IrishTimesBoran-7"><span><b><a href="#cite_ref-IrishTimesBoran_7-0">^</a></b></span> <span><cite id="CITEREFBoran2017">Boran, Marie (November 30, 2017). <a rel="nofollow" href="https://www.irishtimes.com/business/technology/throw-your-phone-in-the-air-like-you-don-t-care-1.3307185">"Throw your phone in the air like you don't care"</a>. <i><a href="https://en.wikipedia.org/wiki/The_Irish_Times" title="The Irish Times">The Irish Times</a></i><span>. Retrieved <span>January 13,</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Irish+Times&amp;rft.atitle=Throw+your+phone+in+the+air+like+you+don%27t+care&amp;rft.date=2017-11-30&amp;rft.aulast=Boran&amp;rft.aufirst=Marie&amp;rft_id=https%3A%2F%2Fwww.irishtimes.com%2Fbusiness%2Ftechnology%2Fthrow-your-phone-in-the-air-like-you-don-t-care-1.3307185&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASend+Me+To+Heaven"></span></span>
</li>
<li id="cite_note-8"><span><b><a href="#cite_ref-8">^</a></b></span> <span><cite id="CITEREFNieva2019">Nieva, Jason (August 14, 2019). <a rel="nofollow" href="https://www.player.one/send-me-heaven-developer-selling-phone-original-version-installed-129087">"Send Me To Heaven Developer Selling Phone With Game's Original Version Installed For $30,000"</a>. <i>Player.One</i><span>. Retrieved <span>January 13,</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Player.One&amp;rft.atitle=Send+Me+To+Heaven+Developer+Selling+Phone+With+Game%27s+Original+Version+Installed+For+%2430%2C000&amp;rft.date=2019-08-14&amp;rft.aulast=Nieva&amp;rft.aufirst=Jason&amp;rft_id=https%3A%2F%2Fwww.player.one%2Fsend-me-heaven-developer-selling-phone-original-version-installed-129087&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASend+Me+To+Heaven"></span></span>
</li>
<li id="cite_note-9"><span><b><a href="#cite_ref-9">^</a></b></span> <span><cite id="CITEREFNieva2019">Nieva, Jason (September 26, 2019). <a rel="nofollow" href="https://www.player.one/smartphone-send-me-heaven-installed-available-100-k-130261">"Smartphone With Send Me To Heaven Installed Available For $100K"</a>. <i>Player.One</i><span>. Retrieved <span>January 13,</span> 2021</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Player.One&amp;rft.atitle=Smartphone+With+Send+Me+To+Heaven+Installed+Available+For+%24100K&amp;rft.date=2019-09-26&amp;rft.aulast=Nieva&amp;rft.aufirst=Jason&amp;rft_id=https%3A%2F%2Fwww.player.one%2Fsmartphone-send-me-heaven-installed-available-100-k-130261&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASend+Me+To+Heaven"></span></span>
</li>
</ol></div>
<h2><span id="Further_reading">Further reading</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Send_Me_To_Heaven&amp;action=edit&amp;section=5" title="Edit section: Further reading"><span>edit</span></a><span>]</span></span></h2>
<ul><li><cite id="CITEREFAllain2013"><a href="https://en.wikipedia.org/wiki/Rhett_Allain" title="Rhett Allain">Allain, Rhett</a> (August 8, 2013). <a rel="nofollow" href="https://www.wired.com/2013/08/how-high-can-you-toss-your-phone/">"How High Can You Toss Your Phone?"</a>. <i><a href="https://en.wikipedia.org/wiki/Wired_(magazine)" title="Wired (magazine)">WIRED</a></i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=WIRED&amp;rft.atitle=How+High+Can+You+Toss+Your+Phone%3F&amp;rft.date=2013-08-08&amp;rft.aulast=Allain&amp;rft.aufirst=Rhett&amp;rft_id=https%3A%2F%2Fwww.wired.com%2F2013%2F08%2Fhow-high-can-you-toss-your-phone%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASend+Me+To+Heaven"></span> An overview of the mathematics involved in calculating the maximum height of a phone as it is thrown into the air.</li></ul>
<h2><span id="External_links">External links</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Send_Me_To_Heaven&amp;action=edit&amp;section=6" title="Edit section: External links"><span>edit</span></a><span>]</span></span></h2>
<ul><li><a rel="nofollow" href="http://www.carrotpop.com/portfolio_apps/index.html">Petr Svarovsky / Carrot Pop Portfolio</a></li>
<li><a rel="nofollow" href="https://www.youtube.com/watch?v=pXr84w1cWIU">S.M.T.H. (Send Me To Heaven)</a></li></ul>
<!-- 
NewPP limit report
Parsed by mw1456
Cached time: 20231215190857
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.244
Real time usage: 0.334
Preprocessor visited node count: 1927
Post‐expand include size: 29498
Template argument size: 2782
Highest expansion depth: 27
Expensive parser function count: 3
Unstrip recursion depth: 1
Unstrip post‐expand size: 34275
Lua time usage: 0.119
Lua memory usage: 6788178
Number of Wikibase entities loaded: 1
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  300.422      1 -total
 36.55%  109.806      1 Template:Reflist
 31.23%   93.834      2 Template:Infobox
 26.18%   78.655      1 Template:Infobox_software
 24.06%   72.267      4 Template:Cite_magazine
 19.38%   58.234      1 Template:Short_description
  9.35%   28.096      2 Template:Pagetype
  7.98%   23.968      6 Template:Cite_news
  7.77%   23.339      1 Template:Infobox_software/simple
  6.80%   20.441      2 Template:Start_date_and_age
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:66375537-0!canonical and timestamp 20231215190856 and revision id 1141611876. Rendering was triggered because: page-view
 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple to halt Apple Watch Series 9 and Ultra 2 sales in the US this week (105 pts)]]></title>
            <link>https://9to5mac.com/2023/12/18/apple-halting-apple-watch-series-9-and-apple-watch-ultra-2-sales/</link>
            <guid>38682631</guid>
            <pubDate>Mon, 18 Dec 2023 14:03:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://9to5mac.com/2023/12/18/apple-halting-apple-watch-series-9-and-apple-watch-ultra-2-sales/">https://9to5mac.com/2023/12/18/apple-halting-apple-watch-series-9-and-apple-watch-ultra-2-sales/</a>, See on <a href="https://news.ycombinator.com/item?id=38682631">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
			<img src="https://9to5mac.com/wp-content/uploads/sites/6/2023/12/no-watches-1.webp?w=1600" srcset="https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2023/12/no-watches-1.webp?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2023/12/no-watches-1.webp?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2023/12/no-watches-1.webp?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2023/12/no-watches-1.webp?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" width="1600" height="800" alt="" fetchpriority="high">
	
	</figure>

<p>In a statement to <em>9to5Mac</em>, Apple has announced that it will soon halt sales of its flagship Apple Watch models in the United States.</p>



<p>The Apple Watch Series 9 and Apple Watch Ultra 2 will no longer be available to purchase from Apple starting later this week.</p>



<p>The move comes <a href="https://9to5mac.com/2023/10/26/itc-order-ban-apple-watch-us/" target="_blank" rel="noreferrer noopener">following an ITC ruling</a> as part of a long-running patent dispute between Apple and medical technology company Masimo around the Apple Watch’s blood oxygen sensor technology.</p>



<p>The Apple Watch Ultra 2 and Apple Watch Series 9 will no longer be available to order from Apple’s website in the U.S. after 3 p.m. ET on Thursday, December 21. In-store inventory will no longer be available from Apple retail locations after December 24.</p>



<p>The International Trade Commission <a href="https://9to5mac.com/2023/10/26/itc-order-ban-apple-watch-us/" target="_blank" rel="noreferrer noopener">announced</a> its ruling in October, upholding a judge’s <a href="https://9to5mac.com/2023/01/11/apple-watch-patent-infringement/" target="_blank" rel="noreferrer noopener">decision from January</a>. This sent the case to the Biden administration for a 60-day Presidential Review Period.</p>



<p>During this process, President Biden could veto the ruling, although this has not yet occurred. The Presidential Review Period expires on December 25, and Apple is making this announcement today to “preemptively” take steps to comply with the ITC’s decision.</p>



<p>Apple says that the ITC’s ban only impacts sales of the Apple Watch Series 9 and Apple Watch Ultra 2 because those devices offer blood oxygen monitoring capabilities. The lower-end <a href="https://amzn.to/3vbNfum" target="_blank" rel="noreferrer noopener">Apple Watch SE</a>, which lacks this sensor, is unaffected and will remain available for sale.&nbsp;</p>



<p>The ITC’s decision only prohibits Apple from selling the affected Apple models. For now, this means the devices will remain <a href="https://amzn.to/3TvKVZj" target="_blank" rel="noreferrer noopener">available for purchase</a> from other outlets including <a href="https://amzn.to/4ajZBB3" target="_blank" rel="noreferrer noopener">Amazon and Best Buy</a>. Our friends over at <em>9to5Toys</em> also have details on some <a href="https://9to5toys.com/2023/12/18/apple-watch-series-9-ban-sale/" target="_blank" rel="noreferrer noopener">get-the-while-can Apple Watch deals</a>. </p>



<p>However, the order does block all Apple Watch Series 9 and Ultra 2 imports to the United States after December 25. At this point, Apple would also be prohibited from selling those devices to resellers, as well. So if the ruling is upheld, it could subsequently impact Apple Watch availability for other retailers as well.&nbsp;</p>



<p>Meanwhile, any Apple Watch with a blood oxygen sensor that has already been sold is unaffected by today’s news. The blood oxygen sensor first debuted with the Apple Watch Series 6 in 2020. Existing Apple Watch models with blood oxygen monitoring will continue to function without change. The ITC ban only applies to new sales of affected Apple Watch models.</p>



<p>The ITC order also makes an exception for the service, repair, or warranty period of units sold prior to December 25. </p>



<p>Here is Apple’s full statement to <em>9to5Mac</em>:</p>



<blockquote>
<p>A Presidential Review Period is in progress regarding an order from the U.S. International Trade Commission on a technical intellectual property dispute pertaining to Apple Watch devices containing the Blood Oxygen feature. While the review period will not end until December 25, Apple is preemptively taking steps to comply should the ruling stand. This includes pausing sales of the Apple Watch Series 9 and Apple Watch Ultra 2 from Apple.com starting December 21, and from Apple retail locations after December 24.</p>



<p>Apple’s teams work tirelessly to create products and services that empower users with industry-leading health, wellness, and safety features. Apple strongly disagrees with the order and is pursuing a range of legal and technical options to ensure that Apple Watch is available to customers.</p>



<p>Should the order stand, Apple will continue to take all measures to return Apple Watch Series 9 and Apple Watch Ultra 2 to customers in the U.S. as soon as possible.</p>
</blockquote>



<h2 id="h-apple-and-masimo-s-history"><strong>Apple and Masimo’s history</strong></h2>



<figure><img fetchpriority="high" decoding="async" width="1500" height="750" src="https://9to5mac.com/wp-content/uploads/sites/6/2023/05/Apple-vs-Masimo-mistrial.jpg?quality=82&amp;strip=all&amp;w=1024" alt="Apple vs Masimo mistrial | Apple Watch O2 reading" srcset="https://9to5mac.com/wp-content/uploads/sites/6/2023/05/Apple-vs-Masimo-mistrial.jpg 1500w, https://9to5mac.com/wp-content/uploads/sites/6/2023/05/Apple-vs-Masimo-mistrial.jpg?resize=155,78 155w, https://9to5mac.com/wp-content/uploads/sites/6/2023/05/Apple-vs-Masimo-mistrial.jpg?resize=655,328 655w, https://9to5mac.com/wp-content/uploads/sites/6/2023/05/Apple-vs-Masimo-mistrial.jpg?resize=768,384 768w, https://9to5mac.com/wp-content/uploads/sites/6/2023/05/Apple-vs-Masimo-mistrial.jpg?resize=1024,512 1024w, https://9to5mac.com/wp-content/uploads/sites/6/2023/05/Apple-vs-Masimo-mistrial.jpg?resize=350,175 350w, https://9to5mac.com/wp-content/uploads/sites/6/2023/05/Apple-vs-Masimo-mistrial.jpg?resize=140,70 140w, https://9to5mac.com/wp-content/uploads/sites/6/2023/05/Apple-vs-Masimo-mistrial.jpg?resize=290,145 290w, https://9to5mac.com/wp-content/uploads/sites/6/2023/05/Apple-vs-Masimo-mistrial.jpg?resize=150,75 150w" sizes="(max-width: 1500px) 100vw, 1500px"></figure>



<p>Masimo, a medical technology company, has been embroiled in multiple legal disputes with Apple for years. The disagreements center around accusations from Masimo that Apple Watch blood oxygen sensor technology infringes on several Masimo patents.</p>



<p>There are two parts to this situation. First, there’s a <a href="https://9to5mac.com/2020/01/09/apple-masimo-apple-watch-lawsuit/" target="_blank" rel="noreferrer noopener">lawsuit filed by Masimo</a> against Apple in the US District Court in the Central District of California in early 2020.</p>



<p>Second, there’s a case filed by Masimo with the International Trade Commission <a href="https://9to5mac.com/2021/06/30/apple-watch-series-6-import-ban-masimo/" target="_blank" rel="noreferrer noopener">in June 2021</a>.</p>



<p>Masimo started its campaign with the ITC because it was frustrated by the slow pace of the initial district court case. The ITC complaint is what is pressuring Apple to preemptively halt Apple Watch Series 9 and Apple Watch Ultra 2 sales in the United States.&nbsp;</p>



<h2 id="h-the-itc-case-and-apple-watch-ban"><strong>The ITC case and Apple Watch ban</strong></h2>



<p>In its initial filing with the ITC, Masimo accused Apple of 103 instances of patent infringement across five different patents. However, the ITC found that Apple infringed on only two patents, covering five different instances of patent infringements –&nbsp;each related to the Apple Watch’s pulse oximeter feature. </p>



<p>The ITC handed down <a href="https://9to5mac.com/2023/10/26/itc-order-ban-apple-watch-us/">this order in October</a>, starting the clock on a 60-day Presidential Review Period, now set to expire on December 25. The Biden administration can step in and veto the ITC ban, but so far the White House has chosen not to act. </p>



<p>Apple emphasizes that today’s announcement and upcoming suspension of Apple Watch sales is the company “preemptively taking steps to comply should the ruling stand.”</p>



<p>It is rare for a president to veto a decision from the ITC, although Apple is no stranger to the process. The last time such a veto occurred was in 2013 when <a href="https://9to5mac.com/2013/08/03/president-obama-vetos-apple-iphone-4-3g-ipad-2-product-ban/" target="_blank" rel="noreferrer noopener">President Obama vetoed</a> a ban on the iPhone as part of Apple’s extended legal dispute with Samsung. Prior to that, the previous presidential veto involved Samsung when the Reagan administration vetoed an ITC ban on all products using Samsung semiconductor memory chip imports in 1987.&nbsp;</p>



<h2 id="h-the-impact-of-an-apple-watch-ban">The impact of an Apple Watch ban</h2>



<p>Barring a last-minute veto, why might the Apple Watch ban occur despite the iPhone ban being avoided? Experts <a href="https://news.bloomberglaw.com/ip-law/dear-santa-will-us-trade-ban-on-apple-watch-ruin-christmas" target="_blank" rel="noreferrer noopener">have argued</a> that the Apple Watch doesn’t have the same economic impact as the iPhone, making a Biden veto of the ITC ruling unlikely.</p>



<figure><img decoding="async" width="2000" height="1000" src="https://9to5mac.com/wp-content/uploads/sites/6/2023/01/apple-watch-ultra-action-button.jpg?quality=82&amp;strip=all&amp;w=1024" alt="free apple watch ultra" srcset="https://9to5mac.com/wp-content/uploads/sites/6/2023/01/apple-watch-ultra-action-button.jpg 2000w, https://9to5mac.com/wp-content/uploads/sites/6/2023/01/apple-watch-ultra-action-button.jpg?resize=155,78 155w, https://9to5mac.com/wp-content/uploads/sites/6/2023/01/apple-watch-ultra-action-button.jpg?resize=655,328 655w, https://9to5mac.com/wp-content/uploads/sites/6/2023/01/apple-watch-ultra-action-button.jpg?resize=768,384 768w, https://9to5mac.com/wp-content/uploads/sites/6/2023/01/apple-watch-ultra-action-button.jpg?resize=1024,512 1024w, https://9to5mac.com/wp-content/uploads/sites/6/2023/01/apple-watch-ultra-action-button.jpg?resize=1536,768 1536w, https://9to5mac.com/wp-content/uploads/sites/6/2023/01/apple-watch-ultra-action-button.jpg?resize=350,175 350w, https://9to5mac.com/wp-content/uploads/sites/6/2023/01/apple-watch-ultra-action-button.jpg?resize=140,70 140w, https://9to5mac.com/wp-content/uploads/sites/6/2023/01/apple-watch-ultra-action-button.jpg?resize=1600,800 1600w, https://9to5mac.com/wp-content/uploads/sites/6/2023/01/apple-watch-ultra-action-button.jpg?resize=290,145 290w, https://9to5mac.com/wp-content/uploads/sites/6/2023/01/apple-watch-ultra-action-button.jpg?resize=150,75 150w" sizes="(max-width: 2000px) 100vw, 2000px"></figure>



<p>Apple sees things differently, arguing that the ITC’s finding was unfounded and should be reversed. The company has outlined multiple reasons why it believes the Biden administration should step in and veto the ruling.&nbsp;&nbsp;</p>



<p>Apple believes that the ITC’s decision will harm Apple suppliers as well as consumers, potentially leading to a greater impact on the overall economy.</p>



<p>Apple’s wearables business generated $13.48 billion in revenue during the Q1 2023 holiday quarter. This number underscores the impact of the Apple Watch for both Apple and its broader supply chain economy. </p>



<p>The company also emphasizes the Apple Watch’s life-saving ability to help users discover potential issues with their health. In its lobbying with the United States Trade Representation, Apple has enlisted the American Heart Association and other leading health organizations and physicians to tout the health benefits of the Apple Watch hardware.</p>



<p>Another factor Apple believes the ITC should consider is the impact this could have on ongoing and future clinical health studies that rely on the Apple Watch. </p>



<p>Apple says Masimo has attempted to use this litigation against Apple as a way to boost the launch of its <a href="https://9to5mac.com/2022/10/24/apple-watch-clone/" target="_blank" rel="noreferrer noopener">own smartwatch product</a>. Apple filed two patent infringement lawsuits against Masimo in October 2022, accusing the company of copying patented features of the Apple Watch.</p>



<p>If the ITC decision is upheld, Apple says that Masimo would see no real benefit itself because the Masimo smartwatch is not a substitute for the Apple Watch. </p>



<h2 id="h-what-happens-next"><strong>What happens next?</strong></h2>



<p>As of right now, there is no timeline on how long the Apple Watch Ultra 2 and Apple Watch Series 9 will be unavailable for purchase. The Biden administration could still step in and veto the ITC exclusion. If the ITC’s decision is upheld, there are a few ways forward. </p>



<p>Apple can appeal the ITC’s final decision with the US Court of Appeals for the Federal Circuit once the Presidential Review Period has expired. As such, the company tells <em>9to5Mac</em> that it plans to file an appeal on December 26. Appealing the decision, however, will not delay the ban on Apple Watch Series 9 and Apple Watch Ultra 2 sales and imports.</p>



<p>The two Masimo patents that the ITC says Apple Watch infringes aren’t set to expire until August 2028.</p>



<figure><img loading="lazy" decoding="async" width="2000" height="1047" src="https://9to5mac.com/wp-content/uploads/sites/6/2022/10/apple-watch-blood-oxygen.jpg?quality=82&amp;strip=all&amp;w=1024" alt="apple watch blood oxygen study" srcset="https://9to5mac.com/wp-content/uploads/sites/6/2022/10/apple-watch-blood-oxygen.jpg 2000w, https://9to5mac.com/wp-content/uploads/sites/6/2022/10/apple-watch-blood-oxygen.jpg?resize=155,81 155w, https://9to5mac.com/wp-content/uploads/sites/6/2022/10/apple-watch-blood-oxygen.jpg?resize=655,343 655w, https://9to5mac.com/wp-content/uploads/sites/6/2022/10/apple-watch-blood-oxygen.jpg?resize=768,402 768w, https://9to5mac.com/wp-content/uploads/sites/6/2022/10/apple-watch-blood-oxygen.jpg?resize=1024,536 1024w, https://9to5mac.com/wp-content/uploads/sites/6/2022/10/apple-watch-blood-oxygen.jpg?resize=1536,804 1536w, https://9to5mac.com/wp-content/uploads/sites/6/2022/10/apple-watch-blood-oxygen.jpg?resize=350,183 350w, https://9to5mac.com/wp-content/uploads/sites/6/2022/10/apple-watch-blood-oxygen.jpg?resize=140,73 140w, https://9to5mac.com/wp-content/uploads/sites/6/2022/10/apple-watch-blood-oxygen.jpg?resize=1600,838 1600w, https://9to5mac.com/wp-content/uploads/sites/6/2022/10/apple-watch-blood-oxygen.jpg?resize=150,79 150w" sizes="(max-width: 2000px) 100vw, 2000px"></figure>



<p>There are other paths Apple can pursue, including a potential settlement and licensing agreement with Masimo. It can also attempt to design around those two Masimo patents, such as with firmware changes to the Apple Watch software.</p>



<p>But at this point, Apple has not shared any future plans. The company says additional information will be available at the conclusion of the Presidential Review Period on December 25.</p>



<p>Ultimately, there are still a lot of unknowns about what happens next considering this unprecedented development. Apple says that it will “continue to take all measures to return Apple Watch Series 9 and Apple Watch Ultra 2 to customers in the U.S. as soon as possible.”</p>



<p>In a previous statement, Masimo said that the ITC’s ban “sends a powerful message that even the world’s largest company is not above the law.”</p>



<h2 id="h-a-separate-district-court-case"><strong>A separate district court case</strong></h2>



<p>Separately, Masimo filed a lawsuit <a href="https://9to5mac.com/2020/01/09/apple-masimo-apple-watch-lawsuit/" target="_blank" rel="noreferrer noopener">against Apple in early 2020</a>, accusing Apple of patent infringement and trade secret misappropriation. Apple challenged the patents in that case with the United States Patent Office, asking the agency to re-review the patents that were initially granted to Masimo.</p>




	<p>The Patent Trial and Appeal Board reviewed 17 different Masimo patents as part of this process and found that 15 of them were invalid. Masimo is appealing those decisions.</p>



<p>As for Masimo’s accusations of trade secret misappropriation, that case went to trial back in May. The judge rejected five out of 10 of Masimo’s claims, saying there was not enough evidence to send those claims to the jury.</p>



<p>The remaining claims were put in front of the jury, where six of the seven jurors found in favor of Apple. The remaining juror disagreed, and the jury eventually concluded that it would not be possible to reach a unanimous verdict. The judge in the case declared a mistrial, and it will be retried at a yet-to-be-determined date.</p>



<p><strong>Follow Chance</strong>: <a href="https://www.threads.net/@ChanceHMiller" target="_blank" rel="noreferrer noopener">Threads</a>, <a href="https://twitter.com/chancehmiller" target="_blank" rel="noreferrer noopener">Twitter</a>, <a href="https://www.instagram.com/chancehmiller/" target="_blank" rel="noreferrer noopener">Instagram</a>, and <a href="https://mastodon.social/@ChanceHMiller" target="_blank" rel="noreferrer noopener">Mastodon</a>.</p>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBggKMLOFATDAGg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add 9to5Mac to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://9to5mac.com/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Figma and Adobe are abandoning our proposed merger (1684 pts)]]></title>
            <link>https://www.figma.com/blog/figma-adobe-abandon-proposed-merger/</link>
            <guid>38681861</guid>
            <pubDate>Mon, 18 Dec 2023 13:04:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.figma.com/blog/figma-adobe-abandon-proposed-merger/">https://www.figma.com/blog/figma-adobe-abandon-proposed-merger/</a>, See on <a href="https://news.ycombinator.com/item?id=38681861">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main" tabindex="-1" lang="en"><div><p><time datetime="December 18, 2023">December 18, 2023</time></p><div><p><img src="data:image/jpeg;base64,/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAUABQDASIAAhEBAxEB/8QAGAABAQEBAQAAAAAAAAAAAAAAAAYDBQj/xAAnEAABBAEDBAAHAAAAAAAAAAABAAIDBAUGERIHITFRExQyM0FSYf/EABcBAAMBAAAAAAAAAAAAAAAAAAABAwT/xAAaEQEBAQEAAwAAAAAAAAAAAAABAAIRAxIx/9oADAMBAAIRAxEAPwChyfVai+nEzCRuluWjwg5jZvL2VPQ6+1TpbKuGrImWsc8/dhH0k+NipmaizAw46W1WjElV3I8ndiP57VNrjK15tHyyfAYYjx35bDz69qL0bV4s51hX6VHX6vadmiD5HSsJ/Bai8/8AzOL2bxrOI2/ZE+NH2LHVmRt3sxYZame9kTixjSewAXKfPNJGI5JZHMHhpcSAiKpKwPY9kREov//Z" alt="" data-lqip="true"><img data-loading="true" loading="eager" alt="" src="https://cdn.sanity.io/images/599r6htc/localized/672d9533efa16607fd9f84281a4d158c6a9fd048-400x400.jpg?w=400&amp;h=400&amp;q=75&amp;fit=max&amp;auto=format" srcset="https://cdn.sanity.io/images/599r6htc/localized/672d9533efa16607fd9f84281a4d158c6a9fd048-400x400.jpg?q=75&amp;fit=max&amp;auto=format&amp;dpr=0.5 200w, https://cdn.sanity.io/images/599r6htc/localized/672d9533efa16607fd9f84281a4d158c6a9fd048-400x400.jpg?q=75&amp;fit=max&amp;auto=format&amp;dpr=0.75 300w, https://cdn.sanity.io/images/599r6htc/localized/672d9533efa16607fd9f84281a4d158c6a9fd048-400x400.jpg?q=75&amp;fit=max&amp;auto=format&amp;dpr=2 400w"></p><p>Dylan Field<span>Co-founder &amp; Chief Executive Officer, Figma</span></p></div></div><section><div id="progress-indicator-target"><p>Fifteen months into the regulatory review process, Figma and Adobe no longer see a path toward regulatory approval of our proposed acquisition.</p><div colorscheme="[object Object]"><p>Figma and Adobe have reached a joint decision to end our pending acquisition. It’s not the outcome we had hoped for, but despite thousands of hours spent with regulators around the world detailing differences between our businesses, our products, and the markets we serve, we no longer see a path toward regulatory approval of&nbsp;the&nbsp;deal.</p><p>We entered into this agreement 15 months ago with the goal of accelerating what both Adobe and Figma could do for our respective communities. While we leave that future behind and continue on as an independent company, we are excited to find ways to partner for&nbsp;our&nbsp;users.</p><p>Amid the uncertainty of a pending acquisition, I am deeply proud of how the Figma team delivered for our community and feel we have only continued to accelerate our pace over the past 15 months. Our team built and shipped new products to make it easier to ideate, design and build software, including our first <a href="https://www.figma.com/blog/introducing-ai-to-figjam/">native AI features</a>, <a href="https://www.figma.com/blog/introducing-dev-mode/">Dev Mode</a>, Variables, and Advanced Prototyping. We also opened new hubs in the UK and Asia, hosted an epic <a href="https://www.figma.com/blog/config-2023-recap/">Config IRL in San Francisco</a>, <a href="https://www.figma.com/blog/ai-the-next-chapter-in-design/">acquired AI startup Diagram</a>, and added more than 500 new&nbsp;Figmates.</p><p>Figma’s founding vision was to “eliminate the gap between imagination and reality.” The shift from a physical economy to a digital economy and huge advances in AI have combined to make this aspiration feel even more urgent and within reach today than it did 11&nbsp;years&nbsp;ago.</p><p>This will be our focus moving forward. We want to make it easy for anyone to design and build digital products on a single multiplayer canvas—from start to finish, idea to production. I’m so excited for what the future holds and beyond grateful to our community for supporting us. Figma’s best, most innovative days are still ahead. See you all&nbsp;in&nbsp;2024!</p></div><div><p><img src="data:image/jpeg;base64,/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAUABQDASIAAhEBAxEB/8QAGAABAQEBAQAAAAAAAAAAAAAAAAYDBQj/xAAnEAABBAEDBAAHAAAAAAAAAAABAAIDBAUGERIHITFRExQyM0FSYf/EABcBAAMBAAAAAAAAAAAAAAAAAAABAwT/xAAaEQEBAQEAAwAAAAAAAAAAAAABAAIRAxIx/9oADAMBAAIRAxEAPwChyfVai+nEzCRuluWjwg5jZvL2VPQ6+1TpbKuGrImWsc8/dhH0k+NipmaizAw46W1WjElV3I8ndiP57VNrjK15tHyyfAYYjx35bDz69qL0bV4s51hX6VHX6vadmiD5HSsJ/Bai8/8AzOL2bxrOI2/ZE+NH2LHVmRt3sxYZame9kTixjSewAXKfPNJGI5JZHMHhpcSAiKpKwPY9kREov//Z" alt="" data-lqip="true"><img data-loading="true" loading="eager" alt="" src="https://cdn.sanity.io/images/599r6htc/localized/672d9533efa16607fd9f84281a4d158c6a9fd048-400x400.jpg?w=400&amp;h=400&amp;q=75&amp;fit=max&amp;auto=format" srcset="https://cdn.sanity.io/images/599r6htc/localized/672d9533efa16607fd9f84281a4d158c6a9fd048-400x400.jpg?q=75&amp;fit=max&amp;auto=format&amp;dpr=0.5 200w, https://cdn.sanity.io/images/599r6htc/localized/672d9533efa16607fd9f84281a4d158c6a9fd048-400x400.jpg?q=75&amp;fit=max&amp;auto=format&amp;dpr=0.75 300w, https://cdn.sanity.io/images/599r6htc/localized/672d9533efa16607fd9f84281a4d158c6a9fd048-400x400.jpg?q=75&amp;fit=max&amp;auto=format&amp;dpr=2 400w"></p><div><p>Dylan Field is the co-founder and CEO of Figma. Dylan studied computer science and mathematics at Brown University where he and his co-founder, Evan Wallace, first started experimenting with design tools built on (and for) the web. With funding from a Thiel fellowship, they began Figma. Prior to Figma, Dylan interned at O'Reilly Media, LinkedIn, and&nbsp;Flipboard.</p></div></div></div><div><form novalidate=""><div><h2>Subscribe for a Shortcut to fresh news and fun surprises</h2><div><p><label><p>I agree to opt-in to Figma's mailing list.</p></label></p></div></div></form></div><section><header><h2>Related articles</h2></header><div><a aria-label="Open blog post" tabindex="-1" href="https://www.figma.com/blog/introducing-dev-mode/"><div><p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAABYlAAAWJQFJUiTwAAADPElEQVQokS2QW0yTZwBAi4DcWhSF2OEuMtAxB5OYgZglwGAIlmrLAFtsuZQiaLVQ5FK5TOpEqHIrTRilRWXKTEw0bstiYnxasmUvS5bsxUTHls1tOmEItCAy/u8s23w6bycnR2ao+1uqPbUsLI4Axx1+YelepP70HDX2JxjqZzCcmOXIucfYO39jqOoRY7o/Gdf/xUT5Epf0z5nQrTBwLIDtTICq9lVkpuZnUrdrUYxf9uO9vCD6vNMcHbjDAcso2QedZBVfIM88gLrcib7QSUXRELWacewltxnSPeBj4yLnTvo50ftCaLYHpEH3grh10c9V30/C6v6EPfZa4vPSiXktgZikJDanpxD37i6Uqky2VuWzraaI3ToD5YeG6TD/QFvXPHV9y1S2riKraQlIPV3zwtc1g91xW+xurESuTSXkbSVBcZEEbQpnXWIM69U7iOjMQu5WIR9REd2Zyw7jB2gMk5ganlDZtMbh2jVk1c1LUkf7U3G29T5ay3kRW5xBaEESYepkQrMTCN6+meA344gwv4PCVUS0V0u0R0tUfwGbjuSQru6kpHQanR7KSiVkptYlyTH4VPQNfI/qcINQpCUQmp9IpHUvEda9hOYkEJL2EhH1Gcj7C5EPq1CMqIk6v4+N9VnsKmhCo75HWTGUasW/D5ckl29RfDp1j7q2dqHMTiY4PZ716mTCNDv/kwW/EUu4MQ35wH4UXi0KXzFRznxiK3LILPiIUs0v6EoEh4rXkNXal6TRiYC48/nPjF4ZE3nHVWxIeZlgpYJ1SjlBG8MIio0kJPMVwo/tIao3H0XvPuIa3yPDYMRU+QWNxllsxt+xVt//v3DI6xdffjbDzZvfii6ni9wDel5/K4MtCanEbU1hy7adxKem8GpuBom690mt1KCqs/Ch4xpe50M8tseMN9zFbZ9CVmVbkU5d8ItBzyLDYzOiZ+gB1o6vKKu7TmHJFAX7JzGUd9Ni09PSYuToyR4s7ddw9H+NZ/JXJr0LXD37kCvddxk+fR1ZefWaVGV9LszNK5ibV17wGSbbMoaaVUwVc7gdk3x3I49vbh3EdekGbeOPaPPN0+ad44xnFp/nD0ZHpmlq/5F/AJ6E/jM6ogRrAAAAAElFTkSuQmCC" alt="An abstracted Figma file with a toggle for developers to turn on Dev Mode" width="528" height="297" data-lqip="true"><img data-loading="true" width="528" height="297" loading="lazy" alt="An abstracted Figma file with a toggle for developers to turn on Dev Mode" src="https://cdn.sanity.io/images/599r6htc/localized/a313056d03f6e2734d587ee87c5a38c23936f8e5-5569x3132.png?rect=1,0,5568,3132&amp;w=528&amp;h=297&amp;q=75&amp;fit=max&amp;auto=format" srcset="https://cdn.sanity.io/images/599r6htc/localized/a313056d03f6e2734d587ee87c5a38c23936f8e5-5569x3132.png?w=528&amp;q=75&amp;fit=max&amp;auto=format&amp;dpr=0.5 264w, https://cdn.sanity.io/images/599r6htc/localized/a313056d03f6e2734d587ee87c5a38c23936f8e5-5569x3132.png?w=528&amp;q=75&amp;fit=max&amp;auto=format&amp;dpr=0.75 396w, https://cdn.sanity.io/images/599r6htc/localized/a313056d03f6e2734d587ee87c5a38c23936f8e5-5569x3132.png?w=528&amp;q=75&amp;fit=max&amp;auto=format 528w, https://cdn.sanity.io/images/599r6htc/localized/a313056d03f6e2734d587ee87c5a38c23936f8e5-5569x3132.png?w=528&amp;q=75&amp;fit=max&amp;auto=format&amp;dpr=1.5 792w, https://cdn.sanity.io/images/599r6htc/localized/a313056d03f6e2734d587ee87c5a38c23936f8e5-5569x3132.png?w=528&amp;q=75&amp;fit=max&amp;auto=format&amp;dpr=2 1056w"></p></div></a></div></section><p><section><h2>Create and collaborate with Figma</h2><a href="https://www.figma.com/signup?locale=en" target="_blank" rel="noreferrer">Get started for free</a></section></p></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wasm3 entering a minimal maintenance phase (470 pts)]]></title>
            <link>https://github.com/wasm3/wasm3</link>
            <guid>38681672</guid>
            <pubDate>Mon, 18 Dec 2023 12:43:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/wasm3/wasm3">https://github.com/wasm3/wasm3</a>, See on <a href="https://news.ycombinator.com/item?id=38681672">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><div dir="auto"><p dir="auto">Note</p><p dir="auto">I regret to inform the community that since <a href="https://twitter.com/vshymanskyy/status/1568657607229075456" rel="nofollow">my house was destroyed by russians who invaded my country</a>, <strong>Wasm3 will enter a minimal maintenance phase</strong>. At this time, I am unable to continue the development of new features. However, I am committed to keeping the project alive and will actively review and merge incoming Pull Requests. I deeply appreciate your understanding and support during this difficult period. <strong>Your contributions to Wasm3 are now more valuable than ever.</strong></p>
</div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/wasm3/wasm3/blob/main/extra/screenshot-ios.png"><img width="30%" src="https://github.com/wasm3/wasm3/raw/main/extra/screenshot-ios.png"></a></p>
<h2 tabindex="-1" dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/wasm3/wasm3/blob/main/extra/wasm-symbol.svg"><img src="https://github.com/wasm3/wasm3/raw/main/extra/wasm-symbol.svg" width="32" height="32"></a> Wasm3</h2>
<p dir="auto"><a href="https://github.com/vshymanskyy/StandWithUkraine/blob/main/docs/README.md"><img src="https://raw.githubusercontent.com/vshymanskyy/StandWithUkraine/main/badges/StandWithUkraine.svg" alt="StandWithUkraine"></a>
<a href="https://wapm.io/package/vshymanskyy/wasm3" rel="nofollow"><img src="https://camo.githubusercontent.com/3a7c4be43f68428ee86bfe17bc92bb5b9463f49462c8660677e96d07ad51bb8c/68747470733a2f2f7761706d2e696f2f7061636b6167652f767368796d616e736b79792f7761736d332f62616467652e737667" alt="WAPM" data-canonical-src="https://wapm.io/package/vshymanskyy/wasm3/badge.svg"></a>
<a href="https://github.com/wasm3/wasm3/issues"><img src="https://camo.githubusercontent.com/963bc146066cc6b11570ff4a4ceadb78f378cd5893b1f3cdb5cd88dc7cb1c36e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d7261772f7761736d332f7761736d333f7374796c653d666c61742d737175617265266c6162656c3d69737375657326636f6c6f723d73756363657373" alt="GitHub issues" data-canonical-src="https://img.shields.io/github/issues-raw/wasm3/wasm3?style=flat-square&amp;label=issues&amp;color=success"></a>
<a href="https://github.com/wasm3/wasm3/actions"><img src="https://camo.githubusercontent.com/14a33815462d651385c78c22cd290e3ec9bff2ae0f93e4d45968a1d67f29197b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f616374696f6e732f776f726b666c6f772f7374617475732f7761736d332f7761736d332f74657374732e796d6c3f6272616e63683d6d61696e267374796c653d666c61742d737175617265266c6f676f3d676974687562266c6162656c3d7465737473" alt="Tests status" data-canonical-src="https://img.shields.io/github/actions/workflow/status/wasm3/wasm3/tests.yml?branch=main&amp;style=flat-square&amp;logo=github&amp;label=tests"></a>
<a href="https://bugs.chromium.org/p/oss-fuzz/issues/list?can=1&amp;q=proj:wasm3" rel="nofollow"><img src="https://camo.githubusercontent.com/576ecd33f690472e3308bd0ad399e8322d29113b87099883ca024a33d7eef745/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f73732d2d66757a7a2d66757a7a696e672d737563636573733f7374796c653d666c61742d737175617265" alt="Fuzzing Status" data-canonical-src="https://img.shields.io/badge/oss--fuzz-fuzzing-success?style=flat-square"></a>
<a href="https://github.com/wasm3/wasm3"><img src="https://camo.githubusercontent.com/fa6e10811485d7022ae8c55770e22511f740aad92b141370db14c56e9fc44545/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c75653f7374796c653d666c61742d737175617265" alt="GitHub license" data-canonical-src="https://img.shields.io/badge/license-MIT-blue?style=flat-square"></a></p>
<p dir="auto">A fast WebAssembly interpreter and the most universal WASM runtime.<br>
<sub>Based on <a href="https://github.com/wasm3/wasm3/blob/main/docs/Performance.md"><strong>CoreMark 1.0</strong></a> and <a href="https://00f.net/2021/02/22/webassembly-runtimes-benchmarks" rel="nofollow"><strong>independent</strong></a> benchmarks. Your mileage may vary.</sub></p>
<p dir="auto"><a href="https://twitter.com/wasm3_engine" rel="nofollow"><img src="https://camo.githubusercontent.com/d47f801d4b10a9f29b07fde7d9580090463016618334f33cf783b1db9d1a9dd6/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f7761736d335f656e67696e653f7374796c653d666c61742d73717561726526636f6c6f723d316461316632266c6162656c3d74776974746572266c6f676f3d74776974746572" alt="Twitter" data-canonical-src="https://img.shields.io/twitter/follow/wasm3_engine?style=flat-square&amp;color=1da1f2&amp;label=twitter&amp;logo=twitter"></a>
<a href="https://discord.gg/qmZjgnd" rel="nofollow"><img src="https://camo.githubusercontent.com/c5026ad1cb55fd3dffcf4a9feb18d11d6bfb306c47640680e2de710535fb0ad3/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f3637313431353634353037333730323932353f7374796c653d666c61742d737175617265266c6f676f3d646973636f726426636f6c6f723d373238396461266c6162656c3d646973636f7264" alt="Discord" data-canonical-src="https://img.shields.io/discord/671415645073702925?style=flat-square&amp;logo=discord&amp;color=7289da&amp;label=discord"></a></p>
<h2 tabindex="-1" dir="auto">Getting Started</h2>
<p dir="auto">Here's a small <a href="https://wapm.io/package/vshymanskyy/wasm3" rel="nofollow">getting started guide</a>. Click here to start:</p>
<p dir="auto"><a href="https://webassembly.sh/?run-command=wasm3" rel="nofollow"><img src="https://github.com/wasm3/wasm3/raw/main/extra/button.png" alt="LIVE DEMO"></a></p>
<h2 tabindex="-1" dir="auto">Installation</h2>
<p dir="auto"><strong>Please follow the <a href="https://github.com/wasm3/wasm3/blob/main/docs/Installation.md">installation instructions</a>.</strong></p>
<p dir="auto">Wasm3 can also be used as a library for:</p>
<p dir="auto"><a href="https://github.com/wasm3/pywasm3"><img src="https://camo.githubusercontent.com/09b05de6e527ec5052ee033aaa57ad4a94a637cfcc8900276b3c9087ed62de1c/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f707974686f6e2e737667" width="18" height="18" data-canonical-src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons@develop/icons/python.svg"> Python3</a> │
<a href="https://github.com/Veykril/wasm3-rs"><img src="https://camo.githubusercontent.com/961ceedfe24996e8f1c466bb8f17effba0abbc45075545d9b62bafeb0627a66b/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f727573742e737667" width="18" height="18" data-canonical-src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons@develop/icons/rust.svg"> Rust</a> │
<a href="https://github.com/wasm3/wasm3"><img src="https://camo.githubusercontent.com/6ae1442dc1a0d3dceb928ae37b41849e142c203a2bffab6cda47998d5c9dfa15/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f63706c7573706c75732e737667" width="18" height="18" data-canonical-src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons@develop/icons/cplusplus.svg"> C/C++</a> │
<a href="https://github.com/matiasinsaurralde/go-wasm3"><img src="https://camo.githubusercontent.com/a22c7376805e4aac976c90fe844e758f6fe8576a6fa617e9aea77dc3bd666654/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f676f2e737667" width="18" height="18" data-canonical-src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons@develop/icons/go.svg"> GoLang</a> │
<a href="https://github.com/alichay/zig-wasm3"><img src="https://camo.githubusercontent.com/0d4113b3240164bc349c23a7f542e795798bd784725f2b838c9478251bb0e735/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f7a69672e737667" width="18" height="18" data-canonical-src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons@develop/icons/zig.svg"> Zig</a> │
<a href="https://metacpan.org/pod/Wasm::Wasm3" rel="nofollow"><img src="https://camo.githubusercontent.com/c5c861c7858d76c9163f31e8b7f55a5fe4e1471d5eb0c3f6714d12e224f8c736/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f7065726c2e737667" width="18" height="18" data-canonical-src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons@develop/icons/perl.svg"> Perl</a><br>
<a href="https://github.com/shareup/wasm-interpreter-apple"><img src="https://camo.githubusercontent.com/850f38a806ed27158a6a5f718e0c7326e2ac1791447d035d4e4f091bedc7c3a3/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f73776966742e737667" width="18" height="18" data-canonical-src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons@develop/icons/swift.svg"> Swift</a> │
<a href="https://github.com/tana/Wasm3DotNet"><img src="https://camo.githubusercontent.com/a7a6a508090beb6779b9135e922f438be6f19c8281da60834f5149e0d52f72d1/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f646f746e65742e737667" width="18" height="18" data-canonical-src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons@develop/icons/dotnet.svg"> .Net</a> │
<a href="https://github.com/beef331/wasm3"><img src="https://camo.githubusercontent.com/3759d517a62153b4973c47d452ae762c0480397e8bf2eb802081d9f3848a1ecc/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f6e696d2e737667" width="18" height="18" data-canonical-src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons@develop/icons/nim.svg"> Nim</a> │
<a href="https://github.com/wasm3/wasm3-arduino"><img src="https://camo.githubusercontent.com/60f3f4a2171971846073ed19a21a36c01069f21e883d938cfe87598f209b7669/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f61726475696e6f2e737667" width="18" height="18" data-canonical-src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons@develop/icons/arduino.svg"> Arduino, PlatformIO, Particle</a> │ <a href="https://github.com/saghul/txiki.js">QuickJS</a></p>
<h2 tabindex="-1" dir="auto">Status</h2>
<p dir="auto"><code>wasm3</code> passes the <a href="https://github.com/WebAssembly/spec/tree/master/test/core">WebAssembly spec testsuite</a> and is able to run many <code>WASI</code> apps.</p>
<p dir="auto">Minimum useful system requirements: <strong>~64Kb</strong> for code and <strong>~10Kb</strong> RAM</p>
<p dir="auto"><code>wasm3</code> runs on a wide range of architectures (<code>x86</code>, <code>x86_64</code>, <code>ARM</code>, <code>RISC-V</code>, <code>PowerPC</code>, <code>MIPS</code>, <code>Xtensa</code>, <code>ARC32</code>, ...) and <a href="https://github.com/wasm3/wasm3/blob/main/platforms">platforms</a>:</p>
<ul dir="auto">
<li><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/0fe6ddf5d7d5241ce68518e07b9f18bf982f808c789b312a3335e283af2cc39d/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f6c696e75782e737667"><img src="https://camo.githubusercontent.com/0fe6ddf5d7d5241ce68518e07b9f18bf982f808c789b312a3335e283af2cc39d/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f6c696e75782e737667" width="18" height="18" data-canonical-src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons@develop/icons/linux.svg"></a> Linux,
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/55adf930d73517390de6b22f3aa88c156538a84c0373b28416e5c17130e34850/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f77696e646f77732e737667"><img src="https://camo.githubusercontent.com/55adf930d73517390de6b22f3aa88c156538a84c0373b28416e5c17130e34850/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f77696e646f77732e737667" width="18" height="18" data-canonical-src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons@develop/icons/windows.svg"></a> Windows,
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/77a890fc5e50699ee48fe93fbe3e81067acf5f5b8bc055729d36c7dd7bc43aea/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f6170706c652e737667"><img src="https://camo.githubusercontent.com/77a890fc5e50699ee48fe93fbe3e81067acf5f5b8bc055729d36c7dd7bc43aea/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f6170706c652e737667" width="18" height="18" data-canonical-src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons@develop/icons/apple.svg"></a> OS X,
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/173700e722d00c8eaa8158c8c07bcdd1b21ae924cf71f948bfcf58f4964b472c/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f667265656273642e737667"><img src="https://camo.githubusercontent.com/173700e722d00c8eaa8158c8c07bcdd1b21ae924cf71f948bfcf58f4964b472c/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f667265656273642e737667" width="18" height="18" data-canonical-src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons@develop/icons/freebsd.svg"></a> FreeBSD,
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/eaa98f7b689b1f9d70eee17a9ddaeb416217ac9dea6613d51093bbbe647c9cce/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f616e64726f69642e737667"><img src="https://camo.githubusercontent.com/eaa98f7b689b1f9d70eee17a9ddaeb416217ac9dea6613d51093bbbe647c9cce/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f616e64726f69642e737667" width="18" height="18" data-canonical-src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons@develop/icons/android.svg"></a> Android,
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/77a890fc5e50699ee48fe93fbe3e81067acf5f5b8bc055729d36c7dd7bc43aea/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f6170706c652e737667"><img src="https://camo.githubusercontent.com/77a890fc5e50699ee48fe93fbe3e81067acf5f5b8bc055729d36c7dd7bc43aea/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f6170706c652e737667" width="18" height="18" data-canonical-src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons@develop/icons/apple.svg"></a> iOS</li>
<li><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/f1f67a18307cf58f478d7e51b05622ae5f0b02fe55b8ac448f807645d226261a/68747470733a2f2f63646e2e7261776769742e636f6d2f6665617468657269636f6e732f666561746865722f6d61737465722f69636f6e732f776966692e737667"><img src="https://camo.githubusercontent.com/f1f67a18307cf58f478d7e51b05622ae5f0b02fe55b8ac448f807645d226261a/68747470733a2f2f63646e2e7261776769742e636f6d2f6665617468657269636f6e732f666561746865722f6d61737465722f69636f6e732f776966692e737667" width="18" height="18" data-canonical-src="https://cdn.rawgit.com/feathericons/feather/master/icons/wifi.svg"></a> OpenWrt, Yocto, Buildroot (routers, modems, etc.)</li>
<li><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/e4985d07da9ed03709560a3b26c6e238b9e24a9ab313ed926f4ed5f8ce88e244/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f72617370626572727970692e737667"><img src="https://camo.githubusercontent.com/e4985d07da9ed03709560a3b26c6e238b9e24a9ab313ed926f4ed5f8ce88e244/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f72617370626572727970692e737667" width="18" height="18" data-canonical-src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons@develop/icons/raspberrypi.svg"></a> Raspberry Pi, Orange Pi and other SBCs</li>
<li><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/d46d9f8f4730eb1d393317da5202a544fa495d41989935c3cf8cff9a55d9e144/68747470733a2f2f63646e2e7261776769742e636f6d2f6665617468657269636f6e732f666561746865722f6d61737465722f69636f6e732f6370752e737667"><img src="https://camo.githubusercontent.com/d46d9f8f4730eb1d393317da5202a544fa495d41989935c3cf8cff9a55d9e144/68747470733a2f2f63646e2e7261776769742e636f6d2f6665617468657269636f6e732f666561746865722f6d61737465722f69636f6e732f6370752e737667" width="18" height="18" data-canonical-src="https://cdn.rawgit.com/feathericons/feather/master/icons/cpu.svg"></a> MCUs: Arduino, ESP8266, ESP32, Particle, ... <a href="https://github.com/wasm3/wasm3/blob/main/docs/Hardware.md">see full list</a></li>
<li><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/552d4bb144f1dfc0cb48ccc21cfdbd65f6654da9f66524444167b66e571a700e/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f66697265666f7862726f777365722e737667"><img src="https://camo.githubusercontent.com/552d4bb144f1dfc0cb48ccc21cfdbd65f6654da9f66524444167b66e571a700e/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f73696d706c652d69636f6e732f73696d706c652d69636f6e7340646576656c6f702f69636f6e732f66697265666f7862726f777365722e737667" width="18" height="18" data-canonical-src="https://cdn.jsdelivr.net/gh/simple-icons/simple-icons@develop/icons/firefoxbrowser.svg"></a> Browsers. Yes, using WebAssembly itself!</li>
<li><a target="_blank" rel="noopener noreferrer" href="https://github.com/wasm3/wasm3/blob/main/extra/wasm-symbol.svg"><img src="https://github.com/wasm3/wasm3/raw/main/extra/wasm-symbol.svg" width="18" height="18"></a> <code>wasm3</code> can execute <code>wasm3</code> (self-hosting)</li>
</ul>
<h2 tabindex="-1" dir="auto">Features</h2>
<table>
<thead>
<tr>
<th>Webassembly <a href="https://github.com/WebAssembly/proposals/blob/master/finished-proposals.md" title="WebAssembly Finished Proposals">Core Proposals</a></th>
<th>Extra</th>
</tr>
</thead>
<tbody>
<tr>
<td>☑ Import/Export of Mutable Globals</td>
<td>☑ Structured execution tracing</td>
</tr>
<tr>
<td>☑ Non-trapping float-to-int conversions</td>
<td>☑ Big-Endian systems support</td>
</tr>
<tr>
<td>☑ Sign-extension operators</td>
<td>☑ Wasm and WASI self-hosting</td>
</tr>
<tr>
<td>☑ Multi-value</td>
<td>☑ Gas metering</td>
</tr>
<tr>
<td>☑ Bulk memory operations (partial support)</td>
<td>☑ Linear memory limit (&lt; 64KiB)</td>
</tr>
<tr>
<td>☐ Multiple memories</td>
<td></td>
</tr>
<tr>
<td>☐ Reference types</td>
<td></td>
</tr>
<tr>
<td>☐ Tail call optimization</td>
<td></td>
</tr>
<tr>
<td>☐ Fixed-width SIMD</td>
<td></td>
</tr>
<tr>
<td>☐ Exception handling</td>
<td></td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">Motivation</h2>
<p dir="auto"><strong>Why use a "slow interpreter" versus a "fast JIT"?</strong></p>
<p dir="auto">In many situations, speed is not the main concern. Runtime executable size, memory usage, startup latency can be improved with the interpreter approach. Portability and security are much easier to achieve and maintain. Additionally, development impedance is much lower. A simple library like Wasm3 is easy to compile and integrate into an existing project. (Wasm3 builds in a just few seconds). Finally, on some platforms (i.e. iOS and WebAssembly itself) you can't generate executable code pages in runtime, so JIT is unavailable.</p>
<p dir="auto"><strong>Why would you want to run WASM on embedded devices?</strong></p>
<p dir="auto">Wasm3 started as a research project and remains so by any means. Evaluating the engine in different environments is part of the research. Given that we have <code>Lua</code>, <code>JS</code>, <code>Python</code>, <code>Lisp</code>, <code>...</code> running on MCUs, <code>WebAssembly</code> is a promising alternative. It provides toolchain decoupling as well as a completely sandboxed, well-defined, predictable environment. Among practical use cases we can list <code>edge computing</code>, <code>scripting</code>, <code>plugin systems</code>, running <code>IoT rules</code>, <code>smart contracts</code>, etc.</p>
<h2 tabindex="-1" dir="auto">Used by</h2>
<p dir="auto"><a href="https://wasmcloud.dev/" rel="nofollow"><img src="https://github.com/wasm3/wasm3/raw/main/extra/logos/wasmcloud.png" height="32"></a>　
<a href="https://wowcube.com/" rel="nofollow"><img src="https://github.com/wasm3/wasm3/raw/main/extra/logos/wowcube.png" height="32"></a>　
<a href="https://github.com/siemens/dtasm/tree/main/runtime/dtasm3"><img src="https://camo.githubusercontent.com/51e7cf06b3b65f05606ac3f9e70cd5bd3c00824dd6519e602f02043c113c31d3/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f7468756d622f332f33632f5369656d656e735f41475f6c6f676f2e7376672f3130323470782d5369656d656e735f41475f6c6f676f2e7376672e706e67" height="22" data-canonical-src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Siemens_AG_logo.svg/1024px-Siemens_AG_logo.svg.png"></a>　
<a href="https://scailable.net/" rel="nofollow"><img src="https://github.com/wasm3/wasm3/raw/main/extra/logos/scailable.png" height="32"></a>　
<a href="https://blynk.io/" rel="nofollow"><img src="https://github.com/wasm3/wasm3/raw/main/extra/logos/blynk.png" height="32"></a>　
<a href="https://www.iden3.io/" rel="nofollow"><img src="https://github.com/wasm3/wasm3/raw/main/extra/logos/iden3.svg" height="32"></a>　
<a href="https://github.com/apache/incubator-nuttx-apps/tree/master/interpreters/wasm3"><img src="https://camo.githubusercontent.com/da37eca2607093a7c938d09a2b9f81c6ca4fe5c2e090acde046c76c9065795ef/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f622f62302f4e757474585f6c6f676f2e706e67" height="32" data-canonical-src="https://upload.wikimedia.org/wikipedia/commons/b/b0/NuttX_logo.png"></a>　
<a href="https://github.com/Losant/eea-examples"><img src="https://github.com/wasm3/wasm3/raw/main/extra/logos/losant.png" height="28"></a>　
<a href="https://github.com/kateinoigakukun/wasmic-ios"><img src="https://user-images.githubusercontent.com/1506708/114701856-069ce700-9d2c-11eb-9b72-9ce2dfd9f0fb.png" height="32"></a>　
<a href="https://github.com/balena-io-playground/balena-wasm3"><img src="https://camo.githubusercontent.com/7d511f850262dc4ce09204b7cb52aae544a7698415976c15bc75163af84186b3/68747470733a2f2f6173736574732d676c6f62616c2e776562736974652d66696c65732e636f6d2f3633366162366261306531626432353065336161656461662f3633366531353565393338393463643464303330633464375f62616c656e615f6c6f676f5f6461726b2e737667" height="32" data-canonical-src="https://assets-global.website-files.com/636ab6ba0e1bd250e3aaedaf/636e155e93894cd4d030c4d7_balena_logo_dark.svg"></a>　
<a href="https://github.com/deislabs/krustlet-wasm3"><img src="https://camo.githubusercontent.com/07385dadb6ba6519c190b8cf39c2f4124c618619bd2f9d45e1cf65c74bc19a8a/68747470733a2f2f6b727573746c65742e6465762f696d616765732f686f72697a6f6e74616c2e737667" height="32" data-canonical-src="https://krustlet.dev/images/horizontal.svg"></a>　
<a href="https://shareup.app/blog/introducing-shareup" rel="nofollow"><img src="https://github.com/wasm3/wasm3/raw/main/extra/logos/shareup_app.svg" height="24"></a>　
<a href="https://wasm4.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/3fdc117d401a5a9bc4add3d06b13955daa54f3f9d8b72814e4f331506675cc81/68747470733a2f2f7761736d342e6f72672f696d672f6c6f676f2e706e67" height="32" data-canonical-src="https://wasm4.org/img/logo.png"></a></p>
<h2 tabindex="-1" dir="auto">Further Resources</h2>
<p dir="auto"><a href="https://github.com/wasm3/wasm3/blob/main/docs/Demos.md">Demos</a><br>
<a href="https://github.com/wasm3/wasm3/blob/main/docs/Installation.md">Installation instructions</a><br>
<a href="https://github.com/wasm3/wasm3/blob/main/docs/Cookbook.md">Cookbook</a><br>
<a href="https://github.com/wasm3/wasm3/blob/main/docs/Troubleshooting.md">Troubleshooting</a><br>
<a href="https://github.com/wasm3/wasm3/blob/main/docs/Development.md">Build and Development instructions</a><br>
<a href="https://github.com/wasm3/wasm3/blob/main/docs/Hardware.md">Supported Hardware</a><br>
<a href="https://github.com/wasm3/wasm3/blob/main/docs/Testing.md">Testing &amp; Fuzzing</a><br>
<a href="https://github.com/wasm3/wasm3/blob/main/docs/Performance.md">Performance</a><br>
<a href="https://github.com/wasm3/wasm3/blob/main/docs/Interpreter.md">Interpreter Architecture</a><br>
<a href="https://github.com/wasm3/wasm3/blob/main/docs/Diagnostics.md">Logging</a><br>
<a href="https://github.com/vshymanskyy/awesome-wasm-tools/blob/main/README.md">Awesome WebAssembly Tools</a></p>
<h3 tabindex="-1" dir="auto">License</h3>
<p dir="auto">This project is released under The MIT License (MIT)</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The British Library URL has been offline due to cyberattack for 10 days (164 pts)]]></title>
            <link>https://www.bl.uk/</link>
            <guid>38681468</guid>
            <pubDate>Mon, 18 Dec 2023 12:10:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bl.uk/">https://www.bl.uk/</a>, See on <a href="https://news.ycombinator.com/item?id=38681468">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><time datetime="2023-12-08T17:00:00.000Z">Last updated: 5pm on Friday, 8 December 2023.</time></p><div>
	<p>We're experiencing a major technology outage following a cyber-attack affecting our website, online systems and services, and some onsite services. However, our buildings are still open as usual. We anticipate restoring more services in the next few weeks, but disruption to certain services is now expected to persist for several months.</p>

	<p>Last week the attackers released some of our data onto the dark web including some personal user information. We've contacted our users to alert them to this incident and to offer advice from the National Cyber Security Centre (NCSC) on how to protect themselves, including updating their passwords on other systems.</p>

	<p>Because our systems are still unavailable, you can't change the password for our services. However, if you use the same password for non-British Library services, we recommend that you change it as a precaution.</p>
	
	<p>NCSC provides <a href="https://www.ncsc.gov.uk/section/information-for/individuals-families" target="_blank">guidance on staying secure online</a>, including how to create a strong password, and <a href="https://www.ncsc.gov.uk/guidance/data-breaches" target="_blank">specific guidance for individuals who may have been impacted by a data breach</a>.</p>

	<p>Analysing the data is likely to take several months. Should we find specific information has been compromised, we will alert anyone affected as soon as we can. We are continuing to collaborate with the Metropolitan Police and professional cybersecurity advisors, and are receiving support from the NCSC.</p>

	<p>We're really sorry for the ongoing disruption to our systems and services and we'll provide further updates when we can.</p>
	
	<h3>What is currently available?</h3>
	
	<p>The Library's buildings are open, but some services are limited, including access to collection items. We're regularly updating <a href="https://blogs.bl.uk/living-knowledge/2023/11/cyber-incident.html" target="_blank">our blog</a> with the latest information on what's currently available online and onsite so please check this before you visit.</p>
	
	<p>If you have purchased tickets for our exhibition, <strong>Fantasy: Realms of Imagination</strong>, you can still use them. Exhibition tickets can also be booked via <a href="https://fantasy.seetickets.com/timeslots/filter/fantasy-realms-of-imagination" target="_blank">See Tickets</a>. Our free exhibition, <strong>Malorie Blackman: The Power of Stories</strong>, is open and no booking is required.</p>
	
	<p>All upcoming <strong>public events</strong> are going ahead as planned and you can find more information on our <a href="https://blogs.bl.uk/living-knowledge/2023/11/british-library-events-.html" target="_blank"> events blog
			update</a>. We're continuing to welcome <strong>schools</strong> and <strong>families</strong> too, as well as
		adult learners to our <strong>courses</strong>. </p>
	
	<p><strong>Business &amp; IP Centre</strong> (BIPC) in St Pancras is open to support businesses as usual but digital
		services onsite are unavailable. You can also join <strong>BIPC events and webinars</strong> and access one-to-one
		support. Read our <a href="https://blogs.bl.uk/living-knowledge/2023/11/british-library-business-ip-centre-bipc-services.html" target="_blank">BIPC blog update</a> to find out what help and advice we can offer during this time.</p>
	
	<h3>Contacting us</h3>
	<p>While our systems are offline, you can contact us by emailing <a href="mailto:customer@bl.uk" target="_blank">customer@bl.uk</a> We'll do our best to answer your queries but please bear with us. This inbox is reviewed between 08.30 to 16.30 Monday to Friday. We're experiencing a high volume of enquiries so it may take us some time to respond. We'll get back to you as quickly as we can.</p>
	
	<p>Thank you for your patience and understanding.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[This year in Servo: over 1000 pull requests and beyond (238 pts)]]></title>
            <link>https://servo.org/blog/2023/12/18/this-year-in-servo/</link>
            <guid>38681463</guid>
            <pubDate>Mon, 18 Dec 2023 12:09:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://servo.org/blog/2023/12/18/this-year-in-servo/">https://servo.org/blog/2023/12/18/this-year-in-servo/</a>, See on <a href="https://news.ycombinator.com/item?id=38681463">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><span>2023-12-18</span> Reflections on Servo’s progress in 2023: contributor stats, new features, layout improvements, WPT pass rates, and plans for next year.</p><div>
  <p>Servo is well and truly back.</p>
<figure><a href="https://servo.org/img/blog/recap-2023-contributors.png"><img src="https://servo.org/img/blog/recap-2023-contributors.png" alt="Bar chart: 453 (44%) by Igalia, 195 (19%) by non-Igalia, 389 (37%) by bots"></a>
<figcaption>Contributors to <a href="https://github.com/servo/servo">servo/servo</a> in 2023.</figcaption></figure>
<p><span></span>
This year, to date, we’ve had <strong>53 unique contributors</strong> (+140% over 22 last year), landing <strong>1037 pull requests</strong> (+382% over 215) and 2485 commits (+375% over 523), and that’s just in <a href="https://github.com/servo/servo">our main repo</a>!</p>
<p>Individual contributors are especially important for the health of the project, and of the pull requests made by humans (rather than our <a href="https://github.com/servo-wpt-sync">friendly</a> <a href="https://github.com/dependabot">bots</a>), 30% were by people outside Igalia, and 18% were by non-reviewers.</p>
<p>Servo has been featured in <a href="https://servo.org/about/">six conference talks</a> this year, including at <a href="https://www.youtube.com/watch?v=IdHvHoAO5oo">RustNL</a>, <a href="https://www.youtube.com/watch?v=pfk8s5OD99A">Web Engines Hackfest</a>, <a href="https://www.youtube.com/watch?v=J4qedc-0pjs&amp;t=2356s">LF Europe Member Summit</a>, <a href="https://youtu.be/9lkIX5ryZZ4">Open Source Summit Europe</a>, <a href="https://youtu.be/RugzThWcjn4">GOSIM Workshop</a>, and <a href="https://www.youtube.com/watch?v=lx70W83Bxtc">GOSIM Conference</a>.</p>
<p>Servo now has a usable “minibrowser” UI, now supports offscreen rendering, its experimental WebGPU support (<code>--pref dom.webgpu.enabled</code>) has been updated, and Servo is now listed on <a href="https://wpt.fyi/">wpt.fyi</a> again (click <span>Edit</span> to add Servo).</p>
<p><a href="https://servo.org/blog/2023/04/13/layout-2013-vs-2020/">Our new layout engine</a> is now proving its strengths, with support for iframes, floats, stacking context improvements, inline layout improvements, margin collapsing, ‘position: sticky’, ‘min-width’ and ‘min-height’, ‘max-width’ and ‘max-height’, ‘align-content’, ‘justify-content’, ‘white-space’, ‘text-indent’, ‘text-align: justify’, <a href="https://servo.org/blog/2023/05/31/adding-support-for-outline-properties/">‘outline’ and ‘outline-offset’</a>, and ‘filter: drop-shadow()’.</p>
<figure><a href="https://servo.org/img/blog/recap-2023-wpt.png"><img src="https://servo.org/img/blog/recap-2023-wpt.png" alt="Bar chart: 17% + 64pp in floats, 18% + 55pp in floats-clear, 63% + 15pp in key CSS2 tests, 80% + 14pp in abspos, 34% + 14pp in CSS position module, 67% + 13pp in margin-padding-clear, 49% + 13pp in CSSOM, 51% + 10pp in all CSS tests, 49% + 6pp in all WPT tests"></a>
<figcaption>Pass rates in parts of the <a href="https://web-platform-tests.org/">Web Platform Tests</a> with our new layout engine, showing the improvement we’ve made since the <a href="https://servo.org/blog/2023/07/20/servo-web-platform-tests/">start of our data</a> in April 2023.</figcaption></figure>
<p><span></span>
<a href="https://github.com/dbaron/inlines-and-floats">Floats are notoriously tricky</a>, to the point we found them <a href="https://github.com/servo/servo/wiki/Servo-Layout-Engines-Report">impossible to implement correctly</a> in our legacy layout engine, but thanks to the move from eager to opportunistic parallelism, they are now supported fairly well.
Whereas legacy layout was only ever able to reach 53.9% in the floats tests and 68.2% in floats-clear, we’re now at <strong>82.2% in floats</strong> (+28.3pp over legacy) and <strong>73.3% in floats-clear</strong> (+5.1pp over legacy).</p>
<p><a href="http://acid1.acidtests.org/">Acid1</a> now passes in the new layout engine, and we’ve also surpassed legacy layout in the <strong>CSS2 abspos (by 50.0pp)</strong>, CSS2 positioning (by 6.5pp), and CSS Position (by 4.4pp) test suites, while making big strides in others, like the <strong>CSSOM tests (+13.1pp)</strong> and key parts of the <strong>CSS2 test suite (+15.8pp)</strong>.</p>
<p><span></span>
<a href="https://github.com/servo/servo/wiki/Roadmap/106e95887c3d9768f791a4e0501ba5c89abe9636">Next year</a>, our funding will go towards maintaining Servo, releasing nightlies on Android, finishing our integration with Tauri (thanks to NLNet), and implementing tables and better support for floats and non-Latin text (thanks to NLNet).</p>
<p>Servo will also be at <a href="https://fosdem.org/2024/">FOSDEM 2024</a>, with Rakhi Sharma speaking about <a href="https://fosdem.org/2024/schedule/event/fosdem-2024-2321-embedding-servo-in-rust-projects/">embedding Servo in Rust projects</a> on <strong>3 February</strong> at <strong>16:45 local time</strong> (15:45 UTC).
See you there!</p>
<p>There’s a lot more we would like to do, so if you or a company you know are interested in sponsoring the development of an embeddable, independent, memory-safe, modular, parallel web rendering engine, we want to hear from you!
Head over to <a href="https://servo.org/sponsorship/">our sponsorship page</a>, or email <a href="https://servo.org/cdn-cgi/l/email-protection#4923262027093a2c3b3f2667263b2e"><span data-cfemail="543e3b3d3a14273126223b7a3b2633">[email&nbsp;protected]</span></a> for enquiries.</p>
<p>In a decade that many people feared would become the nadir of browser engine diversity, we hope we can help change that with Servo.</p>
<!--
pull request data
$ tools/list-pull-requests.sh servo/servo '2022-.*' | tee 2022.json
$ tools/list-pull-requests.sh servo/servo '2023-.*' | tee 2023.json

pull requests
- 2022: 215 (< 2022.json jq -s length)
- 2023: 1037 (< 2023.json jq -s length)

contributors
- 2022: 22 (< 2022.json jq -r .user.login | sort | uniq -c | sort -nr | wc -l)
- 2023: 53 (< 2023.json jq -r .user.login | sort | uniq -c | sort -nr | wc -l)

reviewers
- https://github.com/orgs/servo/teams/developers
- copy($$("#team-members li[data-bulk-actions-id]").map(x => x.dataset.bulkActionsId).sort().join("\n"))

commits
- 2022: 523 (git log --pretty=format:$'%h\t%cd' | rg ' 2022 ' | wc -l)
- 2023: 2485 (git log --pretty=format:$'%h\t%cd' | rg ' 2023 ' | wc -l)

for wpt pass rates and all other analysis, see assets/img/blog/recap-2023.ods
-->


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA["I just bought a 2024 Chevy Tahoe for $1" (382 pts)]]></title>
            <link>https://twitter.com/ChrisJBakke/status/1736533308849443121</link>
            <guid>38681450</guid>
            <pubDate>Mon, 18 Dec 2023 12:08:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/ChrisJBakke/status/1736533308849443121">https://twitter.com/ChrisJBakke/status/1736533308849443121</a>, See on <a href="https://news.ycombinator.com/item?id=38681450">Hacker News</a></p>
Couldn't get https://twitter.com/ChrisJBakke/status/1736533308849443121: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[The "Cheap" Web (244 pts)]]></title>
            <link>https://potato.cheap</link>
            <guid>38681437</guid>
            <pubDate>Mon, 18 Dec 2023 12:06:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://potato.cheap">https://potato.cheap</a>, See on <a href="https://news.ycombinator.com/item?id=38681437">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
        <p>
          <marquee scrollamount="15" scrolldelay="100" behavior="slide">
            <a href="https://potato.cheap/">potato.cheap</a> is home of the...
          </marquee>
        </p>
        
        <section>
          <p>
            The "cheap" web is a
            <a href="https://en.wikipedia.org/wiki/Solarpunk">solarpunk</a>
            philosophy of web design.
          </p>
        </section>
        <!--
        - https://thenewleafjournal.com/atw-the-small-web-artisanal-content-and-humane-design/
        - https://blog.kagi.com/small-web
        - https://neustadt.fr/essays/the-small-web/#web-as-creative-space
        - https://neustadt.fr/essays/against-a-user-hostile-web/
        - https://benhoyt.com/writings/the-small-web-is-beautiful/
        - https://smallweb.page/why
        - https://andrewhuth.substack.com/p/a-read-through-the-original-worldwideweb
        --->
        <section id="free">
          <h2>cheap ≠ free</h2>
          <p>Making nice things is difficult and time-consuming.</p>
          <p>
            If we want people to make nice things for us, we have to pay for
            their rent and grocery bills and raw materials.
          </p>
          <p>
            If you are spending less than
            <a href="https://taylor.town/dollar-per-hour">$1 per hour</a> on
            your entertainment (podcasts, videos, articles, games, books, etc.),
            consider finding ways to support creators and the infrastructure
            that supports them.
          </p>
        </section>
        <section id="sleek">
          <h2>cheap ≠ sleek</h2>
          <blockquote>
            <p>
              <em>
                I want [the Mac] to be as beautiful as possible, even if it’s
                inside the box. A great carpenter isn’t going to use lousy wood
                for the back of a cabinet, even though nobody’s going to see it.
              </em>
            </p>
            <p>&nbsp;&nbsp;&nbsp;&nbsp;- Steve Jobs (via Walter Isaacson)</p>
          </blockquote>
          <p>
            Unfortunately, the HTML source for
            <a href="https://www.apple.com/">Apple.com</a> is not so "beautiful
            on the inside", but Apple engineers shouldn't be faulted for ugly
            HTML. Their only option was to wrap a sleek skin around shoddy
            materials.
          </p>
          <p>
            HTML/CSS should evoke feelings of sculpting with digital concrete,
            but it feels more like
            <a href="https://en.wikipedia.org/wiki/Spaghetti_bridge">building bridges with uncooked pasta</a>. The whole digital design landscape is begging for simple markup
            languages that can participate in honest architecture.
            <em>[I hope to finish one such language in 2024-2025!
              <a href="https://potato.cheap/hello@taylor.town=splat">Email me</a>
              if you'd like to help.]</em>
          </p>
          <p>
            Until we adopt simple and stable building materials,
            <a href="https://www.fastcompany.com/90501691/science-confirms-it-web-sites-really-do-all-look-the-same">all websites will continue to look the same</a>. Software has become too complicated to stay honest. Corporations
            can't expose their brick-and-wood architecture because it's actually
            Megablocks and sawdust underneath all that paint.
          </p>
          <p>
            <a href="https://en.wikipedia.org/wiki/Wirth%27s_law">Wirth's Law</a>
            threatens to make things even worse. As software rots,
            multinationals may become the only players capable of making
            websites.
          </p>
          <p>
            But people like Bartosz Ciechanowski are forging paths to elegant
            futures. The
            <a href="https://ciechanow.ski/js/watch.js">source code</a> for his
            <a href="https://ciechanow.ski/mechanical-watch">mechanical watch demo</a>
            is proof that honest software is viable. Each guide is erected as a
            giant wall of WebGL. It's beautiful, but definitely not sleek.
          </p>
          <p>
            The World Wide Web needn't be all 3D WebGL wizardry. The websites of
            <a href="https://patrickcollison.com/about">Patrick Colison</a>,
            <a href="https://www.edwardtufte.com/tufte/">Edward Tufte</a>, and
            <a href="https://www.gyford.com/">Phil Gyford</a> are thriving
            examples of cozy HTML cabins.
          </p>
          <p>
            <a href="https://astronaut.io/">The humans are still out there.</a>
            We can speak sincerely with honest tools and materials. We can
            <a href="https://www.todepond.com/wikiblogarden/tadi-web">stay slippy</a>
            and celebrate our warts and imperfections together.
          </p>
          <p>
            A wobbly wooden chair built by a friend beats any designer chair. We
            need more wobbly websites.
          </p>
        </section>
        <section id="creep">
          <h2>cheap ≠ creep</h2>
          <p>
            The central land of the United States is flat, fertile, and windy.
            <a href="https://www.youtube.com/watch?v=hsWr_JWTZss">Tumbleweed is non-native to the US, yet somehow perfectly
              suited.</a>
            Although destructive, it's so ubiquitous that it's become a symbol
            for the Wild West itself.
          </p>

          <p>
            Likewise, the World Wide Web connects (1) large populations of (2)
            dissimilar people (3) at an impersonal distance (4) fueled by ad
            revenue.
            <a href="https://www.youtube.com/watch?v=rE3j_RHkqJc">Anger is uniquely good at spreading across the web.</a>
            The
            <a href="https://edoardodanna.ch/article/bicycle_for_the_mind">bicycle of the mind</a>
            have become
            <a href="https://taylor.town/frustrating-thing">the de-facto vehicle of frustration</a>.
          </p>

          <p>
            Large parasocial platforms transformed the internet into a hostile
            and impersonal place. They feed our FOMO to keep us clicking. They
            exaggerate our differences for "engagement". They create engines for
            stardom to keep us creeping. They bait us into nutritionless and
            sensationalist content. Humanity cannot subsist on hype alone.
          </p>
          <p>
            Small and sincere communication quietly thrives. It's easy to find
            and even easier to make yourself:
          </p>
          <p>
            <a href="https://www.benkuhn.net/writing/">Write on the internet.</a>
            Find or create a
            <a href="https://en.wikipedia.org/wiki/Third_place">third place</a>.
            Pick up the phone.
            <a href="https://www.reddit.com/r/tokipona/comments/d4uq8t/toki_pona_discord/">Join niche interest groups.</a>
            Live, don't lurk.
            <a href="https://taylor.town/candid-culture">Embrace candid culture.</a>
            Put people you care about on the calendar.
            <a href="https://taylor.town/black-holes">Don't play near black holes.</a>
            Meet people at farmers markets.
            <a href="https://en.wikipedia.org/wiki/Nonviolent_Communication">Learn to communicate.</a>
            Make wobbly things. Subscribe to local events calendars.
            <a href="https://bookshop.org/p/books/how-to-win-friends-and-influence-people-dale-carnegie/7496534?ean=9780671027032">Learn to win friends.</a>
            <!--
            <a href="https://taylor.town/ambient-chatter"
              >Avoid ambient chatter.</a
            >
            --->
            <a href="https://bookshop.org/p/books/atlas-of-the-heart-mapping-meaningful-connection-and-the-language-of-human-experience-brene-brown/17210802?ean=9780399592553">Learn to feel.</a>
            <a href="https://potato.cheap/cdn-cgi/l/email-protection#a7cfc2cbcbc8e7d3c6decbc8d589d3c8d0c9">Email strangers.</a>
            And so on.
          </p>

          <p>
            The peak of
            <a href="https://en.wikipedia.org/wiki/Pok%C3%A9mon_Go">Pokémon Go</a>
            showed us what the future of the internet could look like. With the
            right technology, we might be able to synthesize serendipity. We
            could hybridize the best parts of
            <a href="https://taylor.town/frustrating-thing">the frustrating thing and the peaceful thing</a>.
            <em>[I've been casually designing an AR game called "Peace &amp;
              Progress II" since 2012.
              <a href="https://potato.cheap/cdn-cgi/l/email-protection#5038353c3c3f102431293c3f227e243f273e">Email me</a> if you'd like to
              help build it!]</em>
          </p>
        </section>
        <section id="deep">
          <h2>cheap ≠ deep</h2>
          <p>
            Sturgeon's Law states that
            <a href="https://en.wikipedia.org/wiki/Sturgeon%27s_law">"90% of everything is crap"</a>.
          </p>

          <p>The non-crap 10% of the World Wide Web may be unreachable.</p>

          <p>
            The
            <a href="https://en.wikipedia.org/wiki/Deep_web">deep web</a> (not
            to be confused with the <a href="#dark">dark web</a>) is hard to
            find because it's hard to find.
          </p>

          <p>
            Computers are really good at finding and storing things, so why is
            much of the internet broken and/or missing?
          </p>

          <ul>
            <li>
              <strong>Spam:</strong> Corporations and computers manufacture crap
              at scale, then
              <a href="https://en.wikipedia.org/wiki/Search_engine_optimization">exploit</a>
              (and often pay) Google to overwhelm independent search results.
              Our public library shelves are flooded with junk mail and coupons.
              Consider supporting alternative search engines like
              <a href="https://duckduckgo.com/">DDG</a> and
              <a href="https://kagi.com/">Kagi</a>.
            </li>
            <li>
              <strong>Javascript:</strong> Modern websites are built with more
              JS (dynamic) than HTML (static), and dynamic content is difficult
              for computers to read. Imagine ordering <em>The Hobbit</em> and
              unexpectedly receiving a N64 cartridge with an e-book on it. A
              book is simple and unchanging. A N64 cartridge requires (1) a
              working N64, (2) a compatible television, (3) knowledge of how to
              use/repair the equipment, (4) knowledge of how to use the
              cartridge, and (5) time/energy to load the cartridge and navigate
              menus. Hodgepodge cartridges do not scale. To keep HTML
              competitive with JS, we need better tooling. Some HTML resources
              are listed on the side of this webpage. To supplant JS, the HTML
              development experience must become 10x easier/faster/cheaper/etc
              than the current JS experience.
            </li>
            <li>
              <strong>Images:</strong> HTML is more sustainable than JS, but
              HTML remains hostile to beginners. Without an easy markup
              language, people use Powerpoint/Photoshop to share documents. It's
              hard for computers to decipher/archive images, and it only becomes
              harder as fewer photocopies-of-photocopies survive. We need
              something powerful like HTML/CSS, yet simple like Markdown.
            </li>
            <li>
              <strong>Accessibility:</strong> HTML is generally unkind to people
              of limited hearing, vision, etc. By default, stuff on the cheap
              web should work flexibly with many interfaces.
              <a href="https://en.wikipedia.org/wiki/Curb_cut_effect">Everybody benefits from curb cuts.</a>
            </li>
            <li>
              <strong>Payments:</strong> Browsers could have implemented digital
              wallets to manage subscriptions and one-click payments, but
              consumers had to wait for Amazon and Apple to launch proprietary
              solutions to public platform problems. Payments were difficult, so
              nobody paid for things. Advertising became the default way to
              sustainably make money; piracy became the default way to guard
              one's attention/privacy. To escape from this advertising
              hellscape, we must make online payments better for developers and
              consumers, especially for digital goods.
              <em>[I made <a href="https://wishwell.io/">WishWell</a> to make
                donations easier, but charitable giving is no panacea.]</em>
            </li>
            <li>
              <strong>Arbitrary Addresses:</strong> The modern internet works
              much like Amazon's delivery network. Amazon can deliver stuff in
              its warehouses quickly, but one must wait longer to get products
              directly from suppliers. But digital goods needn't come from a
              supplier nor the closest distribution center. All internet data
              can be sent and received faster by copying data from neighbors!
              Cryptographers
              <a href="https://en.wikipedia.org/wiki/Content-addressable_storage">invented magic</a>
              to do exactly this, but it's not being used at all layers of our
              digital infrastructure. To get mainstream adoption at the www.*
              level, we need
              <a href="https://brave.com/ipfs-support/">more browser support</a>
              and killer apps (an
              <a href="https://imgur.com/">imgur</a> alternative seems like a
              good candidate).
            </li>
            <li>
              <strong>Platforms:</strong> Nobody owns email or podcasts (RSS),
              and everybody benefits tremendously from that freedom and
              flexibility. Corporations like Slack, Twitter, Visa, Zoom, Google,
              Amazon, Instagram, Unity, YouTube, and GoDaddy retain control over
              infrastructure that needn't be controlled at all. To escape
              <a href="https://en.wikipedia.org/wiki/Enshittification">enshittification</a>
              cycles, we need open protocols and designers to make nice
              interfaces for those protocols. Federated services like Mastadon
              are promising.
              <em>[<a href="https://potato.cheap/hello@taylor.town=spew">Email me</a> if you'd like to
                help me launch an open YouTube alternative!]</em>
            </li>
            <li>
              <strong>Ad-Hoc Archival:</strong> If the internet were built on
              something like BitTorrent, archiving and indexing everything would
              be trivial and automatic. Instead,
              <a href="https://archive.org/">archive.org</a> remains perpetually
              underfunded in its futile battle against
              <a href="https://en.wikipedia.org/wiki/Software_rot">bit rot</a>.
              <a href="https://archive.org/donate">Donate to archive.org</a>
              until we build archivable digital infrastructure.
            </li>
          </ul>
        </section>
        <section id="dark">
          <h2>cheap ≠ dark</h2>
          <p>
            <a href="https://www.youtube.com/watch?v=YQ_xWvX1n9g">NFTs were probably always a bad idea</a>, yet much of the cryptocurrency community espouses admirable aims.
            Kudos to the crypto folks -- they are actually trying to fix/replace
            the world's crumbling central infrastructure.
          </p>
          <p>
            The maintainers of the global financial system have repeatedly
            failed us. All the games seem rigged and global inequality seems
            inescapable. Governments and corporations continue to trample our
            privacy. Banks are slow; credit card fees feel like theft. And so
            on.
          </p>
          <p>
            But cryptocurrency zealots also try to
            <a href="https://en.wikipedia.org/wiki/Proof_of_work">set our oil reserves ablaze</a>
            so that they can hoard Dogecoin in virtual caves.
          </p>
          <p>
            It remains unclear what role blockchains will play in a sustainable
            technological future, but surely we needn't squander so much energy
            to obtain the convenience we desire and the privacy we deserve.
          </p>
          <p>
            And if we receive privacy, let's use it responsibly -- let's leave
            all the shitcoin scams and ransomware and toxic stuff behind.
          </p>
        </section>
        <section id="cheap">
          <h2>cheap = cheap</h2>
          <ul>
            <li>
              <strong>Cheap to maintain:</strong> Most webpages should work
              indefinitely without falling over.
            </li>
            <li>
              <strong>Cheap to leave:</strong> Opting-out of the web should be
              painless.
            </li>
            <li>
              <strong>Cheap to access:</strong> Most websites should be
              compatible with screenreaders, etc.
            </li>
            <li>
              <strong>Cheap to participate:</strong> Interacting with the web
              should be possible on a Wii.
            </li>
            <li>
              <strong>Cheap to explore:</strong> Exploring the web should be
              pleasant on 1W of power.
            </li>
            <li>
              <strong>Cheap to contribute:</strong> Making/hosting websites
              should be easier than scrapbooking.
            </li>
          </ul>
        </section>
      </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Paying Netflix $0.53/H, etc. (124 pts)]]></title>
            <link>https://taylor.town/dollar-per-hour</link>
            <guid>38681428</guid>
            <pubDate>Mon, 18 Dec 2023 12:04:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://taylor.town/dollar-per-hour">https://taylor.town/dollar-per-hour</a>, See on <a href="https://news.ycombinator.com/item?id=38681428">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>
Warning: many of the numbers below are probably incorrect!
<a href="https://taylor.town/cdn-cgi/l/email-protection#cea6aba2a2a18ebaafb7a2a1bce0baa1b9a0">Email me</a> if you’d like to help make something more
rigorous.</p>
<p>
<strong>tl;dr:</strong> People pay $0.50-$2.00 for an hour of digital entertainment.</p>
<table>
<thead>
<tr>
<th>
</th>
<th>
ad-free sub. </th>
<th>
avg. usage </th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Xbox Live </td>
<td>
*$10/mo </td>
<td>
40h/mo </td>
<td>
$0.25/h </td>
</tr>
<tr>
<td>
NY Times </td>
<td>
$3/mo </td>
<td>
7h/mo </td>
<td>
$0.46/h </td>
</tr>
<tr>
<td>
Spotify </td>
<td>
$11/mo </td>
<td>
5h/mo </td>
<td>
$0.47/h </td>
</tr>
<tr>
<td>
NFL+ </td>
<td>
$7/mo </td>
<td>
12h/mo </td>
<td>
$0.50/h </td>
</tr>
<tr>
<td>
X </td>
<td>
$3/mo </td>
<td>
6h/mo </td>
<td>
$0.50/h </td>
</tr>
<tr>
<td>
Netflix </td>
<td>
$23/mo </td>
<td>
43h/mo </td>
<td>
$0.53/h </td>
</tr>
<tr>
<td>
Hulu </td>
<td>
$18/mo </td>
<td>
33h/mo </td>
<td>
$0.54/h </td>
</tr>
<tr>
<td>
YouTube </td>
<td>
$13/mo </td>
<td>
23h/mo </td>
<td>
$0.56/h </td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>
</th>
<th>
est. price </th>
<th>
duration </th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
video game (v. long) </td>
<td>
$60 </td>
<td>
180h </td>
<td>
$0.33/h </td>
</tr>
<tr>
<td>
video game (long) </td>
<td>
$60 </td>
<td>
60h </td>
<td>
$1.00/h </td>
</tr>
<tr>
<td>
book </td>
<td>
$12 </td>
<td>
10h </td>
<td>
$1.20/h </td>
</tr>
<tr>
<td>
video game (short) </td>
<td>
$30 </td>
<td>
20h </td>
<td>
$1.50/h </td>
</tr>
<tr>
<td>
film (online) </td>
<td>
$4 </td>
<td>
2h </td>
<td>
$2.00/h </td>
</tr>
<tr>
<td>
audiobook </td>
<td>
$20 </td>
<td>
10h </td>
<td>
$2.00/h </td>
</tr>
<tr>
<td>
cinema </td>
<td>
$12 </td>
<td>
2h </td>
<td>
$6.00/h </td>
</tr>
<tr>
<td>
theme park </td>
<td>
$80 </td>
<td>
10h </td>
<td>
$8.00/h </td>
</tr>
<tr>
<td>
cruise </td>
<td>
$1500 </td>
<td>
168h </td>
<td>
$8.92/h </td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>
</th>
<th>
default min. </th>
<th>
avg. pub. </th>
<th>
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://radiolab.org/">Radiolab </a> </td>
<td>
$5/mo </td>
<td>
160m/mo </td>
<td>
$2/h </td>
</tr>
<tr>
<td>
<a href="https://www.youtube.com/@TechnologyConnections">Tech Connections </a> </td>
<td>
$1/mo </td>
<td>
30m/mo </td>
<td>
$2/h </td>
</tr>
<tr>
<td>
<a href="http://cortex.fm/">Cortex </a> </td>
<td>
$5/mo </td>
<td>
90m/mo </td>
<td>
$3/h </td>
</tr>
<tr>
<td>
<a href="https://www.youtube.com/@hbomberguy">hbomberguy </a> </td>
<td>
$2/mo </td>
<td>
25m/mo </td>
<td>
$5/h </td>
</tr>
<tr>
<td>
<a href="https://www.articlesofinterest.co/">Articles of Interest</a> </td>
<td>
$4/mo </td>
<td>
40m/mo </td>
<td>
$6/h </td>
</tr>
<tr>
<td>
<a href="https://www.todepond.com/">TodePond </a> </td>
<td>
$1/mo </td>
<td>
10m/mo </td>
<td>
$9/h </td>
</tr>
<tr>
<td>
<a href="https://www.youtube.com/@NotJustBikes">NotJustBikes </a> </td>
<td>
$3/mo </td>
<td>
20m/mo </td>
<td>
$11/h </td>
</tr>
<tr>
<td>
<a href="https://thememorypalace.us/">The Memory Palace </a> </td>
<td>
$4/mo </td>
<td>
20m/mo </td>
<td>
$12/h </td>
</tr>
<tr>
<td>
<a href="https://www.henrikkarlsson.xyz/">Escaping Flatland </a> </td>
<td>
$7/mo </td>
<td>
30m/mo </td>
<td>
$14/h </td>
</tr>
<tr>
<td>
<a href="https://www.experimental-history.com/">Experimental History</a> </td>
<td>
$10/mo </td>
<td>
30m/mo </td>
<td>
$20/h </td>
</tr>
<tr>
<td>
<a href="https://www.cgpgrey.com/">CGP Grey </a> </td>
<td>
$7/mo </td>
<td>
10m/mo </td>
<td>
$70/h </td>
</tr>
</tbody>
</table>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EU opens proceedings against X over efforts to combat information manipulation (167 pts)]]></title>
            <link>https://www.reuters.com/technology/eu-opens-proceedings-against-x-over-its-efforts-combat-information-manipulation-2023-12-18/</link>
            <guid>38681353</guid>
            <pubDate>Mon, 18 Dec 2023 11:50:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/technology/eu-opens-proceedings-against-x-over-its-efforts-combat-information-manipulation-2023-12-18/">https://www.reuters.com/technology/eu-opens-proceedings-against-x-over-its-efforts-combat-information-manipulation-2023-12-18/</a>, See on <a href="https://news.ycombinator.com/item?id=38681353">Hacker News</a></p>
Couldn't get https://www.reuters.com/technology/eu-opens-proceedings-against-x-over-its-efforts-combat-information-manipulation-2023-12-18/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Interactive Code Cells (125 pts)]]></title>
            <link>https://antonz.org/code-cells/</link>
            <guid>38681115</guid>
            <pubDate>Mon, 18 Dec 2023 11:00:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://antonz.org/code-cells/">https://antonz.org/code-cells/</a>, See on <a href="https://news.ycombinator.com/item?id=38681115">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><header></header><p>What would you say if Jupyter Notebooks could ➀ support any programming language, ➁ have no hidden state, and ➂ have a native look and feel for any article or blog post?</p><p>Well, I've just shipped something like that! With the latest <a href="https://github.com/nalgeon/codapi-js">codapi-js</a> feature called <em>code cells</em>, you can create a series of interactive code snippets that depend on each other and execute them without leaving your browser.</p><p>Let's look at an example.</p><h2 id="code-cells">Code cells</h2><p>Suppose we are writing an SQL tutorial using PostgreSQL. First, let's create an <code>employees</code> table:</p><div><pre tabindex="0"><code data-lang="sql"><span><span><span>create</span> <span>table</span> <span>employees</span> (
</span></span><span><span>  <span>id</span> <span>integer</span> <span>primary</span> <span>key</span>,
</span></span><span><span>  <span>name</span> <span>varchar</span>(<span>50</span>),
</span></span><span><span>  <span>department</span> <span>varchar</span>(<span>10</span>),
</span></span><span><span>  <span>salary</span> <span>integer</span>
</span></span><span><span>);
</span></span></code></pre></div><codapi-snippet id="create.sql" sandbox="postgres" editor="basic" template="#status.tpl"></codapi-snippet><p>Then insert some employee data:</p><div><pre tabindex="0"><code data-lang="sql"><span><span><span>insert</span> <span>into</span> <span>employees</span>
</span></span><span><span>(<span>id</span>, <span>name</span>, <span>department</span>, <span>salary</span>)
</span></span><span><span><span>values</span>
</span></span><span><span>(<span>11</span>, <span>'Diane'</span>, <span>'hr'</span>, <span>70</span>),
</span></span><span><span>(<span>12</span>, <span>'Bob'</span>, <span>'hr'</span>, <span>78</span>),
</span></span><span><span>(<span>21</span>, <span>'Emma'</span>, <span>'it'</span>, <span>84</span>),
</span></span><span><span>(<span>22</span>, <span>'Grace'</span>, <span>'it'</span>, <span>90</span>),
</span></span><span><span>(<span>23</span>, <span>'Henry'</span>, <span>'it'</span>, <span>104</span>),
</span></span><span><span>(<span>31</span>, <span>'Cindy'</span>, <span>'sales'</span>, <span>96</span>),
</span></span><span><span>(<span>32</span>, <span>'Dave'</span>, <span>'sales'</span>, <span>96</span>),
</span></span><span><span>(<span>33</span>, <span>'Alice'</span>, <span>'sales'</span>, <span>100</span>);
</span></span></code></pre></div><codapi-snippet id="insert.sql" sandbox="postgres" editor="basic" template="#status.tpl" depends-on="create.sql"></codapi-snippet><p>Finally, rank the employees according to their salaries in each department:</p><div><pre tabindex="0"><code data-lang="sql"><span><span><span>select</span>
</span></span><span><span>  <span>department</span> <span>as</span> <span>dep</span>,
</span></span><span><span>  <span>dense_rank</span>() <span>over</span> <span>w</span> <span>as</span> <span>rank</span>,
</span></span><span><span>  <span>name</span>, <span>salary</span>
</span></span><span><span><span>from</span> <span>employees</span>
</span></span><span><span><span>window</span> <span>w</span> <span>as</span> (
</span></span><span><span>  <span>partition</span> <span>by</span> <span>department</span>
</span></span><span><span>  <span>order</span> <span>by</span> <span>salary</span> <span>desc</span>
</span></span><span><span>)
</span></span><span><span><span>order</span> <span>by</span> <span>department</span>, <span>rank</span>;
</span></span></code></pre></div><codapi-snippet sandbox="postgres" editor="basic" template="#select.tpl" depends-on="insert.sql"></codapi-snippet><p>As you can probably see, the <code>insert</code> snippet depends on the <code>create</code> snippet, while the <code>select</code> snippet depends on both <code>create</code> and <code>insert</code>, forming a dependency chain:</p><pre tabindex="0"><code>create ← insert ← select
</code></pre><p>This is how the snippets work:</p><ul><li>When you run the <code>insert</code> snippet, it automatically creates the table before inserting the data.</li><li>When you run the <code>select</code> snippet, it automatically creates the table and inserts the records before selecting the data.</li></ul><p>The dependencies do not have to be linear, they can form an (acyclic) graph. Suppose we want to <code>describe</code> the table schema:</p><pre tabindex="0"><code>\d employees;
</code></pre><codapi-snippet sandbox="postgres" editor="basic" template="#select.tpl" depends-on="create.sql"></codapi-snippet><p>The <code>describe</code> snippet does not need table data, so it can depend directly on the <code>create</code> snippet:</p><pre tabindex="0"><code>create ← insert ← select
   ↖
  describe
</code></pre><p>More complex dependency graphs are also possible, as long as there are no cycles:</p><pre tabindex="0"><code>create ← insert-1 ← select
       ↖ insert-2 ↙
</code></pre><p>You probably get the idea.</p><h2 id="implementation">Implementation</h2><p>Back to our example. Suppose we started with two static code examples — <code>create</code> and <code>insert</code>:</p><div><pre tabindex="0"><code data-lang="sql"><span><span><span>create</span> <span>table</span> <span>employees</span> (
</span></span><span><span>  <span>id</span> <span>integer</span> <span>primary</span> <span>key</span>,
</span></span><span><span>  <span>name</span> <span>varchar</span>(<span>50</span>),
</span></span><span><span>  <span>department</span> <span>varchar</span>(<span>10</span>),
</span></span><span><span>  <span>salary</span> <span>integer</span>
</span></span><span><span>);
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="sql"><span><span><span>insert</span> <span>into</span> <span>employees</span>
</span></span><span><span>(<span>id</span>, <span>name</span>, <span>department</span>, <span>salary</span>)
</span></span><span><span><span>values</span>
</span></span><span><span>(<span>11</span>, <span>'Diane'</span>, <span>'hr'</span>, <span>70</span>),
</span></span><span><span>(<span>12</span>, <span>'Bob'</span>, <span>'hr'</span>, <span>78</span>),
</span></span><span><span>(<span>21</span>, <span>'Emma'</span>, <span>'it'</span>, <span>84</span>);
</span></span></code></pre></div><p>First, we make them interactive by adding <code>codapi-snippet</code>s.</p><p>➀ Create:</p><pre><code>```sql
create table employees (
  id integer primary key,
  name varchar(50),
  department varchar(10),
  salary integer
);
```

&lt;codapi-snippet id="create.sql" sandbox="postgres" editor="basic"&gt;
&lt;/codapi-snippet&gt;
</code></pre><p>➁ Insert:</p><pre><code>```sql
insert into employees
(id, name, department, salary)
values
(11, 'Diane', 'hr', 70),
(12, 'Bob', 'hr', 78),
(21, 'Emma', 'it', 84);
```

&lt;codapi-snippet id="insert.sql" sandbox="postgres" editor="basic"&gt;
&lt;/codapi-snippet&gt;
</code></pre><p>Then we make <code>insert</code> dependent on <code>create</code> by adding a <code>depends-on</code> attribute:</p><div><pre tabindex="0"><code data-lang="html"><span><span>&lt;<span>codapi-snippet</span> <span>id</span><span>=</span><span>"insert.sql"</span> <span>sandbox</span><span>=</span><span>"postgres"</span> <span>editor</span><span>=</span><span>"basic"</span>
</span></span><span><span>    <span>depends-on</span><span>=</span><span>"create.sql"</span>&gt;
</span></span><span><span>&lt;/<span>codapi-snippet</span>&gt;
</span></span></code></pre></div><p>The rest is automatic!</p><p>Behind the scenes, <code>codapi-snippet</code> calls a <a href="https://github.com/nalgeon/codapi">codapi</a> server (either a cloud or self-hosted instance) so it can run any programming language, database or software you've configured.</p><p>As you know, Jupyter notebooks are stateful — that is, they store the state of variables between cell invocations. This can be a good thing for prototyping, but not for documentation or explanation.</p><p>The last thing I want as a reader is code examples that fail or behave oddly because they were run out of order. Or because I didn't run some cells. Or because I changed a cell and didn't re-run it.</p><p>Codapi code cells, unlike Jupyter's, have no hidden state. Instead, they execute the whole chain of dependencies as needed to ensure that the reader gets a consistent result.</p><h2 id="summary">Summary</h2><p>Codapi provides an easy way to create interactive examples in technical documentation. It gets even easier with code cells, which allow declarative dependencies between snippets of code.</p><p>Give it a try!</p><p><a href="https://codapi.org/">About Codapi</a> •
<a href="https://github.com/nalgeon/codapi">Codapi server</a> •
<a href="https://github.com/nalgeon/codapi-js">Snippet widget</a></p><p><em><a href="https://antonz.org/subscribe/"><i></i>&nbsp;<strong>Subscribe</strong></a>
to keep up with new posts.</em></p></div></article></div></div>]]></description>
        </item>
    </channel>
</rss>