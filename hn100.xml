<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 19 Oct 2024 20:30:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Svelte 5 Released (105 pts)]]></title>
            <link>https://www.npmjs.com/package/svelte</link>
            <guid>41889674</guid>
            <pubDate>Sat, 19 Oct 2024 18:38:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npmjs.com/package/svelte">https://www.npmjs.com/package/svelte</a>, See on <a href="https://news.ycombinator.com/item?id=41889674">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div id="readme"><p><a href="https://svelte.dev/" rel="nofollow"><img src="https://camo.githubusercontent.com/859edad6e38e149fe3782b13564f3f88c64d731fbc47c3a2fe4556b34eb8f00d/68747470733a2f2f7376656c74656a732e6769746875622e696f2f6173736574732f62616e6e65722e706e67" alt="Cybernetically enhanced web apps: Svelte" data-canonical-src="https://sveltejs.github.io/assets/banner.png"></a></p>
<p><a href="https://www.npmjs.com/package/svelte" rel="nofollow"><img src="https://camo.githubusercontent.com/aa233b2ce5693c2189f6570b03a4fe9c0afdeb4ded145cb67c98e1a790297832/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f762f7376656c74652e737667" alt="npm version" data-canonical-src="https://img.shields.io/npm/v/svelte.svg"></a> <a href="https://github.com/sveltejs/svelte/blob/HEAD/packages/svelte/LICENSE.md"><img src="https://camo.githubusercontent.com/3fedb1706708c94fa3d5afa55f4021f54f2d3233d346a0ba1bc4d7995e68c692/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f6c2f7376656c74652e737667" alt="license" data-canonical-src="https://img.shields.io/npm/l/svelte.svg"></a> <a href="https://svelte.dev/chat" rel="nofollow"><img src="https://camo.githubusercontent.com/c2c90158c480032a45adcec99107f21ec25c717ce49e05fadff5a3af57d41270/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f3435373931323037373237373835353736343f6c6162656c3d63686174266c6f676f3d646973636f7264" alt="Chat" data-canonical-src="https://img.shields.io/discord/457912077277855764?label=chat&amp;logo=discord"></a></p>
<div><h2>What is Svelte?</h2></div>
<p>Svelte is a new way to build web applications. It's a compiler that takes your declarative components and converts them into efficient JavaScript that surgically updates the DOM.</p>
<p>Learn more at the <a href="https://svelte.dev/" rel="nofollow">Svelte website</a>, or stop by the <a href="https://svelte.dev/chat" rel="nofollow">Discord chatroom</a>.</p>
<div><h2>Getting started</h2></div>
<p>You can play around with Svelte in the <a href="https://learn.svelte.dev/" rel="nofollow">tutorial</a>, <a href="https://svelte.dev/examples" rel="nofollow">examples</a>, and <a href="https://svelte.dev/repl" rel="nofollow">REPL</a>.</p>
<p>When you're ready to build a full-fledge application, we recommend using <a href="https://kit.svelte.dev/" rel="nofollow">SvelteKit</a>:</p>
<div><pre>npm create svelte@latest my-app
<span>cd</span> my-app
npm install
npm run dev</pre></div>
<p>See <a href="https://kit.svelte.dev/docs" rel="nofollow">the SvelteKit documentation</a> to learn more.</p>
<div><h2>Changelog</h2></div>
<p><a href="https://github.com/sveltejs/svelte/blob/master/packages/svelte/CHANGELOG.md">The Changelog for this package is available on GitHub</a>.</p>
<div><h2>Supporting Svelte</h2></div>
<p>Svelte is an MIT-licensed open source project with its ongoing development made possible entirely by fantastic volunteers. If you'd like to support their efforts, please consider:</p>
<ul>
<li>
<a href="https://opencollective.com/svelte" rel="nofollow">Becoming a backer on Open Collective</a>.</li>
</ul>
<p>Funds donated via Open Collective will be used for compensating expenses related to Svelte's development.</p>
</div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Love being interrupted when my monitor asks me to accept user agreements (198 pts)]]></title>
            <link>https://twitter.com/snwy_me/status/1847396175961641176</link>
            <guid>41889140</guid>
            <pubDate>Sat, 19 Oct 2024 17:27:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/snwy_me/status/1847396175961641176">https://twitter.com/snwy_me/status/1847396175961641176</a>, See on <a href="https://news.ycombinator.com/item?id=41889140">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Have McKinsey and its consulting rivals got too big? (135 pts)]]></title>
            <link>https://www.economist.com/business/2024/03/25/have-mckinsey-and-its-consulting-rivals-got-too-big</link>
            <guid>41888061</guid>
            <pubDate>Sat, 19 Oct 2024 14:46:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/business/2024/03/25/have-mckinsey-and-its-consulting-rivals-got-too-big">https://www.economist.com/business/2024/03/25/have-mckinsey-and-its-consulting-rivals-got-too-big</a>, See on <a href="https://news.ycombinator.com/item?id=41888061">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p><span><a href="https://www.economist.com/business" data-analytics="sidebar:section"><span>Business</span></a></span><span> | <!-- -->The lost art of self-management</span></p><h2>The golden age for CEO whisperers may be coming to an end</h2></section><div><div><p><time datetime="2024-03-25T22:03:59.042Z"> <!-- -->Mar 25th 2024</time></p></div><section data-body-id="cp2"><p data-component="paragraph"><span data-caps="initial">A</span><small>N ANONYMOUS MEMO</small> briefly circled the web in March. The authors, who claimed to be former partners at McKinsey, rebuked the illustrious strategy consultancy for its pursuit in recent years of “unchecked and unmanaged growth”, and chastised its leadership for, of all things, a “lack of strategic focus”. With humility typical of McKinseyites, they warned that “an organisation of genuine greatness” was at risk of being lost.</p></section><p>This article appeared in the Business section of the print edition under the headline “The lost art of self-management”</p><div data-tracking-id="content-well-chapter-list"><h2><a href="https://www.economist.com/business">Business</a> <span>March 30th 2024</span></h2><ul><li><a href="https://www.economist.com/business/2024/03/25/have-mckinsey-and-its-consulting-rivals-got-too-big"><span>Have McKinsey and its consulting rivals got too big?</span></a></li><li><a href="https://www.economist.com/business/2024/03/27/making-accounting-sexy-again"><span>Making accounting sexy again</span></a></li><li><a href="https://www.economist.com/business/2024/03/27/a-marketing-victory-for-nike-is-a-business-win-for-adidas"><span>A marketing victory for Nike is a business win for Adidas</span></a></li><li><a href="https://www.economist.com/business/2024/03/27/the-pros-and-cons-of-corporate-uniforms"><span>The pros and cons of corporate uniforms</span></a></li><li><a href="https://www.economist.com/business/2024/03/27/regulators-are-forcing-big-tech-to-rethink-its-ai-strategy"><span>Regulators are forcing big tech to rethink its AI strategy</span></a></li><li><a href="https://www.economist.com/business/2024/03/27/dave-calhoun-bows-out-as-chief-executive-of-boeing"><span>Dave Calhoun bows out as chief executive of Boeing</span></a></li><li><a href="https://www.economist.com/business/2024/03/27/meet-the-digital-david-taking-on-the-google-goliath"><span>Meet the digital David taking on the Google Goliath</span></a></li></ul></div><div orientation="vertical" data-test-id="vertical"><div orientation="vertical"><figure><img loading="lazy" width="1280" height="1709" decoding="async" data-nimg="1" sizes="300px" srcset="https://www.economist.com/cdn-cgi/image/width=16,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 16w, https://www.economist.com/cdn-cgi/image/width=32,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 32w, https://www.economist.com/cdn-cgi/image/width=48,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 48w, https://www.economist.com/cdn-cgi/image/width=64,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 64w, https://www.economist.com/cdn-cgi/image/width=96,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 96w, https://www.economist.com/cdn-cgi/image/width=128,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 128w, https://www.economist.com/cdn-cgi/image/width=256,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 256w, https://www.economist.com/cdn-cgi/image/width=360,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 360w, https://www.economist.com/cdn-cgi/image/width=384,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 384w, https://www.economist.com/cdn-cgi/image/width=480,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 480w, https://www.economist.com/cdn-cgi/image/width=600,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 600w, https://www.economist.com/cdn-cgi/image/width=834,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 834w, https://www.economist.com/cdn-cgi/image/width=960,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 960w, https://www.economist.com/cdn-cgi/image/width=1096,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 1096w, https://www.economist.com/cdn-cgi/image/width=1280,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 1280w, https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg 1424w" src="https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20240330_DE_US.jpg"></figure></div><div orientation="vertical"><h3 orientation="vertical">From the March 30th 2024 edition</h3><p orientation="vertical">Discover stories from this section and more in the list of contents</p><p><a href="https://www.economist.com/weeklyedition/2024-03-30" data-analytics="sidebar:weekly_edition"><span>Explore the edition</span></a></p></div></div><div><p><a href="https://s100.copyright.com/AppDispatchServlet?publisherName=economist&amp;publication=economist&amp;title=Have%20McKinsey%20and%20its%20consulting%20rivals%20got%20too%20big%3F&amp;publicationDate=2024-03-25&amp;contentID=%2Fcontent%2Fh2uo27nddgkvs01g3l6va42ufik5tavk&amp;type=A&amp;orderBeanReset=TRUE" target="_blank" rel="noreferrer" data-analytics="end_of_article:reuse_this_content"><span>Reuse this content</span></a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Send: Open-source fork of Firefox Send (109 pts)]]></title>
            <link>https://send.vis.ee/</link>
            <guid>41887378</guid>
            <pubDate>Sat, 19 Oct 2024 12:17:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://send.vis.ee/">https://send.vis.ee/</a>, See on <a href="https://news.ycombinator.com/item?id=41887378">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The long road to lazy preemption in the Linux CPU scheduler (188 pts)]]></title>
            <link>https://lwn.net/SubscriberLink/994322/45aa5211a50bc63a/</link>
            <guid>41886256</guid>
            <pubDate>Sat, 19 Oct 2024 07:29:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/SubscriberLink/994322/45aa5211a50bc63a/">https://lwn.net/SubscriberLink/994322/45aa5211a50bc63a/</a>, See on <a href="https://news.ycombinator.com/item?id=41886256">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<blockquote>
<div>
<h3>Welcome to LWN.net</h3>
<p>
The following subscription-only content has been made available to you 
by an LWN subscriber.  Thousands of subscribers depend on LWN for the 
best news from the Linux and free software communities.  If you enjoy this 
article, please consider <a href="https://lwn.net/subscribe/">subscribing to LWN</a>.  Thank you
for visiting LWN.net!
</p></div>
</blockquote>
<p>
The kernel's CPU scheduler currently offers several preemption modes that
implement a range of tradeoffs between system throughput and response time.
Back in September 2023, a <a href="https://lwn.net/Articles/944686/">discussion
on scheduling</a> led to the concept of "lazy preemption", which could
simplify scheduling in the kernel while providing better results.  Things
went quiet for a while, but lazy preemption has returned in the form of <a href="https://lwn.net/ml/all/20241007074609.447006177@infradead.org">this patch series</a>
from Peter Zijlstra.  While the concept appears to work well, there is
still a fair amount of work to be done.
</p><h4>Some review</h4>
<p>
Current kernels have four different modes that regulate when one task can
be preempted in favor of another.  <tt>PREEMPT_NONE</tt>, the simplest
mode, only allows preemption to happen when the running task has exhausted
its time slice.  <tt>PREEMPT_VOLUNTARY</tt> adds a large number of points
within the kernel where preemption can happen if needed.
<tt>PREEMPT_FULL</tt> allows preemption at almost any point except places
in the kernel that prevent it, such as when a spinlock is held.  Finally,
<tt>PREEMPT_RT</tt> prioritizes preemption over most other things, even
making most spinlock-holding code preemptible.
</p><p>
A higher level of preemption enables the system to respond more quickly to
events; whether an event is the movement of a mouse or an "imminent
meltdown" signal from a nuclear reactor, faster response tends to be more
gratifying.  But a higher level of preemption can hurt the overall
throughput of the system; workloads with a lot of long-running,
CPU-intensive tasks tend to benefit from being disturbed as little as
possible.  More frequent preemption can also lead to higher lock
contention.  That is why the different modes exist; the optimal preemption
mode will vary for different workloads.
</p><p>
Most distributions ship kernels built with the <tt>PREEMPT_DYNAMIC</tt>
pseudo-mode, which allows any of the first three modes to be selected at
boot time, with <tt>PREEMPT_VOLUNTARY</tt> being the default.  On systems
with debugfs mounted, the current mode can be read from
<tt>/sys/kernel/debug/sched/preempt</tt>.
</p><p>
<tt>PREEMPT_NONE</tt> and <tt>PREEMPT_VOLUNTARY</tt> do not allow the
arbitrary preemption of code running in the kernel; there are times when
that can lead to excessive latency even in systems where minimal latency is
not prioritized.  This problem is the result of places in the kernel where
a large amount of work can be done; if that work is allowed to run
unchecked, it can disrupt the scheduling of the system as a whole.  To get
around this problem, long-running loops have been sprinkled with calls to
<tt>cond_resched()</tt>, each of which is an additional voluntary
preemption point that is active even in the <tt>PREEMPT_NONE</tt> mode.
There are hundreds of these calls in the kernel.
</p><p>
There are some problems with this approach.  <tt>cond_resched()</tt> is a
form of heuristic that only works in the places where a developer has
thought to put it.  Some calls are surely unnecessary, while there will be
other places in the kernel that could benefit from <tt>cond_resched()</tt>
calls, but do not have them.  The use of <tt>cond_resched()</tt>, at its
core, takes a decision that should be confined to the scheduling code and
spreads it throughout the kernel.  It is, in short, a bit of a hack that
mostly works, but which could be done better.
</p><h4>Doing better</h4>
<p>
The tracking of whether a given task can be preempted at any moment is a
complicated affair that must take into account several variables; see <a href="https://lwn.net/Articles/945422/">this article</a> and <a href="https://lwn.net/Articles/831678/">this article</a> for details.  One of those
variables is a simple flag, <tt>TIF_NEED_RESCHED</tt>, that indicates the
presence of a higher-priority task that is waiting for access to the CPU.
Events such as waking a high-priority task can cause that flag to be set in
whatever task is currently running.  In the absence of this flag, there is
no need for the kernel to consider preempting the current task.
</p><p>
There are various points where the kernel can notice that flag and cause
the currently running task to be preempted.  The scheduler's timer tick is
one example; any time a task returns to user space from a system call is
another.  The completion of an interrupt handler is yet another, but that
check, which can cause preemption to happen any time that interrupts are
enabled, is only enabled in <tt>PREEMPT_FULL</tt> kernels.  A call to
<tt>cond_resched()</tt> will also check that flag and, if it is set, call
into the scheduler to yield the CPU to the other task.
</p><p>
The lazy-preemption patches are simple at their core; they add another
flag, <tt>TIF_NEED_RESCHED_LAZY</tt>, that indicates a need for
rescheduling at some point, but not necessarily right away.  In the lazy
preemption mode (<tt>PREEMPT_LAZY</tt>), most events will set the new flag
rather than <tt>TIF_NEED_RESCHED</tt>.  At points like the return to user
space from the kernel, either flag will lead to a call into the scheduler.
At the voluntary preemption points and in the return-from interrupt path,
though, only <tt>TIF_NEED_RESCHED</tt> is checked.
</p><p>
The result of this change is that, in lazy-preemption mode, most events in
the kernel will not cause the current task to be preempted.  That task
<i>should</i> be preempted eventually, though.  To make that happen, the
kernel's timer-tick handler will check whether
<tt>TIF_NEED_RESCHED_LAZY</tt> is set; if so, <tt>TIF_NEED_RESCHED</tt>
will also be set, possibly causing the running task to be preempted.  Tasks
will generally end up running for something close to their full time slice
unless they give up the CPU voluntarily, which should lead to good
throughput. 
</p><p>
With these changes, the lazy-preemption mode can, like
<tt>PREEMPT_FULL</tt>, run with kernel preemption enabled at (almost) all
times.  Preemption <i>can</i> happen any time that the preemption counter
says that it should.  That allows long-running kernel code to be preempted
whenever other conditions do not prevent it.  It also allows preemption to
happen quickly in those cases where it is truly needed.  For example, 
should a realtime task become runnable, as the result of
handling an interrupt, for example, the <tt>TIF_NEED_RESCHED</tt> flag will
be set, leading to an almost immediate preemption.  There will be no need
to wait for the timer tick in such cases.
</p><p>
Preemption will <i>not</i> happen, though, if only
<tt>TIF_NEED_RESCHED_LAZY</tt> is set, which will be the case much of the
time. So a <tt>PREEMPT_LAZY</tt> kernel will be far less likely to preempt
a running task than a <tt>PREEMPT_FULL</tt> kernel.
</p><h4>Removing <tt>cond_resched()</tt> — eventually</h4>
<p>
The end goal of this work is to have a scheduler with only two non-realtime
modes: <tt>PREEMPT_LAZY</tt> and <tt>PREEMPT_FULL</tt>.  The lazy mode will
occupy a place between <tt>PREEMPT_NONE</tt> and
<tt>PREEMPT_VOLUNTARY</tt>, replacing both of them.  It will, however, not
need the voluntary preemption points that were added for the two modes it
replaces.  Since preemption can now happen almost anywhere, there is no
longer a need to enable it in specific spots.
</p><p>
For now, though, the <tt>cond_resched()</tt> calls remain; if nothing else,
they are required for as long as the <tt>PREEMPT_NONE</tt> and
<tt>PREEMPT_VOLUNTARY</tt> modes exist.  Those calls also help to ensure
that problems are not introduced while lazy preemption is being stabilized.
</p><p>
In the current patch set, <tt>cond_resched()</tt> only checks
<tt>TIF_NEED_RESCHED</tt>, meaning that preemption will be deferred in many
situations where it will happen immediately from <tt>cond_resched()</tt> in
<tt>PREEMPT_VOLUNTARY</tt> or <tt>PREEMPT_NONE</tt> mode.
Steve Rostedt <a href="https://lwn.net/ml/all/20241009100133.2569e2a7@gandalf.local.home">questioned</a>
this change, asking whether <tt>cond_resched()</tt> should retain its older
meaning, at least for the <tt>PREEMPT_VOLUNTARY</tt> case.  Even though
<tt>PREEMPT_VOLUNTARY</tt> is slated for eventual removal, he thought,
keeping the older behavior could help to ease the transition.
</p><p>
Thomas Gleixner
<a href="https://lwn.net/ml/all/87h69lqbk0.ffs@tglx">answered</a> that only checking
<tt>TIF_NEED_RESCHED</tt> is the correct choice, since it will help in the
process of removing the <tt>cond_resched()</tt> calls entirely:
</p><blockquote>
	That forces us to look at all of them and figure out whether they
	need to be extended to include the lazy bit or not. Those which do
	not need it can be eliminated when LAZY is in effect because that
	will preempt on the next possible preemption point once the
	non-lazy bit is set in the tick.
</blockquote>
<p>
He added that he expects "<q>less than 5%</q>" of the
<tt>cond_resched()</tt> calls need to check <tt>TIF_NEED_RESCHED_LAZY</tt>
and, thus, will need to remain even after the transition to
<tt>PREEMPT_LAZY</tt> is complete.
</p><p>
Before then, though, there are hundreds of <tt>cond_resched()</tt> calls
that need to be checked and, for most of them at least, removed.  Many
other details have to be dealt with as well; <a href="https://lwn.net/ml/all/20241009165411.3426937-1-ankur.a.arora@oracle.com">this patch
set</a> from Ankur Arora addresses a few of them.  There is
also, of course, the need for extensive performance testing; Mike Galbraith
has made <a href="https://lwn.net/ml/all/579b7ea34ef6e2f7c955abdfc0929fe1af36faef.camel@gmx.de">an
early start</a> on that work, showing that throughput with lazy preemption
falls just short of that with <tt>PREEMPT_VOLUNTARY</tt>.
</p><p>
It all adds up to a lot to be done still, but the end result
of the lazy-preemption work should be a kernel that is a bit smaller and
simpler while delivering predictable latencies without the need to
sprinkle scheduler-related calls throughout the code.  That seems like a
better solution, but getting there is going to take some time.<br clear="all"></p><table>
           <tbody><tr><th colspan="2">Index entries for this article</th></tr>
           <tr><td><a href="https://lwn.net/Kernel/Index">Kernel</a></td><td><a href="https://lwn.net/Kernel/Index#Preemption">Preemption</a></td></tr>
            <tr><td><a href="https://lwn.net/Kernel/Index">Kernel</a></td><td><a href="https://lwn.net/Kernel/Index#Scheduler">Scheduler</a></td></tr>
            </tbody></table><br clear="all">

               <br clear="all">
               <hr>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US probes Tesla's Full Self-Driving software in 2.4M cars after fatal crash (139 pts)]]></title>
            <link>https://www.reuters.com/business/autos-transportation/nhtsa-opens-probe-into-24-mln-tesla-vehicles-over-full-self-driving-collisions-2024-10-18/</link>
            <guid>41884740</guid>
            <pubDate>Sat, 19 Oct 2024 00:46:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/business/autos-transportation/nhtsa-opens-probe-into-24-mln-tesla-vehicles-over-full-self-driving-collisions-2024-10-18/">https://www.reuters.com/business/autos-transportation/nhtsa-opens-probe-into-24-mln-tesla-vehicles-over-full-self-driving-collisions-2024-10-18/</a>, See on <a href="https://news.ycombinator.com/item?id=41884740">Hacker News</a></p>
Couldn't get https://www.reuters.com/business/autos-transportation/nhtsa-opens-probe-into-24-mln-tesla-vehicles-over-full-self-driving-collisions-2024-10-18/: Error: Request failed with status code 401]]></description>
        </item>
    </channel>
</rss>