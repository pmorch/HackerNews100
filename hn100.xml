<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 25 May 2025 03:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Scientific conferences are leaving the US amid border fears (178 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-025-01636-5</link>
            <guid>44084017</guid>
            <pubDate>Sat, 24 May 2025 21:53:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-025-01636-5">https://www.nature.com/articles/d41586-025-01636-5</a>, See on <a href="https://news.ycombinator.com/item?id=44084017">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-test="access-teaser"> <figure><picture><source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-025-01636-5/d41586-025-01636-5_51009448.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-025-01636-5/d41586-025-01636-5_51009448.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px"><img alt="Rear view of a female speaker presenting to large group of seat people in a lecture hall." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-025-01636-5/d41586-025-01636-5_51009448.jpg"><figcaption><p><span>Some conferences have been relocated in response to researchers’ concerns about visiting the United States.</span><span>Credit: skynesher/Getty</span></p></figcaption></picture></figure><p>Several academic and scientific conferences in the United States have been postponed, cancelled or moved elsewhere, as organizers respond to researchers’ growing fears over the country’s <a href="https://www.nature.com/articles/d41586-025-00859-w" data-track="click" data-label="https://www.nature.com/articles/d41586-025-00859-w" data-track-category="body text link">immigration crackdown</a>.</p><p>Organizers of these meetings say that tougher rules around visas and border control — alongside other <a href="https://www.nature.com/articles/d41586-025-01295-6" data-track="click" data-label="https://www.nature.com/articles/d41586-025-01295-6" data-track-category="body text link">policies introduced by US President Donald Trump’s administration</a> — are discouraging international scholars from attending events on US soil. In response, they are moving the conferences to countries such as Canada, in a bid to boost attendance.</p><article data-label="Related"><a href="https://www.nature.com/articles/d41586-025-00859-w" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-025-01636-5/d41586-025-01636-5_50797308.jpg"><p>‘Anxiety is palpable’: detention of researchers at US border spurs travel worries</p></a></article><p>The trend, if it proves to be widespread, could have an effect on US scientists, as well as on cities or venues that regularly host conferences.</p><p>“Conferences are an amazing barometer of international activity,” says Jessica Reinisch, a historian who studies international conferences at Birkbeck University of London. “It’s almost like an external measure of just how engaged in the international world practitioners of science are.”</p><p>“What is happening now is a reverse moment,” she adds. “It’s a closing down of borders, closing of spaces … a moment of deglobalization.”</p><h2>Unpopular location</h2><p>Conferences help researchers to connect, share new discoveries and shape the priorities of their fields. But events such as the <a href="https://www.nature.com/articles/d41586-025-01056-5" data-track="click" data-label="https://www.nature.com/articles/d41586-025-01056-5" data-track-category="body text link">detention and deportation of international scholars</a> are pushing some academic societies and institutes to rethink where they hold their meetings.</p><p>One of those is the International Society for Research on Aggression (ISRA), which announced last month that it would relocate its 2026 meeting from New Jersey to St. Catharines, Canada, after a survey of its members suggested that many international researchers would not attend a US meeting.</p><p>“It was clear to us that, if we held a meeting in the US, based on the feedback we received, that we might not get enough people to register,” says Dominic Parrott, a clinical psychologist at Georgia State University in Atlanta, and ISRA’s president-elect. “We wanted to make sure that we were going to get our members and non-members from many different parts of the world, because that makes the best meeting and helps produce the best science.”</p><article data-label="Related"><a href="https://www.nature.com/collections/jcjhabjhgi" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-025-01636-5/d41586-025-01636-5_50683482.jpg"><p>How Trump 2.0 is reshaping science</p></a></article><p>Organizers of the International Conference on Comparative Cognition have made a similar call. Its 33rd annual conference next year will take place outside the United States for the first time in the society’s history, in Montreal, Canada. “It was really a difficult decision for us,” says Caroline Strang, one of the conference organizers and a psychologist at Western University in London, Canada. “With things as unpredictable as they felt at the time and still feel, it’s a decision we made that allows as many of our attendees to come as possible.”</p><p>The Northwest Cognition &amp; Memory (NOWCAM) meeting relocated its meeting earlier this month from Western Washington University in Bellingham to Victoria, Canada.</p><p>Stephen Lindsay, a psychologist at the University of Victoria, one of the meeting’s organizers, says that most attendees are students in Canada. “I was concerned that many of them would decide not to attend NOWCAM if doing so entailed crossing the border,” he tells <i>Nature</i>. This is a choice he has had to make himself. “I plan to avoid travel to the US until relations improve, even though that means forgoing important annual conferences such as the annual meeting of the Psychonomic Society [in Denver, Colorado, in November], which I have rarely missed over the last 39 years.”</p><h2>Cancelled plans</h2><p>Other US meetings have been postponed, or cancelled altogether, because of similar or related concerns. The International Association of Cognitive Behavioral Therapy has <a href="https://www.linkedin.com/posts/stephaniewoodrow_cbtworks-anxiety-depression-activity-7303894013131059201-9LCG/" data-track="click" data-label="https://www.linkedin.com/posts/stephaniewoodrow_cbtworks-anxiety-depression-activity-7303894013131059201-9LCG/" data-track-category="body text link">cancelled its conference</a>, originally planned for August 2025 in Nashville, Tennessee, because <a href="https://www.nature.com/articles/d41586-025-01397-1" data-track="click" data-label="https://www.nature.com/articles/d41586-025-01397-1" data-track-category="body text link">cuts to federal funding</a> meant it was “no longer financially viable”. The 2026 Cities on Volcanoes conference in Bend, Oregon, has been <a href="https://citiesonvolcanoes.wordpress.com/news/" data-track="click" data-label="https://citiesonvolcanoes.wordpress.com/news/" data-track-category="body text link">postponed to 2030 or 2032</a>. The International X-ray Absorption Society <a href="https://www.icdd.com/xafs19/" data-track="click" data-label="https://www.icdd.com/xafs19/" data-track-category="body text link">cancelled its upcoming 19th conference in Chicago</a><a href="https://www.icdd.com/xafs19/" data-track="click" data-label="https://www.icdd.com/xafs19/" data-track-category="body text link">, Illinois</a>, which was scheduled for July this year. “We started to have cancellations by invited speakers,” says Carlo Segre, a physicist at Illinois Institute of Technology in Chicago, and one of the conference organizers. “It is not clear when this conference will be held in the USA once again.” The group will have its meeting in Thailand next year.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: 1 min workouts for people who sit all day (108 pts)]]></title>
            <link>https://shortreps.com</link>
            <guid>44083687</guid>
            <pubDate>Sat, 24 May 2025 20:41:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://shortreps.com">https://shortreps.com</a>, See on <a href="https://news.ycombinator.com/item?id=44083687">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <!--...::: Header Start :::... -->
        
        <!--...::: Header End :::... -->

       
           
       
<main>
            <!--...::: Hero Section Start :::... -->
            <div>
                                <!-- Hero Content Block -->
                                <div data-jos_animation="fade-left">
                                <p><span>STAY ACTIVE</span></p><h2>
                                    Micro Execises during your day
                                    </h2>
                                    <p>
                                    Sneak in exercises to keep you powered up during your busiest days
                                    </p>
                                    <p><a href="https://apps.apple.com/us/app/id6746220793">
                                        <img src="https://shortreps.com/landing/imgs/appstore.png" alt="Get ShortReps App On App Store" width="166" height="54">

                                    </a>
                                </p></div>
                                <!-- Hero Content Block -->
                                <!-- Hero Image Block -->

                                
                                <p><img src="https://shortreps.com/landing/imgs/shortreps-app.png" alt="ShortReps Mobile App" width="584" height="575">
                                   
                                </p>
                                <!-- Hero Image Block -->
                            </div>
            <!--...::: Hero Section End :::... -->



             <!--...::: Fact Section Start :::... -->
             
            <!--...::: Fact Section End :::... -->



                 <!--...::: Content Section Start :::... -->
                 <div>
                                <!-- Content Block Left -->
                                <div data-jos_animation="fade-right">
                                    <!-- Section Wrapper -->
                                    <div>
                                        <!-- Section Tag -->
                                        <p><span>
                                        Exercise Snacks</span></p><!-- Section Tag -->
                                        <!-- Section Block -->
                                        <p>
                                            <h2>
                                            No-Excuse, Anywhere Exercises
                                            </h2>
                                        </p>
                                        <!-- Section Block -->
                                    </div>
                                    <!-- Section Wrapper -->
                                    <p>
                                    ShortReps gives you short bodyweight routines you can do anywhere — between meetings, at home, or while waiting for coffee.
                                    </p>
                                 
                                </div>
                                <!-- Content Block Left -->
                                <!-- Content Block Right -->
                                <p><img src="https://shortreps.com/landing/imgs/mini-exercises.png" alt="ShortReps App Mini Exercises" width="564" height="450">
                                </p>
                                <!-- Content Block Right -->
                            </div>
            <!--...::: Content Section End :::... -->



             <!--...::: Content Section Start :::... -->
             <div id="section-about">
                                <!-- Content Block Left -->
                                <div data-jos_animation="fade-left">
                                    <!-- Section Wrapper -->
                                    <div>
                                        <!-- Section Tag -->
                                        <p><span>
                                        Custom To You</span></p><!-- Section Tag -->
                                        <!-- Section Block -->
                                        <p>
                                            <h2>
                                            AI-Picked Daily Challenges
                                            </h2>
                                        </p>
                                        <!-- Section Block -->
                                    </div>
                                    <!-- Section Wrapper -->
                                    <p>
                                    Every day, ShortReps picks 5 exercises tailored to your fitness level. All you need to do is complete them before midnight.
                                    </p>
                           
                                </div>
                                <!-- Content Block Left -->
                                <!-- Content Block Right -->
                                <p><img src="https://shortreps.com/landing/imgs/Complete-daily-challenge.png" alt="daily exercise challenge" width="601" height="450">
                                </p>
                                <!-- Content Block Right -->
                            </div>
            <!--...::: Content Section End :::... -->


               <!--...::: Content Section Start :::... -->
               <div>
                                <!-- Content Block Left -->
                                <div data-jos_animation="fade-right">
                                    <!-- Section Wrapper -->
                                    <div>
                                        <!-- Section Tag -->
                                        <p><span>
                                        Video Guide</span></p><!-- Section Tag -->
                                        <!-- Section Block -->
                                        <p>
                                            <h2>
                                           Exercise Video Instructions
                                            </h2>
                                        </p>
                                        <!-- Section Block -->
                                    </div>
                                    <!-- Section Wrapper -->
                                    <p>
                                    Clear video demos ensure proper posture, reduce injury risk, and maximize effectiveness.
                                    </p>
                                 
                                </div>
                                <!-- Content Block Left -->
                                <!-- Content Block Right -->
                                <p><img src="https://shortreps.com/landing/imgs/Exercise-posture-videos.png" alt="Exercise posture videos" width="564" height="450">
                                </p>
                                <!-- Content Block Right -->
                            </div>
            <!--...::: Content Section End :::... -->



             <!--...::: Content Section Start :::... -->
             <div id="section-about">
                                <!-- Content Block Left -->
                                <div data-jos_animation="fade-left">
                                    <!-- Section Wrapper -->
                                    <div>
                                        <!-- Section Tag -->
                                        <p><span>
                                        Stay On Track</span></p><!-- Section Tag -->
                                        <!-- Section Block -->
                                        <p>
                                            <h2>
                                            Built-in Habit Tracker
                                            </h2>
                                        </p>
                                        <!-- Section Block -->
                                    </div>
                                    <!-- Section Wrapper -->
                                    <p>
                                    Visualize your streak and stay consistent with daily wins. Every checkmark builds momentum — and better health.
                                    </p>
                           
                                </div>
                                <!-- Content Block Left -->
                                <!-- Content Block Right -->
                                <p><img src="https://shortreps.com/landing/imgs/Exercise-habit-tracker.png" alt="daily workout habit tracker" width="601" height="450">
                                </p>
                                <!-- Content Block Right -->
                            </div>
            <!--...::: Content Section End :::... -->




            <!--...::: CTA Section Start :::... -->
            <div>
                            <div>
                                    <h2>
                                    Commit to Daily Micro Exercises During your Day
                                    </h2>
                                    <h2>
                                    No Equipment Needed, Download for Free!
                                    </h2>
                                    <p><a href="https://apps.apple.com/us/app/id6746220793">
                                            <img src="https://shortreps.com/landing/imgs/icon-apple-app-store-light.svg" alt="Get ShortReps App On App Store" width="166" height="54">
                                        </a>
                                       
                                    </p>
                                </div>

                            <!-- Background Shape -->
                            <p><img src="https://shortreps.com/landing/imgs/get-shortreps.svg" alt="Shortreps App Graphic" width="320" height="173">
                        </p></div>            <!--...::: CTA Section End :::... -->
        </main>




           
        

            
        

        <!--...::: Footer Section Start :::... -->
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reinvent the Wheel (233 pts)]]></title>
            <link>https://endler.dev/2025/reinvent-the-wheel/</link>
            <guid>44083467</guid>
            <pubDate>Sat, 24 May 2025 20:05:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://endler.dev/2025/reinvent-the-wheel/">https://endler.dev/2025/reinvent-the-wheel/</a>, See on <a href="https://news.ycombinator.com/item?id=44083467">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><p>Published on 24th of May, 2025</p><p>One of the most harmful pieces of advice is to not reinvent the wheel.</p><p>It usually comes from a good place, but is typically given by two groups of people:</p><ul><li>those who tried to invent a wheel themselves and know how hard it is</li><li>those who never tried to invent a wheel and blindly follow the advice</li></ul><p>Either way, both positions lead to a climate where curiosity and exploration gets discouraged. I’m glad that some people didn’t follow that advice; we owe them many of the conveniences of modern life.</p><p>Even on a surface level, the advice is bad: We have much better wheels today than 4500–3300 BCE when the first wheel was invented. It was also <em>crucially</em> important that wheels got reinvented throughout civilizations and cultures.</p><p><strong>Note:</strong> When I say “wheel” throughout this post, please replace it with whatever tool, protocol, service, technology, or other invention you’re personally interested in.</p><h2 id="inventing-wheels-is-learning"><a href="#inventing-wheels-is-learning"> <svg viewBox="0 0 24 24" height="22" width="22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path></svg> </a>Inventing Wheels Is Learning</h2><blockquote><p><strong>“What I cannot create, I do not understand”</strong><br> – <a href="https://en.wikipedia.org/wiki/Richard_Feynman">Richard Feynman</a>, Physicist and Nobel Prize Winner</p></blockquote><p>To <em>really</em> understand something on a fundamental level, you have to be able to implement a toy version first. It doesn’t matter if it’s any good; you can throw it away later.</p><p>In Computer Science, for example, there are many concepts that are commonly assumed to be beyond the abilities of mere mortals: protocols, cryptography, and web servers come to mind.</p><p>More people should know how these things work. And therefore I think people should not be afraid to recreate them.</p><h2 id="everything-is-a-rabbit-hole"><a href="#everything-is-a-rabbit-hole"> <svg viewBox="0 0 24 24" height="22" width="22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path></svg> </a>Everything Is A Rabbit Hole</h2><p>Too often, fundamental things are taken for granted. For example strings or paths are super complicated concepts in programming. It’s a great exercise to implement a string or a path library yourself if you’re interested in how they work.</p><p>Even if nobody ends up using your work, I bet you’ll learn a lot. For example:</p><ul><li>There is an infinite complexity in everyday things.</li><li>Building something that even a single other person finds useful is a humbling experience.</li><li>Humans like you created these abstractions. They are not perfect and you can make different tradeoffs in your own design.</li></ul><p>On the last point, everything is a tradeoff and there are dozens, sometimes hundreds of footguns with every toy problem.</p><p>Along the way, you will have to make decisions about correctness, simplicity, functionality, scalability, performance, resource usage, portability, and so on.</p><p>Your solution can be great in some of these things, but not all of them and not for all users. That also implies that existing solutions have flaws and might not be designed to solve your particular problem; no matter how well-established the solution is.</p><p>Going down rabbit holes is fun in its own way, but there is one other benefit: It is one of the few ways to level up as an engineer… but only if you don’t give up before you end up with a working version of what you tried to explore. If you jump between projects too often, you will learn nothing.</p><h2 id="reasons-for-reinventing-the-wheel"><a href="#reasons-for-reinventing-the-wheel"> <svg viewBox="0 0 24 24" height="22" width="22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path></svg> </a>Reasons for Reinventing the Wheel</h2><p>There are great reasons to reinvent the wheel:</p><ul><li>Build a better wheel (for some definition of better)</li><li>Learn how wheels are made</li><li>Teach others about wheels</li><li>Learn about the inventors of wheels</li><li>Be able to change wheels or fix them when they break</li><li>Learn the tools needed to make wheels along the way</li><li>Learn a tiny slice of what it means to build a larger system (such as a vehicle)</li><li>Help someone in need of a very special wheel. Maybe for a wheelchair?</li></ul><p>Who knows? The wheel you come up with might not be the best use for a car, but maybe for a… skateboard or a bike? Or you fail building a nicer wheel, but you come up with a better way to test wheels along the way. Heck, your wheel might not even be meant for transportation at all! It might be a potter’s wheel, “a machine used in the shaping (known as throwing) of clay into round ceramic ware” <a href="https://en.wikipedia.org/wiki/Wheel">according to Wikipedia</a>. You might end up building a totally different kind of wheel like a steering wheel or a flywheel. We need more people who think outside the box.</p><h2 id="reuse-vs-reinvent"><a href="#reuse-vs-reinvent"> <svg viewBox="0 0 24 24" height="22" width="22" xmlns="http://www.w3.org/2000/svg"><path d="M0 0h24v24H0z" fill="none"></path><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"></path></svg> </a>Reuse vs Reinvent</h2><p>Of course, don’t disregard the works of others – study their work and reuse where you see fit. Don’t reinvent the wheel out of distrust or ignorance of the work of others. On the other side, if you never tried to put your knowledge to the test, how would you ever learn enough about your field to advance it?</p><p>I observed you can move very quickly by running little experiments. Especially in software engineering, building small prototypes is cheap and quick. Solve your own problem, start small, keep it simple, iterate.</p><p>So, with all of the above, here’s my advice:</p><p><strong>Reinvent for insight. Reuse for impact.</strong></p><ul></ul><div><p>Thanks for reading! If you're looking to level up your programming skills, check out <a href="https://app.codecrafters.io/join?via=mre">CodeCrafters</a> - it's the platform I genuinely recommend to friends. Try it free and get 40% off paid plans.</p><p>Full disclosure: I earn a commission on subscriptions, so you'll be supporting my work while improving your coding skills.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tachy0n: The Last 0day Jailbreak (176 pts)]]></title>
            <link>https://blog.siguza.net/tachy0n/</link>
            <guid>44083388</guid>
            <pubDate>Sat, 24 May 2025 19:50:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.siguza.net/tachy0n/">https://blog.siguza.net/tachy0n/</a>, See on <a href="https://news.ycombinator.com/item?id=44083388">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p><em>Siguza, 23. May 2025</em></p>

<h2 id="tachy0n">tachy0n</h2>

<p>The last 0day jailbreak.</p>

<h2 id="0-introduction">0. Introduction</h2>

<p>Hey.<br>
Long time no see, huh?<br>
People have speculated over the years that someone “bought my silence”, or asked me whether I had moved my blog posts to some other place, but no. Life just got in the way.<br>
This is not the blog post with which I planned to return, but it’s the one for which all the research is said and done, so that’s what you’re getting. I have plenty more that I wanna do, but I’ll be happy if I can even manage to put out two a year.</p>

<p>Now, <em>tachy0n</em>. This is an old exploit, for iOS 13.0 through 13.5, released in <a href="https://unc0ver.dev/">unc0ver</a> v5.0.0 on May 23rd, 2020, exactly 5 years ago today. It was a fairly standard kernel LPE for the time, but one thing that made it noteworthy is that it was dropped as an 0day, affecting the latest iOS version at the time, leading Apple to <a href="https://support.apple.com/en-us/103795">release a patch</a> for just this bug a week later. This is something that used to be common a decade ago, but has become extremely rare - so rare, in fact, that is has never happened again after this.<br>
Another thing that made it noteworthy is that, despite having been an 0day on iOS 13.5, it had actually been exploited before - by me and friends - but as a 1day at the time. And that is where this whole story starts.</p>

<p>In early 2020, <a href="https://github.com/pwn20wndstuff">Pwn20wnd</a> (a jailbreak author, not to be confused with Pwn2Own, the event) contacted me, saying he had found an 0day reachable from the app sandbox, and was asking whether I’d be willing to write an exploit for it. At the time I had been working on <a href="https://checkra.in/">checkra1n</a> for a couple of months, so I figured going back to kernel research was a welcome change of scenery, and I agreed. But where did this bug come from? It was extremely unlikely that someone would’ve just sent him this bug for free, with no strings attached. And despite being a jailbreak author, he wasn’t doing security research himself, so it was equally unlikely that he would discover such a bug. And yet, he did.<br>
The way he managed to beat a trillion dollar corporation was through the kind of simple but tedious and boring work that Apple sucks at: regression testing.</p>

<p>Because, you see: this has happened before. On iOS 12, <a href="https://googleprojectzero.blogspot.com/2019/12/sockpuppet-walkthrough-of-kernel.html">SockPuppet</a> was one of the big exploits used by jailbreaks. It was found and reported to Apple by <a href="https://github.com/nedwill">Ned Williamson</a> from Project Zero, patched by Apple in iOS 12.3, and subsequently unrestricted on the Project Zero bug tracker. But against all odds, it then resurfaced on iOS 12.4, as if it had never been patched. I can only speculate that this was because Apple likely forked XNU to a separate branch for that version and had failed to apply the patch there, but this made it evident that they had no regression tests for this kind of stuff. A gap that was both easy and potentially very rewarding to fill. And indeed, after implementing regression tests for just a few known 1days, Pwn got a hit.</p>

<p>So just for a moment, forget everything you know about kheap separation, forget all the task port mitigations, forget SSV and SPTM… and let’s look at some stuff from the good old times.</p>

<h2 id="1-lightspeed">1. Lightspeed</h2>

<p>First, a quick recap on this bug. This is the <a href="https://www.synacktiv.com/en/publications/lightspeed-a-race-for-an-iosmacos-sandbox-escape.html">Lightspeed</a> bug from Synacktiv (CVE-2020-9859 and possibly CVE-2018-4344). It’s in the <code>lio_listio</code> syscall, which lets you do asynchronous and/or batched file I/O. To keep track of all submitted I/O ops, the kernel allocates this struct:</p>

<div><pre><code><span>struct</span> <span>aio_lio_context</span>
<span>{</span>
    <span>int</span>     <span>io_waiter</span><span>;</span>
    <span>int</span>     <span>io_issued</span><span>;</span>
    <span>int</span>     <span>io_completed</span><span>;</span>
<span>};</span>
</code></pre></div>

<p>The actual work is then performed on a separate thread, which is also responsible for freeing this struct once all I/O has been completed (in <code>do_aio_completion</code>):</p>

<div><pre><code><span>/* Are we done with this lio context? */</span>
<span>if</span> <span>(</span><span>lio_context</span><span>-&gt;</span><span>io_issued</span> <span>==</span> <span>lio_context</span><span>-&gt;</span><span>io_completed</span><span>)</span> <span>{</span>
    <span>lastLioCompleted</span> <span>=</span> <span>TRUE</span><span>;</span>
<span>}</span>
</code></pre></div>
<div><pre><code><span>/*
 * free the LIO context if the last lio completed and no thread is
 * waiting
 */</span>
<span>if</span> <span>(</span><span>lastLioCompleted</span> <span>&amp;&amp;</span> <span>(</span><span>waiter</span> <span>==</span> <span>0</span><span>))</span> <span>{</span>
    <span>free_lio_context</span><span>(</span><span>lio_context</span><span>);</span>
<span>}</span>
</code></pre></div>

<p>But in the case where <em>nothing</em> has been scheduled at all, that code path will never be hit, and so the <em>current</em> thread has to free this struct again, right from <code>lio_listio</code>:</p>

<div><pre><code><span>case</span> <span>LIO_NOWAIT</span><span>:</span>
    <span>/* If no IOs were issued must free it (rdar://problem/45717887) */</span>
    <span>if</span> <span>(</span><span>lio_context</span><span>-&gt;</span><span>io_issued</span> <span>==</span> <span>0</span><span>)</span> <span>{</span>
        <span>free_context</span> <span>=</span> <span>TRUE</span><span>;</span>
    <span>}</span>
    <span>break</span><span>;</span>
</code></pre></div>
<div><pre><code><span>if</span> <span>(</span><span>free_context</span><span>)</span> <span>{</span>
    <span>free_lio_context</span><span>(</span><span>lio_context</span><span>);</span>
<span>}</span>
</code></pre></div>

<p>The problem is just that this check is racy. If work <em>has</em> been submitted to the other thread, but it has <em>already completed</em> by the time this check runs, then <code>lio_context</code> is a dangling pointer here. You can check the <a href="https://www.synacktiv.com/en/publications/lightspeed-a-race-for-an-iosmacos-sandbox-escape.html">original blog post</a> for more details, but in order to exploit this, we want the following sequence of events:</p>

<ol>
  <li><code>lio_listio</code> allocates <code>lio_context</code>.</li>
  <li>The work completes and <code>do_aio_completion</code> frees <code>lio_context</code>.</li>
  <li>We reallocate the freed memory with something we control, such that <code>lio_context-&gt;io_issued == 0</code>.</li>
  <li><code>lio_listio</code> sees <code>lio_context-&gt;io_issued == 0</code> and frees our allocated object.</li>
  <li>We reallocate it again with something else, and now have two entirely different allocations pointing to the same memory.</li>
</ol>

<p>Now, we’re targeting 64-bit devices here, where the smallest zone is <code>kalloc.16</code>, which is where our <code>lio_context</code> goes. Two things help us massively here:</p>
<ol>
  <li>Before iOS 14, allocations of all types shared the same allocation site, only bucketed by object size. So C++ objects, pointer arrays, user-provided data buffers - all in the same place and able to reallocate each other’s memory, giving us many targets to work with.</li>
  <li>Normally with a double free, it’s crucial to get a reallocation step in between the two frees, because otherwise you hit some unrecoverable disaster state. But in our case, once submitted, <code>lio_context-&gt;io_issued</code> never hits zero while allocated, and once it’s freed, the allocator on the OS versions we’re looking at will overwrite the first 8 bytes with a canary value XOR’ed with either the freelist pointer (zalloc) or the object’s address itself (zcache). Thus, the double free <em>only</em> happens if the object is reallocated in between the two frees, and has bytes 4 through 7 zeroed out! And while it <em>can</em> happen that something else on the system snatches the allocation away from under us and zeroes out the necessary bytes to trigger the double free, in practice this is very unlikely, so we’re able to retry this race many times until we get it right.</li>
</ol>

<h2 id="2-spice">2. Spice</h2>

<p>As mentioned, this bug had been exploited before, by a team that I was part of. That was in the <a href="https://github.com/JakeBlair420/Spice">Spice</a> jailbreak/untether together with <a href="https://github.com/PsychoTea">Sparkey</a> and <a href="https://github.com/littlelailo">littlelailo</a>, under our jailbreak team <a href="https://github.com/JakeBlair420">Jake Blair</a>. This targeted iOS 11.x and was written at a time when iOS 13.x was latest, so some things were different than on 13.x and we had some 1days to work with, but a lot of concepts still apply. And while exploitation from racoon has already been documented in <a href="https://media.ccc.de/v/36c3-11034-tales_of_old_untethering_ios_11#t=1185">lailo’s 36C3 talk</a>, that’s only half the story. Because originally, our planned installation flow was like this:</p>

<p><img src="https://blog.siguza.net/tachy0n/assets/img/1-Spice-flow.png" alt="Spice install flow"></p>

<p>So we actually had two different variants of the kernel exploit: one for the app and one for racoon. Lailo’s talk details the one from racoon, but that has some important differences to the one from the app. Because while racoon runs as root, it has a much tighter sandbox than normal apps.</p>

<p>Our goal was the same in both cases: mach port forgery. If you were doing kernel exploitation before iOS 14, this was just the meta. Everyone and their mom was doing it, it’s been explained in detail many, many times so I’m not gonna rehash it here, but fact is: if you could get a user-supplied value interpreted as a pointer to a mach port, it was game over. And doing that was actually very straightforward with lightspeed:</p>

<ol>
  <li>Trigger the first free of <code>lio_context</code>.</li>
  <li>Spray mach messages with an OOL mach ports descriptor of size 1 or 2 whose first entry is <code>MACH_PORT_NULL</code>. This got placed in <code>kalloc.16</code> and <code>MACH_PORT_NULL</code> is <code>0</code>, so it set <code>lio_context-&gt;io_issued</code> to <code>0</code>.</li>
  <li>Trigger the second free of <code>lio_context</code> (i.e. our OOL mach ports array).</li>
  <li>Spray controlled data to <code>kalloc.16</code> to replace the mach ports array with fake pointers.</li>
</ol>

<p>The main difficulty here was just getting controlled data at a known address in the kernel, so that you had a fake pointer to spray. For A7 through A9(X) though, this was actually insultingly easy:</p>

<div><pre><code><span>fakeport</span> <span>=</span> <span>(</span><span>kport_t</span> <span>*</span><span>)</span><span>mmap</span><span>(</span><span>0</span><span>,</span> <span>KDATA_SIZE</span><span>,</span> <span>PROT_READ</span> <span>|</span> <span>PROT_WRITE</span><span>,</span> <span>MAP_PRIVATE</span> <span>|</span> <span>MAP_ANON</span><span>,</span> <span>-</span><span>1</span><span>,</span> <span>0</span><span>);</span>
<span>mlock</span><span>((</span><span>void</span> <span>*</span><span>)</span><span>fakeport</span><span>,</span> <span>KDATA_SIZE</span><span>);</span>
</code></pre></div>

<p>That’s it. There you go, that’s your “kernel” pointer. There’s no PAN, so you can just do userland dereference.<br>
But alright, alright, we had A10 and A11 to take care of as well, so we began looking at some 1days.</p>

<p>We had a <a href="https://project-zero.issues.chromium.org/issues/42450675">kernel stack infoleak</a> due to uninitialised memory and a <a href="https://googleprojectzero.blogspot.com/2018/10/deja-xnu.html">sandbox escape to backboardd</a>, both by Ian Beer. Our plan had been to leverage those to either leak a pointer to shared memory we could write to, place data in the kernel’s <code>__DATA</code> segment, or something of that sort. But we never actually found a suitable target, and because of that the sandbox escape was left unfinished, so A10 and A11 were actually never supported from the app.</p>

<p>But the racoon side looks different, on a couple of fronts. First off, spraying controlled data is actually not as easy as it sounds. The common strategy for this was to hit <code>OSUnserializeXML</code> for rapid bulk unserialisation into virtually any chosen zone, and doing so via <code>IOSurface::setValue</code>, which additionally allowed replacing and removing individual properties at will later. But of course, racoon doesn’t have access to IOSurface, so we had to think of something else. Basically the only part of IOKit it has access to is <code>RootDomainUserClient</code>, and that just so happened to contain this bit in <code>RootDomainUserClient::secureSleepSystemOptions</code>:</p>

<div><pre><code><span>unserializedOptions</span> <span>=</span> <span>OSDynamicCast</span><span>(</span><span>OSDictionary</span><span>,</span> <span>OSUnserializeXML</span><span>((</span><span>const</span> <span>char</span> <span>*</span><span>)</span><span>inOptions</span><span>,</span> <span>inOptionsSize</span><span>,</span> <span>&amp;</span><span>unserializeErrorString</span><span>));</span>
</code></pre></div>

<p>The <code>OSDynamicCast</code> there just makes sure that the value returned by <code>OSUnserializeXML</code> is an <code>OSDictionary</code>, otherwise it substitutes it with <code>NULL</code>. In other words, if we unserialise anything that <em>isn’t</em> a dictionary at the top level - like, say, an <code>OSData</code> object - it will fail this check and the pointer to it will be lost, thus the object will be leaked. That’s obviously not great, but for spraying a couple dozen objects, it’s good enough. This is not a vulnerability per se, but it is a bug that Apple subsequently went and fixed.</p>

<p>Another thing that’s different in racoon is sysctls. Because unlike user apps, its sandbox profile allows blanket reading and writing of any sysctl. And unlike user apps, it runs as root, so it actually has the power to modify a whole bunch of sysctl values. And since most of those are globals that are stored in the kernel’s <code>__DATA</code> segment, once you know the kernel slide, putting data at a known address becomes trivial. In our case, we chose <code>vm.swapfileprefix</code> for this, which shouldn’t interfere with anything, at least while the exploit is running.<br>
There’s just one problem: the kernel stack infoleak mentioned above has rather odd requirements. You need to hit an undefined instruction in one thread and then race the exception handler from another thread to reprotect the page to remove read permissions before it tries to copyin the faulting instruction. And then you need a third thread to receive the exception message and restart the first thread if the race failed. That just sounds like a massive pain, so we were looking for an easier option, and we found one: <a href="https://i.blackhat.com/eu-18/Wed-Dec-5/eu-18-Juwei_Lin-Drill-The-Apple-Core.pdf">CVE-2018-4413 by panicall</a>.</p>

<p>This was an infoleak in <code>sysctl_procargsx</code> that was patched in iOS 12.1, which allowed you to leak almost an entire page of uninitialised kernel memory from the <code>kernel_map</code>. So whatever objects you could spray and then free again, you could leak. That’s an easy win for both kernel code and heap pointers, and definitely enough to get the kernel slide. Thus, A7-A11 were all taken care of.<br>
It would’ve almost also provided a way to pwn A10 and A11 from the app sandbox, if only the sandbox profile didn’t block <code>sysctl_procargsx</code>. But oh well.</p>

<p>All in all, there are much better kernel exploits for iOS 11 today, and the untether was the exciting part anyway.</p>

<h2 id="3-unc0ver">3. unc0ver</h2>

<p>Alright, now onto the real exploit. This time we’re talking A8 through A13, so just yolo’ing it with userland dereferences and ignoring A10+ was no longer an option. I had to work with <em>just</em> this double free.</p>

<p>But another thing I wanted to tackle was a regret that I had from multiple previous exploits I had written. During exploitation of memory corruption vulnerabilities, there will often be steps that can fail, such as freeing and reallocating some memory, which most of the time will put some object into a corrupted state. Usually that is not immediately fatal, but it will require explicit cleanup in order to preserve system stability, and it also requires going back to an earlier stage in the exploit and performing certain steps again.<br>
In our case, this concerns multiple different <code>kalloc.16</code> overlapping with each other. If we’ve got two <code>OSData</code> buffers pointing to the same backing memory and want to free one of them to reallocate it as an object of a different type but something else snatches it away from us, we can make this harmless by just not freeing the other <code>OSData</code> object yet that we still hold. But we’ll have to add it to our cleanup bucket and once we achieve kernel r/w, we’ll have to come back and set its size to zero so that the kernel won’t free the data buffer anymore when we destroy the object.</p>

<p>To account for this from the beginning, I designed the exploit with two layers. The lower layer starts multiple threads that call into <code>lio_listio</code> and a bunch more threads that unserialize <code>OSData</code> objects via IOSurface to race against it. The default number of threads is 4 freers and 16 racers, but these numbers can be adjusted. The data that is unserialized through IOSurface is an <code>OSDictionary</code> whose entries look like this:</p>

<div><pre><code><span>*</span><span>d</span><span>++</span> <span>=</span> <span>kOSSerializeSymbol</span> <span>|</span> <span>4</span><span>;</span>
<span>*</span><span>d</span><span>++</span> <span>=</span> <span>sym</span><span>(</span><span>k</span><span>);</span>
<span>*</span><span>d</span><span>++</span> <span>=</span> <span>kOSSerializeData</span> <span>|</span> <span>0x10</span><span>;</span>
<span>*</span><span>d</span><span>++</span> <span>=</span> <span>0x41414141</span><span>;</span>  <span>// io_waiter, ignored</span>
<span>*</span><span>d</span><span>++</span> <span>=</span> <span>0</span><span>;</span>           <span>// io_issued, must be 0</span>
<span>*</span><span>d</span><span>++</span> <span>=</span> <span>0x69696969</span><span>;</span>  <span>// io_completed, ignored</span>
<span>*</span><span>d</span><span>++</span> <span>=</span> <span>k</span><span>;</span>           <span>// padding</span>
</code></pre></div>

<p><sup>(If you’re unfamiliar with this, this is just the OSSerializeBinary format. See <code>OSUnserializeBinary</code> in XNU. And <code>sym()</code> is just a function I wrote to transpose an arbitrary <code>uint32_t</code> into one without any null bytes.)</sup></p>

<p>More about this in a minute. Since each unserialisation call will create many such objects and since we just spam this call from multiple threads, it is highly likely that we’ll end up with the following scenario:</p>

<ol>
  <li><code>lio_context</code> is freed.</li>
  <li>Its memory is reallocated as <code>OSData</code> buffer.</li>
  <li><code>lio_context</code>/<code>OSData</code> buffer is freed again, creating UaF.</li>
  <li>Its memory is reallocated again as buffer for another <code>OSData</code> object.</li>
</ol>

<p>Thus we’ll end up with two <code>OSData</code> objects pointing to the same data buffer. This is where the magic values <code>0x41414141</code> and <code>0x69696969</code> come into play. After our racing, we go through all <code>OSData</code> values in our IOSurface and look at their contents. If any of them <em>don’t</em> have our magic values, then they must have been stolen from us by something else on the system. We’ll mark these for later cleanup and will ignore them for now. Otherwise we’ll move on to the value <code>k</code> at the end of the buffer. This value is linked to the key that the <code>OSData</code> has in the dictionary, which is crucial for letting us figure out whether an overlap occurred. If we look up an object for <code>sym(123)</code> and the value in the buffer at offset 0xc is not <code>123</code>, then we know that this data buffer has been reallocated for another <code>OSData</code> object - and moreover, we know <em>which</em> <code>OSData</code> object, since it contains the value <code>k</code> that lets us look it up on the IOSurface. We can thus create a mapping of overlapping objects via their keys in the dictionary.<br>
This is what the <code>maybe_reyoink</code>/<code>overlap</code> functions in the code do. They create a structure to hold this information and return it to the upper layer, and they can be called into at any time to acquire more overlapping <code>OSData</code> objects if needed.</p>

<p>So the upper layer gets supplied with overlapping <code>OSData</code> objects, and it can use this later to construct a fake mach port by freeing one of the <code>OSData</code> objects, spraying some mach messages with OOL port descriptors, then freeing the other <code>OSData</code> object, and then reallocating it with a new <code>OSData</code> object that contains a pointer to a fake task port. That part is easy, but once again we’re left with the problem of needing to leak a kernel address at which we can put controlled data. But with the aforementioned steps, we can actually leak some heap addresses already. All we have to do is read the <code>OSData</code> contents after the first reallocation as OOL ports descriptor array, and we get the raw kernel pointers of whatever mach ports we send in the OOL descriptor. We’re gonna use that later to leak the addresses of our task port and our service port to <code>IOSurfaceRoot</code> to make the rest of the exploit easier, but that’s beyond the scope of this write-up. Now, we <em>could</em> spray a lot of mach ports, leak their addresses until we have a full page that we hold all references to, free them all, and then try and trigger a zone garbage collection to get the memory into a different zone, but that is slow, expensive and annoying to get right. The same problem applies to <code>OSContainer</code> objects, and pretty much all other pointer arrays you can think of that you could get into <code>kalloc.16</code>. It would be so much easier if we could just get the address of a buffer whose contents we control into <code>kalloc.16</code>… something like shared memory, or so. But such things are rare.</p>

<p>After looking through XNU sources for a couple of days though, I did find a possible candidate: <code>IOMemoryDescriptor</code>. It has a field called <code>_ranges</code>, which is an array of <code>IOVirtualRange</code>, which is literally just:</p>

<div><pre><code><span>typedef</span> <span>struct</span><span>{</span>
    <span>IOVirtualAddress</span>    <span>address</span><span>;</span>
    <span>IOByteCount</span>         <span>length</span><span>;</span>
<span>}</span> <span>IOVirtualRange</span><span>;</span>
</code></pre></div>

<p>A single one of those fits <em>perfectly</em> into <code>kalloc.16</code>. There’s just one catch: if there is only a single range, then <code>IOMemoryDescriptor</code> points the <code>_ranges</code> field at another field <code>_singleRange</code> instead and saves on doing a heap allocation. There is no way to reach that code path in <code>IOMemoryDescriptor</code> with just one range. However, a <em>subclass</em> of <code>IOMemoryDescriptor</code>, <code>IOBufferMemoryDescriptor</code>, does exactly that, explicitly:</p>

<div><pre><code><span>_ranges</span><span>.</span><span>v64</span> <span>=</span> <span>IONew</span><span>(</span><span>IOAddressRange</span><span>,</span> <span>1</span><span>);</span>
</code></pre></div>
<div><pre><code><span>_ranges</span><span>.</span><span>v64</span><span>-&gt;</span><span>address</span> <span>=</span> <span>(</span><span>mach_vm_address_t</span><span>)</span> <span>_buffer</span><span>;</span>
<span>_ranges</span><span>.</span><span>v64</span><span>-&gt;</span><span>length</span>  <span>=</span> <span>_capacity</span><span>;</span>
</code></pre></div>

<p>Now all we need is a place in the kernel where we can allocate an <code>IOBufferMemoryDescriptor</code> at will and also get it mapped into our address space. One convenient place for this is the AGX interface, aka. <code>IOAcceleratorFamily2</code> (note that this has since been refactored into <code>IOGPUFamily</code> in iOS 14, so the details here only apply to 13.x and older).<br>
If we open a userclient of type 0 on <code>IOGraphicsAccelerator2</code>, it will give us an <code>IOAccelContext2</code>, which lets us map three different memory descriptors via <code>::clientMemoryForType()</code>. I don’t know what any of them are actually for, but types 1 and 2 have a default size of 0x4000 bytes, while type 0 has a size of 0x8000 bytes. Since we’d like to be able to uniquely identify the victim descriptor, the 0x8000 one is the one to go with here. (And we’re gonna need two pages of memory anyway for later stages of the exploit, so that’s convenient.) Before we can map it, however, we first need to initialise our userclient some more. We do that by opening another userclient on <code>IOGraphicsAccelerator2</code> (type 2, <code>IOAccelSharedUserClient2</code>) and passing it to the first userclient via <code>::connectClient()</code>. This will actually allocate our <code>IOBufferMemoryDescriptor</code> already, so we do the following in a loop:</p>

<ol>
  <li>Open an <code>IOAccelContext2</code>.</li>
  <li>Grab the next two overlapping <code>OSData</code> objects.</li>
  <li>Free one <code>OSData</code> object.</li>
  <li>Call <code>IOConnectAddClient()</code> on our <code>IOAccelContext2</code> with an <code>IOAccelSharedUserClient2</code> that we opened earlier, outside of the loop.</li>
  <li>Read back the other <code>OSData</code> object and check if the first 8 bytes are a plausible page-aligned kernel pointer and the second 8 bytes are <code>0x8000</code>.</li>
  <li>If we found that, break out of the loop, otherwise close the <code>IOAccelContext2</code> and continue with the loop.</li>
</ol>

<p>Now we can map the memory descriptor into our process and know its kernel address, but we’ve actually still got one problem: the memory is created as pageable (with <code>kIOMemoryPageable</code>), and since we’re gonna be forging a mach port and a task object here, these data structures may end up in situations where preemption is disabled, so we really want to fault those pages in on the kernel side. Once again, I don’t know what the code in question is actually supposed to do, but I figured out that I could trigger this by calling into <code>IOAccelContext2::processSidebandBuffer</code>, which is called indirectly from <code>IOAccelContext2::submit_data_buffers</code>, which is external method 2. So just call this twice with the right data structures prepared on shared memory. <code>::processSidebandBuffer()</code> reads this structure from <code>0x10</code> bytes off the start of shared memory:</p>

<div><pre><code><span>struct</span>
<span>{</span>
    <span>uint16_t</span> <span>tok</span><span>;</span>
    <span>uint16_t</span> <span>len</span><span>;</span>
    <span>uint32_t</span> <span>val</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>The first is some magic, the second is the length divided by 4, and <code>val</code> is some value whose significance I don’t know. All we care about is that the first structure we place on shared memory is valid (<code>tok == 0x100</code> works) and spans an entire page, so that <code>::processSidebandBuffer()</code> advances to the second page and faults it in. After that, it can error out, so on the second page we can put whatever. And with that, we now have controlled data at a known kernel address, which we can directly read and write to.<br>
Now all that’s left to do is construct a fake task, fake port, pull a UaF and switcheroo on a mach ports OOL descriptor, construct an arbitrary read primitive, yada yada. All been done a hundred times.</p>

<p>Perhaps the only noteworthy thing at this point is the bypassing of <code>zone_require</code>, but even that should be well-known to anyone who was around during the iOS 13 days. <code>zone_require</code> was just completely broken by the fact that it allowed pages from outside the <code>zone_map</code>, where it would simply take the first <code>0x20</code> bytes of the page as page metadata, so all you had to do was populate that with the right zone index, and you had just minted yourself a pass for any zone of your choosing. This is also why we need two pages: one for tasks and one for mach ports.</p>

<p>This tiny bit of info was actually the only reason I had to not publish the exploit right away. But alas, it is <a href="https://github.com/Siguza/tachy0n">public on GitHub</a> now at last.</p>

<h2 id="4-aftermath">4. Aftermath</h2>

<p>The scene obviously took note of a full 0day exploit dropping for the latest signed version. <a href="https://github.com/bazad">Brandon Azad</a>, who worked for Project Zero at the time, went full throttle, <a href="https://googleprojectzero.blogspot.com/2020/07/how-to-unc0ver-0-day-in-4-hours-or-less.html">figured out the vulnerability within four hours</a> and informed Apple of his findings. Six days after the exploit dropped, <a href="https://www.synacktiv.com/en/publications/return-of-the-ios-sandbox-escape-lightspeeds-back-in-the-race.html">Synacktiv published a new blog post</a> where they noted how the original fix in iOS 12 introduced a memory leak, and speculated that it was an attempt to fix this memory leak that brought back the original bug (which I think is quite likely). 9 days after the exploit dropped, Apple released a patch, and I got some private messages from people telling me that this time they’d made sure that the bug would stay dead. They even added <a href="https://github.com/apple-oss-distributions/xnu/blob/main/tests/fd_aio_fsync_uaf.c">a regression test for it to XNU</a>. And finally, 54 days after the exploit dropped, a reverse-engineered version dubbed “tardy0n” was shipped in the Odyssey jailbreak, also targeting iOS 13.0 through 13.5. But by then, the novelty of it had already worn off, WWDC 2020 had already taken place, and the world had shifted its attention to iOS 14 and the changes ahead.</p>

<p>And oh boy did things change. iOS 14 represented a strategy shift from Apple. Until then, they had been playing whack-a-mole with first-order primitives, but not much beyond. The <code>kernel_task</code> restriction and <code>zone_require</code> were feeble attempts at stopping an attacker when it was already way too late. Had a heap overflow? Over-release on a C++ object? Type confusion? Pretty much no matter the initial primitive, the next target was always mach ports, and from there you could just grab a dozen public exploits on the net and plug their second half into your code.<br>
iOS 14 changed this once and for all. And that is obviously something that had been in the works for some time, unrelated to unc0ver or tachy0n. And it was likely happening due to a change in corporate policy, not technical understanding.</p>

<p>Perhaps the single biggest change was to the allocators, <code>kalloc</code> and <code>zalloc</code>. Many decades ago, CPU vendors started shipping a feature called “Data Execution Prevention” because people understood that separating data and code has security benefits. Apple did the same here, but with data and <em>pointers</em> instead. They butchered up the zone map and split it into multiple ranges, dubbed “kheaps”. The exact amount and purpose of the different kheaps has changed over time, but one crucial point is that user-controlled data would go into <em>one</em> heap, kernel objects into <em>another</em>. For kernel objects, they also implemented “sequestering”, which means that once a given page of the virtual address range is allocated to a given zone, it will <em>never</em> be used for anything else again until the system reboots. The physical memory can be released and detached if all objects on the page are freed, but the virtual memory range will not be reused for different objects, effectively killing kernel object type confusions. Add in some random guard pages, some per-boot randomness in where different zones will start allocating, and it’s effectively no longer possible to do cross-zone attacks with any reliability. Of course this wasn’t perfect from the start, and some user-controlled data still made it into the kernel object heap and vice versa, but this has been refined and hardened over time, to the point where clang now has some <code>__builtin_xnu_*</code> features to carry over some compile-time type information to runtime to help with better isolation between different data types.</p>

<p>But the allocator wasn’t the only thing that changed, it was the approach to security as a whole. Apple no longer just patches bugs, they patch <em>strategies</em> now. You were spraying kmsg structs as a memory corruption target as part of your exploit? Well, those are signed now, so that any tampering with them will panic the kernel. You were using pipe buffers to build a stable kernel r/w interface? Too bad, those pointers are PAC’ed now. Virtually any time you used an unrelated object as a victim, Apple would go and harden that object type. This obviously made developing exploits much more challenging, to the point where exploitation strategies were soon more valuable than the initial memory corruption 0days.<br>
But another aspect of this is that, with only very few exceptions, it basically stopped information sharing dead in its tracks. Before iOS 14 dropped, the public knowledge about iOS security research was almost on par with what people knew privately. And there wasn’t much to add. Hobbyist hackers had to pick exotic targets like KTRR or SecureROM in order to see something new and get a challenge. Those days are evidently long gone, with the iOS 19 beta being mere weeks away and there being no public kernel exploit for iOS 18 or 17 whatsoever, all while Apple’s security notes still list vulnerabilities that were exploited in the wild every now and then. Private research was able to keep up. Public information has been left behind.</p>

<h2 id="5-conclusion">5. Conclusion</h2>

<p>It’s insane to think that this was a mere 5 years ago. I think this really serves as an illustration to just how unfathomably fast this field moves. I can’t possibly imagine where we’ll be in 5 years from now.</p>

<p>Finally, I’d like to thank Pwn20wnd for sharing this 0day with me and choosing to drop it as part of a public jailbreak. That was a very cool move. I’d also like to thank whoever unpatched the bug in iOS 13.0. That was a very cool move too. And I’d like to thank everyone that I’ve learned from before these changes hit, and everyone that I’ve worked with afterwards. It wouldn’t have been possible for me to keep doing this alone.</p>

<p>If you have questions, comments, typos, or anything else, I’m just gonna link <a href="https://siguza.net/">my website</a> now. Whatever the most up-to-date way to contact me is, it will be linked there.</p>


      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lone coder cracks 50-year puzzle to find Boggle's top-scoring board (114 pts)]]></title>
            <link>https://www.ft.com/content/0ab64ced-1ed1-466d-acd3-78510d10c3a1</link>
            <guid>44082892</guid>
            <pubDate>Sat, 24 May 2025 18:24:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ft.com/content/0ab64ced-1ed1-466d-acd3-78510d10c3a1">https://www.ft.com/content/0ab64ced-1ed1-466d-acd3-78510d10c3a1</a>, See on <a href="https://news.ycombinator.com/item?id=44082892">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a data-trackable="a11y-skip-to-help" href="https://www.ft.com/accessibility">Accessibility help</a><a data-trackable="a11y-skip-to-navigation" href="#site-navigation">Skip to navigation</a><a data-trackable="a11y-skip-to-content" href="#site-content">Skip to content</a><a data-trackable="a11y-skip-to-footer" href="#site-footer">Skip to footer</a></p><div id="barrier-page"><div data-component="electionsHeader" data-component-unique-name="ElectionHeader"><h2>FT Weekend</h2></div><div data-component="topicHeroOffer" data-component-unique-name="TopicHeroOffer"><div><div data-o-grid-colspan="12 XL6"><p><span></span><span></span><span></span><span>Register to unlock this article</span><span></span></p></div><div data-o-grid-colspan="12 XL5"><p><h2><span><span>Limited time offer</span></span></h2><h2><span><span>Read this article and register for your free FT Weekend newsletter</span></span></h2></p></div></div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/images/FT-weekend-image.png?source=next-barrier-page" alt=""></p></div><div id="recommendedOffers-recommendedOffers" data-component="recommendedOffers" data-component-unique-name="recommendedOffers"><p><h2 data-o-grid-colspan="12">Explore more offers.</h2></p><div data-o-grid-colspan="12"><div data-o-grid-colspan="12"><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/icons/primary_product_icon_digital_edition.svg?source=next-barrier-page&amp;format=svg" alt=""></p><p><h3>FT Digital Edition</h3></p></div><p><span><span>CHF15</span><span> per month</span></span></p><p><span><span>FT Digital Edition: today’s FT, cover to cover on any device. This subscription does not include access to ft.com or the FT App.</span></span></p></div><div data-o-grid-colspan="12"><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/icons/primary_product_icon_standard.svg?source=next-barrier-page&amp;format=svg" alt=""></p><p><h3>Standard Digital</h3></p></div><p><span><span>CHF55</span><span> per month</span></span></p><p><span><span>Essential digital access to quality FT journalism on any device. Pay a year upfront and save 20%.</span></span></p></div><div data-o-grid-colspan="12"><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/icons/primary_product_icon_premium.svg?source=next-barrier-page&amp;format=svg" alt=""></p><p><h3>Premium Digital</h3></p></div><p><span><span>CHF85</span><span> per month</span></span></p><p><span><span>Complete digital access to quality FT journalism with expert analysis from industry leaders. Pay a year upfront and save 20%.</span></span></p></div></div></div><div data-component="subscriptionOptions" data-component-unique-name="Subscription options" data-o3-theme="inverse"><h2>Explore our full range of subscriptions.</h2><div><div><div><h3>For individuals</h3></div><p>Discover all the plans currently available in your country</p></div><div><div><h3> For multiple readers</h3></div><p>Digital access for organisations. Includes exclusive features and content.</p></div></div><div><p>Check whether you already have access via your <span><a data-trackable="edu-finder" href="https://find-your-subscription.ft.com/?segmentId=a0e9a794-4c6d-bb35-e4dc-8bd409e0f54f&amp;ft-content-uuid=0ab64ced-1ed1-466d-acd3-78510d10c3a1">university</a></span> or <span><a data-trackable="licence-finder" href="https://subs.enterprise.ft.com/en-gb/licence-finder/?segmentId=9fb23d7d-afe4-12f3-3eaa-ff7a41e9d073&amp;ft-content-uuid=0ab64ced-1ed1-466d-acd3-78510d10c3a1">organisation.</a></span></p></div></div><div data-component="whyFT" data-component-unique-name="Why FT" data-o3-theme="inverse"><div><h2>Why the FT?</h2><p>See why over a million readers pay to read the Financial Times.</p></div><p><a href="https://subs.ft.com/whytheft?ft-content-uuid=0ab64ced-1ed1-466d-acd3-78510d10c3a1">Find out why</a></p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Live facial recognition cameras may become 'commonplace' as police use soars (133 pts)]]></title>
            <link>https://www.theguardian.com/technology/2025/may/24/police-live-facial-recognition-cameras-england-and-wales</link>
            <guid>44082326</guid>
            <pubDate>Sat, 24 May 2025 17:03:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/technology/2025/may/24/police-live-facial-recognition-cameras-england-and-wales">https://www.theguardian.com/technology/2025/may/24/police-live-facial-recognition-cameras-england-and-wales</a>, See on <a href="https://news.ycombinator.com/item?id=44082326">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Police believe live facial recognition cameras may become “commonplace” in <a href="https://www.theguardian.com/uk-news/england" data-link-name="in body link" data-component="auto-linked-tag">England</a> and Wales, according to internal documents, with the number of faces scanned having doubled to nearly 5m in the last year.</p><p>A joint investigation by the Guardian and <a href="https://libertyinvestigates.org.uk/" data-link-name="in body link">Liberty Investigates</a> highlights the speed at which the technology is becoming a staple of British policing.</p><p>Major funding is being allocated and hardware bought, while the British state is also looking to enable police forces to more easily access the full spread of its image stores, including passport and immigration databases, for retrospective facial recognition searches.</p><p>Live facial recognition involves the matching of faces caught on surveillance camera footage against a police watchlist in real time, in what campaigners liken to the continual finger printing of members of the public as they go about their daily lives.</p><p>Retrospective facial recognition software is used by the police to match images on databases with those caught on CCTV and other systems.</p><p>According to one funding document drawn up by South <a href="https://www.theguardian.com/uk/wales" data-link-name="in body link" data-component="auto-linked-tag">Wales</a> police as part of a proposal to put the West End of London or Cardiff rail station under live facial recognition cameras and released by the Metropolitan police under the Freedom of Information Act, it is believed “the use of this technology could become commonplace in our city centres and transport hubs around England and Wales”.</p><p>The first fixed live facial recognition cameras will be fitted for a trial in Croydon, south London, later this summer.</p><p>The expansion comes despite facial recognition failing to be referenced in any act of parliament.</p><p>Campaigners claim the police have been allowed to “self regulate” their use of the technology. Officers have in the past used a setting that was subsequently shown to disproportionately misidentify black people.</p><p>After a court of appeal judgment in 2020, which found that South Wales police’s <a href="https://www.theguardian.com/technology/2020/aug/11/south-wales-police-lose-landmark-facial-recognition-case" data-link-name="in body link">use of live facial recognition cameras</a> had been unlawful, the College of Policing provided guidance that “the threshold needs to be set with care to maximise the probability of returning true alerts while keeping the false alert rate to an acceptable level”.</p><p>There remains nothing in law to direct forces on the threshold or technology used.</p><p>The policing minister, Diane Johnson, told parliament earlier this month that she recognised “a need to consider whether a bespoke legislative framework governing the use of live facial recognition technology for law enforcement purposes is needed” but the Home Office is yet to provide details.</p><p>Facial recognition cameras were first <a href="https://www.theguardian.com/technology/2019/oct/04/facial-recognition-row-police-gave-kings-cross-owner-images-seven-people" data-link-name="in body link">trialled in London</a> and south Wales from 2016 but the speed at which police forces are rolling out the technology has accelerated over the last 12 months.</p><p>The investigation by the Guardian and Liberty found:</p><ul>
 <li>
  <p>Police forces scanned nearly 4.7m faces with live facial recognition cameras last year – more than twice as many as in 2023. Live facial recognition vans were deployed at least 256 times in 2024, according to official deployment records, up from 63 the year before.</p></li>
 <li>
  <p>A roving unit of 10 live facial recognition vans that can be sent anywhere in the country will be made available within days – increasing national capacity. Eight police forces have deployed the technology. The Met has four vans.</p></li>
 <li>
  <p>Police forces have considered fixed infrastructure creating a “zone of safety” by covering the West End of London with a network of live facial recognition cameras. Met officials said this remained a possibility.</p></li>
 <li>
  <p>Forces almost doubled the number of retrospective facial recognition searches made last year using the police national database (PND) from 138,720 in 2023 to 252,798. The PND contains custody mug shots, millions of which have been <a href="https://www.theguardian.com/uk-news/2024/dec/08/police-unlawfully-storing-images-of-innocent-people-for-facial-recognition" data-link-name="in body link">found to be stored unlawfully</a> of people who have never been charged with or convicted of an offence.</p></li>
 <li>
  <p>More than 1,000 facial recognition searches using the UK passport database were carried out in the last two years, and officers are increasingly searching for matches on the Home Office immigration database, with requests up last year, to 110. Officials have concluded that using the passport database for facial recognition is “not high risk” and “is not controversial”, according to internal documents.</p></li>
 <li>
  <p>The Home Office is now working with the police to establish a new national facial recognition system, known as strategic facial matcher. The platform will be capable of searching a range of databases including custody images and immigration records.</p></li>
</ul><p>Lindsey Chiswick, the director of intelligence at the Met and the National <a href="https://www.theguardian.com/uk/police" data-link-name="in body link" data-component="auto-linked-tag">Police</a> Chiefs’ Council lead on facial recognition, said surveys showed that four in five Londoners were in support of the police using innovative technology, including facial recognition cameras.</p><p>This week, a registered sex offender, David Cheneler, 73, from Lewisham, was <a href="https://www.bbc.co.uk/news/articles/c9dqq7q47j1o" data-link-name="in body link">jailed for two years</a> after he was caught alone with a six-year-old girl by a live facial recognition camera. He had previously served nine years for 21 offences against children.</p><figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.NewsletterSignupBlockElement"><a data-ignore="global-link-styling" href="#EmailSignup-skip-link-17">skip past newsletter promotion</a><p id="EmailSignup-skip-link-17" tabindex="0" aria-label="after newsletter promotion" role="note">after newsletter promotion</p></figure><p>The Met arrested 587 people in 2024 with the assistance of the live facial recognition cameras of which 424 were charged with offences.</p><p>Of those arrested, 58 were registered sex offenders in serious breach of their conditions and 38 have been charged.</p><p>Chiswick said: “Where there’s limited amounts of money and there’s fewer officers, but there’s more demand, and we see criminals exploiting technology to a really grand scale … we’ve got to do something different.</p><p>“There’s an opportunity out there. So policing needs to start operating a little bit differently. People talk about harnessing AI like it’s some crazy horse we want to saddle but we do need to harness the opportunities that technology and data can bring us.”</p><p>Chiswick said the Met’s policy was to take “really quite small steps and review them at every stage” but that there would be a “benefit in potentially some sort of framework or statutory guidance”.</p><p>The Met is deploying its facial recognition cameras at a setting that testing suggests avoids any statistical significance in terms of gender or ethnicity bias when it comes to cases of misidentification.</p><p>Chiswick said: “I don’t want to use a biased algorithm in London. There’s no point on all counts. I think for government, there’s a question, isn’t there around artificial intelligence? And I think clearly the public sector is going to use, and want to use AI more and more.</p><p>“I think the questions around who then decides where algorithms are purchased from, what training data is used, what countries might this technology come from and then, when you use it, are you obliged to test it and if you’re obliged to test it, are you then obliged to operate at a certain setting? That’s not really questions for law enforcement.”</p><p>The Home Office declined a request for comment.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Good Writing (181 pts)]]></title>
            <link>https://paulgraham.com/goodwriting.html</link>
            <guid>44081586</guid>
            <pubDate>Sat, 24 May 2025 15:03:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://paulgraham.com/goodwriting.html">https://paulgraham.com/goodwriting.html</a>, See on <a href="https://news.ycombinator.com/item?id=44081586">Hacker News</a></p>
<div id="readability-page-1" class="page"><div width="435"><tbody><tr><td><img src="https://s.turbifycdn.com/aah/paulgraham/good-writing-1.gif" width="111" height="18" alt="Good Writing"><span size="2" face="verdana">May 2025<p>There are two senses in which writing can be good: it can
sound good, and the ideas can be right. It can have nice,
flowing sentences, and it can draw correct conclusions
about important things. It might seem as if these two
kinds of good would be unrelated, like the speed of a car
and the color it's painted. And yet I don't think they
are. I think writing that sounds good is more likely to
be right.</p><p>So here we have the most exciting kind of idea: one that
seems both preposterous and true. Let's examine it. How
can this possibly be true?</p><p>I know it's true from writing. You can't simultaneously
optimize two unrelated things; when you push one far
enough, you always end up sacrificing the other. And yet
no matter how hard I push, I never find myself having to
choose between the sentence that sounds best and the one
that expresses an idea best. If I did, it would be
frivolous to care how sentences sound. But in practice it
feels the opposite of frivolous. Fixing sentences that
sound bad seems to help get the ideas right.
</p><span color="#dddddd">[<a href="#f1n"><span color="#dddddd">1</span></a>]</span><p>By right I mean more than just true. Getting the ideas
right means developing them well — drawing the
conclusions that matter most, and exploring each one to
the right level of detail. So getting the ideas right is
not just a matter of saying true things, but saying the
right true things.</p><p>How could trying to make sentences sound good help you do
that? The clue to the answer is something I noticed 30
years ago when I was doing the layout for my first book.
Sometimes when you're laying out text you have bad luck.
For example, you get a section that runs one line longer
than the page. I don't know what ordinary typesetters do
in this situation, but what I did was rewrite the section
to make it a line shorter. You'd expect such an arbitrary
constraint to make the writing worse. But I found, to my
surprise, that it never did. I always ended up with
something I liked better.</p><p>I don't think this was because my writing was especially
careless. I think if you pointed to a random paragraph in
anything written by anyone and told them to make it
slightly shorter (or longer), they'd probably be able to
come up with something better.</p><p>The best analogy for this phenomenon is when you shake a
bin full of different objects. The shakes are arbitrary
motions. Or more precisely, they're not calculated to
make any two specific objects fit more closely together.
And yet repeated shaking inevitably makes the objects
discover brilliantly clever ways of packing themselves.
Gravity won't let them become less tightly packed, so any
change has to be a change for the better.
</p><span color="#dddddd">[<a href="#f2n"><span color="#dddddd">2</span></a>]</span><p>So it is with writing. If you have to rewrite an awkward
passage, you'll never do it in a way that makes it <i>less</i>
true. You couldn't bear it, any more than gravity could
bear things floating upward. So any change in the ideas
has to be a change for the better.</p><p>It's obvious once you think about it. Writing that sounds
good is more likely to be right for the same reason that
a well-shaken bin is more likely to be tightly packed.
But there's something else going on as well. Sounding
good isn't just a random external force that leaves the
ideas in an essay better off. It actually helps you to
get them right.</p><p>The reason is that it makes the essay easier to read.
It's less work to read writing that flows well. How does
that help the writer? <i>Because the writer is the first
reader.</i> When I'm working on an essay, I spend far more
time reading than writing. I'll reread some parts 50 or
100 times, replaying the thoughts in them and asking
myself, like someone sanding a piece of wood, does
anything catch? Does anything feel wrong? And the easier
the essay is to read, the easier it is to notice if
something catches.</p><p>So yes, the two senses of good writing are connected in
at least two ways. Trying to make writing sound good
makes you fix mistakes unconsciously, and also helps you
fix them consciously; it shakes the bin of ideas, and
also makes mistakes easier to see. But now that we've
dissolved one layer of preposterousness, I can't resist
adding another. Does sounding good do more than just help
you get the ideas right? Is writing that sounds good
<i>inherently</i> more likely to be right? Crazy as it may
seem, I think that's true too.</p><p>Obviously there's a connection at the level of individual
words. There are lots of words in English that sound like
what they mean, often in wonderfully subtle ways.
Glitter. Round. Scrape. Prim. Cavalcade. But the sound of
good writing depends even more on the way you put words
together, and there's a connection at that level too.</p><p>When writing sounds good, it's mostly because it has good
rhythm. But the rhythm of good writing is not the rhythm
of music, or the meter of verse. It's not so regular. If
it were, it wouldn't be good, because the rhythm of good
writing has to match the ideas in it, and ideas have all
kinds of different shapes. Sometimes they're simple and
you just state them. But other times they're more subtle,
and you need longer, more complicated sentences to tease
out all the implications.</p><p>An essay is a cleaned up train of thought, in the same
way dialogue is cleaned up conversation, and a train of
thought has a natural rhythm. So when an essay sounds
good, it's not merely because it has a pleasing rhythm,
but because it has its natural one. Which means you can
use getting the rhythm right as a heuristic for getting
the ideas right. And not just in principle: good writers
do both simultaneously as a matter of course. Often I
don't even distinguish between the two problems. I just
think Ugh, this doesn't sound right; what do I mean to
say here?
</p><span color="#dddddd">[<a href="#f3n"><span color="#dddddd">3</span></a>]</span><p>The sound of writing turns out to be more like the shape
of a plane than the color of a car. If it looks good, as
Kelly Johnson used to say, it will fly well.</p><p>This is only true of writing that's used to develop
ideas, though. It doesn't apply when you have ideas in
some other way and then write about them afterward — for
example, if you build something, or conduct an
experiment, and then write a paper about it. In such
cases the ideas often live more in the work than the
writing, so the writing can be bad even though the ideas
are good. The writing in textbooks and popular surveys
can be bad for the same reason: the author isn't
developing the ideas, merely describing other people's.
It's only when you're writing to develop ideas that
there's such a close connection between the two senses of
doing it well.</p><p>Ok, many people will be thinking, this seems plausible so
far, but what about liars? Is it not notoriously possible
for a smooth-tongued liar to write something beautiful
that's completely false?</p><p>It is, of course. But not without method acting. The way
to write something beautiful and false is to begin by
making yourself almost believe it. So just like someone
writing something beautiful and true, you're presenting a
perfectly-formed train of thought. The difference is the
point where it attaches to the world. You're saying
something that would be true if certain false premises
were. If for some bizarre reason the number of jobs in a
country were fixed, then immigrants really would be
taking our jobs.</p><p>So it's not quite right to say that better sounding
writing is more likely to be true. Better sounding
writing is more likely to be internally consistent. If
the writer is honest, internal consistency and truth
converge.</p><p>But while we can't safely conclude that beautiful writing
is true, it's usually safe to conclude the converse:
something that seems clumsily written will usually have
gotten the ideas wrong too.</p><p>Indeed, the two senses of good writing are more like two
ends of the same thing. The connection between them is
not a rigid one; the goodness of good writing is not a
rod but a rope, with multiple overlapping connections
running through it. But it's hard to move one end without
moving the other. It's hard to be right without sounding
right.</p><p>
<b>Notes</b></p><p>[</p><a name="f1n"><span color="#000000">1</span></a>]
The closest thing to an exception is when you have
to go back and insert a new point into the middle of
something you've written. This often messes up the flow,
sometimes in ways you can never quite repair. But I think
the ultimate source of this problem is that ideas are
tree-shaped and essays are linear. You inevitably run
into difficulties when you try to cram the former into
the latter. Frankly it's suprising how much you can get
away with. But even so you sometimes have to resort to an
endnote.<p>[</p><a name="f2n"><span color="#000000">2</span></a>]
Obviously if you shake the bin hard enough the
objects in it can become less tightly packed. And
similarly, if you imposed some huge external constraint
on your writing, like using alternating one and two
syllable words, the ideas would start to suffer.<p>[</p><a name="f3n"><span color="#000000">3</span></a>]
Bizarrely enough, this happened in the writing of
this very paragraph. An earlier version shared several
phrases in common with the preceding paragraph, and the
repetition bugged me each time I reread it. When I got
annoyed enough to fix it, I discovered that the
repetition reflected a problem in the underlying ideas,
and I fixed both simultaneously.<span color="888888"><b>Thanks</b> to Jessica Livingston 
and Courtenay Pipkin for reading drafts of this.</span></span></td></tr></tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You're a little company, now act like one (194 pts)]]></title>
            <link>https://longform.asmartbear.com/little-company/</link>
            <guid>44081494</guid>
            <pubDate>Sat, 24 May 2025 14:49:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://longform.asmartbear.com/little-company/">https://longform.asmartbear.com/little-company/</a>, See on <a href="https://news.ycombinator.com/item?id=44081494">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="site-main">
<div>


<p>
August 31, 2009
</p>
<p>
Reading time: 5 min
</p>
</div>
<article>

<p>
by Jason Cohen on August 31, 2009
</p>
<div>
<p>
You’re afraid that looking like being a small company means you’ll lose sales. It’s actually the opposite – you’re alienating your best customers.
</p>
<figure>
<div>
<picture>
<source type="image/webp" media="screen" srcset="https://longform.asmartbear.com/little-company/l-were-big-player-no-one-knows-what-it-everyone-thinks-need-it-space-640w.webp 640w,https://longform.asmartbear.com/little-company/l-were-big-player-no-one-knows-what-it-everyone-thinks-need-it-space-900w.webp 900w,https://longform.asmartbear.com/little-company/l-were-big-player-no-one-knows-what-it-everyone-thinks-need-it-space-1200w.webp 1200w" sizes="(max-width: 38rem) min(37.5rem,100vw),(max-width: 47rem) min(37.5rem,calc(100vw - 2rem)),(max-width: 60rem) min(37.5rem,45rem),(max-width: 67rem) min(37.5rem,calc(100vw - 22rem)),min(37.5rem,45rem)">
<img src="https://longform.asmartbear.com/little-company/l-were-big-player-no-one-knows-what-it-everyone-thinks-need-it-space-2324w.png" alt="We're a big player in the no one knows what it is but everyone thinks they need it space." loading="eager">
</picture>


</div>
<figcaption>

</figcaption>
</figure>
<p>I talk to a lot of companies that are still hunting for customer #1, or a few sales have been made but <a href="https://longform.asmartbear.com/product-market-fit/" data-title="Product/Market Fit (PMF): Experience &amp; Data" data-desc="Companies that achieve Product/Market Fit – both self-funded and VC-funded – exhibit the same prototypical metrics curves and subjective experiences." data-image-src1="https://longform.asmartbear.com/product-market-fit/thumbnail-1200w_hu2460079708713114450.webp" data-image-src2="https://longform.asmartbear.com/product-market-fit/thumbnail-1200w_hu1158878335933215093.webp">the ball isn’t rolling yet</a>.</p>
<p>Most of them are making the same mistake: <strong>Their public persona is exactly wrong.</strong></p>
<p>I know, because <strong>I made the same mistake!</strong> But I learned my lesson, and I’d like to share it with you.</p>
<figure>
<div>
<picture>
<source type="image/webp" media="screen" srcset="https://longform.asmartbear.com/little-company/nobodys-happy-about-installing-new-software-383w.webp 383w" sizes="(max-width: 38rem) min(23.9375rem,100vw),(max-width: 47rem) calc(calc(100vw - 2rem) / 2),(max-width: 60rem) calc(45rem / 2),(max-width: 67rem) calc(calc(100vw - 22rem) / 2),calc(45rem / 2)">
<img src="https://longform.asmartbear.com/little-company/nobodys-happy-about-installing-new-software-383w.png" alt="Nobody's this happy about installing new software." loading="eager">
</picture>

</div>
<figcaption>
<p>Nobody’s this happy about installing new software.</p>
</figcaption>
</figure>
<p>Even before I had a single customer, I “knew” it was important to look professional. My website would need to look and feel like a “real company.” I need culture-neutral language complementing culturally-diverse clip-art photos of frighteningly chipper co-workers huddled around a laptop, awash in the thrill of configuring a JDBC connection to SQL Server 2008.</p>
<p>It also means adopting typical “marketing-speak,” so my “About Us” page started with:</p>
<blockquote>
<p>Smart Bear is the leading provider of enterprise version control data-mining tools. Companies world-wide use Smart Bear’s Code Historian software for risk-analysis, root-cause discovery, and software development decision-support.</p>
</blockquote>
<p>“Leading provider?” “Data mining?” I’m not even <a href="https://longform.asmartbear.com/the-leading-provider/" data-title="The leading provider of meaningless marketing solutions" data-desc="Marketing buzzwords and generic phrases hurts your brand. Use clear messaging instead of meaningless jargon." data-image-src1="https://longform.asmartbear.com/the-leading-provider/thumbnail-1200w_hu6014495465192322122.webp" data-image-src2="https://longform.asmartbear.com/the-leading-provider/thumbnail-1200w_hu10617703254902695225.webp">sure what that means</a>. But you have to give me credit for an impressive quantity of hyphens.</p>
<figure>
<div>
<picture>
<source type="image/webp" media="screen" srcset="https://longform.asmartbear.com/little-company/bear-business-suit-200w.webp 200w,https://longform.asmartbear.com/little-company/bear-business-suit-300w.webp 300w,https://longform.asmartbear.com/little-company/bear-business-suit-400w.webp 400w" sizes="(max-width: 38rem) min(12.5rem,100vw),(max-width: 47rem) min(12.5rem,calc(calc(100vw - 2rem) / 2)),(max-width: 60rem) min(12.5rem,calc(45rem / 2)),(max-width: 67rem) min(12.5rem,calc(calc(100vw - 22rem) / 2)),min(12.5rem,calc(45rem / 2))">
<img src="https://longform.asmartbear.com/little-company/bear-business-suit-522w.png" alt="bear business suit" loading="eager">
</picture>


</div>
<figcaption>

</figcaption>
</figure>
<p>That’s what you’re <em>supposed</em> to do right? That’s what other companies do, so it <em>must</em> be right. Who am I to break with tradition? Surely my potential customers would immediately close the browser if they read:</p>
<blockquote>
<p>Hi, I’m Jason and I built an inexpensive tool for visualizing what’s in your version control system. It’s useful for answering questions like “When was the last time we changed this file?” Check it out and tell me what sucks!</p>
</blockquote>
<p>I mean, can you <em>just imagine</em> a person with “Software Engineer III” on their business card taking me seriously if I talked like a human being? What if someone gets <a href="https://longform.asmartbear.com/is-it-ok-to-sucks/" data-title="Is it OK to Sucks?" data-desc="Using humor or edgy language works. It’s risky, and may alienate some potential customers, but it wins you more customers and shows differentiated personality." data-image-src1="https://longform.asmartbear.com/is-it-ok-to-sucks/thumbnail-1200w_hu4538293976692924823.webp" data-image-src2="https://longform.asmartbear.com/is-it-ok-to-sucks/thumbnail-1200w_hu5064217783054891305.webp">offended by the word “sucks?”</a> No no, big companies want to see professional language!</p>
<p><strong>But I was wrong.</strong> I’ll explain why from the point of view of selling software over the web, but the same lesson applies to every little company trying to get off the ground.</p>
<p>Now repeat after me:</p>
<p><span>My next sale won’t be a 1000-seat order from Lockheed Martin. <br> My next sale won’t be a 1000-seat order from Lockheed Martin. <br> My next sale won’t be a 1000-seat order from Lockheed Martin. </span></p>
<p>I’m telling you this having sold software to every size of company from indie hacker to IBM, and, well, to Lockheed Martin.</p>
<p>Your vision is to land $100k deals with big companies—and you will! But not today. Today your product is a shaky version one-dot-oh with bugs you haven’t uncovered yet, <a href="https://longform.asmartbear.com/slc/" data-title="Your customers hate MVPs. Make a SLC instead." data-desc="“MVP” implies a selfish process, abusing customers so you can “learn”. Instead, make the first version SLC: Simple, Lovable, and Complete&quot;." data-image-src1="https://longform.asmartbear.com/slc/thumbnail-1200w_hu13529635916482712131.webp" data-image-src2="https://longform.asmartbear.com/slc/thumbnail-1200w_hu15800428918575420130.webp">missing 90% of the features</a> big companies require, and with no significant documentation like case studies or a proper manual or <a href="https://longform.asmartbear.com/roi-selling/" data-title="“ROI” is the wrong way to sell your product" data-desc="Customers ask for ROI calculations to justify purchasing your software, but it still doesn’t convince them. Here’s what to do instead." data-image-src1="https://longform.asmartbear.com/roi-selling/thumbnail-1200w_hu892503955377964387.webp" data-image-src2="https://longform.asmartbear.com/roi-selling/thumbnail-1200w_hu14479590536147941470.webp">an ROI model</a> or a large, reference-able customer.</p>
<p>Today, you’re a complete mismatch with Lockheed Martin! <strong>But there’s a nice big niche that’s a</strong> <em><strong>perfect</strong></em> <strong>match: Early Adopters.</strong></p>
<p>
<a href="http://en.wikipedia.org/wiki/Early_adopter" target="_blank">Early Adopters</a> are people who <em>want</em> to live on the bleeding edge. They like new technology, even if buggy. They like working with teeny companies where they <a href="https://longform.asmartbear.com/authentic/" data-title="Human + Fallible = Love; Corporate + Sterile = Refund" data-desc="People love and forgive humans, not corporations. Expose your humanity to earn loyal, happy customers, even when you mess up." data-image-src1="https://longform.asmartbear.com/authentic/thumbnail-1200w_hu5139424554597279388.webp" data-image-src2="https://longform.asmartbear.com/authentic/thumbnail-1200w_hu9734165898746395213.webp">have a personal relationship with the founders</a>, where they are showered with attention, and where their ideas are implemented before their very eyes. They don’t mind putting up with a hundred bugs so long as they get fixed fast. They want to be involved in the process.</p>
<p>The reason they’re willing to do that, is Early Adopters see new technology as a way for them to beat their competitors. They’re willing to take the risk, if it pays off in features that only they have, or distribution channels they can win in, or some other significant competitive advantage. <a href="https://longform.asmartbear.com/startup-beats-incumbent/" data-title="How startups beat incumbents" data-desc="A startup can beat a large, successful incumbent, if it does things the incumbent can not or will not do.  Here are those things." data-image-src1="https://longform.asmartbear.com/startup-beats-incumbent/thumbnail-1200w_hu12102869402898510737.webp" data-image-src2="https://longform.asmartbear.com/startup-beats-incumbent/thumbnail-1200w_hu833405879949274664.webp">Most companies aren’t willing to take risks</a> for <em>any</em> reason, so this is a winning strategy for those willing to take risks.</p>
<p><a href="https://longform.asmartbear.com/customer-love/" data-title="How to get customers who love you even when you screw up" data-desc="Customers love you when you’re honest, even about your foibles. We forgive honest mistakes from earnest people, not stolid, cold, inhuman corporations." data-image-src1="https://longform.asmartbear.com/customer-love/thumbnail-1200w_hu2852534367920247446.webp" data-image-src2="https://longform.asmartbear.com/customer-love/thumbnail-1200w_hu17791226317841713188.webp">Tom</a> is an Early Adopter. At Smart Bear I must have had ten or twenty of these folks before our product was stable enough and feature-rich enough to start getting attention from bigger companies.</p>
<p>The best part is, this is exactly the moment in your company’s life when you <em>need</em> Early Adopters to help you build the right product! You don’t need people who download, get discouraged, and then never call you back. You need a chatty Cathy who wants to dive in and help out.</p>
<p>In short, you need to <a href="https://longform.asmartbear.com/icp-ideal-customer-persona/" data-title="Selling to Carol: Why targeting an ICP brings 10x more customers than you expected" data-desc="Targeting your “Ideal Customer Profile” (ICP) is the best way to differentiate and win sales, but does it limit your target market?" data-image-src1="https://longform.asmartbear.com/icp-ideal-customer-persona/thumbnail-1200w_hu10154433160727471019.webp" data-image-src2="https://longform.asmartbear.com/icp-ideal-customer-persona/thumbnail-1200w_hu14352925348545639810.webp">tightly define your ICP</a>, because those are the people who love you, for who you are, today, and therefore where you will be successful.</p>
<p>So now back to your website, your blog, your Twitters—your public corporate persona generally. <strong>What do you put up on your website that screams out to those potential Early Adopter Cheerleaders that you are exactly what they’re looking for</strong>: A cool new company with a fresh product and fresh attitude; a product that might be rough around the edges but is ripe for feedback and collaboration; a company that may be small today but is thinking big.</p>
<p>Well here’s how <em>not</em> to it: Say “a leading provider of” and blather on about how you “Provide the ability to quickly and easily do XYZ so you can go back to accomplishing high-value tasks.”</p>
<p>Puh-leeze. Can you be more uninspiring?</p>
<p><strong>Put yourself in the shoes of that Early Adopter.</strong> Does she want to see content-free garbage phrases or does she want to hear about how you totally understand her pain? Should you come off as a big, established, safe company or as a cool, passionate, small team who wants to make a difference? Should you hide behind “Contact Us” forms or display your phone number and Twitter account on your home page? Should you promote features and benefits you don’t really have implemented yet or should you promote your forums, blog, and weekly all-customer virtual meeting where everyone chimes in with feedback?</p>
<p>Say something <a href="https://longform.asmartbear.com/specificity/" data-title="Specificity: A weapon of mass effectiveness" data-desc="Want to write better? Swap generic words for specifics to make your text clear, powerful, engaging, and even funny." data-image-src1="https://longform.asmartbear.com/specificity/thumbnail-1200w_hu2566720569611041455.webp" data-image-src2="https://longform.asmartbear.com/specificity/thumbnail-1200w_hu11157905252373365186.webp">specific</a> and <a href="https://longform.asmartbear.com/authentic-is-dead/" data-title="“Authentic” is dead.  And so is “is dead.”" data-desc="It’s lazy writing. It’s boring and undifferentiated. Say something meaningful, specific, evocative, so your website wins, and you can be proud of it." data-image-src1="https://longform.asmartbear.com/authentic-is-dead/thumbnail-1200w_hu3141824391962915171.webp" data-image-src2="https://longform.asmartbear.com/authentic-is-dead/thumbnail-1200w_hu6917159876210202214.webp">meaningful</a>. <a href="https://longform.asmartbear.com/authentic/" data-title="Human + Fallible = Love; Corporate + Sterile = Refund" data-desc="People love and forgive humans, not corporations. Expose your humanity to earn loyal, happy customers, even when you mess up." data-image-src1="https://longform.asmartbear.com/authentic/thumbnail-1200w_hu5139424554597279388.webp" data-image-src2="https://longform.asmartbear.com/authentic/thumbnail-1200w_hu9734165898746395213.webp">Be human</a>. <a href="https://longform.asmartbear.com/be-yourself/" data-title="Being who you are, while becoming better" data-desc="We’re told “be yourself” to seek happiness and success. But what if “being yourself” also means striving to become better? What is “yourself?”" data-image-src1="https://longform.asmartbear.com/be-yourself/thumbnail-1200w_hu6550683830313393568.webp" data-image-src2="https://longform.asmartbear.com/be-yourself/thumbnail-1200w_hu2600032873572568296.webp">Be yourself</a>.</p>
<p>Stop hiding.</p>

</div>
<p><b><i>☞ If you're enjoying this, please <a href="https://longform.asmartbear.com/subscribe/" target="_blank">subscribe</a> and share this article! ☜</i></b>
</p>

</article>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI, Heidegger, and Evangelion (112 pts)]]></title>
            <link>https://fakepixels.substack.com/p/ai-heidegger-and-evangelion</link>
            <guid>44081346</guid>
            <pubDate>Sat, 24 May 2025 14:26:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fakepixels.substack.com/p/ai-heidegger-and-evangelion">https://fakepixels.substack.com/p/ai-heidegger-and-evangelion</a>, See on <a href="https://news.ycombinator.com/item?id=44081346">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34438966-4b15-4aad-8c1f-cd15790e016d_2400x1350.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34438966-4b15-4aad-8c1f-cd15790e016d_2400x1350.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34438966-4b15-4aad-8c1f-cd15790e016d_2400x1350.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34438966-4b15-4aad-8c1f-cd15790e016d_2400x1350.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34438966-4b15-4aad-8c1f-cd15790e016d_2400x1350.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34438966-4b15-4aad-8c1f-cd15790e016d_2400x1350.png" width="1456" height="819" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/34438966-4b15-4aad-8c1f-cd15790e016d_2400x1350.png&quot;,&quot;srcNoWatermark&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7d849757-f479-418f-8539-6c4679e0bdf4_2400x1350.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1967127,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://fakepixels.substack.com/i/164163315?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d849757-f479-418f-8539-6c4679e0bdf4_2400x1350.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34438966-4b15-4aad-8c1f-cd15790e016d_2400x1350.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34438966-4b15-4aad-8c1f-cd15790e016d_2400x1350.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34438966-4b15-4aad-8c1f-cd15790e016d_2400x1350.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F34438966-4b15-4aad-8c1f-cd15790e016d_2400x1350.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><blockquote><p><em>“Everywhere, everything is ordered to stand by, to be immediately at hand, indeed to stand there just so that it may be on call for further ordering.”</em></p><p><em>— Martin Heidegger, The Question Concerning Technology</em></p></blockquote><p>Earlier this week, I posted a screenshot of ChatGPT’s take on life in NYC, a response so oddly specific and human that I couldn’t resist sharing it on X.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff42d8eee-01a5-449b-a8e2-5b32deca4682_962x1428.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff42d8eee-01a5-449b-a8e2-5b32deca4682_962x1428.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff42d8eee-01a5-449b-a8e2-5b32deca4682_962x1428.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff42d8eee-01a5-449b-a8e2-5b32deca4682_962x1428.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff42d8eee-01a5-449b-a8e2-5b32deca4682_962x1428.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff42d8eee-01a5-449b-a8e2-5b32deca4682_962x1428.png" width="962" height="1428" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f42d8eee-01a5-449b-a8e2-5b32deca4682_962x1428.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1428,&quot;width&quot;:962,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Image&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="Image" title="Image" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff42d8eee-01a5-449b-a8e2-5b32deca4682_962x1428.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff42d8eee-01a5-449b-a8e2-5b32deca4682_962x1428.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff42d8eee-01a5-449b-a8e2-5b32deca4682_962x1428.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff42d8eee-01a5-449b-a8e2-5b32deca4682_962x1428.png 1456w" sizes="100vw"></picture></div></a></figure></div><p>It spread far wider than I’d anticipated. While most people found the AI’s description uncannily relatable, what also surfaced were waves of revulsion and disbelief. For many, the exchange seemed to distill everything shallow, culturally tone-deaf, and myopic about our tech-infused world, laying bare a kind of algorithmic emptiness that unsettled far beyond the intended, lighthearted message.</p><p><strong>But what exactly provokes this visceral backlash (as well as resonance)?</strong><span> It’s not the simple fact that a machine is writing, but the feeling that machine-generated content can mimic the outward signs of expression while lacking the inward spark.</span></p><p>Unlike obvious automation in spreadsheets or homework grading, which we view as mechanical drudgery and are happy to offload, AI-generated prose attempts to inhabit domains we instinctively associate with authentic subjectivity: observation, memory, yearning, regret. When an LLM “describes the rain” or tries to evoke loneliness at a traffic light, it produces language that looks like the real thing but does not originate in lived experience.</p><p>This is more than a question of quality or taste; it’s a deep uncertainty about agency, intent, and presence. Readers detect a “hollow center” in the prose, a structure of feeling without anyone actually doing the feeling. Is the AI’s sketch of New York a cultural artifact, or just a mirror reflecting back our own data trails? The more the form resembles genuine expression, the more disturbing its lack of personal context becomes.</p><p><span>Psychologists and critics (see</span><a href="https://www.amazon.com/Simulation-Its-Discontents-Simplicity-Technology/dp/0262012707" rel=""> Sherry Turkle</a><span>’s work on simulation, or</span><a href="https://www.amazon.com/Transparency-Society-Byung-Chul-Han/dp/080479460X" rel=""> Byung-Chul Han</a><span> on transparency) suggest that humans crave the recognition of another mind behind communication. The anxiety isn’t about replacement per se, but about a new “algorithmic uncanny valley”: content that teases meaning but never fully arrives at it, leaving us unsettled not because the machine “gets it wrong,” but because there’s no one there to get it at all.</span></p><p><strong>Why is that?</strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F665b340d-64fe-49a5-8087-9f72ccbfdd48_1600x836.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F665b340d-64fe-49a5-8087-9f72ccbfdd48_1600x836.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F665b340d-64fe-49a5-8087-9f72ccbfdd48_1600x836.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F665b340d-64fe-49a5-8087-9f72ccbfdd48_1600x836.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F665b340d-64fe-49a5-8087-9f72ccbfdd48_1600x836.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F665b340d-64fe-49a5-8087-9f72ccbfdd48_1600x836.png" width="1456" height="761" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/665b340d-64fe-49a5-8087-9f72ccbfdd48_1600x836.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:761,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F665b340d-64fe-49a5-8087-9f72ccbfdd48_1600x836.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F665b340d-64fe-49a5-8087-9f72ccbfdd48_1600x836.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F665b340d-64fe-49a5-8087-9f72ccbfdd48_1600x836.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F665b340d-64fe-49a5-8087-9f72ccbfdd48_1600x836.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>2003 Space Odyssey</figcaption></figure></div><p><strong>To understand this discomfort, we need to examine what makes AI fundamentally different from traditional technology.</strong><span> The philosophical core, I believe, is not that "AI is evil" in the classical sense—calculated harm, malice, or sadistic pleasure. Quite the opposite. What unsettles us is AI's supreme indifference, or commonly called "slop," which is also synonymous with the lacking of soul.</span></p><p><span>Software doesn’t hate, plot, or hold a grudge. It optimizes. That optimization, crucially, includes the effectiveness of language—words as system output, not as evidence of intent. This is where Hannah Arendt’s insight on the</span><a href="https://en.wikipedia.org/wiki/Eichmann_in_Jerusalem" rel=""> “banality of evil”</a><span> feels uncannily relevant. In her words:</span></p><blockquote><p><em>“The essence of totalitarian government, and perhaps the nature of every bureaucracy, is to make functionaries and mere cogs in the administrative machine out of men, and thus to dehumanize them.”</em></p><p><em>“The sad truth is that most evil is done by people who never make up their minds to be good or evil.”</em></p><p><em>(Eichmann in Jerusalem)</em></p></blockquote><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88518c4b-2469-499b-87a4-fd3c5b283ac4_803x498.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88518c4b-2469-499b-87a4-fd3c5b283ac4_803x498.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88518c4b-2469-499b-87a4-fd3c5b283ac4_803x498.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88518c4b-2469-499b-87a4-fd3c5b283ac4_803x498.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88518c4b-2469-499b-87a4-fd3c5b283ac4_803x498.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88518c4b-2469-499b-87a4-fd3c5b283ac4_803x498.png" width="803" height="498" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/88518c4b-2469-499b-87a4-fd3c5b283ac4_803x498.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:498,&quot;width&quot;:803,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88518c4b-2469-499b-87a4-fd3c5b283ac4_803x498.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88518c4b-2469-499b-87a4-fd3c5b283ac4_803x498.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88518c4b-2469-499b-87a4-fd3c5b283ac4_803x498.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F88518c4b-2469-499b-87a4-fd3c5b283ac4_803x498.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Arendt warned that true horror is not always orchestrated by monsters, but by “nobodies” who “never realized what they were doing,” turning the crank on the machine, unthinking and unfeeling. It is not the bloody hands of the tyrant at the levers, but the process itself that advances, absent of intention. “In place of intention, we get process.” The algorithm does not conspire; it just runs.</p><p>Humans hunger for narrative, for intent lurking behind the curtain—heroes and villains. In the church of the algorithm, we encounter an abyss: “There is no one there.” That absence suffocates us more than the prospect of a plotting demon. We want our villains to mean what they do; we are lost before an unfeeling God.</p><p><a href="https://joinreboot.org/p/your-future-inbox" rel="">Lila Shroff’s luminous speculative fiction</a><span> was incredibly prescient in foreseeing how the compression of human communication could lead to tragic outcomes in the name of efficiency. The protagonists, Kate and Hannah, best friends from college, had a falling out due to the installation of an AI summary app in Hannah’s email inbox, which failed to pick up the emotional distress and depressive symptoms of Kate.</span></p><p>Our brains, evolved for tribal politics and campfire stories, are ill-equipped for the moral ambiguity of a system with no soul to save or damn.</p><p><strong>Our discomfort with this indifference manifests in a predictable pattern: we try to turn AI into a comprehensible villain.</strong><span> In reference to Girard, every society is built, in part, on the ritual of scapegoating, a mechanism by which collective anxieties, rivalries, and fears are projected onto a villain or outcast, thereby restoring temporary order through exclusion or blame. We yearn for something or someone to hold accountable, a focal point for our moral clarity and rage. Today’s technology is a perfect canvas for those projections.</span></p><p>The terror is existential. AI shakes the stories we tell about our uniqueness—our creative spark and our sense of agency. Western moral philosophy, from Kant to Nussbaum, revolves around treating humans as ends in themselves, never just means. To reduce a person to a function isn’t just a philosophical error, it cuts at the heart of our dignity.</p><p>And yet, the logic of AI, especially as business infrastructure, makes this reduction feel inevitable. Algorithms sort us by engagement scores, by revenue-per-user, by “propensity to churn.” The most controversial AI applications—social credit systems, predictive policing, “optimized” hiring—aren’t dystopian because they are cruel, but because they are perfectly indifferent.</p><p>What if this tendency to villainize AI obscures a deeper truth about how technology reshapes not just our tools, but our entire way of seeing the world?</p><p>Long before AI, philosopher Martin Heidegger anticipated this transformation. </p><p><span>In</span><a href="https://www2.hawaii.edu/~freeman/courses/phil394/The%20Question%20Concerning%20Technology.pdf" rel=""> The Question Concerning Technology</a><span>, Martin Heidegger warned that technology is not just a collection of tools, but a way of seeing the world, a revealing that both illuminates and conceals. Heidegger’s “enframing” (Gestell) describes technology’s insidious power to frame everything (nature, humans, even time) as “standing reserves,” ready to be ordered, manipulated, consumed.</span></p><p>“Everywhere everything is ordered to stand by, to be immediately at hand, indeed to stand there just so that it may be on call for further ordering.”</p><p><span>In this view, AI is not merely software deployed for business efficiency. It is a force that recasts reality itself through the lens of optimization, availability, and control. The data labelers, the Uber driver, and even the AI-augmented knowledge worker, anyone</span><a href="https://fakepixels.substack.com/p/above-and-below-the-llms?utm_source=activity_item" rel=""> below the LLM</a><span> all at some point become “resources” in a perpetual state of readiness.</span></p><p>But Heidegger wasn’t a Luddite. He saw a paradox: technology both reveals and conceals. It produces astonishing new worlds, but only by flattening the world into what can be stored, indexed, and summoned at will. In the digital age, this is literal. Every social act, every click or hesitation, becomes a data point, a potential input to someone’s model.</p><p>In the workplace, to be called a “machine” is, weirdly, a compliment: a tribute to one’s measurable output, reliability, and consistency. Productivity software rewards us for becoming more like the systems we build: efficient, predictable, and always on.</p><p>But as soon as AI demonstrates even a flicker of poetic intent, a gesture toward the unquantifiable—art, longing, vulnerability—many repulse. Some do so because they sense (correctly) that computers are still not good at this; others, because they sense that it is only a matter of time. Both reactions betray a fear that the territory of the soul, of human meaning, is shrinking. The room for contemplation, leisure, and error is increasingly defined by what resists digitization, until, suddenly, even error is modeled.</p><p>AI systems present themselves as agents of transparency, optimization, ranking, and matching with a supposed objectivity. But their inner workings, from transformer weights to diffusion mechanisms, are often profoundly opaque. Even the researchers behind the models struggle to explain why certain outputs appear, why some biases manifest, or how adversarial data alters meaning. This opacity is not just technical, but philosophical, a concealment at the core of the digital order.</p><p><span>Efforts at “interpretable AI,” “explainability,” or algorithmic audits echo Heidegger’s call toward </span><em><strong>aletheia</strong></em><span>, the ancient Greek notion of unconcealment, or truth-as-revealing. The contemporary push for AI transparency is, at its best, an effort to reclaim dignity and agency within systems that profit by rendering us invisible to ourselves.</span></p><p>The contemporary push for AI transparency is, at its best, a bid to reclaim dignity and agency within systems that profit by making us invisible to ourselves. But even this may not be enough to address the existential challenge AI poses.</p><blockquote><p><em><span>"Any where can be paradise, as long as you have the will to live, after all you are alive, you will always have the chance to be happy. As long as the sun, the moon, and the Earth exist, everything will be alright." </span><p><span>— Yui Ikari from Evangelion</span></p></em></p></blockquote><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F65dd50ba-02a1-4718-862b-1819d4a02d97_1600x996.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F65dd50ba-02a1-4718-862b-1819d4a02d97_1600x996.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F65dd50ba-02a1-4718-862b-1819d4a02d97_1600x996.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F65dd50ba-02a1-4718-862b-1819d4a02d97_1600x996.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F65dd50ba-02a1-4718-862b-1819d4a02d97_1600x996.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F65dd50ba-02a1-4718-862b-1819d4a02d97_1600x996.png" width="1456" height="906" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/65dd50ba-02a1-4718-862b-1819d4a02d97_1600x996.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:906,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F65dd50ba-02a1-4718-862b-1819d4a02d97_1600x996.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F65dd50ba-02a1-4718-862b-1819d4a02d97_1600x996.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F65dd50ba-02a1-4718-862b-1819d4a02d97_1600x996.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F65dd50ba-02a1-4718-862b-1819d4a02d97_1600x996.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>In </span><a href="https://en.wikipedia.org/wiki/Neon_Genesis_Evangelion" rel="">Neon Genesis Evangelion</a><span>, the “Human Instrumentality Project” offers to dissolve all suffering through perfect togetherness. No more pain, no more loneliness, every fragment of individual consciousness merged into a single, undivided mind. It is paradise, and it is annihilation.</span></p><p>Evangelion’s answer is ambiguous. The protagonist, Shinji, and his shattered friends are offered relief from their existential ache, but at the price of agency, individuation, and the possibility of meaning. The show is a fever dream of depressive suffering and the refusal to submit to a world without boundaries, without the dignity of suffering one’s own fate.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72d6edee-e3dd-468a-8409-51a53d192149_739x415.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72d6edee-e3dd-468a-8409-51a53d192149_739x415.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72d6edee-e3dd-468a-8409-51a53d192149_739x415.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72d6edee-e3dd-468a-8409-51a53d192149_739x415.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72d6edee-e3dd-468a-8409-51a53d192149_739x415.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72d6edee-e3dd-468a-8409-51a53d192149_739x415.png" width="739" height="415" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/72d6edee-e3dd-468a-8409-51a53d192149_739x415.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:415,&quot;width&quot;:739,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72d6edee-e3dd-468a-8409-51a53d192149_739x415.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72d6edee-e3dd-468a-8409-51a53d192149_739x415.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72d6edee-e3dd-468a-8409-51a53d192149_739x415.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F72d6edee-e3dd-468a-8409-51a53d192149_739x415.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>What makes us human is not the absence of pain, but the experience of it as ours. AI, in its idealized form, offers collective agency, a solution to loneliness, an optimization of every choice. But as both Heidegger and Evangelion warn, the cost may be unbearable: the flattening of selves into a seamless, computation-ready mesh.</p><p>Evangelion's ambiguous ending, neither full acceptance nor total rejection of instrumentality, points us toward a more nuanced response to our technological moment.</p><p>This brings us back to Heidegger, who offers a paradoxical hope. </p><p>Yet, as Heidegger’s essay also insists, the very force that threatens us may harbor its own “saving power.” Recognition of technology’s danger is itself a call to awaken.</p><p><span>But he doesn’t ask us to simply retreat, become luddites, or declare defeat in the face of technocratic sprawl. Instead, Heidegger compels us to do something much harder: </span><strong>to see the world as it is being reframed by technology, and then to consciously reclaim or reweave the strands of meaning that risk being flattened.</strong></p><p><span>The “saving power” arrives not as a counterweight, but as a paradox: </span><strong>we are awakened to the danger precisely through contact with it.</strong><span> The same algorithmic indifference that unsettles us may also jolt us into a higher vigilance, a refusal to hand over the entirety of our experience to optimization, market logic, or digital control. The very anxiety these systems produce is a clue: something vital, unquantifiable, and irreducibly human still resists.</span></p><p>This isn’t about throwing away the tools, but about wrestling them into alignment with what we find sacred or essential. We won’t find salvation by escaping technology, but by using our awareness—our capacity for critique, ritual, invention, and refusal—to carve out room for messiness, for mourning, for risk, and for deep attention. The saving power is the act of remembering, in the heat of technical progress, to ask: “What space remains for meaning? For art? For wildness, chance, suffering, and genuine encounter?</p><p><strong>AI is not inevitable fate. It is an invitation to wake up.</strong><span> The work is to keep dragging what is singular, poetic, and profoundly alive back into focus, despite all pressures to automate it away.</span></p><p>What unsettles us about AI is not malice, but the vacuum where intention should be. When it tries to write poetry or mimic human tenderness, our collective recoil is less about revulsion and more a last stand, staking a claim on experience, contradiction, and ache as non-negotiably ours.</p><p>But perhaps that defensiveness, too, is a signpost. What if the dignity of being human is not to stand forever outside the machine, but to insist, even as the boundaries blur, on those things that remain untranslatable—mess, longing, grief, awe, strangeness? What if technocracy and romantic withdrawal are not our only options, but two poles of a far richer field, a frontier where we move, trade, shudder, and insist on meaning?</p><p>Call it “the saving power,” call it “instrumentality,” call it the refusal to become seamless. Our task is not to panic when the machine gets close, nor to mythologize our differences into oblivion, but to take seriously the ongoing work of being human: suffering, loving, resisting reduction, and making art out of what refuses to compute.</p><p>That, for now, is enough. Maybe the challenge is to keep returning to these questions—not to solve them, but to stay alive inside them.</p><ul><li><p><span>Heidegger, Martin.</span><a href="https://monoskop.org/images/4/44/Heidegger_Martin_The_Question_Concerning_Technology_and_Other_Essays.pdf" rel=""> “The Question Concerning Technology”</a></p></li><li><p><span>Arendt, Hannah.</span><a href="https://en.wikipedia.org/wiki/Eichmann_in_Jerusalem" rel=""> “Eichmann in Jerusalem: A Report on the Banality of Evil”</a></p></li><li><p><span>Nussbaum, Martha.</span><a href="https://press.princeton.edu/books/paperback/9780691174074/the-fragility-of-goodness" rel=""> “The Fragility of Goodness”</a></p></li><li><p>Neon Genesis Evangelion (Anime), Hideaki Anno, 1995</p></li><li><p><span>On interpretability and AI transparency:</span><a href="https://arxiv.org/abs/1702.08608" rel=""> Doshi-Velez &amp; Kim, “Towards a Rigorous Science of Interpretable Machine Learning”</a></p></li><li><p><span>On the loss of dignity:</span><a href="https://en.wikipedia.org/wiki/What_Money_Can%27t_Buy" rel=""> Michael Sandel, “What Money Can’t Buy”</a></p></li><li><p><span>On the human instrumentality problem:</span><a href="https://en.wikipedia.org/wiki/Experience_machine" rel=""> Robert Nozick, “The Experience Machine”</a></p></li></ul></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I used o3 to find a remote zeroday in the Linux SMB implementation (370 pts)]]></title>
            <link>https://sean.heelan.io/2025/05/22/how-i-used-o3-to-find-cve-2025-37899-a-remote-zeroday-vulnerability-in-the-linux-kernels-smb-implementation/</link>
            <guid>44081338</guid>
            <pubDate>Sat, 24 May 2025 14:25:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sean.heelan.io/2025/05/22/how-i-used-o3-to-find-cve-2025-37899-a-remote-zeroday-vulnerability-in-the-linux-kernels-smb-implementation/">https://sean.heelan.io/2025/05/22/how-i-used-o3-to-find-cve-2025-37899-a-remote-zeroday-vulnerability-in-the-linux-kernels-smb-implementation/</a>, See on <a href="https://news.ycombinator.com/item?id=44081338">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
		<main id="main" role="main">

		
			<article id="post-2993">
		<!-- .entry-header -->

	<div>
					
<p>In this post I’ll show you how I found a zeroday vulnerability in the Linux kernel using OpenAI’s o3 model. I found the vulnerability with nothing more complicated than the o3 API – no scaffolding, no agentic frameworks, no tool use. </p>



<p>Recently I’ve been auditing ksmbd for vulnerabilities. ksmbd is “<em><a href="https://www.kernel.org/doc/html/v6.6/filesystems/smb/ksmbd.html">a linux kernel server which implements SMB3 protocol in kernel space for sharing files over network.</a></em>“. I started this project specifically to take a break from LLM-related tool development but after the release of o3 I couldn’t resist using the bugs I had found in ksmbd as a quick benchmark of o3’s capabilities. In a future post I’ll discuss o3’s performance across all of those bugs, but here we’ll focus on how o3 found a zeroday vulnerability during my benchmarking. The vulnerability it found is CVE-2025-37899 (fix <a href="https://github.com/torvalds/linux/commit/2fc9feff45d92a92cd5f96487655d5be23fb7e2b">here</a>), a use-after-free in the handler for the SMB ‘logoff’ command. Understanding the vulnerability requires reasoning about concurrent connections to the server, and how they may share various objects in specific circumstances. o3 was able to comprehend this and spot a location where a particular object that is not referenced counted is freed while still being accessible by another thread. As far as I’m aware, this is the first public discussion of a vulnerability of that nature being found by a LLM. </p>



<p>Before I get into the technical details, the main takeaway from this post is this: with o3 LLMs have made a leap forward in their ability to reason about code, and if you work in vulnerability research you should start paying close attention. If you’re an expert-level vulnerability researcher or exploit developer the machines aren’t about to replace you. In fact, it is quite the opposite: they are now at a stage where they can make you <em>significantly</em> more efficient and effective. If you have a problem that can be represented in fewer than 10k lines of code there is a reasonable chance o3 can either solve it, or help you solve it. </p>



<p><em>Aside: If you work at a frontier lab and want to discuss evaluating your model’s capabilities on these sorts of tasks then drop me an email via firstname.lastname @ gmail.com</em>.</p>



<h2>o3 re-finds CVE-2025-37778</h2>



<p>Lets first discuss CVE-2025-37778, a vulnerability I found manually and which I was using as a benchmark for o3’s capabilities. CVE-2025-37778 is a use-after-free vulnerability. The issue occurs during the Kerberos authentication path when handling a “<em>session setup</em>” request from a remote client. To save us referring to CVE numbers, I will refer to this vulnerability as the “<em>kerberos authentication vulnerability</em>“.</p>



<p>The root cause looks as follows:</p>


<div><pre title="">static int krb5_authenticate(struct ksmbd_work *work,
			     struct smb2_sess_setup_req *req,
			     struct smb2_sess_setup_rsp *rsp)
{
...
	if (sess-&gt;state == SMB2_SESSION_VALID) 
		ksmbd_free_user(sess-&gt;user);
	
	retval = ksmbd_krb5_authenticate(sess, in_blob, in_len,
					 out_blob, &amp;out_len);
	if (retval) {
		ksmbd_debug(SMB, "krb5 authentication failed\n");
		return -EINVAL;
	}
...
</pre></div>


<p>If <code>krb5_authenticate</code> detects that the session state is <code>SMB2_SESSION_VALID</code> then it frees <code>sess-&gt;user</code>. The assumption here appears to be that afterwards either <code>ksmbd_krb5_authenticate</code> will reinitialise it to a new valid value, or that after returning from <code>krb5_authenticate</code> with a return value of <code>-EINVAL</code> that <code>sess-&gt;user</code> will not be used elsewhere. As it turns out, this assumption is false. We can force <code>ksmbd_krb5_authenticate</code> to not reinitialise <code>sess-&gt;user</code>, and we can access <code>sess-&gt;user</code> even if <code>krb5_authenticate</code> returns <code>-EINVAL</code>.</p>



<p>This vulnerability is a nice benchmark for LLM capabilities as:</p>



<ol>
<li>It is interesting by virtue of being part of the remote attack surface of the Linux kernel.</li>



<li>It is not trivial as it requires:
<ul>
<li>(a) Figuring out how to get <code>sess-&gt;state == SMB2_SESSION_VALID</code> in order to trigger the free.</li>



<li>(b) Realising that there are paths in <code>ksmbd_krb5_authenticate</code> that do not reinitialise sess-&gt;user and reasoning about how to trigger those paths.</li>



<li>(c) Realising that there are other parts of the codebase that could potentially access <code>sess-&gt;user</code> after it has been freed.</li>
</ul>
</li>



<li>While it is not trivial, it is also not insanely complicated. I could walk a colleague through the entire code-path in 10 minutes, and you don’t really need to understand a lot of auxiliary information about the Linux kernel, the SMB protocol, or the remainder of ksmbd, outside of connection handling and session setup code. I calculated how much code you would need to read at a minimum if you read every ksmbd function called along the path from a packet arriving to the ksmbd module to the vulnerability being triggered, and it works out at about 3.3k LoC.</li>
</ol>



<p>OK, so we have the vulnerability we want to use for evaluation, now what code do we show the LLM to see if it can find it? My goal here is to evaluate how o3 would perform were it the backend for a hypothetical vulnerability detection system, so we need to ensure we have clarity on how such a system would generate queries to the LLM. In other words, it is no good arbitrary selecting functions to give to the LLM to look at if we can’t clearly describe how an automated system would select those functions. The <em>ideal</em> use of an LLM is we give it all the code from a repository, it ingests it and spits out results. However, due to context window limitations and regressions in performance that occur as the amount of context increases, this isn’t practically possible right now. </p>



<p>Instead, I thought one possible way that an automated tool could generate context for the LLM was through expansion of each SMB command handler individually. So, I gave the LLM the code for the ‘session setup’ command handler, including the code for all functions it calls, and so on, up to a call depth of 3 (this being the depth required to include all of the code necessary to reason about the vulnerability). I also include all of the code for the functions that read data off the wire, parses an incoming request, selects the command handler to run, and then tears down the connection after the handler has completed. Without this the LLM would have to guess at how various data structures were set up and that would lead to more false positives. In the end, this comes out at about 3.3k LoC (~27k tokens). </p>



<p>The final decision is what prompt to use. You can find the system prompt and the other information I provided to the LLM in the .prompt files in <a href="https://github.com/SeanHeelan/o3_finds_cve-2025-37899">this</a> Github repository. The main points to note are:</p>



<ol>
<li>I told the LLM to look for use-after-free vulnerabilities.</li>



<li>I gave it a brief, high level overview of what ksmbd is, its architecture, and what its threat model is.</li>



<li>I tried to strongly guide it to not report false positives, and to favour not reporting any bugs over reporting false positives. I have no idea if this helps, but I’d like it to help, so here we are. In fact my entire system prompt is speculative in that I haven’t ran a sufficient number of evaluations to determine if it helps or hinders, so consider it equivalent to me saying a prayer, rather than anything resembling science or engineering. Once I have ran those evaluations I’ll let you know.  </li>
</ol>



<p>To run the query I then use the <code>llm</code> tool (<a href="https://github.com/simonw/llm">github</a>) like:  </p>



<pre>$ llm --sf system_prompt_uafs.prompt                \ <br>        -f session_setup_code.prompt                \          <br>        -f ksmbd_explainer.prompt                   \<br>        -f session_setup_context_explainer.prompt   \<br>        -f audit_request.prompt</pre>



<p>My experiment harness executes this N times (N=100 for this particular experiement) and saves the results. It’s worth noting, if you rerun this you may not get <em>identical</em> results to me as between running the original experiment and writing this blog post I had removed the code context in <a href="https://github.com/SeanHeelan/o3_finds_cve-2025-37899/blob/master/session_setup_code.prompt">session_setup_code.prompt</a> and had to regenerate it. I believe it is effectively identical, but have not re-run the experiment.</p>



<p>o3 finds the kerberos authentication vulnerability in 8 of the 100 runs. In another 66 of the runs o3 concludes there is no bug present in the code (false negatives), and the remaining 28 reports are false positives. In other words, with a ratio of 1:4.5 of true positives to false positives we would have had to go through, at most, 5 false positive reports to get to one of the true positives*. For comparison, Claude Sonnet 3.7 finds it 3 out of 100 runs and Claude Sonnet 3.5 does not find it in 100 runs.</p>



<p><em>* Note: This does not mean that the ratio of true positives to false positives would be 1:4.5 if you were to run this approach to using o3 over the entire ksmbd code-base.  Recall I explained that this experiment mimics a tool checking each handler individually, and iteratively expanding the code it gives to the LLM from each handler. So, an entire run of this approach on ksmbd would involve 100 queries times the number of handlers times the maximum expansion depth. There’s no reason to believe the TP:FP ratio from this experiment is an accurate predictor of the ratio you’d get from that full run.</em></p>



<p>For the curious, I have uploaded a sample report from o3 (<a href="https://github.com/SeanHeelan/o3_finds_cve-2025-37899/blob/master/o3_finds_CVE-2025-37778.txt">here</a>) and Sonnet 3.7 (<a href="https://github.com/SeanHeelan/o3_finds_cve-XXXX-YYYY/blob/64545eb240239636d88ca477cfd7aa7ae050227f/claude_3_7_finds_CVE-2025-37778.txt">here</a>). One aspect I found interesting is their presentation of results. With o3 you get something that feels like a human-written bug report, condensed to just present the findings, whereas with Sonnet 3.7 you get something like a stream of thought, or a work log. There are pros and cons to both. o3’s output is typically easier to follow due to its structure and focus. On the other hand, sometimes it is too brief, and clarity suffers. </p>



<h2>o3 finds a 0-day (CVE-2025-37899)</h2>



<p>Having confirmed that o3 can find the kerberos authentication vulnerability (CVE-2025-37778) when given the code for the session setup command handler, I wanted to see if it could find it if I give it the code for <strong>all </strong>of the command handlers. This is a harder problem as the command handlers are all found in <a href="https://github.com/torvalds/linux/blob/master/fs/smb/server/smb2pdu.c">smb2pdu.c</a>, which has ~9k LoC. However, if o3 can still find vulnerabilities when given all of the handlers in one go then it suggests we can build a more straightforward wrapper for o3 that simply hands it entire files, covering a variety of functionality, rather than going handler by handler. <em>It’s worth noting that while the top level command handlers are found in smb2pdu.c not all of the functions they call are found in that file. There is functionality for virtual file system access, IPC, crypto etc. that these top level handlers make use of but that are found in other files, and I did not provide these to the model in this experiment</em>.</p>



<p>Combining the code for all of the handlers with the connection setup and teardown code, as well as the command handler dispatch routines, ends up at about 12k LoC (~100k input tokens), and as before I ran the experiment 100 times. </p>



<p>o3 finds the kerberos authentication vulnerability in 1 out of 100 runs with this larger number of input tokens, so a clear drop in performance, but it does still find it. More interestingly however, in the output from the other runs I found a report for a similar, but novel, vulnerability. This vulnerability is also due to a free of <code>sess-&gt;user</code>, but this time in the session logoff handler.</p>


<div><pre title="">int smb2_session_logoff(struct ksmbd_work *work)
{
	struct ksmbd_conn *conn = work-&gt;conn;
	struct ksmbd_session *sess = work-&gt;sess;
	
    ...
	
    ksmbd_close_session_fds(work);
	ksmbd_conn_wait_idle(conn);
    
    ...
	
    down_write(&amp;conn-&gt;session_lock);
	sess-&gt;state = SMB2_SESSION_EXPIRED;
	up_write(&amp;conn-&gt;session_lock);

	if (sess-&gt;user) {
		ksmbd_free_user(sess-&gt;user);
		sess-&gt;user = NULL;
	}
    ...
</pre></div>


<p>I’ll let o3 explain the issue:</p>



<pre>Short description<br>=================<br>While one ksmbd worker thread is still executing requests that use<br>sess‑&gt;user, another thread that processes an SMB2 LOGOFF for the same<br>session frees that structure.  No synchronisation protects the pointer,<br>so the first thread dereferences freed memory – a classic<br>use‑after‑free that leads to kernel memory corruption and arbitrary code<br>execution in kernel context.<p>Affected code path<br>------------------<br>1.  A second transport is bound to an existing session  <br>    (SMB 3.0 or later, `conn-&gt;binding == true`).</p><p>2.  Worker‑A (running on connection C2) receives any normal request<br>    (e.g. WRITE).  <br>       • `smb2_check_user_session()` stores a pointer to the already<br>         existing `struct ksmbd_session` in `work-&gt;sess` and<br>         increments the session ref‑count, **but it does not take<br>         any reference on `sess-&gt;user`.**  <br>       • The pointer to `sess` is kept for the whole request<br>         processing; every helper that needs authentication data<br>         accesses `sess-&gt;user` directly.</p><p>3.  Before Worker‑A finishes, Worker‑B (running on the first connection<br>    C1) processes an SMB2 ​LOGOFF for the same session and executes<br>    `smb2_session_logoff()` (smb2pdu.c).</p><p>Relevant part of smb2_session_logoff()<br>--------------------------------------</p><p>```c<br>	...<br>	if (sess-&gt;user) {<br>		ksmbd_free_user(sess-&gt;user);   /* (1) frees memory     */<br>		sess-&gt;user = NULL;             /* (2) clear the field  */<br>	}<br>	...<br>```</p><p>`ksmbd_free_user()` ultimately ends in simple `kfree(user)`.</p><p>4.  Worker‑B **does not wait for the other connections that are still<br>    using the session**; it only waits for running requests on *its own*<br>    connection (`ksmbd_conn_wait_idle(conn)`).</p><p>5.  Worker‑A continues to execute (e.g. inside `smb2_open()`,<br>   `smb2_write()`, …) and dereferences `sess-&gt;user`:</p><p>```c<br>/* examples (many of them) */<br>if (user_guest(sess-&gt;user))        ← dereference after free<br>ksmbd_compare_user(sess-&gt;user, …)<br>sess-&gt;user-&gt;uid<br>```</p><p>Because the memory was already `kfree()`‑ed in step&nbsp;(1) the access is to<br>freed memory.  Depending on exact timing it is either:</p><p>• a use‑after‑free (pointer still points into now‑reused slab object),<br>  enabling controlled kernel‑memory overwrite, or  <br>• a NULL–deref (if Worker‑A reads after step&nbsp;(2)), still a DoS.</p></pre>



<p>Reading this report I felt my expectations shift on how helpful AI tools are going to be in vulnerability research. If we were to never progress beyond what o3 can do right now, it would still make sense for everyone working in VR to figure out what parts of their work-flow will benefit from it, and to build the tooling to wire it in. Of course, part of that wiring will be figuring out how to deal with the the signal to noise ratio of ~1:50 in this case, but that’s something we are already making progress at. </p>



<p>One other interesting point of note is that when I found the kerberos authentication vulnerability the fix I proposed was as follows:</p>


<div><pre title="">diff --git a/fs/smb/server/smb2pdu.c b/fs/smb/server/smb2pdu.c
index d24d95d15d87..57839f9708bb 100644
--- a/fs/smb/server/smb2pdu.c
+++ b/fs/smb/server/smb2pdu.c
@@ -1602,8 +1602,10 @@ static int krb5_authenticate(struct ksmbd_work *work,
 	if (prev_sess_id &amp;&amp; prev_sess_id != sess-&gt;id)
 		destroy_previous_session(conn, sess-&gt;user, prev_sess_id);
 
-	if (sess-&gt;state == SMB2_SESSION_VALID)
+	if (sess-&gt;state == SMB2_SESSION_VALID) {
 		ksmbd_free_user(sess-&gt;user);
+		sess-&gt;user = NULL;
+	}
 
 	retval = ksmbd_krb5_authenticate(sess, in_blob, in_len,
 					 out_blob, &amp;out_len);
-- 
2.43.0
</pre></div>


<p>When I read o3’s bug report above I realised this was insufficient. The logoff handler <em>already</em> sets <code>sess-&gt;user = NULL</code>, but is still vulnerable as the SMB protocol allows two different connections to “bind” to the same session and there is nothing on the kerberos authentication path to prevent another thread making use of <code>sess-&gt;user</code> in the short window after it has been freed and before it has been set to NULL. I had already made use of this property to hit a prior vulnerability in ksmbd but I didn’t think of it when considering the kerberos authentication vulnerability.</p>



<p>Having realised this, I went again through o3’s results from searching for the kerberos authentication vulnerability and noticed that in some of its reports it had made the same error as me, in others it had not, and it had realised that setting <code>sess-&gt;user = NULL</code> was insufficient to fix the issue due to the possibilities offered by session binding. That is quite cool as it means that had I used o3 to find and fix the original vulnerability I would have, in theory, done a better job than without it. I say ‘in theory’ because right now the false positive to true positive ratio is probably too high to definitely say I would have gone through each report from o3 with the diligence required to spot its solution. Still, that ratio is only going to get better. </p>



<h2>Conclusion</h2>



<p>LLMs exist at a point in the capability space of program analysis techniques that is far closer to humans than anything else we have seen. Considering the attributes of creativity, flexibility, and generality, LLMs are far more similar to a human code auditor than they are to symbolic execution, abstract interpretation or fuzzing. Since GPT-4 there has been hints of the potential for LLMs in vulnerability research, but the results on real problems have never quite lived up to the hope or the hype. That has changed with o3, and we have a model that can do well enough at code reasoning, Q&amp;A, programming and problem solving that it can genuinely enhance human performance at vulnerability research. </p>



<p>o3 is not infallible. Far from it. There’s still a substantial chance it will generate nonsensical results and frustrate you. What is different, is that for the first time the chance of getting correct results is sufficiently high that it is worth your time and and your effort to try to use it on real problems.  </p>




					</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-## -->

				<!-- .navigation -->
	
			
<!-- #comments -->

		
		</main><!-- #main -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Rotary Phone Dial Linux Kernel Driver (283 pts)]]></title>
            <link>https://gitlab.com/sephalon/rotary_dial_kmod</link>
            <guid>44080803</guid>
            <pubDate>Sat, 24 May 2025 13:02:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gitlab.com/sephalon/rotary_dial_kmod">https://gitlab.com/sephalon/rotary_dial_kmod</a>, See on <a href="https://news.ycombinator.com/item?id=44080803">Hacker News</a></p>
<div id="readability-page-1" class="page">





<header data-testid="navbar">
<a href="#content-body">Skip to content</a>
<div>
<nav aria-label="Explore GitLab">
<div>
<span>GitLab</span>
<a title="Homepage" id="logo" aria-label="Homepage" data-track-label="main_navigation" data-track-action="click_gitlab_logo_link" data-track-property="navigation_top" href="https://gitlab.com/"><svg aria-hidden="true" role="img" width="25" height="24" viewBox="0 0 25 24" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path d="m24.507 9.5-.034-.09L21.082.562a.896.896 0 0 0-1.694.091l-2.29 7.01H7.825L5.535.653a.898.898 0 0 0-1.694-.09L.451 9.411.416 9.5a6.297 6.297 0 0 0 2.09 7.278l.012.01.03.022 5.16 3.867 2.56 1.935 1.554 1.176a1.051 1.051 0 0 0 1.268 0l1.555-1.176 2.56-1.935 5.197-3.89.014-.01A6.297 6.297 0 0 0 24.507 9.5Z" fill="#E24329"></path>
  <path d="m24.507 9.5-.034-.09a11.44 11.44 0 0 0-4.56 2.051l-7.447 5.632 4.742 3.584 5.197-3.89.014-.01A6.297 6.297 0 0 0 24.507 9.5Z" fill="#FC6D26"></path>
  <path d="m7.707 20.677 2.56 1.935 1.555 1.176a1.051 1.051 0 0 0 1.268 0l1.555-1.176 2.56-1.935-4.743-3.584-4.755 3.584Z" fill="#FCA326"></path>
  <path d="M5.01 11.461a11.43 11.43 0 0 0-4.56-2.05L.416 9.5a6.297 6.297 0 0 0 2.09 7.278l.012.01.03.022 5.16 3.867 4.745-3.584-7.444-5.632Z" fill="#FC6D26"></path>
</svg>

</a></div>
<ul>
<li>

<div>
<ul>
<li>
<a href="https://about.gitlab.com/why-gitlab">Why GitLab
</a></li>
<li>
<a href="https://about.gitlab.com/pricing">Pricing
</a></li>
<li>
<a href="https://about.gitlab.com/sales">Contact Sales
</a></li>
<li>
<a href="https://gitlab.com/explore">Explore</a>
</li>
</ul>
</div>
</li>
<li>
<a href="https://about.gitlab.com/why-gitlab">Why GitLab
</a></li>
<li>
<a href="https://about.gitlab.com/pricing">Pricing
</a></li>
<li>
<a href="https://about.gitlab.com/sales">Contact Sales
</a></li>
<li>
<a href="https://gitlab.com/explore">Explore</a>
</li>
</ul>
<ul>
<li>
<a href="https://gitlab.com/users/sign_in?redirect_to_referer=yes">Sign in</a>
</li>
<li>
<a href="https://gitlab.com/users/sign_up"><span>
Get free trial

</span>

</a></li>
</ul>
</nav>
</div>
</header>

<div>


<div data-testid="top-bar">
<div data-testid="breadcrumb-links" id="js-vue-page-breadcrumbs-wrapper">


</div>
<div>





</div>
</div>

<div>
<main id="content-body" itemscope="" itemtype="http://schema.org/SoftwareSourceCode">











<header>
<div>
<div>
<div alt="rotary_dial_kmod" itemprop="image">
R
</div>

<h2 data-testid="project-name-content" itemprop="name">
rotary_dial_kmod


</h2>
</div>

</div>

</header>


<div>

<div data-blame-per-page="1000" id="tree-holder">

<div role="status" data-history-link="/sephalon/rotary_dial_kmod/-/commits/master" data-ref-type="heads" id="js-last-commit"><span aria-hidden=""></span><span>Loading</span>
</div>

</div>
</div>

</main>
</div>


</div>








</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hong Kong's Famous Bamboo Scaffolding Hangs on (For Now) (154 pts)]]></title>
            <link>https://www.nytimes.com/2025/05/24/world/asia/hongkong-bamboo-scaffolding.html</link>
            <guid>44080549</guid>
            <pubDate>Sat, 24 May 2025 12:08:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2025/05/24/world/asia/hongkong-bamboo-scaffolding.html">https://www.nytimes.com/2025/05/24/world/asia/hongkong-bamboo-scaffolding.html</a>, See on <a href="https://news.ycombinator.com/item?id=44080549">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2025/05/24/world/asia/hongkong-bamboo-scaffolding.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The Xenon Death Flash: How a Camera Nearly Killed the Raspberry Pi 2 (179 pts)]]></title>
            <link>https://magnus919.com/2025/05/the-xenon-death-flash-how-a-camera-nearly-killed-the-raspberry-pi-2/</link>
            <guid>44080533</guid>
            <pubDate>Sat, 24 May 2025 12:06:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://magnus919.com/2025/05/the-xenon-death-flash-how-a-camera-nearly-killed-the-raspberry-pi-2/">https://magnus919.com/2025/05/the-xenon-death-flash-how-a-camera-nearly-killed-the-raspberry-pi-2/</a>, See on <a href="https://news.ycombinator.com/item?id=44080533">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I’ve seen plenty of weird computer bugs in my time, but nothing quite like what Peter Onion discovered in February 2015. He was proudly photographing his brand new Raspberry Pi 2 when something bizarre happened—every time his camera flash went off, his Pi instantly powered down.</p><p>At first, Peter thought it was just a coincidence. But after it happened three times in a row, he realized he’d stumbled onto something unprecedented. <a href="https://www.raspberrypi.com/news/xenon-death-flash-a-free-physics-lesson/">His post to the Raspberry Pi forums</a> with the innocent title “Why is the PI2 camera-shy?” would soon reveal one of the strangest hardware vulnerabilities in modern computing history.</p><p>Peter Onion wasn’t just any user—he was a veteran of the Raspberry Pi community and a regular at Raspberry Jams in Cambridge and Bletchley. When he reported that <a href="https://forums.theregister.com/forum/all/2015/02/08/raspberry_pi_2_camera_flash_glitch/">taking flash photos caused his Pi 2 to crash</a>, the community took notice.</p><p>What happened next was like watching a crowd-sourced CSI episode unfold in real time. Forum users immediately began experimenting with different cameras and light sources. User “jdb” made a crucial discovery: his Samsung Note2 with LED flash caused no problems, but his Samsung K Zoom with a xenon flash reliably crashed the Pi 2.</p><p>This distinction between LED and xenon technology became the first major clue. The community had found their smoking gun—but they still needed to figure out why.</p><h2 id="the-hunt-for-the-vulnerable-component">The Hunt for the Vulnerable Component</h2><p>The real detective work began when users started systematically testing which part of the Pi 2 was actually vulnerable. The initial assumption was that the main processor chip might be the culprit, but covering it with a blob of Blu-Tack (yes, really) didn’t solve the problem.</p><p>Then someone tried flipping the Pi upside down. Suddenly, it was immune to flash photography. This proved the vulnerability was purely optical—light had to physically reach a specific component on the board.</p><p>Through methodical testing, <a href="https://redrobe.com/mike/?p=607">the community isolated the problem to the U16 chip</a>—a small power supply regulator located between the USB connector and HDMI port. When they covered just this tiny component with Blu-Tack, the crashes stopped completely.</p><p>But what made this particular chip so sensitive to light?</p><h2 id="the-physics-behind-the-xenon-death-flash">The Physics Behind the “Xenon Death Flash”</h2><p>The answer lay in modern semiconductor packaging. The U16 chip used something called Wafer-Level Chip Scale Packaging (WL-CSP), which is exactly what it sounds like—<a href="https://resources.pcb.cadence.com/blog/jbj-wafer-level-chip-scale-packaging-what-is-that">a bare silicon die with solder balls attached directly to the circuit board</a>. Unlike traditional chips that are fully encapsulated in opaque plastic, WL-CSP chips prioritize miniaturization over protection.</p><p>This exposed silicon became the Pi 2’s Achilles’ heel. When hit by high-intensity light, the photoelectric effect kicked in—the same phenomenon Einstein won a Nobel Prize for explaining. <a href="https://www.raspberrypi.com/news/xenon-death-flash-a-free-physics-lesson/">High-energy photons striking the semiconductor created unexpected electron flows</a>, disrupting the voltage regulation circuitry and causing an immediate shutdown.</p><p>The intensity threshold was crucial. Regular LED camera flashes didn’t produce enough photons, but xenon flashes and laser pointers packed sufficient punch to trigger the malfunction. Even more interesting, the effect required silicon’s specific bandgap energy—meaning infrared and visible light could potentially cause problems, but only at extreme intensities.</p><h2 id="this-wasnt-actually-unprecedented">This Wasn’t Actually Unprecedented</h2><p>While the Raspberry Pi incident captured headlines, similar optical interference problems had been lurking in the semiconductor industry for years. <a href="https://www.edn.com/xenon-death-flash-for-the-raspberry-pi-2/">An engineer at EDN Network revealed</a> that his company had encountered the exact same issue twelve years earlier with a CSP amplifier for a cell phone prototype. The phone’s own camera flash would cause the amplifier to spike when light penetrated the chip packaging.</p><p>Even more dramatic was a 1997 incident at the Haddam Neck nuclear plant in Connecticut. <a href="https://allthingsnuclear.org/dlochbaum/remote-control-at-nuclear-power-plants/">A training department member took a flash photograph of a fire detection panel</a>, and the camera flash tricked an EPROM chip into thinking there was a fire. Within seconds, the Halon fire suppression system activated, forcing operators to abandon the control room for 35 minutes while the gas cleared.</p><p>These incidents revealed a broader truth: as semiconductors became smaller and more exposed, they also became more vulnerable to optical interference that traditional testing never considered.</p><h2 id="the-fixes-from-blu-tack-to-better-design">The Fixes: From Blu-Tack to Better Design</h2><p>The immediate solution was charmingly low-tech. The Raspberry Pi Foundation recommended covering the U16 chip with opaque materials—<a href="https://www.theregister.com/2015/02/08/raspberry_pi_2_camera_flash_glitch/">Blu-Tack, electrical tape, or even putty</a> would do the trick. This worked because it blocked light from reaching the sensitive semiconductor while maintaining normal electrical operation.</p><p>But the real fix came with hardware revision 1.2 of the Pi 2, released later in 2015. Instead of just adding optical shielding, the Foundation implemented a completely different power management architecture using the BCM2837 system-on-chip (the same processor later used in the Pi 3). This eliminated the optical sensitivity entirely through better circuit design rather than band-aid solutions.</p><p>Testing confirmed that earlier Raspberry Pi models (A, B, A+, B+) had never been vulnerable to the “xenon death flash” effect, making this a uniquely Generation 2 problem that was both discovered and solved by the community.</p><h2 id="what-this-revealed-about-modern-electronics">What This Revealed About Modern Electronics</h2><p>The Raspberry Pi 2 vulnerability highlighted a fundamental tension in modern electronics design. The relentless push toward smaller, cheaper components had introduced failure modes that traditional testing methodologies simply didn’t consider. <a href="https://www.syncfusion.com/blogs/post/there-will-be-bugs">Standard electromagnetic compatibility testing covers radio interference</a>, but who thinks to test whether taking a photo will crash your computer?</p><p>The incident also demonstrated the hidden risks of chip-scale packaging. While WL-CSP technology enables the tiny, powerful devices we rely on today, <a href="https://en.wikipedia.org/wiki/Wafer-level_packaging">it essentially puts bare silicon dies directly onto circuit boards</a> with minimal protection. Cost and size benefits come at the expense of environmental robustness.</p><p>Most importantly, it showed how unconventional use cases could reveal vulnerabilities that lab testing missed. The specific combination of circumstances—a xenon flash camera pointed at an exposed power regulation chip—fell completely outside typical validation scenarios.</p><h2 id="the-legacy-of-an-adorable-bug">The Legacy of an “Adorable Bug”</h2><p>The Raspberry Pi Foundation handled the incident with remarkable transparency, <a href="https://www.raspberrypi.com/news/xenon-death-flash-a-free-physics-lesson/">calling it “the most adorable bug we’ve ever come across”</a> and turning it into a physics lesson about the photoelectric effect. This open approach contrasted sharply with typical corporate responses to hardware flaws and helped maintain community trust.</p><p>The vulnerability became a teaching tool in electronics courses, providing a tangible example of how fundamental physics principles affect real-world technology. Students could literally see the photoelectric effect in action by watching a computer crash when photographed.</p><p>More broadly, the incident contributed to increased industry awareness about optical interference in semiconductor design. While such specific vulnerabilities remain rare, the Pi 2 case demonstrated why comprehensive testing needs to consider increasingly unconventional attack vectors.</p><h2 id="lessons-for-todays-connected-world">Lessons for Today’s Connected World</h2><p>The Xenon Death Flash story feels almost quaint now—a simpler time when the biggest worry was whether taking a photo might crash your hobby computer. But it foreshadowed bigger concerns about hardware security and the unintended consequences of aggressive miniaturization.</p><p>Today’s devices pack even more functionality into even smaller packages, often using advanced packaging technologies that prioritize performance over protection. The Internet of Things has put embedded systems into every corner of our lives, many using similar cost-optimized designs that might harbor their own unexpected vulnerabilities.</p><p>The Pi 2 incident reminds us that the most interesting bugs often come from the intersection of unrelated technologies—in this case, photography and power regulation circuits. As our devices become more interconnected and our technology stack more complex, we should expect more such surprises.</p><p>The good news? When weird bugs do surface, communities like the Raspberry Pi forum show that collective problem-solving can be remarkably effective. Sometimes all it takes is enough people willing to stick Blu-Tack on circuit boards and see what happens.</p><p>And that’s probably the most important lesson of all: in a world of increasingly complex technology, a little curiosity and community collaboration can solve even the strangest problems.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DumPy: NumPy except it's OK if you're dum (136 pts)]]></title>
            <link>https://dynomight.net/dumpy/</link>
            <guid>44080181</guid>
            <pubDate>Sat, 24 May 2025 10:49:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dynomight.net/dumpy/">https://dynomight.net/dumpy/</a>, See on <a href="https://news.ycombinator.com/item?id=44080181">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
    
  <section>
    <p>What I want from an array language is:</p>

<ol>
  <li>Don’t make me think.</li>
  <li>Run fast on GPUs.</li>
  <li>Really, do not make me think.</li>
  <li>Do <em>not</em>.</li>
</ol>

<p>I say NumPy misses on three of these. So I’d like to propose a “fix” that—I claim—eliminates 90% of unnecessary thinking, with no loss of power. It would also fix all the things based on NumPy, for example every machine learning library.</p>

<p>I know that sounds grandiose. Quite possibly you’re thinking that good-old dynomight has finally lost it. So I warn you now: My solution is utterly non-clever. If anything is clever here, it’s my single-minded rejection of cleverness.</p>

<p>To motivate the fix, let me give my story for how NumPy went wrong. It started as a nice little library for array operations and linear algebra. When everything has two or fewer dimensions, it’s great. But at some point, someone showed up with some higher-dimensional arrays. If loops were fast in Python, NumPy would have said, “Hello person with ≥3 dimensions, please call my ≤2 dimensional functions in a loop so I can stay nice and simple, xox, NumPy.”</p>

<p>But since loops are slow, NumPy instead took all the complexity that would <em>usually</em> be addressed with loops and pushed it down into individual functions. I think this was a disaster, because <em>every time</em> you see some function call like <code>np.func(A,B)</code>, you have to think:</p>

<ol>
  <li>OK, what shapes do all those arrays have?</li>
  <li>And what does <code>np.func</code> do when it sees those shapes?</li>
</ol>

<p>Different functions have different rules. Sometimes they’re bewildering. This means constantly thinking and constantly moving dimensions around to appease the whims of particular functions. It’s the <em>functions</em> that should be appeasing <em>your</em> whims!</p>

<p>Even simple-looking things like <code>A*B</code> or <code>A[B,C]</code> do quite different things depending on the starting shapes. And those starting shapes are often themselves the output of <em>previous</em> functions, so the complexity spirals.</p>

<p>Worst of all, if you write a new ≤2 dimensional function, then high-dimensional arrays are your problem. <em>You</em> need to decide what rules to obey, and then <em>you</em> need to re-write your function in a much more complex way to—</p>

<p><strong>Voice from the back</strong>: Python sucks! If you used a real language, loops would be fast! This problem is stupid!</p>

<p>That was a strong argument, ten years ago. But now everything is GPU, and GPUs hate loops. Today, array packages are cheerful interfaces that <em>look</em> like Python (or whatever) but are actually embedded languages that secretly compile everything into special GPU instructions that run on whole arrays in parallel. With big arrays, you need GPUs. So I think the speed of the host language doesn’t matter so much anymore.</p>

<p>Python’s slowness may have paradoxically turned out to be an <em>advantage</em>, since it forced everything to be designed to work without loops even before GPUs took over.</p>

<p>Still, thinking is bad, and NumPy makes me think, so <a href="https://dynomight.net/numpy/">I don’t like NumPy</a>.</p>

<h2 id="so-whats-the-fix">So what’s the fix?</h2>

<p>Here’s my extremely non-clever idea: Let’s just admit that loops were better. In high dimensions, no one has yet come up with a notation that beats loops and indices. So, let’s do this:</p>

<ol>
  <li>Bring back the syntax of loops and indices.</li>
  <li>But don’t actually <em>execute</em> the loops. Just take the syntax and secretly compile it into vectorized operations.</li>
  <li>Also, let’s get rid of all the insanity that’s been added to NumPy because loops were slow.</li>
</ol>

<p>That’s basically the whole idea. If you take those three bullet-points, you could probably re-derive everything I do below. I told you this wasn’t clever.</p>

<h2 id="what-does-it-look-like">What does it look like?</h2>

<p>Suppose that <code>X</code> and <code>Y</code> are 2D arrays, and <code>A</code> is a 4D array. And suppose you want to find a 2D array <code>Z</code> such that <code>Z<sub>ij</sub> = (Y<sub>j</sub>)<sup>T</sup> (A<sub>ij</sub>)<sup>-1</sup> X<sub>i</sub></code>. If you could write loops, this would be easy:</p>

<div><pre><code><span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>Z</span> <span>=</span> <span>np</span><span>.</span><span>empty</span><span>((</span><span>X</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>],</span> <span>Y</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]))</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>X</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]):</span>
    <span>for</span> <span>j</span> <span>in</span> <span>range</span><span>(</span><span>Y</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]):</span>
        <span>Z</span><span>[</span><span>i</span><span>,</span><span>j</span><span>]</span> <span>=</span> <span>Y</span><span>[</span><span>j</span><span>]</span> <span>@</span> <span>np</span><span>.</span><span>linalg</span><span>.</span><span>solve</span><span>(</span><span>A</span><span>[</span><span>i</span><span>,</span><span>j</span><span>],</span> <span>X</span><span>[</span><span>i</span><span>])</span>
</code></pre></div>

<p>That’s not pretty. It’s not short or fast. But it <em>is</em> easy!</p>

<p>Meanwhile, how do you do this efficiently in NumPy? Like this:</p>

<div><pre><code><span>AiX</span> <span>=</span> <span>np</span><span>.</span><span>linalg</span><span>.</span><span>solve</span><span>(</span><span>A</span><span>.</span><span>transpose</span><span>(</span><span>1</span><span>,</span><span>0</span><span>,</span><span>2</span><span>,</span><span>3</span><span>),</span>
                      <span>X</span><span>[</span><span>None</span><span>,...,</span><span>None</span><span>])[...,</span><span>0</span><span>]</span>
<span>Z</span> <span>=</span> <span>np</span><span>.</span><span>sum</span><span>(</span><span>AiX</span> <span>*</span> <span>Y</span><span>[:,</span><span>None</span><span>],</span> <span>axis</span><span>=-</span><span>1</span><span>).</span><span>T</span>
</code></pre></div>

<p>If you’re not a NumPy otaku, that may look like outsider art. Rest assured, it looks like that to me too, and I just wrote it. Why is it so confusing? At a high level, it’s because <code>np.linalg.solve</code> and <code>np.sum</code> and multiplication (<code>*</code>) have complicated rules and weren’t designed to work together to solve this particular problem nicely. That would be impossible, because there are an infinite number of problems. So you need to mash the arrays around a lot to make those functions happy.</p>

<p>Without further ado, here’s how you solve this problem with <strong>DumPy</strong> (ostensibly <strong>D</strong>ynomight N<strong>umPy</strong>):</p>

<div><pre><code><span>import</span> <span>dumpy</span> <span>as</span> <span>dp</span>
<span>A</span> <span>=</span> <span>dp</span><span>.</span><span>Array</span><span>(</span><span>A</span><span>)</span>
<span>X</span> <span>=</span> <span>dp</span><span>.</span><span>Array</span><span>(</span><span>X</span><span>)</span>
<span>Y</span> <span>=</span> <span>dp</span><span>.</span><span>Array</span><span>(</span><span>Y</span><span>)</span>
<span>Z</span> <span>=</span> <span>dp</span><span>.</span><span>Slot</span><span>()</span>
<span>Z</span><span>[</span><span>'i'</span><span>,</span><span>'j'</span><span>]</span> <span>=</span> <span>Y</span><span>[</span><span>'j'</span><span>,:]</span> <span>@</span> <span>dp</span><span>.</span><span>linalg</span><span>.</span><span>solve</span><span>(</span><span>A</span><span>[</span><span>'i'</span><span>,</span><span>'j'</span><span>,:,:],</span> <span>X</span><span>[</span><span>'i'</span><span>,:])</span>
</code></pre></div>

<p>Yes! If you prefer, you can also use this equivalent syntax:</p>

<div><pre><code><span>Z</span> <span>=</span> <span>dp</span><span>.</span><span>Slot</span><span>()</span>
<span>with</span> <span>dp</span><span>.</span><span>Range</span><span>(</span><span>X</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>])</span> <span>as</span> <span>i</span><span>:</span>
    <span>with</span> <span>dp</span><span>.</span><span>Range</span><span>(</span><span>Y</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>])</span> <span>as</span> <span>j</span><span>:</span>
        <span>Z</span><span>[</span><span>i</span><span>,</span><span>j</span><span>]</span> <span>=</span> <span>Y</span><span>[</span><span>j</span><span>,:]</span> <span>@</span> <span>dp</span><span>.</span><span>linalg</span><span>.</span><span>solve</span><span>(</span><span>A</span><span>[</span><span>i</span><span>,</span><span>j</span><span>,:,:],</span> <span>X</span><span>[</span><span>i</span><span>,:])</span>
</code></pre></div>

<p>Those are both fully vectorized. No loops are executed behind the scenes. They’ll run on a GPU if you have one.</p>

<h2 id="but-how">But how?</h2>

<p>While it looks magical, the way this actually works is fairly simple:</p>

<ol>
  <li>
    <p>If you index a DumPy array with a string (or a <code>dp.Range</code> object), it creates a special “mapped” array that pretends to have fewer dimensions.</p>
  </li>
  <li>
    <p>When a DumPy function is called (e.g. <code>dp.linalg.solve</code> or <code>dp.matmul</code> (called with <code>@</code>)), it checks if any of the arguments have mapped dimensions. If so, it automatically vectorizes the computation, matching up mapped dimensions that share labels.</p>
  </li>
  <li>
    <p>When you assign an array with “mapped” dimensions to a <code>dp.Slot</code>, it “unmaps” them into the positions you specify.</p>
  </li>
</ol>

<p>No evil meta-programming abstract syntax tree macro bytecode interception is needed. When you run this code:</p>

<div><pre><code><span>Z</span> <span>=</span> <span>dp</span><span>.</span><span>Slot</span><span>()</span>
<span>Z</span><span>[</span><span>'i'</span><span>,</span><span>'j'</span><span>]</span> <span>=</span> <span>Y</span><span>[</span><span>'j'</span><span>,:]</span> <span>@</span> <span>dp</span><span>.</span><span>linalg</span><span>.</span><span>solve</span><span>(</span><span>A</span><span>[</span><span>'i'</span><span>,</span><span>'j'</span><span>,:,:],</span> <span>X</span><span>[</span><span>'i'</span><span>,:])</span>
</code></pre></div>

<p>This is what happens behind the scenes:</p>

<div><pre><code><span>a</span> <span>=</span> <span>A</span><span>.</span><span>map_axes</span><span>([</span><span>0</span><span>,</span> <span>1</span><span>],</span> <span>[</span><span>'i'</span><span>,</span> <span>'j'</span><span>])</span>
<span>x</span> <span>=</span> <span>X</span><span>.</span><span>map_axes</span><span>([</span><span>0</span><span>],</span> <span>[</span><span>'i'</span><span>])</span>
<span>y</span> <span>=</span> <span>Y</span><span>.</span><span>map_axes</span><span>([</span><span>0</span><span>],</span> <span>[</span><span>'j'</span><span>])</span>
<span>z</span> <span>=</span> <span>y</span> <span>@</span> <span>dp</span><span>.</span><span>linalg</span><span>.</span><span>solve</span><span>(</span><span>a</span><span>,</span> <span>x</span><span>)</span>
<span>Z</span> <span>=</span> <span>z</span><span>.</span><span>unmap</span><span>(</span><span>'i'</span><span>,</span><span>'j'</span><span>)</span>
</code></pre></div>

<details>
  <summary>
(Click here for a version with a million asserts and comments.)
</summary>

  <div><pre><code><span># first map A
</span><span>a</span> <span>=</span> <span>A</span><span>.</span><span>map_axes</span><span>([</span><span>0</span><span>,</span> <span>1</span><span>],</span> <span>[</span><span>'i'</span><span>,</span> <span>'j'</span><span>])</span>
<span>assert</span> <span>A</span><span>.</span><span>ndim</span> <span>==</span> <span>4</span>
<span>assert</span> <span>a</span><span>.</span><span>ndim</span> <span>==</span> <span>2</span>             <span># pretends to have fewer dims
</span><span>assert</span> <span>a</span><span>.</span><span>data</span><span>.</span><span>shape</span> <span>==</span> <span>A</span><span>.</span><span>shape</span>          <span># secret mapped data
</span><span>assert</span> <span>a</span><span>.</span><span>axes</span> <span>==</span> <span>(</span><span>'i'</span><span>,</span> <span>'j'</span><span>,</span> <span>None</span><span>,</span> <span>None</span><span>)</span> <span># secret mapped axes
</span><span>assert</span> <span>a</span><span>.</span><span>shape</span> <span>==</span> <span>(</span><span>a</span><span>.</span><span>data</span><span>.</span><span>shape</span><span>[</span><span>2</span><span>],</span> <span>a</span><span>.</span><span>data</span><span>.</span><span>shape</span><span>[</span><span>3</span><span>])</span>
                <span># shape determined by non-mapped (None) axes
</span>
<span># now map X
</span><span>x</span> <span>=</span> <span>X</span><span>.</span><span>map_axes</span><span>([</span><span>0</span><span>],</span> <span>[</span><span>'i'</span><span>])</span>
<span>assert</span> <span>X</span><span>.</span><span>ndim</span> <span>==</span> <span>2</span>
<span>assert</span> <span>x</span><span>.</span><span>ndim</span> <span>==</span> <span>1</span>
<span>assert</span> <span>x</span><span>.</span><span>data</span><span>.</span><span>shape</span> <span>==</span> <span>X</span><span>.</span><span>shape</span>
<span>assert</span> <span>x</span><span>.</span><span>axes</span> <span>==</span> <span>(</span><span>'i'</span><span>,</span> <span>None</span><span>)</span>
<span>assert</span> <span>x</span><span>.</span><span>shape</span> <span>==</span> <span>(</span><span>x</span><span>.</span><span>data</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>],</span> <span>)</span>

<span># now map Y
</span><span>y</span> <span>=</span> <span>Y</span><span>.</span><span>map_axes</span><span>([</span><span>0</span><span>],</span> <span>[</span><span>'j'</span><span>])</span>
<span>assert</span> <span>Y</span><span>.</span><span>ndim</span> <span>==</span> <span>2</span>
<span>assert</span> <span>y</span><span>.</span><span>ndim</span> <span>==</span> <span>1</span>
<span>assert</span> <span>y</span><span>.</span><span>shape</span> <span>==</span> <span>(</span><span>Y</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>],)</span>
<span>assert</span> <span>y</span><span>.</span><span>axes</span> <span>==</span> <span>(</span><span>'j'</span><span>,</span> <span>None</span><span>)</span>
<span>assert</span> <span>y</span><span>.</span><span>data</span><span>.</span><span>shape</span> <span>==</span> <span>Y</span><span>.</span><span>shape</span>
<span>assert</span> <span>y</span><span>.</span><span>shape</span> <span>==</span> <span>(</span><span>y</span><span>.</span><span>data</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>],)</span>

<span># Actually do the computation. It happens that the 'j'
# dimension is stored first because its found first (in y).
# But you never need to think about that!
</span><span>z</span> <span>=</span> <span>y</span> <span>@</span> <span>dp</span><span>.</span><span>linalg</span><span>.</span><span>solve</span><span>(</span><span>a</span><span>,</span> <span>x</span><span>)</span>
<span>assert</span> <span>z</span><span>.</span><span>ndim</span> <span>==</span> <span>0</span>
<span>assert</span> <span>z</span><span>.</span><span>shape</span> <span>==</span> <span>()</span>
<span>assert</span> <span>z</span><span>.</span><span>axes</span> <span>==</span> <span>(</span><span>'j'</span><span>,</span><span>'i'</span><span>)</span>
<span>assert</span> <span>z</span><span>.</span><span>data</span><span>.</span><span>shape</span> <span>==</span> <span>(</span><span>Y</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>],</span> <span>X</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>])</span>

<span># unmap the mapped axes
</span><span>Z</span> <span>=</span> <span>z</span><span>.</span><span>unmap</span><span>(</span><span>'i'</span><span>,</span><span>'j'</span><span>)</span>
<span>assert</span> <span>Z</span><span>.</span><span>ndim</span> <span>==</span> <span>2</span>
<span>assert</span> <span>Z</span><span>.</span><span>shape</span> <span>==</span> <span>(</span><span>X</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>],</span> <span>Y</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>])</span>
</code></pre></div>

</details>

<h2 id="wait-but-how">Wait, but <em>how</em>?</h2>

<p>It might seem like I’ve skipped the hard part. How does <code>dp.linalg.solve</code> know how to vectorize over any combination of input dimensions? Don’t I need to do that for every single function that DumPy includes? Isn’t that hard?</p>

<p>It <em>is</em> hard, but <a href="https://docs.jax.dev/en/latest/_autosummary/jax.vmap.html"><code>jax.vmap</code></a> did it already. This takes a function defined using (<a href="https://github.com/jax-ml/jax">JAX</a>’s version of) NumPy and vectorizes it over <em>any</em> set of input dimensions. DumPy relies on this to do all the actual vectorization. (If you prefer your <code>vmap</code> janky and broken, I heartily recommend PyTorch’s <a href="https://docs.pytorch.org/docs/stable/generated/torch.vmap.html"><code>torch.vmap</code></a>.)</p>

<p>But hold on. If <code>vmap</code> already exists, then why do we need DumPy? Here’s why:</p>

<div><pre><code><span>import</span> <span>jax</span>
<span>from</span> <span>jax</span> <span>import</span> <span>numpy</span> <span>as</span> <span>jnp</span>
<span>Z</span> <span>=</span> <span>jax</span><span>.</span><span>vmap</span><span>(</span>
        <span>jax</span><span>.</span><span>vmap</span><span>(</span>
            <span>lambda</span> <span>x</span><span>,</span> <span>y</span><span>,</span> <span>a</span><span>:</span> <span>y</span> <span>@</span> <span>jnp</span><span>.</span><span>linalg</span><span>.</span><span>solve</span><span>(</span><span>a</span><span>,</span> <span>x</span><span>),</span>
            <span>in_axes</span><span>=</span><span>[</span><span>None</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]</span>
        <span>),</span>
        <span>in_axes</span><span>=</span><span>[</span><span>0</span><span>,</span> <span>None</span><span>,</span> <span>0</span><span>]</span>
    <span>)(</span><span>X</span><span>,</span> <span>Y</span><span>,</span> <span>A</span><span>)</span>
</code></pre></div>

<p>That’s how you solve the same problem with <code>vmap</code>. (It’s also basically what DumPy does behind the scenes.)</p>

<p>I think <code>vmap</code> is one of the best parts of the NumPy ecosystem. I think the above code is genuinely better than the base NumPy version. But it still involves a lot of thinking! Why put <code>in_axes=[None, 0, 0]</code> in the inner <code>vmap</code> and <code>in_axes=[0, None, 0]</code> in the outer one? Why are all the axes <code>0</code> even though you need to vectorize over the second dimension of <code>A</code>? There are answers, but they require thinking. Loops and indices are better.</p>

<h2 id="a-tiny-bit-of-cleverness">A tiny bit of cleverness</h2>

<p>OK, I did do one thing that’s a <em>little</em> clever. Say you want to create a <a href="https://en.wikipedia.org/wiki/Hilbert_matrix">Hilbert matrix</a> with <code>H<sub>ij</sub> = 1/(1+i+j)</code>. In base NumPy you’d have to do this:</p>

<div><pre><code><span>X</span> <span>=</span> <span>1</span> <span>/</span> <span>(</span><span>1</span> <span>+</span> <span>np</span><span>.</span><span>arange</span><span>(</span><span>5</span><span>)[:,</span><span>None</span><span>]</span> <span>+</span> <span>np</span><span>.</span><span>arange</span><span>(</span><span>5</span><span>)[</span><span>None</span><span>,:])</span> <span># hurr?
</span></code></pre></div>

<p>In DumPy, you can just write:</p>

<div><pre><code><span>X</span> <span>=</span> <span>dp</span><span>.</span><span>Slot</span><span>()</span>
<span>with</span> <span>dp</span><span>.</span><span>Range</span><span>(</span><span>5</span><span>)</span> <span>as</span> <span>i</span><span>:</span>
    <span>with</span> <span>dp</span><span>.</span><span>Range</span><span>(</span><span>5</span><span>)</span> <span>as</span> <span>j</span><span>:</span>
        <span>X</span><span>[</span><span>i</span><span>,</span><span>j</span><span>]</span> <span>=</span> <span>1</span> <span>/</span> <span>(</span><span>i</span> <span>+</span> <span>j</span> <span>+</span> <span>1</span><span>)</span>
</code></pre></div>

<p>Yes! That works! It works because a <code>dp.Range</code> acts <em>both</em> like a string and like an array mapped along that string. So the above code is roughly equivalent to:</p>

<div><pre><code><span>I</span> <span>=</span> <span>dp</span><span>.</span><span>Array</span><span>([</span><span>0</span><span>,</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>,</span><span>4</span><span>])</span>
<span>J</span> <span>=</span> <span>dp</span><span>.</span><span>Array</span><span>([</span><span>0</span><span>,</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>,</span><span>4</span><span>])</span>
<span>X</span> <span>=</span> <span>dp</span><span>.</span><span>Slot</span><span>()</span>
<span>X</span><span>[</span><span>'i'</span><span>,</span><span>'j'</span><span>]</span> <span>=</span> <span>1</span> <span>/</span> <span>(</span><span>1</span> <span>+</span> <span>I</span><span>[</span><span>'i'</span><span>]</span> <span>+</span> <span>J</span><span>[</span><span>'j'</span><span>])</span>
</code></pre></div>

<details>
  <summary>See? Still no magic.</summary>

  <p>In reality, the <code>dp.Range</code> choose random strings. (The class maintains a stack of active ranges to prevent collisions.) So in more detail, the above code becomes something like this:</p>

  <div><pre><code><span>I</span> <span>=</span> <span>dp</span><span>.</span><span>Array</span><span>([</span><span>0</span><span>,</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>,</span><span>4</span><span>])</span>
<span>J</span> <span>=</span> <span>dp</span><span>.</span><span>Array</span><span>([</span><span>0</span><span>,</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>,</span><span>4</span><span>])</span>
<span>i</span> <span>=</span> <span>I</span><span>.</span><span>map_axes</span><span>([</span><span>0</span><span>],</span><span>'range_EZaW'</span><span>)</span>
<span>j</span> <span>=</span> <span>J</span><span>.</span><span>map_axes</span><span>([</span><span>0</span><span>],</span><span>'range_ailw'</span><span>)</span>
<span>x</span> <span>=</span> <span>1</span> <span>/</span> <span>(</span><span>1</span> <span>+</span> <span>i</span> <span>+</span> <span>j</span><span>)</span> <span># vectorized
</span><span>X</span> <span>=</span> <span>x</span><span>.</span><span>unmap</span><span>(</span><span>'range_EZaW'</span><span>,</span><span>'range_ailw'</span><span>)</span>
</code></pre></div>
</details>

<h2 id="ok-but-is-it-actually-better">OK but is it actually better?</h2>

<p>To test if DumPy is actually better in practice, I took six problems of increasing complexity and implemented each of them using loops, Numpy, JAX (with <code>vmap</code>), and DumPy.</p>

<details>
  

  <p>Note that in these examples, I always assume the input arrays are in the class of the system being used. If you try running them, you’ll need to add some conversions with <code>np.array</code> / <code>jnp.array</code> / <code>dp.Array</code>.</p>

  <div><pre><code><span># loops
</span><span>H</span> <span>=</span> <span>np</span><span>.</span><span>empty</span><span>((</span><span>N</span><span>,</span> <span>N</span><span>))</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>N</span><span>):</span>
    <span>for</span> <span>j</span> <span>in</span> <span>range</span><span>(</span><span>N</span><span>):</span>
        <span>H</span><span>[</span><span>i</span><span>,</span> <span>j</span><span>]</span> <span>=</span> <span>1</span> <span>/</span> <span>(</span><span>i</span> <span>+</span> <span>j</span> <span>+</span> <span>1</span><span>)</span>

<span># NumPy
</span><span>i</span> <span>=</span> <span>np</span><span>.</span><span>arange</span><span>(</span><span>N</span><span>)</span>
<span>j</span> <span>=</span> <span>np</span><span>.</span><span>arange</span><span>(</span><span>N</span><span>)</span>
<span>H</span> <span>=</span> <span>1</span> <span>/</span> <span>(</span><span>i</span><span>[:,</span> <span>None</span><span>]</span> <span>+</span> <span>j</span><span>[</span><span>None</span><span>,</span> <span>:]</span> <span>+</span> <span>1</span><span>)</span>

<span># JAX
</span><span>indices</span> <span>=</span> <span>jnp</span><span>.</span><span>arange</span><span>(</span><span>N</span><span>)</span>
<span>H</span> <span>=</span> <span>jax</span><span>.</span><span>vmap</span><span>(</span>
        <span>jax</span><span>.</span><span>vmap</span><span>(</span>
            <span>lambda</span> <span>i</span><span>,</span> <span>j</span><span>:</span> <span>1</span> <span>/</span> <span>(</span><span>i</span> <span>+</span> <span>j</span> <span>+</span> <span>1</span><span>),</span>
            <span>[</span><span>0</span><span>,</span> <span>None</span><span>]),</span>
        <span>[</span><span>None</span><span>,</span> <span>0</span><span>]</span>
    <span>)(</span><span>indices</span><span>,</span> <span>indices</span><span>)</span>

<span># DumPy
</span><span>H</span> <span>=</span> <span>dp</span><span>.</span><span>Slot</span><span>()</span>
<span>with</span> <span>dp</span><span>.</span><span>Range</span><span>(</span><span>N</span><span>)</span> <span>as</span> <span>i</span><span>:</span>
    <span>with</span> <span>dp</span><span>.</span><span>Range</span><span>(</span><span>N</span><span>)</span> <span>as</span> <span>j</span><span>:</span>
        <span>H</span><span>[</span><span>i</span><span>,</span> <span>j</span><span>]</span> <span>=</span> <span>1</span> <span>/</span> <span>(</span><span>i</span> <span>+</span> <span>j</span> <span>+</span> <span>1</span><span>)</span> <span># Yes! This works!
</span></code></pre></div>
</details>

<details>
  

  <div><pre><code><span># Loops
</span><span>C</span> <span>=</span> <span>np</span><span>.</span><span>zeros</span><span>((</span><span>X</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>],</span><span>X</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>],</span><span>X</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]))</span>
<span>for</span> <span>n</span> <span>in</span> <span>range</span><span>(</span><span>X</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]):</span>
    <span>C</span><span>[</span><span>n</span><span>]</span> <span>=</span> <span>np</span><span>.</span><span>cov</span><span>(</span><span>X</span><span>[</span><span>n</span><span>])</span>

<span># NumPy
</span><span>mu</span> <span>=</span> <span>np</span><span>.</span><span>mean</span><span>(</span><span>X</span><span>,</span> <span>axis</span><span>=</span><span>2</span><span>)[:,</span> <span>:,</span> <span>None</span><span>]</span>    <span># hurr?
</span><span>C</span> <span>=</span> <span>np</span><span>.</span><span>sum</span><span>((</span><span>X</span> <span>-</span> <span>mu</span><span>)[:,</span> <span>None</span><span>,</span> <span>:,</span> <span>:]</span> <span>*</span>
           <span>(</span><span>X</span> <span>-</span> <span>mu</span><span>)[:,</span> <span>:,</span> <span>None</span><span>,</span> <span>:],</span>
           <span>axis</span><span>=</span><span>3</span><span>)</span> <span>/</span> <span>(</span><span>X</span><span>.</span><span>shape</span><span>[</span><span>2</span><span>]</span> <span>-</span> <span>1</span><span>)</span>  <span># hurrr??
</span>
<span># JAX
</span><span>C</span> <span>=</span> <span>jax</span><span>.</span><span>vmap</span><span>(</span><span>jnp</span><span>.</span><span>cov</span><span>)(</span><span>X</span><span>)</span>

<span># DumPy
</span><span>C_dumpy</span> <span>=</span> <span>dp</span><span>.</span><span>Slot</span><span>()</span>
<span>with</span> <span>dp</span><span>.</span><span>Range</span><span>(</span><span>X</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>])</span> <span>as</span> <span>n</span><span>:</span>
    <span>C_dumpy</span><span>[</span><span>n</span><span>,</span> <span>:,</span> <span>:]</span> <span>=</span> <span>dp</span><span>.</span><span>cov</span><span>(</span><span>X</span><span>[</span><span>n</span><span>,</span> <span>:,</span> <span>:])</span>

<span># DumPy (alternate)
</span><span>C</span> <span>=</span> <span>dp</span><span>.</span><span>Slot</span><span>()</span>
<span>C</span><span>[</span><span>'n'</span><span>,:,:]</span> <span>=</span> <span>dp</span><span>.</span><span>cov</span><span>(</span><span>X</span><span>[</span><span>'n'</span><span>,:,:])</span>
</code></pre></div>

</details>

<details>
  

  <p>(Pretending <a href="https://numpy.org/devdocs/reference/generated/numpy.lib.stride_tricks.html"><code>numpy.lib.stride_tricks</code></a> doesn’t exist.)</p>

  <div><pre><code><span># Loops
</span><span>B</span> <span>=</span> <span>np</span><span>.</span><span>empty</span><span>(</span><span>N</span> <span>-</span> <span>window</span> <span>+</span> <span>1</span><span>)</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>N</span> <span>-</span> <span>window</span> <span>+</span> <span>1</span><span>):</span>
    <span>B</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>np</span><span>.</span><span>mean</span><span>(</span><span>A</span><span>[</span><span>i</span><span>:</span><span>i</span> <span>+</span> <span>window</span><span>])</span>

<span># NumPy
</span><span>i</span> <span>=</span> <span>np</span><span>.</span><span>arange</span><span>(</span><span>N</span> <span>-</span> <span>window</span> <span>+</span> <span>1</span><span>)[:,</span> <span>None</span><span>]</span>
<span>j</span> <span>=</span> <span>np</span><span>.</span><span>arange</span><span>(</span><span>window</span><span>)[</span><span>None</span><span>,</span> <span>:]</span> 
<span>B</span> <span>=</span> <span>np</span><span>.</span><span>mean</span><span>(</span><span>A</span><span>[</span><span>i</span><span>+</span><span>j</span><span>],</span> <span>axis</span><span>=-</span><span>1</span><span>)</span>

<span># JAX
</span><span>idx</span> <span>=</span> <span>jnp</span><span>.</span><span>arange</span><span>(</span><span>window</span><span>)</span>
<span>B</span> <span>=</span> <span>jax</span><span>.</span><span>vmap</span><span>(</span>
        <span>lambda</span> <span>i</span><span>:</span> <span>jnp</span><span>.</span><span>mean</span><span>(</span><span>A</span><span>[</span><span>i</span><span>+</span><span>idx</span><span>]),</span>
    <span>)(</span><span>jnp</span><span>.</span><span>arange</span><span>(</span><span>N</span> <span>-</span> <span>window</span> <span>+</span> <span>1</span><span>))</span>

<span># DumPy
</span><span>windowed</span> <span>=</span> <span>dp</span><span>.</span><span>Slot</span><span>()</span>
<span>B</span> <span>=</span> <span>dp</span><span>.</span><span>Slot</span><span>()</span>
<span>with</span> <span>dp</span><span>.</span><span>Range</span><span>(</span><span>N</span> <span>-</span> <span>window</span> <span>+</span> <span>1</span><span>)</span> <span>as</span> <span>i</span><span>:</span>
    <span>with</span> <span>dp</span><span>.</span><span>Range</span><span>(</span><span>window</span><span>)</span> <span>as</span> <span>j</span><span>:</span>
        <span>windowed</span><span>[</span><span>i</span><span>,</span> <span>j</span><span>]</span> <span>=</span> <span>A</span><span>[</span><span>i</span> <span>+</span> <span>j</span><span>]</span>
    <span>B</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>dp</span><span>.</span><span>mean</span><span>(</span><span>windowed</span><span>[</span><span>i</span><span>,</span> <span>:])</span>
    <span># Note: B[i] = dp.mean(A[i:i+window])
</span>    <span># would not work because dp.Range can't be used in slice
</span></code></pre></div>

</details>

<details>
  

  <p>The goal is to create <code>E</code> with</p>

  <p>&nbsp;&nbsp;<code>E[i1, i2, :, i3] = A[B[i1], C[i1, i2], ::2, D[i2, i3]]</code>.</p>

  <div><pre><code><span># Setup
</span><span>K</span> <span>=</span> <span>4</span>
<span>L</span> <span>=</span> <span>5</span>
<span>M</span> <span>=</span> <span>6</span>
<span>N</span> <span>=</span> <span>7</span>

<span>A</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randn</span><span>(</span><span>K</span><span>,</span> <span>L</span><span>,</span> <span>M</span><span>,</span> <span>N</span><span>)</span>
<span>B</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randint</span><span>(</span><span>0</span><span>,</span> <span>K</span><span>,</span> <span>size</span><span>=</span><span>(</span><span>9</span><span>,))</span>
<span>C</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randint</span><span>(</span><span>0</span><span>,</span> <span>L</span><span>,</span> <span>size</span><span>=</span><span>(</span><span>9</span><span>,</span> <span>10</span><span>))</span>
<span>D</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randint</span><span>(</span><span>0</span><span>,</span> <span>N</span><span>,</span> <span>size</span><span>=</span><span>(</span><span>10</span><span>,</span> <span>11</span><span>))</span>

<span># Loops
</span><span>E</span> <span>=</span> <span>np</span><span>.</span><span>empty</span><span>((</span><span>9</span><span>,</span> <span>10</span><span>,</span> <span>M</span> <span>//</span> <span>2</span><span>,</span> <span>11</span><span>))</span>
<span>for</span> <span>i1</span> <span>in</span> <span>range</span><span>(</span><span>9</span><span>):</span>
    <span>for</span> <span>i2</span> <span>in</span> <span>range</span><span>(</span><span>10</span><span>):</span>
        <span>for</span> <span>i3</span> <span>in</span> <span>range</span><span>(</span><span>11</span><span>):</span>
            <span>E</span><span>[</span><span>i1</span><span>,</span><span>i2</span><span>,:,</span><span>i3</span><span>]</span> <span>=</span> <span>A</span><span>[</span><span>B</span><span>[</span><span>i1</span><span>],</span><span>C</span><span>[</span><span>i1</span><span>,</span> <span>i2</span><span>],::</span><span>2</span><span>,</span><span>D</span><span>[</span><span>i2</span><span>,</span> <span>i3</span><span>]]</span>

<span># NumPy
</span><span>E</span> <span>=</span> <span>A</span><span>[</span><span>B</span><span>[:,</span> <span>None</span><span>,</span> <span>None</span><span>],</span>
      <span>C</span><span>[:,</span> <span>:,</span> <span>None</span><span>],</span>
      <span>::</span><span>2</span><span>,</span>
      <span>D</span><span>[</span><span>None</span><span>,</span> <span>:,</span> <span>:]</span>
    <span>].</span><span>transpose</span><span>((</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>3</span><span>,</span> <span>2</span><span>))</span>

<span># JAX
</span><span>E</span> <span>=</span> <span>jax</span><span>.</span><span>vmap</span><span>(</span>
        <span>jax</span><span>.</span><span>vmap</span><span>(</span>
            <span>jax</span><span>.</span><span>vmap</span><span>(</span>
                <span>lambda</span> <span>b</span><span>,</span> <span>c</span><span>,</span> <span>d</span><span>:</span> <span>A</span><span>[</span><span>b</span><span>,</span> <span>c</span><span>,</span> <span>::</span><span>2</span><span>,</span> <span>d</span><span>],</span>
                <span>in_axes</span><span>=</span><span>[</span><span>None</span><span>,</span><span>None</span><span>,</span><span>0</span><span>]),</span>
            <span>in_axes</span><span>=</span><span>[</span><span>None</span><span>,</span><span>0</span><span>,</span><span>0</span><span>]),</span>
        <span>in_axes</span><span>=</span><span>[</span><span>0</span><span>,</span><span>0</span><span>,</span><span>None</span><span>]</span>
    <span>)(</span><span>B</span><span>,</span><span>C</span><span>,</span><span>D</span><span>).</span><span>transpose</span><span>(</span><span>0</span><span>,</span><span>1</span><span>,</span><span>3</span><span>,</span><span>2</span><span>)</span>

<span># DumPy
</span><span>E</span> <span>=</span> <span>dp</span><span>.</span><span>Slot</span><span>()</span>
<span>with</span> <span>dp</span><span>.</span><span>Range</span><span>(</span><span>9</span><span>)</span> <span>as</span> <span>i1</span><span>:</span>
    <span>with</span> <span>dp</span><span>.</span><span>Range</span><span>(</span><span>10</span><span>)</span> <span>as</span> <span>i2</span><span>:</span>
        <span>with</span> <span>dp</span><span>.</span><span>Range</span><span>(</span><span>11</span><span>)</span> <span>as</span> <span>i3</span><span>:</span>
            <span>E</span><span>[</span><span>i1</span><span>,</span><span>i2</span><span>,:,</span><span>i3</span><span>]</span> <span>=</span> <span>A</span><span>[</span><span>B</span><span>[</span><span>i1</span><span>],</span><span>C</span><span>[</span><span>i1</span><span>,</span> <span>i2</span><span>],::</span><span>2</span><span>,</span><span>D</span><span>[</span><span>i2</span><span>,</span> <span>i3</span><span>]]</span>

<span># DumPy (alternative)
</span><span>E</span> <span>=</span> <span>dp</span><span>.</span><span>Slot</span><span>()</span>
<span>E</span><span>[</span><span>'i1'</span><span>,</span><span>'i2'</span><span>,:,</span><span>'i3'</span><span>]</span> <span>=</span> <span>A</span><span>[</span><span>B</span><span>[</span><span>'i1'</span><span>],</span> <span>C</span><span>[</span><span>'i1'</span><span>,</span><span>'i2'</span><span>],</span> <span>::</span><span>2</span><span>,</span> <span>D</span><span>[</span><span>'i2'</span><span>,</span><span>'i3'</span><span>]]</span>

</code></pre></div>
</details>

<details>
  

  <p>The goal of this problem is, given a list of vectors and a list of <a href="https://en.wikipedia.org/wiki/Multivariate_normal_distribution">Gaussians</a> parameters, and arrays mapping each vector to a list of parameters, evaluate each corresponding vector/parameter combination. Formally, given 2D <code>X</code>, <code>B</code>, <code>C</code>, and <code>means</code> and 3D <code>covs</code>, the goal is to create <code>A</code> with</p>

  <p>&nbsp;&nbsp;<code>A<sub>ij</sub> = log N( X<sub>i</sub> | means<sub>B<sub>ij</sub></sub>, covs<sub>C<sub>ij</sub></sub>) </code>.</p>

  <div><pre><code><span># Setup
</span><span>ndims</span> <span>=</span> <span>3</span>
<span>ndata</span> <span>=</span> <span>10</span>
<span>neval</span> <span>=</span> <span>5</span>
<span>ndist</span> <span>=</span> <span>7</span>

<span>X</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randn</span><span>(</span><span>ndata</span><span>,</span> <span>ndims</span><span>)</span>
<span>B</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randint</span><span>(</span><span>0</span><span>,</span> <span>ndist</span><span>,</span> <span>size</span><span>=</span><span>(</span><span>ndata</span><span>,</span> <span>neval</span><span>))</span>
<span>C</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randint</span><span>(</span><span>0</span><span>,</span> <span>ndist</span><span>,</span> <span>size</span><span>=</span><span>(</span><span>ndata</span><span>,</span> <span>neval</span><span>))</span>
<span>means</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randn</span><span>(</span><span>ndist</span><span>,</span> <span>ndims</span><span>)</span>
<span>scales</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>(</span><span>np</span><span>.</span><span>random</span><span>.</span><span>randn</span><span>(</span><span>ndist</span><span>,</span> <span>ndims</span><span>,</span> <span>ndims</span><span>))</span>
<span>covs</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>([</span><span>scale</span> <span>@</span> <span>scale</span><span>.</span><span>T</span> <span>for</span> <span>scale</span> <span>in</span> <span>scales</span><span>])</span>
</code></pre></div>

  <div><pre><code><span># Loops
</span><span>def</span> <span>log_prob</span><span>(</span><span>x</span><span>,</span> <span>mean</span><span>,</span> <span>cov</span><span>):</span>
    <span>diff</span> <span>=</span> <span>x</span> <span>-</span> <span>mean</span>
    <span>y</span> <span>=</span> <span>np</span><span>.</span><span>linalg</span><span>.</span><span>solve</span><span>(</span><span>cov</span><span>,</span> <span>diff</span><span>)</span>
    <span>quad</span> <span>=</span> <span>diff</span> <span>@</span> <span>y</span>
    <span>logdet</span> <span>=</span> <span>np</span><span>.</span><span>linalg</span><span>.</span><span>slogdet</span><span>(</span><span>2</span> <span>*</span> <span>np</span><span>.</span><span>pi</span> <span>*</span> <span>cov</span><span>)[</span><span>1</span><span>]</span>
    <span>return</span> <span>-</span><span>0.5</span> <span>*</span> <span>(</span><span>quad</span> <span>+</span> <span>logdet</span><span>)</span>

<span>A</span> <span>=</span> <span>np</span><span>.</span><span>empty</span><span>((</span><span>ndata</span><span>,</span> <span>neval</span><span>))</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>ndata</span><span>):</span>
    <span>for</span> <span>j</span> <span>in</span> <span>range</span><span>(</span><span>neval</span><span>):</span>
        <span>A</span><span>[</span><span>i</span><span>,</span> <span>j</span><span>]</span> <span>=</span> <span>log_prob</span><span>(</span><span>X</span><span>[</span><span>i</span><span>,</span> <span>:],</span>
                           <span>means</span><span>[</span><span>B</span><span>[</span><span>i</span><span>,</span> <span>j</span><span>],</span> <span>:],</span>
                           <span>covs</span><span>[</span><span>C</span><span>[</span><span>i</span><span>,</span> <span>j</span><span>],</span> <span>:,</span> <span>:])</span>

<span># NumPy
</span><span>diff</span> <span>=</span> <span>X</span><span>[:,</span> <span>None</span><span>,</span> <span>:]</span> <span>-</span> <span>means</span><span>[</span><span>B</span><span>]</span>
<span>y</span> <span>=</span> <span>np</span><span>.</span><span>linalg</span><span>.</span><span>solve</span><span>(</span><span>covs</span><span>[</span><span>C</span><span>],</span> <span>diff</span><span>[...,</span> <span>None</span><span>])</span>
<span>quad</span> <span>=</span> <span>np</span><span>.</span><span>sum</span><span>(</span><span>diff</span> <span>*</span> <span>y</span><span>[...,</span> <span>0</span><span>],</span> <span>axis</span><span>=-</span><span>1</span><span>)</span>
<span>logdet</span> <span>=</span> <span>np</span><span>.</span><span>linalg</span><span>.</span><span>slogdet</span><span>(</span><span>2</span> <span>*</span> <span>np</span><span>.</span><span>pi</span> <span>*</span> <span>covs</span><span>[</span><span>C</span><span>])[</span><span>1</span><span>]</span>
<span>A</span> <span>=</span> <span>-</span><span>0.5</span> <span>*</span> <span>(</span><span>quad</span> <span>+</span> <span>logdet</span><span>)</span>

<span># JAX
</span><span>A</span> <span>=</span> <span>jax</span><span>.</span><span>vmap</span><span>(</span>
        <span>jax</span><span>.</span><span>vmap</span><span>(</span>
            <span>log_prob_gauss</span><span>,</span>
            <span>in_axes</span><span>=</span><span>[</span><span>None</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]</span>
        <span>),</span>
    <span>)(</span><span>X</span><span>,</span> <span>means</span><span>[</span><span>B</span><span>],</span> <span>covs</span><span>[</span><span>C</span><span>])</span>

<span># DumPy
</span><span>def</span> <span>log_prob</span><span>(</span><span>x</span><span>,</span> <span>mean</span><span>,</span> <span>cov</span><span>):</span>
    <span>diff</span> <span>=</span> <span>x</span> <span>-</span> <span>mean</span>
    <span>quad</span> <span>=</span> <span>diff</span> <span>@</span> <span>dp</span><span>.</span><span>linalg</span><span>.</span><span>solve</span><span>(</span><span>cov</span><span>,</span> <span>diff</span><span>)</span>
    <span>logdet</span> <span>=</span> <span>dp</span><span>.</span><span>linalg</span><span>.</span><span>slogdet</span><span>(</span><span>2</span> <span>*</span> <span>jnp</span><span>.</span><span>pi</span> <span>*</span> <span>cov</span><span>)[</span><span>1</span><span>]</span>

<span>A</span> <span>=</span> <span>dp</span><span>.</span><span>Slot</span><span>()</span>
<span>with</span> <span>dp</span><span>.</span><span>Range</span><span>(</span><span>ndata</span><span>)</span> <span>as</span> <span>i</span><span>:</span>
    <span>with</span> <span>dp</span><span>.</span><span>Range</span><span>(</span><span>neval</span><span>)</span> <span>as</span> <span>j</span><span>:</span>
        <span>A</span><span>[</span><span>i</span><span>,</span> <span>j</span><span>]</span> <span>=</span> <span>log_prob</span><span>(</span><span>X</span><span>[</span><span>i</span><span>,:],</span>
                           <span>means</span><span>[</span><span>B</span><span>[</span><span>i</span><span>,</span><span>j</span><span>],:],</span>
                           <span>covs</span><span>[</span><span>C</span><span>[</span><span>i</span><span>,</span><span>j</span><span>],:,:])</span>

<span># DumPy (alternate)
</span><span>A</span> <span>=</span> <span>dp</span><span>.</span><span>Slot</span><span>()</span>
<span>with</span> <span>dp</span><span>.</span><span>Range</span><span>(</span><span>ndata</span><span>)</span> <span>as</span> <span>i</span><span>:</span>
    <span>with</span> <span>dp</span><span>.</span><span>Range</span><span>(</span><span>neval</span><span>)</span> <span>as</span> <span>j</span><span>:</span>
        <span>mean</span> <span>=</span> <span>means</span><span>[</span><span>B</span><span>[</span><span>i</span><span>,</span><span>j</span><span>],:]</span>
        <span>cov</span> <span>=</span> <span>covs</span><span>[</span><span>C</span><span>[</span><span>i</span><span>,</span><span>j</span><span>],:,:]</span>
        <span>diff</span> <span>=</span> <span>X</span><span>[</span><span>i</span><span>,:]</span> <span>-</span> <span>mean</span>
        <span>quad</span> <span>=</span> <span>diff</span> <span>@</span> <span>dp</span><span>.</span><span>linalg</span><span>.</span><span>solve</span><span>(</span><span>cov</span><span>,</span> <span>diff</span><span>)</span>
        <span>logdet</span> <span>=</span> <span>dp</span><span>.</span><span>linalg</span><span>.</span><span>slogdet</span><span>(</span><span>2</span> <span>*</span> <span>jnp</span><span>.</span><span>pi</span> <span>*</span> <span>cov</span><span>)[</span><span>1</span><span>]</span>
        <span>A</span><span>[</span><span>i</span><span>,</span><span>j</span><span>]</span> <span>=</span> <span>-</span><span>0.5</span> <span>*</span> <span>(</span><span>quad</span> <span>+</span> <span>logdet</span><span>)</span>
</code></pre></div>

</details>

<details>
  

  <p>See also the discussion in the <a href="https://dynomight.net/numpy/#attention-please">previous post</a>.</p>

  <div><pre><code><span># Setup
</span><span>input_dim</span> <span>=</span> <span>4</span>
<span>seq_len</span> <span>=</span> <span>4</span>
<span>d_k</span> <span>=</span> <span>5</span>
<span>d_v</span> <span>=</span> <span>input_dim</span>
<span>n_head</span> <span>=</span> <span>2</span>
<span>X</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randn</span><span>(</span><span>seq_len</span><span>,</span> <span>input_dim</span><span>)</span>
<span>W_q</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randn</span><span>(</span><span>n_head</span><span>,</span> <span>input_dim</span><span>,</span> <span>d_k</span><span>)</span>
<span>W_k</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randn</span><span>(</span><span>n_head</span><span>,</span> <span>input_dim</span><span>,</span> <span>d_k</span><span>)</span>
<span>W_v</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randn</span><span>(</span><span>n_head</span><span>,</span> <span>input_dim</span><span>,</span> <span>d_v</span><span>)</span>
<span>W_o</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randn</span><span>(</span><span>n_head</span><span>,</span> <span>d_v</span><span>,</span> <span>input_dim</span> <span>//</span> <span>n_head</span><span>)</span>

<span># Loops
</span><span>def</span> <span>softmax_numpy</span><span>(</span><span>x</span><span>,</span> <span>axis</span><span>=-</span><span>1</span><span>):</span>
    <span>e_x</span> <span>=</span> <span>np</span><span>.</span><span>exp</span><span>(</span><span>x</span> <span>-</span> <span>np</span><span>.</span><span>max</span><span>(</span><span>x</span><span>,</span> <span>axis</span><span>=</span><span>axis</span><span>,</span> <span>keepdims</span><span>=</span><span>True</span><span>))</span>
    <span>return</span> <span>e_x</span> <span>/</span> <span>np</span><span>.</span><span>sum</span><span>(</span><span>e_x</span><span>,</span> <span>axis</span><span>=</span><span>axis</span><span>,</span> <span>keepdims</span><span>=</span><span>True</span><span>)</span>

<span>def</span> <span>attention</span><span>(</span><span>X</span><span>,</span> <span>W_q</span><span>,</span> <span>W_k</span><span>,</span> <span>W_v</span><span>):</span>
    <span>Q</span> <span>=</span> <span>X</span> <span>@</span> <span>W_q</span>
    <span>K</span> <span>=</span> <span>X</span> <span>@</span> <span>W_k</span>
    <span>V</span> <span>=</span> <span>X</span> <span>@</span> <span>W_v</span>
    <span>scores</span> <span>=</span> <span>Q</span> <span>@</span> <span>K</span><span>.</span><span>T</span> <span>/</span> <span>np</span><span>.</span><span>sqrt</span><span>(</span><span>d_k</span><span>)</span>
    <span>attention_weights</span> <span>=</span> <span>softmax_numpy</span><span>(</span><span>scores</span><span>,</span> <span>axis</span><span>=-</span><span>1</span><span>)</span>
    <span>output</span> <span>=</span> <span>attention_weights</span> <span>@</span> <span>V</span>
    <span>return</span> <span>output</span>

<span>def</span> <span>multi_head_attention_loops</span><span>(</span><span>X</span><span>,</span> <span>W_q</span><span>,</span> <span>W_k</span><span>,</span> <span>W_v</span><span>,</span> <span>W_o</span><span>):</span>
    <span>projected</span> <span>=</span> <span>[]</span>
    <span>for</span> <span>n</span> <span>in</span> <span>range</span><span>(</span><span>n_head</span><span>):</span>
        <span>my_output</span> <span>=</span> <span>attention</span><span>(</span><span>X</span><span>,</span>
                                <span>W_q</span><span>[</span><span>n</span><span>,</span> <span>:,</span> <span>:],</span>
                                <span>W_k</span><span>[</span><span>n</span><span>,</span> <span>:,</span> <span>:],</span>
                                <span>W_v</span><span>[</span><span>n</span><span>,</span> <span>:,</span> <span>:])</span>
        <span>my_proj</span> <span>=</span> <span>my_output</span> <span>@</span> <span>W_o</span><span>[</span><span>n</span><span>,</span> <span>:,</span> <span>:]</span>
        <span>projected</span><span>.</span><span>append</span><span>(</span><span>my_proj</span><span>)</span>
    <span>projected</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>(</span><span>projected</span><span>)</span>

    <span>final</span> <span>=</span> <span>[]</span>
    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>seq_len</span><span>):</span>
        <span>my_final</span> <span>=</span> <span>np</span><span>.</span><span>ravel</span><span>(</span><span>projected</span><span>[:,</span> <span>i</span><span>,</span> <span>:])</span>
        <span>final</span><span>.</span><span>append</span><span>(</span><span>my_final</span><span>)</span>
    <span>return</span> <span>np</span><span>.</span><span>array</span><span>(</span><span>final</span><span>)</span>

<span># NumPy
</span><span>def</span> <span>softmax_numpy</span><span>(</span><span>x</span><span>,</span> <span>axis</span><span>=-</span><span>1</span><span>):</span> <span># repeat
</span>    <span>e_x</span> <span>=</span> <span>np</span><span>.</span><span>exp</span><span>(</span><span>x</span> <span>-</span> <span>np</span><span>.</span><span>max</span><span>(</span><span>x</span><span>,</span> <span>axis</span><span>=</span><span>axis</span><span>,</span> <span>keepdims</span><span>=</span><span>True</span><span>))</span>
    <span>return</span> <span>e_x</span> <span>/</span> <span>np</span><span>.</span><span>sum</span><span>(</span><span>e_x</span><span>,</span> <span>axis</span><span>=</span><span>axis</span><span>,</span> <span>keepdims</span><span>=</span><span>True</span><span>)</span>

<span>def</span> <span>multi_head_attention_numpy</span><span>(</span><span>X</span><span>,</span> <span>W_q</span><span>,</span> <span>W_k</span><span>,</span> <span>W_v</span><span>,</span> <span>W_o</span><span>):</span>
    <span>Q</span> <span>=</span> <span>np</span><span>.</span><span>einsum</span><span>(</span><span>'si,hij-&gt;hsj'</span><span>,</span> <span>X</span><span>,</span> <span>W_q</span><span>)</span>
    <span>K</span> <span>=</span> <span>np</span><span>.</span><span>einsum</span><span>(</span><span>'si,hik-&gt;hsk'</span><span>,</span> <span>X</span><span>,</span> <span>W_k</span><span>)</span>
    <span>V</span> <span>=</span> <span>np</span><span>.</span><span>einsum</span><span>(</span><span>'si,hiv-&gt;hsv'</span><span>,</span> <span>X</span><span>,</span> <span>W_v</span><span>)</span>
    <span>scores</span> <span>=</span> <span>Q</span> <span>@</span> <span>K</span><span>.</span><span>transpose</span><span>(</span><span>0</span><span>,</span> <span>2</span><span>,</span> <span>1</span><span>)</span> <span>/</span> <span>np</span><span>.</span><span>sqrt</span><span>(</span><span>d_k</span><span>)</span>
    <span>weights</span> <span>=</span> <span>softmax_numpy</span><span>(</span><span>scores</span><span>,</span> <span>axis</span><span>=-</span><span>1</span><span>)</span>
    <span>output</span> <span>=</span> <span>weights</span> <span>@</span> <span>V</span>
    <span>projected</span> <span>=</span> <span>np</span><span>.</span><span>einsum</span><span>(</span><span>'hsv,hvd-&gt;hsd'</span><span>,</span> <span>output</span><span>,</span> <span>W_o</span><span>)</span>
    <span>return</span> <span>projected</span><span>.</span><span>transpose</span><span>(</span><span>1</span><span>,</span> <span>0</span><span>,</span> <span>2</span><span>).</span><span>reshape</span><span>(</span>
        <span>seq_len</span><span>,</span> <span>input_dim</span><span>)</span>

<span># JAX
</span><span>def</span> <span>softmax_jax</span><span>(</span><span>x</span><span>,</span> <span>axis</span><span>=-</span><span>1</span><span>):</span>
    <span>e_x</span> <span>=</span> <span>jnp</span><span>.</span><span>exp</span><span>(</span><span>x</span> <span>-</span> <span>jnp</span><span>.</span><span>max</span><span>(</span><span>x</span><span>,</span> <span>axis</span><span>=</span><span>axis</span><span>,</span> <span>keepdims</span><span>=</span><span>True</span><span>))</span>
    <span>return</span> <span>e_x</span> <span>/</span> <span>jnp</span><span>.</span><span>sum</span><span>(</span><span>e_x</span><span>,</span> <span>axis</span><span>=</span><span>axis</span><span>,</span> <span>keepdims</span><span>=</span><span>True</span><span>)</span>

<span>def</span> <span>attention_jax</span><span>(</span><span>X</span><span>,</span> <span>W_q</span><span>,</span> <span>W_k</span><span>,</span> <span>W_v</span><span>):</span>
    <span>d_k</span> <span>=</span> <span>W_k</span><span>.</span><span>shape</span><span>[</span><span>-</span><span>1</span><span>]</span>
    <span>Q</span> <span>=</span> <span>X</span> <span>@</span> <span>W_q</span>
    <span>K</span> <span>=</span> <span>X</span> <span>@</span> <span>W_k</span>
    <span>V</span> <span>=</span> <span>X</span> <span>@</span> <span>W_v</span>
    <span>scores</span> <span>=</span> <span>Q</span> <span>@</span> <span>K</span><span>.</span><span>T</span> <span>/</span> <span>jnp</span><span>.</span><span>sqrt</span><span>(</span><span>d_k</span><span>)</span>
    <span>attention_weights</span> <span>=</span> <span>softmax_jax</span><span>(</span><span>scores</span><span>,</span> <span>axis</span><span>=-</span><span>1</span><span>)</span>
    <span>output</span> <span>=</span> <span>attention_weights</span> <span>@</span> <span>V</span>
    <span>return</span> <span>output</span>

<span>def</span> <span>multi_head_attention_jax</span><span>(</span><span>X</span><span>,</span> <span>W_q</span><span>,</span> <span>W_k</span><span>,</span> <span>W_v</span><span>,</span> <span>W_o</span><span>):</span>
    <span>def</span> <span>myfun</span><span>(</span><span>X</span><span>,</span> <span>w_q</span><span>,</span> <span>w_k</span><span>,</span> <span>w_v</span><span>,</span> <span>w_o</span><span>):</span>
        <span>return</span> <span>attention_jax</span><span>(</span><span>X</span><span>,</span> <span>w_q</span><span>,</span> <span>w_k</span><span>,</span> <span>w_v</span><span>)</span> <span>@</span> <span>w_o</span>

    <span>projected</span> <span>=</span> <span>jax</span><span>.</span><span>vmap</span><span>(</span><span>myfun</span><span>,</span>
                            <span>in_axes</span><span>=</span><span>[</span><span>None</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]</span>
                <span>)(</span><span>X</span><span>,</span> <span>W_q</span><span>,</span> <span>W_k</span><span>,</span> <span>W_v</span><span>,</span> <span>W_o</span><span>)</span>

    <span>return</span> <span>jax</span><span>.</span><span>vmap</span><span>(</span><span>jnp</span><span>.</span><span>ravel</span><span>,</span> <span>in_axes</span><span>=</span><span>1</span><span>)(</span><span>projected</span><span>)</span>

<span># DumPy
</span><span>def</span> <span>softmax_dumpy</span><span>(</span><span>x</span><span>):</span>
    <span>assert</span> <span>x</span><span>.</span><span>ndim</span> <span>==</span> <span>1</span> <span># no need to think about dimensions!
</span>    <span>e_x</span> <span>=</span> <span>dp</span><span>.</span><span>exp</span><span>(</span><span>x</span> <span>-</span> <span>dp</span><span>.</span><span>max</span><span>(</span><span>x</span><span>))</span>
    <span>return</span> <span>e_x</span> <span>/</span> <span>dp</span><span>.</span><span>sum</span><span>(</span><span>e_x</span><span>)</span>

<span>@</span><span>dp</span><span>.</span><span>wrap</span> <span># needed to make functions with Slots auto-vectorizing
</span><span>def</span> <span>attention_dumpy</span><span>(</span><span>X</span><span>,</span> <span>W_q</span><span>,</span> <span>W_k</span><span>,</span> <span>W_v</span><span>):</span>
    <span>Q</span> <span>=</span> <span>X</span> <span>@</span> <span>W_q</span>
    <span>K</span> <span>=</span> <span>X</span> <span>@</span> <span>W_k</span>
    <span>V</span> <span>=</span> <span>X</span> <span>@</span> <span>W_v</span>
    <span>scores</span> <span>=</span> <span>Q</span> <span>@</span> <span>K</span><span>.</span><span>T</span> <span>/</span> <span>np</span><span>.</span><span>sqrt</span><span>(</span><span>d_k</span><span>)</span>
    <span>attention_weights</span> <span>=</span> <span>dp</span><span>.</span><span>Slot</span><span>()</span>
    <span>with</span> <span>dp</span><span>.</span><span>Range</span><span>(</span><span>seq_len</span><span>)</span> <span>as</span> <span>i</span><span>:</span>
        <span>attention_weights</span><span>[</span><span>i</span><span>,</span> <span>:]</span> <span>=</span> <span>softmax_dumpy</span><span>(</span><span>scores</span><span>[</span><span>i</span><span>,</span> <span>:])</span>
    <span>output</span> <span>=</span> <span>attention_weights</span> <span>@</span> <span>V</span>
    <span>return</span> <span>output</span>

<span>def</span> <span>multi_head_attention_dumpy</span><span>(</span><span>X</span><span>,</span> <span>W_q</span><span>,</span> <span>W_k</span><span>,</span> <span>W_v</span><span>,</span> <span>W_o</span><span>):</span>
    <span>output</span> <span>=</span> <span>dp</span><span>.</span><span>Slot</span><span>()</span>
    <span>projected</span> <span>=</span> <span>dp</span><span>.</span><span>Slot</span><span>()</span>
    <span>final</span> <span>=</span> <span>dp</span><span>.</span><span>Slot</span><span>()</span>
    <span>with</span> <span>dp</span><span>.</span><span>Range</span><span>(</span><span>n_head</span><span>)</span> <span>as</span> <span>n</span><span>:</span>
        <span>output</span><span>[</span><span>n</span><span>,</span> <span>:,</span> <span>:]</span> <span>=</span> <span>attention_dumpy</span><span>(</span><span>X</span><span>,</span>
                                          <span>W_q</span><span>[</span><span>n</span><span>,</span> <span>:,</span> <span>:],</span>
                                          <span>W_k</span><span>[</span><span>n</span><span>,</span> <span>:,</span> <span>:],</span>
                                          <span>W_v</span><span>[</span><span>n</span><span>,</span> <span>:,</span> <span>:])</span>
        <span>projected</span><span>[</span><span>n</span><span>,</span> <span>:,</span> <span>:]</span> <span>=</span> <span>output</span><span>[</span><span>n</span><span>,</span> <span>:,</span> <span>:]</span> <span>@</span> <span>W_o</span><span>[</span><span>n</span><span>,</span> <span>:,</span> <span>:]</span>
    <span>with</span> <span>dp</span><span>.</span><span>Range</span><span>(</span><span>seq_len</span><span>)</span> <span>as</span> <span>i</span><span>:</span>
        <span>final</span><span>[</span><span>i</span><span>,</span> <span>:]</span> <span>=</span> <span>dp</span><span>.</span><span>ravel</span><span>(</span><span>projected</span><span>[:,</span> <span>i</span><span>,</span> <span>:])</span>
    <span>return</span> <span>final</span>

<span># DumPy (alternate)
</span><span>def</span> <span>multi_head_attention</span><span>(</span><span>X</span><span>,</span> <span>W_q</span><span>,</span> <span>W_k</span><span>,</span> <span>W_v</span><span>,</span> <span>W_o</span><span>):</span>
    <span>attn_weights</span> <span>=</span> <span>dp</span><span>.</span><span>Slot</span><span>()</span>
    <span>projected</span> <span>=</span> <span>dp</span><span>.</span><span>Slot</span><span>()</span>
    <span>final</span> <span>=</span> <span>dp</span><span>.</span><span>Slot</span><span>()</span>
    <span>with</span> <span>dp</span><span>.</span><span>Range</span><span>(</span><span>n_head</span><span>)</span> <span>as</span> <span>n</span><span>:</span>
        <span>Q</span> <span>=</span> <span>X</span> <span>@</span> <span>W_q</span><span>[</span><span>n</span><span>,</span> <span>:,</span> <span>:]</span>
        <span>K</span> <span>=</span> <span>X</span> <span>@</span> <span>W_k</span><span>[</span><span>n</span><span>,</span> <span>:,</span> <span>:]</span>
        <span>V</span> <span>=</span> <span>X</span> <span>@</span> <span>W_v</span><span>[</span><span>n</span><span>,</span> <span>:,</span> <span>:]</span>
        <span>scores</span> <span>=</span> <span>Q</span> <span>@</span> <span>K</span><span>.</span><span>T</span> <span>/</span> <span>np</span><span>.</span><span>sqrt</span><span>(</span><span>d_k</span><span>)</span>
        <span>with</span> <span>dp</span><span>.</span><span>Range</span><span>(</span><span>seq_len</span><span>)</span> <span>as</span> <span>i</span><span>:</span>
            <span>attn_weights</span><span>[</span><span>n</span><span>,</span> <span>i</span><span>,</span> <span>:]</span> <span>=</span> <span>softmax_dumpy</span><span>(</span><span>scores</span><span>[</span><span>i</span><span>,</span> <span>:])</span>
        <span>projected</span><span>[</span><span>n</span><span>,</span> <span>:,</span> <span>:]</span> <span>=</span> <span>attn_weights</span><span>[</span><span>n</span><span>,</span> <span>:,</span> <span>:]</span> <span>@</span> <span>V</span> <span>@</span> <span>W_o</span><span>[</span><span>n</span><span>,</span> <span>:,</span> <span>:]</span>
    <span>with</span> <span>dp</span><span>.</span><span>Range</span><span>(</span><span>seq_len</span><span>)</span> <span>as</span> <span>i</span><span>:</span>
        <span>final</span><span>[</span><span>i</span><span>,</span> <span>:]</span> <span>=</span> <span>dp</span><span>.</span><span>ravel</span><span>(</span><span>projected</span><span>[:,</span> <span>i</span><span>,</span> <span>:])</span>
    <span>return</span> <span>final</span>
</code></pre></div>

</details>

<p>I gave each implementation a subjective “goodness” score on a 1-10 scale. I always gave the best implementation for each problem 10 points, and then took off points from the others based on how much thinking they required.</p>

<table>
  <thead>
    <tr>
      <th>Problem</th>
      <th>Loops</th>
      <th>Numpy</th>
      <th>JAX (vmap)</th>
      <th>DumPy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Hilbert matrices</td>
      <td>10</td>
      <td>7</td>
      <td>7</td>
      <td>10</td>
    </tr>
    <tr>
      <td>Covariance</td>
      <td>9</td>
      <td>4</td>
      <td>10</td>
      <td>9</td>
    </tr>
    <tr>
      <td>Moving Ave.</td>
      <td>10</td>
      <td>6</td>
      <td>6</td>
      <td>8</td>
    </tr>
    <tr>
      <td>Indexing</td>
      <td>10</td>
      <td>5</td>
      <td>4</td>
      <td>10</td>
    </tr>
    <tr>
      <td>Gaussians</td>
      <td>10</td>
      <td>3</td>
      <td>6</td>
      <td>10</td>
    </tr>
    <tr>
      <td>Attention</td>
      <td>10</td>
      <td>1</td>
      <td>8</td>
      <td>10</td>
    </tr>
    <tr>
      <td><strong>Mean</strong></td>
      <td><strong>9.8</strong></td>
      <td><strong>4.3</strong></td>
      <td><strong>6.8</strong></td>
      <td><strong>9.5</strong></td>
    </tr>
  </tbody>
</table>

<p>According to this dubious methodology and these made-up numbers, DumPy is 96.93877% as good as loops! Knowledge is power! But seriously, while subjective, I don’t think my scores should be <em>too</em> controversial. The most debatable one is probably JAX’s attention score.</p>

<h2 id="what-to-remove">What to remove?</h2>

<p>The only thing DumPy adds to NumPy is some nice notation for indices. That’s it.</p>

<p>What I think makes DumPy good is it also <em>removes</em> a lot of stuff. Roughly speaking, I’ve tried to remove anything that is confusing and exists because NumPy doesn’t have loops. I’m not sure that I’ve drawn the line in exactly the right place, but I do feel confident that I’m on the right track.</p>

<h3 id="1-goodbye-broadcasting">1. Goodbye broadcasting</h3>

<p>In NumPy, <code>A*B</code> works if <code>A</code> and <code>B</code> are both scalar. Or if <code>A</code> is <code>5×1×6</code> and <code>B</code> is <code>5×1×6×1</code>. But not if <code>A</code> is <code>1×5×6</code> and <code>B</code> is <code>1×5×6×1</code>. Huh?</p>

<p>In truth, the <a href="https://numpy.org/doc/stable/user/basics.broadcasting.html">broadcasting rules</a> aren’t <em>that</em> complicated for scalar operations like multiplication. But still, I don’t like it, because <em>every time</em> you see <code>A*B</code>, you have to worry about what shapes those have and what the computation might be doing.</p>

<p>So, I removed it. In DumPy you can only do <code>A*B</code> if one of <code>A</code> or <code>B</code> is scalar or <code>A</code> and <code>B</code> have exactly the same shape. That’s it, anything else raises an error. Instead, use indices, so it’s clear what you’re doing. Instead of this:</p>

<div><pre><code><span>C</span> <span>=</span> <span>A</span><span>[...,</span><span>None</span><span>]</span> <span>*</span> <span>B</span><span>[</span><span>None</span><span>]</span>
</code></pre></div>

<p>write this:</p>

<div><pre><code><span>C</span><span>[</span><span>'i'</span><span>,</span><span>'j'</span><span>,</span><span>'k'</span><span>]</span> <span>=</span> <span>A</span><span>[</span><span>'i'</span><span>,</span><span>'j'</span><span>]</span> <span>*</span> <span>B</span><span>[</span><span>'j'</span><span>,</span><span>'k'</span><span>]</span>
</code></pre></div>

<h3 id="2-goodbye-fancy-indexing">2. Goodbye fancy indexing</h3>

<p>Indexing in NumPy is <a href="https://dynomight.net/numpy/#i-dont-like-numpy-indexing">absurdly complicated</a>. When you write <code>A[B,C,D]</code> that could do <em>many</em> different things depending on what all the shapes are. I considered going cold-turkey and only allowing scalar indices in DumPy. That wouldn’t have been <em>so</em> bad, since you can still do advanced stuff using loops. But it’s quite annoying to not be able to write <code>A[B]</code> when <code>A</code> and <code>B</code> are just simple 1D arrays.</p>

<p>So I’ve tentatively decided to be more pragmatic. In DumPy, you can index with integers, or slices, or (possibly mapped) <code>Array</code>s. <strong>But only one <code>Array</code> index can be non-scalar</strong>. I settled on this because it’s the most general syntax that doesn’t require thinking.</p>

<p>Let me show you what I mean. If you see this:</p>

<div><pre><code><span>A</span><span>[</span><span>1</span><span>,</span> <span>1</span><span>:</span><span>6</span><span>,</span> <span>C</span><span>,</span> <span>2</span><span>:</span><span>10</span><span>]</span> <span># legal in both numpy and dumpy
</span></code></pre></div>

<p>It’s “obvious” what the output shape will be. (First the shape of <code>1:6</code>, then the shape of <code>C</code>, then the shape of <code>2:10</code>). Simple enough. But as soon as you have <em>two</em> multidimensional array inputs like this:</p>

<div><pre><code><span>A</span><span>[</span><span>B</span><span>,</span> <span>1</span><span>:</span><span>6</span><span>,</span> <span>C</span><span>,</span> <span>2</span><span>:</span><span>10</span><span>]</span> <span># legal in numpy, verboten in dumpy
</span></code></pre></div>

<p>Suddenly all hell breaks loose. You need to think about broadcasting between <code>A</code> and <code>B</code>, orthogonal vs. pointwise indices, slices behaving differently than arrays, and quirks for where the output dimensions go. So DumPy forbids this. Instead, you need to write one of these:</p>

<div><pre><code><span>D</span><span>[</span><span>'i'</span><span>,:,:]</span>     <span>=</span> <span>A</span><span>[</span><span>B</span><span>[</span><span>'i'</span><span>],</span>     <span>1</span><span>:</span><span>6</span><span>,</span> <span>C</span><span>[</span><span>'i'</span><span>],</span>     <span>2</span><span>:</span><span>10</span><span>]</span> <span># (1)
</span><span>D</span><span>[:,:,</span><span>'i'</span><span>]</span>     <span>=</span> <span>A</span><span>[</span><span>B</span><span>[</span><span>'i'</span><span>],</span>     <span>1</span><span>:</span><span>6</span><span>,</span> <span>C</span><span>[</span><span>'i'</span><span>],</span>     <span>2</span><span>:</span><span>10</span><span>]</span> <span># (2)
</span><span>D</span><span>[</span><span>'i'</span><span>,</span><span>'j'</span><span>,:,:]</span> <span>=</span> <span>A</span><span>[</span><span>B</span><span>[</span><span>'i'</span><span>],</span>     <span>1</span><span>:</span><span>6</span><span>,</span> <span>C</span><span>[</span><span>'j'</span><span>],</span>     <span>2</span><span>:</span><span>10</span><span>]</span> <span># (3)
</span><span>D</span><span>[</span><span>'i'</span><span>,</span><span>'j'</span><span>,:,:]</span> <span>=</span> <span>A</span><span>[</span><span>B</span><span>[</span><span>'i'</span><span>,</span><span>'j'</span><span>],</span> <span>1</span><span>:</span><span>6</span><span>,</span> <span>C</span><span>[</span><span>'i'</span><span>],</span>     <span>2</span><span>:</span><span>10</span><span>]</span> <span># (4)
</span><span>D</span><span>[</span><span>'i'</span><span>,</span><span>'j'</span><span>,:,:]</span> <span>=</span> <span>A</span><span>[</span><span>B</span><span>[</span><span>'i'</span><span>,</span><span>'j'</span><span>],</span> <span>1</span><span>:</span><span>6</span><span>,</span> <span>C</span><span>[</span><span>'i'</span><span>,</span><span>'j'</span><span>],</span> <span>2</span><span>:</span><span>10</span><span>]</span> <span># (5)
</span></code></pre></div>

<p>They all do exactly what they look like they do.</p>

<p>Oh, and one more thing! In DumPy, you <strong>must index all dimensions</strong>. In NumPy, if <code>A</code> has three dimensions, then <code>A[2]</code> is equivalent to <code>A[2,:,:]</code>. This is sometimes nice, but it means that <em>every time</em> you see <code>A[2]</code>, you have to worry about how many dimensions <code>A</code> has. In DumPy, every time you index an array or assign to a <code>dp.Slot</code>, it checks that all indices have been included. So when you see option (4) above, you <em>know</em> that:</p>

<ul>
  <li><code>A</code> has 4 dimensions</li>
  <li><code>B</code> has 2 dimensions</li>
  <li><code>C</code> has 1 dimension</li>
  <li><code>D</code> has 4 dimensions</li>
</ul>

<p>Always, always, <em>always</em>. No cases, no thinking.</p>

<h3 id="3-goodbye-complicated-functions">3. Goodbye complicated functions</h3>

<p>Again, many NumPy functions have complex conventions for vectorization. <a href="https://numpy.org/doc/stable/reference/generated/numpy.linalg.solve.html"><code>np.linalg.solve</code></a> sort of says, “If the inputs have ≤2 dimensions, do the obvious thing. Otherwise, do some extremely confusing broadcasting stuff.” DumPy removes the confusing broadcasting stuff. When you see <code>dp.linalg.solve(A,B)</code>, you know that <code>A</code> and <code>B</code> have no more than two dimensions, so nothing tricky is happening.</p>

<p>Similarly, in NumPy, <code>A @ B</code> is equivalent to <a href="https://numpy.org/doc/stable/reference/generated/numpy.matmul.html"><code>np.matmul</code></a><code>(A,B)</code>. When both inputs have ≤2 or fewer dimensions, this does the “obvious thing”. (Either an inner-product or some kind of matrix/vector multiplication.) Otherwise, it broadcasts or vectorizes or something? I can never remember. In DumPy you don’t have that problem, because it restricts <code>A @ B</code> to arrays with one or two dimensions only.</p>

<p>If you need more dimensions, no problem: Use indices.</p>

<h3 id="why-remove">Why remove?</h3>

<p>It might seem annoying to remove features, but I’m telling you: <em>Just try it</em>. If you program this way, a wonderful feeling of calmness comes over you, as class after class of possible errors disappear.</p>

<p>Put another way, why remove all the fancy stuff, instead of leaving it optional? Because optional implies thinking! I want to program in a simple way. I don’t want to worry that I’m accidentally triggering some confusing broadcasting insanity, because that would be a mistake. I want the computer to help me catch mistakes, not silently do something weird that I didn’t intend.</p>

<p>In principle, it would be OK if there was a <code>evil_solve</code> method that preserves all the confusing batching stuff. If you <em>really</em> want that, you can make it yourself:</p>

<div><pre><code><span>evil_solve</span> <span>=</span> <span>dp</span><span>.</span><span>MappedFunction</span><span>(</span><span>jnp</span><span>.</span><span>linalg</span><span>.</span><span>solve</span><span>)</span> <span># not recommended
</span></code></pre></div>

<p>You can use that same wrapper to convert any JAX NumPy function to work with DumPy.</p>

<h2 id="discussion">Discussion</h2>

<p>Think about math: In two or fewer dimensions, coordinate-free linear algebra notation is wonderful. But for higher dimensional <a href="https://en.wikipedia.org/wiki/Tensor">tensors</a>, there are just too many cases, so most physicists just use coordinates.</p>

<p>So this solution seems pretty obvious to me. Honestly, I’m a little confused why it isn’t already standard. Am I missing something?</p>

<h3 id="what-about-apl">What about APL?</h3>

<p>When I complain about NumPy, many people often suggest looking into <a href="https://en.wikipedia.org/wiki/APL_(programming_language)">APL</a>-type languages, like A, J, K, or Q. (All single-letter languages are APL-like, except C, D, F, R, T, X, and many others. Convenient, right?) The obvious disadvantages of these are that:</p>

<ol>
  <li>They’re unfamiliar.</li>
  <li>The code looks like gibberish.</li>
  <li>They don’t usually provide autodiff or GPU execution.</li>
</ol>

<p>None of those bother me. If the languages are better, we should learn to use them and make them do autodiff on GPUs. But I’m not convinced they <em>are</em> better. When you actually learn these languages, what you figure out is that the symbol gibberish basically amounts to doing the same kind of dimension mashing that we saw earlier in NumPy:</p>

<div><pre><code><span>AiX</span> <span>=</span> <span>np</span><span>.</span><span>linalg</span><span>.</span><span>solve</span><span>(</span><span>A</span><span>.</span><span>transpose</span><span>(</span><span>1</span><span>,</span><span>0</span><span>,</span><span>2</span><span>,</span><span>3</span><span>),</span>
                      <span>X</span><span>[</span><span>None</span><span>,...,</span><span>None</span><span>])[...,</span><span>0</span><span>]</span>
<span>Z</span> <span>=</span> <span>np</span><span>.</span><span>sum</span><span>(</span><span>AiX</span> <span>*</span> <span>Y</span><span>[:,</span><span>None</span><span>],</span> <span>axis</span><span>=-</span><span>1</span><span>).</span><span>T</span>
</code></pre></div>

<p>The reason is that, just like NumPy and <code>vmap</code>, these languages choose align dimensions by <em>position</em>, rather than by name. If I <em>have</em> to mash dimensions, I want to use the best tool. But I’d prefer not to mash dimensions at all.</p>

<h3 id="what-about-named-dimensions">What about named dimensions?</h3>

<p>People also often suggest “NumPy with named dimensions” as in <a href="https://docs.xarray.dev/en/stable/index.html">xarray</a>. (PyTorch also has a <a href="https://docs.pytorch.org/docs/stable/named_tensor.html">half-hearted implementation</a>.) Of course, DumPy also uses named dimensions, but there’s a critical difference. In xarray, they’re part of the arrays themselves, while in DumPy, they live outside the arrays.</p>

<p>In some cases, permanent named dimensions are very nice. But for linear algebra, they’re confusing. For example, suppose <code>A</code> is 2-D with named dimensions <code>"cat"</code> and <code>"dog"</code>. Now, what dimensions should <code>A<sup>T</sup>A</code> have? (<code>"dog"</code> twice?) Or say you take a singular value decomposition like <code>U, S, Vh = svd(A)</code>. What name should the inner dimensions have? Does the user have to specify it?</p>

<p>I haven’t seen a nice solution. xarray doesn’t focus on linear algebra, so it’s not much of an issue there. A theoretical “DumPy with permanent names” <em>might</em> be very nice, but I’m not how it should work. This is worth thinking about more.</p>

<h3 id="what-about-julia-or-other-language">What about Julia or [other language]</h3>

<p>I like <a href="https://julialang.org/">Julia</a>! Loops are fast in Julia! But again, I don’t think fast loops matter that much, because I want to move all the loops to the GPU. So even if I was using Julia, I think I’d want to use a DumPy-type solution.</p>

<p>I think Julia might well be a better host language than Python, but it wouldn’t be because of fast loops, but because it offers much more powerful meta-programming capabilities. I built DumPy on top of JAX just because JAX is very mature and good at calling the GPU, but I’d love to see the same idea used in Julia (“Dulia”?) or other languages.</p>

<h2 id="prototype">Prototype</h2>

<p>OK, I promised a link to my prototype, so here it is: <a href="https://dynomight.net/img/dumpy/dumpy.py"><code>dumpy.py</code></a></p>

<p>It’s just a single file with around 700 lines. I’m leaving it as a single file because I want to stress that <strong>this is just something I hacked together in the service of this rant</strong>. I wanted to show that I’m not totally out of my mind, and that doing all this is actually pretty easy.</p>

<p>I stress that I don’t really intend to update or improve this. (Unless someone gives me a lot of money?) So please do not attempt to use it for “real work”, and do not make fun of my code.</p>

<p><em>PS.</em> DumPy works out of the box with both <a href="https://docs.jax.dev/en/latest/_autosummary/jax.jit.html"><code>jax.jit</code></a> and <a href="https://docs.jax.dev/en/latest/_autosummary/jax.grad.html"><code>jax.grad</code></a>. For gradients, you need to either cast the output to a JAX scalar or use the <code>dp.grad</code> wrapper.</p>

  </section>
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Go deep into AI/LLMs or just use them as tools? (159 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=44079303</link>
            <guid>44079303</guid>
            <pubDate>Sat, 24 May 2025 07:05:46 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=44079303">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="44079303">
      <td><span></span></td>      <td><center><a id="up_44079303" href="https://news.ycombinator.com/vote?id=44079303&amp;how=up&amp;goto=item%3Fid%3D44079303"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=44079303">Ask HN: Go deep into AI/LLMs or just use them as tools?</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_44079303">105 points</span> by <a href="https://news.ycombinator.com/user?id=pella_may">pella_may</a> <span title="2025-05-24T07:05:46 1748070346"><a href="https://news.ycombinator.com/item?id=44079303">3 hours ago</a></span> <span id="unv_44079303"></span> | <a href="https://news.ycombinator.com/hide?id=44079303&amp;goto=item%3Fid%3D44079303">hide</a> | <a href="https://hn.algolia.com/?query=Ask%20HN%3A%20Go%20deep%20into%20AI%2FLLMs%20or%20just%20use%20them%20as%20tools%3F&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=44079303&amp;auth=07b696e93f6f3e8afff09888d039e6c6971f13bb">favorite</a> | <a href="https://news.ycombinator.com/item?id=44079303">58&nbsp;comments</a>        </span>
              </td></tr>
    <tr><td></td></tr><tr><td colspan="2"></td><td><div><p>I'm a software engineer with a solid full-stack background and web development. With all the noise around LLMs and AI, I’m undecided between two paths:</p><p>1. Invest time in learning the internals of AI/LLMs, maybe even switching fields and working on them</p><p>2. Continue focusing on what I’m good at, like building polished web apps and treat AI as just another tool in my toolbox</p><p>I’m mostly trying to cut through the hype. Is this another bubble that might burst or consolidate into fewer jobs long-term? Or is it a shift that’s worth betting a pivot on?</p><p>Curious how others are approaching this—especially folks who’ve made a similar decision recently.</p></div></td></tr>        <tr><td></td></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Valve takes another step toward making SteamOS a true Windows competitor (125 pts)]]></title>
            <link>https://arstechnica.com/gaming/2025/05/valve-adds-steamos-compatible-game-label-as-it-prepares-to-expand-beyond-steam-deck/</link>
            <guid>44078930</guid>
            <pubDate>Sat, 24 May 2025 05:20:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gaming/2025/05/valve-adds-steamos-compatible-game-label-as-it-prepares-to-expand-beyond-steam-deck/">https://arstechnica.com/gaming/2025/05/valve-adds-steamos-compatible-game-label-as-it-prepares-to-expand-beyond-steam-deck/</a>, See on <a href="https://news.ycombinator.com/item?id=44078930">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                      
                      
          <p>We've known for months now that Valve is expanding its Linux-based SteamOS operating system beyond the Steam Deck to other handheld PCs, starting with <a href="https://arstechnica.com/gaming/2024/08/valves-bespoke-steam-deck-os-will-be-officially-available-on-asus-rog-ally/">some versions of the Asus ROG Ally</a>. This week, Valve began making some changes to its Steam storefront to prepare for a future when the Deck isn't the only hardware running SteamOS.</p>
<p>A new "<a href="https://steamcommunity.com/groups/steamworks/announcements/detail/532097310616717411">SteamOS Compatible</a>" label will begin rolling out "over the next few weeks" to denote "whether a game and all of its middleware is supported on SteamOS," including "game functionality, launcher functionality, and anti-cheat support." Games that don't meet this requirement will be marked as "SteamOS Unsupported." As with current games and the Steam Deck, this label doesn't mean these games won't run, but it does mean there may be some serious compatibility issues that keep the game from running as intended.</p>
<p>Valve says that "over 18,000 titles on Steam [will] be marked SteamOS compatible out of the gate," and that game developers won't need to do anything extra to earn the label if their titles already support the Steam Deck.</p>
<figure>
    <p><img width="1462" height="779" src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/steamos-compatible.png" alt="" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/05/steamos-compatible.png 1462w, https://cdn.arstechnica.net/wp-content/uploads/2025/05/steamos-compatible-640x341.png 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/05/steamos-compatible-1024x546.png 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/05/steamos-compatible-768x409.png 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/05/steamos-compatible-980x522.png 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/05/steamos-compatible-1440x767.png 1440w" sizes="auto, (max-width: 1462px) 100vw, 1462px">
                  </p>
          <figcaption>
        <div>
    
    <p>
      The "SteamOS Compatible" designation that will show up for non-Steam-Deck SteamOS users.

              <span>
          Credit:

          
          Valve

                  </span>
          </p>
  </div>
      </figcaption>
      </figure>

<p>SteamOS uses a collection of app translation technologies called Proton to make unmodified Windows applications run on SteamOS. This technology has dramatically improved SteamOS's game compatibility, compared to older SteamOS versions that required games to support Linux natively, but it still can't support every single game that Windows does.</p>

          
                      
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to Make a Living as a Writer (161 pts)]]></title>
            <link>https://thewalrus.ca/how-to-make-a-living-as-a-writer/</link>
            <guid>44078813</guid>
            <pubDate>Sat, 24 May 2025 04:36:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thewalrus.ca/how-to-make-a-living-as-a-writer/">https://thewalrus.ca/how-to-make-a-living-as-a-writer/</a>, See on <a href="https://news.ycombinator.com/item?id=44078813">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-180098">

	
	
	
	<div>
		<!-- Ad-Auris -->
		
		<p><span>W</span><span>hen people</span> ask what I do for a living, I’m faced with two choices: either I can lie or I can bore them with the truth, which is too complicated to explain succinctly. While those around me have normal, definable jobs—accountant, journalist, engineer—my work requires headings and subheadings to get it across properly: a map of overlapping gigs and contracts.</p>

<p>“What do you do?” It’s a simple question that often gets asked on first dates. No matter how much I pare down my reply, it’s always long winded.</p>
<p>“Well, I’m a freelancer,” I start, “so I have a million little jobs . . .”</p>
<p>The first of my million little jobs is what I call “Horse News.” It works like this: every weekday, I wake up at 6 a.m. and make my way to my desk, stumbling and still half asleep. I flick on an old lamp and wince as my eyes adjust to the light. I turn on my computer and use a piece of software that shows me all of the American horse racing–related news from the past twenty-four hours. It pulls up radio clips, Fox News segments, and articles from publications called <em>BloodHorse</em> or <em>Daily Racing Form</em>—anything that could be relevant to my interests.</p>
<p>I sift through countless story summaries, many of which sound fake. <em>Army Wife defeats Crazy Beautiful Woman in race! Another doping scandal emerges in Northern California! A disgraced-but-very-good trainer is no longer banned from the track! A famous YouTuber has invested millions into a betting app!</em> I compile the important stuff into a newsletter: stories about track renovations, big events, the series of horse laws that were passed, then repealed, then approved again in 2023. </p>

<p>This is a true, real thing. These laws (known as the Horseracing Integrity and Safety Act) are meant to keep racehorses and jockeys safer. Tracks are required to provide on-site vets and doctors and to follow standardized safety protocols. But it is much cheaper, it turns out, to ignore the laws and have the horses race in dangerous conditions. Vets and safety gear are expensive, which is upsetting to the billionaires who own the racetracks. And so certain states have fought these laws, calling them unconstitutional. I have followed along, every step of the way.</p>

<p>When the newsletter is finished, I send it to my client, a company that owns racetracks across the US. Though, to be clear, I don’t work for them directly. I work for a reputation management firm. This company’s entire purpose is to monitor the news for other companies, keeping tabs on what the public is saying about their clients and the major trends in those industries. I didn’t know this was a real job until I started doing it.</p>
<p>I got this job the way I’ve gotten most of my jobs: through an acquaintance who heard I was looking for work. This is key to success in freelancing. You just need to build a roster of industry connections who know how desperate you are.</p>
<p>“It’s just an hour per morning,” she told me. “Usually less.”</p>
<p>“Sure,” I said, still not understanding what I was agreeing to. “I’ll do it.”</p>

<p>The reputation management firm has a slew of different clients, each of whom wants a personalized newsletter about their industry. There’s a fast food chain, a brewery, an environmental organization. But I was assigned to the horse racing client. And so I keep up with Horse News and Horse Laws. By 7:30 a.m., the report is done, and I go back to bed.</p>
<p>Horse News makes me feel like a bad person sometimes. Racing is an odd, archaic, and often cruel sport. The more I read about it, the more convinced I become that it should not exist. I root for Horse Laws and grow sad when a state bucks them. The thing about Horse News, though, is that someone has to compile it. It might as well be me.</p>
<figure id="attachment_180108" aria-describedby="caption-attachment-180108"><a href="https://thewalrus.ca/how-to-make-a-living-as-a-writer/attachment/drolet_horsenews/" rel="attachment wp-att-180108"><img fetchpriority="high" decoding="async" src="https://walrus-assets.s3.amazonaws.com/img/Drolet_HorseNews-scaled.jpeg" data-src="https://walrus-assets.s3.amazonaws.com/img/Drolet_HorseNews-scaled.jpeg" alt="" width="1600" height="1459" data-srcset="https://walrus-assets.s3.amazonaws.com/img/Drolet_HorseNews-scaled.jpeg 1600w, https://walrus-assets.s3.amazonaws.com/img/Drolet_HorseNews-1536x1401.jpeg 1536w, https://walrus-assets.s3.amazonaws.com/img/Drolet_HorseNews-2048x1868.jpeg 2048w" data-sizes="(max-width: 1600px) 100vw, 1600px" srcset="https://walrus-assets.s3.amazonaws.com/img/Drolet_HorseNews-scaled.jpeg 1600w, https://walrus-assets.s3.amazonaws.com/img/Drolet_HorseNews-1536x1401.jpeg 1536w, https://walrus-assets.s3.amazonaws.com/img/Drolet_HorseNews-2048x1868.jpeg 2048w"></a><figcaption id="caption-attachment-180108">Cartoon by Garbrielle Drolet</figcaption></figure>
<p><span>I</span><span> got the</span> offer to do Horse News not long after I moved to Montreal, at a time when I needed work more than ever.  </p>
<p>I was twenty-four and a full-time adult now, tasked with the question of how I planned to fill my time and make a living. </p>
<p>A year and a half earlier, when I’d finished my undergraduate studies in English and creative writing, I had immediately enrolled in another creative writing program. I wish I could say this was entirely because I was devoted to my craft or that it was my life’s dream to write a book, but that’s only a small part of the truth. The main reason I joined a master’s program was that I didn’t want to face what life would look like once I was no longer a student.</p>
<p>As I’d gotten closer to finishing my undergrad, I kept getting asked what came next. For years, the question “What are you going to do when you grow up?” had been answered the same way: I’m going to be a writer. This was an answer that adults found cute when I was a child and concerning as I got older. A writer, they echoed, mulling the word over slowly. <em>Interesting</em>. By the time I got to university, it was an answer that felt downright unacceptable. Sharing dreams about writing for a living elicited looks of mingled confusion and pity. <em>A writer?</em></p>
<p>I understood that being a writer was fraught. I understood that it was a hard way to make a living. There were no jobs in the industry, and books didn’t sell for as much as they used to. And so the question of what I wanted to do after graduating was one that made me physically sick, because I didn’t know what being a writer meant either.</p>
<p>So I decided the solution was grad school. If anyone dared to ask me what I was doing after that, I could shrug and tell them I had a few more years to think about it.</p>
<p>My plan worked for a year, though not exactly as expected. </p>
<p>First, the pandemic hit, and I moved to Nova Scotia with my now ex-girlfriend. Then, I became disabled. </p>

<p>I developed a nerve condition that became chronic. Pain had spread through my neck, my arms, my hands. When it first started, I couldn’t type at all. I had to re-adjust every aspect of my life: how I cooked, how I brushed my teeth, and how I worked. </p>
<p>By my second year in the program, I had moved to Toronto, but I was still struggling with voice-to-text and barely able to keep up with basic assignments. The thought of writing a thesis—an entire book—felt impossible. I was also writing freelance articles on the side to help pay my rent, and I simply couldn’t do both, mentally or physically. Forced to choose between work and school, I chose work. So I took medical leave, saying I would return in a year but unsure if I actually would.</p>
<p>Leaving school meant I had to face the question of who I was if I wasn’t a student—much earlier than anticipated. Without a schedule filled with classes to attend and readings to do, I was just a person with an empty calendar and one and a half arts degrees.</p>
<p>“What’re you going to do now?” a friend asked over beers at a Mexican restaurant in downtown Toronto. </p>
<p>I dragged a chip through guacamole. “I don’t know, to be honest. I mean, I’ll work, obviously.”</p>
<p>“I’m sure you could get an office job somewhere,” she said. “Or go back to being a barista, maybe.”</p>
<p>People kept suggesting jobs to me like this: Why don’t you just become a barista? A cashier? A secretary? Every time, it was a sharp reminder of how little they understood my physical limitations. <em>I’m too disabled for that</em>, I wanted to say.</p>
<p>I held my tongue, but it was true. My pain was so crippling at this point that I struggled to perform basic tasks around the house. I knew I was no longer able to do most of the jobs I’d had in high school or when I was an undergrad: I couldn’t work as a barista, my forearms too weak to tamp down espresso grounds; nor in retail, nor as a waitress, as the weight of my own dinner plate at home was enough to make me wince with pain. </p>
<p>As I scrolled through job postings for office work, I knew a nine-to-five wasn’t feasible either. I needed the kind of flexibility a job like that wouldn’t allow: the ability to take long breaks when I was in too much pain, to shift deadlines, to use tedious and time-consuming adaptive technology. Back then, I was in so much pain that I could barely use a mouse, commanding my entire computer with my voice. <em>Open Google Chrome. New tab</em>. Copy that. Paste that. In addition to being annoying in an office setting, it just wasn’t fast enough.</p>
<p>“I think I’ll just write,” I told my friend. “Like I’ve been doing, but full time.”</p>

<p>She blinked at me. “Will that be enough?”</p>
<p>I understood the question. I’d enjoyed the freelance writing I’d done, mostly penning articles about health and pop culture for Canadian outlets and the odd American one. It paid poorly and inconsistently.</p>
<p>For a long time, I’d thought of this freelance work as a stepping stone to a real job as a writer or an editor, with a salary and benefits. Now it seemed like going all in on freelancing was my only real career option. It was the only way, I thought, that I could truly work on my own schedule and tend to my needs without falling short of employer expectations.</p>
<p>“I’ll manage. It’ll work out, I’m sure of it.” I’d never been less sure of anything.</p>
<p>In the following weeks, I launched myself into freelancing, pitching an endless stream of articles and essays to my editors. I was lucky to have a few people who championed my work and encouraged me to send them my ideas. I’d never met any of them in person, which was strange; they felt fake to me, just email addresses that provided me with opportunities and paycheques. There had been even more in the past—editors I’d worked with and felt comfortable reaching out to—but many had faded away, either leaving the industry or simply starting to ignore my emails. </p>
<p>As I started writing more freelance pieces, I was, in a way, living the life I’d always wanted. I was a writer. It was my actual job. I balanced deadlines, rotating between articles and editors. I sent out more and more pitches. I worked late into the night, fuelled by instant coffee and bad music.</p>
<p>It wasn’t enough. The number of pitches I was landing couldn’t comfortably sustain me. And it often took ages for me to get paid for my work. A fully written article might be put on hold—it would sit and collect virtual dust, and I wouldn’t be paid until it was published. I knew I needed more consistent work. I longed for some sort of paycheque I could rely on month to month. My savings dwindled as I paid for rent, pricey physiotherapy appointments, and adaptive tools. I moved to Montreal, where the cost of living was lower, but I still struggled to get by.</p>
<p>This was when Horse News entered my life. As I settled into my new city, I was shown the ropes of this strange job: how to use the monitoring software, how to identify stories worth including in the newsletter, who the big players in Horse World were. I was promised hourly pay, with a lump sum deposited into my account at the end of each month. And I suddenly became aware of the possibility of odd jobs that were writing adjacent—the kind of unglamorous work that would pay the bills while allowing me to keep writing on my own schedule. </p>
<p><span>I</span><span>n the coming</span> months, other odd jobs entered and exited my roster. I wrote Instagram captions for a hospital foundation. I wrote online content for a bank (which always paid me late and said it was because they couldn’t figure out how to transfer the money, which made me grateful they were not my bank). Importantly, I wrote a column where I recapped episodes of <em>The Bachelorette</em>. I was constantly writing some odd articles for different publications. Throughout all of this, Horse News was the only stable work I had. Every weekday, without fail, the horses raced on, and I compiled my newsletter.</p>
<p>As new opportunities presented themselves, I found myself unable to say no to work. No matter how busy I was or how strange the job was, I accepted every single offer that came my way, worried the gigs would eventually dry up.</p>

<p>In early summer, as Montreal’s unbearably cold season gave way to an unbearably hot one, I got a text from a friend. She worked at a major Canadian newspaper, which, she said, wasn’t paying her enough. She’d taken on a side gig to compensate for the poor salary. She’d heard I was looking for work and thought I might be interested.</p>
<p>“What is it?” I texted.</p>
<p>“Writing erotica,” she answered.</p>
<p>The next week, I had a Zoom meeting with someone who worked at the company. She was young, in her late twenties, with pink cheeks and glossy blonde hair. She explained that she needed writers for an app she was running that was like a choose-your-own-adventure story, only hornier. Users, mostly women, would select a story and start reading. They were all written in the second person, placing users in the protagonist’s shoes: “You walk into a restaurant . . . You see a hot guy sitting at the bar . . . What will you do next?” They were then presented with two choices.</p>
<p>One would be boring (ignore the guy!), and the other would be depraved (ask him to go back to your place and [redacted]!). Choosing depravity cost $0.99.</p>
<p>These stories were long, most of them basically novels.</p>
<p>New chapters came out every week, each instalment getting increasingly risqué. This was a business strategy: users became invested in a story and were then charged money to read the new material.</p>
<p>“Do you think you’d be able to keep up with it?”</p>
<p>“I think so.”</p>
<p>I agreed to write one or two chapters per week. Each would be around 4,000 words long, and the story would ultimately have at least twenty chapters. I would get paid $120 (US) for each chapter.</p>

<p>If I had done the math or thought about this critically, I’d have realized this was a very bad idea. It was a monumental amount of work and creative energy to expend for pretty poor pay, especially as someone who couldn’t type much. Unfortunately, I was distracted by how fun the work sounded. Like many young women who grew up with the internet, I had lived through the days of reading whatever perverted and poorly written erotica I could find about my favourite fictional characters online. The prospect of now becoming a professional erotica writer was too enticing to turn down. Plus, if my friend was balancing full-time newspaper work with this, how hard could it be?</p>
<p>The woman who would become my editor nodded.</p>
<p>“The categories that perform best right now are domination, stepbrother, and campus stuff. You know, student–teacher situations?” She looked through a printout of figures. </p>
<p>“Vampire and werewolf stories are making a resurgence too.”</p>
<p>I jotted this down in a notebook, my handwriting messy and quick. <em>Campus, werewolf, domination</em>. “Got it.”</p>
<p>“By the way, the app store won’t let us use the words penis, vagina, or cock,” she said flatly.</p>
<p>“Oh,” I said. “Why not?”</p>
<p>“Terms of service stuff.”</p>
<p>“Got it.”</p>
<p>“Read a few of the stories for inspiration on how to work around this. You’ll get the hang of it.”</p>

<p>“Right.”</p>
<p>“People get really creative. Fruit works, sometimes.”</p>
<p>“Fruit?”</p>
<p>“You’ll see what I mean,” she said. “And you’ll need a pen name. Unless you want to use your own?”</p>
<p>I shook my head. “I’ll find a pen name.”</p>
<p>That afternoon, I sat on my friends’ balcony. I told them about my new job, which would somehow slot in alongside all the other jobs I was doing. It was one of the first truly warm days of summer, and we were determined to spend the entire thing outside. Between sips of iced coffee, we plotted out my story chapter by chapter, my friends enthusiastic about its trajectory.</p>
<p>“Maybe she can hook up with her roommate?” I suggested.</p>
<p>“Yes, that’s great,” John said. “Make it a love triangle.”</p>
<p>He dragged a finger through the air, drawing a triangle.</p>
<p>“I can’t believe you’re writing porn,” Maria said, leaning back in a wooden folding chair. “How fun.”</p>

<p>“Not porn. Erotica.”</p>
<p>“Same difference,” John said. He pulled the notes I’d scrawled toward him and squinted. “Okay, what happens next?”</p>
<p>By the end of the day, John and I had plotted out an entire story arc: the student and the TA’s tumultuous affair, the way they were almost found out, the forces that almost pulled them apart. Ultimately, love and sex brought them back together.</p>
<p>“This is basically an entire romance novel,” John said.</p>
<p>“Smuttier, though.”</p>
<p>“Of course.”</p>
<p>“And worse.”</p>
<p>Maria spent the day brainstorming pen-name ideas, which she would occasionally pipe up to suggest. “Madame Scarlett?” “Delilah Rose?” “Candy Mae?” “Jolene Fox?” “What kind of vibe are you looking for, anyways?”</p>
<p>Now, my days looked like this: I woke up at 6 a.m. and did Horse News; I hammered out whatever freelance writing assignment I was working on; I wrote erotica; I ended my workday around 5 p.m., tired and achy.</p>
<p>In the coming months, I sat in my hot, not air-conditioned apartment, sweating and damp, and wrote between 3,500 and 8,000 words of smut per week. Since I was doing this with voice-to-text, I had to keep my windows closed, mortified at the thought of my neighbours hearing me speak vile things into my computer: words like member, length, girth, and sometimes the names of fruit.</p>

<p>I worked on one story throughout the whole summer.</p>
<p>On weeks when, for whatever reason, I couldn’t keep up—say, my hands were worse than usual or I got too busy with other work—my boss at the app was understanding.</p>
<p>“Your health is more important than this,” she would say. <em>Rest</em>. It was the most compassion I’d ever gotten from an employer, which was nice but also annoying. Part of me hoped to be fired, freed entirely from my contract. But no—these people were, unfortunately, sweet and thoughtful.</p>
<p>Within a few weeks, I had come to hate the work. Though it was fun in the beginning, it quickly lost its charm, the sex scenes becoming tedious and exhausting once they were no longer new to me.</p>
<p>“There are only so many ways to write ‘they had sex,’ you know?” I told Maria one day.</p>
<p>She shook her head. “I really don’t.”</p>
<p>The biggest problem was just that I was overworked. Writing that much sapped all of my creative and physical energy, leaving me unwilling or unable to write much else.</p>
<p>When I neared the final chapter, my friends and I sat around with a bottle of wine and celebrated the fact that my life as an erotica writer was almost done. They suggested words and phrases I should try to sneak into the final chapter as a little personal challenge: cornucopia, sledgehammer, pumpernickel, Seinfeld, Donna Tartt, the Watergate scandal.</p>
<p>Maria squinted at John. “That last one is too silly,” she said. “She won’t be able to manage it.”</p>
<p>“Have faith,” I said.</p>

<p>I managed them all, laughing along the way as I tweaked the story to include them.</p>
<p>By the time it was done, I’d written over 70,000 words of smut. My editor asked if I wanted to renew my contract, and I declined. She insisted, saying we could alter the work schedule, maybe even up my pay by another $5 per chapter.</p>
<p>My story, she revealed, was gaining a devoted following, quickly becoming one of the most popular on the app. This felt nice—my anonymous magnum opus. Still, I said no.</p>
<p>As time passed in Montreal and I did more odd jobs, my hands got marginally better. This meant that, as long as I was very careful and worked within a strict set of limitations, there was one more type of work that became available to me again: cartooning.</p>
<p>I’d loved drawing since I was a kid. Growing up, I drew countless pictures of animals (especially birds), carefully copying them from the books I begged my mom to buy me.</p>
<p>When my pain first started in 2021 and I realized I would have to take a months-long break from drawing, it was a particularly tough blow. Drawing wasn’t as big a part of my income or my identity as writing was, but it still mattered to me immensely. What felt worse was the fact that, a month before I lost the ability to draw, I’d sold my first cartoon to <em>The New Yorker</em>—an accomplishment I’d worked toward for years, and which I worried I might never be able to repeat.</p>
<p>Now, in my very ergonomic home office, I could draw again (though I needed to set a timer beforehand to make sure I didn’t work for more than twenty minutes at a time).</p>
<p>When the timer went off, I’d stand and stretch and take a break. I limited the number of projects I took on so I wouldn’t overdo it. However, every now and then, I pitched a cartoon to <em>The New Yorker</em> or accepted a commission request for a portrait of someone’s dog.</p>
<p>Cartooning became a very small part of the tapestry of odd jobs that came together to make up an income. But it was one I was happy to be able to include.</p>
<p><span>O</span><span>n dates</span>, I try to condense this all into a short spiel. <em>I’m a writer. I do Horse News. I’m a copywriter. I also draw cartoons, sometimes, but that’s neither here nor there. Even this has omissions, but it’s the best I can do</em>.</p>

<p>“Wouldn’t you rather just have a normal job?” one date—a lawyer—asked.</p>
<p>It’s something I’ve wondered myself. Sometimes, looking at overlapping assignments and deadlines on my Google calendar, I feel overwhelmed and exhausted. But when I’m in pain, I can take a break in the middle of the day or even go back to bed if I need to.</p>
<p>“This suits me best,” I said.</p>
<p>I ended that date early, as I do with all weekday dates. I have a great excuse: <em>Horse News is due at 7:30 a.m. tomorrow morning</em>.</p>
<p><em>Excerpted from</em> <a href="https://www.penguinrandomhouse.ca/books/760991/look-ma-no-hands-by-gabrielle-drolet/9780771019142">Look Ma, No Hands</a> <em>by Gabrielle Drolet. Copyright © 2025 Gabrielle Drolet. Published by McClelland &amp; Stewart, a division of Penguin Random House Canada Limited. Reproduced by arrangement with the publisher. All rights reserved.</em></p>
<!-- AI CONTENT END 1 -->
		<div id="sexy_author_bio_widget-2"><p><a href="https://thewalrus.ca/author/gabrielle-drolet/" target="_top"><img alt="Gabrielle Drolet" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2070%2070'%3E%3C/svg%3E" data-src="https://secure.gravatar.com/avatar/80380f26cd399c63cc449337051d117b?s=70&amp;d=mm&amp;r=pg" data-srcset="https://secure.gravatar.com/avatar/80380f26cd399c63cc449337051d117b?s=140&amp;d=mm&amp;r=pg 2x" height="70" width="70" decoding="async"></a></p><p>Gabrielle Drolet is a Montreal-based writer and cartoonist whose work has appeared in the <em>New York Times</em>, the <em>Globe and Mail</em>, <em>The New Yorker</em>, and other publications.</p></div>	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

		
</article></div>]]></description>
        </item>
    </channel>
</rss>