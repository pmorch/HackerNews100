<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 17 Jul 2024 02:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[DevRel at HuggingFace (141 pts)]]></title>
            <link>https://dx.tips/huggingface</link>
            <guid>40979221</guid>
            <pubDate>Tue, 16 Jul 2024 18:56:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dx.tips/huggingface">https://dx.tips/huggingface</a>, See on <a href="https://news.ycombinator.com/item?id=40979221">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-content-parent"><blockquote>
<p>Following the <a target="_blank" href="https://dx.tips/zirp">ZIRP DevRel</a> post, the community has had many great discussions on where devrel needs to go next. DXTips exists to share this tacit niche industry knowledge. <strong>DX@X</strong> is our new async interview series we are starting with DevRel leaders to get more perspectives on the state of the art in DX and DevRel. We're excited to kick it off with <strong><a target="_blank" href="https://x.com/osanseviero">Omar Sanseviero</a>, Chief Llama Officer at HuggingFace</strong>!</p>
<p>HuggingFace is well known for being incredible stewards of the open source ML community, building critical infrastructure at hypergrowth (growing from 780k to 2.3m repos on the HF Hub in the past year) and doing so <a target="_blank" href="https://analyticsindiamag.com/ai-news-updates/hugging-face-announces-profitability-with-free-and-open-source-models/">profitably</a>. They are also a rare startup whose large online community also translates to <a target="_blank" href="https://x.com/search?q=huggingface%20woodstock&amp;src=recent_search_click&amp;f=top"><em>massive</em> multi-thousand people meetups</a> all <a target="_blank" href="https://x.com/search?q=huggingface%20station%20f&amp;src=typed_query&amp;f=top">over the world</a>.</p>
<p><strong>Request for Suggestions: Who else would you like to hear from? Let us know on <a target="_blank" href="https://x.com/dxtipshq">X/Twitter</a> and join our <a target="_blank" href="https://dx.tips/newsletter">Newsletter</a> to get the next issue!</strong></p>
</blockquote>
<h2 id="heading-introduction-to-omar-and-huggingface">Introduction to Omar and HuggingFace</h2>
<blockquote>
<p><strong>Intro:</strong> <em>Hey Omar! Let’s assume people know the surface level of HuggingFace - it’s the largest AI community which collaborates on open source models, datasets, and applications, with paid compute and enterprise solutions. What does a Chief Llama Officer do at HF?</em></p>
</blockquote>
<p><a target="_blank" href="https://x.com/osanseviero/media">Memes</a>! More seriously, my title might translate to “<strong>Head of Platform and Community</strong>” at another company, although the scope of what I do is quite broad. There are two aspects to my role:</p>
<ul>
<li><strong>Leadership</strong>: Within HF, my role involves horizontal and vertical leadership. Vertically, I direct a family of teams (Dev Advocacy Engineering, On-device ML, Moonshot Factory, Argilla - our most recent acquisition). Horizontally, our team sits at the intersection of Open Source, Product, and the external community (+ sometimes research). In my day-to-day, I aim to identify high-impact potential areas, connect dots across teams at HF and the community, and unblock people to succeed.</li>
<li><strong>IC</strong>: HF has a very bottom-up leadership culture. This, combined with a meeting-less async culture (<a target="_blank" href="https://x.com/mervenoyann/status/1692111147783143751">example</a>, <a target="_blank" href="https://x.com/SashaMTL/status/1773344913502929014">example</a>, <a target="_blank" href="https://x.com/osanseviero/status/1573055162070999061">example</a>, <a target="_blank" href="https://www.hbs.edu/faculty/Pages/item.aspx?num=63185">old HBS case study</a>), allows folks in leadership positions to dedicate significant time to technical and meaningful contributions to different projects. A significant part of my role involves collaborating with partners to release new models, such as the latest Llama and Gemma models. Each release is unique, intense, and fun, and I quite enjoy being deeply involved in the entire process.</li>
</ul>
<blockquote>
<p><strong>Followup</strong>: <em>What do you think is under-appreciated about HF’s open source work?</em></p>
</blockquote>
<p>Hugging Face is a community-centric company. It's hard to exaggerate how community-centric we are. Some examples:</p>
<ul>
<li>We prioritize giving the spotlight to community members and collaborators as much as possible.</li>
<li>Provide compute and no-strings-attached cash grants (including but not limited to <a target="_blank" href="https://www.theverge.com/2024/5/16/24156755/hugging-face-celement-delangue-free-shared-gpus-ai">the $10m ZeroGPU program</a>) to community members/communities (for example, in the past, Eleuther, Boris from Dall-e Mini, and lucidrains have been sponsored by HF, allowing them to keep doing their cool work without financial constraints).</li>
<li>Help maintain open-source libraries (eg <a target="_blank" href="https://github.com/UKPLab/sentence-transformers">sentence transformers</a> and <a target="_blank" href="https://github.com/bitsandbytes-foundation/bitsandbytes">bitsandbytes</a>) from other groups and closely collaborate with other tools (eg <a target="_blank" href="https://github.com/EleutherAI/lm-evaluation-harness/tree/main">LM Eval Harness</a> and <a target="_blank" href="https://github.com/mlfoundations/open_clip">OpenCLIP</a>)</li>
</ul>
<p>Our approach to working with other groups and open-source platforms and libraries is always collaborative. We view ourselves as "the Switzerland" of the ML community, actively contributing to and supporting the ML ecosystem. We want the community to be successful and grow the pie.</p>
<p>So, one aspect of HF that I think is underappreciated is the extent of the support and collaboration with the community. Many see the outputs—like models and libraries—but might not realize the significant behind-the-scenes effort that the team puts into fostering the thriving ecosystem.</p>
<h2 id="heading-devrel-at-huggingface-metrics-and-velocity">DevRel at HuggingFace: Metrics and Velocity</h2>
<blockquote>
<p><strong>Credibility/Success:</strong> <em>What are some “real” metrics that you track that point to HF’s devrel success?</em></p>
</blockquote>
<p>DevRel comes in all kinds of flavors in the industry. Some DevRel teams are part of a marketing function, and some are within a monetization-team function. At Hugging Face, DevRel sits between the open-source and product organizations and is primarily an engineering function.</p>
<p>This means <strong>HF DevRel's goal is to see increased usage of the Hub platform and open-source tools</strong> rather than focusing on revenue as our primary goal. Two of our north stars are the <strong>number of repositories on HF and logged-in usage of the Hub</strong> platform. For example, the Hub has 2.3 million repositories today, compared to 780k repositories a year ago. (Of course, we can look at everything with more granularity, e.g., the number of Spaces, which grew from 187k in June last year to 650k this year).</p>
<p><img loading="lazy" src="https://gist.github.com/user-attachments/assets/ca97fe47-127d-4bc6-9d05-b4f2c0fdf863" alt="image"></p>
<p>Each team member works on different topics (e.g., Computer Vision, Audio ML, ML for 3D CV, etc.), so we jointly define some metrics that we would like to see move based on our efforts. <strong>We prioritize usage-based</strong> (number of repos, downloads, installs) <strong>over visibility-driven</strong> (GitHub stars, Twitter likes, views), which are also valuable but not the main motivation of our work.</p>
<p>That said, I'm skeptical of cultures that overemphasize metrics (of course, this is nuanced and depends on a lot of context). From my experience at Google and looking at other startups, I've seen the downsides of measuring too much too early. Metrics are an imperfect proxy for impact and are game-able. <strong>Cultures prioritizing metrics above all risk losing sight of user needs and making wrong decisions</strong> (e.g., to improve metrics for their performance review rather than genuine user benefit). Some DevRel activities might not have immediate metric changes but have long-term impact.</p>
<p>One of the most rewarding moments was after two years of building connections with Spanish-speaking folks, we <a target="_blank" href="https://platzi.com/blog/ayuda-a-mejorar-los-llm-en-espanol-en-7-sencillos-pasos/">initiated</a> an exciting Alpaca translation effort involving Argilla, Platzi (a Colombian edtech), and many community super-users. This 'Avengers assemble' moment is becoming more frequent as we foster stronger relationships with practitioners, communities, and organizations. Examples of these are <a target="_blank" href="https://x.com/_lewtun/status/1778429536264188214">Zephyr ORPO</a> (KAIST + HF + Argilla), <a target="_blank" href="https://huggingface.co/blog/4bit-transformers-bitsandbytes">QLoRA</a> (University of Washington), and the very recent <a target="_blank" href="https://huggingface.co/blog/winning-aimo-progress-prize">AI Math Olympiad winner</a> (NuminaM + HF).</p>
<blockquote>
<p><strong>DevRel @ HF:</strong> <em>What was your reaction to <a target="_blank" href="https://dx.tips/zirp">the ZIRP DevRel article</a>? What’s different at HF?</em></p>
</blockquote>
<p>As mentioned before, DevRel comes in all kinds of flavors. There were things that I could relate to. Specially two points:</p>
<ul>
<li>I'm a bit skeptical of the impact of traveling to conferences. While conferences can be impactful if approached strategically, the highest impact usually doesn't come from giving a talk. Instead, it's often the connections made and behind-the-scenes collaborations which require a different mindset. We support conference travel (and people do that a lot), but we encourage team members to attend with an impact-driven mindset, ready to achieve some concrete things beyond attending an event.</li>
<li>Lack of OKRs. <strong>We do not have OKRs</strong>. The ML ecosystem moves incredibly fast, so we need to be nimble and action-driven. Gemini Nano was added to Chrome? Let's figure out how to run it and <a target="_blank" href="https://x.com/xenovacom/status/1810356703826977183">release some docs</a>. Model 504B is coming out next month; let's make sure it's usable by the community. Although exciting, this comes with cons: priorities can and will change, planning becomes challenging, and maintaining focus can be difficult in the chaos of the current ML space.</li>
</ul>
<p>That said, I think HF DevRel has been successful overall for a couple of reasons:</p>
<ul>
<li>It's an <strong>engineering-centric</strong> function. Day-to-day activities might involve fine-tuning models to get a training script right, collaborating on a research project, or finding out why a model is not quantizing well to 4 bits. Our users are engineers and researchers, so it's essential that we are in their world to understand them.</li>
<li>It's a <strong>decentralized</strong> function. Although we have a dedicated DevRel team, <strong>everyone at HF is expected to do activities usually associated with DevRel</strong>. Although we have a DevRel team, everyone at HF, from research to success engineers, is involved in doing DevRel-like activities themselves, so you'll see everyone engaging in social media, creating content (youtube, blog posts, etc), giving presentations, etc. If you build a feature/tool, you're responsible of its visibility and growth (of course, with support/guidance from others). Marketing your own work could involve writing a blog post or a technical deep dive, crafting some beautiful notebooks, and yes, sometimes making memes. If you visit <a target="_blank" href="https://huggingface.co/blog">HF blog</a>, you'll see content from all across the company. Rather than "outsourcing" these responsibilities to a third team (either a marketing or a DevRel team in many companies), HF members are encouraged and expected to own their work, end to end. <a target="_blank" href="https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1">FineWeb</a> is an amazing example of how this can be successful.</li>
</ul>
<p>The two points combined lead to very genuine and scalable relationships. Rather than a competitive culture, we've fostered a culture in which people are excited to collaborate both internally and externally and ready to amplify the amazing work being done by the community.</p>
<blockquote>
<p><strong>Followup question on DevRel Velocity:</strong> <em>I notice that OKRs very rarely prioritize moving fast. What has worked/not worked in encouraging your team members to move fast (other than the obvious intrinsic motivation)?</em></p>
</blockquote>
<ul>
<li><strong>What works well</strong>: Beyond intrinsic motivation, which is indeed a strong factor, collective momentum plays a big role. Being surrounded by a group of smart, driven individuals working on the latest ML advancements creates an environment where progress is both expected and contagious. This collaborative atmosphere builds some sense of urgency and encourages everyone to push forward together.</li>
<li><strong>What does not work well</strong>: On the flip side, a lack of structured planning and clear OKRs can affect some people. While flexibility is desired a lot in the industry, it can lead to ambiguity and confusion about expectations, making it harder for new team members to get up to speed quickly. This can result in onboarding challenges and potential mismatches in cultural fit. Each team is a bit different, but there's a balance between agility and more structured goal-setting that can help everyone thrive.</li>
</ul>

<blockquote>
<p><strong>Open Source Engineering and Community:</strong> <em>HF maintains a -lot- of open source work, and only (~200?) employees. How do you organize the different projects you work on, and how does the community engagement work?</em></p>
</blockquote>
<p>Yes, we're a relatively small team (215 persons), and maintain a large number of libraries ourselves: demos (Gradio), data (datasets, Argilla, distilabel), modeling (transformers, diffusers, timm, peft, Candle, tokenizers, accelerate, parler TTS, transformers.js), production (TGI and TEI), and research related (lerobot, alignment handbook), plus support community libraries (bitsandbytes and sentence-transformers and others as mentioned above).</p>
<p>There are some key strategies that have worked well for us</p>
<ul>
<li><strong>Strong async culture</strong>. We mostly communicate through Slack and GitHub, enabling collaboration across different projects. This fosters transparency, allowing everyone to gain visibility into other projects.</li>
<li><strong>Flexible organizational and role boundaries.</strong> The organizational structure is flexible, allowing people from different teams to contribute where needed. For example, when we were preparing for Llama 2 release, people from all kinds of teams contributed to make sure the model was in good shape and usable by the community. It's quite powerful to see different teams working organically to make things happen without having to go through bureaucracy or process management.</li>
<li>(other points mentioned above, such as being collaboration and community centric)</li>
<li><strong>Pragmatic</strong>. Let me dive into this one more in the next point :)</li>
</ul>
<blockquote>
<p><strong>Prioritization:</strong> <em>There’s a lot of interesting directions in ML and only so much time/resources. How do you decide -what- to invest in? And what to cut? Because you're decentralized - what do managers decide vs leave to ICs?</em></p>
</blockquote>
<p>That's a great question and likely one of our biggest challenges. As you said, there are many interesting directions, and the ecosystem is changing quickly. We see new players, from new libraries and startups to new organizations releasing models.</p>
<p>In general, I like to apply the concept of exploration/exploitation from Reinforcement Learning. This involves two main stages:</p>
<ol>
<li><strong>Exploration</strong>: We do small projects or comms to gauge their potential impact and community interest. This allows us to experiment without having too many people working on it or committing lots of time.</li>
<li><strong>Exploitation</strong>: Based on the knowledge gained from the exploration stage, we focus our efforts on things we are more confident will have a significant impact. This involves scaling up successful projects and allocating more resources to areas with proven value.</li>
</ol>
<p>Of course, it's never as simple as that (the ϵ is variable), and it's usually cyclical (exploration -&gt; exploitation -&gt; exploration), but it's a good mental framework to have. Some projects are heavy in exploration by nature (for example, exploring a very niche domain or community), and others might require a larger time investment (which tends to happen in research-oriented projects).</p>
<p>The second point, related to the above, is pragmatism. That means being willing to pause or stop projects if they aren't having the expected impact. For example, investing days to make a YouTube video with a few hundred views may not be a worthwhile investment unless it leads to some very valuable or targeted outcome. It can be sad to spend some weeks building an open-source library and then see no engagement or adoption. What is worse, however, is to keep pushing and pushing for a tool that might lack product-market fit.</p>
<p>Failure is a part of the process for all of us. The key is to learn from it, understand what went well and what didn't, and know when to pivot or stop. This pragmatic approach helps us stay focused on what truly matters.</p>
<blockquote>
<p><strong>Followup Question:</strong> <em>Let’s apply Explore-Exploit. Just to pick on a specific, visible example that has caught my (swyx’s) eye recently, <a target="_blank" href="https://x.com/reach_vb/">VB (Vaibhav)</a> has staked out a very notable position as “the audio guy” on AI Twitter. Always the first to have great takes on anything in audio, shipping insanely-fast-whisper and the TTS Arena, and goodness knows what else I don’t even know about. He of course also does <a target="_blank" href="https://x.com/reach_vb/status/1806343018640781675">other open source AI work eg on LLMs</a>. Was there a top down decision to focus on Audio? It must have been… But I’m also equally sure that audio doesn’t drive nearly as much revenue for HF as, say, LLMs or Diffusion models (Apolinario). So… great hire, but how did you decide to invest in audio in the first place? Is there any calculation driven by the GTM/Product/Sales side of HF?</em></p>
</blockquote>
<p>It might sound surprising, but audio (with VB) was a very validated area we wanted to invest in, while diffusion/art (<a target="_blank" href="https://x.com/multimodalart">Poli</a>) was a very experimental area.</p>
<p><img loading="lazy" src="https://gist.github.com/user-attachments/assets/56f995f4-8f48-467f-9463-2d4582e1f730" alt="image"></p>
<p><strong>For audio</strong>, back in 2022, we saw a significant wave of OS libraries (SpeechBrain, ESPNet, Asteroid, etc) and interesting research (Whisper, XLS-R by Meta, etc). We were actively organizing community sprints with free GPUs to help people fine-tune speech recognition models in their languages. There was a lot going on that led to the decision to hire a DA for the role (apart from the MLE in the open source team already working on the topic). VB was working in audio in his masters and had already engaged with us through different efforts. Despite being somewhat junior in the open ML space, his <strong>very</strong> strong alignment with the open ML culture and mindset allowed him to scale his impact. Since joining, VB has expanded beyond audio, leading different collaborations and integrations, including recent work with Georgi on llama.cpp. Now, VB is even <a target="_blank" href="https://x.com/reach_vb/status/1810977320275943852">hiring an intern</a> to support the ML ecosystem for audio!</p>
<p><img loading="lazy" src="https://gist.github.com/user-attachments/assets/030763e7-ce88-4cab-9371-4120525f1461" alt="image"></p>
<p><strong>For diffusion/art</strong>, Poli was our first Moonshot MLE hired to make "ML for art as accessible and open source as possible." This was before the hype around Stable Diffusion. We hired him because of his strong cultural alignment, his contributions to early HF Spaces and him being a Gradio super-user. At that time, while more experimental, the impact on Spaces and the potential of diffusion models (like latent diffusion by CompVis) showed promising signs. As a power (and somewhat early) user for Spaces, he also brought lots of product ideas on making Spaces more successful.</p>
<p>In summary, our decision to invest in audio was based on clear community and research validation as well as growth potential. In contrast, MLxArt was a more experimental exploration that showed early impacts and ended up being a very high impact area.</p>
<p>Sometimes both intercept! Talking about AI x music <a target="_blank" href="https://x.com/iamwill/status/1696546638863749154">with will.i.am</a> is definitely a highlight of last year.</p>
<p><img loading="lazy" src="https://gist.github.com/user-attachments/assets/655f586e-61f1-471c-a4d2-20c44ec621ec" alt="image"></p>

<blockquote>
<p><strong>Open Questions:</strong> <em>What are you looking for help with? What questions do you want answered that would help you get to your “next level” (whatever that means to you)?</em></p>
</blockquote>
<p>Hugging Face's core audience has traditionally been people with ML experience, but we've seen more and more <strong>developers without an ML background who want to incorporate ML into their projects or learn about ML</strong>. These developers often feel overwhelmed by the complexity of ML and the speed of the ecosystem. While the community has introduced new tools and APIs to simplify things, and we have exciting features coming soon, there's still much to be done to lower the entry barriers further. I'm looking for <strong>insights and suggestions on how we can make our tools even more accessible to non-ML developers</strong>. (<em>Editor: some might call these <a target="_blank" href="https://www.latent.space/p/ai-engineer">AI Engineers</a>?</em>)</p>
<p>Additionally, <strong>we're expanding our team and are looking for individuals with strong developer empathy and technical skills based in the Bay Area</strong>. If you're interested or know someone who might be, <a target="_blank" href="https://x.com/osanseviero">please reach out</a>!</p>
<blockquote>
<p><strong>Request for Startups/Tools:</strong> <em>You <a target="_blank" href="https://argilla.io/blog/argilla-joins-hugggingface/">recently acquired Argilla</a> for collaborating on high quality datasets — what else do you wish people worked on? (that would be useful to the ecosystem from your POV)</em></p>
</blockquote>
<p>Some topics I'm interested in (not necessarily for a startup):</p>
<p>In <strong>Research</strong>: </p>
<ul>
<li>more distillation experiments and OS tooling</li>
<li>densification of sparse (MoE) models</li>
<li>quantization (sub-1-bit for MoEs, &lt;8-bit fine-tuning), tooling on speculative decoding strategies, more people trying the KTO alignment algorithm (which removes the need of preference data for RLHF/PPO/DPO)</li>
<li>true multimodality (2+ input modalities and 2+ output modalities, e.g., text+image+video to text+image in a unified model)</li>
</ul>
<p>There are trends in all of this already.</p>
<p>More generally: We want <strong>more developer-friendly ML tooling</strong> (i.e. making it super easy for any developer to use ML, not just LLMs).  If you come from a background in which you can speak both the language of a discipline (biochemistry, chemistry, material sciences, health) and ML, and communicate and work well with both audiences, you're a unicorn and can do very impactful things, not just in the ML domain, but in other industries.</p>
<blockquote>
<p><em>Thank you for your time, Omar!</em></p>
</blockquote>
<hr>
<p><strong>CTA from DXTips: Who else would you like to hear from? Let us know on <a target="_blank" href="https://x.com/dxtipshq">X/Twitter</a> and join our <a target="_blank" href="https://dx.tips/newsletter">Newsletter</a> to get the next issue!</strong></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I am starting an AI+Education company (494 pts)]]></title>
            <link>https://twitter.com/karpathy/status/1813263734707790301</link>
            <guid>40978731</guid>
            <pubDate>Tue, 16 Jul 2024 17:57:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/karpathy/status/1813263734707790301">https://twitter.com/karpathy/status/1813263734707790301</a>, See on <a href="https://news.ycombinator.com/item?id=40978731">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[XLSTMTime: Long-Term Time Series Forecasting with xLSTM (149 pts)]]></title>
            <link>https://arxiv.org/abs/2407.10240</link>
            <guid>40978372</guid>
            <pubDate>Tue, 16 Jul 2024 17:14:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2407.10240">https://arxiv.org/abs/2407.10240</a>, See on <a href="https://news.ycombinator.com/item?id=40978372">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2407.10240">View PDF</a></p><blockquote>
            <span>Abstract:</span>In recent years, transformer-based models have gained prominence in multivariate long-term time series forecasting (LTSF), demonstrating significant advancements despite facing challenges such as high computational demands, difficulty in capturing temporal dynamics, and managing long-term dependencies. The emergence of LTSF-Linear, with its straightforward linear architecture, has notably outperformed transformer-based counterparts, prompting a reevaluation of the transformer's utility in time series forecasting. In response, this paper presents an adaptation of a recent architecture termed extended LSTM (xLSTM) for LTSF. xLSTM incorporates exponential gating and a revised memory structure with higher capacity that has good potential for LTSF. Our adopted architecture for LTSF termed as xLSTMTime surpasses current approaches. We compare xLSTMTime's performance against various state-of-the-art models across multiple real-world da-tasets, demonstrating superior forecasting capabilities. Our findings suggest that refined recurrent architectures can offer competitive alternatives to transformer-based models in LTSF tasks, po-tentially redefining the landscape of time series forecasting.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Musleh Alharthi [<a href="https://arxiv.org/show-email/df681557/2407.10240">view email</a>]      <br>    <strong>[v1]</strong>
        Sun, 14 Jul 2024 15:15:00 UTC (848 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Private Browsing 2.0 (163 pts)]]></title>
            <link>https://webkit.org/blog/15697/private-browsing-2-0/</link>
            <guid>40977945</guid>
            <pubDate>Tue, 16 Jul 2024 16:23:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://webkit.org/blog/15697/private-browsing-2-0/">https://webkit.org/blog/15697/private-browsing-2-0/</a>, See on <a href="https://news.ycombinator.com/item?id=40977945">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                
                <p>When <a href="https://en.wikipedia.org/wiki/Private_browsing#History">we invented</a> Private Browsing back in 2005, our aim was to provide users with an easy way to keep their browsing private from anyone who shared the same device. We created a mode where users do not leave any local, persistent traces of their browsing. Eventually all other browsers shipped the same feature. At times, this is called “ephemeral browsing.”</p>
<p>We baked in cross-site tracking prevention in all Safari browsing through our cookie policy, starting with Safari 1.0 in 2003. And we’ve increased privacy protections incrementally over the last 20 years. (Learn more by reading <a href="https://webkit.org/tracking-prevention/">Tracking Prevention in Webkit</a>.) Other popular browsers have not been as quick to follow our lead in tracking prevention but there is progress.</p>
<p>Apple believes that users should not be tracked across the web without their knowledge or their consent. Entering Private Browsing is a strong signal that the user wants the best possible protection against privacy invasions, while still being able to enjoy and utilize the web. Staying with the 2005 definition of private mode as only being ephemeral, such as <a href="https://support.google.com/chrome/answer/9845881?hl=en#zippy=%2Chow-incognito-mode-works%2Chow-incognito-mode-protects-your-privacy">Chrome’s Incognito Mode</a>, simply doesn’t cut it anymore. Users expect and deserve more.</p>
<p>So, we decided to take Private Browsing further and add even more protection beyond the normal Safari experience. Last September, we added a whole new level of privacy protections to Private Browsing in Safari 17.0. And we enhanced it even further in Safari 17.2 and Safari 17.5. Plus, when a user enables them, all of the new safeguards are available in regular Safari browsing too.</p>
<p>With this work we’ve enhanced web privacy immensely and hope to set a new industry standard for what Private Browsing should be.</p>
<h2>Enhanced Private Browsing in a Nutshell</h2>
<p>These are the protections and defenses added to Private Browsing in Safari 17.0:</p>
<ul>
<li>Link Tracking Protection</li>
<li>Blocking network loads of known trackers, including CNAME-cloaked known trackers</li>
<li>Advanced Fingerprinting Protection</li>
<li>Extensions with website or history access are off by default</li>
</ul>
<p>In addition, we added these protections and defenses in all browsing modes:</p>
<ul>
<li>Capped lifetime of cookies set in responses from cloaked third-party IP addresses</li>
<li>Partitioned SessionStorage</li>
<li>Partitioned blob URLs (starting in Safari 17.2)</li>
</ul>
<p>We also expanded Web AdAttributionKit (formerly Private Click Measurement) as a replacement for tracking parameters in URL to help developers understand the performance of their marketing campaigns even under Private Browsing.</p>
<figure><picture><source srcset="https://www.webkit.org/wp-content/uploads/safari-private-browsing-dark.png" media="(prefers-color-scheme: dark)"><img fetchpriority="high" decoding="async" src="https://www.webkit.org/wp-content/uploads/safari-private-browsing-light.png" alt="Screenshot of Private Browsing in Safari" width="2704" height="1628" srcset="https://webkit.org/wp-content/uploads/safari-private-browsing-light.png 2704w, https://webkit.org/wp-content/uploads/safari-private-browsing-light-300x181.png 300w, https://webkit.org/wp-content/uploads/safari-private-browsing-light-1024x617.png 1024w, https://webkit.org/wp-content/uploads/safari-private-browsing-light-768x462.png 768w, https://webkit.org/wp-content/uploads/safari-private-browsing-light-1536x925.png 1536w, https://webkit.org/wp-content/uploads/safari-private-browsing-light-2048x1233.png 2048w" sizes="(max-width: 2704px) 100vw, 2704px"></picture><figcaption>Private Browsing in Safari</figcaption></figure>
<p>However, before we dive into these new and enhanced privacy protections, let’s first consider an important aspect of these changes: website compatibility risk.</p>
<h2>The Risk of Breaking Websites and How We Mitigate It</h2>
<p>There are many ideas for how to protect privacy on the web, but unfortunately many of them may break the user’s experience. Like security protections in real life, a balance must be struck. The new Private Browsing goes right up to the line, attempting to never break websites. But of course there is a risk that some parts of some sites won’t work. To solve this, we give users affordances to reduce privacy protections on a per-site basis. Such a change in privacy protections is only remembered while browsing within a site. This option is a last resort when a web page is not usable due to the privacy protections.</p>
<figure><picture><source srcset="https://www.webkit.org/wp-content/uploads/webkit-tracking-prevention-dark.png" media="(prefers-color-scheme: dark)"><img decoding="async" src="https://www.webkit.org/wp-content/uploads/webkit-tracking-prevention-light.png" alt="Reload menu with Reload Reducing Privacy Protections selected" width="2564" height="1544" srcset="https://webkit.org/wp-content/uploads/webkit-tracking-prevention-light.png 2564w, https://webkit.org/wp-content/uploads/webkit-tracking-prevention-light-300x181.png 300w, https://webkit.org/wp-content/uploads/webkit-tracking-prevention-light-1024x617.png 1024w, https://webkit.org/wp-content/uploads/webkit-tracking-prevention-light-768x462.png 768w, https://webkit.org/wp-content/uploads/webkit-tracking-prevention-light-1536x925.png 1536w, https://webkit.org/wp-content/uploads/webkit-tracking-prevention-light-2048x1233.png 2048w" sizes="(max-width: 2564px) 100vw, 2564px"></picture><figcaption>Reload Reducing Privacy Protections</figcaption></figure>
<p>All of the new privacy protections in Private Browsing are also available in regular browsing. On iOS, iPadOS and visionOS go to Settings &gt; Apps &gt; Safari &gt; Advanced &gt; Advanced Tracking and Fingerprinting Protection and enable “All Browsing”. On macOS go to Safari &gt; Settings &gt; Advanced and enable  “Use advanced tracking and fingerprinting protection”:</p>
<figure><picture><source srcset="https://www.webkit.org/wp-content/uploads/safari-advanced-tracking-protection-dark.png" media="(prefers-color-scheme: dark)"><img decoding="async" width="1700" height="1155" src="https://www.webkit.org/wp-content/uploads/safari-advanced-tracking-protection-light.png" alt="Safari Advanced Settings with &quot;Use advanced tracking and fingerprinting protection in all browsing&quot; selected" srcset="https://webkit.org/wp-content/uploads/safari-advanced-tracking-protection-light.png 1700w, https://webkit.org/wp-content/uploads/safari-advanced-tracking-protection-light-300x204.png 300w, https://webkit.org/wp-content/uploads/safari-advanced-tracking-protection-light-1024x696.png 1024w, https://webkit.org/wp-content/uploads/safari-advanced-tracking-protection-light-768x522.png 768w, https://webkit.org/wp-content/uploads/safari-advanced-tracking-protection-light-1536x1044.png 1536w" sizes="(max-width: 1700px) 100vw, 1700px"></picture><figcaption>Use advanced tracking and fingerprinting protection in all browsing from Safari Advanced Settings</figcaption></figure>
<p>Let’s now walk through how these enhancements work.</p>
<h2>Link Tracking Protection</h2>
<p>Safari’s Private Browsing implements two new protections against tracking information in the destination URL when the user navigates between different websites. The specific parts of the URL covered are query parameters and the fragment. The goal of these protections is to make it more difficult for third-party scripts running on the destination site to correlate user activity across websites by reading the URL.</p>
<p>Let’s consider an example where the user clicks a link on <code>clickSource.example</code>, which takes them to <code>clickDestination.example.</code> The URL looks like this:</p>
<pre><code>https://clickDestination.example/article?known_tracking_param=123&amp;campaign=abc&amp;click_val=456
</code></pre>
<p>Safari removes a subset of query parameters that have been identified as being used for pervasive cross-site tracking granular to users or clicks. This is done <em>prior to</em> navigation, such that these values are never propagated over the network. If <code>known_tracking_param</code> above represents such a query parameter, the URL that’s used for navigation will be:</p>
<pre><code>https://clickDestination.example/article?campaign=abc&amp;click_val=456
</code></pre>
<p>As its name suggests, the <code>campaign</code> above represents a parameter that’s only used for campaign attribution, as opposed to click or user-level tracking. Safari allows such parameters to pass through.</p>
<p>Finally, on the destination site after a cross-site navigation, all third-party scripts that attempt to read the full URL (e.g. using <code>location.search</code>, <code>location.href</code>, or <code>document.URL</code>) will get a version of the URL that has no query parameters or fragment. In our example, this script-exposed value is simply:</p>
<pre><code>https://clickDestination.example/article
</code></pre>
<p>In a similar vein, Safari also hides cross-site any <code>document.referrer</code> from script access in Private Browsing.</p>
<h2>Web AdAttributionKit in Private Browsing</h2>
<p>Web AdAttributionKit (formerly Private Click Measurement) is a way for advertisers, websites, and apps to implement ad attribution and click measurement in a privacy-preserving way. You can <a href="https://webkit.org/blog/11529/introducing-private-click-measurement-pcm/">read more about it here</a>. Alongside the new suite of enhanced privacy protections in Private Browsing, Safari also brings a version of Web AdAttributionKit to Private Browsing. This allows click measurement and attribution to continue working in a privacy-preserving manner.</p>
<p>Web AdAttributionKit in Private Browsing works the same way as it does in normal browsing, but with some limits:</p>
<ul>
<li>Attribution is scoped to individual Private Browsing tabs, and transfers attribution across new tabs opened when clicking on links. However, attribution is not preserved through other indirect means of navigation: for instance, copying a link and pasting in a new tab. In effect, this behaves similarly to how Web AdAttributionKit works for <a href="https://webkit.org/blog/12042/pcm-for-in-app-direct-response-advertising/">Direct Response Advertising</a>.</li>
<li>Since Private Browsing doesn’t persist any data, pending attribution requests are discarded when the tab is closed.</li>
</ul>
<h2>Blocking Network Loads of Known Trackers</h2>
<p>Safari 17.0 also comes with an automatically enabled content blocker in Private Browsing, which blocks network loads to known trackers. While Intelligent Tracking Prevention has long blocked all third party cookies, blocking trackers’ network requests from leaving the user’s device in the first place ensures that no personal information or tracking parameters are exfiltrated through the URL itself.</p>
<p>This automatically enabled content blocker is compiled using data from DuckDuckGo and from the EasyPrivacy filtering rules from EasyList. The requests flagged by this content blocker are only entries that are flagged as trackers by <em>both</em> DuckDuckGo and EasyPrivacy. In doing so, Safari intentionally allows most ads to continue loading even in Private Browsing.</p>
<p>Private Browsing also blocks cloaked network requests to known tracking domains. They otherwise have the ability to save third party cookies in a first-party context. This protection requires macOS Sonoma or iOS 17. By cloaked we mean subdomains mapped to a third-party server via CNAME cloaking or third-party IP address cloaking. See also the “Defending Against Cloaked First Party IP Addresses” section below.</p>
<p>When Safari blocks a network request to a known tracker, a console message of this form is logged, and can be viewed using Web Inspector:</p>
<pre><code>`<span>Blocked</span> <span>connection</span> <span>to</span> <span>known</span> <span>tracker</span><span>:</span> <span>tracker</span>.<span>example</span>` 
</code></pre>
<h2>Network Privacy Enhancements</h2>
<p>Safari 15.0 started hiding IP addresses from known trackers by default. Private Browsing in Safari 17.0 adds the following protections for all users:</p>
<ul>
<li><strong>Encrypted DNS</strong>. DNS queries are used to resolve server hostnames into IP addresses, which is a necessary function of accessing the internet. However, DNS is traditionally unencrypted, and allows network operators to track user activity or redirect users to other servers. Private Browsing uses <a href="https://en.wikipedia.org/wiki/DNS_over_HTTPS#Oblivious_DNS_over_HTTPS">Oblivious DNS over HTTPS</a> by default, which encrypts and proxies DNS queries to protect the privacy and integrity of these lookups.</li>
<li><strong>Proxying unencrypted HTTP</strong>. Any unencrypted HTTP resources loaded in Private Browsing will use the same multi-hop proxy network used to hide IP addresses from trackers. This ensures that attackers in the local network cannot see or modify the content of Private Browsing traffic.</li>
</ul>
<p>Additionally, for iCloud+ subscribers who have iCloud Private Relay turned on, Private Browsing takes privacy to the next level with these enhancements:</p>
<ul>
<li><strong>Separate sessions per tab</strong>. Every tab that the user opens in Private Browsing now uses a separate session to the iCloud Private Relay proxies. This means that web servers won’t be able to tell if two tabs originated on the same device. Each session is assigned egress IP addresses independently. Note that this doesn’t apply to parent-child windows that need a programmatic relationship, such as popups and their openers.</li>
<li><strong>Geolocation privacy by default</strong>. Private Browsing uses an IP location based on your country and time zone, not a more specific location.</li>
<li><strong>Warnings before revealing IP address</strong>. When accessing a server that is not accessible on the public internet, such as a local network server or an internal corporate server, Safari cannot use iCloud Private Relay. In Private Browsing, Safari now displays a warning requesting that the user consents to revealing their IP address to the server before loading the page.</li>
</ul>
<h2>Extensions in Private Browsing</h2>
<p>Safari 17.0 also boosts the privacy of Extensions in Private Browsing. Extensions that can access website data and browsing history are now off by default in Private Browsing. Users can still choose to allow an extension to run in Private Browsing and gain all of the extension’s utility. Extensions that don’t access webpage contents or browsing history, like Content Blockers, are turned on by default in Private Browsing when turned on in Safari.</p>
<h2>Advanced Fingerprinting Protection</h2>
<p>With Safari and subsequently <a href="https://wiki.mozilla.org/Security/Anti_tracking_policy">other</a> <a href="https://www.chromium.org/Home/chromium-privacy/privacy-sandbox/#turning-down-third-party-cookies">browsers</a> restricting stateful tracking (e.g. cross-site cookies), many trackers have turned to stateless tracking, often referred to as <em>fingerprinting</em>.</p>
<h3>Types of Fingerprinting</h3>
<p>We distinguish these types of fingerprinting:</p>
<ul>
<li><strong>Device fingerprinting</strong>. This is about building a fingerprint based on device characteristics, including hardware and the current operating system and browser. It can also include connected peripherals if they are allowed to be detected. Such a fingerprint cannot be changed by the user through settings or web extensions.</li>
<li><strong>Network and geographic position fingerprinting</strong>. This is about building a fingerprint based on how the device connects to the Internet and any means of detecting its geographic position. It could be done by measuring roundtrip speeds of network requests or simply using the IP address as an identifier.</li>
<li><strong>User settings fingerprinting</strong>. This is about reading the state of user settings such as dark/light mode, locale, font size adjustments, and window size on platforms where the user can change it. It also includes detecting web extensions and accessibility tools. We find this kind of fingerprinting to be extra hurtful since it exploits how users customize their web experience to fit their needs.</li>
<li><strong>User behavior fingerprinting</strong>. This is about detecting recurring patterns in how the user behaves. It could be how the mouse pointer is used, how quickly they type in form fields, or how they scroll.</li>
<li><strong>User traits fingerprinting</strong>. This is about figuring out things about the user, such as their interests, age, health status, financial status, and educational background. Those gleaned traits can contribute to a unique ID but also can be used directly to target them with certain content, adjust prices, or tailor messages.</li>
</ul>
<h3>Fingerprint Stability</h3>
<p>A challenge for any tracker trying to create a fingerprint is how stable the fingerprint will be over time. Software version fingerprinting changes with software updates, web extension fingerprinting changes with extension updates and enablement/disablement, user settings change when the user wants, multiple users of the same device means behavior fingerprints change, and roaming devices may change network and geographic position a lot.</p>
<h3>Fingerprinting Privacy Problem 1: Cross-Site Tracking</h3>
<p>Fingerprints can be used to track the user across websites. If successful, it defeats tracking preventions such as storage partitioning and link decoration filtering.</p>
<p>There are two types of solutions to this problem:</p>
<ol>
<li>Make the fingerprint be shared among many users, so called herd immunity.</li>
<li>Make the fingerprint unique per website, typically achieved via randomized noise injection.</li>
</ol>
<h3>Fingerprinting Privacy Problem 2: Per-Site User Recall</h3>
<p>Less talked about is the fingerprinting problem of per-site user recall. Web browsers offer at least two ways for the user to reset their relationship with a website: Clear website data or use Private Browsing. Both make a subsequent navigation to a website start out fresh.</p>
<p>But fingerprinting defeats this and allows a website to remember the user even though they’ve opted to clear website data or use Private Browsing.</p>
<p>There are two types of solutions to this problem:</p>
<ol>
<li>Make the fingerprint be shared among many users, so called herd immunity.</li>
<li>Make the fingerprint unique per website, and generate a new unique fingerprint for every fresh start.</li>
</ol>
<h3>Fingerprinting Privacy Problem 3: Per-Site Visitor Uniqueness</h3>
<p>The ultimate anti fingerprinting challenge in our view is to address a specific user’s uniqueness when visiting a specific website. Here’s a simple example:</p>
<p>Having the locale setting to US/EN for American English may provide ample herd immunity in many cases. But what happens when a user with that setting visits an Icelandic government website or a Korean reading club website? They may find themselves in a very small “herd” on that particular website and combined with just a few more fingerprinting touch points they can be uniquely identified.</p>
<p>Addressing per-site visitor uniqueness is not possible in general by a browser unless it knows what the spread of visitors looks like for individual websites.</p>
<h3>Fingerprinting Protections at a High Level</h3>
<p>We view cross-site tracking and per-site user recall as privacy problems to be addressed by browsers.</p>
<p><strong>Our approach</strong>:<br>
Make the fingerprint unique per website, and generate a new unique fingerprint for every fresh start such as at website data removal.</p>
<p><strong>Our tools</strong>:</p>
<ul>
<li>Use multi-hop proxies to hide IP addresses and defend against network and geographic position fingerprinting.</li>
<li>Limit the number of fingerprintable web APIs whenever possible. This could mean altering the APIs, gating them behind user permissions, or not implementing them.</li>
<li>Inject small amounts of noise in return values of fingerprintable web APIs.</li>
</ul>
<h3>Fingerprinting Protection Details</h3>
<p>Safari’s new advanced fingerprinting protections make it difficult for scripts to <strong>reliably</strong> extract <strong>high-entropy</strong> data through the use of several web APIs:</p>
<ol>
<li>To make it more difficult to <strong>reliably</strong> extract details about the user’s configuration, Safari injects noise into various APIs: namely, during 2D canvas and WebGL readback, and when reading <code>AudioBuffer</code> samples using WebAudio.</li>
<li>To reduce the overall <strong>entropy</strong> exposed through other APIs, Safari also overrides the results of certain web APIs related to window or screen metrics to fixed values, such that fingerprinting scripts that call into these APIs for users with different screen or window configurations will get the same results, even if the users’ underlying configurations are different.</li>
</ol>
<h4>2D Canvas and WebGL</h4>
<p>Many modern web browsers use a computer’s graphics processing unit (GPU) to accelerate rendering graphics. The Web’s Canvas API (2D Canvas) and WebGL API give a web page the tools it needs for rendering arbitrary images and complex scenes using the GPU, and analyzing the result. These APIs are valuable for the web platform, but they allow the web page to learn unique details about the underlying hardware without asking for consent. With Safari’s advanced fingerprinting protections enabled, Safari applies tiny amounts of noise to pixels on the canvas that have been painted using drawing commands. These modifications reduce the value of a fingerprint when using these APIs without significantly impacting the rendered graphics.</p>
<p>It’s important to emphasize that:</p>
<ol>
<li>This noise injection only happens in regions of the canvas where drawing occurs.</li>
<li>The amount of noise injected is extremely small, and (mostly) should not result in observable differences or artifacts.</li>
</ol>
<p>This strategy helps mitigate many of the compatibility issues that arise from this kind of noise injection, while still maintaining robust fingerprinting mitigations.</p>
<p>In Safari 17.5, we’ve bolstered these protections by additionally injecting noise when reading back data from offscreen canvas in both service workers and shared workers.</p>
<h4>Web Audio</h4>
<p>Similarly, when reading samples using the WebAudio API — via <code>AudioBuffer.getChannelData()</code> — a tiny amount of noise is applied to each sample to make it very difficult to reliably measure OS differences. In practice, these differences are already extremely minor. Typically due to slight differences in the order of operations when applying FFT or IFFT. As such, a relatively low amount of noise can make it substantially more difficult to obtain a stable fingerprint.</p>
<p>In Safari 17.5, we made audio noise injection more robust in the following ways:</p>
<ul>
<li>The injected noise now applies consistently to the same values in a given audio buffer — this means a looping  <code>AudioSourceNode</code> that contains a single high-entropy sample can’t be used to average out the injected noise and obtain the original value quickly.</li>
<li>Instead of using a uniform distribution for the injected noise, we now use normally-distributed noise. The mean of this distribution converges much more slowly on the original value, when compared to the average of the minimum and maximum value in the case of uniformly-distributed noise.</li>
<li>Rather than using a low, fixed amount of noise (0.1%), we’ve refactored the noise injection mechanism to support arbitrary levels of noise injection. This allows us to easily fine-tune noise injection, such that the magnitude of noise increases when using audio nodes that are known to reveal subtle OS or hardware differences through minute differences in sample values.</li>
</ul>
<p>This noise injection also activates when using Audio Worklets (e.g. <code>AudioWorkletNode</code>) to read back audio samples.</p>
<h4>Screen/Window Metrics</h4>
<p>Lastly, for various web APIs that currently directly expose window and screen-related metrics, Safari takes a different approach: instead of the noise-injection-based mitigations described above, entropy is reduced by fixing the results to either hard-coded values, or values that match other APIs.</p>
<ul>
<li><code>screen.width</code> / <code>screen.height</code>: The screen size is fixed to the values of <code>innerWidth</code> and <code>innerHeight</code>.</li>
<li><code>screenX</code> / <code>screenY</code>: The screen position is fixed to <code>(0, 0)</code>.</li>
<li><code>outerWidth</code> / <code>outerHeight</code>: Like screen size, these values are fixed to <code>innerWidth</code> and <code>innerHeight</code>.</li>
</ul>
<p>These mitigations also apply when using media queries to indirectly observe the screen size.</p>
<h2>Don’t Add Fingerprintable APIs to the Web, Like The Topics API</h2>
<p>We have worked for many years with the standards community on improving user privacy of the web platform. There are existing web APIs that are fingerprintable, such as Canvas, and reining in their fingerprintability is a long journey. Especially since we want to ensure existing websites can continue to work well.</p>
<p>It is key for the future privacy of the web to not compound the fingerprinting problem with new, fingerprintable APIs. There are cases where the tradeoff tells us that a rich web experience or enhanced accessibility motivates some level of fingerprintability. But in general, our position is that we should progress the web without increasing fingerprintability.</p>
<p>A recent example where we opposed a new proposal is the Topics API which is now <a href="https://developers.google.com/privacy-sandbox/relevance/topics">shipping in the Chrome browser</a>. We provided <a href="https://github.com/WebKit/standards-positions/issues/111">extensive critical feedback</a> as part of the standards process and we’d like to highlight a few pieces here.</p>
<h3>The Topics API in a Nutshell</h3>
<p>From the <a href="https://github.com/patcg-individual-drafts/topics">proposal</a>:</p>
<pre><code><span>// document.browsingTopics() returns an array of up to three topic objects in random order.
</span><span>const</span> <span>topics</span> <span>=</span> <span>await</span> <span>document</span>.<span>browsingTopics</span>();
</code></pre>
<p>Any JavaScript can call this function on a webpage. Yes, that includes tracker scripts, advertising scripts, and data broker scripts.</p>
<p>The topics come from a predefined list of hundreds of topics. It’s not the user who picks from these topics, but instead Chrome will record the user’s browsing history over time and deduce interests from it. The user doesn’t get told upfront which topics Chrome has tagged them with or which topics it exposes to which parties. It all happens in the background and by default.</p>
<p>The intent of the API is to help advertisers target users with ads based on each user’s interests even though the current website does not necessarily imply that they have those interests.</p>
<h3>The Fingerprinting Problem With the Topics API</h3>
<p>A new <a href="https://arxiv.org/html/2403.19577v1">research paper</a> by Yohan Beugin and Patrick McDaniel from University of Wisconsin-Madison goes into detail on Chrome’s actual implementation of the Topics API.</p>
<p>The authors use large scale real user browsing data (voluntarily donated) to show both how the 5% noise supposed to provide plausible deniability for users can be defeated, and how the Topics API can be used to fingerprint and re-identify users.</p>
<blockquote><p>
  “We conclude that an important part of the users from this real dataset are re-identified across websites through only the observations of their topics of interest in our experiment. Thus, the real users from our dataset can be fingerprinted through the Topics API. Moreover, as can be seen, the information leakage and so, privacy violation worsen over time as more users are uniquely re-identified.” —Beugin and McDaniel, University of Wisconsin-Madison
</p></blockquote>
<p>The paper was published at the <a href="https://ieeexplore.ieee.org/document/10579537">2024 IEEE Security and Privacy Workshops (SPW)</a> in May.</p>
<h3>Further Privacy Problems With the Topics API</h3>
<p>Re-identifying and tracking users is not the only privacy problem with the Topics API. There is also the profiling of users’ cross-site activity. Here’s an example using topics on <a href="https://github.com/patcg-individual-drafts/topics/blob/main/taxonomy_v2.md">Chrome’s predefined list</a>.</p>
<p>Imagine in May 2024 you go to <code>news.example</code> where you are a subscriber and have provided your email address. Embedded on the website, <code>dataBroker.example</code>. The data broker has gleaned your email address from the login form and calls the Topics API to learn that you currently have these interests:</p>
<ul>
<li>Flowers</li>
<li>Event &amp; Studio Photography</li>
<li>Luxury Travel</li>
</ul>
<p>In May 2026 you go to <code>news.example</code> where <code>dataBroker.example</code> calls the Topics API and is told that you now have these interests:</p>
<ul>
<li>Children’s Clothing</li>
<li>Family Travel</li>
<li>Toys</li>
</ul>
<p>Finally, in May 2029 you go to <code>news.example</code> where <code>dataBroker.example</code> calls the Topics API and is told that you have these interests:</p>
<ul>
<li>Legal Services</li>
<li>Furnished Rentals</li>
<li>Child Care</li>
</ul>
<p>You haven’t told any website with access to your email address anything that’s been going on in your family life. But the data broker has been able to read your shifting interests and store them in their permanent profile of you — while you were reading the news.</p>
<p>Now imagine what advanced machine learning and artificial intelligence can deduce about you based on various combinations of interest signals. What patterns will emerge when data brokers and trackers can compare and contrast across large portions of the population? Remember that they can combine the output of the Topics API with any other data points they have available, and it’s the analysis of all of it together that feeds the algorithms that try to draw conclusions about you.</p>
<p>We think the web should not expose such information across websites and we don’t think the browser, i.e. <em>the user agent</em>, should facilitate any such data collection or use.</p>
<h2>Privacy Enhancements in Both Browsing Modes</h2>
<p>Our defenses against cloaked third-party IP addresses and our partitioning of SessionStorage and blob URLs are enabled by default in both regular browsing and Private Browsing. Here’s how those protections work.</p>
<h3>Defending Against Cloaked First Party IP Addresses</h3>
<p>In 2020, Intelligent Tracking Prevention (ITP) gained the ability to <a href="https://webkit.org/blog/11338/cname-cloaking-and-bounce-tracking-defense">cap the expiry of cookies set in third-party CNAME-cloaked HTTP responses to 7 days</a>.</p>
<p>This defense did not mitigate cases where IP aliasing is used to cloak third party requests under first party subdomains. ITP now also applies a 7-day cap to the expiry of cookies in responses from cloaked third-party IP addresses. Detection of third-party IP addresses is heuristic, and may change in the future. Currently, two IP addresses are considered different parties if any of the following criteria are met:</p>
<ol>
<li>One IP address is IPv4, while the other is IPv6.</li>
<li>If both addresses are IPv4, the length of the common subnet mask is less than 16 bits (half of the full address length).</li>
<li>If both addresses are IPv6, the length of the common subnet mask is less than 64 bits (also half of the full address length).</li>
</ol>
<h3>Partitioned SessionStorage and Blob URLs</h3>
<p>Websites have many options for how they store information over longer time periods. <a href="https://developer.mozilla.org/en-US/docs/Web/API/Window/sessionStorage">Session Storage</a> is a storage area in Safari that is scoped to the current tab. When a tab in Safari is closed, all of the session storage associated with it is destroyed. Beginning in Safari 16.1 cross-site Session Storage is partitioned by first-party web site.</p>
<p>Similarly, <a href="https://developer.mozilla.org/en-US/docs/Web/API/Blob">Blobs</a> are a storage type that allow websites to store raw, file-like data in the browser. A blob can hold almost anything, from simple text to something larger and more complex like a video file. A unique URL can be <a href="https://developer.mozilla.org/en-US/docs/Web/API/URL/createObjectURL_static">created for a blob</a>, and that URL can be used to gain access to the associated blob, as long as the blob still exists. These URLs are often referred to as Blob URLs, and a Blob URL’s lifetime is scoped to the document that creates it. Beginning in Safari 17.2, cross-site Blob URLs are partitioned by first-party web site, and first-party Blob URLs are not usable by third parties.</p>
<h2>Setting a New Industry Standard</h2>
<p>The additional privacy protections of Private Browsing in Safari 17.0, Safari 17.2 and Safari 17.5 set a new bar for user protection. We’re excited for all Safari users and the web itself to benefit from this work!</p>
<h2>Feedback</h2>
<p>We love hearing from you! To share your thoughts on Private Browsing 2.0, find John Wilander on Mastodon at <a href="https://mastodon.social/@wilander">@wilander@mastodon.social</a> or send a reply on X to <a href="https://x.com/webkit">@webkit</a>. You can also <a href="https://www.linkedin.com/in/apple-webkit/">follow WebKit on LinkedIn</a>. If you run into any issues, we welcome your <a href="https://feedbackassistant.apple.com/">feedback</a> on Safari UI (learn more about <a href="https://developer.apple.com/bug-reporting/">filing Feedback</a>), or your <a href="https://bugs.webkit.org/">WebKit bug report</a> about web technologies or Web Inspector.</p>

                            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I quit my job and made an automatic time tracker (120 pts)]]></title>
            <link>https://taimapp.io</link>
            <guid>40977453</guid>
            <pubDate>Tue, 16 Jul 2024 15:28:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://taimapp.io">https://taimapp.io</a>, See on <a href="https://news.ycombinator.com/item?id=40977453">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>     <main><header></header>    <section><div><p><img src="https://taimapp.io/tray.png" alt="Taim logo"></p><h2 data-svelte-h="svelte-1s4m87e">Automated time tracking software<br>to save you time</h2> <p data-svelte-h="svelte-ppsrs9">Forgetting to start a timer is an issue of the past. You do your job, we keep track of it.</p> <div data-svelte-h="svelte-r1ro5t"><p><a href="#pricing">Pre-order now</a></p><p>macOS Ventura 13.1+, Win 10+* is recommended</p></div></div> <div><p><img src="https://taimapp.io/taimapp-preview.png" alt="Automatic time tracking software interface"></p>  </div> </section> <div><div id="section-one"><h2>Struggling with Tracking<br> Your Work Hours?</h2> <p>Freelancers often face the hassle of manually starting and stopping timers, leading to inaccurate time tracking and billing. 
        Missed hours and overcharges can harm your reputation and client trust.</p></div> <div> <div data-svelte-h="svelte-mv45p8"> <p>Documenting
        <span>11:30 - 13.00</span></p></div>      <div><div data-svelte-h="svelte-e0k7ia"> <p>My Project 1
        <span>09:00 - 10.00</span></p></div>  <div data-svelte-h="svelte-1v8rkjr"> <p>Mega Corp Inc.
        <span>11.30 - 13.00</span></p></div></div></div> <div id="product"><h2>Why Choose Taim?</h2> <p>You have full control over your sessions. You can either record sessions manually or automatically.
      Need to change the duration or date of a session? No problem. You can easily edit sessions to reflect the correct information.</p> </div> <div id="features"><h2>Control your sessions</h2> <p>It doesn't matter if you work on a personal project or on a client's project, you can adjust settings accordingly.</p> <div id="cards"><div><p><img src="https://taimapp.io/features/toggle-billing.png" alt="Toggle Billing"></p><div><h3>Toggle Billing</h3> <p>Select whether a session is billable &amp; paid or not, to make your invoicing process easier.</p> </div></div><div><p><img src="https://taimapp.io/features/application-flow.png" alt="Application Flow"></p><div><h3>Application Flow</h3> <p>Easily see an overview of your activity, and choose what to log.</p> </div></div><div><p><img src="https://taimapp.io/features/time-modifying.png" alt="Modify time &amp; sessions"></p><div><h3>Modify time &amp; sessions</h3> <p>Edit your session data by adding or removing time &amp; data whenever needed.</p> </div></div><div><p><img src="https://taimapp.io/features/notes.png" alt="Notes"></p><div><h3>Notes</h3> <p>Add shareable notes to your sessions &amp; projects to keep track of important details.</p> </div></div><div><p><img src="https://taimapp.io/features/ai-time-tracker.png" alt="Learns from you"></p><div><h3>Learns from you</h3> <p>More work equals bigger brains. Over time Taim can start to log sessions automatically.</p> </div></div><div><p><img src="https://taimapp.io/features/filtering.png" alt="Advanced Filtering"></p><div><h3>Advanced Filtering</h3> <p>Filter time your tracked time by date, statuses, project, tags, and more.</p> </div></div></div> </div></div> <div><h2>Resource efficient</h2> <p>Designed to consume low power, storage. Just like any native application.</p> <div data-svelte-h="svelte-1gpxnfw"><p><span>CPU USAGE: 5-15%</span>
        Other apps</p>  <svg viewBox="0 0 1653 512" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#clip0_2222_2)"><path d="M0 332.453L12.5227 333.066C25.0455 333.679 50.0909 334.904 75.1364 338.357C100.182 341.809 125.227 347.488 150.273 326.69C175.318 305.892 200.364 258.617 225.409 258.952C250.455 259.287 275.5 307.231 300.545 344.666C325.591 382.101 350.636 409.026 375.682 424.843C400.727 440.659 425.773 445.367 450.818 452.882C475.864 460.398 500.909 470.721 525.955 468.756C551 466.791 576.045 452.538 601.091 384.897C626.136 317.256 651.182 196.226 676.227 186.558C701.273 176.889 726.318 278.582 751.364 270.579C776.409 262.576 801.455 144.879 826.5 132.177C851.545 119.475 876.591 211.769 901.636 207.823C926.682 203.877 951.727 103.691 976.773 78.7498C1001.82 53.8091 1026.86 104.114 1051.91 122.007C1076.95 139.901 1102 125.383 1127.05 141.174C1152.09 156.964 1177.14 203.064 1202.18 197.931C1227.23 192.797 1252.27 136.431 1277.32 148.65C1302.36 160.868 1327.41 241.672 1352.45 285.831C1377.5 329.99 1402.55 337.503 1427.59 316.721C1452.64 295.94 1477.68 246.863 1502.73 186.553C1527.77 126.243 1552.82 54.6998 1577.86 27.2078C1602.91 -0.284178 1627.95 16.2749 1640.48 24.5544L1653 32.8339" stroke="url(#paint0_linear_2222_2)" stroke-width="3"></path><path d="M0 452.057L13.3492 452.457C26.6984 452.856 53.3968 453.656 80.0952 454.901C106.794 456.147 133.492 457.838 160.19 454.227C186.889 450.615 213.587 441.7 240.286 442.322C266.984 442.943 293.683 453.1 320.381 461.152C347.079 469.204 373.778 475.151 400.476 478.873C427.175 482.595 453.873 484.092 480.571 486.151C507.27 488.21 533.968 490.832 560.667 490.992C587.365 491.153 614.063 488.852 640.762 475.858C667.46 462.864 694.159 439.177 720.857 437.794C747.556 436.412 774.254 457.334 800.952 456.285C827.651 455.236 854.349 432.216 881.048 430.226C907.746 428.236 934.444 447.276 961.143 447.04C987.841 446.804 1014.54 427.291 1041.24 422.85C1067.94 418.408 1094.63 429.038 1121.33 433.176C1148.03 437.314 1174.73 434.96 1201.43 438.677C1228.13 442.394 1254.83 452.181 1281.52 451.707C1308.22 451.233 1334.92 440.497 1361.62 443.499C1388.32 446.5 1415.02 463.239 1441.71 472.637C1468.41 482.036 1495.11 484.095 1521.81 480.487C1548.51 476.878 1575.21 467.602 1601.9 456.077C1628.6 444.551 1655.3 430.776 1668.65 423.888L1682 417" stroke="url(#paint1_linear_2222_2)" stroke-width="3"></path></g><defs><linearGradient id="paint0_linear_2222_2" x1="0" y1="240.5" x2="1653" y2="240.5" gradientUnits="userSpaceOnUse"><stop stop-color="#A91576" stop-opacity="0"></stop><stop offset="0.255" stop-color="#A91576"></stop><stop offset="0.765" stop-color="#870505"></stop><stop offset="1" stop-color="#870505" stop-opacity="0"></stop></linearGradient><linearGradient id="paint1_linear_2222_2" x1="0" y1="454" x2="1682" y2="454" gradientUnits="userSpaceOnUse"><stop stop-color="#18A0FB" stop-opacity="0"></stop><stop offset="0.205" stop-color="#18A0FB"></stop><stop offset="0.775" stop-color="#53023C"></stop><stop offset="1" stop-color="#53023C" stop-opacity="0"></stop></linearGradient><clipPath id="clip0_2222_2"><rect width="1653" height="512" fill="white"></rect></clipPath></defs></svg></div></div> <div id="fullcontrol"><h2>Time tracking software with full control</h2> <p>Taim is a time tracking software that works just like you want it to. Clicks and calculations that would otherwise take a lot of time are made instantly for you.</p> <div><div><p><span><span>CSV</span> Jun 9 - Jun 10 sessions</span></p></div><div><p><span><span>PDF</span> Paid sessions this week</span></p></div><div><p><span><span>XLS</span> Billable sessions last month</span></p></div></div></div> <div id="section-three"><h2>Work Smarter, Not Harder</h2> <p>Customize Taim to your needs, if you want to track time manually, you can do that. 
        If you want to track time automatically, you can do that as well.
         It is up to you to decide how you want to track your time.</p> </div>  <div><div id="pricing"><h2>Pay once, use forever</h2> <p>Taim is a one-time purchase. You get all the features in every plan.</p> <div data-svelte-h="svelte-k74s6c"><p><span>PRE-SALE IS LIVE!</span> <span>Currently Taim is available to purchase as a presale. We are planning to launch Taim to the public in early autumn (Sep-Oct), be sure to checkout our <a href="https://taimapp.io/roadmap">roadmap.</a></span></p></div> <div> <div><div><h3>Individual</h3> <p>Early-bird 56% off</p></div> <p>One-time payment for a single user.</p>   <ul role="list"><li> <svg fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clip-rule="evenodd"></path></svg> <span>Pay once, use forever</span> </li><li> <svg fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clip-rule="evenodd"></path></svg> <span>1 macOS device</span> </li><li> <svg fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clip-rule="evenodd"></path></svg> <span>All features</span> </li><li> <svg fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clip-rule="evenodd"></path></svg> <span>Free updates for 12 months</span> </li><li> <svg fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clip-rule="evenodd"></path></svg> <span>Local storage</span> </li></ul>  </div><div><p><h3>Teams</h3> </p> <p>Great for multi-devices setups &amp; teams.</p>   <ul role="list"><li> <svg fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clip-rule="evenodd"></path></svg> <span>Pay per seat for your team.</span> </li><li> <svg fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clip-rule="evenodd"></path></svg> <span>Unlimited devices</span> </li><li> <svg fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clip-rule="evenodd"></path></svg> <span>All features</span> </li><li> <svg fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clip-rule="evenodd"></path></svg> <span>App updates during the subscription</span> </li><li> <svg fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clip-rule="evenodd"></path></svg> <span>Cloud storage</span> </li></ul>  </div></div></div> <div><h2>Questions &amp; Answers</h2> <p>Get answers to your questions. For additional questions, please get in touch.</p> </div></div></main>  
			
			
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Devs need system design tools, not diagramming tools (128 pts)]]></title>
            <link>https://thenewstack.io/devs-need-system-design-tools-not-diagramming-tools/</link>
            <guid>40977308</guid>
            <pubDate>Tue, 16 Jul 2024 15:09:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thenewstack.io/devs-need-system-design-tools-not-diagramming-tools/">https://thenewstack.io/devs-need-system-design-tools-not-diagramming-tools/</a>, See on <a href="https://news.ycombinator.com/item?id=40977308">Hacker News</a></p>
Couldn't get https://thenewstack.io/devs-need-system-design-tools-not-diagramming-tools/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Codestral Mamba (377 pts)]]></title>
            <link>https://mistral.ai/news/codestral-mamba/</link>
            <guid>40977103</guid>
            <pubDate>Tue, 16 Jul 2024 14:44:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mistral.ai/news/codestral-mamba/">https://mistral.ai/news/codestral-mamba/</a>, See on <a href="https://news.ycombinator.com/item?id=40977103">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Following the publishing of the Mixtral family, Codestral Mamba is another step in our effort to study and provide new architectures. It is available for free use, modification, and distribution, and we hope it will open new perspectives in architecture research. Codestral Mamba was designed with help from Albert Gu and Tri Dao.</p><p>Unlike Transformer models, <a href="https://arxiv.org/abs/2312.00752">Mamba models</a> offer the advantage of linear time inference and the theoretical ability to model sequences of infinite length. It allows users to engage with the model extensively with quick responses, irrespective of the input length. This efficiency is especially relevant for code productivity use cases—this is why we trained this model with advanced code and reasoning capabilities, enabling it to perform on par with SOTA transformer-based models.</p><p><img src="https://mistral.ai/images/news/codestral-mamba/codestral-mamba-benchmarks.png" alt="Detailed Codestral Mamba benchmarks" width="100%"></p><p>We have tested Codestral Mamba on in-context retrieval capabilities up to 256k tokens. We expect it to be a great local code assistant!</p><p>You can deploy Codestral Mamba using the <a href="https://github.com/mistralai/mistral-inference">mistral-inference</a> SDK, which relies on the reference implementations from Mamba’s GitHub repository. The model can also be deployed through <a href="https://github.com/NVIDIA/TensorRT-LLM/tree/main/examples/mamba">TensorRT-LLM</a>. For local inference, keep an eye out for support in llama.cpp. You may download the raw weights from <a href="https://huggingface.co/mistralai/mamba-codestral-7B-v0.1">HuggingFace</a>.</p><p>For easy testing, we made Codestral Mamba available on <a href="https://console.mistral.ai/">la Plateforme</a> (<code>codestral-mamba-2407</code>), alongside its big sister, Codestral 22B. While Codestral Mamba is available under the Apache 2.0 license, Codestral 22B is available under a <a href="https://mistral.ai/contact/">commercial license</a> for self-deployment or a community license for testing purposes.</p><p><strong>Important:</strong> This is an instructed model, with 7,285,403,648 parameters.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Godotcaml for Godot 4.2 (114 pts)]]></title>
            <link>https://fizzixnerd.com/blog/2024-06-24-announcing-godotcaml/</link>
            <guid>40975509</guid>
            <pubDate>Tue, 16 Jul 2024 11:25:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fizzixnerd.com/blog/2024-06-24-announcing-godotcaml/">https://fizzixnerd.com/blog/2024-06-24-announcing-godotcaml/</a>, See on <a href="https://news.ycombinator.com/item?id=40975509">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>Hello!  Today I’m releasing a project on which I’ve been working, that is in an early stage of development, into the open source world.  It is integration and bindings to Godot (currently just 4.2) from a new language: OCaml.  It is called Godotcaml.  Details below!</p>
<h2 id="why-godot">Why Godot?</h2>
<p>There are many reasons to choose Godot, but the reason I’ll focus on is that it provides a full game-development IDE from which you can develop production quality 2D and 3D games.  It’s suitable for small-to-medium-sized teams, quite mature, and very fun to use; I think most devs have a secret inclination to “one day” make a video game.  If there is one piece of advice I could give to those devs, it’s choose a good engine that already exists, unless you want to be stuck in Vulkan hell for 6-12 months.  Godot is a good engine, and happily, already exists, and is free and open source — so is a good first choice, even if you abandon it for something different later.</p>
<h2 id="why-ocaml">Why OCaml?</h2>
<p>While my greatest loved language is Haskell, there are some specific reasons that it is somewhat unsuitable for game development.  Instead of listing those, however, I will instead take a more positive approach and talk about why OCaml is an excellent language for game development.</p>
<ul>
<li>
<p><strong>Garbage Collected by Default:</strong> This may shock game devs used to the C++ lyfe, but will come as no surprise to people who’ve used Godot and/or Unity.  Programmers are just more productive when there is a garbage collector, and programmer time is what is usually most valuable — not machine time.  Now, you can write some pretty cool allocation-free OCaml code too — but that’s an optimization that you should measure your need for before you commit to it.</p>
</li>
<li>
<p><strong>Functional by Default:</strong> I love functional programming, and I love the kind of code you can write in an ML-like curried functional language (such as OCaml or Haskell).  So <em>if</em> I were to bind Godot to a new language, it would have to be a functional one.  However, excellent bindings (<code>gdext</code>) for Rust already exist, and it can be used as a workable functional language.  That being said, Rust has the borrowchecker and an aversion to garbage collection, and put simply, I don’t think it makes a particularly good game scripting language, even though it is a wonderful systems programming language.  I think OCaml can one day prove to be a more efficient vehicle for experienced functional programmers to create a game in.  (No hate intended!  This is just how I <em>feel</em>.)</p>
</li>
<li>
<p><strong>Eager by Default:</strong> I absolutely adore lazy APIs.  I might actually be in the minority now in the Haskell community that I think that laziness was not a mistake, but was an excellent choice because of the ergonomics it provides.  However, it’s definitely true that it makes it somewhat less straight-forward to reason about the runtime performance of your code, and indeed to debug it — at least without specialized knowledge that is, in my experience, rather rare to have.  OCaml is eager by default, and I think that’s probably better for a soft-realtime system, unless you’re using some specialized framework (e.g. one that I don’t know whether exists or not!).</p>
</li>
<li>
<p><strong>Side-effects for When You Need Them:</strong> If the world was all written in one language, Haskell would make a pretty good choice — not perfect by any stretch, but pretty good.  However, we live in the real world, where a C FFI is the glue holding this pot of spaghetti we call an operating system together.  Because of that, when doing FFI heavy code, a beautiful language that makes it slightly more tedious to work with side-effects is less preferable in my experience than a language that simply encourages you to think before you use them, but still easily allows you to do things like have global mutable references at the top level.</p>
</li>
<li>
<p><strong>PPXes For CodeGen Help:</strong> I’m not totally sold on the pervasive use of PPXes for OCaml code, but one thing they are definitely useful for is code gen, and you would need a <em>lot</em> of tedious hand-written code if you wanted to interact with Godot directly by hand.  PPXes lie somewhere between Rust macros and TemplateHaskell in their power, but most problems with codegen were able to be solved to my satisfaction using the wonderful PpxLib and context-free extenders.  For example, here is the definition of a simple Godot class that inherits from the stock <code>Node</code> class, and provides a successor function for Godot <code>int</code>s:</p>
</li>
</ul>
<pre is:raw="" tabindex="0"><code><span><span>module</span><span>%</span><span>gclass </span><span>MyClass</span><span> </span><span>=</span><span> struct</span></span>
<span><span>  </span><span>[</span><span>%%</span><span>ginherits </span><span>Node]</span></span>
<span></span>
<span><span>  </span><span>let</span><span>%</span><span>gfunc </span><span>succ</span><span> </span><span>=</span><span> </span></span>
<span><span>    </span><span>[|</span><span> </span><span>ClassMethodFlags</span><span>.</span><span>default </span><span>|]</span></span>
<span><span>      (module </span><span>BuiltinClass0</span><span>.</span><span>Int</span><span>)</span></span>
<span><span>      (module </span><span>Class</span><span>.</span><span>Node</span><span>)</span></span>
<span><span>      (module </span><span>BuiltinClass0</span><span>.</span><span>Int</span><span>) </span></span>
<span><span>      (</span><span>fun</span><span> </span><span>i</span><span> </span><span>_self</span><span> </span><span>-&gt;</span><span> </span><span>Int64</span><span>.</span><span>(i </span><span>+</span><span> </span><span>1</span><span>L))</span></span>
<span><span>end</span></span></code></pre>
<p>Whether or not you like the use of PPXes in general, it is tough to argue that this code isn’t at least <em>short</em>, especially if I were to show you the amount of work you’d have to do without those <code>%</code>s!</p>
<ul>
<li><strong>More:</strong> If you’re reading this post, you probably already like OCaml already, so I’ll leave it there at “it’s a really nice pragmatic functional language, and I thought it would be a good candidate”!</li>
</ul>
<h2 id="what-can-it-do">What Can It Do?</h2>
<p>This is an extremely early stage of development, but basically at this point it is possible to:</p>
<ol>
<li>Call any builtin Godot utility function or method (static, virtual, or otherwise) from OCaml easily, and with documentation comments for the original function intact an available through your favourite OCaml LSP implementation.</li>
<li>Use Godot (binary) operators in a natural way from OCaml. (Unary operators are currently broken, which I will be investigating!)</li>
<li>Construct Godot values from OCaml easily, and from OCaml analogues if they exist (e.g. I incur a dependency on <code>Gg</code> for low-dimensional vector math)</li>
<li>Marshalling in and out of all these functions to/from the OCaml analogues.  That is, a method that is in Godot on an object of type <code>ClassyClass</code> taking an <code>int</code> parameter and returning an <code>int</code> will appear in Godotcaml as <code>int64 -&gt; ClassyClass.t structure ptr -&gt; int64</code>, where the <code>ClassyClass.t structure ptr</code> is the “pointer to the Godot object”, commonly called <code>self</code>.  (Note that this is always the <em>last</em> argument, to facilitate pipeline-style programming when GDScript programmers have a method-chaining interface.)</li>
<li>Naturally define a new Godot class in OCaml that inherits from an existing Godot-registered class.  (Currently NOT tested with classes defined in GDScript and/or externally.)</li>
<li>Most of the code-gen for custom engines that define new stock/builtin types and classes, etc.</li>
<li>Simulated inheritence for stock (and easily extendable to user-defined) classes using module inclusion:  That is if <code>Derived</code> inherits from <code>Base</code>, then simply include <code>Base</code> in the module representing <code>Derived</code>, and you get access to all the methods from <code>Base</code> without explicit casting (or in the case of Rust’s <code>gdext</code>, object composition).</li>
<li>Naturally define a new Godot method in OCaml and have it called from GDScript or another Godot-bound language. (ergonomics still WIP).</li>
</ol>
<h2 id="todo-or-what-cant-it-do">TODO (Or, What Can’t It Do):</h2>
<ol>
<li><strong>Signals:</strong> I’m still cooking ideas for how best to do this, but user-defined signals are not currently nicely supported, and even built in ones are not nice to call or interact with right now.  I’d also like them to be type-safe, so there’s that.  Very WIP, but fixable with some thought and work.</li>
<li><strong>Garbage Collection:</strong> Right now, if a OCaml reference is stored in a, say, GDScript variable, and contains no references in the OCaml world, then it might be collected out from under you.  This is fixable because of Godot’s wonderful reference-counting hooks and OCaml finalisers, I just haven’t gotten around to it yet.</li>
<li><strong>Nice Interface to Various Kinds of Methods:</strong> As of the writing of this blog post, it is only possible to define methods of arity <code>1 + Self</code> from OCaml.  No static methods, no virtual methods  This will be fixed soon, but I wanted to get the stuff in the hands of interested enthusiasts as soon as I was able to call OCaml functions from Godot.</li>
<li><strong>Real First Class Modules for Method Definitions:</strong> Taking again the example above, we can write</li>
</ol>
<pre is:raw="" tabindex="0"><code><span><span>let</span><span>%</span><span>gfunc </span><span>f</span><span> </span><span>=</span><span> </span></span>
<span><span>  </span><span>[|</span><span> </span><span>ClassMethodFlags</span><span>.</span><span>default </span><span>|]</span></span>
<span><span>  (module </span><span>ArgumentGodotTypeModule</span><span>)</span></span>
<span><span>  (module </span><span>SelfGodotTypeModule</span><span>)</span></span>
<span><span>  (module </span><span>ReturnValueGodotTypeModule</span><span>)</span></span>
<span><span>  (</span><span>fun</span><span> </span><span>x</span><span> </span><span>self</span><span> </span><span>-&gt;</span><span> </span><span>(* implementation here ...*)</span><span> </span><span>()</span><span>)</span></span></code></pre>
<p>making it seem like you could write, say</p>
<pre is:raw="" tabindex="0"><code><span><span>let</span><span> </span><span>m</span><span> </span><span>=</span><span> (module </span><span>SomeGodotTypeModule</span><span>)</span></span>
<span></span>
<span><span>let</span><span>%</span><span>gfunc </span><span>g</span><span> </span><span>=</span><span> </span><span>[|</span><span> </span><span>ClassMethodFlags</span><span>.</span><span>default </span><span>|]</span><span> m m m (</span><span>fun</span><span> </span><span>x</span><span> </span><span>y</span><span> </span><span>-&gt;</span><span> x)</span></span></code></pre>
<p>or something, but that wouldn’t work.  This is due to the way I generate code, but basically you have to consider the <code>module</code> as part of the “syntax” for <code>gfunc</code>; it directly takes the packed module out of the expression and codegens using whatever the <code>module</code> operator is applied to (i.e. at <em>parse</em> time, not <em>run</em> time).  This is pretty messed up and not ideal, but the way I justify it to myself is that <code>let%gfunc</code> introduces it’s own syntactic form for declaring a <em>type signature</em> and <em>implementation</em> of a method.  This is, as far as I can tell, <em>not fixable</em>, but I’d love to hear your thoughts if you think it is.  (Briefly, the problem is that if you try to use real first-class modules, their types escape the scope of the function because the implementation function contains them.)</p>
<ol start="5">
<li><strong>General Clean-up:</strong> This implementation was designed sort of ad-hoc and in-the-moment, so some of the stuff doesn’t quite make sense in the module architecture.  This is fixable but lower priority until I iron out the rest of the implementation details of the other features.</li>
<li><strong>Better Build System Integration:</strong> I don’t know dune very well, so I got it <em>working</em>, but it’s not exactly nice to use and develop on.  Lots of ad-hoc calls to <code>dune exec ./gen_api.exe</code> when something has changed, and then trying to remember to format with <code>ocamlformat -i *.ml</code> — that sort of thing; I’m sure dune can help with it, but I didn’t invest the time into learning properly (but I will).  Fixable.</li>
<li><strong>Hot-Reloading:</strong> This should be possible, as Rust somehow manages it in Godot 4.2+ but I haven’t even begun to look into it.  Right now, if you change an OCaml file and recompile the extension, you probably need to restart the editor to see the effects.  Fixable.</li>
<li><strong>Name-mangling for Custom Operators:</strong> I just haven’t done this, but it wouldn’t be hard (and would probably make a good first issue, if you’re looking to contribute).  Right now custom operators defined as <code>gfunc</code> methods in OCaml probably can’t be used from GDScript, or most other languages.  Perhaps at all!  I haven’t even tried.  Fixable.</li>
<li><strong>Finishing the C API:</strong> These represent a work-in-progress set of bindings that are by no means complete at the moment.  That needs to change eventually.  Fixable.</li>
<li><strong>Embedding a TopLevel:</strong> I’d like to be able to interact with the Godot world, well, interactively, from an OCaml Toplevel.  This is on my backburner, but it’s harder than it looks at first, because the shared_object you have to build must of course be native code, but Toplevel and friends are (seemingly?) only available as bytecode.  Ping me if you have ideas here! Fixability unknown!</li>
<li><strong>Reliably Not Segfault:</strong> This is an unsafe C api, and so it’s extremely sharp, and the interface is very rough around the edges, as I figure out what exactly each value is supposed to actually do.  DO NOT TRY TO MAKE A PRODUCTION GAME IN GODOTCAML RIGHT NOW!  I’m going to fix things, but they definitely aren’t ready for prime-time at the moment.  This is fixable, but will take time and testing.</li>
<li><strong>Testing:</strong> Speaking of testing, I have none.  If you’d like to contribute here, I’d be happy to hear from you; I’m personally going to prioritize other above areas until things are a little more stable in the API, so I’m not constantly changing things and fixing <em>broken tests</em> (i.e. as opposed to <em>broken code that is being tested</em>).  Fixable.</li>
<li><strong>Type Safety Concerns:</strong> Right now all classes have the same object type.  This makes it nice for when you’re inheriting from them, as module inclusion “just works”, but obviously have negative effects on the type safety of the system.  Destructive updates of the module types during inclusion is one possible solution, but this requires you to have a module type for every Godot class from which you wish to inherit — a tall order.  I believe this is fixable with some thought — and indeed, it <em>must</em> be fixed in my eyes, even if it means more code gen for the module signatures — but I haven’t given it much thought beyond that.</li>
<li><strong>Support Multiple Native Type Sizes:</strong> Godot’s api supports multiple configurations, depending on if you want float64 or float32, and 64-bit and 32-bit systems.  Right now, I’m concentrating on the float64 + 64-bit configuration, but this should be expanded at some point in the future.  Fixable.</li>
</ol>
<p>For more, check the issue page on GitHub, as that is where I’ll be doing the development.</p>
<h2 id="to-be-continued">To Be Continued</h2>
<p>More details and a setup guide to come!  If you’d like to get involved, I’d love to hear from you — best place to find me is either GitHub or the OCaml Discourse currently.  Beware, the code is pretty funky at the moment, but it’ll get there!</p>
<p>Best,</p>
<p><em>Matt</em></p>

        <p><span>#open-source</span><span>#ocaml</span><span>#godot</span><span>#godotcaml</span><span>#announcement</span>
        </p>
      </div><div>
    <p><img alt="Author Photo" width="96" height="96" src="https://fizzixnerd.com/_astro/fizzixnerd_Z1RMnIC.png" loading="eager" decoding="async">
    </p>
    <div>
      <p>
          About Matt Walker
        </p>
      <p>Matt Walker is a software engineer with a love for all things Functional, DevOps, and Typed, currently residing in Toronto, Canada.</p>
    </div>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Live Stream of VC Funded Startups – Use It for Research and Sales (503 pts)]]></title>
            <link>https://old.reddit.com/r/SaaSMarketing/comments/1e4ktjy/i_creatd_a_tool_to_track_all_live_vc_investments/</link>
            <guid>40975351</guid>
            <pubDate>Tue, 16 Jul 2024 10:59:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/SaaSMarketing/comments/1e4ktjy/i_creatd_a_tool_to_track_all_live_vc_investments/">https://old.reddit.com/r/SaaSMarketing/comments/1e4ktjy/i_creatd_a_tool_to_track_all_live_vc_investments/</a>, See on <a href="https://news.ycombinator.com/item?id=40975351">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="searchexpando"><p><label>limit my search to r/SaaSMarketing</label></p><div id="moresearchinfo"><p>use the following search parameters to narrow your results:</p><dl><dt>subreddit:<i>subreddit</i></dt><dd>find submissions in "subreddit"</dd><dt>author:<i>username</i></dt><dd>find submissions by "username"</dd><dt>site:<i>example.com</i></dt><dd>find submissions from "example.com"</dd><dt>url:<i>text</i></dt><dd>search for "text" in url</dd><dt>selftext:<i>text</i></dt><dd>search for "text" in self post contents</dd><dt>self:yes (or self:no)</dt><dd>include (or exclude) self posts</dd><dt>nsfw:yes (or nsfw:no)</dt><dd>include (or exclude) results marked as NSFW</dd></dl><p>e.g. <code>subreddit:aww site:imgur.com dog</code></p><p><a href="https://www.reddit.com/wiki/search">see the search faq for details.</a></p></div><p><a href="https://www.reddit.com/wiki/search" id="search_showmore">advanced search: by author, subreddit...</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Engineer's Guide to Deep Learning: Understanding the Transformer Model (240 pts)]]></title>
            <link>https://www.interdb.jp/dl/</link>
            <guid>40974193</guid>
            <pubDate>Tue, 16 Jul 2024 07:01:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.interdb.jp/dl/">https://www.interdb.jp/dl/</a>, See on <a href="https://news.ycombinator.com/item?id=40974193">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body-inner" tabindex="-1">
          <article>
            


<h2 id="the-engineers-guide-to-deep-learning">The Engineer’s Guide To Deep Learning</h2>
<figure><a href="https://www.flickr.com/photos/x-ray_delta_one/35257686756">
    <img src="https://www.interdb.jp/dl/metropolis.jpg" width="480"> </a>
</figure>


<p>We are in the third golden age of AI.</p>
<p>In the previous two golden ages (1950s-1960s and the 1980s),
our expectations outpaced the capabilities of the technology at the time, leading to disappointment.
In contrast, the AI technology of the current golden age, which began in the mid-2010s, has consistently exceeded our expectations.</p>
<p>Among AI technologies, the Transformer, introduced in 2017, stands as a groundbreaking breakthrough.
Initially developed as a machine translation model, its impact has extended to permeate nearly every field.
Today, the Transformer model is considered essential knowledge for modern engineers.</p>
<p>The first goal of this document is to provide the shortest path for engineers to understand the Transformer.</p>
<h6 id="what-is-this-document">What is this document</h6>
<ul>
<li>A concise guidebook:<br>
This document provides just enough information to learn the Transformer.</li>
</ul>
<!--
Unlike a textbook, it avoids detailed explanations.
However, I will explain where appropriate documentation is not available or where readers find the material difficult to understand.
-->
<h6 id="what-this-document-provides">What this document provides</h6>
<ul>
<li>
<p>Working <a href="https://github.com/s-hironobu/guide2dl/tree/main" target="_blank">Python code examples</a> for hands-on learning:<br>
To enhance comprehension, this document provides working Python code examples that readers can run themselves.</p>
</li>
<li>
<p>References for further exploration:<br>
This document introduces readers to a variety of documentation options, recognizing that different individuals find different resources more accessible.</p>
</li>
</ul>

<div>
  <p>Contents</p>
  <div>

<ul>
<li>Part 1: <a href="https://www.interdb.jp/dl/part01.html">Neural Networks</a><br>Introduces the fundamental concepts of neural networks.</li>
<li>Part 2: <a href="https://www.interdb.jp/dl/part02.html">Recurrent Neural Networks (RNNs)</a><br>Explores RNNs, including LSTM and GRU.</li>
<li>Part 3: <a href="https://www.interdb.jp/dl/part03.html">Natural Language Processing (NLP) and Attention Mechanisms</a><br>Provides the essential principles of NLP, encompassing machine translation and attention mechanisms.</li>
<li>Part 4: <a href="https://www.interdb.jp/dl/part04.html">Transformer</a><br>Unravels the Transformer model.</li>
<li>Appendix: <a href="https://www.interdb.jp/dl/L-00">Basic Knowledge</a><br>Provides the minimum knowledge of Python and mathematics required to understand the Transformer.</li>
</ul>
</div>
</div>

<div>
    <p>
    <label for="expand-05cf400c8aed19a98bb9d3ea186aea44">
        <i></i>
        <i></i>
        Change History (since 21st May, 2024)
    </label></p>
</div>
<h5 id="next-goal">Next goal</h5>
<p>Many Transformer-based technologies are currently being developed.
There will definitely be another major breakthrough in the near future.
I might write about them if I have time.</p>
<h5 id="copyright">Copyright</h5>
<p>© Copyright ALL Right Reserved, Hironobu SUZUKI.</p>
<p>For any inquiries regarding the use of this document or any of its figures, please contact me after reading the following FAQ:</p>

<div>
    <p>
    <label for="expand-988bd57a55344cb0d300647b4c8666b0">
        <i></i>
        <i></i>
        FAQ
    </label></p><div id="expandcontent-988bd57a55344cb0d300647b4c8666b0">

<p>Since publishing my content, I’ve been fortunate to receive a lot of positive feedback, which is truly gratifying.
However, I’ve also encountered a few instances where people tried to misuse my content for self-promotion in the past.</p>
<!--
(For more details, refer to the FAQ in "[the internals of PostgreSQL](https://www.interdb.jp/pg/)")
-->
<p>These experiences have shaped the approach I’ve outlined below:</p>
<ol>
<li>Who can use this document freely?<br>
If you are a teacher or a student belonging to an educational organization, you can freely use this document and figures in your study.
Anyone can use this document and figures with noncommercial meetings and lectures, if you state the link to this site and the copyright; otherwise, contact me.</li>
<li>Is it available for commercial contents?<br>
This content can be used under two options:
<ul>
<li>Revenue Share:
You can leverage this content after a revenue share agreement is signed.
Under this agreement, you’ll share 20% of the sales generated from using this content including the github repository.</li>
<li>Full Buyout:
In very rare cases, I consider requests for full commercial use of all content on this site (and the github repository).
For a complete buyout of all content rights, the cost is €10,000,000.</li>
</ul>
</li>
<li>Why doesn’t the author waive the copyright of this document or use the creative commons license?<br>
I’d like to ask you what problems you have by that I keep on having the copyright of my document.</li>
</ol>
</div>
</div>
<p>When you send me an email, please <strong>provide at least two SNS addresses (e.g. LinkedIn, Twitter) for verification purposes</strong>.
Due to the XZ backdoor incident, I no longer accept contact from anonymous individuals.</p>
<p><span><span><i></i></span><span>Exception</span></span> Educational institutions can use this document freely.</p>

<h6 id="hironobu-suzuki">Hironobu SUZUKI</h6>
<p>I am a software programmer/engineer, the author of:</p>
<ul>
<li><a href="http://www.interdb.jp/pg/" target="_blank">The Internals of PostgreSQL</a></li>
<li><a href="http://www.interdb.jp/dl/" target="_blank">The Engineer’s Guide To Deep Learning</a></li>
<li><a href="https://github.com/s-hironobu/pg_plan_inspector" target="_blank">pg_plan_inspector</a></li>
<li><a href="https://github.com/s-hironobu/pg_tuner" target="_blank">pg_tuner</a></li>
</ul>
<p>I graduated from graduate school in information engineering (M.S. in Information Engineering),
had worked for several companies as a software developer and technical manager/director,
and published seven books (4 PostgreSQL books and 3 MySQL books) in Japanese and a Chinese book.</p>
<p>As a director of the Japan PostgreSQL Users Group (2010-2016),
I organized the largest (non-commercial) technical seminar/lecture on PostgreSQL in Japan for more than six years,
and also served as the program committee chair of the Japan PostgreSQL Conference in 2013 and as a member in 2008 and 2009.
In June 2022, <a href="https://postgresql.life/post/hironobu_suzuki/" target="_blank">my interview article</a> was published.</p>
<p>Cuando era joven, vivió en Sudamérica por unos años. Recientemente, a veces vuelve a allí.</p>
<p>I am looking for a new job, applying ML and AI technologies to DBMS.</p>
<p>I’m interested in History, Animal Rights, Cosmology, Social Issues, Environment Issues. I play the piano and guitar. Vegetarian. I love animals, music, science.</p>

            
          </article>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI illegally barred staff from airing safety risks, whistleblowers say (152 pts)]]></title>
            <link>https://www.washingtonpost.com/technology/2024/07/13/openai-safety-risks-whistleblower-sec/</link>
            <guid>40974154</guid>
            <pubDate>Tue, 16 Jul 2024 06:51:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/technology/2024/07/13/openai-safety-risks-whistleblower-sec/">https://www.washingtonpost.com/technology/2024/07/13/openai-safety-risks-whistleblower-sec/</a>, See on <a href="https://news.ycombinator.com/item?id=40974154">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="PBIKSWH2CJH27NQS6BVBMESB24" data-el="text" dir="null">OpenAI whistleblowers have filed a complaint with the Securities and Exchange Commission alleging the artificial intelligence company illegally prohibited its employees from <a href="https://www.washingtonpost.com/technology/2024/06/04/openai-employees-ai-whistleblowers/?itid=lk_inline_manual_2" target="_blank">warning </a>regulators about the grave risks its technology may pose to humanity, calling for an investigation.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="I2BEYH4RENHTBLYB2G5VYLGMDU" data-el="text" dir="null">The whistleblowers said OpenAI issued its employees overly restrictive employment, severance and nondisclosure agreements that could have led to penalties against workers who raised concerns about OpenAI to federal regulators,<a href="https://www.washingtonpost.com/documents/83df0e55-546c-498a-9efc-06fac591904e.pdf?itid=lk_inline_manual_4" target="_blank"> according to a seven-page letter</a> sent to the SEC commissioner earlier this month that referred to the formal complaint. The letter was obtained exclusively by The Washington Post.</p></div><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="U7EFJOVSBJANHMID5ZODY4GNNI" data-el="text" dir="null">OpenAI made staff sign employee agreements that required them to waive their federal rights to whistleblower compensation, the letter said. These agreements also required OpenAI staff to get prior consent from the company if they wished to disclose information to federal authorities. OpenAI did not create exemptions in its employee nondisparagement clauses for disclosing securities violations to the SEC.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="WADFSEVK5NHI3JTJURT65MRGLI" data-el="text" dir="null">These overly broad agreements violated long-standing federal laws and regulations meant to protect whistleblowers who wish to reveal damning information about their company anonymously and without fear of retaliation, the letter said.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="57HMR3A3IJG7ND4UJF2ZKP76AY" data-el="text" dir="null">“These contracts sent a message that ‘we don’t want … employees talking to federal regulators,’” said one of the whistleblowers, who spoke on the condition of anonymity for fear of retaliation. “I don’t think that AI companies can build technology that is safe and in the public interest if they shield themselves from scrutiny and dissent.”</p><div role="group" aria-roledescription="carousel" data-qa="article-body"><h2>GET CAUGHT UP<p>Stories to keep you informed</p></h2></div><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="QBGXLIXUFJGQFD7HASNP3JPDIY" data-el="text" dir="null">In a statement, Hannah Wong, a spokesperson for OpenAI said, “Our whistleblower policy protects employees’ rights to make protected disclosures. Additionally, we believe rigorous debate about this technology is essential and have already made important changes to our departure process to remove nondisparagement terms.”</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="MLHFUMOBBFEELIFOVC4BKMCAQY" data-el="text" dir="null">The whistleblowers’ letter comes amid concerns that OpenAI, which started as a<b> </b>nonprofit with an altruistic mission, is putting profit before safety in creating its technology. The Post <a href="https://www.washingtonpost.com/technology/2024/07/12/openai-ai-safety-regulation-gpt4/?itid=lk_inline_manual_13" target="_blank">reported Friday</a> that OpenAI rushed out its latest AI model that fuels ChatGPT to meet a May release date set by company leaders, despite employee concerns that the company “failed” to live up to its own security testing protocol that it said would keep its AI safe from catastrophic harms, like teaching users to build bioweapons or helping hackers develop new kinds of cyberattacks. In a statement, OpenAI spokesperson Lindsey Held said the company “didn’t cut corners on our safety process, though we recognize the launch was stressful for our teams.”</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="TH3SN445UVE7PC4L3TFGYHYC5U" data-el="text" dir="null">Tech companies’ strict confidentiality agreements have long vexed workers and regulators. During the #MeToo movement and national protests in response to the murder of George Floyd, <a href="https://www.washingtonpost.com/news/powerpost/paloma/the-technology-202/2020/07/02/the-technology-202-here-s-what-facebook-ad-boycott-organizers-plan-to-tell-mark-zuckerberg/5efcc6f388e0fa7b44f6c2fd/?itid=lk_inline_manual_14" target="_blank">workers warned</a> that such legal agreements limited their ability to report sexual misconduct or racial discrimination. Regulators, meanwhile, have worried that the terms muzzle tech employees who could alert them to misconduct in the opaque<b> </b>tech sector, especially amid allegations that companies’ algorithms promote content that undermines elections, public health and children’s safety.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="PBRT3ZCHC10B7ATVQ4TZ16V3MW" data-el="text" dir="null">The rapid advance of artificial intelligence sharpened<b> </b>policymakers’ concerns about the power of the tech industry, prompting a flood of calls for regulation. In the United States, AI companies are largely operating in a legal vacuum, and policymakers say they cannot effectively create new AI policies without the help of whistleblowers, who can help explain the potential threats posed by the fast-moving technology.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="1MJTVFK93N5C5ANZ20PUGG5TW8" data-el="text" dir="null">“OpenAI’s policies and practices appear to cast a chilling effect on whistleblowers’ right to speak up and receive due compensation for their protected disclosures,” said Sen. Chuck Grassley (R-Iowa) in a statement to The Post. “In order for the federal government to stay one step ahead of artificial intelligence, OpenAI’s nondisclosure agreements must change.”</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="652ZX455XZAFFCRJF54SSPIDIU" data-el="text" dir="null">A copy of the letter, addressed to SEC chairman Gary Gensler, was sent to Congress. The Post obtained the whistleblower letter from Grassley’s office.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="TNEC468CUD38VEBX5T95KAUFTW" data-el="text" dir="null">The official complaints referred to<b> </b>in the letter were submitted to the SEC in June. Stephen Kohn, a lawyer representing the OpenAI whistleblowers, said the SEC has responded to the complaint.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="7YWSZPAHU5ESVBEY4UCH3TVOAQ" data-el="text" dir="null">It could not be determined whether the SEC has launched an investigation. The agency declined to comment.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="25MGV72VVNFVPAU2QHSNMBBD7U" data-el="text" dir="null">The SEC must take “swift and aggressive” steps to address these illegal agreements, the letter says, as they might be relevant to the wider AI sector and could violate the October <a href="https://www.washingtonpost.com/technology/2023/10/30/biden-artificial-intelligence-executive-order/?itid=lk_inline_manual_24" target="_blank">White House executive order</a> that demands AI companies develop the technology safely.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="YF6YXKL6QJABXFSKJOMEJK2LIA" data-el="text" dir="null">“At the heart of any such enforcement effort is the recognition that insiders … must be free to report concerns to federal authorities,” the letter said. “Employees are in the best position to detect and warn against the types of dangers referenced in the Executive Order and are also in the best position to help ensure that AI benefits humanity, instead of having the opposite effect.”</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="VBLIBHJZ7RH67L564Q47DMO2TI" data-el="text" dir="null">These agreements threatened employees with criminal prosecutions if they reported violations of law to federal authorities under trade secret laws, Kohn said. Employees were instructed to keep company information confidential and threatened with “severe sanctions” without recognition of their right to report such information to the government, he said.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="MTDF47KSXFFCHGKVEQ6P24ZLXQ" data-el="text" dir="null">“In terms of oversight of AI, we are at the very beginning,” Kohn said. “We need employees to step forward, and we need OpenAI to be open.”</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="63IGWQ6QEBERXD7HMFWTBTM6BY" data-el="text" dir="null">The SEC should require OpenAI to produce every employment, severance and investor agreement that contains nondisclosure clauses to ensure they don’t violate federal laws, the letter said. Federal regulators should require OpenAI to notify all past and current employees of the violations the company committed as well as notify them that they have the right to confidentially and anonymously report any violations of law to the SEC. The SEC should issue fines to OpenAI for “each improper agreement” under SEC law and direct OpenAI to cure the “chilling effect” of its past practices, according to the whistleblowers letter.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="T4GVHMFCIJBUZH4UKMEZ5GO34Y" data-el="text" dir="null">Multiple tech employees, including <a href="https://www.washingtonpost.com/technology/2021/10/26/frances-haugen-facebook-whistleblower-documents/?itid=lk_inline_manual_32" target="_blank">Facebook whistleblower Frances Haugen</a>, have filed complaints with the SEC, which established a whistleblower program in the wake of the 2008 financial crisis.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="5GFZHILTJRHHNJUGOYTAWL5ZKE" data-el="text" dir="null">Fighting back against Silicon Valley’s use of NDAs to “monopolize information” has been a protracted battle, said Chris Baker, a San Francisco lawyer. He won a $27 million settlement for Google employees in December against claims that the tech giant used onerous confidentiality agreements to block whistleblowing and other protected activity. Now tech companies are increasingly fighting back with clever ways to deter speech, he said.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="VQNXXU4DJ97DQ4N4YTY49QZ82C" data-el="text" dir="null">“Employers have learned that the cost of leaks is sometimes way greater than the cost of litigation, so they are willing to take the risk,” Baker said.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[For advertising: Firefox now collects user data by default (541 pts)]]></title>
            <link>https://www.heise.de/en/news/For-advertising-Firefox-now-collects-user-data-by-default-9801345.html</link>
            <guid>40974112</guid>
            <pubDate>Tue, 16 Jul 2024 06:41:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.heise.de/en/news/For-advertising-Firefox-now-collects-user-data-by-default-9801345.html">https://www.heise.de/en/news/For-advertising-Firefox-now-collects-user-data-by-default-9801345.html</a>, See on <a href="https://news.ycombinator.com/item?id=40974112">Hacker News</a></p>
Couldn't get https://www.heise.de/en/news/For-advertising-Firefox-now-collects-user-data-by-default-9801345.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Peter Buxtun, whistleblower who exposed Tuskegee syphilis study, has died (234 pts)]]></title>
            <link>https://www.theguardian.com/us-news/article/2024/jul/15/peter-buxtun-tuskegee-whistleblower-dies</link>
            <guid>40973422</guid>
            <pubDate>Tue, 16 Jul 2024 03:17:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/us-news/article/2024/jul/15/peter-buxtun-tuskegee-whistleblower-dies">https://www.theguardian.com/us-news/article/2024/jul/15/peter-buxtun-tuskegee-whistleblower-dies</a>, See on <a href="https://news.ycombinator.com/item?id=40973422">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Peter Buxtun, the whistleblower who revealed that the US government allowed hundreds of Black men in rural <a href="https://www.theguardian.com/us-news/alabama" data-link-name="in body link" data-component="auto-linked-tag">Alabama</a> to go untreated for syphilis in what became known as the Tuskegee study, has died. He was 86.</p><p>Buxtun died on 18 May of Alzheimer’s disease in Rocklin, California, according to his attorney, Minna Fernan.</p><p>Buxtun is revered as a hero to public health scholars and ethicists for his role in bringing to light the most notorious medical research scandal in US history. Documents that Buxtun provided to the Associated Press, and its subsequent investigation and reporting, led to a public outcry that ended the study in 1972.</p><p>Forty years earlier, in 1932, federal scientists began studying 400 Black men in Tuskegee, Alabama, who were infected with syphilis. When antibiotics became available in the 1940s that could treat the disease, federal health officials ordered that the drugs be withheld. The study became an observation of how the disease ravaged the body over time.</p><p>In the mid-1960s, Buxtun was a federal public health employee working in San Francisco when he overheard a co-worker talking about the study. The research was not exactly a secret – about a dozen medical journal articles about it had been published in the previous 20 years. But hardly anyone had raised any concerns about how the experiment was being conducted.</p><p>“This study was completely accepted by the American medical community,” said Ted Pestorius of the US Centers for Disease Control and Prevention, speaking at a 2022 program marking the 50th anniversary of the end of the study.</p><p>Buxtun had a different reaction. After learning more about the study, he raised ethical concerns in a 1966 letter to officials at the CDC. In 1967, he was summoned to a meeting in Atlanta, where he was chewed out by agency officials for what they deemed to be impertinence. Repeatedly, agency leaders rejected his complaints and his call for the men in Tuskegee to be treated.</p><p>He left the US Public Health Service and attended law school, but the study ate at him. In 1972, he provided documents about the research to Edith Lederer, an AP reporter he had met in San Francisco. Lederer passed the documents to the AP investigative reporter Jean Heller, telling her colleague: “I think there might be something here.”</p><p>Heller’s story was published on 25 July 1972, leading to congressional hearings, a class-action lawsuit that resulted in a $10m settlement and the study’s termination about four months later. In 1997, President Bill Clinton formally apologized for the study, calling it “shameful”.</p><p>The leader of a group dedicated to the memory of the study participants said on Monday they were grateful to Buxtun for exposing the experiment.</p><p>“We are thankful for his honesty and his courage,” said Lille Tyson Head, whose father was in the study.</p><p>Buxtun was born in Prague in 1937. His father was Jewish, and his family immigrated to the US in 1939 from Nazi-occupied Czechoslovakia, eventually settling in Irish Bend, Oregon, on the Columbia River.</p><p>In his complaints to federal health officials, he drew comparisons between the Tuskegee study and medical experiments Nazi doctors had conducted on Jews and other prisoners. Federal scientists did not believe they were guilty of the same kind of moral and ethical sins, but after the Tuskegee study was exposed, the government put in place new rules about how it conducts medical research. Today, the study is often blamed for the unwillingness of some African Americans to participate in medical research.</p><p>“Peter’s life experiences led him to immediately identify the study as morally indefensible and to seek justice in the form of treatment for the men. Ultimately, he could not relent,” said the CDC’s Pestorius.</p><p>Buxtun attended the University of Oregon, served in the US army as a combat medic and psychiatric social worker and joined the federal health service in 1965.</p><p>Buxtun went on to write, give presentations and win awards for his involvement in the Tuskegee study. A global traveler, he collected and sold antiques, especially military weapons and swords and gambling equipment from California’s gold rush era.</p><p>He also spent more than 20 years trying to recover his family’s properties confiscated by the Nazis and was partly successful.</p><p>“Peter was wise, witty, classy and unceasingly generous,” said David M Golden, a close friend of Buxtun’s for over 25 years. “He was a staunch advocate for personal freedoms and spoke often against prohibition, whether it be drugs, prostitution or firearms.”</p><p>Another longtime friend Angie Bailie said she attended many of Buxtun’s presentations about Tuskegee.</p><p>“Peter never ended a single talk without fighting back tears,” she said</p><p>Buxtun himself could be self-effacing about his actions, saying he did not anticipate the vitriolic reaction of some health officials when he started questioning the study’s ethics.</p><p>At a Johns Hopkins University forum in 2018, Buxtun was asked where he got the moral strength to blow the whistle.</p><p>“It wasn’t strength,” he said. “It was stupidity.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Exo: Run your own AI cluster at home with everyday devices (355 pts)]]></title>
            <link>https://github.com/exo-explore/exo</link>
            <guid>40973339</guid>
            <pubDate>Tue, 16 Jul 2024 02:55:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/exo-explore/exo">https://github.com/exo-explore/exo</a>, See on <a href="https://news.ycombinator.com/item?id=40973339">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto">
<themed-picture data-catalyst-inline="true"><picture>
  <source media="(prefers-color-scheme: light)" srcset="https://github.com/exo-explore/exo/raw/main/docs/exo-logo-black-bg.jpg">
  <img alt="exo logo" src="https://github.com/exo-explore/exo/raw/main/docs/exo-logo-transparent.png" width="50%" height="50%">
</picture></themed-picture>
<p dir="auto">exo: Run your own AI cluster at home with everyday devices. Maintained by <a href="https://x.com/exolabs_" rel="nofollow">exo labs</a>.</p>

</div>
<hr>
<p dir="auto">Forget expensive NVIDIA GPUs, unify your existing devices into one powerful GPU: iPhone, iPad, Android, Mac, Linux, pretty much any device!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Get Involved</h2><a id="user-content-get-involved" aria-label="Permalink: Get Involved" href="#get-involved"></a></p>
<p dir="auto">exo is <strong>experimental</strong> software. Expect bugs early on. Create issues so they can be fixed. The <a href="https://x.com/exolabs_" rel="nofollow">exo labs</a> team will strive to resolve issues quickly.</p>
<p dir="auto">We also welcome contributions from the community. We have a list of bounties in <a href="https://docs.google.com/spreadsheets/d/1cTCpTIp48UnnIvHeLEUNg1iMy_Q6lRybgECSFCoVJpE/edit?usp=sharing" rel="nofollow">this sheet</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Wide Model Support</h3><a id="user-content-wide-model-support" aria-label="Permalink: Wide Model Support" href="#wide-model-support"></a></p>
<p dir="auto">exo supports LLaMA and other popular models.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Dynamic Model Partitioning</h3><a id="user-content-dynamic-model-partitioning" aria-label="Permalink: Dynamic Model Partitioning" href="#dynamic-model-partitioning"></a></p>
<p dir="auto">exo optimally splits up models based on the current network topology and device resources available. This enables you to run larger models than you would be able to on any single device.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Automatic Device Discovery</h3><a id="user-content-automatic-device-discovery" aria-label="Permalink: Automatic Device Discovery" href="#automatic-device-discovery"></a></p>
<p dir="auto">exo will automatically discover other devices using the best method available. Zero manual configuration.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">ChatGPT-compatible API</h3><a id="user-content-chatgpt-compatible-api" aria-label="Permalink: ChatGPT-compatible API" href="#chatgpt-compatible-api"></a></p>
<p dir="auto">exo provides a ChatGPT-compatible API for running models. It's a one-line change in your application to run models on your own hardware using exo.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Device Equality</h3><a id="user-content-device-equality" aria-label="Permalink: Device Equality" href="#device-equality"></a></p>
<p dir="auto">Unlike other distributed inference frameworks, exo does not use a master-worker architecture. Instead, exo devices connect p2p. As long as a device is connected somewhere in the network, it can be used to run models.</p>
<p dir="auto">Exo supports different partitioning strategies to split up a model across devices. The default partitioning strategy is <a href="https://github.com/exo-explore/exo/blob/main/topology/ring_memory_weighted_partitioning.py">ring memory weighted partitioning</a>. This runs an inference in a ring where each device runs a number of model layers proportional to the memory of the device.</p>
<themed-picture data-catalyst-inline="true"><picture>
  <img alt="ring topology" src="https://github.com/exo-explore/exo/raw/main/docs/ring-topology.png" width="30%" height="30%">
</picture></themed-picture>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">The current recommended way to install exo is from source.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">From source</h3><a id="user-content-from-source" aria-label="Permalink: From source" href="#from-source"></a></p>
<p dir="auto">Python&gt;=3.12.0 is required because of <a href="https://github.com/exo-explore/exo/issues/5" data-hovercard-type="issue" data-hovercard-url="/exo-explore/exo/issues/5/hovercard">issues with asyncio</a> in previous versions.</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/exo-explore/exo.git
cd exo
pip install -r requirements.txt"><pre>git clone https://github.com/exo-explore/exo.git
<span>cd</span> exo
pip install -r requirements.txt</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example Usage on Multiple MacOS Devices</h3><a id="user-content-example-usage-on-multiple-macos-devices" aria-label="Permalink: Example Usage on Multiple MacOS Devices" href="#example-usage-on-multiple-macos-devices"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Device 1:</h4><a id="user-content-device-1" aria-label="Permalink: Device 1:" href="#device-1"></a></p>

<p dir="auto"><h4 tabindex="-1" dir="auto">Device 2:</h4><a id="user-content-device-2" aria-label="Permalink: Device 2:" href="#device-2"></a></p>

<p dir="auto">That's it! No configuration required - exo will automatically discover the other device(s).</p>
<p dir="auto">The native way to access models running on exo is using the exo library with peer handles. See how in <a href="https://github.com/exo-explore/exo/blob/main/examples/llama3_distributed.py">this example for Llama 3</a>.</p>
<p dir="auto">exo also starts a ChatGPT-compatible API endpoint on <a href="http://localhost:8000/" rel="nofollow">http://localhost:8000</a>. Note: this is currently only supported by tail nodes (i.e. nodes selected to be at the end of the ring topology). Example request:</p>
<div data-snippet-clipboard-copy-content="curl http://localhost:8000/v1/chat/completions \
  -H &quot;Content-Type: application/json&quot; \
  -d '{
     &quot;model&quot;: &quot;llama-3-70b&quot;,
     &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What is the meaning of exo?&quot;}],
     &quot;temperature&quot;: 0.7
   }'"><pre><code>curl http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
     "model": "llama-3-70b",
     "messages": [{"role": "user", "content": "What is the meaning of exo?"}],
     "temperature": 0.7
   }'
</code></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="curl -X POST http://localhost:8001/api/v1/chat -H &quot;Content-Type: application/json&quot; -d '{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What is the meaning of life?&quot;}]}'"><pre>curl -X POST http://localhost:8001/api/v1/chat -H <span><span>"</span>Content-Type: application/json<span>"</span></span> -d <span><span>'</span>{"messages": [{"role": "user", "content": "What is the meaning of life?"}]}<span>'</span></span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Inference Engines</h2><a id="user-content-inference-engines" aria-label="Permalink: Inference Engines" href="#inference-engines"></a></p>
<p dir="auto">exo supports the following inference engines:</p>
<ul dir="auto">
<li>✅ <a href="https://github.com/exo-explore/exo/blob/main/inference/mlx/sharded_inference_engine.py">MLX</a></li>
<li>✅ <a href="https://github.com/exo-explore/exo/blob/main/inference/tinygrad/inference.py">tinygrad</a></li>
<li>🚧 <a href="https://github.com/exo-explore/exo/blob/main/TODO">llama.cpp</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Networking Modules</h2><a id="user-content-networking-modules" aria-label="Permalink: Networking Modules" href="#networking-modules"></a></p>
<ul dir="auto">
<li>✅ <a href="https://github.com/exo-explore/exo/blob/main/networking/grpc">GRPC</a></li>
<li>🚧 <a href="https://github.com/exo-explore/exo/blob/main/TODO">Radio</a></li>
<li>🚧 <a href="https://github.com/exo-explore/exo/blob/main/TODO">Bluetooth</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Known Issues</h2><a id="user-content-known-issues" aria-label="Permalink: Known Issues" href="#known-issues"></a></p>
<ul dir="auto">
<li>🚧 As the library is evolving so quickly, the iOS implementation has fallen behind Python. This is being addressed, and longer term we will push out an approach that will unify the implementations so we don't have to maintain separate implementations.</li>
</ul>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>