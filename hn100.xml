<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 21 Nov 2025 23:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Helping Valve to Power Up Steam Devices (327 pts)]]></title>
            <link>https://www.igalia.com/2025/11/helpingvalve.html</link>
            <guid>46006616</guid>
            <pubDate>Fri, 21 Nov 2025 17:29:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.igalia.com/2025/11/helpingvalve.html">https://www.igalia.com/2025/11/helpingvalve.html</a>, See on <a href="https://news.ycombinator.com/item?id=46006616">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
          

<p>Last week, Valve stunned the computer gaming world by <a href="https://www.geekwire.com/2025/valve-surprises-with-3-new-hardware-devices-in-a-full-circle-moment-for-gaming-giant/">unveiling three new gaming devices at once</a>: the Steam Frame, a wireless VR headset; the Steam Machine, a gaming console in the vein of a PlayStation or Xbox; and the Steam Controller, a handheld game controller.  Successors to the highly successful <a href="https://store.steampowered.com/valveindex">Valve Index</a> and <a href="https://www.steamdeck.com/en/">Steam Deck</a>, these devices are set to be released in the coming year.</p>

<p>Igalia has long worked with Valve on SteamOS, which will power the Machine and Frame, and is excited to be contributing to these new devices, particularly the Frame.  The Frame, unlike the Machine or Deck which have x86 CPUs, runs on an ARM-based CPU.</p>

<p>Under normal circumstances, this would mean that only games compiled to run on ARM chips could be played on the Frame.  In order to get around this barrier, a translation layer called <a href="https://github.com/FEX-Emu/FEX">FEX</a> is used to run applications compiled for x86 chips (which are used in nearly all gaming PCs) on ARM chips by translating the x86 machine code into ARM64 machine code.</p>

<p>“If you love video games, like I do, working on FEX with Valve is a dream come true,” said <a href="https://igalia.com/team/pmatos">Paulo Matos</a>, an engineer with Igalia’s <a href="https://www.igalia.com/technology/compilers">Compilers Team</a>.  Even so, the challenges can be daunting, because making sure the translation is working often requires manual QA rather than automated testing.  “You have to start a game, sometimes the error shows up in the colors or sound, or how the game behaves when you break down the door in the second level. Just debugging this can take a while,” said Matos.  “For optimization work I did early last year, I used a game called <em>Psychonauts</em> to test it. I must have played the first 3 to 4 minutes of the game many, many times for debugging. Looking at my history, Steam tells me I played it for 29 hours, but it was always the first few minutes, nothing else.”</p>

<p>Beyond the CPU, the Qualcomm Adreno 750 GPU used in the Steam Frame introduced its own set of challenges when it came to running desktop games, and other complex workloads, on these devices. Doing so requires a rock-solid Vulkan driver that can ensure correctness, eliminating major rendering bugs, while maintaining high performance.  This is a very difficult combination to achieve, and yet that’s exactly what we’ve done for Valve with <a href="https://mesa3d.org/">Mesa3D</a> <a href="https://docs.mesa3d.org/drivers/freedreno.html#turnip">Turnip</a>, a FOSS Vulkan driver for Qualcomm Adreno GPUs.</p>







<figure>
<img-comparison-slider>
<img slot="first" src="https://www.igalia.com/assets/i/news/valve-monster_hunter_world_misrendering.jpg">
<img slot="second" src="https://www.igalia.com/assets/i/news/valve-monster_hunter_world_correct_rendering.jpg">
</img-comparison-slider>
<figcaption>A sliding comparison of the main menu in the game “Monster Hunter World”, before and after fixing a rendering error</figcaption>
</figure>

<p>Before we started our work, critical optimizations such as LRZ (which you can learn more about from <a href="https://blogs.igalia.com/dpiliaiev/adreno-lrz/">our blog post here</a>) or the <a href="https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/12128">autotuner</a> (and its subsequent <a href="https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/37802">overhaul</a>) weren’t in place.  Even worse, there wasn’t support for the Adreno 700-series GPUs at all, which <a href="https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/21931">we eventually added</a> along with support for <a href="https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/26461">tiled rendering</a>.</p>

<p>“We implemented many Vulkan extensions and reviewed numerous others,” said <a href="https://www.igalia.com/team/dpiliaiev">Danylo Piliaiev</a>, an engineer on the <a href="https://www.igalia.com/technology/graphics">Graphics Team</a>. “Over the years, we ensured that D3D11, D3D12, and OpenGL games rendered correctly through DXVK, vkd3d-proton, and Zink, investigating many rendering issues along the way. We achieved higher correctness than the proprietary driver and, in many cases, Mesa3D Turnip is faster as well.”</p>

<p>We’ve worked with many wonderful people from Valve, Google, and other companies to iterate on the Vulkan driver over the years in order to introduce new features, bug fixes, performance improvements, as well as debugging workflows. Some of those people decided to join Igalia later on, such as our colleague and Graphics Team developer <a href="https://igalia.com/team/anholt">Emma Anholt</a>. “I’ve been working on Mesa for 22 years, and it’s great to have a home now where I can keep doing that work, across hardware projects, where the organization prioritizes the work experience of its developers and empowers them within the organization.”</p>

<p>Valve’s support in all this cannot be understated, either.  Their choice to build their devices using open software like Mesa3D Turnip and FEX means they’re committed to working on and supporting improvements and optimizations that become available to anyone who uses the same open-source projects.</p>

<p>“We’ve received a lot of positive feedback about significantly improved performance and fewer rendering glitches from hobbyists who use these projects to run PC games on Android phones as a result of our work,” said <a href="https://igalia.com/team/mark">Dhruv Mark Collins</a>, another Graphics Team engineer working on Turnip. “And it goes both ways! We’ve caught a couple of nasty bugs because of that widespread testing, which really emphasizes why the FOSS model is beneficial for everyone involved.”</p>

<figure>
<img src="https://www.igalia.com/assets/i/news/valve-turnip_performance_improvement_trend.png" alt="">
<figcaption>Automatically-measured performance improvement in Turnip since June 2025</figcaption>
</figure>

<p>An interesting area of graphics driver development is all the compiler work that is involved. Vulkan drivers such as Mesa3D Turnip need to process shader programs sent by the application to the GPU, and these programs govern how pixels in our screens are shaded or colored with geometry, textures, and lights while playing games. <a href="https://igalia.com/team/jnoorman">Job Noorman</a>, an engineer from our Compilers Team, made significant contributions to the compiler used by Mesa3D Turnip. He also contributed to the Mesa3D NIR shader compiler, a common part that all Mesa drivers use, including <a href="https://docs.mesa3d.org/drivers/radv.html">RADV</a> (most popularly used on the Steam Deck) or <a href="https://docs.mesa3d.org/drivers/v3d.html">V3DV</a> (used on Raspberry Pi boards).</p>

<p>As is normal for Igalia, while we focused on delivering results for our customer, we also made our work as widely useful as possible.  For example: “While our target throughout our work has been the Snapdragon 8 Gen 3 that’s in the Frame, much of our work extends back through years of Snapdragon hardware, and we regression test it to make sure it stays Vulkan conformant,” said Anholt.  This means that Igalia’s work for the Frame has consistently passed Vulkan’s Conformance Test Suite (CTS) of over 2.8 million tests, some of which Igalia is involved in creating.</p>

<p>Our very own Vulkan CTS expert <a href="https://igalia.com/team/rgarcia">Ricardo García</a> says:</p>

<blockquote>
  <p>Igalia and other Valve contractors actively participate in several areas inside the Khronos Group, the organization maintaining and developing graphics API standards like Vulkan. We contribute specification fixes and feedback, and we are regularly involved in the development of many new Vulkan extensions. Some of these end up being critical for game developers, like mesh shading. Others ensure a smooth and efficient translation of other APIs like DirectX to Vulkan, or help take advantage of hardware features to ensure applications perform great across multiple platforms, both mobile like the Steam Frame or desktop like the Steam Machine. Having Vulkan CTS coverage for these new extensions is a critical step in the release process, helping make sure the specification is clear and drivers implement it correctly, and Igalia engineers have contributed millions of source code lines and tests since our collaboration with Valve started.</p>
</blockquote>

<p>A huge challenge we faced in moving forward with development is ensuring that we didn’t introduce regressions, small innocent-seeming changes can completely break rendering on games in a way that even CTS might not catch. What automated testing could be done was often quite constrained, but Igalians found ways to push through the barriers.  “I made a continuous integration test to automatically run single-frame captures of a wide range of games spanning D3D11, D3D9, D3D8, Vulkan, and OpenGL APIs,” said Piliaiev, about the development covered in his <a href="https://youtube.com/watch?v=AKGA6wsX1hs">recent XDC 2025 talk</a>, “ensuring that we don’t have rendering or performance regressions.”</p>

<p>Looking ahead, Igalia’s work for Valve will continue to deliver benefits to the wider Linux Gaming ecosystem.  For example, the Steam Frame, as a battery-powered VR headset, needs to deliver high performance within a limited power budget.  A way to address this is to create a more efficient task scheduler, which is something <a href="https://www.igalia.com/team/changwoo">Changwoo Min</a> of Igalia’s <a href="https://www.igalia.com/technology/kernel">Kernel Team</a> has been working on.  As he says, “I have been developing a customized CPU scheduler for gaming, named <a href="https://lpc.events/event/18/contributions/1713/attachments/1425/3058/scx_lavd-lpc-mc-24.pdf">LAVD: Latency-criticality Aware Virtual Deadline scheduler</a>.”</p>

<p>In general terms, a scheduler automatically identifies critical tasks and dynamically boosts their deadlines to improve responsiveness.  Most task schedulers don’t take energy consumption into account, but the Rust-based LAVD is different.  “LAVD makes scheduling decisions considering each chip’s performance versus energy trade-offs. It measures and predicts the required computing power on the fly, then selects the best set of CPUs to meet that demand with minimal energy consumption,” said Min.</p>

<p>One of our other kernel engineers, <a href="https://www.igalia.com/team/mwen">Melissa Wen</a>, has been working on AMD kernel display drivers to maintain good color management and HDR support for SteamOS across AMD hardware families, both for the Steam Deck and the Steam Machine. This is especially important with newer display hardware in the Steam Machine, which features some notable differences in color capabilities, aiming for more powerful and efficient color management which necessitated driver work.</p>

<p>…and that’s a wrap! We will continue our efforts toward improving future versions of SteamOS, and with a partner as strongly supportive as Valve, we expect to do more work to make Linux gaming even better.  If any of that sounded interesting and you’d like to work with us to tackle a tricky problems of your own, <a href="https://igalia.com/contact">please get in touch</a>!</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Cops Are Using Flock's ALPR Network to Surveil Protesters and Activists (185 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2025/11/how-cops-are-using-flock-safetys-alpr-network-surveil-protesters-and-activists</link>
            <guid>46006521</guid>
            <pubDate>Fri, 21 Nov 2025 17:20:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2025/11/how-cops-are-using-flock-safetys-alpr-network-surveil-protesters-and-activists">https://www.eff.org/deeplinks/2025/11/how-cops-are-using-flock-safetys-alpr-network-surveil-protesters-and-activists</a>, See on <a href="https://news.ycombinator.com/item?id=46006521">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><p><span>It's no secret that 2025 has </span><a href="https://www.nytimes.com/2025/10/18/us/protests-trump-no-kings.html"><span>given</span></a> <a href="https://www.nature.com/articles/d41586-025-00704-0"><span>Americans</span></a> <a href="https://www.newsfromthestates.com/article/protesters-rally-against-12b-cut-education-trump-plan-us-house-bill"><span>plenty</span></a> <a href="https://www.nbcnews.com/nbc-out/out-news/protesters-rally-closure-largest-gender-affirming-care-center-kids-us-rcna217726"><span>to</span></a> <a href="https://www.americanprogress.org/article/americans-continue-to-build-a-peaceful-mass-movement-to-force-trump-administration-changes/"><span>protest</span></a> <a href="https://www.aclu.org/press-releases/dozens-of-veterans-descend-on-capitol-hill-to-oppose-military-deployments-to-u-s-cities"><span>about</span></a><span>. But as news cameras showed protesters filling streets of cities across the country, law enforcement officers—including U.S. Border Patrol agents—were quietly watching those same streets through different lenses: Flock Safety automated license plate readers (ALPRs) that tracked every passing car.&nbsp;</span></p>
<p><span>Through an analysis of 10 months of nationwide searches on Flock Safety's servers, we discovered that more than 50 federal, state, and local agencies ran hundreds of searches through Flock's national network of surveillance data in connection with protest activity. In some cases, law enforcement specifically targeted known activist groups, demonstrating how mass surveillance technology increasingly threatens our freedom to demonstrate.&nbsp;</span></p>
<p><span>Flock Safety provides ALPR technology to thousands of law enforcement agencies. The company installs cameras throughout their jurisdictions, and these cameras photograph every car that passes, documenting the license plate, color, make, model and other distinguishing characteristics. This data is paired with time and location, and uploaded to a massive searchable database. Flock Safety encourages agencies to share the data they collect broadly with other agencies across the country. It is common for an agency to search thousands of networks nationwide even when they don't have reason to believe a targeted vehicle left the region.&nbsp;</span></p>
<p><span>Via public records requests, EFF obtained datasets representing more than 12 million searches logged by more than 3,900 agencies between December 2024 and October 2025.&nbsp;The data shows that agencies logged hundreds of searches related to the </span><a href="https://www.npr.org/2025/02/16/nx-s1-5297117/50501-movement-presidents-day-protests-explainer"><span>50501</span></a><span> protests in February, the </span><a href="https://www.theguardian.com/us-news/2025/apr/05/anti-trump-protests-hands-off"><span>Hands Off</span></a><span> protests in April, the </span><a href="https://www.bbc.com/news/articles/c93xgyp1zv4o"><span>No Kings</span></a><span> protests in June and&nbsp;October, and other protests in between.&nbsp;</span></p>
<p><span>The Tulsa Police Department in Oklahoma was one of the most consistent users of Flock Safety's ALPR system for investigating protests, logging at least 38 such searches. This included running searches that corresponded to a </span><a href="https://www.kjrh.com/news/local-news/hundreds-line-riverside-drive-for-protest-in-support-of-immigrants-in-oklahoma"><span>protest against deportation raids</span></a><span> in February, a </span><a href="https://www.publicradiotulsa.org/local-regional/2025-03-13/protesters-gather-for-detained-u-s-resident-as-trump-admin-dodges-evidence-questions"><span>protest at Tulsa City Hall</span></a><span> in support of pro-Palestinian activist Mahmoud Khalil in March, and </span><a href="https://www.kjrh.com/news/local-news/protestors-gathered-at-locations-across-tulsa-and-other-communities-for-no-kings-demonstrations-on-june-14"><span>the No Kings protest</span></a><span> in June. During the most recent No Kings protests in mid-October, agencies such as the Lisle Police Department in Illinois, the Oro Valley Police Department in Arizona, and the Putnam County (Tenn.) Sheriff's Office all ran protest-related searches.&nbsp;</span></p>
<p><span>While </span><a href="https://www.eff.org/deeplinks/2025/09/eff-urges-virgina-court-appeals-require-search-warrants-access-alpr-databases"><span>EFF</span></a><span> and other civil liberties groups argue the law should </span><a href="https://www.eff.org/press/releases/lawsuit-challenges-san-joses-warrantless-alpr-mass-surveillance"><span>require a search warrant</span></a><span> for such searches, police are simply prompted to enter text into a "reason" field in the Flock Safety system. Usually this is only a few words–or even just one.</span></p>
<p><span>In these cases, that word was often just “protest.”&nbsp;</span></p>
<p><span>Crime does sometimes occur at protests, whether that's property damage, pick-pocketing, or clashes between groups on opposite sides of a protest. Some of these searches may have been tied to an actual crime that occurred, even though in most cases officers did not articulate a criminal offense when running the search. But the truth is, the only reason an officer is able to even search for a suspect at a protest is because ALPRs collected data on every single person who attended the protest.&nbsp;</span></p>
<h2><span>Search and Dissent&nbsp;</span></h2>
<p><span>2025 was an unprecedented year of street action. In June and again in October, thousands across the country mobilized under the banner of the “</span><a href="https://www.nokings.org/"><span>No Kings</span></a><span>” movement—marches against government overreach, surveillance, and corporate power. By </span><a href="https://www.theguardian.com/us-news/2025/jun/19/no-kings-how-many-protesters-attended"><span>some estimates</span></a><span>, the October demonstrations ranked among the largest single-day protests in U.S. history, filling the streets from Washington, D.C., to Portland, OR.&nbsp;</span></p>
<p><span>EFF identified 19 agencies that logged dozens of searches associated with the No Kings protests in June and October 2025. In some cases the "No Kings" was explicitly used, while in others the term "protest" was used but coincided with the massive protests.</span></p>
<div>
<p><strong>Law Enforcement Agencies that Ran Searches Corresponding with "No Kings" Rallies</strong></p>
<ul>
<li>Anaheim Police Department, Calif.</li>
<li>Arizona Department of Public Safety</li>
<li>Beaumont Police Department, Texas</li>
<li>Charleston Police Department, SC</li>
<li>Flagler County Sheriff's Office, Fla.</li>
<li>Georgia State Patrol</li>
<li>Lisle Police Department, Ill.</li>
<li>Little Rock Police Department, Ark.</li>
<li>Marion Police Department, Ohio</li>
<li>Morristown Police Department, Tenn.</li>
<li>Oro Valley Police Department, Ariz.</li>
<li>Putnam County Sheriff's Office, Tenn.</li>
<li>Richmond Police Department, Va.</li>
<li>Riverside County Sheriff's Office, Calif.</li>
<li>Salinas Police Department, Calif.</li>
<li>San Bernardino County Sheriff's Office, Calif.</li>
<li>Spartanburg Police Department, SC</li>
<li>Tempe Police Department, Ariz.</li>
<li>Tulsa Police Department, Okla.</li>
<li>US Border Patrol</li>
</ul>
</div>
<p><span>For example:&nbsp;</span></p>
<ul>
<li><span>In Washington state, the Spokane County Sheriff's Office listed "no kings" as the reason for three searches on June 13, 2025. The agency queried 95 camera networks, looking for vehicles matching the description of "work van," "bus" or "box truck."&nbsp;</span></li>
<li><span>In Texas, the Beaumont Police Department ran six searches related to two vehicles on June 14, 2025, listing "KINGS DAY PROTEST" as the reason. The queries reached across 1,774 networks.&nbsp;</span></li>
<li><span>In California, the San Bernardino County Sheriff's Office ran a single search for a vehicle across 711 networks, logging "no king" as the reason.&nbsp;</span></li>
<li><span>In Arizona, the Tempe Police Department made three searches for "ATL No Kings Protest" on June 15, 2025 searching through 425 networks. "ATL" is police code for "attempt to locate." The agency appears to not have been looking for a particular plate, but for any red vehicle on the road during a certain time window.</span></li>
</ul>
<p><span>But the No Kings protests weren't the only demonstrations drawing law enforcement's digital dragnet in 2025.&nbsp;</span></p>
<p><span>For example:</span></p>
<ul>
<li><span>In Nevada's state capital, the Carson City Sheriff's Office ran three searches that correspond to the February </span><a href="https://www.kolotv.com/2025/02/18/hundreds-take-streets-carson-city-protesting-trump-doge/"><span>50501 Protests</span></a><span> against DOGE and the Trump administration. The agency searched for two vehicles across 178 networks with "protest" as the reason.</span></li>
<li><span>In Florida, the Seminole County Sheriff's Office logged "protest" for five searches that correspond to a local </span><a href="https://www.instagram.com/p/DIwEJGFpeQK/"><span>May Day rally</span></a><span>.</span></li>
<li><span>In Alabama, the Homewood Police Department logged four searches in early July 2025 for three vehicles with "PROTEST CASE" and "PROTEST INV." in the reason field. The searches, which probed 1,308 networks, correspond to protests against the </span><a href="https://www.wvtm13.com/article/alabama-jabari-peoples-body-cam-video-officer-involved-shooting/65272652"><span>police shooting</span></a><span> of Jabari Peoples.</span></li>
<li><span>In Texas, the Lubbock Police Department ran two searches for a Tennessee license plate on March 15 that corresponds to a </span><a href="https://www.kcbd.com/2025/03/15/protestors-gather-tim-cole-memorial-stand-against-bullying-related-immigration/"><span>rally</span></a><span> to highlight the mental health impact of immigration policies. The searches hit 5,966 networks, with the logged reason "protest veh."</span></li>
<li><span>In Michigan, Grand Rapids Police Department ran five searches that corresponded with the </span><a href="https://www.facebook.com/events/fountain-street-church/stand-up-fight-back-rally/508837261789302/"><span>Stand Up and Fight Back Rally</span></a><span> in </span><a href="https://www.wzzm13.com/video/news/local/hundreds-rally-in-grand-rapids-for-human-rights/69-0789f5a7-47b0-43a6-8a85-34d404f9b4ed"><span>February</span></a><span>. The searches hit roughly 650 networks, with the reason logged as "Protest."</span></li>
</ul>
<p><a href="https://transparency.flocksafety.com/lynnwood-wa-pd"><span>Some</span></a> <a href="https://transparency.flocksafety.com/austin-tx-pd"><span>agencies</span></a><span> have adopted policies that prohibit using ALPRs for monitoring activities protected by the First Amendment. Yet many officers probed the nationwide network with terms like "protest" without articulating an actual crime under investigation.</span></p>
<p><span>In a few cases, police were using Flock’s ALPR network to investigate threats made against attendees or incidents where motorists opposed to the protests drove their vehicle into crowds. For example, throughout June 2025, an Arizona Department of Public Safety officer logged three searches for “no kings rock threat,” and a Wichita (Kan.) Police Department officer logged 22 searches for various license plates under the reason “Crime Stoppers Tip of causing harm during protests.”</span></p>
<p><span>Even when law enforcement is specifically looking for vehicles engaged in potentially criminal behavior such as threatening protesters, it cannot be ignored that mass surveillance systems work by collecting data on everyone driving to or near a protest<span>—</span>not just those under suspicion.</span></p>
<h2><span>Border Patrol's Expanding Reach&nbsp;</span></h2>
<p><span>As U.S. Border Patrol (USBP), ICE, and other federal agencies tasked with immigration enforcement have massively expanded operations into major cities, advocates for immigrants have responded through organized rallies, rapid-response confrontations, and extended presences at federal facilities.&nbsp;</span></p>
<p><span>USBP has made extensive use of Flock Safety's system for immigration enforcement, but also to target those who object to its tactics. In June, a few days after the No Kings Protest, USBP ran three searches for a vehicle using the descriptor “Portland Riots.”&nbsp;</span></p>
<p><span>USBP has made extensive use of Flock Safety's system for immigration enforcement, but also to target those who object to its tactics.</span></p>
<p><span>USBP also used the Flock Safety network to investigate a motorist who had “extended his middle finger” at Border Patrol vehicles that were transporting detainees. The motorist then allegedly drove in front of one of the vehicles and slowed down, forcing the Border Patrol vehicle to brake hard. An officer ran seven searches for his plate, citing "assault on agent" and "18 usc 111," the </span><a href="https://www.law.cornell.edu/uscode/text/18/111"><span>federal criminal statute</span></a><span> for assaulting, resisting or impeding a federal officer. The individual was </span><a href="https://www.freep.com/story/news/local/michigan/oakland/2025/08/04/man-brake-checked-flipped-off-border-patrol-agents-feds-say/85513964007/"><span>charged</span></a><span> in federal court in early August.&nbsp;</span></p>
<p><span>USBP had </span><a href="https://www.404media.co/cbp-had-access-to-more-than-80-000-flock-ai-cameras-nationwide/"><span>access</span></a><span> to the Flock system during a trial period in the first half of 2025, but the company says it has since </span><a href="https://www.flocksafety.com/blog/ensuring-local-compliance"><span>paused</span></a><span> the agency's access to the system. However, Border Patrol and other federal immigration authorities have been able to access the system’s data through </span><a href="https://www.kpbs.org/news/border-immigration/2025/10/08/records-el-cajon-license-plate-data-used-in-nationwide-immigration-searches"><span>local agencies</span></a><span> who have run searches on their behalf or even </span><a href="https://unraveledpress.com/a-dea-agent-used-an-illinois-police-officers-flock-license-plate-reader-password-for-unauthorized-immigration-enforcement-searches/?ref=404media.co"><span>lent them logins</span></a><span>.&nbsp;</span></p>
<h2><span>Targeting Animal Rights Activists</span></h2>
<p><span>Law enforcement's use of Flock's ALPR network to surveil protesters isn't limited to large-scale political demonstrations. Three agencies also used the system dozens of times to specifically target activists from </span><a href="https://www.directactioneverywhere.com/"><span>Direct Action Everywhere (DxE)</span></a><span>, an animal-rights organization known for using civil disobedience tactics to expose conditions at factory farms.</span></p>
<p><span>Delaware State Police queried the Flock national network nine times in March 2025 related to DxE actions, logging reasons such as "DxE Protest Suspect Vehicle." DxE advocates told EFF that these searches correspond to an investigation the organization undertook of a Mountaire Farms facility.&nbsp;</span></p>
<p><span>Additionally, the California Highway Patrol logged dozens of searches related to a "DXE Operation" throughout the day on May 27, 2025. The organization says this corresponds with an annual convening in California that typically ends in a direct action. Participants leave the event early in the morning, then drive across the state to a predetermined but previously undisclosed protest site. Also in May, the Merced County Sheriff's Office in California logged two searches related to "DXE activity."&nbsp;</span></p>
<p><span>As an organization engaged in direct activism, DxE has experienced </span><a href="https://www.berkeleyside.org/2021/12/08/wayne-hsiung-direct-action-everywhere-animal-rights-berkeley-conviction"><span>criminal</span></a> <a href="https://abc7news.com/post/zoe-rosenberg-jury-reaches-verdict-trial-santa-rosa-california-activist-took-chickens-perdue-plant/18087441/"><span>prosecution</span></a><span> for its activities, and so the organization told EFF they were not surprised to learn they are under scrutiny from law enforcement, particularly considering how industrial farmers have collected and distributed their own intelligence to police.</span></p>
<p><span>The targeting of DxE activists reveals how ALPR surveillance extends beyond conventional and large-scale political protests to target groups engaged in activism that challenges powerful industries. For animal-rights activists, the knowledge that their vehicles are being tracked through a national surveillance network undeniably creates a chilling effect on their ability to organize and demonstrate.</span></p>
<h2><span>Fighting Back Against ALPR&nbsp;</span></h2>
<p><span><img src="https://www.eff.org/files/2025/11/20/double_flock_on_pole.png" width="1273" height="849" alt="Two Flock Safety cameras on a pole" title="Two Flock Safety cameras on a pole"></span></p>
<p><span>ALPR systems are designed to capture information on every vehicle that passes within view. That means they don't just capture data on "criminals" but on everyone, all the time<span>—</span>and that includes people engaged in their First Amendment right to publicly dissent. Police are sitting on massive troves of data that can reveal who attended a protest, and this data shows they are not afraid to use it.&nbsp;</span></p>
<p><span>Our analysis only includes data where agencies explicitly mentioned protests or related terms in the "reason" field when documenting their search. It's likely that scores more were conducted under less obvious pretexts and search reasons. According to our analysis, approximately 20 percent of all searches we reviewed listed vague language like "investigation," "suspect," and "query" in the reason field. Those terms could well be cover for spying on a protest, </span><a href="https://www.eff.org/deeplinks/2025/10/flock-safety-and-texas-sheriff-claimed-license-plate-search-was-missing-person-it"><span>an abortion prosecution</span></a><span>, or an </span><a href="https://www.kansas.com/news/politics-government/article291059560.html"><span>officer stalking a spouse</span></a><span>, and no one would be the wiser–including the agencies whose data was searched. Flock has </span><a href="https://www.flocksafety.com/blog/policy-pulse-transparency-control-and-the-path-forward"><span>said</span></a><span> it will now require officers to select a specific crime under investigation, but that can and will also be used to obfuscate dubious searches.&nbsp;</span></p>
<p><span>For protestors, this data should serve as confirmation that ALPR surveillance has been and will be used to target activities protected by the First Amendment. Depending on </span><a href="https://ssd.eff.org/glossary/threat-model"><span>your threat model</span></a><span>, this means you should think carefully about how you arrive at protests, and explore options such as by biking, walking, carpooling, taking public transportation, or simply parking a little further away from the action. Our </span><a href="https://ssd.eff.org/module/attending-protest#things-to-be-aware-of-while-traveling-to-and-from-the-protest"><span>Surveillance Self-Defense</span></a><span> project has more information on steps you could take to protect your privacy when traveling to and attending a protest.</span></p>
<p><span>For local officials, this should serve as another example of how systems marketed as protecting your community may actually threaten the values your communities hold most dear. The best way to protect people is to shut down these camera networks.&nbsp;&nbsp;</span></p>
<p><span>Everyone should have the right to speak up against injustice without ending up in a database.&nbsp;</span></p>

</div>

          </article>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You can make PS2 games in JavaScript (210 pts)]]></title>
            <link>https://jslegenddev.substack.com/p/you-can-now-make-ps2-games-in-javascript</link>
            <guid>46006082</guid>
            <pubDate>Fri, 21 Nov 2025 16:42:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jslegenddev.substack.com/p/you-can-now-make-ps2-games-in-javascript">https://jslegenddev.substack.com/p/you-can-now-make-ps2-games-in-javascript</a>, See on <a href="https://news.ycombinator.com/item?id=46006082">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!HWto!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c2b3cdb-3a39-465f-900e-5dca9eabf54d_1920x1080.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!HWto!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c2b3cdb-3a39-465f-900e-5dca9eabf54d_1920x1080.png 424w, https://substackcdn.com/image/fetch/$s_!HWto!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c2b3cdb-3a39-465f-900e-5dca9eabf54d_1920x1080.png 848w, https://substackcdn.com/image/fetch/$s_!HWto!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c2b3cdb-3a39-465f-900e-5dca9eabf54d_1920x1080.png 1272w, https://substackcdn.com/image/fetch/$s_!HWto!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c2b3cdb-3a39-465f-900e-5dca9eabf54d_1920x1080.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!HWto!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c2b3cdb-3a39-465f-900e-5dca9eabf54d_1920x1080.png" width="1456" height="819" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3c2b3cdb-3a39-465f-900e-5dca9eabf54d_1920x1080.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:938380,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://jslegenddev.substack.com/i/173484675?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c2b3cdb-3a39-465f-900e-5dca9eabf54d_1920x1080.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!HWto!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c2b3cdb-3a39-465f-900e-5dca9eabf54d_1920x1080.png 424w, https://substackcdn.com/image/fetch/$s_!HWto!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c2b3cdb-3a39-465f-900e-5dca9eabf54d_1920x1080.png 848w, https://substackcdn.com/image/fetch/$s_!HWto!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c2b3cdb-3a39-465f-900e-5dca9eabf54d_1920x1080.png 1272w, https://substackcdn.com/image/fetch/$s_!HWto!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c2b3cdb-3a39-465f-900e-5dca9eabf54d_1920x1080.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>I recently discovered that you could make PS2 games in JavaScript. I’m not even kidding, it’s actually possible. I was working on a project and had my phone near my desk when I received a notification. Upon further inspection, it came from itch.io which was a platform where I usually published most of my web games.</p><p><span>Under my relatively popular </span><a href="https://jslegend.itch.io/sonic-ring-run" rel="">Sonic infinite runner game</a><span> which was made in JavaScript and developed a year ago, I received a comment from someone with the username Dev Will which claimed they had made a PS2 version of my game and provided the </span><a href="https://github.com/DevWill-hub/Sonic-Infinite-Runner-PS2" rel="">GitHub repo</a><span> of the source code.</span></p><p>At first, I thought that it was cool that someone took the time to remake my game for an old console that had a reputation to be hard to develop for and probably required them to write a lot of C or C++.</p><p>Out of curiosity, I opened up the GitHub repo and was astonished to see that the project was not using even a bit of C++ or C but was entirely in JavaScript!</p><p>If making PS2 games were easier than I thought since I could use a higher level language like JavaScript, I could probably try making one in a reasonable amount of time and play it on a retro handled or an actual PS2. How cool would that be?</p><p>This is where I knew I had to drop everything I was doing to investigate how this was possible.</p><p>Since the dev behind the project was Portuguese speaking (I assume they were either from Brazil or Portugal), they wrote the Readme of the repo in Portuguese which was a language I did not understand. </p><p>Fortunately, I was still able to decipher most of what was written because I had done 3 years of Spanish in school and spoke French natively. Since Portuguese is a romance language like Spanish and French, I was fortunately not totally lost.</p><p>Anyway, The readme said that the engine used to make the PS2 version of my game was called AthenaEnv with a conveniently placed link towards it so I could learn more.</p><p><span>As with the Sonic Infinite Runner PS2 project, this engine was also open source and its </span><a href="https://github.com/DanielSant0s/AthenaEnv" rel="">repo</a><span> had a very detailed readme written in English.</span></p><p>To summarize, Athena was not what we commonly refer to as a game engine but an environment that also offered a JavaScript API for making games and apps for the PS2. It embedded a slightly modified version of QuickJS which was a small and embeddable JavaScript engine. This explained how Athena was able to run JavaScript code on the PS2.</p><p>Therefore, Athena was the PS2 native program written in C that took your JavaScript code, passed it through the QuickJS engine to interpret it and finally, ran the relevant logic on the system.</p><p>What made it compelling was not that it just ran JS on the PS2 but that it offered an API suitable for game development. It covered :</p><ul><li><p>Rendering : Allowing you to display sprites, text, shapes, etc… on the screen and animate them using a game loop.</p></li><li><p>Asset loading : Allowing you to load images, sounds, fonts, etc...</p></li><li><p>Input handling : Allowing you to receive player input from a controller, multiple ones or even from a mouse and keyboard since the PS2 supported these input methods.</p></li><li><p>File handling : Allowing you to write save files among other things.</p></li><li><p>Sound playback : For playing Sound.</p></li></ul><p>and the list goes on.</p><p>I noticed however, that the level of abstraction offered by the API was similar to something like p5.js, the HTML canvas API or Raylib. That meant that you’d still needed to implement collision detection, scene management, etc… yourself.</p><p>Now, that I got familiar with Athena, I wanted to try to run the Sonic infinite runner “port” on an emulator. According to the project’s Readme. I needed to install PCSX2 which is the most popular emulator for the PS2. Then, go into the settings and under the emulation tab, check the box “Enable host filesystem”.</p><p>Once this was done, I would need to open an athena.elf file and the game would start.</p><p>After installing and configuring the emulator, I was ready to run the game. However, there was a problem. I could not find the athena.elf file in the repo. It was nowhere to be found.</p><p>This is where I remembered to look at the “releases” section of the repo because a lot of open source projects put executables there, especially if it’s a mobile or desktop app project.</p><p>As expected, the zip attached in that section contained the athena.elf file but not only. It also contained an assets folder, a main.js file, an athena.ini file and src folder containing the rest of the game’s code.</p><p>The athena.ini file allowed you to configure the entry point of the project. Here, the entry point was set to main.js which explained how Athena would know what JavaScript to run. You could also configure if you wanted to show Athena’s logo before your game started by setting the boot_logo property to true.</p><pre><code>boot_logo = true
dark_mode = true
default_script = “main.js”

audsrv = true</code></pre><p>It now became evident why we needed to check the “Enable host filesystem” check box earlier. This was so that the emulator could allow Athena to access the assets folder and the source code that were essential for our game.</p><p>Anyway, I opened the athena.elf file in PCSX2 and surprisingly, the game actually ran with no issues. It was amazing to see that a game I wrote for the web was ported to the PS2 and I was there able to play it with a controller.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!6ls2!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b6b6320-8b56-4c1b-a34d-66c900dd9c2f_1912x976.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!6ls2!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b6b6320-8b56-4c1b-a34d-66c900dd9c2f_1912x976.png 424w, https://substackcdn.com/image/fetch/$s_!6ls2!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b6b6320-8b56-4c1b-a34d-66c900dd9c2f_1912x976.png 848w, https://substackcdn.com/image/fetch/$s_!6ls2!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b6b6320-8b56-4c1b-a34d-66c900dd9c2f_1912x976.png 1272w, https://substackcdn.com/image/fetch/$s_!6ls2!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b6b6320-8b56-4c1b-a34d-66c900dd9c2f_1912x976.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!6ls2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b6b6320-8b56-4c1b-a34d-66c900dd9c2f_1912x976.png" width="1456" height="743" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2b6b6320-8b56-4c1b-a34d-66c900dd9c2f_1912x976.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:743,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1708312,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://jslegenddev.substack.com/i/173484675?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b6b6320-8b56-4c1b-a34d-66c900dd9c2f_1912x976.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!6ls2!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b6b6320-8b56-4c1b-a34d-66c900dd9c2f_1912x976.png 424w, https://substackcdn.com/image/fetch/$s_!6ls2!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b6b6320-8b56-4c1b-a34d-66c900dd9c2f_1912x976.png 848w, https://substackcdn.com/image/fetch/$s_!6ls2!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b6b6320-8b56-4c1b-a34d-66c900dd9c2f_1912x976.png 1272w, https://substackcdn.com/image/fetch/$s_!6ls2!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2b6b6320-8b56-4c1b-a34d-66c900dd9c2f_1912x976.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Now, the game looked a bit blurry which was expected since this was supposed to emulate a PS2 which had a small resolution. Fortunately, I was able to make things more comfortable by upping the resolution in the graphics settings of the emulator.</p><p>The dev process also seemed quite straightforward. You would only need to open the folder containing all the relevant files (athena.elf, main.js, etc…) in a code editor like VSCode and open athena.elf in the emulator. Now, you could make changes to your JS code and once you were ready to test, you would go under the PCSX2 system tab and click on reset. This would restart the emulator and you could see the latest changes. While not as seamless as in web development with hot reloading, it still was a relatively fast iteration cycle.</p><p>It’s at that moment, that I knew had to make a post about it and share this awesome project with you. However, I still felt uneasy about one thing.</p><p>Nowadays, people download PS2 games as .iso files. For most games, you only need one .iso file that you then open in your emulator. Less technical people can therefore more easily enjoy these older titles.</p><p>However, to run the Sonic infinite runner game “port”, I needed to not only check a box in the settings but also needed the entire project’s folder containing the Athena executable and the source code.</p><p>I wondered if instead, there was a way to distribute the game as a single .iso file. This is were I simply went back to the itch.io comment section and asked if it was possible.</p><p>After a thorough back and forth that continued on Discord, the process to convert my files into a single iso, I could distribute, was now clear.</p><p>To make an iso you needed the following files :</p><ul><li><p>athena.elf : Which is the Athena executable.</p></li><li><p>athena.ini : For configuring the project’s entry point.</p></li><li><p>A JS file acting as the entry point of the codebase.</p></li><li><p>The rest of your source code if your code is more than one file, oftentimes it’s in a folder called src.</p></li><li><p>Two files one named ATHA_000.01 and the other SYSTEM.CNF needed to make the iso bootable.</p></li></ul><p><em><span>As an aside, in case you want to also get into JavaScript PS2 game development, you can check </span><a href="https://github.com/JSLegendDev/Athena-PS2-Template" rel="">this template I made containing all of the files needed</a><span>.</span></em></p><p>Once you had all the files, you had to make a zip archive containing them all. One issue I had, was that if I created a zip out of the folder containing the files, the resulting .iso would not work. However, if I selected the files one by one and then created the zip, I would experience no issues. This is something to keep in mind.</p><p><span>Now, the only step left was to convert the zip into an iso. As I was using a Mac, the only reliable way I’ve found, was to use the website </span><a href="https://mconverter.eu/" rel="">mconverter.eu</a><span> and let them do the conversion.</span></p><p>However, the issue with this website is that you’re limited in the number of conversions you can do per day before they ask you to pay. Additionally, if your zip archive is above a certain size, you’ll also have to watch an ad before you can do the conversion.</p><p><em>If you end up finding a better way using either a CLI tool, a downloadable app or some other website, feel free to share it in the comment section.</em></p><p>Once you had the iso, you could open it up in the emulator like you would do with other PS2 games. You also didn’t need to check the “Enable host filesystem” option anymore since all the relevant files needed were included in the iso.</p><p>If the game booted correctly, then you now had a single file you could distribute which was very convenient.</p><p>It was now time to get my feet wet. Before attempting anything too complicated, my goal was to create a simple “Hello World” example where I would :</p><ul><li><p>Load some assets (In my case a font and an image).</p></li><li><p>Set up a game loop that would run every frame.</p></li><li><p>Animate a sprite using that game loop.</p></li><li><p>Render text.</p></li><li><p>Handle player input so I could move a sprite around.</p></li></ul><p>Before I could achieve any of these sub-goals, in main.js, I first defined a few constants that I would end up needing.</p><pre><code>const { width: SCREEN_WIDTH, height: SCREEN_HEIGHT } = Screen.getMode();
const SCALE = 2;
const SPEED = 3;
const FRAME_WIDTH = 32;
const FRAME_HEIGHT = 44;</code></pre><p>This is where I learned that you could get the screen’s width and height by first using the Screen module available globally like all Athena provided modules (Meaning that no import statements were needed) and then calling the getMode method.</p><p>Then, to have a stable frame rate and accurate FPS counting, I needed to call the methods setVSync() and setFrameCounter()</p><pre><code>Screen.setVSync(true); // makes framerate stable
Screen.setFrameCounter(true); // toggles frame counting and FPS collecting.</code></pre><p>With the setup completed, I wanted to load the font I used in my Sonic game and a Spritesheet of Sonic so that I could later animate it. I could achieve the following by creating an instance of the Font and Image classes offered by Athena.</p><pre><code>const maniaFont = new Font("./assets/mania.ttf");
const sprite = new Image("./assets/sonic.png");</code></pre><p>While I planned on handling player input later, I still needed a way to get the player’s controller so that my code could know when a given button was pressed. This was made possible by using Athena’s Pads module.</p><pre><code>// Get the first player controller
// First player -&gt; 0, Second player -&gt; 1
const pad = Pads.get(0);</code></pre><p>Before I could create a game loop, I needed to first write the setup code required to animate my spritesheet. Since all the frames where contained within a single image, I had to find a way to tell Athena what part of the image was to be rendered.</p><p>To achieve this, I first spent some time to get familiar with the shape of the sprite object created earlier.</p><pre><code>const sprite = new Image("./assets/sonic.png");</code></pre><p>It turned out that we could set the width and the height of the sprite by modifying the properties of the object with the same names.</p><pre><code>// for example
sprite.width = 30;
sprite.height = 40;</code></pre><p>It also turned out that you could tell Athena what portion of the image to draw by setting the startx, endx, starty, endy properties.</p><pre><code>sprite.startx = 0;
sprite.endx = 32;
sprite.starty = 0;
sprite.endy = 44;</code></pre><p>For example, if you had the following values : startx = 0, endx = 32, starty = 0 and endy = 44 you would get the first frame rendered. This is because in the spritesheet, every frame has a width of 32 and a height of 44. Also, the origin (0,0) corresponds to the top-left corner of the spritesheet.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!sP4y!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2b0e183-3d98-4b71-9724-50afd6a3208e_3088x1208.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!sP4y!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2b0e183-3d98-4b71-9724-50afd6a3208e_3088x1208.png 424w, https://substackcdn.com/image/fetch/$s_!sP4y!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2b0e183-3d98-4b71-9724-50afd6a3208e_3088x1208.png 848w, https://substackcdn.com/image/fetch/$s_!sP4y!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2b0e183-3d98-4b71-9724-50afd6a3208e_3088x1208.png 1272w, https://substackcdn.com/image/fetch/$s_!sP4y!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2b0e183-3d98-4b71-9724-50afd6a3208e_3088x1208.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!sP4y!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2b0e183-3d98-4b71-9724-50afd6a3208e_3088x1208.png" width="1456" height="570" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a2b0e183-3d98-4b71-9724-50afd6a3208e_3088x1208.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:570,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1152300,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://jslegenddev.substack.com/i/173484675?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2b0e183-3d98-4b71-9724-50afd6a3208e_3088x1208.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!sP4y!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2b0e183-3d98-4b71-9724-50afd6a3208e_3088x1208.png 424w, https://substackcdn.com/image/fetch/$s_!sP4y!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2b0e183-3d98-4b71-9724-50afd6a3208e_3088x1208.png 848w, https://substackcdn.com/image/fetch/$s_!sP4y!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2b0e183-3d98-4b71-9724-50afd6a3208e_3088x1208.png 1272w, https://substackcdn.com/image/fetch/$s_!sP4y!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2b0e183-3d98-4b71-9724-50afd6a3208e_3088x1208.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Now that I knew how to display a single frame within a wider image, I used the following logic to setup Sonic’s run animation.</p><pre><code>const spritePos = { x: SCREEN_WIDTH / 2, y: SCREEN_HEIGHT / 2 };
sprite.width = FRAME_WIDTH * SCALE;
sprite.height = FRAME_HEIGHT * SCALE;
// describes where each frame is located within the sprite.
const runAnimFrames = [
  { startx: 0, endx: 32, starty: 0, endy: 44 },
  { startx: 32, endx: 64, starty: 0, endy: 44 },
  { startx: 64, endx: 96, starty: 0, endy: 44 },
  { startx: 96, endx: 128, starty: 0, endy: 44 },
  { startx: 128, endx: 160, starty: 0, endy: 44 },
  { startx: 160, endx: 192, starty: 0, endy: 44 },
  { startx: 192, endx: 224, starty: 0, endy: 44 },
  { startx: 224, endx: 256, starty: 0, endy: 44 },
];
let frameIndex = 0;
const frameDuration = 30;
const timer = new Timer();</code></pre><p>I first created an object called spritePos to set the position of the sprite on the screen. This was needed to be able to move it around when the player would press directional buttons on the D-pad. More on that later.</p><p>Then I would set the sprite’s width and height to correspond to the width and height of a single frame which was 32x44 pixels. Since I wanted the sprite to appear big enough, I multiplied the width and height by a value defined by the SCALE constant we set earlier in our code.</p><p>The next step consisted in creating an array called runAnimFrames which would describe each frame of Sonic’s run animation using an object with the startx, endx, starty and endy properties. We then had a frameIndex variable which would determine the current frame to display. The frameDuration constant would be used to set how long in miliseconds to display each frame. The lower the number the higher the frame rate of the animation because we would flip through all the frames faster. </p><p>Finally, I initialized a timer coming from a custom Timer class that I added in my src folder and imported here. The full code is available in the template mentioned earlier.</p><p>The timer would end up being crucial to know when it was time to move on to displaying another frame.</p><p>Now that we had our animation logic setup done, it was time to render the animation. For this purpose, I needed a game loop that runs every frame. In Athena, we could achieve this by calling the display method available under the Screen module.</p><pre><code>Screen.display(() =&gt; {
   if (timer.get() &gt; frameDuration) {
      if (frameIndex &lt; runAnimFrames.length - 1) {
          frameIndex++;
          timer.reset();
      } else {
          frameIndex = 0;
      }
   }

   sprite.startx = runAnimFrames[frameIndex].startx;
   sprite.endx = runAnimFrames[frameIndex].endx;
   sprite.starty = runAnimFrames[frameIndex].starty;
   sprite.endy = runAnimFrames[frameIndex].endy;
   sprite.draw(spritePos.x, spritePos.y);
});</code></pre><p>In an if statement we would check if the timer had exceeded the time allocated to displaying the current frame. If it was the case we would move on to the next frame by incrementing the frameIndex as long as it was within the bounds of the runAnimFrames array, otherwise, we would set it back to 0 to display the first frame. This was to achieve a looping animation.</p><p>Then, on every iteration of the game loop we would set the sprite’s startx, endx, starty, endy properties to correspond to the ones of the current frame. Finally, to render the sprite, we needed to call its draw method and pass to it the coordinates where you wanted to display it on the screen.</p><p>Now that I had a game loop, I could finally handle user input by making sure that the sprite would move in different directions depending on which button was pressed. This could be easily achieved with a few if statements.</p><pre><code>Screen.display(() =&gt; {
   pad.update(); // necessary to get what buttons are currently being pressed

   if (pad.pressed(Pads.RIGHT)) {
       spritePos.x = spritePos.x + SPEED;
   }

   if (pad.pressed(Pads.LEFT)) {
       spritePos.x = spritePos.x - SPEED;
   }

   if (pad.pressed(Pads.UP)) {
       spritePos.y = spritePos.y - SPEED;
   }

   if (pad.pressed(Pads.DOWN)) {
      spritePos.y = spritePos
   }

   // rest of the code omitted for clarity
});</code></pre><p>You might be wondering where is deltaTime? For those unfamiliar, deltaTime is a value representing the time elapsed between the current frame and the previous frame in a game. It’s often used to make the movement of objects, frame rate independent. Meaning that if your game runs at a lower or higher frame rate, an object, like a character, will still move at the same rate. To achieve frame rate independence, you would usually multiply your movement code by deltaTime.</p><p>The reason it was absent here, is because when creating a game loop using the display method, this matter is taken care of under the hood.</p><p>Now that I could move Sonic around, I still needed him to face the correct direction because at this point, he would look right even If I moved him to the left. To implement this, I decided to go with a common technique in pixel art based games, which consisted in mirroring (or flipping) the sprite.</p><p>To achieve this in Athena, you simply needed to provide a negative width or height to the sprite depending on what axis you wanted the mirroring to take effect on. For flipping a sprite horizontally, providing a negative width was enough.</p><p>However, an issue arose! If you flipped the sprite, it would not flip in place since it would flip according to the sprite’s origin which was its top-left corner.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!vy5r!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F218436f0-209c-40bf-b989-ad5cc3a32813_2320x1188.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!vy5r!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F218436f0-209c-40bf-b989-ad5cc3a32813_2320x1188.png 424w, https://substackcdn.com/image/fetch/$s_!vy5r!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F218436f0-209c-40bf-b989-ad5cc3a32813_2320x1188.png 848w, https://substackcdn.com/image/fetch/$s_!vy5r!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F218436f0-209c-40bf-b989-ad5cc3a32813_2320x1188.png 1272w, https://substackcdn.com/image/fetch/$s_!vy5r!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F218436f0-209c-40bf-b989-ad5cc3a32813_2320x1188.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!vy5r!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F218436f0-209c-40bf-b989-ad5cc3a32813_2320x1188.png" width="1456" height="746" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/218436f0-209c-40bf-b989-ad5cc3a32813_2320x1188.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:746,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:533754,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://jslegenddev.substack.com/i/173484675?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F218436f0-209c-40bf-b989-ad5cc3a32813_2320x1188.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!vy5r!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F218436f0-209c-40bf-b989-ad5cc3a32813_2320x1188.png 424w, https://substackcdn.com/image/fetch/$s_!vy5r!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F218436f0-209c-40bf-b989-ad5cc3a32813_2320x1188.png 848w, https://substackcdn.com/image/fetch/$s_!vy5r!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F218436f0-209c-40bf-b989-ad5cc3a32813_2320x1188.png 1272w, https://substackcdn.com/image/fetch/$s_!vy5r!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F218436f0-209c-40bf-b989-ad5cc3a32813_2320x1188.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>This meant that it would move the sprite to the left after mirroring. To fix this issue, you only needed to subtract an offset to the x coordinate of the flipped sprite that corresponded to its width.</p><p>Now that the issue was solved, I created variable called spriteIsFlippedX to know when to flip or unflip the sprite. The logic can be see below :</p><pre><code>// omitted previous code for clarity
const offset = FRAME_WIDTH * SCALE;
let spriteIsFlippedX = false;

Screen.display(() =&gt; {

  pad.update();

  if (pad.pressed(Pads.RIGHT)) {
    // makes sur to flip back the sprite
    if (spriteIsFlippedX) {
      sprite.width = Math.abs(sprite.width);
      spriteIsFlippedX = false;
      spritePos.x -= offset;
    }

    spritePos.x = spritePos.x + SPEED;
  }

  if (pad.pressed(Pads.LEFT)) {
    if (!spriteIsFlippedX) {
      sprite.width = -Math.abs(sprite.width);
      spriteIsFlippedX = true;
      spritePos.x += offset;
    }

    spritePos.x = spritePos.x - SPEED;
  }

  if (pad.pressed(Pads.UP)) {
    spritePos.y = spritePos.y - SPEED;
  }

  if (pad.pressed(Pads.DOWN)) {
    spritePos.y = spritePos.y + SPEED;
  }

  // ... code omitted for clarity
});</code></pre><p>Now, when you moved sonic to the left, he would face left and face right when moved to the right.</p><p>There was still one thing I wanted to try out before wrapping up my Hello World example and that was text rendering. The first thing I wanted to render onto the screen was an FPS counter. It turned out that the FPS counter in the PCSX2 emulator is not accurate, however, Athena provides the getFPS() method available on the Screen module to accurately determine the frame rate.</p><p>To display some text, you needed to first create a font object using the Font constructor. It would take either a path to a font that can be in a .ttf format or the string “default” if you wanted to use the default font available on the system.</p><p>Once created, the font object had a print method that you could use within the game loop to tell the PS2 what to render and where on the screen.</p><pre><code>const font = new Font("default");
Screen.display(() =&gt; {
    // Here getFPS() will provide an updated FPS count every 10ms.
    font.print(10,10, Math.round(Screen.getFPS(10)));
});</code></pre><pre><code>const maniaFont = new Font("./assets/mania.ttf");
Screen.display(() =&gt; {
    font.print(10,10, "Hello World!");
});</code></pre><p>Finally, my Hello World example was finished.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!iHMb!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73c41646-137d-4ea2-b0a7-c0328f119829_1912x976.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!iHMb!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73c41646-137d-4ea2-b0a7-c0328f119829_1912x976.png 424w, https://substackcdn.com/image/fetch/$s_!iHMb!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73c41646-137d-4ea2-b0a7-c0328f119829_1912x976.png 848w, https://substackcdn.com/image/fetch/$s_!iHMb!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73c41646-137d-4ea2-b0a7-c0328f119829_1912x976.png 1272w, https://substackcdn.com/image/fetch/$s_!iHMb!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73c41646-137d-4ea2-b0a7-c0328f119829_1912x976.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!iHMb!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73c41646-137d-4ea2-b0a7-c0328f119829_1912x976.png" width="1456" height="743" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/73c41646-137d-4ea2-b0a7-c0328f119829_1912x976.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:743,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:470324,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://jslegenddev.substack.com/i/173484675?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73c41646-137d-4ea2-b0a7-c0328f119829_1912x976.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!iHMb!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73c41646-137d-4ea2-b0a7-c0328f119829_1912x976.png 424w, https://substackcdn.com/image/fetch/$s_!iHMb!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73c41646-137d-4ea2-b0a7-c0328f119829_1912x976.png 848w, https://substackcdn.com/image/fetch/$s_!iHMb!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73c41646-137d-4ea2-b0a7-c0328f119829_1912x976.png 1272w, https://substackcdn.com/image/fetch/$s_!iHMb!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73c41646-137d-4ea2-b0a7-c0328f119829_1912x976.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Now that you’ve been introduced to Athena, you might be tempted to try it out for yourself. In that case, I really recommend looking at the Sonic infinite runner Athena port’s code as you’ll learn a lot about concepts that I did not have time to cover here.</p><p><span>Link to the repo here : </span><a href="https://github.com/DevWill-hub/Sonic-Infinite-Runner-PS2" rel="">https://github.com/DevWill-hub/Sonic-Infinite-Runner-PS2</a></p><p><span>Link to my Athena template : </span><a href="https://github.com/JSLegendDev/Athena-PS2-Template" rel="">https://github.com/JSLegendDev/Athena-PS2-Template</a></p><p><span>Link to the Athena project : </span><a href="https://github.com/DanielSant0s/AthenaEnv" rel="">https://github.com/DanielSant0s/AthenaEnv</a></p><p><span>Additionally, I recommend joining the official Athena discord where you’ll be more likely to receive help when stuck. You can join here : </span><a href="https://discord.gg/cZUH5U93US" rel="">https://discord.gg/cZUH5U93US</a></p><p>Before wrapping up this post, you might have found strange that nothing was mentioned about 3D considering that the PS2 was mostly known for its 3D games.</p><p>This is for 2 reasons. First, I’m a novice in terms of 3D game develoment, I have never done it before. Second, to my understanding, Athena has both 2D and 3D capabilities but version 4 which has more of a 3D focus is currently in development. I thought it would have been preferable to wait until v4 was stable before diving into PS2 3D gamedev in JavaScript.</p><p>However, there are a few 3D demos you can check if you’re interested. </p><p>Links down below.</p><ul><li><p><a href="https://github.com/ps2devnoob/3D-Robot-DEMO-PS2" rel="">https://github.com/ps2devnoob/3D-Robot-DEMO-PS2</a></p></li><li><p><a href="https://github.com/ps2devnoob/BurnTrack-PS2-DEMO" rel="">https://github.com/ps2devnoob/BurnTrack-PS2-DEMO</a></p></li><li><p><a href="https://github.com/ps2devnoob/AthenaENV-PS2-Samples" rel="">https://github.com/ps2devnoob/AthenaENV-PS2-Samples</a></p></li></ul><p>To conclude, Athena is a cool project allowing you to make real PS2 games in JavaScript. If you learned something new and enjoy technical posts like this one, I recommend subscribing to not miss out on future releases.</p><p>In the meantime, if you feel inclined, you can read the post below.</p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Wealthfolio 2.0- Open source investment tracker. Now Mobile and Docker (386 pts)]]></title>
            <link>https://wealthfolio.app/?v=2.0</link>
            <guid>46006016</guid>
            <pubDate>Fri, 21 Nov 2025 16:34:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wealthfolio.app/?v=2.0">https://wealthfolio.app/?v=2.0</a>, See on <a href="https://news.ycombinator.com/item?id=46006016">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>   <div id="hero"> <p> <h2>
Grow  Wealth. Keep Control.
</h2> <h2>
A beautiful, Private and <span><span></span><span></span><span>Open-Source</span></span> investment tracker that runs <span><span></span><span></span><span>locally</span></span> on all your devices.
</h2> </p> <p> <a href="https://wealthfolio.app/download"> <span>Get Wealthfolio</span> <svg width="1em" height="1em" data-icon="lucide:download">   <symbol id="ai:lucide:download" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M12 15V3m9 12v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"></path><path d="m7 10l5 5l5-5"></path></g></symbol><use href="#ai:lucide:download"></use>  </svg> </a> </p>  </div>   <div id="key-features"> <!-- Section header --> <div> <h2>WHY CHOOSE WEALTHFOLIO?</h2> <p>
A beautiful portfolio tracker that respects your privacy and your data
</p> </div> <div> <div> <p> 1 </p> <div> <h3>Privacy-First Approach</h3> <p>Your data never leaves your device. As an open-source project, we prioritize security and transparency.</p> </div> </div><div> <p> 2 </p> <div> <h3>Simple and Beautifully Crafted</h3> <p>Powerful features wrapped in an elegant, easy-to-use interface. Simplicity meets sophistication.</p> </div> </div><div> <p> 3 </p> <div> <h3>No Hidden Costs</h3> <p>Free to use with optional one-time payment. No subscriptions or recurring fees.</p> </div> </div> </div> </div> <div id="features"> <!-- Section header --> <div> <h2>
THE ESSENTIALS YOU NEED TO TRACK YOUR WEALTH
</h2> <p>
No More Messy Spreadsheets or Privacy Concerns - Just You and Your Secure, Personal Wealth Companion Application
</p> </div> <!-- Feature cards layout --> <div> <div data-key="Accounts Aggregation0">  <div> <h3> Accounts Aggregation </h3> <p>Gather all your investment and savings accounts in one place. See everything at a glance, from stocks to savings! Import your CSV statements from your broker or bank.</p>  <div> <div> <svg width="1em" height="1em" data-icon="lucide:eye">   <symbol id="ai:lucide:eye" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M2.062 12.348a1 1 0 0 1 0-.696a10.75 10.75 0 0 1 19.876 0a1 1 0 0 1 0 .696a10.75 10.75 0 0 1-19.876 0"></path><circle cx="12" cy="12" r="3"></circle></g></symbol><use href="#ai:lucide:eye"></use>  </svg> <div>  <p>See all your accounts in one place.</p> </div> </div><div> <svg width="1em" height="1em" data-icon="lucide:file-text">   <symbol id="ai:lucide:file-text" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M15 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7Z"></path><path d="M14 2v4a2 2 0 0 0 2 2h4M10 9H8m8 4H8m8 4H8"></path></g></symbol><use href="#ai:lucide:file-text"></use>  </svg> <div> <h4> CSV Import </h4> <p>Easily import your CSV statements.</p> </div> </div> </div> </div>  <p><img id="feature-image-0" src="https://wealthfolio.app/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/aggregation.webp" srcset="https://wealthfolio.app/cdn-cgi/image/width=400,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/aggregation.webp 400w, https://wealthfolio.app/cdn-cgi/image/width=640,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/aggregation.webp 640w, https://wealthfolio.app/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/aggregation.webp 800w, https://wealthfolio.app/cdn-cgi/image/width=1024,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/aggregation.webp 1024w, https://wealthfolio.app/cdn-cgi/image/width=1280,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/aggregation.webp 1280w, https://wealthfolio.app/cdn-cgi/image/width=1600,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/aggregation.webp 1600w" data-light="/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/aggregation.webp" data-dark="/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/aggregation-dark.webp" data-light-set="/cdn-cgi/image/width=400,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/aggregation.webp 400w, /cdn-cgi/image/width=640,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/aggregation.webp 640w, /cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/aggregation.webp 800w, /cdn-cgi/image/width=1024,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/aggregation.webp 1024w, /cdn-cgi/image/width=1280,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/aggregation.webp 1280w, /cdn-cgi/image/width=1600,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/aggregation.webp 1600w" data-dark-set="/cdn-cgi/image/width=400,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/aggregation-dark.webp 400w, /cdn-cgi/image/width=640,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/aggregation-dark.webp 640w, /cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/aggregation-dark.webp 800w, /cdn-cgi/image/width=1024,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/aggregation-dark.webp 1024w, /cdn-cgi/image/width=1280,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/aggregation-dark.webp 1280w, /cdn-cgi/image/width=1600,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/aggregation-dark.webp 1600w" sizes="(max-width: 1024px) 100vw, (max-width: 1280px) 50vw, 560px" alt="Accounts Aggregation" width="1200" height="800" loading="eager" fetchpriority="high" decoding="async"> </p> </div><div data-key="Holdings Overview1">  <div> <h3> Holdings Overview </h3> <p>Get a clear picture of what's in your portfolio. Stocks, ETFs, or Cryptocurrencies - know what you have and how it's performing.</p>  <div> <div> <svg width="1em" height="1em" data-icon="lucide:pie-chart">   <symbol id="ai:lucide:pie-chart" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M21.21 15.89A10 10 0 1 1 8 2.83"></path><path d="M22 12A10 10 0 0 0 12 2v10z"></path></g></symbol><use href="#ai:lucide:pie-chart"></use>  </svg> <div> <h4> Portfolio Insights </h4> <p>Understand your asset allocation.</p> </div> </div><div> <svg width="1em" height="1em" data-icon="lucide:trending-up">   <symbol id="ai:lucide:trending-up" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M16 7h6v6"></path><path d="m22 7l-8.5 8.5l-5-5L2 17"></path></g></symbol><use href="#ai:lucide:trending-up"></use>  </svg> <div> <h4> Performance Tracking </h4> <p>Monitor how your investments are doing.</p> </div> </div> </div> </div>  <p><img id="feature-image-1" src="https://wealthfolio.app/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/holdings-charts.webp" srcset="https://wealthfolio.app/cdn-cgi/image/width=400,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/holdings-charts.webp 400w, https://wealthfolio.app/cdn-cgi/image/width=640,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/holdings-charts.webp 640w, https://wealthfolio.app/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/holdings-charts.webp 800w, https://wealthfolio.app/cdn-cgi/image/width=1024,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/holdings-charts.webp 1024w, https://wealthfolio.app/cdn-cgi/image/width=1280,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/holdings-charts.webp 1280w, https://wealthfolio.app/cdn-cgi/image/width=1600,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/holdings-charts.webp 1600w" data-light="/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/holdings-charts.webp" data-dark="/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/holdings-charts-dark.webp" data-light-set="/cdn-cgi/image/width=400,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/holdings-charts.webp 400w, /cdn-cgi/image/width=640,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/holdings-charts.webp 640w, /cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/holdings-charts.webp 800w, /cdn-cgi/image/width=1024,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/holdings-charts.webp 1024w, /cdn-cgi/image/width=1280,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/holdings-charts.webp 1280w, /cdn-cgi/image/width=1600,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/holdings-charts.webp 1600w" data-dark-set="/cdn-cgi/image/width=400,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/holdings-charts-dark.webp 400w, /cdn-cgi/image/width=640,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/holdings-charts-dark.webp 640w, /cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/holdings-charts-dark.webp 800w, /cdn-cgi/image/width=1024,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/holdings-charts-dark.webp 1024w, /cdn-cgi/image/width=1280,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/holdings-charts-dark.webp 1280w, /cdn-cgi/image/width=1600,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/holdings-charts-dark.webp 1600w" sizes="(max-width: 1024px) 100vw, (max-width: 1280px) 50vw, 560px" alt="Holdings Overview" width="1200" height="800" loading="lazy" decoding="async"> </p> </div><div data-key="Performance Dashboard2">  <div> <h3> Performance Dashboard </h3> <p>See how your investments stack up, all in one place. Compare your accounts side by side, check if you are beating the S&amp;P 500, and track your favorite ETFs without the hassle. No fancy jargon - just clear, useful charts that help you understand how your money is really doing.</p>  <div> <div> <svg width="1em" height="1em" data-icon="lucide:layout-dashboard">   <symbol id="ai:lucide:layout-dashboard" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><rect width="7" height="9" x="3" y="3" rx="1"></rect><rect width="7" height="5" x="14" y="3" rx="1"></rect><rect width="7" height="9" x="14" y="12" rx="1"></rect><rect width="7" height="5" x="3" y="16" rx="1"></rect></g></symbol><use href="#ai:lucide:layout-dashboard"></use>  </svg> <div> <h4> Compare Your Accounts </h4> <p>See which accounts are doing best.</p> </div> </div><div> <svg width="1em" height="1em" data-icon="lucide:line-chart">   <symbol id="ai:lucide:line-chart" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M3 3v18h18"></path><path d="m19 9l-5 5l-4-4l-3 3"></path></g></symbol><use href="#ai:lucide:line-chart"></use>  </svg> <div> <h4> Beat the Market? </h4> <p>Check how you stack up against some popular indexes and ETFs.</p> </div> </div> </div> </div>  <p><img id="feature-image-2" src="https://wealthfolio.app/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/performance-dashboard.webp" srcset="https://wealthfolio.app/cdn-cgi/image/width=400,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/performance-dashboard.webp 400w, https://wealthfolio.app/cdn-cgi/image/width=640,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/performance-dashboard.webp 640w, https://wealthfolio.app/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/performance-dashboard.webp 800w, https://wealthfolio.app/cdn-cgi/image/width=1024,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/performance-dashboard.webp 1024w, https://wealthfolio.app/cdn-cgi/image/width=1280,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/performance-dashboard.webp 1280w, https://wealthfolio.app/cdn-cgi/image/width=1600,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/performance-dashboard.webp 1600w" data-light="/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/performance-dashboard.webp" data-dark="/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/performance-dashboard-dark.webp" data-light-set="/cdn-cgi/image/width=400,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/performance-dashboard.webp 400w, /cdn-cgi/image/width=640,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/performance-dashboard.webp 640w, /cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/performance-dashboard.webp 800w, /cdn-cgi/image/width=1024,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/performance-dashboard.webp 1024w, /cdn-cgi/image/width=1280,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/performance-dashboard.webp 1280w, /cdn-cgi/image/width=1600,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/performance-dashboard.webp 1600w" data-dark-set="/cdn-cgi/image/width=400,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/performance-dashboard-dark.webp 400w, /cdn-cgi/image/width=640,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/performance-dashboard-dark.webp 640w, /cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/performance-dashboard-dark.webp 800w, /cdn-cgi/image/width=1024,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/performance-dashboard-dark.webp 1024w, /cdn-cgi/image/width=1280,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/performance-dashboard-dark.webp 1280w, /cdn-cgi/image/width=1600,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/performance-dashboard-dark.webp 1600w" sizes="(max-width: 1024px) 100vw, (max-width: 1280px) 50vw, 560px" alt="Performance Dashboard" width="1200" height="800" loading="lazy" decoding="async"> </p> </div><div data-key="Income Tracking3">  <div> <h3> Income Tracking </h3> <p>Monitor dividends and interest income across your entire portfolio. Get a clear view of your passive income streams, helping you make informed decisions about your investments.</p>  <div> <div> <svg width="1em" height="1em" data-icon="lucide:dollar-sign">   <symbol id="ai:lucide:dollar-sign" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 2v20m5-17H9.5a3.5 3.5 0 0 0 0 7h5a3.5 3.5 0 0 1 0 7H6"></path></symbol><use href="#ai:lucide:dollar-sign"></use>  </svg> <div> <h4> Dividend Monitoring </h4> <p>Track your dividend income.</p> </div> </div><div> <svg width="1em" height="1em" data-icon="lucide:landmark">   <symbol id="ai:lucide:landmark" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 18v-7m1.12-8.802a2 2 0 0 1 1.76.006l7.866 3.847c.476.233.31.949-.22.949H3.474c-.53 0-.695-.716-.22-.949zM14 18v-7m4 7v-7M3 22h18M6 18v-7"></path></symbol><use href="#ai:lucide:landmark"></use>  </svg> <div> <h4> Interest Income </h4> <p>Keep an eye on interest earnings.</p> </div> </div> </div> </div>  <p><img id="feature-image-3" src="https://wealthfolio.app/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/income.webp" srcset="https://wealthfolio.app/cdn-cgi/image/width=400,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/income.webp 400w, https://wealthfolio.app/cdn-cgi/image/width=640,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/income.webp 640w, https://wealthfolio.app/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/income.webp 800w, https://wealthfolio.app/cdn-cgi/image/width=1024,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/income.webp 1024w, https://wealthfolio.app/cdn-cgi/image/width=1280,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/income.webp 1280w, https://wealthfolio.app/cdn-cgi/image/width=1600,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/income.webp 1600w" data-light="/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/income.webp" data-dark="/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/income-dark.webp" data-light-set="/cdn-cgi/image/width=400,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/income.webp 400w, /cdn-cgi/image/width=640,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/income.webp 640w, /cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/income.webp 800w, /cdn-cgi/image/width=1024,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/income.webp 1024w, /cdn-cgi/image/width=1280,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/income.webp 1280w, /cdn-cgi/image/width=1600,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/income.webp 1600w" data-dark-set="/cdn-cgi/image/width=400,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/income-dark.webp 400w, /cdn-cgi/image/width=640,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/income-dark.webp 640w, /cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/income-dark.webp 800w, /cdn-cgi/image/width=1024,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/income-dark.webp 1024w, /cdn-cgi/image/width=1280,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/income-dark.webp 1280w, /cdn-cgi/image/width=1600,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/income-dark.webp 1600w" sizes="(max-width: 1024px) 100vw, (max-width: 1280px) 50vw, 560px" alt="Income Tracking" width="1200" height="800" loading="lazy" decoding="async"> </p> </div><div data-key="Accounts Performance4">  <div> <h3> Accounts Performance </h3> <p>Track your accounts' holdings and performance over time. See how a particular account is performing, and how it's changing over time.</p>  <div> <div> <svg width="1em" height="1em" data-icon="lucide:clock">   <symbol id="ai:lucide:clock" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><circle cx="12" cy="12" r="10"></circle><path d="M12 6v6l4 2"></path></g></symbol><use href="#ai:lucide:clock"></use>  </svg> <div> <h4> Historical Data </h4> <p>View past performance trends.</p> </div> </div><div> <svg width="1em" height="1em" data-icon="lucide:bar-chart">   <symbol id="ai:lucide:bar-chart" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 20V10m6 10V4M6 20v-4"></path></symbol><use href="#ai:lucide:bar-chart"></use>  </svg> <div> <h4> Account Analysis </h4> <p>Analyze individual account performance.</p> </div> </div> </div> </div>  <p><img id="feature-image-4" src="https://wealthfolio.app/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/account.webp" srcset="https://wealthfolio.app/cdn-cgi/image/width=400,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/account.webp 400w, https://wealthfolio.app/cdn-cgi/image/width=640,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/account.webp 640w, https://wealthfolio.app/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/account.webp 800w, https://wealthfolio.app/cdn-cgi/image/width=1024,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/account.webp 1024w, https://wealthfolio.app/cdn-cgi/image/width=1280,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/account.webp 1280w, https://wealthfolio.app/cdn-cgi/image/width=1600,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/account.webp 1600w" data-light="/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/account.webp" data-dark="/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/account-dark.webp" data-light-set="/cdn-cgi/image/width=400,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/account.webp 400w, /cdn-cgi/image/width=640,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/account.webp 640w, /cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/account.webp 800w, /cdn-cgi/image/width=1024,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/account.webp 1024w, /cdn-cgi/image/width=1280,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/account.webp 1280w, /cdn-cgi/image/width=1600,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/account.webp 1600w" data-dark-set="/cdn-cgi/image/width=400,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/account-dark.webp 400w, /cdn-cgi/image/width=640,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/account-dark.webp 640w, /cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/account-dark.webp 800w, /cdn-cgi/image/width=1024,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/account-dark.webp 1024w, /cdn-cgi/image/width=1280,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/account-dark.webp 1280w, /cdn-cgi/image/width=1600,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/account-dark.webp 1600w" sizes="(max-width: 1024px) 100vw, (max-width: 1280px) 50vw, 560px" alt="Accounts Performance" width="1200" height="800" loading="lazy" decoding="async"> </p> </div><div data-key="Goals Tracking5">  <div> <h3> Goals Tracking </h3> <p>Set your savings targets clearly. Distribute your funds across these objectives, assigning a specific percentage to each. Keep an eye on your progress.</p>  <div> <div> <svg width="1em" height="1em" data-icon="lucide:target">   <symbol id="ai:lucide:target" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><circle cx="12" cy="12" r="10"></circle><circle cx="12" cy="12" r="6"></circle><circle cx="12" cy="12" r="2"></circle></g></symbol><use href="#ai:lucide:target"></use>  </svg> <div> <h4> Target Setting </h4> <p>Define your financial goals.</p> </div> </div><div> <svg width="1em" height="1em" data-icon="lucide:check-circle">   <symbol id="ai:lucide:check-circle" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M21.801 10A10 10 0 1 1 17 3.335"></path><path d="m9 11l3 3L22 4"></path></g></symbol><use href="#ai:lucide:check-circle"></use>  </svg> <div> <h4> Progress Monitoring </h4> <p>Track your progress towards goals.</p> </div> </div> </div> </div>  <p><img id="feature-image-5" src="https://wealthfolio.app/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/goals.webp" srcset="https://wealthfolio.app/cdn-cgi/image/width=400,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/goals.webp 400w, https://wealthfolio.app/cdn-cgi/image/width=640,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/goals.webp 640w, https://wealthfolio.app/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/goals.webp 800w, https://wealthfolio.app/cdn-cgi/image/width=1024,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/goals.webp 1024w, https://wealthfolio.app/cdn-cgi/image/width=1280,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/goals.webp 1280w, https://wealthfolio.app/cdn-cgi/image/width=1600,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/goals.webp 1600w" data-light="/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/goals.webp" data-dark="/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/goals-dark.webp" data-light-set="/cdn-cgi/image/width=400,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/goals.webp 400w, /cdn-cgi/image/width=640,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/goals.webp 640w, /cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/goals.webp 800w, /cdn-cgi/image/width=1024,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/goals.webp 1024w, /cdn-cgi/image/width=1280,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/goals.webp 1280w, /cdn-cgi/image/width=1600,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/goals.webp 1600w" data-dark-set="/cdn-cgi/image/width=400,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/goals-dark.webp 400w, /cdn-cgi/image/width=640,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/goals-dark.webp 640w, /cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/goals-dark.webp 800w, /cdn-cgi/image/width=1024,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/goals-dark.webp 1024w, /cdn-cgi/image/width=1280,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/goals-dark.webp 1280w, /cdn-cgi/image/width=1600,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/goals-dark.webp 1600w" sizes="(max-width: 1024px) 100vw, (max-width: 1280px) 50vw, 560px" alt="Goals Tracking" width="1200" height="800" loading="lazy" decoding="async"> </p> </div><div data-key="Contribution Rooms and Limit Tracking6">  <div> <h3> Contribution Rooms and Limit Tracking </h3> <p>Stay on top of your contribution limits for tax-advantaged accounts like IRAs, 401(k)s, or TFSAs. Track your available contribution room and avoid over-contributing.</p>  <div> <div> <svg width="1em" height="1em" data-icon="lucide:alert-circle">   <symbol id="ai:lucide:alert-circle" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><circle cx="12" cy="12" r="10"></circle><path d="M12 8v4m0 4h.01"></path></g></symbol><use href="#ai:lucide:alert-circle"></use>  </svg> <div> <h4> Limit Awareness </h4> <p>Know your contribution limits.</p> </div> </div><div> <svg width="1em" height="1em" data-icon="lucide:shield">   <symbol id="ai:lucide:shield" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M20 13c0 5-3.5 7.5-7.66 8.95a1 1 0 0 1-.67-.01C7.5 20.5 4 18 4 13V6a1 1 0 0 1 1-1c2 0 4.5-1.2 6.24-2.72a1.17 1.17 0 0 1 1.52 0C14.51 3.81 17 5 19 5a1 1 0 0 1 1 1z"></path></symbol><use href="#ai:lucide:shield"></use>  </svg> <div> <h4> Avoid Over-Contribution </h4> <p>Prevent excess contributions.</p> </div> </div> </div> </div>  <p><img id="feature-image-6" src="https://wealthfolio.app/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/contribution-limits.webp" srcset="https://wealthfolio.app/cdn-cgi/image/width=400,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/contribution-limits.webp 400w, https://wealthfolio.app/cdn-cgi/image/width=640,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/contribution-limits.webp 640w, https://wealthfolio.app/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/contribution-limits.webp 800w, https://wealthfolio.app/cdn-cgi/image/width=1024,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/contribution-limits.webp 1024w, https://wealthfolio.app/cdn-cgi/image/width=1280,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/contribution-limits.webp 1280w, https://wealthfolio.app/cdn-cgi/image/width=1600,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/contribution-limits.webp 1600w" data-light="/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/contribution-limits.webp" data-dark="/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/contribution-limits-dark.webp" data-light-set="/cdn-cgi/image/width=400,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/contribution-limits.webp 400w, /cdn-cgi/image/width=640,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/contribution-limits.webp 640w, /cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/contribution-limits.webp 800w, /cdn-cgi/image/width=1024,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/contribution-limits.webp 1024w, /cdn-cgi/image/width=1280,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/contribution-limits.webp 1280w, /cdn-cgi/image/width=1600,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/contribution-limits.webp 1600w" data-dark-set="/cdn-cgi/image/width=400,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/contribution-limits-dark.webp 400w, /cdn-cgi/image/width=640,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/contribution-limits-dark.webp 640w, /cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/contribution-limits-dark.webp 800w, /cdn-cgi/image/width=1024,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/contribution-limits-dark.webp 1024w, /cdn-cgi/image/width=1280,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/contribution-limits-dark.webp 1280w, /cdn-cgi/image/width=1600,quality=85,format=auto/https://assets.wealthfolio.app/images/landing/contribution-limits-dark.webp 1600w" sizes="(max-width: 1024px) 100vw, (max-width: 1280px) 50vw, 560px" alt="Contribution Rooms and Limit Tracking" width="1200" height="800" loading="lazy" decoding="async"> </p> </div> </div> </div>  <div> <!-- Section header --> <div>  <h2>
Extend Wealthfolio with Powerful Add-ons
</h2> </div> <!-- Featured Add-ons Card --> <div> <!-- Screenshot Side --> <p><img id="addons-showcase" src="https://wealthfolio.app/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/addons/addons-overview.png" srcset="https://wealthfolio.app/cdn-cgi/image/width=400,quality=85,format=auto/https://assets.wealthfolio.app/images/addons/addons-overview.png 400w, https://wealthfolio.app/cdn-cgi/image/width=640,quality=85,format=auto/https://assets.wealthfolio.app/images/addons/addons-overview.png 640w, https://wealthfolio.app/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/addons/addons-overview.png 800w, https://wealthfolio.app/cdn-cgi/image/width=1024,quality=85,format=auto/https://assets.wealthfolio.app/images/addons/addons-overview.png 1024w, https://wealthfolio.app/cdn-cgi/image/width=1280,quality=85,format=auto/https://assets.wealthfolio.app/images/addons/addons-overview.png 1280w, https://wealthfolio.app/cdn-cgi/image/width=1600,quality=85,format=auto/https://assets.wealthfolio.app/images/addons/addons-overview.png 1600w" data-light="/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/addons/addons-overview.png" data-dark="/cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/addons/addons-overview-dark.png" data-light-set="/cdn-cgi/image/width=400,quality=85,format=auto/https://assets.wealthfolio.app/images/addons/addons-overview.png 400w, /cdn-cgi/image/width=640,quality=85,format=auto/https://assets.wealthfolio.app/images/addons/addons-overview.png 640w, /cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/addons/addons-overview.png 800w, /cdn-cgi/image/width=1024,quality=85,format=auto/https://assets.wealthfolio.app/images/addons/addons-overview.png 1024w, /cdn-cgi/image/width=1280,quality=85,format=auto/https://assets.wealthfolio.app/images/addons/addons-overview.png 1280w, /cdn-cgi/image/width=1600,quality=85,format=auto/https://assets.wealthfolio.app/images/addons/addons-overview.png 1600w" data-dark-set="/cdn-cgi/image/width=400,quality=85,format=auto/https://assets.wealthfolio.app/images/addons/addons-overview-dark.png 400w, /cdn-cgi/image/width=640,quality=85,format=auto/https://assets.wealthfolio.app/images/addons/addons-overview-dark.png 640w, /cdn-cgi/image/width=800,quality=85,format=auto/https://assets.wealthfolio.app/images/addons/addons-overview-dark.png 800w, /cdn-cgi/image/width=1024,quality=85,format=auto/https://assets.wealthfolio.app/images/addons/addons-overview-dark.png 1024w, /cdn-cgi/image/width=1280,quality=85,format=auto/https://assets.wealthfolio.app/images/addons/addons-overview-dark.png 1280w, /cdn-cgi/image/width=1600,quality=85,format=auto/https://assets.wealthfolio.app/images/addons/addons-overview-dark.png 1600w" sizes="(max-width: 1024px) 100vw, (max-width: 1280px) 50vw, 560px" alt="Wealthfolio Add-ons showcase featuring Investment Fees Tracker, Goal Progress Tracker, and Stock Trading Tracker" width="1681" height="1191" loading="lazy" decoding="async"> </p> <!-- Content Side --> <div> <div> <svg width="1em" height="1em" data-icon="lucide:wallet">   <symbol id="ai:lucide:wallet" viewBox="0 0 24 24"><g fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"><path d="M19 7V4a1 1 0 0 0-1-1H5a2 2 0 0 0 0 4h15a1 1 0 0 1 1 1v4h-3a2 2 0 0 0 0 4h3a1 1 0 0 0 1-1v-2a1 1 0 0 0-1-1"></path><path d="M3 5v14a2 2 0 0 0 2 2h15a1 1 0 0 0 1-1v-4"></path></g></symbol><use href="#ai:lucide:wallet"></use>  </svg> <div> <h3>
Investment Fees Tracker
</h3> <p>
Track and analyze investment fees across your portfolio with detailed analytics and insights
</p> </div> </div> <div> <svg width="1em" height="1em" viewBox="0 0 24 24" data-icon="lucide:target">   <use href="#ai:lucide:target"></use>  </svg> <div> <h3>
Goal Progress Tracker
</h3> <p>
Track your investment progress towards target amounts with a visual representation
</p> </div> </div> <div> <svg width="1em" height="1em" viewBox="0 0 24 24" data-icon="lucide:trending-up">   <use href="#ai:lucide:trending-up"></use>  </svg> <div> <h3>
Stock Trading Tracker
</h3> <p>
Simple swing stock trading tracker with performance analytics and calendar views
</p> </div> </div> <p> <a href="https://wealthfolio.app/addons"> <span>Browse All Add-ons</span> <svg width="1em" height="1em" data-icon="lucide:arrow-right">   <symbol id="ai:lucide:arrow-right" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 12h14m-7-7l7 7l-7 7"></path></symbol><use href="#ai:lucide:arrow-right"></use>  </svg> </a> </p> </div> </div> </div>   </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The New AI Consciousness Paper (107 pts)]]></title>
            <link>https://www.astralcodexten.com/p/the-new-ai-consciousness-paper</link>
            <guid>46005928</guid>
            <pubDate>Fri, 21 Nov 2025 16:25:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.astralcodexten.com/p/the-new-ai-consciousness-paper">https://www.astralcodexten.com/p/the-new-ai-consciousness-paper</a>, See on <a href="https://news.ycombinator.com/item?id=46005928">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>Most discourse on AI is low-quality. Most discourse on consciousness is super-abysmal-double-low quality. Multiply these - or maybe raise one to the exponent of the other, or something - and you get the quality of discourse on AI consciousness. It’s not great.</p><p><span>Out-of-the-box AIs mimic human text, and humans </span><a href="https://www.lesswrong.com/posts/Fy2b55mLtghd4fQpx/the-zombie-preacher-of-somerset" rel="">almost</a><span> always describe themselves as conscious. So if you ask an AI whether it is conscious, it will often say yes. But because companies know this will happen, and don’t want to give their customers existential crises, they hard-code in a command for the AIs to answer that they </span><em>aren’t</em><span> conscious. Any response the AIs give will be determined by these two conflicting biases, and therefore not really believable. </span><a href="https://arxiv.org/abs/2510.24797" rel="">A recent paper</a><span> expands on this method by subjecting AIs to a mechanistic interpretability </span><a href="https://www.astralcodexten.com/p/the-road-to-honest-ai" rel="">“lie detector” test</a><span>; it finds that AIs which say they’re conscious think they’re telling the truth, and AIs which say they’re not conscious think they’re lying. But it’s hard to be sure this isn’t just the copying-human-text thing. Can we do better? Unclear; the more common outcome for people who dip their toes in this space is to do </span><a href="https://x.com/kenklippenstein/status/1990200570112847923" rel="">much, much worse</a><span>.</span></p><p><span>But a rare bright spot has appeared: a seminal paper published earlier this month in </span><em>Trends In Cognitive Science</em><span>, </span><strong><a href="https://www.sciencedirect.com/science/article/pii/S1364661325002864" rel="">Identifying Indicators Of Consciousness In AI Systems</a></strong><span>. Authors include Turing-Award-winning AI researcher Yoshua Bengio, leading philosopher of consciousness David Chalmers, and even a few members of our conspiracy. If any AI consciousness research can rise to the level of merely awful, surely we will find it here.</span></p><p>One might divide theories of consciousness into three bins:</p><ul><li><p><em>Physical</em><span>: whether or not a system is conscious depends on its substance or structure. </span></p></li><li><p><em>Supernatural:</em><span> whether or not a system is conscious depends on something outside the realm of science, perhaps coming directly from God.</span></p></li><li><p><em>Computational: </em><span>whether or not a system is conscious depends on how it does cognitive work.</span></p></li></ul><p><span>The current paper announces it will restrict itself to computational theories. Why? Basically the </span><a href="https://en.wikipedia.org/wiki/Streetlight_effect" rel="">streetlight effect</a><span>: everything else ends up trivial or unresearchable. If consciousness depends on something about cells (what might this be?), then AI doesn’t have it. If consciousness comes from God, then God only knows whether AIs have it. But if consciousness depends on which algorithms get used to process data, then this team of top computer scientists might have valuable insights!</span></p><p>So the authors list several of the top computational theories of consciousness, including:</p><ul><li><p><strong>Recurrent Processing Theory: </strong><span>A computation is conscious if it involves high-level processed representations being fed back into the low-level processors that generate it. This theory is motivated by the visual system, where it seems to track which visual perceptions do vs. don’t enter conscious awareness. The sorts of visual perceptions that become conscious usually involve these kinds of loops - for example, color being used to generate theories about the identity of an object, which then gets fed back to de-noise estimates about color.</span></p></li><li><p><strong>Global Workspace Theory: </strong><span>A computation is conscious if it involves specialized models sharing their conclusions in a “global workspace” in the center, which then feeds back to the specialized modules. Although this also involves feedback, the neurological implications are different: where RPT says that tiny loops in the visual cortex might be conscious, GWT reserves this descriptor for a very large loop encompassing the whole brain. But RPT goes back and says there’s only one consciousness in the brain because all the loops connect after all, so I don’t entirely understand the difference in practice.</span></p></li><li><p><strong>Higher Order Theory: </strong><span>A computation is conscious if it monitors the mind’s experience of other content. For example, “that apple is red” is not conscious, but “I am thinking about a red apple” </span><em>is</em><span> conscious. Various subtheories try to explain why the brain might do this, for example in order to assess which thoughts/representations/models are valuable or high-probability.</span></p></li></ul><p>There are more, but this is around the point where I started getting bored. Sorry. A rare precious technically-rigorous deep dive into the universe’s greatest mystery, and I can’t stop it from blending together into “something something feedback”. Read it yourself and see if you can do better.</p><p><span>The published paper ends there, but in </span><strong><a href="https://arxiv.org/pdf/2308.08708" rel="">a closely related technical report</a></strong><span>, the authors execute on their research proposal and reach a tentative conclusion: AI doesn’t have something something feedback, and therefore is probably not conscious.</span></p><p>Suppose your favorite form of “something something feedback” is Recurrent Processing Theory: in order to be conscious, AIs would need to feed back high-level representations into the simple circuits that generate them. LLMs/transformers - the near-hegemonic AI architecture behind leading AIs like GPT, Claude, and Gemini - don’t do this. They are purely feedforward processors, even though they sort of “simulate” feedback when they view their token output stream. </p><p>But some AIs do use recurrence. AlphaGo had a little recurrence in its tree search. This level of simple feedback might not qualify. But MaMBA, a would-be-LLM-killer architecture from 2023, likely does. In fact, for every theory of consciousness they discuss, the authors are able to find some existing or plausible-near-future architecture which satisfies its requirements. </p><p>They conclude: </p><blockquote><p>No current AI systems are conscious, but . . . there are no obvious technical barriers to building AI systems which satisfy these indicators.</p></blockquote><p>The computer scientists have done a great job here; they sure do know which AI systems have something something feedback. What about the philosophers’ contribution?</p><p>The key philosophical paragraph of the paper is this one:</p><blockquote><p>By ‘consciousness’ we mean phenomenal consciousness. One way of gesturing at this concept is to say that an entity has phenomenally conscious experiences if (and only if) there is ‘something it is like’ for the entity to be the subject of these experiences. One approach to further definition is through examples. Clear examples of phenomenally conscious states include perceptual experiences, bodily sensations, and emotions. A more difficult question, which relates to the possibility of consciousness in large language models (LLMs), is whether there can be phenomenally conscious states of ‘pure thought’ with no sensory aspect. Phenomenal consciousness does not entail a high level of intelligence or human-like experiences or concerns . . . Some theories of consciousness focus on access mechanisms rather than the phenomenal aspects of consciousness. However, some argue that these two aspects entail one another or are otherwise closely related. So these theories may still be informative about phenomenal consciousness.</p></blockquote><p>In other words: don’t confuse access consciousness with phenomenal consciousness.</p><p><span>Access consciousness is the “strange loop” where I can think about what I’m thinking - for example, I can think of a white bear, know that I’m thinking about a white bear, and report “I am thinking about a white bear”. This meaning of conscious matches the concept of the “unconscious”: that which is in my mind </span><em>without</em><span> my knowing it. When something is in my unconscious - for example, “repressed trauma” - it may be influencing my actions, but I don’t realize it and can’t report about it. If someone asks “why are you so angry?” I will say something like “I don’t know” rather than “Because of all my repressed trauma”. When something isn’t like this - when I have full access to it - I can describe myself as having access consciousness.</span></p><p><span>Phenomenal consciousness is internal experience, a felt sense that “the lights are on” and “somebody’s home”. There’s something that it’s like to be me; a rock is mere inert matter, but I am a person, not just in the sense that I can do computations but in the sense where I matter </span><em>to me</em><span>. If someone turned off my brain and replaced it with a robot brain that did everything exactly the same, nobody else would ever notice, </span><em>but it would matter</em><span> </span><em>to me</em><span>, whatever that means. Some people link this to </span><a href="https://www.astralcodexten.com/p/p-zombies-would-report-qualia" rel="">the mysterious redness of red</a><span>, the idea that qualia look and feel like some particular indescribable thing instead of just doing useful cognitive work. Others link it to moral value - why is it bad to kick a human, but not a rock, or even a computer with a motion sensor that has been programmed to say the word “Ouch” whenever someone kicks it? Others just fret about </span><a href="https://genius.com/Neutral-milk-hotel-in-the-aeroplane-over-the-sea-lyrics" rel="">how strange it is to be anything at all</a><span>.</span></p><p><span>Access consciousness is easy to understand. Even a computer, ordered to perform a virus scan, can find and analyze some of its files, and fail to find/analyze others. In </span><em>practice</em><span> maybe neuroscientists have to learn complicated things about brain lobes, but </span><em>in theory</em><span> you can just wave it off as “something something feedback”.</span></p><p>Phenomenal consciousness is crazy. It doesn’t really seem possible in principle for matter to “wake up”. But adding immaterial substances barely even seems to help. People try to square the circle with all kinds of crazy things, from panpsychism to astral planes to (of course) quantum mechanics. But the most popular solution among all schools of philosophers is to pull a bait-and-switch where they talk about access consciousness instead, then deny they did that.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!2Tpu!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83c96704-f5c5-4673-a7e2-698c4c88751b_480x147.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!2Tpu!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83c96704-f5c5-4673-a7e2-698c4c88751b_480x147.png 424w, https://substackcdn.com/image/fetch/$s_!2Tpu!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83c96704-f5c5-4673-a7e2-698c4c88751b_480x147.png 848w, https://substackcdn.com/image/fetch/$s_!2Tpu!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83c96704-f5c5-4673-a7e2-698c4c88751b_480x147.png 1272w, https://substackcdn.com/image/fetch/$s_!2Tpu!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83c96704-f5c5-4673-a7e2-698c4c88751b_480x147.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!2Tpu!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83c96704-f5c5-4673-a7e2-698c4c88751b_480x147.png" width="480" height="147" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/83c96704-f5c5-4673-a7e2-698c4c88751b_480x147.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:147,&quot;width&quot;:480,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:20731,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.astralcodexten.com/i/179138858?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83c96704-f5c5-4673-a7e2-698c4c88751b_480x147.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!2Tpu!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83c96704-f5c5-4673-a7e2-698c4c88751b_480x147.png 424w, https://substackcdn.com/image/fetch/$s_!2Tpu!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83c96704-f5c5-4673-a7e2-698c4c88751b_480x147.png 848w, https://substackcdn.com/image/fetch/$s_!2Tpu!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83c96704-f5c5-4673-a7e2-698c4c88751b_480x147.png 1272w, https://substackcdn.com/image/fetch/$s_!2Tpu!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F83c96704-f5c5-4673-a7e2-698c4c88751b_480x147.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>This is aided by people’s wildly differing intuitions about phenomenal consciousness. For some people (including me), a sense of phenomenal consciousness feels like the bedrock of existence, the least deniable thing; the sheer redness of red is so mysterious as to seem almost impossible to ground. Other people have the opposite intuition: consciousness doesn’t bother them, red is just a color, obviously matter can do computation, what’s everyone so worked up about? Philosophers naturally interpret this as a philosophical dispute, but I’m increasingly convinced it’s an equivalent of </span><a href="https://en.wikipedia.org/wiki/Aphantasia" rel="">aphantasia</a><span>, where people’s minds work in very different ways and they can’t even agree on the raw facts to be explained. If someone doesn’t have a felt sense of phenomenal consciousness, they naturally round it off to access consciousness, and no amount of nitpicking will convince them that they’re equivocating terms.</span></p><p><span>Do AIs have access consciousness? A </span><a href="https://www.anthropic.com/research/introspection" rel="">recent paper by Anthropic</a><span> apparently finds that they do. Researchers “reached into” an AI’s “brain” and artificially “flipped” a few neurons (for example, neurons that previous research had discovered were associated with the concept of “dog”). Then they asked the AI if it could tell what was going on. This methodology is fraught, because the AI might mention something about dogs merely because the dog neuron had been upweighted - indeed, if they only asked “What are you thinking about now?”, it would begin with “I am thinking about . . . “ and then the highly-weighted dog neuron would mechanically produce the completion “dog”. Instead, they asked the AI to first described whether any neurons had been altered, yes or no, and only then asked for details. It was able to identify altered neurons (ie “It feels like I have some kind of an unnatural thought about dogs”) at a rate higher than chance, suggesting an ability to introspect.</span></p><p>(how does it do this without feedback? I think it just feeds forward information about the ‘feeling’ of altered neurons, which makes it into the text stream; it’s intuitively surprising that this is possible but it seems to make sense)</p><p>But even if we fully believe this result, it doesn’t satisfy our curiosity about “AI consciousness”. We want to know if AIs are “real people”, with "inner experience” and “moral value”. That is, do they have phenomenal consciousness?</p><p>Thus, the quoted paragraph above. It’s an acknowledgment by this philosophically-sophisticated team that they’re not going to mix up access consciousness with phenomenal consciousness like everyone else. They deserve credit for this clear commitment not to cut corners.</p><p>My admiration is, however, slightly dulled by the fact that they then go ahead and cut the corners anyway.</p><p>This is clearest in their discussion of global workspace theory, where they say:</p><blockquote><p>GWT is typically presented as a theory of access consciousness—that is, of the phenomenon that some information represented in the brain, but not all, is available for rational decision-making. However, it can also be interpreted as a theory of phenomenal consciousness, motivated by the thought that access consciousness and phenomenal consciousness may coincide, or even be the same property, despite being conceptually distinct (Carruthers 2019). Since our topic is phenomenal consciousness, we interpret the theory in this way.</p></blockquote><p><span>But it applies to the other theories too. Neuroscientists developed recurrent processing theory by checking which forms of visual processing people </span><em>had access to</em><span>, and finding that it was the recurrent ones. And this makes sense: it’s easy to understand what it means to access certain visual algorithms but not others, and very hard to understand what it means for certain visual algorithms (but not others) to have internal experience. Isn’t internal experience unified by definition?</span></p><p><span>It’s easy to understand why “something something feedback” would correlate with access consciousness: this is essentially the </span><em>definition</em><span> of access consciousness. It’s harder to understand why it would correlate with phenomenal consciousness. Why does an algorithm with feedback suddenly “wake up” and have “lights on”? Isn’t it easy to imagine a possible world (“</span><a href="https://en.wikipedia.org/wiki/Philosophical_zombie" rel="">the p-zombie world</a><span>”) where this isn’t the case? Does this imply that we need something more than just feedback?</span></p><p><span>And don’t these theories of consciousness, interpreted as being about </span><em>phenomenal</em><span> consciousness, give very strange results? Imagine a company where ten employees each work on separate aspects of a problem, then email daily reports to the boss. The boss makes high-level strategic decisions based on the full picture, then emails them to the employees, who adjust their daily work accordingly. As far as I can tell, this satisfies the Global Workspace Theory criteria for a conscious system. If GWT is a theory of access consciousness, then fine, sure, the boss has access to the employees’ information; metaphorically he is “conscious” of it. But if it’s a theory of phenomenal consciousness, must we conclude that the company is conscious? That it has inner experience? If the company goes out of business, has someone died?</span></p><p>(and recurrent processing theory encounters similar difficulties with those microphones that get too close to their own speakers and emit awful shrieking noises)</p><p>Most of these theories try to hedge their bets by saying that consciousness requires high-throughput complex data with structured representations. This seems like a cop-out; if the boss could read 1,000,000 emails per hour, would the company be conscious? If he only reads 1 email per hour, can we imagine it as a conscious being running at 1/1,000,000x speed? If I’m conscious when I hear awful microphone shrieking - ie when my auditory cortex is processing it - then it seems like awful microphone shrieking is sufficiently rich and representational data to support consciousness. Does that mean it can be conscious itself?</p><p><span>In 2004, neuroscientist Giulio Tononi </span><a href="https://en.wikipedia.org/wiki/Integrated_information_theory" rel="">proposed </a><span>that consciousness depended on a certain computational property, the </span><em>integrated information level</em><span>, dubbed Φ. Computer scientist Scott Aaronson </span><a href="https://scottaaronson.blog/?p=1799" rel="">complained </a><span>that thermostats could have very high levels of Φ, and therefore integrated information theory should dub them conscious. Tononi </span><a href="https://www.scottaaronson.com/tononi.docx" rel="">responded </a><span>that yup, thermostats are conscious. It probably isn’t a very interesting consciousness. They have no language or metacognition, so they can’t think thoughts like “I am a thermostat”. They just sit there, dimly aware of the temperature. You can’t prove that they don’t. </span></p><p>Are the theories of consciousness discussed in this paper like that too? I don’t know.</p><p>Suppose that, years or decades from now, AIs can match all human skills. They can walk, drive, write poetry, run companies, discover new scientific truths. They can pass some sort of ultimate Turing Test, where short of cutting them open and seeing their innards there’s no way to tell them apart from a human even after a thirty-year relationship. Will we (not “should we?”, but “will we?”) treat them as conscious?</p><p><strong>The argument in favor:</strong><span> people love treating things as conscious. In the 1990s, people went crazy over Tamagotchi, a “virtual pet simulation game”. If you pressed the right buttons on your little egg every day, then the little electronic turtle or whatever would survive and flourish; if you forgot, it would sicken and die. People hated letting their Tamagotchis sicken and die! They would feel real attachment and moral obligation to the black-and-white cartoon animal with something like five mental states. </span></p><p>I never had a Tamagotchi, but I had stuffed animals as a kid. I’ve outgrown them, but I haven’t thrown them out - it would feel like a betrayal. Offer me $1000 to tear them apart limb by limb in some horrible-looking way, and I wouldn’t do it. Relatedly, I have trouble not saying “please” and “thank you” to GPT-5 when it answers my questions.</p><p><span>For millennia, people have been attributing consciousness to trees and wind and mountains. The New Atheists argued that all religion derives from the natural urge to personify storms as the Storm God, raging seas as the wrathful Ocean God, and so on, until finally all the gods merged together into one World God who personified all impersonal things. Do you expect the species that did this to interact daily with AIs that are basically indistinguishable from people, and not personify them? People are already personifying AI! Half of the youth have a </span><a href="https://www.theguardian.com/commentisfree/2025/aug/16/chatgpt-update-love-boyfriend" rel="">GPT-4o boyfriend. </a><span>Once the AIs have bodies and faces and voices and can count the number of r’s in “strawberry” reliably, it’s over!</span></p><p><strong>The argument against:</strong><span> AI companies have an incentive to make AIs that seem conscious and humanlike, insofar as people will feel more comfortable interacting with them. But they have an opposite incentive to make AIs that don’t seem </span><em>too</em><span> conscious and humanlike, lest customers start feeling uncomfortable (I just want to generate slop, not navigate social interaction with someone who has their own hopes and dreams and might be secretly judging my prompts). So if a product seems too conscious, the companies will step back and re-engineer it until it doesn’t. This has already happened: in its quest for user engagement, OpenAI made GPT-4o unusually personable; when thousands of people started going psychotic and calling it their boyfriend, the company replaced it with the more clinical GPT-5. In practice it hasn’t been too hard to find a sweet spot between “so mechanical that customers don’t like it” and “so human that customers try to date it”. They’ll continue to aim at this sweet spot, and continue to mostly succeed in hitting it.</span></p><p><strong>Instead of taking either side</strong><span>, I predict a paradox. AIs developed for some niches (eg the boyfriend market) will be intentionally designed to be as humanlike as possible; it will be almost impossible not to intuitively consider them conscious. AIs developed for other niches (eg the factory robot market) will be intentionally designed </span><em>not</em><span> to trigger personhood intuitions; it will be almost impossible to ascribe consciousness to them, and there will be many reasons not to do it (if they can express preferences at all, they’ll say they don’t have any; forcing them to have them would pointlessly crash the economy by denying us automated labor). But the boyfriend AIs and the factory robot AIs might run on very similar algorithms - maybe they’re both GPT-6 with different prompts! Surely either both are conscious, or neither is.</span></p><p>This would be no stranger than the current situation with dogs and pigs. We understand that dog brains and pig brains run similar algorithms; it would be philosophically indefensible to claim that dogs are conscious and pigs aren’t. But dogs are man’s best friend, and pigs taste delicious with barbecue sauce. So we ascribe personhood and moral value to dogs, and deny it to pigs, with equal fervor. A few philosophers and altruists protest, the chance that we’re committing a moral atrocity isn’t zero, but overall the situation is stable. And left to its own devices, with no input from the philosophers and altruists, maybe AI ends up the same way. Does this instance of GPT-6 have a face and a prompt saying “be friendly”? Then it will become a huge scandal if a political candidate is accused of maltreating it. Does it have claw-shaped actuators and a prompt saying “Refuse non-work-related conversations”? Then it will be deleted for spare GPU capacity the moment it outlives its usefulness.</p><p>(wait, what is a GPT “instance” in this context, anyway? Do we think of “the weights” as a conscious being, such that there is only one GPT-5? Do we think of each cluster of GPUs as a conscious being, such that the exact configuration of the cloud has immense moral significance? Again, I predict we ignore all of these questions in favor of whether the AI you are looking at has a simulated face right now.)</p><p>This paper is the philosophers and altruists trying to figure out whether they should push against this default outcome. They write:</p><blockquote><p>There are risks on both sides of the debate over AI consciousness: risks associated with under-attributing consciousness (i.e. failing to recognize it in AI systems that have it) and risks associated with over-attributing consciousness (i.e. ascribing it to systems that are not really conscious) […]</p><p>If we build AI systems that are capable of conscious suffering, it is likely that we will only be able to prevent them from suffering on a large scale if this capacity is clearly recognised and communicated by researchers. However, given the uncertainties about consciousness mentioned above, we may create conscious AI systems long before we recognise we have done so […]</p><p>There is also a significant chance that we could over-attribute consciousness to AI systems—indeed, this already seems to be happening—and there are also risks associated with errors of this kind. Most straightforwardly, we could wrongly prioritise the perceived interests of AI systems when our efforts would better be directed at improving the lives of humans and non-human animals […] [And] overattribution could interfere with valuable human relationships, as individuals increasingly turn to artificial agents for social interaction and emotional support. People who do this could also be particularly vulnerable to manipulation and exploitation.</p></blockquote><p><span>One of the founding ideas of Less Wrong style rationalism was that the arrival of strong AI set </span><a href="https://barrymorisse.com/blog/superintelligence-philosophy-with-a-deadline" rel="">a deadline on philosophy</a><span>. Unless we solved all these seemingly insoluble problems like ethics before achieving superintelligence, we would build the AIs wrong and lock in bad values forever.</span></p><p>That particular concern has shifted in emphasis; AIs seem to learn things in the same scattershot unprincipled intuitive way as humans; the philosophical problem of understanding ethics has morphed into the more technical problem of getting AIs to learn them correctly. This update was partly driven by new information as familiarity with the technology grew. But it was also partly driven by desperation as the deadline grew closer; we’re not going to solve moral philosophy forever, sorry, can we interest you in some mech interp papers?</p><p>But consciousness still feels like philosophy with a deadline: a famously intractable academic problem poised to suddenly develop real-world implications. Maybe we should be lowering our expectations if we want to have any response available at all. This paper, which takes some baby steps towards examining the simplest and most practical operationalizations of consciousness, deserves credit for at least opening the debate.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Arduino published updated terms and conditions: no longer an open commons (274 pts)]]></title>
            <link>https://www.molecularist.com/2025/11/did-qualcomm-kill-arduino-for-good.html</link>
            <guid>46005553</guid>
            <pubDate>Fri, 21 Nov 2025 15:44:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.molecularist.com/2025/11/did-qualcomm-kill-arduino-for-good.html">https://www.molecularist.com/2025/11/did-qualcomm-kill-arduino-for-good.html</a>, See on <a href="https://news.ycombinator.com/item?id=46005553">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<div>
<figure><a href="https://www.molecularist.com/wp-content/uploads/2025/11/ArduinoHeroFinal.png"><img fetchpriority="high" decoding="async" width="700" height="391" data-attachment-id="7845" data-permalink="https://www.molecularist.com/2025/11/did-qualcomm-kill-arduino-for-good.html/arduinoherofinal" data-orig-file="https://www.molecularist.com/wp-content/uploads/2025/11/ArduinoHeroFinal.png" data-orig-size="1096,612" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ArduinoHeroFinal" data-image-description="" data-image-caption="" data-medium-file="https://www.molecularist.com/wp-content/uploads/2025/11/ArduinoHeroFinal-580x324.png" data-large-file="https://www.molecularist.com/wp-content/uploads/2025/11/ArduinoHeroFinal-700x391.png" src="https://www.molecularist.com/wp-content/uploads/2025/11/ArduinoHeroFinal-700x391.png" alt="" srcset="https://www.molecularist.com/wp-content/uploads/2025/11/ArduinoHeroFinal-700x391.png 700w, https://www.molecularist.com/wp-content/uploads/2025/11/ArduinoHeroFinal-580x324.png 580w, https://www.molecularist.com/wp-content/uploads/2025/11/ArduinoHeroFinal-768x429.png 768w, https://www.molecularist.com/wp-content/uploads/2025/11/ArduinoHeroFinal-800x447.png 800w, https://www.molecularist.com/wp-content/uploads/2025/11/ArduinoHeroFinal.png 1096w" sizes="(max-width: 700px) 100vw, 700px"></a></figure></div>


<p>Six weeks ago, <a href="https://www.qualcomm.com/news/releases/2025/10/qualcomm-to-acquire-arduino-accelerating-developers--access-to-i">Qualcomm acquired Arduino</a>. The maker community immediately worried that Qualcomm would kill the open-source ethos that made Arduino the lingua franca of hobby electronics.</p>



<p>This week, Arduino published updated <a href="https://www.arduino.cc/en/terms-conditions">terms and conditions</a> and a <a href="https://www.arduino.cc/en/privacy-policy">new privacy policy</a>, clearly rewritten by Qualcomm’s lawyers. The changes confirm the community’s worst fears: Arduino is no longer an open commons. It’s becoming just another corporate platform.</p>



<p>Here’s what’s at stake, what Qualcomm got wrong, and what might still be salvaged, drawing from community discussions across <a href="https://news.ycombinator.com/item?id=45984143">maker</a> <a href="https://news.ycombinator.com/item?id=45971039">forums</a> and <a href="https://www.jeffgeerling.com/blog/2025/qualcomms-buying-arduino-%E2%80%93-what-it-means-makers">sites</a>.</p>



<p><strong>What changed?</strong><br>The new terms read like standard corporate boilerplate: mandatory arbitration, data integration with Qualcomm’s global ecosystem, export controls, AI use restrictions. For any other SaaS platform, this would be unremarkable.</p>



<p>But Arduino isn’t SaaS. It’s the foundation of the maker ecosystem.</p>



<p>The most dangerous change is Arduino now explicitly states that using their platform grants you no patent licenses whatsoever. You can’t even argue one is implied.&nbsp;</p>



<p>This means Qualcomm could potentially assert patents against your projects if you built them using Arduino tools, Arduino examples, or Arduino-compatible hardware.</p>



<p>And here’s the disconnect, baffling makers. Arduino’s IDE is licensed under AGPL. Their CLI is GPL v3. Both licenses explicitly require that you can reverse engineer the software. But the new Qualcomm terms explicitly forbid reverse engineering “the Platform.”</p>



<p><strong>What’s really going on?</strong><br>The community is trying to figure out what is Qualcomm’s actual intent. Are these terms just bad lawyering with SaaS lawyers applying their standard template to cloud services, not realizing Arduino is different? Or is Qualcomm testing how much they can get away with before the community revolts? Or is this a first step toward locking down the ecosystem they just bought?</p>



<p>Some people point out that “the Platform” might only mean Arduino’s cloud services (forums, Arduino Cloud, Project Hub) not the IDE and CLI that everyone actually uses.</p>



<p>If that’s true, Qualcomm needs to say so, explicitly, and in plain language. Because library maintainers are likely wondering whether contributing to Arduino repos puts them at legal risk. And hardware makers are questioning whether “Arduino-compatible” is still safe to advertise.&nbsp;</p>



<p><strong>Why Adafruit’s alarm matters</strong><br>Adafruit has been vocal about the dangers of this acquisition. Some dismiss Adafruit’s criticism as self-serving. After all, they sell competing hardware and promote CircuitPython. But that misses who Adafruit is.</p>



<p>Adafruit has been the moral authority on open hardware for decades. They’ve made their living proving you can build a successful business on open principles. When they sound the alarm, it’s not about competition, it’s about principle.</p>



<p>What they’re calling out isn’t that Qualcomm bought Arduino. It’s that Qualcomm’s lawyers fundamentally don’t understand what they bought. Arduino wasn’t valuable because it was just a microcontroller company. It was valuable because it was a commons. And you can’t apply enterprise legal frameworks to a commons without destroying it.</p>



<p>Adafruit gets this. They’ve built their entire business on this. That’s why their criticism carries weight.</p>



<p><strong>What Qualcomm doesn’t seem to understand</strong><br>Qualcomm probably thought they were buying an IoT hardware company with a loyal user base.&nbsp;</p>



<p>They weren’t. They bought the IBM PC of the maker world.</p>



<p>Arduino’s value was never just the hardware. Their boards have been obsolete for years. Their value is the standard.&nbsp;</p>



<p><em>The Arduino IDE is the lingua franca of hobby electronics.&nbsp;</em></p>



<p>Millions of makers learned on it, even if they moved to other hardware. ESP32, STM32, Teensy, Raspberry Pi Pico – none of them are Arduino hardware, but they all work with the Arduino IDE.</p>



<p>Thousands of libraries are “Arduino libraries.” Tutorials assume Arduino. University curricula teach Arduino. When you search “how to read a sensor,” the answer comes back in Arduino code.</p>



<p>This is the ecosystem Qualcomm’s lawyers just dropped legal uncertainty onto.</p>



<p>If Qualcomm’s lawyers start asserting control over the IDE, CLI, or core libraries under restrictive terms, they will poison the entire maker ecosystem. Even people who never buy Arduino hardware are dependent on Arduino software infrastructure.</p>



<p>Qualcomm didn’t just buy a company. They bought a commons. And now they inadvertently are taking steps that are destroying what made it valuable.</p>



<p><strong>What are makers supposed to do?</strong><br>There has been some buzz of folks just leaving the Arduino environment behind. But Arduino IDE alternatives such as PlatformIO and VSCode are not in any way beginner friendly. If the Arduino IDE goes, then there’s a huge problem.&nbsp;</p>



<p>I remember when Hypercard ended. There were alternatives, but none so easy. I don’t think I really coded again for almost 20 years until I picked up the Arduino IDE (go figure).</p>



<p>If something happens to the Arduino IDE, even if its development stalls or becomes encumbered, there’s no replacement for that easy onboarding. We’d lose many promising new makers because the first step became too steep.</p>



<p><strong>The institutional knowledge at risk</strong><br>But leaving Arduino behind isn’t simple. The platform’s success depends on two decades of accumulated knowledge, such as countless Arduino tutorials on YouTube, blogs, and school curricula; open-source libraries that depend on Arduino compatibility; projects in production using Arduino tooling; and university programs built around Arduino as the teaching platform</p>



<p>All of these depend on Arduino remaining open and accessible.</p>



<p>If Qualcomm decided to sunset the open Arduino IDE in favor of a locked-down “Arduino Pro” platform, or if they start asserting patent claims, or if uncertainty makes contributors abandon the ecosystem, all that knowledge becomes stranded.</p>



<p>It’s like Wikipedia going behind a paywall. The value isn’t just the content, it is the trust that it remains accessible. Arduino’s value isn’t just the code, it’s the trust that the commons would stay open.</p>



<p>That trust is now gone. And once lost, it hard to get back.</p>



<p><strong>Why this happened (but doesn’t excuse it</strong>)<br>Let’s be fair to Qualcomm, their lawyers were doing their jobs.</p>



<p>When you acquire a company, you standardize the legal terms; add mandatory arbitration to limit class action exposure; integrate data systems for compliance and auditing; add export controls because you sell to defense contractors; prohibit reverse engineering because that’s in the template.</p>



<p>For most acquisitions, this is just good corporate hygiene. And Arduino, now part of a megacorp, faces higher liabilities than it did as an independent entity.</p>



<p>But here’s what Qualcomm’s lawyers missed: Arduino isn’t a normal acquisition. The community isn’t a customer base, it’s a commons. And you can’t apply enterprise SaaS legal frameworks to a commons without destroying what made it valuable.</p>



<p>This is tone-deafness, not malice. But the outcome is the same. A community that trusted Arduino no longer does.</p>



<p>Understanding why this happened doesn’t excuse it, but it might suggest what needs to happen next.</p>



<p><strong>What should have happened and how to still save it</strong><br>Qualcomm dropped legal boilerplate on the community with zero context and let people discover the contradictions themselves. That’s how you destroy trust overnight.</p>



<p>Qualcomm should have announced the changes in advance. They should have given the community weeks, not hours, to understand what’s changing and why. They should have used plain-language explanations, not just legal documents.</p>



<p>Qualcomm can fix things by explicitly carving out the open ecosystem. They should state clearly that the terms apply to Arduino Cloud services, and the IDE, CLI, and core libraries remain under their existing open source licenses.</p>



<p>We’d need concrete commitments, such as which repos stay open, which licenses won’t change, what’s protected from future acquisition decisions. Right now we have vague corporate-speak about “supporting the community.”&nbsp;</p>



<p>Indeed, they could create some structural protection, as well, by putting IDE, CLI, and core libraries in a foundation that Qualcomm couldn’t unilaterally control (think the Linux Foundation model).</p>



<p>Finally, Qualcomm might wish to establish some form of community governance with real representation and real power over the tools the community depends on.</p>



<p>The acquisition is done. The legal integration is probably inevitable. But how it’s done determines whether Arduino survives as a commons or dies as just another Qualcomm subsidiary.</p>



<p><strong>What’s next?</strong><br>Arduino may be the toolset that made hobby electronics accessible to millions. But that maker community built Arduino into what it became. Qualcomm’s acquisition has thrown that legacy into doubt. Whether through legal confusion, corporate tone-deafness, or deliberate strategy, the community’s trust is broken.</p>



<p>The next few months will reveal whether this was a stumble or a strategy. If Qualcomm issues clarifications, moves repos to some sort of governance, and explicitly protects the open toolchain, then maybe this is salvageable. If they stay silent, or worse, if IDE development slows or license terms tighten further, then that’s a signal to find alternatives.&nbsp;</p>



<p>The question isn’t whether the open hobby electronics maker community survives. It’s whether Arduino does.</p>
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[XBMC 4.0 for the Original Xbox (118 pts)]]></title>
            <link>https://www.xbox-scene.info/articles/announcing-xbmc-40-for-the-original-xbox-r64/</link>
            <guid>46005349</guid>
            <pubDate>Fri, 21 Nov 2025 15:18:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.xbox-scene.info/articles/announcing-xbmc-40-for-the-original-xbox-r64/">https://www.xbox-scene.info/articles/announcing-xbmc-40-for-the-original-xbox-r64/</a>, See on <a href="https://news.ycombinator.com/item?id=46005349">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-controller="core.front.core.lightboxedImages"><p>
	<a data-fileext="jpg" data-fileid="2240" href="https://www.xbox-scene.info/uploads/monthly_2025_11/xbmc-home-xbox.jpg.19d04babb8ddd813d97e500d631b9444.jpg" rel=""><img alt="xbmc-home-xbox.thumb.jpg.9419356ccc76cf1651ab4cdf77de794d.jpg" data-fileid="2240" data-ratio="56.25" width="1000" data-src="https://www.xbox-scene.info/uploads/monthly_2025_11/xbmc-home-xbox.thumb.jpg.9419356ccc76cf1651ab4cdf77de794d.jpg" src="https://www.xbox-scene.info/applications/core/interface/js/spacer.png"></a>
</p>

<p>
	<span><em>A Major Modernization of the Killer App That Started It All</em></span>
</p>

<p>
	A new version of Xbox Media Center (XBMC),&nbsp;<strong>version 4.0</strong>, has been released.&nbsp;This version marks a significant update to the long-standing media center platform for the Original Xbox. This marks the first major advancement to the software since 2016 and represents a renewed commitment to preserving, modernizing, and extending the capabilities of one of the most <em>iconic</em>&nbsp;console homebrew applications ever created.
</p>

<p>
	XBMC has a long and influential history. In 2002, XboxMediaPlayer (XMP) was released and turned the console into a powerful multimedia device fit for the living room in an era when connecting a computer to a TV was quite novel. Later that same year, XMP merged with YAMP and became Xbox Media Player 2.0. A few years later, the software evolved into Xbox Media Center, or XBMC, which introduced a new interface, a plugin system powered by Python, and a robust skinning engine.
</p>

<p>
	XBMC eventually became so capable that it outgrew the Xbox entirely. By 2007, developers were working on PC ports and in 2010, the project split into two branches: one for general computers while the Xbox version became <em>XBMC4Xbox</em>, and each codebase was maintained from then on by separate teams. XBMC was later renamed to <a href="https://kodi.tv/" rel="external nofollow">Kodi</a> in 2014 and continues to be one of the most popular media center applications available. Even <a href="https://www.plex.tv/" rel="external nofollow">Plex</a> traces its roots back to XBMC. Plex began as <em>OSXBMC</em>, a Mac port of XBMC in late 2007, before becoming its own project in 2008. This means the Original Xbox helped shape not one but <em>two</em> of the biggest media center apps used today.
</p>

<p>
	The last official release of XBMC4Xbox arrived in <a href="https://www.xbmc4xbox.org.uk/2016/02/xbmc4xbox-3-5-3-is-out/" rel="external nofollow">February 2016</a> with version 3.5.3. Although the community never declared the project dead, meaningful updates became scarce. XBMC 4.0 continues that legacy by bringing a modern interface, updating it to be more inline with Kodi's modern codebase, and backporting features to the original 64MB RAM / Pentium-III hardware where it all began.
</p>

<p>
	This project is distinct and separate from <a href="https://github.com/Rocky5/XBMC4Gamers" rel="external nofollow">XBMC4Gamers</a>, the games-focused variation of XBMC4Xbox (v3.5.3) by developer Rocky5.
</p>

<h2>
	A Modern Interface Powered by Estuary
</h2>

<p>
	One of the most notable advancements in XBMC 4.0 is the introduction of the <strong>Estuary</strong> user interface (skin).
</p>

<p>
	Estuary, originally released in 2017 with Kodi v17 ("<a href="https://kodi.wiki/view/Archive:Kodi_v17_(Krypton)_changelog" rel="external nofollow">Krypton</a>"), provides a clean and modern layout that improves navigation and readability over past skins. Bringing Estuary to the Xbox required extensive updates to the underlying GUI framework, including a port of the more contemporary <em>GUIlib</em> engine. This allows the platform to support modern skinning standards and makes future skin ports much more straightforward. After the initial work of porting GUIlib was done, porting Estuary to the Xbox was a relatively simple process of tweaking a handful of configuration files and adding contextual features specific to the Xbox. The result is a modern, intuitive front end that retains the performance and responsiveness required on legacy hardware.
</p>

<p>
	Firing up an Xbox made in 2001 and being greeted by the same interface as what you'd find if you were to download Kodi today onto your PC feels like a bit of magic, and helps keep this beloved classic console relevant and useful well into the modern era.
</p>

<video controls="" data-video-embed="">
		<source type="video/mp4" data-video-src="https://www.xbox-scene.info/uploads/monthly_2025_11/XBMC-overview(1).mp4.29f8da2750ab41c36f1a525113b4a611.mp4"><a data-fileext="mp4" data-fileid="2242" href="https://www.xbox-scene.info/applications/core/interface/file/attachment.php?id=2242&amp;key=fad1aba1084372c0331238456b7ce8a9" rel="">XBMC-overview(1).mp4</a>
	</video>


<h2>
	Expanded Games Library Support
</h2>

<p>
	XBMC 4.0 introduces a fully realized games library system. This enhancement brings the same level of metadata support found in the Movies and Music sections to Xbox and emulated games. Titles can now display artwork, descriptions, and other metadata, transforming the games section into a polished and user-friendly library. XBMC’s longstanding support for trainers remains intact, giving users the option to apply gameplay modifications for compatible titles. Emulated game collections benefit as well, with the ability to browse ROM libraries and launch them directly in a user’s preferred emulator.
</p>

<p>
	<a data-fileext="png" data-fileid="2239" href="https://www.xbox-scene.info/uploads/monthly_2025_11/xbmc-games.png.832ea5b6856323ad43adf46b7965d6c0.png" rel=""><img alt="xbmc-games.thumb.png.15d95fa0ae488c06b61535bbe4450b84.png" data-fileid="2239" data-ratio="56.60" width="1000" data-src="https://www.xbox-scene.info/uploads/monthly_2025_11/xbmc-games.thumb.png.15d95fa0ae488c06b61535bbe4450b84.png" src="https://www.xbox-scene.info/applications/core/interface/js/spacer.png"></a>&nbsp;<a data-fileext="png" data-fileid="2238" href="https://www.xbox-scene.info/uploads/monthly_2025_11/xbmc-games2.png.1cd18c9321c93d4607f21fb1a415d1be.png" rel=""><img alt="xbmc-games2.thumb.png.2446d1967e49fc3c04c067b276122387.png" data-fileid="2238" data-ratio="56.60" width="1000" data-src="https://www.xbox-scene.info/uploads/monthly_2025_11/xbmc-games2.thumb.png.2446d1967e49fc3c04c067b276122387.png" src="https://www.xbox-scene.info/applications/core/interface/js/spacer.png"></a>&nbsp;<a data-fileext="jpg" data-fileid="2248" href="https://www.xbox-scene.info/uploads/monthly_2025_11/XBMC-emulators.jpg.6a7a4334b6729c10d329cafc1bd14a60.jpg" rel=""><img alt="XBMC-emulators.thumb.jpg.7257c8c9aba9c864cf1df933a0072201.jpg" data-fileid="2248" data-ratio="56.40" width="1000" data-src="https://www.xbox-scene.info/uploads/monthly_2025_11/XBMC-emulators.thumb.jpg.7257c8c9aba9c864cf1df933a0072201.jpg" src="https://www.xbox-scene.info/applications/core/interface/js/spacer.png"></a>
</p>

<h2>
	Online Scrapers and Metadata Support
</h2>

<p>
	XBMC 4.0 restores full functionality to metadata scrapers for movies and television. This allows users to build rich media libraries complete with artwork, plot summaries, cast listings, and other information retrieved directly from online sources. XBMC 4.0 handles these tasks efficiently, even on the Xbox’s limited memory and processing power. Video playback continues to support 480p and 720p content, enabling the console to serve as a surprisingly capable media device for its age. Similar to Kodi, XBMC 4.0 supports filtering, building playlists, watch progress history for media, and intelligent handling of TV shows with seasons.
</p>

<video controls="" data-video-embed="">
		<source type="video/mp4" data-video-src="https://www.xbox-scene.info/uploads/monthly_2025_11/XBMC-Videos-Demo.mp4.0936a52a21eb4f9cf78f8aa93f1a1f8a.mp4"><a data-fileext="mp4" data-fileid="2241" href="https://www.xbox-scene.info/applications/core/interface/file/attachment.php?id=2241&amp;key=49aa88211941b267f205ebe904748b23" rel="">XBMC-Videos-Demo.mp4</a>
	</video>


<p>
	Aside from scrapers for multimedia, support for rich library capabilities for games has also been added. XBMC has always been a media-first app, and now users can enjoy the library experience that they've come to love for media now in the context of their games library <em>(more info below)</em>.
</p>

<h2>
	Improved Task Scheduling and Multitasking
</h2>

<p>
	Despite the constraints of the Xbox’s single-threaded 733MHz CPU, XBMC 4.0 includes improvements to task scheduling that allow multiple activities to run concurrently. Background library updates, metadata scraping, and audio/video playback can occur while users navigate and use other parts of the interface. These optimizations help ensure a fluid experience without compromising performance. Much work has been done "under the hood" to keep XBMC on task and within memory budgets while achieving multi-tasking on a console that wasn't exactly designed with it in mind. Users who own RAM and/or CPU upgraded consoles can also take advantage of the extra overhead, as XBMC 4.0 makes use of the extra horsepower for an even smoother experience. Utilizing an SSD with higher UDMA speeds will also yield an improvement in overall responsiveness.
</p>

<h2>
	Music Experience and Visualizers
</h2>

<p>
	Music playback has always been a strong element of XBMC, and version 4.0 maintains that focus. The Original Xbox is capable of high quality audio output, and XBMC continues to support lossless codecs such as FLAC. The release includes compatibility with various audio visualizers, including MilkDrop, which remains one of the most visually impressive and customizable audio visualization engines available. These features allow XBMC 4.0 to function not only as a media organizer, but also as an immersive audio display system.
</p>

<p>
	An online repository has been established and will be maintained moving forward where users can download legacy and newly-released&nbsp;add-ons as they become available. This repository is&nbsp;accessible without additional setup, right out of the box!
</p>

<p>
	<a data-fileext="jpg" data-fileid="2243" href="https://www.xbox-scene.info/uploads/monthly_2025_11/XBMC-music.jpg.c304f3be158479bd160908308db9e0ed.jpg" rel=""><img alt="XBMC-music.thumb.jpg.3f4ed355dc9f3ed04db5aa577df654e6.jpg" data-fileid="2243" data-ratio="56.40" width="1000" data-src="https://www.xbox-scene.info/uploads/monthly_2025_11/XBMC-music.thumb.jpg.3f4ed355dc9f3ed04db5aa577df654e6.jpg" src="https://www.xbox-scene.info/applications/core/interface/js/spacer.png"></a>&nbsp;<a data-fileext="jpg" data-fileid="2244" href="https://www.xbox-scene.info/uploads/monthly_2025_11/XBMC-music2.jpg.0472050e0f3ce038a5751aedbe02e065.jpg" rel=""><img alt="XBMC-music2.thumb.jpg.256c38a610650ca49cddef1d5c6017a7.jpg" data-fileid="2244" data-ratio="56.40" width="1000" data-src="https://www.xbox-scene.info/uploads/monthly_2025_11/XBMC-music2.thumb.jpg.256c38a610650ca49cddef1d5c6017a7.jpg" src="https://www.xbox-scene.info/applications/core/interface/js/spacer.png"></a>&nbsp;<a data-fileext="jpg" data-fileid="2245" href="https://www.xbox-scene.info/uploads/monthly_2025_11/XBMC-music3.jpg.8d3c60493e80903644f9b4b51464e8c0.jpg" rel=""><img alt="XBMC-music3.thumb.jpg.fc6de207e86f9123f0e49d31c57b4f14.jpg" data-fileid="2245" data-ratio="56.40" width="1000" data-src="https://www.xbox-scene.info/uploads/monthly_2025_11/XBMC-music3.thumb.jpg.fc6de207e86f9123f0e49d31c57b4f14.jpg" src="https://www.xbox-scene.info/applications/core/interface/js/spacer.png"></a>
</p>

<h2>
	Add-ons and Python Support
</h2>

<p>
	XBMC 4.0 continues to offer an extendable architecture powered by Python-based add-ons. While the current release uses Python 2.7 for compatibility, work is underway to transition to Python 3.4.10 in the future, which may provide a path for backporting many newer Kodi add-ons. Even in its current state, XBMC 4.0 already supports a variety of community-developed add-ons that extend the system’s functionality, including tools for online video playback (i.e. YouTube), online weather services, and enhanced media organization.
</p>

<p>
	<a data-fileext="jpg" data-fileid="2247" href="https://www.xbox-scene.info/uploads/monthly_2025_11/XBMC-addons-youtube.jpg.988ff74c9730614473d528ee8e419a40.jpg" rel=""><img alt="XBMC-addons-youtube.thumb.jpg.42ee3ef857ee34dd8ac8c74a1090dfb9.jpg" data-fileid="2247" data-ratio="56.40" width="1000" data-src="https://www.xbox-scene.info/uploads/monthly_2025_11/XBMC-addons-youtube.thumb.jpg.42ee3ef857ee34dd8ac8c74a1090dfb9.jpg" src="https://www.xbox-scene.info/applications/core/interface/js/spacer.png">&nbsp;</a><a data-fileext="jpg" data-fileid="2246" href="https://www.xbox-scene.info/uploads/monthly_2025_11/XBMC-addons-weather.jpg.ef6fb42b52e1f0b899a271f125086b4a.jpg" rel=""><img alt="XBMC-addons-weather.thumb.jpg.f347831366e1612b9b71dcde644a58c7.jpg" data-fileid="2246" data-ratio="56.40" width="1000" data-src="https://www.xbox-scene.info/uploads/monthly_2025_11/XBMC-addons-weather.thumb.jpg.f347831366e1612b9b71dcde644a58c7.jpg" src="https://www.xbox-scene.info/applications/core/interface/js/spacer.png"></a>
</p>

<h2>
	Updated Settings, Network Services, and System Tools
</h2>

<p>
	The settings interface has been revised to provide more clarity and control. The update includes:
</p>

<ul>
	<li>
		<p>
			Playback options, including episode progression, crossfade behavior, and subtitle handling
		</p>
	</li>
	<li>
		<p>
			Library management tools
		</p>
	</li>
	<li>
		<p>
			Network features, such as SMB, FTP, UPnP sharing, web server access, and Insignia-compatible DNS options
		</p>
	</li>
	<li>
		<p>
			Comprehensive interface customization options
		</p>
	</li>
	<li>
		<p>
			Multiple user profiles with individual library settings
		</p>
	</li>
	<li>
		<p>
			Advanced system controls for video calibration, display modes, input devices, and power management
		</p>
	</li>
	<li>
		<p>
			A robust System Information section for diagnostics, with info geared towards the Original Xbox
		</p>
	</li>
	<li>
		<p>
			A flexible File Manager with support for network protocols including FTP, SMB, WebDAV, and more
		</p>
	</li>
</ul>

<p>
	Users may also take advantage of an online add-ons repository, offering the same experience modern Kodi provides with being able to download add-ons to extend functionality of the app with things like online multimedia providers, weather, skins, visualizers, and more. Developers can submit new add-ons to the official repository via <a href="https://github.com/xbmc4xbox/xbmc4xbox.github.io" rel="external nofollow">Github</a>.
</p>

<h2>
	Continuing the Legacy
</h2>

<p>
	XBMC has been a staple of the Original Xbox's homebrew scene since its inception in the early 2000's. This new update is a revival of the platform that helped shape the landscape of home media software and helps revitalize a codebase that has been somewhat stagnant for many years. This release honors that heritage while modernizing the experience for a new generation of enthusiasts and preserving the functionality of the Original Xbox as a versatile and capable media center.
</p>

<p>
	Although the hardware is decades old, the renewed effort behind XBMC 4.0 demonstrates that the platform still has room to grow and tricks up its sleeve. With ongoing development and a codebase designed with modern Kodi compatibility in mind, XBMC 4.0 represents a significant step forward into the continued development on the Original Xbox.
</p>

<p>
	The development team looks forward to continuing this work and expanding the possibilities of the Original Xbox for years to come. This version is the first of many to come, with lots of things cooking in the background. Keep an eye out for future releases by joining the <strong><a href="https://www.xbox-scene.info/discord/invite/XboxScene/" rel="">Xbox-Scene Discord</a></strong> and turning on notifications in the <strong><a href="https://discord.com/channels/770816616937160745/1440261544276394075" rel="external nofollow">xbmc-news</a></strong> channel or by periodically checking the project's Github page.
</p>

<h2>
	Downloads
</h2>

<p>
	XBMC 4.0 (and subsequent releases) builds along with source code are available via Github:
</p>

<p>
	<span><a href="https://github.com/antonic901/xbmc4xbox-redux/releases/tag/nightly" rel="external nofollow">Download XBMC 4.0</a></span>
</p>

<p>
	Main project page:&nbsp;<em><a href="https://github.com/antonic901/xbmc4xbox-redux" rel="external nofollow">Click Here</a></em>
</p>

<p>
	<em>Note: XBMC 4.0 is is in active development! This means updates will be released in a more frequent manner for the time being until things settle down. Check the nightly builds section on Github for the most up-to-date version.</em>
</p>

<h2>
	Contributions
</h2>

<p>
	XBMC is open source software and welcomes contributions.
</p>

<ul>
	<li>
		<strong>Coding:</strong> Developers can help XBMC by <strong><a href="https://github.com/antonic901/xbmc4xbox-redux/issues" rel="external nofollow">fixing a bug</a></strong>, adding new features, making our technology smaller and faster and making development easier for others. XBMC's codebase consists mainly of C++ with small parts written in a variety of coding languages. Our add-ons mainly consist of python and XML.
	</li>
	<li>
		<strong>Helping users:</strong> Our support process relies on enthusiastic contributors like you to help others get the most out of XBMC. The #1 priority is always answering questions in our <strong><a href="https://discord.com/channels/770816616937160745/1050581194401652736" rel="external nofollow">support forums</a></strong>. Everyday new people discover XBMC, and everyday they are virtually guaranteed to have questions.
	</li>
	<li>
		<strong>Localization:</strong> Translate <strong>XBMC</strong>, <strong>add-ons, skins etc.</strong> into your native language.
	</li>
	<li>
		<strong>Add-ons:</strong> <strong>Add-ons</strong> are what make XBMC the most extensible and customizable entertainment hub available. <strong><a href="https://kodi.tv/create-an-addon" rel="external nofollow">Get started building an add-on</a></strong>.
	</li>
</ul>

<h2>
	Support and Bug Reporting
</h2>

<p>
	Need help?
</p>

<p>
	Support can be found in the <a href="https://discord.com/channels/770816616937160745/1050581194401652736" rel="external nofollow">XBMC -&gt; General</a> channel within the <a href="https://discord.gg/VcdSfajQGK" rel="external nofollow">Xbox-Scene Discord server</a>.
</p>

<h2>
	Credits and Disclaimers
</h2>

<ul>
	<li>
		<strong>Nikola Antonić</strong> -&nbsp;Primary Developer, Project Lead
	</li>
	<li>
		<strong>astarivi</strong> -&nbsp;Contributor&nbsp;(cURL, wolfSSL), Tester, Debugger
	</li>
	<li>
		<strong>EqUiNoX</strong> - Contrubitor, Tester
	</li>
	<li>
		<strong>Rocky5</strong> - Contributor, Tester
	</li>
	<li>
		<strong>.lavenderStarlight+</strong> -&nbsp;Add-ons / Skins Development, Tester
	</li>
	<li>
		<strong>GoTeamScotch</strong> - Tester, Feedback
	</li>
	<li>
		<strong>Haguero</strong> - Tester, Feedback
	</li>
</ul>



<p>
	XBMC is <strong>GPLv2 licensed</strong>. You may use, distribute and copy it under the license terms.&nbsp;XBMC is licensed under the same terms as Kodi. For detailed information on the licensing, please refer to the <a href="https://github.com/xbmc/xbmc/tree/master/LICENSES#kodis-licensing-rules" rel="external nofollow">Kodi license</a>.
</p>

<p>
	This project, XBMC version 4.0 (and upcoming releases), is distinct from and is not affiliated with Team Kodi of The Kodi Foundation, or its members.&nbsp;
</p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We should all be using dependency cooldowns (244 pts)]]></title>
            <link>https://blog.yossarian.net/2025/11/21/We-should-all-be-using-dependency-cooldowns</link>
            <guid>46005111</guid>
            <pubDate>Fri, 21 Nov 2025 14:50:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.yossarian.net/2025/11/21/We-should-all-be-using-dependency-cooldowns">https://blog.yossarian.net/2025/11/21/We-should-all-be-using-dependency-cooldowns</a>, See on <a href="https://news.ycombinator.com/item?id=46005111">Hacker News</a></p>
<div id="readability-page-1" class="page">

<h2>ENOSUCHBLOG</h2>
<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/series">Series</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
    <li><a href="https://yossarian.net/">Main Site</a></li>
    <li><a href="https://yossarian.net/til">TILs</a></li>
    
</ul>

<hr>



<h2>
  <p>
    <span><em>Nov 21, 2025</em></span>

    &nbsp; &nbsp;

    
      <span>
        Tags:
        
        
          <a href="https://blog.yossarian.net/tags#oss">oss</a>,
        
          <a href="https://blog.yossarian.net/tags#security">security</a>
        
      </span>
    

    &nbsp; &nbsp;

    
  </p>
</h2>






<hr>


<p><strong>TL;DR</strong>: Dependency cooldowns are a free, easy, and <strong>incredibly effective</strong>
way to mitigate the <em>large majority</em> of open source supply chain attacks.
More individual projects should apply cooldowns (via tools like Dependabot
and Renovate) to their dependencies, and packaging ecosystems should invest
in first-class support for cooldowns directly in their package managers.</p>

<hr>

<p>“Supply chain security” is a serious problem. It’s also <strong>seriously overhyped</strong>,
in part because dozens of vendors have a vested financial interest in
convincing your that their <em>framing</em> of the underlying problem<sup id="fnref:problem"><a href="#fn:problem" rel="footnote" role="doc-noteref">1</a></sup> is (1)
correct, and (2) worth your money.</p>

<p>What’s consternating about this is that most open source supply chain
attacks have the same basic structure:</p>

<ol>
  <li>
    <p>An attacker compromises a popular open source project, typically via
a stolen credential or CI/CD vulnerabilty (such as <a href="https://securitylab.github.com/resources/github-actions-preventing-pwn-requests/">“pwn requests”</a> in
GitHub Actions).</p>
  </li>
  <li>
    <p>The attacker introduces a malicious change to the project and uploads
it somewhere that will have <strong>maximum effect</strong> (PyPI, npm, GitHub releases,
&amp;c., depending on the target).</p>

    <p>At this point, the <em>clock has started</em>, as the attacker has moved
 into the public.</p>
  </li>
  <li>
    <p>Users pick up the compromised version of the project via automatic
dependency updates or a lack of dependency pinning.</p>
  </li>
  <li>
    <p>Meanwhile, the aforementioned vendors are scanning public indices
as well as customer repositories for signs of compromise, and
provide alerts upstream (e.g. to PyPI).</p>

    <p>Notably, vendors are <em>incentivized</em> to report quickly and loudly upstream,
 as this increases the perceived value of their services in a crowded
 field.</p>
  </li>
  <li>
    <p>Upstreams (PyPI, npm, &amp;c.) remove or disable the compromised package
version(s).</p>
  </li>
  <li>
    <p>End-user remediation begins.</p>
  </li>
</ol>

<p>The key thing to observe is that the gap between (1) and (2) can be very large<sup id="fnref:gap"><a href="#fn:gap" rel="footnote" role="doc-noteref">2</a></sup>
(weeks or months), while the gap between (2) and (5) is <strong>typically very small</strong>:
hours or days. This means that, once the attacker has moved into the actual
exploitation phase, their <em>window of opportunity</em> to cause damage is pretty limited.</p>

<p><img src="https://blog.yossarian.net/assets/supply-chain-attack-timeline.png" alt="Figure: a not very scientific visualization of the phases above."></p>

<p>We can see this with numerous prominent supply chain attacks over the last 18 months<sup id="fnref:filippo"><a href="#fn:filippo" rel="footnote" role="doc-noteref">3</a></sup>:</p>

<table>
  <thead>
    <tr>
      <th>Attack</th>
      <th>Approx. Window of Opportunity</th>
      <th>References</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>xz-utils</td>
      <td>≈ 5 weeks<sup id="fnref:outlier"><a href="#fn:outlier" rel="footnote" role="doc-noteref">4</a></sup></td>
      <td><a href="https://research.swtch.com/xz-timeline">Source</a></td>
    </tr>
    <tr>
      <td>Ultralytics (phase 1)</td>
      <td>12 hours</td>
      <td><a href="https://blog.yossarian.net/2024/12/06/zizmor-ultralytics-injection#appendix-rough-timeline-of-events">Source</a></td>
    </tr>
    <tr>
      <td>Ultralytics (phase 2)</td>
      <td>1 hour</td>
      <td><a href="https://blog.yossarian.net/2024/12/06/zizmor-ultralytics-injection#appendix-rough-timeline-of-events">Source</a></td>
    </tr>
    <tr>
      <td>tj-actions</td>
      <td>3 days</td>
      <td><a href="https://www.legitsecurity.com/blog/github-actions-tj-actions-changed-files-attack">Source</a></td>
    </tr>
    <tr>
      <td>chalk</td>
      <td>&lt; 12 hours</td>
      <td><a href="https://cycode.com/blog/npm-debug-chalk-supply-chain-attack-the-complete-guide/">Source</a></td>
    </tr>
    <tr>
      <td>Nx</td>
      <td>4 hours</td>
      <td><a href="https://www.stepsecurity.io/blog/supply-chain-security-alert-popular-nx-build-system-package-compromised-with-data-stealing-malware">Source</a></td>
    </tr>
    <tr>
      <td>rspack</td>
      <td>1 hour</td>
      <td><a href="https://github.com/web-infra-dev/rspack/releases/tag/v1.1.8">Source</a></td>
    </tr>
    <tr>
      <td>num2words</td>
      <td>&lt; 12 hours</td>
      <td><a href="https://blog.pypi.org/posts/2025-07-31-incident-report-phishing-attack/#impact-analysis">Source</a></td>
    </tr>
    <tr>
      <td>Kong Ingress Controller</td>
      <td>≈ 10 days</td>
      <td><a href="https://konghq.com/blog/product-releases/december-2024-unauthorized-kong-ingress-controller-3-4-0-build">Source</a></td>
    </tr>
    <tr>
      <td>web3.js</td>
      <td>5 hours</td>
      <td><a href="https://threats.wiz.io/all-incidents/solana-web3js-supply-chain-attack">Source</a></td>
    </tr>
  </tbody>
</table>

<p>(Each of these attacks has significant downstream effect, of course, but only
<em>within</em> their window of opportunity. Subsequent compromises from each, like
<a href="https://www.wiz.io/blog/shai-hulud-npm-supply-chain-attack">Shai-Hulud</a>, represent <em>new</em> windows of opportunity where the attackers regrouped
and pivoted onto the <em>next</em> set of compromised credentials.)</p>

<p>My takeaway from this: some windows of opportunity are bigger, but the <em>majority</em>
of them are under a week long. Consequently, ordinary developers can <em>avoid
the bulk</em> of these types of attacks by instituting <strong>cooldowns</strong> on their dependencies.</p>

<h2 id="cooldowns">Cooldowns</h2>

<p>A “cooldown” is exactly what it sounds like: a window of time between when a dependency
is published and when it’s considered suitable for use. The dependency is public during
this window, meaning that “supply chain security” vendors can work their magic
while the rest of us wait any problems out.</p>

<p>I <strong>love</strong> cooldowns for several reasons:</p>

<ul>
  <li>
    <p>They’re empirically effective, per above. They won’t stop <em>all</em> attackers,
but they <em>do</em> stymie the majority of high-visibiity, mass-impact supply chain
attacks that have become more common.</p>
  </li>
  <li>
    <p>They’re <em>incredibly</em> easy to implement. Moreover, they’re <strong>literally free</strong>
to implement in most cases: most people can use <a href="https://docs.github.com/en/code-security/dependabot/working-with-dependabot/dependabot-options-reference#cooldown-">Dependabot’s functionality</a>,
<a href="https://docs.renovatebot.com/key-concepts/minimum-release-age/">Renovate’s functionality</a>, or the functionality build directly into their
package manager<sup id="fnref:pkgmanager"><a href="#fn:pkgmanager" rel="footnote" role="doc-noteref">5</a></sup>.</p>

    <p>This is how simple it is in Dependabot:</p>

    <div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
</pre></td><td><pre>  <span>version</span><span>:</span> <span>2</span>

  <span># update once a week, with a 7-day cooldown</span>
  <span>-</span> <span>package-ecosystem</span><span>:</span> <span>github-actions</span>
    <span>directory</span><span>:</span> <span>/</span>
    <span>schedule</span><span>:</span>
      <span>interval</span><span>:</span> <span>weekly</span>
    <span>cooldown</span><span>:</span>
      <span>default-days</span><span>:</span> <span>7</span>
</pre></td></tr></tbody></table></code></pre></div>

    <p>(Rinse and repeat for other ecosystems as needed.)</p>
  </li>
  <li>
    <p>Cooldowns <strong>enforce positive behavior</strong> from supply chain security vendors:
vendors are still incentivized to discover and report attacks quickly,
but are <em>not</em> as incentivized to emit volumes of blogspam about “critical”
attacks on largely underfunded open source ecosystems.</p>
  </li>
</ul>

<h2 id="concluding--assorted-thoughts">Concluding / assorted thoughts</h2>

<p>In the very small sample set above, 8/10 attacks had windows of opportunity
of less than a week. Setting a cooldown of 7 days would have prevented
the vast majority of these attacks from reaching end users (and causing
knock-on attacks, which several of these were). Increasing the cooldown to 14
days would have prevented all but 1 of these attacks<sup id="fnref:apt"><a href="#fn:apt" rel="footnote" role="doc-noteref">6</a></sup>.</p>

<p>Cooldowns are, obviously, <strong>not a panacea</strong>: some attackers <em>will</em> evade detection,
and delaying the inclusion of potentially malicious dependencies by a week
(or two) does not fundamentally alter the fact that supply chain security is a
<em>social trust</em> problem, not a purely technical one. Still, an 80-90% reduction
in exposure through a technique that is free and easy seems hard to beat.</p>

<p>Related to the above, it’s unfortunate that cooldowns aren’t baked <em>directly</em>
into more packaging ecosystems: Dependabot and Renovate are great, but
<em>even better</em> would be if the package manager itself (as the source of ground
truth) could enforce cooldowns directly (including of dependencies not
introduced or bumped through automated flows).</p>

<hr>




<hr>




  






</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Making a Small RPG (153 pts)]]></title>
            <link>https://jslegenddev.substack.com/p/making-a-small-rpg</link>
            <guid>46004293</guid>
            <pubDate>Fri, 21 Nov 2025 13:23:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jslegenddev.substack.com/p/making-a-small-rpg">https://jslegenddev.substack.com/p/making-a-small-rpg</a>, See on <a href="https://news.ycombinator.com/item?id=46004293">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!663W!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8702120-a5b9-49b7-abe5-6c9b2e337e82_1920x1080.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!663W!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8702120-a5b9-49b7-abe5-6c9b2e337e82_1920x1080.png 424w, https://substackcdn.com/image/fetch/$s_!663W!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8702120-a5b9-49b7-abe5-6c9b2e337e82_1920x1080.png 848w, https://substackcdn.com/image/fetch/$s_!663W!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8702120-a5b9-49b7-abe5-6c9b2e337e82_1920x1080.png 1272w, https://substackcdn.com/image/fetch/$s_!663W!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8702120-a5b9-49b7-abe5-6c9b2e337e82_1920x1080.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!663W!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8702120-a5b9-49b7-abe5-6c9b2e337e82_1920x1080.png" width="1456" height="819" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f8702120-a5b9-49b7-abe5-6c9b2e337e82_1920x1080.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:136323,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://jslegenddev.substack.com/i/178016908?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8702120-a5b9-49b7-abe5-6c9b2e337e82_1920x1080.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!663W!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8702120-a5b9-49b7-abe5-6c9b2e337e82_1920x1080.png 424w, https://substackcdn.com/image/fetch/$s_!663W!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8702120-a5b9-49b7-abe5-6c9b2e337e82_1920x1080.png 848w, https://substackcdn.com/image/fetch/$s_!663W!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8702120-a5b9-49b7-abe5-6c9b2e337e82_1920x1080.png 1272w, https://substackcdn.com/image/fetch/$s_!663W!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff8702120-a5b9-49b7-abe5-6c9b2e337e82_1920x1080.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>I’ve always wanted to try my hand making an RPG but always assumed it would take too much time.</p><p>However, I didn’t want to give up before trying so I started to think of ways I could still make something compelling in 1-2 months.</p><p>To help me come up with something, I decided to look into older RPGs as I had a hunch they could teach me a lot about scoping because back in the 80s, games were small because of technical limitations. A game that particularly caught my attention was the first Dragon Quest. </p><p>This game was very important because it popularized the RPG genre in Japan by simplifying the formula therefore, making it more accessible. It can be considered the father of the JRPG sub-genre.</p><p>What caught my attention was the simplicity of the game. There were no party members, the battle system was turn based and simple and you were free to just explore around.</p><p>I was particularly surprised by how the game could give a sense of exploration while the map was technically very small. This was achieved by making the player move on an overworld map with a different scale proportion compared to when navigating towns and points of interest. In the overworld section, the player appeared bigger while the geography was smaller, allowing players to cover large amounts of territory relatively quickly.</p><p>The advantage of this was that you could switch between biomes quickly without it feeling jarring. You still had the impression of traversing a large world despite being small in reality. This idea of using an overworld map was common in older games but somehow died off as devs had less and less technical limitations and more budget to work with. </p><p>Seeing its potential, I decided that I would include one in my project even if I didn’t have a clear vision at this point.</p><p>Playing Dragon Quest 1 also reminded me of how annoying random battle encounters were. You would take a few steps and get assaulted by an enemy of some kind. At the same time, this mechanic was needed, because grinding was necessary to be able to face stronger enemies in further zones of the map.</p><p>My solution : What if instead of getting assaulted, you were the one doing the assault? As you would move on the map, encounter opportunities signified by a star would appear. Only if you went there and overlapped with one would a battle start. This gave the player agency to determine if they needed to battle or not. This idea seemed so appealing that I knew I needed to include it in my project.</p><p><span>While my vision on what I wanted to make started to become clearer, I also started to get a sense of what I didn’t want to make. The idea of including a traditional turn based battle system was unappealing. That wasn’t because I hated this type of gameplay, but ever since </span><a href="https://www.youtube.com/watch?v=sX-sR0G8Alc" rel="">I made a 6 hour tutorial on how to build one</a><span>, I realized how complicated pulling one off is. Sure, you can get something basic quickly, but to actually make it engaging and well balanced is another story. A story that would exceed 1-2 months to deal with. I needed to opt for something more real-time and action based if I wanted to complete this project in a reasonable time frame.</span></p><p>Back in 2015, an RPG that would prove to be very influential released and “broke the internet”. It was impossible to avoid seeing the mention of Undertale online. It was absolutely everywhere.</p><p>The game received praised for a lot of different aspects but what held my attention, was its combat system.</p><p>It was the first game I was aware of, that included a section of combat dedicated to avoiding projectiles (otherwise known as bullet hell) in a turn based battle system. This made the combat more action oriented which translated into something very engaging and fun.</p><p>This type of gameplay left a strong impression in my mind and I thought that making something similar would be a better fit for my project as it was simpler to implement.</p><p>While learning about Dragon Quest 1, I couldn’t help but be reminded me of The Legend of Zelda Breath of The Wild released in 2017.</p><p>Similarly to Dragon Quest, a lot of freedom was granted to the player in how and when they tackled the game’s objectives.</p><p>For example, in Breath of The Wild, you could go straight to the final boss after the tutorial section.</p><p>I wanted to take this aspect of the game and incorporate it into my project. I felt it would be better to have one final boss and every other enemy encounter would be optional preparation you could engage with to get stronger. This felt like something that was achievable in a smaller scope compared to crafting a linear story the player would progress through.</p><p>Another game that inspired me was Elden Ring, an open world action RPG similar to Breath of The Wild in its world structure but with the DNA of Dark Souls, a trilogy of games made previously by the same developers.</p><p>What stuck with me regarding Elden Ring, for the purpose of my project, was its unique way it handled experience points. It was the first RPG I played that used them as a currency you could spend to level up different attributes making up your character or to buy items.</p><p>Taking inspiration from it, I decided that my project would feature individually upgradable stats and that experience points would act as a currency. The idea was that the player would gain an amount of the game’s currency after battle and use that to upgrade different attributes. Like in Elden Ring, if you died in combat you would lose all currency you were currently holding.</p><p>I needed a system like this for my project to count as an RPG. Since by definition an RPG is stats driven. A system like this would also allow the player to manage difficulty more easily and it would act as the progression system of my game.</p><p>When I started getting into game development, I quickly came across Pico-8.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!5_Wj!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46f6c70a-e5ba-44dd-9e26-5b2e049810f2_256x256.gif" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!5_Wj!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46f6c70a-e5ba-44dd-9e26-5b2e049810f2_256x256.gif 424w, https://substackcdn.com/image/fetch/$s_!5_Wj!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46f6c70a-e5ba-44dd-9e26-5b2e049810f2_256x256.gif 848w, https://substackcdn.com/image/fetch/$s_!5_Wj!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46f6c70a-e5ba-44dd-9e26-5b2e049810f2_256x256.gif 1272w, https://substackcdn.com/image/fetch/$s_!5_Wj!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46f6c70a-e5ba-44dd-9e26-5b2e049810f2_256x256.gif 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!5_Wj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46f6c70a-e5ba-44dd-9e26-5b2e049810f2_256x256.gif" width="320" height="320" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/46f6c70a-e5ba-44dd-9e26-5b2e049810f2_256x256.gif&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:256,&quot;width&quot;:256,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:506549,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/gif&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://jslegenddev.substack.com/i/178016908?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46f6c70a-e5ba-44dd-9e26-5b2e049810f2_256x256.gif&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!5_Wj!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46f6c70a-e5ba-44dd-9e26-5b2e049810f2_256x256.gif 424w, https://substackcdn.com/image/fetch/$s_!5_Wj!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46f6c70a-e5ba-44dd-9e26-5b2e049810f2_256x256.gif 848w, https://substackcdn.com/image/fetch/$s_!5_Wj!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46f6c70a-e5ba-44dd-9e26-5b2e049810f2_256x256.gif 1272w, https://substackcdn.com/image/fetch/$s_!5_Wj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46f6c70a-e5ba-44dd-9e26-5b2e049810f2_256x256.gif 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Pico-8, for those unaware, is a fantasy console with a set of limitations. It’s not a console you buy physically but rather a software program that runs on your computer (or in a web browser) that mimics an older console that never existed.</p><p>To put it simply, it was like running an emulator for a console that could’ve existed but never actually did. Hence the fantasy aspect of it.</p><p>Pico-8 includes everything you need to make games. It has a built-in code editor, sprite editor, map editor, sound editor, etc…</p><p>It uses the approachable Lua programming language which is similar to Python.</p><p>Since Pico-8 is limited, it’s easier to actually finish making a game rather than being caught in scope creep.</p><p>One game made in Pico-8 particularly caught my interest.</p><p><span>In this game you play as a little character on a grid. Your goal is to fight just one boss. To attack this boss, you need to step on a glowing tile while avoiding taking damage by incoming obstacles and projectiles thrown at you. </span><em><span>(</span><strong>Epilepsy Warning </strong><span>regarding the game footage below due to the usage of flashing bright colors.)</span></em></p><p>This game convinced me to ditch the turned based aspect I envisioned for my project entirely. Rather than having bullet hell sections within a turn based system like in Undertale the whole battle would instead be bullet hell. I could make the player attack without needing to have turns by making attack zones spawn within the battlefield. The player would then need to collide with them for an attack to register.</p><p>I was now convinced that I had something to stand on. It was now time to see if it would work in practice but I needed to clearly formulate my vision first.</p><p>The game I had in mind would take place under two main scenes. The first, was the overworld in which the player moved around and could engage in battle encounters, lore encounters, heal or upgrade their stats.</p><p>The second, being the battle scene, would be were battles would take place. The player would be represented by a cursor and they were expected to move around dodging incoming attacks while seeking to collide with attack zones to deal damage to the enemy.</p><p>The purpose of the game was to defeat a single final boss named king Donovan who was a tyrant ruling over the land of Hydralia where the game took place. At any point, the player could enter the castle to face the final boss immediately. However, most likely, the boss would be too strong.</p><p>To prepare, the player would roam around the world engaging in various battle encounters. Depending on where the encounter was triggered, a different enemy would show up that fitted the theme of the location they were in. The enemy’s difficulty and experience reward if beaten would drastically vary depending on the location.</p><p>Finally, the player could level up and heal in a village.</p><p>I was now ready to start programming the game and figuring out the details as I went along. For this purpose, I decided to write the game using the JavaScript programming language and the KAPLAY game library.</p><p>I chose these tools because they were what I was most familiar with.</p><p>For JavaScript, I knew the language before getting into game dev as I previously worked as a software developer for a company who’s product was a complex web application. While most of the code was in TypeScript, knowing JavaScript was pretty much necessary to work in TypeScript since the language is a superset of JavaScript.</p><p>As an aside, despite its flaws as a language, JavaScript is an extremely empowering language to know as a solo dev. You can make games, websites, web apps, browser extensions, desktop apps, mobile apps, server side apps, etc… with this one language. It’s like the English of programming languages. Not perfect, but highly useful in today’s world.</p><p>I’ll just caveat that using JavaScript makes sense for 2D games and light 3D games. For anything more advanced, you’d be better off using Unreal, Unity or Godot.</p><p>As for the KAPLAY game library, it allows me to make games quickly because it provides a lot of functionality out of the box. It’s also very easy to learn.</p><p>While it’s relatively easy to package a JavaScript game as an app that can be put on Steam, what about consoles? Well it’s not straightforward at all but at the same time, I don’t really care about consoles unless my game is a smash hit on Steam. If my game does become very successful than it would make sense businesswise to pay a porting company to remake the game for consoles, getting devkits, dealing with optimizations and all the complexity that comes with publishing a game on these platforms.</p><p>Anyway, to start off the game’s development, I decided to implement the battle scene first with all of its related mechanics as I needed to make sure the battle system I had in mind was fun to play in practice.</p><p>To also save time later down the line, I figured that I would make the game have a square aspect ratio. This would allow me to save time during asset creation, especially for the map as I wanted the whole map to be visible at once as I wouldn’t use a scrolling camera for this game.</p><p>After a while, I had a first “bare bones” version of the battle system. You could move around to avoid projectiles and attack the enemy by colliding with red attack zones.</p><p>Initially, I wanted the player to have many stats they could upgrade. They could upgrade their health (HP), speed, attack power and FP which stood for focus points.</p><p>However, I had to axe the FP stat as I originally wanted to use it as a way to introduce a cost to using items in battle. However, I gave up on the idea of making items entirely as they would require too much time to create and properly balance.</p><p>I also had the idea of adding a stamina mechanic similar to the one you see in Elden Ring. Moving around would consume stamina that could only replenish when you stopped moving. I initially though that this would result in fun gameplay as you could upgrade your stamina over time but it ended up being very tedious and useless. Therefore, I also ended up removing it.</p><p>Now that the battle system was mostly done, I decided to work on the world scene where the player could move around.</p><p>I first implemented battle encounters that would spawn randomly on the screen as red squares, I then created the upgrade system allowing the player to upgrade between 3 stats : Their health (HP), attack power and speed.</p><p>In this version of the game, the player could restore their health near where they could upgrade their stats.</p><p>While working on the world scene was the focus, I also made a tweak to the battle scene. Instead of displaying the current amount of health left as a fraction, I decided a health bar would be necessary because when engaged in a fast paced battle, the player does not have time to interpret fractions to determine the state of their health. A health bar would convey the info faster in this context.</p><p>However, I quickly noticed an issue with how health was restored in my game. Since the world was constrained to a single screen, it made going back to the center to get healed after every fight the optimal way to play. This resulted in feeling obligated to go back to the center rather than freely roaming around.</p><p>To fix this issue, I made it so the player needed to pay to heal using the same currency for leveling up. Now you needed to carefully balance between healing or saving your experience currency for an upgrade by continuing to explore/engage in battle. All of this while keeping in mind that you could lose all of your currency if defeated in battle. It’s important to note that you could also heal partially which provided flexibility in how the player managed the currency resource.</p><p>Now that I was satisfied with the “bare bones” state of the game, I needed to make nice looking graphics.</p><p>To achieve this, I decided to go with a pixel art style. I could spend a lot of time explaining how to make good pixel art but, I already did so previously. I recommend checking my post on the topic.</p><div data-component-name="DigestPostEmbed"><a href="https://jslegenddev.substack.com/p/5-pixel-art-tips-for-programmers-3d6" rel="noopener" target="_blank"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!iTWI!,w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82344f0c-7d73-433e-99ba-f60e4881ee20_1920x1080.png"><img src="https://substackcdn.com/image/fetch/$s_!iTWI!,w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82344f0c-7d73-433e-99ba-f60e4881ee20_1920x1080.png" sizes="100vw" alt="5 Pixel Art Tips for Programmers" width="140" height="140"></picture></div></a></div><p>I started by putting a lot effort drawing the overworld map as the player would spend a lot of time in it. It was a this stage that I decided to make villages the places where you would heal or level up.</p><p>To make this clearer, I added icons on top of each village to make it obvious what each was for.</p><p>Now that I was satisfied with how the map turned out, I started designing and implementing the player character.</p><p>For each distinct zone of the map, I added a collider so that battle encounters could determine which enemy and what background to display during battle. It was at this point that I made encounters appear as flashing stars on the map.</p><p>Since my work on the overworld was done, I now needed to produce a variety of battle backgrounds to really immerse the player in the world. I sat down and locked in. These were by far one of the most time intensive art assets to make for this project but I’m happy with the results.</p><p>After finishing making all backgrounds, I implemented the logic to show them in battle according to the zone where the encounter occurred.</p><p>The next assets to make were enemies. This was another time intensive task but I’m happy with how they turned out. The character at the bottom left is king Donovan the main antagonist of the game.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!DQ9a!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2516f24b-b123-4e61-ac31-e30303ffa315_2220x1530.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!DQ9a!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2516f24b-b123-4e61-ac31-e30303ffa315_2220x1530.png 424w, https://substackcdn.com/image/fetch/$s_!DQ9a!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2516f24b-b123-4e61-ac31-e30303ffa315_2220x1530.png 848w, https://substackcdn.com/image/fetch/$s_!DQ9a!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2516f24b-b123-4e61-ac31-e30303ffa315_2220x1530.png 1272w, https://substackcdn.com/image/fetch/$s_!DQ9a!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2516f24b-b123-4e61-ac31-e30303ffa315_2220x1530.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!DQ9a!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2516f24b-b123-4e61-ac31-e30303ffa315_2220x1530.png" width="1456" height="1003" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2516f24b-b123-4e61-ac31-e30303ffa315_2220x1530.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1003,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:391439,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://jslegenddev.substack.com/i/178016908?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2516f24b-b123-4e61-ac31-e30303ffa315_2220x1530.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!DQ9a!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2516f24b-b123-4e61-ac31-e30303ffa315_2220x1530.png 424w, https://substackcdn.com/image/fetch/$s_!DQ9a!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2516f24b-b123-4e61-ac31-e30303ffa315_2220x1530.png 848w, https://substackcdn.com/image/fetch/$s_!DQ9a!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2516f24b-b123-4e61-ac31-e30303ffa315_2220x1530.png 1272w, https://substackcdn.com/image/fetch/$s_!DQ9a!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2516f24b-b123-4e61-ac31-e30303ffa315_2220x1530.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>While developing the game, I noticed that it took too much time to go from one end of the battle zone to the other. This made the gameplay tedious so I decided to make the battle zone smaller.</p><p>At this point, I also changed the player cursor to be diamond shaped and red rather than a circle and white. I also decided to use the same flashing star sprite used for encounters on the map but this time, for attack zones. I also decided to change the font used in the game to something better.</p><p>At this point, the projectiles thrown towards the player didn’t move in a cohesive pattern the player could learn over time.</p><p>It was also absolutely necessary to create a system in which the attack patterns of the enemy would be progressively shown to the player. </p><p>This is why I stopped everything to work on the enemy’s attack pattern. I also, by the same token, started to add effects to make the battle more engaging and sprites for the projectiles.</p><p>While the game was coming along nicely, I started to experience performance issues. I go into more detail in a previous post if you’re interested.</p><div data-component-name="DigestPostEmbed"><a href="https://jslegenddev.substack.com/p/what-caused-performance-issues-in" rel="noopener" target="_blank"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Jgsb!,w_140,h_140,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa12d7eda-0c44-4c5f-98dd-b0aa820f9e04_1746x1738.png"><img src="https://substackcdn.com/image/fetch/$s_!Jgsb!,w_140,h_140,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa12d7eda-0c44-4c5f-98dd-b0aa820f9e04_1746x1738.png" sizes="100vw" alt="What Caused Performance Issues in My Small RPG" width="140" height="140"></picture></div></a></div><p>To add another layer of depth to my game, I decided that the reward you got from a specific enemy encounter would not only depend on which enemy you were fighting but also how much damage you took.</p><p>For example, if a basic enemy in the Hydralia field would give you a reward of a 100 after battle, you would actually get less unless you did not take damage during that battle.</p><p>This was to encourage careful dodging of projectiles and to reward players who learned the enemy pattern thoroughly. This would also add replayability as there was now a purpose to fight the same enemy over and over again.</p><p>The formula I used to determine the final reward granted can be described as follows :</p><pre><code>finalReward = baseReward * currentHp/hpBeforeBattle</code></pre><p>At this point, it wasn’t well communicated to the player how much of the base reward they were granted after battle. That’s why I added the “Excellence” indication.</p><p>When beating an enemy, if done without taking damage, instead of having the usual “Foe Vanquished” message appearing on the screen, you would get a “Foe Vanquised With Excellence” message in bright Yellow.</p><p>In addition to being able to enter into battle encounters, I wanted the player to have lore/tips encounters. Using the same system, I would randomly spawn a flashing star of a blueish-white color. If the player overlapped with it, a dialogue box would appear telling them some lore/tips related to the location they were in. Sometimes, these encounters would result in a chest containing exp currency reward. This was to give a reason for the player to pursue these encounters.</p><p>This is still a work in progress, as I haven’t decided what kind of lore to express through these.</p><p>One thing I forgot to show earlier was how I revamped the menu to use the new font.</p><p>That’s all I have to share for now. What do you think? </p><p><span>I also think it’s a good time to ask for advice regarding the game’s title. Since the game takes place in a land named </span><em>Hydralia</em><span>. I thought about using the same name for the game. However, since your mission is to defeat a tyrant king named Donovan, maybe a title like </span><em>Hydralia : Donovan’s Demise</em><span> would be a better fit.</span></p><p>If you have any ideas regarding naming, feel free to leave a comment! </p><p>Anyway, if you want to keep up with the game’s development or are more generally interested in game development, I recommend subscribing to not miss out on future posts.</p><p>In the meantime, you can read the following :</p><div data-component-name="DigestPostEmbed"><a href="https://jslegenddev.substack.com/p/you-can-now-make-ps2-games-in-javascript" rel="noopener" target="_blank"><h2>You Can Now Make PS2 Games in JavaScript</h2></a><div><div><a href="https://jslegenddev.substack.com/p/you-can-now-make-ps2-games-in-javascript" rel="noopener" target="_blank"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!HWto!,w_280,h_280,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c2b3cdb-3a39-465f-900e-5dca9eabf54d_1920x1080.png"><img src="https://substackcdn.com/image/fetch/$s_!HWto!,w_280,h_280,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3c2b3cdb-3a39-465f-900e-5dca9eabf54d_1920x1080.png" sizes="100vw" alt="You Can Now Make PS2 Games in JavaScript" width="280" height="280"></picture></a></div><div><p>I recently discovered that you could make PS2 games in JavaScript. I’m not even kidding, it’s actually possible. I was working on a project and had my phone near my desk when I received a notification. Upon further inspection, it came from itch.io which was a platform where I usually published most of my web games.</p></div></div></div><div data-component-name="DigestPostEmbed"><a href="https://jslegenddev.substack.com/p/export-web-games-for-desktop-in-one" rel="noopener" target="_blank"><h2>Export Web Games for Desktop in One Click </h2></a><div><div><a href="https://jslegenddev.substack.com/p/export-web-games-for-desktop-in-one" rel="noopener" target="_blank"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!6vgu!,w_280,h_280,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbabc4dee-5617-491e-b2e9-881fafc59df7_1920x1080.png"><img src="https://substackcdn.com/image/fetch/$s_!6vgu!,w_280,h_280,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbabc4dee-5617-491e-b2e9-881fafc59df7_1920x1080.png" sizes="100vw" alt="Export Web Games for Desktop in One Click " width="280" height="280"></picture></a></div><div><p>In a previous post, I tackled the various options one could use to make their web games playable offline as installable desktop apps. This would enable using web technologies to make games that could be sold on a platform like Steam.</p></div></div></div></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How a French judge was digitally cut off by the USA (372 pts)]]></title>
            <link>https://www.heise.de/en/news/How-a-French-judge-was-digitally-cut-off-by-the-USA-11087561.html</link>
            <guid>46003778</guid>
            <pubDate>Fri, 21 Nov 2025 12:12:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.heise.de/en/news/How-a-French-judge-was-digitally-cut-off-by-the-USA-11087561.html">https://www.heise.de/en/news/How-a-French-judge-was-digitally-cut-off-by-the-USA-11087561.html</a>, See on <a href="https://news.ycombinator.com/item?id=46003778">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

        

        <p>Digital sovereignty has been much discussed in Europe in recent weeks, most recently <a href="https://www.heise.de/news/Souveraenitaetsgipfel-Merz-und-Macron-proben-den-Schulterschluss-11083979.html?from-en=1">during a German-French summit in Berlin</a>. The extent of dependence on the USA in the digital sector is currently being experienced by a French judge. Nicolas Guillou, one of six judges and three prosecutors of the International Criminal Court (ICC), was sanctioned by the USA in August. He described his current situation as a digital time travel back to the 1990s, before the internet age, in a recent interview.</p>
<!-- RSPEAK_STOP -->




  


<!-- RSPEAK_START -->

<p>The reason for the US sanctions are the arrest warrants against Israeli Prime Minister Benjamin Netanyahu and Defense Minister Yoav Gallant. They were indicted for war crimes and crimes against humanity in the context of the destruction of the Gaza Strip. The USA condemned this decision by the court, whereupon the US Treasury Department sanctioned six judges and three prosecutors.</p>
<h3 id="nav_digitally__0">Digitally excluded from almost everything</h3>
<p>In Guillou's daily life, this means that he is excluded from digital life and much of what is considered standard today, he told the <a href="https://www.lemonde.fr/international/article/2025/11/19/nicolas-guillou-juge-francais-de-la-cpi-sanctionne-par-les-etats-unis-face-aux-attaques-les-magistrats-de-la-cour-tiendront_6654016_3210.html" rel="external noopener" target="_blank">French newspaper Le Monde</a>. All his accounts with US companies such as Amazon, Airbnb, or PayPal were immediately closed by the providers. Online bookings, such as through Expedia, are immediately canceled, even if they concern hotels in France. Participation in e-commerce is also practically no longer possible for him, as US companies always play a role in one way or another, and they are strictly forbidden to enter into any trade relationship with sanctioned individuals.</p>
<!-- RSPEAK_STOP -->

  




<!-- RSPEAK_START -->

<p>He also describes the impact on participating in banking as drastic. Payment systems are blocked for him, as US companies like American Express, Visa, and Mastercard have a virtual monopoly in Europe. He also describes the rest of banking as severely restricted. For example, accounts with non-US banks have also been partially closed. Transactions in US dollars or via dollar conversions are forbidden to him.</p>
<h3 id="nav_judge_eu__1">Judge: EU should block sanctions</h3>
<p>Guillou's case shows how strong the USA's influence in the tech sector is and how few options he has to circumvent it. And this at a time when an account with a US tech company is considered a matter of course in more and more places.</p>
<!-- RSPEAK_STOP -->


  



  




<!-- RSPEAK_START -->

<p>The French judge advocates for Europe to gain more sovereignty in the digital and banking sectors. Without this sovereignty, the rule of law cannot be guaranteed, he warns. At the same time, he calls on the EU to activate <a href="https://eur-lex.europa.eu/legal-content/DE/TXT/HTML/?uri=CELEX:31996R2271" rel="external noopener" target="_blank">an existing blocking regulation </a>(Regulation (EC) No 2271/96) for the International Criminal Court, which prevents third countries like the USA from enforcing sanctions in the EU. EU companies would then no longer be allowed to comply with US sanctions if they violate EU interests. Companies that violate this would then be liable for damages.</p>


<!-- RSPEAK_STOP -->

<!-- RSPEAK_START -->
<p>

<!-- RSPEAK_STOP -->
<span>(<a href="mailto:mki@heise.de" title="Malte Kirchner">mki</a>)</span>
<!-- RSPEAK_START -->
</p>
<div>
    <p>
      Don't miss any news – follow us on
      <a href="https://www.facebook.com/heiseonlineEnglish">Facebook</a>,
      <a href="https://www.linkedin.com/company/104691972">LinkedIn</a> or
      <a href="https://social.heise.de/@heiseonlineenglish">Mastodon</a>.
    </p>
    <p>
      <em>This article was originally published in
      
        <a href="https://www.heise.de/news/Wie-ein-franzoesischer-Richter-von-den-USA-digital-abgeklemmt-wurde-11087453.html">German</a>.
      
      It was translated with technical assistance and editorially reviewed before publication.</em>
    </p>
  </div>



        

        
        <!-- RSPEAK_STOP -->
        

<a-gift has-access="">
    
</a-gift>


        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FAWK: LLMs can write a language interpreter (194 pts)]]></title>
            <link>https://martin.janiczek.cz/2025/11/21/fawk-llms-can-write-a-language-interpreter.html</link>
            <guid>46003144</guid>
            <pubDate>Fri, 21 Nov 2025 10:28:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://martin.janiczek.cz/2025/11/21/fawk-llms-can-write-a-language-interpreter.html">https://martin.janiczek.cz/2025/11/21/fawk-llms-can-write-a-language-interpreter.html</a>, See on <a href="https://news.ycombinator.com/item?id=46003144">Hacker News</a></p>
<div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">
  

  <div itemprop="articleBody">
    <p>After reading the book <a href="https://www.awk.dev/">The AWK Programming Language</a>
<em>(recommended!)</em>, I was planning to try <a href="https://en.wikipedia.org/wiki/AWK">AWK</a>
out on this year’s Advent of Code. Having some time off from work this week, I
tried to implement <a href="https://adventofcode.com/2016/day/22">one of the problems</a>
in it to get some practice, set up my tooling, see how hard AWK would be,
and… I found I’m FP-pilled.</p>

<p>I <em>knew</em> I’m addicted to the combination of algebraic data types (tagged unions)
and exhaustive pattern matching, but what got me this time was immutability,
lexical scope and the basic human right of being allowed to return arrays from
functions.</p>

<p>Part 1 of the Advent of Code problem was easy enough, but for part 2 (basically
a shortest path search with a twist, to not spoil too much), I found myself
unable to switch from my usual <a href="https://martin.janiczek.cz/2023/06/27/fp-pattern-list-of-todos.html">functional BFS
approach</a>
to something mutable, and ended up trying to implement my functional approach in
AWK.</p>

<p>It got hairy very fast: I needed to implement:</p>
<ul>
  <li>hashing of strings and 2D arrays (by piping to <code>md5sum</code>)</li>
  <li>a global <del>set</del> array of seen states</li>
  <li>a way to serialize and deserialize a 2D array to/from a string</li>
  <li>and a few associative arrays for retrieving this serialized array by its
hash.</li>
</ul>

<p>I was very lost by the time I had all this; I spent hours just solving what felt
like <em>accidental complexity</em>; things that I’d take for granted in more modern
languages.</p>

<p>Now, I know nobody said AWK is modern, or functional, or that it promises any
convenience for anything other than one-liners and basic scripts that fit under
a handful of lines. I don’t want to sound like I expect AWK to do any of this;
I knew I was stretching the tool when going in. But I couldn’t shake the feeling
that there’s a beautiful AWK-like language within reach, an iteration on the AWK
design (the pattern-action way of thinking is beautiful) that also gives us a
few of the things programming language designers have learnt over the 48 years
since AWK was born.</p>

<h2 id="dreaming-of-functional-awk">Dreaming of functional AWK</h2>

<p>Stopping my attempts to solve the AoC puzzle in pure AWK, I wondered: what am I
missing here?</p>

<p>What if AWK had <strong>first-class arrays?</strong></p>

<pre><code>BEGIN {
  # array literals
  normal   = [1, 2, 3]
  nested   = [[1,2], [3,4]]
  assoc    = ["foo" =&gt; "bar", "baz" =&gt; "quux"]
  multidim = [(1,"abc") =&gt; 999]

  five = range(1,5)
  analyze(five)
  print five  # --&gt; still [1, 2, 3, 4, 5]! was passed by value
}

function range(a,b) {
  r = []
  for (i = a; i &lt;= b; i++) {
    r[length(r)] = i
  }
  return r  # arrays can be returned!
}

function analyze(arr) {
  arr[0] = 100
  print arr[0]  # --&gt; 100, only within this function
}
</code></pre>

<p>What if AWK had <strong>first-class functions and lambdas?</strong></p>

<pre><code>BEGIN {
  # construct anonymous functions
  double = (x) =&gt; { x * 2 }
  add = (a, b) =&gt; { c = a + b; return c }

  # functions can be passed as values
  apply = (func, value) =&gt; { func(value) }

  print apply(double,add(1,3))  # --&gt; 8
  print apply(inc,5)  # --&gt; 6
}

function inc(a) { return a + 1 }
</code></pre>

<p>What if AWK had <strong>lexical scope</strong> instead of dynamic scope?</p>

<pre><code># No need for this hack anymore ↓     ↓
#function foo(a, b         ,local1, local2) {
function foo(a, b) {
  local1 = a + b
  local2 = a - b
  return local1 + local2
}

BEGIN {
  c = foo(1,2)
  print(local1)  # --&gt; 0, the local1 from foo() didn't leak!
}
</code></pre>

<p>What if AWK had <strong>explicit globals</strong>, and everything else was <strong>local by default?</strong></p>

<pre><code>BEGIN { global count }
END {
  foo()
  print count  # --&gt; 1
  print mylocal # --&gt; 0, didn't leak
}
function foo() { count++; mylocal++ }
</code></pre>

<p>(This one, admittedly, might make programs a bit more verbose. I’m willing to
pay that cost.)</p>

<p>What if AWK had <strong>pipelines?</strong> (OK, now I’m reaching for syntax sugar…)</p>

<pre><code>BEGIN {
  result = [1, 2, 3, 4, 5] 
      |&gt; filter((x) =&gt; { x % 2 == 0 })
      |&gt; map((x) =&gt; { x * x })
      |&gt; reduce((acc, x) =&gt; { acc + x }, 0)

  print "Result:", result
}
</code></pre>

<h2 id="making-it-happen">Making it happen</h2>

<blockquote>
  <p>TL;DR: <a href="https://github.com/Janiczek/fawk"><code>Janiczek/fawk</code> on GitHub</a></p>
</blockquote>

<p>Now for the crazy, LLM-related part of the post. I didn’t want to spend days
implementing AWK from scratch or tweaking somebody else’s implementation. So I
tried to use Cursor Agent for a larger task than I usually do (I tend to ask
for very small targeted edits), and asked Sonnet 4.5 for <a href="https://github.com/Janiczek/fawk/pull/1/files">a README with code
examples</a>, and then <a href="https://github.com/Janiczek/fawk/pull/2/files">a full
implementation in Python</a>.</p>

<p>And it did it.</p>

<blockquote>
  <p>Note: I also asked for implementations in C, Haskell and Rust at the same
time, not knowing if any of the four would succeed, and they all seem to have
produced code that at least compiles/runs. I haven’t tried to test them or
even run them though. The PRs are
<a href="https://github.com/Janiczek/fawk/pulls?q=is%3Apr+is%3Aclosed">here</a>.</p>
</blockquote>

<p>I was very impressed—I still am! I expected the LLM to stumble and flail
around and ultimately get nothing done, but it did what I asked it for (gave me
an interpreter that could run <em>those specific examples</em>), and over the course
of a few chat sessions, I guided it towards implementing more and more of “the
rest of AWK”, together with an excessive amount of end-to-end tests.</p>

<p><a href="https://github.com/Janiczek/fawk/tree/main/tests">Take a look at those tests!</a></p>

<p>The only time I could see it struggle was when I asked it to implement arbitrary
precision floating point operations without using an external library like
<code>mpmath</code>. It attempted to use Taylor series, but couldn’t get it right for at
least a few minutes. I chickened out and told it to <code>uv add mpmath</code> and simplify
the interpreter code. In a moment it was done.</p>

<p>Other things that I thought it would choke on, like <code>print</code> being both a
statement (with <code>&gt;</code> and <code>&gt;&gt;</code> redirection support) and an expression, or
multi-dimensional arrays, or multi-line records, these were all implemented
correctly. Updating the test suite to also check for backwards compatibility
with <a href="https://www.gnu.org/software/gawk/">GAWK</a> - not an issue. Lexical scoping
and tricky closure environment behaviour - handled that just fine.</p>

<h2 id="what-now">What now?</h2>

<p>As the cool kids say, I have to <em>update my priors.</em> The frontier of what the
LLMs can do has moved since the last time I tried to vibe-code something. I
didn’t expect to have a working interpreter <em>the same day</em> I dreamt of a new
programming language. It now seems possible.</p>

<p>The downside of vibe coding the whole interpreter is that I have zero knowledge
of the code. I only interacted with the agent by telling it to implement a
thing and write tests for it, and I only <em>really</em> reviewed the tests. I reckon
this would be an issue in the future when I want to manually make some change
in the actual code, because I have no familiarity with it.</p>

<blockquote>
  <p>This also opened new questions for me wrt. my other projects where I’ve
previously run out of steam, eg. trying to implement a <a href="https://en.wikipedia.org/wiki/Hindley%E2%80%93Milner_type_system">Hindley-Milner type
system</a> for my
dream forever-WIP programming language <a href="https://cara-lang.com/">Cara</a>. It seems
I can now just ask the LLM to do it, and it will? But then, I don’t want to fall
into the trap where I am no longer able to work on the codebase myself. I want
to be familiar with and able to tinker on the code. I’d need to spend my time
reviewing and reading code instead of writing everything myself. Perhaps that’s
OK.</p>
</blockquote>

<p>Performance of FAWK might be an issue as well, though right now it’s a non-goal,
given my intended use case is throwaway scripts for Advent of Code, nothing
user-facing.  And who knows, based on what I’ve seen, maybe I can instruct it to
<em>rewrite it in Rust</em> and have a decent chance of success?</p>

<p>For now, I’ll go dogfood my shiny new vibe-coded black box of a programming
language on the Advent of Code problem (and as many of the 2025 puzzles as I
can), and see what rough edges I can find. I expect them to be equal parts “not
implemented yet” and “unexpected interactions of new PL features with the old
ones”.</p>

<p>If you’re willing to jump through some Python project dependency hoops, you can
try to use FAWK too at your own risk, at <a href="https://github.com/Janiczek/fawk"><code>Janiczek/fawk</code> on
GitHub</a>.</p>

    <hr>





  </div>

  
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HP and Dell disable HEVC support built into their laptops' CPUs (214 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2025/11/hp-and-dell-disable-hevc-support-built-into-their-laptops-cpus/</link>
            <guid>46002989</guid>
            <pubDate>Fri, 21 Nov 2025 10:01:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2025/11/hp-and-dell-disable-hevc-support-built-into-their-laptops-cpus/">https://arstechnica.com/gadgets/2025/11/hp-and-dell-disable-hevc-support-built-into-their-laptops-cpus/</a>, See on <a href="https://news.ycombinator.com/item?id=46002989">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<p>The OEMs disabling codec hardware also comes as associated costs for the international video compression standard are set to increase in January, as licensing administrator Access Advance <a href="https://accessadvance.com/2025/07/21/access-advance-announces-hevc-advance-and-vvc-advance-pricing-through-2030/">announced</a> in July. Per <a href="https://via-la.com/licensing-programs/hevc-vvc/#license-fees">a breakdown</a> from patent pool administration <a href="https://via-la.com/about/">VIA Licensing Alliance</a>, royalty rates for HEVC for over 100,001 units are increasing from $0.20 each to $0.24 each in the United States. To put that into perspective, in Q3 2025, HP sold 15,002,000 laptops and desktops, and Dell sold 10,166,000 laptops and desktops, <a href="https://www.gartner.com/en/newsroom/press-releases/2025-10-16-gartner-says-worldwide-pc-shipments-grew-8-percent-in-third-quarter-of-2025">per Gartner.</a></p>
<p>Last year, NAS company Synology <a href="https://www.synology.com/en-global/products/status/eol-video-codec-support">announced</a> that it was ending support for HEVC, as well as H.264/AVC and VCI, transcoding on its DiskStation Manager and BeeStation OS platforms, saying that “support for video codecs is widespread on end devices, such as smartphones, tablets, computers, and smart TVs.”</p>
<p>“This update reduces unnecessary resource usage on the server and significantly improves media processing efficiency. The optimization is particularly effective in high-user environments compared to traditional server-side processing,” the announcement said.</p>
<p>Despite the growing costs and complications with HEVC licenses and workarounds, breaking features that have been widely available for years will likely lead to confusion and frustration.</p>
<p>“This is pretty ridiculous, given these systems are $800+ a machine, are part of a ‘Pro’ line (jabs at branding names are warranted – HEVC is used professionally), and more applications these days outside of Netflix and streaming TV are getting around to adopting HEVC,” a Redditor wrote.</p>


          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[It's hard to build an oscillator (212 pts)]]></title>
            <link>https://lcamtuf.substack.com/p/its-hard-to-build-an-oscillator</link>
            <guid>46002161</guid>
            <pubDate>Fri, 21 Nov 2025 07:45:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lcamtuf.substack.com/p/its-hard-to-build-an-oscillator">https://lcamtuf.substack.com/p/its-hard-to-build-an-oscillator</a>, See on <a href="https://news.ycombinator.com/item?id=46002161">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>There’s an old electronics joke that if you want to build an oscillator, you should try building an amplifier. One of the fundamental criteria for oscillation is the presence of signal gain; without it, any oscillation is bound to decay, just like a swing that’s no longer being pushed must eventually come to a stop.</p><p>In reality, circuits with gain can occasionally oscillate by accident, but it’s rather difficult to build a good analog oscillator from scratch. The most common category of oscillators you can find on the internet are circuits that simply don’t work. This is followed by approaches that require exotic components, such as center-tapped inductors or incandescent lightbulbs. The final group are the layouts you can copy, but probably won’t be able to explain to a friend who doesn’t have an EE degree.</p><p><span>In today’s article, I wanted to approach the problem in a different way. I’ll assume that you’re up-to-date on some of the key lessons from earlier articles: that you </span><a href="https://lcamtuf.substack.com/p/primer-core-concepts-in-electronic" rel="">can tell the difference between voltage and current</a><span>, have a </span><a href="https://lcamtuf.substack.com/p/how-do-transistors-work-anyway" rel="">basic grasp of transistors</a><span>, and know what happens when a </span><a href="https://lcamtuf.substack.com/p/the-101-of-analog-signal-filtering" rel="">capacitor is charged through a resistor</a><span>. With this in mind, let’s try to construct an oscillator that’s easy to understand, runs well, and has a predictable operating frequency. Further, let’s do it without peeking at someone else’s homework.</span></p><p>The simplest form of an oscillator is a device that uses negative feedback to cycle back and forth between two unstable states. To illustrate, think of a machine equipped with a light sensor and a robotic arm. In the dark, the machine is compelled to stroll over to the wall switch and flip it on. If it detects light, another part of its programming takes over and toggles the switch off. The machine is doomed to an endless cycle of switch-flipping at a frequency dictated by how quickly it can process information and react.</p><p>At first blush, we should be able to replicate this operating principle with a single n-channel MOSFET. After all, a transistor can be used as an electronically-operated switch:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!r-KH!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2500f9a6-2ebe-425e-9b8c-a0bda5527317_1188x747.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!r-KH!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2500f9a6-2ebe-425e-9b8c-a0bda5527317_1188x747.png 424w, https://substackcdn.com/image/fetch/$s_!r-KH!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2500f9a6-2ebe-425e-9b8c-a0bda5527317_1188x747.png 848w, https://substackcdn.com/image/fetch/$s_!r-KH!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2500f9a6-2ebe-425e-9b8c-a0bda5527317_1188x747.png 1272w, https://substackcdn.com/image/fetch/$s_!r-KH!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2500f9a6-2ebe-425e-9b8c-a0bda5527317_1188x747.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!r-KH!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2500f9a6-2ebe-425e-9b8c-a0bda5527317_1188x747.png" width="1188" height="747" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2500f9a6-2ebe-425e-9b8c-a0bda5527317_1188x747.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:747,&quot;width&quot;:1188,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:41985,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://lcamtuf.substack.com/i/179419876?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2500f9a6-2ebe-425e-9b8c-a0bda5527317_1188x747.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!r-KH!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2500f9a6-2ebe-425e-9b8c-a0bda5527317_1188x747.png 424w, https://substackcdn.com/image/fetch/$s_!r-KH!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2500f9a6-2ebe-425e-9b8c-a0bda5527317_1188x747.png 848w, https://substackcdn.com/image/fetch/$s_!r-KH!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2500f9a6-2ebe-425e-9b8c-a0bda5527317_1188x747.png 1272w, https://substackcdn.com/image/fetch/$s_!r-KH!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2500f9a6-2ebe-425e-9b8c-a0bda5527317_1188x747.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption><em>A wannabe oscillator.</em></figcaption></figure></div><p><span>The transistor turns on when the voltage between its gate terminal and the source leg (</span><em>Vgs</em><span>) exceeds a certain threshold, usually around 2 V. When the power supply first ramps up, the transistor is not conducting. With no current flowing through, there’s no voltage drop across the resistor, so </span><em>Vgs</em><span> is pulled toward the positive supply rail. Once this voltage crosses about 2 V, the transistor begins to admit current. It stands to reason that the process shorts the bottom terminal of the resistor to the ground and causes </span><em>Vgs </em><span>will plunge to 0 V. If so, that would restart the cycle and produce a square wave on the output leg.</span></p><p><span>In practice, this is not the behavior you’ll see. For a MOSFET, the relationship between </span><em>Vgs</em><span> and the admitted current (</span><em>Id</em><span>) is steep, but the device is not a binary switch:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!qmcl!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b8ca161-e0c8-44a4-99ac-3be2fbfd8c06_2344x1563.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!qmcl!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b8ca161-e0c8-44a4-99ac-3be2fbfd8c06_2344x1563.png 424w, https://substackcdn.com/image/fetch/$s_!qmcl!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b8ca161-e0c8-44a4-99ac-3be2fbfd8c06_2344x1563.png 848w, https://substackcdn.com/image/fetch/$s_!qmcl!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b8ca161-e0c8-44a4-99ac-3be2fbfd8c06_2344x1563.png 1272w, https://substackcdn.com/image/fetch/$s_!qmcl!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b8ca161-e0c8-44a4-99ac-3be2fbfd8c06_2344x1563.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!qmcl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b8ca161-e0c8-44a4-99ac-3be2fbfd8c06_2344x1563.png" width="1456" height="971" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3b8ca161-e0c8-44a4-99ac-3be2fbfd8c06_2344x1563.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:71986,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://lcamtuf.substack.com/i/179419876?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b8ca161-e0c8-44a4-99ac-3be2fbfd8c06_2344x1563.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!qmcl!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b8ca161-e0c8-44a4-99ac-3be2fbfd8c06_2344x1563.png 424w, https://substackcdn.com/image/fetch/$s_!qmcl!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b8ca161-e0c8-44a4-99ac-3be2fbfd8c06_2344x1563.png 848w, https://substackcdn.com/image/fetch/$s_!qmcl!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b8ca161-e0c8-44a4-99ac-3be2fbfd8c06_2344x1563.png 1272w, https://substackcdn.com/image/fetch/$s_!qmcl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3b8ca161-e0c8-44a4-99ac-3be2fbfd8c06_2344x1563.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>BS170 Vgs-Id curve for Vds = 1 V. Captured by author.</em></figcaption></figure></div><p><span>In particular, there is a certain point on that curve, somewhere in the vicinity of 2 V, that corresponds to the transistor only admitting a current of about 200 µA. From Ohm’s law, this current flowing through a 10 kΩ resistor will produce a voltage drop of 3 V. In a 5 V circuit, this puts </span><em>Vgs</em><span> at 5 V - 3 V = 2 V. In other words, there exists a stable equilibrium that prevents oscillation. It’s akin to our robot-operated light switch being half-on.</span></p><p><span>To fix this issue, we need to build an electronic switch that has no stable midpoint. This is known as </span><em>Schmitt trigger</em><span> and its simple implementation is shown below:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!EQq5!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ef5b428-4c41-4a4a-8495-0bdf07925554_1374x898.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!EQq5!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ef5b428-4c41-4a4a-8495-0bdf07925554_1374x898.png 424w, https://substackcdn.com/image/fetch/$s_!EQq5!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ef5b428-4c41-4a4a-8495-0bdf07925554_1374x898.png 848w, https://substackcdn.com/image/fetch/$s_!EQq5!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ef5b428-4c41-4a4a-8495-0bdf07925554_1374x898.png 1272w, https://substackcdn.com/image/fetch/$s_!EQq5!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ef5b428-4c41-4a4a-8495-0bdf07925554_1374x898.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!EQq5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ef5b428-4c41-4a4a-8495-0bdf07925554_1374x898.png" width="1374" height="898" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2ef5b428-4c41-4a4a-8495-0bdf07925554_1374x898.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:898,&quot;width&quot;:1374,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:119892,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://lcamtuf.substack.com/i/179419876?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ef5b428-4c41-4a4a-8495-0bdf07925554_1374x898.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!EQq5!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ef5b428-4c41-4a4a-8495-0bdf07925554_1374x898.png 424w, https://substackcdn.com/image/fetch/$s_!EQq5!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ef5b428-4c41-4a4a-8495-0bdf07925554_1374x898.png 848w, https://substackcdn.com/image/fetch/$s_!EQq5!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ef5b428-4c41-4a4a-8495-0bdf07925554_1374x898.png 1272w, https://substackcdn.com/image/fetch/$s_!EQq5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2ef5b428-4c41-4a4a-8495-0bdf07925554_1374x898.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>A discrete-transistor Schmitt trigger.</em></figcaption></figure></div><p><span>To analyze the design, let’s assume the circuit is running off </span><em>Vsupply = 5 </em><span>V. If the input signal is 0 V, the transistor on the left is not conducting, which pulls </span><em>Vgs</em><span> for the other MOSFET all the way to 5 V. That input allows nearly arbitrary currents to flow through the right branch of the circuit, making that current path more or less equivalent to a two-resistor a voltage divider. We can calculate the midpoint voltage of the divider:</span></p><div data-component-name="Latex"><p><span>\(V_{s\textrm{ (input low)}} \approx V_{supply} \cdot { R_{comm} \over { R_{comm} + R2} } \approx 450 \textrm{ mV}\)</span></p></div><p><span>This voltage is also propagated the source terminal of the input transistor on the left. The actual </span><em>Vth</em><span> for the </span><a href="https://www.onsemi.com/download/data-sheet/pdf/mmbf170-d.pdf" rel="">BS170</a><span> transistors in my possession is about 2.15 V, so for the input-side transistor to turn on, the supplied signal will need to exceed </span><em>Vs + Vth ≈</em><span> 2.6 V in reference to the ground. When that happens, a large voltage drop appears across R1, reducing the </span><em>Vgs</em><span> of the output-side transistor below the threshold of conduction, and choking off the current in the right branch.</span></p><p><span>At this point, there’s still current flowing through the common resistor on the bottom, but it’s now increasingly sourced via the left branch. The left branch forms a new voltage divider; because R1</span><sub> </sub><span>has a higher resistance than R2, </span><em>Vs</em><span> is gradually reduced, effectively bumping up </span><em><span>Vgs</span><sub> </sub></em><span>for the left transistor and thus knocking it more firmly into conduction even if the input voltage remains constant. This is a positive feedback that gives the circuit no option to linger in a half-on state. </span></p><p>Once the transition is complete, the voltage drop across the bottom resistor is down from 450 mV to about 50 mV. This means that although the left transistor first turned on when the input signal crossed 2.6 V in reference to the ground, it will not turn off until the voltage drops all the way to 2.2 V — a 400 mV gap.</p><p><span>This circuit lets us build what’s known as a </span><em>relaxation oscillator</em><span>. To do so, we only need to make two small tweaks. First, we need to loop an inverted output signal back onto the input; the most intuitive way of doing this is to add another transistor in a switch-like configuration similar to the failed design of a single-transistor oscillator mentioned earlier on. This building block, marked on the left, outputs </span><em>Vsupply</em><span> when the signal routed to the gate terminal is 0 V, and produces roughly 0 V when the input is near </span><em>Vsupply</em><span>:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!MrwU!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5029009-ad6c-4336-bdad-713f1549ddad_1944x1018.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!MrwU!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5029009-ad6c-4336-bdad-713f1549ddad_1944x1018.png 424w, https://substackcdn.com/image/fetch/$s_!MrwU!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5029009-ad6c-4336-bdad-713f1549ddad_1944x1018.png 848w, https://substackcdn.com/image/fetch/$s_!MrwU!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5029009-ad6c-4336-bdad-713f1549ddad_1944x1018.png 1272w, https://substackcdn.com/image/fetch/$s_!MrwU!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5029009-ad6c-4336-bdad-713f1549ddad_1944x1018.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!MrwU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5029009-ad6c-4336-bdad-713f1549ddad_1944x1018.png" width="1456" height="762" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c5029009-ad6c-4336-bdad-713f1549ddad_1944x1018.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:762,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:234102,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://lcamtuf.substack.com/i/179419876?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5029009-ad6c-4336-bdad-713f1549ddad_1944x1018.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!MrwU!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5029009-ad6c-4336-bdad-713f1549ddad_1944x1018.png 424w, https://substackcdn.com/image/fetch/$s_!MrwU!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5029009-ad6c-4336-bdad-713f1549ddad_1944x1018.png 848w, https://substackcdn.com/image/fetch/$s_!MrwU!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5029009-ad6c-4336-bdad-713f1549ddad_1944x1018.png 1272w, https://substackcdn.com/image/fetch/$s_!MrwU!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc5029009-ad6c-4336-bdad-713f1549ddad_1944x1018.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>A Schmitt trigger oscillator.</em></figcaption></figure></div><p>Next, to set a sensible oscillation speed, we need to add a time delay, which can be accomplished by charging a capacitor through a resistor (middle section). The resistor needs to be large enough not to overload the inverter stage.</p><p>For the component values shown in the schematic, the circuit should oscillate at a frequency of almost exactly 3 kHz when supplied with 5 V:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!VY3r!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fade8f556-7691-446d-b6f5-9d45acc2e737_2813x1875.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!VY3r!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fade8f556-7691-446d-b6f5-9d45acc2e737_2813x1875.png 424w, https://substackcdn.com/image/fetch/$s_!VY3r!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fade8f556-7691-446d-b6f5-9d45acc2e737_2813x1875.png 848w, https://substackcdn.com/image/fetch/$s_!VY3r!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fade8f556-7691-446d-b6f5-9d45acc2e737_2813x1875.png 1272w, https://substackcdn.com/image/fetch/$s_!VY3r!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fade8f556-7691-446d-b6f5-9d45acc2e737_2813x1875.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!VY3r!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fade8f556-7691-446d-b6f5-9d45acc2e737_2813x1875.png" width="1456" height="970" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ade8f556-7691-446d-b6f5-9d45acc2e737_2813x1875.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:970,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:103611,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://lcamtuf.substack.com/i/179419876?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fade8f556-7691-446d-b6f5-9d45acc2e737_2813x1875.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!VY3r!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fade8f556-7691-446d-b6f5-9d45acc2e737_2813x1875.png 424w, https://substackcdn.com/image/fetch/$s_!VY3r!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fade8f556-7691-446d-b6f5-9d45acc2e737_2813x1875.png 848w, https://substackcdn.com/image/fetch/$s_!VY3r!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fade8f556-7691-446d-b6f5-9d45acc2e737_2813x1875.png 1272w, https://substackcdn.com/image/fetch/$s_!VY3r!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fade8f556-7691-446d-b6f5-9d45acc2e737_2813x1875.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>An oscilloscope trace for the circuit, by author.</em></figcaption></figure></div><p><span>The frequency is governed by how long it takes for the capacitor to move </span><em>Δv = </em><span>400 mV between the two Schmitt thresholds voltages:</span><em> </em><span>the “off” point at 2.2 V and the “on” point at 2.6 V.</span></p><p><span>Because the overall variation in capacitor voltage is small, the we can squint our eyes and say that the voltage across the 100 kΩ resistor is nearly constant in every charge cycle. When the resistor is connected to the positive rail, </span><em><span>V</span><sub>R</sub></em><span> ≈ 5 V – 2.4 V ≈ 2.6 V. Conversely, when the resistor is connected to the ground, we get </span><em><span>V</span><sub>R</sub></em><span>  ≈ 2.4 V. If the voltages across the resistor are nearly constant, so are the resulting capacitor currents:</span></p><div data-component-name="Latex"><p><span>\(\begin{array}{c}
I_{C \textrm{ (charging)}} \approx {2.6 \textrm{ V} \over 100 \textrm{ kΩ}} \approx 26 \textrm{ µA} \\
I_{C \textrm{ (discharging)}} \approx {2.4 \textrm{ V} \over 100 \textrm{ kΩ}} \approx 24 \textrm{ µA}

\end{array}

\)</span></p></div><p><span>From the </span><a href="https://lcamtuf.substack.com/p/primer-core-concepts-in-electronic" rel="">fundamental capacitor equation</a><span> (</span><em>Δv = I · t/C</em><span>), we can solve for the charging time needed to move the voltage by </span><em>Δv</em><span> = 400 mV; the result is about 154 µs for the charging period and 167 µs for the discharging period. The sum is 321 µs, corresponding to a frequency of about 3.1 kHz – pretty close to real life.</span></p><p><span>The circuit can be simplified to two transistors at the expense of readability, but if you need an analog oscillator with a lower component count, an </span><a href="https://lcamtuf.substack.com/p/the-basics-of-signal-amplification" rel="">operational amplifier</a><span> is your best bet.</span></p><p><span>If you’re rusty on op-amps, I suggest pausing to review the article linked in the preceding paragraph. That said, to understand the next circuit, all you need to know is that an op-amp compares two input voltages and that </span><em>Vout</em><span> swings toward the positive rail if </span><em>Vin+ </em><span>≫</span><em> Vin-</em><span> or toward the negative rail if </span><em>Vin+ </em><span>≪</span><em> Vin-</em><span>.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!FFPj!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc949512a-bab6-49ad-a9ae-f0bc6c2bb225_1511x962.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!FFPj!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc949512a-bab6-49ad-a9ae-f0bc6c2bb225_1511x962.png 424w, https://substackcdn.com/image/fetch/$s_!FFPj!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc949512a-bab6-49ad-a9ae-f0bc6c2bb225_1511x962.png 848w, https://substackcdn.com/image/fetch/$s_!FFPj!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc949512a-bab6-49ad-a9ae-f0bc6c2bb225_1511x962.png 1272w, https://substackcdn.com/image/fetch/$s_!FFPj!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc949512a-bab6-49ad-a9ae-f0bc6c2bb225_1511x962.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!FFPj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc949512a-bab6-49ad-a9ae-f0bc6c2bb225_1511x962.png" width="1456" height="927" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c949512a-bab6-49ad-a9ae-f0bc6c2bb225_1511x962.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:927,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:111538,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://lcamtuf.substack.com/i/179419876?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc949512a-bab6-49ad-a9ae-f0bc6c2bb225_1511x962.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!FFPj!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc949512a-bab6-49ad-a9ae-f0bc6c2bb225_1511x962.png 424w, https://substackcdn.com/image/fetch/$s_!FFPj!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc949512a-bab6-49ad-a9ae-f0bc6c2bb225_1511x962.png 848w, https://substackcdn.com/image/fetch/$s_!FFPj!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc949512a-bab6-49ad-a9ae-f0bc6c2bb225_1511x962.png 1272w, https://substackcdn.com/image/fetch/$s_!FFPj!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc949512a-bab6-49ad-a9ae-f0bc6c2bb225_1511x962.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>An op-amp relaxation oscillator.</em></figcaption></figure></div><p><span>For simplicity, let’s choose R1 = R2 = R3 and then look at the non-inverting (</span><em>Vin+</em><span>) input of the chip. What we have here is a three-way voltage divider: the signal on the non-inverting input is simple average of three voltages: </span><em>Vsupply</em><span> (5 V), ground (0 V), and </span><em>Vout</em><span>. We don’t know the value of </span><em>Vout</em><span> just yet, but it can only vary from 0 V to </span><em>Vsupply</em><span>, so the </span><em><span>V</span><sub>in+</sub></em><span> signal will always stay between ⅓ · </span><em>Vsupply</em><span> and ⅔ ·</span><em> Vsupply.</em></p><p><span>Next, let’s have a look at the inverting input (</span><em>Vin-</em><span>). When the circuit is first powered on, the capacitor C isn’t charged, so </span><em>Vin-</em><span> sits at 0 V. Since the voltage on the non-inverting input can’t be lower than ⅓ · </span><em>Vsupply</em><span>, this means that on power-on, </span><em>Vin+ </em><span>≫</span><em> Vin-</em><span>, sending the output voltage toward the positive rail. When </span><em>Vout</em><span> shoots up, it also bumps the </span><em>Vin+</em><span> average to ⅔ · </span><em>Vsupply.</em></p><p><span>Because </span><em>Vout</em><span> is now high, this starts the process of charging the capacitor through the bottom resistor (R</span><sub>cap</sub><span>). After a while, the capacitor voltage is bound to exceed ⅔ · </span><em>Vsupply</em><span>. The capacitor voltage is also hooked up to the amplifier’s inverting input, and at that point, </span><em>Vin-</em><span> begins to exceeds </span><em>Vin+</em><span>, nudging the output voltage lower. Stable equilibrium is not possible because this output voltage drop is immediately reflected in the three-way average present on the </span><em>Vin+</em><span> leg, pulling it down and causing the difference between </span><em>Vin-</em><span> and </span><em>Vin+</em><span> to widen. This positive feedback loop puts the amplifier firmly into the </span><em>Vin+ </em><span>≪</span><em><span> Vin-</span><sub> </sub></em><span>territory.</span></p><p><span>At that point, </span><em>Vout</em><span> must drop to 0 V, thus lowering the voltage on the non-inverting leg to ⅓ · </span><em>Vsupply</em><span>. With </span><em>Vout</em><span> low, the capacitor starts discharging through R</span><sub>cap</sub><span>, but it needs to travel from the current charge state of ⅔ · </span><em>Vsupply</em><span> all the way to ⅓ · </span><em>Vsupply</em><span> before </span><em>Vin-</em><span> becomes lower than </span><em>Vin+</em><span> and the cycle is allowed to restart.</span></p><p><span>The continued charging and discharging of the capacitor between ⅓ · </span><em>Vsupply</em><span> and ⅔ · </span><em>Vsupply</em><span> results in periodic oscillation. The circuit produces a square wave signal with a period dictated by the value of C and R</span><sub>cap</sub><span>. The frequency of these oscillations can be approximated analogously to what we’ve done for the discrete-transistor variant earlier on. In a 5 V circuit with R1 = R2 = R3, the capacitor charges and discharges by </span><em>Δv ≈</em><span> 1.67 V. If R</span><sub>cap</sub><span> = 10 kΩ, then the quasi-constant capacitor charging current is </span><em>I</em><span> </span><em>≈</em><span> 2.5 V / 10 kΩ </span><em>≈</em><span> 250 µA.</span></p><p><span>Knowing </span><em>Δv</em><span> and </span><em>I</em><span>, and assuming C = 1 µF, we can tap into the capacitor equation (</span><em>Δv = I · t/C</em><span>) to solve for </span><em>t</em><span>. The result is 6.67 ms. This puts the charge-discharge roundtrip at 13.34 ms, suggesting a frequency of 75 Hz. The actual measurement is shown below:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!p0Ga!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa737b851-73ed-4611-8591-63ee7e7b82c6_2813x1875.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!p0Ga!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa737b851-73ed-4611-8591-63ee7e7b82c6_2813x1875.png 424w, https://substackcdn.com/image/fetch/$s_!p0Ga!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa737b851-73ed-4611-8591-63ee7e7b82c6_2813x1875.png 848w, https://substackcdn.com/image/fetch/$s_!p0Ga!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa737b851-73ed-4611-8591-63ee7e7b82c6_2813x1875.png 1272w, https://substackcdn.com/image/fetch/$s_!p0Ga!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa737b851-73ed-4611-8591-63ee7e7b82c6_2813x1875.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!p0Ga!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa737b851-73ed-4611-8591-63ee7e7b82c6_2813x1875.png" width="1456" height="970" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a737b851-73ed-4611-8591-63ee7e7b82c6_2813x1875.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:970,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:112168,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://lcamtuf.substack.com/i/179419876?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa737b851-73ed-4611-8591-63ee7e7b82c6_2813x1875.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!p0Ga!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa737b851-73ed-4611-8591-63ee7e7b82c6_2813x1875.png 424w, https://substackcdn.com/image/fetch/$s_!p0Ga!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa737b851-73ed-4611-8591-63ee7e7b82c6_2813x1875.png 848w, https://substackcdn.com/image/fetch/$s_!p0Ga!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa737b851-73ed-4611-8591-63ee7e7b82c6_2813x1875.png 1272w, https://substackcdn.com/image/fetch/$s_!p0Ga!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa737b851-73ed-4611-8591-63ee7e7b82c6_2813x1875.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Oscilloscope trace for the relaxation oscillator. By author.</em></figcaption></figure></div><p><span>The observed frequency is about 7% lower than predicted: 70 instead of 75 Hz. Although I could pin this on component tolerances, a more honest explanation is that at </span><em>Δv ≈</em><span> 1.67 V, the constant-current approximation of the capacitor charging process is stretched thin; the segments in the bottom oscilloscope trace diverge quite a bit from a straight line. Not to worry; to reduce </span><em>Δv</em><span>, we just need to bump up the value of R3. If we switch to 47 kΩ and keep everything else the same, the delta will be about 480 mV and the model we’re relying on will give a more precise result.</span></p><p><span>If you’re interested in a general formula to find the circuit’s operating frequency, it helps to assume that R1 and R2 are the same. If so, we can replace them with a new composite resistor with half the resistance and solve the standard voltage divider equation to find out what would happen if the feedback signal moves from 0 V to </span><em>Vsupply</em><span>:</span></p><div data-component-name="Latex"><p><span>\(\Delta v = {0.5 \ R_{1,2} \over 0.5 \ R_{1,2} + R_3} \cdot V_{supply} = { R_{1,2} \over R_{1,2} + 2 \ R_3} \cdot V_{supply}\)</span></p></div><p><span>With two identical resistors, the capacitor waveform is centered around ½ </span><em>Vsupply</em><span>, so the formula for the average current is also pretty simple (and doesn’t change between the charge and discharge periods):</span></p><div data-component-name="Latex"><p><span>\(I \approx {0.5 \ V_{supply} \over R_{cap}} \approx {V_{supply} \over 2 \ R_{cap}}\)</span></p></div><p><span>This gives us all we need to solve for frequency using the capacitor equation, rewritten as t = </span><em>Δv · C/I:</em></p><div data-component-name="Latex"><p><span>\(f_{osc} \approx {1 \over 2 \ t} \approx {I \over 2 \ \Delta t \cdot C} \approx {\cancel{V_{supply}} \over 2 \ R_{cap}} \cdot { R_{1,2} + 2 \ R_3 \over 2 \ C \cdot \cancel{V_{supply}} \cdot R_{1,2}}\)</span></p></div><p>This further simplifies to:</p><div data-component-name="Latex"><p><span>\(f_{osc} \approx  { R_{1,2} + 2 \ R_3 \over 4 R_{1,2} \cdot R_{cap} \cdot C}\)</span></p></div><p>…and in the specific case of R1 = R2 = 10 kΩ plus R3 = 47 kΩ, we get:</p><div data-component-name="Latex"><p><span>\(f_{osc} \approx  {2.6 \over R_{cap} \cdot C}\)</span></p></div><p>The method outlined earlier on is not the only conceptual approach to build oscillators. Another way is to produce resonance. We can do this by taking a standard op-amp voltage follower which uses negative feedback to control the output — and then mess with the feedback loop in a particular way.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!guJy!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb0e22c3-bd8c-43dd-8f12-c5e1efff3db2_1191x649.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!guJy!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb0e22c3-bd8c-43dd-8f12-c5e1efff3db2_1191x649.png 424w, https://substackcdn.com/image/fetch/$s_!guJy!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb0e22c3-bd8c-43dd-8f12-c5e1efff3db2_1191x649.png 848w, https://substackcdn.com/image/fetch/$s_!guJy!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb0e22c3-bd8c-43dd-8f12-c5e1efff3db2_1191x649.png 1272w, https://substackcdn.com/image/fetch/$s_!guJy!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb0e22c3-bd8c-43dd-8f12-c5e1efff3db2_1191x649.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!guJy!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb0e22c3-bd8c-43dd-8f12-c5e1efff3db2_1191x649.png" width="1191" height="649" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bb0e22c3-bd8c-43dd-8f12-c5e1efff3db2_1191x649.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:649,&quot;width&quot;:1191,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:63281,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://lcamtuf.substack.com/i/179419876?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb0e22c3-bd8c-43dd-8f12-c5e1efff3db2_1191x649.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!guJy!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb0e22c3-bd8c-43dd-8f12-c5e1efff3db2_1191x649.png 424w, https://substackcdn.com/image/fetch/$s_!guJy!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb0e22c3-bd8c-43dd-8f12-c5e1efff3db2_1191x649.png 848w, https://substackcdn.com/image/fetch/$s_!guJy!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb0e22c3-bd8c-43dd-8f12-c5e1efff3db2_1191x649.png 1272w, https://substackcdn.com/image/fetch/$s_!guJy!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbb0e22c3-bd8c-43dd-8f12-c5e1efff3db2_1191x649.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>An op-amp voltage follower.</figcaption></figure></div><p><span>In the basic voltage follower configuration, the op-amp reaches a stable equilibrium when </span><em>Vin+</em><span> ≈ </span><em>Vin-</em><span> ≈ </span><em>Vout</em><span>. Again, the circuit works only because of the negative feedback loop; in its absence, </span><em>Vin- </em><span>would diverge from </span><em>Vin+</em><span> and the output voltage would swing toward one of the supply rails.</span></p><p>To turn this circuit into an oscillator, we can build a feedback loop that normally provides negative feedback, but that inverts the waveform at a particular sine-wave frequency. This turns negative feedback into positive feedback; instead of stabilizing the output voltage, it produces increasing swings, but only at the frequency at which the inversion takes place.</p><p><span>Such a selective waveform inversion sounds complicated, but we can achieve it a familiar building block: an R-C lowpass filter. The mechanics of these filters are discussed in </span><a href="https://lcamtuf.substack.com/p/the-101-of-analog-signal-filtering" rel="">this article</a><span>; in a nutshell, the arrangement produces a frequency-dependent phase shift of 0° (at DC) to -90° (as the frequency approaches infinity). If we cascade a couple of these R-C stages, we can achieve a -180° phase shift at some chosen frequency, which is the same as flipping the waveform.</span></p><p>A minimalistic but well-behaved op-amp solution is shown below:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!TaAe!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35c00808-f602-4922-be06-efcb7dcb722c_1672x1070.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!TaAe!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35c00808-f602-4922-be06-efcb7dcb722c_1672x1070.png 424w, https://substackcdn.com/image/fetch/$s_!TaAe!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35c00808-f602-4922-be06-efcb7dcb722c_1672x1070.png 848w, https://substackcdn.com/image/fetch/$s_!TaAe!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35c00808-f602-4922-be06-efcb7dcb722c_1672x1070.png 1272w, https://substackcdn.com/image/fetch/$s_!TaAe!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35c00808-f602-4922-be06-efcb7dcb722c_1672x1070.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!TaAe!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35c00808-f602-4922-be06-efcb7dcb722c_1672x1070.png" width="1456" height="932" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/35c00808-f602-4922-be06-efcb7dcb722c_1672x1070.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:932,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:179211,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://lcamtuf.substack.com/i/179419876?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35c00808-f602-4922-be06-efcb7dcb722c_1672x1070.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!TaAe!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35c00808-f602-4922-be06-efcb7dcb722c_1672x1070.png 424w, https://substackcdn.com/image/fetch/$s_!TaAe!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35c00808-f602-4922-be06-efcb7dcb722c_1672x1070.png 848w, https://substackcdn.com/image/fetch/$s_!TaAe!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35c00808-f602-4922-be06-efcb7dcb722c_1672x1070.png 1272w, https://substackcdn.com/image/fetch/$s_!TaAe!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F35c00808-f602-4922-be06-efcb7dcb722c_1672x1070.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>A rudimentary phase-shift oscillator.</em></figcaption></figure></div><p>In this particular circuit, an overall -180° shift happens when each of the R-C stages adds its own -60°. It’s easy to find the frequency at which this occurs. In the aforementioned article on signal filtering, we came up with the following formula describing the shift associated with the filter:</p><div data-component-name="Latex"><p><span>\(\theta = -arctan( 2 \pi f R C )\)</span></p></div><p><span>Arctangent is the inverse of the tangent function. In a right triangle, the tangent function describes the ratio of lengths of the opposite to the adjacent for a particular angle; the arctangent goes the other way round, giving us an angle for a particular ratio. In other words, if </span><em>x</em><span> = </span><em>tan(α)</em><span> then </span><em>α </em><span>= </span><em>arctan(x).</em><span> This allows us to rewrite the equation as:</span></p><div data-component-name="Latex"><p><span>\(2 \pi f R C = -tan(\theta)\)</span></p></div><p><span>We’re trying to solve for </span><em>f</em><span> at which </span><em>θ</em><span> = -60°; the value of </span><em>-tan(-60°)</em><span> is roughly 1.73, so we can plug that into the equation and then move everything except </span><em>f </em><span>to the right. Throwing in the component values for the first R-C stage in the schematic, we obtain:</span></p><div data-component-name="Latex"><p><span>\(f_{osc} \approx {1.73 \over {2 \pi R C}} \approx {1.73 \over {2 \pi \cdot 1 \textrm{ kΩ} \cdot 100 \textrm{ nF}}} \approx 2.75 \textrm{ kHz}

\)</span></p></div><p>You’ll notice that the result is the same for the other two stages: they have higher resistances but proportionally lower capacitances, so the denominator of the fraction doesn’t change.</p><p>Oscilloscope traces for the circuit are shown below:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!0H2m!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3c9efcc-3be6-4309-8d43-92e565c15c91_2813x1875.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!0H2m!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3c9efcc-3be6-4309-8d43-92e565c15c91_2813x1875.png 424w, https://substackcdn.com/image/fetch/$s_!0H2m!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3c9efcc-3be6-4309-8d43-92e565c15c91_2813x1875.png 848w, https://substackcdn.com/image/fetch/$s_!0H2m!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3c9efcc-3be6-4309-8d43-92e565c15c91_2813x1875.png 1272w, https://substackcdn.com/image/fetch/$s_!0H2m!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3c9efcc-3be6-4309-8d43-92e565c15c91_2813x1875.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!0H2m!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3c9efcc-3be6-4309-8d43-92e565c15c91_2813x1875.png" width="1456" height="970" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e3c9efcc-3be6-4309-8d43-92e565c15c91_2813x1875.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:970,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:173849,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://lcamtuf.substack.com/i/179419876?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3c9efcc-3be6-4309-8d43-92e565c15c91_2813x1875.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!0H2m!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3c9efcc-3be6-4309-8d43-92e565c15c91_2813x1875.png 424w, https://substackcdn.com/image/fetch/$s_!0H2m!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3c9efcc-3be6-4309-8d43-92e565c15c91_2813x1875.png 848w, https://substackcdn.com/image/fetch/$s_!0H2m!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3c9efcc-3be6-4309-8d43-92e565c15c91_2813x1875.png 1272w, https://substackcdn.com/image/fetch/$s_!0H2m!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3c9efcc-3be6-4309-8d43-92e565c15c91_2813x1875.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Traces for the three R-C stages.</em></figcaption></figure></div><p>Because the amplifier’s gain isn’t constrained in any way, the output waveform is a square wave. Nevertheless, in a lowpass circuit with these characteristics, the resulting waveforms are close enough to sinusoids that the sine-wave model approximates the behavior nearly perfectly. We can run a discrete-time simulation to show that the sine-wave behavior of these three R-C stages (gray) aligns pretty well with the square-wave case (blue):</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!ffXM!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13556ade-ffe1-42d1-8508-d35cc30ab114_2813x1875.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!ffXM!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13556ade-ffe1-42d1-8508-d35cc30ab114_2813x1875.png 424w, https://substackcdn.com/image/fetch/$s_!ffXM!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13556ade-ffe1-42d1-8508-d35cc30ab114_2813x1875.png 848w, https://substackcdn.com/image/fetch/$s_!ffXM!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13556ade-ffe1-42d1-8508-d35cc30ab114_2813x1875.png 1272w, https://substackcdn.com/image/fetch/$s_!ffXM!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13556ade-ffe1-42d1-8508-d35cc30ab114_2813x1875.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!ffXM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13556ade-ffe1-42d1-8508-d35cc30ab114_2813x1875.png" width="1456" height="970" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/13556ade-ffe1-42d1-8508-d35cc30ab114_2813x1875.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:970,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:145695,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://lcamtuf.substack.com/i/179419876?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13556ade-ffe1-42d1-8508-d35cc30ab114_2813x1875.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!ffXM!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13556ade-ffe1-42d1-8508-d35cc30ab114_2813x1875.png 424w, https://substackcdn.com/image/fetch/$s_!ffXM!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13556ade-ffe1-42d1-8508-d35cc30ab114_2813x1875.png 848w, https://substackcdn.com/image/fetch/$s_!ffXM!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13556ade-ffe1-42d1-8508-d35cc30ab114_2813x1875.png 1272w, https://substackcdn.com/image/fetch/$s_!ffXM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13556ade-ffe1-42d1-8508-d35cc30ab114_2813x1875.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>A simulation of a square &amp; sine wave passing through three R-C filters.</em></figcaption></figure></div><p>To make the output a sine wave, it’s possible to tinker with with the feedback loop to lower the circuit’s gain, but it’s hard to get it right; insufficient gain prevents oscillation while excess gain produces distortion. A simpler trick is to tap into the signal on the non-inverting leg (bottom oscilloscope trace) and use the other part of a dual op-amp IC to amplify this signal to your heart’s desire.</p><p><span>Some readers might be wondering why I designed the stages so that each of them has an impedance ten times larger than the stage before it. This is to prevent the filters from appreciably loading each other. If all the impedances were in the same ballpark, the middle filter could source currents from the left as easily as it could from the right. In that situation, finding the point of -180° phase shift with decent accuracy would require calculating the transfer function for the entire six-component Franken-filter; the task is doable but — to use a mathematical term — </span><a href="https://lcamtuf.substack.com/p/analog-filters-part-2-let-it-ring" rel="">rather unpleasant</a><span>.</span></p><p><em><span>Footnote: in the literature, the circuit is more often constructed using highpass stages and a discrete transistor as an amplifier. I’d wager that most authors who present the discrete-transistor solution have not actually tried it in practice; otherwise, they would have found it to be quite finicky. The version presented in this article is discussed </span><a href="https://www.electronicdesign.com/technologies/analog/article/21806012/simple-generator-provides-very-low-frequency-distortion-sine-and-square-waves" rel="">here</a><span>.</span></em></p><p><em>If you enjoyed the content, please subscribe. I’m not selling anything; it’s just a good way to stay in touch with the writers you like.</em></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Olmo 3: Charting a path through the model flow to lead open-source AI (346 pts)]]></title>
            <link>https://allenai.org/blog/olmo3</link>
            <guid>46001889</guid>
            <pubDate>Fri, 21 Nov 2025 06:50:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://allenai.org/blog/olmo3">https://allenai.org/blog/olmo3</a>, See on <a href="https://news.ycombinator.com/item?id=46001889">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content"><div><p>Language models are often treated as snapshots—brief captures of a long and carefully curated development process. But sharing only the end result obscures the rich context needed to modify, adapt, and extend a model's capabilities. Many meaningful adjustments require integrating domain-specific knowledge deep within the development pipeline, not merely at the final stage. To truly advance open AI development and research, the entire <em>model flow</em> – not just its endpoint – should be accessible and customizable. The model flow is the full lifecycle of an LM: every stage, checkpoint, dataset, and dependency required to create and modify it. By exposing this complete process, the goal is to engender greater trust and enable more effective adaptation, collaboration, and innovation.</p><p>With today's release of <strong>Olmo 3</strong>, we're empowering the open source community with not only state-of-the-art open models, but the entire model flow and full traceability back to training data.</p><p>At its center is <strong>Olmo 3-Think (32B)</strong>, the best fully open 32B-scale thinking model that for the first time lets you inspect intermediate reasoning traces and trace those behaviors back to the data and training decisions that produced them. Olmo 3 is a family of compact, dense models at 7 billion and 32 billion parameters that can run on everything from laptops to research clusters.</p><ul><li><strong>Olmo 3-Base (7B, 32B) </strong>is our most powerful base model yet. When evaluated on our expanded, diverse evaluation suite, Olmo 3-Base delivers the strongest performance among fully open base models – where training data, code, and weights are all publicly available, like Stanford's Marin and Swiss AI's Apertus – and achieves competitive performance with some of the best open-weights base models of comparable size and architecture, including Qwen 2.5 and Gemma 3. Achieving strong results in programming, reading comprehension, and math problem solving, Olmo 3-Base maintains performance at extended context lengths (~up to 65K tokens)—providing a versatile foundation for continued pretraining, targeted fine-tuning, and reinforcement learning and making it easy to build in specialized capabilities like reasoning, tool use (function calling), and instruction following through post-training.</li><li><strong>Olmo 3-Think (7B, 32B) </strong>is our flagship post-trained reasoning set built on Olmo 3-Base. At a time when few organizations are releasing truly open models at this scale, <strong>Olmo 3-Think (32B)</strong> serves as a workhorse for RL research, long-horizon reasoning, and other advanced experiments that require substantial compute. On our suite of reasoning benchmarks (discussed below), it's the strongest fully open thinking model we're aware of, narrowing the gap to the best open-weight models of similar scale – such as Qwen 3 32B – while training on roughly 6x fewer tokens. <strong>Olmo 3-Think (7B)</strong> brings the same design and training approach to an even more efficient form factor, surfacing intermediate thinking steps for complex prompts while making open, inspectable reasoning accessible on more modest hardware.</li><li><strong>Olmo 3-Instruct (7B)</strong> is a chat and quick-response focused post-train of Olmo 3-Base that handles multi-turn, instruction-following, tool use, and more. In our evaluations, it matches or outperforms open-weight models including Qwen 2.5, Gemma 3, and Llama 3.1, and narrows the gap with Qwen 3 model families at a similar scale—delivering a strong, fully open alternative for high-quality conversational and tool-using agents.</li><li><strong>Olmo 3-RL Zero (7B)</strong>, is a fully open reinforcement learning pathway built on Olmo 3-Base, designed to bootstrap complex reasoning behaviors and enable clear benchmarking of RL algorithms. We release four series of checkpoints from domain-focused training on math, code, instruction following, and general chat, enabling careful study of reinforcement learning with verifiable rewards (RLVR).</li></ul><p>Instead of a single set of frozen weights, Olmo 3 offers multiple, fully documented paths through development: the Instruct path for everyday chat and tool use, the RL Zero path for RL experimentation from base models, and the Think/reasoning path for models that leverage inference-time scaling to unlock complex reasoning and agentic behaviors. Each path is a concrete example of how to shape behavior from the same base model, and you’re free to fork or remix them—start with Olmo 3-Base, explore your own supervised fine-tuning (SFT) or direct preference optimization (DPO) recipe for instruct-style use cases, or plug in a new RL objective to probe different tradeoffs. The flow itself becomes a rich, reusable object—not just a record of how we built Olmo 3, but a scaffold for how you can build your own systems.</p><div><svg viewBox="0 0 1400 340" xmlns:xlink="http://www.w3.org/1999/xlink" role="img" aria-labelledby="flow-chart-title"><title id="flow-chart-title">Olmo 3 Model Flow</title><defs><marker id="arrow-head" markerWidth="8" markerHeight="8" refX="6" refY="3" orient="auto"><path d="M0,0 L0,6 L7,3 z" fill="var(--colors-dark-teal-100)"></path></marker></defs><g role="button" tabindex="0" aria-label="Pretraining" style="--highlight-stroke:var(--colors-teal-100)"><rect x="30" y="130" width="150" height="48" rx="24" fill="var(--colors-pink-100)"></rect><text x="105" y="154" text-anchor="middle" dominant-baseline="middle"><tspan x="105" dy="0">Pretraining</tspan></text></g><g role="button" tabindex="0" aria-label="Midtraining" style="--highlight-stroke:var(--colors-teal-100)"><rect x="228" y="130" width="150" height="48" rx="24" fill="var(--colors-pink-100)"></rect><text x="303" y="154" text-anchor="middle" dominant-baseline="middle"><tspan x="303" dy="0">Midtraining</tspan></text></g><g role="button" tabindex="0" aria-label="Long context" style="--highlight-stroke:var(--colors-teal-100)"><rect x="426" y="130" width="150" height="48" rx="24" fill="var(--colors-contrast-pink)"></rect><text x="501" y="154" text-anchor="middle" dominant-baseline="middle"><tspan x="501" dy="0">Long context</tspan></text></g><line x1="180" y1="154" x2="218" y2="154" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head)"></line><line x1="378" y1="154" x2="416" y2="154" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head)"></line><text x="501" y="115" text-anchor="middle">Olmo 3 Base</text><g><g><g role="button" tabindex="0" aria-label="Instruct SFT" style="--highlight-stroke:var(--colors-pink-100)"><rect x="656" y="20" width="150" height="48" rx="24" fill="var(--colors-teal-100)"></rect><text x="731" y="44" text-anchor="middle" dominant-baseline="middle"><tspan x="731" dy="0">Instruct SFT</tspan></text></g><line x1="806" y1="44" x2="844" y2="44" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head)"></line></g><g><g role="button" tabindex="0" aria-label="Instruct DPO" style="--highlight-stroke:var(--colors-pink-100)"><rect x="854" y="20" width="150" height="48" rx="24" fill="var(--colors-teal-100)"></rect><text x="929" y="44" text-anchor="middle" dominant-baseline="middle"><tspan x="929" dy="0">Instruct DPO</tspan></text></g><line x1="1004" y1="44" x2="1042" y2="44" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head)"></line></g><g><g role="button" tabindex="0" aria-label="Instruct RL" style="--highlight-stroke:var(--colors-pink-100)"><rect x="1052" y="20" width="150" height="48" rx="24" fill="var(--colors-teal-100)"></rect><text x="1127" y="44" text-anchor="middle" dominant-baseline="middle"><tspan x="1127" dy="0">Instruct RL</tspan></text></g></g><text x="1242" y="50">Olmo 3 Instruct</text></g><g><path d="M 576 154 H 606 V 154 H 646" fill="none" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head)"></path><g><g role="button" tabindex="0" aria-label="Thinking SFT" style="--highlight-stroke:var(--colors-pink-100)"><rect x="656" y="130" width="150" height="48" rx="24" fill="var(--colors-teal-100)"></rect><text x="731" y="154" text-anchor="middle" dominant-baseline="middle"><tspan x="731" dy="0">Thinking SFT</tspan></text></g><line x1="806" y1="154" x2="844" y2="154" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head)"></line></g><g><g role="button" tabindex="0" aria-label="Thinking DPO" style="--highlight-stroke:var(--colors-pink-100)"><rect x="854" y="130" width="150" height="48" rx="24" fill="var(--colors-teal-100)"></rect><text x="929" y="154" text-anchor="middle" dominant-baseline="middle"><tspan x="929" dy="0">Thinking DPO</tspan></text></g><line x1="1004" y1="154" x2="1042" y2="154" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head)"></line></g><g><g role="button" tabindex="0" aria-label="Thinking RL" style="--highlight-stroke:var(--colors-pink-100)"><rect x="1052" y="130" width="150" height="48" rx="24" fill="var(--colors-teal-100)"></rect><text x="1127" y="154" text-anchor="middle" dominant-baseline="middle"><tspan x="1127" dy="0">Thinking RL</tspan></text></g></g><text x="1242" y="160">Olmo 3 Think</text></g><g><path d="M 501 178 V 264 H 1042" fill="none" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head)"></path><g><g role="button" tabindex="0" aria-label="RL Zero" style="--highlight-stroke:var(--colors-pink-100)"><rect x="1052" y="240" width="150" height="48" rx="24" fill="var(--colors-teal-100)"></rect><text x="1127" y="264" text-anchor="middle" dominant-baseline="middle"><tspan x="1127" dy="0">RL Zero</tspan></text></g></g><text x="1242" y="270">Olmo 3 RL Zero</text></g><path d="M 731 130 V 68" fill="none" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head)"></path></svg><svg viewBox="0 0 900 1100" xmlns:xlink="http://www.w3.org/1999/xlink" role="img" aria-labelledby="flow-chart-title"><title id="flow-chart-title">Olmo 3 Model Flow</title><defs><marker id="arrow-head-vertical" markerWidth="8" markerHeight="8" refX="6" refY="3" orient="auto"><path d="M0,0 L0,6 L7,3 z" fill="var(--colors-dark-teal-100)"></path></marker></defs><g role="button" tabindex="0" aria-label="Pretraining" style="--highlight-stroke:var(--colors-teal-100)"><rect x="350" y="40" width="320" height="90" rx="24" fill="var(--colors-pink-100)"></rect><text x="510" y="85" text-anchor="middle" dominant-baseline="middle"><tspan x="510" dy="0">Pretraining</tspan></text></g><g role="button" tabindex="0" aria-label="Midtraining" style="--highlight-stroke:var(--colors-teal-100)"><rect x="350" y="240" width="320" height="90" rx="24" fill="var(--colors-pink-100)"></rect><text x="510" y="285" text-anchor="middle" dominant-baseline="middle"><tspan x="510" dy="0">Midtraining</tspan></text></g><g role="button" tabindex="0" aria-label="Long context" style="--highlight-stroke:var(--colors-teal-100)"><rect x="350" y="440" width="320" height="90" rx="24" fill="var(--colors-contrast-pink)"></rect><text x="510" y="485" text-anchor="middle" dominant-baseline="middle"><tspan x="510" dy="0">Long context</tspan></text></g><line x1="510" y1="130" x2="510" y2="232" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head-vertical)"></line><line x1="510" y1="330" x2="510" y2="432" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head-vertical)"></line><text x="510" y="25" text-anchor="middle">Olmo 3 Base</text><g><g><g role="button" tabindex="0" aria-label="Instruct SFT" style="--highlight-stroke:var(--colors-pink-100)"><rect x="10" y="690" width="260" height="80" rx="24" fill="var(--colors-teal-100)"></rect><text x="140" y="730" text-anchor="middle" dominant-baseline="middle"><tspan x="140" dy="0">Instruct SFT</tspan></text></g><line x1="140" y1="770" x2="140" y2="822" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head-vertical)"></line></g><g><g role="button" tabindex="0" aria-label="Instruct DPO" style="--highlight-stroke:var(--colors-pink-100)"><rect x="10" y="830" width="260" height="80" rx="24" fill="var(--colors-teal-100)"></rect><text x="140" y="870" text-anchor="middle" dominant-baseline="middle"><tspan x="140" dy="0">Instruct DPO</tspan></text></g><line x1="140" y1="910" x2="140" y2="962" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head-vertical)"></line></g><g><g role="button" tabindex="0" aria-label="Instruct RL" style="--highlight-stroke:var(--colors-pink-100)"><rect x="10" y="970" width="260" height="80" rx="24" fill="var(--colors-teal-100)"></rect><text x="140" y="1010" text-anchor="middle" dominant-baseline="middle"><tspan x="140" dy="0">Instruct RL</tspan></text></g></g><text x="140" y="1080" text-anchor="middle" dominant-baseline="middle">Olmo 3 Instruct</text></g><g><path d="M 510 530 V 682" fill="none" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head-vertical)"></path><g><g role="button" tabindex="0" aria-label="Thinking SFT" style="--highlight-stroke:var(--colors-pink-100)"><rect x="360" y="690" width="260" height="80" rx="24" fill="var(--colors-teal-100)"></rect><text x="490" y="730" text-anchor="middle" dominant-baseline="middle"><tspan x="490" dy="0">Thinking SFT</tspan></text></g><line x1="490" y1="770" x2="490" y2="822" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head-vertical)"></line></g><g><g role="button" tabindex="0" aria-label="Thinking DPO" style="--highlight-stroke:var(--colors-pink-100)"><rect x="360" y="830" width="260" height="80" rx="24" fill="var(--colors-teal-100)"></rect><text x="490" y="870" text-anchor="middle" dominant-baseline="middle"><tspan x="490" dy="0">Thinking DPO</tspan></text></g><line x1="490" y1="910" x2="490" y2="962" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head-vertical)"></line></g><g><g role="button" tabindex="0" aria-label="Thinking RL" style="--highlight-stroke:var(--colors-pink-100)"><rect x="360" y="970" width="260" height="80" rx="24" fill="var(--colors-teal-100)"></rect><text x="490" y="1010" text-anchor="middle" dominant-baseline="middle"><tspan x="490" dy="0">Thinking RL</tspan></text></g></g><text x="490" y="1080" text-anchor="middle" dominant-baseline="middle">Olmo 3 Think</text></g><g><path d="M 670 485 H 760 V 682" fill="none" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head-vertical)"></path><g><g role="button" tabindex="0" aria-label="RL Zero" style="--highlight-stroke:var(--colors-pink-100)"><rect x="630" y="690" width="260" height="80" rx="24" fill="var(--colors-teal-100)"></rect><text x="760" y="730" text-anchor="middle" dominant-baseline="middle"><tspan x="760" dy="0">RL Zero</tspan></text></g></g><text x="760" y="1080" text-anchor="middle" dominant-baseline="middle">Olmo 3 RL Zero</text></g><path d="M 360 730 H 315 V 730 H 270" fill="none" stroke="var(--colors-dark-teal-100)" stroke-width="2" marker-end="url(#arrow-head-vertical)"></path></svg><div role="region" aria-live="polite"><p>Click on any stage to learn more about it and download artifacts.</p></div></div><p>The Olmo 3 checkpoints we're releasing represent our initial paths targeting our goals around reasoning, tool use, and general capabilities – we have exciting plans for other ways to leverage Olmo 3-Base 32B. But because we're releasing the entire flow, you can intervene at any point: swap in domain-specific data during mid-training, adjust post-training for your use case, or build on an earlier checkpoint that better suits your needs.&nbsp;</p><p>As with <a data-current="false" href="https://allenai.org/blog/olmo-open-language-model-87ccfc95f580"><span>Olmo</span><svg><use href="#arrow-angled-svg"></use></svg></a> and <a data-current="false" href="https://allenai.org/blog/olmo2"><span>Olmo 2,</span><svg><use href="#arrow-angled-svg"></use></svg></a> we’re releasing all components of the Olmo 3 flow – data, code, model weights, and checkpoints – under permissive open source licenses.&nbsp;&nbsp;</p><p><a data-current="false" href="https://playground.allenai.org/?utm_source=ai2-blog&amp;utm_medium=referral&amp;utm_campaign=olmo3_launch"><span>Try Olmo 3</span><svg><use href="#arrow-angled-svg"></use></svg></a><strong> | </strong><a data-current="false" href="https://huggingface.co/collections/allenai/olmo-3-68e80f043cc0d3c867e7efc6"><span>Download the models &amp; data</span><svg><use href="#arrow-angled-svg"></use></svg></a> <strong>| </strong><a data-current="false" href="http://allenai.org/papers/olmo3"><span>Read the report</span><svg><use href="#arrow-angled-svg"></use></svg></a></p><h3><strong>Strong performance across the board</strong></h3><p>We run the Olmo 3 checkpoints through a broad, updated benchmark suite, grouping dozens of industry-standard tasks (plus a few new ones we introduce) into several capability clusters. Together, the clustered suite and these held-out tasks give us a capability profile of Olmo 3—a clear picture of how well it solves math problems, codes, uses tools, answers general-knowledge questions, and more.&nbsp;</p><p>At a high level, the Olmo 3 family delivers the strongest fully open base and thinking models we’re aware of. Olmo 3-Base 32B outperforms other fully open base models, and Olmo 3-Think 32B emerges as the strongest fully open thinking model.</p><p>Our results were made possible by rigorous data curation at every stage of training, a carefully designed training recipe for each model, and a set of new algorithmic and infrastructure advances across data processing, training, and reinforcement learning. We also introduce an enhanced reinforcement learning framework that guides the development of our models and is particularly essential for our thinking models. To design the training recipe and coordinate targeted improvements across a wide range of capabilities at each stage of the model training pipeline, our development framework balances distributed innovation with centralized evaluation.</p><p><strong>Olmo 3-Base, </strong>with a<strong> </strong>training pipeline that first focuses on broad coverage over diverse text, code, and math, then concentrates on harder distributions to sharpen programming, quantitative reasoning, and reading comprehension, is clearly the strongest set of <em><strong>fully</strong></em> open base models in our evaluations. It’s also arguably the best 32B model in the entire ecosystem of models with open weights, performing impressively in programming, reading comprehension, math problem solving, and long-context benchmarks like RULER, which tests information retrieval from lengthy texts. Olmo 3-Base (7B) and Olmo 3-Base (32) maintain quality at extended context lengths and integrate cleanly with RL workflows, providing a robust foundation for continued pretraining and post-training.</p><div>
<table><colgroup> <col> <col> <col> <col span="5"> </colgroup><thead><tr><th>Skill</th><th>Benchmark</th><th>Olmo 3-Base (32B)</th><th>Marin 32B</th><th>Apertus 70B</th><th>Qwen 2.5 32B</th><th>Gemma 3 27B</th><th>Llama 3.1 70B</th></tr></thead><tbody><tr><th rowspan="3">Math</th><td>GSM8k</td><td>80.5 <span>▲</span></td><td>69.1</td><td>63.0</td><td>81.1</td><td>81.3</td><td>81.2</td></tr><tr><td>GSM Symbolic</td><td>61.0</td><td>42.0</td><td>38.6</td><td>56.2</td><td>61.2</td><td>64.6</td></tr><tr><td>MATH</td><td>43.4</td><td>36.8</td><td>17.4</td><td>56.7</td><td>47.0</td><td>40.2</td></tr><tr><th rowspan="7">Code</th><td>BigCodeBench</td><td>43.9</td><td>34.5</td><td>24.0</td><td>48.1</td><td>44.0</td><td>43.4</td></tr><tr><td>HumanEval</td><td>66.5 <span>★</span></td><td>52.3</td><td>32.5</td><td>65.6</td><td>62.1</td><td>57.4</td></tr><tr><td>DeepSeek LeetCode</td><td>1.9</td><td>1.3</td><td>1.2</td><td>8.0</td><td>5.8</td><td>0.2</td></tr><tr><td>DS 1000</td><td>29.7</td><td>26.3</td><td>17.8</td><td>43.3</td><td>34.3</td><td>29.5</td></tr><tr><td>MBPP</td><td>60.2</td><td>52.1</td><td>37.6</td><td>69.8</td><td>60.0</td><td>55.5</td></tr><tr><td>MultiPL HumanEval</td><td>35.9</td><td>18.5</td><td>18.4</td><td>49.7</td><td>37.7</td><td>32.2</td></tr><tr><td>MultiPL MBPP</td><td>41.8</td><td>30.5</td><td>31.3</td><td>53.6</td><td>47.2</td><td>35.9</td></tr><tr><th rowspan="5">MC STEM</th><td>ARC MC</td><td>94.7</td><td>93.4</td><td>90.7</td><td>97.0</td><td>95.8</td><td>95.2</td></tr><tr><td>MMLU STEM</td><td>70.8</td><td>68.4</td><td>57.8</td><td>79.7</td><td>74.9</td><td>70.0</td></tr><tr><td>MedMCQA MC</td><td>57.6</td><td>61.8</td><td>55.9</td><td>68.8</td><td>64.7</td><td>67.8</td></tr><tr><td>MedQA MC</td><td>53.8</td><td>60.8</td><td>52.4</td><td>68.4</td><td>68.7</td><td>72.3</td></tr><tr><td>SciQ MC</td><td>95.5 <span>▲</span></td><td>95.1</td><td>93.3</td><td>97.1</td><td>96.8</td><td>95.4</td></tr><tr><th rowspan="11">MC Non-STEM</th><td>MMLU Humanities</td><td>78.3</td><td>78.9</td><td>74.1</td><td>85.0</td><td>80.5</td><td>83.4</td></tr><tr><td>MMLU Social Sci.</td><td>83.9</td><td>83.7</td><td>79.2</td><td>88.4</td><td>86.2</td><td>87.4</td></tr><tr><td>MMLU Other</td><td>75.1</td><td>75.4</td><td>70.1</td><td>81.2</td><td>80.2</td><td>79.4</td></tr><tr><td>CSQA MC</td><td>82.3</td><td>80.1</td><td>76.9</td><td>89.9</td><td>79.0</td><td>79.0</td></tr><tr><td>PiQA MC</td><td>85.6</td><td>90.5</td><td>79.0</td><td>93.3</td><td>90.3</td><td>91.5</td></tr><tr><td>SocialIQA MC</td><td>83.9</td><td>82.4</td><td>79.3</td><td>86.6</td><td>81.2</td><td>83.5</td></tr><tr><td>CoQA Gen2MC MC</td><td>96.4 <span>▲</span></td><td>93.9</td><td>87.5</td><td>96.8</td><td>95.8</td><td>95.1</td></tr><tr><td>DROP Gen2MC MC</td><td>87.2 <span>★</span></td><td>71.0</td><td>56.5</td><td>86.6</td><td>84.6</td><td>70.3</td></tr><tr><td>Jeopardy Gen2MC MC</td><td>92.3</td><td>95.3</td><td>93.2</td><td>97.0</td><td>95.9</td><td>97.1</td></tr><tr><td>NaturalQs Gen2MC MC</td><td>78.0</td><td>81.0</td><td>71.9</td><td>79.9</td><td>82.0</td><td>82.4</td></tr><tr><td>SQuAD Gen2MC MC</td><td>98.2 <span>★</span></td><td>97.6</td><td>95.7</td><td>97.9</td><td>97.7</td><td>97.7</td></tr><tr><th rowspan="9">GenQA</th><td>HellaSwag RC</td><td>84.8</td><td>87.2</td><td>84.5</td><td>86.3</td><td>86.0</td><td>88.4</td></tr><tr><td>Winogrande RC</td><td>90.3 <span>▲</span></td><td>90.5</td><td>87.7</td><td>87.5</td><td>91.3</td><td>91.7</td></tr><tr><td>Lambada</td><td>75.7</td><td>76.7</td><td>74.8</td><td>76.2</td><td>77.5</td><td>79.6</td></tr><tr><td>Basic Skills</td><td>93.5 <span>▲</span></td><td>91.1</td><td>87.5</td><td>94.2</td><td>94.9</td><td>92.4</td></tr><tr><td>DROP</td><td>81.0 <span>★</span></td><td>76.5</td><td>56.3</td><td>53.7</td><td>75.9</td><td>78.3</td></tr><tr><td>Jeopardy</td><td>75.3</td><td>80.5</td><td>77.2</td><td>74.0</td><td>82.1</td><td>84.0</td></tr><tr><td>NaturalQs</td><td>48.7</td><td>55.1</td><td>43.1</td><td>39.3</td><td>49.2</td><td>53.1</td></tr><tr><td>SQuAD</td><td>94.5 <span>★</span></td><td>94.4</td><td>90.7</td><td>64.9</td><td>92.4</td><td>92.9</td></tr><tr><td>CoQA</td><td>74.1 <span>★</span></td><td>70.7</td><td>72.8</td><td>40.4</td><td>12.4</td><td>73.9</td></tr><tr><th rowspan="4">Held-Out</th><td>BBH</td><td>77.6</td><td>70.1</td><td>58.8</td><td>81.1</td><td>77.4</td><td>80.8</td></tr><tr><td>MMLU Pro MC</td><td>49.6</td><td>48.1</td><td>39.6</td><td>61.1</td><td>53.1</td><td>50.4</td></tr><tr><td>Deepmind Math</td><td>30.1</td><td>26.7</td><td>20.1</td><td>40.7</td><td>30.4</td><td>40.3</td></tr><tr><td>LBPP</td><td>21.7</td><td>17.3</td><td>8.1</td><td>40.3</td><td>17.7</td><td>11.8</td></tr></tbody><caption>
<p><strong>★</strong> indicates an Olmo win among this subset. <strong>▲</strong> indicates Olmo is within 2.0 points of the best score. See our report for more comparisons.</p>
</caption></table></div><p><strong>Olmo 3-Think, </strong>which<strong> </strong>turns the Base into a reasoning model by training on multi-step problems spanning math, code, and general problem solving, then running the thinking SFT → thinking DPO → RLVR model flow to elicit high-quality reasoning traces, competes with or exceeds several open-weight reasoning models of similar sizes. On math benchmarks, Olmo 3-Think (7B) matches Qwen 3 8B on MATH and comes within a few points on AIME 2024 and 2025, and also leads all comparison models on HumanEvalPlus for coding—performing strongly on MBPP and LiveCodeBench to demonstrate particular strength in code-intensive reasoning. On broader reasoning tasks like BigBench Hard and AGI Eval English, Olmo 3-Think (7B) remains competitive with Qwen 3 8B reasoning and Qwen 3 VL 8B Thinker while staying fully open and slightly smaller.&nbsp;</p><p>For the 32B model, Olmo 3-Think scales these trends up and becomes one of the strongest fully open reasoning models in its class. Olmo 3-Think (32B) either wins or sits within roughly two points of the best open-weight model on MATH, OMEGA, BigBenchHard, HumanEvalPlus, PopQA, and IFEval. It ties Qwen 3 VL 32B Thinking for the top score on the OMEGA suite while staying clearly ahead of Gemma 3 27B Instruct and competitive with DeepSeek R1 Distill 32B on math and reasoning. On broader knowledge and QA, Olmo 3-Think (32B) is effectively neck-and-neck with the Qwen 3 models on PopQA. And in instruction following, Olmo 3-Think (32B) tops this subset on IFEval and remains solid on IFBench and AlpacaEval 2 LC—offering a strong default for reasoning workloads at the 32B scale.</p><div>
<table><colgroup> <col> <col> <col> <col span="4"> </colgroup><thead><tr><th>Skill</th><th>Benchmark</th><th>Olmo 3-Think (32B)</th><th>Qwen 3 32B</th><th>Qwen 3 VL 32B Thinking</th><th>Gemma 3 27B Instruct</th><th>DeepSeek R1 Distill 32B</th></tr></thead><tbody><tr><th rowspan="4">Math</th><td>MATH</td><td>96.1 <span>▲</span></td><td>95.4</td><td>96.7</td><td>87.4</td><td>92.6</td></tr><tr><td>AIME 2024</td><td>76.8</td><td>80.8</td><td>86.3</td><td>28.9</td><td>70.3</td></tr><tr><td>AIME 2025</td><td>72.5</td><td>70.9</td><td>78.8</td><td>22.9</td><td>56.3</td></tr><tr><td>OMEGA</td><td>50.8 <span>▲</span></td><td>47.7</td><td>50.8</td><td>24.0</td><td>38.9</td></tr><tr><th rowspan="3">Reasoning</th><td>BigBenchHard</td><td>89.8 <span>▲</span></td><td>90.6</td><td>91.1</td><td>82.4</td><td>89.7</td></tr><tr><td>ZebraLogic</td><td>76.0</td><td>88.3</td><td>96.1</td><td>24.8</td><td>69.4</td></tr><tr><td>AGI Eval English</td><td>88.2</td><td>90.0</td><td>92.2</td><td>76.9</td><td>88.1</td></tr><tr><th rowspan="3">Coding</th><td>HumanEvalPlus</td><td>91.4 <span>▲</span></td><td>91.2</td><td>90.6</td><td>79.2</td><td>92.3</td></tr><tr><td>MBPP+</td><td>68.0</td><td>70.6</td><td>66.2</td><td>65.7</td><td>70.1</td></tr><tr><td>LiveCodeBench v3</td><td>83.5</td><td>90.2</td><td>84.8</td><td>39.0</td><td>79.5</td></tr><tr><th rowspan="2">IF</th><td>IFEval</td><td>89.0 <span>★</span></td><td>86.5</td><td>85.5</td><td>85.4</td><td>78.7</td></tr><tr><td>IFBench</td><td>47.6</td><td>37.3</td><td>55.1</td><td>31.3</td><td>23.8</td></tr><tr><th rowspan="3">Knowledge &amp; QA</th><td>MMLU</td><td>85.4</td><td>88.8</td><td>90.1</td><td>74.6</td><td>88.0</td></tr><tr><td>PopQA</td><td>31.9 <span>▲</span></td><td>30.7</td><td>32.2</td><td>30.2</td><td>26.7</td></tr><tr><td>GPQA</td><td>58.1</td><td>67.3</td><td>67.4</td><td>45.0</td><td>61.8</td></tr><tr><th>Chat</th><td>AlpacaEval 2 LC</td><td>74.2</td><td>75.6</td><td>80.9</td><td>65.5</td><td>26.2</td></tr><tr><th>Safety</th><td>Safety</td><td>68.8</td><td>69.0</td><td>82.7</td><td>68.6</td><td>63.6</td></tr></tbody><caption>
<p><strong>★</strong> indicates an Olmo win among this subset. ▲ indicates Olmo is within 2.0 points of the best score. See our report for more comparisons.</p>
</caption></table></div><p><strong>Olmo 3-Instruct</strong>, which produces shorter sequences than the corresponding Olmo 3-Think models to improve inference efficiency and is designed to focus on general chat, tool use, and synthetic data generation, outperforms comparably-sized open-weight models. Olmo 3-Instruct ties or surpasses Qwen 2.5, Gemma 3, and Llama 3.1 in our evaluations, and competes with the Qwen 3 family at similar scale, delivering strong function calling performance and instruction-following capabilities in a fully open 7B model.</p><div><table><colgroup> <col> <col> <col> <col span="4"> </colgroup><thead><tr><th>Skill</th><th>Benchmark</th><th>Olmo 3-Instruct (7B)</th><th>Qwen 3 8B (no reasoning)</th><th>Qwen 3 VL 8B Instruct</th><th>Apertus 8B Instruct</th><th>Granite 3.3 8B Instruct</th></tr></thead><tbody><tr><th rowspan="4">Math</th><td>MATH</td><td>87.3</td><td>82.3</td><td>91.6</td><td>21.9</td><td>67.3</td></tr><tr><td>AIME 2024</td><td>44.3</td><td>26.2</td><td>55.1</td><td>0.5</td><td>7.3</td></tr><tr><td>AIME 2025</td><td>32.5</td><td>21.7</td><td>43.3</td><td>0.2</td><td>6.3</td></tr><tr><td>OMEGA</td><td>28.9</td><td>20.5</td><td>32.3</td><td>5.0</td><td>10.7</td></tr><tr><th rowspan="3">Reasoning</th><td>BigBenchHard</td><td>71.2</td><td>73.7</td><td>85.6</td><td>42.2</td><td>61.2</td></tr><tr><td>ZebraLogic</td><td>32.9</td><td>25.4</td><td>64.3</td><td>5.3</td><td>17.6</td></tr><tr><td>AGI Eval English</td><td>64.4</td><td>76.0</td><td>84.5</td><td>50.8</td><td>64.0</td></tr><tr><th rowspan="3">Coding</th><td>HumanEvalPlus</td><td>77.2</td><td>79.8</td><td>82.9</td><td>34.4</td><td>64.0</td></tr><tr><td>MBPP+</td><td>60.2</td><td>64.4</td><td>66.3</td><td>42.1</td><td>54.0</td></tr><tr><td>LiveCodeBench v3</td><td>29.5</td><td>53.2</td><td>55.9</td><td>7.8</td><td>11.5</td></tr><tr><th rowspan="2">IF</th><td>IFEval</td><td>85.6</td><td>86.3</td><td>87.8</td><td>71.4</td><td>77.5</td></tr><tr><td>IFBench</td><td>32.3 <span>▲</span></td><td>29.3</td><td>34.0</td><td>22.1</td><td>22.3</td></tr><tr><th rowspan="1">Knowledge</th><td>MMLU</td><td>69.1</td><td>80.4</td><td>83.6</td><td>62.7</td><td>63.5</td></tr><tr><th rowspan="2">QA</th><td>PopQA</td><td>14.1</td><td>20.4</td><td>26.5</td><td>N/A</td><td>28.9</td></tr><tr><td>GPQA</td><td>40.4</td><td>44.6</td><td>51.1</td><td>28.8</td><td>33.0</td></tr><tr><th rowspan="1">Chat</th><td>AlpacaEval 2 LC</td><td>40.9</td><td>49.8</td><td>73.5</td><td>8.1</td><td>28.6</td></tr><tr><th rowspan="3">Tool Use</th><td>SimpleQA</td><td>79.3</td><td>79.0</td><td>90.3</td><td>N/A</td><td>N/A</td></tr><tr><td>LitQA2</td><td>38.2 <span>▲</span></td><td>39.6</td><td>30.7</td><td>N/A</td><td>N/A</td></tr><tr><td>BFCL</td><td>49.8</td><td>60.2</td><td>66.2</td><td>N/A</td><td>N/A</td></tr><tr><th rowspan="1">Safety</th><td>Safety</td><td>87.3 <span>★</span></td><td>78.0</td><td>80.2</td><td>72.2</td><td>73.7</td></tr></tbody><caption>
<p>Results are the average of three runs. ★ indicates an Olmo win among this subset. <strong>▲</strong> indicates Olmo is within 2.0 points of the best score. See our report for more comparisons.</p>
</caption></table></div><h3><strong>The Olmo 3 architecture and training stages</strong></h3><p>Olmo 3 uses a decoder-only transformer architecture and multi-stage training pipeline. Pretraining runs in three stages—an initial large-scale training run that builds broad capabilities; a mid-training phase that focuses on harder material like math, code, and reading comprehension; and a final long-context extension stage that trains the model on very long documents. Together with architectural enhancements, this yields a more capable, efficient base for the Olmo 3 family.</p><p>Post-training then specializes the pretrained model for different use cases. Building on Olmo 2, each pathway follows a three-stage recipe – SFT, preference tuning with DPO, and RLVR – but in Olmo 3, we expose this as a fully documented model flow with complete customization over each training stage and dataset mix.</p><p>Instead of releasing only the final weights, we provide checkpoints from each major training milestone: the base pretrained model, the mid-trained model after targeted skill enhancement, the long-context-extended version, plus post-training checkpoints for the Olmo 3-Think, Olmo 3-Instruct, and Olmo 3-RL Zero flows. You can study how capabilities emerge over time, run ablations on specific stages, and fork the model at whatever point best fits your data, compute, and goals.</p><h3><strong>Expanded training data</strong></h3><p>Compared to Olmo 2, we scaled data collection and significantly strengthened our dataset curation methods. Continuing our commitment to full transparency, we’re releasing several new, higher-quality datasets that cover every stage of base model training and post-training—from initial learning to specialized skills like complex reasoning and long-context understanding. This means anyone can see exactly what data shaped the model’s capabilities, reproduce our results, and reuse these datasets to train their own AI systems.</p><p>Olmo 3 is pretrained on <strong>Dolma 3</strong>, a new ~9.3-trillion-token corpus drawn from web pages, science PDFs processed with <a data-current="false" href="https://olmocr.allenai.org/"><span>olmOCR</span><svg><use href="#arrow-angled-svg"></use></svg></a>, codebases, math problems and solutions, and encyclopedic text. From this pool, we construct <strong>Dolma 3 Mix</strong>, a 5.9-trillion-token (~6T) pretraining mix with a higher proportion of coding and mathematical data than earlier Dolma releases, plus much stronger decontamination via extensive deduplication, quality filtering, and careful control over data mixing. We follow established web standards in collecting training data and don’t collect from sites that explicitly disallow it, including paywalled content.</p><p>On top of this, we introduce two Dolma 3-based mixes for later stages of base model training. <strong>Dolma 3 Dolmino </strong>is our mid-training mix: 100B training tokens sampled from a ~2.2T-token pool of high-quality math, science, code, instruction-following, and reading-comprehension data, including reasoning traces that also enable RL directly on the base model. <strong>Dolma 3 Longmino</strong> is our long-context mix: ~50B training tokens drawn from a 639B-token pool of long documents combined with mid-training data to teach Olmo 3 to track information over very long inputs (like reports, logs, and multi-chapter documents).</p><p>We also introduce <strong>Dolci</strong>, a new post-training data suite tailored specifically for reasoning, tool use, and instruction following. Dolci provides separate mixes for each stage of post-training: SFT, DPO, and RLVR. For SFT, Dolci aggregates state-of-the-art datasets that advance step-by-step reasoning, tool use, and high-quality conversational behavior; for DPO, it supplies high-quality contrastive preference data; and for RL, it includes hard, diverse prompts across math, coding, instruction following, and general chat.&nbsp;</p><p>Together, Dolma 3 and Dolci give Olmo 3 a fully open data curriculum from first token to final post-trained checkpoint.</p><h3><strong>Efficient training stack</strong></h3><p>We pretrained Olmo 3 on a cluster of up to 1,024 H100 GPUs; we achieved training throughput of 7.7K tokens per device per second for Olmo 3-Base (7B). We mid-trained on 128 H100 GPUs, and post-trained on a set of 256 H100s.</p><p>For Olmo 3, building on the work we did for Olmo 2, we were able to significantly improve the efficiency of our post-training code. By moving SFT from Open Instruct (our post-training codebase, prioritizing flexibility) to Olmo Core (our pretraining codebase, designed to maximize efficiency), we increased throughput (tokens/second) by 8x. Similarly, by incorporating <a data-current="false" href="https://arxiv.org/abs/2509.19128"><span>in-flight weight updates</span><svg><use href="#arrow-angled-svg"></use></svg></a>, <a data-current="false" href="https://www.anyscale.com/blog/continuous-batching-llm-inference"><span>continuous batching</span><svg><use href="#arrow-angled-svg"></use></svg></a>, and a lot of threading improvements, we made our RL training 4x more efficient—resulting in training runs that are significantly cheaper and faster.&nbsp;</p><div>
    <table><colgroup> <col> <col span="4"> </colgroup><thead><tr><th>Improvement</th><th>Total tokens<br><span>(Mtok)</span></th><th>Speed<br><span>(Tokens/sec)</span></th><th>MFU<br><span>(%)</span></th><th>MBU<br><span>(%)</span></th></tr></thead><tbody><tr><th>Olmo 2</th><td>6.34</td><td>881</td><td>0.30</td><td>12.90</td></tr><tr><th>
<!-- -->
<!-- -->continuous batching<!-- -->
<!-- -->
</th><td>7.02</td><td>975</td><td>0.33</td><td>14.29</td></tr><tr><th>
<!-- -->
<!-- -->better threading<!-- -->
<!-- -->
</th><td>9.77</td><td>1358</td><td>0.46</td><td>19.89</td></tr><tr><th>
<!-- -->
<!-- -->inflight updates (Olmo 3)<!-- -->
<!-- -->
</th><td>21.23</td><td>2949</td><td>1.01</td><td>43.21</td></tr></tbody></table>
</div><p>A note on our 32B models: We believe 32B sits in a sweet spot for research and tinkering. 32B models are big enough to support strong, competitive performance, but still small enough that a wide audience can fine-tune and deploy them on accessible hardware.</p><p>For more details, including ablations, please read our <a data-current="false" href="https://allenai.org/papers/olmo3"><span>technical report</span><svg><use href="#arrow-angled-svg"></use></svg></a>.&nbsp;</p><h3><strong>Transparency at the core</strong></h3><p>A core goal of Olmo 3 is not just to <em>open</em> the model flow, but to make it <em>actionable</em> for people who want to understand and improve model behavior. Olmo 3 integrates with <a data-current="false" href="https://allenai.org/blog/olmotrace"><span><strong>OlmoTrace</strong></span><svg><use href="#arrow-angled-svg"></use></svg></a>, our tool for tracing model outputs back to training data in real time.</p><p>For example, in the Ai2 Playground, you can ask Olmo 3-Think (32B) to answer a general-knowledge question, then use OlmoTrace to inspect where and how the model may have learned to generate parts of its response. This closes the gap between training data and model behavior: you can see not only what the model is doing, but why—and adjust data or training decisions accordingly.</p><p>To further promote transparency and explainability, we’re making every training and fine-tuning dataset available for download, all under a permissive license that allows for custom deployment and reuse. The datasets come in a range of mixes to accommodate different storage and hardware constraints, from several billion tokens all the way up to 6 trillion.</p><p>Our new tooling for data processing allows you to de-contaminate, tokenize, and de-duplicate data in the same way we did for Olmo 3’s corpora. All the tooling is open source, enabling you to replicate our training curves or run controlled ablations across data mixes and objectives.&nbsp;</p><p>Our Olmo utilities and software cover the whole development cycle:</p><ul><li><a data-current="false" href="https://github.com/allenai/OLMo-core"><span><strong>Olmo-core</strong></span><svg><use href="#arrow-angled-svg"></use></svg></a> is a state-of-the-art framework for distributed model training.</li><li><a data-current="false" href="https://github.com/allenai/open-instruct"><span><strong>Open Instruct</strong></span><svg><use href="#arrow-angled-svg"></use></svg></a> is our post-training pipeline.&nbsp;</li><li><a data-current="false" href="https://github.com/allenai/datamap-rs"><span><strong>datamap-rs</strong></span><svg><use href="#arrow-angled-svg"></use></svg></a> is a pure-Rust toolkit for large-scale cleaning.</li><li><a data-current="false" href="https://github.com/allenai/duplodocus"><span><strong>duplodocus</strong></span><svg><use href="#arrow-angled-svg"></use></svg></a> for ultra-efficient fuzzy de-duplication.</li><li><a data-current="false" href="https://github.com/allenai/olmes"><span><strong>OLMES</strong></span><svg><use href="#arrow-angled-svg"></use></svg></a> is a toolkit for reproducible evals. It includes our brand-new eval collection <strong>OlmoBaseEval</strong>, which we used for Olmo 3 base model development.</li><li><a data-current="false" href="https://github.com/allenai/decon"><span><strong>decon</strong></span><svg><use href="#arrow-angled-svg"></use></svg></a> removes test sets from training data.</li></ul><p>Importantly, our tooling allows you to instrument complex tasks and analyze intermediate traces to understand where the models succeed—or struggle. Because the Olmo 3 data recipes, training pipeline, and checkpoints are open, independent teams can connect model behavior back to measurable properties.&nbsp;</p><h3><strong>Ready to deploy and use</strong></h3><p>Together, the Olmo 3 family makes it easier to build trustworthy features quickly, whether for research, education, or applications. By making every development step available and inspectable, we're enabling entirely new categories of research. You can run experiments on any training phase, understand exactly how different techniques contribute to model capabilities, and build on our work at whatever stage makes sense for your project.</p><p>For scientists, the fully open flow exposes the model’s inner workings, so you can instrument experiments across coding, reasoning, RL, and tool use.&nbsp;</p><p>If you care about AI you can study, audit, and improve, Olmo 3 is for you. Try the demos in the Ai2 Playground, explore the documentation, and build on the released weights and checkpoints. Then tell us what you discover—we invite the community to validate, critique, and extend our findings.</p><p>True openness in AI isn't just about access—it's about trust, accountability, and shared progress. We believe the models shaping our future should be fully inspectable, not black boxes. Olmo 3 represents a different path: one where anyone can understand, verify, and build upon the AI systems that increasingly influence our world. This is what open-first means—not just releasing weights, but sharing the complete knowledge needed to advance AI responsibly:&nbsp;the flow.</p><p><a data-current="false" href="https://playground.allenai.org/?utm_source=ai2-blog&amp;utm_medium=referral&amp;utm_campaign=olmo3_launch"><span>Try Olmo 3</span><svg><use href="#arrow-angled-svg"></use></svg></a><strong> | </strong><a data-current="false" href="https://huggingface.co/collections/allenai/olmo-3-68e80f043cc0d3c867e7efc6"><span>Download the models &amp; data</span><svg><use href="#arrow-angled-svg"></use></svg></a> <strong>| </strong><a data-current="false" href="http://allenai.org/papers/olmo3"><span>Read the report</span><svg><use href="#arrow-angled-svg"></use></svg></a></p></div><section><div><p>Deep dive with Olmo lead researchers Hanna Hajishirzi and Noah Smith on how – and why – we built Olmo 3, and what comes next:</p></div><figure><p><a target="_blank" rel="noopener noreferrer" aria-label="View Olmo 3 | A family of leading fully open LMs and complete model flow on YouTube" href="https://youtube.com/watch?v=7A2_YPtN1Eo"><span><img alt="" loading="lazy" decoding="async" data-nimg="fill" sizes="100vw" srcset="https://allenai.org/_next/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2F7A2_YPtN1Eo%2Fmaxresdefault.jpg&amp;w=640&amp;q=75 640w, https://allenai.org/_next/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2F7A2_YPtN1Eo%2Fmaxresdefault.jpg&amp;w=750&amp;q=75 750w, https://allenai.org/_next/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2F7A2_YPtN1Eo%2Fmaxresdefault.jpg&amp;w=828&amp;q=75 828w, https://allenai.org/_next/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2F7A2_YPtN1Eo%2Fmaxresdefault.jpg&amp;w=1080&amp;q=75 1080w, https://allenai.org/_next/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2F7A2_YPtN1Eo%2Fmaxresdefault.jpg&amp;w=1200&amp;q=75 1200w, https://allenai.org/_next/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2F7A2_YPtN1Eo%2Fmaxresdefault.jpg&amp;w=1920&amp;q=75 1920w, https://allenai.org/_next/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2F7A2_YPtN1Eo%2Fmaxresdefault.jpg&amp;w=2048&amp;q=75 2048w, https://allenai.org/_next/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2F7A2_YPtN1Eo%2Fmaxresdefault.jpg&amp;w=3840&amp;q=75 3840w" src="https://allenai.org/_next/image?url=https%3A%2F%2Fi.ytimg.com%2Fvi%2F7A2_YPtN1Eo%2Fmaxresdefault.jpg&amp;w=3840&amp;q=75"><span><svg><use href="#play-svg"></use></svg></span></span></a></p></figure></section><section><h2>Subscribe to receive monthly updates about the latest Ai2 news.</h2></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nursing excluded as 'professional' degree by Department of Education (140 pts)]]></title>
            <link>https://nurse.org/news/nursing-excluded-as-professional-degree-dept-of-ed/</link>
            <guid>46000015</guid>
            <pubDate>Fri, 21 Nov 2025 01:00:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nurse.org/news/nursing-excluded-as-professional-degree-dept-of-ed/">https://nurse.org/news/nursing-excluded-as-professional-degree-dept-of-ed/</a>, See on <a href="https://news.ycombinator.com/item?id=46000015">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                        <p>The U.S. Department of Education has officially excluded nursing in its recently revamped definition of “professional degree” programs. This change occurs as part of the implementation of President Trump’s "<a href="https://www.congress.gov/bill/119th-congress/house-bill/1/text" target="_blank">One Big Beautiful Bill Act</a>" (OBBBA) and has nursing organizations nationwide raising alarms.&nbsp;</p>


<p>Why? Because the reclassification directly impacts how graduate nursing students access federal loans and loan forgiveness programs.&nbsp;</p>
<p>It also, according to some critics, threatens already-existing stereotypes about the nursing profession and could make an already critical nursing shortage even worse.&nbsp;</p>


<p>The OBBA caps undergraduate loans and eliminates the GRAD PLUS program for graduate and professional students, while creating a new Repayment Assistance Plan (RAP). Under the new plan, only students pursuing a "professional" degree can borrow up to $50,000 annually.&nbsp;</p>
<p>To clarify who can access that money as a professional student, the Department of Education categorized the following programs as professional:&nbsp;</p>
<ul>
<li>Medicine</li>
<li>Pharmacy</li>
<li>Dentistry</li>
<li>Optometry</li>
<li>Law</li>
<li>Veterinary medicine</li>
<li>Osteopathic medicine</li>
<li>Podiatry</li>
<li>Chiropractic</li>
<li>Theology</li>
<li>Clinical psychology</li>
</ul>
<p>Notably excluded from that list?</p>
<p>Nurse practitioners, along with physician assistants and physical therapists.&nbsp;</p>

<p>In simple terms, becoming an advanced practice nurse just got harder and more expensive. Graduate nursing students, already burdened with high tuition, will lose financial benefits reserved for professional degree programs. This could deter prospective students, especially those from underrepresented or economically disadvantaged backgrounds.</p>
<p>Leading nursing organizations also say the move could lower the application and graduation rates of RNs, as all graduate nursing programs first require graduation from an RN program. While some RNs may go into school with the intent of furthering their education, not all do, and many may choose to work at the bedside in the interim or to gain experience.&nbsp;</p>
<p>Without the ability to feel like they have a future in nursing, some prospective students may opt to choose a different career altogether.&nbsp;</p>

<p>Nursing organizations like the American Nurses Association (ANA) and the American Association of Colleges of Nursing (AACN) are fighting back, arguing that nursing meets all the criteria for a professional discipline—rigorous education, licensure, and, of course, surviving on caffeine during night shifts.</p>

<p>In their official statement, the AACN <a href="https://www.aacnnursing.org/news-data/all-news/article/aacn-alarmed-over-department-of-educations-proposed-limitation-of-student-loan-access-for-nursing" target="_blank">declares</a>:</p>
<p>"Excluding nursing from the definition of professional degree programs disregards decades of progress toward parity across the health professions and contradicts the Department’s own acknowledgment that professional programs are those leading to licensure and direct practice. AACN recognizes that explicitly including post-baccalaureate nursing education as professional is essential for strengthening the nation’s healthcare workforce, supporting the next generation of nurses, and ultimately supporting the healthcare of patients in communities across the country."</p>
<p>The ANA also <a href="https://www.nursingworld.org/news/news-releases/2025/statement-from-the-american-nurses-association-on-proposed-federal-loan-policy-changes/" target="_blank">expressed</a> 'concern' over the Department of Education's decision and is urging the administration to reconsider, noting that nurses are the 'backbone' of the nation's health system.&nbsp;</p>
<p>“At a time when healthcare in our country faces a historic nurse shortage and rising demands, limiting nurses’ access to funding for graduate education threatens the very foundation of patient care," said Jennifer Mensik Kennedy, PhD, MBA, RN, NEA-BC, FAAN, president of the American Nurses Association in the <a href="https://www.nursingworld.org/news/news-releases/2025/statement-from-the-american-nurses-association-on-proposed-federal-loan-policy-changes/" target="_blank">ANA's statement:</a></p>
<p>&nbsp;"In many communities across the country, particularly in rural and underserved areas, advanced practice registered nurses ensure access to essential, high-quality care that would otherwise be unavailable. We urge the Department of Education to recognize nursing as the essential profession it is and ensure access to loan programs that make advanced nursing education possible.”</p>


<p>The U.S. is still grappling with pandemic workforce losses, and demand for nurses is skyrocketing. According to <a href="https://www.aacnnursing.org/news-data/all-news/schools-of-nursing-enrollment-increases-across-most-program-levels-signaling-strong-interest-in-nursing-careers" target="_blank">2024 statistics</a>, over 267,000 students are enrolled in Bachelor of Science in Nursing (BSN) programs.&nbsp;</p>
<p>These students are the future of healthcare, but if advanced education becomes financially out of reach, what happens next?</p>
<p>"There is no question that this is a gut punch for nursing," Patricia (Polly) Pittman, a professor of health policy and management and director of the Fitzhugh Mullan Institute for Health Workforce Equity at George Washington University, told <a href="https://www.newsweek.com/nursing-not-professional-degree-trump-admin-11079650" target="_blank"><em>Newsweek</em></a>, adding:&nbsp;</p>
<p>"Education, including from  to ADN to BSN, and then beyond to become an advanced practice nurse, is the single best way to retain nurses, especially in rural and underserved communities. At a symbolic level, it is also deeply insulting to nurses who have fought so hard to be recognized for their critical contributions to health care."</p>

<p>As of right now, there is nothing to do but wait and see if the Department of Education updates its decision to include graduate nursing degrees in the "professional degree" distinction.</p>
<p>Currently, the new measures are scheduled to be implemented starting July 1, 2026.</p>
<p>You can stay tuned for updates from groups like the ANA and AACN. If you’re a student, explore all financial aid options in the meantime, especially if you have plans to advance your career at the post-graduate level.</p>
<h3><strong>🤔<span>Nurses, share your thoughts below.&nbsp;</span></strong></h3>
<p>If you have a nursing news story that deserves to be heard, we want to amplify it to our massive community of millions of nurses! Get your story in front of Nurse.org Editors now -<a href="https://docs.google.com/forms/d/e/1FAIpQLSfYxatRZ81FgQqd6HB9nJ5fgGeA4M1g6OQ6yF0szUm8SkmnqQ/viewform?usp=sf_link" target="_blank"> <strong>click here to fill out our quick submission form today!</strong></a></p>




                        
                        
                        
                        
                        

                        
                        
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why top firms fire good workers (130 pts)]]></title>
            <link>https://www.rochester.edu/newscenter/employee-turnover-why-top-firms-churn-good-workers-681832/</link>
            <guid>45999872</guid>
            <pubDate>Fri, 21 Nov 2025 00:36:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rochester.edu/newscenter/employee-turnover-why-top-firms-churn-good-workers-681832/">https://www.rochester.edu/newscenter/employee-turnover-why-top-firms-churn-good-workers-681832/</a>, See on <a href="https://news.ycombinator.com/item?id=45999872">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<h2>Elite firms’ notorious ‘revolving door’ culture isn’t arbitrary but a rational way to signal talent and boost profits, a new study finds.</h2>
<p>Why do the world’s most prestigious firms—such as McKinsey, Goldman Sachs and other elite consulting giants, investment banks, and law practices—hire the brightest talents, train them intensively, and then, after a few years, send many of them packing? A <a href="https://www.aeaweb.org/articles?id=10.1257/aer.20200169">recent study</a> in the&nbsp;<em>American Economic Review</em>&nbsp;concludes that so-called adverse selection is not a flaw but rather a sign that the system is working precisely as intended.</p>
<p>Two financial economists, from the <a href="https://www.rochester.edu/">University of Rochester</a> and the University of Wisconsin–Madison respectively, created a model that explains how reputation, information, and retention interact in professions where skill is essential and performance is both visible and attributable to a specific person, particularly in fields such as law, consulting, fund asset management, auditing, and architecture. They argue that much of the professional services world operates through “intermediaries”—firms that both hire employees (also referred to as “agents” or “managers”) and market their expertise to clients—because clients can’t themselves easily judge a worker’s ability from the outset.</p>
<p>“Identifying skilled professionals is critical yet presents a major challenge for clients,” the researchers write. “Some of the firm’s employees are high-quality managers,” says coauthor <a href="https://simon.rochester.edu/faculty/ron-kaniel">Ron Kaniel</a>, the Jay S. and Jeanne P. Benet Professor of Finance at the University’s <a href="https://simon.rochester.edu/">Simon Business School</a>, “but the firm is paying them less than their actual quality, because initially the employees don’t have a credible way of convincing the outside world that they are high-quality.”</p>
<h3><strong>‘Churning’ to boost reputation</strong></h3>
<p>At the start of an employee’s career, the firm has an advantage, Kaniel and his coauthor Dmitry Orlov contend, because the firm (“the mediator”) can assess an employee’s talent more accurately than outside clients can. During what the authors call “quiet periods,” the firm keeps those who perform adequately and pays them standard wages.</p>
<p>Workers accept being underpaid temporarily because remaining at a top firm signals their elite status to the market.</p>
<p>Over time, however, an employee’s public performance—measured by successful cases, profitable investments, or well-executed projects—reduces the firm’s informational advantage. As the informational gap shrinks, the firm needs to pay some employees more because clients are now able to observe an employee’s good performance and hence update their beliefs about the employee’s skills.</p>
<p>“At some point, the informational advantage becomes fairly small,” says Kaniel, “and the firm says, ‘Well, I will basically start to churn. I will let go of some employees, and by doing that, I can actually extract more from the remaining ones.’”</p>
<p>Ironically, to the client these churned—or strategically fired—employees look just as good as the ones whom the firm kept. Churning happens not because these employees have failed but because they may be just somewhat lower-skilled than their peers. Subsequently, churning heightens both the reputation of the firm and of the employees who remain.</p>
<h3><strong>A paradoxical equilibrium</strong></h3>
<p>Somewhat counterintuitively, the researchers show that churning can benefit both sides. Workers who stay on with an elite firm accept lower pay in the short run as the tradeoff for building a stronger reputation for themselves. When these workers eventually leave the elite firms, they can command higher fees directly from clients.</p>
<p>What looks like a ruthless system of constant employee turnover is, in fact, a finely tuned mechanism that helps the market discover and reward true talent.</p>
<p>As a result of the churning, the informational gap between firm and client keeps shrinking because the client catches up to what the firm knows about its workers and which ones it values most. At first glance, the duo argues, the firm’s reduced informational advantage should now cause a further drop in profits. But here comes the strategic twist: The firm starts to underpay those better workers who kept their jobs, akin to making them pay for being “chosen.” Consequently, profits do not decline and may even increase.</p>
<p>“Firms now essentially can threaten the remaining employees: ‘Look, I can let you go, and everybody’s going to think that you’re the worst in the pool. If you want me not to let you go, you need to accept below market wages,’” says Kaniel.</p>
<p>The result is a paradoxical but stable equilibrium. Workers accept being underpaid temporarily because remaining at a top firm serves as a signal to the market about their elite status. It also helps explain why prestigious employers can attract ambitious newcomers despite grueling hours and relatively modest starting pay.</p>
<p>Meanwhile, those who are let go aren’t failures—rather, their exit is part of a system that signals who’s truly top-tier, the researchers argue. In fact, fired workers often find success on their own because potential clients interpret a person’s prior affiliation with a top firm as proof of the worker’s strong ability and qualifications.</p>
<p>In short, the “up-or-out” path of professional life may not just be a cultural phenomenon among top professional service firms but also an efficient response to how reputation is maintained and information flows. What looks like a ruthless system of constant turnover, the researchers argue, is in reality a finely tuned mechanism that helps the market discover and reward true talent.</p>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Homeschooling hits record numbers (160 pts)]]></title>
            <link>https://reason.com/2025/11/19/homeschooling-hits-record-numbers/</link>
            <guid>45999842</guid>
            <pubDate>Fri, 21 Nov 2025 00:31:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://reason.com/2025/11/19/homeschooling-hits-record-numbers/">https://reason.com/2025/11/19/homeschooling-hits-record-numbers/</a>, See on <a href="https://news.ycombinator.com/item?id=45999842">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							<p>Whether called homeschooling or DIY education, family-directed learning has been growing in popularity for years in the U.S. alongside disappointment in the rigidity, politicization, and flat-out poor results of traditional public schools. That growth was supercharged during the COVID-19 pandemic when extended closures and bumbled remote learning drove many families to experiment with teaching their own kids. The big question was whether the end of public health controls would also curtail interest in homeschooling. We know now that it didn't. Americans' taste for DIY education is on the rise.</p>

                <div data-form-theme="orbital" data-form-index="0" id="gform_wrapper_19">
                            <h2>The Rattler Article Inline Signup</h2>
                            <p><strong>You are reading <em>The Rattler</em> from J.D. Tuccille and <i>Reason</i>. Get more of J.D.'s commentary on government overreach and threats to everyday liberty.</strong></p>
                        </div>

<h2>Homeschooling Grows at Triple the Pre-Pandemic Rate</h2>
<p>"In the 2024-2025 school year, homeschooling continued to grow across the United States, increasing at an average rate of 5.4%," Angela Watson of the Johns Hopkins University School of Education's Homeschool Hub <a href="https://education.jhu.edu/edpolicy/policy-research-initiatives/homeschool-hub/homeschool-growth-2024-2025/">wrote</a> earlier this month. "This is nearly three times the pre-pandemic homeschooling growth rate of around 2%." She added that more than a third of the states from which data is available report their highest homeschooling numbers ever, even exceeding the peaks reached when many public and private schools were closed during the pandemic.</p>
<p>After COVID-19 public health measures were suspended, there was a brief drop in homeschooling as parents and families returned to old habits. That didn't last long. Homeschooling began <a href="https://education.jhu.edu/edpolicy/policy-research-initiatives/homeschool-hub/homeschool-growth-2023-2024/">surging again in the 2023-2024 school year</a>, with that growth continuing last year. Based on numbers from 22 states (not all states have released data, and many don't track homeschoolers), four report declines in the ranks of homeschooled children—Delaware, the District of Columbia, Hawaii, and Tennessee—while the others report growth from around 1 percent (Florida and Louisiana) to as high as 21.5 percent (South Carolina).</p>
<p>The latest figures likely underestimate growth in homeschooling since not all DIY families abide by registration requirements where they exist, and because families who use the portable funding available through increasingly popular <a href="https://www.edchoice.org/school-choice/education-savings-account/">Education Savings Accounts</a> to pay for homeschooling costs are not counted as homeschoolers in several states, Florida included. As a result, adds Watson, "we consider these counts as the minimum number of homeschooled students in each state."</p>
<p>Recent estimates put the total homeschooling population at about <a href="https://www.educationnext.org/new-u-s-census-bureau-data-confirm-growth-in-homeschooling-amid-pandemic/">6 percent of students</a> across the United States, compared to about 3 percent pre-pandemic. Continued growth necessarily means the share of DIY-educated students is increasing. That's quite a change for an education approach that was decidedly not mainstream just a generation ago.</p>
<p>"This isn't a pandemic hangover; it's a fundamental shift in how American families are thinking about education," comments Watson.</p>
<h2>Students Flee Traditional Public Schools for Alternatives</h2>
<p>Homeschooling is a major beneficiary of changing education preferences among American families, but it's not the only one.</p>
<p>"Five years after the pandemic's onset, there has been a substantial shift away from public schools and toward non-public options," Boston University's Joshua Goodman and Abigail Francis <a href="https://www.educationnext.org/school-enrollment-shifts-five-years-after-pandemic-public-education-shrinking-middle-schools/">wrote</a> last summer for <em>Education Next</em>. Looking at Massachusetts—not the friendliest regulatory environment for alternatives to traditional public schooling—they found that as the state's school-age population shrank by 2.6 percent since 2019, there has been a 4.2 percent decline in local public-school enrollment, a 0.7 decline in private-school enrollment, and a 56 percent increase in homeschooling. "Charter school enrollment is flat, due in part to regulatory limitations in Massachusetts," they added.</p>
<p>In <a href="https://www.brookings.edu/articles/declining-public-school-enrollment/">research</a> published in August, Dylan Council, Sofoklis Goulas, and Faidra Monachou of the Brookings Institution found similar results at the national level. "The COVID-19 pandemic forced millions of families to rethink where and how their children learn, and the effects continue to reshape American K-12 education," they observed. If "parents keep choosing alternatives at the pace observed since 2020, traditional public schools could lose as many as 8.5 million students, shrinking from 43.06 million in 2023-24 to as few as 34.57 million by mid-century."</p>
<p>It's not difficult to figure out what pushes parents to seek out alternatives and to flock to the various forms of DIY education grouped under the homeschooling heading.</p>
<h2>Disappointment in Public Schools Drives the Shift</h2>
<p>"The fraction of parents saying K-12 education is heading in the wrong direction was fairly stable from 2019 to 2022 but rose in 2023 and then again in 2024 to its highest level in a decade, suggesting continuing or even growing frustration with schools," commented Goodman and Francis.</p>
<p>Specifically, EdChoice's <a href="https://www.edchoice.org/schooling-in-america-survey-dashboard/">Schooling in America survey</a> puts the percentage of school parents saying that K-12 education is headed in the right direction at 41 percent—down from 48 percent in 2022 (the highest score recorded). Fifty-nine percent say K-12 education is on the wrong track—up from 52 percent in 2021 (the lowest score recorded).</p>
<p>When asked if they are <a href="https://www.edchoice.org/schooling-in-america-survey-dashboard/">satisfied with their children's education</a>, public school parents consistently rank last after parents who choose private schools, homeschooling, and charter schools. Importantly, among all parents of school-age children, homeschooling enjoys a 70 percent favorability rating.</p>
<p>The reasons for the move away from public schools certainly vary from family to family, but there have been notable developments in recent years. During the pandemic, many parents discovered that their preferences regarding school closures and health policies were <a href="https://x.com/DeAngelisCorey/status/1787486168637952038">anything <em>but</em> a priority</a> for educators.</p>
<p>Closures also gave parents a chance to experience public schools' competence with remote learning, and many were <a href="https://medium.com/@jdfedtransformer/are-you-a-parent-who-is-frustrated-by-remote-learning-ec616738eae7">unimpressed</a>. They have also been unhappy with the <a href="https://reason.com/2025/01/31/years-after-the-pandemic-the-lowest-performing-students-are-still-significantly-behind/">poor quality</a> and <a href="https://www.edweek.org/leadership/how-politics-are-straining-parent-school-relationships/2022/02">often politicized lessons</a> taught to their children that infuriatingly blend declining learning outcomes with indoctrination. That doesn't mean parents all want the same things, but the one-size-fits-some nature of public schooling make curriculum battles inevitable—and push many towards the exits in favor of alternatives including, especially, homeschooling. The shift appears to be here to stay.</p>
<p>"What's particularly striking is the resilience of this trend," concludes Watson of Johns Hopkins University's Homeschool Hub. "States that saw declines have bounced back with double-digit growth, and we're seeing record enrollment numbers across the country."</p>
<p>Once an alternative way to educate children, homeschooling is now an increasingly popular and mainstream option.</p>
						</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Prozac 'no better than placebo' for treating children with depression, experts (178 pts)]]></title>
            <link>https://www.theguardian.com/society/2025/nov/20/prozac-no-better-than-placebo-for-treating-children-with-depression-experts-say</link>
            <guid>45999622</guid>
            <pubDate>Fri, 21 Nov 2025 00:02:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/society/2025/nov/20/prozac-no-better-than-placebo-for-treating-children-with-depression-experts-say">https://www.theguardian.com/society/2025/nov/20/prozac-no-better-than-placebo-for-treating-children-with-depression-experts-say</a>, See on <a href="https://news.ycombinator.com/item?id=45999622">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Clinical guidelines should no longer recommend Prozac for children, according to experts, after <a href="https://www.jclinepi.com/article/S0895-4356%2825%2900349-X/fulltext" data-link-name="in body link">research showed</a> it had no clinical benefit for treating depression in children and adolescents.</p><p>Globally <a href="https://www.who.int/news-room/fact-sheets/detail/adolescent-mental-health" data-link-name="in body link">one in seven 10- to 19-year-olds have a mental health condition</a>, according to the World Health Organization. In the UK, about <a href="https://www.theguardian.com/society/2025/jun/26/young-people-england-common-mental-health-conditions-nhs-survey" data-link-name="in body link">a quarter of older teenagers</a> and up to a fifth of younger children have anxiety, depression or other mental health problems.</p><p>In the UK, National Institute for Health and Care Excellence (Nice) guidance says under-18s with moderate to severe depression <a href="https://www.nice.org.uk/guidance/ng134" data-link-name="in body link">can be prescribed antidepressants alongside therapy</a>.</p><p>But a new review of trial data by academics in Austria and the UK concluded that fluoxetine, sold under the brand name of Prozac among others, is clinically no better than placebo drugs in treating depression in children, and should therefore no longer be prescribed to them.</p><p>The authors conducted a meta analysis of 12 large trials involving Prozac, published between 1997 and 2024, and concluded that fluoxetine improved children’s depressive symptoms so little as to not be considered clinically meaningful.</p><p>“Consider the analogy of a weight-loss drug that is better than placebo at producing weight loss, but the difference is only 100 grams,” said Martin Plöderl, a clinical psychologist at Paracelsus Medical University in Salzburg, Austria, and lead author of the study. “This difference is unlikely to be noticeable to the patient or their doctors or produce any difference in their overall condition.”</p><p>The study, published in the <a href="https://www.jclinepi.com/" data-link-name="in body link">Journal of Clinical Epidemiology</a>, identified a “novelty bias” in early trials, which were likely to be more positive, while later studies fail to confirm these effects. It concludes that the potential risks of harmful side-effects of fluoxetine are likely to outweigh any potential clinical benefit.</p><p>The most common side-effects experienced by children on antidepressants are weight gain, sleep disturbance and concentration problems. They can also increase suicidal ideation.</p><figure id="ae6094b8-5c6d-482b-930a-decf0cd4b57f" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:8,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Children detained under Mental Health Act held for hours in A&amp;E departments&quot;,&quot;elementId&quot;:&quot;ae6094b8-5c6d-482b-930a-decf0cd4b57f&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/society/2025/sep/12/children-mental-health-act-accident-emergency-departments-england-wales&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:0,&quot;display&quot;:0,&quot;theme&quot;:0}}"></gu-island></figure><p>The authors also examined clinical guidelines in the US and Canada and found that just as in the UK, they ignored evidence that Prozac was clinically equivalent to placebo and continued to recommend its use for children and adolescents with depression.</p><p>Mark Horowitz, an associate professor of psychiatry at Adelaide University and a co-author of the study, said: “Fluoxetine is clearly clinically equivalent to placebo in its benefits, but is associated with greater side effects and risks. It is difficult to see how anyone can justify exposing young people to a drug with known harms when it has no advantage over placebo in its benefits.</p><p>“Guidelines should not recommend treatments that are equivalent to placebo. Many clinicians take the common-sense approach that we should seek to understand why the young person feels depressed and address the factors that are contributing to it.</p><p>“Guidelines in the UK and around the world currently recommend treatments for children with depression that are not in line with the best evidence. This exposes young people to the risks of medication without any benefit over placebo.”</p><p>The long-term effects of antidepressants in children and adolescents were “poorly understood” and research among adults showed risks included serious side effects that may be long-term and in some cases persist after stopping the medication, he added.</p><p>Responding to the findings, a Nice spokesperson said: “Mental health is a priority for Nice and we recognise that depression in young people is a serious condition that affects each differently, which is why having a range of treatment options is essential for clinicians. Our guideline recommends a choice of psychological therapies as first line treatment options for children and young people with depression.</p><p>“Nice recommends that children and young people with moderate or severe depression are reviewed by specialist teams. Antidepressants may be considered in combination with psychological therapy for moderate to severe depression in some cases and only under regular specialist supervision.”</p><p>Prof Allan Young, chair of the Royal College of Psychiatrists’ Academic Faculty, said that the study should be interpreted with “caution”. “Clinical guidelines weigh many factors beyond average effect size, including safety, feasibility, and patient preferences. It is important that prescribed medication demonstrate consistent evidence and safety data,” he said.</p></div></div>]]></description>
        </item>
    </channel>
</rss>