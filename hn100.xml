<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 17 Jun 2024 15:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Backdoor in D-Link routers enables telnet access (121 pts)]]></title>
            <link>https://supportannouncement.us.dlink.com/security/publication.aspx?name=SAP10398</link>
            <guid>40704505</guid>
            <pubDate>Mon, 17 Jun 2024 11:29:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://supportannouncement.us.dlink.com/security/publication.aspx?name=SAP10398">https://supportannouncement.us.dlink.com/security/publication.aspx?name=SAP10398</a>, See on <a href="https://news.ycombinator.com/item?id=40704505">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><span>E15 / E30 / G403 / G415 / G416 / M15 / M18 / M30 / M32 / M60 / R03 / R04 / R12 / R15 / R18 / R32 :: H/W Rev. Ax :: TWCERT Reports :: (CVE-2024-6044) LAN-Side arbitrary rile reading and (CVE-2024-6045) elevated unauthenticated access attack vectors</span>
</p><div id="ctl00_cphContent_pnlPublication">
	
    <p><span>
            <b>Publication ID:</b> SAP10398<br>
            <b>Resolved Status:</b> Yes<br>
            <b>Published on:</b> 31 May 2024 1:42 GMT<br>
            <b>Last updated on:</b> 17 June 2024 1:27 GMT<br>
        </span>
    </p>
    
    <p><span>
<p><strong><span>Overview </span></strong></p>

<p><span><span data-preserver-spaces="true">The EAGLE PRO AI Family (hardware rev. Ax) Models E15 / G403 / G415 / G416 / M15 / M18 / M32 / R03 / R04 / R12 / R15 / R18 / R32 and AQUILA PRO AI Family (hardware rev. Ax) Model E30 / M30 / M60 were reported to D-Link by TWCERT in April 2024 as having multiple vulnerabilities. D-Link Corporation immediately verified the reports and began mitigation, and the affected models are listed below.</span></span></p>

<p><span>D-Link has released fixes for these vulnerabilities, automatically updating the devices. Owners can use their D-Link Device Mobile applications to check and trigger updates manually.</span></p>

<p><strong><span>3rd Party Report information</span></strong></p>

<p><span>·</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><strong><span>R</span></strong><strong><span>eports provided:</span></strong><span>&nbsp;<span>TW CERT ::</span></span>&nbsp; <a href="https://www.twcert.org.tw/en/mp-2.html">Link</a></p>
<p><strong><span>Exploit 1:</span></strong><span> TW CERT: </span><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-6044">CVE-2024-6044</a> / <a href="https://www.twcert.org.tw/en/cp-139-7878-7c3d9-2.html">TVN-202406012</a></p>

<p><span>- CVSS</span><span><span lang="ZH-CN">：</span><span><span> </span></span></span>6.5 (Medium) CVSS:3.1/AV:A/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N</p>
<p><span>- </span><span><span>CWE</span><span> :&nbsp;<span> </span>CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')</span></span></p>
<p><span>- CAPEC : CAPEC-126: Path Traversal</span></p>

<p><strong><span>LAN-Side Arbitrary File Reading</span></strong><strong><span>: </span></strong><strong><span>The affected devices have an unauthenticated path traversal vulnerability</span></strong><span>. Unauthenticated attackers on the same network can read arbitrary system files.&nbsp; </span></p>

<p><strong><span><span>Exploit </span>2:</span></strong><span> TW CERT: </span><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-6045">CVE-2024-6045</a> / <a href="https://www.twcert.org.tw/en/cp-139-7880-629f5-2.html">TVN-202406013</a></p>

<p><span>- </span>8.8 (High) CVSS:3.1/AV:A/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H</p>
<p><span>- </span><span><span>CWE</span><span> :&nbsp;<span> </span>CWE-22: Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')</span></span></p>
<p><span>- CAPEC : CAPEC-126: Path Traversal</span></p>

<p><span>LAN-Side Unauthenticated Access to Management Features: Unauthenticated attackers on the same network can force the device to enable telnet service by accessing a specific URL and can log in using the hardcoded credentials obtained from reverse engineering and analyzing the firmware</span></p>

<p><strong><span>Affected Models</span></strong></p>

<table>
    <tbody>
        <tr>
            <td>
            <p><span>&nbsp;<span>&nbsp; </span></span><span>Model</span></p>
            </td>
            <td>
            <p><span>Region</span></p>
            </td>
            <td>
            <p><strong><span>Hardware Revision</span></strong></p>
            </td>
            <td>
            <p><strong><span>Affected</span></strong></p>
            </td>
            <td>
            <p><span>Fixed   F/W</span></p>
            </td>
            <td>
            <p><strong><span>Recommendation</span></strong></p>
            </td>
            <td>
            <p><span>&nbsp;</span><strong><span>Last Updated</span></strong></p>
            </td>
        </tr>
        <tr>
            <td>
            <p><span>E15</span></p>
            </td>
            <td>
            <p><span>Worldwide</span></p>
            </td>
            <td>
            <p><span>All H/W Revs.</span></p>
            </td>
            <td>
            <p><span>Yes: 1 &amp; 2</span></p>
            </td>
            <td>
            <p>v1.20.01</p>
            </td>
            <td>
            <p><span>Automatic Forced Update <span>**</span></span></p>
            </td>
            <td>
            <p><span>06/16/2024</span></p>
            </td>
        </tr>
        <tr>
            <td>
            <p><span>E30</span></p>
            </td>
            <td>
            <p><span>Worldwide</span></p>
            </td>
            <td>
            <p><span>All H/W Revs.</span></p>
            </td>
            <td>
            <p><span>Yes: 1 &amp; 2</span></p>
            </td>
            <td>
            <p>v1.10.02</p>
            </td>
            <td>
            <p><span>Automatic Forced Update <span>**</span></span></p>
            </td>
            <td>
            <p><span>06/16/2024</span></p>
            </td>
        </tr>
        <tr>
            <td>
            <p><span>G403</span></p>
            </td>
            <td>
            <p><span>Non-US</span></p>
            </td>
            <td>
            <p><span>All H/W Revs.</span></p>
            </td>
            <td>
            <p><span>Yes: 1 &amp; 2</span></p>
            </td>
            <td>
            <p>v1.10.01</p>
            </td>
            <td>
            <p><span>Automatic Forced Update <span>**</span></span></p>
            </td>
            <td>
            <p><span>06/16/2024</span></p>
            </td>
        </tr>
        <tr>
            <td>
            <p><span>G415</span></p>
            </td>
            <td>
            <p><span>Non-US</span></p>
            </td>
            <td>
            <p><span>All H/W Revs.</span></p>
            </td>
            <td>
            <p><span>Yes: 1 &amp; 2</span></p>
            </td>
            <td>
            <p>v1.10.01</p>
            </td>
            <td>
            <p><span>Automatic Forced Update <span>**</span></span></p>
            </td>
            <td>
            <p><span>06/16/2024</span></p>
            </td>
        </tr>
        <tr>
            <td>
            <p><span>G416</span></p>
            </td>
            <td>
            <p><span>Non-US</span></p>
            </td>
            <td>
            <p><span>All H/W Revs.</span></p>
            </td>
            <td>
            <p><span>Yes: 1 &amp; 2</span></p>
            </td>
            <td>
            <p>v1.10.01</p>
            </td>
            <td>
            <p><span>Automatic Forced Update <span>**</span></span></p>
            </td>
            <td>
            <p><span>06/16/2024</span></p>
            </td>
        </tr>
        <tr>
            <td>
            <p><span>M15</span></p>
            </td>
            <td>
            <p><span>Worldwide</span></p>
            </td>
            <td>
            <p><span>All H/W Revs. Including /2 &amp; /3 Kits</span></p>
            </td>
            <td>
            <p><span>Yes: 1 &amp; 2</span></p>
            </td>
            <td>
            <p>v1.20.01&nbsp;&amp; v1.21.01</p>
            </td>
            <td>
            <p><span>Automatic Forced Update <span>**</span></span></p>
            </td>
            <td>
            <p><span>06/16/2024</span></p>
            </td>
        </tr>
        <tr>
            <td>
            <p><span>M18</span></p>
            </td>
            <td>
            <p><span>Worldwide</span></p>
            </td>
            <td>
            <p><span>All H/W Revs. Including /2 &amp; /3 Kits</span></p>
            </td>
            <td>
            <p><span>Yes: 1 &amp; 2</span></p>
            </td>
            <td>
            <p>v1.10.01</p>
            </td>
            <td>
            <p><span>Automatic Forced Update <span>**</span></span></p>
            </td>
            <td>
            <p><span>06/16/2024</span></p>
            </td>
        </tr>
        <tr>
            <td>
            <p><span>M32</span></p>
            </td>
            <td>
            <p><span>Worldwide</span></p>
            </td>
            <td>
            <p><span>All H/W Revs. Including /2 &amp; /3 Kits</span></p>
            </td>
            <td>
            <p><span>Yes: 1 &amp; 2</span></p>
            </td>
            <td>
            <p>v1.10.02</p>
            </td>
            <td>
            <p><span>Automatic Forced Update <span>**</span></span></p>
            </td>
            <td>
            <p><span>06/16/2024</span></p>
            </td>
        </tr>
        <tr>
            <td>
            <p><span>R03</span></p>
            </td>
            <td>
            <p><span>Non-US</span></p>
            </td>
            <td>
            <p><span>All H/W Revs.</span></p>
            </td>
            <td>
            <p><span>Yes: 1 &amp; 2</span></p>
            </td>
            <td>
            <p>v1.10.01</p>
            </td>
            <td>
            <p><span>Automatic Forced Update <span>**</span></span></p>
            </td>
            <td>
            <p><span>06/16/2024</span></p>
            </td>
        </tr>
        <tr>
            <td>
            <p><span>R04</span></p>
            </td>
            <td>
            <p><span>Non-US</span></p>
            </td>
            <td>
            <p><span>All H/W Revs.</span></p>
            </td>
            <td>
            <p><span>Yes: 1 &amp; 2</span></p>
            </td>
            <td>
            <p>v1.10.01</p>
            </td>
            <td>
            <p><span>Automatic Forced Update <span>**</span></span></p>
            </td>
            <td>
            <p><span>06/16/2024</span></p>
            </td>
        </tr>
        <tr>
            <td>
            <p><span>R12</span></p>
            </td>
            <td>
            <p><span>Worldwide</span></p>
            </td>
            <td>
            <p><span>All H/W Revs.</span></p>
            </td>
            <td>
            <p><span>Yes: 1 &amp; 2</span></p>
            </td>
            <td>
            <p>v1.10.01</p>
            </td>
            <td>
            <p><span>Automatic Forced Update <span>**</span></span></p>
            </td>
            <td>
            <p><span>06/16/2024</span></p>
            </td>
        </tr>
        <tr>
            <td>
            <p><span>R15</span></p>
            </td>
            <td>
            <p><span>Worldwide</span></p>
            </td>
            <td>
            <p><span>All H/W Revs. Including /2 &amp; /3 Kits</span></p>
            </td>
            <td>
            <p><span>Yes: 1 &amp; 2</span></p>
            </td>
            <td>
            <p>v1.20.01</p>
            </td>
            <td>
            <p><span>Automatic Forced Update <span>**</span></span></p>
            </td>
            <td>
            <p><span>06/16/2024</span></p>
            </td>
        </tr>
        <tr>
            <td>
            <p><span>R18</span></p>
            </td>
            <td>
            <p><span>Non-US</span></p>
            </td>
            <td>
            <p><span>All H/W Revs.</span></p>
            </td>
            <td>
            <p><span>Yes: 1 &amp; 2</span></p>
            </td>
            <td>
            <p>v1.10.01</p>
            </td>
            <td>
            <p><span>Automatic Forced Update <span>**</span></span></p>
            </td>
            <td>
            <p><span>06/16/2024</span></p>
            </td>
        </tr>
        <tr>
            <td>
            <p><span>R32</span></p>
            </td>
            <td>
            <p><span>Worldwide</span></p>
            </td>
            <td>
            <p><span>All H/W Revs. Including /2 &amp; /3 Kits</span></p>
            </td>
            <td>
            <p><span>Yes: 1 &amp; 2</span></p>
            </td>
            <td>
            <p>v1.10.02</p>
            </td>
            <td>
            <p><span>Automatic Forced Update <span>**</span></span></p>
            </td>
            <td>
            <p><span>06/16/2024</span></p>
            </td>
        </tr>
        <tr>
            <td>
            <p><span>M30</span></p>
            </td>
            <td>
            <p><span>Worldwide</span></p>
            </td>
            <td>
            <p><span>All H/W Revs. Including /2 &amp; /3 Kits</span></p>
            </td>
            <td>
            <p><span>Yes: 1 &amp; 2</span></p>
            </td>
            <td>
            <p>v1.10.02</p>
            </td>
            <td>
            <p><span>Automatic Forced Update <span>**</span></span></p>
            </td>
            <td>
            <p><span>06/16/2024</span></p>
            </td>
        </tr>
        <tr>
            <td>
            <p><span>M60</span></p>
            </td>
            <td>
            <p><span>Worldwide</span></p>
            </td>
            <td>
            <p><span>All H/W Revs. Including /2 &amp; /3 Kits</span></p>
            </td>
            <td>
            <p><span>Yes: 1 &amp; 2</span></p>
            </td>
            <td>
            <p>v1.10.02</p>
            </td>
            <td>
            <p><span>Automatic Forced Update <span>**</span></span></p>
            </td>
            <td>
            <p><span>06/16/2024</span></p>
            </td>
        </tr>
    </tbody>
</table>

<p><b><span>Regarding the Security Update for Your D-Link Device</span></b></p>
<p><span>Installing firmware updates is critical in addressing security vulnerabilities in your D-Link devices. D-Link strongly urges all users to install the relevant updates and regularly check for further updates. After downloading the firmware update, it is essential to ALWAYS validate its success by comparing the firmware version on your product interface to the firmware update version.</span></p>

<p><span>Please note that beta software, beta firmware, or a hot-fix release is still undergoing rigorous testing before its official release. This ensures that the software is of the highest quality and meets our stringent standards. However, it is essential to understand that the user assumes all risk and liability for its use. D-Link does not provide any express or implied warranties regarding the suitability or usability of the beta software, beta firmware, or hot-fix release. D-Link will not be liable for any direct, indirect, special, or consequential loss suffered by any party due to their use of the beta firmware, beta software, or hit-fix release.</span></p>

<p><span>NOTE: Our products have different hardware revisions, so please check your device’s hardware revision before downloading the corresponding firmware update. The hardware revision can be found on the product label next to the serial number or on the device's web interface.</span></p>

<p><b><span>**In the Event Automatic Forced Update Fails to new firmware </span></b></p>

<p><span>As this is a critical and required firmware update, if your D-Link Mobile Application does not report the fixed firmware version or newer, you can manually download the patched updates on 06/17/2024 and manually upload the firmware to the web GUI of the device.</span></p>

<p><span>The link to firmware updates is <a href="https://support.dlink.com/">https://support.dlink.com/</a>; search for your model. If you require help in manual update this page also has links for Customer Care Help.</span></p>
</span>
    </p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Being laid off and unplanned entrepreneurship (190 pts)]]></title>
            <link>https://www.deepsouthventures.com/on-being-laid-off-unplanned-entrepreneurship/</link>
            <guid>40704428</guid>
            <pubDate>Mon, 17 Jun 2024 11:14:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.deepsouthventures.com/on-being-laid-off-unplanned-entrepreneurship/">https://www.deepsouthventures.com/on-being-laid-off-unplanned-entrepreneurship/</a>, See on <a href="https://news.ycombinator.com/item?id=40704428">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
			<p>〰️ it’s weird to look back; I sometimes get confused on how I got here 〰️</p>
<figure id="attachment_2862" aria-describedby="caption-attachment-2862"><a href="https://www.deepsouthventures.com/wp-content/uploads/highlands-nc-whiteside-mountain-nc.jpeg"><img fetchpriority="high" decoding="async" src="https://www.deepsouthventures.com/wp-content/uploads/highlands-nc-whiteside-mountain-nc-300x225.jpeg" alt="Whiteside Mountain in Highlands NC" width="300" height="225" srcset="https://www.deepsouthventures.com/wp-content/uploads/highlands-nc-whiteside-mountain-nc-300x225.jpeg 300w, https://www.deepsouthventures.com/wp-content/uploads/highlands-nc-whiteside-mountain-nc-700x525.jpeg 700w, https://www.deepsouthventures.com/wp-content/uploads/highlands-nc-whiteside-mountain-nc.jpeg 1024w" sizes="(max-width: 300px) 100vw, 300px"></a><figcaption id="caption-attachment-2862">Whiteside Mountain in Highlands NC</figcaption></figure>
<p>Most folks dream of being entrepreneur; “<em>a path that seemed inevitable</em>“, they say. None of that shit applies to me. I’m only here cause I kept getting laid off and that nonsense infuriated me.</p>
<p>I treated my first layoff as a joke, as I’d seen them in movies &amp; TV; “<em>now they’re happening to me – how funny</em>“. My second felt like a whispered “fuck-you”, as the company had been acquired and I was deemed useless. The third and fourth scrambled my brain and forced me down a path <strong><em>I never intended to travel</em></strong>.</p>
<h2>I’m only here cause I had to save myself.</h2>
<p>I remember thinking:</p>
<blockquote><p><em>I can’t trust them anymore; I gotta figure out a way to generate revenue myself; from my own business; that I control. Online preferably.</em></p></blockquote>
<p>That’s where I started. Daunting for someone with a History degree. I had no other choice.</p>
<p>So, I took stock of my background at that moment. Web analytics, Paid Search, and pittance of SEO.</p>
<blockquote><p>Ok, I’ll start there. I’ll skip coding for now.</p></blockquote>
<p>I’d recently been exposed to a new online ad network, that paid by lead and/or click. I had previously implemented it on a company’s website &amp; it generated around $30-$50 a day for them.</p>
<blockquote><p>Sounds good to me, let’s try something like that.</p></blockquote>
<p>Since I couldn’t code, I couldn’t launch a website. So the gears of my dusty cobweb cranium began to turn. What can I do that doesn’t require coding? Eventually, a thought bubbled up:</p>
<blockquote><p>Well, what’s stopping me from signing up for one of those ad networks, and then going to a search engine, typing a popular search term, digging through the organic results, searching for sites WITHOUT advertising, emailing them to request ad rates, and implementing <span>//my own//</span> ad pixel there.</p></blockquote>
<p>There wasn’t a damn thing stopping me. So I started doing that (with the hopes the website owner never found out about said ad network, as I could be cut out of loop). This was late 2003.</p>
<p>I needed a topic. Alot of people seemed to search for tourism information online, so I leaned into that corner. Began searching broad terms &amp; phrases in any search engine. My thought was, if site is in top ten results for major keyword, then it’s safe to say they’re receiving a significant (enough) amount of traffic.</p>
<p><img decoding="async" src="https://www.deepsouthventures.com/wp-content/uploads/Caribbean.jpg" alt="Caribbean" width="277" height="182">I’d search ‘Aruba’, and would email every site that fit the bill. “<em>Do you accept advertising? If so, what are your rates?</em>” I’d search ‘Bahamas’ &amp; repeat process. Then ‘Key West’. And on and on.</p>
<p>I’d get a nibble occasionally. I’d reply asking their traffic levels &amp; monthly ad rates. Then I’d napkin math whether I’d be able to cover *their* ad expense &amp; (possibly) generate profit with my own ad revenue from the network (which was guesstimated, on my part). Oftentimes, the numbers wouldn’t work.</p>
<p>Until the owner of a Cancun travel website replied. His rate was $50/month to advertise. His site ranked well for several Cancun related terms &amp; received significant traffic. I estimated my ad unit, if placed in a certain section on the page, would receive 2% CTR. Then I multiplied that number by his daily traffic levels, and guesstimated $5-$8 of revenue per day. I remember thinking I was going to get hosed on the deal, but me being me, I kept going.</p>
<p>He asked what type of ads I’d run. I didn’t know, as they were dynamically generated based on the content of the site/page. I told him “<em>several travel &amp; tourism promotions targeted to Cancun</em>“. ¯\_(ツ)_/¯</p>
<p>That worked for him, so I began paying $50 a month, and shot him my ad pixel to implement. Off-the-bat, the darn thing began generating $300-$350 a month.</p>
<p>The ads were perfectly targeted. Cancun hotels. Swim with dolphins. Paragliding. Cruises. Most months I was clearing $300/month profit (after ad expenses to the website owner). I couldn’t fukkin believe it. It was my mini-watershed moment; exposing me to the fact that, yes, dolt-brain me could do this. If I could generate revenue from this disgustingly duct-taped business model, I could do it in other fashions online. I just didn’t know what those fashions were yet. One thing I did know:</p>
<blockquote><p>I gotta learn how to code</p></blockquote>
<p>This was the avenue hanging me up &amp; intimidating me. I was currently advertising <em>on other folks websites. That they built. They hosted. They managed.</em> I had to mimic that same position. And that meant coding, launching, &amp; managing my own sites. </p>
<p>Outside of its complexities, coding tripped me up cause it required a basic tenet that I typically veered away from: <em>basic reading</em>.</p>
<p><a href="https://www.deepsouthventures.com/wp-content/uploads/mad-corn.jpeg"><img decoding="async" src="https://www.deepsouthventures.com/wp-content/uploads/mad-corn-230x300.jpeg" alt="Alfred E Neumann" width="230" height="300" srcset="https://www.deepsouthventures.com/wp-content/uploads/mad-corn-230x300.jpeg 230w, https://www.deepsouthventures.com/wp-content/uploads/mad-corn.jpeg 474w" sizes="(max-width: 230px) 100vw, 230px"></a>I don’t mind reading, I just don’t like doing it, I find it difficult to focus (I’m more of a distinguished MAD Magazine type of reader). I’d rather watch a video tutorial, listen to an audiobook, or have someone side-by-side explaining things. Those avenues didn’t quite exist back then; so I had to get creative.</p>
<p>Instead of lamenting &amp; bemoaning my position, I decided to throw out all the rules and <strong>✨ <em>just start building a website although I didn’t know how</em> ✨</strong>. I’d figure out the rest once I started.</p>
<p>Someone told me ‘hosting’ was required, so I bought a cheap package and began to poke around. Once I skipped the documentation, I discovered they had a ‘ticket’ system where they allowed customers to submit support questions. Huhmm.</p>
<p>~ ~ ~ ~ ~<br>
<em><strong>Ticket #1:</strong><br>
<strong>from:</strong> Peter<br>
<strong>message:</strong> please help me get a website online</em> (╯˘ -˘ )╯<br>
~ ~ ~ ~ ~</p>
<p>… and – God bless them – they replied. That’s where I learned about the “index.html” file. They became my unpaid tutors. Volleying countless questions on how all this stuff works. What the hell a domain name was. How to update my DNS. File transfer protocol. They pushed me far enough where I became comfortable researching myself. Googling questions. Forum questions. Twitter. Asking friends. All of it. Hell, my friend Charles Lumpkin educated me on the wonders of a &lt; div &gt; tag.</p>
<p>From there, I got a basic one-page website online. Hand-coded. I felt like trashcan-Superman.</p>
<p>Then I channeled my advertising/marketing background. “What’s a website I can build that might generate ad revenue &amp; serve small businesses?”</p>
<p><img loading="lazy" decoding="async" src="https://www.deepsouthventures.com/wp-content/uploads/yp2-300x256.jpeg" alt="Yellow Pages" width="300" height="256" srcset="https://www.deepsouthventures.com/wp-content/uploads/yp2-300x256.jpeg 300w, https://www.deepsouthventures.com/wp-content/uploads/yp2.jpeg 558w" sizes="(max-width: 300px) 100vw, 300px">My father’s friend worked in the Yellow Pages industry, and always remarked how profitable that business model was. We were still in early internet days (2004’ish), so I mused how I could mimic that industry online. In other words, create a central directory bringing buyers &amp; sellers together. Buyers searching for services; businesses providing those services. I liked this simple model, so I swung that way.</p>
<p>I grabbed a Yellow Pages book in my apartment, opened it up, and began to flip through. In those days, basic listing were free, but businesses could advertise large rectangle ads in their category. As I fanned through the pages, I’d keep an eye out for sections with heavy ad promotion (as it indicated an industry that understood the value of advertising). I found a few. Windshield repair. Limos. Carpet cleaning. Self storage. Pest control. And on and on. Then, I’d buy an ugly domain &amp; create an online directory of that category (ie. pest control), mixed in with geography based terms for seo, like ‘atlanta pest control’. And on that page, I’d curate several atlanta pest control operators, and list all their contact info. About as basic &amp; boring of a site as you can get. But simple to navigate, and no hoops to jump through.</p>
<p><img loading="lazy" decoding="async" src="https://www.deepsouthventures.com/wp-content/uploads/viewsourcedsv.jpg" alt="View source" width="500" height="291" srcset="https://www.deepsouthventures.com/wp-content/uploads/viewsourcedsv.jpg 500w, https://www.deepsouthventures.com/wp-content/uploads/viewsourcedsv-300x175.jpg 300w" sizes="(max-width: 500px) 100vw, 500px">Then, as I further began to code, I discovered the wonders of “view page source”. I could right-click, copy &amp; paste another website’s syntax into my editor; monkey with that updated design; then upload it to my server. Tables &amp; rows, mainly. I’d swap out the logo; change the background color; the width of the container; manually add new pages. My trashcan-Superman aura was morphing into trashcan-Zeus. It felt like walking through a deep fog treasure-chest where I could only touch &amp; feel what was directly in front of me, and each outcome was bizarrely fascinating. An ape could have designed better, yes, but I was proud.</p>
<p>Then traffic began trickling in. From outreach; from sponsorships I placed; from seo stuff; from all kinds of marketing endeavors.&nbsp; I began offering premium listings; businesses began signing up; I’d charge them through Paypal (no Stripe back then). Then I began adding those ad networks (I mentioned above). And more revenue began to appear. A somewhat consistent monthly recurring revenue stream.</p>
<p>I was still working 9-5, but an escape hatch was coming into focus. A path to avoid someone else’s bonehead business decision which kneecaps a company &amp; executes my career. The glitter of fancy salaries had already grown dim – that hook they’d dangle to entrap me. I yearned for my own {mini} golden goose that provided the independence I was blindly searching for. The <em>Rage Against The Machine</em> lyric often came to mind:&nbsp; <em>“Fuck the G-ride, I want the machines that are makin’ ’em”.</em> [<a href="https://www.youtube.com/watch?v=qDZV8TdnCoo" target="_blank" rel="noopener">src</a>]</p>
<p><img loading="lazy" decoding="async" src="https://www.deepsouthventures.com/wp-content/uploads/wordpress-300x194.jpg" alt="Wordpress" width="300" height="194" srcset="https://www.deepsouthventures.com/wp-content/uploads/wordpress-300x194.jpg 300w, https://www.deepsouthventures.com/wp-content/uploads/wordpress.jpg 500w" sizes="(max-width: 300px) 100vw, 300px">My development path accelerated when I discovered WordPress. Most hosts had one-click installation. WP had recently added the ability to create ‘Pages’, so I moved my development focus inside that petri dish. The pre-built themes (free &amp; paid) were a boon to my design inadequacies.</p>
<p>I built more sites ~ nights &amp; weekends ~ thanks to WordPress. But that became time consuming, so I began *<em>buying</em>* fully developed websites, direct from mom &amp; pop operators via cold email. Usually informational sites. Then I could expand the content based on search volume trends and incorporate small bits of advertising. </p>
<figure><img loading="lazy" decoding="async" src="https://www.deepsouthventures.com/wp-content/uploads/at-ads.jpg" alt="Appalachian Trail" width="400" height="533" srcset="https://www.deepsouthventures.com/wp-content/uploads/at-ads.jpg 400w, https://www.deepsouthventures.com/wp-content/uploads/at-ads-225x300.jpg 225w" sizes="(max-width: 400px) 100vw, 400px"><figcaption>AppalachianTrail.com circa 2008’ish (now sold)</figcaption></figure><p>AppalachianTrail.com was a good example. I cold emailed the owner a $3,000 offer for the site &amp; domain. I received no reply, which was normal. Until I did receive a reply; 30 days later; accepting the offer. I further built the site out &amp; it began generating around $500/month for me.</p>
<p>What I kept noticing, though, when I’d transfer a site under my wing, I’d {immediately} focus on domain transfer, as control of that asset dictated ownership of the site.</p>
<p>These domain <em>‘things’</em> seemed intriguing, so I dug deeper. I discovered the expiring domain name market. A universe where 50k-100k domains expire &amp; auction every day. There, I discovered the impact of a blue chip, descriptive .com domain name ~ especially in development. An unfair advantage that allows small players to punch up.</p>
<p>I remember sitting in a pizza joint with my friend <a href="https://x.com/agraber" target="_blank" rel="noopener">Allen Graber</a>, grabbing lunch one day. At some point, he stepped away from the table and my mind was wandering. Dissecting my path to that point, and trying to stitch together what it all meant, and if there was a next step. And a thought surfaced: <em>Why not just wait. Sit and wait. And watch the expiry lists. For a premium .com domain to expire, that has development potential.</em> I was in no rush. That seemed to jive with my inner-nature. I’d already witnessed a few gorilla .com’s go up, so I understood others could as well. I’d just need to empty my mind and wait for the pull to arrive.</p>
<p><img loading="lazy" decoding="async" src="https://www.deepsouthventures.com/wp-content/uploads/boots-rope.jpeg" alt="boots and rope" width="170" height="187">The pull came in 2009. The domain was marvelous. A group in NY state abandoned ‘DudeRanch.com’, and I <a href="https://www.deepsouthventures.com/dude-that-built-duderanch-com/">acquired at auction</a> for $17,949. It provided the backbone for me to build a vacation marketplace for that historic industry. An environment where I could shepherd vacationers towards dude ranches that met their needs. And monetize the asset through premium (highlighted) listings that paid me a flat-fee per year.</p>
<p>The mild success I achieved there allowed me to quit the 9-5. It opened me to more projects. More domains. And opened me to empty myself into these endeavors.</p>
<p>I didn’t raise any money for these projects. I funded them with my 9-5 salary. Solo. And the reason for that was simple – why on earth would I vehemently abandon boneheaded micro-managing layoff kings in the 9-5 world only to raise money &amp; adopt a board of boneheaded micro-managing layoff kings in the startup world. If I’m gonna build, I’m gonna have free-rein decision making to pursue any and all ludicrous business models, with no oversight. If I fail, fine. That’s on me. If it works, son-of-a-gun, my job will feel like play.</p>
<p>I still to this day, over 20 years later, experience the sting from those layoffs. The check-mate move that I couldn’t counter. I had no plan, but I started. I had no goal; I just got going. I guess I’m still going; I don’t quite know where. But I’m quite content. And thankful. It appears peace of mind is the prize I’m pursuing.</p>
<p>it’s weird to look back.</p>
<p>[ <em>Some images from first projects of mine circa 2004-2008’ish; plus early &amp; current views of DudeRanch.com.</em> ]</p>

<hr>
<p><iframe loading="lazy" width="560" height="315" src="https://www.youtube.com/embed/hBE8NJJw4Cg?si=hXLPdLbxb-pKeW6f" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p>
<hr>
<p><span><a href="https://twitter.com/searchbound" target="_blank" rel="noopener noreferrer">Follow me on Twitter</a> as I continue to document my journey there. Or get an email when I post new stuff (below):</span></p>

		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Developer Takes 'Retro' Concept to New Level by Creating Physical Winamp Player (102 pts)]]></title>
            <link>https://www.xatakaon.com/makers/a-developer-has-just-taken-the-concept-of-retro-to-a-new-level-by-creating-a-physical-winamp-player</link>
            <guid>40703176</guid>
            <pubDate>Mon, 17 Jun 2024 07:40:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.xatakaon.com/makers/a-developer-has-just-taken-the-concept-of-retro-to-a-new-level-by-creating-a-physical-winamp-player">https://www.xatakaon.com/makers/a-developer-has-just-taken-the-concept-of-retro-to-a-new-level-by-creating-a-physical-winamp-player</a>, See on <a href="https://news.ycombinator.com/item?id=40703176">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
   <p>Retro devices, like old game consoles and CD players, bring joy to people who are <strong>nostalgic</strong>. They allow them to revisit the past in today’s ever-changing tech world. Now, someone has combined the old and now to create Linamp.</p>
<!-- BREAK 1 --> 

<p>Linamp is a physical media player inspired by Winamp, a Windows media player first released in 1997. The new device features a 7.9-inch touch screen that displays the interface of the legendary program, along with many other interesting features.</p>
<!-- BREAK 2 -->
<h2><strong>Linamp, the Physical Media Player Inspired by Winamp</strong></h2>

<p>Linamp is powered by a Raspberry Pi 4B with a 32 GB SD card. This microcomputer board has made it possible to include a <strong>3.5 mm headphone jack</strong>, a USB-C port, a USB-A port, and an Ethernet port. The body of the device is made of aluminum and seeks to mimic the style of audio devices from the 1990s.</p>
<!-- BREAK 3 --> 

<p>The front part has been 3D printed. Instead of “Winamp,” it says Linamp, but it adopts the exterior appearance of the program’s classic skin. To play an audio file, you need to to connect an SD card or use an external disc player.</p>
<!-- BREAK 4 --><div>
   <p><a href="https://www.xatakaon.com/audio/what-happened-to-creative-technology-the-company-that-created-the-legendary-sound-blaster-cards">
     <img alt="What Happened to Creative Technology, the Company That Created the Legendary Sound Blaster Cards?" width="375" height="142" src="https://i.blogs.es/f3e373/original/375_142.jpeg">
    </a>
   </p>
   
  </div>
<p>When users insert a CD, Linamp automatically detects the disc, extracts the track information, and is ready to play your selection. To start listening to music, all you need to do is <strong>press the Play button</strong> on the touch screen. In the future, the creator plans to add support for Bluetooth and Spotify.</p>
<!-- BREAK 5 -->
<p>Linamp is a project by Rodrigo Méndez. According to his <a rel="noopener, noreferrer" href="https://hackaday.io/rodmg">Hackaday profile</a>, he’s a Mexico-based “computer engineer by training, software engineer by trade, geek by birth” who “also enjoys embedded systems and electronics.” You can find additional details about his latest creation in a <a rel="noopener, noreferrer" href="https://www.youtube.com/watch?si=EyidVBoFrTISYUQ2&amp;v=5nUYHROVOmo&amp;feature=youtu.be">video posted on YouTube</a>.</p>
<!-- BREAK 6 --> 

<p>Image | Rodrigo Méndez</p>

<p>Related | <a rel="noopener, noreferrer" href="https://www.xatakaon.com/apps/neuralinks-impossible-challenge-isnt-a-brain-implant-its-a-pied-piper-and-mp3-players">Neuralink’s ‘Impossible’ Challenge Isn’t a Brain Implant: It’s a ‘Pied Piper’ and MP3 Players</a></p>

 
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The time keepers: pg_cron and pg_timetable (116 pts)]]></title>
            <link>https://notso.boringsql.com/posts/time-keepers-pg-cron-pg-timetable/</link>
            <guid>40702985</guid>
            <pubDate>Mon, 17 Jun 2024 07:05:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://notso.boringsql.com/posts/time-keepers-pg-cron-pg-timetable/">https://notso.boringsql.com/posts/time-keepers-pg-cron-pg-timetable/</a>, See on <a href="https://news.ycombinator.com/item?id=40702985">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p>Working with PostgreSQL, and virtually any database system, extends far beyond merely inserting and retrieving data. Many application and business processes, maintenance tasks, reporting, and orchestration tasks require the integration of a job scheduler. While third-party tools can drive automation, you can also automate the execution of predefined tasks directly within the database environment. Although system-level cron might be a starting point, the power of the database system lies in its ability to store all the necessary information alongside your data/schema. In this article, we will explore <code>pg_cron</code> and <code>pg_timetable</code> as two distinct PostgreSQL-specific tools for scheduled task automation.</p>
<h2 id="the-many-roles-of-job-scheduling">The Many Roles of Job Scheduling
</h2>
<p>Usually, the first requirement to automate job execution is the optimisation of the PostgreSQL cluster and databases. Except in very low usage scenarios, <strong>routine maintenance</strong> is the foundation of all database deployments. Whether it is VACUUMing, index rebuilding, or updating statistics, these are tasks that you will eventually need to automate to maintain operational efficiency.</p>
<p>Job scheduling is also indispensable for <strong>maintaining data quality</strong>, particularly through operations like refreshing materialised views or batch removal of outdated data from the system. From there, it is just a step to <strong>reporting</strong>, which can involve the automation of generating operational and business reports.</p>
<p>I also believe that databases are an excellent place to <strong>coordinate business processes</strong>. Automating data flows between components, teams, and departments helps create agile systems. As mentioned above, there is no better place to store the description of such automations than alongside your data.</p>
<h2 id="pg-cron-automation-s-first-gear">pg_cron: Automation's First Gear
</h2>
<p>Traditionally, the role of automation started with operating system tools like cron or Task Scheduler. That's where <a href="https://github.com/citusdata/pg_cron"><code>pg_cron</code></a> comes in. It's a PostgreSQL extension that provides the simplicity and familiarity of cron's scheduling directly within the database environment.</p>
<p>Due to its dependency on a shared library (because of the use of the background worker), it requires a full cluster restart. Nevertheless, due to its popularity, it is available within most managed cloud environments.</p>
<pre data-lang="sql"><code data-lang="sql"><span># requires configuration update in postgresql.conf (or conf.d)
</span><span>shared_preload_libraries = '</span><span>pg_cron</span><span>'
</span><span>
</span><span># add extension as superuser 
</span><span>CREATE EXTENSION pg_cron;
</span></code></pre>
<p>As long as you are familiar with cron-like syntax, you can get started immediately by using commands like:</p>
<pre data-lang="sql"><code data-lang="sql"><span>SELECT </span><span>cron</span><span>.</span><span>schedule</span><span>('</span><span>30 3 * * 6</span><span>', $$</span><span>DELETE FROM</span><span> events </span><span>WHERE</span><span> event_time &lt; now() - interval '</span><span>1 week</span><span>'$$);
</span></code></pre>
<p>By default, <code>pg_cron</code> exposes its functionality in the <code>postgres</code> database (configurable), where it expects its metadata tables. Personally, I consider this a drawback, as it makes it less obvious to the casual DBA who might not be aware of the scheduling logic present.</p>
<p>In the same database, you can perform basic monitoring, for example, getting details of running and recently completed jobs:</p>
<pre data-lang="sql"><code data-lang="sql"><span>SELECT </span><span>* </span><span>FROM </span><span>cron</span><span>.</span><span>job_run_details </span><span>ORDER BY</span><span> start_time </span><span>DESC LIMIT </span><span>5</span><span>;
</span></code></pre>
<p>There is no direct support to talk to other PostgreSQL clusters (you would have to facilitate this, for example, using Foreign Data Wrappers).</p>
<p>While cron-like syntax is beneficial for adoption, it is where <code>pg_cron</code> falls short, as it does not support advanced cases like task chaining, dependencies, and triggers.</p>

<p>If <code>pg_cron</code> offers automation in first gear, <code>pg_timetable</code> is where you can go full speed ahead. It not only provides cron-like syntax but elevates it to a whole new level with task chaining, parameter support, multiple execution clients, enhanced scheduling, and much more.</p>
<p>The first difference you might notice is in its distribution. Timetable is not a PostgreSQL extension but a standalone binary (or available as a Docker image) that you have to configure and run. This immediately raises the bar in terms of the infrastructure it requires. On the other hand, not being distributed as an extension makes it compatible with all managed services by default (if you can get the process up and running).</p>
<p>While the basic syntax might be similar to <code>pg_cron</code>:</p>
<pre data-lang="sql"><code data-lang="sql"><span>SELECT </span><span>timetable</span><span>.</span><span>add_job</span><span>('</span><span>execute-func</span><span>', '</span><span>5 0 * 8 *</span><span>', '</span><span>SELECT public.my_func()</span><span>');
</span></code></pre>
<p>this is not anywhere near the limits of <code>pg_timetable</code>. <code>add_job</code> is a helper function that creates a simple one-task chain. For task execution, it directly supports more options, including built-in tasks (like sending emails if properly configured, downloading files, sleeping, copying files, etc.), external commands, the ability to choose which client should execute the job, concurrency, and more.</p>
<p>In its full definition, <code>add_job</code> is quite powerful (see <a href="https://pg-timetable.readthedocs.io/en/master/basic_jobs.html#add-simple-job">documentation</a> for details):</p>
<pre data-lang="sql"><code data-lang="sql"><span>SELECT </span><span>timetable</span><span>.</span><span>add_job</span><span>(
</span><span>    job_name            =&gt; '</span><span>notify every minute</span><span>',
</span><span>    job_schedule        =&gt; '</span><span>* * * * *</span><span>',
</span><span>    job_command         =&gt; '</span><span>SELECT pg_notify($1, $2)</span><span>',
</span><span>    job_parameters      =&gt; '</span><span>["TT_CHANNEL", "Hello World!"]</span><span>'::jsonb,
</span><span>    job_kind            =&gt; '</span><span>SQL</span><span>'::</span><span>timetable</span><span>.</span><span>command_kind</span><span>,
</span><span>    job_client_name     =&gt; </span><span>NULL</span><span>,
</span><span>    job_max_instances   =&gt; </span><span>1</span><span>,
</span><span>    job_live            =&gt; </span><span>TRUE</span><span>,
</span><span>    job_self_destruct   =&gt; </span><span>FALSE</span><span>,
</span><span>    job_ignore_errors   =&gt; </span><span>TRUE
</span><span>) AS chain_id;
</span></code></pre>
<p>The components of <code>pg_timetable</code> consist of the <strong>command</strong> (SQL/program or built-in), <strong>task</strong> controlling the configuration for the command execution (error handling, timeout, or database connection to use), and <strong>chain</strong> which can contain a number of tasks chained together.</p>
<p>The big difference comes in the scheduling options. While <code>pg_cron</code> is limited (as its name suggests) to cron-like syntax, <code>pg_timetable</code> uses it for simple use cases but offers much more. It supports schedules <code>@every</code> and <code>@after</code>, allowing repeated execution and breaking away from the limitations of cron notation as it can go down to custom intervals (including second intervals). Another case is <code>@reboot</code> for instances when the <code>pg_timetable</code> controller reconnects to the database.</p>
<p>The timetable setup manages own schema migrations and stores all the configuration in schema <code>timetable</code> (by default), where you can find the definitions of chains/tasks and relevant auditing information (logs).</p>
<p>And yes, if you have been paying attention, <code>pg_timetable</code> architecture allows for running tasks across multiple PostgreSQL clusters, making it an advanced orchestration tool. The database connection, which can be configured in-place or via a drop-in <a href="https://www.postgresql.org/docs/current/libpq-pgservice.html">connection service file</a>, can be set on a per-task basis.</p>
<p>With chains, the setup can be much more complex:</p>
<pre data-lang="sql"><code data-lang="sql"><span>DO $$
</span><span>DECLARE
</span><span>  v_chain_id </span><span>BIGINT</span><span>;
</span><span>  v_notify_task_id </span><span>BIGINT</span><span>;
</span><span>BEGIN
</span><span>    </span><span>INSERT INTO </span><span>timetable</span><span>.</span><span>chain</span><span> (
</span><span>        chain_name,
</span><span>        run_at,
</span><span>        max_instances,
</span><span>        live)
</span><span>    </span><span>VALUES</span><span> (
</span><span>        '</span><span>Generate Weekly Report</span><span>',
</span><span>        '</span><span>5 4 * * 1</span><span>',
</span><span>        </span><span>1</span><span>,
</span><span>        </span><span>TRUE    
</span><span>    )
</span><span>    RETURNING chain_id INTO v_chain_id;
</span><span>
</span><span>    </span><span>INSERT INTO </span><span>timetable</span><span>.</span><span>task</span><span> (
</span><span>        chain_id,       
</span><span>        task_order,     
</span><span>        task_name,      
</span><span>        command,        
</span><span>        database_connection 
</span><span>    )
</span><span>    </span><span>VALUES</span><span> (
</span><span>        v_chain_id,
</span><span>        </span><span>1</span><span>,                                    </span><span>-- task_order
</span><span>        '</span><span>generate_report</span><span>',                    </span><span>-- task_name
</span><span>        '</span><span>SELECT generate_weekly_report();</span><span>',   </span><span>-- command
</span><span>        </span><span>NULL                                  </span><span>-- database_connection
</span><span>    );
</span><span>
</span><span>    </span><span>INSERT INTO </span><span>timetable</span><span>.</span><span>task</span><span> (
</span><span>        chain_id,       
</span><span>        task_order,     
</span><span>        task_name,      
</span><span>        command,        
</span><span>        database_connection 
</span><span>    )
</span><span>    </span><span>VALUES</span><span> (
</span><span>        v_chain_id,
</span><span>        </span><span>2</span><span>,                                   </span><span>-- task_order (second task in the chain)
</span><span>        '</span><span>notify_management</span><span>',                 </span><span>-- task_name
</span><span>        '</span><span>SELECT pg_notify($1, $2)</span><span>',          </span><span>-- command
</span><span>        '</span><span>service=service_db</span><span>'                 </span><span>-- database_connection
</span><span>    )
</span><span>    RETURNING task_id INTO v_notify_task_id;
</span><span>
</span><span>    </span><span>INSERT INTO </span><span>timetable</span><span>.</span><span>task_parameter</span><span> (task_id, order_id, value) 
</span><span>    </span><span>VALUES
</span><span>        (v_notify_task_id, </span><span>1</span><span>, '</span><span>management_notifications</span><span>'),
</span><span>        (v_notify_task_id, </span><span>2</span><span>, '</span><span>Weekly report</span><span>');
</span><span>END</span><span>;
</span><span>$$ LANGUAGE plpgsql;
</span></code></pre>
<h2 id="the-comparison">The Comparison
</h2>
<p>When deciding between <code>pg_cron</code> and <code>pg_timetable</code>, it's essential to consider the specific needs of your use case, as both tools target different scenarios and scales of deployment. Here’s a comparison to help you decide which tool is more suitable for your requirements:</p>
<table><thead><tr><th>Feature</th><th>pg_cron</th><th>pg_timetable</th></tr></thead><tbody>
<tr><td>Distribution</td><td>PostgreSQL extension</td><td>Standalone executable</td></tr>
<tr><td>Scheduling</td><td>Limited (cron-like)</td><td>Extensive (intervals, calendar, custom)</td></tr>
<tr><td>Job Types</td><td>SQL</td><td>SQL, Built-in, Shell</td></tr>
<tr><td>Job Chaining</td><td>No</td><td>Yes</td></tr>
<tr><td>Error Handling</td><td>Basic</td><td>Intermediate</td></tr>
<tr><td>Logging</td><td>Basic</td><td>Intermediate</td></tr>
<tr><td>Dependencies</td><td>No</td><td>Yes</td></tr>
<tr><td>Ease of Use</td><td>Easy</td><td>Moderate</td></tr>
<tr><td>Configuration</td><td>Easy</td><td>Moderate</td></tr>
<tr><td>Orchestration</td><td>Single Cluster</td><td>Advanced (multiple clusters)</td></tr>
</tbody></table>
<h3 id="when-to-use-pg-cron">When to Use <code>pg_cron</code>
</h3>
<ol>
<li>If your requirements are straightforward, such as running maintenance tasks, refreshing materialised views, or generating periodic reports using simple SQL commands, <code>pg_cron</code> is an excellent choice. Its cron-like syntax is familiar and <strong>easy to use</strong>.</li>
<li><code>pg_cron</code> is a PostgreSQL extension, making it <strong>easier to install</strong> and configure within your existing PostgreSQL environment. This makes it ideal for users who prefer minimal setup effort.</li>
<li>When your environment is limited to a <strong>single PostgreSQL cluster</strong>, <code>pg_cron</code> is well-suited for the job. It does not support orchestration across multiple clusters, so it’s best used in environments where all operations are confined to one database cluster.</li>
<li>If <strong>Basic Error Handling and Logging</strong> is sufficient, <code>pg_cron</code> provides the necessary functionalities without additional complexity.</li>
</ol>
<h3 id="when-to-use-pg-timetable">When to Use <code>pg_timetable</code>
</h3>
<ol>
<li>If you need more <strong>advanced scheduling capabilities</strong> and <strong>task depedencies and chaining</strong>, such as task chaining, complex intervals, and custom execution times, <code>pg_timetable</code> is the better choice. It supports extensive scheduling options beyond the typical cron syntax.</li>
<li><code>pg_timetable</code> supports a <strong>variety of job types</strong>, including SQL commands, built-in tasks (like sending emails or downloading files), and shell commands. This makes it ideal for more complex automation needs that go beyond simple SQL execution.</li>
<li>If your environment spans multiple PostgreSQL clusters, <code>pg_timetable</code> can handle <strong>advanced orchestration</strong>, allowing tasks to be executed across different clusters seamlessly.</li>
<li><strong>Intermediate Error Handling and Logging</strong> provides better insights and control over job executions.</li>
<li>Although bit more complex to setup, <code>pg_timetable</code> works as <strong>standalone Service</strong>, which makes it suitable for environments where extensions cannot be installed directly.</li>
</ol>
<p>Choosing between <code>pg_cron</code> and <code>pg_timetable</code> depends on your specific needs. For simpler, single-cluster tasks, <code>pg_cron</code> offers ease of use and straightforward setup. For more complex requirements involving advanced scheduling, task dependencies, and multi-cluster orchestration, <code>pg_timetable</code> provides a more powerful and flexible solution.</p>
<p>By understanding the strengths and limitations of each tool, you can make an informed decision that best suits your database automation needs.</p>
<p>PS: there's also <a href="https://github.com/pgadmin-org/pgagent">pgAgent</a>, but it is generally not used and does not seem to be actively maintained.</p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to get stuff repaired when the manufacturer don't wanna: take 'em to court (355 pts)]]></title>
            <link>https://blog.simonrumble.com/how-to-get-your-stuff-repaired-when-the-retailer-and-manufacturer-dont-wanna-take-em-to-court</link>
            <guid>40702782</guid>
            <pubDate>Mon, 17 Jun 2024 06:14:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.simonrumble.com/how-to-get-your-stuff-repaired-when-the-retailer-and-manufacturer-dont-wanna-take-em-to-court">https://blog.simonrumble.com/how-to-get-your-stuff-repaired-when-the-retailer-and-manufacturer-dont-wanna-take-em-to-court</a>, See on <a href="https://news.ycombinator.com/item?id=40702782">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post_body_2116956"><div id="posthaven_gallery[2140350]">
          <p>
          <img src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3196658/CiUdmRx96L6fOGk-we1a_QjyMIk/medium_PXL_20240530_015115189.jpg" data-posthaven-state="processed" data-medium-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3196658/CiUdmRx96L6fOGk-we1a_QjyMIk/medium_PXL_20240530_015115189.jpg" data-medium-width="800" data-medium-height="450" data-large-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3196658/CiUdmRx96L6fOGk-we1a_QjyMIk/large_PXL_20240530_015115189.jpg" data-large-width="1200" data-large-height="675" data-thumb-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3196658/CiUdmRx96L6fOGk-we1a_QjyMIk/thumb_PXL_20240530_015115189.jpg" data-thumb-width="200" data-thumb-height="200" data-xlarge-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3196658/CiUdmRx96L6fOGk-we1a_QjyMIk/xlarge_PXL_20240530_015115189.jpg" data-xlarge-width="2400" data-xlarge-height="1350" data-orig-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/3196658/CiUdmRx96L6fOGk-we1a_QjyMIk/PXL_20240530_015115189.jpg" data-orig-width="4032" data-orig-height="2268" data-posthaven-id="3196658">
        </p>
          
        </div>
<p>A few weeks ago I was roasting some pumpkin for a delicious soup and towards the end of the cooking time the fan on the oven started into overdrive, making a lot of noise then it started beeping and popped up this obscure error message. I phoned the manufacturer, Electrolux, on the provided number and they told me I'd need to pay at least $160 to have their engineer come out and tell me what was wrong.</p><p>You've probably had this experience with lots of stuff. "Sorry, the item is out of warranty so you'll have to pay." The problem with this is that <a href="https://consumer.gov.au/consumers-and-acl">Australian Consumer Law</a> gives an <i>automatic</i> warranty. You can expect the item to last a reasonable amount of time. Now an old fashioned light bulb shouldn't be expected to last a decade, but an oven?</p><p>Challenged on this, I went around and around in circles with the Electrolux call centre worker. "So you think an oven should only last for two years?" and eventually I asked to be escalated to a manager who could actually make a decision. After some follow up, I finally got a call from a manager who was well drilled in shutting down any idea I should expect something from them. Eventually I said okay thanks, I'll see you at the Tribunal.</p><h2>How long should an appliance last?</h2><p>The "warranty" companies talk about is actually an "express warranty" and if you read them you'll notice these days they now include mandatory text about how they aren't able to exclude guarantees that come from the Australian Consumer Law. Anything they offer in their written warranty is in addition to your base rights.</p><p>So you have a reasonable expectation that your appliance will last a reasonable amount of time. So how long is reasonable? Well if you look around on the web you'll find different lengths of time for different classes of appliance. And if you buy the cheapest Chinesium appliance, you shouldn't expect it to last as long as the exxy Miele model.</p><h2>Time to book a court date</h2><p>NSW (and I think all the other states) has a tribunal especially for consumer claims, what used to be the "small claims court" is now the <a href="https://ncat.nsw.gov.au/" title="Link: https://ncat.nsw.gov.au/">NSW Civil and Administrative Tribunal</a>, NCAT. It's specifically designed to be low cost and straightforward. You shouldn't need a lawyer and can turn up with your documents.</p><p>The important thing to know about tribunals like NCAT is you're paying mostly with your time. You'll need to front up on the booked date and make your case. There's a small filing fee: in this case it was $58, which is still a lot less than Electrolux wanted to charge just to tell me what the problem was.</p><p>Before you book your date, you need to work out who is the other side of the transaction. You don't ordinarily go after the manufacturer but the retailer. So I contacted Appliances Online to talk it through. They took the same line as Electrolux that it was out of warranty and so not their problem. Again: see you in the Tribunal.</p><p>I filled in the forms. They're annoyingly slow, but the online system mostly works. Paid my fee and bingo, out comes an email with a tribunal date and location.</p><h2>Amazing service, just add NCAT date</h2><p>And the next day I get a call from the lovely Dylan from Appliances Online, someone who's evidently empowered to make decisions that make tribunal appointments go away. He tells me he'll get Electrolux to invoice them instead, an appointment is booked and we're off to the races.</p><p>One thing worth understanding is this: if the retailer has to send someone along to the Tribunal, they lose already. Even the cost of a junior lawyer going to the tribunal is going to be more than it would cost to repair your appliance. They might do it on principle if you're taking the piss but if you have a decent case they're wasting time and money.</p><h2>A couple of engineer visits</h2><p>Don't go cancelling your NCAT date just yet though! First you need the problem resolved. Remember, this could have all been resolved by them applying Australian Consumer Law when you first asked, so keep that clock ticking, it keeps things moving.</p><p>I had a lovely engineer from Electrolux visit and take a look. He wasn't sure what the problem was: tested the fan and heater element and found no problem. In the end he replaced the light bulb (which hadn't worked for years, we hadn't bothered replacing it) and the message had gone away anyway.</p><p>Next day the message is back, and Dylan drops me a note asking me to remove the NCAT booking. I respond saying it still isn't resolved and magically another engineer appointment pops up.</p><p>The second visit does the trick. The engineer replaced the heating element and fan and the message has gone away. We've done a few baking projects since and all seems good!</p><h2>Satisfaction, but annoyed I have to assert my rights</h2><p>So my oven is fixed. Otherwise it's a <i>great</i> oven. It's annoying that I have to push to get my consumer rights though. It should just be standard! My hope is that by encouraging others to also assert their rights it'll become easier. Don't put up with this shit about appliances having a tiny warranty period!<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Creativity Has Left the Chat: The Price of Debiasing Language Models (103 pts)]]></title>
            <link>https://arxiv.org/abs/2406.05587</link>
            <guid>40702617</guid>
            <pubDate>Mon, 17 Jun 2024 05:38:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2406.05587">https://arxiv.org/abs/2406.05587</a>, See on <a href="https://news.ycombinator.com/item?id=40702617">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="labstabs"><p>
    <label for="tabone">Bibliographic Tools</label></p><div>
      <h2>Bibliographic and Citation Tools</h2>
      <div>
          <p><label>
              
              <span></span>
              <span>Bibliographic Explorer Toggle</span>
            </label>
          </p>
          
        </div>
        
        
        
    </div>


    <p>
    <label for="tabtwo">Code, Data, Media</label></p><div>
      <h2>Code, Data and Media Associated with this Article</h2>
      

      
      
      
      
      
      
    </div>


      <p>
      <label for="labstabs-demos-input" id="labstabs-demos-label">Demos</label></p><div>
        <h2>Demos</h2>
        
        
        
        
      </div>
      <p>
      <label for="tabfour">Related Papers</label></p><div>
        <h2>Recommenders and Search Tools</h2>
        
        
        
        
        
        
      </div>

      <p>
      <label for="tabfive">
        About arXivLabs
      </label></p><div>
            <h2>arXivLabs: experimental projects with community collaborators</h2>
            <p>arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.</p>
            <p>Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.</p>
            <p>Have an idea for a project that will add value for arXiv's community? <a href="https://info.arxiv.org/labs/index.html"><strong>Learn more about arXivLabs</strong></a>.</p>
          </div>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Marion Stokes, the Woman Who Spent over 30 Years Recording Every Minute of US TV (161 pts)]]></title>
            <link>https://allthatsinteresting.com/marion-stokes</link>
            <guid>40702546</guid>
            <pubDate>Mon, 17 Jun 2024 05:23:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://allthatsinteresting.com/marion-stokes">https://allthatsinteresting.com/marion-stokes</a>, See on <a href="https://news.ycombinator.com/item?id=40702546">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<h2><p>The Astonishing Story Of Marion Stokes, The Woman Who Spent Over 30 Years Recording Every Minute Of U.S. Television</p></h2>
		  </div><div>
      <main role="main">
        <article itemprop="articleBody">
<h2>Beginning in 1979, former librarian Marion Stokes privately recorded broadcasts from multiple televisions at once, 24 hours a day, eventually accumulating a startling 71,000 tapes of television history.</h2><div id="attachment_475597"><p><img fetchpriority="high" decoding="async" aria-describedby="caption-attachment-475597" src="https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/marion-stokes.jpg" alt="Marion Stokes" width="900" height="462" srcset="https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/marion-stokes.jpg 900w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/marion-stokes-300x154.jpg 300w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/marion-stokes-768x394.jpg 768w" sizes="(max-width: 900px) 100vw, 900px"></p><p id="caption-attachment-475597"><span>Zeitgeist Films</span><span>Marion Stokes took it upon herself to record and archive every moment of television.</span></p></div>
<p>Marion Stokes believed that the news held crucial historical details at risk of disappearing forever. So, beginning around 1979, the former librarian and civil rights activist began obsessively recording television broadcasts 24 hours a day. </p>
<p>For more than three decades, Stokes attempted to archive every broadcast that she had access to, eventually recording programs on as many as eight televisions at once. In the end, she wound up with more than 70,000 recorded tapes. </p>
<p>Stokes was equal parts compulsive hoarder and guerrilla archivist, and her unique project has raised important questions about media preservation. Although she died in 2012, her project has been given new life thanks to the Internet Archive, which began the painstaking process of digitizing Stokes’ tapes in 2013. This massive undertaking is itself a years-long task, which shows just how prolific Marion Stokes’ work truly was. </p>

<p>Marion Marguerite Stokes was born on Nov. 25, 1929, in Philadelphia, Pennsylvania. Stokes grew up in the city’s Germantown neighborhood and attended Girls High School. From the 1940s to the early 1960s, she worked as a librarian at the Free Library of Philadelphia.</p>
<p>But it was Stokes’ later work as a <a href="https://allthatsinteresting.com/civil-rights-movement-photos" rel="noopener" target="_blank">civil rights</a> activist, working to help integrate Girard College, that initially made her a standout. She helped organize buses to the 1963 <a href="https://allthatsinteresting.com/march-on-washington" rel="noopener" target="_blank">March on Washington</a>, and served as a founding board member of the National Organization for Women. She was likewise the Chair for the Fair Play for Cuba Committee, an organization that opposed the economic boycott of Cuba. </p>
<div id="attachment_475596"><p><img decoding="async" aria-describedby="caption-attachment-475596" src="https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/marion-stokes-with-her-son.jpg" alt="Marion Stokes With Her Son" width="900" height="640" srcset="https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/marion-stokes-with-her-son.jpg 900w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/marion-stokes-with-her-son-300x213.jpg 300w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/marion-stokes-with-her-son-768x546.jpg 768w" sizes="(max-width: 900px) 100vw, 900px" data-src="https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/marion-stokes-with-her-son.jpg" data-srcset="https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/marion-stokes-with-her-son.jpg 900w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/marion-stokes-with-her-son-300x213.jpg 300w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/marion-stokes-with-her-son-768x546.jpg 768w" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p id="caption-attachment-475596"><span>Zeitgeist Films</span><span>Marion Stokes with her son, Michael.</span></p></div>
<p>In 1960, Stokes married a teacher named Melvin Metelits, with whom she had one son, Michael. The couple later split, and Marion would go on to marry television anchor John Stokes Jr., whom she met while working as a panelist on a local news show called <em>Input.</em> </p>
<p>The Stokeses later moved into a new home in Rittenhouse Square. Around 1975, Stokes bought herself a Betamax magnetic videotape recorder and began to casually record episodes of her favorite sit-coms, documentaries, and news broadcasts.</p>
<p>But in 1979, amid the Iran Hostage Crisis, something in Marion Stokes changed. </p>
<p>As her son Michael Metelits said in the 2019 documentary <em><a href="https://recorderfilm.com/" rel="noopener" target="_blank">Recorder: The Marion Stokes Project</a>,</em> “she hit record and she never stopped.”</p>
<h2>The Birth Of A Unique Obsession</h2>
<p>Marion Stokes became obsessed with chronicling and archiving news footage. She would purchase countless tapes, load them into the recorder, and let the television run all day long. </p>
<p>Every six to eight hours — depending on the length of the tape — she quickly swapped it out for a new one. Sometimes, this meant rushing home early from a meal to ensure she didn’t miss a second of a broadcast.</p>
<p>Gradually, she bought more and more TVs so she could document multiple programs at once until she was recording from eight different devices.</p>
<p>“It was just a logistical nightmare — that’s really the only way to put it,” Michael Metelits told <em><a href="https://www.fastcompany.com/3022022/the-incredible-story-of-marion-stokes-who-single-handedly-taped-35-years-of-tv-news" rel="noopener" target="_blank">Fast Company</a></em> in 2013.</p>
<div id="attachment_485763"><p><img decoding="async" aria-describedby="caption-attachment-485763" src="https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/archived-tapes.webp" alt="Archived Tapes" width="1280" height="1594" srcset="https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/archived-tapes.webp 1280w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/archived-tapes-241x300.webp 241w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/archived-tapes-723x900.webp 723w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/archived-tapes-768x956.webp 768w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/archived-tapes-1233x1536.webp 1233w" sizes="(max-width: 1280px) 100vw, 1280px" data-src="https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/archived-tapes.webp" data-srcset="https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/archived-tapes.webp 1280w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/archived-tapes-241x300.webp 241w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/archived-tapes-723x900.webp 723w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/archived-tapes-768x956.webp 768w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/archived-tapes-1233x1536.webp 1233w" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p id="caption-attachment-485763"><span>Family handout</span><span>Marion Stokes had to buy several additional apartments in which to store her tapes.</span></p></div>
<p>As one might expect, these tapes eventually began to take up space — a lot of it. By investing in Apple stock, Stokes saved enough money to buy as many as nine additional apartments, which she used as storage units to hold all of her tapes. </p>
<p>“Pretty much everything else took a back seat,” Metelits said. “It provided a certain rhythm to her life, and a certain amount of deep, deep conviction that this stuff was going to be useful. That somehow, someone would find a way to index it, archive it, store it — that it would be useful.”</p>
<p>The archives eventually grew to approximately 71,000 VHS and Betamax tapes, stored in various locations. These tapes contained not only news broadcasts but also sit-coms, commercials, and talk shows, recorded in Extended Play format. </p>
<div id="attachment_475595"><p><img loading="lazy" decoding="async" aria-describedby="caption-attachment-475595" src="https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/marion-stokes-recorder.jpeg" alt="Marion Stokes In Recorder" width="900" height="644" srcset="https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/marion-stokes-recorder.jpeg 900w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/marion-stokes-recorder-300x215.jpeg 300w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/marion-stokes-recorder-768x550.jpeg 768w" sizes="(max-width: 900px) 100vw, 900px" data-src="https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/marion-stokes-recorder.jpeg" data-srcset="https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/marion-stokes-recorder.jpeg 900w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/marion-stokes-recorder-300x215.jpeg 300w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/marion-stokes-recorder-768x550.jpeg 768w" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p id="caption-attachment-475595"><span>Zeitgeist Films</span><span>Marion Stokes often watched two televisions at a time, while several others ran throughout her home.</span></p></div>
<p>Stokes worried that facts and details from early news broadcasts could become lost or muddied as stories were retold over time. Little inconsistencies could start to add up, leaving viewers with no way of knowing how the story was originally reported. </p>
<p>“Television has been our most pervasive and persuasive medium,” said Roger MacDonald, the librarian in charge of the Internet Archive’s television portion. “But we’ve never really had much of a pause and rewind button on our experience of it to reflect back on television news, to compare and contrast and mine it for knowledge.”</p>
<p>Archiving television programs was not Stokes’ only fascination. In fact, the tech-savvy hoarder also took an early interest in Apple computers — and amassed 192 Macintosh computers before she died. </p>
<p>Still, it was her obsessive archiving of the daily news that would be her ultimate legacy.</p>
<h2>The Legacy And Lasting Impact Of Marion Stokes’ Work</h2>
<p>Marion Stokes continued to record and archive television footage up until the end. She lived to be 83 years old. And as it would turn out, her last day on Earth would coincide with her last recordings — and a horrible tragedy. </p>
<p>Stokes died on Dec. 14, 2012. That very same day, news organizations across the United States were reporting on the mass shooting at <a href="https://allthatsinteresting.com/false-flag-conspiracies" rel="noopener" target="_blank">Sandy Hook Elementary School</a>. </p>
<p>“I got to the house and this horrific news was going on,” Metelits said. “Kids being killed. Teachers being killed while shielding children, that sort of thing… I remember being very grateful that that wasn’t the last news she saw.”</p>
<p>Marion Stokes’ project died with her that day. Her son did not continue her archival work, saying he “came to respect her project, but it wasn’t my project.” </p>
<div id="attachment_485762"><p><img loading="lazy" decoding="async" aria-describedby="caption-attachment-485762" src="https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/recorder.webp" alt="Recorder" width="960" height="960" srcset="https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/recorder.webp 960w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/recorder-300x300.webp 300w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/recorder-900x900.webp 900w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/recorder-150x150.webp 150w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/recorder-768x768.webp 768w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/recorder-120x120.webp 120w" sizes="(max-width: 960px) 100vw, 960px" data-src="https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/recorder.webp" data-srcset="https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/recorder.webp 960w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/recorder-300x300.webp 300w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/recorder-900x900.webp 900w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/recorder-150x150.webp 150w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/recorder-768x768.webp 768w, https://allthatsinteresting.com/wordpress/wp-content/uploads/2024/04/recorder-120x120.webp 120w" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p id="caption-attachment-485762"><span>Family handout</span><span>In total, Stokes collected more than 400,000 hours of footage.</span></p></div>
<p>But while no new tapes would ever be added to Stokes’ collection, her project did find new life in 2013, just a year after her death, when the Internet Archive began the process of digitizing Stokes’ tapes and putting them online. </p>
<p>Then, in 2019, filmmaker Matt Wolf released his documentary about Marion Stokes, allowing audiences to understand Stokes’ obsession with archiving television. The film premiered at the Tribeca Film Festival and was met with positive reviews, with some critics noting that the film — and Stokes herself — made a compelling case for guerrilla archiving.</p>
<p>Marion Stokes’ story also resonates strongly today, albeit somewhat differently, as private ownership of the media we consume daily begins to fade. With more and more services shifting to a streaming or digital model, only to then restrict access to certain media or get rid of it altogether, many are considering the merits of physical media as a means of preserving history.</p>
<p>As MacDonald told <em>Fast Company</em>, some moments in television history have likely been lost forever.</p>
<p>“But who knows,” he said. “Because there may be other Marion Stokeses out there who had that similar passion.”</p>
<hr>
<p><em>After reading about the massive television archive kept by Marion Stokes, see 45 stunning unpublished photos from the </em><a href="https://allthatsinteresting.com/national-geographic-photos">National Geographic</a><em> archives. Or,<a href="https://allthatsinteresting.com/dorothy-height"> meet Dorothy Height</a>, the “Godmother” of the civil rights movement.</em></p>
        </article>
      </main>

      

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenBSD, the computer appliance maker's secret weapon (122 pts)]]></title>
            <link>https://hiandrewquinn.github.io/til-site/posts/openbsd-the-computer-appliance-maker-s-secret-weapon/</link>
            <guid>40702180</guid>
            <pubDate>Mon, 17 Jun 2024 03:53:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hiandrewquinn.github.io/til-site/posts/openbsd-the-computer-appliance-maker-s-secret-weapon/">https://hiandrewquinn.github.io/til-site/posts/openbsd-the-computer-appliance-maker-s-secret-weapon/</a>, See on <a href="https://news.ycombinator.com/item?id=40702180">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Between our ESP32 prokaryotic organisms and our 24/7 Internet-enabled
megafauna servers, there exists a vast and loosely-defined ecosystem of things
the
B2B world likes to call <strong>computer appliances</strong>. Picture a bespoke Pi 4 packaged
up neatly with some Python scripts, a little fancy plastic embossing, and maybe
a well-guarded <code>id_ed25519.pub</code> in case you end up in hot water during the
(long - very long, stable cash flow for generations long) maintenance contract,
and you’re in the ballpark.</p><p>This is the little slice of computing heaven I currently live within. In a lot
of ways it feels like what I imagine employed hackers of old in the 90s were up
to. You can’t feed your data into Grafana, but you <em>can</em> <code>tail -f /var/log/syslog</code>
and make
a tidy profit off of your long-gestating Bash/Perl scripting skills.
You probably can’t <code>terraform destroy &amp;&amp; terraform apply</code>, but when was the
last time you saw immutable infrastructure done right anyway? Et cetera,
et similia.</p><p>Hey, you know what’s really dangerous over the 15 to 30 year lifespan of an
average B2B computer appliance? <em>Forgetting stuff.</em> Everyone can feel their
way around Debian 12, 11, maybe even 10 – but how do you debug a service that
is running all the way back on Debian <em>4</em>? Let’s not even get into the horrors
of Windows XP-based appliances, which power more of the world than you want
to know.</p><p>If only there were a freely-usable set of Unix-like operating systems, with an
emphasis on keeping things very, very stable over releases, even more stable
than Debian does. Enter <strong>the BSDs</strong>. Free, Open, Net, take your pick. All of
them take a “don’t fix it if it ain’t broken” approach to things, which means
someone who started slinging NetBSD installs back in 2007 can probably spin up
a well-manicured VM of that 2007 install and reliably make their way around
the system, even today, in 2024.</p><p>I’ve recently
<a href="https://hiandrewquinn.github.io/til-site/posts/i-m-turning-30-so-i-m-switching-to-openbsd/">taken to learning OpenBSD</a>
for this very reason. And for reasons of security: While having the box not
physically connected to the Internet creates an activation energy to doing
something nasty with them that
99.9% of
ne’er-do-wells will ignore, the remaining 0.1% are likely to be
<em>really motivated</em> to want to do this. If they run into OpenBSD, however, their
efforts are quite likely to be thwarted just because the blowfish is so darn
spiky.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I learned Haskell in just 15 years (200 pts)]]></title>
            <link>https://duckrabbit.tech/articles/learning-haskell.html</link>
            <guid>40702146</guid>
            <pubDate>Mon, 17 Jun 2024 03:44:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://duckrabbit.tech/articles/learning-haskell.html">https://duckrabbit.tech/articles/learning-haskell.html</a>, See on <a href="https://news.ycombinator.com/item?id=40702146">Hacker News</a></p>
Couldn't get https://duckrabbit.tech/articles/learning-haskell.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[They make USB-C cables with displays now (168 pts)]]></title>
            <link>https://ounapuu.ee/posts/2024/06/05/usb-c-cables/</link>
            <guid>40701310</guid>
            <pubDate>Mon, 17 Jun 2024 00:37:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ounapuu.ee/posts/2024/06/05/usb-c-cables/">https://ounapuu.ee/posts/2024/06/05/usb-c-cables/</a>, See on <a href="https://news.ycombinator.com/item?id=40701310">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      <p>I’ve reached a point in my setup where most of the devices that I use are
based around the coveted USB-C port. This meant that I had a valid reason to get
a few extra because I didn’t yet have a stockpile of good USB-C cables.</p>
<p>That’s when I found out that there exist cables that have little screens on them
that show the power consumption of the connected device. This is a great little
addition
to <a href="https://ounapuu.ee/posts/2024/05/02/smartplugs/">my power consumption monitoring addiction.</a>
It’s also a simple way to understand if your device is charging at the speed
that you expect it to.</p>
<p>The cable I ordered cost 6.72 EUR. It is a bit stiff and hard to work with,
probably due to its supposed USB 4 support requiring actually good cabling and
shielding. It works well enough for an USB-C dock with a DisplayPort
connection that’s running a 3440x1440 display at 60 Hz.</p>
<p>It’s too early to give a definitive answer about the longevity of the cable.</p>
<p>You should be able to find these types of cables with a search query like “USB 4
Cable with LED Display”.</p>
<p>The paranoid side of me suspects that a cable like this one would be an ideal
place to hide a malicious chip. That’s the only downside that I can think of.</p>
<p>If you’re interested in going more in depth with measuring the power consumption
over USB, then you might want to look at other options.
<a href="https://github.com/fqueze/usb-power-profiling?tab=readme-ov-file#power-meters-known-to-work">This GitHub repository lists a few examples of these types of measuring devices.</a></p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Maintaining large-scale AI capacity at Meta (101 pts)]]></title>
            <link>https://engineering.fb.com/2024/06/12/production-engineering/maintaining-large-scale-ai-capacity-meta/</link>
            <guid>40700586</guid>
            <pubDate>Sun, 16 Jun 2024 22:18:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://engineering.fb.com/2024/06/12/production-engineering/maintaining-large-scale-ai-capacity-meta/">https://engineering.fb.com/2024/06/12/production-engineering/maintaining-large-scale-ai-capacity-meta/</a>, See on <a href="https://news.ycombinator.com/item?id=40700586">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

		<p><span>Meta is currently operating many data centers with GPU training clusters across the world. Our data centers are the backbone of our operations, meticulously designed to support the scaling demands of compute and storage. A year ago, however, as the industry reached a critical inflection point due to the rise of artificial intelligence (AI), we recognized that to lead in the generative AI space we’d need to transform our fleet.&nbsp;</span></p>
<p><span>Our increased focus on AI was driven both by its rise in driving business outcomes and the huge growth in these types of workloads’ computational needs. In addition to wider use of traditional AI for things like ad targeting, we have also seen increasing numbers of large generative AI models that mimic almost-human intelligence in everything from human verbal interaction to the creation of pictures and other media. And these types of models are huge, with trillions of training parameters, and to train them we need vast resources.&nbsp;</span></p>
<p><span>In this process, we’ve built one of the </span><a href="https://engineering.fb.com/2024/03/12/data-center-engineering/building-metas-genai-infrastructure/"><span>world’s largest AI training infrastructures</span></a><span>, and it has been growing exponentially over the last years. Meta’s training infrastructure comprises dozens of AI clusters of varying sizes, with a plan to scale to 600,000 GPUs in the next year. It runs thousands of training jobs every day from hundreds of different Meta teams. Training jobs characteristics vary greatly too. They can be as small as a single GPU running for a couple minutes, while generative AI jobs can have trillions of parameters and often span thousands of hosts that need to work together and are very sensitive to interruptions. In addition to that, training jobs are tied much closer to the hardware, and that hardware varies greatly. Meta runs different types of backend networks, topologies, and training jobs that have tight dependencies between software and hardware components.&nbsp;</span></p>
<p><span>This transition has not been without its challenges. We had to reconfigure the fleet without disrupting our hypergrowth, a task akin to rebuilding an airplane mid-flight. This pushed us to innovate and collaborate with vendors and utility companies to create a supportive ecosystem. In this blog we will discuss only one of these transformations. We will describe how Meta is maintaining these training clusters and what sets us apart from the average AI environment. And what do we mean by maintaining? Basically, any kind of operation that updates or verifies software and firmware components in the clusters, including the networking path.&nbsp;</span></p>
<h2><span>The main characteristics of GPU training</span></h2>
<p><span>GPU training has some demanding characteristics:</span></p>
<ul>
<li aria-level="1"><b>Capacity guarantees</b><span>: While some training jobs can be paused, a lot of Meta jobs are time-critical</span> <span>and recurring or online. This means we cannot take large amounts of capacity on a default basis.</span></li>
<li aria-level="1"><b>Bad hosts are very bad</b><span>: Since many jobs require all hosts to be synchronized, bad hosts that are a bit slower, have some non-fatal hardware, or have networking issues are extremely damaging.</span></li>
<li aria-level="1"><b>Low interruption rate</b><span>: Since many hosts work with each other on a shared problem, AI training jobs are sensitive to interruptions.&nbsp;</span></li>
<li aria-level="1"><b>Rollout safety</b><span>: The AI software stack is deep, and problems are often hard to pinpoint, so we need to be careful when rolling out new components.</span></li>
<li aria-level="1"><b>Host consistency</b><span>: AI training jobs are in general cross-host, and while outside of the CUDA version there are rarely hard incompatibilities, we have learned that cluster consistency is highly important for debugging and SEV avoidance.&nbsp;</span></li>
</ul>
<h2><span>What’s special about Meta’s GPU training?</span></h2>
<p><span>Meta uses bespoke training hardware with the newest chips possible and high-performance backend networks that are highly speed optimized. We also try to stay as current and flexible as possible with the software stack; in the event of firmware upgrades, this allows us to utilize new features or reduce failure rates.&nbsp;</span></p>
<p><span>Together this means we have more than:</span></p>
<ul>
<li aria-level="1"><span>30 maintenance operations</span></li>
<li aria-level="1"><span>50 different components that are updated&nbsp;</span></li>
<li aria-level="1"><span>Three different host-verification tasks to ensure optimal performance and stability</span></li>
<li aria-level="1"><span>Thousands of disruptive AI host tasks every day&nbsp;</span></li>
</ul>
<p><span>And we need to do them safely, while guaranteeing capacity. After all, our training clusters are also used flexibly to run a wide variety of workloads, from single-host to some of the biggest training jobs in the world, and from offline tasks to jobs that need to be up and running 24/7.</span></p>
<figure id="attachment_21311" aria-describedby="caption-attachment-21311"><img decoding="async" src="https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-1.png?w=1024" alt="" width="1024" height="462" srcset="https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-1.png 1600w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-1.png?resize=916,413 916w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-1.png?resize=768,347 768w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-1.png?resize=1024,462 1024w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-1.png?resize=1536,693 1536w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-1.png?resize=96,43 96w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-1.png?resize=192,87 192w" sizes="(max-width: 992px) 100vw, 62vw"><figcaption id="caption-attachment-21311">An overview of different maintenance rollouts happening on Meta capacity over time with overlapping durations.</figcaption></figure>
<p><span>Given the variety of upgrades, we have a large amount of overlapping inflight changes at any given time, including some that are consistently being applied, such as verification tasks. Accepting this gives Meta the flexibility we need in using cutting-edge hardware, scaling our infrastructure, and using both in flexible ways. In smaller environments it is often possible to keep clusters in a consistent state and upgrade the whole cluster and all of its firmware and software components in the same maintenance window. Doing this in a large, diverse environment like Meta, however, would introduce big risks and be operationally infeasible. Instead, we ensure components are compatible with each other and roll component upgrades up in a sliding fashion. This approach also allows us to guarantee capacity availability.&nbsp;</span></p>
<h2><span>Maintenance trains</span></h2>
<figure id="attachment_21312" aria-describedby="caption-attachment-21312"><img decoding="async" src="https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-2.jpg?w=1024" alt="" width="1024" height="295" srcset="https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-2.jpg 1999w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-2.jpg?resize=916,264 916w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-2.jpg?resize=768,221 768w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-2.jpg?resize=1024,295 1024w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-2.jpg?resize=1536,443 1536w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-2.jpg?resize=96,28 96w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-2.jpg?resize=192,55 192w" sizes="(max-width: 992px) 100vw, 62vw"><figcaption id="caption-attachment-21312">Meta maintains capacity by using maintenance trains, which involves shutting down small amounts of capacity in a cyclic fashion.</figcaption></figure>
<p><span>Outside of special cases, Meta maintains its fleet of clusters using a technique called maintenance trains. This is used for all capacity, including compute and storage capacity. A small number of servers are taken out of production and maintained with all applicable upgrades. Trains provide the guarantee that all capacity minus one maintenance domain is up and running 24/7, thus providing capacity predictability. This is mandatory for all capacity that is used for online and recurring training.</span></p>
<p><span>Maintenance trains pick up any new upgrade and guarantee a full-visit cycle in a guaranteed timeframe. Longer-running upgrades can have lower rollout guarantees and may be scheduled to be applied in multiple cycles. So you can have many overlapping upgrades, and, if beneficial, upgrades can be aligned.&nbsp;</span></p>
<p><span>For AI capacity, we have optimized domains that allow for different kinds of AI capacity, very strict SLOs, and a contract with services that allows them to avoid maintenance-train interruptions, if possible.&nbsp;</span></p>
<h2><span>Gradual rollouts</span></h2>
<figure id="attachment_21313" aria-describedby="caption-attachment-21313"><img loading="lazy" decoding="async" src="https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-3.jpg?w=571" alt="" width="195" height="350" srcset="https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-3.jpg 992w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-3.jpg?resize=511,916 511w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-3.jpg?resize=768,1377 768w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-3.jpg?resize=571,1024 571w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-3.jpg?resize=857,1536 857w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-3.jpg?resize=96,172 96w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-3.jpg?resize=192,344 192w" sizes="(max-width: 992px) 100vw, 62vw"><figcaption id="caption-attachment-21313">An illustration of the distinction between higher-level components of the AI stack—such as the CUDA drivers, and the lower-level components involved in the training job,.</figcaption></figure>
<p><span>Because of the scale of our infrastructure, we had to ensure that all disruptive rollouts outside of special cases happen in a gradual fashion. This means different servers in a cluster can run a different host stack for a short period of time. This is quite normal in traditional capacity but challenging in AI training, since AI jobs are very closely tied to the hardware.&nbsp;</span></p>
<p><span>At Meta, we’ve ensured that jobs have a consistent stack but upgrade lower-level components in a gradual fashion. In contrast to this, the AI job itself, which includes the CUDA library, is always consistent. </span><span>This distinction is necessary because lower-level components often require hours to install and configure or require rebooting the host, while higher-level components in the job container itself can be restarted fluidly. </span></p>
<p><span>This sounds simple, but because of the tight integration of AI with hardware, we have needed to do a lot of development, including careful testing on all lower levels, special monitoring, and tight work with vendors. </span></p>
<p><span>By and large, this has been very successful. The AI stack in general has matured a lot over the past three years. We also added tooling for rare compatibility-breaking upgrades.&nbsp;</span></p>

<h2><span>Selecting the correct maintenance domains&nbsp;</span></h2>
<figure id="attachment_21314" aria-describedby="caption-attachment-21314"><img loading="lazy" decoding="async" src="https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-4.jpg?w=916" alt="" width="916" height="623" srcset="https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-4.jpg 1950w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-4.jpg?resize=916,623 916w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-4.jpg?resize=768,522 768w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-4.jpg?resize=1024,696 1024w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-4.jpg?resize=1536,1044 1536w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-4.jpg?resize=96,65 96w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-4.jpg?resize=192,131 192w" sizes="(max-width: 992px) 100vw, 62vw"><figcaption id="caption-attachment-21314">Maintenance domains are selected based on the amount of buffer-reserved capacity (the smaller the better) and the amount of interruptions we cause to training jobs (the bigger the better).</figcaption></figure>
<p><span>One way to ensure optimal AI performance was to work with AI teams to design the optimal size of maintenance domains. A maintenance domain is the percentage of capacity we take down in one go, and selecting the optimal size is a function of both the cost of interruptions and the capacity that is lost during the maintenance duration. Since interruption costs are high for AI jobs, optimizing this relationship allowed us to significantly reduce the maintenance overhead for AI capacity.</span></p>
<h2><span>OpsPlanner: Meta disruptive-work orchestrator</span></h2>
<p><span>Critical to AI capacity are the consistency requirements. For example, if you want to move to a new CUDA version, you may need all of the capacity on a new driver version. This becomes really difficult in an environment with thousands of hosts and lots of planned and unplanned operations that may overlap with each other. To do this safely and guarantee hosts have the correct upgrades applied before entering production, Meta has unified them in the OpsPlanner work orchestrator. Not only can it work on overlapping scopes of operations and correctly serialize them, it also takes them safely out and into production. In addition, it has a built-in handover flow that ensures correct escalation behavior and avoids overlaps and deadlocks. OpsPlanner can also ensure upgrades are applied to hosts before they are returned to production. And OpsPlanner owns planned maintenance and failure buffers and safeguards them. Furthermore, it’s highly effective and efficient: OpsPlanner currently handles a million operations per day.&nbsp;</span></p>
<figure id="attachment_21315" aria-describedby="caption-attachment-21315"><img loading="lazy" decoding="async" src="https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-5.jpg?w=1024" alt="" width="1024" height="495" srcset="https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-5.jpg 1768w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-5.jpg?resize=916,442 916w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-5.jpg?resize=768,371 768w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-5.jpg?resize=1024,495 1024w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-5.jpg?resize=1536,742 1536w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-5.jpg?resize=96,46 96w, https://engineering.fb.com/wp-content/uploads/2024/06/Systems@scale_AI-Maintence_image-5.jpg?resize=192,93 192w" sizes="(max-width: 992px) 100vw, 62vw"><figcaption id="caption-attachment-21315">Example scenarios illustrating the disruptive work scheduler the OpsPlanner needs to handle to ensure host consistency.</figcaption></figure>
<h2><span>Safety and failure scenarios&nbsp;</span></h2>
<p><span>Meta has a deep stack of safety features that includes:</span><span><br>
</span></p>
<ul>
<li aria-level="1"><span>Autostop of maintenance trains if maintenance or failure buffers are exhausted;</span></li>
<li aria-level="1"><span>Automatic offboarding of failing upgrades; and</span></li>
<li aria-level="1"><span>Rollout phases for upgrades, so that only well-tested changes reach global systems.</span></li>
</ul>
<p><span>If something does go wrong, however, we can react quickly, depending on the needed fix, with emergency trains, large-scale maintenance for breaking upgrades, and more.</span></p>
<h2><span>Rapidly moving to the future of generative AI</span></h2>
<p><span>At Meta, we believe in moving fast and learning by doing. Rapid innovation is in our ethos. This is what fundamentally shaped our journey as we continually innovated towards building the foundational infrastructure that makes us leaders in generative AI. We will remain dedicated to creating technologies that not only benefit Meta but also have a positive impact on society as a whole.&nbsp;</span></p>
<p><span>As we move forward, we invite you to join us on this journey. Together, we can shape a future where AI is not just a tool but a force for good, transforming industries, empowering individuals, and creating a more sustainable world.</span></p>
<p><span>The best is yet to come, and we are excited to pioneer tomorrow’s possibilities in generative AI.</span></p>

		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: SQLite Database Explorer (167 pts)]]></title>
            <link>https://github.com/frectonz/sqlite-studio</link>
            <guid>40700343</guid>
            <pubDate>Sun, 16 Jun 2024 21:39:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/frectonz/sqlite-studio">https://github.com/frectonz/sqlite-studio</a>, See on <a href="https://news.ycombinator.com/item?id=40700343">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">SQLite Studio</h2><a id="user-content-sqlite-studio" aria-label="Permalink: SQLite Studio" href="#sqlite-studio"></a></p>
<p dir="auto">Single binary, single command SQLite database explorer.</p>
<div dir="auto" data-snippet-clipboard-copy-content="sqlite-studio <sqlite_db>"><pre>sqlite-studio <span>&lt;</span>sqlite_db<span>&gt;</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Overview page with common metadata.</li>
<li>Tables page with each table's metadata, including the disk size being used by each table.</li>
<li>Infinite scroll rows view.</li>
<li>A custom query page that gives you more access to your db.</li>
</ul>
<p dir="auto">More features available on the <a href="https://github.com/frectonz/sqlite-studio/releases">releases page</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Screenshots</h2><a id="user-content-screenshots" aria-label="Permalink: Screenshots" href="#screenshots"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Home Page</h3><a id="user-content-home-page" aria-label="Permalink: Home Page" href="#home-page"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/frectonz/sqlite-studio/blob/main/screenshots/homepage.png"><img src="https://github.com/frectonz/sqlite-studio/raw/main/screenshots/homepage.png" alt="homepage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Tables Page</h3><a id="user-content-tables-page" aria-label="Permalink: Tables Page" href="#tables-page"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/frectonz/sqlite-studio/blob/main/screenshots/tables.png"><img src="https://github.com/frectonz/sqlite-studio/raw/main/screenshots/tables.png" alt="tables"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/53809656/339976146-b6d8f627-4a21-46c2-bef7-8dea206b3689.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTg2MDk3MDIsIm5iZiI6MTcxODYwOTQwMiwicGF0aCI6Ii81MzgwOTY1Ni8zMzk5NzYxNDYtYjZkOGY2MjctNGEyMS00NmMyLWJlZjctOGRlYTIwNmIzNjg5LmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MTclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjE3VDA3MzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWYwOWExZjJhZDZjZTU3NDc4ZWFhOWViZmY0MjNhNzNmNjEwNzY4YzUwYjRkNGY4Njc4ZTJjNzg4ZjNlNDAxMDkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.xYlazaBFqPOQj-3JXdGLwu69ErTrZaSAf73buD_vGDk"><img src="https://private-user-images.githubusercontent.com/53809656/339976146-b6d8f627-4a21-46c2-bef7-8dea206b3689.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTg2MDk3MDIsIm5iZiI6MTcxODYwOTQwMiwicGF0aCI6Ii81MzgwOTY1Ni8zMzk5NzYxNDYtYjZkOGY2MjctNGEyMS00NmMyLWJlZjctOGRlYTIwNmIzNjg5LmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MTclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjE3VDA3MzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWYwOWExZjJhZDZjZTU3NDc4ZWFhOWViZmY0MjNhNzNmNjEwNzY4YzUwYjRkNGY4Njc4ZTJjNzg4ZjNlNDAxMDkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.xYlazaBFqPOQj-3JXdGLwu69ErTrZaSAf73buD_vGDk" alt="infinite scroll" data-animated-image=""></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Query Page</h3><a id="user-content-query-page" aria-label="Permalink: Query Page" href="#query-page"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/frectonz/sqlite-studio/blob/main/screenshots/query.png"><img src="https://github.com/frectonz/sqlite-studio/raw/main/screenshots/query.png" alt="query"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/53809656/339525291-3e47a890-ddd9-4c7f-be88-53e30cc23b15.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTg2MDk3MDIsIm5iZiI6MTcxODYwOTQwMiwicGF0aCI6Ii81MzgwOTY1Ni8zMzk1MjUyOTEtM2U0N2E4OTAtZGRkOS00YzdmLWJlODgtNTNlMzBjYzIzYjE1LmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MTclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjE3VDA3MzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWZlMGIwZTUxMWM4NmQ1NDg1MGUyYWYyMDEwMzgxNzAzMjE3MGEwNjYzOTk2N2JkZTMxNDMyYjFmYWRjZWIwZTgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.PAPxhum6gYAgbbmU1X3h6VJcDFdHJpwubPo9RYOxLCs"><img src="https://private-user-images.githubusercontent.com/53809656/339525291-3e47a890-ddd9-4c7f-be88-53e30cc23b15.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTg2MDk3MDIsIm5iZiI6MTcxODYwOTQwMiwicGF0aCI6Ii81MzgwOTY1Ni8zMzk1MjUyOTEtM2U0N2E4OTAtZGRkOS00YzdmLWJlODgtNTNlMzBjYzIzYjE1LmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MTclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjE3VDA3MzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWZlMGIwZTUxMWM4NmQ1NDg1MGUyYWYyMDEwMzgxNzAzMjE3MGEwNjYzOTk2N2JkZTMxNDMyYjFmYWRjZWIwZTgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.PAPxhum6gYAgbbmU1X3h6VJcDFdHJpwubPo9RYOxLCs" alt="query gif" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How To Run It</h2><a id="user-content-how-to-run-it" aria-label="Permalink: How To Run It" href="#how-to-run-it"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Pre-Built Binaries</h3><a id="user-content-pre-built-binaries" aria-label="Permalink: Pre-Built Binaries" href="#pre-built-binaries"></a></p>
<p dir="auto">You can find pre-built binaries for the following targets on the <a href="https://github.com/frectonz/sqlite-studio/releases">releases</a> page.</p>
<ul dir="auto">
<li>Linux <code>sqlite-studio_&lt;release&gt;_x86_64-unknown-linux-musl.zip</code></li>
<li>Windows <code>sqlite-studio_&lt;release&gt;_x86_64-pc-windows-gnu.zip</code></li>
<li>MacOS x86 <code>sqlite-studio_&lt;release&gt;_x86_64-apple-darwin.zip</code></li>
</ul>
<p dir="auto">After downloading the ZIP archive, you can extract it and get the binary.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Nix</h3><a id="user-content-nix" aria-label="Permalink: Nix" href="#nix"></a></p>
<p dir="auto">If you are using <a href="https://nixos.org/" rel="nofollow">Nix</a>, to build it from source.</p>
<div dir="auto" data-snippet-clipboard-copy-content="nix shell github:frectonz/sqlite-studio
sqlite-studio <sqlite_db>"><pre>nix shell github:frectonz/sqlite-studio
sqlite-studio <span>&lt;</span>sqlite_db<span>&gt;</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Before executing <code>cargo run</code> you need to build the UI because the rust app statically embedded the UI files in the binary.</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone git@github.com:frectonz/sqlite-studio.git
cd sqlite-studio
nix develop # if you use nix
cd ui
npm install
npm run build
cd ..
cargo run <sqlite_db>"><pre>git clone git@github.com:frectonz/sqlite-studio.git
<span>cd</span> sqlite-studio
nix develop <span><span>#</span> if you use nix</span>
<span>cd</span> ui
npm install
npm run build
<span>cd</span> ..
cargo run <span>&lt;</span>sqlite_db<span>&gt;</span></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why Google Takeout is sooo bad (128 pts)]]></title>
            <link>https://marcin.cylke.com.pl/2024/06/16/why-google-takeout-is-sooo-bad/</link>
            <guid>40700146</guid>
            <pubDate>Sun, 16 Jun 2024 21:12:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://marcin.cylke.com.pl/2024/06/16/why-google-takeout-is-sooo-bad/">https://marcin.cylke.com.pl/2024/06/16/why-google-takeout-is-sooo-bad/</a>, See on <a href="https://news.ycombinator.com/item?id=40700146">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p>















  
  
      
      
  <picture>
  <img src="https://marcin.cylke.com.pl/post_images/why-google-takeout-is-sooo-bad-0.png?v=583ac1f00b55e860bec2435a9f014ec7" alt="Image" loading="lazy" height="1024" width="1024">
</picture>

<em>Author: <a href="https://ideogram.ai/">IdeogramAI</a> Prompt: The image shows a typical Google Takeout interface with a large error message indicating that the service is unavailable. In the background, there are frustrated users trying to download their data with unsuccessful attempts, represented by repeated “Failed” and “Retry” notifications.</em></p>
<hr>
<p>My current data setup is centered around Google Cloud as a place where I store my data. That’s also related to how I use the whole vendor ecosystem.</p>
<p>The main issue I have with keeping the data only in Google Cloud is data safety. I just don’t want either identity theft or accidental block on my account (by Google) to cut me off from all of my previous photos. You might think it’s something close to impossible, but there are numerous examples of that happening to people - eg. look here <a href="https://www.nytimes.com/2022/08/21/technology/google-surveillance-toddler-photo.html">https://www.nytimes.com/2022/08/21/technology/google-surveillance-toddler-photo.html</a> And ok, this might be a reasonable approach from Google, but who knows what else can trigger that kind of blockage.</p>
<p>So, to be safe against anything similar or just any other data lose, it would be good to have some backup in place.</p>
<p>An ideal solution right now would be to:</p>
<ul>
<li>copy all the photos to some other cloud</li>
<li>have an offline copy of those files/photos</li>
</ul>
<p>Ideally both of those should happen automatically, according to some predefined schedule. Of course be as maintenance-free as possible.</p>
<p>I have ~200GB of data that I would like backed up on a regular basis. I’d imagine this is not the biggest set of photos a person can have stored there.</p>
<h2 id="first-attempts">First attempts</h2>
<p>My first approach was to synchronize all the files and all the photos using some syncing tools. Store them on a local hard drive, for future use. But that was less then satisfying. Mainly due to how long the process would take for my size of data.</p>
<p>There’s this open-source python tool <a href="https://github.com/gilesknap/gphotos-sync">https://github.com/gilesknap/gphotos-sync</a> - but I’m yet to try that. Although they also note on their project page issues with the backup process. Citing from there:</p>
<ul>
<li>Videos are transcoded to lower quality</li>
<li>Raw or Original photos are converted to ‘High Quality’</li>
<li>GPS info is removed from photos metadata</li>
</ul>
<p>Bad, but I could live with that, if treating this as a backup.</p>
<p>There’s also a paid tool <a href="https://photovaultone.com/">https://photovaultone.com/</a> - but it’s just another small vendor lock-in. I’d like to avoid getting deeper into other vendor to be protected from Google.</p>
<h2 id="so-theres-google-takeout">So there’s Google Takeout</h2>
<p>And yet, there’s this Google-offered option, that’s designed as a way to take all your data out of Google Cloud and potentially go to some other vendor, or host that on your own. Great idea! Of course Google, as other BigTech companies was coherced to implement it mainly due to GDPR restrictions - so that any user can take the data he/she owns and move out to other place.
Naturally, I thought I’d use this approach to backup my data.
This seemed even more amazing, as there’s an option to backup directly to other providers - the options are Dropbox, Microsoft OneDrive, Box.</p>
<p>I thought that using Microsoft OneDrive is a good alternative! Especially in terms of provider diversification. Also, the options of the backup would allow me to create a couple of bigger files - and copying those to my local backup would be much easier then doing so with hundreds of thousands of photos.</p>
<p>Choosing Microsoft OneDrive as an intermediate solution is just using another vendor. But the goal is to:</p>
<ul>
<li>have the data backed up in another cloud</li>
<li>be able to download the data in bigger chunks</li>
</ul>
<p>On the surface, it looks nice. You can create a scheduled backup process - that may happen at specified intervals, or you can do it one-time.
You can select data you want to export - be it just Photos, or maybe whole Google Drive, and Calendar, Gmail. Everything is there.</p>
<p>But when it actually needs to happen - that’s where the issues happen.</p>
<h2 id="issues">Issues</h2>
<ul>
<li>the process always fails - no matter what’s the size of a chunk I choose</li>
<li>the logs are kept only for some time, afer 7 days I’m not able to see what happened with the chunks. It’s easy to spot missing files - when you have parts from 1 to 10, but there’s a 7th missing. But what if there are 10 parts but should be 11?</li>
<li>no logs of the process</li>
<li>errors are very cryptic “Failed to backup”</li>
<li>tech support is non-existent - I’ve reached out to the tech support, but they were just passing my issue between different support divisions. Ultimately there were hints like “reinstall your operating system”, “turn it off and on”</li>
</ul>
<p>All in all I don’t see this whole process as <strong>extremely</strong> hard. Also, I totally understand those things may fail. But we, as an industry, know what to do with that. There are retries, informative logging. And here I got none of the above.</p>
<p>So for me, this broadly looks like Google just does not want people to backup their data outside of their cloud, which is super bad!</p>
<h2 id="important-considerations-that-i-may-have-missed">Important considerations that I may have missed</h2>
<p>I share my photo collection with my closest family. I suspect that Google Takeout won’t backup those shared photos. But my purpose <strong>is</strong> to do also copy those.</p>
<p>If I’ll be able to make this process reliable, I’d need to think of data retention on target.</p>
<p>Right now I backup just Google Photos - wanted to move to other parts of the ecosystem, when the backup issues are sorted out.</p>
<h2 id="follow-up-actions">Follow-up actions</h2>
<ul>
<li>try other providers - I don’t want to use Dropbox, but perhaps Box would work better then OneDrive?</li>
<li>are there tools that I’ve missed that might actually work?</li>
<li>schedule separate backup processes for other parts of the data stored in Google - they’ll be smaller and maybe that will result in successful backups</li>
<li>monitor the backup process state - based on target drive contents</li>
</ul>
<h2 id="closing-notes">Closing notes</h2>
<p>So, for know I still do the backups. I accept the issues with Google Takeout. It’s just better to have majority of my data, then to not have any of that.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MicroMac, a Macintosh for Under £5 (721 pts)]]></title>
            <link>https://axio.ms/projects/2024/06/16/MicroMac.html</link>
            <guid>40699684</guid>
            <pubDate>Sun, 16 Jun 2024 20:02:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://axio.ms/projects/2024/06/16/MicroMac.html">https://axio.ms/projects/2024/06/16/MicroMac.html</a>, See on <a href="https://news.ycombinator.com/item?id=40699684">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    
<p><a href="https://axio.ms/images/umac/umac_startup.png"> 
    <img src="https://axio.ms/images/umac/umac_startup.png" srcset="     https://axio.ms/images/umac/umac_startup.png 454w" width="100%" alt=" ">
 </a></p>

<h2 id="a-microcontroller-macintosh">A microcontroller Macintosh</h2>

<p>This all started from a conversation about the RP2040 MCU, and building a simple desktop/GUI for it.  I’d made a comment along the lines of “or, just run some old OS”, and it got me thinking about the <a href="https://en.wikipedia.org/wiki/Macintosh_128K">original Macintosh</a>.</p>

<p>The original Macintosh was released 40.5 years before this post, and is a pretty cool machine especially considering that the hardware is very simple.  <a href="https://www.stevenlevy.com/insanely-great">Insanely Great</a> and <a href="https://folklore.org/">folklore.org</a> are fun reads, and give a glimpse into the Macintosh’s development.  Memory was a squeeze; the original 128KB version was underpowered and only sold for a few months before being replaced by the <em>Macintosh 512K</em>, arguably a more appropriate amount of memory.</p>

<p>But, the 128 still runs <em>some</em> real applications and, though it pre-dates MultiFinder/actual multitasking, I found it pretty charming.  As a tourist.  In 1984 the Mac cost roughly 1/3 as much as a VW Golf and, as someone who’s into old computers and old cars, it’s hard to decide which is more frustrating to use.</p>

<p>So back to this £3.80 RPi Pico microcontroller board:  The RP2040’s 264KB of RAM gives a lot to play with after carving out the Mac’s 128KB – how cool would it be to do a quick hack, and play with a Mac on it?</p>

<p>Time passes.  A lot of time.  But I totally delivered on the janky hack front:</p>

<p><a href="https://axio.ms/images/umac/umac_whole.jpg"> 
    <img src="https://axio.ms/assets/resized/1400/umac_whole.jpg" srcset="            https://axio.ms/assets/resized/480/umac_whole.jpg 480w,            https://axio.ms/assets/resized/800/umac_whole.jpg 800w,            https://axio.ms/assets/resized/1400/umac_whole.jpg 1400w,    " width="100%" alt=" ">
 </a></p>

<p><del>You won’t believe that this quality item didn’t take that long to build.</del> So the software was obviously the <em>involved</em> part, and turned into work on 3 distinct projects.</p>

<p>This post is going to be a “development journey” story, as a kind of code/design/venting narrative.  If you’re just here for the pictures, scroll along!</p>

<h2 id="what-is-pico-mac">What is pico-mac?</h2>

<p>A Raspberry Pi RP2040 microcontroller (on a Pico board), driving monochrome VGA video and taking USB keyboard/mouse input, emulating a <em>Macintosh 128K</em> computer and disc storage.  The RP2040 has easily enough RAM to house the Mac’s memory, plus that of the emulator; it’s fast enough (with some tricks) to meet the performance of the real machine, has USB host capability, and the PIO department makes driving VGA video fairly uneventful (with some tricks).  The basic Pico board’s 2MB of flash is plenty for a disc image with OS and software.</p>

<p>Here’s the Pico MicroMac in action, ready for the paperless office of the future:</p>

<figure>
 <a href="https://axio.ms/images/umac/umac_workstation.jpg"> 
    <img src="https://axio.ms/assets/resized/1400/umac_workstation.jpg" srcset="            https://axio.ms/assets/resized/480/umac_workstation.jpg 480w,            https://axio.ms/assets/resized/800/umac_workstation.jpg 800w,            https://axio.ms/assets/resized/1400/umac_workstation.jpg 1400w,    " width="100%" alt=" The Pico MicroMac RISC CISC workstation of the future">
 </a> 
<figcaption>The Pico MicroMac RISC CISC workstation of the future</figcaption></figure>

<p>I hadn’t really used a <em>Mac 128K</em> much before; a few clicks on a museum machine once.  But I knew they ran MacDraw, and MacWrite, and MacPaint.  All three of these applications are pretty cool for a 128K machine; a largely WYSIWYG word processor with multiple fonts, and a vector drawing package.</p>

<p>A great way of playing with early Macintosh system software, and applications of these wonderful machines is via <a href="https://infinitemac.org/">https://infinitemac.org</a>, which has shrinkwrapped running the Mini vMac emulator by emscriptening it to run in the browser.  Highly recommended, lots to play with.</p>

<p>As a spoiler, MicroMac does run MacDraw, and it was great to play with it on “real fake hardware”:</p>

<p><a href="https://axio.ms/images/umac/umac_workstation2.jpg"> 
    <img src="https://axio.ms/assets/resized/1400/umac_workstation2.jpg" srcset="            https://axio.ms/assets/resized/480/umac_workstation2.jpg 480w,            https://axio.ms/assets/resized/800/umac_workstation2.jpg 800w,            https://axio.ms/assets/resized/1400/umac_workstation2.jpg 1400w,    " width="100%" alt=" ">
 </a></p>

<p>(Do you find “Pico Micro Mac” doesn’t really scan?  I didn’t think this taxonomy through, did I?)</p>

<p>GitHub links are at the bottom of this page:  the <code>pico-mac</code> repo has <a href="https://github.com/evansm7/pico-mac?tab=readme-ov-file#hardware-contruction">construction directions</a> if you want to build your own!</p>

<h2 id="the-journey">The journey</h2>

<p>Back up a bit.  I wasn’t committed to building a Pico thing, but was vaguely interested in whether it was feasible, so started tinkering with building a <em>Mac 128K emulator</em> on my normal computer first.</p>

<h3 id="the-three-rules">The three rules</h3>

<p>I had a few simple rules for this project:</p>

<ol>
  <li>It had to be fun.  It’s OK to hack stuff to get it working, it’s not as though I’m being paid for this.</li>
  <li>I like writing emulation stuff, but I really don’t want to learn 68K assembler, or much about the 68K.  There’s a lot of love for 68K out there and that’s cool, but meh I don’t adore it as a CPU.  So, right from the outset I wanted to use someone else’s 68K interpreter – I knew there were loads around.</li>
  <li>Similarly, there are a load of OSes whose innards I’d like to learn more about, but the shittiest early Mac System software isn’t high on the list.  Get in there, emulate the hardware, boot the OS as a black box, done.</li>
</ol>

<p>I ended up breaking 2 of and sometimes all 3 of these rules during this project.</p>

<h3 id="the-mac-128k">The Mac 128K</h3>

<p>The machines are generally pretty simple, and of their time.  I started with schematics and <em>Inside Macintosh</em>, PDFs of which covered various details of the original Mac hardware, memory map, mouse/keyboard, etc.</p>
<ul>
  <li><a href="https://tinkerdifferent.com/resources/macintosh-128k-512k-schematics.79/">https://tinkerdifferent.com/resources/macintosh-128k-512k-schematics.79/</a></li>
  <li><a href="https://vintageapple.org/inside_o/">https://vintageapple.org/inside_o/</a> <em>Inside Macintosh Volumes I-III</em> are particularly useful for hardware information; also <em>Guide to Macintosh Family Hardware 2nd Edition</em>.</li>
</ul>

<p>The Macintosh has:</p>
<ul>
  <li>A Motorola 68000 CPU running at <del>7.whatever MHz</del> roughly 8MHz</li>
  <li>Flat memory, decoded into regions for memory-mapped IO going to the 6522 VIA, the 8530 SCC, and the IWM floppy controller.  (Some of the address decoding is a little funky, though.)</li>
  <li>Keyboard and mouse hang off the VIA/SCC chips.</li>
  <li>No external interrupt controller: the 68K has 3 IRQ lines, and there are 3 IRQ sources (VIA, SCC, programmer switch/NMI).</li>
  <li>“No slots” or expansion cards.</li>
  <li>No DMA controller: a simple autonomous PAL state machine scans video (and audio samples) out of DRAM.  Video is fixed at 512x342 1BPP.</li>
  <li>The only storage is an internal FDD (plus an external drive), driven by the IWM chip.</li>
</ul>

<p>The first three Mac models are extremely similar:</p>
<ul>
  <li>The <em>Mac 128K</em> and <em>Mac 512K</em> are the same machine, except for RAM.</li>
  <li>The <em>Mac Plus</em> added SCSI to a convenient space in the memory map and an 800K floppy drive, which is double-sided whereas the original was a single 400K side.</li>
  <li>The <em>Mac Plus</em> ROM also supports the 128K/512K, and was an upgrade to create the <em>Macintosh 512Ke</em>.  ‘e’ for Extra ROM Goodness.</li>
</ul>

<p>The <em>Mac Plus</em> ROM supports the HD20 external hard disc, and HFS, <em>and</em> Steve Chamberlin has <a href="https://www.bigmessowires.com/rom-adapter/plus-rom-listing.asm">annotated a disassembly of it</a>.  This was the ROM to use:  I was making a <em>Macintosh 128Ke</em>.</p>

<h3 id="mac-emulator-umac">Mac emulator: umac</h3>

<p>After about 8 minutes of research, I chose the <a href="https://github.com/kstenerud/Musashi">Musashi</a> 68K interpreter.  It’s C, simple to interface to, and had a simple out-of-box example of a 68K system with RAM, ROM, and some IO.  <em>Musashi</em> is structured to be embedded in bigger projects: wire in memory read/write callbacks, a function to raise an IRQ, call execute in a loop, done.</p>

<p>I started building an emulator around it, which ultimately became the <a href="https://github.com/evansm7/umac">umac</a> project.  The first half (of, say, five halves) went pretty well:</p>

<ol>
  <li>A simple commandline app loading the ROM image, allocating RAM, providing debug messages/assertions/logging, and configuring <em>Musashi</em>.</li>
  <li>Add address decoding: CPU reads/writes are steered to RAM, or ROM.  The “overlay” register lets the ROM boot at <code>0x00000000</code> and then trampoline up to a high ROM mirror after setting up CPU exception vectors – this affects the address decoding.  This is done by poking a VIA register, so decoded just that bit of that register for now.</li>
  <li>At this point, the ROM starts running and accessing more non-existent VIA and SCC registers.  Added more decoding and a skeleton for emulating these devices elsewhere – the MMIO read/writes are just stubbed out.</li>
  <li>There are some magic addresses that the ROM accesses that “miss” documented devices: there’s a manufacturing test option that probes for a plugin (just thunk it), and then we witness the RAM size probing.  The <em>Mac Plus</em> ROM is looking for up to 4MB of RAM.  In the large region devoted to RAM, the smaller amount of actual RAM is mirrored over and over, so the probe writes a magic value at high addresses and spots where it starts to wrap around.</li>
  <li>RAM is then initialised and filled with a known pattern.  This was an exciting point to get to because I could dump the RAM, convert the region used for the video framebuffer into an image, and see the “diagonal stripe” pattern used for RAM testing!  <em>“She’s alive!”</em></li>
  <li>Not all of the device code enjoyed reading all zeroes, so there was a certain amount of referring to the disassembly and returning, uh, <code>0xffffffff</code> sometimes to push it further.  The goal was to get it as far as accessing the IWM chip, i.e. trying to load the OS.</li>
  <li>After seeing some IWM accesses there and returning random rubbish values, the first wonderful moment was getting the “Unknown Disc” icon with the question mark – real graphics!  The ROM was <em>REALLY DOING SOMETHING!</em></li>
  <li>I <em>think</em> I hadn’t implemented any IRQs at this point, and found the ROM in an infinite loop: it was counting a few Vsyncs to delay the flashing question mark.  Diversion into a better VIA, with callbacks for GPIO register read/write, and IRQ handling.  This also needed to wire into <em>Musashi</em>’s IRQ functions.</li>
</ol>

<p>This was motivating to get to – remembering rule #1 – and “graphics”, even though via a manual memory dump/ImageMagick conversion, was great.</p>

<p>I knew the <a href="https://en.wikipedia.org/wiki/Integrated_Woz_Machine">IWM</a> was an “interesting” chip, but didn’t know details.  I planned to figure it out when I got there (rule #1).</p>

<h4 id="iwm-68k-and-disc-drivers">IWM, 68K, and disc drivers</h4>

<p>My god, I’m glad I put IWM off until this point.  If I’d read the “datasheet” (vague register documentation) first, I’d’ve just gone to the pub instead of writing this shitty emulator.</p>

<p>IWM is very clever, but very very low-level.  The disc controllers in other contemporary machines, e.g. <a href="https://en.wikipedia.org/wiki/Western_Digital_FD1771">WD1770</a>, abstract the disc physics.  At one level, you can poke regs to step to track 17 and then ask the controller to grab sector 3.  Not so with IWM:  first, the discs are Constant Linear Velocity, meaning the angular rotation needs to change appropriate to whichever track you’re on, and second the IWM just gives the CPU a firehose of crap from the disc head (with minimal decoding).  I spent a while reading through the disassembly of the ROM’s IWM driver (breaking rule #2 and rule #1): there’s some kind of servo control loop where the driver twiddles PWM values sent to a DAC to control the disc motor, measured against a VIA timer reference to do some sort of dynamic rate-matching to get the correct bitrate from the disc sectors.  I think once it finds the track start it then streams the track into memory, and the driver decodes the symbols (more clever encoding) and selects the sector of interest.</p>

<p>I was sad.  Surely <em>Basilisk II</em> and <em>Mini vMac</em> etc. had solved this in some clever way – they emulated floppy discs.  I learned they do not, and do the smart engineering thing instead:  avoid the problem.</p>

<p>The other emulators do quite a lot of ROM patching: the ROM isn’t run unmodified.  You can argue that this then isn’t a perfect hardware emulation if you’re patching out inconvenient parts of the ROM, but so what.  I suspect they were also abiding by a rule #1 too.</p>

<p>I was going to do the same:  I figured out a bit of how the Mac driver interface works (gah, rule #3!) and understood how the other emulators patched this.  They use a custom <em>paravirtualised</em> 68K driver which is copied over the ROM’s IWM driver, servicing <code>.Sony</code> requests from the block layer and routing them to more convenient host-side code to manage the requests.  <em>Basilisk II</em> uses some custom 68K opcodes and a simple driver, and <em>Mini vMac</em> a complex driver with trappy accesses to a custom region of memory.  I reused the <em>Basilisk II</em> driver but converted to access a trappy region (easier to route: just emulate another device).  The driver callbacks land in the host/C side and some cut-down <em>Basilisk II</em> code interprets the requests and copies data to/from the OS-provided buffers.  Right now, all I needed was to read blocks from one disc:  I didn’t need different formats (or even write support), or multiple drives, or ejecting/changing images.</p>

<p>Getting the first block loaded from disc took waaaayyy longer than the first part.  And, I’d had to learn a bit of 68K (gah), but just in the nick of time I got a Happy Mac icon as the System software started to load.</p>

<p>This was still a simple Linux commandline application, with zero UI.  No keyboard or mouse, no video.  Time to wrap it in an SDL2 frontend (the <code>unix_main</code> test build in the <code>umac</code> project), and I could watch the screen redraw live.  I hadn’t coded the 1Hz timer interrupt into the VIA, and after adding that it booted to a desktop!</p>

<figure>
 <a href="https://axio.ms/images/umac/umac_first_desktop.png"> 
    <img src="https://axio.ms/assets/resized/480/umac_first_desktop.png" srcset="            https://axio.ms/assets/resized/480/umac_first_desktop.png 480w,    " width="100%" alt=" The first boot">
 </a> 
<figcaption>The first boot</figcaption></figure>

<p>As an aside, I try to create a dual-target build for all my embedded projects, with a native host build for rapid prototyping/debugging; libSDL instead of an LCD.  It means I don’t need to code <em>at</em> the MCU, so I can code in the garden.  :)</p>

<p>Next was mouse support.  <em>Inside Macintosh</em> and the schematics show how it’s wired, to the VIA (good) and the SCC (a beast).  The SCC is my second least-favourite chip in this machine; it’s complex and the datasheet/manual seems to be intentionally written to hide information, piss off readers, get one back at the world.  (I didn’t go near the serial side, its main purpose, just external IRQ management.  But, it’ll do all kinds of exciting 1980s line coding schemes, offloading bitty work from the CPU.  It was key for supporting things like AppleTalk.)</p>

<p>Life was almost complete at this point; with a working mouse I could build a new disc image (using <em>Mini vMac</em>, an exercise in itself) with <em>Missile Command</em>.  This game is pretty fun for under 10KB on disc.</p>

<p>So:</p>
<ul>
  <li>Video works</li>
  <li>Boots from disc</li>
  <li>Mouse works, Missile Command</li>
</ul>

<p>I had no keyboard, but it’s largely working now.  Time to start on sub-project numero due:</p>

<h3 id="hardware-and-rp2040">Hardware and RP2040</h3>

<p>Completely unrelated to <code>umac</code>, I built up a circuit and firmare with two goals:</p>

<ol>
  <li>Display 512x342x1 video to VGA with minimal components,</li>
  <li>Get the TinyUSB HID example working and integrated.</li>
</ol>

<p>This would just display a test image copied to a framebuffer, and <code>printf()</code> keyboard/mouse events, as a PoC.  The video portion was fun:  I’d done some <code>I2S</code> audio PIO work before, but here I wanted to scan out video and arbitrarily control Vsync/Hsync.</p>

<p>Well, to test I needed a circuit.  VGA wants 0.7V max on the video R,G,B signals and (mumble, some volts) on the syncs.  The R,G,B signals are 75Ω to ground:  with some maths, a 3.3V GPIO driving all three through a 100Ω resistor is roughly right.</p>

<p>The day I started soldering it together I needed a VGA connector.  I had a DB15 but wanted it for another project, and felt bad about cutting up a VGA cable.  But when I took a walk at lunchtime, no shitting you, I passed some street cables.  I had a VGA cable – the rust helps with the janky aesthetic.</p>

<figure>
 <a href="https://axio.ms/images/umac/street_wire.jpg"> 
    <img src="https://axio.ms/assets/resized/1400/street_wire.jpg" srcset="            https://axio.ms/assets/resized/480/street_wire.jpg 480w,            https://axio.ms/assets/resized/800/street_wire.jpg 800w,            https://axio.ms/assets/resized/1400/street_wire.jpg 1400w,    " width="100%" alt=" Free VGA cable">
 </a> 
<figcaption>Free VGA cable</figcaption></figure>

<p>The <a href="https://github.com/evansm7/pico-mac/blob/main/src/pio_video.pio">VGA PIO side</a> was pretty fun.  It ended up as PIO reading config info dynamically to control Hsync width, display position, and so on, and then some tricks with DMA to scan out the config info interleaved with framebuffer data.  By shifting the bits in the right direction and by using the byteswap option on the RP2040 DMA, the big-endian Mac framebuffer can be output directly without CPU-side copies or format conversion.  Cool.  This can be fairly easily re-used in other projects: see <a href="https://github.com/evansm7/pico-mac/blob/main/src/video.c">video.c</a>.</p>

<p>But.  I ended up (re)writing the video side three times in total:</p>

<p>First version had two DMA channels writing to the PIO TX FIFO.  The first would transfer the config info, then trigger the second to transfer video data, then raise an IRQ.  The IRQ handler would then have a short time (the FIFO depth!) to choose a new framebuffer address to read from, and reprogram DMA.  It worked OK, but was highly sensitive to other activity in the system.  First and most obvious fix is that any latency-sensitive IRQ handler <em>must</em> have the <code>__not_in_flash_func()</code> attribute so as to run out of RAM.  But even with that, the design didn’t give much time to reconfigure the DMA:  random glitches and blanks occurred when moving the mouse rapidly.</p>

<p>Second version did double-buffering with the goal of making the IRQ handler’s job trivial: poke in a pre-prepared DMA config quickly, then after the critical rush calculate the buffer to use for next time.  Lots better, but still some glitches under some high load.  Even weirder, it’d sometimes just blank out completely, requiring a reset.  This was puzzling for a while; I ended up printing out the PIO FIFO’s <code>FDEBUG</code> register to try to catch the bug in the act.  I saw that the <code>TXOVER</code> overflow flag was set, and this should be impossible: the FIFOs pull data from DMA on demand with DMA requests and a credited flow-contr…OH WAIT.  If credits get messed up or duplicated, too many transfers can happen, leading to an overflow at the receiver side.</p>

<p>Well, I’d missed a subtle rule in the RP2040 DMA docs:</p>

<blockquote>
  <p>Another caveat is that multiple channels should not be connected to the same DREQ.</p>
</blockquote>

<p>So the third version…… doesn’t break this rule, and is more complicated as a result:</p>
<ul>
  <li>One DMA channel transfers to the PIO TX FIFO</li>
  <li>Another channel programs the first channel to send from the config data buffer</li>
  <li>A third channel programs the first to send the video data</li>
  <li>The programming of the first triggers the corresponding “next reprogram me” channel</li>
</ul>

<p>The nice thing – aside from no lock-ups or video corruption – is that this now triggers a Hsync IRQ during the video line scan-out, greatly relaxing the deadline of reconfiguring the DMA.  I’d like to further improve this (with yet another DMA channel) to transfer without an IRQ per line, as the current IRQ overhead of about 1% of CPU time can be avoided.</p>

<p>(It would’ve been simpler to just hardwire the VGA display timing in the PIO code, but I like (for future projects) being able to dynamically-reconfigure the video mode.)</p>

<p>So now we have a platform and firmware framework to embed <code>umac</code> into, HID in and video out.  The hardware’s done, fuggitthat’lldo, let’s throw it over to the software team:</p>

<figure>
 <a href="https://axio.ms/images/umac/umac_annotated.jpg"> 
    <img src="https://axio.ms/assets/resized/2048/umac_annotated.jpg" srcset="            https://axio.ms/assets/resized/480/umac_annotated.jpg 480w,            https://axio.ms/assets/resized/800/umac_annotated.jpg 800w,            https://axio.ms/assets/resized/1400/umac_annotated.jpg 1400w,            https://axio.ms/assets/resized/2048/umac_annotated.jpg 2048w,    " width="100%" alt=" How it all works">
 </a> 
<figcaption>How it all works</figcaption></figure>

<h3 id="back-to-emulating-things">Back to emulating things</h3>

<p>A glance at the native <code>umac</code> binary showed a few things to fix before it could run on the Pico:</p>

<ul>
  <li><em>Musashi</em> constructed a <em>huge</em> opcode decode jumptable at runtime, in RAM.  It’s never built differently, and never changes at runtime.  I added a <em>Musashi</em> build-time generator so that this table could be <code>const</code> (and therefore live in flash).</li>
  <li>The disassembler was large, and not going to be used on the Pico, so another option to build without.</li>
  <li><em>Musashi</em> tries to accurately count execution cycles for each instruction, with more large lookup tables.  Maybe useful for console games, but the Mac doesn’t have the same degree of timing sensitivity.  <em>REMOVED</em>.</li>
</ul>

<p>(This work is in my <a href="https://github.com/evansm7/Musashi/commits/small-build/">small-build</a> branch.)</p>

<p><code>pico-mac</code> takes shape, with the ROM and disc image in flash, and enjoyably it now builds and runs on the Pico!  With some careful attention to not shoving stuff in RAM, the RAM use is looking pretty good.  The emulator plus HID code is using about 35-40KB on top of the Mac’s 128KB RAM area – there’s 95+KB of RAM still free.</p>

<p>This was a good time to finish off adding the keyboard support to <code>umac</code>.  The Mac keyboard is interfaced serially through the VIA ‘shift register’, a basic synchronous serial interface.  This was logically simple, but frustrating because early attempts at replying to the ROM’s “init” command just were persistently ignored.  The ROM disassembly was super-useful again: reading the keyboard init code, it looked like a race condition in interrupt acknowledgement if the response byte appears too soon after the request is sent.  Shoved in a delay to hold off a reply until a later poll, and then it was just a matter of mapping keycodes (boooooorrrriiiiing).</p>

<p>With a keyboard, the end-of-level MacWrite boss is reached:</p>

<p><a href="https://axio.ms/images/umac/umac_macwrite.jpg"> 
    <img src="https://axio.ms/assets/resized/2048/umac_macwrite.jpg" srcset="            https://axio.ms/assets/resized/480/umac_macwrite.jpg 480w,            https://axio.ms/assets/resized/800/umac_macwrite.jpg 800w,            https://axio.ms/assets/resized/1400/umac_macwrite.jpg 1400w,            https://axio.ms/assets/resized/2048/umac_macwrite.jpg 2048w,    " width="100%" alt=" ">
 </a></p>

<p>One problem though:  it totally sucked.  It was suuuuper slow.  I added a 1Hz dump of instruction count, and it was doing about 300 KIPS.</p>

<p>The 68000 isn’t an amazing CPU in terms of IPC.  Okay, there are some instructions that execute in 4 cycles.  But you want to use those extravagant addressing modes don’t you, and touching memory is spending those cycles all over the place.  Not an expert, but targeting about 1 MIPS for an about 8MHz 68000 seems right.  Only 3x improvement needed.</p>

<h3 id="performance">Performance</h3>

<p>I didn’t say I wasn’t gonna cheat:  let’s run that Pico at 250MHz instead of 125MHz.  Okay better, but not 2x better.  From memory, only about 30% better.  Damn, no free lunch today.</p>

<p><em>Musashi</em> has a lot of configurable options.  My first goal was to get its main loop (as seen from disassembly/post-compile end!) small:  the Mac doesn’t report Bus Errors, so the registers don’t need copies for unwinding.  The opcodes are always fetched from a 16b boundary, so don’t need alignment checking, and can use halfword loads (instead of two byte loads munged into a halfword!).  For the Cortex-M0+/<code>armv6m</code> ISA, reordering some of the CPU context structure fields enabled immediate-offset access and better code.  The CPU type, mysteriously, was dynamically-changeable and led to a bunch of runtime indirection.</p>

<p>Looking better, maybe 2x improvement, but not enough.  <em>Missile Command</em> was still janky and the mouse wasn’t smooth!</p>

<p>Next, some naughty/dangerous optimisations: remove address alignment checking, because unaligned accesses don’t happen <em>in this constrained environment</em>.</p>

<p>(Then, this work is in my <a href="https://github.com/evansm7/Musashi/commits/umac-hacks">umac-hacks</a> branch.)</p>

<p>But the real perf came from a different trick.  First, a diversion!</p>

<h4 id="rp2040-memory-access">RP2040 memory access</h4>

<p>The RP2040 has fast RAM, which is multi-banked so as to allow generally single-cycle access to multiple users (2 CPUs, DMA, etc.).  Out of the box, most code runs via XIP from external QSPI flash.  The QSPI usually runs at the core clock (125MHz default), but has a latency of ~20 cycles for a random word read.  The RP2040 uses a relatively simple 16KB cache in front of the flash to protect you from horrible access latency, but the more code you have the more likely you are to call a function and have to crank up QSPI.  When overclocking to 250MHz, the QSPI can’t go that fast so stays at 125MHz (I think).  Bear in mind, then, that your 20ish QSPI cycles on a miss become 40ish CPU cycles.</p>

<p>The particular rock-and-a-hard-place here is that <em>Musashi</em> build-time generates a ton of code, a function for each of its 1968 opcodes, plus that 256KB opcode jumptable.  Even if we make the inner execution loop completely free, the opcode dispatch might miss in the flash cache, and the opcode function itself too.  (If we want to get 1 MIPS out of about 200 MIPS, a few of these delays are going to really add up.)</p>

<p>The <code>__not_in_flash_func()</code> attribute can be used to copy a given function into RAM, guaranteeing fast execution.  At the very minimum, the main loop and memory accessors are decorated:  every instruction is going to access an opcode and most likely read or write RAM.</p>

<p>This improves performance a few percent.</p>

<p>Then, I tried decorating whole classes of opcodes: <code>move</code> is frequent, as are branches, so put ‘em in RAM.  This helped a lot, but the remaining free RAM was used up very quickly, and I wasn’t at my goal of much above 1 MIPS.</p>

<p>Remember that <a href="https://en.wikipedia.org/wiki/Reduced_instruction_set_computer">RISC architecture</a> is gonna change everything?</p>

<p>We want to put some of those 1968 68K opcodes into RAM to make them fast.  What are the top 10 most often-used instructions?  Top 100?  By adding a 64K table of counters to <code>umac</code>, booting the Mac and running key applications (okay, playing <em>Missile Command</em> for a bit), we get a profile of dynamic instruction counts.  It turns out that the 100 hottest opcodes (5% of the total) account for 89% of the execution.  And the top 200 account for a whopping 98% of execution.</p>

<p>Armed with this profile, the <code>umac</code> build post-processes the <em>Musashi</em> auto-generated code and decorates the top 200 functions with <code>__not_in_flash_func()</code>.  This adds only 17KB of extra RAM usage (leaving 95KB spare), and hits about 1.4 MIPS!  Party on!</p>

<p>At last, the world can enjoy <em>Missile Command</em>’s dark subject matter in performant comfort:</p>

<figure>
 <a href="https://axio.ms/images/umac/umac_missile.jpg"> 
    <img src="https://axio.ms/assets/resized/1400/umac_missile.jpg" srcset="            https://axio.ms/assets/resized/480/umac_missile.jpg 480w,            https://axio.ms/assets/resized/800/umac_missile.jpg 800w,            https://axio.ms/assets/resized/1400/umac_missile.jpg 1400w,    " width="100%" alt=" Missile Command on pico-mac">
 </a> 
<figcaption>Missile Command on pico-mac</figcaption></figure>

<h3 id="what-about-macpaint">What about MacPaint?</h3>

<p>Everyone loves MacPaint.  Maybe <em>you</em> love MacPaint, and have noticed I’ve deftly avoided mentioning it.  Okay, FINE:</p>

<p><img src="https://axio.ms/images/umac/macpaint_mem.png" alt="There is not enough memory for MacPaint!"></p>

<p>It doesn’t run on a <em>Mac 128Ke</em>, because the <em>Mac Plus</em> ROM uses more RAM than the original.  :sad-face:</p>

<p>I’d seen this thread on 68kMLA about a “Mac 256K”: <a href="https://68kmla.org/bb/index.php?threads/the-mythical-mac-256k.46149/">https://68kmla.org/bb/index.php?threads/the-mythical-mac-256k.46149/</a>  Chances are that the <em>Mac 128K</em> was really a <em>Mac 256K</em> in the lab (or maybe even intended to have 256K and cost-cut before release), as the OS functions fine with 256KB.</p>

<p>I wondered, does the Mac ROM/OS need a power-of-two amount of RAM?  If not, I have that 95K going spare.  Could I make a “Mac 200K”, and then run precious MacPaint?</p>

<p>Well, I tried a local hack that patches the ROM to update its global <code>memTop</code> variable based on a given memory size, and yes, System 3.2 is happy with non-power-of-2 sizes.  I booted with 256K, 208K, and 192K.  However, there were some additional problems to solve:  the ROM memtest craps itself without a power-of-2 size (totally fair), and NOPping that out leads to other issues.  These can be fixed, though also some parts of boot access off the end of RAM.  A power-of-2 size means a cheap address mask wraps RAM accesses to the valid buffer, and that can’t be done with 192K.</p>

<p>Unfortunately, when I then tested MacPaint it <em>still</em> wouldn’t run because it wanted to write a scratch file to the read-only boot volume.  This is totally breaking rule #1 by this point, so we are staying with 128KB for now.</p>

<p>However, a 256K MicroMac is extremely possible.  We just need an MCU with, say, 300KB of RAM…  Then we’d be cooking on gas.</p>

<h2 id="goodbye-friend">Goodbye, friend</h2>

<p>Well, dear reader, this has been a blast.  I hope there’s been something fun here for ya.  Ring off now, caller!</p>



<h2 id="resources">Resources</h2>

<ul>
  <li><a href="https://github.com/evansm7/umac">https://github.com/evansm7/umac</a></li>
  <li><a href="https://github.com/evansm7/pico-mac">https://github.com/evansm7/pico-mac</a></li>
  <li><a href="https://www.macintoshrepository.org/7038-all-macintosh-roms-68k-ppc-">https://www.macintoshrepository.org/7038-all-macintosh-roms-68k-ppc-</a></li>
  <li><a href="https://winworldpc.com/product/mac-os-0-6/system-3x">https://winworldpc.com/product/mac-os-0-6/system-3x</a></li>
  <li><a href="https://68kmla.org/bb/index.php?threads/macintosh-128k-mac-plus-roms.4006/">https://68kmla.org/bb/index.php?threads/macintosh-128k-mac-plus-roms.4006/</a></li>
  <li><a href="https://docs.google.com/spreadsheets/d/1wB2HnysPp63fezUzfgpk0JX_b7bXvmAg6-Dk7QDyKPY/edit#gid=840977089">https://docs.google.com/spreadsheets/d/1wB2HnysPp63fezUzfgpk0JX_b7bXvmAg6-Dk7QDyKPY/edit#gid=840977089</a></li>
</ul>

  </div>

</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bouba/kiki effect (238 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/Bouba/kiki_effect</link>
            <guid>40699583</guid>
            <pubDate>Sun, 16 Jun 2024 19:50:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/Bouba/kiki_effect">https://en.wikipedia.org/wiki/Bouba/kiki_effect</a>, See on <a href="https://news.ycombinator.com/item?id=40699583">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							

						<p>From Wikipedia, the free encyclopedia</p>
					</div><div lang="en" dir="ltr" id="mw-content-text">
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Booba-Kiki.svg"><img alt="A spiky geometric shape (left) and a rounded geometric shape (right)" src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Booba-Kiki.svg/250px-Booba-Kiki.svg.png" decoding="async" width="250" height="128" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Booba-Kiki.svg/375px-Booba-Kiki.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Booba-Kiki.svg/500px-Booba-Kiki.svg.png 2x" data-file-width="500" data-file-height="255"></a><figcaption>This picture is used as a test to demonstrate that people may not attach sounds to shapes arbitrarily. When given the names "kiki" and "bouba", many cultural and linguistic communities worldwide robustly tend to label the shape on the left "kiki" and the one on the right "bouba".</figcaption></figure>
<p>The <b>bouba/kiki effect</b>, or <b>kiki/bouba effect</b>, is a non-arbitrary <a href="https://en.wikipedia.org/wiki/Association_(psychology)" title="Association (psychology)">mental association</a> between certain speech sounds and certain visual shapes. Most narrowly, it is the tendency for people, when presented with the <a href="https://en.wikipedia.org/wiki/Nonsense_word" title="Nonsense word">nonsense words</a> <i>bouba</i>  and <i>kiki</i> , to associate <i>bouba</i> with a rounded shape and <i>kiki</i> with a spiky shape. Its discovery dates back to the 1920s, when psychologists documented experimental participants as connecting nonsense words to shapes in consistent ways. There is a strong general tendency towards the effect worldwide; it has been robustly confirmed across a majority of cultures and languages in which it has been researched,<sup id="cite_ref-Cwiek_1-0"><a href="#cite_note-Cwiek-1">[1]</a></sup> for example including among English-speaking American university students, <a href="https://en.wikipedia.org/wiki/Tamil_language" title="Tamil language">Tamil</a> speakers in India, speakers of certain languages with no writing system, young children, infants, and (though to a much lesser degree) the <a href="https://en.wikipedia.org/wiki/Congenital_blindness" title="Congenital blindness">congenitally blind</a>.<sup id="cite_ref-Cwiek_1-1"><a href="#cite_note-Cwiek-1">[1]</a></sup> It has also been shown to occur with familiar names. The effect was investigated using <a href="https://en.wikipedia.org/wiki/Functional_magnetic_resonance_imaging" title="Functional magnetic resonance imaging">fMRI</a> in 2018.<sup id="cite_ref-:0_2-0"><a href="#cite_note-:0-2">[2]</a></sup> The bouba/kiki effect is one form of <a href="https://en.wikipedia.org/wiki/Sound_symbolism" title="Sound symbolism">sound symbolism</a>.<sup id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup>
</p>
<meta property="mw:PageProp/toc">
<h2><span id="Research">Research</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Bouba/kiki_effect&amp;action=edit&amp;section=1" title="Edit section: Research"><span>edit</span></a><span>]</span></span></h2>
<h3><span id="Discovery">Discovery</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Bouba/kiki_effect&amp;action=edit&amp;section=2" title="Edit section: Discovery"><span>edit</span></a><span>]</span></span></h3>
<p>This effect was first observed by Georgian <a href="https://en.wikipedia.org/wiki/Psychologist" title="Psychologist">psychologist</a> <a href="https://en.wikipedia.org/wiki/Dimitri_Uznadze" title="Dimitri Uznadze">Dimitri Uznadze</a> in a 1924 paper.<sup id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup><sup>[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:No_original_research#Primary,_secondary_and_tertiary_sources" title="Wikipedia:No original research"><span title="This claim needs references to reliable secondary sources. (May 2023)">non-primary source needed</span></a></i>]</sup> He conducted an experiment with 10 participants who were given a list with nonsense words, shown six drawings for five seconds each, then instructed to pick a name for the drawing from the list of given words. He describes the different "strategies" participants developed to match words to drawings and quotes their reasoning. He also describes situations where participants described very specific forms that they associated with a nonsense word, without reference to the shown drawings. He develops a theory of four factors that influence the way names for objects are decided.
</p><p>In total, there were 42 words. For one particular drawing, 45% picked the same word. For three others, the percentages were 40%. Uznadze points out that this is significantly more overlap than one could expect, given the high number of possible words. He speculates that there must therefore be certain regularities "which the human soul follows in the process of name-giving". 
</p><p><a href="https://en.wikipedia.org/wiki/German_Americans" title="German Americans">German American</a> <a href="https://en.wikipedia.org/wiki/Psychologist" title="Psychologist">psychologist</a> <a href="https://en.wikipedia.org/wiki/Wolfgang_K%C3%B6hler" title="Wolfgang Köhler">Wolfgang Köhler</a> referred to Uznadze's experiment in a 1929 book<sup id="cite_ref-Kohler1929_5-0"><a href="#cite_note-Kohler1929-5">[5]</a></sup> which showed two forms and asked readers which shape was called "takete" and which was called "maluma". Although he does not say so outright, Köhler implies that there is a strong preference to pair the jagged shape with "takete" and the rounded shape with "maluma".<sup id="cite_ref-6"><a href="#cite_note-6">[6]</a></sup>
</p>
<h3><span id="Extension_to_other_contexts">Extension to other contexts</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Bouba/kiki_effect&amp;action=edit&amp;section=3" title="Edit section: Extension to other contexts"><span>edit</span></a><span>]</span></span></h3>
<p>In 2001, <a href="https://en.wikipedia.org/wiki/V._S._Ramachandran" title="V. S. Ramachandran">V. S. Ramachandran</a> and Edward Hubbard repeated Köhler's experiment using the words "kiki" and "bouba" and asked American college undergraduates and <a href="https://en.wikipedia.org/wiki/Tamil_language" title="Tamil language">Tamil</a> speakers in India, "Which of these shapes is bouba and which is kiki?" In both groups, 95% to 98% selected the curvy shape as "bouba" and the jagged one as "kiki", suggesting that the human brain somehow attaches abstract meanings to the shapes and sounds consistently.<sup id="cite_ref-Rama2001_7-0"><a href="#cite_note-Rama2001-7">[7]</a></sup><sup>[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Verifiability" title="Wikipedia:Verifiability"><span title="The material near this tag failed verification of its source citation(s). (August 2020)">failed verification</span></a> – <a href="https://en.wikipedia.org/wiki/Talk:Bouba/kiki_effect#Ramachandran_and_Hubbard_2001" title="Talk:Bouba/kiki effect">see discussion</a></i>]</sup>
</p><p><a href="https://en.wikipedia.org/wiki/Daphne_Maurer" title="Daphne Maurer">Daphne Maurer</a> and colleagues showed that even children as young as 2<span><span>1</span>⁄<span>2</span></span> years old may show this preference.<sup id="cite_ref-8"><a href="#cite_note-8">[8]</a></sup> More recent work by Ozge Ozturk and colleagues in 2013 showed that even 4-month-old infants have the same sound–shape mapping biases as adults and toddlers.<sup id="cite_ref-9"><a href="#cite_note-9">[9]</a></sup> Infants are able to differentiate between congruent trials (pairing an angular shape with "kiki" or a curvy shape with "bubu") and incongruent trials (pairing a curvy shape with "kiki" or an angular shape with "bubu"). Infants looked longer at incongruent pairings than at congruent pairings. Infants' mapping was based on the combination of <a href="https://en.wikipedia.org/wiki/Consonant" title="Consonant">consonants</a> and <a href="https://en.wikipedia.org/wiki/Vowel" title="Vowel">vowels</a> in the words, and neither consonants nor vowels alone sufficed for mapping. These results suggest that some sound–shape mappings precede <a href="https://en.wikipedia.org/wiki/Language_acquisition" title="Language acquisition">language learning</a>, and may in fact aid in language learning by establishing a basis for matching labels to referents and narrowing the hypothesis space for young infants. Adults in this study, like infants, used a combination of consonant and vowel information to match the labels they heard with the shapes they saw. However, this was not the only strategy that was available to them. Adults, unlike infants, were also able to use consonant information alone and vowel information alone to match the labels to the shapes, albeit less frequently than the consonant–vowel combination. When vowels and consonants were put in conflict, adults used consonants more often than vowels.
</p><p>The effect has also been shown to emerge in other contexts, such as when words are paired with evaluative meanings (with "bouba" words associated with positive concepts and "kiki" words associated with negative concepts)<sup id="cite_ref-10"><a href="#cite_note-10">[10]</a></sup> or when the words to be paired are existing first names, suggesting that some familiarity with the linguistic stimuli does not eliminate the effect. A study showed that individuals will pair names such as "Molly" with round silhouettes, and names such as "Kate" with sharp silhouettes. Moreover, individuals will associate different personality traits with either group of names (e.g., easygoingness with "round names"; determination with "sharp names"). This may hint at a role of abstract concepts in the effect.<sup id="cite_ref-11"><a href="#cite_note-11">[11]</a></sup>
</p>
<h3><span id="Contexts_where_the_effect_is_smaller_or_absent">Contexts where the effect is smaller or absent</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Bouba/kiki_effect&amp;action=edit&amp;section=4" title="Edit section: Contexts where the effect is smaller or absent"><span>edit</span></a><span>]</span></span></h3>
<p>Other research suggests that this effect does not occur in all communities,<sup id="cite_ref-12"><a href="#cite_note-12">[12]</a></sup> and it appears that the effect breaks if the sounds do not make licit words in the language.<sup id="cite_ref-13"><a href="#cite_note-13">[13]</a></sup> The bouba/kiki effect seems to be dependent on a long <a href="https://en.wikipedia.org/wiki/Critical_period" title="Critical period">sensitive period</a>, with high visual capacities in childhood being necessary for its typical development. Although the congenitally blind have been reported to show a bouba/kiki effect, they show a much smaller one for touched shapes than sighted individuals do for visual shapes.<sup id="cite_ref-Fryer2014_14-0"><a href="#cite_note-Fryer2014-14">[14]</a></sup><sup id="cite_ref-Hamilton-Fletcher2018_15-0"><a href="#cite_note-Hamilton-Fletcher2018-15">[15]</a></sup>
</p>
<h3><span id="Languages_where_the_effect_is_smaller_or_absent">Languages where the effect is smaller or absent</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Bouba/kiki_effect&amp;action=edit&amp;section=5" title="Edit section: Languages where the effect is smaller or absent"><span>edit</span></a><span>]</span></span></h3>
<p>Studies show that speakers of certain languages have notably failed to show the effect, namely including <a href="https://en.wikipedia.org/wiki/Mandarin_Chinese" title="Mandarin Chinese">Mandarin Chinese</a>, <a href="https://en.wikipedia.org/wiki/Turkish_language" title="Turkish language">Turkish</a>, and <a href="https://en.wikipedia.org/wiki/Romanian_language" title="Romanian language">Romanian</a>.<sup id="cite_ref-Cwiek_1-2"><a href="#cite_note-Cwiek-1">[1]</a></sup>
</p>
<h3><span id="Neuroscience">Neuroscience</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Bouba/kiki_effect&amp;action=edit&amp;section=6" title="Edit section: Neuroscience"><span>edit</span></a><span>]</span></span></h3>
<p>In 2019, Nathan Peiffer-Smadja and Laurent Cohen published the first study using <a href="https://en.wikipedia.org/wiki/Functional_magnetic_resonance_imaging" title="Functional magnetic resonance imaging">fMRI</a> to explore the bouba/kiki effect.<sup id="cite_ref-:0_2-1"><a href="#cite_note-:0-2">[2]</a></sup> They found that prefrontal activation is stronger to mismatching (bouba with spiky shape) than to matching (bouba with round shape) stimuli. A subsequent study by Kelly McCormick and colleagues reported a similar pattern of greater activation for mismatched word-shape stimuli, but with most activity in <a href="https://en.wikipedia.org/wiki/Parietal_region" title="Parietal region">parietal regions</a> including the <a href="https://en.wikipedia.org/wiki/Intraparietal_sulcus" title="Intraparietal sulcus">intraparietal sulcus</a> and <a href="https://en.wikipedia.org/wiki/Supramarginal_gyrus" title="Supramarginal gyrus">supramarginal gyrus</a>, regions known to play a role in sensory association and perceptual-motor processing.<sup id="cite_ref-16"><a href="#cite_note-16">[16]</a></sup> Peiffer-Smadja and Cohen also found that sound-shape matching also influences activations in the auditory and visual cortices, suggesting an effect of matching at an early stage in <a href="https://en.wikipedia.org/wiki/Sensory_processing" title="Sensory processing">sensory processing</a>.<sup id="cite_ref-:0_2-2"><a href="#cite_note-:0-2">[2]</a></sup>
</p>
<h3><span id="Implications_for_understanding_language">Implications for understanding language</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Bouba/kiki_effect&amp;action=edit&amp;section=7" title="Edit section: Implications for understanding language"><span>edit</span></a><span>]</span></span></h3>
<p>Ramachandran and Hubbard suggest that the kiki/bouba effect has implications for the evolution of language, because it suggests that the naming of objects is not completely arbitrary.<sup id="cite_ref-Rama2001_7-1"><a href="#cite_note-Rama2001-7">[7]</a></sup><sup><span title="Page / location: 17">: 17 </span></sup> The rounded shape may most commonly be named "bouba" because the mouth makes a more rounded shape to produce that sound while a more taut, angular mouth shape is needed to make the sounds in "kiki".<sup id="cite_ref-17"><a href="#cite_note-17">[17]</a></sup> Alternatively, the distinction may be between <a href="https://en.wikipedia.org/wiki/Coronal_consonant" title="Coronal consonant">coronal</a> or <a href="https://en.wikipedia.org/wiki/Dorsal_consonant" title="Dorsal consonant">dorsal</a> consonants like <a href="https://en.wikipedia.org/wiki/Voiceless_velar_stop" title="Voiceless velar stop">/k/</a> and <a href="https://en.wikipedia.org/wiki/Labial_consonant" title="Labial consonant">labial</a> consonants like <a href="https://en.wikipedia.org/wiki/Voiced_bilabial_stop" title="Voiced bilabial stop">/b/</a>.<sup id="cite_ref-18"><a href="#cite_note-18">[18]</a></sup> Additionally, it was shown that it is not only different consonants (e.g., voiceless versus voiced) and different vowel qualities (e.g., /a/ versus /i/) that play a role in the effect, but also vowel quantity (long versus short vowels). In one study, participants rated words containing long vowels to refer to longer objects and short vowels to short objects, at least for languages that make a <a href="https://en.wikipedia.org/wiki/Vowel_length" title="Vowel length">vowel length</a> distinction.<sup id="cite_ref-19"><a href="#cite_note-19">[19]</a></sup>  The presence of these "<a href="https://en.wikipedia.org/wiki/Synesthesia" title="Synesthesia">synesthesia</a>-like mappings" suggest that this effect may be the neurological basis for <a href="https://en.wikipedia.org/wiki/Sound_symbolism" title="Sound symbolism">sound symbolism</a>, in which sounds are non-arbitrarily mapped to objects and events in the world.<sup>[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (April 2016)">citation needed</span></a></i>]</sup> Research has also indicated that the effect may be a case of <a href="https://en.wikipedia.org/wiki/Ideasthesia" title="Ideasthesia">ideasthesia</a>,<sup id="cite_ref-20"><a href="#cite_note-20">[20]</a></sup> a phenomenon in which activations of concepts (inducers) evoke perception-like experiences (concurrents). The name comes from the Greek <i>idea</i> and <i>aisthesis</i>, meaning "sensing concepts" or "sensing ideas", and was introduced by Danko Nikolić.<sup id="cite_ref-21"><a href="#cite_note-21">[21]</a></sup>
</p>
<h2><span id="See_also">See also</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Bouba/kiki_effect&amp;action=edit&amp;section=8" title="Edit section: See also"><span>edit</span></a><span>]</span></span></h2>
<ul><li><a href="https://en.wikipedia.org/wiki/Color_symbolism" title="Color symbolism">Color symbolism</a></li>
<li><a href="https://en.wikipedia.org/wiki/Japanese_sound_symbolism" title="Japanese sound symbolism">Japanese sound symbolism</a></li>
<li><a href="https://en.wikipedia.org/wiki/Origin_of_language" title="Origin of language">Origin of language</a></li>
<li><a href="https://en.wikipedia.org/wiki/Semiotics" title="Semiotics">Semiotics</a></li>
<li><a href="https://en.wikipedia.org/wiki/Universal_language" title="Universal language">Universal language</a></li></ul>
<h2><span id="References">References</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Bouba/kiki_effect&amp;action=edit&amp;section=9" title="Edit section: References"><span>edit</span></a><span>]</span></span></h2>
<div><ol>
<li id="cite_note-Cwiek-1"><span>^ <a href="#cite_ref-Cwiek_1-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Cwiek_1-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-Cwiek_1-2"><sup><i><b>c</b></i></sup></a></span> <span><cite id="CITEREFĆwiekFuchsDraxlerAsu2022">Ćwiek, Aleksandra; Fuchs, Susanne; Draxler, Christoph; Asu, Eva Liina; Dediu, Dan; Hiovain, Katri; Kawahara, Shigeto; Koutalidis, Sofia; Krifka, Manfred; Lippus, Pärtel; Lupyan, Gary; Oh, Grace E.; Paul, Jing; Petrone, Caterina; Ridouane, Rachid; Reiter, Sabine; Schümchen, Nathalie; Szalontai, Ádám; Ünal-Logacev, Özlem; Zeller, Jochen; Perlman, Marcus; Winter, Bodo (2022). <a rel="nofollow" href="https://doi.org/10.1098/rstb.2020.0390">"The <i>bouba/Kiki</i> effect is robust across cultures and writing systems"</a>. <i>Philosophical Transactions of the Royal Society B: Biological Sciences</i>. <b>377</b> (1841). <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1098%2Frstb.2020.0390">10.1098/rstb.2020.0390</a>. <a href="https://en.wikipedia.org/wiki/PMC_(identifier)" title="PMC (identifier)">PMC</a>&nbsp;<span title="Freely accessible"><a rel="nofollow" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8591387">8591387</a></span>. <a href="https://en.wikipedia.org/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a>&nbsp;<a rel="nofollow" href="https://pubmed.ncbi.nlm.nih.gov/34775818">34775818</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Philosophical+Transactions+of+the+Royal+Society+B%3A+Biological+Sciences&amp;rft.atitle=The+bouba%2FKiki+effect+is+robust+across+cultures+and+writing+systems&amp;rft.volume=377&amp;rft.issue=1841&amp;rft.date=2022&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC8591387%23id-name%3DPMC&amp;rft_id=info%3Apmid%2F34775818&amp;rft_id=info%3Adoi%2F10.1098%2Frstb.2020.0390&amp;rft.aulast=%C4%86wiek&amp;rft.aufirst=Aleksandra&amp;rft.au=Fuchs%2C+Susanne&amp;rft.au=Draxler%2C+Christoph&amp;rft.au=Asu%2C+Eva+Liina&amp;rft.au=Dediu%2C+Dan&amp;rft.au=Hiovain%2C+Katri&amp;rft.au=Kawahara%2C+Shigeto&amp;rft.au=Koutalidis%2C+Sofia&amp;rft.au=Krifka%2C+Manfred&amp;rft.au=Lippus%2C+P%C3%A4rtel&amp;rft.au=Lupyan%2C+Gary&amp;rft.au=Oh%2C+Grace+E.&amp;rft.au=Paul%2C+Jing&amp;rft.au=Petrone%2C+Caterina&amp;rft.au=Ridouane%2C+Rachid&amp;rft.au=Reiter%2C+Sabine&amp;rft.au=Sch%C3%BCmchen%2C+Nathalie&amp;rft.au=Szalontai%2C+%C3%81d%C3%A1m&amp;rft.au=%C3%9Cnal-Logacev%2C+%C3%96zlem&amp;rft.au=Zeller%2C+Jochen&amp;rft.au=Perlman%2C+Marcus&amp;rft.au=Winter%2C+Bodo&amp;rft_id=http%3A%2F%2Fdoi.org%2F10.1098%2Frstb.2020.0390&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABouba%2Fkiki+effect"></span></span>
</li>
<li id="cite_note-:0-2"><span>^ <a href="#cite_ref-:0_2-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:0_2-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-:0_2-2"><sup><i><b>c</b></i></sup></a></span> <span><cite id="CITEREFPeiffer-SmadjaCohen2019">Peiffer-Smadja, Nathan; Cohen, Laurent (2019-02-01). <a rel="nofollow" href="https://doi.org/10.1016%2Fj.neuroimage.2018.11.033">"The cerebral bases of the bouba-kiki effect"</a>. <i>NeuroImage</i>. <b>186</b>: 679–689. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<span title="Freely accessible"><a rel="nofollow" href="https://doi.org/10.1016%2Fj.neuroimage.2018.11.033">10.1016/j.neuroimage.2018.11.033</a></span>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" href="https://www.worldcat.org/issn/1053-8119">1053-8119</a>. <a href="https://en.wikipedia.org/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a>&nbsp;<a rel="nofollow" href="https://pubmed.ncbi.nlm.nih.gov/30503933">30503933</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:54164828">54164828</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=NeuroImage&amp;rft.atitle=The+cerebral+bases+of+the+bouba-kiki+effect&amp;rft.volume=186&amp;rft.pages=679-689&amp;rft.date=2019-02-01&amp;rft.issn=1053-8119&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A54164828%23id-name%3DS2CID&amp;rft_id=info%3Apmid%2F30503933&amp;rft_id=info%3Adoi%2F10.1016%2Fj.neuroimage.2018.11.033&amp;rft.aulast=Peiffer-Smadja&amp;rft.aufirst=Nathan&amp;rft.au=Cohen%2C+Laurent&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.1016%252Fj.neuroimage.2018.11.033&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABouba%2Fkiki+effect"></span></span>
</li>
<li id="cite_note-3"><span><b><a href="#cite_ref-3">^</a></b></span> <span><cite id="CITEREFMargiotoudi_Konstantina_and_Pulvermüller_Friedemann2020">Margiotoudi Konstantina and Pulvermüller Friedemann (2020). <a rel="nofollow" href="https://www.proquest.com/docview/2428279185">"Action sound–shape congruencies explain sound symbolism"</a>. <i>Scientific Reports</i>. <b>10</b> (1): 12706. <a href="https://en.wikipedia.org/wiki/Bibcode_(identifier)" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" href="https://ui.adsabs.harvard.edu/abs/2020NatSR..1012706M">2020NatSR..1012706M</a>. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1038%2Fs41598-020-69528-4">10.1038/s41598-020-69528-4</a>. <a href="https://en.wikipedia.org/wiki/PMC_(identifier)" title="PMC (identifier)">PMC</a>&nbsp;<span title="Freely accessible"><a rel="nofollow" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7392762">7392762</a></span>. <a href="https://en.wikipedia.org/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a>&nbsp;<a rel="nofollow" href="https://pubmed.ncbi.nlm.nih.gov/32728096">32728096</a>. <a href="https://en.wikipedia.org/wiki/ProQuest_(identifier)" title="ProQuest (identifier)">ProQuest</a>&nbsp;<a rel="nofollow" href="https://search.proquest.com/docview/2428279185">2428279185</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Scientific+Reports&amp;rft.atitle=Action+sound%E2%80%93shape+congruencies+explain+sound+symbolism&amp;rft.volume=10&amp;rft.issue=1&amp;rft.pages=12706&amp;rft.date=2020&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC7392762%23id-name%3DPMC&amp;rft_id=info%3Apmid%2F32728096&amp;rft_id=info%3Adoi%2F10.1038%2Fs41598-020-69528-4&amp;rft_id=info%3Abibcode%2F2020NatSR..1012706M&amp;rft.au=Margiotoudi+Konstantina+and+Pulverm%C3%BCller+Friedemann&amp;rft_id=https%3A%2F%2Fwww.proquest.com%2Fdocview%2F2428279185&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABouba%2Fkiki+effect"></span></span>
</li>
<li id="cite_note-4"><span><b><a href="#cite_ref-4">^</a></b></span> <span><cite id="CITEREFDimitri_Usnadze">Dimitri Usnadze. <a rel="nofollow" href="https://core.ac.uk/download/pdf/210861794.pdf">"Ein experimenteller Beitrag zum Problem der psychologischen Grundlagen der Namengebung"</a> <span>(PDF)</span>. <i>bard.edu</i> (in German)<span>. Retrieved <span>18 April</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=bard.edu&amp;rft.atitle=Ein+experimenteller+Beitrag+zum+Problem+der+psychologischen+Grundlagen+der+Namengebung&amp;rft.au=Dimitri+Usnadze&amp;rft_id=https%3A%2F%2Fcore.ac.uk%2Fdownload%2Fpdf%2F210861794.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABouba%2Fkiki+effect"></span></span>
</li>
<li id="cite_note-Kohler1929-5"><span><b><a href="#cite_ref-Kohler1929_5-0">^</a></b></span> <span><cite id="CITEREFKöhler1929">Köhler, Wolfgang (1929). <span title="Free registration required"><a rel="nofollow" href="https://archive.org/details/gestaltpsycholog0000kohl"><i>Gestalt Psychology</i></a></span>. New York: Liveright.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Gestalt+Psychology.&amp;rft.place=New+York&amp;rft.pub=Liveright&amp;rft.date=1929&amp;rft.aulast=K%C3%B6hler&amp;rft.aufirst=Wolfgang&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fgestaltpsycholog0000kohl&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABouba%2Fkiki+effect"></span></span>
</li>
<li id="cite_note-6"><span><b><a href="#cite_ref-6">^</a></b></span> <span><cite id="CITEREFKöhler1947">Köhler, Wolfgang (1947). <span title="Free registration required"><a rel="nofollow" href="https://archive.org/details/gestaltpsycholog00kh"><i>Gestalt Psychology</i></a></span> (2nd&nbsp;ed.). New York: Liveright. p.&nbsp;<a rel="nofollow" href="https://archive.org/details/gestaltpsycholog00kh/page/132">133</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Gestalt+Psychology&amp;rft.place=New+York&amp;rft.pages=133&amp;rft.edition=2nd&amp;rft.pub=Liveright&amp;rft.date=1947&amp;rft.aulast=K%C3%B6hler&amp;rft.aufirst=Wolfgang&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fgestaltpsycholog00kh&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABouba%2Fkiki+effect"></span></span>
</li>
<li id="cite_note-Rama2001-7"><span>^ <a href="#cite_ref-Rama2001_7-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Rama2001_7-1"><sup><i><b>b</b></i></sup></a></span> <span><cite id="CITEREFRamachandranHubbard2001">Ramachandran, V.S. &amp; Hubbard, E.M. (2001). <a rel="nofollow" href="https://web.archive.org/web/20110813064348/http://cbc.ucsd.edu/pdf/Synaesthesia%20-%20JCS.pdf">"Synaesthesia: A window into perception, thought and language"</a> <span>(PDF)</span>. <i>Journal of Consciousness Studies</i>. <b>8</b> (12): 3–34. Archived from <a rel="nofollow" href="http://cbc.ucsd.edu/pdf/Synaesthesia%20-%20JCS.pdf">the original</a> <span>(PDF)</span> on 2011-08-13<span>. Retrieved <span>2011-10-20</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Consciousness+Studies&amp;rft.atitle=Synaesthesia%3A+A+window+into+perception%2C+thought+and+language&amp;rft.volume=8&amp;rft.issue=12&amp;rft.pages=3-34&amp;rft.date=2001&amp;rft.aulast=Ramachandran&amp;rft.aufirst=V.S.&amp;rft.au=Hubbard%2C+E.M.&amp;rft_id=http%3A%2F%2Fcbc.ucsd.edu%2Fpdf%2FSynaesthesia%2520-%2520JCS.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABouba%2Fkiki+effect"></span></span>
</li>
<li id="cite_note-8"><span><b><a href="#cite_ref-8">^</a></b></span> <span><cite id="CITEREFMaurerPathmanMondloch2006">Maurer, Daphne; Pathman, Thanujeni &amp; Mondloch, Catherine J. (2006). <a rel="nofollow" href="https://web.archive.org/web/20110723035944/http://psych.mcmaster.ca/maurerlab/Publications/Maurer_bouba.pdf">"The shape of boubas: Sound-shape correspondences in toddlers and adults"</a> <span>(PDF)</span>. <i>Developmental Science</i>. <b>9</b> (3): 316–322. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1111%2Fj.1467-7687.2006.00495.x">10.1111/j.1467-7687.2006.00495.x</a>. <a href="https://en.wikipedia.org/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a>&nbsp;<a rel="nofollow" href="https://pubmed.ncbi.nlm.nih.gov/16669803">16669803</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:7297731">7297731</a>. Archived from <a rel="nofollow" href="http://psych.mcmaster.ca/maurerlab/Publications/Maurer_bouba.pdf">the original</a> <span>(PDF)</span> on 2011-07-23<span>. Retrieved <span>2011-06-19</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Developmental+Science&amp;rft.atitle=The+shape+of+boubas%3A+Sound-shape+correspondences+in+toddlers+and+adults&amp;rft.volume=9&amp;rft.issue=3&amp;rft.pages=316-322&amp;rft.date=2006&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A7297731%23id-name%3DS2CID&amp;rft_id=info%3Apmid%2F16669803&amp;rft_id=info%3Adoi%2F10.1111%2Fj.1467-7687.2006.00495.x&amp;rft.aulast=Maurer&amp;rft.aufirst=Daphne&amp;rft.au=Pathman%2C+Thanujeni&amp;rft.au=Mondloch%2C+Catherine+J.&amp;rft_id=http%3A%2F%2Fpsych.mcmaster.ca%2Fmaurerlab%2FPublications%2FMaurer_bouba.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABouba%2Fkiki+effect"></span></span>
</li>
<li id="cite_note-9"><span><b><a href="#cite_ref-9">^</a></b></span> <span><cite id="CITEREFOzturkKrehmVouloumanos2013">Ozturk, Ozge; Krehm, Madelaine; Vouloumanos, Athena (2013). <a rel="nofollow" href="https://web.archive.org/web/20200817164233/http://www.psych.nyu.edu/niccl/publicationlinks/OzturkKrehmVouloumanos_JECP_InPress.pdf">"Sound symbolism in infancy: Evidence for sound–shape cross-modal correspondences in 4-month-olds"</a> <span>(PDF)</span>. <i>Journal of Experimental Child Psychology</i>. <b>114</b> (2): 173–186. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1016%2Fj.jecp.2012.05.004">10.1016/j.jecp.2012.05.004</a>. <a href="https://en.wikipedia.org/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a>&nbsp;<a rel="nofollow" href="https://pubmed.ncbi.nlm.nih.gov/22960203">22960203</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:7274252">7274252</a>. Archived from <a rel="nofollow" href="http://www.psych.nyu.edu/niccl/publicationlinks/OzturkKrehmVouloumanos_JECP_InPress.pdf">the original</a> <span>(PDF)</span> on 2020-08-17<span>. Retrieved <span>2019-09-24</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Experimental+Child+Psychology&amp;rft.atitle=Sound+symbolism+in+infancy%3A+Evidence+for+sound%E2%80%93shape+cross-modal+correspondences+in+4-month-olds&amp;rft.volume=114&amp;rft.issue=2&amp;rft.pages=173-186&amp;rft.date=2013&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A7274252%23id-name%3DS2CID&amp;rft_id=info%3Apmid%2F22960203&amp;rft_id=info%3Adoi%2F10.1016%2Fj.jecp.2012.05.004&amp;rft.aulast=Ozturk&amp;rft.aufirst=Ozge&amp;rft.au=Krehm%2C+Madelaine&amp;rft.au=Vouloumanos%2C+Athena&amp;rft_id=http%3A%2F%2Fwww.psych.nyu.edu%2Fniccl%2Fpublicationlinks%2FOzturkKrehmVouloumanos_JECP_InPress.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABouba%2Fkiki+effect"></span></span>
</li>
<li id="cite_note-10"><span><b><a href="#cite_ref-10">^</a></b></span> <span><cite id="CITEREFBross2018">Bross, Fabian (2018). "The Good, the Bad, the Bouba, and the Kiki. Cross-Modal Correspondences Between Evaluative Meanings, Speech-Sounds, and Object Shapes". <i>14th conference "Phonetics &amp; Phonology in the German-Speaking World"</i>. University of Vienna. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.13140%2FRG.2.2.11463.14240">10.13140/RG.2.2.11463.14240</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.atitle=The+Good%2C+the+Bad%2C+the+Bouba%2C+and+the+Kiki.+Cross-Modal+Correspondences+Between+Evaluative+Meanings%2C+Speech-Sounds%2C+and+Object+Shapes&amp;rft.btitle=14th+conference+%22Phonetics+%26+Phonology+in+the+German-Speaking+World%22&amp;rft.place=University+of+Vienna&amp;rft.date=2018&amp;rft_id=info%3Adoi%2F10.13140%2FRG.2.2.11463.14240&amp;rft.aulast=Bross&amp;rft.aufirst=Fabian&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABouba%2Fkiki+effect"></span></span>
</li>
<li id="cite_note-11"><span><b><a href="#cite_ref-11">^</a></b></span> <span><cite id="CITEREFSidhuPexman2015">Sidhu, David M.; Pexman, Penny M. (2015-05-27). <a rel="nofollow" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4446333">"What's in a Name? Sound Symbolism and Gender in First Names"</a>. <i>PLOS ONE</i>. <b>10</b> (5): e0126809. <a href="https://en.wikipedia.org/wiki/Bibcode_(identifier)" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" href="https://ui.adsabs.harvard.edu/abs/2015PLoSO..1026809S">2015PLoSO..1026809S</a>. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<span title="Freely accessible"><a rel="nofollow" href="https://doi.org/10.1371%2Fjournal.pone.0126809">10.1371/journal.pone.0126809</a></span>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" href="https://www.worldcat.org/issn/1932-6203">1932-6203</a>. <a href="https://en.wikipedia.org/wiki/PMC_(identifier)" title="PMC (identifier)">PMC</a>&nbsp;<span title="Freely accessible"><a rel="nofollow" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4446333">4446333</a></span>. <a href="https://en.wikipedia.org/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a>&nbsp;<a rel="nofollow" href="https://pubmed.ncbi.nlm.nih.gov/26016856">26016856</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=PLOS+ONE&amp;rft.atitle=What%27s+in+a+Name%3F+Sound+Symbolism+and+Gender+in+First+Names&amp;rft.volume=10&amp;rft.issue=5&amp;rft.pages=e0126809&amp;rft.date=2015-05-27&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4446333%23id-name%3DPMC&amp;rft_id=info%3Abibcode%2F2015PLoSO..1026809S&amp;rft_id=info%3Apmid%2F26016856&amp;rft_id=info%3Adoi%2F10.1371%2Fjournal.pone.0126809&amp;rft.issn=1932-6203&amp;rft.aulast=Sidhu&amp;rft.aufirst=David+M.&amp;rft.au=Pexman%2C+Penny+M.&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4446333&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABouba%2Fkiki+effect"></span></span>
</li>
<li id="cite_note-12"><span><b><a href="#cite_ref-12">^</a></b></span> <span><cite id="CITEREFRogersRoss1975">Rogers, Susan K.; Ross, Abraham S. (1975). "A cross-cultural test of the maluma–takete phenomenon". <i>Perception</i>. <b>4</b> (1): 105–106. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1068%2Fp040105">10.1068/p040105</a>. <a href="https://en.wikipedia.org/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a>&nbsp;<a rel="nofollow" href="https://pubmed.ncbi.nlm.nih.gov/1161435">1161435</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:30045028">30045028</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Perception&amp;rft.atitle=A+cross-cultural+test+of+the+maluma%E2%80%93takete+phenomenon&amp;rft.volume=4&amp;rft.issue=1&amp;rft.pages=105-106&amp;rft.date=1975&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A30045028%23id-name%3DS2CID&amp;rft_id=info%3Apmid%2F1161435&amp;rft_id=info%3Adoi%2F10.1068%2Fp040105&amp;rft.aulast=Rogers&amp;rft.aufirst=Susan+K.&amp;rft.au=Ross%2C+Abraham+S.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABouba%2Fkiki+effect"></span></span>
</li>
<li id="cite_note-13"><span><b><a href="#cite_ref-13">^</a></b></span> <span><cite id="CITEREFStylesGawne2017">Styles, Suzy; Gawne, Lauren (2017). <a rel="nofollow" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5574486">"When Does Maluma/Takete Fail? Two Key Failures and a Meta-Analysis Suggest That Phonology and Phonotactics Matter"</a>. <i>i-Perception</i>. <b>8</b> (4): 204166951772480. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1177%2F2041669517724807">10.1177/2041669517724807</a>. <a href="https://en.wikipedia.org/wiki/PMC_(identifier)" title="PMC (identifier)">PMC</a>&nbsp;<span title="Freely accessible"><a rel="nofollow" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5574486">5574486</a></span>. <a href="https://en.wikipedia.org/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a>&nbsp;<a rel="nofollow" href="https://pubmed.ncbi.nlm.nih.gov/28890777">28890777</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=i-Perception&amp;rft.atitle=When+Does+Maluma%2FTakete+Fail%3F+Two+Key+Failures+and+a+Meta-Analysis+Suggest+That+Phonology+and+Phonotactics+Matter&amp;rft.volume=8&amp;rft.issue=4&amp;rft.pages=204166951772480&amp;rft.date=2017&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC5574486%23id-name%3DPMC&amp;rft_id=info%3Apmid%2F28890777&amp;rft_id=info%3Adoi%2F10.1177%2F2041669517724807&amp;rft.aulast=Styles&amp;rft.aufirst=Suzy&amp;rft.au=Gawne%2C+Lauren&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC5574486&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABouba%2Fkiki+effect"></span></span>
</li>
<li id="cite_note-Fryer2014-14"><span><b><a href="#cite_ref-Fryer2014_14-0">^</a></b></span> <span><cite id="CITEREFFryerFreemanPring2014">Fryer, Louise; Freeman, Jonathan &amp; Pring, Linda (2014). <a rel="nofollow" href="http://research.gold.ac.uk/10499/1/PSY-Fryer-Freeman-Pring-2014.pdf">"Touching words is not enough: How visual experience influences haptic–auditory associations in the "Bouba–Kiki" effect"</a> <span>(PDF)</span>. <i>Cognition</i>. <b>132</b> (2): 164–173. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1016%2Fj.cognition.2014.03.015">10.1016/j.cognition.2014.03.015</a>. <a href="https://en.wikipedia.org/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a>&nbsp;<a rel="nofollow" href="https://pubmed.ncbi.nlm.nih.gov/24809744">24809744</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:29605784">29605784</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Cognition&amp;rft.atitle=Touching+words+is+not+enough%3A+How+visual+experience+influences+haptic%E2%80%93auditory+associations+in+the+%22Bouba%E2%80%93Kiki%22+effect.&amp;rft.volume=132&amp;rft.issue=2&amp;rft.pages=164-173&amp;rft.date=2014&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A29605784%23id-name%3DS2CID&amp;rft_id=info%3Apmid%2F24809744&amp;rft_id=info%3Adoi%2F10.1016%2Fj.cognition.2014.03.015&amp;rft.aulast=Fryer&amp;rft.aufirst=Louise&amp;rft.au=Freeman%2C+Jonathan&amp;rft.au=Pring%2C+Linda&amp;rft_id=http%3A%2F%2Fresearch.gold.ac.uk%2F10499%2F1%2FPSY-Fryer-Freeman-Pring-2014.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABouba%2Fkiki+effect"></span></span>
</li>
<li id="cite_note-Hamilton-Fletcher2018-15"><span><b><a href="#cite_ref-Hamilton-Fletcher2018_15-0">^</a></b></span> <span><cite id="CITEREFHamilton-FletcherPisanskiRebyStefańczyk2018">Hamilton-Fletcher, Giles; Pisanski, Katarzyna; Reby, David; Stefańczyk, Michał; Ward, Jamie &amp; Sorokowska, Agnieszka (2018). <a rel="nofollow" href="http://sro.sussex.ac.uk/id/eprint/74197/1/__smbhome.uscs.susx.ac.uk_ellenaj_Desktop_SRO_after%20august_blnd%20correspondences%20cognition%20accepted%20version.pdf">"The role of visual experience in the emergence of cross-modal correspondences"</a> <span>(PDF)</span>. <i>Cognition</i>. <b>175</b>: 114–121. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1016%2Fj.cognition.2018.02.023">10.1016/j.cognition.2018.02.023</a>. <a href="https://en.wikipedia.org/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a>&nbsp;<a rel="nofollow" href="https://pubmed.ncbi.nlm.nih.gov/29502009">29502009</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:3688492">3688492</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Cognition&amp;rft.atitle=The+role+of+visual+experience+in+the+emergence+of+cross-modal+correspondences.&amp;rft.volume=175&amp;rft.pages=114-121&amp;rft.date=2018&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A3688492%23id-name%3DS2CID&amp;rft_id=info%3Apmid%2F29502009&amp;rft_id=info%3Adoi%2F10.1016%2Fj.cognition.2018.02.023&amp;rft.aulast=Hamilton-Fletcher&amp;rft.aufirst=Giles&amp;rft.au=Pisanski%2C+Katarzyna&amp;rft.au=Reby%2C+David&amp;rft.au=Stefa%C5%84czyk%2C+Micha%C5%82&amp;rft.au=Ward%2C+Jamie&amp;rft.au=Sorokowska%2C+Agnieszka&amp;rft_id=http%3A%2F%2Fsro.sussex.ac.uk%2Fid%2Feprint%2F74197%2F1%2F__smbhome.uscs.susx.ac.uk_ellenaj_Desktop_SRO_after%2520august_blnd%2520correspondences%2520cognition%2520accepted%2520version.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABouba%2Fkiki+effect"></span></span>
</li>
<li id="cite_note-16"><span><b><a href="#cite_ref-16">^</a></b></span> <span><cite id="CITEREFMcCormickLaceyStillaNygaard2021">McCormick, Kelly; Lacey, Simon; Stilla, Randall; Nygaard, Lynne C.; Sathian, K. (2021-08-11). <a rel="nofollow" href="https://brill.com/view/journals/msr/aop/article-10.1163-22134808-bja10060/article-10.1163-22134808-bja10060.xml">"Neural Basis of the Sound-Symbolic Crossmodal Correspondence Between Auditory Pseudowords and Visual Shapes"</a>. <i>Multisensory Research</i>. <b>-1</b> (aop): 29–78. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1163%2F22134808-bja10060">10.1163/22134808-bja10060</a>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" href="https://www.worldcat.org/issn/2213-4794">2213-4794</a>. <a href="https://en.wikipedia.org/wiki/PMC_(identifier)" title="PMC (identifier)">PMC</a>&nbsp;<span title="Freely accessible"><a rel="nofollow" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9196751">9196751</a></span>. <a href="https://en.wikipedia.org/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a>&nbsp;<a rel="nofollow" href="https://pubmed.ncbi.nlm.nih.gov/34384048">34384048</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:236998825">236998825</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Multisensory+Research&amp;rft.atitle=Neural+Basis+of+the+Sound-Symbolic+Crossmodal+Correspondence+Between+Auditory+Pseudowords+and+Visual+Shapes&amp;rft.volume=-1&amp;rft.issue=aop&amp;rft.pages=29-78&amp;rft.date=2021-08-11&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC9196751%23id-name%3DPMC&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A236998825%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1163%2F22134808-bja10060&amp;rft.issn=2213-4794&amp;rft_id=info%3Apmid%2F34384048&amp;rft.aulast=McCormick&amp;rft.aufirst=Kelly&amp;rft.au=Lacey%2C+Simon&amp;rft.au=Stilla%2C+Randall&amp;rft.au=Nygaard%2C+Lynne+C.&amp;rft.au=Sathian%2C+K.&amp;rft_id=https%3A%2F%2Fbrill.com%2Fview%2Fjournals%2Fmsr%2Faop%2Farticle-10.1163-22134808-bja10060%2Farticle-10.1163-22134808-bja10060.xml&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABouba%2Fkiki+effect"></span></span>
</li>
<li id="cite_note-17"><span><b><a href="#cite_ref-17">^</a></b></span> <span><cite id="CITEREFD'Onofrio2013">D'Onofrio, Annette (2013). "Phonetic Detail and Dimensionality in Sound-shape Correspondences: Refining the <i>Bouba-Kiki</i> Paradigm". <i>Language and Speech</i>. <b>57</b> (3): 367–393. <a href="https://en.wikipedia.org/wiki/CiteSeerX_(identifier)" title="CiteSeerX (identifier)">CiteSeerX</a>&nbsp;<span title="Freely accessible"><a rel="nofollow" href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.1020.1352">10.1.1.1020.1352</a></span>. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1177%2F0023830913507694">10.1177/0023830913507694</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:51937587">51937587</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Language+and+Speech&amp;rft.atitle=Phonetic+Detail+and+Dimensionality+in+Sound-shape+Correspondences%3A+Refining+the+Bouba-Kiki+Paradigm&amp;rft.volume=57&amp;rft.issue=3&amp;rft.pages=367-393&amp;rft.date=2013&amp;rft_id=https%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.1020.1352%23id-name%3DCiteSeerX&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A51937587%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1177%2F0023830913507694&amp;rft.aulast=D%27Onofrio&amp;rft.aufirst=Annette&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABouba%2Fkiki+effect"></span></span>
</li>
<li id="cite_note-18"><span><b><a href="#cite_ref-18">^</a></b></span> <span><cite id="CITEREFMcCormickKimListNygaard2015">McCormick, Kelly; Kim, Jee Young; List, Sara; Nygaard, Lynne C. (2015). <a rel="nofollow" href="https://web.archive.org/web/20190209124406/https://mindmodeling.org/cogsci2015/papers/0273/paper0273.pdf">"Sound to Meaning Mappings in the Bouba-Kiki Effect"</a> <span>(PDF)</span>. <i>Proceedings of the 37th Annual Conference of the Cognitive Science Society: Mind, Technology, and Society: Pasadena, California, 23–25 July 2015</i>. Austin, TX: Cognitive Science Society. pp.&nbsp;1565–1570. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-9911967-2-2" title="Special:BookSources/978-0-9911967-2-2"><bdi>978-0-9911967-2-2</bdi></a>. Archived from <a rel="nofollow" href="https://mindmodeling.org/cogsci2015/papers/0273/paper0273.pdf">the original</a> <span>(PDF)</span> on 2019-02-09<span>. Retrieved <span>2019-02-08</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.atitle=Sound+to+Meaning+Mappings+in+the+Bouba-Kiki+Effect&amp;rft.btitle=Proceedings+of+the+37th+Annual+Conference+of+the+Cognitive+Science+Society%3A+Mind%2C+Technology%2C+and+Society%3A+Pasadena%2C+California%2C+23%E2%80%9325+July+2015&amp;rft.place=Austin%2C+TX&amp;rft.pages=1565-1570&amp;rft.pub=Cognitive+Science+Society&amp;rft.date=2015&amp;rft.isbn=978-0-9911967-2-2&amp;rft.aulast=McCormick&amp;rft.aufirst=Kelly&amp;rft.au=Kim%2C+Jee+Young&amp;rft.au=List%2C+Sara&amp;rft.au=Nygaard%2C+Lynne+C.&amp;rft_id=https%3A%2F%2Fmindmodeling.org%2Fcogsci2015%2Fpapers%2F0273%2Fpaper0273.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABouba%2Fkiki+effect"></span></span>
</li>
<li id="cite_note-19"><span><b><a href="#cite_ref-19">^</a></b></span> <span><cite id="CITEREFBross2018">Bross, Fabian (2018). <a rel="nofollow" href="https://www.researchgate.net/publication/323749384">"Cognitive associations between vowel length and object size: A new feature contributing to a bouba/kiki effect"</a>. In Belz, M.; Mooshammer, C.; Fuchs, S.; Jannedy, S.; Rasskazova, O.; Zygis, M. (eds.). <i>Proceedings of the Conference on Phonetics &amp; Phonology in German-Speaking Countries</i>. Vol.&nbsp;13. Berlin: Humbold University. pp.&nbsp;17–20.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.atitle=Cognitive+associations+between+vowel+length+and+object+size%3A+A+new+feature+contributing+to+a+bouba%2Fkiki+effect&amp;rft.btitle=Proceedings+of+the+Conference+on+Phonetics+%26+Phonology+in+German-Speaking+Countries&amp;rft.place=Berlin&amp;rft.pages=17-20&amp;rft.pub=Humbold+University&amp;rft.date=2018&amp;rft.aulast=Bross&amp;rft.aufirst=Fabian&amp;rft_id=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F323749384&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABouba%2Fkiki+effect"></span></span>
</li>
<li id="cite_note-20"><span><b><a href="#cite_ref-20">^</a></b></span> <span><cite id="CITEREFGómez_MilánIborrade_CórdobaJuárez-Ramos2013">Gómez Milán, E.; Iborra, O.; de Córdoba, M.J.; Juárez-Ramos, V.; Rodríguez Artacho, M.A.; Rubio, J.L. (2013). <span title="Paid subscription required"><a rel="nofollow" href="https://www.ingentaconnect.com/content/imp/jcs/2013/00000020/F0020001/art00005">"The Kiki-Bouba effect: A case of personification and ideaesthesia"</a></span>. <i>Journal of Consciousness Studies</i>. <b>20</b> (1–2): 84–102.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Consciousness+Studies&amp;rft.atitle=The+Kiki-Bouba+effect%3A+A+case+of+personification+and+ideaesthesia&amp;rft.volume=20&amp;rft.issue=1%E2%80%932&amp;rft.pages=84-102&amp;rft.date=2013&amp;rft.aulast=G%C3%B3mez+Mil%C3%A1n&amp;rft.aufirst=E.&amp;rft.au=Iborra%2C+O.&amp;rft.au=de+C%C3%B3rdoba%2C+M.J.&amp;rft.au=Ju%C3%A1rez-Ramos%2C+V.&amp;rft.au=Rodr%C3%ADguez+Artacho%2C+M.A.&amp;rft.au=Rubio%2C+J.L.&amp;rft_id=https%3A%2F%2Fwww.ingentaconnect.com%2Fcontent%2Fimp%2Fjcs%2F2013%2F00000020%2FF0020001%2Fart00005&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABouba%2Fkiki+effect"></span></span>
</li>
<li id="cite_note-21"><span><b><a href="#cite_ref-21">^</a></b></span> <span><cite id="CITEREFNikolić2009">Nikolić, Danko (2009). <a rel="nofollow" href="http://www.danko-nikolic.com/wp-content/uploads/2011/09/Synesthesia2009-Nikolic-Ideaesthesia.pdf">"Is synaesthesia actually ideaestesia? An inquiry into the nature of the phenomenon"</a> <span>(PDF)</span>. <i>Proceedings of the Third International Congress on Synaesthesia, Science &amp; Art</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.atitle=Is+synaesthesia+actually+ideaestesia%3F+An+inquiry+into+the+nature+of+the+phenomenon&amp;rft.btitle=Proceedings+of+the+Third+International+Congress+on+Synaesthesia%2C+Science+%26+Art&amp;rft.date=2009&amp;rft.aulast=Nikoli%C4%87&amp;rft.aufirst=Danko&amp;rft_id=http%3A%2F%2Fwww.danko-nikolic.com%2Fwp-content%2Fuploads%2F2011%2F09%2FSynesthesia2009-Nikolic-Ideaesthesia.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABouba%2Fkiki+effect"></span></span>
</li>
</ol></div>
<!-- 
NewPP limit report
Parsed by mw‐web.codfw.main‐776d5fcf9b‐dns87
Cached time: 20240520162536
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.366 seconds
Real time usage: 0.485 seconds
Preprocessor visited node count: 2296/1000000
Post‐expand include size: 69597/2097152 bytes
Template argument size: 2604/2097152 bytes
Highest expansion depth: 16/100
Expensive parser function count: 4/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 95402/5000000 bytes
Lua time usage: 0.222/10.000 seconds
Lua memory usage: 7323083/52428800 bytes
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  435.253      1 -total
 53.67%  233.597      1 Template:Reflist
 37.98%  165.311     14 Template:Cite_journal
 16.52%   71.884      1 Template:Short_description
  9.17%   39.923      2 Template:Pagetype
  7.84%   34.145      2 Template:IPAc-en
  5.48%   23.836      3 Template:Fix
  5.32%   23.162      4 Template:Cite_conference
  5.02%   21.864      1 Template:Rp
  4.78%   20.819      4 Template:Main_other
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:21438003-0!canonical and timestamp 20240520162536 and revision id 1217045468. Rendering was triggered because: page-view
 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[First look at the upcoming Starlink Mini (182 pts)]]></title>
            <link>https://www.starlinkhardware.com/first-look-at-the-upcoming-starlink-mini/</link>
            <guid>40699504</guid>
            <pubDate>Sun, 16 Jun 2024 19:39:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.starlinkhardware.com/first-look-at-the-upcoming-starlink-mini/">https://www.starlinkhardware.com/first-look-at-the-upcoming-starlink-mini/</a>, See on <a href="https://news.ycombinator.com/item?id=40699504">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text"><p>The launch of the highly anticipated Starlink Mini dish is imminent. Last week, Starlink got <a href="https://fcc.report/FCC-ID/2AWHPW231/7390216.pdf" target="_blank" rel="noreferrer noopener">approval from the FCC</a> for the Mini’s Wifi router. Today, Starlink updated their app with some juicy new details. In this post, I’m going to dive into what we know so far, and show you the first images of the Mini.</p><p>Based on previous FCC documents filed by SpaceX, we know the size of Starlink Mini to be 11.4″ x 9.8″, or about the size of a laptop. Here is a graphic I made to compare the size of the Standard and the Mini:</p><div><figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/www.starlinkhardware.com\/wp-content\/uploads\/2024\/01\/Starlink-Standard-Gen-3.jpg&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-full&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-5368&quot;,&quot;imgStyles&quot;:null,&quot;targetWidth&quot;:1920,&quot;targetHeight&quot;:1080,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image: Starlink Standard vs Starlink Mini Size Comparison&quot;,&quot;alt&quot;:&quot;Starlink Standard vs Starlink Mini Size Comparison&quot;}" data-wp-interactive="core/image"><img fetchpriority="high" decoding="async" width="1920" height="1080" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://www.starlinkhardware.com/wp-content/uploads/2024/01/Starlink-Standard-Gen-3.jpg" alt="Starlink Standard vs Starlink Mini Size Comparison" srcset="https://www.starlinkhardware.com/wp-content/uploads/2024/01/Starlink-Standard-Gen-3.jpg 1920w, https://www.starlinkhardware.com/wp-content/uploads/2024/01/Starlink-Standard-Gen-3-400x225.jpg 400w, https://www.starlinkhardware.com/wp-content/uploads/2024/01/Starlink-Standard-Gen-3-300x169.jpg 300w, https://www.starlinkhardware.com/wp-content/uploads/2024/01/Starlink-Standard-Gen-3-1024x576.jpg 1024w, https://www.starlinkhardware.com/wp-content/uploads/2024/01/Starlink-Standard-Gen-3-768x432.jpg 768w, https://www.starlinkhardware.com/wp-content/uploads/2024/01/Starlink-Standard-Gen-3-1536x864.jpg 1536w" sizes="(max-width: 1920px) 100vw, 1920px"><figcaption>Dimensions of the Standard dish (left) vs Mini dish (right)</figcaption></figure></div><p>Based on the size of the dish, it looks like Starlink Mini will be aimed at portable use cases, such as camping, RV’s, vans, hiking, etc. It’s designed to be easy to store, transport, and deploy. I’m hoping Starlink listens to customer feedback and offers a DC power supply accessory, but many details are still unknown.</p><p>What I do know at this point comes to us from a recent Starlink app update. The app update shows a new shop page for the upcoming Mini dish, as well as developer mode pages. This gives us our first look at the Mini:</p><div><figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/www.starlinkhardware.com\/wp-content\/uploads\/2024\/06\/IMG_3293.jpeg&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-full&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-6199&quot;,&quot;imgStyles&quot;:null,&quot;targetWidth&quot;:1179,&quot;targetHeight&quot;:704,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image: Starlink Mini&quot;,&quot;alt&quot;:&quot;Starlink Mini&quot;}" data-wp-interactive="core/image"><img decoding="async" width="1179" height="704" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://www.starlinkhardware.com/wp-content/uploads/2024/06/IMG_3293.jpeg" alt="Starlink Mini" srcset="https://www.starlinkhardware.com/wp-content/uploads/2024/06/IMG_3293.jpeg 1179w, https://www.starlinkhardware.com/wp-content/uploads/2024/06/IMG_3293-400x239.jpeg 400w, https://www.starlinkhardware.com/wp-content/uploads/2024/06/IMG_3293-1024x611.jpeg 1024w, https://www.starlinkhardware.com/wp-content/uploads/2024/06/IMG_3293-768x459.jpeg 768w" sizes="(max-width: 1179px) 100vw, 1179px"></figure></div><div><figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/www.starlinkhardware.com\/wp-content\/uploads\/2024\/06\/IMG_3292.jpeg&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-full&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-6200&quot;,&quot;imgStyles&quot;:null,&quot;targetWidth&quot;:1179,&quot;targetHeight&quot;:693,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image: Starlink Mini Side View&quot;,&quot;alt&quot;:&quot;Starlink Mini Side View&quot;}" data-wp-interactive="core/image"><img decoding="async" width="1179" height="693" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://www.starlinkhardware.com/wp-content/uploads/2024/06/IMG_3292.jpeg" alt="Starlink Mini Side View" srcset="https://www.starlinkhardware.com/wp-content/uploads/2024/06/IMG_3292.jpeg 1179w, https://www.starlinkhardware.com/wp-content/uploads/2024/06/IMG_3292-400x235.jpeg 400w, https://www.starlinkhardware.com/wp-content/uploads/2024/06/IMG_3292-1024x602.jpeg 1024w, https://www.starlinkhardware.com/wp-content/uploads/2024/06/IMG_3292-768x451.jpeg 768w" sizes="(max-width: 1179px) 100vw, 1179px"></figure></div><p>As you can see, the Mini is very similar to the Standard dish, just smaller. It has a similar shape, and even a kickstand.</p><p>The Starlink app update gives us more details about the Mini. If you go into developer mode and play around with the Mini network settings, you notice something interesting. There is no separate router. Devices are connected to the dish itself:</p><div><figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/www.starlinkhardware.com\/wp-content\/uploads\/2024\/06\/IMG_3294.jpeg&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-full&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-6198&quot;,&quot;imgStyles&quot;:null,&quot;targetWidth&quot;:1179,&quot;targetHeight&quot;:670,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image: Starlink Mini network page showing connected devices&quot;,&quot;alt&quot;:&quot;Starlink Mini network page showing connected devices&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="1179" height="670" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://www.starlinkhardware.com/wp-content/uploads/2024/06/IMG_3294.jpeg" alt="Starlink Mini network page showing connected devices" srcset="https://www.starlinkhardware.com/wp-content/uploads/2024/06/IMG_3294.jpeg 1179w, https://www.starlinkhardware.com/wp-content/uploads/2024/06/IMG_3294-400x227.jpeg 400w, https://www.starlinkhardware.com/wp-content/uploads/2024/06/IMG_3294-1024x582.jpeg 1024w, https://www.starlinkhardware.com/wp-content/uploads/2024/06/IMG_3294-768x436.jpeg 768w" sizes="(max-width: 1179px) 100vw, 1179px"></figure></div><p>That can only mean one thing: The Starlink Mini will feature a built-in Wifi router. I’m guessing that, in order to make the Mini as portable as possible, Starlink decided it was best to simplify the system and limit the number of components.</p><p>There are more Wifi details that have been revealed, and that is mesh compatibility. For those of you that might be interested in using the Mini at home, or for larger events where you need additional Wifi coverage, the Mini’s built-in router will be compatible with Starlink mesh. You’ll be able to wirelessly pair another Starlink router to the Mini, as seen in this Starlink app graphic:</p><div><figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/www.starlinkhardware.com\/wp-content\/uploads\/2024\/06\/IMG_3295.jpeg&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-large is-resized&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-6197&quot;,&quot;imgStyles&quot;:&quot;width:474px;height:auto&quot;,&quot;targetWidth&quot;:1179,&quot;targetHeight&quot;:1187,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image: Starlink Mini paired with a mesh router&quot;,&quot;alt&quot;:&quot;Starlink Mini paired with a mesh router&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="1017" height="1024" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://www.starlinkhardware.com/wp-content/uploads/2024/06/IMG_3295-1017x1024.jpeg" alt="Starlink Mini paired with a mesh router" srcset="https://www.starlinkhardware.com/wp-content/uploads/2024/06/IMG_3295-1017x1024.jpeg 1017w, https://www.starlinkhardware.com/wp-content/uploads/2024/06/IMG_3295-397x400.jpeg 397w, https://www.starlinkhardware.com/wp-content/uploads/2024/06/IMG_3295-150x150.jpeg 150w, https://www.starlinkhardware.com/wp-content/uploads/2024/06/IMG_3295-768x773.jpeg 768w, https://www.starlinkhardware.com/wp-content/uploads/2024/06/IMG_3295.jpeg 1179w" sizes="(max-width: 1017px) 100vw, 1017px"></figure></div><p>There you have it, we’ve now seen what the Mini will look like, and how practical it will be for camping and other activities where portability is key. I speculate that Starlink will launch the Mini within the next several weeks, based on the familiar pattern we’ve seen from other product launches. The fact that Starlink created the shop page and updated the app suggests we are very close.</p><p>I’d love to hear your thoughts on the images and details shared in this post. Let’s discuss it in the comments below!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NumPy 2.0 (290 pts)]]></title>
            <link>https://numpy.org/devdocs/release/2.0.0-notes.html</link>
            <guid>40699470</guid>
            <pubDate>Sun, 16 Jun 2024 19:32:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://numpy.org/devdocs/release/2.0.0-notes.html">https://numpy.org/devdocs/release/2.0.0-notes.html</a>, See on <a href="https://news.ycombinator.com/item?id=40699470">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
                  
  <section id="numpy-2-0-0-release-notes">

<div>
<p>Note</p>
<p>The release of 2.0 is in progress and the current release overview and
highlights are still in a draft state. However, the highlights should
already list the most significant changes detailed in the full notes below,
and those full notes should be complete (if not copy-edited well enough
yet).</p>
</div>
<p>NumPy 2.0.0 is the first major release since 2006. It is the result of X months
of development since the last feature release by Y contributors, and contains a
large amount of exciting new features as well as a large amount of changes to
both the Python and C APIs.</p>
<p>This major release includes breaking changes that could not happen in a regular
minor (feature) release - including an ABI break, changes to type promotion
rules, and API changes which may not have been emitting deprecation warnings
in 1.26.x. Key documents related to how to adapt to changes in NumPy 2.0, in
addition to these release notes, include:</p>
<ul>
<li><p>The <a href="https://numpy.org/devdocs/numpy_2_0_migration_guide.html#numpy-2-migration-guide"><span>NumPy 2.0 migration guide</span></a></p></li>
<li><p>The <a href="https://numpy.org/devdocs/dev/depending_on_numpy.html#numpy-2-abi-handling"><span>NumPy 2.0-specific advice</span></a> in
<a href="https://numpy.org/devdocs/dev/depending_on_numpy.html#for-downstream-package-authors"><span>For downstream package authors</span></a></p></li>
</ul>
<section id="highlights">
<h2>Highlights<a href="#highlights" title="Link to this heading">#</a></h2>
<p>Highlights of this release include:</p>
<ul>
<li><p>New features:</p>
<ul>
<li><p>A new variable-length string dtype, <a href="https://numpy.org/devdocs/reference/routines.dtypes.html#numpy.dtypes.StringDType" title="numpy.dtypes.StringDType"><code><span>StringDType</span></code></a> and a new
<a href="https://numpy.org/devdocs/reference/routines.strings.html#module-numpy.strings" title="numpy.strings"><code><span>numpy.strings</span></code></a> namespace with performant ufuncs for string operations,</p></li>
<li><p>Support for <code><span>float32</span></code> and <code><span>longdouble</span></code> in all <a href="https://numpy.org/devdocs/reference/routines.fft.html#module-numpy.fft" title="numpy.fft"><code><span>numpy.fft</span></code></a> functions,</p></li>
<li><p>Support for the array API standard in the main <code><span>numpy</span></code> namespace.</p></li>
</ul>
</li>
<li><p>Performance improvements:</p>
<ul>
<li><p>Sorting functions (<a href="https://numpy.org/devdocs/reference/generated/numpy.sort.html#numpy.sort" title="numpy.sort"><code><span>sort</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.argsort.html#numpy.argsort" title="numpy.argsort"><code><span>argsort</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.partition.html#numpy.partition" title="numpy.partition"><code><span>partition</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.argpartition.html#numpy.argpartition" title="numpy.argpartition"><code><span>argpartition</span></code></a>)
have been accelerated through the use of the Intel x86-simd-sort and Google
Highway libraries, and may see large (hardware-specific) speedups,</p></li>
<li><p>macOS Accelerate support and binary wheels for macOS &gt;=14, with significant
performance improvements for linear algebra operations on macOS, and wheels
that are about 3 times smaller,</p></li>
<li><p><a href="https://numpy.org/devdocs/reference/routines.char.html#module-numpy.char" title="numpy.char"><code><span>numpy.char</span></code></a> fixed-length string operations have been accelerated by
implementing ufuncs that also support <a href="https://numpy.org/devdocs/reference/routines.dtypes.html#numpy.dtypes.StringDType" title="numpy.dtypes.StringDType"><code><span>StringDType</span></code></a> in
addition to the the fixed-length string dtypes,</p></li>
<li><p>A new tracing and introspection API, <a href="https://numpy.org/devdocs/reference/generated/numpy.lib.introspect.opt_func_info.html#numpy.lib.introspect.opt_func_info" title="numpy.lib.introspect.opt_func_info"><code><span>opt_func_info</span></code></a>,
to determine which hardware-specific kernels are available and will be
dispatched to.</p></li>
</ul>
</li>
<li><p>Python API improvements:</p>
<ul>
<li><p>A clear split between public and private API, with a new
<a href="https://numpy.org/devdocs/reference/module_structure.html#module-structure"><span>module structure</span></a>, and each public function now
available in a single place,</p></li>
<li><p>Many removals of non-recommended functions and aliases. This should make
it easier to learn and use NumPy. The number of objects in the main
namespace decreased by ~10% and in <code><span>numpy.lib</span></code> by ~80%,</p></li>
<li><p><a href="https://numpy.org/devdocs/user/basics.types.html#canonical-python-and-c-types"><span>Canonical dtype names</span></a> and a new
<a href="https://numpy.org/devdocs/reference/generated/numpy.isdtype.html#numpy.isdtype" title="numpy.isdtype"><code><span>isdtype</span></code></a> introspection function,</p></li>
</ul>
</li>
<li><p>C API improvements:</p>
<ul>
<li><p>A new <a href="https://numpy.org/devdocs/reference/c-api/array.html#dtype-api"><span>public C API for creating custom dtypes</span></a>,</p></li>
<li><p>Many outdated functions and macros removed, and private internals hidden to
ease future extensibility,</p></li>
<li><p>New, easier to use, initialization functions:
<a href="https://numpy.org/devdocs/reference/c-api/array.html#c.PyArray_ImportNumPyAPI" title="PyArray_ImportNumPyAPI"><code><span>PyArray_ImportNumPyAPI</span></code></a> and <a href="https://numpy.org/devdocs/reference/c-api/ufunc.html#c.PyUFunc_ImportUFuncAPI" title="PyUFunc_ImportUFuncAPI"><code><span>PyUFunc_ImportUFuncAPI</span></code></a>.</p></li>
</ul>
</li>
<li><p>Improved behavior:</p>
<ul>
<li><p>Improvements to type promotion behavior was changed by adopting <a href="https://numpy.org/devdocs/release/NEP50">NEP
50</a>. This fixes many user surprises about promotions which
previously often depended on data values of input arrays rather than only
their dtypes.  Please see the NEP and the <a href="https://numpy.org/devdocs/numpy_2_0_migration_guide.html#numpy-2-migration-guide"><span>NumPy 2.0 migration guide</span></a>
for details as this change can lead to changes in output dtypes and lower
precision results for mixed-dtype operations.</p></li>
<li><p>The default integer type on Windows is now <code><span>int64</span></code> rather than <code><span>int32</span></code>,
matching the behavior on other platforms,</p></li>
<li><p>The maximum number of array dimensions is changed from 32 to 64</p></li>
</ul>
</li>
<li><p>Documentation:</p>
<ul>
<li><p>The reference guide navigation was signficantly improved, and there is now
documentation on NumPy’s <a href="https://numpy.org/devdocs/reference/module_structure.html#module-structure"><span>module structure</span></a>,</p></li>
<li><p>The <a href="https://numpy.org/devdocs/building/index.html#building-from-source"><span>building from source</span></a> documentation was
completely rewritten,</p></li>
</ul>
</li>
</ul>
<p>Furthermore there are many changes to NumPy internals, including continuing to
migrate code from C to C++, that will make it easier to improve and maintain
NumPy in the future.</p>
<p>The “no free lunch” theorem dictates that there is a price to pay for all these
API and behavior improvements and better future extensibility. This price is:</p>
<ol>
<li><p>Backwards compatibility. There are a significant number of breaking changes
to both the Python and C APIs. In the majority of cases, there are clear
error messages that will inform the user how to adapt their code. However,
there are also changes in behavior for which it was not possible to give
such an error message - these cases are all covered in the Deprecation and
Compatibility sections below, and in the <a href="https://numpy.org/devdocs/numpy_2_0_migration_guide.html#numpy-2-migration-guide"><span>NumPy 2.0 migration guide</span></a>.</p>
<p>Note that there is a <code><span>ruff</span></code> mode to auto-fix many things in Python code.</p>
</li>
<li><p>Breaking changes to the NumPy ABI. As a result, binaries of packages that
use the NumPy C API and were built against a NumPy 1.xx release will not
work with NumPy 2.0. On import, such packages will see an <code><span>ImportError</span></code>
with a message about binary incompatibiliy.</p>
<p>It is possible to build binaries against NumPy 2.0 that will work at runtime
with both NumPy 2.0 and 1.x. See <a href="https://numpy.org/devdocs/dev/depending_on_numpy.html#numpy-2-abi-handling"><span>NumPy 2.0-specific advice</span></a> for more details.</p>
<p><strong>All downstream packages that depend on the NumPy ABI are advised to do a
new release built against NumPy 2.0 and verify that that release works with
both 2.0 and 1.26 - ideally in the period between 2.0.0rc1 (which will be
ABI-stable) and the final 2.0.0 release to avoid problems for their users.</strong></p>
</li>
</ol>
<p>The Python versions supported by this release are 3.9-3.12.</p>
</section>
<section id="numpy-2-0-python-api-removals">
<h2>NumPy 2.0 Python API removals<a href="#numpy-2-0-python-api-removals" title="Link to this heading">#</a></h2>
<ul>
<li><p><code><span>np.geterrobj</span></code>, <code><span>np.seterrobj</span></code> and the related ufunc keyword argument
<code><span>extobj=</span></code> have been removed.  The preferred replacement for all of these
is using the context manager <code><span>with</span> <span>np.errstate():</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23922">gh-23922</a>)</p>
</li>
<li><p><code><span>np.cast</span></code> has been removed. The literal replacement for
<code><span>np.cast[dtype](arg)</span></code> is <code><span>np.asarray(arg,</span> <span>dtype=dtype)</span></code>.</p></li>
<li><p><code><span>np.source</span></code> has been removed. The preferred replacement is
<code><span>inspect.getsource</span></code>.</p></li>
<li><p><code><span>np.lookfor</span></code> has been removed.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24144">gh-24144</a>)</p>
</li>
<li><p><code><span>numpy.who</span></code> has been removed. As an alternative for the removed functionality, one
can use a variable explorer that is available in IDEs such as Spyder or Jupyter Notebook.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24321">gh-24321</a>)</p>
</li>
<li><p>Warnings and exceptions present in <a href="https://numpy.org/devdocs/reference/routines.exceptions.html#module-numpy.exceptions" title="numpy.exceptions"><code><span>numpy.exceptions</span></code></a> (e.g,
<a href="https://numpy.org/devdocs/reference/generated/numpy.exceptions.ComplexWarning.html#numpy.exceptions.ComplexWarning" title="numpy.exceptions.ComplexWarning"><code><span>ComplexWarning</span></code></a>,
<a href="https://numpy.org/devdocs/reference/generated/numpy.exceptions.VisibleDeprecationWarning.html#numpy.exceptions.VisibleDeprecationWarning" title="numpy.exceptions.VisibleDeprecationWarning"><code><span>VisibleDeprecationWarning</span></code></a>) are no longer exposed in the
main namespace.</p></li>
<li><p>Multiple niche enums, expired members and functions have been removed from
the main namespace, such as: <code><span>ERR_*</span></code>, <code><span>SHIFT_*</span></code>, <code><span>np.fastCopyAndTranspose</span></code>,
<code><span>np.kernel_version</span></code>, <code><span>np.numarray</span></code>, <code><span>np.oldnumeric</span></code> and <code><span>np.set_numeric_ops</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24316">gh-24316</a>)</p>
</li>
<li><p>Replaced <code><span>from</span> <span>...</span> <span>import</span> <span>*</span></code> in the <code><span>numpy/__init__.py</span></code> with explicit imports.
As a result, these main namespace members got removed: <code><span>np.FLOATING_POINT_SUPPORT</span></code>,
<code><span>np.FPE_*</span></code>, <code><span>np.NINF</span></code>, <code><span>np.PINF</span></code>, <code><span>np.NZERO</span></code>, <code><span>np.PZERO</span></code>, <code><span>np.CLIP</span></code>,
<code><span>np.WRAP</span></code>, <code><span>np.WRAP</span></code>, <code><span>np.RAISE</span></code>, <code><span>np.BUFSIZE</span></code>, <code><span>np.UFUNC_BUFSIZE_DEFAULT</span></code>,
<code><span>np.UFUNC_PYVALS_NAME</span></code>, <code><span>np.ALLOW_THREADS</span></code>, <code><span>np.MAXDIMS</span></code>, <code><span>np.MAY_SHARE_EXACT</span></code>,
<code><span>np.MAY_SHARE_BOUNDS</span></code>, <code><span>add_newdoc</span></code>, <code><span>np.add_docstring</span></code> and
<code><span>np.add_newdoc_ufunc</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24357">gh-24357</a>)</p>
</li>
<li><p>Alias <code><span>np.float_</span></code> has been removed. Use <code><span>np.float64</span></code> instead.</p></li>
<li><p>Alias <code><span>np.complex_</span></code> has been removed. Use <code><span>np.complex128</span></code> instead.</p></li>
<li><p>Alias <code><span>np.longfloat</span></code> has been removed. Use <code><span>np.longdouble</span></code> instead.</p></li>
<li><p>Alias <code><span>np.singlecomplex</span></code> has been removed. Use <code><span>np.complex64</span></code> instead.</p></li>
<li><p>Alias <code><span>np.cfloat</span></code> has been removed. Use <code><span>np.complex128</span></code> instead.</p></li>
<li><p>Alias <code><span>np.longcomplex</span></code> has been removed. Use <code><span>np.clongdouble</span></code> instead.</p></li>
<li><p>Alias <code><span>np.clongfloat</span></code> has been removed. Use <code><span>np.clongdouble</span></code> instead.</p></li>
<li><p>Alias <code><span>np.string_</span></code> has been removed. Use <code><span>np.bytes_</span></code> instead.</p></li>
<li><p>Alias <code><span>np.unicode_</span></code> has been removed. Use <code><span>np.str_</span></code> instead.</p></li>
<li><p>Alias <code><span>np.Inf</span></code> has been removed. Use <code><span>np.inf</span></code> instead.</p></li>
<li><p>Alias <code><span>np.Infinity</span></code> has been removed. Use <code><span>np.inf</span></code> instead.</p></li>
<li><p>Alias <code><span>np.NaN</span></code> has been removed. Use <code><span>np.nan</span></code> instead.</p></li>
<li><p>Alias <code><span>np.infty</span></code> has been removed. Use <code><span>np.inf</span></code> instead.</p></li>
<li><p>Alias <code><span>np.mat</span></code> has been removed. Use <code><span>np.asmatrix</span></code> instead.</p></li>
<li><p><code><span>np.issubclass_</span></code> has been removed. Use the <code><span>issubclass</span></code> builtin instead.</p></li>
<li><p><code><span>np.asfarray</span></code> has been removed. Use <code><span>np.asarray</span></code> with a proper dtype instead.</p></li>
<li><p><code><span>np.set_string_function</span></code> has been removed. Use <code><span>np.set_printoptions</span></code>
instead with a formatter for custom printing of NumPy objects.</p></li>
<li><p><code><span>np.tracemalloc_domain</span></code> is now only available from <code><span>np.lib</span></code>.</p></li>
<li><p><code><span>np.recfromcsv</span></code> and <code><span>recfromtxt</span></code> are now only available from <code><span>np.lib.npyio</span></code>.</p></li>
<li><p><code><span>np.issctype</span></code>, <code><span>np.maximum_sctype</span></code>, <code><span>np.obj2sctype</span></code>, <code><span>np.sctype2char</span></code>,
<code><span>np.sctypes</span></code>, <code><span>np.issubsctype</span></code> were all removed from the
main namespace without replacement, as they where niche members.</p></li>
<li><p>Deprecated <code><span>np.deprecate</span></code> and <code><span>np.deprecate_with_doc</span></code> has been removed
from the main namespace. Use <code><span>DeprecationWarning</span></code> instead.</p></li>
<li><p>Deprecated <code><span>np.safe_eval</span></code> has been removed from the main namespace.
Use <code><span>ast.literal_eval</span></code> instead.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24376">gh-24376</a>)</p>
</li>
<li><p><code><span>np.find_common_type</span></code> has been removed. Use <code><span>numpy.promote_types</span></code> or
<code><span>numpy.result_type</span></code> instead. To achieve semantics for the <code><span>scalar_types</span></code>
argument, use <code><span>numpy.result_type</span></code> and pass <code><span>0</span></code>, <code><span>0.0</span></code>, or <code><span>0j</span></code> as a
Python scalar instead.</p></li>
<li><p><code><span>np.round_</span></code> has been removed. Use <code><span>np.round</span></code> instead.</p></li>
<li><p><code><span>np.nbytes</span></code> has been removed. Use <code><span>np.dtype(&lt;dtype&gt;).itemsize</span></code> instead.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24477">gh-24477</a>)</p>
</li>
<li><p><code><span>np.compare_chararrays</span></code> has been removed from the main namespace.
Use <code><span>np.char.compare_chararrays</span></code> instead.</p></li>
<li><p>The <code><span>charrarray</span></code> in the main namespace has been deprecated. It can be imported
without a deprecation warning from <code><span>np.char.chararray</span></code> for now,
but we are planning to fully deprecate and remove <code><span>chararray</span></code> in the future.</p></li>
<li><p><code><span>np.format_parser</span></code> has been removed from the main namespace.
Use <code><span>np.rec.format_parser</span></code> instead.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24587">gh-24587</a>)</p>
</li>
<li><p>Support for seven data type string aliases has been removed from <code><span>np.dtype</span></code>:
<code><span>int0</span></code>, <code><span>uint0</span></code>, <code><span>void0</span></code>, <code><span>object0</span></code>, <code><span>str0</span></code>, <code><span>bytes0</span></code> and <code><span>bool8</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24807">gh-24807</a>)</p>
</li>
<li><p>The experimental <code><span>numpy.array_api</span></code> submodule has been removed. Use the main
<code><span>numpy</span></code> namespace for regular usage instead, or the separate
<code><span>array-api-strict</span></code> package for the compliance testing use case for which
<code><span>numpy.array_api</span></code> was mostly used.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25911">gh-25911</a>)</p>
</li>
</ul>
<section id="array-prepare-is-removed">
<h3><code><span>__array_prepare__</span></code> is removed<a href="#array-prepare-is-removed" title="Link to this heading">#</a></h3>
<p>UFuncs called <code><span>__array_prepare__</span></code> before running computations
for normal ufunc calls (not generalized ufuncs, reductions, etc.).
The function was also called instead of <code><span>__array_wrap__</span></code> on the
results of some linear algebra functions.</p>
<p>It is now removed. If you use it, migrate to <code><span>__array_ufunc__</span></code> or rely on
<code><span>__array_wrap__</span></code> which is called with a context in all cases, although only
after the result array is filled. In those code paths, <code><span>__array_wrap__</span></code> will
now be passed a base class, rather than a subclass array.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25105">gh-25105</a>)</p>
</section>
</section>
<section id="deprecations">
<h2>Deprecations<a href="#deprecations" title="Link to this heading">#</a></h2>
<ul>
<li><p><code><span>np.compat</span></code> has been deprecated, as Python 2 is no longer supported.</p></li>
<li><p><code><span>np.safe_eval</span></code> has been deprecated. <code><span>ast.literal_eval</span></code> should be used instead.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23830">gh-23830</a>)</p>
</li>
<li><p><code><span>np.recfromcsv</span></code>, <code><span>np.recfromtxt</span></code>, <code><span>np.disp</span></code>, <code><span>np.get_array_wrap</span></code>,
<code><span>np.maximum_sctype</span></code>, <code><span>np.deprecate</span></code> and <code><span>np.deprecate_with_doc</span></code>
have been deprecated.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24154">gh-24154</a>)</p>
</li>
<li><p><code><span>np.trapz</span></code> has been deprecated. Use <code><span>np.trapezoid</span></code> or a <code><span>scipy.integrate</span></code> function instead.</p></li>
<li><p><code><span>np.in1d</span></code> has been deprecated. Use <code><span>np.isin</span></code> instead.</p></li>
<li><p>Alias <code><span>np.row_stack</span></code> has been deprecated. Use <code><span>np.vstack</span></code> directly.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24445">gh-24445</a>)</p>
</li>
<li><p><code><span>__array_wrap__</span></code> is now passed <code><span>arr,</span> <span>context,</span> <span>return_scalar</span></code> and
support for implementations not accepting all three are deprecated.  Its signature
should be <code><span>__array_wrap__(self,</span> <span>arr,</span> <span>context=None,</span> <span>return_scalar=False)</span></code></p>
<p>(<a href="https://github.com/numpy/numpy/pull/25408">gh-25408</a>)</p>
</li>
<li><p>Arrays of 2-dimensional vectors for <code><span>np.cross</span></code> have been deprecated. Use
arrays of 3-dimensional vectors instead.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24818">gh-24818</a>)</p>
</li>
<li><p><code><span>np.dtype("a")</span></code> alias for <code><span>np.dtype(np.bytes_)</span></code> was deprecated. Use
<code><span>np.dtype("S")</span></code> alias instead.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24854">gh-24854</a>)</p>
</li>
<li><p>Use of keyword arguments <code><span>x</span></code> and <code><span>y</span></code> with functions
<code><span>assert_array_equal</span></code> and <code><span>assert_array_almost_equal</span></code> has been deprecated.
Pass the first two arguments as positional arguments instead.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24978">gh-24978</a>)</p>
</li>
</ul>
<section id="numpy-fft-deprecations-for-n-d-transforms-with-none-values-in-arguments">
<h3><a href="https://numpy.org/devdocs/reference/routines.fft.html#module-numpy.fft" title="numpy.fft"><code><span>numpy.fft</span></code></a> deprecations for n-D transforms with None values in arguments<a href="#numpy-fft-deprecations-for-n-d-transforms-with-none-values-in-arguments" title="Link to this heading">#</a></h3>
<p>Using <code><span>fftn</span></code>, <code><span>ifftn</span></code>, <code><span>rfftn</span></code>, <code><span>irfftn</span></code>, <code><span>fft2</span></code>, <code><span>ifft2</span></code>,
<code><span>rfft2</span></code> or <code><span>irfft2</span></code> with the <code><span>s</span></code> parameter set to a value that is not
<code><span>None</span></code> and the <code><span>axes</span></code> parameter set to <code><span>None</span></code> has been deprecated, in
line with the array API standard. To retain current behaviour, pass a sequence
[0, …, k-1] to <code><span>axes</span></code> for an array of dimension k.</p>
<p>Furthermore, passing an array to <code><span>s</span></code> which contains <code><span>None</span></code> values is
deprecated as the parameter is documented to accept a sequence of integers
in both the NumPy docs and the array API specification. To use the default
behaviour of the corresponding 1-D transform, pass the value matching
the default for its <code><span>n</span></code> parameter. To use the default behaviour for every
axis, the <code><span>s</span></code> argument can be omitted.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25495">gh-25495</a>)</p>
</section>
<section id="np-linalg-lstsq-now-defaults-to-a-new-rcond-value">
<h3><code><span>np.linalg.lstsq</span></code> now defaults to a new <code><span>rcond</span></code> value<a href="#np-linalg-lstsq-now-defaults-to-a-new-rcond-value" title="Link to this heading">#</a></h3>
<p><a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.lstsq.html#numpy.linalg.lstsq" title="numpy.linalg.lstsq"><code><span>lstsq</span></code></a> now uses the new rcond value of the machine precision
times <code><span>max(M,</span> <span>N)</span></code>.  Previously, the machine precision was used but a
FutureWarning was given to notify that this change will happen eventually.
That old behavior can still be achieved by passing <code><span>rcond=-1</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25721">gh-25721</a>)</p>
</section>
</section>
<section id="expired-deprecations">
<h2>Expired deprecations<a href="#expired-deprecations" title="Link to this heading">#</a></h2>
<ul>
<li><p>The <code><span>np.core.umath_tests</span></code> submodule has been removed from the public API.
(Deprecated in NumPy 1.15)</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23809">gh-23809</a>)</p>
</li>
<li><p>The <code><span>PyDataMem_SetEventHook</span></code> deprecation has expired and it is
removed.  Use <code><span>tracemalloc</span></code> and the <code><span>np.lib.tracemalloc_domain</span></code>
domain.  (Deprecated in NumPy 1.23)</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23921">gh-23921</a>)</p>
</li>
<li><p>The deprecation of <code><span>set_numeric_ops</span></code> and the C functions
<code><span>PyArray_SetNumericOps</span></code> and <code><span>PyArray_GetNumericOps</span></code> has
been expired and the functions removed.  (Deprecated in NumPy 1.16)</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23998">gh-23998</a>)</p>
</li>
<li><p>The <code><span>fasttake</span></code>, <code><span>fastclip</span></code>, and <code><span>fastputmask</span></code>  <code><span>ArrFuncs</span></code>
deprecation is now finalized.</p></li>
<li><p>The deprecated function <code><span>fastCopyAndTranspose</span></code> and its C counterpart
are now removed.</p></li>
<li><p>The deprecation of <code><span>PyArray_ScalarFromObject</span></code> is now finalized.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24312">gh-24312</a>)</p>
</li>
<li><p><code><span>np.msort</span></code> has been removed. For a replacement, <code><span>np.sort(a,</span> <span>axis=0)</span></code>
should be used instead.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24494">gh-24494</a>)</p>
</li>
<li><p><code><span>np.dtype(("f8",</span> <span>1)</span></code> will now return a shape 1 subarray dtype
rather than a non-subarray one.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25761">gh-25761</a>)</p>
</li>
<li><p>Assigning to the <code><span>.data</span></code> attribute of an ndarray is disallowed and will
raise.</p></li>
<li><p><code><span>np.binary_repr(a,</span> <span>width)</span></code> will raise if width is too small.</p></li>
<li><p>Using <code><span>NPY_CHAR</span></code> in <code><span>PyArray_DescrFromType()</span></code> will raise, use
<code><span>NPY_STRING</span></code> <code><span>NPY_UNICODE</span></code>, or <code><span>NPY_VSTRING</span></code> instead.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25794">gh-25794</a>)</p>
</li>
</ul>
</section>
<section id="compatibility-notes">
<h2>Compatibility notes<a href="#compatibility-notes" title="Link to this heading">#</a></h2>
<section id="loadtxt-and-genfromtxt-default-encoding-changed">
<h3><code><span>loadtxt</span></code> and <code><span>genfromtxt</span></code> default encoding changed<a href="#loadtxt-and-genfromtxt-default-encoding-changed" title="Link to this heading">#</a></h3>
<p><code><span>loadtxt</span></code> and <code><span>genfromtxt</span></code> now both default to <code><span>encoding=None</span></code>
which may mainly modify how <code><span>converters</span></code> work.
These will now be passed <code><span>str</span></code> rather than <code><span>bytes</span></code>. Pass the
encoding explicitly to always get the new or old behavior.
For <code><span>genfromtxt</span></code> the change also means that returned values will now be
unicode strings rather than bytes.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25158">gh-25158</a>)</p>
</section>
<section id="f2py-compatibility-notes">
<h3><code><span>f2py</span></code> compatibility notes<a href="#f2py-compatibility-notes" title="Link to this heading">#</a></h3>
<p><code><span>f2py</span></code> will no longer accept ambiguous <code><span>-m</span></code> and <code><span>.pyf</span></code> CLI combinations.
When more than one <code><span>.pyf</span></code> file is passed, an error is raised. When both <code><span>-m</span></code>
and a <code><span>.pyf</span></code> is passed, a warning is emitted and the <code><span>-m</span></code> provided name is
ignored.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25181">gh-25181</a>)</p>
<p>The <code><span>f2py.compile()</span></code> helper has been removed because it leaked memory, has
been marked as experimental for several years now, and was implemented as a thin
<code><span>subprocess.run</span></code> wrapper. It is also one of the test bottlenecks. See
<a href="https://github.com/numpy/numpy/issues/25122">gh-25122</a> for the full
rationale. It also used several <code><span>np.distutils</span></code> features which are too fragile
to be ported to work with <code><span>meson</span></code>.</p>
<p>Users are urged to replace calls to <code><span>f2py.compile</span></code> with calls to
<code><span>subprocess.run("python",</span> <span>"-m",</span> <span>"numpy.f2py",...</span></code> instead, and to use
environment variables to interact with <code><span>meson</span></code>. <a href="https://mesonbuild.com/Machine-files.html">Native files</a> are also an option.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25193">gh-25193</a>)</p>
</section>
<section id="arange-s-start-argument-is-positional-only">
<h3><code><span>arange</span></code>’s <code><span>start</span></code> argument is positional-only<a href="#arange-s-start-argument-is-positional-only" title="Link to this heading">#</a></h3>
<p>The first argument of <code><span>arange</span></code> is now positional only. This way,
specifying a <code><span>start</span></code> argument as a keyword, e.g. <code><span>arange(start=0,</span> <span>stop=4)</span></code>,
raises a TypeError. Other behaviors, are unchanged so <code><span>arange(stop=4)</span></code>,
<code><span>arange(2,</span> <span>stop=4)</span></code> and so on, are still valid and have the same meaning as
before.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25336">gh-25336</a>)</p>
</section>
<section id="minor-changes-in-behavior-of-sorting-functions">
<h3>Minor changes in behavior of sorting functions<a href="#minor-changes-in-behavior-of-sorting-functions" title="Link to this heading">#</a></h3>
<p>Due to algorithmic changes and use of SIMD code, sorting functions with methods
that aren’t stable may return slightly different results in 2.0.0 compared to
1.26.x. This includes the default method of <a href="https://numpy.org/devdocs/reference/generated/numpy.argsort.html#numpy.argsort" title="numpy.argsort"><code><span>argsort</span></code></a> and
<a href="https://numpy.org/devdocs/reference/generated/numpy.argpartition.html#numpy.argpartition" title="numpy.argpartition"><code><span>argpartition</span></code></a>.</p>
</section>
<section id="removed-ambiguity-when-broadcasting-in-np-solve">
<h3>Removed ambiguity when broadcasting in <code><span>np.solve</span></code><a href="#removed-ambiguity-when-broadcasting-in-np-solve" title="Link to this heading">#</a></h3>
<p>The broadcasting rules for <code><span>np.solve(a,</span> <span>b)</span></code> were ambiguous when <code><span>b</span></code> had 1
fewer dimensions than <code><span>a</span></code>. This has been resolved in a backward-incompatible
way and is now compliant with the Array API. The old behaviour can be
reconstructed by using <code><span>np.solve(a,</span> <span>b[...,</span> <span>None])[...,</span> <span>0]</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25914">gh-25914</a>)</p>
</section>
<section id="modified-representation-for-polynomial">
<h3>Modified representation for <code><span>Polynomial</span></code><a href="#modified-representation-for-polynomial" title="Link to this heading">#</a></h3>
<p>The representation method for <a href="https://numpy.org/devdocs/reference/generated/numpy.polynomial.polynomial.Polynomial.html#numpy.polynomial.polynomial.Polynomial" title="numpy.polynomial.polynomial.Polynomial"><code><span>Polynomial</span></code></a> was
updated to include the domain in the representation. The plain text and latex
representations are now consistent. For example the output of
<code><span>str(np.polynomial.Polynomial([1,</span> <span>1],</span> <span>domain=[.1,</span> <span>.2]))</span></code> used to be <code><span>1.0</span> <span>+</span>
<span>1.0</span> <span>x</span></code>, but now is <code><span>1.0</span> <span>+</span> <span>1.0</span> <span>(-3.0000000000000004</span> <span>+</span> <span>20.0</span> <span>x)</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/21760">gh-21760</a>)</p>
</section>
</section>
<section id="c-api-changes">
<h2>C API changes<a href="#c-api-changes" title="Link to this heading">#</a></h2>
<ul>
<li><p>The <code><span>PyArray_CGT</span></code>, <code><span>PyArray_CLT</span></code>, <code><span>PyArray_CGE</span></code>, <code><span>PyArray_CLE</span></code>,
<code><span>PyArray_CEQ</span></code>, <code><span>PyArray_CNE</span></code> macros have been removed.</p></li>
<li><p><code><span>PyArray_MIN</span></code> and <code><span>PyArray_MAX</span></code> have been moved from <code><span>ndarraytypes.h</span></code>
to <code><span>npy_math.h</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24258">gh-24258</a>)</p>
</li>
<li><p>A C API for working with <a href="https://numpy.org/devdocs/reference/routines.dtypes.html#numpy.dtypes.StringDType" title="numpy.dtypes.StringDType"><code><span>numpy.dtypes.StringDType</span></code></a> arrays has been exposed.
This includes functions for acquiring and releasing mutexes which lock access
to the string data, as well as packing and unpacking UTF-8 bytestreams from
array entries.</p></li>
<li><p><code><span>NPY_NTYPES</span></code> has been renamed to <code><span>NPY_NTYPES_LEGACY</span></code> as it does not
include new NumPy built-in DTypes. In particular the new string DType
will likely not work correctly with code that handles legacy DTypes.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25347">gh-25347</a>)</p>
</li>
<li><p>The C-API now only exports the static inline function versions
of the array accessors (previously this depended on using “deprecated API”).
While we discourage it, the struct fields can still be used directly.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25789">gh-25789</a>)</p>
</li>
<li><p>NumPy now defines <a href="https://numpy.org/devdocs/reference/c-api/array.html#c.PyArray_Pack" title="PyArray_Pack"><code><span>PyArray_Pack</span></code></a> to set an individual memory
address.  Unlike <code><span>PyArray_SETITEM</span></code> this function is equivalent to setting
an individual array item and does not require a NumPy array input.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25954">gh-25954</a>)</p>
</li>
<li><p>The <code><span>-&gt;f</span></code> slot has been removed from <code><span>PyArray_Descr</span></code>.
If you use this slot, replace accessing it with
<code><span>PyDataType_GetArrFuncs</span></code> (see its documentation and the
<a href="https://numpy.org/devdocs/numpy_2_0_migration_guide.html#numpy-2-migration-guide"><span>NumPy 2.0 migration guide</span></a>). In some cases using other functions like
<code><span>PyArray_GETITEM</span></code> may be an alternatives.</p></li>
<li><p><code><span>PyArray_GETITEM</span></code> and <code><span>PyArray_SETITEM</span></code> now require the import of the
NumPy API table to be used and are no longer defined in <code><span>ndarraytypes.h</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25812">gh-25812</a>)</p>
</li>
<li><p>Due to runtime dependencies, the definition for functionality accessing
the dtype flags was moved from <code><span>numpy/ndarraytypes.h</span></code> and is only available
after including <code><span>numpy/ndarrayobject.h</span></code> as it requires <code><span>import_array()</span></code>.
This includes <code><span>PyDataType_FLAGCHK</span></code>, <code><span>PyDataType_REFCHK</span></code> and
<code><span>NPY_BEGIN_THREADS_DESCR</span></code>.</p></li>
<li><p>The dtype flags on <code><span>PyArray_Descr</span></code> must now be accessed through the
<code><span>PyDataType_FLAGS</span></code> inline function to be compatible with both 1.x and 2.x.
This function is defined in <code><span>npy_2_compat.h</span></code> to allow backporting.
Most or all users should use <code><span>PyDataType_FLAGCHK</span></code> which is available on
1.x and does not require backporting.
Cython users should use Cython 3.  Otherwise access will go through Python
unless they use <code><span>PyDataType_FLAGCHK</span></code> instead.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25816">gh-25816</a>)</p>
</li>
</ul>
<section id="datetime-functionality-exposed-in-the-c-api-and-cython-bindings">
<h3>Datetime functionality exposed in the C API and Cython bindings<a href="#datetime-functionality-exposed-in-the-c-api-and-cython-bindings" title="Link to this heading">#</a></h3>
<p>The functions <code><span>NpyDatetime_ConvertDatetime64ToDatetimeStruct</span></code>,
<code><span>NpyDatetime_ConvertDatetimeStructToDatetime64</span></code>,
<code><span>NpyDatetime_ConvertPyDateTimeToDatetimeStruct</span></code>,
<code><span>NpyDatetime_GetDatetimeISO8601StrLen</span></code>, <code><span>NpyDatetime_MakeISO8601Datetime</span></code>,
and <code><span>NpyDatetime_ParseISO8601Datetime</span></code> have been added to the C API to
facilitate converting between strings, Python datetimes, and NumPy datetimes in
external libraries.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/21199">gh-21199</a>)</p>
</section>
<section id="const-correctness-for-the-generalized-ufunc-c-api">
<h3>Const correctness for the generalized ufunc C API<a href="#const-correctness-for-the-generalized-ufunc-c-api" title="Link to this heading">#</a></h3>
<p>The NumPy C API’s functions for constructing generalized ufuncs
(<code><span>PyUFunc_FromFuncAndData</span></code>, <code><span>PyUFunc_FromFuncAndDataAndSignature</span></code>,
<code><span>PyUFunc_FromFuncAndDataAndSignatureAndIdentity</span></code>) take <code><span>types</span></code> and <code><span>data</span></code>
arguments that are not modified by NumPy’s internals. Like the <code><span>name</span></code> and
<code><span>doc</span></code> arguments, third-party Python extension modules are likely to supply
these arguments from static constants. The <code><span>types</span></code> and <code><span>data</span></code> arguments are
now const-correct: they are declared as <code><span>const</span> <span>char</span> <span>*types</span></code> and
<code><span>void</span> <span>*const</span> <span>*data</span></code>, respectively. C code should not be affected, but C++
code may be.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23847">gh-23847</a>)</p>
</section>
<section id="larger-npy-maxdims-and-npy-maxargs-npy-ravel-axis-introduced">
<h3>Larger <code><span>NPY_MAXDIMS</span></code> and <code><span>NPY_MAXARGS</span></code>, <code><span>NPY_RAVEL_AXIS</span></code> introduced<a href="#larger-npy-maxdims-and-npy-maxargs-npy-ravel-axis-introduced" title="Link to this heading">#</a></h3>
<p><code><span>NPY_MAXDIMS</span></code> is now 64, you may want to review its use.  This is usually
used in a stack allocation, where the increase should be safe.
However, we do encourage generally to remove any use of <code><span>NPY_MAXDIMS</span></code> and
<code><span>NPY_MAXARGS</span></code> to eventually allow removing the constraint completely.
For the conversion helper and C-API functions mirroring Python ones such as
<code><span>take</span></code>, <code><span>NPY_MAXDIMS</span></code> was used to mean <code><span>axis=None</span></code>. Such usage must be
replaced with <code><span>NPY_RAVEL_AXIS</span></code>. See also <a href="https://numpy.org/devdocs/numpy_2_0_migration_guide.html#migration-maxdims"><span>Increased maximum number of dimensions</span></a>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25149">gh-25149</a>)</p>
</section>
<section id="npy-maxargs-not-constant-and-pyarraymultiiterobject-size-change">
<h3><code><span>NPY_MAXARGS</span></code> not constant and <code><span>PyArrayMultiIterObject</span></code> size change<a href="#npy-maxargs-not-constant-and-pyarraymultiiterobject-size-change" title="Link to this heading">#</a></h3>
<p>Since <code><span>NPY_MAXARGS</span></code> was increased, it is now a runtime constant and not
compile-time constant anymore.
We expect almost no users to notice this.  But if used for stack allocations
it now must be replaced with a custom constant using <code><span>NPY_MAXARGS</span></code> as an
additional runtime check.</p>
<p>The <code><span>sizeof(PyArrayMultiIterObject)</span></code> no longer includes the full size
of the object.  We expect nobody to notice this change.  It was necessary
to avoid issues with Cython.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25271">gh-25271</a>)</p>
</section>
<section id="required-changes-for-custom-legacy-user-dtypes">
<h3>Required changes for custom legacy user dtypes<a href="#required-changes-for-custom-legacy-user-dtypes" title="Link to this heading">#</a></h3>
<p>In order to improve our DTypes it is unfortunately necessary
to break the ABI, which requires some changes for dtypes registered
with <code><span>PyArray_RegisterDataType</span></code>.
Please see the documentation of <code><span>PyArray_RegisterDataType</span></code> for how
to adapt your code and achieve compatibility with both 1.x and 2.x.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25792">gh-25792</a>)</p>
</section>
<section id="new-public-dtype-api">
<h3>New Public DType API<a href="#new-public-dtype-api" title="Link to this heading">#</a></h3>
<p>The C implementation of the NEP 42 DType API is now public. While the DType API
has shipped in NumPy for a few versions, it was only usable in sessions with a
special environment variable set. It is now possible to write custom DTypes
outside of NumPy using the new DType API and the normal <code><span>import_array()</span></code>
mechanism for importing the numpy C API.</p>
<p>See <a href="https://numpy.org/devdocs/reference/c-api/array.html#dtype-api"><span>Custom Data Types</span></a> for more details about the API. As always with a new
feature, please report any bugs you run into implementing or using a new
DType. It is likely that downstream C code that works with dtypes will need to
be updated to work correctly with new DTypes.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25754">gh-25754</a>)</p>
</section>
<section id="new-c-api-import-functions">
<h3>New C-API import functions<a href="#new-c-api-import-functions" title="Link to this heading">#</a></h3>
<p>We have now added <code><span>PyArray_ImportNumPyAPI</span></code> and <code><span>PyUFunc_ImportUFuncAPI</span></code>
as static inline functions to import the NumPy C-API tables.
The new functions have two advantages over <code><span>import_array</span></code> and
<code><span>import_ufunc</span></code>:</p>
<ul>
<li><p>They check whether the import was already performed and are light-weight
if not, allowing to add them judiciously (although this is not preferable
in most cases).</p></li>
<li><p>The old mechanisms were macros rather than functions which included a
<code><span>return</span></code> statement.</p></li>
</ul>
<p>The <code><span>PyArray_ImportNumPyAPI()</span></code> function is included in <code><span>npy_2_compat.h</span></code>
for simpler backporting.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25866">gh-25866</a>)</p>
</section>
<section id="structured-dtype-information-access-through-functions">
<h3>Structured dtype information access through functions<a href="#structured-dtype-information-access-through-functions" title="Link to this heading">#</a></h3>
<p>The dtype structures fields <code><span>c_metadata</span></code>, <code><span>names</span></code>,
<code><span>fields</span></code>, and <code><span>subarray</span></code> must now be accessed through new
functions following the same names, such as <code><span>PyDataType_NAMES</span></code>.
Direct access of the fields is not valid as they do not exist for
all <code><span>PyArray_Descr</span></code> instances.
The <code><span>metadata</span></code> field is kept, but the macro version should also be preferred.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25802">gh-25802</a>)</p>
</section>
<section id="descriptor-elsize-and-alignment-access">
<h3>Descriptor <code><span>elsize</span></code> and <code><span>alignment</span></code> access<a href="#descriptor-elsize-and-alignment-access" title="Link to this heading">#</a></h3>
<p>Unless compiling only with NumPy 2 support, the <code><span>elsize</span></code> and <code><span>aligment</span></code>
fields must now be accessed via <code><span>PyDataType_ELSIZE</span></code>,
<code><span>PyDataType_SET_ELSIZE</span></code>, and <code><span>PyDataType_ALIGNMENT</span></code>.
In cases where the descriptor is attached to an array, we advise
using <code><span>PyArray_ITEMSIZE</span></code> as it exists on all NumPy versions.
Please see <a href="https://numpy.org/devdocs/numpy_2_0_migration_guide.html#migration-c-descr"><span>The PyArray_Descr struct has been changed</span></a> for more information.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25943">gh-25943</a>)</p>
</section>
</section>
<section id="numpy-2-0-c-api-removals">
<h2>NumPy 2.0 C API removals<a href="#numpy-2-0-c-api-removals" title="Link to this heading">#</a></h2>
<ul>
<li><p><code><span>npy_interrupt.h</span></code> and the corresponding macros like <code><span>NPY_SIGINT_ON</span></code>
have been removed.  We recommend querying <code><span>PyErr_CheckSignals()</span></code> or
<code><span>PyOS_InterruptOccurred()</span></code> periodically (these do currently require
holding the GIL though).</p></li>
<li><p>The <code><span>noprefix.h</span></code> header has been removed. Replace missing symbols with
their prefixed counterparts (usually an added <code><span>NPY_</span></code> or <code><span>npy_</span></code>).</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23919">gh-23919</a>)</p>
</li>
<li><p><code><span>PyUFunc_GetPyVals</span></code>, <code><span>PyUFunc_handlefperr</span></code>, and <code><span>PyUFunc_checkfperr</span></code>
have been removed.
If needed, a new backwards compatible function to raise floating point errors
could be restored. Reason for removal: there are no known users and the
functions would have made <code><span>with</span> <span>np.errstate()</span></code> fixes much more difficult).</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23922">gh-23922</a>)</p>
</li>
<li><p>The <code><span>numpy/old_defines.h</span></code> which was part of the API deprecated since NumPy 1.7
has been removed.  This removes macros of the form <code><span>PyArray_CONSTANT</span></code>.
The <a href="https://github.com/numpy/numpy/blob/main/tools/replace_old_macros.sed">replace_old_macros.sed</a>
script may be useful to convert them to the <code><span>NPY_CONSTANT</span></code> version.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24011">gh-24011</a>)</p>
</li>
<li><p>The <code><span>legacy_inner_loop_selector</span></code> member of the ufunc struct is removed
to simplify improvements to the dispatching system.
There are no known users overriding or directly accessing this member.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24271">gh-24271</a>)</p>
</li>
<li><p><code><span>NPY_INTPLTR</span></code> has been removed to avoid confusion (see <code><span>intp</span></code>
redefinition).</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24888">gh-24888</a>)</p>
</li>
<li><p>The advanced indexing <code><span>MapIter</span></code> and related API has been removed.
The (truly) public part of it was not well tested and had only one
known user (Theano).  Making it private will simplify improvements
to speed up <code><span>ufunc.at</span></code>, make advanced indexing more maintainable,
and was important for increasing the maximum number of dimensions of arrays
to 64. Please let us know if this API is important to you so we can find a
solution together.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25138">gh-25138</a>)</p>
</li>
<li><p>The <code><span>NPY_MAX_ELSIZE</span></code> macro has been removed, as it only ever reflected
builtin numeric types and served no internal purpose.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25149">gh-25149</a>)</p>
</li>
<li><p><code><span>PyArray_REFCNT</span></code> and <code><span>NPY_REFCOUNT</span></code> are removed. Use <code><span>Py_REFCNT</span></code> instead.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25156">gh-25156</a>)</p>
</li>
<li><p><code><span>PyArrayFlags_Type</span></code> and <code><span>PyArray_NewFlagsObject</span></code> as well as
<code><span>PyArrayFlagsObject</span></code> are private now.
There is no known use-case; use the Python API if needed.</p></li>
<li><p><code><span>PyArray_MoveInto</span></code>, <code><span>PyArray_CastTo</span></code>, <code><span>PyArray_CastAnyTo</span></code> are removed
use <code><span>PyArray_CopyInto</span></code> and if absolutely needed <code><span>PyArray_CopyAnyInto</span></code>
(the latter does a flat copy).</p></li>
<li><p><code><span>PyArray_FillObjectArray</span></code> is removed, its only true use is for
implementing <code><span>np.empty</span></code>.  Create a new empty array or use
<code><span>PyArray_FillWithScalar()</span></code> (decrefs existing objects).</p></li>
<li><p><code><span>PyArray_CompareUCS4</span></code> and <code><span>PyArray_CompareString</span></code> are removed.
Use the standard C string comparison functions.</p></li>
<li><p><code><span>PyArray_ISPYTHON</span></code> is removed as it is misleading, has no known
use-cases, and is easy to replace.</p></li>
<li><p><code><span>PyArray_FieldNames</span></code> is removed, as it is unclear what it would
be useful for.  It also has incorrect semantics in some possible
use-cases.</p></li>
<li><p><code><span>PyArray_TypestrConvert</span></code> is removed, since it seems a misnomer and unlikely
to be used by anyone.  If you know the size or are limited to few types, just
use it explicitly, otherwise go via Python strings.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25292">gh-25292</a>)</p>
</li>
<li><p><code><span>PyDataType_GetDatetimeMetaData</span></code> has been removed, it did not actually
do anything since at least NumPy 1.7.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25802">gh-25802</a>)</p>
</li>
</ul>
<section id="pyarray-getcastfunc-was-removed">
<h3><code><span>PyArray_GetCastFunc</span></code> was removed<a href="#pyarray-getcastfunc-was-removed" title="Link to this heading">#</a></h3>
<p>Note that custom legacy user dtypes can still provide a castfunc
as their implementation, but any access to them is now removed.
The reason for this is that NumPy never used these internally
for many years.
If you use simple numeric types, please just use C casts directly.
In case you require an alternative, please let us know so we can
create new API such as <code><span>PyArray_CastBuffer()</span></code> which could
use old or new cast functions depending on the NumPy version.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25161">gh-25161</a>)</p>
</section>
</section>
<section id="new-features">
<h2>New Features<a href="#new-features" title="Link to this heading">#</a></h2>
<ul>
<li><p><code><span>np.add</span></code> was extended to work with <code><span>unicode</span></code> and <code><span>bytes</span></code> dtypes.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24858">gh-24858</a>)</p>
</li>
</ul>
<section id="a-new-bitwise-count-function">
<h3>A new <code><span>bitwise_count</span></code> function<a href="#a-new-bitwise-count-function" title="Link to this heading">#</a></h3>
<p>This new function counts the number of 1-bits in a number.
<a href="https://numpy.org/devdocs/reference/generated/numpy.bitwise_count.html#numpy.bitwise_count" title="numpy.bitwise_count"><code><span>bitwise_count</span></code></a> works on all the numpy integer types and
integer-like objects.</p>
<div><pre><span></span><span>&gt;&gt;&gt; </span><span>a</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>([</span><span>2</span><span>**</span><span>i</span> <span>-</span> <span>1</span> <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>16</span><span>)])</span>
<span>&gt;&gt;&gt; </span><span>np</span><span>.</span><span>bitwise_count</span><span>(</span><span>a</span><span>)</span>
<span>array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],</span>
<span>      dtype=uint8)</span>
</pre></div>
<p>(<a href="https://github.com/numpy/numpy/pull/19355">gh-19355</a>)</p>
</section>
<section id="macos-accelerate-support-including-the-ilp64">
<h3>macOS Accelerate support, including the ILP64<a href="#macos-accelerate-support-including-the-ilp64" title="Link to this heading">#</a></h3>
<p>Support for the updated Accelerate BLAS/LAPACK library, including ILP64 (64-bit
integer) support, in macOS 13.3 has been added. This brings arm64 support, and
significant performance improvements of up to 10x for commonly used linear
algebra operations. When Accelerate is selected at build time, or if no
explicit BLAS library selection is done, the 13.3+ version will automatically
be used if available.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24053">gh-24053</a>)</p>
<p>Binary wheels are also available. On macOS &gt;=14.0, users who install NumPy from
PyPI will get wheels built against Accelerate rather than OpenBLAS.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25255">gh-25255</a>)</p>
</section>
<section id="option-to-use-weights-for-quantile-and-percentile-functions">
<h3>Option to use weights for quantile and percentile functions<a href="#option-to-use-weights-for-quantile-and-percentile-functions" title="Link to this heading">#</a></h3>
<p>A <code><span>weights</span></code> keyword is now available for <a href="https://numpy.org/devdocs/reference/generated/numpy.quantile.html#numpy.quantile" title="numpy.quantile"><code><span>quantile</span></code></a>,
<a href="https://numpy.org/devdocs/reference/generated/numpy.percentile.html#numpy.percentile" title="numpy.percentile"><code><span>percentile</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.nanquantile.html#numpy.nanquantile" title="numpy.nanquantile"><code><span>nanquantile</span></code></a> and <a href="https://numpy.org/devdocs/reference/generated/numpy.nanpercentile.html#numpy.nanpercentile" title="numpy.nanpercentile"><code><span>nanpercentile</span></code></a>. Only
<code><span>method="inverted_cdf"</span></code> supports weights.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24254">gh-24254</a>)</p>
</section>
<section id="improved-cpu-optimization-tracking">
<h3>Improved CPU optimization tracking<a href="#improved-cpu-optimization-tracking" title="Link to this heading">#</a></h3>
<p>A new tracer mechanism is available which enables tracking of the enabled
targets for each optimized function (i.e., that uses hardware-specific SIMD
instructions) in the NumPy library. With this enhancement, it becomes possible
to precisely monitor the enabled CPU dispatch targets for the dispatched
functions.</p>
<p>A new function named <code><span>opt_func_info</span></code> has been added to the new namespace
<a href="https://numpy.org/devdocs/reference/generated/numpy.lib.introspect.html#module-numpy.lib.introspect" title="numpy.lib.introspect"><code><span>numpy.lib.introspect</span></code></a>, offering this tracing capability. This function allows
you to retrieve information about the enabled targets based on function names
and data type signatures.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24420">gh-24420</a>)</p>
</section>
<section id="a-new-meson-backend-for-f2py">
<h3>A new Meson backend for <code><span>f2py</span></code><a href="#a-new-meson-backend-for-f2py" title="Link to this heading">#</a></h3>
<p><code><span>f2py</span></code> in compile mode (i.e. <code><span>f2py</span> <span>-c</span></code>) now accepts the <code><span>--backend</span> <span>meson</span></code>
option. This is the default option for Python &gt;=3.12. For older Python versions,
<code><span>f2py</span></code> will still default to <code><span>--backend</span> <span>distutils</span></code>.</p>
<p>To support this in realistic use-cases, in compile mode <code><span>f2py</span></code> takes a
<code><span>--dep</span></code> flag one or many times which maps to <code><span>dependency()</span></code> calls in the
<code><span>meson</span></code> backend, and does nothing in the <code><span>distutils</span></code> backend.</p>
<p>There are no changes for users of <code><span>f2py</span></code> only as a code generator, i.e. without <code><span>-c</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24532">gh-24532</a>)</p>
</section>
<section id="bind-c-support-for-f2py">
<h3><code><span>bind(c)</span></code> support for <code><span>f2py</span></code><a href="#bind-c-support-for-f2py" title="Link to this heading">#</a></h3>
<p>Both functions and subroutines can be annotated with <code><span>bind(c)</span></code>. <code><span>f2py</span></code> will
handle both the correct type mapping, and preserve the unique label for other
C interfaces.</p>
<p><strong>Note:</strong> <code><span>bind(c,</span> <span>name</span> <span>=</span> <span>'routine_name_other_than_fortran_routine')</span></code> is not
honored by the <code><span>f2py</span></code> bindings by design, since <code><span>bind(c)</span></code> with the <code><span>name</span></code>
is meant to guarantee only the same name in C and Fortran, not in Python and
Fortran.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24555">gh-24555</a>)</p>
</section>
<section id="a-new-strict-option-for-several-testing-functions">
<h3>A new <code><span>strict</span></code> option for several testing functions<a href="#a-new-strict-option-for-several-testing-functions" title="Link to this heading">#</a></h3>
<p>The <code><span>strict</span></code> keyword is now available for <a href="https://numpy.org/devdocs/reference/generated/numpy.testing.assert_allclose.html#numpy.testing.assert_allclose" title="numpy.testing.assert_allclose"><code><span>assert_allclose</span></code></a>,
<a href="https://numpy.org/devdocs/reference/generated/numpy.testing.assert_equal.html#numpy.testing.assert_equal" title="numpy.testing.assert_equal"><code><span>assert_equal</span></code></a>, and <a href="https://numpy.org/devdocs/reference/generated/numpy.testing.assert_array_less.html#numpy.testing.assert_array_less" title="numpy.testing.assert_array_less"><code><span>assert_array_less</span></code></a>.
Setting <code><span>strict=True</span></code> will disable the broadcasting behaviour for scalars
and ensure that input arrays have the same data type.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24680">gh-24680</a>,
<a href="https://github.com/numpy/numpy/pull/24770">gh-24770</a>,
<a href="https://github.com/numpy/numpy/pull/24775">gh-24775</a>)</p>
</section>
<section id="add-np-core-umath-find-and-np-core-umath-rfind-ufuncs">
<h3>Add <code><span>np.core.umath.find</span></code> and <code><span>np.core.umath.rfind</span></code> UFuncs<a href="#add-np-core-umath-find-and-np-core-umath-rfind-ufuncs" title="Link to this heading">#</a></h3>
<p>Add two <code><span>find</span></code> and <code><span>rfind</span></code> UFuncs that operate on unicode or byte strings
and are used in <code><span>np.char</span></code>. They operate similar to <code><span>str.find</span></code> and
<code><span>str.rfind</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24868">gh-24868</a>)</p>
</section>
<section id="diagonal-and-trace-for-numpy-linalg">
<h3><code><span>diagonal</span></code> and <code><span>trace</span></code> for <a href="https://numpy.org/devdocs/reference/routines.linalg.html#module-numpy.linalg" title="numpy.linalg"><code><span>numpy.linalg</span></code></a><a href="#diagonal-and-trace-for-numpy-linalg" title="Link to this heading">#</a></h3>
<p><a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.diagonal.html#numpy.linalg.diagonal" title="numpy.linalg.diagonal"><code><span>numpy.linalg.diagonal</span></code></a> and <a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.trace.html#numpy.linalg.trace" title="numpy.linalg.trace"><code><span>numpy.linalg.trace</span></code></a> have been
added, which are array API standard-compatible variants of <a href="https://numpy.org/devdocs/reference/generated/numpy.diagonal.html#numpy.diagonal" title="numpy.diagonal"><code><span>numpy.diagonal</span></code></a> and
<a href="https://numpy.org/devdocs/reference/generated/numpy.trace.html#numpy.trace" title="numpy.trace"><code><span>numpy.trace</span></code></a>. They differ in the default axis selection which define 2-D
sub-arrays.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24887">gh-24887</a>)</p>
</section>
<section id="new-long-and-ulong-dtypes">
<h3>New <code><span>long</span></code> and <code><span>ulong</span></code> dtypes<a href="#new-long-and-ulong-dtypes" title="Link to this heading">#</a></h3>
<p><a href="https://numpy.org/devdocs/reference/arrays.scalars.html#numpy.long" title="numpy.long"><code><span>numpy.long</span></code></a> and <a href="https://numpy.org/devdocs/reference/arrays.scalars.html#numpy.ulong" title="numpy.ulong"><code><span>numpy.ulong</span></code></a> have been added as NumPy integers mapping
to C’s <code><span>long</span></code> and <code><span>unsigned</span> <span>long</span></code>. Prior to NumPy 1.24, <code><span>numpy.long</span></code> was
an alias to Python’s <code><span>int</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24922">gh-24922</a>)</p>
</section>
<section id="svdvals-for-numpy-linalg">
<h3><code><span>svdvals</span></code> for <a href="https://numpy.org/devdocs/reference/routines.linalg.html#module-numpy.linalg" title="numpy.linalg"><code><span>numpy.linalg</span></code></a><a href="#svdvals-for-numpy-linalg" title="Link to this heading">#</a></h3>
<p><a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.svdvals.html#numpy.linalg.svdvals" title="numpy.linalg.svdvals"><code><span>numpy.linalg.svdvals</span></code></a> has been added. It computes singular values for
(a stack of) matrices. Executing <code><span>np.svdvals(x)</span></code> is the same as calling
<code><span>np.svd(x,</span> <span>compute_uv=False,</span> <span>hermitian=False)</span></code>.
This function is compatible with the array API standard.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24940">gh-24940</a>)</p>
</section>
<section id="a-new-isdtype-function">
<h3>A new <code><span>isdtype</span></code> function<a href="#a-new-isdtype-function" title="Link to this heading">#</a></h3>
<p><a href="https://numpy.org/devdocs/reference/generated/numpy.isdtype.html#numpy.isdtype" title="numpy.isdtype"><code><span>numpy.isdtype</span></code></a> was added to provide a canonical way to classify NumPy’s dtypes
in compliance with the array API standard.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25054">gh-25054</a>)</p>
</section>
<section id="a-new-astype-function">
<h3>A new <code><span>astype</span></code> function<a href="#a-new-astype-function" title="Link to this heading">#</a></h3>
<p><a href="https://numpy.org/devdocs/reference/generated/numpy.astype.html#numpy.astype" title="numpy.astype"><code><span>numpy.astype</span></code></a> was added to provide an array API standard-compatible
alternative to the <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.astype.html#numpy.ndarray.astype" title="numpy.ndarray.astype"><code><span>numpy.ndarray.astype</span></code></a> method.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25079">gh-25079</a>)</p>
</section>
<section id="array-api-compatible-functions-aliases">
<h3>Array API compatible functions’ aliases<a href="#array-api-compatible-functions-aliases" title="Link to this heading">#</a></h3>
<p>13 aliases for existing functions were added to improve compatibility with the array API standard:</p>
<ul>
<li><p>Trigonometry: <code><span>acos</span></code>, <code><span>acosh</span></code>, <code><span>asin</span></code>, <code><span>asinh</span></code>, <code><span>atan</span></code>, <code><span>atanh</span></code>, <code><span>atan2</span></code>.</p></li>
<li><p>Bitwise: <code><span>bitwise_left_shift</span></code>, <code><span>bitwise_invert</span></code>, <code><span>bitwise_right_shift</span></code>.</p></li>
<li><p>Misc: <code><span>concat</span></code>, <code><span>permute_dims</span></code>, <code><span>pow</span></code>.</p></li>
<li><p>In <code><span>numpy.linalg</span></code>: <code><span>tensordot</span></code>, <code><span>matmul</span></code>.</p></li>
</ul>
<p>(<a href="https://github.com/numpy/numpy/pull/25086">gh-25086</a>)</p>
</section>
<section id="new-unique-functions">
<h3>New <code><span>unique_*</span></code> functions<a href="#new-unique-functions" title="Link to this heading">#</a></h3>
<p>The <a href="https://numpy.org/devdocs/reference/generated/numpy.unique_all.html#numpy.unique_all" title="numpy.unique_all"><code><span>unique_all</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.unique_counts.html#numpy.unique_counts" title="numpy.unique_counts"><code><span>unique_counts</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.unique_inverse.html#numpy.unique_inverse" title="numpy.unique_inverse"><code><span>unique_inverse</span></code></a>,
and <a href="https://numpy.org/devdocs/reference/generated/numpy.unique_values.html#numpy.unique_values" title="numpy.unique_values"><code><span>unique_values</span></code></a> functions have been added. They provide
functionality of <a href="https://numpy.org/devdocs/reference/generated/numpy.unique.html#numpy.unique" title="numpy.unique"><code><span>unique</span></code></a> with different sets of flags. They are array API
standard-compatible, and because the number of arrays they return does not
depend on the values of input arguments, they are easier to target for JIT
compilation.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25088">gh-25088</a>)</p>
</section>
<section id="matrix-transpose-support-for-ndarrays">
<h3>Matrix transpose support for ndarrays<a href="#matrix-transpose-support-for-ndarrays" title="Link to this heading">#</a></h3>
<p>NumPy now offers support for calculating the matrix transpose of an array (or
stack of arrays). The matrix transpose is equivalent to swapping the last two
axes of an array. Both <code><span>np.ndarray</span></code> and <code><span>np.ma.MaskedArray</span></code> now expose a
<code><span>.mT</span></code> attribute, and there is a matching new <a href="https://numpy.org/devdocs/reference/generated/numpy.matrix_transpose.html#numpy.matrix_transpose" title="numpy.matrix_transpose"><code><span>numpy.matrix_transpose</span></code></a>
function.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23762">gh-23762</a>)</p>
</section>
<section id="array-api-compatible-functions-for-numpy-linalg">
<h3>Array API compatible functions for <code><span>numpy.linalg</span></code><a href="#array-api-compatible-functions-for-numpy-linalg" title="Link to this heading">#</a></h3>
<p>Six new functions and two aliases were added to improve compatibility with
the Array API standard for <a href="https://numpy.org/devdocs/reference/routines.linalg.html#module-numpy.linalg" title="numpy.linalg"><code><span>numpy.linalg</span></code></a>:</p>
<ul>
<li><p><a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.matrix_norm.html#numpy.linalg.matrix_norm" title="numpy.linalg.matrix_norm"><code><span>numpy.linalg.matrix_norm</span></code></a> - Computes the matrix norm of a matrix (or a stack of matrices).</p></li>
<li><p><a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.vector_norm.html#numpy.linalg.vector_norm" title="numpy.linalg.vector_norm"><code><span>numpy.linalg.vector_norm</span></code></a> - Computes the vector norm of a vector (or batch of vectors).</p></li>
<li><p><a href="https://numpy.org/devdocs/reference/generated/numpy.vecdot.html#numpy.vecdot" title="numpy.vecdot"><code><span>numpy.vecdot</span></code></a> - Computes the (vector) dot product of two arrays.</p></li>
<li><p><a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.vecdot.html#numpy.linalg.vecdot" title="numpy.linalg.vecdot"><code><span>numpy.linalg.vecdot</span></code></a> - An alias for <a href="https://numpy.org/devdocs/reference/generated/numpy.vecdot.html#numpy.vecdot" title="numpy.vecdot"><code><span>numpy.vecdot</span></code></a>.</p></li>
<li><p><a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.matrix_transpose.html#numpy.linalg.matrix_transpose" title="numpy.linalg.matrix_transpose"><code><span>numpy.linalg.matrix_transpose</span></code></a> - An alias for <a href="https://numpy.org/devdocs/reference/generated/numpy.matrix_transpose.html#numpy.matrix_transpose" title="numpy.matrix_transpose"><code><span>numpy.matrix_transpose</span></code></a>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25155">gh-25155</a>)</p>
</li>
<li><p><a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.outer.html#numpy.linalg.outer" title="numpy.linalg.outer"><code><span>numpy.linalg.outer</span></code></a> has been added. It computes the outer product of two
vectors. It differs from <a href="https://numpy.org/devdocs/reference/generated/numpy.outer.html#numpy.outer" title="numpy.outer"><code><span>numpy.outer</span></code></a> by accepting one-dimensional arrays
only. This function is compatible with the array API standard.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25101">gh-25101</a>)</p>
</li>
<li><p><a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.cross.html#numpy.linalg.cross" title="numpy.linalg.cross"><code><span>numpy.linalg.cross</span></code></a> has been added. It computes the cross product of two
(arrays of) 3-dimensional vectors. It differs from <a href="https://numpy.org/devdocs/reference/generated/numpy.cross.html#numpy.cross" title="numpy.cross"><code><span>numpy.cross</span></code></a> by accepting
three-dimensional vectors only. This function is compatible with the array
API standard.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25145">gh-25145</a>)</p>
</li>
</ul>
</section>
<section id="a-correction-argument-for-var-and-std">
<h3>A <code><span>correction</span></code> argument for <code><span>var</span></code> and <code><span>std</span></code><a href="#a-correction-argument-for-var-and-std" title="Link to this heading">#</a></h3>
<p>A <code><span>correction</span></code> argument was added to <a href="https://numpy.org/devdocs/reference/generated/numpy.var.html#numpy.var" title="numpy.var"><code><span>var</span></code></a> and <a href="https://numpy.org/devdocs/reference/generated/numpy.std.html#numpy.std" title="numpy.std"><code><span>std</span></code></a>, which is
an array API standard compatible alternative to <code><span>ddof</span></code>. As both arguments
serve a similar purpose, only one of them can be provided at the same time.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25169">gh-25169</a>)</p>
</section>
<section id="ndarray-device-and-ndarray-to-device">
<h3><code><span>ndarray.device</span></code> and <code><span>ndarray.to_device</span></code><a href="#ndarray-device-and-ndarray-to-device" title="Link to this heading">#</a></h3>
<p>An <code><span>ndarray.device</span></code> attribute and <code><span>ndarray.to_device</span></code> method were
added to <code><span>numpy.ndarray</span></code> for array API standard compatibility.</p>
<p>Additionally, <code><span>device</span></code> keyword-only arguments were added to:
<a href="https://numpy.org/devdocs/reference/generated/numpy.asarray.html#numpy.asarray" title="numpy.asarray"><code><span>asarray</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.arange.html#numpy.arange" title="numpy.arange"><code><span>arange</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.empty.html#numpy.empty" title="numpy.empty"><code><span>empty</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.empty_like.html#numpy.empty_like" title="numpy.empty_like"><code><span>empty_like</span></code></a>,
<a href="https://numpy.org/devdocs/reference/generated/numpy.eye.html#numpy.eye" title="numpy.eye"><code><span>eye</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.full.html#numpy.full" title="numpy.full"><code><span>full</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.full_like.html#numpy.full_like" title="numpy.full_like"><code><span>full_like</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.linspace.html#numpy.linspace" title="numpy.linspace"><code><span>linspace</span></code></a>,
<a href="https://numpy.org/devdocs/reference/generated/numpy.ones.html#numpy.ones" title="numpy.ones"><code><span>ones</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.ones_like.html#numpy.ones_like" title="numpy.ones_like"><code><span>ones_like</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.zeros.html#numpy.zeros" title="numpy.zeros"><code><span>zeros</span></code></a>, and <a href="https://numpy.org/devdocs/reference/generated/numpy.zeros_like.html#numpy.zeros_like" title="numpy.zeros_like"><code><span>zeros_like</span></code></a>.</p>
<p>For all these new arguments, only <code><span>device="cpu"</span></code> is supported.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25233">gh-25233</a>)</p>
</section>
<section id="stringdtype-has-been-added-to-numpy">
<h3>StringDType has been added to NumPy<a href="#stringdtype-has-been-added-to-numpy" title="Link to this heading">#</a></h3>
<p>We have added a new variable-width UTF-8 encoded string data type, implementing
a “NumPy array of Python strings”, including support for a user-provided missing
data sentinel. It is intended as a drop-in replacement for arrays of Python
strings and missing data sentinels using the object dtype. See <a href="https://numpy.org/neps/nep-0055-string_dtype.html">NEP 55</a> and <a href="https://numpy.org/devdocs/user/basics.strings.html#stringdtype"><span>the
documentation</span></a> for more details.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25347">gh-25347</a>)</p>
</section>
<section id="new-keywords-for-cholesky-and-pinv">
<h3>New keywords for <code><span>cholesky</span></code> and <code><span>pinv</span></code><a href="#new-keywords-for-cholesky-and-pinv" title="Link to this heading">#</a></h3>
<p>The <code><span>upper</span></code> and <code><span>rtol</span></code> keywords were added to <a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.cholesky.html#numpy.linalg.cholesky" title="numpy.linalg.cholesky"><code><span>numpy.linalg.cholesky</span></code></a> and
<a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.pinv.html#numpy.linalg.pinv" title="numpy.linalg.pinv"><code><span>numpy.linalg.pinv</span></code></a>, respectively, to improve array API standard compatibility.</p>
<p>For <a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.pinv.html#numpy.linalg.pinv" title="numpy.linalg.pinv"><code><span>pinv</span></code></a>, if neither <code><span>rcond</span></code> nor <code><span>rtol</span></code> is specified,
the <code><span>rcond</span></code>’s default is used. We plan to deprecate and remove <code><span>rcond</span></code> in
the future.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25388">gh-25388</a>)</p>
</section>
<section id="new-keywords-for-sort-argsort-and-linalg-matrix-rank">
<h3>New keywords for <code><span>sort</span></code>, <code><span>argsort</span></code> and <code><span>linalg.matrix_rank</span></code><a href="#new-keywords-for-sort-argsort-and-linalg-matrix-rank" title="Link to this heading">#</a></h3>
<p>New keyword parameters were added to improve array API standard compatibility:</p>
<ul>
<li><p><code><span>rtol</span></code> was added to <a href="https://numpy.org/devdocs/reference/generated/numpy.linalg.matrix_rank.html#numpy.linalg.matrix_rank" title="numpy.linalg.matrix_rank"><code><span>matrix_rank</span></code></a>.</p></li>
<li><p><code><span>stable</span></code> was added to <a href="https://numpy.org/devdocs/reference/generated/numpy.sort.html#numpy.sort" title="numpy.sort"><code><span>sort</span></code></a> and <a href="https://numpy.org/devdocs/reference/generated/numpy.argsort.html#numpy.argsort" title="numpy.argsort"><code><span>argsort</span></code></a>.</p></li>
</ul>
<p>(<a href="https://github.com/numpy/numpy/pull/25437">gh-25437</a>)</p>
</section>
<section id="new-numpy-strings-namespace-for-string-ufuncs">
<h3>New <code><span>numpy.strings</span></code> namespace for string ufuncs<a href="#new-numpy-strings-namespace-for-string-ufuncs" title="Link to this heading">#</a></h3>
<p>NumPy now implements some string operations as ufuncs. The old <code><span>np.char</span></code>
namespace is still available, and where possible the string manipulation
functions in that namespace have been updated to use the new ufuncs,
substantially improving their performance.</p>
<p>Where possible, we suggest updating code to use functions in <code><span>np.strings</span></code>
instead of <code><span>np.char</span></code>. In the future we may deprecate <code><span>np.char</span></code> in favor of
<code><span>np.strings</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25463">gh-25463</a>)</p>
</section>
<section id="numpy-fft-support-for-different-precisions-and-in-place-calculations">
<h3><a href="https://numpy.org/devdocs/reference/routines.fft.html#module-numpy.fft" title="numpy.fft"><code><span>numpy.fft</span></code></a> support for different precisions and in-place calculations<a href="#numpy-fft-support-for-different-precisions-and-in-place-calculations" title="Link to this heading">#</a></h3>
<p>The various FFT routines in <a href="https://numpy.org/devdocs/reference/routines.fft.html#module-numpy.fft" title="numpy.fft"><code><span>numpy.fft</span></code></a> now do their calculations natively in
float, double, or long double precision, depending on the input precision,
instead of always calculating in double precision. Hence, the calculation will
now be less precise for single and more precise for long double precision.
The data type of the output array will now be adjusted accordingly.</p>
<p>Furthermore, all FFT routines have gained an <code><span>out</span></code> argument that can be used
for in-place calculations.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25536">gh-25536</a>)</p>
</section>
<section id="configtool-and-pkg-config-support">
<h3>configtool and pkg-config support<a href="#configtool-and-pkg-config-support" title="Link to this heading">#</a></h3>
<p>A new <code><span>numpy-config</span></code> CLI script is available that can be queried for the
NumPy version and for compile flags needed to use the NumPy C API. This will
allow build systems to better support the use of NumPy as a dependency.
Also, a <code><span>numpy.pc</span></code> pkg-config file is now included with Numpy. In order to
find its location for use with <code><span>PKG_CONFIG_PATH</span></code>, use
<code><span>numpy-config</span> <span>--pkgconfigdir</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25730">gh-25730</a>)</p>
</section>
<section id="array-api-standard-support-in-the-main-namespace">
<h3>Array API standard support in the main namespace<a href="#array-api-standard-support-in-the-main-namespace" title="Link to this heading">#</a></h3>
<p>The main <code><span>numpy</span></code> namespace now supports the array API standard. See
<a href="https://numpy.org/devdocs/reference/array_api.html#array-api-standard-compatibility"><span>Array API standard compatibility</span></a> for details.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25911">gh-25911</a>)</p>
</section>
</section>
<section id="improvements">
<h2>Improvements<a href="#improvements" title="Link to this heading">#</a></h2>
<ul>
<li><p>Strings are now supported by <code><span>any</span></code>, <code><span>all</span></code>, and the logical ufuncs.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25651">gh-25651</a>)</p>
</li>
</ul>
<section id="integer-sequences-as-the-shape-argument-for-memmap">
<h3>Integer sequences as the shape argument for <code><span>memmap</span></code><a href="#integer-sequences-as-the-shape-argument-for-memmap" title="Link to this heading">#</a></h3>
<p><a href="https://numpy.org/devdocs/reference/generated/numpy.memmap.html#numpy.memmap" title="numpy.memmap"><code><span>numpy.memmap</span></code></a> can now be created with any integer sequence as the <code><span>shape</span></code>
argument, such as a list or numpy array of integers. Previously, only the
types of tuple and int could be used without raising an error.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23729">gh-23729</a>)</p>
</section>
<section id="errstate-is-now-faster-and-context-safe">
<h3><code><span>errstate</span></code> is now faster and context safe<a href="#errstate-is-now-faster-and-context-safe" title="Link to this heading">#</a></h3>
<p>The <a href="https://numpy.org/devdocs/reference/generated/numpy.errstate.html#numpy.errstate" title="numpy.errstate"><code><span>numpy.errstate</span></code></a> context manager/decorator is now faster and
safer.  Previously, it was not context safe and had (rare)
issues with thread-safety.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23936">gh-23936</a>)</p>
</section>
<section id="aarch64-quicksort-speed-improved-by-using-highway-s-vqsort">
<h3>AArch64 quicksort speed improved by using Highway’s VQSort<a href="#aarch64-quicksort-speed-improved-by-using-highway-s-vqsort" title="Link to this heading">#</a></h3>
<p>The first introduction of the Google Highway library, using VQSort on AArch64.
Execution time is improved by up to 16x in some cases, see the PR for benchmark
results. Extensions to other platforms will be done in the future.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24018">gh-24018</a>)</p>
</section>
<section id="complex-types-underlying-c-type-changes">
<h3>Complex types - underlying C type changes<a href="#complex-types-underlying-c-type-changes" title="Link to this heading">#</a></h3>
<ul>
<li><p>The underlying C types for all of NumPy’s complex types have been changed to
use C99 complex types.</p></li>
<li><p>While this change does not affect the memory layout of complex types, it
changes the API to be used to directly retrieve or write the real or
complex part of the complex number, since direct field access (as in <code><span>c.real</span></code>
or <code><span>c.imag</span></code>) is no longer an option. You can now use utilities provided in
<code><span>numpy/npy_math.h</span></code> to do these operations, like this:</p>
<div><pre><span></span><span>npy_cdouble</span><span> </span><span>c</span><span>;</span>
<span>npy_csetreal</span><span>(</span><span>&amp;</span><span>c</span><span>,</span><span> </span><span>1.0</span><span>);</span>
<span>npy_csetimag</span><span>(</span><span>&amp;</span><span>c</span><span>,</span><span> </span><span>0.0</span><span>);</span>
<span>printf</span><span>(</span><span>"%d + %di</span><span>\n</span><span>"</span><span>,</span><span> </span><span>npy_creal</span><span>(</span><span>c</span><span>),</span><span> </span><span>npy_cimag</span><span>(</span><span>c</span><span>));</span>
</pre></div>
</li>
<li><p>To ease cross-version compatibility, equivalent macros and a compatibility
layer have been added which can be used by downstream packages to continue
to support both NumPy 1.x and 2.x. See <a href="https://numpy.org/devdocs/reference/c-api/coremath.html#complex-numbers"><span>Support for complex numbers</span></a> for more info.</p></li>
<li><p><code><span>numpy/npy_common.h</span></code> now includes <code><span>complex.h</span></code>, which means that <code><span>complex</span></code>
is now a reserved keyword.</p></li>
</ul>
<p>(<a href="https://github.com/numpy/numpy/pull/24085">gh-24085</a>)</p>
</section>
<section id="iso-c-binding-support-and-improved-common-blocks-for-f2py">
<h3><code><span>iso_c_binding</span></code> support and improved common blocks for <code><span>f2py</span></code><a href="#iso-c-binding-support-and-improved-common-blocks-for-f2py" title="Link to this heading">#</a></h3>
<p>Previously, users would have to define their own custom <code><span>f2cmap</span></code> file to use
type mappings defined by the Fortran2003 <code><span>iso_c_binding</span></code> intrinsic module.
These type maps are now natively supported by <code><span>f2py</span></code></p>
<p>(<a href="https://github.com/numpy/numpy/pull/24555">gh-24555</a>)</p>
<p><code><span>f2py</span></code> now handles <code><span>common</span></code> blocks which have <code><span>kind</span></code> specifications from
modules. This further expands the usability of intrinsics like
<code><span>iso_fortran_env</span></code> and <code><span>iso_c_binding</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25186">gh-25186</a>)</p>
</section>
<section id="call-str-automatically-on-third-argument-to-functions-like-assert-equal">
<h3>Call <code><span>str</span></code> automatically on third argument to functions like <code><span>assert_equal</span></code><a href="#call-str-automatically-on-third-argument-to-functions-like-assert-equal" title="Link to this heading">#</a></h3>
<p>The third argument to functions like <a href="https://numpy.org/devdocs/reference/generated/numpy.testing.assert_equal.html#numpy.testing.assert_equal" title="numpy.testing.assert_equal"><code><span>assert_equal</span></code></a> now has
<code><span>str</span></code> called on it automatically. This way it mimics the built-in <code><span>assert</span></code>
statement, where <code><span>assert_equal(a,</span> <span>b,</span> <span>obj)</span></code> works like <code><span>assert</span> <span>a</span> <span>==</span> <span>b,</span> <span>obj</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24877">gh-24877</a>)</p>
</section>
<section id="support-for-array-like-atol-rtol-in-isclose-allclose">
<h3>Support for array-like <code><span>atol</span></code>/<code><span>rtol</span></code> in <code><span>isclose</span></code>, <code><span>allclose</span></code><a href="#support-for-array-like-atol-rtol-in-isclose-allclose" title="Link to this heading">#</a></h3>
<p>The keywords <code><span>atol</span></code> and <code><span>rtol</span></code> in <a href="https://numpy.org/devdocs/reference/generated/numpy.isclose.html#numpy.isclose" title="numpy.isclose"><code><span>isclose</span></code></a> and <a href="https://numpy.org/devdocs/reference/generated/numpy.allclose.html#numpy.allclose" title="numpy.allclose"><code><span>allclose</span></code></a>
now accept both scalars and arrays. An array, if given, must broadcast
to the shapes of the first two array arguments.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24878">gh-24878</a>)</p>
</section>
<section id="consistent-failure-messages-in-test-functions">
<h3>Consistent failure messages in test functions<a href="#consistent-failure-messages-in-test-functions" title="Link to this heading">#</a></h3>
<p>Previously, some <a href="https://numpy.org/devdocs/reference/routines.testing.html#module-numpy.testing" title="numpy.testing"><code><span>numpy.testing</span></code></a> assertions printed messages that
referred to the actual and desired results as <code><span>x</span></code> and <code><span>y</span></code>.
Now, these values are consistently referred to as <code><span>ACTUAL</span></code> and
<code><span>DESIRED</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24931">gh-24931</a>)</p>
</section>
<section id="n-d-fft-transforms-allow-s-i-1">
<h3>n-D FFT transforms allow <code><span>s[i]</span> <span>==</span> <span>-1</span></code><a href="#n-d-fft-transforms-allow-s-i-1" title="Link to this heading">#</a></h3>
<p>The <a href="https://numpy.org/devdocs/reference/generated/numpy.fft.fftn.html#numpy.fft.fftn" title="numpy.fft.fftn"><code><span>fftn</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.fft.ifftn.html#numpy.fft.ifftn" title="numpy.fft.ifftn"><code><span>ifftn</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.fft.rfftn.html#numpy.fft.rfftn" title="numpy.fft.rfftn"><code><span>rfftn</span></code></a>,
<a href="https://numpy.org/devdocs/reference/generated/numpy.fft.irfftn.html#numpy.fft.irfftn" title="numpy.fft.irfftn"><code><span>irfftn</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.fft.fft2.html#numpy.fft.fft2" title="numpy.fft.fft2"><code><span>fft2</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.fft.ifft2.html#numpy.fft.ifft2" title="numpy.fft.ifft2"><code><span>ifft2</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.fft.rfft2.html#numpy.fft.rfft2" title="numpy.fft.rfft2"><code><span>rfft2</span></code></a>
and <a href="https://numpy.org/devdocs/reference/generated/numpy.fft.irfft2.html#numpy.fft.irfft2" title="numpy.fft.irfft2"><code><span>irfft2</span></code></a> functions now use the whole input array along the axis
<code><span>i</span></code> if <code><span>s[i]</span> <span>==</span> <span>-1</span></code>, in line with the array API standard.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25495">gh-25495</a>)</p>
</section>
<section id="guard-pyarrayscalar-val-and-pyunicodescalarobject-for-the-limited-api">
<h3>Guard PyArrayScalar_VAL and PyUnicodeScalarObject for the limited API<a href="#guard-pyarrayscalar-val-and-pyunicodescalarobject-for-the-limited-api" title="Link to this heading">#</a></h3>
<p><code><span>PyUnicodeScalarObject</span></code> holds a <code><span>PyUnicodeObject</span></code>, which is not available
when using <code><span>Py_LIMITED_API</span></code>. Add guards to hide it and consequently also make
the <code><span>PyArrayScalar_VAL</span></code> macro hidden.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25531">gh-25531</a>)</p>
</section>
</section>
<section id="changes">
<h2>Changes<a href="#changes" title="Link to this heading">#</a></h2>
<ul>
<li><p><code><span>np.gradient()</span></code> now returns a tuple rather than a list making the
return value immutable.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23861">gh-23861</a>)</p>
</li>
<li><p>Being fully context and thread-safe, <code><span>np.errstate</span></code> can only
be entered once now.</p></li>
<li><p><code><span>np.setbufsize</span></code> is now tied to <code><span>np.errstate()</span></code>: leaving an
<code><span>np.errstate</span></code> context will also reset the <code><span>bufsize</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23936">gh-23936</a>)</p>
</li>
<li><p>A new public <code><span>np.lib.array_utils</span></code> submodule has been introduced and it
currently contains three functions: <code><span>byte_bounds</span></code> (moved from
<code><span>np.lib.utils</span></code>), <code><span>normalize_axis_tuple</span></code> and <code><span>normalize_axis_index</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24540">gh-24540</a>)</p>
</li>
<li><p>Introduce <a href="https://numpy.org/devdocs/reference/arrays.scalars.html#numpy.bool" title="numpy.bool"><code><span>numpy.bool</span></code></a> as the new canonical name for NumPy’s boolean dtype,
and make <a href="https://numpy.org/devdocs/reference/arrays.scalars.html#numpy.bool_" title="numpy.bool_"><code><span>numpy.bool_</span></code></a> an alias to it. Note that until NumPy 1.24,
<code><span>np.bool</span></code> was an alias to Python’s builtin <code><span>bool</span></code>. The new name helps
with array API standard compatibility and is a more intuitive name.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25080">gh-25080</a>)</p>
</li>
<li><p>The <code><span>dtype.flags</span></code> value was previously stored as a signed integer.
This means that the aligned dtype struct flag lead to negative flags being
set (-128 rather than 128). This flag is now stored unsigned (positive). Code
which checks flags manually may need to adapt.  This may include code
compiled with Cython 0.29.x.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25816">gh-25816</a>)</p>
</li>
</ul>
<section id="representation-of-numpy-scalars-changed">
<h3>Representation of NumPy scalars changed<a href="#representation-of-numpy-scalars-changed" title="Link to this heading">#</a></h3>
<p>As per <a href="https://numpy.org/neps/nep-0051-scalar-representation.html#nep51" title="(in NumPy Enhancement Proposals)"><span>NEP 51</span></a>, the scalar representation has been
updated to include the type information to avoid confusion with
Python scalars.</p>
<p>Scalars are now printed as <code><span>np.float64(3.0)</span></code> rather than just <code><span>3.0</span></code>.
This may disrupt workflows that store representations of numbers
(e.g., to files) making it harder to read them. They should be stored as
explicit strings, for example by using <code><span>str()</span></code> or <code><span>f"{scalar!s}"</span></code>.
For the time being, affected users can use <code><span>np.set_printoptions(legacy="1.25")</span></code>
to get the old behavior (with possibly a few exceptions).
Documentation of downstream projects may require larger updates,
if code snippets are tested.  We are working on tooling for
<a href="https://github.com/scientific-python/pytest-doctestplus/issues/107">doctest-plus</a>
to facilitate updates.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/22449">gh-22449</a>)</p>
</section>
<section id="truthiness-of-numpy-strings-changed">
<h3>Truthiness of NumPy strings changed<a href="#truthiness-of-numpy-strings-changed" title="Link to this heading">#</a></h3>
<p>NumPy strings previously were inconsistent about how they defined
if the string is <code><span>True</span></code> or <code><span>False</span></code> and the definition did not
match the one used by Python.
Strings are now considered <code><span>True</span></code> when they are non-empty and
<code><span>False</span></code> when they are empty.
This changes the following distinct cases:</p>
<ul>
<li><p>Casts from string to boolean were previously roughly equivalent
to <code><span>string_array.astype(np.int64).astype(bool)</span></code>, meaning that only
valid integers could be cast.
Now a string of <code><span>"0"</span></code> will be considered <code><span>True</span></code> since it is not empty.
If you need the old behavior, you may use the above step (casting
to integer first) or <code><span>string_array</span> <span>==</span> <span>"0"</span></code> (if the input is only ever <code><span>0</span></code> or <code><span>1</span></code>).
To get the new result on old NumPy versions use <code><span>string_array</span> <span>!=</span> <span>""</span></code>.</p></li>
<li><p><code><span>np.nonzero(string_array)</span></code> previously ignored whitespace so that
a string only containing whitespace was considered <code><span>False</span></code>.
Whitespace is now considered <code><span>True</span></code>.</p></li>
</ul>
<p>This change does not affect <code><span>np.loadtxt</span></code>, <code><span>np.fromstring</span></code>, or <code><span>np.genfromtxt</span></code>.
The first two still use the integer definition, while <code><span>genfromtxt</span></code> continues to
match for <code><span>"true"</span></code> (ignoring case).
However, if <code><span>np.bool_</span></code> is used as a converter the result will change.</p>
<p>The change does affect <code><span>np.fromregex</span></code> as it uses direct assignments.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/23871">gh-23871</a>)</p>
</section>
<section id="a-mean-keyword-was-added-to-var-and-std-function">
<h3>A <code><span>mean</span></code> keyword was added to var and std function<a href="#a-mean-keyword-was-added-to-var-and-std-function" title="Link to this heading">#</a></h3>
<p>Often when the standard deviation is needed the mean is also needed. The same
holds for the variance and the mean. Until now the mean is then calculated twice,
the change introduced here for the <a href="https://numpy.org/devdocs/reference/generated/numpy.var.html#numpy.var" title="numpy.var"><code><span>var</span></code></a> and <a href="https://numpy.org/devdocs/reference/generated/numpy.std.html#numpy.std" title="numpy.std"><code><span>std</span></code></a> functions
allows for passing in a precalculated mean as an keyword argument. See the
docstrings for details and an example illustrating the speed-up.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24126">gh-24126</a>)</p>
</section>
<section id="remove-datetime64-deprecation-warning-when-constructing-with-timezone">
<h3>Remove datetime64 deprecation warning when constructing with timezone<a href="#remove-datetime64-deprecation-warning-when-constructing-with-timezone" title="Link to this heading">#</a></h3>
<p>The <a href="https://numpy.org/devdocs/reference/arrays.scalars.html#numpy.datetime64" title="numpy.datetime64"><code><span>numpy.datetime64</span></code></a> method now issues a UserWarning rather than a
DeprecationWarning whenever a timezone is included in the datetime
string that is provided.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24193">gh-24193</a>)</p>
</section>
<section id="default-integer-dtype-is-now-64-bit-on-64-bit-windows">
<h3>Default integer dtype is now 64-bit on 64-bit Windows<a href="#default-integer-dtype-is-now-64-bit-on-64-bit-windows" title="Link to this heading">#</a></h3>
<p>The default NumPy integer is now 64-bit on all 64-bit systems as the historic
32-bit default on Windows was a common source of issues. Most users should not
notice this. The main issues may occur with code interfacing with libraries
written in a compiled language like C.  For more information see
<a href="https://numpy.org/devdocs/numpy_2_0_migration_guide.html#migration-windows-int64"><span>Windows default integer</span></a>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24224">gh-24224</a>)</p>
</section>
<section id="renamed-numpy-core-to-numpy-core">
<h3>Renamed <code><span>numpy.core</span></code> to <code><span>numpy._core</span></code><a href="#renamed-numpy-core-to-numpy-core" title="Link to this heading">#</a></h3>
<p>Accessing <code><span>numpy.core</span></code> now emits a DeprecationWarning. In practice
we have found that most downstream usage of <code><span>numpy.core</span></code> was to access
functionality that is available in the main <code><span>numpy</span></code> namespace.
If for some reason you are using functionality in <code><span>numpy.core</span></code> that
is not available in the main <code><span>numpy</span></code> namespace, this means you are likely
using private NumPy internals. You can still access these internals via
<code><span>numpy._core</span></code> without a deprecation warning but we do not provide any
backward compatibility guarantees for NumPy internals. Please open an issue
if you think a mistake was made and something needs to be made public.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24634">gh-24634</a>)</p>
<p>The “relaxed strides” debug build option, which was previously enabled through
the <code><span>NPY_RELAXED_STRIDES_DEBUG</span></code> environment variable or the
<code><span>-Drelaxed-strides-debug</span></code> config-settings flag has been removed.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24717">gh-24717</a>)</p>
</section>
<section id="redefinition-of-np-intp-np-uintp-almost-never-a-change">
<h3>Redefinition of <code><span>np.intp</span></code>/<code><span>np.uintp</span></code> (almost never a change)<a href="#redefinition-of-np-intp-np-uintp-almost-never-a-change" title="Link to this heading">#</a></h3>
<p>Due to the actual use of these types almost always matching the use of
<code><span>size_t</span></code>/<code><span>Py_ssize_t</span></code> this is now the definition in C.
Previously, it matched <code><span>intptr_t</span></code> and <code><span>uintptr_t</span></code> which would often
have been subtly incorrect.
This has no effect on the vast majority of machines since the size
of these types only differ on extremely niche platforms.</p>
<p>However, it means that:</p>
<ul>
<li><p>Pointers may not necessarily fit into an <code><span>intp</span></code> typed array anymore.
The <code><span>p</span></code> and <code><span>P</span></code> character codes can still be used, however.</p></li>
<li><p>Creating <code><span>intptr_t</span></code> or <code><span>uintptr_t</span></code> typed arrays in C remains possible
in a cross-platform way via <code><span>PyArray_DescrFromType('p')</span></code>.</p></li>
<li><p>The new character codes <code><span>nN</span></code> were introduced.</p></li>
<li><p>It is now correct to use the Python C-API functions when parsing
to <code><span>npy_intp</span></code> typed arguments.</p></li>
</ul>
<p>(<a href="https://github.com/numpy/numpy/pull/24888">gh-24888</a>)</p>
</section>
<section id="numpy-fft-helper-made-private">
<h3><code><span>numpy.fft.helper</span></code> made private<a href="#numpy-fft-helper-made-private" title="Link to this heading">#</a></h3>
<p><code><span>numpy.fft.helper</span></code> was renamed to <code><span>numpy.fft._helper</span></code> to indicate
that it is a private submodule. All public functions exported by it
should be accessed from <a href="https://numpy.org/devdocs/reference/routines.fft.html#module-numpy.fft" title="numpy.fft"><code><span>numpy.fft</span></code></a>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24945">gh-24945</a>)</p>
</section>
<section id="numpy-linalg-linalg-made-private">
<h3><code><span>numpy.linalg.linalg</span></code> made private<a href="#numpy-linalg-linalg-made-private" title="Link to this heading">#</a></h3>
<p><code><span>numpy.linalg.linalg</span></code> was renamed to <code><span>numpy.linalg._linalg</span></code>
to indicate that it is a private submodule. All public functions
exported by it should be accessed from <a href="https://numpy.org/devdocs/reference/routines.linalg.html#module-numpy.linalg" title="numpy.linalg"><code><span>numpy.linalg</span></code></a>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/24946">gh-24946</a>)</p>
</section>
<section id="out-of-bound-axis-not-the-same-as-axis-none">
<h3>Out-of-bound axis not the same as <code><span>axis=None</span></code><a href="#out-of-bound-axis-not-the-same-as-axis-none" title="Link to this heading">#</a></h3>
<p>In some cases <code><span>axis=32</span></code> or for concatenate any large value
was the same as <code><span>axis=None</span></code>.
Except for <code><span>concatenate</span></code> this was deprecate.
Any out of bound axis value will now error, make sure to use
<code><span>axis=None</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25149">gh-25149</a>)</p>
</section>
<section id="new-copy-keyword-meaning-for-array-and-asarray-constructors">
<span id="copy-keyword-changes-2-0"></span><h3>New <code><span>copy</span></code> keyword meaning for <code><span>array</span></code> and <code><span>asarray</span></code> constructors<a href="#new-copy-keyword-meaning-for-array-and-asarray-constructors" title="Link to this heading">#</a></h3>
<p>Now <a href="https://numpy.org/devdocs/reference/generated/numpy.array.html#numpy.array" title="numpy.array"><code><span>numpy.array</span></code></a> and <a href="https://numpy.org/devdocs/reference/generated/numpy.asarray.html#numpy.asarray" title="numpy.asarray"><code><span>numpy.asarray</span></code></a> support three values for <code><span>copy</span></code> parameter:</p>
<ul>
<li><p><code><span>None</span></code> - A copy will only be made if it is necessary.</p></li>
<li><p><code><span>True</span></code> - Always make a copy.</p></li>
<li><p><code><span>False</span></code> - Never make a copy. If a copy is required a <code><span>ValueError</span></code> is raised.</p></li>
</ul>
<p>The meaning of <code><span>False</span></code> changed as it now raises an exception if a copy is needed.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25168">gh-25168</a>)</p>
</section>
<section id="the-array-special-method-now-takes-a-copy-keyword-argument">
<h3>The <code><span>__array__</span></code> special method now takes a <code><span>copy</span></code> keyword argument.<a href="#the-array-special-method-now-takes-a-copy-keyword-argument" title="Link to this heading">#</a></h3>
<p>NumPy will pass <code><span>copy</span></code> to the <code><span>__array__</span></code> special method in situations where
it would be set to a non-default value (e.g. in a call to
<code><span>np.asarray(some_object,</span> <span>copy=False)</span></code>). Currently, if an
unexpected keyword argument error is raised after this, NumPy will print a
warning and re-try without the <code><span>copy</span></code> keyword argument. Implementations of
objects implementing the <code><span>__array__</span></code> protocol should accept a <code><span>copy</span></code> keyword
argument with the same meaning as when passed to <a href="https://numpy.org/devdocs/reference/generated/numpy.array.html#numpy.array" title="numpy.array"><code><span>numpy.array</span></code></a> or
<a href="https://numpy.org/devdocs/reference/generated/numpy.asarray.html#numpy.asarray" title="numpy.asarray"><code><span>numpy.asarray</span></code></a>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25168">gh-25168</a>)</p>
</section>
<section id="cleanup-of-initialization-of-numpy-dtype-with-strings-with-commas">
<h3>Cleanup of initialization of <code><span>numpy.dtype</span></code> with strings with commas<a href="#cleanup-of-initialization-of-numpy-dtype-with-strings-with-commas" title="Link to this heading">#</a></h3>
<p>The interpretation of strings with commas is changed slightly, in that a
trailing comma will now always create a structured dtype.  E.g., where
previously <code><span>np.dtype("i")</span></code> and <code><span>np.dtype("i,")</span></code> were treated as identical,
now <code><span>np.dtype("i,")</span></code> will create a structured dtype, with a single
field. This is analogous to <code><span>np.dtype("i,i")</span></code> creating a structured dtype
with two fields, and makes the behaviour consistent with that expected of
tuples.</p>
<p>At the same time, the use of single number surrounded by parenthesis to
indicate a sub-array shape, like in <code><span>np.dtype("(2)i,")</span></code>, is deprecated.
Instead; one should use <code><span>np.dtype("(2,)i")</span></code> or <code><span>np.dtype("2i")</span></code>.
Eventually, using a number in parentheses will raise an exception, like is the
case for initializations without a comma, like <code><span>np.dtype("(2)i")</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25434">gh-25434</a>)</p>
</section>
<section id="change-in-how-complex-sign-is-calculated">
<h3>Change in how complex sign is calculated<a href="#change-in-how-complex-sign-is-calculated" title="Link to this heading">#</a></h3>
<p>Following the array API standard, the complex sign is now calculated as
<code><span>z</span> <span>/</span> <span>|z|</span></code> (instead of the rather less logical case where the sign of
the real part was taken, unless the real part was zero, in which case
the sign of the imaginary part was returned).  Like for real numbers,
zero is returned if <code><span>z==0</span></code>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25441">gh-25441</a>)</p>
</section>
<section id="return-types-of-functions-that-returned-a-list-of-arrays">
<h3>Return types of functions that returned a list of arrays<a href="#return-types-of-functions-that-returned-a-list-of-arrays" title="Link to this heading">#</a></h3>
<p>Functions that returned a list of ndarrays have been changed to return a tuple
of ndarrays instead. Returning tuples consistently whenever a sequence of
arrays is returned makes it easier for JIT compilers like Numba, as well as for
static type checkers in some cases, to support these functions. Changed
functions are: <a href="https://numpy.org/devdocs/reference/generated/numpy.atleast_1d.html#numpy.atleast_1d" title="numpy.atleast_1d"><code><span>atleast_1d</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.atleast_2d.html#numpy.atleast_2d" title="numpy.atleast_2d"><code><span>atleast_2d</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.atleast_3d.html#numpy.atleast_3d" title="numpy.atleast_3d"><code><span>atleast_3d</span></code></a>,
<a href="https://numpy.org/devdocs/reference/generated/numpy.broadcast_arrays.html#numpy.broadcast_arrays" title="numpy.broadcast_arrays"><code><span>broadcast_arrays</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.meshgrid.html#numpy.meshgrid" title="numpy.meshgrid"><code><span>meshgrid</span></code></a>, <a href="https://numpy.org/devdocs/reference/generated/numpy.ogrid.html#numpy.ogrid" title="numpy.ogrid"><code><span>ogrid</span></code></a>,
<a href="https://numpy.org/devdocs/reference/generated/numpy.histogramdd.html#numpy.histogramdd" title="numpy.histogramdd"><code><span>histogramdd</span></code></a>.</p>
</section>
<section id="np-unique-return-inverse-shape-for-multi-dimensional-inputs">
<h3><code><span>np.unique</span></code> <code><span>return_inverse</span></code> shape for multi-dimensional inputs<a href="#np-unique-return-inverse-shape-for-multi-dimensional-inputs" title="Link to this heading">#</a></h3>
<p>When multi-dimensional inputs are passed to <code><span>np.unique</span></code> with <code><span>return_inverse=True</span></code>,
the <code><span>unique_inverse</span></code> output is now shaped such that the input can be reconstructed
directly using <code><span>np.take(unique,</span> <span>unique_inverse)</span></code> when <code><span>axis=None</span></code>, and
<code><span>np.take_along_axis(unique,</span> <span>unique_inverse,</span> <span>axis=axis)</span></code> otherwise.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25553">gh-25553</a>,
<a href="https://github.com/numpy/numpy/pull/25570">gh-25570</a>)</p>
</section>
<section id="any-and-all-return-booleans-for-object-arrays">
<h3><code><span>any</span></code> and <code><span>all</span></code> return booleans for object arrays<a href="#any-and-all-return-booleans-for-object-arrays" title="Link to this heading">#</a></h3>
<p>The <code><span>any</span></code> and <code><span>all</span></code> functions and methods now return
booleans also for object arrays.  Previously, they did
a reduction which behaved like the Python <code><span>or</span></code> and
<code><span>and</span></code> operators which evaluates to one of the arguments.
You can use <code><span>np.logical_or.reduce</span></code> and <code><span>np.logical_and.reduce</span></code>
to achieve the previous behavior.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/25712">gh-25712</a>)</p>
</section>
<section id="np-can-cast-cannot-be-called-on-python-int-float-or-complex">
<h3><code><span>np.can_cast</span></code> cannot be called on Python int, float, or complex<a href="#np-can-cast-cannot-be-called-on-python-int-float-or-complex" title="Link to this heading">#</a></h3>
<p><code><span>np.can_cast</span></code> cannot be called with Python int, float, or complex instances
anymore.  This is because NEP 50 means that the result of <code><span>can_cast</span></code> must
not depend on the value passed in.
Unfortunately, for Python scalars whether a cast should be considered
<code><span>"same_kind"</span></code> or <code><span>"safe"</span></code> may depend on the context and value so that
this is currently not implemented.
In some cases, this means you may have to add a specific path for:
<code><span>if</span> <span>type(obj)</span> <span>in</span> <span>(int,</span> <span>float,</span> <span>complex):</span> <span>...</span></code>.</p>
<p><strong>Content from release note snippets in doc/release/upcoming_changes:</strong></p>
</section>
</section>
<section id="id1">
<h2>Deprecations<a href="#id1" title="Link to this heading">#</a></h2>
<blockquote>
<div><ul>
<li><p>The <em>fix_imports</em> keyword argument in <a href="https://numpy.org/devdocs/reference/generated/numpy.save.html#numpy.save" title="numpy.save"><code><span>numpy.save</span></code></a> is deprecated. Since
NumPy 1.17, <a href="https://numpy.org/devdocs/reference/generated/numpy.save.html#numpy.save" title="numpy.save"><code><span>numpy.save</span></code></a> uses a pickle protocol that no longer supports
Python 2, and ignored <em>fix_imports</em> keyword. This keyword is kept only
for backward compatibility. It is now deprecated.</p></li>
</ul>
</div></blockquote>
<p>(<a href="https://github.com/numpy/numpy/pull/26452">gh-26452</a>)</p>
</section>
<section id="id2">
<h2>Expired deprecations<a href="#id2" title="Link to this heading">#</a></h2>
<ul>
<li><p>Scalars and 0D arrays are disallowed for <a href="https://numpy.org/devdocs/reference/generated/numpy.nonzero.html#numpy.nonzero" title="numpy.nonzero"><code><span>numpy.nonzero</span></code></a> and <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.nonzero.html#numpy.ndarray.nonzero" title="numpy.ndarray.nonzero"><code><span>numpy.ndarray.nonzero</span></code></a>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/26268">gh-26268</a>)</p>
</li>
</ul>
</section>
<section id="id3">
<h2>C API changes<a href="#id3" title="Link to this heading">#</a></h2>
<section id="api-symbols-now-hidden-but-customizable">
<h3>API symbols now hidden but customizable<a href="#api-symbols-now-hidden-but-customizable" title="Link to this heading">#</a></h3>
<p>NumPy now defaults to hide the API symbols it adds to allow all NumPy API
usage.
This means that by default you cannot dynamically fetch the NumPy API from
another library (this was never possible on windows).</p>
<p>If you are experiencing linking errors related to <code><span>PyArray_API</span></code> or
<code><span>PyArray_RUNTIME_VERSION</span></code>, you can define the
<a href="https://numpy.org/devdocs/reference/c-api/array.html#c.NPY_API_SYMBOL_ATTRIBUTE" title="NPY_API_SYMBOL_ATTRIBUTE"><code><span>NPY_API_SYMBOL_ATTRIBUTE</span></code></a> to opt-out of this change.</p>
<p>If you are experiencing problems due to an upstream header including NumPy,
the solution is to make sure you <code><span>#include</span> <span>"numpy/ndarrayobject.h"</span></code> before
their header and import NumPy yourself based on  <a href="https://numpy.org/devdocs/reference/c-api/array.html#including-the-c-api"><span>Including and importing the C API</span></a>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/26103">gh-26103</a>)</p>
</section>
</section>
<section id="id4">
<h2>New Features<a href="#id4" title="Link to this heading">#</a></h2>
<ul>
<li><p><a href="https://numpy.org/devdocs/reference/generated/numpy.reshape.html#numpy.reshape" title="numpy.reshape"><code><span>numpy.reshape</span></code></a> and <a href="https://numpy.org/devdocs/reference/generated/numpy.ndarray.reshape.html#numpy.ndarray.reshape" title="numpy.ndarray.reshape"><code><span>numpy.ndarray.reshape</span></code></a> now support <code><span>shape</span></code> and <code><span>copy</span></code> arguments.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/26292">gh-26292</a>)</p>
</li>
<li><p>NumPy now supports DLPack v1, support for older versions will
be deprecated in the future.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/26501">gh-26501</a>)</p>
</li>
<li><p><a href="https://numpy.org/devdocs/reference/generated/numpy.asanyarray.html#numpy.asanyarray" title="numpy.asanyarray"><code><span>numpy.asanyarray</span></code></a> now supports <code><span>copy</span></code> and <code><span>device</span></code> arguments, matching <a href="https://numpy.org/devdocs/reference/generated/numpy.asarray.html#numpy.asarray" title="numpy.asarray"><code><span>numpy.asarray</span></code></a>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/26580">gh-26580</a>)</p>
</li>
</ul>
</section>
<section id="id5">
<h2>Improvements<a href="#id5" title="Link to this heading">#</a></h2>
<section id="histogram-auto-binning-now-returns-bin-sizes-1-for-integer-input-data">
<h3><code><span>histogram</span></code> auto-binning now returns bin sizes &gt;=1 for integer input data<a href="#histogram-auto-binning-now-returns-bin-sizes-1-for-integer-input-data" title="Link to this heading">#</a></h3>
<p>For integer input data, bin sizes smaller than 1 result in spurious empty
bins.  This is now avoided when the number of bins is computed using one of the
algorithms provided by <a href="https://numpy.org/devdocs/reference/generated/numpy.histogram_bin_edges.html#numpy.histogram_bin_edges" title="numpy.histogram_bin_edges"><code><span>histogram_bin_edges</span></code></a>.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/12150">gh-12150</a>)</p>
</section>
</section>
<section id="performance-improvements-and-changes">
<h2>Performance improvements and changes<a href="#performance-improvements-and-changes" title="Link to this heading">#</a></h2>
<section id="ma-cov-and-ma-corrcoef-are-now-significantly-faster">
<h3><code><span>ma.cov</span></code> and <code><span>ma.corrcoef</span></code> are now significantly faster<a href="#ma-cov-and-ma-corrcoef-are-now-significantly-faster" title="Link to this heading">#</a></h3>
<p>The private function has been refactored along with <a href="https://numpy.org/devdocs/reference/generated/numpy.ma.cov.html#numpy.ma.cov" title="numpy.ma.cov"><code><span>ma.cov</span></code></a> and
<a href="https://numpy.org/devdocs/reference/generated/numpy.ma.corrcoef.html#numpy.ma.corrcoef" title="numpy.ma.corrcoef"><code><span>ma.corrcoef</span></code></a>. They are now significantly faster, particularly on large,
masked arrays.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/26285">gh-26285</a>)</p>
<blockquote>
<div><ul>
<li><p><a href="https://numpy.org/devdocs/reference/generated/numpy.save.html#numpy.save" title="numpy.save"><code><span>numpy.save</span></code></a> now uses pickle protocol version 4 for saving arrays with
object dtype, which allows for pickle objects larger than 4GB and improves
saving speed by about 5% for large arrays.</p></li>
</ul>
</div></blockquote>
<p>(<a href="https://github.com/numpy/numpy/pull/26388">gh-26388</a>)</p>
</section>
</section>
<section id="id6">
<h2>Changes<a href="#id6" title="Link to this heading">#</a></h2>
<ul>
<li><p>As <a href="https://numpy.org/devdocs/reference/generated/numpy.vecdot.html#numpy.vecdot" title="numpy.vecdot"><code><span>numpy.vecdot</span></code></a> is now a ufunc it has a less precise signature.
This is due to the limitations of ufunc’s typing stub.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/26313">gh-26313</a>)</p>
</li>
</ul>
<section id="ma-corrcoef-may-return-a-slightly-different-result">
<h3><code><span>ma.corrcoef</span></code> may return a slightly different result<a href="#ma-corrcoef-may-return-a-slightly-different-result" title="Link to this heading">#</a></h3>
<p>A pairwise observation approach is currently used in <a href="https://numpy.org/devdocs/reference/generated/numpy.ma.corrcoef.html#numpy.ma.corrcoef" title="numpy.ma.corrcoef"><code><span>ma.corrcoef</span></code></a> to
calculate the standard deviations for each pair of variables. This has been
changed as it is being used to normalise the covariance, estimated using
<a href="https://numpy.org/devdocs/reference/generated/numpy.ma.cov.html#numpy.ma.cov" title="numpy.ma.cov"><code><span>ma.cov</span></code></a>, which does not consider the observations for each variable in a
pairwise manner, rendering it unnecessary. The normalisation has been
replaced by the more appropriate standard deviation for each variable,
which significantly reduces the wall time, but will return slightly different
estimates of the correlation coefficients in cases where the observations
between a pair of variables are not aligned. However, it will return the same
estimates in all other cases, including returning the same correlation matrix
as <a href="https://numpy.org/devdocs/reference/generated/numpy.corrcoef.html#numpy.corrcoef" title="numpy.corrcoef"><code><span>corrcoef</span></code></a> when using a masked array with no masked values.</p>
<p>(<a href="https://github.com/numpy/numpy/pull/26285">gh-26285</a>)</p>
</section>
</section>
</section>


                </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Quake 1 potential original font (171 pts)]]></title>
            <link>https://cohost.org/bekoha/post/2859948-quake-1-potential-or</link>
            <guid>40699459</guid>
            <pubDate>Sun, 16 Jun 2024 19:30:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cohost.org/bekoha/post/2859948-quake-1-potential-or">https://cohost.org/bekoha/post/2859948-quake-1-potential-or</a>, See on <a href="https://news.ycombinator.com/item?id=40699459">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Some time last year while watching a video I got jumpscared by a logo that used a font that is immediately recognizable as <!-- --><em>the Quake font<!-- --></em>, and they used it at the very least 20+ years before Quake 1 even came out. This made me realize that <!-- --><em>the Quake font<!-- --></em> wasn't drawn completely from scratch and that it's probably possible to find it, most likely in a book or a digitization by someone.<!-- --></p><div><hr>
<!-- --><p><img src="https://staging.cohostcdn.org/attachment/e3875a72-5d4a-455a-87c6-f2c1f58f05a1/chrome_2023-09-16_02-39-25.jpg" alt=""><br>
This has been nagging me for some time and I've made several unsuccessful attempts at trying to find it before, but recently I've come across Dan X. Solo's "The Solotype Catalog of 4,147 Display Typefaces", 1992, and under "Stencil fonts" on the page 119 surprisingly actually found a sample for a font named "Visa", as pictured above. Checking Dan X. Solo's other books lead me to an earlier book named "Stencil Alphabets: 100 Complete Fonts", published in 1988, and turns out there's an entire page dedicated to this font showing the entire alphabet and numbers and other characters.<!-- --></p>
<!-- --><p><img src="https://staging.cohostcdn.org/attachment/cb178dcc-fea9-403a-bcba-bebb404b8d7d/e9780486168883_i0098.jpg" alt=""><br>
While differences between this sample and both the Schott logo and final result in Quake are present, similarities between most of letterforms and some really specific ones like X and Y make me believe that Visa (or, more likely, its progenitor or a derivative because legally it's a typography free-for-all out there with everyone ripping off each other) was in fact used as a base for the Quake font.<!-- --></p>
<!-- --><p>edit: According to <!-- --><a href="http://luc.devroye.org/fonts-44242.html" target="_blank" rel="nofollow noopener">Luc Devroye's "On Snot and Fonts"<!-- --></a>, original Visa font's designer is Raphael Boguslav.<!-- --></p>
<!-- --><blockquote>
<!-- --><p>His typeface Avia (VGC) was an expansion of a logofont he did for Abex Corporation, almost like a stencil. It is now at Font Bureau, where Jill Pichotta has added the Light and Bold in 2000. His typeface Visa (1966, VGC) won the Second Prize in the 1966 VGC National Type Face Design Competition. Others (thanks, Alexander Tochilovsky) confirm what I thought---that Visa and Avia are the same thing.<!-- --></p>
<!-- --></blockquote>
<!-- --><p>Excerpt from the official promotional PDF for FontBureau's Avia<!-- --><br>
<!-- --><img src="https://staging.cohostcdn.org/attachment/5814a628-676a-4f76-95bb-105d02757125/Avia.png" alt=""><br>
<!-- --><a href="https://fontsinuse.com/typefaces/2173/avia" target="_blank" rel="nofollow noopener">https://fontsinuse.com/typefaces/2173/avia<!-- --></a><br>
<!-- --><a href="http://web.archive.org/web/20130617135330/http://www.fontbureau.com/fonts/avia/" target="_blank" rel="nofollow noopener">http://web.archive.org/web/20130617135330/http://www.fontbureau.com/fonts/avia/<!-- --></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Experts vs. Imitators (298 pts)]]></title>
            <link>https://fs.blog/experts-vs-imitators/</link>
            <guid>40699079</guid>
            <pubDate>Sun, 16 Jun 2024 18:33:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fs.blog/experts-vs-imitators/">https://fs.blog/experts-vs-imitators/</a>, See on <a href="https://news.ycombinator.com/item?id=40699079">Hacker News</a></p>
Couldn't get https://fs.blog/experts-vs-imitators/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Japanese words and names sound African (2022) (106 pts)]]></title>
            <link>https://www.farooqkperogi.com/2022/10/japanese-words-and-names-sound-african.html</link>
            <guid>40699007</guid>
            <pubDate>Sun, 16 Jun 2024 18:20:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.farooqkperogi.com/2022/10/japanese-words-and-names-sound-african.html">https://www.farooqkperogi.com/2022/10/japanese-words-and-names-sound-african.html</a>, See on <a href="https://news.ycombinator.com/item?id=40699007">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post23291839112526094550"><p><b>By Farooq Kperogi</b></p><p><b>Twitter: <a href="https://twitter.com/farooqkperogi" target="_blank">@farooqkperogi</a></b></p><p>Most Japanese words and names sound like—and actually appear in—most languages in west, central, east, and even southern African. The reverse is also true: Japanese people find a curious phonetic correspondence between their language and most African languages.</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgKGPHxg2vWy_cisaKH6ry9hPwULEtZsaqTseBZKfXidmXOCmczY4FhHYhBB4f3SsDiS_W8EM8IQH2qg_toA94ez_WmAjh69UqBLReN2PKz6nh2y75l3YLZZ0VueHnz0YURpn5NaREe4v-8ol88tML1L1ob6Xk-d025Ja5ImTrpasCFXpq5eODfrRfA/s960/Japanese%20and%20Africans.jpg" imageanchor="1"><img data-original-height="720" data-original-width="960" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgKGPHxg2vWy_cisaKH6ry9hPwULEtZsaqTseBZKfXidmXOCmczY4FhHYhBB4f3SsDiS_W8EM8IQH2qg_toA94ez_WmAjh69UqBLReN2PKz6nh2y75l3YLZZ0VueHnz0YURpn5NaREe4v-8ol88tML1L1ob6Xk-d025Ja5ImTrpasCFXpq5eODfrRfA/s16000/Japanese%20and%20Africans.jpg"></a></p><p>The most famous example of this is the name Obama, a Luo name from Kenya, which is also the name of a town in Japan. When Barack Obama was elected US president in 2008, the town shot to international prominence.&nbsp;</p><p>We later learned that Obama means a “small beach” in the Japanese language. (There’s also a town called Obama in Nigeria’s River State).</p><p>Until relatively recently, I used to think Ajinomoto, whose seasoning was omnipresent in Nigerian kitchens when I lived there, was a Nigerian company that derived its name from a Nigerian language.</p><p>In fact, just yesterday, I asked my wife, who is half Nigerian (Igbo) and half American, to guess what language Ajinomoto came from. She said with cocksure certainty that it had to be Yoruba! (She spent three years in Ogbomosho and speaks some Yoruba). She was shocked to realize that Ajinomoto is Japanese.</p><p>Japanese brands like Suzuki, Yamaha, Kawasaki, etc. resonated with us when I was growing up in Nigeria because they sounded every bit African, even Nigerian.</p><p>But it gets even more interesting. Japanese capital Tokyo used to be called Edo, the name of a state and people in midwestern Nigeria.&nbsp;</p><p>The Japanese also bear person names like Chika, an Igbo name; Aina, a Yoruba name; Fumi, a Yoruba name; Ikimi, an Edo name; Yaru, a Borgu name; Sambo, a Fulani name; Maitama, a Hausa name; Adachi, a Nupe/Igala name; and so on.</p><p>Tutor-World also identified several more Japanese personal names that are either also personal names, names of common things, or names of towns in Nigeria, including: Azuka, Baba, Duro, Eijiro, Emiko, Femi, Fuji, Gobe, Goro, Haruna, Imoko, Iyamu, Kano, Kwashi, Mabuchi, Maduka, Mai, Obi, Oba, Ogi, Okada, Osahon, Sada, Ta-Daura (even Buhari’s adopted hometown made the list!), Waka, and Zoro.</p><p>Many people have pointed out that most words and names in a Black African language has a phonetic, and sometimes semantic, match in a Japanese word or name—and vice versa.&nbsp;</p><p>Take, for an example, the word Yoruba, the name of a major ethnic group in Nigeria. It also occurs in Japanese and can be translated as a “night horse,” according to the Sundaland Research Society, which says “yoru” means night and “ba” means horse in Japanese.</p><p>&nbsp;Several random words in Japanese can also have meanings, often unrelated to the original, in several African languages.</p><p>In spite of the uncanny congruence between the speech sounds of Black African languages and Japanese, there is no evidence that it’s anything more than a pleasantly giant phono-semantic accident.</p><p>It’s similar to the similarities in sound and rhythm between Plateau State languages and the Sino-Tibetan languages of China and its neighbors.&nbsp;</p><p>Many Plateau State names can pass for Mandarin names. A former Plateau journalist I used to be fond of (because of the exotic musicality of his name) is called Shok Jok. That name could pass for a Mandarin or Cantonese name.&nbsp;</p><p>There’s also a Professor Pam Dung Sha who teaches political science at the University of Jos. People who pay attention to politics are probably familiar with the late Senator Gyang Nyam Shom Pwajok. Names can’t get more Chinese than that!&nbsp;</p><p>How about Plateau names like Chuwang and Vongkong that Chinese people actually bear? The popular Plateau name Gyang sounds similar to a place in Tibet called Qungdo’gyang.</p><p>Similarly, many Plateau toponyms such as Qua'an Pan, Pankshin, Shendam, etc. sound distinctly Chinese. (This is also true of the toponyms and sometimes personal names in southern Kaduna and southern Adamawa.)</p><p>The first time I visited Jos in the late 1990s, I stayed at a hotel called Kufang Chindi International Hotel. I honestly thought it was a Chinese-owned hotel, more so that it had “international” in its name, but its name is actually native to Plateau!</p><p>I read about a Japanese linguist who was intrigued by the sounds of Plateau names and decided to map the glottochronology of the languages.&nbsp;</p><p>His lexicostatistical analysis found that less than 30 percent of the similar-sounding words between Plateau State languages and China’s Sino-Tibetan languages share similar meanings. Linguists call these kinds of similarities "accidental evidence."&nbsp;</p><p>In other words, the researcher found that there was no evidence of even a remote common origin for Chinese and the Plateau languages. It was merely a case of accidental similarities in sound.</p><p>Interestingly, Chinese-sounding Plateau languages and the Japanese language don’t belong to the major language families of their locations. They are both what linguists call language isolates.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why Structure and Interpretation of Computer Programs Matters (249 pts)]]></title>
            <link>https://people.eecs.berkeley.edu/~bh/sicp.html</link>
            <guid>40698906</guid>
            <pubDate>Sun, 16 Jun 2024 18:02:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://people.eecs.berkeley.edu/~bh/sicp.html">https://people.eecs.berkeley.edu/~bh/sicp.html</a>, See on <a href="https://news.ycombinator.com/item?id=40698906">Hacker News</a></p>
<div id="readability-page-1" class="page">

<cite>Brian Harvey<br>University of California, Berkeley</cite>

<p>In 2011, to celebrate the 150th anniversary of MIT, the <i>Boston Globe</i>
made a list of the most important innovations developed there.  They asked me
to explain the importance of <i>SICP,</i> and this is what I sent them:

</p><p>SICP was revolutionary in many different ways.  Most importantly, it
dramatically raised the bar for the intellectual content of introductory
computer science.  Before SICP, the first CS course was almost always
entirely filled with learning the details of some programming language.
SICP is about standing back from the details to learn big-picture ways
to think about the programming process.  It focused attention on the
central idea of <i>abstraction</i> -- finding general patterns from specific
problems and building software tools that embody each pattern.  It made
heavy use of the idea of <i>functions as data</i>, an idea that's hard to learn
initially, but immensely powerful once learned.  (This is the same idea,
in a different form, that makes freshman calculus so notoriously hard even
for students who've done well in earlier math classes.)  It fit into the
first CS course three different <i>programming paradigms</i> (functional,
object oriented, and declarative), when most other courses didn't even
really discuss even one paradigm.

</p><p>Another revolution was the choice of Scheme as the programming language.
To this day, most introductions to computer science use whatever is the
"hot" language of the moment: from Pascal to C to C++ to Java to Python.
Scheme has never been widely used in industry, but it's the perfect
language for an introduction to CS.  For one thing, it has a very simple,
uniform notation for everything.  Other languages have one notation for
variable assignment, another notation for conditional execution, two or
three more for looping, and yet another for function calls.  Courses that
teach those languages spend at least half their time just on learning the
notation.  In my SICP-based course at Berkeley, we spend the first hour
on notation and that's all we need; for the rest of the semester we're
learning ideas, not syntax.  Also, despite (or because of) its simplicity,
Scheme is a very versatile language, making it possible for us to examine
those three programming paradigms and, in particular, letting us see how
object oriented programming is implemented, so OOP languages don't seem
like magic to our students.  Scheme is a dialect of Lisp, so it's great
at handling functions as data, but it's a stripped-down version compared
to the ones more commonly used for professional programming, with a
minimum of bells and whistles.  It was very brave of Abelson and Sussman
to teach their introductory course in the best possible language <i>for
teaching</i>, paying no attention to complaints that all the jobs were in
some other language.  Once you learned the big ideas, they thought, and
this is my experience also, learning another programming language isn't
a big deal; it's a chore for a weekend.  I tell my students, "the language
in which you'll spend most of your working life hasn't been invented yet,
so we can't teach it to you.  Instead we have to give you the skills you
need to learn new languages as they appear."

</p><p>Finally, SICP was firmly optimistic about what a college freshman can be
expected to accomplish.  SICP students write interpreters for programming
languages, ordinarily considered more appropriate for juniors or seniors.
The text itself isn't easy reading; it has none of the sidebars and colored
boxes and interesting pictures that typify the modern textbook aimed at
students with low attention spans.  There are no redundant exercises; each
exercise teaches an important new idea.  It uses big words.  But it repays a
close reading; every sentence matters.

</p><p>Statistically, SICP-based courses have been a small minority.  But the book
has had an influence beyond that minority.  It inspired a number of later
textbooks whose authors consciously tried to live up to SICP's standard.  The
use of Scheme as a language for learners has been extended by others over a
range from middle school to graduate school.  Even the more mainstream courses
have become sensitive to the idea of programming paradigms, although most of
them concentrate on object oriented programming.  The idea that computer
science should be about ideas, not entirely about programming practice, has
since widened to include non-technical ideas about the context and social
implications of computing.

</p><p>SICP itself has had a longevity that's very unusual for introductory CS
textbooks.  Usually, a book lasts only as long as the language fad to which it
is attached.  SICP has been going strong for over 25 years and shows no sign
of going out of print.  Computing has changed enormously over that time, from
giant mainframe computers to personal computers to the Internet on cell
phones.  And yet the big ideas behind these changes remain the same, and they
are well captured by SICP.

</p><p>I've been teaching a SICP-based course since 1987.  The course has changed
incrementally over that time; we've added sections on parallelism, concurrency
control, user interface design, and the client/server paradigm.  But it's
still essentially the same course.  Every five years or so, someone on the
faculty suggests that our first course should use language X instead; each
time, I say "when someone writes the best computer science book in the world
using language X, that'll be fine" and so far the faculty have always voted to
stay with the SICP course.  We'll find out pretty soon whether the course can
survive my own retirement.

</p><ul><li>(Footnote: Nope.  Berkeley's new first course for majors uses Python,
with lecture notes that try to keep the ideas (and some of the text) of SICP.)
</li></ul>

<p>The discussion has been sharper recently because MIT underwent a major
redesign of their lower division EECS curriculum.  People outside MIT tend to
summarize that redesign as "MIT decided to switch to Python," but that's not a
perceptive description.  What MIT decided was to move from a curriculum
organized around topics (programming paradigms, then circuits, then signal
processing, then architecture) to a curriculum organized around applications
(let's build and program a robot; let's build and program a cell phone).
<i>Everything</i> about their courses had to be reorganized; the choice of
programming language was the least of those decisions.  Their new approach is
harder to teach; for one thing, each course requires a partnership of
Electrical Engineering faculty and Computer Science faculty.  Perhaps in time
the applications-first approach will spark a revolution as profound as the one
that followed SICP, but it hasn't happened yet.

</p><p>In my experience, relatively few students appreciate how much they're
learning in my course while they're in it.  But in surveys of all our
CS students, it turns out to be among the most popular courses in
retrospect, and I regularly get visits and emails from long-gone students
to tell me about how they're using in their work ideas that they thought
were impractical ivory-tower notions as students.  The invention of the
MapReduce software for data parallelism at Google, based on functional
programming ideas, has helped eliminate that ivory-tower reputation.

</p><address>
<a href="https://people.eecs.berkeley.edu/~bh/index.html"><code>www.cs.berkeley.edu/~bh</code></a>
</address>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[I've compared nearly all Rust crates.io crates to contents of their Git repos (143 pts)]]></title>
            <link>https://mastodon.social/@kornel/112626463128422583</link>
            <guid>40698536</guid>
            <pubDate>Sun, 16 Jun 2024 17:07:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mastodon.social/@kornel/112626463128422583">https://mastodon.social/@kornel/112626463128422583</a>, See on <a href="https://news.ycombinator.com/item?id=40698536">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Building SimCity: How to put the world in a machine (367 pts)]]></title>
            <link>https://mitpress.mit.edu/9780262547482/building-simcity/</link>
            <guid>40698442</guid>
            <pubDate>Sun, 16 Jun 2024 16:55:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mitpress.mit.edu/9780262547482/building-simcity/">https://mitpress.mit.edu/9780262547482/building-simcity/</a>, See on <a href="https://news.ycombinator.com/item?id=40698442">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">
        <p><a href="#content">Skip to content</a></p><header role="banner" id="masthead">
                <div>
            
        <p><a href="https://mitpress.mit.edu/" rel="home"><img width="386" height="610" src="https://dhjhkxawhe8q4.cloudfront.net/mit-press/wp-content/uploads/2022/05/20143118/logo.png" alt="MIT Press" decoding="async" fetchpriority="high" srcset="https://dhjhkxawhe8q4.cloudfront.net/mit-press/wp-content/uploads/2022/05/20143118/logo.png 386w, https://dhjhkxawhe8q4.cloudfront.net/mit-press/wp-content/uploads/2022/05/20143118/logo-190x300.png 190w, https://dhjhkxawhe8q4.cloudfront.net/mit-press/wp-content/uploads/2022/05/20143118/logo-309x488.png 309w, https://dhjhkxawhe8q4.cloudfront.net/mit-press/wp-content/uploads/2022/05/20143118/logo-127x200.png 127w" sizes="(max-width: 386px) 100vw, 386px"></a>
        </p>

        
        <div>

                
        <nav role="navigation" aria-label="main menu: press escape to close the menu">
            <div><ul id="primary-menu"><li><a href="https://mitpress.mit.edu/" role="link"><img src="https://dhjhkxawhe8q4.cloudfront.net/mit-press/wp-content/uploads/2021/11/26163520/mitp-colophon-white-black-bkg.gif" alt="MIT Press"></a></li><li id="menu-item-10853"><a href="#" aria-haspopup="true" aria-expanded="false">Books</a>
<ul>
	<li id="menu-item-77"><a href="#" aria-haspopup="true" aria-expanded="false">Column</a>
	<ul>
		<li id="menu-item-121"><a href="https://mitpress.mit.edu/books/subjects/">View all subjects</a></li>
		<li id="menu-item-11089"><a href="https://mitpress.mit.edu/new-releases/">New releases</a></li>
		<li id="menu-item-85"><a href="https://mitpress.mit.edu/catalogs/">Catalogs</a></li>
		<li id="menu-item-9600"><a href="https://mitpress.mit.edu/textbooks/">Textbooks</a></li>
		<li id="menu-item-118"><a href="https://mitpress.mit.edu/books/series/">Series</a></li>
		<li id="menu-item-13156"><a href="https://mitpress.mit.edu/awards/">Awards</a></li>
	</ul>
</li>
	<li id="menu-item-117"><a href="#" aria-haspopup="true" aria-expanded="false">Column</a>
	<ul>
		<li id="menu-item-76"><a href="https://mitpress.mit.edu/authors/">Authors</a></li>
		<li id="menu-item-9677"><a href="https://mitpress.mit.edu/publishers/">Distributed presses</a></li>
		<li id="menu-item-3490"><a target="_blank" rel="noopener" href="https://thereader.mitpress.mit.edu/">The MIT Press Reader</a></li>
		<li id="menu-item-3492"><a target="_blank" rel="noopener" href="https://newbooksnetwork.com/category/up-partners/mit-press-podcast">Podcasts</a></li>
		<li id="menu-item-12667"><a href="https://mitpress.mit.edu/collections/">Collections</a></li>
	</ul>
</li>
	<li id="menu-item-124"><a href="#" aria-haspopup="true" aria-expanded="false">Column</a>
	<ul>
		<li id="menu-item-3434"><a target="_blank" rel="noopener" href="https://direct.mit.edu/" aria-haspopup="true" aria-expanded="false">MIT Press Direct</a><p>MIT Press Direct is a distinctive collection of influential MIT Press books curated for scholars and libraries worldwide.</p>
		<ul>
			<li id="menu-item-3435"><a href="https://direct.mit.edu/">Learn more</a></li>
		</ul>
</li>
	</ul>
</li>
</ul>
</li>
<li id="menu-item-3494"><a href="#" aria-haspopup="true" aria-expanded="false">Journals</a>
<ul>
	<li id="menu-item-3495"><a href="#" aria-haspopup="true" aria-expanded="false">column</a>
	<ul>
		<li id="menu-item-3497"><a target="_blank" rel="noopener" href="https://direct.mit.edu/journals/pages/browse_by_topic">Journals all topics</a></li>
		<li id="menu-item-3498"><a target="_blank" rel="noopener" href="https://direct.mit.edu/journals/pages/browse_by_topic#econ">Economics</a></li>
		<li id="menu-item-3499"><a target="_blank" rel="noopener" href="https://direct.mit.edu/journals/pages/browse_by_topic#interpol">International Affairs, History, &amp; Political Science</a></li>
	</ul>
</li>
	<li id="menu-item-3496"><a href="#" aria-haspopup="true" aria-expanded="false">column</a>
	<ul>
		<li id="menu-item-3500"><a target="_blank" rel="noopener" href="https://direct.mit.edu/journals/pages/browse_by_topic#artshuman">Arts &amp; Humanities</a></li>
		<li id="menu-item-3501"><a target="_blank" rel="noopener" href="https://direct.mit.edu/journals/pages/browse_by_topic#scitech">Science &amp; Technology</a></li>
		<li id="menu-item-11045"><a target="_blank" rel="noopener" href="https://direct.mit.edu/journals/pages/open-access">Open access</a></li>
	</ul>
</li>
	<li id="menu-item-3503"><a href="#" aria-haspopup="true" aria-expanded="false">column</a>
	<ul>
		<li id="menu-item-3502"><a target="_blank" rel="noopener" href="https://direct.mit.edu/journals" aria-haspopup="true" aria-expanded="false">MIT Press journals</a><p>MIT Press began publishing journals in 1970 with the first volumes of <em>Linguistic Inquiry</em> and the <em>Journal of Interdisciplinary History</em>. Today we publish over 30 titles in the arts and humanities, social sciences, and science and technology.</p>
		<ul>
			<li id="menu-item-3504"><a target="_blank" rel="noopener" href="https://direct.mit.edu/journals">Learn more</a></li>
		</ul>
</li>
	</ul>
</li>
</ul>
</li>
<li id="menu-item-3430"><a aria-haspopup="true" aria-expanded="false">Open Access</a>
<ul>
	<li id="menu-item-3464"><a href="#" aria-haspopup="true" aria-expanded="false">column</a>
	<ul>
		<li id="menu-item-18875"><a href="https://mitpress.mit.edu/open-access-at-mit-press/">Open access at the MIT Press</a></li>
		<li id="menu-item-18876"><a href="https://mitpress.mit.edu/open-access-at-mit-press/initiatives/">Open access initiatives</a></li>
		<li id="menu-item-3467"><a target="_blank" rel="noopener" href="https://direct.mit.edu/books/pages/direct-to-open">Direct to Open</a></li>
		<li id="menu-item-18847"><a href="https://mitpress.mit.edu/open-access-at-mit-press/mit-open-publishing-services/">MIT Open Publishing Services</a></li>
	</ul>
</li>
	<li id="menu-item-3468"><a href="#" aria-haspopup="true" aria-expanded="false">column</a>
	<ul>
		<li id="menu-item-18878"><a href="https://mitpress.mit.edu/open-access-at-mit-press/books/">Open access books</a></li>
		<li id="menu-item-18877"><a href="https://mitpress.mit.edu/open-access-at-mit-press/journals/">Open access journals</a></li>
		<li id="menu-item-11873"><a href="https://mitpressonpubpub.mitpress.mit.edu/">MIT Press Open Access @ PubPub</a></li>
	</ul>
</li>
	<li id="menu-item-3470"><a href="#" aria-haspopup="true" aria-expanded="false">Column</a>
	<ul>
		<li id="menu-item-10527"><a href="https://mitpress.mit.edu/?page_id=9671" aria-haspopup="true" aria-expanded="false">Open access</a><p>The MIT Press has been a leader in open access book publishing for over two decades, beginning in 1995 with the publication of William Mitchell’s City of Bits, which appeared simultaneously in print and in a dynamic, open web edition.</p>
		<ul>
			<li id="menu-item-10445"><a href="https://mitpress.mit.edu/about-our-oa-program/">Learn more</a></li>
		</ul>
</li>
	</ul>
</li>
</ul>
</li>
<li id="menu-item-3431"><a href="#" aria-haspopup="true" aria-expanded="false">Info for</a>
<ul>
	<li id="menu-item-3474"><a href="#" aria-haspopup="true" aria-expanded="false">column</a>
	<ul>
		<li id="menu-item-3482"><a href="https://mitpress.mit.edu/for-authors/">Current authors</a></li>
		<li id="menu-item-3478"><a href="https://mitpress.mit.edu/prospective-authors/">Prospective authors</a></li>
		<li id="menu-item-9771"><a href="https://mitpress.mit.edu/instructors/">Instructors</a></li>
	</ul>
</li>
	<li id="menu-item-3476"><a href="#" aria-haspopup="true" aria-expanded="false">column</a>
	<ul>
		<li id="menu-item-9665"><a href="https://mitpress.mit.edu/media-inquiries/">Media inquiries</a></li>
		<li id="menu-item-9664"><a href="https://mitpress.mit.edu/booksellers/">Booksellers</a></li>
		<li id="menu-item-3609"><a href="https://mitpress.mit.edu/rights-permissions/">Rights and permissions</a></li>
	</ul>
</li>
	<li id="menu-item-3475"><a href="#" aria-haspopup="true" aria-expanded="false">column</a>
	<ul>
		<li id="menu-item-3485"><a href="#" aria-haspopup="true" aria-expanded="false">Resources</a><p>Collaborating with authors, instructors, booksellers, librarians, and the media is at the heart of what we do as a scholarly publisher. If you can’t find the resource you need here, visit our contact page to get in touch.</p>
		<ul>
			<li id="menu-item-10443"><a href="https://mitpress.mit.edu/for-authors/">Learn more</a></li>
		</ul>
</li>
	</ul>
</li>
</ul>
</li>
<li id="menu-item-19570"><a href="https://mitpress.mit.edu/give-to-the-mit-press/">Give</a></li>
<li id="menu-item-10854"><a href="#" aria-haspopup="true" aria-expanded="false">About</a>
<ul>
	<li id="menu-item-10441"><a href="#" aria-haspopup="true" aria-expanded="false">Column</a>
	<ul>
		<li id="menu-item-11348"><a href="https://mitpress.mit.edu/about/">About</a></li>
		<li id="menu-item-10327"><a href="https://mitpress.mit.edu/jobs/">Jobs</a></li>
		<li id="menu-item-10328"><a href="https://mitpress.mit.edu/internships-paid-internships-books-journals/">Internships</a></li>
		<li id="menu-item-10324"><a href="https://mitpress.mit.edu/mit-press-editorial-board/">MIT Press Editorial Board</a></li>
		<li id="menu-item-10325"><a href="https://mitpress.mit.edu/mit-press-management-board/">MIT Press Management Board</a></li>
		<li id="menu-item-14905"><a href="https://mitpress.mit.edu/collections/our-mit-story/">Our MIT story</a></li>
	</ul>
</li>
	<li id="menu-item-10329"><a href="#" aria-haspopup="true" aria-expanded="false">Column</a>
	<ul>
		<li id="menu-item-10330"><a href="https://mitpress.mit.edu/catalogs/">Catalogs</a></li>
		<li id="menu-item-10331"><a href="https://mitpress.mit.edu/?page_id=105">News</a></li>
		<li id="menu-item-9516"><a href="https://mitpress.mit.edu/events/">Events</a></li>
		<li id="menu-item-10332"><a href="https://mitpress.mit.edu/conferences/">Conferences</a></li>
		<li id="menu-item-10333"><a href="http://mitpressbookstore.mit.edu/">Bookstore</a></li>
	</ul>
</li>
	<li id="menu-item-10440"><a href="#" aria-haspopup="true" aria-expanded="false">Column</a>
	<ul>
		<li id="menu-item-10334"><a href="#" aria-haspopup="true" aria-expanded="false">The MIT Press</a><p>Established in 1962, the MIT Press is one of the largest and most distinguished university presses in the world and a leading publisher of books and journals at the intersection of science, technology, art, social science, and design.</p>
		<ul>
			<li id="menu-item-10442"><a href="https://mitpress.mit.edu/about">Learn more</a></li>
		</ul>
</li>
	</ul>
</li>
</ul>
</li>
<li id="menu-item-11708"><a href="https://mitpress.mit.edu/contact-us/">Contact Us</a></li>
</ul></div>        </nav>

                        
        
                </div>

                </div>
        
        

        
                    
        
            </header>
    
    <div id="content">
        
    <main id="main">

        <div id="product-details-32" data-widget-params="{&quot;include_price&quot;:1}" data-ajax-url="https://mitpress.mit.edu/wp-admin/admin-ajax.php">
                <ul>
                                                                        <li>
                                <a href="#tab-1">
                                    Description                                </a>
                            </li>
                                                                                                                                            <li>
                                <a href="#tab-3">Author(s)</a>
                            </li>
                                                                                                <li>
                                <a href="#tab-4">Praise</a>
                            </li>
                                                                                                                                </ul>
                                                            
                                                                                                                    
                                                                                
                                                                                    </div>

    </main><!-- #main -->


</div><!-- #content -->



    

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Edinburgh, Scotland makes it illegal to advertise SUVs (119 pts)]]></title>
            <link>https://www.washingtonpost.com/climate-solutions/2024/06/15/fossil-fuel-advertising-bans-edinburgh/</link>
            <guid>40698412</guid>
            <pubDate>Sun, 16 Jun 2024 16:50:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/climate-solutions/2024/06/15/fossil-fuel-advertising-bans-edinburgh/">https://www.washingtonpost.com/climate-solutions/2024/06/15/fossil-fuel-advertising-bans-edinburgh/</a>, See on <a href="https://news.ycombinator.com/item?id=40698412">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="C2FKBZ64ANAXDEZ4Q4FRVJSIOU" data-el="text" dir="null">EDINBURGH — Last month this Scottish city — filled with medieval spires and shadowed by the looming castle on the hill said to have inspired the Harry Potter books — made a startlingly modern decision. Edinburgh’s city council voted to <a href="https://democracy.edinburgh.gov.uk/documents/s70730/9.1%20Policy%20on%20Advertising%20and%20Sponsorship%20-%20Proposed%20Amendments.pdf" target="_blank">ban fossil fuel advertisements</a> on city property, undermining the ability of not only <a href="https://www.washingtonpost.com/politics/2022/06/13/house-democrats-probe-pr-industry-role-advertising-big-oil/?itid=lk_inline_manual_2" target="_blank">oil companies</a>, but also car manufacturers, <a href="https://www.washingtonpost.com/climate-solutions/2024/02/02/sustainable-aviation-fuel-future/?itid=lk_inline_manual_2" target="_blank">airlines</a> and <a href="https://www.washingtonpost.com/travel/2022/09/28/green-cruises-environment/?itid=lk_inline_manual_2" target="_blank">cruise ships</a>, to promote their products. The ban targeted arms manufacturers as well.</p></div><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="OQM4JNVRWFAPJD2JQWJTA3RBW4" data-el="text" dir="null">Edinburgh is not alone. <a href="https://www.euronews.com/green/2021/05/20/amsterdam-becomes-first-city-in-the-world-to-ban-this-type-of-advert" target="_blank">Amsterdam</a> and <a href="https://www.adnews.com.au/news/city-of-sydney-votes-to-end-fossil-fuel-advertising" target="_blank">Sydney</a> have cracked down on advertisements for fossil fuels and high-emissions products. France also limited the promotion of coal, gas and hydrogen made from fossil fuels. Even the United Nations Secretary General, António Guterres, has joined in, endorsing a ban on fossil fuel ads this month in a speech in New York this month: “Stop the Mad Men from fueling the madness.”</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="LJIYXFY3EVCDLPP4BNACCOPQCM" data-el="text" dir="null">“There’s a moment happening here,” said Ben Parker, the Edinburgh city councilor who spearheaded the ban and a member of the Scottish Green Party. “It’s a way of saying fossil fuel companies and arms manufacturers are not welcome in our city.”</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="BIJKKZVQFNAXTECEJMO4TRTVCM" data-el="text" dir="null">A local ban on fossil fuel advertisements might seem minor at a time when carbon emissions — and <a href="https://www.washingtonpost.com/weather/2024/06/05/global-temperatures-1-5-celsius-record-year/?itid=lk_inline_manual_8" target="_blank">temperatures</a> — continue to march upward. But there is evidence that sweeping advertising bans, such as those targeting tobacco products in many countries, can change how consumers view and purchase certain products. The question is whether the new fossil fuel advertising bans are substantial enough to have an impact.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="N5OGPPP4DRC57AOZICGCHWXQUI" data-el="text" dir="null">“A lot of these bans that are being put forward are at the municipal and city level,” said Timothy Dewhirst, professor of marketing and consumer studies at the University of Guelph. “And partial bans have proven to be ineffective.”</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="2MX33FQJRBF67LDBQQQPBOT5HY" data-el="text" dir="null">Fossil fuel producers counter that they are focused on addressing climate change. “Our industry is focused on continuing to produce affordable, reliable energy while tackling the climate challenge, and any allegations to the contrary are false,” Scott Lauermann, a spokesperson for the American Petroleum Institute, said in an email.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="GMM7ZG63PZHHRL5A5OG2W25KTA" data-el="text" dir="null">Proponents of advertising bans seek to accomplish<b> </b>two goals: convince people not to use<b> </b>the product, and lower the reputation of an industry or company. Given how embedded fossil fuels are in modern society, some experts see the latter goal as more achievable.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="Z2MSLJH52FDKRETQAJDF5FXAP4" data-el="text" dir="null">At the individual level, seeing fewer advertisements for gas-guzzling cars or international trips could make people less likely to opt for those products. “What you are doing is reducing the amount of consumption that is coming from those advertisements,” said Andrew Simms, co-director of the New Weather Institute and a campaigner for fossil fuel ad bans.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="PR5KYC5F2VHPBMJ5IO65D4J2JI" data-el="text" dir="null">There’s <a href="https://www.sciencedirect.com/science/article/abs/pii/S0167629608000155?via%3Dihub" target="_blank">evidence</a> that this works. Starting in the 1970s, the constant drumbeat of new findings on the health effects of cigarettes triggered a lengthy process where nations restricted advertisements for cigarettes on TV, the radio and in public spaces. In the United States, bans began with cigarette advertising on television, and grew to covering the sponsorship of events, public transit ads and more.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="7BNZVWICBFARJLY3XWD3MTUDNM" data-el="text" dir="null">Today, dozens of countries — including the <a href="https://www.fda.gov/tobacco-products/products-guidance-regulations/advertising-and-promotion" target="_blank">United States</a>,<b> </b><a href="https://www.tobaccocontrollaws.org/legislation/china" target="_blank">China</a> and the <a href="https://health.ec.europa.eu/tobacco/ban-cross-border-tobacco-advertising-and-sponsorship_en" target="_blank">European Union</a><b> — </b>have bans, restrictions or other limitations on selling tobacco products. There is even an <a href="https://fctc.who.int/who-fctc/overview" target="_blank">international treaty</a> under the World Health Organization, adopted in 2003,<b> </b>that urges all countries to enact bans that target all forms of tobacco advertising. There are currently 168 signatories on the treaty; the<b> </b>United States has signed on the treaty but not ratified it.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="JOY3PX4PRZGEHEGXVR4YQMOPKI" data-el="text" dir="null">Research shows that those bans that block TV, radio, print and in-store advertising — as well as sponsorship of events — are most effective at stopping smoking, particularly among young people who have yet to start smoking in the first place. As of 2017, full bans were implemented in less than 20 percent of countries worldwide.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="DVWP7M35TJHP3AL725OTGVECA4" data-el="text" dir="null">But bans that are partial, such as those that only target TV commercials, are less effective. Companies may just reallocate their advertising budgets to other media, or shift to sponsoring sports teams and similar.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="4QV5CMPSZRBGFGXAYE5DTBPUXI" data-el="text" dir="null">“It’s like a tube of toothpaste,” said David Hammond, a professor of public health at the University of Waterloo. “If you press in just one spot, it just squeezes to another part of the tube.”</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="I25TBOYU2VB4XGZL6BF3C7COGQ" data-el="text" dir="null">Fossil fuels also present a particular challenge: While an individual can choose not to smoke, it is almost impossible to disconnect from an electricity grid that runs partly on fossil fuels. Ad bans can target some discretionary spending, like cruise ships and air travel, but oil, gas and coal are deeply embedded in everyday life.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="II7OMBGFZ5H6TMYA5PJZHESDRQ" data-el="text" dir="null">Parker, the city councilor, says that there are still reasons to target sources of global warming. “We protect people from things like gambling, alcohol, and tobacco,” he said. “Climate change is a different type of harm, but it’s still a harm.”</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="4NBEDPX22FCCTLYGNBNSA2553U" data-el="text" dir="null">Meanwhile, some advocates and scholars emphasize that advertising allows companies to shape their public image, which can protect them from stricter regulation.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="EI4ESXJ4LFAT5K36RPXITCKRTI" data-el="text" dir="null">Researchers say that fossil fuel companies use ads to maintain their “social license to operate” — a shorthand for a corporation’s ability to be seen as acceptable by society and policymakers. By showing ads connecting their operations to clean energy, jobs, or energy security — and sponsoring popular events — fossil fuel companies can bolster their reputations in the public sphere.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="2V2LR5FUEZCLXK5QJ6MRRR2UHU" data-el="text" dir="null">“Political scientists refer to fossil fuel advertising as a form of ‘outside’ lobbying,” said Geoffrey Supran, associate professor of environmental science and policy at the University of Miami. “It complements lobbying inside the Hill and in state governments and so on.”</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="R7TNUGIUYRA5VN4CEXOHFHXQXM" data-el="text" dir="null">Earlier this month, for example, the fossil fuel company Chevron sponsored the annual Congressional Baseball Game — which was interrupted by <a href="https://www.washingtonpost.com/dc-md-va/2024/06/12/congressional-baseball-game-arrests-climate-activists/?itid=lk_inline_manual_32" target="_blank">climate protesters</a>.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="ZYTXPN4XDBBKRBK7GWJBLHBSLI" data-el="text" dir="null">Robert Brulle, a visiting professor of environment and society at Brown University, says that advertising allows fossil fuel companies to help define the solutions to climate change — such as things like carbon capture from oil and gas plants. “They’re saying ‘We need to be part of the solution, we have the technical know-how,’” Brulle explained.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="3ETU2DQF3FCQXDVG64OPJTE5ZM" data-el="text" dir="null">In one <a href="https://link.springer.com/article/10.1007/s10584-019-02582-8" target="_blank">study</a> by Brulle and his co-authors, the researchers found that fossil fuel companies increased their advertising spending in response to congressional attention to and media coverage of climate change.</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="LF53Y2HKRVA7BHQEM4GUHLQHLY" data-el="text" dir="null">Even if there were substantial advertising bans instituted for fossil fuels, it would be difficult to measure how such bans affect a company’s reputation. But some experts believe that it could make a difference. “It would be monumental,” said Supran. “It could loosen the stranglehold of the industry in a way that would politically and financially open the door to lower carbon technologies.”</p><p data-testid="drop-cap-letter" data-apitype="text" data-contentid="YQFY2ZL6GFDE5BR6LZC7SGS4BE" data-el="text" dir="null">For now, ad bans are still only instituted in a small number of cities and nations worldwide — in a manner not so different from how tobacco advertising bans began. “It happened incrementally,” said Hammond. “It was a multi-decade process.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Packaging Swift Apps for Alpine Linux (108 pts)]]></title>
            <link>https://mko.re/blog/swift-alpine-packaging/</link>
            <guid>40697992</guid>
            <pubDate>Sun, 16 Jun 2024 15:59:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mko.re/blog/swift-alpine-packaging/">https://mko.re/blog/swift-alpine-packaging/</a>, See on <a href="https://news.ycombinator.com/item?id=40697992">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><header><img src="https://mko.re/blog/swift-alpine-packaging/hero.jpg"><a href="https://mko.re/blog/">BLOG</a></header><section><p>While trying to build my <a href="https://github.com/remko/age-plugin-se">Age Apple Secure Enclave
plugin</a>, a small Swift CLI app, on
<a href="https://www.alpinelinux.org/">Alpine Linux</a>, I realized that the Swift
toolchain doesn’t run on Alpine Linux. The upcoming Swift 6 will support
(cross-)compilation to a static (musl-based) Linux target, but I suspect an
Alpine Linux version of Swift itself isn’t going to land soon. So, I
explored some alternatives for getting my Swift app on Alpine.</p><p>You can find all the scripts used in this post in <a href="https://github.com/remko/age-plugin-se/tree/main/Scripts/alpine">the <code>age-plugin-se</code> repository</a>.</p><h2 id="option-1-running-a-pre-built-binary">Option 1: Running a pre-built binary</h2><p>A first option is to use a pre-built dynamically linked binary compiled by
Swift on e.g. Debian, and get it to run on Alpine.</p><p>Installing <a href="https://pkgs.alpinelinux.org/packages?name=gcompat"><code>gcompat</code></a> is
usually the easiest way of getting glibc binaries to run
Alpine. Unfortunately, this doesn’t seem to cut it: the binary crashes at load time (most likely due to incompatibilities of libraries such as libstdc++):</p><pre><code>Error relocating age-plugin-se: fts_open: symbol not found
Error relocating age-plugin-se: fts_read: symbol not found
Error relocating age-plugin-se: fts_close: symbol not found
Error relocating age-plugin-se: fts_set: symbol not found
</code></pre><p>The second recommended workaround is installing a glibc-based distribution in a
chroot, and set up the loader using symlinks, as described <a href="https://wiki.alpinelinux.org/wiki/Running_glibc_programs">in this
article</a>. After
setting up a Debian chroot this way, the pre-built binaries generated by Swift
on Debian work as expected. However, having to go through this setup on every
installation just to get a simple app working is still a nuisance.</p><h2 id="option-2-packaging-a-binary-with-loader--libraries">Option 2: Packaging a binary with loader &amp; libraries</h2><p>A second option is to create a package containing the
(glibc-based) Swift-compiled binary, bundled with all its dynamic library
dependencies, including the glibc <code>ld</code> dynamic linker used to load the binary.</p><p>For <code>age-plugin-se</code>, I run the entire procedure from <a href="https://github.com/remko/age-plugin-se/blob/main/Scripts/alpine/chroot-build.sh">a shell script</a> running on Alpine. The script has following
steps:</p><ol><li><p>Create a Debian chroot (using <a href="https://wiki.debian.org/Debootstrap">debootstrap</a>)</p></li><li><p>Install <a href="https://www.swift.org/download/">the Swift compiler</a> (and all its
dependencies) in the chroot</p></li><li><p>Copy the sources of the Swift app into the chroot</p></li><li><p>Use Swift inside the chroot to compile the sources into a (glibc-based) executable.</p><p>This executable is loaded using the glibc <code>ld</code> loader, which will be bundled at a
package-specific private location (<code>/usr/lib/my-package/ld-....</code>).
The loader is always hard-coded as an absolute path into an
executable, so you need to tell the Swift compiler the full path where
the custom loader will be located after installation. This is done using the
<code>--dynamic-linker</code> linker flag.</p><p>All the dynamic library dependencies will also be included in the package.
To make the linker find these (and not pick up the system ones if they exist),
you also have to set the run-time search path
of the executable to a relative path where these libraries will be shipped.
This is done using the <code>-rpath</code> linker flag. Since the executable will be installed in
<code>/usr/bin</code>, the relative path where the dynamic libraries will end up will
be <code>../lib/my-package</code>.</p><p>The full Swift compiler invocation looks like:</p><pre><code>swift build -c release --static-swift-stdlib \
  -Xlinker --dynamic-linker=/usr/lib/my-package/ld-linux-x86-64.so.2 \
  -Xlinker -rpath='$ORIGIN'/../lib/my-package
</code></pre></li><li><p>Copy all files from the chroot dir to the system (or package) dir:
the resulting executable is copied to <code>/usr/bin</code>, and the dynamic linker
(<code>ld-linux-x86-64.so.2</code> for <code>x86-64</code> platforms, <code>ld-linux-aarch64.so.1</code> for
<code>aarch64</code> platforms) and all dynamic libraries (<code>libc.so.6</code>,
<code>libstdc++.so.6</code>, <code>libgcc_s.so.1</code>, <code>libm.so.6</code>) to <code>/usr/lib/my-package</code>.</p></li></ol><p>Note that, because the script runs commands in a chroot, it has to
be run with root privileges.</p><p>The <a href="https://github.com/remko/age-plugin-se/blob/main/Scripts/alpine/chroot-build.sh">chroot build script</a> can finally be integrated into <a href="https://github.com/remko/age-plugin-se/blob/main/Scripts/alpine/APKBUILD">an <code>APKBUILD</code> script</a> to create a self-contained Alpine package:</p><pre><code>$ abuild -r
&gt;&gt;&gt; age-plugin-se: Building main/age-plugin-se 0.1.3-r0 (using abuild 3.13.0-r3) 
...
&gt;&gt;&gt; age-plugin-se: Build complete

$ ls ~/packages/main/aarch64/*.apk
age-plugin-se-0.1.3-r0.apk
age-plugin-se-doc-0.1.3-r0.apk
</code></pre><p>The resulting package can then be installed on a clean Alpine system using <code>apk add</code>, without any other steps or requirements:</p><pre><code>$ doas apk add ./age-plugin-se-0.1.3-r0.aarch64.apk 
(1/1) Installing age-plugin-se (0.1.3-r0)
OK: 237 MiB in 72 packages

$ age-plugin-se --version
v0.1.3
</code></pre><h2 id="option-3-cross-compiling-a-static-linux-binary">Option 3: (Cross-)Compiling a static Linux binary</h2><p>Swift 6 will support compiling a fully static Linux binary, using
<a href="https://www.swift.org/documentation/articles/static-linux-getting-started.html">musl</a>
as its standard C library. The complete instructions for creating a static
Linux build of your app can be found <a href="https://www.swift.org/documentation/articles/static-linux-getting-started.html">on the Swift.org
page</a>.</p><p>Since you can even create Linux binaries using the macOS toolchain, and since
there currently only is a Swift 6 build for macOS, I adapted the <code>age-plugin-se</code>
packaging procedure to create a static Linux binary on macOS for all architectures.</p><p>Although the resulting static Linux binaries run fine on Alpine Linux, I wanted
to have a cleaner way of installing the package instead of just extracting the
package tarball somewhere. Since I’m building the binaries on macOS, and
Alpine’s <a href="https://wiki.alpinelinux.org/wiki/Abuild_and_Helpers"><code>abuild</code></a>
package build system doesn’t run on macOS, I created <a href="https://github.com/remko/age-plugin-se/blob/main/Scripts/alpine/dir2apk.go">a Go script to convert
the binary release tarball into an <code>.apk</code>
file</a>.
This script implements the <a href="https://wiki.alpinelinux.org/wiki/Apk_spec">APK package
specification</a> in pure Go, and
creates and signs an <code>.apk</code> without relying on external tools (such as abuild).
This script is integrated into the GitHub workflow to package a binary release
of <code>age-plugin-se</code>.</p><h2 id="package-size">Package size</h2><p>Here’s a comparison of the package sizes of the above approaches:</p><table><thead><tr><th>Package</th><th>OS</th><th>Size</th></tr></thead><tbody><tr><td>Dynamic</td><td>macOS</td><td>252 KiB</td></tr><tr><td>Dynamic</td><td>Linux</td><td>1.2 MiB</td></tr><tr><td>Dynamic + static Swift stdlib</td><td>Linux</td><td>43.4 MiB</td></tr><tr><td>Dynamic + static Swift stdlib + dylibs</td><td>Linux</td><td>48.1 MiB</td></tr><tr><td>Static</td><td>Linux</td><td>100.4 MiB</td></tr></tbody></table><p>The minimal baseline package is the dynamically linked binary on macOS, which
comes in at 252 KiB. This binary links dynamically against the Swift standard
library and all required system libraries.</p><p>Linking dynamically on Linux yields a bigger binary (1.2 MiB). This is because
on Linux, <code>age-plugin-se</code> compiles against <a href="https://github.com/apple/swift-crypto">Swift Crypto</a>, a drop-in replacement for the <a href="https://developer.apple.com/documentation/cryptokit">CryptoKit</a> framework on macOS. Swift Crypto uses <a href="https://boringssl.googlesource.com/boringssl/">BoringSSL</a>, which is linked statically into the binary (contrary to CryptoKit on macOS, which is a dynamic system library). This causes the binary to be
bigger, although the size increase is still limited in absolute numbers.</p><p>Using dynamic linking on Linux would require the Swift standard library to be
present on the target system. Since Swift isn’t always available on
Linux distributions (including Alpine), this isn’t a practical solution.
By statically linking the Swift standard library into the binary (using
<code>--static-swift-stdlib</code>), the dependency on Swift can be removed. Doing this
makes the binary a lot larger, though: 43.4 MiB.</p><p>The binary with static Swift standard library still depends on system libraries
(libc, libstdc++, libm, …). As explained above, these aren’t available on
Alpine Linux, so we package these together with the binary. Doing this adds a few
megabytes to the package, resulting in a total of 48.1 MiB.</p><p>Finally, creating a statically linked Swift binary, which avoids any dependency
on system libraries, results in more than double the size of the packaged
dynamic binary with all its deendencies: 100.4 MiB. I’m not sure why the package
is so much larger (maybe some link-time optimizations and dead-code elimination that
isn’t done), and I don’t think there’s a good reason in theory for it to be
this way. I hope this is something that will be improved in later releases.</p></section></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Raspberry Pi 5 Is No Match for a Tini-Mini-Micro PC (405 pts)]]></title>
            <link>https://louwrentius.com/the-raspberry-pi-5-is-no-match-for-a-tini-mini-micro-pc.html</link>
            <guid>40697831</guid>
            <pubDate>Sun, 16 Jun 2024 15:38:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://louwrentius.com/the-raspberry-pi-5-is-no-match-for-a-tini-mini-micro-pc.html">https://louwrentius.com/the-raspberry-pi-5-is-no-match-for-a-tini-mini-micro-pc.html</a>, See on <a href="https://news.ycombinator.com/item?id=40697831">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              <p>I've always been fond of the idea of the Raspberry Pi. An energy efficient, small, cheap but capable computer. An ideal home server. Until the Pi 4, the Pi was not that capable, and only with the relatively recent Pi 5 (fall 2023) do I feel the Pi is OK performance wise, although still hampered by SD card performance<sup id="fnref:good"><a href="#fn:good">1</a></sup>. And the Pi isn't that cheap either.</p>
<p>The Pi 5 can be fitted with an NVME SSD, but for me it's too little, too late.
Because I feel there is a type of computer on the market, that is much more compelling than the Pi. </p>
<p>I'm talking about the <a href="https://www.servethehome.com/introducing-project-tinyminimicro-home-lab-revolution/">tinyminimicro</a> home lab 'revolution' started by
<a href="https://www.servethehome.com/">servethehome.com</a> about four years ago (2020).</p>
<p><img alt="mini pc" src="https://louwrentius.com/static/images/tmm/tmm01.webp"></p>
<p><em>A 1L mini PC (Elitedesk 705 G4) with a Raspberry Pi 5 on top</em></p>
<p>During the pandemic, the Raspberry Pi was in short supply and people started looking for alternatives. The people at servethehome realised that these small enterprise desktop PCs could be a good option. Dell (micro), Lenovo (tiny) and HP (mini) all make these small desktop PCs, which are also known as 1L (one liter) PCs.</p>
<p>These Mini PC are not cheap<sup id="fnref:cheap"><a href="#fn:cheap">2</a></sup> when bought new, but older models are sold at a very steep discount as enterprises offload old models by the thousands on the second hand market (through intermediates).</p>
<p>Although these computers are often several years old, they are still much faster than a Raspberry Pi (including the Pi 5) and can hold more RAM.</p>
<p>I decided to buy two HP Elitedesk Mini PCs to try them out, one based on AMD and the other based on AMD.</p>
<h3>The Hardware</h3>
<table>
<thead>
<tr>
<th></th>
<th><a href="https://support.hp.com/th-en/document/c05371240">Elitedesk Mini G3 800</a></th>
<th><a href="https://support.hp.com/us-en/document/c06101574">Elitedesk Mini G4 705</a></th>
</tr>
</thead>
<tbody>
<tr>
<td>CPU</td>
<td>Intel i5-6500 (65W)</td>
<td>AMD Ryzen 3 PRO 2200GE (35W)</td>
</tr>
<tr>
<td>RAM</td>
<td>16 GB (max 32 GB)</td>
<td>16 GB (max 32 GB)</td>
</tr>
<tr>
<td>HDD</td>
<td>250 GB (SSD)</td>
<td>250 GB (NVME)</td>
</tr>
<tr>
<td>Network</td>
<td>1Gb (Intel)</td>
<td>1Gb (Realtek)</td>
</tr>
<tr>
<td>WiFi</td>
<td>Not installed</td>
<td>Not installed</td>
</tr>
<tr>
<td>Display</td>
<td>2 x DP, 1 x VGA</td>
<td>3 x DP</td>
</tr>
<tr>
<td>Remote management</td>
<td>Yes</td>
<td>No</td>
</tr>
<tr>
<td>Idle power</td>
<td>4 W</td>
<td>10 W</td>
</tr>
<tr>
<td>Price</td>
<td>€160</td>
<td>€115</td>
</tr>
</tbody>
</table>
<p>The AMD-based system is cheaper, but you 'pay' in higher idle power usage. In absolute terms 10 watt is still decent, but the Intel model directly competes with the Pi 5 on idle power consumption. </p>
<p><a href="https://louwrentius.com/static/images/tmm/tmm03.webp"><img alt="inside the mini pic" src="https://louwrentius.com/static/images/tmm/tmm03_small.webp"></a></p>
<p><em>Elitedesk 705 left, Elitedesk 800 right (click to enlarge)</em></p>
<p>Regarding display output, these devices have two fixed displayport outputs, but there is one port that is configurable. It can be displayport, VGA or HDMI. Depending on the supplier you may be able to configure this option, or you can buy them separately for €15-€25 online.</p>
<p><a href="https://louwrentius.com/static/images/tmm/HPEliteDesk800G3DesktopMini.pdf"><img alt="back800" src="https://louwrentius.com/static/images/tmm/tmm06.webp"></a>
<a href="https://louwrentius.com/static/images/tmm/HPEliteDesk705G4DesktopMini.pdf"><img alt="back705" src="https://louwrentius.com/static/images/tmm/tmm05.webp"></a>
<em>Click on image for official specs in PDF format</em></p>
<p>Both models seem to be equipped with socketed CPUs. Although options for this formfactor are limited, it's possible to upgrade.</p>
<h3>Comparing cost with the Pi 5</h3>
<p>The Raspberry Pi 5 with (max) 8 GB of RAM costs ~91 Euro, almost exactly the same price as the AMD-based mini PC<sup id="fnref:psu"><a href="#fn:psu">3</a></sup> in its base configuration (8GB RAM). Yet, with the Pi, you still need:</p>
<ol>
<li>power supply (€13)</li>
<li>case (€11)</li>
<li>SD card or NVME SSD (€10-€45)</li>
<li>NVME hat (€15) (optional but would be more comparable)</li>
</ol>
<p>It's true that I'm comparing a new computer to a second hand device, and you can decide if that matters in this case. With a complete Pi 5 at around €160 including taxes and shipping, the AMD-based 1L PC is clearly the cheaper and still more capable option.</p>
<h3>Comparing performance with the Pi 5</h3>
<p>The first two rows in this table show the Geekbench 6 score of the Intel and AMD mini PCs I've bought for evaluation. I've added the benchmark results of some other computers I've access to, just to provide some context.</p>
<table>
<thead>
<tr>
<th>CPU</th>
<th>Single-core</th>
<th>Multi-core</th>
</tr>
</thead>
<tbody>
<tr>
<td>AMD Ryzen 3 PRO 2200GE (32W)</td>
<td>1148</td>
<td>3343</td>
</tr>
<tr>
<td>Intel i5-6500 (65W)</td>
<td>1307</td>
<td>3702</td>
</tr>
<tr>
<td>Mac Mini M2</td>
<td>2677</td>
<td>9984</td>
</tr>
<tr>
<td>Mac Mini i3-8100B</td>
<td>1250</td>
<td>3824</td>
</tr>
<tr>
<td>HP Microserver Gen8 Xeon E3-1200v2</td>
<td>744</td>
<td>2595</td>
</tr>
<tr>
<td>Raspberry Pi 5</td>
<td>806</td>
<td>1861</td>
</tr>
<tr>
<td>Intel i9-13900k</td>
<td>2938</td>
<td>21413</td>
</tr>
<tr>
<td>Intel E5-2680 v2</td>
<td>558</td>
<td>5859</td>
</tr>
</tbody>
</table>
<p>Sure, these mini PCs won't come close to modern hardware like the Apple M2 or the intel i9. But if we look at the performance of the mini PCs we can observe that:</p>
<ol>
<li>The Intel i5-6500T CPU is 13% faster in single-core than the AMD Ryzen 3 PRO</li>
<li>Both the Intel and AMD processors are 42% - 62% faster than the Pi 5 regarding single-core performance.</li>
</ol>
<h3>Storage (performance)</h3>
<p>If there's one thing that really holds the Pi back, it's the SD card storage.
If you buy a decent SD card (A1/A2) that doesn't have terrible random IOPs performance, you realise that you can get a SATA or NVME SSD for almost the same price that has more capacity and much better (random) IO performance.</p>
<p>With the Pi 5, NVME SSD storage isn't standard and requires an extra hat. I feel that the missing integrated NVME storage option for the Pi 5 is a missed opportunity that - in my view - hurts the Pi 5.</p>
<p>Now in contrast, the Intel-based mini PC came with a SATA SSD in a special mounting bracket. That bracket also contained a small fan(1) to keep the underlying NVME storage (not present) cooled. </p>
<p><a href="https://louwrentius.com/static/images/tmm/tmm04.webp"><img alt="inside the mini pic" src="https://louwrentius.com/static/images/tmm/tmm04_small.webp"></a></p>
<p><em>There is a fan under the SATA SSD (click to enlarge)</em></p>
<p>The AMD-based mini PC was equipped with an NVME SSD and was not equipped with the SSD mounting bracket. The low price must come from somewhere...</p>
<p>However, both systems have support for SATA SSD storage, an 80mm NVME SSD and a small 2230 slot for a WiFi card. There seems no room on the 705 G4 to put in a small SSD, but there are adapters available that convert the WiFi slot to a slot usable for an extra NVME SSD, which might be an option for the 800 G3.</p>
<h3>Noice levels (subjective)</h3>
<p>Both systems are barely audible at idle, but you will notice them (if you sensitive to that sort of thing). The AMD system seems to become quite loud under full load. The Intel system also became loud under full load, but much more like a Mac Mini: the noise is less loud and more tolerable in my view.</p>
<h2>Idle power consumption</h2>
<h3>Elitedesk 800 (Intel)</h3>
<p>I can get the Intel-based Elitedesk 800 G3 to 3.5 watt at idle. Let that sink in for a moment. That's about the same power draw as the Raspberry Pi 5 at idle!</p>
<p>Just installing Debian 12 instead of Windows 10 makes the idle power consumption drop from 10-11 watt to around 7 watt. </p>
<p>Then on Debian, you:</p>
<ol>
<li>run <code>apt install powertop</code></li>
<li>run <code>powertop --auto-tune</code> (saves ~2 Watt)</li>
<li>Unplug the monitor (run headless) (saves ~1 Watt)</li>
</ol>
<p>You have to put the <code>powertop --auto-tune</code> command in /etc/rc.local:</p>
<div><pre><span></span><code><span>#!/usr/bin/env bash</span>
powertop<span> </span>--auto-tune
<span>exit</span><span> </span><span>0</span>
</code></pre></div>

<p>Then apply <code>chmod +x /etc/rc.local</code></p>
<p>So, for about the same idle power draw you get so much more performance, and go beyond the max 8GB RAM of the Pi 5.</p>
<h3>Elitedesk 705 (AMD)</h3>
<p>I managed to get this system to 10-11 watt at idle, but it was a pain to get there. </p>
<p>I measured around 11 Watts idle power consumption running a preinstalled Windows 11 (with monitor connected). After installing Debian 12 the system used 18 Watts at idle and so began a journey of many hours trying to solve this problem. </p>
<p>The culprit is the integrated Radeon Vega GPU. To solve the problem you have to:</p>
<ol>
<li>Configure the 'bios' to only use UEFI</li>
<li>Reinstall Debian 12 using UEFI</li>
<li>install the appropriate firmware with <code>apt install firmware-amd-graphics</code></li>
</ol>
<p>If you boot the computer using legacy 'bios' mode, the AMD Radeon firmware won't load no matter what you try. You can see this by issuing the commands:</p>
<div><pre><span></span><code>rmmod<span> </span>amdgpu
modprobe<span> </span>amdgpu
</code></pre></div>

<p>You may notice errors on the physical console or in the logs that the GPU driver isn't loaded because it's missing firmware (a lie).</p>
<p>This whole process got me to around 12 Watt at idle. To get to <strong>~10 Watts idle</strong> you need to do also run <code>powertop --auto-tune</code> and disconnect the monitor, as stated in the 'Intel' section earlier.</p>
<p>Given the whole picture, 10-11 Watt at idle is perfectly okay for a home server, and if you just want the cheapest option possible, this is still a fine system.</p>
<h2>KVM Virtualisation</h2>
<p>I'm running vanilla KVM (Debian 12) on these Mini PCs and it works totally fine. I've created multiple virtual machines without issue and performance seemed perfectly adequate. </p>
<h2>Boot performance</h2>
<p>From the moment I pressed the power button to SSH connecting, it took 17 seconds for the Elitedesk 800.</p>
<p>The Elitedesk 705 took 33 seconds until I got an SSH shell.</p>
<p>These boot times include the 5 second boot delay within the GRUB bootloader screen that is default for Debian 12.</p>
<h2>Remote management support</h2>
<p>Some of you may be familiar with <a href="https://en.wikipedia.org/wiki/Intelligent_Platform_Management_Interface">IPMI</a> (ILO, DRAC, and so on) which is standard on most servers. But there is also similar technology for (enterprise) desktops.</p>
<p>Intel <a href="https://en.wikipedia.org/wiki/Intel_Management_Engine">AMT/ME</a> is a technology used for remote out-of-band management of computers. It can be an interesting feature in a homelab environment but I have no need for it. If you want to try it, you can follow <a href="https://en.wikipedia.org/wiki/Intel_Management_Engine">this guide</a>.</p>
<p>For most people, it may be best to disable the AMT/ME feature as it has a history of security vulnerabilities. This may not be a huge issue within a trusted home network, but you have been warned.</p>
<p>The AMD-based Elitedesk 705 didn't came with equivalent remote management capabilities as far as I can tell.</p>
<h2>Alternatives</h2>
<p>The models discussed here are older models that are selected for a particular price point. Newer models from Lenovo, HP and Dell, equip more modern processors which are faster and have more cores. They are often also priced significantly higher. </p>
<p>If you are looking for low-power small formfactor PCs with more potent or customisable hardware, you may want to look at second-hand NUC formfactor PCs.</p>
<h2>Stacking multiple mini PCs</h2>
<p>The AMD-based Elitedesk 705 G4 is closed at the top and it's possible to stack other mini PCs on top. </p>
<p>The Intel-based Elitedesk 800 G3 has a perforated top enclosure, and putting another mini pc on top might suffocate the CPU fan.</p>
<p><img alt="topbottom" src="https://louwrentius.com/static/images/tmm/tmm07_small.webp"></p>
<p>As you can see, the bottom/foot of the mini PC doubles as a VESA mount and has four screw holes. By putting some screws in those holes, you may effectively create standoffs that gives the machine below enough space to breathe (maybe you can use actual standoffs).</p>
<h2>Evaluation and conclusion</h2>
<p>I think these second-hand 1L tinyminimicro PCs are better suited to play the role of home (lab) server than the Raspberry Pi (5). </p>
<p>The increased CPU performance, the built-in SSD/NVME support, the option to go beyond 8 GB of RAM (up to 32GB) and the price point on the second-hand market really makes a difference. </p>
<p>I love the Raspberry Pi and I still have a ton of Pi 4s. This <a href="https://louwrentius.com/i-made-my-blog-solar-powered-then-things-escalated.html">solar-powered</a> blog is hosted on a Pi 4 because of the low power consumption and the availability of GPIO pins for the solar status display. </p>
<p>That said, unless the Raspberry Pi becomes a lot cheaper (and more potent), I'm not so sure it's such a compelling home server.</p>

            </div></div>]]></description>
        </item>
    </channel>
</rss>