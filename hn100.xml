<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 25 Apr 2024 11:00:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[HTML Attributes vs. DOM Properties (193 pts)]]></title>
            <link>https://jakearchibald.com/2024/attributes-vs-properties/</link>
            <guid>40152682</guid>
            <pubDate>Thu, 25 Apr 2024 02:34:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jakearchibald.com/2024/attributes-vs-properties/">https://jakearchibald.com/2024/attributes-vs-properties/</a>, See on <a href="https://news.ycombinator.com/item?id=40152682">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Attributes and properties are <em>fundamentally</em> different things. You can have an attribute and property of the same name set to different values. For example:</p>
<div><pre><code><span><span><span>&lt;</span>div</span> <span>foo</span><span><span>=</span><span>"</span>bar<span>"</span></span><span>&gt;</span></span>…<span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
  <span>const</span> div <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'div[foo=bar]'</span><span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttribute</span><span>(</span><span>'foo'</span><span>)</span><span>)</span><span>;</span> <span>// 'bar'</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span>foo<span>)</span><span>;</span> <span>// undefined</span>

  div<span>.</span>foo <span>=</span> <span>'hello world'</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttribute</span><span>(</span><span>'foo'</span><span>)</span><span>)</span><span>;</span> <span>// 'bar'</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span>foo<span>)</span><span>;</span> <span>// 'hello world'</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre></div><p>It seems like fewer and fewer developers know this, partially thanks to frameworks:</p>
<div><pre><code><span><span><span>&lt;</span>input</span> <span>className</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>aria-label</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>value</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>/&gt;</span></span></code></pre></div><p>If you do the above in a framework's templating language, you're using attribute-like syntax, but under the hood it'll sometimes be setting the property instead, and when it does that differs from framework to framework. In some cases, it'll set a property <em>and</em> an attribute as a side-effect, but that isn't the framework's fault.</p>
<p>Most of the time, these distinctions don't matter. I think it's good that developers can have a long and happy career without caring about the differences between properties and attributes. But, if you need to dig down into the DOM at a lower level, it helps to know. Even if you feel you know the difference, maybe I'll touch on a couple of details you hadn't considered. So let's dig in…</p>
<h2 id="the-key-differences"><a href="#the-key-differences">The key differences</a></h2>
<p>Before we get to the interesting stuff, let's get some of the technical differences out of the way:</p>
<h3 id="html-serialisation"><a href="#html-serialisation">HTML serialisation</a></h3>
<p>Attributes serialise to HTML, whereas properties don't:</p>
<div><pre><code><span>const</span> div <span>=</span> document<span>.</span><span>createElement</span><span>(</span><span>'div'</span><span>)</span><span>;</span>

div<span>.</span><span>setAttribute</span><span>(</span><span>'foo'</span><span>,</span> <span>'bar'</span><span>)</span><span>;</span>
div<span>.</span>hello <span>=</span> <span>'world'</span><span>;</span>

console<span>.</span><span>log</span><span>(</span>div<span>.</span>outerHTML<span>)</span><span>;</span> <span>// '&lt;div foo="bar"&gt;&lt;/div&gt;'</span></code></pre></div><p>So when you're looking at the elements panel in browser developer tools, you're only seeing attributes on elements, not properties.</p>
<h3 id="value-types"><a href="#value-types">Value types</a></h3>
<p>In order to work in the serialised format, attribute values are always strings, whereas properties can be any type:</p>
<div><pre><code><span>const</span> div <span>=</span> document<span>.</span><span>createElement</span><span>(</span><span>'div'</span><span>)</span><span>;</span>
<span>const</span> obj <span>=</span> <span>{</span> <span>foo</span><span>:</span> <span>'bar'</span> <span>}</span><span>;</span>

div<span>.</span><span>setAttribute</span><span>(</span><span>'foo'</span><span>,</span> obj<span>)</span><span>;</span>
console<span>.</span><span>log</span><span>(</span><span>typeof</span> div<span>.</span><span>getAttribute</span><span>(</span><span>'foo'</span><span>)</span><span>)</span><span>;</span> <span>// 'string'</span>
console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttribute</span><span>(</span><span>'foo'</span><span>)</span><span>)</span><span>;</span> <span>// '[object Object]'</span>

div<span>.</span>hello <span>=</span> obj<span>;</span>
console<span>.</span><span>log</span><span>(</span><span>typeof</span> div<span>.</span>hello<span>)</span><span>;</span> <span>// 'object'</span>
console<span>.</span><span>log</span><span>(</span>div<span>.</span>hello<span>)</span><span>;</span> <span>// { foo: 'bar' }</span></code></pre></div><h3 id="case-sensitivity"><a href="#case-sensitivity">Case sensitivity</a></h3>
<p>Attribute names are case-insensitive, whereas property names are case-sensitive.</p>
<div><pre><code><span><span><span>&lt;</span>div</span> <span>id</span><span><span>=</span><span>"</span>test<span>"</span></span> <span>HeLlO</span><span><span>=</span><span>"</span>world<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
  <span>const</span> div <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'#test'</span><span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttributeNames</span><span>(</span><span>)</span><span>)</span><span>;</span> <span>// ['id', 'hello']</span>

  div<span>.</span><span>setAttribute</span><span>(</span><span>'FOO'</span><span>,</span> <span>'bar'</span><span>)</span><span>;</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttributeNames</span><span>(</span><span>)</span><span>)</span><span>;</span> <span>// ['id', 'hello', 'foo']</span>

  div<span>.</span>TeSt <span>=</span> <span>'value'</span><span>;</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span>TeSt<span>)</span><span>;</span> <span>// 'value'</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span>test<span>)</span><span>;</span> <span>// undefined</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre></div><p>However, attribute <em>values</em> are case-sensitive.</p>
<p>Ok, here's where things start to get blurry:</p>
<h2 id="reflection"><a href="#reflection">Reflection</a></h2>
<p>Take a look at this:</p>
<div><pre><code><span><span><span>&lt;</span>div</span> <span>id</span><span><span>=</span><span>"</span>foo<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
  <span>const</span> div <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'#foo'</span><span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttribute</span><span>(</span><span>'id'</span><span>)</span><span>)</span><span>;</span> <span>// 'foo'</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span>id<span>)</span><span>;</span> <span>// 'foo'</span>

  div<span>.</span>id <span>=</span> <span>'bar'</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>div<span>.</span><span>getAttribute</span><span>(</span><span>'id'</span><span>)</span><span>)</span><span>;</span> <span>// 'bar'</span>
  console<span>.</span><span>log</span><span>(</span>div<span>.</span>id<span>)</span><span>;</span> <span>// 'bar'</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre></div><p>This seems to contradict the first example in the post, but the above only works because <code>Element</code> has an <code>id</code> getter &amp; setter that 'reflects' the <code>id</code> attribute.</p>
<p>When a property reflects an attribute, the <em>attribute</em> is the source of the data. When you set the property, it's updating the attribute. When you read from the property, it's reading the attribute.</p>
<p>For convenience, most specs will create a property equivalent for every defined attribute. It didn't work in the example at the start of the article, because <code>foo</code> isn't a spec-defined attribute, so there isn't a spec-defined <code>foo</code> property that reflects it.</p>
<p><a href="https://html.spec.whatwg.org/multipage/grouping-content.html#the-ol-element">Here's the spec for <code>&lt;ol&gt;</code></a>. The "Content attributes" section defines the attributes, and the "DOM interface" defines the properties. If you click on <code>reversed</code> in the DOM interface, it takes you to this:</p>
<blockquote>

<p>The <code>reversed</code> and <code>type</code> IDL attributes must <a href="https://html.spec.whatwg.org/multipage/common-dom-interfaces.html#reflect">reflect</a> the respective content attributes of the same name.</p>
</blockquote>

<p>But not all of these reflectors are as simple as these.</p>
<h3 id="naming-differences"><a href="#naming-differences">Naming differences</a></h3>
<p>Ok, this is relatively minor, but sometimes the property has a different name to the attribute it reflects.</p>
<p>In some cases it's just to add the kind of casing you'd expect from a property:</p>
<ul>
<li>On <code>&lt;img&gt;</code>, <code>el.crossOrigin</code> reflects the <code>crossorigin</code> attribute.</li>
<li>On all elements, <code>el.ariaLabel</code> reflects the <code>aria-label</code> attribute (the aria reflectors became cross browser in late 2023. Before that you could only use the attributes).</li>
</ul>
<p>In some cases, names had to be changed due to old JavaScript reserved words:</p>
<ul>
<li>On all elements, <code>el.className</code> reflects the <code>class</code> attribute.</li>
<li>On <code>&lt;label&gt;</code>, <code>el.htmlFor</code> reflects the <code>for</code> attribute.</li>
</ul>
<h3 id="validation-type-coercion-and-defaults"><a href="#validation-type-coercion-and-defaults">Validation, type coercion, and defaults</a></h3>
<p>Properties come with validation and defaults, whereas attribute don't:</p>
<div><pre><code><span>const</span> input <span>=</span> document<span>.</span><span>createElement</span><span>(</span><span>'input'</span><span>)</span><span>;</span>

console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'type'</span><span>)</span><span>)</span><span>;</span> <span>// null</span>
console<span>.</span><span>log</span><span>(</span>input<span>.</span>type<span>)</span><span>;</span> <span>// 'text'</span>

input<span>.</span>type <span>=</span> <span>'number'</span><span>;</span>

console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'type'</span><span>)</span><span>)</span><span>;</span> <span>// 'number'</span>
console<span>.</span><span>log</span><span>(</span>input<span>.</span>type<span>)</span><span>;</span> <span>// 'number'</span>

input<span>.</span>type <span>=</span> <span>'foo'</span><span>;</span>

console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'type'</span><span>)</span><span>)</span><span>;</span> <span>// 'foo'</span>
console<span>.</span><span>log</span><span>(</span>input<span>.</span>type<span>)</span><span>;</span> <span>// 'text'</span></code></pre></div><p>In this case, the validation is handled by the <code>type</code> getter. The setter allowed the invalid value <code>'foo'</code>, but when the getter saw the invalid value, or no value, it returned <code>'text'</code>.</p>
<p>Some properties perform type coercion:</p>
<div><pre><code><span><span><span>&lt;</span>details</span> <span>open</span><span>&gt;</span></span>…<span><span><span>&lt;/</span>details</span><span>&gt;</span></span>
<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
  <span>const</span> details <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'details'</span><span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>details<span>.</span><span>getAttribute</span><span>(</span><span>'open'</span><span>)</span><span>)</span><span>;</span> <span>// ''</span>
  console<span>.</span><span>log</span><span>(</span>details<span>.</span>open<span>)</span><span>;</span> <span>// true</span>

  details<span>.</span>open <span>=</span> <span>false</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>details<span>.</span><span>getAttribute</span><span>(</span><span>'open'</span><span>)</span><span>)</span><span>;</span> <span>// null</span>
  console<span>.</span><span>log</span><span>(</span>details<span>.</span>open<span>)</span><span>;</span> <span>// false</span>

  details<span>.</span>open <span>=</span> <span>'hello'</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>details<span>.</span><span>getAttribute</span><span>(</span><span>'open'</span><span>)</span><span>)</span><span>;</span> <span>// ''</span>
  console<span>.</span><span>log</span><span>(</span>details<span>.</span>open<span>)</span><span>;</span> <span>// true</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre></div><p>In this case, the <code>open</code> property is a boolean, returning whether the attribute exists. The setter also coerces the type - even though the setter is given <code>'hello'</code>, it's turned to a boolean rather than going directly to the attribute.</p>
<p>Properties like <code>img.height</code> coerce the attribute value to a number. The setter converts the incoming value to a number, and treats negative values as 0.</p>
<h3 id="value-on-input-fields"><a href="#value-on-input-fields"><code>value</code> on input fields</a></h3>
<p><code>value</code> is a fun one. There's a <code>value</code> property and a <code>value</code> attribute. However, the <code>value</code> property does not reflect the <code>value</code> attribute. Instead, the <code>defaultValue</code> property reflects the <code>value</code> attribute.</p>
<p>I know, I know.</p>
<p>In fact, the <code>value</code> property doesn't reflect <em>any</em> attribute. That isn't unusual, there's loads of these (<code>offsetWidth</code>, <code>parentNode</code>, <code>indeterminate</code> on checkboxes for some reason, and many more).</p>
<p>Initially, the <code>value</code> property defers to the <code>defaultValue</code> property. Then, once the <code>value</code> property is set, either via JavaScript or through user interaction, it switches to an internal value. It's as if it's implemented <em>roughly</em> like this:</p>
<div><pre><code><span>class</span> <span>HTMLInputElement</span> <span>extends</span> <span>HTMLElement</span> <span>{</span>
  <span>get</span> <span>defaultValue</span><span>(</span><span>)</span> <span>{</span>
    <span>return</span> <span>this</span><span>.</span><span>getAttribute</span><span>(</span><span>'value'</span><span>)</span> <span>??</span> <span>''</span><span>;</span>
  <span>}</span>

  <span>set</span> <span>defaultValue</span><span>(</span><span>newValue</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span><span>setAttribute</span><span>(</span><span>'value'</span><span>,</span> <span>String</span><span>(</span>newValue<span>)</span><span>)</span><span>;</span>
  <span>}</span>

  #value <span>=</span> <span>undefined</span><span>;</span>

  <span>get</span> <span>value</span><span>(</span><span>)</span> <span>{</span>
    <span>return</span> <span>this</span><span>.</span>#value <span>??</span> <span>this</span><span>.</span>defaultValue<span>;</span>
  <span>}</span>

  <span>set</span> <span>value</span><span>(</span><span>newValue</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span>#value <span>=</span> <span>String</span><span>(</span>newValue<span>)</span><span>;</span>
  <span>}</span>

  <span>// This happens when the associated form resets</span>
  <span>formResetCallback</span><span>(</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span>#value <span>=</span> <span>undefined</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre></div><p>So:</p>
<div><pre><code><span><span><span>&lt;</span>input</span> <span>type</span><span><span>=</span><span>"</span>text<span>"</span></span> <span>value</span><span><span>=</span><span>"</span>default<span>"</span></span> <span>/&gt;</span></span>
<span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span>
  <span>const</span> input <span>=</span> document<span>.</span><span>querySelector</span><span>(</span><span>'input'</span><span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'value'</span><span>)</span><span>)</span><span>;</span> <span>// 'default'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>value<span>)</span><span>;</span> <span>// 'default'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>defaultValue<span>)</span><span>;</span> <span>// 'default'</span>

  input<span>.</span>defaultValue <span>=</span> <span>'new default'</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'value'</span><span>)</span><span>)</span><span>;</span> <span>// 'new default'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>value<span>)</span><span>;</span> <span>// 'new default'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>defaultValue<span>)</span><span>;</span> <span>// 'new default'</span>

  <span>// Here comes the mode switch:</span>
  input<span>.</span>value <span>=</span> <span>'hello!'</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'value'</span><span>)</span><span>)</span><span>;</span> <span>// 'new default'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>value<span>)</span><span>;</span> <span>// 'hello!'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>defaultValue<span>)</span><span>;</span> <span>// 'new default'</span>

  input<span>.</span><span>setAttribute</span><span>(</span><span>'value'</span><span>,</span> <span>'another new default'</span><span>)</span><span>;</span>

  console<span>.</span><span>log</span><span>(</span>input<span>.</span><span>getAttribute</span><span>(</span><span>'value'</span><span>)</span><span>)</span><span>;</span> <span>// 'another new default'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>value<span>)</span><span>;</span> <span>// 'hello!'</span>
  console<span>.</span><span>log</span><span>(</span>input<span>.</span>defaultValue<span>)</span><span>;</span> <span>// 'another new default'</span>
</span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre></div><p>This would have made way more sense if the <code>value</code> attribute was named <code>defaultvalue</code>. Too late now.</p>
<h2 id="attributes-should-be-for-configuration"><a href="#attributes-should-be-for-configuration">Attributes should be for configuration</a></h2>
<p>In my opinion, attributes should be for configuration, whereas properties can contain state. I also believe that the light-DOM tree should have a single owner.</p>
<p>In that sense, I think <code>&lt;input value&gt;</code> gets it right (aside from the naming). The <code>value</code> attribute configures the default value, whereas the <code>value</code> property gives you the current state.</p>
<p>It also makes sense that validation applies when getting/setting properties, but never when getting/setting attributes.</p>
<p>I say 'in my opinion', because a couple of recent HTML elements have done it differently.</p>
<p>The <code>&lt;details&gt;</code> and <code>&lt;dialog&gt;</code> elements represent their open state via the <code>open</code> attribute, and the browser will self add/remove this attribute in response to user interaction.</p>
<p>I think this was a design mistake. It breaks the idea that attributes are for configuration, but more importantly it means that the system in charge of maintaining the DOM (a framework, or vanilla JS) needs to be prepared for the DOM to change itself.</p>
<p>I think it should have been:</p>
<div><pre><code><span><span><span>&lt;</span>details</span> <span>defaultopen</span><span>&gt;</span></span>…<span><span><span>&lt;/</span>details</span><span>&gt;</span></span></code></pre></div><p>And a <code>details.open</code> property to get/set the current state, along with a CSS pseudo-class for targeting that state.</p>
<p>I guess <code>contenteditable</code> also breaks that contract, but… well… it's a opt-in to a lot of breakage.</p>
<h2 id="how-frameworks-handle-the-difference"><a href="#how-frameworks-handle-the-difference">How frameworks handle the difference</a></h2>
<p>Back to the example from earlier:</p>
<div><pre><code><span><span><span>&lt;</span>input</span> <span>className</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>aria-label</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>value</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>/&gt;</span></span></code></pre></div><p>How do frameworks handle this?</p>
<h3 id="preact-and-vuejs"><a href="#preact-and-vuejs">Preact and VueJS</a></h3>
<p>Aside from a predefined set of cases where they favour attributes, they'll set the prop as a property if <code>propName in element</code>, otherwise they'll set an attribute. Basically, they prefer properties over attributes. Their render-to-string methods do the opposite, and ignore things that are property-only.</p>
<ul>
<li><a href="https://github.com/preactjs/preact/blob/aa95aa924dd5fe28798f2712acdabdc2e9fa38c9/src/diff/props.js#L37"><code>setProperty</code> in Preact</a>.</li>
<li><a href="https://github.com/vuejs/core/blob/958286e3f050dc707ad1af293e91bfb190bdb191/packages/runtime-dom/src/patchProp.ts#L69"><code>shouldSetAsProp</code> in VueJS</a>.</li>
</ul>
<h3 id="react"><a href="#react">React</a></h3>
<p>React does things the other way around. Aside from a predefined set of cases where they favour properties, they'll set an attribute. This makes their render-to-string method similar in logic.</p>
<p>This explains why custom elements don't seem to work in React. Since they're custom, their properties aren't in React's 'predefined list', so they're set as attributes instead. Anything that's property-only on the custom element simply won't work. This will be fixed in React 19, where they'll switch to the Preact/VueJS model for custom elements.</p>
<p>The funny thing is, React popularised using <code>className</code> instead of <code>class</code> in what <em>looks like</em> an attribute. But, even though you're using the property name rather than the attribute name, <a href="https://github.com/facebook/react/blob/699d03ce1a175442fe3443e1d1bed14f14e9c197/packages/react-dom-bindings/src/client/ReactDOMComponent.js#L388-L389">React will set the <code>class</code> attribute under the hood</a>.</p>
<ul>
<li><a href="https://github.com/facebook/react/blob/699d03ce1a175442fe3443e1d1bed14f14e9c197/packages/react-dom-bindings/src/client/ReactDOMComponent.js#L349"><code>setProp</code> in React</a>.</li>
</ul>
<h3 id="lit-html"><a href="#lit-html">lit-html</a></h3>
<p>Lit does things a little differently:</p>
<div><pre><code><span><span><span>&lt;</span>input</span> <span>type</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>.value</span><span><span>=</span><span>"</span>…<span>"</span></span> <span>/&gt;</span></span></code></pre></div><p>It keeps the distinction between attributes and properties, requiring you to prefix the name with <code>.</code> if you want to set the property rather than the attribute.</p>
<ul>
<li><a href="https://lit.dev/docs/templates/expressions/">Lit's expression docs</a>.</li>
</ul>
<h2 id="and-thats-yer-lot"><a href="#and-thats-yer-lot">And that's yer lot</a></h2>
<p>That's pretty much everything I know about the difference between properties and attributes. If there's something I've missed, or you have a question, let me know in the comments below!</p>
<p>Thanks to my <a href="https://offthemainthread.tech/">podcast husband</a> <a href="https://surma.dev/">Surma</a> for his usual reviewing skills.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fine tune LLAMA3 on million scale dataset in consumer GPU using QLora, DeepSpeed (119 pts)]]></title>
            <link>https://medium.com/@sumandas0/fine-tune-llama3-on-million-scale-dataset-in-consumer-gpu-using-qlora-deepspeed-3ae8ad75299a</link>
            <guid>40152486</guid>
            <pubDate>Thu, 25 Apr 2024 02:03:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medium.com/@sumandas0/fine-tune-llama3-on-million-scale-dataset-in-consumer-gpu-using-qlora-deepspeed-3ae8ad75299a">https://medium.com/@sumandas0/fine-tune-llama3-on-million-scale-dataset-in-consumer-gpu-using-qlora-deepspeed-3ae8ad75299a</a>, See on <a href="https://news.ycombinator.com/item?id=40152486">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a rel="noopener follow" href="https://medium.com/@sumandas0?source=post_page-----3ae8ad75299a--------------------------------"><div aria-hidden="false"><p><img alt="Suman" src="https://miro.medium.com/v2/resize:fill:88:88/1*cPgbuLwwvCkde8ztQQcNFA.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div><h2 id="6688">Highlights,</h2><p id="9884"><strong>Model</strong> : LLAMA-8b-instruct</p><p id="e592"><strong>Dataset</strong>: Openhermes-2.5(700k training, 300k testing)</p><p id="7df9"><strong>GPU</strong>: 4 RTX 4090, 24GB</p><h2 id="88aa">Bit of background about me,</h2><p id="cd1d">I’m a full-time software engineer 2, at the core of our platform team. In my scarce free time, I explore various aspects of the machine learning world, with interests in tabular data, NLP, and sound. Whatever I’m sharing here are scraps from all over the internet consolidated into one place. I have decent experience in training small NLP models and have submitted a solution in a Kaggle competition using DeBERTa v3, scoring enough to be in the top 50%, but I have never tried working with large language models. This is my first time, so please let me know if there are any oversights. Yes, this is my first blog post. Writing this will definitely help me, and hopefully, it will be useful for any readers as well</p><h2 id="023a">LLama</h2><p id="7eff">Who don’t know about this long necked creature revolutionizing the AI field from its birth. Joke apart release of llama where the whole OSS powered LLM kicked of the revolution which don’t seems like stopping in near future.</p><p id="b306">To learn more on llama in depth and technical do checkout this <a href="https://www.linkedin.com/posts/ujamil_llama-explained-kv-cache-rotary-positional-activity-7100620274642866176-XaKO/" rel="noopener ugc nofollow" target="_blank">Post | LinkedIn</a> , this is one of the most technically simplified explanation I can found all over the internet. Few things they implemented in their architecture like Grouped Multi Query Attention, KV-Cache, Rotary Positional Embeddings(RoPE) which are very cool. These are not in scope of this article. They continued releasing their versions of LLama with latest version came few days ago. And this time with massive data compacted into few GBs of parameters.</p><figure><figcaption><a href="https://www.forbes.com/sites/janakirammsv/2024/04/19/meta-unveils-llama-310-key-facts-about-the-advanced-llm/" rel="noopener ugc nofollow" target="_blank">Meta Unveils Llama 3–10 Key Facts About The Advanced LLM (forbes.com)</a></figcaption></figure><h2 id="226e">Deepspeed</h2><blockquote><p id="0a5f"><em>DeepSpeed is a deep learning optimization library that makes distributed training and inference easy, efficient, and effective.</em></p><p id="eddb"><a href="https://github.com/microsoft/DeepSpeed" rel="noopener ugc nofollow" target="_blank"><em>https://github.com/microsoft/DeepSpeed</em></a></p></blockquote><p id="dee0">I will be training this model using four RTX 4090 GPUs that I’ve rented from <a href="http://vast.ai/" rel="noopener ugc nofollow" target="_blank">vast.ai</a>, so we need to take some steps to train the models across multiple GPUs. Training on multiple GPUs is a complex task compared to training on a single GPU. Why? When we train on a single GPU, the Optimizer state, parameters and gradients reside in a single system, which helps iterating over models on one GPU.</p><p id="c422">Now, if we add another GPU, there are two systems that will train the models, each with its own state(Optimizer state, parameters and gradients). After one epoch or several steps, we would like to obtain a single result. Now imagine two systems training two batches of data in parallel; they need to communicate about their state and converge the results with minimal data loss. There are multiple ways to utilize multiple GPUs: we can replicate parameters, gradients, and optimizer state across all GPUs, or we could shard only the optimizer state, or the optimizer state and gradients. DeepSpeed helps in distributing the load over the GPUs without any issues. And accelerate package from Huggingface lets us do this like its piece of cake.</p><p id="91cc">I will use stage 3 which will shard all parameters, gradients and optimizer state which will let us training over less memory requirement,</p><figure></figure><p id="2411">More details in their blog, <a href="https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/" rel="noopener ugc nofollow" target="_blank">ZeRO &amp; DeepSpeed: New system optimizations enable training models with over 100 billion parameters — Microsoft Research</a></p><h2 id="9ade">QLoRA</h2><p id="ebf1">Until I write something about QLoRA, please take a look into this blog to get more technical context <a href="https://wandb.ai/sauravmaheshkar/QLoRA/reports/What-is-QLoRA---Vmlldzo2MTI2OTc5" rel="noopener ugc nofollow" target="_blank">What is QLoRA? | QLoRA — Weights &amp; Biases (wandb.ai)</a>, basically 70B/8B models are very large in size means when you fine tune it you will not be able to fully fine tune with any GPU in normal people’s budget, so we tried to fine tune it with very low resource and came LoRA which helped us just training over parameters with low rank and merging them with original weights, then came QLoRA which helped even more reducing memory consumption by quantizing the pre trained LLM to 4 bit precision, quantizing is a topic in itself so not going beyond this.</p><p id="51ad">Also take a look into this article <a href="https://www.entrypointai.com/blog/lora-fine-tuning/" rel="noopener ugc nofollow" target="_blank">LoRA Fine-tuning &amp; Hyperparameters Explained (in Plain English) | Entry Point AI</a></p><h2 id="50cb">Lets start finetuning LLamA 3</h2><p id="a905">We will be finetuning the llama3 instruct model <a href="https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct" rel="noopener ugc nofollow" target="_blank">meta-llama/Meta-Llama-3–8B-Instruct · Hugging Face</a> over <a href="https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B" rel="noopener ugc nofollow" target="_blank">openhermes</a> dataset provided by teknium.</p><h2 id="0e59">Data preparation</h2><p id="a219">Meta has their own chat format so tried to follow the format they provided and read their encoding algorithm in their llama3 repository,</p><p id="b4df"><strong>Load the dataset</strong></p><pre><span id="0492">from datasets import load_dataset<p>dataset = load_dataset("teknium/OpenHermes-2.5")</p></span></pre><p id="3943"><strong>The encoding utility I took inspiration from</strong><a href="https://github.com/meta-llama/llama3/blob/af6eedf7042fb51d00b2b26d8ef1ceaab73e1670/llama/tokenizer.py#L202" rel="noopener ugc nofollow" target="_blank"><strong> llama3 repo</strong></a><strong>,</strong></p><pre><span id="2427">def _return_header(message)-&gt; str:<br>    role = message["from"]<br>    header = ""<br>    if role == "system":<br>        header = "system"<br>    elif role == "gpt":<br>        header = "assistant"<br>    elif role == "human":<br>        header = "user"<br>    return header<p>def encode_header(message):<br>    text = ''<br>    text = text + "&lt;|start_header_id|&gt;"<br>    header = _return_header(message)<br>    text = text + header<br>    text = text + "&lt;|end_header_id|&gt;"<br>    text = text + "\n\n"<br>    return text</p><p>def encode_message(message)-&gt;str:<br>    text = encode_header(message)<br>    text = text + message["value"].strip()<br>    text = text + "&lt;|eot_id|&gt;"<br>    return text</p><p>def encode_dialog_prompt(dialog):<br>    text = ''<br>    text = text + "&lt;|begin_of_text|&gt;"<br>    for message in dialog:<br>        text = text + encode_message(message)<br>    return text</p></span></pre><pre><span id="c697">ds = dataset.map(lambda x: {"content":encode_dialog_prompt(x['conversations'])}, num_proc=10)</span></pre><p id="6128">Remove redundunt columns and split it into train and validation</p><pre><span id="6147">ds = ds.remove_columns(['custom_instruction', 'topic', 'model_name', 'model', 'skip_prompt_formatting', 'category', 'conversations', 'views', 'language', 'id', 'title', 'idx', 'hash', 'avatarUrl', 'system_prompt', 'source'])<br>train_test_split = ds["train"].train_test_split(test_size=0.3)</span></pre><p id="e8fc"><strong>And push it to hub,</strong></p><pre><span id="c29e">train_test_split.push_to_hub("sumandas/openhermes-2.5-llama3")</span></pre><p id="6614">The resultant dataset, <a href="https://huggingface.co/datasets/sumandas/openhermes-2.5-llama3" rel="noopener ugc nofollow" target="_blank">sumandas/openhermes-2.5-llama3 · Datasets at Hugging Face</a>, example text</p><pre><span id="3556">&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt; You are an AI assistant. Provide a detailed answer so user don’t need to search outside to understand the answer.&lt;|eot_id|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt; Instructions: Given a sentence, generate what should be the most likely next statement. The next statement should be reasonable and logically correct. Input: The screen is full of white bubbles and words, while a pair of hands plays the piano. The bubbles and words disappear and it Output:&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt; Output: becomes apparent that the hands are creating a visual representation of the music being played, captivating the audience with this unique sensory experience.&lt;|eot_id|&gt;</span></pre><h2 id="1ba2">Now its time for training LLama3</h2><p id="cab1">All of the resources were already available in internet I just fine tuned those for my setup and requirements,</p><p id="ebdc"><strong>Prerequisites,</strong></p><ol><li id="0bf2">Install cuda dev kit <code>conda install cuda</code> or follow <a href="https://developer.nvidia.com/cuda-downloads?target_os=Linux" rel="noopener ugc nofollow" target="_blank">developer.nvidia.com/cuda-downloads?target_os=Linux</a></li><li id="0a0a">Install deepspeed</li><li id="cd39">Install flash-attention <em>pip install flash-attn — no-build-isolation</em></li><li id="6a5a">Install these libraries, I use <a href="https://github.com/astral-sh/uv" rel="noopener ugc nofollow" target="_blank">uv</a> for faster dependency resolution,</li></ol><pre><span id="2bb2">git+https://github.com/huggingface/transformers<br>git+https://github.com/huggingface/accelerate<br>git+https://github.com/huggingface/peft<br>git+https://github.com/huggingface/trl<br>huggingface-hub<br>bitsandbytes<br>evaluate<br>datasets<br>einops<br>wandb<br>tiktoken<br>xformers<br>sentencepiece<br>deepspeed<br>torch==2.2.2</span></pre><p id="ebd9"><strong>Training code</strong></p><p id="d43d">This is Swiss knife training code where you can train in multiple mode as per you convenience, found this in this repo <a href="https://github.com/pacman100/LLM-Workshop" rel="noopener ugc nofollow" target="_blank">pacman100/LLM-Workshop: LLM Workshop by Sourab Mangrulkar (github.com)</a>,</p><blockquote><p id="93e4">The <code>training.py</code> file is the one we will launch using accelerate with proper configs, just putting the training.py gist here, <a href="https://gist.github.com/sumandas0/0483db8514ea43e45cc5e5f5525914ab" rel="noopener ugc nofollow" target="_blank">https://gist.github.com/sumandas0/0483db8514ea43e45cc5e5f5525914ab</a></p></blockquote><p id="831b">This training code uses SFTTrainer from huggingface, more details <a href="https://huggingface.co/docs/trl/en/sft_trainer" rel="noopener ugc nofollow" target="_blank">Supervised Fine-tuning Trainer (huggingface.co)</a></p><p id="7822">You can do multiple thing with this, you can train with loftq, unsloth, FFT, normal lora but I will just use QloRa with Deepspeed ZerO stage 3.</p><p id="cc17"><strong>First lets define the accelerate config for using deepspeed</strong></p><figure></figure><blockquote><p id="2bfa">Note, If you increase the number of GPU update number in <em>num_processes</em></p></blockquote><p id="56e5">Now lets just run the accelerate command to start training,</p><pre><span id="7326">accelerate launch --config_file "deepspeed_config.yaml"  train.py \<br>--seed 100 \<br>--model_name_or_path "meta-llama/Meta-Llama-3-8B-Instruct" \<br>--dataset_name "sumandas/openhermes-2.5-llama3" \<br>--chat_template_format "none" \<br>--add_special_tokens False \<br>--append_concat_token False \<br>--splits "train,test" \<br>--max_seq_len 2048 \<br>--num_train_epochs 1 \<br>--logging_steps 5 \<br>--log_level "info" \<br>--logging_strategy "steps" \<br>--evaluation_strategy "epoch" \<br>--save_strategy "steps" \<br>--push_to_hub \<br>--hub_private_repo True \<br>--report_to "wandb" \<br>--hub_strategy "every_save" \<br>--bf16 True \<br>--packing True \<br>--learning_rate 1e-4 \<br>--lr_scheduler_type "cosine" \<br>--weight_decay 1e-4 \<br>--warmup_ratio 0.0 \<br>--max_grad_norm 1.0 \<br>--output_dir "llama3-openhermes-2.5" \<br>--per_device_train_batch_size 4\<br>--per_device_eval_batch_size 4\<br>--gradient_accumulation_steps 2 \<br>--gradient_checkpointing True \<br>--use_reentrant True \<br>--dataset_text_field "content" \<br>--use_flash_attn True \<br>--use_peft_lora True \<br>--lora_r 8 \<br>--lora_alpha 16 \<br>--lora_dropout 0.1 \<br>--lora_target_modules "all-linear" \<br>--use_4bit_quantization True \<br>--use_nested_quant True \<br>--bnb_4bit_compute_dtype "bfloat16" \<br>--bnb_4bit_quant_storage_dtype "bfloat16"</span></pre><p id="85c8"><strong>Notes,</strong></p><ol><li id="7f33">Set env variable HF_HUB_ENABLE_HF_TRANSFER=1 first</li><li id="10d8">output_dir will also be the repo created in huggingface where all the checkpoints will be stored, checkpoints will be created every 500 steps by default</li><li id="e8df">I set chat template format as <code>none</code> , because I already formatted those in my way, if you have other format do use for e.g chatml, zephyr</li><li id="9507"><code>lora_target_modules</code> is set as all-linear which is QLoRa specific where they published paper to show fine tuning all linear layers gives us comparable result to full fine tune.</li><li id="7c14">For setting up hyperparameters for LoRa, take a look into this awesome blog <a href="https://www.entrypointai.com/blog/lora-fine-tuning/" rel="noopener ugc nofollow" target="_blank">LoRA Fine-tuning &amp; Hyperparameters Explained (in Plain English) | Entry Point AI</a></li><li id="c733">Set up WANDB_API_KEY=&lt;key&gt; if you are reporting to wandb else remove <code>report_to='wandb'</code></li></ol><p id="bc6b">This should be it and your training should be running in full force, look for GPU utilization.</p><h2 id="f2df">Observation</h2><p id="38ff">Ran the fine tuning for only 1 epoch, took around 15 hours. Loss curve</p><figure><figcaption>fig: training loss <a href="https://wandb.ai/sumandas0/huggingface/reports/train-loss-24-04-25-02-44-11---Vmlldzo3Njg1NzIw?accessToken=hinzctjy4lbm48zwjoamnmhxs5r56zp8l88iqpss2jb0xo2w2bu049jkiqd59btj" rel="noopener ugc nofollow" target="_blank">train/loss (24/04/25 02:44:11) | huggingface — Weights &amp; Biases (wandb.ai)</a></figcaption></figure><p id="38c3"><strong>WandB summary</strong></p><pre><span id="e856">{<br>  "train/learning_rate": 0.00004551803455482833,<br>  "eval/steps_per_second": 0.893,<br>  "_wandb.runtime": 51487,<br>  "_runtime": 51480.36651659012,<br>  "_timestamp": 1713698971.6200776,<br>  "train/epoch": 1.0571428571428572,<br>  "train/grad_norm": 0.14189070214353952,<br>  "train/global_step": 8325,<br>  "eval/samples_per_second": 7.141,<br>  "_step": 1665,<br>  "eval/loss": 0.963840126991272,<br>  "train/loss": 0.9674,<br>  "eval/runtime": 7532.9797<br>}</span></pre><h2 id="602e">Last steps,</h2><p id="02a5">After the finetuning what model you will get is small adapter model not full model that you can just start using just now, we need to add the adapter to the original meta llama3 weights,</p><p id="d092">Load PEFT adapter model,</p><pre><span id="866d">from peft import PeftModel<br>from transformers import AutoModelForCausalLM<p>base_model = AutoModelForCausalLM.from_pretrained("meta-llama/Meta-Llama-3-8B-Instruct",torch_dtype=torch.bfloat16, device_map="auto")<br>adapter_model = PeftModel.from_pretrained(base_model, "sumandas/llama3-openhermes-2.5")<br>adapter_model.merge_and_unload()</p></span></pre><p id="11a1">Now save the adapter model into hf,</p><pre><span id="c058">adapter_model.push_to_hub("sumandas/llama3-openhermes-2.5")</span></pre><h2 id="6ffe">Inference</h2><pre><span id="2c4c">import torch<br>import transformers<br>from transformers import pipeline<p>pipe = pipeline("text-generation", model="sumandas/llama3-openhermes-2.5",model_kwargs={"torch_dtype": torch.bfloat16},<br>    device="cuda")</p><p>generate_kwargs = {<br>    "do_sample": True,<br>    "temperature": 0.7,<br>    "max_new_tokens": 35,<br>}</p></span></pre><pre><span id="e8fe">pipe("&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt; Describe the food of Thailand&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;",max_length=2048)</span></pre><p id="a1a4">Response,</p><pre><span id="dce7">Thai cuisine is a blend of bold flavors and aromatic ingredients that create a harmonious balance of sweet, sour, salty, bitter, and spicy taste. The food in Thailand varies between different regions, but some common ingredients found throughout include rice, noodles, vegetables, herbs, and spices. Rice is a staple of Thai cuisine and is served with almost every meal, whether it is stir-fried, boiled, or used to make congee or fried rice. Noodles, made from rice or wheat, are also very popular and can be found served with various broths, sauces, and toppings in many Thai dishes. Thai food is known for its use of fresh herbs and spices such as lemongrass, galangal, coriander, basil, kaffir lime leaves, ginger, and garlic, which give the dishes their distinct flavors. Thai chilies are also widely used to add varying levels of heat to the food. Some popular Thai dishes include Tom Yum soup (hot and sour soup with lemongrass, kaffir lime leaves, and chilies), Pad Thai (stir-fried rice noodles with vegetables, peanuts, and a tangy sauce), and green curry (a spicy curry made with green chilies, coconut milk, and Thai basil). Many Thai dishes are also accompanied by a variety of sauces and condiments, including fish sauce, soy sauce, chili paste, and tamarind sauce. Fresh fruits like mango, papaya, and pineapple are also commonly enjoyed as a sweet ending to a meal. Overall, Thai food is a vibrant and flavorful cuisine that combines traditional ingredients and cooking techniques with a balance of flavors that tantalize the taste buds.&lt;|eot_id|&gt;</span></pre><p id="9238">Do send my model and dataset some love if it has any worth :)</p><p id="45d9"><a href="https://huggingface.co/datasets/sumandas/openhermes-2.5-llama3" rel="noopener ugc nofollow" target="_blank">sumandas/openhermes-2.5-llama3 · Datasets at Hugging Face</a></p><p id="2c72"><a href="https://huggingface.co/sumandas/llama3-openhermes-2.5" rel="noopener ugc nofollow" target="_blank">sumandas/llama3-openhermes-2.5 · Hugging Face</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Beginner's Guide to the ESP8266 (176 pts)]]></title>
            <link>https://tttapa.github.io/ESP8266/Chap01%20-%20ESP8266.html</link>
            <guid>40151982</guid>
            <pubDate>Thu, 25 Apr 2024 01:03:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tttapa.github.io/ESP8266/Chap01%20-%20ESP8266.html">https://tttapa.github.io/ESP8266/Chap01%20-%20ESP8266.html</a>, See on <a href="https://news.ycombinator.com/item?id=40151982">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

   
<i>Pieter P, 08-03-2017</i>
   <p>
        Some time ago, I wrote <a href="http://www.instructables.com/id/A-Beginners-Guide-to-Arduino/">a Beginner's Guide to Arduino</a> that seems to be very popular, so I decided to create a follow-up: <b>A Beginner's Guide to the ESP8266</b>. That's right, a tutorial on how to use the world's most popular $3 Wi-Fi board.
   </p>
   
   <p>
        This is going to be a very in-depth tutorial, covering some networking concepts as well. If you're a beginner, and just want to go straight to the more exciting Wi-Fi part, feel free to do so, I included short <i>TL;DR's </i>in the longer, more technical parts.
   </p>
   
   <p>
        A short overview of what I'll cover in this article: 
   </p>
   <div>
       <ol>
           <li><b>What is an ESP8266?</b> A short overview of what an ESP8266 is, and what you can do with it</li>
           <li><b>Deciding on what board to buy</b>: There's loads of different ESP8266 available these days, finding the one that's best for you can be hard</li>
           <li><b>Installing the software</b>: you need to install some software to program the ESP8266, and maybe a USB driver</li>
           <li><b>Setting up the hardware</b>: some modules and boards need some external components</li>
           <li><b>The ESP8266 as a microcontroller</b>: the ESP8266 can be used as a normal microcontroller, just like an Arduino</li>
           <li><b>Network protocols</b>: Before we start using the Wi-Fi capabilities of the ESP8266, I'll teach you some of the network protocols involved</li>
           <li><b>Setting up a Wi-Fi connection</b>: That's probably why you're reading this, right?</li>
           <li><b>Name resolution</b>: Find the ESP8266 on your local network using mDNS</li>
           <li><b>Setting up a simple web server</b>: This enables you to add web pages to the ESP8266, and browse them from your computer or phone</li>
           <li><b>Setting up an advanced web server</b>: a more advanced server with a real file system that allows you to upload new files over Wi-Fi</li>
           <li><b>OTA - uploading programs over Wi-Fi</b>: You don't have to upload programs over USB, you can use Wi-Fi instead</li>
           <li><b>Wirelessly controlling your RGB lighting</b>: Change the color of your LED strips using your phone or computer</li>
           <li><b>Getting the time</b>: Connect to a time server using NTP and sync the ESP's clock</li>
           <li><b>Monitoring sensors</b>: log the temperature in your living room, save it in flash memory and show it in a fancy graph in your browser</li>
           <li><b>Getting email notifications</b>: Turn on a notification light when you've got unread emails</li>
           <li><b>Advanced features</b>: use DNS, captive portals, Wi-Fi connector libraries, OSC ...</li>
       </ol>
   </div>
   
   <p>
        This guide expects some basic knowledge of microcontrollers like the Arduino. If that's something you're not already familiar with, I'd recommend you to read my <a href="https://www.instructables.com/id/A-Beginners-Guide-to-Arduino/">Beginner's Guide to Arduino</a> first, it covers a lot of the basics that I won't go into in this article.
   </p>
   <p>
        I really want to focus on the ESP8266-specific things, like Wi-Fi and other network protocols, the ESP's hardware, software, IoT, etc ...
   </p>
   <h3>What is an ESP8266?</h3>
   <p>
        The ESP8266 is a System on a Chip (SoC), manufactured by the Chinese company <a href="https://espressif.com/en/">Espressif</a>. It consists of a Tensilica L106 32-bit <b>micro controller</b> unit (MCU) and a <b>Wi-Fi transceiver</b>. It has <b>11 GPIO pins</b>* (General Purpose Input/Output pins), and an <b>analog input</b> as well. This means that you can program it like any normal Arduino or other microcontroller. And on top of that, you get Wi-Fi communication, so you can use it to connect to your Wi-Fi network, connect to the Internet, host a web server with real web pages, let your smartphone connect to it, etc ... The possibilities are endless! It's no wonder that this chip has become the most popular IOT device available. 
   </p>
   
   <p>
        There are many different modules available, standalone modules like the <a href="http://en.ai-thinker.com/html/Products/WIFI_Module/ESP_01-14Series/">ESP-## series</a> by AI Thinker, or complete development boards like the <a href="http://nodemcu.com/index_en.html">NodeMCU DevKit</a> or the <a href="http://www.wemos.cc/">WeMos D1</a>. Different boards may have different pins broken out, have different Wi-Fi antennas, or a different amount of flash memory on board.
   </p>
   
   <p><small>(*) The ESP8266 chip itself has 17 GPIO pins, but 6 of these pins (6-11) are used for communication with the on-board flash memory chip.</small>
   </p>
   <h3>Programming</h3>
   <p>
        There are different ways to program the ESP8266, but I'll only cover the method using the Arduino IDE. This is really easy for beginners, and it's a very familiar environment if you've used Arduino boards before. 
   </p>
   <p>
        Just keep in mind that it's not limited to this option: there's also an official SDK available to program it in real C, this is very useful if you want to optimize your code or do some advanced tricks that aren't supported by the Arduino IDE. Another possibility is to flash it with a <a href="https://github.com/nodemcu/nodemcu-firmware">LUA</a> interpreter, so you can upload and run LUA scripts. Or maybe you're more familiar with Python? Then you should check out the <a href="http://micropython.org/download#esp8266">MicroPython firmware</a> to interpret MicroPython scripts. I'm sure there's other languages available as well, so just do a quick Google search and write your code in the language of your choice.
   </p>
   <h3>Requirements</h3>
   <p>
        You'll need a couple of things in order to follow this guide:
   </p>
   <div>
       <ul>
           <li>An ESP8266 board</li>
           <li>A computer that can run the Arduino IDE (Windows, Mac or Linux)</li>
           <li>A USB-to-Serial converter, it is very important that you use a <b>3.3V</b> model*</li>
           <li>A USB cable</li>
           <li>A 3.3V power supply or voltage regulator*</li>
           <li>A Wi-Fi network to connect to</li>
       </ul>
       <p><small>(*) Your board may already include these. More information can be found in the next chapter.</small>
       </p>
   </div>
    
<hr>
            
            
        </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You are what you read, even if you don't always remember it (456 pts)]]></title>
            <link>https://blog.jim-nielsen.com/2024/you-are-what-you-read/</link>
            <guid>40151952</guid>
            <pubDate>Thu, 25 Apr 2024 00:58:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.jim-nielsen.com/2024/you-are-what-you-read/">https://blog.jim-nielsen.com/2024/you-are-what-you-read/</a>, See on <a href="https://news.ycombinator.com/item?id=40151952">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          <p>Here’s Dave Rupert (<a href="https://notes.jim-nielsen.com/#2024-03-22T1029">from my notes</a>):</p>
<blockquote>
<p>the goal of a book isn’t to get to the last page, it’s to expand your thinking.</p>
</blockquote>
<p>I have to constantly remind myself of this. Especially in an environment that prioritizes optimizing and maximizing personal productivity, where it seems if you can’t measure (let alone remember) the impact of a book in your life then it wasn’t worth reading.</p>
<p>I don’t believe that, but I never quite had the words for expressing why I don’t believe that. Dave’s articulation hit pretty close.</p>
<p>Then a couple days later my wife sent me this quote from Ralph Waldo Emerson:</p>
<blockquote>
<p>I cannot remember the books I've read any more than the meals I have eaten; even so, they have made me.</p>
</blockquote>
<p>YES!</p>
<p>Damn, great writers are sO gOOd wITh wORdz, amirite?</p>
<p>Emerson articulates with acute brevity something I couldn’t suss out in my own thoughts, let alone put into words. It makes me jealous.</p>
<p>Anyhow, I wanted to write this down to reinforce remembering it.</p>
<p>And in a similar vein for the online world: I cannot remember the blog posts I’ve read any more than the meals I’ve eaten; even so, they’ve made me.</p>
<p>It’s a good reminder to be mindful of my content diet — you are what you <del>eat</del> read, even if you don’t always remember it.</p>
<h2 id="update-2024-04-12">Update 2024-04-12</h2>
<p><a href="https://mastodon.online/@halas#.">@halas@mastodon.social</a> shared this story in response, which I really liked:</p>
<blockquote>
<p>At the university I had a professor who had a class with us in the first year and then in the second. At the beginning of the second year’s classes he asked us something from the material of previous year. When met with silence he nodded thoughtfully and said: “Education is something you have even if you don't remember anything”</p>
</blockquote>
<p>I love stories that stick with people like that, e.g. “something a teacher told me once...”</p>
<p><a href="https://blog.jim-nielsen.com/2024/immeasurable-impact/">Some impact is immeasurable</a>.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Airlines required to refund passengers for canceled, delayed flights (532 pts)]]></title>
            <link>https://abcnews.go.com/Politics/airlines-give-automatic-refunds-canceled-flights-delayed-3/story?id=109573733</link>
            <guid>40150639</guid>
            <pubDate>Wed, 24 Apr 2024 22:29:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://abcnews.go.com/Politics/airlines-give-automatic-refunds-canceled-flights-delayed-3/story?id=109573733">https://abcnews.go.com/Politics/airlines-give-automatic-refunds-canceled-flights-delayed-3/story?id=109573733</a>, See on <a href="https://news.ycombinator.com/item?id=40150639">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="prism-article-body"><p>Good news for airline travelers: the Department of Transportation on Wednesday announced it is rolling out new rules that will require airlines to automatically give cash refunds to passengers for canceled and significantly delayed flights.</p><p>"This is a big day for America's flying public," said Transportation Secretary Pete Buttigieg at a Wednesday morning news conference. Buttigieg said the new rules -- which require prompt refunds -- are the biggest expansion of passenger rights in the department's history.</p><p>Airlines can no longer decide how long a delay must be before a refund is issued. Under the new DOT rules, the delays covered would be more than three hours for domestic flights and more than six hours for international flights, the agency said.</p><p>This includes tickets purchased directly from airlines, travel agents and third-party sites such as Expedia and Travelocity.</p><p>The DOT rules lay out that passengers will be "entitled to a refund if their flight is canceled or significantly changed, and they do not accept alternative transportation or travel credits offered."</p><div data-testid="prism-inline-image"><figure data-testid="prism-figure"><img alt="PHOTO: A person walks through the terminal as planes remain at gates at Ronald Reagan Washington National Airport in Arlington, Va., Wednesday, Jan. 11, 2023." data-testid="prism-image" draggable="false" src="https://i.abcnewsfe.com/a/2b5ef9d0-6caa-4597-893b-48a6a419bb31/airport-file-ap-jef-240424_1713963231114_hpMain.jpg"><figcaption><div data-testid="prism-caption"><p><span data-testid="prism-truncate"><span><span>A person walks through the terminal as planes remain at gates at Ronald Reagan Washington National Airport in Arlington, Va., Wednesday, Jan. 11, 2023.</span></span></span></p><p><span>Patrick Semansky/AP, FILE</span></p></div></figcaption></figure></div><p>DOT will also require airlines to give cash refunds if your bags are lost and not delivered within 12 hours.</p><p>The refunds must be issued within seven days, according to the new DOT rules, and must be in cash unless the passenger chooses another form of compensation. Airlines can no longer issue refunds in forms of vouchers or credits when consumers are entitled to receive cash.</p><p>Airlines will have six months to comply with the new rules.</p><div data-testid="prism-inline-image"><figure data-testid="prism-figure"><img alt="PHOTO: U.S. Secretary of Transportation Pete Buttigieg speaks at a press conference at the Reagan National Airport on April 24, 2024." data-testid="prism-image" draggable="false" src="https://i.abcnewsfe.com/a/22e4aad0-0b73-4e97-a784-ba8ba3bf64af/airport-abc-ml-240424_1713973025448_hpMain_16x9.jpg"><figcaption><div data-testid="prism-caption"><p><span data-testid="prism-truncate"><span><span>U.S. Secretary of Transportation Pete Buttigieg speaks at a press conference at the Reagan National Airport on April 24, 2024.</span></span></span></p><p><span>ABC News, POOL</span></p></div></figcaption></figure></div><p>"Passengers deserve to get their money back when an airline owes them -- without headaches or haggling," Buttigieg said in a statement.</p><p>The DOT said it is also working on rules related to family seating fees, enhancing rights for wheelchair-traveling passengers for safe and dignified travel and mandating compensation and amenities if flights are delayed or canceled by airlines.</p><p>Buttigieg said the DOT is also protecting airline passengers from being surprised by hidden fees -- a move he estimates will have Americans billions of dollars every year.</p><section data-testid="prism-collection"><header><p><h2>Related Stories</h2></p></header></section><p><a data-testid="prism-linkbase" href="https://www.transportation.gov/briefing-room/biden-harris-administration-announces-final-rule-requiring-automatic-refunds-airline" target="_blank">The DOT rules</a> include that passengers will receive refunds for extra services paid for and not provided, such as Wi-Fi, seat selection or inflight entertainment.</p><p>The rules come after the agency <a data-testid="prism-linkbase" href="https://abcnews.go.com/International/southwest-airlines-fined-record-140-million-dot-2022/story?id=105733507" target="_blank">handed Southwest Airlines a record $140 million fine</a> for its <a data-testid="prism-linkbase" href="https://abcnews.go.com/Business/stranded-southwest-customers-details-exhaustive-efforts-home-amid/story?id=95848764" target="_blank">operational meltdown</a> during the 2022 holiday travel season.</p><p>Buttigieg said Southwest's fine sets a "new standard" for airlines and passenger rights.</p><p>"To be clear, we want the airline sector to thrive. It is why we put so much into helping them survive the pandemic and honestly it's why we're being so rigorous on passenger protection," he said.</p><p>Buttigieg reiterated that refund requirements are already the standard for airlines, but the new DOT rules hold the airlines to account and makes sure passengers get the "refunds that are owed to them."</p><p>"Airlines are not enthusiastic about us holding them to a higher standard," Buttigieg said, adding that he "knows they will be able to adapt to this."</p><p>Airlines for America, the trade association for the country's leading passenger and cargo airlines, told ABC News in a statement that its members "offer a range of options -- including fully refundable fares." Is said consumers are "given the choice of refundable ticket options with terms and conditions that best fit their needs at first search results."</p><p>The group said the 11 largest U.S. airlines issued $43 billion in customer refunds from 2020 through 2023 nearly $11 billion in refunds just last year.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bicycle use now exceeds car use in Paris (116 pts)]]></title>
            <link>https://english.elpais.com/lifestyle/2024-04-24/the-cycling-revolution-in-paris-continues-bicycle-use-now-exceeds-car-use.html</link>
            <guid>40150545</guid>
            <pubDate>Wed, 24 Apr 2024 22:20:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://english.elpais.com/lifestyle/2024-04-24/the-cycling-revolution-in-paris-continues-bicycle-use-now-exceeds-car-use.html">https://english.elpais.com/lifestyle/2024-04-24/the-cycling-revolution-in-paris-continues-bicycle-use-now-exceeds-car-use.html</a>, See on <a href="https://news.ycombinator.com/item?id=40150545">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-dtm-region="articulo_cuerpo"><p>It’s rush hour on Rue de Rivoli, one of the main arteries of the French capital. The bicycles pass one after another in quick succession, ringing their bell when a pedestrian crosses without looking. Five years ago, it was cars that monopolized this three-kilometer axis that runs in front of Paris City Hall and <a href="https://english.elpais.com/culture/2023-07-01/the-restitution-of-art-to-its-origins.html">the Louvre Museum</a>. Not anymore. Two-wheel transportation has prevailed, favored by a paradigm shift in urban mobility. The cycling revolution, promoted by local authorities, is beginning to bear fruit: according to a recent study by the Paris Région Institute, a public agency, bicycles already surpass cars as a means of transportation in the interior of Paris, accounting for 11.2% of trips compared to 4.3%. A similar trend is seen in trips between the suburbs and the city center: 14% are made by bicycle and 11.8% by car.</p><p>Rue de Rivoli, with its two-way cycle lanes and its dedicated lane for buses and taxis, is perhaps one of the most emblematic examples of the change that the city has experienced in recent years. But it’s not the only one. The perpendicular Boulevard de Sébastopol has become the route most frequented by cyclists, with figures that usually exceed 10,000 daily trips, according to the count kept by the association Paris en Selle.</p><p>When it is sunny, the density can be so high that traffic jams sometimes occur, and the narrowness of the lane causes friction between bikes, creating moments of tension. City officials led by Mayor Anne Hidalgo, a Socialist, have tried to remedy this situation by building other bike lanes on parallel streets.</p><p>From north to south and east to west, the map of the capital has been filled with infrastructure that gives the bicycle a privileged place. Paris has more than 1,000 kilometers (621 miles) of facilities adapted for cyclists, including more than 300 km (186 m) of bike lanes and 52 km (32 m) of provisional lanes, according to the latest available municipal data, from 2021. The rest are lanes shared with cars or lanes only marked with paint on the ground.</p><p>By 2026, local officials want the entire city to be suitable for two-wheel transportation. To this end, it has set aside $250 million, $100 million more than in Hidalgo’s first term. This summer’s Olympic Games will serve as an accelerator of this new “bike plan,” with routes that will allow access to the Olympic venues.</p><p>But there is still some way to go. The Paris en Selle association warns that only 27% of the “bike plan” has been carried out despite the fact that 62% of Hidalgo’s second term in office has already elapsed. The Deputy Mayor of Paris for Transportation, David Belliard, acknowledges that there are delays, but does not lose hope. Progress is noticeable.</p><p>In some thoroughfares, the number of bikes already surpasses vehicles. Between 2022 and 2023, the use of bike lanes doubled at peak times, according to data collected by the capital’s 128 counters. The goal is to create a network of cycling paths that run along the busiest metro lines, to unclog public transit and offer an equally fast and safe alternative for commuters.</p><p>The number of people who travel by bicycle has increased exponentially. Vélib, the municipal urban bicycle rental service, has increased its fleet with 3,000 new bikes since March. Edmée Doroszlai, a 62-year-old Parisian, still remembers the first time she started riding on two wheels in the early 1980s. “It was monstrous, almost impossible and very dangerous,” she says from the center of Paris, with her bike at her side.</p><p>“There is also a big change in how men behave when they see a woman on a bike,” she adds, alluding to the normalization of its use. The presence of adapted infrastructure, she confirms, has encouraged her to use it more, as have many families who travel on cycle paths with small children.</p><p>“We still have to go further,” Belliard insisted in an interview with BFMTV earlier this month. The councilor was reacting to the study by the Paris Région Institute, the regional urban planning and environment agency, which indicated that 11.2% of trips in Paris were made by bike between 2022 and 2023, compared to 4.3% by car. The change in trend is clear. In 2021, two wheels still represented 5.6% of trips, while cars were 9%, according to Belliard.</p><figure><span><img alt="Notre Dame" decoding="auto" height="262" srcset="https://imagenes.elpais.com/resizer/v2/QUBHQ6LEH2CCT3MOQ2GH7ABCC4.jpg?auth=9815ecb7d31b0dfd6408c2465c80f0735bd2e8c3f36692e516985133b830715d&amp;width=414 414w,https://imagenes.elpais.com/resizer/v2/QUBHQ6LEH2CCT3MOQ2GH7ABCC4.jpg?auth=9815ecb7d31b0dfd6408c2465c80f0735bd2e8c3f36692e516985133b830715d&amp;width=828 640w,https://imagenes.elpais.com/resizer/v2/QUBHQ6LEH2CCT3MOQ2GH7ABCC4.jpg?auth=9815ecb7d31b0dfd6408c2465c80f0735bd2e8c3f36692e516985133b830715d&amp;width=980 1000w,https://imagenes.elpais.com/resizer/v2/QUBHQ6LEH2CCT3MOQ2GH7ABCC4.jpg?auth=9815ecb7d31b0dfd6408c2465c80f0735bd2e8c3f36692e516985133b830715d&amp;width=1960 1960w" width="414" sizes="(min-width:1199px) 1155px,(min-width:1001px) calc(100vw - 44px),(min-width:768px) 767px, 100vw" src="https://imagenes.elpais.com/resizer/v2/QUBHQ6LEH2CCT3MOQ2GH7ABCC4.jpg?auth=9815ecb7d31b0dfd6408c2465c80f0735bd2e8c3f36692e516985133b830715d&amp;width=414" loading="lazy"></span><figcaption><span>Bike path on the banks of the Seine, in Paris.</span><span>Ciclistas y 'pic-nics' en la orilla sur del Sena, en París (Jon Hicks)</span></figcaption></figure><p>In addition to surpassing the car as a means of travel within Paris, the research indicates that residents of the nearest suburbs also prefer to use the bike, with 14% of trips compared to 11.8% for cars. The figures are even better during rush hour, when 18.9% of trips are made by bike and only 6.6% by car. Travel on foot, however, continues to lead mobility within the municipality with 53%, followed by those made on public transit, with 30%. The study was carried out with 3,337 residents of the capital region who agreed to be fitted with a GPS tracker.</p><p>The bike gradually gained popularity during the public transist strike that paralyzed the capital in December 2019, in protest of <a href="https://english.elpais.com/international/2023-03-17/france-braces-for-more-unrest-after-macron-passes-pension-reform-by-decree.html">President Emmanuel Macron’s pension reform</a>. But it was also prominent <a href="https://english.elpais.com/society/2023-05-20/millions-ditched-cars-for-bikes-during-the-pandemic-these-cities-want-the-habit-to-stick.html">after the Covid confinement</a> in 2020, when the city tested the so-called “coronapistes,” temporary cycling lanes that progressively became permanent. Like Rivoli’s.</p><h3>Better connections with neighborhoods</h3><p>“The network is very good,” says Arnaud Faure, 31, co-owner of the Bivouac Cycles bicycle repair shop in Saint Ouen, a banlieue (suburb) in the north of the city. He has been in the French capital for two years and every day he travels 13 km (8 miles) to get to work and again the same to get back home. He says that almost all of his journey is along bike paths. But he cites two drawbacks. On one hand, the lack of safe parking, a determining factor for bicycle use. On the other hand, the fact that “just like in big cities, traffic is dense and can sometimes be dangerous.”</p><p>In 12 years, car traffic has decreased by 40% in Paris, according to City Hall. “But these rapid changes in habits have been accompanied by tension” in the streets, the mayor has admitted. “It takes time for everyone to find their place and feel safe,” she added, following road regulations that seek to raise awareness about the shared use of public space. Last summer, posters appeared throughout the city reminding everyone that pedestrians have the priority and that the speed limit for cars is 30 km/h (18 mph).</p><p>The city’s plan includes increasing the number of parking spaces for bicycles. The goal is to build more than 130,000 new spots. “Parking at train stations must be developed on a massive scale,” stresses Aymeric Cotard, 29, a member of the association Mieux se déplacer à bicyclette [Better to get around by bike]. One of the large projects that should be completed this year, with 1,200 spaces, is located just behind the Gare du Nord, one of the busiest stations in France. For Cotard, however, it will be insufficient. In <a href="https://english.elpais.com/international/2023-02-27/we-didnt-know-if-they-were-being-taken-to-another-country-where-do-stolen-dutch-bikes-go.html">the Dutch city</a> of Utrecht, the station has 12,500 spaces for bikes.</p><p>The idea is that people who live in the suburbs and take the train daily to work will also use the bicycle once they arrive in Paris. It is one of the main challenges of the coming years, along with facilitating continuous journeys between the capital and its suburbs. “This requires the banlieue cities to do their job and the city of Paris to also improve its entrances, which are inhospitable and unpleasant by bike,” warns Cotard. In addition, it is necessary to provide infrastructure for a flow of cyclists that will be even greater in the future.</p><p>The process takes time and has encountered some opposition. But the morphology of the city is changing, adapting to the bike. And, with it, its resilience to the effects of climate change.</p><p><i>Sign up for </i><a href="https://plus.elpais.com/newsletters/lnp/1/333/?lang=en"><i><u>our weekly newsletter</u></i></a> <i>to get more English-language news coverage from EL PAÍS USA Edition</i></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Magic Numbers (138 pts)]]></title>
            <link>https://exple.tive.org/blarg/2024/04/24/magic-numbers/</link>
            <guid>40149446</guid>
            <pubDate>Wed, 24 Apr 2024 20:50:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://exple.tive.org/blarg/2024/04/24/magic-numbers/">https://exple.tive.org/blarg/2024/04/24/magic-numbers/</a>, See on <a href="https://news.ycombinator.com/item?id=40149446">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-6105" role="article" itemscope="" itemtype="http://schema.org/BlogPosting">

	<header>

		
		

	</header>

	<section itemprop="articleBody">

		<p><strong>April 24, 2024</strong></p>

		<p>The <a href="https://en.wikipedia.org/wiki/Maximum_transmission_unit">Maximum Transmission Unit</a> – MTU – of an <a href="https://en.wikipedia.org/wiki/Ethernet">Ethernet</a> frame is 1500 bytes.</p>
<p>1500 bytes is a bit out there as numbers go, or at least it seems that way if you touch computers for a living. It’s not a power of two or anywhere close, it’s <em>suspiciously</em> base-ten-round, and computers don’t care all that much about base ten, so how did we get here? </p>
<p>Well, today I learned that the size of an Ethernet header – 36 bytes – comes from the fact that MTU plus Ethernet header is 1536 bytes, which is 12288 bits, which takes 2^12 microseconds to transmit at 3Mb/second, because the <a href="https://en.wikipedia.org/wiki/Xerox_Alto">Xerox Alto</a> computer for which Ethernet was invented had a internal data path that ran at 3Mhz, so the interface could <em>just</em> write the bits into the Alto’s memory at the precise speed at which they arrived, saving the very-expensive-then cost of extra silicon for an interface or any buffering hardware. </p>
<p>Now, “we need to pick just the right magic number <em>here</em> so we can take data straight off the wire and blow it directly into the memory of this specific machine over <em>there</em>” is to any modern sensibilities insane. It’s obviously, dangerously insane. But back when the idea of network security didn’t exist because computers barely existed and networks mostly didn’t exist and unvetted and unsanctioned access to those networks definitely didn’t exist, I bet it seemed like a very reasonable tradeoff.</p>
<p>It really is amazing how many of the things we sort of ambiently accept as standards today, if we even realize we’re making that decision at all, are what they are only because some now-esoteric property of the now-esoteric hardware on which the tech was first invented let the inventors save a few bucks.</p>

		
	</section> <!-- end article section -->

	

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[IBM to Acquire HashiCorp, Inc for $6.4 billion (352 pts)]]></title>
            <link>https://newsroom.ibm.com/2024-04-24-IBM-to-Acquire-HashiCorp-Inc-Creating-a-Comprehensive-End-to-End-Hybrid-Cloud-Platform</link>
            <guid>40149136</guid>
            <pubDate>Wed, 24 Apr 2024 20:24:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newsroom.ibm.com/2024-04-24-IBM-to-Acquire-HashiCorp-Inc-Creating-a-Comprehensive-End-to-End-Hybrid-Cloud-Platform">https://newsroom.ibm.com/2024-04-24-IBM-to-Acquire-HashiCorp-Inc-Creating-a-Comprehensive-End-to-End-Hybrid-Cloud-Platform</a>, See on <a href="https://news.ycombinator.com/item?id=40149136">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wd_move_content_up">

<p>$6.4 billion acquisition adds suite of leading hybrid and multi-cloud lifecycle management products to help clients grappling with today's AI-driven application growth and complexity</p><p>HashiCorp's capabilities to drive significant synergies across multiple strategic growth areas for IBM, including Red Hat, watsonx, data security, IT automation and Consulting</p><p>As a part of IBM, HashiCorp is expected to accelerate innovation and enhance its go-to-market, growth and monetization initiatives</p><p>Transaction expected to be accretive to Adjusted EBITDA within the first full year, post close, and free cash flow in year two</p>
<p>Apr 24, 2024</p>

			
		
</div><div wd_resize="formatNews" wd_print_url="https://newsroom.ibm.com/2024-04-24-IBM-to-Acquire-HashiCorp-Inc-Creating-a-Comprehensive-End-to-End-Hybrid-Cloud-Platform?printable=1"><p>,  /<a href="http://www.prnewswire.com/" target="_blank">PRNewswire</a>/ -- IBM (NYSE: <a href="http://www.ibm.com/investor" rel="nofollow" target="_blank">IBM</a>) and HashiCorp Inc. (NASDAQ: HCP), a leading multi-cloud infrastructure automation company, today announced they have entered into a definitive agreement under which IBM will acquire HashiCorp for <span>$35</span> per share in cash, representing an enterprise value of <span>$6.4 billion</span>. HashiCorp's suite of products provides enterprises with extensive Infrastructure Lifecycle Management and Security Lifecycle Management capabilities to enable organizations to automate their hybrid and multi-cloud environments. Today's announcement is a continuation of IBM's deep focus and investment in hybrid cloud and AI, the two most transformational technologies for clients today.</p>

<p><a href="https://mma.prnewswire.com/media/2319830/IBM_LOGO_1.html" rel="nofollow" target="_blank"><img alt="IBM Corporation logo. (PRNewsfoto/IBM Corporation)" src="https://mma.prnewswire.com/media/2319830/IBM_LOGO_1.jpg" title="IBM Corporation logo. (PRNewsfoto/IBM Corporation)"> </a></p>

<p>"Enterprise clients are wrestling with an unprecedented expansion in infrastructure and applications across public and private clouds, as well as on-prem environments. The global excitement surrounding generative AI has exacerbated these challenges and CIOs and developers are up against dramatic complexity in their tech strategies," said <span>Arvind Krishna</span>, IBM chairman and chief executive officer. "HashiCorp has a proven track record of enabling clients to manage the complexity of today's infrastructure and application sprawl. Combining IBM's portfolio and expertise with HashiCorp's capabilities and talent will create a comprehensive hybrid cloud platform designed for the AI era."</p>

<p>The rise of cloud-native workloads and associated applications is driving a radical expansion in the number of cloud workloads enterprises are managing. In addition, generative AI deployment continues to grow alongside traditional workloads. As a result, developers are working with increasingly heterogeneous, dynamic, and complex infrastructure strategies. This represents a massive challenge for technology professionals.</p>

<p>HashiCorp's capabilities enable enterprises to use automation to deliver lifecycle management for infrastructure and security, providing a system of record for the critical workflows needed for hybrid and multi-cloud environments. HashiCorp's Terraform is the industry standard for infrastructure provisioning in these environments. HashiCorp's offerings help clients take a cloud-agnostic, and highly interoperable approach to multi-cloud management, and complement IBM's commitment to industry collaboration (including deep and expanding partnerships with hyperscale cloud service providers), developer communities, and open-source hybrid cloud and AI innovation.</p>

<p>"Our strategy at its core is about enabling companies to innovate in the cloud, while providing a consistent approach to managing cloud at scale. The need for effective management and automation is critical with the rise of multi-cloud and hybrid cloud, which is being accelerated by today's AI revolution," said <span>Armon Dadgar</span>, HashiCorp co-founder and chief technology officer. "I'm incredibly excited by today's news and to be joining IBM to accelerate HashiCorp's mission and expand access to our products to an even broader set of developers and enterprises."</p>

<p>"Today is an exciting day for our dedicated teams across the world as well as the developer communities we serve," said <span>Dave McJannet</span>, HashiCorp chief executive officer. "IBM's leadership in hybrid cloud along with its rich history of innovation, make it the ideal home for HashiCorp as we enter the next phase of our growth journey. I'm proud of the work we've done as a standalone company, I am excited to be able to help our customers further, and I look forward to the future of HashiCorp as part of IBM."</p>

<p><b>Transaction Rationale</b></p>

<ul type="disc">
	<li><b>Strong Strategic Fit – </b>The acquisition of HashiCorp by IBM creates a comprehensive end-to-end hybrid cloud platform built for AI-driven complexity. The combination of each company's portfolio and talent will deliver clients extensive application, infrastructure and security lifecycle management capabilities</li>
	<li><b>Accelerates growth in key focus areas – </b>Upon close, HashiCorp is expected to drive significant synergies for IBM, including across multiple strategic growth areas like Red Hat, watsonx, data security, IT automation and Consulting. For example, the powerful combination of Red Hat's Ansible Automation Platform's configuration management and Terraform's automation will simplify provisioning and configuration of applications across hybrid cloud environments. The two companies also anticipate an acceleration of HashiCorp's growth initiatives by leveraging IBM's world-class go-to-market strategy, scale, and reach, operating in more than 175 countries across the globe</li>
	<li><b>Expands Total Addressable Market (TAM) – </b>The acquisition will create the opportunity to deliver more comprehensive hybrid and multi-cloud offerings to enterprise clients. HashiCorp's offerings, combined with IBM and Red Hat, will give clients a platform to automate the deployment and orchestration of workloads across evolving infrastructure including hyperscale cloud service providers, private clouds and on-prem environments. This will enhance IBM's ability to address the total cloud opportunity, which according to IDC had a TAM of <span>$1.1 trillion</span> in 2023, with a compound annual growth rate in the high teens through 2027.<sup>1</sup></li>
	<li><b>Attractive Financial Opportunity – </b>The transaction will accelerate IBM's growth profile over time driven by go-to-market and product synergies. This growth combined with operating efficiencies, is expected to achieve substantial near-term margin expansion for the acquired business. It is anticipated that the transaction will be accretive to Adjusted EBITDA within the first full year, post close, and free cash flow in year two.</li>
</ul>

<p>HashiCorp boasts a roster of more than 4,400 clients, including Bloomberg, Comcast, Deutsche Bank, GitHub, J.P Morgan Chase, Starbucks and Vodafone. HashiCorp's offerings have widescale adoption in the developer community and are used by 85% of the Fortune 500. Their community products across infrastructure and security were downloaded more than 500 million times in HashiCorp's FY2024 and include:</p>

<ul type="disc">
	<li><b>Terraform</b> – provides organizations with a single workflow to provision their cloud, private datacenter, and SaaS infrastructure and continuously manage infrastructure throughout its lifecycle</li>
	<li><b>Vault</b> – provides organizations with identity-based security to automatically authenticate and authorize access to secrets and other sensitive data</li>
	<li><b>Additional products</b> – <i>Boundary</i> for secure remote access;<i> Consul</i> for service-based networking; <i>Nomad</i> for workload orchestration; <i>Packer</i> for building and managing images as code; and <i>Waypoint</i> internal developer platform</li>
</ul>

<p><b>Transaction Details</b></p>

<p>Under the terms of the agreement, IBM will acquire HashiCorp for <span>$35</span> per share in cash, or <span>$6.4 billion</span> enterprise value, net of cash. HashiCorp will be acquired with available cash on hand.</p>

<p>The boards of directors of IBM and HashiCorp have both approved the transaction. The acquisition is subject to approval by HashiCorp shareholders, regulatory approvals and other customary closing conditions.</p>

<p>The Company's largest shareholders and investors, who collectively hold approximately 43% of the voting power of&nbsp;HashiCorp's outstanding common stock, entered into a voting agreement with IBM pursuant to which each has agreed to vote all of their common shares in favor of the transaction and against any alternative transactions.</p>

<p>The transaction is expected to close by the end of 2024.</p>

<p>____________________<br>
<sup>1</sup> The total cloud opportunity is the sum of the cloud-directed spends across Hardware, IT services and SW for Private and Public cloud implementation, sourced from IDC's Worldwide Black Book Live Edition, <span>March 2024</span> (V1 2024)</p>

<p><b>Conference Call Details</b></p>

<p>IBM's regular quarterly earnings conference call is scheduled to begin at <span>5:00 p.m. ET</span>, today. The Webcast may be accessed <a href="https://www.ibm.com/investor/events/earnings-1q24" rel="nofollow" target="_blank">here</a>. Presentation charts will be available shortly before the Webcast.</p>

<p><b>About IBM</b></p>

<p>IBM is a leading provider of global hybrid cloud and AI, and consulting expertise. We help clients in more than 175 countries capitalize on insights from their data, streamline business processes, reduce costs and gain the competitive edge in their industries. Thousands of government and corporate entities in critical infrastructure areas such as financial services, telecommunications and healthcare rely on IBM's hybrid cloud platform and Red Hat OpenShift to affect their digital transformations quickly, efficiently and securely. IBM's breakthrough innovations in AI, quantum computing, industry-specific cloud solutions and consulting deliver open and flexible options to our clients. All of this is backed by IBM's legendary commitment to trust, transparency, responsibility, inclusivity and service. Visit&nbsp;<a href="http://www.ibm.com/" rel="nofollow" target="_blank">www.ibm.com</a>&nbsp;for more information.&nbsp;</p>

<p><b>About HashiCorp</b></p>

<p>HashiCorp&nbsp;is The Infrastructure Cloud™ company, helping organizations automate multi-cloud and hybrid environments with Infrastructure Lifecycle Management and Security Lifecycle Management. HashiCorp&nbsp;offers The Infrastructure Cloud on the HashiCorp&nbsp;Cloud Platform (HCP) for managed cloud services, as well as self-hosted enterprise offerings and community source-available products. The company is headquartered in <span>San Francisco, California</span>. For more information, visit&nbsp;<a href="https://urldefense.proofpoint.com/v2/url?u=http-3A__hashicorp.com&amp;d=DwMFaQ&amp;c=BSDicqBQBDjDI9RkVyTcHQ&amp;r=W9dONwI1yR8TY6fdJkjNwdlDQU2ROvWbv1mlvkWQFLs&amp;m=uOTnwadDTxZ2XD2uC6bDCFPG-9K-Oq5GBVfeuYs3n7-_Z1xbsLo_2585JrS2L788&amp;s=RF6C-_LsY0GUJ3MnM2K_hfDsjYfnI-WCPo4lNlnulgE&amp;e=" rel="nofollow" target="_blank">HashiCorp.com</a>.</p>

<p><b>Press Contacts:</b></p>

<p>IBM:<br>
<span>Tim Davidson</span>, 914-844-7847<br>
<a href="mailto:tfdavids@us.ibm.com" rel="nofollow" target="_blank">tfdavids@us.ibm.com</a></p>

<p>HashiCorp:<br>
<span>Matthew Sherman</span> / <span>Jed Repko</span> / <span>Haley Salas</span> / <span>Joycelyn Barnett</span><br>
<span>Joele Frank</span>, Wilkinson Brimmer Katcher<br>
212-355-4449</p>



<p><i><b>Additional Information and Where to Find It</b></i></p>

<p><i>HashiCorp, Inc. ("HashiCorp"), the members of HashiCorp's board of directors and certain of HashiCorp's executive officers are participants in the solicitation of proxies from stockholders in connection with the pending acquisition of HashiCorp (the "Transaction"). HashiCorp plans to file a proxy statement (the "Transaction Proxy Statement") with the Securities and Exchange Commission (the "SEC") in connection with the solicitation of proxies to approve the Transaction. <span>David McJannet</span>, <span>Armon Dadgar</span>, <span>Susan St. Ledger</span>, <span>Todd Ford</span>, <span>David Henshall</span>, <span>Glenn Solomon</span> and <span>Sigal Zarmi</span>, all of whom are members of HashiCorp's board of directors, and <span>Navam Welihinda</span>, HashiCorp's chief financial officer, are participants in HashiCorp's solicitation. Information regarding such participants, including their direct or indirect interests, by security holdings or otherwise, will be included in the Transaction Proxy Statement and other relevant documents to be filed with the SEC in connection with the Transaction. Additional information about such participants is available under the captions "Board of Directors and Corporate Governance," "Executive Officers" and "Security Ownership of Certain Beneficial Owners and Management" in HashiCorp's definitive proxy statement in connection with its 2023 Annual Meeting of Stockholders (the "2023 Proxy Statement"), which was filed with the SEC on <span>May 17, 2023</span> (and is available at&nbsp;<a href="https://urldefense.proofpoint.com/v2/url?u=https-3A__www.sec.gov_ix-3Fdoc-3D_Archives_edgar_data_1720671_000114036123025250_ny20008192x1-5Fdef14a.htm&amp;d=DwMGaQ&amp;c=BSDicqBQBDjDI9RkVyTcHQ&amp;r=W9dONwI1yR8TY6fdJkjNwdlDQU2ROvWbv1mlvkWQFLs&amp;m=WIP1VyxuvBGNlzTUaYuNxHpbet03ywNI-NapdbhVOxO7G4LhtR2egnoPZFg5wgFk&amp;s=DAxP0uH2PZLVIrXRiK8JS2ywGdYGNx-kvMHxAEWkP_4&amp;e=" rel="nofollow" target="_blank">https://www.sec.gov/ix?doc=/Archives/edgar/data/1720671/000114036123025250/ny20008192x1_def14a.htm</a>). To the extent that holdings of HashiCorp's securities have changed since the amounts printed in the 2023 Proxy Statement, such changes have been or will be reflected on Statements of Change in Ownership on Form 4 filed with the SEC (which are available at&nbsp;<a href="https://urldefense.proofpoint.com/v2/url?u=https-3A__www.sec.gov_cgi-2Dbin_browse-2Dedgar-3Faction-3Dgetcompany-26CIK-3D0001720671-26type-3D-26dateb-3D-26owner-3Donly-26count-3D40-26search-5Ftext-3D&amp;d=DwMGaQ&amp;c=BSDicqBQBDjDI9RkVyTcHQ&amp;r=W9dONwI1yR8TY6fdJkjNwdlDQU2ROvWbv1mlvkWQFLs&amp;m=WIP1VyxuvBGNlzTUaYuNxHpbet03ywNI-NapdbhVOxO7G4LhtR2egnoPZFg5wgFk&amp;s=bqavEZgqjNge6kAvbmk0zLhMXTAYmIjA5rzwhQaJDd8&amp;e=" rel="nofollow" target="_blank">https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&amp;CIK=0001720671&amp;type=&amp;dateb=&amp;owner=only&amp;count=40&amp;search_text=</a>). Information regarding HashiCorp's transactions with related persons is set forth under the caption "Related Person Transactions" in the 2023 Proxy Statement. Certain illustrative information regarding the payments to that may be owed, and the circumstances in which they may be owed, to HashiCorp's named executive officers in a change of control of HashiCorp is set forth under the caption "Executive Compensation—Potential Payments upon Termination or Change in Control" in the 2023 Proxy Statement. With respect to Ms. St. Ledger, certain of such illustrative information is contained in the Current Report on Form 8-K filed with the SEC on <span>June 7, 2023</span> (and is available at&nbsp;<a href="https://urldefense.proofpoint.com/v2/url?u=https-3A__www.sec.gov_ix-3Fdoc-3D_Archives_edgar_data_1720671_000162828023021270_hcp-2D20230607.htm&amp;d=DwMGaQ&amp;c=BSDicqBQBDjDI9RkVyTcHQ&amp;r=W9dONwI1yR8TY6fdJkjNwdlDQU2ROvWbv1mlvkWQFLs&amp;m=WIP1VyxuvBGNlzTUaYuNxHpbet03ywNI-NapdbhVOxO7G4LhtR2egnoPZFg5wgFk&amp;s=4QQvgxl7VrRT-9dgZy45Vw0gBhmWz7KH8fzaGjGwkIk&amp;e=" rel="nofollow" target="_blank">https://www.sec.gov/ix?doc=/Archives/edgar/data/1720671/000162828023021270/hcp-20230607.htm</a>).&nbsp;Promptly after filing the definitive Transaction Proxy Statement with the SEC, HashiCorp will mail the definitive Transaction Proxy Statement and a WHITE proxy card to each stockholder entitled to vote at the special meeting to consider the Transaction. STOCKHOLDERS ARE URGED TO READ THE TRANSACTION PROXY STATEMENT (INCLUDING ANY AMENDMENTS OR SUPPLEMENTS THERETO) AND ANY OTHER RELEVANT DOCUMENTS THAT HASHICORP WILL FILE WITH THE SEC WHEN THEY BECOME AVAILABLE BECAUSE THEY WILL CONTAIN IMPORTANT INFORMATION. Stockholders may obtain, free of charge, the preliminary and definitive versions of the Transaction Proxy Statement, any amendments or supplements thereto, and any other relevant documents filed by HashiCorp with the SEC in connection with the Transaction at the SEC's website (<a href="https://urldefense.proofpoint.com/v2/url?u=http-3A__www.sec.gov&amp;d=DwMGaQ&amp;c=BSDicqBQBDjDI9RkVyTcHQ&amp;r=W9dONwI1yR8TY6fdJkjNwdlDQU2ROvWbv1mlvkWQFLs&amp;m=WIP1VyxuvBGNlzTUaYuNxHpbet03ywNI-NapdbhVOxO7G4LhtR2egnoPZFg5wgFk&amp;s=97Mk6TtDEGohehH043KUy50rAX9jXPHlNPxdtGwcYPc&amp;e=" rel="nofollow" target="_blank">http://www.sec.gov</a>). Copies of HashiCorp's definitive Transaction Proxy Statement, any amendments or supplements thereto, and any other relevant documents filed by HashiCorp with the SEC in connection with the Transaction will also be available, free of charge, at HashiCorp's investor relations website (<a href="https://urldefense.proofpoint.com/v2/url?u=https-3A__ir.hashicorp.com_&amp;d=DwMGaQ&amp;c=BSDicqBQBDjDI9RkVyTcHQ&amp;r=W9dONwI1yR8TY6fdJkjNwdlDQU2ROvWbv1mlvkWQFLs&amp;m=WIP1VyxuvBGNlzTUaYuNxHpbet03ywNI-NapdbhVOxO7G4LhtR2egnoPZFg5wgFk&amp;s=zgti-5JjrLH_7Ja9Wdc81ipMwWNQ-4K0YQu2LW5qZnw&amp;e=" rel="nofollow" target="_blank">https://ir.hashicorp.com/</a>), or by emailing HashiCorp's investor relations department (<a href="mailto:ir@hashicorp.com" rel="nofollow" target="_blank">ir@hashicorp.com</a>).</i></p>

<p><i><b>Forward-Looking Statements</b></i></p>

<p><i>Certain statements contained in this communication may be characterized as forward-looking under the Private Securities Litigation Reform Act of 1995. These statements involve a number of risks, uncertainties and other factors that could cause actual results to differ materially.</i></p>

<p><i>Statements in this communication regarding IBM and HashiCorp that are forward-looking may include statements regarding: (i) the Transaction; (ii) the expected timing of the closing of the Transaction; (iii) considerations taken into account in approving and entering into the Transaction; (iv) the anticipated benefits to, or impact of, the Transaction on IBM's and HashiCorp's businesses; and (v) expectations for IBM and HashiCorp following the closing of the Transaction. There can be no assurance that the Transaction will be consummated.</i></p>

<p><i>Risks and uncertainties that could cause actual results to differ materially from those indicated in the forward-looking statements, in addition to those identified above, include: (i) the possibility that the conditions to the closing of the Transaction are not satisfied, including the risk that required approvals from HashiCorp's stockholders for the Transaction or required regulatory approvals to consummate the Transaction are not obtained, on a timely basis or at all; (ii) the occurrence of any event, change or other circumstance that could give rise to a right to terminate the Transaction, including in circumstances requiring HashiCorp to pay a termination fee; (iii) possible disruption related to the Transaction to IBM's and HashiCorp's current plans, operations and business relationships, including through the loss of customers and employees; (iv) the amount of the costs, fees, expenses and other charges incurred by IBM and HashiCorp related to the Transaction; (v) the risk that IBM's or HashiCorp's stock price may fluctuate during the pendency of the Transaction and may decline if the Transaction is not completed; (vi) the diversion of IBM and HashiCorp management's time and attention from ongoing business operations and opportunities; (vii) the response of competitors and other market participants to the Transaction; (viii) potential litigation relating to the Transaction; (ix) uncertainty as to timing of completion of the Transaction and the ability of each party to consummate the Transaction; and (x) other risks and uncertainties detailed in the periodic reports that IBM and HashiCorp filed with the SEC, including IBM's and HashiCorp's respective Annual Reports on Form 10-K.&nbsp; All forward-looking statements in this communication are based on information available to IBM and HashiCorp as of the date of this communication, and, except as required by law, IBM and HashiCorp do not assume any obligation to update the forward-looking statements provided to reflect events that occur or circumstances that exist after the date on which they were made.</i></p>

<p>SOURCE IBM</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[IBM to buy HashiCorp in $6.4B deal (472 pts)]]></title>
            <link>https://www.reuters.com/markets/deals/ibm-buy-hashicorp-64-billion-deal-expand-cloud-software-2024-04-24/</link>
            <guid>40149095</guid>
            <pubDate>Wed, 24 Apr 2024 20:21:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/markets/deals/ibm-buy-hashicorp-64-billion-deal-expand-cloud-software-2024-04-24/">https://www.reuters.com/markets/deals/ibm-buy-hashicorp-64-billion-deal-expand-cloud-software-2024-04-24/</a>, See on <a href="https://news.ycombinator.com/item?id=40149095">Hacker News</a></p>
Couldn't get https://www.reuters.com/markets/deals/ibm-buy-hashicorp-64-billion-deal-expand-cloud-software-2024-04-24/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Eric Schmidt-backed Augment, a GitHub Copilot rival, launches out of stealth (122 pts)]]></title>
            <link>https://techcrunch.com/2024/04/24/eric-schmidt-backed-augment-a-github-copilot-rival-launches-out-of-stealth-with-252m/</link>
            <guid>40149071</guid>
            <pubDate>Wed, 24 Apr 2024 20:19:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2024/04/24/eric-schmidt-backed-augment-a-github-copilot-rival-launches-out-of-stealth-with-252m/">https://techcrunch.com/2024/04/24/eric-schmidt-backed-augment-a-github-copilot-rival-launches-out-of-stealth-with-252m/</a>, See on <a href="https://news.ycombinator.com/item?id=40149071">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p id="speakable-summary">AI is supercharging coding — and developers are embracing it.</p>
<p>In a recent StackOverflow poll, 44% of software engineers said that they <a href="https://stackoverflow.blog/2023/06/14/hype-or-not-developers-have-something-to-say-about-ai/" target="_blank" rel="noopener">use AI tools as part of their development processes</a> now and 26% plan to soon. Gartner <a href="https://www.gartner.com/en/newsroom/press-releases/2024-04-11-gartner-says-75-percent-of-enterprise-software-engineers-will-use-ai-code-assistants-by-2028" target="_blank" rel="noopener">estimates</a> that over half of organizations are currently piloting or have already deployed AI-driven coding assistants, and that 75% of developers will use coding assistants in some form by 2028.</p>
<p>Ex-Microsoft software developer Igor Ostrovsky <span>believes that soon, there won’t be a developer who </span><em>doesn’</em><em>t&nbsp;</em><span>use AI in their workflows.&nbsp;</span>“Software engineering remains a difficult and all-too-often tedious and frustrating job, particularly at scale,” he told TechCrunch. “AI can improve software quality, team productivity and help restore the joy of programming.”</p>
<p>So Ostrovsky <span>decided to build the AI-powered coding platform that he himself would want to use.</span></p>
<p>That platform is <a href="https://www.augmentcode.com/" target="_blank" rel="noopener">Augment</a>, and on Wednesday it <a href="https://www.augmentcode.com/blog/augment-inc-raises-227-million">emerged</a> from stealth with $252 million in funding at a near-unicorn ($977 million) post-money valuation. With investments from former Google CEO Eric Schmidt and VCs including Index Ventures, Sutter Hill Ventures, Lightspeed Venture Partners, Innovation Endeavors and Meritech Capital, Augment aims to shake up the still-nascent market for generative AI coding technologies.</p>
<p>“Most companies are dissatisfied with the programs they produce and consume; software is too often fragile, complex and expensive to maintain with development teams bogged down with long backlogs for feature requests, bug fixes, security patches, integration requests, migrations and upgrades,” Ostrovsky said. “Augment has both the best team and recipe for empowering programmers and their organizations to deliver high-quality software quicker.”</p>
<p>Ostrovsky spent nearly seven years at Microsoft before joining Pure Storage, a startup developing flash data storage hardware and software products, as a founding engineer. While at Microsoft, Ostrovsky worked on components of Midori, a next-generation operating system the company never released but whose concepts have made their way into other Microsoft projects over the last decade.</p>
<p>In 2022, Ostrovsky and Guy Gur-Ari, previously an AI research scientist at Google, teamed up to create Augment’s MVP. To fill out the startup’s executive ranks, Ostrovsky and Gur-Ari brought on Scott Dietzen, ex-CEO of Pure Storage, and Dion Almaer, formerly a Google engineering director and a VP of engineering at Shopify.</p>
<p>Augment remains a strangely hush-hush operation.</p>
<p>In our conversation, Ostrovsky wasn’t willing to say much about the user experience or even the generative AI models driving Augment’s features (whatever they may be) — save that Augment is using fine-tuned “industry-leading” open models of some sort.</p>
<p>He did say how Augment plans to make money: standard software-as-a-service subscriptions. Pricing and other details will be revealed later this year, Ostrovsky added, closer to Augment’s planned GA release.</p>
<p>“Our funding provides many years of runway to continue to build what we believe to be the best team in enterprise AI,” he said. “We’re accelerating product development and building out Augment’s product, engineering and go-to-market functions as the company gears up for rapid growth.”</p>
<p>Rapid growth is perhaps the best shot Augment has at making waves in an increasingly cutthroat industry.</p>
<p>Practically every tech giant offers its own version of an AI coding assistant. Microsoft has GitHub Copilot, which is by far the firmest entrenched with over 1.3 million paying individual and 50,000 enterprise customers as of February. Amazon has AWS’ CodeWhisperer. And Google has Gemini Code Assist, recently rebranded from Duet AI for Developers.</p>
<p>Elsewhere, there’s a torrent of coding assistant startups: <a href="https://techcrunch.com/2023/02/06/magic-dev-code-generating-startup-raises-23m/" data-mrf-link="https://techcrunch.com/2023/02/06/magic-dev-code-generating-startup-raises-23m/">Magic</a><span>,&nbsp;</span><a href="https://techcrunch.com/2023/11/08/code-generating-ai-platform-tabnine-nabs-25m-investment/" data-mrf-link="https://techcrunch.com/2023/11/08/code-generating-ai-platform-tabnine-nabs-25m-investment/">Tabnine</a><span>,&nbsp;</span><a href="https://techcrunch.com/2023/11/16/codegen-raises-new-capital-llm-automation-for-software-dev/" data-mrf-link="https://techcrunch.com/2023/11/16/codegen-raises-new-capital-llm-automation-for-software-dev/">Codegen</a>, <a href="https://techcrunch.com/2024/01/29/refact-launches-to-make-code-generating-ai-more-appealing-to-enterprises/">Refact</a>, <a href="https://techcrunch.com/2023/10/10/tabbyml-github-copilot-alternative-raises-3-2-million/">TabbyML</a>, <a href="https://techcrunch.com/2023/11/02/sweep-aims-to-automate-basic-dev-tasks-using-large-language-models/">Sweep</a>,<span>&nbsp;</span><a href="https://techcrunch.com/2023/12/12/laredo-wants-to-use-gen-ai-to-automate-dev-work/" data-mrf-link="https://techcrunch.com/2023/12/12/laredo-wants-to-use-gen-ai-to-automate-dev-work/">Laredo</a> and <span>Cognition (which <a href="https://www.theinformation.com/articles/six-month-old-ai-coding-startup-valued-at-2-billion-by-founders-fund?offer=rtsu-engagement-24&amp;utm_campaign=RTSU+-+Cognition%2FFou&amp;utm_content=3915&amp;utm_medium=email&amp;utm_source=cio&amp;utm_term=2713" target="_blank" rel="noopener">reportedly</a> just raised $175 million), </span>to name a few. <span><a href="https://techcrunch.com/2023/06/21/harness-releases-generative-ai-assistant-to-help-ease-developer-workloads/">Harness</a></span> and <span>JetBrains, which developed the Kotlin programming language, recently </span><a href="https://techcrunch.com/2023/12/07/as-a-new-ai-driven-coding-assistant-is-launched-the-battle-for-ai-mindshare-moves-to-developers/">released</a><span> their <a href="https://techcrunch.com/2023/12/07/as-a-new-ai-driven-coding-assistant-is-launched-the-battle-for-ai-mindshare-moves-to-developers/">own</a>. So did&nbsp;<a href="https://techcrunch.com/2024/03/20/sentrys-ai-powered-autofix-helps-developers-quickly-debug-and-fix-their-production-code/">Sentry</a> (albeit with more of a cybersecurity bent).&nbsp;</span></p>
<p>Can they all — plus Augment now — do business harmoniously together? It seems unlikely. Eye-watering compute costs alone make the AI coding assistant business a challenging one to maintain. Overruns related to training and serving models forced generative AI coding startup <a href="https://techcrunch.com/2022/12/10/with-kites-demise-can-generative-ai-for-code-succeed/" data-mrf-link="https://techcrunch.com/2022/12/10/with-kites-demise-can-generative-ai-for-code-succeed/">Kite</a> to shut down in December 2022. <a href="https://aibusiness.com/nlp/github-copilot-loses-20-a-month-per-user" target="_blank" rel="noopener">Even Copilot loses money</a>, to the tune of around $20 to $80 a month per user, according to The Wall Street Journal.</p>
<p>Ostrovsky implies that there’s momentum behind Augment already; he claims that “h<span>undreds” of software developers across “dozens” of companies, including payment startup <a href="https://techcrunch.com/2023/06/06/eric-schmidt-keeta-cross-border-payments-fintech/">Keeta</a> (which is also Eric Schmidt-backed), are using Augment in early access. But will the uptake sustain? That’s the million-dollar question, indeed.</span></p>
<p>I also wonder if Augment has made any steps toward solving the technical setbacks plaguing code-generating AI, particularly around vulnerabilities.</p>
<p>An analysis by GitClear, the developer of the code analytics tool of the same name, <a href="https://visualstudiomagazine.com/Articles/2024/01/25/copilot-research.aspx">found</a> that coding assistants are resulting in more mistaken code being pushed to codebases, creating headaches for software maintainers. Security researchers have warned that generative coding tools can <a href="https://www.techtarget.com/searchsecurity/news/366571117/GitHub-Copilot-replicating-vulnerabilities-insecure-code" target="_blank" rel="noopener">amplify</a> existing bugs and exploits in projects. And Stanford researchers have <a href="https://www.theregister.com/2022/12/21/ai_assistants_bad_code/" target="_blank" rel="noopener">found</a> that developers who accept code recommendations from AI assistants tend to produce less secure code.</p>
<p>Then there’s copyright to worry about.</p>
<p>Augment’s models were undoubtedly trained on publicly available data, like all generative AI models — some of which may’ve been copyrighted or under a restrictive license. Some vendors have argued that <a href="https://www.copyright.gov/fair-use/#:~:text=Fair%20use%20is%20a%20legal,protected%20works%20in%20certain%20circumstances." target="_blank" rel="noopener" data-mrf-link="https://www.copyright.gov/fair-use/#:~:text=Fair%20use%20is%20a%20legal,protected%20works%20in%20certain%20circumstances.">fair use doctrine</a> shields them from copyright claims while at the same time rolling out tools to mitigate potential infringement. But that hasn’t stopped coders from <a href="https://www.finnegan.com/en/insights/articles/insights-from-the-pending-copilot-class-action-lawsuit.html" target="_blank" rel="noopener" data-mrf-link="https://www.finnegan.com/en/insights/articles/insights-from-the-pending-copilot-class-action-lawsuit.html">filing</a> class action lawsuits over what they allege are open licensing and IP violations.</p>
<p>To all this, Ostrovsky says: “Current AI coding assistants don’t adequately understand the programmer’s intent, improve software quality nor facilitate team productivity, and they don’t properly protect intellectual property. Augment’s engineering team boasts deep AI and systems expertise. We’re poised to bring AI coding assistance innovations to developers and software teams.”</p>
<p>Augment, which is based in Palo Alto, has around 50 employees; Ostrovsky expects that number to double by the end of the year.</p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta Reports First Quarter 2024 Results (123 pts)]]></title>
            <link>https://investor.fb.com/investor-news/press-release-details/2024/Meta-Reports-First-Quarter-2024-Results/default.aspx</link>
            <guid>40148998</guid>
            <pubDate>Wed, 24 Apr 2024 20:12:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://investor.fb.com/investor-news/press-release-details/2024/Meta-Reports-First-Quarter-2024-Results/default.aspx">https://investor.fb.com/investor-news/press-release-details/2024/Meta-Reports-First-Quarter-2024-Results/default.aspx</a>, See on <a href="https://news.ycombinator.com/item?id=40148998">Hacker News</a></p>
Couldn't get https://investor.fb.com/investor-news/press-release-details/2024/Meta-Reports-First-Quarter-2024-Results/default.aspx: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The Rise and Fall of the LAN Party (200 pts)]]></title>
            <link>https://aftermath.site/lan-party-merritt-k-book-read-only-memory-rom</link>
            <guid>40148833</guid>
            <pubDate>Wed, 24 Apr 2024 19:56:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aftermath.site/lan-party-merritt-k-book-read-only-memory-rom">https://aftermath.site/lan-party-merritt-k-book-read-only-memory-rom</a>, See on <a href="https://news.ycombinator.com/item?id=40148833">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Today it is trivially easy to play games on a computer with one’s friends over the internet. I can log into a game like <em>Fortnite</em>, party up with a squad and chat in either the game’s built-in voice protocol or use another service like Discord, and be in a game within minutes. I can do this from my computer, a game console, or even my phone. But before the wide availability of high-speed internet, things were more complicated.</p><hr><p><em>The following is excerpted from the book </em>LAN Party, <em>by Merritt K.&nbsp;<a rel="noreferrer noopener" href="https://readonlymemory.com/shop/book/lan-party/" target="_blank">The book is available for purchase now.</a></em></p><hr><p>In the 1990s and early 2000s, three-dimensional graphics in videogames were becoming more and more complex. Titles like 1998’s <em>Half-Life</em> pushed games in more cinematic directions, with lighting and textures that went beyond anything released even a few years earlier. Other first-person shooters (FPS) like <em>Counter-Strike</em> (itself originally a mod for <em>Half-Life</em>) and <em>Unreal Tournament</em> built on the work of earlier titles like <em>DOOM</em>, <em>Wolfenstein 3D</em>, and <em>Duke Nukem 3D</em>. Many of these titles were designed for multiplayer action. However, the typically low network speeds of the period meant that these games, unlike slower-paced and less graphically intensive strategy games, were nearly unplayable over an internet connection. In this moment, in which communications technology was being outpaced by graphical power, the LAN (local area network) party was born.</p><p>The term itself conjures up strong sensory memories for those who were there—sweaty bodies packed into a basement or convention hall, a&nbsp;dozen CPUs noticeably warming the space, the heft of a CRT monitor being maneuvered into position. For those on the outside, these were scenes of incomprehension or ridicule. But for those who were there, the LAN party was a singular event, a&nbsp;defining social occasion of the early 21st century. It represented the last gasps of the isolated gamer stereotype, ushering in an age in which gaming was not only mainstream, but a social, networked activity.</p><p>Of course, people had been bringing together computers for some time prior to the Y2K era. (The demoparty, in which participants cracked code to evade copyright protection and share artistic creations, was an important antecedent to the LAN party.) But it was in this particular period—in the United States, at least—that the social and technological configuration of the LAN party became a true phenomenon. Participants hauled their monitors, towers, and peripherals to a central location, where they would set up their machines and connect them through a network switch. This&nbsp;local connection enabled speeds far beyond those available to the average internet user, enabling lag-free gameplay, not to mention high-speed file sharing at a time when downloading or transporting large files could be an extremely onerous task.</p><p>LAN parties ranged from small, private gatherings to massive, multi-day events with thousands of participants, such as QuakeCon, DreamHack, The Gathering, and Euskal Encounter. Both types are represented in this book, though the focus is more on the former. As accessible digital photography was emerging around the same time as LAN parties—and perhaps because computer enthusiasts were more likely than the general population to own gadgets like digital cameras—these events are extraordinarily well documented.</p><h6>Gaming at the Turn of the Millennium</h6><p>What do these photos show? Young people—primarily young men—goofing off and playing games, of course. But it’s more than that. Technological and cultural artifacts of the era are strewn throughout, illustrating trends, obsessions, and now-forgotten relics. One of my favorite photos in the book depicts, among other things: a Windows XP error dialogue box; a beige Microsoft keyboard; a disposable film camera; a pair of wraparound headphones that I and nearly everyone else I knew owned in the early 2000s; and a pile of burned CD-Rs, one of which has “<em>StarCraft</em>” written on it in permanent marker. Junk foods and caffeinated beverages appear frequently in the collection, with the energy drink Bawls Guarana in particular popping up again and again. While Mountain Dew&nbsp;has since acquired a reputation as the gamer beverage of choice, Bawls was certainly the unofficial sponsoring drink of the LAN party.</p><p>Some games feature prominently in the mythos of the LAN party and in the photos collected in this book. The aforementioned <em>Counter-Strike</em> and <em>Unreal Tournament</em> are two of them, being primarily team-based first-person shooters that laid the groundwork for the ongoing popularity of the genre. These games are best played with minimum latency; they each support large numbers of players and feature quick rounds, which made them big hits at LAN parties. Certain maps in these games have become iconic, celebrated and recreated in other titles—for <em>Counter-Strike</em>, Dust II (de_dust2) is probably the best-known, while for <em>Unreal Tournament</em>, it’s Facing Worlds (CTF-Face). Both of these maps are so significant, so well-remembered and influential that they have their own Wikipedia pages.</p><p>Other first-person shooters popular at turn-of-the-century LAN parties include <em>Starsiege: Tribes</em>, <em>Tom Clancy’s Rainbow Six: Rogue Spear</em>, and id’s <em>Quake</em> series. <em>Quake III Arena</em> was released in 1999 and eschewed a single-player narrative component, instead focusing on highspeed multiplayer battles. The engine developed for the game was later used for a number of other successful games, including the awkwardly titled <em>Star Wars Jedi Knight II: Jedi Outcast</em>, which contained a robust multiplayer mode that players built on by creating elaborate rituals around lightsaber duels.</p><p>Of course, not all of the games played at LAN parties were first-person shooters. Real-time strategy (RTS) games were also quite popular in the early 2000s, with Blizzard’s <em>StarCraft</em> (1998) and <em>Warcraft III : Reign of Chaos</em> (2002) celebrated for their intricate design, customizability, and multiplayer capabilities. These games, like many 3FPS games of the era, came with tools that made it easy for players to create their own content. This led to a boom in hobbyist developer creativity that in turn generated entirely new genres of videogames such as the multiplayer online battle arena (MOBA), later refined by immensely successful titles like <em>League of Legends</em> and <em>Dota 2</em>. Other well-loved RTS games of the era include Westwood’s <em>Command &amp; Conquer</em> franchise, Ensemble’s <em>Age of Empires</em> series, and Creative Assembly’s <em>Total War</em> titles.</p><p>When it came to console gaming in the Y2K era, the Nintendo 64 set a new standard for multiplayer games with the introduction of four controller ports in 1996, and most subsequent machines followed its lead. Microsoft released the original Xbox in 2001, and its launch title, <em>Halo: Combat Evolved</em>, kicked off a new generation of console-based first-person shooters. In addition to featuring split-screen multiplayer, the Xbox supported a form of LAN play called <em>System Link</em>, which allowed up to sixteen players to play games like <em>Halo</em> simultaneously. The <em>Halo</em> series and Xbox also happened to be instrumental in the decline of the LAN party—more on that later.</p><figure><img alt="" src="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?w=1440&amp;h=810&amp;crop=1" srcset="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=480,270&amp;quality=75 480w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=960,540&amp;quality=75 960w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=640,360&amp;quality=75 640w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=1280,720&amp;quality=75 1280w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=768,432&amp;quality=75 768w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=1536,864&amp;quality=75 1536w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=1024,576&amp;quality=75 1024w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=2048,1152&amp;quality=75 2048w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=1280,720&amp;quality=75 1280w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=2560,1440&amp;quality=75 2560w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=1440,810&amp;quality=75 1440w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/LP-p-26_1998-4.jpg?resize=2880,1620&amp;quality=75 2880w" sizes="100vw" loading="lazy"><figcaption><span>Pg 26: © Erwin de Gier Amsterdam (The Netherlands), 1998</span></figcaption></figure><h6>Y2K Cultural Trends</h6><p>Beyond games, LAN party photos also demonstrate some other cultural trends of the period. The late 90s and early 2000s saw the rise of the nu metal musical genre, which included artists like Limp Bizkit, Slipknot, Korn, and Linkin Park. These groups harnessed feelings of isolation and teenage angst and fused rock instrumentation with hip-hop style and delivery, creating a kind of music that was beloved and reviled in equal measure for its direct, unselfconscious emotional pleas, macho posturing, and nihilistic themes.</p><p>Simultaneously, anime and Japanese subcultures were becoming more popular in the US due to the introduction of shows like Dragon Ball Z and Sailor Moon on American children’s networks. The growth of the internet, too, was making it easier than ever for young people interested in anime and other niche topics to share their interests and learn more about them on message boards and webrings. Anime and nu metal often went together in the form of the animated music video (AMV), where fans would stitch together clips of their favorite shows as makeshift music videos for their favorite angsty tracks.</p><p>The influence of anime and nu metal, as well as the mainstreaming of hip-hop to white suburban audiences, the dark guns-and-leather aesthetics of the films Blade and The Matrix, skater culture, and more can be seen in many of the photos in this book—in the clothing people are wearing, the posters on their walls, and desktop backgrounds. What has today become massively mainstream—anime, gaming, comic books, and so on—was, in the early 2000s, still on the fringes of normalcy. Remember: Iron Man didn’t kick off the Marvel Cinematic Universe until 2008. Crunchyroll, the anime streaming platform, didn’t exist until 2006.</p><p>In the same vein, this period also saw the birth of meme culture online. Early internet memes like “Mr. T Ate My Balls,” “All your base are belong to us,” and l33tspeak spread through forums like Something Awful and Flash portals such as Newgrounds, giving young internet users a kind of shared secret language. In the late 2000s, as social networks like Facebook gained traction among college students and more and more people got online, meme culture gradually became mass culture.</p><h6>Creative Chaos</h6><p>In addition to the cultural trends of the time, these pictures also show people bringing computers into places where they didn’t traditionally belong. In the 1990s and early 2000s, bulky desktop computers often lived in home offices or even dedicated “computer rooms.” Some lucky few kids at that time had their own personal computers in their bedrooms, but in my experience, this was rare.</p><p>During LAN parties, participants brought computers into garages, basements, living rooms, and other spaces, setting them up on dining-room tables, TV trays, kitchen counters, and any available surface. The raw excitement on the part of the participants is evident in the sometimes absurd lengths they went to in order to participate in LAN parties—computer towers crammed between cushions in the back seat of a van to ensure their safe transportation across town; cables crisscrossing the floor to connect machines; CRT monitors balanced haphazardly around the room.</p><p>It’s this passion, I think, which partly explains the appeal of these photos—even to those who weren’t around at the time. This book is full of images of people being truly excited about computers and playing games on them. There’s a sense, in looking at these photos, that these people were on the cusp of something—even if they weren’t necessarily aware of it at the time. Since the home computer boom of the 1990s and the introduction of high-speed internet in the 2000s, the omnipresence of computers and communication technology has rendered them mundane to many people. It’s almost quaint to see people so genuinely thrilled to be playing PC games with their friends when, today, doing so is an everyday occurrence.</p><p>Making a LAN party happen took work. It took physical effort, technical know-how, and a willingness to hack things together. The range of computer equipment depicted in the photos is testament to that. Yes, there are the standard massive, beige CRT monitors associated with the period, but we see computer towers ranging from stock models in the same color to complex monstrosities built by enthusiastic geeks. This was before Apple’s sleek industrial design took over the tech world, before LED lights were standard on pretty much any gaming PC. It was the era of user-driven customization, and LAN parties are perfectly emblematic of that time.</p><h6>The Decline Of The LAN Party</h6><p>LAN parties occurred throughout the 1990s, peaked (in the US, at least) in the early-mid-2000s and began to decline in the early 2010s. Of course, people do still throw LAN parties, especially people who grew up with them, but their heyday has long since passed. So what killed the LAN party? The most obvious answer is the widespread introduction of communication infrastructure that made it possible to play games like first-person shooters over the internet with low latency.</p><p>LAN parties were a creation of circumstance, which withered away once it was no longer a necessity to transport computers to the same physical space in order to get an ideal gaming experience. It’s certainly true that it is now more convenient than ever for many people to play games online with strangers or friends. But convenience in technology often comes with a commensurate loss of control on the part of users.</p><p>In 2004, Bungie released <em>Halo 2</em> for the Xbox. The game built on the original’s landmark success by introducing online play through Microsoft’s Xbox Live service. It went on to become the most popular Xbox Live title of all time and was played until the discontinuation of the service on the original Xbox in 2010.</p><figure><img alt="" src="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?w=1440&amp;h=810&amp;crop=1" srcset="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=480,270&amp;quality=75 480w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=960,540&amp;quality=75 960w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=640,360&amp;quality=75 640w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=1280,720&amp;quality=75 1280w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=768,432&amp;quality=75 768w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=1536,864&amp;quality=75 1536w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=1024,576&amp;quality=75 1024w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=2048,1152&amp;quality=75 2048w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=1280,720&amp;quality=75 1280w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=2560,1440&amp;quality=75 2560w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=1440,810&amp;quality=75 1440w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/200X-13981651_2052b974c9_o.jpg?resize=2880,1620&amp;quality=75 2880w" sizes="100vw" loading="lazy"><figcaption><span>Pgs 70-71: © Kiel Oleson/Electronox  Lee’s Summit, MO (USA), 2002</span></figcaption></figure><p>The Xbox Live service was easy to use, popularizing the method of allowing players to party up with their friends and enter into matchmaking queues. This was a major shift from the then prevalent system of presenting players with a list of servers to join, each hosted by different players and groups. As well as being a more seamless experience emphasizing ease of use, this new model also represented a move away from user control. Matchmaking is now the dominant mode of playing multiplayer games online. There are certainly advantages inherent in it—developers can try to create fairer matchups based on skill and players can keep their ranks and reputations across games—but it also puts players at the mercy of a company’s algorithms and servers.</p><p>Many of the most popular multiplayer videogames today are entirely server-side, meaning that they cannot be played without connecting to the game’s servers. This is advantageous for developers and publishers, who can ensure that players have the latest updates, prevent cheating, and create large worlds in which numerous players can be online and interacting at once. But it also means that control of game experiences has shifted significantly away from users. Even games that have offline components often do not have any kind of peer-to-peer or private server functionality, meaning that it is impossible for a group to play them together in a LAN environment.</p><p>The way we buy and play games has also changed. Today, digital platforms like Steam and the Epic Game Store allow players to purchase titles without leaving their homes. But digital copies of games, and their management through these platforms, mean that the old practices of burning copies of games or sharing legal “spawn installations” of games to facilitate multiplayer experiences are less and less possible.</p><p>Thus, the story that LAN parties died because they were simply an obsolete social structure is a little too straightforward. It may be true that most people would prefer to play games in the comfort of their own home rather than transporting expensive and bulky equipment elsewhere, but technological and economic forces also contributed to the decline of LAN events. The fact is that the shift to digital, producer-owned environments in every aspect of gaming—from sales to play—tremendously benefits the corporations publishing and selling games, sometimes at the expense of those purchasing and playing them.</p><h6>Looking Back</h6><p>In the photos collected in this book, then, we can see some things that have been lost, or at least forgotten—an adventurous spirit around computing and a world in which ownership of software and play belonged more to individuals than corporations. I don’t mean to suggest that LAN parties were utopian spaces. They were, of course, mostly—but&nbsp;certainly not exclusively—attended and organized by young white men, and even many of the larger events were male-dominated spaces, hostile to women. Nonetheless, from my position, decades later, I can’t help but look fondly on images of LAN parties. At a time when communications technology paradoxically seems to produce a sense of disconnection for many people through algorithmically generated echo chambers and the indexing of personal worth to follower counts or likes, seeing people literally coming together with and around computers is almost aspirational.</p><p>It’s tempting to see the mainstreaming of gaming and tech as a uniformly positive trend. And certainly, more people having access to these things and feeling like they belong in associated spaces is a good thing. But there are always trade-offs. The ubiquity of, and widespread access to, tech has come with an unprecedented rise in surveillance through our devices, a loss of control over our personal data, and a sense of alienation fostered by tech companies who want to own as much of our attention as possible.</p><p>For people like me, who grew up during the 1990s and 2000s, it can sometimes feel like the exciting period of the internet and computing is over. Pictures of LAN parties represent that early era of the internet, when it was a place that you visited rather than a parallel layer of reality. As we’ve watched that mysterious, alluring, and perilous internet get progressively fenced off, paywalled, and centralized by a few massive corporations, some of us are beginning to reflect on our relationship to&nbsp;it.</p><p>Perhaps this thing that was so important to us in our youth, that we’ve stubbornly stuck with despite sweeping structural changes, is no longer so relevant to our lives. Maybe it’s time to start figuring out new ways to use the internet and computers to enrich our world. And maybe LAN parties can offer one model for that.</p><p><em>Excerpted from </em>LAN PARTY: Inside the Multiplayer Revolution<em>, by merritt k</em></p><p><em>Text © 2023 merritt k&nbsp;</em></p><p><em>© 2024 Thames &amp; Hudson Ltd, London</em></p><p><em>Reprinted by permission of Thames &amp; Hudson Inc, </em><a href="http://www.thamesandhudsonusa.com/" target="_blank" rel="noreferrer noopener"><em>www.thamesandhudsonusa.com</em></a></p><figure><img alt="" src="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?w=1440&amp;h=810&amp;crop=1" srcset="https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=480,270&amp;quality=75 480w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=960,540&amp;quality=75 960w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=640,360&amp;quality=75 640w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=1280,720&amp;quality=75 1280w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=768,432&amp;quality=75 768w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=1536,864&amp;quality=75 1536w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=1024,576&amp;quality=75 1024w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=2048,1152&amp;quality=75 2048w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=1280,720&amp;quality=75 1280w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=2560,1440&amp;quality=75 2560w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=1440,810&amp;quality=75 1440w, https://lede-admin.aftermath.site/wp-content/uploads/sites/55/2024/04/2006-IMG_0713.jpg?resize=2880,1620&amp;quality=75 2880w" sizes="100vw" loading="lazy"><figcaption><span>Pg 118: © Robert McNeil  Brisbane (Australia), 2006</span></figcaption></figure></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[McKinsey Under Criminal Investigation over Opioid-Related Consulting (332 pts)]]></title>
            <link>https://www.wsj.com/articles/mckinsey-faces-criminal-probe-over-opioid-related-consulting-a3f816d4</link>
            <guid>40148729</guid>
            <pubDate>Wed, 24 Apr 2024 19:47:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/articles/mckinsey-faces-criminal-probe-over-opioid-related-consulting-a3f816d4">https://www.wsj.com/articles/mckinsey-faces-criminal-probe-over-opioid-related-consulting-a3f816d4</a>, See on <a href="https://news.ycombinator.com/item?id=40148729">Hacker News</a></p>
Couldn't get https://www.wsj.com/articles/mckinsey-faces-criminal-probe-over-opioid-related-consulting-a3f816d4: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Nearsightedness is at epidemic levels – and the problem begins in childhood (206 pts)]]></title>
            <link>https://theconversation.com/nearsightedness-is-at-epidemic-levels-and-the-problem-begins-in-childhood-225255</link>
            <guid>40148707</guid>
            <pubDate>Wed, 24 Apr 2024 19:44:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theconversation.com/nearsightedness-is-at-epidemic-levels-and-the-problem-begins-in-childhood-225255">https://theconversation.com/nearsightedness-is-at-epidemic-levels-and-the-problem-begins-in-childhood-225255</a>, See on <a href="https://news.ycombinator.com/item?id=40148707">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Myopia, or the need for corrected vision to focus or see objects at a distance, has become a lot more common in recent decades. <a href="https://doi.org/10.1038/519276a">Some even consider myopia</a>, also known as nearsightedness, an epidemic.</p>

<p>Optometry researchers estimate that <a href="http://dx.doi.org/10.1016/j.ophtha.2016.01.006">about half of the global population</a> will need corrective lenses to offset myopia by 2050 if current rates continue – up from 23% in 2000 and <a href="https://myopiainstitute.org/myopia/#">less than 10% in some countries</a>. </p>

<p>The associated health care costs are huge. In the United States alone, spending on corrective lenses, eye tests and related expenses <a href="https://www.doi.org/10.3389/fmed.2021.718724">may be as high as US$7.2 billion a year</a>.</p>

<p>What explains the rapid growth in myopia? </p>

<p><a href="https://scholar.google.com/citations?user=fExMMysAAAAJ&amp;hl=en">I’m a vision scientist</a> who has studied visual perception and perceptual defects. To answer that question, first let’s examine what causes myopia – and what reduces it.</p>

<figure>
            <p><iframe data-src="https://www.youtube.com/embed/ezP3oCRaBBQ?wmode=transparent&amp;start=0" frameborder="0" allowfullscreen="" width="100%" height="400"></iframe></p>
            <figcaption><span>A closer look at myopia.</span></figcaption>
          </figure>

<h2>How myopia develops</h2>

<p>While having two myopic parents does mean you’re more likely to be nearsighted, <a href="https://doi.org/10.1007/978-981-13-8491-2_5">there’s no single myopia gene</a>. That means the causes of myopia are more behavioral than genetic. </p>

<p>Optometrists have learned a great deal about the progression of myopia by <a href="https://www.scientificamerican.com/article/space-perception-in-the-chick/">studying visual development in infant chickens</a>. They do so by putting little helmets on baby chickens. Lenses on the face of the helmet cover the chicks’ eyes and are adjusted to affect how much they see.</p>

<p>Just like in humans, if visual input is distorted, a chick’s eyes grow too large, <a href="https://doi.org/10.1016/j.cub.2006.02.065">resulting in myopia</a>. And it’s progressive. Blur leads to eye growth, which causes more blur, which makes the eye grow even larger, and so on. </p>

<p>Two recent studies featuring extensive surveys of children and their parents provide strong support for the idea that an <a href="https://doi.org/10.1186/s12889-022-14377-1">important driver of the uptick</a> in myopia is that <a href="https://doi.org/10.1111/aos.14980">people are spending more time</a> focusing on objects immediately in front of our eyes, whether a screen, a book or a drawing pad. The more time we spend focusing on something within arm’s length of our faces, dubbed “near work,” the greater the odds of having myopia. </p>

<p>So as much as <a href="https://www.cbc.ca/news/canada/excessive-screen-use-eyes-myopia-1.6815857">people might blame new technologies like smartphones</a> and too much “screen time” for hurting our eyes, the truth is even activities as valuable as reading a good book can affect your eyesight.</p>

<h2>Outside light keeps myopia at bay</h2>

<p>Other research has shown that this unnatural eye growth can be interrupted by sunlight.</p>

<p>A 2022 study, for example, found that myopia rates <a href="https://doi.org/10.1186/s12889-022-14377-1">were more than four times greater</a> for children who didn’t spend much time outdoors – say, once or twice a week – compared with those who were outside daily. At the same time, kids who spent more than three hours a day while not at school reading or looking at a screen close-up were four times more likely to have myopia than those who spent an hour or less doing so. </p>

<p>In another paper, from 2012, researchers <a href="https://www.doi.org/10.1016/j.ophtha.2012.04.020">conducted a meta-analysis of seven studies</a> that compared duration of time spent outdoors with myopia incidence. They also found that more time spent outdoors was associated with lower myopia incidence and progression. The odds of developing myopia dropped by 2% for each hour spent outside per week. </p>

<p>Other researchers have reported similar effects and argued for <a href="https://doi.org/10.1159/000501937">much more time outdoors</a> and changes in early-age schooling to reduce myopia prevalence. </p>

<figure>
            <p><iframe data-src="https://www.youtube.com/embed/LAkFtka3UFw?wmode=transparent&amp;start=0" frameborder="0" allowfullscreen="" width="100%" height="400"></iframe></p>
            <figcaption><span>‘Why so many people need glasses now.’</span></figcaption>
          </figure>

<h2>What’s driving the epidemic</h2>

<p>That still doesn’t explain why it’s on the rise so rapidly.</p>

<p>Globally, a <a href="https://www.doi.org/10.1097/MD.0000000000014777">big part of this is due to the rapid development</a> and industrialization of countries in East Asia over the last 50 years. Around that time, young people began spending more time in classrooms reading and focusing on other objects very close to their eyes and less time outdoors. </p>

<p>This is also what researchers <a href="https://doi.org/10.1111/opo.12879">observed in the North American Arctic</a> after World War II, when schooling was mandated for Indigenous people. Myopia rates for Inuit went from the single digits before the 1950s to upwards of 70% by the 1970s as all children began attending schools for the first time.</p>

<p>Countries in Western Europe, <a href="https://doi.org/10.1001/archophthalmol.2009.303">North America</a> and Australia have shown <a href="https://doi.org/10.1097/OPX.0000000000000069">increased rates of myopia</a> in recent years but nothing approaching what has been observed recently in <a href="https://doi.org/10.1016/j.preteyeres.2017.09.004">China, Japan, Singapore and a few other East Asian countries</a>. The two main factors identified as leading to increased myopia are <a href="https://www.chinasmack.com/chinese-school-desks-with-railings-prevent-near-sightedness">increased reading</a> and other activities that require focusing on an object close to one’s eyes and a <a href="https://doi.org/10.1371/journal.pone.0181772">reduction in time spent outdoors</a>.</p>

<p>The surge in myopia cases will likely have its worst effects 40 or 50 years from now because <a href="https://doi.org/10.1186/s12889-022-14377-1">it takes time</a> for the young people being diagnosed with nearsightedness now to experience the most severe vision problems.</p>

<h2>Treating myopia</h2>

<p>Fortunately, just a few minutes a day with glasses or contact lenses that correct for blur <a href="https://doi.org/10.1016/s0042-6989(98)00304-6">stops the progression of myopia</a>, which is why early vision testing and vision correction are important to limit the development of myopia. Eye checks for children are mandatory in some countries, <a href="https://www.orthoptics.org.uk/patients-and-public/childrens-vision-screening/">such as the U.K.</a> and <a href="http://en.moe.gov.cn/news/press_releases/202404/t20240408_1124412.html">now China</a>, as well as <a href="https://nationalcenter.preventblindness.org/vision-screening-requirements-by-state/">most U.S. states</a>.</p>

<p>People with with high myopia, however, have <a href="https://doi.org/10.3390/ijerph16142595">increased risk of blindness and other severe eye problems</a>, such as retinal detachment, in which the retina pulls away from the the back of the eye. The chances of myopia-related <a href="https://www.webmd.com/eye-health/macular-degeneration/what-is-myopic-macular-degeneration">macular degeneration</a> increase by <a href="https://doi.org/10.1111/opo.12945">40% for each diopter of myopia</a>. A diopter is a unit of measurement used in eye prescriptions.</p>

<p>But there appear to be two sure-fire ways to offset or delay these effects: Spend less time focusing on objects close to your face, like books and smartphones, and spend more time outside in the bright, natural light. Given the first one is difficult advice to take in our modern age, the next best thing is taking frequent breaks – or perhaps spend more time reading and scrolling outside in the sun.</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I now lack the juice to fuel the bluster to conceal that I am a simpleton (310 pts)]]></title>
            <link>https://lithub.com/i-now-lack-the-juice-to-fuel-the-bluster-to-conceal-that-i-am-a-simpleton-padgett-powell-legend/</link>
            <guid>40148563</guid>
            <pubDate>Wed, 24 Apr 2024 19:32:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lithub.com/i-now-lack-the-juice-to-fuel-the-bluster-to-conceal-that-i-am-a-simpleton-padgett-powell-legend/">https://lithub.com/i-now-lack-the-juice-to-fuel-the-bluster-to-conceal-that-i-am-a-simpleton-padgett-powell-legend/</a>, See on <a href="https://news.ycombinator.com/item?id=40148563">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							        
									<p><span itemprop="articleBody"><p>Forty years ago, Padgett Powell’s erudite coming of age novel <a href="https://bookshop.org/a/132/9781936787722" target="_blank"><em>Edisto</em></a> was released and introduced readers to a 12-year-old literary prodigy named Simons Everson Manigault. Following an acrimonious separation between the “Duchess” and the “Progenitor” (Simons’ parents), the young boy finds himself living in the Manigault&nbsp;summer home in Edisto, South Carolina while his mother descends into alcoholism.</p>
<p>With his domestic reality crumbling to its foundations, Simons spends most of his time at the Baby Grand, a Black nightclub whose patrons take a shine to the young truant. When the Manigault maid’s biracial grandson arrives in Edisto looking for his mother, Simons names him “Taurus” and the name sticks. The unlikely pair develop a friendship, ushering Simons into the world of mid-century American race relations, the sexual revolution, and the infelicitous vortex of confusion that is puberty.</p>
<p>In addition to celebrating <em>Edisto’s</em> milestone anniversary this year, Powell will be releasing <em>Blasphemy and Other Ancestors </em>(Gordon Hill Press), a collaborative book co-authored with myself, Darius James, and Lee Henderson about the tag end of existence and the abasements that memory holds in store for characters living outside of their time.</p>
<p>I corresponded with Powell to discuss the relationship between cornpone and Flann O’Brien, the “rotten taste of America” informing literary culture, and building a career around the “fey interface between believing in the South and making fun of believing in the South.”</p>
<p><strong>*</strong></p>
<p><strong>Jean Marc Ah-Sen: </strong>What was the central attraction of writing <em>Edisto</em>, a bildungsroman that explored Black and white race relations in the South? Why do you think so many writers feel compelled to start their careers writing about emotional and intellectual maturation, and to which characteristics of the coming-of-age novel do you attribute its pride of place among a broadly defined readership?</p>
<span>The attractive characteristic of a young narrator is the absurdity of it and the license of it.</span>
<p><strong>Padgett Powell:</strong> Let me warn us that these questions are too <em>recherche</em> for me. I now lack the juice to fuel the bluster to conceal that I am a simpleton.</p>
<p>A professor in college was roundly pregnant on a Monday, absent Wednesday, and giving her lecture on “The Miller’s Tale” on Friday with the baby on her hip. I thought “What if that little bastard picks this stuff up and knows Chaucer when he’s five?” My own brother had a good mouth on him, there was already the mother in front of me—the novel was there for the writing. The cerebral cogitation was done. Just Strunk &amp; White some sentences and connect them head to tail and throw in everything you’ve ever seen or heard. Done.</p>
<p>You don’t write about “emotional and intellectual maturation.” The attractive characteristic of a young narrator is the absurdity of it and the license of it. Huck Finn is a 14-year-old uneducated antebellum white boy in Mississippi? Huck Finn is Mark Twain being as smart as Mark Twain was. Huck Finn turns him loose. The absurdity of the proposition is like lightning.</p>
<p><strong>JMA: </strong><em>Edisto</em> explored the legacy and aftermath of the reconstruction era all the way into the 1960s. Donald Barthelme in particular praised you for writing about things readers had never heard before between Black and white characters. Did you have a sense that books written about a similar milieu before or around the time of <em>Edisto’s</em> publication were characteristic of a mealy-mouthedness when it came to racial politics?</p>
<p><strong>PP:</strong> I am innocent of anything written along these lines or the spectrum of candor in them. Because I was arrested for my underground newspaper <em>Tough Shit</em> in high school and the principal sent it to my college to dematriculate me from it, and I had as a result narrated the events of my arrest to four eminences at that college, the Dean of Men there put me in a dorm room with the odd Black boy out because he figured I was radical enough to be liberal enough to handle early integration.</p>
<p>“I didn’t want some redneck to eat him up,” he put it to me three weeks into the semester. I said I wouldn’t. Jinx took me to his bar—it’s in the book, verisimilitudinously. I saw some low country Black life behind some doors. We’d had a long-term maid, a complicated woman—in the book as Theenie, verbatim. I saw some mullet fishing in Florida where a woman berated a fellow for his sloth; “You so slow, no wonder your wife left you.” His name was Buckwheat, a name I could not alter or drop, as prudence would have suggested; she called him Wheat, and when he said, “She din’ leave me, she died,” the woman yelled, “The ultimate leff!” If these are things not heard before, it is only because no one has listened and written them down. You could not publish them in America today because of liberal-editing racism.</p>
<p><strong>JMA: </strong>Twelve years after the release of <em>Edisto</em>, you returned to the world of the Manigault family with <em>Edisto Revisited</em>. What were your motivations for dropping back into the land of mullet fishing, moonshine, and professorial mores during Simons’ university years? Did you always have a sense that there was more to Simons’ story that warranted revisiting, or was there some realization that came afterwards that signaled the attractive possibilities of the story continuing in a sequel?</p>
<p><strong>PP:</strong> I had no sense of more to tell, certainly no sense that more was merited, but it was what I could write at the time and I wrote it. Let me lean us up on Flannery O’Connor, our late racist goddesshead: “When I told you to write what is easy I meant what is possible. It is never easy.” If I have misquoted her, it is because my brain has little spots of something in it.</p>
<p><strong>JMA: </strong>Your career has been described as participating in the American Southern literary tradition. Was this an association you felt honored by, or perhaps something that you were suspicious of? Do you think that writing embodying the principles of the American South needs to be constantly evolving, or is it something that needs to be carefully curated, and whose boundaries must be clearly defined, in order for it to endure?</p>
<p><strong>PP:</strong> It might be fun to tear it all up after the Jews Will Not Replace Us boys in their khakis protest, holding copies of <em>Absalom! Absalom!</em> upside down in the style of Trump with his Bible with duped General Milley at his side. It could all go into the big smelter with the Bobbie E. Lee bronze. But then some smartass would invent another plantation house, another confederate widow, another lost utterancer of the not yet lost cause.</p>
<p>I have made a career of dancing without dancing in the fey interface between believing in the South and making fun of believing in the South, which is why no one has ever heard of me. It’s a lame-ass position. The proper term is chicken-shit.</p>
<p>Who would object if clubists wanted to shove you into a cubbyhole with Faulkner and O’Connor and their queer son Tennessee and too straight son Walker and what-litter-is-he-from son Don? Not I. And my God, Barry Hannah got more out of the whiskey oracle than anyone dead. I do not like the sentimental blood-and-grits crowd and I do not like the apotheosis of Story as Panacea, the from-farm-to-porch menu. Cornpone. No.</p>
<p>Southern writing, not often actually defined, means a deep-down knowing that people are beat to shit. An earnest suspicion of earnestness, a recognition and denial of whippedness. I am now spinning cornpone myself. End of the foregoing. Let’s go read some Flann O’Brien. Those brothers are whipped for real.</p>
<p><strong>JMA: </strong>The book that you are perhaps most known for is <a href="https://bookshop.org/a/132/9780061859434" target="_blank"><em>The Interrogative Mood</em>, <em>A </em><em>Novel?</em></a> which is entirely written in the form of meditative questions—“If you were to participate in a spice war, what spice would you fight for?” is my personal favorite. Did you conceive the book as a rascally wedge that could be placed between experimental and commercial fiction? Or was the book perhaps an effort to assert the primacy of artistic questioning over the fatuousness of shopworn opinions?</p>
<p><strong>PP:</strong> You continue to try to flatter. But this is sharp flattery. It moves me to pomposity: experimental fiction means no more or less than fiction whose central thrust in not made-up people doing made-up things. Let’s call that MUPDMUT. With some liberty, Mupdeemut. Experimental fiction may of course have Mupdeemut in it, but not as the thrust of it—something beyond our believing in Mupdeemut is at hand.</p>
<p>When Hulga’s leg is stolen by a Bible salesman, we are to believe it. When our friend Colby has gone too far and is to be hanged, we are not to believe it. We have the pleasure of seeing Colby in his anguish, but we have a larger or smaller pleasure of distraction from the dictate to pretend this horseshit actually happens. That is the “experiment.”</p>
<p>Does the imperative to not believe exceed the pleasure of the imperative to believe? Donald Barthelme believed it did if the writing still contained emotional payoff. O’Connor would have said, did say, to hell with it. “If [the Devil] is only a symbol, to hell with it.” The imperative to believe is at one level rather childish, as in Once upon a time… This is why Coleridge had the wit to call it a “suspension of disbelief,” not precisely an imperative to believe. What an upgrade to be told, “Don’t <em>believe</em> this, you morons.” What you do, mischievously, is believe <em>more</em>. At which point the “experiment” has succeeded.</p>
<p><em>The Int. Mood</em> goes way too far, in Colby terms, and dispenses with Mupdeemut altogether, except for the occasional Jimi Hendrix’s being offered a BLT as he affects to play you a tune. There is no history of intellection in its conception or intent and no prefiguring in its execution (Huck Finn shows you prefigurating for a book like <em>Edisto</em>).</p>
<p>I received an email from a colleague who wanted me to talk to the Dean that opened, “Is it time for us to have a chat with the dean? Are we remembering what was promised us, last spring, at lunch? Are we going to let history repeat itself?” I suffered pique at this and wrote back, “Are your emotions pure? Are your nerves adjustable? How do you stand in relation to the potato? Should it still be Constantinople?”</p>
<p>The pleasure in this was extreme. I thought how funny it would be—Reply All—for her to receive 600 of these questions, and wrote 600 of them, and then could not stop and wrote 142 pages of them. I saw the “rules” immediately, using her model, but exaggerating the forces. Relieve the silly with the grave, the arch with the colloquial, perfect the overt non-sequitur, watch rhythm, let each sentence deliver its impact—a stonking of someone who would presume write your ass with questions as annoying as they were. Marvelous fun, therapeutic because I was fair exercising some deep contours in my shallow brain, and I felt fine every time I wrote a batch of these things, which I began to liken to thousands of redundant missiles like those we have in our nuclear silos.</p>
<p><strong>JMA: </strong>Your prose tends to be voice-driven and characterized by a kind of malapert urbanity. Can you talk about how this stylized way of writing developed, and if it was an artistic response to things you were reading (whether inhospitably or with a deal of enthusiasm)?</p>
<p><strong>PP:</strong> I am ignorant of “malapert” but I do get “urbanity.” Here is as an almost certainly impertinent answer that I do not intend to be impertinent: I learned to write the English I have written by taking three years of Latin, in the putatively desolate educational backwater of Jacksonville, Florida, ending in the tenth grade translating <em>The Aeneid</em>. I was in homeroom sitting with Allen Collins of Lynyrd Skynyrd. We was gettin’ it. We did not know we was gettin’ it.</p>
<p><strong>JMA: </strong>Does the prose voice that you adopt develop in parallel to the thematic concerns that you will tackle in a given work, or does it emerge as a result of other considerations?</p>
<p><strong>PP:</strong> It emerges with no consideration for anything but the next correct word.</p>
<p><strong>JMA:</strong> The destiny of all books is to become unmoored from the time which birthed them, and as new readers discover them, their relationship can become not just tinged, but entirely defined by a sense of presentism. You spent a large part of your career teaching at the University of Florida Creative Writing program, and I’m wondering how you would address this reality when and if it occurred in the classroom? Is there, in point of fact, a “right” and “wrong” way to read?</p>
<p><strong>PP:</strong> We read formative work asking only what might make it better, by which I meant power in the writing. As I came to the end, the students seemed to have been coached toward a new kind of “better” that meant what was less offensive, and the offense was a multi-headed, surprising beast. One student got in trouble with others when he created a character named Phone Ho. I was mystified by all this and got away rather than try to breast the tide.</p>
<p>I was not going to be able to teach writing, if I ever had taught it. I was turned in for use of the phrase “tsunami of inclusivity.” The phrase was examined for “racial content.” It was judged to be empty of racial content. A prior student suggested I use “politicalicity” as in “tsunami of politicalicity” and I paid him $20 for the word, inserted the phrase, and retired. Please see my students Kevin Wilson and Chris Bachelder, and Kevin Canty and Chris Adrian. There are more. These are just my Kevins and my Chrises, as Trump would put it. God are we doomed.</p>
<span>The destiny of all books is to become unmoored from the time which birthed them.</span>
<p><strong>JMA: </strong>Your latest work will be the novelette “The New Book” in our omnibus book <em>Blasphemy and Other Ancestors</em>. Your offering concerns a man of letters taking on an assistant and training him in the righteous arts of romance, but it also features a metafictionally aware narrator playing against a hypothetical reader’s reservations about events unfolding in Florida. I’m curious if this was a way to express frustration with the sensibilities of modern readership or literary criticism?</p>
<p><strong>PP:</strong> I think not. What I recall was writing a fairly comprehensible sketch in the South-satire genre, kind of my schtick, getting tired of my schtick, and for relief sliding into something untenably surreal in which even I could not keep straight what I was talking about. So I shet that thing down. My hero turned into Ted Turner, and Monteagle, Tennessee became the Philippines in WWII, and a girl at Walmart turned into Vanna White and I was doomed.</p>
<p><strong>JMA: </strong>In an industry that routinely heaps indignity after indignity on its practitioners, what has been the most startling development that you have encountered in recent years while releasing your books? Was it an issue arising as a matter of course from past frustrations, or did it spring from some unprecedented corner of the industry?</p>
<p><strong>PP:</strong> It sprang from the unprecedented corner of my own publisher. My book <em>Indigo</em> had been edited and copyedited by two astute, eminent editors, was set to roll, when a “sensitivity editor” was brought in because someone in marketing at the house was not “comfortable representing the book.” (For the record I never saw any evidence that anyone represented the book)</p>
<p>The sensitivity editor, who I suspect was given four times the money I was given for the book, fell to with their sensitivity broadaxe. In a long true account of a dust-up at a restaurant in old Austin, not new Austin, a Black man on my roofing crew came to my defense and knocked out a white restaurant manager, who was at the moment presuming to assault me. Willie had noticed that the manager had Black back-up and felt I should too. “Old Padge need him some brothers too,” he would explain later.</p>
<p>The piece was essentially a portrait of a hero, Willie Ebert Brown, in a terrain of racial relations that had hope in it. The sentence that announced the Black back-up for the manager was this: “A sturdy-looking Black guy came out of the kitchen.” This is choice low fruit for a sensitivity editor. “Objectifying description,” she wrote, “that may invoke associations with slavery.”</p>
<p>I should have desisted publishing the book, but I am a chicken-shit person and I really wanted a book with a beautiful photo of an indigo snake on its cover. My celebration of Willie was thrown out; my invocation of slavery (to which who objects, its absurdity aside?) was one of a hundred other crimes in the piece. Liberal racism had its way: remove racism by removing race.</p>
<p>There is not a person of color in my book except a very positive small tribute to Barack Obama as a tool by which we might argue the French can slow their roll about how racist we are and they aren’t. How that was not deemed racist is a wonder, because it somewhat is. It’s not a wonder: liberal racism is a photo-negative argument. I apologize for this rant. Chicken-shit and now tired too.</p>
<p><strong>JMA: </strong>For decades now, readers and writers alike have speculated about where the future of literature is headed, with some espousing the belief that literary fiction in particular is going the way of opera and ballet. I think it could be argued that anything betraying a high literary sensibility is already beholden to blue-blooded patronage and sponsorship, whether we are talking about arts grants and awards bodies or content subscription models like Substack or Patreon. Do you think that literary fiction can find mass appeal among readers or has its place always been in contradistinction to an upmarket reading sensibility?</p>
<p><strong>PP:</strong> Does “an upmarket reading sensibility” mean people who buy books at the airport? I confess to feeling loose reading this question. Let’s do a loose answer: a really good book, with anomalies here and there, will not sell well to a mass American market. If you make money here, you have done something wrong. It’s the rotten taste of America, the same force that explains a Trump. We have problems way larger than a poor good writer and a successful conman at large in Washington.</p>
</span></p>
									
																		
																		
									<br><hr>
									
							    										
								</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA['So hot you can't breathe': Extreme heat hits the Philippines (103 pts)]]></title>
            <link>https://www.japantimes.co.jp/news/2024/04/24/asia-pacific/philippines-extreme-heat/</link>
            <guid>40148012</guid>
            <pubDate>Wed, 24 Apr 2024 18:40:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.japantimes.co.jp/news/2024/04/24/asia-pacific/philippines-extreme-heat/">https://www.japantimes.co.jp/news/2024/04/24/asia-pacific/philippines-extreme-heat/</a>, See on <a href="https://news.ycombinator.com/item?id=40148012">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="jtarticle">
                                    <p><span>Manila – </span></p><p>Extreme heat scorched the Philippines on Wednesday, forcing thousands of schools to suspend in-person classes and prompting warnings for people to limit the amount of time spent outdoors.</p><p>The months of March, April and May are typically the hottest and driest in the archipelago nation, but conditions this year have been exacerbated by the El Nino weather phenomenon.</p><p>"It's so hot you can't breathe," said Erlin Tumaron, 60, who works at a seaside resort in Cavite province, south of Manila, where the heat index reached 47 degrees Celsius on Tuesday.</p>
                    
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A feature-rich front-end drag-and-drop component library (283 pts)]]></title>
            <link>https://github.com/atlassian/pragmatic-drag-and-drop</link>
            <guid>40147883</guid>
            <pubDate>Wed, 24 Apr 2024 18:25:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/atlassian/pragmatic-drag-and-drop">https://github.com/atlassian/pragmatic-drag-and-drop</a>, See on <a href="https://news.ycombinator.com/item?id=40147883">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">

<p dir="auto"><h2 tabindex="-1" dir="auto">About</h2><a id="user-content-about" aria-label="Permalink: About" href="#about"></a></p>
<p dir="auto">Pragmatic drag and drop is a low level drag and drop toolchain that enables safe and successful usage of the browsers built in drag and drop functionality. Pragmatic drag and drop can be used with any view layer (<a href="https://react.dev/" rel="nofollow"><code>react</code></a>, <a href="https://svelte.dev/" rel="nofollow"><code>svelte</code></a>, <a href="https://vuejs.org/" rel="nofollow"><code>vue</code></a>, <a href="https://angular.io/" rel="nofollow"><code>angular</code></a> and so on). Pragmatic drag and drop is powering some of the biggest products on the web, including <a href="https://trello.com/" rel="nofollow">Trello</a>, <a href="https://www.atlassian.com/software/jira" rel="nofollow">Jira</a> and <a href="https://www.atlassian.com/software/confluence" rel="nofollow">Confluence</a>.</p>
<details>
    <summary>Capabilities</summary>
<p dir="auto">Pragmatic drag and drop consists of a few high level pieces:</p>
<ol dir="auto">
<li><strong>Low level drag and drop behavior</strong></li>
</ol>
<p dir="auto">Pragmatic drag and drop contains a core package, and a number of optional packages, that provide you the pieces to create <em>any</em> drag and drop experience.</p>
<p dir="auto">These pieces are unopinionated about visual language or accessibility, and have no dependency on the Atlassian Design System.</p>
<ul dir="auto">
<li><em>Tiny</em>: ~<code>4.7kB</code> core</li>
<li><em>Incremental</em>: Only use the pieces that you need</li>
<li><em>Headless</em>: Full rendering and style control</li>
<li><em>Framework agnostic</em>: Works with any frontend framework</li>
<li><em>Deferred compatible</em>: Delay the loading the core packages and optional packages in order to further improve page load speeds</li>
<li><em>Flexible</em>: create any experience you want, make any changes you want during a drag operation.</li>
<li><em>Works everywhere</em>: Full feature support in Firefox, Safari, and Chrome, iOS and Android</li>
<li><em>Virtualization support</em>: create any virtual experience you want!</li>
</ul>
<ol start="2" dir="auto">
<li><strong>Optional visual outputs</strong></li>
</ol>
<p dir="auto">We have created optional visual outputs (eg our drop indicator) to make it super fast for us to build consistent Atlassian user experiences. Non Atlassian consumers are welcome to use these outputs, create their own that copy the visual styling, or go a totally different direction.</p>
<ol start="3" dir="auto">
<li><strong>Optional assistive technology controls</strong></li>
</ol>
<p dir="auto">Not all users can achieve pointer based drag and drop experiences. In order to achieve fantastic experiences for assistive technology users, we provide a toolchain to allow you to quickly wire up performant assistive technology friendly flows for any experience.</p>
<p dir="auto">The optional assistive controls we provide are based on the Atlassian Design System. If you do not want to use the Atlassian Design System, you can use our guidelines and substitute our components with your own components, or you can go about accessibility in a different way if you choose.</p>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is this repository?</h2><a id="user-content-what-is-this-repository" aria-label="Permalink: What is this repository?" href="#what-is-this-repository"></a></p>
<p dir="auto">This repository is currently one way mirror from our internal monorepo that contains all the code for Pragmatic drag and drop.</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/2182637/318564281-b45c2dfe-2c54-459e-a3e6-68b2342fe97b.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTM5OTk5MDYsIm5iZiI6MTcxMzk5OTYwNiwicGF0aCI6Ii8yMTgyNjM3LzMxODU2NDI4MS1iNDVjMmRmZS0yYzU0LTQ1OWUtYTNlNi02OGIyMzQyZmU5N2IucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDQyNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA0MjRUMjMwMDA2WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MWQwMTYyZTAzY2ZmNjAzZDhlNzE2OTc3MjYyM2M1OGM2OTU4ZTZlZjY3YWQ5MTgxZGYyYmEzZDk2YTY1NTVkZiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.TYJ6omA7YyBaTEUgm2eXaNIyMQNOv_FUCnmLl9LciSA"><img src="https://private-user-images.githubusercontent.com/2182637/318564281-b45c2dfe-2c54-459e-a3e6-68b2342fe97b.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTM5OTk5MDYsIm5iZiI6MTcxMzk5OTYwNiwicGF0aCI6Ii8yMTgyNjM3LzMxODU2NDI4MS1iNDVjMmRmZS0yYzU0LTQ1OWUtYTNlNi02OGIyMzQyZmU5N2IucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDQyNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA0MjRUMjMwMDA2WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MWQwMTYyZTAzY2ZmNjAzZDhlNzE2OTc3MjYyM2M1OGM2OTU4ZTZlZjY3YWQ5MTgxZGYyYmEzZDk2YTY1NTVkZiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.TYJ6omA7YyBaTEUgm2eXaNIyMQNOv_FUCnmLl9LciSA" alt="Diagram of how the mirror works" width="600px"></a>
</p>
<p dir="auto">The intention of this repository is to make public our code, but not to accept code contributions (at this stage). In the future we could explore setting up a two way mirror so that contributions to this repo can also make their way back to our monorepo. You are still welcome to raise issues or suggestions on this repository!</p>
<p dir="auto">All documentation and <code>npm</code> packages are public and available for use by everyone</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Can I use this with my own Design System?</h2><a id="user-content-can-i-use-this-with-my-own-design-system" aria-label="Permalink: Can I use this with my own Design System?" href="#can-i-use-this-with-my-own-design-system"></a></p>
<p dir="auto">Yep! Pragmatic drag and drop as a <a href="https://atlassian.design/components/pragmatic-drag-and-drop/core-package" rel="nofollow">small core package</a>, and then a range of <a href="https://atlassian.design/components/pragmatic-drag-and-drop/optional-package" rel="nofollow">optional packages</a>. Some of the optional packages have dependencies on styling solutions (eg <code>emotion</code>), view libraries (eg <code>react</code>) or on some additional Atlassian outputs (eg <code>@atlaskit/tokens</code>). We have separated out optional packages that have other dependencies so they can be easily swapped with your own pieces that use your own tech stack and visual outputs.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Can I use my own design language?</h2><a id="user-content-can-i-use-my-own-design-language" aria-label="Permalink: Can I use my own design language?" href="#can-i-use-my-own-design-language"></a></p>
<p dir="auto">Yep! We have created some design guidelines which embody how we want to achieve drag and drop in our products, and some of those decisions are embodied in some optional packages. However, you are free to use whatever design language you like, including ours!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is <code>@atlaskit</code>?</h2><a id="user-content-what-is-atlaskit" aria-label="Permalink: What is @atlaskit?" href="#what-is-atlaskit"></a></p>
<p dir="auto">The Pragmatic drag and drop packages are published under the <code>@atlaskit</code> namespace on <code>npm</code></p>
<div dir="auto" data-snippet-clipboard-copy-content="import { draggable } from '@atlaskit/pragmatic-drag-and-drop/element/adapter';"><pre><span>import</span> <span>{</span> <span>draggable</span> <span>}</span> <span>from</span> <span>'@atlaskit/pragmatic-drag-and-drop/element/adapter'</span><span>;</span></pre></div>
<p dir="auto"><code>@atlaskit</code> is the <code>npm</code> namespace that we publish all of our public packages on from inside our internal monorepo. We <em>could</em> look at creating a separate namespace in the future just for Pragmatic drag and drop. If we do that, we'll release some tooling to help folks automatically switch over.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Credits</h2><a id="user-content-credits" aria-label="Permalink: Credits" href="#credits"></a></p>
<p dir="auto">Made with love by:</p>
<ul dir="auto">
<li><a href="https://twitter.com/alexandereardon" rel="nofollow">Alex Reardon</a></li>
<li><a href="https://twitter.com/DeclanWarn" rel="nofollow">Declan Warn</a></li>
<li><a href="https://twitter.com/lewishealey" rel="nofollow">Lewis Healey</a></li>
<li><a href="https://www.linkedin.com/in/elenimisthos/" rel="nofollow">Eleni Misthos</a></li>
<li><a href="https://soundcloud.com/jessebauer" rel="nofollow">Jesse Bauer</a></li>
<li><a href="https://twitter.com/MitchG23" rel="nofollow">Mitch Gavan</a></li>
<li><a href="https://twitter.com/michaelguitars7" rel="nofollow">Michael Abrahamian</a></li>
<li><a href="https://twitter.com/ReDrUmNZ" rel="nofollow">Tim Keir</a></li>
<li><a href="https://www.linkedin.com/in/gretarit/" rel="nofollow">Greta Ritchard</a></li>
<li><a href="https://www.atlassian.com/" rel="nofollow">Many other folks at Atlassian</a></li>
<li>Logo created by <a href="https://twitter.com/michelleholik" rel="nofollow">Michelle Holik</a> and <a href="https://twitter.com/vojta_holik" rel="nofollow">Vojta Holik</a></li>
</ul>
<p dir="auto">Pragmatic drag and drop stands on the shoulders of giants, including the folks who created the <a href="https://html.spec.whatwg.org/multipage/dnd.html" rel="nofollow">drag and drop specifications</a>, implemented drag and drop in browsers, and the many drag and drop libraries that came before this.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[When do we stop finding new music? (316 pts)]]></title>
            <link>https://www.statsignificant.com/p/when-do-we-stop-finding-new-music</link>
            <guid>40147534</guid>
            <pubDate>Wed, 24 Apr 2024 17:50:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.statsignificant.com/p/when-do-we-stop-finding-new-music">https://www.statsignificant.com/p/when-do-we-stop-finding-new-music</a>, See on <a href="https://news.ycombinator.com/item?id=40147534">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3794bcbc-f1c9-48bf-ad20-f1f474f3de1a_800x514.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3794bcbc-f1c9-48bf-ad20-f1f474f3de1a_800x514.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3794bcbc-f1c9-48bf-ad20-f1f474f3de1a_800x514.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3794bcbc-f1c9-48bf-ad20-f1f474f3de1a_800x514.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3794bcbc-f1c9-48bf-ad20-f1f474f3de1a_800x514.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3794bcbc-f1c9-48bf-ad20-f1f474f3de1a_800x514.png" width="624" height="400.92" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3794bcbc-f1c9-48bf-ad20-f1f474f3de1a_800x514.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:514,&quot;width&quot;:800,&quot;resizeWidth&quot;:624,&quot;bytes&quot;:825644,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3794bcbc-f1c9-48bf-ad20-f1f474f3de1a_800x514.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3794bcbc-f1c9-48bf-ad20-f1f474f3de1a_800x514.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3794bcbc-f1c9-48bf-ad20-f1f474f3de1a_800x514.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3794bcbc-f1c9-48bf-ad20-f1f474f3de1a_800x514.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>Say Anything (1989). Credit: 20th Century Studios.</figcaption></figure></div><p>I recently tried Spotify's new DJ feature in which an AI bot curates personalized listening sessions, introducing songs while explaining the intention behind its selections (much like a real-life disc jockey). Every four or five pieces, the bot interjects to set up its next block of music, ascribing a theme to these upcoming works. Here are some of my example introductions:</p><ul><li><p>"Next, we're gonna play some of your favorites from 2016."</p></li><li><p>"Here are some of your favorite indie rock songs from the 2010s."&nbsp; &nbsp;&nbsp;</p></li><li><p>"Up next, we have some music inspired by your love of 2000s hip-hop."</p></li></ul><p>With each DJ interlude, something became increasingly clear: my music taste had barely changed over the course of a decade. Armed with full knowledge of my musical interests, this AI agent had pinpointed my musical paralysis, packaging an algorithmic echo chamber of 2010s indie rock, 2000s pop, Bo Burnham, Blink-182, and Bruce Springsteen. Had my music taste stagnated?&nbsp; &nbsp; &nbsp;</p><p>This minor existential tailspin sent me down a Google rabbit hole—I began frantically researching music paralysis and the science of sonic preference. Was this phenomenon of my own doing or a natural product of aging? Fortunately, the topic of song stagnation has been well-researched, aided by the robust datasets of streaming services.&nbsp;</p><p>So today, we'll explore how our relationship to music changes with age and the developmental phenomena driving our forever-shifting cultural tastes.</p><p>Open-earedness refers to an individual's desire and ability to listen and consider different sounds and musical styling. Research has shown that adolescents exhibit higher levels of open-earedness, with a greater willingness to explore and appreciate diverse musical genres. During these years of sonic exploration, music gets wrapped up in the emotion and identity formation of youth; as a result, the songs of our childhood prove wildly influential over our lifelong music tastes.</p><p><span>A New York Times analysis of Spotify data revealed that </span><a href="https://www.nytimes.com/2018/02/10/opinion/sunday/favorite-songs.html" rel="">our most-played songs often stem from our teenage years, particularly between the ages of 13 and 16</a><span>.</span></p><p>This finding has personal resonance, as I remember my cultural preferences being easily influenced during my pre-teen and early teenage years. For instance, I was twelve when Green Day released their landmark "American Idiot" album, a work that proved monumental in my relationship to music. Listening to the album's titular track felt like a supreme act of rebellion (for a twelve-year-old suburbanite). I was entranced by this song's iconoclastic spirit—could they actually say, "f**k America?" &nbsp; &nbsp; &nbsp;</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6143e4a-29e6-4e37-9c9d-91880dd2bb94_1898x1032.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6143e4a-29e6-4e37-9c9d-91880dd2bb94_1898x1032.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6143e4a-29e6-4e37-9c9d-91880dd2bb94_1898x1032.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6143e4a-29e6-4e37-9c9d-91880dd2bb94_1898x1032.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6143e4a-29e6-4e37-9c9d-91880dd2bb94_1898x1032.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6143e4a-29e6-4e37-9c9d-91880dd2bb94_1898x1032.png" width="514" height="279.5934065934066" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e6143e4a-29e6-4e37-9c9d-91880dd2bb94_1898x1032.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:792,&quot;width&quot;:1456,&quot;resizeWidth&quot;:514,&quot;bytes&quot;:2637748,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6143e4a-29e6-4e37-9c9d-91880dd2bb94_1898x1032.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6143e4a-29e6-4e37-9c9d-91880dd2bb94_1898x1032.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6143e4a-29e6-4e37-9c9d-91880dd2bb94_1898x1032.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6143e4a-29e6-4e37-9c9d-91880dd2bb94_1898x1032.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>American Idiot Music Video: Credit: Reprise Records.</figcaption></figure></div><p>But "American Idiot" wasn't a true act of revolution. In fact, the album was produced and promoted by a multinational conglomerate with the intent of packaging seemingly transgressive pop-punk acts for my exact demographic. How was I so thoroughly seduced by this song? And yet, to this day, my visceral reaction to “American Idiot” is still one of euphoria, despite my cynicism. I guess I have no choice but to love this song forever (thanks to pre-teen me).&nbsp;</p><p><span>Indeed, </span><a href="https://today.yougov.com/entertainment/articles/36462-best-decade-for-music-americans-poll-data?redirect_from=%2Ftopics%2Fentertainment%2Farticles-reports%2F2021%2F06%2F16%2Fbest-decade-for-music-americans-poll-data" rel="">YouGov survey data indicates a strong bias toward music from our teenage years</a><span>, a phenomenon that is consistent across generations. Every cohort believes that music was "better back in my day."&nbsp;&nbsp;</span></p><p>Ultimately, cultural preferences are subject to generational relativism, heavily rooted in the media of our adolescence. It's strange how much your 13-year-old self defines your lifelong artistic tastes. At this age, we're unable to drive, vote, drink alcohol, or pay taxes, yet we're old enough to cultivate enduring musical preferences.&nbsp;</p><p>The pervasive nature of music paralysis across generations suggests that the phenomenon's roots go beyond technology, likely stemming from developmental factors. So what changes as we age, and when does open-eardness decline?</p><p><strong><a href="https://www.businessinsider.com/why-we-stop-discovering-new-music-around-age-30-2018-6#:~:text=A%20survey%20from%20music%20streaming%20service%20Deezer,choice%2C%20and%20busy%20with%20work%20and%20children." rel="">Survey</a></strong><a href="https://www.businessinsider.com/why-we-stop-discovering-new-music-around-age-30-2018-6#:~:text=A%20survey%20from%20music%20streaming%20service%20Deezer,choice%2C%20and%20busy%20with%20work%20and%20children." rel="">&nbsp;</a><strong><a href="https://www.businessinsider.com/why-we-stop-discovering-new-music-around-age-30-2018-6#:~:text=A%20survey%20from%20music%20streaming%20service%20Deezer,choice%2C%20and%20busy%20with%20work%20and%20children." rel="">research from European streaming service Deezer indicates that</a></strong><a href="https://www.businessinsider.com/why-we-stop-discovering-new-music-around-age-30-2018-6#:~:text=A%20survey%20from%20music%20streaming%20service%20Deezer,choice%2C%20and%20busy%20with%20work%20and%20children." rel="">&nbsp;</a><strong><a href="https://www.businessinsider.com/why-we-stop-discovering-new-music-around-age-30-2018-6#:~:text=A%20survey%20from%20music%20streaming%20service%20Deezer,choice%2C%20and%20busy%20with%20work%20and%20children." rel="">music discovery peaks at 24</a></strong><span>, with survey respondents reporting increased variety in their music rotation during this time. However, after this age, our ability to keep up with music trends typically declines, with respondents reporting significantly lower levels of discovery in their early thirties. Ultimately,</span><strong>&nbsp;the Deezer study pinpoints 31 as the age when musical tastes start to stagnate.</strong></p><p><span>These findings have been replicated across numerous analyses, including a study of Spotify user data from 2014. Produced from Spotify's internal dataset, this </span><a href="https://skynetandebert.com/2015/04/22/music-was-better-back-then-when-do-we-stop-keeping-up-with-popular-music/" rel="">research explores how tastes deviate from the mainstream with age</a><span>. In this analysis, a contemporary pop star like Dua Lipa would score a 1 (the most popular), and an artist further out of the zeitgeist like Led Zeppelin would rank somewhere in the 200s. The resulting visual is unnerving as we observe our cultural preferences (quite literally) spiral away from the mainstream as we grow older.</span></p><p><strong>This study identifies 33 as the tipping point for sonic stagnation</strong><span>, an age where artistic taste calcifies, increasingly deviating from contemporary works. But wait, there's more. Spotify data indicates that parents stray from the mainstream at an accelerated rate compared to empty nesters—a sort of "parent tax" on one's cultural relevancy.</span></p><p><span>But this stagnation goes beyond the popularity of our music selections; it's also the diversity across these works. From 30 onward, we listen to more music outside the mainstream and </span><a href="https://musicmachinery.com/2014/02/13/age-specific-listening/" rel="">sample fewer artists during streaming sessions</a><span>.</span></p><p>Reading these studies proved an existential body blow because I am 31, apparently on the precipice of becoming a musical dinosaur. I like to think I'm special—that my high-minded dedication to culture makes me an exceptionally unique snowflake—but apparently I'm just like everybody else. I turned 30, and now I'm in a musical rut, content to have an AI bot DJ pacify me with the songs of my youth.&nbsp;</p><p>I used to spend hours researching artists, scrutinizing my CD purchases, and, later, my iTunes selections. Musical exploration was an activity in and of itself; songs were more than background noise. Now, I'm stuck listening to James Blunt's "You're Beautiful" for the 1,000th time. What happened to me?</p><p><span>Music paralysis is the product of both biological trends and practical constraints. Deezer survey respondents who identified as being "in a musical rut" </span><a href="https://www.businessinsider.com/why-we-stop-discovering-new-music-around-age-30-2018-6#:~:text=A%20survey%20from%20music%20streaming%20service%20Deezer,choice%2C%20and%20busy%20with%20work%20and%20children." rel="">cited numerous day-to-day limitations as cause for their stagnation, with the top three reasons being</a><span>:&nbsp;</span></p><ol><li><p>Overwhelmed by the amount of choice available: 19%</p></li><li><p>Having a demanding job: 16%</p></li><li><p>Caring for young children: 11%</p></li></ol><p>This first point regarding the paradox of choice is especially intriguing and would speak to streaming as some sort of societal ill, bombarding us with boundless content. It's easy to condemn Spotify for giving us too many options, but this complaint is likely emblematic of a broader developmental shift.&nbsp;</p><p><span>Context is critical to cultural discovery. An extensive cross-sectional study regarding musical attitudes and preferences from adolescence through middle age found that </span><a href="https://www.researchgate.net/publication/253337104_Music_Through_the_Ages_Trends_in_Musical_Engagement_and_Preferences_From_Adolescence_Through_Middle_Adulthood" rel="">our relationship with music drastically changes over time</a><span>. Surveying over 250,000 individuals, this study found:</span></p><ol><li><p>The degree of importance attributed to music declines with age, even though adults still consider music important.</p></li><li><p>Young people listen to music significantly more than middle-aged adults.</p></li><li><p>Young people listen to music in a wide variety of contexts and settings, whereas adults listen to music primarily in private contexts.</p></li></ol><p>The issue of music discovery does not originate from infinite choice; instead, this problem likely stems from decreased listenership and a waning commitment to exploration. Spending two hours a day combing through iTunes (now Spotify) is impractical. My priorities have changed, my emotional connection to music has changed, and I simply just don't have the time.&nbsp; &nbsp;</p><p>Indeed, this same cross-sectional study revealed that musical preferences are closely related to trends in psychosocial development. In this survey, researchers investigated how tastes vary across five dimensions as we age: intensity, contemporaneous, unpretentiousness, sophistication, and mellowness. The data they collected demonstrates a universality to our forever-changing relationship with music—it's natural to expect a progression in our preferences.&nbsp;</p><p>It's tempting to despair over these results, to accept changing cultural attitudes and the phenomenon of music paralysis as a predetermined truth. At the same time, stagnation is not a certainty. Research suggests that open-eardness and the discovery of new songs can be cultivated. Finding new music is a challenge, but it is achievable with dedicated time and effort. If we avoid the warm complacency of nostalgia, we can recapture our flare for music discovery.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e0a2b5-3d4c-4565-8ba2-752e410b8d6c_1200x720.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e0a2b5-3d4c-4565-8ba2-752e410b8d6c_1200x720.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e0a2b5-3d4c-4565-8ba2-752e410b8d6c_1200x720.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e0a2b5-3d4c-4565-8ba2-752e410b8d6c_1200x720.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e0a2b5-3d4c-4565-8ba2-752e410b8d6c_1200x720.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e0a2b5-3d4c-4565-8ba2-752e410b8d6c_1200x720.png" width="616" height="369.6" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/31e0a2b5-3d4c-4565-8ba2-752e410b8d6c_1200x720.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:720,&quot;width&quot;:1200,&quot;resizeWidth&quot;:616,&quot;bytes&quot;:1302433,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e0a2b5-3d4c-4565-8ba2-752e410b8d6c_1200x720.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e0a2b5-3d4c-4565-8ba2-752e410b8d6c_1200x720.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e0a2b5-3d4c-4565-8ba2-752e410b8d6c_1200x720.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e0a2b5-3d4c-4565-8ba2-752e410b8d6c_1200x720.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>High Fidelity (2000). Credit: Buena Vista Pictures.</figcaption></figure></div><p><span>My father "likes what he likes": Bruce Springsteen,&nbsp;</span><em>Field of Dreams</em><span>, The Washington Nationals, and consistently reminding me that Fleetwood Mac's&nbsp;</span><em>Rumours</em><span>&nbsp;was made after its bandmates divorced one another. Whenever I point out my dad's stubborn habits, he'll look at me, smile, and quote the immortal wisdom of Popeye: "I am what I am."&nbsp;&nbsp;</span></p><p>When I was younger, I strongly disliked this rationale. Surely, there is no fixed version of who we are. Humans are constantly evolving—perpetually engaged in self-discovery. But maybe this isn't the case for all facets of life.&nbsp; &nbsp;</p><p>The explore-exploit trade-off refers to the dilemma between seeking new information (exploring) and optimizing decisions based on known information (exploiting). Some examples of the explore-exploit trade-off include:&nbsp;</p><ul><li><p><strong>Restaurant selection</strong><span>: Do you find a new restaurant or return to your old haunts?&nbsp;</span></p></li><li><p><strong>Movies</strong><span>: Do you watch something new or re-watch an all-time favorite?&nbsp;&nbsp;</span></p></li><li><p><strong>Career</strong><span>: Should you keep your current job or look for a new one?</span></p></li></ul><p>In the case of music discovery, exploring would consist of finding new songs and subgenres, while exploiting would entail listening to already-beloved tunes.</p><p>The explore-exploit trade-off and an adjacent decision-making puzzle known as the optimal-stopping problem have prompted extensive research and the coining of a shortcut known as the 37% rule. This heuristic suggests we spend the first 37% of available search time exploring our options before settling on a preferred solution or selection.&nbsp;&nbsp;</p><p>In the case of musical preference, the current American lifespan averages 80 years; when we multiply this figure by 37%, we get 30 years—coincidentally, the age at which music tastes stagnate. This back-of-the-envelope math could be interpreted in two ways:&nbsp;</p><ol><li><p><strong>I am going crazy</strong><span>: I see numbers and symbols that don't mean anything. The 37% rule is a vague heuristic that may not even apply to this case, and I am perceiving order from true randomness. </span></p></li><li><p><strong>30 is our optimal stopping point</strong><span>: Despite the 37% rule being a highly generalized heuristic, there is some merit to doubling down on our favorites after a sustained period of searching—a phenomenon that appears to be our default state. We spend 30 years exploring new music, and once we've sampled enough works, we reach an optimal stopping point, comfortable with our rotation of artists and songs.</span></p></li></ol><p>Maybe music paralysis is a feature, not a bug. Running on a never-ending treadmill of cultural exploration may be a recipe for discontent. There is nothing inherently wrong with "liking what you like." Is it my waning music discovery that's making me unhappy or the fact that I've yet to accept this reality?</p><p>Perhaps I should forsake sonic exploration and exploit my love of "American Idiot," 2010s indie rock, 2000s pop, Bo Burnham, Blink-182, and Bruce Springsteen, content to live in an algorithmic echo chamber curated by DJ—my new AI savior.&nbsp;</p><div data-attrs="{&quot;url&quot;:&quot;https://www.statsignificant.com/p/when-do-we-stop-finding-new-music?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="CaptionedButtonToDOM"><p>This post is public so feel free to share it.</p><p data-attrs="{&quot;url&quot;:&quot;https://www.statsignificant.com/p/when-do-we-stop-finding-new-music?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="ButtonCreateButton"><a href="https://www.statsignificant.com/p/when-do-we-stop-finding-new-music?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div><p><em><span>Want to chat about data and statistics? Have an interesting data project? Just want to say hi? Email </span><a href="http://daniel@statsignificant.com/" rel="">daniel@statsignificant.com</a></em><span>&nbsp; &nbsp;&nbsp; &nbsp;</span><strong>&nbsp;</strong><span>&nbsp; </span></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TypeScript: Branded Types (169 pts)]]></title>
            <link>https://prosopo.io/articles/typescript-branding/</link>
            <guid>40146751</guid>
            <pubDate>Wed, 24 Apr 2024 16:48:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://prosopo.io/articles/typescript-branding/">https://prosopo.io/articles/typescript-branding/</a>, See on <a href="https://news.ycombinator.com/item?id=40146751">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong><a href="https://prosopo.io/articles/typescript-mapped-type-magic/">PART 1: TypeScript Mapped Type Magic</a></strong></p><p>Ahoy there TypeScript warriors! 👋 Today we're extending our work in the <a href="https://prosopo.io/articles/typescript-mapped-type-magic/">TypeScript mapped types article</a> to provide <em>branding</em>. The previous article discussed how to use TypeScript mapped types in a nominal rather than structural nature.</p><pre><code><span>type</span> <span><span>A</span></span> <span>=</span> <span>{</span>
    x<span>:</span> <span>number</span>
<span>}</span>

<span>type</span> <span><span>B</span></span> <span>=</span> <span>{</span>
    x<span>:</span> <span>number</span>
<span>}</span></code></pre><p>This is a fancy way of saying TypeScript is structural by default, i.e. it will see type <code>A</code> and <code>B</code> as equal when dealing with types. Making type <code>A</code> and <code>B</code> nominal would make TypeScript differentiate them apart, even though their structure is the same.</p><p>In this post, we're building on that work to produce a way to <em>brand</em> a type, providing an automated and easy-to-use way of making a type nominal. Branding focuses on the type system only, rather than introducing runtime fields like in the previous post, which is a major benefit over the previous approach.</p><h2>What's the problem?</h2><p>Branding, also known as opaque types, enable differentiation of types in TypeScript which otherwise would be classified as the same type. For example</p><pre><code>
<span>type</span> <span><span>A</span></span> <span>=</span> <span>{</span>
    x<span>:</span> <span>number</span><span>,</span>
    y<span>:</span> <span>boolean</span><span>,</span>
    z<span>:</span> <span>string</span><span>,</span>
<span>}</span>

<span>type</span> <span><span>B</span></span> <span>=</span> <span>{</span>
    x<span>:</span> <span>number</span><span>,</span>
    y<span>:</span> <span>boolean</span><span>,</span>
    z<span>:</span> <span>string</span><span>,</span>
<span>}</span>
</code></pre><p><code>A</code> and <code>B</code> are structurally the same, ergo TypeScript accepts any instance of <code>A</code> or <code>B</code> in place of each other:</p><pre><code>
<span>const</span> <span>fn</span> <span>=</span> <span>(</span>a<span>:</span> <span>A</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>'do something with A'</span><span>)</span>
<span>}</span>

<span>const</span> obj<span>:</span> <span>B</span> <span>=</span> <span>{</span>
    x<span>:</span> <span>1</span><span>,</span>
    y<span>:</span> <span>true</span><span>,</span>
    z<span>:</span> <span>'hello'</span>
<span>}</span>

<span>fn</span><span>(</span>obj<span>)</span> <span>// absolutely fine, even though fn accepts types of A and obj is of type B!</span></code></pre><p>The function is looking for a value of type <code>A</code> as input, whereas we're passing it a value of type <code>B</code>. TypeScript compares the types structurally, and because they have exactly the same structure it deems this operation to be fine.</p><p>But what if we need to tell <code>A</code> and <code>B</code> apart? What if, conceptually speaking, they must be different? What if we're doing something fancy with <code>A</code> and <code>B</code> which TypeScript is unaware of but we require the types to be different? That's exactly the situation we found ourselves in lately!</p><p>We need branding to do exactly that.</p><h2>The solution</h2><p>Much like in the <a href="https://prosopo.io/articles/typescript-mapped-type-magic/">TypeScript mapped types article</a>, the key lies in creating a field with the name of a symbol to act as our <em>id</em>. However, with branding we only need this field at a type-level rather than the runtime-level. Since types are erased after compilation, we need to add this field to a type without altering the runtime data whatsoever. Casting, anyone?</p><p>First, lets introduce the <code>brand</code> field.</p><pre><code>
<span>const</span> brand <span>=</span> <span>Symbol</span><span>(</span><span>'brand'</span><span>)</span> <span>// keep this private!!</span>

<span>type</span> <span><span>A</span></span> <span>=</span> <span>{</span>
    x<span>:</span> <span>number</span><span>,</span>
    y<span>:</span> <span>boolean</span><span>,</span>
    z<span>:</span> <span>string</span><span>,</span>
<span>}</span> <span>&amp;</span> <span>{</span>
    <span>[</span>brand<span>]</span><span>:</span> <span>'A'</span>
<span>}</span></code></pre><p>Here we're adding the <code>brand</code> field to type <code>A</code>. The brand field name is a symbol, akin to a UUID. We use a symbol to ensure the <code>brand</code> field never clashes with any other field for <code>A</code>, because we'd be overwriting a field otherwise and introducing the worse kind of bugs: type bugs 🐛 . We've set the brand to <code>'A'</code> at the moment, though this could be anything you desire. It's akin to the type name. Now let's compare <code>A</code> and <code>B</code> again:</p><pre><code>
<span>const</span> <span>fn</span> <span>=</span> <span>(</span>a<span>:</span> <span>A</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>'do something with A'</span><span>)</span>
<span>}</span>

<span>const</span> obj<span>:</span> <span>B</span> <span>=</span> <span>{</span>
    x<span>:</span> <span>1</span><span>,</span>
    y<span>:</span> <span>true</span><span>,</span>
    z<span>:</span> <span>'hello'</span>
<span>}</span>

<span>fn</span><span>(</span>obj<span>)</span> <span>// Error!</span></code></pre><p>Here's the error:</p><pre><code>Argument of type 'B' is not assignable to parameter of type 'A'.
  Property '[brand]' is missing in type 'B' but required in type '{ [brand]: "a"; }'.ts(2345)
</code></pre><p>TypeScript won't let us pass an instance of <code>B</code> to the function accepting <code>A</code> because it's missing the <code>brand</code> field - brilliant! <code>A</code> and <code>B</code> are now different types. But what about if <code>B</code> had its own brand?</p><pre><code>
<span>type</span> <span><span>B</span></span> <span>=</span> <span>{</span>
    x<span>:</span> <span>number</span><span>,</span>
    y<span>:</span> <span>boolean</span><span>,</span>
    z<span>:</span> <span>string</span><span>,</span>
<span>}</span> <span>&amp;</span> <span>{</span>
    <span>[</span>brand<span>]</span><span>:</span> <span>'B'</span>
<span>}</span></code></pre><p>Note that we're using the same <code>brand</code> variable from before. It's important to keep this constant, otherwise we're declaring fields with different names!</p><p>Now lets try the function again:</p><pre><code>
<span>const</span> <span>fn</span> <span>=</span> <span>(</span>a<span>:</span> <span>A</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>'do something with A'</span><span>)</span>
<span>}</span>

<span>const</span> obj<span>:</span> <span>B</span> <span>=</span> <span>{</span>
    x<span>:</span> <span>1</span><span>,</span>
    y<span>:</span> <span>true</span><span>,</span>
    z<span>:</span> <span>'hello'</span>
<span>}</span>

<span>fn</span><span>(</span>obj<span>)</span> <span>// Error!</span></code></pre><p>And here's the error</p><pre><code>Argument of type 'B' is not assignable to parameter of type 'A'.
  Type 'B' is not assignable to type '{ [brand]: "A"; }'.
    Types of property '[brand]' are incompatible.
      Type '"B"' is not assignable to type '"A"'.ts(2345)
</code></pre><p>There we go! The error is saying that though both types have a <code>brand</code> field, the value for the brand is different for the two types, i.e. <code>'A' != 'B'</code>!</p><p>Let's see what happens if the <code>brand</code> is the same:</p><pre><code>

<span>type</span> <span><span>A</span></span> <span>=</span> <span>{</span>
    x<span>:</span> <span>number</span><span>,</span>
    y<span>:</span> <span>boolean</span><span>,</span>
    z<span>:</span> <span>string</span><span>,</span>
<span>}</span> <span>&amp;</span> <span>{</span>
    <span>[</span>brand<span>]</span><span>:</span> <span>'foobar'</span>
<span>}</span>

<span>type</span> <span><span>B</span></span> <span>=</span> <span>{</span>
    x<span>:</span> <span>number</span><span>,</span>
    y<span>:</span> <span>boolean</span><span>,</span>
    z<span>:</span> <span>string</span><span>,</span>
<span>}</span> <span>&amp;</span> <span>{</span>
    <span>[</span>brand<span>]</span><span>:</span> <span>'foobar'</span>
<span>}</span>

<span>const</span> <span>fn</span> <span>=</span> <span>(</span>a<span>:</span> <span>A</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>'do something with A'</span><span>)</span>
<span>}</span>

<span>const</span> obj<span>:</span> <span>B</span> <span>=</span> <span>{</span>
    x<span>:</span> <span>1</span><span>,</span>
    y<span>:</span> <span>true</span><span>,</span>
    z<span>:</span> <span>'hello'</span>
<span>}</span>

<span>fn</span><span>(</span>obj<span>)</span> <span>// absolutely fine!</span>
</code></pre><p>No error! <code>A</code> and <code>B</code> are seen as interchangeable types because they're structurally the same, having the same fields <em>and</em> same brand value of <code>'foobar'</code>. Excellent!</p><h2>Make it generic!</h2><p>Awesome, so that works. But it's a toy example, not fit for production. Let's create a <code>Brand</code> type which can brand any type you wish:</p><pre><code><span>const</span> brand <span>=</span> <span>Symbol</span><span>(</span><span>'brand'</span><span>)</span> <span>// keep this private!</span>

<span>type</span> <span>Brand<span>&lt;</span><span>T</span><span>,</span> <span>U</span><span>&gt;</span></span> <span>=</span> <span>T</span> <span>&amp;</span> <span>{</span>
    <span>[</span>brand<span>]</span><span>:</span> <span>U</span>
<span>}</span></code></pre><p>This type is very simple, it takes your type <code>T</code> and adds a <code>brand</code> field with <code>U</code> being the brand value. Here's how to use it:</p><pre><code>
<span>type</span> <span>A_Unbranded</span> <span>=</span> <span>{</span>
    x<span>:</span> <span>number</span><span>,</span>
    y<span>:</span> <span>boolean</span><span>,</span>
    z<span>:</span> <span>string</span><span>,</span>
<span>}</span>

<span>type</span> <span><span>A</span></span> <span>=</span> Brand<span>&lt;</span>A_Unbranded<span>,</span> <span>'A'</span><span>&gt;</span> <span>// {</span>
<span>//     x: number;</span>
<span>//     y: boolean;</span>
<span>//     z: string;</span>
<span>// } &amp; {</span>
<span>//     [brand]: "A";</span>
<span>// }</span></code></pre><p>So now we can brand any type. For completeness, here's the same kind of thing to <em>remove</em> the brand and go back to plain ol' TypeScript types:</p><pre><code><span>type</span> <span>RemoveBrand<span>&lt;</span><span>T</span><span>&gt;</span></span> <span>=</span> <span>T</span><span>[</span>Exclude<span>&lt;</span><span>keyof</span> <span>T</span><span>,</span> <span>typeof</span> brand<span>&gt;</span><span>]</span></code></pre><p>And this will remove the <code>brand</code> field from any branded type. Also note that if the type is not branded, it will not be touched!</p><h2>Real world usage</h2><p>Let's put this into practice. We've got a class which needs branding to identify its type when dealing with <a href="https://prosopo.io/articles/typescript-mapped-type-magic/">mapped types</a>.</p><p>For simplicity, lets boil the class down to a <code>Dog</code> class:</p><pre><code>
<span>class</span> <span>Dog</span> <span>{</span>
    <span>constructor</span><span>(</span><span>public</span> name<span>:</span> <span>string</span><span>)</span> <span>{</span><span>}</span>
<span>}</span>

<span>type</span> <span>DogBranded</span> <span>=</span> Brand<span>&lt;</span>Dog<span>,</span> <span>'Dog'</span><span>&gt;</span>

<span>const</span> dog <span>=</span> <span>new</span> <span>DogBranded</span><span>(</span><span>'Spot'</span><span>)</span> <span>// Error!</span>
</code></pre><p>TypeScript won't let us construct a branded dog 😢 . We're going to need to do some casting using the constructor to brand the <em>constructor</em> rather than the <em>class</em> itself.</p><pre><code>
<span>type</span> <span>Ctor<span>&lt;</span><span>T</span><span>&gt;</span></span> <span>=</span> <span>new</span> <span>(</span><span>...</span>args<span>:</span> <span>any</span><span>[</span><span>]</span><span>)</span> <span>=&gt;</span> <span>T</span>

<span>const</span> addBrand <span>=</span> <span>&lt;</span><span>T</span><span>&gt;</span><span>(</span>ctor<span>:</span> Ctor<span>&lt;</span><span>T</span><span>&gt;</span><span>,</span> name<span>:</span> <span>string</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>return</span> ctor <span>as</span> Ctor<span>&lt;</span>Brand<span>&lt;</span><span>T</span><span>,</span> <span>typeof</span> name<span>&gt;&gt;</span>
<span>}</span>

<span>const</span> DogBranded <span>=</span> <span>addBrand</span><span>(</span>Dog<span>,</span> <span>'Dog'</span><span>)</span>

<span>const</span> dog <span>=</span> <span>new</span> <span>DogBranded</span><span>(</span><span>'Spot'</span><span>)</span> <span>// ok</span></code></pre><p>The <code>addBrand</code> function takes a constructor of a class and casts it to a branded type. This essentially makes an alias for the <code>Dog</code> class which can be used in exactly the same way as the <code>Dog</code> class, e.g. calling <code>new</code> on it.</p><p>We can <code>export</code> the <code>DogBranded</code> type to allow the outer world to use our class whilst ensuring it's always branded:</p><pre><code><span>export</span> <span>type</span> <span>DogExported</span> <span>=</span> <span>typeof</span> DogBranded</code></pre><p>Likewise, we can do the same for brand removal:</p><pre><code>
<span>const</span> removeBrand <span>=</span> <span>&lt;</span><span>T</span><span>&gt;</span><span>(</span>value<span>:</span> <span>T</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>return</span> value <span>as</span> RemoveBrand<span>&lt;</span><span>T</span><span>&gt;</span>
<span>}</span></code></pre><p>This simply removes the brand by casting the type to a type mapped without the brand field.</p><p>And there we go: a sure-fire way to brand and un-brand your types in TypeScript 😃</p><p>We've published this work as a library which you can access via <a href="https://www.npmjs.com/package/@prosopo/ts-brand">NPM</a>!</p><p>At Prosopo, we're using TypeScript branding to fortify our types and do clever type mapping for our soon-to-be-released runtime type validator. Stay tuned for updates!</p><p><strong><a href="https://prosopo.io/articles/typescript-mapped-type-magic/">PART 1: TypeScript Mapped Type Magic</a></strong></p><hr></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Borrow Checking, RC, GC, and the Eleven () Other Memory Safety Approaches (153 pts)]]></title>
            <link>https://verdagon.dev/grimoire/grimoire</link>
            <guid>40146615</guid>
            <pubDate>Wed, 24 Apr 2024 16:39:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://verdagon.dev/grimoire/grimoire">https://verdagon.dev/grimoire/grimoire</a>, See on <a href="https://news.ycombinator.com/item?id=40146615">Hacker News</a></p>
<div id="readability-page-1" class="page"><div class="page">
  

        <div>
          <div>
  

            <div>
    

              
    

              <p>The Memory Safety Grimoire, Part 1</p>
        

              <p><span>April 24, 2024</span>
        

                <span>&nbsp;—&nbsp;</span>
          

                
        

              </p>
      

            </div>
    
<section>
<p>
A fellow named Zeke came into my server one day.
</p>

</section>
<section>
<p>
<b>Zeke:</b> "Wait, so with generational references, we now have <b>four</b> ways to do memory safety?"
</p>
<p>
<b>Evan:</b> "In fact, there are <b>fourteen</b> by my count. Maybe more!" <a href="#note0" data-noteid="0">0</a>
</p>
<p>
<b>Zeke:</b> "Fourteen?!"
</p>

</section>
<section>
<p>
I've gotten so used to it that it's not surprising to me anymore, so it's always a delight to vicariously feel people's surprise when I tell them this.
</p>

</section>
<section>
<p>
<b>Evan:</b> "Indeed," and I proceed to show him <i>the grimoire</i> <a href="#note1" data-noteid="1">1</a> that I've kept secret all these years.
</p>
<p>
<b>Zeke:</b> "How did you find all these?!"
</p>

</section>
<section>
<p>
At this point, I likely told him some nonsense like "I just kept my eyes open and collected them over the years!" but I think that you, my dear reader, deserve to know <b>the truth!</b> <a href="#note2" data-noteid="2">2</a>
</p>

</section>
<section>
<p>
This article is the introduction to my secret collection of memory safety techniques, which I call the <b>memory safety grimoire</b>.
</p>

</section>
<section>
<p>
With this wisdom, one can see the vast hidden landscape of memory safety, get a hint about where the programming world might head in the next decades, and even design new memory safety approaches. <a href="#note3" data-noteid="3">3</a>
</p>

</section>
<section>
<p>
If you like this topic, check out this <a href="https://www.youtube.com/watch?v=UavYVf0UEoc">Developer Voices episode</a> where Kris Jenkins and I talked about linear types and regions!
</p>

</section>

      </div>
  
<div>

      <nav>
      <p>Borrow checking, RC, GC, and the Eleven (!) Other Memory Safety Approaches</p>
    
<ul>
</ul>

      </nav>
      
    

      <div>
    
<div id="note0" data-noteid="0">
<p><span>0</span></p><section>
<p>
And I'd bet that someone on reddit or HN will comment on some I haven't heard before, and I'll have to change the title and add to the list!
</p>

</section>
</div>
<div id="note1" data-noteid="1">
<p><span>1</span></p><section>
<p>
 A grimoire is a cursed spellbook, like the necronomicon.
</p>
<p>
However, those of weak wills should be careful not to read grimoires... they might end up pursuing the dark arts for years.

</p>

</section>
</div>
<div id="note2" data-noteid="2">
<p><span>2</span></p><section>
<p>
Or perhaps this entire article is just a clever ruse, the <a href="https://hpmor.com/chapter/35">mask behind the mask</a>, and the truth still remains a secret.
</p>

</section>
</div>


        </div>
    
</div>

    </div>
    <div>
      <div>
  
<section>
<h2 id="a-cursd-tome-and-ancient-memory-safety">
 A Curséd Tome, and Ancient Memory Safety</h2>
<p>
Mid-2023, a team of archaeologists discovered <a href="https://www.reuters.com/world/americas/ancient-maya-city-discovered-mexican-jungle-2023-06-21/">an ancient Mayan city in Campeche</a>. I was on the ground as the team's consulting software engineer, as the Mayans were known as some of the earliest and most powerful practitioners of the software arts.
</p>

</section>
<section>
<p>
The hours are long and there's always the chance of being kidnapped and ransomed by the marauding bands of <a href="https://www.fodors.com/world/mexico-and-central-america/mexico/yucatan-and-campeche-states/experiences/news/photos/10-fantastic-beasts-of-the-yucatan-and-where-to-find-them">white-nosed coatis</a>, <a href="#note4" data-noteid="4">4</a> but nobody asks me if I can add an RSS feed to a DBMS, so there's that. <a href="#note5" data-noteid="5">5</a>
</p>

</section>
<section>
<p>
Our leader Ivan was hoping that this ancient city might contain a fifth memory safety tome, similar to the ancient borrow checking codex that Graydon Hoare found in the <a href="https://www.theguardian.com/world/2016/nov/17/mexican-pyramid-has-two-more-inside-scientists-discover">Kukulkan pyramid</a> in 2016.
</p>

</section>
<section>
<p>
We made it to the central pyramid, and discovered a pedestal with a tattered tome, surprisingly intact after all this time. <a href="#note6" data-noteid="6">6</a> 
</p>

</section>
<section>
<p>
With my heart pounding, I approached the pedestal, looking closer at the inscriptions on the front. Sure enough, it had the Mayan symbols for "stack frame", "reference", and "region" on the front! We'd found it!
</p>

</section>

      </div>
  
<div>
    
<div id="note4" data-noteid="4">
<p><span>4</span></p><section>
<p>
The coatis probably wouldn't be so endangered if they robbed banks instead, like <a href="https://zeenews.india.com/india/bizzare-monkey-steals-bag-with-rs-4-lakh-throws-currency-notes-outside-registry-office-in-up-2332462.html">monkeys</a> and <a href="https://globalnews.ca/news/9560059/calgary-poisonous-snake-bank-robbery-re-arrest/">snakes</a> do. Their 180-degree ankles would be invaluable for heisting.
</p>

</section>
</div>
<div id="note5" data-noteid="5">
<p><span>5</span></p><section>
<p>
Free cookies to anyone who got <a href="https://github.com/docker/cli/issues/267#issuecomment-695149477">the reference</a>!
</p>

</section>
</div>
<div id="note6" data-noteid="6">
<p><span>6</span></p><section>
<p>
Our team lead <a href="https://inah.gob.mx/boletines/descubren-antigua-ciudad-maya-campeche-la-nombran-ocomtun-columna-de-piedra">Ivan Spracj</a> explained that modern paper degrades much more quickly than the <a href="https://en.wikipedia.org/wiki/Amate">amate</a> paper the Mayans used. Their ancient techniques were better than ours, both in paper and memory safety.
</p>

</section>
</div>

        </div>

    </div>
    <div>
      <div>
  
<section>
<h2 id="blending-techniques">
 Blending Techniques</h2>

</section>
<section>
<p>
Before this, we only had three choices for memory safety, each with it's own tradeoffs:
</p>
<ul>
<li>
Garbage collection <a href="#note7" data-noteid="7">7</a> is easy, flexible, has high throughput, but uses <a href="https://thenewstack.io/which-programming-languages-use-the-least-electricity/">more energy</a>, <a href="https://stackoverflow.com/a/764706/1424454">more memory</a>, and has nondeterministic pauses.
</li>
<li>
Reference counting is simple and uses less memory, but is slow and can leak cycles. <a href="#note8" data-noteid="8">8</a>
</li>
<li>
Borrow checking is faster and allows for aliasing inline data <a href="#note9" data-noteid="9">9</a>, but can cause complexity and can't do patterns like <a href="https://en.wikipedia.org/wiki/Observer_pattern">observers</a>, <a href="https://lwn.net/Articles/907876/">intrusive data structures</a>, many kinds of RAII, etc. <a href="#note10" data-noteid="10">10</a>
</li>
</ul>

</section>
<section>
<p>
But we've long suspected that the Mayans had ways to blend these together at a more fundamental level.
</p>

</section>
<section>
<p>
We've certainly tried blending them before, and we've even had some success. For example, to work around the borrow checker in Rust we can put an object in an <span>Rc&lt;RefCell&lt;T&gt;&gt;</span> to make it reference counted, though that just delays the borrow checker to later when we <span>borrow</span>/<span>borrow_mut</span> the contents. Did the Mayans have a way to <i>truly blend</i> the two approaches, like hinted on the walls of the Mayan <a href="https://www.livescience.com/maya-kingdom-discovered-in-mexico.html">Sak Tz'i' tablets</a>? <a href="#note11" data-noteid="11">11</a>
</p>

</section>
<section>
<p>
Some ancient writings also describe a way to make fast languages that are not only safe but also <i>correct</i> in a way that no languages are today <a href="#note12" data-noteid="12">12</a>, functional languages that use neither GC nor RC under the hood, <a href="#note13" data-noteid="13">13</a> and ways we can have unbounded reference counted objects <i>without a count integer</i>. <a href="#note14" data-noteid="14">14</a> How did they do all this?
</p>

</section>
<section>
<p>
This is why we were so excited to find this tome. Perhaps it had the answers!
</p>

</section>

      </div>
  
<div>
    
<div id="note7" data-noteid="7">
<p><span>7</span></p><section>
<p>
By "garbage collection", we're referring to tracing garbage collection.
</p>

</section>
</div>
<div id="note8" data-noteid="8">
<p><span>8</span></p><section>
<p>
With good use of weak references, one can avoid the leaks.
</p>

</section>
</div>
<div id="note9" data-noteid="9">
<p><span>9</span></p><section>
<p>
"Inline data" means we can have a struct's memory live on the stack, or inside another struct's memory, or directly in an array next to the other arrays' elements' memory. This is the default in C, and impossible in e.g. Javascript.
</p>

</section>
</div>
<div id="note10" data-noteid="10">
<p><span>10</span></p><section>
<p>
Luckily in Rust we can work around this limitation with reference counting!
</p>

</section>
</div>
<div id="note11" data-noteid="11">
<p><span>11</span></p><section>
<p>
Below I talk about how we can use regions to blend borrowing and reference counting to get the benefits of both worlds.
</p>

</section>
</div>
<div id="note12" data-noteid="12">
<p><span>12</span></p><section>
<p>
Except for <a href="https://borretti.me/article/introducing-austral">Austral</a>! It's safe because of borrow checking, and correct because it adds linear types. More on this below.
</p>

</section>
</div>
<div id="note13" data-noteid="13">
<p><span>13</span></p><section>
<p>
This is referring to Kindelia's <a href="https://github.com/HigherOrderCO/HVM">HVM</a> project!
</p>

</section>
</div>
<div id="note14" data-noteid="14">
<p><span>14</span></p><section>
<p>
See "Linear reference counting" below.
</p>

</section>
</div>

        </div>

    </div>
    <div>
      <div>
  
<section>
<h2 id="impossibly-prophetic">
 Impossibly Prophetic</h2>
<p>
As I deciphered the first few pages, I was shocked to find that it was referencing <i>things that hadn't happened yet</i>.
</p>

</section>
<section>
<p>
It was referencing to elucent's <a href="https://degaz.io/blog/632020/post.html">Basil</a> language, Fernando's <a href="https://borretti.me/article/introducing-austral">Austral</a>, and Marco's <a href="http://forty2.is/">Forty2</a> language... and yet carbon dating tells us that the book is hundreds of years old!
</p>

</section>
<section>
<p>
Somehow, the Mayans were looking <i>forward in time</i> to techniques that were invented by people alive <i>today</i>. So maybe the Mayans were just time-traveling collectors, and this tome contains techniques from the recent past...
</p>
<p>
...and also the recent future. There's an entire half of this tome that seems to build on strange higher concepts that don't exist in our world yet. <a href="#note15" data-noteid="15">15</a> Other pages seem to mention laws we haven't yet discovered. <a href="#note16" data-noteid="16">16</a>
</p>

</section>

      </div>
  
<div>
    
<div id="note15" data-noteid="15">
<p><span>15</span></p><section>
<p>
Almost as if their CPU designs were slightly different than our own, in a key way that unlocked more possibilities. I'm still scratching my head on this one.
</p>

</section>
</div>
<div id="note16" data-noteid="16">
<p><span>16</span></p><section>
<p>
And there's one technique that I've tried to re-engineer thirty one (!) times without success: Hybrid-Generational Memory, one of my most elusive goals. I've gotten close by combining regions and generational references, but not in the automatic way that the Mayans seem to describe. Perhaps one of you can solve the rest of this puzzle!
</p>

</section>
</div>

        </div>

    </div>
    <div>
      <section>
<h2 id="the-list">
 The List</h2>
<p>
To keep this post short, <a href="#note17" data-noteid="17">17</a> I'll assume the reader knows the basics of reference counting, (tracing) garbage collection, and knows how borrow checking works at a high level.
</p>
<p>
Even so, this is a <i>very</i> dense, compact overview of each technique, mainly meant as a starting point for further reading.
</p>
<p>
<b>Don't worry, I'll be posting many follow-up posts</b> (<a href="https://verdagon.dev/rss.xml">RSS</a>, <a href="https://reddit.com/r/vale">subreddit</a>) <b>that describe each one much more clearly and how it fits into the larger puzzle.</b> <a href="#note18" data-noteid="18">18</a>
</p>
<p>
Afterward, I'll also talk about the interesting gaps in the puzzle, and the hints that might lead to discovery there.
</p>
<p>
Without further ado, here's the list!
</p>

</section>
  
<div>
    
<div id="note17" data-noteid="17">
<p><span>17</span></p><section>
<p>
Because I've wasted all this space with the dramatic buildup, my bad!
</p>

</section>
</div>
<div id="note18" data-noteid="18">
<p><span>18</span></p><section>
<p>
I unfortunately can't give a timeline on this though, my health is a bit unstable lately.
</p>

</section>
</div>

        </div>

    </div>
    <div>
      <section>
<p>
<b>1: Move-only programming</b> was the most surprising one to me. In this, every object can only be known to one variable (or field or array element), and that one "owner" can give it up to transfer it to another variable, field, array element, or function parameter or return. In Java terms, only one reference can point to an object at any given time.
</p>
<p>
Some of you may recognize these as <a href="https://en.wikipedia.org/wiki/Substructural_type_system#Affine_types">affine types</a> (and also kind of <a href="https://en.wikipedia.org/wiki/Substructural_type_system#Linear_types">linear types</a>), but will be surprised to learn that we can <a href="https://verdagon.dev/blog/linear-types-borrowing">write entire programs</a> like this, without making any more references to any objects, as long as we're willing to go through some acrobatics. <a href="#note19" data-noteid="19">19</a>
</p>
<p>
Various languages build on this with different mechanisms: Rust adds <a href="https://doc.rust-lang.org/rust-by-example/scope/borrow.html">borrow checking</a>, Austral adds borrow checking and <a href="https://austral-lang.org/linear-types">linear typing</a>, and Vale has the <a href="https://vale.dev/linear-aliasing-model">linear-aliasing model</a>. I suspect the tome is hinting at other possible blends too. <a href="#note20" data-noteid="20">20</a>
</p>

</section>
  
<div>
    
<div id="note19" data-noteid="19">
<p><span>19</span></p><section>
<p>
For example, you can't just point to something that is currently in a hash map... you first have to temporarily remove it so you can read it.
</p>

</section>
</div>
<div id="note20" data-noteid="20">
<p><span>20</span></p><section>
<p>
Specifically, if we can add Pony-style <span>val</span> to it, we might get an interesting result.
</p>

</section>
</div>

        </div>

    </div>
    <div>
      <section>
<p>
<b>2: Reference counting</b> is fairly mainstream. Some will be surprised to learn that it can coexist with tracing GC (<a href="https://devguide.python.org/internals/garbage-collector/index.html">like in Python</a> and <a href="https://nim-lang.org/blog/2020/10/15/introduction-to-arc-orc-in-nim.html">Nim</a>), and we also learned that there's a <a href="https://courses.cs.washington.edu/courses/cse590p/05au/p50-bacon.pdf">whole spectrum</a> between the two.
</p>
<p>
And as it turns out, reference counting can be <a href="https://github.com/Verdagon/RegionsRCCellularAutomataBenchmark/blob/main/README.md">blended with immutable region borrowing</a> to greatly reduce its cache misses and make it data-race safe, something no language has done yet. <a href="#note21" data-noteid="21">21</a> <a href="#note22" data-noteid="22">22</a>
</p>

</section>
  
<div>
    
<div id="note21" data-noteid="21">
<p><span>21</span></p><section>
<p>
I couldn't resist prototyping this, so the Vale compiler actually has a flag that switches Vale from generational references to RC so we can see this in action. See <a href="https://github.com/Verdagon/RegionsRCCellularAutomataBenchmark/blob/main/README.md">this experimental repo</a> for more.
</p>

</section>
</div>
<div id="note22" data-noteid="22">
<p><span>22</span></p><section>
<p>
<a href="https://nim-lang.org/">Nim</a> could theoretically do this, but alas, I was unable to convince Araq that it was possible. I also thought for a while that Rust could do this, but it's unfortunately foiled by the <span>RefCell</span> escape hatch.
</p>

</section>
</div>

        </div>

    </div>
    <div>
      <section>
<p>
<b>3: Borrow checking</b> lets our code be as fast as C and even almost as safe as Haskell. <a href="#note23" data-noteid="23">23</a> It works by ensuring that we only use pointers temporarily (in certain scopes) and in restricted ways to ensure others won't change the data that you're reading.
</p>
<p>
<a href="https://borretti.me/article/introducing-austral">Austral</a> takes it a step further: it's not only safe, but also <i>correct</i> by adding <a href="https://en.wikipedia.org/wiki/Safety_and_liveness_properties">liveness</a> via linear types which any code can use to ensure that some future action will happen. This is a pattern I call <a href="https://verdagon.dev/blog/higher-raii-7drl">Higher RAII</a> in Vale, but I think it naturally occurs in any language with linear types. <a href="#note24" data-noteid="24">24</a>
</p>
<p>
If you're curious for more, check out this <a href="https://www.youtube.com/watch?v=UavYVf0UEoc">Developer Voices episode</a> where Kris Jenkins interviewed me on linear types and higher RAII.
</p>

</section>
  
<div>
    
<div id="note23" data-noteid="23">
<p><span>23</span></p><section>
<p>
I say almost because Rust's single-ownership nature sometimes introduces failure conditions that wouldn't exist in Haskell.
</p>

</section>
</div>
<div id="note24" data-noteid="24">
<p><span>24</span></p><section>
<p>
Haskell can have linear types too! I foresee a future where functional programming and linear types are actually the best choice for safety-critical systems that can handle nondeterministic GC pauses. And the Mayans mention a new way that we can nearly eliminate those pauses...
</p>

</section>
</div>

        </div>

    </div>
    <div>
      <section>
<p>
<b>4: Arena-only programming</b> is where we never use malloc or free, and <a href="https://www.rfleury.com/p/untangling-lifetimes-the-arena-allocator">always use arenas instead</a>, even for function returns. This is a familiar paradigm to users of C, Ada, Zig, and especially Odin which has a way to <a href="https://odin-lang.org/docs/overview/#implicit-context-system">automatically decouple code from allocator strategy</a>.
</p>
<p>
As described, this is more of a memory <i>management</i> approach than a memory <i>safety</i> approach. However, <a href="https://en.wikipedia.org/wiki/Cyclone_(programming_language">Cyclone</a> and <a href="https://en.wikipedia.org/wiki/SPARK_(programming_language">Ada/SPARK</a> show us that we can track which pointers are pointing into which arenas, to prevent any use-after-frees. <a href="https://github.com/microsoft/verona">Verona</a> shows us that by combining arenas with regions (described below), we can take things even further. <a href="#note25" data-noteid="25">25</a> 
</p>

</section>
  
<div id="note25" data-noteid="25">
<p><span>25</span></p><section>
<p>
We could also combine arena-only programming with generational references, regions, constraint references, or MMM++.
</p>

</section>
</div>

    </div>
    <div>
      <section>
<p>
<b>5: Ada/SPARK</b> has a mechanism where a pointer cannot point to an object that is more deeply scoped than itself. If you imagine the stack growing to the right, <a href="#note26" data-noteid="26">26</a> pointers are only allowed to point left. If you really stretch your brain, this has some similarities to mutable value semantics or borrow checking. <a href="#note27" data-noteid="27">27</a>
</p>

</section>
  
<div id="note26" data-noteid="26">
<p><span>26</span></p><section>
<p>
"But Evan, stacks grow down!" <a href="https://memedrop.io/meme/ZRy5yVV68X7m">Listen here</a>, no it doesn't, nobody knows the orientation of the RAM chip in the computer.
</p>

</section>
</div>

    </div>
    <div>
      <div>
  
<section>
<p>
<b>6: Regions</b> are surprisingly flexible and powerful. I first learned about them from <a href="https://www.ponylang.io/">Pony</a>'s <a href="https://tutorial.ponylang.io/reference-capabilities/guarantees.html#mutable-reference-capabilities">iso</a> keyword: an <span>iso</span>'d object (and its contents) are only reachable from your pointer; nobody else points at that object or anything the object contains. In other words, it establishes an isolated subgraph of objects, and you hold the only reference to the entire thing.
</p>
<p>
<a href="https://www.cs.drexel.edu/~csg63/papers/oopsla12.pdf">Colin Gordon</a> showed how we can "temporarily open" an isolated subgraph for a given scope, and afterward it would still be properly isolated.
</p>
<p>
I later wrote <a href="https://verdagon.dev/blog/zero-cost-refs-regions">an article</a> about how we could temporarily open an isolated subgraph and see it as an <b>immutable region</b> so to speak <a href="#note28" data-noteid="28">28</a> to <i>completely eliminate</i> the memory safety cost for references pointing into that immutable region.
</p>
<p>
In that article I also explored how we can use a <span>pure</span> function to <b>temporarily reinterpret all pre-existing regions as immutable</b>, removing a vast amount of overhead. In 2023, we <a href="https://verdagon.dev/blog/first-regions-prototype">completed the first prototype</a> showing this in action for generational references. It also <a href="https://github.com/Verdagon/RegionsRCCellularAutomataBenchmark/tree/main">helps reference counting approaches</a> too.
</p>
<p>
Other languages such as <a href="https://forty2.is/">Forty2</a> and <a href="https://github.com/microsoft/verona">Verona</a> are going all-in on regions, and you'll see why further below.
</p>

</section>
<section>
<p>
I'm thinking about separating "regions" into two separate simpler concepts in my writing: <b>regions</b> (a set of objects that can freely point to each other) and <b>region views</b> (a mutable or immutable view of a region). Region views are really what unlock regions' potential, I think. If anyone has opinions, <a href="https://verdagon.dev/grimoire/verdagon_epsa@verdagon.dev">drop me an email</a>!
</p>

</section>

      </div>
  
<div id="note28" data-noteid="28">
<p><span>28</span></p><section>
<p>
"Explicit locking" in the linked article.
</p>

</section>
</div>

    </div>
    <div>
      <section>
<p>
<b>7: Stack arenas</b> is an approach that's spiritually similar to arena-only programming, but it's automatic and does it for every stack frame. Elucent's <a href="https://degaz.io/blog/632020/post.html">Basil</a> used to do this! It wasn't efficient, but the Mayans mention something about combining it with other techniques to make it a <i>lot</i> faster. I can kind of see what they mean <a href="#note29" data-noteid="29">29</a> but I haven't seen anyone try it yet.
</p>

</section>
  
<div id="note29" data-noteid="29">
<p><span>29</span></p><section>
<p>
I <i>think</i> it's compatible with reference counting, and I'm fairly certain it's compatible with linear types.
</p>

</section>
</div>

    </div>
    <section>
<p>
<b>8: <a href="https://verdagon.dev/blog/generational-references">Generational References</a></b> is a technique that prevents use-after-frees by telling us whether a pointer is pointing at a valid object, by comparing a pointer's accompanying "remembered" generation number to the "current" generation number living in the object it's pointing at. We increment an object's generation number whenever we want to destroy it, preventing any future accesses. This approach is made much faster by <a href="https://verdagon.dev/blog/zero-cost-borrowing-regions-overview">regions</a>: we never have to do that comparison if the object is in a temporarily immutable region, which we can establish with a <span>pure</span> function or block.
</p>
<p>
I hope other languages start using the generational references approach. There are a couple attempts in Rust (<a href="https://github.com/Kile-Asmussen/genref">here</a> and <a href="https://docs.rs/generational-box/latest/generational_box/">here</a>), but the language's rules prevent them from doing the faster variant described below.
</p>

</section>
    <div>
      <section>
<p>
<b>9: Random Generational References</b> is a faster variant that lets us have "inline data", in other words it lets us put structs on the stack and inside arrays or other structs. This is similar to <a href="https://source.android.com/docs/security/test/memory-safety/arm-mte">memory tagging</a>, but much more reliable because of a wider tag (64 bits instead of 4) and when paired with perfect determinism, <a href="#note30" data-noteid="30">30</a> more secure. <a href="#note31" data-noteid="31">31</a>
</p>
<p>
This improvement is exciting to me because it lets the generation live right next to the object, and lets both live anywhere: on the stack, in an array, or inline inside another object. This makes it much faster in theory, because it means a program will incur less cache misses.
</p>
<p>
One can even blend this with <a href="https://verdagon.dev/blog/linear-types-borrowing">a technique that can reduce generation checks to zero</a> where desired and regions for eliminating them everywhere else.
</p>
<p>
I think this blend has a lot of potential, because it has the strengths of C++ (architectural simplicity <a href="#note32" data-noteid="32">32</a>) and Rust (memory safety) while being simpler and easier than both.
</p>
<p>
But I'm a bit biased of course, as any human would be about their own idea!
</p>

</section>
  
<div>
    
<div id="note30" data-noteid="30">
<p><span>30</span></p><section>
<p>
Perfect determinism is where the language doesn't introduce any features (e.g. reading uninitialized memory or casting pointers to integers) that could let nondeterminism leak into the program's logic. It's required for <a href="https://verdagon.dev/blog/perfect-replayability-prototyped">perfect replayability</a>
</p>

</section>
</div>
<div id="note31" data-noteid="31">
<p><span>31</span></p><section>
<p>
Specifically, it means that we can defend against side-channel attacks at the program's architectural level, by never letting any nondeterminism leak into any untrusted code.
</p>

</section>
</div>
<div id="note32" data-noteid="32">
<p><span>32</span></p><section>
<p>
This means we can organize our program how we want, without interference from upwardly viral constraints (like async/await or borrow checking) or immutability concerns (like in functional programming). A litmus test for a language's architectural simplicity is whether you can implement a basic observer. Languages that don't have it will tend to have less stable APIs and a lot more refactoring.
</p>

</section>
</div>

        </div>

    </div>
    <div>
      <section>
<p>
<b>10: MMM++</b> <a href="#note33" data-noteid="33">33</a> is where objects are allocated from global arrays, and slots in those arrays are released and reused for other objects of the same type, thus avoiding use-after-free's normal memory unsafety problems. See <a href="https://verdagon.dev/blog/myth-zero-overhead-memory-safety">Arrrlang</a> for a simple theoretical example, and one usually adds <a href="https://verdagon.dev/blog/when-to-use-memory-safe-part-1#the-safer-way-to-use-mmm-languages">other techniques too</a> to make a real paradigm out of it. This is similar to how a lot of embedded, safety-critical, and real-time software works today, <a href="#note34" data-noteid="34">34</a> though no language comprehensively enforces it yet.
</p>

</section>
  
<div>
    
<div id="note33" data-noteid="33">
<p><span>33</span></p><section>
<p>
I'm sure this has a better name, someone let me know!
</p>

</section>
</div>
<div id="note34" data-noteid="34">
<p><span>34</span></p><section>
<p>
Including many servers, databases, and games. For example, <a href="https://github.com/tigerbeetledb/tigerbeetle/blob/main/docs/TIGER_STYLE.md#safety">TigerBeetleDB</a> has a similar set of rules.
</p>

</section>
</div>

        </div>

    </div>
    <section>
<p>
<b>11: Tracing garbage collection</b> is familiar to all of us, but there's a surprising twist: there's a secret way to make a garbage collector without the stop-the-world pauses! <a href="https://www.ponylang.io/">Pony</a> does this: by separating each actor into its own little world, each actor can do its own garbage collection without stopping the other ones. Its <a href="https://tutorial.ponylang.io/appendices/garbage-collection.html">ORCA</a> mechanism then enables sharing data between the worlds via an interesting reference counting message passing mechanism.
</p>
<p>
<a href="https://github.com/microsoft/verona">Verona</a> then takes this a step further by adding regions, giving the user more fine-grained control over when and where garbage collection might happen, and lets them use a regular bump allocator for a region instead if they wish.
</p>
<p>
If Verona or a new language allowed us to set the maximum memory for a GC'd region, that would make the entire approach <i>completely deterministic</i>, solving the biggest problem for garbage collection (in my opinion).
</p>
<p>
Don't tell anyone I said this, but I believe that 30 years from now, this blend is going to be the most widely used paradigm for servers.
</p>

</section>
    <div>
      <section>
<p>
<b>12: Interaction nets</b> are a <i>very</i> fast way to manage purely immutable data <i>without</i> garbage collection or reference counting. The <a href="https://github.com/HigherOrderCO/HVM">HVM</a> runtime implements this for Haskell. HVM starts with affine types (like move-only programming), but then adds an extremely efficient lazy <span>.clone()</span> primitive, so it can strategically clone objects instead of referencing them. Check out its <a href="https://github.com/HigherOrderCO/HVM/blob/master/guide/HOW.md">guide</a> to learn more! <a href="#note35" data-noteid="35">35</a>
</p>

</section>
  
<div id="note35" data-noteid="35">
<p><span>35</span></p><section>
<p>
And if someone has a better explanation, please send it to me! I don't understand interaction nets that well. I <i>think</i> it's actually a blend of automatic borrowing and cloning, but the guide says it's not really borrowing, so I'm not sure.
</p>

</section>
</div>

    </div>
    <section>
<p>
<b>13: Constraint references</b> is a blend of reference counting and single ownership (in the C++ sense, unrelated to borrow checking). In this approach, every object has a single owner, doesn't necessarily need to be on the heap, and has a counter for all references to it. When we try to destroy the object, we just assert that there are no other references to this object.
</p>
<p>
This is used surprisingly often. Some <a href="https://discord.com/channels/402956206529970177/402956206529970180/451828861861101569">game developers</a> have been using this for a long time, and it can be used as the memory safety model for an entire language like in <a href="https://web.archive.org/web/20220111001720/https://researcher.watson.ibm.com/researcher/files/us-bacon/Dingle07Ownership.pdf">Gel</a>. It supports a lot more patterns than borrow checking (intrusive data structures, graphs, observers, back-references, dependency references, callbacks, delegates, many forms of RAII, etc).
</p>
<p>
However, this checking is at run-time. Halting in release mode is often undesirable, so this technique shines the most when it's very targeted or when we can fall back to a different strategy in release mode.
</p>

</section>
    <div>
      <section>
<p>
<b>14: Linear reference counting</b> is an elusive concept, where we can completely eliminate the counter integer, and do all of the reference counting at compile time. No language can do this today, but there might be a way to get close with linear types. <a href="#note36" data-noteid="36">36</a> Basically, we have two types of linear reference:
</p>
<ul>
<li>
A "tine" reference remembers (in its type, at compile-time) L, the number of forks to get from the original value to here.
</li>
<li>
A "fork" reference holds the original value (or a tine reference <a href="#note37" data-noteid="37">37</a>), and remembers L and also N, the number of L+1 tine references created at the same time as this fork reference. Reclaiming the contents requires destroying this and all (N) of the L+1 tine references.
</li>
</ul>
<p>
I don't expect anyone to understand that rushed explanation, but I hope to write an article soon on this! <a href="#note38" data-noteid="38">38</a>
</p>
<p>
I'm not actually sure what kind of architectural restrictions it might impose, how situational it is, or if it even works at all. It's just something I came up with--I mean uh, <i>the grimoire</i> mentions--as a hypothetical avenue to explore.
</p>

</section>
  
<div>
    
<div id="note36" data-noteid="36">
<p><span>36</span></p><section>
<p>
Matthieu's <a href="https://github.com/matthieu-m/static-rc">static-rc</a> crate gets pretty close to this, but without linear types in Rust, it has to leak under certain conditions.
</p>

</section>
</div>
<div id="note37" data-noteid="37">
<p><span>37</span></p><section>
<p>
This is another difference between this idea and static-rc crate, I believe this will allow us to "borrow the borrow references" in objects, without lifetimes, rather than just on the stack.
</p>

</section>
</div>
<div id="note38" data-noteid="38">
<p><span>38</span></p><section>
<p>
I also talked about it a bit <a href="https://discord.com/channels/398263331808346123/734119020613075052/1135196844360736798">here</a> and <a href="https://discord.com/channels/398263331808346123/734119020613075052/1137411293310099546">here</a> and <a href="https://discord.com/channels/398263331808346123/734819934760075264/1141854334171222098">here</a>. If someone knows how to make better publicly-accessible discord logs, let me know!
</p>

</section>
</div>

        </div>

    </div>
    <section>
<p>
<b>15: Mutable value semantics</b> is a very interesting approach. Imagine a Java or Swift where every object has exactly one reference pointing to it at any given time (similar to move-only programming) but that reference can be lent out to a function call. It's like a Rust with no shared references (<span>&amp;</span>), only unique references (<span>&amp;mut</span>) which can't be stored in structs. It's simple, fast, and powerful, though we may have to <span>.clone()</span> more often than even Rust programs.
</p>
<p>
<a href="https://www.hylo-lang.org/">Hylo</a> uses mutable value semantics, with extra ergonomics like <span>subscript</span> on top to make it easier to work with. It's a very promising sweet spot on the performance vs. simplicity spectrum.
</p>

</section>
    <div>
      <section>
<p>
<b>16: <a href="https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/">CHERI</a></b> is a project that's attempting to make hardware and a compiler that can run languages like C in a memory-safe way. In CHERI, every 64-bit pointer also comes with a 64-bit "capability" which expresses what can be done with that pointer, to achieve spatial memory safety. <a href="https://ieeexplore.ieee.org/document/9152640">Cornucopia</a> adds temporal memory safety to that with special allocators that don't reuse memory in a page until it's empty and all of the existing capabilities have been revoked <a href="#note39" data-noteid="39">39</a> via an application-wide memory sweep done concurrently in the background.
</p>
<p>
If a new language used a system like this plus some techniques to prevent use-after-free on the stack, it could have a brand new memory safety model nobody's seen before.
</p>

</section>
  
<div id="note39" data-noteid="39">
<p><span>39</span></p><section>
<p>
This is an important memory safety concept: Memory unsafety comes not from use-after-free, but <i>use-after-reuse</i>. In fact, even that's too loose; memory unsafety comes from "use after shape change", which I'll explain later in the grimoire.
</p>

</section>
</div>

    </div>
    <div>
      <div>
  
<section>
<p>
<b>17: Neverfree</b> doesn't really count, but I'll mention it as a bonus item just for fun. Basically, just don't call <span>free</span>! If you never <span>free</span> memory, you can't use-after-free, which instantly solves the hardest part of memory safety. <a href="#note40" data-noteid="40">40</a> The idea is from this famous <a href="https://devblogs.microsoft.com/oldnewthing/20180228-00/?p=98125">email conversation</a>:
</p>
<p>
Norman Cohen said:
</p>
<p>
The only programs I know of with deliberate memory leaks are those whose executions are short enough, and whose target machines have enough virtual memory space, that running out of memory is not a concern. (This class of programs includes many student programming exercises and some simple applets and utilities; it includes few if any embedded or safety-critical programs.)
</p>
<p>
Kent Mitchell replied:
</p>
<p>
I was once working with a customer who was producing on-board software for a missile. In my analysis of the code, I pointed out that they had a number of problems with storage leaks. Imagine my surprise when the customers chief software engineer said "Of course it leaks". He went on to point out that they had calculated the amount of memory the application would leak in the total possible flight time for the missile and then doubled that number. They added this much additional memory to the hardware to "support" the leaks. Since the missile will explode when it hits its target or at the end of its flight, the ultimate in garbage collection is performed without programmer intervention.
</p>
<p>
It kind of makes sense in a way. If you have a program that uses all the memory all the way until the end (like <span>sort</span>), why not skip the expensive <span>free</span>s and let the OS clean it up when the process exits? You can't use-after-free if you never <span>free</span>!
</p>

</section>
<section>
<p>
Wait a minute, this list goes to 17, yet the intro only mentions 14! I actually did that because a couple might overlap <a href="#note41" data-noteid="41">41</a> and a couple of them are half-approaches <a href="#note42" data-noteid="42">42</a>, and that last one is just here for fun. Besides, as I learn more approaches and add them to the list, the title will get more and more out of date anyway.
</p>

</section>

      </div>
  
<div>
    
<div id="note40" data-noteid="40">
<p><span>40</span></p><section>
<p>
One might need to also add some bounds checking and a few other measures, but it's a start!
</p>

</section>
</div>
<div id="note41" data-noteid="41">
<p><span>41</span></p><section>
<p>
 Ada/SPARK might be a blend of MMM++ and arena-only programming, perhaps. I haven't used Ada/SPARK, so let me know!
</p>

</section>
</div>
<div id="note42" data-noteid="42">
<p><span>42</span></p><section>
<p>
 It could be said that regions on its own isn't really a memory safety approach, and it could be said that arena-only programming is just a memory <i>management</i> technique. But hey, when you put those two halves together you get <a href="https://github.com/microsoft/verona">Verona</a>'s memory safety approach, so together they probably count as one.
</p>


</section>
</div>

        </div>

    </div>
    <div>
      <div>
  
<section>
<h2 id="what-do-we-do-with-this-avalanche-of-knowledge">
 What do we do with this avalanche of knowledge?</h2>
<p>
Perhaps someone, after reading this article, will go forth and <b>design a new memory safety blend!</b> It's not impossible, I even used this grimoire to <a href="https://verdagon.dev/blog/vale-memory-safe-cpp">make a theoretical blend for C++</a>.
</p>

</section>
<section>
<p>
The world needs more memory safety blends and techniques! Especially ones that let us have better architectures, more simplicity, and less constraints. And who knows, searching for new techniques and blends might lead to interesting spinoff features, like Vale's <a href="https://verdagon.dev/blog/perfect-replayability-prototyped">perfect replayability</a> and <a href="https://verdagon.dev/blog/seamless-fearless-structured-concurrency">concurrency without data-coloring</a>.
</p>

</section>
<section>
<p>
We often fall into a mental trap where we optimistically believe that we've solved everything there is to solve, and pessimistically believe there's nothing left to discover. That mental trap is a mind-killer, because we can't discover new things if we aren't open to their existence.
</p>
<p>
In fact, one of my favorite cognitive science tricks is to convince myself that there is a better solution and it's <i>just barely</i> within reach if I just give it a little more thought. For some reason, that removes the mental barriers and lets one truly, fully explore. <a href="#note43" data-noteid="43">43</a>
</p>

</section>
<section>
<p>
If someone were to ask me why we should keep looking, I'd show them the unique strengths of each paradigm:
</p>
<ul>
<li>
RC's weak pointers let us easily know <a href="#note44" data-noteid="44">44</a> when another object's logical lifetime has ended, which is a surprisingly common need when you're looking out for it.
</li>
<li>
C and C++ let us use intrusive data structures, like no other language can. <a href="#note45" data-noteid="45">45</a>
</li>
<li>
Austral and Vale's linear types allow for <a href="https://verdagon.dev/blog/higher-raii-7drl">Higher RAII</a>, which lets compilers prevent a lot of logic problems.
</li>
<li>
GC is the easiest, and depending on one's definitions, the safest too. <a href="#note46" data-noteid="46">46</a>
</li>
</ul>
<p>
...and then I'd show them the whole list of approaches, and how many ways there are to blend them together.
</p>

</section>
<section>
<p>
With that in mind, it's pretty clear that memory safety is truly a wide-open world, waiting to be explored!
</p>

</section>

      </div>
  
<div>
    
<div id="note43" data-noteid="43">
<p><span>43</span></p><section>
<p>
This is a great technique in algorithm interviews, by the way.
</p>

</section>
</div>
<div id="note44" data-noteid="44">
<p><span>44</span></p><section>
<p>
In other languages, we need some sort of central tracking data structure to pull this off.
</p>

</section>
</div>
<div id="note45" data-noteid="45">
<p><span>45</span></p><section>
<p>
GC'd languages generally don't allow long-lived references to inline data, and Rust's borrow checker <a href="https://lwn.net/Articles/907876/">prevents intrusive data structures</a>
</p>

</section>
</div>
<div id="note46" data-noteid="46">
<p><span>46</span></p><section>
<p>
 It's a tricky topic. When one thinks not just about memory safety but about safety in general, a null-safe functional GC'd language has an edge over other approaches, even over borrow checking which forces long-term-referrable objects into central collections which have their own potential edge cases.

</p>

</section>
</div>

        </div>

    </div>
    <div>
      <div>
  
<section>
<h2 id="more-in-the-grimoire">
 More in the Grimoire</h2>
<p>
The above list is not complete, of course. There are some half-deciphered hints and building blocks in the grimoire that might be able to assist memory safety models in new ways.
</p>

</section>
<section>
<p>
Beware: We don't know which of these techniques actually help memory safety, and which summon ancient demons. Proceed at your own risk!
</p>

</section>
<section>
<p>
Here's just a handful:
</p>
<ul>
<li>
<b><a href="https://engineering.backtrace.io/2021-08-04-slitter-a-slab-allocator-that-trusts-but-verifies/">Type stability</a></b> shows us that use-after-free isn't the enemy, but rather a simplistic approximation of the enemy. The real memory safety problems arise when we access some memory after we've released and <i>reused it for something of a different type.</i> <a href="#note47" data-noteid="47">47</a>
</li>
<li>
<b>Final references</b> (like in Java) can help a lot in designing memory safety models. I won't explain too much here, but <a href="https://verdagon.dev/grimoire/verdagon_epsa@verdagon.dev">email</a> or discord me (Verdagon) and I can explain there. I dare not write publicly about what these unlock for memory safety, for what it would do to the world.
</li>
<li>
<b>Unique References</b>, in other words, guaranteeing that you have the only usable reference to an object, has been the key breakthrough in more approaches than I can count, including borrow checking, mutable value semantics, move-only programming, etc. There are even techniques that can make any object temporarily unique (like <a href="https://news.ycombinator.com/item?id=15294334">how Swift's inout works</a>, or how in generational references we can just temporarily change the generation). <a href="#note48" data-noteid="48">48</a>
</li>
<li>
<b>Change detectors</b> is a mechanism that will track at run-time whether something's been changed. Java collections <a href="https://stackoverflow.com/a/34629665/1424454">use a modCount</a> to prevent modifying while iterating, and one could conceivably use this to assist in memory safety as well.
</li>
<li>
<b>Check-on-set</b> is a pattern where we check at run-time if we're allowed to modify an object in a certain way. The best example of this how we can <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/freeze">freeze</a> a Javascript object, and whenever we modify an object, the runtime will assert it's not frozen. Anything that can guarantee an object immutable could be used for a memory safety approach.
</li>
<li>
<b>Thread isolation</b> is where we guarantee that an object is only visible to one thread at a given time. This property has helped enable borrow checking, generational references, Vale's immutable region borrowing, and faster forms of reference counting. It's likely important to other potential memory safety approaches.
</li>
<li>
<b>Page Headers</b> are where an allocator can strategically put metadata about an object at the top of its 4096-byte page.
</li>
<li>
<b>Fat pointers</b> is where some other data always accompanies a pointer. The biggest example of this is Rust's <a href="https://stackoverflow.com/questions/57754901/what-is-a-fat-pointer">trait references</a> and Vale uses it for its <a href="https://verdagon.dev/blog/generational-references">generational references</a> memory safety approach.
</li>
<li>
<b><a href="https://www.linaro.org/blog/top-byte-ignore-for-fun-and-memory-savings/">Top-byte ignore</a></b> refers to how some CPUs ignore the top byte of any particular pointer, so you can conveniently put anything you want there. You can even simulate top-byte-ignore on other systems by manually masking that byte off before dereferencing. This can be used to e.g. store how far the reference count integer is, so that you can point to the interior of a reference counted object. There are more arcane ways to use bits in the middle and end too. <a href="#note49" data-noteid="49">49</a>
</li>
<li>
And many more, hopefully in upcoming articles!
</li>
</ul>

</section>
<section>
<p>
You would be surprised how many little tricks can be used to complete or assist new memory safety models.
</p>

</section>
<section>
<p>
If you know of any more memory safety techniques, or want to see in-progress decipherings, then come on over to the #grimoire channel in the <a href="https://discord.com/invite/SNB8yGH">Vale discord</a>.
</p>

</section>

      </div>
  
<div>
    
<div id="note47" data-noteid="47">
<p><span>47</span></p><section>
<p>
"Shape stability" takes that a step further: we can reuse e.g. an integer's memory for a float and still not trigger memory unsafety, so really the problem is when we confuse a pointer for an integer or vice versa.
</p>

</section>
</div>
<div id="note48" data-noteid="48">
<p><span>48</span></p><section>
<p>
 Easter egg note!
</p>
<p>
<a href="https://en.wikipedia.org/wiki/William_Windsor_%28goat%29">William "Billy" Windsor I</a> is a <a href="https://en.wikipedia.org/wiki/Cashmere_goat">cashmere goat</a> who served as lance corporal in the British Army's <a href="https://en.wikipedia.org/wiki/Royal_Welsh">Royal Welsh</a> 1st Battalion from 2001 until 2009.
</p>
<p>
He was demoted to rank <a href="https://en.wikipedia.org/wiki/Fusilier">fusilier</a> for three months for inappropriate behaviour during the 2006 <a href="https://en.wikipedia.org/wiki/Queen%27s_Official_Birthday">Queen's Official Birthday</a> celebrations while on active duty with the battalion on Cyprus.
</p>
<p>
If you read this note, mention "that one lance corporal goat" anywhere on HN or reddit! <a href="https://youtu.be/-UBgNREvlIo">Nobody will believe you</a>.
</p>
<p>
(Cheers to <a href="https://news.ycombinator.com/item?id=36691658">cbsmith</a>, <a href="https://news.ycombinator.com/item?id=36692089">kubanczyk</a>, <a href="https://www.reddit.com/r/programming/comments/14wu830/comment/jrklcry/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">TheGoldenMinion</a>, <a href="https://news.ycombinator.com/item?id=36691564">lovich</a>, <a href="https://www.reddit.com/r/programming/comments/14wu830/comment/jrkmjiw/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">padraig_oh</a>, and <a href="https://news.ycombinator.com/item?id=36691737">leksak</a> for the <a href="https://verdagon.dev/blog/easter-egg-notes">last one</a>!)

</p>

</section>
</div>
<div id="note49" data-noteid="49">
<p><span>49</span></p><section>
<p>
We can also use the lower bits if we know the alignment of the data we're pointing to. We might even be able to use the bits in the middle by manually specifying the address <span>mmap</span> should give us.
</p>

</section>
</div>

        </div>

    </div>
    <div>
  
<section>
<h2 id="thats-all">
 That's all!</h2>
<p>
I hope you enjoyed this article! It represents my findings after a decade of searching and designing, so I hope it helps a lot of people out there.
</p>

</section>
<section>
<p>
In the next post, I'll talk about how we can blend reference counting with some of the above techniques to drastically reduce their overhead and add fearless concurrency, so keep an eye out on our <a href="https://verdagon.dev/rss.xml">RSS feed</a>, <a href="https://twitter.com/vale_pl">twitter</a>, <a href="https://discord.gg/SNB8yGH">discord server</a>, or <a href="https://reddit.com/r/vale">subreddit</a>!
</p>

</section>
<section>
<p>
Donations and sponsorships for Vale are currently paused, but if you like these articles, please <a href="https://www.doc.govt.nz/kakapo-donate">Donate to Kākāpō Recovery</a> and let me know. I love those birds, let's save them!
</p>

</section>
<section>
<p>
Cheers,
</p>
<p>
- Evan Ovadia
</p>


</section>

      </div>
    <section>
<h2 id="thank-you">
 Thank you!</h2>
<p>
I want to give a huge thanks to <a href="https://github.com/aweagel">Arthur Weagel</a>, <a href="https://github.com/KirilMihaylov">Kiril Mihaylov</a>, <a href="https://github.com/radekm">Radek Miček</a>, <a href="https://github.com/Geomitron">Geomitron</a>, <a href="https://github.com/chiuzon">Chiuzon</a>, <a href="https://github.com/soupertonic">Felix Scholz</a>, <a href="https://github.com/linkmonitor">Joseph Jaoudi</a>, <a href="https://github.com/lupuchard">Luke Puchner-Hardman</a>, <a href="https://github.com/tootoobeepbeep">Jonathan Zielinski</a>, <a href="https://github.com/albinkc">Albin Kocheril Chacko</a>, <a href="https://github.com/ezschemi">Enrico Zschemisch</a>, <a href="https://github.com/Svintooo">Svintooo</a>, <a href="https://github.com/tstack">Tim Stack</a>, <a href="https://github.com/kripken">Alon Zakai</a>, <a href="https://github.com/rovaughn">Alec Newman</a>, <a href="https://github.com/Shnatsel">Sergey Davidoff</a>, <a href="https://github.com/linuxy">Ian (linuxy)</a>, <a href="https://github.com/Ivo-Balbaert/">Ivo Balbaert</a>, <a href="https://github.com/pierrec">Pierre Curto</a>, <a href="https://github.com/loveJesus">Love Jesus</a>, <a href="https://github.com/jryans">J. Ryan Stinnett</a>, <a href="https://github.com/cdinu">Cristian Dinu</a>, and <a href="https://github.com/lasernoises">Florian Plattner</a> (plus a very generous anonymous donor!) for sponsoring Vale over all these years.
</p>
<p>
My recent medical troubles may have forced me to stop coding for a while and led me to pause donations and sponsorships, but your support all this time is still giving me spirit and strength. My recovery is going well (I'm able to write articles again!) so hopefully I'll be back to 100% soon!

</p>

</section>
    
  

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Stainless SDK Generator (200 pts)]]></title>
            <link>https://www.stainlessapi.com/blog/announcing-the-stainless-sdk-generator</link>
            <guid>40146505</guid>
            <pubDate>Wed, 24 Apr 2024 16:34:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.stainlessapi.com/blog/announcing-the-stainless-sdk-generator">https://www.stainlessapi.com/blog/announcing-the-stainless-sdk-generator</a>, See on <a href="https://news.ycombinator.com/item?id=40146505">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Stainless generates the official client libraries for OpenAI, Anthropic, Cloudflare, and more. Today, we’re making the Stainless SDK generator available to every developer with a REST API.</p><p>During our private beta, we’ve been able to help millions of developers integrate faster and more reliably with the latest features of some of the world’s most powerful and exciting APIs.</p><p>The Stainless SDK generator accepts an OpenAPI specification and uses it to produce quality SDKs in multiple programming languages. As your API evolves, our automated generator continuously pushes changes, ensuring that your SDKs remain up-to-date—even as you make <a href="https://app.stainlessapi.com/docs/guides/patch-custom-code" target="_blank">arbitrary custom edits</a> to the generated code.</p><p>Here’s a quick, real-world example of the code we can do for you, and how you configure it with Stainless:<br>‍</p><div>



<pre><code>
import Cloudflare from "cloudflare";

async function main() {
  const cloudflare = new Cloudflare();
  const zone = await cloudflare.zones.create({
    account: { id: "xxx" },
    name: "example.com",
    type: "full",
  });
}
</code>
</pre>




<pre><code>
resources:
  zones:
    methods:
      create: post /v1/zones
</code>
</pre>

</div><p><em><br>See the source code for these endpoints in </em><a href="https://github.com/cloudflare/cloudflare-typescript/blob/54faa1bd35ae5f394e37e8ac7f75c36f738baff9/src/resources/zones/zones.ts#L27-L34" target="_blank"><em>TypeScript</em></a><em>, </em><a href="https://github.com/cloudflare/cloudflare-python/blob/77cd2adc0ea0e48fb7419dfe6d48a7a5af78f35c/src/cloudflare/resources/zones/zones.py#L129-L177" target="_blank"><em>Python</em></a><em>, and </em><a href="https://github.com/cloudflare/cloudflare-go/blob/21580812b4a3fb3f215ea1f539c2c14e2fa123bb/zones/zone.go#L50-L61" target="_blank"><em>Go</em></a><em>.</em><br></p><p>‍</p><div><blockquote>“The decision to use Stainless has allowed us to move our focus from building the generation engine to instead building high-quality schemas to describe our services. <p>In the span of a few months, we have gone from inconsistent, manually maintained SDKs to automatically shipping over 1,000 endpoints across three language SDKs with hands-off updates.”</p><p><em>Jacob Bednarz, API Platform Tech Lead, Cloudflare (</em><a href="https://blog.cloudflare.com/lessons-from-building-an-automated-sdk-pipeline" target="blank"><em>see blog post</em></a><em>)</em></p></blockquote></div><p>‍</p><h2><strong>Backstory: scaling SDKs at Stripe</strong></h2><p>From <a href="https://web.archive.org/web/20111213031731/https://stripe.com/" target="_blank">the very first day that stripe.com existed on the internet</a>, SDKs were a big part of the pitch to developers. Today, well over 90% of Stripe developers make well over 90% of requests to the Stripe API through the SDKs. As the front door to the API, the SDKs are how developers think about Stripe—to most people, it’s <code>stripe.charges.create()</code>, not <code>POST /v1/charges</code>.</p><p>Personally, I hadn’t appreciated this until I joined Stripe in 2017—but by then, the growing scope of the Stripe API had exceeded our capacity to build SDKs by hand sustainably. Making manual changes across 7 different programming languages whenever we shipped a new endpoint was toilsome and error-prone.</p><p>Not only that, TypeScript had eaten the world. Now, developers expect typeahead and documentation-on-hover directly in their text editor. Building SDKs that support comprehensive static types in a variety of languages was totally unthinkable without code generation.</p><p>The team had spent over a year exploring existing open-source code generation tools before concluding that none could meet Stripe’s quality standards. Most codegen tools either work in only one language or just use string templating, which leaves you constantly fiddling with issues like trailing commas in Go and invalid indentation in Python. We needed to build our own codegen tool that enabled us to “learn once, write everywhere” and easily produce clean, correct code across all our languages.</p><p>Over a weekend, I hacked together a surprising mashup of JSX and the internals of prettier to enable product developers to quickly template quality code that came well-formatted out of the box. Over the next several months, dozens of engineers helped convert the SDKs to codegen, matching our carefully handcrafted code byte for byte.</p><p>By later that year, I was pairing with a colleague to <a href="https://twitter.com/stripe/status/1222944951853432832" target="_blank">produce the first official TypeScript definitions</a> for the Stripe API.</p><p>‍</p><h2><strong>Scaling SDKs for everybody</strong>‍</h2><p>After I left Stripe, engineers kept asking me how to build great SDKs for their API. I didn’t have a great answer—most companies don’t have several engineer-years lying around to build whole a suite of high-quality code generators spanning a range of popular languages.</p><p>In early 2022, I set out to bootstrap a company, and Lithic became our first customer, making Stainless ramen-profitable from day one. Their head of product had previously been the PM of SDKs at Plaid, where she’d seen firsthand both how valuable SDKs are and how hard it is to codegen decent ones with the openapi-generator.</p><p>Despite the allure of a small, bootstrapped company, I felt bad limiting its impact to the small number of clients I could handle by myself. What’s more, I also got asked how to keep OpenAPI specs up-to-date and valid, how to evolve API versions, how to design RESTful pagination, how to set up API Keys, and a million other problems my old team had already solved at Stripe.</p><p>Eventually it became clear that the world needed a comprehensive developer platform—from docs to request logs to rate-limiting—that could enable REST to live up to its potential.</p><p>Sequoia soon became our first investor, shortly followed by great angels like Cristina Cordova, Guillermo Rauch, Calvin French-Owen, and dozens more.</p><p>There was clearly a huge opportunity to advance the whole REST ecosystem and help a ton of people ship better APIs.</p><p>‍</p><h2><strong>Advancing the API ecosystem</strong></h2><p>APIs are the dendrites of the internet. Literally all internet software connects through APIs—they make up the vast majority of internet traffic.</p><p>Today, the API ecosystem is deeply fragmented:</p><ol role="list"><li>GraphQL. Great for frontends, but not built for server-to-server interactions and hasn’t worked out well for public APIs.</li><li>gRPC. Great for microservices, but doesn’t work for frontends and is unpopular for public APIs.</li><li>REST. Works for frontends, microservices, and public APIs. It’s simple, flexible, and aligned with web standards—but also messy and hard to get right.</li></ol><p>Engineering organizations should be able to use one API technology for everything—their frontends, their microservices, and their public API—and have a good experience everywhere.</p><p>At Stainless, rather than trying to fit GraphQL or gRPC into the square holes they weren’t designed for—or invent some new 15th standard—we are staunch believers that “REST done right” can deliver this vision.</p><p>We want to build great open-source standards and tooling that bring the benefits of GraphQL (types, field selection/expansion, standards) and gRPC (types, speed, versioning) to REST.</p><p>When Stainless REST is realized, you’ll be able to start building a full-stack application using our API layer and have at least as good of a frontend experience as you would have had with GraphQL. When you add a Go microservice, you’ll be able to interconnect with typed clients, efficient packets, and low latency. And then—uniquely—when your biggest customer asks you for an external API, you’ll be able to just say “yes” and change <code>internal(true)</code> to <code>internal(false)</code> instead of rewriting the whole thing.</p><p>Today, our SDK announcement tackles the most salient problem with REST: type safety.</p><p>Our next project is building out a development framework that enables users to ship quality, typesafe REST APIs from any TypeScript backend. With the upcoming Stainless API framework, you declare the shape and behavior of your API in declarative TypeScript code and get an OpenAPI specification, documentation, and typed frontend client without a build step.</p><p>We’re building the framework around REST API design conventions that support rich pagination, consistent errors, field inclusion and selection, and normalized caching on the frontend. These conventions, influenced by best practices at Stripe, can help your team achieve consistent, high-quality results without untold hours of bikeshedding.</p></div><div><h2><strong>Building Stainless</strong></h2><div><blockquote>“The cool part about this is that you can define your API once and get client libraries in every language for free, whether you are an expert in those languages or not. <p> It’s rare that a startup will have people who know Python, Node, Ruby, Rust, Go, Java, etc, etc. But now they can market to all those developers at once.”
</p><p><em>Calvin French-Owen, co-founder, Segment</em></p></blockquote></div><p>Producing a good SDK is more involved than many developers may realize, especially when relying on code generation. The details matter, and it’s not just about pretty code—it’s about making the right choices and balancing some challenging tradeoffs between the characteristics of REST APIs and the idioms of the language at hand.</p><p>Here are a few generic examples:</p><ul role="list"><li>How do you handle response enums in Java? The obvious approach can result in crashes when adding a new variant in the future.</li><li>If your API introduces a union type, how do you express that in Go, given that the language does not have a standard way to express union types?</li><li>If unexpected data comes back from the server—whether due to a beta feature, an edge case, or a bug—how do you expose that data to the user? Should the client library treat it like an error? Is there an idiomatic way to achieve this across every programming language? Finding a good solution requires carefully weighing conflicting type safety and runtime safety considerations.</li><li>Should you automatically retry on 429 or 503 errors? How quickly? What if the API is experiencing a production outage?</li><li>What should you call the method for <code>/v1/invoices/{id}/void</code> in a Java client library? (hint: it can’t be <code>void</code>).</li></ul><p>Note that last problem can’t simply be decided by a machine—it requires context about the rest of the API, and must be decided by a human (even if an LLM can offer a first guess).</p><p>The <code>void</code> endpoint example is obviously an edge case, but the general question of what to name each method and type is as pernicious as it is pedestrian. If an SDK generator infers all names directly from the OpenAPI specification—particularly a specification generated from other sources—users may be confronted with nonsensical types like <code>AccountWrapperConfigurationUnionMember4</code> that raise questions about your company’s overall engineering quality.</p><p>If you ship an SDK without first addressing these issues, you risk locking yourself into design blunders that you may not be able to resolve later without breaking backwards compatibility in ways that are highly disruptive to users.</p><p>We shared the <code>void</code> example above because it is easy to understand, but there are a range of potential pitfalls that are even more subtle and abstruse that inevitably arise in non-trivial APIs. We can build tools to identify such issues, but deciding how to resolve them is often beyond the scope of what can be achieved with automation—even with AI. You need a human being with relevant context and sound judgement to assess the options and make an informed decision.</p><p>From experience, we knew that thoughtful SDK development is a lot more difficult than it seems—auditing every single type name in a typical, medium-sized API requires scanning through tens of thousands of lines of code.</p><p>To enable every developer to ship with the same level of care that we devote to our enterprise clients, we created an SDK Studio that highlights potential problems and makes it easy to quickly scan through all the things you may want to review before shipping a v1:</p><figure><p><img src="https://assets-global.website-files.com/662240109faccc0cefd740ae/66225e04b91b2310f4740bc2_Screenshot_2024-03-27_at_3.49.35_PM.png" loading="lazy" alt=""></p><figcaption>The Stainless SDK Studio</figcaption></figure><p>To start using the Stainless SDK generator, all you need is an OpenAPI specification.</p><p>Within a few minutes, you’ll get alpha SDKs you can publish to package managers—and after a bit of polishing, something you’re proud to release as v1.0.0.</p><p>To get started, check out <a href="https://app.stainlessapi.com/docs/" target="_blank">our documentation</a> or <a href="https://app.stainlessapi.com/login" target="_blank">connect your GitHub account</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US bans TikTok owner ByteDance, will prohibit app in US unless it is sold (110 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2024/04/biden-signs-bill-to-ban-tiktok-if-chinese-owner-bytedance-doesnt-sell/</link>
            <guid>40146203</guid>
            <pubDate>Wed, 24 Apr 2024 16:17:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2024/04/biden-signs-bill-to-ban-tiktok-if-chinese-owner-bytedance-doesnt-sell/">https://arstechnica.com/tech-policy/2024/04/biden-signs-bill-to-ban-tiktok-if-chinese-owner-bytedance-doesnt-sell/</a>, See on <a href="https://news.ycombinator.com/item?id=40146203">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      Get outta here    —
</h4>
            
            <h2 itemprop="description">Bill gives ByteDance 270 days to sell TikTok or app loses access to US market.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/tiktok-800x502.jpg" alt="A TikTok app icon on a phone screen.">
      <figcaption><p>Getty Images | Chesnot </p></figcaption>  </figure>

  




<!-- cache hit 344:single/related:64de479a699749d7c72ce7bf35fcda82 --><!-- empty -->
<p>The Senate last night approved a bill that orders TikTok owner ByteDance to sell the company within 270 days or lose access to the US market. The House had already passed the bill, and President Biden signed it into law today.</p>
<p>The "Protecting Americans From Foreign Adversary Controlled Applications Act" was approved as part of a <a href="https://www.congress.gov/bill/118th-congress/house-bill/815/text">larger appropriations bill</a> that provides aid to Ukraine, Israel, and Taiwan. It passed in a <a href="https://www.senate.gov/legislative/LIS/roll_call_votes/vote1182/vote_118_2_00154.htm">79-18 vote</a>. Biden last night issued a <a href="https://www.whitehouse.gov/briefing-room/statements-releases/2024/04/23/statement-from-president-joe-biden-on-senate-passage-of-the-national-security-package/">statement</a> saying he will sign the appropriations bill into law "as soon as it reaches my desk." He signed the bill into law today, the White House <a href="https://www.whitehouse.gov/briefing-room/presidential-actions/2024/04/24/bill-signed-h-r-815/">announced</a>.</p>
<p>The bill classifies TikTok as a "foreign adversary controlled application" and gives the Chinese company ByteDance 270 days to sell it to another entity. Biden can extend the deadline by up to 90 days if a sale is in progress.</p>
<p>TikTok would maintain access to the US market if the president determines that the divestiture "would result in the relevant foreign adversary controlled application no longer being controlled by a foreign adversary." The same divestiture-or-sale requirement would apply to other applications subsequently designated as being controlled by foreign adversaries.</p>
<p>If ByteDance doesn't sell TikTok, app stores in the US would have to drop the app, and Internet hosting services would be prohibited from providing services that enable distribution of TikTok in the US. Companies that violate the prohibition would have to pay civil penalties.</p>                                            
                                                        
<h2>ByteDance will fight law in court</h2>
<p>"Congress is not acting to punish ByteDance, TikTok, or any other individual company," Senate Commerce Committee Chair Maria Cantwell (D-Wash.) said, <a href="https://apnews.com/article/tiktok-ban-congress-bill-1c48466df82f3684bd6eb21e61ebcb8d">according to the Associated Press</a>. "Congress is acting to prevent foreign adversaries from conducting espionage, surveillance, maligned operations, harming vulnerable Americans, our servicemen and women, and our US government personnel."</p>
<p><a href="https://www.reuters.com/world/us/senators-hope-tiktok-will-remain-business-us-under-new-owner-2024-04-23/">Reuters quoted</a> Sen. Ed Markey (D-Mass.) as saying the bill is "really just a TikTok ban" and that "censorship is not who we are as a people. We should not downplay or deny this trade-off." Senator Ron Wyden (D-Ore.) expressed concern that the bill "provides broad authority that could be abused by a future administration to violate Americans' First Amendment rights."</p>
<p>Despite those statements, Markey and Wyden both voted in favor of the appropriations bill that includes the TikTok-inspired law.</p>
<p>ByteDance has said it will file a lawsuit in an attempt to block the law. "This legislation is a clear violation of the First Amendment rights of TikTok's 170 million American users," Michael Beckerman, TikTok's public policy head in the US, <a href="https://arstechnica.com/tech-policy/2024/04/tiktok-ready-to-move-to-the-courts-to-prevent-ban-in-us/">reportedly</a> told staff in a memo after the House vote on Saturday. "We'll continue to fight... This is the beginning, not the end of this long process."</p>
<p>In a <a href="https://twitter.com/TikTokPolicy/status/1783149300471525637">statement</a> today, TikTok said it "will ultimately prevail" in court and that "we have invested billions of dollars to keep US data safe and our platform free from outside influence and manipulation."</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Snowflake Arctic Instruct (128x3B MoE), largest open source model (279 pts)]]></title>
            <link>https://replicate.com/snowflake/snowflake-arctic-instruct</link>
            <guid>40146088</guid>
            <pubDate>Wed, 24 Apr 2024 16:09:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://replicate.com/snowflake/snowflake-arctic-instruct">https://replicate.com/snowflake/snowflake-arctic-instruct</a>, See on <a href="https://news.ycombinator.com/item?id=40146088">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  















<div data-react-placeholder="APIPlayground">
    <div>
        <p>
          <h2>Input</h2>
        </p>
      </div>
    
    <div>
          <p>
            <h2>Output</h2>
          </p>
        </div>
  </div>



















<section id="pricing">
  <a id="performance"></a>

  <h4>Pricing</h4>

  <p>
    This language model is priced by how many input tokens are sent as inputs and how many output tokens are generated.
  </p>

  

  <p>
    Check out
    <a href="https://replicate.com/docs/billing#language-models">our docs</a>
    for more information about how per-token pricing works on Replicate.
  </p>
</section>




<article>
  <p id="readme">
    <h4>Readme</h4>
    
  </p>
  
  <div>
    <h2 id="demo-app">Demo App</h2>
<p>Want to chat with Arctic? <a href="https://arctic.streamlit.app/" rel="nofollow">Try the Streamlit demo app.</a></p>
<h2 id="model-details">Model Details</h2>
<p>Arctic is a dense-MoE Hybrid transformer architecture pre-trained from scratch by the Snowflake AI 
Research Team. We are releasing model checkpoints for both the base and instruct-tuned versions of 
Arctic under an Apache-2.0 license. This means you can use them freely in your own research, 
prototypes, and products. Please see our blog 
<a href="https://www.snowflake.com/blog/arctic-open-and-efficient-foundation-language-models-snowflake" rel="nofollow">Snowflake Arctic: The Best LLM for Enterprise AI — Efficiently Intelligent, Truly Open</a> 
for more information on Arctic and links to other relevant resources such as our series of cookbooks 
covering topics around training your own custom MoE models, how to produce high-quality training data, 
and much more.</p>
<ul>
<li><a href="https://huggingface.co/Snowflake/snowflake-arctic-base/" rel="nofollow">Arctic-Base</a></li>
<li><a href="https://huggingface.co/Snowflake/snowflake-arctic-instruct/" rel="nofollow">Arctic-Instruct</a></li>
<li><a href="https://arctic.streamlit.app/" rel="nofollow">Arctic Demo App</a></li>
</ul>
<p>For the latest details about Snowflake Arctic including tutorials, etc. please refer to our github repo: <a href="https://github.com/Snowflake-Labs/snowflake-arctic" rel="nofollow">https://github.com/Snowflake-Labs/snowflake-arctic</a></p>
<p><strong>Model developers</strong> Snowflake AI Research Team</p>
<p><strong>License</strong> Apache-2.0</p>
<p><strong>Input</strong> Models input text only.</p>
<p><strong>Output</strong> Models generate text and code only.</p>
<p><strong>Model Release Date</strong> April, 24th 2024.</p>
<h2 id="model-architecture">Model Architecture</h2>
<p>Arctic combines a 10B dense transformer model with a residual 128x3.66B MoE MLP resulting in 480B 
total and 17B active parameters chosen using a top-2 gating. For more details about Arctic’s model
Architecture, training process, data, etc. <a href="https://www.snowflake.com/en/data-cloud/arctic/cookbook/" rel="nofollow">see our series of cookbooks</a>.</p>
  </div>
  
</article>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Biden signs TikTok 'ban' bill into law, starting clock for ByteDance to divest (665 pts)]]></title>
            <link>https://www.theverge.com/2024/4/24/24139036/biden-signs-tiktok-ban-bill-divest-foreign-aid-package</link>
            <guid>40145963</guid>
            <pubDate>Wed, 24 Apr 2024 15:59:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/4/24/24139036/biden-signs-tiktok-ban-bill-divest-foreign-aid-package">https://www.theverge.com/2024/4/24/24139036/biden-signs-tiktok-ban-bill-divest-foreign-aid-package</a>, See on <a href="https://news.ycombinator.com/item?id=40145963">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>President Joe Biden signed a foreign aid package that includes a <a href="https://www.theverge.com/2024/4/23/24137638/senate-passes-tiktok-ban-bill-divest-bytedance-foreign-aid">bill that would ban TikTok if China-based parent company ByteDance fails to divest</a> the app within a year.</p></div><p>The divest-or-ban bill is now law, starting the clock for ByteDance to make its move. The company has an initial nine months to sort out a deal, though the president could extend that another three months if he sees progress.</p><p>While just recently the legislation seemed like it would stall out in the Senate after being passed as a standalone bill in the House, political maneuvering helped usher it through to Biden’s desk. The House packaged the TikTok bill — which upped the timeline for divestment from the six months allowed in the earlier version — with foreign aid to US allies, which effectively forced the Senate to consider the measures together. The longer divestment period also seemed to get some lawmakers who were on the fence on board.</p><p>TikTok spokesperson Alex Haurek said in a statement that the company plans to challenge the law in the courts, which could ultimately extend the timeline should the courts delay enforcement pending a resolution. There also remains the question of how China will respond and whether it would let ByteDance sell TikTok and, most importantly, its coveted algorithm that keeps users coming back to the app.</p><p>“As we continue to challenge this unconstitutional ban, we will continue investing and innovating to ensure TikTok remains a space where Americans of all walks of life can safely come to share their experiences, find joy, and be inspired,” Haurek said.&nbsp;</p><p>“Make no mistake, this is a ban,” TikTok CEO Shou Chew said in a video posted on TikTok Wednesday, objecting to some lawmakers’ assertions that they just want to see the platform disconnected from Chinese ownership. “A ban on TikTok and a ban on you and your voice.”</p><p><em><strong>Update, April 24th: </strong>The article has been updated with an official statement from a TikTok spokesperson and its CEO.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[VideoGigaGAN: Towards Detail-Rich Video Super-Resolution (186 pts)]]></title>
            <link>https://videogigagan.github.io/</link>
            <guid>40144554</guid>
            <pubDate>Wed, 24 Apr 2024 14:04:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://videogigagan.github.io/">https://videogigagan.github.io/</a>, See on <a href="https://news.ycombinator.com/item?id=40144554">Hacker News</a></p>
<div id="readability-page-1" class="page">


  

<div>
          

          

          <p><span><sup>🐢</sup>University of Maryland, College Park</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <span><sup><img src="https://videogigagan.github.io/assets/images/adobe.png" width="15"></sup>Adobe Research</span>
          </p>

          
          



          
        </div>


<!-- first row -->
<div id="8xresults">


    <p>
        <h2>8× Upsampling results (128×128→1024×1024)</h2>
    </p>    
    
  
       
    

      <center>
        <p>Our model is able to upsample a video up to 8× with rich details.</p>
      </center>
  </div>

<div id="abstract">
        <h2>Abstract</h2>
        <p>Video super-resolution (VSR) approaches have shown impressive temporal consistency in upsampled videos. 
            However, these approaches tend to generate blurrier results than their image counterparts as they are limited in their generative capability.
            This raises a fundamental question: can we extend the success of a generative image upsampler to the VSR task while preserving the temporal consistency?
            We introduce VideoGigaGAN, a new generative VSR model that can produce videos with high-frequency details and temporal consistency.
            VideoGigaGAN builds upon a large-scale image upsampler -- GigaGAN. 
            Simply inflating GigaGAN to a video model by adding temporal modules produces severe temporal flickering.
            We identify several key issues and propose techniques that significantly improve the temporal consistency of upsampled videos.
            Our experiments show that, unlike previous VSR methods, VideoGigaGAN generates temporally consistent videos with more fine-grained appearance details.
            We validate the effectiveness of VideoGigaGAN by comparing it with state-of-the-art VSR models on public datasets and showcasing video results with 8× super-resolution.</p>
        <!-- <div class="column" style="display: flex; justify-content: center;">
          <div class="column has-text-justified" style="flex: 1;  max-width: 45%">
            <image src="assets/images/abstract.svg"/>
          </div>
          <div class="column has-text-justified" style="flex: 1; display: table;">
            <p style="display: table-cell; vertical-align: middle;">
              Our method only takes 15 minutes to optimize a representation from an in-the-wild video and can render novel views at 27 FPS.
              <br><br>
              On the NVIDIA Dataset, our method achieves a rendering quality comparable to state-of-the-art NeRF-based methods but is much faster to train and render. 
              <br><br>
              * The bubble size in the figure indicates the training time (GPU-hours). The training time does not include preprocessing time for all methods.
            </p>
          </div> -->
        </div>

<!-- Paper video. -->

  <div id="spotlight-video">
            <h2>
              <span>Overview: Why is it challenging?</span>
            </h2>
            
        </div>





<div id="method-overview">
        <h2>Method Overview</h2>
        <div>
          <p><img src="https://videogigagan.github.io/assets/images/method_overview.svg"></p><p>Our Video Super-Resolution (VSR) model is built upon the asymmetric U-Net architecture of the image GigaGAN upsampler. 
            To enforce temporal consistency, we first inflate the image upsampler into a video upsampler by adding <span>temporal attention</span> layers into the decoder blocks. 
            We also enhance consistency by incorporating the features from the <span>flow-guided propagation</span> module. 
            To suppress aliasing artifacts, we use <span>Anti-aliasing block</span> in the downsampling layers of the encoder. 
            Lastly, we directly <span>shuttle the high frequency features</span> via skip connection to the decoder layers to compensate for the loss of details in the BlurPool process. 
          </p>
        </div>
      </div>


<div id="ablation">
        <p>
            <h2>Ablation study</h2>
        </p>
        
        <center> 
          <p>
            Strong hallucination capability of image GigaGAN results in temporally flickering artifacts, 
            especially aliasing caused by the artifacted LR input.
          </p>
        </center>
        
        
        
        <!-- Slider for Data -->
        
        
        <p>Slide to switch between different examples</p> 

        <!-- Method Buttons -->
        <p> <br>
            We progressively add components to the base model to handle these artifacts →
          </p>
        
      <div>
        
        <p id="currentMethodDisplay2"> Image GigaGAN (base model) </p>
        <p> GT </p>
      </div>
        
        
       
        
    </div>

<div id="comparison">
        <p>
            <h2>Comparison with previous methods</h2>
        </p>
        

        <center>
          <p>
            Compared to previous models, our models provides a detail-rich result with comparable temporal consistency.
          </p>
          </center><br>

        <!-- Slider for Data -->
        
        
        
        <!-- <div class="columns is-centered has-text-centered">
          <p>Slide to switch between different examples</p>
        </div> -->

        

        

        

        <!-- Method Buttons -->
        
      
      

        

        
    </div>


<div id="4xresults">
      <p>
        <h2>Results on generic videos (128×128→512×512)</h2>
      </p>
      
      
    
    <center>
      <p>
        Our model is able to handle generic videos of different categories.
      </p>
    </center>
</div>


<div id="BibTeX">
    <h2>BibTeX</h2>
    <pre><code>@article{xu2024videogigagan,
      title={VideoGigaGAN: Towards Detail-rich Video Super-Resolution}, 
      author={Yiran Xu and Taesung Park and Richard Zhang and Yang Zhou and Eli Shechtman and Feng Liu and Jia-Bin Huang and Difan Liu},
      year={2024},
      eprint={2404.12388},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
  }</code></pre>
  </div>





  <!-- custom js file  -->
  <!-- <script defer src="./assets/js/fontawesome.all.min.js"></script> -->
  
  
  
  
  
  
  
  
  


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nvidia to Acquire Run:AI (168 pts)]]></title>
            <link>https://blogs.nvidia.com/blog/runai/</link>
            <guid>40144235</guid>
            <pubDate>Wed, 24 Apr 2024 13:36:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blogs.nvidia.com/blog/runai/">https://blogs.nvidia.com/blog/runai/</a>, See on <a href="https://news.ycombinator.com/item?id=40144235">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
	<main id="main" role="main">
			<div>
		

<article id="post-71285" data-url="https://blogs.nvidia.com/blog/runai/" data-identifier="71285 https://blogs.nvidia.com/?p=71285" data-title="NVIDIA to Acquire GPU Orchestration Software Provider Run:ai">

	<!-- .entry-header -->

	<!-- META -->
	<!-- .entry-meta -->

	<div>
		<p>To help customers make more efficient use of their AI computing resources, NVIDIA today announced it has entered into a definitive agreement to acquire Run:ai, a Kubernetes-based workload management and orchestration software provider.</p>
<p>Customer AI deployments are becoming increasingly complex, with workloads distributed across cloud, edge and on-premises data center infrastructure.</p>
<p>Managing and orchestrating generative AI, recommender systems, search engines and other workloads requires sophisticated scheduling to optimize performance at the system level and on the underlying infrastructure.</p>
<p>Run:ai enables enterprise customers to manage and optimize their compute infrastructure, whether on premises, in the cloud or in hybrid environments.</p>
<p>The company has built an open platform on <a href="https://www.nvidia.com/en-us/glossary/kubernetes/">Kubernetes</a>, the orchestration layer for modern AI and cloud infrastructure. It supports all popular Kubernetes variants and integrates with third-party AI tools and frameworks.</p>
<p>Run:ai customers include some of the world’s largest enterprises across multiple industries, which use the Run:ai platform to manage data-center-scale GPU clusters.</p>
<p>“Run:ai has been a close collaborator with NVIDIA since 2020 and we share a passion for helping our customers make the most of their infrastructure,” said Omri Geller, Run:ai cofounder and CEO. “We’re thrilled to join NVIDIA and look forward to continuing our journey together.”</p>
<p>The Run:ai platform provides AI developers and their teams:</p>
<ul>
<li aria-level="1">A centralized interface to manage shared compute infrastructure, enabling easier and faster access for complex AI workloads.</li>
<li aria-level="1">Functionality to add users, curate them under teams, provide access to cluster resources, control over quotas, priorities and pools, and monitor and report on resource use.</li>
<li aria-level="1">The ability to pool GPUs and share computing power — from <a href="https://www.nvidia.com/en-us/technologies/multi-instance-gpu/#:~:text=Multi%2DInstance%20GPU%20(MIG)%20expands%20the%20performance%20and%20value,%2C%20cache%2C%20and%20compute%20cores.">fractions of GPUs</a> to multiple GPUs or multiple nodes of GPUs running on different clusters — for separate tasks.</li>
<li aria-level="1">Efficient GPU cluster resource utilization, enabling customers to gain more from their compute investments.</li>
</ul>
<p>NVIDIA will continue to offer Run:ai’s products under the same business model for the immediate future. And NVIDIA will continue to invest in the Run:ai product roadmap as part of <a href="http://www.nvidia.com/dgx-cloud">NVIDIA DGX Cloud</a>, an AI platform co-engineered with leading clouds for enterprise developers, offering an integrated, full-stack service optimized for generative AI.</p>
<p>NVIDIA DGX and DGX Cloud customers will gain access to Run:ai’s capabilities for their AI workloads, particularly for large language model deployments. Run:ai’s solutions are already integrated with <a href="https://www.nvidia.com/en-us/data-center/dgx-platform/">NVIDIA DGX</a>, <a href="https://www.nvidia.com/en-us/data-center/dgx-superpod/">NVIDIA DGX SuperPOD</a>, <a href="https://www.nvidia.com/en-us/data-center/base-command/">NVIDIA Base Command</a>, <a href="https://www.nvidia.com/en-us/gpu-cloud/">NGC</a> containers, and <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/">NVIDIA AI Enterprise</a> software, among other products.</p>
<p>NVIDIA’s accelerated computing platform and Run:ai’s platform will continue to support a broad ecosystem of third-party solutions, giving customers choice and flexibility.</p>
<p>Together with Run:ai, NVIDIA will enable customers to have a single fabric that accesses GPU solutions anywhere. Customers can expect to benefit from better GPU utilization, improved management of GPU infrastructure and greater flexibility from the open architecture.</p>

		<!-- .entry-footer -->

	</div><!-- .entry-content -->
	
<!-- #secondary -->
	

</article><!-- #post-## -->
			<!-- .navigation -->
					</div>
			</main><!-- #main -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Basque Country’s Mondragón Corporation is the largest industrial co-op (264 pts)]]></title>
            <link>https://www.theguardian.com/lifeandstyle/2024/apr/24/in-the-us-they-think-were-communists-the-70000-workers-showing-the-world-another-way-to-earn-a-living</link>
            <guid>40143814</guid>
            <pubDate>Wed, 24 Apr 2024 12:58:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/lifeandstyle/2024/apr/24/in-the-us-they-think-were-communists-the-70000-workers-showing-the-world-another-way-to-earn-a-living">https://www.theguardian.com/lifeandstyle/2024/apr/24/in-the-us-they-think-were-communists-the-70000-workers-showing-the-world-another-way-to-earn-a-living</a>, See on <a href="https://news.ycombinator.com/item?id=40143814">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p><span>W</span>hen Marisa Fernández lost her husband to cancer a few years ago, her employers at the Eroski hypermarket went, she says, “above and beyond to help me through the dark days afterwards, rejigging my timetable and giving me time off when I couldn’t face coming in.”</p><p>She had a chance to return the favour recently when the store, in Arrasate-Mondragón in Spain’s Basque Country, was undergoing renovations. Fernández, 58, who started on the cashier desk 34 years ago, and now manages the store’s non-food section, volunteered to work extra shifts over the weekend along with her colleagues to ensure everything was ready for Monday morning. “It’s not just me. Everyone is ready to go the extra mile,” she says.</p><p>Such harmonious employer-worker relations are the stuff of corporate dreams, and they are no accident here: the Eroski retail chain is part of Mondragón Corporation, the largest industrial co-op in the world. As a fully signed-up member, Fernández co-owns part of the supermarket chain that also employs her. “It feels like mine,” she says. “We work hard, but it’s a totally different feeling from working for someone else.”</p><p>That sentiment is echoed by <a href="https://www.mondragon-corporation.com/en/" data-link-name="in body link">Mondragón’s</a> 70,000 other workers. Made up of 81 autonomous co-operatives, the corporation has grown since its creation in 1956 to become a leading force in the Basque economy. Eroski is one of its most conspicuous manifestations, with 1,645 outlets across Spain. In addition to food, the chain has profitable sidelines in white goods, electronics, insurance and holiday bookings.</p><figure id="aff07454-5698-4bb0-9d19-651f202758bf" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/38211391a4b98f8892df00c09a71545690c6b375/0_0_6000_4000/master/6000.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/38211391a4b98f8892df00c09a71545690c6b375/0_0_6000_4000/master/6000.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/38211391a4b98f8892df00c09a71545690c6b375/0_0_6000_4000/master/6000.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/38211391a4b98f8892df00c09a71545690c6b375/0_0_6000_4000/master/6000.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/38211391a4b98f8892df00c09a71545690c6b375/0_0_6000_4000/master/6000.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/38211391a4b98f8892df00c09a71545690c6b375/0_0_6000_4000/master/6000.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Aerial view of a Basque Country supermarket." src="https://i.guim.co.uk/img/media/38211391a4b98f8892df00c09a71545690c6b375/0_0_6000_4000/master/6000.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="296.66666666666663" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Inside an Eroski supermarket in Arrasate-Mondragón.</span> Photograph: Markel Redondo/The Guardian</figcaption></figure><p>More than its economic success, though, Mondragón has become a beacon for the co-operative model, as a more humane and egalitarian way of doing business that puts “people over capital”. Every worker has a stake in the company’s fortunes and a say in how it is run, and receives a share of the profits. But the goal is more about creating “rich societies, not rich people”. That means looking after workers during not only the good times but the tough times, too.</p><p>The lowest point for Maite Aguirrebeitia, for example, came back in 2013, when, after 20 years’ service, the Mondragón co-operative that she and her husband were affiliated to, Fagor Electrodomésticos, filed for bankruptcy. Demand for its ovens and household appliances had plummeted after the 2008 financial crisis and despite help from a Mondragón “solidarity fund”, it never recovered.</p><p>“I felt this overwhelming sense of pain and grief at the time, as if someone close to me had died,” the 56-year-old communications specialist recalls. “Plus we had two kids and bills to pay and so on. The mental stress of it all was huge.”</p><p>Rather than thank the redundant workers for their service and wish them on their way, Mondragón committed to find alternative employment for as many of Fagor’s 1,900 or so workers as it could. After temporary stints in five Mondragón co-operatives in 2022, Aguirrebeitia found a permanent placement with Mondragon Assembly, a manufacturer of equipment for process automation.</p><p>Although it has meant a shift in career – she now works part-time in human resources, and part-time as a receptionist – the security of having a fixed job is a “huge relief”, she says. “I always felt confident that somehow I’d be looked after. I talked to other people who were out of work at the time and they had none of that. They were out on the street, totally alone. If I’d had to compete in the open job market against all the youngsters coming out of university, I’m not sure I’d have ever found another job.”</p><p>Mondragón’s human-centric approach originated far from any business management school. Its roots lie in a socially engaged form of Catholicism that gained ground in the 1940s, during the early years of the Francoist regime. Its initial champion was a Basque-born cleric named José María Arizmendiarrieta, who, in 1941, arrived in the small town of Arrasate-Mondragón, about 30 miles (50km) south-east of Bilbao.</p><figure id="d2208b53-b871-4eb3-8120-678234e365b0" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-3"><picture><source srcset="https://i.guim.co.uk/img/media/5a1477826656c4bf5dc552da7f2886010e556131/0_0_6000_4000/master/6000.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/5a1477826656c4bf5dc552da7f2886010e556131/0_0_6000_4000/master/6000.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/5a1477826656c4bf5dc552da7f2886010e556131/0_0_6000_4000/master/6000.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/5a1477826656c4bf5dc552da7f2886010e556131/0_0_6000_4000/master/6000.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/5a1477826656c4bf5dc552da7f2886010e556131/0_0_6000_4000/master/6000.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/5a1477826656c4bf5dc552da7f2886010e556131/0_0_6000_4000/master/6000.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Statue of a seated José María Arizmendiarrieta. In front of the plinth are colourful flowers." src="https://i.guim.co.uk/img/media/5a1477826656c4bf5dc552da7f2886010e556131/0_0_6000_4000/master/6000.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="296.66666666666663" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>A statue of Mondragón Corporation founder José María Arizmendiarrieta.</span> Photograph: Markel Redondo/The Guardian</figcaption></figure><p>Taking it as his pastoral mission to revitalise the local economy, the diocesan priest set up a technical school for young men. A few years later, he arranged for some of them to take distance-learning degrees in industrial engineering. “After graduating, they all found jobs in conventional companies in the town, but they felt stifled … they wanted more of a say over their destiny, but their employers thought otherwise,” explains Ander Etxeberria, head of Mondragón’s outreach programme.</p><p>With Arizmendiarrieta’s encouragement, five of these first 11 graduates decided in 1955 to set up the now defunct Fagor Electrodomésticos. Seeking a model that reflected their Christian socialist philosophy, they turned to the <a href="https://www.theguardian.com/business/2014/apr/23/rochdale-pioneers-paul-flowers-co-operative-debts" data-link-name="in body link">Rochdale Pioneers</a>, a group of tradespeople from the Lancashire town who, more than a century before, had established the world’s first co-operative. That venture grew to become today’s Co-operative Group, home to the UK’s fifth biggest food retailer and its largest provider of funeral services.</p><p>Mondragón’s founders adopted wholesale many of the Pioneers’ core tenets. In their modern-day headquarters, located in a renovated 14th-century tower with a spectacular mountain backdrop, Etxeberria counts off the group’s 10 “basic principles”. The list ranges from the sovereignty of labour and democratic organisation (one member, one vote), to wage solidarity and “social transformation” – which includes reinvesting surpluses to create new jobs, supporting local charities and community development projects, and strengthening the Basque Country’s Euskara language. Top of the list is voluntary and open membership – namely, the opportunity for everyone to have a personal stake in the enterprise where they work. As an early version of the principles reads: “The first form of elemental justice that we need to practise is to consider each other as free human beings.”</p><figure id="2eb6c58a-b663-4fc0-8789-f6239dd3c5da" data-spacefinder-role="supporting" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-4"><picture><source srcset="https://i.guim.co.uk/img/media/2b367f9256078da1b92282fa6e078feedebc6650/0_0_4000_6000/master/4000.jpg?width=380&amp;dpr=2&amp;s=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/2b367f9256078da1b92282fa6e078feedebc6650/0_0_4000_6000/master/4000.jpg?width=380&amp;dpr=1&amp;s=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/2b367f9256078da1b92282fa6e078feedebc6650/0_0_4000_6000/master/4000.jpg?width=300&amp;dpr=2&amp;s=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/2b367f9256078da1b92282fa6e078feedebc6650/0_0_4000_6000/master/4000.jpg?width=300&amp;dpr=1&amp;s=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/2b367f9256078da1b92282fa6e078feedebc6650/0_0_4000_6000/master/4000.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/2b367f9256078da1b92282fa6e078feedebc6650/0_0_4000_6000/master/4000.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/2b367f9256078da1b92282fa6e078feedebc6650/0_0_4000_6000/master/4000.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/2b367f9256078da1b92282fa6e078feedebc6650/0_0_4000_6000/master/4000.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/2b367f9256078da1b92282fa6e078feedebc6650/0_0_4000_6000/master/4000.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/2b367f9256078da1b92282fa6e078feedebc6650/0_0_4000_6000/master/4000.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Bearded middle-aged man, wearing a grey blazer and dark shirt." src="https://i.guim.co.uk/img/media/2b367f9256078da1b92282fa6e078feedebc6650/0_0_4000_6000/master/4000.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="667.5" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Ander Etxeberria, head of outreach programmes at the Mondragón Corporation.</span> Photograph: Markel Redondo/The Guardian</figcaption></figure><p>These values hold true into the present, Etxeberria explains. The salary differential between the highest and lowest paid workers in Mondragón, for example, remains about six to one; for the largest 500 listed companies in the US, the <a href="https://www.reuters.com/business/ceo-pay-averaged-167-million-last-year-sp-500-companies-decline-2023-08-03/" data-link-name="in body link">gap is closer to 272 to one.</a> At the year end, members of Mondragón’s co-operatives also decide collectively on whether they should pay themselves bonuses and, if so, how much. This profit-sharing comes in addition to a base pay rate that, on average, is 40% above Spain’s minimum wage.</p><p>Despite its social responsibility credentials, Mondragón remains a competitive business. When Etxeberria presses “play” on an introductory video, the screen shows not pictures of happy workers doing yoga but gleaming industrial facilities and straight-faced technicians in lab coats. Overlaying these images are facts and figures that would have mainstream financiers salivating: €10.6bn (£9.1bn) in annual revenues; a dozen research and development facilities; a global roster of blue-chip clients; and a diversified sector spread – industry, retail, finance and education.</p><p>The same no-nonsense, professional vibe is on show at Fagor Arrasate, a Mondragón affiliate located on one of the many industrial estates that ring Arrasate-Mondragón, a vibrant town of cafe-strewn streets and busy bars. A specialist in metal presses and stamping systems, Fagor Arrasate boasts several hangar-sized workshops full of robotic machinery and giant components ready for export. “Some of the installations we make for customers can be three to four storeys high, so these are massive, multimillion-euro investments,” enthuses Edorta Mendieta, the venture’s marketing manager.</p><p>Pinned to a cork noticeboard beside a busy production line are photos of a recent charity run, a printout of donations to local causes (including €60,000 for a nearby organic food association), and a poster about a forthcoming “women in science” event. In the centre of the board, an A4 sheet of closely printed text gives notice of the co-operative’s general assembly, where next year’s strategy plan will be put to an all-member vote.</p><figure id="d2bfe53e-f89f-443b-a471-97a981705da2" data-spacefinder-role="showcase" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-5"><picture><source srcset="https://i.guim.co.uk/img/media/15bfa8e2bc3f9408a07efc627e71c0242c70f14a/0_434_5272_3163/master/5272.jpg?width=880&amp;dpr=2&amp;s=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/15bfa8e2bc3f9408a07efc627e71c0242c70f14a/0_434_5272_3163/master/5272.jpg?width=880&amp;dpr=1&amp;s=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/15bfa8e2bc3f9408a07efc627e71c0242c70f14a/0_434_5272_3163/master/5272.jpg?width=800&amp;dpr=2&amp;s=none" media="(min-width: 1140px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1140px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/15bfa8e2bc3f9408a07efc627e71c0242c70f14a/0_434_5272_3163/master/5272.jpg?width=800&amp;dpr=1&amp;s=none" media="(min-width: 1140px)"><source srcset="https://i.guim.co.uk/img/media/15bfa8e2bc3f9408a07efc627e71c0242c70f14a/0_434_5272_3163/master/5272.jpg?width=640&amp;dpr=2&amp;s=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/15bfa8e2bc3f9408a07efc627e71c0242c70f14a/0_434_5272_3163/master/5272.jpg?width=640&amp;dpr=1&amp;s=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/15bfa8e2bc3f9408a07efc627e71c0242c70f14a/0_434_5272_3163/master/5272.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/15bfa8e2bc3f9408a07efc627e71c0242c70f14a/0_434_5272_3163/master/5272.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/15bfa8e2bc3f9408a07efc627e71c0242c70f14a/0_434_5272_3163/master/5272.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/15bfa8e2bc3f9408a07efc627e71c0242c70f14a/0_434_5272_3163/master/5272.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/15bfa8e2bc3f9408a07efc627e71c0242c70f14a/0_434_5272_3163/master/5272.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/15bfa8e2bc3f9408a07efc627e71c0242c70f14a/0_434_5272_3163/master/5272.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Mondragón in the Basque Country, where a number of Mondragón Corporation’s factories are based." src="https://i.guim.co.uk/img/media/15bfa8e2bc3f9408a07efc627e71c0242c70f14a/0_434_5272_3163/master/5272.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="266.9831183611533" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Mondragón in the Basque Country, where a number of Mondragón Corporation’s factories are based.</span> Photograph: Markel Redondo/The Guardian</figcaption></figure><p>Mondragón’s collective spirit also offers an edge with innovation. In a process that the movement refers to as “inter-cooperation”, co-operatives within the group frequently swap ideas between themselves and engage in joint research.</p><p>Over the years, many of the best innovations have come from alliances with Mondragón’s homegrown university. Located on a leafy campus in Arrasate-Mondragón, the university was set up with a strong practical bent to both its teaching and its research. So much so, in fact, that the European Commission recently selected it to co-lead a major “dual training” programme aimed at blending academia with business to tackle global challenges such as the climate crisis.</p><p>Mondragón’s approach has proved itself profitable and resilient, so could it become a realistic alternative to the modern corporation?</p><p>It’s a moot point. Despite their worker-first philosophy, the movement’s leaders are reluctant to denounce the wealth-maximising nature of modern market capitalism. The reason is as simple as it is awkward: Mondragón must actively participate in that same capitalist system for its survival.</p><p>This tactic of being “in, but not of” the world of mainstream business has seen the Basque-based movement face charges of double standards. In particular, critics highlight its outsourcing of some of its production to low-wage countries with weaker labour standards, such as China and Mexico. Mondragón argues that it has checks and balances in place to ensure that its foreign business partners uphold workers’ rights, and that keeping costs low is part and parcel of staying competitive. “For us, workers will always come before capital. But capital is still important because without it we cannot fulfil our mission of social transformation,” says Javier Marcos, Mondragón’s director of communications.</p><p>Radical as that mission is, its focus is and always has been primarily on <em>el territorio</em> (the local Basque region); less about rewriting the global economic order and more about improving co-op members’ lives. That said, if others want to copy the Mondragón model, then its doors are always open, insists Etxeberria. In the past month alone, he has hosted large groups of policymakers and business students from the Philippines, Brazil and the US. “They come to see if our approach works in practice,” he says. “They all go back pleasantly surprised, I think.”</p><p>Young people, in particular, are attracted to the notion of business and entrepreneurship going beyond just the pursuit of profit, but they “don’t know the co-operative possibility exists,” says Ana Aguirre, a graduate of Mondragón University. The 33-year-old now co-runs <a href="https://tzbz.coop/en/home/" data-link-name="in body link">Tazebaez</a>, a worker-owned consultancy and education provider that she and eight fellow students created during their bachelor’s degree. For the few who have heard of co-operativism, she adds, most relegate it in the folksy, do-gooder box. “The problem is that it’s portrayed as something to do with charity or [philanthropic] foundations, rather than as a credible business model.”</p><figure id="7f5489aa-c109-499b-a61b-b51c59e09cb6" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-6"><picture><source srcset="https://i.guim.co.uk/img/media/5486d710179b82602e658df0b6cc0f7aa9cc23fe/0_0_6000_4000/master/6000.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/5486d710179b82602e658df0b6cc0f7aa9cc23fe/0_0_6000_4000/master/6000.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/5486d710179b82602e658df0b6cc0f7aa9cc23fe/0_0_6000_4000/master/6000.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/5486d710179b82602e658df0b6cc0f7aa9cc23fe/0_0_6000_4000/master/6000.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/5486d710179b82602e658df0b6cc0f7aa9cc23fe/0_0_6000_4000/master/6000.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/5486d710179b82602e658df0b6cc0f7aa9cc23fe/0_0_6000_4000/master/6000.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Three young women walking along a walkway with a roof." src="https://i.guim.co.uk/img/media/5486d710179b82602e658df0b6cc0f7aa9cc23fe/0_0_6000_4000/master/6000.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="296.66666666666663" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Students at the Mondragón University campus.</span> Photograph: Markel Redondo/The Guardian</figcaption></figure><p>Pursuing a co-operative model is far from plain sailing, however. Numerous hurdles exist. For one, membership does not come cheap. To join a co-operative, workers typically put up a one-off payment of about €17,000 each. Plus, just as they are entitled to a share of any profits, so, too, are they liable for any losses.</p><p>Commercial pressures can also prove acute, as Fagor Electrodomésticos’s troubled history shows. The fact that all major investment decisions have to be put to the vote can also make Mondragón’s co-operatives less agile than their conventional competitors. And finding financing can be problematic as the private capital markets are effectively closed to them, admits Fagor Arrasate’s Mendieta: “We can’t incorporate external capital into the co-operative’s share capital because we are governed by the principle of ‘one person, one vote’, which no capitalist investor would accept.”</p><p>In some parts of the world, Mondragón’s approach just looks downright weird. No one bats an eyelid at the co-operative model in countries such as Germany, “but with these ideas in Texas or Kansas, you’re basically a communist,” says Mendieta, only half jokingly.</p><figure id="1b49055b-9c22-4d44-bb7e-6647798c4ab4" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:32,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Best bits: can co-operatives compete with big business?&quot;,&quot;elementId&quot;:&quot;1b49055b-9c22-4d44-bb7e-6647798c4ab4&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/social-enterprise-network/2014/mar/14/co-operatives-compete-big-business&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:2,&quot;theme&quot;:4,&quot;design&quot;:10}}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false}"></gu-island></figure><p>Across Europe, at least, the co-operative model is widespread. In Norway, for instance, co-ops have a <a href="https://www.nbbl.no/english/" data-link-name="in body link">strong heritage in the social housing sector</a>. Italy’s <a href="https://www.lowimpact.org/posts/why-is-the-co-operative-movement-so-successful-in-emilia-romagna-with-matt-hancock-no-not-that-one" data-link-name="in body link">Emilia-Romagna region</a> boasts a long tradition of industrial co-operatives similar to that of the Basque Country. And, as well as the Co-operative Group, <a href="https://www.consultancy.uk/news/12130/co-operative-businesses-contribute-34-billion-to-uk-economy#:~:text=The%20top%20five%20is%20closed,Co%2Doperative%20and%20First%20Milk." data-link-name="in body link">the UK</a>’s almost 7,000 co-operatives include the mighty John Lewis Partnership, which has a turnover of nearly £10bn. In total, the EU hosts about <a href="https://single-market-economy.ec.europa.eu/sectors/proximity-and-social-economy/social-economy-eu/cooperatives_en" data-link-name="in body link">250,000 co-operatives, providing 5.4m jobs</a>.</p><p>Increasingly, the movement’s footprint is also being seen in company law. Germany has long required <a href="https://worker-participation.eu/legislation/european-company-se/countries-transposition/germany" data-link-name="in body link">corporate boards to have worker representatives</a>, for instance. Similarly, Spanish law allows unemployed people to lump together their unemployment benefit to set up small businesses – known as <a href="https://www.europarl.europa.eu/RegData/etudes/STUD/2016/587300/IPOL_STU(2016)587300_EN.pdf" data-link-name="in body link">Sociedades Laborales</a> – as long as they are majority owned by their employees. The rise in mainstream corporations now talking the language of employee autonomy, horizontal management, dignified wages and similar themes suggests co-operativism is leaving its mark on business company practices if not – yet – on capitalist ownership</p><p>Back in Mondragón’s fort-like headquarters, Etxeberria is quietly confident about the movement’s prospects. Co-operativism, he says, is a little like <em>zirimiri</em> – the Eusakara word for “drizzle”. “It’s the same ideas that keep falling; they’ll settle eventually.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Faer-rs: Linear algebra foundation for the Rust programming language (206 pts)]]></title>
            <link>https://github.com/sarah-ek/faer-rs</link>
            <guid>40143669</guid>
            <pubDate>Wed, 24 Apr 2024 12:41:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/sarah-ek/faer-rs">https://github.com/sarah-ek/faer-rs</a>, See on <a href="https://news.ycombinator.com/item?id=40143669">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">faer</h2><a id="user-content-faer" aria-label="Permalink: faer" href="#faer"></a></p>
<p dir="auto"><a href="https://docs.rs/faer" rel="nofollow"><img src="https://camo.githubusercontent.com/54926fb41b51f51d9b0036d79246ce995716617cfcbf55a5e111429fbe7d904c/68747470733a2f2f646f63732e72732f666165722f62616467652e737667" alt="Documentation" data-canonical-src="https://docs.rs/faer/badge.svg"></a>
<a href="https://crates.io/crates/faer" rel="nofollow"><img src="https://camo.githubusercontent.com/fe6554c6f68eaf3ce5f8dbd91150957dfa2a1f5b90613ed557e56c06c3afc6e3/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f666165722e737667" alt="Crate" data-canonical-src="https://img.shields.io/crates/v/faer.svg"></a></p>
<p dir="auto"><code>faer</code> is a Rust crate that implements low level linear algebra routines and a high level wrapper for ease of use, in pure Rust.
The aim is to provide a fully featured library for linear algebra with focus on portability, correctness, and performance.</p>
<p dir="auto">See the <a href="https://faer-rs.github.io/" rel="nofollow">official website</a> and the <a href="https://docs.rs/faer/latest/faer" rel="nofollow">docs.rs</a> documentation for code examples and usage instructions.</p>
<p dir="auto">Questions about using the library, contributing, and future directions can be discussed in the <a href="https://discord.gg/Ak5jDsAFVZ" rel="nofollow">Discord server</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">If you'd like to contribute to <code>faer</code>, check out the list of "good first issue"
issues. These are all (or should be) issues that are suitable for getting
started, and they generally include a detailed set of instructions for what to
do. Please ask questions on the Discord server or the issue itself if anything
is unclear!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Minimum supported Rust version</h2><a id="user-content-minimum-supported-rust-version" aria-label="Permalink: Minimum supported Rust version" href="#minimum-supported-rust-version"></a></p>
<p dir="auto">The current MSRV is Rust 1.67.0.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Benchmarks</h2><a id="user-content-benchmarks" aria-label="Permalink: Benchmarks" href="#benchmarks"></a></p>
<p dir="auto">The benchmarks were run on an <code>11th Gen Intel(R) Core(TM) i5-11400 @ 2.60GHz</code> with 12 threads.</p>
<ul dir="auto">
<li><code>nalgebra</code> is used with the <code>matrixmultiply</code> backend</li>
<li><code>ndarray</code> is used with the <code>openblas</code> backend</li>
<li><code>eigen</code> is compiled with <code>-march=native -O3 -fopenmp</code></li>
</ul>
<p dir="auto">All computations are done on column major matrices containing <code>f64</code> values.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Matrix multiplication</h2><a id="user-content-matrix-multiplication" aria-label="Permalink: Matrix multiplication" href="#matrix-multiplication"></a></p>
<p dir="auto">Multiplication of two square matrices of dimension <code>n</code>.</p>
<div data-snippet-clipboard-copy-content="    n       faer  faer(par)    ndarray   nalgebra      eigen
    4       40ns       41ns      139ns       29ns       17ns
    8       77ns       80ns       63ns      161ns       85ns
   16      189ns      193ns      201ns      363ns      219ns
   32      1.1µs      1.1µs      1.1µs      1.5µs      1.2µs
   64      7.9µs      7.9µs      7.9µs     10.5µs      5.1µs
   96     27.5µs     11.2µs     26.2µs     34.9µs     10.1µs
  128     65.5µs     17.1µs     35.7µs     78.3µs     32.9µs
  192    216.6µs     54.4µs     57.3µs    260.7µs     51.7µs
  256    510.8µs    117.8µs    183.2µs    602.6µs    142.9µs
  384      1.7ms    339.1µs    575.8µs        2ms    327.9µs
  512        4ms    785.6µs      1.3ms      4.7ms        1ms
  640      7.9ms      1.6ms      2.3ms      9.2ms      1.9ms
  768     13.8ms      2.9ms      3.6ms       16ms      3.2ms
  896     22.2ms      4.6ms      6.5ms     25.7ms      5.9ms
 1024     33.9ms      6.6ms      9.7ms     39.1ms      8.3ms"><pre><code>    n       faer  faer(par)    ndarray   nalgebra      eigen
    4       40ns       41ns      139ns       29ns       17ns
    8       77ns       80ns       63ns      161ns       85ns
   16      189ns      193ns      201ns      363ns      219ns
   32      1.1µs      1.1µs      1.1µs      1.5µs      1.2µs
   64      7.9µs      7.9µs      7.9µs     10.5µs      5.1µs
   96     27.5µs     11.2µs     26.2µs     34.9µs     10.1µs
  128     65.5µs     17.1µs     35.7µs     78.3µs     32.9µs
  192    216.6µs     54.4µs     57.3µs    260.7µs     51.7µs
  256    510.8µs    117.8µs    183.2µs    602.6µs    142.9µs
  384      1.7ms    339.1µs    575.8µs        2ms    327.9µs
  512        4ms    785.6µs      1.3ms      4.7ms        1ms
  640      7.9ms      1.6ms      2.3ms      9.2ms      1.9ms
  768     13.8ms      2.9ms      3.6ms       16ms      3.2ms
  896     22.2ms      4.6ms      6.5ms     25.7ms      5.9ms
 1024     33.9ms      6.6ms      9.7ms     39.1ms      8.3ms
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Triangular solve</h2><a id="user-content-triangular-solve" aria-label="Permalink: Triangular solve" href="#triangular-solve"></a></p>
<p dir="auto">Solving <code>AX = B</code> in place where <code>A</code> and <code>B</code> are two square matrices of dimension <code>n</code>, and <code>A</code> is a triangular matrix.</p>
<div data-snippet-clipboard-copy-content="    n       faer  faer(par)    ndarray   nalgebra      eigen
    4       20ns       19ns      755ns       39ns       65ns
    8      118ns      118ns      1.5µs      308ns      156ns
   16      498ns      502ns      3.3µs      1.5µs      671ns
   32      2.1µs      2.1µs      8.6µs      6.6µs      2.9µs
   64      9.7µs      9.8µs     25.9µs     34.2µs     13.8µs
   96     27.7µs     24.5µs     55.2µs    101.4µs     36.9µs
  128     56.4µs     39.9µs    145.2µs      232µs     81.7µs
  192    167.8µs       92µs    263.6µs    815.5µs    213.6µs
  256    367.7µs      163µs      660µs      1.9ms    488.1µs
  384      1.1ms    317.5µs      1.4ms      7.4ms      1.4ms
  512      2.6ms    662.7µs      3.5ms     17.2ms      3.3ms
  640      4.7ms      1.2ms      5.7ms     33.6ms      5.5ms
  768        8ms      2.3ms      9.4ms     56.2ms      9.3ms
  896     12.3ms      3.6ms     13.6ms     89.3ms       14ms
 1024     18.7ms      5.2ms     20.1ms    131.9ms     22.9ms"><pre><code>    n       faer  faer(par)    ndarray   nalgebra      eigen
    4       20ns       19ns      755ns       39ns       65ns
    8      118ns      118ns      1.5µs      308ns      156ns
   16      498ns      502ns      3.3µs      1.5µs      671ns
   32      2.1µs      2.1µs      8.6µs      6.6µs      2.9µs
   64      9.7µs      9.8µs     25.9µs     34.2µs     13.8µs
   96     27.7µs     24.5µs     55.2µs    101.4µs     36.9µs
  128     56.4µs     39.9µs    145.2µs      232µs     81.7µs
  192    167.8µs       92µs    263.6µs    815.5µs    213.6µs
  256    367.7µs      163µs      660µs      1.9ms    488.1µs
  384      1.1ms    317.5µs      1.4ms      7.4ms      1.4ms
  512      2.6ms    662.7µs      3.5ms     17.2ms      3.3ms
  640      4.7ms      1.2ms      5.7ms     33.6ms      5.5ms
  768        8ms      2.3ms      9.4ms     56.2ms      9.3ms
  896     12.3ms      3.6ms     13.6ms     89.3ms       14ms
 1024     18.7ms      5.2ms     20.1ms    131.9ms     22.9ms
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Triangular inverse</h2><a id="user-content-triangular-inverse" aria-label="Permalink: Triangular inverse" href="#triangular-inverse"></a></p>
<p dir="auto">Computing <code>A^-1</code> where <code>A</code> is a square triangular matrix with dimension <code>n</code>.</p>
<div data-snippet-clipboard-copy-content="    n       faer  faer(par)    ndarray   nalgebra      eigen
    4      162ns      5.2µs      771ns       38ns       65ns
    8      514ns      5.9µs      1.5µs      308ns      156ns
   16      1.6µs      7.7µs      3.4µs      1.5µs      672ns
   32      4.2µs     10.5µs      8.7µs      6.6µs      2.9µs
   64     12.5µs     18.1µs     25.7µs     34.2µs     13.8µs
   96     30.6µs     39.8µs       55µs    101.4µs     36.9µs
  128     42.7µs     51.9µs    144.9µs      232µs     81.6µs
  192      110µs     89.7µs    262.9µs    815.7µs    213.3µs
  256    191.7µs    138.3µs    645.5µs      1.9ms    486.9µs
  384    533.5µs    274.7µs      1.4ms      6.7ms      1.4ms
  512      1.1ms    449.4µs      3.5ms     15.6ms      3.3ms
  640        2ms    861.3µs      5.6ms     30.2ms      5.5ms
  768      3.2ms      1.2ms      9.3ms     51.8ms      9.3ms
  896      4.8ms      1.7ms     13.4ms     81.9ms       14ms
 1024      7.2ms      2.4ms     19.9ms    122.8ms     22.7ms"><pre><code>    n       faer  faer(par)    ndarray   nalgebra      eigen
    4      162ns      5.2µs      771ns       38ns       65ns
    8      514ns      5.9µs      1.5µs      308ns      156ns
   16      1.6µs      7.7µs      3.4µs      1.5µs      672ns
   32      4.2µs     10.5µs      8.7µs      6.6µs      2.9µs
   64     12.5µs     18.1µs     25.7µs     34.2µs     13.8µs
   96     30.6µs     39.8µs       55µs    101.4µs     36.9µs
  128     42.7µs     51.9µs    144.9µs      232µs     81.6µs
  192      110µs     89.7µs    262.9µs    815.7µs    213.3µs
  256    191.7µs    138.3µs    645.5µs      1.9ms    486.9µs
  384    533.5µs    274.7µs      1.4ms      6.7ms      1.4ms
  512      1.1ms    449.4µs      3.5ms     15.6ms      3.3ms
  640        2ms    861.3µs      5.6ms     30.2ms      5.5ms
  768      3.2ms      1.2ms      9.3ms     51.8ms      9.3ms
  896      4.8ms      1.7ms     13.4ms     81.9ms       14ms
 1024      7.2ms      2.4ms     19.9ms    122.8ms     22.7ms
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Cholesky decomposition</h2><a id="user-content-cholesky-decomposition" aria-label="Permalink: Cholesky decomposition" href="#cholesky-decomposition"></a></p>
<p dir="auto">Factorizing a square matrix with dimension <code>n</code> as <code>L×L.T</code>, where <code>L</code> is lower triangular.</p>
<div data-snippet-clipboard-copy-content="    n       faer  faer(par)    ndarray   nalgebra      eigen
    4       49ns       49ns      149ns       52ns       43ns
    8      128ns      128ns      329ns       99ns      125ns
   16      408ns      408ns      950ns      412ns      376ns
   32      1.8µs      1.8µs      3.3µs      1.8µs      2.3µs
   64        7µs        7µs     34.6µs     10.5µs        9µs
   96       18µs     18.2µs     70.5µs     31.3µs       21µs
  128     30.1µs     30.4µs    202.2µs     77.4µs     40.3µs
  192     86.4µs     92.7µs    301.3µs    259.8µs    105.2µs
  256    161.7µs    149.4µs    711.5µs    607.4µs    216.6µs
  384    462.9µs    423.9µs      1.2ms      2.1ms    596.5µs
  512      1.1ms    619.5µs      3.8ms      5.4ms      1.3ms
  640      1.9ms      1.3ms      3.3ms     10.4ms      2.2ms
  768      3.3ms      1.8ms      5.4ms     17.9ms      3.7ms
  896        5ms      2.7ms      6.9ms     28.4ms      5.6ms
 1024      7.8ms      3.4ms     14.5ms     41.2ms      8.4ms"><pre><code>    n       faer  faer(par)    ndarray   nalgebra      eigen
    4       49ns       49ns      149ns       52ns       43ns
    8      128ns      128ns      329ns       99ns      125ns
   16      408ns      408ns      950ns      412ns      376ns
   32      1.8µs      1.8µs      3.3µs      1.8µs      2.3µs
   64        7µs        7µs     34.6µs     10.5µs        9µs
   96       18µs     18.2µs     70.5µs     31.3µs       21µs
  128     30.1µs     30.4µs    202.2µs     77.4µs     40.3µs
  192     86.4µs     92.7µs    301.3µs    259.8µs    105.2µs
  256    161.7µs    149.4µs    711.5µs    607.4µs    216.6µs
  384    462.9µs    423.9µs      1.2ms      2.1ms    596.5µs
  512      1.1ms    619.5µs      3.8ms      5.4ms      1.3ms
  640      1.9ms      1.3ms      3.3ms     10.4ms      2.2ms
  768      3.3ms      1.8ms      5.4ms     17.9ms      3.7ms
  896        5ms      2.7ms      6.9ms     28.4ms      5.6ms
 1024      7.8ms      3.4ms     14.5ms     41.2ms      8.4ms
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">LU decomposition with partial pivoting</h2><a id="user-content-lu-decomposition-with-partial-pivoting" aria-label="Permalink: LU decomposition with partial pivoting" href="#lu-decomposition-with-partial-pivoting"></a></p>
<p dir="auto">Factorizing a square matrix with dimension <code>n</code> as <code>P×L×U</code>, where <code>P</code> is a permutation matrix, <code>L</code> is unit lower triangular and <code>U</code> is upper triangular.</p>
<div data-snippet-clipboard-copy-content="    n       faer  faer(par)    ndarray   nalgebra      eigen
    4      103ns       99ns      180ns       77ns       98ns
    8      210ns      217ns      405ns      241ns      278ns
   16      649ns      625ns      1.4µs      859ns      880ns
   32      2.7µs      2.6µs      5.6µs      4.4µs      3.9µs
   64     12.4µs     12.5µs     17.4µs     22.9µs     15.6µs
   96     30.2µs     31.6µs     34.4µs     67.9µs     36.7µs
  128     61.3µs     60.7µs     97.4µs    159.4µs      126µs
  192    163.5µs    187.3µs    182.4µs    527.8µs    425.5µs
  256      352µs    360.9µs    491.1µs      1.3ms    824.9µs
  384    968.8µs    781.3µs    909.5µs      4.5ms      1.9ms
  512      2.1ms      1.5ms      1.5ms     11.1ms      4.3ms
  640      3.8ms      2.2ms      2.2ms     20.7ms      5.6ms
  768      6.2ms      3.2ms      3.4ms     35.8ms      8.6ms
  896      9.5ms      4.6ms      4.7ms     56.1ms     11.4ms
 1024     14.4ms      6.5ms      6.7ms       88ms     17.1ms"><pre><code>    n       faer  faer(par)    ndarray   nalgebra      eigen
    4      103ns       99ns      180ns       77ns       98ns
    8      210ns      217ns      405ns      241ns      278ns
   16      649ns      625ns      1.4µs      859ns      880ns
   32      2.7µs      2.6µs      5.6µs      4.4µs      3.9µs
   64     12.4µs     12.5µs     17.4µs     22.9µs     15.6µs
   96     30.2µs     31.6µs     34.4µs     67.9µs     36.7µs
  128     61.3µs     60.7µs     97.4µs    159.4µs      126µs
  192    163.5µs    187.3µs    182.4µs    527.8µs    425.5µs
  256      352µs    360.9µs    491.1µs      1.3ms    824.9µs
  384    968.8µs    781.3µs    909.5µs      4.5ms      1.9ms
  512      2.1ms      1.5ms      1.5ms     11.1ms      4.3ms
  640      3.8ms      2.2ms      2.2ms     20.7ms      5.6ms
  768      6.2ms      3.2ms      3.4ms     35.8ms      8.6ms
  896      9.5ms      4.6ms      4.7ms     56.1ms     11.4ms
 1024     14.4ms      6.5ms      6.7ms       88ms     17.1ms
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">LU decomposition with full pivoting</h2><a id="user-content-lu-decomposition-with-full-pivoting" aria-label="Permalink: LU decomposition with full pivoting" href="#lu-decomposition-with-full-pivoting"></a></p>
<p dir="auto">Factorizing a square matrix with dimension <code>n</code> as <code>P×L×U×Q.T</code>, where <code>P</code> and <code>Q</code> are permutation matrices, <code>L</code> is unit lower triangular and <code>U</code> is upper triangular.</p>
<div data-snippet-clipboard-copy-content="    n       faer  faer(par)    ndarray   nalgebra      eigen
    4      132ns      134ns          -      111ns      164ns
    8      386ns      415ns          -      418ns      493ns
   16      1.7µs      1.7µs          -      2.3µs      2.1µs
   32      5.9µs        6µs          -     14.7µs     12.2µs
   64     25.8µs     25.4µs          -    106.4µs     72.2µs
   96     67.7µs     67.9µs          -    347.3µs    206.3µs
  128    156.4µs    155.2µs          -    819.1µs    460.9µs
  192    463.4µs    460.6µs          -      2.8ms      1.4ms
  256      1.1ms      1.1ms          -      6.6ms      3.3ms
  384      3.8ms      3.8ms          -     22.1ms       11ms
  512     10.1ms      7.9ms          -     53.4ms     27.4ms
  640     17.7ms       12ms          -    102.5ms     50.7ms
  768     31.2ms     17.5ms          -    176.9ms     87.3ms
  896     47.3ms     25.1ms          -      280ms    136.1ms
 1024     76.1ms     33.9ms          -      431ms    207.9ms"><pre><code>    n       faer  faer(par)    ndarray   nalgebra      eigen
    4      132ns      134ns          -      111ns      164ns
    8      386ns      415ns          -      418ns      493ns
   16      1.7µs      1.7µs          -      2.3µs      2.1µs
   32      5.9µs        6µs          -     14.7µs     12.2µs
   64     25.8µs     25.4µs          -    106.4µs     72.2µs
   96     67.7µs     67.9µs          -    347.3µs    206.3µs
  128    156.4µs    155.2µs          -    819.1µs    460.9µs
  192    463.4µs    460.6µs          -      2.8ms      1.4ms
  256      1.1ms      1.1ms          -      6.6ms      3.3ms
  384      3.8ms      3.8ms          -     22.1ms       11ms
  512     10.1ms      7.9ms          -     53.4ms     27.4ms
  640     17.7ms       12ms          -    102.5ms     50.7ms
  768     31.2ms     17.5ms          -    176.9ms     87.3ms
  896     47.3ms     25.1ms          -      280ms    136.1ms
 1024     76.1ms     33.9ms          -      431ms    207.9ms
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">QR decomposition with no pivoting</h2><a id="user-content-qr-decomposition-with-no-pivoting" aria-label="Permalink: QR decomposition with no pivoting" href="#qr-decomposition-with-no-pivoting"></a></p>
<p dir="auto">Factorizing a square matrix with dimension <code>n</code> as <code>QR</code>, where <code>Q</code> is unitary and <code>R</code> is upper triangular.</p>
<div data-snippet-clipboard-copy-content="    n       faer  faer(par)    ndarray   nalgebra      eigen
    4      132ns      132ns      758ns      138ns      273ns
    8      345ns      346ns      1.7µs      321ns      777ns
   16      1.1µs      1.1µs      4.8µs      1.3µs      2.2µs
   32      4.4µs      4.4µs     15.3µs      6.9µs      7.4µs
   64     30.5µs     30.1µs     61.7µs     43.4µs     45.2µs
   96     65.2µs     65.2µs    322.4µs    141.3µs     79.1µs
  128    118.4µs    118.3µs    842.4µs    320.9µs    154.3µs
  192    315.3µs    316.1µs      1.6ms      1.1ms    383.7µs
  256    643.8µs    693.4µs      2.8ms      2.4ms    794.6µs
  384      1.9ms      1.7ms      7.6ms      8.1ms      2.1ms
  512      4.1ms        3ms     16.1ms       19ms      4.5ms
  640      7.4ms      4.5ms     22.5ms     36.2ms        8ms
  768     12.2ms      6.6ms     34.7ms     62.1ms     13.2ms
  896     18.6ms      9.2ms     46.3ms     97.7ms     20.4ms
 1024     27.7ms     12.9ms     65.9ms      150ms     30.2ms"><pre><code>    n       faer  faer(par)    ndarray   nalgebra      eigen
    4      132ns      132ns      758ns      138ns      273ns
    8      345ns      346ns      1.7µs      321ns      777ns
   16      1.1µs      1.1µs      4.8µs      1.3µs      2.2µs
   32      4.4µs      4.4µs     15.3µs      6.9µs      7.4µs
   64     30.5µs     30.1µs     61.7µs     43.4µs     45.2µs
   96     65.2µs     65.2µs    322.4µs    141.3µs     79.1µs
  128    118.4µs    118.3µs    842.4µs    320.9µs    154.3µs
  192    315.3µs    316.1µs      1.6ms      1.1ms    383.7µs
  256    643.8µs    693.4µs      2.8ms      2.4ms    794.6µs
  384      1.9ms      1.7ms      7.6ms      8.1ms      2.1ms
  512      4.1ms        3ms     16.1ms       19ms      4.5ms
  640      7.4ms      4.5ms     22.5ms     36.2ms        8ms
  768     12.2ms      6.6ms     34.7ms     62.1ms     13.2ms
  896     18.6ms      9.2ms     46.3ms     97.7ms     20.4ms
 1024     27.7ms     12.9ms     65.9ms      150ms     30.2ms
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">QR decomposition with column pivoting</h2><a id="user-content-qr-decomposition-with-column-pivoting" aria-label="Permalink: QR decomposition with column pivoting" href="#qr-decomposition-with-column-pivoting"></a></p>
<p dir="auto">Factorizing a square matrix with dimension <code>n</code> as <code>QRP</code>, where <code>P</code> is a permutation matrix, <code>Q</code> is unitary and <code>R</code> is upper triangular.</p>
<div data-snippet-clipboard-copy-content="    n       faer  faer(par)    ndarray   nalgebra      eigen
    4      167ns      185ns          -      172ns      373ns
    8      430ns      433ns          -      552ns        1µs
   16      1.7µs      1.7µs          -      2.8µs      2.9µs
   32      5.9µs        6µs          -     17.6µs      9.5µs
   64     33.2µs     50.6µs          -    126.9µs     37.9µs
   96     85.6µs    104.7µs          -    421.8µs    104.7µs
  128    182.3µs    209.2µs          -    987.7µs    218.1µs
  192    548.2µs    600.4µs          -      3.3ms    628.1µs
  256      1.3ms      1.4ms          -      7.6ms      1.6ms
  384      4.6ms      3.5ms          -     25.4ms      5.6ms
  512     11.4ms      6.7ms          -       60ms     15.1ms
  640     22.2ms     10.5ms          -    116.2ms     26.6ms
  768     37.7ms     14.8ms          -    199.7ms     46.2ms
  896     60.7ms     20.1ms          -    317.9ms     71.1ms
 1024     90.2ms     30.7ms          -    488.3ms      114ms"><pre><code>    n       faer  faer(par)    ndarray   nalgebra      eigen
    4      167ns      185ns          -      172ns      373ns
    8      430ns      433ns          -      552ns        1µs
   16      1.7µs      1.7µs          -      2.8µs      2.9µs
   32      5.9µs        6µs          -     17.6µs      9.5µs
   64     33.2µs     50.6µs          -    126.9µs     37.9µs
   96     85.6µs    104.7µs          -    421.8µs    104.7µs
  128    182.3µs    209.2µs          -    987.7µs    218.1µs
  192    548.2µs    600.4µs          -      3.3ms    628.1µs
  256      1.3ms      1.4ms          -      7.6ms      1.6ms
  384      4.6ms      3.5ms          -     25.4ms      5.6ms
  512     11.4ms      6.7ms          -       60ms     15.1ms
  640     22.2ms     10.5ms          -    116.2ms     26.6ms
  768     37.7ms     14.8ms          -    199.7ms     46.2ms
  896     60.7ms     20.1ms          -    317.9ms     71.1ms
 1024     90.2ms     30.7ms          -    488.3ms      114ms
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Matrix inverse</h2><a id="user-content-matrix-inverse" aria-label="Permalink: Matrix inverse" href="#matrix-inverse"></a></p>
<p dir="auto">Computing the inverse of a square matrix with dimension <code>n</code>.</p>
<div data-snippet-clipboard-copy-content="    n       faer  faer(par)    ndarray   nalgebra      eigen
    4      795ns      7.5µs      534ns       77ns      381ns
    8      2.2µs      8.9µs      995ns      825ns      794ns
   16      5.3µs       12µs      2.9µs        4µs      2.7µs
   32     15.2µs     29.9µs     10.3µs       19µs     10.8µs
   64     49.8µs     66.2µs     40.5µs    101.2µs     45.9µs
   96    127.1µs    122.7µs    182.1µs    285.3µs    119.2µs
  128    199.9µs    172.7µs    314.9µs    661.3µs      341µs
  192      543µs    419.8µs    587.1µs      2.2ms    963.8µs
  256        1ms    668.3µs      1.1ms      5.6ms        2ms
  384      2.9ms      1.4ms      2.4ms     18.7ms      5.1ms
  512      6.2ms      2.6ms      4.6ms     44.2ms     11.9ms
  640     11.5ms      5.5ms      7.2ms       83ms     19.2ms
  768     19.2ms      8.7ms     11.2ms    142.3ms     30.9ms
  896     29.5ms     12.9ms     16.7ms    223.1ms     44.1ms
 1024     43.5ms     18.2ms     23.9ms    347.1ms     68.8ms"><pre><code>    n       faer  faer(par)    ndarray   nalgebra      eigen
    4      795ns      7.5µs      534ns       77ns      381ns
    8      2.2µs      8.9µs      995ns      825ns      794ns
   16      5.3µs       12µs      2.9µs        4µs      2.7µs
   32     15.2µs     29.9µs     10.3µs       19µs     10.8µs
   64     49.8µs     66.2µs     40.5µs    101.2µs     45.9µs
   96    127.1µs    122.7µs    182.1µs    285.3µs    119.2µs
  128    199.9µs    172.7µs    314.9µs    661.3µs      341µs
  192      543µs    419.8µs    587.1µs      2.2ms    963.8µs
  256        1ms    668.3µs      1.1ms      5.6ms        2ms
  384      2.9ms      1.4ms      2.4ms     18.7ms      5.1ms
  512      6.2ms      2.6ms      4.6ms     44.2ms     11.9ms
  640     11.5ms      5.5ms      7.2ms       83ms     19.2ms
  768     19.2ms      8.7ms     11.2ms    142.3ms     30.9ms
  896     29.5ms     12.9ms     16.7ms    223.1ms     44.1ms
 1024     43.5ms     18.2ms     23.9ms    347.1ms     68.8ms
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Square matrix singular value decomposition</h2><a id="user-content-square-matrix-singular-value-decomposition" aria-label="Permalink: Square matrix singular value decomposition" href="#square-matrix-singular-value-decomposition"></a></p>
<p dir="auto">Computing the SVD of a square matrix with dimension <code>n</code>.</p>
<div data-snippet-clipboard-copy-content="    n       faer  faer(par)    ndarray   nalgebra      eigen
    4        2µs      1.9µs        3µs      1.3µs      1.8µs
    8      9.7µs     24.4µs      8.2µs      3.9µs      9.1µs
   16       32µs     57.8µs     25.9µs     16.9µs     49.8µs
   32      107µs    132.1µs     90.3µs     95.9µs      222µs
   64    409.1µs    381.5µs    562.5µs      555µs    987.6µs
   96    903.9µs    913.1µs      1.7ms      1.7ms      2.7ms
  128      1.6ms      1.5ms      2.9ms      4.6ms      4.3ms
  192        4ms        4ms      6.7ms     14.8ms      9.9ms
  256      7.8ms        7ms     11.7ms     47.4ms     17.3ms
  384     20.9ms     15.1ms     25.8ms    121.1ms     42.9ms
  512     45.3ms     28.1ms       52ms    472.1ms     83.9ms
  640       80ms     44.5ms     79.1ms    665.7ms    133.8ms
  768    130.9ms     78.5ms    123.9ms      1.48s    208.9ms
  896    198.4ms    110.9ms    182.8ms      2.11s    295.4ms
 1024    297.8ms      152ms    253.8ms      3.95s    433.6ms"><pre><code>    n       faer  faer(par)    ndarray   nalgebra      eigen
    4        2µs      1.9µs        3µs      1.3µs      1.8µs
    8      9.7µs     24.4µs      8.2µs      3.9µs      9.1µs
   16       32µs     57.8µs     25.9µs     16.9µs     49.8µs
   32      107µs    132.1µs     90.3µs     95.9µs      222µs
   64    409.1µs    381.5µs    562.5µs      555µs    987.6µs
   96    903.9µs    913.1µs      1.7ms      1.7ms      2.7ms
  128      1.6ms      1.5ms      2.9ms      4.6ms      4.3ms
  192        4ms        4ms      6.7ms     14.8ms      9.9ms
  256      7.8ms        7ms     11.7ms     47.4ms     17.3ms
  384     20.9ms     15.1ms     25.8ms    121.1ms     42.9ms
  512     45.3ms     28.1ms       52ms    472.1ms     83.9ms
  640       80ms     44.5ms     79.1ms    665.7ms    133.8ms
  768    130.9ms     78.5ms    123.9ms      1.48s    208.9ms
  896    198.4ms    110.9ms    182.8ms      2.11s    295.4ms
 1024    297.8ms      152ms    253.8ms      3.95s    433.6ms
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Thin matrix singular value decomposition</h2><a id="user-content-thin-matrix-singular-value-decomposition" aria-label="Permalink: Thin matrix singular value decomposition" href="#thin-matrix-singular-value-decomposition"></a></p>
<p dir="auto">Computing the SVD of a rectangular matrix with shape <code>(4096, n)</code>.</p>
<div data-snippet-clipboard-copy-content="    n       faer  faer(par)    ndarray   nalgebra      eigen
    4     73.4µs     73.5µs      311µs    127.5µs     76.7µs
    8    170.8µs    180.7µs    813.8µs    364.3µs    302.3µs
   16    440.4µs      513µs      2.1ms      1.4ms    775.5µs
   32      1.2ms      1.2ms      5.3ms      5.2ms      3.1ms
   64      3.4ms      3.2ms     15.7ms     19.9ms        8ms
   96      6.8ms      5.4ms     30.1ms     44.5ms     17.2ms
  128     11.2ms      8.3ms     47.4ms     79.4ms     30.9ms
  192     23.6ms     16.1ms       63ms    182.2ms     60.7ms
  256     40.7ms     25.5ms       84ms    353.1ms    101.3ms
  384     90.7ms     48.3ms      133ms    904.4ms    219.7ms
  512    164.7ms     80.2ms    303.4ms      2.02s    400.7ms
  640    258.7ms    119.7ms      289ms      3.24s    646.8ms
  768    381.7ms      187ms    440.1ms      5.15s      952ms
  896    532.6ms    252.7ms    550.2ms      7.23s      1.33s
 1024    724.4ms      327ms    849.6ms     10.64s      1.75s"><pre><code>    n       faer  faer(par)    ndarray   nalgebra      eigen
    4     73.4µs     73.5µs      311µs    127.5µs     76.7µs
    8    170.8µs    180.7µs    813.8µs    364.3µs    302.3µs
   16    440.4µs      513µs      2.1ms      1.4ms    775.5µs
   32      1.2ms      1.2ms      5.3ms      5.2ms      3.1ms
   64      3.4ms      3.2ms     15.7ms     19.9ms        8ms
   96      6.8ms      5.4ms     30.1ms     44.5ms     17.2ms
  128     11.2ms      8.3ms     47.4ms     79.4ms     30.9ms
  192     23.6ms     16.1ms       63ms    182.2ms     60.7ms
  256     40.7ms     25.5ms       84ms    353.1ms    101.3ms
  384     90.7ms     48.3ms      133ms    904.4ms    219.7ms
  512    164.7ms     80.2ms    303.4ms      2.02s    400.7ms
  640    258.7ms    119.7ms      289ms      3.24s    646.8ms
  768    381.7ms      187ms    440.1ms      5.15s      952ms
  896    532.6ms    252.7ms    550.2ms      7.23s      1.33s
 1024    724.4ms      327ms    849.6ms     10.64s      1.75s
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Hermitian matrix eigenvalue decomposition</h2><a id="user-content-hermitian-matrix-eigenvalue-decomposition" aria-label="Permalink: Hermitian matrix eigenvalue decomposition" href="#hermitian-matrix-eigenvalue-decomposition"></a></p>
<p dir="auto">Computing the EVD of a Hermitian matrix with shape <code>(n, n)</code>.</p>
<div data-snippet-clipboard-copy-content="    n       faer  faer(par)    ndarray   nalgebra      eigen
    4      1.3µs      1.3µs      1.4µs      675ns        1µs
    8      3.9µs        4µs      6.6µs      2.3µs      3.4µs
   16     13.2µs     13.6µs     25.9µs     10.3µs     12.5µs
   32     50.9µs     51.1µs    167.1µs     50.8µs     49.7µs
   64    223.9µs    217.5µs      1.2ms    293.9µs    211.2µs
   96      519µs    518.2µs      2.6ms      876µs      518µs
  128    931.7µs    885.5µs      5.4ms      1.9ms      1.1ms
  192      2.2ms      2.1ms       16ms      5.8ms      3.1ms
  256      4.1ms      3.5ms     33.9ms     13.2ms      6.6ms
  384     10.5ms      8.8ms    105.5ms     42.7ms     21.2ms
  512     21.9ms     16.5ms      175ms     99.3ms     51.4ms
  640     37.6ms     26.5ms    266.2ms    187.4ms     94.2ms
  768     60.4ms     38.1ms    403.3ms    322.6ms    161.9ms
  896     90.4ms     52.2ms    615.3ms    502.5ms    249.9ms
 1024    132.1ms     68.4ms      909ms    764.1ms      392ms"><pre><code>    n       faer  faer(par)    ndarray   nalgebra      eigen
    4      1.3µs      1.3µs      1.4µs      675ns        1µs
    8      3.9µs        4µs      6.6µs      2.3µs      3.4µs
   16     13.2µs     13.6µs     25.9µs     10.3µs     12.5µs
   32     50.9µs     51.1µs    167.1µs     50.8µs     49.7µs
   64    223.9µs    217.5µs      1.2ms    293.9µs    211.2µs
   96      519µs    518.2µs      2.6ms      876µs      518µs
  128    931.7µs    885.5µs      5.4ms      1.9ms      1.1ms
  192      2.2ms      2.1ms       16ms      5.8ms      3.1ms
  256      4.1ms      3.5ms     33.9ms     13.2ms      6.6ms
  384     10.5ms      8.8ms    105.5ms     42.7ms     21.2ms
  512     21.9ms     16.5ms      175ms     99.3ms     51.4ms
  640     37.6ms     26.5ms    266.2ms    187.4ms     94.2ms
  768     60.4ms     38.1ms    403.3ms    322.6ms    161.9ms
  896     90.4ms     52.2ms    615.3ms    502.5ms    249.9ms
 1024    132.1ms     68.4ms      909ms    764.1ms      392ms
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Non Hermitian matrix eigenvalue decomposition</h2><a id="user-content-non-hermitian-matrix-eigenvalue-decomposition" aria-label="Permalink: Non Hermitian matrix eigenvalue decomposition" href="#non-hermitian-matrix-eigenvalue-decomposition"></a></p>
<p dir="auto">Computing the EVD of a matrix with shape <code>(n, n)</code>.</p>
<div data-snippet-clipboard-copy-content="    n       faer  faer(par)    ndarray   nalgebra      eigen
    4      4.8µs      5.1µs      3.5µs          -      3.1µs
    8     15.6µs     16.7µs      9.6µs          -     10.5µs
   16     54.7µs     54.4µs     35.9µs          -     44.4µs
   32    270.7µs    235.6µs    172.6µs          -    199.3µs
   64      1.1ms      1.1ms        1ms          -      1.1ms
   96      2.7ms      2.9ms      5.5ms          -      3.1ms
  128      4.9ms      5.6ms     11.6ms          -      9.2ms
  192     14.4ms     14.3ms     22.4ms          -     26.9ms
  256     24.4ms     26.2ms     49.9ms          -     86.6ms
  384     56.4ms     62.6ms      107ms          -    246.1ms
  512    126.8ms    130.1ms    281.7ms          -    887.6ms
  640    205.8ms    192.6ms    415.6ms          -       1.2s
  768    323.5ms    285.6ms    547.2ms          -      2.84s
  896    438.1ms    375.8ms    704.3ms          -      3.67s
 1024    687.8ms    579.3ms    957.1ms          -         7s"><pre><code>    n       faer  faer(par)    ndarray   nalgebra      eigen
    4      4.8µs      5.1µs      3.5µs          -      3.1µs
    8     15.6µs     16.7µs      9.6µs          -     10.5µs
   16     54.7µs     54.4µs     35.9µs          -     44.4µs
   32    270.7µs    235.6µs    172.6µs          -    199.3µs
   64      1.1ms      1.1ms        1ms          -      1.1ms
   96      2.7ms      2.9ms      5.5ms          -      3.1ms
  128      4.9ms      5.6ms     11.6ms          -      9.2ms
  192     14.4ms     14.3ms     22.4ms          -     26.9ms
  256     24.4ms     26.2ms     49.9ms          -     86.6ms
  384     56.4ms     62.6ms      107ms          -    246.1ms
  512    126.8ms    130.1ms    281.7ms          -    887.6ms
  640    205.8ms    192.6ms    415.6ms          -       1.2s
  768    323.5ms    285.6ms    547.2ms          -      2.84s
  896    438.1ms    375.8ms    704.3ms          -      3.67s
 1024    687.8ms    579.3ms    957.1ms          -         7s
</code></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google delays third-party cookie demise yet again (150 pts)]]></title>
            <link>https://digiday.com/marketing/google-delays-third-party-cookie-demise-yet-again/</link>
            <guid>40143242</guid>
            <pubDate>Wed, 24 Apr 2024 11:51:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://digiday.com/marketing/google-delays-third-party-cookie-demise-yet-again/">https://digiday.com/marketing/google-delays-third-party-cookie-demise-yet-again/</a>, See on <a href="https://news.ycombinator.com/item?id=40143242">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-wrapper">
	
<div>
				<div><p> &nbsp;•&nbsp; <span>April 23, 2024&nbsp;&nbsp;•&nbsp;&nbsp;4 min read</span> &nbsp;•</p>








</div>
        <div>
            <p><img width="1030" height="579" src="https://digiday.com/wp-content/uploads/sites/3/2024/03/cookie-sunset-digiday.gif?w=1030&amp;h=579&amp;crop=1" alt="" decoding="async" fetchpriority="high"></p><p>
                        Ivy Liu                    </p>
                            </div>
    </div>
	<div>
				
<p>Google is delaying the end of third-party cookies in its Chrome browser —&nbsp;again. In other unsurprising developments, water remains wet.</p>



<p>The announcement <a href="https://privacysandbox.com/intl/en_us/news/update-on-the-plan-for-phase-out-of-third-party-cookies-on-chrome/">was made on Tuesday</a> ahead of quarterly reports from Google and the ever-watchful U.K. Competition and Markets Authority (CMA), keeping tabs on how this whole situation unfolds.</p>
<div id="piano-meter-offer">


<p>“We recognize that there are ongoing challenges related to reconciling divergent feedback from the industry, regulators and developers, and will continue to engage closely with the entire ecosystem,” according to a statement Google posted on its website for the Privacy Sandbox. “It’s also critical that the CMA has sufficient time to review all evidence including results from industry tests, which the CMA has asked market participants to provide by the end of June. Given both of these significant considerations, we will not complete third-party cookie deprecation during the second half of Q4.”</p>








<p>Google did not outline a more specific timetable beyond hoping for 2025.&nbsp;</p>





<p>This is the third time Google has pushed back its original deadline set in January 2020. Back then, the tech behemoth promised to phase out third-party cookies “within two years” to beef up security for users while surfing the web. But since then, Google’s hit the brakes twice already. And every time, it’s been to give the ad industry more prep time for something that’s been surrounded by a lot of ifs, buts, and maybes. Even at the start of the year, <a href="https://digiday.com/media/four-months-in-heres-the-rundown-of-googles-chrome-cookie-conundrum-so-far/">as Google phased out</a> cookies for one percent of browser traffic, questions loomed over when more significant changes would occur.</p>



<p>With this track record, Google’s latest delay won’t shock many. And even those caught off guard might get a pass. After all, Google had been <a href="https://digiday.com/podcasts/googles-2024-cookie-deprecation-deadline-is-still-on-says-vp-of-global-advertising-dan-taylor/">preaching for months</a> that third-party cookies would vanish from Chrome by the end of 2024.</p>



<p>Despite their assurances, hitting the deadline seemed increasingly unlikely. Especially after the CMA raised 39 “concerns” to be addressed before the plan could proceed back in January. And with the U.K. data watchdog, the Information Commissioner’s Office (ICO), voicing its own reservations earlier this month, the plot thickened. Toss in the fact that Google’s own alternatives to third-party cookies (aforementioned Sandbox) left a lot to be desired, and another delay seemed inevitable.</p>





<p>“We welcome Google’s announcement clarifying the timing of third-party cookie deprecation. This will allow time to assess the results of industry tests and resolve remaining issues,” said a spokesperson from the CMA. “Under the commitments, Google has agreed to resolve our remaining competition concerns before going ahead with third-party cookie deprecation. Working closely with the ICO we expect to conclude this process by the end of 2024.”</p>



<p>For now, Google seems to have next year in mind as the latest end date for its plan to eliminate third-party cookies. </p>



<p>“We remain committed to engaging closely with the CMA and ICO and we hope to conclude that process this year,” Google’s statement read. “Assuming we can reach an agreement, we envision proceeding with third-party cookie deprecation starting early next year.”</p>



<p>Needless to say, the ad industry isn’t holding its breath.</p>



<p>That was certainly true of the&nbsp;46&nbsp;marketers who responded to the latest survey for <a href="https://digiday.com/series/research/">Digiday+ Research</a>, which asked them for their thoughts on the third-party cookie timeline. Of those who responded, 39% said they believe it&nbsp;would&nbsp;be at some point in Q2 2025 or beyond while 26% said they&nbsp;believed&nbsp;Google will get rid of third-party cookies in the Chrome browser before the end of the year.</p>



<p>“It’s unsurprising news given the magnitude of what is happening and the involvement of the CMA, but ultimately still frustrating,” said Wayne Blodwell, founder and CEO of Impact Media, an AI powered attention platform. “However, smart measurement is comfortably the largest way advertisers can create competitive advantage by leaning into durable/non cookie methods such as attention, MMM and econometrics and connecting that to media buying so it really shouldn’t slow down the sophisticated &amp; progressive advertisers anyway.”</p>
</div>		<div>
				








				<p>https://digiday.com/?p=542257</p>
		</div>
				</div><!-- .article-columns-wrapper -->

        <div id="latest_stories">
                                        <h3>
                            <span>More in Marketing</span>
                        </h3>
                                                    
                                    </div>

    <!--
    <div class="top-stories-module">
        <div class="container">
            <div class="module-title">Digiday Top Stories</div>
			        </div>
    </div>
    -->

    

	<!-- Div to serve Piano -->
	
</div></div>]]></description>
        </item>
    </channel>
</rss>