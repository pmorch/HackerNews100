(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 06 Apr 2025 00:30:13 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Ten Rules for Negotiating a Job Offer (101 pts)]]></title>
            <link>https://haseebq.com/my-ten-rules-for-negotiating-a-job-offer/</link>
            <guid>43596864</guid>
            <pubDate>Sat, 05 Apr 2025 21:15:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://haseebq.com/my-ten-rules-for-negotiating-a-job-offer/">https://haseebq.com/my-ten-rules-for-negotiating-a-job-offer/</a>, See on <a href="https://news.ycombinator.com/item?id=43596864">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    <p>When <a href="https://haseebq.com/farewell-app-academy-hello-airbnb-part-i/">the story of how I landed a job at Airbnb</a> went viral, I was surprised at how infatuated people were with my negotiations. Media stories portrayed me as some kind of master negotiator—a wily ex-poker-player who was able to con the tech giants into a lucrative job offer.</p>

<p>This is silly. It’s silly for a lot of reasons, but one of the main ones is that in reality, my negotiation skills are nothing special. There are lots of job candidates who are better negotiators than I, to speak nothing of recruiters and other professional negotiators.</p>

<p>It just so happens that most people don’t negotiate at all, or if they do, they just negotiate just enough to satisfy themselves that they did.</p>

<p>Worse yet, most of the advice out there on negotiation is borderline useless. Almost anything you read on the subject will be a vague and long-winded exhortation to “make sure you negotiate” and “never say the first number.” Beyond those two morsels of advice, you’re pretty much on your own.</p>

<p>I thought to myself: why is there so little actionable advice out there about negotiation? I suspect it’s because deep down, many people believe that negotiation is inexplicable, that it’s something some people can do and others can’t, and that there’s no real way to break it down so anyone can learn it.</p>

<p>I say that’s bullshit. Negotiation is a skill that can be learned just like any other, and I don’t believe it’s particularly elusive or hard to understand. So I’m going to try to explain how anyone can do it.</p>

<p>Three caveats.</p>

<p>First: I’m not an expert. There are people who really are experts at this, and when my advice contradicts theirs, you should assume I’m wrong.</p>

<p>Second: negotiation is tricky to generalize about because it’s deeply intertwined with social dynamics and power. The appropriate advice for an Asian male in Silicon Valley may not be appropriate for a black woman in Birmingham, Alabama. Racial, sexual, and political dynamics accompany you to the negotiating table.</p>

<p>At the same time, I want to caution against overemphasizing these factors. Being afraid to negotiate out of fear of discrimination can often be just as deleterious as discrimination itself.</p>

<p>Ceteris paribus, negotiate aggressively.</p>

<p>Third: I’m the first to admit that negotiation is stupid. It’s a practice that inherently benefits those who are good at it, and is an absurd axis on which to reward people. But it’s a reality of our economic system. And like most collective action problems, we’re probably not going to be able to abolish it any time soon. In which case, you might as well improve at it.</p>

<p>So here’s my guide to negotiation. It’s going to be split into two parts: this first part will be about conceptualizing the negotiating process, about how to begin the process and set yourself up for maximal success. The second part will be advice on the actual back-and-forth portion of negotiating and how to ask for what you want.</p>

<p>Let’s take it from the top.</p>

<h2 id="what-it-means-to-get-a-job">What it means to “get a job”</h2>

<p>In our culture we call entering the employment market “trying to get a job.” This is an unfortunate turn of phrase. “Getting a job” implies that jobs are a resource out in the world, and you’re attempting to secure one of these resources. But that’s completely backwards. What you are actually doing is selling your labor, and a company is bidding for it.</p>

<p><strong>Employment is just striking a mutual deal in the labor market.</strong></p>

<p>Like any market, the labor market only functions well if it’s competitive. This is the only way to ensure fair and equitable pricing. Imagine you were a farmer selling watermelons. Would you just sell your watermelons to the first buyer who agreed to purchase them? Or would you survey the marketplace of buyers, see the best price (and business partner) you could get, and then make an informed decision on which buyer to sell to?</p>

<p>And yet, when people talk about the labor market, they think “oh, a company wants to <em>give me a job</em>! What a relief!” As though having a job were in itself some special privilege for which a company is the gatekeeper.</p>

<p>Dispel yourself of this mindset.</p>

<p>A job is just a deal. It is a deal between you and a company to exchange labor for money (and other things you value).</p>

<p>This might sound like an abstract point, but you should absolutely approach negotiation from this perspective.</p>

<h2 id="the-role-of-negotiation">The role of negotiation</h2>

<p>Negotiating is a natural and expected part of the process of trying to make a deal. It’s also a signal of competence and seriousness. Companies generally respect candidates who negotiate, and most highly attractive candidates negotiate (if for no other reason, because they often have too many options to choose from).</p>

<p>At the risk of spouting truisms: always, always negotiate. Doesn’t matter how good or bad you think you are. You never damage a relationship by negotiating.</p>

<p>In all my time as an instructor at App Academy, out of hundreds of offers negotiated, only once or twice were offers ever rescinded in negotiations. It basically never happens. And when it does, usually the candidate was being an unconscionable asshole, or the company was imploding and needed an excuse to rescind the offer.</p>

<p>You might think to yourself: “<em>well, I don’t want to set high expectations, and the offer is already generous, so I ought to just take it.</em>“</p>

<p><strong>No. Negotiate.</strong></p>

<p>Or maybe: “<em>I don’t want to start off on the wrong foot and look greedy with my future employer.</em>“</p>

<p><strong>No. Negotiate.</strong></p>

<p>“<em>But this company is small and—</em>“</p>

<p><strong>No. Shut up. Negotiate.</strong></p>

<p>We’ll talk more in the next section about why a lot of these objections are bullshit, and fundamentally misapprehend the dynamics of hiring. But for now, just trust me that you should always negotiate.</p>



<p>I’ve tried to boil down negotiation to ten rules. The rules, in order of appearance, are:</p>

<ol>
  <li>Get everything in writing</li>
  <li>Always keep the door open</li>
  <li>Information is power</li>
  <li>Always be positive</li>
  <li>Don’t be the decision maker</li>
  <li>Have alternatives</li>
  <li>Proclaim reasons for everything</li>
  <li>Be motivated by more than just money</li>
  <li>Understand what they value</li>
  <li>Be winnable</li>
</ol>

<p>We’ll only get through some of these in this blog post, and the rest will appear in the second part. But I’ll explain each rule as we get to it.</p>

<p>So let’s start from the top and try to walk through a negotiation process from the very beginning. For most, that starts when you receive an offer.</p>

<h2 id="the-offer-conversation">The offer conversation</h2>

<p>You’ve just received the phone call: your interview went well, and after much deliberation they decided they like you. They want to make you an offer. Congratulations!</p>

<p>Don’t get too excited though. The fun is just getting started.</p>

<p>Thank your recruiter. Sound excited—hopefully this won’t be hard. Before jumping into details, try to ask for specific feedback on your interview performance. If they give it to you, this will help you gauge how much they want you, as well as tell you things you can improve on in your next interview(s).</p>

<p>Now time to explore the offer.</p>

<p><strong>Rule #1 of negotiating: have everything in writing.</strong></p>

<p>Eventually, they’ll give you information about the offer. Write it all down. Doesn’t matter if they’re going to send you a written version later, <strong>write everything down</strong>. Even if there are things that are not directly monetary, if they relate to the job, write them down. If they tell you “we’re working on porting the front-end to Angular,” write that down. If they say they have 20 employees, write that down. You want as much information as you can. You’ll forget a lot of this stuff, and it’s going to be important in informing your final decision.</p>

<p>Depending on the company, they’ll also tell you about the equity package. We’ll look more specifically at equity in part II, but be sure to write everything down.</p>

<p>The rule from here on out is that everything significant you discuss will have some kind of a paper trail. Often, the company won’t even send you an official offer letter until a deal is finalized. So it falls to you to confirm all of the important details in subsequent e-mails.</p>

<p>So yadda yadda, lots of details, writing stuff down, oh there’s a joke, time to laugh. Now the recruiter is done talking and you’re done asking all of your questions.</p>

<p>Your recruiter will now say something along the lines of “<em>so what do you think?</em>“</p>

<p>This seems innocuous, but your reply here is critical, because there’s a lot you can say to weaken your position. This is your first decision point.</p>

<p>A decision point is a moment in the negotiation where your interlocutor wants to compel you to make a decision. If they succeed in tying you to a position, they will close the door on further negotiating. Of course “what do you think?” is a subtle prod. But it is the beginning of many attempts to get you to make a premature commitment.</p>

<p><strong>This leads to rule #2 of negotiating: always keep the door open.</strong> Never give up your negotiating power until you’re absolutely ready to make an informed, deliberate final decision.</p>

<p>This means your job is to traverse as many of these decision points as possible without giving up the power to continue negotiating. Very frequently, your interlocutor will try to trick you into making a decision, or tie you to a decision you didn’t commit to. You must keep verbally jiu-jitsu-ing out of these antics until you’re actually ready to make your final decision.</p>

<h2 id="protecting-information">Protecting information</h2>

<p>There’s an uncomfortable silence by now, and their “<em>what do you think?</em>” is hanging in the air.</p>

<p>If you say “<em>yes, that sounds amazing, when do I start?</em>” you implicitly accept the offer and completely close the door on the negotiation. This is your recruiter’s number one favorite thing to hear. It stands to reason you probably shouldn’t do this.</p>

<p>But their second favorite thing to hear you say is “<em>can you do 90K instead of 85K?</em>” This also closes the door, but for a different and more subtle reason. And it’s the number one reason why most people suck at negotiation.</p>

<p><strong>Rule #3 of negotiating: information is power.</strong> To protect your power in the negotiation, you must protect information as much as possible.</p>

<p>A company doesn’t give you insight into what it’s thinking. It doesn’t tell you its price range, how much it paid the previous candidate with your experience, or anything like that. It intentionally obfuscates those things. But it wants you not to do the same.</p>

<p>A company wants to be like a bidder in a secret auction. But unlike the other bidders, it wants to know exactly how high all of the other bids are. It then openly intends to exploit that knowledge, often by bidding one cent more than the second highest bid.</p>

<p>Yeah, no. Screw that. It’s a silent auction, and to keep it that way, you must protect information.</p>

<p>In many situations, the only reason why you have any negotiating power at all is because the employer doesn’t actually know what you’re thinking. They might not know how good your other offers are, or how much you were making in your last job, or how you weigh salary vs equity, or even how rational you are as a decision-maker. Bottom line, you want them to be uncertain on exactly what it would take to sign you.</p>

<p>When you say “<em>can you do 90K instead of 85K,</em>” you’ve told them exactly what it will take to make you sign. The sheet’s pulled back, the secret auction is up, and they’re going to bid 90K (or more likely, 87K). And they know there’s almost no risk in doing so, because you’ll probably accept.</p>

<p>What if you were the kind of person who wouldn’t even consider an offer below 110K? Or the kind of person who wouldn’t consider an offer below 120K? If you were, you wouldn’t ask for 90K, and if they offered it as conciliation, you’d tell them to stop wasting your time.</p>

<p>By staying silent, <em>they don’t actually know which of those kinds of people you are.</em> In their mind, you could be any of the three.</p>

<p>A corollary of this rule is that you should not reveal to companies what you’re currently making. There are some exceptions, but as a rule you should assume this. If you must divulge what you’re making, you should be liberal in noting the total value of your package (incorporate bonuses, unvested stock, nearness to promotion etc.), and always mention it in a context like “<em>[XYZ] is what I’m currently making, and I’m definitely looking for a step up in my career for my next role.</em>“</p>

<p>Companies will ask about your current compensation at different stages in the process—some before they ever interview you, some after they decide to make you an offer. But be mindful of this, and protect information.</p>

<p>So given this offer, don’t ask for more money or equity or anything of the sort. Don’t comment on any specific details of the offer except to clarify them.</p>

<p>Give away nothing. Retain your power.</p>

<p>Say instead: “<em>Yeah, [COMPANY_NAME] sounds great! I really thought this was a good fit, and I’m glad that you guys agree. Right now I’m talking with a few other companies so I can’t speak to the specific details of the offer until I’m done with the process and get closer to making a decision. But I’m sure we’ll be able to find a package that we’re both happy with, because I really would love to be a part of the team.</em>“</p>

<p>Think like the watermelon farmer. This offer is just is the first businessman who’s stopped by your watermelon patch, glanced over your crops, and announced “I’ll take all of these right now for $2 a melon.”</p>

<p>Cool. It’s a big market, and you’re patient—you’re a farmer after all. Just smile and tell them you’ll keep their offer in mind.</p>

<p>And this is super important: always be unequivocally positive.</p>

<h2 id="the-importance-of-positivity">The importance of positivity</h2>

<p><strong>Staying positive is rule #4 of negotiation</strong>. Even if the offer is shit, it’s extremely important to remain positive and excited about the company. This is because <em>your excitement is one of your most valuable assets in a negotiation.</em></p>

<p>A company is making you an offer because they think you’ll do hard work for them if they pay you. If you lose your excitement for the company during the interview process, then they’ll lose confidence that you’ll actually want to work hard or stay there for a long time. Each of those makes you less attractive as an investment. Remember, you are the product! If you become less excited, then the product you’re selling actually loses value.</p>

<p>Imagine you were negotiating with someone over buying your watermelons, but the negotiation took so long that by the time you’d reached an agreement, your watermelons had gone bad.</p>

<p>Companies are terrified of that. They don’t want their candidates to go bad during a negotiation. Hence why they hire professional recruiters to manage the process and make sure they remain amicable. You and the recruiter share the same interest in that regard. If a company feels like you’ve gone bad, suddenly they’re a lot less willing to pay for you.</p>

<p>So despite whatever is happening in the negotiation, give the company the impression that 1) you still like the company, and that 2) you’re still excited to work there, even if the numbers or the money or the timing is not working out. Generally the most convincing thing to signal this is to reiterate you love the mission, the team, or the problem they’re working on, and really want to see things work out.</p>

<h2 id="dont-be-the-decision-maker">Don’t be the decision-maker</h2>

<p>You can wrap up the conversation now by saying:</p>

<blockquote>
  <p>I’ll look over some of these details and discuss it with my [FAMILY/CLOSE_FRIENDS/SIGNIFICANT_OTHER]. I’ll reach out to you if I have any questions. Thanks so much for sharing the good news with me, and I’ll be in touch!</p>
</blockquote>

<p>So not only are you ending the conversation with the power all in your hands, but note there’s another important move here: you’re roping in other decision-makers.</p>

<p><strong>Rule #5 of negotiation: don’t be the decision-maker.</strong> Even if you don’t particularly care what your friends/family/husband/mother thinks, by mentioning them, you’re no longer the only person the recruiter needs to win over. There’s no point in them trying to bully and intimidate you; the “true decision-maker” is beyond their reach.</p>

<p>This is a classic technique in customer support and remediation. It’s never the person on the phone’s fault, they’re just some poor schmuck doing their job. It’s not their decision to make. This helps to defuse tension and give them more control of the situation.</p>

<p>It’s much harder to pressure someone if they’re not the final decision-maker. So take advantage of that.</p>

<p>Okay!</p>

<p>We have our first offer. Send a follow-up e-mail confirming all of the details you discussed with your recruiter so you have a paper trail. Just say “<em>just wanted to confirm I had all the details right.</em>“</p>

<p>Groovy. Next step is to leverage this to land other offers and find the best deal we can find in the job market.</p>

<h2 id="getting-other-offers">Getting other offers</h2>

<p>Turns out, it doesn’t matter that much where your first offer is from, or even how much they’re offering you. Just having an offer in hand will get the engine running.</p>

<p>If you’re already in the pipeline with other companies (which you should be if you’re doing it right), you should proactively reach out and let them know that you’ve just received an offer. Try to build a sense of urgency. Regardless of whether you know the expiration date, all offers expire at some point, so take advantage of that.</p>

<blockquote>
  <p>Hello [PERSON],</p>

  <p>I just wanted to update you on my own process. I’ve just received an offer from [COMPANY] which is quite strong. That said, I’m really excited about [YOUR AMAZING COMPANY] and really want to see if we can make it work. Since my timeline is now compressed, is there anything you can do to expedite the process?</p>
</blockquote>

<p>Should you specifically mention the company that gave you an offer? Depends. If it’s a well-known company or a competitor, then definitely mention it. If it’s a no-name or unsexy company, you should just say you received an offer. If it’s expiring soon, you should mention that as well.</p>

<p>Either way, send out a letter like this to every single company you’re talking to. No matter how hopeless or pointless you think your application is, you want to send this signal to everyone who is considering you in the market.</p>

<p>Second, if there are any other companies you are looking to apply to (whether through referral or cold application), or even companies at which you’ve already applied but haven’t heard back, I would also follow up with a similar e-mail.</p>

<p>So why do this? Isn’t this tacky, annoying, or even desperate?</p>

<p>None of the above. It is the oldest method in history to galvanize a marketplace—show that supplies are limited and build urgency. Demand breeds demand. Not every company will respond to this, but many will.</p>

<p>Isn’t it stupid that companies respond to this though?</p>

<h2 id="why-companies-care-about-other-offers">Why companies care about other offers</h2>

<p><a href="https://haseebq.com/farewell-app-academy-hello-airbnb-part-i/">When I wrote about the story of my own job search</a>, I mentioned how having an offer from Google made companies turn around and expedite me through their funnels. Many commentators lamented at the capriciousness of these companies. If Uber or Twitch only talked to me because of Google and until then weren’t willing to look at me, what did that say about their hiring processes? What legitimately are they evaluating, if anything at all?</p>

<p>I think this response is totally backwards. The behavior of tech companies here is actually very rational, and you would do well to understand it.</p>

<p>First, you must realize what a company’s goal is. A company’s goal is to hire someone who will become an effective employee and produce more value than their cost. How do you figure out who will do that? Well, you can’t know for certain without actually hiring them, but there are a few proxies. Pedigree is the strongest signal; if they did it at other companies, they can probably do it at yours. And if someone trusted within the organization can vouch for them, that’s often a strong signal as well.</p>

<p>But turns out, almost everything else is a weak signal. Weak in the sense that it’s just not very reliable. Interviews, if you think about it, are long, sweaty, uncomfortable affairs that only glancingly resemble actual employment. They’re weird and can’t tell you that much about whether an individual will be a good at their job. There’s no way around this. There are a few stronger signals, like bringing someone in for a week or two on a contract-to-hire position, but strong candidates won’t consider this. So candidates as a whole have effectively forced companies to assume almost all of the risk in hiring.</p>

<p>The truth is, knowing that someone has passed your interview just doesn’t say <em>that much</em> about whether they’ll be a good employee. It’s as though you knew nothing about a student other than their SAT score. It’s just not a lot of data to go off.</p>

<p>Nobody has solved this problem. Not Google nor anyone else.</p>

<p>And this is precisely why it’s rational for companies to care that you’ve received other offers. They care because each company knows that their own process is noisy, and the processes of most other companies are also noisy. But a candidate having multiple offers means that they have multiple weak signals in their favor. Combined, these converge into a much stronger signal than any single interview. It’s like knowing that a student has a strong SAT score, and GPA, and won various scholarships. Sure, it’s still possible that they’re a dunce, but it’s much harder for that to be true.</p>

<p>This is not to say that companies respond proportionally to these signals, or that they don’t overvalue credentials and brands. They do. But caring about whether you have other offers and valuing you accordingly is completely rational.</p>

<p>So this is all to say—tell other companies that you’ve received offers. Give them more signal so that they know you’re a valued and compelling candidate. And understand why this changes their mind about whether to interview you.</p>

<p>As you continue interviewing, remember to keep practicing your interview skills. The single strongest determinant of your final offer will be the number and strength of offers that you receive.</p>

<h2 id="some-advice-on-timing">Some advice on timing</h2>

<p>You want to be strategic about the timing of your offers. Generally, you should try to start interviewing at larger companies earlier. Their processes are slower and their offer windows are wider (meaning they allow you more time to decide). Startups are the other way around.</p>

<p>Your goal should be to have as many offers overlapping at the same time as possible. This will maximize your window for negotiating.</p>

<p>When you receive an offer, often the first thing you should ask for is more time to make your decision. Especially in your first offer, more time is by far the most valuable thing you can ask for. It’s time that enables you to activate other companies and end up with the strongest possible offer. So be prepared to fight for time.</p>

<h2 id="how-to-approach-exploding-offers">How to approach exploding offers</h2>

<p>Hoo boy.</p>

<p>Exploding offers are offers that expire within 24-72 hours. You won’t see this much at big companies, but they’re becoming increasingly common among startups and mid-sized companies.</p>

<p>Exploding offers suck, and I share most people’s disdain for this practice. But I do understand it. Exploding offers are a natural weapon for employers to combat a strong hiring market for tech workers. Companies know exactly what they’re doing with exploding offers—they play on fear and limit your ability to seek out counteroffers.</p>

<p>In a sense, it’s unsurprising that if startups have more difficulty attracting and securing talent, they’d resort to this practice. What I don’t like is the dishonesty about it. Employers often justify this by saying “<em>If you need more time than this, then that’s a sign you’re not the kind of person we’re looking for.</em>“</p>

<p>Please don’t buy this crap or feel guilty over it. They’re simply doing this to improve their chance of closing candidates. Needing more than three days to make a life decision isn’t a sign of anything other than thoughtfulness.</p>

<p>So what should you do if you receive an exploding offer?</p>

<p>Exploding offers are anathema to your ability to effectively navigate the labor market. Thus, there is only one thing to do. Treat the offer as a non-offer unless the expiration window is widened.</p>

<p>In no uncertain terms, convey that if the offer is exploding, it’s useless to you.</p>

<p>Example conversation:</p>

<blockquote>
  <p>I have one big concern. You mentioned that this offer explodes in 48 hours. I’m afraid this doesn’t work at all for me. There’s no way that I can make a decision on this offer within a 48 hour window. I’m currently wrapping up my interview process at a few other companies, which is likely to take me another week or so. So I’m going to need more time to make an informed decision.</p>
</blockquote>

<p>If they push back and say this is the best they can do, then politely reply:</p>

<blockquote>
  <p>That’s really unfortunate. I like [YOUR COMPANY] and was really excited about the team, but like I said, there’s no way I can consider this offer. 48 hours just too unreasonable of a window. The next company I join will be a big life decision for me, and I take my commitments very seriously. I also need to consult with my [EXTERNAL_DECISION_MAKER]. There’s no way that I can make a decision I’m comfortable with in this short an amount of time.</p>
</blockquote>

<p>Pretty much any company will relent at this point. If they persist, don’t be afraid to walk away over it. (They probably won’t let that happen, and will come grab you as you’re walking out the door. But if they don’t, then honestly, screw ‘em.)</p>

<p>I was given several exploding offers during my job search. And every time, I did essentially this. Every single offer immediately widened to become more reasonable, sometimes by several weeks.</p>

<p>I want to emphasize, lest I be misunderstood here—what I’m saying is not to just silently let an exploding offer expire, and assume that everything will be fine and they’ll still hire you. They won’t. For exploding offers to be a credible weapon, a company has to have a reputation of enforcing them. I’m saying explicitly call this out as an issue when they make the offer.</p>

<p>Don’t let a company bully you into giving away your negotiating power.</p>

<h2 id="the-negotiating-mindset">The Negotiating Mindset</h2>

<p>Before we enter into the actual back-and-forth, I want to examine the mindset you should have as a negotiator. This applies not just to how you approach the conversation, but also to how you think about the company.</p>

<p>Do not fall into the trap of valuing companies solely along one dimension. That means don’t just value companies based on salary, equity, or even on prestige. Those are all important dimensions, but so are cultural fit, the challenge of the work, learning potential, later career options, quality of life, growth potential, and just overall happiness. None of these inherently trump any of the other. Anyone who tells you “just choose wherever you think you’ll be happiest” is being just as simplistic than someone who says “just choose the one that offers the most money.” All of these things matter, and your decision should be genuinely multi-dimensional.</p>

<p>Be open to being surprised as you explore different companies.</p>

<p>It’s also important to understand that companies don’t all value you along the same dimension either. That is, different companies are genuinely looking for different skills, and there are some companies at which you will be more and less valuable. Even at peer companies this is true, especially so if you have a specialized skill-set.</p>

<p>The more companies you talk to, the more likely you are to find a company to which you are significantly more valuable than the rest. Chances are this is where you’ll be able to negotiate your strongest offer. It might surprise you which company this turns out to be; keep an open mind, and remember that a job search is a 2-sided process.</p>

<p>One of the most valuable things you can do for yourself in this process is to really try to understand how employers think and what motivates them. Understanding your interlocutor is extremely important in negotiation, and we’ll be exploring that a lot in the next blog post.</p>

<p>But most of all I want to emphasize: be curious about the other side. Try to understand why employers think the way they do. Be sympathetic toward them. Care about what they want and help them try to get it. Adopting this mindset will make you a much stronger negotiator, and accordingly, a much better employee and team member.</p>

<p>Okay. That’s as far as we’re going for today. In the next blog post, I’m going to cover the last four rules of negotiation. I’ll also go over the actual back-and-forth process—how to ask for what you want, how to strengthen offers, and how to dismantle the tricks that companies will try to pull on you. Also a lot more on the theory of negotiation, which I really dig.</p>

<p>Do share this post if you found it useful! And <a href="https://twitter.com/intent/follow?original_referer=http%3A%2F%2Fhaseebq.com%2F%3Fp%3D2393%26preview%3Dtrue&amp;ref_src=twsrc%5Etfw&amp;region=follow_link&amp;screen_name=hosseeb&amp;tw_p=followbutton">follow me on Twitter</a>.</p>

<p><a href="https://haseebq.com/how-not-to-bomb-your-offer-negotiation/">You can read part 2 here!</a></p>

<p>Until next time,</p>

    <p>Haseeb</p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Llama 4 Now Live on Groq (101 pts)]]></title>
            <link>https://groq.com/llama-4-now-live-on-groq-build-fast-at-the-lowest-cost-without-compromise/</link>
            <guid>43596470</guid>
            <pubDate>Sat, 05 Apr 2025 20:13:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://groq.com/llama-4-now-live-on-groq-build-fast-at-the-lowest-cost-without-compromise/">https://groq.com/llama-4-now-live-on-groq-build-fast-at-the-lowest-cost-without-compromise/</a>, See on <a href="https://news.ycombinator.com/item?id=43596470">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-id="63e34e6" data-element_type="container" data-elementor-type="wp-post" data-elementor-id="6435" data-elementor-post-type="post" data-widget_type="theme-post-content.default">
				<div data-id="722ca0c" data-element_type="widget" data-widget_type="text-editor.default">
				<p>
									<h4><span>Meta’s Llama 4 Scout and Maverick models are live today on GroqCloud™, giving developers and enterprises day-zero access to the most advanced open-source AI models available.<br></span></h4>								</p>
				</div>
				<div data-id="1ab7589" data-element_type="widget" data-widget_type="text-editor.default">
				<p>Today, Meta released the first models in the Llama 4 herd, which will enable people to build more personalized multimodal experiences. With Llama 4 Scout and Llama 4 Maverick available on GroqCloud today to its free users and paid customers, developers can run cutting-edge multimodal workloads while keeping costs low and latency predictable.</p>
				</div>
				
				<div data-id="345d7c5" data-element_type="widget" data-widget_type="text-editor.default">
				<p>
									<h4><span>Groq Performance &amp; Pricing<br></span></h4>								</p>
				</div>
				<div data-id="3568efc" data-element_type="widget" data-widget_type="text-editor.default">
									<p><span>Our vertically integrated GroqCloud and inference-first architecture deliver unmatched performance and price. With Llama 4 models, developers can run cutting-edge multimodal workloads while keeping costs low and latency predictable.</span></p>
<p><span>Llama 4 Scout is currently running at over 460</span><span>&nbsp;tokens/s</span><span> while Llama 4 Maverick is coming today</span><span>.&nbsp;</span><span>Stay tuned for official 3rd party benchmarks from Artificial Analysis.&nbsp;</span></p>
<p><span>Groq is offering the first of the Llama 4 model herd at the following pricing:</span></p>								</div>
				<div data-id="355d301" data-element_type="widget" data-widget_type="text-editor.default">
									<ul><li aria-level="1"><b>Llama 4 Scout: </b><span>$0.11 / M input tokens and $0.34 / M output tokens</span></li><li aria-level="1"><strong>Llama 4 Maverick:</strong> $0.50 / M input tokens and $0.77 / M output tokens</li></ul>								</div>
				
				<div data-id="1ee4919" data-element_type="widget" data-widget_type="text-editor.default">
				<p>
									<h4><span>About Llama 4 <br></span></h4>								</p>
				</div>
				<div data-id="f519fef" data-element_type="widget" data-widget_type="text-editor.default">
				<p>The new Llama 4 models are Meta’s first models that use a Mixture of Experts (MoE) architecture. In MoE models, a single token activates only a fraction of the total parameters. MoE architectures are more compute efficient for model training and inference and, given a fixed training FLOPs budget, deliver higher quality models compared to dense architectures.<br>Llama 4 models are designed with native multimodality, incorporating early fusion to seamlessly integrate text and vision tokens into a unified model backbone. <br>Meta aims to develop the most helpful, useful models for developers while protecting against and mitigating the most severe risks. This includes integrating mitigations at each layer of model development from pre-training to post training and tunable system-level mitigations that shield developers from adversarial users. In doing so, Meta is helping empower developers to create helpful, safe, and adaptable experiences for their Llama supported applications.</p>
				</div>
				
				<div data-id="e9fc04b" data-element_type="widget" data-widget_type="text-editor.default">
				<p>
									<h4><span>Llama 4 Scout &amp; Maverick<br></span></h4>								</p>
				</div>
				<div data-id="9a49798" data-element_type="widget" data-widget_type="text-editor.default">
									<p><span>These latest Llama models from Meta include smaller and larger options to accommodate a range of use cases and developer needs.</span></p><p><span>Llama 4 Scout is a leading multimodal model and is more powerful than the Llama 3 models. It contains 17 billion active parameters, 16 experts, and 109 billion total parameters; it delivers state-of-the-art performance for its class.&nbsp;</span></p><p><span>Llama 4 Maverick contains 17 billion active parameters, 128 experts, and 400 billion total parameters, offering high quality at a lower price compared to Llama 3.3 70B. It offers unparalleled, industry-leading performance in image and text understanding with support for 12 languages, enabling the creation of sophisticated AI applications that bridge language barriers. As the workhorse model for general assistant and chat use cases, Llama 4 Maverick is great for precise image understanding and creative writing. For developers, it offers state-of-the-art intelligence with high speed, optimized for best response quality on tone, and refusals.</span></p>								</div>
				
				<div data-id="531d7d8" data-element_type="widget" data-widget_type="text-editor.default">
				<p>
									<h4><span>Build Fast with Llama 4 on GroqCloud<br></span></h4>								</p>
				</div>
				
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Llama4 (789 pts)]]></title>
            <link>https://www.llama.com/llama4/</link>
            <guid>43595585</guid>
            <pubDate>Sat, 05 Apr 2025 18:33:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.llama.com/llama4/">https://www.llama.com/llama4/</a>, See on <a href="https://news.ycombinator.com/item?id=43595585">Hacker News</a></p>
Couldn't get https://www.llama.com/llama4/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[What If We Made Advertising Illegal? (678 pts)]]></title>
            <link>https://simone.org/advertising/</link>
            <guid>43595269</guid>
            <pubDate>Sat, 05 Apr 2025 17:57:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simone.org/advertising/">https://simone.org/advertising/</a>, See on <a href="https://news.ycombinator.com/item?id=43595269">Hacker News</a></p>
Couldn't get https://simone.org/advertising/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Exeter's unassuming co-op worker leads double life as 'Lord of the Logos' (102 pts)]]></title>
            <link>https://www.devonlive.com/whats-on/whats-on-news/exeters-unassuming-co-op-worker-10039941</link>
            <guid>43594396</guid>
            <pubDate>Sat, 05 Apr 2025 15:54:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.devonlive.com/whats-on/whats-on-news/exeters-unassuming-co-op-worker-10039941">https://www.devonlive.com/whats-on/whats-on-news/exeters-unassuming-co-op-worker-10039941</a>, See on <a href="https://news.ycombinator.com/item?id=43594396">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody"><!-- Article Start--><p>The famous saying 'never judge a book by its cover' couldn't be more fitting for part-time Exeter Co-op worker <a data-content-type="news" data-link-tracking="InArticle|Link" href="https://www.devonlive.com/news/devon-news/meet-christophe-szpajdel-exeter-co-410444" rel="Follow" target="_self">Christophe Szpajdel.</a> Behind the nondescript uniform and happy and warm welcoming smile lies a hidden talent that has seen the 54-year-old award-winning artist produce outstanding work for the likes of pop star Rihanna alongside renowned names in the world of the heavy metal scene, as well as fashion and films.</p> <p>The common thread between them all is striking logos which Belgium-born Christophe produces using the old school method of just a piece of paper and a pencil. You'll be more likely to find him sitting in the outdoors as that's where he feels most at ease and creative.</p> <p>My first encounter with Christophe - nickname Lord of the Logos i is at Heavitree Pleasure Ground in Exeter. The <a data-content-type="section-topic" data-link-tracking="InArticle|Link" href="https://www.devonlive.com/all-about/weather">weather</a> is unusually warm for a March day, so Christophe has found himself a sunny spot outside the front of the Parklife Cafe.</p> <figure data-mod="image" data-orientation="landscape" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="10044178" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article10044178.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo03.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="461">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article10044178.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo03.jpg" alt="Christophe Szpajdel, aka Lord of the Logos, working on his designs at Heavitree Pleasure Ground in Exeter" content="https://i2-prod.devonlive.com/incoming/article10044178.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo03.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article10044178.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo03.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">Christophe Szpajdel, aka Lord of the Logos, working on his designs at Heavitree Pleasure Ground in Exeter</span>
<span itemprop="author"> (Image: DevonLive)</span>
</figcaption>
</figure> <p>As I approach, he is busy working on a new logo called Exe'uber'ances which is the title of an exhibition he is participating in Exeter this summer.</p> <p>Knowing that his speciality is heavy metal, I expect to see him dressed in a black t-shirt brandishing a fearsome gothic inspired design. To my surprise, he is wearing a bright blue t-shirt emblazoned with yellow lettering. On closer inspection, it becomes apparent that Christophe is turning his talents to political protest t-shirts as the front reads 'make Russia small again', with an anti-Trump and vice-president JD Vance.</p> <p>He explains it was created in a 'moment of anger' and that he has Ukrainian heritage in his family. For his own personal satisfaction creates controversial drawings of American president Donald Trump that can only ever be kept under wraps to limit any damage to his career that has earned him the nickname 'Lord of the Logos'.</p> <figure data-mod="image" data-orientation="landscape" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="10044199" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article10044199.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo203JPG.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="461">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article10044199.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo203JPG.jpg" alt="The work of Christophe Szpajdel, aka Lord of the Logos" content="https://i2-prod.devonlive.com/incoming/article10044199.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo203JPG.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article10044199.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo203JPG.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">The work of Christophe Szpajdel, aka Lord of the Logos</span>
<span itemprop="author"> (Image: Christophe Szpajdel)</span>
</figcaption>
</figure> <p>Christophe's life-long passion for art started when he was a schoolboy drawing wildlife. His art then turned in a new direction when he discovered English rock band Motörhead, much to the disapproval of his mum whose favourite artist was Barbara Streisand and his dad's being Elvis.</p> <p>It led to a love of heavy metal, particularly the black and death metal sub-genres. His two passions have since taken him all over the world. His work first came to wider international attention in the mid '90s off of the back of logos for the likes of Emperor, Old Man's Child and Enthroned. </p> <p>Since then he has continued to make a significant contribution to the extreme metal scene having drawn logos for hundreds of bands including Melechesh, Falkenbach, Aborted, Abigail Williams and Bloodshot Dawn. For 'fun', he has designed unofficial logos for the likes of Ed Sheeran and Bruno Mars.</p> <figure data-mod="image" data-orientation="landscape" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="10044203" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article10044203.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo202JPG.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="461">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article10044203.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo202JPG.jpg" alt="The work of Christophe Szpajdel, aka Lord of the Logos, on stage" content="https://i2-prod.devonlive.com/incoming/article10044203.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo202JPG.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article10044203.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo202JPG.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">The work of Christophe Szpajdel, aka Lord of the Logos, on stage</span>
<span itemprop="author"> (Image: Christophe Szpajdel)</span>
</figcaption>
</figure> <p>Christophe created his first logo at the tender age of 17 for a Polish band called Totustus back in 1987. Unfortunately, the band never achieved fame. </p> <p>The first 'important' logo he says he designed was in 1989 for Finland band Disgrace, but what he credits for getting his name out there was creating logos for Germany band Endseeker, a well-known death metal band, and Enthroned from Belgium.</p> <p>But his biggest claim to fame remains the global recognition he gained after designing a show-stopping logo for pop star Rihanna in 2016. One of his visually striking designs was projected onto a 100ft backdrop at the MTV VMA awards during a live performance of her single B*tch Better Have My Money.</p> <figure data-mod="image" data-orientation="landscape" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="410479" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article410479.ece/ALTERNATES/s615b/15515776ljk.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="411">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article410479.ece/ALTERNATES/s615b/15515776ljk.jpg" alt="Belgium-born Christophe Szpajdel's logo was projected onto a 100ft backdrop at the MTV VMA awards" content="https://i2-prod.devonlive.com/incoming/article410479.ece/ALTERNATES/s615b/15515776ljk.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article410479.ece/ALTERNATES/s615b/15515776ljk.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">Belgium-born Christophe Szpajdel's logo was projected onto a 100ft backdrop at the MTV VMA awards</span>
</figcaption>
</figure> <p>Nothing can be more grounding than the fact he designed it at <a data-content-type="section-topic" data-link-tracking="InArticle|Link" href="https://www.devonlive.com/all-about/sidmouth">Sidmouth</a> Library in between shifts at the Co-op in the town. The opportunity came following a chance encounter with a member of Rihanna's management team on the tube between Canada Water and London Paddington.</p> <p>But it isn't the logo he is the most proud of. Instead he says it is the one he designed for Norwegian black metal band Emperor, simply because it is 'readable and iconic'.</p> <p>"If I could create a logo for anyone it would be Muse. I would also like to do ones for Ed Sheeran, Calvin Harris and also Elbow who are one of my favourite bands.</p> <figure data-mod="image" data-orientation="landscape" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="10044201" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article10044201.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo207.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="435">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article10044201.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo207.jpg" alt="The Emperor logo created by Christophe Szpajdel" content="https://i2-prod.devonlive.com/incoming/article10044201.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo207.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article10044201.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo207.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">The Emperor logo created by Christophe Szpajdel</span>
<span itemprop="author"> (Image: Christophe Szpajdel)</span>
</figcaption>
</figure> <p>Explaining how to make the perfect logo, Christophe, who lives in the Stoke Hill area of Exeter, said: "They have to be fluid to the eye. You need harmony, flow, symmetry and for it to be pleasant to the eye and very stylish.</p> <p>"If something is off centre it looks distracting; I'm a bit of a perfectionist! I love the aesthetics of an arched logo.</p> <p>"I prefer my logos to be simple, but have a kick. They also need to have a certain readability. Using a calligraphy style means the letters blend together rather than letters in existing fonts."</p> <figure data-mod="image" data-orientation="portrait" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="10044202" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article10044202.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo205.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="642">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article10044202.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo205.jpg" alt="The Exe'uber'ances logo created by Christophe Szpajdel" content="https://i2-prod.devonlive.com/incoming/article10044202.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo205.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article10044202.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo205.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">The Exe'uber'ances logo created by Christophe Szpajdel</span>
<span itemprop="author"> (Image: Christophe Szpajdel)</span>
</figcaption>
</figure> <p>Christophe's reputation for designing logos means he receives commissions from all over the world. His finalised sketches are then digitised by graphic designer Faye Burn to speed up the process for clients. </p> <p>However, the industry is fiercely competitive which is a constant struggle for Christophe to battle against.</p> <p>He said: "Within the past 10 years, the industry has been ruined by cheap designers using a computer and changing existing logos into a different name. Stealing intellectual property is something I have experienced extremely frequently.</p> <p>"You can tell when all the detail has been done by hand rather than by a computer, and those 'designers' charge a much cheaper price which makes people more inclined to use them."</p> <figure data-mod="image" data-orientation="portrait" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="10044200" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article10044200.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo201.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="820">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article10044200.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo201.jpg" alt="Christophe Szpajdel in his Co-op uniform" content="https://i2-prod.devonlive.com/incoming/article10044200.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo201.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article10044200.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo201.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">Christophe Szpajdel in his Co-op uniform</span>
<span itemprop="author"> (Image: Christophe Szpajdel)</span>
</figcaption>
</figure> <p>It means that Christophe relies on the steady income of his job at the Co-op serving customers. He is contracted to do 12 to 20 hours a week, currently at its store in Queen Street, but also can occasionally be seen doing shifts in Heavitree.</p> <p>He said: "The reason I will never be able to fulfil my dream to be living exclusively off my art is because of the competition there now is so I have to have two sources of income.</p> <p>"Working at the Co-op also helps me maintain contact with the outside world as otherwise you can be immersed in your own art world. As long as my tummy is full and I have a roof over my head, that is the most important thing."</p> <p>Being part-time at the Co-op enables Christophe to spend as much time as he can abroad exhibiting his work and also attending events and award ceremonies. In January, he was awarded the prestigious Artist of the Year 2025 International Prize at the Palazzo Pucci in Italy. </p> <figure data-mod="image" data-orientation="landscape" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="10044179" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article10044179.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo02.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="461">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article10044179.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo02.jpg" alt="Christophe Szpajdel, aka Lord of the Logos, with his latest award" content="https://i2-prod.devonlive.com/incoming/article10044179.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo02.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article10044179.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo02.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">Christophe Szpajdel, aka Lord of the Logos, with his latest award</span>
<span itemprop="author"> (Image: DevonLive)</span>
</figcaption>
</figure> <p>The award is presented to a select group of artists who have distinguished themselves through their aesthetic research and the stylistic values of their artwork. Additionally, he has been nominated as one of the top 60 masters by the internationally renowned ArtTour International Magazine which will be a red carpet event.</p> <p>Significant clients Christophe have worked with recently include producing a logo for short film Framed in Blood by Chris Sheeran, an alternative logo design for band The Pretty Wild, a logo for Italian alternative model and designer Amigdala, and a t-shirt design to be a potentially worn at the film premiere of Turkish movie Pavlonya by Kadir Uzun. In May, Christophe will be hosting his first exhibition in Chile during the Metal Fest at the Movistar Arena.</p> <figure data-mod="image" data-orientation="landscape" data-tmdatatrack="inline-widget" data-tmdatatrack-articleid="10044222" itemprop="image" itemscope="" itemtype="http://schema.org/ImageObject">
<meta itemprop="url" content="https://i2-prod.devonlive.com/incoming/article10044222.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo204JPG.jpg">
<meta itemprop="width" content="615">
<meta itemprop="height" content="461">
<div>

<p><img data-src="https://i2-prod.devonlive.com/incoming/article10044222.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo204JPG.jpg" alt="Christophe Szpajdel presenting a logo to death metal band Heksen" content="https://i2-prod.devonlive.com/incoming/article10044222.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo204JPG.jpg" data-inline-image="true" src="https://i2-prod.devonlive.com/incoming/article10044222.ece/ALTERNATES/s615b/0_AMR_DCM21032025logo204JPG.jpg">
</p>
</div>
<figcaption>
<span itemprop="description">Christophe Szpajdel presenting a logo to death metal band Heksen</span>
<span itemprop="author"> (Image: Christophe Szpajdel)</span>
</figcaption>
</figure> <p>However, he also remains true to his long-established Devon roots. From June 9 to 15, he will be among three artists taking part in an exhibition at Tabac Taphouse in <a data-content-type="section-topic" data-link-tracking="InArticle|Link" href="https://www.devonlive.com/all-about/exeter">Exeter</a>, as part of Art Week Exeter. He will also be participating in annual art event Devon Open Studios.</p> <p>Again with other local artists, he will be showcasing his work at Café Momus, located within Manor Street Galleries in <a data-content-type="section-topic" data-link-tracking="InArticle|Link" href="https://www.devonlive.com/all-about/plymouth">Plymouth</a>, from September 1 to 30. Christophe has also written books about his work, the first titled under his nickname Lord of the Logos with limited copies now available. His work has also featured in other books among other prestigious artists.rtists.</p><!-- Article End--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I built a word game. My mom thinks it's great. What do you think? (260 pts)]]></title>
            <link>https://www.whatsit.today/</link>
            <guid>43593789</guid>
            <pubDate>Sat, 05 Apr 2025 14:26:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.whatsit.today/">https://www.whatsit.today/</a>, See on <a href="https://news.ycombinator.com/item?id=43593789">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Loading daily challenge...</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Vision for WebAssembly Support in Swift (164 pts)]]></title>
            <link>https://forums.swift.org/t/pitch-a-vision-for-webassembly-support-in-swift/79060</link>
            <guid>43593596</guid>
            <pubDate>Sat, 05 Apr 2025 13:58:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://forums.swift.org/t/pitch-a-vision-for-webassembly-support-in-swift/79060">https://forums.swift.org/t/pitch-a-vision-for-webassembly-support-in-swift/79060</a>, See on <a href="https://news.ycombinator.com/item?id=43593596">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
              <p>As WebAssembly support has been developed by the Swift community and significantly improved over the years, I would like to put up a pitch for a vision describing WebAssembly support in Swift. Your feedback would be highly appreciated! Full vision text is included below, while <a href="https://github.com/swiftlang/swift-evolution/pull/2590">the corresponding PR is also available on GitHub</a>.</p>
<h2><a name="p-362448-introduction-1" href="#p-362448-introduction-1"></a>Introduction</h2>
<p>WebAssembly (abbreviated <a href="https://webassembly.github.io/spec/core/intro/introduction.html#wasm">Wasm</a>) is a virtual machine instruction set focused on portability, security, and high performance. It is vendor-neutral, designed and developed by <a href="https://w3.org/">W3C</a>. An implementation of a WebAssembly virtual machine is usually called a <strong>WebAssembly runtime</strong>.</p>
<p>One prominent spec-compliant implementation of a Wasm runtime in Swift is <a href="https://github.com/swiftwasm/WasmKit">WasmKit</a>. It is available as a Swift package, supports multiple host platforms, and has a simple API for interaction with guest Wasm modules.</p>
<p>An application compiled to a Wasm module can run on any platform that has a Wasm runtime available. Despite its origins in the browser, it is a general-purpose technology that has use cases in client-side and server-side applications and services. WebAssembly support in Swift makes the language more appealing in those settings, and also brings it to the browser where it previously wasn't available at all<sup><a href="#footnote-362448-1" id="footnote-ref-362448-1">[1]</a></sup>. It facilitates a broader adoption of Swift in more environments and contexts.</p>
<p>The WebAssembly instruction set has useful properties from a security perspective, as it has no interrupts or peripheral access instructions. Access to the underlying system is always done by calling explicitly imported functions, implementations for which are provided by an imported WebAssembly module or a WebAssembly runtime itself. The runtime has full control over interactions of the virtual machine with the outside world.</p>
<p>WebAssembly code and data live in completely separate address spaces, with all executable code in a given module loaded and validated by the runtime upfront. Combined with the lack of "jump to address" and a limited set of control flow instructions that require explicit labels in the same function body, this makes a certain class of attacks impossible to execute in a correctly implemented spec-compliant WebAssembly runtime.</p>
<h3><a name="p-362448-webassembly-system-interface-and-the-component-model-2" href="#p-362448-webassembly-system-interface-and-the-component-model-2"></a>WebAssembly System Interface and the Component Model</h3>
<p>The WebAssembly virtual machine has no in-built support for I/O; instead, a Wasm module's access to I/O is dependent entirely upon the runtime that executes it.</p>
<p>A standardized set of APIs implemented by a Wasm runtime for interaction with the host operating system is called <a href="https://wasi.dev/">WebAssembly System Interface (WASI)</a>. <a href="https://github.com/WebAssembly/wasi-libc">WASI libc</a> is a layer on top of WASI that Swift apps compiled to Wasm can already use thanks to C interop. The current implementation of Swift stdlib and runtime for <code>wasm32-unknown-wasi</code> triple is based on this C library. It is important for WASI support in Swift to be as complete as possible to ensure portability of Swift code in the broader Wasm ecosystem.</p>
<p>In the last few years, the W3C WebAssembly Working Group considered multiple proposals for improving the WebAssembly <a href="https://github.com/webassembly/interface-types">type system</a> and <a href="https://github.com/webassembly/module-linking">module linking</a>. These were later subsumed into a combined <a href="https://component-model.bytecodealliance.org/">Component Model</a> proposal thanks to the ongoing work on <a href="https://github.com/WebAssembly/WASI/blob/main/wasip2/README.md">WASI Preview 2</a>, which served as playground for the new design.</p>
<p>The Component Model defines these core concepts:</p>
<ul>
<li>
<p>A <strong>component</strong> is a composable container for one or more WebAssembly modules that have a predefined interface;</p>
</li>
<li>
<p><strong>WebAssembly Interface Types (WIT) language</strong> allows defining contracts between components;</p>
</li>
<li>
<p><strong>Canonical ABI</strong> is an ABI for types defined by WIT and used by component interfaces in the Component Model.</p>
</li>
</ul>
<p>Preliminary support for WIT has been implemented in <a href="https://github.com/swiftwasm/WasmKit/blob/0.0.3/Sources/WITTool/WITTool.swift">the <code>wit-tool</code> subcommand</a> of the WasmKit CLI. Users of this tool can generate <code>.wit</code> files from Swift declarations, and vice versa: Swift bindings from <code>.wit</code> files.</p>
<h2><a name="p-362448-use-cases-3" href="#p-362448-use-cases-3"></a>Use Cases</h2>
<p>We can't anticipate every possible application Swift developers are going to create with Wasm, but we can provide a few examples of its possible adoption in the Swift toolchain itself. To quote <a href="https://www.swift.org/gsoc2024/#building-swift-macros-with-webassembly">a GSoC 2024 idea</a>:</p>
<blockquote>
<p>WebAssembly could provide a way to build Swift macros into binaries that can be distributed and run anywhere, eliminating the need to rebuild them continually.</p>
</blockquote>
<p>This can be applicable not only to Swift macros, but also for the evaluation of SwiftPM manifests and plugins.</p>
<p>In the context of Swift developer tools, arbitrary code execution during build time can be virtualized with Wasm. While Swift macros, SwiftPM manifests, and plugins are sandboxed on Darwin platforms, with Wasm we can provide stronger security guarantees on other platforms that have a compatible Wasm runtime available.</p>
<p>The WebAssembly instruction set is designed with performance in mind. A WebAssembly module can be JIT-compiled or compiled on a client machine to an optimized native binary ahead of time. With recently accepted proposals to the Wasm specification it now supports features such as SIMD, atomics, multi-threading, and more. A WebAssembly runtime can generate a restricted subset of native binary code that implements these features with little performance overhead.</p>
<p>Adoption of Wasm in developer tools does not imply unavoidable performance overhead. With security guarantees that virtualization brings, there's no longer a need to spawn a separate process for each Swift compiler and SwiftPM plugin/manifest invocation. Virtualized Wasm binaries can run in the host process of a Wasm runtime, removing the overhead of new process setup and IPC infrastructure.</p>
<h2><a name="p-362448-goals-4" href="#p-362448-goals-4"></a>Goals</h2>
<p>As of March 2024 all patches necessary for basic Wasm and WASI Preview 1 support have been merged to the Swift toolchain and core libraries. Based on this, we propose a high-level roadmap for WebAssembly support and adoption in the Swift ecosystem:</p>
<ol>
<li>
<p>Make it easier to evaluate and adopt Wasm with increased API coverage for this platform in the Swift core libraries. Main prerequisite for that is setting up CI jobs for those libraries that run tests for WASI and also Embedded Wasm, where possible. As a virtualized embeddable platform, not all system APIs are always available or easy to port to WASI. For example, multi-threading, file system access, networking and localization need special support in Wasm runtimes and a certain amount of consideration from a developer adopting these APIs.</p>
</li>
<li>
<p>Improve support for cross-compilation in Swift and SwiftPM. We can simplify versioning, installation, and overall management of Swift SDKs for cross-compilation in general, which is beneficial not only for WebAssembly, but for all platforms.</p>
</li>
<li>
<p>Continue work on Wasm Component Model support in Swift as the Component Model proposal is stabilized. Ensure that future versions of WASI are available to Swift developers targeting Wasm.</p>
</li>
<li>
<p>Make interoperability with Wasm components as smooth as C and C++ interop already is for Swift. With a formal specification for Canonical ABI progressing, this will become more achievable with time. This includes consuming components from, and building components with Swift.</p>
</li>
<li>
<p>Improve debugging experience of Swift code compiled to Wasm. While rudimentary support for debugging exists in some Wasm runtimes, we aim to improve it and, where possible, make it as good as debugging Swift code compiled to other platforms.</p>
</li>
</ol>
<h3><a name="p-362448-proposed-language-features-5" href="#p-362448-proposed-language-features-5"></a>Proposed Language Features</h3>
<p>In our work on Wasm support in Swift, we experimented with a few function attributes that could be considered as pitches and eventually Swift Evolution proposals, if the community is interested in their wider adoption. These attributes allow easier interoperation between Swift code and other Wasm modules linked with it by a Wasm runtime.</p>
<h2><a name="p-362448-platform-specific-considerations-6" href="#p-362448-platform-specific-considerations-6"></a>Platform-specific Considerations</h2>
<h3><a name="p-362448-debugging-7" href="#p-362448-debugging-7"></a>Debugging</h3>
<p>Debugging Wasm modules is challenging because Wasm does not expose ways to introspect and control the execution of a Wasm module instance, so a debugger cannot be built on top of Wasm itself. Special support from the Wasm execution engine is necessary for debugging.</p>
<p>The current state of debugging tools in the Wasm ecosystem is not as mature as other platforms, but there are two main directions:</p>
<ol>
<li>
<p><a href="https://github.com/llvm/llvm-project/pull/77949">LLDB debugger with Wasm runtime</a> supporting GDB Remote Serial Protocol;</p>
</li>
<li>
<p><a href="https://book.swiftwasm.org/getting-started/debugging.html#enhanced-dwarf-extension-for-swift">Wasm runtime with a built-in debugger</a>.</p>
</li>
</ol>
<p>The first approach provides an almost equivalent experience to existing debugging workflows on other platforms. It can utilize LLDB's Swift support, remote metadata inspection, and serialized Swift module information. However, since Wasm is a Harvard architecture and has no way to allocate executable memory space at runtime, implementing expression evaluation with JIT in user space is challenging. In other words, GDB stub in Wasm engines need tricky implementations or need to extend the GDB Remote Serial Protocol.</p>
<p>The second approach embeds the debugger within the Wasm engine. In scenarios where the Wasm engine is embedded as a guest in another host engine (e.g. within a Web Browser), this approach allows seamless debugging experiences with the host language by integrating with the host debugger. For example, in cases where JavaScript and Wasm call frames are interleaved, the debugger works well in both contexts without switching tools. Debugging tools like Chrome DevTools can use DWARF information embedded in Wasm file to provide debugging support. However, supporting Swift-specific metadata information and JIT-based expression evaluation will require integrating LLDB's Swift plugin with these debuggers in some way.</p>
<p>In summary, debugging in the browser and outside of the browser context are sufficiently different activities to require separate implementation approaches.</p>
<h3><a name="p-362448-multi-threading-and-concurrency-8" href="#p-362448-multi-threading-and-concurrency-8"></a>Multi-threading and Concurrency</h3>
<p>WebAssembly has <a href="https://github.com/WebAssembly/threads">atomic operations in the instruction set</a> (only sequential consistency is supported), but it does not have a built-in way to create threads. Instead, it relies on the host environment to provide multi-threading support. This means that multi-threading in Wasm is dependent on the Wasm runtime that executes a module. There are two proposals to standardize ways to create threads in Wasm:</p>
<p>(1) <a href="https://github.com/WebAssembly/wasi-threads">wasi-threads</a>, which is already supported by some toolchains, runtimes, and libraries but has been superseded;</p>
<p>(2) The new <a href="https://github.com/WebAssembly/shared-everything-threads">shared-everything-threads</a> proposal is still in the early stages, but is expected to be the future of multi-threading in Wasm.</p>
<p>Swift currently supports two threading models in Wasm: single-threaded (<code>wasm32-unknown-wasi</code>) and multi-threaded using wasi-threads (<code>wasm32-unknown-wasip1-threads</code>). Despite the latter supporting multi-threading, Swift Concurrency defaults to a cooperative single-threaded executor due to the lack of wasi-threads support in libdispatch. Preparing for the shared-everything-threads proposal is crucial to ensure that Swift Concurrency can adapt to future multi-threading standards in Wasm.</p>
<h3><a name="p-362448-h-64-bit-address-space-9" href="#p-362448-h-64-bit-address-space-9"></a>64-bit address space</h3>
<p>WebAssembly currently uses a 32-bit address space, but <a href="https://github.com/WebAssembly/memory64/">64-bit address space</a> proposal is already in the implementation phase.</p>
<p>Swift supports 64-bit pointers on other platforms where available, however WebAssembly is the first platform where relative reference from data to code is not allowed. Alternative solutions like image-base relative addressing or "small code model" for fitting 64-bit pointer in 32-bit are unavailable, at least for now. This means that we need cooperation from the WebAssembly toolchain side or different memory layout in Swift metadata to support 64-bit linear memory support in WebAssembly.</p>
<h3><a name="p-362448-shared-libraries-10" href="#p-362448-shared-libraries-10"></a>Shared libraries</h3>
<p>There are two approaches to using shared libraries in the WebAssembly ecosystem:</p>
<ol>
<li>
<p><a href="https://emscripten.org/docs/compiling/Dynamic-Linking.html">Emscripten-style dynamic linking</a></p>
</li>
<li>
<p><a href="https://github.com/WebAssembly/component-model/blob/main/design/mvp/Linking.md">Component Model-based "ahead-of-time" linking</a></p>
</li>
</ol>
<p>Emscripten-style dynamic linking is a traditional way to use shared libraries in WebAssembly, where the host environment provides non-standard dynamic loading capabilities.</p>
<p>The latter approach cannot fully replace the former, as it is unable to handle dynamic loading of shared libraries at runtime, but it is more portable way to distribute programs linked with shared libraries, as it does not require the host environment to provide any special capabilities except for Component Model support.</p>
<p>Support for shared libraries in Swift means ensuring that Swift programs can be compiled in position-independent code mode and linked with shared libraries by following the corresponding dynamic linking ABI.</p>
<hr>

<ol>
<li id="footnote-362448-1"><p>Browser-specific use cases remain to be addressed in a separate document. <a href="#footnote-ref-362448-1">↩︎</a></p>
</li>
</ol>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Compilers: Incrementally and Extensibly (2024) (101 pts)]]></title>
            <link>https://okmij.org/ftp/tagless-final/Compiler/index.html</link>
            <guid>43593088</guid>
            <pubDate>Sat, 05 Apr 2025 12:55:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://okmij.org/ftp/tagless-final/Compiler/index.html">https://okmij.org/ftp/tagless-final/Compiler/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=43593088">Hacker News</a></p>
Couldn't get https://okmij.org/ftp/tagless-final/Compiler/index.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Earth's clouds are shrinking, boosting global warming (151 pts)]]></title>
            <link>https://www.science.org/content/article/earth-s-clouds-are-shrinking-boosting-global-warming</link>
            <guid>43592756</guid>
            <pubDate>Sat, 05 Apr 2025 12:08:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/article/earth-s-clouds-are-shrinking-boosting-global-warming">https://www.science.org/content/article/earth-s-clouds-are-shrinking-boosting-global-warming</a>, See on <a href="https://news.ycombinator.com/item?id=43592756">Hacker News</a></p>
Couldn't get https://www.science.org/content/article/earth-s-clouds-are-shrinking-boosting-global-warming: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Europe needs its own social media platforms to safeguard sovereignty (101 pts)]]></title>
            <link>https://mediascope.group/europe-needs-its-own-social-media-platforms-to-safeguard-sovereignty/</link>
            <guid>43592454</guid>
            <pubDate>Sat, 05 Apr 2025 11:07:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mediascope.group/europe-needs-its-own-social-media-platforms-to-safeguard-sovereignty/">https://mediascope.group/europe-needs-its-own-social-media-platforms-to-safeguard-sovereignty/</a>, See on <a href="https://news.ycombinator.com/item?id=43592454">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Social media has emerged as the central nervous system of global communication, shaping politics, culture, and identity. Yet, Europe’s digital public square is not its own. Over 80% of the continent’s social media activity flows through platforms headquartered in the United States—Meta (Facebook, Instagram), Alphabet (YouTube), and X (Twitter)—creating a dependency that undermines Europe’s autonomy.</p>



<p>Recently, it has become increasingly clear that European companies urgently need to build Europe’s own sovereign social media ecosystem to counter disinformation, protect democratic integrity, preserve cultural diversity, and reclaim control from US corporate and geopolitical interests. Europe’s sovereignty in the 21st century is at stake.</p>



<h2>The threat of US interference: Disinformation as a geopolitical weapon</h2>



<p>The 2016 Brexit referendum exposed how US-based actors exploited European vulnerabilities. For example, Cambridge Analytica harvested data from 87 million Facebook users—including millions of Europeans—to micro-target voters with divisive ads. Leaked documents revealed campaigns designed to inflame anti-EU sentiment, demonstrating how US corporate tools can destabilize European unity.</p>



<p>Moreover, false narratives about voter fraud propagated by US politicians on Twitter and Facebook flooded European networks, bolstering extreme movements. In Germany, the “Querdenker” movement leveraged these claims to protest COVID-19 measures, while in other countries, several disinformation groups backed by US billionaires amplified baseless accusations about election rigging.</p>



<p>It is important to understand that US platforms optimize for engagement and their owners interests, not truth. During France’s 2022 presidential race, YouTube’s algorithm disproportionately recommended far-right candidate Éric Zemmour, boosting his visibility despite his marginal polling. Researchers found that 60% of French-language election content on YouTube contained misinformation, much of it algorithmically amplified.</p>



<h2>US billionaire oligarchy problem</h2>



<p>American billionaires, including tech billionaires, wield outsized influence over European discourse. Elon Musk’s acquisition of Twitter (rebranded as X) led to the reinstatement of 62,000 banned accounts, including extremists, far-right figures like Germany’s Nikolai Nerling, who had spread anti-vaccine conspiracies, persons who committed several serious crimes in Europe, and persons who promote illegal activities such as rape and dehumanization of others. Meanwhile, Meta’s content moderation policies routinely ignore EU directives; in 2023, the European Commission accused Meta of failing to curb disinformation campaigns. Recently, several disinformation campaigns linked to US billionaires attacked EU officials on social media platforms, spreading false narratives and encouraging committing crimes (e.g., murdering officials or overthrowing governments in the EU). It has become clear that these platforms operate as extensions of US corporate power and the new US administration, prioritizing profit and political gains over Europe’s stability and safety.</p>



<h2>Data colonialism: US platforms exploit Europe</h2>



<h3><strong>GDPR vs the US surveillance state</strong></h3>



<p>While the EU’s <a href="https://mediascope.group/what-is-the-general-data-protection-regulation-gdpr/" title="GDPR. What is the General Data Protection Regulation?">General Data Protection Regulation (GDPR)</a> enshrines privacy as a fundamental right, US platforms remain bound by laws like the <a href="https://mediascope.group/the-us-cloud-act-and-risks-for-european-asian-and-african-companies/" title="The US CLOUD Act and risks for European, Asian and African companies">CLOUD Act</a>, which grants American authorities access to data stored anywhere in the world. In 2022, the European Data Protection Board fined Meta for transferring EU user data to US servers, citing risks of NSA surveillance. Despite the EU-US Data Privacy Framework, experts warn that European data remains vulnerable to US intelligence overreach.</p>



<h3><strong>Economic extraction</strong></h3>



<p>US platforms siphon billions from Europe’s digital economy. In 2022, Meta reported €4.3 billion in EU revenue but paid an effective tax rate of 8.5% through Irish loopholes—€2.5 billion less than standard EU corporate rates. Google and Apple similarly route profits through tax havens, depriving European governments of funds needed for tech innovation. This financial drain perpetuates Europe’s dependency, stifling homegrown competitors.</p>



<h3><strong>Erasing Europe’s diversity</strong></h3>



<p>US platforms homogenize culture by privileging English-language content aligning with the worldview of the current US presidential administration and US billionaires. More than 70% of trends on social media originate in the US, overshadowing local creators. European journalists and influencers struggle to compete with US influencers, while platforms like Instagram algorithmically promote American beauty standards, marginalizing Europe’s diverse cultural identities. The shrinking visibility of local users and their regional languages also threatens linguistic heritage of Europe.</p>



<h2>Europe is facing digital sovereignty crisis</h2>



<p>The US tech cold war has turned data into a strategic asset, yet Europe remains a digital colony. US platforms dominate critical infrastructure: 92% of European governments use Facebook for public communication, while Google’s search monopoly shapes access to information. This dependency leaves Europe exposed to geopolitical coercion. For instance, US platforms are involved in limiting and censoring pro-European content but promoting anti-European narratives that are aligned with US interests. Developing sovereign European platforms, including social media platforms and search engines, would ensure the sovereignty in technology, economy, information space, security and defense.</p>



<h2>Building on European strengths: The fediverse and beyond</h2>



<p>European companies and communities already host decentralized alternatives like Mastodon, a federated network powered by the homegrown Mastodon software. These GDPR-compliant tools allow users to control data and interconnect across servers—a model echoing the EU’s federalist values. However, fragmentation, lack of user-friendly UI and underfunding limit their reach. A unified EU initiative could fund these projects while the alliance of European companies and communities could merge these projects into a public-private platform.</p>



<p>It is in the best interest of the European Union to provide funding for European-owned social media platforms to ensure their development and European digital sovereignty.</p>



<h2>Network effects and innovation</h2>



<p>Critics often argue that Silicon Valley’s dominance is insurmountable, citing global statistics of Meta-owned platforms (Facebook, Instagram, Threads) and X. Yet Europe’s 450 million affluent users offer a critical mass. Moreover, Europe attracts people from other regions such as Asia, Africa and South America. Case studies from China (WeChat, Weibo, Xiaohongshu) show that sovereign platforms can thrive and expand globally.</p>



<p>Moreover, the EU is a regulatory superpower which can use legislation to support homegrown social media platforms. For example, the EU can mandate US “gatekeeper” platforms (per the Digital Markets Act) to interconnect with European alternatives, allowing cross-platform interactions. In addition, the EU could introduce EU-wide tax breaks for creators using European platforms in the form of “cultural exceptions”.</p>



<h2>Europe’s digital destiny</h2>



<p>The choice is stark: continue as a digital colony of US tech giants or forge a sovereign future. European social media platforms are not just a tool—they shield against disinformation, act as guardian of cultural diversity, and a pillar of strategic autonomy. By combining support and strategic interests with cutting-edge innovation, the EU can support the development of the homegrown social media ecosystem. The time to act is now, before the algorithms of Meta and X platforms write Europe’s next chapter for it.</p>



<hr>



<p>You can read more writings of Dawid Wiktor on his&nbsp;<a href="https://mediascope.group/?page_id=2567">Exec Profile</a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Emulating an iPhone in QEMU (181 pts)]]></title>
            <link>https://eshard.com/posts/emulating-ios-14-with-qemu</link>
            <guid>43592409</guid>
            <pubDate>Sat, 05 Apr 2025 10:57:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eshard.com/posts/emulating-ios-14-with-qemu">https://eshard.com/posts/emulating-ios-14-with-qemu</a>, See on <a href="https://news.ycombinator.com/item?id=43592409">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Start of the journey</h2>
<p>We started our journey with iOS emulation by looking at existing open-source solutions. We had successfully run <a href="https://github.com/alephsecurity/xnu-qemu-arm64">alephsecurity/xnu-qemu-arm64</a> before, but the project being read-only was concerning.</p>
<p>Then we tried <a href="https://github.com/TrungNguyen1909/qemu-t8030">TrungNguyen1909/qemu-t8030</a> and it had quite a few interesting features:</p>
<ul>
<li>the ability to actually restore iOS (using a second "companion" QEMU for USB connectivity)</li>
<li>running iOS 14</li>
<li>a more recent version of QEMU</li>
<li>a nice wiki on how to bring up the emulator</li>
</ul>
<p>With that project, we quickly managed to get a shell and ssh by modifying <code>System/Library/xpc/launchd.plist</code> so it was a great starting point.</p>
<p><img src="https://cms.eshard.com/uploads/image_16_ff7341d07a.png" alt="image (16).png"></p>
<p>We set our long term objective on getting a functional iOS emulated, with UI and at least the ability to execute some apps.</p>
<p>The first thing that bothered us with the <code>t8030</code> project was the fact that they added code in QEMU itself to patch the xnu kernel. We knew we were going to probably need more patching and wanted a cleaner way to do this.
As we had some experience with a jailbroken real iPhone, we looked into using <a href="https://github.com/palera1n/PongoOS">Pongo</a> to apply checkra1n patches, as this would allow us to remove any patching done in QEMU.</p>
<p>In a jailbreaking scenario, after getting pwned by checkmate, PongoOS is injected in SRAM and the checkra1n-kpf module is sent through USB.
Rather than bothering with early USB we chose to increase the SRAM on our emulated phone, and use PongoOS with checkra1n’s KPF module.</p>
<p>Executing PongoOS, first, was not without its issues, any boot code usually done by the bootrom or iboot would be missing, such as setting up the FPU before performing any double/float instructions. Skimming through <a href="https://developer.arm.com/documentation/dai0527/latest/">ARM documentation (section 5.4)</a> and a some <a href="https://github.com/citruz/pongoOS-QEMU/commit/033413bfaa6ebc4e1b8680b7548a3505fabe808b#diff-94255394208544c1bce0ef3fc2b955262dc6f5e8ed391005a521f28a0440a042L109-R117">Googling</a> helped.</p>
<p>Features introduced with A13 and later devices, not supported by Pongo, broke the pattern-matching of some patches. For example Pointer Authentication (PAC) instructions added <code>autda</code> / <code>xpacd</code> and Apple used a different slide.</p>
<p>Example with the infamous <a href="https://theapplewiki.com/wiki/Tfp0_patch">task_for_pid (tfp0)</a></p>
<pre><p><code><span>% ipsw macho info kernelcache.release.iphone10b.decompressed
</span>000: LC_SEGMENT_64 sz=0x006d8000 off=0x00000000-0x006d8000 addr=0xfffffff007004000-0xfffffff0076dc000 r-x/r-x   __TEXT
<!-- -->
<!-- -->Previous version (iphone-X (14.0_18A373_GM))
<!-- --> - tfp0 address 0xfffffff0076e9e70
<!-- -->   0xfffffff0076e9e70 - 0ffffffff007004000 = 0x6e5e70
<!-- --> - binary
<!-- -->   % hexdump -s 0x6e5e70 -n 8 kernelcache.release.iphone10b.decompressed
<!-- -->   06e5e70 7f70 07ec fff0 0017
<!-- -->
<!-- --> 	Raw: 	0x0017_fff0_07ec_7f70
<!-- --> 	Ghidra:  0xffff_fff0_70ec_7f70
<!-- -->
<!-- -->Later version (iphone-11 (14.0_18A5351d))
<!-- --> - tfp0 address 0x0xfffffff0076c9e40
<!-- -->   0xfffffff0076c9e40 - 0ffffffff007004000 = 0x6c5e40
<!-- --> - binary
<!-- -->   % hexdump -s 0x6c5e40 -n 8 kernelcache.research.iphone12b.decompressed
<!-- -->   06c5e40 1d70 00f0 307a 8010
<!-- -->	 
<!-- -->	Raw:	0x8010_307a_00f0_1d70
<!-- -->	Ghidra: 0xffff_fff0_07f0_5d70
</code></p></pre>
<p><img src="https://cms.eshard.com/uploads/unnamed2_cb01bfe271.png" alt="unnamed2.png"></p>

<p>Pongo allowed us to get access to existing checkra1n patches for multiple iOS versions, and although the dynamic application was interesting, it wasn't easy to read, modify or share. We wanted a more declarative approach, just like actual code patches.</p>
<p>So we made tools allowing us to diff between two <code>Mach-O</code>, and generate a text patch file with the assembly differences. The other program would take this patch file and simply apply to a binary.</p>
<p><img src="https://cms.eshard.com/uploads/Screenshot_20250224_174126_cde0ed3bb5.png" alt="Screenshot_20250224_174126.png"></p>

<p>We then booted with Pongo, and used QEMU monitor to dump the memory sections patched by Pongo, then reassembled a patched kernel and finally generated a patch file with all the modifications.
The big patch was then split and commented properly, allowing us to review and control exactly what was patched in the kernel.</p>
<p><img src="https://cms.eshard.com/uploads/unnamed_e4a4ff90f0.png" alt="unnamed.png"></p>

<h2>It’s dark in there</h2>
<p>We knew that on modern iPhones every graphical rendering ends up going through their <a href="https://developer.apple.com/documentation/metal"><code>Metal</code></a> API, which then needs an actual GPU. We believed emulating the Apple Silicon GPU would be way too complex and so we had two solutions in mind:</p>
<ul>
<li>Use software rendering: it seemed it was possible in older versions of iOS (using the gpu=0 bootarg)</li>
<li>Forwarding the Metal calls to a device capable of doing the rendering such as real iPhone or maybe a Mac with OSX</li>
</ul>
<p><img src="https://cms.eshard.com/uploads/graphic_architecture_8d6484c452.png" alt="graphic_architecture.png"></p>

<p>The software rendering seemed much easier, so we first looked into that. Unfortunately, the <code>XNU</code> kernel bootarg option was gone in iOS 14. After looking at the <code>QuartzCore</code> framework with Ghidra it seemed that the software rendering would only be called as a fallback if no <code>Metal</code> renderer was available.</p>
<p>In order to confirm that software rendering was indeed usable we worked on a real jailbroken iPhone, and patched <code>Quartzcore</code> to use software rendering. And indeed we confirmed it was possible! With these modifications, the UI was much slower, and had artifacts on parts which probably directly required <code>Metal</code> for rendering.</p>
<p><img src="https://cms.eshard.com/uploads/iphonex_sw_rendering_fae74d73b1.png" alt="iphonex_sw_rendering.png"></p>

<p>After these experiments, we knew we could get software rendering on QEMU, for anything not using <code>Metal</code> or <code>OpenGL</code> directly (so basically all <code>UIKit</code> apps).</p>
<p>We also explored the alternative of proxying the metal calls, working with 2 physical iPhones. What we did was:</p>
<ul>
<li>Parse all iOS headers with LLVM</li>
<li>All pointers to objective C object on the server is a stub pointer on the client</li>
<li>Generate automatic code to exchange structs and pointers</li>
<li>Hook all functions and methods</li>
<li>Forward every call to a server, executing them and returning the result</li>
</ul>
<p>We got some basic calls to go back and forth for Metal initialization, but we realized the road was still very long to get something to actually work. The Objetive C language and the <code>Metal</code> API are quite complex and have many features making this endeavor very complex.</p>
<p><img src="https://cms.eshard.com/uploads/metal_hook_da83384ee9.png" alt="metal_hook.png"></p>

<p>We ended up postponing this solution for a later time and thought starting with software rendering, even though it’s more restrictive, would help us advance with other problems faster.</p>
<p>Furthermore, we found out, iOS frameworks actually expose private APIs not present in the public headers. Although there are some ways to parse these and generate headers, they are most of the time not usable directly and complicate things further.</p>

<h2>IOSurface hunting</h2>
<p>After trying to make software rendering work, we decided we still needed at least a framebuffer device and the original t8030 QEMU didn’t implement one. However, we found <a href="https://github.com/ChefKissInc/QEMUAppleSilicon">a fork of the project</a> which was apparently working on IOMFB support, and decided to try debugging the display with it.</p>
<p><img src="https://cms.eshard.com/uploads/image_2_2c83473f84.png" alt="image (2).png"></p>

<p>And indeed while restoring iOS with that version, we could see the Apple logo and progress bar. However on normal boot the display would remain completely black so it was time for debugging!</p>
<p>Looking at the IOMFB kext in Ghidra and the framebuffer implementation in QEMU, it seemed that two modes were possible:</p>
<ul>
<li>A raw framebuffer at fixed hardware address was available (we guessed for early display)</li>
<li>A more complex API using registers to configure multiple planes and using dma to write surfaces data</li>
</ul>
<p>We first started experimenting with the raw framebuffer (which we later found out was how <code>Pongo</code> displayed stuff). Using it, we could display arbitrary ARGB surfaces, but when booting, that framebuffer was never written to by the system.</p>
<p>Therefore, we started looking into the second display mode. By enabling traces in the framebuffer implementation in QEMU, we could see that the kernel would set up graphical planes using registers but then nothing happened.</p>
<p>At this point we needed to debug why nothing was displayed after boot, even though the framebuffer seemed implemented and detected by the kernel.</p>

<h2>Address randomization</h2>
<p>Even though we had SSH access, we quickly got limited on what we could observe on the running system. We needed to be able to debug the kernel and userspace components with GDB.</p>
<p>For the kernel randomization, it was actually set up in the t8030 board initialization and allowed to turn it off entirely, so it was easy enough.</p>
<p>For userland we had two cases, randomization for executables and for dynamic libraries inside the dyld cache. For executables, simply patching the _load_machfile kernel function was enough to disable it.</p>
<p><img src="https://cms.eshard.com/uploads/image_20_ec79b11511.png" alt="image (20).png"></p>

<p>For the dynamic libraries we ended up handling it a bit differently.  The first thing to know is that every library is contained in a big binary blob called the dyld cache (located at <code>/System/Library/Caches/com.apple.dyld/dyld_shared_cache_arm64e</code>).</p>
<p>All libraries from this cache (called frameworks) are loaded once at boot and then mapped into processes memory space, even though dlopen is called with a path on the filesystem (like <code>/System/Library/Frameworks/QuartzCore</code>).</p>
<p>We noticed that address randomization actually happened only once at boot, and then a library was always loaded by every executable at the same address later on.</p>
<p>So all we had to do was to write some C tool which would dlopen every framework library and then use the <code>_dyld*</code> functions to list the loaded images and get their offset.</p>
<p>Using this solution (and also the reverse process while debugging with addresses coming from GDB), we could easily debug any library from the dyld cache. We were particularly interested with the <code>IOMFB</code> kext, the <code>backboardd</code> and <code>SpringBoard</code> daemons and the <code>QuartzCore</code> framework.</p>
<p><img src="https://cms.eshard.com/uploads/unnamed5_ad1129e037.png" alt="unnamed5.png"></p>

<p><img src="https://cms.eshard.com/uploads/unnamed4_1148ce717f.png" alt="unnamed4.png"></p>

<p><img src="https://cms.eshard.com/uploads/unnamed3_6dc57084e9.png" alt="unnamed3.png"></p>

<p><img src="https://cms.eshard.com/uploads/unnamed6_1acb33616d.png" alt="unnamed6.png"></p>

<pre><p><code><span>debugserver localhost:1111 –attach backboardd
</span>iproxy 1111:1111
<!-- -->gdb-multiarch -x "set architecture arch" -x "target remote localhost:1111"
</code></p></pre>
<p><strong>Note2:</strong> we later found out how to disable the dyld  cache by patching the kernel. Doing so allows to get look for virtual address directly in the dyld cache on the host (which we did using the great <a href="https://github.com/gimli-rs/object">object</a> Rust library from the Gimli project).</p>
<p><strong>Note1:</strong> to debug userspace you need to have a gdb server on the guest (see the debugserver package from <a href="https://github.com/ProcursusTeam">Procursus</a> for example). We started using gdb on the host but it’s somehow limited or bugged, and lldb seemed better.</p>

<h2>Please talk to me</h2>
<p>Armed with a working GDB we could see that  <code>backboardd</code> appeared to be starting properly, but we realized system logs would be a great help to know what was or wasn’t happening.</p>
<p>On a real iPhone, you can get the system logs (after pairing with you computer in USB) with the tool <code>idevicesyslog</code>. This pairing process involves the generation of key pair with the private key being stored on the phone. <code>lockdownd</code> uses this to verify the identity of the computer (after the user has authorized it once in the UI).</p>
<p>In our case, although we could interact with the phone through USB, <code>lockdownd</code> would not work properly. After some Ghidra sessions we realized that <code>lockdownd</code> was trying to use the <code>keybag</code> to store the private key, which would require the SEP we are lacking.</p>
<p>In order to go further, we created a shellcode injected in place of some presumably useless existing function. The code reads a pre-generated pair of private/public keys from the filesystem, and basically loads them every time <code>lockdownd</code> tries to get them from the <code>keybag</code>.</p>
<p>After much debugging (and some more patching to simulate the user trusting the computer and the phone being unlocked), we finally got it to work, and could pair with the emulated iPhone from our companion QEMU.</p>
<p><img src="https://cms.eshard.com/uploads/unnamed7_d7cd518551.png" alt="unnamed7.png"></p>
<p>We found out later on you can also use a tool called oslog on the iphone directly to show the logs (didn’t seem to work at the time), although having the ability would give us much more than just the logs afterwards.</p>
<p><img src="https://cms.eshard.com/uploads/unnamed8_a1c58cc9ab.png" alt="unnamed8.png"></p>
<p>Unfortunately, the logs revealed that <code>QuartzCore</code> seemed to be initializing properly, detecting the size of the display. It also showed that software rendering was being used as a fallback. So everything was working properly but still no display!</p>
<p>Note:  a single error about pixel format was showing and we worked around it by forcing RGBA (we’ll talk later about patching userspace), although this was removed later on.</p>
<p><img src="https://cms.eshard.com/uploads/unnamed9_675d25af99.png" alt="unnamed9.png"></p>

<h2>PAC or not PAC</h2>
<p>Modifying <code>backboardd</code> to fix a pixel format error showed us we were going to have issues with multiple aspects of iOS security.</p>
<p>The signature check at load and runtime were fixed with kernel patches, however we still had issues with pointer authentication failure interrupting our modified <code>backboardd</code> execution.</p>
<p>Pointer authentication is a feature added with ARM8.3 which is used on the <code>t8030</code> board we were emulating and not on t8015 which we used before, so this was new to us.</p>
<p>Since we had foreseen a lot more patching in the future, we decided to tackle that issue at that moment, and try to find a way to bypass this to make our life easier.</p>
<p><img src="https://cms.eshard.com/uploads/esr_pac_2e382a4e6a.png" alt="esr_pac.png"></p>
<p><img src="https://cms.eshard.com/uploads/esr_pac_decoded_8ec8ba3ab6.png" alt="esr_pac_decoded.png"></p>
<p>At the time, we first thought we could just replace all the PAC instructions with either NOP or equivalent non PAC instructions.</p>
<p>Although this would have probably worked, it was a bit invasive and we later found out that you can build an ARM64 PAC binary two ways:</p>
<ul>
<li>Either use a dedicated PAC instruction set, which can only be executed on ARM8.3+ CPU</li>
<li>Or an “unused” instruction set which will be interpreted as PAC on ARM8.3+ or non and non PAC equivalent on earlier ARM versions</li>
</ul>
<p>After running some tests with buildroot and an ARM64 linux system, we verified this to be true and also verified that the binaries compiled for our t8030, used the backward compatible instruction set (architecture called arm64e).</p>
<p>So basically, all we had to do was to disable PAC enforcing in QEMU, and it would just run like non PAC code. Unfortunately this didn’t work, and at the time we were using QEMU 7, and found out that QEMU 8 didn’t have the same behavior.</p>
<p>So we did the natural thing, and started porting the current code base to QEMU 8.2.1. This was painful as a lot of code modified QEMU generic code, particularly the code handling the apple specific instructions <code>genter</code>/<code>gexit</code> and the GL exception levels.</p>
<p>After countless xnu panics, gdb attaching to the kernel, gdb attaching to qemu itself, and a desperate git bisect to find our last bug, we finally got iOS booting again on QEMU 8!
And with it, the ability to disable PAC, and modify any executable code, anywhere as we want it.</p>

<h2>The light at the end of the tunnel</h2>
<p>Since <code>backboardd</code> appeared to be working properly in the system logs, we had no choice but to dig further into backboard behavior to try and understand why it still wasn’t displaying anything.</p>
<p>Writing raw ARGB frames on these addresses allowed us to actually modify the display and write on the different graphical planes, so we knew that the display part was actually working properly.</p>
<p>We were left with a few possibilities, either:</p>
<ul>
<li><code>backboardd</code> was not writing anything for some reason</li>
<li>or it wasn’t writing at the proper addresses</li>
<li>or what was written was not valid</li>
</ul>
<p>To investigate, we started by trying to dump physical DMA memory, where <code>backboardd</code> was supposed to write, maybe it was written to but not displayed properly.</p>
<p><img src="https://cms.eshard.com/uploads/Screenshot_20250225_092231_cf2b7f405a.png" alt="Screenshot_20250225_092231.png"></p>

<p>To do this, we used a QEMU monitor to get the non contiguous addresses, and then a crude script to dump the physical memory and merge it all in a single file.</p>
<p><img src="https://cms.eshard.com/uploads/Screenshot_20250225_092657_bec571344d.png" alt="Screenshot_20250225_092657.png"></p>

<p>Finally using ffplay we tried interpreting that data as an ARGB frame but unfortunately we didn’t get anything interesting.</p>
<p><img src="https://cms.eshard.com/uploads/unnamed10_1e6630e287.png" alt="unnamed10.png"></p>

<p>The second idea was to play with the surfaces allocated by iOS, getting the mapped address in <code>backboardd</code> memory with GDB (by breaking in iosurface_lock).</p>
<p>Searching for all these addresses for some clue, even though we had no idea what was being displayed or if something was even supposed to be displayed. We sometimes found strange things shaped apple an logo, but clearly something was wrong about the way the frames were being written.</p>
<p><img src="https://cms.eshard.com/uploads/unnamed11_5f113d14b2.png" alt="unnamed11.png"></p>

<p>We did the same thing on a real iPhone 10, and we easily dumped perfect raw ARGB frames of the current display. It turned out that with iPhone 11 (so t8030) and later, surfaces appear to be passed compressed to the GPU which knows how to handle it.</p>
<p>But since this doesn’t happen on iPhone X (t8015), we tried modifying the DTB in the QEMU to pass 8015 as <code>chip-id</code> instead of 8030. And finally, we got some apple logo showing on screen after the boot!</p>
<p><img src="https://cms.eshard.com/uploads/unnamed12_7806fbaf2d.png" alt="unnamed12.png"></p>

<h2>Some progress…bar</h2>
<p>At this point, we were happy to finally get a logo displayed but that’s all it did, and the system logs were quite verbose with many system daemons and different libraries we didn’t know about.</p>
<p>All we could do at this point is guess which of the many errors shown in the logs were related to the current issue and fix them one by one until the behavior of the UI changed.</p>
<p>We noticed issues about user authentication and found the errors originated from the daemon <code>mobileactivationd</code> and the framework <code>SpringBoardFoundation</code>.</p>
<p>After patching these, the UI started to display a white progress bar similar to what is shown during the restore phase. The bar seemed to progress indeed but seemed stuck at 90% even after waiting for hours :\</p>

<h2>Patching them all</h2>
<p>Patching the userspace and the framework of the dyld cache was made possible by disabling address randomization. The same way we patched the kernel, we created textual patch files split for each binary / library that we applied with our internal tools.</p>
<p>However, we quickly realized we were going to patch the dyld cache quite often, and while trying modifications it was very painful to handle the 2GB binary file.</p>
<p>Patching it directly was not realistic, we all work on Linux so we cannot modify the nvme directly, and copying the 2GB back and forth through SSH would take forever.</p>
<p>So what we did was to update our internal diffing/patching tool to work with dyld, search the offset of the framework in the dyld cache blob.</p>
<p>Furthermore, we added an option to allow generating simple “dd” commands (and their revert), which can be applied directly on the iPhone (after remounting the fs in rw).</p>
<p>This method allowed us to test many iterations of modifications, and only required a reboot of iOS to have modifications of the dyld cache taken into account.</p>
<p><strong>Note:</strong> a few extra modifications of signature checks in the kernel were necessary for these to work.</p>

<h2>It’s alive!</h2>
<p>Before finding out how to fix the stuck progress bar, we had a little experiment with a system process called <code>PreBoard</code>. It appears to be normally only shown to the user if something goes wrong (like an update interrupting).</p>
<p>Because it’s a system application which draws directly using <code>backboardd</code> (just like <code>SpringBoard</code> would do), it can be started directly from the command line. And with it we get a white screen asking us to swipe to upgrade!</p>

<p><img src="https://cms.eshard.com/uploads/unnamed13_35a54c70e0.png" alt="unnamed13.png"></p>

<p>Armed with knowledge of a past project about using a VNC server on a physical iPhone, we tried adding it, and after quite a few failed attempts, managed to actually unlock that white screen (not by swiping but with a keyboard key).</p>
<p>Right after unlocking, QEMU would stop the execution because iOS was apparently using an illegal instruction. After some digging into <code>backboardd</code>, we found out that it uses the <code>vImage</code> framework to do some hardware accelerated graphical operations (like _vHorizontal_Scale_ARGB_8888_Accelerate).</p>
<p>These operations rely on AMX (Apple Matrix Coprocessor) which have a set of proprietary instructions which are not implemented in the emulated ARM CPU running in QEMU. Fortunately, the <code>vImage</code> framework provides alternative software versions for these calls which only use generic ARM instructions, so we did yet again some patching.</p>
<p>The result is a new screen with an actual <code>IOKit</code> window asking us to enter the passcod and working textbox, in which we can type with the VNC injected keyboard events.</p>

<p><img src="https://cms.eshard.com/uploads/unnamed14_9319700bbb.png" alt="unnamed14.png"></p>

<p>At this point we knew everything was ready for <code>SpringBoard</code> to display properly and it was only a matter of time before we got it to start.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nebula Sans (332 pts)]]></title>
            <link>https://nebulasans.com/</link>
            <guid>43591225</guid>
            <pubDate>Sat, 05 Apr 2025 06:03:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nebulasans.com/">https://nebulasans.com/</a>, See on <a href="https://news.ycombinator.com/item?id=43591225">Hacker News</a></p>
<div id="readability-page-1" class="page">

<section>
  <img src="https://nebulasans.com/img/star_120.png" alt="Nebula star">
  <div>
    <p>Introducing</p>
    <h2>Nebula<span>Sans</span></h2>
    <p>A versatile, modern, humanist sans-serif with a neutral aesthetic, designed for legibility in both digital and print applications.</p>
    <p>Based on <em>Source Sans</em> by Paul D. Hunt for Adobe Fonts.</p>
  </div>
</section>

<div>
    <p>Nebula Sans is the new brand typeface for <a href="https://nebula.tv/">Nebula</a>, the premium streaming service from independent creators. Based on <a href="https://adobe-fonts.github.io/source-sans/" rel="noopener noreferrer"><em>Source Sans</em></a> and designed to be a drop-in alternative to <a href="https://www.typography.com/fonts/whitney/styles/screensmart" rel="noopener noreferrer"><em>Whitney SSm</em></a>, Nebula Sans is available for anyone to use under the SIL Open Font License.</p>
      
    <a href="https://nebula.tv/videos/nebula-sans">
      <img src="https://nebulasans.com/img/NebulaSans-thumbnail.jpg" alt="">
      <svg viewBox="0 0 96 111" fill="none" xmlns="http://www.w3.org/2000/svg">
        <path d="M93.9694 52.0324C96.6442 53.5704 96.6442 57.4296 93.9693 58.9676L5.99388 109.554C3.32722 111.087 1.68452e-07 109.162 3.03461e-07 106.086L4.7439e-06 4.91411C4.87891e-06 1.83804 3.32723 -0.0868459 5.99389 1.44648L93.9694 52.0324Z" fill="white"></path>
        </svg>
    </a>
    <p>
      Watch our short documentary film about the story behind Nebula&nbsp;Sans, written &amp; directed by David Friedman.
    </p>  
    
    <p>Featuring two styles in six weights, Nebula Sans is well-suited for use in interfaces, print, and for any other graphical, digital, physical, metaphysical, metaphorical, or allegorical typeface needs.</p>
 


    <p><a href="https://nebulasans.com/download/NebulaSans-1.010.zip">Download</a> 
      <a href="https://nebulasans.com/license">View font license</a>
    </p>
  </div>



<div data-theme="light">
    <div>
      <p>Nebula Sans Light</p>
      <p>I’d take the awe of understanding over the awe of ignorance any day</p>
    </div>
    <div>
      <p>Nebula Sans Book</p>
      <p>The “tv” in nebula.tv stands for “Taylor’s Version”</p>
    </div>
    <div>
      <p>Nebula Sans Medium</p>
      <p>Don’t use seven words when four will do</p>
    </div>
    <div>
      <p>Nebula Sans Semibold</p>
      <p>Introducing: Facts and fiction</p>
    </div>
    <div>
      <p>Nebula Sans Bold</p>
      <p id="test2">An indie streaming service</p>
    </div>
    <div>
      <p>Nebula Sans Black</p>
      <p id="test">Powered by humans</p>
    </div>
  </div>

<div data-theme="dark">
    <div>
      <p>Nebula Sans Black Italic</p>
      <p id="test">Enter the Snack Zone</p>
    </div>
    <div>
      <p>Nebula Sans Bold Italic</p>
      <p id="test2">There’s no place like home</p>
    </div>
    <div>
      <p>Nebula Sans Semibold Italic</p>
      <p>Charl is the key to our success</p>
    </div>
    <div>
      <p>Nebula Sans Medium Italic</p>
      <p>We’re assembling a crew for a heist</p>
    </div>
    <div>
      <p>Nebula Sans Book Italic</p>
      <p>We believe in facts, science, and human rights</p>
    </div>
    <div>
      <p>Nebula Sans Light Italic</p>
      <p>I’ve been navigating based on cardinal directions…and vibes</p>
    </div>
  </div>



<section>
    <h2>Why we made this</h2>
  
    <p>We built our own typeface for a few key reasons:</p>
    
    <ol>
      <li><strong>Personalization</strong>: we can customize the fonts to align with our preferences.</li>
      <li><strong>Features</strong>: we can integrate advanced typography features tailored to our use cases.</li>
      <li><strong>Sustainability</strong>: the cost of licensing commercial typefaces increases as we grow.</li>
    </ol>

    <p>Source Sans was the perfect foundation for Nebula Sans because it shares many primary characteristics with <em>Whitney SSm</em>, our previous brand typeface — both were designed to bridge the gap between American gothic and European humanist typefaces, with a strong emphasis on readability. The majority of the adjustments we made were to adapt the metrics of <em>Source Sans</em> to better match those of <em>Whitney SSm</em>, since <em>Source Sans</em> is smaller and narrower by default.</p>

    <figure>
      <img src="https://nebulasans.com/img/handgloves.png" alt="The word 'handgloves' in both fonts, overlayed on each other to show the differences.">
      <figcaption>Comparison of Nebula Sans versus <em>Whitney SSm</em></figcaption>
    </figure>

</section>


<section>
  <img src="https://nebulasans.com/img/upright-italic.png" alt="Nebual Sans upright and italic examples.">
  <img src="https://nebulasans.com/img/centaurus.png" alt="Text about a literal nebula, showcasing the font's capital letters and numbers.">
  <img src="https://nebulasans.com/img/standard-alternates.png" alt="Alternate glyphs for the letters 'A', 'L', and 'G'.">
</section>


<section>

  <h2>Typographical Details</h2>

  <h3>Punctuation</h3>
  <p>The default punctuation marks in <em>Whitney SSm</em> were, to our taste, too straight. Nebula Sans uses beautiful curly glyphs from <em>Source Sans</em>.</p>

  <figure role="group">
    <figure>
      <img src="https://nebulasans.com/svg/curly-quotes.svg" alt="Curly, or smart, quotes.">
    </figure>
    <figure>
      <img src="https://nebulasans.com/svg/comma-period.svg" alt="Comma and period.">
    </figure>
    <figure>
      <img src="https://nebulasans.com/svg/colon-semicolon.svg" alt="Colon and semicolon.">
    </figure>
    <figure>
      <img src="https://nebulasans.com/svg/at-sign.svg" alt="At sign.">
    </figure>
    <figure>
      <img src="https://nebulasans.com/svg/ampersand.svg" alt="Ampersand.">
    </figure>
    <figure>
      <img src="https://nebulasans.com/svg/parentheses.svg" alt="Parentheses.">
    </figure>
    <figcaption>Whitney SSm vs Nebula Sans</figcaption>
  </figure>

  <h3>Stylistic Alternates</h3>
  <p>Nebula Sans features the same stylistic alternates as <em>Source Sans</em>, with the defaults aligned with those of <em>Whitney SSm</em>.</p>

  <figure role="group">
    <figure>
      <img src="https://nebulasans.com/svg/alternate_a.svg" alt="">
      <figcaption>
        Single storey a
        <pre>font-feature-settings: 'ss01';</pre>
      </figcaption>
    </figure>
    <figure>
      <img src="https://nebulasans.com/svg/alternate_g.svg" alt="">
      <figcaption>
        Open g
        <pre>font-feature-settings: 'ss02';</pre>
      </figcaption>
    </figure>
    <figure>
      <img src="https://nebulasans.com/svg/alternate_l.svg" alt="">
      <figcaption>
        Tailed l
        <pre>font-feature-settings: 'ss03';</pre>
      </figcaption>
    </figure>
  </figure>


  <h3>Asterisk</h3>
  <p>In typography, the asterisk symbol was named as such because it resembles a star. We love stars, so how could we not put our own spin on this little glyph?</p>

  <figure role="group">
    <figure>
      <img src="https://nebulasans.com/svg/star.svg" alt="An upside-down star.">
      <figcaption>Nebula logo</figcaption>
    </figure>
    <figure>
      <img src="https://nebulasans.com/svg/asterisk.svg" alt="An upside-down five-pointed asterisk.">
      <figcaption>Nebula Sans asterisk</figcaption>
    </figure>
  </figure>


  <h3>Tabular Figures</h3>
  <p>The default version of <em>Whitney SSm</em> lacks support for tabular lining figures, so we were thrilled to be able to include them in Nebula Sans. Tabular figures (or monospaced numerals) allow us to do things like increment the timestamp in the video player while keeping the digits from jumping around as they change.</p>

  <figure role="group">
    <figure>
      <img src="https://nebulasans.com/svg/tabular-2.svg" alt="Proportional versus tabular figures. With tabular figures, every digit is the same width.">
    </figure>
    <figure>
      <img src="https://nebulasans.com/img/timestamps-2.png" alt="The timestamp on a Nebula video player.">
    </figure>
  </figure>

</section>


<div>
      <p>Wait now it’s working</p>
      <p>Why did it not work <em>5 minutes ago</em></p>
      <p>Internet weather</p>
      <p>Sent 2:57pm</p>
      <p>@&amp;%!$#?!*</p>
      <p>Sent 3:06pm</p>
    </div>



<section>
  
  <p contenteditable="true" spellcheck="false">Lorem ipsum dolor sit amet, consectetur adipiscing elit.</p>

   
</section>









</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Recreating Daft Punk's Something About Us (241 pts)]]></title>
            <link>https://thoughts-and-things.ghost.io/recreating-daft-punks-something-about-us/</link>
            <guid>43591050</guid>
            <pubDate>Sat, 05 Apr 2025 05:31:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thoughts-and-things.ghost.io/recreating-daft-punks-something-about-us/">https://thoughts-and-things.ghost.io/recreating-daft-punks-something-about-us/</a>, See on <a href="https://news.ycombinator.com/item?id=43591050">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p><strong>Marca Tatem</strong><em>&nbsp;</em>—&nbsp;San Francisco, April 3rd, 2025</p><p>After years of finding it confusing and unintuitive, I finally gave <a href="https://www.ableton.com/en/live/?ref=thoughts-and-things.ghost.io"><strong>Ableton Live</strong></a> another shot. With <strong>version 12</strong> (current as of this writing), it feels significantly more refined—so much so that it's officially become my DAW of choice.</p><p>When learning a new music production software, recreating a cover track is always a smart move. You don't have to worry too much about the songwriting itself, which frees you up to focus on the tools and the production process.</p><p>For this project, I picked a track that's emblematic of the<strong> French Touch</strong> movement and now nearing its 25th anniversary: <strong>Daft Punk's </strong><a href="https://www.youtube.com/watch?v=sOS9aOIXPEk&amp;ref=thoughts-and-things.ghost.io"><strong><em>Something About Us</em></strong></a>. Rebuilding it in a modern production environment turned out to be trickier than I expected, but here's how it went, track by track.</p><figure></figure><h2 id="wait-whats-the-french-touch-anyway">Wait... What's the French Touch, Anyway?</h2><p>To me, <strong>French Touch</strong> isn't just a genre—it's a <em>cultural artifact</em> born from a very specific time and place: France in the late <strong>'70s</strong> and <strong>'80s</strong>. Its distinct sound is the product of a generation raised on <em>analog dreams of the digital future</em>.</p><p>These artists—<strong>Daft Punk</strong>, <strong>Justice</strong>, <strong>Kavinsky</strong>, and others—grew up immersed in a bizarre and colorful media landscape. Japanese TV shows like <a href="https://www.youtube.com/watch?v=rV2yjpuPjaU&amp;ref=thoughts-and-things.ghost.io"><em>X-OR</em></a>, <a href="https://www.youtube.com/watch?v=amrDS3CvrNI&amp;ref=thoughts-and-things.ghost.io"><em>Sankukai</em></a>, and <a href="https://www.youtube.com/watch?v=ROXpxDtKv7o&amp;ref=thoughts-and-things.ghost.io"><em>Albator 84</em></a> filled French screens with space corsairs, robotic heroes, and mythological remixes set in futuristic worlds. Their themes were packed with synths, arpeggiators, and digitized voices—sounds that now echo, with a grown-up edge, in the textures of <strong>French Touch</strong> music.</p><p>At the same time, France was pushing into the future: science museums, open-air <a href="https://www.youtube.com/watch?v=NRO2EtDQ_nA&amp;ref=thoughts-and-things.ghost.io">electronic concerts by pioneers like <strong>Jean-Michel Jarre</strong></a>, and a sense that the 21st century was just around the corner. Yet beneath that techno-utopian veneer, cities like Paris remained gritty and raw. That tension—between the shiny and the grimy—runs deep in the DNA of <strong>French Touch</strong>. You hear it, especially in the darker, distorted edges of <strong>Justice</strong> and <strong>Kavinsky</strong>.</p><p>Let's also not forget the artists who laid the groundwork long before the <strong>French Touch</strong> became a thing. Quirky French electronic pioneers like <a href="https://www.youtube.com/watch?v=Gv3wVHiqP9g&amp;ref=thoughts-and-things.ghost.io"><strong>Jacno</strong></a>, the retro-futurist charm of <a href="https://www.youtube.com/watch?v=6OpnRuooGfw&amp;ref=thoughts-and-things.ghost.io"><strong>Telex</strong></a> from Belgium, and, of course,<strong> </strong><a href="https://www.youtube.com/watch?v=V-HqE1VdPgA&amp;ref=thoughts-and-things.ghost.io"><strong>Giorgio Moroder</strong></a>, the godfather of <strong>Italo Disco</strong>—all contributed textures, tones, and sensibilities that would echo decades later. Even mainstream pop acts like <a href="https://www.youtube.com/watch?v=sJZ1G0e5bWU&amp;ref=thoughts-and-things.ghost.io"><strong>Lio</strong></a>, <a href="https://www.youtube.com/watch?v=EqeJUGzvnq0&amp;ref=thoughts-and-things.ghost.io"><strong>Étienne Daho</strong></a>, or the orchestral-synth hybrids of <a href="https://www.youtube.com/watch?v=Y4FrnrD7jCA&amp;ref=thoughts-and-things.ghost.io"><strong>Rondo Veneziano</strong></a> were constantly spinning on French FM radio, which in the '80s was a chaotic, genre-blurring space. This eclectic mix quietly wired an entire generation of young listeners with an appetite for melody, groove, and synthetic textures—key ingredients in what would later become <strong>French Touch</strong>.</p><figure><img src="https://thoughts-and-things.ghost.io/content/images/2025/04/outrun.png" alt="" loading="lazy" width="1536" height="1024" srcset="https://thoughts-and-things.ghost.io/content/images/size/w600/2025/04/outrun.png 600w, https://thoughts-and-things.ghost.io/content/images/size/w1000/2025/04/outrun.png 1000w, https://thoughts-and-things.ghost.io/content/images/2025/04/outrun.png 1536w" sizes="(min-width: 720px) 720px"><figcaption><span>Outrun never looked as good as in your dreams</span></figcaption></figure><p>There's also a certain <em>California dreamin</em>g that runs through much of <strong>French Touch</strong>. The imagery of Los Angeles—<em>endless boulevards flanked by towering palm trees and that golden sunset light</em>—is a romanticized vision of America that influenced the aesthetic, especially in later works. This fusion of European electronic sensibilities with American dream imagery created something uniquely transportive.</p><p>What started as a movement became a signature sound: <em>nostalgic, futuristic, cinematic, dirty, emotional.</em></p><h2 id="why-it-was-so-hard-to-recreate">Why It Was So Hard to Recreate</h2><p>Part of what makes <strong>French Touch</strong> so compelling is also what makes it hard to replicate today. Those<em> lush, imperfect textures</em> weren't just stylistic choices—they were the natural result of a specific time, place, and set of tools. Many of these tracks were recorded in a single take, often in cramped Parisian apartments or modest studios, using vintage analog gear and early digital samplers.</p><p>There's a rawness and spontaneity to that process. The <em>hiss of a dusty synth</em>, the <em>unquantized groove of a looped disco break</em>, the warmth of <em>tape compression</em>—all of it baked into the DNA of those tracks. Today’s high-resolution digital tools are often too clean, too precise. When you remove the imperfections, you also risk scrubbing out the soul.</p><figure><img src="https://thoughts-and-things.ghost.io/content/images/2025/04/124DC7C1-7FAF-427F-9C62-8B637496C697_1_102_a.jpeg" alt="" loading="lazy" width="2000" height="1125" srcset="https://thoughts-and-things.ghost.io/content/images/size/w600/2025/04/124DC7C1-7FAF-427F-9C62-8B637496C697_1_102_a.jpeg 600w, https://thoughts-and-things.ghost.io/content/images/size/w1000/2025/04/124DC7C1-7FAF-427F-9C62-8B637496C697_1_102_a.jpeg 1000w, https://thoughts-and-things.ghost.io/content/images/size/w1600/2025/04/124DC7C1-7FAF-427F-9C62-8B637496C697_1_102_a.jpeg 1600w, https://thoughts-and-things.ghost.io/content/images/2025/04/124DC7C1-7FAF-427F-9C62-8B637496C697_1_102_a.jpeg 2364w" sizes="(min-width: 720px) 720px"><figcaption><span>The Ableton Live's session</span></figcaption></figure><p>So when I set out to recreate <em>Something About Us</em> using modern software, I knew that recreating this track would be more than just copying notes or layering samples—I’d have to <em>chase a feeling</em>.</p><h2 id="the-keys">The Keys</h2><p>In the original track, the keyboard part is likely played on a <a href="https://en.wikipedia.org/wiki/Wurlitzer_electronic_piano?ref=thoughts-and-things.ghost.io"><strong>Wurlitzer</strong></a><strong> electric piano</strong>—its <em>signature bite and warmth</em> are unmistakable. For my version, I opted for something slightly different: a warmer, more rounded tone using the excellent <a href="https://www.skystudiosplugins.com/?ref=thoughts-and-things.ghost.io"><strong>S.K.Y.&nbsp;Keys plugin</strong></a>, specifically the <em>Everything Right</em> preset. It doesn't try to mimic the original exactly but brings a vibe that fits the song's emotional core.</p><p>I kept the processing minimal: just a gentle midrange boost (mainly to make the part shine a bit more on <a href="https://en.wikipedia.org/wiki/Smiley_face_curve?ref=thoughts-and-things.ghost.io"><strong>AirPods</strong></a>), a touch of Ableton's stock <strong>Vinyl Distortion</strong> for added warmth, and <strong>side-chain compression</strong> tied to the kick for subtle movement in the mix. After the intro section, I remove the bass note from the keys to carve out space for the actual bassline to enter cleanly.</p><p>Here's what that part sounds like, dry and uncompressed:</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/keys_thumb.png" alt="audio-thumbnail"></p></div><h2 id="drums">Drums</h2><p>The drum part in <em>Something About Us</em> is deceptively simple. For this project, I built a custom kit: the <strong>kick</strong> comes from a <a href="https://en.wikipedia.org/wiki/Roland_TR-505?ref=thoughts-and-things.ghost.io"><strong>Roland TR-505</strong></a>, the <strong>closed hi-hats</strong> are from a <a href="https://en.wikipedia.org/wiki/Roland_TR-808?ref=thoughts-and-things.ghost.io"><strong>TR-808</strong></a>, and I kept the <strong>open hi-hat</strong> from the stock<strong> TR-505</strong> sounds. It’s a classic combo that delivers the crisp, laid-back groove the track needs.</p><figure><img src="https://thoughts-and-things.ghost.io/content/images/2025/04/IMG_1131-1.jpeg" alt="" loading="lazy" width="2000" height="1381" srcset="https://thoughts-and-things.ghost.io/content/images/size/w600/2025/04/IMG_1131-1.jpeg 600w, https://thoughts-and-things.ghost.io/content/images/size/w1000/2025/04/IMG_1131-1.jpeg 1000w, https://thoughts-and-things.ghost.io/content/images/size/w1600/2025/04/IMG_1131-1.jpeg 1600w, https://thoughts-and-things.ghost.io/content/images/2025/04/IMG_1131-1.jpeg 2000w" sizes="(min-width: 720px) 720px"><figcaption><span>My Arturia Beatstep Pro</span></figcaption></figure><p>Now—the <strong>snare</strong>. This one was tough. I spent a long time trying to recreate it, convinced it was a processed acoustic snare layered with something synthetic. After too many failed attempts, I caved and sampled the original. Yes, the snare is the only part I couldn’t fully replicate.</p><p>To isolate it, I used an AI stem-splitting tool called <a href="https://www.landr.com/plugins/landr-stems?ref=thoughts-and-things.ghost.io"><strong>LANDR Stems</strong>,</a> which did a surprisingly clean job of pulling the drum track apart from the rest of the mix.</p><p>Here's the full drum pattern:</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/Drums_thumb.png" alt="audio-thumbnail"></p></div><p>Here's the final snare sample, isolated:</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/Snare_thumb.png" alt="audio-thumbnail"></p></div><p>In terms of processing, I applied <strong>compression</strong> to give the groove some punch and then ran the whole drum track through a <strong>tape emulation</strong> plugin (<a href="https://www.ikmultimedia.com/products/trtapemac24/?ref=thoughts-and-things.ghost.io"><strong>Tape Machine 24</strong></a> from IK Multimedia) to smooth out the transients and give it that slightly worn-in warmth.</p><h2 id="bassline">Bassline</h2><p>Like the drums, the bassline in <em>Something About Us</em> is incredibly minimal—just a straightforward <strong>octave pattern</strong>, no ghost notes. It's tightly quantized and split across two layers that work together to form the full tone.</p><p>The <strong>low octave</strong> is a simple synth—nothing fancy. I used Ableton's stock <strong>Operator</strong> with the <em>Guitar Bass</em> preset as a starting point. A bit of EQ boosts the low mids and rolls off everything below 40Hz, and it sits nicely in the mix.</p><p>The <strong>high octave</strong>, on the other hand, comes from a sampled electric bass. I recorded a single plucked note on my own bass, loaded it into <strong>Simpler</strong>, activated Warping, and that was enough to get the right texture.</p><p>I grouped both tracks and ran them through a <strong>Glue Compressor</strong>, side-chained to the drum track for a bit of breathing and bounce. It's clean, tight, and fits under the keys without stepping on anything.</p><p>Here's the bassline coupled with drums:</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/Drums-and-Bass_thumb.png" alt="audio-thumbnail"></p></div><p>Here's the bassline soloed.</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/Bass_thumb.png" alt="audio-thumbnail"></p></div><h2 id="the-cocotte">The Cocotte</h2><p>One of the more unique textures in <em>Something About Us</em> is what we in France call a <em>"cocotte"</em>—a muted, rhythmic funk guitar riff, aka <strong>chicken guitar</strong>. In this case, it's processed through a <strong>Talkbox</strong>, which gives it that vocal, filtered tone.</p><figure><img src="https://thoughts-and-things.ghost.io/content/images/2025/04/00C0D7EA-02BB-46CC-96C7-A738C7E4824E_1_102_a.jpeg" alt="" loading="lazy" width="2000" height="1500" srcset="https://thoughts-and-things.ghost.io/content/images/size/w600/2025/04/00C0D7EA-02BB-46CC-96C7-A738C7E4824E_1_102_a.jpeg 600w, https://thoughts-and-things.ghost.io/content/images/size/w1000/2025/04/00C0D7EA-02BB-46CC-96C7-A738C7E4824E_1_102_a.jpeg 1000w, https://thoughts-and-things.ghost.io/content/images/size/w1600/2025/04/00C0D7EA-02BB-46CC-96C7-A738C7E4824E_1_102_a.jpeg 1600w, https://thoughts-and-things.ghost.io/content/images/2025/04/00C0D7EA-02BB-46CC-96C7-A738C7E4824E_1_102_a.jpeg 2048w" sizes="(min-width: 720px) 720px"><figcaption><span>My old, beaten Talkbox</span></figcaption></figure><p>If you're unfamiliar with a <strong>Talkbox</strong>, it's essentially a tiny speaker pushing sound through a plastic tube into your mouth. You shape the sound using your mouth movements, almost like playing a <em>mouth harp</em>, and that modulated sound is then picked up by a microphone. It's been famously used by artists like <a href="https://youtu.be/L_CBZkd2tGE?t=31&amp;ref=thoughts-and-things.ghost.io"><strong>Zapp &amp; Roger</strong></a>, <a href="https://www.youtube.com/watch?v=-c3N_0a_WJc&amp;ref=thoughts-and-things.ghost.io"><strong>Stevie Wonder</strong></a>, and of course, <strong>Daft Punk</strong>.</p><p>I must admit something: while I consider <strong>Daft Punk's</strong> first two albums absolute masterpieces, I've never been a huge fan of their guitar tones—especially their later collaborations with <strong>Nile Rodgers</strong>. There's nothing technically wrong with them, but I prefer funk guitars that are punchier, more percussive, and full-bodied. <a href="https://www.youtube.com/watch?v=FtzBduHNol8&amp;ref=thoughts-and-things.ghost.io"><strong>Yarol Poupaud’s</strong></a> work with <strong>FFF</strong> is more my jam—or, even closer to home, <a href="https://www.youtube.com/watch?v=EzjJQs9jHBY&amp;ref=thoughts-and-things.ghost.io"><strong>Nicolas Bogue</strong></a>, <strong>Breakbot's</strong> guitarist, who taught me everything I know about <strong>funk guitar</strong> when I was a teenager.</p><p>In <em>Something About Us,</em> the cocotte is very subdued—the ghost notes are barely there, almost unnaturally so. That may have been intentional, but I wanted to bring a little more texture and bounce into my version.</p><p>I recorded the part using a <strong>Les Paul</strong> through <a href="https://www.native-instruments.com/en/products/komplete/guitar/guitar-rig-7-pro/amps-and-cabinets/?ref=thoughts-and-things.ghost.io"><strong>Guitar Rig's</strong></a><strong> "High White"</strong> amp sim (a <strong>Hiwatt</strong> emulation), with a touch of cabinet (around 5%) to keep it from sounding too boxy. The space and depth come mostly from reverb, sent through a bus using <a href="https://www.wavealchemy.co.uk/product/magic7/?ref=thoughts-and-things.ghost.io"><strong>Wave Alchemy's Magic 7</strong></a> (a lush emulation of the <a href="https://www.bricasti.com/en/pro/m7.php?ref=thoughts-and-things.ghost.io"><strong>Bricasti M7</strong></a>).</p><p>Here's the cocotte soloed:</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/Cocotte_thumb.png" alt="audio-thumbnail"></p></div><h2 id="the-wakawak">The Wakawak</h2><p>Okay, I couldn't think of a better name for this one—<em>Wakawak</em> just fits. It's a synthetic take on a trimmed <strong>funk guitar chord</strong>, dripping in <strong>reverb</strong> and slapped with a tightly <strong>synced, panned echo</strong>. It's playful and rhythmic and adds a little magic sparkle in the background.</p><p>This sound was one of the trickiest to get right. It took quite a bit of back-and-forth. At its core, it's a <strong>synth patch</strong> designed to mimic that snappy, vocal-like quality you'd get from a well-timed guitar chop.</p><p>The patch starts with a simple waveform in Ableton Live's <strong>Wavetable</strong>, shaped by a smooth, triangle-like <strong>LFO</strong> that modulates both the amplitude and filter cutoff frequency, creating the signature pulsing movement. To add a bit more funk character, I ran it through an <strong>envelope filter stompbox</strong> emulation, which gave it a gritty, slightly overdriven sweep—more like a dusty analog auto-wah you'd find on an old pedalboard than a pristine digital effect.</p><p>The spacey vibe comes from a stock Ableton <strong>Delay</strong> on a send bus, <strong>panned hard right</strong> and set to <strong>tempo-sync</strong>. Tons of reverb helps it blend into the background without losing presence.</p><p>Here's the Wakawaka soloed:</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/Wakawaka_thumb.png" alt="audio-thumbnail"></p></div><h2 id="the-theme">The Theme</h2><p>This lead sound—<em>silly, playful, and deceptively simple</em>—was surprisingly difficult to pin down. After quite a bit of experimenting, I landed on something pretty close using <a href="https://www.arturia.com/products/software-instruments/jun-6-v/overview?ref=thoughts-and-things.ghost.io"><strong>Arturia's Jun-6V</strong></a>, their emulation of the iconic <a href="https://en.wikipedia.org/wiki/Roland_Juno-60?ref=thoughts-and-things.ghost.io"><strong>Roland Juno-6</strong></a>.</p><p>That<em> soft, rubbery tone</em> with just a hint of analog instability is key to the emotional feel of <em>Something About Us</em>. While you can approximate it using Ableton Live's <strong>Operator</strong> with the <em>Analog Bouquet</em> preset, it still lacks the warmth and nuance of a proper analog emulation.</p><p>Here's the theme soloed:</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/Theme_thumb.png" alt="audio-thumbnail"></p></div><h2 id="the-guitar-solo">The Guitar Solo</h2><p>The <em>silky, melancholic guitar solo</em> is one of the emotional peaks of <em>Something About Us</em>. While I can't say for sure, I'd wager the original was played on a <strong>hollow or semi-hollow body guitar</strong>—you can hear that smooth resonance and airy tone in the phrasing.</p><figure><img src="https://thoughts-and-things.ghost.io/content/images/2025/04/IMG_1128.jpeg" alt="" loading="lazy" width="2000" height="1500" srcset="https://thoughts-and-things.ghost.io/content/images/size/w600/2025/04/IMG_1128.jpeg 600w, https://thoughts-and-things.ghost.io/content/images/size/w1000/2025/04/IMG_1128.jpeg 1000w, https://thoughts-and-things.ghost.io/content/images/size/w1600/2025/04/IMG_1128.jpeg 1600w, https://thoughts-and-things.ghost.io/content/images/size/w2400/2025/04/IMG_1128.jpeg 2400w" sizes="(min-width: 720px) 720px"><figcaption><span>My humble Honey burst Les Paul ❤️</span></figcaption></figure><p>For my version, I recorded the solo <em>ad-lib</em> on my <strong>Les Paul</strong>, and I was lucky enough to stumble upon a preset in <strong>Guitar Rig</strong> that felt just right. I gave it a few subtle tweaks, adding in simulated hum and noise via the <strong>Noise Machine</strong> rack to inject a bit of vintage character and imperfection.</p><p>I ran it through a <strong>compressor</strong> to even out dynamics and used <strong>Raum</strong>, also in <strong>Guitar Rig</strong>, for some warm, spacey reverb that lets the notes breathe without feeling too polished.</p><p>Here's the guitar solo (with the keys):</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/Solo_thumb.png" alt="audio-thumbnail"></p></div><h2 id="the-vocals">The Vocals</h2><h3 id="lead">Lead</h3><p>Ah yes—the vocals. Now<em> that's</em> a big one. First, I genuinely believe you can't fully replicate the vocal texture of the original unless you're <em>slightly sick</em>—it's got that warm, congested, <strong>Vick Vaporub feel</strong>.</p><p>I tried a few approaches, including a <strong>vocoder</strong>, but it ended up sounding too synthetic. Even with careful dry/wet blending, it was either too robotic or too clean—and in both cases, it lost clarity.</p><figure><img src="https://thoughts-and-things.ghost.io/content/images/2025/04/IMG_1129.jpeg" alt="" loading="lazy" width="2000" height="2000" srcset="https://thoughts-and-things.ghost.io/content/images/size/w600/2025/04/IMG_1129.jpeg 600w, https://thoughts-and-things.ghost.io/content/images/size/w1000/2025/04/IMG_1129.jpeg 1000w, https://thoughts-and-things.ghost.io/content/images/size/w1600/2025/04/IMG_1129.jpeg 1600w, https://thoughts-and-things.ghost.io/content/images/size/w2400/2025/04/IMG_1129.jpeg 2400w" sizes="(min-width: 720px) 720px"><figcaption><span>A dreamy vocal booth</span></figcaption></figure><p>In the end, I went with a more organic solution: I tracked the vocals in my apartment in the Mission, San Francisco, and used Ableton's <strong>Auto Filter</strong> to sculpt the tone dynamically. I automated the filter to <strong>gradually open</strong> during the second half of each phrase, and <strong>close it sharply</strong> at the start of the next one—giving the vocal that breathing, evolving texture. I also played around with the filter automation on specific words like<em> "do"</em> and <em>"you"</em> in the phrase <em>"I've got to do/share with you."</em> It's not perfect, but it captures the vibe.</p><h3 id="harmonies">Harmonies</h3><p>There's a beautiful, super-typical Daft Punk harmony on <em>"right one"</em> and <em>"right time"</em> in the second verse—possibly vocoded in the original. It took me a while to figure out the voicings (I'm no music theory wizard), but after some trial and error, I got something I'm really happy with. <em>"Right one"</em> might still be a little off, but I think I nailed <em>"right time"</em>—and let's be honest, that's <strong>the pretty one</strong>.</p><p>I filtered the harmonies using <strong>Auto Filter</strong> again, bounced them down to a stereo track, and used the <em>Wide Stereo</em> preset in Ableton's <strong>Utility</strong> plugin to give them that spread. Add a bit of <strong>Magic 7 reverb</strong> on a bus, and boom—they melt right into the mix.</p><p>Here are the harmonies soloed:</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/Harmonies_thumb.png" alt="audio-thumbnail"></p></div><p>Here they are with the lead vocals:</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/Harmonies-and-Main_thumb.png" alt="audio-thumbnail"></p></div><h3 id="vocoder">Vocoder</h3><p>For the final section, I went <em>full robot</em>. I used a stock <strong>Operator</strong> synth as the carrier, routed it into Ableton's stock <strong>Vocoder</strong>, and processed the output with a <strong>high-pass filter</strong> and the <strong>Chorus-Ensemble</strong> plugin to give it more dimension and movement.</p><p>The vocoder is mixed in with the dry vocal until the balance feels just right—enough to sound synthetic but emotionally grounded. Basically, it ends up sounding like <em>a little robot backing me up with its heart on its sleeve.</em></p><p>Here's the vocoder soloed:</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/Vocoder_thumb.png" alt="audio-thumbnail"></p></div><p>And here's the vocoder blended with the lead:</p><div><p><img src="https://thoughts-and-things.ghost.io/content/media/2025/04/Vocoder-and-Main_thumb.png" alt="audio-thumbnail"></p></div><h2 id="from-paris-to-san-francisco-a-personal-note">From Paris to San Francisco: A Personal Note</h2><p>This project was as much about nostalgia as it was about production techniques. Born and raised in <strong>Paris in the '80s</strong>, I grew up surrounded by the cultural influences that would eventually shape <strong>French Touch</strong>. Now, having lived in California for the past seven years, reconstructing this track felt like building a <em>sonic bridge</em> between my past and present.</p><p>This recreation isn't perfect—nor was it meant to be. It's a <em>personal interpretation</em> filtered through my musical sensibilities and the tools available to me. What mattered more than technical precision was <em>capturing the emotional essence</em> that made the original so affecting.</p><p>A huge part of the joy came from working in <strong>Ableton Live 12</strong>, which now feels like an extension of how I think:</p><ul><li>The <strong>keyboard shortcuts</strong> and editing feel almost like using a great text editor—<strong>Sublime Text</strong> for music.</li><li><strong>Audio editing</strong> has improved dramatically. Where <a href="https://www.avid.com/pro-tools?ref=thoughts-and-things.ghost.io" rel="noreferrer"><strong>Pro Tools</strong></a> was once the undisputed champion, it now feels more like <a href="https://www.barebones.com/products/bbedit/?ref=thoughts-and-things.ghost.io"><strong>BBEdit</strong></a>. Still powerful, but clunky. <a href="https://www.apple.com/logic-pro/?ref=thoughts-and-things.ghost.io"><strong>Logic</strong></a>, meanwhile, still lags behind.</li><li>The <strong>stock effects</strong> and instruments are incredibly well-designed. The built-in <strong>Sampler</strong> and <strong>Wavetable</strong> synths are top-notch. For certain sounds, sure, I still reach for plugins (especially analog emulations like <strong>Arturia’s</strong>), but the native tools are more than enough to create something great.</li><li>Every module shares a <strong>consistent user interface</strong>, which really helps you stay in the flow.</li><li><strong>It’s <em>fast</em>.</strong> Projects load quickly, startup is near-instant, and it handles plugins like a champ. (Seriously, how does Logic still take so long?)</li><li>Even under load, <strong>Live</strong> stays snappy. It never gets in the way of the creative process.</li><li>The <strong>Drum Rack</strong> is beautifully intuitive—a joy to use and <em>miles ahead</em> of <strong>Logic’s</strong> equivalent.</li></ul><p>After bouncing the session, I moved to <a href="https://www.ikmultimedia.com/products/tr6/?ref=thoughts-and-things.ghost.io"><strong>T-Racks</strong></a> for mastering, putting the final polish on a project that was as educational as it was enjoyable.</p><p>This is a personal interpretation, not a definitive one. But I <em>hope you enjoyed reading it</em>, and maybe even listening along&nbsp;❤️</p><p>Here's my <a href="https://marca.fyi/?ref=thoughts-and-things.ghost.io" rel="noreferrer">personal page</a> and my <a href="https://www.instagram.com/marcatatem/?ref=thoughts-and-things.ghost.io" rel="noreferrer">Instagram account</a>.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: OCR pipeline for ML training (tables, diagrams, math, multilingual) (148 pts)]]></title>
            <link>https://github.com/ses4255/Versatile-OCR-Program</link>
            <guid>43590998</guid>
            <pubDate>Sat, 05 Apr 2025 05:22:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ses4255/Versatile-OCR-Program">https://github.com/ses4255/Versatile-OCR-Program</a>, See on <a href="https://news.ycombinator.com/item?id=43590998">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">OCR System Optimized for Machine Learning: Figures, Diagrams, Tables, Math &amp; Multilingual Text</h2><a id="user-content-ocr-system-optimized-for-machine-learning-figures-diagrams-tables-math--multilingual-text" aria-label="Permalink: OCR System Optimized for Machine Learning: Figures, Diagrams, Tables, Math &amp; Multilingual Text" href="#ocr-system-optimized-for-machine-learning-figures-diagrams-tables-math--multilingual-text"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Overview</h2><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<p dir="auto">This OCR system is specifically designed to extract structured data from complex educational materials—such as exam papers—in a format optimized for machine learning (ML) training.
It supports multilingual text, mathematical formulas, tables, diagrams, and charts, making it ideal for creating high-quality training datasets.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Key Features</h2><a id="user-content-key-features" aria-label="Permalink: Key Features" href="#key-features"></a></p>
<p dir="auto">– Optimized for ML Training: Extracted elements such as diagrams, tables, and figures are semantically annotated with contextual explanations.
This includes automatic generation of natural language descriptions for visual content (e.g., “This figure shows the process of mitosis in four stages”) to enhance downstream model training.</p>
<p dir="auto">– Multilingual Support: Works with Japanese, Korean, and English, and can be easily customized for additional languages.</p>
<p dir="auto">– Structured Output: Generates AI-ready outputs in JSON or Markdown, including human-readable descriptions of mathematical expressions, table summaries, and figure captions.</p>
<p dir="auto">– High Accuracy: Achieves over 90–95% accuracy on real-world academic datasets such as EJU Biology and UTokyo Math.</p>
<p dir="auto">– Complex Layout Support: Accurately processes exam-style PDFs with dense scientific content, formula-heavy paragraphs, and rich visual elements.</p>
<p dir="auto">– Built With: DocLayout-YOLO, Google Vision API, Gemini Pro Vision, MathPix OCR, OpenAI API, OpenCV, and more.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Sample Outputs</h2><a id="user-content-sample-outputs" aria-label="Permalink: Sample Outputs" href="#sample-outputs"></a></p>
<p dir="auto">Below are actual examples of outputs generated by this system using real-world materials (2017 EJU Biology &amp; 2014 University of Tokyo Math), including English-translated semantic context and extracted data.</p>
<p dir="auto"><strong>Math Input</strong>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/ses4255/Versatile-OCR-Program/blob/main/sample_images/Math_Original.jpeg"><img src="https://github.com/ses4255/Versatile-OCR-Program/raw/main/sample_images/Math_Original.jpeg" alt="Math Original"></a>
<strong>Output</strong>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/ses4255/Versatile-OCR-Program/blob/main/sample_images/Math_Converted.jpeg"><img src="https://github.com/ses4255/Versatile-OCR-Program/raw/main/sample_images/Math_Converted.jpeg" alt="Math Converted"></a></p>
<p dir="auto"><strong>English-translated outputs</strong></p>
<p dir="auto">Question 1. Consider the rectangular prism OABC–DEFG with a square base of side length 1. Points P, Q, R are on the segments AE, BF, and CG, respectively, and four points O, P, Q, and R lie on the same plane. Let S be the area of quadrilateral OPQR. Also, let ∠AOP be α and ∠COR be β. (2) If α + β = 1 and S = S, find the value of tan α + tan β. Also, if α ≤ β, find the value of tan α.</p>
<p dir="auto">[Image Start]</p>
<p dir="auto">Image description:
This image shows the rectangular prism OAB–CDEFGQ. Each vertex is labeled with alphabets. The angle α is marked on face OAB. The plane ORPQ intersects the prism and is highlighted. Line RC lies on face ODCG, and line PB lies on face ABFQ.</p>
<p dir="auto">Educational value:
This image enhances spatial reasoning by visualizing 3D geometry and cross-sections. It helps learners understand concepts such as plane geometry, solid shapes, spatial visualization, and angles.</p>
<p dir="auto">Related topics:
Solid geometry, cross-sections, prism faces, triangle, spatial reasoning</p>
<p dir="auto">Exam relevance:
This type of question appears in entrance exams like:</p>
<ol dir="auto">
<li>Calculate the area of ORPQ using angle α</li>
<li>Find the lengths of OR, RP, PQ, QO</li>
<li>Determine the angle between ORPQ and the prism's face</li>
<li>Locate points P, Q, R in coordinate space</li>
<li>Calculate volume/area of the prism parts</li>
<li>Predict shapes based on constraints</li>
<li>Sketch the shape of the prism</li>
</ol>
<p dir="auto">[Image End]</p>
<p dir="auto"><strong>Biology Input</strong>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/ses4255/Versatile-OCR-Program/blob/main/sample_images/Biology_Original.jpeg"><img src="https://github.com/ses4255/Versatile-OCR-Program/raw/main/sample_images/Biology_Original.jpeg" alt="Biology Original"></a>
<strong>Output</strong>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/ses4255/Versatile-OCR-Program/blob/main/sample_images/Biology_Converted.jpeg"><img src="https://github.com/ses4255/Versatile-OCR-Program/raw/main/sample_images/Biology_Converted.jpeg" alt="Biology Converted"></a></p>
<p dir="auto"><strong>English-translated outputs</strong></p>
<p dir="auto">Question 39. The photo shows the mitotic cell division process (somatic cell division) of an onion root tip. Cells A–D are in different stages of division. Match the stages (prophase, metaphase, anaphase, telophase) to each cell and select the correct combination from options ①–⑧.</p>
<p dir="auto">[Image Start]</p>
<p dir="auto">Image description:
This image shows the process of plant cell division observed under a microscope. Various cells are in different mitotic phases, including chromosomes aligned at the center (metaphase), separating to poles (anaphase), or forming daughter nuclei (telophase).</p>
<p dir="auto">A – appears to be in anaphase<br>
B – possibly telophase<br>
C – prophase or prometaphase<br>
D – metaphase</p>
<p dir="auto">Educational value:
This helps students visually understand the process of mitosis, reinforcing knowledge of cell division phases and their characteristics. It connects to biology concepts like DNA replication, cancer biology, and genetics.</p>
<p dir="auto">Related topics:
Mitosis, Cell cycle, Prophase, Metaphase, Anaphase, Telophase, DNA replication</p>
<p dir="auto">Exam relevance:
This image is used in questions such as:</p>
<ol dir="auto">
<li>Match A, B, C, D to appropriate mitotic phases</li>
<li>Describe characteristics of each phase</li>
<li>Explain the significance of mitosis</li>
<li>Discuss how errors in mitosis lead to genetic diseases</li>
</ol>
<p dir="auto">[Image End]</p>
<p dir="auto">[Table Start]</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>前期</th>
<th>中期</th>
<th>後期</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>C</td>
<td>D</td>
</tr>
<tr>
<td>A</td>
<td>D</td>
<td>B</td>
</tr>
<tr>
<td>B</td>
<td>C</td>
<td>C</td>
</tr>
<tr>
<td>B</td>
<td>D</td>
<td>C</td>
</tr>
<tr>
<td>C</td>
<td>A</td>
<td>D</td>
</tr>
<tr>
<td>C</td>
<td>D</td>
<td>A</td>
</tr>
<tr>
<td>D</td>
<td>A</td>
<td>B</td>
</tr>
<tr>
<td>D</td>
<td>C</td>
<td>A</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">Summary:
Each option (①–⑧) corresponds to a specific mapping of A, B, C, D to prophase, metaphase, and anaphase.</p>
<p dir="auto">Educational value:
Understanding time-based transition in mitosis and data organization in tables. Enhances data interpretation, pattern recognition, and analysis skills.</p>
<p dir="auto">Related topics:
Data analysis, table interpretation, biological data classification</p>
<p dir="auto">[Table End]</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage Workflow</h2><a id="user-content-usage-workflow" aria-label="Permalink: Usage Workflow" href="#usage-workflow"></a></p>
<ol dir="auto">
<li>
<p dir="auto">Step 1 – Initial OCR Extraction
Run ocr_stage1.py to extract raw elements (text, tables, figures, etc.) from input PDFs.
This step performs layout detection and stores intermediate results (e.g., coordinates, cropped images, raw content).</p>
</li>
<li>
<p dir="auto">Step 2 – Semantic Interpretation &amp; Final Output
Run ocr_stage2.py to process the intermediate data and convert it into structured, human-readable output.
This includes generating natural-language explanations, summaries, and organizing content into AI-ready formats (JSON/Markdown).</p>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Technical Implementation</h2><a id="user-content-technical-implementation" aria-label="Permalink: Technical Implementation" href="#technical-implementation"></a></p>
<p dir="auto">– Table Processing OptimizationTable regions are detected using DocLayout-YOLO</p>
<p dir="auto">– Google Vision OCR is used for table processing instead of MathPix for better accuracy with Japanese text</p>
<p dir="auto">– Table structures are preserved in structured JSON format (maintaining row/column structure)</p>
<p dir="auto">– Y-coordinate information is maintained to ensure contextual continuity</p>
<p dir="auto">– Original layout information is preserved alongside structured data for ML training</p>
<p dir="auto">– Image and Special Region ProcessingImage regions are processed using Google Vision API's image analysis features (imageProperties, labelDetection, textDetection)</p>
<p dir="auto">– Image descriptions are generated using Google Cloud Vision API</p>
<p dir="auto">– Graphs/charts are processed using Google Cloud Vision API's document analysis features with data point extraction</p>
<p dir="auto">– Special region processing results are stored in structured JSON format for ML training</p>
<p dir="auto">– Original coordinate information and region type metadata are added to maintain contextual continuity</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Purpose and Contact</h2><a id="user-content-purpose-and-contact" aria-label="Permalink: Purpose and Contact" href="#purpose-and-contact"></a></p>
<p dir="auto">This OCR system is an open project, and I’d love to see others improve or build upon it. Continuous updates and community-driven enhancements are the goal.</p>
<p dir="auto">If you’re interested in custom AI tools or would like to collaborate on an AI-related project, feel free to reach out via email:</p>
<p dir="auto"><strong>Email</strong>: <a href="mailto:ses425500000@gmail.com">ses425500000@gmail.com</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the <strong>MIT License</strong>.<br>
You are free to use, modify, distribute, and sublicense this software for any purpose, including commercial use.</p>
<p dir="auto">See the <a href="https://github.com/ses4255/Versatile-OCR-Program/blob/main/LICENSE">LICENSE</a> file for full terms.
⸻
<em>Note: The English translations in the examples were manually reformatted for clarity and consistency. Please treat them as reference only, as structure and layout may differ slightly from the original.</em>
_Keywords: OCR, exam OCR, table recognition, diagram OCR, AI education tools, OpenAI, Gemini Pro Vision, multilingual OCR, DocLayout-YOLO, Machine Learning, educational ML dataset, research OCR, paper OCR, document AI</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Trump's Tariff Formula Makes No Economic Sense. It's Also Based on an Error (237 pts)]]></title>
            <link>https://www.aei.org/economics/president-trumps-tariff-formula-makes-no-economic-sense-its-also-based-on-an-error/</link>
            <guid>43590421</guid>
            <pubDate>Sat, 05 Apr 2025 03:24:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.aei.org/economics/president-trumps-tariff-formula-makes-no-economic-sense-its-also-based-on-an-error/">https://www.aei.org/economics/president-trumps-tariff-formula-makes-no-economic-sense-its-also-based-on-an-error/</a>, See on <a href="https://news.ycombinator.com/item?id=43590421">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                        
                    <article>
                        
                        <div>
                                                        
<p>President Trump on Wednesday announced tariffs on practically every foreign country (and some non-countries), ranging from a 10 percent minimum all the way up to 50 percent. The economic fallout has been dramatic, with the stock market losing nine percent of its value (based on the S&amp;P 500 index at the time of writing) and forecasted probabilities of a recession rising.</p>



<p>President Trump described the tariffs as reciprocal, equal to half of the rate of tariffs and non-tariff trade barriers imposed by other countries. However, they are nothing of the sort. The tariff the United States is placing on other countries is equal to the US trade deficit divided by US imports from a given country, divided by two, or 10 percent, whichever rate is higher. So even if the United States has no trade deficit (or a trade surplus) with a country, they still receive a minimum tariff of 10 percent.</p>



<p>As an example, if the US imports $100 million worth of goods and services while exporting $50 million to a country, then the Trump Administration alleges that country levies a 50 percent tariff on the United States (the difference between $100 million and $50 million, divided by $100 million). The “reciprocal” tariff put into effect by President Trump on Wednesday would be half of that, 25 percent.</p>



<p>The formula for the tariffs, originally credited to the Council of Economic Advisers and&nbsp;<a href="https://ustr.gov/issue-areas/reciprocal-tariff-calculations" target="_blank" rel="noreferrer noopener">published</a>&nbsp;by the Office of the United States Trade Representative, does not make economic sense. The trade deficit with a given country is not determined only by tariffs and non-tariff trade barriers, but also by international capital flows, supply chains, comparative advantage, geography, etc.&nbsp;&nbsp;</p>



<p>But even if one were to take the Trump Administration’s tariff formula seriously, it makes an error that inflates the tariffs assumed to be levied by foreign countries four-fold. As a result, the “reciprocal” tariffs imposed by President Trump are highly inflated as well.</p>



<p>Though in effect the formula for the tariff placed on the United States by another country is equal to the trade deficit divided by imports, the formula published by the Office of the US Trade Representative has two additional terms in the denominator that just so happen to cancel out: (1) the elasticity of import demand with respect to import prices,&nbsp;<em>ε</em>, and (2) the elasticity of import prices with respect to tariffs,&nbsp;<em>φ</em>.</p>


<div>
<figure><img decoding="async" width="236" height="83" src="https://www.aei.org/wp-content/uploads/2025/04/corinthveugerequation040425.png?x85095" alt=""></figure></div>


<p>The idea is that as tariffs rise, the change in the trade deficit will depend on the responsiveness of import demand to tariffs, which depends on how import demand responds to import prices and how import prices respond to tariffs. The Trump Administration assumes an elasticity of import demand with respect to import prices of four, and an elasticity of import prices with respect to tariffs of 0.25, the product of which is one and is the reason they cancel out in the Administration’s formula.</p>



<p>However, the elasticity of import prices with respect to tariffs should be about one (actually 0.945), not 0.25 as the Trump Administration states. Their mistake is that they base the elasticity on the response of&nbsp;<em>retail&nbsp;</em>prices to tariffs, as opposed to&nbsp;<em>import</em>&nbsp;prices as they should have done. The&nbsp;<a href="https://www.aeaweb.org/articles?id=10.1257/aeri.20190536" target="_blank" rel="noreferrer noopener">article</a>&nbsp;they cite by&nbsp;<a href="https://x.com/albertocavallo/status/1907974351967633570" target="_blank" rel="noreferrer noopener">Alberto Cavallo</a>&nbsp;and his coauthors makes this distinction clear. The authors state that “tariffs [are] passed through almost fully to US import prices,” while finding “more mixed evidence regarding retail price increases.” It is inconsistent to multiply the elasticity of import demand with respect to&nbsp;<em>import</em>&nbsp;prices by the elasticity of&nbsp;<em>retail</em>&nbsp;prices with respect to tariffs.</p>



<p>Correcting the Trump Administration’s error would reduce the tariffs assumed to be applied by each country to the United States to about a fourth of their stated level, and as a result, cut the tariffs announced by President Trump on Wednesday by the same fraction, subject to the 10 percent tariff floor. As shown in Table 1, the tariff rate would not exceed 14 percent for any country. For all but a few countries, the tariff would be exactly 10 percent, the floor imposed by the Trump Administration.</p>



<p>Now, our view is that the formula the administration relied on has no foundation in either economic theory or trade law. But if we are going to pretend that it is a sound basis for US trade policy, we should at least be allowed to expect that the relevant White House officials do their calculations carefully. Hopefully they will correct their mistake soon: the resulting trade liberalization would provide a much-needed boost to the economy and may yet help us stave off a recession.</p>



<p><strong>Table 1. President Trump’s Tariffs Announced April 2, 2025, actual and with corrected formula</strong></p>



<figure><table><tbody><tr><td><strong>Country</strong></td><td><strong>(Announced) Tariff</strong></td><td><strong>(Corrected) Tariff</strong></td></tr><tr><td>Lesotho</td><td>50%</td><td>13.2%</td></tr><tr><td>Cambodia</td><td>49%</td><td>13.0%</td></tr><tr><td>Laos</td><td>48%</td><td>12.7%</td></tr><tr><td>Madagascar</td><td>47%</td><td>12.4%</td></tr><tr><td>Vietnam</td><td>46%</td><td>12.2%</td></tr><tr><td>Myanmar (Burma)</td><td>44%</td><td>11.6%</td></tr><tr><td>Sri Lanka</td><td>44%</td><td>11.6%</td></tr><tr><td>Falkland Islands</td><td>41%</td><td>10.8%</td></tr><tr><td>Syria</td><td>41%</td><td>10.8%</td></tr><tr><td>Mauritius</td><td>40%</td><td>10.6%</td></tr><tr><td>Iraq</td><td>39%</td><td>10.3%</td></tr><tr><td>Guyana</td><td>38%</td><td>10.1%</td></tr><tr><td>Bangladesh</td><td>37%</td><td>10.0%</td></tr><tr><td>Botswana</td><td>37%</td><td>10.0%</td></tr><tr><td>Liechtenstein</td><td>37%</td><td>10.0%</td></tr><tr><td>Serbia</td><td>37%</td><td>10.0%</td></tr><tr><td>Thailand</td><td>36%</td><td>10.0%</td></tr><tr><td>Bosnia and Herzegovina</td><td>35%</td><td>10.0%</td></tr><tr><td>China</td><td>34%</td><td>10.0%</td></tr><tr><td>North Macedonia</td><td>33%</td><td>10.0%</td></tr><tr><td>Angola</td><td>32%</td><td>10.0%</td></tr><tr><td>Fiji</td><td>32%</td><td>10.0%</td></tr><tr><td>Indonesia</td><td>32%</td><td>10.0%</td></tr><tr><td>Taiwan</td><td>32%</td><td>10.0%</td></tr><tr><td>Libya</td><td>31%</td><td>10.0%</td></tr><tr><td>Moldova</td><td>31%</td><td>10.0%</td></tr><tr><td>Switzerland</td><td>31%</td><td>10.0%</td></tr><tr><td>Algeria</td><td>30%</td><td>10.0%</td></tr><tr><td>Nauru</td><td>30%</td><td>10.0%</td></tr><tr><td>South Africa</td><td>30%</td><td>10.0%</td></tr><tr><td>Pakistan</td><td>29%</td><td>10.0%</td></tr><tr><td>Tunisia</td><td>28%</td><td>10.0%</td></tr><tr><td>Kazakhstan</td><td>27%</td><td>10.0%</td></tr><tr><td>India</td><td>26%</td><td>10.0%</td></tr><tr><td>South Korea</td><td>25%</td><td>10.0%</td></tr><tr><td>Brunei</td><td>24%</td><td>10.0%</td></tr><tr><td>Japan</td><td>24%</td><td>10.0%</td></tr><tr><td>Malaysia</td><td>24%</td><td>10.0%</td></tr><tr><td>Vanuatu</td><td>22%</td><td>10.0%</td></tr><tr><td>Cote d’Ivoire</td><td>21%</td><td>10.0%</td></tr><tr><td>Namibia</td><td>21%</td><td>10.0%</td></tr><tr><td>European Union</td><td>20%</td><td>10.0%</td></tr><tr><td>Jordan</td><td>20%</td><td>10.0%</td></tr><tr><td>Nicaragua</td><td>18%</td><td>10.0%</td></tr><tr><td>Zimbabwe</td><td>18%</td><td>10.0%</td></tr><tr><td>Israel</td><td>17%</td><td>10.0%</td></tr><tr><td>Malawi</td><td>17%</td><td>10.0%</td></tr><tr><td>Philippines</td><td>17%</td><td>10.0%</td></tr><tr><td>Zambia</td><td>17%</td><td>10.0%</td></tr><tr><td>Mozambique</td><td>16%</td><td>10.0%</td></tr><tr><td>Norway</td><td>15%</td><td>10.0%</td></tr><tr><td>Venezuela</td><td>15%</td><td>10.0%</td></tr><tr><td>Nigeria</td><td>14%</td><td>10.0%</td></tr><tr><td>Chad</td><td>13%</td><td>10.0%</td></tr><tr><td>Equatorial Guinea</td><td>13%</td><td>10.0%</td></tr><tr><td>Cameroon</td><td>11%</td><td>10.0%</td></tr><tr><td>Democratic Republic of the Congo</td><td>11%</td><td>10.0%</td></tr></tbody></table><figcaption>Source: Annex I,&nbsp;<a href="https://www.whitehouse.gov/presidential-actions/2025/04/regulating-imports-with-a-reciprocal-tariff-to-rectify-trade-practices-that-contribute-to-large-and-persistent-annual-united-states-goods-trade-deficits/" target="_blank" rel="noreferrer noopener">https://www.whitehouse.gov/presidential-actions/2025/04/regulating-imports-with-a-reciprocal-tariff-to-rectify-trade-practices-that-contribute-to-large-and-persistent-annual-united-states-goods-trade-deficits/</a>. Note: Countries with an announced tariff of 10% are not included in the table. Their tariffs would not change.</figcaption></figure>




                        </div>
                    </article>
                            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenVertebrate Presents a Database of 13,000 3D Scans of Specimens (164 pts)]]></title>
            <link>https://www.openculture.com/2024/03/openvertebrate-presents-a-massive-database-of-13000-3d-scans-of-vertebrate-specimens.html</link>
            <guid>43589989</guid>
            <pubDate>Sat, 05 Apr 2025 02:15:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.openculture.com/2024/03/openvertebrate-presents-a-massive-database-of-13000-3d-scans-of-vertebrate-specimens.html">https://www.openculture.com/2024/03/openvertebrate-presents-a-massive-database-of-13000-3d-scans-of-vertebrate-specimens.html</a>, See on <a href="https://news.ycombinator.com/item?id=43589989">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<p><img loading="lazy" fetchpriority="high" decoding="async" src="https://cdn8.openculture.com/2024/03/18230102/Screenshot-2024-03-18-at-10.57.49%E2%80%AFPM.png" alt="" width="2386" height="1588" srcset="https://cdn8.openculture.com/2024/03/18230102/Screenshot-2024-03-18-at-10.57.49%E2%80%AFPM.png 2386w, https://cdn8.openculture.com/2024/03/18230102/Screenshot-2024-03-18-at-10.57.49%E2%80%AFPM-360x240.png 360w, https://cdn8.openculture.com/2024/03/18230102/Screenshot-2024-03-18-at-10.57.49%E2%80%AFPM-1024x682.png 1024w, https://cdn8.openculture.com/2024/03/18230102/Screenshot-2024-03-18-at-10.57.49%E2%80%AFPM-240x160.png 240w, https://cdn8.openculture.com/2024/03/18230102/Screenshot-2024-03-18-at-10.57.49%E2%80%AFPM-768x511.png 768w, https://cdn8.openculture.com/2024/03/18230102/Screenshot-2024-03-18-at-10.57.49%E2%80%AFPM-1536x1022.png 1536w, https://cdn8.openculture.com/2024/03/18230102/Screenshot-2024-03-18-at-10.57.49%E2%80%AFPM-2048x1363.png 2048w" sizes="(max-width: 2386px) 100vw, 2386px" data-old-src="https://www.openculture.com/wp-content/plugins/native-lazyload/assets/images/placeholder.svg" data-src="https://cdn8.openculture.com/2024/03/18230102/Screenshot-2024-03-18-at-10.57.49%E2%80%AFPM.png" data-srcset="https://cdn8.openculture.com/2024/03/18230102/Screenshot-2024-03-18-at-10.57.49%E2%80%AFPM.png 2386w, https://cdn8.openculture.com/2024/03/18230102/Screenshot-2024-03-18-at-10.57.49%E2%80%AFPM-360x240.png 360w, https://cdn8.openculture.com/2024/03/18230102/Screenshot-2024-03-18-at-10.57.49%E2%80%AFPM-1024x682.png 1024w, https://cdn8.openculture.com/2024/03/18230102/Screenshot-2024-03-18-at-10.57.49%E2%80%AFPM-240x160.png 240w, https://cdn8.openculture.com/2024/03/18230102/Screenshot-2024-03-18-at-10.57.49%E2%80%AFPM-768x511.png 768w, https://cdn8.openculture.com/2024/03/18230102/Screenshot-2024-03-18-at-10.57.49%E2%80%AFPM-1536x1022.png 1536w, https://cdn8.openculture.com/2024/03/18230102/Screenshot-2024-03-18-at-10.57.49%E2%80%AFPM-2048x1363.png 2048w"></p>
<p>From The Flori­da Muse­um of Nat­ur­al His­to­ry comes the <a href="https://www.floridamuseum.ufl.edu/overt/gallery/">open­Ver­te­brate project</a>, a new ini­tia­tive to “pro­vide free, dig­i­tal 3D ver­te­brate anato­my mod­els and data to researchers, edu­ca­tors, stu­dents and the pub­lic.” Intro­duc­ing the new project (oth­er­wise known as oVert), the muse­um writes:</p>
<blockquote><p>Between 2017 and 2023, oVert project mem­bers took CT scans of more than 13,000 spec­i­mens, with rep­re­sen­ta­tive species across the ver­te­brate tree of life. This includes more than half the gen­era of all amphib­ians, rep­tiles, fish­es and mam­mals. CT scan­ners use high-ener­gy X‑rays to peer past an organism’s exte­ri­or and view the dense bone struc­ture beneath. Thus, skele­tons make up the major­i­ty of oVert recon­struc­tions. A small num­ber of spec­i­mens were also stained with a tem­po­rary con­trast-enhanc­ing solu­tion that allowed researchers to visu­al­ize soft tis­sues, such as skin, mus­cle and oth­er organs.</p>
<p>The mod­els give an inti­mate look at inter­nal por­tions of a spec­i­men that could pre­vi­ous­ly only be observed through destruc­tive dis­sec­tion and tis­sue sam­pling.</p></blockquote>
<p>In the com­ing years, the <a href="https://www.floridamuseum.ufl.edu/overt/gallery/">open­Ver­te­brate</a> team will “CT scan 20,000 flu­id-pre­served spec­i­mens from U.S. muse­um col­lec­tions, pro­duc­ing high-res­o­lu­tion anatom­i­cal data for more than 80 per­cent of ver­te­brate gen­era.” The project will also make dig­i­tal images and 3D mesh files avail­able to down­load and 3D print.</p>
<p>The video below pro­vides a short, visu­al intro­duc­tion to the <a href="https://www.floridamuseum.ufl.edu/overt/">dig­i­tal col­lec­tion</a>. You can learn more about the project <a href="https://www.floridamuseum.ufl.edu/science/scientists-ct-scanned-thousands-of-natural-history-specimens-which-you-can-access-for-free/">here</a>.</p>
<div>
<p><span><iframe title="YouTube video player" type="text/html" width="640" height="505" src="//www.youtube.com/embed/1VqLsNMIPmc?wmode=transparent&amp;fs=1&amp;hl=en&amp;showsearch=0&amp;rel=0&amp;theme=dark" frameborder="0" allowfullscreen="" loading="lazy"></iframe></span>
	</p>
</div>

<p><a href="https://boingboing.net/2024/03/10/openvertebrate-is-a-massive-database-of-3-d-scanned-images-of-13000-and-counting-vertebrate-specimens.html" rel="nofollow">via Boing­Bo­ing</a></p>
<p><strong>Relat­ed Con­tent</strong></p>
<p><a title="Permanent Link to Franz Kafka Says the Insect in <i>The Metamorphosis</i> Should Never Be Drawn; and Vladimir Nabokov Draws It Anyway" href="https://www.openculture.com/2022/03/franz-kafka-says-the-insect-in-the-metamorphosis-should-never-be-drawn-and-vladimir-nabokov-draws-it-anyway.html" rel="bookmark">Franz Kaf­ka Says the Insect in&nbsp;The Meta­mor­pho­sis&nbsp;Should Nev­er Be Drawn; and Vladimir Nabokov Draws It Any­way</a></p>
<p><a title="Permanent Link to Watch <i>The Insects’ Christmas</i> from 1913: A Stop Motion Film Starring a Cast of Dead Bugs" href="https://www.openculture.com/2019/12/watch-the-insects-christmas-from-1913.html" rel="bookmark">Watch&nbsp;<em>The Insects’ Christ­mas&nbsp;</em>from 1913: A Stop Motion Film Star­ring a Cast of Dead Bugs</a></p>
<p><a title="Permanent Link to Captivating Collaboration: Artist Hubert Duprat Uses Insects to Create Golden Sculptures" href="https://www.openculture.com/2013/02/artist_hubert_duprat_uses_insects_to_create_golden_sculptures.html" rel="bookmark">Cap­ti­vat­ing Col­lab­o­ra­tion: Artist Hubert Duprat Uses Insects to Cre­ate Gold­en Sculp­tures</a></p>

<br>		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Learn electricity and electronics fundamentals without taking a formal course (380 pts)]]></title>
            <link>https://simonmonk.org/tyee7</link>
            <guid>43589776</guid>
            <pubDate>Sat, 05 Apr 2025 01:50:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonmonk.org/tyee7">https://simonmonk.org/tyee7</a>, See on <a href="https://news.ycombinator.com/item?id=43589776">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article>

  

  <div>
    

<p>Learn electricity and electronics fundamentals and up-to-date applications―all without taking a formal course</p>

<p><img src="https://simonmonk.org/assets/images/cover_tyee7.jpg" alt="cover"></p>

<p>This fully updated guide offers practical, easy-to-follow instruction on electricity and electronics. Written by a pair of experienced instructors, Teach Yourself Electricity and Electronics, Seventh Edition features plain language explanations and step-by-step lessons that make it easy to understand the material quickly. Throughout, detailed illustrations and practical examples reinforce key concepts. This new edition brings the book up to date with modern electronics and places much more emphasis on the use of Integrated Circuits and practical electronics design. You will also get access to a valuable online exam to test your knowledge and identify areas for further study.</p>

<p>This thoroughly revised seventh edition covers:</p>

<ul>
  <li>Direct current (DC) circuits</li>
  <li>Electrical units</li>
  <li>Resistors</li>
  <li>Cells and batteries</li>
  <li>Magnetism</li>
  <li>Alternating current (AC) circuits</li>
  <li>Inductors and capacitors</li>
  <li>Phase</li>
  <li>Inductive and capacitive reactance</li>
  <li>Impedance and admittance</li>
  <li>AC power and resonance</li>
  <li>Transformers and impedance matching</li>
  <li>Semiconductors, diodes, and transistors</li>
  <li>Integrated Circuits (ICs)</li>
  <li>Amplifiers and oscillators</li>
  <li>Wireless transmitters and receivers</li>
  <li>Digital circuits</li>
  <li>Microcontrollers, including the Arduino</li>
  <li>Transducers and sensors</li>
  <li>Acoustics and audio</li>
  <li>Antennas for RF communications</li>
</ul>

<p><a href="https://simonmonk.org/assets/downloads/quiz_section_1.pdf">Quiz Section 1</a></p>

<p><a href="https://simonmonk.org/assets/downloads/quiz_section_2.pdf">Quiz Section 2</a></p>

<p><a href="https://simonmonk.org/assets/downloads/quiz_section_3.pdf">Quiz Section 3</a></p>

<p><a href="https://simonmonk.org/assets/downloads/quiz_section_4.pdf">Quiz Section 4</a></p>

<p><a href="https://simonmonk.org/assets/downloads/quiz_final.pdf">Final Quiz</a></p>

  </div>

</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AT&T Email-to-Text Gateway Service Ending June 17 (125 pts)]]></title>
            <link>https://www.att.com/support/article/wireless/KM1061254/</link>
            <guid>43589523</guid>
            <pubDate>Sat, 05 Apr 2025 01:22:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.att.com/support/article/wireless/KM1061254/">https://www.att.com/support/article/wireless/KM1061254/</a>, See on <a href="https://news.ycombinator.com/item?id=43589523">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><div><p>Starting June 17, 2025, you won’t be able to send or receive texts using email.</p></div><hr></div><div><div id="firstStepComponentDiv"><h2>What to know</h2><div id="FirstStepContentLess"><p>On June 17, 2025, our email-to-text and text-to-email service is going away. This means you won’t be able to use email to send or receive texts. Also, others who have AT&amp;T Wireless<sup>SM</sup> won’t be able to use email to send you a text or use text to send you an email.&nbsp;</p>
<p>Have a FirstNet account? <a id="idFirstToReportClicks1" href="https://www.firstnet.com/help/email-messaging-gateway.html" title="Link opens in a new window" target="_blank">Find out if you’ll be impacted by end of email-to-text service</a>.</p>
<p>Have Business or Internet of Things (IoT) account? <a id="idFirstToReportClicks2" href="https://businessdigital.att.com/email-messaging-gateway" title="Link opens in a new window" target="_blank">Learn how ending email-to-text service might impact you</a>.</p></div></div><hr></div><div id="FAQData"><p><h2>FREQUENTLY ASKED QUESTIONS</h2></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Trump's Tariffs Wipe Out over $6T on Wall Street in Epic Two-Day Rout (423 pts)]]></title>
            <link>https://www.wsj.com/finance/stocks/u-s-stock-futures-fall-further-after-china-retaliates-against-trump-tariffs-3be33fa7</link>
            <guid>43589231</guid>
            <pubDate>Sat, 05 Apr 2025 00:41:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/finance/stocks/u-s-stock-futures-fall-further-after-china-retaliates-against-trump-tariffs-3be33fa7">https://www.wsj.com/finance/stocks/u-s-stock-futures-fall-further-after-china-retaliates-against-trump-tariffs-3be33fa7</a>, See on <a href="https://news.ycombinator.com/item?id=43589231">Hacker News</a></p>
Couldn't get https://www.wsj.com/finance/stocks/u-s-stock-futures-fall-further-after-china-retaliates-against-trump-tariffs-3be33fa7: Error: Request failed with status code 401]]></description>
        </item>
    </channel>
</rss>