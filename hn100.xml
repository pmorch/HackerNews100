<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 01 Oct 2024 06:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Boris Vallejo and the pixel art of the demoscene (175 pts)]]></title>
            <link>https://marincomics.com/vallejo-pixelart.html</link>
            <guid>41703213</guid>
            <pubDate>Mon, 30 Sep 2024 23:31:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://marincomics.com/vallejo-pixelart.html">https://marincomics.com/vallejo-pixelart.html</a>, See on <a href="https://news.ycombinator.com/item?id=41703213">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article id="vallejo-00">
          <h2>Boris Vallejo and the Pixel Art of the Demoscene</h2>
          <p>
            As an epic fantasy painter, Boris Vallejo had a great influence on 1980s and 90s fantasy book covers, computer game box art, and the <a href="https://en.m.wikipedia.org/wiki/Demoscene" target="_blank" rel="noopener">demoscene</a>. Through the decades, his works have been replicated by pixel artists. This article features fantasy art history, demoscene drama, and a lot of pixel art fun creating a Boris Vallejo imitation graphic using only four colors.
          </p>
          <p>October 2024</p>

          <p>
            <img src="https://marincomics.com/img/vallejo/axe-warrior-combo.jpg" alt="Left, the full painting by Boris Vallejo. Right, the line art version with only four colors."><br>
            <em>
              On the left, the original painting "Gillkarth's Odyssey" by Boris Vallejo. On the right, is my line art
              recreation using only four colors. I call it "Wrath of the Vallerian" (after Boris Vallejo).
            </em>
          </p>

          <p>
            Recently, I was going through the historical results of the <a href="https://www.demoparty.net/revision" target="_blank" rel="noopener">Revision</a> demoparty, as you do. I was looking
            for a subject to draw for a new pixel art piece. I had learned to appreciate the color limitations during
            the old-school graphics competition at <a href="https://www.demoparty.net/evoke" target="_blank" rel="noopener">Evoke</a>, where we could only use a predefined color palette. The
            first time I submitted an entry in 2022, I hated it. The second time, in 2023, I came to accept the
            limited color palette as a problem to solve. And by 2024, I actually started to enjoy the challenge.
          </p>
          <p>I wanted to create a new piece outside of competition and was looking for inspiration.</p>
          <p>
            In the
            <a href="https://2013.revision-party.net/history/2013.html" target="_blank" rel="noopener">results.txt</a>
            file of Revision 2013, I found an interesting phrase. Right above the list of results for the graphics
            competition, it said:
          </p>

          <p>
            <em>
              "GRAPHICS COMPETITIONS HAVEN'T BEEN<br>
              THE SAME EVER SINCE PEOPLE STOPPED<br>
              RIPPING BORIS VALLEJO AND SORAYAMA"</em>
          </p>
          <h2 id="vallejo-01">Whatever Happened to Boris Vallejo?</h2>
          <p>
            I hadn't thought of Peruvian artist <a href="https://en.m.wikipedia.org/wiki/Boris_Vallejo" target="_blank" rel="noopener">Boris Vallejo</a> in ages. I remembered his slick fantasy artwork,
            featuring idealistically rendered warriors and princesses, muscular and scantily clad (but not indecent).
            If they weren't battling monsters, the figures wouldn't look out of place in a romance novel. Vallejo's
            paintings were always beautifully done, but they're a bit out of fashion these days.
          </p>
          <p>
            <img src="https://marincomics.com/img/vallejo/dragon-riders.jpg" alt="A group of scantily clad young women on the backs of dragons flying in the sky"><br>
            <em> Boris Vallejo, "Dragon Riders", 1982 </em>
          </p>
          <p>
            Pixel artists copied his work in the late 1980s and 1990s. Vallejo's visual aesthetic was one that many
            <a href="https://en.m.wikipedia.org/wiki/Demoscene" target="_blank" rel="noopener">demoscene</a> groups sought to replicate or pay homage to on the new 16-bit platforms like the Commodore
            Amiga, the Atari ST, and the PC with its wonderful VGA graphics.
          </p>

          <p>
            <img src="https://marincomics.com/img/vallejo/john-carter.jpg" alt="John Carter and the Princess of Mars confronting a four-armed giant white ape"><br>
            <em>Boris Vallejo and Julie Bell, "John Carter of Mars", 2009</em>
          </p>

          <p>
            Vallejo's art was filled with heroic characters, often set in mythical or alien worlds, similar to the
            themes explored in many demoscene productions. Demos in the 1990s, especially on platforms like the Amiga,
            frequently featured surreal landscapes, epic narratives, and fantastical characters reminiscent of
            Vallejo's paintings.
          </p>
          <p>
            There was a time when I loved Vallejo's art. It was a fascinating blend of imagination and breathtaking
            realism, with vivid portrayals of fantasy worlds populated by powerful, heroic figures and fantastical
            creatures. Vallejo's mastery of anatomy and attention to detail brought his subjects to life. I used to
            feel a true sense of awe and wonder when looking at his paintings. Back then, I felt that his work struck
            a balance between strength and beauty, craftsmanship and adventure.
          </p>
          <p>
            <img src="https://marincomics.com/img/vallejo/tenacious-gor.jpg" alt="Book cover of Tarnsman of Gor and a painting of the band Tenacious D"><br>
            <em>
              Left: One of Boris Vallejo's early works from 1977, the cover of "Tarnsman of Gor". Right: A recent
              painting by Boris Vallejo and Julie Bell from 2023: "Tenacious D".
            </em>
          </p>
          <p>
            These days, I'm not so sure. I've grown older, and my tastes have changed. I still admire Vallejo's work,
            but now I find it a bit too slick, idealized, and repetitive. I've come to appreciate rougher, more
            abstract, and more experimental art styles.
          </p>
          <p>
            I looked up Boris Vallejo, and by all accounts, he is in his 80s, alive and well. He collaborates with his artist wife <a href="https://en.m.wikipedia.org/wiki/Julie_Bell" target="_blank" rel="noopener">Julie
            Bell</a>, continues to produce and successfully sell their artwork online:
            <a href="https://www.borisjulie.com/" target="_blank" rel="noopener">borisjulie.com</a>.</p>
          <p>Yet, while
            reminiscing about Vallejo's paintings, I realized I might have found a topic for a drawing.
          </p>

          <h2 id="vallejo-02">The Appropriation of Popular Art by Sceners</h2>

          <p>
            As of September 2024,
            <a href="https://demozoo.org/productions/tagged/boris-vallejo/" target="_blank" rel="noopener">around 35 images</a>
            submitted by sceners on Demozoo are tagged with "boris-vallejo" though the tagging is probably not comprehensive. Given his significant influence on the demoscene,
            Boris Vallejo even has entries on both
            <a href="https://demozoo.org/sceners/91415/" target="_blank" rel="noopener">demozoo.org</a> and
            <a href="http://janeway.exotica.org.uk/author.php?id=2112" target="_blank" rel="noopener">janeway.exotica.org</a>.
          </p>

          <p>
            <img src="https://marincomics.com/img/vallejo/edge-of-tomorrow.jpg" alt="Boris Vallejo's cover of the book Edge of Tomorrow was used in the demo Hardwired by The Silents and Kefrens"><br>
            <em>
              Left: Boris Vallejo's art as found in the Hardwired demo by The Silents and Kefrens Right: Vallejo's
              orignal cover of the book "Edge of Tomorrow" by Isaac Asimov
            </em>
          </p>

          <p>
            The other artist mentioned in the results.txt was the Japanese artist <a href="https://en.m.wikipedia.org/wiki/Hajime_Sorayama" target="_blank" rel="noopener">Hajime Sorayama</a>. He is best known
            for his hyper-realistic erotic robots and cyborgs. His work explores the fusion of man and machine, often
            focusing on eroticism, fetishism, and the beauty of artificial forms. Sorayama rose to international fame
            in the 1980s and has influenced various fields, from fine art to commercial design, including
            contributions to film, music, and fashion. For the young men in the demoscene, this was a perfect
            combination.
          </p>

          <p>
            <img src="https://marincomics.com/img/vallejo/sorayama.jpg" alt="A sexy robot woman by Sorayama, copied by a pixel artist on the Amiga"><br>
            <em>On the Left: the pixel art copy on the Amiga of the original painting by Sorayama on the right.</em>
          </p>

          <p>
            Over the years, Boris Vallejo and his long-time collaborator Julie Bell had other intersections with
            computers in the 1990s. They painted box art for computer and video games such as the fantasy role-playing
            game <em>Dragon Wars</em>, the platform shooter <em>Turrican</em>, the side-scrolling fantasy beat-'em-up
            <em>Golden Axe</em>, and the delightful underwater adventure <em>Ecco the Dolphin</em>. Here is a
            <a href="https://vgdensetsu.net/2_BorisVallejo.html" target="_blank" rel="noopener">list of computer and video game box art credits by Boris Vallejo</a>.
          </p>

          <p>
            Vallejo's influence on sceners was unquestionable. Below are more examples of Vallejo's artwork used in
            demoscene productions. Many of these artworks were digitized or scanned, which doesn't require any
            artistry. It's a cheap and easy way to get good graphics for a demo.
          </p>

          <p>
            <img src="https://marincomics.com/img/vallejo/swipe0.jpg" alt="An obvious scan of a Vallejo painting in a demo slideshow"><br>
            <em>
              The
              <a hef="https://demozoo.org/productions/224392/" target="_blank" rel="noopener">Fantasy Slideshow by Turtletronic</a>
              has a number of obvious scans (left) of Vallejo's paintings, e.g. the harpy kissing a woman (right).
              Turtletronic could pull off this scan or capture because their slideshow uses Amiga's HAM mode that
              allows the nearly unrestricted use of all of the Amiga's 4,096 color.
            </em>
          </p>

          <p>
            <img src="https://marincomics.com/img/vallejo/swipe1.jpg" alt="A copy of Vallejo's art by Peachy"><br>
            <em>
              I feel that
              <a href="https://demozoo.org/graphics/5359/" target="_blank" rel="noopener">Peachy's recreation</a> (on
              the left) of a painting by Boris Vallejo (on the right) looks to be hand-pixelled and not a scan. The
              slightly different angle of the front leg and the bark on the tree trunk look different.
            </em>
          </p>

          <p>
            <img src="https://marincomics.com/img/vallejo/swipe2.jpg" alt="A copy of Vallejo's art by Archmage"><br>
            <em>
              I also believe that
              <a href="https://demozoo.org/graphics/4232/" target="_blank" rel="noopener">Archmage</a> (left)
              recreated the painting by Boris Vallejo (right) by hand-pixelling it in a painting program. The face of
              the woman in the center is angled differently and trees in the background look differnt.
            </em>
          </p>

          <p>
            Scanned paintings are quite controversial in the scene. In a blog post by a scener called <em>Danny</em>,
            who used to work for the computer game company Eidos Interactive, he does not like the practice of using scanned images of paintings and then declaring them as your own work. But he also does not find critics great who condemn sceners who copy paintings but delare that they are copies. He even
            wrote that it is the main reason he left the scene and would no longer submit any graphics for
            competitions. His post,
            <a href="http://www.kameli.net/nocopy/disint.htm" target="_blank" rel="noopener">Disintegration Of The Old Graphics Scene</a>, is worth reading. He wrote it in 1998, making it a reflection of that time period in the demoscene.
          </p>

          <p>
            Some of <em>Danny's</em> arguments sound distressingly familiar nowadays in the context of AI-generated
            art. In his post, he wrote:
          </p>

          <p>
            <em>
              "There are quite a number of artists (even some famous ones that get much respect) that have practiced
              so long on making a scanned image look hand drawn, that their lame efforts have become almost
              undetectable. There is almost no way of telling if the image is created through blood, sweat, and tears,
              or the powers of modern-day technology.
            </em>
          </p>

<p><em>Danny</em> does not outright condemn or defend copying. He just does not fully discount its value in a hobbyist community like the demoscene as long as it is clear that a work is a reproduction of another work. This is for me the culmination of his text:</p>

<blockquote>
<em>
"My point is that everybody copies. Some do it to learn, others do it to grasp a bit of fame in a very challenging environment. It's not just the artists that copy, it's the whole bloody scene. And everyone that makes any form of art. Artists just get all the crap for it because it's easiest to spot."
</em>
</blockquote>

          <p>
            <img src="https://marincomics.com/img/vallejo/editions64k-book.jpg" alt="Works inspired by Vallejo in the Amiga demoscene book by Éditions64K"><br>
            <em>The history of the Amiga demoscene is paved with Vallejo immitations.</em>
          </p>

          <p>
            Some graphics based on Vallejo paintings were actually pixel painted by the sceners, as can be seen in
            this article in
            <a href="https://www.editions64k.fr/product/demoscene-the-amiga-years-vol-1/" target="_blank" rel="noopener">Demoscene: the Amiga Years. Volume 1 1984-1993</a>
            by Éditions64k. This requires artistry and dedication.
          </p>
          
          <p>
            <img src="https://marincomics.com/img/vallejo/suny.jpg" alt="Suny's Vallejo"><br>
            <em>The Éditions64K book features three pages about the process that Suny used to hand-pixel a recreation of a Vallejo painting on the Commodore Amiga.</em>
          </p>

<p>It is amazing how many demoscene pixel artists in the 1990s got their inspiration or motives from Boris Vallejo. <em>Suny</em> wrote in the Éditions64K book about the Amiga demoscene:</p>

<blockquote>
<em>
"My main influence was Boris Vallejo who seems to have inspired a lot of artists at the time. I then got interested in design, photography, painting and animation."
</em>
</blockquote>

<p>Then <em>Suny</em> went on to close out his section of the Éditions64K book with the following:</p>

<blockquote>
<em>
"With time, I realized I was not a real artist. I had rached a very good technical level and could reproduce an existing image perfectly. However, this is not the definition of an artist, and I am not super creative. This is why I became a Technical Artist in the video game industry, and now I am working at Apple."
</em>
</blockquote>

<p>This started out somewhat discouraging, but then we see that his meticulous reproductions of Vallejo’s work and other pixel art helped him find his strengths and discover new professional roles.</p>


          <p>
            <img src="https://marincomics.com/img/vallejo/hardcore-facet-vallejo.jpg" alt="Another copy of Vallejo's art, this time by Facet"><br>
            <em>Some sceners only use parts of a Vallejo painting, like in this example by Facet from the Hardcore demo.</em>
          </p>

          <p>
            In a post on
            <a href="https://m.pouet.net/topic.php?which=9040&amp;page=1" target="_blank" rel="noopener">pouet.net</a>,
            user <em>friol</em> asked what the point of re-drawing paintings by others actually is. He even
            specifically refered to sceners who copy Boris Vallejo's work:
          </p>

          <blockquote>
            <em>
              "Oh well... I knew the demoscene was ripping Boris Vallejo, but not that much (we are talking of at
              least of one hundred pictures). But while some pictures are... I would call them "re-elaborations",
              others are 1-1 copies.<p>
              
              What's the point of that?"
            </p></em>
          </blockquote>

          <p>Another user, <em>gaspode</em> replied to <em>friol's</em> post:</p>

          <blockquote>
            <em>
              "That's the dark side of the scene, I think. I can not understand why obviously talented people copy
              pictures nearly 1:1. Even if they were re-drawn or re-pixeled or whatever, they are still copys for me
              (because the idea, colors and structure was stolen). Other people apparently don't have problems with
              that but for me everytime I discover such a thing my respect for the copying artist decreases and first
              of all I cannot enjoy their future artworks anymore, cause I always think they could have been copied."
            </em>
          </blockquote>

          <p>
            This opinion is well-supported by many sceners. User <em>ok3anos</em> pointed out that there is another
            side to copying artwork as long as the original artist gets credited:
          </p>

          <blockquote>
            <em>
              "Well, consider this: In painting, masters have always been copied by the apprentices to let them learn
              the basis techniques.<br>
              It does not disturb me at all to see pixel artists copying Boris Vallejo or others to increase their
              pixel technique as long as the original artist is credited in a way or another.<br>
              Would be more annoying if some of the works were just simple scans reworked a bit (which I suspect
              some...)</em>
          </blockquote>

          <p>
            <em>ok3anos</em> reply can be interpreted as a defense of copying artwork as long as the scener remains
            honest. A link can be found in this thread on pouet that points to the
            <a href="http://www.kameli.net/nocopy/" target="_blank" rel="noopener">No-Copy site</a>. You can find a
            gallery of images created by sceners but copied from other artists. There are a lot of examples of swiped
            Vallejo art.
          </p>

          <p>
            <img src="https://marincomics.com/img/vallejo/no-copy.jpg" alt="A screenshot of the No Copy website showing how a scener copied Vallejo's painting of a merman and a mermaid copulating"><br>
            <em>The <a href="http://www.kameli.net/nocopy/" target="_blank" rel="noopener">No-Copy</a> website. If we
              disregard for a moment that there are so many examples of swipes of Vallejo's merman and mermaid image,
              and look closely at this particular copy, then we can see that it looks like an actual painstaking
              recreation and not a scan (though this is only my personal feeling).</em>
          </p>

          <p>
            The first thing that strikes me, just looking at the swipes on the
            <a href="http://www.kameli.net/nocopy/" target="_blank" rel="noopener">No-Copy</a> site, is how often
            Vallejo's painting of the merman and the mermaid was copied. I never wanted to know what it looks like
            when merpeople have sex. The second thing that strikes me is that many of the graphics definitely look
            like full scans or collages of partial scans.
          </p>

          <p>
            Yet, I think some of them are not scans but incredible reproductions. If my suspicion is true, I
            personally believe it takes a lot of craft to reproduce a painting as pixel art with the comparatively low
            resolution and limited color palette of a Commodore Amiga or a PC with VGA graphics. The most commonly
            used graphics mode for a regular Amiga was 320 x 256 with 32 colors (or 64 colors if extra halfbrite mode
            was used). The later AGA chipset in the Amiga 1200 and 4000 had a graphics mode comparable to the PC's VGA
            graphics. When the <a href="http://www.kameli.net/nocopy/" target="_blank" rel="noopener">No-Copy</a> site
            was published in the second half of the 1990s, the most common VGA mode used for pixel graphics was 320 x
            200 with 256 colors, though some people used the higher resolution of 640 x 480, also with 256 colors. It
            takes patience and a lot of precision to copy Vallejo's art in a pixel paint program like
            <em>Deluxe Paint</em> or <em>Brilliance</em>.
          </p>

<p>My journey through Vallejo's influence on the demoscene brought me to the essay <a href="https://tarnkappe.info/jurassic-pack/an-original-picture-253480.html" target="_blank" rel="noopener">An Original Picture</a> written in 2007 by <em>Lars <a href="https://demozoo.org/sceners/10963/" target="_blank" rel="noopener">Ghandy</a> Sobiraj</em>, the main editor of the longest running Amiga diskmag <a href="https://demozoo.org/productions/tagged/jurassic-pack/" target="_blank" rel="noopener">Jurassic Pack</a>. He is very critical of pixel artists and graphicians who copy art or photos. He not only condemns scans but even folks who hand pixel their graphics based on someone else's paintings. He mentions a traditional, analog technique in which a grid is overlaid on both the original image and the drawing surface. This allows the copying artist to focus on replicating one small part at a time. This method ensured accurate proportions and alignment, helping the artist recreate the image in precise detail. However, he does not consider this technique to be high art.</p>

<p>Lars Sobiraj writes:</p>

<blockquote>
<em>
"The biggest shame with copied motives are the artists never telling others if it was copied or not. They just secretly hope not to be discovered by the scene police."
</em>
</blockquote>

<p>I actually support this statement. If you copy something, then make it clear that you are. This is the bile-filled finale of <em>Lars Sobiraj's</em> essay, like a curse upon copying artists (the spelling is unchanged from the original):</p>

<blockquote>
<em>
"Here is a last message from me: You took the express road for your success. But you are worthless peace of junk. No own fantasies, using grids, copying ideas. Damn lame. You will never develop yourself, and even if you get place #1 in the charts or by your scene friends, that is nothing compared to real life true graphicians based on the bigger world outside the scene.<p>
(b)lame yourself"
</p></em>
</blockquote>

<p>I understand the feeling of betrayal one might feel when confronted with artists who so obviously cheat. Yet I feel that this is also a bit too harsh.</p>

          <p>
            All that being said, I don't think copying Vallejo's art is reprehensible as long as you credit the
            original artist and learn something from the recreation, perhaps by altering it enough to make it
            distinct.
          </p>

<p>
Criticizing other artists for copying the works of Boris Vallejo becomes somewhat ironic when we consider Vallejo's own creative process. Vallejo often uses models and bodybuilders as references, photographing them in specific poses, and then using these images as a foundation for his paintings. In this way, imitation plays a significant role even in his artistic method.</p>

<p>However, what distinguishes Vallejo is his remarkable ability to synthesize and transform these real-life references into something new and beautiful through his extraordinary skill with paint and brush. His artistry lies not just in copying but in elevating these references into highly imaginative and dynamic works, blending realism with fantasy. This process shows that while imitation may be part of art, true creativity comes from how those references are interpreted and reimagined.
</p>

          <h2 id="vallejo-03">How I Learned Not To Worry And Love Color Limitations</h2>
 
          <p>
            I wanted to copy a Vallejo painting in my own style, using a super limited color palette. And, of course,
            I'd give credit to good ole Boris! But first, I need to wax poetic about the beauty of limited color
            palettes.
          </p>

          <p>
            <img src="https://marincomics.com/img/vallejo/ochre-palette.jpg" alt="The four shades of ochre that I wanted to use for my recreation of a Vallejo painting"><br>
            <em>I chose to use only these four colors for my recreation of a Vallejo painting.</em>
          </p>

          <p>
            I used to paint pixel art on an Atari ST, which was limited to 16 colors on screen at the same time from a
            palette of 512 available shades. I always found this limiting and frustrating, especially considering that
            the Atari ST's main competitor, the Commodore Amiga, could display 32 and even 64 colors from 4,096
            available shades.
          </p>

          <p>
            Then, I started participating in graphics competitions at demoparties, using ridiculously limited six- to
            eight-color palettes. That's when I discovered an interesting challenge.
          </p>

          <p>
            There's something exciting about working within a limited color palette. I found that the constraints
            forced me to focus more on composition, shapes, and contrast. I had to make the most of the few colors I
            had.
          </p>

          <p>
            It might be unfair to call the limited color palette required for the Evoke graphics compo "old school"
            (or "old skool," if you're too cool for "school"). There are no restrictions on resolution, meaning I can
            use much higher resolutions than any retro "old school" machine was capable of. The results can look quite
            modern, and the style can be deliberately atmospheric due to the limited color palette.
          </p>

          <h2 id="vallejo-04">Video Walkthrough of Line Art Drawing</h2>

          <p>
            <iframe src="https://www.youtube.com/embed/Puq5XI2Cknk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
          </p>
          <p>
            <em>A full walkthrough of the process of painting the picture.</em>
          </p>

          <h2 id="vallejo-05">Drawing A Vallejo in Line Art and Four Colors</h2>

          <p>
            So I decided to challenge myself by limiting a drawing to four colors. As a callback to the old days of
            the demoscene, I used a Boris Vallejo painting as my model. I chose Vallejo's "Gillkarth's Odyssey (The
            Axe Man)" from 1998. I used Procreate on my iPad Pro with the Apple Pencil. I absolutely adore Procreate.
            It is a phenomenally frictionless and intuitive painting tool.
          </p>

          <p>
            I ended up quite happy with my copy of it as line art. After a few dead ends in coloring, I was also
            pleased with how it turned out using only four colors.
          </p>

          <div>
            <p>
                <img src="https://marincomics.com/img/vallejo/line-art-01.jpg" alt="First step in the process of drawing the line art version of Vallejo's painting">

                <em>Step 1</em>
              </p>
            <p>
                <img src="https://marincomics.com/img/vallejo/line-art-02.jpg" alt="Second step in the process of drawing the line art version of the Vallejo's painting">

                <em>Step 2</em>
              </p>
            <p>
                <img src="https://marincomics.com/img/vallejo/line-art-03.jpg" alt="Third step in the process of drawing the line art version of the Vallejo's painting">

                <em>Step 3</em>
              </p>
            <p>
                <img src="https://marincomics.com/img/vallejo/line-art-04.jpg" alt="Fourth step in the process of drawing the line art version of the Vallejo's painting">

                <em>Step 4</em>
              </p>
          </div>

          <p>
            There was one odd thing I only realized while making the drawing: I have no idea what the barbarian fellow
            in the center is swinging his axe at. It might be that he's trying to chop into the snake, which is
            actually facing away from him and minding its own business. Or maybe he's attacking the viewer of the
            image. It could even be that he's being influenced by the two demon-like creatures behind him to attack.
            In the original image, his eyes are red, as though he's possessed. To this day, I don't know what this
            person is up to.
          </p>

          <p>
            I actually only learned that he's <em>not</em> Conan after I had started the drawing. I asked on the
            <a href="https://www.reddit.com/r/ConanTheBarbarian/comments/1fribzp/when_did_boris_vallejo_paint_this_picture_of/" target="_blank" rel="noopener">Conan Reddit,</a>
            if anyone had more information about the painting, and I was quickly corrected. Reddit user <em>mattmirth</em> provided the real name of the paintin. And another user wrote: <em>"Every Boris Vallejo painting is Conan, he just doesn't know it. /s".</em> This comment got the most upvotes.
          </p>

          <p>
            I had a lot of fun drawing this piece. I learned a lot about working within color limitations and how to
            make the most of them. I also rekindled my appreciation for the art of Boris Vallejo. While I might not be
            a fan of his work anymore, I can see why he was so popular and influential. I understand why so many pixel
            artists copied his work.
          </p>

          <p>
            <img src="https://marincomics.com/img/vallejo/vallejo-recreation-drawing-4c.jpg" alt="The final line art version of the Vallejo painting with only four colors"><br>
            <em> And here is my final line art version of Vallejo's Axe Man from "Gillkarth's Odyssey" called <a href="https://demozoo.org/graphics/358357/" target="_blank" rel="noopener">Wrath of the Vallerian</a> (after Boris Vallejo).</em>
          </p>
        </article>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI chipmaker Cerebras files for IPO to take on Nvidia (163 pts)]]></title>
            <link>https://www.cnbc.com/2024/09/30/cerebras-files-for-ipo.html</link>
            <guid>41702789</guid>
            <pubDate>Mon, 30 Sep 2024 22:26:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2024/09/30/cerebras-files-for-ipo.html">https://www.cnbc.com/2024/09/30/cerebras-files-for-ipo.html</a>, See on <a href="https://news.ycombinator.com/item?id=41702789">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-108039780" data-test="InlineImage"><p>Andrew Feldman, co-founder and CEO of Cerebras Systems, speaks at the Collision conference in Toronto on June 20, 2024.</p><p>Ramsey Cardy | Sportsfile | Collision | Getty Images</p></div><div><p>Artificial intelligence chip startup Cerebras Systems on Monday filed its prospectus for an initial public offering, with plans to trade under the ticker symbol "CBRS" on the Nasdaq.</p><p>Cerebras competes with <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-1"><a href="https://www.cnbc.com/quotes/NVDA/">Nvidia</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span>, whose graphics processing units are the industry's choice for training and running AI models. Cerebras says on its website that its WSE-3 chip comes with more cores and memory than Nvidia's popular H100. It's also a physically larger chip. In addition to selling chips, Cerebras offers cloud-based services that rely on its own computing clusters.</p><p>Cerebras had a net loss of $66.6 million in the first six months of 2024 on $136.4 million in sales, according to the filing. For the fist six months of 2023, the company had a net loss of $77.8 million and $8.7 million in sales.</p><p>For the full year of 2023, Cerebras reported a net loss of $127.2 million on revenue of $78.7 million.</p><p>The company reported a net loss of $50.9 million on $69.8 million in revenue in the second quarter, compared with a $26.2 million loss and $5.7 million in revenue in the same period a year earlier.</p><p>Operating expenses have increased this year in part because of higher personnel costs to support revenue growth, the company said.</p><p>AI chips are a growing and crowded market. Cloud providers <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-2"><a href="https://www.cnbc.com/quotes/AMZN/">Amazon</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span>, <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-3"><a href="https://www.cnbc.com/quotes/GOOGL/">Google</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> and <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-4"><a href="https://www.cnbc.com/quotes/MSFT/">Microsoft</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> have developed their own AI chips. The company said that Group 42, <a href="https://www.cnbc.com/2024/08/25/a-controversial-mideast-partner-to-microsoft-openai-global-ambitions.html">a UAE-based AI firm</a> that counts Microsoft as an investor, accounted for 83% of Cerebras's revenue last year.</p></div><div id="ArticleBody-InlineImage-107422916" data-test="InlineImage"><p>Cerebras' WSE-3 chip is one example of new silicon from upstarts designed to run and train artificial intelligence.</p><p>Cerebras Systems</p></div><div><p>In addition to Nvidia, Cerebras cites AMD, Intel, Microsoft and Google as competitors, "as well as internally developed custom application-specific integrated circuits and a variety of private companies."</p><p>Taiwan Semiconductor Manufacturing Company makes the Cerebras chips. Cerebrus warned investors that any possible supply chain disruptions may hurt the company.</p><p>Cerebras was founded in 2016 and is based in Sunnyvale, California. Andrew Feldman, the startup's co-founder and CEO, sold server startup SeaMicro to <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-6"><a href="https://www.cnbc.com/quotes/AMD/">AMD</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> for $355 million in 2012.</p><p>The company <a href="https://cerebras.ai/press-release/cerebras-systems-raises-250m-in-funding-for-over-4b-valuation-to-advance-the-future-of-artificial-intelligence-compute/" target="_blank">said</a> in 2021 that it was valued at over $4 billion in a $250 million funding round.In May, G42 committed to purchasing $1.43 billion in orders from Cerebras before March 2025, according to the filing.&nbsp;G42 currently owns under 5% of Cerebras' Class A shares, and the firm has an option to purchase more depending on how much Cerebras product it buys.</p><p>The technology IPO market has generally been sparse in 2024, as higher interest rates pushed investors toward profitable assets. Social media app Reddit <a href="https://www.cnbc.com/2024/03/21/reddit-ipo-rddt-starts-trading-on-nyse.html">went public</a> on the New York Stock Exchange in March, and data management software maker Rubrik <a href="https://www.cnbc.com/2024/04/25/rubrik-ipo-rbrk-starts-trading-on-new-york-stock-exchange.html">followed</a> in April. Earlier this month, the Federal Reserve pushed ahead with its <a href="https://www.cnbc.com/2024/09/18/fed-cuts-rates-september-2024-.html">first rate cut</a> since 2020, prompting gains in the tech-heavy Nasdaq Composite index.</p><p>Neither Morgan Stanley nor Goldman Sachs, the two leading tech investment banks, are on the deal. Citigroup and Barclays are leading the offering.</p><p>The biggest investor in Cerebras is venture firm Foundation Capital, followed by Benchmark and Eclipse Ventures. Alpha Wave, Coatue and Altimeter each own at least 5% as well, according to the filing. Other investors include OpenAI CEO Sam Altman and Sun Microsystems co-founder Andy Bechtolsheim. The only individual who owns 5% or more is Feldman.</p><p><strong>WATCH:</strong> <a href="https://www.cnbc.com/video/2024/08/29/cerebras-ceo-our-inference-offering-is-20x-faster-than-nvidias-and-a-fraction-of-the-price.html">Cerebras CEO: Our inference offering is 20x faster than Nvidia's and a fraction of the price</a></p></div><div id="Placeholder-ArticleBody-Video-108027193" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000350179" aria-labelledby="Placeholder-ArticleBody-Video-108027193"><p><img src="https://image.cnbcfm.com/api/v1/image/108027195-17249456671724945665-36031374255-1080pnbcnews.jpg?v=1724945667&amp;w=750&amp;h=422&amp;vtcrop=y" alt="Cerebras CEO: Our inference offering is 20x faster than Nvidia's and a fraction of the price"><span></span><span></span></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[BorgBackup 2.0 supports Rclone – over 70 cloud providers in addition to SSH (132 pts)]]></title>
            <link>https://borgbackup.readthedocs.io/en/2.0.0b11/changes.html#version-2-0-0b11-2024-09-26</link>
            <guid>41702315</guid>
            <pubDate>Mon, 30 Sep 2024 21:24:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://borgbackup.readthedocs.io/en/2.0.0b11/changes.html#version-2-0-0b11-2024-09-26">https://borgbackup.readthedocs.io/en/2.0.0b11/changes.html#version-2-0-0b11-2024-09-26</a>, See on <a href="https://news.ycombinator.com/item?id=41702315">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="right-column">
            
  <section id="important-notes-2-x">
<span id="important-notes"></span>
<p>This section provides information about security and corruption issues.</p>
<p>(nothing to see here yet)</p>
</section>
<section id="upgrade-notes">
<span id="upgradenotes2"></span><h2>Upgrade Notes<a href="#upgrade-notes" title="Link to this heading">¶</a></h2>
<section id="borg-1-2-x-1-4-x-to-borg-2-0">
<h2>borg 1.2.x/1.4.x to borg 2.0<a href="#borg-1-2-x-1-4-x-to-borg-2-0" title="Link to this heading">¶</a></h2>
<p>Compatibility notes:</p>
<ul>
<li><p>this is a major “breaking” release that is not compatible with existing repos.</p>
<p>We tried to put all the necessary “breaking” changes into this release, so we
hopefully do not need another breaking release in the near future. The changes
were necessary for improved security, improved speed and parallelism,
unblocking future improvements, getting rid of legacy crap and design
limitations, having less and simpler code to maintain.</p>
<p>You can use “borg transfer” to transfer archives from borg 1.2/1.4 repos to
a new borg 2.0 repo, but it will need some time and space.</p>
<p>Before using “borg transfer”, you must have upgraded to borg &gt;= 1.2.6 (or
another borg version that was patched to fix CVE-2023-CVE-2023-36811) and
you must have followed the upgrade instructions at top of the change log
relating to manifest and archive TAMs (borg2 just requires these TAMs now).</p>
</li>
<li><p>command line syntax was changed, scripts and wrappers will need changes:</p>
<ul>
<li><p>you will usually either export BORG_REPO=&lt;MYREPO&gt; into your environment or
call borg like: “borg -r &lt;MYREPO&gt; &lt;COMMAND&gt;”.
in the docs, we usually omit “-r …” for brevity.</p></li>
<li><p>the scp-style REPO syntax was removed, please use <a href="ssh://">ssh://</a>…, #6697</p></li>
<li><p><a href="ssh://">ssh://</a> URLs: removed support for /~otheruser/, #6855.
If you used this, just replace it by: <a href="ssh://user@host:port/home/otheruser/">ssh://user@host:port/home/otheruser/</a></p></li>
<li><p>-P / --prefix option was removed, please use the similar -a / --match-archives.</p></li>
<li><p>archive names don’t need to be unique anymore. to the contrary:
it is now strongly recommended to use the identical name for borg create
within the same series of archives to make borg work more efficiently.
the name now identifies a series of archive, to identify a single archive
please use aid:&lt;archive-hash-prefix&gt;, e.g.: borg delete aid:d34db33f</p></li>
<li><p>the archive id is always given separately from the repository
(differently than with borg 1.x you must not give repo::archive).</p></li>
<li><p>the series name or archive id is either given as a positional parameter,
like:</p>
<ul>
<li><p>borg create documents ~/Documents</p></li>
<li><p>borg diff aid:deadbeef aid:d34db33f</p></li>
</ul>
</li>
<li><p>or, if the command makes sense for an arbitrary amount of archives, archives
can be selected using a glob pattern, like:</p>
<ul>
<li><p>borg delete -a ‘sh:myarchive-2024-??-??’</p></li>
<li><p>borg recreate -a ‘sh:myarchive-2024-??-??’</p></li>
</ul>
</li>
<li><p>some borg 1.x commands that supported working on a repo AND on an archive
were split into 2 commands, some others were renamed:</p>
<ul>
<li><p>borg 2 repo commands:</p>
<ul>
<li><p>borg repo-create  # was: borg init</p></li>
<li><p>borg repo-list</p></li>
<li><p>borg repo-info</p></li>
<li><p>borg repo-delete</p></li>
<li><p>borg repo-compress</p></li>
<li><p>borg repo-space</p></li>
</ul>
</li>
<li><p>borg 2 archive commands:</p>
<ul>
<li><p>borg create NAME …</p></li>
<li><p>borg list ID</p></li>
<li><p>borg extract ID …</p></li>
<li><p>borg diff ID1 ID2</p></li>
<li><p>borg rename ID NEWNAME</p></li>
<li><p>borg info ID</p></li>
<li><p>borg delete ID</p></li>
<li><p>borg recreate ID …</p></li>
<li><p>borg mount -a ID mountpoint …</p></li>
</ul>
</li>
</ul>
<p>For more details, please consult the docs or --help option output.</p>
</li>
<li><p>create/recreate/import-tar --timestamp: defaults to local timezone
now (was: UTC)</p></li>
</ul>
</li>
<li><p>some deprecated options were removed:</p>
<ul>
<li><p>removed --remote-ratelimit (use --upload-ratelimit)</p></li>
<li><p>removed --numeric-owner (use --numeric-ids)</p></li>
<li><p>removed --nobsdflags (use --noflags)</p></li>
<li><p>removed --noatime (default now, see also --atime)</p></li>
<li><p>removed --save-space option (does not change behaviour)</p></li>
</ul>
</li>
<li><p>removed --bypass-lock option</p></li>
<li><p>removed borg config command (only worked locally anyway)</p></li>
<li><p>using --list together with --progress is now disallowed (except with --log-json), #7219</p></li>
<li><p>the --glob-archives option was renamed to --match-archives (the short option
name -a is unchanged) and extended to support different pattern styles:</p>
<ul>
<li><p>id: for identical string match (this is the new default!)</p></li>
<li><p>sh: for shell pattern / globbing match (this was used by --glob-archives)</p></li>
<li><p>re: for regular expression match</p></li>
</ul>
<p>So you might need to edit your scripts like e.g.:</p>
<div><pre><span></span><span>borg</span> <span>1.</span><span>x</span><span>:</span> <span>--</span><span>glob</span><span>-</span><span>archives</span> <span>'myserver-2024-*'</span>
<span>borg</span> <span>2.0</span><span>:</span> <span>--</span><span>match</span><span>-</span><span>archives</span> <span>'sh:myserver-2024-*'</span>
</pre></div>
</li>
<li><p>use platformdirs 3.x.x instead of home-grown code. Due to that:</p>
<ul>
<li><p>XDG_*_HOME is not honoured on macOS and on Windows.</p></li>
<li><p>BORG_BASE_DIR can still be used to enforce some base dir + .config/ or .cache/.</p></li>
<li><p>the default macOS config and cache dir will now be in ~/Library/Application Support/borg/.</p></li>
</ul>
</li>
<li><p>create: different included/excluded status chars, #7321</p>
<ul>
<li><p>dry-run: now uses “+” (was: “-”) and “-” (was: “x”) for included/excluded status</p></li>
<li><p>non-dry-run: now uses “-” (was: “x”) for excluded files</p></li>
</ul>
<p>Option --filter=… might need an update, if you filter for the status chars
that were changed.</p>
</li>
<li><p>borg is now more strict and disallows giving some options multiple times -
if that makes no sense. Highlander options, see #6269. That might make scripts
fail now that somehow “worked” before (but maybe didn’t work as intended due to
the contradicting options).</p></li>
</ul>
</section>
</section>
<section id="change-log-2-x">
<span id="changelog"></span><h2>Change Log 2.x<a href="#change-log-2-x" title="Link to this heading">¶</a></h2>
<section id="version-2-0-0b11-2024-09-26">
<h2>Version 2.0.0b11 (2024-09-26)<a href="#version-2-0-0b11-2024-09-26" title="Link to this heading">¶</a></h2>
<p>Please note:</p>
<p>Beta releases are only for testing on NEW repos - do not use for production.</p>
<p>For upgrade and compatibility hints, please also read the section “Upgrade Notes”
above.</p>
<p>New features:</p>
<ul>
<li><p>Support rclone:// URLs for borg repositories.</p>
<p>This enables 70+ cloud storage products, including Amazon S3, Backblaze B2,
Ceph, Dropbox, ftp(s), Google Cloud Storage, Google Drive, Microsoft Azure,
Microsoft OneDrive, OpenStack Swift, pCloud, Seafile, sftp, SMB / CIFS and
WebDAV!</p>
<p>See <a href="https://rclone.org/">https://rclone.org/</a> for more details.</p>
</li>
<li><p>Parallel operations in same repo from same client (same user/machine).</p></li>
<li><p>Archive series feature, #7930.</p>
<p>TL;DR: a NAME now identifies a series of identically named archives,
to identify a specific single archive, use aid:&lt;archive hash&gt;.</p>
<p>in borg 1.x, we used to put a timestamp into the archive name, because borg1
required unique archive names.</p>
<p>borg2 does not require unique archive names, but it encourages you to even
use a identical archive names within the same SERIES of archives, e.g. you
could backup user files to archives named “user-files” and system files to
archives named “system-files”.
that makes matching (e.g. for prune, for the files cache, …) much simpler
and borg now KNOWS which archives belong to the same series (because they all
have the same name).</p>
</li>
<li><p>info/delete/prune: allow positional NAME argument, e.g.:</p>
<ul>
<li><p>borg prune --keep-daily 30 &lt;seriesname&gt;</p></li>
<li><p>borg delete aid:&lt;archive hash&gt;</p></li>
</ul>
</li>
<li><p>create: also archive inode number, #8362</p>
<p>Borg can use this when using archive series to rebuild the local files cache
from the previous archive (of the same series) in the repository.</p>
</li>
</ul>
<p>Fixes:</p>
<ul>
<li><p>Remove superfluous repository.list() call. for high latency repos
(like sftp, cloud), this improves performance of borg check and compact.</p></li>
<li><p>repository.list: refresh lock more frequently</p></li>
<li><p>misc. commands fixed for non-unique archive names</p></li>
<li><p>remote: allow get_manifest method</p></li>
<li><p>files cache: fix rare race condition with data loss potential, #3536</p></li>
<li><p>storelocking: misc. fixes / cleanups</p></li>
</ul>
<p>Other changes:</p>
<ul>
<li><p>Cache the chunks index in the repository, #8397.
Improves high latency repo performance for most commands compared to b10.</p></li>
<li><p>repo-compress: faster by using chunks index rather than repository.list().</p></li>
<li><p>Files cache entries now have both ctime AND mtime.</p></li>
<li><p>Borg updates the ctime and mtime of known and “unchanged” files, #4915.</p></li>
<li><p>Rebuild files cache from previous archive in same series, #8385.</p></li>
<li><p>Reduce RAM usage by splitting the files cache by archive series, #5658.</p></li>
<li><p>Remove AdHocCache, remove BORG_CACHE_IMPL (we only have one implementation).</p></li>
<li><p>Docs: user@ and :port are optional in sftp and ssh URLs.</p></li>
<li><p>CI: re-enable windows build after fixing it.</p></li>
<li><p>Upgrade pyinstaller to 6.10.0.</p></li>
<li><p>Increase IDS_PER_CHUNK, #6945.</p></li>
</ul>
</section>
<section id="version-2-0-0b10-2024-09-09">
<h2>Version 2.0.0b10 (2024-09-09)<a href="#version-2-0-0b10-2024-09-09" title="Link to this heading">¶</a></h2>
<p>New features:</p>
<ul>
<li><p>borgstore based repository, file:, ssh: and sftp: for now, more possible.</p></li>
<li><p>repository stores objects separately now, not using segment files.
this has more fs overhead, but needs much less I/O because no segment
files compaction is required anymore. also, no repository index is
needed anymore because we can directly find the objects by their ID.</p></li>
<li><p>locking: new borgstore based repository locking with automatic stale
lock removal (if lock does not get refreshed, if lock owner process is dead).</p></li>
<li><p>simultaneous repository access for many borg commands except check/compact.
the cache lock for adhocwithfiles is still exclusive though, so use
BORG_CACHE_IMPL=adhoc if you want to try that out using only 1 machine
and 1 user (that implementation doesn’t use a cache lock). When using
multiple client machines or users, it also works with the default cache.</p></li>
<li><p>delete/prune: much quicker now and can be undone.</p></li>
<li><p>check --repair --undelete-archives: bring archives back from the dead.</p></li>
<li><p>repo-space: manage reserved space in repository (avoid dead-end situation if
repository filesystem runs full).</p></li>
</ul>
<p>Bugs/issues fixed:</p>
<ul>
<li><p>a lot! all linked from PR #8332.</p></li>
</ul>
<p>Other changes:</p>
<ul>
<li><p>repository: remove transactions, solved differently and much simpler now
(convergence and write order primarily).</p></li>
<li><p>repository: replaced precise reference counting with “object exists in repo?”
and “garbage collection of unused objects”.</p></li>
<li><p>cache: remove transactions, remove chunks cache.
removed LocalCache, BORG_CACHE_IMPL=local, solving all related issues.
as in beta 9, adhowwithfiles is the default implementation.</p></li>
<li><p>compact: needs the borg key now (run it clientside), -v gives nice stats.</p></li>
<li><p>transfer: archive transfers from borg 1.x need the --from-borg1 option</p></li>
<li><p>check: reimplemented / bigger changes.</p></li>
<li><p>code: got rid of a metric ton of not needed complexity.
when borg does not need to read borg 1.x repos/archives anymore, after
users have transferred their archives, even much more can be removed.</p></li>
<li><p>docs: updated / removed outdated stuff</p></li>
<li><p>renamed r* commands to repo-*</p></li>
</ul>
</section>
<section id="version-2-0-0b9-2024-07-20">
<h2>Version 2.0.0b9 (2024-07-20)<a href="#version-2-0-0b9-2024-07-20" title="Link to this heading">¶</a></h2>
<p>New features:</p>
<ul>
<li><p>add BORG_CACHE_IMPL, default is “adhocwithfiles” to test the new cache
implementation, featuring an adhoc non-persistent chunks cache and a
persistent files cache. See the docs for other values.</p>
<p>Requires to run “borg check --repair --archives-only” to delete orphaned
chunks before running “borg compact” to free space! These orphans are
expected due to the simplified refcounting with the AdHocFilesCache.</p>
</li>
<li><p>make BORG_EXIT_CODES=”modern” the default, #8110</p></li>
<li><p>add BORG_USE_CHUNKS_ARCHIVE env var, #8280</p></li>
<li><p>automatically rebuild cache on exception, #5213</p></li>
</ul>
<p>Bug fixes:</p>
<ul>
<li><p>fix Ctrl-C / SIGINT behaviour for pyinstaller-made binaries, #8155</p></li>
<li><p>delete: fix error handling with Ctrl-C</p></li>
<li><p>rcompress: fix error handling with Ctrl-C</p></li>
<li><p>delete: fix error handling when no archive is specified, #8256</p></li>
<li><p>setup.py: fix import error reporting for cythonize import, see #8208</p></li>
<li><p>create: deal with EBUSY, #8123</p></li>
<li><p>benchmark: inherit options --rsh --remote-path, #8099</p></li>
<li><p>benchmark: fix return value, #8113</p></li>
<li><p>key export: fix crash when no path is given, fix exception handling</p></li>
</ul>
<p>Other changes:</p>
<ul>
<li><p>setup.py: detect noexec build fs issue, see #8208</p></li>
<li><p>improve acl_get / acl_set error handling (forward port from 1.4-maint)</p></li>
<li><p>allow msgpack 1.1.0</p></li>
<li><p>vagrant: use pyinstaller 6.7.0</p></li>
<li><p>use Python 3.11.9 for binary builds</p></li>
<li><p>require Cython 3.0.3 at least, #8133</p></li>
<li><p>docs: add non-root deployment strategy</p></li>
</ul>
</section>
<section id="version-2-0-0b8-2024-02-20">
<h2>Version 2.0.0b8 (2024-02-20)<a href="#version-2-0-0b8-2024-02-20" title="Link to this heading">¶</a></h2>
<p>New features:</p>
<ul>
<li><p>create: add the slashdot hack, update docs, #4685</p></li>
<li><p>BORG_EXIT_CODES=modern: optional more specific return codes (for errors and warnings).</p>
<p>The default value of this new environment variable is “legacy”, which should result in
a behaviour similar to borg 1.2 and older (only using rc 0, 1 and 2).
“modern” exit codes are much more specific (see the internals/frontends docs).</p>
</li>
<li><p>implement “borg version” (shows client and server version), #7829</p></li>
</ul>
<p>Fixes:</p>
<ul>
<li><p>docs: CVE-2023-36811 upgrade steps: consider checkpoint archives, #7802</p></li>
<li><p>check/compact: fix spurious reappearance of orphan chunks since borg 1.2, #6687 -
this consists of 2 fixes:</p>
<ul>
<li><p>for existing chunks: check --repair: recreate shadow index, #7897 #6687</p></li>
<li><p>for newly created chunks: update shadow index when doing a double-put, #7896 #5661</p></li>
</ul>
<p>If you have experienced issue #6687, you may want to run borg check --repair
after upgrading to borg 1.2.7 to recreate the shadow index and get rid of the
issue for existing chunks.</p>
</li>
<li><p>check: fix return code for index entry value discrepancies</p></li>
<li><p>LockRoster.modify: no KeyError if element was already gone, #7937</p></li>
<li><p>create --X-from-command: run subcommands with a clean environment, #7916</p></li>
<li><p>list --sort-by: support “archive” as alias of “name”, #7873</p></li>
<li><p>fix rc and msg if arg parsing throws an exception, #7885</p></li>
<li><p>PATH: do not accept empty strings, #4221</p></li>
<li><p>fix invalid pattern argument error msg</p></li>
<li><p>zlib legacy decompress fixes, #7883</p></li>
</ul>
<p>Other changes:</p>
<ul>
<li><p>replace archive/manifest TAMs by typed repo objects (ro_type), docs, #7670</p></li>
<li><p>crypto: use a one-step kdf for session keys, #7953</p></li>
<li><p>remove recreate --recompress option, use the more efficient repo-wide “rcompress”.</p></li>
<li><p>include unistd.h in _chunker.c (fix for Python 3.13)</p></li>
<li><p>allow msgpack 1.0.7</p></li>
<li><p>allow platformdirs 4, #7950</p></li>
<li><p>use and require cython3</p></li>
<li><p>move conftest.py to src/borg/testsuite, #6386</p></li>
<li><p>use less setup.py, use pip and build</p></li>
<li><p>linux: use pkgconfig to find libacl</p></li>
<li><p>borg.logger: use same method params as python logging</p></li>
<li><p>create and use Brewfile, document “brew bundle” install (macOS)</p></li>
<li><p>blacken master branch</p></li>
<li><p>prevent CLI argument issues in scripts/glibc_check.py</p></li>
<li><p>pyproject.toml: exclude source files which have been compiled, #7828</p></li>
<li><p>sdist: dynamically compute readme (long_description)</p></li>
<li><p>init: better borg key export instructions</p></li>
<li><p>scripts/make.py: move clean, build_man, build_usage to there,
so we do not need to invoke setup.py directly, update docs</p></li>
<li><p>vagrant:</p>
<ul>
<li><p>use openssl 3.0 on macOS</p></li>
<li><p>add script for fetching borg binaries from VMs, #7989</p></li>
<li><p>use generic/openbsd7 box</p></li>
<li><p>netbsd: test on py311 only</p></li>
<li><p>remove debian 9 “stretch” box</p></li>
<li><p>use freebsd 14, #6871</p></li>
<li><p>use python 3.9.4 for tests, latest python 3.11.7 for binary builds</p></li>
<li><p>use pyinstaller 6.3.0</p></li>
</ul>
</li>
<li><p>docs:</p>
<ul>
<li><p>add typical PR workflow to development docs, #7495</p></li>
<li><p>improve docs for borg with-lock, add example #8024</p></li>
<li><p>create disk/partition sector backup by disk serial number</p></li>
<li><p>Add “check.rebuild_refcounts” message</p></li>
<li><p>not only attack/unsafe, can also be a fs issue, #7853</p></li>
<li><p>use virtualenv on Cygwin</p></li>
<li><p>readthedocs: also build offline docs, #7835</p></li>
<li><p>do not refer to setup.py installation method</p></li>
<li><p>how to run the testsuite using the dist package</p></li>
<li><p>requirements are defined in pyproject.toml</p></li>
</ul>
</li>
</ul>
</section>
<section id="version-2-0-0b7-2023-09-14">
<h2>Version 2.0.0b7 (2023-09-14)<a href="#version-2-0-0b7-2023-09-14" title="Link to this heading">¶</a></h2>
<p>New features:</p>
<ul>
<li><p>BORG_WORKAROUNDS=authenticated_no_key to extract from authenticated repos
without having the borg key, #7700</p></li>
</ul>
<p>Fixes:</p>
<ul>
<li><p>archive tam verify security fix, fixes CVE-2023-36811</p></li>
<li><p>remote logging/progress: use callback to send queued records, #7662</p></li>
<li><p>make_path_safe: remove test for backslashes, #7651</p></li>
<li><p>benchmark cpu: use sanitized path, #7654</p></li>
<li><p>create: do not try to read parent dir of recursion root, #7746</p></li>
</ul>
<p>Other changes:</p>
<ul>
<li><p>always implicitly require archive TAMs (all archives have TAMs since borg 1.2.6)</p></li>
<li><p>always implicitly require manifest TAMs (manifests have TAMs since borg 1.0.9)</p></li>
<li><p>rlist: remove support for {tam} placeholder, archives are now always TAM-authenticated.</p></li>
<li><p>support / test on Python 3.12</p></li>
<li><p>allow msgpack 1.0.6 (which has py312 wheels), #7810</p></li>
<li><p>manifest: move item_keys into config dict (manifest.version == 2 now), #7710</p></li>
<li><p>replace “datetime.utcfromtimestamp” to avoid deprecation warnings with Python 3.12</p></li>
<li><p>properly normalise paths on Windows (forward slashes, integrate drive letter into path)</p></li>
<li><p>Docs:</p>
<ul>
<li><p>move upgrade / compat. notes to own section, see #7546</p></li>
<li><p>fix borg delete examples, #7759</p></li>
<li><p>improve rcreate / related repos docs</p></li>
<li><p>automated-local.rst: use UUID for consistent udev rule</p></li>
<li><p>rewrite <cite>borg check</cite> docs, #7578</p></li>
<li><p>misc. other docs updates</p></li>
</ul>
</li>
<li><p>Tests / CI / Vagrant:</p>
<ul>
<li><p>major testsuite refactoring: a lot more tests now use pytest, #7626</p></li>
<li><p>freebsd: add some ACL tests, #7745</p></li>
<li><p>fix test_disk_full, #7617</p></li>
<li><p>fix failing test_get_runtime_dir test on OpenBSD, #7719</p></li>
<li><p>CI: run on ubuntu 22.04</p></li>
<li><p>CI: test building the docs</p></li>
<li><p>simplify flake8 config, fix some complaints</p></li>
<li><p>use pyinstaller 5.13.1 to build the borg binaries</p></li>
</ul>
</li>
</ul>
</section>
<section id="version-2-0-0b6-2023-06-11">
<h2>Version 2.0.0b6 (2023-06-11)<a href="#version-2-0-0b6-2023-06-11" title="Link to this heading">¶</a></h2>
<p>New features:</p>
<ul>
<li><p>diff: include changes in ctime and mtime, #7248</p></li>
<li><p>diff: sort JSON output alphabetically</p></li>
<li><p>diff --content-only: option added to ignore metadata changes</p></li>
<li><p>diff: add --format option, #4634</p></li>
<li><p>import-tar --ignore-zeros: new option to support importing concatenated tars, #7432</p></li>
<li><p>debug id-hash / parse-obj / format-obj: new debug commands, #7406</p></li>
<li><p>transfer --compression=C --recompress=M: recompress while transferring, #7529</p></li>
<li><p>extract --continue: continue a previously interrupted extraction, #1356</p></li>
<li><p>prune --list-kept/--list-pruned: only list the kept (or pruned) archives, #7511</p></li>
<li><p>prune --short/--format: enable users to format the list output, #3238</p></li>
<li><p>implement BORG_&lt;CMD&gt;_FORMAT env vars for prune, list, rlist, #5166</p></li>
<li><p>rlist: size and nfiles format keys</p></li>
<li><p>implement unix domain (ipc) socket support, #6183:</p>
<div><pre><span></span><span>borg</span> <span>serve</span> <span>--</span><span>socket</span>  <span># server side (not started automatically!)</span>
<span>borg</span> <span>-</span><span>r</span> <span>socket</span><span>:</span><span>///</span><span>path</span><span>/</span><span>to</span><span>/</span><span>repo</span> <span>...</span>  <span># client side</span>
</pre></div>
</li>
<li><p>add get_runtime_dir / BORG_RUNTIME_DIR (contains e.g. .sock and .pid file)</p></li>
<li><p>support shell-style alternatives, like: sh:image.{png,jpg}, #7602</p></li>
</ul>
<p>Fixes:</p>
<ul>
<li><p>do not retry on permission errors (pointless)</p></li>
<li><p>transfer: verify chunks we get using assert_id, #7383</p></li>
<li><p>fix config/cache dir compatibility issues, #7445</p></li>
<li><p>xattrs: fix namespace processing on FreeBSD, #6997</p></li>
<li><p>ProgressIndicatorPercent: fix space computation for wide chars, #3027</p></li>
<li><p>delete: remove --cache-only option, #7440.
for deleting the cache only, use: borg rdelete --cache-only</p></li>
<li><p>borg debug get-obj/put-obj: fixed chunk id</p></li>
<li><p>create: ignore empty paths, print warning, #5637</p></li>
<li><p>extract: support extraction of atime/mtime on win32</p></li>
<li><p>benchmark crud: use TemporaryDirectory below given path, #4706</p></li>
<li><p>Ensure that cli options specified with action=Highlander can only be set once, even
if the set value is a default value. Add tests for action=Highlander, #7500, #6269.</p></li>
<li><p>Fix argparse error messages from misc. validators (being more specific).</p></li>
<li><p>put security infos into data dir, add BORG_DATA_DIR env var, #5760</p></li>
<li><p>setup.cfg: remove setup_requires (we have a pyproject.toml for that), #7574</p></li>
<li><p>do not crash for empty archives list in borg rlist date based matching, #7522</p></li>
<li><p>sanitize paths during archive creation and extraction, #7108 #7099</p></li>
<li><p>make sure we do not get backslashes into item paths</p></li>
</ul>
<p>Other changes:</p>
<ul>
<li><p>allow msgpack 1.0.5 also</p></li>
<li><p>development.lock.txt: upgrade cython to 0.29.35, misc. other upgrades</p></li>
<li><p>clarify platformdirs requirements, #7393.
3.0.0 is only required for macOS due to breaking changes.
2.6.0 was the last breaking change for Linux/UNIX.</p></li>
<li><p>mount: improve mountpoint error msgs, see #7496</p></li>
<li><p>more Highlander options, #6269</p></li>
<li><p>Windows: simplify building (just use pip)</p></li>
<li><p>refactor toplevel exception handling, #6018</p></li>
<li><p>remove nonce management, related repo methods (not needed for borg2)</p></li>
<li><p>borg.remote: remove support for borg &lt; 1.1.0
($LOG, logging setup, exceptions, rpc tuple data format, version)</p></li>
<li><p>new remote and progress logging, #7604</p></li>
<li><p>borg.logger: add logging debugging functionality</p></li>
<li><p>add function to clear empty directories at end of compact process</p></li>
<li><p>unify scanning and listing of segment dirs / segment files, #7597</p></li>
<li><p>replace <cite>LRUCache</cite> internals with <cite>OrderedDict</cite></p></li>
<li><p>docs:</p>
<ul>
<li><p>add installation instructions for Windows</p></li>
<li><p>improve --one-file-system help and docs (macOS APFS), #5618 #4876</p></li>
<li><p>BORG_KEY_FILE: clarify docs, #7444</p></li>
<li><p>installation: add link to OS dependencies, #7356</p></li>
<li><p>update FAQ about locale/unicode issues, #6999</p></li>
<li><p>improve mount options rendering, #7359</p></li>
<li><p>make timestamps in manual pages reproducible.</p></li>
<li><p>describe performing pull-backups via ssh remote forwarding</p></li>
<li><p>suggest to use forced command when using remote-forwarding via ssh</p></li>
<li><p>fix some -a / --match-archives docs issues</p></li>
<li><p>incl./excl. options header, clarify --path-from-stdin exclusive control</p></li>
<li><p>add note about MAX_DATA_SIZE</p></li>
<li><p>update security support docs</p></li>
<li><p>improve patterns help</p></li>
</ul>
</li>
<li><p>CI / tests / vagrant:</p>
<ul>
<li><p>added pre-commit for linting purposes, #7476</p></li>
<li><p>resolved mode bug and added sleep clause for darwin systems, #7470</p></li>
<li><p>“auto” compressor tests: do not assume zlib is better than lz4, #7363</p></li>
<li><p>add stretch64 VM with deps built from source</p></li>
<li><p>misc. other CI / test fixes and updates</p></li>
<li><p>vagrant: add lunar64 VM, fix packages_netbsd</p></li>
<li><p>avoid long ids in pytest output</p></li>
<li><p>tox: package = editable-legacy, #7580</p></li>
<li><p>tox under fakeroot: fix finding setup_docs, #7391</p></li>
<li><p>check buzhash chunksize distribution, #7586</p></li>
<li><p>use debian/bookworm64 box</p></li>
</ul>
</li>
</ul>
</section>
<section id="version-2-0-0b5-2023-02-27">
<h2>Version 2.0.0b5 (2023-02-27)<a href="#version-2-0-0b5-2023-02-27" title="Link to this heading">¶</a></h2>
<p>New features:</p>
<ul>
<li><p>create: implement retries for individual fs files
(e.g. if a file changed while we read it, if a file had an OSError)</p></li>
<li><p>info: add used storage quota, #7121</p></li>
<li><p>transfer: support --progress</p></li>
<li><p>create/recreate/import-tar: add --checkpoint-volume option</p></li>
<li><p>support date-based matching for archive selection,
add --newer/--older/--newest/--oldest options, #7062 #7296</p></li>
</ul>
<p>Fixes:</p>
<ul>
<li><p>disallow --list with --progress, #7219</p></li>
<li><p>create: fix --list --dry-run output for directories, #7209</p></li>
<li><p>do no assume hardlink_master=True if not present, #7175</p></li>
<li><p>fix item_ptrs orphaned chunks of checkpoint archives</p></li>
<li><p>avoid orphan content chunks on BackupOSError, #6709</p></li>
<li><p>transfer: fix bug in obfuscated data upgrade code</p></li>
<li><p>fs.py: fix bug in f-string (thanks mypy!)</p></li>
<li><p>recreate: when --target is given, do not detect “nothing to do”, #7254</p></li>
<li><p>locking (win32): deal with os.rmdir/listdir PermissionErrors</p></li>
<li><p>locking: thread id must be parsed as hex from lock file name</p></li>
<li><p>extract: fix mtime when ResourceFork xattr is set (macOS specific), #7234</p></li>
<li><p>recreate: without --chunker-params borg shall not rechunk, #7336</p></li>
<li><p>allow mixing --progress and --list in log-json mode</p></li>
<li><p>add “files changed while reading” to Statistics class, #7354</p></li>
<li><p>fixed keys determination in Statistics.__add__(), #7355</p></li>
</ul>
<p>Other changes:</p>
<ul>
<li><p>use local time / local timezone to output timestamps, #7283</p></li>
<li><p>update development.lock.txt, including a setuptools security fix, #7227</p></li>
<li><p>remove --save-space option (does not change behaviour)</p></li>
<li><p>remove part files from final archive</p></li>
<li><p>remove --consider-part-files, related stats code, update docs</p></li>
<li><p>transfer: drop part files</p></li>
<li><p>check: show id of orphaned chunks</p></li>
<li><p>ArchiveItem.cmdline list-of-str -&gt; .command_line str, #7246</p></li>
<li><p>Item: symlinks: rename .source to .target, #7245</p></li>
<li><p>Item: make user/group/uid/gid optional</p></li>
<li><p>create: do not store user/group for stdin data by default, #7249</p></li>
<li><p>extract: chown only if we have u/g info in archived item, #7249</p></li>
<li><p>export-tar: for items w/o uid/gid, default to 0/0, #7249</p></li>
<li><p>fix some uid/gid lookup code / tests for win32</p></li>
<li><p>cache.py: be less verbose during cache sync</p></li>
<li><p>update bash completion script commands and options, #7273</p></li>
<li><p>require and use platformdirs 3.x.x package, tests</p></li>
<li><p>better included/excluded status chars, docs, #7321</p></li>
<li><p>undef NDEBUG for chunker and hashindex (make assert() work)</p></li>
<li><p>assert_id: better be paranoid (add back same crypto code as in old borg), #7362</p></li>
<li><p>check --verify_data: always decompress and call assert_id(), #7362</p></li>
<li><p>make hashindex_compact simpler and probably faster, minor fixes, cleanups, more tests</p></li>
<li><p>hashindex minor fixes, refactor, tweaks, tests</p></li>
<li><p>pyinstaller: remove icon</p></li>
<li><p>validation / placeholders / JSON:</p>
<ul>
<li><p>implement (text|binary)_to_json: key (text), key_b64 (base64(binary))</p></li>
<li><p>remove bpath, barchive, bcomment placeholders / JSON keys</p></li>
<li><p>archive metadata: make sure hostname and username have no surrogate escapes</p></li>
<li><p>text attributes (like archive name, comment): validate more strictly, #2290</p></li>
<li><p>transfer: validate archive names and comment before transfer</p></li>
<li><p>json output: use text_to_json (path, target), #6151</p></li>
</ul>
</li>
<li><p>docs:</p>
<ul>
<li><p>docs and comments consistency, readability and spelling fixes</p></li>
<li><p>fix --progress display description, #7180</p></li>
<li><p>document how borg deals with non-unicode bytes in JSON output</p></li>
<li><p>document another way to get UTF-8 encoding on stdin/stdout/stderr, #2273</p></li>
<li><p>pruning interprets timestamps in the local timezone where borg prune runs</p></li>
<li><p>shellpattern: add license, use copyright/license markup</p></li>
<li><p>key change-passphrase: fix --encryption value in examples</p></li>
<li><p>remove BORG_LIBB2_PREFIX (not used any more)</p></li>
<li><p>Installation: Update Fedora in distribution list, #7357</p></li>
<li><p>add .readthedocs.yaml (use py311, use non-shallow clone)</p></li>
</ul>
</li>
<li><p>tests:</p>
<ul>
<li><p>fix archiver tests on Windows, add running the tests to Windows CI</p></li>
<li><p>fix tox4 passenv issue, #7199</p></li>
<li><p>github actions updates (fix deprecation warnings)</p></li>
<li><p>add tests for borg transfer/upgrade</p></li>
<li><p>fix test hanging reading FIFO when <cite>borg create</cite> failed</p></li>
<li><p>mypy inspired fixes / updates</p></li>
<li><p>fix prune tests, prune in localtime</p></li>
<li><p>do not look up uid 0 / gid 0, but current process uid/gid</p></li>
<li><p>safe_unlink tests: use os.link to support win32 also</p></li>
<li><p>fix test_size_on_disk_accurate for large st_blksize, #7250</p></li>
<li><p>relaxed timestamp comparisons, use same_ts_ns</p></li>
<li><p>add test for extracted directory mtime</p></li>
<li><p>use “fail” chunker to test erroneous input file skipping</p></li>
</ul>
</li>
</ul>
</section>
<section id="version-2-0-0b4-2022-11-27">
<h2>Version 2.0.0b4 (2022-11-27)<a href="#version-2-0-0b4-2022-11-27" title="Link to this heading">¶</a></h2>
<p>Fixes:</p>
<ul>
<li><p>transfer/upgrade: fix borg &lt; 1.2 chunker_params, #7079</p></li>
<li><p>transfer/upgrade: do not access Item._dict, #7077</p></li>
<li><p>transfer/upgrade: fix crash in borg transfer, #7156</p></li>
<li><p>archive.save(): always use metadata from stats, #7072</p></li>
<li><p>benchmark: fixed TypeError in compression benchmarks, #7075</p></li>
<li><p>fix repository.scan api minimum requirement</p></li>
<li><p>fix args.paths related argparsing, #6994</p></li>
</ul>
<p>Other changes:</p>
<ul>
<li><p>tar_filter: recognize .tar.zst as zstd, #7093</p></li>
<li><p>adding performance statistics to borg create, #6991</p></li>
<li><p>docs: add rcompress to usage index</p></li>
<li><p>tests:</p>
<ul>
<li><p>use github and MSYS2 for Windows CI, #7097</p></li>
<li><p>win32 and cygwin: test fixes / skip hanging test</p></li>
<li><p>vagrant / github CI: use python 3.11.0 / 3.10.8</p></li>
</ul>
</li>
<li><p>vagrant:</p>
<ul>
<li><p>upgrade pyinstaller to 5.6.2 (supports python 3.11)</p></li>
<li><p>use python 3.11 to build the borg binary</p></li>
</ul>
</li>
</ul>
</section>
<section id="version-2-0-0b3-2022-10-02">
<h2>Version 2.0.0b3 (2022-10-02)<a href="#version-2-0-0b3-2022-10-02" title="Link to this heading">¶</a></h2>
<p>Fixes:</p>
<ul>
<li><p>transfer: fix user/group == None crash with borg1 archives</p></li>
<li><p>compressors: avoid memoryview related TypeError</p></li>
<li><p>check: fix uninitialised variable if repo is completely empty, #7034</p></li>
<li><p>do not use version_tuple placeholder in setuptools_scm template, #7024</p></li>
<li><p>get_chunker: fix missing sparse=False argument, #7056</p></li>
</ul>
<p>New features:</p>
<ul>
<li><p>rcompress: do a repo-wide (re)compression, #7037</p></li>
<li><p>implement pattern support for --match-archives, #6504</p></li>
<li><p>BORG_LOCK_WAIT=n env var to set default for --lock-wait option, #5279</p></li>
</ul>
<p>Other:</p>
<ul>
<li><p>repository.scan: misc. fixes / improvements</p></li>
<li><p>metadata: differentiate between empty/zero and unknown, #6908</p></li>
<li><p>CI: test pyfuse3 with python 3.11</p></li>
<li><p>use more relative imports</p></li>
<li><p>make borg.testsuite.archiver a package, split archiver tests into many modules</p></li>
<li><p>support reading new, improved hashindex header format, #6960.
added version number and num_empty to the HashHeader, fixed alignment.</p></li>
<li><p>vagrant: upgrade pyinstaller 4.10 -&gt; 5.4.1, use python 3.9.14 for binary build</p></li>
<li><p>item.pyx: use more Cython (faster, uses less memory), #5763</p></li>
</ul>
</section>
<section id="version-2-0-0b2-2022-09-10">
<h2>Version 2.0.0b2 (2022-09-10)<a href="#version-2-0-0b2-2022-09-10" title="Link to this heading">¶</a></h2>
<p>Bug fixes:</p>
<ul>
<li><p>xattrs / extended stat: improve exception handling, #6988</p></li>
<li><p>fix and refactor replace_placeholders, #6966</p></li>
</ul>
<p>New features:</p>
<ul>
<li><p>support archive timestamps with utc offsets, adapt them when using
borg transfer to transfer from borg 1.x repos (append +00:00 for UTC).</p></li>
<li><p>create/recreate/import-tar --timestamp: accept giving timezone via
its utc offset. defaults to local timezone, if no utc offset is given.</p></li>
</ul>
<p>Other changes:</p>
<ul>
<li><p>chunks: have separate encrypted metadata (ctype, clevel, csize, size)</p>
<p>chunk = enc_meta_len16 + encrypted(msgpacked(meta)) + encrypted(compressed(data)).</p>
<p>this breaks repo format compatibility, you need to create fresh repos!</p>
</li>
<li><p>repository api: flags support, #6982</p></li>
<li><p>OpenBSD only - statically link OpenSSL, #6474.
Avoid conflicting with shared libcrypto from the base OS pulled in via dependencies.</p></li>
<li><p>restructured source code</p></li>
<li><p>update diagrams to odg format, #6928</p></li>
</ul>
</section>
<section id="version-2-0-0b1-2022-08-08">
<h2>Version 2.0.0b1 (2022-08-08)<a href="#version-2-0-0b1-2022-08-08" title="Link to this heading">¶</a></h2>
<p>New features:</p>
<ul>
<li><p>massively increase archive metadata stream size limit, #1473.
currently rather testing the code, scalability will improve later, see #6945.</p></li>
<li><p>rcreate --copy-crypt-key: copy crypt_key from key of other repo, #6710.
default: create new, random authenticated encryption key.</p></li>
<li><p>prune/delete --checkpoint-interval=1800 and ctrl-c/SIGINT support, #6284</p></li>
</ul>
<p>Fixes:</p>
<ul>
<li><p>ctrl-c must not kill important subprocesses, #6912</p></li>
<li><p>transfer: check whether ID hash method and chunker secret are same.
add PlaintextKey and AuthenticatedKey support to uses_same_id_hash function.</p></li>
<li><p>check: try harder to create the key, #5719</p></li>
<li><p>SaveFile: use a custom mkstemp with mode support, #6933, #6400</p></li>
<li><p>make setuptools happy, #6874</p></li>
<li><p>fix misc. compiler warnings</p></li>
<li><p>list: fix {flags:&lt;WIDTH&gt;} formatting, #6081</p></li>
</ul>
<p>Other changes:</p>
<ul>
<li><p>new crypto does not need to call ._assert_id(), update code and docs.
<a href="https://github.com/borgbackup/borg/pull/6463#discussion_r925436156">https://github.com/borgbackup/borg/pull/6463#discussion_r925436156</a></p></li>
<li><p>check: --verify-data does not need to decompress with new crypto modes</p></li>
<li><p>Key: crypt_key instead of enc_key + enc_hmac_key, #6611</p></li>
<li><p>misc. docs updates and improvements</p></li>
<li><p>CI: test on macOS 12 without fuse / fuse tests</p></li>
<li><p>repository: add debug logging for issue #6687</p></li>
<li><p>_version.py: remove trailing blank, add LF at EOF (make pep8 checker happy)</p></li>
</ul>
</section>
<section id="version-2-0-0a4-2022-07-17">
<h2>Version 2.0.0a4 (2022-07-17)<a href="#version-2-0-0a4-2022-07-17" title="Link to this heading">¶</a></h2>
<p>New features:</p>
<ul>
<li><p>recreate: consider level for recompression, #6698, #3622</p></li>
</ul>
<p>Other changes:</p>
<ul>
<li><p>stop using libdeflate</p></li>
<li><p>CI: add mypy (if we add type hints, it can do type checking)</p></li>
<li><p>big changes to the source code:</p>
<ul>
<li><p>split up archiver module, transform it into a package</p></li>
<li><p>use Black for automated code formatting</p></li>
<li><p>remove some legacy code</p></li>
<li><p>adapt/fix code for mypy</p></li>
</ul>
</li>
<li><p>use language_level = 3str for cython (this will be the default in cython 3)</p></li>
<li><p>docs: document HardLinkManager and hlid, #2388</p></li>
</ul>
</section>
<section id="version-2-0-0a3-2022-07-04">
<h2>Version 2.0.0a3 (2022-07-04)<a href="#version-2-0-0a3-2022-07-04" title="Link to this heading">¶</a></h2>
<p>Fixes:</p>
<ul>
<li><p>check repo version, accept old repos only for --other-repo (e.g. rcreate/transfer).
v2 is the default repo version for borg 2.0. v1 repos must only be used in a
read-only way, e.g. for --other-repo=V1_REPO with borg init and borg transfer!</p></li>
</ul>
<p>New features:</p>
<ul>
<li><p>transfer: --upgrader=NoOp is the default.
This is to support general-purpose transfer of archives between related borg2
repos.</p></li>
<li><p>transfer: --upgrader=From12To20 must be used to transfer (and convert) archives
from borg 1.2 repos to borg 2.0 repos.</p></li>
</ul>
<p>Other changes:</p>
<ul>
<li><p>removed some deprecated options</p></li>
<li><p>removed -P (aka --prefix) option, #6806. The option -a (aka --glob-archives)
can be used for same purpose and is more powerful, e.g.: -a ‘PREFIX*’</p></li>
<li><p>rcreate: always use argon2 kdf for new repos, #6820</p></li>
<li><p>rcreate: remove legacy encryption modes for new repos, #6490</p></li>
</ul>
</section>
<section id="version-2-0-0a2-2022-06-26">
<h2>Version 2.0.0a2 (2022-06-26)<a href="#version-2-0-0a2-2022-06-26" title="Link to this heading">¶</a></h2>
<p>Changes:</p>
<ul>
<li><p>split repo and archive name into separate args, #948</p>
<ul>
<li><p>use -r or --repo or BORG_REPO env var to give the repository</p></li>
<li><p>use --other-repo or BORG_OTHER_REPO to give another repo (e.g. borg transfer)</p></li>
<li><p>use positional argument for archive name or <cite>-a ARCH_GLOB</cite></p></li>
</ul>
</li>
<li><p>remove support for scp-style repo specification, use <a href="ssh://">ssh://</a>…</p></li>
<li><p>simplify stats output: repo ops -&gt; repo stats, archive ops -&gt; archive stats</p></li>
<li><p>repository index: add payload size (==csize) and flags to NSIndex entries</p></li>
<li><p>repository index: set/query flags, iteration over flagged items (NSIndex)</p></li>
<li><p>repository: sync write file in get_fd</p></li>
<li><p>stats: deduplicated size now, was deduplicated compressed size in borg 1.x</p></li>
<li><p>remove csize support at most places in the code (chunks index, stats, get_size,
Item.chunks)</p></li>
<li><p>replace problematic/ugly hardlink_master approach of borg 1.x by:</p>
<ul>
<li><p>symmetric hlid (all hardlinks pointing to same inode have same hlid)</p></li>
<li><p>all archived hardlinked regular files have a chunks list</p></li>
</ul>
</li>
<li><p>borg rcreate --other-repo=OTHER_REPO: reuse key material from OTHER_REPO, #6554.
This is useful if you want to use borg transfer to transfer archives from an
existing borg 1.1/1.2 repo. If the chunker secret and the id key and algorithm
stay the same, the deduplication will also work between past and future backups.</p></li>
<li><p>borg transfer:</p>
<ul>
<li><p>efficiently copy archives from a borg 1.1/1.2 repo to a new repo.
uses deduplication and does not decompress/recompress file content data.</p></li>
<li><p>does some cleanups / fixes / conversions:</p>
<ul>
<li><p>disallow None value for .user/group/chunks/chunks_healthy</p></li>
<li><p>cleanup msgpack related str/bytes mess, use new msgpack spec, #968</p></li>
<li><p>obfuscation: fix byte order for size, #6701</p></li>
<li><p>compression: use the 2 bytes for type and level, #6698</p></li>
<li><p>use version 2 for new archives</p></li>
<li><p>convert timestamps int/bigint -&gt; msgpack.Timestamp, see #2323</p></li>
<li><p>all hardlinks have chunks, maybe chunks_healthy, hlid</p></li>
<li><p>remove the zlib type bytes hack</p></li>
<li><p>make sure items with chunks have precomputed size</p></li>
<li><p>removes the csize element from the tuples in the Item.chunks list</p></li>
<li><p>clean item of attic 0.13 ‘acl’ bug remnants</p></li>
</ul>
</li>
</ul>
</li>
<li><p>crypto: see 1.3.0a1 log entry</p></li>
<li><p>removed “borg upgrade” command (not needed any more)</p></li>
<li><p>compact: removed --cleanup-commits option</p></li>
<li><p>docs: fixed quickstart and usage docs with new cli command syntax</p></li>
<li><p>docs: removed the parts talking about potential AES-CTR mode issues
(we will not use that any more).</p></li>
</ul>
</section>
<section id="version-1-3-0a1-2022-04-15">
<h2>Version 1.3.0a1 (2022-04-15)<a href="#version-1-3-0a1-2022-04-15" title="Link to this heading">¶</a></h2>
<p>Although this was released as 1.3.0a1, it can be also seen as 2.0.0a1 as it was
later decided to do breaking changes and thus the major release number had to
be increased (thus, there will not be a 1.3.0 release, but 2.0.0).</p>
<p>New features:</p>
<ul>
<li><p>init: new --encryption=(repokey|keyfile)-[blake2-](aes-ocb|chacha20-poly1305)</p>
<ul>
<li><p>New, better, faster crypto (see encryption-aead diagram in the docs), #6463.</p></li>
<li><p>New AEAD cipher suites: AES-OCB and CHACHA20-POLY1305.</p></li>
<li><p>Session keys are derived via HKDF from random session id and master key.</p></li>
<li><p>Nonces/MessageIVs are counters starting from 0 for each session.</p></li>
<li><p>AAD: chunk id, key type, messageIV, sessionID are now authenticated also.</p></li>
<li><p>Solves the potential AES-CTR mode counter management issues of the legacy crypto.</p></li>
</ul>
</li>
<li><p>init: --key-algorithm=argon2 (new default KDF, older pbkdf2 also still available)</p>
<p>borg key change-passphrase / change-location keeps the key algorithm unchanged.</p>
</li>
<li><p>key change-algorithm: to upgrade existing keys to argon2 or downgrade to pbkdf2.</p>
<p>We recommend you to upgrade unless you have to keep the key compatible with older versions of borg.</p>
</li>
<li><p>key change-location: usable for repokey &lt;-&gt; keyfile location change</p></li>
<li><p>benchmark cpu: display benchmarks of cpu bound stuff</p></li>
<li><p>export-tar: new --tar-format=PAX (default: GNU)</p></li>
<li><p>import-tar/export-tar: can use PAX format for ctime and atime support</p></li>
<li><p>import-tar/export-tar: --tar-format=BORG: roundtrip ALL item metadata, #5830</p></li>
<li><p>repository: create and use version 2 repos only for now</p></li>
<li><p>repository: implement PUT2: header crc32, overall xxh64, #1704</p></li>
</ul>
<p>Other changes:</p>
<ul>
<li><p>require python &gt;= 3.9, #6315</p></li>
<li><p>simplify libs setup, #6482</p></li>
<li><p>unbundle most bundled 3rd party code, use libs, #6316</p></li>
<li><p>use libdeflate.crc32 (Linux and all others) or zlib.crc32 (macOS)</p></li>
<li><p>repository: code cleanups / simplifications</p></li>
<li><p>internal crypto api: speedups / cleanups / refactorings / modernisation</p></li>
<li><p>remove “borg upgrade” support for “attic backup” repos</p></li>
<li><p>remove PassphraseKey code and borg key migrate-to-repokey command</p></li>
<li><p>OpenBSD: build borg with OpenSSL (not: LibreSSL), #6474</p></li>
<li><p>remove support for LibreSSL, #6474</p></li>
<li><p>remove support for OpenSSL &lt; 1.1.1</p></li>
</ul>
</section>
</section>


          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: qrframe – generate beautiful qr codes with javascript code (173 pts)]]></title>
            <link>https://github.com/zhengkyl/qrframe</link>
            <guid>41701644</guid>
            <pubDate>Mon, 30 Sep 2024 20:20:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/zhengkyl/qrframe">https://github.com/zhengkyl/qrframe</a>, See on <a href="https://news.ycombinator.com/item?id=41701644">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">qrframe</h2><a id="user-content-qrframe" aria-label="Permalink: qrframe" href="#qrframe"></a></p>
<p dir="auto">code-based qr code generator</p>
<p dir="auto">Blatantly inspired by <a href="https://qrbtf.com/" rel="nofollow">QRBTF</a> and <a href="https://qrcode.antfu.me/" rel="nofollow">Anthony Fu's QR Toolkit</a>.</p>
<p dir="auto"><a href="https://kylezhe.ng/posts/crafting_qr_codes" rel="nofollow">Here's a post I wrote about crafting QR codes</a> that goes into deeper detail about how they work and ways to make them pretty.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto">I'm working on more examples.</p>
<markdown-accessiblity-table><table>
  <tbody>
    <tr>
      <th colspan="3">Creative possibilities</th>
    </tr>
    <tr>
      <td>
        <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhengkyl/qrframe/blob/main/examples/quantum.svg"><img src="https://github.com/zhengkyl/qrframe/raw/main/examples/quantum.svg" width="300"></a>
      </td>
      <td>
        <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhengkyl/qrframe/blob/main/examples/mondrian.svg"><img src="https://github.com/zhengkyl/qrframe/raw/main/examples/mondrian.svg" width="300"></a>
      </td>
      <td>
        <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhengkyl/qrframe/blob/main/examples/wood.svg"><img src="https://github.com/zhengkyl/qrframe/raw/main/examples/wood.svg" width="300"></a>
      </td>
    </tr>
    <tr>
      <td>
        <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhengkyl/qrframe/blob/main/examples/tile.png"><img src="https://github.com/zhengkyl/qrframe/raw/main/examples/tile.png"></a>
      </td>
      <td>
        <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhengkyl/qrframe/blob/main/examples/dots.svg"><img src="https://github.com/zhengkyl/qrframe/raw/main/examples/dots.svg" width="300"></a>
      </td>
      <td>
        <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhengkyl/qrframe/blob/main/examples/layers1.svg"><img src="https://github.com/zhengkyl/qrframe/raw/main/examples/layers1.svg" width="300"></a>
      </td>
    </tr>
    <tr>
      <td>
        <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhengkyl/qrframe/blob/main/examples/neon.svg"><img src="https://github.com/zhengkyl/qrframe/raw/main/examples/neon.svg" width="300"></a>
      </td>
      <td>
        <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhengkyl/qrframe/blob/main/examples/camo.svg"><img src="https://github.com/zhengkyl/qrframe/raw/main/examples/camo.svg" width="300"></a>
      </td>
      <td>
        <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhengkyl/qrframe/blob/main/examples/matrix.svg"><img src="https://github.com/zhengkyl/qrframe/raw/main/examples/matrix.svg" width="300"></a>
      </td>
    </tr>
    <tr>
      <td>
        <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhengkyl/qrframe/blob/main/examples/glass.svg"><img src="https://github.com/zhengkyl/qrframe/raw/main/examples/glass.svg" width="300"></a>
      </td>
      <td>
        <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhengkyl/qrframe/blob/main/examples/childhood.svg"><img src="https://github.com/zhengkyl/qrframe/raw/main/examples/childhood.svg" width="300"></a>
      </td>
      <td>
        <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhengkyl/qrframe/blob/main/examples/layers2.svg"><img src="https://github.com/zhengkyl/qrframe/raw/main/examples/layers2.svg" width="300"></a>
      </td>
    </tr>
    <tr>
      <th colspan="3">Import external libs, fetch external files, etc </th>
    </tr>
    <tr><td>
      <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhengkyl/qrframe/blob/main/examples/drawing1.png"><img src="https://github.com/zhengkyl/qrframe/raw/main/examples/drawing1.png"></a>
    </td>
    <td>
      <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhengkyl/qrframe/blob/main/examples/drawing2.png"><img src="https://github.com/zhengkyl/qrframe/raw/main/examples/drawing2.png"></a>
    </td>
      <td>
        <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhengkyl/qrframe/blob/main/examples/halftone.png"><img src="https://github.com/zhengkyl/qrframe/raw/main/examples/halftone.png" width="300"></a>
      </td>
    </tr><tr>
      <th colspan="3">Styles copied from <a href="https://qrbtf.com/" rel="nofollow">QRBTF</a></th>
    </tr>
    <tr>
      <td>
        <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhengkyl/qrframe/blob/main/examples/blocks.svg"><img src="https://github.com/zhengkyl/qrframe/raw/main/examples/blocks.svg" width="300"></a>
      </td>
      <td>
        <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhengkyl/qrframe/blob/main/examples/bubbles.svg"><img src="https://github.com/zhengkyl/qrframe/raw/main/examples/bubbles.svg" width="300"></a>
      </td>
      <td>
        <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhengkyl/qrframe/blob/main/examples/alien.svg"><img src="https://github.com/zhengkyl/qrframe/raw/main/examples/alien.svg" width="300"></a>
      </td>
    </tr><tr>
      <th colspan="3">Boring options are available</th>
    </tr>
    <tr>
      <td>
        <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhengkyl/qrframe/blob/main/examples/boring1.png"><img src="https://github.com/zhengkyl/qrframe/raw/main/examples/boring1.png"></a>
      </td>
      <td>
        <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhengkyl/qrframe/blob/main/examples/boring2.png"><img src="https://github.com/zhengkyl/qrframe/raw/main/examples/boring2.png"></a>
      </td>
      <td>
        <a target="_blank" rel="noopener noreferrer" href="https://github.com/zhengkyl/qrframe/blob/main/examples/boring3.png"><img src="https://github.com/zhengkyl/qrframe/raw/main/examples/boring3.png"></a>
      </td>
    </tr>
  </tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>
<p dir="auto">Customize data:</p>
<ul dir="auto">
<li>encoding mode, version, error tolerance, mask pattern</li>
<li>powered by <a href="https://github.com/zhengkyl/fuqr"><code>fuqr</code></a>, my own Rust library imported as WASM. (i use windows, btw)</li>
</ul>
</li>
<li>
<p dir="auto">Customize appearance:</p>
<ul dir="auto">
<li>Choose any preset, customize or even create a new one from scratch via code editor.</li>
<li>Define arbitrary UI parameters in code</li>
<li>Supports SVG and PNG</li>
<li>All code runs <em>directly</em> in browser in a web worker with no restrictions.
<ul dir="auto">
<li>There is no sandbox, whitelist, blacklist, or anything besides a 5s timeout to stop infinite loops.</li>
<li>Generated SVGs are not sanitized. This is an impossible task and attempting it breaks perfectly fine SVGs, makes debugging harder, and adds latency to previewing changes.</li>
<li>These should be non-issues, but even if you copy-and-paste and run malware there's no secrets to leak.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Use existing presets</h3><a id="user-content-use-existing-presets" aria-label="Permalink: Use existing presets" href="#use-existing-presets"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/zhengkyl/qrframe/blob/main/examples/ui1.png"><img src="https://github.com/zhengkyl/qrframe/raw/main/examples/ui1.png" alt="style select ui"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Customizable parameters defined in code</h3><a id="user-content-customizable-parameters-defined-in-code" aria-label="Permalink: Customizable parameters defined in code" href="#customizable-parameters-defined-in-code"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/zhengkyl/qrframe/blob/main/examples/ui2.png"><img src="https://github.com/zhengkyl/qrframe/raw/main/examples/ui2.png" alt="code and parameter editor ui"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Creating a preset</h2><a id="user-content-creating-a-preset" aria-label="Permalink: Creating a preset" href="#creating-a-preset"></a></p>
<p dir="auto">A preset must export <code>paramsSchema</code> and either <code>renderSVG</code> or <code>renderCanvas</code></p>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>paramsSchema</code></h2><a id="user-content-paramsschema" aria-label="Permalink: paramsSchema" href="#paramsschema"></a></p>
<p dir="auto">This schema defines the UI components whose values are passed into <code>renderSVG</code> or <code>renderCanvas</code> via the <code>params</code> object.</p>
<p dir="auto">All properties besides <code>type</code> are optional, except</p>
<ul dir="auto">
<li>type <code>select</code> must have a nonempty options array</li>
<li>type <code>array</code> must have a valid <code>props</code> value.</li>
</ul>
<p dir="auto">In this example, <code>default</code> is set explicitly to the implicit default value.</p>
<div dir="auto" data-snippet-clipboard-copy-content="export const paramsSchema = {
  Example1: {
    type: &quot;number&quot;,
    min: 0,
    max: 10,
    step: 0.1,
    default: 0,
  },
  Example2: {
    type: &quot;boolean&quot;,
    default: false,
  },
  Example3: {
    type: &quot;color&quot;,
    default: &quot;#000000&quot;, // css color string (hex/rgba/hsla)
  },
  Example4: {
    type: &quot;select&quot;,
    options: [&quot;I'm feeling&quot;, 22],
    default: &quot;I'm feeling&quot;, // first option
  },
  Example5: {
    type: &quot;file&quot;,
    accept: &quot;.jpeg, .jpg, .png&quot;,
    default: null,
  },
  Example6: {
    type: &quot;array&quot;,
    props: {
      type: &quot;number&quot;, // any type except &quot;array&quot;
      // corresponding props
    },
    resizable: true,
    defaultLength: 5, // overridden by default
    default: [], // overrides defaultLength
  },
};"><pre><span>export</span> <span>const</span> <span>paramsSchema</span> <span>=</span> <span>{</span>
  <span>Example1</span>: <span>{</span>
    <span>type</span>: <span>"number"</span><span>,</span>
    <span>min</span>: <span>0</span><span>,</span>
    <span>max</span>: <span>10</span><span>,</span>
    <span>step</span>: <span>0.1</span><span>,</span>
    <span>default</span>: <span>0</span><span>,</span>
  <span>}</span><span>,</span>
  <span>Example2</span>: <span>{</span>
    <span>type</span>: <span>"boolean"</span><span>,</span>
    <span>default</span>: <span>false</span><span>,</span>
  <span>}</span><span>,</span>
  <span>Example3</span>: <span>{</span>
    <span>type</span>: <span>"color"</span><span>,</span>
    <span>default</span>: <span>"#000000"</span><span>,</span> <span>// css color string (hex/rgba/hsla)</span>
  <span>}</span><span>,</span>
  <span>Example4</span>: <span>{</span>
    <span>type</span>: <span>"select"</span><span>,</span>
    <span>options</span>: <span>[</span><span>"I'm feeling"</span><span>,</span> <span>22</span><span>]</span><span>,</span>
    <span>default</span>: <span>"I'm feeling"</span><span>,</span> <span>// first option</span>
  <span>}</span><span>,</span>
  <span>Example5</span>: <span>{</span>
    <span>type</span>: <span>"file"</span><span>,</span>
    <span>accept</span>: <span>".jpeg, .jpg, .png"</span><span>,</span>
    <span>default</span>: <span>null</span><span>,</span>
  <span>}</span><span>,</span>
  <span>Example6</span>: <span>{</span>
    <span>type</span>: <span>"array"</span><span>,</span>
    <span>props</span>: <span>{</span>
      <span>type</span>: <span>"number"</span><span>,</span> <span>// any type except "array"</span>
      <span>// corresponding props</span>
    <span>}</span><span>,</span>
    <span>resizable</span>: <span>true</span><span>,</span>
    <span>defaultLength</span>: <span>5</span><span>,</span> <span>// overridden by default</span>
    <span>default</span>: <span>[</span><span>]</span><span>,</span> <span>// overrides defaultLength</span>
  <span>}</span><span>,</span>
<span>}</span><span>;</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto"><code>renderSVG</code> and <code>renderCanvas</code></h2><a id="user-content-rendersvg-and-rendercanvas" aria-label="Permalink: renderSVG and renderCanvas" href="#rendersvg-and-rendercanvas"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="type renderSVG = (qr: Qr, params: Params) => string;

type renderCanvas = (qr: Qr, params: Params, canvas: OffscreenCanvas) => void;"><pre><span>type</span> <span>renderSVG</span> <span>=</span> <span>(</span><span>qr</span>: <span>Qr</span><span>,</span> <span>params</span>: <span>Params</span><span>)</span> <span>=&gt;</span> <span>string</span><span>;</span>

<span>type</span> <span>renderCanvas</span> <span>=</span> <span>(</span><span>qr</span>: <span>Qr</span><span>,</span> <span>params</span>: <span>Params</span><span>,</span> <span>canvas</span>: <span>OffscreenCanvas</span><span>)</span> <span>=&gt;</span> <span><span>void</span></span><span>;</span></pre></div>
<p dir="auto"><code>params</code> is an object with all the keys of <code>paramsSchema</code> paired with the value from their respective input component.</p>
<p dir="auto"><code>qr</code> contains the final QR code in <code>matrix</code>. This represents a square where one side is <code>version * 4 + 17</code> wide, and modules (aka pixels) are stored from the left to right, top to bottom.</p>
<div dir="auto" data-snippet-clipboard-copy-content="type Qr = {
  matrix: Uint8Array; // see below
  version: number; // 1- 40
  mask: number; // 0 - 7,
  ecl: number; // 0 - 3, Low, Medium, Quartile, High
  mode: number; // 0 - 2, Numeric, Alphanumeric, Byte
};

// bit flags for each u8 in matrix
const Module = {
  ON: 1 << 0,
  DATA: 1 << 1,
  FINDER: 1 << 2,
  ALIGNMENT: 1 << 3,
  TIMING: 1 << 4,
  FORMAT: 1 << 5,
  VERSION: 1 << 6,
  MODIFIER: 1 << 7,
};"><pre><span>type</span> <span>Qr</span> <span>=</span> <span>{</span>
  <span>matrix</span>: <span>Uint8Array</span><span>;</span> <span>// see below</span>
  <span>version</span>: <span>number</span><span>;</span> <span>// 1- 40</span>
  <span>mask</span>: <span>number</span><span>;</span> <span>// 0 - 7,</span>
  <span>ecl</span>: <span>number</span><span>;</span> <span>// 0 - 3, Low, Medium, Quartile, High</span>
  <span>mode</span>: <span>number</span><span>;</span> <span>// 0 - 2, Numeric, Alphanumeric, Byte</span>
<span>}</span><span>;</span>

<span>// bit flags for each u8 in matrix</span>
<span>const</span> <span>Module</span> <span>=</span> <span>{</span>
  <span>ON</span>: <span>1</span> <span>&lt;&lt;</span> <span>0</span><span>,</span>
  <span>DATA</span>: <span>1</span> <span>&lt;&lt;</span> <span>1</span><span>,</span>
  <span>FINDER</span>: <span>1</span> <span>&lt;&lt;</span> <span>2</span><span>,</span>
  <span>ALIGNMENT</span>: <span>1</span> <span>&lt;&lt;</span> <span>3</span><span>,</span>
  <span>TIMING</span>: <span>1</span> <span>&lt;&lt;</span> <span>4</span><span>,</span>
  <span>FORMAT</span>: <span>1</span> <span>&lt;&lt;</span> <span>5</span><span>,</span>
  <span>VERSION</span>: <span>1</span> <span>&lt;&lt;</span> <span>6</span><span>,</span>
  <span>MODIFIER</span>: <span>1</span> <span>&lt;&lt;</span> <span>7</span><span>,</span>
<span>}</span><span>;</span></pre></div>
<p dir="auto"><code>MODIFIER</code> is set for Finder and Alignment centers, Format and Version copy.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MusicBrainz: An open music encyclopedia (272 pts)]]></title>
            <link>https://musicbrainz.org/</link>
            <guid>41701156</guid>
            <pubDate>Mon, 30 Sep 2024 19:36:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://musicbrainz.org/">https://musicbrainz.org/</a>, See on <a href="https://news.ycombinator.com/item?id=41701156">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page"><div id="maincontent"><h2>Welcome to MusicBrainz!</h2><p>MusicBrainz is an open music encyclopedia that collects music metadata and makes it available to the public.</p><p>MusicBrainz aims to be:</p><ol><li><strong>The ultimate source of music information</strong> by allowing anyone to contribute and releasing the <a href="https://musicbrainz.org/doc/MusicBrainz_Database">data</a> under <a href="https://musicbrainz.org/doc/About/Data_License">open licenses</a>.</li><li><strong>The universal lingua franca for music</strong> by providing a reliable and unambiguous form of <a href="https://musicbrainz.org/doc/MusicBrainz_Identifier">music identification</a>, enabling both people and machines to have meaningful conversations about music.</li></ol><p>Like Wikipedia, MusicBrainz is maintained by a global community of users and we want everyone — including you — to <a href="https://musicbrainz.org/doc/How_to_Contribute">participate and contribute</a>.</p><p>MusicBrainz is operated by the <a href="https://metabrainz.org/">MetaBrainz Foundation</a>, a California based 501(c)(3) tax-exempt non-profit corporation dedicated to keeping MusicBrainz <a href="https://musicbrainz.org/doc/About/Data_License">free and open source</a>.</p></div><div id="triple"><ul><li><a href="https://musicbrainz.org/doc/How_to_Contribute">How to contribute</a></li><li><a href="https://tickets.metabrainz.org/">Bug tracker</a></li><li><a href="https://community.metabrainz.org/">Forums</a></li></ul></div><div><h2>Recently added releases</h2></div><div><h2>Recently added events</h2></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[California bans legacy admissions at private universities (440 pts)]]></title>
            <link>https://www.nytimes.com/2024/09/30/us/california-bans-legacy-admissions-private-universities.html</link>
            <guid>41700516</guid>
            <pubDate>Mon, 30 Sep 2024 18:42:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/09/30/us/california-bans-legacy-admissions-private-universities.html">https://www.nytimes.com/2024/09/30/us/california-bans-legacy-admissions-private-universities.html</a>, See on <a href="https://news.ycombinator.com/item?id=41700516">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/09/30/us/california-bans-legacy-admissions-private-universities.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Apple No Longer in Talks to Invest in ChatGPT Maker OpenAI (168 pts)]]></title>
            <link>https://www.macrumors.com/2024/09/30/apple-no-longer-investing-openai-chatgpt/</link>
            <guid>41700496</guid>
            <pubDate>Mon, 30 Sep 2024 18:39:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.macrumors.com/2024/09/30/apple-no-longer-investing-openai-chatgpt/">https://www.macrumors.com/2024/09/30/apple-no-longer-investing-openai-chatgpt/</a>, See on <a href="https://news.ycombinator.com/item?id=41700496">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main" id="maincontent"><article expanded="true"><div data-io-article-url="/2024/09/30/apple-no-longer-investing-openai-chatgpt/"><p>Apple has reportedly exited negotiations to invest in OpenAI, the company behind the popular ChatGPT AI chatbot, according to <em><a href="https://www.wsj.com/tech/apple-no-longer-in-talks-to-join-openai-investment-round-e3be3e66">The Wall Street Journal</a></em>.</p>
<p><img src="https://images.macrumors.com/t/TCcDaGLiCnr7Ks2UgWuSxzndIqI=/400x0/article-new/2024/08/iOS-18-ChatGPT.jpg?lossy" srcset="https://images.macrumors.com/t/TCcDaGLiCnr7Ks2UgWuSxzndIqI=/400x0/article-new/2024/08/iOS-18-ChatGPT.jpg?lossy 400w,https://images.macrumors.com/t/G5kpWmOYMm6YRLimQ-1nwt8205A=/800x0/article-new/2024/08/iOS-18-ChatGPT.jpg?lossy 800w,https://images.macrumors.com/t/itGwY1Pztpi8Q6lHbms2pZHfaUw=/1600x0/article-new/2024/08/iOS-18-ChatGPT.jpg 1600w,https://images.macrumors.com/t/qYFkvKDN0oid7zg8LRNHUk8G6_0=/2500x0/filters:no_upscale()/article-new/2024/08/iOS-18-ChatGPT.jpg 2500w" sizes="(max-width: 900px) 100vw, 697px" alt="iOS 18 ChatGPT" width="1825" height="1027"><br>Apple had been in discussions to participate in a funding round for OpenAI that is expected to raise approximately $6.5 billion. However, Apple recently dropped out of the talks for reasons that remain unclear. The funding round is set to close this week.</p>
<p>The development comes just a month after <em>WSJ</em> reported that Apple was <a href="https://www.macrumors.com/2024/08/29/apple-reportedly-in-talks-to-invest-in-openai/">considering an investment in OpenAI</a> as part of a fundraising effort that could value the AI company at over $100 billion. The high valuation reflects the intense competition in the artificial intelligence sector that OpenAI helped ignite with ChatGPT's launch in late 2022.</p>
<p>While Apple has stepped away, other major tech companies remain involved. Microsoft, which has already invested $13 billion in OpenAI, is expected to contribute about $1 billion to this latest round. Nvidia is also reportedly in talks to participate.</p>
<p>The news of Apple's withdrawal may surprise some, given the company's recent moves in the AI space. Apple previously announced plans to integrate ChatGPT into Siri on iOS 18, iPadOS 18, and macOS Sequoia later this year. This integration will allow Siri to display ChatGPT responses directly with user permission. However, recent reports of <a href="https://www.wsj.com/tech/ai/open-ai-division-for-profit-da26c24b">turmoil within OpenAI's ranks</a> as it pursues a for-profit structure, may have factored into Apple's decision not to pursue the investment.</p>
<p>That said, Apple's planned ChatGPT integration for its platforms is still expected to proceed before the end of the year. The company has said that iPhone, iPad, and Mac users will be able to use ChatGPT for free without creating an account, while ChatGPT Plus subscribers will be able to access paid features on Apple devices.</p>
</div></article><p><h2>Popular Stories</h2></p><div><h3><a href="https://www.macrumors.com/2024/09/27/new-things-your-iphone-will-do-ios-18-1/">15 New Things Your iPhone Can Do in iOS 18.1</a></h3><p>Friday September 27, 2024 6:14 am PDT by <a href="https://www.macrumors.com/author/tim-hardwick/" rel="author">Tim Hardwick</a></p><p>Apple is set to release iOS 18.1 in October, bringing the first set of Apple Intelligence features to iPhone 15 Pro and iPhone 16 models. This update marks a significant step forward in Apple's AI integration, offering a new Siri contextually-aware experience and a range of additional capabilities powered by on-device machine learning and large language models. There are a couple of handy new...</p></div><div><h3><a href="https://www.macrumors.com/2024/09/26/apple-releases-new-airpods-pro-2-firmware-7a305/">Apple Releases New AirPods Pro 2 Firmware</a></h3><p>Thursday September 26, 2024 11:16 am PDT by <a href="https://www.macrumors.com/author/juli-clover/" rel="author">Juli Clover</a></p><p>Apple today released a new firmware update for the AirPods Pro 2, with the software available for both the USB-C and Lightning models. The AirPods Pro 2 firmware has a build number of 7A305, up from the 7A302 firmware released earlier in September. There is no word yet on what's included in the firmware, but Apple is planning to add hearing aid and hearing test features to the AirPods Pro 2...</p></div><div><h3><a href="https://www.macrumors.com/2024/09/26/best-buy-m2-ipad-pro/">Best Buy Takes Up to $1,000 Off M2 iPad Pro With Record Low Prices</a></h3><p>Best Buy is back this week with big discounts on the M2 11-inch and 12.9-inch iPad Pro, providing up to $1,000 off select models. A My Best Buy Plus/Total membership is not required to see these discounts. You'll find both Wi-Fi and cellular tablets on sale at Best Buy, with a particular focus on the larger capacity 1TB and 2TB models. All deals listed below represent record low prices on...</p></div><div><h3><a href="https://www.macrumors.com/2024/09/27/apple-event-october-2024-preview/">What to Expect From an Apple Event in October: iPad Mini 7, Redesigned Mac Mini, and More</a></h3><p>Friday September 27, 2024 11:47 am PDT by <a href="https://www.macrumors.com/author/joe-rossignol/" rel="author">Joe Rossignol</a></p><p>Apple will likely hold another event in October this year to announce new Macs and iPads. If so, it would be the fourth time in the last five years that Apple has held an event in October. Last year, Apple held a virtual event on Monday, October 30 to announce new MacBook Pro and iMac models with the M3 series of chips. Subscribe to the MacRumors YouTube channel for more videos. Below, we...</p></div><div><h3><a href="https://www.macrumors.com/2024/09/23/10-reasons-to-wait-iphone-17/">10 Reasons to Wait for Next Year's iPhone 17</a></h3><p>Monday September 23, 2024 2:00 am PDT by <a href="https://www.macrumors.com/author/tim-hardwick/" rel="author">Tim Hardwick</a></p><p>Apple's iPhone development roadmap runs several years into the future and the company is continually working with suppliers on several successive iPhone models simultaneously, which is why we sometimes get rumored feature leaks so far ahead of launch. The iPhone 17 series is no different – already we have some idea of what to expect from Apple's 2025 smartphone lineup. If you plan to skip...</p></div><div><h3><a href="https://www.macrumors.com/2024/09/26/apple-preparing-ios-18-0-1/">Apple Preparing iOS 18.0.1 Update for iPhone Following Several Bugs</a></h3><p>Thursday September 26, 2024 9:34 am PDT by <a href="https://www.macrumors.com/author/joe-rossignol/" rel="author">Joe Rossignol</a></p><p>Apple appears to be internally testing iOS 18.0.1 for the iPhone, based on evidence of the software update in our website's analytics this week. Our logs have accurately revealed many iOS versions before they were released. We expect iOS 18.0.1 to be a minor update focused on bug fixes. Issues that could be addressed with the update include touchscreen issues affecting the iPhone 16 series...</p></div><div><h3><a href="https://www.macrumors.com/2024/09/28/airpods-4-vs-airpods-pro-2/">AirPods 4 With ANC vs. AirPods Pro 2</a></h3><p>Saturday September 28, 2024 7:02 am PDT by <a href="https://www.macrumors.com/author/juli-clover/" rel="author">Juli Clover</a></p><p>Apple last week released the AirPods 4, and one version of the new earbuds has Active Noise Cancellation included. ANC means the AirPods 4 have a feature set that rivals the AirPods Pro 2, so we thought we'd compare the two for those undecided on which to get. Subscribe to the MacRumors YouTube channel for more videos. The AirPods 4 are Apple's first open-ear earbuds to include ANC, and the...</p></div><div><h3><a href="https://www.macrumors.com/2024/09/24/iphone-80-percent-charging-test/">Apple's 80% Charging Limit for iPhone: How Much Did It Help After a Year?</a></h3><p>Tuesday September 24, 2024 2:09 pm PDT by <a href="https://www.macrumors.com/author/juli-clover/" rel="author">Juli Clover</a></p><p>With the iPhone 15 models that came out last year, Apple added an opt-in battery setting that limits maximum charge to 80 percent. The idea is that never charging the iPhone above 80 percent will increase battery longevity, so I kept my iPhone at that 80 percent limit from September 2023 to now, with no cheating. My iPhone 15 Pro Max battery level is currently at 94 percent with 299 cycles....</p></div><div><h3><a href="https://www.macrumors.com/2024/09/27/iphone-16-pro-max-camera-review/">iPhone 16 Pro Max: One Week Camera Review</a></h3><p>Friday September 27, 2024 11:10 am PDT by <a href="https://www.macrumors.com/author/juli-clover/" rel="author">Juli Clover</a></p><p>It's been a full week since the new iPhone 16 models launched, and we've now had enough time to give the Camera Control button and the camera setup a more in-depth look. We tested the iPhone 16 Pro and Pro Max, which have triple-lens rear camera setups with 48-megapixel Fusion lens, 48-megapixel Ultra Wide lens, and 5x Telephoto lens. Subscribe to the MacRumors YouTube channel for more videos. ...</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GnuCash 5.9 Released (212 pts)]]></title>
            <link>https://www.gnucash.org/news.phtml</link>
            <guid>41699730</guid>
            <pubDate>Mon, 30 Sep 2024 17:26:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gnucash.org/news.phtml">https://www.gnucash.org/news.phtml</a>, See on <a href="https://news.ycombinator.com/item?id=41699730">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
    
    <p>Announcement of New Releases, Server Maintenance …</p>
    <!-- top_dir = . , home = . -->
<!-- in news/news-script.php: top_dir = . -->
<!-- lang-path: ./news/en ; en-path: ./news -->
<div>
<h2>GnuCash 5.9 Released</h2>

<p>The GnuCash development team announces GnuCash 5.9, the tenth release in the stable 5.x series.</p>

<h4>Between 5.8 and 5.9, the following bugfixes were accomplished:</h4>
<ul>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=724745">Bug 724745 - Added new transaction during reconcile, didn't show up in reconcile window.</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=797045">Bug 797045 - Improve error reporting for bad credentials with MySQL backend ("bad or corrupt data" =&gt; "access denied")</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798568">Bug 798568 - Transaction Copy/Paste problem</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799308">Bug 799308 - sqlite backend: Example Python script prints error when creating new file.</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799370">Bug 799370 - Transaction Journal view cursor placement after commit to transaction change.</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799384">Bug 799384 - Reconciled date cannot be parsed.</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799389">Bug 799389 - Crash when removing an account</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799391">Bug 799391 - Transaction Cut/Paste doesn't move the transaction to the target account</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799395">Bug 799395 - relative date offset quarters occasionally wrong</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799399">Bug 799399 - Windows Keypad decimal locale error</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799416">Bug 799416 - Post invoice: post to account dropdown listbox too small</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799419">Bug 799419 - Intermittent quote price issue</a></li>
</ul>

<h4>The following fixes and improvements were not associated with bug reports:</h4>
<ul>
    <li>Add YH Finance (FINANCEAPI) API Key to Quotes infrastructure with a preference in the Online Quotes page and add financeapi to known sources. </li>
    <li>Move copied_class and copied_leader_guid<p>Move static copied_class and static copied_leader_guid to be part of the copied_item structure. This makes it more evident that calling clear_copied_item needs to be called before copied_item is used. </p></li>
    <li>[gnc-datetime] improve CSV date parser with ICU and Boost.
        <ol><li> Add dateformat "Locale" with ICU; uses current locale for date    parsing. ICU's locale date parser may parse "3 May 2023" or    "2024年9月13日" (LC_TIME=zh_TW.utf8) and maybe others.</li>
            <li>Augment d-m-y m-d-y and y-m-d with boost UK/US/ISO parsers. This allows    CSV import of dates with months as words as "30 Sep 2023" or    "May 4, 1978" or "2023-Dec-25". Note boost parser cannot recognise    2-digit years, therefore "30 Sep 24" is invalid.</li>
        </ol></li>
    <li>Csv Import - improve assisant's introduction page</li>
    <li>Correctly handle uncommitted edits when opening a file from history.</li>
    <li>Don't use gnc_difftime and deprecate it because it casts time64 to doubles </li>
    <li>[gnc-pricedb.h] remove unused gnc_pricedb_substitute_commodity</li>
    <li>[gnc-pricedb.h] remove unused gnc_pricedb_lookup_at_time64</li>
</ul>
<p>New and Updated Translations: Assamese, Chinese (Simplified), Chinese (Traditional), Croatian, Dutch, English (United Kingdom), Hebrew, Hungarian, Macedonian, Norwegian Bokmål, Portuguese (Brazil), Russian, Spanish, Swedish, Turkish</p>


<p><a href="https://hosted.weblate.org/engage/gnucash/">Help translate GnuCash on Weblate</a></p><h4>German AQBanking Users:</h4>
<p>The AQBanking author is still working to get his updated PIN/TAN code finalized so the Flatpak, macOS, and Windows bundles of this release contain the last stable version, 6.5.4. The <a href="https://code.gnucash.org/builds/">GnuCash nightly builds</a> have beta releases with the new implementation, so consider using one of those if the stable AQBanking doesn't work for you.</p>

<h4>Known Problems</h4>
<p><a href="https://bugs.gnucash.org/buglist.cgi?bug_severity=blocker&amp;bug_severity=critical&amp;bug_severity=major&amp;bug_severity=normal&amp;bug_severity=minor&amp;bug_severity=trivial&amp;bug_status=NEW&amp;bug_status=ASSIGNED&amp;bug_status=NEEDINFO&amp;bug_status=REOPENED&amp;limit=0&amp;list_id=8149&amp;order=priority%2Cbug_severity&amp;query_format=advanced">Complete list of all open bugs.</a></p>

<h2>Documentation</h2>
<h4>The following fixes and improvements were not associated with bug reports:</h4>
<ul>
    <li>Update github CI actions versions.</li>
</ul>
<p>New and Updated Translations: German</p>

    <h3>Getting GnuCash for Windows and MacOS</h3>
<p>GnuCash is provided for both Microsoft Windows 10® and later
    and MacOS 10.13 (High Sierra)® and later in pre-built, all-in-one
    packages. An installer is provided for Microsoft Windows® while
    the MacOS® package is a disk image containing a drag-and-drop
    application bundle.</p>

<p>GnuCash is also available as a flatpak from Flathub.org. <a href="https://wiki.gnucash.org/wiki/Flatpak">Instructions for installing and running.</a></p>

<p>The SHA256 Hashes for the downloadable files are:</p>
<ul>
    <li><code>5be2e5364fc36464fc32c768e2ab460a630f74db6aeb7d44266e3dab98222fd0</code>&nbsp;&nbsp;gnucash-5.9.tar.bz2</li>
    <li><code>35375b2b1affe2a7e46becefb9e1205f432262c6ed0c7baa72f41b3b13f7235d</code>&nbsp;&nbsp;gnucash-5.9.tar.gz</li>
    <li><code>18882e68d445c32b7f06c58a55b6b81480cef4fdf6e159e8d628040357479b86</code>&nbsp;&nbsp;gnucash-5.9.setup.exe</li>
    <li><code>ab56dc3d9e7e07ad5b3abd97e181070780d62010a4184ff826bbe935a7d84a1d</code>&nbsp;&nbsp;Gnucash-Arm-5.9-1.dmg</li>
    <li><code>ebb05ce936059a1f6d5ceecd2de2de4aa7a5808210b35c8df318cdce9fc40475</code>&nbsp;&nbsp;Gnucash-Intel-5.9-1.dmg</li>
    <li><code>9bc43a2bd11cb431de446023fa6c273e0c432b5bd8933e2177ad007091f294c9</code>&nbsp;&nbsp;gnucash-docs-5.9.tar.gz</li>
</ul>

<ul>
    <li>SourceForge:
        <ul>
            <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.9/gnucash-5.9.setup.exe">Win32</a></li>
            <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.9/Gnucash-Arm-5.9-1.dmg">Mac-Apple Silicon</a></li>
            <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.9/Gnucash-Intel-5.9-1.dmg">Mac-Intel</a></li>
        </ul></li>
    <li>Github
        <ul>
            <li><a href="https://github.com/Gnucash/gnucash/releases/download/5.9/gnucash-5..setup.exe">Win32</a></li>
            <li><a href="https://github.com/Gnucash/gnucash/releases/download/5.9/Gnucash-Arm-5.9-1.dmg">Mac-Apple Silicon</a></li>
            <li><a href="https://github.com/Gnucash/gnucash/releases/download/5.9/Gnucash-Intel-5.9-1.dmg">Mac-Intel</a></li>
        </ul></li></ul>

<h3>Getting GnuCash as source code</h3>
<p>If you want to compile GnuCash 5.9 for yourself, the source code can be downloaded from:</p>
<ul>

    <li>Sourceforge: <a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.9/gnucash-5.9.tar.bz2">bzip2</a>, <a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.9/gnucash-5.9.tar.gz">gzip</a>.</li>

    <li>Github: <a href="https://github.com/Gnucash/gnucash/releases/download/5.9/gnucash-5.9.tar.bz2">bzip</a>, <a href="https://github.com/Gnucash/gnucash/releases/download/5.9/gnucash-5.9.tar.gz">gzip</a></li>

    <li>You can also checkout the sources directly from the git repository as <a href="https://wiki.gnucash.org/wiki/Git">described here.</a></li>
</ul>

<p>To compile GnuCash from the source code by yourself, you will need at least <a href="https://www.gtk.org/">Gtk+</a> 3.22.30, <a href="https://www.gnu.org/software/guile/">Guile</a> 2.0.9, <a href="https://www.boost.org/">Boost</a> 1.67, <a href="https://webkitgtk.org/">WebKitGtk</a> 2.4, <a href="https://github.com/google/googletest">GoogleTest</a> 1.8.0, <a href="https://cmake.org/">cmake 3.14.5</a> and <a href="http://www.swig.org/">SWIG</a> 3.0.12. Please consult the README.dependencies file in the sources for the exact list of dependencies and versions.</p>

<h3>Getting the documentation</h3>

<p>The documentation is available at <a href="https://www.gnucash.org/docs.phtml">Documentation page</a> of the <a href="https://www.gnucash.org/">GnuCash website</a>. The 5.9 documentation can be found under "GnuCash v5 (current stable release)" in multiple languages both for reading online and for download in pdf, epub, and mobi formats. The documentation is also included in the MacOS and Windows application bundles.</p>

<p>If you want to compile the GnuCash Documentation 5.9 for yourself, the source code can be downloaded from:</p>
<ul>
    <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.9/gnucash-docs-5.9.tar.gz">Sourceforge</a> or <a href="https://github.com/Gnucash/gnucash/releases/download/5.9/gnucash-docs-5.9.tar.gz">GitHub</a></li>
    <li>You can also checkout the sources directly from the git repository as <a href="https://wiki.gnucash.org/wiki/Git">described here.</a></li>
</ul>


<h3>About the Program</h3>

<p>GnuCash is a free, open source accounting program released under
    the GNU General Public License (GPL) and available for GNU/Linux,
    *BSD, Solaris, MacOS, and Microsoft Windows.  Programming on GnuCash
    began in 1997, and its first stable release was in 1998.</p>
  </div> <div>
<h2>GnuCash 5.8 Released</h2>

<p>The GnuCash development team announces GnuCash 5.8, the ninth release in the stable 5.x series. This is a snap releae to fix a serious bug in GnuCash 5.8.</p>

<h4>Between 5.7 and 5.8, the following bugfixes were accomplished:</h4><ul>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799347">Bug 799347 - Edit account to make it sub account under other account</a></li>
</ul>

<h4>There were no other changes.</h4>

<p>New and Updated Translations: Chinese (Traditional), Hebrew, Hungarian, Macedonian, Spanish</p>

<p><a href="https://hosted.weblate.org/engage/gnucash/">Help translate GnuCash on Weblate</a></p><h4>German AQBanking Users:</h4>
<p>The AQBanking author is still working to get his updated PIN/TAN code finalized so the Flatpak, macOS, and Windows bundles of this release contain the last stable version, 6.5.4. The <a href="https://code.gnucash.org/builds/">GnuCash nightly builds</a> have beta releases with the new implementation, so consider using one of those if the stable AQBanking doesn't work for you.</p>

<h4>Known Problems</h4>
<p><a href="https://bugs.gnucash.org/buglist.cgi?bug_severity=blocker&amp;bug_severity=critical&amp;bug_severity=major&amp;bug_severity=normal&amp;bug_severity=minor&amp;bug_severity=trivial&amp;bug_status=NEW&amp;bug_status=ASSIGNED&amp;bug_status=NEEDINFO&amp;bug_status=REOPENED&amp;limit=0&amp;list_id=8149&amp;order=priority%2Cbug_severity&amp;query_format=advanced">Complete list of all open bugs.</a></p>

<h2>Documentation</h2>
<h4>No changes were made between 5.7 and 5.8.</h4>
<h3>Getting GnuCash for Windows and MacOS</h3>
<p>GnuCash is provided for both Microsoft Windows 10® and later
    and MacOS 10.13 (High Sierra)® and later in pre-built, all-in-one
    packages. An installer is provided for Microsoft Windows® while
    the MacOS® package is a disk image containing a drag-and-drop
    application bundle.</p>

<p>GnuCash is also available as a flatpak from Flathub.org. <a href="https://wiki.gnucash.org/wiki/Flatpak">Instructions for installing and running.</a></p>

<p>The SHA256 Hashes for the downloadable files are:</p>
<ul>
    <li><code>a2c823fb700b9d4598692ec81394959bde388d8ef191efe4ea2c02426bb52593</code>&nbsp;&nbsp;gnucash-5.8.tar.bz2</li>
    <li><code>b00cff635e8bc8ff996a9f7942fd92414f13ccf3415402cc33220ee58d6f12b8</code>&nbsp;&nbsp;gnucash-5.8.tar.gz</li>
    <li><code>a8fdeab6ea49dfb78fa5f6b638005b3e392a8d87c1ed6bc9b0f56ebb48eaa48f</code>&nbsp;&nbsp;gnucash-5.8-1.setup.exe</li>
    <li><code>d3f24a955547d30fa4116252d1bc35247117b6449cdedf51236b502f294cb436</code>  Gnucash-Arm-5.8-2.dmg</li>
    <li><code>ddfbbecc87db276dc30a164a90b51189702215d4326160346824cb69d7f0ffe9</code>&nbsp;&nbsp;Gnucash-Intel-5.8-2.dmg</li>
    <li><code>b8f344ec5824090669f93e9ba3ecfafecd55462a5ff1b2d323d7a9c8f9aa5a3f</code>&nbsp;&nbsp;gnucash-docs-5.8.tar.gz</li>
</ul>

<ul>
    <li>SourceForge:
        <ul>
            <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.8/gnucash-5.8-1.setup.exe">Win32</a></li>
            <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.8/Gnucash-Arm-5.8-1.dmg">Mac-Apple Silicon</a></li>
            <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.8/Gnucash-Intel-5.8-2.dmg">Mac-Intel</a></li>
        </ul></li>
    <li>Github
        <ul>
            <li><a href="https://github.com/Gnucash/gnucash/releases/download/5.8/gnucash-5.8-1.setup.exe">Win32</a></li>
            <li><a href="https://github.com/Gnucash/gnucash/releases/download/5.8/Gnucash-Arm-5.8-1.dmg">Mac-Apple Silicon</a></li>
            <li><a href="https://github.com/Gnucash/gnucash/releases/download/5.8/Gnucash-Intel-5.8-2.dmg">Mac-Intel</a></li>
        </ul></li></ul>

<h3>Getting GnuCash as source code</h3>
<p>If you want to compile GnuCash 5.8 for yourself, the source code can be downloaded from:</p>
<ul>

    <li>Sourceforge: <a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.8/gnucash-5.8.tar.bz2">bzip2</a>, <a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.8/gnucash-5.8.tar.gz">gzip</a>.</li>

    <li>Github: <a href="https://github.com/Gnucash/gnucash/releases/download/5.8/gnucash-5.8.tar.bz2">bzip</a>, <a href="https://github.com/Gnucash/gnucash/releases/download/5.8/gnucash-5.8.tar.gz">gzip</a></li>

    <li>You can also checkout the sources directly from the git repository as <a href="https://wiki.gnucash.org/wiki/Git">described here.</a></li>
</ul>

<p>To compile GnuCash from the source code by yourself, you will need at least <a href="https://www.gtk.org/">Gtk+</a> 3.22.29, <a href="https://www.gnu.org/software/guile/">Guile</a> 2.0, <a href="https://www.boost.org/">Boost</a> 1.67, <a href="https://webkitgtk.org/">WebKitGtk</a> 2.4, <a href="https://github.com/google/googletest">GoogleTest</a> 1.8.0, <a href="https://cmake.org/">cmake 3.10</a> and <a href="http://www.swig.org/">SWIG</a> 2.0.12. Please consult the README.dependencies file in the sources for the exact list of dependencies and versions.</p>

<h3>Getting the documentation</h3>

<p>The documentation is available at <a href="https://www.gnucash.org/docs.phtml">Documentation page</a> of the <a href="https://www.gnucash.org/">GnuCash website</a>. The 5.8 documentation can be found under "GnuCash v5 (current stable release)" in multiple languages both for reading online and for download in pdf, epub, and mobi formats. The documentation is also included in the MacOS and Windows application bundles.</p>

<p>If you want to compile the GnuCash Documentation 5.8 for yourself, the source code can be downloaded from:</p>
<ul>
    <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.8/gnucash-docs-5.8.tar.gz">Sourceforge</a> or <a href="https://github.com/Gnucash/gnucash/releases/download/5.8/gnucash-docs-5.8.tar.gz">GitHub</a></li>
    <li>You can also checkout the sources directly from the git repository as <a href="https://wiki.gnucash.org/wiki/Git">described here.</a></li>
</ul>


<h3>About the Program</h3>

<p>GnuCash is a free, open source accounting program released under
    the GNU General Public License (GPL) and available for GNU/Linux,
    *BSD, Solaris, MacOS, and Microsoft Windows.  Programming on GnuCash
    began in 1997, and its first stable release was in 1998.</p>
  </div> <div>
<h2>GnuCash 5.7 Released</h2>

<p>The GnuCash development team announces GnuCash 5.7, the eighth release in the stable 5.x series.</p>

<h4>Between 5.6 and 5.7, the following bugfixes were accomplished:</h4>
<ul>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=669031">Bug 669031 - Save the Scheduled Transactions number of months</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=669035">Bug 669035 - Save the Scheduled Transaction divider position</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798822">Bug 798822 - Move to blank transaction</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799047">Bug 799047 - AutoComplete Only Considers Visible Transactions</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799258">Bug 799258 - Reports calculating net worth incorrectly after stock split</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799262">Bug 799262 - Failed import QIF investment</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799264">Bug 799264 - option account selector fails to include appropriate hidden accounts.</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799268">Bug 799268 - Cannot write a check over $1000</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799272">Bug 799272 - Crashes when pasting a copied transaction</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799279">Bug 799279 - Import Matcher (CSV) does not compute correctly the share amount based on security price</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799281">Bug 799281 - Deleting a transaction may trigger a crash</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799290">Bug 799290 - Invoice register context menu issue</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799298">Bug 799298 - Shortcut Ctrl-G does not work in the General Journal register for the default date value</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799300">Bug 799300 - Nullpointer exception in gnc_quote_source_s</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799305">Bug 799305 - Crash when there is more than one unknown quote source for commodities</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799309">Bug 799309 - Import Multi-split CSV can duplicate 'Notes' field from one transaction to next</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799320">Bug 799320 - GNUCash Immediately Exits on Startup</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799324">Bug 799324 - Invalid free in gvalue_from_kvp_value()</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799334">Bug 799334 - GnuCash re-opens to incorrect account window if there are transient tabs present when closed.</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799336">Bug 799336 - Stock Assistant closes with its New Account dialog</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799339">Bug 799339 - RFE: Add Document Link for Payments to Owner Report</a></li>
</ul>
<h4>The following fixes and improvements were not associated with bug reports:</h4>
<ul>
    <li>New Report: Exprimental&gt;Transaction Breakdown Report<p>Retrieves transactions from an account, distributes the splits into accounts - note if a transaction has 2 or more splits into 1 account, the transaction account cell will show the sum of the 2 splits - note if a transaction's currency is different from the account's currency, both amounts will be shown into the appropriate currency.  [txn-columns] multilevel sorting - type then name. </p></li>
    <li>Add ability for the dense calendar to start from any week day.</li>
    <li>In the dense calendar, add a default number of months per column entry to the view model to get a better layout when the function gnc_dense_cal_set_num_months is solely used.</li>
    <li>Add today indication on the dense calendar</li>
    <li>Updated the Quote Sources list in the Security Editor to match F::Q v1.59</li>
    <li>Import Matcher - select row if none is selected yet when right-clicking the list of matches</li>
    <li>Change the default visible period for General Ledger from 1 calendar month to 30 days.</li>
    <li>Fix Failing SRFI-64 tests being reported as pass by ctest with guile-3.</li>
    <li>Ensure that filters are re-applied to multi-account registers when the number of included sub-accounts changes.</li>
    <li>Copy the latest price when creating a new entry in the Price Editor from a commodity selection</li>
    <li>New function <code>gnc_account_foreach_until_date</code> uses binary search to find first split after date, then for_each from earliest split to (but excluding) that split. </li>
    <li>New function <code>gnc_reports_foreach</code> to abstract GHashTable-base implementation.</li>
    <li>Cleanup - remove deprecated function (re-)defines that were deprected 11 years ago.</li>
    <li>[engine.i] move gnc_accounts_and_all_descendants to engine.i</li>
    <li>[Account.cpp] Convert children from GList to std::vector. </li>
    <li>[html-utilities.scm] show acct full names in gnc:html-render-options-changed</li>
    <li>[ifrs-cost-basis.scm] amend truth table as per bug 797796 comment 241 further amendments to match updated truth table.</li>
    <li>Clean up some obsolete tools and references to non-git VCS's</li>
    <li>Rework version-info rules to allow building from github downloaded zip archives</li>
    <li>Remove account splits in reverse crono order, speeds up book shutdown.</li>
    <li>Move libgnucash/doc/xml to libgnucash/backend/xml/DTD</li>
    <li>Remove libgnucash/docs, ensuring all of the content is available either in Doxygen comments or in the Wiki.</li>
    <li>Remove XCode info from HACKING, obsolete. Move valgrind/callgrind instructions to the Wiki.</li>
    <li>Move doxygen target and related files to toplevel. Note: this also means the target directory changes from libgnucash/docs/html to [toplevel]/doxygen/html and the main page is specified directly in doxygen.cfg.</li>
    <li>Drop old migration script to split qof from engine</li>
    <li>Update doxygen.cfg file to more recent release</li>
    <li>Doxygen - Clean up obsolete files and comments.</li>
    <li>[gnc-ofx-import.cpp] show message while deduplicating download</li>
    <li>Replace more GLib containers with C++ containers.</li>
    <li>Change python install path to be compatible with distro installations.</li>
    <li>Update some C++ template override signatures to be C++20 compliant.</li>
    <li>[gnc-log-replay.cpp] don't set import to DEBUG because it'll spew too many debug messages when gnc-log-replay completes.</li>
    <li>Fix transaction report sorting/show-account-description and display.</li>
    <li>[test-commodity-utils.scm] don't test TZ-sensitive datetimes</li>
    <li>[engine.i] gnc_get_match_commodity_splits from scheme to c++ for better efficiency.</li>
    <li>[utest-Account] add more balance limit tests</li>
    <li>Convert more C files to C++</li>
    <li>Fix more memory leaks and use-after-frees.</li>
    <li>[Transaction|Split.cpp] Remove Reg2 unused functions</li>
</ul>

<h4>German AQBanking Users:</h4>
<p>The AQBanking author is still working to get his updated PIN/TAN code finalized so the Flatpak, macOS, and Windows bundles of this release contain the last stable version, 6.5.4. The <a href="https://code.gnucash.org/builds/">GnuCash nightly builds</a> have beta releases with the new implementation, so consider using one of those if the stable AQBanking doesn't work for you.</p>

<p><b>New and Updated Translations:</b> Arabic, Croatian, Dutch, English (Australia), English (New Zealand), English (United Kingdom), French, German, Hebrew, Hungarian, Italian, Japanese, Macedonian, Norwegian Bokmål, Polish, Portuguese (Brazil), Slovak, Tamil, Turkish, Urdu</p>

<p><a href="https://hosted.weblate.org/engage/gnucash/">Help translate GnuCash on Weblate</a></p><h4>Known Problems</h4>
<p><a href="https://bugs.gnucash.org/buglist.cgi?bug_severity=blocker&amp;bug_severity=critical&amp;bug_severity=major&amp;bug_severity=normal&amp;bug_severity=minor&amp;bug_severity=trivial&amp;bug_status=NEW&amp;bug_status=ASSIGNED&amp;bug_status=NEEDINFO&amp;bug_status=REOPENED&amp;limit=0&amp;list_id=8149&amp;order=priority%2Cbug_severity&amp;query_format=advanced">Complete list of all open bugs.</a></p>

<h2>Documentation</h2>
<h4>Between 5.6 and 5.7, no bugfixes were accomplished:</h4>


<h4>The following fixes and improvements were not associated with bug reports:</h4>
<ul>
<li>gnc-struct: change entity and section id's for 'employee-voucher'</li>
<li>All: manual, ch_Business: Harmonize section IDs: Numbers for the nesting depth of the sections are not required.</li>
<li>All: manual, ch_Business, Change id=“busnss-emplyedit” to “busnss-emplyfind”, as the Find dialog is described here.</li>
<li>docbook: Improve entity untranslated</li>
<li>docbook: use entitiy for url-wiki</li>
<li>de, pt: Update &amp;untranslated-*; to &amp;untranslated;</li>
<li>C: Manual: Getting Help: resolve ambiguities</li>
<li>de: Handbuch: ergänze Leerzeichen, löse Mehrdeutigkeiten auf</li>
<li>docbook: additional entities for business menuitems</li>
<li>Guide(zh): fix xml validity error</li>
</ul>

<p>New and Updated Translations: Chinese, German</p>


<h3>Getting GnuCash for Windows and MacOS</h3>
<p>GnuCash is provided for both Microsoft Windows 10® and later
    and MacOS 10.13 (High Sierra)® and later in pre-built, all-in-one
    packages. An installer is provided for Microsoft Windows® while
    the MacOS® package is a disk image containing a drag-and-drop
    application bundle.</p>

<p>GnuCash is also available as a flatpak from Flathub.org. <a href="https://wiki.gnucash.org/wiki/Flatpak">Instructions for installing and running.</a></p>

<p>The SHA256 Hashes for the downloadable files are:</p>
<ul>
    <li><code>bdd09df26e0863b3b1b09d6e5ea469ad0224b04691380c6c794c76e51fbae702</code>&nbsp;&nbsp;gnucash-5.7.tar.bz2</li>
    <li><code>f6af2a455e7b8a5e95f3f71041f1eeec43fc92ec3bff37c3fdb4e364b2bb2239</code>&nbsp;&nbsp;gnucash-5.7.tar.gz</li>
    <li><code>8c000a84246f08a193e9da22d3ae760499f00fbe4fb77d310488c596715c1487</code>&nbsp;&nbsp;gnucash-5.7-1.setup.exe</li>
    <li><code>1f55eb6eadd1ff18c41947601d57d43e280732dff577621e0441b47d9d688b0a</code>&nbsp;&nbsp;Gnucash-Intel-5.7-1.dmg</li>
    <li><code>1cb5dc4a7a84f12ce1d7f1f072456c8a5cbc14486b2ccf6918bf88c8dd98647a</code>&nbsp;&nbsp;gnucash-docs-5.7.tar.gz</li>
</ul>

<ul>
    <li>SourceForge:
        <ul>
            <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.7/gnucash-5.7-1.setup.exe">Win32</a></li>
            <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.7/Gnucash-Intel-5.7-1.dmg">Mac-Intel</a></li>
        </ul></li>
    <li>Github
        <ul>
            <li><a href="https://github.com/Gnucash/gnucash/releases/download/5.7/gnucash-5.7-1.setup.exe">Win32</a></li>
            <li><a href="https://github.com/Gnucash/gnucash/releases/download/5.7/Gnucash-Intel-5.7-1.dmg">Mac-Intel</a></li>
        </ul></li></ul>

<h3>Getting GnuCash as source code</h3>
<p>If you want to compile GnuCash 5.7 for yourself, the source code can be downloaded from:</p>
<ul>

    <li>Sourceforge: <a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.7/gnucash-5.7.tar.bz2">bzip2</a>, <a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.7/gnucash-5.7.tar.gz">gzip</a>.</li>

    <li>Github: <a href="https://github.com/Gnucash/gnucash/releases/download/5.7/gnucash-5.7.tar.bz2">bzip</a>, <a href="https://github.com/Gnucash/gnucash/releases/download/5.7/gnucash-5.7.tar.gz">gzip</a></li>

    <li>You can also checkout the sources directly from the git repository as <a href="https://wiki.gnucash.org/wiki/Git">described here.</a></li>
</ul>

<p>To compile GnuCash from the source code by yourself, you will need at least <a href="https://www.gtk.org/">Gtk+</a> 3.22.29, <a href="https://www.gnu.org/software/guile/">Guile</a> 2.0, <a href="https://www.boost.org/">Boost</a> 1.67, <a href="https://webkitgtk.org/">WebKitGtk</a> 2.4, <a href="https://github.com/google/googletest">GoogleTest</a> 1.8.0, <a href="https://cmake.org/">cmake 3.10</a> and <a href="http://www.swig.org/">SWIG</a> 2.0.12. Please consult the README.dependencies file in the sources for the exact list of dependencies and versions.</p>

<h3>Getting the documentation</h3>

<p>The documentation is available at <a href="https://www.gnucash.org/docs.phtml">Documentation page</a> of the <a href="https://www.gnucash.org/">GnuCash website</a>. The 5.7 documentation can be found under "GnuCash v5 (current stable release)" in multiple languages both for reading online and for download in pdf, epub, and mobi formats. The documentation is also included in the MacOS and Windows application bundles.</p>

<p>If you want to compile the GnuCash Documentation 5.7 for yourself, the source code can be downloaded from:</p>
<ul>
    <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.7/gnucash-docs-5.7.tar.gz">Sourceforge</a> or <a href="https://github.com/Gnucash/gnucash/releases/download/5.7/gnucash-docs-5.7.tar.gz">GitHub</a></li>
    <li>You can also checkout the sources directly from the git repository as <a href="https://wiki.gnucash.org/wiki/Git">described here.</a></li>
</ul>


<h3>About the Program</h3>

<p>GnuCash is a free, open source accounting program released under
    the GNU General Public License (GPL) and available for GNU/Linux,
    *BSD, Solaris, MacOS, and Microsoft Windows.  Programming on GnuCash
    began in 1997, and its first stable release was in 1998.</p>
  </div> <div>
<h2>GnuCash 5.6 Released</h2>

<p>The GnuCash development team announces GnuCash 5.6, the seventh release in the stable 5.x series.</p>

<h4>Between 5.5 and 5.6, the following bugfixes were accomplished:</h4>
<ul>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798946">Bug 798946 - start/end of current/last quarter have off-by-one error</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799093">Bug 799093 - Cannot reconcile since v5.4</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799179">Bug 799179 - SLR won't allow change from "Reminder" to any other state</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799210">Bug 799210 - Bad encoding of accented chars in account names in "Import CSV" wizard</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799213">Bug 799213 - SIGSEGV caused by revising an auto completed transaction</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799222">Bug 799222 - Crash when changing the parent of an account that has had two or more levels of sub-accounts auto-created using the register in the current session.</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799224">Bug 799224 - Import of QIF gets Bug detected during duplicates (partial fix</a>: If the new-splits object is null, it means the new account tree from the current import has no splits. Therefore the (apply min|max dates) will fail. Omitting the date query is a simple fix to prevent crashing.  This is a partial fix because the crash is likely a symptom of another bug which causes the new account-tree to be empty. </li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799225">Bug 799225 - QIF Importer Crashes Silently after "Start Import" Button</a>: Don't allow a QIF investment transaction without an action (buy/sell/etc) </li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799246">Bug 799246 - import matcher will rename incorrect splits</a></li>
</ul>
<h4>The following fixes and improvements were not associated with bug reports:</h4>
<ul>
    <li>Numeric parsing and string handling improvements in the Engine and XML backend.</li>
    <li>[gnc-dense-cal.c] sx popup: show date in preference (cf.locale) format because the date format preference is user-facing and customisable. it's jarring if the preference is dd/mm/yyyy and the display shows mm/dd/yyyy in accordance to the locale. </li>
    <li>Correct misleading description about creating Scheduled Transaction.</li>
    <li>Date parsing efficiency improvements.</li>
    <li>Update minumum Python version to 3.8, made necessary by updating the C API in the Python bindings.</li>
    <li>Replace deprecated distutils.sysconfig with sysconfig. distutils is not present in Python 3.12.2. </li>
    <li>Query user via dialog for date when creating a reverse transaction.</li>
    <li>More C++ conversions</li>
    <li>Avoid deprecation warning for -py3 in swig &gt;= 4.1</li>
    <li>[gnc-commodities.cpp] gnc_new_iso_codes is a std::unordered_map</li>
    <li>Replace some naked for loops with C++ algorithms</li>
    <li>Convert gnc-commodity to C++ and make GncQuoteSources a C++ class.</li>
    <li>[test-commodities.cpp] add some tests for gnc_quote_sources</li>
    <li>Remove the SLR status sort as it is too confusing</li>
    <li>Allow sorting of the transaction column in the Since Last Run dialog by schedule name or occurrence date.  To sort by schedule name, a schedule name is first selected and then the column header is pressed to change order.  To sort by occurrence date, a date is selected and then the column header is pressed to change order based on the date of the first occurrence.  A tool tip has been added to indicate the sort order being used. </li>
    <li>[gtest-gnc-numeric] add operator comparisons with example int64 numbers </li>
    <li>[assistant-stock-transaction] store &amp; retrieve associated account as metadata</li>
    <li>Update Form/Schedule line references for 2023 for the US Income Tax Report</li>
    <li>Update another gnucash-help to gnucash-manual</li>
    <li>[invoice.scm] centralize layout components into layout-key-list instead of maintaining 2 assoc lists. </li>
    <li>[invoice.scm] normalize header section generators, changing the functions to require 1 options argument only </li>
    <li>Update invoice.scm: Add spacing for long Invoice ID's (Displayed as "Reference" on the Invoice)</li>
</ul>

<p>New and Updated Translations: Croatian, Dutch, English (Australia), English (New Zealand), English (United Kingdom), French, German, Hebrew, Hungarian, Indonesian, Japanese, Norwegian Bokmål, Polish, Portuguese, Slovak, Spanish, Swedish</p>

<p><a href="https://hosted.weblate.org/engage/gnucash/">Help translate GnuCash on Weblate</a></p><h4>Known Problems</h4>
<p><a href="https://bugs.gnucash.org/buglist.cgi?bug_severity=blocker&amp;bug_severity=critical&amp;bug_severity=major&amp;bug_severity=normal&amp;bug_severity=minor&amp;bug_severity=trivial&amp;bug_status=NEW&amp;bug_status=ASSIGNED&amp;bug_status=NEEDINFO&amp;bug_status=REOPENED&amp;limit=0&amp;list_id=8149&amp;order=priority%2Cbug_severity&amp;query_format=advanced">Complete list of all open bugs.</a></p>

<h2>Documentation</h2>
<h6>Between 5.5 and 5.6, the following bugfixes were accomplished:</h6>
<ul>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799237">Bug 799237 - Dead Link</a></li>
</ul>

<h4>The following fixes and improvements were not associated with bug reports:</h4>
<ul>
    <li>C, de:Manual:Finance-Quote: Note about Expected Time Commitment</li>
    <li>C, de:Manual:Finance-Quote: Tip about 'gnc-fq-update: Command not found'</li>
    <li>docbook: gnc-gui-de: Improve accelerator of menuitems</li>
    <li>Link https://wiki.gnucash.org/wiki/Documentation_Translation#The_Procedure in recent gnc-gui-*.dtd files</li>
    <li>Replace *dquote entities by &lt;quote&gt; tags</li>
    <li>C:Manual:Tools:Unify main section titles and other minor improvements</li>
    <li>Unify filename extension</li>
    <li>C:Manual:CSV Import: show icons</li>
    <li>xmlformat: Apply changes at the element 'screeninfo'</li>
    <li>xmlformat.conf: new element 'screeninfo' with no entry- and no exit-break</li>
</ul>


<p>New and Updated Translations: German</p>


<h3>Getting GnuCash for Windows and MacOS</h3>
<p>GnuCash is provided for both Microsoft Windows 8.1® and later
    and MacOS 10.13 (High Sierra)® and later in pre-built, all-in-one
    packages. An installer is provided for Microsoft Windows® while
    the MacOS® package is a disk image containing a drag-and-drop
    application bundle.</p>

<p>GnuCash is also available as a flatpak from Flathub.org. <a href="https://wiki.gnucash.org/wiki/Flatpak">Instructions for installing and running.</a></p>

<p>The SHA256 Hashes for the downloadable files are:</p>
<ul>
    <li><code>b4b42c626350f3e79f7ca1f2173545cc63ddee1addf2460b1a1f22221bf21bd1</code>&nbsp;&nbsp;gnucash-5.6.tar.bz2</li>
    <li><code>50aebe914da600003c3b668c6a0b86df3d583a200c378f0f16658bec299bbbd3</code>&nbsp;&nbsp;gnucash-5.6.tar.gz</li>
    <li><code>4596d431e5785ef3d80bcbea6e1c5e1df98c3b9b27314e6d8d2eae679424f56c</code>&nbsp;&nbsp;gnucash-5.6-1.setup.exe</li>
    <li><code>2cc91f36d9939065dac366058aae1a6a8c41cfe84850b6b549ee87ba075d50d4</code>&nbsp;&nbsp;Gnucash-Intel-5.6-1.dmg</li>
    <li><code>8ad9da28199074fc5ef604d4489a82413031290a06e5f6418fe85cceb5fa3f02</code>&nbsp;&nbsp;gnucash-docs-5.6.tar.gz</li>
</ul>

<ul>
    <li>SourceForge:
        <ul>
            <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.6/gnucash-5.6-1.setup.exe">Win32</a></li>
            <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.6/Gnucash-Intel-5.6-1.dmg">Mac-Intel</a></li>
        </ul></li>
    <li>Github
        <ul>
            <li><a href="https://github.com/Gnucash/gnucash/releases/download/5.6/gnucash-5.6-1.setup.exe">Win32</a></li>
            <li><a href="https://github.com/Gnucash/gnucash/releases/download/5.6/Gnucash-Intel-5.6-1.dmg">Mac-Intel</a></li>
        </ul></li></ul>

<h3>Getting GnuCash as source code</h3>
<p>If you want to compile GnuCash 5.6 for yourself, the source code can be downloaded from:</p>
<ul>

    <li>Sourceforge: <a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.6/gnucash-5.6.tar.bz2">bzip2</a>, <a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.6/gnucash-5.6.tar.gz">gzip</a>.</li>

    <li>Github: <a href="https://github.com/Gnucash/gnucash/releases/download/5.6/gnucash-5.6.tar.bz2">bzip</a>, <a href="https://github.com/Gnucash/gnucash/releases/download/5.6/gnucash-5.6.tar.gz">gzip</a></li>

    <li>You can also checkout the sources directly from the git repository as <a href="https://wiki.gnucash.org/wiki/Git">described here.</a></li>
</ul>

<p>To compile GnuCash from the source code by yourself, you will need at least <a href="https://www.gtk.org/">Gtk+</a> 3.22.29, <a href="https://www.gnu.org/software/guile/">Guile</a> 2.0, <a href="https://www.boost.org/">Boost</a> 1.67, <a href="https://webkitgtk.org/">WebKitGtk</a> 2.4, <a href="https://github.com/google/googletest">GoogleTest</a> 1.8.0, <a href="https://cmake.org/">cmake 3.10</a> and <a href="http://www.swig.org/">SWIG</a> 2.0.12. Please consult the README.dependencies file in the sources for the exact list of dependencies and versions.</p>

<h3>Getting the documentation</h3>

<p>The documentation is available at <a href="https://www.gnucash.org/docs.phtml">Documentation page</a> of the <a href="https://www.gnucash.org/">GnuCash website</a>. The 5.6 documentation can be found under "GnuCash v5 (current stable release)" in multiple languages both for reading online and for download in pdf, epub, and mobi formats. The documentation is also included in the MacOS and Windows application bundles.</p>

<p>If you want to compile the GnuCash Documentation 5.6 for yourself, the source code can be downloaded from:</p>
<ul>
    <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.6/gnucash-docs-5.6.tar.gz">Sourceforge</a> or <a href="https://github.com/Gnucash/gnucash/releases/download/5.6/gnucash-docs-5.6.tar.gz">GitHub</a></li>
    <li>You can also checkout the sources directly from the git repository as <a href="https://wiki.gnucash.org/wiki/Git">described here.</a></li>
</ul>


<h3>About the Program</h3>

<p>GnuCash is a free, open source accounting program released under
    the GNU General Public License (GPL) and available for GNU/Linux,
    *BSD, Solaris, MacOS, and Microsoft Windows.  Programming on GnuCash
    began in 1997, and its first stable release was in 1998.</p>
  </div> <div>
<h2>GnuCash 5.5 Released</h2>

<p>The GnuCash development team announces GnuCash 5.5, the sixth release in the stable 5.x series.</p>

<h4>Between 5.4 and 5.5, the following bugfixes were accomplished:</h4>
<ul>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=607000">Bug 607000 - SLR visible transactions</a><p>Change the Since Last Run dialog to show only transactions with a non-empty Status. </p></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=792241">Bug 792241 - Allow sorting scheduled transactions</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798025">Bug 798025 - SLR Value entry not tied to location</a><p>Disable scrolling and the horizontal scroll bar while an entry has focus. </p></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798760">Bug 798760 - SLR OK button to complete value entry</a><p>With this change the Since Last Run dialog's OK button will commit an in-progress edit and advance to the next edit requiring input. It will close the dialog only if there are no more edits.</p></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798760">Bug 798760 - SLR change reminder with value entry</a><p>Change transaction state from Reminder to ToCreate when the user has provided the needed value and clicked OK.</p></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798890">Bug 798890 - Printing Problem</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799087">Bug 799087 - Import - Unbalanced (need acct) transactions now show in red (previously orange).</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799090">Bug 799090 - Right Clicking scheduled transaction</a><p>Ensure that the selection highlight changes to the item under the pointer when right-clicking in the SX Editor.</p></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799092">Bug 799092 - GnuCash 5.4 leaves background process running on exit</a><p>Clear the schema_hash at app shutdown via gnc_prefs_remove_registered and make that function available to the Python bindings so that python programs can do so too. </p></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799099">Bug 799099 - Crash when trying to get quotes</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799104">Bug 799104 - "Asset Chart" broken</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799108">Bug 799108 - "Since Last Run" crashes if there are any errors creating a scheduled transaction</a><p>Capture errors and display them in a dialog box instead.</p></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799113">Bug 799113 - "Start Import" button reports "Failed"</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799121">Bug 799121 - Parse error on CSV import on MacOS</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799130">Bug 799130 - split-register.c:1847:gnc_split_register_save: assertion failed: (xaccTransIsOpen (blank_trans))</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799134">Bug 799134 - Fails to build with GCC 14 (‘find_if’ is not a member of ‘std’; did you mean ‘find’)</a> </li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799138">Bug 799138 - Port to new Python C config API</a>
    <p>Note that this increases the minimum Python version to 3.8</p></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799143">Bug 799143 - FTBFS on 32bit architectures</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799144">Bug 799144 - Date Completion is broken after 5.4 upgrade</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799148">Bug 799148 - Reliable crash when saving a modified saved report configuration</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799150">Bug 799150 - Can't paste text (with Ctrl+V) in Notes field in Account Tree View</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799151">Bug 799151 - gnc_date_get_last_mday () does not account for leap years correctly. </a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799152">Bug 799152 - normalize_reldate_tm() does not handle dates with months greater than 11 or less than -11 correctly. </a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799156">Bug 799156 - normalize_struct_tm() does not normalize seconds,minutes, and hours correctly.</a></li>
</ul>
<h4>The following fixes and improvements were not associated with bug reports:</h4>
<ul>
    <li>Cancel the QIF import instead of inserting the default directory if the user cancels the file-selection dialog.</li>

    <li>Memory leak fixes</li>
    <li>Rename the scheduled transaction edit/new/delete menus to resolve a shortcut conflict.</li>
    <li>Allow saving the sort column in the Since Last Run dialog</li>
    <li>Ensure that Print Checks obtains for the check amount the sum of all splits in the current register account and subaccounts.</li>
    <li>Ensure that report page actions are re-enabled after editing options. Some actions (Print, PDFExport, and Report Options) had been left disabled.</li>
    <li> Ensure GncDateEntry always reverts to today if the user enters an invalid date string.</li>
    <li>Direct cmake to find the base installed Python3 instead of the latest version installed. Reference <a href="https://gitlab.kitware.com/cmake/cmake/-/issues/24126">Cmake Issue 24126</a>, <a href="https://gitlab.kitware.com/cmake/cmake/-/issues/24878">Cmake Issue 24878</a>, and <a href="https://gitlab.kitware.com/cmake/cmake/-/merge_requests/8287">CMake merge request 8287</a>. Note that this requires CMake 3.20 or later; users of older versions will still get the newest installed Python version.</li>
    <li>CI: Run distcheck on one workflow to catch quickly instances where someone adds a file but forgets to update the distribution. </li>
    <li>Primarily of interest to developers: We've added a new CMAKE_BUILD_TYPE, Asan, with two options -DLEAKS and -DODR, both of which default to OFF. This creates a non-optimized, with-symbols build with the Address Sanitizer hooks compiled in. While the primary motivation is a CI run to ensure that there aren't any memory allocation errors revealed in the test suite, this is also a useful build to use when debugging a segfault crash, many of which are caused by use-after-free errors. When building on non-Apple platforms -DLEAKS=ON will add leak detection, dumping a stack trace for the allocation of any leaked heap or free-store allocations. Similarly and on non-Apple platforms only -DODR=ON will log violations of the C++ one definition rule.</li>
    <li>Also of interest to developers: A new cmake option -DCOVERAGE. When on and in a non-optimized build this will instrument the program and libraries to count usage for every source line. The option also adds three targets, lcov-initialize, lcov-collect, and lcov-generate-html. The primary motivation is to assess the completeness of tests in CI, see <a href="https://gnucash.github.io/Coverage-HTML">Coverage-HTML</a> for the latest results.</li>
</ul>

<p>New and Updated Translations: Chinese (Simplified), Croatian, Dutch, English
    (Australia), English (New Zealand), English (United Kingdom), Finnish,
    German, Gujarati, Hungarian, Italian, Norwegian Bokmål, Polish, Portuguese,
    Portuguese (Brazil), Romanian, Russian, Slovak, Spanish, Swedish</p>

<p><a href="https://hosted.weblate.org/engage/gnucash/">Help translate GnuCash on Weblate</a></p><h4>Known Problems</h4>
<p><a href="https://bugs.gnucash.org/buglist.cgi?bug_severity=blocker&amp;bug_severity=critical&amp;bug_severity=major&amp;bug_severity=normal&amp;bug_severity=minor&amp;bug_severity=trivial&amp;bug_status=NEW&amp;bug_status=ASSIGNED&amp;bug_status=NEEDINFO&amp;bug_status=REOPENED&amp;limit=0&amp;list_id=8149&amp;order=priority%2Cbug_severity&amp;query_format=advanced">Complete list of all open bugs.</a></p>

<h2>Documentation</h2>
<h4>No changes were associated with bug reports between releases 5.4 and 5.5</h4>

<h4>The following fixes and improvements were not associated with bug reports:</h4>
<ul>
    <li>EBICS: for business customers (of the bank) rather than business users.</li>
    <li>docbook: additional entities for business GUI-elements</li>
    <li>docbook: gnc-gui-*: Rename the scheduled edit/new/delete menus to match a change in the program.</li>
</ul>

<p>New and Updated Translations: German</p>


<h3>Getting GnuCash for Windows and MacOS</h3>
<p>GnuCash is provided for both Microsoft Windows 8.1® and later
    and MacOS 10.13 (High Sierra)® and later in pre-built, all-in-one
    packages. An installer is provided for Microsoft Windows® while
    the MacOS® package is a disk image containing a drag-and-drop
    application bundle.</p>

<p>GnuCash is also available as a flatpak from Flathub.org. <a href="https://wiki.gnucash.org/wiki/Flatpak">Instructions for installing and running.</a></p>

<p>The SHA256 Hashes for the downloadable files are:</p>
<ul>
    <li><code>b4daf67bb892b706323f62e9fa97242039d7dd0a2e1e10771e0c25817dd0ed3b</code>&nbsp;&nbsp;gnucash-5.5.tar.bz2</li>
    <li><code>73d2c367f7f1c2da045ce08cb7dfc619e43002ac1e17bb708e3287edff96ae47</code>&nbsp;&nbsp;gnucash-5.5.tar.gz</li>
    <li><code>ca0fc0c79f378a3bc5cf767fe83bc5d073ae617bb1907443b41b470dbb5be7ea</code>&nbsp;&nbsp;gnucash-5.5-1.setup.exe</li>
    <li><code>a27ab3dd3ada69456cb8033473f7bab5ae5874a4880416672d9b4fd2e1c26408</code>&nbsp;&nbsp;Gnucash-Intel-5.5-1.dmg</li>
    <li><code>93560f55d9305aef45525cf7e7143b72503365c353840dfaaa382d9dfb97c8ab</code>&nbsp;&nbsp;gnucash-docs-5.5.tar.gz</li>
</ul>

<ul>
    <li>SourceForge:
        <ul>
            <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.5/gnucash-5.5.setup.exe">Win32</a></li>
            <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.5/Gnucash-Intel-5.5-1.dmg">Mac-Intel</a></li>
        </ul></li>
    <li>Github
        <ul>
            <li><a href="https://github.com/Gnucash/gnucash/releases/download/5.5/gnucash-5.5.setup.exe">Win32</a></li>
            <li><a href="https://github.com/Gnucash/gnucash/releases/download/5.5/Gnucash-Intel-5.5-1.dmg">Mac-Intel</a></li>
        </ul></li></ul>

<h3>Getting GnuCash as source code</h3>
<p>If you want to compile GnuCash 5.5 for yourself, the source code can be downloaded from:</p>
<ul>

    <li>Sourceforge: <a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.5/gnucash-5.5.tar.bz2">bzip2</a>, <a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.5/gnucash-5.5.tar.gz">gzip</a>.</li>

    <li>Github: <a href="https://github.com/Gnucash/gnucash/releases/download/5.5/gnucash-5.5.tar.bz2">bzip</a>, <a href="https://github.com/Gnucash/gnucash/releases/download/5.5/gnucash-5.5.tar.gz">gzip</a></li>

    <li>You can also checkout the sources directly from the git repository as <a href="https://wiki.gnucash.org/wiki/Git">described here.</a></li>
</ul>

<p>To compile GnuCash from the source code by yourself, you will need at least <a href="https://www.gtk.org/">Gtk+</a> 3.22.29, <a href="https://www.gnu.org/software/guile/">Guile</a> 2.0, <a href="https://www.boost.org/">Boost</a> 1.67, <a href="https://webkitgtk.org/">WebKitGtk</a> 2.4, <a href="https://github.com/google/googletest">GoogleTest</a> 1.8.0, <a href="https://cmake.org/">cmake 3.10</a> and <a href="http://www.swig.org/">SWIG</a> 2.0.12. Please consult the README.dependencies file in the sources for the exact list of dependencies and versions.</p>

<h3>Getting the documentation</h3>

<p>The documentation is available at <a href="https://www.gnucash.org/docs.phtml">Documentation page</a> of the <a href="https://www.gnucash.org/">GnuCash website</a>. The 5.5 documentation can be found under "GnuCash v4 (current stable release)" in multiple languages both for reading online and for download in pdf, epub, and mobi formats. The documentation is also included in the MacOS and Windows application bundles. Note that we are preparing to remove autotools support from the documentation build and that it is no longer included in the tarball.</p>

<p>If you want to compile the GnuCash Documentation 5.5 for yourself, the source code can be downloaded from:</p>
<ul>
    <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.5/gnucash-docs-5.5.tar.gz">Sourceforge</a> or <a href="https://github.com/Gnucash/gnucash/releases/download/5.5/gnucash-docs-5.5.tar.gz">GitHub</a></li>
    <li>You can also checkout the sources directly from the git repository as <a href="https://wiki.gnucash.org/wiki/Git">described here.</a></li>
</ul>


<h3>About the Program</h3>

<p>GnuCash is a free, open source accounting program released under
    the GNU General Public License (GPL) and available for GNU/Linux,
    *BSD, Solaris, MacOS, and Microsoft Windows.  Programming on GnuCash
    began in 1997, and its first stable release was in 1998.</p>
  </div> <div>
<h2>GnuCash 5.4 Released</h2>

<p>The GnuCash development team announces GnuCash 5.4, the fifth release in the stable 5.x series.</p>

<h4>Between 5.3 and 5.4, the following bugfixes were accomplished:</h4>
<ul>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=728875">Bug 728875 - Back button does not work in QIF import assistant</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=797507">Bug 797507 - GnuCash Splash screen may disappear before the main window appears</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798709">Bug 798709 - Total(Period) column does not refresh period's value after update of the period in settings.</a>a&gt;</li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798904">Bug 798904 - GnuCash on Windows opens a CMD window at startup.</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798925">Bug 798925 - Python bindings: "invalid unclassed pointer in cast to 'QofInstance'".</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798944">Bug 798944 - Program crashes when matching transactions</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798950">Bug 798950 - Bug Report: Incorrect Currency Conversion and Provider Invoice Payment Recording</a>
        <ul>
            <li>When balancing lots use the split amount, not the value</li>
            <li>Recalculate the values using deduced exchange rates after adjusting split amounts.</li>
            <li>Be conservative when recalculating values after breaking up a split to avoid imbalances caused by rounding.</li>
        </ul></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798958">Bug 798958 - gncScrubLotLinks will infinite loop in some conditions</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798982">Bug 798982 - GetQuotes crashes if Finance::Quote returns an empty date.</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798983">Bug 798983 - Empty Orphan account appears after entering transactions in 5.3</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798990">Bug 798990 - Notes No Longer Autofills</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798991">Bug 798991 - Incorrect Account Name Order in Transaction Report</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798995">Bug 798995 - Keystrokes ignored during ledger entry</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798998">Bug 798998 - Job Report Not Working</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799004">Bug 799004 - Update of Prices attaches incorrect Date</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799010">Bug 799010 - gnc-register-account-sel-limited-option errors doesn't work</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799020">Bug 799020 - widget of gnc-register-list-option disregards user's clicks</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799021">Bug 799021 - Saved report renders default of gnc-register-list-option</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799036">Bug 799036 - Import prices from a CSV date problem</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799039">Bug 799039 - gnc:strify produces unusual results or crashes GnuCash when fed an option from gnc-lookup-option</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799048">Bug 799048 - Hover on tab not correct</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799051">Bug 799051 - Shortcut Ctrl + Tab not working in 5.3</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799054">Bug 799054 - Stock Assist not functioning</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799060">Bug 799060 - Consistent Crash in Invoices</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799068">Bug 799068 - csv export active register not working</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799069">Bug 799069 - Multicurrency Invoice Payment</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799075">Bug 799075 - Saving display tab changes in Report Options does not work.</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799084">Bug 799084 - Unable to create new scheduled transaction</a></li>
</ul>
<h4>The following fixes and improvements were not associated with bug reports:</h4>
<ul>
    <li>[import-main-matcher.cpp] After clicking/toggling A/U+C/C checkbox, reselect the row because it'll be much faster to use keyboard navigation -- use up/down/left/right to target desired checkbox, hit &lt;down&gt; &lt;space&gt; repeatedly to repeat the same action over several consecutive rows. </li>
    <li>Implement support for !Type:Prices records in the QIF importer.</li>
    <li> Modernize construction of GObjects using G_DECLARE_DERIVABLE, G_DECLARE_FINAL, etc.</li>
    <li> Fix yet more leaks.</li>
    <li>[DBI backend] Change DBI test URLs to environment variables from cmake configuration definitions. </li>
    <li> Restore the Stock Transaction Assistant to full operation.</li>
    <li> Fix the Fancy Date file property so that it saves. </li>
    <li>Fix formatting error in po files project-id line.</li>
    <li>[simple-business-create.py] Overwrite an existing file instead of crashing.</li>
    <li>Update github action package versions.</li>
    <li>Add parsing mixed number and fraction (e.g. 10 1/2) to the gnc_numeric string constructor.</li>
    <li>Bump minimum cmake version to 3.14 and drop some conditionals for older versions </li>
    <li>Major speedup in the SQLBackend by replacing C++ exceptions with std::optional for null values.</li>
    <li>Refresh the GUI on completion of the import matcher so that the imports are immediately reflected in the register.</li>
    <li>Improve online quote retrieval error reporting.</li>
    <li>Test loading and saving XML files with and without compression</li>
    <li>[import-main-matcher] always defer_bal_computation during import to speed up both importing new transactions, and destroying existing ones. </li>
    <li>GncGtkListUIItem::set_option_from_ui_item: Iterate over selected items Instead of all possible items. </li>
    <li>Convert gnc-ofx-import.c, import-parse.c, import-utilities.c, import-format-dialog.c, import-account-matcher.c, import-commodity-matcher.c, import-settings.c, import-pending-matches.c, import-match-picker.c, import-main-matcher.c, and gnc-pricedb.c to .cpp</li>
    <li>By default, filter out online_wiggle in test-gnc-quotes. Running ./bin/test-gnc-quotes from the command line will still include online_wiggle </li>
    <li>Replace yahoo_json with alphavantage in test-gnc-quotes. yahoo_json is too unstable.</li>
    <li>Include timezone in price-quote date diagnostic messages.</li>
</ul>
<p>New and Updated Translations: Arabic, Chinese (Traditional), Croatian, Dutch, English (Australia), English (New Zealand), English (United Kingdom), French, German, Greek, Hebrew, Hungarian, Indonesian, Italian, Polish, Portuguese, Portuguese (Brazil), Romanian, Slovak, Spanish, Swedish, Ukrainian</p>


<p><a href="https://hosted.weblate.org/engage/gnucash/">Help translate GnuCash on Weblate</a></p><h4>Known Problems</h4>
<p><a href="https://bugs.gnucash.org/buglist.cgi?bug_severity=blocker&amp;bug_severity=critical&amp;bug_severity=major&amp;bug_severity=normal&amp;bug_severity=minor&amp;bug_severity=trivial&amp;bug_status=NEW&amp;bug_status=ASSIGNED&amp;bug_status=NEEDINFO&amp;bug_status=REOPENED&amp;limit=0&amp;list_id=8149&amp;order=priority%2Cbug_severity&amp;query_format=advanced">Complete list of all open bugs.</a></p>

<h2>Documentation</h2>
<h4>Between 5.2 and 5.4, the following bugfixes were accomplished:</h4>
<ul>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=799074">Bug 799074 - Incorrect note re cash page in stock-txn-assistant</a></li>
</ul>
<h4>The following fixes and improvements were not associated with bug reports:</h4>
<ul>
    <li> Add a Chinese translation for the Tutorial and Concepts Guide.</li>
    <li>Update git branches for API docs</li>
    <li>Refactor the build system feature for adding customized xslt files.</li>
    <li>Bump minimum cmake version to 3.14 to keep it in sync with the gnucash repo </li>
    <li>Fix race condition in creating symlinks for the kde help system.</li>
    <li>Update GitHub actions/checkout to v3 in all actions and add nightly-build github workflow.</li>
    <li>Manual (C,de): Replace obsolete 'gnc-fq-*' with 'gnucash-cli --quotes *'</li>
    <li>Guide (C,de,ru): Repair broken links from 'help' to 'manual'</li>
    <li>Guide (C,de), ch_invest: Remove section 'Finance::Quote install'</li>
    <li>Manual (C, de) Update F::Q screens to 1.57</li>
    <li>Change version 4 to 5, branch maint to stable, and update Finance::Quote docs to reflect changes in GnuCash.</li>
</ul>
<p>New and Updated Translations: German</p>

<h3>Getting GnuCash for Windows and MacOS</h3>
<p>GnuCash is provided for both Microsoft Windows 8.1® and later
    and MacOS 10.13 (High Sierra)® and later in pre-built, all-in-one
    packages. An installer is provided for Microsoft Windows® while
    the MacOS® package is a disk image containing a drag-and-drop
    application bundle.</p>

<p>GnuCash is also available as a flatpak from Flathub.org. <a href="https://wiki.gnucash.org/wiki/Flatpak">Instructions for installing and running.</a></p>

<p>The SHA256 Hashes for the downloadable files are:</p>
<ul>
    <li><code>7741165d6d652ea7b4a1e8498cf439a56b81a5cc8b653291a59054f2362abfcc</code>&nbsp;&nbsp;gnucash-5.4-1.tar.bz2</li>
    <li><code>7989c2fff67ff356e99c9a4b8d90a7759c7bde73844afb0595ee1322f4a19ced</code>&nbsp;&nbsp;gnucash-5.4.tar.gz</li>
    <li><code>e1925591bbdddd80b1ff8ddf0634652ef098072bd96a5bb98f000cdcc5c841ff</code>&nbsp;&nbsp;gnucash-5.4-1.setup.exe</li>
    <li><code>ffe311fd2077cf1df15c253a5e062dc3801fa9db06829d3d12184184727e89c8</code>&nbsp;&nbsp;Gnucash-Intel-5.4-2.dmg</li>
    <li><code>e2a93460e7768b1b18e466e352ac13212b75094be6334ca0427b6cd4f66d8793</code>&nbsp;&nbsp;gnucash-docs-5.4.tar.gz</li>
</ul>

<ul>
    <li>SourceForge:
        <ul>
            <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.4/gnucash-5.4.setup.exe">Win32</a></li>
            <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.4/Gnucash-Intel-5.4-1.dmg">Mac-Intel</a></li>
        </ul></li>
    <li>Github
        <ul>
            <li><a href="https://github.com/Gnucash/gnucash/releases/download/5.4/gnucash-5.4.setup.exe">Win32</a></li>
            <li><a href="https://github.com/Gnucash/gnucash/releases/download/5.4/Gnucash-Intel-5.4-1.dmg">Mac-Intel</a></li>
        </ul></li></ul>

<h3>Getting GnuCash as source code</h3>
<p>If you want to compile GnuCash 5.4 for yourself, the source code can be downloaded from:</p>
<ul>

    <li>Sourceforge: <a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.4/gnucash-5.4.tar.bz2">bzip2</a>, <a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.4/gnucash-5.4.tar.gz">gzip</a>.</li>

    <li>Github: <a href="https://github.com/Gnucash/gnucash/releases/download/5.4/gnucash-5.4.tar.bz2">bzip</a>, <a href="https://github.com/Gnucash/gnucash/releases/download/5.4/gnucash-5.4.tar.gz">gzip</a></li>

    <li>You can also checkout the sources directly from the git repository as <a href="https://wiki.gnucash.org/wiki/Git">described here.</a></li>
</ul>

<p>To compile GnuCash from the source code by yourself, you will need at least <a href="https://www.gtk.org/">Gtk+</a> 3.22.29, <a href="https://www.gnu.org/software/guile/">Guile</a> 2.0, <a href="https://www.boost.org/">Boost</a> 1.67, <a href="https://webkitgtk.org/">WebKitGtk</a> 2.4, <a href="https://github.com/google/googletest">GoogleTest</a> 1.8.0, <a href="https://cmake.org/">cmake 3.10</a> and <a href="http://www.swig.org/">SWIG</a> 2.0.12. Please consult the README.dependencies file in the sources for the exact list of dependencies and versions.</p>

<h3>Getting the documentation</h3>

<p>The documentation is available at <a href="https://www.gnucash.org/docs.phtml">Documentation page</a> of the <a href="https://www.gnucash.org/">GnuCash website</a>. The 5.4 documentation can be found under "GnuCash v4 (current stable release)" in multiple languages both for reading online and for download in pdf, epub, and mobi formats. The documentation is also included in the MacOS and Windows application bundles. Note that we are preparing to remove autotools support from the documentation build and that it is no longer included in the tarball.</p>

<p>If you want to compile the GnuCash Documentation 5.4 for yourself, the source code can be downloaded from:</p>
<ul>
    <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.4/gnucash-docs-5.4.tar.gz">Sourceforge</a> or <a href="https://github.com/Gnucash/gnucash/releases/download/5.4/gnucash-docs-5.4.tar.gz">GitHub</a></li>
    <li>You can also checkout the sources directly from the git repository as <a href="https://wiki.gnucash.org/wiki/Git">described here.</a></li>
</ul>


<h3>About the Program</h3>

<p>GnuCash is a free, open source accounting program released under
    the GNU General Public License (GPL) and available for GNU/Linux,
    *BSD, Solaris, MacOS, and Microsoft Windows.  Programming on GnuCash
    began in 1997, and its first stable release was in 1998.</p>
  </div> <div>
<h2>GnuCash 5.3 Released</h2>

<p>The GnuCash development team announces GnuCash 5.3, the fourth release in the stable 5.x series. This is a snap release to fix the bug listed below.</p>

<h4>Between 5.2 and 5.3, the following bugfixes were accomplished:</h4>
<ul>
<li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798967">Bug 798967 - Cannot Save to Any Path After Upgrading to 5.2 Fix inverted if statement condition for save success flag</a></li>
</ul>
<h4>The following fixes and improvements were not associated with bug reports:</h4>
<ul>
    <li>Some memory cleanup by Chris Lam.</li>
    <li>Missing from the 5.2 release notes is that Chris streamlined the
        transaction scrubbing so that each transaction gets scrubbed
        only once. This improves--in some cases substantially--the time
        to load and to run Check and Repair.</li>
</ul>
<p>New and Updated Translations: Dutch, French, Hungarian, Italian, Portuguese</p>

<p><a href="https://hosted.weblate.org/engage/gnucash/">Help translate GnuCash on Weblate</a></p><h4>Known Problems</h4>
<p><a href="https://bugs.gnucash.org/buglist.cgi?bug_severity=blocker&amp;bug_severity=critical&amp;bug_severity=major&amp;bug_severity=normal&amp;bug_severity=minor&amp;bug_severity=trivial&amp;bug_status=NEW&amp;bug_status=ASSIGNED&amp;bug_status=NEEDINFO&amp;bug_status=REOPENED&amp;limit=0&amp;list_id=8149&amp;order=priority%2Cbug_severity&amp;query_format=advanced">Complete list of all open bugs.</a></p>

<h2>Documentation</h2>
<p>This being a snap release there is no new documentation. Please continue to use the 5.2 versions.</p>

<h3>Getting GnuCash for Windows and MacOS</h3>
<p>GnuCash is provided for both Microsoft Windows 8.1® and later
    and MacOS 10.13 (High Sierra)® and later in pre-built, all-in-one
    packages. An installer is provided for Microsoft Windows® while
    the MacOS® package is a disk image containing a drag-and-drop
    application bundle.</p>

<p>GnuCash is also available as a flatpak from Flathub.org. <a href="https://wiki.gnucash.org/wiki/Flatpak">Instructions for installing and running.</a></p>

<p>The SHA256 Hashes for the downloadable files are:</p>
<ul>
    <li><code>1458cb08c585eae9d724bec6f2812bcc03bbe83ed294a46a7897aaab01a6f15a</code>&nbsp;&nbsp;gnucash-5.3.tar.bz2</li>
    <li><code>e0d04e0fd5f03f39136e1f4d941ccd0202b64a6e92418f5382cb6a6772493529</code>&nbsp;&nbsp;gnucash-5.3.tar.gz</li>
    <li><code>4cd66cf6c261fe7f5fc071b8e01314f33fb97e3496fe832e07bad360c1cf685a</code>&nbsp;&nbsp;gnucash-5.3.setup.exe</li>
    <li><code>6bf4940d851b49a4edf5d6dd3cbe37a1112bc3606cdb924ed6668ce0ad7c7427</code>&nbsp;&nbsp;Gnucash-Intel-5.3-1.dmg</li>
    <li><code>b9eb6581b403665c308b8909cc4d588c9ce483139cbc3ed3638403f61aefb49b</code>&nbsp;&nbsp;gnucash-docs-5.2.tar.gz</li>
</ul>

<ul>
    <li>SourceForge:
        <ul>
            <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.3/gnucash-5.3.setup.exe">Win32</a></li>
            <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.3/Gnucash-Intel-5.3-1.dmg">Mac-Intel</a></li>
        </ul></li>
    <li>Github
        <ul>
            <li><a href="https://github.com/Gnucash/gnucash/releases/download/5.3/gnucash-5.3.setup.exe">Win32</a></li>
            <li><a href="https://github.com/Gnucash/gnucash/releases/download/5.3/Gnucash-Intel-5.3-1.dmg">Mac-Intel</a></li>
        </ul></li></ul>

<h3>Getting GnuCash as source code</h3>
<p>If you want to compile GnuCash 5.3 for yourself, the source code can be downloaded from:</p>
<ul>

    <li>Sourceforge: <a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.3/gnucash-5.3.tar.bz2">bzip2</a>, <a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.3/gnucash-5.3.tar.gz">gzip</a>.</li>

    <li>Github: <a href="https://github.com/Gnucash/gnucash/releases/download/5.3/gnucash-5.3.tar.bz2">bzip</a>, <a href="https://github.com/Gnucash/gnucash/releases/download/5.3/gnucash-5.3.tar.gz">gzip</a></li>

    <li>You can also checkout the sources directly from the git repository as <a href="https://wiki.gnucash.org/wiki/Git">described here.</a></li>
</ul>

<p>To compile GnuCash from the source code by yourself, you will need at least <a href="https://www.gtk.org/">Gtk+</a> 3.22.29, <a href="https://www.gnu.org/software/guile/">Guile</a> 2.0, <a href="https://www.boost.org/">Boost</a> 1.67, <a href="https://webkitgtk.org/">WebKitGtk</a> 2.4, <a href="https://github.com/google/googletest">GoogleTest</a> 1.8.0, <a href="https://cmake.org/">cmake 3.10</a> and <a href="http://www.swig.org/">SWIG</a> 2.0.12. Please consult the README.dependencies file in the sources for the exact list of dependencies and versions.</p>

<h3>Getting the documentation</h3>

<p>The documentation is available at <a href="https://www.gnucash.org/docs.phtml">Documentation page</a> of the <a href="https://www.gnucash.org/">GnuCash website</a>. The 5.3 documentation can be found under "GnuCash v4 (current stable release)" in multiple languages both for reading online and for download in pdf, epub, and mobi formats. The documentation is also included in the MacOS and Windows application bundles. Note that we are preparing to remove autotools support from the documentation build and that it is no longer included in the tarball.</p>

<p>If you want to compile the GnuCash Documentation 5.3 for yourself, the source code can be downloaded from:</p>
<ul>
    <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.3/gnucash-docs-5.2.tar.gz">Sourceforge</a> or <a href="https://github.com/Gnucash/gnucash/releases/download/5.3/gnucash-docs-5.2.tar.gz">GitHub</a></li>
    <li>You can also checkout the sources directly from the git repository as <a href="https://wiki.gnucash.org/wiki/Git">described here.</a></li>
</ul>


<h3>About the Program</h3>

<p>GnuCash is a free, open source accounting program released under
    the GNU General Public License (GPL) and available for GNU/Linux,
    *BSD, Solaris, MacOS, and Microsoft Windows.  Programming on GnuCash
    began in 1997, and its first stable release was in 1998.</p>
  </div> <div>
<h2>GnuCash 5.2 Released</h2>

<p>The GnuCash development team announces GnuCash 5.2, the third release in the stable 5.x series</p>

<h4>Between 5.1 and 5.2, the following bugfixes were accomplished:</h4>
<ul>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=777472">Bug 777472 - reconcile does not work if transaction selected</a><p> Check that there's no outstanding activity in the current register page before starting a reconciliation.  It is still possible to start modifying a transaction after the reconciliation window is open but this will stop the most common issue with the process.  Starting a reconciliation from the account tree is left unprotected. </p></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798564">Bug 798564 - GnuCash is slow when there are a lot of open tabs/registers (37)</a><p>Lazily load registers as is already done with reports.</p></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798597">Bug 798597 - The word "Separators" needs two separate versions</a><p>Use "Character-separated" when it's a choice between that and fixed field width and "Select Separator Character" when it's a heading. </p></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798695">Bug 798695 - Deleting everything from the "Transfer" cell after suggestions pop-up restricts search to the first 30 accounts</a><p>Skip the search on an empty value and return all accounts in the combo box as it normally does if the account list is opened without searching for something. </p></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798796">Bug 798796 - Account list incomplete in report options</a><p>Allow stock/fund accounts that are descendants of Bank accounts to be selected for the Advanced Portfolio, Investment Lots and Investment Portfolio reports. </p></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798809">Bug 798809 - Multicolumn report error when reopened after saving.</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798839">Bug 798839 - Edit -&gt; Preferences string not translatable (reopened)</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798862">Bug 798862 - Merge identical strings (reopened)</a><p>Ensure similar strings are identical and use double line view instead of double line mode. </p></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798879">Bug 798879 - RFE: [Transaction Report] add Running Total option</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798885">Bug 798885 - Accented character in folder name on Account Export (reopened)</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798899">Bug 798899 - Gnucash crashes during CSV import when using a template if the destination account is changed from one used in the template</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798901">Bug 798901 - Wrong value for very small prices from Finance::Quote.</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798916">Bug 798916 - Exchange rates fetched from openexchange off by factor of 10</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798919">Bug 798919 - Inconsistent signs in creating budget</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798923">Bug 798923 - OFX import is no longer matching security nor asking for stock account.</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798930">Bug 798930 - invoices won't sequence to the next number</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798948">Bug 798948 - XML file corrupted by saving twice in extremely short period</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798952">Bug 798952 - Unable to set day threshold or counters in properties.</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798960">Bug 798960 - Transaction completion horizontal scrolling opens without the new text being visible and remembers previous position/width</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798966">Bug 798966 - Uninitialised variable used in dialog-account-picker.c:dialog_response_cb()</a></li>
</ul>

<h4>The following fixes and improvements were not associated with bug reports:</h4>
<ul>
    <li>The type-ahead selection of transaction descriptions has been substantially overhauled based on extensive user feedback. Matches are now only on the beginning of words and are now sorted by age since last use. This both substantially reduces the number of matches and prioritizes the most recently used as being the most likely candidates for re-use. To help distinguish cases of long descriptions where the match would be outside the popup's viewport the viewport is automatically scrolled horizontally so that the end of the left-most (right-most in rtl languages) matches is centered in the view. Completion can be aborted with the &lt;escape&gt; key or a new <em>Don't autocomplete</em> selection that's the first entry in the popup.</li>
    <li>Fix lockup on Windows in type-ahead selection of transaction descriptions.</li>
    <li>More budget-module sign fixes and improvements.</li>
    <li>Lots of memory-leak fixes, GLib modernization, and code cleanup by Richard Cohen, Simon Arlott, &amp; Chris Lam.</li>
    <li>bugfix xaccTransGetTxnType: avoid returning TXN_TYPE_LINK incorrectly: A TXN_TYPE_PAYMENT will have non-APAR splits; a TXN_TYPE_LINK will not have non-APAR splits. This bug manifests as a regular TXN_TYPE_PAYMENT transaction being later voided being incorrectly changed to TXN_TYPE_LINK.</li>
    <li>Including brokerage fees in Money Out calculation (if not ignoring them) in advanced-portfolio.scm report and updating the "advanced" tests to reflect selling fees being included into the money out value</li>
    <li>[stock-txn-asst] Don't use the initial value in amount edit widgets unless they're valid. Otherwise the invalid value will log an error that will prevent later valid input from working. </li>
    <li>BUGFIX: Actions &gt; Online Actions &gt; Show log Window does not open when it is first clicked.</li>
    <li>cmake: check gdk only when building GUI</li>
    <li>Get the tooltip working on "Online Banking Setup"</li>

</ul>
<p>New and Updated Translations: Chinese (Simplified), Chinese (Traditional), Croatian, English (Australia), English (New Zealand), English (United Kingdom), Estonian, French, German, Hungarian, Lithuanian, Marathi, Norwegian Bokmål, Polish, Portuguese, Romanian, Spanish, Swedish, Ukrainian</p>

<p><a href="https://hosted.weblate.org/engage/gnucash/">Help translate GnuCash on Weblate</a></p><h4>Known Problems</h4>
<p><a href="https://bugs.gnucash.org/buglist.cgi?bug_severity=blocker&amp;bug_severity=critical&amp;bug_severity=major&amp;bug_severity=normal&amp;bug_severity=minor&amp;bug_severity=trivial&amp;bug_status=NEW&amp;bug_status=ASSIGNED&amp;bug_status=NEEDINFO&amp;bug_status=REOPENED&amp;limit=0&amp;list_id=8149&amp;order=priority%2Cbug_severity&amp;query_format=advanced">Complete list of all open bugs.</a></p>

<h2>Documentation</h2>
<p>Concurrent with the release of GnuCash 5.2 we're pleased to also release a new version of the companion Manual and the Tutorial and Concepts Guide:</p>

<p> There are no changes in the documentation for this release.</p>

<h3>Getting GnuCash for Windows and MacOS</h3>
<p>GnuCash is provided for both Microsoft Windows 8.1® and later
    and MacOS 10.13 (High Sierra)® and later in pre-built, all-in-one
    packages. An installer is provided for Microsoft Windows® while
    the MacOS® package is a disk image containing a drag-and-drop
    application bundle.</p>

<p>GnuCash is also available as a flatpak from Flathub.org. <a href="https://wiki.gnucash.org/wiki/Flatpak">Instructions for installing and running.</a></p>

<p>The SHA256 Hashes for the downloadable files are:</p>
<ul>
    <li><code>4826176b7e70bb889f99c206faffadd892628d78525715e9f7128ecf48b14680</code>&nbsp;&nbsp;gnucash-5.2.tar.bz2</li>
    <li><code>2d594cc889bb723746beb490f50853ccfb987b6e99e0a4587b058c51ca2a75a3</code>&nbsp;&nbsp;gnucash-5.2.tar.gz</li>
    <li><code>8299701f54d9b19743cbe90f1f369a4c998fd87436571d1b8fc630e7c71ffc13</code>&nbsp;&nbsp;gnucash-5.2.setup.exe</li>
    <li><code>f7f0c82976755d228c32f71db4db8bde4e5de40c161011071dc39cac1f6f5a20</code>&nbsp;&nbsp;Gnucash-Intel-5.2-1.dmg</li>
    <li><code>b9eb6581b403665c308b8909cc4d588c9ce483139cbc3ed3638403f61aefb49b</code>&nbsp;&nbsp;gnucash-docs-5.2.tar.gz</li>
</ul>

<ul>
    <li>SourceForge:
        <ul>
            <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.2/gnucash-5.2.setup.exe">Win32</a></li>
            <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.2/Gnucash-Intel-5.2-1.dmg">Mac-Intel</a></li>
        </ul></li>
    <li>Github
        <ul>
            <li><a href="https://github.com/Gnucash/gnucash/releases/download/5.2/gnucash-5.2.setup.exe">Win32</a></li>
            <li><a href="https://github.com/Gnucash/gnucash/releases/download/5.2/Gnucash-Intel-5.2-1.dmg">Mac-Intel</a></li>
        </ul></li></ul>

<h3>Getting GnuCash as source code</h3>
<p>If you want to compile GnuCash 5.2 for yourself, the source code can be downloaded from:</p>
<ul>

    <li>Sourceforge: <a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.2/gnucash-5.2.tar.bz2">bzip2</a>, <a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.2/gnucash-5.2.tar.gz">gzip</a>.</li>

    <li>Github: <a href="https://github.com/Gnucash/gnucash/releases/download/5.2/gnucash-5.2.tar.bz2">bzip</a>, <a href="https://github.com/Gnucash/gnucash/releases/download/5.2/gnucash-5.2.tar.gz">gzip</a></li>

    <li>You can also checkout the sources directly from the git repository as <a href="https://wiki.gnucash.org/wiki/Git">described here.</a></li>
</ul>

<p>To compile GnuCash from the source code by yourself, you will need at least <a href="https://www.gtk.org/">Gtk+</a> 3.22.29, <a href="https://www.gnu.org/software/guile/">Guile</a> 2.0, <a href="https://www.boost.org/">Boost</a> 1.67, <a href="https://webkitgtk.org/">WebKitGtk</a> 2.4, <a href="https://github.com/google/googletest">GoogleTest</a> 1.8.0, <a href="https://cmake.org/">cmake 3.10</a> and <a href="http://www.swig.org/">SWIG</a> 2.0.12. Please consult the README.dependencies file in the sources for the exact list of dependencies and versions.</p>

<h3>Getting the documentation</h3>

<p>The documentation is available at <a href="https://www.gnucash.org/docs.phtml">Documentation page</a> of the <a href="https://www.gnucash.org/">GnuCash website</a>. The 5.2 documentation can be found under "GnuCash v4 (current stable release)" in multiple languages both for reading online and for download in pdf, epub, and mobi formats. The documentation is also included in the MacOS and Windows application bundles. Note that we are preparing to remove autotools support from the documentation build and that it is no longer included in the tarball.</p>

<p>If you want to compile the GnuCash Documentation 5.2 for yourself, the source code can be downloaded from:</p>
<ul>
    <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.2/gnucash-docs-5.2.tar.gz">Sourceforge</a> or <a href="https://github.com/Gnucash/gnucash/releases/download/5.2/gnucash-docs-5.2.tar.gz">GitHub</a></li>
    <li>You can also checkout the sources directly from the git repository as <a href="https://wiki.gnucash.org/wiki/Git">described here.</a></li>
</ul>


<h3>About the Program</h3>

<p>GnuCash is a free, open source accounting program released under
    the GNU General Public License (GPL) and available for GNU/Linux,
    *BSD, Solaris, MacOS, and Microsoft Windows.  Programming on GnuCash
    began in 1997, and its first stable release was in 1998.</p>
  </div> <div>
<h2>GnuCash 5.1 Released</h2>

<p>The GnuCash development team announces GnuCash 5.1, the second release in the stable 5.x series</p>

<h4>Between 5.0 and 5.1, the following bugfixes were accomplished:</h4>
<ul>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=765920">Bug 765920 - Running balance not accurate when sorted different ways</a>
      <ul><li>Renamed option to "Account Balance" to avoid confusion with running total.</li>
        <li>Added helper function to ensure running balance and balance forward are only shown when transaction are grouped by account and sorted as in register. In that case column heading remains "Running Balance" and balance forward is shown. Otherwwise column heading is renamed "Account Balance" and balance forward is not shown.</li>
        <li>Also added missing code for Common Currency conversion.</li>
      </ul>
    </li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=797879">Bug 797879 - [Transaction Report] running balance column not consistent with amount column for SAME transaction date</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798461">Bug 798461 - balance sheet shows positions with zero balances despite report options</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798775">Bug 798775 - Why is General Journal called "Register" in the tabs?</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798802">Bug 798802 - Online Price quote - Stocks not working GNU 5.0 Windows Bis</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798802">Bug 798802 - Online Price quote - Stocks not working GNU 5.0 Windows</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798807">Bug 798807 - Keyboard shortcuts not working</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798808">Bug 798808 - Saved reports shown on main menu</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798810">Bug 798810 - Income Statement (multicolumn) - account sorting is 'reversed' each time you restart.</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798812">Bug 798812 - crashes after I open a customer report and select…</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798813">Bug 798813 - Under File-&gt;Import, Missing OFX/QFX menu item</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798815">Bug 798815 - flatpak run --command=gnucash-cli cannot download quotes since 5.0.</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798821">Bug 798821 - Crash when running report in window</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798834">Bug 798834 - CSS-based Stylesheet Help Button not working</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798839">Bug 798839 - Edit -&gt; Preferences string not translatable</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798844">Bug 798844 - "Assign as Payment" does nothing in 4.14 &amp; 5.0</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798845">Bug 798845 - User Config and User Data link broken</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798851">Bug 798851 - Account Balance 'include subaccounts' not saved</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798854">Bug 798854 - Softkey 'Save Config' remains dark</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798862">Bug 798862 - Merge identical strings</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798863">Bug 798863 - Crash on clicking Settings button second time</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798864">Bug 798864 - Budget Reporting on select reports are wrong</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798869">Bug 798869 - Transaction Import MAP</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798872">Bug 798872 - Reload inoperative for reports</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798877">Bug 798877 - Program crashes upon selection of CSV profile</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798885">Bug 798885 - Accented character in folder name on Account Export</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798886">Bug 798886 - [Transaction Report] Subtotal upper headings do not follow font style of lower headings</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798893">Bug 798893 - several menu tip messages in reports are marked translatable but unused.</a></li>
    <li><a href="https://bugs.gnucash.org/show_bug.cgi?id=798894">Bug 798894 - TOTD with ellipsis broken.</a></li>
</ul>

<h4>The following fixes and improvements were not associated with bug reports:</h4>
<ul>
    <li>Add filters to the File&gt;Open dialog in File mode to show only files with GnuCash extensions, only those matching GnuCash's backup file pattern, or any extension.</li>
    <li>Select the first result in the Customer/Vendor search box. This allows faster keyboard navigation -- Find Customer, input search string, press ENTER, use up/down to select desired object, press ENTER to open object. </li>
    <li>Improve foreign currency handling in budget report</li>
    <li>Improve handling of the blank transaction when the register is sorted in reverse:
        <ul>
            <li>Change the preference option 'Future transactions after blank transaction'</li>
            <li>Change tooltip for 'Blank Transaction' in register to mention moving to the blank transaction. </li>
            <li>Show the blank transaction at top of register</li>
        </ul></li>
    <li>Prevent infinite recursion from gnucash_item_edit_focus_out when using an input method.</li>
    <li>Create obsolete features list with first member book_currency.Obsolete features set in the book will be removed from the book's KVP and ignored. </li>
    <li>Restore existence, but not implementation, of GNC_FEATURE_BOOK_CURRENCY.<p>At least one user has managed to get it set on their book so even though it was supposed to be unimplemented it got through somehow. Restoring it allows books with it set to load. </p></li>
    <li>Offer to force edit non-identical fields when multiple matches are selected in the import matcher window. Previously only identical Desc/Notes/Memo were unlocked for editing.</li>
    <li>Guard against there being no namespaces in the new security dialog</li>
    <li>Fix Finance::Quote use on Win32 by dealing with Win32 \r\n newlines on return from finance-quote-wrapper.</li>
    <li>Fix some menu labels that were not marked for translation</li>
    <li>Fix category in CSV export with simple layout.<p>If Trading accounts is enabled, and the transaction is a transfer between two accounts of differing commodities, the CSV simple-layout export would incorrectly show "--Split Transaction--" as the category. </p></li>
    <li>When configuring Guile use pkg-config before searching for binaries.</li>
</ul>

<p>New and Updated Translations: Chinese (Simplified), Croatian, English (Australia), English (New Zealand), English (United Kingdom), Estonian, French, German, Hindi, Hungarian, Japanese, Portuguese, Slovak, Spanish, Swedish, Turkish, Ukrainian</p>

<p><a href="https://hosted.weblate.org/engage/gnucash/">Help translate GnuCash on Weblate</a></p><h4>Known Problems</h4>
<p><a href="https://bugs.gnucash.org/buglist.cgi?bug_severity=blocker&amp;bug_severity=critical&amp;bug_severity=major&amp;bug_severity=normal&amp;bug_severity=minor&amp;bug_severity=trivial&amp;bug_status=NEW&amp;bug_status=ASSIGNED&amp;bug_status=NEEDINFO&amp;bug_status=REOPENED&amp;limit=0&amp;list_id=8149&amp;order=priority%2Cbug_severity&amp;query_format=advanced">Complete list of all open bugs.</a></p>

<h2>Documentation</h2>
<p>Concurrent with the release of GnuCash 5.1 we're pleased to also release a new version of the companion Manual and the Tutorial and Concepts Guide:</p>

<h4>The following fixes and improvements were not associated with bug reports:</h4>
<ul>
    <li>Add details for some CSV import options. </li>
</ul>

<p>New and Updated Translations: None</p>

<h3>Getting GnuCash for Windows and MacOS</h3>
<p>GnuCash is provided for both Microsoft Windows 8.1® and later
    and MacOS 10.13 (High Sierra)® and later in pre-built, all-in-one
    packages. An installer is provided for Microsoft Windows® while
    the MacOS® package is a disk image containing a drag-and-drop
    application bundle.</p>

<p>GnuCash is also available as a flatpak from Flathub.org. <a href="https://wiki.gnucash.org/wiki/Flatpak">Instructions for installing and running.</a></p>

<p>The SHA256 Hashes for the downloadable files are:</p>
<ul>
    <li><code>8a6581ddf7c7409db636510601351af724eda363ab59b1d5da8d981033f26f72</code>&nbsp;&nbsp;gnucash-5.1.tar.bz2</li>
    <li><code>bd73204896d71cb19c2071bca9cc6faaf19d1499be66124f4fe66c8e15f876cb</code>&nbsp;&nbsp;gnucash-5.1.tar.gz</li>
    <li><code>3ddc5547b5694a11a33e21e4110d1adb908f04995637a54bfa930df68c7df014</code>&nbsp;&nbsp;gnucash-5.1.setup.exe</li>
    <li><code>65a67bdffbe2d50e5dbe69b7193acfde6d8964a0fbd631edfd0d064fbaea03d3</code>&nbsp;&nbsp;Gnucash-Intel-5.1-2.dmg</li>
    <li><code>59bd2b5ccc1efa7a034b38663e28f855b4ad16ee28b2248d61af8145097152f6</code>&nbsp;&nbsp;gnucash-docs-5.1.tar.gz</li>
</ul>

<ul>
    <li>SourceForge:
        <ul>
            <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.1/gnucash-5.1.setup.exe">Win32</a></li>
            <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.1/Gnucash-Intel-5.1-2.dmg">Mac-Intel</a></li>
        </ul></li>
    <li>Github
        <ul>
            <li><a href="https://github.com/Gnucash/gnucash/releases/download/5.1/gnucash-5.1.setup.exe">Win32</a></li>
            <li><a href="https://github.com/Gnucash/gnucash/releases/download/5.1/Gnucash-Intel-5.1-2.dmg">Mac-Intel</a></li>
        </ul></li></ul>

<h3>Getting GnuCash as source code</h3>
<p>If you want to compile GnuCash 5.1 for yourself, the source code can be downloaded from:</p>
<ul>

    <li>Sourceforge: <a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.1/gnucash-5.1.tar.bz2">bzip2</a>, <a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.1/gnucash-5.1.tar.gz">gzip</a>.</li>

    <li>Github: <a href="https://github.com/Gnucash/gnucash/releases/download/5.1/gnucash-5.1.tar.bz2">bzip</a>, <a href="https://github.com/Gnucash/gnucash/releases/download/5.1/gnucash-5.1.tar.gz">gzip</a></li>

    <li>You can also checkout the sources directly from the git repository as <a href="https://wiki.gnucash.org/wiki/Git">described here.</a></li>
</ul>

<p>To compile GnuCash from the source code by yourself, you will need at least <a href="https://www.gtk.org/">Gtk+</a> 3.22.29, <a href="https://www.gnu.org/software/guile/">Guile</a> 2.0, <a href="https://www.boost.org/">Boost</a> 1.67, <a href="https://webkitgtk.org/">WebKitGtk</a> 2.4, <a href="https://github.com/google/googletest">GoogleTest</a> 1.8.0, <a href="https://cmake.org/">cmake 3.10</a> and <a href="http://www.swig.org/">SWIG</a> 2.0.12. Please consult the README.dependencies file in the sources for the exact list of dependencies and versions.</p>

<h3>Getting the documentation</h3>

<p>The documentation is available at <a href="https://www.gnucash.org/docs.phtml">Documentation page</a> of the <a href="https://www.gnucash.org/">GnuCash website</a>. The 5.1 documentation can be found under "GnuCash v4 (current stable release)" in multiple languages both for reading online and for download in pdf, epub, and mobi formats. The documentation is also included in the MacOS and Windows application bundles. Note that we are preparing to remove autotools support from the documentation build and that it is no longer included in the tarball.</p>

<p>If you want to compile the GnuCash Documentation 5.1 for yourself, the source code can be downloaded from:</p>
<ul>
    <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.1/gnucash-docs-5.1.tar.gz">Sourceforge</a> or <a href="https://github.com/Gnucash/gnucash/releases/download/5.1/gnucash-docs-5.1.tar.gz">GitHub</a></li>
    <li>You can also checkout the sources directly from the git repository as <a href="https://wiki.gnucash.org/wiki/Git">described here.</a></li>
</ul>


<h3>About the Program</h3>

<p>GnuCash is a free, open source accounting program released under
    the GNU General Public License (GPL) and available for GNU/Linux,
    *BSD, Solaris, MacOS, and Microsoft Windows.  Programming on GnuCash
    began in 1997, and its first stable release was in 1998.</p>
  </div> <div>
<h2>GnuCash 5.0 Released</h2>

<p>The GnuCash development team announces GnuCash 5.0</p>

<h3>New Features</h3>
<ul>
    <li> A new Stock Transaction Assistant to guide you through entering most investment transactions for stocks, bonds, and mutual funds. You can access it from <em>Actions&gt;Stock Assistant</em> when the focus tab is the Accounts page or a Stock or Fund account register.</li>
    <li> A new Investment Lots report showing a graph of capital gains and losses in a period by investment lot. Note that if you don't use the View Lots dialog to manage capital gains and losses this report won't have anything to show you. Use <em>Reports&gt;Assets &amp; Liabilities&gt;Investment Lots</em> to see the report.</li>
    <li>The Online Quotes facility has been completely rewritten and the old <kbd>gnc-fq-check</kbd>, <kbd>gnc-fq-dump</kbd>, and <kbd>gnc-fq-helper</kbd> programs have been replaced with <kbd>finance-quote-wrapper</kbd>. The functions performed by those programs may now be accomplished by passing commands to <kbd>gnucash-cli -Q</kbd>, see <kbd>gnucash-cli --help</kbd> for specifics. The perl module requirements have changed with the rewrite: The new version doesn't need <code>Date::Manip</code> but needs <code>JSON::Parse</code> instead. <kbd>gnc-fq-update</kbd> has been, er, updated to reflect that.</li>
    <li>A new tab on the New/Edit Account dialog called <em>More Properties</em> includes entries to set a high and low limit on an account. That's coupled to a new column that's available on the Accounts Page, <em>Balance Limit</em>. If you set a high or low limit and the account balance falls above or below the respective limit an indicator will be shown in the Balance Limit column.</li>
    <li>The description field quickfill in the register now displays a drop-down list of possible completions instead of just one inline completion.</li>
    <li>File import menu items for the MT940, MT942, and DTAUS formats is replaced with a single <em>Import from AQBanking</em> that supports importing any file format supported by AQBanking, including the frequently requested CAMT. (Note that some CAMT profiles are under the XML format.) </li>
    <li>The import matcher now permits editing descriptions, notes, and memo fields in the matcher window before creating the transactions. Right-click and select from the context menu.</li>
    <li>The report generated by the Print Invoice button on the Edit Invoice tab can now be configured as a book option at the bottom of the Business tab; this permits selecting a saved configuration of one of the standard invoice reports. Another option enables a delay, during which a dialog box will appear enabling the user to select a different report. Note: When saving a configuration make sure that the invoice number is <em>not set</em> or you'll get that particular invoice instead of the one that you pressed the button for.</li>
</ul>

<h3>Significant Code Changes</h3>

<h4>Deprecations (will be removed in GnuCash 6.0)</h4>
<ul>
    <li>_ (the alias for gettext. Use G_ instead</li>
    <li>gnc:make-account-list-limited-option</li>
    <li>gnc:make-account-list-option</li>
    <li>gnc:make-account-sel-limited-option</li>
    <li>gnc:make-account-sel-option</li>
    <li>gnc:make-budget-option</li>
    <li>gnc:make-color-option</li>
    <li>gnc:make-commodity-option</li>
    <li>gnc:make-complex-boolean-option</li>
    <li>gnc:make-counter-format-option</li>
    <li>gnc:make-counter-option</li>
    <li>gnc:make-currency-option</li>
    <li>gnc:make-date-format-option</li>
    <li>gnc:make-font-option</li>
    <li>gnc:make-internal-option</li>
    <li>gnc:make-invoice-option</li>
    <li>gnc:make-list-option</li>
    <li>gnc:make-multichoice-callback-option</li>
    <li>gnc:make-multichoice-option</li>
    <li>gnc:make-number-plot-size-option</li>
    <li>gnc:make-number-range-option</li>
    <li>gnc:make-owner-option</li>
    <li>gnc:make-pixmap-option</li>
    <li>gnc:make-query-option</li>
    <li>gnc:make-radiobutton-option</li>
    <li>gnc:make-simple-boolean-option</li>
    <li>gnc:make-string-option</li>
    <li>gnc:make-taxtable-option</li>
    <li>gnc:make-text-option</li>
    <li>gnc:option-set-default-value</li>
    <li>gnc:option-set-value</li>
    <li>gnc:option-setter</li>
    <li>gnc:option-value</li>
    <li>gnc:register-option</li>
    <li>The invoice option to gnc:register-report-create-internal</li>
</ul>

<h4>Report and Book Options</h4>
<ul><li>This major change will affect everyone who has written custom reports in Guile Scheme.</li>
    <li>The report and book options code has been completely rewritten in C++ with SWIG providing Guile Scheme access for reports. The new design requires directly registering options with for example <code>gnc-optiondb-register-string-option</code> instead of calling <code>gnc:make-string-option</code> to create an option followed by <code>gnc:register-option</code> to insert it in the report's options.</li>
    <li>Value access is also changed: Instead of retrieving an option and then querying or setting its value with <code>gnc:option-value</code> one will query the optiondb with <code>gnc-option-value</code>, the arguments to which are the optiondb, the section, and the option name.</li>
<li>Supporting the new options backend the options dialog code in gnc-dialog-options, gnc-business-options, and the new gnc-option-gtk-ui have also been rewritten in C++.</li>
</ul>
<h4>Online Price Retrieval</h4>
<ul>
<li>As noted under New Features the interface to Finance::Quote has been completely rewritten in C++ with much of the behavior previously coded in external perl scripts moved into GnuCash proper. This permits much better access to Finance::Quotes's facilities and in particular should provide much richer error reporting.</li>
</ul>
<h4>Stability Improvements</h4>
<ul>
<li>There are hundreds of small changes to prevent memory leaks, reduce unnecessary memory allocations, and fix compiler and static analyzer warnings.</li>
<li>Use of deprecated API in C/C++ is now an error (with 3 exceptions), including for the minimum required version of GLib and Gtk.</li>
<li>Extensive changes to the CSV importer, resolving most known bugs.</li>
<li>Remove all unused variables and made an unused variable a compile error.</li>
<li>Move all extern "C" declarations into the respective header files and remove extern "C" wrappers around #include statements.</li>
<li>Separate the scheme financial functions into a separate module so that all other scheme code can be banished from libgnucash to bindings.</li>
</ul>
<h4>Modernization</h4>
<ul>
    <li>The menus and toolbars now use the GAction and GActionGroup actuation functions, replacing the deprecated GtkAction and GtkActionGroup APIs.</li>
    <li>The experimental Register2 implementation is removed, as is the never-used Jalali calendar code and partly-written option code for creating a book currency.</li>
</ul>
<p>New and Updated Translations: Chinese (Simplified), Croatian, Czech, English (Australia), English (New Zealand), English (United Kingdom), Hungarian, Japanese, Macedonian, Polish, Portuguese, Portuguese (Brazil), Russian,  Spanish, Swedish, Ukrainian</p>

<h4>Known Problems</h4>
<p><a href="https://bugs.gnucash.org/buglist.cgi?bug_severity=blocker&amp;bug_severity=critical&amp;bug_severity=major&amp;bug_severity=normal&amp;bug_severity=minor&amp;bug_severity=trivial&amp;bug_status=NEW&amp;bug_status=ASSIGNED&amp;bug_status=NEEDINFO&amp;bug_status=REOPENED&amp;limit=0&amp;list_id=8149&amp;order=priority%2Cbug_severity&amp;query_format=advanced">Complete list of all open bugs.</a></p><p>.

</p><h2>Documentation</h2>
<p>Concurrent with the release of GnuCash 5.0 we're pleased to also release a new version of the companion Manual and Tutorial and Concepts Guide</p>
<p>Note that the document formerly titled Help is now the Manual</p>
<p>The installation of the documentation has changed to match the XDG-Documentation recommendations so that recent releases of Gnome Desktop's Yelp can find it.</p>

<h3>Getting GnuCash for Windows and MacOS</h3>
<p>GnuCash is provided for both Microsoft Windows 8.1® and later
    and MacOS 10.13 (High Sierra)® and later in pre-built, all-in-one
    packages. An installer is provided for Microsoft Windows® while
    the MacOS® package is a disk image containing a drag-and-drop
    application bundle.</p>
<p>The SHA256 Hashes for the downloadable files are:</p>
<ul>
    <li><code>cfc13bab31aed8e4962805ef56530f9772889604910b5678cb5c79c283138824</code>&nbsp;&nbsp;gnucash-5.0.tar.bz2</li>
    <li><code>66dd5e32829cb6d8dd9a7e017a894583c7579932d13c4fe024329d9c6cfe956d</code>&nbsp;&nbsp;gnucash-5.0.tar.gz</li>
    <li><code>e9d30e36163a7f047daf2523ac35bf2218d2e661bcfc7f279d57d4d396caa33d</code>&nbsp;&nbsp;gnucash-5.0.setup.exe</li>
    <li><code>c8ea60b2ccbeab5f6997a927939a0fad715fbbe494644e586c6c386bfec6857a</code>&nbsp;&nbsp;Gnucash-Intel-5.0-1.dmg</li>
    <li><code>02a1d6d0d8c61aae47b1200af482967ed16322a41f31dd8cf3a6679e7159edb1</code>&nbsp;&nbsp;gnucash-docs-5.0.tar.gz</li>
</ul>

<ul>
  <li>SourceForge:
  <ul>
    <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/4.1/gnucash-5.0.setup.exe">Win32</a></li>
    <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.0/Gnucash-Intel-5.0-1.dmg">Mac-Intel</a></li>
  </ul></li>
  <li>Github
  <ul>
    <li><a href="https://github.com/Gnucash/gnucash/releases/download/5.0/gnucash-5.0.setup.exe">Win32</a></li>
    <li><a href="https://github.com/Gnucash/gnucash/releases/download/5.0/Gnucash-Intel-5.0-1.dmg">Mac-Intel</a></li>
</ul></li></ul>

<p>GnuCash is now available as a flatpak from Flathub.org. <a href="https://wiki.gnucash.org/wiki/Flatpak">Instructions for installing and running.</a></p>

<h3>Getting GnuCash as source code</h3>
<p>If you want to compile GnuCash 5.0 for yourself, the source code can be downloaded from:</p>
<ul>

  <li>Sourceforge: <a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.0/gnucash-5.0.tar.bz2">bzip2</a>, <a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.0/gnucash-5.0.tar.gz">gzip</a>.</li>

  <li>Github: <a href="https://github.com/Gnucash/gnucash/releases/download/5.0/gnucash-5.0.tar.bz2">bzip</a>, <a href="https://github.com/Gnucash/gnucash/releases/download/5.0/gnucash-5.0.tar.gz">gzip</a></li>

  <li>You can also checkout the sources directly from the git repository as <a href="https://wiki.gnucash.org/wiki/Git">described here.</a></li>
</ul>

<p>To compile GnuCash from the source code by yourself, you will need at least <a href="https://www.gtk.org/">Gtk+</a> 3.22.29, <a href="https://www.gnu.org/software/guile/">Guile</a> 2.0, <a href="https://www.boost.org/">Boost</a> 1.67, <a href="https://webkitgtk.org/">WebKitGtk</a> 2.4, <a href="https://github.com/google/googletest">GoogleTest</a> 1.8.0, <a href="https://cmake.org/">cmake 3.10</a> and <a href="http://www.swig.org/">SWIG</a> 2.0.12. Please consult the README.dependencies file in the sources for the exact list of dependencies and versions.</p>

<h3>Getting the documentation</h3>

<p>The documentation is available at <a href="https://www.gnucash.org/docs.phtml">Documentation page</a> of the <a href="https://www.gnucash.org/">GnuCash website</a>. The 5.0 documentation can be found under "GnuCash v5 (current stable release)" in multiple languages both for reading online and for download in pdf, epub, and mobi formats. The documentation is also included in the MacOS and Windows application bundles.</p>

<p>If you want to compile the GnuCash Documentation 5.0 for yourself, the source code can be downloaded from:</p>
<ul>
  <li><a href="https://downloads.sourceforge.net/gnucash/gnucash%20%28stable%29/5.0/gnucash-docs-5.0-1.tar.gz">Sourceforge</a> or <a href="https://github.com/Gnucash/gnucash/releases/download/5.0/gnucash-docs-5.0.tar.gz">GitHub</a></li>
  <li>You can also checkout the sources directly from the git repository as <a href="https://wiki.gnucash.org/wiki/Git">described here.</a></li>
</ul>


<h3>About the Program</h3>

<p>GnuCash is a free, open source accounting program released under
the GNU General Public License (GPL) and available for GNU/Linux,
*BSD, Solaris, MacOS, and Microsoft Windows.  Programming on GnuCash
began in 1997, and its first stable release was in 1998.</p>
  </div>     <div>
      
      <p>
        Click <a href="https://www.gnucash.org/oldnews.phtml">here</a> for older announcements.      </p> <!-- newsinner -->
    </div> <!-- newsborder -->
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Peer Calls: WebRTC peer to peer calls for everyone (117 pts)]]></title>
            <link>https://github.com/peer-calls/peer-calls</link>
            <guid>41699323</guid>
            <pubDate>Mon, 30 Sep 2024 16:51:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/peer-calls/peer-calls">https://github.com/peer-calls/peer-calls</a>, See on <a href="https://news.ycombinator.com/item?id=41699323">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Peer Calls v4</h2><a id="user-content-peer-calls-v4" aria-label="Permalink: Peer Calls v4" href="#peer-calls-v4"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/peer-calls/peer-calls/workflows/Peer%20Calls%20CI/badge.svg"><img src="https://github.com/peer-calls/peer-calls/workflows/Peer%20Calls%20CI/badge.svg" alt="Peer Calls CI"></a>
<a href="https://goreportcard.com/report/github.com/peer-calls/peer-calls" rel="nofollow"><img src="https://camo.githubusercontent.com/da9c9c0b746385f2020b3c1ee4e9ca79abcde95495bb88addb5a5419fdf124e3/68747470733a2f2f676f7265706f7274636172642e636f6d2f62616467652f6769746875622e636f6d2f706565722d63616c6c732f706565722d63616c6c73" alt="Go Report Card" data-canonical-src="https://goreportcard.com/badge/github.com/peer-calls/peer-calls"></a></p>
<p dir="auto">WebRTC peer to peer calls for everyone. See it live in action at
<a href="https://peercalls.com/" rel="nofollow">peercalls.com</a>.</p>
<p dir="auto">The server has been completely rewriten in Go and all the original
functionality works. An optional implementation of a Selective Forwarding Unit
(SFU) is available to make Peer Calls consume less bandwith for user video
uploads. This wouldn't haven been possible without the awesome
<a href="https://github.com/pion/webrtc">pion/webrtc</a> library.</p>
<p dir="auto">The config file format is still YAML, but is different than what was in v3. The
v3 source code is available in <code>version-3</code> branch.  Version 4 will no longer be
published on NPM since the server is no longer written in NodeJS.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What's New in v4</h2><a id="user-content-whats-new-in-v4" aria-label="Permalink: What's New in v4" href="#whats-new-in-v4"></a></p>
<ul>
<li> Core rewritten in Golang.</li>
<li> Selective Forwarding Unit. Can be enabled using <code>NETWORK_TYPE=sfu</code> environment variable. The <a href="https://peercalls.com/" rel="nofollow">peercalls.com</a> instance has this enabled.</li>
<li> Ability to change video and audio devices without reconnecting.</li>
<li> Improved toolbar layout. Can be toggled by clicking or tapping.</li>
<li> Multiple videos are now shown in a full-size grid and each can be minimized.</li>
<li> Video cropping can be turned off.</li>
<li> Improved file sending. Users are now able to send files larger than 64 or 256 KB (depends on the browser).</li>
<li> Device names are correctly populated in the dropdown list.</li>
<li> Improved desktop sharing.</li>
<li> Copy invite link to clipboard. Will show as share icon on devices that support it.</li>
<li> Fix: Toolbar icons render correctly on iOS 12 devices.</li>
<li> Fix: Video autoplays.</li>
<li> Fix: Toolbar is no longer visible until call is joined</li>
<li> Fix: Add warning when using an unsupported browser</li>
<li> Fix: Add warning when JavaScript is disabled</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">TODO for Selective Forwarding Unit</h2><a id="user-content-todo-for-selective-forwarding-unit" aria-label="Permalink: TODO for Selective Forwarding Unit" href="#todo-for-selective-forwarding-unit"></a></p>
<ul>
<li> Support dynamic adding and removing of streams</li>
<li> Support RTCP packet Picture Loss Indicator (PLI)</li>
<li> Support RTCP packet Receiver Estimated Maximum Bitrate (REMB)</li>
<li> Add handling of other RTCP packets besides NACK, PLI and REMB</li>
<li> Add JitterBuffer (experimental, currently without congestion control)</li>
<li> Support multiple Peer Calls nodes when using SFU</li>
<li> Add support for passive ICE TCP candidates</li>
<li> End-to-End Encryption (E2EE) using Insertable Streams. See <a href="https://github.com/peer-calls/peer-calls/pull/142" data-hovercard-type="pull_request" data-hovercard-url="/peer-calls/peer-calls/pull/142/hovercard">#142</a>.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Requirements for Development</h2><a id="user-content-requirements-for-development" aria-label="Permalink: Requirements for Development" href="#requirements-for-development"></a></p>
<ul dir="auto">
<li><a href="https://nodejs.org/" rel="nofollow">Node.js 18.13</a></li>
<li><a href="https://golang.org/" rel="nofollow">Go 1.19.5</a></li>
</ul>
<p dir="auto">Alternatively, Docker  can be used to run Peer Calls.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Stack</h2><a id="user-content-stack" aria-label="Permalink: Stack" href="#stack"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Backend</h2><a id="user-content-backend" aria-label="Permalink: Backend" href="#backend"></a></p>
<ul dir="auto">
<li><a href="https://golang.org/" rel="nofollow">Golang</a></li>
<li><a href="https://github.com/pion/webrtc">pion/webrtc</a></li>
<li>github.com/go-chi/chi</li>
<li>nhooyr.io/websocket</li>
</ul>
<p dir="auto">See <a href="https://github.com/peer-calls/peer-calls/blob/master/go.mod">go.mod</a> for more information</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Frontend</h2><a id="user-content-frontend" aria-label="Permalink: Frontend" href="#frontend"></a></p>
<ul dir="auto">
<li>React</li>
<li>Redux</li>
<li>TypeScript (since peer-calls <code>v2.1.0</code>)</li>
</ul>
<p dir="auto">See <a href="https://github.com/peer-calls/peer-calls/blob/master/package.json">package.json</a> for more information.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation &amp; Running</h2><a id="user-content-installation--running" aria-label="Permalink: Installation &amp; Running" href="#installation--running"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Download Release</h2><a id="user-content-download-release" aria-label="Permalink: Download Release" href="#download-release"></a></p>
<p dir="auto">Head to <a href="https://github.com/peer-calls/peer-calls/releases">Releases</a> and
download a precompiled version. Currently the binaries for the following
systems are built automatically:</p>
<ul dir="auto">
<li>linux amd64</li>
<li>linux arm</li>
<li>darwin (macOS) amd64</li>
<li>windows amd64</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Deploying onto Kubernetes</h2><a id="user-content-deploying-onto-kubernetes" aria-label="Permalink: Deploying onto Kubernetes" href="#deploying-onto-kubernetes"></a></p>
<p dir="auto">The root of this repository contains a <code>kustomization.yaml</code>, allowing anyone to
patch the manifests found within the <code>deploy/</code> directory. To deploy the manifests
without applying any patches, pass the URL to <code>kubectl</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="kubectl apply -k github.com/peer-calls/peer-calls"><pre>kubectl apply -k github.com/peer-calls/peer-calls</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Using Docker</h2><a id="user-content-using-docker" aria-label="Permalink: Using Docker" href="#using-docker"></a></p>
<p dir="auto">The automated builds on Docker Hub now require a subscription, and approval is
required even for open source projects. We recently switched to using GitHub
Container Registry instead:</p>
<p dir="auto">Use the <a href="https://ghcr.io/peer-calls/peer-calls" rel="nofollow"><code>ghcr.io/peer-calls/peer-calls</code></a> image:</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker run --rm -it -p 3000:3000 ghcr.io/peer-calls/peer-calls:latest"><pre>docker run --rm -it -p 3000:3000 ghcr.io/peer-calls/peer-calls:latest</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building from Source</h2><a id="user-content-building-from-source" aria-label="Permalink: Building from Source" href="#building-from-source"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/peer-calls/peer-calls.git
cd peer-calls
npm install

# for production
npm run build
npm run build:go:linux

# for development
npm run start"><pre>git clone https://github.com/peer-calls/peer-calls.git
<span>cd</span> peer-calls
npm install

<span><span>#</span> for production</span>
npm run build
npm run build:go:linux

<span><span>#</span> for development</span>
npm run start</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building Docker Image</h2><a id="user-content-building-docker-image" aria-label="Permalink: Building Docker Image" href="#building-docker-image"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/peer-calls/peer-calls
cd peer-calls
docker build -t peer-calls .
docker run --rm -it -p 3000:3000 peer-calls"><pre>git clone https://github.com/peer-calls/peer-calls
<span>cd</span> peer-calls
docker build -t peer-calls <span>.</span>
docker run --rm -it -p 3000:3000 peer-calls</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration</h2><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Environment variables</h2><a id="user-content-environment-variables" aria-label="Permalink: Environment variables" href="#environment-variables"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Variable</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>PEERCALLS_LOG</code></td>
<td>csv</td>
<td>Enables or disables logging for certain modules</td>
<td><code>-sdp,-ws,-nack,-rtp,-rtcp,-pion:*:trace,-pion:*:debug,-pion:*:info,*</code></td>
</tr>
<tr>
<td><code>PEERCALLS_FS</code></td>
<td>string</td>
<td>When set to a non-empty value, use the path to find resource files</td>
<td></td>
</tr>
<tr>
<td><code>PEERCALLS_BASE_URL</code></td>
<td>string</td>
<td>Base URL of the application</td>
<td></td>
</tr>
<tr>
<td><code>PEERCALLS_BIND_HOST</code></td>
<td>string</td>
<td>IP to listen to</td>
<td><code>0.0.0.0</code></td>
</tr>
<tr>
<td><code>PEERCALLS_BIND_PORT</code></td>
<td>int</td>
<td>Port to listen to</td>
<td><code>3000</code></td>
</tr>
<tr>
<td><code>PEERCALLS_TLS_CERT</code></td>
<td>string</td>
<td>Path to TLS PEM certificate. If set will enable TLS</td>
<td></td>
</tr>
<tr>
<td><code>PEERCALLS_TLS_KEY</code></td>
<td>string</td>
<td>Path to TLS PEM cert key. If set will enable TLS</td>
<td></td>
</tr>
<tr>
<td><code>PEERCALLS_STORE_TYPE</code></td>
<td>string</td>
<td>Can be <code>memory</code> or <code>redis</code></td>
<td><code>memory</code></td>
</tr>
<tr>
<td><code>PEERCALLS_STORE_REDIS_HOST</code></td>
<td>string</td>
<td>Hostname of Redis server</td>
<td></td>
</tr>
<tr>
<td><code>PEERCALLS_STORE_REDIS_PORT</code></td>
<td>int</td>
<td>Port of Redis server</td>
<td></td>
</tr>
<tr>
<td><code>PEERCALLS_STORE_REDIS_PREFIX</code></td>
<td>string</td>
<td>Prefix for Redis keys. Suggestion: <code>peercalls</code></td>
<td></td>
</tr>
<tr>
<td><code>PEERCALLS_NETWORK_TYPE</code></td>
<td>string</td>
<td>Can be <code>mesh</code> or <code>sfu</code>. Setting to SFU will make the server the main peer</td>
<td><code>mesh</code></td>
</tr>
<tr>
<td><code>PEERCALLS_NETWORK_SFU_INTERFACES</code></td>
<td>csv</td>
<td>List of interfaces to use for ICE candidates, uses all available when empty</td>
<td></td>
</tr>
<tr>
<td><code>PEERCALLS_NETWORK_SFU_JITTER_BUFFER</code></td>
<td>bool</td>
<td>Set to <code>true</code> to enable the use of Jitter Buffer</td>
<td><code>false</code></td>
</tr>
<tr>
<td><code>PEERCALLS_NETWORK_SFU_PROTOCOLS</code></td>
<td>csv</td>
<td>Can be <code>udp4</code>, <code>udp6</code>, <code>tcp4</code> or <code>tcp6</code></td>
<td><code>udp4,udp6</code></td>
</tr>
<tr>
<td><code>PEERCALLS_NETWORK_SFU_TCP_BIND_ADDR</code></td>
<td>string</td>
<td>ICE TCP bind address. By default listens on all interfaces.</td>
<td></td>
</tr>
<tr>
<td><code>PEERCALLS_NETWORK_SFU_TCP_LISTEN_PORT</code></td>
<td>int</td>
<td>ICE TCP listen port. By default uses a random port.</td>
<td><code>0</code></td>
</tr>
<tr>
<td><code>PEERCALLS_NETWORK_SFU_TRANSPORT_LISTEN_ADDR</code></td>
<td>string</td>
<td>When set, will listen for external RTP, Data and Metadata UDP streams</td>
<td></td>
</tr>
<tr>
<td><code>PEERCALLS_NETWORK_SFU_TRANSPORT_NODES</code></td>
<td>csv</td>
<td>When set, will transmit media and data to designated <code>host:port</code>(s).</td>
<td></td>
</tr>
<tr>
<td><code>PEERCALLS_NETWORK_SFU_UDP_PORT_MIN</code></td>
<td>int</td>
<td>Defines ICE UDP range start to use for UDP host candidates.</td>
<td><code>0</code></td>
</tr>
<tr>
<td><code>PEERCALLS_NETWORK_SFU_UDP_PORT_MAX</code></td>
<td>int</td>
<td>Defines ICE UDP range end to use for UDP host candidates.</td>
<td><code>0</code></td>
</tr>
<tr>
<td><code>PEERCALLS_ICE_SERVER_URLS</code></td>
<td>csv</td>
<td>List of ICE Server URLs</td>
<td></td>
</tr>
<tr>
<td><code>PEERCALLS_ICE_SERVER_AUTH_TYPE</code></td>
<td>string</td>
<td>Can be empty or <code>secret</code> for coturn <code>static-auth-secret</code> config option.</td>
<td></td>
</tr>
<tr>
<td><code>PEERCALLS_ICE_SERVER_SECRET</code></td>
<td>string</td>
<td>Secret for coturn</td>
<td></td>
</tr>
<tr>
<td><code>PEERCALLS_ICE_SERVER_USERNAME</code></td>
<td>string</td>
<td>Username for coturn</td>
<td></td>
</tr>
<tr>
<td><code>PEERCALLS_PROMETHEUS_ACCESS_TOKEN</code></td>
<td>string</td>
<td>Access token for prometheus <code>/metrics</code> URL</td>
<td></td>
</tr>
<tr>
<td><code>PEERCALLS_FRONTEND_ENCODED_INSERTABLE_STREAMS</code></td>
<td>bool</td>
<td>Enable insertable streams</td>
<td><code>false</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">The default ICE servers in use are:</p>
<ul dir="auto">
<li><code>stun:stun.l.google.com:19302</code></li>
<li><code>stun:global.stun.twilio.com:3478?transport=udp</code></li>
</ul>
<p dir="auto">Only a single ICE server can be defined via environment variables. To define
more use a YAML config file. To load a config file, use the <code>-c /path/to/config.yml</code> command line argument.</p>
<p dir="auto">See <a href="https://github.com/peer-calls/peer-calls/blob/master/src/server/config/types.go">config/types.go</a> for configuration types.</p>
<p dir="auto">Example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="base_url: ''
bind_host: '0.0.0.0'
bind_port: 3005
ice_servers:
 - urls:
   - 'stun:stun.l.google.com:19302'
- urls:
  - 'stun:global.stun.twilio.com:3478?transport=udp'
#- urls:
#  - 'turn:coturn.mydomain.com'
#  auth_type: secret
#  auth_secret:
#    username: &quot;peercalls&quot;
#    secret: &quot;some-static-secret&quot;
# tls:
#   cert: test.pem
#   key: test.key
store:
  type: memory
  # type: redis
  # redis:
  #   host: localhost
  #   port: 6379
  #   prefix: peercalls
network:
  type: mesh
  # type: sfu
  # sfu:
  #   interfaces:
  #   - eth0
prometheus:
  access_token: &quot;mytoken&quot;
frontend:
  encodedInsertableStreams: false"><pre><span>base_url</span>: <span><span>'</span><span>'</span></span>
<span>bind_host</span>: <span><span>'</span>0.0.0.0<span>'</span></span>
<span>bind_port</span>: <span>3005</span>
<span>ice_servers</span>:
 - <span>urls</span>:
   - <span><span>'</span>stun:stun.l.google.com:19302<span>'</span></span>
- <span>urls</span>:
  - <span><span>'</span>stun:global.stun.twilio.com:3478?transport=udp<span>'</span></span>
<span><span>#</span>- urls:</span>
<span><span>#</span>  - 'turn:coturn.mydomain.com'</span>
<span><span>#</span>  auth_type: secret</span>
<span><span>#</span>  auth_secret:</span>
<span><span>#</span>    username: "peercalls"</span>
<span><span>#</span>    secret: "some-static-secret"</span>
<span><span>#</span> tls:</span>
<span><span>#</span>   cert: test.pem</span>
<span><span>#</span>   key: test.key</span>
<span>store</span>:
  <span>type</span>: <span>memory</span>
  <span><span>#</span> type: redis</span>
  <span><span>#</span> redis:</span>
  <span><span>#</span>   host: localhost</span>
  <span><span>#</span>   port: 6379</span>
  <span><span>#</span>   prefix: peercalls</span>
<span>network</span>:
  <span>type</span>: <span>mesh</span>
  <span><span>#</span> type: sfu</span>
  <span><span>#</span> sfu:</span>
  <span><span>#</span>   interfaces:</span>
  <span><span>#</span>   - eth0</span>
<span>prometheus</span>:
  <span>access_token</span>: <span><span>"</span>mytoken<span>"</span></span>
<span>frontend</span>:
  <span>encodedInsertableStreams</span>: <span>false</span></pre></div>
<p dir="auto">Prometheus <code>/metrics</code> URL will not be accessible without an access token set.
The access token can be provided by either:</p>
<ul dir="auto">
<li>Setting <code>Authorization</code> header to <code>Bearer mytoken</code>, or</li>
<li>Providing the access token as a query string: <code>/metrics?access_token=mytoken</code></li>
</ul>
<p dir="auto">To access the server, go to <a href="http://localhost:3000/" rel="nofollow">http://localhost:3000</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Accessing From Network</h2><a id="user-content-accessing-from-network" aria-label="Permalink: Accessing From Network" href="#accessing-from-network"></a></p>
<p dir="auto">Most browsers will prevent access to user media devices if the application is
accessed from the network (not via 127.0.0.1). If you wish to test your mobile
devices, you'll have to enable TLS by setting the <code>PEERCALLS_TLS_CERT</code> and
<code>PEERCALLS_TLS_KEY</code> environment variables. To generate a self-signed certificate
you can use:</p>
<div data-snippet-clipboard-copy-content="openssl req -nodes -x509 -newkey rsa:4096 -keyout key.pem -subj &quot;/C=US/ST=Oregon/L=Portland/O=Company Name/OU=Org/CN=example.com&quot; -out cert.pem -days 365"><pre><code>openssl req -nodes -x509 -newkey rsa:4096 -keyout key.pem -subj "/C=US/ST=Oregon/L=Portland/O=Company Name/OU=Org/CN=example.com" -out cert.pem -days 365
</code></pre></div>
<p dir="auto">Replace <code>example.com</code> with your server's hostname.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Multiple Instances and Redis</h2><a id="user-content-multiple-instances-and-redis" aria-label="Permalink: Multiple Instances and Redis" href="#multiple-instances-and-redis"></a></p>
<p dir="auto">Redis can be used to allow users connected to different instances to connect.
The following needs to be added to <code>config.yaml</code> to enable Redis:</p>
<div dir="auto" data-snippet-clipboard-copy-content="store:
  type: redis
  redis:
    host: redis-host  # redis host
    port: 6379        # redis port
    prefix: peercalls # all instances must use the same prefix"><pre><span>store</span>:
  <span>type</span>: <span>redis</span>
  <span>redis</span>:
    <span>host</span>: <span>redis-host  </span><span><span>#</span> redis host</span>
    <span>port</span>: <span>6379</span>        <span><span>#</span> redis port</span>
    <span>prefix</span>: <span>peercalls </span><span><span>#</span> all instances must use the same prefix</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Logging</h2><a id="user-content-logging" aria-label="Permalink: Logging" href="#logging"></a></p>
<p dir="auto">By default, Peer Calls server will log only basic information. Client-side
logging is disabled by default.</p>
<p dir="auto">Server-side logs can be configured via the <code>PEERCALLS_LOG</code> environment variable. Setting
it to <code>*</code> will enable all server-side logging:</p>
<ul dir="auto">
<li><code>PEERCALLS_LOG=*</code></li>
</ul>
<p dir="auto">Client-side logs can be configured via <code>localStorage.DEBUG</code> and
<code>localStorage.LOG</code> variables:</p>
<ul dir="auto">
<li>Setting <code>localStorage.log=1</code> enables logging of Redux actions and state
changes</li>
<li>Setting <code>localStorage.debug=peercalls,peercalls:*</code> enables all other
client-side logging</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Development</h2><a id="user-content-development" aria-label="Permalink: Development" href="#development"></a></p>
<p dir="auto">Below are some common scripts used for development:</p>
<div data-snippet-clipboard-copy-content="npm start              build all resources and start the server.
npm run build          build all client-side resources.
npm run start:server   start the server
npm run js:watch       build and watch resources
npm test               run all client-side tests.
go test ./...          run all server tests
npm run ci             run all linting, tests and build the client-side"><pre><code>npm start              build all resources and start the server.
npm run build          build all client-side resources.
npm run start:server   start the server
npm run js:watch       build and watch resources
npm test               run all client-side tests.
go test ./...          run all server tests
npm run ci             run all linting, tests and build the client-side
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Browser Support</h2><a id="user-content-browser-support" aria-label="Permalink: Browser Support" href="#browser-support"></a></p>
<p dir="auto">Tested on Firefox and Chrome, including mobile versions. Also works on Safari
and iOS since version 11. Does not work on Microsoft Edge because they do not
support DataChannels yet.</p>
<p dir="auto">For more details, see here:</p>
<ul dir="auto">
<li><a href="http://caniuse.com/#feat=rtcpeerconnection" rel="nofollow">http://caniuse.com/#feat=rtcpeerconnection</a></li>
<li><a href="http://caniuse.com/#search=getUserMedia" rel="nofollow">http://caniuse.com/#search=getUserMedia</a></li>
</ul>
<p dir="auto">In Firefox, it might be useful to use <code>about:webrtc</code> to debug connection
issues. In Chrome, use <code>about:webrtc-internals</code>.</p>
<p dir="auto">When experiencing connection issues, the first thing to try is to have all
peers to use the same browser.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Epheremal UDP Ports for ICE</h2><a id="user-content-epheremal-udp-ports-for-ice" aria-label="Permalink: Epheremal UDP Ports for ICE" href="#epheremal-udp-ports-for-ice"></a></p>
<p dir="auto">The UDP port range can be defined for opening epheremal ports. These ports will
be used for generating UDP host ICE candidates. It is recommended to enable
these UDP ports when ICE TCP is enabled, because the priority of TCP host
candidates will be higher than srflx/prflx candidates, as such TCP will be used
even though UDP connectivity might be possible.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">ICE TCP</h2><a id="user-content-ice-tcp" aria-label="Permalink: ICE TCP" href="#ice-tcp"></a></p>
<p dir="auto">Peer Calls supports ICE over TCP as described in RFC6544. Currently only
passive ICE candidates are supported. This means that users whose ISPs or
corporate firewalls block UDP packets can use TCP to connect to the SFU. In
most scenarios, this removes the need to use a TURN server, but this
functionality is currently experimental and is not enabled by default.</p>
<p dir="auto">Add the <code>tcp4</code> and <code>tcp6</code> to your <code>PEERCALLS_NETWORK_SFU_PROTOCOLS</code> to enable
support for ICE TCP:</p>
<div data-snippet-clipboard-copy-content="PEERCALLS_NETWORK_TYPE=sfu PEERCALLS_NETWORK_SFU_PROTOCOLS=`udp4,udp6,tcp4,tcp6` peer-calls"><pre><code>PEERCALLS_NETWORK_TYPE=sfu PEERCALLS_NETWORK_SFU_PROTOCOLS=`udp4,udp6,tcp4,tcp6` peer-calls
</code></pre></div>
<p dir="auto">To test this functionality, <code>udp4</code> and <code>udp6</code> network types should be omitted:</p>
<div data-snippet-clipboard-copy-content="PEERCALLS_NETWORK_TYPE=sfu PEERCALLS_NETWORK_SFU_PROTOCOLS=`tcp4,tcp6` peer-calls"><pre><code>PEERCALLS_NETWORK_TYPE=sfu PEERCALLS_NETWORK_SFU_PROTOCOLS=`tcp4,tcp6` peer-calls
</code></pre></div>
<p dir="auto">Please note that in production the <code>PEERCALLS_NETWORK_SFU_TCP_LISTEN_PORT</code> should
be specified and external TCP access allowed through the server firewall.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">TURN Server</h2><a id="user-content-turn-server" aria-label="Permalink: TURN Server" href="#turn-server"></a></p>
<p dir="auto">When a direct connection cannot be established, it might be help to use a TURN
server. The peercalls.com instance is configured to use a TURN server and it
can be used for testing. However, the server bandwidth there is not unlimited.</p>
<p dir="auto">Here are the steps to install a TURN server on Ubuntu/Debian Linux:</p>

<p dir="auto">Use the following configuration as a template for <code>/etc/turnserver.conf</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="lt-cred-mech
use-auth-secret
static-auth-secret=p4ssw0rd
realm=example.com
total-quota=300
cert=/etc/letsencrypt/live/rtc.example.com/fullchain.pem
pkey=/etc/letsencrypt/live/rtc.example.com/privkey.pem
log-file=/dev/stdout
no-multicast-peers
proc-user=turnserver
proc-group=turnserver"><pre>lt-cred-mech
use-auth-secret
static-auth-secret=p4ssw0rd
realm=example.com
total-quota=300
cert=/etc/letsencrypt/live/rtc.example.com/fullchain.pem
pkey=/etc/letsencrypt/live/rtc.example.com/privkey.pem
log-file=/dev/stdout
no-multicast-peers
proc-user=turnserver
proc-group=turnserver</pre></div>
<p dir="auto">Change the <code>p4ssw0rd</code>, <code>realm</code>  and paths to server certificates.</p>
<p dir="auto">Use the following configuration for Peer Calls:</p>
<div dir="auto" data-snippet-clipboard-copy-content="iceServers:
- urls:
  - 'turn:rtc.example.com'
  auth_type: secret
  auth_secret:
    username: 'example'
    secret: 'p4ssw0rd'"><pre><span>iceServers</span>:
- <span>urls</span>:
  - <span><span>'</span>turn:rtc.example.com<span>'</span></span>
  <span>auth_type</span>: <span>secret</span>
  <span>auth_secret</span>:
    <span>username</span>: <span><span>'</span>example<span>'</span></span>
    <span>secret</span>: <span><span>'</span>p4ssw0rd<span>'</span></span></pre></div>
<p dir="auto">Finally, enable and start the <code>coturn</code> service:</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo systemctl enable coturn
sudo systemctl start coturn"><pre>sudo systemctl <span>enable</span> coturn
sudo systemctl start coturn</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">See <a href="https://github.com/peer-calls/peer-calls/blob/master/CONTRIBUTING.md">Contributing</a> section.</p>
<p dir="auto">If you encounter a bug, please open a new issue!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Support</h2><a id="user-content-support" aria-label="Permalink: Support" href="#support"></a></p>
<p dir="auto">The development of Peer Calls is sponsored by <a href="https://rondomoon.com/" rel="nofollow">rondomoon</a>. If you'd
like enterprise on-site support or become a sponsor, please contact
<a href="mailto:hello@rondomoon.com">hello@rondomoon.com</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto"><a href="https://github.com/peer-calls/peer-calls/blob/master/LICENSE">Apache 2.0</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Generate pip requirements.txt file based on imports of any project (115 pts)]]></title>
            <link>https://github.com/bndr/pipreqs</link>
            <guid>41698995</guid>
            <pubDate>Mon, 30 Sep 2024 16:26:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/bndr/pipreqs">https://github.com/bndr/pipreqs</a>, See on <a href="https://news.ycombinator.com/item?id=41698995">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto"><code>pipreqs</code> - Generate requirements.txt file for any project based on imports</h2><a id="user-content-pipreqs---generate-requirementstxt-file-for-any-project-based-on-imports" aria-label="Permalink: pipreqs - Generate requirements.txt file for any project based on imports" href="#pipreqs---generate-requirementstxt-file-for-any-project-based-on-imports"></a></p>
<a href="https://travis-ci.org/bndr/pipreqs" rel="nofollow"><img src="https://camo.githubusercontent.com/4a6691405e80046b2adfc4e84ad1d75e54cd2a2f8e0e72f271785279d5d5999a/68747470733a2f2f696d672e736869656c64732e696f2f7472617669732f626e64722f706970726571732e737667" data-canonical-src="https://img.shields.io/travis/bndr/pipreqs.svg">
</a>
<a href="https://pypi.python.org/pypi/pipreqs" rel="nofollow"><img src="https://camo.githubusercontent.com/9af8172088d35f66648d3f92489d90160e55ba47a219678d7afc5620e7265e25/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f706970726571732e737667" data-canonical-src="https://img.shields.io/pypi/v/pipreqs.svg">
</a>
<a href="https://codecov.io/gh/bndr/pipreqs" rel="nofollow"><img alt="https://codecov.io/gh/bndr/pipreqs/branch/master/graph/badge.svg?token=0rfPfUZEAX" src="https://camo.githubusercontent.com/ad7be79c5c0fdce111ac5f98493b1be66aedc0fda9825d649e02f27074f102c1/68747470733a2f2f636f6465636f762e696f2f67682f626e64722f706970726571732f6272616e63682f6d61737465722f67726170682f62616467652e7376673f746f6b656e3d3072665066555a454158" data-canonical-src="https://codecov.io/gh/bndr/pipreqs/branch/master/graph/badge.svg?token=0rfPfUZEAX"></a>
<a href="https://pypi.python.org/pypi/pipreqs" rel="nofollow"><img src="https://camo.githubusercontent.com/6b14a9ccb959b96dd0190a32c2b798c3be30b383c29198bc7670171da3876522/68747470733a2f2f696d672e736869656c64732e696f2f707970692f6c2f706970726571732e737667" data-canonical-src="https://img.shields.io/pypi/l/pipreqs.svg">
</a>
<a name="user-content-installation"></a>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>

<p dir="auto">Obs.: if you don't want support for jupyter notebooks, you can install pipreqs without the dependencies that give support to it.
To do so, run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install --no-deps pipreqs
pip install yarg==0.1.9 docopt==0.6.2"><pre>pip install --no-deps pipreqs
pip install yarg==0.1.9 docopt==0.6.2</pre></div>
<a name="user-content-usage"></a>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<pre>Usage:
    pipreqs [options] [&lt;path&gt;]

Arguments:
    &lt;path&gt;                The path to the directory containing the application files for which a requirements file
                          should be generated (defaults to the current working directory)

Options:
    --use-local           Use ONLY local package info instead of querying PyPI
    --pypi-server &lt;url&gt;   Use custom PyPi server
    --proxy &lt;url&gt;         Use Proxy, parameter will be passed to requests library. You can also just set the
                          environments parameter in your terminal:
                          $ export HTTP_PROXY="http://10.10.1.10:3128"
                          $ export HTTPS_PROXY="https://10.10.1.10:1080"
    --debug               Print debug information
    --ignore &lt;dirs&gt;...    Ignore extra directories, each separated by a comma
    --no-follow-links     Do not follow symbolic links in the project
    --encoding &lt;charset&gt;  Use encoding parameter for file open
    --savepath &lt;file&gt;     Save the list of requirements in the given file
    --print               Output the list of requirements in the standard output
    --force               Overwrite existing requirements.txt
    --diff &lt;file&gt;         Compare modules in requirements.txt to project imports
    --clean &lt;file&gt;        Clean up requirements.txt by removing modules that are not imported in project
    --mode &lt;scheme&gt;       Enables dynamic versioning with &lt;compat&gt;, &lt;gt&gt; or &lt;non-pin&gt; schemes
                          &lt;compat&gt; | e.g. Flask~=1.1.2
                          &lt;gt&gt;     | e.g. Flask&gt;=1.1.2
                          &lt;no-pin&gt; | e.g. Flask
    --scan-notebooks      Look for imports in jupyter notebook files.
</pre>
<a name="user-content-example"></a>
<p dir="auto"><h2 tabindex="-1" dir="auto">Example</h2><a id="user-content-example" aria-label="Permalink: Example" href="#example"></a></p>
<pre>$ pipreqs /home/project/location
Successfully saved requirements file in /home/project/location/requirements.txt
</pre>
<p dir="auto">Contents of requirements.txt</p>
<pre>wheel==0.23.0
Yarg==0.1.9
docopt==0.6.2
</pre>
<a name="user-content-why-not-pip-freeze"></a>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why not pip freeze?</h2><a id="user-content-why-not-pip-freeze" aria-label="Permalink: Why not pip freeze?" href="#why-not-pip-freeze"></a></p>
<ul dir="auto">
<li><code>pip freeze</code> only saves the packages that are installed with <code>pip install</code> in your environment.</li>
<li><code>pip freeze</code> saves all packages in the environment including those that you don't use in your current project (if you don't have <code>virtualenv</code>).</li>
<li>and sometimes you just need to create <code>requirements.txt</code> for a new project without installing modules.</li>
</ul>

</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Liquid Foundation Models: Our First Series of Generative AI Models (171 pts)]]></title>
            <link>https://www.liquid.ai/liquid-foundation-models</link>
            <guid>41698361</guid>
            <pubDate>Mon, 30 Sep 2024 15:33:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.liquid.ai/liquid-foundation-models">https://www.liquid.ai/liquid-foundation-models</a>, See on <a href="https://news.ycombinator.com/item?id=41698361">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="w-node-_4ac69c6b-6354-b7f1-d147-da6548bbc4fa-18e46dab"><div id="takeaways"><h2>Takeaways</h2><div><p>We announce the first series of Liquid Foundation Models (LFMs), a new generation of generative AI models built from first principles.</p><p>Our 1B, 3B, and 40B LFMs achieve state-of-the-art performance in terms of quality at each scale, while maintaining a smaller memory footprint and more efficient inference.</p><p>Try LFMs today on <strong>Liquid Playground, Lambda (Chat UI&nbsp;and API)</strong>, <strong>Perplexity Labs</strong>, and soon on <strong>Cerebras Inference</strong>. The LFM stack is being optimized for NVIDIA, AMD, Qualcomm, Cerebras, and Apple hardware.</p><p>We build private, edge, and on-premise AI solutions for enterprises of any size.</p><p>We are scaling LFMs and expect to introduce new and better capabilities across various industries, such as financial services, biotechnology, and consumer electronics.</p></div><a href="https://playground.liquid.ai/" target="_blank"><p>Try Liquid</p></a><div><p>At Liquid AI, we build new methods for designing powerful AI systems over which we have significant control. We design them the same way engineers built engines, cars, and airplanes:&nbsp; from first principles. Our mission is to create best-in-class, intelligent, and efficient systems at every scale – systems designed to process large amounts of sequential multimodal data, to enable advanced reasoning, and to achieve reliable decision-making.</p><p>Today, we introduce the first generation of Liquid Foundation Models (LFMs). LFMs are large neural networks built with computational units deeply rooted in the theory of dynamical systems, signal processing, and numerical linear algebra. This unique blend allows us to leverage decades of theoretical advances in these fields in our quest to enable intelligence at every scale. LFMs are general-purpose AI models that can be used to model any kind of sequential data, including video, audio, text, time series, and signals.&nbsp;</p><p>Our name “Liquid” pays homage to our roots in dynamic and adaptive learning systems.&nbsp;</p></div></div><div id="introducing-the-first-generation-of-language-LFMs"><h2>Introducing the First Generation of Language LFMs</h2><p>We are proud to release our first series of language models:</p><div><p>A dense <strong>1.3B model</strong>, ideal for highly resource-constrained environments.</p><p>A dense <strong>3.1B model</strong>, optimized for edge deployment.</p><p>A <strong>40.3B Mixture of Experts (MoE) model</strong>, designed for tackling more complex tasks.</p></div><p>Architecture work cannot happen in a vacuum – our goal is to develop useful models that are competitive with the current best-in-class LLMs. In doing so, we hope to show that model performance isn’t just about scale – it’s also about innovation.</p><h3>State-of-the-Art Performance</h3><div><p>We report the results of our fine-tuned LFMs and compare them with similar-sized language models using Eleuther AI’s lm-evaluation-harness v0.4. Unless specified otherwise, we compare to other fine-tuned models.</p><p><strong>LFM-1B</strong> achieves the highest scores across various benchmarks in the 1B category, making it the new state-of-the-art model at this size. This is the first time a non-GPT architecture significantly outperforms transformer-based models.</p><div id="w-node-_97d9569a-40ce-c3ad-84c4-675d45429df8-18e46dab"><div id="w-node-d5abe0b5-a930-2283-c7fb-4f8b95e238f5-18e46dab"><p>Stable LM 2</p><p>(Stability)</p><p>1.6B</p></div><div id="w-node-_44879ce4-d147-caeb-102b-0af001f662a5-18e46dab"><p>Smol LM</p><p>(Hugging Face)</p><p>1.7B</p></div><div id="w-node-_40cf2a32-93de-6a91-aba4-d9f8f6f04145-18e46dab"><p>R Gemma 2</p><p>(Google)</p><p>Base 2.7B</p></div></div></div><div><p><strong>LFM-3B</strong> delivers incredible performance for its size. It positions itself as first place among 3B parameter transformers, hybrids, and RNN models, but also outperforms the previous generation of 7B and 13B models. It is also on par with Phi-3.5-mini on multiple benchmarks, while being 18.4% smaller. LFM-3B is the ideal choice for mobile and other edge text-based applications.</p><div id="w-node-d97be800-342f-17e8-df37-a6c1da029509-18e46dab"><div id="w-node-d97be800-342f-17e8-df37-a6c1da02952b-18e46dab"><p>Mistral-7b v0.3</p><p>(Mistral AI)</p><p>7B</p></div><div id="w-node-d97be800-342f-17e8-df37-a6c1da029535-18e46dab"><p>Mistral Nemo</p><p>(Mistral AI)</p><p>12.2B</p></div></div><p>*Scores reported by the developers. All the other scores were calculated with the same evaluation harness we used for our own models.</p></div><div><p><strong>LFM-40B</strong> offers a new balance between model size and output quality. It leverages 12B activated parameters at use. Its performance is comparable to models larger than itself, while its MoE architecture enables higher throughput and deployment on more cost-effective hardware.</p><p>*Scores reported by the developers. All the other scores were calculated with the same evaluation harness we used for our own models.</p></div><h3>LFMs are Memory-Efficient</h3><p>LFMs have a reduced memory footprint compared to transformer architectures. This is particularly true for long inputs, where the KV cache in transformer-based LLMs grows linearly with sequence length. By efficiently compressing inputs, LFMs can process longer sequences on the same hardware. For example, compared to other 3B-class models, LFMs maintain a minimal memory footprint.</p><p><img src="https://cdn.prod.website-files.com/6557a2b6957fcb7aeb0efcf0/66f9a9b9624c365c96251a0c_desktop%20graph.png" loading="lazy" width="854" sizes="(max-width: 991px) 100vw, 900px" alt="Fig. 2. Total inference memory footprint of different language models vs. the input+generation length." srcset="https://cdn.prod.website-files.com/6557a2b6957fcb7aeb0efcf0/66f9a9b9624c365c96251a0c_desktop%20graph-p-500.png 500w, https://cdn.prod.website-files.com/6557a2b6957fcb7aeb0efcf0/66f9a9b9624c365c96251a0c_desktop%20graph-p-800.png 800w, https://cdn.prod.website-files.com/6557a2b6957fcb7aeb0efcf0/66f9a9b9624c365c96251a0c_desktop%20graph-p-1080.png 1080w, https://cdn.prod.website-files.com/6557a2b6957fcb7aeb0efcf0/66f9a9b9624c365c96251a0c_desktop%20graph-p-1600.png 1600w, https://cdn.prod.website-files.com/6557a2b6957fcb7aeb0efcf0/66f9a9b9624c365c96251a0c_desktop%20graph.png 1788w"><img src="https://cdn.prod.website-files.com/6557a2b6957fcb7aeb0efcf0/66f9a633c50a28b58fc3d8b6_figure-wrapper.png" loading="lazy" width="632" sizes="(max-width: 767px) 100vw, (max-width: 991px) 900px, 100vw" alt="Fig. 2. Total inference memory footprint of different language models vs. the input+generation length." srcset="https://cdn.prod.website-files.com/6557a2b6957fcb7aeb0efcf0/66f9a633c50a28b58fc3d8b6_figure-wrapper-p-500.png 500w, https://cdn.prod.website-files.com/6557a2b6957fcb7aeb0efcf0/66f9a633c50a28b58fc3d8b6_figure-wrapper-p-800.png 800w, https://cdn.prod.website-files.com/6557a2b6957fcb7aeb0efcf0/66f9a633c50a28b58fc3d8b6_figure-wrapper-p-1080.png 1080w, https://cdn.prod.website-files.com/6557a2b6957fcb7aeb0efcf0/66f9a633c50a28b58fc3d8b6_figure-wrapper.png 1328w"></p><p><strong>Fig. 2. </strong>Total inference memory footprint of different language models vs. the input+generation length.</p><h3>LFMs Truly Exploit their Context Length</h3><p>In this preview release, we have optimized our models to deliver a best-in-class 32k token context length, pushing the boundaries of efficiency for our size. This was confirmed by the RULER benchmark, where a length is considered “effective” when its corresponding score is higher than 85.6 [<a href="https://arxiv.org/abs/2404.06654" target="_blank">Hsieh et al. 2024 - RULER</a>]. The following table compares several models at different context lengths.</p><div id="w-node-_8548bc75-6140-0d97-eb1c-5c619016a9b5-18e46dab"><p>Phi-3.5 3.8 B <br><span>(Microsoft)</span></p></div><div><p>This highly efficient context window enables long-context tasks on edge devices for the first time. For developers, it unlocks new applications, including document analysis and summarization, more meaningful interactions with context-aware chatbots, and improved Retrieval-Augmented Generation (RAG) performance.</p><p>Our goal is to keep scaling LFMs across model size, train/test time compute, and context length. Beyond our language LFMs, we have designed models for various data modalities, domains, and applications that we plan to release in the next months.</p></div><h3>Advancing the Pareto Frontier of Large AI Models</h3><p>To achieve these results, we optimized our pre- and post-training pipelines and infrastructure to ensure our models excel across five criteria:</p><div><div data-hover="false" data-delay="0"><nav><p>Breadth and depth of information across various domains and tasks at any given size. We achieve this using a comprehensive pre-training set, advances in model architectures, new pre-training/mid-training/post-training strategies. This allows LFMs to be competitive with larger models on knowledge-based tasks.</p></nav></div><div data-hover="false" data-delay="0"><nav><p>The ability to break down a problem and apply logical and rigorous thinking. We distilled system 2 tasks during the core phases of training, enabling robust analytical capabilities in compact model architectures.</p></nav></div><div data-hover="false" data-delay="0"><nav><p>A model's maximum input size is not the same as its effective context length. We specifically trained LFMs to maximize recall performance and in-context learning capabilities across the entire input range.</p></nav></div><div data-hover="false" data-delay="0"><nav><p>Memory usage of transformer-based models explodes for long inputs, which makes them ill-suited for edge deployment. LFMs have near-constant inference time and memory complexity – as the input context length grows, it does not significantly affect generation speed or increase the amount of memory required.</p></nav></div><div data-hover="false" data-delay="0"><nav><p>Training GPT-like foundation models demands significant computational resources. LFMs are efficient for training on long-context data.</p></nav></div></div></div><div id="reimagining-model-architectures"><h2>Reimagining Model Architectures</h2><div><p>Building on <a href="https://www.liquid.ai/blog/liquid-neural-networks-research" target="_blank">a long line of research</a> in designing expressive and efficient learning systems, we have developed a new design space for foundation models, focusing on different modalities and hardware requirements. Our goal is to explore ways to build foundation models beyond Generative Pre-trained Transformers (GPTs).</p><p>With LFMs, we put into practice new principles and methods guiding model design, developed by our team over the past months.</p></div><div><div data-hover="false" data-delay="0"><div><p>LFMs are composed of structured operators.</p></div><nav><p>Our models are derived from a set of computational units – the building blocks of an architecture – belonging to a new <em>design space</em>. Liquid systems and their composition maximize knowledge capacity and reasoning, while unlocking improved training efficiency, reduced memory cost at inference time, and increased performance in modeling data such as video, audio, text, time series, and signals.</p></nav></div><div data-hover="false" data-delay="0"><div><p>LFM architectures are under control.</p></div><nav><p>The design of our models reciprocally informs our scaling, inference, alignment, and model analysis strategy. We can analyze the dynamics of LFMs via classical signal processing analysis methods and probe their behavior, from model outputs to model internals.</p></nav></div><div data-hover="false" data-delay="0"><div><p>LFMs are adaptive and can serve as the substrate for AI at every scale.</p></div><nav><p>We can <strong>automatically</strong> optimize architectures for a specific platform (e.g., Apple, Qualcomm, Cerebras, and AMD) or match given parameter requirements and inference cache size.</p></nav></div></div><p><strong>Fig. 3. </strong>Our architectures feature custom computational units arranged in <em>depth groups</em> (targeted weight sharing), with additional <em>featurizer interconnections </em>(feature sharing).</p><p>Liquid’s design space is primarily defined by featurization and footprint of architectures and their core operators. Featurization refers to the process of converting input data (e.g., text, audio, images, video) into a structured set of features or vectors that are used to modulate computation inside the model in an adaptive manner. For example, audio and time series data generally requires <em>less</em> featurization in operators due to lower information density, compared to language and multi-modal data. The other key dimension is the computational complexity of the operators. Being able to traverse and complete the design space of structured adaptive operators allows us maximize performance with controlled computational requirements.</p><p><img src="https://cdn.prod.website-files.com/6557a2b6957fcb7aeb0efcf0/66eb44838e25f89817c56644_figure-wrapper%20(2).avif" loading="lazy" width="894" sizes="(max-width: 991px) 100vw, 900px" alt="Fig. 5. We built the foundations of a new design space for computational units, enabling customization to different modalities and hardware requirements." srcset="https://cdn.prod.website-files.com/6557a2b6957fcb7aeb0efcf0/66eb44838e25f89817c56644_figure-wrapper%20(2)-p-500.avif 500w, https://cdn.prod.website-files.com/6557a2b6957fcb7aeb0efcf0/66eb44838e25f89817c56644_figure-wrapper%20(2)-p-800.avif 800w, https://cdn.prod.website-files.com/6557a2b6957fcb7aeb0efcf0/66eb44838e25f89817c56644_figure-wrapper%20(2)-p-1080.avif 1080w, https://cdn.prod.website-files.com/6557a2b6957fcb7aeb0efcf0/66eb44838e25f89817c56644_figure-wrapper%20(2).avif 1788w"><img src="https://cdn.prod.website-files.com/6557a2b6957fcb7aeb0efcf0/66eb4498a147f24853fcb5fb_figure-wrapper.avif" loading="lazy" width="664" sizes="(max-width: 767px) 100vw, (max-width: 991px) 900px, 100vw" alt="Fig. 5. We built the foundations of a new design space for computational units, enabling customization to different modalities and hardware requirements." srcset="https://cdn.prod.website-files.com/6557a2b6957fcb7aeb0efcf0/66eb4498a147f24853fcb5fb_figure-wrapper-p-500.avif 500w, https://cdn.prod.website-files.com/6557a2b6957fcb7aeb0efcf0/66eb4498a147f24853fcb5fb_figure-wrapper.avif 1328w"></p><p><strong>Fig. 4. </strong>We built the foundations of a new design space for computational units, enabling customization to different modalities and hardware requirements.</p><p>At their core, LFMs are built with computational units that can be expressed as adaptive linear operators whose actions are determined by inputs. The LFM design framework unifies and subsumes a wide range of existing computational units in deep learning, providing a systematic approach to exploring the space of architectures. Specifically, our analysis informs model building by improving three key aspects: token-mixing structure (how the operator mixes embeddings in the input sequence), channel-mixing structure (how it mixes channel dimensions), and featurization, responsible for modulating computation based on the input context.</p></div><div id="join-us-as-an-early-adopter-of-LFMs"><h2>Join us as an early adopter of LFMs</h2><div><p>As we are still in the early stages of this journey, we welcome the opportunity to collaborate and discover the strengths and weaknesses of these systems together.</p><p>What are Language LFMs good at today:</p><ul role="list"><li>General and expert knowledge</li><li>Mathematics and logical reasoning</li><li>Efficient and effective long-context tasks</li><li>Their primary language is English, with secondary multilingual capabilities in Spanish, French, German, Chinese, Arabic, Japanese, and Korean</li></ul><p>What are Language LFMs not good at today:</p><ul role="list"><li>Zero-shot code tasks</li><li>Precise numerical calculations</li><li>Time-sensitive information</li><li>Counting r's in the word "Strawberry"!</li><li>Human preference optimization techniques have not been applied extensively to our models yet.</li></ul><p>At Liquid AI, we take an open-science approach. We have and will continue to contribute to the advancement of the AI field by openly publishing our findings and methods through scientific and technical reports. As part of this commitment, we will release relevant data and models produced by our research efforts to the wider AI community. We have dedicated a lot of time and resources to developing these architectures, so we're not open-sourcing our models at the moment. This allows us to continue building on our progress and maintain our edge in the competitive AI landscape.</p><p>If your enterprise is looking to experience the forefront of AI, we invite you to <a href="https://www.liquid.ai/talk-to-our-team">get in touch with us</a>. If this aligns with your personal goals and ambitions, we invite you to <a href="https://jobs.lever.co/liquid.ai/" target="_blank">join our team</a> and drive this vision forward. We are very early on this journey and actively innovating across various aspects of foundation model development and deployment. We invite enthusiastic users to share their experience as well as criticism, and join our red-teaming efforts to improve the capabilities of our models.</p></div><p><a href="https://docs.google.com/forms/d/e/1FAIpQLSdPNEPTajcbz_iEE3nWhI_xheLxo7qpApSBs_ohwxU9wTHLXg/viewform" target="_blank">Share your feedback</a></p></div><div><h2>Liquid Product Launch Event </h2><h2>October 23, 2024 &nbsp;| &nbsp;Cambridge, MA&nbsp;</h2><p>Come join us at MIT Kresge, Cambridge, MA on October 23rd 2024, to learn more about Liquid as we unveil more products and progress on LFMs and their applications in consumer electronics, finance, healthcare, biotechnology, and more! </p><p><a href="https://lu.ma/liquid-ai-launch" target="_blank">RSVP&nbsp;Here</a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Y Combinator Traded Prestige for Growth (484 pts)]]></title>
            <link>https://unfashionable.blog/p/yc/</link>
            <guid>41697032</guid>
            <pubDate>Mon, 30 Sep 2024 13:48:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://unfashionable.blog/p/yc/">https://unfashionable.blog/p/yc/</a>, See on <a href="https://news.ycombinator.com/item?id=41697032">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-header">


  <div>
    <h2>
      Unfashionable
    </h2>
    <p><i>
      For some things Harvard suffices; this blog is for the rest.
      </i>
    </p>
  </div>

    <nav>

      <ul>
    <li><a href="https://unfashionable.blog/">Home</a></li>
    <li><a href="https://unfashionable.blog/about/">About</a></li>
</ul>


    </nav>

</div><div id="content">

  <article>


      

      <section>
        <p>Y Combinator is arguably the most successful early-stage VC fund or accelerator ever. The issue, however, is that they never truly grasped the factors behind their success, which is why YC's peak is already behind them—it’s likely all downhill from here.</p><p>In particular, Sam Altman didn’t grasp what truly made YC successful. He did what he does best: being ambitious and scaling it up! To him, this seemed obvious—there were plenty of companies eager to join YC, and since predicting which ones would succeed was unreliable, why not just accept more? Even if it meant a few more failures, everyone knows VC is a power law game—one extra winner compensates for many flops. Plus, more companies naturally mean more management fees and carry!</p><p>What he failed to grasp (or didn’t care about, since the effects take a long time to unfold) is that reputation and prestige are everything. Take Harvard, for instance: the reason they don’t accept a higher percentage of applicants isn’t because they can’t scale—they have the resources to build more facilities or could even switch to remote like YC—but because they choose not to. Harvard knows its success lies in exclusivity. If everyone could get in, no one would care. People don’t attend Harvard for the lectures, which are all on YouTube anyway, but because being accepted there is a status symbol. Harvard thrives on its reputation and prestige—or simply, its brand.</p><p>Founders want to raise money from the top VCs—e.g. Sequoia or a16z—for the same reason. Sure, these firms offer some of the best support to their portfolio companies, much like Harvard offers top-tier lectures, but that's not the main draw. The real reason to raise from elite VCs is the prestige and legitimacy it confers on your startup. It signals to prospective employees, customers, and future investors that your company is the real deal. Naturally, this signal weakens the easier it becomes to secure funding from these VCs.</p><p>If the main appeal of joining YC isn’t the mentorship but the prestige of being able to write "YC W22" in your Twitter bio and on your company’s landing page, then they've got a problem because you can't scale that arbitrarily. What Sam initiated, and what YC continues to do, is trade their reputation capital for real capital (i.e., more money). However, they’ll soon realize that once their reputation capital is exhausted, rebuilding it will be nearly impossible. Put simply, once YC becomes uncool – which might have already happened – you can’t make it cool again.</p><p>We’re already witnessing the decline of YC in the current batch. For instance, one of the many "AI code editors" YC funded, <a href="https://x.com/CodeFryingPan/status/1840203597478539477?ref=unfashionable.blog">PearAI</a>, is simply a clone of another YC-backed, open-source AI code editor called <a href="https://www.continue.dev/?ref=unfashionable.blog">Continue</a>. Unsurprisingly, the PearAI team doesn’t appear <a href="https://x.com/that_anokha_boy/status/1840476530536780072?ref=unfashionable.blog">super competent</a>. People on Twitter were quick to <a href="https://x.com/RhysSullivan/status/1840461449371812289?ref=unfashionable.blog">mock the project</a>, and as a reaction, Garry Tan (CEO of YC) retweeted a <a href="https://x.com/amaldorai/status/1840476104592900571?ref=unfashionable.blog" rel="noreferrer">post</a> defending it.</p><figure><img src="https://digitalpress.fra1.cdn.digitaloceanspaces.com/ekvtmdn/2024/09/Screenshot-2024-09-30-at-10.36.21.png" alt="" loading="lazy" width="1098" height="364"></figure><p>This is a telling defense. While he is likely correct about the legality of copying Continue's code, that completely misses the point. The issue isn't that PearAI did something illegal—it's that they got funded by YC with nothing more than a codebase copied from another YC-backed company. This shows that (1) YC is willing to fund just about anything, (2) they’re not doing any real due diligence, and (3) they don't particularly care about their existing portfolio companies. If PearAI can secure funding, it means anyone can, and the YC brand loses much of its prestige.</p><p>YC is no longer an exclusive club where membership signals legitimacy—it’s becoming a broad index of tech startups. This decline will continue until cool, innovative companies no longer see any reason to apply.</p>
      </section>

      <br>

      



  </article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The best browser bookmarking system is files (196 pts)]]></title>
            <link>https://afewthingz.com/browserbookmark</link>
            <guid>41696560</guid>
            <pubDate>Mon, 30 Sep 2024 12:51:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://afewthingz.com/browserbookmark">https://afewthingz.com/browserbookmark</a>, See on <a href="https://news.ycombinator.com/item?id=41696560">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Along the years I have tested various browser bookmarking systems. </p>
<p>And for 10 years, I've realised that the best bookmarking system is already built-in to most browsers (Firefox, Chrome), and that is:</p>
<p>files!</p>
<p>See the video, the drag-and-drop creates a <code>.url</code> shortcut file:</p>
<video controls="" autoplay="" muted="" loop="" width="60%"><source src="https://afewthingz.com/files/browserbookmark.mp4"></video>
<p>Just that. You drag and drop the URL to the Desktop or any folder.</p>
<p>No browser extension needed.</p>
<ul>
<li>
<p>Want to delete/copy/move/rename a bookmark? Just delete/copy/move/rename the file.</p>
</li>
<li>
<p>Want to organize your bookmarks? Use directories in your filesystem, as usual.</p>
</li>
<li>
<p>Want to join the bookmark to a work-in-progress in its dedicated directory? Just copy the file there, you'll have the bookmarks grouped with your other files:</p>
<p><img src="https://afewthingz.com/files/browserbookmark2.png" alt=""></p>
</li>
<li>
<p>Want to backup all your bookmarks? They are just <code>.url</code> files in folders, so you can do a backup with all your other documents.</p>
</li>
<li>
<p>Want to sync them with other devices? Use the same sync system as your other documents (Syncthing is great)</p>
</li>
<li>
<p>Want to use your bookmarks in <em>multiple browsers</em>? No problem, you just drag and drop the bookmark file into the browser, and it opens automatically</p>
</li>
<li>
<p>Want to change your main browser? No need to do anything, you just keep the bookmark files (no need to "export" anything, no need to install a browser extension to save the bookmarks and/or convert them to another format...)</p>
</li>
<li>
<p>Want to search among your thousands of bookmarks? Just use your OS's search among all .url files</p>
</li>
<li>
<p>Want to add tags to your bookmarks? Just rename the file <code>Super bookmarking system.url</code> into <code>Super bookmarking system #productivity.url</code> and later you can search your bookmarks with tags, example query in your favorite OS's file search tool: "bookmarking #productivity"</p>
</li>
<li>
<p>Want to do some data mining on your thousands of bookmarks? You can do it with any programming language, since a <code>.url</code> file is just that:</p>
<pre><code>[InternetShortcut]
URL=https://www.afewthingz.com/browserbookmark</code></pre>
</li>
</ul>
<p>That's it!</p>
<p>This has worked for decades with Firefox, Chrome, Internet Explorer, and probably others, at least on Windows.</p>
<p>Remarks:</p>
<ul>
<li>
<p>sadly, it doesn't work out of the box on Ubuntu + Firefox. Mozilla, please fix this :)</p>
</li>
<li>There has been a regression about this in recent versions of Firefox on Windows, you now have to modify your default Firefox shortcut to <code>firefox.exe -no-deelevate</code>. Please Mozilla, don't let this awesome feature die, this should work out of the box. It works on Chrome.</li>
</ul><p><a href="https://afewthingz.com/">← Other articles</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New research on anesthesia and microtubules gives new clues about consciousness (138 pts)]]></title>
            <link>https://www.sciencedaily.com/releases/2024/09/240905120923.htm</link>
            <guid>41696434</guid>
            <pubDate>Mon, 30 Sep 2024 12:34:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sciencedaily.com/releases/2024/09/240905120923.htm">https://www.sciencedaily.com/releases/2024/09/240905120923.htm</a>, See on <a href="https://news.ycombinator.com/item?id=41696434">Hacker News</a></p>
Couldn't get https://www.sciencedaily.com/releases/2024/09/240905120923.htm: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Phrase matching in Marginalia Search (153 pts)]]></title>
            <link>https://www.marginalia.nu/log/a_111_phrase_matching/</link>
            <guid>41696046</guid>
            <pubDate>Mon, 30 Sep 2024 11:42:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.marginalia.nu/log/a_111_phrase_matching/">https://www.marginalia.nu/log/a_111_phrase_matching/</a>, See on <a href="https://news.ycombinator.com/item?id=41696046">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><p>Marginalia Search now properly supports phrase matching. This not only permits a more robust implementation of quoted search queries, but also helps promote results where the search terms occur in the document exactly in the same order as they do in the query.</p><p>This is a write-up about implementing this change. This is going to be a relatively long post, as it represents about 4 months of work.</p><p>I’m also happy and grateful to announce that the nlnet people reached out after the run of <a href="https://www.marginalia.nu/log/a_107_nlnext">the grant</a> was over and asked me if I had more work in the pipe, and agreed to fund this change as well!</p><h2 id="the-old-design">The old design</h2><p>Previously the positions for each term in the documents were stored in an approximate fashion. 56 bits were assigned to each word, and each bit corresponded to a set of positions in the document, with a sentence-level granularity. This can be very loosely thought of like a bloom filter.</p><p>To deal with quoted search queries, the search engine would try to guess relevant word n-grams and store them in the index along with the rest of the keywords. “Steve Jobs” was simply stored as the keyword <em>steve_jobs</em>. It would be logistically impossible to store all word n-grams present in every document due to combinatoric explosion, so limiting heuristics were needed to identify which were likely to be important. This used both grammatical analysis and word lists like wikipedia titles.</p><p>This covered cases like “to be or not to be”, because it was such a well known sequence of words and identifiable as a word n-gram, for many queries these approaches worked adequately, but a number of cases cropped up where the approach did not work.</p><p>A good example comes from a friendly detractor on hacker news, who had discovered that the query [the vietnam of computer science] turned up nothing but vietnamese computer scientists, and nothing about the famous blog post “ORM is the vietnam of computer science”.</p><p>What the search engine did when it saw the query was first to remove stop words:</p><pre>   <s>the</s> vietnam <s>of</s> computer science
</pre><p>then it expanded the query with possible n-grams to help the query</p><pre>  vietnam, computer, science -&gt; computer_science
</pre><p>It’s seems pretty straightforward from this processing that it would indeed find computer scientists in Vietnam.</p><p>To adequately serve the query, exact positions were needed so we could get away from the word ngram guessing game and sentence-level position matching.</p><h2 id="representing-positions-lists">Representing positions lists</h2><p>Thankfully, this is well trodden ground in information retrieval, and the literal textbook solution is to just store a compressed list each position of a term in the document as a list of positive integers.</p><p>The positions themselves tend to be on average small, but the distribution is fairly wide and large values are a common sight. To give an intuition for this, I’m attaching some plots.</p><figure><a href="https://www.marginalia.nu/log/a_111_phrase_matching/pos-abs.png"><img src="https://www.marginalia.nu/log/a_111_phrase_matching/pos-abs.png" title="plot of the number of document positions for a given length"></a><figcaption>Plot of the number of document positions for a given length.</figcaption></figure><p>The data can be better behaved by calculating the difference between each position, to get a list of smaller numbers. The statistical distribution is still fairly diverse, but since words tend to either be common and appear in many sentences, or cluster up in a few sentences of a document, you get a lot of very small values when you look at the relative difference in position.</p><p>Plotting the difference between position values, we see the number of small values has drastically been increased. There is still a tail of larger values, but it tapers off much faster.</p><figure><a href="https://www.marginalia.nu/log/a_111_phrase_matching/pos-delta.png"><img src="https://www.marginalia.nu/log/a_111_phrase_matching/pos-delta.png" title="plot of relative distance between adjacent positions in a sample of positions lists"></a><figcaption>Plot of relative distance between adjacent positions in a sample of positions lists.</figcaption></figure><p>For compression of a list positive integers, several options are available. I initially implemented Elias gamma coding, which is a simple variable bit width code that is effective for very small numbers.</p><div><p><strong>Elias Gamma Code:</strong></p><p>In short, you count the significant bits in the number to be encoded, subtract one from that count, and then you prefix the number to be encoded with that many binary zeroes.</p><p><strong>Example:</strong> To encode the byte 56, or 0011'1000<sub>2</sub> in binary, note that there are 6 significant bits:</p><pre>   00<u>11'1000</u><sub>2</sub>
</pre><p>We prefix the significant bits with 6-1 = 5 binary zeroes</p><pre>   <u>000'00</u>11'1000<sub>2</sub>
</pre><p>And thus we’ve arrived at the 11 bit encoding of the number 56! Just mind that the leading zeroes are significant.</p></div><p>This is frequently used in combination with other techniques as part of a compression algorithm, but in our case since the data to be compressed was already a series of small positive numbers, Elias gamma seemed like a good choice as-is.</p><p>In terms of functionality, this worked very well, but later during performance testing it was found to not be quite performing well enough. Since the code is variable bit and not octet aligned, it’s always going to be a bit slow on modern hardware.</p><p>Plan B was to use varints instead. The varint coding scheme is also relatively easy to implement, and more importantly quite a lot more CPU-friendly.</p><div><p><strong>Varints:</strong></p><p>The flavor of varint encoding chosen uses the highest bit as a continuation flag. The value to be encoded is grouped into segments of 7 bits, and all the the least significant grouping of bits has its 8:th bit set as a continuation flag.</p><p><strong>Example:</strong> To represent the number 700 (0010'0101'1000<sub>2</sub>), we first break into groups of 7 bits</p><pre>  <s>0000'0</s>100<sub>2</sub>  (bits 10-7, padded to byte)
  <s>0</s>101'1000<sub>2</sub>  (bits 7-0, padded to byte)
</pre><p>Then set the highest one bit to signal continuation for all but the lowest byte</p><pre>  <u>1</u>000'0100<sub>2</sub>
  <u>0</u>101'1000<sub>2</sub>
</pre></div><p>There’s a large number of varint variants and relatives, but this is favorable for our use case as it favors decoding efficiency over encoding and deals well with the common case of just having a single small value to encode.</p><p>Since the statistical distribution of the data is strongly biased toward small numbers, that case can be broken out into its own if-statement when decoding the values. This is very branch predictor friendly and makes the code about 20% faster on real-world position data.</p><div><pre tabindex="0"><code data-lang="java"><span><span><span>byte</span> b <span>=</span> buffer<span>.</span><span>get</span><span>();</span>  
</span></span><span><span><span>if</span> <span>((</span>b <span>&amp;</span> 0x80<span>)</span> <span>==</span> 0<span>)</span> <span>{</span>  
</span></span><span><span>    <span>// this is the most common case
</span></span></span><span><span><span></span>    <span>return</span> b<span>;</span>  
</span></span><span><span><span>}</span>  
</span></span><span><span>
</span></span><span><span><span>// the case where there are multiple bytes:
</span></span></span><span><span><span></span><span>int</span> value <span>=</span> b <span>&amp;</span> 0x7F<span>;</span>  
</span></span><span><span><span>do</span> <span>{</span>  
</span></span><span><span>    b <span>=</span> buffer<span>.</span><span>get</span><span>();</span>  
</span></span><span><span>    value <span>=</span> <span>(</span>value <span>&lt;&lt;</span> 7<span>)</span> <span>|</span> <span>(</span>b <span>&amp;</span> 0x7F<span>);</span>  
</span></span><span><span><span>}</span> <span>while</span> <span>((</span>b <span>&amp;</span> 0x80<span>)</span> <span>!=</span> 0<span>);</span>  
</span></span><span><span>  
</span></span><span><span><span>return</span> value<span>;</span>
</span></span></code></pre></div><p>In many cases this type of micro-optimization would not see much actual impact, but this code is so hot it really does make a significant difference. Overall this is approximately twice as fast as the gamma code implementation, and half as fast as just reading the data from an array.</p><p>There are even faster vectorized implementations of varints (e.g. Lemire et al’s <a href="https://arxiv.org/abs/1709.08990">Stream VByte</a>), but I’ve been unable to get them to perform well in Java, largely due to inadequate access to the <a href="https://www.bazhenov.me/posts/rust-stream-vbyte-varint-decoding/">PSHUFB instruction</a>.</p><p>There are also reasons to expect Stream VByte may not perform well in this particular instance: The length of the lists follows via eyeball statistics an apparent pareto distribution that is heavily biased toward very short lists, average length is less than 4, and because of this looking at vector operations is likely not going to be as useful as it might seem.</p><figure><a href="https://www.marginalia.nu/log/a_111_phrase_matching/poslistlength.png"><img src="https://www.marginalia.nu/log/a_111_phrase_matching/poslistlength.png" alt="log-log graph of the distribution of positions lists lengths, showing a linear descending slope"></a><figcaption>Log log plot of the number of positions lists lengths for a given length. Outlier at 512 is because this is the maximum permissible length, longer lists are truncated.</figcaption></figure><h3 id="size-and-shape-of-the-coded-data">Size and shape of the coded data</h3><p>When switching to varint, a concern was that varints might use more disk space compared to the gamma code representation, but it turned out to largely be an even match.</p><p>The gamma coded data lost a lot of its lead due to each positions list being rounded up to be byte aligned as a whole, and varints actually have a size benefit when representing numbers in the 32-127 range, a somewhat common case in the data.</p><p>If we plot the output size as a function of input size, we can see the two schemes are a relatively even match throughout the most common magnitude of values under 1000.</p><figure><a href="https://www.marginalia.nu/log/a_111_phrase_matching/bitsizes.png"><img src="https://www.marginalia.nu/log/a_111_phrase_matching/bitsizes.png" alt="Graph of bit widths of the gamma and varint coding schemes as a function of the magnitude of the input, showing two lines crossing at a bit width of 5, with varint becoming more advantageous after that point"></a><figcaption>Number of bits in output as a function of number of bits in input for the gamma and varint codes</figcaption></figure><p>Even though the choice in coding scheme doesn’t seem to have an impact on the size of the position data, the position data does require additional disk space! About 85 GB per index partition, of which there are currently 9, so roundabout 700 GB in total.</p><p>It was possible to redeem this disk space usage by shrinking and compressing the priority index, see Appendix A.</p><h2 id="position-spans">Position spans</h2><p>In the old design, each keyword would have a number of bit flags associated with it, containing information about whether it for example appeared in the title or in a heading.</p><p>This is bit mask approach is again a fairly blunt tool, still useful in some areas, but since we’ve improved the position resolution by encoding positions lists, we also stand to benefit from a new approach for coding information about a individual occurrences of a word.</p><p>The solution is very similar to the positions list. For each field, we store a coded list of start and end positions.</p><p>The span data for an imaginary document may look like this:</p><table><thead><tr><th>Field</th><th>Positions</th></tr></thead><tbody><tr><td>Title</td><td>1,6</td></tr><tr><td>Heading</td><td>7,10,32,38,100,105</td></tr><tr><td>Nav</td><td>11,20</td></tr><tr><td>Code</td><td>50,72</td></tr><tr><td>Body</td><td>1,11,20,50,72,120</td></tr><tr><td>Ext link</td><td>170,210</td></tr></tbody></table><p>At this point the tools for representing lists of positions already exists, we just need to store a few more of them, with the added requirement that the size of the list is even, and the implied semantics that even positions are the starts of spans, and their succeeding odd position marks the end.</p><p>This data is stored in a separate file from the positions and will be an additional disk read, but since we’re always interested in all the data, we can consume all the data at once.</p><p>This turned out to be a very nice improvement that permits the search engine to index more of the documents.</p><p>Previously, without this degree of precision information, the search engine would discard information from e.g. code blocks, because it tended to be less useful. Now it can simply assign matches in code blocks a lower score, without outright discarding the data.</p><p>The search engine stores all the information of the document in one go, separating the actual contents of the document from a block of e.g. external link texts by a segment of empty positions to prevent phrase matching from happening across different fields.</p><p>This is different from how general-purpose search engines tend to work, and a concession to the needs of web search, where you’re virtually always interested in all the fields at once, and have an interest in budgeting the number of disk read instructions.</p><p>Intersecting term positions lists with these fields lists is relatively easy and performs very well due to the extreme cpu-friendliness of the operation.</p><p>In practice the intersection algorithm switches between a linear and a binary search depending on the length of the data.</p><h2 id="phrase-matching-and-ranking-factors">Phrase matching and ranking factors</h2><p>At this point, all the prerequisites are available to do phrase matching, but a few changes are still needed.</p><p>To make the most of phrase matching, stop words need to go. The stop word list was never very long in the first place, but turning “to be or not to be’ into ‘? be ? ? ? be?’ is not great. Indexing every word grows the index and increases the amount of data that needs to be fetched in many queries, but it really can’t be helped.</p><p>The ranking algorithm also needs fairly extensive modification and tuning.</p><p>Several new ranking factors are available with the change:</p><ul><li><p>The presence of the search query as a phrase in the document</p><p>We can apply negative offsets based on the position of each keyword in the query to the corresponding position lists from the document being ranked, and if we find any case where these offset positions list overlap, we have a phrase match!</p><p>We can also use these positions matches and intersect them with the field data, to lift information about <em>where</em> in the document the match is, whether it’s in the title or a heading, or in a navigational element?</p><p>This is a bit of a liability for a flavor of SEO spam called query sniping, where a document is crafted to specifically contain a query, and have it rank well because of its verbatim match.</p></li><li><p>The minimum distance between the keywords in the query in the document</p><p>Finding the smallest distance between two items in a pair of lists is relatively trivial, but extending this to cover an arbitrary number of lists this turned out to be a surprisingly difficult calculation that was fairly resistant to optimization of the algorithm.</p><p>The trick that still permitted this to still be used turned out to be to attack the input data instead, and to omit positions lists if they were too long from the calculations, effectively excluding frequently occurring words from the calculations. This appears to have small impact on the quality of the ranking signal, as the omitted words tends to appear all over the document and don’t add a lot of information.</p></li><li><p>The distance in the document before you’ve seen all keywords once</p><p>Early occurrences are generally a good thing, although this is a secondary signal at best and should not be dialed up very high, as there are many examples of documents where a sentence appears early, despite being a somewhat mediocre search result.</p></li></ul><p>There are also the old factors, such as two versions of BM25, and even some lingering word ngram data. Putting all of this together and making it work well is a lot of tuning, and it’s a pretty protracted process of manual adjustments.</p><p>It seems to be in relatively good place now, but there’s always more adjustments to be done.</p><p>All the ranking factors can be explored using the <a href="https://search.marginalia.nu/qdebug?q=platonic+solid">qdebug utility</a>, which is a tool I built to diagnose ranking problems. It’s very much a debug tool and not very user friendly, but I’m including a link mostly to highlight that this article is very much skimming the surface.</p><h2 id="conclusion">Conclusion</h2><p>This has been a relatively a large change. The PR consisted of over 200 commits, with a delta of nearly 20,000 lines of code changed, owing to the fact that this breaks binary compatibility for the index and hasn’t been possible to merge until it’s all done.</p><p>Overall it’s been a success. There are queries that the search engine can answer now that it could not answer before this work, and many queries that were decent before perform better now.</p><p>There’s always some element of gamble when making a change like this, you don’t know how well it will work until it’s live in production, after one or more months of work.</p><p>The feedback cycle in web search engine development is very long, probably longer than anything I’ve ever encountered in programming. Rebuilding the index in the test environment, which has about 10% the data of production, took 2.5 days. It was possible to get that down to 1.5 days toward the end of this process, but it’s still very long, and even still no tests or test environments can quite do production justice.</p><p>Overall the approach taken to improving search result quality is looking at a query that does not give good results, asking what needs to change for that to improve, and then making that change. Sometimes it’s a small improvement, sometimes it’s a huge game changer. But it does seem like a solid vehicle for moving the search result quality in the right direction.</p><h2 id="appendix-a-shrinking-the-priority-index">Appendix A: Shrinking the priority index</h2><p>The search engine uses two indexes, a full index that, as it says on the box, indexes everything. It contains a mapping from keywords to a record with a document id, some document metadata, and a pointer into the positions file.</p><p>The search engine also has a priority index, which only contains documents that are in one way or another seems strongly related a keyword. Maybe it appears in the title, or an inbound link text, or some other relevance signal.</p><p>The priority index exists to help the search engine find the most relevant items first, as queries execute on a timer, and will terminate the search after a configurable time limit has passed and return the best of what’s been dug up so far.</p><p>To keep things simple, the priority index was built using the same code as the full index, meaning it would store redundant information, and also contain structures supporting operations like fast intersection with other documents lists.</p><p>What the index was actually used for though was just to iterate through the document id:s from start to finish for each keyword.</p><p>Originally the priority index was about 175 GB, but removing the metadata and additional indexing structures from the file, leaving it just an uncompressed list of document ids, brought the size down to 85 GB.</p><p>This already redeems the cost of adding positions data, but at this point I was curious to see how much smaller it could get if I compressed the ids. Trouble is that since these ids are constructed by concatenating different components, they have a really nasty statistical distribution that does not favor basic difference-coding schemes.</p><p>There’s a longer rationale behind these constructed id:s in the post <a href="https://www.marginalia.nu/log/87_absurd_success/">Absurd Success</a>, but in short they’re constructed to allow intelligent re-use of id:s to keep the document ids in a 64 bit long.</p><p>The document id construction scheme looks like this:</p><table><thead><tr><th>bits</th><th>purpose</th><th></th></tr></thead><tbody><tr><td>0-26</td><td>document ordinal</td><td>unique within document id, not<br>persistent over time</td></tr><tr><td>26-56</td><td>domain id</td><td>id of the domain</td></tr><tr><td>56-63</td><td>ranking component</td><td>used to change the order of<br>domains in the index so that<br>important ones appear earlier</td></tr></tbody></table><p>This gives the difference between subsequent document id:s has a statistical distribution with 3 modes:</p><ul><li>Bits 0-26 change by a small amount</li><li>Bits 25-56 change by a small amount, bits 0-26 change unpredictably</li><li>Bits 56-63 change by a small amount, bits 0-56 change unpredictably</li></ul><figure><a href="https://www.marginalia.nu/log/a_111_phrase_matching/docidhisto.png"><img src="https://www.marginalia.nu/log/a_111_phrase_matching/docidhisto.png" alt="A histogram of the magnitude of difference between adjacent document ids, showing three modes"></a><figcaption>A histogram of the magnitude of difference between adjacent document ids in a priority document list</figcaption></figure><p>The first mode is by far the most common, and benefits from something like the Elias gamma code, whereas the second and third modes are so large as to behave very poorly under such a scheme.</p><p>I ended up constructing a compression scheme for this by hand.</p><p>First a code is specified using two bits, then an unspecified number of bits is consumed to increment the document id. Each code is designed to cater to the modes mentioned before, and a fourth case is added to bootstrap the initial value of the list.</p><p>Expressed in terms of decoding:</p><p>The case when code=0:</p><ul><li>ordinal += read Elias gamma coded value</li></ul><p>The case when code=1:</p><ul><li>ordinal = 1 + read Elias delta coded value</li><li>domain += read Elias delta coded value</li></ul><p>The case when code=2:</p><ul><li>rank += read Elias gamma coded value</li><li>domain = read uncompressed value</li><li>ordinal = read uncompressed value</li></ul><p>The case when code=3:</p><ul><li>read uncompressed document id</li></ul><p>Here Elias delta is a coding scheme similar to Elias gamma, but favors slightly larger values.</p><div><p><strong>Elias Delta Code:</strong></p><p>The Elias Delta code is similar to the gamma code, except instead of using base 1 to code the bit width, you use the Gamma code.</p><p><strong>Example:</strong> To encode the byte 56, or 0011'1000<sub>2</sub> in binary, note that there are 6 significant bits:</p><pre>   00<u>11'1000</u><sub>2</sub>
</pre><p>Gamma code the number of significant bits - 1:</p><pre>  gamma(6-1) = gamma(101<sub>2</sub>) = <u>00</u>101<sub>2</sub>.
</pre><p>Prefix the significant bits of 56, 11'1000<sub>2</sub>, with gamma(6-1)</p><pre>   <u>001'01</u>11'1000<sub>2</sub>
</pre><p>And thus we’ve arrived at the 10 bit encoding of the number 56!</p></div><figure><a href="https://www.marginalia.nu/log/a_111_phrase_matching/bitsizes2.png"><img src="https://www.marginalia.nu/log/a_111_phrase_matching/bitsizes2.png" alt="Graph of bit widths of the gamma, delta and varint coding schemes as a function of the magnitude of the input"></a><figcaption>Number of bits in output as a function of number of bits in input for the gamma, delta and varint codes</figcaption></figure><h3 id="outcome">Outcome</h3><p>This was remarkably efficient. The compressed index is just 10 GB, down from the initial size of 175 GB, before irrelevant metadata was removed, indexes cleaned out, and any compression applied.</p><p>This result is better than zstd compression (25 GB), which isn’t a huge surprise since custom compression schemes can often outperform general purpose algorithms when you have misbehaving data with strong human-understandable idiosyncrasies like in this case.</p><p>Compressing the full index is significantly more complicated, but likely something I’ll look into in the future (though it will mean another very large re-write…)</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Live stream of VC funded startups (177 pts)]]></title>
            <link>https://old.reddit.com/r/DigitalMarketingHack/comments/1fssxk0/i_created_a_tool_which_tracks_all_vc_funding/</link>
            <guid>41696005</guid>
            <pubDate>Mon, 30 Sep 2024 11:37:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/DigitalMarketingHack/comments/1fssxk0/i_created_a_tool_which_tracks_all_vc_funding/">https://old.reddit.com/r/DigitalMarketingHack/comments/1fssxk0/i_created_a_tool_which_tracks_all_vc_funding/</a>, See on <a href="https://news.ycombinator.com/item?id=41696005">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="searchexpando"><p><label>limit my search to r/DigitalMarketingHack</label></p><div id="moresearchinfo"><p>use the following search parameters to narrow your results:</p><dl><dt>subreddit:<i>subreddit</i></dt><dd>find submissions in "subreddit"</dd><dt>author:<i>username</i></dt><dd>find submissions by "username"</dd><dt>site:<i>example.com</i></dt><dd>find submissions from "example.com"</dd><dt>url:<i>text</i></dt><dd>search for "text" in url</dd><dt>selftext:<i>text</i></dt><dd>search for "text" in self post contents</dd><dt>self:yes (or self:no)</dt><dd>include (or exclude) self posts</dd><dt>nsfw:yes (or nsfw:no)</dt><dd>include (or exclude) results marked as NSFW</dd></dl><p>e.g. <code>subreddit:aww site:imgur.com dog</code></p><p><a href="https://www.reddit.com/wiki/search">see the search faq for details.</a></p></div><p><a href="https://www.reddit.com/wiki/search" id="search_showmore">advanced search: by author, subreddit...</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Screenpipe: 24/7 local AI screen and mic recording (195 pts)]]></title>
            <link>https://github.com/mediar-ai/screenpipe</link>
            <guid>41695840</guid>
            <pubDate>Mon, 30 Sep 2024 11:15:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/mediar-ai/screenpipe">https://github.com/mediar-ai/screenpipe</a>, See on <a href="https://news.ycombinator.com/item?id=41695840">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
   <a href="https://screenpi.pe/" rel="nofollow">
      <img src="https://private-user-images.githubusercontent.com/25003283/357953213-d3b1de26-c3c0-4c84-b9c4-b03213b97a30.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjc3MTQxMDIsIm5iZiI6MTcyNzcxMzgwMiwicGF0aCI6Ii8yNTAwMzI4My8zNTc5NTMyMTMtZDNiMWRlMjYtYzNjMC00Yzg0LWI5YzQtYjAzMjEzYjk3YTMwLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MzAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTMwVDE2MzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQzOWE1NDgyOGM2NjFlNGE5MDIxZGJjNjIwODJlNjMyYjU0NzZkZTJhNjBlMDU1NjFiYzFiZjkxM2NhNzM5YmImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.xUhg9zj5XjeDrqwZufWSzJl3YFR-1tWgh_VHcG_XZHY" alt="logo" width="200" secured-asset-link="">
   </a>
</p>
<pre>   ___  ___ _ __ ___  ___ _ __  _ __ (_)_ __   ___ 
  / __|/ __| '__/ _ \/ _ \ '_ \| '_ \| | '_ \ / _ \
  \__ \ (__| | |  __/  __/ | | | |_) | | |_) |  __/
  |___/\___|_|  \___|\___|_| |_| .__/|_| .__/ \___|
                               |_|     |_|         
</pre>
<p dir="auto">
    <a href="https://screenpi.pe/" rel="nofollow">
        <img src="https://camo.githubusercontent.com/83a346e54d1244dba29dc23f4419a6750f2ee726d524c8912f6ce97411141099/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f776e6c6f61642532305468652d4465736b746f702532304170702d626c75653f7374796c653d666f722d7468652d6261646765" alt="Download the Desktop App" data-canonical-src="https://img.shields.io/badge/Download%20The-Desktop%20App-blue?style=for-the-badge">
    </a>
</p>
<p dir="auto">
    <a href="https://www.youtube.com/@mediar_ai" rel="nofollow">
        <img src="https://camo.githubusercontent.com/f64d2cd4f638377a768b47026a57c006f76fe469e31b87dcd221f721ceddcba5/68747470733a2f2f696d672e736869656c64732e696f2f656e64706f696e743f7374796c653d666f722d7468652d62616467652675726c3d6874747073253341253246253246796f75747562652d6368616e6e656c2d62616467652e6e676f6c6461636b2e76657263656c2e61707025324661706925324673756273637269626572" alt="Subs" data-canonical-src="https://img.shields.io/endpoint?style=for-the-badge&amp;url=https%3A%2F%2Fyoutube-channel-badge.ngoldack.vercel.app%2Fapi%2Fsubscriber">
    </a>
</p>
<p dir="auto">
    <a href="https://discord.gg/dU9EBuw7Uq" rel="nofollow">
        <img src="https://camo.githubusercontent.com/a0d96960e0025d2bba43e338ce9037ae33c2c86558d9595d799d9d26d735470a/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f3832333831333135393539323030313533373f636f6c6f723d353836354632266c6f676f3d646973636f7264266c6f676f436f6c6f723d7768697465267374796c653d666c61742d737175617265" alt="Join us on Discord" data-canonical-src="https://img.shields.io/discord/823813159592001537?color=5865F2&amp;logo=discord&amp;logoColor=white&amp;style=flat-square">
    </a>
        <a href="https://twitter.com/screen_pipe" rel="nofollow"><img alt="X account" src="https://camo.githubusercontent.com/4c0969bb945df274715bf7b95790e6fec4e8ae638f354f12e5a56c98c7724a17/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f75726c2f68747470732f747769747465722e636f6d2f6469666675736572736c69622e7376673f7374796c653d736f6369616c266c6162656c3d466f6c6c6f7725323025343073637265656e5f70697065" data-canonical-src="https://img.shields.io/twitter/url/https/twitter.com/diffuserslib.svg?style=social&amp;label=Follow%20%40screen_pipe"></a>
</p>
<p dir="auto">
  <a href="https://cal.com/louis030195/screenpipe" rel="nofollow">
    <img alt="Let's chat" src="https://camo.githubusercontent.com/298517cca77af25bc85b9663f5f3981400cbfff904619bffae30dae85f45d5a5/68747470733a2f2f63616c2e636f6d2f626f6f6b2d776974682d63616c2d6461726b2e737667" data-canonical-src="https://cal.com/book-with-cal-dark.svg">
  </a>
</p><p dir="auto">
   <a href="https://screenpi.pe/" rel="nofollow">
       <img alt="demo" src="https://private-user-images.githubusercontent.com/25003283/357733866-39d27adc-e17e-4ca5-89c5-faf45a3ea20f.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjc3MTQxMDIsIm5iZiI6MTcyNzcxMzgwMiwicGF0aCI6Ii8yNTAwMzI4My8zNTc3MzM4NjYtMzlkMjdhZGMtZTE3ZS00Y2E1LTg5YzUtZmFmNDVhM2VhMjBmLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MzAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTMwVDE2MzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWI4YjQzMjEyODE3Mjc2Y2VjYjc1NWYwMDRjODI1MGRkZTk0NTMxMTUyMzg0YjMzNTg5M2YxOGZlMzM2NjVhNTUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.2k5rZx9Cpiq0N-VkpZxOOiQ7Tp3RaNEwikYJGDwiPTg" width="800" secured-asset-link="" data-animated-image="">
   </a>
</p>
<hr>
<p dir="auto"><em>Latest News</em> 🔥</p>
<ul dir="auto">
<li>[2024/09] 70 users run screenpipe 24/7!</li>
<li>[2024/09] Released a v0 of our <a href="https://docs.screenpi.pe/" rel="nofollow">documentation</a></li>
<li>[2024/08] Anyone can now <a href="https://youtu.be/iCqHgZgQHyA?si=DjKJir7HfZoQKItK" rel="nofollow">create, share, install pipes</a> (plugins) from the app interface based on a github repo/dir</li>
<li>[2024/08] We're running bounties! Contribute to screenpipe &amp; make money, <a href="https://github.com/mediar-ai/screenpipe/issues">check issues</a></li>
<li>[2024/08] Audio input &amp; output now works perfect on Windows, Linux, MacOS (&lt;15.0). We also support multi monitor capture and defaulting STT to Whisper Distil large v3</li>
<li>[2024/08] We released video embedding. AI gives you links to your video recording in the chat!</li>
<li>[2024/08] We released the pipe store! Create, share, use plugins that get you the most out of your data in less than 30s, even if you are not technical.</li>
<li>[2024/08] We released Apple &amp; Windows Native OCR.</li>
<li>[2024/08] <strong>The Linux desktop app is here!</strong>.</li>
<li>[2024/07] <strong>The Windows desktop app is here! <a href="https://screenpi.pe/" rel="nofollow">Get it now!</a></strong>.</li>
<li>[2024/07] 🎁 Screenpipe won Friends (the AI necklace) hackathon at AGI House (integrations soon)</li>
<li>[2024/07] <strong>We just launched the desktop app! <a href="https://screenpi.pe/" rel="nofollow">Download now!</a></strong></li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">24/7 Screen &amp; Audio Capture</h2><a id="user-content-247-screen--audio-capture" aria-label="Permalink: 24/7 Screen &amp; Audio Capture" href="#247-screen--audio-capture"></a></p>
<p dir="auto">Library to build personalized AI powered by what you've seen, said, or heard. Works with Ollama. Alternative to Rewind.ai. Open. Secure. You own your data. Rust.<br>
We are shipping daily, make suggestions, post bugs, <a href="mailto:louis@screenpi.pe?subject=Screenpipe%20Feedback&amp;body=I'd%20like%20to%20use%20Screenpipe%20for%20...%0D%0A%0D%0AI%20cannot%20because%20of%20...%0D%0A%0D%0AWe%20can%20also%20have%20a%20call,%20book%20at%20https://cal.com/louis030195/screenpipe">give feedback</a>.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/mediar-ai/screenpipe/blob/main/content/diagram2.png"><img src="https://github.com/mediar-ai/screenpipe/raw/main/content/diagram2.png" alt="diagram"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why?</h2><a id="user-content-why" aria-label="Permalink: Why?" href="#why"></a></p>
<p dir="auto">Building a reliable stream of audio and screenshot data, where a user simply clicks a button and the script runs in the background 24/7, collecting and extracting data from screen and audio input/output, can be frustrating.</p>
<p dir="auto">There are numerous use cases that can be built on top of this layer. To simplify life for other developers, we decided to solve this non-trivial problem. It's still in its early stages, but it works end-to-end. We're working on this full-time and would love to hear your feedback and suggestions.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Get started</h2><a id="user-content-get-started" aria-label="Permalink: Get started" href="#get-started"></a></p>
<p dir="auto">There are multiple ways to install screenpipe:</p>
<ul dir="auto">
<li>as a CLI for technical users</li>
<li>as a <a href="https://screenpi.pe/onboarding" rel="nofollow">paid desktop app</a> with 1 year updates, priority support, and priority features</li>
<li>as a free forever desktop app (but you need to build it yourself). We're 100% OSS.</li>
<li>as a free forever desktop app - by sending a PR (<a href="https://github.com/mediar-ai/screenpipe/issues/120#issuecomment-2275043418" data-hovercard-type="issue" data-hovercard-url="/mediar-ai/screenpipe/issues/120/hovercard">example</a>) or <a href="https://screenpi.pe/onboarding/free-community" rel="nofollow">sharing about screenpipe online</a></li>
<li>as a Rust or WASM library - check this <a href="https://github.com/mediar-ai/screenpipe/blob/main/screenpipe-vision/examples/websocket.rs">websocket</a> to stream frames + OCR to your app</li>
<li><a href="https://cal.com/louis030195/screenpipe-for-businesses" rel="nofollow">as a business</a></li>
</ul>
<p dir="auto"><a href="https://docs.screenpi.pe/docs/getting-started" rel="nofollow"><strong>👉 install screenpipe now</strong></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">usage</h2><a id="user-content-usage" aria-label="Permalink: usage" href="#usage"></a></p>
<p dir="auto">screenpipe has a plugin system called "pipe" which lets you run code in a sandboxed environment within the Rust code, <a href="https://docs.screenpi.pe/docs/plugins" rel="nofollow">get started</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">examples</h2><a id="user-content-examples" aria-label="Permalink: examples" href="#examples"></a></p>
<p dir="auto"><a href="https://docs.screenpi.pe/docs/examples" rel="nofollow">check examples</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">star history</h2><a id="user-content-star-history" aria-label="Permalink: star history" href="#star-history"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/25003283/371910965-6bb3f559-5016-4e1c-a91e-563ce89cd855.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjc3MTQxMDIsIm5iZiI6MTcyNzcxMzgwMiwicGF0aCI6Ii8yNTAwMzI4My8zNzE5MTA5NjUtNmJiM2Y1NTktNTAxNi00ZTFjLWE5MWUtNTYzY2U4OWNkODU1LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MzAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTMwVDE2MzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWJkMzgzMjBlNGM2NzI2MDQyM2NiODkzYzYxNTBkZjBhODhhN2M1ODNlYjg2MTJjNTBjNmVhN2U3NDBkZmEzMGMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.mDd96eIfbi3kQAlC1OKpV3bUjHRFewwWX3XiXffL4Uw"><img src="https://private-user-images.githubusercontent.com/25003283/371910965-6bb3f559-5016-4e1c-a91e-563ce89cd855.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjc3MTQxMDIsIm5iZiI6MTcyNzcxMzgwMiwicGF0aCI6Ii8yNTAwMzI4My8zNzE5MTA5NjUtNmJiM2Y1NTktNTAxNi00ZTFjLWE5MWUtNTYzY2U4OWNkODU1LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MzAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTMwVDE2MzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWJkMzgzMjBlNGM2NzI2MDQyM2NiODkzYzYxNTBkZjBhODhhN2M1ODNlYjg2MTJjNTBjNmVhN2U3NDBkZmEzMGMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.mDd96eIfbi3kQAlC1OKpV3bUjHRFewwWX3XiXffL4Uw" alt="GitHub Star History (3)"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Contributions are welcome! If you'd like to contribute, please read <a href="https://github.com/mediar-ai/screenpipe/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: A macOS app to prevent sound quality degradation on AirPods (154 pts)]]></title>
            <link>https://apps.apple.com/us/app/crystalclear-sound/id6695723746?mt=12</link>
            <guid>41695756</guid>
            <pubDate>Mon, 30 Sep 2024 11:03:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apps.apple.com/us/app/crystalclear-sound/id6695723746?mt=12">https://apps.apple.com/us/app/crystalclear-sound/id6695723746?mt=12</a>, See on <a href="https://news.ycombinator.com/item?id=41695756">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="" data-test-bidi=""><p>AirPods are on, playing a song on Mac and tried to Shazam. What did you notice? The sound went and came back at much lower quality, right? This app is here to solve it</p><p>AirPods are great, but if you have a recent MacBook it means you probably have studio-quality microphones at your disposal(recent Macbook microphones are THAT good), or you might connect an external one, which you would prefer over any microphone on earphones or headphones.  It's just physics.</p><p>Use CrystalClear audio to effortlessly and automatically switch to the internal Mac microphones or the external microphones you connect to achieve the best possible sound quality when you speak.&nbsp;</p><p>Even if you're not using the mic, connecting wireless headphones or earphones with microphones can degrade your listening experience by activating the microphone, such as when you're trying to Shazam that amazing song.</p><p>Since recently Shazam is built in into macOS and you can access it from the menubar to find songs, even with your AirPods on. It's fantastic, you should use it all the time.<br>Give it a try, put on your AirPods,  play a song on your Mac and then try to Shazam from the Mac menu bar. What did you notice? The sound was lost for a moment and then came back at much lower quality, right? This is because the bluetooth mic on your headset was activated.&nbsp;The same will happen with any app which uses the microphone.<br>CrystalClear Sound is solving this by automatically picking the internal microphone and prevents this unnecessary activation and if you need to use the bluetooth mic you can quickly switch microphones by changing the mode.</p><p>CrystalClear Sound requires a paid subscription(a rather cheap one), which supports the development of the app.<br>It comes with a 1-month FREE trial period.&nbsp;Give it a try,  keep it if you like it or cancel any time.</p><p>EULA:  https://github.com/mrtksn/CrystalClearSound/blob/main/EULA.md<br>Privacy Policy: https://github.com/mrtksn/CrystalClearSound/blob/main/privacyPolicy.md</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FFmpeg 7.1 release: a tons of codecs (156 pts)]]></title>
            <link>https://jbkempf.com/blog/2024/ffmpeg-7.1.0/</link>
            <guid>41695025</guid>
            <pubDate>Mon, 30 Sep 2024 09:05:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jbkempf.com/blog/2024/ffmpeg-7.1.0/">https://jbkempf.com/blog/2024/ffmpeg-7.1.0/</a>, See on <a href="https://news.ycombinator.com/item?id=41695025">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
          <div>
            <h2 id="ffmpeg-71">FFmpeg 7.1</h2>
<p><strong>FFmpeg 7.1</strong> has been <a href="https://git.ffmpeg.org/gitweb/ffmpeg.git/tag/refs/tags/n7.1">released today</a>: a major release with numerous features that nevertheless maintains API compatibility with 7.0.<br>
It has a full native VVC decoder, a new MV-HEVC decoder, a new LC-EVC decoder, a new xHE-AAC decoder, it finishes the IAMF decoder and it also adds Vulkan hardware encoding, VVC encoding, ARM64 and RISC-V optimizations and other hardware accelerations.</p>
<p>Knowing that <strong>FFmpeg 7.1</strong> is a LTS release, this is a major feat, in addition to the already very strong FFmpeg <strong>7.0</strong> release.</p>
<h2 id="vvc-decoder">VVC decoder</h2>
<p>We decided, a couple of years ago, to do our own <a href="https://en.wikipedia.org/wiki/Versatile_Video_Coding">VVC</a> decoder, instead of using the official <em>vvcdec</em> decoder.<br>
There are a tons of reasons to prefer native decoders inside FFmpeg, notably for better control of the codebase, but mostly because it allows sharing code between decoders, and this is especially true for the <em>VVC</em> decoder <em>(and other MPEG decoders)</em></p>
<p>The VVC decoder was a large project, notably done by <a href="https://summerofcode.withgoogle.com/">Google Summer of Code</a> students last year, and the main decoder landed in FFmpeg 7.0, but it was not complete, and was therefore marked as <em>experimental</em>.<br>
The continuation of the work, notably numerous extensions but also optimizations were implemented, which makes that now the decoder can decode DVB streams. This means that the decoder is now production ready in <strong>7.1!</strong>. Congratulations to the amazing VVC team, and mostly <em>Nuo Mi</em> and <em>Frank Plowman</em>.</p>
<p>This decoder shares some code with the H.264 and the HEVC decoders, which means that some assembly optimizations are shared or that most SEI parsing is shared <em>(for example, the H.274 Film Grain should work with VVC)</em>.</p>
<p>Finally, the VVC decoder is already fast on ARM and on x86, with new optimizations written, and the reuse of the optimizations from the previous decoders!</p>
<h3 id="more-vvc">More VVC</h3>
<p>In addition to the decoder, the <strong>vvcenc</strong> encoder is now available in FFmpeg, through the external library, so you should be able to encode directly in VVC in FFmpeg.</p>
<p>Finally, the <em>Intel</em> folks have added VVC hardware decoding through <strong>QSV</strong>.</p>
<h2 id="lc-evc-mv-hevc">LC-EVC, MV-HEVC</h2>
<p>On the MPEG side, two new codecs were added to the codebase: <strong>MV-HEVC</strong> and <strong>LC-EVC</strong>.</p>
<p>MV-HEVC is the 3D version of HEVC, that is used in recent iPhones and in the Apple Vision Pro.<br>
While technically, it’s not a new codec, but an extension of a codec, adding this to the codebase required large refactoring of the HEVC decoder <em>(which got us to fix some longstanding HEVC bugs)</em> and it required new APIs to manage Multi-Views in FFmpeg.</p>
<p>Please note that <em>x265</em> should be able to encode in MV-HEVC now!</p>
<p>Very different from MV-HEVC, the <a href="https://en.wikipedia.org/wiki/LCEVC">LC-EVC</a> decoder was also added to this release too.<br>
LC-EVC is a layer enhancement codec, sponsored by <a href="https://www.v-nova.com/lcevc-enhanced-video/">V-Nova</a> and called <em>MPEG-5 Part 2</em>. It adds layers to a main codec, to allow to improve it: you can use LC-EVC with H.264, HEVC or AV1 base layers.</p>
<p>Adding this codec was quite complex for FFmpeg architecture, because we don’t have many enhancement codecs, and this made us leverage the Stream Groups concept that we’ve added also for IAMF. I expect that we see more of those type of codecs, in the future.</p>
<p>The <strong>LC-EVC</strong> decoder is now in FFmpeg, and it depends on an open-source external library, that is BSD-licensed!</p>
<p>Thanks <em>James</em> and <em>Anton</em> for those 2 decoders!</p>
<h2 id="xhe-aac-iamf">xHE-AAC, IAMF</h2>
<p><em>Lynne</em> spent a large part of her past year to work on a native <strong>xHE-AAC</strong> decoder.</p>
<p>Again, this required large preparatory work to prepare this new decoder. A lot of refactoring of the AAC decoder was necessary to support USAC and other features that got us this new xHE-AAC decoder.</p>
<p>As we’ve not seen many xHE-AAC streams in the wild, we’re not 100% sure of the compliance, but we’re sure it will improve when more samples are available.</p>
<p>On the other side of the spectrum, the <a href="https://aomedia.org/">AOM</a> <strong>IAMF</strong> decoder/demuxer, introduced in 7.0 got a lot of fixes and testing, so I’m now quite sure that the <strong>IAMF</strong> decoder is now production ready!</p>
<p>To finish on the audio side of things, support for <strong><a href="https://github.com/google/liblc3">LC3</a></strong>, the Low Complexity codec from Google, was also wired through the official external library.</p>
<h2 id="vulkan-hardware-encoding-and-other-hardware-news">Vulkan hardware encoding and other hardware news</h2>
<p>On of the other major feature of <strong>7.1</strong> done by <em>Lynne</em> is the support of encoding through <strong>Vulkan</strong>.<br>
I know, it feels like yet another hardware encoding library, but maybe this one will unify all the other ones, since it’s part of Vulkan standardisation.</p>
<p>FFmpeg now supports H.264 and HEVC encoding through Vulkan. AV1 will come soon, I hope. <em>(Vulkan decoding was done in 6.1)</em></p>
<p>We also now have a <strong>D3D12 encoding</strong> for HEVC, after we added D3D12 decoder <em>(Decoding of H.264, HEVC, AV1 and others were added in 7.0)</em>.</p>
<h3 id="misc">Misc</h3>
<p>I would also like to mention, as the maintainer of <a href="https://www.videolan.org/developers/libdvdnav.html">libdvdread</a>, that <strong>DVD</strong> seeking was added to FFmpeg <strong>7.1</strong>, which makes the DVD playback complete.</p>
<p>And finally, the <strong>YUVJ</strong> pixel format is officially deprecated!<br>
A method for YUV colorspace negotiation for codecs and filters was added in this release to fix this problem.<br>
The topic of YUVJ removal has been a recurring one for the last 5 years. I’m very happy that this is solved!</p>
<p>And like with <strong>dav1d</strong>, a large number of optimizations for <strong>ARM64</strong> and <strong>RISC-V</strong> were added to accelerate FFmpeg decoding on non-x86 platforms. Your mobiles will love it :)</p>
<h2 id="final-words-and-lts">Final words and LTS</h2>
<p>This is a very strong release, with a lot of important features and continuing the work that was started for <strong>7.0</strong>, which was a huge release because of the multi-threading development.<br>
I don’t recall an FFmpeg release with this many codecs added in a single release.</p>
<p>This release is more than 2700 commits, and the diff is around 211kLoC!<br>
Thanks so much to <em>Andreas, Michael, Anton, James, Rémi, Lynne, Niklas, Zhao, Nuo Mi, Ramiro, Marvin, Haihao</em> and <em>Martin</em>, who are our top contributors for this release!</p>
<p>As for me, I consider FFmpeg 7.1 an LTS release, like the 5.1 release, so it’s a good release to bet on!</p>
<p><strong>I hope you Enjoy this release!</strong></p>

          </div>
        </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Keep Track: 3D Satellite Toolkit (155 pts)]]></title>
            <link>https://app.keeptrack.space</link>
            <guid>41694712</guid>
            <pubDate>Mon, 30 Sep 2024 08:10:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://app.keeptrack.space">https://app.keeptrack.space</a>, See on <a href="https://news.ycombinator.com/item?id=41694712">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[How we built ngrok's data platform (149 pts)]]></title>
            <link>https://ngrok.com/blog-post/how-we-built-ngroks-data-platform</link>
            <guid>41694504</guid>
            <pubDate>Mon, 30 Sep 2024 07:35:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ngrok.com/blog-post/how-we-built-ngroks-data-platform">https://ngrok.com/blog-post/how-we-built-ngroks-data-platform</a>, See on <a href="https://news.ycombinator.com/item?id=41694504">Hacker News</a></p>
<div id="readability-page-1" class="page"><div fs-richtext-element="rich-text"><p>At ngrok, we manage an extensive data lake with an engineering team of one (me!).</p><p>This article is a look at how we built it, what we learned, as well as some selective deep dives I found interesting enough to be worth sharing in more detail, since they’ll bridge the gap between what people usually understand by the term “data engineering” and how we run data here at ngrok.</p><p>Some of this might even be useful (or, at the very least, interesting!) for your own data platform endeavors, whether your team is big or small.</p><h2>Data we store</h2><p>First of all, as an ngrok user, it's important to understand what data we store and what we use it for, especially when talking about building a data platform. I want to be as transparent and upfront as possible about this, since talking about storing and processing data will always raise valid privacy concerns.</p><p>My colleague Ari recently wrote in-depth about what <a href="https://ngrok.com/blog-post/data-at-ngrok">personal data of customers we store</a> and you can always find up to date compliance data in our <a href="https://trust.ngrok.com/">Trust Center</a>.</p><h3>What we store</h3><p>But to give you a more concise overview, we generally store and process:</p><ul role="list"><li>Data from our globally distributed Postgres instances, which contains customer data, such as account IDs, user to account mappings, certificates, domains and similar data.</li><li>Data from our metering and usage cluster which tracks the usage of resources.</li><li>Subscription and payment information (<em>excluding</em> credit card information).</li><li>Third-party data, such as support interactions from Zendesk.</li><li>Metadata about movement of events through the various components that make up ngrok's infrastructure.</li><li>Purpose-built product signals, also as real-time events (more on those two later!).</li></ul><p><strong>Note that we do not store any data about the traffic content flowing through your tunnels—we only ever look at metadata</strong>. While you have the ability to enable full capture mode of all <em>your</em> traffic and can <a href="https://ngrok.com/docs/obs/traffic-inspection/#full-capture-mode">opt in to</a> this service, we never store or analyze this data in our data platform. Instead, we use Clickhouse with a short data retention period in a completely separate platform and strong access controls to store this information and make it available to customers.</p><p>I hope this demystifies our data processing efforts a bit, so we can talk about the engineering side of things.</p><h2>Why data engineering is different at ngrok (and probably not what you think)</h2><p>We hired the first full time data person (it’s me!) in the summer of 2023. Before we filled that position, the data platform was set up by our CTO, Peter. Because of that, our data engineering (DE) team (or rather, our data role) is part of the Office of the CTO and effectively works horizontally across our engineering organization.</p><p>One artifact of having such a small team, our DE work is much closer aligned to holistic backend engineering work than the term "data engineering" often implies.&nbsp;</p><p>While I’m primarily responsible for the Data Platform and all associated services and tooling, I frequently find myself working on the actual ngrok products (as opposed to “just” the data lake). That includes architecture proposals and designs that span multiple teams and services and are mostly tangentially related to the “core” data work. And yes, I do write a fair bit of Go because of it.</p><p>As such, the majority of the data modeling work (i.e., SQL) is done by subject matter experts, which is very different to DE roles in many other organizations. In other words, I write very little SQL on a day to day basis and won’t usually be the person that writes a data model.&nbsp;&nbsp;</p><p>Within those subject matter experts, some people write reusable, well-structured dbt models, while other people focus on ad hoc analysis (based on these models) via our BI tooling in Superset. It’s worth noting that our entire organization has access to Superset and most data models and sources!</p><p>For instance, our growth team implements a huge amount of our actual data models and knows the business, product, and finance side much better than I do. They’re much better equipped to build sensible, complex, and maintainable data models that properly answer business questions.&nbsp;</p><p>In addition to that, we have a small-but-mighty infrastructure team that owns and operates our core infrastructure, such as Kubernetes, as well as the developer tools that are instrumental in keeping <em>every</em> engineering team (and, of course, ngrok itself!) running smoothly.</p><p>This particular setup—viewing DE as a very technical, general-purpose distributed system SWE discipline and making the people who know best what real-world scenarios they want to model—makes our setup work in practice.&nbsp;</p><h2>Our data platform architecture</h2><p>Now that you know how our (data) engineering org is structured, let’s talk about what we actually built and maintain and how it evolved over time.</p><p>ngrok as a product is a large, distributed, worldwide networking system with very high uptime guarantees, huge traffic volumes, and a large set of inherently eventually consistent (and often, ephemeral) data that can be difficult to interpret. Think about how a TCP connection works, and what steps are involved with making and routing it!</p><p>In other words, even our basic architecture was a bit more complex than “just copy your Postgres database somewhere to query it offline.”</p><h3>ngrok's data architecture in the past</h3><p>Despite that, our original architecture was utilitarian and relied more heavily on AWS tools than our contemporary architecture, which is very open-source focused.&nbsp;</p><p>Its primary goal was to get the most important data sets we needed—Postgres, important external data, as well as some events—to effectively run finance reporting, abuse, and support.</p><p>On the <strong>batch</strong> ingestion side, we used <a href="https://airbyte.com/">Airbyte</a> open source on Kubernetes to ingest third-party data via their respective APIs. We utilized the <a href="https://ngrok.com/docs/http/oauth/">ngrok OAuth module</a> to do authentication (as we do for all our open-source services that require an ingress controller).&nbsp;</p><p>Airbyte wrote JSON files, where we determined the schema with manual runs of a Glue parser and several Python scripts to create the target schemas, as well as another Glue job to write the target schema as Iceberg.</p><p>At the time, we did not have an orchestrator available and relied on Glue internal schedules. This meant we had no alerting or any integration with on-call tools.</p><p>We used AWS DMS here to get our core Postgres data, writing <code>parquet</code> data to S3. This was a once-a-day batch job.</p><p>On the <strong>streaming</strong> side, we streamed event metadata via <a href="https://aws.amazon.com/firehose/">AWS Firehose</a>, writing JSON data to 2 different S3 locations.</p><figure><p><img src="https://cdn.prod.website-files.com/63ed707844acb1ccf1ccb700/66f5ad4d164a1823bfd96722_AD_4nXfYyBtcqFhu7pqpNygGwL3lAUmYOmSD_hHRwR8oHKL2XehTo_cQ2R2-C-a1LRGuAOrLSqZXWPORD-y9K445_E7XQmd6H5pMH141Y-Er0qLnz4SqOmlclRwcDNbwWlYMBsk4IbNyokm2-2BkFLBqMk_UEeI.png" loading="lazy" alt=""></p></figure><p>For <strong>analytics</strong>, all our data was (and still is) eventually stored as <a href="https://iceberg.apache.org/">Apache Iceberg</a> and generally queried via AWS Athena, although the legacy architecture did have some datasets that were based on raw JSON in the mix. We used AWS Glue as a meta store.</p><p>Our SQL models were actually SQL <em>views</em> directly in Athena, with no version control or lineage, that were directly created in production and queried via <a href="https://preset.io/">Preset</a> (which is the managed cloud version of Superset).</p><h3>Expensive queries and unreasonable models</h3><p>Our eventing system, which is core to understand system behavior, relied on a very pricy AWS Firehose pipeline, as the way we split and organized events required us to both write JSON data (creating hundreds of TiB of data), as well as maintain data platform specific Go code in otherwise purely customer facing services (see the later section on <a href="https://ngrok.com/blog-post/how-we-built-ngroks-data-platform#scaling-apache-flink-scala-and-protobuf-to-650-gbday">Apache Flink, Scala, and Protobuf</a>).&nbsp;</p><p>Some of the data became straight up <strong>impossible to query</strong> (or very expensive), as queries would time-out despite tuning with partitions and other tricks. The entire system was on borrowed time from the start.&nbsp;</p><p>It was also hard to impossible to reason about our models, since we lacked any of dbt‘s (or a comparable tool's) creature comforts, such as lineage, documentation, version control, auditing, tests, and so on.</p><p>Without expecting you to be able to grok the details here, imagine getting asked why a certain field looks suspicious (if not to say, wrong), at the very end of this lineage tree:</p><figure><p><img src="https://cdn.prod.website-files.com/63ed707844acb1ccf1ccb700/66f5d7ac250e4813d857a27f_66f5d7a54f68c947eb236d78_fry-lineage-tree(1).png" loading="lazy" alt=""></p></figure><p>…without having this lineage tree available, of course.</p><p>On a similar vein, not having a central orchestrator, alerting, and auditing for our data jobs was an operational challenge (you can learn more about how we solved those two issues <a href="https://ngrok.com/blog-post/how-ngrok-uses-dagster-to-run-our-data-platform">here</a>).</p><p>Our data stack was also not integrated very deeply in our Go monorepo and tooling, missing things like Datadog monitors and metrics, good test coverage, or style guides and enforcements via CI (see the <a href="#collaborating-on-data-and-infra-in-a-go-monorepo">Working in a go monorepo</a> section).</p><p>Lastly (at least for the scope of this article), Airbyte and Glue have been a challenge to get right, but we’ll tell you how we did a few <a href="#wrestling-schemas-and-structs-between-airbyte-and-glue">sections from now</a>.</p><h3>ngrok's data architecture now</h3><p>Our modern data platform is more heavily based around open-source tools we self-host on Kubernetes, dogfooding ngrok, with some AWS native tools in the mix.</p><p>To solve these challenges, a simplified, contemporary view of our current architecture looks like this.</p><figure><p><img src="https://cdn.prod.website-files.com/63ed707844acb1ccf1ccb700/66f5b443bca0929628977694_AD_4nXeesX1V23GIlojpvnKKGgezRvIO8obStqkECKBYFnORDls08RPlz51sBerc0szjpeEGcrkKIvQaRVxwsxKSX6BwEyEJ1tp8NK4xTSton0K8tnFTbtr-7JdWJVcxKLmU2jaiLSrmM5h6VdUc4nxeMg1H3EqS.png" loading="lazy" alt=""></p></figure><p>All our <strong>batch</strong> ingestion is now run and orchestrated via Dagster, which I’ve <a href="https://ngrok.com/blog-post/how-ngrok-uses-dagster-to-run-our-data-platform">written about previously</a>. We still use <a href="https://airbyte.com/">Airbyte</a> and still use ngrok to do so, but write directly to Glue and maintain our schemas as Terraform by querying the Glue API.</p><p>For <strong>streaming</strong> data (which is where most of our volume and complexity comes from), we now run <a href="https://flink.apache.org/">Apache Flink</a> to consume Protobuf messages directly from Kafka, rather than rely on Firehose and internal services. We’ll also cover this in more detail in a bit.</p><p>Our database ingestion is still using DMS, but now mostly relies on streaming writes, which are faster and more efficient (when responding to a support request, you don’t want yesterday’s data!).</p><p>For <strong>analytics</strong>, we heavily rely on dbt now, as well as self-host the open-source version of <a href="https://superset.apache.org/">Apache Superset</a>. We also added a hosted version of the <a href="https://docs.getdbt.com/docs/build/documentation">dbt docs</a>, of course also dogfooded behind an ngrok endpoint.</p><h2>Technical deep-dives and problem-solving</h2><p>While we cannot get into <em>all</em> the details of all the challenges we solved in the past 12 or so months, here are some challenges I found especially interesting as a software engineer.</p><h3>Collaborating on data and infra in a Go monorepo</h3><p>Most of ngrok's code base is written in Go and exists in a monorepo. We run <a href="https://bazel.build/">Bazel</a> for build tooling, as well as Nix as a package manager. This allows us to have reproducible developer environments, as well as reasonably fast compile, build, and by proxy, CI times.</p><p>As most of our data infrastructure exists in Python and Scala, we had to adapt our workflow to this environment, as it is important to us to integrate the data environment with the rest of the engineering organization at ngrok.&nbsp;</p><p>Speaking from experience, having a completely separate data engineering team or department will eventually result in a fragmented engineering environment, with many bespoke paths that are not applicable to all team members, usually causing huge support and maintenance burdens on individual teams (e.g., maintaining two or more iterations of a CI/CD system).</p><p>Having one deployment system all engineers use is much easier and can be maintained by one infrastructure team:</p><figure><p><img src="https://cdn.prod.website-files.com/63ed707844acb1ccf1ccb700/66f5b45c4af04a7348c9e74c_AD_4nXereSxb1LwbF3gQkWmaRIiaTWnLerkCOe1LQC7UkXb1fHsoBFVsObM61xQOrKuUxci1VFe8EJJifGOqG9Kp4CrkcnYMklYglRboEOYzE4T4y_ZO-mYYaPMB665HXIK_bTfjnVrqSHR5Las7xKwwypB19ZaF.png" loading="lazy" alt=""></p></figure><p>I find this is often an artifact of the DE roles not being equipped with the necessary knowledge of more generic SWE tools, and general SWEs not being equipped with knowledge of data-specific tools and workflows.</p><p>Speaking of, especially in smaller companies, equipping all engineers with the technical tooling and knowledge to work on all parts of the platform (including data) is a big advantage, since it allows people not usually on your team to help on projects as needed. Standardized tooling is a part of that equation.</p><p>For instance, we have an internal, Go-based developer CLI, called <code>nd</code>, that does a lot of heavy lifting (think “abstract <code>kubectl</code> commands for half a dozen clusters”). We also use it to run diffs between a developer’s branch and expected state, for instance to enforce formatting and code styles. Our CI runners run NixOS.&nbsp;</p><p>So, for our data work, enforcing standards around dbt models involved a custom Nix package for <a href="https://pypi.org/project/shandy-sqlfmt/">shandy-sqlfmt</a>, which we use as a standard for formatting all our dbt models, as well as integration into our <code>nd</code> tool, so developers (as well as CI) have access to <code>nd sql fmt</code>, just as they have <code>nd go fmt</code>.</p><p>While this <em>does</em> involve additional work for me, it ensures data tooling is never the “odd one out” and ramping onto data work (or vice versa) is much less of a cognitive shift.</p><p>Other integrations we've added over time include:</p><ul role="list"><li>Bespoke, modern Python tooling (not only for our data tools), such as <code>poetry</code> and <code>ruff</code>, as well as enforcement of style and static analysis via CI.</li><li>Smart <code>sbt</code> caches for Scala, since Scala + Bazel is not something we’ve explored in depth.</li><li>Datadog monitors and metrics, including custom metric interfaces for all our data tools.</li><li>Integration in our on-call tooling, such as Slack alerts, OpsGenie integration, and others.</li><li>Various custom Nix derivations.</li></ul><h3>Wrestling schemas and structs between Airbyte and Glue</h3><p>A more "data specific" challenge we've dealt with are complex schemas in Airbyte that often don’t match the actual data or are otherwise incompatible with our query engine, which is something I’m sure a lot of you are familiar with.</p><p>With a team of one, I can’t reasonably write individual jobs for individual tables or sources that handle all corner cases, as we simply have too large and diverse a set of data sources. Myself and others <em>have</em> to rely on code-gen and automated processing. This holds true for all data tools, not just Airbyte.</p><p>Originally, we wrote JSON files to S3, which supported the arbitrary data and schema changes that might happen, and ran AWS Glue <a href="https://docs.aws.amazon.com/glue/latest/dg/add-crawler.html">crawlers</a> on top of these files to detect the schema and create "raw" tables.&nbsp;</p><p>JSON is conceptually nice for this, since it can deal with arbitrary schemas. For example, using <a href="https://docs.airbyte.com/integrations/destinations/s3#parquet">a parquet writer</a> to S3 would rely on the source schema to be 100% accurate and has to deal with an array of <a href="https://docs.airbyte.com/understanding-airbyte/json-avro-conversion">limitations</a>. Glue crawlers, on paper, support table versions and table evolutions.</p><p>But we quickly realized that these crawlers were very unreliable, especially with changing schemas or differences between <code>dev</code> and <code>prod</code>. This resulted in schemas that either couldn't be queried outright or reported incorrect data.</p><p>We experimented with custom schema detection logic, which gave us more control over parameters like sample size, look back windows, and corner cases, but found that burdensome to manage, despite using existing libraries.</p><p>A part of this was AWS Glue's odd way of storing <code>structs</code>, which are (deceptively so) depicted as arbitrarily deep JSON objects in the Glue web UI:</p><pre contenteditable="false"><code><span>{
</span><span>  </span><span>"payment_method_configuration_details"</span><span>: {
</span><span>    </span><span>"id"</span><span>: </span><span>"string"</span><span>,
</span><span>    </span><span>"parent"</span><span>: </span><span>"string"</span><span>
</span>  }
}
</code></pre><p><br>Whereas the API describes these fields as:</p><pre contenteditable="false"><code><span>{
</span><span>  </span><span>"Name"</span><span>: </span><span>"payment_method_configuration_details"</span><span>,
</span><span>  </span><span>"Type"</span><span>: </span><span>"struct&lt;id:string,parent:string&gt;"</span><span>
</span>}
</code></pre><p><br>Which includes describe table and show create table statements via Athena:</p><pre contenteditable="false"><code><span>CREATE</span><span> </span><span>EXTERNAL</span><span> </span><span>TABLE</span><span> `...`(
</span><span>  `status` string COMMENT </span><span>'from deserializer'</span><span>, 
</span><span>  `payment_method_configuration_details` struct</span><span>&lt;</span><span>id:string,parent:string</span><span>&gt;</span><span> COMMENT </span><span>'from deserializer'</span><span>, 
</span></code></pre><p><br>This very custom, bespoke way of describing structs meant that standard "JSON to JSON schema" parsers would not work out of the box. While it <em>is</em> possible to work around some of this, this became a very convoluted problem, given that some AWS APIs are notoriously convoluted in themselves. The Glue API expects the <code>struct&lt;</code> syntax, for instance.&nbsp;</p><p>It’s also arguably not a problem we <em>should</em> need to solve.</p><p>So, we settled on using the <a href="https://docs.airbyte.com/integrations/destinations/s3-glue">Airbyte Glue</a> destination connector, which would create the tables <em>directly</em> on Glue based on the <em>reported</em> schema of the source. This eliminates the additional hop (and point of failure) of running a crawler entirely and ensures we get at least a valid Glue table (albeit not necessarily a valid Athena table).</p><p>But it still does not solve the issue of fields being reported incorrectly at times, usually directly by the API.&nbsp;</p><p>For instance, the table <code>stripe.charges</code> cannot be queried due to Athena returning a <code>TYPE_NOT_FOUND: Unknown type: row</code> error. Trying to get a DDL will yield a <code>java.lang.IllegalArgumentException: Error: name expected at the position 204</code>. Keep in mind that this was entirely set up by Airbyte, with no human involvement or custom code run yet.</p><p>Position 204, for those that are curious, looks like this: <code>total_count:decimal(38)&gt;:boolean:struct&lt;&gt;:</code></p><p>This <code>struct&lt;&gt;</code> field can't be queried in Athena.&nbsp;</p><p>To solve this, we now have a post-processing step that turns each <code>struct</code> field into a custom tree data structure, maps or removes invalid types at arbitrary depth (such as <code>struct&lt;&gt;</code>), and generates a terraform representation of each table, so we get uniform environments between <code>dev</code> and <code>prod</code>.</p><p>It also does an additional step by creating a flattened table that will map each nested field into a flat field with the appropriate type. We do this to maximize compatibility with Iceberg and make queries more ergonomic for users.</p><p>This works by querying the Glue API and some basic DSA. For instance, the following field might present as:</p><figure><p><img src="https://cdn.prod.website-files.com/63ed707844acb1ccf1ccb700/66f5b58a45ad187d0e21c138_AD_4nXeNLfZZI-46_knQ9jRrw4jecER1YNMusOiLSmgMBImh8QrrdxsayanRiTzMd4UZYru3WSFUYy0GOSRWE1VfarzAiLjPTcr2LbJ144LcmsT9pJoM_V1jFg5O_7-fwH3R6X9CXvzktm8qNZW52mvlKKEZ56VA.png" loading="lazy" alt=""></p></figure><p>But <em>really</em> contain the following data, as reported to Glue (note the object under <code>subscription_items</code>):</p><pre contenteditable="false"><code><span>{
</span><span>  </span><span>"pending_update"</span><span>: {
</span><span>    </span><span>"trial_end"</span><span>: </span><span>"int"</span><span>,
</span><span>    </span><span>"expires_at"</span><span>: </span><span>"int"</span><span>,
</span><span>    </span><span>"trial_from_plan"</span><span>: </span><span>"boolean"</span><span>,
</span><span>    </span><span>"subscription_items"</span><span>: [
</span>      {
<span>        </span><span>"id"</span><span>: </span><span>"string"</span><span>,
</span><span>        </span><span>"price"</span><span>: {
</span><span>          </span><span>"id"</span><span>: </span><span>"string"</span><span>,
</span><span>          </span><span>"type"</span><span>: </span><span>"string"</span><span>,
</span><span>          </span><span>// ...</span><span>
</span>  }
}
</code></pre><p><br>If any of these fields is invalid, we map them to valid names or remove them.</p><p>For instance, a <code>struct&lt;&gt;</code> or simply a field that has a name that’s invalid in Athena, but valid in Glue). Invalid names like <code>"street-name"</code> or <code>"1streetname"</code> need to be escaped with <code>"</code> in Athena, but cannot be used in nested <a href="https://aws.amazon.com/blogs/big-data/create-tables-in-amazon-athena-from-nested-json-and-mappings-using-jsonserde/">fields</a>, which are very common in JSON.</p><p>Airbyte also doesn’t have a <code>bigint</code> type, but Athena does; if a schema reports an Athena <code>Integer</code> type, we generally map it to a <code>bigint</code> to be safe, since a value &gt;= 2^32 will cause Athena queries to fail. We also normalize other types, such as <code>decimal(38)</code>.</p><p>All of this results in parsed (stripped) tree similar to this, with types attached on the nodes:</p><figure><p><img src="https://cdn.prod.website-files.com/63ed707844acb1ccf1ccb700/66f5b5eb4af04a7348cb4928_66f5b5e45c7adfabdfed07ca_blog-ngrok-data-platform-diagram.png" loading="lazy" alt=""></p></figure><p>Which we can now traverse and mutate, e.g. change names, types, or set deletion tombstones.&nbsp;</p><p>This would yield a field in the "raw" table as:</p><pre contenteditable="false"><code><span>columns {
</span><span>  name    = </span><span>"pending_update"</span><span>
</span><span>  type    = </span><span>"struct&lt;trial_end:bigint,expires_at:bigint,trial_from_plan:boolean,subscription_items:array&lt;struct&lt; //...</span></code></pre><p><br>As well as several fields in the target table, mapping the to aforementioned flat fields:</p><pre contenteditable="false"><code><span>columns {
</span><span>    name    = </span><span>"pending_update_billing_cycle_anchor"</span><span>
</span><span>    type    = </span><span>"bigint"</span><span>
</span>    parameters = {
<span>      </span><span>"iceberg.field.current"</span><span>: </span><span>"true"</span><span>,
</span><span>      </span><span>"iceberg.field.id"</span><span>: </span><span>"67"</span><span>,
</span><span>      </span><span>"iceberg.field.optional"</span><span>: </span><span>"true"</span><span>
</span>    }
  }
</code></pre><p><br>This way, we reap several benefits:</p><ul role="list"><li>We can rely on a provided schema by the source as much as possible by directly writing from Airbyte to Glue.</li><li>We have generated code that we can version control for both the raw as well as the target table.</li><li>We eliminate any potential differences between <code>dev</code> and <code>prod</code>, since we rely on the sources' reported schema.</li></ul><p>And, perhaps most importantly, it makes this process manageable for our specific team setup. Our next step is to terraform the entire Airbyte process.</p><p>While this is arguably just as complicated as running custom JSON schema parsers, we found that investing the time into building a proper data structure once and adjusting the ruleset where needed down the line was very much worth it, rather than trying to beat Glue crawlers or external JSON parser libraries into submission.</p><h3>Scaling Apache Flink, Scala, and Protobuf to 650 GB/day</h3><p>Another technically challenging, albeit interesting component, is our streaming integration with our core codebase.</p><p>We stream a subset of our Protobuf messages to Apache Iceberg via Kafka and Flink and make them available to query—in fact, it's one of our core sources to fight abuse (more on that in a second). Our Flink jobs are all written in Scala 3, relying on <a href="https://github.com/flink-extended/flink-scala-api"><code>flink-extended/flink-scala-api</code></a>.</p><p>Between our regular services, we interact via GRPC and talk Protobuf, which perhaps isn't the most common format in the data world. However, hooking our data processing tools directly into Protobuf has several advantages:</p><ul role="list"><li>Protobuf's schema evolution is one-directional; Apache Iceberg actually supports a lot more evolutions than Protobuf does, making sure our schemas stay in sync with the business' schemas</li><li>Old messages are always compatible with newer ones, meaning we never run into distributed ordering messages (i.e., processing a message with an old schema for a new table)</li><li>Protobuf, albeit oddly opinionated, is relatively straightforward and has great Scala support via <a href="https://scalapb.github.io/">scalapb</a></li><li>It's a very efficient format on the wire, making it so that our pipelines can process tens or hundreds of thousands of events per second</li></ul><p>Our main job consumes an average of ~9,000-15,000 events/s and at about ~691 bytes per message. Over time, this works out to roughly ~1,000,000,000 events or ~650 GB per day, split across ~55 message types, each with a different schema. Our other, more specialized streaming jobs are in the lower millions a day.</p><p>From a technical perspective, this was a fun challenge to solve. We achieve the entire process by, in essence, sending a wrapper message called <code>SubscriptionEvent</code> that contains an <code>EventType</code> (an <code>enum</code>) that describes the content of the wrapper and a <code>[]byte</code> field that contains the actual target Protobuf (one of the aforementioned 55 message types). Newer pipelines skip that wrapper message, but this system predates the data platform.</p><ol role="list"><li>We generate all Protobuf Scala classes with some custom mappings to ensure all types are compatible with Iceberg (<code>one-ofs</code>, for instance, are not!), using <code>scalapb</code>.</li><li>We generate a slightly customized <code>avro</code> schema (mostly to add metadata), <code>serializers</code>, <code>deserializers</code>, and so on, for each target message and store them as Scala objects (so this isn’t done at runtime).</li></ol><p>In the pipeline:</p><ol role="list"><li>We read the raw <em>wrapper</em> message from Kafka.</li><li>We split it by the <code>EventType</code> and parse the <em>target</em> Protobuf type by parsing the <code>[]byte</code> field on the message and yield an output tag to route messages by type.</li><li>We use previously generated <code>avro</code> schema and use the <code>FlinkWriter</code> for Iceberg to write the data, based on the job's checkpoint interval.</li></ol><p>Or, in Scala terms:</p><pre contenteditable="false"><code><span>pipeline[</span><span>A</span><span> &lt;: </span><span>GeneratedMessage</span><span>: </span><span>TypeInformation</span><span> : </span><span>EventTyper</span><span> : </span><span>SerializableTimestampAssigner</span><span> : </span><span>ProtoHandler</span><span>]</span></code></pre><p><br>The combination of having nested messages and incompatible types made it impossible to use any of the built-in Protobuf parser that exist w/in the Flink ecosystem. In fact, I had to <a href="https://github.com/scalapb/ScalaPB/pull/1674">customize</a> <code>scalapb</code>.</p><p>One of the key elements in this is a typeclass called <code>ProtoHandle</code> that provides a <code>ProtoHandle</code>:</p><pre contenteditable="false"><code><span>trait</span><span> </span><span>ProtoHandle</span><span>[
</span><span>    </span><span>A</span><span>,
</span><span>    </span><span>B</span><span> &lt;: </span><span>GeneratedMessage</span><span>: </span><span>EventTyper</span><span>: </span><span>AvroMeta</span><span>
</span><span>] </span><span>extends</span><span> </span><span>Serializable</span><span> </span><span>{
</span><span>  </span><span>type</span><span> </span><span>ValueType</span><span> </span><span>= </span><span>A</span><span>
</span><span>  </span><span>def</span><span> </span><span>derivedSchema</span><span>: </span><span>AvroSchema</span><span>
</span><span>  </span><span>protected</span><span> </span><span>def</span><span> </span><span>encoder</span><span>: </span><span>MetaRecordEncoder</span><span>[</span><span>A</span><span>]
</span><span>  </span><span>def</span><span> </span><span>encode</span><span>(msg: </span><span>A</span><span>, schema: </span><span>AvroSchema</span><span>, metadata: </span><span>AvroMetadata</span><span>): </span><span>Record</span><span>
</span><span></span><span>// …</span><span>
</span>  }
</code></pre><p><br>A <code>ProtoHandle</code> is a generic structure that's responsible for schema parsing and encoding, for each Protobuf.</p><p>For efficiency reasons by front loading a lot of heavily lifting to compile time, we code generate all known <code>ProtoHandle</code>s based on the <code>enum</code>:</p><pre contenteditable="false"><code><span>case</span><span> </span><span>object</span><span> </span><span>CAComp</span><span> </span><span>extends</span><span> </span><span>CompanionComp</span><span>[</span><span>CA</span><span>] </span><span>{
</span><span>  </span><span>private</span><span> </span><span>val</span><span> </span><span>T</span><span> = </span><span>CA</span><span>
</span><span>  </span><span>private</span><span> </span><span>val</span><span> coreSchema: </span><span>Schema</span><span> = </span><span>AvroSchema</span><span>[</span><span>CA</span><span>]
</span><span>  </span><span>private</span><span> </span><span>val</span><span> schema: </span><span>Schema</span><span> = coreSchema.withMetadata
</span><span>  </span><span>private</span><span> </span><span>val</span><span> enc: </span><span>AvroEncoder</span><span>[</span><span>CA</span><span>] = </span><span>AvroEncoder</span><span>[</span><span>CA</span><span>]
</span><span>  </span><span>private</span><span> </span><span>val</span><span> ti: </span><span>TypeInformation</span><span>[</span><span>CA</span><span>] = deriveTypeInformation[</span><span>CA</span><span>]
</span><span>  </span><span>override</span><span> </span><span>val</span><span> handle: </span><span>ProtoHandle</span><span>[</span><span>CA</span><span>, </span><span>SubscriptionEvent</span><span>] = </span><span>SubscriptionEventProtoHandle</span><span>(
</span><span>    </span><span>T</span><span>.messageCompanion,
</span>    schema,
    enc,
    ti
  )
}
</code></pre><p><br>These objects (in Java terms, <code>static</code>) derive the <code>avro</code> schema using <code>com.sksamuel.avro4s.AvroSchema</code>, as well as the encoder using <code>com.sksamuel.avro4s.Encoder</code>, which uses <code>magnolia</code> under the hood.</p><p>We now have one correct, working <code>avro</code> schema + encoder for each possible Protobuf message.</p><blockquote>Note: Some of the type signatures look a bit <em>wild</em>—that's an artifact of the nested Protobufs&nbsp; and can only be partially simplified.<p>For instance, a <code>ProtoHandle</code> needs to know its own type (<code>A</code>) as well as its wrapper type (<code>B</code>) to correctly derive schemas and encoders, but for providing a concrete handler to a downstream implementation, we don't need to know about the concrete type of <code>A</code> anymore.</p><p>We also had to work around some other fun JVM limitations, such as <code>ClassTooLarge</code> errors, which did not make some of these class and type hierarchies easier to read.</p><p>This can be optimized, but this is also one of the results of a small team.</p></blockquote><p>We can then expose this mapping as <code>Map[FlinkEventTag, ProtoHandle[_, SubscriptionEvent]]</code> to the job.</p><p>For each mapping, we can now:</p><ul role="list"><li>Create the table or update its schema during the job's startup by relying on Iceberg's schema evolution.</li><li>Add a sink dynamically to a <code>Ref</code> of an incoming data stream.</li></ul><p>Or, expressed in code:</p><pre contenteditable="false"><code><span>trait</span><span> </span><span>FlinkWriter</span><span>[</span><span>A</span><span>, </span><span>B</span><span>: </span><span>IcebergTableNamer</span><span>] </span><span>extends</span><span> </span><span>Serializable</span><span> </span><span>{
</span><span>  </span><span>// Builds/updates tables and returns a cached map of all remote schemas</span><span>
</span><span>  </span><span>def</span><span> </span><span>buildTablesAndCacheSchemas</span><span>(): </span><span>Map</span><span>[</span><span>B</span><span>, </span><span>AvroSchema</span><span>]
</span><span>  </span><span>// Sink assigner. Mutates the DataStream[A] ref</span><span>
</span><span>  </span><span>def</span><span> </span><span>addSinksToStream</span><span>(
</span><span>      cfg: </span><span>Config</span><span>,
</span><span>      schemas: </span><span>Map</span><span>[</span><span>B</span><span>, </span><span>AvroSchema</span><span>],
</span><span>      env: </span><span>Ref</span><span>[</span><span>DataStream</span><span>[</span><span>A</span><span>]]
</span><span>  ): </span><span>List</span><span>[</span><span>DataStreamSink</span><span>[</span><span>Void</span><span>]]
</span>}
</code></pre><blockquote>Note: We do not (yet!) use an effect system and <code>Ref</code> is just a hint that we mutate a reference in a function: <code>type Ref[A] = A</code>.</blockquote><h3>Fighting abuse with meta signals</h3><p>One of the ways we actually use this data is to understand, fight, and ultimately prevent abusive behavior like the <a href="https://www.helpnetsecurity.com/2024/08/28/pioneer-kitten-iranian-hackers-partnering-with-ransomware-affiliates/">state-sponsored Pioneer Kitten group</a>.</p><p>While a lot of our processes around abuse detection are automated, some require human intervention.&nbsp;</p><p>Oftentimes, we’ll get abuse reports (via abuse@ngrok.com) and need to verify that these are accurate before we take action (such as banning an account). To do that, we can verify the reported abusive events match a certain account’s behavior on our platform.</p><p>If we suspect IP <code>198.51.100.1</code> to have hosted a phishing scam on port <code>443</code> via URL <code>anexampleofabusewedontwant.ngrok.app</code> on 2024-09-01, we can query our metadata similar to this:</p><pre contenteditable="false"><code><span>select</span><span> </span><span>case</span><span>
</span><span>    </span><span>when</span><span> event_type </span><span>=</span><span> </span><span>'ENDPOINT_CREATED'</span><span> </span><span>then</span><span> </span><span>'created'</span><span>
</span><span>    </span><span>when</span><span> event_type </span><span>=</span><span> </span><span>'ENDPOINT_DELETED'</span><span> </span><span>then</span><span> </span><span>'deleted'</span><span> </span><span>else</span><span> </span><span>'unknown'</span><span>
</span><span>  </span><span>end</span><span> </span><span>as</span><span> action,
</span>  account_id,
  event_timestamp,
  url,
  geo_location
<span></span><span>from</span><span> meta_events__audit_event_endpoint e
</span><span></span><span>where</span><span> account_id </span><span>=</span><span> </span><span>'bad_actor_id'</span><span> </span><span>and</span><span> </span><span>-- … other filters</span></code></pre><p><br>This will give us a full sequence of events, including what tunnels an account started, stopped, when, and from where. Based on this data, we can take action, such as suspending the account if the report is accurate.</p><p>On a similar note, in the event an account gets banned incorrectly and reaches out to our support team, they can query similar tables to do the same report in reverse and unban users.&nbsp;</p><h2>Build your own ngrok data platform (or work on ours!)</h2><p>While there are a lot of topics we didn't cover in this article, I hope it provided both a good high-level overview about data engineering work at ngrok, as well as some details on specific challenges we faced and solved.</p><p>To do your own digging on ngrok data, try exploring <a href="https://ngrok.com/docs/api/resources/event-subscriptions/">event subscriptions</a> or <a href="https://ngrok.com/docs/obs/traffic-inspection/">Traffic Inspector</a> to get insight into your own traffic data flowing through ngrok.</p><p>Or, if you prefer to work on and with our actual data platform, we’re currently <a href="https://boards.greenhouse.io/ngrokinc/jobs/5314175004">hiring a Senior Software Engineer, Trust &amp; Abuse</a>!&nbsp;</p><p>We’d love to chat about what additional challenges and improvement you’d want to dig into as an ngrokker. And, as always, you can ask questions about our data platform and beyond on our <a href="https://github.com/ngrok/ngrok">community repo</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Arch Linux team is now working directly with Valve (185 pts)]]></title>
            <link>https://www.tomshardware.com/software/linux/the-arch-linux-team-is-now-working-directly-with-valve-steamos-and-arch-should-both-benefit-greatly</link>
            <guid>41694283</guid>
            <pubDate>Mon, 30 Sep 2024 06:56:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/software/linux/the-arch-linux-team-is-now-working-directly-with-valve-steamos-and-arch-should-both-benefit-greatly">https://www.tomshardware.com/software/linux/the-arch-linux-team-is-now-working-directly-with-valve-steamos-and-arch-should-both-benefit-greatly</a>, See on <a href="https://news.ycombinator.com/item?id=41694283">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">

<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/cD6Mk3Td9BKRozyENhivpG-320-80.png.webp 320w, https://cdn.mos.cms.futurecdn.net/cD6Mk3Td9BKRozyENhivpG-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/cD6Mk3Td9BKRozyENhivpG-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/cD6Mk3Td9BKRozyENhivpG-970-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/cD6Mk3Td9BKRozyENhivpG-1024-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/cD6Mk3Td9BKRozyENhivpG-1200-80.png.webp 1200w, https://cdn.mos.cms.futurecdn.net/cD6Mk3Td9BKRozyENhivpG-1920-80.png.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/cD6Mk3Td9BKRozyENhivpG-320-80.png" alt="Arch Linux" srcset="https://cdn.mos.cms.futurecdn.net/cD6Mk3Td9BKRozyENhivpG-320-80.png 320w, https://cdn.mos.cms.futurecdn.net/cD6Mk3Td9BKRozyENhivpG-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/cD6Mk3Td9BKRozyENhivpG-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/cD6Mk3Td9BKRozyENhivpG-970-80.png 970w, https://cdn.mos.cms.futurecdn.net/cD6Mk3Td9BKRozyENhivpG-1024-80.png 1024w, https://cdn.mos.cms.futurecdn.net/cD6Mk3Td9BKRozyENhivpG-1200-80.png 1200w, https://cdn.mos.cms.futurecdn.net/cD6Mk3Td9BKRozyENhivpG-1920-80.png 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/cD6Mk3Td9BKRozyENhivpG.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/cD6Mk3Td9BKRozyENhivpG.png" data-pin-nopin="true" fetchpriority="high">
</picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/cD6Mk3Td9BKRozyENhivpG.png">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: Arch Linux)</span>
</figcaption>
</div>

<div id="article-body">
<p>The Arch Linux team has <a data-analytics-id="inline-link" href="https://lists.archlinux.org/archives/list/arch-dev-public@lists.archlinux.org/thread/RIZSKIBDSLY4S5J2E2STNP5DH4XZGJMR/" target="_blank" data-url="https://lists.archlinux.org/archives/list/arch-dev-public@lists.archlinux.org/thread/RIZSKIBDSLY4S5J2E2STNP5DH4XZGJMR/" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">announced on its public mailing list</a> that it will be entering into a direct collaboration with <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tag/valve" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.tomshardware.com/tag/valve">Valve</a>. This is a big deal for several reasons, but let's start with why and how it happened. If you're familiar with Valve and Steam Deck, you may already know that the Deck uses SteamOS 3, which is built on top of Arch Linux. Thanks to the Arch Linux base and Valve's development of the Proton compatibility layer for playing Windows games on Linux, we now have a far improved Linux gaming scene, especially on Valve's Steam Deck and Deck OLED handhelds.&nbsp;</p><p>While Valve's specific reasons for picking Arch Linux for Steam Deck remain unknown, it's pretty easy to guess why it was picked. Mainly, it's a particularly lightweight distribution maintained since March 2002, which lends itself well to gaming with minimal performance overhead. A more intensive Linux distribution may not have been the ideal base for SteamOS 3, which is targeted at handhelds like Steam Deck first.</p><p>As primary Arch Linux developer Levente Polyak discloses in the announcement post, "Valve is generously providing backing for two critical projects that will have a huge impact on our distribution: a build service infrastructure and a secure signing enclave. By supporting work on a freelance basis for these topics, Valve enables us to work on them without being limited solely by the free time of our volunteers."</p><p>Polyak continues, "This opportunity allows us to address some of the biggest outstanding challenges we have been facing for a while. The collaboration will speed up the progress that would otherwise take much longer for us to achieve, and will ultimately unblock us from finally pursuing some of our planned endeavors [...] We believe this collaboration will greatly benefit Arch Linux, and are looking forward to share further development on the mailing list as work progresses."</p><p>These quotes go to show how bigger corporations like Valve can still be a helpful, desirable influence in the FOSS (Free and Open Source Software) community. While the rules of FOSS dictate that Valve was under no obligation whatsoever to give back to the community in any way, it's had a great track record so far through Proton and is now directly funding the continued development of Arch Linux, which forms the foundation of its own SteamOS 3 operating system. It's true that volunteers in FOSS make that part of the tech world go round, but it's always nice when these projects can actually afford to pay people to get the work that needs to be done for the rest of our enjoyment.</p><p>In the long-term, the funding touted should, at minimum, allow Arch Linux to improve the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tag/security" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.tomshardware.com/tag/security">security</a> of its distribution and provide more structured releases compared to its current near-continuous update cycle. This could also lead to greater long-term improvements and feature additions, perhaps even ones that will benefit SteamOS 3 and its gaming performance, but for now, that part remains in the air.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-qVMNe7A62QoXQENKadU4Yo"><section><p>Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.</p></section></div>
</div>
<div id="slice-container-authorBio-qVMNe7A62QoXQENKadU4Yo"><p>Christopher Harper has been a successful freelance tech writer specializing in PC hardware and gaming since 2015, and ghostwrote&nbsp;for various B2B clients in High School before that. Outside of work, Christopher is best known to friends and rivals as an active competitive player in various eSports (particularly fighting games and arena shooters) and a purveyor of music ranging from Jimi Hendrix to Killer Mike to the&nbsp;Sonic Adventure 2&nbsp;soundtrack.</p></div>



<!-- Drop in a standard article here maybe? -->



</section>





<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>








</div></div>]]></description>
        </item>
    </channel>
</rss>